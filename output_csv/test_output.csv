,cleaned_method,target_block,tokens_in_method
0,"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True):<tab>try:<tab><tab>return self._read(count, timeout)<tab>except usb.USBError as e:<tab><tab>if DEBUG_COMM:<tab><tab><tab>log.info(<tab><tab><tab><tab>""read: e.errno=%s e.strerror=%s e.message=%s repr=%s""<tab><tab><tab><tab>% (e.errno, e.strerror, e.message, repr(e))<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return []<tab><tab>if ignore_non_errors and is_noerr(e):<tab><tab><tab>return []<tab><tab>raise",if ignore_timeouts and is_timeout ( e ) :,174
1,"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None):<tab>""""""cache hidden states into memory.""""""<tab>if mem_len is None or mem_len == 0:<tab><tab>return None<tab>else:<tab><tab>if reuse_len is not None and reuse_len > 0:<tab><tab><tab>curr_out = curr_out[:reuse_len]<tab><tab><IF-STMT><tab><tab><tab>new_mem = curr_out[-mem_len:]<tab><tab>else:<tab><tab><tab>new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:]<tab>new_mem.stop_gradient = True<tab>return new_mem",if prev_mem is None :,165
2,def filtered(gen):<tab>for example in gen:<tab><tab>example_len = length_fn(example)<tab><tab># Checking max length boundary.<tab><tab>if max_length is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab># Checking min length boundary.<tab><tab>if min_length is not None:<tab><tab><tab>if example_len < min_length:<tab><tab><tab><tab>continue<tab><tab># Within bounds.<tab><tab>yield example,if example_len > max_length :,117
3,"def search(self, query):<tab># ""Search.ashx?query="" + query + filterVal<tab>if not query:<tab><tab>logger.debug(""Empty search query"")<tab><tab>return []<tab>logger.debug('Searching TuneIn for ""%s""' % query)<tab>args = ""&query="" + query<tab>search_results = self._tunein(""Search.ashx"", args)<tab>results = []<tab>for item in self._flatten(search_results):<tab><tab><IF-STMT><tab><tab><tab># Only return stations<tab><tab><tab>self._stations[item[""guide_id""]] = item<tab><tab><tab>results.append(item)<tab>return results","if item . get ( ""type"" , """" ) == ""audio"" :",163
4,"def _check_script(self, script, directive):<tab>for var in compile_script(script):<tab><tab><IF-STMT><tab><tab><tab># Skip variable checks<tab><tab><tab>return False<tab><tab>if var.can_contain("".""):<tab><tab><tab># Yay! Our variable can contain any symbols!<tab><tab><tab>reason = (<tab><tab><tab><tab>'At least variable ""${var}"" can contain untrusted user input'.format(<tab><tab><tab><tab><tab>var=var.name<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>self.add_issue(directive=[directive] + var.providers, reason=reason)<tab><tab><tab>return True<tab>return False","if var . must_contain ( ""/"" ) :",157
5,"def getAllDataLinkIDs():<tab>linkDataIDs = set()<tab>dataType = _forestData.dataTypeBySocket<tab>for socketID, linkedIDs in _forestData.linkedSockets.items():<tab><tab>for linkedID in linkedIDs:<tab><tab><tab><IF-STMT>  # check which one is origin/target<tab><tab><tab><tab>linkDataIDs.add(<tab><tab><tab><tab><tab>(socketID, linkedID, dataType[socketID], dataType[linkedID])<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>linkDataIDs.add(<tab><tab><tab><tab><tab>(linkedID, socketID, dataType[linkedID], dataType[socketID])<tab><tab><tab><tab>)<tab>return linkDataIDs",if socketID [ 1 ] :,174
6,"def _stderr_supports_color():<tab>try:<tab><tab>if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty():<tab><tab><tab>if curses:<tab><tab><tab><tab>curses.setupterm()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab>elif colorama:<tab><tab><tab><tab>if sys.stderr is getattr(<tab><tab><tab><tab><tab>colorama.initialise, ""wrapped_stderr"", object()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>return True<tab>except Exception:<tab><tab># Very broad exception handling because it's always better to<tab><tab># fall back to non-colored logs than to break at startup.<tab><tab>pass<tab>return False","if curses . tigetnum ( ""colors"" ) > 0 :",170
7,"def offsets(self):<tab>offsets = {}<tab>offset_so_far = 0<tab>for name, ty in self.fields.items():<tab><tab>if isinstance(ty, SimTypeBottom):<tab><tab><tab>l.warning(<tab><tab><tab><tab>""Found a bottom field in struct %s. Ignore and increment the offset using the default ""<tab><tab><tab><tab>""element size."",<tab><tab><tab><tab>self.name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>if not self._pack:<tab><tab><tab>align = ty.alignment<tab><tab><tab><IF-STMT><tab><tab><tab><tab>offset_so_far += align - offset_so_far % align<tab><tab>offsets[name] = offset_so_far<tab><tab>offset_so_far += ty.size // self._arch.byte_width<tab>return offsets",if offset_so_far % align != 0 :,196
8,"def Restore(self):<tab>picker, obj = self._window, self._pObject<tab>value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH)<tab>if value is not None:<tab><tab>if issubclass(picker.__class__, wx.FileDialog):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value[-1]<tab><tab>picker.SetPath(value)<tab><tab>return True<tab>return False",if type ( value ) == list :,102
9,"def dt_s_tup_to_string(dt_s_tup):<tab>dt_string = dt_s_tup[0]  # string for identifying the file to parse.<tab>if dt_s_tup[1] > 0:  # if there are seasons in the model<tab><tab><IF-STMT><tab><tab><tab>dt_string = dt_string[:2] + ""s"" + dt_string[2:]<tab><tab>else:<tab><tab><tab>dt_string = ""s"" + dt_string<tab>return dt_string","if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",146
10,"def writer(stream, items):<tab>sep = """"<tab>for item in items:<tab><tab>stream.write(sep)<tab><tab>sep = "" ""<tab><tab><IF-STMT><tab><tab><tab>item = str(item)<tab><tab>if not PY3K:<tab><tab><tab>if not isinstance(item, unicode):<tab><tab><tab><tab>item = str(item)<tab><tab>stream.write(item)<tab>stream.write(""\n"")","if not isinstance ( item , str ) :",106
11,"def _get_result_keys(self, config):<tab>result_key = config.get(""result_key"")<tab>if result_key is not None:<tab><tab><IF-STMT><tab><tab><tab>result_key = [result_key]<tab><tab>result_key = [jmespath.compile(rk) for rk in result_key]<tab><tab>return result_key","if not isinstance ( result_key , list ) :",92
12,"def _download_build_artifacts(self, build: Dict[str, Any]) -> None:<tab>arch = build[""arch_tag""]<tab>snap_build = self._lp_load_url(build[""self_link""])<tab>urls = snap_build.getFileUrls()<tab>if not urls:<tab><tab>logger.error(f""Snap file not available for arch {arch!r}."")<tab><tab>return<tab>for url in urls:<tab><tab>file_name = _get_url_basename(url)<tab><tab>self._download_file(url=url, dst=file_name)<tab><tab><IF-STMT><tab><tab><tab>logger.info(f""Snapped {file_name}"")<tab><tab>else:<tab><tab><tab>logger.info(f""Fetched {file_name}"")","if file_name . endswith ( "".snap"" ) :",187
13,"def _add_custom_statement(self, custom_statements):<tab>if custom_statements is None:<tab><tab>return<tab>self.resource_policy[""Version""] = ""2012-10-17""<tab>if self.resource_policy.get(""Statement"") is None:<tab><tab>self.resource_policy[""Statement""] = custom_statements<tab>else:<tab><tab>if not isinstance(custom_statements, list):<tab><tab><tab>custom_statements = [custom_statements]<tab><tab>statement = self.resource_policy[""Statement""]<tab><tab>if not isinstance(statement, list):<tab><tab><tab>statement = [statement]<tab><tab>for s in custom_statements:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statement.append(s)<tab><tab>self.resource_policy[""Statement""] = statement",if s not in statement :,184
14,"def display_failures_for_single_test(result: TestResult) -> None:<tab>""""""Display a failure for a single method / endpoint.""""""<tab>display_subsection(result)<tab>checks = _get_unique_failures(result.checks)<tab>for idx, check in enumerate(checks, 1):<tab><tab>message: Optional[str]<tab><tab><IF-STMT><tab><tab><tab>message = f""{idx}. {check.message}""<tab><tab>else:<tab><tab><tab>message = None<tab><tab>example = cast(Case, check.example)  # filtered in `_get_unique_failures`<tab><tab>display_example(example, check.name, message, result.seed)<tab><tab># Display every time except the last check<tab><tab>if idx != len(checks):<tab><tab><tab>click.echo(""\n"")",if check . message :,188
15,"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""qangaroo"")<tab>version = ""v1.1""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,188
16,"def call(self, step_input, states):<tab>new_states = []<tab>for i in range(self.num_layers):<tab><tab>out, new_state = self.lstm_cells[i](step_input, states[i])<tab><tab>step_input = (<tab><tab><tab>layers.dropout(<tab><tab><tab><tab>out, self.dropout_prob, dropout_implementation=""upscale_in_train""<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab>else out<tab><tab>)<tab><tab>new_states.append(new_state)<tab>return step_input, new_states",if self . dropout_prob > 0.0,148
17,"def jupyter_progress_bar(min=0, max=1.0):<tab>""""""Returns an ipywidget progress bar or None if we can't import it""""""<tab>widgets = wandb.util.get_module(""ipywidgets"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab># TODO: this currently works in iPython but it's deprecated since 4.0<tab><tab><tab>from IPython.html import widgets  # type: ignore<tab><tab>assert hasattr(widgets, ""VBox"")<tab><tab>assert hasattr(widgets, ""Label"")<tab><tab>assert hasattr(widgets, ""FloatProgress"")<tab><tab>return ProgressWidget(widgets, min=min, max=max)<tab>except (ImportError, AssertionError):<tab><tab>return None",if widgets is None :,168
18,"def _record_event(self, path, fsevent_handle, filename, events, error):<tab>with self.lock:<tab><tab>self.events[path].append(events)<tab><tab><IF-STMT><tab><tab><tab>if not os.path.exists(path):<tab><tab><tab><tab>self.watches.pop(path).close()",if events | pyuv . fs . UV_RENAME :,89
19,"def _get_v1_id_from_tags(self, tags_obj, tag):<tab>""""""Get image id from array of tags""""""<tab>if isinstance(tags_obj, dict):<tab><tab>try:<tab><tab><tab>return tags_obj[tag]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>elif isinstance(tags_obj, []):<tab><tab>try:<tab><tab><tab>for tag_dict in tags_obj:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return tag_dict[""layer""]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return """"","if tag_dict [ ""name"" ] == tag :",142
20,"def query_lister(domain, query="""", max_items=None, attr_names=None):<tab>more_results = True<tab>num_results = 0<tab>next_token = None<tab>while more_results:<tab><tab>rs = domain.connection.query_with_attributes(<tab><tab><tab>domain, query, attr_names, next_token=next_token<tab><tab>)<tab><tab>for item in rs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if num_results == max_items:<tab><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>yield item<tab><tab><tab>num_results += 1<tab><tab>next_token = rs.next_token<tab><tab>more_results = next_token != None",if max_items :,166
21,"def filter(this, args):<tab>array = to_object(this, args.space)<tab>callbackfn = get_arg(args, 0)<tab>arr_len = js_arr_length(array)<tab>if not is_callable(callbackfn):<tab><tab>raise MakeError(""TypeError"", ""callbackfn must be a function"")<tab>_this = get_arg(args, 1)<tab>k = 0<tab>res = []<tab>while k < arr_len:<tab><tab><IF-STMT><tab><tab><tab>kValue = array.get(unicode(k))<tab><tab><tab>if to_boolean(callbackfn.call(_this, (kValue, float(k), array))):<tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return args.space.ConstructArray(res)",if array . has_property ( unicode ( k ) ) :,194
22,"def every_one_is(self, dst):<tab>msg = ""all members of %r should be %r, but the %dth is %r""<tab>for index, item in enumerate(self._src):<tab><tab>if self._range:<tab><tab><tab>if index < self._range[0] or index > self._range[1]:<tab><tab><tab><tab>continue<tab><tab>error = msg % (self._src, dst, index, item)<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(error)<tab>return True",if item != dst :,124
23,"def schedule_logger(job_id=None, delete=False):<tab>if not job_id:<tab><tab>return getLogger(""fate_flow_schedule"")<tab>else:<tab><tab>if delete:<tab><tab><tab>with LoggerFactory.lock:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>for key in LoggerFactory.schedule_logger_dict.keys():<tab><tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab><tab>del LoggerFactory.schedule_logger_dict[key]<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab><tab>key = job_id + ""schedule""<tab><tab>if key in LoggerFactory.schedule_logger_dict:<tab><tab><tab>return LoggerFactory.schedule_logger_dict[key]<tab><tab>return LoggerFactory.get_schedule_logger(job_id)",if job_id in key :,198
24,"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab>if item[0]:<tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab>elif item[1]:<tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab><IF-STMT><tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab>elif item[3]:<tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",elif item [ 2 ] :,181
25,"def _read_data_from_all_categories(self, directory, config, categories):<tab>lines = []<tab>for category in categories:<tab><tab>data_file = os.path.join(directory, _DATASET_VERSION, category, config)<tab><tab><IF-STMT><tab><tab><tab>with open(data_file) as f:<tab><tab><tab><tab>ls = f.read().split(""\n"")<tab><tab><tab><tab>for l in ls[::-1]:<tab><tab><tab><tab><tab>if not l:<tab><tab><tab><tab><tab><tab>ls.remove(l)<tab><tab><tab><tab>lines.extend(ls)<tab>return lines",if os . path . exists ( data_file ) :,150
26,"def find_handlers(self, forms):<tab>handlers = {}<tab>for form in forms.itervalues():<tab><tab>for action_name, _action_label in form.actions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handlers[action_name] = form<tab><tab><tab>else:<tab><tab><tab><tab>raise HandlerError(<tab><tab><tab><tab><tab>""More than one form defines the handler %s"" % action_name<tab><tab><tab><tab>)<tab>return handlers",if action_name not in handlers :,112
27,"def get_story_task_completed_body(payload: Dict[str, Any]) -> Optional[str]:<tab>action = get_action_with_primary_id(payload)<tab>kwargs = {<tab><tab>""task_description"": action[""description""],<tab>}<tab>story_id = action[""story_id""]<tab>for ref in payload[""references""]:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""name_template""] = STORY_NAME_TEMPLATE.format(<tab><tab><tab><tab>name=ref[""name""],<tab><tab><tab><tab>app_url=ref[""app_url""],<tab><tab><tab>)<tab>if action[""changes""][""complete""][""new""]:<tab><tab>return STORY_TASK_COMPLETED_TEMPLATE.format(**kwargs)<tab>else:<tab><tab>return None","if ref [ ""id"" ] == story_id :",188
28,"def _create_valid_graph(graph):<tab>nodes = graph.nodes()<tab>for i in range(len(nodes)):<tab><tab>for j in range(len(nodes)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>edge = (nodes[i], nodes[j])<tab><tab><tab>if graph.has_edge(edge):<tab><tab><tab><tab>graph.del_edge(edge)<tab><tab><tab>graph.add_edge(edge, 1)",if i == j :,112
29,"def _post_order(op):<tab>if isinstance(op, tvm.tir.Allocate):<tab><tab>lift_stmt[-1].append(op)<tab><tab>return op.body<tab>if isinstance(op, tvm.tir.AttrStmt):<tab><tab><IF-STMT><tab><tab><tab>lift_stmt[-1].append(op)<tab><tab><tab>return op.body<tab><tab>if op.attr_key == ""virtual_thread"":<tab><tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab><tab>return op<tab>if isinstance(op, tvm.tir.For):<tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab>raise RuntimeError(""not reached"")","if op . attr_key == ""storage_scope"" :",188
30,"def format_lazy_import(names):<tab>""""""Formats lazy import lines""""""<tab>lines = """"<tab>for _, name, asname in names:<tab><tab>pkg, _, _ = name.partition(""."")<tab><tab><IF-STMT><tab><tab><tab>line = ""{pkg} = _LazyModule.load({pkg!r}, {mod!r})\n""<tab><tab>else:<tab><tab><tab>line = ""{asname} = _LazyModule.load({pkg!r}, {mod!r}, {asname!r})\n""<tab><tab>lines += line.format(pkg=pkg, mod=name, asname=asname)<tab>return lines",if asname is None :,140
31,"def evaluateWord(self, argument):<tab>wildcard_count = argument[0].count(""*"")<tab>if wildcard_count > 0:<tab><tab>if wildcard_count == 1 and argument[0].startswith(""*""):<tab><tab><tab>return self.GetWordWildcard(argument[0][1:], method=""endswith"")<tab><tab>if wildcard_count == 1 and argument[0].endswith(""*""):<tab><tab><tab>return self.GetWordWildcard(argument[0][:-1], method=""startswith"")<tab><tab>else:<tab><tab><tab>_regex = argument[0].replace(""*"", "".+"")<tab><tab><tab>matched = False<tab><tab><tab>for w in self.words:<tab><tab><tab><tab>matched = bool(re.search(_regex, w))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>return matched<tab>return self.GetWord(argument[0])",if matched :,194
32,"def setup(self, ir: ""IR"", aconf: Config) -> bool:<tab>if self.kind == ""ConsulResolver"":<tab><tab>self.resolve_with = ""consul""<tab><tab><IF-STMT><tab><tab><tab>self.post_error(""ConsulResolver is required to have a datacenter"")<tab><tab><tab>return False<tab>elif self.kind == ""KubernetesServiceResolver"":<tab><tab>self.resolve_with = ""k8s""<tab>elif self.kind == ""KubernetesEndpointResolver"":<tab><tab>self.resolve_with = ""k8s""<tab>else:<tab><tab>self.post_error(f""Resolver kind {self.kind} unknown"")<tab><tab>return False<tab>return True","if not self . get ( ""datacenter"" ) :",170
33,"def get_success_url(self):<tab>""""""Continue to the flow index or redirect according `?back` parameter.""""""<tab>if ""back"" in self.request.GET:<tab><tab>back_url = self.request.GET[""back""]<tab><tab><IF-STMT><tab><tab><tab>back_url = ""/""<tab><tab>return back_url<tab>return reverse(self.success_url)","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :",111
34,"def download_main(<tab>download, download_playlist, urls, playlist, output_dir, merge, info_only):<tab>for url in urls:<tab><tab>if url.startswith(""https://""):<tab><tab><tab>url = url[8:]<tab><tab><IF-STMT><tab><tab><tab>url = ""http://"" + url<tab><tab>if playlist:<tab><tab><tab>download_playlist(<tab><tab><tab><tab>url, output_dir=output_dir, merge=merge, info_only=info_only<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>download(url, output_dir=output_dir, merge=merge, info_only=info_only)","if not url . startswith ( ""http://"" ) :",155
35,"def __str__(self):<tab>buf = [""""]<tab>if self.fileName:<tab><tab>buf.append(self.fileName + "":"")<tab>if self.line != -1:<tab><tab><IF-STMT><tab><tab><tab>buf.append(""line "")<tab><tab>buf.append(str(self.line))<tab><tab>if self.column != -1:<tab><tab><tab>buf.append("":"" + str(self.column))<tab><tab>buf.append("":"")<tab>buf.append("" "")<tab>return str("""").join(buf)",if not self . fileName :,124
36,"def parse_bash_set_output(output):<tab>""""""Parse Bash-like 'set' output""""""<tab>if not sys.platform.startswith(""win""):<tab><tab># Replace ""\""-continued lines in *Linux* environment dumps.<tab><tab># Cannot do this on Windows because a ""\"" at the end of the<tab><tab># line does not imply a continuation.<tab><tab>output = output.replace(""\\\n"", """")<tab>environ = {}<tab>for line in output.splitlines(0):<tab><tab>line = line.rstrip()<tab><tab>if not line:<tab><tab><tab>continue  # skip black lines<tab><tab>item = _ParseBashEnvStr(line)<tab><tab><IF-STMT><tab><tab><tab>environ[item[0]] = item[1]<tab>return environ",if item :,177
37,"def remove_selected(self):<tab>""""""Removes selected items from list.""""""<tab>to_delete = []<tab>for i in range(len(self)):<tab><tab>if self[i].selected:<tab><tab><tab>to_delete.append(i)<tab>to_delete.reverse()<tab>for i in to_delete:<tab><tab>self.pop(i)<tab>if len(to_delete) > 0:<tab><tab>first_to_delete = to_delete[-1]<tab><tab><IF-STMT><tab><tab><tab>self[0].selected = True<tab><tab>elif first_to_delete > 0:<tab><tab><tab>self[first_to_delete - 1].selected = True",if first_to_delete == 0 and len ( self ) > 0 :,169
38,"def update(self, update_tracks=True):<tab>self.enable_update_metadata_images(False)<tab>old_album_title = self.metadata[""album""]<tab>self.metadata[""album""] = config.setting[""nat_name""]<tab>for track in self.tracks:<tab><tab><IF-STMT><tab><tab><tab>track.metadata[""album""] = self.metadata[""album""]<tab><tab>for file in track.linked_files:<tab><tab><tab>track.update_file_metadata(file)<tab>self.enable_update_metadata_images(True)<tab>super().update(update_tracks)","if old_album_title == track . metadata [ ""album"" ] :",149
39,"def on_input(self, target, message):<tab>if message.strip() == """":<tab><tab>self.panel(""No commit message provided"")<tab><tab>return<tab>if target:<tab><tab>command = [""git"", ""add""]<tab><tab><IF-STMT><tab><tab><tab>command.append(""--all"")<tab><tab>else:<tab><tab><tab>command.extend((""--"", target))<tab><tab>self.run_command(command, functools.partial(self.add_done, message))<tab>else:<tab><tab>self.add_done(message, """")","if target == ""*"" :",125
40,"def go_to_last_edit_location(self):<tab>if self.last_edit_cursor_pos is not None:<tab><tab>filename, position = self.last_edit_cursor_pos<tab><tab><IF-STMT><tab><tab><tab>self.last_edit_cursor_pos = None<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>self.load(filename)<tab><tab><tab>editor = self.get_current_editor()<tab><tab><tab>if position < editor.document().characterCount():<tab><tab><tab><tab>editor.set_cursor_position(position)",if not osp . isfile ( filename ) :,135
41,"def returnByType(self, results):<tab>new_results = {}<tab>for r in results:<tab><tab>type_name = r.get(""type"", ""movie"") + ""s""<tab><tab><IF-STMT><tab><tab><tab>new_results[type_name] = []<tab><tab>new_results[type_name].append(r)<tab># Combine movies, needs a cleaner way..<tab>if ""movies"" in new_results:<tab><tab>new_results[""movies""] = self.combineOnIMDB(new_results[""movies""])<tab>return new_results",if type_name not in new_results :,144
42,"def cache_sns_topics_across_accounts() -> bool:<tab>function: str = f""{__name__}.{sys._getframe().f_code.co_name}""<tab># First, get list of accounts<tab>accounts_d: list = async_to_sync(get_account_id_to_name_mapping)()<tab>for account_id in accounts_d.keys():<tab><tab>if config.get(""environment"") == ""prod"":<tab><tab><tab>cache_sns_topics_for_account.delay(account_id)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cache_sns_topics_for_account.delay(account_id)<tab>stats.count(f""{function}.success"")<tab>return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",185
43,"def get(self, subject, topic):<tab>""""""Handles GET requests.""""""<tab>if subject in feconf.AVAILABLE_LANDING_PAGES:<tab><tab><IF-STMT><tab><tab><tab>self.render_template(""topic-landing-page.mainpage.html"")<tab><tab>else:<tab><tab><tab>raise self.PageNotFoundException<tab>else:<tab><tab>raise self.PageNotFoundException",if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,100
44,"def callback(compiled):<tab><IF-STMT><tab><tab>logger.show_tabulated(<tab><tab><tab>""Compiled"", showpath(codepath), ""without writing to file.""<tab><tab>)<tab>else:<tab><tab>with univ_open(destpath, ""w"") as opened:<tab><tab><tab>writefile(opened, compiled)<tab><tab>logger.show_tabulated(""Compiled to"", showpath(destpath), ""."")<tab>if self.show:<tab><tab>print(compiled)<tab>if run:<tab><tab>if destpath is None:<tab><tab><tab>self.execute(compiled, path=codepath, allow_show=False)<tab><tab>else:<tab><tab><tab>self.execute_file(destpath)",if destpath is None :,166
45,"def _find_start_index(self, string, start, end):<tab>while True:<tab><tab>index = string.find(""{"", start, end) - 1<tab><tab>if index < 0:<tab><tab><tab>return -1<tab><tab><IF-STMT><tab><tab><tab>return index<tab><tab>start = index + 2","if self . _start_index_is_ok ( string , index ) :",84
46,"def _get_nlu_target_format(export_path: Text) -> Text:<tab>guessed_format = loading.guess_format(export_path)<tab>if guessed_format not in {MARKDOWN, RASA, RASA_YAML}:<tab><tab>if rasa.shared.data.is_likely_json_file(export_path):<tab><tab><tab>guessed_format = RASA<tab><tab>elif rasa.shared.data.is_likely_markdown_file(export_path):<tab><tab><tab>guessed_format = MARKDOWN<tab><tab><IF-STMT><tab><tab><tab>guessed_format = RASA_YAML<tab>return guessed_format",elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,166
47,"def moveToThreadNext(self):<tab>""""""Move a position to threadNext position.""""""<tab>p = self<tab>if p.v:<tab><tab>if p.v.children:<tab><tab><tab>p.moveToFirstChild()<tab><tab>el<IF-STMT><tab><tab><tab>p.moveToNext()<tab><tab>else:<tab><tab><tab>p.moveToParent()<tab><tab><tab>while p:<tab><tab><tab><tab>if p.hasNext():<tab><tab><tab><tab><tab>p.moveToNext()<tab><tab><tab><tab><tab>break  # found<tab><tab><tab><tab>p.moveToParent()<tab><tab><tab># not found.<tab>return p",if p . hasNext ( ) :,150
48,"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None):<tab>for attr in attributes:<tab><tab>value = getattr(obj, attr, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>name = name_fmt % attr<tab><tab>if formatter is not None:<tab><tab><tab>value = formatter(attr, value)<tab><tab>info_add(name, value)",if value is None :,97
49,"def getElement(self, aboutUri, namespace, name):<tab>for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""):<tab><tab><IF-STMT><tab><tab><tab>attr = desc.getAttributeNodeNS(namespace, name)<tab><tab><tab>if attr != None:<tab><tab><tab><tab>yield attr<tab><tab><tab>for element in desc.getElementsByTagNameNS(namespace, name):<tab><tab><tab><tab>yield element","if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :",113
50,def run(self):<tab>while not self.completed:<tab><tab>if self.block:<tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab><IF-STMT><tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab>if dt > self.timeout:<tab><tab><tab><tab>self.stop()<tab><tab>if self.counter == self.count:<tab><tab><tab>self.stop(),if self . timeout is not None :,159
51,"def _parse_fixits(message, titer, line):<tab>""""""Parses fixit messages.""""""<tab>while (<tab><tab>OutputParser.message_line_re.match(line) is None<tab><tab>and OutputParser.note_line_re.match(line) is None<tab>):<tab><tab>message_text = line.strip()<tab><tab><IF-STMT><tab><tab><tab>message.fixits.append(<tab><tab><tab><tab>Note(<tab><tab><tab><tab><tab>message.path,<tab><tab><tab><tab><tab>message.line,<tab><tab><tab><tab><tab>line.find(message_text) + 1,<tab><tab><tab><tab><tab>message_text,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>line = next(titer)<tab>return line","if message_text != """" :",177
52,"def _connect_db(self, force_reconnect=False):<tab>thread_id = thread.get_ident()<tab>if force_reconnect and thread_id in ENGINES:<tab><tab>del ENGINES[thread_id]<tab>conn = None<tab>try:<tab><tab>engine = ENGINES[thread_id]<tab><tab>conn = engine.connect()<tab><tab>_test = conn.execute(""SELECT 1"")<tab><tab>_test.fetchall()<tab>except (KeyError, MySQLdb.OperationalError):<tab><tab><IF-STMT><tab><tab><tab>conn.close()<tab><tab>engine = sqla.create_engine(self.db_url, pool_recycle=3600)<tab><tab>ENGINES[thread_id] = engine<tab><tab>conn = engine.connect()<tab>return conn",if conn :,183
53,"def read(self, n):<tab>if self.current_frame:<tab><tab>data = self.current_frame.read(n)<tab><tab><IF-STMT><tab><tab><tab>self.current_frame = None<tab><tab><tab>return self.file_read(n)<tab><tab>if len(data) < n:<tab><tab><tab>raise UnpicklingError(""pickle exhausted before end of frame"")<tab><tab>return data<tab>else:<tab><tab>return self.file_read(n)",if not data and n != 0 :,115
54,"def __setLoadCmd(self):<tab>base = self.__rawLoadCmd<tab>for _ in range(self.__machHeader.ncmds):<tab><tab>command = LOAD_COMMAND.from_buffer_copy(base)<tab><tab><IF-STMT><tab><tab><tab>segment = SEGMENT_COMMAND.from_buffer_copy(base)<tab><tab><tab>self.__setSections(segment, base[56:], 32)<tab><tab>elif command.cmd == MACHOFlags.LC_SEGMENT_64:<tab><tab><tab>segment = SEGMENT_COMMAND64.from_buffer_copy(base)<tab><tab><tab>self.__setSections(segment, base[72:], 64)<tab><tab>base = base[command.cmdsize :]",if command . cmd == MACHOFlags . LC_SEGMENT :,174
55,"def emit_post_sync_signal(created_models, verbosity, interactive, db):<tab># Emit the post_sync signal for every application.<tab>for app in models.get_apps():<tab><tab>app_name = app.__name__.split(""."")[-2]<tab><tab><IF-STMT><tab><tab><tab>print(""Running post-sync handlers for application %s"" % app_name)<tab><tab>models.signals.post_syncdb.send(<tab><tab><tab>sender=app,<tab><tab><tab>app=app,<tab><tab><tab>created_models=created_models,<tab><tab><tab>verbosity=verbosity,<tab><tab><tab>interactive=interactive,<tab><tab><tab>db=db,<tab><tab>)",if verbosity >= 2 :,158
56,"def git_pull(args):<tab>if len(args) <= 1:<tab><tab>repo = _get_repo()<tab><tab>_confirm_dangerous()<tab><tab>url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """")<tab><tab>if url in repo.remotes:<tab><tab><tab>origin = url<tab><tab><tab>url = repo.remotes.get(origin)<tab><tab><IF-STMT><tab><tab><tab>repo.pull(origin_uri=url)<tab><tab>else:<tab><tab><tab>print(""No pull URL."")<tab>else:<tab><tab>print(command_help[""git pull""])",if url :,147
57,"def version(self):<tab>try:<tab><tab>return self._version<tab>except AttributeError:<tab><tab>for line in self._get_metadata(self.PKG_INFO):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._version = safe_version(line.split("":"", 1)[1].strip())<tab><tab><tab><tab>return self._version<tab><tab>else:<tab><tab><tab>tmpl = ""Missing 'Version:' header and/or %s file""<tab><tab><tab>raise ValueError(tmpl % self.PKG_INFO, self)","if line . lower ( ) . startswith ( ""version:"" ) :",127
58,"def increment(self, metric, labels, delta):<tab>""""""Increment a value by |delta|.""""""<tab>with self._lock:<tab><tab>key = self._get_key(metric.name, labels)<tab><tab><IF-STMT><tab><tab><tab>start_time = self._store[key].start_time<tab><tab><tab>value = self._store[key].value + delta<tab><tab>else:<tab><tab><tab>start_time = time.time()<tab><tab><tab>value = metric.default_value + delta<tab><tab>self._store[key] = _StoreValue(metric, labels, start_time, value)",if key in self . _store :,143
59,"def get_current_connections(session):<tab>""""""Retrieves open connections using the the given session""""""<tab># Use Show process list to count the open sesions.<tab>res = session.sql(""SHOW PROCESSLIST"").execute()<tab>rows = res.fetch_all()<tab>connections = {}<tab>for row in rows:<tab><tab><IF-STMT><tab><tab><tab>connections[row.get_string(""User"")] = [row.get_string(""Host"")]<tab><tab>else:<tab><tab><tab>connections[row.get_string(""User"")].append(row.get_string(""Host""))<tab>return connections","if row . get_string ( ""User"" ) not in connections :",148
60,"def asset(*paths):<tab>for path in paths:<tab><tab>fspath = www_root + ""/assets/"" + path<tab><tab>etag = """"<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>etag = asset_etag(fspath)<tab><tab><tab>else:<tab><tab><tab><tab>os.stat(fspath)<tab><tab>except FileNotFoundError as e:<tab><tab><tab>if path == paths[-1]:<tab><tab><tab><tab>if not os.path.exists(fspath + "".spt""):<tab><tab><tab><tab><tab>tell_sentry(e, {})<tab><tab><tab>else:<tab><tab><tab><tab>continue<tab><tab>except Exception as e:<tab><tab><tab>tell_sentry(e, {})<tab><tab>return asset_url + path + (etag and ""?etag="" + etag)",if env . cache_static :,182
61,def thread_loop(self) -> None:<tab>while not self.stop_event.is_set():<tab><tab>time.sleep(1)<tab><tab>new_trials = self.study.trials<tab><tab>with self.lock:<tab><tab><tab>need_to_add_callback = self.new_trials is None<tab><tab><tab>self.new_trials = new_trials<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.doc.add_next_tick_callback(self.update_callback),if need_to_add_callback :,122
62,"def _cache_db_tables_iterator(tables, cache_alias, db_alias):<tab>no_tables = not tables<tab>cache_aliases = settings.CACHES if cache_alias is None else (cache_alias,)<tab>db_aliases = settings.DATABASES if db_alias is None else (db_alias,)<tab>for db_alias in db_aliases:<tab><tab>if no_tables:<tab><tab><tab>tables = connections[db_alias].introspection.table_names()<tab><tab><IF-STMT><tab><tab><tab>for cache_alias in cache_aliases:<tab><tab><tab><tab>yield cache_alias, db_alias, tables",if tables :,145
63,"def remove_subscriber(self, topic, subscriber):<tab>if subscriber in self.subscribers[topic]:<tab><tab>if hasattr(subscriber, ""_pyroRelease""):<tab><tab><tab>subscriber._pyroRelease()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>proxy = self.proxy_cache[subscriber._pyroUri]<tab><tab><tab><tab>proxy._pyroRelease()<tab><tab><tab><tab>del self.proxy_cache[subscriber._pyroUri]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab>self.subscribers[topic].discard(subscriber)","if hasattr ( subscriber , ""_pyroUri"" ) :",139
64,"def test_constructor(job_id):<tab>with patch(""apscheduler.job.Job._modify"") as _modify:<tab><tab>scheduler_mock = MagicMock(BaseScheduler)<tab><tab>job = Job(scheduler_mock, id=job_id)<tab><tab>assert job._scheduler is scheduler_mock<tab><tab>assert job._jobstore_alias is None<tab><tab>modify_kwargs = _modify.call_args[1]<tab><tab><IF-STMT><tab><tab><tab>assert len(modify_kwargs[""id""]) == 32<tab><tab>else:<tab><tab><tab>assert modify_kwargs[""id""] == job_id",if job_id is None :,141
65,"def get_connection(self):<tab>if self.config.proxy_host != """":<tab><tab>return httplib.HTTPConnection(self.config.proxy_host, self.config.proxy_port)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return httplib.HTTPSConnection(self.config.simpledb_host)<tab><tab>else:<tab><tab><tab>return httplib.HTTPConnection(self.config.simpledb_host)",if self . config . use_https :,107
66,"def notify_login(self, ipaddress=""""):<tab>if app.NOTIFY_ON_LOGIN:<tab><tab>update_text = common.notifyStrings[common.NOTIFY_LOGIN_TEXT]<tab><tab>title = common.notifyStrings[common.NOTIFY_LOGIN]<tab><tab><IF-STMT><tab><tab><tab>self._notify_pht(title, update_text.format(ipaddress))",if update_text and title and ipaddress :,93
67,"def _getItemHeight(self, item, ctrl=None):<tab>""""""Returns the full height of the item to be inserted in the form""""""<tab>if type(ctrl) == psychopy.visual.TextBox2:<tab><tab>return ctrl.size[1]<tab>if type(ctrl) == psychopy.visual.Slider:<tab><tab># Set radio button layout<tab><tab>if item[""layout""] == ""horiz"":<tab><tab><tab>return 0.03 + ctrl.labelHeight * 3<tab><tab><IF-STMT><tab><tab><tab># for vertical take into account the nOptions<tab><tab><tab>return ctrl.labelHeight * len(item[""options""])","elif item [ ""layout"" ] == ""vert"" :",155
68,"def _get_errors_lines(self):<tab>""""""Return the number of lines that contains errors to highlight.""""""<tab>errors_lines = []<tab>block = self.document().begin()<tab>while block.isValid():<tab><tab>user_data = get_user_data(block)<tab><tab><IF-STMT><tab><tab><tab>errors_lines.append(block.blockNumber())<tab><tab>block = block.next()<tab>return errors_lines",if user_data . error :,105
69,"def set_pbar_fraction(self, frac, progress, stage=None):<tab>gtk.gdk.threads_enter()<tab>try:<tab><tab>self.is_pulsing = False<tab><tab>self.set_stage_text(stage or _(""Processing...""))<tab><tab>self.pbar.set_text(progress)<tab><tab>if frac > 1:<tab><tab><tab>frac = 1.0<tab><tab><IF-STMT><tab><tab><tab>frac = 0<tab><tab>self.pbar.set_fraction(frac)<tab>finally:<tab><tab>gtk.gdk.threads_leave()",if frac < 0 :,135
70,"def list_files(basedir):<tab>""""""List files in the directory rooted at |basedir|.""""""<tab>if not os.path.isdir(basedir):<tab><tab>raise NoSuchDirectory(basedir)<tab>directories = [""""]<tab>while directories:<tab><tab>d = directories.pop()<tab><tab>for basename in os.listdir(os.path.join(basedir, d)):<tab><tab><tab>filename = os.path.join(d, basename)<tab><tab><tab>if os.path.isdir(os.path.join(basedir, filename)):<tab><tab><tab><tab>directories.append(filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield filename","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",159
71,"def assistive(self):<tab>""""""Detects if item can be used as assistance""""""<tab># Make sure we cache results<tab>if self.__assistive is None:<tab><tab>assistive = False<tab><tab># Go through all effects and find first assistive<tab><tab>for effect in self.effects.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab># If we find one, stop and mark item as assistive<tab><tab><tab><tab>assistive = True<tab><tab><tab><tab>break<tab><tab>self.__assistive = assistive<tab>return self.__assistive",if effect . isAssistance is True :,141
72,"def closest_unseen(self, row1, col1, filter=None):<tab># find the closest unseen from this row/col<tab>min_dist = maxint<tab>closest_unseen = None<tab>for row in range(self.height):<tab><tab>for col in range(self.width):<tab><tab><tab>if filter is None or (row, col) not in filter:<tab><tab><tab><tab>if self.map[row][col] == UNSEEN:<tab><tab><tab><tab><tab>dist = self.distance(row1, col1, row, col)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab><tab><tab>closest_unseen = (row, col)<tab>return closest_unseen",if dist < min_dist :,174
73,"def _maybe_has_default_route(self):<tab>for route in self.iter_routes():<tab><tab><IF-STMT><tab><tab><tab>return True<tab>for iface in self.iter_interfaces():<tab><tab>for subnet in iface.get(""subnets"", []):<tab><tab><tab>for route in subnet.get(""routes"", []):<tab><tab><tab><tab>if self._is_default_route(route):<tab><tab><tab><tab><tab>return True<tab>return False",if self . _is_default_route ( route ) :,113
74,"def data(self, data):<tab>if data is None:<tab><tab>raise Exception(""Data cannot be None"")<tab>val = []<tab>for d in data:<tab><tab>if isinstance(d, str):<tab><tab><tab>val.append(bytes(d, ""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>val.append(d)<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Invalid type, data can only be an str or a bytes not {}: {}"".format(<tab><tab><tab><tab><tab>type(data), d<tab><tab><tab><tab>)<tab><tab><tab>)<tab>self.__data = val","elif isinstance ( d , bytes ) :",149
75,"def get_one_segment_function(data, context, echoerr):<tab>ext = data[""ext""]<tab>function_name = context[-2][1].get(""function"")<tab>if function_name:<tab><tab>module, function_name = get_function_strings(function_name, context, ext)<tab><tab>func = import_segment(function_name, data, context, echoerr, module=module)<tab><tab><IF-STMT><tab><tab><tab>yield func",if func :,107
76,"def generic_visit(self, node, parents=None):<tab>parents = (parents or []) + [node]<tab>for field, value in iter_fields(node):<tab><tab>if isinstance(value, list):<tab><tab><tab>for item in value:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.visit(item, parents)<tab><tab>elif isinstance(value, AST):<tab><tab><tab>self.visit(value, parents)","if isinstance ( item , AST ) :",106
77,"def find_scintilla_constants(f):<tab>lexers = []<tab>states = []<tab>for name in f.order:<tab><tab>v = f.features[name]<tab><tab><IF-STMT><tab><tab><tab>if v[""FeatureType""] == ""val"":<tab><tab><tab><tab>if name.startswith(""SCE_""):<tab><tab><tab><tab><tab>states.append((name, v[""Value""]))<tab><tab><tab><tab>elif name.startswith(""SCLEX_""):<tab><tab><tab><tab><tab>lexers.append((name, v[""Value""]))<tab>return (lexers, states)","if v [ ""Category"" ] != ""Deprecated"" :",137
78,"def things(self, query):<tab>limit = query.pop(""limit"", 100)<tab>offset = query.pop(""offset"", 0)<tab>keys = set(self.docs)<tab>for k, v in query.items():<tab><tab><IF-STMT><tab><tab><tab># query keys need to be flattened properly,<tab><tab><tab># this corrects any nested keys that have been included<tab><tab><tab># in values.<tab><tab><tab>flat = common.flatten_dict(v)[0]<tab><tab><tab>k += ""."" + web.rstrips(flat[0], "".key"")<tab><tab><tab>v = flat[1]<tab><tab>keys = set(k for k in self.filter_index(self.index, k, v) if k in keys)<tab>keys = sorted(keys)<tab>return keys[offset : offset + limit]","if isinstance ( v , dict ) :",194
79,"def del_(self, key):<tab>initial_hash = hash_ = self.hash(key)<tab>while True:<tab><tab>if self._keys[hash_] is self._empty:<tab><tab><tab># That key was never assigned<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab># key found, assign with deleted sentinel<tab><tab><tab>self._keys[hash_] = self._deleted<tab><tab><tab>self._values[hash_] = self._deleted<tab><tab><tab>self._len -= 1<tab><tab><tab>return<tab><tab>hash_ = self._rehash(hash_)<tab><tab>if initial_hash == hash_:<tab><tab><tab># table is full and wrapped around<tab><tab><tab>return None",elif self . _keys [ hash_ ] == key :,166
80,"def test_204_invalid_content_length(self):<tab># 204 status with non-zero content length is malformed<tab>with ExpectLog(gen_log, "".*Response with code 204 should not have body""):<tab><tab>response = self.fetch(""/?error=1"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""requires HTTP/1.x"")<tab><tab>if self.http_client.configured_class != SimpleAsyncHTTPClient:<tab><tab><tab>self.skipTest(""curl client accepts invalid headers"")<tab><tab>self.assertEqual(response.code, 599)",if not self . http1 :,136
81,"def __str__(self) -> str:<tab>text = ""\n""<tab>for k, r in self.result.items():<tab><tab>text += ""{}\n"".format(""#"" * 40)<tab><tab><IF-STMT><tab><tab><tab>text += ""# {} (failed)\n"".format(k)<tab><tab>else:<tab><tab><tab>text += ""# {} (succeeded)\n"".format(k)<tab><tab>text += ""{}\n"".format(""#"" * 40)<tab><tab>for sub_r in r:<tab><tab><tab>text += ""**** {}\n"".format(sub_r.name)<tab><tab><tab>text += ""{}\n"".format(sub_r)<tab>return text",if r . failed :,153
82,"def DeleteTask():<tab>oid = request.form.get(""oid"", """")<tab>if oid:<tab><tab>result = Mongo.coll[""Task""].delete_one({""_id"": ObjectId(oid)})<tab><tab><IF-STMT><tab><tab><tab>result = Mongo.coll[""Result""].delete_many({""task_id"": ObjectId(oid)})<tab><tab><tab>if result:<tab><tab><tab><tab>return ""success""<tab>return ""fail""",if result . deleted_count > 0 :,108
83,"def _replace_vars(self, line, extracted, env_variables):<tab>for e in extracted:<tab><tab><IF-STMT><tab><tab><tab>value = env_variables.get(e)<tab><tab><tab>if isinstance(value, dict) or isinstance(value, list):<tab><tab><tab><tab>value = pprint.pformat(value)<tab><tab><tab>decorated = self._decorate_var(e)<tab><tab><tab>line = line.replace(decorated, str(value))<tab>return line",if e in env_variables :,113
84,"def should_include(service):<tab>for f in filt:<tab><tab>if f == ""status"":<tab><tab><tab>state = filt[f]<tab><tab><tab>containers = project.containers([service.name], stopped=True)<tab><tab><tab>if not has_container_with_state(containers, state):<tab><tab><tab><tab>return False<tab><tab>elif f == ""source"":<tab><tab><tab>source = filt[f]<tab><tab><tab>if source == ""image"" or source == ""build"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>raise UserError(""Invalid value for source filter: %s"" % source)<tab><tab>else:<tab><tab><tab>raise UserError(""Invalid filter: %s"" % f)<tab>return True",if source not in service . options :,184
85,def state_callback_loop():<tab>if usercallback:<tab><tab>when = 1<tab><tab>while (<tab><tab><tab>when<tab><tab><tab>and not self.future_removed.done()<tab><tab><tab>and not self.session.shutdownstarttime<tab><tab>):<tab><tab><tab>result = usercallback(self.get_state())<tab><tab><tab>when = (await result) if iscoroutine(result) else result<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await sleep(when),if when > 0.0 and not self . session . shutdownstarttime :,122
86,"def __get_new_timeout(self, timeout):<tab>""""""When using --timeout_multiplier=#.#""""""<tab>self.__check_scope()<tab>try:<tab><tab>timeout_multiplier = float(self.timeout_multiplier)<tab><tab><IF-STMT><tab><tab><tab>timeout_multiplier = 0.5<tab><tab>timeout = int(math.ceil(timeout_multiplier * timeout))<tab><tab>return timeout<tab>except Exception:<tab><tab># Wrong data type for timeout_multiplier (expecting int or float)<tab><tab>return timeout",if timeout_multiplier <= 0.5 :,126
87,"def readexactly(self, n):<tab>buf = b""""<tab>while n:<tab><tab>yield IORead(self.s)<tab><tab>res = self.s.read(n)<tab><tab>assert res is not None<tab><tab><IF-STMT><tab><tab><tab>yield IOReadDone(self.s)<tab><tab><tab>break<tab><tab>buf += res<tab><tab>n -= len(res)<tab>return buf",if not res :,99
88,"def contract_rendering_pane(event):<tab>""""""Expand the rendering pane.""""""<tab>c = event.get(""c"")<tab>if c:<tab><tab>vr = c.frame.top.findChild(QtWidgets.QWidget, ""viewrendered_pane"")<tab><tab><IF-STMT><tab><tab><tab>vr.contract()<tab><tab>else:<tab><tab><tab># Just open the pane.<tab><tab><tab>viewrendered(event)",if vr :,103
89,"def translate_headers(self, environ):<tab>""""""Translate CGI-environ header names to HTTP header names.""""""<tab>for cgiName in environ:<tab><tab># We assume all incoming header keys are uppercase already.<tab><tab><IF-STMT><tab><tab><tab>yield self.headerNames[cgiName], environ[cgiName]<tab><tab>elif cgiName[:5] == ""HTTP_"":<tab><tab><tab># Hackish attempt at recovering original header names.<tab><tab><tab>translatedHeader = cgiName[5:].replace(""_"", ""-"")<tab><tab><tab>yield translatedHeader, environ[cgiName]",if cgiName in self . headerNames :,134
90,"def get_value_from_string(self, string_value):<tab>""""""Return internal representation starting from CFN/user-input value.""""""<tab>param_value = self.get_default_value()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>string_value = str(string_value).strip()<tab><tab><tab>if string_value != ""NONE"":<tab><tab><tab><tab>param_value = int(string_value)<tab>except ValueError:<tab><tab>self.pcluster_config.warn(<tab><tab><tab>""Unable to convert the value '{0}' to an Integer. ""<tab><tab><tab>""Using default value for parameter '{1}'"".format(string_value, self.key)<tab><tab>)<tab>return param_value",if string_value is not None :,172
91,"def monitor_filter(self):<tab>""""""Return filtered service objects list""""""<tab>services = self.client.services.list(filters={""label"": ""com.ouroboros.enable""})<tab>monitored_services = []<tab>for service in services:<tab><tab>ouro_label = service.attrs[""Spec""][""Labels""].get(""com.ouroboros.enable"")<tab><tab><IF-STMT><tab><tab><tab>monitored_services.append(service)<tab>self.data_manager.monitored_containers[self.socket] = len(monitored_services)<tab>self.data_manager.set(self.socket)<tab>return monitored_services","if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",176
92,"def nextEditable(self):<tab>""""""Moves focus of the cursor to the next editable window""""""<tab>if self.currentEditable is None:<tab><tab>if len(self._editableChildren):<tab><tab><tab>self._currentEditableRef = self._editableChildren[0]<tab>else:<tab><tab>for ref in weakref.getweakrefs(self.currentEditable):<tab><tab><tab>if ref in self._editableChildren:<tab><tab><tab><tab>cei = self._editableChildren.index(ref)<tab><tab><tab><tab>nei = cei + 1<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>nei = 0<tab><tab><tab><tab>self._currentEditableRef = self._editableChildren[nei]<tab>return self.currentEditable",if nei >= len ( self . _editableChildren ) :,179
93,"def linkify_cm_by_tp(self, timeperiods):<tab>for rm in self:<tab><tab>mtp_name = rm.modulation_period.strip()<tab><tab># The new member list, in id<tab><tab>mtp = timeperiods.find_by_name(mtp_name)<tab><tab><IF-STMT><tab><tab><tab>err = (<tab><tab><tab><tab>""Error: the business impact modulation '%s' got an unknown ""<tab><tab><tab><tab>""modulation_period '%s'"" % (rm.get_name(), mtp_name)<tab><tab><tab>)<tab><tab><tab>rm.configuration_errors.append(err)<tab><tab>rm.modulation_period = mtp","if mtp_name != """" and mtp is None :",169
94,def close_open_fds(keep=None):  # noqa<tab>keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None]<tab>for fd in reversed(range(get_fdmax(default=2048))):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.close(fd)<tab><tab><tab>except OSError as exc:<tab><tab><tab><tab>if exc.errno != errno.EBADF:<tab><tab><tab><tab><tab>raise,if fd not in keep :,120
95,"def _append_child_from_unparsed_xml(father_node, unparsed_xml):<tab>""""""Append child xml nodes to a node.""""""<tab>dom_tree = parseString(unparsed_xml)<tab>if dom_tree.hasChildNodes():<tab><tab>first_child = dom_tree.childNodes[0]<tab><tab><IF-STMT><tab><tab><tab>child_nodes = first_child.childNodes<tab><tab><tab>for _ in range(len(child_nodes)):<tab><tab><tab><tab>childNode = child_nodes.item(0)<tab><tab><tab><tab>father_node.appendChild(childNode)<tab><tab><tab>return<tab>raise DistutilsInternalError(<tab><tab>""Could not Append append elements to "" ""the Windows msi descriptor.""<tab>)",if first_child . hasChildNodes ( ) :,178
96,"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab><IF-STMT><tab><tab><tab>body = six.ensure_str(request.body)<tab><tab><tab>if old in body:<tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",if is_text_payload ( request ) and request . body :,103
97,"def __init__(self, **options):<tab>self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True)<tab>self.disabled_modules = get_list_opt(options, ""disabled_modules"", [])<tab>self._functions = set()<tab>if self.func_name_highlighting:<tab><tab>from pygments.lexers._luabuiltins import MODULES<tab><tab>for mod, func in MODULES.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._functions.update(func)<tab>RegexLexer.__init__(self, **options)",if mod not in self . disabled_modules :,153
98,"def GetBestSizeForParentSize(self, parentSize):<tab>""""""Finds the best width and height given the parent's width and height.""""""<tab>if len(self.GetChildren()) == 1:<tab><tab>win = self.GetChildren()[0]<tab><tab><IF-STMT><tab><tab><tab>temp_dc = wx.ClientDC(self)<tab><tab><tab>childSize = win.GetBestSizeForParentSize(parentSize)<tab><tab><tab>clientParentSize = self._art.GetPanelClientSize(<tab><tab><tab><tab>temp_dc, self, wx.Size(*parentSize), None<tab><tab><tab>)<tab><tab><tab>overallSize = self._art.GetPanelSize(<tab><tab><tab><tab>temp_dc, self, wx.Size(*clientParentSize), None<tab><tab><tab>)<tab><tab><tab>return overallSize<tab>return self.GetSize()","if isinstance ( win , RibbonControl ) :",199
99,"def pid_from_name(name):<tab>processes = []<tab>for pid in os.listdir(""/proc""):<tab><tab>try:<tab><tab><tab>pid = int(pid)<tab><tab><tab>pname, cmdline = SunProcess._name_args(pid)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pid<tab><tab><tab>if name in cmdline.split("" "", 1)[0]:<tab><tab><tab><tab>return pid<tab><tab>except:<tab><tab><tab>pass<tab>raise ProcessException(""No process with such name: %s"" % name)",if name in pname :,126
100,"def __get_file_by_num(self, num, file_list, idx=0):<tab>for element in file_list:<tab><tab>if idx == num:<tab><tab><tab>return element<tab><tab><IF-STMT><tab><tab><tab>i = self.__get_file_by_num(num, element[3], idx + 1)<tab><tab><tab>if not isinstance(i, int):<tab><tab><tab><tab>return i<tab><tab><tab>idx = i<tab><tab>else:<tab><tab><tab>idx += 1<tab>return idx",if element [ 3 ] and element [ 4 ] :,127
101,"def scan_block_scalar_indentation(self):<tab># See the specification for details.<tab>chunks = []<tab>max_indent = 0<tab>end_mark = self.get_mark()<tab>while self.peek() in "" \r\n\x85\u2028\u2029"":<tab><tab>if self.peek() != "" "":<tab><tab><tab>chunks.append(self.scan_line_break())<tab><tab><tab>end_mark = self.get_mark()<tab><tab>else:<tab><tab><tab>self.forward()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>max_indent = self.column<tab>return chunks, max_indent, end_mark",if self . column > max_indent :,161
102,"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab>if col == LAND:<tab><tab><tab><tab>tmp += "".""<tab><tab><tab>elif col == BARRIER:<tab><tab><tab><tab>tmp += ""%""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""*""<tab><tab><tab>elif col == UNSEEN:<tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",elif col == FOOD :,199
103,"def prepare_data(entry):<tab>branch_wise_entries = {}<tab>gross_pay = 0<tab>for d in entry:<tab><tab>gross_pay += d.gross_pay<tab><tab><IF-STMT><tab><tab><tab>branch_wise_entries[d.branch][d.mode_of_payment] = d.net_pay<tab><tab>else:<tab><tab><tab>branch_wise_entries.setdefault(d.branch, {}).setdefault(<tab><tab><tab><tab>d.mode_of_payment, d.net_pay<tab><tab><tab>)<tab>return branch_wise_entries, gross_pay",if branch_wise_entries . get ( d . branch ) :,146
104,"def __init__(self, uuid=None, cluster_state=None, children=None, **kwargs):<tab>self.uuid = uuid<tab>self.cluster_state = cluster_state<tab>if self.cluster_state is not None:<tab><tab>self.children = WeakSet(<tab><tab><tab>self.cluster_state.tasks.get(task_id)<tab><tab><tab>for task_id in children or ()<tab><tab><tab><IF-STMT><tab><tab>)<tab>else:<tab><tab>self.children = WeakSet()<tab>self._serializer_handlers = {<tab><tab>""children"": self._serializable_children,<tab><tab>""root"": self._serializable_root,<tab><tab>""parent"": self._serializable_parent,<tab>}<tab>if kwargs:<tab><tab>self.__dict__.update(kwargs)",if task_id in self . cluster_state . tasks,192
105,"def listdir(self, d):<tab>try:<tab><tab>return [<tab><tab><tab>p<tab><tab><tab>for p in os.listdir(d)<tab><tab><tab><IF-STMT><tab><tab>]<tab>except OSError:<tab><tab>return []","if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )",84
106,"def send_packed_command(self, command, check_health=True):<tab>if not self._sock:<tab><tab>self.connect()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>command = [command]<tab><tab>for item in command:<tab><tab><tab>self._sock.sendall(item)<tab>except socket.error as e:<tab><tab>self.disconnect()<tab><tab>if len(e.args) == 1:<tab><tab><tab>_errno, errmsg = ""UNKNOWN"", e.args[0]<tab><tab>else:<tab><tab><tab>_errno, errmsg = e.args<tab><tab>raise ConnectionError(<tab><tab><tab>""Error %s while writing to socket. %s."" % (_errno, errmsg)<tab><tab>)<tab>except Exception:<tab><tab>self.disconnect()<tab><tab>raise","if isinstance ( command , str ) :",188
107,"def run(self):<tab>""""""Start the scanner""""""<tab>logging.info(""Dirscanner starting up"")<tab>self.shutdown = False<tab>while not self.shutdown:<tab><tab># Wait to be woken up or triggered<tab><tab>with self.loop_condition:<tab><tab><tab>self.loop_condition.wait(self.dirscan_speed)<tab><tab><IF-STMT><tab><tab><tab>self.scan()",if self . dirscan_speed and not self . shutdown :,104
108,"def __aexit__(<tab>self, exc_type: type, exc_value: BaseException, tb: TracebackType) -> None:<tab>if exc_type is not None:<tab><tab>await self.close()<tab>await self._task<tab>while not self._receive_queue.empty():<tab><tab>data = await self._receive_queue.get()<tab><tab>if isinstance(data, bytes):<tab><tab><tab>self.response_data.extend(data)<tab><tab><IF-STMT><tab><tab><tab>raise data","elif not isinstance ( data , HTTPDisconnect ) :",121
109,"def f(msg):<tab>text = extractor(msg)<tab>for px in prefix:<tab><tab><IF-STMT><tab><tab><tab>chunks = text[len(px) :].split(separator)<tab><tab><tab>return chunks[0], (chunks[1:],) if pass_args else ()<tab>return ((None,),)  # to distinguish with `None`",if text . startswith ( px ) :,83
110,"def _flatten(*args):<tab>ahs = set()<tab>if len(args) > 0:<tab><tab>for item in args:<tab><tab><tab>if type(item) is ActionHandle:<tab><tab><tab><tab>ahs.add(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for ah in item:<tab><tab><tab><tab><tab>if type(ah) is not ActionHandle:  # pragma:nocover<tab><tab><tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(ah))<tab><tab><tab><tab><tab>ahs.add(ah)<tab><tab><tab>else:  # pragma:nocover<tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(item))<tab>return ahs","elif type ( item ) in ( list , tuple , dict , set ) :",183
111,"def find_class(self, module, name):<tab># Subclasses may override this.<tab>sys.audit(""pickle.find_class"", module, name)<tab>if self.proto < 3 and self.fix_imports:<tab><tab>if (module, name) in _compat_pickle.NAME_MAPPING:<tab><tab><tab>module, name = _compat_pickle.NAME_MAPPING[(module, name)]<tab><tab><IF-STMT><tab><tab><tab>module = _compat_pickle.IMPORT_MAPPING[module]<tab>__import__(module, level=0)<tab>if self.proto >= 4:<tab><tab>return _getattribute(sys.modules[module], name)[0]<tab>else:<tab><tab>return getattr(sys.modules[module], name)",elif module in _compat_pickle . IMPORT_MAPPING :,178
112,"def _send_until_done(self, data):<tab>while True:<tab><tab>try:<tab><tab><tab>return self.connection.send(data)<tab><tab>except OpenSSL.SSL.WantWriteError:<tab><tab><tab>wr = util.wait_for_write(self.socket, self.socket.gettimeout())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise timeout()<tab><tab><tab>continue<tab><tab>except OpenSSL.SSL.SysCallError as e:<tab><tab><tab>raise SocketError(str(e))",if not wr :,120
113,"def __new__(cls, *args, **kwargs):<tab>""""""Hack to ensure method defined as async are implemented as such.""""""<tab>coroutines = inspect.getmembers(BaseManager, predicate=inspect.iscoroutinefunction)<tab>for coroutine in coroutines:<tab><tab>implemented_method = getattr(cls, coroutine[0])<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""The method %s must be a coroutine"" % implemented_method)<tab>return super().__new__(cls, *args, **kwargs)",if not inspect . iscoroutinefunction ( implemented_method ) :,120
114,"def add_directive(self, name, obj, content=None, arguments=None, **options):<tab>if isinstance(obj, clstypes) and issubclass(obj, Directive):<tab><tab><IF-STMT><tab><tab><tab>raise ExtensionError(<tab><tab><tab><tab>""when adding directive classes, no "" ""additional arguments may be given""<tab><tab><tab>)<tab><tab>directives.register_directive(name, directive_dwim(obj))<tab>else:<tab><tab>obj.content = content<tab><tab>obj.arguments = arguments<tab><tab>obj.options = options<tab><tab>directives.register_directive(name, obj)",if content or arguments or options :,144
115,"def create(self, w):<tab>if w.use_eventloop:<tab><tab># does not use dedicated timer thread.<tab><tab>w.timer = _Timer(max_interval=10.0)<tab>else:<tab><tab><IF-STMT><tab><tab><tab># Default Timer is set by the pool, as for example, the<tab><tab><tab># eventlet pool needs a custom timer implementation.<tab><tab><tab>w.timer_cls = w.pool_cls.Timer<tab><tab>w.timer = self.instantiate(<tab><tab><tab>w.timer_cls,<tab><tab><tab>max_interval=w.timer_precision,<tab><tab><tab>on_error=self.on_timer_error,<tab><tab><tab>on_tick=self.on_timer_tick,<tab><tab>)",if not w . timer_cls :,182
116,"def _config(_molecule_file, request):<tab>with open(_molecule_file) as f:<tab><tab>d = util.safe_load(f)<tab>if hasattr(request, ""param""):<tab><tab><IF-STMT><tab><tab><tab>d2 = util.safe_load(request.getfixturevalue(request.param))<tab><tab>else:<tab><tab><tab>d2 = request.getfixturevalue(request.param)<tab><tab># print(100, d)<tab><tab># print(200, d2)<tab><tab>d = util.merge_dicts(d, d2)<tab><tab># print(300, d)<tab>return d","if isinstance ( request . getfixturevalue ( request . param ) , str ) :",164
117,"def _instrument_model(self, model):<tab>for key, value in list(<tab><tab>model.__dict__.items()<tab>):  # avoid ""dictionary keys changed during iteration""<tab><tab><IF-STMT><tab><tab><tab>new_layer = self._instrument(value)<tab><tab><tab>if new_layer is not value:<tab><tab><tab><tab>setattr(model, key, new_layer)<tab><tab>elif isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, tf.keras.layers.Layer):<tab><tab><tab><tab><tab>value[i] = self._instrument(item)<tab>return model","if isinstance ( value , tf . keras . layers . Layer ) :",164
118,"def is_accepted_drag_event(self, event):<tab>if event.source() == self.table:<tab><tab>return True<tab>mime = event.mimeData()<tab>if mime.hasUrls():<tab><tab>for url in mime.urls():<tab><tab><tab># Only support local files.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab># And only allow supported extensions.<tab><tab><tab>filename = url.toLocalFile()<tab><tab><tab>extension = os.path.splitext(filename)[1].lower()[1:]<tab><tab><tab>if extension not in _dictionary_formats():<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return True<tab>return False",if not url . isLocalFile ( ) :,163
119,"def explain(self, other, depth=0):<tab>exp = super(UnionType, self).explain(other, depth)<tab>for ndx, subtype in enumerate(self.params[""allowed_types""]):<tab><tab><IF-STMT><tab><tab><tab>exp += ""\n{}and"".format("""".join([""\t""] * depth))<tab><tab>exp += ""\n"" + subtype.explain(other, depth=depth + 1)<tab>return exp",if ndx > 0 :,101
120,"def test_k_is_stochastic_parameter(self):<tab># k as stochastic parameter<tab>aug = iaa.MedianBlur(k=iap.Choice([3, 5]))<tab>seen = [False, False]<tab>for i in sm.xrange(100):<tab><tab>observed = aug.augment_image(self.base_img)<tab><tab>if np.array_equal(observed, self.blur3x3):<tab><tab><tab>seen[0] += True<tab><tab><IF-STMT><tab><tab><tab>seen[1] += True<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected result in MedianBlur@2"")<tab><tab>if all(seen):<tab><tab><tab>break<tab>assert np.all(seen)","elif np . array_equal ( observed , self . blur5x5 ) :",176
121,"def test_get_message(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>async with self.chat_thread_client:<tab><tab><tab>message_id = await self._send_message()<tab><tab><tab>message = await self.chat_thread_client.get_message(message_id)<tab><tab><tab>assert message.id == message_id<tab><tab><tab>assert message.type == ChatMessageType.TEXT<tab><tab><tab>assert message.content.message == ""hello world""<tab><tab># delete chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)",if not self . is_playback ( ) :,163
122,"def do_write_property(self, device, callback=None):<tab>try:<tab><tab>iocb = (<tab><tab><tab>device<tab><tab><tab><IF-STMT><tab><tab><tab>else self.form_iocb(device, request_type=""writeProperty"")<tab><tab>)<tab><tab>deferred(self.request_io, iocb)<tab><tab>self.requests_in_progress.update({iocb: {""callback"": callback}})<tab><tab>iocb.add_callback(self.__general_cb)<tab>except Exception as error:<tab><tab>log.exception(""exception: %r"", error)","if isinstance ( device , IOCB )",146
123,"def fit(self, dataset, force_retrain):<tab>if force_retrain:<tab><tab>self.sub_unit_1[""fitted""] = True<tab><tab>self.sub_unit_1[""calls""] += 1<tab><tab>self.sub_unit_2[""fitted""] = True<tab><tab>self.sub_unit_2[""calls""] += 1<tab>else:<tab><tab>if not self.sub_unit_1[""fitted""]:<tab><tab><tab>self.sub_unit_1[""fitted""] = True<tab><tab><tab>self.sub_unit_1[""calls""] += 1<tab><tab><IF-STMT><tab><tab><tab>self.sub_unit_2[""fitted""] = True<tab><tab><tab>self.sub_unit_2[""calls""] += 1<tab>return self","if not self . sub_unit_2 [ ""fitted"" ] :",183
124,"def _insert_with_loop(self):<tab>id_list = []<tab>last_id = None<tab>return_id_list = self._return_id_list<tab>for row in self._rows:<tab><tab>last_id = InsertQuery(self.model_class, row).upsert(self._upsert).execute()<tab><tab><IF-STMT><tab><tab><tab>id_list.append(last_id)<tab>if return_id_list:<tab><tab>return id_list<tab>else:<tab><tab>return last_id",if return_id_list :,126
125,"def merge_block(self):<tab>""""""merges a block in the map""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>c = self.block.get(i, j)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.map[(i + self.block.pos.x, j + self.block.pos.y)] = c",if c :,99
126,"def configure_plex(config):<tab>core.PLEX_SSL = int(config[""Plex""][""plex_ssl""])<tab>core.PLEX_HOST = config[""Plex""][""plex_host""]<tab>core.PLEX_PORT = config[""Plex""][""plex_port""]<tab>core.PLEX_TOKEN = config[""Plex""][""plex_token""]<tab>plex_section = config[""Plex""][""plex_sections""] or []<tab>if plex_section:<tab><tab><IF-STMT><tab><tab><tab>plex_section = "","".join(plex_section)  # fix in case this imported as list.<tab><tab>plex_section = [tuple(item.split("","")) for item in plex_section.split(""|"")]<tab>core.PLEX_SECTION = plex_section","if isinstance ( plex_section , list ) :",182
127,"def select(self):<tab>e = xlib.XEvent()<tab>while xlib.XPending(self._display):<tab><tab>xlib.XNextEvent(self._display, e)<tab><tab># Key events are filtered by the xlib window event<tab><tab># handler so they get a shot at the prefiltered event.<tab><tab><IF-STMT><tab><tab><tab>if xlib.XFilterEvent(e, e.xany.window):<tab><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>dispatch = self._window_map[e.xany.window]<tab><tab>except KeyError:<tab><tab><tab>continue<tab><tab>dispatch(e)","if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) :",171
128,"def format_message(self):<tab>bits = [self.message]<tab>if self.possibilities:<tab><tab><IF-STMT><tab><tab><tab>bits.append(""Did you mean %s?"" % self.possibilities[0])<tab><tab>else:<tab><tab><tab>possibilities = sorted(self.possibilities)<tab><tab><tab>bits.append(""(Possible options: %s)"" % "", "".join(possibilities))<tab>return ""  "".join(bits)",if len ( self . possibilities ) == 1 :,106
129,"def _collect_logs(model):<tab>page_token = None<tab>all_logs = []<tab>while True:<tab><tab>paginated_logs = model.lookup_logs(now, later, page_token=page_token)<tab><tab>page_token = paginated_logs.next_page_token<tab><tab>all_logs.extend(paginated_logs.logs)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return all_logs",if page_token is None :,105
130,"def run(self):<tab>while True:<tab><tab>context_id_list_tuple = self._inflated_addresses.get(block=True)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>c_id, inflated_address_list = context_id_list_tuple<tab><tab>inflated_value_map = dict(inflated_address_list)<tab><tab>if c_id in self._contexts:<tab><tab><tab>self._contexts[c_id].set_from_tree(inflated_value_map)",if context_id_list_tuple is _SHUTDOWN_SENTINEL :,135
131,"def _setup_prefix(self):<tab># we assume here that our metadata may be nested inside a ""basket""<tab># of multiple eggs; that's why we use module_path instead of .archive<tab>path = self.module_path<tab>old = None<tab>while path != old:<tab><tab><IF-STMT><tab><tab><tab>self.egg_name = os.path.basename(path)<tab><tab><tab>self.egg_info = os.path.join(path, ""EGG-INFO"")<tab><tab><tab>self.egg_root = path<tab><tab><tab>break<tab><tab>old = path<tab><tab>path, base = os.path.split(path)","if path . lower ( ) . endswith ( "".egg"" ) :",160
132,"def get_filename(self, prompt):<tab>okay = False<tab>val = """"<tab>while not okay:<tab><tab>val = raw_input(""%s: %s"" % (prompt, val))<tab><tab>val = os.path.expanduser(val)<tab><tab>if os.path.isfile(val):<tab><tab><tab>okay = True<tab><tab><IF-STMT><tab><tab><tab>path = val<tab><tab><tab>val = self.choose_from_list(os.listdir(path))<tab><tab><tab>if val:<tab><tab><tab><tab>val = os.path.join(path, val)<tab><tab><tab><tab>okay = True<tab><tab><tab>else:<tab><tab><tab><tab>val = """"<tab><tab>else:<tab><tab><tab>print(""Invalid value: %s"" % val)<tab><tab><tab>val = """"<tab>return val",elif os . path . isdir ( val ) :,194
133,"def versions(self, sitename, data):<tab># handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}}<tab>if ""query"" in data:<tab><tab>q = json.loads(data[""query""])<tab><tab>itemid = self._get_itemid(q.get(""key""))<tab><tab><IF-STMT><tab><tab><tab>key = q[""key""]<tab><tab><tab>return json.dumps([self.dummy_edit(key)])<tab># if not just go the default way<tab>return ConnectionMiddleware.versions(self, sitename, data)",if itemid :,133
134,"def read_stanza(self):<tab>while True:<tab><tab>try:<tab><tab><tab>stanza_end = self._buffer.index(b""\n"")<tab><tab><tab>stanza = self.decoder.decode(self._buffer[:stanza_end])<tab><tab><tab>self._buffer = self._buffer[stanza_end + 1 :]<tab><tab><tab>colon = stanza.index("":"")<tab><tab><tab>return stanza[:colon], stanza[colon + 1 :]<tab><tab>except ValueError:<tab><tab><tab>bytes = self.read_bytes()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>self._buffer += bytes",if not bytes :,164
135,def decodeattrs(attrs):<tab>names = []<tab>for bit in range(16):<tab><tab>mask = 1 << bit<tab><tab><IF-STMT><tab><tab><tab>if attrnames.has_key(mask):<tab><tab><tab><tab>names.append(attrnames[mask])<tab><tab><tab>else:<tab><tab><tab><tab>names.append(hex(mask))<tab>return names,if attrs & mask :,88
136,"def _set_http_cookie():<tab>if conf.cookie:<tab><tab><IF-STMT><tab><tab><tab>conf.http_headers[HTTP_HEADER.COOKIE] = ""; "".join(<tab><tab><tab><tab>map(lambda x: ""="".join(x), conf.cookie.items())<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>conf.http_headers[HTTP_HEADER.COOKIE] = conf.cookie","if isinstance ( conf . cookie , dict ) :",101
137,"def __ne__(self, other):<tab>if isinstance(other, WeakMethod):<tab><tab><IF-STMT><tab><tab><tab>return self is not other<tab><tab>return weakref.ref.__ne__(self, other) or self._func_ref != other._func_ref<tab>return True",if not self . _alive or not other . _alive :,72
138,"def update_unread(self, order_id, reset=False):<tab>conn = Database.connect_database(self.PATH)<tab>with conn:<tab><tab>cursor = conn.cursor()<tab><tab><IF-STMT><tab><tab><tab>cursor.execute(<tab><tab><tab><tab>""""""UPDATE sales SET unread = unread + 1 WHERE id=?;"""""", (order_id,)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>cursor.execute(""""""UPDATE sales SET unread=0 WHERE id=?;"""""", (order_id,))<tab><tab>conn.commit()<tab>conn.close()",if reset is False :,131
139,"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab>if member[0] == key:<tab><tab><tab><tab>field_value = member[1]<tab><tab><tab>elif member[0] == ""wildcards"":<tab><tab><tab><tab>wildcards = member[1]<tab><tab>if key == ""nw_src"":<tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab><IF-STMT><tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value","elif key == ""nw_dst"" :",200
140,"def nested_filter(self, items, mask):<tab>keep_current = self.current_mask(mask)<tab>keep_nested_lookup = self.nested_masks(mask)<tab>for k, v in items:<tab><tab>keep_nested = keep_nested_lookup.get(k)<tab><tab><IF-STMT><tab><tab><tab>if keep_nested is not None:<tab><tab><tab><tab>if isinstance(v, dict):<tab><tab><tab><tab><tab>yield k, dict(self.nested_filter(v.items(), keep_nested))<tab><tab><tab>else:<tab><tab><tab><tab>yield k, v",if k in keep_current :,142
141,"def goToPrevMarkedHeadline(self, event=None):<tab>""""""Select the next marked node.""""""<tab>c = self<tab>p = c.p<tab>if not p:<tab><tab>return<tab>p.moveToThreadBack()<tab>wrapped = False<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif p:<tab><tab><tab>p.moveToThreadBack()<tab><tab>elif wrapped:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>wrapped = True<tab><tab><tab>p = c.rootPosition()<tab>if not p:<tab><tab>g.blue(""done"")<tab>c.treeSelectHelper(p)  # Sets focus.",if p and p . isMarked ( ) :,164
142,"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = {}<tab>ret.update(self.data)<tab>kwspaces = self.kwspaces<tab>kwspaces.update(config)<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for k, v in kwspaces.items():<tab><tab><IF-STMT><tab><tab><tab>if isinstance(v, NestedSpace):<tab><tab><tab><tab>sub_config = _strip_config_space(config, prefix=k)<tab><tab><tab><tab>ret[k] = v.sample(**sub_config)<tab><tab><tab>else:<tab><tab><tab><tab>ret[k] = v<tab>return ret",if k in striped_keys :,172
143,"def update_gradients_full(self, dL_dK, X, X2=None):<tab>if self.ARD:<tab><tab>phi1 = self.phi(X)<tab><tab><IF-STMT><tab><tab><tab>self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi1)<tab><tab>else:<tab><tab><tab>phi2 = self.phi(X2)<tab><tab><tab>self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi2)<tab>else:<tab><tab>self.variance.gradient = np.einsum(""ij,ij"", dL_dK, self._K(X, X2)) * self.beta",if X2 is None or X is X2 :,185
144,"def post(self):<tab>host_json = json.loads(request.data)<tab>host_os = host_json.get(""os"")<tab>if host_os:<tab><tab>result = get_monkey_executable(host_os.get(""type""), host_os.get(""machine""))<tab><tab>if result:<tab><tab><tab># change resulting from new base path<tab><tab><tab>executable_filename = result[""filename""]<tab><tab><tab>real_path = MonkeyDownload.get_executable_full_path(executable_filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[""size""] = os.path.getsize(real_path)<tab><tab><tab><tab>return result<tab>return {}",if os . path . isfile ( real_path ) :,167
145,"def _encode_data(<tab>self,<tab>data,<tab>content_type,):<tab>if content_type is MULTIPART_CONTENT:<tab><tab>return encode_multipart(BOUNDARY, data)<tab>else:<tab><tab># Encode the content so that the byte representation is correct.<tab><tab>match = CONTENT_TYPE_RE.match(content_type)<tab><tab><IF-STMT><tab><tab><tab>charset = match.group(1)<tab><tab>else:<tab><tab><tab>charset = settings.DEFAULT_CHARSET<tab><tab>return force_bytes(data, encoding=charset)",if match :,130
146,"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]:<tab>tokens = list(tokens)<tab>i = 0<tab>while ""e"" in tokens[i + 1 :]:<tab><tab>i = tokens.index(""e"", i + 1)<tab><tab>s = i - 1<tab><tab>e = i + 1<tab><tab>if not re.match(""[0-9]"", str(tokens[s])):<tab><tab><tab>continue<tab><tab>if re.match(""[+-]"", str(tokens[e])):<tab><tab><tab>e += 1<tab><tab><IF-STMT><tab><tab><tab>e += 1<tab><tab><tab>tokens[s:e] = ["""".join(tokens[s:e])]<tab><tab><tab>i -= 1<tab>return tokens","if re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :",184
147,"def convert_with_key(self, key, value, replace=True):<tab>result = self.configurator.convert(value)<tab># If the converted value is different, save for next time<tab>if value is not result:<tab><tab><IF-STMT><tab><tab><tab>self[key] = result<tab><tab>if type(result) in (ConvertingDict, ConvertingList, ConvertingTuple):<tab><tab><tab>result.parent = self<tab><tab><tab>result.key = key<tab>return result",if replace :,111
148,"def OnListEndLabelEdit(self, std, extra):<tab>item = extra[0]<tab>text = item[4]<tab>if text is None:<tab><tab>return<tab>item_id = self.GetItem(item[0])[6]<tab>from bdb import Breakpoint<tab>for bplist in Breakpoint.bplist.itervalues():<tab><tab>for bp in bplist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if text.strip().lower() == ""none"":<tab><tab><tab><tab><tab>text = None<tab><tab><tab><tab>bp.cond = text<tab><tab><tab><tab>break<tab>self.RespondDebuggerData()",if id ( bp ) == item_id :,151
149,"def add(self, url: str, future_nzo: NzbObject, when: Optional[int] = None):<tab>""""""Add an URL to the URLGrabber queue, 'when' is seconds from now""""""<tab>if future_nzo and when:<tab><tab># Always increase counter<tab><tab>future_nzo.url_tries += 1<tab><tab># Too many tries? Cancel<tab><tab><IF-STMT><tab><tab><tab>self.fail_to_history(future_nzo, url, T(""Maximum retries""))<tab><tab><tab>return<tab><tab>future_nzo.url_wait = time.time() + when<tab>self.queue.put((url, future_nzo))",if future_nzo . url_tries > cfg . max_url_retries ( ) :,172
150,def _is_datetime_string(series):<tab>if series.dtype == object:<tab><tab>not_numeric = False<tab><tab>try:<tab><tab><tab>pd.to_numeric(series)<tab><tab>except Exception as e:<tab><tab><tab>not_numeric = True<tab><tab>datetime_col = None<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>datetime_col = pd.to_datetime(series)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>return False<tab><tab>if datetime_col is not None:<tab><tab><tab>return True<tab>return False,if not_numeric :,138
151,"def _getEventAndObservers(self, event):<tab>if isinstance(event, xpath.XPathQuery):<tab><tab># Treat as xpath<tab><tab>observers = self._xpathObservers<tab>else:<tab><tab><IF-STMT><tab><tab><tab># Treat as event<tab><tab><tab>observers = self._eventObservers<tab><tab>else:<tab><tab><tab># Treat as xpath<tab><tab><tab>event = xpath.internQuery(event)<tab><tab><tab>observers = self._xpathObservers<tab>return event, observers",if self . prefix == event [ : len ( self . prefix ) ] :,131
152,"def test_wildcard_import():<tab>bonobo = __import__(""bonobo"")<tab>assert bonobo.__version__<tab>for name in dir(bonobo):<tab><tab># ignore attributes starting by underscores<tab><tab>if name.startswith(""_""):<tab><tab><tab>continue<tab><tab>attr = getattr(bonobo, name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>assert name in bonobo.__all__",if inspect . ismodule ( attr ) :,97
153,"def relint_views(wid=None):<tab>windows = [sublime.Window(wid)] if wid else sublime.windows()<tab>for window in windows:<tab><tab>for view in window.views():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hit(view, ""relint_views"")",if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,93
154,def _check_for_unknown_gender(self):<tab>if self.obj.get_gender() == Person.UNKNOWN:<tab><tab>d = GenderDialog(parent=self.window)<tab><tab>gender = d.run()<tab><tab>d.destroy()<tab><tab><IF-STMT><tab><tab><tab>self.obj.set_gender(gender),if gender >= 0 :,83
155,"def add_to_path(self, fnames):<tab>""""""Add fnames to path""""""<tab>indexes = []<tab>for path in fnames:<tab><tab>project = self.get_source_project(path)<tab><tab><IF-STMT><tab><tab><tab>self.parent_widget.emit(SIGNAL(""pythonpath_changed()""))<tab><tab><tab>indexes.append(self.get_index(path))<tab>if indexes:<tab><tab>self.reset_icon_provider()<tab><tab>for index in indexes:<tab><tab><tab>self.update(index)",if project . add_to_pythonpath ( path ) :,132
156,"def validate(self, value):<tab>if value.grid_id is not None:<tab><tab>if not isinstance(value, self.proxy_class):<tab><tab><tab>self.error(""FileField only accepts GridFSProxy values"")<tab><tab><IF-STMT><tab><tab><tab>self.error(""Invalid GridFSProxy value"")","if not isinstance ( value . grid_id , ObjectId ) :",82
157,"def shortcut(self, input, ch_out, stride, name, if_first=False):<tab>ch_in = input.shape[1]<tab>if ch_in != ch_out or stride != 1:<tab><tab><IF-STMT><tab><tab><tab>return self.conv_bn_layer(input, ch_out, 1, stride, name=name)<tab><tab>else:<tab><tab><tab>return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name)<tab>else:<tab><tab>return input",if if_first :,127
158,"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab>if code == Path.MOVETO:<tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab>elif code == Path.CURVE3:<tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>ctx.curve_to(*points)<tab><tab>elif code == Path.CLOSEPOLY:<tab><tab><tab>ctx.close_path()",elif code == Path . CURVE4 :,172
159,"def _get_build_status(self, job_name, build_number):<tab>try:<tab><tab>build_info = self.server.get_build_info(job_name, build_number)<tab><tab><IF-STMT><tab><tab><tab>return ""building""<tab><tab>else:<tab><tab><tab>return ""built""<tab>except jenkins.NotFoundException:<tab><tab>return ""not found""","if build_info [ ""building"" ] :",96
160,"def _parse_param_value(name, datatype, default):<tab>if datatype == ""bool"":<tab><tab>if default.lower() == ""true"":<tab><tab><tab>return True<tab><tab>elif default.lower() == ""false"":<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>_s = ""{}: Invalid default value '{}' for bool parameter {}""<tab><tab><tab>raise SyntaxError(_s.format(self.name, default, p))<tab>elif datatype == ""int"":<tab><tab>if type(default) == int:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return int(default, 0)<tab>elif datatype == ""real"":<tab><tab><IF-STMT><tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return float(default)<tab>else:<tab><tab>return str(default)",if type ( default ) == float :,191
161,"def get_fills(self, exchange_order_id):<tab>async with aiohttp.ClientSession() as client:<tab><tab>response: aiohttp.ClientResponse = await client.get(<tab><tab><tab>f""{BASE_URL}{FILLS_ROUTE}"",<tab><tab><tab>params={""orderId"": exchange_order_id, ""limit"": 100},<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>msg = await response.json()<tab><tab><tab>except ValueError:<tab><tab><tab><tab>msg = await response.text()<tab><tab><tab>raise DydxAsyncAPIError(response.status, msg)<tab><tab>return await response.json()",if response . status >= 300 :,156
162,"def semanticTags(self, semanticTags):<tab>if semanticTags is None:<tab><tab>self.__semanticTags = OrderedDict()<tab># check<tab>for key, value in list(semanticTags.items()):<tab><tab>if not isinstance(key, int):<tab><tab><tab>raise TypeError(""At least one key is not a valid int position"")<tab><tab>if not isinstance(value, list):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab>)<tab><tab>for x in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(<tab><tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab><tab>)<tab>self.__semanticTags = semanticTags","if not isinstance ( x , str ) :",184
163,"def start_cutting_tool(self, event, axis, direction):<tab>toggle = event.EventObject<tab>self.cutting = toggle.Value<tab>if toggle.Value:<tab><tab># Disable the other toggles<tab><tab>for child in self.cutsizer.Children:<tab><tab><tab>child = child.Window<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child.Value = False<tab><tab>self.cutting_axis = axis<tab><tab>self.cutting_direction = direction<tab>else:<tab><tab>self.cutting_axis = None<tab><tab>self.cutting_direction = None<tab>self.cutting_dist = None",if child != toggle :,150
164,"def decoration_helper(self, patched, args, keywargs):<tab>extra_args = []<tab>with contextlib.ExitStack() as exit_stack:<tab><tab>for patching in patched.patchings:<tab><tab><tab>arg = exit_stack.enter_context(patching)<tab><tab><tab>if patching.attribute_name is not None:<tab><tab><tab><tab>keywargs.update(arg)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extra_args.append(arg)<tab><tab>args += tuple(extra_args)<tab><tab>yield (args, keywargs)",elif patching . new is DEFAULT :,134
165,def decodeattrs(attrs):<tab>names = []<tab>for bit in range(16):<tab><tab>mask = 1 << bit<tab><tab>if attrs & mask:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.append(attrnames[mask])<tab><tab><tab>else:<tab><tab><tab><tab>names.append(hex(mask))<tab>return names,if attrnames . has_key ( mask ) :,88
166,"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/params""):<tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))","if ""init"" not in item . keywords :",102
167,"def handle_socket(self, request):<tab>conn = request.connection<tab>while True:<tab><tab>chunk = conn.recv(4)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>slen = struct.unpack("">L"", chunk)[0]<tab><tab>chunk = conn.recv(slen)<tab><tab>while len(chunk) < slen:<tab><tab><tab>chunk = chunk + conn.recv(slen - len(chunk))<tab><tab>obj = pickle.loads(chunk)<tab><tab>record = logging.makeLogRecord(obj)<tab><tab>self.log_output += record.msg + ""\n""<tab><tab>self.handled.release()",if len ( chunk ) < 4 :,156
168,"def on_source_foreach(self, model, path, iter, id):<tab>m_id = model.get_value(iter, self.COLUMN_ID)<tab>if m_id == id:<tab><tab>if self._foreach_mode == ""get"":<tab><tab><tab>self._foreach_take = model.get_value(iter, self.COLUMN_ENABLED)<tab><tab><IF-STMT><tab><tab><tab>self._foreach_take = iter","elif self . _foreach_mode == ""set"" :",113
169,"def parts():<tab>for l in lists.leaves:<tab><tab>head_name = l.get_head_name()<tab><tab>if head_name == ""System`List"":<tab><tab><tab>yield l.leaves<tab><tab><IF-STMT><tab><tab><tab>raise MessageException(""Catenate"", ""invrp"", l)","elif head_name != ""System`Missing"" :",78
170,"def __fill_counter_values(self, command: str):<tab>result = []<tab>regex = r""(item[0-9]+\.counter_value)""<tab>for token in re.split(regex, command):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>result.append(str(self.simulator_config.item_dict[token].value))<tab><tab><tab>except (KeyError, ValueError, AttributeError):<tab><tab><tab><tab>logger.error(""Could not get counter value for "" + token)<tab><tab>else:<tab><tab><tab>result.append(token)<tab>return """".join(result)","if re . match ( regex , token ) is not None :",152
171,"def IMPORTFROM(self, node):<tab><IF-STMT><tab><tab>if not self.futuresAllowed:<tab><tab><tab>self.report(messages.LateFutureImport, node, [n.name for n in node.names])<tab>else:<tab><tab>self.futuresAllowed = False<tab>for alias in node.names:<tab><tab>if alias.name == ""*"":<tab><tab><tab>self.scope.importStarred = True<tab><tab><tab>self.report(messages.ImportStarUsed, node, node.module)<tab><tab><tab>continue<tab><tab>name = alias.asname or alias.name<tab><tab>importation = Importation(name, node)<tab><tab>if node.module == ""__future__"":<tab><tab><tab>importation.used = (self.scope, node)<tab><tab>self.addBinding(node, importation)","if node . module == ""__future__"" :",190
172,"def _split_batch_list(args, batch_list):<tab>new_list = []<tab>for batch in batch_list.batches:<tab><tab>new_list.append(batch)<tab><tab><IF-STMT><tab><tab><tab>yield batch_pb2.BatchList(batches=new_list)<tab><tab><tab>new_list = []<tab>if new_list:<tab><tab>yield batch_pb2.BatchList(batches=new_list)",if len ( new_list ) == args . batch_size_limit :,116
173,"def get_branch_or_use_upstream(branch_name, arg, repo):<tab>if not branch_name:  # use upstream branch<tab><tab>current_b = repo.current_branch<tab><tab>upstream_b = current_b.upstream<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""No {0} branch specified and the current branch has no upstream ""<tab><tab><tab><tab>""branch set"".format(arg)<tab><tab><tab>)<tab><tab>ret = current_b.upstream<tab>else:<tab><tab>ret = get_branch(branch_name, repo)<tab>return ret",if not upstream_b :,148
174,"def __init__(self, **settings):<tab>default_settings = self.get_default_settings()<tab>for name, value in default_settings.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(self, name, value)<tab>for name, value in settings.items():<tab><tab>if name not in default_settings:<tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Invalid setting '{}' for {}"".format(<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>self.__class__.__name__,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>setattr(self, name, value)","if not hasattr ( self , name ) :",144
175,"def _declare(self, name, obj, included=False, quals=0):<tab>if name in self._declarations:<tab><tab>prevobj, prevquals = self._declarations[name]<tab><tab>if prevobj is obj and prevquals == quals:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>raise api.FFIError(<tab><tab><tab><tab>""multiple declarations of %s (for interactive usage, ""<tab><tab><tab><tab>""try cdef(xx, override=True))"" % (name,)<tab><tab><tab>)<tab>assert ""__dotdotdot__"" not in name.split()<tab>self._declarations[name] = (obj, quals)<tab>if included:<tab><tab>self._included_declarations.add(obj)",if not self . _override :,174
176,"def include_file(name, fdir=tmp_dir, b64=False):<tab>try:<tab><tab>if fdir is None:<tab><tab><tab>fdir = """"<tab><tab><IF-STMT><tab><tab><tab>with io.open(os.path.join(fdir, name), ""rb"") as f:<tab><tab><tab><tab>return base64.b64encode(f.read()).decode(""utf-8"")<tab><tab>else:<tab><tab><tab>with io.open(os.path.join(fdir, name), ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>return f.read()<tab>except (OSError, IOError) as e:<tab><tab>logger.error(""Could not include file '{}': {}"".format(name, e))",if b64 :,174
177,"def to_raw_json(self):<tab>parts = {}<tab>for p in self.parts:<tab><tab><IF-STMT><tab><tab><tab>parts[p[0]] = []<tab><tab>parts[p[0]].append({""value"": p[2], ""parameters"": p[1]})<tab>children = [x.to_raw_json() for x in self.children]<tab>return {<tab><tab>""type"": self.__class__.__name__,<tab><tab>""children"": children,<tab><tab>""parts"": parts,<tab>}",if p [ 0 ] not in parts :,127
178,"def process_output(<tab>output: str, filename: str, start_line: int) -> Tuple[Optional[str], bool]:<tab>error_found = False<tab>for line in output.splitlines():<tab><tab>t = get_revealed_type(line, filename, start_line)<tab><tab><IF-STMT><tab><tab><tab>return t, error_found<tab><tab>elif ""error:"" in line:<tab><tab><tab>error_found = True<tab>return None, True  # finding no reveal_type is an error",if t :,117
179,"def __init__(<tab>self, resize_keyboard=None, one_time_keyboard=None, selective=None, row_width=3):<tab>if row_width > self.max_row_keys:<tab><tab># Todo: Will be replaced with Exception in future releases<tab><tab><IF-STMT><tab><tab><tab>logger.error(<tab><tab><tab><tab>""Telegram does not support reply keyboard row width over %d.""<tab><tab><tab><tab>% self.max_row_keys<tab><tab><tab>)<tab><tab>row_width = self.max_row_keys<tab>self.resize_keyboard = resize_keyboard<tab>self.one_time_keyboard = one_time_keyboard<tab>self.selective = selective<tab>self.row_width = row_width<tab>self.keyboard = []",if not DISABLE_KEYLEN_ERROR :,188
180,"def realizeElementExpressions(innerElement):<tab>elementHasBeenRealized = False<tab>for exp in innerElement.expressions:<tab><tab>if not hasattr(exp, ""realize""):<tab><tab><tab>continue<tab><tab># else:<tab><tab>before, during, after = exp.realize(innerElement)<tab><tab>elementHasBeenRealized = True<tab><tab>for n in before:<tab><tab><tab>newStream.append(n)<tab><tab><IF-STMT><tab><tab><tab>newStream.append(during)<tab><tab>for n in after:<tab><tab><tab>newStream.append(n)<tab>if elementHasBeenRealized is False:<tab><tab>newStream.append(innerElement)",if during is not None :,164
181,"def lex_number(self, pos):<tab># numeric literal<tab>start = pos<tab>found_dot = False<tab>while pos < len(self.string) and (<tab><tab>self.string[pos].isdigit() or self.string[pos] == "".""<tab>):<tab><tab><IF-STMT><tab><tab><tab>if found_dot is True:<tab><tab><tab><tab>raise ValueError(""Invalid number. Found multiple '.'"")<tab><tab><tab>found_dot = True<tab><tab># technically we allow more than one ""."" and let float()'s parsing<tab><tab># complain later<tab><tab>pos += 1<tab>val = self.string[start:pos]<tab>return Token(TokenType.LNUM, val, len(val))","if self . string [ pos ] == ""."" :",168
182,"def rename(src, dst):<tab># Try atomic or pseudo-atomic rename<tab>if _rename(src, dst):<tab><tab>return<tab># Fall back to ""move away and replace""<tab>try:<tab><tab>os.rename(src, dst)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>old = ""%s-%08x"" % (dst, random.randint(0, sys.maxsize))<tab><tab>os.rename(dst, old)<tab><tab>os.rename(src, dst)<tab><tab>try:<tab><tab><tab>os.unlink(old)<tab><tab>except Exception:<tab><tab><tab>pass",if e . errno != errno . EEXIST :,156
183,"def _the_callback(widget, event_id):<tab>point = widget.GetCenter()<tab>index = widget.WIDGET_INDEX<tab>if hasattr(callback, ""__call__""):<tab><tab>if num > 1:<tab><tab><tab>args = [point, index]<tab><tab>else:<tab><tab><tab>args = [point]<tab><tab><IF-STMT><tab><tab><tab>args.append(widget)<tab><tab>try_callback(callback, *args)<tab>return",if pass_widget :,109
184,"def run(self):<tab>for _ in range(self.n):<tab><tab>error = True<tab><tab>try:<tab><tab><tab>self.collection.insert_one({""test"": ""insert""})<tab><tab><tab>error = False<tab><tab>except:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>if self.expect_exception:<tab><tab><tab>assert error",if not self . expect_exception :,91
185,"def handle(self, *args: Any, **options: Any) -> None:<tab>realm = self.get_realm(options)<tab>if options[""all""]:<tab><tab><IF-STMT><tab><tab><tab>raise CommandError(<tab><tab><tab><tab>""You must specify a realm if you choose the --all option.""<tab><tab><tab>)<tab><tab>self.fix_all_users(realm)<tab><tab>return<tab>self.fix_emails(realm, options[""emails""])",if realm is None :,108
186,"def recv_tdi(self, nbits, pos):<tab>bits = 0<tab>for n in range(nbits * 2):<tab><tab>yield from self._wait_for_tck()<tab><tab><IF-STMT><tab><tab><tab>bits = (bits << 1) | (yield self.tdi.o)<tab>return bits",if ( yield self . tck . o ) == pos :,86
187,"def _split_head(self):<tab>if not hasattr(self, ""_severed_head""):<tab><tab><IF-STMT><tab><tab><tab>tree = self._tree.copy()<tab><tab><tab>head = tree.get_heading_text()<tab><tab><tab>tree.remove_heading()<tab><tab><tab>self._severed_head = (head, tree)<tab><tab>else:<tab><tab><tab>self._severed_head = (None, None)<tab>return self._severed_head",if self . _tree :,113
188,"def buildSearchTrie(self, choices):<tab>searchtrie = trie.Trie()<tab>for choice in choices:<tab><tab>for token in self.tokenizeChoice(choice):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>searchtrie[token] = []<tab><tab><tab>searchtrie[token].append(choice)<tab>return searchtrie",if not searchtrie . has_key ( token ) :,85
189,"def format_sql(sql, params):<tab>rv = []<tab>if isinstance(params, dict):<tab><tab># convert sql with named parameters to sql with unnamed parameters<tab><tab>conv = _FormatConverter(params)<tab><tab>if params:<tab><tab><tab>sql = sql_to_string(sql)<tab><tab><tab>sql = sql % conv<tab><tab><tab>params = conv.params<tab><tab>else:<tab><tab><tab>params = ()<tab>for param in params or ():<tab><tab><IF-STMT><tab><tab><tab>rv.append(""NULL"")<tab><tab>param = safe_repr(param)<tab><tab>rv.append(param)<tab>return sql, rv",if param is None :,151
190,def on_completed2():<tab>doner[0] = True<tab>if not qr:<tab><tab>if len(ql) > 0:<tab><tab><tab>observer.on_next(False)<tab><tab><tab>observer.on_completed()<tab><tab><IF-STMT><tab><tab><tab>observer.on_next(True)<tab><tab><tab>observer.on_completed(),elif donel [ 0 ] :,86
191,"def notify_digest(self, frequency, changes):<tab>notifications = defaultdict(list)<tab>users = {}<tab>for change in changes:<tab><tab>for user in self.get_users(frequency, change):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>notifications[user.pk].append(change)<tab><tab><tab><tab>users[user.pk] = user<tab>for user in users.values():<tab><tab>self.send_digest(<tab><tab><tab>user.profile.language,<tab><tab><tab>user.email,<tab><tab><tab>notifications[user.pk],<tab><tab><tab>subscription=user.current_subscription,<tab><tab>)",if change . project is None or user . can_access_project ( change . project ) :,163
192,"def _any_listener_using(self, target_group_arn):<tab>for load_balancer in self.load_balancers.values():<tab><tab>for listener in load_balancer.listeners.values():<tab><tab><tab>for rule in listener.rules:<tab><tab><tab><tab>for action in rule.actions:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False","if action . data . get ( ""target_group_arn"" ) == target_group_arn :",110
193,"def train_dict(self, triples):<tab>""""""Train a dict lemmatizer given training (word, pos, lemma) triples.""""""<tab># accumulate counter<tab>ctr = Counter()<tab>ctr.update([(p[0], p[1], p[2]) for p in triples])<tab># find the most frequent mappings<tab>for p, _ in ctr.most_common():<tab><tab>w, pos, l = p<tab><tab>if (w, pos) not in self.composite_dict:<tab><tab><tab>self.composite_dict[(w, pos)] = l<tab><tab><IF-STMT><tab><tab><tab>self.word_dict[w] = l<tab>return",if w not in self . word_dict :,158
194,"def parse_git_config(path):<tab>""""""Parse git config file.""""""<tab>config = dict()<tab>section = None<tab>with open(os.path.join(path, ""config""), ""r"") as f:<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>section = line[1:-1].strip()<tab><tab><tab><tab>config[section] = dict()<tab><tab><tab>elif section:<tab><tab><tab><tab>key, value = line.replace("" "", """").split(""="")<tab><tab><tab><tab>config[section][key] = value<tab>return config","if line . startswith ( ""["" ) :",146
195,"def send_signal(self, pid, signum):<tab>if pid in self.processes:<tab><tab>process = self.processes[pid]<tab><tab>hook_result = self.call_hook(""before_signal"", pid=pid, signum=signum)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(<tab><tab><tab><tab>""before_signal hook didn't return True ""<tab><tab><tab><tab>""=> signal %i is not sent to %i"" % (signum, pid)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>process.send_signal(signum)<tab><tab>self.call_hook(""after_signal"", pid=pid, signum=signum)<tab>else:<tab><tab>logger.debug(""process %s does not exist"" % pid)",if signum != signal . SIGKILL and not hook_result :,186
196,"def validate_pos_return(self):<tab>if self.is_pos and self.is_return:<tab><tab>total_amount_in_payments = 0<tab><tab>for payment in self.payments:<tab><tab><tab>total_amount_in_payments += payment.amount<tab><tab>invoice_total = self.rounded_total or self.grand_total<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Total payments amount can't be greater than {}"").format(<tab><tab><tab><tab><tab>-invoice_total<tab><tab><tab><tab>)<tab><tab><tab>)",if total_amount_in_payments < invoice_total :,144
197,"def delete(key, inner_key=None):<tab>if inner_key is not None:<tab><tab>try:<tab><tab><tab>del cache[key][inner_key]<tab><tab><tab>del use_count[key][inner_key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del cache[key]<tab><tab><tab><tab>del use_count[key]<tab><tab><tab>wrapper.cache_size -= 1<tab><tab>except KeyError:<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return True<tab>else:<tab><tab>try:<tab><tab><tab>wrapper.cache_size -= len(cache[key])<tab><tab><tab>del cache[key]<tab><tab><tab>del use_count[key]<tab><tab>except KeyError:<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return True",if not cache [ key ] :,189
198,"def insertionsort(array):<tab>size = array.getsize()<tab>array.reset(""Insertion sort"")<tab>for i in range(1, size):<tab><tab>j = i - 1<tab><tab>while j >= 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>array.swap(j, j + 1)<tab><tab><tab>j = j - 1<tab>array.message(""Sorted"")","if array . compare ( j , j + 1 ) <= 0 :",109
199,"def publish_state(cls, payload, state):<tab>try:<tab><tab>if isinstance(payload, LiveActionDB):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls.process(payload)<tab><tab><tab>else:<tab><tab><tab><tab>worker.get_worker().process(payload)<tab>except Exception:<tab><tab>traceback.print_exc()<tab><tab>print(payload)",if state == action_constants . LIVEACTION_STATUS_REQUESTED :,99
200,"def change_opacity_function(self, new_f):<tab>self.opacity_function = new_f<tab>dr = self.radius / self.num_levels<tab>sectors = []<tab>for submob in self.submobjects:<tab><tab>if type(submob) == AnnularSector:<tab><tab><tab>sectors.append(submob)<tab>for (r, submob) in zip(np.arange(0, self.radius, dr), sectors):<tab><tab><IF-STMT><tab><tab><tab># it's the shadow, don't dim it<tab><tab><tab>continue<tab><tab>alpha = self.opacity_function(r)<tab><tab>submob.set_fill(opacity=alpha)",if type ( submob ) != AnnularSector :,180
201,"def is_suppressed_warning(<tab>type: str, subtype: str, suppress_warnings: List[str]) -> bool:<tab>""""""Check the warning is suppressed or not.""""""<tab>if type is None:<tab><tab>return False<tab>for warning_type in suppress_warnings:<tab><tab><IF-STMT><tab><tab><tab>target, subtarget = warning_type.split(""."", 1)<tab><tab>else:<tab><tab><tab>target, subtarget = warning_type, None<tab><tab>if target == type:<tab><tab><tab>if (<tab><tab><tab><tab>subtype is None<tab><tab><tab><tab>or subtarget is None<tab><tab><tab><tab>or subtarget == subtype<tab><tab><tab><tab>or subtarget == ""*""<tab><tab><tab>):<tab><tab><tab><tab>return True<tab>return False","if ""."" in warning_type :",178
202,"def set_many(self, mapping, timeout=None):<tab>timeout = self._normalize_timeout(timeout)<tab># Use transaction=False to batch without calling redis MULTI<tab># which is not supported by twemproxy<tab>pipe = self._client.pipeline(transaction=False)<tab>for key, value in _items(mapping):<tab><tab>dump = self.dump_object(value)<tab><tab><IF-STMT><tab><tab><tab>pipe.set(name=self.key_prefix + key, value=dump)<tab><tab>else:<tab><tab><tab>pipe.setex(name=self.key_prefix + key, value=dump, time=timeout)<tab>return pipe.execute()",if timeout == - 1 :,160
203,"def maybe_relative_path(path):<tab>if not os.path.isabs(path):<tab><tab>return path  # already relative<tab>dir = path<tab>names = []<tab>while True:<tab><tab>prevdir = dir<tab><tab>dir, name = os.path.split(prevdir)<tab><tab>if dir == prevdir or not dir:<tab><tab><tab>return path  # failed to make it relative<tab><tab>names.append(name)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.reverse()<tab><tab><tab><tab>return os.path.join(*names)<tab><tab>except OSError:<tab><tab><tab>pass","if samefile ( dir , os . curdir ) :",155
204,"def word_range(word):<tab>for ind in range(len(word)):<tab><tab>temp = word[ind]<tab><tab>for c in [chr(x) for x in range(ord(""a""), ord(""z"") + 1)]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield word[:ind] + c + word[ind + 1 :]",if c != temp :,83
205,"def validate(self):<tab>self.update_soil_edit(""sand_composition"")<tab>for soil_type in self.soil_types:<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""{0} should be a value between 0 and 100"").format(soil_type))<tab>if sum(self.get(soil_type) for soil_type in self.soil_types) != 100:<tab><tab>frappe.throw(_(""Soil compositions do not add up to 100""))",if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,142
206,"def on_click(self, event):<tab>run = self._is_running()<tab>if event[""button""] == self.button_activate:<tab><tab>self.py3.command_run([""xscreensaver-command"", ""-activate""])<tab>if event[""button""] == self.button_toggle:<tab><tab><IF-STMT><tab><tab><tab>self.py3.command_run([""xscreensaver-command"", ""-exit""])<tab><tab>else:<tab><tab><tab># Because we want xscreensaver to continue running after<tab><tab><tab># exit, we instead use preexec_fn=setpgrp here.<tab><tab><tab>Popen(<tab><tab><tab><tab>[""xscreensaver"", ""-no-splash"", ""-no-capture-stderr""],<tab><tab><tab><tab>stdout=PIPE,<tab><tab><tab><tab>stderr=PIPE,<tab><tab><tab><tab>preexec_fn=setpgrp,<tab><tab><tab>)",if run :,199
207,"def maybe_relative_path(path):<tab>if not os.path.isabs(path):<tab><tab>return path  # already relative<tab>dir = path<tab>names = []<tab>while True:<tab><tab>prevdir = dir<tab><tab>dir, name = os.path.split(prevdir)<tab><tab><IF-STMT><tab><tab><tab>return path  # failed to make it relative<tab><tab>names.append(name)<tab><tab>try:<tab><tab><tab>if samefile(dir, os.curdir):<tab><tab><tab><tab>names.reverse()<tab><tab><tab><tab>return os.path.join(*names)<tab><tab>except OSError:<tab><tab><tab>pass",if dir == prevdir or not dir :,155
208,"def _format_micros(self, datestring):<tab>parts = datestring[:-1].split(""."")<tab>if len(parts) == 1:<tab><tab><IF-STMT><tab><tab><tab>return datestring[:-1] + "".000000Z""<tab><tab>else:<tab><tab><tab>return datestring + "".000000Z""<tab>else:<tab><tab>micros = parts[-1][:6] if len(parts[-1]) > 6 else parts[-1]<tab><tab>return ""."".join(parts[:-1] + [""{:06d}"".format(int(micros))]) + ""Z""","if datestring . endswith ( ""Z"" ) :",135
209,"def preprocess_raw_enwik9(input_filename, output_filename):<tab>with open(input_filename, ""r"") as f1:<tab><tab>with open(output_filename, ""w"") as f2:<tab><tab><tab>while True:<tab><tab><tab><tab>line = f1.readline()<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>line = list(enwik9_norm_transform([line]))[0]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if line[0] == "" "":<tab><tab><tab><tab><tab><tab>line = line[1:]<tab><tab><tab><tab><tab>f2.writelines(line + ""\n"")","if line != "" "" and line != """" :",164
210,"def set(self, item, data):<tab>if not type(item) is slice:<tab><tab>item = slice(item, item + len(data), None)<tab>virt_item = self.item2virtitem(item)<tab>if not virt_item:<tab><tab>return<tab>off = 0<tab>for s, n_item in virt_item:<tab><tab><IF-STMT><tab><tab><tab>i = slice(off, n_item.stop + off - n_item.start, n_item.step)<tab><tab><tab>data_slice = data.__getitem__(i)<tab><tab><tab>s.content.__setitem__(n_item, data_slice)<tab><tab><tab>off = i.stop<tab><tab>else:<tab><tab><tab>raise ValueError(""TODO XXX"")<tab>return","if isinstance ( s , ProgBits ) :",184
211,"def walk(msg, callback, data):<tab>partnum = 0<tab>for part in msg.walk():<tab><tab># multipart/* are just containers<tab><tab>if part.get_content_maintype() == ""multipart"":<tab><tab><tab>continue<tab><tab>ctype = part.get_content_type()<tab><tab>if ctype is None:<tab><tab><tab>ctype = OCTET_TYPE<tab><tab>filename = part.get_filename()<tab><tab><IF-STMT><tab><tab><tab>filename = PART_FN_TPL % (partnum)<tab><tab>headers = dict(part)<tab><tab>LOG.debug(headers)<tab><tab>headers[""Content-Type""] = ctype<tab><tab>payload = util.fully_decoded_payload(part)<tab><tab>callback(data, filename, payload, headers)<tab><tab>partnum = partnum + 1",if not filename :,190
212,"def _run_wes(args):<tab>""""""Run CWL using a Workflow Execution Service (WES) endpoint""""""<tab>main_file, json_file, project_name = _get_main_and_json(args.directory)<tab>main_file = _pack_cwl(main_file)<tab>if args.host and ""stratus"" in args.host:<tab><tab>_run_wes_stratus(args, main_file, json_file)<tab>else:<tab><tab>opts = [""--no-wait""]<tab><tab><IF-STMT><tab><tab><tab>opts += [""--host"", args.host]<tab><tab>if args.auth:<tab><tab><tab>opts += [""--auth"", args.auth]<tab><tab>cmd = [""wes-client""] + opts + [main_file, json_file]<tab><tab>_run_tool(cmd)",if args . host :,197
213,"def insertTestData(self, rows):<tab>for row in rows:<tab><tab>if isinstance(row, Worker):<tab><tab><tab>self.workers[row.id] = dict(<tab><tab><tab><tab>id=row.id, name=row.name, paused=0, graceful=0, info=row.info<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>row.id = row.buildermasterid * 10000 + row.workerid<tab><tab><tab>self.configured[row.id] = dict(<tab><tab><tab><tab>buildermasterid=row.buildermasterid, workerid=row.workerid<tab><tab><tab>)<tab><tab>elif isinstance(row, ConnectedWorker):<tab><tab><tab>self.connected[row.id] = dict(masterid=row.masterid, workerid=row.workerid)","elif isinstance ( row , ConfiguredWorker ) :",194
214,"def local_shape_to_shape_i(node):<tab>if node.op == T.shape:<tab><tab># This optimization needs ShapeOpt and fgraph.shape_feature<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>shape_feature = node.fgraph.shape_feature<tab><tab>ret = shape_feature.make_vector_shape(node.inputs[0])<tab><tab># We need to copy over stack trace from input to output<tab><tab>copy_stack_trace(node.outputs[0], ret)<tab><tab>return [ret]","if not hasattr ( node . fgraph , ""shape_feature"" ) :",136
215,"def get_config():<tab>""""""Get INI parser with version.ini data.""""""<tab># TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`.<tab>ini_path = os.path.join(THIS_DIRECTORY, ""version.ini"")<tab><IF-STMT><tab><tab>ini_path = os.path.join(THIS_DIRECTORY, ""../../version.ini"")<tab><tab>if not os.path.exists(ini_path):<tab><tab><tab>raise RuntimeError(""Couldn't find version.ini"")<tab>config = configparser.ConfigParser()<tab>config.read(ini_path)<tab>return config",if not os . path . exists ( ini_path ) :,156
216,"def init_weights(self, pretrained=None):<tab>if isinstance(pretrained, str):<tab><tab>logger = logging.getLogger()<tab><tab>load_checkpoint(self, pretrained, strict=False, logger=logger)<tab>elif pretrained is None:<tab><tab>for m in self.modules():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kaiming_init(m)<tab><tab><tab>elif isinstance(m, (_BatchNorm, nn.GroupNorm)):<tab><tab><tab><tab>constant_init(m, 1)<tab>else:<tab><tab>raise TypeError(""pretrained must be a str or None"")","if isinstance ( m , nn . Conv2d ) :",141
217,"def isValidDateString(config_param_name, value, valid_value):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return value<tab><tab>day, month, year = value.split(""-"")<tab><tab>if int(day) < 1 or int(day) > 31:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(month) < 1 or int(month) > 12:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(year) < 1900 or int(year) > 2013:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>return value<tab>except Exception:<tab><tab>raise DateStringValueError(config_param_name, value)","if value == ""DD-MM-YYYY"" :",187
218,"def from_obj(cls, py_obj):<tab>if not isinstance(py_obj, Image):<tab><tab>raise TypeError(""py_obj must be a wandb.Image"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>box_keys = list(py_obj._boxes.keys())<tab><tab>else:<tab><tab><tab>box_keys = []<tab><tab>if hasattr(py_obj, ""masks"") and py_obj.masks:<tab><tab><tab>mask_keys = list(py_obj.masks.keys())<tab><tab>else:<tab><tab><tab>mask_keys = []<tab><tab>return cls(box_keys, mask_keys)","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :",164
219,"def _path_type(st, lst):<tab>parts = []<tab>if st:<tab><tab>if stat.S_ISREG(st.st_mode):<tab><tab><tab>parts.append(""file"")<tab><tab><IF-STMT><tab><tab><tab>parts.append(""dir"")<tab><tab>else:<tab><tab><tab>parts.append(""other"")<tab>if lst:<tab><tab>if stat.S_ISLNK(lst.st_mode):<tab><tab><tab>parts.append(""link"")<tab>return "" "".join(parts)",elif stat . S_ISDIR ( st . st_mode ) :,130
220,"def is_destructive(queries):<tab>""""""Returns if any of the queries in *queries* is destructive.""""""<tab>keywords = (""drop"", ""shutdown"", ""delete"", ""truncate"", ""alter"")<tab>for query in sqlparse.split(queries):<tab><tab>if query:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>elif query_starts_with(<tab><tab><tab><tab>query, [""update""]<tab><tab><tab>) is True and not query_has_where_clause(query):<tab><tab><tab><tab>return True<tab>return False","if query_starts_with ( query , keywords ) is True :",136
221,"def _store_gsuite_membership_post(self):<tab>""""""Flush storing gsuite memberships.""""""<tab>if not self.member_cache:<tab><tab>return<tab>self.session.flush()<tab># session.execute automatically flushes<tab>if self.membership_items:<tab><tab><IF-STMT><tab><tab><tab># SQLite doesn't support bulk insert<tab><tab><tab>for item in self.membership_items:<tab><tab><tab><tab>stmt = self.dao.TBL_MEMBERSHIP.insert(item)<tab><tab><tab><tab>self.session.execute(stmt)<tab><tab>else:<tab><tab><tab>stmt = self.dao.TBL_MEMBERSHIP.insert(self.membership_items)<tab><tab><tab>self.session.execute(stmt)","if get_sql_dialect ( self . session ) == ""sqlite"" :",182
222,"def forward(self, inputs: paddle.Tensor):<tab>outputs = []<tab>blocks = self.block(inputs)<tab>route = None<tab>for i, block in enumerate(blocks):<tab><tab><IF-STMT><tab><tab><tab>block = paddle.concat([route, block], axis=1)<tab><tab>route, tip = self.yolo_blocks[i](block)<tab><tab>block_out = self.block_outputs[i](tip)<tab><tab>outputs.append(block_out)<tab><tab>if i < 2:<tab><tab><tab>route = self.route_blocks_2[i](route)<tab><tab><tab>route = self.upsample(route)<tab>return outputs",if i > 0 :,163
223,"def deep_dict(self, root=None):<tab>if root is None:<tab><tab>root = self<tab>result = {}<tab>for key, value in root.items():<tab><tab><IF-STMT><tab><tab><tab>result[key] = self.deep_dict(root=self.__class__._get_next(key, root))<tab><tab>else:<tab><tab><tab>result[key] = value<tab>return result","if isinstance ( value , dict ) :",99
224,"def _parse_param_list(self, content):<tab>r = Reader(content)<tab>params = []<tab>while not r.eof():<tab><tab>header = r.read().strip()<tab><tab><IF-STMT><tab><tab><tab>arg_name, arg_type = header.split("" : "")[:2]<tab><tab>else:<tab><tab><tab>arg_name, arg_type = header, """"<tab><tab>desc = r.read_to_next_unindented_line()<tab><tab>desc = dedent_lines(desc)<tab><tab>params.append((arg_name, arg_type, desc))<tab>return params","if "" : "" in header :",147
225,"def _ungroup(sequence, groups=None):<tab>for v in sequence:<tab><tab><IF-STMT><tab><tab><tab>if groups is not None:<tab><tab><tab><tab>groups.append(list(_ungroup(v, groups=None)))<tab><tab><tab>for v in _ungroup(v, groups):<tab><tab><tab><tab>yield v<tab><tab>else:<tab><tab><tab>yield v","if isinstance ( v , ( list , tuple ) ) :",95
226,"def _add_resource_group(obj):<tab>if isinstance(obj, list):<tab><tab>for array_item in obj:<tab><tab><tab>_add_resource_group(array_item)<tab>elif isinstance(obj, dict):<tab><tab>try:<tab><tab><tab>if ""resourcegroup"" not in [x.lower() for x in obj.keys()]:<tab><tab><tab><tab>if obj[""id""]:<tab><tab><tab><tab><tab>obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""]<tab><tab>except (KeyError, IndexError, TypeError):<tab><tab><tab>pass<tab><tab>for item_key in obj:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_add_resource_group(obj[item_key])","if item_key != ""sourceVault"" :",175
227,"def haslayer(self, cls):<tab>""""""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax.""""""<tab>if self.__class__ == cls or self.__class__.__name__ == cls:<tab><tab>return 1<tab>for f in self.packetfields:<tab><tab>fvalue_gen = self.getfieldval(f.name)<tab><tab>if fvalue_gen is None:<tab><tab><tab>continue<tab><tab>if not f.islist:<tab><tab><tab>fvalue_gen = SetGen(fvalue_gen, _iterpacket=0)<tab><tab>for fvalue in fvalue_gen:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = fvalue.haslayer(cls)<tab><tab><tab><tab>if ret:<tab><tab><tab><tab><tab>return ret<tab>return self.payload.haslayer(cls)","if isinstance ( fvalue , Packet ) :",199
228,"def _post_attachment(self, message, channel, color, sub_fields=None):<tab>if channel is None:<tab><tab>message_channels = self.channels<tab>else:<tab><tab>message_channels = [channel]<tab>for message_channel in message_channels:<tab><tab>attachment = {<tab><tab><tab>""fallback"": message,<tab><tab><tab>""text"": message,<tab><tab><tab>""color"": color,<tab><tab>}<tab><tab><IF-STMT><tab><tab><tab>attachment[""fields""] = sub_fields<tab><tab>self.slack_client.api_call(<tab><tab><tab>""chat.postMessage"",<tab><tab><tab>channel=message_channel,<tab><tab><tab>attachments=[attachment],<tab><tab><tab>as_user=True,<tab><tab>)",if sub_fields is not None :,178
229,"def create(cls, repository, args):<tab>key = cls()<tab>passphrase = os.environ.get(""ATTIC_PASSPHRASE"")<tab>if passphrase is not None:<tab><tab>passphrase2 = passphrase<tab>else:<tab><tab>passphrase, passphrase2 = 1, 2<tab>while passphrase != passphrase2:<tab><tab>passphrase = getpass(""Enter passphrase: "")<tab><tab><IF-STMT><tab><tab><tab>print(""Passphrase must not be blank"")<tab><tab><tab>continue<tab><tab>passphrase2 = getpass(""Enter same passphrase again: "")<tab><tab>if passphrase != passphrase2:<tab><tab><tab>print(""Passphrases do not match"")<tab>key.init(repository, passphrase)<tab>if passphrase:<tab><tab>print(""Remember your passphrase. Your data will be inaccessible without it."")<tab>return key",if not passphrase :,184
230,"def _generate_create_date(self):<tab>if self.timezone is not None:<tab><tab># First, assume correct capitalization<tab><tab>tzinfo = tz.gettz(self.timezone)<tab><tab><IF-STMT><tab><tab><tab># Fall back to uppercase<tab><tab><tab>tzinfo = tz.gettz(self.timezone.upper())<tab><tab>if tzinfo is None:<tab><tab><tab>raise util.CommandError(""Can't locate timezone: %s"" % self.timezone)<tab><tab>create_date = (<tab><tab><tab>datetime.datetime.utcnow().replace(tzinfo=tz.tzutc()).astimezone(tzinfo)<tab><tab>)<tab>else:<tab><tab>create_date = datetime.datetime.now()<tab>return create_date",if tzinfo is None :,168
231,"def _read_header_lines(fp):<tab>""""""Read lines with headers until the start of body""""""<tab>lines = deque()<tab>for line in fp:<tab><tab>if is_empty(line):<tab><tab><tab>break<tab><tab># tricky case if it's not a header and not an empty line<tab><tab># usually means that user forgot to separate the body and newlines<tab><tab># so ""unread"" this line here, what means to treat it like a body<tab><tab><IF-STMT><tab><tab><tab>fp.seek(fp.tell() - len(line))<tab><tab><tab>break<tab><tab>lines.append(line)<tab>return lines",if not _RE_HEADER . match ( line ) :,153
232,"def _media_files_drag_received(widget, context, x, y, data, info, timestamp):<tab>uris = data.get_uris()<tab>files = []<tab>for uri in uris:<tab><tab>try:<tab><tab><tab>uri_tuple = GLib.filename_from_uri(uri)<tab><tab>except:<tab><tab><tab>continue<tab><tab>uri, unused = uri_tuple<tab><tab><IF-STMT><tab><tab><tab>if utils.is_media_file(uri) == True:<tab><tab><tab><tab>files.append(uri)<tab>if len(files) == 0:<tab><tab>return<tab>open_dropped_files(files)",if os . path . exists ( uri ) == True :,159
233,"def remove_importlib(frame, options):<tab>if frame is None:<tab><tab>return None<tab>for child in frame.children:<tab><tab>remove_importlib(child, options=options)<tab><tab><IF-STMT><tab><tab><tab># remove this node, moving the self_time and children up to the parent<tab><tab><tab>frame.self_time += child.self_time<tab><tab><tab>frame.add_children(child.children, after=child)<tab><tab><tab>child.remove_from_parent()<tab>return frame","if ""<frozen importlib._bootstrap"" in child . file_path :",132
234,"def __call__(self, graph):<tab>for layer_name, data in self.params:<tab><tab><IF-STMT><tab><tab><tab>node = graph.get_node(layer_name)<tab><tab><tab>node.data = self.adjust_parameters(node, data)<tab><tab>else:<tab><tab><tab>print_stderr(""Ignoring parameters for non-existent layer: %s"" % layer_name)<tab>return graph",if layer_name in graph :,99
235,"def test_with_three_points(self):<tab>cba = ia.Polygon([(1, 2), (3, 4), (5, 5)])<tab>for i, xy in enumerate(cba):<tab><tab>assert i in [0, 1, 2]<tab><tab>if i == 0:<tab><tab><tab>assert np.allclose(xy, (1, 2))<tab><tab><IF-STMT><tab><tab><tab>assert np.allclose(xy, (3, 4))<tab><tab>elif i == 2:<tab><tab><tab>assert np.allclose(xy, (5, 5))<tab>assert i == 2",elif i == 1 :,136
236,"def _serve(self):<tab>self._conn = self.manager.request(REQUEST_DNS_LISTENER, self.domain)<tab>conn = MsgPackMessages(self._conn)<tab>while self.active:<tab><tab>request = conn.recv()<tab><tab>if not request:<tab><tab><tab>logger.warning(""DNS: Recieved empty request. Shutdown"")<tab><tab><tab>self.stop()<tab><tab><tab>break<tab><tab>now = time.time()<tab><tab>response = self.handler.process(request)<tab><tab>if not response:<tab><tab><tab>response = []<tab><tab>used = time.time() - now<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""DNS: Slow processing speed (%s)s"", used)<tab><tab>conn.send(response)",if used > 1 :,180
237,"def read(cls, fp, **kwargs):<tab>major_version, minor_version, count = read_fmt(""2HI"", fp)<tab>items = []<tab>for _ in range(count):<tab><tab>length = read_fmt(""I"", fp)[0] - 4<tab><tab><IF-STMT><tab><tab><tab>with io.BytesIO(fp.read(length)) as f:<tab><tab><tab><tab>items.append(Annotation.read(f))<tab>return cls(major_version=major_version, minor_version=minor_version, items=items)",if length > 0 :,129
238,"def save_uploaded_files():<tab>files = []<tab>unzip = bool(request.form.get(""unzip"") in [""true"", ""on""])<tab>for uploaded_file in request.files.getlist(""files""):<tab><tab><IF-STMT><tab><tab><tab>with zipfile.ZipFile(uploaded_file, ""r"") as zf:<tab><tab><tab><tab>for info in zf.infolist():<tab><tab><tab><tab><tab>name = info.filename<tab><tab><tab><tab><tab>size = info.file_size<tab><tab><tab><tab><tab>data = zf.read(name)<tab><tab><tab><tab><tab>if size > 0:<tab><tab><tab><tab><tab><tab>files.append(save_file(data, filename=name.split(""/"")[-1]))<tab><tab>else:<tab><tab><tab>files.append(save_file(uploaded_file))<tab>return files",if unzip and zipfile . is_zipfile ( uploaded_file ) :,195
239,"def analyze_string_content(self, string, line_num, filename):<tab>output = {}<tab>if self.keyword_exclude and self.keyword_exclude.search(string):<tab><tab>return output<tab>for identifier in self.secret_generator(<tab><tab>string,<tab><tab>filetype=determine_file_type(filename),<tab>):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>secret = PotentialSecret(<tab><tab><tab>self.secret_type,<tab><tab><tab>filename,<tab><tab><tab>identifier,<tab><tab><tab>line_num,<tab><tab>)<tab><tab>output[secret] = secret<tab>return output",if self . is_secret_false_positive ( identifier ) :,157
240,"def _validate_and_set_default_hyperparameters(self):<tab>""""""Placeholder docstring""""""<tab># Check if all the required hyperparameters are set. If there is a default value<tab># for one, set it.<tab>for name, definition in self.hyperparameter_definitions.items():<tab><tab>if name not in self.hyperparam_dict:<tab><tab><tab>spec = definition[""spec""]<tab><tab><tab>if ""DefaultValue"" in spec:<tab><tab><tab><tab>self.hyperparam_dict[name] = spec[""DefaultValue""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Required hyperparameter: %s is not set"" % name)","elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :",158
241,"def get_code(self, fullname=None):<tab>fullname = self._fix_name(fullname)<tab>if self.code is None:<tab><tab>mod_type = self.etc[2]<tab><tab>if mod_type == imp.PY_SOURCE:<tab><tab><tab>source = self.get_source(fullname)<tab><tab><tab>self.code = compile(source, self.filename, ""exec"")<tab><tab>elif mod_type == imp.PY_COMPILED:<tab><tab><tab>self._reopen()<tab><tab><tab>try:<tab><tab><tab><tab>self.code = read_code(self.file)<tab><tab><tab>finally:<tab><tab><tab><tab>self.file.close()<tab><tab><IF-STMT><tab><tab><tab>self.code = self._get_delegate().get_code()<tab>return self.code",elif mod_type == imp . PKG_DIRECTORY :,196
242,"def eigh_abstract_eval(operand, lower):<tab>if isinstance(operand, ShapedArray):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Argument to symmetric eigendecomposition must have shape [..., n, n],""<tab><tab><tab><tab>""got shape {}"".format(operand.shape)<tab><tab><tab>)<tab><tab>batch_dims = operand.shape[:-2]<tab><tab>n = operand.shape[-1]<tab><tab>v = ShapedArray(batch_dims + (n, n), operand.dtype)<tab><tab>w = ShapedArray(batch_dims + (n,), lax.lax._complex_basetype(operand.dtype))<tab>else:<tab><tab>v, w = operand, operand<tab>return v, w",if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,191
243,"def conninfo_parse(dsn):<tab>ret = {}<tab>length = len(dsn)<tab>i = 0<tab>while i < length:<tab><tab>if dsn[i].isspace():<tab><tab><tab>i += 1<tab><tab><tab>continue<tab><tab>param_match = PARAMETER_RE.match(dsn[i:])<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>param = param_match.group(1)<tab><tab>i += param_match.end()<tab><tab>if i >= length:<tab><tab><tab>return<tab><tab>value, end = read_param_value(dsn[i:])<tab><tab>if value is None:<tab><tab><tab>return<tab><tab>i += end<tab><tab>ret[param] = value<tab>return ret",if not param_match :,175
244,"def load_weights_from_unsupervised(self, unsupervised_model):<tab>update_state_dict = copy.deepcopy(self.network.state_dict())<tab>for param, weights in unsupervised_model.network.state_dict().items():<tab><tab>if param.startswith(""encoder""):<tab><tab><tab># Convert encoder's layers name to match<tab><tab><tab>new_param = ""tabnet."" + param<tab><tab>else:<tab><tab><tab>new_param = param<tab><tab><IF-STMT><tab><tab><tab># update only common layers<tab><tab><tab>update_state_dict[new_param] = weights<tab>self.network.load_state_dict(update_state_dict)",if self . network . state_dict ( ) . get ( new_param ) is not None :,170
245,"def viewer_setup(self):<tab>for key, value in DEFAULT_CAMERA_CONFIG.items():<tab><tab><IF-STMT><tab><tab><tab>getattr(self.viewer.cam, key)[:] = value<tab><tab>else:<tab><tab><tab>setattr(self.viewer.cam, key, value)","if isinstance ( value , np . ndarray ) :",75
246,"def colormap_changed(change):<tab>if change[""new""]:<tab><tab>cmap_colors = [<tab><tab><tab>color[1:] for color in cmap.step.__dict__[""_schemes""][colormap.value]<tab><tab>]<tab><tab>palette.value = "", "".join(cmap_colors)<tab><tab>colorbar = getattr(cmap.step, colormap.value)<tab><tab>colorbar_output = self.colorbar_widget<tab><tab>with colorbar_output:<tab><tab><tab>colorbar_output.clear_output()<tab><tab><tab>display(colorbar)<tab><tab><IF-STMT><tab><tab><tab>labels = [f""Class {i+1}"" for i in range(len(palette.value.split("","")))]<tab><tab><tab>legend_labels.value = "", "".join(labels)","if len ( palette . value ) > 0 and "","" in palette . value :",185
247,"def invalidate(self, layers=None):<tab>if layers is None:<tab><tab>layers = Layer.AllLayers<tab>if layers:<tab><tab>layers = set(layers)<tab><tab>self.invalidLayers.update(layers)<tab><tab>blockRenderers = [<tab><tab><tab>br<tab><tab><tab>for br in self.blockRenderers<tab><tab><tab>if br.layer is Layer.Blocks or br.layer not in layers<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>self.forgetDisplayLists()<tab><tab>self.blockRenderers = blockRenderers<tab><tab>if self.renderer.showRedraw and Layer.Blocks in layers:<tab><tab><tab>self.needsRedisplay = True",if len ( blockRenderers ) < len ( self . blockRenderers ) :,184
248,"def fromstring(cls, input):<tab>productions = []<tab>for linenum, line in enumerate(input.split(""\n"")):<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>productions += _read_dependency_production(line)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""Unable to parse line %s: %s"" % (linenum, line))<tab>if len(productions) == 0:<tab><tab>raise ValueError(""No productions found!"")<tab>return DependencyGrammar(productions)","if line . startswith ( ""#"" ) or line == """" :",130
249,"def repl(m, base_path, rel_path=None):<tab>if m.group(""comments""):<tab><tab>tag = m.group(""comments"")<tab>else:<tab><tab>tag = m.group(""open"")<tab><tab><IF-STMT><tab><tab><tab>tag += RE_TAG_LINK_ATTR.sub(<tab><tab><tab><tab>lambda m2: repl_absolute(m2, base_path), m.group(""attr"")<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>tag += RE_TAG_LINK_ATTR.sub(<tab><tab><tab><tab>lambda m2: repl_relative(m2, base_path, rel_path), m.group(""attr"")<tab><tab><tab>)<tab><tab>tag += m.group(""close"")<tab>return tag",if rel_path is None :,179
250,"def encode(path):<tab>if isinstance(path, str_cls):<tab><tab>try:<tab><tab><tab>path = path.encode(fs_encoding, ""strict"")<tab><tab>except UnicodeEncodeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>path = path.encode(fs_fallback_encoding, ""strict"")<tab>return path",if not platform . is_linux ( ) :,86
251,"def __iter__(self):<tab>base_iterator = super(ProcessIterable, self).__iter__()<tab>if getattr(self.queryset, ""_coerced"", False):<tab><tab>for process in base_iterator:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>process = coerce_to_related_instance(<tab><tab><tab><tab><tab>process, process.flow_class.process_class<tab><tab><tab><tab>)<tab><tab><tab>yield process<tab>else:<tab><tab>for process in base_iterator:<tab><tab><tab>yield process","if isinstance ( process , self . queryset . model ) :",125
252,"def footnotes_under(n: Element) -> Iterator[nodes.footnote]:<tab>if isinstance(n, nodes.footnote):<tab><tab>yield n<tab>else:<tab><tab>for c in n.children:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>elif isinstance(c, nodes.Element):<tab><tab><tab><tab>yield from footnotes_under(c)","if isinstance ( c , addnodes . start_of_file ) :",99
253,"def _process_submissions(self) -> None:<tab>""""""Process all submissions which have not been processed yet.""""""<tab>while self._to_be_processed:<tab><tab>job = self._to_be_processed[0]<tab><tab>job.process()  # trigger computation<tab><tab><IF-STMT><tab><tab><tab>heapq.heappush(<tab><tab><tab><tab>self._steady_priority_queue,<tab><tab><tab><tab>OrderedJobs(job.release_time, self._order, job),<tab><tab><tab>)<tab><tab>self._to_be_processed.popleft()  # remove right after it is added to the heap queue<tab><tab>self._order += 1",if not self . batch_mode :,156
254,"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab>if strip_delimiters:<tab><tab><tab>if "","" in line or "";"" in line:<tab><tab><tab><tab>continue<tab><tab>yield line",if match :,145
255,"def _get_payload_hash(self, method, data=None):<tab>if method in (""POST"", ""PUT""):<tab><tab>if data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># File upload; don't try to read the entire payload<tab><tab><tab><tab>return UNSIGNED_PAYLOAD<tab><tab><tab>return _hash(data)<tab><tab>else:<tab><tab><tab>return UNSIGNED_PAYLOAD<tab>else:<tab><tab>return _hash("""")","if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :",118
256,"def get_download_info(self):<tab>try:<tab><tab>download_info = self.api.get_download_info(self.game)<tab><tab>result = True<tab>except NoDownloadLinkFound as e:<tab><tab>print(e)<tab><tab><IF-STMT><tab><tab><tab>Config.unset(""current_download"")<tab><tab>GLib.idle_add(<tab><tab><tab>self.parent.parent.show_error,<tab><tab><tab>_(""Download error""),<tab><tab><tab>_(<tab><tab><tab><tab>""There was an error when trying to fetch the download link!\n{}"".format(<tab><tab><tab><tab><tab>e<tab><tab><tab><tab>)<tab><tab><tab>),<tab><tab>)<tab><tab>download_info = False<tab><tab>result = False<tab>return result, download_info","if Config . get ( ""current_download"" ) == self . game . id :",191
257,"def find_id(self, doc_id):<tab>self._lock.acquire()<tab>try:<tab><tab>doc = self._docs.get(doc_id)<tab><tab><IF-STMT><tab><tab><tab>doc = copy.deepcopy(doc)<tab><tab><tab>doc[""id""] = doc_id<tab><tab><tab>return doc<tab>finally:<tab><tab>self._lock.release()",if doc :,88
258,"def assign_art(self, session, task):<tab>""""""Place the discovered art in the filesystem.""""""<tab>if task in self.art_candidates:<tab><tab>candidate = self.art_candidates.pop(task)<tab><tab>self._set_art(task.album, candidate, not self.src_removed)<tab><tab><IF-STMT><tab><tab><tab>task.prune(candidate.path)",if self . src_removed :,93
259,"def _replace_named(self, named, replace_scalar):<tab>for item in named:<tab><tab>for name, value in self._get_replaced_named(item, replace_scalar):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise DataError(""Argument names must be strings."")<tab><tab><tab>yield name, value",if not is_string ( name ) :,79
260,"def qtTypeIdent(conn, *args):<tab># We're not using the conn object at the moment, but - we will<tab># modify the<tab># logic to use the server version specific keywords later.<tab>res = None<tab>value = None<tab>for val in args:<tab><tab># DataType doesn't have len function then convert it to string<tab><tab>if not hasattr(val, ""__len__""):<tab><tab><tab>val = str(val)<tab><tab>if len(val) == 0:<tab><tab><tab>continue<tab><tab>value = val<tab><tab><IF-STMT><tab><tab><tab>value = value.replace('""', '""""')<tab><tab><tab>value = '""' + value + '""'<tab><tab>res = ((res and res + ""."") or """") + value<tab>return res","if Driver . needsQuoting ( val , True ) :",181
261,"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops):<tab>for n in tileable_graph:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>tiled_n = get_tiled(n)<tab><tab>if has_unknown_shape(tiled_n):<tab><tab><tab>if any(c.key not in chunk_result for c in tiled_n.chunks):<tab><tab><tab><tab># some of the chunks has been fused<tab><tab><tab><tab>continue<tab><tab><tab>new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result)<tab><tab><tab>for node in (n, tiled_n):<tab><tab><tab><tab>node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits))<tab><tab><tab>tiled_n._nsplits = new_nsplits",if n . op in failed_ops :,200
262,"def _read_filter(self, data):<tab>if data:<tab><tab><IF-STMT><tab><tab><tab>self.inner_sha.update(data)<tab><tab>if self.expected_inner_md5sum:<tab><tab><tab>self.inner_md5.update(data)<tab>return data",if self . expected_inner_sha256 :,76
263,"def find_previous_editable(self, *args):<tab>if self.editw == 0:<tab><tab>if self._active_page > 0:<tab><tab><tab>self.switch_page(self._active_page - 1)<tab>if not self.editw == 0:<tab><tab># remember that xrange does not return the 'last' value,<tab><tab># so go to -1, not 0! (fence post error in reverse)<tab><tab>for n in range(self.editw - 1, -1, -1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.editw = n<tab><tab><tab><tab>break",if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,161
264,"def _get_event_for_message(self, message_id):<tab>with self.event_lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Event for message[{}] should have been created before accessing"".format(<tab><tab><tab><tab><tab>message_id<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>return self._events[message_id]",if message_id not in self . _events :,97
265,"def _get_deepest(self, t):<tab>if isinstance(t, list):<tab><tab>if len(t) == 1:<tab><tab><tab>return t[0]<tab><tab>else:<tab><tab><tab>for part in t:<tab><tab><tab><tab>res = self._get_deepest(part)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return res<tab><tab><tab>return None<tab>return None",if res :,95
266,"def _get_notify(self, action_node):<tab>if action_node.name not in self._skip_notify_tasks:<tab><tab><IF-STMT><tab><tab><tab>task_notify = NotificationsHelper.to_model(action_node.notify)<tab><tab><tab>return task_notify<tab><tab>elif self._chain_notify:<tab><tab><tab>return self._chain_notify<tab>return None",if action_node . notify :,95
267,"def __init__(self, centered=None, shape_params=()):<tab>assert centered is None or isinstance(centered, (float, torch.Tensor))<tab>assert isinstance(shape_params, (tuple, list))<tab>assert all(isinstance(name, str) for name in shape_params)<tab>if is_validation_enabled():<tab><tab>if isinstance(centered, float):<tab><tab><tab>assert 0 <= centered and centered <= 1<tab><tab><IF-STMT><tab><tab><tab>assert (0 <= centered).all()<tab><tab><tab>assert (centered <= 1).all()<tab><tab>else:<tab><tab><tab>assert centered is None<tab>self.centered = centered<tab>self.shape_params = shape_params","elif isinstance ( centered , torch . Tensor ) :",163
268,"def collect(self):<tab>for nickname in self.squid_hosts.keys():<tab><tab>squid_host = self.squid_hosts[nickname]<tab><tab>fulldata = self._getData(squid_host[""host""], squid_host[""port""])<tab><tab>if fulldata is not None:<tab><tab><tab>fulldata = fulldata.splitlines()<tab><tab><tab>for data in fulldata:<tab><tab><tab><tab>matches = self.stat_pattern.match(data)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.publish_counter(<tab><tab><tab><tab><tab><tab>""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2))<tab><tab><tab><tab><tab>)",if matches :,166
269,"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab><IF-STMT><tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64MIME.base64_len(""x"" * size), bsize)",elif size <= 9 :,160
270,"def wait_for_initial_conf(self, timeout=1.0):<tab>logger.info(""Waiting for initial configuration"")<tab>cur_timeout = timeout<tab># Arbiter do not already set our have_conf param<tab>while not self.new_conf and not self.interrupted:<tab><tab>elapsed, _, _ = self.handleRequests(cur_timeout)<tab><tab>if elapsed:<tab><tab><tab>cur_timeout -= elapsed<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>cur_timeout = timeout<tab><tab>sys.stdout.write(""."")<tab><tab>sys.stdout.flush()",if cur_timeout > 0 :,142
271,"def __init__(self, querylist=None):<tab>self.query_id = -1<tab>if querylist is None:<tab><tab>self.querylist = []<tab>else:<tab><tab>self.querylist = querylist<tab><tab>for query in self.querylist:<tab><tab><tab>if self.query_id == -1:<tab><tab><tab><tab>self.query_id = query.query_id<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(""query in list must be same query_id"")",if self . query_id != query . query_id :,137
272,"def candidates() -> Generator[""Symbol"", None, None]:<tab>s = self<tab>if Symbol.debug_lookup:<tab><tab>Symbol.debug_print(""searching in self:"")<tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")<tab>while True:<tab><tab>if matchSelf:<tab><tab><tab>yield s<tab><tab><IF-STMT><tab><tab><tab>yield from s.children_recurse_anon<tab><tab>else:<tab><tab><tab>yield from s._children<tab><tab>if s.siblingAbove is None:<tab><tab><tab>break<tab><tab>s = s.siblingAbove<tab><tab>if Symbol.debug_lookup:<tab><tab><tab>Symbol.debug_print(""searching in sibling:"")<tab><tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")",if recurseInAnon :,190
273,"def get_default_params(problem_type: str, penalty: str):<tab># TODO: get seed from seeds provider<tab>if problem_type == REGRESSION:<tab><tab>default_params = {""C"": None, ""random_state"": 0, ""fit_intercept"": True}<tab><tab><IF-STMT><tab><tab><tab>default_params[""solver""] = ""auto""<tab>else:<tab><tab>default_params = {<tab><tab><tab>""C"": None,<tab><tab><tab>""random_state"": 0,<tab><tab><tab>""solver"": _get_solver(problem_type),<tab><tab><tab>""n_jobs"": -1,<tab><tab><tab>""fit_intercept"": True,<tab><tab>}<tab>model_params = list(default_params.keys())<tab>return model_params, default_params",if penalty == L2 :,187
274,"def _UploadDirectory(local_dir: str, gcs_bucket: storage.Bucket, gcs_dir: str):<tab>""""""Upload the contents of a local directory to a GCS Bucket.""""""<tab>for file_name in os.listdir(local_dir):<tab><tab>path = os.path.join(local_dir, file_name)<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Skipping %s as it's not a file."", path)<tab><tab><tab>continue<tab><tab>logging.info(""Uploading: %s"", path)<tab><tab>gcs_blob = gcs_bucket.blob(f""{gcs_dir}/{file_name}"")<tab><tab>gcs_blob.upload_from_filename(path)",if not os . path . isfile ( path ) :,173
275,"def decode_query_ids(self, trans, conditional):<tab>if conditional.operator == ""and"":<tab><tab>self.decode_query_ids(trans, conditional.left)<tab><tab>self.decode_query_ids(trans, conditional.right)<tab>else:<tab><tab>left_base = conditional.left.split(""."")[0]<tab><tab>if left_base in self.FIELDS:<tab><tab><tab>field = self.FIELDS[left_base]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>conditional.right = trans.security.decode_id(conditional.right)",if field . id_decode :,135
276,"def data_dir(self) -> Path:<tab>try:<tab><tab>from appdirs import user_data_dir<tab>except ImportError:<tab><tab># linux<tab><tab>path = Path.home() / "".local"" / ""share""<tab><tab><IF-STMT><tab><tab><tab>return path / ""dephell""<tab><tab># mac os<tab><tab>path = Path.home() / ""Library"" / ""Application Support""<tab><tab>if path.exists():<tab><tab><tab>return path / ""dephell""<tab><tab>self.pip_main([""install"", ""appdirs""])<tab><tab>from appdirs import user_data_dir<tab>return Path(user_data_dir(""dephell""))",if path . exists ( ) :,157
277,"def setGameCard(self, isGameCard=False):<tab>if isGameCard:<tab><tab>targetValue = 1<tab>else:<tab><tab>targetValue = 0<tab>for nca in self:<tab><tab>if isinstance(nca, Nca):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>Print.info(""writing isGameCard for %s, %d"" % (str(nca._path), targetValue))<tab><tab><tab>nca.header.setIsGameCard(targetValue)",if nca . header . getIsGameCard ( ) == targetValue :,132
278,"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab>if mode == ""start"":<tab><tab><tab>if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""key""<tab><tab><IF-STMT><tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab>elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","elif mode == ""key"" :",195
279,"def register_aggregate_groups(conn, *groups):<tab>seen = set()<tab>for group in groups:<tab><tab>klasses = AGGREGATE_COLLECTION[group]<tab><tab>for klass in klasses:<tab><tab><tab>name = getattr(klass, ""name"", klass.__name__)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>seen.add(name)<tab><tab><tab><tab>conn.create_aggregate(name, -1, klass)",if name not in seen :,106
280,"def _impl(inputs, input_types):<tab>data = inputs[0]<tab>axis = None<tab>keepdims = False<tab>if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False<tab><tab>if isinstance(inputs[1], int):<tab><tab><tab>axis = int(inputs[1])<tab><tab><IF-STMT><tab><tab><tab>axis = inputs[1]<tab><tab>else:<tab><tab><tab>axis = list(_infer_shape(inputs[1]))<tab><tab>keepdims = bool(inputs[2])<tab>return get_relay_op(name)(data, axis=axis, keepdims=keepdims)",elif _is_int_seq ( inputs [ 1 ] ) :,158
281,"def walks_generator():<tab>if filelist is not None:<tab><tab>bucket = []<tab><tab>for filename in filelist:<tab><tab><tab>with io.open(filename) as inf:<tab><tab><tab><tab>for line in inf:<tab><tab><tab><tab><tab>walk = [int(x) for x in line.strip(""\n"").split("" "")]<tab><tab><tab><tab><tab>bucket.append(walk)<tab><tab><tab><tab><tab>if len(bucket) == batch_size:<tab><tab><tab><tab><tab><tab>yield bucket<tab><tab><tab><tab><tab><tab>bucket = []<tab><tab><IF-STMT><tab><tab><tab>yield bucket<tab>else:<tab><tab>for _ in range(epoch):<tab><tab><tab>for nodes in graph.node_batch_iter(batch_size):<tab><tab><tab><tab>walks = graph.random_walk(nodes, walk_len)<tab><tab><tab><tab>yield walks",if len ( bucket ) :,198
282,"def _calculate_runtimes(states):<tab>results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0}<tab>for state, resultset in states.items():<tab><tab><IF-STMT><tab><tab><tab># Count the pass vs failures<tab><tab><tab>if resultset[""result""]:<tab><tab><tab><tab>results[""num_passed_states""] += 1<tab><tab><tab>else:<tab><tab><tab><tab>results[""num_failed_states""] += 1<tab><tab><tab># Count durations<tab><tab><tab>results[""runtime""] += resultset[""duration""]<tab>log.debug(""Parsed state metrics: {}"".format(results))<tab>return results","if isinstance ( resultset , dict ) and ""duration"" in resultset :",167
283,"def _replicator_primary_device() -> snt_replicator.Replicator:<tab># NOTE: The explicit device list is required since currently Replicator<tab># only considers CPU and GPU devices. This means on TPU by default we only<tab># mirror on the local CPU.<tab>for device_type in (""TPU"", ""GPU"", ""CPU""):<tab><tab>devices = tf.config.experimental.list_logical_devices(device_type=device_type)<tab><tab><IF-STMT><tab><tab><tab>devices = [d.name for d in devices]<tab><tab><tab>logging.info(""Replicating over %s"", devices)<tab><tab><tab>return snt_replicator.Replicator(devices=devices)<tab>assert False, ""No TPU/GPU or CPU found""",if devices :,180
284,"def get_tag_values(self, event):<tab>http = event.interfaces.get(""sentry.interfaces.Http"")<tab>if not http:<tab><tab>return []<tab>if not http.headers:<tab><tab>return []<tab>headers = http.headers<tab># XXX: transitional support for workers<tab>if isinstance(headers, dict):<tab><tab>headers = headers.items()<tab>output = []<tab>for key, value in headers:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ua = Parse(value)<tab><tab>if not ua:<tab><tab><tab>continue<tab><tab>result = self.get_tag_from_ua(ua)<tab><tab>if result:<tab><tab><tab>output.append(result)<tab>return output","if key != ""User-Agent"" :",176
285,"def general(metadata, value):<tab>if metadata.get(""commands"") and value:<tab><tab><IF-STMT><tab><tab><tab>v = quote(value)<tab><tab>else:<tab><tab><tab>v = value<tab><tab>return u""{0} {1}"".format(metadata[""commands""][0], v)<tab>else:<tab><tab>if not value:<tab><tab><tab>return None<tab><tab>elif not metadata.get(""nargs""):<tab><tab><tab>return quote(value)<tab><tab>else:<tab><tab><tab>return value","if not metadata . get ( ""nargs"" ) :",122
286,"def _actions_read(self, c):<tab>self.action_input.handle_read(c)<tab>if c in [curses.KEY_ENTER, util.KEY_ENTER2]:<tab><tab># take action<tab><tab>if self.action_input.selected_index == 0:  # Cancel<tab><tab><tab>self.back_to_parent()<tab><tab>elif self.action_input.selected_index == 1:  # Apply<tab><tab><tab>self._apply_prefs()<tab><tab><tab>client.core.get_config().addCallback(self._update_preferences)<tab><tab><IF-STMT>  # OK<tab><tab><tab>self._apply_prefs()<tab><tab><tab>self.back_to_parent()",elif self . action_input . selected_index == 2 :,174
287,def logic():<tab>if reset == 1:<tab><tab>lfsr.next = 1<tab>else:<tab><tab><IF-STMT><tab><tab><tab># lfsr.next[24:1] = lfsr[23:0]<tab><tab><tab>lfsr.next = lfsr << 1<tab><tab><tab>lfsr.next[0] = lfsr[23] ^ lfsr[22] ^ lfsr[21] ^ lfsr[16],if enable :,110
288,"def action_delete(self, request, attachments):<tab>deleted_attachments = []<tab>desynced_posts = []<tab>for attachment in attachments:<tab><tab><IF-STMT><tab><tab><tab>deleted_attachments.append(attachment.pk)<tab><tab><tab>desynced_posts.append(attachment.post_id)<tab>if desynced_posts:<tab><tab>with transaction.atomic():<tab><tab><tab>for post in Post.objects.filter(id__in=desynced_posts):<tab><tab><tab><tab>self.delete_from_cache(post, deleted_attachments)<tab>for attachment in attachments:<tab><tab>attachment.delete()<tab>message = _(""Selected attachments have been deleted."")<tab>messages.success(request, message)",if attachment . post :,165
289,"def __getitem__(self, index):<tab>if self._check():<tab><tab>if isinstance(index, int):<tab><tab><tab>if index < 0 or index >= len(self.features):<tab><tab><tab><tab>raise IndexError(index)<tab><tab><tab>if self.features[index] is None:<tab><tab><tab><tab>feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index)<tab><tab><tab><tab>if feature:<tab><tab><tab><tab><tab>(feature,) = _unpack(""!H"", feature[:2])<tab><tab><tab><tab><tab>self.features[index] = FEATURE[feature]<tab><tab><tab>return self.features[index]<tab><tab><IF-STMT><tab><tab><tab>indices = index.indices(len(self.features))<tab><tab><tab>return [self.__getitem__(i) for i in range(*indices)]","elif isinstance ( index , slice ) :",195
290,"def _skip_start(self):<tab>start, stop = self.start, self.stop<tab>for chunk in self.app_iter:<tab><tab>self._pos += len(chunk)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif self._pos == start:<tab><tab><tab>return b""""<tab><tab>else:<tab><tab><tab>chunk = chunk[start - self._pos :]<tab><tab><tab>if stop is not None and self._pos > stop:<tab><tab><tab><tab>chunk = chunk[: stop - self._pos]<tab><tab><tab><tab>assert len(chunk) == stop - start<tab><tab><tab>return chunk<tab>else:<tab><tab>raise StopIteration()",if self . _pos < start :,156
291,"def get_files(d):<tab>f = []<tab>for root, dirs, files in os.walk(d):<tab><tab>for name in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if ""qemux86copy-"" in root or ""qemux86-"" in root:<tab><tab><tab><tab>continue<tab><tab><tab>if ""do_build"" not in name and ""do_populate_sdk"" not in name:<tab><tab><tab><tab>f.append(os.path.join(root, name))<tab>return f","if ""meta-environment"" in root or ""cross-canadian"" in root :",143
292,"def _load_windows_store_certs(self, storename, purpose):<tab>certs = bytearray()<tab>try:<tab><tab>for cert, encoding, trust in enum_certificates(storename):<tab><tab><tab># CA certs are never PKCS#7 encoded<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if trust is True or purpose.oid in trust:<tab><tab><tab><tab><tab>certs.extend(cert)<tab>except PermissionError:<tab><tab>warnings.warn(""unable to enumerate Windows certificate store"")<tab>if certs:<tab><tab>self.load_verify_locations(cadata=certs)<tab>return certs","if encoding == ""x509_asn"" :",145
293,"def test_tokenizer_identifier_with_correct_config(self):<tab>for tokenizer_class in [BertTokenizer, BertTokenizerFast, AutoTokenizer]:<tab><tab>tokenizer = tokenizer_class.from_pretrained(""wietsedv/bert-base-dutch-cased"")<tab><tab>self.assertIsInstance(tokenizer, (BertTokenizer, BertTokenizerFast))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(tokenizer.basic_tokenizer.do_lower_case, False)<tab><tab>else:<tab><tab><tab>self.assertEqual(tokenizer.do_lower_case, False)<tab><tab>self.assertEqual(tokenizer.model_max_length, 512)","if isinstance ( tokenizer , BertTokenizer ) :",146
294,"def run(self):<tab>global WAITING_BEFORE_START<tab>time.sleep(WAITING_BEFORE_START)<tab>while self.keep_alive:<tab><tab>path_id, module, resolve = self.queue_receive.get()<tab><tab>if path_id is None:<tab><tab><tab>continue<tab><tab>self.lock.acquire()<tab><tab>self.modules[path_id] = module<tab><tab>self.lock.release()<tab><tab><IF-STMT><tab><tab><tab>resolution = self._resolve_with_other_modules(resolve)<tab><tab><tab>self._relations[path_id] = []<tab><tab><tab>for package in resolution:<tab><tab><tab><tab>self._relations[path_id].append(resolution[package])<tab><tab><tab>self.queue_send.put((path_id, module, False, resolution))",if resolve :,190
295,"def __new__(mcs, name, bases, attrs):<tab>include_profile = include_trace = include_garbage = True<tab>bases = list(bases)<tab>if name == ""SaltLoggingClass"":<tab><tab>for base in bases:<tab><tab><tab>if hasattr(base, ""trace""):<tab><tab><tab><tab>include_trace = False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>include_garbage = False<tab>if include_profile:<tab><tab>bases.append(LoggingProfileMixin)<tab>if include_trace:<tab><tab>bases.append(LoggingTraceMixin)<tab>if include_garbage:<tab><tab>bases.append(LoggingGarbageMixin)<tab>return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)","if hasattr ( base , ""garbage"" ) :",176
296,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_owner_:<tab><tab>res += prefix + (""owner: %s\n"" % self.DebugFormatString(self.owner_))<tab>cnt = 0<tab>for e in self.entries_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""entries%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>return res",if printElemNumber :,154
297,"def parse_tag(self):<tab>buf = []<tab>escaped = False<tab>for c in self.get_next_chars():<tab><tab>if escaped:<tab><tab><tab>buf.append(c)<tab><tab>elif c == ""\\"":<tab><tab><tab>escaped = True<tab><tab><IF-STMT><tab><tab><tab>return """".join(buf)<tab><tab>else:<tab><tab><tab>buf.append(c)<tab>raise Exception(""Unclosed tag "" + """".join(buf))","elif c == "">"" :",110
298,"def get_batches(train_nodes, train_labels, batch_size=64, shuffle=True):<tab>if shuffle:<tab><tab>random.shuffle(train_nodes)<tab>total = train_nodes.shape[0]<tab>for i in range(0, total, batch_size):<tab><tab><IF-STMT><tab><tab><tab>cur_nodes = train_nodes[i : i + batch_size]<tab><tab><tab>cur_labels = train_labels[cur_nodes]<tab><tab><tab>yield cur_nodes, cur_labels",if i + batch_size <= total :,127
299,"def _get_all_info_lines(data):<tab>infos = []<tab>for row in data:<tab><tab>splitrow = row.split()<tab><tab>if len(splitrow) > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>infos.append("" "".join(splitrow[1:]))<tab>return infos","if splitrow [ 0 ] == ""INFO:"" :",82
300,"def _validate_client_public_key(self, username, key_data):<tab>""""""Validate a client public key for the specified user""""""<tab>try:<tab><tab>key = decode_ssh_public_key(key_data)<tab>except KeyImportError:<tab><tab>return None<tab>options = None<tab>if self._client_keys:<tab><tab>options = self._client_keys.validate(key, self._peer_addr)<tab>if options is None:<tab><tab>result = self._owner.validate_public_key(username, key)<tab><tab>if asyncio.iscoroutine(result):<tab><tab><tab>result = yield from result<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>options = {}<tab>self._key_options = options<tab>return key",if not result :,177
301,"def attach_related_versions(addons, addon_dict=None):<tab>if addon_dict is None:<tab><tab>addon_dict = {addon.id: addon for addon in addons}<tab>all_ids = set(filter(None, (addon._current_version_id for addon in addons)))<tab>versions = list(Version.objects.filter(id__in=all_ids).order_by())<tab>for version in versions:<tab><tab>try:<tab><tab><tab>addon = addon_dict[version.addon_id]<tab><tab>except KeyError:<tab><tab><tab>log.info(""Version %s has an invalid add-on id."" % version.id)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>addon._current_version = version<tab><tab>version.addon = addon",if addon . _current_version_id == version . id :,200
302,"def move_view(obj, evt):<tab>position = obj.GetCurrentCursorPosition()<tab>for other_axis, axis_number in self._axis_names.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ipw3d = getattr(self, ""ipw_3d_%s"" % other_axis)<tab><tab>ipw3d.ipw.slice_position = position[axis_number]",if other_axis == axis_name :,104
303,"def func_wrapper(*args, **kwargs):<tab>warnings.simplefilter(""always"", DeprecationWarning)  # turn off filter<tab>for old, new in arg_mapping.items():<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>f""Keyword argument '{old}' has been ""<tab><tab><tab><tab>f""deprecated in favour of '{new}'. ""<tab><tab><tab><tab>f""'{old}' will be removed in a future version."",<tab><tab><tab><tab>category=DeprecationWarning,<tab><tab><tab><tab>stacklevel=2,<tab><tab><tab>)<tab><tab><tab>val = kwargs.pop(old)<tab><tab><tab>kwargs[new] = val<tab># reset filter<tab>warnings.simplefilter(""default"", DeprecationWarning)<tab>return func(*args, **kwargs)",if old in kwargs :,173
304,"def inner_connection_checker(self, *args, **kwargs):<tab>LOG.debug(""in _connection_checker"")<tab>for attempts in range(5):<tab><tab>try:<tab><tab><tab>return func(self, *args, **kwargs)<tab><tab>except exception.VolumeBackendAPIException as e:<tab><tab><tab>pattern = re.compile(r"".*Session id expired$"")<tab><tab><tab>matches = pattern.match(six.text_type(e))<tab><tab><tab>if matches:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>LOG.debug(""Session might have expired."" "" Trying to relogin"")<tab><tab><tab><tab><tab>self._login()<tab><tab><tab><tab><tab>continue<tab><tab><tab>LOG.error(""Re-throwing Exception %s"", e)<tab><tab><tab>raise",if attempts < 4 :,182
305,"def set(self, pcount):<tab>""""""Set channel prefetch_count setting.""""""<tab>if pcount != self.prev:<tab><tab>new_value = pcount<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""QoS: Disabled: prefetch_count exceeds %r"", PREFETCH_COUNT_MAX<tab><tab><tab>)<tab><tab><tab>new_value = 0<tab><tab>logger.debug(""basic.qos: prefetch_count->%s"", new_value)<tab><tab>self.callback(prefetch_count=new_value)<tab><tab>self.prev = pcount<tab>return pcount",if pcount > PREFETCH_COUNT_MAX :,146
306,"def _build_gcs_object_key(self, key):<tab>if self.platform_specific_separator:<tab><tab><IF-STMT><tab><tab><tab>gcs_object_key = os.path.join(<tab><tab><tab><tab>self.prefix, self._convert_key_to_filepath(key)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>gcs_object_key = self._convert_key_to_filepath(key)<tab>else:<tab><tab>if self.prefix:<tab><tab><tab>gcs_object_key = ""/"".join((self.prefix, self._convert_key_to_filepath(key)))<tab><tab>else:<tab><tab><tab>gcs_object_key = self._convert_key_to_filepath(key)<tab>return gcs_object_key",if self . prefix :,185
307,"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab><IF-STMT><tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in self.unops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)",if name not in skip :,187
308,def isCurveMonotonic(set_):<tab>for i in range(len(set_) - 1):<tab><tab># ==== added by zli =======<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab># ==== added by zli =======<tab><tab># ==== added by zli =======<tab><tab># if set_[i][1] > set_[i + 1][1]:<tab><tab>if set_[i][1] >= set_[i + 1][1]:<tab><tab><tab># ==== added by zli =======<tab><tab><tab>return False<tab>return True,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,141
309,"def show_topics():<tab>""""""prints all available miscellaneous help topics.""""""<tab>print(_stash.text_color(""Miscellaneous Topics:"", ""yellow""))<tab>for pp in PAGEPATHS:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>content = os.listdir(pp)<tab><tab>for pn in content:<tab><tab><tab>if ""."" in pn:<tab><tab><tab><tab>name = pn[: pn.index(""."")]<tab><tab><tab>else:<tab><tab><tab><tab>name = pn<tab><tab><tab>print(name)",if not os . path . isdir ( pp ) :,125
310,"def test_send_error(self):<tab>allow_transfer_encoding_codes = (205, 304)<tab>for code in (101, 102, 204, 205, 304):<tab><tab>self.con.request(""SEND_ERROR"", ""/{}"".format(code))<tab><tab>res = self.con.getresponse()<tab><tab>self.assertEqual(code, res.status)<tab><tab>self.assertEqual(None, res.getheader(""Content-Length""))<tab><tab>self.assertEqual(None, res.getheader(""Content-Type""))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(None, res.getheader(""Transfer-Encoding""))<tab><tab>data = res.read()<tab><tab>self.assertEqual(b"""", data)",if code not in allow_transfer_encoding_codes :,173
311,"def _length_hint(obj):<tab>""""""Returns the length hint of an object.""""""<tab>try:<tab><tab>return len(obj)<tab>except (AttributeError, TypeError):<tab><tab>try:<tab><tab><tab>get_hint = type(obj).__length_hint__<tab><tab>except AttributeError:<tab><tab><tab>return None<tab><tab>try:<tab><tab><tab>hint = get_hint(obj)<tab><tab>except TypeError:<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return hint","if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 :",135
312,"def _rmtree(self, path):<tab># Essentially a stripped down version of shutil.rmtree.  We can't<tab># use globals because they may be None'ed out at shutdown.<tab>for name in self._listdir(path):<tab><tab>fullname = self._path_join(path, name)<tab><tab>try:<tab><tab><tab>isdir = self._isdir(fullname)<tab><tab>except self._os_error:<tab><tab><tab>isdir = False<tab><tab><IF-STMT><tab><tab><tab>self._rmtree(fullname)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>self._remove(fullname)<tab><tab><tab>except self._os_error:<tab><tab><tab><tab>pass<tab>try:<tab><tab>self._rmdir(path)<tab>except self._os_error:<tab><tab>pass",if isdir :,183
313,"def get_sources(self, sources=None):<tab>""""""Returns all sources from this provider.""""""<tab>self._load()<tab>if sources is None:<tab><tab>sources = list(self.data.keys())<tab>elif not isinstance(sources, (list, tuple)):<tab><tab>sources = [sources]<tab>for source in sources:<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(<tab><tab><tab><tab>""Invalid data key: {}. Valid keys are: {}"".format(<tab><tab><tab><tab><tab>source, "", "".join(str(k) for k in self.data)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return {k: self.data[k] for k in sources}",if source not in self . data :,163
314,"def do_shorts(<tab>opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str]) -> Tuple[List[Tuple[str, str]], List[str]]:<tab>while optstring != """":<tab><tab>opt, optstring = optstring[0], optstring[1:]<tab><tab>if short_has_arg(opt, shortopts):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not args:<tab><tab><tab><tab><tab>raise GetoptError(""option -%s requires argument"" % opt, opt)<tab><tab><tab><tab>optstring, args = args[0], args[1:]<tab><tab><tab>optarg, optstring = optstring, """"<tab><tab>else:<tab><tab><tab>optarg = """"<tab><tab>opts.append((""-"" + opt, optarg))<tab>return opts, args","if optstring == """" :",183
315,"def _sanitize_dict(self, config_dict, allow_val_change=None, ignore_keys: set = None):<tab>sanitized = {}<tab>for k, v in six.iteritems(config_dict):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>k, v = self._sanitize(k, v, allow_val_change)<tab><tab>sanitized[k] = v<tab>return sanitized",if ignore_keys and k in ignore_keys :,104
316,def x(data):<tab>count = 0<tab>while count < 10:<tab><tab>data.start_example(SOME_LABEL)<tab><tab>b = data.draw_bits(1)<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>data.stop_example(discard=not b)<tab>data.mark_interesting(),if b :,79
317,"def prompt_for_resume(config):<tab>logger = logging.getLogger(""changeme"")<tab>logger.error(<tab><tab>""A previous scan was interrupted. Type R to resume or F to start a fresh scan""<tab>)<tab>answer = """"<tab>while not (answer == ""R"" or answer == ""F""):<tab><tab>prompt = ""(R/F)> ""<tab><tab>answer = """"<tab><tab>try:<tab><tab><tab>answer = raw_input(prompt)<tab><tab>except NameError:<tab><tab><tab>answer = input(prompt)<tab><tab>if answer.upper() == ""F"":<tab><tab><tab>logger.debug(""Forcing a fresh scan"")<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Resuming previous scan"")<tab><tab><tab>config.resume = True<tab>return config.resume","elif answer . upper ( ) == ""R"" :",189
318,"def _evaluate_local_single(self, iterator):<tab>for batch in iterator:<tab><tab>in_arrays = convert._call_converter(self.converter, batch, self.device)<tab><tab>with function.no_backprop_mode():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results = self.calc_local(*in_arrays)<tab><tab><tab>elif isinstance(in_arrays, dict):<tab><tab><tab><tab>results = self.calc_local(**in_arrays)<tab><tab><tab>else:<tab><tab><tab><tab>results = self.calc_local(in_arrays)<tab><tab>if self._progress_hook:<tab><tab><tab>self._progress_hook(batch)<tab><tab>yield results","if isinstance ( in_arrays , tuple ) :",166
319,"def _send_until_done(self, data):<tab>while True:<tab><tab>try:<tab><tab><tab>return self.connection.send(data)<tab><tab>except OpenSSL.SSL.WantWriteError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise timeout()<tab><tab><tab>continue<tab><tab>except OpenSSL.SSL.SysCallError as e:<tab><tab><tab>raise SocketError(str(e))","if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :",112
320,"def _read_jtl_chunk(self, jtl):<tab>data = jtl.read(1024 * 1024 * 10)<tab>if data:<tab><tab>parts = data.rsplit(""\n"", 1)<tab><tab><IF-STMT><tab><tab><tab>ready_chunk = self.buffer + parts[0] + ""\n""<tab><tab><tab>self.buffer = parts[1]<tab><tab><tab>df = string_to_df(ready_chunk)<tab><tab><tab>self.stat_queue.put(df)<tab><tab><tab>return df<tab><tab>else:<tab><tab><tab>self.buffer += parts[0]<tab>else:<tab><tab>if self.jmeter_finished:<tab><tab><tab>self.agg_finished = True<tab><tab>jtl.readline()<tab>return None",if len ( parts ) > 1 :,182
321,"def __new__(mcl, classname, bases, dictionary):<tab>slots = list(dictionary.get(""__slots__"", []))<tab>for getter_name in [key for key in dictionary if key.startswith(""get_"")]:<tab><tab>name = getter_name<tab><tab>slots.append(""__"" + name)<tab><tab>getter = dictionary.pop(getter_name)<tab><tab>setter = dictionary.get(setter_name, None)<tab><tab><IF-STMT><tab><tab><tab>del dictionary[setter_name]<tab><tab>dictionary[name] = property(getter.setter)<tab><tab>dictionary[""__slots__""] = tuple(slots)<tab><tab>return super().__new__(mcl, classname, bases, dictionary)","if setter is not None and isinstance ( setter , collections . Callable ) :",166
322,"def tex_coords(self):<tab>""""""Array of texture coordinate data.""""""<tab>if ""multi_tex_coords"" not in self.domain.attribute_names:<tab><tab><IF-STMT><tab><tab><tab>domain = self.domain<tab><tab><tab>attribute = domain.attribute_names[""tex_coords""]<tab><tab><tab>self._tex_coords_cache = attribute.get_region(<tab><tab><tab><tab>attribute.buffer, self.start, self.count<tab><tab><tab>)<tab><tab><tab>self._tex_coords_cache_version = domain._version<tab><tab>region = self._tex_coords_cache<tab><tab>region.invalidate()<tab><tab>return region.array<tab>else:<tab><tab>return None",if self . _tex_coords_cache_version != self . domain . _version :,173
323,"def index(self, sub, start=0):<tab>""""""Returns the index of the closing bracket""""""<tab>br = ""([{<""["")]}>"".index(sub)]<tab>count = 0<tab>for i in range(start, len(self.string)):<tab><tab>char = self.string[i]<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>elif char == sub:<tab><tab><tab>if count > 0:<tab><tab><tab><tab>count -= 1<tab><tab><tab>else:<tab><tab><tab><tab>return i<tab>err = ""Closing bracket {!r} missing in string {!r}"".format(<tab><tab>sub, """".join(self.original)<tab>)<tab>raise ParseError(err)",if char == br :,161
324,"def test_createFile(self):<tab>text = ""This is a test!""<tab>path = tempfile.mktemp()<tab>try:<tab><tab>koDoc = self._koDocFromPath(path, load=False)<tab><tab>koDoc.buffer = text<tab><tab>koDoc.save(0)<tab><tab>del koDoc<tab><tab>koDoc2 = self._koDocFromPath(path)<tab><tab>assert koDoc2.buffer == text<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(path)  # clean up",if os . path . exists ( path ) :,134
325,"def __editScopeHasEdit(self, attributeHistory):<tab>with attributeHistory.context:<tab><tab>tweak = GafferScene.EditScopeAlgo.acquireParameterEdit(<tab><tab><tab>attributeHistory.scene.node(),<tab><tab><tab>attributeHistory.context[""scene:path""],<tab><tab><tab>attributeHistory.attributeName,<tab><tab><tab>IECoreScene.ShaderNetwork.Parameter("""", self.__parameter),<tab><tab><tab>createIfNecessary=False,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>return tweak[""enabled""].getValue()",if tweak is None :,139
326,"def mail_migrator(app, schema_editor):<tab>Event_SettingsStore = app.get_model(""pretixbase"", ""Event_SettingsStore"")<tab>for ss in Event_SettingsStore.objects.filter(<tab><tab>key__in=[<tab><tab><tab>""mail_text_order_approved"",<tab><tab><tab>""mail_text_order_placed"",<tab><tab><tab>""mail_text_order_placed_require_approval"",<tab><tab>]<tab>):<tab><tab>chgd = ss.value.replace(""{date}"", ""{expire_date}"")<tab><tab><IF-STMT><tab><tab><tab>ss.value = chgd<tab><tab><tab>ss.save()<tab><tab><tab>cache.delete(""hierarkey_{}_{}"".format(""event"", ss.object_id))",if chgd != ss . value :,179
327,"def __get_limits(self):<tab>dimension = len(self.__tree.get_root().data)<tab>nodes = self.__get_all_nodes()<tab>max, min = [float(""-inf"")] * dimension, [float(""+inf"")] * dimension<tab>for node in nodes:<tab><tab>for d in range(dimension):<tab><tab><tab>if max[d] < node.data[d]:<tab><tab><tab><tab>max[d] = node.data[d]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>min[d] = node.data[d]<tab>return min, max",if min [ d ] > node . data [ d ] :,145
328,"def get_complete_position(self, context: UserContext) -> int:<tab># Check member prefix pattern.<tab>for prefix_pattern in convert2list(<tab><tab>self.get_filetype_var(context[""filetype""], ""prefix_patterns"")<tab>):<tab><tab>m = re.search(self._object_pattern + prefix_pattern + r""\w*$"", context[""input""])<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._prefix = re.sub(r""\w*$"", """", m.group(0))<tab><tab>m = re.search(r""\w*$"", context[""input""])<tab><tab>if m:<tab><tab><tab>return m.start()<tab>return -1","if m is None or prefix_pattern == """" :",166
329,"def _stderr_supports_color():<tab>try:<tab><tab>if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty():<tab><tab><tab>if curses:<tab><tab><tab><tab>curses.setupterm()<tab><tab><tab><tab>if curses.tigetnum(""colors"") > 0:<tab><tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if sys.stderr is getattr(<tab><tab><tab><tab><tab>colorama.initialise, ""wrapped_stderr"", object()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>return True<tab>except Exception:<tab><tab># Very broad exception handling because it's always better to<tab><tab># fall back to non-colored logs than to break at startup.<tab><tab>pass<tab>return False",elif colorama :,170
330,"def setLabelColumnWidth(self, panel, width):<tab>for child in panel.GetChildren():<tab><tab><IF-STMT><tab><tab><tab>size = child.GetSize()<tab><tab><tab>size[0] = width<tab><tab><tab>child.SetBestSize(size)","if isinstance ( child , wx . lib . stattext . GenStaticText ) :",74
331,"def update(self, other):<tab>if other.M is None:<tab><tab><IF-STMT><tab><tab><tab>self.items.update(other.items)<tab><tab>else:<tab><tab><tab>for i in other.items:<tab><tab><tab><tab>self.add(i)<tab><tab>return<tab>if self.M is None:<tab><tab>self.convert()<tab>self.M = array.array(""B"", list(map(max, list(zip(self.M, other.M)))))",if self . M is None :,119
332,"def on_end_epoch(self, state):<tab>if self.write_epoch_metrics:<tab><tab><IF-STMT><tab><tab><tab>self.writer.add_text(<tab><tab><tab><tab>""epoch"",<tab><tab><tab><tab>""<h4>Epoch {}</h4>"".format(state[torchbearer.EPOCH])<tab><tab><tab><tab>+ self.table_formatter(str(state[torchbearer.METRICS])),<tab><tab><tab><tab>1,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.writer.add_text(<tab><tab><tab><tab>""epoch"",<tab><tab><tab><tab>self.table_formatter(str(state[torchbearer.METRICS])),<tab><tab><tab><tab>state[torchbearer.EPOCH],<tab><tab><tab>)",if self . visdom :,174
333,"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool:<tab>""""""Check if the conversation is in need for a user message.""""""<tab>tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED)<tab>for i, e in enumerate(reversed(tracker.get(""events"", []))):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>elif e.get(""event"") == ActionExecuted.type_name:<tab><tab><tab>return e.get(""name"") == ACTION_LISTEN_NAME<tab>return False","if e . get ( ""event"" ) == UserUttered . type_name :",154
334,"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None):<tab>assert nw_id != self.nw_id_unknown<tab>ret = []<tab>for port in self.get_ports(dpid):<tab><tab>nw_id_ = port.network_id<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if nw_id_ == nw_id:<tab><tab><tab>ret.append(port.port_no)<tab><tab>elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external:<tab><tab><tab>ret.append(port.port_no)<tab>return ret",if port . port_no == in_port :,167
335,"def next_month(billing_cycle_anchor: datetime, dt: datetime) -> datetime:<tab>estimated_months = round((dt - billing_cycle_anchor).days * 12.0 / 365)<tab>for months in range(max(estimated_months - 1, 0), estimated_months + 2):<tab><tab>proposed_next_month = add_months(billing_cycle_anchor, months)<tab><tab><IF-STMT><tab><tab><tab>return proposed_next_month<tab>raise AssertionError(<tab><tab>""Something wrong in next_month calculation with ""<tab><tab>f""billing_cycle_anchor: {billing_cycle_anchor}, dt: {dt}""<tab>)",if 20 < ( proposed_next_month - dt ) . days < 40 :,165
336,"def wait_complete(self):<tab>""""""Wait for futures complete done.""""""<tab>for future in concurrent.futures.as_completed(self._futures.keys()):<tab><tab>try:<tab><tab><tab>error = future.exception()<tab><tab>except concurrent.futures.CancelledError:<tab><tab><tab>break<tab><tab>name = self._futures[future]<tab><tab><IF-STMT><tab><tab><tab>err_msg = 'Extracting ""{0}"", got: {1}'.format(name, error)<tab><tab><tab>logger.error(err_msg)",if error is not None :,124
337,"def _accept_with(cls, orm, target):<tab>if target is orm.mapper:<tab><tab>return mapperlib.Mapper<tab>elif isinstance(target, type):<tab><tab>if issubclass(target, mapperlib.Mapper):<tab><tab><tab>return target<tab><tab>else:<tab><tab><tab>mapper = _mapper_or_none(target)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return mapper<tab><tab><tab>else:<tab><tab><tab><tab>return _MapperEventsHold(target)<tab>else:<tab><tab>return target",if mapper is not None :,123
338,"def gvariant_args(args: List[Any]) -> str:<tab>""""""Convert args into gvariant.""""""<tab>gvariant = """"<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>gvariant += "" {}"".format(str(arg).lower())<tab><tab>elif isinstance(arg, (int, float)):<tab><tab><tab>gvariant += f"" {arg}""<tab><tab>elif isinstance(arg, str):<tab><tab><tab>gvariant += f' ""{arg}""'<tab><tab>else:<tab><tab><tab>gvariant += f"" {arg!s}""<tab>return gvariant.lstrip()","if isinstance ( arg , bool ) :",139
339,"def _list_cases(suite):<tab>for test in suite:<tab><tab>if isinstance(test, unittest.TestSuite):<tab><tab><tab>_list_cases(test)<tab><tab><IF-STMT><tab><tab><tab>if support.match_test(test):<tab><tab><tab><tab>print(test.id())","elif isinstance ( test , unittest . TestCase ) :",75
340,def get_and_set_all_disambiguation(self):<tab>all_disambiguations = []<tab>for page in self.pages:<tab><tab><IF-STMT><tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links_norm)<tab><tab>if page.relations.disambiguation_links is not None:<tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links)<tab>return set(all_disambiguations),if page . relations . disambiguation_links_norm is not None :,113
341,"def test_decode_invalid(self):<tab>testcases = [<tab><tab>(b""xn--w&"", ""strict"", UnicodeError()),<tab><tab>(b""xn--w&"", ""ignore"", ""xn-""),<tab>]<tab>for puny, errors, expected in testcases:<tab><tab>with self.subTest(puny=puny, errors=errors):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertRaises(UnicodeError, puny.decode, ""punycode"", errors)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(puny.decode(""punycode"", errors), expected)","if isinstance ( expected , Exception ) :",144
342,"def find_globs(walker, patterns, matches):<tab>for root, dirs, files in walker:<tab><tab>for d in dirs:<tab><tab><tab>d = join(root, d)<tab><tab><tab>for pattern in patterns:<tab><tab><tab><tab>for p in Path(d).glob(pattern):<tab><tab><tab><tab><tab>matches.add(str(p))<tab><tab>sub_files = set()<tab><tab>for p in matches:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for f in files:<tab><tab><tab><tab><tab>sub_files.add(join(root, f))<tab><tab>matches.update(sub_files)",if root . startswith ( p ) :,149
343,"def parse_stack_trace(self, it, line):<tab>""""""Iterate over lines and parse stack traces.""""""<tab>events = []<tab>stack_traces = []<tab>while self.stack_trace_re.match(line):<tab><tab>event = self.parse_stack_trace_line(line)<tab><tab><IF-STMT><tab><tab><tab>events.append(event)<tab><tab>stack_traces.append(line)<tab><tab>line = get_next(it)<tab>events.reverse()<tab>return stack_traces, events, line",if event :,123
344,"def process(self):<tab>""""""Do processing necessary, storing result in feature.""""""<tab>summation = 0  # count of all<tab>histo = self.data[""flat.notes.quarterLengthHistogram""]<tab>if not histo:<tab><tab>raise NativeFeatureException(""input lacks notes"")<tab>maxKey = 0  # max found for any one key<tab>for key in histo:<tab><tab># all defined keys should be greater than zero, but just in case<tab><tab>if histo[key] > 0:<tab><tab><tab>summation += histo[key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>maxKey = histo[key]<tab>self.feature.vector[0] = maxKey / summation",if histo [ key ] >= maxKey :,169
345,"def load_resource(name):<tab>""""""return file contents for files within the package root folder""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return sublime.load_resource(""Packages/Markdown Preview/{0}"".format(name))<tab><tab>else:<tab><tab><tab>filename = os.path.join(<tab><tab><tab><tab>sublime.packages_path(), INSTALLED_DIRECTORY, os.path.normpath(name)<tab><tab><tab>)<tab><tab><tab>return load_utf8(filename)<tab>except:<tab><tab>print(""Error while load_resource('%s')"" % name)<tab><tab>traceback.print_exc()<tab><tab>return """"",if is_ST3 ( ) :,154
346,"def get_password(self, service, repo_url):<tab>if self.is_unlocked:<tab><tab>asyncio.set_event_loop(asyncio.new_event_loop())<tab><tab>collection = secretstorage.get_default_collection(self.connection)<tab><tab>attributes = {""application"": ""Vorta"", ""service"": service, ""repo_url"": repo_url}<tab><tab>items = list(collection.search_items(attributes))<tab><tab>logger.debug(""Found %i passwords matching repo URL."", len(items))<tab><tab><IF-STMT><tab><tab><tab>return items[0].get_secret().decode(""utf-8"")<tab>return None",if len ( items ) > 0 :,156
347,"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab>if fname == ""output"":<tab><tab><tab>continue<tab><tab>if fname == ""PureMVC_Python_1_0"":<tab><tab><tab>continue<tab><tab>if fname[-4:] == "".pyc"":  # ehmm.. no.<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res",if os . path . isdir ( p ) :,162
348,"def test_nic_names(self):<tab>p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE)<tab>out = p.communicate()[0]<tab>if PY3:<tab><tab>out = str(out, sys.stdout.encoding)<tab>nics = psutil.net_io_counters(pernic=True).keys()<tab>for nic in nics:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if nic not in out:<tab><tab><tab>self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)","if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :",145
349,"def vexop_to_simop(op, extended=True, fp=True):<tab>res = operations.get(op)<tab>if res is None and extended:<tab><tab>attrs = op_attrs(op)<tab><tab><IF-STMT><tab><tab><tab>raise UnsupportedIROpError(""Operation not implemented"")<tab><tab>res = SimIROp(op, **attrs)<tab>if res is None:<tab><tab>raise UnsupportedIROpError(""Operation not implemented"")<tab>if res._float and not fp:<tab><tab>raise UnsupportedIROpError(""Floating point support disabled"")<tab>return res",if attrs is None :,141
350,"def rule_builder_add_value(self, value, screenshot_name=None):<tab>rule_builder = self.components.rule_builder<tab>rule_builder.menu_button_column.wait_for_and_click()<tab>with self.rule_builder_rule_editor(""add-column-value"") as editor_element:<tab><tab>filter_input = editor_element.find_element_by_css_selector(""input[type='text']"")<tab><tab>filter_input.clear()<tab><tab>filter_input.send_keys(value)<tab><tab><IF-STMT><tab><tab><tab>self.screenshot(screenshot_name)",if screenshot_name :,147
351,"def make_open_socket(self):<tab>s = socket.socket()<tab>try:<tab><tab>s.bind(DEFAULT_BIND_ADDR_TUPLE)<tab><tab><IF-STMT><tab><tab><tab># Windows and linux (with psutil) doesn't show as open until<tab><tab><tab># we call listen (linux with lsof accepts either)<tab><tab><tab>s.listen(1)<tab><tab>self.assert_open(s, s.fileno())<tab>except:<tab><tab>s.close()<tab><tab>s = None<tab><tab>raise<tab>return s",if WIN or greentest . LINUX :,135
352,"def handle_ray_task_error(e):<tab>for s in e.traceback_str.split(""\n"")[::-1]:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>raise getattr(builtins, s.split("":"")[0])("""".join(s.split("":"")[1:]))<tab><tab><tab>except AttributeError as att_err:<tab><tab><tab><tab>if ""module"" in str(att_err) and builtins.__name__ in str(att_err):<tab><tab><tab><tab><tab>pass<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise att_err<tab>raise e","if ""Error"" in s or ""Exception"" in s :",144
353,"def compare_multiple_events(i, expected_results, actual_results):<tab>events_in_a_row = []<tab>j = i<tab>while j < len(expected_results) and isinstance(<tab><tab>actual_results[j], actual_results[i].__class__<tab>):<tab><tab>events_in_a_row.append(actual_results[j])<tab><tab>j += 1<tab>message = """"<tab>for event in events_in_a_row:<tab><tab>for k in range(i, j):<tab><tab><tab>passed, message = compare_events(expected_results[k], event)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expected_results[k] = None<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return i, False, message<tab>return j, True, """"",if passed :,192
354,"def ListSubscriptions(self, params):<tab>queryreturn = sqlQuery(""""""SELECT label, address, enabled FROM subscriptions"""""")<tab>data = '{""subscriptions"":['<tab>for row in queryreturn:<tab><tab>label, address, enabled = row<tab><tab>label = shared.fixPotentiallyInvalidUTF8Data(label)<tab><tab><IF-STMT><tab><tab><tab>data += "",""<tab><tab>data += json.dumps(<tab><tab><tab>{<tab><tab><tab><tab>""label"": label.encode(""base64""),<tab><tab><tab><tab>""address"": address,<tab><tab><tab><tab>""enabled"": enabled == 1,<tab><tab><tab>},<tab><tab><tab>indent=4,<tab><tab><tab>separators=("","", "": ""),<tab><tab>)<tab>data += ""]}""<tab>return data",if len ( data ) > 20 :,177
355,"def compile(self, args):<tab>compiled_args = {}<tab>for key, value in six.iteritems(args):<tab><tab><IF-STMT><tab><tab><tab>compiled_args[key] = str(value)<tab><tab>else:<tab><tab><tab>compiled_args[key] = sjson_dumps(value)<tab>return self._minified_code % compiled_args",if key in self . clean_args :,91
356,"def insert(self, pack_id, data):<tab>if (pack_id not in self.queue) and pack_id > self.begin_id:<tab><tab>self.queue[pack_id] = PacketInfo(data)<tab><tab>if self.end_id == pack_id:<tab><tab><tab>self.end_id = pack_id + 1<tab><tab><IF-STMT><tab><tab><tab>eid = self.end_id<tab><tab><tab>while eid < pack_id:<tab><tab><tab><tab>self.miss_queue.add(eid)<tab><tab><tab><tab>eid += 1<tab><tab><tab>self.end_id = pack_id + 1<tab><tab>else:<tab><tab><tab>self.miss_queue.remove(pack_id)",elif self . end_id < pack_id :,182
357,"def _target_generator(self):<tab># since we do not have predictions yet, so we ignore sampling here<tab>if self._internal_target_generator is None:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>from ....model_zoo.ssd.target import SSDTargetGenerator<tab><tab>self._internal_target_generator = SSDTargetGenerator(<tab><tab><tab>iou_thresh=self._iou_thresh,<tab><tab><tab>stds=self._box_norm,<tab><tab><tab>negative_mining_ratio=-1,<tab><tab><tab>**self._kwargs<tab><tab>)<tab><tab>return self._internal_target_generator<tab>else:<tab><tab>return self._internal_target_generator",if self . _anchors_none :,166
358,"def test_heapsort(self):<tab># Exercise everything with repeated heapsort checks<tab>for trial in range(100):<tab><tab>size = random.randrange(50)<tab><tab>data = [random.randrange(25) for i in range(size)]<tab><tab><IF-STMT>  # Half of the time, use heapify<tab><tab><tab>heap = data[:]<tab><tab><tab>self.module.heapify(heap)<tab><tab>else:  # The rest of the time, use heappush<tab><tab><tab>heap = []<tab><tab><tab>for item in data:<tab><tab><tab><tab>self.module.heappush(heap, item)<tab><tab>heap_sorted = [self.module.heappop(heap) for i in range(size)]<tab><tab>self.assertEqual(heap_sorted, sorted(data))",if trial & 1 :,189
359,"def wait(self, timeout=None):<tab>if self.returncode is None:<tab><tab>if timeout is None:<tab><tab><tab>msecs = _subprocess.INFINITE<tab><tab>else:<tab><tab><tab>msecs = max(0, int(timeout * 1000 + 0.5))<tab><tab>res = _subprocess.WaitForSingleObject(int(self._handle), msecs)<tab><tab><IF-STMT><tab><tab><tab>code = _subprocess.GetExitCodeProcess(self._handle)<tab><tab><tab>if code == TERMINATE:<tab><tab><tab><tab>code = -signal.SIGTERM<tab><tab><tab>self.returncode = code<tab>return self.returncode",if res == _subprocess . WAIT_OBJECT_0 :,154
360,"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",elif value is None :,145
361,"def isnotsurplus(self, item: T) -> bool:<tab>if not self.matchers:<tab><tab><IF-STMT><tab><tab><tab>self.mismatch_description.append_text(<tab><tab><tab><tab>""not matched: ""<tab><tab><tab>).append_description_of(item)<tab><tab>return False<tab>return True",if self . mismatch_description :,80
362,"def resolve_env_secrets(config, environ):<tab>""""""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ""""""<tab>if isinstance(config, dict):<tab><tab><IF-STMT><tab><tab><tab>return environ.get(list(config.values())[0])<tab><tab>elif list(config.keys()) == [""$file""]:<tab><tab><tab>return open(list(config.values())[0]).read()<tab><tab>else:<tab><tab><tab>return {<tab><tab><tab><tab>key: resolve_env_secrets(value, environ)<tab><tab><tab><tab>for key, value in config.items()<tab><tab><tab>}<tab>elif isinstance(config, list):<tab><tab>return [resolve_env_secrets(value, environ) for value in config]<tab>else:<tab><tab>return config","if list ( config . keys ( ) ) == [ ""$env"" ] :",190
363,"def __open__(filename, *args, **kwargs):<tab>if os.path.isfile(filename):<tab><tab>return __realopen__(filename, *args, **kwargs)<tab>if not os.path.isabs(filename):<tab><tab>datafilename = __papplet__.dataPath(filename)<tab><tab><IF-STMT><tab><tab><tab>return __realopen__(datafilename, *args, **kwargs)<tab><tab>sketchfilename = __papplet__.sketchPath(filename)<tab>if os.path.isfile(sketchfilename):<tab><tab>return __realopen__(sketchfilename, *args, **kwargs)<tab># Fail naturally<tab>return __realopen__(filename, *args, **kwargs)",if os . path . isfile ( datafilename ) :,172
364,def run(self):<tab>while not self.completed:<tab><tab><IF-STMT><tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab>if self.timeout is not None:<tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab>if dt > self.timeout:<tab><tab><tab><tab>self.stop()<tab><tab>if self.counter == self.count:<tab><tab><tab>self.stop(),if self . block :,159
365,"def remove(self, path, config=None, error_on_path=False, defaults=None):<tab>if not path:<tab><tab><IF-STMT><tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>return<tab>if config is not None or defaults is not None:<tab><tab>if config is None:<tab><tab><tab>config = self._config<tab><tab>if defaults is None:<tab><tab><tab>defaults = dict(self._map.parents)<tab><tab>chain = HierarchicalChainMap(config, defaults)<tab>else:<tab><tab>chain = self._map<tab>try:<tab><tab>chain.del_by_path(path)<tab><tab>self._mark_dirty()<tab>except KeyError:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>pass",if error_on_path :,184
366,"def structured_dot_grad(sparse_A, dense_B, ga):<tab>if sparse_A.type.format in (""csc"", ""csr""):<tab><tab><IF-STMT><tab><tab><tab>sdgcsx = sdg_csc<tab><tab><tab>CSx = CSC<tab><tab>else:<tab><tab><tab>sdgcsx = sdg_csr<tab><tab><tab>CSx = CSR<tab><tab>g_A_data = sdgcsx(csm_indices(sparse_A), csm_indptr(sparse_A), dense_B, ga)<tab><tab>return CSx(<tab><tab><tab>g_A_data, csm_indices(sparse_A), csm_indptr(sparse_A), csm_shape(sparse_A)<tab><tab>)<tab>else:<tab><tab>raise NotImplementedError()","if sparse_A . type . format == ""csc"" :",180
367,"def step_async(self, actions):<tab>listify = True<tab>try:<tab><tab><IF-STMT><tab><tab><tab>listify = False<tab>except TypeError:<tab><tab>pass<tab>if not listify:<tab><tab>self.actions = actions<tab>else:<tab><tab>assert (<tab><tab><tab>self.num_envs == 1<tab><tab>), f""actions {actions} is either not a list or has a wrong size - cannot match to {self.num_envs} environments""<tab><tab>self.actions = [actions]",if len ( actions ) == self . num_envs :,130
368,"def tempFailureRetry(func, *args, **kwargs):<tab>while True:<tab><tab>try:<tab><tab><tab>return func(*args, **kwargs)<tab><tab>except (os.error, IOError) as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>raise",if ex . errno == errno . EINTR :,83
369,"def test_learning_always_changes_generation(chars, order):<tab>learner = LStar(lambda s: len(s) == 1 and s[0] in chars)<tab>for c in order:<tab><tab>prev = learner.generation<tab><tab>s = bytes([c])<tab><tab><IF-STMT><tab><tab><tab>learner.learn(s)<tab><tab><tab>assert learner.generation > prev",if learner . dfa . matches ( s ) != learner . member ( s ) :,108
370,"def test_costs_5D_noisy_names(signal_bkps_5D_noisy, cost_name):<tab>signal, bkps = signal_bkps_5D_noisy<tab>cost = cost_factory(cost_name)<tab>cost.fit(signal)<tab>cost.error(0, 100)<tab>cost.error(100, signal.shape[0])<tab>cost.error(10, 50)<tab>cost.sum_of_costs(bkps)<tab>with pytest.raises(NotEnoughPoints):<tab><tab><IF-STMT><tab><tab><tab>cost.min_size = 4<tab><tab><tab>cost.error(1, 2)<tab><tab>else:<tab><tab><tab>cost.error(1, 2)","if cost_name == ""cosine"" :",174
371,"def remove_empty_dirs(dirname):<tab>logger.debug(""remove_empty_dirs '%s'"" % (dirname))<tab>try:<tab><tab><IF-STMT><tab><tab><tab>dirname = dirname.encode(""utf-8"")<tab><tab>os.removedirs(dirname)<tab><tab>logger.debug(""remove_empty_dirs '%s' done"" % (dirname))<tab>except OSError as exc:  # Python >2.5<tab><tab>if exc.errno == errno.ENOTEMPTY:<tab><tab><tab>logger.debug(""remove_empty_dirs '%s' not empty"" % (dirname))<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise<tab>except Exception as e:<tab><tab>logger.exception(e)<tab><tab>logger.error(""remove_empty_dirs exception: "" + dirname)<tab><tab>raise e","if not isinstance ( dirname , str ) :",193
372,"def get_unique_attribute(self, name: str):<tab>feat = None<tab>for f in self.features:<tab><tab><IF-STMT><tab><tab><tab>if feat is not None:<tab><tab><tab><tab>raise RuntimeError(""The attribute was not unique."")<tab><tab><tab>feat = f<tab>if feat is None:<tab><tab>raise RuntimeError(""The attribute did not exist"")<tab>return getattr(feat, name)","if self . _return_feature ( f ) and hasattr ( f , name ) :",106
373,"def get_allocated_address(<tab>self, config: ActorPoolConfig, allocated: allocated_type) -> str:<tab>addresses = config.get_external_addresses(label=self.label)<tab>for addr in addresses:<tab><tab>occupied = False<tab><tab>for strategy, _ in allocated.get(addr, dict()).values():<tab><tab><tab>if strategy == self:<tab><tab><tab><tab>occupied = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return addr<tab>raise NoIdleSlot(<tab><tab>f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}""<tab>)",if not occupied :,146
374,"def __deepcopy__(self, memo):<tab>cls = self.__class__<tab>result = cls.__new__(cls)<tab>memo[id(self)] = result<tab>for key, value in self.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(result, key, copy.copy(value))<tab><tab>else:<tab><tab><tab>setattr(result, key, copy.deepcopy(value, memo))<tab>return result",if key in cls . dynamic_methods :,105
375,def restore_forward(model):<tab>for child in model.children():<tab><tab># leaf node<tab><tab><IF-STMT><tab><tab><tab>child.forward = child.old_forward<tab><tab><tab>child.old_forward = None<tab><tab>else:<tab><tab><tab>restore_forward(child),"if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :",82
376,"def add(self, obj, allow_duplicates=False):<tab>if allow_duplicates or obj not in self._constants:<tab><tab>self._constant_pool.append(obj)<tab><tab>self._constants[obj] = len(self)<tab><tab><IF-STMT><tab><tab><tab>self._constant_pool.append(None)","if obj . __class__ in ( Double , Long ) :",83
377,"def find_file_copyright_notices(fname):<tab>ret = set()<tab>f = open(fname)<tab>lines = f.readlines()<tab>for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines<tab><tab>idx = l.lower().find(""copyright"")<tab><tab>if idx < 0:<tab><tab><tab>continue<tab><tab>copyright = l[idx + 9 :].strip()<tab><tab>if not copyright:<tab><tab><tab>continue<tab><tab>copyright = sanitise(copyright)<tab><tab># hmm, do a quick check to see if there's a year,<tab><tab># if not, skip it<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ret.add(copyright)<tab>return ret","if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :",186
378,"def callback(lexer, match, context):<tab>text = match.group()<tab>extra = """"<tab>if start:<tab><tab>context.next_indent = len(text)<tab><tab>if context.next_indent < context.indent:<tab><tab><tab>while context.next_indent < context.indent:<tab><tab><tab><tab>context.indent = context.indent_stack.pop()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extra = text[context.indent :]<tab><tab><tab><tab>text = text[: context.indent]<tab>else:<tab><tab>context.next_indent += len(text)<tab>if text:<tab><tab>yield match.start(), TokenClass, text<tab>if extra:<tab><tab>yield match.start() + len(text), TokenClass.Error, extra<tab>context.pos = match.end()",if context . next_indent > context . indent :,196
379,"def queries(self):<tab>if DEV:<tab><tab>cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s)<tab><tab>if not cmd.check(f""docker check for {self.path.k8s}""):<tab><tab><tab>if not cmd.stdout.strip():<tab><tab><tab><tab>log_cmd = ShellCommand(<tab><tab><tab><tab><tab>""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT<tab><tab><tab><tab>)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>print(cmd.stdout)<tab><tab><tab><tab>pytest.exit(f""container failed to start for {self.path.k8s}"")<tab>return ()","if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",188
380,"def nodes(self):<tab>if not self._nodes:<tab><tab>nodes = self.cluster_group.instances()<tab><tab>self._nodes = []<tab><tab>master = self.master_node<tab><tab>nodeid = 1<tab><tab>for node in nodes:<tab><tab><tab>if node.state not in [""pending"", ""running""]:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._nodes.insert(0, master)<tab><tab><tab><tab>continue<tab><tab><tab>self._nodes.append(Node(node, self.key_location, ""node%.3d"" % nodeid))<tab><tab><tab>nodeid += 1<tab>else:<tab><tab>for node in self._nodes:<tab><tab><tab>log.debug(""refreshing instance %s"" % node.id)<tab><tab><tab>node.update()<tab>return self._nodes",if node . id == master . id :,198
381,"def match(cls, agent_name, guid, uri, media=None):<tab># Retrieve `Agent` for provided `guid`<tab>agent = Agents.get(agent_name)<tab>if agent is None:<tab><tab><IF-STMT><tab><tab><tab># First occurrence of unsupported agent<tab><tab><tab>log.warn(""Unsupported metadata agent: %s"" % agent_name)<tab><tab><tab># Mark unsupported agent as ""seen""<tab><tab><tab>unsupported_agents[agent_name] = True<tab><tab><tab>return False<tab><tab># Duplicate occurrence of unsupported agent<tab><tab>log.warn(<tab><tab><tab>""Unsupported metadata agent: %s"" % agent_name, extra={""duplicate"": True}<tab><tab>)<tab><tab>return False<tab># Fill `guid` with details from agent<tab>return agent.fill(guid, uri, media)",if agent_name not in unsupported_agents :,199
382,"def __createRandom(plug):<tab>node = plug.node()<tab>parentNode = node.ancestor(Gaffer.Node)<tab>with Gaffer.UndoScope(node.scriptNode()):<tab><tab>randomNode = Gaffer.Random()<tab><tab>parentNode.addChild(randomNode)<tab><tab>if isinstance(plug, (Gaffer.FloatPlug, Gaffer.IntPlug)):<tab><tab><tab>plug.setInput(randomNode[""outFloat""])<tab><tab><IF-STMT><tab><tab><tab>plug.setInput(randomNode[""outColor""])<tab>GafferUI.NodeEditor.acquire(randomNode)","elif isinstance ( plug , Gaffer . Color3fPlug ) :",158
383,"def post_arrow(self, arr: pa.Table, graph_type: str, opts: str = """"):<tab>dataset_id = self.dataset_id<tab>tok = self.token<tab>sub_path = f""api/v2/upload/datasets/{dataset_id}/{graph_type}/arrow""<tab>try:<tab><tab>resp = self.post_arrow_generic(sub_path, tok, arr, opts)<tab><tab>out = resp.json()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""No success indicator in server response"")<tab><tab>return out<tab>except Exception as e:<tab><tab>logger.error(""Failed to post arrow to %s"", sub_path, exc_info=True)<tab><tab>raise e","if not ( ""success"" in out ) or not out [ ""success"" ] :",179
384,"def dict_to_XML(tag, dictionary, **kwargs):<tab>""""""Return XML element converting dicts recursively.""""""<tab>elem = Element(tag, **kwargs)<tab>for key, val in dictionary.items():<tab><tab><IF-STMT><tab><tab><tab>child = dict_to_XML(""layer"", val, name=key)<tab><tab>elif isinstance(val, MutableMapping):<tab><tab><tab>child = dict_to_XML(key, val)<tab><tab>else:<tab><tab><tab>if tag == ""config"":<tab><tab><tab><tab>child = Element(""variable"", name=key)<tab><tab><tab>else:<tab><tab><tab><tab>child = Element(key)<tab><tab><tab>child.text = str(val)<tab><tab>elem.append(child)<tab>return elem","if tag == ""layers"" :",175
385,"def apply_incpaths_ml(self):<tab>inc_lst = self.includes.split()<tab>lst = self.incpaths_lst<tab>for dir in inc_lst:<tab><tab>node = self.path.find_dir(dir)<tab><tab><IF-STMT><tab><tab><tab>error(""node not found: "" + str(dir))<tab><tab><tab>continue<tab><tab>if not node in lst:<tab><tab><tab>lst.append(node)<tab><tab>self.bld_incpaths_lst.append(node)",if not node :,121
386,"def _table_reprfunc(self, row, col, val):<tab>if self._table.column_names[col].endswith(""Size""):<tab><tab>if isinstance(val, compat.string_types):<tab><tab><tab>return ""  %s"" % val<tab><tab>elif val < 1024 ** 2:<tab><tab><tab>return ""  %.1f KB"" % (val / 1024.0 ** 1)<tab><tab><IF-STMT><tab><tab><tab>return ""  %.1f MB"" % (val / 1024.0 ** 2)<tab><tab>else:<tab><tab><tab>return ""  %.1f GB"" % (val / 1024.0 ** 3)<tab>if col in (0, """"):<tab><tab>return str(val)<tab>else:<tab><tab>return ""  %s"" % val",elif val < 1024 ** 3 :,182
387,"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None):<tab>""""""cache hidden states into memory.""""""<tab>if mem_len is None or mem_len == 0:<tab><tab>return None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>curr_out = curr_out[:reuse_len]<tab><tab>if prev_mem is None:<tab><tab><tab>new_mem = curr_out[-mem_len:]<tab><tab>else:<tab><tab><tab>new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:]<tab>new_mem.stop_gradient = True<tab>return new_mem",if reuse_len is not None and reuse_len > 0 :,165
388,"def GROUP_CONCAT(builder, distinct, expr, sep=None):<tab>assert distinct in (None, True, False)<tab>result = distinct and ""GROUP_CONCAT(DISTINCT "" or ""GROUP_CONCAT("", builder(expr)<tab>if sep is not None:<tab><tab><IF-STMT><tab><tab><tab>result = result, "" SEPARATOR "", builder(sep)<tab><tab>else:<tab><tab><tab>result = result, "", "", builder(sep)<tab>return result, "")""","if builder . provider . dialect == ""MySQL"" :",117
389,"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab>self.custom_fields = []<tab>self.obj_type = ContentType.objects.get_for_model(self.model)<tab># Add all applicable CustomFields to the form<tab>custom_fields = CustomField.objects.filter(content_types=self.obj_type)<tab>for cf in custom_fields:<tab><tab># Annotate non-required custom fields as nullable<tab><tab><IF-STMT><tab><tab><tab>self.nullable_fields.append(cf.name)<tab><tab>self.fields[cf.name] = cf.to_form_field(<tab><tab><tab>set_initial=False, enforce_required=False<tab><tab>)<tab><tab># Annotate this as a custom field<tab><tab>self.custom_fields.append(cf.name)",if not cf . required :,199
390,"def is_child_of(self, item_hash, possible_child_hash):<tab>if self.get_last(item_hash) != self.get_last(possible_child_hash):<tab><tab>return None<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if possible_child_hash not in self.items:<tab><tab><tab>return False<tab><tab>possible_child_hash = self.items[possible_child_hash].previous_hash",if possible_child_hash == item_hash :,119
391,"def validate(self):<tab>self.assertEqual(len(self.inputs), len(self.outputs))<tab>for batch_in, batch_out in zip(self.inputs, self.outputs):<tab><tab>self.assertEqual(len(batch_in), len(batch_out))<tab><tab><IF-STMT><tab><tab><tab>self.validate_unordered_batch(batch_in, batch_out)<tab><tab>else:<tab><tab><tab>for in_data, out_data in zip(batch_in, batch_out):<tab><tab><tab><tab>self.assertEqual(in_data.shape, out_data.shape)<tab><tab><tab><tab>if not self.use_parallel_executor:<tab><tab><tab><tab><tab>self.assertTrue((in_data == out_data).all())",if self . use_parallel_executor and not self . use_double_buffer :,189
392,"def add_cells(self, cells):<tab>for cell in cells:<tab><tab><IF-STMT><tab><tab><tab>id = len(self.cell_id_map)<tab><tab><tab>self.cell_id_map[cell] = id<tab><tab><tab>self.id_cell_map[id] = cell",if cell not in self . cell_id_map :,80
393,"def _verify_out(marker="">>""):<tab>if shared:<tab><tab>self.assertIn(""libapp_lib.dylib"", self.client.out)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(""libapp_lib.a"", self.client.out)<tab><tab>else:  # Incremental build not the same msg<tab><tab><tab>self.assertIn(""Built target app_lib"", self.client.out)<tab>out = str(self.client.out).splitlines()<tab>for k, v in vals.items():<tab><tab>self.assertIn(""%s %s: %s"" % (marker, k, v), out)","if marker == "">>"" :",152
394,"def Visit_expr(self, node):  # pylint: disable=invalid-name<tab># expr ::= xor_expr ('|' xor_expr)*<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :",92
395,"def fill_members(self):<tab>if self._get_retrieve():<tab><tab>after = self.after.id if self.after else None<tab><tab>data = await self.get_members(self.guild.id, self.retrieve, after)<tab><tab>if not data:<tab><tab><tab># no data, terminate<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self.limit = 0  # terminate loop<tab><tab>self.after = Object(id=int(data[-1][""user""][""id""]))<tab><tab>for element in reversed(data):<tab><tab><tab>await self.members.put(self.create_member(element))",if len ( data ) < 1000 :,153
396,"def assert_warns(expected):<tab>with warnings.catch_warnings(record=True) as w:<tab><tab>warnings.simplefilter(""always"")<tab><tab>yield<tab># Python 2 does not raise warnings multiple times from the same stack<tab># frame.<tab>if sys.version_info >= (3, 0):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>exc_name = expected.__name__<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>exc_name = str(expected)<tab><tab><tab>raise AssertionError(""%s not triggerred"" % exc_name)","if not any ( isinstance ( m . message , expected ) for m in w ) :",147
397,"def __init__(self, measures):<tab>""""""Constructs a ContingencyMeasures given a NgramAssocMeasures class""""""<tab>self.__class__.__name__ = ""Contingency"" + measures.__class__.__name__<tab>for k in dir(measures):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>v = getattr(measures, k)<tab><tab>if not k.startswith(""_""):<tab><tab><tab>v = self._make_contingency_fn(measures, v)<tab><tab>setattr(self, k, v)","if k . startswith ( ""__"" ) :",116
398,"def _omit_keywords(self, context):<tab>omitted_kws = 0<tab>for event, elem in context:<tab><tab># Teardowns aren't omitted to allow checking suite teardown status.<tab><tab>omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown""<tab><tab>start = event == ""start""<tab><tab><IF-STMT><tab><tab><tab>omitted_kws += 1<tab><tab>if not omitted_kws:<tab><tab><tab>yield event, elem<tab><tab>elif not start:<tab><tab><tab>elem.clear()<tab><tab>if omit and not start:<tab><tab><tab>omitted_kws -= 1",if omit and start :,144
399,"def read_block(buffer, i):<tab>offset = i * BLOCK_LENGTH % config.CAPTURE_BUFFER<tab>while True:<tab><tab>if buffer[offset] == BLOCK_MARKER.END:<tab><tab><tab>return None<tab><tab>while buffer[offset] == BLOCK_MARKER.WRITE:<tab><tab><tab>time.sleep(SHORT_SENSOR_SLEEP_TIME)<tab><tab>buffer[offset] = BLOCK_MARKER.READ<tab><tab>buffer.seek(offset + 1)<tab><tab>length = struct.unpack(""=H"", buffer.read(2))[0]<tab><tab>retval = buffer.read(length)<tab><tab><IF-STMT><tab><tab><tab>break<tab>buffer[offset] = BLOCK_MARKER.NOP<tab>return retval",if buffer [ offset ] == BLOCK_MARKER . READ :,179
400,def _start(self):<tab>try:<tab><tab>instance_info = self._get_instance_info()<tab><tab><IF-STMT><tab><tab><tab>self._multipass_cmd.start(instance_name=self.instance_name)<tab>except errors.ProviderInfoError as instance_error:<tab><tab># Until we have proper multipass error codes to know if this<tab><tab># was a communication error we should keep this error tracking<tab><tab># and generation here.<tab><tab>raise errors.ProviderInstanceNotFoundError(<tab><tab><tab>instance_name=self.instance_name<tab><tab>) from instance_error,if not instance_info . is_running ( ) :,145
401,"def _river_driver(self):<tab>if self._cached_river_driver:<tab><tab>return self._cached_river_driver<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._cached_river_driver = MsSqlDriver(<tab><tab><tab><tab>self.workflow, self.wokflow_object_class, self.field_name<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self._cached_river_driver = OrmDriver(<tab><tab><tab><tab>self.workflow, self.wokflow_object_class, self.field_name<tab><tab><tab>)<tab><tab>return self._cached_river_driver",if app_config . IS_MSSQL :,156
402,"def __LazyMap__(self, attr):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>debug_attr_print(<tab><tab><tab><tab>""%s.__LazyMap__(%s) added something"" % (self._username_, attr)<tab><tab><tab>)<tab><tab><tab>return 1<tab>except AttributeError:<tab><tab>return 0",if self . _LazyAddAttr_ ( attr ) :,80
403,"def prepare(self, data=None, user=None):<tab>""""""Prepare activation for execution.""""""<tab>super(ManagedStartViewActivation, self).prepare.original()<tab>self.task.owner = user<tab>management_form_class = self.get_management_form_class()<tab>self.management_form = management_form_class(data=data, instance=self.task)<tab>if data:<tab><tab><IF-STMT><tab><tab><tab>raise FlowRuntimeError(<tab><tab><tab><tab>""Activation metadata is broken {}"".format(self.management_form.errors)<tab><tab><tab>)<tab><tab>self.task = self.management_form.save(commit=False)",if not self . management_form . is_valid ( ) :,160
404,"def PreprocessConditionalStatement(self, IfList, ReplacedLine):<tab>while self:<tab><tab>if self.__Token:<tab><tab><tab>x = 1<tab><tab>elif not IfList:<tab><tab><tab>if self <= 2:<tab><tab><tab><tab>continue<tab><tab><tab>RegionSizeGuid = 3<tab><tab><tab><IF-STMT><tab><tab><tab><tab>RegionLayoutLine = 5<tab><tab><tab><tab>continue<tab><tab><tab>RegionLayoutLine = self.CurrentLineNumber<tab>return 1",if not RegionSizeGuid :,111
405,"def _get_completion(self, document):<tab>try:<tab><tab>completion_header = document.xpath(""//div[@id='complete_day']"")[0]<tab><tab>completion_message = completion_header.getchildren()[0]<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>elif ""day_complete_message"" in completion_message.classes:<tab><tab><tab>return True<tab>except IndexError:<tab><tab>return False  # Who knows, probably not my diary.","if ""day_incomplete_message"" in completion_message . classes :",123
406,"def run(self):<tab>DISPATCH_SYNC = components.interfaces.nsIEventTarget.DISPATCH_SYNC<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for match in findlib2.find_all_matches(self.regex, self.text):<tab><tab><tab>if self._stopped:<tab><tab><tab><tab>return<tab><tab><tab>self.target.dispatch(lambda: self.callback(match), DISPATCH_SYNC)<tab><tab><tab>if self._stopped:<tab><tab><tab><tab>return<tab><tab>self.target.dispatch(lambda: self.callback(None), DISPATCH_SYNC)<tab>finally:<tab><tab>self.callback = None<tab><tab>self.target = None",if self . _stopped :,164
407,"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab>if isinstance(k, float):<tab><tab><tab>return unicode(float_repr(k))<tab><tab><IF-STMT><tab><tab><tab>return compose_regex(k)<tab><tab>elif isinstance(k, bool):<tab><tab><tab>return ""true"" if k else ""false""<tab><tab>elif k is None:<tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)","elif ""regex"" in literal_or_identifier :",179
408,"def process_image_pre_creation(sender, instance: Image, **kwargs):<tab># FIXME(winkidney): May have issue on determining if it<tab>#  is created or not<tab>if instance.pk is not None:<tab><tab>return<tab>for plugin in _plugin_instances:<tab><tab>process_fn = getattr(plugin, ""process_image_pre_creation"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>process_fn(<tab><tab><tab><tab>django_settings=settings,<tab><tab><tab><tab>image_instance=instance,<tab><tab><tab>)<tab><tab>except Exception:<tab><tab><tab>logging.exception(<tab><tab><tab><tab>""Error occurs while trying to access plugin's pin_pre_save ""<tab><tab><tab><tab>""for plugin %s"" % plugin<tab><tab><tab>)",if process_fn is None :,197
409,"def check_screenshots(self):<tab># If we arrive here, there have not been any failures yet<tab>if self.interactive:<tab><tab>self._commit_screenshots()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._validate_screenshots()<tab><tab><tab># Always commit the screenshots here. They can be used for the next test run.<tab><tab><tab># If reference screenshots were already present and there was a mismatch, it should<tab><tab><tab># have failed above.<tab><tab><tab>self._commit_screenshots()<tab><tab>elif self.allow_missing_screenshots:<tab><tab><tab>warnings.warn(""No committed reference screenshots available. Ignoring."")<tab><tab>else:<tab><tab><tab>self.fail(<tab><tab><tab><tab>""No committed reference screenshots available. Run interactive first.""<tab><tab><tab>)",if self . _has_reference_screenshots ( ) :,190
410,"def on_task_abort(self, task, config):<tab>if ""abort"" in config:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>log.debug(""sending abort notification"")<tab><tab>self.send_notification(<tab><tab><tab>config[""abort""][""title""],<tab><tab><tab>config[""abort""][""message""],<tab><tab><tab>config[""abort""][""via""],<tab><tab><tab>template_renderer=task.render,<tab><tab>)",if task . silent_abort :,104
411,"def block_users(self, user_ids):<tab>broken_items = []<tab>self.logger.info(""Going to block %d users."" % len(user_ids))<tab>for user_id in tqdm(user_ids):<tab><tab><IF-STMT><tab><tab><tab>self.error_delay()<tab><tab><tab>broken_items = user_ids[user_ids.index(user_id) :]<tab><tab><tab>break<tab>self.logger.info(""DONE: Total blocked %d users."" % self.total[""blocks""])<tab>return broken_items",if not self . block ( user_id ) :,135
412,"def find_widget_by_id(self, id, parent=None):<tab>""""""Recursively searches for widget with specified ID""""""<tab>if parent == None:<tab><tab>if id in self:<tab><tab><tab>return self[id]  # Do things fast if possible<tab><tab>parent = self[""editor""]<tab>for c in parent.get_children():<tab><tab>if hasattr(c, ""get_id""):<tab><tab><tab>if c.get_id() == id:<tab><tab><tab><tab>return c<tab><tab>if isinstance(c, Gtk.Container):<tab><tab><tab>r = self.find_widget_by_id(id, c)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return r<tab>return None",if not r is None :,167
413,"def addClasses(self, name):<tab># Result: void - None<tab># In: name: string<tab>for n in name.split():<tab><tab>try:<tab><tab><tab>k, method = n.split(""."")<tab><tab>except ValueError:<tab><tab><tab>k = n<tab><tab><tab>method = None<tab><tab>self.classes[k] = 1<tab><tab><IF-STMT><tab><tab><tab>self.methods.setdefault(k, {})[method] = 1",if method is not None :,109
414,"def Read(self, lex_mode):<tab>while True:<tab><tab>t = self._Read(lex_mode)<tab><tab>self.was_line_cont = t.id == Id.Ignored_LineCont<tab><tab># TODO: Change to ALL IGNORED types, once you have SPACE_TOK.  This means<tab><tab># we don't have to handle them in the VS_1/VS_2/etc. states.<tab><tab><IF-STMT><tab><tab><tab>break<tab># log('Read() Returning %s', t)<tab>return t",if t . id != Id . Ignored_LineCont :,137
415,"def _dir_guildfile(dir, ctx):<tab>from guild import guildfile<tab>try:<tab><tab>return guildfile.for_dir(dir)<tab>except guildfile.NoModels:<tab><tab><IF-STMT><tab><tab><tab>help_suffix = "" or '%s' for help"" % click_util.cmd_help(ctx)<tab><tab>else:<tab><tab><tab>help_suffix = """"<tab><tab>cli.error(<tab><tab><tab>""%s does not contain a Guild file (guild.yml)\n""<tab><tab><tab>""Try specifying a project path or package name%s.""<tab><tab><tab>% (cwd_desc(dir), help_suffix)<tab><tab>)<tab>except guildfile.GuildfileError as e:<tab><tab>cli.error(str(e))",if ctx :,186
416,"def check_response(self, response):<tab>""""""Specialized version of check_response().""""""<tab>for line in response:<tab><tab># Skip blank lines:<tab><tab>if not line.strip():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>elif line.startswith(b""Benutzer/Passwort Fehler""):<tab><tab><tab>raise BadLogin(line)<tab><tab>else:<tab><tab><tab>raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))","if line . startswith ( b""OK"" ) :",126
417,"def ParseResponses(<tab>self,<tab>knowledge_base: rdf_client.KnowledgeBase,<tab>responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]:<tab>for response in responses:<tab><tab>if not isinstance(response, rdf_client_fs.StatEntry):<tab><tab><tab>raise TypeError(f""Unexpected response type: `{type(response)}`"")<tab><tab># TODO: `st_mode` has to be an `int`, not `StatMode`.<tab><tab><IF-STMT><tab><tab><tab>homedir = response.pathspec.path<tab><tab><tab>username = os.path.basename(homedir)<tab><tab><tab>if username not in self._ignore_users:<tab><tab><tab><tab>yield rdf_client.User(username=username, homedir=homedir)",if stat . S_ISDIR ( int ( response . st_mode ) ) :,198
418,"def __call__(self, x, uttid=None):<tab>if self.utt2spk is not None:<tab><tab>spk = self.utt2spk[uttid]<tab>else:<tab><tab>spk = uttid<tab>if not self.reverse:<tab><tab><IF-STMT><tab><tab><tab>x = np.add(x, self.bias[spk])<tab><tab>if self.norm_vars:<tab><tab><tab>x = np.multiply(x, self.scale[spk])<tab>else:<tab><tab>if self.norm_vars:<tab><tab><tab>x = np.divide(x, self.scale[spk])<tab><tab>if self.norm_means:<tab><tab><tab>x = np.subtract(x, self.bias[spk])<tab>return x",if self . norm_means :,189
419,"def hasFixtures(self, ctx_callback=None):<tab>context = self.context<tab>if context is None:<tab><tab>return False<tab>if self.implementsAnyFixture(context, ctx_callback=ctx_callback):<tab><tab>return True<tab># My context doesn't have any, but its ancestors might<tab>factory = self.factory<tab>if factory:<tab><tab>ancestors = factory.context.get(self, [])<tab><tab>for ancestor in ancestors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :",137
420,def UpdateControlState(self):<tab>active = self.demoModules.GetActiveID()<tab># Update the radio/restore buttons<tab>for moduleID in self.radioButtons:<tab><tab>btn = self.radioButtons[moduleID]<tab><tab>if moduleID == active:<tab><tab><tab>btn.SetValue(True)<tab><tab>else:<tab><tab><tab>btn.SetValue(False)<tab><tab>if self.demoModules.Exists(moduleID):<tab><tab><tab>btn.Enable(True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.btnRestore.Enable(True)<tab><tab>else:<tab><tab><tab>btn.Enable(False)<tab><tab><tab>if moduleID == modModified:<tab><tab><tab><tab>self.btnRestore.Enable(False),if moduleID == modModified :,177
421,"def ignore_proxy_host(self):<tab>""""""Check if self.host is in the $no_proxy ignore list.""""""<tab>if urllib.proxy_bypass(self.host):<tab><tab>return True<tab>no_proxy = os.environ.get(""no_proxy"")<tab>if no_proxy:<tab><tab>entries = [parse_host_port(x) for x in no_proxy.split("","")]<tab><tab>for host, port in entries:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if host . lower ( ) == self . host and port == self . port :,133
422,"def run(self, _):<tab>view = self.view<tab>if not view.settings().get(""terminus_view""):<tab><tab>return<tab>terminal = Terminal.from_id(view.id())<tab>if terminal:<tab><tab>terminal.close()<tab><tab>panel_name = terminal.panel_name<tab><tab><IF-STMT><tab><tab><tab>window = panel_window(view)<tab><tab><tab>if window:<tab><tab><tab><tab>window.destroy_output_panel(panel_name)<tab><tab>else:<tab><tab><tab>view.close()",if panel_name :,128
423,"def get_docname_for_node(self, node: Node) -> str:<tab>while node:<tab><tab><IF-STMT><tab><tab><tab>return self.env.path2doc(node[""source""])<tab><tab>elif isinstance(node, addnodes.start_of_file):<tab><tab><tab>return node[""docname""]<tab><tab>else:<tab><tab><tab>node = node.parent<tab>return None  # never reached here. only for type hinting","if isinstance ( node , nodes . document ) :",110
424,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.add_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,90
425,"def _maybe_female(self, path_elements, female, strict):<tab>if female:<tab><tab>if self.has_gender_differences:<tab><tab><tab>elements = path_elements + [""female""]<tab><tab><tab>try:<tab><tab><tab><tab>return self._get_file(elements, "".png"", strict=strict)<tab><tab><tab>except ValueError:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise<tab><tab>elif strict:<tab><tab><tab>raise ValueError(""Pokemon %s has no gender differences"" % self.species_id)<tab>return self._get_file(path_elements, "".png"", strict=strict)",if strict :,146
426,"def OnKeyUp(self, event):<tab>if self._properties.modifiable:<tab><tab>if event.GetKeyCode() == wx.WXK_ESCAPE:<tab><tab><tab>self._cancel_editing()<tab><tab>elif event.GetKeyCode() == wx.WXK_RETURN:<tab><tab><tab>self._update_value()<tab><tab><IF-STMT><tab><tab><tab>self.SetValue("""")<tab>if event.GetKeyCode() != wx.WXK_RETURN:<tab><tab># Don't send skip event if enter key is pressed<tab><tab># On some platforms this event is sent too late and causes crash<tab><tab>event.Skip()",elif event . GetKeyCode ( ) == wx . WXK_DELETE :,145
427,"def sync_up_to_new_location(self, worker_ip):<tab>if worker_ip != self.worker_ip:<tab><tab>logger.debug(""Setting new worker IP to %s"", worker_ip)<tab><tab>self.set_worker_ip(worker_ip)<tab><tab>self.reset()<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""Sync up to new location skipped. This should not occur."")<tab>else:<tab><tab>logger.warning(""Sync attempted to same IP %s."", worker_ip)",if not self . sync_up ( ) :,126
428,"def _get_download_link(self, url, download_type=""torrent""):<tab>links = {<tab><tab>""torrent"": """",<tab><tab>""magnet"": """",<tab>}<tab>try:<tab><tab>data = self.session.get(url).text<tab><tab>with bs4_parser(data) as html:<tab><tab><tab>downloads = html.find(""div"", {""class"": ""download""})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for download in downloads.findAll(""a""):<tab><tab><tab><tab><tab>link = download[""href""]<tab><tab><tab><tab><tab>if link.startswith(""magnet""):<tab><tab><tab><tab><tab><tab>links[""magnet""] = link<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>links[""torrent""] = urljoin(self.urls[""base_url""], link)<tab>except Exception:<tab><tab>pass<tab>return links[download_type]",if downloads :,200
429,"def force_ipv4(self, *args):<tab>""""""only ipv4 localhost in /etc/hosts""""""<tab>logg.debug(""checking /etc/hosts for '::1 localhost'"")<tab>lines = []<tab>for line in open(self.etc_hosts()):<tab><tab>if ""::1"" in line:<tab><tab><tab>newline = re.sub(""\\slocalhost\\s"", "" "", line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip())<tab><tab><tab><tab>line = newline<tab><tab>lines.append(line)<tab>f = open(self.etc_hosts(), ""w"")<tab>for line in lines:<tab><tab>f.write(line)<tab>f.close()",if line != newline :,182
430,"def prepare(self):<tab># Maybe the brok is a old daemon one or was already prepared<tab># if so, the data is already ok<tab>if hasattr(self, ""prepared"") and not self.prepared:<tab><tab>self.data = SafeUnpickler.loads(self.data)<tab><tab><IF-STMT><tab><tab><tab>self.data[""instance_id""] = self.instance_id<tab>self.prepared = True","if hasattr ( self , ""instance_id"" ) :",104
431,"def _test_compute_q0(self):<tab># Stub code to search a logq space and figure out logq0 by eyeballing<tab># results. This code does not run with the tests. Remove underscore to run.<tab>sigma = 15<tab>order = 250<tab>logqs = np.arange(-290, -270, 1)<tab>count = 0<tab>for logq in logqs:<tab><tab>count += 1<tab><tab>sys.stdout.write(<tab><tab><tab>""\t%0.5g: %0.10g"" % (logq, pate.rdp_gaussian(logq, sigma, order))<tab><tab>)<tab><tab>sys.stdout.flush()<tab><tab><IF-STMT><tab><tab><tab>print("""")",if count % 5 == 0 :,175
432,"def valid_fieldnames(fieldnames):<tab>""""""check if fieldnames are valid""""""<tab>for fieldname in fieldnames:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif fieldname in fieldname_map and fieldname_map[fieldname] == ""source"":<tab><tab><tab>return True<tab>return False","if fieldname in canonical_field_names and fieldname == ""source"" :",81
433,"def ns_provide(self, id_):<tab>global controllers, layouts<tab>if id_ == ""_leo_viewrendered"":<tab><tab>c = self.c<tab><tab>vr = controllers.get(c.hash()) or ViewRenderedController(c)<tab><tab>h = c.hash()<tab><tab>controllers[h] = vr<tab><tab><IF-STMT><tab><tab><tab>layouts[h] = c.db.get(""viewrendered_default_layouts"", (None, None))<tab><tab># return ViewRenderedController(self.c)<tab><tab>return vr",if not layouts . get ( h ) :,143
434,"def remove(self, path, config=None, error_on_path=False, defaults=None):<tab>if not path:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>return<tab>if config is not None or defaults is not None:<tab><tab>if config is None:<tab><tab><tab>config = self._config<tab><tab><IF-STMT><tab><tab><tab>defaults = dict(self._map.parents)<tab><tab>chain = HierarchicalChainMap(config, defaults)<tab>else:<tab><tab>chain = self._map<tab>try:<tab><tab>chain.del_by_path(path)<tab><tab>self._mark_dirty()<tab>except KeyError:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>pass",if defaults is None :,184
435,"def _mongo_query_and(self, queries):<tab>if len(queries) == 1:<tab><tab>return queries[0]<tab>query = {}<tab>for q in queries:<tab><tab>for k, v in q.items():<tab><tab><tab>if k not in query:<tab><tab><tab><tab>query[k] = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab># TODO check exists of k in query, may be it should be update<tab><tab><tab><tab>query[k] = v<tab><tab><tab>else:<tab><tab><tab><tab>query[k].update(v)<tab>return query","if isinstance ( v , list ) :",141
436,"def write(self, data):<tab>self.size -= len(data)<tab>passon = None<tab>if self.size > 0:<tab><tab>self.data.append(data)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>data, passon = data[: self.size], data[self.size :]<tab><tab>else:<tab><tab><tab>passon = b""""<tab><tab>if data:<tab><tab><tab>self.data.append(data)<tab>return passon",if self . size :,114
437,"def updateVar(name, data, mode=None):<tab>if mode:<tab><tab>if mode == ""append"":<tab><tab><tab>core.config.globalVariables[name].append(data)<tab><tab><IF-STMT><tab><tab><tab>core.config.globalVariables[name].add(data)<tab>else:<tab><tab>core.config.globalVariables[name] = data","elif mode == ""add"" :",91
438,"def vi_pos_back_short(line, index=0, count=1):<tab>line = vi_list(line)<tab>try:<tab><tab>for i in range(count):<tab><tab><tab>index -= 1<tab><tab><tab>while vi_is_space(line[index]):<tab><tab><tab><tab>index -= 1<tab><tab><tab>in_word = vi_is_word(line[index])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>while vi_is_word(line[index]):<tab><tab><tab><tab><tab>index -= 1<tab><tab><tab>else:<tab><tab><tab><tab>while not vi_is_word_or_space(line[index]):<tab><tab><tab><tab><tab>index -= 1<tab><tab>return index + 1<tab>except IndexError:<tab><tab>return 0",if in_word :,179
439,"def _truncate_to_length(generator, len_map=None):<tab>for example in generator:<tab><tab>example = list(example)<tab><tab><IF-STMT><tab><tab><tab>for key, max_len in len_map.items():<tab><tab><tab><tab>example_len = example[key].shape<tab><tab><tab><tab>if example_len > max_len:<tab><tab><tab><tab><tab>example[key] = np.resize(example[key], max_len)<tab><tab>yield tuple(example)",if len_map is not None :,120
440,"def decorate(f):<tab># call-signature of f is exposed via __wrapped__.<tab># we want it to mimic Obj.__init__<tab>f.__wrapped__ = Obj.__init__<tab>f._uses_signature = Obj<tab># Supplement the docstring of f with information from Obj<tab>if Obj.__doc__:<tab><tab>doclines = Obj.__doc__.splitlines()<tab><tab><IF-STMT><tab><tab><tab>doc = f.__doc__ + ""\n"".join(doclines[1:])<tab><tab>else:<tab><tab><tab>doc = ""\n"".join(doclines)<tab><tab>try:<tab><tab><tab>f.__doc__ = doc<tab><tab>except AttributeError:<tab><tab><tab># __doc__ is not modifiable for classes in Python < 3.3<tab><tab><tab>pass<tab>return f",if f . __doc__ :,192
441,"def IncrementErrorCount(self, category):<tab>""""""Bumps the module's error statistic.""""""<tab>self.error_count += 1<tab>if self.counting in (""toplevel"", ""detailed""):<tab><tab>if self.counting != ""detailed"":<tab><tab><tab>category = category.split(""/"")[0]<tab><tab><IF-STMT><tab><tab><tab>self.errors_by_category[category] = 0<tab><tab>self.errors_by_category[category] += 1",if category not in self . errors_by_category :,115
442,"def _delete_fields(self, data):<tab>data = self._del(<tab><tab>data, [""speaker_ids"", ""track_id"", ""microlocation_id"", ""session_type_id""]<tab>)<tab># convert datetime fields<tab>for _ in [""start_time_tz"", ""end_time_tz""]:<tab><tab><IF-STMT><tab><tab><tab>data[_] = SESSION_POST[_[0:-3]].from_str(data[_])<tab><tab><tab>data[_[0:-3]] = data.pop(_)<tab>return data",if _ in data :,128
443,"def get_strings_of_set(word, char_set, threshold=20):<tab>count = 0<tab>letters = """"<tab>strings = []<tab>for char in word:<tab><tab>if char in char_set:<tab><tab><tab>letters += char<tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strings.append(letters)<tab><tab><tab>letters = """"<tab><tab><tab>count = 0<tab>if count > threshold:<tab><tab>strings.append(letters)<tab>return strings",if count > threshold :,125
444,"def _ArgumentListHasDictionaryEntry(self, token):<tab>""""""Check if the function argument list has a dictionary as an arg.""""""<tab>if _IsArgumentToFunction(token):<tab><tab>while token:<tab><tab><tab>if token.value == ""{"":<tab><tab><tab><tab>length = token.matching_bracket.total_length - token.total_length<tab><tab><tab><tab>return length + self.stack[-2].indent > self.column_limit<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if token.OpensScope():<tab><tab><tab><tab>token = token.matching_bracket<tab><tab><tab>token = token.next_token<tab>return False",if token . ClosesScope ( ) :,153
445,"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab>if mode == ""start"":<tab><tab><tab>if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""key""<tab><tab>elif mode == ""key"":<tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :",195
446,"def main(self):<tab>self.model.clear()<tab>self.callman.unregister_all()<tab>active_handle = self.get_active(""Person"")<tab>if active_handle:<tab><tab>active = self.dbstate.db.get_person_from_handle(active_handle)<tab><tab><IF-STMT><tab><tab><tab>self.callman.register_obj(active)<tab><tab><tab>self.display_citations(active)<tab><tab>else:<tab><tab><tab>self.set_has_data(False)<tab>else:<tab><tab>self.set_has_data(False)",if active :,141
447,"def _validate(self) -> None:<tab># Paren validation and such<tab>super(Tuple, self)._validate()<tab>if len(self.elements) == 0:<tab><tab><IF-STMT>  # assumes len(lpar) == len(rpar), via superclass<tab><tab><tab>raise CSTValidationError(<tab><tab><tab><tab>""A zero-length tuple must be wrapped in parentheses.""<tab><tab><tab>)",if len ( self . lpar ) == 0 :,101
448,"def _session_from_arg(self, session_obj, lock_type=None):<tab>if not isinstance(session_obj, self.ISession):<tab><tab>vm = self._machine_from_arg(session_obj)<tab><tab>lock_type = lock_type or self.LockType.null<tab><tab><IF-STMT><tab><tab><tab>return vm.create_session(lock_type)<tab><tab>return None<tab>return session_obj",if vm :,102
449,"def _decorator(cls):<tab>for name, meth in inspect.getmembers(cls, inspect.isroutine):<tab><tab>if name not in cls.__dict__:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if not private and name.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab>if name in butnot:<tab><tab><tab>continue<tab><tab>setattr(cls, name, decorator(meth))<tab>return cls","if name != ""__init__"" :",99
450,"def pdb(message=""""):<tab>""""""Fall into pdb.""""""<tab>import pdb  # Required: we have just defined pdb as a function!<tab>if app and not app.useIpython:<tab><tab># from leo.core.leoQt import QtCore<tab><tab># This is more portable.<tab><tab>try:<tab><tab><tab>import PyQt5.QtCore as QtCore<tab><tab>except ImportError:<tab><tab><tab>try:<tab><tab><tab><tab>import PyQt4.QtCore as QtCore<tab><tab><tab>except ImportError:<tab><tab><tab><tab>QtCore = None<tab><tab><IF-STMT><tab><tab><tab># pylint: disable=no-member<tab><tab><tab>QtCore.pyqtRemoveInputHook()<tab>if message:<tab><tab>print(message)<tab>pdb.set_trace()",if QtCore :,183
451,"def get_s3_bucket_locations(buckets, self_log=False):<tab>""""""return (bucket_name, prefix) for all s3 logging targets""""""<tab>for b in buckets:<tab><tab>if b.get(""Logging""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if b[""Name""] != b[""Logging""][""TargetBucket""]:<tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""])<tab><tab>if not self_log and b[""Name""].startswith(""cf-templates-""):<tab><tab><tab>yield (b[""Name""], """")",if self_log :,138
452,"def prepare_fields(self):<tab># See clean()<tab>for k, v in self.fields.items():<tab><tab>v._required = v.required<tab><tab>v.required = False<tab><tab>v.widget.is_required = False<tab><tab><IF-STMT><tab><tab><tab>v._required = v.one_required<tab><tab><tab>v.one_required = False<tab><tab><tab>v.widget.enabled_locales = self.locales","if isinstance ( v , I18nFormField ) :",110
453,"def __pack__(self):<tab>new_values = []<tab>for i in xrange(len(self.__unpacked_data_elms__)):<tab><tab>for key in self.__keys__[i]:<tab><tab><tab>new_val = getattr(self, key)<tab><tab><tab>old_val = self.__unpacked_data_elms__[i]<tab><tab><tab># In the case of Unions, when the first changed value<tab><tab><tab># is picked the loop is exited<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>new_values.append(new_val)<tab>return struct.pack(self.__format__, *new_values)",if new_val != old_val :,153
454,"def run(self):<tab>pwd_found = []<tab>if constant.user_dpapi and constant.user_dpapi.unlocked:<tab><tab>main_vault_directory = os.path.join(<tab><tab><tab>constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>for vault_directory in os.listdir(main_vault_directory):<tab><tab><tab><tab>cred = constant.user_dpapi.decrypt_vault(<tab><tab><tab><tab><tab>os.path.join(main_vault_directory, vault_directory)<tab><tab><tab><tab>)<tab><tab><tab><tab>if cred:<tab><tab><tab><tab><tab>pwd_found.append(cred)<tab>return pwd_found",if os . path . exists ( main_vault_directory ) :,197
455,"def on_revision_plugin_revision_pre_save(**kwargs):<tab>instance = kwargs[""instance""]<tab>if kwargs.get(""created"", False):<tab><tab>update_previous_revision = (<tab><tab><tab>not instance.previous_revision<tab><tab><tab>and instance.plugin<tab><tab><tab>and instance.plugin.current_revision<tab><tab><tab>and instance.plugin.current_revision != instance<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>instance.previous_revision = instance.plugin.current_revision<tab>if not instance.revision_number:<tab><tab>try:<tab><tab><tab>previous_revision = instance.plugin.revision_set.latest()<tab><tab><tab>instance.revision_number = previous_revision.revision_number + 1<tab><tab>except RevisionPluginRevision.DoesNotExist:<tab><tab><tab>instance.revision_number = 1",if update_previous_revision :,194
456,"def __setattr__(self, name, value):<tab>super().__setattr__(name, value)<tab>field = self._fields.get(name)<tab>if field:<tab><tab>self.check_field_type(field, value)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(f""cannot set immutable {name} on {self!r}"")",if name in self . __ast_frozen_fields__ :,88
457,"def _check_for_req_data(data):<tab>required_args = [""columns""]<tab>for arg in required_args:<tab><tab><IF-STMT><tab><tab><tab>return True, make_json_response(<tab><tab><tab><tab>status=400,<tab><tab><tab><tab>success=0,<tab><tab><tab><tab>errormsg=gettext(""Could not find required parameter ({})."").format(arg),<tab><tab><tab>)<tab>return False, """"","if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :",123
458,"def train_dict(self, triples):<tab>""""""Train a dict lemmatizer given training (word, pos, lemma) triples.""""""<tab># accumulate counter<tab>ctr = Counter()<tab>ctr.update([(p[0], p[1], p[2]) for p in triples])<tab># find the most frequent mappings<tab>for p, _ in ctr.most_common():<tab><tab>w, pos, l = p<tab><tab><IF-STMT><tab><tab><tab>self.composite_dict[(w, pos)] = l<tab><tab>if w not in self.word_dict:<tab><tab><tab>self.word_dict[w] = l<tab>return","if ( w , pos ) not in self . composite_dict :",158
459,"def render(type_, obj, context):<tab>if type_ == ""foreign_key"":<tab><tab>return None<tab>if type_ == ""column"":<tab><tab>if obj.name == ""y"":<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return ""col(%s)"" % obj.name<tab>if type_ == ""type"" and isinstance(obj, MySpecialType):<tab><tab>context.imports.add(""from mypackage import MySpecialType"")<tab><tab>return ""MySpecialType()""<tab>return ""render:%s"" % type_","elif obj . name == ""q"" :",144
460,"def test_knows_when_stepping_back_possible(self):<tab>iterator = bidirectional_iterator.BidirectionalIterator([0, 1, 2, 3])<tab>commands = [0, 1, 0, 0, 1, 1, 0, 0, 0, 0]<tab>command_count = 0<tab>results = []<tab>for _ in iterator:<tab><tab><IF-STMT><tab><tab><tab>iterator.step_back_on_next_iteration()<tab><tab>results.append(iterator.can_step_back())<tab><tab>command_count += 1<tab>assert results == [False, True, False, True, True, True, False, True, True, True]",if commands [ command_count ] :,157
461,"def flask_debug_true(context):<tab>if context.is_module_imported_like(""flask""):<tab><tab>if context.call_function_name_qual.endswith("".run""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return bandit.Issue(<tab><tab><tab><tab><tab>severity=bandit.HIGH,<tab><tab><tab><tab><tab>confidence=bandit.MEDIUM,<tab><tab><tab><tab><tab>text=""A Flask app appears to be run with debug=True, ""<tab><tab><tab><tab><tab>""which exposes the Werkzeug debugger and allows ""<tab><tab><tab><tab><tab>""the execution of arbitrary code."",<tab><tab><tab><tab><tab>lineno=context.get_lineno_for_call_arg(""debug""),<tab><tab><tab><tab>)","if context . check_call_arg_value ( ""debug"" , ""True"" ) :",181
462,"def __exit__(self, exc_type, exc_val, exc_tb):<tab>if self._should_meta_profile:<tab><tab>end_time = timezone.now()<tab><tab>exception_raised = exc_type is not None<tab><tab>if exception_raised:<tab><tab><tab>Logger.error(<tab><tab><tab><tab>""Exception when performing meta profiling, dumping trace below""<tab><tab><tab>)<tab><tab><tab>traceback.print_exception(exc_type, exc_val, exc_tb)<tab><tab>request = getattr(DataCollector().local, ""request"", None)<tab><tab><IF-STMT><tab><tab><tab>curr = request.meta_time or 0<tab><tab><tab>request.meta_time = curr + _time_taken(self.start_time, end_time)",if request :,176
463,"def get_job_offer(ja_list):<tab>ja_joff_map = {}<tab>offers = frappe.get_all(<tab><tab>""Job Offer"",<tab><tab>filters=[[""job_applicant"", ""IN"", ja_list]],<tab><tab>fields=[""name"", ""job_applicant"", ""status"", ""offer_date"", ""designation""],<tab>)<tab>for offer in offers:<tab><tab><IF-STMT><tab><tab><tab>ja_joff_map[offer.job_applicant] = [offer]<tab><tab>else:<tab><tab><tab>ja_joff_map[offer.job_applicant].append(offer)<tab>return ja_joff_map",if offer . job_applicant not in ja_joff_map . keys ( ) :,176
464,"def _get_deepest(self, t):<tab>if isinstance(t, list):<tab><tab><IF-STMT><tab><tab><tab>return t[0]<tab><tab>else:<tab><tab><tab>for part in t:<tab><tab><tab><tab>res = self._get_deepest(part)<tab><tab><tab><tab>if res:<tab><tab><tab><tab><tab>return res<tab><tab><tab>return None<tab>return None",if len ( t ) == 1 :,95
465,"def test_main(self):<tab>root = os.path.dirname(mutagen.__path__[0])<tab>skip = [os.path.join(root, ""docs""), os.path.join(root, ""venv"")]<tab>for dirpath, dirnames, filenames in os.walk(root):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for filename in filenames:<tab><tab><tab>if filename.endswith("".py""):<tab><tab><tab><tab>path = os.path.join(dirpath, filename)<tab><tab><tab><tab>self._check_encoding(path)",if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,146
466,"def xview(self, mode=None, value=None, units=None):<tab>if type(value) == str:<tab><tab>value = float(value)<tab>if mode is None:<tab><tab>return self.hsb.get()<tab>elif mode == ""moveto"":<tab><tab>frameWidth = self.innerframe.winfo_reqwidth()<tab><tab>self._startX = value * float(frameWidth)<tab>else:  # mode == 'scroll'<tab><tab>clipperWidth = self._clipper.winfo_width()<tab><tab><IF-STMT><tab><tab><tab>jump = int(clipperWidth * self._jfraction)<tab><tab>else:<tab><tab><tab>jump = clipperWidth<tab><tab>self._startX = self._startX + value * jump<tab>self.reposition()","if units == ""units"" :",181
467,"def test_training_script_with_max_history_set(tmpdir):<tab>train_dialogue_model(<tab><tab>DEFAULT_DOMAIN_PATH,<tab><tab>DEFAULT_STORIES_FILE,<tab><tab>tmpdir.strpath,<tab><tab>interpreter=RegexInterpreter(),<tab><tab>policy_config=""data/test_config/max_hist_config.yml"",<tab><tab>kwargs={},<tab>)<tab>agent = Agent.load(tmpdir.strpath)<tab>for policy in agent.policy_ensemble.policies:<tab><tab><IF-STMT><tab><tab><tab>if type(policy) == FormPolicy:<tab><tab><tab><tab>assert policy.featurizer.max_history == 2<tab><tab><tab>else:<tab><tab><tab><tab>assert policy.featurizer.max_history == 5","if hasattr ( policy . featurizer , ""max_history"" ) :",191
468,"def generate_auto_complete(self, base, iterable_var):<tab>sugg = []<tab>for entry in iterable_var:<tab><tab>compare_entry = entry<tab><tab>compare_base = base<tab><tab><IF-STMT><tab><tab><tab>compare_entry = compare_entry.lower()<tab><tab><tab>compare_base = compare_base.lower()<tab><tab>if self.compare_entries(compare_entry, compare_base):<tab><tab><tab>if entry not in sugg:<tab><tab><tab><tab>sugg.append(entry)<tab>return sugg",if self . settings . get ( IGNORE_CASE_SETTING ) :,137
469,"def marker_expr(remaining):<tab>if remaining and remaining[0] == ""("":<tab><tab>result, remaining = marker(remaining[1:].lstrip())<tab><tab><IF-STMT><tab><tab><tab>raise SyntaxError(""unterminated parenthesis: %s"" % remaining)<tab><tab>remaining = remaining[1:].lstrip()<tab>else:<tab><tab>lhs, remaining = marker_var(remaining)<tab><tab>while remaining:<tab><tab><tab>m = MARKER_OP.match(remaining)<tab><tab><tab>if not m:<tab><tab><tab><tab>break<tab><tab><tab>op = m.groups()[0]<tab><tab><tab>remaining = remaining[m.end() :]<tab><tab><tab>rhs, remaining = marker_var(remaining)<tab><tab><tab>lhs = {""op"": op, ""lhs"": lhs, ""rhs"": rhs}<tab><tab>result = lhs<tab>return result, remaining","if remaining [ 0 ] != "")"" :",196
470,"def __repr__(self):<tab>""""""Dump the class data in the format of a .netrc file.""""""<tab>rep = """"<tab>for host in self.hosts.keys():<tab><tab>attrs = self.hosts[host]<tab><tab>rep = rep + ""machine "" + host + ""\n\tlogin "" + repr(attrs[0]) + ""\n""<tab><tab><IF-STMT><tab><tab><tab>rep = rep + ""account "" + repr(attrs[1])<tab><tab>rep = rep + ""\tpassword "" + repr(attrs[2]) + ""\n""<tab>for macro in self.macros.keys():<tab><tab>rep = rep + ""macdef "" + macro + ""\n""<tab><tab>for line in self.macros[macro]:<tab><tab><tab>rep = rep + line<tab><tab>rep = rep + ""\n""<tab>return rep",if attrs [ 1 ] :,192
471,"def _parse_policies(self, policies_yaml):<tab>for item in policies_yaml:<tab><tab>id_ = required_key(item, ""id"")<tab><tab>controls_ids = required_key(item, ""controls"")<tab><tab><IF-STMT><tab><tab><tab>if controls_ids != ""all"":<tab><tab><tab><tab>msg = ""Policy {id_} contains invalid controls list {controls}."".format(<tab><tab><tab><tab><tab>id_=id_, controls=str(controls_ids)<tab><tab><tab><tab>)<tab><tab><tab><tab>raise ValueError(msg)<tab><tab>self.policies[id_] = controls_ids","if not isinstance ( controls_ids , list ) :",155
472,"def __set__(self, obj, value):  # noqa<tab>if (<tab><tab>value is not None<tab><tab>and self.field._currency_field.null<tab><tab>and not isinstance(value, MONEY_CLASSES + (Decimal,))<tab>):<tab><tab># For nullable fields we need either both NULL amount and currency or both NOT NULL<tab><tab>raise ValueError(""Missing currency value"")<tab>if isinstance(value, BaseExpression):<tab><tab><IF-STMT><tab><tab><tab>value = self.prepare_value(obj, value.value)<tab><tab>elif not isinstance(value, Func):<tab><tab><tab>validate_money_expression(obj, value)<tab><tab><tab>prepare_expression(value)<tab>else:<tab><tab>value = self.prepare_value(obj, value)<tab>obj.__dict__[self.field.name] = value","if isinstance ( value , Value ) :",193
473,"def Children(self):<tab>""""""Returns a list of all of this object's owned (strong) children.""""""<tab>children = []<tab>for property, attributes in self._schema.iteritems():<tab><tab>(is_list, property_type, is_strong) = attributes[0:3]<tab><tab><IF-STMT><tab><tab><tab>if not is_list:<tab><tab><tab><tab>children.append(self._properties[property])<tab><tab><tab>else:<tab><tab><tab><tab>children.extend(self._properties[property])<tab>return children",if is_strong and property in self . _properties :,130
474,"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab>if i == start:<tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab>if i >= len(self.items):<tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab>if self.select(i):<tab><tab><tab>break<tab><tab>i += direction<tab><tab><IF-STMT><tab><tab><tab>start = 0",if start < 0 :,194
475,"def setup_displace(self):<tab>self.displace_mod = None<tab>self.displace_strength = 0.020<tab>for mod in self.obj.modifiers:<tab><tab><IF-STMT><tab><tab><tab>self.displace_mod = mod<tab><tab><tab>self.displace_strength = mod.strength<tab>if not self.displace_mod:<tab><tab>bpy.ops.object.modifier_add(type=""DISPLACE"")<tab><tab>self.displace_mod = self.obj.modifiers[-1]<tab><tab>self.displace_mod.show_expanded = False<tab><tab>self.displace_mod.strength = self.displace_strength<tab><tab>self.displace_mod.show_render = False<tab><tab>self.displace_mod.show_viewport = False","if mod . type == ""DISPLACE"" :",195
476,"def set_json_body(cls, request_builder):<tab>old_body = request_builder.info.pop(""data"", {})<tab>if isinstance(old_body, abc.Mapping):<tab><tab>body = request_builder.info.setdefault(""json"", {})<tab><tab>for path in old_body:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls._sequence_path_resolver(path, old_body[path], body)<tab><tab><tab>else:<tab><tab><tab><tab>body[path] = old_body[path]<tab>else:<tab><tab>request_builder.info.setdefault(""json"", old_body)","if isinstance ( path , tuple ) :",147
477,"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""DBLL"")<tab>version = None<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,181
478,"def test_prefix_lm(self):<tab>num_tries = 100<tab>original = ""This is a long test with lots of words to see if it works ok.""<tab>dataset = tf.data.Dataset.from_tensor_slices({""text"": [original] * num_tries})<tab>dataset = prep.prefix_lm(dataset)<tab>for data in test_utils.dataset_as_text(dataset):<tab><tab>inputs = data[""inputs""].replace(""prefix: "", """")<tab><tab>targets = data[""targets""]<tab><tab>reconstructed = """".join(inputs)<tab><tab><IF-STMT><tab><tab><tab>reconstructed += "" ""<tab><tab>reconstructed += """".join(targets)<tab><tab>self.assertEqual(reconstructed, original)",if inputs :,162
479,"def leading_whitespace(self, inputstring):<tab>""""""Get leading whitespace.""""""<tab>leading_ws = []<tab>for i, c in enumerate(inputstring):<tab><tab>if c in legal_indent_chars:<tab><tab><tab>leading_ws.append(c)<tab><tab>else:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>self.indchar = c<tab><tab>elif c != self.indchar:<tab><tab><tab>self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i)<tab>return """".join(leading_ws)",if self . indchar is None :,139
480,"def __init__(self, text):<tab>self.mappings = {}<tab>self.attributes = collections.defaultdict(set)<tab>for stanza in _ParseTextProperties(text):<tab><tab>processor_id, single_values, multiple_values = self._ParseStanza(stanza)<tab><tab>if processor_id is None:  # can be 0<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>logging.warn(""Processor id %s seen twice in %s"", processor_id, text)<tab><tab><tab>continue<tab><tab>self.mappings[processor_id] = single_values<tab><tab>for key, value in multiple_values.items():<tab><tab><tab>self.attributes[key].add(value)",if processor_id in self . mappings :,172
481,"def __iter__(self):<tab>for chunk in self.source:<tab><tab><IF-STMT><tab><tab><tab>self.wait_counter = 0<tab><tab><tab>yield chunk<tab><tab>elif self.wait_counter < self.wait_cntr_max:<tab><tab><tab>self.wait_counter += 1<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Data poller has been receiving no data for {} seconds.\n""<tab><tab><tab><tab>""Closing data poller"".format(self.wait_cntr_max * self.poll_period)<tab><tab><tab>)<tab><tab><tab>break<tab><tab>time.sleep(self.poll_period)",if chunk is not None :,156
482,"def download(self, prefetch=False):<tab>while self.running:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>(path, start, end) = self.prefetch_queue.get(<tab><tab><tab><tab><tab>True, 1<tab><tab><tab><tab>)  # 1 second time-out<tab><tab><tab>else:<tab><tab><tab><tab>(path, start, end) = self.download_queue.get(<tab><tab><tab><tab><tab>True, 1<tab><tab><tab><tab>)  # 1 second time-out<tab><tab><tab>self.download_data(path, start, end)<tab><tab><tab>if prefetch:<tab><tab><tab><tab>self.prefetch_queue.task_done()<tab><tab><tab>else:<tab><tab><tab><tab>self.download_queue.task_done()<tab><tab>except Queue.Empty:<tab><tab><tab>pass",if prefetch :,193
483,"def process_messages(self, found_files, messages):<tab>for message in messages:<tab><tab><IF-STMT><tab><tab><tab>message.to_absolute_path(self.config.workdir)<tab><tab>else:<tab><tab><tab>message.to_relative_path(self.config.workdir)<tab>if self.config.blending:<tab><tab>messages = blender.blend(messages)<tab>filepaths = found_files.iter_module_paths(abspath=False)<tab>return postfilter.filter_messages(filepaths, self.config.workdir, messages)",if self . config . absolute_paths :,139
484,"def set_indentation_params(self, ispythonsource, guess=1):<tab>if guess and ispythonsource:<tab><tab>i = self.guess_indent()<tab><tab><IF-STMT><tab><tab><tab>self.indentwidth = i<tab><tab>if self.indentwidth != self.tabwidth:<tab><tab><tab>self.usetabs = 0<tab>self.editwin.set_tabwidth(self.tabwidth)",if 2 <= i <= 8 :,100
485,"def to_tree(self, tagname=None, value=None, namespace=None):<tab>namespace = getattr(self, ""namespace"", namespace)<tab>if value is not None:<tab><tab><IF-STMT><tab><tab><tab>tagname = ""{%s}%s"" % (namespace, tagname)<tab><tab>el = Element(tagname)<tab><tab>el.text = safe_string(value)<tab><tab>return el",if namespace is not None :,96
486,"def execute(self, argv: List) -> bool:<tab>if not argv:<tab><tab>print(""ERROR: You must give at least one module to download."")<tab><tab>return False<tab>for _arg in argv:<tab><tab>result = module_server.search_module(_arg)<tab><tab>CacheUpdater(""hub_download"", _arg).start()<tab><tab><IF-STMT><tab><tab><tab>url = result[0][""url""]<tab><tab><tab>with log.ProgressBar(""Download {}"".format(url)) as bar:<tab><tab><tab><tab>for file, ds, ts in utils.download_with_progress(url):<tab><tab><tab><tab><tab>bar.update(float(ds) / ts)<tab><tab>else:<tab><tab><tab>print(""ERROR: Could not find a HubModule named {}"".format(_arg))<tab>return True",if result :,185
487,"def visit_type_type(self, t: TypeType) -> ProperType:<tab>if isinstance(self.s, TypeType):<tab><tab>typ = self.meet(t.item, self.s.item)<tab><tab><IF-STMT><tab><tab><tab>typ = TypeType.make_normalized(typ, line=t.line)<tab><tab>return typ<tab>elif isinstance(self.s, Instance) and self.s.type.fullname == ""builtins.type"":<tab><tab>return t<tab>elif isinstance(self.s, CallableType):<tab><tab>return self.meet(t, self.s)<tab>else:<tab><tab>return self.default(self.s)","if not isinstance ( typ , NoneType ) :",154
488,"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>items.append(item.name())<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",if len ( items ) > 1 :,113
489,"def get_icon(self):<tab>if self.icon is not None:<tab><tab># Load it from an absolute filename<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24)<tab><tab><tab>except GObject.GError as ge:<tab><tab><tab><tab>pass<tab><tab># Load it from the current icon theme<tab><tab>(icon_name, extension) = os.path.splitext(os.path.basename(self.icon))<tab><tab>theme = Gtk.IconTheme()<tab><tab>if theme.has_icon(icon_name):<tab><tab><tab>return theme.load_icon(icon_name, 24, 0)",if os . path . exists ( self . icon ) :,174
490,"def setup_logger():<tab>""""""Set up logger and add stdout handler""""""<tab>logging.setLoggerClass(IPDLogger)<tab>logger = logging.getLogger(""icloudpd"")<tab>has_stdout_handler = False<tab>for handler in logger.handlers:<tab><tab><IF-STMT><tab><tab><tab>has_stdout_handler = True<tab>if not has_stdout_handler:<tab><tab>formatter = logging.Formatter(<tab><tab><tab>fmt=""%(asctime)s %(levelname)-8s %(message)s"", datefmt=""%Y-%m-%d %H:%M:%S""<tab><tab>)<tab><tab>stdout_handler = logging.StreamHandler(stream=sys.stdout)<tab><tab>stdout_handler.setFormatter(formatter)<tab><tab>stdout_handler.name = ""stdoutLogger""<tab><tab>logger.addHandler(stdout_handler)<tab>return logger","if handler . name == ""stdoutLogger"" :",195
491,"def process_extra_fields(self):<tab>if self.instance.pk is not None:<tab><tab>if self.cleaned_data.get(""initialize"", None):<tab><tab><tab>self.instance.initialize()<tab><tab><IF-STMT><tab><tab><tab>self.instance.update_from_templates()","if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :",88
492,"def testFunctions(self):<tab>from zim.formats.wiki import match_url, is_url<tab>for input, input_is_url, tail in self.examples:<tab><tab>if input_is_url:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(match_url(input), input[: -len(tail)])<tab><tab><tab><tab>self.assertFalse(is_url(input))<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(match_url(input), input)<tab><tab><tab><tab>self.assertTrue(is_url(input))<tab><tab>else:<tab><tab><tab>self.assertEqual(match_url(input), None)<tab><tab><tab>self.assertFalse(is_url(input))",if tail :,168
493,"def _SetUser(self, users):<tab>for user in users.items():<tab><tab>username = user[0]<tab><tab>settings = user[1]<tab><tab>room = settings[""room""][""name""] if ""room"" in settings else None<tab><tab>file_ = settings[""file""] if ""file"" in settings else None<tab><tab><IF-STMT><tab><tab><tab>if ""joined"" in settings[""event""]:<tab><tab><tab><tab>self._client.userlist.addUser(username, room, file_)<tab><tab><tab>elif ""left"" in settings[""event""]:<tab><tab><tab><tab>self._client.removeUser(username)<tab><tab>else:<tab><tab><tab>self._client.userlist.modUser(username, room, file_)","if ""event"" in settings :",170
494,"def restoreTerminals(self, state):<tab>for name in list(self.terminals.keys()):<tab><tab><IF-STMT><tab><tab><tab>self.removeTerminal(name)<tab>for name, opts in state.items():<tab><tab>if name in self.terminals:<tab><tab><tab>term = self[name]<tab><tab><tab>term.setOpts(**opts)<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>opts = strDict(opts)<tab><tab><tab>self.addTerminal(name, **opts)<tab><tab>except:<tab><tab><tab>printExc(""Error restoring terminal %s (%s):"" % (str(name), str(opts)))",if name not in state :,150
495,"def htmlify(path, text):<tab>fname = os.path.basename(path)<tab>if any((fnmatch.fnmatchcase(fname, p) for p in _patterns)):<tab><tab># Get file_id, skip if not in database<tab><tab>sql = ""SELECT files.id FROM files WHERE path = ? LIMIT 1""<tab><tab>row = _conn.execute(sql, (path,)).fetchone()<tab><tab><IF-STMT><tab><tab><tab>return ClangHtmlifier(_tree, _conn, path, text, row[0])<tab>return None",if row :,127
496,"def autoformat_filter_conv2d(fsize, in_depth, out_depth):<tab>if isinstance(fsize, int):<tab><tab>return [fsize, fsize, in_depth, out_depth]<tab>elif isinstance(fsize, (tuple, list, tf.TensorShape)):<tab><tab><IF-STMT><tab><tab><tab>return [fsize[0], fsize[1], in_depth, out_depth]<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""filter length error: ""<tab><tab><tab><tab>+ str(len(fsize))<tab><tab><tab><tab>+ "", only a length of 2 is supported.""<tab><tab><tab>)<tab>else:<tab><tab>raise Exception(""filter format error: "" + str(type(fsize)))",if len ( fsize ) == 2 :,172
497,"def _rle_encode(string):<tab>new = b""""<tab>count = 0<tab>for cur in string:<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab>if count:<tab><tab><tab><tab>new += b""\0"" + bytes([count])<tab><tab><tab><tab>count = 0<tab><tab><tab>new += bytes([cur])<tab>return new",if not cur :,92
498,"def is_clean(self):<tab>acceptable_statuses = {""external"", ""unversioned""}<tab>root = self._capture_output(""status"", ""--quiet"")<tab>for elem in root.findall(""./target/entry""):<tab><tab>status = elem.find(""./wc-status"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>log.debug(""Path %s is %s"", elem.get(""path""), status.get(""item""))<tab><tab>return False<tab>return True","if status . get ( ""item"" , None ) in acceptable_statuses :",119
499,"def process(self, body, message):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>'Received an unexpected type ""%s"" for payload.' % type(body)<tab><tab><tab>)<tab><tab>response = self._handler.pre_ack_process(body)<tab><tab>self._dispatcher.dispatch(self._process_message, response)<tab>except:<tab><tab>LOG.exception(""%s failed to process message: %s"", self.__class__.__name__, body)<tab>finally:<tab><tab># At this point we will always ack a message.<tab><tab>message.ack()","if not isinstance ( body , self . _handler . message_type ) :",152
500,"def page_file(self, page):<tab>try:<tab><tab>page = self.notebook.get_page(page)<tab><tab><IF-STMT><tab><tab><tab>return page.source<tab><tab>else:<tab><tab><tab>return None<tab>except PageNotFoundError:<tab><tab>return None","if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :",79
501,"def _optimize(self, solutions):<tab>best_a = None<tab>best_silhouette = None<tab>best_k = None<tab>for a, silhouette, k in solutions():<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif silhouette <= best_silhouette:<tab><tab><tab>break<tab><tab>best_silhouette = silhouette<tab><tab>best_a = a<tab><tab>best_k = k<tab>return best_a, best_silhouette, best_k",if best_silhouette is None :,109
502,"def _cancel_tasks_for_partitions(self, to_cancel_partitions):<tab># type: (Iterable[str]) -> None<tab>with self._lock:<tab><tab>_LOGGER.debug(<tab><tab><tab>""EventProcessor %r tries to cancel partitions %r"",<tab><tab><tab>self._id,<tab><tab><tab>to_cancel_partitions,<tab><tab>)<tab><tab>for partition_id in to_cancel_partitions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._consumers[partition_id].stop = True<tab><tab><tab><tab>_LOGGER.info(<tab><tab><tab><tab><tab>""EventProcessor %r has cancelled partition %r"",<tab><tab><tab><tab><tab>self._id,<tab><tab><tab><tab><tab>partition_id,<tab><tab><tab><tab>)",if partition_id in self . _consumers :,184
503,"def get_intersect_all(self, refine=False):<tab>result = None<tab>for source, parts in self._per_source.items():<tab><tab><IF-STMT><tab><tab><tab>result = parts<tab><tab>else:<tab><tab><tab>result.intersection_update(parts)<tab>if not result:<tab><tab>return None<tab>elif len(result) == 1:<tab><tab>return list(result)[0].item<tab>else:<tab><tab>solids = [p.item for p in result]<tab><tab>solid = solids[0].fuse(solids[1:])<tab><tab>if refine:<tab><tab><tab>solid = solid.removeSplitter()<tab><tab>return solid",if result is None :,159
504,"def geli_detach(self, pool, clear=False):<tab>failed = 0<tab>for ed in self.middleware.call_sync(<tab><tab>""datastore.query"",<tab><tab>""storage.encrypteddisk"",<tab><tab>[(""encrypted_volume"", ""="", pool[""id""])],<tab>):<tab><tab>dev = ed[""encrypted_provider""]<tab><tab>try:<tab><tab><tab>self.geli_detach_single(dev)<tab><tab>except Exception as ee:<tab><tab><tab>self.logger.warn(str(ee))<tab><tab><tab>failed += 1<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.geli_clear(dev)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>self.logger.warn(""Failed to clear %s: %s"", dev, e)<tab>return failed",if clear :,191
505,def compute_lengths(batch_sizes):<tab>tmp_batch_sizes = np.copy(batch_sizes)<tab>lengths = []<tab>while True:<tab><tab>c = np.count_nonzero(tmp_batch_sizes > 0)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>lengths.append(c)<tab><tab>tmp_batch_sizes = np.array([b - 1 for b in tmp_batch_sizes])<tab>return np.array(lengths),if c == 0 :,111
506,"def _render_raw_list(bytes_items):<tab>flatten_items = []<tab>for item in bytes_items:<tab><tab><IF-STMT><tab><tab><tab>flatten_items.append(b"""")<tab><tab>elif isinstance(item, bytes):<tab><tab><tab>flatten_items.append(item)<tab><tab>elif isinstance(item, int):<tab><tab><tab>flatten_items.append(str(item).encode())<tab><tab>elif isinstance(item, list):<tab><tab><tab>flatten_items.append(_render_raw_list(item))<tab>return b""\n"".join(flatten_items)",if item is None :,138
507,"def update(self, new_config):<tab>jsonschema.validate(new_config, self.schema)<tab>config = {}<tab>for k, v in new_config.items():<tab><tab><IF-STMT><tab><tab><tab>config[k] = self[k]<tab><tab>else:<tab><tab><tab>config[k] = v<tab>self._config = config<tab>self.changed()","if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :",108
508,"def _encode_numpy(values, uniques=None, encode=False, check_unknown=True):<tab># only used in _encode below, see docstring there for details<tab>if uniques is None:<tab><tab>if encode:<tab><tab><tab>uniques, encoded = np.unique(values, return_inverse=True)<tab><tab><tab>return uniques, encoded<tab><tab>else:<tab><tab><tab># unique sorts<tab><tab><tab>return np.unique(values)<tab>if encode:<tab><tab><IF-STMT><tab><tab><tab>diff = _encode_check_unknown(values, uniques)<tab><tab><tab>if diff:<tab><tab><tab><tab>raise ValueError(""y contains previously unseen labels: %s"" % str(diff))<tab><tab>encoded = np.searchsorted(uniques, values)<tab><tab>return uniques, encoded<tab>else:<tab><tab>return uniques",if check_unknown :,190
509,"def restore_dtype_and_merge(arr, input_dtype):<tab>if isinstance(arr, list):<tab><tab>arr = [restore_dtype_and_merge(arr_i, input_dtype) for arr_i in arr]<tab><tab>shapes = [arr_i.shape for arr_i in arr]<tab><tab><IF-STMT><tab><tab><tab>arr = np.array(arr)<tab>if ia.is_np_array(arr):<tab><tab>arr = iadt.restore_dtypes_(arr, input_dtype)<tab>return arr",if len ( set ( shapes ) ) == 1 :,131
510,"def proc_minute(d):<tab>if expanded[0][0] != ""*"":<tab><tab>diff_min = nearest_diff_method(d.minute, expanded[0], 60)<tab><tab>if diff_min is not None and diff_min != 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=59)<tab><tab><tab>else:<tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=0)<tab><tab><tab>return True, d<tab>return False, d",if is_prev :,128
511,"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab><IF-STMT><tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab>elif isinstance(v, bool):<tab><tab><tab>self._populate_bool(element, k, v)<tab><tab>elif isinstance(v, basestring):<tab><tab><tab>self._populate_str(element, k, v)<tab><tab>elif type(v) in [int, float, long, complex]:<tab><tab><tab>self._populate_number(element, k, v)","if isinstance ( v , dict ) :",178
512,"def __createItemAttribute(self, item, function, preload):<tab>""""""Create the new widget, add it, and remove the old one""""""<tab>try:<tab><tab>self.__stack.addWidget(function(item, preload))<tab><tab># Remove the widget<tab><tab><IF-STMT><tab><tab><tab>oldWidget = self.__stack.widget(0)<tab><tab><tab>self.__stack.removeWidget(oldWidget)<tab><tab><tab>oldWidget.setParent(QtWidgets.QWidget())<tab>except Exception as e:<tab><tab>list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if self . __stack . count ( ) > 1 :,145
513,"def download_main(<tab>download, download_playlist, urls, playlist, output_dir, merge, info_only):<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>url = url[8:]<tab><tab>if not url.startswith(""http://""):<tab><tab><tab>url = ""http://"" + url<tab><tab>if playlist:<tab><tab><tab>download_playlist(<tab><tab><tab><tab>url, output_dir=output_dir, merge=merge, info_only=info_only<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>download(url, output_dir=output_dir, merge=merge, info_only=info_only)","if url . startswith ( ""https://"" ) :",155
514,"def add_enc_zero(obj, enc_zero):<tab>if isinstance(obj, np.ndarray):<tab><tab>return obj + enc_zero<tab>elif isinstance(obj, Iterable):<tab><tab>return type(obj)(<tab><tab><tab>EncryptModeCalculator.add_enc_zero(o, enc_zero)<tab><tab><tab><IF-STMT><tab><tab><tab>else o + enc_zero<tab><tab><tab>for o in obj<tab><tab>)<tab>else:<tab><tab>return obj + enc_zero","if isinstance ( o , Iterable )",118
515,"def ensemble(self, pairs, other_preds):<tab>""""""Ensemble the dict with statistical model predictions.""""""<tab>lemmas = []<tab>assert len(pairs) == len(other_preds)<tab>for p, pred in zip(pairs, other_preds):<tab><tab>w, pos = p<tab><tab>if (w, pos) in self.composite_dict:<tab><tab><tab>lemma = self.composite_dict[(w, pos)]<tab><tab>elif w in self.word_dict:<tab><tab><tab>lemma = self.word_dict[w]<tab><tab>else:<tab><tab><tab>lemma = pred<tab><tab><IF-STMT><tab><tab><tab>lemma = w<tab><tab>lemmas.append(lemma)<tab>return lemmas",if lemma is None :,164
516,"def replace_to_6hex(color):<tab>""""""Validate and replace 3hex colors to 6hex ones.""""""<tab>if match(r""^#(?:[0-9a-fA-F]{3}){1,2}$"", color):<tab><tab><IF-STMT><tab><tab><tab>color = ""#{0}{0}{1}{1}{2}{2}"".format(color[1], color[2], color[3])<tab><tab>return color<tab>else:<tab><tab>exit(_(""Invalid color {}"").format(color))",if len ( color ) == 4 :,120
517,"def computeMachineName(self):<tab>""""""Return the name of the current machine, i.e, HOSTNAME.""""""<tab># This is prepended to leoSettings.leo or myLeoSettings.leo<tab># to give the machine-specific setting name.<tab># How can this be worth doing??<tab>try:<tab><tab>import os<tab><tab>name = os.getenv(""HOSTNAME"")<tab><tab><IF-STMT><tab><tab><tab>name = os.getenv(""COMPUTERNAME"")<tab><tab>if not name:<tab><tab><tab>import socket<tab><tab><tab>name = socket.gethostname()<tab>except Exception:<tab><tab>name = """"<tab>return name",if not name :,151
518,"def _git_dirty_working_directory(q, include_untracked):<tab>try:<tab><tab>cmd = [""git"", ""status"", ""--porcelain""]<tab><tab>if include_untracked:<tab><tab><tab>cmd += [""--untracked-files=normal""]<tab><tab>else:<tab><tab><tab>cmd += [""--untracked-files=no""]<tab><tab>status = _run_git_cmd(cmd)<tab><tab><IF-STMT><tab><tab><tab>q.put(bool(status))<tab><tab>else:<tab><tab><tab>q.put(None)<tab>except (subprocess.CalledProcessError, OSError, FileNotFoundError):<tab><tab>q.put(None)",if status is not None :,156
519,"def runAndWaitWork(server, work):<tab>work.touch()<tab>thr = threading.Thread(target=workThread, args=(server, work))<tab>thr.setDaemon(True)<tab>thr.start()<tab># Wait around for done or timeout<tab>while True:<tab><tab>if work.isTimedOut():<tab><tab><tab>break<tab><tab># If the thread is done, lets get out.<tab><tab>if not thr.isAlive():<tab><tab><tab>break<tab><tab># If our parent, or some thread closes stdin,<tab><tab># time to pack up and go.<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(2)",if sys . stdin . closed :,160
520,"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True):<tab>try:<tab><tab>return self._read(count, timeout)<tab>except usb.USBError as e:<tab><tab>if DEBUG_COMM:<tab><tab><tab>log.info(<tab><tab><tab><tab>""read: e.errno=%s e.strerror=%s e.message=%s repr=%s""<tab><tab><tab><tab>% (e.errno, e.strerror, e.message, repr(e))<tab><tab><tab>)<tab><tab>if ignore_timeouts and is_timeout(e):<tab><tab><tab>return []<tab><tab><IF-STMT><tab><tab><tab>return []<tab><tab>raise",if ignore_non_errors and is_noerr ( e ) :,174
521,"def PrintHeader(self):  # print the header array<tab>if self.draw == False:<tab><tab>return<tab>for val in self.parent.header:<tab><tab>self.SetPrintFont(val[""Font""])<tab><tab>header_indent = val[""Indent""] * self.pwidth<tab><tab>text = val[""Text""]<tab><tab>htype = val[""Type""]<tab><tab><IF-STMT><tab><tab><tab>addtext = self.GetDate()<tab><tab>elif htype == ""Date & Time"":<tab><tab><tab>addtext = self.GetDateTime()<tab><tab>else:<tab><tab><tab>addtext = """"<tab><tab>self.OutTextPageWidth(<tab><tab><tab>text + addtext, self.pheader_margin, val[""Align""], header_indent, True<tab><tab>)","if htype == ""Date"" :",184
522,"def get_intersect_all(self, refine=False):<tab>result = None<tab>for source, parts in self._per_source.items():<tab><tab>if result is None:<tab><tab><tab>result = parts<tab><tab>else:<tab><tab><tab>result.intersection_update(parts)<tab>if not result:<tab><tab>return None<tab>elif len(result) == 1:<tab><tab>return list(result)[0].item<tab>else:<tab><tab>solids = [p.item for p in result]<tab><tab>solid = solids[0].fuse(solids[1:])<tab><tab><IF-STMT><tab><tab><tab>solid = solid.removeSplitter()<tab><tab>return solid",if refine :,159
523,"def captured_updateNode(self, context):<tab>if not self.updating_name_from_pointer:<tab><tab>font_datablock = self.get_bpy_data_from_name(self.fontname, bpy.data.fonts)<tab><tab><IF-STMT><tab><tab><tab>self.font_pointer = font_datablock<tab><tab><tab>updateNode(self, context)",if font_datablock :,91
524,"def __add__(self, other):<tab>if isinstance(other, Vector2):<tab><tab># Vector + Vector -> Vector<tab><tab># Vector + Point -> Point<tab><tab># Point + Point -> Vector<tab><tab><IF-STMT><tab><tab><tab>_class = Vector2<tab><tab>else:<tab><tab><tab>_class = Point2<tab><tab>return _class(self.x + other.x, self.y + other.y)<tab>else:<tab><tab>assert hasattr(other, ""__len__"") and len(other) == 2<tab><tab>return Vector2(self.x + other[0], self.y + other[1])",if self . __class__ is other . __class__ :,150
525,"def _flatten_settings_from_form(self, settings, form, form_values):<tab>""""""Take a nested dict and return a flat dict of setting values.""""""<tab>setting_values = {}<tab>for field in form.c:<tab><tab><IF-STMT><tab><tab><tab>setting_values.update(<tab><tab><tab><tab>self._flatten_settings_from_form(<tab><tab><tab><tab><tab>settings, field, form_values[field._name]<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>elif field._name in settings:<tab><tab><tab>setting_values[field._name] = form_values[field._name]<tab>return setting_values","if isinstance ( field , _ContainerMixin ) :",156
526,"def add_include_dirs(self, args):<tab>ids = []<tab>for a in args:<tab><tab># FIXME same hack, forcibly unpack from holder.<tab><tab>if hasattr(a, ""includedirs""):<tab><tab><tab>a = a.includedirs<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArguments(<tab><tab><tab><tab>""Include directory to be added is not an include directory object.""<tab><tab><tab>)<tab><tab>ids.append(a)<tab>self.include_dirs += ids","if not isinstance ( a , IncludeDirs ) :",120
527,"def _clip_array(array, config):<tab>if ""threshold"" in config.keys():<tab><tab>threshold = config[""threshold""]<tab>else:<tab><tab>abs_array = np.max(np.abs(array))<tab><tab><IF-STMT><tab><tab><tab>return array<tab><tab>threshold = np.percentile(np.abs(array), 99.99)<tab>return np.clip(array, -threshold, threshold)",if abs_array < 1.0 :,103
528,def dfs(v: str) -> Iterator[Set[str]]:<tab>index[v] = len(stack)<tab>stack.append(v)<tab>boundaries.append(index[v])<tab>for w in edges[v]:<tab><tab><IF-STMT><tab><tab><tab>yield from dfs(w)<tab><tab>elif w not in identified:<tab><tab><tab>while index[w] < boundaries[-1]:<tab><tab><tab><tab>boundaries.pop()<tab>if boundaries[-1] == index[v]:<tab><tab>boundaries.pop()<tab><tab>scc = set(stack[index[v] :])<tab><tab>del stack[index[v] :]<tab><tab>identified.update(scc)<tab><tab>yield scc,if w not in index :,162
529,"def create_balancer(<tab>self, name, members, protocol=""http"", port=80, algorithm=DEFAULT_ALGORITHM):<tab>balancer = self.ex_create_balancer_nowait(name, members, protocol, port, algorithm)<tab>timeout = 60 * 20<tab>waittime = 0<tab>interval = 2 * 15<tab>if balancer.id is not None:<tab><tab>return balancer<tab>else:<tab><tab>while waittime < timeout:<tab><tab><tab>balancers = self.list_balancers()<tab><tab><tab>for i in balancers:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return i<tab><tab><tab>waittime += interval<tab><tab><tab>time.sleep(interval)<tab>raise Exception(""Failed to get id"")",if i . name == balancer . name and i . id is not None :,190
530,"def handle(self, scope: Scope, receive: Receive, send: Send) -> None:<tab>if self.methods and scope[""method""] not in self.methods:<tab><tab><IF-STMT><tab><tab><tab>raise HTTPException(status_code=405)<tab><tab>else:<tab><tab><tab>response = PlainTextResponse(""Method Not Allowed"", status_code=405)<tab><tab>await response(scope, receive, send)<tab>else:<tab><tab>await self.app(scope, receive, send)","if ""app"" in scope :",116
531,"def convert(data):<tab>result = []<tab>for d in data:<tab><tab># noinspection PyCompatibility<tab><tab>if isinstance(d, tuple) and len(d) == 2:<tab><tab><tab>result.append((d[0], None, d[1]))<tab><tab><IF-STMT><tab><tab><tab>result.append(d)<tab>return result","elif isinstance ( d , basestring ) :",86
532,"def register_adapters():<tab>global adapters_registered<tab>if adapters_registered is True:<tab><tab>return<tab>try:<tab><tab>import pkg_resources<tab><tab>packageDir = pkg_resources.resource_filename(""pyamf"", ""adapters"")<tab>except:<tab><tab>packageDir = os.path.dirname(__file__)<tab>for f in glob.glob(os.path.join(packageDir, ""*.py"")):<tab><tab>mod = os.path.basename(f).split(os.path.extsep, 1)[0]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>register_adapter(mod[1:].replace(""_"", "".""), PackageImporter(mod))<tab><tab>except ImportError:<tab><tab><tab>pass<tab>adapters_registered = True","if mod == ""__init__"" or not mod . startswith ( ""_"" ) :",188
533,"def load_modules(<tab>to_load, load, attr, modules_dict, excluded_aliases, loading_message=None):<tab>if loading_message:<tab><tab>print(loading_message)<tab>for name in to_load:<tab><tab>module = load(name)<tab><tab>if module is None or not hasattr(module, attr):<tab><tab><tab>continue<tab><tab>cls = getattr(module, attr)<tab><tab>if hasattr(cls, ""initialize"") and not cls.initialize():<tab><tab><tab>continue<tab><tab>if hasattr(module, ""aliases""):<tab><tab><tab>for alias in module.aliases():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>modules_dict[alias] = module<tab><tab>else:<tab><tab><tab>modules_dict[name] = module<tab>if loading_message:<tab><tab>print()",if alias not in excluded_aliases :,195
534,"def clean_items(event, items, variations):<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(_(""One or more items do not belong to this event.""))<tab><tab>if item.has_variations:<tab><tab><tab>if not any(var.item == item for var in variations):<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(<tab><tab><tab><tab><tab><tab>""One or more items has variations but none of these are in the variations list.""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",if event != item . event :,127
535,"def __get_file_by_num(self, num, file_list, idx=0):<tab>for element in file_list:<tab><tab><IF-STMT><tab><tab><tab>return element<tab><tab>if element[3] and element[4]:<tab><tab><tab>i = self.__get_file_by_num(num, element[3], idx + 1)<tab><tab><tab>if not isinstance(i, int):<tab><tab><tab><tab>return i<tab><tab><tab>idx = i<tab><tab>else:<tab><tab><tab>idx += 1<tab>return idx",if idx == num :,127
536,"def check(chip, xeddb, chipdb):<tab>all_inst = []<tab>undoc = []<tab>for inst in xeddb.recs:<tab><tab><IF-STMT><tab><tab><tab>if inst.undocumented:<tab><tab><tab><tab>undoc.append(inst)<tab><tab><tab>else:<tab><tab><tab><tab>all_inst.append(inst)<tab>return (all_inst, undoc)",if inst . isa_set in chipdb [ chip ] :,108
537,"def get_all_topic_src_files(self):<tab>""""""Retrieves the file paths of all the topics in directory""""""<tab>topic_full_paths = []<tab>topic_names = os.listdir(self.topic_dir)<tab>for topic_name in topic_names:<tab><tab># Do not try to load hidden files.<tab><tab><IF-STMT><tab><tab><tab>topic_full_path = os.path.join(self.topic_dir, topic_name)<tab><tab><tab># Ignore the JSON Index as it is stored with topic files.<tab><tab><tab>if topic_full_path != self.index_file:<tab><tab><tab><tab>topic_full_paths.append(topic_full_path)<tab>return topic_full_paths","if not topic_name . startswith ( ""."" ) :",174
538,"def _get_element(dom_msi, tag_name, name=None, id_=None):<tab>""""""Get a xml element defined on Product.""""""<tab>product = dom_msi.getElementsByTagName(""Product"")[0]<tab>elements = product.getElementsByTagName(tag_name)<tab>for element in elements:<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>element.getAttribute(""Name"") == name<tab><tab><tab><tab>and element.getAttribute(""Id"") == id_<tab><tab><tab>):<tab><tab><tab><tab>return element<tab><tab>elif id_:<tab><tab><tab>if element.getAttribute(""Id"") == id_:<tab><tab><tab><tab>return element",if name and id_ :,153
539,"def __init__(self, *models):<tab>super().__init__()<tab>self.models = ModuleList(models)<tab>for m in models:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs)""<tab><tab><tab>)<tab>self.likelihood = LikelihoodList(*[m.likelihood for m in models])","if not hasattr ( m , ""likelihood"" ) :",101
540,"def _sniff(filename, oxlitype):<tab>try:<tab><tab>with open(filename, ""rb"") as fileobj:<tab><tab><tab>header = fileobj.read(4)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fileobj.read(1)  # skip the version number<tab><tab><tab><tab>ftype = fileobj.read(1)<tab><tab><tab><tab>if binascii.hexlify(ftype) == oxlitype:<tab><tab><tab><tab><tab>return True<tab><tab>return False<tab>except OSError:<tab><tab>return False","if header == b""OXLI"" :",126
541,"def convert_port_bindings(port_bindings):<tab>result = {}<tab>for k, v in six.iteritems(port_bindings):<tab><tab>key = str(k)<tab><tab>if ""/"" not in key:<tab><tab><tab>key += ""/tcp""<tab><tab><IF-STMT><tab><tab><tab>result[key] = [_convert_port_binding(binding) for binding in v]<tab><tab>else:<tab><tab><tab>result[key] = [_convert_port_binding(v)]<tab>return result","if isinstance ( v , list ) :",119
542,"def input_data(self):<tab>gen = self.config.generator<tab># don't try running the generator if we specify an output file explicitly,<tab># otherwise generator may segfault and we end up returning the output file anyway<tab>if gen and (not self.config[""out""] or not self.config[""in""]):<tab><tab><IF-STMT><tab><tab><tab>self._run_generator(gen, args=self.config.generator_args)<tab><tab>if self._generated[0]:<tab><tab><tab>return self._generated[0]<tab># in file is optional<tab>return (<tab><tab>self._normalize(self.problem.problem_data[self.config[""in""]])<tab><tab>if self.config[""in""]<tab><tab>else b""""<tab>)",if self . _generated is None :,175
543,"def __new__(cls, *tasks, **kwargs):<tab># This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z`<tab>if not kwargs and tasks:<tab><tab><IF-STMT><tab><tab><tab>tasks = tasks[0] if len(tasks) == 1 else tasks<tab><tab><tab>return reduce(operator.or_, tasks)<tab>return super(chain, cls).__new__(cls, *tasks, **kwargs)",if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,118
544,"def get_file_sources():<tab>global _file_sources<tab>if _file_sources is None:<tab><tab>from galaxy.files import ConfiguredFileSources<tab><tab>file_sources = None<tab><tab>if os.path.exists(""file_sources.json""):<tab><tab><tab>file_sources_as_dict = None<tab><tab><tab>with open(""file_sources.json"", ""r"") as f:<tab><tab><tab><tab>file_sources_as_dict = json.load(f)<tab><tab><tab>if file_sources_as_dict is not None:<tab><tab><tab><tab>file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict)<tab><tab><IF-STMT><tab><tab><tab>ConfiguredFileSources.from_dict([])<tab><tab>_file_sources = file_sources<tab>return _file_sources",if file_sources is None :,196
545,"def InitializeColours(self):<tab>""""""Initializes the 16 custom colours in :class:`CustomPanel`.""""""<tab>curr = self._colourData.GetColour()<tab>self._colourSelection = -1<tab>for i in range(16):<tab><tab>c = self._colourData.GetCustomColour(i)<tab><tab><IF-STMT><tab><tab><tab>self._customColours[i] = self._colourData.GetCustomColour(i)<tab><tab>else:<tab><tab><tab>self._customColours[i] = wx.WHITE<tab><tab>if c == curr:<tab><tab><tab>self._colourSelection = i",if c . IsOk ( ) :,147
546,"def convert_obj_into_marshallable(self, obj):<tab>if isinstance(obj, self.marshalable_types):<tab><tab>return obj<tab>if isinstance(obj, array.array):<tab><tab>if obj.typecode == ""c"":<tab><tab><tab>return obj.tostring()<tab><tab><IF-STMT><tab><tab><tab>return obj.tounicode()<tab><tab>return obj.tolist()<tab>return self.class_to_dict(obj)","if obj . typecode == ""u"" :",113
547,"def run(self):<tab>self.run_command(""egg_info"")<tab>from glob import glob<tab>for pattern in self.match:<tab><tab>pattern = self.distribution.get_name() + ""*"" + pattern<tab><tab>files = glob(os.path.join(self.dist_dir, pattern))<tab><tab>files = [(os.path.getmtime(f), f) for f in files]<tab><tab>files.sort()<tab><tab>files.reverse()<tab><tab>log.info(""%d file(s) matching %s"", len(files), pattern)<tab><tab>files = files[self.keep :]<tab><tab>for (t, f) in files:<tab><tab><tab>log.info(""Deleting %s"", f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.unlink(f)",if not self . dry_run :,188
548,"def render_token_list(self, tokens):<tab>result = []<tab>vars = []<tab>for token in tokens:<tab><tab>if token.token_type == TOKEN_TEXT:<tab><tab><tab>result.append(token.contents.replace(""%"", ""%%""))<tab><tab><IF-STMT><tab><tab><tab>result.append(""%%(%s)s"" % token.contents)<tab><tab><tab>vars.append(token.contents)<tab>return """".join(result), vars",elif token . token_type == TOKEN_VAR :,113
549,"def _handle_raise(self, values, is_NAs, origins):<tab>for is_NA, origin in zip(is_NAs, origins):<tab><tab><IF-STMT><tab><tab><tab>msg = (<tab><tab><tab><tab>""Missing values detected. If you want rows with missing ""<tab><tab><tab><tab>""values to be automatically deleted in a list-wise ""<tab><tab><tab><tab>""manner (not recommended), please set dropna=True in ""<tab><tab><tab><tab>""the Bambi Model initialization.""<tab><tab><tab>)<tab><tab><tab>raise PatsyError(msg, origin)<tab>return values",if np . any ( is_NA ) :,145
550,"def add_node_data(node_array, ntwk):<tab>node_ntwk = nx.Graph()<tab>newdata = {}<tab>for idx, data in ntwk.nodes(data=True):<tab><tab><IF-STMT><tab><tab><tab>newdata[""value""] = node_array[int(idx) - 1]<tab><tab><tab>data.update(newdata)<tab><tab><tab>node_ntwk.add_node(int(idx), **data)<tab>return node_ntwk",if not int ( idx ) == 0 :,119
551,"def safe_parse_date(date_hdr):<tab>""""""Parse a Date: or Received: header into a unix timestamp.""""""<tab>try:<tab><tab>if "";"" in date_hdr:<tab><tab><tab>date_hdr = date_hdr.split("";"")[-1].strip()<tab><tab>msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr)))<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>return msg_ts<tab>except (ValueError, TypeError, OverflowError):<tab><tab>return None",if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,150
552,"def _route_db(self, model, **hints):<tab>chosen_db = None<tab>for router in self.routers:<tab><tab>try:<tab><tab><tab>method = getattr(router, action)<tab><tab>except AttributeError:<tab><tab><tab># If the router doesn't have a method, skip to the next one.<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>chosen_db = method(model, **hints)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return chosen_db<tab>try:<tab><tab>return hints[""instance""]._state.db or DEFAULT_DB_ALIAS<tab>except KeyError:<tab><tab>return DEFAULT_DB_ALIAS",if chosen_db :,154
553,"def get_keys(struct, ignore_first_level=False):<tab>res = []<tab>if isinstance(struct, dict):<tab><tab>if not ignore_first_level:<tab><tab><tab>keys = [x.split(""("")[0] for x in struct.keys()]<tab><tab><tab>res.extend(keys)<tab><tab>for key in struct:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logging.debug(""Ignored: %s: %s"", key, struct[key])<tab><tab><tab><tab>continue<tab><tab><tab>res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL))<tab>elif isinstance(struct, list):<tab><tab>for item in struct:<tab><tab><tab>res.extend(get_keys(item))<tab>return res",if key in IGNORED_KEYS :,178
554,"def launch_app(self, fs_id):<tab>if fs_id in self.app_infos:<tab><tab>row = self.get_row_by_fsid(fs_id)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>app_info = self.app_infos[fs_id]<tab><tab>filepath = os.path.join(row[SAVEDIR_COL], row[SAVENAME_COL])<tab><tab>gfile = Gio.File.new_for_path(filepath)<tab><tab>app_info.launch(<tab><tab><tab>[<tab><tab><tab><tab>gfile,<tab><tab><tab>],<tab><tab><tab>None,<tab><tab>)<tab><tab>self.app_infos.pop(fs_id, None)",if not row :,166
555,"def create_skipfile(files_changed, skipfile):<tab># File is likely to contain some garbage values at start,<tab># only the corresponding json should be parsed.<tab>json_pattern = re.compile(r""^\{.*\}"")<tab>for line in files_changed.readlines():<tab><tab><IF-STMT><tab><tab><tab>for filename in json.loads(line):<tab><tab><tab><tab>if ""/COMMIT_MSG"" in filename:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>skipfile.write(""+*/%s\n"" % filename)<tab>skipfile.write(""-*\n"")","if re . match ( json_pattern , line ) :",142
556,"def zscore(self, client, request, N):<tab>check_input(request, N != 2)<tab>key = request[1]<tab>db = client.db<tab>value = db.get(key)<tab>if value is None:<tab><tab>client.reply_bulk(None)<tab>elif not isinstance(value, self.zset_type):<tab><tab>client.reply_wrongtype()<tab>else:<tab><tab>score = value.score(request[2], None)<tab><tab><IF-STMT><tab><tab><tab>score = str(score).encode(""utf-8"")<tab><tab>client.reply_bulk(score)",if score is not None :,148
557,"def _list_cases(suite):<tab>for test in suite:<tab><tab>if isinstance(test, unittest.TestSuite):<tab><tab><tab>_list_cases(test)<tab><tab>elif isinstance(test, unittest.TestCase):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(test.id())",if support . match_test ( test ) :,75
558,"def Run(self):<tab>""""""The main run method of the client.""""""<tab>for thread in self._threads.values():<tab><tab>thread.start()<tab>logging.info(START_STRING)<tab>while True:<tab><tab>dead_threads = [tn for (tn, t) in self._threads.items() if not t.isAlive()]<tab><tab><IF-STMT><tab><tab><tab>raise FatalError(<tab><tab><tab><tab>""These threads are dead: %r. Shutting down..."" % dead_threads<tab><tab><tab>)<tab><tab>time.sleep(10)",if dead_threads :,130
559,"def _slice_queryset(queryset, order_by, per_page, start):<tab>page_len = int(per_page) + 1<tab>if start:<tab><tab><IF-STMT><tab><tab><tab>filter_name = ""%s__lte"" % order_by[1:]<tab><tab>else:<tab><tab><tab>filter_name = ""%s__gte"" % order_by<tab><tab>return queryset.filter(**{filter_name: start})[:page_len]<tab>return queryset[:page_len]","if order_by . startswith ( ""-"" ) :",118
560,"def compute_timer_precision(timer):<tab>precision = None<tab>points = 0<tab>timeout = timeout_timer() + 1.0<tab>previous = timer()<tab>while timeout_timer() < timeout or points < 5:<tab><tab>for _ in XRANGE(10):<tab><tab><tab>t1 = timer()<tab><tab><tab>t2 = timer()<tab><tab><tab>dt = t2 - t1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>dt = t2 - previous<tab><tab><tab>if dt <= 0.0:<tab><tab><tab><tab>continue<tab><tab>if precision is not None:<tab><tab><tab>precision = min(precision, dt)<tab><tab>else:<tab><tab><tab>precision = dt<tab><tab>points += 1<tab><tab>previous = timer()<tab>return precision",if 0 < dt :,189
561,"def findWorkingDir():<tab>frozen = getattr(sys, ""frozen"", """")<tab>if not frozen:<tab><tab>path = os.path.dirname(__file__)<tab>elif frozen in (""dll"", ""console_exe"", ""windows_exe"", ""macosx_app""):<tab><tab>path = os.path.dirname(<tab><tab><tab>os.path.dirname(os.path.dirname(os.path.dirname(__file__)))<tab><tab>)<tab>elif frozen:  # needed for PyInstaller<tab><tab><IF-STMT><tab><tab><tab>path = getattr(sys, ""_MEIPASS"", """")  # --onefile<tab><tab>else:<tab><tab><tab>path = os.path.dirname(sys.executable)  # --onedir<tab>else:<tab><tab>path = """"<tab>return path","if getattr ( sys , ""_MEIPASS"" , """" ) is not None :",192
562,"def CreateDataType(vmodlName, wsdlName, parent, version, props):<tab>with _lazyLock:<tab><tab>dic = [vmodlName, wsdlName, parent, version, props]<tab><tab>names = vmodlName.split(""."")<tab><tab><IF-STMT><tab><tab><tab>vmodlName = ""."".join(name[0].lower() + name[1:] for name in names)<tab><tab>_AddToDependencyMap(names)<tab><tab>typeNs = GetWsdlNamespace(version)<tab><tab>_dataDefMap[vmodlName] = dic<tab><tab>_wsdlDefMap[(typeNs, wsdlName)] = dic<tab><tab>_wsdlTypeMapNSs.add(typeNs)",if _allowCapitalizedNames :,170
563,"def ParseResponses(<tab>self,<tab>knowledge_base: rdf_client.KnowledgeBase,<tab>responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]:<tab>for response in responses:<tab><tab>if not isinstance(response, rdf_client_fs.StatEntry):<tab><tab><tab>raise TypeError(f""Unexpected response type: `{type(response)}`"")<tab><tab># TODO: `st_mode` has to be an `int`, not `StatMode`.<tab><tab>if stat.S_ISDIR(int(response.st_mode)):<tab><tab><tab>homedir = response.pathspec.path<tab><tab><tab>username = os.path.basename(homedir)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield rdf_client.User(username=username, homedir=homedir)",if username not in self . _ignore_users :,198
564,"def process_question(qtxt):<tab>question = """"<tab>skip = False<tab>for letter in qtxt:<tab><tab>if letter == ""<"":<tab><tab><tab>skip = True<tab><tab>if letter == "">"":<tab><tab><tab>skip = False<tab><tab>if skip:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if letter == "" "":<tab><tab><tab><tab>letter = ""_""<tab><tab><tab>question += letter.lower()<tab>return question","if letter . isalnum ( ) or letter == "" "" :",110
565,"def process_all(self, lines, times=1):<tab>gap = False<tab>for _ in range(times):<tab><tab>for line in lines:<tab><tab><tab>if gap:<tab><tab><tab><tab>self.write("""")<tab><tab><tab>self.process(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>gap = True<tab>return 0",if not is_command ( line ) :,86
566,"def _get(self, domain):<tab>with self.lock:<tab><tab>try:<tab><tab><tab>record = self.cache[domain]<tab><tab><tab>time_now = time.time()<tab><tab><tab>if time_now - record[""update""] > self.ttl:<tab><tab><tab><tab>record = None<tab><tab>except KeyError:<tab><tab><tab>record = None<tab><tab><IF-STMT><tab><tab><tab>record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0}<tab><tab># self.cache[domain] = record<tab><tab>return record",if not record :,137
567,"def gen_constant_folding(cw):<tab>types = [""Int32"", ""Double"", ""BigInteger"", ""Complex""]<tab>for cur_type in types:<tab><tab>cw.enter_block(""if (constLeft.Value.GetType() == typeof(%s))"" % (cur_type,))<tab><tab>cw.enter_block(""switch (_op)"")<tab><tab>for op in ops:<tab><tab><tab>gen = getattr(op, ""genConstantFolding"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>gen(cw, cur_type)<tab><tab>cw.exit_block()<tab><tab>cw.exit_block()",if gen is not None :,147
568,"def unreferenced_dummy(self):<tab>for g, base in zip(self.evgroups, self.evbases):<tab><tab>for ind, j in enumerate(g):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>debug_print(<tab><tab><tab><tab><tab>""replacing unreferenced %d %s with dummy"" % ((base + ind), g[ind])<tab><tab><tab><tab>)<tab><tab><tab><tab>g[ind] = ""dummy""<tab><tab><tab><tab>self.evnum[base + ind] = ""dummy""",if not self . indexobj [ base + ind ] :,127
569,"def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]:<tab>for cls in self.__class__.__mro__:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""PyDecoratorMixin is deprecated. ""<tab><tab><tab><tab>""Please check the implementation of %s"" % cls,<tab><tab><tab><tab>RemovedInSphinx50Warning,<tab><tab><tab><tab>stacklevel=2,<tab><tab><tab>)<tab><tab><tab>break<tab>else:<tab><tab>warnings.warn(<tab><tab><tab>""PyDecoratorMixin is deprecated"", RemovedInSphinx50Warning, stacklevel=2<tab><tab>)<tab>ret = super().handle_signature(sig, signode)  # type: ignore<tab>signode.insert(0, addnodes.desc_addname(""@"", ""@""))<tab>return ret","if cls . __name__ != ""DirectiveAdapter"" :",199
570,"def _iter_lines(path=path, response=response, max_next=options.http_max_next):<tab>path.responses = []<tab>n = 0<tab>while response:<tab><tab>path.responses.append(response)<tab><tab>yield from response.iter_lines(decode_unicode=True)<tab><tab>src = response.links.get(""next"", {}).get(""url"", None)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>n += 1<tab><tab>if n > max_next:<tab><tab><tab>vd.warning(f""stopping at max {max_next} pages"")<tab><tab><tab>break<tab><tab>vd.status(f""fetching next page from {src}"")<tab><tab>response = requests.get(src, stream=True)",if not src :,179
571,"def ordered_indices(self):<tab>with data_utils.numpy_seed(self.seed, self.epoch):<tab><tab># Used to store the order of indices of each dataset to use<tab><tab>indices = [<tab><tab><tab>np.random.permutation(len(dataset)) for dataset in self.datasets.values()<tab><tab>]<tab><tab># Keep track of which samples we've  used for each dataset<tab><tab>counters = [0 for _ in self.datasets]<tab><tab>sampled_indices = [<tab><tab><tab>self._sample(indices, counters) for _ in range(self.total_num_instances)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>sampled_indices.sort(key=lambda i: self.num_tokens(i))<tab><tab>return np.array(sampled_indices, dtype=np.int64)",if self . sort_indices :,195
572,"def _build_columns(self):<tab>self.columns = [Column() for col in self.keys]<tab>for row in self:<tab><tab>for (col_idx, col_val) in enumerate(row):<tab><tab><tab>col = self.columns[col_idx]<tab><tab><tab>col.append(col_val)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>col.is_quantity = False<tab>for (idx, key_name) in enumerate(self.keys):<tab><tab>self.columns[idx].name = key_name<tab>self.x = Column()<tab>self.ys = []",if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,158
573,"def tearDown(self):<tab>subprocess_list = self.subprocess_list<tab>processes = subprocess_list.processes<tab>self.schedule.reset()<tab>del self.schedule<tab>for proc in processes:<tab><tab><IF-STMT><tab><tab><tab>terminate_process(proc.pid, kill_children=True, slow_stop=True)<tab>subprocess_list.cleanup()<tab>processes = subprocess_list.processes<tab>if processes:<tab><tab>for proc in processes:<tab><tab><tab>if proc.is_alive():<tab><tab><tab><tab>terminate_process(proc.pid, kill_children=True, slow_stop=False)<tab><tab>subprocess_list.cleanup()<tab>processes = subprocess_list.processes<tab>if processes:<tab><tab>log.warning(""Processes left running: %s"", processes)",if proc . is_alive ( ) :,187
574,"def colorNetwork(cls, network, nodesInNetwork, nodeByID=None):<tab>for node in nodesInNetwork:<tab><tab>node.use_custom_color = True<tab><tab>neededCopies = sum(socket.execution.neededCopies for socket in node.outputs)<tab><tab><IF-STMT><tab><tab><tab>color = (0.7, 0.9, 0.7)<tab><tab>else:<tab><tab><tab>color = (1.0, 0.3, 0.3)<tab><tab>node.color = color",if neededCopies == 0 :,121
575,"def _init_warmup_scheduler(self, optimizer, states):<tab>updates_so_far = states.get(""number_training_updates"", 0)<tab>if self.warmup_updates > 0 and (<tab><tab>updates_so_far <= self.warmup_updates or self.hard_reset<tab>):<tab><tab>self.warmup_scheduler = optim.lr_scheduler.LambdaLR(optimizer, self._warmup_lr)<tab><tab><IF-STMT><tab><tab><tab>self.warmup_scheduler.load_state_dict(states[""warmup_scheduler""])<tab>else:<tab><tab>self.warmup_scheduler = None","if states . get ( ""warmup_scheduler"" ) :",144
576,"def inner(self, *iargs, **ikwargs):<tab>try:<tab><tab>return getattr(super(VEXResilienceMixin, self), func)(*iargs, **ikwargs)<tab>except excs as e:<tab><tab>for exc, handler in zip(excs, handlers):<tab><tab><tab>if isinstance(e, exc):<tab><tab><tab><tab>v = getattr(self, handler)(*iargs, **ikwargs)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise<tab><tab><tab><tab>return v<tab><tab>assert False, ""this should be unreachable if Python is working correctly""",if v is raiseme :,140
577,"def unwrap_envelope(self, data, many):<tab>if many:<tab><tab>if data[""items""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.context[""total""] = len(data)<tab><tab><tab><tab>return data<tab><tab><tab>else:<tab><tab><tab><tab>self.context[""total""] = data[""total""]<tab><tab>else:<tab><tab><tab>self.context[""total""] = 0<tab><tab><tab>data = {""items"": []}<tab><tab>return data[""items""]<tab>return data","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :",130
578,"def __subclasscheck__(self, cls):<tab>if self.__origin__ is not None:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Parameterized generics cannot be used with class "" ""or instance checks""<tab><tab><tab>)<tab><tab>return False<tab>if self is Generic:<tab><tab>raise TypeError(<tab><tab><tab>""Class %r cannot be used with class "" ""or instance checks"" % self<tab><tab>)<tab>return super().__subclasscheck__(cls)","if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :",130
579,"def __init__(self, pyversions, coverage_service):<tab>build_matrix = """"<tab>for version in pyversions:<tab><tab>build_matrix += ""\n<tab>{},"".format(<tab><tab><tab>version<tab><tab><tab><IF-STMT><tab><tab><tab>else ""py{}"".format("""".join(version.split(""."")))<tab><tab>)<tab>coverage_package = """"<tab>if coverage_service:<tab><tab>coverage_package += ""\n<tab>{}"".format(coverage_service.package)<tab>coverage_package += ""\n""<tab>super(Tox, self).__init__(<tab><tab>""tox.ini"",<tab><tab>TEMPLATE.format(build_matrix=build_matrix, coverage_package=coverage_package),<tab>)","if version . startswith ( ""pypy"" )",172
580,"def _get_app(self, body=None):<tab>app = self._app<tab>if app is None:<tab><tab>try:<tab><tab><tab>tasks = self.tasks.tasks  # is a group<tab><tab>except AttributeError:<tab><tab><tab>tasks = self.tasks<tab><tab>if len(tasks):<tab><tab><tab>app = tasks[0]._app<tab><tab><IF-STMT><tab><tab><tab>app = body._app<tab>return app if app is not None else current_app",if app is None and body is not None :,117
581,"def logic():<tab>for v in [True, False, None, 0, True, None, None, 1]:<tab><tab>yield clk.posedge<tab><tab>xd.next = v<tab><tab><IF-STMT><tab><tab><tab>yd.next = zd.next = None<tab><tab>elif v:<tab><tab><tab>yd.next = zd.next = 11<tab><tab>else:<tab><tab><tab>yd.next = zd.next = 0",if v is None :,104
582,"def run(self):<tab>eid = self.start_episode()<tab>obs = self.env.reset()<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>action = self.env.action_space.sample()<tab><tab><tab>self.log_action(eid, obs, action)<tab><tab>else:<tab><tab><tab>action = self.get_action(eid, obs)<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>self.log_returns(eid, reward, info=info)<tab><tab>if done:<tab><tab><tab>self.end_episode(eid, obs)<tab><tab><tab>obs = self.env.reset()<tab><tab><tab>eid = self.start_episode()",if random . random ( ) < self . off_pol_frac :,187
583,"def tearDown(self):<tab>os.chdir(self.orig_working_dir)<tab>sys.argv = self.orig_argv<tab>sys.stdout = self.orig_stdout<tab>sys.stderr = self.orig_stderr<tab>for dirname in [""lv_LV"", ""ja_JP""]:<tab><tab>locale_dir = os.path.join(self.datadir, ""project"", ""i18n"", dirname)<tab><tab><IF-STMT><tab><tab><tab>shutil.rmtree(locale_dir)",if os . path . isdir ( locale_dir ) :,122
584,"def sentry_set_scope(process_context, entity, project, email=None, url=None):<tab># Using GLOBAL_HUB means these tags will persist between threads.<tab># Normally there is one hub per thread.<tab>with sentry_sdk.hub.GLOBAL_HUB.configure_scope() as scope:<tab><tab>scope.set_tag(""process_context"", process_context)<tab><tab>scope.set_tag(""entity"", entity)<tab><tab>scope.set_tag(""project"", project)<tab><tab><IF-STMT><tab><tab><tab>scope.user = {""email"": email}<tab><tab>if url:<tab><tab><tab>scope.set_tag(""url"", url)",if email :,157
585,"def getDataMax(self):<tab>result = -Double.MAX_VALUE<tab>nCurves = self.chart.getNCurves()<tab>for i in range(nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if c.getYAxis() == Y_AXIS:<tab><tab><tab>nPoints = c.getNPoints()<tab><tab><tab>for j in range(nPoints):<tab><tab><tab><tab>result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY())<tab>if result == -Double.MAX_VALUE:<tab><tab>return Double.NaN<tab>return result",if not c . isVisible ( ) :,163
586,"def handle_starttag(self, tag, attrs):<tab>if tag == ""link"" and (""rel"", ""icon"") in attrs or (""rel"", ""shortcut icon"") in attrs:<tab><tab>href = None<tab><tab>icon_type = None<tab><tab>for attr, value in attrs:<tab><tab><tab>if attr == ""href"":<tab><tab><tab><tab>href = value<tab><tab><tab>elif attr == ""type"":<tab><tab><tab><tab>icon_type = value<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>mimetype = extension_to_mimetype(href.rpartition(""."")[2])<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>icon_type = mimetype<tab><tab><tab>if icon_type:<tab><tab><tab><tab>self.icons.append((href, icon_type))",if href :,188
587,"def get_version(version_file=STATIC_VERSION_FILE):<tab>version_info = get_static_version_info(version_file)<tab>version = version_info[""version""]<tab>if version == ""__use_git__"":<tab><tab>version = get_version_from_git()<tab><tab><IF-STMT><tab><tab><tab>version = get_version_from_git_archive(version_info)<tab><tab>if not version:<tab><tab><tab>version = Version(""unknown"", None, None)<tab><tab>return pep440_format(version)<tab>else:<tab><tab>return version",if not version :,137
588,"def _Sleep(self, seconds):<tab>if threading.current_thread() is not self._worker_thread:<tab><tab>return self._original_sleep(seconds)<tab>self._time += seconds<tab>self._budget -= seconds<tab>while self._budget < 0:<tab><tab>self._worker_thread_turn.clear()<tab><tab>self._owner_thread_turn.set()<tab><tab>self._worker_thread_turn.wait()<tab><tab><IF-STMT><tab><tab><tab>raise FakeTimeline._WorkerThreadExit()",if self . _worker_thread_done :,127
589,"def validate_attributes(self):<tab>if not (self.has_variants or self.variant_of):<tab><tab>return<tab>if not self.variant_based_on:<tab><tab>self.variant_based_on = ""Item Attribute""<tab>if self.variant_based_on == ""Item Attribute"":<tab><tab>attributes = []<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Attribute table is mandatory""))<tab><tab>for d in self.attributes:<tab><tab><tab>if d.attribute in attributes:<tab><tab><tab><tab>frappe.throw(<tab><tab><tab><tab><tab>_(<tab><tab><tab><tab><tab><tab>""Attribute {0} selected multiple times in Attributes Table""<tab><tab><tab><tab><tab>).format(d.attribute)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>attributes.append(d.attribute)",if not self . attributes :,197
590,"def check_digest_auth(user, passwd):<tab>""""""Check user authentication using HTTP Digest auth""""""<tab>if request.headers.get(""Authorization""):<tab><tab>credentails = parse_authorization_header(request.headers.get(""Authorization""))<tab><tab>if not credentails:<tab><tab><tab>return<tab><tab>response_hash = response(<tab><tab><tab>credentails,<tab><tab><tab>passwd,<tab><tab><tab>dict(<tab><tab><tab><tab>uri=request.script_root + request.path,<tab><tab><tab><tab>body=request.data,<tab><tab><tab><tab>method=request.method,<tab><tab><tab>),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False","if credentails . get ( ""response"" ) == response_hash :",165
591,"def _get_index_type(return_index_type, ctx):<tab>if return_index_type is None:  # pragma: no cover<tab><tab>if ctx.running_mode == RunningMode.local:<tab><tab><tab>return_index_type = ""object""<tab><tab><IF-STMT><tab><tab><tab>return_index_type = ""filename""<tab><tab>else:<tab><tab><tab>return_index_type = ""bytes""<tab>return return_index_type",elif ctx . running_mode == RunningMode . local_cluster :,116
592,"def iter_event_handlers(<tab>self,<tab>resource: resources_.Resource,<tab>event: bodies.RawEvent,) -> Iterator[handlers.ResourceWatchingHandler]:<tab>warnings.warn(<tab><tab>""SimpleRegistry.iter_event_handlers() is deprecated; use ""<tab><tab>""ResourceWatchingRegistry.iter_handlers()."",<tab><tab>DeprecationWarning,<tab>)<tab>cause = _create_watching_cause(resource, event)<tab>for handler in self._handlers:<tab><tab>if not isinstance(handler, handlers.ResourceWatchingHandler):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>yield handler","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",160
593,"def subprocess_post_check(<tab>completed_process: subprocess.CompletedProcess, raise_error: bool = True) -> None:<tab>if completed_process.returncode:<tab><tab><IF-STMT><tab><tab><tab>print(completed_process.stdout, file=sys.stdout, end="""")<tab><tab>if completed_process.stderr is not None:<tab><tab><tab>print(completed_process.stderr, file=sys.stderr, end="""")<tab><tab>if raise_error:<tab><tab><tab>raise PipxError(<tab><tab><tab><tab>f""{' '.join([str(x) for x in completed_process.args])!r} failed""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>logger.info(f""{' '.join(completed_process.args)!r} failed"")",if completed_process . stdout is not None :,185
594,"def __pow__(self, power):<tab>if power == 1:<tab><tab>return self<tab>if power == -1:<tab><tab># HACK: break cycle<tab><tab>from cirq.devices import line_qubit<tab><tab>decomposed = protocols.decompose_once_with_qubits(<tab><tab><tab>self, qubits=line_qubit.LineQid.for_gate(self), default=None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return NotImplemented<tab><tab>inverse_decomposed = protocols.inverse(decomposed, None)<tab><tab>if inverse_decomposed is None:<tab><tab><tab>return NotImplemented<tab><tab>return _InverseCompositeGate(self)<tab>return NotImplemented",if decomposed is None :,164
595,"def tearDown(self):<tab>""""""Close the application after tests""""""<tab># set it back to it's old position so not to annoy users :-)<tab>self.old_pos = self.dlg.rectangle<tab># close the application<tab>self.dlg.menu_select(""File->Exit"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.app.UntitledNotepad[""Do&n't Save""].click()<tab><tab><tab>self.app.UntitledNotepad.wait_not(""visible"")<tab>except Exception:<tab><tab>pass<tab>finally:<tab><tab>self.app.kill()","if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :",160
596,"def terminate_subprocess(proc, timeout=0.1, log=None):<tab><IF-STMT><tab><tab>if log:<tab><tab><tab>log.info(""Sending SIGTERM to %r"", proc)<tab><tab>proc.terminate()<tab><tab>timeout_time = time.time() + timeout<tab><tab>while proc.poll() is None and time.time() < timeout_time:<tab><tab><tab>time.sleep(0.02)<tab><tab>if proc.poll() is None:<tab><tab><tab>if log:<tab><tab><tab><tab>log.info(""Sending SIGKILL to %r"", proc)<tab><tab><tab>proc.kill()<tab>return proc.returncode",if proc . poll ( ) is None :,152
597,"def validate(self, detection, expectation):<tab>config = SigmaConfiguration()<tab>self.basic_rule[""detection""] = detection<tab>with patch(""yaml.safe_load_all"", return_value=[self.basic_rule]):<tab><tab>parser = SigmaCollectionParser(""any sigma io"", config, None)<tab><tab>backend = SQLiteBackend(config, self.table)<tab><tab>assert len(parser.parsers) == 1<tab><tab>for p in parser.parsers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(expectation, backend.generate(p))<tab><tab><tab>elif isinstance(expectation, Exception):<tab><tab><tab><tab>self.assertRaises(type(expectation), backend.generate, p)","if isinstance ( expectation , str ) :",167
598,"def makelist(d):<tab>""""""Convert d into a list if all the keys of d are integers.""""""<tab>if isinstance(d, dict):<tab><tab><IF-STMT><tab><tab><tab>return [makelist(d[k]) for k in sorted(d, key=int)]<tab><tab>else:<tab><tab><tab>return web.storage((k, makelist(v)) for k, v in d.items())<tab>else:<tab><tab>return d",if all ( isint ( k ) for k in d ) :,112
599,"def __share_local_dir(self, lpath, rpath, fast):<tab>result = const.ENoError<tab>for walk in self.__walk_normal_file(lpath):<tab><tab>(dirpath, dirnames, filenames) = walk<tab><tab>for filename in filenames:<tab><tab><tab>rpart = os.path.relpath(dirpath, lpath)<tab><tab><tab>if rpart == ""."":<tab><tab><tab><tab>rpart = """"<tab><tab><tab>subr = self.__share_local_file(<tab><tab><tab><tab>joinpath(dirpath, filename),<tab><tab><tab><tab>posixpath.join(rpath, rpart, filename),<tab><tab><tab><tab>fast,<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = subr<tab>return result",if subr != const . ENoError :,183
600,"def _targets(self, sigmaparser):<tab># build list of matching target mappings<tab>targets = set()<tab>for condfield in self.conditions:<tab><tab><IF-STMT><tab><tab><tab>rulefieldvalues = sigmaparser.values[condfield]<tab><tab><tab>for condvalue in self.conditions[condfield]:<tab><tab><tab><tab>if condvalue in rulefieldvalues:<tab><tab><tab><tab><tab>targets.update(self.conditions[condfield][condvalue])<tab>return targets",if condfield in sigmaparser . values :,115
601,"def _wrapped_view(request, *args, **kwargs):<tab># based on authority/decorators.py<tab>user = request.user<tab>if user.is_authenticated():<tab><tab>obj = _resolve_lookup(obj_lookup, kwargs)<tab><tab>perm_obj = _resolve_lookup(perm_obj_lookup, kwargs)<tab><tab>granted = access.has_perm_or_owns(user, perm, obj, perm_obj, owner_attr)<tab><tab><IF-STMT><tab><tab><tab>return view_func(request, *args, **kwargs)<tab># In all other cases, permission denied<tab>return HttpResponseForbidden()",if granted or user . has_perm ( perm ) :,157
602,"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint):<tab>cleaned_parts = []<tab>for earlier in earlier_parts:<tab><tab>earlier_part = earlier[""part""]<tab><tab>earlier_step = earlier[""step""]<tab><tab>found = False<tab><tab>for current in current_parts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab>if not found:<tab><tab><tab>cleaned_parts.append(dict(part=earlier_part, step=earlier_step))<tab>self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint)<tab>for expected in expected_parts:<tab><tab>self.assertThat(cleaned_parts, Contains(expected), hint)","if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :",194
603,"def show_image(self, wnd_name, img):<tab>if wnd_name in self.named_windows:<tab><tab>if self.named_windows[wnd_name] == 0:<tab><tab><tab>self.named_windows[wnd_name] = 1<tab><tab><tab>self.on_create_window(wnd_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.capture_mouse(wnd_name)<tab><tab>self.on_show_image(wnd_name, img)<tab>else:<tab><tab>print(""show_image: named_window "", wnd_name, "" not found."")",if wnd_name in self . capture_mouse_windows :,159
604,"def readlines(self, hint=None):<tab># Again, allow hint but ignore<tab>body = self._get_body()<tab>rest = body[self.position :]<tab>self.position = len(body)<tab>result = []<tab>while 1:<tab><tab>next = rest.find(""\r\n"")<tab><tab><IF-STMT><tab><tab><tab>result.append(rest)<tab><tab><tab>break<tab><tab>result.append(rest[: next + 2])<tab><tab>rest = rest[next + 2 :]<tab>return result",if next == - 1 :,125
605,"def __lt__(self, other):<tab>olen = len(other)<tab>for i in range(olen):<tab><tab>try:<tab><tab><tab>c = self[i] < other[i]<tab><tab>except IndexError:<tab><tab><tab># self must be shorter<tab><tab><tab>return True<tab><tab>if c:<tab><tab><tab>return c<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return len(self) < olen",elif other [ i ] < self [ i ] :,108
606,"def social_user(backend, uid, user=None, *args, **kwargs):<tab>provider = backend.name<tab>social = backend.strategy.storage.user.get_social_auth(provider, uid)<tab>if social:<tab><tab>if user and social.user != user:<tab><tab><tab>msg = ""This account is already in use.""<tab><tab><tab>raise AuthAlreadyAssociated(backend, msg)<tab><tab><IF-STMT><tab><tab><tab>user = social.user<tab>return {<tab><tab>""social"": social,<tab><tab>""user"": user,<tab><tab>""is_new"": user is None,<tab><tab>""new_association"": social is None,<tab>}",elif not user :,170
607,"def markUVs(self, indices=None):<tab>if isinstance(indices, tuple):<tab><tab>indices = indices[0]<tab>ntexco = len(self.texco)<tab>if indices is None:<tab><tab>self.utexc = True<tab>else:<tab><tab>if self.utexc is False:<tab><tab><tab>self.utexc = np.zeros(ntexco, dtype=bool)<tab><tab><IF-STMT><tab><tab><tab>self.utexc[indices] = True",if self . utexc is not True :,120
608,"def destination(self, type, name, arglist):<tab>classname = ""ResFunction""<tab>listname = ""functions""<tab>if arglist:<tab><tab>t, n, m = arglist[0]<tab><tab><IF-STMT><tab><tab><tab>classname = ""ResMethod""<tab><tab><tab>listname = ""resmethods""<tab>return classname, listname","if t == ""Handle"" and m == ""InMode"" :",90
609,"def select(self, regions, register):<tab>self.view.sel().clear()<tab>to_store = []<tab>for r in regions:<tab><tab>self.view.sel().add(r)<tab><tab>if register:<tab><tab><tab>to_store.append(self.view.substr(self.view.full_line(r)))<tab>if register:<tab><tab>text = """".join(to_store)<tab><tab><IF-STMT><tab><tab><tab>text = text + ""\n""<tab><tab>state = State(self.view)<tab><tab>state.registers[register] = [text]","if not text . endswith ( ""\n"" ) :",142
610,"def _skip_start(self):<tab>start, stop = self.start, self.stop<tab>for chunk in self.app_iter:<tab><tab>self._pos += len(chunk)<tab><tab>if self._pos < start:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return b""""<tab><tab>else:<tab><tab><tab>chunk = chunk[start - self._pos :]<tab><tab><tab>if stop is not None and self._pos > stop:<tab><tab><tab><tab>chunk = chunk[: stop - self._pos]<tab><tab><tab><tab>assert len(chunk) == stop - start<tab><tab><tab>return chunk<tab>else:<tab><tab>raise StopIteration()",elif self . _pos == start :,156
611,"def start(self):<tab>self.on_config_change()<tab>self.start_config_watch()<tab>try:<tab><tab>if self.config[""MITMf""][""DNS""][""tcp""].lower() == ""on"":<tab><tab><tab>self.startTCP()<tab><tab>else:<tab><tab><tab>self.startUDP()<tab>except socket.error as e:<tab><tab><IF-STMT><tab><tab><tab>shutdown(<tab><tab><tab><tab>""\n[DNS] Unable to start DNS server on port {}: port already in use"".format(<tab><tab><tab><tab><tab>self.config[""MITMf""][""DNS""][""port""]<tab><tab><tab><tab>)<tab><tab><tab>)","if ""Address already in use"" in e :",158
612,"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab>if other not in self.ignoreExprs:<tab><tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",if self . expr is not None :,129
613,"def test_relative_deploy_path_override():<tab>s = Site(TEST_SITE_ROOT)<tab>s.load()<tab>res = s.content.resource_from_relative_path(<tab><tab>""blog/2010/december/merry-christmas.html""<tab>)<tab>res.relative_deploy_path = ""blog/2010/december/happy-holidays.html""<tab>for page in s.content.walk_resources():<tab><tab><IF-STMT><tab><tab><tab>assert page.relative_deploy_path == ""blog/2010/december/happy-holidays.html""<tab><tab>else:<tab><tab><tab>assert page.relative_deploy_path == Folder(page.relative_path)",if res . source_file == page . source_file :,177
614,"def _parser(cls, buf):<tab>tlvs = []<tab>while buf:<tab><tab>tlv_type = LLDPBasicTLV.get_type(buf)<tab><tab>tlv = cls._tlv_parsers[tlv_type](buf)<tab><tab>tlvs.append(tlv)<tab><tab>offset = LLDP_TLV_SIZE + tlv.len<tab><tab>buf = buf[offset:]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>assert len(buf) > 0<tab>lldp_pkt = cls(tlvs)<tab>assert lldp_pkt._tlvs_len_valid()<tab>assert lldp_pkt._tlvs_valid()<tab>return lldp_pkt, None, buf",if tlv . tlv_type == LLDP_TLV_END :,192
615,"def _do_pull(self, repo, pull_kwargs, silent, ignore_pull_failures):<tab>try:<tab><tab>output = self.client.pull(repo, **pull_kwargs)<tab><tab>if silent:<tab><tab><tab>with open(os.devnull, ""w"") as devnull:<tab><tab><tab><tab>yield from stream_output(output, devnull)<tab><tab>else:<tab><tab><tab>yield from stream_output(output, sys.stdout)<tab>except (StreamOutputError, NotFound) as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>log.error(str(e))",if not ignore_pull_failures :,151
616,def _collect_bytecode(ordered_code):<tab>bytecode_blocks = []<tab>stack = [ordered_code]<tab>while stack:<tab><tab>code = stack.pop()<tab><tab>bytecode_blocks.append(code.co_code)<tab><tab>for const in code.co_consts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>stack.append(const)<tab>return bytecode_blocks,"if isinstance ( const , blocks . OrderedCode ) :",99
617,"def displayhook(value):<tab>if value is None:<tab><tab>return<tab>builtins = modules[""builtins""]<tab># Set '_' to None to avoid recursion<tab>builtins._ = None<tab>text = repr(value)<tab>try:<tab><tab>local_stdout = stdout<tab>except NameError as e:<tab><tab>raise RuntimeError(""lost sys.stdout"") from e<tab>try:<tab><tab>local_stdout.write(text)<tab>except UnicodeEncodeError:<tab><tab>bytes = text.encode(local_stdout.encoding, ""backslashreplace"")<tab><tab><IF-STMT><tab><tab><tab>local_stdout.buffer.write(bytes)<tab><tab>else:<tab><tab><tab>text = bytes.decode(local_stdout.encoding, ""strict"")<tab><tab><tab>local_stdout.write(text)<tab>local_stdout.write(""\n"")<tab>builtins._ = value","if hasattr ( local_stdout , ""buffer"" ) :",200
618,"def _analyze(self):<tab>lines = open(self.log_path, ""r"").readlines()<tab>prev_line = None<tab>for line in lines:<tab><tab>if line.startswith(""ERROR:"") and prev_line and prev_line.startswith(""=""):<tab><tab><tab>self.errors.append(line[len(""ERROR:"") :].strip())<tab><tab><IF-STMT><tab><tab><tab>self.failures.append(line[len(""FAIL:"") :].strip())<tab><tab>prev_line = line","elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :",128
619,"def _flush(self):<tab>if self._data:<tab><tab>if self._last is not None:<tab><tab><tab>text = """".join(self._data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert self._last.tail is None, ""internal error (tail)""<tab><tab><tab><tab>self._last.tail = text<tab><tab><tab>else:<tab><tab><tab><tab>assert self._last.text is None, ""internal error (text)""<tab><tab><tab><tab>self._last.text = text<tab><tab>self._data = []",if self . _tail :,125
620,"def write(self, chunk):<tab>consumer = self._current_consumer<tab>server_side = consumer.server_side<tab>if server_side:<tab><tab>server_side.data_received(chunk)<tab>else:<tab><tab>consumer.message += chunk<tab><tab>assert consumer.in_parser.execute(chunk, len(chunk)) == len(chunk)<tab><tab><IF-STMT><tab><tab><tab>consumer.finished()",if consumer . in_parser . is_message_complete ( ) :,114
621,"def _api_change_cat(name, output, kwargs):<tab>""""""API: accepts output, value(=nzo_id), value2(=category)""""""<tab>value = kwargs.get(""value"")<tab>value2 = kwargs.get(""value2"")<tab>if value and value2:<tab><tab>nzo_id = value<tab><tab>cat = value2<tab><tab><IF-STMT><tab><tab><tab>cat = None<tab><tab>result = sabnzbd.NzbQueue.change_cat(nzo_id, cat)<tab><tab>return report(output, keyword=""status"", data=bool(result > 0))<tab>else:<tab><tab>return report(output, _MSG_NO_VALUE)","if cat == ""None"" :",164
622,"def get_allocated_address(<tab>self, config: ActorPoolConfig, allocated: allocated_type) -> str:<tab>addresses = config.get_external_addresses(label=self.label)<tab>for addr in addresses:<tab><tab>occupied = False<tab><tab>for strategy, _ in allocated.get(addr, dict()).values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>occupied = True<tab><tab><tab><tab>break<tab><tab>if not occupied:<tab><tab><tab>return addr<tab>raise NoIdleSlot(<tab><tab>f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}""<tab>)",if strategy == self :,146
623,"def schedule_logger(job_id=None, delete=False):<tab>if not job_id:<tab><tab>return getLogger(""fate_flow_schedule"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>with LoggerFactory.lock:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>for key in LoggerFactory.schedule_logger_dict.keys():<tab><tab><tab><tab><tab><tab>if job_id in key:<tab><tab><tab><tab><tab><tab><tab>del LoggerFactory.schedule_logger_dict[key]<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab><tab>key = job_id + ""schedule""<tab><tab>if key in LoggerFactory.schedule_logger_dict:<tab><tab><tab>return LoggerFactory.schedule_logger_dict[key]<tab><tab>return LoggerFactory.get_schedule_logger(job_id)",if delete :,198
624,"def quick_load(tool_file, async_load=True):<tab>try:<tab><tab>tool = self.load_tool(tool_file, tool_cache_data_dir)<tab><tab>self.__add_tool(tool, load_panel_dict, elems)<tab><tab># Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file.<tab><tab>key = ""tool_%s"" % str(tool.id)<tab><tab>integrated_elems[key] = tool<tab><tab><IF-STMT><tab><tab><tab>self._load_tool_panel()<tab><tab><tab>self._save_integrated_tool_panel()<tab><tab>return tool.id<tab>except Exception:<tab><tab>log.exception(""Failed to load potential tool %s."", tool_file)<tab><tab>return None",if async_load :,195
625,"def _get_default_ordering(self):<tab>try:<tab><tab>ordering = super(DocumentChangeList, self)._get_default_ordering()<tab>except AttributeError:<tab><tab>ordering = []<tab><tab>if self.model_admin.ordering:<tab><tab><tab>ordering = self.model_admin.ordering<tab><tab><IF-STMT><tab><tab><tab>ordering = self.lookup_opts.ordering<tab>return ordering",elif self . lookup_opts . ordering :,99
626,"def names(self, persistent=None):<tab>u = set()<tab>result = []<tab>for s in [<tab><tab>self.__storage(None),<tab><tab>self.__storage(self.__category),<tab>]:<tab><tab>for b in s:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if b.name.startswith(""__""):<tab><tab><tab><tab>continue<tab><tab><tab>if b.name not in u:<tab><tab><tab><tab>result.append(b.name)<tab><tab><tab><tab>u.add(b.name)<tab>return result",if persistent is not None and b . persistent != persistent :,139
627,"def common_check_get_messages_query(<tab>self, query_params: Dict[str, object], expected: str) -> None:<tab>user_profile = self.example_user(""hamlet"")<tab>request = POSTRequestMock(query_params, user_profile)<tab>with queries_captured() as queries:<tab><tab>get_messages_backend(request, user_profile)<tab>for query in queries:<tab><tab><IF-STMT><tab><tab><tab>sql = str(query[""sql""]).replace("" /* get_messages */"", """")<tab><tab><tab>self.assertEqual(sql, expected)<tab><tab><tab>return<tab>raise AssertionError(""get_messages query not found"")","if ""/* get_messages */"" in query [ ""sql"" ] :",161
628,"def _activate_only_current_top_active():<tab>for i in range(0, len(current_sequence().tracks) - 1):<tab><tab><IF-STMT><tab><tab><tab>current_sequence().tracks[i].active = True<tab><tab>else:<tab><tab><tab>current_sequence().tracks[i].active = False<tab>gui.tline_column.widget.queue_draw()",if i == current_sequence ( ) . get_first_active_track ( ) . id :,103
629,"def http_wrapper(self, url, postdata={}):<tab>try:<tab><tab>if postdata != {}:<tab><tab><tab>f = urllib.urlopen(url, postdata)<tab><tab>else:<tab><tab><tab>f = urllib.urlopen(url)<tab><tab>response = f.read()<tab>except:<tab><tab>import traceback<tab><tab>import logging, sys<tab><tab>cla, exc, tb = sys.exc_info()<tab><tab>logging.error(url)<tab><tab><IF-STMT><tab><tab><tab>logging.error(""with post data"")<tab><tab>else:<tab><tab><tab>logging.error(""without post data"")<tab><tab>logging.error(exc.args)<tab><tab>logging.error(traceback.format_tb(tb))<tab><tab>response = """"<tab>return response",if postdata :,178
630,"def frequent_thread_switches():<tab>""""""Make concurrency bugs more likely to manifest.""""""<tab>interval = None<tab><IF-STMT><tab><tab>if hasattr(sys, ""getswitchinterval""):<tab><tab><tab>interval = sys.getswitchinterval()<tab><tab><tab>sys.setswitchinterval(1e-6)<tab><tab>else:<tab><tab><tab>interval = sys.getcheckinterval()<tab><tab><tab>sys.setcheckinterval(1)<tab>try:<tab><tab>yield<tab>finally:<tab><tab>if not sys.platform.startswith(""java""):<tab><tab><tab>if hasattr(sys, ""setswitchinterval""):<tab><tab><tab><tab>sys.setswitchinterval(interval)<tab><tab><tab>else:<tab><tab><tab><tab>sys.setcheckinterval(interval)","if not sys . platform . startswith ( ""java"" ) :",177
631,"def iter_filters(filters, block_end=False):<tab>queue = deque(filters)<tab>while queue:<tab><tab>f = queue.popleft()<tab><tab><IF-STMT><tab><tab><tab>if block_end:<tab><tab><tab><tab>queue.appendleft(None)<tab><tab><tab>for gf in f.filters:<tab><tab><tab><tab>queue.appendleft(gf)<tab><tab>yield f","if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :",105
632,"def smartsplit(code):<tab>""""""Split `code` at "" symbol, only if it is not escaped.""""""<tab>strings = []<tab>pos = 0<tab>while pos < len(code):<tab><tab><IF-STMT><tab><tab><tab>word = """"  # new word<tab><tab><tab>pos += 1<tab><tab><tab>while pos < len(code):<tab><tab><tab><tab>if code[pos] == '""':<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>if code[pos] == ""\\"":<tab><tab><tab><tab><tab>word += ""\\""<tab><tab><tab><tab><tab>pos += 1<tab><tab><tab><tab>word += code[pos]<tab><tab><tab><tab>pos += 1<tab><tab><tab>strings.append('""%s""' % word)<tab><tab>pos += 1<tab>return strings","if code [ pos ] == '""' :",174
633,"def get_folder_content(cls, name):<tab>""""""Return (folders, files) for the given folder in the root dir.""""""<tab>folders = set()<tab>files = set()<tab>for path in cls.LAYOUT:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>parts = path.split(""/"")<tab><tab>if len(parts) == 2:<tab><tab><tab>files.add(parts[1])<tab><tab>else:<tab><tab><tab>folders.add(parts[1])<tab>folders = list(folders)<tab>folders.sort()<tab>files = list(files)<tab>files.sort()<tab>return (folders, files)","if not path . startswith ( name + ""/"" ) :",155
634,"def array_for(self, i):<tab>if 0 <= i < self._cnt:<tab><tab><IF-STMT><tab><tab><tab>return self._tail<tab><tab>node = self._root<tab><tab>level = self._shift<tab><tab>while level > 0:<tab><tab><tab>assert isinstance(node, Node)<tab><tab><tab>node = node._array[(i >> level) & 0x01F]<tab><tab><tab>level -= 5<tab><tab>assert isinstance(node, Node)<tab><tab>return node._array<tab>affirm(False, u""Index out of Range"")",if i >= self . tailoff ( ) :,135
635,"def __or__(self, other) -> ""MultiVector"":<tab>r""""""``self | other``, the inner product :math:`M \cdot N`""""""<tab>other, mv = self._checkOther(other)<tab>if mv:<tab><tab>newValue = self.layout.imt_func(self.value, other.value)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>obj = self.__array__()<tab><tab><tab>return obj | other<tab><tab># l * M = M * l = 0 for scalar l<tab><tab>return self._newMV(dtype=np.result_type(self.value.dtype, other))<tab>return self._newMV(newValue)","if isinstance ( other , np . ndarray ) :",163
636,"def parse_bzr_stats(status):<tab>stats = RepoStats()<tab>statustype = ""changed""<tab>for statusline in status:<tab><tab>if statusline[:2] == ""  "":<tab><tab><tab>setattr(stats, statustype, getattr(stats, statustype) + 1)<tab><tab><IF-STMT><tab><tab><tab>statustype = ""staged""<tab><tab>elif statusline == ""unknown:"":<tab><tab><tab>statustype = ""new""<tab><tab>else:  # removed, missing, renamed, modified or kind changed<tab><tab><tab>statustype = ""changed""<tab>return stats","elif statusline == ""added:"" :",146
637,"def write(self, timestamps, actualValues, predictedValues, predictionStep=1):<tab>assert len(timestamps) == len(actualValues) == len(predictedValues)<tab>for index in range(len(self.names)):<tab><tab>timestamp = timestamps[index]<tab><tab>actual = actualValues[index]<tab><tab>prediction = predictedValues[index]<tab><tab>writer = self.outputWriters[index]<tab><tab><IF-STMT><tab><tab><tab>outputRow = [timestamp, actual, prediction]<tab><tab><tab>writer.writerow(outputRow)<tab><tab><tab>self.lineCounts[index] += 1",if timestamp is not None :,142
638,"def clean(self):<tab>""""""Delete old files in ""tmp"".""""""<tab>now = time.time()<tab>for entry in os.listdir(os.path.join(self._path, ""tmp"")):<tab><tab>path = os.path.join(self._path, ""tmp"", entry)<tab><tab><IF-STMT>  # 60 * 60 * 36<tab><tab><tab>os.remove(path)",if now - os . path . getatime ( path ) > 129600 :,101
639,"def _get_info(self, path):<tab>info = OrderedDict()<tab>if not self._is_mac() or self._has_xcode_tools():<tab><tab>stdout = None<tab><tab>try:<tab><tab><tab>stdout, stderr = Popen(<tab><tab><tab><tab>[self._find_binary(), ""info"", os.path.realpath(path)],<tab><tab><tab><tab>stdout=PIPE,<tab><tab><tab><tab>stderr=PIPE,<tab><tab><tab>).communicate()<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for line in stdout.splitlines():<tab><tab><tab><tab><tab>line = u(line).split("": "", 1)<tab><tab><tab><tab><tab>if len(line) == 2:<tab><tab><tab><tab><tab><tab>info[line[0]] = line[1]<tab>return info",if stdout :,194
640,"def add(meta_list, info_list=None):<tab>if not info_list:<tab><tab>info_list = meta_list<tab>if not isinstance(meta_list, (list, tuple)):<tab><tab>meta_list = (meta_list,)<tab>if not isinstance(info_list, (list, tuple)):<tab><tab>info_list = (info_list,)<tab>for info_f in info_list:<tab><tab><IF-STMT><tab><tab><tab>for meta_f in meta_list:<tab><tab><tab><tab>metadata[meta_f] = info[info_f]<tab><tab><tab>break",if info . get ( info_f ) is not None :,149
641,"def _compute_log_r(model_trace, guide_trace):<tab>log_r = MultiFrameTensor()<tab>stacks = get_plate_stacks(model_trace)<tab>for name, model_site in model_trace.nodes.items():<tab><tab><IF-STMT><tab><tab><tab>log_r_term = model_site[""log_prob""]<tab><tab><tab>if not model_site[""is_observed""]:<tab><tab><tab><tab>log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""]<tab><tab><tab>log_r.add((stacks[name], log_r_term.detach()))<tab>return log_r","if model_site [ ""type"" ] == ""sample"" :",162
642,"def pickline(file, key, casefold=1):<tab>try:<tab><tab>f = open(file, ""r"")<tab>except IOError:<tab><tab>return None<tab>pat = re.escape(key) + "":""<tab>prog = re.compile(pat, casefold and re.IGNORECASE)<tab>while 1:<tab><tab>line = f.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab>if prog.match(line):<tab><tab><tab>text = line[len(key) + 1 :]<tab><tab><tab>while 1:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>text = text + line<tab><tab><tab>return text.strip()<tab>return None",if not line or not line [ 0 ] . isspace ( ) :,182
643,"def build_iterator(data, infinite=True):<tab>""""""Build the iterator for inputs.""""""<tab>index = 0<tab>size = len(data[0])<tab>while True:<tab><tab>if index + batch_size > size:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>index = 0<tab><tab><tab>else:<tab><tab><tab><tab>return<tab><tab>yield data[0][index : index + batch_size], data[1][index : index + batch_size]<tab><tab>index += batch_size",if infinite :,116
644,"def checkall(g, bg, dst_nodes, include_dst_in_src=True):<tab>for etype in g.etypes:<tab><tab>ntype = g.to_canonical_etype(etype)[2]<tab><tab><IF-STMT><tab><tab><tab>check(g, bg, ntype, etype, dst_nodes[ntype], include_dst_in_src)<tab><tab>else:<tab><tab><tab>check(g, bg, ntype, etype, None, include_dst_in_src)",if dst_nodes is not None and ntype in dst_nodes :,124
645,"def minimalBases(classes):<tab>""""""Reduce a list of base classes to its ordered minimum equivalent""""""<tab>if not __python3:  # pragma: no cover<tab><tab>classes = [c for c in classes if c is not ClassType]<tab>candidates = []<tab>for m in classes:<tab><tab>for n in classes:<tab><tab><tab>if issubclass(n, m) and m is not n:<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># m has no subclasses in 'classes'<tab><tab><tab><IF-STMT><tab><tab><tab><tab>candidates.remove(m)  # ensure that we're later in the list<tab><tab><tab>candidates.append(m)<tab>return candidates",if m in candidates :,160
646,"def __keep_songs_enable(self, enabled):<tab>config.set(""memory"", ""queue_keep_songs"", enabled)<tab>if enabled:<tab><tab>self.queue.set_first_column_type(CurrentColumn)<tab>else:<tab><tab>for col in self.queue.get_columns():<tab><tab><tab># Remove the CurrentColum if it exists<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.queue.set_first_column_type(None)<tab><tab><tab><tab>break","if isinstance ( col , CurrentColumn ) :",121
647,"def outlineView_heightOfRowByItem_(self, tree, item) -> float:<tab>default_row_height = self.rowHeight<tab>if item is self:<tab><tab>return default_row_height<tab>heights = [default_row_height]<tab>for column in self.tableColumns:<tab><tab>value = getattr(item.attrs[""node""], str(column.identifier))<tab><tab><IF-STMT><tab><tab><tab># if the cell value is a widget, use its height<tab><tab><tab>heights.append(value._impl.native.intrinsicContentSize().height)<tab>return max(heights)","if isinstance ( value , toga . Widget ) :",146
648,"def condition(self):<tab>if self.__condition is None:<tab><tab><IF-STMT><tab><tab><tab># Avoid an extra indirection in the common case of only one condition.<tab><tab><tab>self.__condition = self.flat_conditions[0]<tab><tab>elif len(self.flat_conditions) == 0:<tab><tab><tab># Possible, if unlikely, due to filter predicate rewriting<tab><tab><tab>self.__condition = lambda _: True<tab><tab>else:<tab><tab><tab>self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions)<tab>return self.__condition",if len ( self . flat_conditions ) == 1 :,143
649,"def _find_delimiter(f, block_size=2 ** 16):<tab>delimiter = b""\n""<tab>if f.tell() == 0:<tab><tab>return 0<tab>while True:<tab><tab>b = f.read(block_size)<tab><tab>if not b:<tab><tab><tab>return f.tell()<tab><tab><IF-STMT><tab><tab><tab>return f.tell() - len(b) + b.index(delimiter) + 1",elif delimiter in b :,105
650,"def serialize(self, name=None):<tab>data = super(SimpleText, self).serialize(name)<tab>data[""contentType""] = self.contentType<tab>data[""content""] = self.content<tab>if self.width:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidWidthException(self.width)<tab><tab>data[""inputOptions""] = {}<tab><tab>data[""width""] = self.width<tab>return data","if self . width not in [ 100 , 50 , 33 , 25 ] :",108
651,"def inference(self):<tab>self.attention_weight_dim = self.input_dims[0][-1]<tab>if self.keep_dim:<tab><tab>self.output_dim = copy.deepcopy(self.input_dims[0])<tab>else:<tab><tab>self.output_dim = []<tab><tab>for idx, dim in enumerate(self.input_dims[0]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.output_dim.append(dim)<tab>super(<tab><tab>LinearAttentionConf, self<tab>).inference()  # PUT THIS LINE AT THE END OF inference()",if idx != len ( self . input_dims [ 0 ] ) - 2 :,152
652,"def __delete_hook(self, rpc):<tab>try:<tab><tab>rpc.check_success()<tab>except apiproxy_errors.Error:<tab><tab>return None<tab>result = []<tab>for status in rpc.response.delete_status_list():<tab><tab>if status == MemcacheDeleteResponse.DELETED:<tab><tab><tab>result.append(DELETE_SUCCESSFUL)<tab><tab><IF-STMT><tab><tab><tab>result.append(DELETE_ITEM_MISSING)<tab><tab>else:<tab><tab><tab>result.append(DELETE_NETWORK_FAILURE)<tab>return result",elif status == MemcacheDeleteResponse . NOT_FOUND :,139
653,def identify_page_at_cursor(self):<tab>for region in self.view.sel():<tab><tab>text_on_cursor = None<tab><tab>pos = region.begin()<tab><tab>scope_region = self.view.extract_scope(pos)<tab><tab><IF-STMT><tab><tab><tab>text_on_cursor = self.view.substr(scope_region)<tab><tab><tab>return text_on_cursor.strip(string.punctuation)<tab>return None,if not scope_region . empty ( ) :,111
654,"def from_elem(cls, parent, when_elem):<tab>""""""Loads the proper when by attributes of elem""""""<tab>when_value = when_elem.get(""value"", None)<tab><IF-STMT><tab><tab>return ValueToolOutputActionConditionalWhen(parent, when_elem, when_value)<tab>else:<tab><tab>when_value = when_elem.get(""datatype_isinstance"", None)<tab><tab>if when_value is not None:<tab><tab><tab>return DatatypeIsInstanceToolOutputActionConditionalWhen(<tab><tab><tab><tab>parent, when_elem, when_value<tab><tab><tab>)<tab>raise TypeError(""When type not implemented"")",if when_value is not None :,151
655,"def test_insert_entity_empty_string_rk(<tab>self, tables_cosmos_account_name, tables_primary_cosmos_account_key):<tab># Arrange<tab>await self._set_up(tables_cosmos_account_name, tables_primary_cosmos_account_key)<tab>try:<tab><tab>entity = {""PartitionKey"": ""pk"", ""RowKey"": """"}<tab><tab># Act<tab><tab>with pytest.raises(HttpResponseError):<tab><tab><tab>await self.table.create_entity(entity=entity)<tab><tab><tab># Assert<tab><tab>#  assert resp is None<tab>finally:<tab><tab>await self._tear_down()<tab><tab><IF-STMT><tab><tab><tab>sleep(SLEEP_DELAY)",if self . is_live :,179
656,"def provider_uris(self):<tab>login_urls = {}<tab>continue_url = self.request.get(""continue_url"")<tab>for provider in self.provider_info:<tab><tab><IF-STMT><tab><tab><tab>login_url = self.uri_for(<tab><tab><tab><tab>""social-login"", provider_name=provider, continue_url=continue_url<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>login_url = self.uri_for(""social-login"", provider_name=provider)<tab><tab>login_urls[provider] = login_url<tab>return login_urls",if continue_url :,140
657,"def expand_extensions(existing):<tab>for name in extension_names:<tab><tab>ext = (<tab><tab><tab>im(""lizard_ext.lizard"" + name.lower()).LizardExtension()<tab><tab><tab><IF-STMT><tab><tab><tab>else name<tab><tab>)<tab><tab>existing.insert(<tab><tab><tab>len(existing) if not hasattr(ext, ""ordering_index"") else ext.ordering_index,<tab><tab><tab>ext,<tab><tab>)<tab>return existing","if isinstance ( name , str )",116
658,"def wrapper(self, *args, **kwargs):<tab>if not self.request.path.endswith(""/""):<tab><tab>if self.request.method in (""GET"", ""HEAD""):<tab><tab><tab>uri = self.request.path + ""/""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab>return<tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)",if self . request . query :,118
659,"def subword_map_by_joiner(subwords, marker=SubwordMarker.JOINER):<tab>""""""Return word id for each subword token (annotate by joiner).""""""<tab>flags = [0] * len(subwords)<tab>for i, tok in enumerate(subwords):<tab><tab><IF-STMT><tab><tab><tab>flags[i] = 1<tab><tab>if tok.startswith(marker):<tab><tab><tab>assert i >= 1 and flags[i - 1] != 1, ""Sentence `{}` not correct!"".format(<tab><tab><tab><tab>"" "".join(subwords)<tab><tab><tab>)<tab><tab><tab>flags[i - 1] = 1<tab>marker_acc = list(accumulate([0] + flags[:-1]))<tab>word_group = [(i - maker_sofar) for i, maker_sofar in enumerate(marker_acc)]<tab>return word_group",if tok . endswith ( marker ) :,193
660,"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab>if i == start:<tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab>if i >= len(self.items):<tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>i += direction<tab><tab>if start < 0:<tab><tab><tab>start = 0",if self . select ( i ) :,194
661,"def get_config(cls):<tab># FIXME: Replace this as soon as we have a config module<tab>config = {}<tab># Try to get iflytek_yuyin config from config<tab>profile_path = dingdangpath.config(""profile.yml"")<tab>if os.path.exists(profile_path):<tab><tab>with open(profile_path, ""r"") as f:<tab><tab><tab>profile = yaml.safe_load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ""vid"" in profile[""iflytek_yuyin""]:<tab><tab><tab><tab><tab>config[""vid""] = profile[""iflytek_yuyin""][""vid""]<tab>return config","if ""iflytek_yuyin"" in profile :",169
662,"def get_signed_in_user(test_case):<tab>playback = not (test_case.is_live or test_case.in_recording)<tab>if playback:<tab><tab>return MOCKED_USER_NAME<tab>else:<tab><tab>account_info = test_case.cmd(""account show"").get_output_in_json()<tab><tab><IF-STMT><tab><tab><tab>return account_info[""user""][""name""]<tab>return None","if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :",115
663,"def rename_project(self, project, new_name):<tab>""""""Rename project, update the related projects if necessary""""""<tab>old_name = project.name<tab>for proj in self.projects:<tab><tab>relproj = proj.get_related_projects()<tab><tab><IF-STMT><tab><tab><tab>relproj[relproj.index(old_name)] = new_name<tab><tab><tab>proj.set_related_projects(relproj)<tab>project.rename(new_name)<tab>self.save()",if old_name in relproj :,121
664,"def test_call_extern_c_fn(self):<tab>global memcmp<tab>memcmp = cffi_support.ExternCFunction(<tab><tab>""memcmp"",<tab><tab>(""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""),<tab>)<tab>@udf(BooleanVal(FunctionContext, StringVal, StringVal))<tab>def fn(context, a, b):<tab><tab>if a.is_null != b.is_null:<tab><tab><tab>return False<tab><tab>if a is None:<tab><tab><tab>return True<tab><tab>if len(a) != b.len:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>return memcmp(a.ptr, b.ptr, a.len) == 0",if a . ptr == b . ptr :,199
665,"def parse_variable(self):<tab>begin = self._pos<tab>while True:<tab><tab>ch = self.read()<tab><tab><IF-STMT><tab><tab><tab>return ScriptVariable(self._text[begin : self._pos - 1])<tab><tab>elif ch is None:<tab><tab><tab>self.__raise_eof()<tab><tab>elif not isidentif(ch) and ch != "":"":<tab><tab><tab>self.__raise_char(ch)","if ch == ""%"" :",101
666,"def h_file(self):<tab>filename = self.abspath()<tab>st = os.stat(filename)<tab>cache = self.ctx.hashes_md5_tstamp<tab>if filename in cache and cache[filename][0] == st.st_mtime:<tab><tab>return cache[filename][1]<tab>if STRONGEST:<tab><tab>ret = Utils.h_file(filename)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""Not a file"")<tab><tab>ret = Utils.md5(str((st.st_mtime, st.st_size)).encode()).digest()<tab>cache[filename] = (st.st_mtime, ret)<tab>return ret",if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,172
667,"def add_widgets(self, *widgets_or_spacings):<tab>""""""Add widgets/spacing to dialog vertical layout""""""<tab>layout = self.layout()<tab>for widget_or_spacing in widgets_or_spacings:<tab><tab><IF-STMT><tab><tab><tab>layout.addSpacing(widget_or_spacing)<tab><tab>else:<tab><tab><tab>layout.addWidget(widget_or_spacing)","if isinstance ( widget_or_spacing , int ) :",103
668,"def _str_index(self):<tab>idx = self[""index""]<tab>out = []<tab>if len(idx) == 0:<tab><tab>return out<tab>out += ["".. index:: %s"" % idx.get(""default"", """")]<tab>for section, references in idx.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif section == ""refguide"":<tab><tab><tab>out += [""   single: %s"" % ("", "".join(references))]<tab><tab>else:<tab><tab><tab>out += [""   %s: %s"" % (section, "","".join(references))]<tab>return out","if section == ""default"" :",145
669,"def dictify_CPPDEFINES(env):<tab>cppdefines = env.get(""CPPDEFINES"", {})<tab>if cppdefines is None:<tab><tab>return {}<tab>if SCons.Util.is_Sequence(cppdefines):<tab><tab>result = {}<tab><tab>for c in cppdefines:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[c[0]] = c[1]<tab><tab><tab>else:<tab><tab><tab><tab>result[c] = None<tab><tab>return result<tab>if not SCons.Util.is_Dict(cppdefines):<tab><tab>return {cppdefines: None}<tab>return cppdefines",if SCons . Util . is_Sequence ( c ) :,155
670,"def decoder(s):<tab>r = []<tab>decode = []<tab>for c in s:<tab><tab>if c == ""&"" and not decode:<tab><tab><tab>decode.append(""&"")<tab><tab>elif c == ""-"" and decode:<tab><tab><tab>if len(decode) == 1:<tab><tab><tab><tab>r.append(""&"")<tab><tab><tab>else:<tab><tab><tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab><tab><tab>decode = []<tab><tab><IF-STMT><tab><tab><tab>decode.append(c)<tab><tab>else:<tab><tab><tab>r.append(c)<tab>if decode:<tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab>bin_str = """".join(r)<tab>return (bin_str, len(s))",elif decode :,188
671,"def optimize(self, graph: Graph):<tab>MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE<tab>flag_changed = False<tab>for v in traverse.listup_variables(graph):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>height, width = TextureShape.get(v)<tab><tab>if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE:<tab><tab><tab>continue<tab><tab>if not v.has_attribute(SplitTarget):<tab><tab><tab>flag_changed = True<tab><tab><tab>v.attributes.add(SplitTarget())<tab>return graph, flag_changed",if not Placeholder . check_resolved ( v . size ) :,157
672,"def one_gpr_reg_one_mem_scalable(ii):<tab>n, r = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_agen(op) or (op_mem(op) and op.oc2 in [""v""]):<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>r += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and r == 1",elif op_gprv ( op ) :,113
673,"def get_genome_dir(gid, galaxy_dir, data):<tab>""""""Return standard location of genome directories.""""""<tab>if galaxy_dir:<tab><tab>refs = genome.get_refs(gid, None, galaxy_dir, data)<tab><tab>seq_file = tz.get_in([""fasta"", ""base""], refs)<tab><tab>if seq_file and os.path.exists(seq_file):<tab><tab><tab>return os.path.dirname(os.path.dirname(seq_file))<tab>else:<tab><tab>gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid))<tab><tab><IF-STMT><tab><tab><tab>return gdirs[0]",if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) :,190
674,"def __modules(self):<tab>raw_output = self.__module_avail_output().decode(""utf-8"")<tab>for line in StringIO(raw_output):<tab><tab>line = line and line.strip()<tab><tab>if not line or line.startswith(""-""):<tab><tab><tab>continue<tab><tab>line_modules = line.split()<tab><tab>for module in line_modules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>module = module[0 : -len(self.default_indicator)].strip()<tab><tab><tab>module_parts = module.split(""/"")<tab><tab><tab>module_version = None<tab><tab><tab>if len(module_parts) == 2:<tab><tab><tab><tab>module_version = module_parts[1]<tab><tab><tab>module_name = module_parts[0]<tab><tab><tab>yield module_name, module_version",if module . endswith ( self . default_indicator ) :,199
675,"def save(self):<tab>updates = self.cinder_obj_get_changes()<tab>if updates:<tab><tab><IF-STMT><tab><tab><tab>metadata = updates.pop(""metadata"", None)<tab><tab><tab>self.metadata = db.backup_metadata_update(<tab><tab><tab><tab>self._context, self.id, metadata, True<tab><tab><tab>)<tab><tab>updates.pop(""parent"", None)<tab><tab>db.backup_update(self._context, self.id, updates)<tab>self.obj_reset_changes()","if ""metadata"" in updates :",127
676,"def test_set_tag(association_obj, sagemaker_session):<tab>tag = {""Key"": ""foo"", ""Value"": ""bar""}<tab>association_obj.set_tag(tag)<tab>while True:<tab><tab>actual_tags = sagemaker_session.sagemaker_client.list_tags(<tab><tab><tab>ResourceArn=association_obj.source_arn<tab><tab>)[""Tags""]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(5)<tab># When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints,<tab># length of actual tags will be greater than 1<tab>assert len(actual_tags) > 0<tab>assert actual_tags[0] == tag",if actual_tags :,175
677,"def test_error_stream(environ, start_response):<tab>writer = start_response(""200 OK"", [])<tab>wsgi_errors = environ[""wsgi.errors""]<tab>error_msg = None<tab>for method in [<tab><tab>""flush"",<tab><tab>""write"",<tab><tab>""writelines"",<tab>]:<tab><tab>if not hasattr(wsgi_errors, method):<tab><tab><tab>error_msg = ""wsgi.errors has no '%s' attr"" % method<tab><tab><IF-STMT><tab><tab><tab>error_msg = ""wsgi.errors.%s attr is not callable"" % method<tab><tab>if error_msg:<tab><tab><tab>break<tab>return_msg = error_msg or ""success""<tab>writer(return_msg)<tab>return []","if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :",185
678,"def current_dict(cursor_offset, line):<tab>""""""If in dictionary completion, return the dict that should be used""""""<tab>for m in current_dict_re.finditer(line):<tab><tab><IF-STMT><tab><tab><tab>return LinePart(m.start(1), m.end(1), m.group(1))<tab>return None",if m . start ( 2 ) <= cursor_offset and m . end ( 2 ) >= cursor_offset :,99
679,"def show_file_browser(self):<tab>""""""Show/hide the file browser.""""""<tab>if self.show_file_browser_action.isChecked():<tab><tab>sizes = self.panel.sizes()<tab><tab><IF-STMT><tab><tab><tab>sizes[0] = sum(sizes) // 4<tab><tab><tab>self.panel.setSizes(sizes)<tab><tab>self.file_browser.show()<tab>else:<tab><tab>self.file_browser.hide()",if sizes [ 0 ] == 0 :,112
680,"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>items.append(item.nameEncoded())<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",if len ( items ) > 1 :,114
681,"def prepend(self, value):<tab>""""""prepend value to nodes""""""<tab>root, root_text = self._get_root(value)<tab>for i, tag in enumerate(self):<tab><tab><IF-STMT><tab><tab><tab>tag.text = """"<tab><tab>if len(root) > 0:<tab><tab><tab>root[-1].tail = tag.text<tab><tab><tab>tag.text = root_text<tab><tab>else:<tab><tab><tab>tag.text = root_text + tag.text<tab><tab>if i > 0:<tab><tab><tab>root = deepcopy(list(root))<tab><tab>tag[:0] = root<tab><tab>root = tag[: len(root)]<tab>return self",if not tag . text :,160
682,"def getLabel(self, address=None):<tab>if address is None:<tab><tab>address = self.address<tab>label = address<tab>if shared.config.has_section(address):<tab><tab>label = shared.config.get(address, ""label"")<tab>queryreturn = sqlQuery(""""""select label from addressbook where address=?"""""", address)<tab><IF-STMT><tab><tab>for row in queryreturn:<tab><tab><tab>(label,) = row<tab>else:<tab><tab>queryreturn = sqlQuery(<tab><tab><tab>""""""select label from subscriptions where address=?"""""", address<tab><tab>)<tab><tab>if queryreturn != []:<tab><tab><tab>for row in queryreturn:<tab><tab><tab><tab>(label,) = row<tab>return label",if queryreturn != [ ] :,168
683,"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab>if ""axis"" in self.args:<tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab>if not isinstance(self.axis, int):<tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab><IF-STMT><tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab>if not isinstance(self.momentum, (int, float)):<tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')","if ""momentum"" in self . args :",157
684,"def urlquote(*args, **kwargs):<tab>new_kwargs = dict(kwargs)<tab>if not PY3:<tab><tab>new_kwargs = dict(kwargs)<tab><tab>if ""encoding"" in new_kwargs:<tab><tab><tab>del new_kwargs[""encoding""]<tab><tab><IF-STMT><tab><tab><tab>del new_kwargs[""errors""]<tab>return quote(*args, **new_kwargs)","if ""errors"" in kwargs :",93
685,"def setNextFormPrevious(self, backup=STARTING_FORM):<tab>try:<tab><tab>if self._THISFORM.FORM_NAME == self._FORM_VISIT_LIST[-1]:<tab><tab><tab>self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list<tab><tab><IF-STMT><tab><tab><tab># take no action if it looks as if someone has already set the next form.<tab><tab><tab>self.setNextForm(<tab><tab><tab><tab>self._FORM_VISIT_LIST.pop()<tab><tab><tab>)  # Switch to the previous form if one exists<tab>except IndexError:<tab><tab>self.setNextForm(backup)",if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM :,178
686,"def iter_chars_to_words(self, chars):<tab>current_word = []<tab>for char in chars:<tab><tab>if not self.keep_blank_chars and char[""text""].isspace():<tab><tab><tab>if current_word:<tab><tab><tab><tab>yield current_word<tab><tab><tab><tab>current_word = []<tab><tab><IF-STMT><tab><tab><tab>yield current_word<tab><tab><tab>current_word = [char]<tab><tab>else:<tab><tab><tab>current_word.append(char)<tab>if current_word:<tab><tab>yield current_word","elif current_word and self . char_begins_new_word ( current_word , char ) :",150
687,"def get(self):<tab>""""""return a secret by name""""""<tab>results = self._get(""secrets"", self.name)<tab>results[""decoded""] = {}<tab>results[""exists""] = False<tab>if results[""returncode""] == 0 and results[""results""][0]:<tab><tab>results[""exists""] = True<tab><tab><IF-STMT><tab><tab><tab>if ""data"" in results[""results""][0]:<tab><tab><tab><tab>for sname, value in results[""results""][0][""data""].items():<tab><tab><tab><tab><tab>results[""decoded""][sname] = base64.b64decode(value)<tab>if results[""returncode""] != 0 and '""%s"" not found' % self.name in results[""stderr""]:<tab><tab>results[""returncode""] = 0<tab>return results",if self . decode :,173
688,"def insert_use(self, edit):<tab>if self.is_first_use():<tab><tab>for location in [r""^\s*namespace\s+[\w\\]+[;{]"", r""<\?php""]:<tab><tab><tab>inserted = self.insert_first_use(location, edit)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>else:<tab><tab>self.insert_use_among_others(edit)",if inserted :,99
689,"def _new_rsa_key(spec):<tab>if ""name"" not in spec:<tab><tab><IF-STMT><tab><tab><tab>(head, tail) = os.path.split(spec[""key""])<tab><tab><tab>spec[""path""] = head<tab><tab><tab>spec[""name""] = tail<tab><tab>else:<tab><tab><tab>spec[""name""] = spec[""key""]<tab>return rsa_init(spec)","if ""/"" in spec [ ""key"" ] :",98
690,"def mimeData(self, indexes):<tab>if len(indexes) == 1:<tab><tab>index = indexes[0]<tab><tab>model = song = index.data(Qt.UserRole)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>model = song.album<tab><tab><tab>except (ProviderIOError, Exception):<tab><tab><tab><tab>model = None<tab><tab>return ModelMimeData(model)",if index . column ( ) == Column . album :,103
691,"def get(self, url, **kwargs):<tab>app, url = self._prepare_call(url, kwargs)<tab>if app:<tab><tab>if url.endswith(""ping"") and self._first_ping:<tab><tab><tab>self._first_ping = False<tab><tab><tab>return EmptyCapabilitiesResponse()<tab><tab><IF-STMT><tab><tab><tab>return ErrorApiResponse()<tab><tab>else:<tab><tab><tab>response = app.get(url, **kwargs)<tab><tab><tab>return TestingResponse(response)<tab>else:<tab><tab>return requests.get(url, **kwargs)","elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :",153
692,"def handle_noargs(self, **options):<tab>self.style = color_style()<tab>print(""Running Django's own validation:"")<tab>self.validate(display_num_errors=True)<tab>for model in loading.get_models():<tab><tab>if hasattr(model, ""_create_content_base""):<tab><tab><tab>self.validate_base_model(model)<tab><tab><IF-STMT><tab><tab><tab>self.validate_content_type(model)","if hasattr ( model , ""_feincms_content_models"" ) :",117
693,"def test_rules_widget(self):<tab>subreddit = self.reddit.subreddit(pytest.placeholders.test_subreddit)<tab>widgets = subreddit.widgets<tab>with self.use_cassette(""TestSubredditWidgets.fetch_widgets""):<tab><tab>rules = None<tab><tab>for widget in widgets.sidebar:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rules = widget<tab><tab><tab><tab>break<tab><tab>assert isinstance(rules, RulesWidget)<tab><tab>assert rules == rules<tab><tab>assert rules.id == rules<tab><tab>assert rules.display<tab><tab>assert len(rules) > 0<tab><tab>assert subreddit == rules.subreddit","if isinstance ( widget , RulesWidget ) :",173
694,"def __init__(self, exception):<tab>message = str(exception)<tab>with contextlib.suppress(IndexError):<tab><tab>underlying_exception = exception.args[0]<tab><tab><IF-STMT><tab><tab><tab>message = (<tab><tab><tab><tab>""maximum retries exceeded trying to reach the store.\n""<tab><tab><tab><tab>""Check your network connection, and check the store ""<tab><tab><tab><tab>""status at {}"".format(_STORE_STATUS_URL)<tab><tab><tab>)<tab>super().__init__(message=message)","if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :",130
695,"def wrapped(self, request):<tab>try:<tab><tab>return self._finished<tab>except AttributeError:<tab><tab>if self.node_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.debug(<tab><tab><tab><tab><tab>""%s is still going to be used, not terminating it. ""<tab><tab><tab><tab><tab>""Still in use on:\n%s"",<tab><tab><tab><tab><tab>self,<tab><tab><tab><tab><tab>pprint.pformat(list(self.node_ids)),<tab><tab><tab><tab>)<tab><tab><tab><tab>return<tab><tab>log.debug(""Finish called on %s"", self)<tab><tab>try:<tab><tab><tab>return func(request)<tab><tab>finally:<tab><tab><tab>self._finished = True",if not request . session . shouldfail and not request . session . shouldstop :,185
696,"def get_min_vertical_scroll() -> int:<tab># Make sure that the cursor line is not below the bottom.<tab># (Calculate how many lines can be shown between the cursor and the .)<tab>used_height = 0<tab>prev_lineno = ui_content.cursor_position.y<tab>for lineno in range(ui_content.cursor_position.y, -1, -1):<tab><tab>used_height += get_line_height(lineno)<tab><tab><IF-STMT><tab><tab><tab>return prev_lineno<tab><tab>else:<tab><tab><tab>prev_lineno = lineno<tab>return 0",if used_height > height - scroll_offsets_bottom :,148
697,"def cookies(self):<tab># strip cookie_suffix from all cookies in the request, return result<tab>cookies = flask.Request.cookies.__get__(self)<tab>result = {}<tab>desuffixed = {}<tab>for key, value in cookies.items():<tab><tab><IF-STMT><tab><tab><tab>desuffixed[key[: -len(self.cookie_suffix)]] = value<tab><tab>else:<tab><tab><tab>result[key] = value<tab>result.update(desuffixed)<tab>return result",if key . endswith ( self . cookie_suffix ) :,123
698,"def update_vars(state1, state2):<tab>ops = []<tab>for name in state1._fields:<tab><tab>state1_vs = getattr(state1, name)<tab><tab><IF-STMT><tab><tab><tab>ops += [<tab><tab><tab><tab>tf.assign(_v1, _v2)<tab><tab><tab><tab>for _v1, _v2 in zip(state1_vs, getattr(state2, name))<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>ops += [tf.assign(state1_vs, getattr(state2, name))]<tab>return tf.group(*ops)","if isinstance ( state1_vs , list ) :",148
699,"def manifest(self):<tab>""""""The current manifest dictionary.""""""<tab>if self.reload:<tab><tab><IF-STMT><tab><tab><tab>return {}<tab><tab>mtime = self.getmtime(self.manifest_path)<tab><tab>if self._mtime is None or mtime > self._mtime:<tab><tab><tab>self._manifest = self.get_manifest()<tab><tab><tab>self._mtime = mtime<tab>return self._manifest",if not self . exists ( self . manifest_path ) :,102
700,"def csvtitle(self):<tab>if isinstance(self.name, six.string_types):<tab><tab>return '""' + self.name + '""' + char[""sep""] * (len(self.nick) - 1)<tab>else:<tab><tab>ret = """"<tab><tab>for i, name in enumerate(self.name):<tab><tab><tab>ret = ret + '""' + name + '""' + char[""sep""] * (len(self.nick) - 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = ret + char[""sep""]<tab><tab>return ret",if i + 1 != len ( self . name ) :,135
701,"def cache_dst(self):<tab>final_dst = None<tab>final_linenb = None<tab>for linenb, assignblk in enumerate(self):<tab><tab>for dst, src in viewitems(assignblk):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if final_dst is not None:<tab><tab><tab><tab><tab>raise ValueError(""Multiple destinations!"")<tab><tab><tab><tab>final_dst = src<tab><tab><tab><tab>final_linenb = linenb<tab>self._dst = final_dst<tab>self._dst_linenb = final_linenb<tab>return final_dst","if dst . is_id ( ""IRDst"" ) :",144
702,"def _ProcessName(self, name, dependencies):<tab>""""""Retrieve a module name from a node name.""""""<tab>module_name, dot, base_name = name.rpartition(""."")<tab>if dot:<tab><tab><IF-STMT><tab><tab><tab>if module_name in dependencies:<tab><tab><tab><tab>dependencies[module_name].add(base_name)<tab><tab><tab>else:<tab><tab><tab><tab>dependencies[module_name] = {base_name}<tab><tab>else:<tab><tab><tab># If we have a relative import that did not get qualified (usually due<tab><tab><tab># to an empty package_name), don't insert module_name='' into the<tab><tab><tab># dependencies; we get a better error message if we filter it out here<tab><tab><tab># and fail later on.<tab><tab><tab>logging.warning(""Empty package name: %s"", name)",if module_name :,196
703,"def get_aa_from_codonre(re_aa):<tab>aas = []<tab>m = 0<tab>for i in re_aa:<tab><tab>if i == ""["":<tab><tab><tab>m = -1<tab><tab><tab>aas.append("""")<tab><tab>elif i == ""]"":<tab><tab><tab>m = 0<tab><tab><tab>continue<tab><tab>elif m == -1:<tab><tab><tab>aas[-1] = aas[-1] + i<tab><tab><IF-STMT><tab><tab><tab>aas.append(i)<tab>return aas",elif m == 0 :,129
704,"def logic():<tab>count = intbv(0, min=0, max=MAXVAL + 1)<tab>while True:<tab><tab>yield clock.posedge, reset.posedge<tab><tab>if reset == 1:<tab><tab><tab>count[:] = 0<tab><tab>else:<tab><tab><tab>flag.next = 0<tab><tab><tab><IF-STMT><tab><tab><tab><tab>flag.next = 1<tab><tab><tab><tab>count[:] = 0<tab><tab><tab>else:<tab><tab><tab><tab>count += 1",if count == MAXVAL :,115
705,"def _history_define_metric(<tab>self, hkey: str) -> Optional[wandb_internal_pb2.MetricRecord]:<tab>""""""check for hkey match in glob metrics, return defined metric.""""""<tab># Dont define metric for internal metrics<tab>if hkey.startswith(""_""):<tab><tab>return None<tab>for k, mglob in six.iteritems(self._metric_globs):<tab><tab>if k.endswith(""*""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>m = wandb_internal_pb2.MetricRecord()<tab><tab><tab><tab>m.CopyFrom(mglob)<tab><tab><tab><tab>m.ClearField(""glob_name"")<tab><tab><tab><tab>m.name = hkey<tab><tab><tab><tab>return m<tab>return None",if hkey . startswith ( k [ : - 1 ] ) :,180
706,"def optimize_models(args, use_cuda, models):<tab>""""""Optimize ensemble for generation""""""<tab>for model in models:<tab><tab>model.make_generation_fast_(<tab><tab><tab>beamable_mm_beam_size=None if args.no_beamable_mm else args.beam,<tab><tab><tab>need_attn=args.print_alignment,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>model.half()<tab><tab>if use_cuda:<tab><tab><tab>model.cuda()",if args . fp16 :,122
707,"def _Dynamic_Rollback(self, transaction, transaction_response):<tab>txid = transaction.handle()<tab>self.__local_tx_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise apiproxy_errors.ApplicationError(<tab><tab><tab><tab>datastore_pb.Error.BAD_REQUEST, ""Transaction %d not found."" % (txid,)<tab><tab><tab>)<tab><tab>txdata = self.__transactions[txid]<tab><tab>assert (<tab><tab><tab>txdata.thread_id == thread.get_ident()<tab><tab>), ""Transactions are single-threaded.""<tab><tab>del self.__transactions[txid]<tab>finally:<tab><tab>self.__local_tx_lock.release()",if txid not in self . __transactions :,174
708,"def get_job_dirs(path):<tab>regex = re.compile(""[1-9][0-9]*-"")<tab>jobdirs = []<tab>for d in os.listdir(path):<tab><tab># skip directories not matching the job result dir pattern<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d = os.path.join(options.resultsdir, d)<tab><tab>if os.path.isdir(d) and not os.path.exists(os.path.join(d, PUBLISH_FLAGFILE)):<tab><tab><tab>jobdirs.append(d)<tab>return jobdirs",if not regex . match ( d ) :,141
709,"def traverse(node, functions=[]):<tab>if hasattr(node, ""grad_fn""):<tab><tab>node = node.grad_fn<tab>if hasattr(node, ""variable""):<tab><tab>node = graph.nodes_by_id.get(id(node.variable))<tab><tab>if node:<tab><tab><tab>node.functions = list(functions)<tab><tab><tab>del functions[:]<tab>if hasattr(node, ""next_functions""):<tab><tab>functions.append(type(node).__name__)<tab><tab>for f in node.next_functions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(type(f[0]).__name__)<tab><tab><tab><tab>traverse(f[0], functions)<tab>if hasattr(node, ""saved_tensors""):<tab><tab>for t in node.saved_tensors:<tab><tab><tab>traverse(t)",if f [ 0 ] :,195
710,"def get_all_snap_points(self, forts):<tab>points = []<tab>radius = Constants.MAX_DISTANCE_FORT_IS_REACHABLE<tab>for i in range(0, len(forts)):<tab><tab>for j in range(i + 1, len(forts)):<tab><tab><tab>c1, c2 = self.get_enclosing_circles(forts[i], forts[j], radius)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>points.append((c1, c2, forts[i], forts[j]))<tab>return points",if c1 and c2 :,142
711,"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab>if not isinstance(child, minidom.Element):<tab><tab><tab>continue<tab><tab>if child.tagName == ""Directory"":<tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if grandchild.tagName != ""File"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if not isinstance ( grandchild , minidom . Element ) :",152
712,"def computeLeadingWhitespaceWidth(s, tab_width):<tab>w = 0<tab>for ch in s:<tab><tab>if ch == "" "":<tab><tab><tab>w += 1<tab><tab><IF-STMT><tab><tab><tab>w += abs(tab_width) - (w % abs(tab_width))<tab><tab>else:<tab><tab><tab>break<tab>return w","elif ch == ""\t"" :",87
713,"def test_avg_group_by(self):<tab>ret = (<tab><tab>await Book.annotate(avg=Avg(""rating""))<tab><tab>.group_by(""author_id"")<tab><tab>.values(""author_id"", ""avg"")<tab>)<tab>for item in ret:<tab><tab>author_id = item.get(""author_id"")<tab><tab>avg = item.get(""avg"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(avg, 4.5)<tab><tab>elif author_id == self.a2.pk:<tab><tab><tab>self.assertEqual(avg, 2.0)",if author_id == self . a1 . pk :,150
714,"def open_session(self, app, request):<tab>sid = request.cookies.get(app.session_cookie_name)<tab>if sid:<tab><tab>stored_session = self.cls.objects(sid=sid).first()<tab><tab><IF-STMT><tab><tab><tab>expiration = stored_session.expiration<tab><tab><tab>if not expiration.tzinfo:<tab><tab><tab><tab>expiration = expiration.replace(tzinfo=utc)<tab><tab><tab>if expiration > datetime.datetime.utcnow().replace(tzinfo=utc):<tab><tab><tab><tab>return MongoEngineSession(<tab><tab><tab><tab><tab>initial=stored_session.data, sid=stored_session.sid<tab><tab><tab><tab>)<tab>return MongoEngineSession(sid=str(uuid.uuid4()))",if stored_session :,174
715,"def one_line_description(self):<tab>MAX_LINE_LENGTH = 120<tab>desc = util.remove_html_tags(self.description or """")<tab>desc = re.sub(""\s+"", "" "", desc).strip()<tab>if not desc:<tab><tab>return _(""No description available"")<tab>else:<tab><tab># Decode the description to avoid gPodder bug 1277<tab><tab>desc = util.convert_bytes(desc).strip()<tab><tab><IF-STMT><tab><tab><tab>return desc[:MAX_LINE_LENGTH] + ""...""<tab><tab>else:<tab><tab><tab>return desc",if len ( desc ) > MAX_LINE_LENGTH :,142
716,"def setInnerHTML(self, html):<tab>log.HTMLClassifier.classify(<tab><tab>log.ThugLogging.url if log.ThugOpts.local else log.last_url, html<tab>)<tab>self.tag.clear()<tab>for node in bs4.BeautifulSoup(html, ""html.parser"").contents:<tab><tab>self.tag.append(node)<tab><tab>name = getattr(node, ""name"", None)<tab><tab>if name is None:<tab><tab><tab>continue<tab><tab>handler = getattr(log.DFT, ""handle_%s"" % (name,), None)<tab><tab><IF-STMT><tab><tab><tab>handler(node)",if handler :,151
717,def get_supported_period_type_map(cls):<tab>if cls.supported_period_map is None:<tab><tab>cls.supported_period_map = {}<tab><tab>cls.supported_period_map.update(cls.period_type_map)<tab><tab>try:<tab><tab><tab>from dateutil import relativedelta<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls.supported_period_map.update(cls.optional_period_type_map)<tab><tab>except Exception:<tab><tab><tab>pass<tab>return cls.supported_period_map,if relativedelta is not None :,131
718,"def _compare_single_run(self, compares_done):<tab>try:<tab><tab>compare_id, redo = self.in_queue.get(<tab><tab><tab>timeout=float(self.config[""ExpertSettings""][""block_delay""])<tab><tab>)<tab>except Empty:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if redo:<tab><tab><tab><tab>self.db_interface.delete_old_compare_result(compare_id)<tab><tab><tab>compares_done.add(compare_id)<tab><tab><tab>self._process_compare(compare_id)<tab><tab><tab>if self.callback:<tab><tab><tab><tab>self.callback()","if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :",177
719,"def _get_field_actual(cant_be_number, raw_string, field_names):<tab>for line in raw_string.splitlines():<tab><tab>for field_name in field_names:<tab><tab><tab>field_name = field_name.lower()<tab><tab><tab>if "":"" in line:<tab><tab><tab><tab>left, right = line.split("":"", 1)<tab><tab><tab><tab>left = left.strip().lower()<tab><tab><tab><tab>right = right.strip()<tab><tab><tab><tab>if left == field_name and len(right) > 0:<tab><tab><tab><tab><tab>if cant_be_number:<tab><tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab><tab>return right<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return right<tab>return None",if not right . isdigit ( ) :,184
720,"def _p_basicstr_content(s, content=_basicstr_re):<tab>res = []<tab>while True:<tab><tab>res.append(s.expect_re(content).group(0))<tab><tab>if not s.consume(""\\""):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re):<tab><tab><tab>res.append(_chr(int(s.last().group(1), 16)))<tab><tab>else:<tab><tab><tab>s.expect_re(_escapes_re)<tab><tab><tab>res.append(_escapes[s.last().group(0)])<tab>return """".join(res)",if s . consume_re ( _newline_esc_re ) :,179
721,"def removedir(self, path):<tab># type: (Text) -> None<tab>_path = self.validatepath(path)<tab>if _path == ""/"":<tab><tab>raise errors.RemoveRootError()<tab>with ftp_errors(self, path):<tab><tab>try:<tab><tab><tab>self.ftp.rmd(_encode(_path, self.ftp.encoding))<tab><tab>except error_perm as error:<tab><tab><tab>code, _ = _parse_ftp_error(error)<tab><tab><tab>if code == ""550"":<tab><tab><tab><tab>if self.isfile(path):<tab><tab><tab><tab><tab>raise errors.DirectoryExpected(path)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise errors.DirectoryNotEmpty(path)<tab><tab><tab>raise  # pragma: no cover",if not self . isempty ( path ) :,189
722,"def _normalize_store_path(self, resource_store):<tab>if resource_store[""type""] == ""filesystem"":<tab><tab><IF-STMT><tab><tab><tab>resource_store[""base_directory""] = os.path.join(<tab><tab><tab><tab>self.root_directory, resource_store[""base_directory""]<tab><tab><tab>)<tab>return resource_store","if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :",96
723,"def _apply_nested(name, val, nested):<tab>parts = name.split(""."")<tab>cur = nested<tab>for i in range(0, len(parts) - 1):<tab><tab>cur = cur.setdefault(parts[i], {})<tab><tab><IF-STMT><tab><tab><tab>conflicts_with = ""."".join(parts[0 : i + 1])<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""%r cannot be nested: conflicts with {%r: %s}""<tab><tab><tab><tab>% (name, conflicts_with, cur)<tab><tab><tab>)<tab>cur[parts[-1]] = val","if not isinstance ( cur , dict ) :",142
724,"def build_packages(targeted_packages, distribution_directory, is_dev_build=False):<tab># run the build and distribution<tab>for package_root in targeted_packages:<tab><tab>service_hierarchy = os.path.join(os.path.basename(package_root))<tab><tab><IF-STMT><tab><tab><tab>verify_update_package_requirement(package_root)<tab><tab>print(""Generating Package Using Python {}"".format(sys.version))<tab><tab>run_check_call(<tab><tab><tab>[<tab><tab><tab><tab>sys.executable,<tab><tab><tab><tab>build_packing_script_location,<tab><tab><tab><tab>""--dest"",<tab><tab><tab><tab>os.path.join(distribution_directory, service_hierarchy),<tab><tab><tab><tab>package_root,<tab><tab><tab>],<tab><tab><tab>root_dir,<tab><tab>)",if is_dev_build :,199
725,"def resolve_root_node_address(self, root_node):<tab>if ""["" in root_node:<tab><tab>name, numbers = root_node.split(""["", maxsplit=1)<tab><tab>number = numbers.split("","", maxsplit=1)[0]<tab><tab><IF-STMT><tab><tab><tab>number = number.split(""-"")[0]<tab><tab>number = re.sub(""[^0-9]"", """", number)<tab><tab>root_node = name + number<tab>return root_node","if ""-"" in number :",109
726,"def _map_args(maps: dict, **kwargs):<tab># maps: key=old name, value= new name<tab>output = {}<tab>for name, val in kwargs.items():<tab><tab>if name in maps:<tab><tab><tab>assert isinstance(maps[name], str)<tab><tab><tab>output.update({maps[name]: val})<tab><tab>else:<tab><tab><tab>output.update({name: val})<tab>for keys in maps.keys():<tab><tab><IF-STMT><tab><tab><tab>pass<tab>return output",if keys not in output . keys ( ) :,125
727,"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab>if i == start:<tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab>if self.select(i):<tab><tab><tab>break<tab><tab>i += direction<tab><tab>if start < 0:<tab><tab><tab>start = 0",if i >= len ( self . items ) :,194
728,"def detect_reentrancy(self, contract):<tab>for function in contract.functions_and_modifiers_declared:<tab><tab><IF-STMT><tab><tab><tab>if self.KEY in function.context:<tab><tab><tab><tab>continue<tab><tab><tab>self._explore(function.entry_point, [])<tab><tab><tab>function.context[self.KEY] = True",if function . is_implemented :,87
729,"def load_model(self):<tab>if not os.path.exists(self.get_filename(absolute=True)):<tab><tab><IF-STMT><tab><tab><tab>return {}, {}<tab><tab>error(<tab><tab><tab>""Model file with pre-trained convolution layers not found. Download it here..."",<tab><tab><tab>""https://github.com/alexjc/neural-enhance/releases/download/v%s/%s""<tab><tab><tab>% (__version__, self.get_filename()),<tab><tab>)<tab>print(""  - Loaded file `{}` with trained model."".format(self.get_filename()))<tab>return pickle.load(bz2.open(self.get_filename(), ""rb""))",if args . train :,158
730,"def get_nonexisting_check_definition_extends(definition, indexed_oval_defs):<tab># TODO: handle multiple levels of referrals.<tab># OVAL checks that go beyond one level of extend_definition won't be properly identified<tab>for extdefinition in definition.findall("".//{%s}extend_definition"" % oval_ns):<tab><tab># Verify each extend_definition in the definition<tab><tab>extdefinitionref = extdefinition.get(""definition_ref"")<tab><tab># Search the OVAL tree for a definition with the referred ID<tab><tab>referreddefinition = indexed_oval_defs.get(extdefinitionref)<tab><tab><IF-STMT><tab><tab><tab># There is no oval satisfying the extend_definition referal<tab><tab><tab>return extdefinitionref<tab>return None",if referreddefinition is None :,177
731,"def pause(self):<tab>if self.is_playing:<tab><tab>self.state = MusicPlayerState.PAUSED<tab><tab><IF-STMT><tab><tab><tab>self._current_player.pause()<tab><tab>self.emit(""pause"", player=self, entry=self.current_entry)<tab><tab>return<tab>elif self.is_paused:<tab><tab>return<tab>raise ValueError(""Cannot pause a MusicPlayer in state %s"" % self.state)",if self . _current_player :,107
732,"def setNextFormPrevious(self, backup=STARTING_FORM):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list<tab><tab>if self._THISFORM.FORM_NAME == self.NEXT_ACTIVE_FORM:<tab><tab><tab># take no action if it looks as if someone has already set the next form.<tab><tab><tab>self.setNextForm(<tab><tab><tab><tab>self._FORM_VISIT_LIST.pop()<tab><tab><tab>)  # Switch to the previous form if one exists<tab>except IndexError:<tab><tab>self.setNextForm(backup)",if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,178
733,"def get_expr_referrers(schema: s_schema.Schema, obj: so.Object) -> Dict[so.Object, str]:<tab>""""""Return schema referrers with refs in expressions.""""""<tab>refs = schema.get_referrers_ex(obj)<tab>result = {}<tab>for (mcls, fn), referrers in refs.items():<tab><tab>field = mcls.get_field(fn)<tab><tab><IF-STMT><tab><tab><tab>result.update({ref: fn for ref in referrers})<tab>return result","if issubclass ( field . type , ( Expression , ExpressionList ) ) :",136
734,"def _fields_to_index(cls):<tab>fields = []<tab>for field in cls._meta.sorted_fields:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>requires_index = any(<tab><tab><tab>(field.index, field.unique, isinstance(field, ForeignKeyField))<tab><tab>)<tab><tab>if requires_index:<tab><tab><tab>fields.append(field)<tab>return fields",if field . primary_key :,99
735,"def ident_values(self):<tab>value = self._ident_values<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab>if not self.orig_prefix:<tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>idents = getattr(wrapped, ""ident_values"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = [self._wrap_hash(ident) for ident in idents]<tab><tab><tab>##else:<tab><tab><tab>##<tab>ident = self.ident<tab><tab><tab>##<tab>if ident is not None:<tab><tab><tab>##<tab><tab>value = [ident]<tab><tab>self._ident_values = value<tab>return value",if idents :,200
736,"def apply_incpaths_ml(self):<tab>inc_lst = self.includes.split()<tab>lst = self.incpaths_lst<tab>for dir in inc_lst:<tab><tab>node = self.path.find_dir(dir)<tab><tab>if not node:<tab><tab><tab>error(""node not found: "" + str(dir))<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>lst.append(node)<tab><tab>self.bld_incpaths_lst.append(node)",if not node in lst :,121
737,"def application_openFiles_(self, nsapp, filenames):<tab># logging.info('[osx] file open')<tab># logging.info('[osx] file : %s' % (filenames))<tab>for filename in filenames:<tab><tab>logging.info(""[osx] receiving from macOS : %s"", filename)<tab><tab>if os.path.exists(filename):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sabnzbd.add_nzbfile(filename, keep=True)",if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES :,136
738,"def check(self, xp, nout):<tab>input = xp.asarray(self.x).astype(numpy.float32)<tab>with warnings.catch_warnings():<tab><tab>if self.ignore_warning:<tab><tab><tab>warnings.simplefilter(""ignore"", self.ignore_warning)<tab><tab><IF-STMT><tab><tab><tab>self.check_positive(xp, self.func, input, self.eps, nout)<tab><tab>else:<tab><tab><tab>self.check_negative(xp, self.func, input, self.eps, nout)",if self . result :,125
739,"def _set_scheme(url, newscheme):<tab>scheme = _get_scheme(url)<tab>newscheme = newscheme or """"<tab>newseparator = "":"" if newscheme in COLON_SEPARATED_SCHEMES else ""://""<tab>if scheme == """":  # Protocol relative URL.<tab><tab>url = ""%s:%s"" % (newscheme, url)<tab>elif scheme is None and url:  # No scheme.<tab><tab>url = """".join([newscheme, newseparator, url])<tab>elif scheme:  # Existing scheme.<tab><tab>remainder = url[len(scheme) :]<tab><tab><IF-STMT><tab><tab><tab>remainder = remainder[3:]<tab><tab>elif remainder.startswith("":""):<tab><tab><tab>remainder = remainder[1:]<tab><tab>url = """".join([newscheme, newseparator, remainder])<tab>return url","if remainder . startswith ( ""://"" ) :",191
740,"def parquet(tables, data_directory, ignore_missing_dependency, **params):<tab>try:<tab><tab>import pyarrow as pa  # noqa: F401<tab><tab>import pyarrow.parquet as pq  # noqa: F401<tab>except ImportError:<tab><tab>msg = ""PyArrow dependency is missing""<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""Ignored: %s"", msg)<tab><tab><tab>return 0<tab><tab>else:<tab><tab><tab>raise click.ClickException(msg)<tab>data_directory = Path(data_directory)<tab>for table, df in read_tables(tables, data_directory):<tab><tab>arrow_table = pa.Table.from_pandas(df)<tab><tab>target_path = data_directory / ""{}.parquet"".format(table)<tab><tab>pq.write_table(arrow_table, str(target_path))",if ignore_missing_dependency :,199
741,"def h2i(self, pkt, s):<tab>t = ()<tab>if type(s) is str:<tab><tab>t = time.strptime(s)<tab><tab>t = t[:2] + t[2:-3]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>y, m, d, h, min, sec, rest, rest, rest = time.gmtime(time.time())<tab><tab><tab>t = (y, m, d, h, min, sec)<tab><tab>else:<tab><tab><tab>t = s<tab>return t",if not s :,130
742,"def filter_episodes(self, batch, cross_entropy):<tab>""""""Filter the episodes for the cross_entropy method""""""<tab>accumulated_reward = [sum(rewards) for rewards in batch[""rewards""]]<tab>percentile = cross_entropy * 100<tab>reward_bound = np.percentile(accumulated_reward, percentile)<tab># we save the batch with reward above the bound<tab>result = {k: [] for k in self.data_keys}<tab>episode_kept = 0<tab>for i in range(len(accumulated_reward)):<tab><tab><IF-STMT><tab><tab><tab>for k in self.data_keys:<tab><tab><tab><tab>result[k].append(batch[k][i])<tab><tab><tab>episode_kept += 1<tab>return result",if accumulated_reward [ i ] >= reward_bound :,181
743,"def _readenv(var, msg):<tab>match = _ENV_VAR_PAT.match(var)<tab>if match and match.groups():<tab><tab>envvar = match.groups()[0]<tab><tab>if envvar in os.environ:<tab><tab><tab>value = os.environ[envvar]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.decode(""utf8"")<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>raise InvalidConfigException(<tab><tab><tab><tab>""{} - environment variable '{}' not set"".format(msg, var)<tab><tab><tab>)<tab>else:<tab><tab>raise InvalidConfigException(<tab><tab><tab>""{} - environment variable name '{}' does not match pattern '{}'"".format(<tab><tab><tab><tab>msg, var, _ENV_VAR_PAT_STR<tab><tab><tab>)<tab><tab>)",if six . PY2 :,190
744,"def _allocate_nbd(self):<tab>if not os.path.exists(""/sys/block/nbd0""):<tab><tab>self.error = _(""nbd unavailable: module not loaded"")<tab><tab>return None<tab>while True:<tab><tab>if not self._DEVICES:<tab><tab><tab># really want to log this info, not raise<tab><tab><tab>self.error = _(""No free nbd devices"")<tab><tab><tab>return None<tab><tab>device = self._DEVICES.pop()<tab><tab><IF-STMT><tab><tab><tab>break<tab>return device","if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :",146
745,"def _expand_deps_java_generation(self):<tab>""""""Ensure that all multilingual dependencies such as proto_library generate java code.""""""<tab>queue = collections.deque(self.deps)<tab>keys = set()<tab>while queue:<tab><tab>k = queue.popleft()<tab><tab><IF-STMT><tab><tab><tab>keys.add(k)<tab><tab><tab>dep = self.target_database[k]<tab><tab><tab>if ""generate_java"" in dep.attr:  # Has this attribute<tab><tab><tab><tab>dep.attr[""generate_java""] = True<tab><tab><tab><tab>queue.extend(dep.deps)",if k not in keys :,144
746,"def load_syntax(syntax):<tab>context = _create_scheme() or {}<tab>partition_scanner = PartitionScanner(syntax.get(""partitions"", []))<tab>scanners = {}<tab>for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()):<tab><tab>scanners[part_name] = Scanner(part_scanner)<tab>formats = []<tab>for fname, fstyle in list(syntax.get(""formats"", {}).items()):<tab><tab>if isinstance(fstyle, basestring):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key = fstyle[2:-2]<tab><tab><tab><tab>fstyle = context[key]<tab><tab><tab>else:<tab><tab><tab><tab>fstyle = fstyle % context<tab><tab>formats.append((fname, fstyle))<tab>return partition_scanner, scanners, formats","if fstyle . startswith ( ""%("" ) and fstyle . endswith ( "")s"" ) :",199
747,"def rollback(self):<tab>for operation, values in self.current_transaction_state[::-1]:<tab><tab><IF-STMT><tab><tab><tab>values.remove()<tab><tab>elif operation == ""update"":<tab><tab><tab>old_value, new_value = values<tab><tab><tab>if new_value.full_filename != old_value.full_filename:<tab><tab><tab><tab>os.unlink(new_value.full_filename)<tab><tab><tab>old_value.write()<tab>self._post_xact_cleanup()","if operation == ""insert"" :",121
748,"def _buildOffsets(offsetDict, localeData, indexStart):<tab>o = indexStart<tab>for key in localeData:<tab><tab><IF-STMT><tab><tab><tab>for k in key.split(""|""):<tab><tab><tab><tab>offsetDict[k] = o<tab><tab>else:<tab><tab><tab>offsetDict[key] = o<tab><tab>o += 1","if ""|"" in key :",83
749,"def _check_start_pipeline_execution_errors(<tab>graphene_info, execution_params, execution_plan):<tab>if execution_params.step_keys:<tab><tab>for step_key in execution_params.step_keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise UserFacingGraphQLError(<tab><tab><tab><tab><tab>graphene_info.schema.type_named(""InvalidStepError"")(<tab><tab><tab><tab><tab><tab>invalid_step_key=step_key<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",if not execution_plan . has_step ( step_key ) :,132
750,"def __setattr__(self, option_name, option_value):<tab>if option_name in self._options:<tab><tab># type checking<tab><tab>sort = self.OPTIONS[self.arch.name][option_name][0]<tab><tab><IF-STMT><tab><tab><tab>self._options[option_name] = option_value<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>'Value for option ""%s"" must be of type %s' % (option_name, sort)<tab><tab><tab>)<tab>else:<tab><tab>super(CFGArchOptions, self).__setattr__(option_name, option_value)","if sort is None or isinstance ( option_value , sort ) :",155
751,"def value(self):<tab>quote = False<tab>if self.defects:<tab><tab>quote = True<tab>else:<tab><tab>for x in self:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>quote = True<tab>if quote:<tab><tab>pre = post = """"<tab><tab>if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"":<tab><tab><tab>pre = "" ""<tab><tab>if self[-1].token_type == ""cfws"" or self[-1][-1].token_type == ""cfws"":<tab><tab><tab>post = "" ""<tab><tab>return pre + quote_string(self.display_name) + post<tab>else:<tab><tab>return super(DisplayName, self).value","if x . token_type == ""quoted-string"" :",186
752,"def __init__(self, patch_files, patch_directories):<tab>files = []<tab>files_data = {}<tab>for filename_data in patch_files:<tab><tab><IF-STMT><tab><tab><tab>filename, data = filename_data<tab><tab>else:<tab><tab><tab>filename = filename_data<tab><tab><tab>data = None<tab><tab>if not filename.startswith(os.sep):<tab><tab><tab>filename = ""{0}{1}"".format(FakeState.deploy_dir, filename)<tab><tab>files.append(filename)<tab><tab>if data:<tab><tab><tab>files_data[filename] = data<tab>self.files = files<tab>self.files_data = files_data<tab>self.directories = patch_directories","if isinstance ( filename_data , list ) :",171
753,"def _evaluateStack(s):<tab>op = s.pop()<tab>if op in ""+-*/@^"":<tab><tab>op2 = _evaluateStack(s)<tab><tab>op1 = _evaluateStack(s)<tab><tab>result = opn[op](op1, op2)<tab><tab><IF-STMT><tab><tab><tab>print(result)<tab><tab>return result<tab>else:<tab><tab>return op",if debug_flag :,97
754,"def reconnect_user(self, user_id, host_id, server_id):<tab>if host_id == settings.local.host_id:<tab><tab>return<tab>if server_id and self.server.id != server_id:<tab><tab>return<tab>for client in self.clients.find({""user_id"": user_id}):<tab><tab>self.clients.update_id(<tab><tab><tab>client[""id""],<tab><tab><tab>{<tab><tab><tab><tab>""ignore_routes"": True,<tab><tab><tab>},<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.instance.disconnect_wg(client[""id""])<tab><tab>else:<tab><tab><tab>self.instance_com.client_kill(client[""id""])","if len ( client [ ""id"" ] ) > 32 :",176
755,"def _get_library(self, name, args):<tab>library_database = self._library_manager.get_new_connection_to_library_database()<tab>try:<tab><tab>last_updated = library_database.get_library_last_updated(name, args)<tab><tab>if last_updated:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._library_manager.fetch_keywords(<tab><tab><tab><tab><tab>name, args, self._libraries_need_refresh_listener<tab><tab><tab><tab>)<tab><tab><tab>return library_database.fetch_library_keywords(name, args)<tab><tab>return self._library_manager.get_and_insert_keywords(name, args)<tab>finally:<tab><tab>library_database.close()",if time . time ( ) - last_updated > 10.0 :,184
756,"def get_paths(self, path, commit):<tab>""""""Return a generator of all filepaths under path at commit.""""""<tab>_check_path_is_repo_relative(path)<tab>git_path = _get_git_path(path)<tab>tree = self.gl_repo.git_repo[commit.tree[git_path].id]<tab>assert tree.type == pygit2.GIT_OBJ_TREE<tab>for tree_entry in tree:<tab><tab>tree_entry_path = os.path.join(path, tree_entry.name)<tab><tab><IF-STMT><tab><tab><tab>for fp in self.get_paths(tree_entry_path, commit):<tab><tab><tab><tab>yield fp<tab><tab>else:<tab><tab><tab>yield tree_entry_path","if tree_entry . type == ""tree"" :",185
757,"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab>if ""attributes"" in conf[""properties""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if conf[""properties""][""attributes""][""exp""]:<tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",82
758,"def _set_parse_context(self, tag, tag_attrs):<tab># special case: script or style parse context<tab>if not self._wb_parse_context:<tab><tab>if tag == ""style"":<tab><tab><tab>self._wb_parse_context = ""style""<tab><tab>elif tag == ""script"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._wb_parse_context = ""script""",if self . _allow_js_type ( tag_attrs ) :,106
759,"def modified(self):<tab>paths = set()<tab>dictionary_list = []<tab>for op_list in self._operations:<tab><tab>if not isinstance(op_list, list):<tab><tab><tab>op_list = (op_list,)<tab><tab>for item in chain(*op_list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>dictionary = item.dictionary<tab><tab><tab>if dictionary.path in paths:<tab><tab><tab><tab>continue<tab><tab><tab>paths.add(dictionary.path)<tab><tab><tab>dictionary_list.append(dictionary)<tab>return dictionary_list",if item is None :,139
760,def preorder(root):<tab>res = []<tab>if not root:<tab><tab>return res<tab>stack = []<tab>stack.append(root)<tab>while stack:<tab><tab>root = stack.pop()<tab><tab>res.append(root.val)<tab><tab><IF-STMT><tab><tab><tab>stack.append(root.right)<tab><tab>if root.left:<tab><tab><tab>stack.append(root.left)<tab>return res,if root . right :,105
761,"def create(exported_python_target):<tab>if exported_python_target not in created:<tab><tab>self.context.log.info(<tab><tab><tab>""Creating setup.py project for {}"".format(exported_python_target)<tab><tab>)<tab><tab>subject = self.derived_by_original.get(<tab><tab><tab>exported_python_target, exported_python_target<tab><tab>)<tab><tab>setup_dir, dependencies = self.create_setup_py(subject, dist_dir)<tab><tab>created[exported_python_target] = setup_dir<tab><tab>if self._recursive:<tab><tab><tab>for dep in dependencies:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>create(dep)",if is_exported_python_target ( dep ) :,172
762,"def test_array_interface(self, data):<tab>result = np.array(data)<tab>np.testing.assert_array_equal(result[0], data[0])<tab>result = np.array(data, dtype=object)<tab>expected = np.array(list(data), dtype=object)<tab>for a1, a2 in zip(result, expected):<tab><tab><IF-STMT><tab><tab><tab>assert np.isnan(a1) and np.isnan(a2)<tab><tab>else:<tab><tab><tab>tm.assert_numpy_array_equal(a2, a1)",if np . isscalar ( a1 ) :,143
763,"def valueChanged(plug):<tab>changed = plug.getInput() is not None<tab>if not changed and isinstance(plug, Gaffer.ValuePlug):<tab><tab><IF-STMT><tab><tab><tab>changed = not Gaffer.NodeAlgo.isSetToUserDefault(plug)<tab><tab>else:<tab><tab><tab>changed = not plug.isSetToDefault()<tab>return changed",if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,101
764,"def process_tag(hive_name, company, company_key, tag, default_arch):<tab>with winreg.OpenKeyEx(company_key, tag) as tag_key:<tab><tab>version = load_version_data(hive_name, company, tag, tag_key)<tab><tab><IF-STMT>  # if failed to get version bail<tab><tab><tab>major, minor, _ = version<tab><tab><tab>arch = load_arch_data(hive_name, company, tag, tag_key, default_arch)<tab><tab><tab>if arch is not None:<tab><tab><tab><tab>exe_data = load_exe(hive_name, company, company_key, tag)<tab><tab><tab><tab>if exe_data is not None:<tab><tab><tab><tab><tab>exe, args = exe_data<tab><tab><tab><tab><tab>return company, major, minor, arch, exe, args",if version is not None :,199
765,"def __iter__(self):<tab>for name, value in self.__class__.__dict__.items():<tab><tab>if isinstance(value, alias_flag_value):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield (name, self._has_flag(value.flag))","if isinstance ( value , flag_value ) :",71
766,"def connect(self):<tab>self.sock = sockssocket()<tab>self.sock.setproxy(*proxy_args)<tab>if type(self.timeout) in (int, float):<tab><tab>self.sock.settimeout(self.timeout)<tab>self.sock.connect((self.host, self.port))<tab>if isinstance(self, compat_http_client.HTTPSConnection):<tab><tab><IF-STMT>  # Python > 2.6<tab><tab><tab>self.sock = self._context.wrap_socket(self.sock, server_hostname=self.host)<tab><tab>else:<tab><tab><tab>self.sock = ssl.wrap_socket(self.sock)","if hasattr ( self , ""_context"" ) :",158
767,"def frequent_thread_switches():<tab>""""""Make concurrency bugs more likely to manifest.""""""<tab>interval = None<tab>if not sys.platform.startswith(""java""):<tab><tab>if hasattr(sys, ""getswitchinterval""):<tab><tab><tab>interval = sys.getswitchinterval()<tab><tab><tab>sys.setswitchinterval(1e-6)<tab><tab>else:<tab><tab><tab>interval = sys.getcheckinterval()<tab><tab><tab>sys.setcheckinterval(1)<tab>try:<tab><tab>yield<tab>finally:<tab><tab>if not sys.platform.startswith(""java""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sys.setswitchinterval(interval)<tab><tab><tab>else:<tab><tab><tab><tab>sys.setcheckinterval(interval)","if hasattr ( sys , ""setswitchinterval"" ) :",177
768,"def vars(self):<tab>ret = []<tab>if op.intlist:<tab><tab>varlist = op.intlist<tab>else:<tab><tab>varlist = self.discover<tab><tab>for name in varlist:<tab><tab><tab>if name in (""0"", ""1"", ""2"", ""8"", ""CPU0"", ""ERR"", ""LOC"", ""MIS"", ""NMI""):<tab><tab><tab><tab>varlist.remove(name)<tab><tab>if not op.full and len(varlist) > 3:<tab><tab><tab>varlist = varlist[-3:]<tab>for name in varlist:<tab><tab>if name in self.discover:<tab><tab><tab>ret.append(name)<tab><tab><IF-STMT><tab><tab><tab>ret.append(self.intmap[name.lower()])<tab>return ret",elif name . lower ( ) in self . intmap :,191
769,"def deleteDuplicates(gadgets, callback=None):<tab>toReturn = []<tab>inst = set()<tab>count = 0<tab>added = False<tab>len_gadgets = len(gadgets)<tab>for i, gadget in enumerate(gadgets):<tab><tab>inst.add(gadget._gadget)<tab><tab><IF-STMT><tab><tab><tab>count = len(inst)<tab><tab><tab>toReturn.append(gadget)<tab><tab><tab>added = True<tab><tab>if callback:<tab><tab><tab>callback(gadget, added, float(i + 1) / (len_gadgets))<tab><tab><tab>added = False<tab>return toReturn",if len ( inst ) > count :,164
770,"def ident(self):<tab>value = self._ident<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab>if not self.orig_prefix:<tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>ident = getattr(wrapped, ""ident"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = self._wrap_hash(ident)<tab><tab>self._ident = value<tab>return value",if ident is not None :,135
771,"def _flatten_settings_from_form(self, settings, form, form_values):<tab>""""""Take a nested dict and return a flat dict of setting values.""""""<tab>setting_values = {}<tab>for field in form.c:<tab><tab>if isinstance(field, _ContainerMixin):<tab><tab><tab>setting_values.update(<tab><tab><tab><tab>self._flatten_settings_from_form(<tab><tab><tab><tab><tab>settings, field, form_values[field._name]<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>setting_values[field._name] = form_values[field._name]<tab>return setting_values",elif field . _name in settings :,156
772,"def _decorator(cls):<tab>for name, meth in inspect.getmembers(cls, inspect.isroutine):<tab><tab>if name not in cls.__dict__:<tab><tab><tab>continue<tab><tab>if name != ""__init__"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>if name in butnot:<tab><tab><tab>continue<tab><tab>setattr(cls, name, decorator(meth))<tab>return cls","if not private and name . startswith ( ""_"" ) :",99
773,"def _do_cmp(f1, f2):<tab>bufsize = BUFSIZE<tab>with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2:<tab><tab>while True:<tab><tab><tab>b1 = fp1.read(bufsize)<tab><tab><tab>b2 = fp2.read(bufsize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>if not b1:<tab><tab><tab><tab>return True",if b1 != b2 :,118
774,"def _memoized(*args):<tab>now = time.time()<tab>try:<tab><tab>value, last_update = self.cache[args]<tab><tab>age = now - last_update<tab><tab>if self._call_count > self.ctl or age > self.ttl:<tab><tab><tab>self._call_count = 0<tab><tab><tab>raise AttributeError<tab><tab><IF-STMT><tab><tab><tab>self._call_count += 1<tab><tab>return value<tab>except (KeyError, AttributeError):<tab><tab>value = func(*args)<tab><tab>if value:<tab><tab><tab>self.cache[args] = (value, now)<tab><tab>return value<tab>except TypeError:<tab><tab>return func(*args)",if self . ctl :,164
775,"def check(self, hyperlinks: Dict[str, Hyperlink]) -> Generator[CheckResult, None, None]:<tab>self.invoke_threads()<tab>total_links = 0<tab>for hyperlink in hyperlinks.values():<tab><tab><IF-STMT><tab><tab><tab>yield CheckResult(<tab><tab><tab><tab>hyperlink.uri, hyperlink.docname, hyperlink.lineno, ""ignored"", """", 0<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, hyperlink), False)<tab><tab><tab>total_links += 1<tab>done = 0<tab>while done < total_links:<tab><tab>yield self.rqueue.get()<tab><tab>done += 1<tab>self.shutdown_threads()",if self . is_ignored_uri ( hyperlink . uri ) :,188
776,"def remove_subscriber(self, topic, subscriber):<tab>if subscriber in self.subscribers[topic]:<tab><tab><IF-STMT><tab><tab><tab>subscriber._pyroRelease()<tab><tab>if hasattr(subscriber, ""_pyroUri""):<tab><tab><tab>try:<tab><tab><tab><tab>proxy = self.proxy_cache[subscriber._pyroUri]<tab><tab><tab><tab>proxy._pyroRelease()<tab><tab><tab><tab>del self.proxy_cache[subscriber._pyroUri]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab>self.subscribers[topic].discard(subscriber)","if hasattr ( subscriber , ""_pyroRelease"" ) :",139
777,"def delete_arc(collection, document, origin, target, type):<tab>directory = collection<tab>real_dir = real_directory(directory)<tab>mods = ModificationTracker()<tab>projectconf = ProjectConfiguration(real_dir)<tab>document = path_join(real_dir, document)<tab>with TextAnnotations(document) as ann_obj:<tab><tab># bail as quick as possible if read-only<tab><tab><IF-STMT><tab><tab><tab>raise AnnotationsIsReadOnlyError(ann_obj.get_document())<tab><tab>_delete_arc_with_ann(origin, target, type, mods, ann_obj, projectconf)<tab><tab>mods_json = mods.json_response()<tab><tab>mods_json[""annotations""] = _json_from_ann(ann_obj)<tab><tab>return mods_json",if ann_obj . _read_only :,193
778,"def _select_from(self, parent_path, is_dir, exists, listdir):<tab>if not is_dir(parent_path):<tab><tab>return<tab>with _cached(listdir) as listdir:<tab><tab>yielded = set()<tab><tab>try:<tab><tab><tab>successor_select = self.successor._select_from<tab><tab><tab>for starting_point in self._iterate_directories(<tab><tab><tab><tab>parent_path, is_dir, listdir<tab><tab><tab>):<tab><tab><tab><tab>for p in successor_select(starting_point, is_dir, exists, listdir):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield p<tab><tab><tab><tab><tab><tab>yielded.add(p)<tab><tab>finally:<tab><tab><tab>yielded.clear()",if p not in yielded :,183
779,"def _fractional_part(self, n, expr, evaluation):<tab>n_sympy = n.to_sympy()<tab>if n_sympy.is_constant():<tab><tab><IF-STMT><tab><tab><tab>positive_integer_part = (<tab><tab><tab><tab>Expression(""Floor"", n).evaluate(evaluation).to_python()<tab><tab><tab>)<tab><tab><tab>result = n - positive_integer_part<tab><tab>else:<tab><tab><tab>negative_integer_part = (<tab><tab><tab><tab>Expression(""Ceiling"", n).evaluate(evaluation).to_python()<tab><tab><tab>)<tab><tab><tab>result = n - negative_integer_part<tab>else:<tab><tab>return expr<tab>return from_python(result)",if n_sympy >= 0 :,169
780,"def check_bounds(geometry):<tab>if isinstance(geometry[0], (list, tuple)):<tab><tab>return list(map(check_bounds, geometry))<tab>else:<tab><tab>if geometry[0] > 180 or geometry[0] < -180:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Longitude is out of bounds, check your JSON format or data""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Latitude is out of bounds, check your JSON format or data""<tab><tab><tab>)",if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 :,143
781,"def get_absolute_path(self, root, path):<tab># find the first absolute path that exists<tab>self.root = self.roots[0]<tab>for root in self.roots:<tab><tab>abspath = os.path.abspath(os.path.join(root, path))<tab><tab><IF-STMT><tab><tab><tab>self.root = root  # make sure all the other methods in the base class know how to find the file<tab><tab><tab>break<tab>return abspath",if os . path . exists ( abspath ) :,114
782,"def do_setflow(self, l=""""):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>l = str(self.flow_slider.GetValue())<tab><tab>else:<tab><tab><tab>l = l.lower()<tab><tab>flow = int(l)<tab><tab>if self.p.online:<tab><tab><tab>self.p.send_now(""M221 S"" + l)<tab><tab><tab>self.log(_(""Setting print flow factor to %d%%."") % flow)<tab><tab>else:<tab><tab><tab>self.logError(_(""Printer is not online.""))<tab>except Exception as x:<tab><tab>self.logError(_(""You must enter a flow. (%s)"") % (repr(x),))","if not isinstance ( l , str ) or not len ( l ) :",170
783,"def sources():<tab>for d in os.listdir(base):<tab><tab>#<tab><tab>if d.startswith('talis'):<tab><tab>#<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if d == ""indcat"":<tab><tab><tab>continue<tab><tab>if not os.path.isdir(base + d):<tab><tab><tab>continue<tab><tab>yield d","if d . endswith ( ""old"" ) :",105
784,"def create_accumulator(self) -> tf_metric_accumulators.TFCompilableMetricsAccumulator:<tab>configs = zip(self._metric_configs, self._loss_configs)<tab>padding_options = None<tab>if self._eval_config is not None:<tab><tab>model_spec = model_util.get_model_spec(self._eval_config, self._model_name)<tab><tab><IF-STMT><tab><tab><tab>padding_options = model_spec.padding_options<tab>return tf_metric_accumulators.TFCompilableMetricsAccumulator(<tab><tab>padding_options,<tab><tab>[len(m) + len(l) for m, l in configs],<tab><tab>desired_batch_size=self._desired_batch_size,<tab>)","if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :",196
785,"def parseImpl(self, instring, loc, doActions=True):<tab>try:<tab><tab>loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)<tab>except (ParseException, IndexError):<tab><tab><IF-STMT><tab><tab><tab>if self.expr.resultsName:<tab><tab><tab><tab>tokens = ParseResults([self.defaultValue])<tab><tab><tab><tab>tokens[self.expr.resultsName] = self.defaultValue<tab><tab><tab>else:<tab><tab><tab><tab>tokens = [self.defaultValue]<tab><tab>else:<tab><tab><tab>tokens = []<tab>return loc, tokens",if self . defaultValue is not self . __optionalNotMatched :,157
786,"def handleConnection(self):<tab># connection handshake<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>self.csock.close()<tab>except:<tab><tab>ex_t, ex_v, ex_tb = sys.exc_info()<tab><tab>tb = util.formatTraceback(ex_t, ex_v, ex_tb)<tab><tab>log.warning(""error during connect/handshake: %s; %s"", ex_v, ""\n"".join(tb))<tab><tab>self.csock.close()<tab>return False",if self . daemon . _handshake ( self . csock ) :,138
787,"def getProc(su, innerTarget):<tab>if len(su) == 1:  # have a one element wedge<tab><tab>proc = (""first"", ""last"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>proc = (""first"", ""last"")  # same element can be first and last<tab><tab>elif su.isFirst(innerTarget):<tab><tab><tab>proc = (""first"",)<tab><tab>elif su.isLast(innerTarget):<tab><tab><tab>proc = (""last"",)<tab><tab>else:<tab><tab><tab>proc = ()<tab>return proc",if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,143
788,"def get_color_dtype(data, column_names):<tab>has_color = all(column in data[""points""] for column in column_names)<tab>if has_color:<tab><tab>color_data_types = [<tab><tab><tab>data[""points""][column_name].dtype for column_name in column_names<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>f""Data types of color values are inconsistent: got {color_data_types}""<tab><tab><tab>)<tab><tab>color_data_type = color_data_types[0]<tab>else:<tab><tab>color_data_type = None<tab>return color_data_type",if len ( set ( color_data_types ) ) > 1 :,168
789,"def close(self):<tab>children = []<tab>for children_part, line_offset, last_line_offset_leaf in self.children_groups:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>_update_positions(children_part, line_offset, last_line_offset_leaf)<tab><tab><tab>except _PositionUpdatingFinished:<tab><tab><tab><tab>pass<tab><tab>children += children_part<tab>self.tree_node.children = children<tab># Reset the parents<tab>for node in children:<tab><tab>node.parent = self.tree_node",if line_offset != 0 :,138
790,"def get_multi(self, keys, index=None):<tab>with self._lmdb.begin() as txn:<tab><tab>result = []<tab><tab>for key in keys:<tab><tab><tab>packed = txn.get(key.encode())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append((key, cbor.loads(packed)))<tab>return result",if packed is not None :,86
791,"def get_directory_info(prefix, pth, recursive):<tab>res = []<tab>directory = os.listdir(pth)<tab>directory.sort()<tab>for p in directory:<tab><tab>if p[0] != ""."":<tab><tab><tab>subp = os.path.join(pth, p)<tab><tab><tab>p = os.path.join(prefix, p)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append([p, get_directory_info(prefix, subp, 1)])<tab><tab><tab>else:<tab><tab><tab><tab>res.append([p, None])<tab>return res",if recursive and os . path . isdir ( subp ) :,148
792,"def __schedule(self, workflow_scheduler_id, workflow_scheduler):<tab>invocation_ids = self.__active_invocation_ids(workflow_scheduler_id)<tab>for invocation_id in invocation_ids:<tab><tab>log.debug(""Attempting to schedule workflow invocation [%s]"", invocation_id)<tab><tab>self.__attempt_schedule(invocation_id, workflow_scheduler)<tab><tab><IF-STMT><tab><tab><tab>return",if not self . monitor_running :,103
793,"def write(self, data):<tab>self.size -= len(data)<tab>passon = None<tab>if self.size > 0:<tab><tab>self.data.append(data)<tab>else:<tab><tab>if self.size:<tab><tab><tab>data, passon = data[: self.size], data[self.size :]<tab><tab>else:<tab><tab><tab>passon = b""""<tab><tab><IF-STMT><tab><tab><tab>self.data.append(data)<tab>return passon",if data :,114
794,"def __getstate__(self):<tab>try:<tab><tab>store_func, load_func = self.store_function, self.load_function<tab><tab>self.store_function, self.load_function = None, None<tab><tab># ignore analyses. we re-initialize analyses when restoring from pickling so that we do not lose any newly<tab><tab># added analyses classes<tab><tab>d = dict(<tab><tab><tab>(k, v)<tab><tab><tab>for k, v in self.__dict__.items()<tab><tab><tab><IF-STMT><tab><tab><tab>not in {<tab><tab><tab><tab>""analyses"",<tab><tab><tab>}<tab><tab>)<tab><tab>return d<tab>finally:<tab><tab>self.store_function, self.load_function = store_func, load_func",if k,175
795,"def mouse_down(self, event):<tab>if event.button == 1:<tab><tab>if self.scrolling:<tab><tab><tab>p = event.local<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.scroll_up()<tab><tab><tab><tab>return<tab><tab><tab>elif self.scroll_down_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_down()<tab><tab><tab><tab>return<tab>if event.button == 4:<tab><tab>self.scroll_up()<tab>if event.button == 5:<tab><tab>self.scroll_down()<tab>GridView.mouse_down(self, event)",if self . scroll_up_rect ( ) . collidepoint ( p ) :,160
796,"def on_api_command(self, command, data):<tab>if command == ""select"":<tab><tab>if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can():<tab><tab><tab>return flask.abort(403, ""Insufficient permissions"")<tab><tab>if self._prompt is None:<tab><tab><tab>return flask.abort(409, ""No active prompt"")<tab><tab>choice = data[""choice""]<tab><tab><IF-STMT><tab><tab><tab>return flask.abort(<tab><tab><tab><tab>400, ""{!r} is not a valid value for choice"".format(choice)<tab><tab><tab>)<tab><tab>self._answer_prompt(choice)","if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) :",164
797,"def register_predictors(self, model_data_arr):<tab>for integration in self._get_integrations():<tab><tab><IF-STMT><tab><tab><tab>integration.register_predictors(model_data_arr)<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>f""There is no connection to {integration.name}. predictor wouldn't be registred.""<tab><tab><tab>)",if integration . check_connection ( ) :,98
798,"def _pack_shears(shearData):<tab>shears = list()<tab>vidxs = list()<tab>for e_idx, entry in enumerate(shearData):<tab><tab># Should be 3 entries<tab><tab><IF-STMT><tab><tab><tab>shears.extend([float(""nan""), float(""nan"")])<tab><tab><tab>vidxs.extend([0, 0])<tab><tab>else:<tab><tab><tab>vidx1, vidx2, shear1, shear2 = entry<tab><tab><tab>shears.extend([shear1, shear2])<tab><tab><tab>vidxs.extend([vidx1, vidx2])<tab>return (np.asarray(shears, dtype=np.float32), np.asarray(vidxs, dtype=np.uint32))",if entry is None :,173
799,"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]:<tab>yield ""Core"", ""0""<tab>for _dir in data_manager.cog_data_path().iterdir():<tab><tab>fpath = _dir / ""settings.json""<tab><tab>if not fpath.exists():<tab><tab><tab>continue<tab><tab>with fpath.open() as f:<tab><tab><tab>try:<tab><tab><tab><tab>data = json.load(f)<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>continue<tab><tab>if not isinstance(data, dict):<tab><tab><tab>continue<tab><tab>cog_name = _dir.stem<tab><tab>for cog_id, inner in data.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>yield cog_name, cog_id","if not isinstance ( inner , dict ) :",192
800,"def subFeaName(m, newNames, state):<tab>try:<tab><tab>int(m[3], 16)<tab>except:<tab><tab>return m[0]<tab>name = m[2]<tab>if name in newNames:<tab><tab># print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4]))<tab><tab><IF-STMT><tab><tab><tab>print(""sub %r => %r"" % (m[0], m[1] + newNames[name] + m[4]))<tab><tab>state[""didChange""] = True<tab><tab>return m[1] + newNames[name] + m[4]<tab>return m[0]","if name == ""uni0402"" :",172
801,"def log_graph(self, model: LightningModule, input_array=None):<tab>if self._log_graph:<tab><tab>if input_array is None:<tab><tab><tab>input_array = model.example_input_array<tab><tab><IF-STMT><tab><tab><tab>input_array = model._apply_batch_transfer_handler(input_array)<tab><tab><tab>self.experiment.add_graph(model, input_array)<tab><tab>else:<tab><tab><tab>rank_zero_warn(<tab><tab><tab><tab>""Could not log computational graph since the""<tab><tab><tab><tab>"" `model.example_input_array` attribute is not set""<tab><tab><tab><tab>"" or `input_array` was not given"",<tab><tab><tab><tab>UserWarning,<tab><tab><tab>)",if input_array is not None :,182
802,"def apply(self, db, person):<tab>for family_handle in person.get_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>for event_ref in family.get_event_ref_list():<tab><tab><tab><tab>if event_ref:<tab><tab><tab><tab><tab>event = db.get_event_from_handle(event_ref.ref)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab>if not event.get_date_object():<tab><tab><tab><tab><tab><tab>return True<tab>return False",if not event . get_place_handle ( ) :,159
803,"def format(m):<tab>if m > 1000:<tab><tab><IF-STMT><tab><tab><tab>return (str(int(m / 1000)), ""km"")<tab><tab>else:<tab><tab><tab>return (str(round(m / 1000, 1)), ""km"")<tab>return (str(m), ""m"")",if m % 1000 == 0 :,75
804,"def previous(self):<tab>try:<tab><tab>idx = _jump_list_index<tab><tab>next_index = idx + 1<tab><tab><IF-STMT><tab><tab><tab>next_index = 100<tab><tab>next_index = min(len(_jump_list) - 1, next_index)<tab><tab>_jump_list_index = next_index<tab><tab>return _jump_list[next_index]<tab>except (IndexError, KeyError) as e:<tab><tab>return None",if next_index > 100 :,114
805,"def _validate_and_set_default_hyperparameters(self):<tab>""""""Placeholder docstring""""""<tab># Check if all the required hyperparameters are set. If there is a default value<tab># for one, set it.<tab>for name, definition in self.hyperparameter_definitions.items():<tab><tab>if name not in self.hyperparam_dict:<tab><tab><tab>spec = definition[""spec""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.hyperparam_dict[name] = spec[""DefaultValue""]<tab><tab><tab>elif ""IsRequired"" in spec and spec[""IsRequired""]:<tab><tab><tab><tab>raise ValueError(""Required hyperparameter: %s is not set"" % name)","if ""DefaultValue"" in spec :",158
806,"def _actions_read(self, c):<tab>self.action_input.handle_read(c)<tab>if c in [curses.KEY_ENTER, util.KEY_ENTER2]:<tab><tab># take action<tab><tab>if self.action_input.selected_index == 0:  # Cancel<tab><tab><tab>self.back_to_parent()<tab><tab><IF-STMT>  # Apply<tab><tab><tab>self._apply_prefs()<tab><tab><tab>client.core.get_config().addCallback(self._update_preferences)<tab><tab>elif self.action_input.selected_index == 2:  # OK<tab><tab><tab>self._apply_prefs()<tab><tab><tab>self.back_to_parent()",elif self . action_input . selected_index == 1 :,174
807,"def _split_anonymous_function(s):<tab># Regex is not sufficient to handle differences between anonymous<tab># functions and YAML encoded lists. We perform a sniff test to see<tab># if it might be an anonymous function and then confirm by<tab># decoding it as YAML and testing the result.<tab>if s[:1] == ""["" and s[-1:] == ""]"" and "":"" in s:<tab><tab>try:<tab><tab><tab>l = yaml_util.decode_yaml(s)<tab><tab>except Exception:<tab><tab><tab>return None, s[1:-1]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None, s[1:-1]<tab>return None","if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :",177
808,"def test_source_address(self):<tab>for addr, is_ipv6 in VALID_SOURCE_ADDRESSES:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(""No IPv6 support: skipping."", NoIPv6Warning)<tab><tab><tab>continue<tab><tab>pool = HTTPConnectionPool(<tab><tab><tab>self.host, self.port, source_address=addr, retries=False<tab><tab>)<tab><tab>self.addCleanup(pool.close)<tab><tab>r = pool.request(""GET"", ""/source_address"")<tab><tab>self.assertEqual(r.data, b(addr[0]))",if is_ipv6 and not HAS_IPV6_AND_DNS :,150
809,"def vim_G(self):<tab>""""""Put the cursor on the last character of the file.""""""<tab>if self.is_text_wrapper(self.w):<tab><tab><IF-STMT><tab><tab><tab>self.do(""end-of-buffer-extend-selection"")<tab><tab>else:<tab><tab><tab>self.do(""end-of-buffer"")<tab><tab>self.done()<tab>else:<tab><tab>self.quit()","if self . state == ""visual"" :",103
810,"def backend_supported(module, manager, **kwargs):<tab>if CollectionNodeModule.backend_supported(module, manager, **kwargs):<tab><tab>if ""tid"" not in kwargs:<tab><tab><tab>return True<tab><tab>conn = manager.connection(did=kwargs[""did""])<tab><tab>template_path = ""partitions/sql/{0}/#{0}#{1}#"".format(<tab><tab><tab>manager.server_type, manager.version<tab><tab>)<tab><tab>SQL = render_template(<tab><tab><tab>""/"".join([template_path, ""backend_support.sql""]), tid=kwargs[""tid""]<tab><tab>)<tab><tab>status, res = conn.execute_scalar(SQL)<tab><tab># check if any errors<tab><tab><IF-STMT><tab><tab><tab>return internal_server_error(errormsg=res)<tab><tab>return res",if not status :,195
811,"def _get_regex_config(self, data_asset_name: Optional[str] = None) -> dict:<tab>regex_config: dict = copy.deepcopy(self._default_regex)<tab>asset: Optional[Asset] = None<tab>if data_asset_name:<tab><tab>asset = self._get_asset(data_asset_name=data_asset_name)<tab>if asset is not None:<tab><tab># Override the defaults<tab><tab><IF-STMT><tab><tab><tab>regex_config[""pattern""] = asset.pattern<tab><tab>if asset.group_names:<tab><tab><tab>regex_config[""group_names""] = asset.group_names<tab>return regex_config",if asset . pattern :,159
812,"def resolve(self, other):<tab>if other == ANY_TYPE:<tab><tab>return self<tab>elif isinstance(other, ComplexType):<tab><tab>f = self.first.resolve(other.first)<tab><tab>s = self.second.resolve(other.second)<tab><tab><IF-STMT><tab><tab><tab>return ComplexType(f, s)<tab><tab>else:<tab><tab><tab>return None<tab>elif self == ANY_TYPE:<tab><tab>return other<tab>else:<tab><tab>return None",if f and s :,114
813,"def collect_pages(app):<tab>new_images = {}<tab>for full_path, basename in app.builder.images.iteritems():<tab><tab>base, ext = os.path.splitext(full_path)<tab><tab>retina_path = base + ""@2x"" + ext<tab><tab><IF-STMT><tab><tab><tab>new_images[retina_path] = app.env.images[retina_path][1]<tab>app.builder.images.update(new_images)<tab>return []",if retina_path in app . env . images :,129
814,"def has_bad_headers(self):<tab>headers = [self.sender, self.reply_to] + self.recipients<tab>for header in headers:<tab><tab>if _has_newline(header):<tab><tab><tab>return True<tab>if self.subject:<tab><tab>if _has_newline(self.subject):<tab><tab><tab>for linenum, line in enumerate(self.subject.split(""\r\n"")):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if linenum > 0 and line[0] not in ""\t "":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if _has_newline(line):<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if len(line.strip()) == 0:<tab><tab><tab><tab><tab>return True<tab>return False",if not line :,186
815,"def reader():<tab>try:<tab><tab>imgs = mp4_loader(video_path, seg_num, seglen, mode)<tab><tab><IF-STMT><tab><tab><tab>logger.error(<tab><tab><tab><tab>""{} frame length {} less than 1."".format(video_path, len(imgs))<tab><tab><tab>)<tab><tab><tab>yield None, None<tab>except:<tab><tab>logger.error(""Error when loading {}"".format(mp4_path))<tab><tab>yield None, None<tab>imgs_ret = imgs_transform(<tab><tab>imgs, mode, seg_num, seglen, short_size, target_size, img_mean, img_std<tab>)<tab>label_ret = video_path<tab>yield imgs_ret, label_ret",if len ( imgs ) < 1 :,176
816,"def translate_from_sortname(name, sortname):<tab>""""""'Translate' the artist name by reversing the sortname.""""""<tab>for c in name:<tab><tab>ctg = unicodedata.category(c)<tab><tab><IF-STMT><tab><tab><tab>for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""):<tab><tab><tab><tab>if separator in sortname:<tab><tab><tab><tab><tab>parts = sortname.split(separator)<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>parts = [sortname]<tab><tab><tab><tab>separator = """"<tab><tab><tab>return separator.join(map(_reverse_sortname, parts))<tab>return name","if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :",181
817,"def _to_local_path(path):<tab>""""""Convert local path to SFTP path""""""<tab>if sys.platform == ""win32"":  # pragma: no cover<tab><tab>path = os.fsdecode(path)<tab><tab><IF-STMT><tab><tab><tab>path = path[1:]<tab><tab>path = path.replace(""/"", ""\\"")<tab>return path","if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :",95
818,"def __call__(self, text: str) -> str:<tab>for t in self.cleaner_types:<tab><tab>if t == ""tacotron"":<tab><tab><tab>text = tacotron_cleaner.cleaners.custom_english_cleaners(text)<tab><tab><IF-STMT><tab><tab><tab>text = jaconv.normalize(text)<tab><tab>elif t == ""vietnamese"":<tab><tab><tab>if vietnamese_cleaners is None:<tab><tab><tab><tab>raise RuntimeError(""Please install underthesea"")<tab><tab><tab>text = vietnamese_cleaners.vietnamese_cleaner(text)<tab><tab>else:<tab><tab><tab>raise RuntimeError(f""Not supported: type={t}"")<tab>return text","elif t == ""jaconv"" :",174
819,"def cb_syncthing_system_data(self, daemon, mem, cpu, d_failed, d_total):<tab>if self.daemon.get_my_id() in self.devices:<tab><tab># Update my device display<tab><tab>device = self.devices[self.daemon.get_my_id()]<tab><tab>device[""ram""] = sizeof_fmt(mem)<tab><tab>device[""cpu""] = ""%3.2f%%"" % (cpu)<tab><tab><IF-STMT><tab><tab><tab>device[""announce""] = _(""disabled"")<tab><tab>else:<tab><tab><tab>device[""announce""] = ""%s/%s"" % (d_total - d_failed, d_total)",if d_total == 0 :,162
820,"def update_kls(self, sampled_kls):<tab>for i, kl in enumerate(sampled_kls):<tab><tab><IF-STMT><tab><tab><tab>self.kl_coeff_val[i] *= 0.5<tab><tab>elif kl > 1.5 * self.kl_target:<tab><tab><tab>self.kl_coeff_val[i] *= 2.0<tab>return self.kl_coeff_val",if kl < self . kl_target / 1.5 :,106
821,"def DeleteEmptyCols(self):<tab>cols2delete = []<tab>for c in range(0, self.GetCols()):<tab><tab>f = True<tab><tab>for r in range(0, self.GetRows()):<tab><tab><tab>if self.FindItemAtPosition((r, c)) is not None:<tab><tab><tab><tab>f = False<tab><tab><IF-STMT><tab><tab><tab>cols2delete.append(c)<tab>for i in range(0, len(cols2delete)):<tab><tab>self.ShiftColsLeft(cols2delete[i] + 1)<tab><tab>cols2delete = [x - 1 for x in cols2delete]",if f :,150
822,"def get_session(self):<tab>if self._session is None:<tab><tab>session = super(ChildResourceManager, self).get_session()<tab><tab><IF-STMT><tab><tab><tab>session = session.get_session_for_resource(self.resource_type.resource)<tab><tab>self._session = session<tab>return self._session",if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY :,92
823,"def _get_master_authorized_networks_config(self, raw_cluster):<tab>if raw_cluster.get(""masterAuthorizedNetworksConfig""):<tab><tab>config = raw_cluster.get(""masterAuthorizedNetworksConfig"")<tab><tab>config[""includes_public_cidr""] = False<tab><tab>for block in config[""cidrBlocks""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config[""includes_public_cidr""] = True<tab><tab>return config<tab>else:<tab><tab>return {""enabled"": False, ""cidrBlocks"": [], ""includes_public_cidr"": False}","if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :",146
824,"def scan_folder(folder):<tab>scanned_files = []<tab>for root, dirs, files in os.walk(folder):<tab><tab>dirs[:] = [d for d in dirs if d != ""__pycache__""]<tab><tab>relative_path = os.path.relpath(root, folder)<tab><tab>for f in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>relative_name = os.path.normpath(os.path.join(relative_path, f)).replace(<tab><tab><tab><tab>""\\"", ""/""<tab><tab><tab>)<tab><tab><tab>scanned_files.append(relative_name)<tab>return sorted(scanned_files)","if f . endswith ( "".pyc"" ) :",154
825,"def read_progress(self):<tab>while True:<tab><tab>processed_file = self.queue.get()<tab><tab>self.threading_completed.append(processed_file)<tab><tab>total_number = len(self.file_list)<tab><tab>completed_number = len(self.threading_completed)<tab><tab># Just for the record, this slows down book searching by about 20%<tab><tab>if _progress_emitter:  # Skip update in reading mode<tab><tab><tab>_progress_emitter.update_progress(completed_number * 100 // total_number)<tab><tab><IF-STMT><tab><tab><tab>break",if total_number == completed_number :,145
826,"def next_instruction_is_function_or_class(lines):<tab>""""""Is the first non-empty, non-commented line of the cell either a function or a class?""""""<tab>parser = StringParser(""python"")<tab>for i, line in enumerate(lines):<tab><tab>if parser.is_quoted():<tab><tab><tab>parser.read_line(line)<tab><tab><tab>continue<tab><tab>parser.read_line(line)<tab><tab>if not line.strip():  # empty line<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>if line.startswith(""def "") or line.startswith(""class ""):<tab><tab><tab>return True<tab><tab>if line.startswith((""#"", ""@"", "" "", "")"")):<tab><tab><tab>continue<tab><tab>return False<tab>return False",if i > 0 and not lines [ i - 1 ] . strip ( ) :,194
827,def __next__(self):<tab>try:<tab><tab>data = next(self.iter_loader)<tab>except StopIteration:<tab><tab>self._epoch += 1<tab><tab><IF-STMT><tab><tab><tab>self._dataloader.sampler.set_epoch(self._epoch)<tab><tab>self.iter_loader = iter(self._dataloader)<tab><tab>data = next(self.iter_loader)<tab>return data,"if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :",104
828,"def dgl_mp_batchify_fn(data):<tab>if isinstance(data[0], tuple):<tab><tab>data = zip(*data)<tab><tab>return [dgl_mp_batchify_fn(i) for i in data]<tab>for dt in data:<tab><tab>if dt is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return [d for d in data if isinstance(d, dgl.DGLGraph)]<tab><tab><tab>elif isinstance(dt, nd.NDArray):<tab><tab><tab><tab>pad = Pad(axis=(1, 2), num_shards=1, ret_length=False)<tab><tab><tab><tab>data_list = [dt for dt in data if dt is not None]<tab><tab><tab><tab>return pad(data_list)","if isinstance ( dt , dgl . DGLGraph ) :",183
829,"def f(self, info):<tab>for k in keys:<tab><tab><IF-STMT><tab><tab><tab>for k2 in list(info.keys()):<tab><tab><tab><tab>if k(k2):<tab><tab><tab><tab><tab>info.pop(k2)<tab><tab>else:<tab><tab><tab>info.pop(k, None)",if callable ( k ) :,78
830,"def create(path, binary=False):<tab>for i in range(10):<tab><tab>try:<tab><tab><tab>os.makedirs(os.path.dirname(path), exist_ok=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return open(path, ""wb"")<tab><tab><tab>else:<tab><tab><tab><tab>return open(path, ""w"", encoding=""utf-8"")<tab><tab><tab>if i > 0:<tab><tab><tab><tab>log(True, f""Created {path} at attempt {i + 1}"")<tab><tab>except:<tab><tab><tab>time.sleep(0.5)<tab>else:<tab><tab>raise Error(f""Failed to create {path}"")",if binary :,157
831,"def validate_update(self, update_query):<tab>structure = DotCollapsedDict(self.doc_class.structure)<tab>for op, fields in update_query.iteritems():<tab><tab>for field in fields:<tab><tab><tab>if op != ""$unset"" and op != ""$rename"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise UpdateQueryError(<tab><tab><tab><tab><tab><tab>""'%s' not found in %s's structure""<tab><tab><tab><tab><tab><tab>% (field, self.doc_class.__name__)<tab><tab><tab><tab><tab>)",if field not in structure :,133
832,"def check_enums_ATLAS_ISAEXT(lines):<tab>for i, isaext in enumerate(ATLAS_ISAEXT):<tab><tab>got = lines.pop(0).strip()<tab><tab><IF-STMT><tab><tab><tab>expect = ""none: 1""<tab><tab>else:<tab><tab><tab>expect = ""{0}: {1}"".format(isaext, 1 << i)<tab><tab>if got != expect:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""ATLAS_ISAEXT mismatch at position ""<tab><tab><tab><tab>+ str(i)<tab><tab><tab><tab>+ "": got >>""<tab><tab><tab><tab>+ got<tab><tab><tab><tab>+ ""<<, expected >>""<tab><tab><tab><tab>+ expect<tab><tab><tab><tab>+ ""<<""<tab><tab><tab>)",if i == 0 :,180
833,"def _test_export_session_csv(self, test_session=None):<tab>with self.app.test_request_context():<tab><tab><IF-STMT><tab><tab><tab>test_session = SessionFactory()<tab><tab>field_data = export_sessions_csv([test_session])<tab><tab>session_row = field_data[1]<tab><tab>self.assertEqual(session_row[0], ""example (accepted)"")<tab><tab>self.assertEqual(session_row[9], ""accepted"")",if not test_session :,116
834,"def get_report_to_platform(self, args, scan_reports):<tab>if self.bc_api_key:<tab><tab><IF-STMT><tab><tab><tab>repo_id = self.get_repository(args)<tab><tab><tab>self.setup_bridgecrew_credentials(<tab><tab><tab><tab>bc_api_key=self.bc_api_key, repo_id=repo_id<tab><tab><tab>)<tab><tab>if self.is_integration_configured():<tab><tab><tab>self._upload_run(args, scan_reports)",if args . directory :,126
835,"def test_fvalue(self):<tab>if not getattr(self, ""skip_f"", False):<tab><tab>rtol = getattr(self, ""rtol"", 1e-10)<tab><tab>assert_allclose(self.res1.fvalue, self.res2.F, rtol=rtol)<tab><tab><IF-STMT><tab><tab><tab># only available with ivreg2<tab><tab><tab>assert_allclose(self.res1.f_pvalue, self.res2.Fp, rtol=rtol)<tab>else:<tab><tab>raise pytest.skip(""TODO: document why this test is skipped"")","if hasattr ( self . res2 , ""Fp"" ) :",143
836,"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab>if type(e) is Argument or type(e) is Option and e.argcount:<tab><tab><tab><tab>if e.value is None:<tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab>if type(e) is Command or type(e) is Option and e.argcount == 0:<tab><tab><tab><tab>e.value = 0<tab>return self",elif type ( e . value ) is not list :,190
837,"def touch(self):<tab>if not self.exists():<tab><tab>try:<tab><tab><tab>self.parent().touch()<tab><tab>except ValueError:<tab><tab><tab>pass<tab><tab>node = self._fs.touch(self.pathnames, {})<tab><tab>if not node.isdir:<tab><tab><tab>raise AssertionError(""Not a folder: %s"" % self.path)<tab><tab><IF-STMT><tab><tab><tab>self.watcher.emit(""created"", self)",if self . watcher :,107
838,"def __init__(self, _inf=None, _tzinfos=None):<tab>if _inf:<tab><tab>self._tzinfos = _tzinfos<tab><tab>self._utcoffset, self._dst, self._tzname = _inf<tab>else:<tab><tab>_tzinfos = {}<tab><tab>self._tzinfos = _tzinfos<tab><tab>self._utcoffset, self._dst, self._tzname = self._transition_info[0]<tab><tab>_tzinfos[self._transition_info[0]] = self<tab><tab>for inf in self._transition_info[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_tzinfos[inf] = self.__class__(inf, _tzinfos)",if not _tzinfos . has_key ( inf ) :,173
839,"def test_sample_output():<tab>comment = ""SAMPLE OUTPUT""<tab>skip_files = [""__init__.py""]<tab>errors = []<tab>for _file in sorted(MODULE_PATH.iterdir()):<tab><tab><IF-STMT><tab><tab><tab>with _file.open() as f:<tab><tab><tab><tab>if comment not in f.read():<tab><tab><tab><tab><tab>errors.append((comment, _file))<tab>if errors:<tab><tab>line = ""Missing sample error(s) detected!\n\n""<tab><tab>for error in errors:<tab><tab><tab>line += ""`{}` is not in module `{}`\n"".format(*error)<tab><tab>print(line[:-1])<tab><tab>assert False","if _file . suffix == "".py"" and _file . name not in skip_files :",174
840,"def http_get(url, target):<tab>req = requests.get(url, stream=True)<tab>content_length = req.headers.get(""Content-Length"")<tab>total = int(content_length) if content_length is not None else None<tab>progress = tqdm(unit=""B"", total=total)<tab>with open(target, ""wb"") as target_file:<tab><tab>for chunk in req.iter_content(chunk_size=1024):<tab><tab><tab><IF-STMT>  # filter out keep-alive new chunks<tab><tab><tab><tab>progress.update(len(chunk))<tab><tab><tab><tab>target_file.write(chunk)<tab>progress.close()",if chunk :,154
841,"def _elements_to_datasets(self, elements, level=0):<tab>for element in elements:<tab><tab>extra_kwds = {""identifier_%d"" % level: element[""name""]}<tab><tab><IF-STMT><tab><tab><tab>for inner_element in self._elements_to_datasets(<tab><tab><tab><tab>element[""elements""], level=level + 1<tab><tab><tab>):<tab><tab><tab><tab>dataset = extra_kwds.copy()<tab><tab><tab><tab>dataset.update(inner_element)<tab><tab><tab><tab>yield dataset<tab><tab>else:<tab><tab><tab>dataset = extra_kwds<tab><tab><tab>extra_kwds.update(element)<tab><tab><tab>yield extra_kwds","if ""elements"" in element :",156
842,"def update_dict(a, b):<tab>for key, value in b.items():<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>a[key] = value<tab><tab>elif isinstance(a[key], dict) and isinstance(value, dict):<tab><tab><tab>update_dict(a[key], value)<tab><tab>elif isinstance(a[key], list):<tab><tab><tab>a[key].append(value)<tab><tab>else:<tab><tab><tab>a[key] = [a[key], value]",if key not in a :,131
843,"def scan(self, targets):<tab>for target in targets:<tab><tab>target.print_infos()<tab><tab>if self.is_interesting(target):<tab><tab><tab>self.target[""other""].append(target)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return target<tab>return None",if self . match ( target ) :,72
844,"def printConnections(switches):<tab>""Compactly print connected nodes to each switch""<tab>for sw in switches:<tab><tab>output(""%s: "" % sw)<tab><tab>for intf in sw.intfList():<tab><tab><tab>link = intf.link<tab><tab><tab><IF-STMT><tab><tab><tab><tab>intf1, intf2 = link.intf1, link.intf2<tab><tab><tab><tab>remote = intf1 if intf1.node != sw else intf2<tab><tab><tab><tab>output(""%s(%s) "" % (remote.node, sw.ports[intf]))<tab><tab>output(""\n"")",if link :,147
845,"def __cut(sentence):<tab>global emit_P<tab>prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P)<tab>begin, nexti = 0, 0<tab># print pos_list, sentence<tab>for i, char in enumerate(sentence):<tab><tab>pos = pos_list[i]<tab><tab>if pos == ""B"":<tab><tab><tab>begin = i<tab><tab><IF-STMT><tab><tab><tab>yield sentence[begin : i + 1]<tab><tab><tab>nexti = i + 1<tab><tab>elif pos == ""S"":<tab><tab><tab>yield char<tab><tab><tab>nexti = i + 1<tab>if nexti < len(sentence):<tab><tab>yield sentence[nexti:]","elif pos == ""E"" :",174
846,"def check_files(self, paths=None):<tab>""""""Run all checks on the paths.""""""<tab>if paths is None:<tab><tab>paths = self.paths<tab>report = self.options.report<tab>runner = self.runner<tab>report.start()<tab>try:<tab><tab>for path in paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.input_dir(path)<tab><tab><tab>elif not self.excluded(path):<tab><tab><tab><tab>runner(path)<tab>except KeyboardInterrupt:<tab><tab>print(""... stopped"")<tab>report.stop()<tab>return report",if os . path . isdir ( path ) :,140
847,"def verts_of_loop(edge_loop):<tab>verts = []<tab>for e0, e1 in iter_pairs(edge_loop, False):<tab><tab><IF-STMT><tab><tab><tab>v0 = e0.shared_vert(e1)<tab><tab><tab>verts += [e0.other_vert(v0), v0]<tab><tab>verts += [e1.other_vert(verts[-1])]<tab>if len(verts) > 1 and verts[0] == verts[-1]:<tab><tab>return verts[:-1]<tab>return verts",if not verts :,134
848,"def generator(self, data):<tab>for task in data:<tab><tab># Do we scan everything or just /bin/bash instances?<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for bucket in task.bash_hash_entries():<tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>int(task.p_pid),<tab><tab><tab><tab><tab>str(task.p_comm),<tab><tab><tab><tab><tab>int(bucket.times_found),<tab><tab><tab><tab><tab>str(bucket.key),<tab><tab><tab><tab><tab>str(bucket.data.path),<tab><tab><tab><tab>],<tab><tab><tab>)","if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :",174
849,"def __get_ratio(self):<tab>""""""Return splitter ratio of the main splitter.""""""<tab>c = self.c<tab>free_layout = c.free_layout<tab>if free_layout:<tab><tab>w = free_layout.get_main_splitter()<tab><tab>if w:<tab><tab><tab>aList = w.sizes()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n1, n2 = aList<tab><tab><tab><tab># 2017/06/07: guard against division by zero.<tab><tab><tab><tab>ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2)<tab><tab><tab><tab>return ratio<tab>return 0.5",if len ( aList ) == 2 :,170
850,"def geterrors(self):<tab>""""""Get all error messages.""""""<tab>notes = self.getnotes(origin=""translator"").split(""\n"")<tab>errordict = {}<tab>for note in notes:<tab><tab><IF-STMT><tab><tab><tab>error = note.replace(""(pofilter) "", """")<tab><tab><tab>errorname, errortext = error.split("": "", 1)<tab><tab><tab>errordict[errorname] = errortext<tab>return errordict","if ""(pofilter) "" in note :",107
851,"def rename_path(self, path, new_path):<tab>logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path))<tab>dirs = self.readdir(path)<tab>for d in dirs:<tab><tab>if d in [""."", ""..""]:<tab><tab><tab>continue<tab><tab>d_path = """".join([path, ""/"", d])<tab><tab>d_new_path = """".join([new_path, ""/"", d])<tab><tab>attr = self.getattr(d_path)<tab><tab><IF-STMT><tab><tab><tab>self.rename_path(d_path, d_new_path)<tab><tab>else:<tab><tab><tab>self.rename_item(d_path, d_new_path)<tab>self.rename_item(path, new_path, dir=True)","if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :",196
852,"def index(self, url_id: int) -> FlaskResponse:  # pylint: disable=no-self-use<tab>url = db.session.query(models.Url).get(url_id)<tab>if url and url.url:<tab><tab>explore_url = ""//superset/explore/?""<tab><tab><IF-STMT><tab><tab><tab>explore_url += f""r={url_id}""<tab><tab><tab>return redirect(explore_url[1:])<tab><tab>return redirect(url.url[1:])<tab>flash(""URL to nowhere..."", ""danger"")<tab>return redirect(""/"")",if url . url . startswith ( explore_url ) :,142
853,"def testShortCircuit(self):<tab>""""""Test that creation short-circuits to reuse existing references""""""<tab>sd = {}<tab>for s in self.ss:<tab><tab>sd[s] = 1<tab>for t in self.ts:<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(sd.has_key(safeRef(t.x)))<tab><tab><tab>self.assertTrue(safeRef(t.x) in sd)<tab><tab>else:<tab><tab><tab>self.assertTrue(sd.has_key(safeRef(t)))<tab><tab><tab>self.assertTrue(safeRef(t) in sd)","if hasattr ( t , ""x"" ) :",146
854,"def wrapped(request, *args, **kwargs):<tab>if not request.user.is_authenticated():<tab><tab>request.session[""_next""] = request.get_full_path()<tab><tab><IF-STMT><tab><tab><tab>redirect_uri = reverse(<tab><tab><tab><tab>""sentry-auth-organization"", args=[kwargs[""organization_slug""]]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>redirect_uri = get_login_url()<tab><tab>return HttpResponseRedirect(redirect_uri)<tab>return func(request, *args, **kwargs)","if ""organization_slug"" in kwargs :",132
855,"def read_info(reader, dump=None):<tab>line_number_table_length = reader.read_u2()<tab><IF-STMT><tab><tab>reader.debug(<tab><tab><tab>""<tab>"" * dump, ""Line numbers (%s total):"" % line_number_table_length<tab><tab>)<tab>line_numbers = []<tab>for i in range(0, line_number_table_length):<tab><tab>start_pc = reader.read_u2()<tab><tab>line_number = reader.read_u2()<tab><tab>if dump is not None:<tab><tab><tab>reader.debug(""<tab>"" * (dump + 1), ""%s: %s"" % (start_pc, line_number))<tab><tab>line_numbers.append((start_pc, line_number))<tab>return LineNumberTable(line_numbers)",if dump is not None :,198
856,"def compute_timer_precision(timer):<tab>precision = None<tab>points = 0<tab>timeout = timeout_timer() + 1.0<tab>previous = timer()<tab>while timeout_timer() < timeout or points < 5:<tab><tab>for _ in XRANGE(10):<tab><tab><tab>t1 = timer()<tab><tab><tab>t2 = timer()<tab><tab><tab>dt = t2 - t1<tab><tab><tab>if 0 < dt:<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>dt = t2 - previous<tab><tab><tab>if dt <= 0.0:<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>precision = min(precision, dt)<tab><tab>else:<tab><tab><tab>precision = dt<tab><tab>points += 1<tab><tab>previous = timer()<tab>return precision",if precision is not None :,189
857,def get_hi_lineno(self):<tab>lineno = Node.get_hi_lineno(self)<tab>if self.expr1 is None:<tab><tab>pass<tab>else:<tab><tab>lineno = self.expr1.get_hi_lineno()<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>lineno = self.expr2.get_hi_lineno()<tab><tab><tab>if self.expr3 is None:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>lineno = self.expr3.get_hi_lineno()<tab>return lineno,if self . expr2 is None :,142
858,"def validate_cluster_resource_group(cmd, namespace):<tab>if namespace.cluster_resource_group is not None:<tab><tab>client = get_mgmt_service_client(<tab><tab><tab>cmd.cli_ctx, ResourceType.MGMT_RESOURCE_RESOURCES<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArgumentValueError(<tab><tab><tab><tab>""Invalid --cluster-resource-group '%s': resource group must not exist.""<tab><tab><tab><tab>% namespace.cluster_resource_group<tab><tab><tab>)",if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,137
859,"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab><IF-STMT><tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[left - 1]):<tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab>if right == len(text):<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[right]):<tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",if left == 0 :,159
860,"def _check_good_input(self, X, y=None):<tab>if isinstance(X, dict):<tab><tab>lengths = [len(X1) for X1 in X.values()]<tab><tab>if len(set(lengths)) > 1:<tab><tab><tab>raise ValueError(""Not all values of X are of equal length."")<tab><tab>x_len = lengths[0]<tab>else:<tab><tab>x_len = len(X)<tab>if y is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""X and y are not of equal length."")<tab>if self.regression and y is not None and y.ndim == 1:<tab><tab>y = y.reshape(-1, 1)<tab>return X, y",if len ( y ) != x_len :,175
861,"def _get_text_nodes(nodes, html_body):<tab>text = []<tab>open_tags = 0<tab>for node in nodes:<tab><tab>if isinstance(node, HtmlTag):<tab><tab><tab>if node.tag_type == OPEN_TAG:<tab><tab><tab><tab>open_tags += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>open_tags -= 1<tab><tab>elif (<tab><tab><tab>isinstance(node, HtmlDataFragment)<tab><tab><tab>and node.is_text_content<tab><tab><tab>and open_tags == 0<tab><tab>):<tab><tab><tab>text.append(html_body[node.start : node.end])<tab>return text",elif node . tag_type == CLOSE_TAG :,165
862,"def _get_spyne_type(cls_name, k, v):<tab>try:<tab><tab>v = NATIVE_MAP.get(v, v)<tab>except TypeError:<tab><tab>return<tab>try:<tab><tab>subc = issubclass(v, ModelBase) or issubclass(v, SelfReference)<tab>except:<tab><tab>subc = False<tab>if subc:<tab><tab>if issubclass(v, Array) and len(v._type_info) != 1:<tab><tab><tab>raise Exception(""Invalid Array definition in %s.%s."" % (cls_name, k))<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Please specify the number of dimensions"")<tab><tab>return v","elif issubclass ( v , Point ) and v . Attributes . dim is None :",171
863,"def customize(cls, **kwargs):<tab>""""""return a class with some existing attributes customized""""""<tab>for name, value in kwargs.iteritems():<tab><tab><IF-STMT><tab><tab><tab>raise TransportError(<tab><tab><tab><tab>""you cannot customize the protected attribute %s"" % name<tab><tab><tab>)<tab><tab>if not hasattr(cls, name):<tab><tab><tab>raise TransportError(""Transport has no attribute %s"" % name)<tab>NewSubClass = type(""Customized_{}"".format(cls.__name__), (cls,), kwargs)<tab>return NewSubClass","if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :",144
864,"def test_UNrelativize(self):<tab>import URIlib<tab>relative = self.relative + self.full_relativize<tab>for base, rel, fullpath, common in relative:<tab><tab>URI = uriparse.UnRelativizeURL(base, rel)<tab><tab>fullURI = URIlib.URIParser(URI)<tab><tab># We need to canonicalize the result from unrelativize<tab><tab># compared to the original full path we expect to see.<tab><tab><IF-STMT><tab><tab><tab>fullpath = fullpath[:-1]<tab><tab>self.failUnlessSamePath(<tab><tab><tab>os.path.normcase(fullURI.path), os.path.normcase(fullpath)<tab><tab>)","if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :",170
865,"def get_release_info(file_path=RELEASE_FILE):<tab>RELEASE_TYPE_REGEX = re.compile(r""^[Rr]elease [Tt]ype: (major|minor|patch)$"")<tab>with open(file_path, ""r"") as f:<tab><tab>line = f.readline()<tab><tab>match = RELEASE_TYPE_REGEX.match(line)<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""The file RELEASE.md should start with `Release type` ""<tab><tab><tab><tab>""and specify one of the following values: major, minor or patch.""<tab><tab><tab>)<tab><tab><tab>sys.exit(1)<tab><tab>type_ = match.group(1)<tab><tab>changelog = """".join([line for line in f.readlines()]).strip()<tab>return type_, changelog",if not match :,190
866,"def _get_next_history_entry(self):<tab>if self._history:<tab><tab>hist_len = len(self._history) - 1<tab><tab>self.history_index = min(hist_len, self.history_index + 1)<tab><tab>index = self.history_index<tab><tab><IF-STMT><tab><tab><tab>self.history_index += 1<tab><tab>return self._history[index]<tab>return """"",if self . history_index == hist_len :,107
867,"def star_op(self):<tab>""""""Put a '*' op, with special cases for *args.""""""<tab>val = ""*""<tab>if self.paren_level:<tab><tab>i = len(self.code_list) - 1<tab><tab>if self.code_list[i].kind == ""blank"":<tab><tab><tab>i -= 1<tab><tab>token = self.code_list[i]<tab><tab><IF-STMT><tab><tab><tab>self.op_no_blanks(val)<tab><tab>elif token.value == "","":<tab><tab><tab>self.blank()<tab><tab><tab>self.add_token(""op-no-blanks"", val)<tab><tab>else:<tab><tab><tab>self.op(val)<tab>else:<tab><tab>self.op(val)","if token . kind == ""lt"" :",177
868,"def get_safe_settings():<tab>""Returns a dictionary of the settings module, with sensitive settings blurred out.""<tab>settings_dict = {}<tab>for k in dir(settings):<tab><tab><IF-STMT><tab><tab><tab>if HIDDEN_SETTINGS.search(k):<tab><tab><tab><tab>settings_dict[k] = ""********************""<tab><tab><tab>else:<tab><tab><tab><tab>settings_dict[k] = getattr(settings, k)<tab>return settings_dict",if k . isupper ( ) :,109
869,"def nextEditable(self):<tab>""""""Moves focus of the cursor to the next editable window""""""<tab>if self.currentEditable is None:<tab><tab>if len(self._editableChildren):<tab><tab><tab>self._currentEditableRef = self._editableChildren[0]<tab>else:<tab><tab>for ref in weakref.getweakrefs(self.currentEditable):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cei = self._editableChildren.index(ref)<tab><tab><tab><tab>nei = cei + 1<tab><tab><tab><tab>if nei >= len(self._editableChildren):<tab><tab><tab><tab><tab>nei = 0<tab><tab><tab><tab>self._currentEditableRef = self._editableChildren[nei]<tab>return self.currentEditable",if ref in self . _editableChildren :,179
870,"def _handle_dependents_type(types, type_str, type_name, rel_name, row):<tab>if types[type_str[0]] is None:<tab><tab><IF-STMT><tab><tab><tab>type_name = ""index""<tab><tab><tab>rel_name = row[""indname""] + "" ON "" + rel_name<tab><tab>elif type_str[0] == ""o"":<tab><tab><tab>type_name = ""operator""<tab><tab><tab>rel_name = row[""relname""]<tab>else:<tab><tab>type_name = types[type_str[0]]<tab>return type_name, rel_name","if type_str [ 0 ] == ""i"" :",152
871,"def streamErrorHandler(self, conn, error):<tab>name, text = ""error"", error.getData()<tab>for tag in error.getChildren():<tab><tab><IF-STMT><tab><tab><tab>if tag.getName() == ""text"":<tab><tab><tab><tab>text = tag.getData()<tab><tab><tab>else:<tab><tab><tab><tab>name = tag.getName()<tab>if name in stream_exceptions.keys():<tab><tab>exc = stream_exceptions[name]<tab>else:<tab><tab>exc = StreamError<tab>raise exc((name, text))",if tag . getNamespace ( ) == NS_XMPP_STREAMS :,138
872,"def _validate_names(self, settings: _SettingsType) -> None:<tab>""""""Make sure all settings exist.""""""<tab>unknown = []<tab>for name in settings:<tab><tab><IF-STMT><tab><tab><tab>unknown.append(name)<tab>if unknown:<tab><tab>errors = [<tab><tab><tab>configexc.ConfigErrorDesc(<tab><tab><tab><tab>""While loading options"", ""Unknown option {}"".format(e)<tab><tab><tab>)<tab><tab><tab>for e in sorted(unknown)<tab><tab>]<tab><tab>raise configexc.ConfigFileErrors(""autoconfig.yml"", errors)",if name not in configdata . DATA :,139
873,"def can_haz(self, target, credentials):<tab>""""""Check whether key-values in target are present in credentials.""""""<tab># TODO(termie): handle ANDs, probably by providing a tuple instead of a<tab>#<tab><tab><tab>   string<tab>for requirement in target:<tab><tab>key, match = requirement.split("":"", 1)<tab><tab>check = credentials.get(key)<tab><tab><IF-STMT><tab><tab><tab>check = [check]<tab><tab>if match in check:<tab><tab><tab>return True","if check is None or isinstance ( check , basestring ) :",135
874,"def _recursive_fx_apply(input: dict, fx):<tab>for k, v in input.items():<tab><tab><IF-STMT><tab><tab><tab>v = torch.tensor(v)<tab><tab>if isinstance(v, torch.Tensor):<tab><tab><tab>v = fx(v.float())<tab><tab><tab>input[k] = v<tab><tab>else:<tab><tab><tab>_recursive_fx_apply(v, fx)","if isinstance ( v , list ) :",102
875,"def get(self, url, **kwargs):<tab>app, url = self._prepare_call(url, kwargs)<tab>if app:<tab><tab><IF-STMT><tab><tab><tab>self._first_ping = False<tab><tab><tab>return EmptyCapabilitiesResponse()<tab><tab>elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url:<tab><tab><tab>return ErrorApiResponse()<tab><tab>else:<tab><tab><tab>response = app.get(url, **kwargs)<tab><tab><tab>return TestingResponse(response)<tab>else:<tab><tab>return requests.get(url, **kwargs)","if url . endswith ( ""ping"" ) and self . _first_ping :",153
876,"def server_thread_fn():<tab>server_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)<tab>server_ctx.load_cert_chain(""trio-test-1.pem"")<tab>server = server_ctx.wrap_socket(<tab><tab>server_sock,<tab><tab>server_side=True,<tab><tab>suppress_ragged_eofs=False,<tab>)<tab>while True:<tab><tab>data = server.recv(4096)<tab><tab>print(""server got:"", data)<tab><tab><IF-STMT><tab><tab><tab>print(""server waiting for client to finish everything"")<tab><tab><tab>client_done.wait()<tab><tab><tab>print(""server attempting to send back close-notify"")<tab><tab><tab>server.unwrap()<tab><tab><tab>print(""server ok"")<tab><tab><tab>break<tab><tab>server.sendall(data)",if not data :,198
877,"def find_hostnames(data):<tab># sends back an array of hostnames<tab>hostnames = []<tab>for i in re.finditer(hostname_regex, data):<tab><tab>h = string.lower(i.group(1))<tab><tab>tld = h.split(""."")[-1:][0]<tab><tab><IF-STMT><tab><tab><tab>hostnames.append(h)<tab>return hostnames",if tld in tlds :,91
878,"def Validate(self, win):<tab>textCtrl = self.GetWindow()<tab>text = textCtrl.GetValue().strip()<tab>sChar = Character.getInstance()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(_t(""You must supply a name for the Character!""))<tab><tab>elif text in [x.name for x in sChar.getCharacterList()]:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>_t(""Character name already in use, please choose another."")<tab><tab><tab>)<tab><tab>return True<tab>except ValueError as e:<tab><tab>pyfalog.error(e)<tab><tab>wx.MessageBox(""{}"".format(e), _t(""Error""))<tab><tab>textCtrl.SetFocus()<tab><tab>return False",if len ( text ) == 0 :,177
879,def get_random_user_agent(agent_list=UA_CACHE):<tab>if not len(agent_list):<tab><tab>ua_file = file(UA_FILE)<tab><tab>for line in ua_file:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>agent_list.append(line)<tab>ua = random.choice(UA_CACHE)<tab>return ua,if line :,100
880,"def _validate_action_like_for_prefixes(self, key):<tab>for statement in self._statements:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(statement[key], string_types):<tab><tab><tab><tab>self._validate_action_prefix(statement[key])<tab><tab><tab>else:<tab><tab><tab><tab>for action in statement[key]:<tab><tab><tab><tab><tab>self._validate_action_prefix(action)",if key in statement :,100
881,"def predict(self, X):<tab>if self.regression:<tab><tab>return self.predict_proba(X)<tab>else:<tab><tab>y_pred = np.argmax(self.predict_proba(X), axis=1)<tab><tab><IF-STMT><tab><tab><tab>y_pred = self.enc_.inverse_transform(y_pred)<tab><tab>return y_pred",if self . use_label_encoder :,93
882,"def _threaded_request_tracker(self, builder):<tab>while True:<tab><tab>event_type = self._read_q.get()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>payload = {""body"": b""""}<tab><tab>request_id = builder.build_record(event_type, payload, """")<tab><tab>self._write_q.put_nowait(request_id)",if event_type is False :,96
883,"def __call__(self, value):<tab>try:<tab><tab>super(EmailValidator, self).__call__(value)<tab>except ValidationError as e:<tab><tab># Trivial case failed. Try for possible IDN domain-part<tab><tab><IF-STMT><tab><tab><tab>parts = value.split(""@"")<tab><tab><tab>try:<tab><tab><tab><tab>parts[-1] = parts[-1].encode(""idna"").decode(""ascii"")<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab>raise e<tab><tab><tab>super(EmailValidator, self).__call__(""@"".join(parts))<tab><tab>else:<tab><tab><tab>raise","if value and ""@"" in value :",143
884,"def PreprocessConditionalStatement(self, IfList, ReplacedLine):<tab>while self:<tab><tab>if self.__Token:<tab><tab><tab>x = 1<tab><tab><IF-STMT><tab><tab><tab>if self <= 2:<tab><tab><tab><tab>continue<tab><tab><tab>RegionSizeGuid = 3<tab><tab><tab>if not RegionSizeGuid:<tab><tab><tab><tab>RegionLayoutLine = 5<tab><tab><tab><tab>continue<tab><tab><tab>RegionLayoutLine = self.CurrentLineNumber<tab>return 1",elif not IfList :,111
885,"def _arg_with_type(self):<tab>for t in self.d[""Args""]:<tab><tab>m = re.search(""([A-Za-z0-9_-]+)\s{0,4}(\(.+\))\s{0,4}:"", t)<tab><tab><IF-STMT><tab><tab><tab>self.args[m.group(1)] = m.group(2)<tab>return self.args",if m :,95
886,"def get_palette_for_custom_classes(self, class_names, palette=None):<tab>if self.label_map is not None:<tab><tab># return subset of palette<tab><tab>palette = []<tab><tab>for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]):<tab><tab><tab>if new_id != -1:<tab><tab><tab><tab>palette.append(self.PALETTE[old_id])<tab><tab>palette = type(self.PALETTE)(palette)<tab>elif palette is None:<tab><tab><IF-STMT><tab><tab><tab>palette = np.random.randint(0, 255, size=(len(class_names), 3))<tab><tab>else:<tab><tab><tab>palette = self.PALETTE<tab>return palette",if self . PALETTE is None :,194
887,"def Visit_star_expr(self, node):  # pylint: disable=invalid-name<tab># star_expr ::= '*' expr<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.UNARY_OPERATOR)<tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.VARARGS_STAR)","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :",110
888,"def create_if_compatible(cls, typ: Type, *, root: ""RootNode"") -> Optional[""Node""]:<tab>if cls.compatible_types:<tab><tab>target_type: Type = typ<tab><tab><IF-STMT><tab><tab><tab>target_type = getattr(typ, ""__origin__"", None) or typ<tab><tab>if cls._issubclass(target_type, cls.compatible_types):<tab><tab><tab>return cls(typ, root=root)<tab>return None",if cls . use_origin :,109
889,"def grep_full_py_identifiers(tokens):<tab>global pykeywords<tab>tokens = list(tokens)<tab>i = 0<tab>while i < len(tokens):<tab><tab>tokentype, token = tokens[i]<tab><tab>i += 1<tab><tab>if tokentype != ""id"":<tab><tab><tab>continue<tab><tab>while (<tab><tab><tab>i + 1 < len(tokens)<tab><tab><tab>and tokens[i] == (""op"", ""."")<tab><tab><tab>and tokens[i + 1][0] == ""id""<tab><tab>):<tab><tab><tab>token += ""."" + tokens[i + 1][1]<tab><tab><tab>i += 2<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if token in pykeywords:<tab><tab><tab>continue<tab><tab>if token[0] in "".0123456789"":<tab><tab><tab>continue<tab><tab>yield token","if token == """" :",194
890,"def create_config_filepath(cls, visibility=None):<tab>if cls.is_local(visibility):<tab><tab># Local to this directory<tab><tab>base_path = os.path.join(""."")<tab><tab><IF-STMT><tab><tab><tab># Add it to the current ""./.polyaxon""<tab><tab><tab>base_path = os.path.join(base_path, "".polyaxon"")<tab><tab><tab>cls._create_dir(base_path)<tab>elif cls.CONFIG_PATH:  # Custom path<tab><tab>pass<tab>else:  # Handle both global and all cases<tab><tab>base_path = polyaxon_user_path()<tab><tab>cls._create_dir(base_path)",if cls . IS_POLYAXON_DIR :,170
891,"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab><IF-STMT><tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab>elif size <= 9:<tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64MIME.base64_len(""x"" * size), bsize)",elif size <= 3 :,160
892,"def as_dict(path="""", version=""latest"", section=""meta-data""):<tab>result = {}<tab>dirs = dir(path, version, section)<tab>if not dirs:<tab><tab>return None<tab>for item in dirs:<tab><tab><IF-STMT><tab><tab><tab>records = as_dict(path + item, version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[item[:-1]] = records<tab><tab>elif is_dict.match(item):<tab><tab><tab>idx, name = is_dict.match(item).groups()<tab><tab><tab>records = as_dict(path + idx + ""/"", version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[name] = records<tab><tab>else:<tab><tab><tab>result[item] = valueconv(get(path + item, version, section))<tab>return result","if item . endswith ( ""/"" ) :",197
893,"def api_read(self):<tab>result = {}<tab>files = [""my.cnf"", ""debian.cnf""]<tab>directory_list = self.exec_payload(""mysql_config_directory"")[""directory""]<tab>for _file in files:<tab><tab>for directory in directory_list:<tab><tab><tab>mysql_conf = directory + _file<tab><tab><tab>content = self.shell.read(mysql_conf)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[mysql_conf] = content<tab>return result",if content :,118
894,"def generate(self, count=100):<tab>self.pre_generate()<tab>counter = iter(range(count))<tab>created = 0<tab>while True:<tab><tab>batch = list(islice(counter, self.batch_size))<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>self.do_generate(batch, self.batch_size)<tab><tab>from_size = created<tab><tab>created += len(batch)<tab><tab>print(""Generate %s: %s-%s"" % (self.resource, from_size, created))<tab>self.after_generate()",if not batch :,135
895,"def _normalize_fields(self, document, loader):<tab># type: (Dict[Text, Text], Loader) -> None<tab># Normalize fields which are prefixed or full URIn to vocabulary terms<tab>for d in list(document.keys()):<tab><tab>d2 = loader.expand_url(d, u"""", scoped_id=False, vocab_term=True)<tab><tab><IF-STMT><tab><tab><tab>document[d2] = document[d]<tab><tab><tab>del document[d]",if d != d2 :,115
896,"def load_cache(filename, get_key=mangle_key):<tab>cache = {}<tab>if not os.path.exists(filename):<tab><tab>return cache<tab>f = open(filename, ""rb"")<tab>l = 0<tab>for line in f.readlines():<tab><tab>l += 1<tab><tab>fields = line.split(b"" "")<tab><tab><IF-STMT><tab><tab><tab>sys.stderr.write(""Invalid file format in [%s], line %d\n"" % (filename, l))<tab><tab><tab>continue<tab><tab># put key:value in cache, key without ^:<tab><tab>cache[get_key(fields[0][1:])] = fields[1].split(b""\n"")[0]<tab>f.close()<tab>return cache","if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :",197
897,"def __lshift__(self, other):<tab>if not self.symbolic and type(other) is int:<tab><tab>return RegisterOffset(<tab><tab><tab>self._bits, self.reg, self._to_signed(self.offset << other)<tab><tab>)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return RegisterOffset(self._bits, self.reg, self.offset << other)<tab><tab>else:<tab><tab><tab>return RegisterOffset(<tab><tab><tab><tab>self._bits,<tab><tab><tab><tab>self.reg,<tab><tab><tab><tab>ArithmeticExpression(<tab><tab><tab><tab><tab>ArithmeticExpression.LShift,<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>self.offset,<tab><tab><tab><tab><tab><tab>other,<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>),<tab><tab><tab>)",if self . symbolic :,192
898,"def SaveSettings(self, force=False):<tab>if self.config is not None:<tab><tab>frame.ShellFrameMixin.SaveSettings(self)<tab><tab><IF-STMT><tab><tab><tab>frame.Frame.SaveSettings(self, self.config)<tab><tab><tab>self.shell.SaveSettings(self.config)",if self . autoSaveSettings or force :,79
899,"def _parse_gene(element):<tab>for genename_element in element:<tab><tab>if ""type"" in genename_element.attrib:<tab><tab><tab>ann_key = ""gene_%s_%s"" % (<tab><tab><tab><tab>genename_element.tag.replace(NS, """"),<tab><tab><tab><tab>genename_element.attrib[""type""],<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.ParsedSeqRecord.annotations[ann_key] = genename_element.text<tab><tab><tab>else:<tab><tab><tab><tab>append_to_annotations(ann_key, genename_element.text)","if genename_element . attrib [ ""type"" ] == ""primary"" :",157
900,"def _write_pkg_file(self, file):<tab>with TemporaryFile(mode=""w+"") as tmpfd:<tab><tab>_write_pkg_file_orig(self, tmpfd)<tab><tab>tmpfd.seek(0)<tab><tab>for line in tmpfd:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file.write(""Metadata-Version: 2.1\n"")<tab><tab><tab>elif line.startswith(""Description: ""):<tab><tab><tab><tab>file.write(<tab><tab><tab><tab><tab>""Description-Content-Type: %s; charset=UTF-8\n""<tab><tab><tab><tab><tab>% long_description_content_type<tab><tab><tab><tab>)<tab><tab><tab><tab>file.write(line)<tab><tab><tab>else:<tab><tab><tab><tab>file.write(line)","if line . startswith ( ""Metadata-Version: "" ) :",188
901,"def get(self):<tab>""""""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called.""""""<tab>if self._exception is not _NONE:<tab><tab><IF-STMT><tab><tab><tab>return self.value<tab><tab>getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable<tab>else:<tab><tab>if self.greenlet is not None:<tab><tab><tab>raise ConcurrentObjectUseError(<tab><tab><tab><tab>""This Waiter is already used by %r"" % (self.greenlet,)<tab><tab><tab>)<tab><tab>self.greenlet = getcurrent()  # pylint:disable=undefined-variable<tab><tab>try:<tab><tab><tab>return self.hub.switch()<tab><tab>finally:<tab><tab><tab>self.greenlet = None",if self . _exception is None :,188
902,"def connect(self, *args):<tab>""""""connects to the dropbox. args[0] is the username.""""""<tab>if len(args) != 1:<tab><tab>return ""expected one argument!""<tab>try:<tab><tab>dbci = get_dropbox_client(args[0], False, None, None)<tab>except Exception as e:<tab><tab>return e.message<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return ""No Dropbox configured for '{u}'."".format(u=args[0])<tab><tab>else:<tab><tab><tab>self.client = dbci<tab><tab>return True",if dbci is None :,142
903,"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text","if ""\n"" in text :",170
904,def t(ret):<tab>with IPDB() as ipdb:<tab><tab>with ipdb.eventqueue() as evq:<tab><tab><tab>for msg in evq:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ret.append(msg)<tab><tab><tab><tab><tab>return,"if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :",83
905,"def check_stmt(self, stmt):<tab>if is_future(stmt):<tab><tab>for name, asname in stmt.names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.found[name] = 1<tab><tab><tab>else:<tab><tab><tab><tab>raise SyntaxError(""future feature %s is not defined"" % name)<tab><tab>stmt.valid_future = 1<tab><tab>return 1<tab>return 0",if name in self . features :,99
906,"def process_pypi_option(option, option_str, option_value, parser):<tab>if option_str.startswith(""--no""):<tab><tab>setattr(parser.values, option.dest, [])<tab>else:<tab><tab>indexes = getattr(parser.values, option.dest, [])<tab><tab><IF-STMT><tab><tab><tab>indexes.append(_PYPI)<tab><tab>setattr(parser.values, option.dest, indexes)",if _PYPI not in indexes :,102
907,"def modify_address(self, name, address, domain):<tab>if not self.get_entries_by_name(name, domain):<tab><tab>raise exception.NotFound<tab>infile = open(self.filename, ""r"")<tab>outfile = tempfile.NamedTemporaryFile(""w"", delete=False)<tab>for line in infile:<tab><tab>entry = self.parse_line(line)<tab><tab><IF-STMT><tab><tab><tab>outfile.write(<tab><tab><tab><tab>""%s   %s   %s\n"" % (address, self.qualify(name, domain), entry[""type""])<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>outfile.write(line)<tab>infile.close()<tab>outfile.close()<tab>shutil.move(outfile.name, self.filename)","if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :",197
908,"def tms_to_quadkey(self, tms, google=False):<tab>quadKey = """"<tab>x, y, z = tms<tab># this algorithm works with google tiles, rather than tms, so convert<tab># to those first.<tab>if not google:<tab><tab>y = (2 ** z - 1) - y<tab>for i in range(z, 0, -1):<tab><tab>digit = 0<tab><tab>mask = 1 << (i - 1)<tab><tab>if (x & mask) != 0:<tab><tab><tab>digit += 1<tab><tab><IF-STMT><tab><tab><tab>digit += 2<tab><tab>quadKey += str(digit)<tab>return quadKey",if ( y & mask ) != 0 :,164
909,"def add_if_unique(self, issuer, use, keys):<tab>if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]:<tab><tab>for typ, key in keys:<tab><tab><tab>flag = 1<tab><tab><tab>for _typ, _key in self.issuer_keys[issuer][use]:<tab><tab><tab><tab>if _typ == typ and key is _key:<tab><tab><tab><tab><tab>flag = 0<tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.issuer_keys[issuer][use].append((typ, key))<tab>else:<tab><tab>self.issuer_keys[issuer][use] = keys",if flag :,158
910,"def scan_error(self):<tab>""A string describing why the last scan failed, or None if it didn't.""<tab>self.acquire_lock()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self._load_buf_data_once()<tab><tab><tab>except NotFoundInDatabase:<tab><tab><tab><tab>pass<tab><tab>return self._scan_error_cache<tab>finally:<tab><tab>self.release_lock()",if self . _scan_error_cache is None :,114
911,"def _query(self):<tab>if self._mongo_query is None:<tab><tab>self._mongo_query = self._query_obj.to_query(self._document)<tab><tab><IF-STMT><tab><tab><tab>if ""_cls"" in self._mongo_query:<tab><tab><tab><tab>self._mongo_query = {""$and"": [self._cls_query, self._mongo_query]}<tab><tab><tab>else:<tab><tab><tab><tab>self._mongo_query.update(self._cls_query)<tab>return self._mongo_query",if self . _cls_query :,127
912,"def CountButtons(self):<tab>""""""Returns the number of visible buttons in the docked pane.""""""<tab>n = 0<tab>if self.HasCaption() or self.HasCaptionLeft():<tab><tab>if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame):<tab><tab><tab>return 1<tab><tab>if self.HasCloseButton():<tab><tab><tab>n += 1<tab><tab>if self.HasMaximizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasMinimizeButton():<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab>return n",if self . HasPinButton ( ) :,149
913,"def testBind(self):<tab>try:<tab><tab>with socket.socket(socket.PF_CAN, socket.SOCK_DGRAM, socket.CAN_J1939) as s:<tab><tab><tab>addr = (<tab><tab><tab><tab>self.interface,<tab><tab><tab><tab>socket.J1939_NO_NAME,<tab><tab><tab><tab>socket.J1939_NO_PGN,<tab><tab><tab><tab>socket.J1939_NO_ADDR,<tab><tab><tab>)<tab><tab><tab>s.bind(addr)<tab><tab><tab>self.assertEqual(s.getsockname(), addr)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""network interface `%s` does not exist"" % self.interface)<tab><tab>else:<tab><tab><tab>raise",if e . errno == errno . ENODEV :,189
914,"def createFields(self):<tab>while self.current_size < self.size:<tab><tab>pos = self.stream.searchBytes(<tab><tab><tab>""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8<tab><tab>)  # seek forward by at most 1MB<tab><tab>if pos is not None:<tab><tab><tab>padsize = pos - self.current_size<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield PaddingBytes(self, ""pad[]"", padsize // 8)<tab><tab>chunk = Chunk(self, ""chunk[]"")<tab><tab>try:<tab><tab><tab># force chunk to be processed, so that CustomFragments are complete<tab><tab><tab>chunk[""content/data""]<tab><tab>except:<tab><tab><tab>pass<tab><tab>yield chunk",if padsize :,184
915,"def index_modulemd_files(repo_path):<tab>merger = Modulemd.ModuleIndexMerger()<tab>for fn in sorted(os.listdir(repo_path)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yaml_path = os.path.join(repo_path, fn)<tab><tab>mmd = Modulemd.ModuleIndex()<tab><tab>mmd.update_from_file(yaml_path, strict=True)<tab><tab>merger.associate_index(mmd, 0)<tab>return merger.resolve()","if not fn . endswith ( "".yaml"" ) :",129
916,"def set_visible(self, visible=True):<tab>self._visible = visible<tab>if self._nswindow is not None:<tab><tab><IF-STMT><tab><tab><tab># Not really sure why on_resize needs to be here,<tab><tab><tab># but it's what pyglet wants.<tab><tab><tab>self.dispatch_event(""on_resize"", self._width, self._height)<tab><tab><tab>self.dispatch_event(""on_show"")<tab><tab><tab>self.dispatch_event(""on_expose"")<tab><tab><tab>self._nswindow.makeKeyAndOrderFront_(None)<tab><tab>else:<tab><tab><tab>self._nswindow.orderOut_(None)",if visible :,153
917,"def __repr__(self):<tab>if self._in_repr:<tab><tab>return ""<recursion>""<tab>try:<tab><tab>self._in_repr = True<tab><tab>if self.is_computed():<tab><tab><tab>status = ""computed, ""<tab><tab><tab>if self.error() is None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>status += ""= self""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>status += ""= "" + repr(self.value())<tab><tab><tab>else:<tab><tab><tab><tab>status += ""error = "" + repr(self.error())<tab><tab>else:<tab><tab><tab>status = ""isn't computed""<tab><tab>return ""%s (%s)"" % (type(self), status)<tab>finally:<tab><tab>self._in_repr = False",if self . value ( ) is self :,189
918,"def _individual_get(self, segment, index_type, index, strictdoc):<tab>if index_type == ""val"":<tab><tab>for key, value in segment.items():<tab><tab><tab>if key == index[0]:<tab><tab><tab><tab>return value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if key.text == index[0]:<tab><tab><tab><tab><tab>return value<tab><tab>raise Exception(""Invalid state"")<tab>elif index_type == ""index"":<tab><tab>return segment[index]<tab>elif index_type == ""textslice"":<tab><tab>return segment[index[0] : index[1]]<tab>elif index_type == ""key"":<tab><tab>return index[1] if strictdoc else index[0]<tab>else:<tab><tab>raise Exception(""Invalid state"")","if hasattr ( key , ""text"" ) :",186
919,"def _makeSafeAbsoluteURI(base, rel=None):<tab># bail if ACCEPTABLE_URI_SCHEMES is empty<tab>if not ACCEPTABLE_URI_SCHEMES:<tab><tab>return _urljoin(base, rel or u"""")<tab>if not base:<tab><tab>return rel or u""""<tab>if not rel:<tab><tab>try:<tab><tab><tab>scheme = urlparse.urlparse(base)[0]<tab><tab>except ValueError:<tab><tab><tab>return u""""<tab><tab><IF-STMT><tab><tab><tab>return base<tab><tab>return u""""<tab>uri = _urljoin(base, rel)<tab>if uri.strip().split("":"", 1)[0] not in ACCEPTABLE_URI_SCHEMES:<tab><tab>return u""""<tab>return uri",if not scheme or scheme in ACCEPTABLE_URI_SCHEMES :,186
920,"def _write_packet(self, packet):<tab># Immediately writes the given packet to the network. The caller must<tab># have the write lock acquired before calling this method.<tab>try:<tab><tab>for listener in self.early_outgoing_packet_listeners:<tab><tab><tab>listener.call_packet(packet)<tab><tab><IF-STMT><tab><tab><tab>packet.write(self.socket, self.options.compression_threshold)<tab><tab>else:<tab><tab><tab>packet.write(self.socket)<tab><tab>for listener in self.outgoing_packet_listeners:<tab><tab><tab>listener.call_packet(packet)<tab>except IgnorePacket:<tab><tab>pass",if self . options . compression_enabled :,160
921,"def rangelist_to_set(rangelist):<tab>result = set()<tab>if not rangelist:<tab><tab>return result<tab>for x in rangelist.split("",""):<tab><tab><IF-STMT><tab><tab><tab>result.add(int(x))<tab><tab><tab>continue<tab><tab>m = re.match(r""^(\d+)-(\d+)$"", x)<tab><tab>if m:<tab><tab><tab>start = int(m.group(1))<tab><tab><tab>end = int(m.group(2))<tab><tab><tab>result.update(set(range(start, end + 1)))<tab><tab><tab>continue<tab><tab>msg = ""Cannot understand data input: %s %s"" % (x, rangelist)<tab><tab>raise ValueError(msg)<tab>return result","if re . match ( r""^(\d+)$"" , x ) :",181
922,"def test_device_property_logfile_isinstance(self):<tab>mock = MagicMock()<tab>with patch(builtin_string + "".open"", mock):<tab><tab><IF-STMT><tab><tab><tab>builtin_file = ""io.TextIOWrapper""<tab><tab>else:<tab><tab><tab>builtin_file = builtin_string + "".file""<tab><tab>with patch(builtin_file, MagicMock):<tab><tab><tab>handle = open(""filename"", ""r"")<tab><tab><tab>self.dev.logfile = handle<tab><tab><tab>self.assertEqual(self.dev.logfile, handle)","if sys . version > ""3"" :",130
923,"def _line_ranges(statements, lines):<tab>""""""Produce a list of ranges for `format_lines`.""""""<tab>statements = sorted(statements)<tab>lines = sorted(lines)<tab>pairs = []<tab>start = None<tab>lidx = 0<tab>for stmt in statements:<tab><tab>if lidx >= len(lines):<tab><tab><tab>break<tab><tab>if stmt == lines[lidx]:<tab><tab><tab>lidx += 1<tab><tab><tab>if not start:<tab><tab><tab><tab>start = stmt<tab><tab><tab>end = stmt<tab><tab><IF-STMT><tab><tab><tab>pairs.append((start, end))<tab><tab><tab>start = None<tab>if start:<tab><tab>pairs.append((start, end))<tab>return pairs",elif start :,167
924,"def reset_parameters(self):<tab>initialize = layers.get_initializer(self._hparams.initializer)<tab>if initialize is not None:<tab><tab># Do not re-initialize LayerNorm modules.<tab><tab>for name, param in self.named_parameters():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>initialize(param)","if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :",93
925,"def billing_invoice_show_validator(namespace):<tab>from azure.cli.core.azclierror import (<tab><tab>RequiredArgumentMissingError,<tab><tab>MutuallyExclusiveArgumentError,<tab>)<tab>valid_combs = (<tab><tab>""only --account-name, --name / --name / --name, --by-subscription is valid""<tab>)<tab>if namespace.account_name is not None:<tab><tab>if namespace.by_subscription is not None:<tab><tab><tab>raise MutuallyExclusiveArgumentError(valid_combs)<tab><tab><IF-STMT><tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")<tab>if namespace.by_subscription is not None:<tab><tab>if namespace.name is None:<tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")",if namespace . name is None :,188
926,"def DeleteDocuments(self, document_ids, response):<tab>""""""Deletes documents for the given document_ids.""""""<tab>for document_id in document_ids:<tab><tab><IF-STMT><tab><tab><tab>document = self._documents[document_id]<tab><tab><tab>self._inverted_index.RemoveDocument(document)<tab><tab><tab>del self._documents[document_id]<tab><tab>delete_status = response.add_status()<tab><tab>delete_status.set_code(search_service_pb.SearchServiceError.OK)",if document_id in self . _documents :,125
927,"def generate_new_element(items, prefix, numeric=False):<tab>""""""Creates a random string with prefix, that is not in 'items' list.""""""<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>candidate = prefix + generate_random_numeric(8)<tab><tab>else:<tab><tab><tab>candidate = prefix + generate_random_alphanumeric(8)<tab><tab>if not candidate in items:<tab><tab><tab>return candidate<tab><tab>LOG.debug(""Random collision on %s"" % candidate)",if numeric :,115
928,"def generate_text_for_vocab(self, data_dir, tmp_dir):<tab>for i, sample in enumerate(<tab><tab>self.generate_samples(data_dir, tmp_dir, problem.DatasetSplit.TRAIN)<tab>):<tab><tab>if self.has_inputs:<tab><tab><tab>yield sample[""inputs""]<tab><tab>yield sample[""targets""]<tab><tab><IF-STMT><tab><tab><tab>break",if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,118
929,"def _get_ccp(config=None, config_path=None, saltenv=""base""):<tab>"""""" """"""<tab>if config_path:<tab><tab>config = __salt__[""cp.get_file_str""](config_path, saltenv=saltenv)<tab><tab><IF-STMT><tab><tab><tab>raise SaltException(""{} is not available"".format(config_path))<tab>if isinstance(config, six.string_types):<tab><tab>config = config.splitlines()<tab>ccp = ciscoconfparse.CiscoConfParse(config)<tab>return ccp",if config is False :,135
930,"def rpush(key, *vals, **kwargs):<tab>ttl = kwargs.get(""ttl"")<tab>cap = kwargs.get(""cap"")<tab>if not ttl and not cap:<tab><tab>_client.rpush(key, *vals)<tab>else:<tab><tab>pipe = _client.pipeline()<tab><tab>pipe.rpush(key, *vals)<tab><tab><IF-STMT><tab><tab><tab>pipe.ltrim(key, 0, cap)<tab><tab>if ttl:<tab><tab><tab>pipe.expire(key, ttl)<tab><tab>pipe.execute()",if cap :,131
931,"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""key""<tab><tab>elif mode == ""key"":<tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab>elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","if mode == ""start"" :",195
932,"def _add_communication_type(apps, schema_editor, communication_type):<tab>Worker = apps.get_model(""orchestra"", ""Worker"")<tab>CommunicationPreference = apps.get_model(""orchestra"", ""CommunicationPreference"")<tab>for worker in Worker.objects.all():<tab><tab>(<tab><tab><tab>communication_preference,<tab><tab><tab>created,<tab><tab>) = CommunicationPreference.objects.get_or_create(<tab><tab><tab>worker=worker, communication_type=communication_type<tab><tab>)<tab><tab># By default set both Slack and Email notifications to True<tab><tab><IF-STMT><tab><tab><tab>communication_preference.methods.slack = True<tab><tab><tab>communication_preference.methods.email = True<tab><tab>communication_preference.save()",if created :,183
933,"def get_postgresql_driver_name():<tab># pylint: disable=unused-variable<tab>try:<tab><tab>driver = os.getenv(""CODECHECKER_DB_DRIVER"")<tab><tab><IF-STMT><tab><tab><tab>return driver<tab><tab>try:<tab><tab><tab># pylint: disable=W0611<tab><tab><tab>import psycopg2<tab><tab><tab>return ""psycopg2""<tab><tab>except Exception:<tab><tab><tab># pylint: disable=W0611<tab><tab><tab>import pg8000<tab><tab><tab>return ""pg8000""<tab>except Exception as ex:<tab><tab>LOG.error(str(ex))<tab><tab>LOG.error(""Failed to import psycopg2 or pg8000 module."")<tab><tab>raise",if driver :,157
934,"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None:<tab>modules = getattr(env, ""_viewcode_modules"", {})<tab>for modname, entry in list(modules.items()):<tab><tab>if entry is False:<tab><tab><tab>continue<tab><tab>code, tags, used, refname = entry<tab><tab>for fullname in list(used):<tab><tab><tab>if used[fullname] == docname:<tab><tab><tab><tab>used.pop(fullname)<tab><tab><IF-STMT><tab><tab><tab>modules.pop(modname)",if len ( used ) == 0 :,133
935,"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab>if len(q) == 1:<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.append(value)<tab><tab><tab>elif is_iterable(value):<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",if not is_iterable ( value ) :,185
936,"def _get_bucket_for_key(self, key: bytes) -> Optional[_DBValueTuple]:<tab>dbs: Iterable[PartitionDB]<tab>try:<tab><tab>partition = self._key_index[key]<tab><tab>dbs = [PartitionDB(partition, self._dbs[partition])]<tab>except KeyError:<tab><tab>dbs = cast(Iterable[PartitionDB], self._dbs.items())<tab>for partition, db in dbs:<tab><tab>if db.key_may_exist(key)[0]:<tab><tab><tab>value = db.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._key_index[key] = partition<tab><tab><tab><tab>return _DBValueTuple(db, value)<tab>return None",if value is not None :,177
937,"def _clean(self):<tab>logger.info(""Cleaning up..."")<tab>if self._process is not None:<tab><tab>if self._process.poll() is None:<tab><tab><tab>for _ in range(3):<tab><tab><tab><tab>self._process.terminate()<tab><tab><tab><tab>time.sleep(0.5)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self._process.kill()<tab><tab><tab><tab>self._process.wait()<tab><tab><tab><tab>logger.error(""KILLED"")<tab>if os.path.exists(self._tmp_dir):<tab><tab>shutil.rmtree(self._tmp_dir)<tab>self._process = None<tab>self._ws = None<tab>logger.info(""Cleanup complete"")",if self . _process . poll ( ) is not None :,189
938,"def _calculate_runtimes(states):<tab>results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0}<tab>for state, resultset in states.items():<tab><tab>if isinstance(resultset, dict) and ""duration"" in resultset:<tab><tab><tab># Count the pass vs failures<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results[""num_passed_states""] += 1<tab><tab><tab>else:<tab><tab><tab><tab>results[""num_failed_states""] += 1<tab><tab><tab># Count durations<tab><tab><tab>results[""runtime""] += resultset[""duration""]<tab>log.debug(""Parsed state metrics: {}"".format(results))<tab>return results","if resultset [ ""result"" ] :",167
939,"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None):<tab>if next is not None and token.end_mark.line == next.start_mark.line:<tab><tab>spaces = next.start_mark.pointer - token.end_mark.pointer<tab><tab>if max != -1 and spaces > max:<tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column, max_desc<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column + 1, min_desc<tab><tab><tab>)",elif min != - 1 and spaces < min :,184
940,"def getfileinfo(name):<tab>finfo = FInfo()<tab>with io.open(name, ""rb"") as fp:<tab><tab># Quick check for textfile<tab><tab>data = fp.read(512)<tab><tab><IF-STMT><tab><tab><tab>finfo.Type = ""TEXT""<tab><tab>fp.seek(0, 2)<tab><tab>dsize = fp.tell()<tab>dir, file = os.path.split(name)<tab>file = file.replace("":"", ""-"", 1)<tab>return file, finfo, dsize, 0",if 0 not in data :,124
941,"def dict_to_XML(tag, dictionary, **kwargs):<tab>""""""Return XML element converting dicts recursively.""""""<tab>elem = Element(tag, **kwargs)<tab>for key, val in dictionary.items():<tab><tab>if tag == ""layers"":<tab><tab><tab>child = dict_to_XML(""layer"", val, name=key)<tab><tab><IF-STMT><tab><tab><tab>child = dict_to_XML(key, val)<tab><tab>else:<tab><tab><tab>if tag == ""config"":<tab><tab><tab><tab>child = Element(""variable"", name=key)<tab><tab><tab>else:<tab><tab><tab><tab>child = Element(key)<tab><tab><tab>child.text = str(val)<tab><tab>elem.append(child)<tab>return elem","elif isinstance ( val , MutableMapping ) :",175
942,"def _read_bytes(self, length):<tab>buffer = b""""<tab>while length:<tab><tab>chunk = self.request.recv(length)<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Connection closed"")<tab><tab><tab>return False<tab><tab>length -= len(chunk)<tab><tab>buffer += chunk<tab>return buffer","if chunk == b"""" :",79
943,"def rec_deps(services, container_by_name, cnt, init_service):<tab>deps = cnt[""_deps""]<tab>for dep in deps.copy():<tab><tab>dep_cnts = services.get(dep)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dep_cnt = container_by_name.get(dep_cnts[0])<tab><tab>if dep_cnt:<tab><tab><tab># TODO: avoid creating loops, A->B->A<tab><tab><tab>if init_service and init_service in dep_cnt[""_deps""]:<tab><tab><tab><tab>continue<tab><tab><tab>new_deps = rec_deps(services, container_by_name, dep_cnt, init_service)<tab><tab><tab>deps.update(new_deps)<tab>return deps",if not dep_cnts :,181
944,"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if e.value is None:<tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab>elif type(e.value) is not list:<tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab>if type(e) is Command or type(e) is Option and e.argcount == 0:<tab><tab><tab><tab>e.value = 0<tab>return self",if type ( e ) is Argument or type ( e ) is Option and e . argcount :,190
945,"def do_cli(manager, options):<tab>header = [""Name"", ""Description""]<tab>table_data = [header]<tab>for filter_name, filter in get_filters():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>filter_doc = inspect.getdoc(filter) or """"<tab><tab>table_data.append([filter_name, filter_doc])<tab>try:<tab><tab>table = TerminalTable(options.table_type, table_data)<tab>except TerminalTableError as e:<tab><tab>console(""ERROR: %s"" % str(e))<tab>else:<tab><tab>console(table.output)",if options . name and not options . name in filter_name :,155
946,"def _do_cmp(f1, f2):<tab>bufsize = BUFSIZE<tab>with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2:<tab><tab>while True:<tab><tab><tab>b1 = fp1.read(bufsize)<tab><tab><tab>b2 = fp2.read(bufsize)<tab><tab><tab>if b1 != b2:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True",if not b1 :,118
947,"def apply(self, db, person):<tab>families = person.get_parent_family_handle_list()<tab>if families == []:<tab><tab>return True<tab>for family_handle in person.get_parent_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>father_handle = family.get_father_handle()<tab><tab><tab>mother_handle = family.get_mother_handle()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>if not mother_handle:<tab><tab><tab><tab>return True<tab>return False",if not father_handle :,157
948,"def caesar_cipher(s, k):<tab>result = """"<tab>for char in s:<tab><tab>n = ord(char)<tab><tab>if 64 < n < 91:<tab><tab><tab>n = ((n - 65 + k) % 26) + 65<tab><tab><IF-STMT><tab><tab><tab>n = ((n - 97 + k) % 26) + 97<tab><tab>result = result + chr(n)<tab>return result",if 96 < n < 123 :,104
949,"def title_by_index(self, trans, index, context):<tab>d_type = self.get_datatype(trans, context)<tab>for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()):<tab><tab>if i == index:<tab><tab><tab>rval = composite_name<tab><tab><tab>if composite_file.description:<tab><tab><tab><tab>rval = ""{} ({})"".format(rval, composite_file.description)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rval = ""%s [optional]"" % rval<tab><tab><tab>return rval<tab>if index < self.get_file_count(trans, context):<tab><tab>return ""Extra primary file""<tab>return None",if composite_file . optional :,167
950,"def __str__(self):<tab>t = ""<tab>""<tab>if self._name != ""root"":<tab><tab>r = f""{t * (self._level-1)}{self._name}:\n""<tab>else:<tab><tab>r = """"<tab>level = self._level<tab>for i, (k, v) in enumerate(self._pointer.items()):<tab><tab><IF-STMT><tab><tab><tab>r += f""{t * (self._level)}{v}\n""<tab><tab><tab>self._level += 1<tab><tab>else:<tab><tab><tab>r += f""{t * (self._level)}{k}: {v} ({type(v).__name__})\n""<tab><tab>self._level = level<tab>return r[:-1]","if isinstance ( v , Config ) :",176
951,"def __get_securitygroups(vm_):<tab>vm_securitygroups = config.get_cloud_config_value(<tab><tab>""securitygroups"", vm_, __opts__, search_global=False<tab>)<tab>if not vm_securitygroups:<tab><tab>return []<tab>securitygroups = list_securitygroups()<tab>for i in range(len(vm_securitygroups)):<tab><tab>vm_securitygroups[i] = six.text_type(vm_securitygroups[i])<tab><tab><IF-STMT><tab><tab><tab>raise SaltCloudNotFound(<tab><tab><tab><tab>""The specified securitygroups '{0}' could not be found."".format(<tab><tab><tab><tab><tab>vm_securitygroups[i]<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return vm_securitygroups",if vm_securitygroups [ i ] not in securitygroups :,186
952,"def assert_walk_snapshot(<tab>self, field, filespecs_or_globs, paths, ignore_patterns=None, prepare=None):<tab>with self.mk_project_tree(ignore_patterns=ignore_patterns) as project_tree:<tab><tab>scheduler = self.mk_scheduler(<tab><tab><tab>rules=create_fs_rules(), project_tree=project_tree<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>prepare(project_tree)<tab><tab>result = self.execute(scheduler, Snapshot, self.specs(filespecs_or_globs))[0]<tab><tab>self.assertEqual(sorted(getattr(result, field)), sorted(paths))",if prepare :,152
953,"def _parse_rowids(self, rowids):<tab>xploded = []<tab>rowids = [x.strip() for x in rowids.split("","")]<tab>for rowid in rowids:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = int(rowid.split(""-"")[0].strip())<tab><tab><tab><tab>end = int(rowid.split(""-"")[-1].strip())<tab><tab><tab><tab>xploded += range(start, end + 1)<tab><tab><tab>else:<tab><tab><tab><tab>xploded.append(int(rowid))<tab><tab>except ValueError:<tab><tab><tab>continue<tab>return sorted(list(set(xploded)))","if ""-"" in rowid :",156
954,"def ensemble(self, pairs, other_preds):<tab>""""""Ensemble the dict with statistical model predictions.""""""<tab>lemmas = []<tab>assert len(pairs) == len(other_preds)<tab>for p, pred in zip(pairs, other_preds):<tab><tab>w, pos = p<tab><tab><IF-STMT><tab><tab><tab>lemma = self.composite_dict[(w, pos)]<tab><tab>elif w in self.word_dict:<tab><tab><tab>lemma = self.word_dict[w]<tab><tab>else:<tab><tab><tab>lemma = pred<tab><tab>if lemma is None:<tab><tab><tab>lemma = w<tab><tab>lemmas.append(lemma)<tab>return lemmas","if ( w , pos ) in self . composite_dict :",164
955,"def selectionToChunks(self, remove=False, add=False):<tab>box = self.selectionBox()<tab>if box:<tab><tab><IF-STMT><tab><tab><tab>self.selectedChunks = set(self.level.allChunks)<tab><tab><tab>return<tab><tab>selectedChunks = self.selectedChunks<tab><tab>boxedChunks = set(box.chunkPositions)<tab><tab>if boxedChunks.issubset(selectedChunks):<tab><tab><tab>remove = True<tab><tab>if remove and not add:<tab><tab><tab>selectedChunks.difference_update(boxedChunks)<tab><tab>else:<tab><tab><tab>selectedChunks.update(boxedChunks)<tab>self.selectionTool.selectNone()",if box == self . level . bounds :,158
956,"def _ensure_max_size(cls, image, max_size, interpolation):<tab>if max_size is not None:<tab><tab>size = max(image.shape[0], image.shape[1])<tab><tab><IF-STMT><tab><tab><tab>resize_factor = max_size / size<tab><tab><tab>new_height = int(image.shape[0] * resize_factor)<tab><tab><tab>new_width = int(image.shape[1] * resize_factor)<tab><tab><tab>image = ia.imresize_single_image(<tab><tab><tab><tab>image, (new_height, new_width), interpolation=interpolation<tab><tab><tab>)<tab>return image",if size > max_size :,155
957,"def _1_0_cloud_ips(self, method, url, body, headers):<tab>if method == ""GET"":<tab><tab>return self.test_response(httplib.OK, self.fixtures.load(""list_cloud_ips.json""))<tab>elif method == ""POST"":<tab><tab><IF-STMT><tab><tab><tab>body = json.loads(body)<tab><tab>node = json.loads(self.fixtures.load(""create_cloud_ip.json""))<tab><tab>if ""reverse_dns"" in body:<tab><tab><tab>node[""reverse_dns""] = body[""reverse_dns""]<tab><tab>return self.test_response(httplib.ACCEPTED, json.dumps(node))",if body :,159
958,"def get_formatted_stats(self):<tab>""""""Get percentage or number of rar's done""""""<tab>if self.cur_setname and self.cur_setname in self.total_volumes:<tab><tab># This won't work on obfuscated posts<tab><tab><IF-STMT><tab><tab><tab>return ""%02d/%02d"" % (self.cur_volume, self.total_volumes[self.cur_setname])<tab>return self.cur_volume",if self . total_volumes [ self . cur_setname ] >= self . cur_volume and self . cur_volume :,128
959,"def wdayset(self, year, month, day):<tab># We need to handle cross-year weeks here.<tab>dset = [None] * (self.yearlen + 7)<tab>i = datetime.date(year, month, day).toordinal() - self.yearordinal<tab>start = i<tab>for j in range(7):<tab><tab>dset[i] = i<tab><tab>i += 1<tab><tab># if (not (0 <= i < self.yearlen) or<tab><tab>#<tab>self.wdaymask[i] == self.rrule._wkst):<tab><tab># This will cross the year boundary, if necessary.<tab><tab><IF-STMT><tab><tab><tab>break<tab>return dset, start, i",if self . wdaymask [ i ] == self . rrule . _wkst :,184
960,"def do_acquire_read_lock(self, wait=True):<tab>self.condition.acquire()<tab>try:<tab><tab># see if a synchronous operation is waiting to start<tab><tab># or is already running, in which case we wait (or just<tab><tab># give up and return)<tab><tab><IF-STMT><tab><tab><tab>while self.current_sync_operation is not None:<tab><tab><tab><tab>self.condition.wait()<tab><tab>else:<tab><tab><tab>if self.current_sync_operation is not None:<tab><tab><tab><tab>return False<tab><tab>self.asynch += 1<tab>finally:<tab><tab>self.condition.release()<tab>if not wait:<tab><tab>return True",if wait :,162
961,"def _blend(x, y):  # pylint: disable=invalid-name<tab>""""""Implements the ""blend"" strategy for `deep_merge`.""""""<tab>if isinstance(x, (dict, OrderedDict)):<tab><tab><IF-STMT><tab><tab><tab>return y<tab><tab>return _merge(x, y, recursion_func=_blend)<tab>if isinstance(x, (list, tuple)):<tab><tab>if not isinstance(y, (list, tuple)):<tab><tab><tab>return y<tab><tab>result = [_blend(*i) for i in zip(x, y)]<tab><tab>if len(x) > len(y):<tab><tab><tab>result += x[len(y) :]<tab><tab>elif len(x) < len(y):<tab><tab><tab>result += y[len(x) :]<tab><tab>return result<tab>return y","if not isinstance ( y , ( dict , OrderedDict ) ) :",194
962,"def update_forum_nums_topic_post(modeladmin, request, queryset):<tab>for forum in queryset:<tab><tab>forum.num_topics = forum.count_nums_topic()<tab><tab>forum.num_posts = forum.count_nums_post()<tab><tab><IF-STMT><tab><tab><tab>forum.last_post = forum.topic_set.order_by(""-last_reply_on"")[0].last_post<tab><tab>else:<tab><tab><tab>forum.last_post = """"<tab><tab>forum.save()",if forum . num_topics :,123
963,"def get_docname_for_node(self, node: Node) -> str:<tab>while node:<tab><tab>if isinstance(node, nodes.document):<tab><tab><tab>return self.env.path2doc(node[""source""])<tab><tab><IF-STMT><tab><tab><tab>return node[""docname""]<tab><tab>else:<tab><tab><tab>node = node.parent<tab>return None  # never reached here. only for type hinting","elif isinstance ( node , addnodes . start_of_file ) :",110
964,"def _selected_machines(self, virtual_machines):<tab>selected_machines = []<tab>for machine in virtual_machines:<tab><tab>if self._args.host and self._args.host == machine.name:<tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.tags and self._tags_match(machine.tags, self.tags):<tab><tab><tab>selected_machines.append(machine)<tab><tab><IF-STMT><tab><tab><tab>selected_machines.append(machine)<tab>return selected_machines",if self . locations and machine . location in self . locations :,129
965,"def transform_kwarg(self, name, value, split_single_char_options):<tab>if len(name) == 1:<tab><tab>if value is True:<tab><tab><tab>return [""-%s"" % name]<tab><tab><IF-STMT><tab><tab><tab>if split_single_char_options:<tab><tab><tab><tab>return [""-%s"" % name, ""%s"" % value]<tab><tab><tab>else:<tab><tab><tab><tab>return [""-%s%s"" % (name, value)]<tab>else:<tab><tab>if value is True:<tab><tab><tab>return [""--%s"" % dashify(name)]<tab><tab>elif value is not False and value is not None:<tab><tab><tab>return [""--%s=%s"" % (dashify(name), value)]<tab>return []","elif value not in ( False , None ) :",183
966,"def indent(elem, level=0):<tab>i = ""\n"" + level * ""  ""<tab>if len(elem):<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,161
967,"def _run_instances_op(self, op, instance_ids, **kwargs):<tab>while instance_ids:<tab><tab>try:<tab><tab><tab>return self.manager.retry(op, InstanceIds=instance_ids, **kwargs)<tab><tab>except ClientError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>instance_ids.remove(extract_instance_id(e))<tab><tab><tab>raise","if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :",105
968,"def runTest(self):<tab>self.poco(text=""wait UI"").click()<tab>bomb_count = 0<tab>while True:<tab><tab>blue_fish = self.poco(""fish_emitter"").child(""blue"")<tab><tab>yellow_fish = self.poco(""fish_emitter"").child(""yellow"")<tab><tab>bomb = self.poco(""fish_emitter"").child(""bomb"")<tab><tab>fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb])<tab><tab><IF-STMT><tab><tab><tab>bomb_count += 1<tab><tab><tab>if bomb_count > 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>fish.click()<tab><tab>time.sleep(2.5)",if fish is bomb :,192
969,"def lineWidth(self, lw=None):<tab>""""""Set/get width of mesh edges. Same as `lw()`.""""""<tab>if lw is not None:<tab><tab><IF-STMT><tab><tab><tab>self.GetProperty().EdgeVisibilityOff()<tab><tab><tab>self.GetProperty().SetRepresentationToSurface()<tab><tab><tab>return self<tab><tab>self.GetProperty().EdgeVisibilityOn()<tab><tab>self.GetProperty().SetLineWidth(lw)<tab>else:<tab><tab>return self.GetProperty().GetLineWidth()<tab>return self",if lw == 0 :,130
970,"def _current_date_updater(doc, field_name, value):<tab>if isinstance(doc, dict):<tab><tab><IF-STMT><tab><tab><tab># TODO(juannyg): get_current_timestamp should also be using helpers utcnow,<tab><tab><tab># as it currently using time.time internally<tab><tab><tab>doc[field_name] = helpers.get_current_timestamp()<tab><tab>else:<tab><tab><tab>doc[field_name] = mongomock.utcnow()","if value == { ""$type"" : ""timestamp"" } :",118
971,"def fill_members(self):<tab>if self._get_retrieve():<tab><tab>after = self.after.id if self.after else None<tab><tab>data = await self.get_members(self.guild.id, self.retrieve, after)<tab><tab><IF-STMT><tab><tab><tab># no data, terminate<tab><tab><tab>return<tab><tab>if len(data) < 1000:<tab><tab><tab>self.limit = 0  # terminate loop<tab><tab>self.after = Object(id=int(data[-1][""user""][""id""]))<tab><tab>for element in reversed(data):<tab><tab><tab>await self.members.put(self.create_member(element))",if not data :,153
972,"def extract(self, page, start_index=0, end_index=None):<tab>items = []<tab>for extractor in self.extractors:<tab><tab>extracted = extractor.extract(<tab><tab><tab>page, start_index, end_index, self.template.ignored_regions<tab><tab>)<tab><tab>for item in arg_to_iter(extracted):<tab><tab><tab>if item:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>item[u""_template""] = self.template.id<tab><tab><tab><tab>items.append(item)<tab>return items","if isinstance ( item , ( ItemProcessor , dict ) ) :",141
973,"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any:<tab>fields = self.config[fields_key]<tab>node_tags = self.provider.node_tags(node_id)<tab>if TAG_RAY_USER_NODE_TYPE in node_tags:<tab><tab>node_type = node_tags[TAG_RAY_USER_NODE_TYPE]<tab><tab>if node_type not in self.available_node_types:<tab><tab><tab>raise ValueError(f""Unknown node type tag: {node_type}."")<tab><tab>node_specific_config = self.available_node_types[node_type]<tab><tab><IF-STMT><tab><tab><tab>fields = node_specific_config[fields_key]<tab>return fields",if fields_key in node_specific_config :,189
974,"def _write_all(self, writer):<tab>""""""Writes messages and insert comments here and there.""""""<tab># Note: we make no assumptions about the length of original_messages and original_comments<tab>for msg, comment in zip_longest(<tab><tab>self.original_messages, self.original_comments, fillvalue=None<tab>):<tab><tab># msg and comment might be None<tab><tab><IF-STMT><tab><tab><tab>print(""writing comment: "", comment)<tab><tab><tab>writer.log_event(comment)  # we already know that this method exists<tab><tab>if msg is not None:<tab><tab><tab>print(""writing message: "", msg)<tab><tab><tab>writer(msg)",if comment is not None :,157
975,"def run_tests():<tab># type: () -> None<tab>x = 5<tab>with switch(x) as case:<tab><tab><IF-STMT><tab><tab><tab>print(""zero"")<tab><tab><tab>print(""zero"")<tab><tab>elif case(1, 2):<tab><tab><tab>print(""one or two"")<tab><tab>elif case(3, 4):<tab><tab><tab>print(""three or four"")<tab><tab>else:<tab><tab><tab>print(""default"")<tab><tab><tab>print(""another"")",if case ( 0 ) :,114
976,"def date_to_format(value, target_format):<tab>""""""Convert date to specified format""""""<tab>if target_format == str:<tab><tab>if isinstance(value, datetime.date):<tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab><IF-STMT><tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab>elif isinstance(value, datetime.time):<tab><tab><tab>ret = value.strftime(""%H:%M:%S"")<tab>else:<tab><tab>ret = value<tab>return ret","elif isinstance ( value , datetime . datetime ) :",130
977,"def database_app(request):<tab>if request.param == ""postgres_app"":<tab><tab>if not which(""initdb""):<tab><tab><tab>pytest.skip(""initdb must be on PATH for postgresql fixture"")<tab><tab><IF-STMT><tab><tab><tab>pytest.skip(""psycopg2 must be installed for postgresql fixture"")<tab>if request.param == ""sqlite_rabbitmq_app"":<tab><tab>if not os.environ.get(""GALAXY_TEST_AMQP_INTERNAL_CONNECTION""):<tab><tab><tab>pytest.skip(<tab><tab><tab><tab>""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset""<tab><tab><tab>)<tab>return request.getfixturevalue(request.param)",if not psycopg2 :,174
978,"def poll_ms(self, timeout=-1):<tab>s = bytearray(self.evbuf)<tab><IF-STMT><tab><tab>deadline = utime.ticks_add(utime.ticks_ms(), timeout)<tab>while True:<tab><tab>n = epoll_wait(self.epfd, s, 1, timeout)<tab><tab>if not os.check_error(n):<tab><tab><tab>break<tab><tab>if timeout >= 0:<tab><tab><tab>timeout = utime.ticks_diff(deadline, utime.ticks_ms())<tab><tab><tab>if timeout < 0:<tab><tab><tab><tab>n = 0<tab><tab><tab><tab>break<tab>res = []<tab>if n > 0:<tab><tab>vals = struct.unpack(epoll_event, s)<tab><tab>res.append((vals[1], vals[0]))<tab>return res",if timeout >= 0 :,192
979,"def get_all_active_plugins(self) -> List[BotPlugin]:<tab>""""""This returns the list of plugins in the callback ordered defined from the config.""""""<tab>all_plugins = []<tab>for name in self.plugins_callback_order:<tab><tab># None is a placeholder for any plugin not having a defined order<tab><tab>if name is None:<tab><tab><tab>all_plugins += [<tab><tab><tab><tab>plugin<tab><tab><tab><tab>for name, plugin in self.plugins.items()<tab><tab><tab><tab>if name not in self.plugins_callback_order and plugin.is_activated<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>plugin = self.plugins[name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_plugins.append(plugin)<tab>return all_plugins",if plugin . is_activated :,186
980,"def get_expected_sql(self):<tab>sql_base_path = path.join(path.dirname(path.realpath(__file__)), ""sql"")<tab># Iterate the version mapping directories.<tab>for version_mapping in get_version_mapping_directories(self.server[""type""]):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>complete_path = path.join(sql_base_path, version_mapping[""name""])<tab><tab>if not path.exists(complete_path):<tab><tab><tab>continue<tab><tab>break<tab>data_sql = """"<tab>with open(path.join(complete_path, ""test_sql_output.sql"")) as fp:<tab><tab>data_sql = fp.read()<tab>return data_sql","if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :",185
981,"def _validate_headers(self, headers):<tab>if headers is None:<tab><tab>return headers<tab>res = {}<tab>for key, value in headers.items():<tab><tab>if isinstance(value, (int, float)):<tab><tab><tab>value = str(value)<tab><tab><IF-STMT><tab><tab><tab>raise ScriptError(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""message"": ""headers must be a table""<tab><tab><tab><tab><tab>"" with strings as keys and values.""<tab><tab><tab><tab><tab>""Header: `{!r}:{!r}` is not valid"".format(key, value)<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab>res[key] = value<tab>return res","if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) :",181
982,"def _get_literal_value(self, pyval):<tab>if pyval == self.vm.lookup_builtin(""builtins.True""):<tab><tab>return True<tab>elif pyval == self.vm.lookup_builtin(""builtins.False""):<tab><tab>return False<tab>elif isinstance(pyval, str):<tab><tab>prefix, value = parser_constants.STRING_RE.match(pyval).groups()[:2]<tab><tab>value = value[1:-1]  # remove quotation marks<tab><tab><IF-STMT><tab><tab><tab>value = compat.bytestring(value)<tab><tab>elif ""u"" in prefix and self.vm.PY2:<tab><tab><tab>value = compat.UnicodeType(value)<tab><tab>return value<tab>else:<tab><tab>return pyval","if ""b"" in prefix and not self . vm . PY2 :",183
983,"def decode_query_ids(self, trans, conditional):<tab>if conditional.operator == ""and"":<tab><tab>self.decode_query_ids(trans, conditional.left)<tab><tab>self.decode_query_ids(trans, conditional.right)<tab>else:<tab><tab>left_base = conditional.left.split(""."")[0]<tab><tab><IF-STMT><tab><tab><tab>field = self.FIELDS[left_base]<tab><tab><tab>if field.id_decode:<tab><tab><tab><tab>conditional.right = trans.security.decode_id(conditional.right)",if left_base in self . FIELDS :,135
984,"def testLastPhrases(self):<tab>for day in (11, 12, 13, 14, 15, 16, 17):<tab><tab>start = datetime.datetime(2012, 11, day, 9, 0, 0)<tab><tab>(yr, mth, dy, _, _, _, wd, yd, isdst) = start.timetuple()<tab><tab>n = 4 - wd<tab><tab><IF-STMT><tab><tab><tab>n -= 7<tab><tab>target = start + datetime.timedelta(days=n)<tab><tab>self.assertExpectedResult(<tab><tab><tab>self.cal.parse(""last friday"", start.timetuple()),<tab><tab><tab>(target.timetuple(), 1),<tab><tab><tab>dateOnly=True,<tab><tab>)",if n >= 0 :,168
985,"def _convertNbCharsInNbBits(self, nbChars):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbChars is not None:<tab><tab>if isinstance(nbChars, int):<tab><tab><tab>nbMinBit = nbChars * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nbMinBit = nbChars[0] * 8<tab><tab><tab>if nbChars[1] is not None:<tab><tab><tab><tab>nbMaxBit = nbChars[1] * 8<tab>return (nbMinBit, nbMaxBit)",if nbChars [ 0 ] is not None :,158
986,"def getpystone():<tab># Start calculation<tab>maxpystone = 0<tab># Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second<tab>for pyseed in [1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000]:<tab><tab>duration, pystonefloat = pystones(pyseed)<tab><tab>maxpystone = max(maxpystone, int(pystonefloat))<tab><tab># Stop when pystone() has been running for at least 0.1 second<tab><tab><IF-STMT><tab><tab><tab>break<tab>return maxpystone",if duration > 0.1 :,144
987,"def _append_to_io_queue(self, data, stream_name):<tab># Make sure ANSI CSI codes and object links are stored as separate events<tab># TODO: try to complete previously submitted incomplete code<tab>parts = re.split(OUTPUT_SPLIT_REGEX, data)<tab>for part in parts:<tab><tab><IF-STMT>  # split may produce empty string in the beginning or start<tab><tab><tab># split the data so that very long lines separated<tab><tab><tab>for block in re.split(<tab><tab><tab><tab>""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part<tab><tab><tab>):<tab><tab><tab><tab>if block:<tab><tab><tab><tab><tab>self._queued_io_events.append((block, stream_name))",if part :,174
988,"def qtTypeIdent(conn, *args):<tab># We're not using the conn object at the moment, but - we will<tab># modify the<tab># logic to use the server version specific keywords later.<tab>res = None<tab>value = None<tab>for val in args:<tab><tab># DataType doesn't have len function then convert it to string<tab><tab><IF-STMT><tab><tab><tab>val = str(val)<tab><tab>if len(val) == 0:<tab><tab><tab>continue<tab><tab>value = val<tab><tab>if Driver.needsQuoting(val, True):<tab><tab><tab>value = value.replace('""', '""""')<tab><tab><tab>value = '""' + value + '""'<tab><tab>res = ((res and res + ""."") or """") + value<tab>return res","if not hasattr ( val , ""__len__"" ) :",181
989,"def SetVerbose(self, level):<tab>""""""Sets the verbose level.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>level = int(level)<tab><tab>if (level >= 0) and (level <= 3):<tab><tab><tab>self._verbose = level<tab><tab><tab>return<tab>except ValueError:<tab><tab>pass<tab>self.Error(""Verbose level (%s) must be between 0 and 3 inclusive."" % level)",if type ( level ) != types . IntType :,105
990,"def step(self) -> None:<tab>""""""Performs a single optimization step.""""""<tab>for group in self.param_groups:<tab><tab>for p in group[""params""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>p.add_(p.grad, alpha=(-group[""lr""] * self.num_data))<tab>return None",if p . grad is None :,85
991,"def fill(self, values):<tab>if lupa.lua_type(values) != ""table"":<tab><tab>raise ScriptError(<tab><tab><tab>{<tab><tab><tab><tab>""argument"": ""values"",<tab><tab><tab><tab>""message"": ""element:fill values is not a table"",<tab><tab><tab><tab>""splash_method"": ""fill"",<tab><tab><tab>}<tab><tab>)<tab># marking all tables as arrays by default<tab>for key, value in values.items():<tab><tab><IF-STMT><tab><tab><tab>_mark_table_as_array(self.lua, value)<tab>values = self.lua.lua2python(values)<tab>return self.element.fill(values)","if lupa . lua_type ( value ) == ""table"" :",177
992,"def _gen_repr(self, buf):<tab>print >> buf, ""<tab>def __repr__(self):""<tab>if self.argnames:<tab><tab>fmt = COMMA.join([""%s""] * self.nargs)<tab><tab><IF-STMT><tab><tab><tab>fmt = ""(%s)"" % fmt<tab><tab>vals = [""repr(self.%s)"" % name for name in self.argnames]<tab><tab>vals = COMMA.join(vals)<tab><tab>if self.nargs == 1:<tab><tab><tab>vals = vals + "",""<tab><tab>print >> buf, '<tab><tab>return ""%s(%s)"" %% (%s)' % (self.name, fmt, vals)<tab>else:<tab><tab>print >> buf, '<tab><tab>return ""%s()""' % self.name","if ""("" in self . args :",189
993,"def render_observation(self):<tab>x = self.read_head_position<tab>label = ""Observation Grid<tab>: ""<tab>x_str = """"<tab>for j in range(-1, self.rows + 1):<tab><tab><IF-STMT><tab><tab><tab>x_str += "" "" * len(label)<tab><tab>for i in range(-2, self.input_width + 2):<tab><tab><tab>if i == x[0] and j == x[1]:<tab><tab><tab><tab>x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True)<tab><tab><tab>else:<tab><tab><tab><tab>x_str += self._get_str_obs((i, j))<tab><tab>x_str += ""\n""<tab>x_str = label + x_str<tab>return x_str",if j != - 1 :,200
994,"def get_module_comment(self, attrname: str) -> Optional[List[str]]:<tab>try:<tab><tab>analyzer = ModuleAnalyzer.for_module(self.modname)<tab><tab>analyzer.analyze()<tab><tab>key = ("""", attrname)<tab><tab><IF-STMT><tab><tab><tab>return list(analyzer.attr_docs[key])<tab>except PycodeError:<tab><tab>pass<tab>return None",if key in analyzer . attr_docs :,99
995,"def tms_to_quadkey(self, tms, google=False):<tab>quadKey = """"<tab>x, y, z = tms<tab># this algorithm works with google tiles, rather than tms, so convert<tab># to those first.<tab>if not google:<tab><tab>y = (2 ** z - 1) - y<tab>for i in range(z, 0, -1):<tab><tab>digit = 0<tab><tab>mask = 1 << (i - 1)<tab><tab><IF-STMT><tab><tab><tab>digit += 1<tab><tab>if (y & mask) != 0:<tab><tab><tab>digit += 2<tab><tab>quadKey += str(digit)<tab>return quadKey",if ( x & mask ) != 0 :,164
996,"def test_enumerate(app):<tab>async with new_stream(app) as stream:<tab><tab>for i in range(100):<tab><tab><tab>await stream.channel.deliver(message(key=i, value=i * 4))<tab><tab>async for i, value in stream.enumerate():<tab><tab><tab>current_event = stream.current_event<tab><tab><tab>assert i == current_event.key<tab><tab><tab>assert value == i * 4<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>assert await channel_empty(stream.channel)",if i >= 99 :,131
997,"def print_messages(self):<tab>output_reports = self.config.get_output_report()<tab>for report in output_reports:<tab><tab>output_format, output_files = report<tab><tab>self.summary[""formatter""] = output_format<tab><tab>formatter = FORMATTERS[output_format](<tab><tab><tab>self.summary, self.messages, self.config.profile<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.write_to(formatter, sys.stdout)<tab><tab>for output_file in output_files:<tab><tab><tab>with open(output_file, ""w+"") as target:<tab><tab><tab><tab>self.write_to(formatter, target)",if not output_files :,160
998,"def eval_metrics(self):<tab>for task in self.task_list:<tab><tab><IF-STMT><tab><tab><tab>return [<tab><tab><tab><tab>metrics.Metrics.ACC,<tab><tab><tab><tab>metrics.Metrics.NEG_LOG_PERPLEXITY,<tab><tab><tab><tab>metrics.Metrics.ROUGE_2_F,<tab><tab><tab><tab>metrics.Metrics.ROUGE_L_F,<tab><tab><tab>]<tab>return [<tab><tab>metrics.Metrics.ACC,<tab><tab>metrics.Metrics.NEG_LOG_PERPLEXITY,<tab>]","if ""summarize"" in task . name :",137
999,"def _getBuildRequestForBrdict(self, brdict):<tab># Turn a brdict into a BuildRequest into a brdict. This is useful<tab># for API like 'nextBuild', which operate on BuildRequest objects.<tab>breq = self.breqCache.get(brdict[""buildrequestid""])<tab>if not breq:<tab><tab>breq = yield BuildRequest.fromBrdict(self.master, brdict)<tab><tab><IF-STMT><tab><tab><tab>self.breqCache[brdict[""buildrequestid""]] = breq<tab>defer.returnValue(breq)",if breq :,136
1000,"def _stash_splitter(states):<tab>keep, split = [], []<tab>if state_func is not None:<tab><tab>for s in states:<tab><tab><tab>ns = state_func(s)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>split.append(ns)<tab><tab><tab>elif isinstance(ns, (list, tuple, set)):<tab><tab><tab><tab>split.extend(ns)<tab><tab><tab>else:<tab><tab><tab><tab>split.append(s)<tab>if stash_func is not None:<tab><tab>split = stash_func(states)<tab>if to_stash is not stash:<tab><tab>keep = states<tab>return keep, split","if isinstance ( ns , SimState ) :",163
1001,"def sequence_to_text(sequence):<tab>""""""Converts a sequence of IDs back to a string""""""<tab>result = """"<tab>for symbol_id in sequence:<tab><tab><IF-STMT><tab><tab><tab>s = _id_to_symbol[symbol_id]<tab><tab><tab># Enclose ARPAbet back in curly braces:<tab><tab><tab>if len(s) > 1 and s[0] == ""@"":<tab><tab><tab><tab>s = ""{%s}"" % s[1:]<tab><tab><tab>result += s<tab>return result.replace(""}{"", "" "")",if symbol_id in _id_to_symbol :,137
1002,"def get_code(self, fullname=None):<tab>fullname = self._fix_name(fullname)<tab>if self.code is None:<tab><tab>mod_type = self.etc[2]<tab><tab><IF-STMT><tab><tab><tab>source = self.get_source(fullname)<tab><tab><tab>self.code = compile(source, self.filename, ""exec"")<tab><tab>elif mod_type == imp.PY_COMPILED:<tab><tab><tab>self._reopen()<tab><tab><tab>try:<tab><tab><tab><tab>self.code = read_code(self.file)<tab><tab><tab>finally:<tab><tab><tab><tab>self.file.close()<tab><tab>elif mod_type == imp.PKG_DIRECTORY:<tab><tab><tab>self.code = self._get_delegate().get_code()<tab>return self.code",if mod_type == imp . PY_SOURCE :,196
1003,"def identwaf(self, findall=False):<tab>detected = list()<tab>try:<tab><tab>self.attackres = self.performCheck(self.centralAttack)<tab>except RequestBlocked:<tab><tab>return detected<tab>for wafvendor in self.checklist:<tab><tab>self.log.info(""Checking for %s"" % wafvendor)<tab><tab>if self.wafdetections[wafvendor](self):<tab><tab><tab>detected.append(wafvendor)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>self.knowledge[""wafname""] = detected<tab>return detected",if not findall :,143
1004,"def SessionId(self):<tab>""""""Returns the Session ID of the process""""""<tab>if self.Session.is_valid():<tab><tab>process_space = self.get_process_address_space()<tab><tab><IF-STMT><tab><tab><tab>return obj.Object(<tab><tab><tab><tab>""_MM_SESSION_SPACE"", offset=self.Session, vm=process_space<tab><tab><tab>).SessionId<tab>return obj.NoneObject(""Cannot find process session"")",if process_space :,105
1005,"def _convert_java_pattern_to_python(pattern):<tab>""""""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`.""""""<tab>s = list(pattern)<tab>i = 0<tab>while i < len(s) - 1:<tab><tab>c = s[i]<tab><tab>if c == ""$"" and s[i + 1] in ""0123456789"":<tab><tab><tab>s[i] = ""\\""<tab><tab><IF-STMT><tab><tab><tab>s[i] = """"<tab><tab><tab>i += 1<tab><tab>i += 1<tab>return pattern[:0].join(s)","elif c == ""\\"" and s [ i + 1 ] == ""$"" :",152
1006,"def __init__(self, coverage):<tab>self.coverage = coverage<tab>self.config = self.coverage.config<tab>self.source_paths = set()<tab>if self.config.source:<tab><tab>for src in self.config.source:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not self.config.relative_files:<tab><tab><tab><tab><tab>src = files.canonical_filename(src)<tab><tab><tab><tab>self.source_paths.add(src)<tab>self.packages = {}<tab>self.xml_out = None",if os . path . exists ( src ) :,133
1007,"def populate_vol_format(self):<tab>rhel6_file_whitelist = [""raw"", ""qcow2"", ""qed""]<tab>model = self.widget(""vol-format"").get_model()<tab>model.clear()<tab>formats = self.vol_class.formats<tab>if hasattr(self.vol_class, ""create_formats""):<tab><tab>formats = getattr(self.vol_class, ""create_formats"")<tab>if self.vol_class == Storage.FileVolume and not self.conn.rhel6_defaults_caps():<tab><tab>newfmts = []<tab><tab>for f in rhel6_file_whitelist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>newfmts.append(f)<tab><tab>formats = newfmts<tab>for f in formats:<tab><tab>model.append([f, f])",if f in formats :,196
1008,"def get_file_sources():<tab>global _file_sources<tab>if _file_sources is None:<tab><tab>from galaxy.files import ConfiguredFileSources<tab><tab>file_sources = None<tab><tab><IF-STMT><tab><tab><tab>file_sources_as_dict = None<tab><tab><tab>with open(""file_sources.json"", ""r"") as f:<tab><tab><tab><tab>file_sources_as_dict = json.load(f)<tab><tab><tab>if file_sources_as_dict is not None:<tab><tab><tab><tab>file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict)<tab><tab>if file_sources is None:<tab><tab><tab>ConfiguredFileSources.from_dict([])<tab><tab>_file_sources = file_sources<tab>return _file_sources","if os . path . exists ( ""file_sources.json"" ) :",196
1009,"def _blend(x, y):  # pylint: disable=invalid-name<tab>""""""Implements the ""blend"" strategy for `deep_merge`.""""""<tab>if isinstance(x, (dict, OrderedDict)):<tab><tab>if not isinstance(y, (dict, OrderedDict)):<tab><tab><tab>return y<tab><tab>return _merge(x, y, recursion_func=_blend)<tab>if isinstance(x, (list, tuple)):<tab><tab>if not isinstance(y, (list, tuple)):<tab><tab><tab>return y<tab><tab>result = [_blend(*i) for i in zip(x, y)]<tab><tab><IF-STMT><tab><tab><tab>result += x[len(y) :]<tab><tab>elif len(x) < len(y):<tab><tab><tab>result += y[len(x) :]<tab><tab>return result<tab>return y",if len ( x ) > len ( y ) :,194
1010,"def copy_dicts(dct):<tab>if ""_remote_data"" in dct:<tab><tab>dsindex = dct[""_remote_data""][""_content""].dsindex<tab><tab>newdct = dct.copy()<tab><tab>newdct[""_remote_data""] = {""_content"": dsindex}<tab><tab>return list(newdct.items())<tab>elif ""_data"" in dct:<tab><tab>newdct = dct.copy()<tab><tab>newdata = copy_dicts(dct[""_data""])<tab><tab><IF-STMT><tab><tab><tab>newdct[""_data""] = newdata<tab><tab>return list(newdct.items())<tab>return None",if newdata :,139
1011,"def _import_epic_activity(self, project_data, taiga_epic, epic, options):<tab>offset = 0<tab>while True:<tab><tab>activities = self._client.get(<tab><tab><tab>""/projects/{}/epics/{}/activity"".format(<tab><tab><tab><tab>project_data[""id""],<tab><tab><tab><tab>epic[""id""],<tab><tab><tab>),<tab><tab><tab>{""envelope"": ""true"", ""limit"": 300, ""offset"": offset},<tab><tab>)<tab><tab>offset += 300<tab><tab>for activity in activities[""data""]:<tab><tab><tab>self._import_activity(taiga_epic, activity, options)<tab><tab><IF-STMT><tab><tab><tab>break","if len ( activities [ ""data"" ] ) < 300 :",173
1012,"def __get__(self, instance, instance_type=None):<tab>if instance:<tab><tab><IF-STMT><tab><tab><tab>rel_obj = self.get_obj(instance)<tab><tab><tab>if rel_obj:<tab><tab><tab><tab>instance._obj_cache[self.att_name] = rel_obj<tab><tab>return instance._obj_cache.get(self.att_name)<tab>return self",if self . att_name not in instance . _obj_cache :,105
1013,"def download_main(<tab>download, download_playlist, urls, playlist, output_dir, merge, info_only):<tab>for url in urls:<tab><tab>if url.startswith(""https://""):<tab><tab><tab>url = url[8:]<tab><tab>if not url.startswith(""http://""):<tab><tab><tab>url = ""http://"" + url<tab><tab><IF-STMT><tab><tab><tab>download_playlist(<tab><tab><tab><tab>url, output_dir=output_dir, merge=merge, info_only=info_only<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>download(url, output_dir=output_dir, merge=merge, info_only=info_only)",if playlist :,155
1014,"def _mksubs(self):<tab>self._subs = {}<tab>commit_dir = CommitDir(self, "".commit"")<tab>self._subs["".commit""] = commit_dir<tab>tag_dir = TagDir(self, "".tag"")<tab>self._subs["".tag""] = tag_dir<tab>for (name, sha) in git.list_refs():<tab><tab><IF-STMT><tab><tab><tab>name = name[11:]<tab><tab><tab>date = git.rev_get_date(sha.encode(""hex""))<tab><tab><tab>n1 = BranchList(self, name, sha)<tab><tab><tab>n1.ctime = n1.mtime = date<tab><tab><tab>self._subs[name] = n1","if name . startswith ( ""refs/heads/"" ) :",168
1015,"def readAtOffset(self, offset, size, shortok=False):<tab>ret = b""""<tab>self.fd.seek(offset)<tab>while len(ret) != size:<tab><tab>rlen = size - len(ret)<tab><tab>x = self.fd.read(rlen)<tab><tab><IF-STMT><tab><tab><tab>if not shortok:<tab><tab><tab><tab>return None<tab><tab><tab>return ret<tab><tab>ret += x<tab>return ret","if x == b"""" :",111
1016,"def remove_indent(self):<tab>""""""Remove one tab-width of blanks from the previous token.""""""<tab>w = abs(self.tab_width)<tab>if self.result:<tab><tab>s = self.result[-1]<tab><tab><IF-STMT><tab><tab><tab>self.result.pop()<tab><tab><tab>s = s.replace(""\t"", "" "" * w)<tab><tab><tab>if s.startswith(""\n""):<tab><tab><tab><tab>s2 = s[1:]<tab><tab><tab><tab>self.result.append(""\n"" + s2[:-w])<tab><tab><tab>else:<tab><tab><tab><tab>self.result.append(s[:-w])",if s . isspace ( ) :,151
1017,"def flush(self, *args, **kwargs):<tab>with self._lock:<tab><tab>self._last_updated = time.time()<tab><tab>try:<tab><tab><tab>if kwargs.get(""in_place"", False):<tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>mailbox.mbox.flush(self, *args, **kwargs)<tab><tab>except OSError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab><tab>self._last_updated = time.time()","if ""_create_temporary"" in traceback . format_exc ( ) :",157
1018,"def _collect_manual_intervention_nodes(pipeline_tree):<tab>for act in pipeline_tree[""activities""].values():<tab><tab><IF-STMT><tab><tab><tab>_collect_manual_intervention_nodes(act[""pipeline""])<tab><tab>elif act[""component""][""code""] in MANUAL_INTERVENTION_COMP_CODES:<tab><tab><tab>manual_intervention_nodes.add(act[""id""])","if act [ ""type"" ] == ""SubProcess"" :",105
1019,"def banned():<tab>if request.endpoint == ""views.themes"":<tab><tab>return<tab>if authed():<tab><tab>user = get_current_user_attrs()<tab><tab>team = get_current_team_attrs()<tab><tab><IF-STMT><tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"", error=""You have been banned from this CTF""<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)<tab><tab>if team and team.banned:<tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"",<tab><tab><tab><tab><tab>error=""Your team has been banned from this CTF"",<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)",if user and user . banned :,193
1020,"def remove(self, values):<tab>if not isinstance(values, (list, tuple, set)):<tab><tab>values = [values]<tab>for v in values:<tab><tab>v = str(v)<tab><tab>if isinstance(self._definition, dict):<tab><tab><tab>self._definition.pop(v, None)<tab><tab>elif self._definition == ""ANY"":<tab><tab><tab>if v == ""ANY"":<tab><tab><tab><tab>self._definition = []<tab><tab><IF-STMT><tab><tab><tab>self._definition.remove(v)<tab>if (<tab><tab>self._value is not None<tab><tab>and self._value not in self._definition<tab><tab>and self._not_any()<tab>):<tab><tab>raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",elif v in self . _definition :,192
1021,"def save(self, learner, file_name):<tab>""""""Save the model to location specified in file_name.""""""<tab>with open(file_name, ""wb"") as f:<tab><tab><IF-STMT><tab><tab><tab># don't store the large inference cache!<tab><tab><tab>learner.inference_cache_, tmp = (None, learner.inference_cache_)<tab><tab><tab>pickle.dump(learner, f, -1)<tab><tab><tab>learner.inference_cache_ = tmp<tab><tab>else:<tab><tab><tab>pickle.dump(learner, f, -1)","if hasattr ( learner , ""inference_cache_"" ) :",137
1022,"def __init__(self, exprs, savelist=False):<tab>super(ParseExpression, self).__init__(savelist)<tab>if isinstance(exprs, _generatorType):<tab><tab>exprs = list(exprs)<tab>if isinstance(exprs, basestring):<tab><tab>self.exprs = [ParserElement._literalStringClass(exprs)]<tab>elif isinstance(exprs, collections.Iterable):<tab><tab>exprs = list(exprs)<tab><tab># if sequence of strings provided, wrap with Literal<tab><tab><IF-STMT><tab><tab><tab>exprs = map(ParserElement._literalStringClass, exprs)<tab><tab>self.exprs = list(exprs)<tab>else:<tab><tab>try:<tab><tab><tab>self.exprs = list(exprs)<tab><tab>except TypeError:<tab><tab><tab>self.exprs = [exprs]<tab>self.callPreparse = False","if all ( isinstance ( expr , basestring ) for expr in exprs ) :",199
1023,"def find(self, back=False):<tab>flags = 0<tab><IF-STMT><tab><tab>flags = QTextDocument.FindBackward<tab>if self.csBox.isChecked():<tab><tab>flags = flags | QTextDocument.FindCaseSensitively<tab>text = self.searchEdit.text()<tab>if not self.findMain(text, flags):<tab><tab>if text in self.editBoxes[self.ind].toPlainText():<tab><tab><tab>cursor = self.editBoxes[self.ind].textCursor()<tab><tab><tab>if back:<tab><tab><tab><tab>cursor.movePosition(QTextCursor.End)<tab><tab><tab>else:<tab><tab><tab><tab>cursor.movePosition(QTextCursor.Start)<tab><tab><tab>self.editBoxes[self.ind].setTextCursor(cursor)<tab><tab><tab>self.findMain(text, flags)",if back :,195
1024,"def _load_storage(self):<tab>self._storage = {}<tab>for row in self(""SELECT object, resource, amount FROM storage""):<tab><tab>ownerid = int(row[0])<tab><tab><IF-STMT><tab><tab><tab>self._storage[ownerid].append(row[1:])<tab><tab>else:<tab><tab><tab>self._storage[ownerid] = [row[1:]]",if ownerid in self . _storage :,94
1025,"def parse_chunked(self, unreader):<tab>(size, rest) = self.parse_chunk_size(unreader)<tab>while size > 0:<tab><tab>while size > len(rest):<tab><tab><tab>size -= len(rest)<tab><tab><tab>yield rest<tab><tab><tab>rest = unreader.read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise NoMoreData()<tab><tab>yield rest[:size]<tab><tab># Remove \r\n after chunk<tab><tab>rest = rest[size:]<tab><tab>while len(rest) < 2:<tab><tab><tab>rest += unreader.read()<tab><tab>if rest[:2] != b""\r\n"":<tab><tab><tab>raise ChunkMissingTerminator(rest[:2])<tab><tab>(size, rest) = self.parse_chunk_size(unreader, data=rest[2:])",if not rest :,197
1026,"def _augment_batch_(self, batch, random_state, parents, hooks):<tab>for column in batch.columns:<tab><tab><IF-STMT><tab><tab><tab>for i, cbaoi in enumerate(column.value):<tab><tab><tab><tab>column.value[i] = cbaoi.clip_out_of_image_()<tab>return batch","if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :",93
1027,"def to_nim(self):<tab>if self.is_pointer == 2:<tab><tab>s = ""cstringArray"" if self.type == ""GLchar"" else ""ptr pointer""<tab>else:<tab><tab>s = self.type<tab><tab><IF-STMT><tab><tab><tab>default = ""ptr "" + s<tab><tab><tab>s = self.NIM_POINTER_MAP.get(s, default)<tab>return s",if self . is_pointer == 1 :,105
1028,"def find(self, path):<tab>if os.path.isfile(path) or os.path.islink(path):<tab><tab>self.num_files = self.num_files + 1<tab><tab>if self.match_function(path):<tab><tab><tab>self.files.append(path)<tab>elif os.path.isdir(path):<tab><tab>for content in os.listdir(path):<tab><tab><tab>file = os.path.join(path, content)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.num_files = self.num_files + 1<tab><tab><tab><tab>if self.match_function(file):<tab><tab><tab><tab><tab>self.files.append(file)<tab><tab><tab>else:<tab><tab><tab><tab>self.find(file)",if os . path . isfile ( file ) or os . path . islink ( file ) :,192
1029,"def remove(self, event):<tab>try:<tab><tab>self._events_current_sweep.remove(event)<tab><tab><IF-STMT><tab><tab><tab>assert event.in_sweep == True<tab><tab><tab>assert event.other.in_sweep == True<tab><tab><tab>event.in_sweep = False<tab><tab><tab>event.other.in_sweep = False<tab><tab>return True<tab>except KeyError:<tab><tab>if USE_DEBUG:<tab><tab><tab>assert event.in_sweep == False<tab><tab><tab>assert event.other.in_sweep == False<tab><tab>return False",if USE_DEBUG :,134
1030,"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab>if attrname.startswith(""__""):<tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab>if attrvalue == 0:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab>elif hasattr(self.metadata, attrname):<tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass","if attrname == ""salt_version"" :",173
1031,"def _init_auxiliary_head(self, auxiliary_head):<tab>""""""Initialize ``auxiliary_head``""""""<tab>if auxiliary_head is not None:<tab><tab><IF-STMT><tab><tab><tab>self.auxiliary_head = nn.ModuleList()<tab><tab><tab>for head_cfg in auxiliary_head:<tab><tab><tab><tab>self.auxiliary_head.append(builder.build_head(head_cfg))<tab><tab>else:<tab><tab><tab>self.auxiliary_head = builder.build_head(auxiliary_head)","if isinstance ( auxiliary_head , list ) :",121
1032,"def _str_param_list(self, name):<tab>out = []<tab>if self[name]:<tab><tab>out += self._str_header(name)<tab><tab>for param in self[name]:<tab><tab><tab>parts = []<tab><tab><tab>if param.name:<tab><tab><tab><tab>parts.append(param.name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts.append(param.type)<tab><tab><tab>out += ["" : "".join(parts)]<tab><tab><tab>if param.desc and """".join(param.desc).strip():<tab><tab><tab><tab>out += self._str_indent(param.desc)<tab><tab>out += [""""]<tab>return out",if param . type :,157
1033,"def _set_handler(<tab>self, name, handle=None, obj=None, constructor_args=(), constructor_kwds={}):<tab>if handle is None:<tab><tab>handle = obj is not None<tab>if handle:<tab><tab>handler_class = self.handler_classes[name]<tab><tab><IF-STMT><tab><tab><tab>newhandler = handler_class(obj)<tab><tab>else:<tab><tab><tab>newhandler = handler_class(*constructor_args, **constructor_kwds)<tab>else:<tab><tab>newhandler = None<tab>self._replace_handler(name, newhandler)",if obj is not None :,137
1034,"def _extract_subtitles(src):<tab>subtitles = {}<tab>for caption in try_get(src, lambda x: x[""captions""], list) or []:<tab><tab>subtitle_url = url_or_none(caption.get(""uri""))<tab><tab><IF-STMT><tab><tab><tab>lang = caption.get(""language"", ""deu"")<tab><tab><tab>subtitles.setdefault(lang, []).append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""url"": subtitle_url,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>return subtitles",if subtitle_url :,131
1035,"def get_keys(struct, ignore_first_level=False):<tab>res = []<tab>if isinstance(struct, dict):<tab><tab><IF-STMT><tab><tab><tab>keys = [x.split(""("")[0] for x in struct.keys()]<tab><tab><tab>res.extend(keys)<tab><tab>for key in struct:<tab><tab><tab>if key in IGNORED_KEYS:<tab><tab><tab><tab>logging.debug(""Ignored: %s: %s"", key, struct[key])<tab><tab><tab><tab>continue<tab><tab><tab>res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL))<tab>elif isinstance(struct, list):<tab><tab>for item in struct:<tab><tab><tab>res.extend(get_keys(item))<tab>return res",if not ignore_first_level :,178
1036,"def create_dir(path):<tab>curr_path = None<tab>for p in path:<tab><tab>if curr_path is None:<tab><tab><tab>curr_path = os.path.abspath(p)<tab><tab>else:<tab><tab><tab>curr_path = os.path.join(curr_path, p)<tab><tab><IF-STMT><tab><tab><tab>os.mkdir(curr_path)",if not os . path . exists ( curr_path ) :,100
1037,"def dataToDumpFile(dumpFile, data):<tab>try:<tab><tab>dumpFile.write(data)<tab><tab>dumpFile.flush()<tab>except IOError as ex:<tab><tab>if ""No space left"" in getUnicode(ex):<tab><tab><tab>errMsg = ""no space left on output device""<tab><tab><tab>logger.error(errMsg)<tab><tab><IF-STMT><tab><tab><tab>errMsg = ""permission denied when flushing dump data""<tab><tab><tab>logger.error(errMsg)<tab><tab>else:<tab><tab><tab>errMsg = (<tab><tab><tab><tab>""error occurred when writing dump data to file ('%s')"" % getUnicode(ex)<tab><tab><tab>)<tab><tab><tab>logger.error(errMsg)","elif ""Permission denied"" in getUnicode ( ex ) :",176
1038,"def elements(self, top):<tab>res = []<tab># try:<tab>#<tab> string = ""== %s (%s)"" % (self.name,self.__class__)<tab># except AttributeError:<tab>#<tab> string = ""== (%s)"" % (self.__class__,)<tab># print(string)<tab>for part in self.parts:<tab><tab><IF-STMT><tab><tab><tab>res.append(name_or_ref(part, top))<tab><tab>else:<tab><tab><tab>if isinstance(part, Extension):<tab><tab><tab><tab>res.append(part.base)<tab><tab><tab>res.extend(part.elements(top))<tab>return res","if isinstance ( part , Element ) :",159
1039,"def _parse_param_value(name, datatype, default):<tab>if datatype == ""bool"":<tab><tab>if default.lower() == ""true"":<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>_s = ""{}: Invalid default value '{}' for bool parameter {}""<tab><tab><tab>raise SyntaxError(_s.format(self.name, default, p))<tab>elif datatype == ""int"":<tab><tab>if type(default) == int:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return int(default, 0)<tab>elif datatype == ""real"":<tab><tab>if type(default) == float:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return float(default)<tab>else:<tab><tab>return str(default)","elif default . lower ( ) == ""false"" :",191
1040,"def dvmethod(c, dx, doAST=False):<tab>for m in c.get_methods():<tab><tab>mx = dx.get_method(m)<tab><tab>ms = DvMethod(mx)<tab><tab>ms.process(doAST=doAST)<tab><tab><IF-STMT><tab><tab><tab>assert ms.get_ast() is not None<tab><tab><tab>assert isinstance(ms.get_ast(), dict)<tab><tab><tab>assert ""body"" in ms.get_ast()<tab><tab>else:<tab><tab><tab>assert ms.get_source() is not None",if doAST :,132
1041,"def _repr_pretty_(self, p, cycle):<tab>if cycle:<tab><tab>return ""{{...}""<tab>with p.group(2, ""{"", ""}""):<tab><tab>p.breakable("""")<tab><tab>for idx, key in enumerate(self._items):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p.text("","")<tab><tab><tab><tab>p.breakable()<tab><tab><tab>value = self._items[key]<tab><tab><tab>p.pretty(key)<tab><tab><tab>p.text("": "")<tab><tab><tab>if isinstance(value, bytes):<tab><tab><tab><tab>value = trimmed_repr(value)<tab><tab><tab>p.pretty(value)<tab><tab>p.breakable("""")",if idx :,159
1042,"def remove_rating(self, songs, librarian):<tab>count = len(songs)<tab>if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""):<tab><tab>parent = qltk.get_menu_item_top_parent(self)<tab><tab>dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None)<tab><tab><IF-STMT><tab><tab><tab>return<tab>reset = []<tab>for song in songs:<tab><tab>if ""~#rating"" in song:<tab><tab><tab>del song[""~#rating""]<tab><tab><tab>reset.append(song)<tab>librarian.changed(reset)",if dialog . run ( ) != Gtk . ResponseType . YES :,159
1043,"def get_or_create_place(self, place_name):<tab>""Return the requested place object tuple-packed with a new indicator.""<tab>LOG.debug(""get_or_create_place: looking for: %s"", place_name)<tab>for place_handle in self.db.iter_place_handles():<tab><tab>place = self.db.get_place_from_handle(place_handle)<tab><tab>place_title = place_displayer.display(self.db, place)<tab><tab><IF-STMT><tab><tab><tab>return (0, place)<tab>place = Place()<tab>place.set_title(place_name)<tab>place.name = PlaceName(value=place_name)<tab>self.db.add_place(place, self.trans)<tab>return (1, place)",if place_title == place_name :,193
1044,def _skip_trivial(constraint_data):<tab>if skip_trivial_constraints:<tab><tab><IF-STMT><tab><tab><tab>if constraint_data.variables is None:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>if constraint_data.body.polynomial_degree() == 0:<tab><tab><tab><tab>return True<tab>return False,"if isinstance ( constraint_data , LinearCanonicalRepn ) :",90
1045,"def get_other(self, data, items):<tab>is_tuple = False<tab>if type(data) == tuple:<tab><tab>data = list(data)<tab><tab>is_tuple = True<tab>if type(data) == list:<tab><tab>m_items = items.copy()<tab><tab>for idx, item in enumerate(items):<tab><tab><tab>if item < 0:<tab><tab><tab><tab>m_items[idx] = len(data) - abs(item)<tab><tab>for i in sorted(set(m_items), reverse=True):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del data[i]<tab><tab>if is_tuple:<tab><tab><tab>return tuple(data)<tab><tab>else:<tab><tab><tab>return data<tab>else:<tab><tab>return None",if i < len ( data ) and i > - 1 :,191
1046,"def test_case_insensitivity(self):<tab>with support.EnvironmentVarGuard() as env:<tab><tab>env.set(""PYTHONCASEOK"", ""1"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""os.environ changes not reflected in "" ""_os.environ"")<tab><tab>loader = self.find_module()<tab><tab>self.assertTrue(hasattr(loader, ""load_module""))","if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :",103
1047,def field_spec(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.field_spec_ is None:<tab><tab><tab><tab>self.field_spec_ = FieldSpec()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.field_spec_,if self . field_spec_ is None :,95
1048,"def reduce(self, f, init):<tab>for x in range(self._idx, rt.count(self._w_array)):<tab><tab><IF-STMT><tab><tab><tab>return rt.deref(init)<tab><tab>init = f.invoke([init, rt.nth(self._w_array, rt.wrap(x))])<tab>return init",if rt . reduced_QMARK_ ( init ) :,86
1049,"def _find(event: E) -> None:<tab># We first check values after the selected value, then all values.<tab>values = list(self.values)<tab>for value in values[self._selected_index + 1 :] + values:<tab><tab>text = fragment_list_to_text(to_formatted_text(value[1])).lower()<tab><tab><IF-STMT><tab><tab><tab>self._selected_index = self.values.index(value)<tab><tab><tab>return",if text . startswith ( event . data . lower ( ) ) :,118
1050,"def check_permissions():<tab>if platform_os() != ""Windows"":<tab><tab><IF-STMT><tab><tab><tab>print(localization.lang_check_permissions[""permissions_granted""])<tab><tab>else:<tab><tab><tab>print(localization.lang_check_permissions[""permissions_denied""])<tab><tab><tab>exit()<tab>else:<tab><tab>print(localization.lang_check_permissions[""windows_warning""])<tab><tab>exit()",if getuid ( ) == 0 :,101
1051,"def _ProcessName(self, name, dependencies):<tab>""""""Retrieve a module name from a node name.""""""<tab>module_name, dot, base_name = name.rpartition(""."")<tab>if dot:<tab><tab>if module_name:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dependencies[module_name].add(base_name)<tab><tab><tab>else:<tab><tab><tab><tab>dependencies[module_name] = {base_name}<tab><tab>else:<tab><tab><tab># If we have a relative import that did not get qualified (usually due<tab><tab><tab># to an empty package_name), don't insert module_name='' into the<tab><tab><tab># dependencies; we get a better error message if we filter it out here<tab><tab><tab># and fail later on.<tab><tab><tab>logging.warning(""Empty package name: %s"", name)",if module_name in dependencies :,196
1052,"def _load_db(self):<tab>try:<tab><tab>with open(self.db) as db:<tab><tab><tab>content = db.read(8)<tab><tab><tab>db.seek(0)<tab><tab><tab>if content == (""Salted__""):<tab><tab><tab><tab>data = StringIO()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.encryptor.decrypt(db, data)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise EncryptionError(<tab><tab><tab><tab><tab><tab>""Encrpyted credential storage: {}"".format(self.db)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>return json.loads(data.getvalue())<tab><tab><tab>else:<tab><tab><tab><tab>return json.load(db)<tab>except:<tab><tab>return {""creds"": []}",if self . encryptor :,187
1053,"def _parse(self, stream, context):<tab>obj = []<tab>try:<tab><tab>context_for_subcon = context<tab><tab>if self.subcon.conflags & self.FLAG_COPY_CONTEXT:<tab><tab><tab>context_for_subcon = context.__copy__()<tab><tab>while True:<tab><tab><tab>subobj = self.subcon._parse(stream, context_for_subcon)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>obj.append(subobj)<tab>except ConstructError as ex:<tab><tab>raise ArrayError(""missing terminator"", ex)<tab>return obj","if self . predicate ( subobj , context ) :",150
1054,"def is_active_for_user(self, user):<tab>is_active = super(AbstractUserFlag, self).is_active_for_user(user)<tab>if is_active:<tab><tab>return is_active<tab>user_ids = self._get_user_ids()<tab>if hasattr(user, ""pk"") and user.pk in user_ids:<tab><tab>return True<tab>if hasattr(user, ""groups""):<tab><tab>group_ids = self._get_group_ids()<tab><tab>if group_ids:<tab><tab><tab>user_groups = set(user.groups.all().values_list(""pk"", flat=True))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return None",if group_ids . intersection ( user_groups ) :,175
1055,"def lookup_member(self, member_name):<tab>document_choices = self.choices or []<tab>for document_choice in document_choices:<tab><tab>doc_and_subclasses = [document_choice] + document_choice.__subclasses__()<tab><tab>for doc_type in doc_and_subclasses:<tab><tab><tab>field = doc_type._fields.get(member_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return field",if field :,101
1056,"def apply(self, db, person):<tab>families = person.get_parent_family_handle_list()<tab>if families == []:<tab><tab>return True<tab>for family_handle in person.get_parent_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>father_handle = family.get_father_handle()<tab><tab><tab>mother_handle = family.get_mother_handle()<tab><tab><tab>if not father_handle:<tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if not mother_handle :,157
1057,"def init_weights(self):<tab>for m in self.modules():<tab><tab>if isinstance(m, nn.Linear):<tab><tab><tab>normal_init(m, std=0.01)<tab><tab>if isinstance(m, nn.Conv3d):<tab><tab><tab>xavier_init(m, distribution=""uniform"")<tab><tab><IF-STMT><tab><tab><tab>constant_init(m, 1)","if isinstance ( m , nn . BatchNorm3d ) :",99
1058,"def _update_learning_params(self):<tab>model = self.model<tab>hparams = self.hparams<tab>fd = self.runner.feed_dict<tab>step_num = self.step_num<tab>if hparams.model_type == ""resnet_tf"":<tab><tab><IF-STMT><tab><tab><tab>lrn_rate = hparams.mom_lrn<tab><tab>elif step_num < 30000:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 10<tab><tab>elif step_num < 35000:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 100<tab><tab>else:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 1000<tab><tab>fd[model.lrn_rate] = lrn_rate",if step_num < hparams . lrn_step :,190
1059,"def token_producer(source):<tab>token = source.read_uint8()<tab>while token is not None:<tab><tab>if is_push_data_token(token):<tab><tab><tab>yield DataToken(read_data(token, source))<tab><tab><IF-STMT><tab><tab><tab>yield SmallIntegerToken(read_small_integer(token))<tab><tab>else:<tab><tab><tab>yield Token(token)<tab><tab>token = source.read_uint8()",elif is_small_integer ( token ) :,113
1060,"def user_info(oicsrv, userdb, sub, client_id="""", user_info_claims=None):<tab>identity = userdb[sub]<tab>if user_info_claims:<tab><tab>result = {}<tab><tab>for key, restr in user_info_claims[""claims""].items():<tab><tab><tab>try:<tab><tab><tab><tab>result[key] = identity[key]<tab><tab><tab>except KeyError:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise Exception(""Missing property '%s'"" % key)<tab>else:<tab><tab>result = identity<tab>return OpenIDSchema(**result)","if restr == { ""essential"" : True } :",147
1061,"def _helpSlot(self, *args):<tab>help_text = ""Filters are applied to packets in both direction.\n\n""<tab>filter_nb = 0<tab>for filter in self._filters:<tab><tab>help_text += ""{}: {}"".format(filter[""name""], filter[""description""])<tab><tab>filter_nb += 1<tab><tab><IF-STMT><tab><tab><tab>help_text += ""\n\n""<tab>QtWidgets.QMessageBox.information(self, ""Help for filters"", help_text)",if len ( self . _filters ) != filter_nb :,124
1062,"def find_user_theme(self, name: str) -> Theme:<tab>""""""Find a theme named as *name* from latex_theme_path.""""""<tab>for theme_path in self.theme_paths:<tab><tab>config_path = path.join(theme_path, name, ""theme.conf"")<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return UserTheme(name, config_path)<tab><tab><tab>except ThemeError as exc:<tab><tab><tab><tab>logger.warning(exc)<tab>return None",if path . isfile ( config_path ) :,128
1063,"def decompress(self, value):<tab>if value:<tab><tab><IF-STMT><tab><tab><tab>if value.country_code and value.national_number:<tab><tab><tab><tab>return [<tab><tab><tab><tab><tab>""+%d"" % value.country_code,<tab><tab><tab><tab><tab>national_significant_number(value),<tab><tab><tab><tab>]<tab><tab>else:<tab><tab><tab>return value.split(""."")<tab>return [None, """"]",if type ( value ) == PhoneNumber :,111
1064,"def update_prevdoc_status(self, flag):<tab>for quotation in list(set([d.prevdoc_docname for d in self.get(""items"")])):<tab><tab><IF-STMT><tab><tab><tab>doc = frappe.get_doc(""Quotation"", quotation)<tab><tab><tab>if doc.docstatus == 2:<tab><tab><tab><tab>frappe.throw(_(""Quotation {0} is cancelled"").format(quotation))<tab><tab><tab>doc.set_status(update=True)<tab><tab><tab>doc.update_opportunity()",if quotation :,127
1065,"def map(item):<tab>if item.deleted:<tab><tab>return<tab>exploration = exp_fetchers.get_exploration_from_model(item)<tab>for state_name, state in exploration.states.items():<tab><tab>hints_length = len(state.interaction.hints)<tab><tab><IF-STMT><tab><tab><tab>exp_and_state_key = ""%s %s"" % (item.id, state_name.encode(""utf-8""))<tab><tab><tab>yield (python_utils.UNICODE(hints_length), exp_and_state_key)",if hints_length > 0 :,136
1066,"def _selected_machines(self, virtual_machines):<tab>selected_machines = []<tab>for machine in virtual_machines:<tab><tab>if self._args.host and self._args.host == machine.name:<tab><tab><tab>selected_machines.append(machine)<tab><tab><IF-STMT><tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.locations and machine.location in self.locations:<tab><tab><tab>selected_machines.append(machine)<tab>return selected_machines","if self . tags and self . _tags_match ( machine . tags , self . tags ) :",129
1067,"def _ripple_trim_compositors_move(self, delta):<tab>comp_ids = self.multi_data.moved_compositors_destroy_ids<tab>tracks_compositors = _get_tracks_compositors_list()<tab>track_moved = self.multi_data.track_affected<tab>for i in range(1, len(current_sequence().tracks) - 1):<tab><tab>if not track_moved[i - 1]:<tab><tab><tab>continue<tab><tab>track_comps = tracks_compositors[i - 1]<tab><tab>for comp in track_comps:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>comp.move(delta)",if comp . destroy_id in comp_ids :,158
1068,"def stream_docker_log(log_stream):<tab>async for line in log_stream:<tab><tab>if ""stream"" in line and line[""stream""].strip():<tab><tab><tab>logger.debug(line[""stream""].strip())<tab><tab><IF-STMT><tab><tab><tab>logger.debug(line[""status""].strip())<tab><tab>elif ""error"" in line:<tab><tab><tab>logger.error(line[""error""].strip())<tab><tab><tab>raise DockerBuildError","elif ""status"" in line :",108
1069,"def create_keyfile(self, keyfile, size=64, force=False):<tab>if force or not os.path.exists(keyfile):<tab><tab>keypath = os.path.dirname(keyfile)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(keypath)<tab><tab>subprocess.run(<tab><tab><tab>[""dd"", ""if=/dev/random"", f""of={keyfile}"", f""bs={size}"", ""count=1""],<tab><tab><tab>check=True,<tab><tab><tab>stdout=subprocess.DEVNULL,<tab><tab><tab>stderr=subprocess.DEVNULL,<tab><tab>)",if not os . path . exists ( keypath ) :,138
1070,"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab>if self.op == ""+"":<tab><tab><tab>self.current += num<tab><tab>elif self.op == ""-"":<tab><tab><tab>self.current -= num<tab><tab><IF-STMT><tab><tab><tab>self.current *= num<tab><tab>elif self.op == ""/"":<tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res","elif self . op == ""*"" :",187
1071,"def chop(expr, delta=10.0 ** (-10.0)):<tab>if isinstance(expr, Real):<tab><tab>if -delta < expr.get_float_value() < delta:<tab><tab><tab>return Integer(0)<tab>elif isinstance(expr, Complex) and expr.is_inexact():<tab><tab>real, imag = expr.real, expr.imag<tab><tab><IF-STMT><tab><tab><tab>real = Integer(0)<tab><tab>if -delta < imag.get_float_value() < delta:<tab><tab><tab>imag = Integer(0)<tab><tab>return Complex(real, imag)<tab>elif isinstance(expr, Expression):<tab><tab>return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves])<tab>return expr",if - delta < real . get_float_value ( ) < delta :,186
1072,"def get_file_sources():<tab>global _file_sources<tab>if _file_sources is None:<tab><tab>from galaxy.files import ConfiguredFileSources<tab><tab>file_sources = None<tab><tab>if os.path.exists(""file_sources.json""):<tab><tab><tab>file_sources_as_dict = None<tab><tab><tab>with open(""file_sources.json"", ""r"") as f:<tab><tab><tab><tab>file_sources_as_dict = json.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict)<tab><tab>if file_sources is None:<tab><tab><tab>ConfiguredFileSources.from_dict([])<tab><tab>_file_sources = file_sources<tab>return _file_sources",if file_sources_as_dict is not None :,196
1073,"def _get_sort_map(tags):<tab>""""""See TAG_TO_SORT""""""<tab>tts = {}<tab>for name, tag in tags.items():<tab><tab><IF-STMT><tab><tab><tab>if tag.user:<tab><tab><tab><tab>tts[name] = ""%ssort"" % name<tab><tab><tab>if tag.internal:<tab><tab><tab><tab>tts[""~%s"" % name] = ""~%ssort"" % name<tab>return tts",if tag . has_sort :,111
1074,"def __init__(self, **kwargs):<tab>if self.name is None:<tab><tab>raise RuntimeError(""RenderPrimitive cannot be used directly"")<tab>self.option_values = {}<tab>for key, val in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""primitive `{0}' has no option `{1}'"".format(self.name, key)<tab><tab><tab>)<tab><tab>self.option_values[key] = val<tab># set up defaults<tab>for name, (description, default) in self.options.items():<tab><tab>if not name in self.option_values:<tab><tab><tab>self.option_values[name] = default",if not key in self . options :,162
1075,"def modify_bottle_params(self, output_stride=None):<tab>if output_stride is not None and output_stride % 2 != 0:<tab><tab>raise Exception(""output stride must to be even number"")<tab>if output_stride is None:<tab><tab>return<tab>else:<tab><tab>stride = 2<tab><tab>for i, _cfg in enumerate(self.cfg):<tab><tab><tab>stride = stride * _cfg[-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>s = 1<tab><tab><tab><tab>self.cfg[i][-1] = s",if stride > output_stride :,134
1076,"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab>if len(q) == 1:<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.append(value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab>if not is_iterable(value):<tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",elif is_iterable ( value ) :,185
1077,"def make_shares(self, plaintext):<tab>share_arrays = []<tab>for i, p in enumerate(plaintext):<tab><tab>share_array = self.make_byte_shares(p)<tab><tab>for sa in share_array:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>share_arrays.append(array.array(""H""))<tab><tab><tab>current_share_array = sa<tab><tab><tab>current_share_array.append(sa)<tab>return share_arrays",if i == 0 :,112
1078,"def populate(self, item):<tab># log.message('populate: %s', item)<tab>path = self.getItemPath(item)<tab># log.message('populate: path=%s', path)<tab>value = self.getValue(path)<tab>for name in sorted(value.__dict__.keys()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>child = getattr(value, name, None)<tab><tab>if hasattr(child, ""__dict__""):<tab><tab><tab>item.addChild(name, True)<tab><tab>else:<tab><tab><tab>item.addChild(name, False)","if name [ : 2 ] == ""__"" and name [ - 2 : ] == ""__"" :",151
1079,"def __repr__(self):<tab>try:<tab><tab>if self._semlock._is_mine():<tab><tab><tab>name = current_process().name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name += ""|"" + threading.current_thread().name<tab><tab>elif self._semlock._get_value() == 1:<tab><tab><tab>name = ""None""<tab><tab>elif self._semlock._count() > 0:<tab><tab><tab>name = ""SomeOtherThread""<tab><tab>else:<tab><tab><tab>name = ""SomeOtherProcess""<tab>except Exception:<tab><tab>name = ""unknown""<tab>return ""<Lock(owner=%s)>"" % name","if threading . current_thread ( ) . name != ""MainThread"" :",160
1080,"def buffer(self, lines, scroll_end=True, scroll_if_editing=False):<tab>""Add data to be displayed in the buffer.""<tab>self.values.extend(lines)<tab>if scroll_end:<tab><tab><IF-STMT><tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)<tab><tab>elif scroll_if_editing:<tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)",if not self . editing :,124
1081,"def warehouses(self) -> tuple:<tab>from ..repositories import WarehouseBaseRepo<tab>repos = dict()<tab>for dep in chain(self.dependencies, [self]):<tab><tab>if dep.repo is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for repo in dep.repo.repos:<tab><tab><tab>if repo.from_config:<tab><tab><tab><tab>continue<tab><tab><tab>repos[repo.name] = repo<tab>return tuple(repos.values())","if not isinstance ( dep . repo , WarehouseBaseRepo ) :",124
1082,"def _apply_flag_attrs(src_flag, dest_flag):<tab># Use a baseline flag def to get default values for empty data.<tab>baseline_flag = FlagDef("""", {}, None)<tab>for name in dir(src_flag):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dest_val = getattr(dest_flag, name, None)<tab><tab>baseline_val = getattr(baseline_flag, name, None)<tab><tab>if dest_val == baseline_val:<tab><tab><tab>setattr(dest_flag, name, getattr(src_flag, name))","if name [ : 1 ] == ""_"" :",137
1083,"def out(parent, attr, indent=0):<tab>val = getattr(parent, attr)<tab>prefix = ""%s%s:"" % ("" "" * indent, attr.replace(""_"", ""-""))<tab>if val is None:<tab><tab>cli.out(prefix)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>val = [flag_util.encode_flag_val(c.value) for c in val]<tab><tab>cli.out(""%s %s"" % (prefix, flag_util.encode_flag_val(val)))","if attr == ""choices"" :",125
1084,"def add_cand_to_check(cands):<tab>for cand in cands:<tab><tab>x = cand.creator<tab><tab>if x is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># `len(fan_out)` is in order to avoid comparing `x`<tab><tab><tab>heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x))<tab><tab>fan_out[x] += 1",if x not in fan_out :,111
1085,"def task_tree_lines(task=None):<tab>if task is None:<tab><tab>task = current_root_task()<tab>rendered_children = []<tab>nurseries = list(task.child_nurseries)<tab>while nurseries:<tab><tab>nursery = nurseries.pop()<tab><tab>nursery_children = _rendered_nursery_children(nursery)<tab><tab><IF-STMT><tab><tab><tab>nested = _render_subtree(""(nested nursery)"", rendered_children)<tab><tab><tab>nursery_children.append(nested)<tab><tab>rendered_children = nursery_children<tab>return _render_subtree(task.name, rendered_children)",if rendered_children :,172
1086,"def lock_workspace(build_dir):<tab>_BUILDING_LOCK_FILE = "".blade.building.lock""<tab>lock_file_fd, ret_code = lock_file(os.path.join(build_dir, _BUILDING_LOCK_FILE))<tab>if lock_file_fd == -1:<tab><tab><IF-STMT><tab><tab><tab>console.fatal(""There is already an active building in current workspace."")<tab><tab>else:<tab><tab><tab>console.fatal(""Lock exception, please try it later."")<tab>return lock_file_fd",if ret_code == errno . EAGAIN :,136
1087,"def test_list(self):<tab>self._create_locations()<tab>response = self.client.get(self.geojson_boxedlocation_list_url)<tab>self.assertEqual(response.status_code, 200)<tab>self.assertEqual(len(response.data[""features""]), 2)<tab>for feature in response.data[""features""]:<tab><tab>self.assertIn(""bbox"", feature)<tab><tab>fid = feature[""id""]<tab><tab>if fid == 1:<tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent)<tab><tab>else:<tab><tab><tab>self.fail(""Unexpected id: {0}"".format(fid))<tab>BoxedLocation.objects.all().delete()",elif fid == 2 :,196
1088,"def result():<tab># ""global"" does not work here...<tab>R, V = rays, virtual_rays<tab>if V is not None:<tab><tab>if normalize:<tab><tab><tab>V = normalize_rays(V, lattice)<tab><tab>if check:<tab><tab><tab>R = PointCollection(V, lattice)<tab><tab><tab>V = PointCollection(V, lattice)<tab><tab><tab>d = lattice.dimension()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""virtual rays must be linearly ""<tab><tab><tab><tab><tab>""independent and with other rays span the ambient space.""<tab><tab><tab><tab>)<tab>return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,194
1089,"def search_host(self, search_string):<tab>results = []<tab>for host_entry in self.config_data:<tab><tab>if host_entry.get(""type"") != ""entry"":<tab><tab><tab>continue<tab><tab>if host_entry.get(""host"") == ""*"":<tab><tab><tab>continue<tab><tab>searchable_information = host_entry.get(""host"")<tab><tab>for key, value in six.iteritems(host_entry.get(""options"")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = "" "".join(value)<tab><tab><tab>if isinstance(value, int):<tab><tab><tab><tab>value = str(value)<tab><tab><tab>searchable_information += "" "" + value<tab><tab>if search_string in searchable_information:<tab><tab><tab>results.append(host_entry)<tab>return results","if isinstance ( value , list ) :",191
1090,"def test_async_iterator(app):<tab>async with new_stream(app) as stream:<tab><tab>for i in range(100):<tab><tab><tab>await stream.channel.deliver(message(key=i, value=i))<tab><tab>received = 0<tab><tab>async for value in stream:<tab><tab><tab>assert value == received<tab><tab><tab>received += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>assert await channel_empty(stream.channel)",if received >= 100 :,113
1091,"def has_google_credentials():<tab>global _HAS_GOOGLE_CREDENTIALS<tab>if _HAS_GOOGLE_CREDENTIALS is None:<tab><tab>provider = Provider(""google"")<tab><tab><IF-STMT><tab><tab><tab>_HAS_GOOGLE_CREDENTIALS = False<tab><tab>else:<tab><tab><tab>_HAS_GOOGLE_CREDENTIALS = True<tab>return _HAS_GOOGLE_CREDENTIALS",if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,102
1092,"def __cmp__(self, other):<tab>if isinstance(other, date) or isinstance(other, datetime):<tab><tab>a = self._d.getTime()<tab><tab>b = other._d.getTime()<tab><tab>if a < b:<tab><tab><tab>return -1<tab><tab><IF-STMT><tab><tab><tab>return 0<tab>else:<tab><tab>raise TypeError(""expected date or datetime object"")<tab>return 1",elif a == b :,98
1093,"def validate_weight(self, weight):<tab>try:<tab><tab>add_acl_to_obj(self.context[""user_acl""], self.category)<tab>except AttributeError:<tab><tab>return weight  # don't validate weight further if category failed<tab>if weight > self.category.acl.get(""can_pin_threads"", 0):<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""You don't have permission to pin threads globally ""<tab><tab><tab><tab><tab>""in this category.""<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""You don't have permission to pin threads in this category."")<tab><tab><tab>)<tab>return weight",if weight == 2 :,177
1094,"def effective(line):<tab>for b in line:<tab><tab>if not b.cond:<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>val = 5<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if b.ignore:<tab><tab><tab><tab><tab><tab>b.ignore -= 1<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return (b, True)<tab><tab><tab>except:<tab><tab><tab><tab>return (b, False)<tab>return",if val :,118
1095,"def wheelEvent(self, event):<tab>""""""Handle a wheel event.""""""<tab>if QtCore.Qt.ControlModifier & event.modifiers():<tab><tab>d = {""c"": self.leo_c}<tab><tab>if isQt5:<tab><tab><tab>point = event.angleDelta()<tab><tab><tab>delta = point.y() or point.x()<tab><tab>else:<tab><tab><tab>delta = event.delta()<tab><tab><IF-STMT><tab><tab><tab>zoom_out(d)<tab><tab>else:<tab><tab><tab>zoom_in(d)<tab><tab>event.accept()<tab><tab>return<tab>QtWidgets.QTextBrowser.wheelEvent(self, event)",if delta < 0 :,160
1096,"def test_evname_in_mp_events_testcases():<tab>ok = True<tab>for evname in ins.mp_events:<tab><tab>if evname == ""version"":<tab><tab><tab>continue<tab><tab>for i, args in enumerate(ins.mp_events[evname][""test_cases""]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = ""Error, for evname %s the testase #%d does not match evname""<tab><tab><tab><tab>print(msg % (evname, i))<tab><tab><tab><tab>ok = False<tab>if ok:<tab><tab>print(""test_evname_in_mp_events_testcases: passed"")",if evname != args [ 0 ] :,156
1097,"def check_database():<tab>if len(EmailAddress.objects.all()) > 0:<tab><tab>print(<tab><tab><tab>""Are you sure you want to wipe the existing development database and reseed it? (Y/N)""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>destroy_database()<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return True","if raw_input ( ) . lower ( ) == ""y"" :",97
1098,"def _get_requested_databases(self):<tab>""""""Returns a list of databases requested, not including ignored dbs""""""<tab>requested_databases = []<tab>if (self._requested_namespaces is not None) and (self._requested_namespaces != []):<tab><tab>for requested_namespace in self._requested_namespaces:<tab><tab><tab>if requested_namespace[0] is ""*"":<tab><tab><tab><tab>return []<tab><tab><tab><IF-STMT><tab><tab><tab><tab>requested_databases.append(requested_namespace[0])<tab>return requested_databases",elif requested_namespace [ 0 ] not in IGNORE_DBS :,131
1099,"def decorated(self, *args, **kwargs):<tab>start_time = time.perf_counter()<tab>stderr = """"<tab>saved_exception = None<tab>try:<tab><tab>yield from fn(self, *args, **kwargs)<tab>except GitSavvyError as e:<tab><tab>stderr = e.stderr<tab><tab>saved_exception = e<tab>finally:<tab><tab>end_time = time.perf_counter()<tab><tab>util.debug.log_git(args, None, ""<SNIP>"", stderr, end_time - start_time)<tab><tab><IF-STMT><tab><tab><tab>raise saved_exception from None",if saved_exception :,146
1100,"def is_suppressed_warning(<tab>type: str, subtype: str, suppress_warnings: List[str]) -> bool:<tab>""""""Check the warning is suppressed or not.""""""<tab>if type is None:<tab><tab>return False<tab>for warning_type in suppress_warnings:<tab><tab>if ""."" in warning_type:<tab><tab><tab>target, subtarget = warning_type.split(""."", 1)<tab><tab>else:<tab><tab><tab>target, subtarget = warning_type, None<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>subtype is None<tab><tab><tab><tab>or subtarget is None<tab><tab><tab><tab>or subtarget == subtype<tab><tab><tab><tab>or subtarget == ""*""<tab><tab><tab>):<tab><tab><tab><tab>return True<tab>return False",if target == type :,178
1101,"def talk(self, words):<tab>if self.writeSentence(words) == 0:<tab><tab>return<tab>r = []<tab>while 1:<tab><tab>i = self.readSentence()<tab><tab>if len(i) == 0:<tab><tab><tab>continue<tab><tab>reply = i[0]<tab><tab>attrs = {}<tab><tab>for w in i[1:]:<tab><tab><tab>j = w.find(""="", 1)<tab><tab><tab>if j == -1:<tab><tab><tab><tab>attrs[w] = """"<tab><tab><tab>else:<tab><tab><tab><tab>attrs[w[:j]] = w[j + 1 :]<tab><tab>r.append((reply, attrs))<tab><tab><IF-STMT><tab><tab><tab>return r","if reply == ""!done"" :",169
1102,"def encrypt(self, plaintext):<tab>encrypted = []<tab>for p in _string_to_bytes(plaintext):<tab><tab><IF-STMT><tab><tab><tab>self._remaining_block = self._aes.encrypt(self._last_precipherblock)<tab><tab><tab>self._last_precipherblock = []<tab><tab>precipherbyte = self._remaining_block.pop(0)<tab><tab>self._last_precipherblock.append(precipherbyte)<tab><tab>cipherbyte = p ^ precipherbyte<tab><tab>encrypted.append(cipherbyte)<tab>return _bytes_to_string(encrypted)",if len ( self . _remaining_block ) == 0 :,146
1103,"def find_symbol(self, r, globally=False):<tab>query = self.view.substr(self.view.word(r))<tab>fname = self.view.file_name().replace(""\\"", ""/"")<tab>locations = self.view.window().lookup_symbol_in_index(query)<tab>if not locations:<tab><tab>return<tab>try:<tab><tab><IF-STMT><tab><tab><tab>location = [hit[2] for hit in locations if fname.endswith(hit[1])][0]<tab><tab><tab>return location[0] - 1, location[1] - 1<tab><tab>else:<tab><tab><tab># TODO: There might be many symbols with the same name.<tab><tab><tab>return locations[0]<tab>except IndexError:<tab><tab>return",if not globally :,172
1104,"def __getslice__(self, i, j):<tab>try:<tab><tab><IF-STMT><tab><tab><tab># handle the case where the right bound is unspecified<tab><tab><tab>j = len(self)<tab><tab>if i < 0 or j < 0:<tab><tab><tab>raise dns.exception.FormError<tab><tab># If it's not an empty slice, access left and right bounds<tab><tab># to make sure they're valid<tab><tab>if i != j:<tab><tab><tab>super(WireData, self).__getitem__(i)<tab><tab><tab>super(WireData, self).__getitem__(j - 1)<tab><tab>return WireData(super(WireData, self).__getslice__(i, j))<tab>except IndexError:<tab><tab>raise dns.exception.FormError",if j == sys . maxint :,181
1105,"def main():<tab>r = redis.StrictRedis()<tab>curr_memory = prev_memory = r.info()[""used_memory""]<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""Delta Memory : %d, Total Memory : %d""<tab><tab><tab><tab>% ((curr_memory - prev_memory), curr_memory)<tab><tab><tab>)<tab><tab>time.sleep(1)<tab><tab>prev_memory = curr_memory<tab><tab>curr_memory = r.info()[""used_memory""]",if prev_memory != curr_memory :,130
1106,"def _visit(self, func):<tab>fname = func[0]<tab>if fname in self._flags:<tab><tab>if self._flags[fname] == 1:<tab><tab><tab>logger.critical(""Fatal error! network ins not Dag."")<tab><tab><tab>import sys<tab><tab><tab>sys.exit(-1)<tab><tab>else:<tab><tab><tab>return<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._flags[fname] = 1<tab><tab>for output in func[3]:<tab><tab><tab>for f in self._orig:<tab><tab><tab><tab>for input in f[2]:<tab><tab><tab><tab><tab>if output == input:<tab><tab><tab><tab><tab><tab>self._visit(f)<tab>self._flags[fname] = 2<tab>self._sorted.insert(0, func)",if fname not in self . _flags :,188
1107,"def urls(self, version=None):<tab>""""""Returns all URLS that are mapped to this interface""""""<tab>urls = []<tab>for _base_url, routes in self.api.http.routes.items():<tab><tab>for url, methods in routes.items():<tab><tab><tab>for _method, versions in methods.items():<tab><tab><tab><tab>for interface_version, interface in versions.items():<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>if not url in urls:<tab><tab><tab><tab><tab><tab><tab>urls.append(<tab><tab><tab><tab><tab><tab><tab><tab>(""/v{0}"".format(version) if version else """") + url<tab><tab><tab><tab><tab><tab><tab>)<tab>return urls",if interface_version == version and interface == self :,169
1108,"def _handle_data(self, text):<tab>if self._translate:<tab><tab><IF-STMT><tab><tab><tab>self._data.append(text)<tab><tab>else:<tab><tab><tab>self._translate = False<tab><tab><tab>self._data = []<tab><tab><tab>self._comments = []","if not text . startswith ( ""gtk-"" ) :",74
1109,"def set_dir_modes(self, dirname, mode):<tab>if not self.is_chmod_supported():<tab><tab>return<tab>for dirpath, dirnames, fnames in os.walk(dirname):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>log.info(""changing mode of %s to %o"", dirpath, mode)<tab><tab>if not self.dry_run:<tab><tab><tab>os.chmod(dirpath, mode)",if os . path . islink ( dirpath ) :,105
1110,"def language(self):<tab>if self.lang_data:<tab><tab>lang_data = [s if s != ""None"" else None for s in self.lang_data]<tab><tab><IF-STMT><tab><tab><tab>return Language(lang_data[0], country=lang_data[1], script=lang_data[2])",if lang_data [ 0 ] :,80
1111,"def _addItemToLayout(self, sample, label):<tab>col = self.layout.columnCount()<tab>row = self.layout.rowCount()<tab>if row:<tab><tab>row -= 1<tab>nCol = self.columnCount * 2<tab># FIRST ROW FULL<tab>if col == nCol:<tab><tab>for col in range(0, nCol, 2):<tab><tab><tab># FIND RIGHT COLUMN<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>if col + 2 == nCol:<tab><tab><tab># MAKE NEW ROW<tab><tab><tab>col = 0<tab><tab><tab>row += 1<tab>self.layout.addItem(sample, row, col)<tab>self.layout.addItem(label, row, col + 1)","if not self . layout . itemAt ( row , col ) :",185
1112,"def align_comments(tlist):<tab>tidx, token = tlist.token_next_by(i=sql.Comment)<tab>while token:<tab><tab>pidx, prev_ = tlist.token_prev(tidx)<tab><tab><IF-STMT><tab><tab><tab>tlist.group_tokens(sql.TokenList, pidx, tidx, extend=True)<tab><tab><tab>tidx = pidx<tab><tab>tidx, token = tlist.token_next_by(i=sql.Comment, idx=tidx)","if isinstance ( prev_ , sql . TokenList ) :",130
1113,"def hook_GetVariable(ql, address, params):<tab>if params[""VariableName""] in ql.env:<tab><tab>var = ql.env[params[""VariableName""]]<tab><tab>read_len = read_int64(ql, params[""DataSize""])<tab><tab>if params[""Attributes""] != 0:<tab><tab><tab>write_int64(ql, params[""Attributes""], 0)<tab><tab>write_int64(ql, params[""DataSize""], len(var))<tab><tab><IF-STMT><tab><tab><tab>return EFI_BUFFER_TOO_SMALL<tab><tab>if params[""Data""] != 0:<tab><tab><tab>ql.mem.write(params[""Data""], var)<tab><tab>return EFI_SUCCESS<tab>return EFI_NOT_FOUND",if read_len < len ( var ) :,177
1114,"def _PromptMySQL(self, config):<tab>""""""Prompts the MySQL configuration, retrying if the configuration is invalid.""""""<tab>while True:<tab><tab>self._PromptMySQLOnce(config)<tab><tab>if self._CheckMySQLConnection():<tab><tab><tab>print(""Successfully connected to MySQL with the given configuration."")<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>print(""Error: Could not connect to MySQL with the given configuration."")<tab><tab><tab>retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ConfigInitError()",if not retry :,136
1115,"def split_long_line_with_indent(line, max_per_line, indent):<tab>""""""Split the `line` so that it doesn't go over `max_per_line` and adds `indent` to new lines.""""""<tab>words = line.split("" "")<tab>lines = []<tab>current_line = words[0]<tab>for word in words[1:]:<tab><tab><IF-STMT><tab><tab><tab>lines.append(current_line)<tab><tab><tab>current_line = "" "" * indent + word<tab><tab>else:<tab><tab><tab>current_line = f""{current_line} {word}""<tab>lines.append(current_line)<tab>return ""\n"".join(lines)","if len ( f""{current_line} {word}"" ) > max_per_line :",176
1116,"def gen_cli(docs_dir):<tab>with open(os.path.join(docs_dir, ""CLI_template.md""), ""r"") as cli_temp_file:<tab><tab>temp_lines = cli_temp_file.readlines()<tab>lines = []<tab>for line in temp_lines:<tab><tab>matched = re.match(r""{onnx-tf.*}"", line)<tab><tab><IF-STMT><tab><tab><tab>command = matched.string.strip()[1:-1]<tab><tab><tab>output = subprocess.check_output(command.split("" "")).decode(""UTF-8"")<tab><tab><tab>lines.append(output)<tab><tab>else:<tab><tab><tab>lines.append(line)<tab>with open(os.path.join(docs_dir, ""CLI.md""), ""w"") as cli_file:<tab><tab>cli_file.writelines(lines)",if matched :,200
1117,"def read(self, size=None):<tab>if size == 0:<tab><tab>return """"<tab>data = list()<tab>while size is None or size > 0:<tab><tab>line = self.readline(size or -1)<tab><tab>if not line:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>size -= len(line)<tab><tab>data.append(line)<tab>return """".join(data)",if size is not None :,101
1118,"def _get_format_and_pattern(file_path):<tab>file_path = Path(file_path)<tab>with file_path.open() as f:<tab><tab>first_line = f.readline().strip()<tab><tab>match = re.match(r""format *: *(.+)"", first_line)<tab><tab><IF-STMT><tab><tab><tab>return ""gztar"", first_line, 1<tab><tab>return match.group(1), f.readline().strip(), 2",if match is None :,111
1119,"def remove_old_snapshot(install_dir):<tab>logging.info(""Removing any old files in {}"".format(install_dir))<tab>for file in glob.glob(""{}/*"".format(install_dir)):<tab><tab>try:<tab><tab><tab>if os.path.isfile(file):<tab><tab><tab><tab>os.unlink(file)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shutil.rmtree(file)<tab><tab>except Exception as error:<tab><tab><tab>logging.error(""Error: {}"".format(error))<tab><tab><tab>sys.exit(1)",elif os . path . isdir ( file ) :,133
1120,"def _test_forever(self, tests):<tab>while True:<tab><tab>for test_name in tests:<tab><tab><tab>yield test_name<tab><tab><tab>if self.bad:<tab><tab><tab><tab>return<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return",if self . ns . fail_env_changed and self . environment_changed :,76
1121,"def _swig_extract_dependency_files(self, src):<tab>dep = []<tab>for line in open(src):<tab><tab>if line.startswith(""#include"") or line.startswith(""%include""):<tab><tab><tab>line = line.split("" "")[1].strip(""""""'""\r\n"""""")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dep.append(line)<tab>return [i for i in dep if os.path.exists(i)]","if not ( ""<"" in line or line in dep ) :",111
1122,"def update_service_key(kid, name=None, metadata=None):<tab>try:<tab><tab>with db_transaction():<tab><tab><tab>key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key.name = name<tab><tab><tab>if metadata is not None:<tab><tab><tab><tab>key.metadata.update(metadata)<tab><tab><tab>key.save()<tab>except ServiceKey.DoesNotExist:<tab><tab>raise ServiceKeyDoesNotExist",if name is not None :,127
1123,"def range(self, dimension, data_range=True, dimension_range=True):<tab>if self.nodes and dimension in self.nodes.dimensions():<tab><tab>node_range = self.nodes.range(dimension, data_range, dimension_range)<tab><tab><IF-STMT><tab><tab><tab>path_range = self._edgepaths.range(dimension, data_range, dimension_range)<tab><tab><tab>return max_range([node_range, path_range])<tab><tab>return node_range<tab>return super(Graph, self).range(dimension, data_range, dimension_range)",if self . _edgepaths :,137
1124,"def handler(chan, host, port):<tab>sock = socket()<tab>try:<tab><tab>sock.connect((host, port))<tab>except Exception as e:<tab><tab>if verbose == True:<tab><tab><tab>print(e)<tab><tab>return<tab>while True:<tab><tab>r, w, x = select.select([sock, chan], [], [])<tab><tab>if sock in r:<tab><tab><tab>data = sock.recv(1024)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>chan.send(data)<tab><tab>if chan in r:<tab><tab><tab>data = chan.recv(1024)<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>break<tab><tab><tab>sock.send(data)<tab>chan.close()<tab>sock.close()",if len ( data ) == 0 :,190
1125,"def output_layer(self, features, **kwargs):<tab>""""""Project features to the vocabulary size.""""""<tab>if self.adaptive_softmax is None:<tab><tab># project back to size of vocabulary<tab><tab><IF-STMT><tab><tab><tab>return F.linear(features, self.embed_tokens.weight)<tab><tab>else:<tab><tab><tab>return F.linear(features, self.embed_out)<tab>else:<tab><tab>return features",if self . share_input_output_embed :,108
1126,"def generate(self, dest, vars):<tab>util.ensure_dir(dest)<tab>for relpath, src, template in self._file_templates:<tab><tab>file_dest = os.path.join(dest, relpath)<tab><tab>util.ensure_dir(os.path.dirname(file_dest))<tab><tab><IF-STMT><tab><tab><tab>shutil.copyfile(src, file_dest)<tab><tab>else:<tab><tab><tab>_render_template(template, vars, file_dest)",if template is None :,115
1127,"def _py_matching_callback(self, context, result, sender, device):<tab>d = HIDDevice.get_device(c_void_p(device))<tab>if d not in self.devices:<tab><tab>self.devices.add(d)<tab><tab>for x in self.matching_observers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x.device_discovered(d)","if hasattr ( x , ""device_discovered"" ) :",102
1128,"def urlquote(*args, **kwargs):<tab>new_kwargs = dict(kwargs)<tab>if not PY3:<tab><tab>new_kwargs = dict(kwargs)<tab><tab><IF-STMT><tab><tab><tab>del new_kwargs[""encoding""]<tab><tab>if ""errors"" in kwargs:<tab><tab><tab>del new_kwargs[""errors""]<tab>return quote(*args, **new_kwargs)","if ""encoding"" in new_kwargs :",93
1129,"def Set(self, attr, value):<tab>hook = getattr(self, ""_set_%s"" % attr, None)<tab>if hook:<tab><tab># If there is a set hook we must use the context manager.<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Can only update attribute %s using the context manager."" % attr<tab><tab><tab>)<tab><tab>if attr not in self._pending_hooks:<tab><tab><tab>self._pending_hooks.append(attr)<tab><tab>self._pending_parameters[attr] = value<tab>else:<tab><tab>super(Configuration, self).Set(attr, value)",if self . _lock > 0 :,150
1130,"def on_profiles_loaded(self, profiles):<tab>cb = self.builder.get_object(""cbProfile"")<tab>model = cb.get_model()<tab>model.clear()<tab>for f in profiles:<tab><tab>name = f.get_basename()<tab><tab>if name.endswith("".mod""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>name = name[0:-11]<tab><tab>model.append((name, f, None))<tab>cb.set_active(0)","if name . endswith ( "".sccprofile"" ) :",122
1131,"def get_eval_task(self, worker_id):<tab>""""""Return next evaluation (task_id, Task) tuple""""""<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>return -1, None<tab><tab>self._task_id += 1<tab><tab>task = self._eval_todo.pop()<tab><tab>self._doing[self._task_id] = (worker_id, task, time.time())<tab><tab>return self._task_id, task",if not self . _eval_todo :,115
1132,"def queries(self):<tab>if DEV:<tab><tab>cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s)<tab><tab><IF-STMT><tab><tab><tab>if not cmd.stdout.strip():<tab><tab><tab><tab>log_cmd = ShellCommand(<tab><tab><tab><tab><tab>""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT<tab><tab><tab><tab>)<tab><tab><tab><tab>if log_cmd.check(f""docker logs for {self.path.k8s}""):<tab><tab><tab><tab><tab>print(cmd.stdout)<tab><tab><tab><tab>pytest.exit(f""container failed to start for {self.path.k8s}"")<tab>return ()","if not cmd . check ( f""docker check for {self.path.k8s}"" ) :",188
1133,"def disjoined(data):<tab># create marginalized distributions and multiple them together<tab>data_disjoined = None<tab>dim = len(data.shape)<tab>for d in range(dim):<tab><tab>axes = list(range(dim))<tab><tab>axes.remove(d)<tab><tab>data1d = multisum(data, axes)<tab><tab>shape = [1 for k in range(dim)]<tab><tab>shape[d] = len(data1d)<tab><tab>data1d = data1d.reshape(tuple(shape))<tab><tab><IF-STMT><tab><tab><tab>data_disjoined = data1d<tab><tab>else:<tab><tab><tab>data_disjoined = data_disjoined * data1d<tab>return data_disjoined",if d == 0 :,176
1134,"def safe_repr(val):<tab>try:<tab><tab><IF-STMT><tab><tab><tab># We special case dicts to have a sorted repr. This makes testing<tab><tab><tab># significantly easier<tab><tab><tab>val = _obj_with_safe_repr(val)<tab><tab>ret = repr(val)<tab><tab>if six.PY2:<tab><tab><tab>ret = ret.decode(""utf-8"")<tab>except UnicodeEncodeError:<tab><tab>ret = red(""a %r that cannot be represented"" % type(val))<tab>else:<tab><tab>ret = green(ret)<tab>return ret","if isinstance ( val , dict ) :",138
1135,"def wrapper(*args, **kwargs):<tab>resp = view_func(*args, **kwargs)<tab>if isinstance(resp, dict):<tab><tab>ctx_params = request.environ.get(""webrec.template_params"")<tab><tab><IF-STMT><tab><tab><tab>resp.update(ctx_params)<tab><tab>template = self.jinja_env.jinja_env.get_or_select_template(template_name)<tab><tab>return template.render(**resp)<tab>else:<tab><tab>return resp",if ctx_params :,117
1136,"def post(self, request, *args, **kwargs):<tab>contact_id = kwargs.get(""pk"")<tab>self.object = get_object_or_404(Contact, id=contact_id)<tab>if (<tab><tab>self.request.user.role != ""ADMIN""<tab><tab>and not self.request.user.is_superuser<tab><tab>and self.request.user != self.object.created_by<tab>) or self.object.company != self.request.company:<tab><tab>raise PermissionDenied<tab>else:<tab><tab>if self.object.address_id:<tab><tab><tab>self.object.address.delete()<tab><tab>self.object.delete()<tab><tab><IF-STMT><tab><tab><tab>return JsonResponse({""error"": False})<tab><tab>return redirect(""contacts:list"")",if self . request . is_ajax ( ) :,189
1137,"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text","if ""<"" in text :",170
1138,"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict) and k != ""headers"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>elif isinstance(i, _bytes):<tab><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, _bytes):<tab><tab><tab>return False<tab>return True",if not everythingIsUnicode ( v ) :,158
1139,"def fill(self):<tab>try:<tab><tab>while (<tab><tab><tab>not self.stopping.wait(self.sample_wait)<tab><tab><tab>and len(self.queue) < self.queue.maxlen<tab><tab>):<tab><tab><tab>self.queue.append(self.parent._read())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.parent._fire_events()<tab><tab>self.full.set()<tab><tab>while not self.stopping.wait(self.sample_wait):<tab><tab><tab>self.queue.append(self.parent._read())<tab><tab><tab>if isinstance(self.parent, EventsMixin):<tab><tab><tab><tab>self.parent._fire_events()<tab>except ReferenceError:<tab><tab># Parent is dead; time to die!<tab><tab>pass","if self . partial and isinstance ( self . parent , EventsMixin ) :",190
1140,"def _SetListviewTextItems(self, items):<tab>self.listview.DeleteAllItems()<tab>index = -1<tab>for item in items:<tab><tab>index = self.listview.InsertItem(index + 1, item[0])<tab><tab>data = item[1]<tab><tab><IF-STMT><tab><tab><tab>data = """"<tab><tab>self.listview.SetItemText(index, 1, data)",if data is None :,99
1141,"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab>if is_text_payload(request) and request.body:<tab><tab><tab>body = six.ensure_str(request.body)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",if old in body :,103
1142,"def serialize(cls, value, *args, **kwargs):<tab>if value is None:<tab><tab>return """"<tab>value_as_string = six.text_type(value)<tab>if SHOULD_NOT_USE_LOCALE:<tab><tab>return value_as_string<tab>else:<tab><tab>grouping = kwargs.get(""grouping"", None)<tab><tab>has_decimal_places = value_as_string.find(""."") != -1<tab><tab><IF-STMT><tab><tab><tab>string_format = ""%d""<tab><tab>else:<tab><tab><tab>decimal_places = len(value_as_string.split(""."")[1])<tab><tab><tab>string_format = ""%.{}f"".format(decimal_places)<tab><tab>return locale.format(string_format, value, grouping=grouping)",if not has_decimal_places :,185
1143,"def review_link(request, path_obj):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if check_permission(""translate"", request):<tab><tab><tab><tab>text = _(""Review Suggestions"")<tab><tab><tab>else:<tab><tab><tab><tab>text = _(""View Suggestions"")<tab><tab><tab>return {<tab><tab><tab><tab>""href"": dispatch.translate(<tab><tab><tab><tab><tab>request, path_obj.pootle_path, matchnames=[""hassuggestion""]<tab><tab><tab><tab>),<tab><tab><tab><tab>""text"": text,<tab><tab><tab>}<tab>except IOError:<tab><tab>pass",if path_obj . has_suggestions ( ) :,146
1144,"def _migrate_key(self, key):<tab>""""""migrate key from old .dat file""""""<tab>key_path = os.path.join(self.home_path, ""keys.dat"")<tab>if os.path.exists(key_path):<tab><tab>try:<tab><tab><tab>key_data = json.loads(open(key_path, ""rb"").read())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_key(key, key_data.get(key))<tab><tab>except:<tab><tab><tab>self.error(f""Corrupt key file. Manual migration of '{key}' required."")",if key_data . get ( key ) :,148
1145,"def gather_callback_args(self, obj, callbacks):<tab>session = sa.orm.object_session(obj)<tab>for callback in callbacks:<tab><tab>backref = callback.backref<tab><tab>root_objs = getdotattr(obj, backref) if backref else obj<tab><tab>if root_objs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>root_objs = [root_objs]<tab><tab><tab>with session.no_autoflush:<tab><tab><tab><tab>for root_obj in root_objs:<tab><tab><tab><tab><tab>if root_obj:<tab><tab><tab><tab><tab><tab>args = self.get_callback_args(root_obj, callback)<tab><tab><tab><tab><tab><tab>if args:<tab><tab><tab><tab><tab><tab><tab>yield args","if not isinstance ( root_objs , Iterable ) :",182
1146,"def GetDefFile(self, gyp_to_build_path):<tab>""""""Returns the .def file from sources, if any.  Otherwise returns None.""""""<tab>spec = self.spec<tab>if spec[""type""] in (""shared_library"", ""loadable_module"", ""executable""):<tab><tab>def_files = [s for s in spec.get(""sources"", []) if s.endswith("".def"")]<tab><tab><IF-STMT><tab><tab><tab>return gyp_to_build_path(def_files[0])<tab><tab>elif len(def_files) > 1:<tab><tab><tab>raise Exception(""Multiple .def files"")<tab>return None",if len ( def_files ) == 1 :,153
1147,"def _validate_gallery(images):<tab>for image in images:<tab><tab>image_path = image.get(""image_path"", """")<tab><tab>if image_path:<tab><tab><tab>if not isfile(image_path):<tab><tab><tab><tab>raise TypeError(f""{image_path!r} is not a valid image path."")<tab><tab>else:<tab><tab><tab>raise TypeError(""'image_path' is required."")<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""Caption must be 180 characters or less."")","if not len ( image . get ( ""caption"" , """" ) ) <= 180 :",130
1148,"def VType(self):<tab>if ""DW_AT_type"" in self.attributes:<tab><tab>target = self.types[self.type_id]<tab><tab>target_type = target.VType()<tab><tab><IF-STMT><tab><tab><tab>target_type = [target_type, None]<tab><tab>return [""Pointer"", dict(target=target_type[0], target_args=target_type[1])]<tab>return [""Pointer"", dict(target=""Void"")]","if not isinstance ( target_type , list ) :",117
1149,"def addInPlace(self, value1, value2):<tab>for group in value2:<tab><tab>for key in value2[group]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value1[group][key] = value2[group][key]<tab><tab><tab>else:<tab><tab><tab><tab>value1[group][key] += value2[group][key]<tab>return value1",if key not in value1 [ group ] :,97
1150,"def _mongo_query_and(self, queries):<tab>if len(queries) == 1:<tab><tab>return queries[0]<tab>query = {}<tab>for q in queries:<tab><tab>for k, v in q.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>query[k] = {}<tab><tab><tab>if isinstance(v, list):<tab><tab><tab><tab># TODO check exists of k in query, may be it should be update<tab><tab><tab><tab>query[k] = v<tab><tab><tab>else:<tab><tab><tab><tab>query[k].update(v)<tab>return query",if k not in query :,141
1151,"def _handled_eventtype(self, eventtype, handler):<tab>if eventtype not in known_events:<tab><tab>log.error('The event ""%s"" is not known', eventtype)<tab><tab>return False<tab>if known_events[eventtype].__module__.startswith(""deluge.event""):<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>log.error(<tab><tab><tab>""You cannot register custom notification providers ""<tab><tab><tab>""for built-in event types.""<tab><tab>)<tab><tab>return False<tab>return True",if handler . __self__ is self :,130
1152,"def get_ax_arg(uri):<tab>if not ax_ns:<tab><tab>return u""""<tab>prefix = ""openid."" + ax_ns + "".type.""<tab>ax_name = None<tab>for name, values in self.request.arguments.iteritems():<tab><tab><IF-STMT><tab><tab><tab>part = name[len(prefix) :]<tab><tab><tab>ax_name = ""openid."" + ax_ns + "".value."" + part<tab><tab><tab>break<tab>if not ax_name:<tab><tab>return u""""<tab>return self.get_argument(ax_name, u"""")",if values [ - 1 ] == uri and name . startswith ( prefix ) :,148
1153,"def handle_starttag(self, tag, attrs):<tab>if tag == ""base"":<tab><tab>self.base_url = dict(attrs).get(""href"")<tab>if self.scan_tag(tag):<tab><tab>for attr, value in attrs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.strip:<tab><tab><tab><tab><tab>value = strip_html5_whitespace(value)<tab><tab><tab><tab>url = self.process_attr(value)<tab><tab><tab><tab>link = Link(url=url)<tab><tab><tab><tab>self.links.append(link)<tab><tab><tab><tab>self.current_link = link",if self . scan_attr ( attr ) :,151
1154,"def test_long_steadystate_queue_popright(self):<tab>for size in (0, 1, 2, 100, 1000):<tab><tab>d = deque(reversed(range(size)))<tab><tab>append, pop = d.appendleft, d.pop<tab><tab>for i in range(size, BIG):<tab><tab><tab>append(i)<tab><tab><tab>x = pop()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(x, i - size)<tab><tab>self.assertEqual(list(reversed(list(d))), list(range(BIG - size, BIG)))",if x != i - size :,143
1155,"def _update_read(self):<tab>""""""Update state when there is read event""""""<tab>try:<tab><tab>msg = bytes(self._sock.recv(4096))<tab><tab><IF-STMT><tab><tab><tab>self.on_message(msg)<tab><tab><tab>return True<tab><tab># normal close, remote is closed<tab><tab>self.close()<tab>except socket.error as err:<tab><tab>if err.args[0] in (errno.EAGAIN, errno.EWOULDBLOCK):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.on_error(err)<tab>return False",if msg :,142
1156,"def prepend(self, value):<tab>""""""prepend value to nodes""""""<tab>root, root_text = self._get_root(value)<tab>for i, tag in enumerate(self):<tab><tab>if not tag.text:<tab><tab><tab>tag.text = """"<tab><tab><IF-STMT><tab><tab><tab>root[-1].tail = tag.text<tab><tab><tab>tag.text = root_text<tab><tab>else:<tab><tab><tab>tag.text = root_text + tag.text<tab><tab>if i > 0:<tab><tab><tab>root = deepcopy(list(root))<tab><tab>tag[:0] = root<tab><tab>root = tag[: len(root)]<tab>return self",if len ( root ) > 0 :,160
1157,"def cmp(self, other):<tab>v_is_ptr = not isinstance(self, CTypesGenericPrimitive)<tab>w_is_ptr = isinstance(other, CTypesData) and not isinstance(<tab><tab>other, CTypesGenericPrimitive<tab>)<tab>if v_is_ptr and w_is_ptr:<tab><tab>return cmpfunc(self._convert_to_address(None), other._convert_to_address(None))<tab>elif v_is_ptr or w_is_ptr:<tab><tab>return NotImplemented<tab>else:<tab><tab>if isinstance(self, CTypesGenericPrimitive):<tab><tab><tab>self = self._value<tab><tab><IF-STMT><tab><tab><tab>other = other._value<tab><tab>return cmpfunc(self, other)","if isinstance ( other , CTypesGenericPrimitive ) :",179
1158,"def get_external_addresses(self, label=None) -> List[str]:<tab>result = []<tab>for c in self._conf[""pools""].values():<tab><tab><IF-STMT><tab><tab><tab>if label == c[""label""]:<tab><tab><tab><tab>result.append(c[""external_address""][0])<tab><tab>else:<tab><tab><tab>result.append(c[""external_address""][0])<tab>return result",if label is not None :,99
1159,"def coerce_text(v):<tab>if not isinstance(v, basestring_):<tab><tab><IF-STMT><tab><tab><tab>attr = ""__unicode__""<tab><tab>else:<tab><tab><tab>attr = ""__str__""<tab><tab>if hasattr(v, attr):<tab><tab><tab>return unicode(v)<tab><tab>else:<tab><tab><tab>return bytes(v)<tab>return v",if sys . version_info [ 0 ] < 3 :,93
1160,"def check_localhost(self):<tab>""""""Warn if any socket_host is 'localhost'. See #711.""""""<tab>for k, v in cherrypy.config.items():<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""The use of 'localhost' as a socket host can ""<tab><tab><tab><tab>""cause problems on newer systems, since ""<tab><tab><tab><tab>""'localhost' can map to either an IPv4 or an ""<tab><tab><tab><tab>""IPv6 address. You should use '127.0.0.1' ""<tab><tab><tab><tab>""or '[::1]' instead.""<tab><tab><tab>)","if k == ""server.socket_host"" and v == ""localhost"" :",160
1161,"def add_songs(self, filenames, library):<tab>changed = []<tab>for i in range(len(self)):<tab><tab><IF-STMT><tab><tab><tab>song = library[self._list[i]]<tab><tab><tab>self._list[i] = song<tab><tab><tab>changed.append(song)<tab>if changed:<tab><tab>self._emit_changed(changed, msg=""add"")<tab>return bool(changed)","if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :",113
1162,"def _expand_deps_java_generation(self):<tab>""""""Ensure that all multilingual dependencies such as proto_library generate java code.""""""<tab>queue = collections.deque(self.deps)<tab>keys = set()<tab>while queue:<tab><tab>k = queue.popleft()<tab><tab>if k not in keys:<tab><tab><tab>keys.add(k)<tab><tab><tab>dep = self.target_database[k]<tab><tab><tab><IF-STMT>  # Has this attribute<tab><tab><tab><tab>dep.attr[""generate_java""] = True<tab><tab><tab><tab>queue.extend(dep.deps)","if ""generate_java"" in dep . attr :",144
1163,"def get(self):<tab>name = request.args.get(""filename"")<tab>if name is not None:<tab><tab>opts = dict()<tab><tab>opts[""type""] = ""episode""<tab><tab>result = guessit(name, options=opts)<tab><tab>res = dict()<tab><tab><IF-STMT><tab><tab><tab>res[""episode""] = result[""episode""]<tab><tab>else:<tab><tab><tab>res[""episode""] = 0<tab><tab>if ""season"" in result:<tab><tab><tab>res[""season""] = result[""season""]<tab><tab>else:<tab><tab><tab>res[""season""] = 0<tab><tab>if ""subtitle_language"" in result:<tab><tab><tab>res[""subtitle_language""] = str(result[""subtitle_language""])<tab><tab>return jsonify(data=res)<tab>else:<tab><tab>return """", 400","if ""episode"" in result :",196
1164,def _get_error_file(self) -> Optional[str]:<tab>error_file = None<tab>min_timestamp = sys.maxsize<tab>for replicas in self.role_replicas.values():<tab><tab>for replica in replicas:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>mtime = os.path.getmtime(replica.error_file)<tab><tab><tab>if mtime < min_timestamp:<tab><tab><tab><tab>min_timestamp = mtime<tab><tab><tab><tab>error_file = replica.error_file<tab>return error_file,if not os . path . exists ( replica . error_file ) :,138
1165,"def findChapterNameForPosition(self, p):<tab>""""""Return the name of a chapter containing p or None if p does not exist.""""""<tab>cc, c = self, self.c<tab>if not p or not c.positionExists(p):<tab><tab>return None<tab>for name in cc.chaptersDict:<tab><tab><IF-STMT><tab><tab><tab>theChapter = cc.chaptersDict.get(name)<tab><tab><tab>if theChapter.positionIsInChapter(p):<tab><tab><tab><tab>return name<tab>return ""main""","if name != ""main"" :",128
1166,"def remove_files(folder, file_extensions):<tab>for f in os.listdir(folder):<tab><tab>f_path = os.path.join(folder, f)<tab><tab>if os.path.isfile(f_path):<tab><tab><tab>extension = os.path.splitext(f_path)[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(f_path)",if extension in file_extensions :,96
1167,"def execute_uncomment(self, event):<tab>cursor = self._editor.GetCurrentPos()<tab>line, pos = self._editor.GetCurLine()<tab>spaces = "" "" * self._tab_size<tab>comment = ""Comment"" + spaces<tab>cpos = cursor - len(comment)<tab>lenline = len(line)<tab>if lenline > 0:<tab><tab>idx = 0<tab><tab>while idx < lenline and line[idx] == "" "":<tab><tab><tab>idx += 1<tab><tab><IF-STMT><tab><tab><tab>self._editor.DeleteRange(cursor - pos + idx, len(comment))<tab><tab><tab>self._editor.SetCurrentPos(cpos)<tab><tab><tab>self._editor.SetSelection(cpos, cpos)<tab><tab><tab>self.store_position()",if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,197
1168,"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell(<tab>critical_suite_with_citations, empty_data_context):<tab>obs = SuiteEditNotebookRenderer.from_data_context(empty_data_context).render(<tab><tab>critical_suite_with_citations, {""path"": ""./foo/data""}<tab>)<tab>assert isinstance(obs, dict)<tab>found_expected = False<tab>for cell in obs[""cells""]:<tab><tab><IF-STMT><tab><tab><tab>source_code = cell[""source""]<tab><tab><tab>if 'batch_kwargs = {""path"": ""../.././foo/data""}' in source_code:<tab><tab><tab><tab>found_expected = True<tab><tab><tab><tab>break<tab>assert found_expected","if cell [ ""cell_type"" ] == ""code"" :",196
1169,"def _get_file(self):<tab>if self._file is None:<tab><tab>self._file = SpooledTemporaryFile(<tab><tab><tab>max_size=self._storage.max_memory_size,<tab><tab><tab>suffix="".S3Boto3StorageFile"",<tab><tab><tab>dir=setting(""FILE_UPLOAD_TEMP_DIR""),<tab><tab>)<tab><tab>if ""r"" in self._mode:<tab><tab><tab>self._is_dirty = False<tab><tab><tab>self.obj.download_fileobj(self._file)<tab><tab><tab>self._file.seek(0)<tab><tab><IF-STMT><tab><tab><tab>self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0)<tab>return self._file","if self . _storage . gzip and self . obj . content_encoding == ""gzip"" :",184
1170,"def _parse_filters(f_strs):<tab>filters = []<tab>if not f_strs:<tab><tab>return filters<tab>for f_str in f_strs:<tab><tab><IF-STMT><tab><tab><tab>fname, fopts = f_str.split("":"", 1)<tab><tab><tab>filters.append((fname, _parse_options([fopts])))<tab><tab>else:<tab><tab><tab>filters.append((f_str, {}))<tab>return filters","if "":"" in f_str :",107
1171,"def update_completion(self):<tab>""""""Update completion model with exist tags""""""<tab>orig_text = self.widget.text()<tab>text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1])<tab>tags = []<tab>for tag in self.tags_list:<tab><tab><IF-STMT><tab><tab><tab>if orig_text[-1] not in ("","", "" ""):<tab><tab><tab><tab>tags.append(""%s,%s"" % (text, tag))<tab><tab><tab>tags.append(""%s, %s"" % (text, tag))<tab><tab>else:<tab><tab><tab>tags.append(tag)<tab>if tags != self.completer_model.stringList():<tab><tab>self.completer_model.setStringList(tags)","if "","" in orig_text :",177
1172,"def _get_startup_packages(lib_path: Path, packages) -> Set[str]:<tab>names = set()<tab>for path in lib_path.iterdir():<tab><tab>name = path.name<tab><tab>if name == ""__pycache__"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>names.add(name.split(""."")[0])<tab><tab>elif path.is_dir() and ""."" not in name:<tab><tab><tab>names.add(name)<tab>if packages:<tab><tab>packages = {package.lower().replace(""-"", ""_"") for package in packages}<tab><tab>if len(names & packages) == len(packages):<tab><tab><tab>return packages<tab>return names","if name . endswith ( "".py"" ) :",159
1173,"def get_cloud_credential(self):<tab>""""""Return the credential which is directly tied to the inventory source type.""""""<tab>credential = None<tab>for cred in self.credentials.all():<tab><tab><IF-STMT><tab><tab><tab>if cred.kind == self.source.replace(""ec2"", ""aws""):<tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># these need to be returned in the API credential field<tab><tab><tab>if cred.credential_type.kind != ""vault"":<tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab>return credential",if self . source in CLOUD_PROVIDERS :,149
1174,"def newickize(clade):<tab>""""""Convert a node tree to a Newick tree string, recursively.""""""<tab>label = clade.name or """"<tab>if label:<tab><tab>unquoted_label = re.match(token_dict[""unquoted node label""], label)<tab><tab><IF-STMT><tab><tab><tab>label = ""'%s'"" % label.replace(""\\"", ""\\\\"").replace(""'"", ""\\'"")<tab>if clade.is_terminal():  # terminal<tab><tab>return label + make_info_string(clade, terminal=True)<tab>else:<tab><tab>subtrees = (newickize(sub) for sub in clade)<tab><tab>return ""(%s)%s"" % ("","".join(subtrees), label + make_info_string(clade))",if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) :,184
1175,"def __iter__(self):<tab>for name, value in self._vars.store.data.items():<tab><tab>source = self._sources[name]<tab><tab>prefix = self._get_prefix(value)<tab><tab>name = u""{0}{{{1}}}"".format(prefix, name)<tab><tab><IF-STMT><tab><tab><tab>yield ArgumentInfo(name, value)<tab><tab>else:<tab><tab><tab>yield VariableInfo(name, value, source)",if source == self . ARGUMENT_SOURCE :,110
1176,"def filepath_enumerate(paths):<tab>""""""Enumerate the file paths of all subfiles of the list of paths""""""<tab>out = []<tab>for path in paths:<tab><tab><IF-STMT><tab><tab><tab>out.append(path)<tab><tab>else:<tab><tab><tab>for root, dirs, files in os.walk(path):<tab><tab><tab><tab>for name in files:<tab><tab><tab><tab><tab>out.append(os.path.normpath(os.path.join(root, name)))<tab>return out",if os . path . isfile ( path ) :,122
1177,"def del_(self, key):<tab>hash_ = self.hash(key)<tab>node_ = self._table[hash_]<tab>pre_node = None<tab>while node_ is not None:<tab><tab><IF-STMT><tab><tab><tab>if pre_node is None:<tab><tab><tab><tab>self._table[hash_] = node_.next<tab><tab><tab>else:<tab><tab><tab><tab>pre_node.next = node_.next<tab><tab><tab>self._len -= 1<tab><tab>pre_node = node_<tab><tab>node_ = node_.next",if node_ . key == key :,129
1178,"def _recurse(self, base_path, rel_source, rel_zip):<tab>submodules_path = Path(base_path) / ""submodules""<tab>if not submodules_path.is_dir():<tab><tab>return<tab>for submodule in submodules_path.iterdir():<tab><tab>source_path = submodule / rel_source<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>output_path = submodule / rel_zip<tab><tab>self._build_lambdas(source_path, output_path)<tab><tab>self._recurse(submodule, rel_source, rel_zip)",if not source_path . is_dir ( ) :,139
1179,"def find_test_functions(collections):<tab>if not isinstance(collections, list):<tab><tab>collections = [collections]<tab>functions = []<tab>for collection in collections:<tab><tab>if not isinstance(collection, dict):<tab><tab><tab>collection = vars(collection)<tab><tab>keys = collection.keys()<tab><tab>keys.sort()<tab><tab>for key in keys:<tab><tab><tab>value = collection[key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(value)<tab>return functions","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",131
1180,"def __init__(<tab>self,<tab>classifier,<tab>layer_name=None,<tab>transpose=None,<tab>distance=None,<tab>copy_weights=True,):<tab>super().__init__()<tab>self.copy_weights = copy_weights<tab>### set layer weights ###<tab>if layer_name is not None:<tab><tab>self.set_weights(getattr(classifier, layer_name))<tab>else:<tab><tab>for x in self.possible_layer_names:<tab><tab><tab>layer = getattr(classifier, x, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.set_weights(layer)<tab><tab><tab><tab>break<tab>### set distance measure ###<tab>self.distance = classifier.distance if distance is None else distance<tab>self.transpose = transpose",if layer is not None :,183
1181,def multi_dev_generator(self):<tab>for data in self._data_loader():<tab><tab>if len(self._tail_data) < self._base_number:<tab><tab><tab>self._tail_data += data<tab><tab><IF-STMT><tab><tab><tab>yield self._tail_data<tab><tab><tab>self._tail_data = [],if len ( self . _tail_data ) == self . _base_number :,91
1182,"def Resolve(self, updater=None):<tab>if len(self.Conflicts):<tab><tab>for setting, edge in self.Conflicts:<tab><tab><tab>answer = self.AskUser(self.Setting, setting)<tab><tab><tab>if answer == Gtk.ResponseType.YES:<tab><tab><tab><tab>value = setting.Value.split(""|"")<tab><tab><tab><tab>value.remove(edge)<tab><tab><tab><tab>setting.Value = ""|"".join(value)<tab><tab><tab><tab>if updater:<tab><tab><tab><tab><tab>updater.UpdateSetting(setting)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return True",if answer == Gtk . ResponseType . NO :,146
1183,"def _post_process_ttl(zone):<tab>for name in zone:<tab><tab>for record_type in zone[name]:<tab><tab><tab>records = zone[name][record_type]<tab><tab><tab>if isinstance(records, list):<tab><tab><tab><tab>ttl = min([x[""ttl""] for x in records])<tab><tab><tab><tab>for record in records:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>logger.warning(<tab><tab><tab><tab><tab><tab><tab>""Using lowest TTL {} for the record set. Ignoring value {}"".format(<tab><tab><tab><tab><tab><tab><tab><tab>ttl, record[""ttl""]<tab><tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>record[""ttl""] = ttl","if record [ ""ttl"" ] != ttl :",183
1184,"def __init__(self, cmds, env, cleanup=[]):<tab>self.handle = None<tab>self.cmds = cmds<tab>self.env = env<tab>if cleanup:<tab><tab><IF-STMT><tab><tab><tab>cleanup = [cleanup]<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>cleanup = [c for c in cleanup if callable(c)]<tab><tab><tab>except:<tab><tab><tab><tab>cleanup = []<tab>self.cleanup = cleanup",if callable ( cleanup ) :,106
1185,"def _parse_data_of_birth(cls, data_of_birth_string):<tab>if data_of_birth_string:<tab><tab>format = ""%m/%d/%Y""<tab><tab>try:<tab><tab><tab>parsed_date = datetime.datetime.strptime(data_of_birth_string, format)<tab><tab><tab>return parsed_date<tab><tab>except ValueError:<tab><tab><tab># Facebook sometimes provides a partial date format<tab><tab><tab># ie 04/07 (ignore those)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise","if data_of_birth_string . count ( ""/"" ) != 1 :",138
1186,"def process_lib(vars_, coreval):<tab>for d in vars_:<tab><tab>var = d.upper()<tab><tab>if var == ""QTCORE"":<tab><tab><tab>continue<tab><tab>value = env[""LIBPATH_"" + var]<tab><tab>if value:<tab><tab><tab>core = env[coreval]<tab><tab><tab>accu = []<tab><tab><tab>for lib in value:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>accu.append(lib)<tab><tab><tab>env[""LIBPATH_"" + var] = accu",if lib in core :,133
1187,"def throttle_status(server=None):<tab>result = AmonStruct()<tab>result.allow = False<tab>last_check = server.get(""last_check"")<tab>server_check_period = server.get(""check_every"", 60)<tab>if last_check:<tab><tab>period_since_last_check = unix_utc_now() - last_check<tab><tab># Add 15 seconds buffer, for statsd<tab><tab>period_since_last_check = period_since_last_check + 15<tab><tab><IF-STMT><tab><tab><tab>result.allow = True<tab>else:<tab><tab>result.allow = True  # Never checked<tab>return result",if period_since_last_check >= server_check_period :,164
1188,"def fetch_scatter_outputs(self, task):<tab>scatteroutputs = []<tab>for var in task[""body""]:<tab><tab># TODO variable support<tab><tab>if var.startswith(""call""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for output in self.tasks_dictionary[task[""body""][var][""task""]][<tab><tab><tab><tab><tab>""outputs""<tab><tab><tab><tab>]:<tab><tab><tab><tab><tab>scatteroutputs.append(<tab><tab><tab><tab><tab><tab>{""task"": task[""body""][var][""alias""], ""output"": output[0]}<tab><tab><tab><tab><tab>)<tab>return scatteroutputs","if ""outputs"" in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :",152
1189,"def _add_constant_node(self, source_node):<tab>parent_ids = range(len(source_node.in_edges))<tab>for idx in parent_ids:<tab><tab>parent_node = self.tf_graph.get_node(source_node.in_edges[idx])<tab><tab><IF-STMT><tab><tab><tab>self._rename_Const(parent_node)","if parent_node . type == ""Const"" :",96
1190,"def enableCtrls(self):<tab># Check if each ctrl has a requirement or an incompatibility,<tab># look it up, and enable/disable if so<tab>for data in self.storySettingsData:<tab><tab>name = data[""name""]<tab><tab>if name in self.ctrls:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>set = self.getSetting(data[""requires""])<tab><tab><tab><tab>for i in self.ctrls[name]:<tab><tab><tab><tab><tab>i.Enable(set not in [""off"", ""false"", ""0""])","if ""requires"" in data :",133
1191,"def update_realtime(self, stdout="""", stderr="""", delete=False):<tab>wooey_cache = wooey_settings.WOOEY_REALTIME_CACHE<tab>if delete == False and wooey_cache is None:<tab><tab>self.stdout = stdout<tab><tab>self.stderr = stderr<tab><tab>self.save()<tab>elif wooey_cache is not None:<tab><tab>cache = django_cache[wooey_cache]<tab><tab><IF-STMT><tab><tab><tab>cache.delete(self.get_realtime_key())<tab><tab>else:<tab><tab><tab>cache.set(<tab><tab><tab><tab>self.get_realtime_key(),<tab><tab><tab><tab>json.dumps({""stdout"": stdout, ""stderr"": stderr}),<tab><tab><tab>)",if delete :,177
1192,"def _check_for_batch_clashes(xs):<tab>""""""Check that batch names do not overlap with sample names.""""""<tab>names = set([x[""description""] for x in xs])<tab>dups = set([])<tab>for x in xs:<tab><tab>batches = tz.get_in((""metadata"", ""batch""), x)<tab><tab>if batches:<tab><tab><tab>if not isinstance(batches, (list, tuple)):<tab><tab><tab><tab>batches = [batches]<tab><tab><tab>for batch in batches:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dups.add(batch)<tab>if len(dups) > 0:<tab><tab>raise ValueError(<tab><tab><tab>""Batch names must be unique from sample descriptions.\n""<tab><tab><tab>""Clashing batch names: %s"" % sorted(list(dups))<tab><tab>)",if batch in names :,192
1193,"def toggle(self, event=None):<tab>if self.absolute:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 100<tab><tab>if self.split > 20:<tab><tab><tab>self.save = self.split<tab><tab><tab>self.split = 1<tab><tab>else:<tab><tab><tab>self.split = self.save<tab>else:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 0.3<tab><tab><IF-STMT><tab><tab><tab>self.split = self.save<tab><tab>elif self.split < 0.5:<tab><tab><tab>self.split = self.min<tab><tab>else:<tab><tab><tab>self.split = self.max<tab>self.placeChilds()",if self . split <= self . min or self . split >= self . max :,189
1194,"def can_read(self):<tab>if hasattr(self.file, ""__iter__""):<tab><tab>iterator = iter(self.file)<tab><tab>head = next(iterator, None)<tab><tab><IF-STMT><tab><tab><tab>self.repaired = []<tab><tab><tab>return True<tab><tab>if isinstance(head, str):<tab><tab><tab>self.repaired = itertools.chain([head], iterator)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab># We may have mangled a generator at this point, so just abort<tab><tab><tab>raise IOSourceError(<tab><tab><tab><tab>""Could not open source: %r (mode: %r)""<tab><tab><tab><tab>% (self.file, self.options[""mode""])<tab><tab><tab>)<tab>return False",if head is None :,176
1195,"def _print_message_content(self, peer, data):<tab>inheaders = 1<tab>lines = data.splitlines()<tab>for line in lines:<tab><tab># headers first<tab><tab>if inheaders and not line:<tab><tab><tab>peerheader = ""X-Peer: "" + peer[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab># decoded_data=false; make header match other binary output<tab><tab><tab><tab>peerheader = repr(peerheader.encode(""utf-8""))<tab><tab><tab>print(peerheader)<tab><tab><tab>inheaders = 0<tab><tab>if not isinstance(data, str):<tab><tab><tab># Avoid spurious 'str on bytes instance' warning.<tab><tab><tab>line = repr(line)<tab><tab>print(line)","if not isinstance ( data , str ) :",180
1196,"def connect(self):<tab># Makes connection with MySQL server<tab>try:<tab><tab><IF-STMT><tab><tab><tab>connection = pymysql.connect(read_default_file=""/etc/mysql/conf.d/my.cnf"")<tab><tab>else:<tab><tab><tab>connection = pymysql.connect(read_default_file=""~/.my.cnf"")<tab><tab>return connection<tab>except ValueError as e:<tab><tab>Log.debug(self, str(e))<tab><tab>raise MySQLConnectionError<tab>except pymysql.err.InternalError as e:<tab><tab>Log.debug(self, str(e))<tab><tab>raise MySQLConnectionError","if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :",156
1197,"def _copy_package_apps(<tab>local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None:<tab>for src_unresolved in app_paths:<tab><tab>src = src_unresolved.resolve()<tab><tab>app = src.name<tab><tab>dest = Path(local_bin_dir / add_suffix(app, suffix))<tab><tab>if not dest.parent.is_dir():<tab><tab><tab>mkdir(dest.parent)<tab><tab>if dest.exists():<tab><tab><tab>logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"")<tab><tab><tab>dest.unlink()<tab><tab><IF-STMT><tab><tab><tab>shutil.copy(src, dest)",if src . exists ( ) :,177
1198,"def update(self, x, who=None, metadata=None):<tab>self._retain_refs(metadata)<tab>y = self._get_key(x)<tab>if self.keep == ""last"":<tab><tab># remove key if already present so that emitted value<tab><tab># will reflect elements' actual relative ordering<tab><tab>self._buffer.pop(y, None)<tab><tab>self._metadata_buffer.pop(y, None)<tab><tab>self._buffer[y] = x<tab><tab>self._metadata_buffer[y] = metadata<tab>else:  # self.keep == ""first""<tab><tab><IF-STMT><tab><tab><tab>self._buffer[y] = x<tab><tab><tab>self._metadata_buffer[y] = metadata<tab>return self.last",if y not in self . _buffer :,180
1199,"def resolve_credential_keys(m_keys, keys):<tab>res = []<tab>for k in m_keys:<tab><tab>if k[""c7n:match-type""] == ""credential"":<tab><tab><tab>c_date = parse_date(k[""last_rotated""])<tab><tab><tab>for ak in keys:<tab><tab><tab><tab>if c_date == ak[""CreateDate""]:<tab><tab><tab><tab><tab>ak = dict(ak)<tab><tab><tab><tab><tab>ak[""c7n:match-type""] = ""access""<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>res.append(ak)<tab><tab>elif k not in res:<tab><tab><tab>res.append(k)<tab>return res",if ak not in res :,169
1200,"def _apply_flag_attrs(src_flag, dest_flag):<tab># Use a baseline flag def to get default values for empty data.<tab>baseline_flag = FlagDef("""", {}, None)<tab>for name in dir(src_flag):<tab><tab>if name[:1] == ""_"":<tab><tab><tab>continue<tab><tab>dest_val = getattr(dest_flag, name, None)<tab><tab>baseline_val = getattr(baseline_flag, name, None)<tab><tab><IF-STMT><tab><tab><tab>setattr(dest_flag, name, getattr(src_flag, name))",if dest_val == baseline_val :,137
1201,"def _ws_keep_reading(self):<tab>import websockets.exceptions<tab>while not self._reader_stopped:<tab><tab>try:<tab><tab><tab>data = await self._ws.recv()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = data.encode(""UTF-8"")<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>self._error = ""EOF""<tab><tab><tab><tab>break<tab><tab>except websockets.exceptions.ConnectionClosedError:<tab><tab><tab># TODO: try to reconnect in case of Ctrl+D<tab><tab><tab>self._error = ""EOF""<tab><tab><tab>break<tab><tab>self.num_bytes_received += len(data)<tab><tab>self._make_output_available(data, block=False)","if isinstance ( data , str ) :",180
1202,"def to_dict(self) -> Dict[str, Any]:<tab>result = {}<tab>for field_name in self.API_FIELDS:<tab><tab><IF-STMT><tab><tab><tab>result[""stream_id""] = self.id<tab><tab><tab>continue<tab><tab>elif field_name == ""date_created"":<tab><tab><tab>result[""date_created""] = datetime_to_timestamp(self.date_created)<tab><tab><tab>continue<tab><tab>result[field_name] = getattr(self, field_name)<tab>result[""is_announcement_only""] = (<tab><tab>self.stream_post_policy == Stream.STREAM_POST_POLICY_ADMINS<tab>)<tab>return result","if field_name == ""id"" :",164
1203,"def all_masks(<tab>cls,<tab>images,<tab>run,<tab>run_key,<tab>step,):<tab>all_mask_groups = []<tab>for image in images:<tab><tab><IF-STMT><tab><tab><tab>mask_group = {}<tab><tab><tab>for k in image._masks:<tab><tab><tab><tab>mask = image._masks[k]<tab><tab><tab><tab>mask_group[k] = mask.to_json(run)<tab><tab><tab>all_mask_groups.append(mask_group)<tab><tab>else:<tab><tab><tab>all_mask_groups.append(None)<tab>if all_mask_groups and not all(x is None for x in all_mask_groups):<tab><tab>return all_mask_groups<tab>else:<tab><tab>return False",if image . _masks :,183
1204,"def disconnect_all(listener):<tab>""""""Disconnect from all signals""""""<tab>for emitter in listener._signal_data.emitters:<tab><tab>for signal in emitter._signal_data.listeners:<tab><tab><tab>emitter._signal_data.listeners[signal] = [<tab><tab><tab><tab>i<tab><tab><tab><tab>for i in emitter._signal_data.listeners[signal]<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]","if getattr ( i , ""__self__"" , None ) != listener",108
1205,"def wait(self, timeout=None):<tab>if self.returncode is None:<tab><tab>if timeout is None:<tab><tab><tab>msecs = _subprocess.INFINITE<tab><tab>else:<tab><tab><tab>msecs = max(0, int(timeout * 1000 + 0.5))<tab><tab>res = _subprocess.WaitForSingleObject(int(self._handle), msecs)<tab><tab>if res == _subprocess.WAIT_OBJECT_0:<tab><tab><tab>code = _subprocess.GetExitCodeProcess(self._handle)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>code = -signal.SIGTERM<tab><tab><tab>self.returncode = code<tab>return self.returncode",if code == TERMINATE :,154
1206,"def set_pbar_fraction(self, frac, progress, stage=None):<tab>gtk.gdk.threads_enter()<tab>try:<tab><tab>self.is_pulsing = False<tab><tab>self.set_stage_text(stage or _(""Processing...""))<tab><tab>self.pbar.set_text(progress)<tab><tab><IF-STMT><tab><tab><tab>frac = 1.0<tab><tab>if frac < 0:<tab><tab><tab>frac = 0<tab><tab>self.pbar.set_fraction(frac)<tab>finally:<tab><tab>gtk.gdk.threads_leave()",if frac > 1 :,135
1207,"def get_aa_from_codonre(re_aa):<tab>aas = []<tab>m = 0<tab>for i in re_aa:<tab><tab>if i == ""["":<tab><tab><tab>m = -1<tab><tab><tab>aas.append("""")<tab><tab><IF-STMT><tab><tab><tab>m = 0<tab><tab><tab>continue<tab><tab>elif m == -1:<tab><tab><tab>aas[-1] = aas[-1] + i<tab><tab>elif m == 0:<tab><tab><tab>aas.append(i)<tab>return aas","elif i == ""]"" :",129
1208,"def link(token, base_url):<tab>""""""Validation for ``link``.""""""<tab>if get_keyword(token) == ""none"":<tab><tab>return ""none""<tab>parsed_url = get_url(token, base_url)<tab>if parsed_url:<tab><tab>return parsed_url<tab>function = parse_function(token)<tab>if function:<tab><tab>name, args = function<tab><tab>prototype = (name, [a.type for a in args])<tab><tab>args = [getattr(a, ""value"", a) for a in args]<tab><tab><IF-STMT><tab><tab><tab>return (""attr()"", args[0])","if prototype == ( ""attr"" , [ ""ident"" ] ) :",153
1209,"def on_bt_search_clicked(self, widget):<tab>if self.current_provider is None:<tab><tab>return<tab>query = self.en_query.get_text()<tab>@self.obtain_podcasts_with<tab>def load_data():<tab><tab>if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH:<tab><tab><tab>return self.current_provider.on_search(query)<tab><tab><IF-STMT><tab><tab><tab>return self.current_provider.on_url(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_FILE:<tab><tab><tab>return self.current_provider.on_file(query)",elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,172
1210,"def test_handle_single(self):<tab>self.skipTest(<tab><tab>""Pops up windows and needs user input.. so disabled.""<tab><tab>""Still worth keeping whilst we don't have unit tests ""<tab><tab>""for all plugins.""<tab>)<tab># Ignored...<tab>for id_, plugin in self.plugins.items():<tab><tab><IF-STMT><tab><tab><tab>self.h.plugin_enable(plugin, None)<tab><tab><tab>self.h.handle(id_, self.lib, self.parent, SONGS)<tab><tab><tab>self.h.plugin_disable(plugin)",if self . h . plugin_handle ( plugin ) :,144
1211,"def __repr__(self):<tab>attrs = []<tab>for k in self._keydata:<tab><tab><IF-STMT><tab><tab><tab>attrs.append(""p(%d)"" % (self.size() + 1,))<tab><tab>elif hasattr(self, k):<tab><tab><tab>attrs.append(k)<tab>if self.has_private():<tab><tab>attrs.append(""private"")<tab># PY3K: This is meant to be text, do not change to bytes (data)<tab>return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))","if k == ""p"" :",142
1212,"def apply(self, node, code, required):<tab>yield ""try:""<tab>yield from self.iterIndented(code)<tab>yield ""<tab>pass""<tab>yield ""except {}:"".format(self.exceptionString)<tab>outputVariables = node.getOutputSocketVariables()<tab>for i, s in enumerate(node.outputs):<tab><tab><IF-STMT><tab><tab><tab>if hasattr(s, ""getDefaultValueCode""):<tab><tab><tab><tab>yield f""<tab>{outputVariables[s.identifier]} = {s.getDefaultValueCode()}""<tab><tab><tab>else:<tab><tab><tab><tab>yield f""<tab>{outputVariables[s.identifier]} = self.outputs[{i}].getDefaultValue()""<tab>yield ""<tab>pass""",if s . identifier in required :,181
1213,"def __import__(name, globals=None, locals=None, fromlist=(), level=0):<tab>module = orig___import__(name, globals, locals, fromlist, level)<tab>if fromlist and module.__name__ in modules:<tab><tab>if ""*"" in fromlist:<tab><tab><tab>fromlist = list(fromlist)<tab><tab><tab>fromlist.remove(""*"")<tab><tab><tab>fromlist.extend(getattr(module, ""__all__"", []))<tab><tab>for x in fromlist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>from_name = ""{}.{}"".format(module.__name__, x)<tab><tab><tab><tab>if from_name in modules:<tab><tab><tab><tab><tab>importlib.import_module(from_name)<tab>return module","if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :",175
1214,"def _consume_msg(self):<tab>ws = self._ws<tab>try:<tab><tab>while True:<tab><tab><tab>r = await ws.recv()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r = r.decode(""utf-8"")<tab><tab><tab>msg = json.loads(r)<tab><tab><tab>stream = msg.get(""stream"")<tab><tab><tab>if stream is not None:<tab><tab><tab><tab>await self._dispatch(stream, msg)<tab>except websockets.WebSocketException as wse:<tab><tab>logging.warn(wse)<tab><tab>await self.close()<tab><tab>asyncio.ensure_future(self._ensure_ws())","if isinstance ( r , bytes ) :",158
1215,"def add_source(self, source, name=None):<tab>""""""Adds a new data source to an existing provider.""""""<tab>if self.randomize:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Cannot add a non-shuffleable source to an ""<tab><tab><tab><tab>""already shuffled provider.""<tab><tab><tab>)<tab>super().add_source(source, name=name)<tab>if self.randomize is True:<tab><tab>self._shuffle_len = self.entries",if not source . can_shuffle ( ) :,121
1216,"def __str__(self):<tab>buf = [""""]<tab>if self.fileName:<tab><tab>buf.append(self.fileName + "":"")<tab>if self.line != -1:<tab><tab>if not self.fileName:<tab><tab><tab>buf.append(""line "")<tab><tab>buf.append(str(self.line))<tab><tab><IF-STMT><tab><tab><tab>buf.append("":"" + str(self.column))<tab><tab>buf.append("":"")<tab>buf.append("" "")<tab>return str("""").join(buf)",if self . column != - 1 :,124
1217,"def has_bad_headers(self):<tab>headers = [self.sender, self.reply_to] + self.recipients<tab>for header in headers:<tab><tab>if _has_newline(header):<tab><tab><tab>return True<tab>if self.subject:<tab><tab>if _has_newline(self.subject):<tab><tab><tab>for linenum, line in enumerate(self.subject.split(""\r\n"")):<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if linenum > 0 and line[0] not in ""\t "":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if _has_newline(line):<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>return False",if len ( line . strip ( ) ) == 0 :,186
1218,"def scanHexEscape(self, prefix):<tab>code = 0<tab>leng = 4 if (prefix == ""u"") else 2<tab>for i in xrange(leng):<tab><tab><IF-STMT><tab><tab><tab>ch = self.source[self.index]<tab><tab><tab>self.index += 1<tab><tab><tab>code = code * 16 + HEX_CONV[ch]<tab><tab>else:<tab><tab><tab>return """"<tab>return unichr(code)",if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,119
1219,"def _get_table_info(self, table_name):<tab>table_addr = self.addr_space.profile.get_symbol(table_name)<tab>table_size = self._get_table_info_distorm()<tab><IF-STMT><tab><tab>table_size = self._get_table_info_other(table_addr, table_name)<tab><tab>if table_size == 0:<tab><tab><tab>debug.error(""Unable to get system call table size"")<tab>return [table_addr, table_size]",if table_size == 0 :,126
1220,"def format_file_path(filepath):<tab>""""""Formats a path as absolute and with the correct platform separator.""""""<tab>try:<tab><tab>is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN.match(filepath)<tab><tab>filepath = os.path.realpath(os.path.abspath(filepath))<tab><tab>filepath = re.sub(BACKSLASH_REPLACE_PATTERN, ""/"", filepath)<tab><tab>is_windows_drive = WINDOWS_DRIVE_PATTERN.match(filepath)<tab><tab><IF-STMT><tab><tab><tab>filepath = filepath.capitalize()<tab><tab>if is_windows_network_mount:<tab><tab><tab># Add back a / to the front, since the previous modifications<tab><tab><tab># will have replaced any double slashes with single<tab><tab><tab>filepath = ""/"" + filepath<tab>except:<tab><tab>pass<tab>return filepath",if is_windows_drive :,194
1221,"def _match(self, cre, s):<tab># Run compiled regular expression match method on 's'.<tab># Save result, return success.<tab>self.mo = cre.match(s)<tab>if __debug__:<tab><tab><IF-STMT><tab><tab><tab>self._mesg(""\tmatched r'%r' => %r"" % (cre.pattern, self.mo.groups()))<tab>return self.mo is not None",if self . mo is not None and self . debug >= 5 :,108
1222,"def reload_sanitize_allowlist(self, explicit=True):<tab>self.sanitize_allowlist = []<tab>try:<tab><tab>with open(self.sanitize_allowlist_file) as f:<tab><tab><tab>for line in f.readlines():<tab><tab><tab><tab>if not line.startswith(""#""):<tab><tab><tab><tab><tab>self.sanitize_allowlist.append(line.strip())<tab>except OSError:<tab><tab><IF-STMT><tab><tab><tab>log.warning(<tab><tab><tab><tab>""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."",<tab><tab><tab><tab>self.sanitize_allowlist_file,<tab><tab><tab>)",if explicit :,149
1223,"def conj(self):<tab>dtype = self.dtype<tab>if issubclass(self.dtype.type, np.complexfloating):<tab><tab>if not self.flags.forc:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""only contiguous arrays may "" ""be used as arguments to this operation""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>order = ""F""<tab><tab>else:<tab><tab><tab>order = ""C""<tab><tab>result = self._new_like_me(order=order)<tab><tab>func = elementwise.get_conj_kernel(dtype)<tab><tab>func.prepared_async_call(<tab><tab><tab>self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size<tab><tab>)<tab><tab>return result<tab>else:<tab><tab>return self",if self . flags . f_contiguous :,198
1224,"def scan_spec_conf(self, conf):<tab>if ""metadata"" in conf:<tab><tab>if ""annotations"" in conf[""metadata""] and conf[""metadata""].get(""annotations""):<tab><tab><tab>for annotation in conf[""metadata""][""annotations""]:<tab><tab><tab><tab>for key in annotation:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>if (<tab><tab><tab><tab><tab><tab><tab>""docker/default"" in annotation[key]<tab><tab><tab><tab><tab><tab><tab>or ""runtime/default"" in annotation[key]<tab><tab><tab><tab><tab><tab>):<tab><tab><tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED","if ""seccomp.security.alpha.kubernetes.io/defaultProfileName"" in key :",167
1225,"def test_error_through_destructor(self):<tab># Test that the exception state is not modified by a destructor,<tab># even if close() fails.<tab>rawio = self.CloseFailureIO()<tab>with support.catch_unraisable_exception() as cm:<tab><tab>with self.assertRaises(AttributeError):<tab><tab><tab>self.tp(rawio).xyzzy<tab><tab>if not IOBASE_EMITS_UNRAISABLE:<tab><tab><tab>self.assertIsNone(cm.unraisable)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(cm.unraisable.exc_type, OSError)",elif cm . unraisable is not None :,157
1226,"def _dumpf(frame):<tab>if frame is None:<tab><tab>return ""<None>""<tab>else:<tab><tab>addn = ""(with trace!)""<tab><tab><IF-STMT><tab><tab><tab>addn = "" **No Trace Set **""<tab><tab>return ""Frame at %d, file %s, line: %d%s"" % (<tab><tab><tab>id(frame),<tab><tab><tab>frame.f_code.co_filename,<tab><tab><tab>frame.f_lineno,<tab><tab><tab>addn,<tab><tab>)",if frame . f_trace is None :,128
1227,"def containsBadbytes(self, value, bytecount=4):<tab>for b in self.badbytes:<tab><tab>tmp = value<tab><tab><IF-STMT><tab><tab><tab>b = ord(b)<tab><tab>for i in range(bytecount):<tab><tab><tab>if (tmp & 0xFF) == b:<tab><tab><tab><tab>return True<tab><tab><tab>tmp >>= 8<tab>return False",if type ( b ) == str :,95
1228,"def _set_peer_statuses(self):<tab>""""""Set peer statuses.""""""<tab>cutoff = time.time() - STALE_SECS<tab>for peer in self.peers:<tab><tab><IF-STMT><tab><tab><tab>peer.status = PEER_BAD<tab><tab>elif peer.last_good > cutoff:<tab><tab><tab>peer.status = PEER_GOOD<tab><tab>elif peer.last_good:<tab><tab><tab>peer.status = PEER_STALE<tab><tab>else:<tab><tab><tab>peer.status = PEER_NEVER",if peer . bad :,128
1229,"def afterTest(self, test):<tab>try:<tab><tab># If the browser window is still open, close it now.<tab><tab>self.driver.quit()<tab>except AttributeError:<tab><tab>pass<tab>except Exception:<tab><tab>pass<tab>if self.options.headless:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.display.stop()<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",if self . headless_active :,117
1230,"def _written_variables_in_proxy(self, contract):<tab>variables = []<tab>if contract.is_upgradeable:<tab><tab>variables_name_written_in_proxy = self._variable_written_in_proxy()<tab><tab><IF-STMT><tab><tab><tab>variables_in_contract = [<tab><tab><tab><tab>contract.get_state_variable_from_name(v)<tab><tab><tab><tab>for v in variables_name_written_in_proxy<tab><tab><tab>]<tab><tab><tab>variables_in_contract = [v for v in variables_in_contract if v]<tab><tab><tab>variables += variables_in_contract<tab>return list(set(variables))",if variables_name_written_in_proxy :,162
1231,"def _available_symbols(self, scoperef, expr):<tab>cplns = []<tab>found_names = set()<tab>while scoperef:<tab><tab>elem = self._elem_from_scoperef(scoperef)<tab><tab>for child in elem:<tab><tab><tab>name = child.get(""name"", """")<tab><tab><tab>if name.startswith(expr):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>found_names.add(name)<tab><tab><tab><tab><tab>ilk = child.get(""ilk"") or child.tag<tab><tab><tab><tab><tab>cplns.append((ilk, name))<tab><tab>scoperef = self.parent_scoperef_from_scoperef(scoperef)<tab><tab>if not scoperef:<tab><tab><tab>break<tab>return sorted(cplns, key=operator.itemgetter(1))",if name not in found_names :,196
1232,"def get_resource_public_actions(resource_class):<tab>resource_class_members = inspect.getmembers(resource_class)<tab>resource_methods = {}<tab>for name, member in resource_class_members:<tab><tab>if not name.startswith(""_""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not name.startswith(""wait_until""):<tab><tab><tab><tab><tab>if is_resource_action(member):<tab><tab><tab><tab><tab><tab>resource_methods[name] = member<tab>return resource_methods",if not name [ 0 ] . isupper ( ) :,122
1233,def UpdateControlState(self):<tab>active = self.demoModules.GetActiveID()<tab># Update the radio/restore buttons<tab>for moduleID in self.radioButtons:<tab><tab>btn = self.radioButtons[moduleID]<tab><tab><IF-STMT><tab><tab><tab>btn.SetValue(True)<tab><tab>else:<tab><tab><tab>btn.SetValue(False)<tab><tab>if self.demoModules.Exists(moduleID):<tab><tab><tab>btn.Enable(True)<tab><tab><tab>if moduleID == modModified:<tab><tab><tab><tab>self.btnRestore.Enable(True)<tab><tab>else:<tab><tab><tab>btn.Enable(False)<tab><tab><tab>if moduleID == modModified:<tab><tab><tab><tab>self.btnRestore.Enable(False),if moduleID == active :,177
1234,"def test_controlcharacters(self):<tab>for i in range(128):<tab><tab>c = chr(i)<tab><tab>testString = ""string containing %s"" % c<tab><tab>if i >= 32 or c in ""\r\n\t"":<tab><tab><tab># \r, \n and \t are the only legal control chars in XML<tab><tab><tab>data = plistlib.dumps(testString, fmt=plistlib.FMT_XML)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(plistlib.loads(data), testString)<tab><tab>else:<tab><tab><tab>with self.assertRaises(ValueError):<tab><tab><tab><tab>plistlib.dumps(testString, fmt=plistlib.FMT_XML)<tab><tab>plistlib.dumps(testString, fmt=plistlib.FMT_BINARY)","if c != ""\r"" :",188
1235,"def remove_usernames(self, username: SLT[str]) -> None:<tab>with self.__lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""Can't set {self.username_name} in conjunction with (already set) ""<tab><tab><tab><tab>f""{self.chat_id_name}s.""<tab><tab><tab>)<tab><tab>parsed_username = self._parse_username(username)<tab><tab>self._usernames -= parsed_username",if self . _chat_ids :,116
1236,"def get_size(self, shape_info):<tab># The size is the data, that have constant size.<tab>state = np.random.RandomState().get_state()<tab>size = 0<tab>for elem in state:<tab><tab>if isinstance(elem, str):<tab><tab><tab>size += len(elem)<tab><tab>elif isinstance(elem, np.ndarray):<tab><tab><tab>size += elem.size * elem.itemsize<tab><tab><IF-STMT><tab><tab><tab>size += np.dtype(""int"").itemsize<tab><tab>elif isinstance(elem, float):<tab><tab><tab>size += np.dtype(""float"").itemsize<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab>return size","elif isinstance ( elem , int ) :",159
1237,"def before_step(self, step, feed_dict):<tab>if step == 0:<tab><tab>for _type, mem in self.memories.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.gan.session.run(tf.assign(mem[""var""], mem[""source""]))","if ""var"" in mem and ""source"" in mem :",79
1238,"def write(self, *bits):<tab>for bit in bits:<tab><tab>if not self.bytestream:<tab><tab><tab>self.bytestream.append(0)<tab><tab>byte = self.bytestream[self.bytenum]<tab><tab><IF-STMT><tab><tab><tab>if self.bytenum == len(self.bytestream) - 1:<tab><tab><tab><tab>byte = 0<tab><tab><tab><tab>self.bytestream += bytes([byte])<tab><tab><tab>self.bytenum += 1<tab><tab><tab>self.bitnum = 0<tab><tab>mask = 2 ** self.bitnum<tab><tab>if bit:<tab><tab><tab>byte |= mask<tab><tab>else:<tab><tab><tab>byte &= ~mask<tab><tab>self.bytestream[self.bytenum] = byte<tab><tab>self.bitnum += 1",if self . bitnum == 8 :,186
1239,"def _validate_parameter_range(self, value_hp, parameter_range):<tab>""""""Placeholder docstring""""""<tab>for (<tab><tab>parameter_range_key,<tab><tab>parameter_range_value,<tab>) in parameter_range.__dict__.items():<tab><tab>if parameter_range_key == ""scaling_type"":<tab><tab><tab>continue<tab><tab># Categorical ranges<tab><tab><IF-STMT><tab><tab><tab>for categorical_value in parameter_range_value:<tab><tab><tab><tab>value_hp.validate(categorical_value)<tab><tab># Continuous, Integer ranges<tab><tab>else:<tab><tab><tab>value_hp.validate(parameter_range_value)","if isinstance ( parameter_range_value , list ) :",159
1240,"def _trackA(self, tracks):<tab>try:<tab><tab>track, start, end = self.featureA<tab><tab>assert track in tracks<tab><tab>return track<tab>except TypeError:<tab><tab>for track in tracks:<tab><tab><tab>for feature_set in track.get_sets():<tab><tab><tab><tab>if hasattr(feature_set, ""features""):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return track<tab><tab>return None",if self . featureA in feature_set . features . values ( ) :,116
1241,"def walk(directory, path_so_far):<tab>for name in sorted(os.listdir(directory)):<tab><tab>if any(fnmatch(name, pattern) for pattern in basename_ignore):<tab><tab><tab>continue<tab><tab>path = path_so_far + ""/"" + name if path_so_far else name<tab><tab>if any(fnmatch(path, pattern) for pattern in path_ignore):<tab><tab><tab>continue<tab><tab>full_name = os.path.join(directory, name)<tab><tab><IF-STMT><tab><tab><tab>for file_path in walk(full_name, path):<tab><tab><tab><tab>yield file_path<tab><tab>elif os.path.isfile(full_name):<tab><tab><tab>yield path",if os . path . isdir ( full_name ) :,172
1242,"def _poll_ipc_requests(self) -> None:<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>while not self._ipc_requests.empty():<tab><tab><tab>args = self._ipc_requests.get()<tab><tab><tab>try:<tab><tab><tab><tab>for filename in args:<tab><tab><tab><tab><tab>if os.path.isfile(filename):<tab><tab><tab><tab><tab><tab>self.get_editor_notebook().show_file(filename)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>logger.exception(""Problem processing ipc request"", exc_info=e)<tab><tab>self.become_active_window()<tab>finally:<tab><tab>self.after(50, self._poll_ipc_requests)",if self . _ipc_requests . empty ( ) :,180
1243,"def test_read1(self):<tab>self.test_write()<tab>blocks = []<tab>nread = 0<tab>with gzip.GzipFile(self.filename, ""r"") as f:<tab><tab>while True:<tab><tab><tab>d = f.read1()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>blocks.append(d)<tab><tab><tab>nread += len(d)<tab><tab><tab># Check that position was updated correctly (see issue10791).<tab><tab><tab>self.assertEqual(f.tell(), nread)<tab>self.assertEqual(b"""".join(blocks), data1 * 50)",if not d :,146
1244,"def _target_generator(self):<tab>if self._internal_target_generator is None:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>from ....model_zoo.rcnn.rpn.rpn_target import RPNTargetGenerator<tab><tab>self._internal_target_generator = RPNTargetGenerator(<tab><tab><tab>num_sample=self._num_sample,<tab><tab><tab>pos_iou_thresh=self._pos_iou_thresh,<tab><tab><tab>neg_iou_thresh=self._neg_iou_thresh,<tab><tab><tab>pos_ratio=self._pos_ratio,<tab><tab><tab>stds=self._box_norm,<tab><tab><tab>**self._kwargs<tab><tab>)<tab><tab>return self._internal_target_generator<tab>else:<tab><tab>return self._internal_target_generator",if self . _net_none :,191
1245,"def time_left(self):<tab>""""""Return how many seconds are left until the timeout expires""""""<tab>if self.is_non_blocking:<tab><tab>return 0<tab>elif self.is_infinite:<tab><tab>return None<tab>else:<tab><tab>delta = self.target_time - self.TIME()<tab><tab><IF-STMT><tab><tab><tab># clock jumped, recalculate<tab><tab><tab>self.target_time = self.TIME() + self.duration<tab><tab><tab>return self.duration<tab><tab>else:<tab><tab><tab>return max(0, delta)",if delta > self . duration :,132
1246,"def _decorator(cls):<tab>for name, meth in inspect.getmembers(cls, inspect.isroutine):<tab><tab>if name not in cls.__dict__:<tab><tab><tab>continue<tab><tab>if name != ""__init__"":<tab><tab><tab>if not private and name.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>setattr(cls, name, decorator(meth))<tab>return cls",if name in butnot :,99
1247,"def load_vocab(vocab_file: str) -> List:<tab>""""""Loads a vocabulary file into a dictionary.""""""<tab>vocab = collections.OrderedDict()<tab>with io.open(vocab_file, ""r"", encoding=""UTF-8"") as file:<tab><tab>for num, line in enumerate(file):<tab><tab><tab>items = convert_to_unicode(line.strip()).split(""\t"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>token = items[0]<tab><tab><tab>index = items[1] if len(items) == 2 else num<tab><tab><tab>token = token.strip()<tab><tab><tab>vocab[token] = int(index)<tab><tab>return vocab",if len ( items ) > 2 :,164
1248,"def slice_fill(self, slice_):<tab>""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true""<tab>if isinstance(self.indexes, int):<tab><tab>new_slice_ = [0]<tab><tab>offset = 0<tab>else:<tab><tab>new_slice_ = [slice_[0]]<tab><tab>offset = 1<tab>for i in range(1, len(self.nums)):<tab><tab><IF-STMT><tab><tab><tab>new_slice_.append(0)<tab><tab>elif offset < len(slice_):<tab><tab><tab>new_slice_.append(slice_[offset])<tab><tab><tab>offset += 1<tab>new_slice_ += slice_[offset:]<tab>return new_slice_",if self . squeeze_dims [ i ] :,171
1249,"def check_update_function(url, folder, update_setter, version_setter, auto):<tab>remote_version = urllib.urlopen(url).read()<tab>if remote_version.isdigit():<tab><tab>local_version = get_local_timestamp(folder)<tab><tab>if remote_version > local_version:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>update_setter.set_value(True)<tab><tab><tab>version_setter.set_value(remote_version)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return False",if auto :,136
1250,"def iter_content(self, chunk_size_bytes):<tab>while True:<tab><tab>try:<tab><tab><tab>data = self._fp.read(chunk_size_bytes)<tab><tab>except IOError as e:<tab><tab><tab>raise Fetcher.PermanentError(<tab><tab><tab><tab>""Problem reading chunk from {}: {}"".format(self._fp.name, e)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>yield data",if not data :,105
1251,"def gvariant_args(args: List[Any]) -> str:<tab>""""""Convert args into gvariant.""""""<tab>gvariant = """"<tab>for arg in args:<tab><tab>if isinstance(arg, bool):<tab><tab><tab>gvariant += "" {}"".format(str(arg).lower())<tab><tab>elif isinstance(arg, (int, float)):<tab><tab><tab>gvariant += f"" {arg}""<tab><tab><IF-STMT><tab><tab><tab>gvariant += f' ""{arg}""'<tab><tab>else:<tab><tab><tab>gvariant += f"" {arg!s}""<tab>return gvariant.lstrip()","elif isinstance ( arg , str ) :",139
1252,"def _element_keywords(cls, backend, elements=None):<tab>""Returns a dictionary of element names to allowed keywords""<tab>if backend not in Store.loaded_backends():<tab><tab>return {}<tab>mapping = {}<tab>backend_options = Store.options(backend)<tab>elements = elements if elements is not None else backend_options.keys()<tab>for element in elements:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>element = element if isinstance(element, tuple) else (element,)<tab><tab>element_keywords = []<tab><tab>options = backend_options[""."".join(element)]<tab><tab>for group in Options._option_groups:<tab><tab><tab>element_keywords.extend(options[group].allowed_keywords)<tab><tab>mapping[element[0]] = element_keywords<tab>return mapping","if ""."" in element :",185
1253,"def setup_parameter_node(self, param_node):<tab>if param_node.bl_idname == ""SvNumberNode"":<tab><tab>if self.use_prop or self.get_prop_name():<tab><tab><tab>value = self.sv_get()[0][0]<tab><tab><tab>print(""V"", value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>param_node.selected_mode = ""int""<tab><tab><tab><tab>param_node.int_ = value<tab><tab><tab>elif isinstance(value, float):<tab><tab><tab><tab>param_node.selected_mode = ""float""<tab><tab><tab><tab>param_node.float_ = value","if isinstance ( value , int ) :",156
1254,"def _get_oshape(indices_shape, depth, axis):<tab>oshape = []<tab>true_axis = len(indices_shape) if axis == -1 else axis<tab>ndim = len(indices_shape) + 1<tab>indices_index = 0<tab>for i in range(0, ndim):<tab><tab><IF-STMT><tab><tab><tab>oshape.append(depth)<tab><tab>else:<tab><tab><tab>oshape.append(indices_shape[indices_index])<tab><tab><tab>indices_index += 1<tab>return oshape",if i == true_axis :,123
1255,"def check(self, value):<tab>value = String.check(self, value)<tab>if isinstance(value, str):<tab><tab>value = value.upper()<tab><tab>for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]):<tab><tab><tab># e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value[len(prefix) :]<tab><tab><tab>value = value.lstrip(""_"")<tab><tab>if hasattr(self.group, value):<tab><tab><tab>return getattr(self.group, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""No such constant: %s_%s"" % (self.prefix, value))<tab>else:<tab><tab>return value",if value . startswith ( prefix ) :,182
1256,"def shuffle_unison_inplace(list_of_lists, random_state=None):<tab>if list_of_lists:<tab><tab>assert all(len(l) == len(list_of_lists[0]) for l in list_of_lists)<tab><tab><IF-STMT><tab><tab><tab>random_state.permutation(len(list_of_lists[0]))<tab><tab>else:<tab><tab><tab>p = np.random.permutation(len(list_of_lists[0]))<tab><tab>return [l[p] for l in list_of_lists]<tab>return None",if random_state is not None :,139
1257,"def _load_module(self):<tab>spec = self.default_module_spec<tab>module_identifier = self.module_identifier<tab>if module_identifier:<tab><tab>impls = self.get_module_implementation_map()<tab><tab><IF-STMT><tab><tab><tab>raise ModuleNotFound(<tab><tab><tab><tab>""Invalid module identifier %r in %s""<tab><tab><tab><tab>% (module_identifier, force_ascii(repr(self)))<tab><tab><tab>)<tab><tab>spec = impls[module_identifier]<tab>cls = load(<tab><tab>spec, context_explanation=""Loading module for %s"" % force_ascii(repr(self))<tab>)<tab>options = getattr(self, self.module_options_field, None) or {}<tab>return cls(self, options)",if module_identifier not in impls :,185
1258,"def get_data(self, state=None, request=None):<tab>if self.load_in_memory:<tab><tab>data, shapes = self._in_memory_get_data(state, request)<tab>else:<tab><tab>data, shapes = self._out_of_memory_get_data(state, request)<tab>for i in range(len(data)):<tab><tab><IF-STMT><tab><tab><tab>if isinstance(request, numbers.Integral):<tab><tab><tab><tab>data[i] = data[i].reshape(shapes[i])<tab><tab><tab>else:<tab><tab><tab><tab>for j in range(len(data[i])):<tab><tab><tab><tab><tab>data[i][j] = data[i][j].reshape(shapes[i][j])<tab>return tuple(data)",if shapes [ i ] is not None :,187
1259,"def resolve_credential_keys(m_keys, keys):<tab>res = []<tab>for k in m_keys:<tab><tab>if k[""c7n:match-type""] == ""credential"":<tab><tab><tab>c_date = parse_date(k[""last_rotated""])<tab><tab><tab>for ak in keys:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ak = dict(ak)<tab><tab><tab><tab><tab>ak[""c7n:match-type""] = ""access""<tab><tab><tab><tab><tab>if ak not in res:<tab><tab><tab><tab><tab><tab>res.append(ak)<tab><tab>elif k not in res:<tab><tab><tab>res.append(k)<tab>return res","if c_date == ak [ ""CreateDate"" ] :",169
1260,"def _is_legacy_mode(self, node):<tab>""""""Checks if the ``ast.Call`` node's keywords signal using legacy mode.""""""<tab>script_mode = False<tab>py_version = ""py2""<tab>for kw in node.keywords:<tab><tab><IF-STMT><tab><tab><tab>script_mode = (<tab><tab><tab><tab>bool(kw.value.value) if isinstance(kw.value, ast.NameConstant) else True<tab><tab><tab>)<tab><tab>if kw.arg == ""py_version"":<tab><tab><tab>py_version = kw.value.s if isinstance(kw.value, ast.Str) else ""py3""<tab>return not (py_version.startswith(""py3"") or script_mode)","if kw . arg == ""script_mode"" :",173
1261,"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]:<tab>statuses_by_refs = {u: [] for u in upstream}<tab>events = self.events or []  # type: List[V1EventTrigger]<tab>for e in events:<tab><tab>entity_ref = contexts_refs.get_entity_ref(e.ref)<tab><tab>if not entity_ref:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for kind in e.kinds:<tab><tab><tab>status = V1EventKind.events_statuses_mapping.get(kind)<tab><tab><tab>if status:<tab><tab><tab><tab>statuses_by_refs[entity_ref].append(status)<tab>return statuses_by_refs",if entity_ref not in statuses_by_refs :,191
1262,"def items(self):<tab>dict = {}<tab>for userdir in self.XDG_DIRS.keys():<tab><tab>prefix = self.get(userdir).strip('""').split(""/"")[0]<tab><tab><IF-STMT><tab><tab><tab>path = (<tab><tab><tab><tab>os.getenv(""HOME"")<tab><tab><tab><tab>+ ""/""<tab><tab><tab><tab>+ ""/"".join(self.get(userdir).strip('""').split(""/"")[1:])<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>path = self.get(userdir).strip('""')<tab><tab>dict[userdir] = path<tab>return dict.items()",if prefix :,140
1263,"def clean_objects(string, common_attributes):<tab>""""""Return object and attribute lists""""""<tab>string = clean_string(string)<tab>words = string.split()<tab>if len(words) > 1:<tab><tab>prefix_words_are_adj = True<tab><tab>for att in words[:-1]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prefix_words_are_adj = False<tab><tab>if prefix_words_are_adj:<tab><tab><tab>return words[-1:], words[:-1]<tab><tab>else:<tab><tab><tab>return [string], []<tab>else:<tab><tab>return [string], []",if att not in common_attributes :,148
1264,"def extract_custom(extractor, *args, **kw):<tab>for match in extractor(*args, **kw):<tab><tab>msg = match[2]<tab><tab><IF-STMT><tab><tab><tab>unused = (<tab><tab><tab><tab>""<unused singular (hash=%s)>"" % md5(msg[1].encode(""utf8"")).hexdigest()<tab><tab><tab>)<tab><tab><tab>msg = (unused, msg[1], msg[2])<tab><tab><tab>match = (match[0], match[1], msg, match[3])<tab><tab>yield match","if isinstance ( msg , tuple ) and msg [ 0 ] == """" :",136
1265,"def test_convex_decomposition(self):<tab>mesh = g.get_mesh(""quadknot.obj"")<tab>engines = [(""vhacd"", g.trimesh.interfaces.vhacd.exists)]<tab>for engine, exists in engines:<tab><tab><IF-STMT><tab><tab><tab>g.log.warning(""skipping convex decomposition engine %s"", engine)<tab><tab><tab>continue<tab><tab>g.log.info(""Testing convex decomposition with engine %s"", engine)<tab><tab>meshes = mesh.convex_decomposition(engine=engine)<tab><tab>self.assertTrue(len(meshes) > 1)<tab><tab>for m in meshes:<tab><tab><tab>self.assertTrue(m.is_watertight)<tab><tab>g.log.info(""convex decomposition succeeded with %s"", engine)",if not exists :,183
1266,"def _to_string_infix(self, ostream, idx, verbose):<tab>if verbose:<tab><tab>ostream.write("" , "")<tab>else:<tab><tab>hasConst = not (<tab><tab><tab>self._const.__class__ in native_numeric_types and self._const == 0<tab><tab>)<tab><tab>if hasConst:<tab><tab><tab>idx -= 1<tab><tab>_l = self._coef[id(self._args[idx])]<tab><tab>_lt = _l.__class__<tab><tab><IF-STMT><tab><tab><tab>ostream.write("" - "")<tab><tab>else:<tab><tab><tab>ostream.write("" + "")",if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,169
1267,"def get_other(self, data, items):<tab>is_tuple = False<tab>if type(data) == tuple:<tab><tab>data = list(data)<tab><tab>is_tuple = True<tab>if type(data) == list:<tab><tab>m_items = items.copy()<tab><tab>for idx, item in enumerate(items):<tab><tab><tab>if item < 0:<tab><tab><tab><tab>m_items[idx] = len(data) - abs(item)<tab><tab>for i in sorted(set(m_items), reverse=True):<tab><tab><tab>if i < len(data) and i > -1:<tab><tab><tab><tab>del data[i]<tab><tab><IF-STMT><tab><tab><tab>return tuple(data)<tab><tab>else:<tab><tab><tab>return data<tab>else:<tab><tab>return None",if is_tuple :,191
1268,"def process_error(self, data):<tab>if data.get(""error""):<tab><tab><IF-STMT><tab><tab><tab>raise AuthCanceled(self, data.get(""error_description"", """"))<tab><tab>raise AuthFailed(self, data.get(""error_description"") or data[""error""])<tab>elif ""denied"" in data:<tab><tab>raise AuthCanceled(self, data[""denied""])","if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :",103
1269,"def tamper(payload, **kwargs):<tab>junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`""<tab>retval = """"<tab>for i, char in enumerate(payload, start=1):<tab><tab>amount = random.randint(10, 15)<tab><tab>if char == "">"":<tab><tab><tab>retval += "">""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == ""<"":<tab><tab><tab>retval += ""<""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab><IF-STMT><tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>else:<tab><tab><tab>retval += char<tab>return retval","elif char == "" "" :",200
1270,"def retry_http_digest_auth(self, req, auth):<tab>token, challenge = auth.split("" "", 1)<tab>chal = parse_keqv_list(parse_http_list(challenge))<tab>auth = self.get_authorization(req, chal)<tab>if auth:<tab><tab>auth_val = ""Digest %s"" % auth<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>req.add_unredirected_header(self.auth_header, auth_val)<tab><tab>resp = self.parent.open(req)<tab><tab>return resp","if req . headers . get ( self . auth_header , None ) == auth_val :",154
1271,"def close(self):<tab>self.selector.close()<tab>if self.sock:<tab><tab>sockname = None<tab><tab>try:<tab><tab><tab>sockname = self.sock.getsockname()<tab><tab>except (socket.error, OSError):<tab><tab><tab>pass<tab><tab>self.sock.close()<tab><tab>if type(sockname) is str:<tab><tab><tab># it was a Unix domain socket, remove it from the filesystem<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(sockname)<tab>self.sock = None",if os . path . exists ( sockname ) :,128
1272,"def to_nurbs(self, curves):<tab>result = []<tab>for i, c in enumerate(curves):<tab><tab>nurbs = SvNurbsCurve.to_nurbs(c)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(f""Curve #{i} - {c} - can not be converted to NURBS!"")<tab><tab>result.append(nurbs)<tab>return result",if nurbs is None :,102
1273,"def handle_1_roomid_raffle(self, i):<tab>if i[1] in [""handle_1_room_TV"", ""handle_1_room_captain""]:<tab><tab><IF-STMT><tab><tab><tab>await self.notify(""post_watching_history"", i[0])<tab><tab><tab>await self.notify(i[1], i[0], i[2])<tab>else:<tab><tab>print(""hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh"", i)","if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :",144
1274,"def init_ps_var_partition(self):<tab>ps_vars = {}<tab>for v in self._non_embed_vars.values():<tab><tab>if v.name not in self._var_to_ps:<tab><tab><tab>self._var_to_ps[v.name] = string_to_id(v.name, self._ps_num)<tab><tab>ps_id = self._var_to_ps[v.name]<tab><tab><IF-STMT><tab><tab><tab>ps_vars[ps_id] = [v]<tab><tab>else:<tab><tab><tab>ps_vars[ps_id].append(v)<tab>self._ps_vars = ps_vars",if ps_id not in ps_vars :,164
1275,"def get_files(d):<tab>f = []<tab>for root, dirs, files in os.walk(d):<tab><tab>for name in files:<tab><tab><tab>if ""meta-environment"" in root or ""cross-canadian"" in root:<tab><tab><tab><tab>continue<tab><tab><tab>if ""qemux86copy-"" in root or ""qemux86-"" in root:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.append(os.path.join(root, name))<tab>return f","if ""do_build"" not in name and ""do_populate_sdk"" not in name :",143
1276,"def setSelectedLabelState(self, p):  # selected, disabled<tab>c = self.c<tab># g.trace(p,c.edit_widget(p))<tab>if p and c.edit_widget(p):<tab><tab><IF-STMT><tab><tab><tab>g.trace(self.trace_n, c.edit_widget(p), p)<tab><tab><tab># g.trace(g.callers(6))<tab><tab><tab>self.trace_n += 1<tab><tab>self.setDisabledHeadlineColors(p)",if 0 :,122
1277,"def filter_tasks(self, task_types=None, task_states=None, task_text=None):<tab>tasks = self.api.tasks(self.id).get(""tasks"", {})<tab>if tasks and tasks.get(""task""):<tab><tab>return [<tab><tab><tab>Task(self, task)<tab><tab><tab>for task in tasks.get(""task"", [])<tab><tab><tab><IF-STMT><tab><tab><tab>and (not task_states or task[""state""].lower() in task_states)<tab><tab><tab>and (not task_text or task_text.lower() in str(task).lower())<tab><tab>]<tab>else:<tab><tab>return []","if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )",166
1278,"def GenerateVector(self, hits, vector, level):<tab>""""""Generate possible hit vectors which match the rules.""""""<tab>for item in hits.get(level, []):<tab><tab><IF-STMT><tab><tab><tab>if item < vector[-1]:<tab><tab><tab><tab>continue<tab><tab><tab>if item > self.max_separation + vector[-1]:<tab><tab><tab><tab>break<tab><tab>new_vector = vector + [item]<tab><tab>if level + 1 == len(hits):<tab><tab><tab>yield new_vector<tab><tab>elif level + 1 < len(hits):<tab><tab><tab>for result in self.GenerateVector(hits, new_vector, level + 1):<tab><tab><tab><tab>yield result",if vector :,157
1279,def _transmit_from_storage(self) -> None:<tab>for blob in self.storage.gets():<tab><tab># give a few more seconds for blob lease operation<tab><tab># to reduce the chance of race (for perf consideration)<tab><tab>if blob.lease(self._timeout + 5):<tab><tab><tab>envelopes = [TelemetryItem(**x) for x in blob.get()]<tab><tab><tab>result = self._transmit(list(envelopes))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>blob.lease(1)<tab><tab><tab>else:<tab><tab><tab><tab>blob.delete(),if result == ExportResult . FAILED_RETRYABLE :,147
1280,"def load_dictionary(file):<tab>oui = {}<tab>with open(file, ""r"") as f:<tab><tab>for line in f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = line.split(""(hex)"")<tab><tab><tab><tab>key = data[0].replace(""-"", "":"").lower().strip()<tab><tab><tab><tab>company = data[1].strip()<tab><tab><tab><tab>oui[key] = company<tab>return oui","if ""(hex)"" in line :",108
1281,"def _yield_minibatches_idx(self, rgen, n_batches, data_ary, shuffle=True):<tab>indices = np.arange(data_ary.shape[0])<tab>if shuffle:<tab><tab>indices = rgen.permutation(indices)<tab>if n_batches > 1:<tab><tab>remainder = data_ary.shape[0] % n_batches<tab><tab><IF-STMT><tab><tab><tab>minis = np.array_split(indices[:-remainder], n_batches)<tab><tab><tab>minis[-1] = np.concatenate((minis[-1], indices[-remainder:]), axis=0)<tab><tab>else:<tab><tab><tab>minis = np.array_split(indices, n_batches)<tab>else:<tab><tab>minis = (indices,)<tab>for idx_batch in minis:<tab><tab>yield idx_batch",if remainder :,194
1282,"def canonical_custom_headers(self, headers):<tab>hoi = []<tab>custom_headers = {}<tab>for key in headers:<tab><tab>lk = key.lower()<tab><tab>if headers[key] is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>custom_headers[lk] = "","".join(v.strip() for v in headers.get_all(key))<tab>sorted_header_keys = sorted(custom_headers.keys())<tab>for key in sorted_header_keys:<tab><tab>hoi.append(""%s:%s"" % (key, custom_headers[key]))<tab>return ""\n"".join(hoi)","if lk . startswith ( ""x-amz-"" ) :",158
1283,"def validate(self, data):<tab>if not data.get(""reason""):<tab><tab># If reason is not provided, message is required and can not be<tab><tab># null or blank.<tab><tab>message = data.get(""message"")<tab><tab>if not message:<tab><tab><tab>if ""message"" not in data:<tab><tab><tab><tab>msg = serializers.Field.default_error_messages[""required""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = serializers.Field.default_error_messages[""null""]<tab><tab><tab>else:<tab><tab><tab><tab>msg = serializers.CharField.default_error_messages[""blank""]<tab><tab><tab>raise serializers.ValidationError({""message"": [msg]})<tab>return data",elif message is None :,167
1284,def tearDown(self):<tab>try:<tab><tab>os.chdir(self.cwd)<tab><tab><IF-STMT><tab><tab><tab>os.remove(self.pythonexe)<tab><tab>test_support.rmtree(self.parent_dir)<tab>finally:<tab><tab>BaseTestCase.tearDown(self),if self . pythonexe != sys . executable :,77
1285,"def update(self, value, label):<tab>if self._disabled:<tab><tab>return<tab>try:<tab><tab>self._progress.value = value<tab><tab>self._label.value = label<tab><tab><IF-STMT><tab><tab><tab>self._displayed = True<tab><tab><tab>display_widget(self._widget)<tab>except Exception as e:<tab><tab>self._disabled = True<tab><tab>logger.exception(e)<tab><tab>wandb.termwarn(""Unable to render progress bar, see the user log for details"")",if not self . _displayed :,122
1286,"def GetBinaryOperationBinder(self, op):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>return self._binaryOperationBinders[op]<tab><tab>b = runtime.SymplBinaryOperationBinder(op)<tab><tab>self._binaryOperationBinders[op] = b<tab>return b",if self . _binaryOperationBinders . ContainsKey ( op ) :,83
1287,"def apply(self, l, b, evaluation):<tab>""FromDigits[l_, b_]""<tab>if l.get_head_name() == ""System`List"":<tab><tab>value = Integer(0)<tab><tab>for leaf in l.leaves:<tab><tab><tab>value = Expression(""Plus"", Expression(""Times"", value, b), leaf)<tab><tab>return value<tab>elif isinstance(l, String):<tab><tab>value = FromDigits._parse_string(l.get_string_value(), b)<tab><tab><IF-STMT><tab><tab><tab>evaluation.message(""FromDigits"", ""nlst"")<tab><tab>else:<tab><tab><tab>return value<tab>else:<tab><tab>evaluation.message(""FromDigits"", ""nlst"")",if value is None :,163
1288,"def hsconn_sender(self):<tab>while not self.stop_event.is_set():<tab><tab>try:<tab><tab><tab># Block, but timeout, so that we can exit the loop gracefully<tab><tab><tab>request = self.send_queue.get(True, 6.0)<tab><tab><tab>if self.socket is not None:<tab><tab><tab><tab># Socket got closed and set to None in another thread...<tab><tab><tab><tab>self.socket.sendall(request)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.send_queue.task_done()<tab><tab>except queue.Empty:<tab><tab><tab>pass<tab><tab>except OSError:<tab><tab><tab>self.stop_event.set()",if self . send_queue is not None :,168
1289,"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(result, str):<tab><tab><tab>result = result.encode(""ascii"")<tab><tab>if isinstance(expected, str):<tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab>if contains:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True",if eline not in rline :,181
1290,"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for _, m in self.multi_deconv_layers.named_modules():<tab><tab><IF-STMT><tab><tab><tab>normal_init(m, std=0.001)<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>constant_init(m, 1)<tab>for m in self.multi_final_layers.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>normal_init(m, std=0.001, bias=0)","if isinstance ( m , nn . ConvTranspose2d ) :",139
1291,"def filter_rel_attrs(field_name, **rel_attrs):<tab>clean_dict = {}<tab>for k, v in rel_attrs.items():<tab><tab><IF-STMT><tab><tab><tab>splitted_key = k.split(""__"")<tab><tab><tab>key = ""__"".join(splitted_key[1:])<tab><tab><tab>clean_dict[key] = v<tab><tab>else:<tab><tab><tab>clean_dict[k] = v<tab>return clean_dict","if k . startswith ( field_name + ""__"" ) :",114
1292,"def cancel(self):<tab>with self._condition:<tab><tab><IF-STMT><tab><tab><tab>self._squash(<tab><tab><tab><tab>state_root=self._previous_state_hash,<tab><tab><tab><tab>context_ids=[self._previous_context_id],<tab><tab><tab><tab>persist=False,<tab><tab><tab><tab>clean_up=True,<tab><tab><tab>)<tab><tab>self._cancelled = True<tab><tab>self._condition.notify_all()",if not self . _cancelled and not self . _final and self . _previous_context_id :,121
1293,"def _get_level(levels, level_ref):<tab>if level_ref in levels:<tab><tab>return levels.index(level_ref)<tab>if isinstance(level_ref, six.integer_types):<tab><tab><IF-STMT><tab><tab><tab>level_ref += len(levels)<tab><tab>if not (0 <= level_ref < len(levels)):<tab><tab><tab>raise PatsyError(""specified level %r is out of range"" % (level_ref,))<tab><tab>return level_ref<tab>raise PatsyError(""specified level %r not found"" % (level_ref,))",if level_ref < 0 :,138
1294,"def parse_node(self, node, alias_map=None, conv=None):<tab>sql, params, unknown = self._parse(node, alias_map, conv)<tab>if unknown and conv and params:<tab><tab>params = [conv.db_value(i) for i in params]<tab>if isinstance(node, Node):<tab><tab>if node._negated:<tab><tab><tab>sql = ""NOT %s"" % sql<tab><tab><IF-STMT><tab><tab><tab>sql = "" "".join((sql, ""AS"", node._alias))<tab><tab>if node._ordering:<tab><tab><tab>sql = "" "".join((sql, node._ordering))<tab>return sql, params",if node . _alias :,155
1295,"def parse_object_id(_, values):<tab>if values:<tab><tab>for key in values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = values[key]<tab><tab><tab><tab>if len(val) > 10:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>values[key] = utils.ObjectIdSilent(val)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>values[key] = None","if key . endswith ( ""_id"" ) :",108
1296,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_max_rows(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,124
1297,"def has_invalid_cce(yaml_file, product_yaml=None):<tab>rule = yaml.open_and_macro_expand(yaml_file, product_yaml)<tab>if ""identifiers"" in rule and rule[""identifiers""] is not None:<tab><tab>for i_type, i_value in rule[""identifiers""].items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not checks.is_cce_value_valid(""CCE-"" + str(i_value)):<tab><tab><tab><tab><tab>return True<tab>return False","if i_type [ 0 : 3 ] == ""cce"" :",134
1298,"def _generate_table(self, fromdesc, todesc, diffs):<tab>if fromdesc or todesc:<tab><tab>yield (<tab><tab><tab>simple_colorize(fromdesc, ""description""),<tab><tab><tab>simple_colorize(todesc, ""description""),<tab><tab>)<tab>for i, line in enumerate(diffs):<tab><tab>if line is None:<tab><tab><tab># mdiff yields None on separator lines; skip the bogus ones<tab><tab><tab># generated for the first line<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield line",if i > 0 :,170
1299,"def _getPatternTemplate(pattern, key=None):<tab>if key is None:<tab><tab>key = pattern<tab><tab>if ""%"" not in pattern:<tab><tab><tab>key = pattern.upper()<tab>template = DD_patternCache.get(key)<tab>if not template:<tab><tab>if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""):<tab><tab><tab>template = DateEpoch(lineBeginOnly=(key != ""EPOCH""))<tab><tab><IF-STMT><tab><tab><tab>template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False))<tab><tab>else:<tab><tab><tab>template = DatePatternRegex(pattern)<tab>DD_patternCache.set(key, template)<tab>return template","elif key in ( ""TAI64N"" , ""{^LN-BEG}TAI64N"" , ""^TAI64N"" ) :",195
1300,"def ref_max_pooling_2d(x, kernel, stride, ignore_border, pad):<tab>y = []<tab>for xx in x.reshape((-1,) + x.shape[-3:]):<tab><tab><IF-STMT><tab><tab><tab>xx = xx[np.newaxis]<tab><tab>y += [<tab><tab><tab>refs.pooling_2d(xx, ""max"", kernel, stride, pad, ignore_border)[np.newaxis]<tab><tab>]<tab>y = np.vstack(y)<tab>if x.ndim == 2:<tab><tab>y = np.squeeze(y, 1)<tab>return y.reshape(x.shape[:-3] + y.shape[1:])",if xx . ndim == 2 :,160
1301,"def show_topics():<tab>""""""prints all available miscellaneous help topics.""""""<tab>print(_stash.text_color(""Miscellaneous Topics:"", ""yellow""))<tab>for pp in PAGEPATHS:<tab><tab>if not os.path.isdir(pp):<tab><tab><tab>continue<tab><tab>content = os.listdir(pp)<tab><tab>for pn in content:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = pn[: pn.index(""."")]<tab><tab><tab>else:<tab><tab><tab><tab>name = pn<tab><tab><tab>print(name)","if ""."" in pn :",125
1302,"def justify_toggle_auto(self, event=None):<tab>c = self<tab>if c.editCommands.autojustify == 0:<tab><tab>c.editCommands.autojustify = abs(c.config.getInt(""autojustify"") or 0)<tab><tab><IF-STMT><tab><tab><tab>g.es(""Autojustify on, @int autojustify == %s"" % c.editCommands.autojustify)<tab><tab>else:<tab><tab><tab>g.es(""Set @int autojustify in @settings"")<tab>else:<tab><tab>c.editCommands.autojustify = 0<tab><tab>g.es(""Autojustify off"")",if c . editCommands . autojustify :,153
1303,"def render_token_list(self, tokens):<tab>result = []<tab>vars = []<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>result.append(token.contents.replace(""%"", ""%%""))<tab><tab>elif token.token_type == TOKEN_VAR:<tab><tab><tab>result.append(""%%(%s)s"" % token.contents)<tab><tab><tab>vars.append(token.contents)<tab>return """".join(result), vars",if token . token_type == TOKEN_TEXT :,113
1304,"def get_target_dimensions(self):<tab>width, height = self.engine.size<tab>for operation in self.operations:<tab><tab>if operation[""type""] == ""crop"":<tab><tab><tab>width = operation[""right""] - operation[""left""]<tab><tab><tab>height = operation[""bottom""] - operation[""top""]<tab><tab><IF-STMT><tab><tab><tab>width = operation[""width""]<tab><tab><tab>height = operation[""height""]<tab>return (width, height)","if operation [ ""type"" ] == ""resize"" :",112
1305,"def get_eval_matcher(self):<tab>if isinstance(self.data[""match""], str):<tab><tab><IF-STMT><tab><tab><tab>values = [""explicitDeny"", ""implicitDeny""]<tab><tab>else:<tab><tab><tab>values = [""allowed""]<tab><tab>vf = ValueFilter(<tab><tab><tab>{""type"": ""value"", ""key"": ""EvalDecision"", ""value"": values, ""op"": ""in""}<tab><tab>)<tab>else:<tab><tab>vf = ValueFilter(self.data[""match""])<tab>vf.annotate = False<tab>return vf","if self . data [ ""match"" ] == ""denied"" :",140
1306,"def test_training(self):<tab>if not self.model_tester.is_training:<tab><tab>return<tab>config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()<tab>config.return_dict = True<tab>for model_class in self.all_model_classes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>model = model_class(config)<tab><tab>model.to(torch_device)<tab><tab>model.train()<tab><tab>inputs = self._prepare_for_class(inputs_dict, model_class, return_labels=True)<tab><tab>loss = model(**inputs).loss<tab><tab>loss.backward()",if model_class in MODEL_MAPPING . values ( ) :,168
1307,"def prehook(self, emu, op, eip):<tab>if op in self.badops:<tab><tab>emu.stopEmu()<tab><tab>raise v_exc.BadOpBytes(op.va)<tab>if op.mnem in STOS:<tab><tab><IF-STMT><tab><tab><tab>reg = emu.getRegister(envi.archs.i386.REG_EDI)<tab><tab>elif self.arch == ""amd64"":<tab><tab><tab>reg = emu.getRegister(envi.archs.amd64.REG_RDI)<tab><tab>if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None:<tab><tab><tab>self.vw.makePointer(reg, follow=True)","if self . arch == ""i386"" :",186
1308,"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab><IF-STMT><tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab>elif size <= 9:<tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64mime.base64_len(""x"" * size), bsize)",if size == 0 :,160
1309,"def __new__(cls, dependencies):<tab>deps = check.list_param(dependencies, ""dependencies"", of_type=DependencyDefinition)<tab>seen = {}<tab>for dep in deps:<tab><tab>key = dep.solid + "":"" + dep.output<tab><tab><IF-STMT><tab><tab><tab>raise DagsterInvalidDefinitionError(<tab><tab><tab><tab>'Duplicate dependencies on solid ""{dep.solid}"" output ""{dep.output}"" '<tab><tab><tab><tab>""used in the same MultiDependencyDefinition."".format(dep=dep)<tab><tab><tab>)<tab><tab>seen[key] = True<tab>return super(MultiDependencyDefinition, cls).__new__(cls, deps)",if key in seen :,149
1310,"def get_explanation(self, spec):<tab>""""""Expand an explanation.""""""<tab>if spec:<tab><tab>try:<tab><tab><tab>a = self.dns_txt(spec)<tab><tab><tab>if len(a) == 1:<tab><tab><tab><tab>return str(self.expand(to_ascii(a[0]), stripdot=False))<tab><tab>except PermError:<tab><tab><tab># RFC4408 6.2/4 syntax errors cause exp= to be ignored<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise  # but report in harsh mode for record checking tools<tab><tab><tab>pass<tab>elif self.strict > 1:<tab><tab>raise PermError(""Empty domain-spec on exp="")<tab># RFC4408 6.2/4 empty domain spec is ignored<tab># (unless you give precedence to the grammar).<tab>return None",if self . strict > 1 :,200
1311,"def build(self):<tab>if self.args.get(""sle_id""):<tab><tab>self.process_sle_against_current_voucher()<tab>else:<tab><tab>entries_to_fix = self.get_future_entries_to_fix()<tab><tab>i = 0<tab><tab>while i < len(entries_to_fix):<tab><tab><tab>sle = entries_to_fix[i]<tab><tab><tab>i += 1<tab><tab><tab>self.process_sle(sle)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.get_dependent_entries_to_fix(entries_to_fix, sle)<tab>if self.exceptions:<tab><tab>self.raise_exceptions()<tab>self.update_bin()",if sle . dependant_sle_voucher_detail_no :,187
1312,"def ValidateStopLatitude(self, problems):<tab>if self.stop_lat is not None:<tab><tab>value = self.stop_lat<tab><tab>try:<tab><tab><tab>if not isinstance(value, (float, int)):<tab><tab><tab><tab>self.stop_lat = util.FloatStringToFloat(value, problems)<tab><tab>except (ValueError, TypeError):<tab><tab><tab>problems.InvalidValue(""stop_lat"", value)<tab><tab><tab>del self.stop_lat<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>problems.InvalidValue(""stop_lat"", value)",if self . stop_lat > 90 or self . stop_lat < - 90 :,153
1313,"def set(self, obj, **kwargs):<tab>""""""Check for missing event functions and substitute these with""""""<tab>""""""the ignore method""""""<tab>ignore = getattr(self, ""ignore"")<tab>for k, v in kwargs.iteritems():<tab><tab>setattr(self, k, getattr(obj, v))<tab><tab><IF-STMT><tab><tab><tab>for k1 in self.combinations[k]:<tab><tab><tab><tab>if not hasattr(self, k1):<tab><tab><tab><tab><tab>setattr(self, k1, ignore)",if k in self . combinations :,121
1314,"def split(self, duration, include_remainder=True):<tab># Convert seconds to timedelta, if appropriate.<tab>duration = _seconds_or_timedelta(duration)<tab>if duration <= timedelta(seconds=0):<tab><tab>raise ValueError(""cannot call split with a non-positive timedelta"")<tab>start = self.start<tab>while start < self.end:<tab><tab>if start + duration <= self.end:<tab><tab><tab>yield MayaInterval(start, start + duration)<tab><tab><IF-STMT><tab><tab><tab>yield MayaInterval(start, self.end)<tab><tab>start += duration",elif include_remainder :,137
1315,"def get_first_field(layout, clz):<tab>for layout_object in layout.fields:<tab><tab>if issubclass(layout_object.__class__, clz):<tab><tab><tab>return layout_object<tab><tab><IF-STMT><tab><tab><tab>gf = get_first_field(layout_object, clz)<tab><tab><tab>if gf:<tab><tab><tab><tab>return gf","elif hasattr ( layout_object , ""get_field_names"" ) :",94
1316,"def _getPatternTemplate(pattern, key=None):<tab>if key is None:<tab><tab>key = pattern<tab><tab>if ""%"" not in pattern:<tab><tab><tab>key = pattern.upper()<tab>template = DD_patternCache.get(key)<tab>if not template:<tab><tab><IF-STMT><tab><tab><tab>template = DateEpoch(lineBeginOnly=(key != ""EPOCH""))<tab><tab>elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""):<tab><tab><tab>template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False))<tab><tab>else:<tab><tab><tab>template = DatePatternRegex(pattern)<tab>DD_patternCache.set(key, template)<tab>return template","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :",195
1317,"def findOwningViewController(self, object):<tab>while object:<tab><tab><IF-STMT><tab><tab><tab>description = fb.evaluateExpressionValue(object).GetObjectDescription()<tab><tab><tab>print(""Found the owning view controller.\n{}"".format(description))<tab><tab><tab>cmd = 'echo {} | tr -d ""\n"" | pbcopy'.format(object)<tab><tab><tab>os.system(cmd)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>object = self.nextResponder(object)<tab>print(""Could not find an owning view controller"")",if self . isViewController ( object ) :,141
1318,"def __get_file_by_num(self, num, file_list, idx=0):<tab>for element in file_list:<tab><tab>if idx == num:<tab><tab><tab>return element<tab><tab>if element[3] and element[4]:<tab><tab><tab>i = self.__get_file_by_num(num, element[3], idx + 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return i<tab><tab><tab>idx = i<tab><tab>else:<tab><tab><tab>idx += 1<tab>return idx","if not isinstance ( i , int ) :",127
1319,"def promtool(**kwargs):<tab>key = ""prometheus:promtool""<tab>try:<tab><tab>path = pathlib.Path(util.setting(key))<tab>except TypeError:<tab><tab>yield checks.Warning(<tab><tab><tab>""Missing setting for %s in %s "" % (key, settings.PROMGEN_CONFIG_FILE),<tab><tab><tab>id=""promgen.W001"",<tab><tab>)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>yield checks.Warning(""Unable to execute file %s"" % path, id=""promgen.W003"")","if not os . access ( path , os . X_OK ) :",141
1320,"def parse_config(schema, config):<tab>schemaparser = ConfigParser()<tab>schemaparser.readfp(StringIO(schema))<tab>cfgparser = ConfigParser()<tab>cfgparser.readfp(StringIO(config))<tab>result = {}<tab>for section in cfgparser.sections():<tab><tab>result_section = {}<tab><tab>schema = {}<tab><tab><IF-STMT><tab><tab><tab>schema = dict(schemaparser.items(section))<tab><tab>for key, value in cfgparser.items(section):<tab><tab><tab>converter = converters[schema.get(key, ""string"")]<tab><tab><tab>result_section[key] = converter(value)<tab><tab>result[section] = result_section<tab>return result",if section in schemaparser . sections ( ) :,165
1321,"def validate_arguments(args):<tab>if args.num_pss < 1:<tab><tab>print(""Value error: must have ore than one parameter servers."")<tab><tab>exit(1)<tab>if not GPU_IDS:<tab><tab>num_cpus = multiprocessing.cpu_count()<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""Value error: there are %s available CPUs but you are requiring %s.""<tab><tab><tab><tab>% (num_cpus, args.cpu_trainers)<tab><tab><tab>)<tab><tab><tab>exit(1)<tab>if not os.path.isfile(args.file):<tab><tab>print(""Value error: model trainning file does not exist"")<tab><tab>exit(1)",if args . cpu_trainers > num_cpus :,177
1322,"def infer_dataset_impl(path):<tab>if IndexedRawTextDataset.exists(path):<tab><tab>return ""raw""<tab>elif IndexedDataset.exists(path):<tab><tab>with open(index_file_path(path), ""rb"") as f:<tab><tab><tab>magic = f.read(8)<tab><tab><tab>if magic == IndexedDataset._HDR_MAGIC:<tab><tab><tab><tab>return ""cached""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""mmap""<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab>elif FastaDataset.exists(path):<tab><tab>return ""fasta""<tab>else:<tab><tab>return None",elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,167
1323,"def _add_resource_group(obj):<tab>if isinstance(obj, list):<tab><tab>for array_item in obj:<tab><tab><tab>_add_resource_group(array_item)<tab>elif isinstance(obj, dict):<tab><tab>try:<tab><tab><tab>if ""resourcegroup"" not in [x.lower() for x in obj.keys()]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""]<tab><tab>except (KeyError, IndexError, TypeError):<tab><tab><tab>pass<tab><tab>for item_key in obj:<tab><tab><tab>if item_key != ""sourceVault"":<tab><tab><tab><tab>_add_resource_group(obj[item_key])","if obj [ ""id"" ] :",175
1324,"def reformatBody(self, event=None):<tab>""""""Reformat all paragraphs in the body.""""""<tab>c, p = self, self.p<tab>undoType = ""reformat-body""<tab>w = c.frame.body.wrapper<tab>c.undoer.beforeChangeGroup(p, undoType)<tab>w.setInsertPoint(0)<tab>while 1:<tab><tab>progress = w.getInsertPoint()<tab><tab>c.reformatParagraph(event, undoType=undoType)<tab><tab>ins = w.getInsertPoint()<tab><tab>s = w.getAllText()<tab><tab>w.setInsertPoint(ins)<tab><tab><IF-STMT><tab><tab><tab>break<tab>c.undoer.afterChangeGroup(p, undoType)",if ins <= progress or ins >= len ( s ) :,181
1325,"def make_sources(project: RootDependency) -> str:<tab>content = []<tab>if project.readme:<tab><tab>content.append(project.readme.path.name)<tab><tab><IF-STMT><tab><tab><tab>content.append(project.readme.to_rst().path.name)<tab>path = project.package.path<tab>for fname in (""setup.cfg"", ""setup.py""):<tab><tab>if (path / fname).exists():<tab><tab><tab>content.append(fname)<tab>for package in chain(project.package.packages, project.package.data):<tab><tab>for fpath in package:<tab><tab><tab>fpath = fpath.relative_to(project.package.path)<tab><tab><tab>content.append(""/"".join(fpath.parts))<tab>return ""\n"".join(content)","if project . readme . markup != ""rst"" :",193
1326,"def __init__(self, response):<tab>error = ""{} {}"".format(response.status_code, response.reason)<tab>extra = []<tab>try:<tab><tab>response_json = response.json()<tab><tab><IF-STMT><tab><tab><tab>error = "" "".join(error[""message""] for error in response_json[""error_list""])<tab><tab><tab>extra = [<tab><tab><tab><tab>error[""extra""]<tab><tab><tab><tab>for error in response_json[""error_list""]<tab><tab><tab><tab>if ""extra"" in error<tab><tab><tab>]<tab>except JSONDecodeError:<tab><tab>pass<tab>super().__init__(response=response, error=error, extra=extra)","if ""error_list"" in response_json :",161
1327,"def handle_event(self, fileno=None, events=None):<tab>if self._state == RUN:<tab><tab><IF-STMT><tab><tab><tab>self._it = self._process_result(0)  # non-blocking<tab><tab>try:<tab><tab><tab>next(self._it)<tab><tab>except (StopIteration, CoroStop):<tab><tab><tab>self._it = None",if self . _it is None :,92
1328,"def find_query(self, needle, haystack):<tab>try:<tab><tab>import pinyin<tab><tab>haystack_py = pinyin.get_initial(haystack, """")<tab><tab>needle_len = len(needle)<tab><tab>start = 0<tab><tab>result = []<tab><tab>while True:<tab><tab><tab>found = haystack_py.find(needle, start)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>result.append((found, needle_len))<tab><tab><tab>start = found + needle_len<tab><tab>return result<tab>except:<tab><tab>return None",if found < 0 :,136
1329,"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if ""Last-Modified"" not in rv.headers:<tab><tab>try:<tab><tab><tab>result = date<tab><tab><tab>if callable(result):<tab><tab><tab><tab>result = result(rv)<tab><tab><tab>if not isinstance(result, basestring):<tab><tab><tab><tab>from werkzeug.http import http_date<tab><tab><tab><tab>result = http_date(result)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.headers[""Last-Modified""] = result<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the lastmodified value for response {!r}"".format(<tab><tab><tab><tab><tab>rv<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return rv",if result :,189
1330,"def check_require(require_modules, require_lines):<tab>for require_module in require_modules:<tab><tab>st = try_import(require_module)<tab><tab>if st == 0:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""installed {}: {}\n"".format(<tab><tab><tab><tab><tab>require_module, require_lines[require_module]<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>elif st == 2:<tab><tab><tab>print(<tab><tab><tab><tab>""failed installed {}: {}\n"".format(<tab><tab><tab><tab><tab>require_module, require_lines[require_module]<tab><tab><tab><tab>)<tab><tab><tab>)",elif st == 1 :,164
1331,"def bundle_directory(self, dirpath):<tab>""""""Bundle all modules/packages in the given directory.""""""<tab>dirpath = os.path.abspath(dirpath)<tab>for nm in os.listdir(dirpath):<tab><tab>nm = _u(nm)<tab><tab>if nm.startswith("".""):<tab><tab><tab>continue<tab><tab>itempath = os.path.join(dirpath, nm)<tab><tab>if os.path.isdir(itempath):<tab><tab><tab>if os.path.exists(os.path.join(itempath, ""__init__.py"")):<tab><tab><tab><tab>self.bundle_package(itempath)<tab><tab><IF-STMT><tab><tab><tab>self.bundle_module(itempath)","elif nm . endswith ( "".py"" ) :",160
1332,"def _find_root():<tab>test_dirs = [""Src"", ""Build"", ""Package"", ""Tests"", ""Util""]<tab>root = os.getcwd()<tab>test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs])<tab>while not test:<tab><tab>last_root = root<tab><tab>root = os.path.dirname(root)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Root not found"")<tab><tab>test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs])<tab>return root",if root == last_root :,148
1333,"def findMarkForUnitTestNodes(self):<tab>""""""return the position of *all* non-ignored @mark-for-unit-test nodes.""""""<tab>c = self.c<tab>p, result, seen = c.rootPosition(), [], []<tab>while p:<tab><tab>if p.v in seen:<tab><tab><tab>p.moveToNodeAfterTree()<tab><tab>else:<tab><tab><tab>seen.append(p.v)<tab><tab><tab>if g.match_word(p.h, 0, ""@ignore""):<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(p.copy())<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab>else:<tab><tab><tab><tab>p.moveToThreadNext()<tab>return result","elif p . h . startswith ( ""@mark-for-unit-tests"" ) :",200
1334,"def startTagFrameset(self, token):<tab>self.parser.parseError(""unexpected-start-tag"", {""name"": ""frameset""})<tab>if len(self.tree.openElements) == 1 or self.tree.openElements[1].name != ""body"":<tab><tab>assert self.parser.innerHTML<tab>elif not self.parser.framesetOK:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.tree.openElements[1].parent.removeChild(self.tree.openElements[1])<tab><tab>while self.tree.openElements[-1].name != ""html"":<tab><tab><tab>self.tree.openElements.pop()<tab><tab>self.tree.insertElement(token)<tab><tab>self.parser.phase = self.parser.phases[""inFrameset""]",if self . tree . openElements [ 1 ] . parent :,193
1335,"def try_split(self, split_text: List[str]):<tab>ret = []<tab>for i in split_text:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>val = int(i, 2)<tab><tab>if val > 255 or val < 0:<tab><tab><tab>return None<tab><tab>ret.append(val)<tab>if len(ret) != 0:<tab><tab>ret = bytes(ret)<tab><tab>logger.debug(f""binary successful, returning {ret.__repr__()}"")<tab><tab>return ret",if len ( i ) == 0 :,127
1336,"def generator(self, data):<tab>for sock in data:<tab><tab><IF-STMT><tab><tab><tab>offset = sock.obj_offset<tab><tab>else:<tab><tab><tab>offset = sock.obj_vm.vtop(sock.obj_offset)<tab><tab>yield (<tab><tab><tab>0,<tab><tab><tab>[<tab><tab><tab><tab>Address(offset),<tab><tab><tab><tab>int(sock.Pid),<tab><tab><tab><tab>int(sock.LocalPort),<tab><tab><tab><tab>int(sock.Protocol),<tab><tab><tab><tab>str(protos.protos.get(sock.Protocol.v(), ""-"")),<tab><tab><tab><tab>str(sock.LocalIpAddress),<tab><tab><tab><tab>str(sock.CreateTime),<tab><tab><tab>],<tab><tab>)",if not self . _config . PHYSICAL_OFFSET :,181
1337,"def __init__(self, num_bits=4, always_apply=False, p=0.5):<tab>super(Posterize, self).__init__(always_apply, p)<tab>if isinstance(num_bits, (list, tuple)):<tab><tab><IF-STMT><tab><tab><tab>self.num_bits = [to_tuple(i, 0) for i in num_bits]<tab><tab>else:<tab><tab><tab>self.num_bits = to_tuple(num_bits, 0)<tab>else:<tab><tab>self.num_bits = to_tuple(num_bits, num_bits)",if len ( num_bits ) == 3 :,146
1338,"def tearDown(self):<tab>""""""Just in case yn00 creates some junk files, do a clean-up.""""""<tab>del_files = [self.out_file, ""2YN.dN"", ""2YN.dS"", ""2YN.t"", ""rst"", ""rst1"", ""rub""]<tab>for filename in del_files:<tab><tab><IF-STMT><tab><tab><tab>os.remove(filename)<tab>if os.path.exists(self.working_dir):<tab><tab>for filename in os.listdir(self.working_dir):<tab><tab><tab>filepath = os.path.join(self.working_dir, filename)<tab><tab><tab>os.remove(filepath)<tab><tab>os.rmdir(self.working_dir)",if os . path . exists ( filename ) :,179
1339,"def reverse_search_history(self, searchfor, startpos=None):<tab>if startpos is None:<tab><tab>startpos = self.history_cursor<tab>if _ignore_leading_spaces:<tab><tab>res = [<tab><tab><tab>(idx, line.lstrip())<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab><IF-STMT><tab><tab>]<tab>else:<tab><tab>res = [<tab><tab><tab>(idx, line)<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab>if line.startswith(searchfor)<tab><tab>]<tab>if res:<tab><tab>self.history_cursor -= res[0][0]<tab><tab>return res[0][1].get_line_text()<tab>return """"",if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),198
1340,"def ComboBoxDroppedHeightTest(windows):<tab>""Check if each combobox height is the same as the reference""<tab>bugs = []<tab>for win in windows:<tab><tab>if not win.ref:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if win.DroppedRect().height() != win.ref.DroppedRect().height():<tab><tab><tab>bugs.append(<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>win,<tab><tab><tab><tab><tab>],<tab><tab><tab><tab><tab>{},<tab><tab><tab><tab><tab>testname,<tab><tab><tab><tab><tab>0,<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return bugs","if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :",181
1341,"def get_changed(self):<tab>if self._is_expression():<tab><tab>result = self._get_node_text(self.ast)<tab><tab>if result == self.source:<tab><tab><tab>return None<tab><tab>return result<tab>else:<tab><tab>collector = codeanalyze.ChangeCollector(self.source)<tab><tab>last_end = -1<tab><tab>for match in self.matches:<tab><tab><tab>start, end = match.get_region()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not self._is_expression():<tab><tab><tab><tab><tab>continue<tab><tab><tab>last_end = end<tab><tab><tab>replacement = self._get_matched_text(match)<tab><tab><tab>collector.add_change(start, end, replacement)<tab><tab>return collector.get_changed()",if start < last_end :,189
1342,"def unpickle_from_file(file_path, gzip=False):<tab>""""""Unpickle obj from file_path with gzipping.""""""<tab>with tf.io.gfile.GFile(file_path, ""rb"") as f:<tab><tab><IF-STMT><tab><tab><tab>obj = pickle.load(f)<tab><tab>else:<tab><tab><tab>with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:<tab><tab><tab><tab>obj = pickle.load(gzipf)<tab>return obj",if not gzip :,116
1343,"def get_user_context(request, escape=False):<tab>if isinstance(request, HttpRequest):<tab><tab>user = getattr(request, ""user"", None)<tab><tab>result = {""ip_address"": request.META[""REMOTE_ADDR""]}<tab><tab>if user and user.is_authenticated():<tab><tab><tab>result.update(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""email"": user.email,<tab><tab><tab><tab><tab>""id"": user.id,<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[""name""] = user.name<tab>else:<tab><tab>result = {}<tab>return mark_safe(json.dumps(result))",if user . name :,163
1344,"def get_item_address(self, item):<tab>""""""Get an item's address as a collection of names""""""<tab>result = []<tab>while True:<tab><tab>name = self.tree_ctrl.GetItemPyData(item)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>result.insert(0, name)<tab><tab><tab>item = self.tree_ctrl.GetItemParent(item)<tab>return result",if name is None :,104
1345,"def closest_unseen(self, row1, col1, filter=None):<tab># find the closest unseen from this row/col<tab>min_dist = maxint<tab>closest_unseen = None<tab>for row in range(self.height):<tab><tab>for col in range(self.width):<tab><tab><tab>if filter is None or (row, col) not in filter:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dist = self.distance(row1, col1, row, col)<tab><tab><tab><tab><tab>if dist < min_dist:<tab><tab><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab><tab><tab>closest_unseen = (row, col)<tab>return closest_unseen",if self . map [ row ] [ col ] == UNSEEN :,174
1346,"def log_graph(self, model: LightningModule, input_array=None):<tab>if self._log_graph:<tab><tab><IF-STMT><tab><tab><tab>input_array = model.example_input_array<tab><tab>if input_array is not None:<tab><tab><tab>input_array = model._apply_batch_transfer_handler(input_array)<tab><tab><tab>self.experiment.add_graph(model, input_array)<tab><tab>else:<tab><tab><tab>rank_zero_warn(<tab><tab><tab><tab>""Could not log computational graph since the""<tab><tab><tab><tab>"" `model.example_input_array` attribute is not set""<tab><tab><tab><tab>"" or `input_array` was not given"",<tab><tab><tab><tab>UserWarning,<tab><tab><tab>)",if input_array is None :,182
1347,"def get_scene_exceptions_by_season(self, season=-1):<tab>scene_exceptions = []<tab>for scene_exception in self.scene_exceptions:<tab><tab>if not len(scene_exception) == 2:<tab><tab><tab>continue<tab><tab>scene_name, scene_season = scene_exception.split(""|"")<tab><tab><IF-STMT><tab><tab><tab>scene_exceptions.append(scene_name)<tab>return scene_exceptions",if season == scene_season :,121
1348,def _clean_temp_files():<tab>for pattern in _temp_files:<tab><tab>for path in glob.glob(pattern):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(path)<tab><tab><tab>else:<tab><tab><tab><tab>shutil.rmtree(path),if os . path . islink ( path ) or os . path . isfile ( path ) :,81
1349,"def wait_for_completion(self, job_id, offset, max_results, start_time, timeout):<tab>""""""Wait for job completion and return the first page.""""""<tab>while True:<tab><tab>result = self.get_query_results(<tab><tab><tab>job_id=job_id, page_token=None, start_index=offset, max_results=max_results<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return result<tab><tab>if (time.time() - start_time) > timeout:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Timeout: the query doesn't finish within %d seconds."" % timeout<tab><tab><tab>)<tab><tab>time.sleep(1)","if result [ ""jobComplete"" ] :",165
1350,"def get_data(self, element, ranges, style):<tab><IF-STMT><tab><tab>groups = element.groupby(element.kdims).items()<tab>else:<tab><tab>groups = [(element.label, element)]<tab>plots = []<tab>axis = ""x"" if self.invert_axes else ""y""<tab>for key, group in groups:<tab><tab>if element.kdims:<tab><tab><tab>label = "","".join([d.pprint_value(v) for d, v in zip(element.kdims, key)])<tab><tab>else:<tab><tab><tab>label = key<tab><tab>data = {axis: group.dimension_values(group.vdims[0]), ""name"": label}<tab><tab>plots.append(data)<tab>return plots",if element . kdims :,176
1351,"def get_files(self, dirname):<tab>if not self._data.has_key(dirname):<tab><tab>self._create(dirname)<tab>else:<tab><tab>new_time = self._changed(dirname)<tab><tab><IF-STMT><tab><tab><tab>self._update(dirname, new_time)<tab><tab><tab>dcLog.debug(""==> "" + ""\t\n"".join(self._data[dirname][""flist""]))<tab>return self._data[dirname][""flist""]",if new_time :,112
1352,"def __init__(self, dir):<tab>self.module_names = set()<tab>for name in os.listdir(dir):<tab><tab><IF-STMT><tab><tab><tab>self.module_names.add(name[:-3])<tab><tab>elif ""."" not in name:<tab><tab><tab>self.module_names.add(name)","if name . endswith ( "".py"" ) :",79
1353,"def logic():<tab>for i in range(100):<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>count.next = (count + 1) % n<tab>raise StopSimulation",if reset == ACTIVE_LOW :,81
1354,"def sortkeypicker(keynames):<tab>negate = set()<tab>for i, k in enumerate(keynames):<tab><tab>if k[:1] == ""-"":<tab><tab><tab>keynames[i] = k[1:]<tab><tab><tab>negate.add(k[1:])<tab>def getit(adict):<tab><tab>composite = [adict[k] for k in keynames]<tab><tab>for i, (k, v) in enumerate(zip(keynames, composite)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>composite[i] = -v<tab><tab>return composite<tab>return getit",if k in negate :,140
1355,"def show_image(self, wnd_name, img):<tab>if wnd_name in self.named_windows:<tab><tab><IF-STMT><tab><tab><tab>self.named_windows[wnd_name] = 1<tab><tab><tab>self.on_create_window(wnd_name)<tab><tab><tab>if wnd_name in self.capture_mouse_windows:<tab><tab><tab><tab>self.capture_mouse(wnd_name)<tab><tab>self.on_show_image(wnd_name, img)<tab>else:<tab><tab>print(""show_image: named_window "", wnd_name, "" not found."")",if self . named_windows [ wnd_name ] == 0 :,159
1356,"def check_action_permitted(self):<tab>if (<tab><tab>self._action == ""sts:GetCallerIdentity""<tab>):  # always allowed, even if there's an explicit Deny for it<tab><tab>return True<tab>policies = self._access_key.collect_policies()<tab>permitted = False<tab>for policy in policies:<tab><tab>iam_policy = IAMPolicy(policy)<tab><tab>permission_result = iam_policy.is_action_permitted(self._action)<tab><tab>if permission_result == PermissionResult.DENIED:<tab><tab><tab>self._raise_access_denied()<tab><tab><IF-STMT><tab><tab><tab>permitted = True<tab>if not permitted:<tab><tab>self._raise_access_denied()",elif permission_result == PermissionResult . PERMITTED :,184
1357,"def _limit_value(key, value, config):<tab>if config[key].get(""upper_limit""):<tab><tab>limit = config[key][""upper_limit""]<tab><tab># auto handle datetime<tab><tab>if isinstance(value, datetime) and isinstance(limit, timedelta):<tab><tab><tab>if config[key][""inverse""] is True:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value = datetime.now() - limit<tab><tab><tab>else:<tab><tab><tab><tab>if (datetime.now() + limit) < value:<tab><tab><tab><tab><tab>value = datetime.now() + limit<tab><tab>elif value > limit:<tab><tab><tab>value = limit<tab>return value",if ( datetime . now ( ) - limit ) > value :,164
1358,"def replace_dataset_ids(path, key, value):<tab>""""""Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job.""""""<tab>current_case = input_values<tab>if key == ""id"":<tab><tab>for i, p in enumerate(path):<tab><tab><tab>if isinstance(current_case, (list, dict)):<tab><tab><tab><tab>current_case = current_case[p]<tab><tab><IF-STMT><tab><tab><tab>return key, translate_values.get(current_case[""id""], value)<tab>return key, value","if src == current_case . get ( ""src"" ) :",148
1359,"def load_ext(name, funcs):<tab>ExtModule = namedtuple(""ExtModule"", funcs)<tab>ext_list = []<tab>lib_root = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))<tab>for fun in funcs:<tab><tab><IF-STMT><tab><tab><tab>ext_list.append(extension.load(fun, name, lib_dir=lib_root).op)<tab><tab>else:<tab><tab><tab>ext_list.append(extension.load(fun, name, lib_dir=lib_root).op_)<tab>return ExtModule(*ext_list)","if fun in [ ""nms"" , ""softnms"" ] :",146
1360,"def execute_action(self):<tab>selected_actions = self.model_action.get_selected_results_with_index()<tab>if selected_actions and self.args_for_action:<tab><tab>for name, _, act_idx in selected_actions:<tab><tab><tab>try:<tab><tab><tab><tab>action = self.actions[act_idx]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>action.act([arg for arg, _, _ in self.args_for_action], self)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>debug.log(""execute_action"", e)",if action :,140
1361,"def __getattr__(self, attr):<tab>proxy = self.__proxy<tab>if proxy and hasattr(proxy, attr):<tab><tab>return getattr(proxy, attr)<tab>attrmap = self.__attrmap<tab>if attr in attrmap:<tab><tab>source = attrmap[attr]<tab><tab><IF-STMT><tab><tab><tab>value = source()<tab><tab>else:<tab><tab><tab>value = _import_object(source)<tab><tab>setattr(self, attr, value)<tab><tab>self.__log.debug(""loaded lazy attr %r: %r"", attr, value)<tab><tab>return value<tab>raise AttributeError(""'module' object has no attribute '%s'"" % (attr,))",if callable ( source ) :,154
1362,"def forward(self, x):<tab># BxT -> BxCxT<tab>x = x.unsqueeze(1)<tab>for conv in self.conv_layers:<tab><tab>residual = x<tab><tab>x = conv(x)<tab><tab><IF-STMT><tab><tab><tab>tsz = x.size(2)<tab><tab><tab>r_tsz = residual.size(2)<tab><tab><tab>residual = residual[..., :: r_tsz // tsz][..., :tsz]<tab><tab><tab>x = (x + residual) * self.residual_scale<tab>if self.log_compression:<tab><tab>x = x.abs()<tab><tab>x = x + 1<tab><tab>x = x.log()<tab>return x",if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,186
1363,"def __Prefix_Step2a(self, token):<tab>for prefix in self.__prefix_step2a:<tab><tab><IF-STMT><tab><tab><tab>token = token[len(prefix) :]<tab><tab><tab>self.prefix_step2a_success = True<tab><tab><tab>break<tab>return token",if token . startswith ( prefix ) and len ( token ) > 5 :,81
1364,"def is_valid(sample):<tab>if sample is None:<tab><tab>return False<tab>if isinstance(sample, tuple):<tab><tab>for s in sample:<tab><tab><tab>if s is None:<tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, np.ndarray) and s.size == 0:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return True","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :",114
1365,"def get_all_comments(self, gallery_id, post_no, comment_cnt):<tab>comment_page_cnt = (comment_cnt - 1) // self.options.comments_per_page + 1<tab>comments = []<tab>headers = {""X-Requested-With"": ""XMLHttpRequest""}<tab>data = {""ci_t"": self._session.cookies[""ci_c""], ""id"": gallery_id, ""no"": post_no}<tab>for i in range(comment_page_cnt):<tab><tab>data[""comment_page""] = i + 1<tab><tab>response = self.request_comment(headers, data)<tab><tab>batch = self.parse_comments(response.text)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>comments = batch + comments<tab>return comments",if not batch :,187
1366,def run_on_module(self):<tab>try:<tab><tab>self.module_base.disable(self.opts.module_spec)<tab>except dnf.exceptions.MarkingErrors as e:<tab><tab><IF-STMT><tab><tab><tab>if e.no_match_group_specs or e.error_group_specs:<tab><tab><tab><tab>raise e<tab><tab><tab>if (<tab><tab><tab><tab>e.module_depsolv_errors<tab><tab><tab><tab>and e.module_depsolv_errors[1]<tab><tab><tab><tab>!= libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS<tab><tab><tab>):<tab><tab><tab><tab>raise e<tab><tab>logger.error(str(e)),if self . base . conf . strict :,174
1367,"def find_field_notnull_differ(self, meta, table_description, table_name):<tab>if not self.can_detect_notnull_differ:<tab><tab>return<tab>for field in all_local_fields(meta):<tab><tab>attname = field.db_column or field.attname<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>null = self.get_field_db_nullable(field, table_name)<tab><tab>if field.null != null:<tab><tab><tab>action = field.null and ""DROP"" or ""SET""<tab><tab><tab>self.add_difference(""notnull-differ"", table_name, attname, action)","if ( table_name , attname ) in self . new_db_fields :",167
1368,"def _change_moving_module(self, changes, dest):<tab>if not self.source.is_folder():<tab><tab>pymodule = self.pycore.resource_to_pyobject(self.source)<tab><tab>source = self.import_tools.relatives_to_absolutes(pymodule)<tab><tab>pymodule = self.tools.new_pymodule(pymodule, source)<tab><tab>source = self._change_occurrences_in_module(dest, pymodule)<tab><tab>source = self.tools.new_source(pymodule, source)<tab><tab><IF-STMT><tab><tab><tab>changes.add_change(ChangeContents(self.source, source))",if source != self . source . read ( ) :,155
1369,"def get(quality_name):<tab>""""""Returns a quality object based on canonical quality name.""""""<tab>found_components = {}<tab>for part in quality_name.lower().split():<tab><tab>component = _registry.get(part)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""`%s` is not a valid quality string"" % part)<tab><tab>if component.type in found_components:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""`%s` cannot be defined twice in a quality"" % component.type<tab><tab><tab>)<tab><tab>found_components[component.type] = component<tab>if not found_components:<tab><tab>raise ValueError(""No quality specified"")<tab>result = Quality()<tab>for type, component in found_components.items():<tab><tab>setattr(result, type, component)<tab>return result",if not component :,191
1370,def _unselected(self):<tab>selected = self._selected<tab>k = 0<tab>z = selected[k]<tab>k += 1<tab>for i in range(self._n):<tab><tab>if i == z:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>z = selected[k]<tab><tab><tab><tab>k += 1<tab><tab><tab>else:<tab><tab><tab><tab>z = -1<tab><tab>else:<tab><tab><tab>yield i,if k < len ( selected ) :,107
1371,"def render_headers(self) -> bytes:<tab>if not hasattr(self, ""_headers""):<tab><tab>parts = [<tab><tab><tab>b""Content-Disposition: form-data; "",<tab><tab><tab>format_form_param(""name"", self.name),<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>filename = format_form_param(""filename"", self.filename)<tab><tab><tab>parts.extend([b""; "", filename])<tab><tab>if self.content_type is not None:<tab><tab><tab>content_type = self.content_type.encode()<tab><tab><tab>parts.extend([b""\r\nContent-Type: "", content_type])<tab><tab>parts.append(b""\r\n\r\n"")<tab><tab>self._headers = b"""".join(parts)<tab>return self._headers",if self . filename :,189
1372,"def app_middleware(next, root, info, **kwargs):<tab>app_auth_header = ""HTTP_AUTHORIZATION""<tab>prefix = ""bearer""<tab>request = info.context<tab>if request.path == API_PATH:<tab><tab>if not hasattr(request, ""app""):<tab><tab><tab>request.app = None<tab><tab><tab>auth = request.META.get(app_auth_header, """").split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>auth_prefix, auth_token = auth<tab><tab><tab><tab>if auth_prefix.lower() == prefix:<tab><tab><tab><tab><tab>request.app = SimpleLazyObject(lambda: get_app(auth_token))<tab>return next(root, info, **kwargs)",if len ( auth ) == 2 :,171
1373,"def _shortest_hypernym_paths(self, simulate_root):<tab>if self.offset == ""00000000"":<tab><tab>return {self: 0}<tab>queue = deque([(self, 0)])<tab>path = {}<tab>while queue:<tab><tab>s, depth = queue.popleft()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path[s] = depth<tab><tab>depth += 1<tab><tab>queue.extend((hyp, depth) for hyp in s._hypernyms())<tab>if simulate_root:<tab><tab>root = Synset(self._wordnet_corpus_reader, None, self.pos(), ""00000000"", """")<tab><tab>path[root] = max(path.values()) + 1<tab>return path",if s in path :,163
1374,"def _populate_class_variables():<tab>lookup = {}<tab>reverse_lookup = {}<tab>characters_for_re = []<tab>for codepoint, name in list(codepoint2name.items()):<tab><tab>character = chr(codepoint)<tab><tab><IF-STMT><tab><tab><tab># There's no point in turning the quotation mark into<tab><tab><tab># &quot;, unless it happens within an attribute value, which<tab><tab><tab># is handled elsewhere.<tab><tab><tab>characters_for_re.append(character)<tab><tab><tab>lookup[character] = name<tab><tab># But we do want to turn &quot; into the quotation mark.<tab><tab>reverse_lookup[name] = character<tab>re_definition = ""[%s]"" % """".join(characters_for_re)<tab>return lookup, reverse_lookup, re.compile(re_definition)",if codepoint != 34 :,193
1375,"def prepare_data_status(self, view: sublime.View, data: Dict[str, Any]) -> Any:<tab>""""""Prepare the returned data for status""""""<tab>if (<tab><tab>data[""success""]<tab><tab>and ""No docstring"" not in data[""doc""]<tab><tab>and data[""doc""] != ""list\n""<tab>):<tab><tab>self.signature = data[""doc""]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self.signature = self.signature.splitlines()[2]<tab><tab>except KeyError:<tab><tab><tab>return<tab><tab>return self._show_status(view)",if self . _signature_excluded ( self . signature ) :,155
1376,"def _setup_once_tables(cls):<tab>if cls.run_define_tables == ""once"":<tab><tab>cls.define_tables(cls.metadata)<tab><tab><IF-STMT><tab><tab><tab>cls.metadata.create_all(cls.bind)<tab><tab>cls.tables.update(cls.metadata.tables)","if cls . run_create_tables == ""once"" :",84
1377,"def _send_recursive(self, files):<tab>for base in files:<tab><tab><IF-STMT><tab><tab><tab># filename mixed into the bunch<tab><tab><tab>self._send_files([base])<tab><tab><tab>continue<tab><tab>last_dir = asbytes(base)<tab><tab>for root, dirs, fls in os.walk(base):<tab><tab><tab>self._chdir(last_dir, asbytes(root))<tab><tab><tab>self._send_files([os.path.join(root, f) for f in fls])<tab><tab><tab>last_dir = asbytes(root)<tab><tab># back out of the directory<tab><tab>for i in range(len(os.path.split(last_dir))):<tab><tab><tab>self._send_popd()",if not os . path . isdir ( base ) :,183
1378,"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab># Automatically register models if required.<tab>if not is_registered(self.model):<tab><tab>inline_fields = ()<tab><tab>for inline in self.inlines:<tab><tab><tab>inline_model, follow_field = self._reversion_introspect_inline_admin(inline)<tab><tab><tab>if inline_model:<tab><tab><tab><tab>self._reversion_autoregister(inline_model, ())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>inline_fields += (follow_field,)<tab><tab>self._reversion_autoregister(self.model, inline_fields)",if follow_field :,161
1379,"def dispatch_hook(key, hooks, hook_data, **kwargs):<tab>""""""Dispatches a hook dictionary on a given piece of data.""""""<tab>hooks = hooks or dict()<tab>hooks = hooks.get(key)<tab>if hooks:<tab><tab>if hasattr(hooks, ""__call__""):<tab><tab><tab>hooks = [hooks]<tab><tab>for hook in hooks:<tab><tab><tab>_hook_data = hook(hook_data, **kwargs)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hook_data = _hook_data<tab>return hook_data",if _hook_data is not None :,133
1380,"def __call__(self, image, crop=True):<tab>if isinstance(image, PTensor):<tab><tab>return self.crop_to_output(<tab><tab><tab>numpy_to_paddle(self(paddle_to_numpy(image), crop=False))<tab><tab>)<tab>else:<tab><tab>warp = cv.warpAffine(<tab><tab><tab>image,<tab><tab><tab>self.transform_matrix,<tab><tab><tab>image.shape[1::-1],<tab><tab><tab>borderMode=cv.BORDER_REPLICATE,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return self.crop_to_output(warp)<tab><tab>else:<tab><tab><tab>return warp",if crop :,157
1381,"def _analyze(self):<tab>lines = open(self.log_path, ""r"").readlines()<tab>prev_line = None<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>self.errors.append(line[len(""ERROR:"") :].strip())<tab><tab>elif line.startswith(""FAIL:"") and prev_line and prev_line.startswith(""=""):<tab><tab><tab>self.failures.append(line[len(""FAIL:"") :].strip())<tab><tab>prev_line = line","if line . startswith ( ""ERROR:"" ) and prev_line and prev_line . startswith ( ""="" ) :",128
1382,"def end(self, name):<tab>self.soup.endData()<tab>completed_tag = self.soup.tagStack[-1]<tab>namespace, name = self._getNsTag(name)<tab>nsprefix = None<tab>if namespace is not None:<tab><tab>for inverted_nsmap in reversed(self.nsmaps):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nsprefix = inverted_nsmap[namespace]<tab><tab><tab><tab>break<tab>self.soup.handle_endtag(name, nsprefix)<tab>if len(self.nsmaps) > 1:<tab><tab># This tag, or one of its parents, introduced a namespace<tab><tab># mapping, so pop it off the stack.<tab><tab>self.nsmaps.pop()",if inverted_nsmap is not None and namespace in inverted_nsmap :,184
1383,"def _bind_parameters(operation, parameters):<tab># inspired by MySQL Python Connector (conversion.py)<tab>string_parameters = {}<tab>for (name, value) in parameters.iteritems():<tab><tab>if value is None:<tab><tab><tab>string_parameters[name] = ""NULL""<tab><tab><IF-STMT><tab><tab><tab>string_parameters[name] = ""'"" + _escape(value) + ""'""<tab><tab>else:<tab><tab><tab>string_parameters[name] = str(value)<tab>return operation % string_parameters","elif isinstance ( value , basestring ) :",126
1384,"def plugin_on_song_ended(self, song, skipped):<tab>if song is not None:<tab><tab>rating = song(""~#rating"")<tab><tab>invrating = 1.0 - rating<tab><tab>delta = min(rating, invrating) / 2.0<tab><tab><IF-STMT><tab><tab><tab>rating -= delta<tab><tab>else:<tab><tab><tab>rating += delta<tab><tab>song[""~#rating""] = rating",if skipped :,97
1385,"def on_activated_async(self, view):<tab>if settings[""modified_lines_only""]:<tab><tab>self.freeze_last_version(view)<tab>if settings[""enabled""]:<tab><tab>match_trailing_spaces(view)<tab><tab># continuously watch view for changes to the visible region<tab><tab><IF-STMT><tab><tab><tab># track<tab><tab><tab>active_views[view.id()] = view.visible_region()<tab><tab><tab>self.update_on_region_change(view)",if not view . id ( ) in active_views :,123
1386,"def _notin_text(term, text, verbose=False):<tab>index = text.find(term)<tab>head = text[:index]<tab>tail = text[index + len(term) :]<tab>correct_text = head + tail<tab>diff = _diff_text(correct_text, text, verbose)<tab>newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)]<tab>for line in diff:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(u(""- "")):<tab><tab><tab>continue<tab><tab>if line.startswith(u(""+ "")):<tab><tab><tab>newdiff.append(u(""  "") + line[2:])<tab><tab>else:<tab><tab><tab>newdiff.append(line)<tab>return newdiff","if line . startswith ( u ( ""Skipping"" ) ) :",192
1387,"def delete_all(path):<tab>ppath = os.getcwd()<tab>os.chdir(path)<tab>for fn in glob.glob(""*""):<tab><tab>fn_full = os.path.join(path, fn)<tab><tab>if os.path.isdir(fn):<tab><tab><tab>delete_all(fn_full)<tab><tab>elif fn.endswith("".png""):<tab><tab><tab>os.remove(fn_full)<tab><tab><IF-STMT><tab><tab><tab>os.remove(fn_full)<tab><tab>elif DELETE_ALL_OLD:<tab><tab><tab>os.remove(fn_full)<tab>os.chdir(ppath)<tab>os.rmdir(path)","elif fn . endswith ( "".md"" ) :",158
1388,"def reward(self):<tab>""""""Returns a tuple of sum of raw and processed rewards.""""""<tab>raw_rewards, processed_rewards = 0, 0<tab>for ts in self.time_steps:<tab><tab># NOTE: raw_reward and processed_reward are None for the first time-step.<tab><tab>if ts.raw_reward is not None:<tab><tab><tab>raw_rewards += ts.raw_reward<tab><tab><IF-STMT><tab><tab><tab>processed_rewards += ts.processed_reward<tab>return raw_rewards, processed_rewards",if ts . processed_reward is not None :,134
1389,"def formatmonthname(self, theyear, themonth, withyear=True):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab>s = month_name[themonth]<tab><tab><IF-STMT><tab><tab><tab>s = s.decode(encoding)<tab><tab>if withyear:<tab><tab><tab>s = ""%s %s"" % (s, theyear)<tab><tab>return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",if encoding is not None :,115
1390,"def check_digest_auth(user, passwd):<tab>""""""Check user authentication using HTTP Digest auth""""""<tab>if request.headers.get(""Authorization""):<tab><tab>credentails = parse_authorization_header(request.headers.get(""Authorization""))<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>response_hash = response(<tab><tab><tab>credentails,<tab><tab><tab>passwd,<tab><tab><tab>dict(<tab><tab><tab><tab>uri=request.script_root + request.path,<tab><tab><tab><tab>body=request.data,<tab><tab><tab><tab>method=request.method,<tab><tab><tab>),<tab><tab>)<tab><tab>if credentails.get(""response"") == response_hash:<tab><tab><tab>return True<tab>return False",if not credentails :,165
1391,"def wrapped(self, request):<tab>try:<tab><tab>return self._finished<tab>except AttributeError:<tab><tab><IF-STMT><tab><tab><tab>if not request.session.shouldfail and not request.session.shouldstop:<tab><tab><tab><tab>log.debug(<tab><tab><tab><tab><tab>""%s is still going to be used, not terminating it. ""<tab><tab><tab><tab><tab>""Still in use on:\n%s"",<tab><tab><tab><tab><tab>self,<tab><tab><tab><tab><tab>pprint.pformat(list(self.node_ids)),<tab><tab><tab><tab>)<tab><tab><tab><tab>return<tab><tab>log.debug(""Finish called on %s"", self)<tab><tab>try:<tab><tab><tab>return func(request)<tab><tab>finally:<tab><tab><tab>self._finished = True",if self . node_ids :,185
1392,"def run_tests():<tab># type: () -> None<tab>x = 5<tab>with switch(x) as case:<tab><tab>if case(0):<tab><tab><tab>print(""zero"")<tab><tab><tab>print(""zero"")<tab><tab>elif case(1, 2):<tab><tab><tab>print(""one or two"")<tab><tab><IF-STMT><tab><tab><tab>print(""three or four"")<tab><tab>else:<tab><tab><tab>print(""default"")<tab><tab><tab>print(""another"")","elif case ( 3 , 4 ) :",114
1393,"def task_done(self):<tab>with self._cond:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""task_done() called too many times"")<tab><tab>if self._unfinished_tasks._semlock._is_zero():<tab><tab><tab>self._cond.notify_all()",if not self . _unfinished_tasks . acquire ( False ) :,75
1394,"def _set_uid(self, val):<tab>if val is not None:<tab><tab><IF-STMT><tab><tab><tab>self.bus.log(""pwd module not available; ignoring uid."", level=30)<tab><tab><tab>val = None<tab><tab>elif isinstance(val, text_or_bytes):<tab><tab><tab>val = pwd.getpwnam(val)[2]<tab>self._uid = val",if pwd is None :,92
1395,"def process_tag(hive_name, company, company_key, tag, default_arch):<tab>with winreg.OpenKeyEx(company_key, tag) as tag_key:<tab><tab>version = load_version_data(hive_name, company, tag, tag_key)<tab><tab>if version is not None:  # if failed to get version bail<tab><tab><tab>major, minor, _ = version<tab><tab><tab>arch = load_arch_data(hive_name, company, tag, tag_key, default_arch)<tab><tab><tab>if arch is not None:<tab><tab><tab><tab>exe_data = load_exe(hive_name, company, company_key, tag)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>exe, args = exe_data<tab><tab><tab><tab><tab>return company, major, minor, arch, exe, args",if exe_data is not None :,199
1396,"def run(algs):<tab>for alg in algs:<tab><tab>vcs = alg.get(""variantcaller"")<tab><tab>if vcs:<tab><tab><tab>if isinstance(vcs, dict):<tab><tab><tab><tab>vcs = reduce(operator.add, vcs.values())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vcs = [vcs]<tab><tab><tab>return any(vc.startswith(prefix) for vc in vcs if vc)","if not isinstance ( vcs , ( list , tuple ) ) :",117
1397,"def wrapper(self, *args, **kwargs):<tab>if not self.request.path.endswith(""/""):<tab><tab><IF-STMT><tab><tab><tab>uri = self.request.path + ""/""<tab><tab><tab>if self.request.query:<tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab>return<tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)","if self . request . method in ( ""GET"" , ""HEAD"" ) :",118
1398,"def check_response(self, response):<tab>""""""Specialized version of check_response().""""""<tab>for line in response:<tab><tab># Skip blank lines:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(b""OK""):<tab><tab><tab>return<tab><tab>elif line.startswith(b""Benutzer/Passwort Fehler""):<tab><tab><tab>raise BadLogin(line)<tab><tab>else:<tab><tab><tab>raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))",if not line . strip ( ) :,126
1399,"def Walk(self, hMenu=None):<tab>if not hMenu:<tab><tab>hMenu = self.handle<tab>n = user32.GetMenuItemCount(hMenu)<tab>mi = MENUITEMINFO()<tab>for i in range(n):<tab><tab>mi.fMask = 2  #  MIIM_ID<tab><tab>user32.GetMenuItemInfoA(hMenu, i, 1, byref(mi))<tab><tab>handle = user32.GetSubMenu(hMenu, i)<tab><tab><IF-STMT><tab><tab><tab>yield handle, self.ListItems(handle)<tab><tab><tab>for i in self.Walk(handle):<tab><tab><tab><tab>yield i",if handle :,157
1400,"def setSelection(self, labels):<tab>input = self.__validateInput(labels)<tab>if len(input) == 0 and not self.__allowEmptySelection:<tab><tab>return<tab>if self.__allowMultipleSelection:<tab><tab>self.__selectedLabels[:] = input<tab><tab>self.__selectionChanged()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Parameter must be single item or a list with one element.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.__selectedLabels[:] = input<tab><tab><tab>self.__selectionChanged()<tab># Remove all selected labels that are not in the menu, emit signals if necessary and update the button.<tab>self.__validateState()",if len ( input ) > 1 :,168
1401,"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab>if ""axis"" in self.args:<tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab>if not isinstance(self.axis, int):<tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab>if ""momentum"" in self.args:<tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')","if not isinstance ( self . momentum , ( int , float ) ) :",157
1402,"def get_order(self, aBuf):<tab>if not aBuf:<tab><tab>return -1, 1<tab># find out current char's byte length<tab>first_char = wrap_ord(aBuf[0])<tab>if (0x81 <= first_char <= 0x9F) or (0xE0 <= first_char <= 0xFC):<tab><tab>charLen = 2<tab>else:<tab><tab>charLen = 1<tab># return its order if it is hiragana<tab>if len(aBuf) > 1:<tab><tab>second_char = wrap_ord(aBuf[1])<tab><tab><IF-STMT><tab><tab><tab>return second_char - 0x9F, charLen<tab>return -1, charLen",if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,194
1403,"def saveSpecial(self, **kwargs):<tab>for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST:<tab><tab>item = config.get_config(""misc"", kw)<tab><tab>value = kwargs.get(kw)<tab><tab>msg = item.set(value)<tab><tab><IF-STMT><tab><tab><tab>return badParameterResponse(msg)<tab>config.save_config()<tab>raise Raiser(self.__root)",if msg :,105
1404,"def sanitize_event_keys(kwargs, valid_keys):<tab># Sanity check: Don't honor keys that we don't recognize.<tab>for key in list(kwargs.keys()):<tab><tab><IF-STMT><tab><tab><tab>kwargs.pop(key)<tab># Truncate certain values over 1k<tab>for key in [""play"", ""role"", ""task"", ""playbook""]:<tab><tab>if isinstance(kwargs.get(""event_data"", {}).get(key), str):<tab><tab><tab>if len(kwargs[""event_data""][key]) > 1024:<tab><tab><tab><tab>kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars(<tab><tab><tab><tab><tab>1024<tab><tab><tab><tab>)",if key not in valid_keys :,168
1405,"def toggleFactorReload(self, value=None):<tab>self.serviceFittingOptions[""useGlobalForceReload""] = (<tab><tab>value<tab><tab>if value is not None<tab><tab>else not self.serviceFittingOptions[""useGlobalForceReload""]<tab>)<tab>fitIDs = set()<tab>for fit in set(self._loadedFits):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if fit.calculated:<tab><tab><tab>fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""]<tab><tab><tab>fit.clearFactorReloadDependentData()<tab><tab><tab>fitIDs.add(fit.ID)<tab>return fitIDs",if fit is None :,149
1406,"def closest_unseen(self, row1, col1, filter=None):<tab># find the closest unseen from this row/col<tab>min_dist = maxint<tab>closest_unseen = None<tab>for row in range(self.height):<tab><tab>for col in range(self.width):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.map[row][col] == UNSEEN:<tab><tab><tab><tab><tab>dist = self.distance(row1, col1, row, col)<tab><tab><tab><tab><tab>if dist < min_dist:<tab><tab><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab><tab><tab>closest_unseen = (row, col)<tab>return closest_unseen","if filter is None or ( row , col ) not in filter :",174
1407,"def getAlphaClone(lookfor, eager=None):<tab>if isinstance(lookfor, int):<tab><tab><IF-STMT><tab><tab><tab>item = get_gamedata_session().query(AlphaClone).get(lookfor)<tab><tab>else:<tab><tab><tab>item = (<tab><tab><tab><tab>get_gamedata_session()<tab><tab><tab><tab>.query(AlphaClone)<tab><tab><tab><tab>.options(*processEager(eager))<tab><tab><tab><tab>.filter(AlphaClone.ID == lookfor)<tab><tab><tab><tab>.first()<tab><tab><tab>)<tab>else:<tab><tab>raise TypeError(""Need integer as argument"")<tab>return item",if eager is None :,150
1408,"def _rle_encode(string):<tab>new = b""""<tab>count = 0<tab>for cur in string:<tab><tab>if not cur:<tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new += b""\0"" + bytes([count])<tab><tab><tab><tab>count = 0<tab><tab><tab>new += bytes([cur])<tab>return new",if count :,92
1409,def result_iterator():<tab>try:<tab><tab>for future in fs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield future.result()<tab><tab><tab>else:<tab><tab><tab><tab>yield future.result(end_time - time.time())<tab>finally:<tab><tab>for future in fs:<tab><tab><tab>future.cancel(),if timeout is None :,81
1410,"def _individual_get(self, segment, index_type, index, strictdoc):<tab>if index_type == ""val"":<tab><tab>for key, value in segment.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value<tab><tab><tab>if hasattr(key, ""text""):<tab><tab><tab><tab>if key.text == index[0]:<tab><tab><tab><tab><tab>return value<tab><tab>raise Exception(""Invalid state"")<tab>elif index_type == ""index"":<tab><tab>return segment[index]<tab>elif index_type == ""textslice"":<tab><tab>return segment[index[0] : index[1]]<tab>elif index_type == ""key"":<tab><tab>return index[1] if strictdoc else index[0]<tab>else:<tab><tab>raise Exception(""Invalid state"")",if key == index [ 0 ] :,186
1411,"def _reset_sequences(self, db_name):<tab>conn = connections[db_name]<tab>if conn.features.supports_sequence_reset:<tab><tab>sql_list = conn.ops.sequence_reset_by_name_sql(<tab><tab><tab>no_style(), conn.introspection.sequence_list()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>cursor = conn.cursor()<tab><tab><tab><tab>for sql in sql_list:<tab><tab><tab><tab><tab>cursor.execute(sql)<tab><tab><tab>except Exception:<tab><tab><tab><tab>transaction.rollback_unless_managed(using=db_name)<tab><tab><tab><tab>raise<tab><tab><tab>transaction.commit_unless_managed(using=db_name)",if sql_list :,177
1412,"def translate_to_statements(self, statements, conditional_write_vars):<tab>lines = []<tab>for stmt in statements:<tab><tab><IF-STMT><tab><tab><tab>self.temporary_vars.add((stmt.var, stmt.dtype))<tab><tab>line = self.translate_statement(stmt)<tab><tab>if stmt.var in conditional_write_vars:<tab><tab><tab>subs = {}<tab><tab><tab>condvar = conditional_write_vars[stmt.var]<tab><tab><tab>lines.append(""if %s:"" % condvar)<tab><tab><tab>lines.append(indent(line))<tab><tab>else:<tab><tab><tab>lines.append(line)<tab>return lines","if stmt . op == "":="" and not stmt . var in self . variables :",168
1413,"def _bytecode_filenames(self, py_filenames):<tab>bytecode_files = []<tab>for py_file in py_filenames:<tab><tab># Since build_py handles package data installation, the<tab><tab># list of outputs can contain more than just .py files.<tab><tab># Make sure we only report bytecode for the .py files.<tab><tab>ext = os.path.splitext(os.path.normcase(py_file))[1]<tab><tab>if ext != PYTHON_SOURCE_EXTENSION:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>bytecode_files.append(py_file + ""c"")<tab><tab>if self.optimize > 0:<tab><tab><tab>bytecode_files.append(py_file + ""o"")<tab>return bytecode_files",if self . compile :,175
1414,"def logic():<tab>for i in range(100):<tab><tab>yield clock.posedge, reset.negedge<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count.next = (count + 1) % n<tab>raise StopSimulation",if enable :,81
1415,"def _is_subnet_of(a, b):<tab>try:<tab><tab># Always false if one is v4 and the other is v6.<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""%s and %s are not of the same version"" % (a, b))<tab><tab>return (<tab><tab><tab>b.network_address <= a.network_address<tab><tab><tab>and b.broadcast_address >= a.broadcast_address<tab><tab>)<tab>except AttributeError:<tab><tab>raise TypeError(<tab><tab><tab>""Unable to test subnet containment "" ""between %s and %s"" % (a, b)<tab><tab>)",if a . _version != b . _version :,153
1416,"def _filter_paths(basename, path, is_dir, exclude):<tab>"""""".gitignore style file filtering.""""""<tab>for item in exclude:<tab><tab># Items ending in '/' apply only to directories.<tab><tab>if item.endswith(""/"") and not is_dir:<tab><tab><tab>continue<tab><tab># Items starting with '/' apply to the whole path.<tab><tab># In any other cases just the basename is used.<tab><tab>match = path if item.startswith(""/"") else basename<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False","if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",130
1417,"def __recv_null(self):<tab>""""""Receive a null byte.""""""<tab>while 1:<tab><tab>c = self.sock.recv(1)<tab><tab>if c == """":<tab><tab><tab>self.close()<tab><tab><tab>raise EOFError(""Socket Closed"")<tab><tab><IF-STMT><tab><tab><tab>return","if c == ""\0"" :",74
1418,"def onMessage(self, payload, isBinary):<tab>if isBinary:<tab><tab>self.result = ""Expected text message with payload, but got binary.""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.result = (<tab><tab><tab><tab>""Expected text message with payload of length %d, but got %d.""<tab><tab><tab><tab>% (self.DATALEN, len(payload))<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>## FIXME : check actual content<tab><tab><tab>##<tab><tab><tab>self.behavior = Case.OK<tab><tab><tab>self.result = ""Received text message of length %d."" % len(payload)<tab>self.p.createWirelog = True<tab>self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",if len ( payload ) != self . DATALEN :,191
1419,"def rename_path(self, path, new_path):<tab>logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path))<tab>dirs = self.readdir(path)<tab>for d in dirs:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d_path = """".join([path, ""/"", d])<tab><tab>d_new_path = """".join([new_path, ""/"", d])<tab><tab>attr = self.getattr(d_path)<tab><tab>if stat.S_ISDIR(attr[""st_mode""]):<tab><tab><tab>self.rename_path(d_path, d_new_path)<tab><tab>else:<tab><tab><tab>self.rename_item(d_path, d_new_path)<tab>self.rename_item(path, new_path, dir=True)","if d in [ ""."" , "".."" ] :",196
1420,"def dir_box_click(self, double):<tab>if double:<tab><tab>name = self.list_box.get_selected_name()<tab><tab>path = os.path.join(self.directory, name)<tab><tab>suffix = os.path.splitext(name)[1]<tab><tab><IF-STMT><tab><tab><tab>self.directory = path<tab><tab>else:<tab><tab><tab>self.double_click_file(name)<tab>self.update()",if suffix not in self . suffixes and os . path . isdir ( path ) :,119
1421,"def __getattr__(self, key):<tab>try:<tab><tab>value = self.__parent.contents[key]<tab>except KeyError:<tab><tab>pass<tab>else:<tab><tab>if value is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value.mod_ns<tab><tab><tab>else:<tab><tab><tab><tab>assert isinstance(value, _MultipleClassMarker)<tab><tab><tab><tab>return value.attempt_get(self.__parent.path, key)<tab>raise AttributeError(<tab><tab>""Module %r has no mapped classes ""<tab><tab>""registered under the name %r"" % (self.__parent.name, key)<tab>)","if isinstance ( value , _ModuleMarker ) :",154
1422,"def poll_thread():<tab>time.sleep(0.5)<tab>if process.wait() and process_state:<tab><tab>time.sleep(0.25)<tab><tab><IF-STMT><tab><tab><tab>stdout, stderr = process._communicate(None)<tab><tab><tab>logger.error(<tab><tab><tab><tab>""Web server process exited unexpectedly"",<tab><tab><tab><tab>""app"",<tab><tab><tab><tab>stdout=stdout,<tab><tab><tab><tab>stderr=stderr,<tab><tab><tab>)<tab><tab><tab>time.sleep(1)<tab><tab><tab>restart_server(1)",if not check_global_interrupt ( ) :,135
1423,"def apply_dateparser_timezone(utc_datetime, offset_or_timezone_abb):<tab>for name, info in _tz_offsets:<tab><tab><IF-STMT><tab><tab><tab>tz = StaticTzInfo(name, info[""offset""])<tab><tab><tab>return utc_datetime.astimezone(tz)","if info [ ""regex"" ] . search ( "" %s"" % offset_or_timezone_abb ) :",87
1424,"def _load_wordlist(filename):<tab>if filename is None:<tab><tab>return {}<tab>path = None<tab>for dir in (CONFIG_DIR, ASSETS_DIR):<tab><tab>path = os.path.realpath(os.path.join(dir, filename))<tab><tab><IF-STMT><tab><tab><tab>break<tab>words = {}<tab>with open(path, encoding=""utf-8"") as f:<tab><tab>pairs = [word.strip().rsplit("" "", 1) for word in f]<tab><tab>pairs.sort(reverse=True, key=lambda x: int(x[1]))<tab><tab>words = {p[0]: int(p[1]) for p in pairs}<tab>return words",if os . path . exists ( path ) :,168
1425,"def terminate_processes_matching_names(match_strings, kill=False):<tab>""""""Terminates processes matching particular names (case sensitive).""""""<tab>if isinstance(match_strings, str):<tab><tab>match_strings = [match_strings]<tab>for process in psutil.process_iter():<tab><tab>try:<tab><tab><tab>process_info = process.as_dict(attrs=[""name"", ""pid""])<tab><tab><tab>process_name = process_info[""name""]<tab><tab>except (psutil.AccessDenied, psutil.NoSuchProcess, OSError):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>terminate_process(process_info[""pid""], kill)",if any ( x == process_name for x in match_strings ) :,159
1426,"def has_scheme(self, inp):<tab>if ""://"" in inp:<tab><tab>return True<tab>else:<tab><tab>authority = inp.replace(""/"", ""#"").replace(""?"", ""#"").split(""#"")[0]<tab><tab><IF-STMT><tab><tab><tab>_, host_or_port = authority.split("":"", 1)<tab><tab><tab># Assert it's not a port number<tab><tab><tab>if re.match(r""^\d+$"", host_or_port):<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True","if "":"" in authority :",126
1427,"def close(self):<tab>with BrowserContext._BROWSER_LOCK:<tab><tab>BrowserContext._BROWSER_REFCNT -= 1<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Destroying browser main loop"")<tab><tab><tab>BrowserContext._BROWSER_LOOP.destroy()<tab><tab><tab>BrowserContext._BROWSER_LOOP = None",if BrowserContext . _BROWSER_REFCNT == 0 :,77
1428,"def _mock_get_merge_ticks(self, order_book_id_list, trading_date, last_dt=None):<tab>for tick in self._ticks:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>self.env.data_proxy.get_future_trading_date(tick.datetime).date()<tab><tab><tab>!= trading_date.date()<tab><tab>):<tab><tab><tab>continue<tab><tab>if last_dt and tick.datetime <= last_dt:<tab><tab><tab>continue<tab><tab>yield tick",if tick . order_book_id not in order_book_id_list :,146
1429,"def messageSourceStamps(self, source_stamps):<tab>text = """"<tab>for ss in source_stamps:<tab><tab>source = """"<tab><tab><IF-STMT><tab><tab><tab>source += ""[branch %s] "" % ss[""branch""]<tab><tab>if ss[""revision""]:<tab><tab><tab>source += str(ss[""revision""])<tab><tab>else:<tab><tab><tab>source += ""HEAD""<tab><tab>if ss[""patch""] is not None:<tab><tab><tab>source += "" (plus patch)""<tab><tab>discriminator = """"<tab><tab>if ss[""codebase""]:<tab><tab><tab>discriminator = "" '%s'"" % ss[""codebase""]<tab><tab>text += ""Build Source Stamp%s: %s\n"" % (discriminator, source)<tab>return text","if ss [ ""branch"" ] :",176
1430,"def test_open_read_bytes(self, sftp):<tab>""""""Test reading bytes from a file""""""<tab>f = None<tab>try:<tab><tab>self._create_file(""file"", ""xxx"")<tab><tab>f = yield from sftp.open(""file"", ""rb"")<tab><tab>self.assertEqual((yield from f.read()), b""xxx"")<tab>finally:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>yield from f.close()<tab><tab>remove(""file"")",if f :,115
1431,"def handler(chan, host, port):<tab>sock = socket()<tab>try:<tab><tab>sock.connect((host, port))<tab>except Exception as e:<tab><tab>if verbose == True:<tab><tab><tab>print(e)<tab><tab>return<tab>while True:<tab><tab>r, w, x = select.select([sock, chan], [], [])<tab><tab>if sock in r:<tab><tab><tab>data = sock.recv(1024)<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>break<tab><tab><tab>chan.send(data)<tab><tab><IF-STMT><tab><tab><tab>data = chan.recv(1024)<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>break<tab><tab><tab>sock.send(data)<tab>chan.close()<tab>sock.close()",if chan in r :,190
1432,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = re.search(r""url\('/ks-waf-error\.png'\)"", page, re.I) is not None<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,94
1433,"def __init__(self, raw):<tab>ticker_ticks = {}<tab>for tick in raw[""results""]:<tab><tab><IF-STMT><tab><tab><tab>ticker_ticks[tick[""T""]].append(tick)<tab><tab>else:<tab><tab><tab>ticker_ticks[tick[""T""]] = [tick]<tab>super().__init__(<tab><tab>{ticker: Aggsv2({""results"": ticks}) for ticker, ticks in ticker_ticks.items()}<tab>)","if ticker_ticks . get ( tick [ ""T"" ] ) :",114
1434,"def _makefiles(self, f):<tab>if isinstance(f, dict):<tab><tab>for k, v in list(f.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.makedir(dirname=k, content=v)<tab><tab><tab>elif isinstance(v, str):<tab><tab><tab><tab>self.make_file(filename=k, content=v)<tab><tab><tab>else:  # pragma: nocover<tab><tab><tab><tab>raise ValueError(""Unexpected:"", k, v)<tab>elif isinstance(f, str):<tab><tab>self._make_empty_file(f)<tab>elif isinstance(f, list):<tab><tab>self.make_list(f)<tab>else:  # pragma: nocover<tab><tab>raise ValueError(""Unknown type:"", f)","if isinstance ( v , list ) :",182
1435,"def migrate_command_storage(apps, schema_editor):<tab>model = apps.get_model(""terminal"", ""CommandStorage"")<tab>init_storage_data(model)<tab>setting = get_setting(apps, schema_editor, ""TERMINAL_COMMAND_STORAGE"")<tab>if not setting:<tab><tab>return<tab>values = get_storage_data(setting)<tab>for name, meta in values.items():<tab><tab>tp = meta.pop(""TYPE"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>model.objects.create(name=name, type=tp, meta=meta)","if not tp or name in [ ""default"" , ""null"" ] :",146
1436,"def build_vertices(self, ulines):<tab>vertex_idx = 0<tab>vertices = collections.OrderedDict()<tab>for line in ulines:<tab><tab>for vt in line:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>new_vertex = (vt.u, vt.v, 0.0)<tab><tab><tab>if new_vertex in vertices:<tab><tab><tab><tab>continue<tab><tab><tab>vt.index = vertex_idx<tab><tab><tab>vertex_idx += 1<tab><tab><tab>vertices[new_vertex] = 1<tab>return vertex_idx, list(vertices.keys())",if vt . replacement is not None :,145
1437,"def get_quarantine_count(self):<tab>""""""get obj/container/account quarantine counts""""""<tab>qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0}<tab>qdir = ""quarantined""<tab>for device in os.listdir(self.devices):<tab><tab>for qtype in qcounts:<tab><tab><tab>qtgt = os.path.join(self.devices, device, qdir, qtype)<tab><tab><tab>if os.path.exists(qtgt):<tab><tab><tab><tab>linkcount = os.lstat(qtgt).st_nlink<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>qcounts[qtype] += linkcount - 2<tab>return qcounts",if linkcount > 2 :,171
1438,"def _format_arg(self, name, trait_spec, value):<tab>if name == ""mask_file"":<tab><tab>return """"<tab>if name == ""op_string"":<tab><tab><IF-STMT><tab><tab><tab>if isdefined(self.inputs.mask_file):<tab><tab><tab><tab>return self.inputs.op_string % self.inputs.mask_file<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""-k %s option in op_string requires mask_file"")<tab>return super(ImageStats, self)._format_arg(name, trait_spec, value)","if ""-k %s"" in self . inputs . op_string :",146
1439,"def _update_theme_style(self, *args):<tab>self.line_color_normal = self.theme_cls.divider_color<tab>if not any([self.error, self._text_len_error]):<tab><tab>if not self.focus:<tab><tab><tab>self._current_hint_text_color = self.theme_cls.disabled_hint_text_color<tab><tab><tab>self._current_right_lbl_color = self.theme_cls.disabled_hint_text_color<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._current_error_color = self.theme_cls.disabled_hint_text_color","if self . helper_text_mode == ""persistent"" :",158
1440,"def createFields(self):<tab>for item in self.format:<tab><tab><IF-STMT><tab><tab><tab>yield item[0](self, *item[1:-1], **item[-1])<tab><tab>else:<tab><tab><tab>yield item[0](self, *item[1:])","if isinstance ( item [ - 1 ] , dict ) :",72
1441,"def execute(self, statement, arguments=None):<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.cursor.execute(statement, arguments)<tab><tab><tab>else:<tab><tab><tab><tab>self.cursor.execute(statement)<tab><tab>except sqlite3.OperationalError as ex:<tab><tab><tab>if ""locked"" not in getSafeExString(ex):<tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>break<tab>if statement.lstrip().upper().startswith(""SELECT""):<tab><tab>return self.cursor.fetchall()",if arguments :,130
1442,"def set_income_account_for_fixed_assets(self):<tab>disposal_account = depreciation_cost_center = None<tab>for d in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>if not disposal_account:<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>disposal_account,<tab><tab><tab><tab><tab>depreciation_cost_center,<tab><tab><tab><tab>) = get_disposal_account_and_cost_center(self.company)<tab><tab><tab>d.income_account = disposal_account<tab><tab><tab>if not d.cost_center:<tab><tab><tab><tab>d.cost_center = depreciation_cost_center",if d . is_fixed_asset :,170
1443,"def _convertNbCharsInNbBits(self, nbChars):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbChars is not None:<tab><tab>if isinstance(nbChars, int):<tab><tab><tab>nbMinBit = nbChars * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab>if nbChars[0] is not None:<tab><tab><tab><tab>nbMinBit = nbChars[0] * 8<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nbMaxBit = nbChars[1] * 8<tab>return (nbMinBit, nbMaxBit)",if nbChars [ 1 ] is not None :,158
1444,"def _get_service_full_name(self, name, help_command_table):<tab>if help_command_table and name not in self._NON_SERVICE_COMMANDS:<tab><tab><IF-STMT><tab><tab><tab>return self._HIGH_LEVEL_SERVICE_FULL_NAMES[name]<tab><tab>service = help_command_table.get(name)<tab><tab>if service:<tab><tab><tab>return service.service_model.metadata[""serviceFullName""]",if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,116
1445,"def print_addresses(self):<tab>p = 3<tab>tmp_str = ""[""<tab>if self.get_len() >= 7:  # at least one complete IP address<tab><tab>while 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp_str += ""#""<tab><tab><tab>tmp_str += self.get_ip_address(p)<tab><tab><tab>p += 4<tab><tab><tab>if p >= self.get_len():<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>tmp_str += "", ""<tab>tmp_str += ""] ""<tab>if self.get_ptr() % 4:  # ptr field should be a multiple of 4<tab><tab>tmp_str += ""nonsense ptr field: %d "" % self.get_ptr()<tab>return tmp_str",if p + 1 == self . get_ptr ( ) :,191
1446,"def run(self):<tab>for _ in range(self.n):<tab><tab>error = True<tab><tab>try:<tab><tab><tab>self.collection.insert_one({""test"": ""insert""})<tab><tab><tab>error = False<tab><tab>except:<tab><tab><tab>if not self.expect_exception:<tab><tab><tab><tab>raise<tab><tab><IF-STMT><tab><tab><tab>assert error",if self . expect_exception :,91
1447,"def create_composite_mounter_by_args(args):<tab>""""""Creates a CompositeMounter by the images in given args.""""""<tab>logging.info(""Mount images..."")<tab>mounter = composite_mounter.CompositeMounter()<tab>for partition in composite_mounter.SUPPORTED_PARTITIONS:<tab><tab>image_source = vars(args)[partition]<tab><tab><IF-STMT><tab><tab><tab>logging.info(""  %s=%s"", partition, image_source)<tab><tab><tab>mounter.add_by_mount_target(partition, image_source)<tab>if mounter.is_empty():<tab><tab>raise RuntimeError(""Must give at least one image source."")<tab>return mounter",if image_source :,162
1448,"def _get_containing_class(self, pyname):<tab>if isinstance(pyname, pynames.DefinedName):<tab><tab>scope = pyname.get_object().get_scope()<tab><tab>parent = scope.parent<tab><tab><IF-STMT><tab><tab><tab>return parent.pyobject","if parent is not None and parent . get_kind ( ) == ""Class"" :",80
1449,"def test_chunkcoding(self):<tab>tstring_lines = []<tab>for b in self.tstring:<tab><tab>lines = b.split(b""\n"")<tab><tab>last = lines.pop()<tab><tab>assert last == b""""<tab><tab>lines = [line + b""\n"" for line in lines]<tab><tab>tstring_lines.append(lines)<tab>for native, utf8 in zip(*tstring_lines):<tab><tab>u = self.decode(native)[0]<tab><tab>self.assertEqual(u, utf8.decode(""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(native, self.encode(u)[0])",if self . roundtriptest :,161
1450,"def set_default_variants(apps, schema_editor):<tab>Product = apps.get_model(""product"", ""Product"")<tab>for product in Product.objects.iterator():<tab><tab>first_variant = product.variants.first()<tab><tab><IF-STMT><tab><tab><tab>product.default_variant = first_variant<tab><tab><tab>product.save(update_fields=[""default_variant"", ""updated_at""])",if first_variant :,95
1451,"def json(self):<tab>try:<tab><tab>if self.is_json():<tab><tab><tab>raw_data = self.raw_data()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raw_data = raw_data.decode(""utf-8"")<tab><tab><tab>return json.loads(raw_data)<tab>except ValueError:<tab><tab>pass","if not isinstance ( raw_data , text_type ) :",91
1452,"def clear_react(self, message: discord.Message, emoji: MutableMapping = None) -> None:<tab>try:<tab><tab>await message.clear_reactions()<tab>except discord.Forbidden:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>with contextlib.suppress(discord.HTTPException):<tab><tab><tab>async for key in AsyncIter(emoji.values(), delay=0.2):<tab><tab><tab><tab>await message.remove_reaction(key, self.bot.user)<tab>except discord.HTTPException:<tab><tab>return",if not emoji :,134
1453,"def check(self, value):<tab>value = String.check(self, value)<tab>if isinstance(value, str):<tab><tab>value = value.upper()<tab><tab>for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]):<tab><tab><tab># e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD<tab><tab><tab>if value.startswith(prefix):<tab><tab><tab><tab>value = value[len(prefix) :]<tab><tab><tab>value = value.lstrip(""_"")<tab><tab><IF-STMT><tab><tab><tab>return getattr(self.group, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""No such constant: %s_%s"" % (self.prefix, value))<tab>else:<tab><tab>return value","if hasattr ( self . group , value ) :",182
1454,"def value(self):<tab>quote = False<tab>if self.defects:<tab><tab>quote = True<tab>else:<tab><tab>for x in self:<tab><tab><tab>if x.token_type == ""quoted-string"":<tab><tab><tab><tab>quote = True<tab>if quote:<tab><tab>pre = post = """"<tab><tab>if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"":<tab><tab><tab>pre = "" ""<tab><tab><IF-STMT><tab><tab><tab>post = "" ""<tab><tab>return pre + quote_string(self.display_name) + post<tab>else:<tab><tab>return super(DisplayName, self).value","if self [ - 1 ] . token_type == ""cfws"" or self [ - 1 ] [ - 1 ] . token_type == ""cfws"" :",186
1455,"def get_drive(self, root_path="""", volume_guid_path=""""):<tab>for drive in self.drives:<tab><tab>if root_path:<tab><tab><tab>config_root_path = drive.get(""root_path"")<tab><tab><tab>if config_root_path and root_path == config_root_path:<tab><tab><tab><tab>return drive<tab><tab><IF-STMT><tab><tab><tab>config_volume_guid_path = drive.get(""volume_guid_path"")<tab><tab><tab>if config_volume_guid_path and config_volume_guid_path == volume_guid_path:<tab><tab><tab><tab>return drive",elif volume_guid_path :,148
1456,"def parse_edges(self, pcb):<tab>edges = []<tab>drawings = list(pcb.GetDrawings())<tab>bbox = None<tab>for m in pcb.GetModules():<tab><tab>for g in m.GraphicalItems():<tab><tab><tab>drawings.append(g)<tab>for d in drawings:<tab><tab>if d.GetLayer() == pcbnew.Edge_Cuts:<tab><tab><tab>parsed_drawing = self.parse_drawing(d)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>edges.append(parsed_drawing)<tab><tab><tab><tab>if bbox is None:<tab><tab><tab><tab><tab>bbox = d.GetBoundingBox()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>bbox.Merge(d.GetBoundingBox())<tab>if bbox:<tab><tab>bbox.Normalize()<tab>return edges, bbox",if parsed_drawing :,197
1457,"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab>if isinstance(k, float):<tab><tab><tab>return unicode(float_repr(k))<tab><tab>elif ""regex"" in literal_or_identifier:<tab><tab><tab>return compose_regex(k)<tab><tab>elif isinstance(k, bool):<tab><tab><tab>return ""true"" if k else ""false""<tab><tab><IF-STMT><tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)",elif k is None :,179
1458,"def find_multiple_stats(stats, name, _found=None, _on_found=None):<tab>if _found is None:<tab><tab>_found = []<tab>for child_stats in stats:<tab><tab>if child_stats.name == name:<tab><tab><tab>_found.append(child_stats)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_on_found(_found)<tab><tab>find_multiple_stats(child_stats, name, _found)<tab>return _found",if callable ( _on_found ) :,119
1459,"def _run_generated_code(<tab>self,<tab>code,<tab>globs,<tab>locs,<tab>fails_under_py3k=True,):<tab>import warnings<tab>from zope.interface._compat import PYTHON3<tab>with warnings.catch_warnings(record=True) as log:<tab><tab>warnings.resetwarnings()<tab><tab><IF-STMT><tab><tab><tab>exec(code, globs, locs)<tab><tab><tab>self.assertEqual(len(log), 0)  # no longer warn<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>exec(code, globs, locs)<tab><tab><tab>except TypeError:<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>if fails_under_py3k:<tab><tab><tab><tab><tab>self.fail(""Didn't raise TypeError"")",if not PYTHON3 :,195
1460,"def _get_node(self, node_id):<tab>self.non_terminated_nodes({})  # Side effect: updates cache<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>return self.cached_nodes[node_id]<tab><tab>instance = (<tab><tab><tab>self.compute.instances()<tab><tab><tab>.get(<tab><tab><tab><tab>project=self.provider_config[""project_id""],<tab><tab><tab><tab>zone=self.provider_config[""availability_zone""],<tab><tab><tab><tab>instance=node_id,<tab><tab><tab>)<tab><tab><tab>.execute()<tab><tab>)<tab><tab>return instance",if node_id in self . cached_nodes :,156
1461,"def skip_to_close_match(self):<tab>nestedCount = 1<tab>while 1:<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab>ttype = tok[""style""]<tab><tab>if ttype == SCE_PL_UNUSED:<tab><tab><tab>return<tab><tab>elif self.classifier.is_index_op(tok):<tab><tab><tab>tval = tok[""text""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.opHash[tval][1] == 1:<tab><tab><tab><tab><tab>nestedCount += 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>nestedCount -= 1<tab><tab><tab><tab><tab>if nestedCount <= 0:<tab><tab><tab><tab><tab><tab>break",if self . opHash . has_key ( tval ) :,176
1462,"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper:<tab># Prefer creating a new helper when at least one kwarg is specified.<tab>prefer_new = len(kwargs) > 0<tab>kwargs.update(infer_mode=infer_mode)<tab>is_training = not infer_mode if infer_mode is not None else self.training<tab>helper = self._train_helper if is_training else self._infer_helper<tab>if prefer_new or helper is None:<tab><tab>helper = self.create_helper(**kwargs)<tab><tab>if is_training and self._train_helper is None:<tab><tab><tab>self._train_helper = helper<tab><tab><IF-STMT><tab><tab><tab>self._infer_helper = helper<tab>return helper",elif not is_training and self . _infer_helper is None :,195
1463,"def get_ldset(self, ldsets):<tab>ldset = None<tab>if self._properties[""ldset_name""] == """":<tab><tab>nldset = len(ldsets)<tab><tab>if nldset == 0:<tab><tab><tab>msg = _(""Logical Disk Set could not be found."")<tab><tab><tab>raise exception.NotFound(msg)<tab><tab>else:<tab><tab><tab>ldset = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>msg = (<tab><tab><tab><tab>_(""Logical Disk Set `%s` could not be found."")<tab><tab><tab><tab>% self._properties[""ldset_name""]<tab><tab><tab>)<tab><tab><tab>raise exception.NotFound(msg)<tab><tab>ldset = ldsets[self._properties[""ldset_name""]]<tab>return ldset","if self . _properties [ ""ldset_name"" ] not in ldsets :",195
1464,"def calc_fractal_serial(q, maxiter):<tab># calculate z using pure python on a numpy array<tab># note that, unlike the other two implementations,<tab># the number of iterations per point is NOT constant<tab>z = np.zeros(q.shape, complex)<tab>output = np.resize(<tab><tab>np.array(<tab><tab><tab>0,<tab><tab>),<tab><tab>q.shape,<tab>)<tab>for i in range(len(q)):<tab><tab>for iter in range(maxiter):<tab><tab><tab>z[i] = z[i] * z[i] + q[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output[i] = iter<tab><tab><tab><tab>break<tab>return output",if abs ( z [ i ] ) > 2.0 :,180
1465,"def _verifySubs(self):<tab>for inst in self.subs:<tab><tab>if not isinstance(inst, (_Block, _Instantiator, Cosimulation)):<tab><tab><tab>raise BlockError(_error.ArgType % (self.name,))<tab><tab><IF-STMT><tab><tab><tab>if not inst.modctxt:<tab><tab><tab><tab>raise BlockError(_error.InstanceError % (self.name, inst.callername))","if isinstance ( inst , ( _Block , _Instantiator ) ) :",110
1466,"def walks_generator():<tab>if filelist is not None:<tab><tab>bucket = []<tab><tab>for filename in filelist:<tab><tab><tab>with io.open(filename) as inf:<tab><tab><tab><tab>for line in inf:<tab><tab><tab><tab><tab>walk = [int(x) for x in line.strip(""\n"").split("" "")]<tab><tab><tab><tab><tab>bucket.append(walk)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield bucket<tab><tab><tab><tab><tab><tab>bucket = []<tab><tab>if len(bucket):<tab><tab><tab>yield bucket<tab>else:<tab><tab>for _ in range(epoch):<tab><tab><tab>for nodes in graph.node_batch_iter(batch_size):<tab><tab><tab><tab>walks = graph.random_walk(nodes, walk_len)<tab><tab><tab><tab>yield walks",if len ( bucket ) == batch_size :,198
1467,def _traverse(op):<tab>if op in visited:<tab><tab>return<tab>visited.add(op)<tab>if tag.is_injective(op.tag):<tab><tab>if op not in s.outputs:<tab><tab><tab>s[op].compute_inline()<tab><tab>for tensor in op.input_tensors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_traverse(tensor.op)<tab>callback(op),"if isinstance ( tensor . op , tvm . te . ComputeOp ) :",112
1468,"def unwatch_run(self, run_id, handler):<tab>with self._dict_lock:<tab><tab><IF-STMT><tab><tab><tab>self._handlers_dict[run_id] = [<tab><tab><tab><tab>(start_cursor, callback)<tab><tab><tab><tab>for (start_cursor, callback) in self._handlers_dict[run_id]<tab><tab><tab><tab>if callback != handler<tab><tab><tab>]<tab><tab>if not self._handlers_dict[run_id]:<tab><tab><tab>del self._handlers_dict[run_id]<tab><tab><tab>run_id_dict = self._run_id_dict<tab><tab><tab>del run_id_dict[run_id]<tab><tab><tab>self._run_id_dict = run_id_dict",if run_id in self . _run_id_dict :,185
1469,"def _PromptMySQL(self, config):<tab>""""""Prompts the MySQL configuration, retrying if the configuration is invalid.""""""<tab>while True:<tab><tab>self._PromptMySQLOnce(config)<tab><tab><IF-STMT><tab><tab><tab>print(""Successfully connected to MySQL with the given configuration."")<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>print(""Error: Could not connect to MySQL with the given configuration."")<tab><tab><tab>retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True)<tab><tab><tab>if not retry:<tab><tab><tab><tab>raise ConfigInitError()",if self . _CheckMySQLConnection ( ) :,136
1470,"def get_courses_without_topic(topic):<tab>data = []<tab>for entry in frappe.db.get_all(""Course""):<tab><tab>course = frappe.get_doc(""Course"", entry.name)<tab><tab>topics = [t.topic for t in course.topics]<tab><tab><IF-STMT><tab><tab><tab>data.append(course.name)<tab>return data",if not topics or topic not in topics :,103
1471,"def _error_handler(action, **keywords):<tab>if keywords:<tab><tab>file_type = keywords.get(""file_type"", None)<tab><tab>if file_type:<tab><tab><tab>raise exceptions.FileTypeNotSupported(<tab><tab><tab><tab>constants.FILE_TYPE_NOT_SUPPORTED_FMT % (file_type, action)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keywords.pop(""on_demand"")<tab><tab><tab>msg = ""Please check if there were typos in ""<tab><tab><tab>msg += ""function parameters: %s. Otherwise ""<tab><tab><tab>msg += ""unrecognized parameters were given.""<tab><tab><tab>raise exceptions.UnknownParameters(msg % keywords)<tab>else:<tab><tab>raise exceptions.UnknownParameters(""No parameters found!"")","if ""on_demand"" in keywords :",186
1472,"def select(self, regions, register):<tab>self.view.sel().clear()<tab>to_store = []<tab>for r in regions:<tab><tab>self.view.sel().add(r)<tab><tab><IF-STMT><tab><tab><tab>to_store.append(self.view.substr(self.view.full_line(r)))<tab>if register:<tab><tab>text = """".join(to_store)<tab><tab>if not text.endswith(""\n""):<tab><tab><tab>text = text + ""\n""<tab><tab>state = State(self.view)<tab><tab>state.registers[register] = [text]",if register :,142
1473,"def has_actor(self, message: HasActorMessage) -> ResultMessage:<tab>actor_ref = message.actor_ref<tab># lookup allocated<tab>for address, item in self._allocated_actors.items():<tab><tab>ref = create_actor_ref(address, actor_ref.uid)<tab><tab><IF-STMT><tab><tab><tab>return ResultMessage(message.message_id, True, protocol=message.protocol)<tab>return ResultMessage(message.message_id, False, protocol=message.protocol)",if ref in item :,113
1474,"def toggleMetaButton(self, event):<tab>""""""Process clicks on toggle buttons""""""<tab>clickedBtn = event.EventObject<tab>if wx.GetMouseState().GetModifiers() == wx.MOD_CONTROL:<tab><tab>activeBtns = [btn for btn in self.metaButtons if btn.GetValue()]<tab><tab><IF-STMT><tab><tab><tab>clickedBtn.setUserSelection(clickedBtn.GetValue())<tab><tab><tab>self.itemView.filterItemStore()<tab><tab>else:<tab><tab><tab># Do 'nothing' if we're trying to turn last active button off<tab><tab><tab># Keep button in the same state<tab><tab><tab>clickedBtn.setUserSelection(True)<tab>else:<tab><tab>for btn in self.metaButtons:<tab><tab><tab>btn.setUserSelection(btn == clickedBtn)<tab><tab>self.itemView.filterItemStore()",if activeBtns :,198
1475,"def __init__(self, hub=None):  # pylint: disable=unused-argument<tab>if resolver._resolver is None:<tab><tab>_resolver = resolver._resolver = _DualResolver()<tab><tab>if config.resolver_nameservers:<tab><tab><tab>_resolver.network_resolver.nameservers[:] = config.resolver_nameservers<tab><tab><IF-STMT><tab><tab><tab>_resolver.network_resolver.lifetime = config.resolver_timeout<tab># Different hubs in different threads could be sharing the same<tab># resolver.<tab>assert isinstance(resolver._resolver, _DualResolver)<tab>self._resolver = resolver._resolver",if config . resolver_timeout :,147
1476,"def sub_paragraph(self, li):<tab>""""""Search for checkbox in sub-paragraph.""""""<tab>found = False<tab>if len(li):<tab><tab>first = list(li)[0]<tab><tab><IF-STMT><tab><tab><tab>m = RE_CHECKBOX.match(first.text)<tab><tab><tab>if m is not None:<tab><tab><tab><tab>first.text = self.markdown.htmlStash.store(<tab><tab><tab><tab><tab>get_checkbox(m.group(""state"")), safe=True<tab><tab><tab><tab>) + m.group(""line"")<tab><tab><tab><tab>found = True<tab>return found","if first . tag == ""p"" and first . text is not None :",152
1477,"def _check_mswin_locale(locale):<tab>msloc = None<tab>try:<tab><tab>msloc = _LOCALE_NAMES[locale[:5]][:2]<tab><tab>locale = locale[:5]<tab>except KeyError:<tab><tab>try:<tab><tab><tab>msloc = _LOCALE_NAMES[locale[:2]][:2]<tab><tab><tab>locale = locale[:2]<tab><tab>except KeyError:<tab><tab><tab># US English is the outlier, all other English locales want<tab><tab><tab># real English:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (""en_GB"", ""1252"")<tab><tab><tab>return (None, None)<tab>return (locale, msloc)","if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :",176
1478,"def setLabel(self, s, protect=False):<tab>""""""Set the label of the minibuffer.""""""<tab>c, k, w = self.c, self, self.w<tab>if w:<tab><tab># Support for the curses gui.<tab><tab><IF-STMT><tab><tab><tab>g.app.gui.set_minibuffer_label(c, s)<tab><tab>w.setAllText(s)<tab><tab>n = len(s)<tab><tab>w.setSelectionRange(n, n, insert=n)<tab><tab>if protect:<tab><tab><tab>k.mb_prefix = s","if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :",151
1479,"def getProc(su, innerTarget):<tab>if len(su) == 1:  # have a one element wedge<tab><tab>proc = (""first"", ""last"")<tab>else:<tab><tab>if su.isFirst(innerTarget) and su.isLast(innerTarget):<tab><tab><tab>proc = (""first"", ""last"")  # same element can be first and last<tab><tab><IF-STMT><tab><tab><tab>proc = (""first"",)<tab><tab>elif su.isLast(innerTarget):<tab><tab><tab>proc = (""last"",)<tab><tab>else:<tab><tab><tab>proc = ()<tab>return proc",elif su . isFirst ( innerTarget ) :,143
1480,"def await_test_end(self):<tab>iterations = 0<tab>while True:<tab><tab>if iterations > 100:<tab><tab><tab>self.log.debug(""Await: iteration limit reached"")<tab><tab><tab>return<tab><tab>status = self.master.get_status()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>iterations += 1<tab><tab>time.sleep(1.0)","if status . get ( ""status"" ) == ""ENDED"" :",100
1481,"def _handle_autocomplete_request_for_text(text):<tab>if not hasattr(text, ""autocompleter""):<tab><tab>if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text.autocompleter = Completer(text)<tab><tab><tab>elif isinstance(text, ShellText):<tab><tab><tab><tab>text.autocompleter = ShellCompleter(text)<tab><tab><tab>text.bind(""<1>"", text.autocompleter.on_text_click)<tab><tab>else:<tab><tab><tab>return<tab>text.autocompleter.handle_autocomplete_request()","if isinstance ( text , CodeViewText ) :",151
1482,"def validate_party_details(self):<tab>if self.party:<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party))<tab><tab>if self.party_account and self.party_type in (""Customer"", ""Supplier""):<tab><tab><tab>self.validate_account_type(<tab><tab><tab><tab>self.party_account, [erpnext.get_party_account_type(self.party_type)]<tab><tab><tab>)","if not frappe . db . exists ( self . party_type , self . party ) :",140
1483,"def format(self, formatstr):<tab>pieces = []<tab>for i, piece in enumerate(re_formatchars.split(force_text(formatstr))):<tab><tab><IF-STMT><tab><tab><tab>pieces.append(force_text(getattr(self, piece)()))<tab><tab>elif piece:<tab><tab><tab>pieces.append(re_escaped.sub(r""\1"", piece))<tab>return """".join(pieces)",if i % 2 :,99
1484,"def _convert_java_pattern_to_python(pattern):<tab>""""""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`.""""""<tab>s = list(pattern)<tab>i = 0<tab>while i < len(s) - 1:<tab><tab>c = s[i]<tab><tab><IF-STMT><tab><tab><tab>s[i] = ""\\""<tab><tab>elif c == ""\\"" and s[i + 1] == ""$"":<tab><tab><tab>s[i] = """"<tab><tab><tab>i += 1<tab><tab>i += 1<tab>return pattern[:0].join(s)","if c == ""$"" and s [ i + 1 ] in ""0123456789"" :",152
1485,"def download(self, url, filename, **kwargs):<tab>try:<tab><tab>r = self.get(url, timeout=10, stream=True, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab>for chunk in r.iter_content(chunk_size=1024):<tab><tab><tab><tab>if chunk:<tab><tab><tab><tab><tab>f.write(chunk)<tab><tab>helpers.chmod_as_parent(filename)<tab>except Exception as e:<tab><tab>sickrage.app.log.debug(<tab><tab><tab>""Failed to download file from {} - ERROR: {}"".format(url, e)<tab><tab>)<tab><tab>if os.path.exists(filename):<tab><tab><tab>os.remove(filename)<tab><tab>return False<tab>return True",if r . status_code >= 400 :,200
1486,"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedFilesWithExtension(""js""):<tab><tab>items.append(<tab><tab><tab>'<script type=""text/javascript"" src=""'<tab><tab><tab>+ item.pathAbsoluteFromProjectEncoded()<tab><tab><tab>+ '""></script>'<tab><tab>)<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",if len ( items ) > 1 :,153
1487,"def work(self):<tab>while True:<tab><tab>timeout = self.timeout<tab><tab>if idle.is_set():<tab><tab><tab>timeout = self.idle_timeout<tab><tab>log.debug(""Wait for {}"".format(timeout))<tab><tab>fetch.wait(timeout)<tab><tab><IF-STMT><tab><tab><tab>log.info(""Stop fetch worker"")<tab><tab><tab>break<tab><tab>self.fetch()",if shutting_down . is_set ( ) :,99
1488,"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab>if mode == ""start"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mode = ""key""<tab><tab>elif mode == ""key"":<tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab>elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")","if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s :",195
1489,"def compare_lists(self, l1, l2, key):<tab>l2_lookup = {o.get(key): o for o in l2}<tab>for obj1 in l1:<tab><tab>obj2 = l2_lookup.get(obj1.get(key))<tab><tab>for k in obj1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(obj1.get(k), obj2.get(k))","if k not in ""id"" and obj1 . get ( k ) :",117
1490,"def before_get_object(self, view_kwargs):<tab>if view_kwargs.get(""id"") is not None:<tab><tab>try:<tab><tab><tab>user_favourite_event = find_user_favourite_event_by_id(<tab><tab><tab><tab>event_id=view_kwargs[""id""]<tab><tab><tab>)<tab><tab>except NoResultFound:<tab><tab><tab>raise ObjectNotFound(<tab><tab><tab><tab>{""source"": ""/data/relationships/event""}, ""Object: not found""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>view_kwargs[""id""] = user_favourite_event.id<tab><tab><tab>else:<tab><tab><tab><tab>view_kwargs[""id""] = None",if user_favourite_event is not None :,182
1491,"def close(self):<tab>super().close()<tab>if not sys.is_finalizing():<tab><tab>for sig in list(self._signal_handlers):<tab><tab><tab>self.remove_signal_handler(sig)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>f""Closing the loop {self!r} ""<tab><tab><tab><tab>f""on interpreter shutdown ""<tab><tab><tab><tab>f""stage, skipping signal handlers removal"",<tab><tab><tab><tab>ResourceWarning,<tab><tab><tab><tab>source=self,<tab><tab><tab>)<tab><tab><tab>self._signal_handlers.clear()",if self . _signal_handlers :,148
1492,"def install_script(self, script, install_options=None):<tab>try:<tab><tab>fname = utils.do_script(<tab><tab><tab>script,<tab><tab><tab>python_exe=osp.join(self.target, ""python.exe""),<tab><tab><tab>architecture=self.architecture,<tab><tab><tab>verbose=self.verbose,<tab><tab><tab>install_options=install_options,<tab><tab>)<tab>except RuntimeError:<tab><tab><IF-STMT><tab><tab><tab>print(""Failed!"")<tab><tab><tab>raise",if not self . verbose :,123
1493,"def GetRouterForUser(self, username):<tab>""""""Returns a router corresponding to a given username.""""""<tab>for index, router in enumerate(self.routers):<tab><tab>router_id = str(index)<tab><tab><IF-STMT><tab><tab><tab>logging.debug(<tab><tab><tab><tab>""Matched router %s to user %s"", router.__class__.__name__, username<tab><tab><tab>)<tab><tab><tab>return router<tab>logging.debug(<tab><tab>""No router ACL rule match for user %s. Using default "" ""router %s"",<tab><tab>username,<tab><tab>self.default_router.__class__.__name__,<tab>)<tab>return self.default_router","if self . auth_manager . CheckPermissions ( username , router_id ) :",168
1494,"def charset(self):<tab>""""""The charset from the content type.""""""<tab>header = self.environ.get(""CONTENT_TYPE"")<tab>if header:<tab><tab>ct, options = parse_options_header(header)<tab><tab>charset = options.get(""charset"")<tab><tab><IF-STMT><tab><tab><tab>if is_known_charset(charset):<tab><tab><tab><tab>return charset<tab><tab><tab>return self.unknown_charset(charset)<tab>return self.default_charset",if charset :,108
1495,def isFinished(self):<tab># returns true if episode timesteps has reached episode length and resets the task<tab>if self.count > self.epiLen:<tab><tab>self.res()<tab><tab>return True<tab>else:<tab><tab>if self.count == 1:<tab><tab><tab>self.pertGlasPos(0)<tab><tab><IF-STMT><tab><tab><tab>self.env.reset()<tab><tab><tab>self.pertGlasPos(1)<tab><tab>self.count += 1<tab><tab>return False,if self . count == self . epiLen / 2 + 1 :,132
1496,"def mtimes_of_files(dirnames: List[str], suffix: str) -> Iterator[float]:<tab>for dirname in dirnames:<tab><tab>for root, dirs, files in os.walk(dirname):<tab><tab><tab>for sfile in files:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>yield path.getmtime(path.join(root, sfile))<tab><tab><tab><tab><tab>except OSError:<tab><tab><tab><tab><tab><tab>pass",if sfile . endswith ( suffix ) :,113
1497,"def get_all_hashes(self):<tab>event_hashes = []<tab>sample_hashes = []<tab>for a in self.event.attributes:<tab><tab>h = None<tab><tab>if a.type in (""md5"", ""sha1"", ""sha256""):<tab><tab><tab>h = a.value<tab><tab><tab>event_hashes.append(h)<tab><tab>elif a.type in (""filename|md5"", ""filename|sha1"", ""filename|sha256""):<tab><tab><tab>h = a.value.split(""|"")[1]<tab><tab><tab>event_hashes.append(h)<tab><tab><IF-STMT><tab><tab><tab>h = a.value.split(""|"")[1]<tab><tab><tab>sample_hashes.append(h)<tab>return event_hashes, sample_hashes","elif a . type == ""malware-sample"" :",184
1498,"def _validate(self, event):<tab>if self.type is None:<tab><tab>return<tab>new = self.value<tab>if not isinstance(new, self.type) and new is not None:<tab><tab><IF-STMT><tab><tab><tab>self.value = event.old<tab><tab>types = repr(self.type) if isinstance(self.type, tuple) else self.type.__name__<tab><tab>raise ValueError(<tab><tab><tab>""LiteralInput expected %s type but value %s ""<tab><tab><tab>""is of type %s."" % (types, new, type(new).__name__)<tab><tab>)",if event :,140
1499,"def update_dict(a, b):<tab>for key, value in b.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if key not in a:<tab><tab><tab>a[key] = value<tab><tab>elif isinstance(a[key], dict) and isinstance(value, dict):<tab><tab><tab>update_dict(a[key], value)<tab><tab>elif isinstance(a[key], list):<tab><tab><tab>a[key].append(value)<tab><tab>else:<tab><tab><tab>a[key] = [a[key], value]",if value is None :,131
1500,"def on_pre_save(self, view):<tab>extOrClause = ""|"".join(s.get(""format_on_save_extensions""))<tab>extRegex = ""\\.("" + extOrClause + "")$""<tab>if s.get(""format_on_save"") and re.search(extRegex, view.file_name()):<tab><tab># only auto-format on save if there are no ""lint errors""<tab><tab># here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3<tab><tab>lints_regions = [""lint-keyword-underline"", ""lint-keyword-outline""]<tab><tab>for linter in lints_regions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>view.run_command(""js_format"")",if len ( view . get_regions ( linter ) ) :,198
1501,"def readMemory(self, va, size):<tab>for mva, mmaxva, mmap, mbytes in self._map_defs:<tab><tab>if mva <= va < mmaxva:<tab><tab><tab>mva, msize, mperms, mfname = mmap<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise envi.SegmentationViolation(va)<tab><tab><tab>offset = va - mva<tab><tab><tab>return mbytes[offset : offset + size]<tab>raise envi.SegmentationViolation(va)",if not mperms & MM_READ :,127
1502,"def assertFilepathsEqual(self, p1, p2):<tab>if sys.platform == ""win32"":<tab><tab><IF-STMT><tab><tab><tab>p1 = [normcase(normpath(x)) for x in p1]<tab><tab><tab>p2 = [normcase(normpath(x)) for x in p2]<tab><tab>else:<tab><tab><tab>assert isinstance(p1, (str, unicode))<tab><tab><tab>p1 = normcase(normpath(p1))<tab><tab><tab>p2 = normcase(normpath(p2))<tab>self.assertEqual(p1, p2)","if isinstance ( p1 , ( list , tuple ) ) :",140
1503,"def add_directory_csv_files(dir_path, paths=None):<tab>if not paths:<tab><tab>paths = []<tab>for p in listdir(dir_path):<tab><tab>path = join(dir_path, p)<tab><tab>if isdir(path):<tab><tab><tab># call recursively for each dir<tab><tab><tab>paths = add_directory_csv_files(path, paths)<tab><tab><IF-STMT><tab><tab><tab># add every file to the list<tab><tab><tab>paths.append(path)<tab>return paths","elif isfile ( path ) and path . endswith ( "".csv"" ) :",130
1504,"def _verifySubs(self):<tab>for inst in self.subs:<tab><tab><IF-STMT><tab><tab><tab>raise BlockError(_error.ArgType % (self.name,))<tab><tab>if isinstance(inst, (_Block, _Instantiator)):<tab><tab><tab>if not inst.modctxt:<tab><tab><tab><tab>raise BlockError(_error.InstanceError % (self.name, inst.callername))","if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :",110
1505,"def __annotations_bytes(self):<tab>if self.annotations:<tab><tab>a = []<tab><tab>for k, v in self.annotations.items():<tab><tab><tab>if len(k) != 4:<tab><tab><tab><tab>raise errors.ProtocolError(""annotation key must be of length 4"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>k = k.encode(""ASCII"")<tab><tab><tab>a.append(struct.pack(""!4sH"", k, len(v)))<tab><tab><tab>a.append(v)<tab><tab>return b"""".join(a)<tab>return b""""","if sys . version_info >= ( 3 , 0 ) :",143
1506,"def session(self, profile: str = ""default"", region: str = None) -> boto3.Session:<tab>region = self._get_region(region, profile)<tab>try:<tab><tab>session = self._cache_lookup(<tab><tab><tab>self._session_cache,<tab><tab><tab>[profile, region],<tab><tab><tab>self._boto3.Session,<tab><tab><tab>[],<tab><tab><tab>{""region_name"": region, ""profile_name"": profile},<tab><tab>)<tab>except ProfileNotFound:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>session = self._boto3.Session(region_name=region)<tab><tab>self._cache_set(self._session_cache, [profile, region], session)<tab>return session","if profile != ""default"" :",174
1507,"def spans_score(gold_spans, system_spans):<tab>correct, gi, si = 0, 0, 0<tab>while gi < len(gold_spans) and si < len(system_spans):<tab><tab>if system_spans[si].start < gold_spans[gi].start:<tab><tab><tab>si += 1<tab><tab><IF-STMT><tab><tab><tab>gi += 1<tab><tab>else:<tab><tab><tab>correct += gold_spans[gi].end == system_spans[si].end<tab><tab><tab>si += 1<tab><tab><tab>gi += 1<tab>return Score(len(gold_spans), len(system_spans), correct)",elif gold_spans [ gi ] . start < system_spans [ si ] . start :,160
1508,"def to_api(tag, raw_value):<tab>try:<tab><tab>api_tag, converter = _QL_TO_SC[tag] if tag else (""q"", None)<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>raise self.error(<tab><tab><tab><tab>""Unsupported '%s' tag. Try: %s"" % (tag, "", "".join(SUPPORTED))<tab><tab><tab>)<tab><tab>return None, None<tab>else:<tab><tab>value = str(converter(raw_value) if converter else raw_value)<tab><tab>return api_tag, value",if tag not in SUPPORTED :,137
1509,"def unpack(self, buf):<tab>dpkt.Packet.unpack(self, buf)<tab>buf = buf[self.__hdr_len__ :]<tab># single-byte IE<tab>if self.type & 0x80:<tab><tab>self.len = 0<tab><tab>self.data = b""""<tab># multi-byte IE<tab>else:<tab><tab># special PER-encoded UUIE<tab><tab><IF-STMT><tab><tab><tab>self.len = struct.unpack("">H"", buf[:2])[0]<tab><tab><tab>buf = buf[2:]<tab><tab># normal TLV-like IE<tab><tab>else:<tab><tab><tab>self.len = struct.unpack(""B"", buf[:1])[0]<tab><tab><tab>buf = buf[1:]<tab><tab>self.data = buf[: self.len]",if self . type == USER_TO_USER :,195
1510,"def on_bt_search_clicked(self, widget):<tab>if self.current_provider is None:<tab><tab>return<tab>query = self.en_query.get_text()<tab>@self.obtain_podcasts_with<tab>def load_data():<tab><tab><IF-STMT><tab><tab><tab>return self.current_provider.on_search(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_URL:<tab><tab><tab>return self.current_provider.on_url(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_FILE:<tab><tab><tab>return self.current_provider.on_file(query)",if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,172
1511,"def _text(bitlist):<tab>out = """"<tab>for typ, text in bitlist:<tab><tab>if not typ:<tab><tab><tab>out += text<tab><tab><IF-STMT><tab><tab><tab>out += ""\\fI%s\\fR"" % text<tab><tab>elif typ in [""strong"", ""code""]:<tab><tab><tab>out += ""\\fB%s\\fR"" % text<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected tag %r inside text"" % (typ,))<tab>out = out.strip()<tab>out = re.sub(re.compile(r""^\s+"", re.M), """", out)<tab>return out","elif typ == ""em"" :",150
1512,"def process(self, buckets):<tab>with self.executor_factory(max_workers=3) as w:<tab><tab>futures = {}<tab><tab>results = []<tab><tab>for b in buckets:<tab><tab><tab>futures[w.submit(self.process_bucket, b)] = b<tab><tab>for f in as_completed(futures):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>b = futures[f]<tab><tab><tab><tab>self.log.error(<tab><tab><tab><tab><tab>""error modifying bucket:%s\n%s"", b[""Name""], f.exception()<tab><tab><tab><tab>)<tab><tab><tab>results += filter(None, [f.result()])<tab><tab>return results",if f . exception ( ) :,160
1513,"def check_settings(self):<tab>if self.settings_dict[""TIME_ZONE""] is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because USE_TZ is ""<tab><tab><tab><tab>""False."" % self.alias<tab><tab><tab>)<tab><tab>elif self.features.supports_timezones:<tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because its engine ""<tab><tab><tab><tab>""handles time zones conversions natively."" % self.alias<tab><tab><tab>)",if not settings . USE_TZ :,140
1514,"def process_webhook_prop(namespace):<tab>if not isinstance(namespace.webhook_properties, list):<tab><tab>return<tab>result = {}<tab>for each in namespace.webhook_properties:<tab><tab>if each:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key, value = each.split(""="", 1)<tab><tab><tab>else:<tab><tab><tab><tab>key, value = each, """"<tab><tab><tab>result[key] = value<tab>namespace.webhook_properties = result","if ""="" in each :",111
1515,"def _expand_query_values(original_query_list):<tab>query_list = []<tab>for key, value in original_query_list:<tab><tab><IF-STMT><tab><tab><tab>query_list.append((key, value))<tab><tab>else:<tab><tab><tab>key_fmt = key + ""[%s]""<tab><tab><tab>value_list = _to_kv_list(value)<tab><tab><tab>query_list.extend((key_fmt % k, v) for k, v in value_list)<tab>return query_list","if isinstance ( value , basestring ) :",127
1516,"def tags():<tab>""""""Return a dictionary of all tags in the form {hash: [tag_names, ...]}.""""""<tab>tags = {}<tab>for (n, c) in list_refs():<tab><tab>if n.startswith(""refs/tags/""):<tab><tab><tab>name = n[10:]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tags[c] = []<tab><tab><tab>tags[c].append(name)  # more than one tag can point at 'c'<tab>return tags",if not c in tags :,116
1517,"def test_colorspiral(self):<tab>""""""Set of 625 colours, with jitter, using get_colors().""""""<tab>boxedge = 20<tab>boxes_per_row = 25<tab>rows = 0<tab>for i, c in enumerate(get_colors(625)):<tab><tab>self.c.setFillColor(c)<tab><tab>x1 = boxedge * (i % boxes_per_row)<tab><tab>y1 = rows * boxedge<tab><tab>self.c.rect(x1, y1, boxedge, boxedge, fill=1, stroke=0)<tab><tab><IF-STMT><tab><tab><tab>rows += 1<tab>self.finish()",if not ( i + 1 ) % boxes_per_row :,164
1518,"def oldest_pending_update_in_days():<tab>""""""Return the datestamp of the oldest pending update""""""<tab>pendingupdatespath = os.path.join(<tab><tab>prefs.pref(""ManagedInstallDir""), ""UpdateNotificationTracking.plist""<tab>)<tab>try:<tab><tab>pending_updates = FoundationPlist.readPlist(pendingupdatespath)<tab>except FoundationPlist.NSPropertyListSerializationException:<tab><tab>return 0<tab>oldest_date = now = NSDate.date()<tab>for category in pending_updates:<tab><tab>for name in pending_updates[category]:<tab><tab><tab>this_date = pending_updates[category][name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>oldest_date = this_date<tab>return now.timeIntervalSinceDate_(oldest_date) / (24 * 60 * 60)",if this_date < oldest_date :,199
1519,"def _try_read_gpg(path):<tab>path = os.path.expanduser(path)<tab>cmd = _gpg_cmd() + [path]<tab>log.debug(""gpg cmd: %s"", cmd)<tab>try:<tab><tab>p = subprocess.Popen(<tab><tab><tab>cmd, env=os.environ, stdout=subprocess.PIPE, stderr=subprocess.PIPE<tab><tab>)<tab>except OSError as e:<tab><tab>log.error(""cannot decode %s with command '%s' (%s)"", path, "" "".join(cmd), e)<tab>else:<tab><tab>out, err = p.communicate()<tab><tab><IF-STMT><tab><tab><tab>log.error(err.decode(errors=""replace"").strip())<tab><tab><tab>return None<tab><tab>return out.decode(errors=""replace"")",if p . returncode != 0 :,190
1520,"def sort_nested_dictionary_lists(d):<tab>for k, v in d.items():<tab><tab><IF-STMT><tab><tab><tab>for i in range(0, len(v)):<tab><tab><tab><tab>if isinstance(v[i], dict):<tab><tab><tab><tab><tab>v[i] = await sort_nested_dictionary_lists(v[i])<tab><tab><tab><tab>d[k] = sorted(v)<tab><tab>if isinstance(v, dict):<tab><tab><tab>d[k] = await sort_nested_dictionary_lists(v)<tab>return d","if isinstance ( v , list ) :",134
1521,"def _the_callback(widget, event_id):<tab>point = widget.GetCenter()<tab>index = widget.WIDGET_INDEX<tab>if hasattr(callback, ""__call__""):<tab><tab><IF-STMT><tab><tab><tab>args = [point, index]<tab><tab>else:<tab><tab><tab>args = [point]<tab><tab>if pass_widget:<tab><tab><tab>args.append(widget)<tab><tab>try_callback(callback, *args)<tab>return",if num > 1 :,109
1522,"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None):<tab>new_parameters = []<tab>for hp in sub_cs.get_hyperparameters():<tab><tab>new_parameter = copy.deepcopy(hp)<tab><tab># Allow for an empty top-level parameter<tab><tab><IF-STMT><tab><tab><tab>new_parameter.name = prefix<tab><tab>elif not prefix == """":<tab><tab><tab>new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name)<tab><tab>new_parameters.append(new_parameter)<tab>for hp in new_parameters:<tab><tab>_add_hp(master_cs, hp)","if new_parameter . name == """" :",162
1523,"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.server.stop()<tab><tab>if self.sl_hdlr:<tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",if self . server :,92
1524,"def app_uninstall_all(self, excludes=[], verbose=False):<tab>""""""Uninstall all apps""""""<tab>our_apps = [""com.github.uiautomator"", ""com.github.uiautomator.test""]<tab>output, _ = self.shell([""pm"", ""list"", ""packages"", ""-3""])<tab>pkgs = re.findall(r""package:([^\s]+)"", output)<tab>pkgs = set(pkgs).difference(our_apps + excludes)<tab>pkgs = list(pkgs)<tab>for pkg_name in pkgs:<tab><tab><IF-STMT><tab><tab><tab>print(""uninstalling"", pkg_name, "" "", end="""", flush=True)<tab><tab>ok = self.app_uninstall(pkg_name)<tab><tab>if verbose:<tab><tab><tab>print(""OK"" if ok else ""FAIL"")<tab>return pkgs",if verbose :,188
1525,"def httpapi(self, arg, opts):<tab>sc = HttpAPIStatsCollector()<tab>headers = [""#Item"", ""Value""]<tab>table = []<tab>for k, v in sc.get().getStats().items():<tab><tab>if isinstance(v, dict):<tab><tab><tab>v = json.dumps(v)<tab><tab>row = []<tab><tab>row.append(""#%s"" % k)<tab><tab><IF-STMT><tab><tab><tab>row.append(formatDateTime(v))<tab><tab>else:<tab><tab><tab>row.append(v)<tab><tab>table.append(row)<tab>self.protocol.sendData(<tab><tab>tabulate(table, headers, tablefmt=""plain"", numalign=""left"").encode(""ascii"")<tab>)","if k [ - 3 : ] == ""_at"" :",178
1526,"def Get_Gene(self, id):<tab>""""""Retreive the gene name (GN).""""""<tab>entry = self.Get(id)<tab>if not entry:<tab><tab>return None<tab>GN = """"<tab>for line in string.split(entry, ""\n""):<tab><tab><IF-STMT><tab><tab><tab>GN = string.strip(line[5:])<tab><tab><tab>if GN[-1] == ""."":<tab><tab><tab><tab>GN = GN[0:-1]<tab><tab><tab>return GN<tab><tab>if line[0:2] == ""//"":<tab><tab><tab>break<tab>return GN","if line [ 0 : 5 ] == ""GN   "" :",150
1527,"def replace_dir_vars(path, d):<tab>""""""Replace common directory paths with appropriate variable references (e.g. /etc becomes ${sysconfdir})""""""<tab>dirvars = {}<tab># Sort by length so we get the variables we're interested in first<tab>for var in sorted(list(d.keys()), key=len):<tab><tab>if var.endswith(""dir"") and var.lower() == var:<tab><tab><tab>value = d.getVar(var)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dirvars[value] = var<tab>for dirpath in sorted(list(dirvars.keys()), reverse=True):<tab><tab>path = path.replace(dirpath, ""${%s}"" % dirvars[dirpath])<tab>return path","if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :",184
1528,"def _scrub_generated_timestamps(self, target_workdir):<tab>""""""Remove the first line of comment from each file if it contains a timestamp.""""""<tab>for root, _, filenames in safe_walk(target_workdir):<tab><tab>for filename in filenames:<tab><tab><tab>source = os.path.join(root, filename)<tab><tab><tab>with open(source, ""r"") as f:<tab><tab><tab><tab>lines = f.readlines()<tab><tab><tab>if len(lines) < 1:<tab><tab><tab><tab>return<tab><tab><tab>with open(source, ""w"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>f.write(lines[0])<tab><tab><tab><tab>for line in lines[1:]:<tab><tab><tab><tab><tab>f.write(line)",if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,196
1529,"def get_all_active_plugins(self) -> List[BotPlugin]:<tab>""""""This returns the list of plugins in the callback ordered defined from the config.""""""<tab>all_plugins = []<tab>for name in self.plugins_callback_order:<tab><tab># None is a placeholder for any plugin not having a defined order<tab><tab><IF-STMT><tab><tab><tab>all_plugins += [<tab><tab><tab><tab>plugin<tab><tab><tab><tab>for name, plugin in self.plugins.items()<tab><tab><tab><tab>if name not in self.plugins_callback_order and plugin.is_activated<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>plugin = self.plugins[name]<tab><tab><tab>if plugin.is_activated:<tab><tab><tab><tab>all_plugins.append(plugin)<tab>return all_plugins",if name is None :,186
1530,"def test_query_level(self):<tab>""Tests querying at a level other than max""<tab># level 2<tab>l2 = set()<tab>for p in self.tile_paths:<tab><tab>l2.add(p[0:2])<tab>for path in iterate_base4(2):<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(self.tree.query_path(path))<tab><tab>else:<tab><tab><tab>self.assertFalse(self.tree.query_path(path))<tab># level 1:<tab>self.assertTrue(self.tree.query_path((0,)))<tab>self.assertTrue(self.tree.query_path((1,)))<tab>self.assertTrue(self.tree.query_path((2,)))<tab>self.assertFalse(self.tree.query_path((3,)))",if path in l2 :,191
1531,"def program_exists(name):<tab>paths = (os.getenv(""PATH"") or os.defpath).split(os.pathsep)<tab>for p in paths:<tab><tab>fn = ""%s/%s"" % (p, name)<tab><tab><IF-STMT><tab><tab><tab>return not os.path.isdir(fn) and os.access(fn, os.X_OK)",if os . path . exists ( fn ) :,93
1532,"def decoration_helper(self, patched, args, keywargs):<tab>extra_args = []<tab>with contextlib.ExitStack() as exit_stack:<tab><tab>for patching in patched.patchings:<tab><tab><tab>arg = exit_stack.enter_context(patching)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keywargs.update(arg)<tab><tab><tab>elif patching.new is DEFAULT:<tab><tab><tab><tab>extra_args.append(arg)<tab><tab>args += tuple(extra_args)<tab><tab>yield (args, keywargs)",if patching . attribute_name is not None :,134
1533,"def update_neighbor(neigh_ip_address, changes):<tab>rets = []<tab>for k, v in changes.items():<tab><tab>if k == neighbors.MULTI_EXIT_DISC:<tab><tab><tab>rets.append(_update_med(neigh_ip_address, v))<tab><tab><IF-STMT><tab><tab><tab>rets.append(update_neighbor_enabled(neigh_ip_address, v))<tab><tab>if k == neighbors.CONNECT_MODE:<tab><tab><tab>rets.append(_update_connect_mode(neigh_ip_address, v))<tab>return all(rets)",if k == neighbors . ENABLED :,138
1534,"def calcUniqueStates(self):<tab># Here we show which colors can be relied on to map to an<tab># internal state.  The current position will be at the first<tab># character in the buffer styled that color, so this might not<tab># work in all cases.<tab>self.uniqueStates = {}<tab>for k in self.holdUniqueStates.keys():<tab><tab>v = self.holdUniqueStates[k]<tab><tab><IF-STMT><tab><tab><tab>self.uniqueStates[k] = v.keys()[0]<tab><tab><tab>log.debug(""Map style [%s] to state [%s]"", k, v.keys()[0])<tab><tab>log.debug(""Style [%s] maps to states [%s]"", k, "", "".join(v.keys()))<tab>self.holdUniqueStates = None",if len ( v . keys ( ) ) == 1 :,191
1535,"def init_logger():<tab>configured_loggers = [log_config.get(""root"", {})] + [<tab><tab>logger for logger in log_config.get(""loggers"", {}).values()<tab>]<tab>used_handlers = {<tab><tab>handler for log in configured_loggers for handler in log.get(""handlers"", [])<tab>}<tab>for handler_id, handler in list(log_config[""handlers""].items()):<tab><tab><IF-STMT><tab><tab><tab>del log_config[""handlers""][handler_id]<tab><tab>elif ""filename"" in handler.keys():<tab><tab><tab>filename = handler[""filename""]<tab><tab><tab>logfile_path = Path(filename).expanduser().resolve()<tab><tab><tab>handler[""filename""] = str(logfile_path)<tab>logging.config.dictConfig(log_config)",if handler_id not in used_handlers :,192
1536,"def _selected_machines(self, virtual_machines):<tab>selected_machines = []<tab>for machine in virtual_machines:<tab><tab><IF-STMT><tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.tags and self._tags_match(machine.tags, self.tags):<tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.locations and machine.location in self.locations:<tab><tab><tab>selected_machines.append(machine)<tab>return selected_machines",if self . _args . host and self . _args . host == machine . name :,129
1537,"def init(self):<tab>r = self.get_redis()<tab>if r:<tab><tab>key = ""pocsuite_target""<tab><tab>info_msg = ""[PLUGIN] try fetch targets from redis...""<tab><tab>logger.info(info_msg)<tab><tab>targets = r.get(key)<tab><tab>count = 0<tab><tab>if targets:<tab><tab><tab>for target in targets:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>count += 1<tab><tab>info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count)<tab><tab>logger.info(info_msg)",if self . add_target ( target ) :,151
1538,"def tearDown(self):<tab>suffix = str(os.getgid())<tab>cli = monitoring_v3.MetricServiceClient()<tab>for md in cli.list_metric_descriptors(""projects/{}"".format(PROJECT)):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>cli.delete_metric_descriptor(md.name)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass","if ""OpenCensus"" in md . name and suffix in md . name :",106
1539,"def InitializeColours(self):<tab>""""""Initializes the 16 custom colours in :class:`CustomPanel`.""""""<tab>curr = self._colourData.GetColour()<tab>self._colourSelection = -1<tab>for i in range(16):<tab><tab>c = self._colourData.GetCustomColour(i)<tab><tab>if c.IsOk():<tab><tab><tab>self._customColours[i] = self._colourData.GetCustomColour(i)<tab><tab>else:<tab><tab><tab>self._customColours[i] = wx.WHITE<tab><tab><IF-STMT><tab><tab><tab>self._colourSelection = i",if c == curr :,147
1540,"def __getitem__(self, index):<tab>if self._check():<tab><tab>if isinstance(index, int):<tab><tab><tab>if index < 0 or index >= len(self.features):<tab><tab><tab><tab>raise IndexError(index)<tab><tab><tab>if self.features[index] is None:<tab><tab><tab><tab>feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>(feature,) = _unpack(""!H"", feature[:2])<tab><tab><tab><tab><tab>self.features[index] = FEATURE[feature]<tab><tab><tab>return self.features[index]<tab><tab>elif isinstance(index, slice):<tab><tab><tab>indices = index.indices(len(self.features))<tab><tab><tab>return [self.__getitem__(i) for i in range(*indices)]",if feature :,195
1541,"def _get_data_from_buffer(obj):<tab>try:<tab><tab>view = memoryview(obj)<tab>except TypeError:<tab><tab># try to use legacy buffer protocol if 2.7, otherwise re-raise<tab><tab><IF-STMT><tab><tab><tab>view = memoryview(buffer(obj))<tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""using old buffer interface to unpack %s; ""<tab><tab><tab><tab>""this leads to unpacking errors if slicing is used and ""<tab><tab><tab><tab>""will be removed in a future version"" % type(obj),<tab><tab><tab><tab>RuntimeWarning,<tab><tab><tab><tab>stacklevel=3,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise<tab>if view.itemsize != 1:<tab><tab>raise ValueError(""cannot unpack from multi-byte object"")<tab>return view",if PY2 :,188
1542,"def import_modules(modules, safe=True):<tab>""""""Safely import a list of *modules*""""""<tab>all = []<tab>for mname in modules:<tab><tab>if mname.endswith("".*""):<tab><tab><tab>to_load = expand_star(mname)<tab><tab>else:<tab><tab><tab>to_load = [mname]<tab><tab>for module in to_load:<tab><tab><tab>try:<tab><tab><tab><tab>all.append(import_module(module))<tab><tab><tab>except ImportError:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise<tab>return all",if not safe :,139
1543,"def pack(types, *args):<tab>if len(types) != len(args):<tab><tab>raise Exception(""number of arguments does not match format string"")<tab>port = StringIO()<tab>for (type, value) in zip(types, args):<tab><tab>if type == ""V"":<tab><tab><tab>write_vuint(port, value)<tab><tab><IF-STMT><tab><tab><tab>write_vint(port, value)<tab><tab>elif type == ""s"":<tab><tab><tab>write_bvec(port, value)<tab><tab>else:<tab><tab><tab>raise Exception('unknown xpack format string item ""' + type + '""')<tab>return port.getvalue()","elif type == ""v"" :",153
1544,"def create_local_app_folder(local_app_path):<tab>if exists(local_app_path):<tab><tab>raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path)<tab>for folder in subfolders(local_app_path):<tab><tab><IF-STMT><tab><tab><tab>os.mkdir(folder)<tab><tab><tab>init_path = join(folder, ""__init__.py"")<tab><tab><tab>if not exists(init_path):<tab><tab><tab><tab>create_file(init_path)",if not exists ( folder ) :,126
1545,"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any:<tab>fields = self.config[fields_key]<tab>node_tags = self.provider.node_tags(node_id)<tab>if TAG_RAY_USER_NODE_TYPE in node_tags:<tab><tab>node_type = node_tags[TAG_RAY_USER_NODE_TYPE]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(f""Unknown node type tag: {node_type}."")<tab><tab>node_specific_config = self.available_node_types[node_type]<tab><tab>if fields_key in node_specific_config:<tab><tab><tab>fields = node_specific_config[fields_key]<tab>return fields",if node_type not in self . available_node_types :,189
1546,"def _maybe_fix_sequence_in_union(<tab>aliases: List[Alias], typecst: cst.SubscriptElement) -> cst.SubscriptElement:<tab>slc = typecst.slice<tab>if isinstance(slc, cst.Index):<tab><tab>val = slc.value<tab><tab><IF-STMT><tab><tab><tab>return cst.ensure_type(<tab><tab><tab><tab>typecst.deep_replace(val, _get_clean_type_from_subscript(aliases, val)),<tab><tab><tab><tab>cst.SubscriptElement,<tab><tab><tab>)<tab>return typecst","if isinstance ( val , cst . Subscript ) :",144
1547,"def cancel_download(self, downloads):<tab># Make sure we're always dealing with a list<tab>if isinstance(downloads, Download):<tab><tab>downloads = [downloads]<tab>for download in downloads:<tab><tab><IF-STMT><tab><tab><tab>self.cancel_current_download()<tab><tab>else:<tab><tab><tab>self.__paused = True<tab><tab><tab>new_queue = queue.Queue()<tab><tab><tab>while not self.__queue.empty():<tab><tab><tab><tab>queued_download = self.__queue.get()<tab><tab><tab><tab>if download == queued_download:<tab><tab><tab><tab><tab>download.cancel()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>new_queue.put(queued_download)<tab><tab><tab>self.__queue = new_queue<tab><tab><tab>self.__paused = False",if download == self . __current_download :,188
1548,"def migrate_account_metadata(account_id):<tab>from inbox.models.session import session_scope<tab>from inbox.models import Account<tab>with session_scope(versioned=False) as db_session:<tab><tab>account = db_session.query(Account).get(account_id)<tab><tab>if account.discriminator == ""easaccount"":<tab><tab><tab>create_categories_for_easfoldersyncstatuses(account, db_session)<tab><tab>else:<tab><tab><tab>create_categories_for_folders(account, db_session)<tab><tab><IF-STMT><tab><tab><tab>set_labels_for_imapuids(account, db_session)<tab><tab>db_session.commit()","if account . discriminator == ""gmailaccount"" :",168
1549,"def __init__(self, fmt=None, *args):<tab>if not isinstance(fmt, BaseException):<tab><tab>Error.__init__(self, fmt, *args)<tab>else:<tab><tab>e = fmt<tab><tab>cls = e.__class__<tab><tab>fmt = ""%s.%s: %s"" % (cls.__module__, cls.__name__, e)<tab><tab>tb = sys.exc_info()[2]<tab><tab><IF-STMT><tab><tab><tab>fmt += ""\n""<tab><tab><tab>fmt += """".join(traceback.format_tb(tb))<tab><tab>Error.__init__(self, fmt)",if tb :,138
1550,"def setLabel(self, label):<tab>if label is None:<tab><tab><IF-STMT><tab><tab><tab>self.label.scene().removeItem(self.label)<tab><tab><tab>self.label = None<tab>else:<tab><tab>if self.label is None:<tab><tab><tab>self.label = TextItem()<tab><tab><tab>self.label.setParentItem(self)<tab><tab>self.label.setText(label)<tab><tab>self._updateLabel()",if self . label is not None :,112
1551,"def serve_until_stopped(self) -> None:<tab>while True:<tab><tab>rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout)<tab><tab><IF-STMT><tab><tab><tab>self.handle_request()<tab><tab>if self.event is not None and self.event.is_set():<tab><tab><tab>break",if rd :,83
1552,"def generateCompressedFile(inputfile, outputfile, formatstring):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>in_file = open(inputfile, ""rb"")<tab><tab><tab>in_data = in_file.read()<tab><tab><tab>out_file = open(inputfile + "".xz"", ""wb"")<tab><tab><tab>out_file.write(xz.compress(in_data))<tab><tab><tab>in_file.close()<tab><tab><tab>out_file.close()<tab><tab>else:<tab><tab><tab>tarout = tarfile.open(outputfile, formatstring)<tab><tab><tab>tarout.add(inputfile, arcname=os.path.basename(inputfile))<tab><tab><tab>tarout.close()<tab>except Exception as e:<tab><tab>print(e)<tab><tab>return False<tab>return True","if formatstring == ""w:xz"" :",191
1553,"def _datastore_get_handler(signal, sender, keys, **kwargs):<tab>txn = current_transaction()<tab>if txn:<tab><tab>for key in keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise PreventedReadError(<tab><tab><tab><tab><tab>""Attempted to read key (%s:%s) inside a transaction ""<tab><tab><tab><tab><tab>""where it was marked protected"" % (key.kind(), key.id_or_name())<tab><tab><tab><tab>)<tab><tab>txn._fetched_keys.update(set(keys))",if key in txn . _protected_keys :,130
1554,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_access_token(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_expiration_time(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,124
1555,"def write_vuint(port, x):<tab>if x < 0:<tab><tab>raise Exception(""vuints must not be negative"")<tab>elif x == 0:<tab><tab>port.write(""\0"")<tab>else:<tab><tab>while x:<tab><tab><tab>seven_bits = x & 0x7F<tab><tab><tab>x >>= 7<tab><tab><tab><IF-STMT><tab><tab><tab><tab>port.write(chr(0x80 | seven_bits))<tab><tab><tab>else:<tab><tab><tab><tab>port.write(chr(seven_bits))",if x :,129
1556,"def _expand_srcs(self):<tab>""""""Expand src to [(src, full_path)]""""""<tab>result = []<tab>for src in self.srcs:<tab><tab>full_path = self._source_file_path(src)<tab><tab><IF-STMT><tab><tab><tab># Assume generated<tab><tab><tab>full_path = self._target_file_path(src)<tab><tab>result.append((src, full_path))<tab>return result",if not os . path . exists ( full_path ) :,113
1557,"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/ops""):<tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))","if ""init"" not in item . keywords :",102
1558,"def set_shape(self, shape):<tab>""""""Sets a shape.""""""<tab>if self._shape is not None:<tab><tab>logger.warning('Modifying the shape of Placeholder ""%s"".', self.name)<tab>if not isinstance(shape, (list, tuple)):<tab><tab>shape = (shape,)<tab>shape = tuple(x if x != ""None"" else None for x in shape)<tab>for x in shape:<tab><tab><IF-STMT><tab><tab><tab>raise ParsingError(<tab><tab><tab><tab>'All entries in ""shape"" must be integers, or in special '<tab><tab><tab><tab>""cases None. Shape is: {}"".format(shape)<tab><tab><tab>)<tab>self._shape = shape","if not isinstance ( x , ( int , type ( None ) ) ) :",169
1559,"def _get_field_actual(cant_be_number, raw_string, field_names):<tab>for line in raw_string.splitlines():<tab><tab>for field_name in field_names:<tab><tab><tab>field_name = field_name.lower()<tab><tab><tab>if "":"" in line:<tab><tab><tab><tab>left, right = line.split("":"", 1)<tab><tab><tab><tab>left = left.strip().lower()<tab><tab><tab><tab>right = right.strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if cant_be_number:<tab><tab><tab><tab><tab><tab>if not right.isdigit():<tab><tab><tab><tab><tab><tab><tab>return right<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return right<tab>return None",if left == field_name and len ( right ) > 0 :,184
1560,"def validate_attributes(self):<tab>for attribute in self.get_all_attributes():<tab><tab>value = getattr(self, attribute.code, None)<tab><tab>if value is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code}<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>attribute.validate_value(value)<tab><tab><tab>except ValidationError as e:<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e}<tab><tab><tab><tab>)",if attribute . required :,168
1561,"def append(self, s):<tab>buf = self.buf<tab>if buf is None:<tab><tab>strbuf = self.strbuf<tab><tab><IF-STMT><tab><tab><tab>self.strbuf = strbuf + s<tab><tab><tab>return<tab><tab>buf = self._create_buffer()<tab>buf.append(s)<tab># use buf.__len__ rather than len(buf) FBO of not getting<tab># OverflowError on Python 2<tab>sz = buf.__len__()<tab>if not self.overflowed:<tab><tab>if sz >= self.overflow:<tab><tab><tab>self._set_large_buffer()",if len ( strbuf ) + len ( s ) < STRBUF_LIMIT :,154
1562,"def billing_invoice_show_validator(namespace):<tab>from azure.cli.core.azclierror import (<tab><tab>RequiredArgumentMissingError,<tab><tab>MutuallyExclusiveArgumentError,<tab>)<tab>valid_combs = (<tab><tab>""only --account-name, --name / --name / --name, --by-subscription is valid""<tab>)<tab>if namespace.account_name is not None:<tab><tab><IF-STMT><tab><tab><tab>raise MutuallyExclusiveArgumentError(valid_combs)<tab><tab>if namespace.name is None:<tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")<tab>if namespace.by_subscription is not None:<tab><tab>if namespace.name is None:<tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")",if namespace . by_subscription is not None :,188
1563,"def Handle(self, args, context=None):<tab>for client_id in args.client_ids:<tab><tab>cid = str(client_id)<tab><tab>data_store.REL_DB.RemoveClientLabels(cid, context.username, args.labels)<tab><tab>labels_to_remove = set(args.labels)<tab><tab>existing_labels = data_store.REL_DB.ReadClientLabels(cid)<tab><tab>for label in existing_labels:<tab><tab><tab>labels_to_remove.discard(label.name)<tab><tab><IF-STMT><tab><tab><tab>idx = client_index.ClientIndex()<tab><tab><tab>idx.RemoveClientLabels(cid, labels_to_remove)",if labels_to_remove :,164
1564,"def delete_snapshot(self, snapshot):<tab>snap_name = self._get_snap_name(snapshot[""id""])<tab>LOG.debug(""Deleting snapshot (%s)"", snapshot[""id""])<tab>self.client_login()<tab>try:<tab><tab>self.client.delete_snapshot(snap_name, self.backend_type)<tab>except exception.DotHillRequestError as ex:<tab><tab># if the volume wasn't found, ignore the error<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>LOG.exception(""Deleting snapshot %s failed"", snapshot[""id""])<tab><tab>raise exception.Invalid(ex)<tab>finally:<tab><tab>self.client_logout()","if ""The volume was not found on this system."" in ex . args :",165
1565,"def jobs(self):<tab># How many jobs have we done?<tab>total_processed = 0<tab>for jobEntity in self.jobItems.query_entities():<tab><tab># Process the items in the page<tab><tab>yield AzureJob.fromEntity(jobEntity)<tab><tab>total_processed += 1<tab><tab><IF-STMT><tab><tab><tab># Produce some feedback for the user, because this can take<tab><tab><tab># a long time on, for example, Azure<tab><tab><tab>logger.debug(""Processed %d total jobs"" % total_processed)<tab>logger.debug(""Processed %d total jobs"" % total_processed)",if total_processed % 1000 == 0 :,153
1566,def run(self):<tab>while not self.completed:<tab><tab>if self.block:<tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab>if self.timeout is not None:<tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab>if dt > self.timeout:<tab><tab><tab><tab>self.stop()<tab><tab><IF-STMT><tab><tab><tab>self.stop(),if self . counter == self . count :,159
1567,"def get_instance(cls, pool_size=None):<tab>if cls._instance is not None:<tab><tab>return cls._instance<tab># Lazy init<tab>with cls._SINGLETON_LOCK:<tab><tab><IF-STMT><tab><tab><tab>cls._instance = cls(<tab><tab><tab><tab>ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size<tab><tab><tab>)<tab>return cls._instance",if cls . _instance is None :,102
1568,"def set_state(self, state):<tab>if self._inhibit_play:<tab><tab># PLAYING, PAUSED change the state for after buffering is finished,<tab><tab># everything else aborts buffering<tab><tab><IF-STMT><tab><tab><tab># abort<tab><tab><tab>self.__set_inhibit_play(False)<tab><tab><tab>self.bin.set_state(state)<tab><tab><tab>return<tab><tab>self._wanted_state = state<tab>else:<tab><tab>self.bin.set_state(state)","if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :",136
1569,"def seen_add(options):<tab>seen_name = options.add_value<tab>if is_imdb_url(seen_name):<tab><tab>console(""IMDB url detected, try to parse ID"")<tab><tab>imdb_id = extract_id(seen_name)<tab><tab><IF-STMT><tab><tab><tab>seen_name = imdb_id<tab><tab>else:<tab><tab><tab>console(""Could not parse IMDB ID"")<tab>db.add(seen_name, ""cli_add"", {""cli_add"": seen_name})<tab>console(""Added %s as seen. This will affect all tasks."" % seen_name)",if imdb_id :,144
1570,"def test_204_invalid_content_length(self):<tab># 204 status with non-zero content length is malformed<tab>with ExpectLog(gen_log, "".*Response with code 204 should not have body""):<tab><tab>response = self.fetch(""/?error=1"")<tab><tab>if not self.http1:<tab><tab><tab>self.skipTest(""requires HTTP/1.x"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""curl client accepts invalid headers"")<tab><tab>self.assertEqual(response.code, 599)",if self . http_client . configured_class != SimpleAsyncHTTPClient :,136
1571,"def set_related_perm(_mapper: Mapper, _connection: Connection, target: Slice) -> None:<tab>src_class = target.cls_model<tab>id_ = target.datasource_id<tab>if id_:<tab><tab>ds = db.session.query(src_class).filter_by(id=int(id_)).first()<tab><tab><IF-STMT><tab><tab><tab>target.perm = ds.perm<tab><tab><tab>target.schema_perm = ds.schema_perm",if ds :,110
1572,"def on_modified_async(self, view):<tab>if self.is_command_line(view):<tab><tab><IF-STMT><tab><tab><tab>view.run_command(""text_pastry_selection_preview"")","if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :",76
1573,"def _improve_answer_span(<tab>doc_tokens, input_start, input_end, tokenizer, orig_answer_text):<tab>""""""Returns tokenized answer spans that better match the annotated answer.""""""<tab>tok_answer_text = "" "".join(tokenizer.tokenize(orig_answer_text))<tab>for new_start in range(input_start, input_end + 1):<tab><tab>for new_end in range(input_end, new_start - 1, -1):<tab><tab><tab>text_span = "" "".join(doc_tokens[new_start : (new_end + 1)])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return new_start, new_end<tab>return input_start, input_end",if text_span == tok_answer_text :,174
1574,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_app_version_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_method(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 34:<tab><tab><tab>self.set_queue(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,184
1575,"def _add_resource_group(obj):<tab>if isinstance(obj, list):<tab><tab>for array_item in obj:<tab><tab><tab>_add_resource_group(array_item)<tab>elif isinstance(obj, dict):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if obj[""id""]:<tab><tab><tab><tab><tab>obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""]<tab><tab>except (KeyError, IndexError, TypeError):<tab><tab><tab>pass<tab><tab>for item_key in obj:<tab><tab><tab>if item_key != ""sourceVault"":<tab><tab><tab><tab>_add_resource_group(obj[item_key])","if ""resourcegroup"" not in [ x . lower ( ) for x in obj . keys ( ) ] :",175
1576,"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], DECODE)<tab>version = DECODE_VERSION<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,183
1577,"def toterminal(self, tw):<tab># the entries might have different styles<tab>last_style = None<tab>for i, entry in enumerate(self.reprentries):<tab><tab><IF-STMT><tab><tab><tab>tw.line("""")<tab><tab>entry.toterminal(tw)<tab><tab>if i < len(self.reprentries) - 1:<tab><tab><tab>next_entry = self.reprentries[i + 1]<tab><tab><tab>if (<tab><tab><tab><tab>entry.style == ""long""<tab><tab><tab><tab>or entry.style == ""short""<tab><tab><tab><tab>and next_entry.style == ""long""<tab><tab><tab>):<tab><tab><tab><tab>tw.sep(self.entrysep)<tab>if self.extraline:<tab><tab>tw.line(self.extraline)","if entry . style == ""long"" :",198
1578,"def reposition_division(f1):<tab>lines = f1.splitlines()<tab>if lines[2] == division:<tab><tab>lines.pop(2)<tab>found = 0<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>found += 1<tab><tab><tab>if found == 2:<tab><tab><tab><tab>if division in ""\n"".join(lines):<tab><tab><tab><tab><tab>break  # already in the right place<tab><tab><tab><tab>lines.insert(i + 1, """")<tab><tab><tab><tab>lines.insert(i + 2, division)<tab><tab><tab><tab>break<tab>return ""\n"".join(lines)","if line . startswith ( '""""""' ) :",153
1579,def run_on_module(self):<tab>try:<tab><tab>self.module_base.disable(self.opts.module_spec)<tab>except dnf.exceptions.MarkingErrors as e:<tab><tab>if self.base.conf.strict:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab><tab><tab>if (<tab><tab><tab><tab>e.module_depsolv_errors<tab><tab><tab><tab>and e.module_depsolv_errors[1]<tab><tab><tab><tab>!= libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS<tab><tab><tab>):<tab><tab><tab><tab>raise e<tab><tab>logger.error(str(e)),if e . no_match_group_specs or e . error_group_specs :,174
1580,"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab><IF-STMT><tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64mime.base64_len(""x"" * size), bsize)",elif size <= 9 :,160
1581,"def is_valid(self):<tab>""""""Determines whether file is valid for this reader""""""<tab>blocklist = self.open()<tab>valid = True<tab>for line in blocklist:<tab><tab>line = decode_bytes(line)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>(start, end) = self.parse(line)<tab><tab><tab><tab>if not re.match(r""^(\d{1,3}\.){4}$"", start + ""."") or not re.match(<tab><tab><tab><tab><tab>r""^(\d{1,3}\.){4}$"", end + "".""<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>valid = False<tab><tab><tab>except Exception:<tab><tab><tab><tab>valid = False<tab><tab><tab>break<tab>blocklist.close()<tab>return valid",if not self . is_ignored ( line ) :,188
1582,"def next(self):<tab>while self.index < len(self.data):<tab><tab>uid = self._read_next_word()<tab><tab>dont_care = self._read_next_word()<tab><tab>entry = self._read_next_string()<tab><tab>total_size = int(4 + 4 + len(entry))<tab><tab>count = int(total_size / self.SIZE)<tab><tab>if count == 0:<tab><tab><tab>mod = self.SIZE - total_size<tab><tab>else:<tab><tab><tab>mod = self.SIZE - int(total_size - (count * self.SIZE))<tab><tab><IF-STMT><tab><tab><tab>remainder = self._read_next_block(mod)<tab><tab>yield (uid, entry)",if mod > 0 :,175
1583,"def _str_param_list(self, name):<tab>out = []<tab>if self[name]:<tab><tab>out += self._str_header(name)<tab><tab>for param in self[name]:<tab><tab><tab>parts = []<tab><tab><tab>if param.name:<tab><tab><tab><tab>parts.append(param.name)<tab><tab><tab>if param.type:<tab><tab><tab><tab>parts.append(param.type)<tab><tab><tab>out += ["" : "".join(parts)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out += self._str_indent(param.desc)<tab><tab>out += [""""]<tab>return out","if param . desc and """" . join ( param . desc ) . strip ( ) :",157
1584,"def assert_backend(self, expected_translated, language=""cs""):<tab>""""""Check that backend has correct data.""""""<tab>translation = self.get_translation(language)<tab>translation.commit_pending(""test"", None)<tab>store = translation.component.file_format_cls(translation.get_filename(), None)<tab>messages = set()<tab>translated = 0<tab>for unit in store.content_units:<tab><tab>id_hash = unit.id_hash<tab><tab>self.assertFalse(id_hash in messages, ""Duplicate string in in backend file!"")<tab><tab><IF-STMT><tab><tab><tab>translated += 1<tab>self.assertEqual(<tab><tab>translated,<tab><tab>expected_translated,<tab><tab>""Did not found expected number of translations ({} != {})."".format(<tab><tab><tab>translated, expected_translated<tab><tab>),<tab>)",if unit . is_translated ( ) :,195
1585,"def status(self, name, error=""No matching script logs found""):<tab>with self.script_lock:<tab><tab><IF-STMT><tab><tab><tab>return self.script_running[1:]<tab><tab>elif self.script_last and self.script_last[1] == name:<tab><tab><tab>return self.script_last[1:]<tab><tab>else:<tab><tab><tab>raise ValueError(error)",if self . script_running and self . script_running [ 1 ] == name :,107
1586,"def dict_no_value_from_proto_list(obj_list):<tab>d = dict()<tab>for item in obj_list:<tab><tab>possible_dict = json.loads(item.value_json)<tab><tab><IF-STMT><tab><tab><tab># (tss) TODO: This is protecting against legacy 'wandb_version' field.<tab><tab><tab># Should investigate why the config payload even has 'wandb_version'.<tab><tab><tab>logger.warning(""key '{}' has no 'value' attribute"".format(item.key))<tab><tab><tab>continue<tab><tab>d[item.key] = possible_dict[""value""]<tab>return d","if not isinstance ( possible_dict , dict ) or ""value"" not in possible_dict :",167
1587,"def visit(self, node):<tab>""""""dispatcher on node's class/bases name.""""""<tab>cls = node.__class__<tab>try:<tab><tab>visitmethod = self.cache[cls]<tab>except KeyError:<tab><tab>for subclass in cls.__mro__:<tab><tab><tab>visitmethod = getattr(self, subclass.__name__, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>visitmethod = self.__object<tab><tab>self.cache[cls] = visitmethod<tab>visitmethod(node)",if visitmethod is not None :,127
1588,"def _get_adapter(<tab>mcls,<tab>reversed_mro: Tuple[type, ...],<tab>collection: Dict[Any, Dict[type, Adapter]],<tab>kwargs: Dict[str, Any],) -> Optional[Adapter]:<tab>registry_key = mcls.get_registry_key(kwargs)<tab>adapters = collection.get(registry_key)<tab>if adapters is None:<tab><tab>return None<tab>result = None<tab>seen: Set[Adapter] = set()<tab>for base in reversed_mro:<tab><tab>for adaptee, adapter in adapters.items():<tab><tab><tab>found = mcls._match_adapter(base, adaptee, adapter)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = found<tab><tab><tab><tab>seen.add(found)<tab>return result",if found and found not in seen :,190
1589,"def test_pt_BR_rg(self):<tab>for _ in range(100):<tab><tab>to_test = self.fake.rg()<tab><tab><IF-STMT><tab><tab><tab>assert re.search(r""^\d{8}X"", to_test)<tab><tab>else:<tab><tab><tab>assert re.search(r""^\d{9}$"", to_test)","if ""X"" in to_test :",91
1590,"def get_user_extra_data_by_client_id(self, client_id, username):<tab>extra_data = {}<tab>current_client = self.clients.get(client_id, None)<tab>if current_client:<tab><tab>for readable_field in current_client.get_readable_fields():<tab><tab><tab>attribute = list(<tab><tab><tab><tab>filter(<tab><tab><tab><tab><tab>lambda f: f[""Name""] == readable_field,<tab><tab><tab><tab><tab>self.users.get(username).attributes,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extra_data.update({attribute[0][""Name""]: attribute[0][""Value""]})<tab>return extra_data",if len ( attribute ) > 0 :,176
1591,"def augment(self, resources):<tab>super().augment(resources)<tab>for r in resources:<tab><tab>md = r.get(""SAMLMetadataDocument"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>root = sso_metadata(md)<tab><tab>r[""IDPSSODescriptor""] = root[""IDPSSODescriptor""]<tab>return resources",if not md :,82
1592,"def __init__(self, mode=0, decode=None):<tab>self.regex = self.REGEX[mode]<tab>self.decode = decode<tab>if decode:<tab><tab>self.header = _(<tab><tab><tab>""### This log has been decoded with automatic search pattern\n""<tab><tab><tab>""### If some paths are not decoded you can manually decode them with:\n""<tab><tab>)<tab><tab>self.header += ""### 'backintime --quiet ""<tab><tab><IF-STMT><tab><tab><tab>self.header += '--profile ""%s"" ' % decode.config.profileName()<tab><tab>self.header += ""--decode <path>'\n\n""<tab>else:<tab><tab>self.header = """"",if int ( decode . config . currentProfile ( ) ) > 1 :,173
1593,"def _get_dynamic_attr(self, attname, obj, default=None):<tab>try:<tab><tab>attr = getattr(self, attname)<tab>except AttributeError:<tab><tab>return default<tab>if callable(attr):<tab><tab># Check co_argcount rather than try/excepting the function and<tab><tab># catching the TypeError, because something inside the function<tab><tab># may raise the TypeError. This technique is more accurate.<tab><tab>try:<tab><tab><tab>code = six.get_function_code(attr)<tab><tab>except AttributeError:<tab><tab><tab>code = six.get_function_code(attr.__call__)<tab><tab><IF-STMT>  # one argument is 'self'<tab><tab><tab>return attr(obj)<tab><tab>else:<tab><tab><tab>return attr()<tab>return attr",if code . co_argcount == 2 :,190
1594,"def grep_full_py_identifiers(tokens):<tab>global pykeywords<tab>tokens = list(tokens)<tab>i = 0<tab>while i < len(tokens):<tab><tab>tokentype, token = tokens[i]<tab><tab>i += 1<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>while (<tab><tab><tab>i + 1 < len(tokens)<tab><tab><tab>and tokens[i] == (""op"", ""."")<tab><tab><tab>and tokens[i + 1][0] == ""id""<tab><tab>):<tab><tab><tab>token += ""."" + tokens[i + 1][1]<tab><tab><tab>i += 2<tab><tab>if token == """":<tab><tab><tab>continue<tab><tab>if token in pykeywords:<tab><tab><tab>continue<tab><tab>if token[0] in "".0123456789"":<tab><tab><tab>continue<tab><tab>yield token","if tokentype != ""id"" :",194
1595,"def _add_disk_config(self, context, images):<tab>for image in images:<tab><tab>metadata = image[""metadata""]<tab><tab><IF-STMT><tab><tab><tab>raw_value = metadata[INTERNAL_DISK_CONFIG]<tab><tab><tab>value = utils.bool_from_str(raw_value)<tab><tab><tab>image[API_DISK_CONFIG] = disk_config_to_api(value)",if INTERNAL_DISK_CONFIG in metadata :,101
1596,"def test_edgeql_expr_valid_setop_07(self):<tab>expected_error_msg = ""cannot be applied to operands""<tab># IF ELSE with every scalar as the condition<tab>for val in get_test_values():<tab><tab>query = f""""""SELECT 1 IF {val} ELSE 2;""""""<tab><tab><IF-STMT><tab><tab><tab>await self.assert_query_result(query, [1])<tab><tab>else:<tab><tab><tab># every other combination must produce an error<tab><tab><tab>with self.assertRaisesRegex(<tab><tab><tab><tab>edgedb.QueryError, expected_error_msg, msg=query<tab><tab><tab>):<tab><tab><tab><tab>async with self.con.transaction():<tab><tab><tab><tab><tab>await self.con.execute(query)","if val == ""<bool>True"" :",179
1597,"def get_all_url_infos() -> Dict[str, UrlInfo]:<tab>""""""Returns dict associating URL to UrlInfo.""""""<tab>url_infos = {}<tab>for path in _checksum_paths().values():<tab><tab>dataset_url_infos = load_url_infos(path)<tab><tab>for url, url_info in dataset_url_infos.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab><tab>""URL {} is registered with 2+ distinct size/checksum tuples. ""<tab><tab><tab><tab><tab>""{} vs {}"".format(url, url_info, url_infos[url])<tab><tab><tab><tab>)<tab><tab>url_infos.update(dataset_url_infos)<tab>return url_infos","if url_infos . get ( url , url_info ) != url_info :",185
1598,"def global_fixes():<tab>""""""Yield multiple (code, function) tuples.""""""<tab>for function in list(globals().values()):<tab><tab><IF-STMT><tab><tab><tab>arguments = _get_parameters(function)<tab><tab><tab>if arguments[:1] != [""source""]:<tab><tab><tab><tab>continue<tab><tab><tab>code = extract_code_from_function(function)<tab><tab><tab>if code:<tab><tab><tab><tab>yield (code, function)",if inspect . isfunction ( function ) :,106
1599,"def createSocket(self):<tab>skt = Port.createSocket(self)<tab>if self.listenMultiple:<tab><tab>skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)<tab><tab><IF-STMT><tab><tab><tab>skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)<tab>return skt","if hasattr ( socket , ""SO_REUSEPORT"" ) :",90
1600,"def _asStringList(self, sep=""""):<tab>out = []<tab>for item in self._toklist:<tab><tab>if out and sep:<tab><tab><tab>out.append(sep)<tab><tab><IF-STMT><tab><tab><tab>out += item._asStringList()<tab><tab>else:<tab><tab><tab>out.append(str(item))<tab>return out","if isinstance ( item , ParseResults ) :",88
1601,"def parse_c_comments(lexer, tok, ntok):<tab>if tok != ""/"" or ntok != ""*"":<tab><tab>return False<tab>quotes = lexer.quotes<tab>lexer.quotes = """"<tab>while True:<tab><tab>tok = lexer.get_token()<tab><tab>ntok = lexer.get_token()<tab><tab><IF-STMT><tab><tab><tab>lexer.quotes = quotes<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>lexer.push_token(ntok)<tab>return True","if tok == ""*"" and ntok == ""/"" :",121
1602,"def doWorkForFindAll(self, v, target, partialMatch):<tab>sibling = self<tab>while sibling:<tab><tab>c1 = partialMatch and sibling.equalsTreePartial(target)<tab><tab>if c1:<tab><tab><tab>v.append(sibling)<tab><tab>else:<tab><tab><tab>c2 = not partialMatch and sibling.equalsTree(target)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v.append(sibling)<tab><tab>### regardless of match or not, check any children for matches<tab><tab>if sibling.getFirstChild():<tab><tab><tab>sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch)<tab><tab>sibling = sibling.getNextSibling()",if c2 :,163
1603,"def __view_beside(self, onsideof, **kwargs):<tab>bounds = self.info[""bounds""]<tab>min_dist, found = -1, None<tab>for ui in UiObject(self.session, Selector(**kwargs)):<tab><tab>dist = onsideof(bounds, ui.info[""bounds""])<tab><tab><IF-STMT><tab><tab><tab>min_dist, found = dist, ui<tab>return found",if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,112
1604,"def __eq__(self, other):<tab>if isinstance(other, numeric_range):<tab><tab>empty_self = not bool(self)<tab><tab>empty_other = not bool(other)<tab><tab><IF-STMT><tab><tab><tab>return empty_self and empty_other  # True if both empty<tab><tab>else:<tab><tab><tab>return (<tab><tab><tab><tab>self._start == other._start<tab><tab><tab><tab>and self._step == other._step<tab><tab><tab><tab>and self._get_by_index(-1) == other._get_by_index(-1)<tab><tab><tab>)<tab>else:<tab><tab>return False",if empty_self or empty_other :,151
1605,"def _buffered_generator(self, size):<tab>buf = []<tab>c_size = 0<tab>push = buf.append<tab>while 1:<tab><tab>try:<tab><tab><tab>while c_size < size:<tab><tab><tab><tab>c = next(self._gen)<tab><tab><tab><tab>push(c)<tab><tab><tab><tab>if c:<tab><tab><tab><tab><tab>c_size += 1<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>yield concat(buf)<tab><tab>del buf[:]<tab><tab>c_size = 0",if not c_size :,137
1606,"def connect(self):<tab>with self._conn_lock:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Error, database not properly initialized "" ""before opening connection""<tab><tab><tab>)<tab><tab>with self.exception_wrapper():<tab><tab><tab>self.__local.conn = self._connect(self.database, **self.connect_kwargs)<tab><tab><tab>self.__local.closed = False<tab><tab><tab>self.initialize_connection(self.__local.conn)",if self . deferred :,115
1607,"def _merge_substs(self, subst, new_substs):<tab>subst = subst.copy()<tab>for new_subst in new_substs:<tab><tab>for name, var in new_subst.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subst[name] = var<tab><tab><tab>elif subst[name] is not var:<tab><tab><tab><tab>subst[name].PasteVariable(var)<tab>return subst",if name not in subst :,109
1608,"def remove(self, tag):<tab>""""""Removes a tag recursively from all containers.""""""<tab>new_contents = []<tab>self.content_size = 0<tab>for element in self.contents:<tab><tab>if element.name != tag:<tab><tab><tab>new_contents.append(element)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>element.remove(tag)<tab><tab><tab>self.content_size += element.size()<tab>self.contents = new_contents","if isinstance ( element , Container ) :",111
1609,"def _create_object(self, obj_body):<tab>props = obj_body[SYMBOL_PROPERTIES]<tab>for prop_name, prop_value in props.items():<tab><tab>if isinstance(prop_value, dict) and prop_value:<tab><tab><tab># get the first key as the convert function<tab><tab><tab>func_name = list(prop_value.keys())[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>func = getattr(self, func_name)<tab><tab><tab><tab>props[prop_name] = func(prop_value[func_name])<tab>if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping:<tab><tab>return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props)<tab>else:<tab><tab>return props","if func_name . startswith ( ""_"" ) :",199
1610,"def visit_try_stmt(self, o: ""mypy.nodes.TryStmt"") -> str:<tab>a = [o.body]  # type: List[Any]<tab>for i in range(len(o.vars)):<tab><tab>a.append(o.types[i])<tab><tab><IF-STMT><tab><tab><tab>a.append(o.vars[i])<tab><tab>a.append(o.handlers[i])<tab>if o.else_body:<tab><tab>a.append((""Else"", o.else_body.body))<tab>if o.finally_body:<tab><tab>a.append((""Finally"", o.finally_body.body))<tab>return self.dump(a, o)",if o . vars [ i ] :,166
1611,"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict) and k != ""headers"":<tab><tab><tab>if not everythingIsUnicode(v):<tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, _bytes):<tab><tab><tab>return False<tab>return True","elif isinstance ( i , _bytes ) :",158
1612,"def msg_ser(inst, sformat, lev=0):<tab>if sformat in [""urlencoded"", ""json""]:<tab><tab>if isinstance(inst, Message):<tab><tab><tab>res = inst.serialize(sformat, lev)<tab><tab>else:<tab><tab><tab>res = inst<tab>elif sformat == ""dict"":<tab><tab>if isinstance(inst, Message):<tab><tab><tab>res = inst.serialize(sformat, lev)<tab><tab><IF-STMT><tab><tab><tab>res = inst<tab><tab>elif isinstance(inst, str):  # Iff ID Token<tab><tab><tab>res = inst<tab><tab>else:<tab><tab><tab>raise MessageException(""Wrong type: %s"" % type(inst))<tab>else:<tab><tab>raise PyoidcError(""Unknown sformat"", inst)<tab>return res","elif isinstance ( inst , dict ) :",182
1613,"def start_container_if_stopped(self, container, attach_logs=False, quiet=False):<tab>if not container.is_running:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Starting %s"" % container.name)<tab><tab>if attach_logs:<tab><tab><tab>container.attach_log_stream()<tab><tab>return self.start_container(container)",if not quiet :,90
1614,"def layer_op(self, input_image, mask=None):<tab>if not isinstance(input_image, dict):<tab><tab>self._set_full_border(input_image)<tab><tab>input_image = np.pad(input_image, self.full_border, mode=self.mode)<tab><tab>return input_image, mask<tab>for name, image in input_image.items():<tab><tab>self._set_full_border(image)<tab><tab><IF-STMT><tab><tab><tab>tf.logging.warning(<tab><tab><tab><tab>""could not pad, dict name %s not in %s"", name, self.image_name<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>input_image[name] = np.pad(image, self.full_border, mode=self.mode)<tab>return input_image, mask",if name not in self . image_name :,200
1615,"def __Suffix_Noun_Step2b(self, token):<tab>for suffix in self.__suffix_noun_step2b:<tab><tab><IF-STMT><tab><tab><tab>token = token[:-2]<tab><tab><tab>self.suffix_noun_step2b_success = True<tab><tab><tab>break<tab>return token",if token . endswith ( suffix ) and len ( token ) >= 5 :,86
1616,"def replace_header_items(ps, replacments):<tab>match = read_while(ps, header_item_or_end_re.match, lambda match: match is None)<tab>while not ps.current_line.startswith(""*/""):<tab><tab>match = header_item_re.match(ps.current_line)<tab><tab><IF-STMT><tab><tab><tab>key = match.groupdict()[""key""]<tab><tab><tab>if key in replacments:<tab><tab><tab><tab>ps.current_line = match.expand(<tab><tab><tab><tab><tab>""\g<key>\g<space>%s\n"" % replacments[key]<tab><tab><tab><tab>)<tab><tab>ps.read_line()",if match is not None :,163
1617,"def __projectBookmark(widget, location):<tab>script = None<tab>while widget is not None:<tab><tab><IF-STMT><tab><tab><tab>script = widget.scriptNode()<tab><tab><tab>if isinstance(script, Gaffer.ScriptNode):<tab><tab><tab><tab>break<tab><tab>widget = widget.parent()<tab>if script is not None:<tab><tab>p = script.context().substitute(location)<tab><tab>if not os.path.exists(p):<tab><tab><tab>try:<tab><tab><tab><tab>os.makedirs(p)<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass<tab><tab>return p<tab>else:<tab><tab>return os.getcwd()","if hasattr ( widget , ""scriptNode"" ) :",159
1618,"def events_to_str(event_field, all_events):<tab>result = []<tab>for (flag, string) in all_events:<tab><tab>c_flag = flag<tab><tab>if event_field & c_flag:<tab><tab><tab>result.append(string)<tab><tab><tab>event_field = event_field & (~c_flag)<tab><tab><IF-STMT><tab><tab><tab>break<tab>if event_field:<tab><tab>result.append(hex(event_field))<tab>return ""|"".join(result)",if not event_field :,123
1619,"def get_s3_bucket_locations(buckets, self_log=False):<tab>""""""return (bucket_name, prefix) for all s3 logging targets""""""<tab>for b in buckets:<tab><tab>if b.get(""Logging""):<tab><tab><tab>if self_log:<tab><tab><tab><tab>if b[""Name""] != b[""Logging""][""TargetBucket""]:<tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""])<tab><tab><IF-STMT><tab><tab><tab>yield (b[""Name""], """")","if not self_log and b [ ""Name"" ] . startswith ( ""cf-templates-"" ) :",138
1620,"def extract_file(tgz, tarinfo, dst_path, buffer_size=10 << 20, log_function=None):<tab>""""""Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'.""""""<tab>src = tgz.extractfile(tarinfo)<tab>if src is None:<tab><tab>return<tab>dst = tf.compat.v1.gfile.GFile(dst_path, ""wb"")<tab>while 1:<tab><tab>buf = src.read(buffer_size)<tab><tab>if not buf:<tab><tab><tab>break<tab><tab>dst.write(buf)<tab><tab><IF-STMT><tab><tab><tab>log_function(len(buf))<tab>dst.close()<tab>src.close()",if log_function is not None :,165
1621,"def make_index_fields(rec):<tab>fields = {}<tab>for k, v in rec.iteritems():<tab><tab>if k in (""lccn"", ""oclc"", ""isbn""):<tab><tab><tab>fields[k] = v<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>fields[""title""] = [read_short_title(v)]<tab>return fields","if k == ""full_title"" :",93
1622,"def disconnect_application(self):<tab>if not self.is_app_running(self.APP_BACKDROP):<tab><tab>self.socket.send(commands.CloseCommand(destination_id=False))<tab><tab>start_time = time.time()<tab><tab>while not self.is_app_running(None):<tab><tab><tab>try:<tab><tab><tab><tab>self.socket.send_and_wait(commands.StatusCommand())<tab><tab><tab>except cast_socket.ConnectionTerminatedException:<tab><tab><tab><tab>break<tab><tab><tab>current_time = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TimeoutException()<tab><tab><tab>time.sleep(self.WAIT_INTERVAL)<tab>else:<tab><tab>logger.debug(""Closing not necessary. Backdrop is running ..."")",if current_time - start_time > self . timeout :,190
1623,"def matches(self, cursor_offset, line, **kwargs):<tab>cs = lineparts.current_string(cursor_offset, line)<tab>if cs is None:<tab><tab>return None<tab>matches = set()<tab>username = cs.word.split(os.path.sep, 1)[0]<tab>user_dir = os.path.expanduser(username)<tab>for filename in self.safe_glob(os.path.expanduser(cs.word)):<tab><tab>if os.path.isdir(filename):<tab><tab><tab>filename += os.path.sep<tab><tab><IF-STMT><tab><tab><tab>filename = username + filename[len(user_dir) :]<tab><tab>matches.add(filename)<tab>return matches","if cs . word . startswith ( ""~"" ) :",169
1624,"def eventFilter(self, obj, event):<tab>if event.type() == QEvent.MouseButtonPress:<tab><tab>button = event.button()<tab><tab><IF-STMT><tab><tab><tab>self._app.browser.back()<tab><tab><tab>return True<tab><tab>elif button == Qt.ForwardButton:<tab><tab><tab>self._app.browser.forward()<tab><tab><tab>return True<tab>return False",if button == Qt . BackButton :,96
1625,"def reset_parameters(self):<tab>for m in self.modules():<tab><tab>if isinstance(m, nn.Embedding):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>nn.init.constant_(m.weight, 0.1)<tab><tab><tab>nn.init.constant_(m.bias, 0)<tab><tab>else:<tab><tab><tab>for p in m.parameters():<tab><tab><tab><tab>nn.init.normal_(p, 0, 0.1)","elif isinstance ( m , nn . LayerNorm ) :",115
1626,"def get_scalding_core(self):<tab>lib_dir = os.path.join(self.scalding_home, ""lib"")<tab>for j in os.listdir(lib_dir):<tab><tab><IF-STMT><tab><tab><tab>p = os.path.join(lib_dir, j)<tab><tab><tab>logger.debug(""Found scalding-core: %s"", p)<tab><tab><tab>return p<tab>raise luigi.contrib.hadoop.HadoopJobError(""Could not find scalding-core."")","if j . startswith ( ""scalding-core-"" ) :",126
1627,"def save(self):<tab>""""""Saves a new set of golden output frames to disk.""""""<tab>for pixels, (relative_to_assets, filename) in zip(<tab><tab>self.iter_render(), self._iter_paths()<tab>):<tab><tab>full_directory_path = os.path.join(self._ASSETS_DIR, relative_to_assets)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(full_directory_path)<tab><tab>path = os.path.join(full_directory_path, filename)<tab><tab>_save_pixels(pixels, path)",if not os . path . exists ( full_directory_path ) :,147
1628,"def _fix_var_naming(operators, names, mod=""input""):<tab>new_names = []<tab>map = {}<tab>for op in operators:<tab><tab><IF-STMT><tab><tab><tab>iter = op.inputs<tab><tab>else:<tab><tab><tab>iter = op.outputs<tab><tab>for i in iter:<tab><tab><tab>for name in names:<tab><tab><tab><tab>if i.raw_name == name and name not in map:<tab><tab><tab><tab><tab>map[i.raw_name] = i.full_name<tab><tab>if len(map) == len(names):<tab><tab><tab>break<tab>for name in names:<tab><tab>new_names.append(map[name])<tab>return new_names","if mod == ""input"" :",168
1629,"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab>if item[0]:<tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab><IF-STMT><tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab>elif item[2]:<tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab>elif item[3]:<tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",elif item [ 1 ] :,181
1630,"def init_errorhandler():<tab># http error handling<tab>for ex in default_exceptions:<tab><tab>if ex < 500:<tab><tab><tab>app.register_error_handler(ex, error_http)<tab><tab><IF-STMT><tab><tab><tab>app.register_error_handler(ex, internal_error)<tab>if services.ldap:<tab><tab># Only way of catching the LDAPException upon logging in with LDAP server down<tab><tab>@app.errorhandler(services.ldap.LDAPException)<tab><tab>def handle_exception(e):<tab><tab><tab>log.debug(""LDAP server not accessible while trying to login to opds feed"")<tab><tab><tab>return error_http(FailedDependency())",elif ex == 500 :,168
1631,"def decode(self, ids):<tab>ids = pad_decr(ids)<tab>tokens = []<tab>for int_id in ids:<tab><tab><IF-STMT><tab><tab><tab>tokens.append(self._vocab_list[int_id])<tab><tab>else:<tab><tab><tab>tokens.append(self._oov_token)<tab>return self._decode_token_separator.join(tokens)",if int_id < len ( self . _vocab_list ) :,101
1632,"def remove_contest(contest_id):<tab>with SessionGen() as session:<tab><tab>contest = session.query(Contest).filter(Contest.id == contest_id).first()<tab><tab>if not contest:<tab><tab><tab>print(""No contest with id %s found."" % contest_id)<tab><tab><tab>return False<tab><tab>contest_name = contest.name<tab><tab><IF-STMT><tab><tab><tab>print(""Not removing contest `%s'."" % contest_name)<tab><tab><tab>return False<tab><tab>session.delete(contest)<tab><tab>session.commit()<tab><tab>print(""Contest `%s' removed."" % contest_name)<tab>return True",if not ask ( contest ) :,169
1633,def get_hi_lineno(self):<tab>lineno = Node.get_hi_lineno(self)<tab>if self.expr1 is None:<tab><tab>pass<tab>else:<tab><tab>lineno = self.expr1.get_hi_lineno()<tab><tab>if self.expr2 is None:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>lineno = self.expr2.get_hi_lineno()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>lineno = self.expr3.get_hi_lineno()<tab>return lineno,if self . expr3 is None :,142
1634,"def _send_internal(self, bytes_):<tab># buffering<tab>if self.pendings:<tab><tab>self.pendings += bytes_<tab><tab>bytes_ = self.pendings<tab>try:<tab><tab># reconnect if possible<tab><tab>self._reconnect()<tab><tab># send message<tab><tab>self.socket.sendall(bytes_)<tab><tab># send finished<tab><tab>self.pendings = None<tab>except Exception:  # pylint: disable=broad-except<tab><tab># close socket<tab><tab>self._close()<tab><tab># clear buffer if it exceeds max bufer size<tab><tab><IF-STMT><tab><tab><tab># TODO: add callback handler here<tab><tab><tab>self.pendings = None<tab><tab>else:<tab><tab><tab>self.pendings = bytes_",if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,194
1635,"def _unpack(self, fmt, byt):<tab>d = unpack(self._header[""byteorder""] + fmt, byt)[0]<tab>if fmt[-1] in self.MISSING_VALUES:<tab><tab>nmin, nmax = self.MISSING_VALUES[fmt[-1]]<tab><tab>if d < nmin or d > nmax:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return StataMissingValue(nmax, d)<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab>return d",if self . _missing_values :,121
1636,"def tuple_iter(self):<tab>for x in range(<tab><tab>self.center.x - self.max_radius, self.center.x + self.max_radius + 1<tab>):<tab><tab>for y in range(<tab><tab><tab>self.center.y - self.max_radius, self.center.y + self.max_radius + 1<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (x, y)","if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :",126
1637,"def _parse_gene(element):<tab>for genename_element in element:<tab><tab><IF-STMT><tab><tab><tab>ann_key = ""gene_%s_%s"" % (<tab><tab><tab><tab>genename_element.tag.replace(NS, """"),<tab><tab><tab><tab>genename_element.attrib[""type""],<tab><tab><tab>)<tab><tab><tab>if genename_element.attrib[""type""] == ""primary"":<tab><tab><tab><tab>self.ParsedSeqRecord.annotations[ann_key] = genename_element.text<tab><tab><tab>else:<tab><tab><tab><tab>append_to_annotations(ann_key, genename_element.text)","if ""type"" in genename_element . attrib :",157
1638,"def invalidateDependentSlices(self, iFirstCurve):<tab># only user defined curve can have slice dependency relationships<tab>if self.isSystemCurveIndex(iFirstCurve):<tab><tab>return<tab>nCurves = self.getNCurves()<tab>for i in range(iFirstCurve, nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab>if isinstance(c.getSymbol().getSymbolType(), SymbolType.PieSliceSymbolType):<tab><tab><tab>c.invalidate()<tab><tab><IF-STMT><tab><tab><tab># if first curve isn't a slice,<tab><tab><tab>break<tab><tab><tab># there are no dependent slices",elif i == iFirstCurve :,154
1639,"def gen_app_versions(self):<tab>for app_config in apps.get_app_configs():<tab><tab>name = app_config.verbose_name<tab><tab>app = app_config.module<tab><tab>version = self.get_app_version(app)<tab><tab><IF-STMT><tab><tab><tab>yield app.__name__, name, version",if version :,80
1640,"def verify_relative_valid_path(root, path):<tab>if len(path) < 1:<tab><tab>raise PackagerError(""Empty chown path"")<tab>checkpath = root<tab>parts = path.split(os.sep)<tab>for part in parts:<tab><tab>if part in (""."", ""..""):<tab><tab><tab>raise PackagerError("". and .. is not allowed in chown path"")<tab><tab>checkpath = os.path.join(checkpath, part)<tab><tab>relpath = checkpath[len(root) + 1 :]<tab><tab><IF-STMT><tab><tab><tab>raise PackagerError(f""chown path {relpath} does not exist"")<tab><tab>if os.path.islink(checkpath):<tab><tab><tab>raise PackagerError(f""chown path {relpath} is a soft link"")",if not os . path . exists ( checkpath ) :,191
1641,"def create_or_update_tag_at_scope(cmd, resource_id=None, tags=None, tag_name=None):<tab>rcf = _resource_client_factory(cmd.cli_ctx)<tab>if resource_id is not None:<tab><tab><IF-STMT><tab><tab><tab>raise IncorrectUsageError(""Tags could not be empty."")<tab><tab>Tags = cmd.get_models(""Tags"")<tab><tab>tag_obj = Tags(tags=tags)<tab><tab>return rcf.tags.create_or_update_at_scope(scope=resource_id, properties=tag_obj)<tab>return rcf.tags.create_or_update(tag_name=tag_name)",if not tags :,160
1642,"def generate_auto_complete(self, base, iterable_var):<tab>sugg = []<tab>for entry in iterable_var:<tab><tab>compare_entry = entry<tab><tab>compare_base = base<tab><tab>if self.settings.get(IGNORE_CASE_SETTING):<tab><tab><tab>compare_entry = compare_entry.lower()<tab><tab><tab>compare_base = compare_base.lower()<tab><tab><IF-STMT><tab><tab><tab>if entry not in sugg:<tab><tab><tab><tab>sugg.append(entry)<tab>return sugg","if self . compare_entries ( compare_entry , compare_base ) :",137
1643,"def createFields(self):<tab>yield String(self, ""dict_start"", 2)<tab>while not self.eof:<tab><tab>addr = self.absolute_address + self.current_size<tab><tab><IF-STMT><tab><tab><tab>for field in parsePDFType(self):<tab><tab><tab><tab>yield field<tab><tab>else:<tab><tab><tab>break<tab>yield String(self, ""dict_end"", 2)","if self . stream . readBytes ( addr , 2 ) != "">>"" :",107
1644,"def Visit_and_test(self, node):  # pylint: disable=invalid-name<tab># and_test ::= not_test ('and' not_test)*<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :",99
1645,"def getfiledata(directories):<tab>columns = None<tab>data = []<tab>counter = 1<tab>for directory in directories:<tab><tab>for f in os.listdir(directory):<tab><tab><tab>if not os.path.isfile(os.path.join(directory, f)):<tab><tab><tab><tab>continue<tab><tab><tab>counter += 1<tab><tab><tab>st = os.stat(os.path.join(directory, f))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>columns = [""rowid"", ""name"", ""directory""] + [<tab><tab><tab><tab><tab>x for x in dir(st) if x.startswith(""st_"")<tab><tab><tab><tab>]<tab><tab><tab>data.append([counter, f, directory] + [getattr(st, x) for x in columns[3:]])<tab>return columns, data",if columns is None :,185
1646,"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None):<tab>for attr in attributes:<tab><tab>value = getattr(obj, attr, None)<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab>name = name_fmt % attr<tab><tab><IF-STMT><tab><tab><tab>value = formatter(attr, value)<tab><tab>info_add(name, value)",if formatter is not None :,97
1647,"def main(args):<tab>ap = argparse.ArgumentParser()<tab>ap.add_argument(""job_ids"", nargs=""+"", type=int, help=""ID of a running job"")<tab>ns = ap.parse_args(args)<tab>_stash = globals()[""_stash""]<tab>"""""":type : StaSh""""""<tab>for job_id in ns.job_ids:<tab><tab><IF-STMT><tab><tab><tab>print(""killing job {} ..."".format(job_id))<tab><tab><tab>worker = _stash.runtime.worker_registry.get_worker(job_id)<tab><tab><tab>worker.kill()<tab><tab><tab>time.sleep(1)<tab><tab>else:<tab><tab><tab>print(""error: no such job with id: {}"".format(job_id))<tab><tab><tab>break",if job_id in _stash . runtime . worker_registry :,195
1648,"def _check_choice(self):<tab>if self.type == ""choice"":<tab><tab>if self.choices is None:<tab><tab><tab>raise OptionError(""must supply a list of choices for type 'choice'"", self)<tab><tab><IF-STMT><tab><tab><tab>raise OptionError(<tab><tab><tab><tab>""choices must be a list of strings ('%s' supplied)""<tab><tab><tab><tab>% str(type(self.choices)).split(""'"")[1],<tab><tab><tab><tab>self,<tab><tab><tab>)<tab>elif self.choices is not None:<tab><tab>raise OptionError(""must not supply choices for type %r"" % self.type, self)","elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :",162
1649,"def add_file(pipe, srcpath, tgtpath):<tab>with open(srcpath, ""rb"") as handle:<tab><tab><IF-STMT><tab><tab><tab>write(pipe, enc(""M 100755 inline %s\n"" % tgtpath))<tab><tab>else:<tab><tab><tab>write(pipe, enc(""M 100644 inline %s\n"" % tgtpath))<tab><tab>data = handle.read()<tab><tab>write(pipe, enc(""data %d\n"" % len(data)))<tab><tab>write(pipe, enc(data))<tab><tab>write(pipe, enc(""\n""))","if os . access ( srcpath , os . X_OK ) :",148
1650,"def cdf(self, x):<tab>if x == numpy.inf:<tab><tab>return 1.0<tab>else:  # Inefficient sum.<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Invalid value."")<tab><tab>c = 0.0<tab><tab>for i in xrange(x + 1):<tab><tab><tab>c += self.probability(i)<tab><tab>return c",if x != int ( x ) :,91
1651,"def convert_to_strings(self, out, seq_len):<tab>results = []<tab>for b, batch in enumerate(out):<tab><tab>utterances = []<tab><tab>for p, utt in enumerate(batch):<tab><tab><tab>size = seq_len[b][p]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>transcript = """".join(<tab><tab><tab><tab><tab>map(lambda x: self.int_to_char[x.item()], utt[0:size])<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>transcript = """"<tab><tab><tab>utterances.append(transcript)<tab><tab>results.append(utterances)<tab>return results",if size > 0 :,158
1652,"def get_date_range(self):<tab>if not hasattr(self, ""start"") or not hasattr(self, ""end""):<tab><tab>args = (self.today.year, self.today.month)<tab><tab>form = self.get_form()<tab><tab><IF-STMT><tab><tab><tab>args = (int(form.cleaned_data[""year""]), int(form.cleaned_data[""month""]))<tab><tab>self.start = self.get_start(*args)<tab><tab>self.end = self.get_end(*args)<tab>return self.start, self.end",if form . is_valid ( ) :,136
1653,"def save_stats(self):<tab>LOGGER.info(""Saving task-level statistics."")<tab>has_headers = os.path.isfile(paths.TABLE_COUNT_PATH)<tab>with open(paths.TABLE_COUNT_PATH, ""a"") as csvfile:<tab><tab>headers = [""start_time"", ""database_name"", ""number_tables""]<tab><tab>writer = csv.DictWriter(<tab><tab><tab>csvfile, delimiter="","", lineterminator=""\n"", fieldnames=headers<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>writer.writeheader()<tab><tab>writer.writerow(<tab><tab><tab>{<tab><tab><tab><tab>""start_time"": self.start_time,<tab><tab><tab><tab>""database_name"": self.database_name,<tab><tab><tab><tab>""number_tables"": self.count,<tab><tab><tab>}<tab><tab>)",if not has_headers :,199
1654,"def _CheckCanaryCommand(self):<tab><IF-STMT>  # fast path<tab><tab>return<tab>with self._lock:<tab><tab>if OpenStackVirtualMachine.command_works:<tab><tab><tab>return<tab><tab>logging.info(""Testing OpenStack CLI command is installed and working"")<tab><tab>cmd = os_utils.OpenStackCLICommand(self, ""image"", ""list"")<tab><tab>stdout, stderr, _ = cmd.Issue()<tab><tab>if stderr:<tab><tab><tab>raise errors.Config.InvalidValue(<tab><tab><tab><tab>""OpenStack CLI test command failed. Please make sure the OpenStack ""<tab><tab><tab><tab>""CLI client is installed and properly configured""<tab><tab><tab>)<tab><tab>OpenStackVirtualMachine.command_works = True",if OpenStackVirtualMachine . command_works :,176
1655,"def test_windows_hidden(self):<tab>if not sys.platform == ""win32"":<tab><tab>self.skipTest(""sys.platform is not windows"")<tab><tab>return<tab># FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation.<tab>hidden_mask = 2<tab>with tempfile.NamedTemporaryFile() as f:<tab><tab># Hide the file using<tab><tab>success = ctypes.windll.kernel32.SetFileAttributesW(f.name, hidden_mask)<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""unable to set file attributes"")<tab><tab>self.assertTrue(hidden.is_hidden(f.name))",if not success :,147
1656,"def recv_some(p, t=0.1, e=1, tr=5, stderr=0):<tab>if tr < 1:<tab><tab>tr = 1<tab>x = time.time() + t<tab>y = []<tab>r = """"<tab>if stderr:<tab><tab>pr = p.recv_err<tab>else:<tab><tab>pr = p.recv<tab>while time.time() < x or r:<tab><tab>r = pr()<tab><tab>if r is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>y.append(r)<tab><tab>else:<tab><tab><tab>time.sleep(max((x - time.time()) / tr, 0))<tab>return b"""".join(y)",elif r :,169
1657,"def _is_xml(accepts):<tab>if accepts.startswith(b""application/""):<tab><tab>has_xml = accepts.find(b""xml"")<tab><tab><IF-STMT><tab><tab><tab>semicolon = accepts.find(b"";"")<tab><tab><tab>if semicolon < 0 or has_xml < semicolon:<tab><tab><tab><tab>return True<tab>return False",if has_xml > 0 :,86
1658,"def times(self, value: int):<tab>if value is None:<tab><tab>self._times = None<tab>else:<tab><tab>try:<tab><tab><tab>candidate = int(value)<tab><tab>except ValueError:<tab><tab><tab># pylint: disable:raise-missing-from<tab><tab><tab>raise BarException(f""cannot set repeat times to: {value!r}"")<tab><tab>if candidate < 0:<tab><tab><tab>raise BarException(<tab><tab><tab><tab>f""cannot set repeat times to a value less than zero: {value}""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise BarException(""cannot set repeat times on a start Repeat"")<tab><tab>self._times = candidate","if self . direction == ""start"" :",163
1659,"def __call__(self, *args, **kwargs):<tab>if not NET_INITTED:<tab><tab>return self.raw(*args, **kwargs)<tab>for stack in traceback.walk_stack(None):<tab><tab>if ""self"" in stack[0].f_locals:<tab><tab><tab>layer = stack[0].f_locals[""self""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.pytorch_layer_name = layer_names[layer]<tab><tab><tab><tab>print(layer_names[layer])<tab><tab><tab><tab>break<tab>out = self.obj(self.raw, *args, **kwargs)<tab># if isinstance(out,Variable):<tab>#<tab> out=[out]<tab>return out",if layer in layer_names :,173
1660,"def do_begin(self, byte):<tab>if byte.isspace():<tab><tab>return<tab>if byte != ""<"":<tab><tab><IF-STMT><tab><tab><tab>self._leadingBodyData = byte<tab><tab><tab>return ""bodydata""<tab><tab>self._parseError(""First char of document [{!r}] wasn't <"".format(byte))<tab>return ""tagstart""",if self . beExtremelyLenient :,91
1661,"def pretty(self, n, comment=True):<tab>if isinstance(n, (str, bytes, list, tuple, dict)):<tab><tab>r = repr(n)<tab><tab><IF-STMT>  # then it can be inside a comment!<tab><tab><tab>r = r.replace(""*/"", r""\x2a/"")<tab><tab>return r<tab>if not isinstance(n, six.integer_types):<tab><tab>return n<tab>if isinstance(n, constants.Constant):<tab><tab>if comment:<tab><tab><tab>return ""%s /* %s */"" % (n, self.pretty(int(n)))<tab><tab>else:<tab><tab><tab>return ""%s (%s)"" % (n, self.pretty(int(n)))<tab>elif abs(n) < 10:<tab><tab>return str(n)<tab>else:<tab><tab>return hex(n)",if not comment :,194
1662,"def test_training_script_with_max_history_set(tmpdir):<tab>train_dialogue_model(<tab><tab>DEFAULT_DOMAIN_PATH,<tab><tab>DEFAULT_STORIES_FILE,<tab><tab>tmpdir.strpath,<tab><tab>interpreter=RegexInterpreter(),<tab><tab>policy_config=""data/test_config/max_hist_config.yml"",<tab><tab>kwargs={},<tab>)<tab>agent = Agent.load(tmpdir.strpath)<tab>for policy in agent.policy_ensemble.policies:<tab><tab>if hasattr(policy.featurizer, ""max_history""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert policy.featurizer.max_history == 2<tab><tab><tab>else:<tab><tab><tab><tab>assert policy.featurizer.max_history == 5",if type ( policy ) == FormPolicy :,191
1663,"def cli_uninstall_distro():<tab>distro_list = install_distro_list()<tab>if distro_list is not None:<tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab>log(str(index) + ""  --->>  "" + _distro_dir)<tab><tab>user_input = read_input_uninstall()<tab><tab><IF-STMT><tab><tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab><tab>if index == user_input:<tab><tab><tab><tab><tab>config.uninstall_distro_dir_name = _distro_dir<tab><tab><tab><tab><tab>unin_distro()<tab>else:<tab><tab>log(""No distro installed on "" + config.usb_disk)",if user_input is not False :,189
1664,"def set_random_avatar(user):<tab>galleries = get_available_galleries(include_default=True)<tab>if not galleries:<tab><tab>raise RuntimeError(""no avatar galleries are set"")<tab>avatars_list = []<tab>for gallery in galleries:<tab><tab><IF-STMT><tab><tab><tab>avatars_list = gallery[""images""]<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>avatars_list += gallery[""images""]<tab>random_avatar = random.choice(avatars_list)<tab>store.store_new_avatar(user, Image.open(random_avatar.image))","if gallery [ ""name"" ] == DEFAULT_GALLERY :",169
1665,"def make_query(self, key, filters):<tab>meta = self.get_meta(key)<tab>q = {meta.facet_key: self.normalize_key(meta.path)}<tab>if filters:<tab><tab>if filters.get(""has_fulltext"") == ""true"":<tab><tab><tab>q[""has_fulltext""] = ""true""<tab><tab><IF-STMT><tab><tab><tab>q[""publish_year""] = filters[""publish_year""]<tab>return q","if filters . get ( ""publish_year"" ) :",113
1666,"def test_named_parameters_and_constraints(self):<tab>likelihood = gpytorch.likelihoods.GaussianLikelihood()<tab>model = ExactGPModel(None, None, likelihood)<tab>for name, _param, constraint in model.named_parameters_and_constraints():<tab><tab>if name == ""likelihood.noise_covar.raw_noise"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan)<tab><tab><IF-STMT><tab><tab><tab>self.assertIsNone(constraint)<tab><tab>elif name == ""covar_module.raw_outputscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)<tab><tab>elif name == ""covar_module.base_kernel.raw_lengthscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)","elif name == ""mean_module.constant"" :",192
1667,"def _test_pooling(input_shape, **kwargs):<tab>_test_pooling_iteration(input_shape, **kwargs)<tab>if is_gpu_available():<tab><tab><IF-STMT><tab><tab><tab>input_shape = [input_shape[ii] for ii in (0, 3, 1, 2)]<tab><tab><tab>kwargs[""data_format""] = ""NCHW""<tab><tab><tab>_test_pooling_iteration(input_shape, **kwargs)",if len ( input_shape ) == 4 :,111
1668,"def init(self):<tab>r = self.get_redis()<tab>if r:<tab><tab>key = ""pocsuite_target""<tab><tab>info_msg = ""[PLUGIN] try fetch targets from redis...""<tab><tab>logger.info(info_msg)<tab><tab>targets = r.get(key)<tab><tab>count = 0<tab><tab><IF-STMT><tab><tab><tab>for target in targets:<tab><tab><tab><tab>if self.add_target(target):<tab><tab><tab><tab><tab>count += 1<tab><tab>info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count)<tab><tab>logger.info(info_msg)",if targets :,151
1669,"def reload_json_api_settings(*args, **kwargs):<tab>django_setting = kwargs[""setting""]<tab>setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """")<tab>value = kwargs[""value""]<tab>if setting in DEFAULTS.keys():<tab><tab>if value is not None:<tab><tab><tab>setattr(json_api_settings, setting, value)<tab><tab><IF-STMT><tab><tab><tab>delattr(json_api_settings, setting)","elif hasattr ( json_api_settings , setting ) :",115
1670,"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab>if attrname.startswith(""__""):<tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab>if attrvalue == 0:<tab><tab><tab>continue<tab><tab>if attrname == ""salt_version"":<tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass","elif hasattr ( self . metadata , attrname ) :",173
1671,"def test_02_looking_at_listdir_path_(name):<tab>for dline in listdir.json():<tab><tab><IF-STMT><tab><tab><tab>assert dline[""type""] in (""DIRECTORY"", ""FILE""), listdir.text<tab><tab><tab>assert dline[""uid""] == 0, listdir.text<tab><tab><tab>assert dline[""gid""] == 0, listdir.text<tab><tab><tab>assert dline[""name""] == name, listdir.text<tab><tab><tab>break<tab>else:<tab><tab>raise AssertionError(f""/{path}/{name} not found"")","if dline [ ""path"" ] == f""{path}/{name}"" :",136
1672,"def DeletePlugin():<tab>oid = request.form.get(""oid"", """")<tab>if oid:<tab><tab>result = Mongo.coll[""Plugin""].find_one_and_delete(<tab><tab><tab>{""_id"": ObjectId(oid)}, remove=True<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>result[""filename""] = result[""filename""] + "".py""<tab><tab>if os.path.exists(file_path + result[""filename""]):<tab><tab><tab>os.remove(file_path + result[""filename""])<tab><tab><tab>return ""success""<tab>return ""fail""","if not result [ ""filename"" ] . find ( ""."" ) > - 1 :",144
1673,"def iterparent(self, node):<tab>""""""Iterator wrapper to get allowed parent and child all at once.""""""<tab># We do not allow the marker inside a header as that<tab># would causes an enless loop of placing a new TOC<tab># inside previously generated TOC.<tab>for child in node:<tab><tab><IF-STMT><tab><tab><tab>yield node, child<tab><tab><tab>yield from self.iterparent(child)","if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :",120
1674,"def _get_matched_layout(command):<tab># don't use command.split_script here because a layout mismatch will likely<tab># result in a non-splitable script as per shlex<tab>cmd = command.script.split("" "")<tab>for source_layout in source_layouts:<tab><tab>is_all_match = True<tab><tab>for cmd_part in cmd:<tab><tab><tab>if not all([ch in source_layout or ch in ""-_"" for ch in cmd_part]):<tab><tab><tab><tab>is_all_match = False<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return source_layout",if is_all_match :,147
1675,"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops):<tab>for n in tileable_graph:<tab><tab>if n.op in failed_ops:<tab><tab><tab>continue<tab><tab>tiled_n = get_tiled(n)<tab><tab>if has_unknown_shape(tiled_n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># some of the chunks has been fused<tab><tab><tab><tab>continue<tab><tab><tab>new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result)<tab><tab><tab>for node in (n, tiled_n):<tab><tab><tab><tab>node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits))<tab><tab><tab>tiled_n._nsplits = new_nsplits",if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,200
1676,"def _get_items(self, name, target=1):<tab>all_items = self.get_items(name)<tab>items = [o for o in all_items if not o.disabled]<tab>if len(items) < target:<tab><tab>if len(all_items) < target:<tab><tab><tab>raise ItemNotFoundError(""insufficient items with name %r"" % name)<tab><tab>else:<tab><tab><tab>raise AttributeError(""insufficient non-disabled items with name %s"" % name)<tab>on = []<tab>off = []<tab>for o in items:<tab><tab><IF-STMT><tab><tab><tab>on.append(o)<tab><tab>else:<tab><tab><tab>off.append(o)<tab>return on, off",if o . selected :,169
1677,def parse_flow_sequence_entry_mapping_value(self):<tab>if self.check_token(ValueToken):<tab><tab>token = self.get_token()<tab><tab><IF-STMT><tab><tab><tab>self.states.append(self.parse_flow_sequence_entry_mapping_end)<tab><tab><tab>return self.parse_flow_node()<tab><tab>else:<tab><tab><tab>self.state = self.parse_flow_sequence_entry_mapping_end<tab><tab><tab>return self.process_empty_scalar(token.end_mark)<tab>else:<tab><tab>self.state = self.parse_flow_sequence_entry_mapping_end<tab><tab>token = self.peek_token()<tab><tab>return self.process_empty_scalar(token.start_mark),"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :",194
1678,"def serialize_config(self, session, key, tid, language):<tab>cache_key = gen_cache_key(key, tid, language)<tab>cache_obj = None<tab>if cache_key not in self.cache:<tab><tab><IF-STMT><tab><tab><tab>cache_obj = db_admin_serialize_node(session, tid, language)<tab><tab>elif key == ""notification"":<tab><tab><tab>cache_obj = db_get_notification(session, tid, language)<tab><tab>self.cache[cache_key] = cache_obj<tab>return self.cache[cache_key]","if key == ""node"" :",139
1679,"def get_lldp_neighbors(self):<tab>commands = [""show lldp neighbors""]<tab>output = self.device.run_commands(commands)[0][""lldpNeighbors""]<tab>lldp = {}<tab>for n in output:<tab><tab><IF-STMT><tab><tab><tab>lldp[n[""port""]] = []<tab><tab>lldp[n[""port""]].append(<tab><tab><tab>{""hostname"": n[""neighborDevice""], ""port"": n[""neighborPort""]}<tab><tab>)<tab>return lldp","if n [ ""port"" ] not in lldp . keys ( ) :",126
1680,"def handle(self):<tab>from poetry.utils.env import EnvManager<tab>manager = EnvManager(self.poetry)<tab>current_env = manager.get()<tab>for venv in manager.list():<tab><tab>name = venv.path.name<tab><tab>if self.option(""full-path""):<tab><tab><tab>name = str(venv.path)<tab><tab><IF-STMT><tab><tab><tab>self.line(""<info>{} (Activated)</info>"".format(name))<tab><tab><tab>continue<tab><tab>self.line(name)",if venv == current_env :,129
1681,"def resolve_env_secrets(config, environ):<tab>""""""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ""""""<tab>if isinstance(config, dict):<tab><tab>if list(config.keys()) == [""$env""]:<tab><tab><tab>return environ.get(list(config.values())[0])<tab><tab><IF-STMT><tab><tab><tab>return open(list(config.values())[0]).read()<tab><tab>else:<tab><tab><tab>return {<tab><tab><tab><tab>key: resolve_env_secrets(value, environ)<tab><tab><tab><tab>for key, value in config.items()<tab><tab><tab>}<tab>elif isinstance(config, list):<tab><tab>return [resolve_env_secrets(value, environ) for value in config]<tab>else:<tab><tab>return config","elif list ( config . keys ( ) ) == [ ""$file"" ] :",190
1682,"def _is_valid_16bit_as_path(cls, buf):<tab>two_byte_as_size = struct.calcsize(""!H"")<tab>while buf:<tab><tab>(type_, num_as) = struct.unpack_from(<tab><tab><tab>cls._SEG_HDR_PACK_STR, six.binary_type(buf)<tab><tab>)<tab><tab>if type_ is not cls._AS_SET and type_ is not cls._AS_SEQUENCE:<tab><tab><tab>return False<tab><tab>buf = buf[struct.calcsize(cls._SEG_HDR_PACK_STR) :]<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>buf = buf[num_as * two_byte_as_size :]<tab>return True",if len ( buf ) < num_as * two_byte_as_size :,190
1683,"def reparentChildren(self, newParent):<tab>if newParent.childNodes:<tab><tab>newParent.childNodes[-1]._element.tail += self._element.text<tab>else:<tab><tab><IF-STMT><tab><tab><tab>newParent._element.text = """"<tab><tab>if self._element.text is not None:<tab><tab><tab>newParent._element.text += self._element.text<tab>self._element.text = """"<tab>base.Node.reparentChildren(self, newParent)",if not newParent . _element . text :,121
1684,"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab>if isinstance(definition, ast.OperationDefinition):<tab><tab><tab>if not operation_name:<tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab>if operation:<tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return definition<tab>return operation",elif definition . name and definition . name . value == operation_name :,186
1685,"def reprSmart(vw, item):<tab>ptype = type(item)<tab>if ptype is int:<tab><tab><IF-STMT><tab><tab><tab>return str(item)<tab><tab>elif vw.isValidPointer(item):<tab><tab><tab>return vw.reprPointer(item)<tab><tab>else:<tab><tab><tab>return hex(item)<tab>elif ptype in (list, tuple):<tab><tab>return reprComplex(vw, item)  # recurse<tab>elif ptype is dict:<tab><tab>return ""{%s}"" % "","".join(<tab><tab><tab>[""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()]<tab><tab>)<tab>else:<tab><tab>return repr(item)",if - 1024 < item < 1024 :,183
1686,"def cleanDataCmd(cmd):<tab>newcmd = ""AbracadabrA ** <?php ""<tab>if cmd[:6] != ""php://"":<tab><tab><IF-STMT><tab><tab><tab>cmds = cmd.split(""&"")<tab><tab><tab>for c in cmds:<tab><tab><tab><tab>if len(c) > 0:<tab><tab><tab><tab><tab>newcmd += ""system('%s');"" % c<tab><tab>else:<tab><tab><tab>b64cmd = base64.b64encode(cmd)<tab><tab><tab>newcmd += ""system(base64_decode('%s'));"" % b64cmd<tab>else:<tab><tab>newcmd += cmd[6:]<tab>newcmd += ""?> **""<tab>return newcmd",if reverseConn not in cmd :,170
1687,"def render_tasks(self) -> List:<tab>results = []<tab>for task in self.tasks.values():<tab><tab>job_entry = self.jobs.get(task.job_id)<tab><tab><IF-STMT><tab><tab><tab>if not self.should_render_job(job_entry):<tab><tab><tab><tab>continue<tab><tab>files = self.get_file_counts([task])<tab><tab>entry = (<tab><tab><tab>task.job_id,<tab><tab><tab>task.task_id,<tab><tab><tab>task.state,<tab><tab><tab>task.type.name,<tab><tab><tab>task.target,<tab><tab><tab>files,<tab><tab><tab>task.pool,<tab><tab><tab>task.end_time,<tab><tab>)<tab><tab>results.append(entry)<tab>return results",if job_entry :,186
1688,"def __call__(self, environ, start_response):<tab>for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"":<tab><tab>if key not in environ:<tab><tab><tab>continue<tab><tab>request_uri = unquote(environ[key])<tab><tab>script_name = unquote(environ.get(""SCRIPT_NAME"", """"))<tab><tab><IF-STMT><tab><tab><tab>environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0]<tab><tab><tab>break<tab>return self.app(environ, start_response)",if request_uri . startswith ( script_name ) :,140
1689,"def _add_role_information(self, function_dict, role_id):<tab># Make it easier to build rules based on policies attached to execution roles<tab>function_dict[""role_arn""] = role_id<tab>role_name = role_id.split(""/"")[-1]<tab>function_dict[<tab><tab>""execution_role""<tab>] = await self.facade.awslambda.get_role_with_managed_policies(role_name)<tab>if function_dict.get(""execution_role""):<tab><tab>statements = []<tab><tab>for policy in function_dict[""execution_role""].get(""policies""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statements += policy[""Document""][""Statement""]<tab><tab>function_dict[""execution_role""][""policy_statements""] = statements","if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :",196
1690,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_ts(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,90
1691,"def format_counts(results, json_output=False, human_readable=False):<tab>if json_output:<tab><tab>for result in results:<tab><tab><tab>yield json.dumps(result)<tab>else:<tab><tab>for result in results:<tab><tab><tab>space_consumed = result.get(""spaceConsumed"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>space_consumed = _sizeof_fmt(int(result.get(""spaceConsumed"")))<tab><tab><tab>yield ""%12s %12s %18s %s"" % (<tab><tab><tab><tab>result.get(""directoryCount""),<tab><tab><tab><tab>result.get(""fileCount""),<tab><tab><tab><tab>space_consumed,<tab><tab><tab><tab>result.get(""path""),<tab><tab><tab>)",if human_readable :,175
1692,"def parse_edges(self, pcb):<tab>edges = []<tab>drawings = list(pcb.GetDrawings())<tab>bbox = None<tab>for m in pcb.GetModules():<tab><tab>for g in m.GraphicalItems():<tab><tab><tab>drawings.append(g)<tab>for d in drawings:<tab><tab>if d.GetLayer() == pcbnew.Edge_Cuts:<tab><tab><tab>parsed_drawing = self.parse_drawing(d)<tab><tab><tab>if parsed_drawing:<tab><tab><tab><tab>edges.append(parsed_drawing)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>bbox = d.GetBoundingBox()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>bbox.Merge(d.GetBoundingBox())<tab>if bbox:<tab><tab>bbox.Normalize()<tab>return edges, bbox",if bbox is None :,197
1693,"def __getitem__(self, k) -> ""SimMemView"":<tab>if isinstance(k, slice):<tab><tab>if k.step is not None:<tab><tab><tab>raise ValueError(""Slices with strides are not supported"")<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Must specify start index"")<tab><tab>elif k.stop is not None:<tab><tab><tab>raise ValueError(""Slices with stop index are not supported"")<tab><tab>else:<tab><tab><tab>addr = k.start<tab>elif self._type is not None and self._type._can_refine_int:<tab><tab>return self._type._refine(self, k)<tab>else:<tab><tab>addr = k<tab>return self._deeper(addr=addr)",elif k . start is None :,169
1694,"def _parse(self, stream, context):<tab>obj = []<tab>try:<tab><tab>if self.subcon.conflags & self.FLAG_COPY_CONTEXT:<tab><tab><tab>while True:<tab><tab><tab><tab>subobj = self.subcon._parse(stream, context.__copy__())<tab><tab><tab><tab>obj.append(subobj)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>while True:<tab><tab><tab><tab>subobj = self.subcon._parse(stream, context)<tab><tab><tab><tab>obj.append(subobj)<tab><tab><tab><tab>if self.predicate(subobj, context):<tab><tab><tab><tab><tab>break<tab>except ConstructError as ex:<tab><tab>raise ArrayError(""missing terminator"", ex)<tab>return obj","if self . predicate ( subobj , context ) :",191
1695,"def before_run(self, run_context):<tab>if ""featurizer"" in self.model_portion and (<tab><tab>self.need_to_refresh or self.refresh_base_model<tab>):<tab><tab><IF-STMT><tab><tab><tab>self.refresh_base_model = True<tab><tab>self.init_fn(<tab><tab><tab>None, run_context.session, self.model_portion, self.refresh_base_model<tab><tab>)<tab><tab>self.need_to_refresh = False<tab><tab>self.refresh_base_model = False","if self . model_portion == ""whole_featurizer"" :",141
1696,"def run(self):<tab>while True:<tab><tab>task = self.requestQueue.get()<tab><tab>if task is None:<tab><tab><tab># The ""None"" value is used as a sentinel by<tab><tab><tab># ThreadPool.cleanup().  This indicates that there<tab><tab><tab># are no more tasks, so we should quit.<tab><tab><tab>break<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise SCons.Errors.BuildError(task.targets[0], errstr=interrupt_msg)<tab><tab><tab>task.execute()<tab><tab>except:<tab><tab><tab>task.exception_set()<tab><tab><tab>ok = False<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.resultsQueue.put((task, ok))",if self . interrupted ( ) :,178
1697,"def get_overdue_evergreen_documents(*, db_session) -> List[Optional[Document]]:<tab>""""""Returns all documents that have need had a recent evergreen notification.""""""<tab>documents = (<tab><tab>db_session.query(Document).filter(Document.evergreen == True)<tab>).all()  # noqa<tab>overdue_documents = []<tab>now = datetime.utcnow()<tab>for d in documents:<tab><tab>next_reminder = d.evergreen_last_reminder_at + timedelta(<tab><tab><tab>days=d.evergreen_reminder_interval<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>overdue_documents.append(d)<tab>return overdue_documents",if now > next_reminder :,163
1698,"def create_local_app_folder(local_app_path):<tab>if exists(local_app_path):<tab><tab>raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path)<tab>for folder in subfolders(local_app_path):<tab><tab>if not exists(folder):<tab><tab><tab>os.mkdir(folder)<tab><tab><tab>init_path = join(folder, ""__init__.py"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>create_file(init_path)",if not exists ( init_path ) :,126
1699,"def generate():<tab>for leaf in u.leaves:<tab><tab><IF-STMT><tab><tab><tab>val = leaf.get_int_value()<tab><tab><tab>if val in (0, 1):<tab><tab><tab><tab>yield val<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>elif isinstance(leaf, Symbol):<tab><tab><tab>if leaf == SymbolTrue:<tab><tab><tab><tab>yield 1<tab><tab><tab>elif leaf == SymbolFalse:<tab><tab><tab><tab>yield 0<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>else:<tab><tab><tab>raise _NoBoolVector","if isinstance ( leaf , Integer ) :",138
1700,"def replace(self, old, new):<tab>v_m = self.var_map<tab>size = v_m[self.size]<tab>if not (size.is_const() or size.is_ident()):<tab><tab>size.replace(old, new)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>v_m[new.value()] = new<tab><tab><tab>self.size = new.value()<tab><tab>else:<tab><tab><tab>v_m[old] = new",if new . is_ident ( ) :,119
1701,"def method_for_doctype(doctype):<tab>method = ""xhtml""<tab>if doctype:<tab><tab>if doctype.startswith(""html""):<tab><tab><tab>method = ""html""<tab><tab><IF-STMT><tab><tab><tab>method = ""xhtml""<tab><tab>elif doctype.startswith(""svg""):<tab><tab><tab>method = ""xml""<tab><tab>else:<tab><tab><tab>method = ""xhtml""<tab>return method","elif doctype . startswith ( ""xhtml"" ) :",101
1702,"def delete(self, trans, **kwd):<tab>idnum = kwd[self.tagged_item_id]<tab>item = self._get_item_from_id(trans, idnum, check_writable=True)<tab>if item is not None:<tab><tab>ex_obj = self.get_item_extended_metadata_obj(trans, item)<tab><tab><IF-STMT><tab><tab><tab>self.unset_item_extended_metadata_obj(trans, item)<tab><tab><tab>self.delete_extended_metadata(trans, ex_obj)",if ex_obj is not None :,131
1703,"def check_testv(self, testv):<tab>test_good = True<tab>f = open(self.home, ""rb+"")<tab>for (offset, length, operator, specimen) in testv:<tab><tab>data = self._read_share_data(f, offset, length)<tab><tab><IF-STMT><tab><tab><tab>test_good = False<tab><tab><tab>break<tab>f.close()<tab>return test_good","if not testv_compare ( data , operator , specimen ) :",113
1704,"def get_history_user(self, instance):<tab>""""""Get the modifying user from instance or middleware.""""""<tab>try:<tab><tab>return instance._history_user<tab>except AttributeError:<tab><tab>request = None<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>request = self.thread.request<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return self.get_user(instance=instance, request=request)",if self . thread . request . user . is_authenticated :,110
1705,"def _check(self, name, size=None, *extra):<tab>func = getattr(imageop, name)<tab>for height in VALUES:<tab><tab>for width in VALUES:<tab><tab><tab>strlen = abs(width * height)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strlen *= size<tab><tab><tab>if strlen < MAX_LEN:<tab><tab><tab><tab>data = ""A"" * strlen<tab><tab><tab>else:<tab><tab><tab><tab>data = AAAAA<tab><tab><tab>if size:<tab><tab><tab><tab>arguments = (data, size, width, height) + extra<tab><tab><tab>else:<tab><tab><tab><tab>arguments = (data, width, height) + extra<tab><tab><tab>try:<tab><tab><tab><tab>func(*arguments)<tab><tab><tab>except (ValueError, imageop.error):<tab><tab><tab><tab>pass",if size :,188
1706,"def __setattr__(self, name, value):<tab>if name == ""path"":<tab><tab>if value and value != """":<tab><tab><tab>if value[0] != ""/"":<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>'The page path should always start with a slash (""/"").'<tab><tab><tab><tab>)<tab>elif name == ""load_time"":<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Page load time must be specified in integer milliseconds.""<tab><tab><tab>)<tab>object.__setattr__(self, name, value)","if value and not isinstance ( value , int ) :",136
1707,"def __repr__(self):<tab>if self._in_repr:<tab><tab>return ""<recursion>""<tab>try:<tab><tab>self._in_repr = True<tab><tab>if self.is_computed():<tab><tab><tab>status = ""computed, ""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.value() is self:<tab><tab><tab><tab><tab>status += ""= self""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>status += ""= "" + repr(self.value())<tab><tab><tab>else:<tab><tab><tab><tab>status += ""error = "" + repr(self.error())<tab><tab>else:<tab><tab><tab>status = ""isn't computed""<tab><tab>return ""%s (%s)"" % (type(self), status)<tab>finally:<tab><tab>self._in_repr = False",if self . error ( ) is None :,189
1708,"def _exclude_node(self, name):<tab>if ""exclude_nodes"" in self.node_filters:<tab><tab><IF-STMT><tab><tab><tab>self.loggit.info('Excluding node ""{0}"" due to node_filters'.format(name))<tab><tab><tab>return True<tab>return False","if name in self . node_filters [ ""exclude_nodes"" ] :",79
1709,"def enumerate_projects():<tab>""""""List projects in _DEFAULT_APP_DIR.""""""<tab>src_path = os.path.join(_DEFAULT_APP_DIR, ""src"")<tab>projects = {}<tab>for project in os.listdir(src_path):<tab><tab>projects[project] = []<tab><tab>project_path = os.path.join(src_path, project)<tab><tab>for file in os.listdir(project_path):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>projects[project].append(file[:-8])<tab>return projects","if file . endswith ( "".gwt.xml"" ) :",133
1710,"def zip_readline_read_test(self, f, compression):<tab>self.make_test_archive(f, compression)<tab># Read the ZIP archive<tab>with zipfile.ZipFile(f, ""r"") as zipfp, zipfp.open(TESTFN) as zipopen:<tab><tab>data = b""""<tab><tab>while True:<tab><tab><tab>read = zipopen.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>data += read<tab><tab><tab>read = zipopen.read(100)<tab><tab><tab>if not read:<tab><tab><tab><tab>break<tab><tab><tab>data += read<tab>self.assertEqual(data, self.data)",if not read :,155
1711,"def f(view, s):<tab>if mode == modes.NORMAL:<tab><tab>return sublime.Region(0)<tab>elif mode == modes.VISUAL:<tab><tab><IF-STMT><tab><tab><tab>return sublime.Region(s.a + 1, 0)<tab><tab>else:<tab><tab><tab>return sublime.Region(s.a, 0)<tab>elif mode == modes.INTERNAL_NORMAL:<tab><tab>return sublime.Region(view.full_line(s.b).b, 0)<tab>elif mode == modes.VISUAL_LINE:<tab><tab>if s.a < s.b:<tab><tab><tab>return sublime.Region(0, s.b)<tab><tab>else:<tab><tab><tab>return sublime.Region(0, s.a)<tab>return s",if s . a < s . b :,192
1712,def response(self):<tab>try:<tab><tab>response = requests.get(str(self))<tab><tab>rjson = response.json()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(response.text)<tab><tab>return rjson<tab>except Exception as e:<tab><tab>raise ResponseFanartError(str(e)),"if not isinstance ( rjson , dict ) :",82
1713,"def __get_type(self, cexpr):<tab>""""""Returns one of the following types: 'R' - read value, 'W' - write value, 'A' - function argument""""""<tab>child = cexpr<tab>for p in reversed(self.parents):<tab><tab>assert p, ""Failed to get type at "" + helper.to_hex(self.__function_address)<tab><tab>if p.cexpr.op == idaapi.cot_call:<tab><tab><tab>return ""Arg""<tab><tab>if not p.is_expr():<tab><tab><tab>return ""R""<tab><tab>if p.cexpr.op == idaapi.cot_asg:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""W""<tab><tab><tab>return ""R""<tab><tab>child = p.cexpr",if p . cexpr . x == child :,192
1714,"def _extract_lemma(self, parse: Parse) -> str:<tab>special_feats = [x for x in self.SPECIAL_FEATURES if x in parse.tag]<tab>if len(special_feats) == 0:<tab><tab>return parse.normal_form<tab># here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly<tab>for other in parse.lexeme:<tab><tab>tag = other.tag<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>tag.case == ""nomn""<tab><tab><tab>and tag.gender == parse.tag.gender<tab><tab><tab>and tag.number == ""sing""<tab><tab>):<tab><tab><tab>return other.word<tab>return parse.normal_form",if any ( x not in tag for x in special_feats ) :,185
1715,"def evaluateWord(self, argument):<tab>wildcard_count = argument[0].count(""*"")<tab>if wildcard_count > 0:<tab><tab>if wildcard_count == 1 and argument[0].startswith(""*""):<tab><tab><tab>return self.GetWordWildcard(argument[0][1:], method=""endswith"")<tab><tab><IF-STMT><tab><tab><tab>return self.GetWordWildcard(argument[0][:-1], method=""startswith"")<tab><tab>else:<tab><tab><tab>_regex = argument[0].replace(""*"", "".+"")<tab><tab><tab>matched = False<tab><tab><tab>for w in self.words:<tab><tab><tab><tab>matched = bool(re.search(_regex, w))<tab><tab><tab><tab>if matched:<tab><tab><tab><tab><tab>break<tab><tab><tab>return matched<tab>return self.GetWord(argument[0])","if wildcard_count == 1 and argument [ 0 ] . endswith ( ""*"" ) :",194
1716,def getAllEntries(self):<tab>entries = []<tab>for bucket in self.buckets:<tab><tab>last = None<tab><tab>for entry in bucket.entries:<tab><tab><tab>if last is not None:<tab><tab><tab><tab>last.size = entry.virtualOffset - last.virtualOffset<tab><tab><tab>last = entry<tab><tab><tab>entries.append(entry)<tab><tab><IF-STMT><tab><tab><tab>entries[-1].size = bucket.endOffset - entries[-1].virtualOffset<tab>return entries,if len ( entries ) != 0 :,119
1717,def clean(self):<tab>if self._ctx:<tab><tab><IF-STMT><tab><tab><tab>libcrypto.EVP_CIPHER_CTX_cleanup(self._ctx)<tab><tab>else:<tab><tab><tab>libcrypto.EVP_CIPHER_CTX_reset(self._ctx)<tab><tab>libcrypto.EVP_CIPHER_CTX_free(self._ctx),"if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :",96
1718,"def _addTab(self, name, label, idx=None):<tab>label = getLanguageString(label)<tab>tab = Tab(self, name, label)<tab>tab.idx = self._makeTab(tab, idx)<tab>if idx != None:<tab><tab># Update index list when inserting tabs at arbitrary positions<tab><tab>newIdxList = {}<tab><tab>for tIdx, t in list(self._tabs_by_idx.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>t.idx += 1<tab><tab><tab>newIdxList[t.idx] = t<tab><tab>self._tabs_by_idx = newIdxList<tab>self._tabs_by_idx[tab.idx] = tab<tab>self._tabs_by_name[tab.name] = tab<tab>return tab",if int ( tIdx ) >= idx :,189
1719,"def set(self, _key, _new_login=True):<tab>with self.lock:<tab><tab>user = self.users.get(current_user.id, None)<tab><tab><IF-STMT><tab><tab><tab>self.users[current_user.id] = dict(session_count=1, key=_key)<tab><tab>else:<tab><tab><tab>if _new_login:<tab><tab><tab><tab>user[""session_count""] += 1<tab><tab><tab>user[""key""] = _key",if user is None :,116
1720,"def stop(self):<tab># Try to shut the connection down, but if we get any sort of<tab># errors, go ahead and ignore them.. as we're shutting down anyway<tab>try:<tab><tab>self.rpcserver.stop()<tab><tab><IF-STMT><tab><tab><tab>self.backend_rpcserver.stop()<tab><tab>if self.cluster_rpcserver:<tab><tab><tab>self.cluster_rpcserver.stop()<tab>except Exception:<tab><tab>pass<tab>if self.coordination:<tab><tab>try:<tab><tab><tab>coordination.COORDINATOR.stop()<tab><tab>except Exception:<tab><tab><tab>pass<tab>super(Service, self).stop(graceful=True)",if self . backend_rpcserver :,171
1721,"def __genmenuOnlyAllocated(menu):<tab>for submenu in menu.Submenus:<tab><tab>__genmenuOnlyAllocated(submenu)<tab>if menu.OnlyUnallocated == True:<tab><tab>tmp[""cache""].addMenuEntries(menu.AppDirs)<tab><tab>menuentries = []<tab><tab>for rule in menu.Rules:<tab><tab><tab>menuentries = rule.do(<tab><tab><tab><tab>tmp[""cache""].getMenuEntries(menu.AppDirs), rule.Type, 2<tab><tab><tab>)<tab><tab>for menuentry in menuentries:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>menuentry.Parents.append(menu)<tab><tab><tab><tab>#   menuentry.Add = False<tab><tab><tab><tab>#   menuentry.Allocated = True<tab><tab><tab><tab>menu.MenuEntries.append(menuentry)",if menuentry . Add == True :,198
1722,"def __init__(self, **options):<tab>self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True)<tab>self.disabled_modules = get_list_opt(options, ""disabled_modules"", [])<tab>self._functions = set()<tab>if self.func_name_highlighting:<tab><tab>from pygments.lexers._lua_builtins import MODULES<tab><tab>for mod, func in iteritems(MODULES):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._functions.update(func)<tab>RegexLexer.__init__(self, **options)",if mod not in self . disabled_modules :,150
1723,"def recv_some(p, t=0.1, e=1, tr=5, stderr=0):<tab>if tr < 1:<tab><tab>tr = 1<tab>x = time.time() + t<tab>y = []<tab>r = """"<tab>if stderr:<tab><tab>pr = p.recv_err<tab>else:<tab><tab>pr = p.recv<tab>while time.time() < x or r:<tab><tab>r = pr()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif r:<tab><tab><tab>y.append(r)<tab><tab>else:<tab><tab><tab>time.sleep(max((x - time.time()) / tr, 0))<tab>return """".join(y)",if r is None :,168
1724,"def get_menu_items(node):<tab>aList = []<tab>for child in node.children:<tab><tab>for tag in (""@menu"", ""@item""):<tab><tab><tab>if child.h.startswith(tag):<tab><tab><tab><tab>name = child.h[len(tag) + 1 :].strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>aList.append((""%s %s"" % (tag, name), get_menu_items(child), None))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>b = g.splitLines("""".join(child.b))<tab><tab><tab><tab><tab>aList.append((tag, name, b[0] if b else """"))<tab><tab><tab><tab>break<tab>return aList","if tag == ""@menu"" :",173
1725,"def import_suffix_generator(a_block, datatype=False):<tab>if datatype is False:<tab><tab>for name, suffix in iteritems(a_block.component_map(Suffix)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield name, suffix<tab>else:<tab><tab>for name, suffix in iteritems(a_block.component_map(Suffix)):<tab><tab><tab>if (suffix.import_enabled() is True) and (<tab><tab><tab><tab>suffix.get_datatype() is datatype<tab><tab><tab>):<tab><tab><tab><tab>yield name, suffix",if suffix . import_enabled ( ) is True :,136
1726,"def verify_relative_valid_path(root, path):<tab>if len(path) < 1:<tab><tab>raise PackagerError(""Empty chown path"")<tab>checkpath = root<tab>parts = path.split(os.sep)<tab>for part in parts:<tab><tab>if part in (""."", ""..""):<tab><tab><tab>raise PackagerError("". and .. is not allowed in chown path"")<tab><tab>checkpath = os.path.join(checkpath, part)<tab><tab>relpath = checkpath[len(root) + 1 :]<tab><tab>if not os.path.exists(checkpath):<tab><tab><tab>raise PackagerError(f""chown path {relpath} does not exist"")<tab><tab><IF-STMT><tab><tab><tab>raise PackagerError(f""chown path {relpath} is a soft link"")",if os . path . islink ( checkpath ) :,191
1727,"def load_syntax(syntax):<tab>context = _create_scheme() or {}<tab>partition_scanner = PartitionScanner(syntax.get(""partitions"", []))<tab>scanners = {}<tab>for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()):<tab><tab>scanners[part_name] = Scanner(part_scanner)<tab>formats = []<tab>for fname, fstyle in list(syntax.get(""formats"", {}).items()):<tab><tab><IF-STMT><tab><tab><tab>if fstyle.startswith(""%("") and fstyle.endswith("")s""):<tab><tab><tab><tab>key = fstyle[2:-2]<tab><tab><tab><tab>fstyle = context[key]<tab><tab><tab>else:<tab><tab><tab><tab>fstyle = fstyle % context<tab><tab>formats.append((fname, fstyle))<tab>return partition_scanner, scanners, formats","if isinstance ( fstyle , basestring ) :",199
1728,"def should_keep_alive(commit_msg):<tab>result = False<tab>ci = get_current_ci() or """"<tab>for line in commit_msg.splitlines():<tab><tab>parts = line.strip(""# "").split("":"", 1)<tab><tab>(key, val) = parts if len(parts) > 1 else (parts[0], """")<tab><tab><IF-STMT><tab><tab><tab>ci_names = val.replace("","", "" "").lower().split() if val else []<tab><tab><tab>if len(ci_names) == 0 or ci.lower() in ci_names:<tab><tab><tab><tab>result = True<tab>return result","if key == ""CI_KEEP_ALIVE"" :",150
1729,"def get_note_title_file(note):<tab>mo = note_title_re.match(note.get(""content"", """"))<tab>if mo:<tab><tab>fn = mo.groups()[0]<tab><tab>fn = fn.replace("" "", ""_"")<tab><tab>fn = fn.replace(""/"", ""_"")<tab><tab>if not fn:<tab><tab><tab>return """"<tab><tab><IF-STMT><tab><tab><tab>fn = unicode(fn, ""utf-8"")<tab><tab>else:<tab><tab><tab>fn = unicode(fn)<tab><tab>if note_markdown(note):<tab><tab><tab>fn += "".mkdn""<tab><tab>else:<tab><tab><tab>fn += "".txt""<tab><tab>return fn<tab>else:<tab><tab>return """"","if isinstance ( fn , str ) :",169
1730,"def post(self, orgname, teamname):<tab>if _syncing_setup_allowed(orgname):<tab><tab>try:<tab><tab><tab>team = model.team.get_organization_team(orgname, teamname)<tab><tab>except model.InvalidTeamException:<tab><tab><tab>raise NotFound()<tab><tab>config = request.get_json()<tab><tab># Ensure that the specified config points to a valid group.<tab><tab>status, err = authentication.check_group_lookup_args(config)<tab><tab><IF-STMT><tab><tab><tab>raise InvalidRequest(""Could not sync to group: %s"" % err)<tab><tab># Set the team's syncing config.<tab><tab>model.team.set_team_syncing(team, authentication.federated_service, config)<tab><tab>return team_view(orgname, team)<tab>raise Unauthorized()",if not status :,199
1731,"def _marshalData(self):<tab>if self._cache == None:<tab><tab>d = self._data<tab><tab>s = """"<tab><tab>s = time.strftime(""%H:%M:%S"", (0, 0, 0) + d + (0, 0, -1))<tab><tab>f = d[2] - int(d[2])<tab><tab><IF-STMT><tab><tab><tab>s += (""%g"" % f)[1:]<tab><tab>s += ""Z""<tab><tab>self._cache = s<tab>return self._cache",if f != 0 :,126
1732,"def _get_level(levels, level_ref):<tab>if level_ref in levels:<tab><tab>return levels.index(level_ref)<tab>if isinstance(level_ref, six.integer_types):<tab><tab>if level_ref < 0:<tab><tab><tab>level_ref += len(levels)<tab><tab><IF-STMT><tab><tab><tab>raise PatsyError(""specified level %r is out of range"" % (level_ref,))<tab><tab>return level_ref<tab>raise PatsyError(""specified level %r not found"" % (level_ref,))",if not ( 0 <= level_ref < len ( levels ) ) :,138
1733,"def iterfieldselect(source, field, where, complement, missing):<tab>it = iter(source)<tab>hdr = next(it)<tab>yield tuple(hdr)<tab>indices = asindices(hdr, field)<tab>getv = operator.itemgetter(*indices)<tab>for row in it:<tab><tab>try:<tab><tab><tab>v = getv(row)<tab><tab>except IndexError:<tab><tab><tab>v = missing<tab><tab><IF-STMT>  # XOR<tab><tab><tab>yield tuple(row)",if bool ( where ( v ) ) != complement :,122
1734,"def _test_wait_read_invalid_switch(self, sleep):<tab>sock1, sock2 = socket.socketpair()<tab>try:<tab><tab>p = gevent.spawn(<tab><tab><tab>util.wrap_errors(<tab><tab><tab><tab>AssertionError, socket.wait_read<tab><tab><tab>),  # pylint:disable=no-member<tab><tab><tab>sock1.fileno(),<tab><tab>)<tab><tab>gevent.get_hub().loop.run_callback(switch_None, p)<tab><tab><IF-STMT><tab><tab><tab>gevent.sleep(sleep)<tab><tab>result = p.get()<tab><tab>assert isinstance(result, AssertionError), result<tab><tab>assert ""Invalid switch"" in str(result), repr(str(result))<tab>finally:<tab><tab>sock1.close()<tab><tab>sock2.close()",if sleep is not None :,190
1735,"def train(config, args):<tab>gan = setup_gan(config, inputs, args)<tab>test_batches = []<tab>for i in range(args.steps):<tab><tab>gan.step()<tab><tab><IF-STMT><tab><tab><tab>correct_prediction = 0<tab><tab><tab>total = 0<tab><tab><tab>for (x, y) in gan.inputs.testdata():<tab><tab><tab><tab>prediction = gan.generator(x)<tab><tab><tab><tab>correct_prediction += (<tab><tab><tab><tab><tab>torch.argmax(prediction, 1) == torch.argmax(y, 1)<tab><tab><tab><tab>).sum()<tab><tab><tab><tab>total += y.shape[0]<tab><tab><tab>accuracy = (float(correct_prediction) / total) * 100<tab><tab><tab>print(""accuracy: "", accuracy)<tab>return sum_metrics",if i % args . sample_every == 0 and i > 0 :,200
1736,"def process_response(self, request, response, spider):<tab>if not response.body:<tab><tab>return response<tab>for fmt, func in six.iteritems(self._formats):<tab><tab>new_response = func(response)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(<tab><tab><tab><tab>""Decompressed response with format: %(responsefmt)s"",<tab><tab><tab><tab>{""responsefmt"": fmt},<tab><tab><tab><tab>extra={""spider"": spider},<tab><tab><tab>)<tab><tab><tab>return new_response<tab>return response",if new_response :,126
1737,"def detect_ssl_option(self):<tab>for option in self.ssl_options():<tab><tab><IF-STMT><tab><tab><tab>for other_option in self.ssl_options():<tab><tab><tab><tab>if option != other_option:<tab><tab><tab><tab><tab>if scan_argv(self.argv, other_option) is not None:<tab><tab><tab><tab><tab><tab>raise ConfigurationError(<tab><tab><tab><tab><tab><tab><tab>""Cannot give both %s and %s"" % (option, other_option)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab>return option","if scan_argv ( self . argv , option ) is not None :",140
1738,"def load(cls, storefile, template_store):<tab># Did we get file or filename?<tab>if not hasattr(storefile, ""read""):<tab><tab>storefile = open(storefile, ""rb"")<tab># Adjust store to have translations<tab>store = cls.convertfile(storefile, template_store)<tab>for unit in store.units:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># HTML does this properly on loading, others need it<tab><tab>if cls.needs_target_sync:<tab><tab><tab>unit.target = unit.source<tab><tab><tab>unit.rich_target = unit.rich_source<tab>return store",if unit . isheader ( ) :,152
1739,"def _pre_get_table(self, _ctx, table_name):<tab>vsctl_table = self._get_table(table_name)<tab>schema_helper = self.schema_helper<tab>schema_helper.register_table(vsctl_table.table_name)<tab>for row_id in vsctl_table.row_ids:<tab><tab><IF-STMT><tab><tab><tab>schema_helper.register_table(row_id.table)<tab><tab>if row_id.name_column:<tab><tab><tab>schema_helper.register_columns(row_id.table, [row_id.name_column])<tab><tab>if row_id.uuid_column:<tab><tab><tab>schema_helper.register_columns(row_id.table, [row_id.uuid_column])<tab>return vsctl_table",if row_id . table :,194
1740,"def __init__(self, pin=None, pull_up=False):<tab>super(InputDevice, self).__init__(pin)<tab>try:<tab><tab>self.pin.function = ""input""<tab><tab>pull = ""up"" if pull_up else ""down""<tab><tab><IF-STMT><tab><tab><tab>self.pin.pull = pull<tab>except:<tab><tab>self.close()<tab><tab>raise<tab>self._active_state = False if pull_up else True<tab>self._inactive_state = True if pull_up else False",if self . pin . pull != pull :,130
1741,"def _increment_operations_count(self, operation, executed):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self._executed_operations += 1<tab><tab><tab>self._executed[operation.job_type] += 1<tab><tab>else:<tab><tab><tab>self._skipped[operation.job_type] += 1",if executed :,76
1742,"def emit(self, type, info=None):<tab># Overload emit() to send events to the proxy object at the other end<tab>ev = super().emit(type, info)<tab>if self._has_proxy is True and self._session.status > 0:<tab><tab># implicit: and self._disposed is False:<tab><tab><IF-STMT><tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])<tab><tab>elif type in self.__event_types_at_proxy:<tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",if type in self . __proxy_properties__ :,161
1743,"def validate_pull_secret(namespace):<tab>if namespace.pull_secret is None:<tab><tab># TODO: add aka.ms link here<tab><tab>warning = (<tab><tab><tab>""No --pull-secret provided: cluster will not include samples or operators from ""<tab><tab><tab>+ ""Red Hat or from certified partners.""<tab><tab>)<tab><tab>logger.warning(warning)<tab>else:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception()<tab><tab>except:<tab><tab><tab>raise InvalidArgumentValueError(""Invalid --pull-secret."")","if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :",145
1744,"def pack(types, *args):<tab>if len(types) != len(args):<tab><tab>raise Exception(""number of arguments does not match format string"")<tab>port = StringIO()<tab>for (type, value) in zip(types, args):<tab><tab>if type == ""V"":<tab><tab><tab>write_vuint(port, value)<tab><tab>elif type == ""v"":<tab><tab><tab>write_vint(port, value)<tab><tab><IF-STMT><tab><tab><tab>write_bvec(port, value)<tab><tab>else:<tab><tab><tab>raise Exception('unknown xpack format string item ""' + type + '""')<tab>return port.getvalue()","elif type == ""s"" :",153
1745,"def data(self):<tab>if self._data is not None:<tab><tab>return self._data<tab>else:<tab><tab><IF-STMT><tab><tab><tab>with open(self.path, ""rb"") as jsonfile:<tab><tab><tab><tab>data = jsonfile.read().decode(""utf8"")<tab><tab><tab><tab>data = json.loads(data)<tab><tab><tab><tab>self._data = data<tab><tab><tab><tab>return self._data<tab><tab>else:<tab><tab><tab>return dict()",if os . path . exists ( self . path ) :,120
1746,"def interact(self):<tab>self.output.write(""\n"")<tab>while True:<tab><tab>try:<tab><tab><tab>request = self.getline(""help> "")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>except (KeyboardInterrupt, EOFError):<tab><tab><tab>break<tab><tab>request = strip(request)<tab><tab># Make sure significant trailing quotation marks of literals don't<tab><tab># get deleted while cleaning input<tab><tab>if (<tab><tab><tab>len(request) > 2<tab><tab><tab>and request[0] == request[-1] in (""'"", '""')<tab><tab><tab>and request[0] not in request[1:-1]<tab><tab>):<tab><tab><tab>request = request[1:-1]<tab><tab>if lower(request) in (""q"", ""quit""):<tab><tab><tab>break<tab><tab>self.help(request)",if not request :,195
1747,"def api_attachment_metadata(self):<tab>resp = []<tab>for part in self.parts:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>k = {<tab><tab><tab>""content_type"": part.block.content_type,<tab><tab><tab>""size"": part.block.size,<tab><tab><tab>""filename"": part.block.filename,<tab><tab><tab>""id"": part.block.public_id,<tab><tab>}<tab><tab>content_id = part.content_id<tab><tab>if content_id:<tab><tab><tab>if content_id[0] == ""<"" and content_id[-1] == "">"":<tab><tab><tab><tab>content_id = content_id[1:-1]<tab><tab><tab>k[""content_id""] = content_id<tab><tab>resp.append(k)<tab>return resp",if not part . is_attachment :,194
1748,"def _notin_text(term, text, verbose=False):<tab>index = text.find(term)<tab>head = text[:index]<tab>tail = text[index + len(term) :]<tab>correct_text = head + tail<tab>diff = _diff_text(correct_text, text, verbose)<tab>newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)]<tab>for line in diff:<tab><tab>if line.startswith(u(""Skipping"")):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(u(""+ "")):<tab><tab><tab>newdiff.append(u(""  "") + line[2:])<tab><tab>else:<tab><tab><tab>newdiff.append(line)<tab>return newdiff","if line . startswith ( u ( ""- "" ) ) :",192
1749,"def get_api(user, url):<tab>global API_CACHE<tab>if API_CACHE is None or API_CACHE.get(url) is None:<tab><tab>API_CACHE_LOCK.acquire()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>API_CACHE = {}<tab><tab><tab>if API_CACHE.get(url) is None:<tab><tab><tab><tab>API_CACHE[url] = ImpalaDaemonApi(url)<tab><tab>finally:<tab><tab><tab>API_CACHE_LOCK.release()<tab>api = API_CACHE[url]<tab>api.set_user(user)<tab>return api",if API_CACHE is None :,148
1750,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_index_name_:<tab><tab>res += prefix + (""index_name: %s\n"" % self.DebugFormatString(self.index_name_))<tab>cnt = 0<tab>for e in self.prefix_value_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""prefix_value%s: %s\n"" % (elm, self.DebugFormatString(e)))<tab><tab>cnt += 1<tab>if self.has_value_prefix_:<tab><tab>res += prefix + (<tab><tab><tab>""value_prefix: %s\n"" % self.DebugFormatBool(self.value_prefix_)<tab><tab>)<tab>return res",if printElemNumber :,195
1751,"def add_group(x, nl, in_group, mw):<tab>if len(x) == 0:<tab><tab>return x<tab>if len(x) > 1 and not in_group:<tab><tab><IF-STMT><tab><tab><tab>return [""[[""] + x + [""]]""]<tab><tab>mw.warn(<tab><tab><tab>""Equation will multiplex and may produce inaccurate results (see manual)""<tab><tab>)<tab>return [""[""] + x + [""]""]","if supports_group ( x , nl ) :",114
1752,"def unfulfilled_items(self):<tab>unfulfilled_items = 0<tab>for order_item in self.items.all():<tab><tab><IF-STMT><tab><tab><tab>aggr = order_item.deliver_item.aggregate(delivered=Sum(""quantity""))<tab><tab><tab>unfulfilled_items += order_item.quantity - (aggr[""delivered""] or 0)<tab>return unfulfilled_items",if not order_item . canceled :,94
1753,"def _get_pattern(self, pattern_id):<tab>""""""Get pattern item by id.""""""<tab>for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3):<tab><tab><IF-STMT><tab><tab><tab>data = self.tagged_blocks.get_data(key)<tab><tab><tab>for pattern in data:<tab><tab><tab><tab>if pattern.pattern_id == pattern_id:<tab><tab><tab><tab><tab>return pattern<tab>return None",if key in self . tagged_blocks :,110
1754,"def query_lister(domain, query="""", max_items=None, attr_names=None):<tab>more_results = True<tab>num_results = 0<tab>next_token = None<tab>while more_results:<tab><tab>rs = domain.connection.query_with_attributes(<tab><tab><tab>domain, query, attr_names, next_token=next_token<tab><tab>)<tab><tab>for item in rs:<tab><tab><tab>if max_items:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>yield item<tab><tab><tab>num_results += 1<tab><tab>next_token = rs.next_token<tab><tab>more_results = next_token != None",if num_results == max_items :,166
1755,"def find_deprecated_settings(source):  # pragma: no cover<tab>from celery.utils import deprecated<tab>for name, opt in flatten(NAMESPACES):<tab><tab><IF-STMT><tab><tab><tab>deprecated.warn(<tab><tab><tab><tab>description=""The {0!r} setting"".format(name),<tab><tab><tab><tab>deprecation=opt.deprecate_by,<tab><tab><tab><tab>removal=opt.remove_by,<tab><tab><tab><tab>alternative=""Use the {0.alt} instead"".format(opt),<tab><tab><tab>)<tab>return source","if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) :",150
1756,"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.server.stop(2.0)<tab><tab>if self.sl_hdlr:<tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",if self . server :,96
1757,"def broadcast_events(self, events):<tab>LOGGER.debug(""Broadcasting events: %s"", events)<tab>with self._subscribers_cv:<tab><tab># Copy the subscribers<tab><tab>subscribers = {conn: sub.copy() for conn, sub in self._subscribers.items()}<tab>if subscribers:<tab><tab>for connection_id, subscriber in subscribers.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subscriber_events = [<tab><tab><tab><tab><tab>event for event in events if subscriber.is_subscribed(event)<tab><tab><tab><tab>]<tab><tab><tab><tab>event_list = EventList(events=subscriber_events)<tab><tab><tab><tab>self._send(connection_id, event_list.SerializeToString())",if subscriber . is_listening ( ) :,173
1758,"def _get_info(self, path):<tab>info = OrderedDict()<tab>if not self._is_mac() or self._has_xcode_tools():<tab><tab>stdout = None<tab><tab>try:<tab><tab><tab>stdout, stderr = Popen(<tab><tab><tab><tab>[self._find_binary(), ""info"", os.path.realpath(path)],<tab><tab><tab><tab>stdout=PIPE,<tab><tab><tab><tab>stderr=PIPE,<tab><tab><tab>).communicate()<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>if stdout:<tab><tab><tab><tab>for line in stdout.splitlines():<tab><tab><tab><tab><tab>line = u(line).split("": "", 1)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>info[line[0]] = line[1]<tab>return info",if len ( line ) == 2 :,194
1759,"def test_call_extern_c_fn(self):<tab>global memcmp<tab>memcmp = cffi_support.ExternCFunction(<tab><tab>""memcmp"",<tab><tab>(""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""),<tab>)<tab>@udf(BooleanVal(FunctionContext, StringVal, StringVal))<tab>def fn(context, a, b):<tab><tab>if a.is_null != b.is_null:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if len(a) != b.len:<tab><tab><tab>return False<tab><tab>if a.ptr == b.ptr:<tab><tab><tab>return True<tab><tab>return memcmp(a.ptr, b.ptr, a.len) == 0",if a is None :,199
1760,"def _flatten(*args):<tab>ahs = set()<tab>if len(args) > 0:<tab><tab>for item in args:<tab><tab><tab>if type(item) is ActionHandle:<tab><tab><tab><tab>ahs.add(item)<tab><tab><tab>elif type(item) in (list, tuple, dict, set):<tab><tab><tab><tab>for ah in item:<tab><tab><tab><tab><tab><IF-STMT>  # pragma:nocover<tab><tab><tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(ah))<tab><tab><tab><tab><tab>ahs.add(ah)<tab><tab><tab>else:  # pragma:nocover<tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(item))<tab>return ahs",if type ( ah ) is not ActionHandle :,183
1761,"def startElement(self, name, attrs, connection):<tab>if name == ""Parameter"":<tab><tab><IF-STMT><tab><tab><tab>self[self._current_param.name] = self._current_param<tab><tab>self._current_param = Parameter(self)<tab><tab>return self._current_param",if self . _current_param :,73
1762,"def _find_class_in_descendants(self, search_key):<tab>for cls in self.primitive_classes:<tab><tab>cls_key = (cls.__name__, cls.__module__)<tab><tab>self.class_cache[cls_key] = cls<tab><tab><IF-STMT><tab><tab><tab>return cls",if cls_key == search_key :,77
1763,"def doWorkForFindAll(self, v, target, partialMatch):<tab>sibling = self<tab>while sibling:<tab><tab>c1 = partialMatch and sibling.equalsTreePartial(target)<tab><tab>if c1:<tab><tab><tab>v.append(sibling)<tab><tab>else:<tab><tab><tab>c2 = not partialMatch and sibling.equalsTree(target)<tab><tab><tab>if c2:<tab><tab><tab><tab>v.append(sibling)<tab><tab>### regardless of match or not, check any children for matches<tab><tab><IF-STMT><tab><tab><tab>sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch)<tab><tab>sibling = sibling.getNextSibling()",if sibling . getFirstChild ( ) :,163
1764,"def forward(self, inputs: paddle.Tensor):<tab>outputs = []<tab>blocks = self.block(inputs)<tab>route = None<tab>for i, block in enumerate(blocks):<tab><tab>if i > 0:<tab><tab><tab>block = paddle.concat([route, block], axis=1)<tab><tab>route, tip = self.yolo_blocks[i](block)<tab><tab>block_out = self.block_outputs[i](tip)<tab><tab>outputs.append(block_out)<tab><tab><IF-STMT><tab><tab><tab>route = self.route_blocks_2[i](route)<tab><tab><tab>route = self.upsample(route)<tab>return outputs",if i < 2 :,163
1765,"def _filter_paths(basename, path, is_dir, exclude):<tab>"""""".gitignore style file filtering.""""""<tab>for item in exclude:<tab><tab># Items ending in '/' apply only to directories.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Items starting with '/' apply to the whole path.<tab><tab># In any other cases just the basename is used.<tab><tab>match = path if item.startswith(""/"") else basename<tab><tab>if fnmatch.fnmatch(match, item.strip(""/"")):<tab><tab><tab>return True<tab>return False","if item . endswith ( ""/"" ) and not is_dir :",130
1766,"def reposition_division(f1):<tab>lines = f1.splitlines()<tab>if lines[2] == division:<tab><tab>lines.pop(2)<tab>found = 0<tab>for i, line in enumerate(lines):<tab><tab>if line.startswith('""""""'):<tab><tab><tab>found += 1<tab><tab><tab>if found == 2:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break  # already in the right place<tab><tab><tab><tab>lines.insert(i + 1, """")<tab><tab><tab><tab>lines.insert(i + 2, division)<tab><tab><tab><tab>break<tab>return ""\n"".join(lines)","if division in ""\n"" . join ( lines ) :",153
1767,"def buildImage(opt):<tab>dpath = os.path.join(opt[""datapath""], ""COCO-IMG-2015"")<tab>version = ""1""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building image data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES[:1]:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,191
1768,"def colorformat(text):<tab>if text[0:1] == ""#"":<tab><tab>col = text[1:]<tab><tab><IF-STMT><tab><tab><tab>return col<tab><tab>elif len(col) == 3:<tab><tab><tab>return col[0] * 2 + col[1] * 2 + col[2] * 2<tab>elif text == """":<tab><tab>return """"<tab>assert False, ""wrong color format %r"" % text",if len ( col ) == 6 :,105
1769,"def tree_print(tree):<tab>for key in tree:<tab><tab>print(key, end="" "")  # end=' ' prevents a newline character<tab><tab>tree_element = tree[key]  # multiple lookups is expensive, even amortized O(1)!<tab><tab>for subElem in tree_element:<tab><tab><tab>print("" -> "", subElem, end="" "")<tab><tab><tab><IF-STMT>  # OP wants indenting after digits<tab><tab><tab><tab>print(""\n "")  # newline and a space to match indenting<tab><tab>print()  # forces a newline",if type ( subElem ) != str :,138
1770,"def is_dse_cluster(path):<tab>try:<tab><tab>with open(os.path.join(path, ""CURRENT""), ""r"") as f:<tab><tab><tab>name = f.readline().strip()<tab><tab><tab>cluster_path = os.path.join(path, name)<tab><tab><tab>filename = os.path.join(cluster_path, ""cluster.conf"")<tab><tab><tab>with open(filename, ""r"") as f:<tab><tab><tab><tab>data = yaml.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>except IOError:<tab><tab>return False","if ""dse_dir"" in data :",148
1771,"def delete_old_target_output_files(classpath_prefix):<tab>""""""Delete existing output files or symlinks for target.""""""<tab>directory, basename = os.path.split(classpath_prefix)<tab>pattern = re.compile(<tab><tab>r""^{basename}(([0-9]+)(\.jar)?|classpath\.txt)$"".format(<tab><tab><tab>basename=re.escape(basename)<tab><tab>)<tab>)<tab>files = [filename for filename in os.listdir(directory) if pattern.match(filename)]<tab>for rel_path in files:<tab><tab>path = os.path.join(directory, rel_path)<tab><tab><IF-STMT><tab><tab><tab>safe_delete(path)",if os . path . islink ( path ) or os . path . isfile ( path ) :,175
1772,"def test_files(self):<tab># get names of files to test<tab>dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)<tab>names = []<tab>for d in self.test_directories:<tab><tab>test_dir = os.path.join(dist_dir, d)<tab><tab>for n in os.listdir(test_dir):<tab><tab><tab>if n.endswith("".py"") and not n.startswith(""bad""):<tab><tab><tab><tab>names.append(os.path.join(test_dir, n))<tab>for filename in names:<tab><tab><IF-STMT><tab><tab><tab>print(""Testing %s"" % filename)<tab><tab>source = read_pyfile(filename)<tab><tab>self.check_roundtrip(source)",if test_support . verbose :,186
1773,"def __str__(self):<tab>if self.HasError():<tab><tab>return self.ErrorAsStr()<tab>else:<tab><tab># Format is: {action} ""{target}"" ({filename}:{lineno})<tab><tab>string = self._action<tab><tab>if self._target is not None:<tab><tab><tab>string += ' ""{target}""'.format(target=self._target)<tab><tab><IF-STMT><tab><tab><tab>path = self._filename<tab><tab><tab>if self._lineno is not None:<tab><tab><tab><tab>path += "":{lineno}"".format(lineno=self._lineno)<tab><tab><tab>string += "" ({path})"".format(path=path)<tab><tab>return string",if self . _filename is not None :,156
1774,"def extra_action_out(self, input_dict, state_batches, model, action_dist):<tab>with self._no_grad_context():<tab><tab><IF-STMT><tab><tab><tab>stats_dict = extra_action_out_fn(<tab><tab><tab><tab>self, input_dict, state_batches, model, action_dist<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>stats_dict = parent_cls.extra_action_out(<tab><tab><tab><tab>self, input_dict, state_batches, model, action_dist<tab><tab><tab>)<tab><tab>return self._convert_to_non_torch_type(stats_dict)",if extra_action_out_fn :,156
1775,"def _retract_bindings(fstruct, inv_bindings, fs_class, visited):<tab># Visit each node only once:<tab>if id(fstruct) in visited:<tab><tab>return<tab>visited.add(id(fstruct))<tab>if _is_mapping(fstruct):<tab><tab>items = fstruct.items()<tab>elif _is_sequence(fstruct):<tab><tab>items = enumerate(fstruct)<tab>else:<tab><tab>raise ValueError(""Expected mapping or sequence"")<tab>for (fname, fval) in items:<tab><tab>if isinstance(fval, fs_class):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fstruct[fname] = inv_bindings[id(fval)]<tab><tab><tab>_retract_bindings(fval, inv_bindings, fs_class, visited)",if id ( fval ) in inv_bindings :,181
1776,"def warehouses(self) -> tuple:<tab>from ..repositories import WarehouseBaseRepo<tab>repos = dict()<tab>for dep in chain(self.dependencies, [self]):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not isinstance(dep.repo, WarehouseBaseRepo):<tab><tab><tab>continue<tab><tab>for repo in dep.repo.repos:<tab><tab><tab>if repo.from_config:<tab><tab><tab><tab>continue<tab><tab><tab>repos[repo.name] = repo<tab>return tuple(repos.values())",if dep . repo is None :,124
1777,"def detype(self):<tab>if self._detyped is not None:<tab><tab>return self._detyped<tab>ctx = {}<tab>for key, val in self._d.items():<tab><tab>if not isinstance(key, str):<tab><tab><tab>key = str(key)<tab><tab>detyper = self.get_detyper(key)<tab><tab><IF-STMT><tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>deval = detyper(val)<tab><tab>if deval is None:<tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>ctx[key] = deval<tab>self._detyped = ctx<tab>return ctx",if detyper is None :,163
1778,"def populate_obj(self, obj, name):<tab>field = getattr(obj, name, None)<tab>if field is not None:<tab><tab># If field should be deleted, clean it up<tab><tab><IF-STMT><tab><tab><tab>field.delete()<tab><tab><tab>return<tab><tab>if isinstance(self.data, FileStorage) and not is_empty(self.data.stream):<tab><tab><tab>if not field.grid_id:<tab><tab><tab><tab>func = field.put<tab><tab><tab>else:<tab><tab><tab><tab>func = field.replace<tab><tab><tab>func(<tab><tab><tab><tab>self.data.stream,<tab><tab><tab><tab>filename=self.data.filename,<tab><tab><tab><tab>content_type=self.data.content_type,<tab><tab><tab>)",if self . _should_delete :,182
1779,"def _load(container):<tab>if isinstance(container, str):<tab><tab># If container is a filename.<tab><tab><IF-STMT><tab><tab><tab>with open(container, ""rb"") as f:<tab><tab><tab><tab>return pickle.load(f)<tab><tab># If container is a pickle string.<tab><tab>else:<tab><tab><tab>return pickle.loads(container)<tab># If container is an open file<tab>elif isinstance(container, IOBase):<tab><tab>return pickle.load(container)<tab># What else could it be?<tab>else:<tab><tab>l.error(""Cannot unpickle container of type %s"", type(container))<tab><tab>return None",if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,171
1780,"def append_row(self, row):<tab>self.allocate_future_payments(row)<tab>self.set_invoice_details(row)<tab>self.set_party_details(row)<tab>self.set_ageing(row)<tab>if self.filters.get(""group_by_party""):<tab><tab>self.update_sub_total_row(row, row.party)<tab><tab><IF-STMT><tab><tab><tab>self.append_subtotal_row(self.previous_party)<tab><tab>self.previous_party = row.party<tab>self.data.append(row)",if self . previous_party and ( self . previous_party != row . party ) :,152
1781,"def gg1():<tab>while 1:<tab><tab>tt = 3<tab><tab>while tt > 0:<tab><tab><tab>trace.append(tt)<tab><tab><tab>val = yield<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tt = 10  # <= uncomment this line<tab><tab><tab><tab>trace.append(""breaking early..."")<tab><tab><tab><tab>break<tab><tab><tab>tt -= 1<tab><tab>trace.append(""try!"")",if val is not None :,101
1782,"def migrate_common_facts(facts):<tab>""""""Migrate facts from various roles into common""""""<tab>params = {""node"": (""portal_net""), ""master"": (""portal_net"")}<tab>if ""common"" not in facts:<tab><tab>facts[""common""] = {}<tab># pylint: disable=consider-iterating-dictionary<tab>for role in params.keys():<tab><tab>if role in facts:<tab><tab><tab>for param in params[role]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>facts[""common""][param] = facts[role].pop(param)<tab>return facts",if param in facts [ role ] :,137
1783,"def get_measurements(self, pipeline, object_name, category):<tab>if self.get_categories(pipeline, object_name) == [category]:<tab><tab>results = []<tab><tab><IF-STMT><tab><tab><tab>if object_name == ""Image"":<tab><tab><tab><tab>results += [""Correlation"", ""Slope""]<tab><tab><tab>else:<tab><tab><tab><tab>results += [""Correlation""]<tab><tab>if self.do_overlap:<tab><tab><tab>results += [""Overlap"", ""K""]<tab><tab>if self.do_manders:<tab><tab><tab>results += [""Manders""]<tab><tab>if self.do_rwc:<tab><tab><tab>results += [""RWC""]<tab><tab>if self.do_costes:<tab><tab><tab>results += [""Costes""]<tab><tab>return results<tab>return []",if self . do_corr_and_slope :,195
1784,"def access_modes(self):<tab>""""""access_modes property""""""<tab>if self._access_modes is None:<tab><tab>self._access_modes = self.get_access_modes()<tab><tab><IF-STMT><tab><tab><tab>self._access_modes = list(self._access_modes)<tab>return self._access_modes","if not isinstance ( self . _access_modes , list ) :",85
1785,"def unwrap_envelope(self, data, many):<tab>if many:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(data, InstrumentedList) or isinstance(data, list):<tab><tab><tab><tab>self.context[""total""] = len(data)<tab><tab><tab><tab>return data<tab><tab><tab>else:<tab><tab><tab><tab>self.context[""total""] = data[""total""]<tab><tab>else:<tab><tab><tab>self.context[""total""] = 0<tab><tab><tab>data = {""items"": []}<tab><tab>return data[""items""]<tab>return data","if data [ ""items"" ] :",130
1786,"def to_string(self, fmt=""{:.4f}""):<tab>result_str = """"<tab>for key in self.measures:<tab><tab>result = self.m_dict[key][0]()<tab><tab>result_str += (<tab><tab><tab>"","".join(fmt.format(x) for x in result)<tab><tab><tab><IF-STMT><tab><tab><tab>else fmt.format(result)<tab><tab>)<tab><tab>result_str += "",""<tab>return result_str[:-1]  # trim the last comma","if isinstance ( result , tuple )",121
1787,"def on_torrent_created(self, result):<tab>if not result:<tab><tab>return<tab>self.dialog_widget.btn_create.setEnabled(True)<tab>self.dialog_widget.edit_channel_create_torrent_progress_label.setText(<tab><tab>""Created torrent""<tab>)<tab>if ""torrent"" in result:<tab><tab>self.create_torrent_notification.emit({""msg"": ""Torrent successfully created""})<tab><tab><IF-STMT><tab><tab><tab>self.add_torrent_to_channel(result[""torrent""])<tab><tab>self.close_dialog()",if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,151
1788,"def save(self):<tab>for var_name in self.default_config:<tab><tab><IF-STMT><tab><tab><tab>if var_name in self.file_config:<tab><tab><tab><tab>del self.file_config[var_name]<tab><tab>else:<tab><tab><tab>self.file_config[var_name] = getattr(self, var_name)<tab>with open(self.config_path, ""w"") as f:<tab><tab>f.write(json.dumps(self.file_config, indent=2))","if getattr ( self , var_name , None ) == self . default_config [ var_name ] :",141
1789,"def get_class_parameters(kwarg):<tab>ret = {""attrs"": []}<tab>for key in (""rsc"", ""fsc"", ""usc""):<tab><tab><IF-STMT><tab><tab><tab>ret[""attrs""].append(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>""TCA_HFSC_%s"" % key.upper(),<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""m1"": get_rate(kwarg[key].get(""m1"", 0)),<tab><tab><tab><tab><tab><tab>""d"": get_time(kwarg[key].get(""d"", 0)),<tab><tab><tab><tab><tab><tab>""m2"": get_rate(kwarg[key].get(""m2"", 0)),<tab><tab><tab><tab><tab>},<tab><tab><tab><tab>]<tab><tab><tab>)<tab>return ret",if key in kwarg :,184
1790,"def forward(self, x):<tab>f_x = x<tab>if self.exp:<tab><tab>f_x = self.exp_swish(self.exp_bn(self.exp(f_x)))<tab>f_x = self.dwise_swish(self.dwise_bn(self.dwise(f_x)))<tab>f_x = self.se(f_x)<tab>f_x = self.lin_proj_bn(self.lin_proj(f_x))<tab>if self.has_skip:<tab><tab><IF-STMT><tab><tab><tab>f_x = drop_connect(f_x, effnet_cfg.EN.DC_RATIO)<tab><tab>f_x = x + f_x<tab>return f_x",if self . training and effnet_cfg . EN . DC_RATIO > 0.0 :,193
1791,"def cli_uninstall_distro():<tab>distro_list = install_distro_list()<tab>if distro_list is not None:<tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab>log(str(index) + ""  --->>  "" + _distro_dir)<tab><tab>user_input = read_input_uninstall()<tab><tab>if user_input is not False:<tab><tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>config.uninstall_distro_dir_name = _distro_dir<tab><tab><tab><tab><tab>unin_distro()<tab>else:<tab><tab>log(""No distro installed on "" + config.usb_disk)",if index == user_input :,189
1792,"def IMPORTFROM(self, node):<tab>if node.module == ""__future__"":<tab><tab><IF-STMT><tab><tab><tab>self.report(messages.LateFutureImport, node, [n.name for n in node.names])<tab>else:<tab><tab>self.futuresAllowed = False<tab>for alias in node.names:<tab><tab>if alias.name == ""*"":<tab><tab><tab>self.scope.importStarred = True<tab><tab><tab>self.report(messages.ImportStarUsed, node, node.module)<tab><tab><tab>continue<tab><tab>name = alias.asname or alias.name<tab><tab>importation = Importation(name, node)<tab><tab>if node.module == ""__future__"":<tab><tab><tab>importation.used = (self.scope, node)<tab><tab>self.addBinding(node, importation)",if not self . futuresAllowed :,190
1793,"def _split_and_load(batch, ctx_list):<tab>""""""Split data to 1 batch each device.""""""<tab>new_batch = []<tab>for _, data in enumerate(batch):<tab><tab><IF-STMT><tab><tab><tab>new_data = [x.as_in_context(ctx) for x, ctx in zip(data, ctx_list)]<tab><tab>else:<tab><tab><tab>new_data = [data.as_in_context(ctx_list[0])]<tab><tab>new_batch.append(new_data)<tab>return new_batch","if isinstance ( data , ( list , tuple ) ) :",135
1794,"def wait_success(self, timeout=60 * 10):<tab>for i in range(timeout // 10):<tab><tab>time.sleep(10)<tab><tab>status = self.query_job()<tab><tab>print(""job {} status is {}"".format(self.job_id, status))<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if status and status in [<tab><tab><tab>StatusSet.CANCELED,<tab><tab><tab>StatusSet.TIMEOUT,<tab><tab><tab>StatusSet.FAILED,<tab><tab>]:<tab><tab><tab>return False<tab>return False",if status and status == StatusSet . SUCCESS :,134
1795,"def copy_tree(self, src_dir, dst_dir, skip_variables=False):<tab>for src_root, _, files in os.walk(src_dir):<tab><tab><IF-STMT><tab><tab><tab>rel_root = os.path.relpath(src_root, src_dir)<tab><tab>else:<tab><tab><tab>rel_root = """"<tab><tab>if skip_variables and rel_root.startswith(""variables""):<tab><tab><tab>continue<tab><tab>dst_root = os.path.join(dst_dir, rel_root)<tab><tab>if not os.path.exists(dst_root):<tab><tab><tab>os.makedirs(dst_root)<tab><tab>for f in files:<tab><tab><tab>shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",if src_root != src_dir :,197
1796,"def _make_padded_shapes(self, dataset, decoders):<tab>padded_shapes = dataset.output_shapes<tab>for i, hparams_i in enumerate(self._hparams.datasets):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not hparams_i[""pad_to_max_seq_length""]:<tab><tab><tab>continue<tab><tab>text_and_id_shapes = MonoTextData._make_padded_text_and_id_shapes(<tab><tab><tab>dataset, hparams_i, decoders[i], self.text_name(i), self.text_id_name(i)<tab><tab>)<tab><tab>padded_shapes.update(text_and_id_shapes)<tab>return padded_shapes","if not _is_text_data ( hparams_i [ ""data_type"" ] ) :",179
1797,"def format_errors(messages):<tab>errors = {}<tab>for k, v in messages.items():<tab><tab>key = camelize(k, uppercase_first_letter=False)<tab><tab><IF-STMT><tab><tab><tab>errors[key] = format_errors(v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>errors[key] = v[0]<tab>return errors","if isinstance ( v , dict ) :",94
1798,"def generic_visit(self, node, parents=None):<tab>parents = (parents or []) + [node]<tab>for field, value in iter_fields(node):<tab><tab><IF-STMT><tab><tab><tab>for item in value:<tab><tab><tab><tab>if isinstance(item, AST):<tab><tab><tab><tab><tab>self.visit(item, parents)<tab><tab>elif isinstance(value, AST):<tab><tab><tab>self.visit(value, parents)","if isinstance ( value , list ) :",106
1799,"def get_override_css(self):<tab>""""""handls allow_css_overrides setting.""""""<tab>if self.settings.get(""allow_css_overrides""):<tab><tab>filename = self.view.file_name()<tab><tab>filetypes = self.settings.get(""markdown_filetypes"")<tab><tab>if filename and filetypes:<tab><tab><tab>for filetype in filetypes:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>css_filename = filename.rpartition(filetype)[0] + "".css""<tab><tab><tab><tab><tab>if os.path.isfile(css_filename):<tab><tab><tab><tab><tab><tab>return u""<style>%s</style>"" % load_utf8(css_filename)<tab>return """"",if filename . endswith ( filetype ) :,165
1800,"def clean(self):<tab>super().clean()<tab># If the Cluster is assigned to a Site, all Devices must be assigned to that Site.<tab>if self.cluster.site is not None:<tab><tab>for device in self.cleaned_data.get(""devices"", []):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""devices"": ""{} belongs to a different site ({}) than the cluster ({})"".format(<tab><tab><tab><tab><tab><tab><tab>device, device.site, self.cluster.site<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>}<tab><tab><tab><tab>)",if device . site != self . cluster . site :,156
1801,"def _setProcessPriority(process, nice_val, disable_gc):<tab>org_nice_val = Computer._process_original_nice_value<tab>try:<tab><tab>process.nice(nice_val)<tab><tab>Computer.in_high_priority_mode = nice_val != org_nice_val<tab><tab><IF-STMT><tab><tab><tab>gc.disable()<tab><tab>else:<tab><tab><tab>gc.enable()<tab><tab>return True<tab>except psutil.AccessDenied:<tab><tab>print2err(<tab><tab><tab>""WARNING: Could not set process {} priority ""<tab><tab><tab>""to {}"".format(process.pid, nice_val)<tab><tab>)<tab><tab>return False",if disable_gc :,161
1802,"def _setResultsName(self, name, listAllMatches=False):<tab>if __diag__.warn_multiple_tokens_in_named_alternation:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""{}: setting results name {!r} on {} expression ""<tab><tab><tab><tab>""may only return a single token for an And alternative, ""<tab><tab><tab><tab>""in future will return the full list of tokens"".format(<tab><tab><tab><tab><tab>""warn_multiple_tokens_in_named_alternation"",<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>type(self).__name__,<tab><tab><tab><tab>),<tab><tab><tab><tab>stacklevel=3,<tab><tab><tab>)<tab>return super()._setResultsName(name, listAllMatches)","if any ( isinstance ( e , And ) for e in self . exprs ) :",193
1803,"def make_sources(project: RootDependency) -> str:<tab>content = []<tab>if project.readme:<tab><tab>content.append(project.readme.path.name)<tab><tab>if project.readme.markup != ""rst"":<tab><tab><tab>content.append(project.readme.to_rst().path.name)<tab>path = project.package.path<tab>for fname in (""setup.cfg"", ""setup.py""):<tab><tab><IF-STMT><tab><tab><tab>content.append(fname)<tab>for package in chain(project.package.packages, project.package.data):<tab><tab>for fpath in package:<tab><tab><tab>fpath = fpath.relative_to(project.package.path)<tab><tab><tab>content.append(""/"".join(fpath.parts))<tab>return ""\n"".join(content)",if ( path / fname ) . exists ( ) :,193
1804,"def findControlPointsInMesh(glyph, va, subsegments):<tab>controlPointIndices = np.zeros((len(va), 1))<tab>index = 0<tab>for i, c in enumerate(subsegments):<tab><tab>segmentCount = len(glyph.contours[i].segments) - 1<tab><tab>for j, s in enumerate(c):<tab><tab><tab>if j < segmentCount:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>controlPointIndices[index] = 1<tab><tab><tab>index += s[1]<tab>return controlPointIndices","if glyph . contours [ i ] . segments [ j ] . type == ""line"" :",143
1805,"def MergeFrom(self, other):<tab>if self.message_class is not None:<tab><tab>if other.Parse(self.message_class):<tab><tab><tab>self.message.MergeFrom(other.message)<tab>elif other.message_class is not None:<tab><tab><IF-STMT><tab><tab><tab>self.message = other.message_class()<tab><tab><tab>self.message_class = other.message_class<tab><tab>self.message.MergeFrom(other.message)<tab>else:<tab><tab>self.message += other.message",if not self . Parse ( other . message_class ) :,134
1806,"def remove_old_snapshot(install_dir):<tab>logging.info(""Removing any old files in {}"".format(install_dir))<tab>for file in glob.glob(""{}/*"".format(install_dir)):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.unlink(file)<tab><tab><tab>elif os.path.isdir(file):<tab><tab><tab><tab>shutil.rmtree(file)<tab><tab>except Exception as error:<tab><tab><tab>logging.error(""Error: {}"".format(error))<tab><tab><tab>sys.exit(1)",if os . path . isfile ( file ) :,133
1807,"def writexml(<tab>self,<tab>stream,<tab>indent="""",<tab>addindent="""",<tab>newl="""",<tab>strip=0,<tab>nsprefixes={},<tab>namespace="""",):<tab>w = _streamWriteWrapper(stream)<tab>if self.raw:<tab><tab>val = self.nodeValue<tab><tab>if not isinstance(val, str):<tab><tab><tab>val = str(self.nodeValue)<tab>else:<tab><tab>v = self.nodeValue<tab><tab>if not isinstance(v, str):<tab><tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>v = "" "".join(v.split())<tab><tab>val = escape(v)<tab>w(val)",if strip :,164
1808,"def validate_attributes(self):<tab>for attribute in self.get_all_attributes():<tab><tab>value = getattr(self, attribute.code, None)<tab><tab><IF-STMT><tab><tab><tab>if attribute.required:<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code}<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>attribute.validate_value(value)<tab><tab><tab>except ValidationError as e:<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e}<tab><tab><tab><tab>)",if value is None :,168
1809,"def PyJsHoisted_BinaryExpression_(node, parent, this, arguments, var=var):<tab>var = Scope(<tab><tab>{u""node"": node, u""this"": this, u""arguments"": arguments, u""parent"": parent}, var<tab>)<tab>var.registers([u""node"", u""parent""])<tab>if PyJsStrictEq(var.get(u""node"").get(u""operator""), Js(u""in"")):<tab><tab><IF-STMT><tab><tab><tab>return var.get(u""true"")<tab><tab>if var.get(u""t"").callprop(u""isFor"", var.get(u""parent"")):<tab><tab><tab>return var.get(u""true"")<tab>return Js(False)","if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :",196
1810,"def distinct(expr, *on):<tab>fields = frozenset(expr.fields)<tab>_on = []<tab>append = _on.append<tab>for n in on:<tab><tab>if isinstance(n, Field):<tab><tab><tab>if n._child.isidentical(expr):<tab><tab><tab><tab>n = n._name<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""on must be a name or field, not: {0}"".format(n))<tab><tab>elif n not in fields:<tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>append(n)<tab>return Distinct(expr, tuple(_on))","if not isinstance ( n , _strtypes ) :",192
1811,"def encode(self, msg):<tab>""""""Encodes the message to the stream encoding.""""""<tab>stream = self.stream<tab>rv = msg + ""\n""<tab>if (PY2 and is_unicode(rv)) or not (<tab><tab>PY2 or is_unicode(rv) or _is_text_stream(stream)<tab>):<tab><tab>enc = self.encoding<tab><tab><IF-STMT><tab><tab><tab>enc = getattr(stream, ""encoding"", None) or ""utf-8""<tab><tab>rv = rv.encode(enc, ""replace"")<tab>return rv",if enc is None :,131
1812,"def color_convert(self, to_color_space, preserve_alpha=True):<tab>if to_color_space == self.color_space and preserve_alpha:<tab><tab>return self<tab>else:<tab><tab>pixels = pixels_as_float(self.pixels)<tab><tab>converted = convert_color(<tab><tab><tab>pixels, self.color_space, to_color_space, preserve_alpha<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return Image(converted, to_color_space)",if converted is None :,125
1813,"def seek(self, pos):<tab>if self.closed:<tab><tab>raise IOError(""Cannot seek on a closed file"")<tab>for n, idx in enumerate(self._indexes[::-1]):<tab><tab>if idx.offset <= pos:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._idxiter = iter(self._indexes[-(n + 1) :])<tab><tab><tab><tab>self._nextidx()<tab><tab><tab>break<tab>else:<tab><tab>raise Exception(""Cannot seek to pos"")<tab>self._curfile.seek(pos - self._curidx.offset)",if idx != self . _curidx :,135
1814,"def load_from_json(self, node_data: dict, import_version: float):<tab>if import_version <= 0.08:<tab><tab>self.image_pointer = unpack_pointer_property_name(<tab><tab><tab>bpy.data.images, node_data, ""image_name""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>proposed_name = node_data.get(""image_name"")<tab><tab><tab>self.info(f""image data not found in current {proposed_name}"")",if not self . image_pointer :,126
1815,"def __init__(self, execution_context, aggregate_operators):<tab>super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context)<tab>self._local_aggregators = []<tab>self._results = None<tab>self._result_index = 0<tab>for operator in aggregate_operators:<tab><tab>if operator == ""Average"":<tab><tab><tab>self._local_aggregators.append(_AverageAggregator())<tab><tab><IF-STMT><tab><tab><tab>self._local_aggregators.append(_CountAggregator())<tab><tab>elif operator == ""Max"":<tab><tab><tab>self._local_aggregators.append(_MaxAggregator())<tab><tab>elif operator == ""Min"":<tab><tab><tab>self._local_aggregators.append(_MinAggregator())<tab><tab>elif operator == ""Sum"":<tab><tab><tab>self._local_aggregators.append(_SumAggregator())","elif operator == ""Count"" :",192
1816,"def attrgetter(item):<tab>items = [None] * len(attribute)<tab>for i, attribute_part in enumerate(attribute):<tab><tab>item_i = item<tab><tab>for part in attribute_part:<tab><tab><tab>item_i = environment.getitem(item_i, part)<tab><tab><IF-STMT><tab><tab><tab>item_i = postprocess(item_i)<tab><tab>items[i] = item_i<tab>return items",if postprocess is not None :,105
1817,"def work(self):<tab>while True:<tab><tab>timeout = self.timeout<tab><tab><IF-STMT><tab><tab><tab>timeout = self.idle_timeout<tab><tab>log.debug(""Wait for {}"".format(timeout))<tab><tab>fetch.wait(timeout)<tab><tab>if shutting_down.is_set():<tab><tab><tab>log.info(""Stop fetch worker"")<tab><tab><tab>break<tab><tab>self.fetch()",if idle . is_set ( ) :,99
1818,"def testCoreInterfaceIntInputData():<tab>result_testing = False<tab>for _ in range(10):<tab><tab>hsyncnet_instance = hsyncnet(<tab><tab><tab>[[1], [2], [3], [20], [21], [22]], 2, initial_type.EQUIPARTITION, ccore=True<tab><tab>)<tab><tab>analyser = hsyncnet_instance.process()<tab><tab><IF-STMT><tab><tab><tab>result_testing = True<tab><tab><tab>break<tab>assert result_testing",if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,132
1819,"def _gen():<tab>buf = []<tab>iterable = dataset()<tab>try:<tab><tab>while len(buf) < buffer_size:<tab><tab><tab>buf.append(next(iterable))<tab><tab>while 1:<tab><tab><tab>i = random.randint(0, buffer_size - 1)<tab><tab><tab>n = next(iterable)<tab><tab><tab>yield buf[i]<tab><tab><tab>buf[i] = n<tab>except StopIteration:<tab><tab><IF-STMT><tab><tab><tab>random.shuffle(buf)<tab><tab><tab>for i in buf:<tab><tab><tab><tab>yield i",if len ( buf ) :,137
1820,"def debug_tree(tree):<tab>l = []<tab>for elt in tree:<tab><tab>if isinstance(elt, (int, long)):<tab><tab><tab>l.append(_names.get(elt, elt))<tab><tab><IF-STMT><tab><tab><tab>l.append(elt)<tab><tab>else:<tab><tab><tab>l.append(debug_tree(elt))<tab>return l","elif isinstance ( elt , str ) :",92
1821,"def reverse_code(apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None:<tab>PreregistrationUser = apps.get_model(""zerver"", ""PreregistrationUser"")<tab>for user in PreregistrationUser.objects.all():<tab><tab><IF-STMT>  # PreregistrationUser.INVITE_AS['REALM_ADMIN']<tab><tab><tab>user.invited_as_admin = True<tab><tab>else:  # PreregistrationUser.INVITE_AS['MEMBER']<tab><tab><tab>user.invited_as_admin = False<tab><tab>user.save(update_fields=[""invited_as_admin""])",if user . invited_as == 2 :,151
1822,"def _fastqc_data_section(self, section_name):<tab>out = []<tab>in_section = False<tab>data_file = os.path.join(self._dir, ""fastqc_data.txt"")<tab>if os.path.exists(data_file):<tab><tab>with open(data_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab>if line.startswith("">>%s"" % section_name):<tab><tab><tab><tab><tab>in_section = True<tab><tab><tab><tab>elif in_section:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>out.append(line.rstrip(""\r\n""))<tab>return out","if line . startswith ( "">>END"" ) :",173
1823,"def determine_block_hints(self, text):<tab>hints = """"<tab>if text:<tab><tab>if text[0] in "" \n\x85\u2028\u2029"":<tab><tab><tab>hints += str(self.best_indent)<tab><tab><IF-STMT><tab><tab><tab>hints += ""-""<tab><tab>elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""+""<tab>return hints","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :",132
1824,"def database_app(request):<tab>if request.param == ""postgres_app"":<tab><tab>if not which(""initdb""):<tab><tab><tab>pytest.skip(""initdb must be on PATH for postgresql fixture"")<tab><tab>if not psycopg2:<tab><tab><tab>pytest.skip(""psycopg2 must be installed for postgresql fixture"")<tab>if request.param == ""sqlite_rabbitmq_app"":<tab><tab><IF-STMT><tab><tab><tab>pytest.skip(<tab><tab><tab><tab>""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset""<tab><tab><tab>)<tab>return request.getfixturevalue(request.param)","if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :",174
1825,"def do_rollout(agent, env, num_steps, render=False):<tab>total_rew = 0<tab>ob = env.reset()<tab>for t in range(num_steps):<tab><tab>a = agent.act(ob)<tab><tab>(ob, reward, done, _info) = env.step(a)<tab><tab>total_rew += reward<tab><tab><IF-STMT><tab><tab><tab>env.render()<tab><tab>if done:<tab><tab><tab>break<tab>return total_rew, t + 1",if render and t % 3 == 0 :,126
1826,"def _handle_subrepos(self, ctx, dirty_trees):<tab>substate = util.parse_hgsubstate(ctx["".hgsubstate""].data().splitlines())<tab>sub = util.OrderedDict()<tab>if "".hgsub"" in ctx:<tab><tab>sub = util.parse_hgsub(ctx["".hgsub""].data().splitlines())<tab>for path, sha in substate.iteritems():<tab><tab># Ignore non-Git repositories keeping state in .hgsubstate.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d = os.path.dirname(path)<tab><tab>dirty_trees.add(d)<tab><tab>tree = self._dirs.setdefault(d, dulobjs.Tree())<tab><tab>tree.add(os.path.basename(path), dulobjs.S_IFGITLINK, sha)","if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :",197
1827,"def get_property_file_image_choices(self, pipeline):<tab>columns = pipeline.get_measurement_columns()<tab>image_names = []<tab>for column in columns:<tab><tab>object_name, feature, coltype = column[:3]<tab><tab>choice = feature[(len(C_FILE_NAME) + 1) :]<tab><tab><IF-STMT><tab><tab><tab>image_names.append(choice)<tab>return image_names","if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :",118
1828,"def check_all_decorator_order():<tab>""""""Check that in all test files, the slow decorator is always last.""""""<tab>errors = []<tab>for fname in os.listdir(PATH_TO_TESTS):<tab><tab><IF-STMT><tab><tab><tab>filename = os.path.join(PATH_TO_TESTS, fname)<tab><tab><tab>new_errors = check_decorator_order(filename)<tab><tab><tab>errors += [f""- {filename}, line {i}"" for i in new_errors]<tab>if len(errors) > 0:<tab><tab>msg = ""\n"".join(errors)<tab><tab>raise ValueError(<tab><tab><tab>f""The parameterized decorator (and its variants) should always be first, but this is not the case in the following files:\n{msg}""<tab><tab>)","if fname . endswith ( "".py"" ) :",182
1829,"def on_edit_button_clicked(self, event=None, a=None, col=None):<tab>tree, tree_id = self.treeView.get_selection().get_selected()<tab>watchdir_id = str(self.store.get_value(tree_id, 0))<tab>if watchdir_id:<tab><tab>if col and col.get_title() == _(""Active""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>client.autoadd.disable_watchdir(watchdir_id)<tab><tab><tab>else:<tab><tab><tab><tab>client.autoadd.enable_watchdir(watchdir_id)<tab><tab>else:<tab><tab><tab>self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)","if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :",187
1830,"def get_conv_output_size(input_size, kernel_size, stride, padding, dilation):<tab>ndim = len(input_size)<tab>output_size = []<tab>for i in range(ndim):<tab><tab>size = (<tab><tab><tab>input_size[i] + 2 * padding[i] - dilation[i] * (kernel_size[i] - 1) - 1<tab><tab>) // stride[i] + 1<tab><tab><IF-STMT><tab><tab><tab>output_size.append(1)<tab><tab>else:<tab><tab><tab>output_size.append(size)<tab>return output_size",if kernel_size [ i ] == - 1 :,151
1831,"def from_location(cls, location, basename, metadata=None, **kw):<tab>project_name, version, py_version, platform = [None] * 4<tab>basename, ext = os.path.splitext(basename)<tab>if ext.lower() in ("".egg"", "".egg-info""):<tab><tab>match = EGG_NAME(basename)<tab><tab><IF-STMT><tab><tab><tab>project_name, version, py_version, platform = match.group(<tab><tab><tab><tab>""name"", ""ver"", ""pyver"", ""plat""<tab><tab><tab>)<tab>return cls(<tab><tab>location,<tab><tab>metadata,<tab><tab>project_name=project_name,<tab><tab>version=version,<tab><tab>py_version=py_version,<tab><tab>platform=platform,<tab><tab>**kw<tab>)",if match :,187
1832,"def __new__(metacls, typename, bases, namespace):<tab>annotations = namespace.get(""__annotations__"", {})<tab>for t in annotations.values():<tab><tab><IF-STMT><tab><tab><tab>for ut in t.__args__:<tab><tab><tab><tab>_assert_tensorizer_type(ut)<tab><tab>else:<tab><tab><tab>_assert_tensorizer_type(t)<tab>return super().__new__(metacls, typename, bases, namespace)","if getattr ( t , ""__origin__"" , """" ) is Union :",110
1833,"def decode_content(self):<tab>""""""Return the best possible representation of the response body.""""""<tab>ct = self.headers.get(""content-type"")<tab>if ct:<tab><tab>ct, options = parse_options_header(ct)<tab><tab>charset = options.get(""charset"")<tab><tab><IF-STMT><tab><tab><tab>return self.json(charset)<tab><tab>elif ct.startswith(""text/""):<tab><tab><tab>return self.text(charset)<tab><tab>elif ct == FORM_URL_ENCODED:<tab><tab><tab>return parse_qsl(self.content.decode(charset), keep_blank_values=True)<tab>return self.content",if ct in JSON_CONTENT_TYPES :,156
1834,"def get_full_path(path):<tab>if ""://"" not in path:<tab><tab>path = os.path.join(self.AUTO_COLL_TEMPL, path, """")<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(abs_path, path)<tab>return path",if abs_path :,71
1835,"def __getitem__(self, name_or_path):<tab>if isinstance(name_or_path, integer_types):<tab><tab>return list.__getitem__(self, name_or_path)<tab>elif isinstance(name_or_path, tuple):<tab><tab>try:<tab><tab><tab>val = self<tab><tab><tab>for fid in name_or_path:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise KeyError  # path contains base value<tab><tab><tab><tab>val = val[fid]<tab><tab><tab>return val<tab><tab>except (KeyError, IndexError):<tab><tab><tab>raise KeyError(name_or_path)<tab>else:<tab><tab>raise TypeError(self._INDEX_ERROR % name_or_path)","if not isinstance ( val , FeatStruct ) :",170
1836,"def scan(scope):<tab>for s in scope.children:<tab><tab>if s.start_pos <= position <= s.end_pos:<tab><tab><tab>if isinstance(s, (tree.Scope, tree.Flow)):<tab><tab><tab><tab>return scan(s) or s<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return scan(s)<tab>return None","elif s . type in ( ""suite"" , ""decorated"" ) :",92
1837,"def _get_key(self):<tab>if not self.key:<tab><tab>self._channel.send(u""pake"", self.msg1)<tab><tab>pake_msg = self._channel.get(u""pake"")<tab><tab>self.key = self.sp.finish(pake_msg)<tab><tab>self.verifier = self.derive_key(u""wormhole:verifier"")<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>confkey = self.derive_key(u""wormhole:confirmation"")<tab><tab>nonce = os.urandom(CONFMSG_NONCE_LENGTH)<tab><tab>confmsg = make_confmsg(confkey, nonce)<tab><tab>self._channel.send(u""_confirm"", confmsg)",if not self . _send_confirm :,181
1838,"def executeScript(self, script):<tab>if len(script) > 0:<tab><tab>commands = []<tab><tab>for l in script:<tab><tab><tab>extracted = self.extract_command(l)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>commands.append(extracted)<tab><tab>for command in commands:<tab><tab><tab>cmd, argv = command<tab><tab><tab>self.dispatch_command(cmd, argv)",if extracted :,98
1839,"def create_path(n, fullname, meta):<tab>if meta:<tab><tab>meta.create_path(fullname)<tab>else:<tab><tab># These fallbacks are important -- meta could be null if, for<tab><tab># example, save created a ""fake"" item, i.e. a new strip/graft<tab><tab># path element, etc.  You can find cases like that by<tab><tab># searching for ""Metadata()"".<tab><tab>unlink(fullname)<tab><tab>if stat.S_ISDIR(n.mode):<tab><tab><tab>mkdirp(fullname)<tab><tab><IF-STMT><tab><tab><tab>os.symlink(n.readlink(), fullname)",elif stat . S_ISLNK ( n . mode ) :,158
1840,def get_cycle(self):<tab>if self.has_cycle():<tab><tab>cross_node = self.path[-1]<tab><tab><IF-STMT><tab><tab><tab>return self.path[self.path.index(cross_node) :]<tab><tab>else:<tab><tab><tab>return self.path<tab>return [],if self . path . count ( cross_node ) > 1 :,84
1841,"def _select_block(str_in, start_tag, end_tag):<tab>""""""Select first block delimited by start_tag and end_tag""""""<tab>start_pos = str_in.find(start_tag)<tab>if start_pos < 0:<tab><tab>raise ValueError(""start_tag not found"")<tab>depth = 0<tab>for pos in range(start_pos, len(str_in)):<tab><tab><IF-STMT><tab><tab><tab>depth += 1<tab><tab>elif str_in[pos] == end_tag:<tab><tab><tab>depth -= 1<tab><tab>if depth == 0:<tab><tab><tab>break<tab>sel = str_in[start_pos + 1 : pos]<tab>return sel",if str_in [ pos ] == start_tag :,171
1842,"def device(self):<tab>""""""Device on which the data array of this variable reside.""""""<tab># lazy initialization for performance<tab>if self._device is None:<tab><tab><IF-STMT><tab><tab><tab>self._device = backend.CpuDevice()<tab><tab>else:<tab><tab><tab>self._device = backend.get_device_from_array(self._data[0])<tab>return self._device",if self . _data [ 0 ] is None :,98
1843,"def function_out(*args, **kwargs):<tab>try:<tab><tab>return function_in(*args, **kwargs)<tab>except dbus.exceptions.DBusException as e:<tab><tab>if e.get_dbus_name() == DBUS_UNKNOWN_METHOD:<tab><tab><tab>raise ItemNotFoundException(""Item does not exist!"")<tab><tab><IF-STMT><tab><tab><tab>raise ItemNotFoundException(e.get_dbus_message())<tab><tab>if e.get_dbus_name() in (DBUS_NO_REPLY, DBUS_NOT_SUPPORTED):<tab><tab><tab>raise SecretServiceNotAvailableException(e.get_dbus_message())<tab><tab>raise",if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT :,162
1844,"def run(self):<tab>""""""Continual loop evaluating when_statements""""""<tab>while len(self.library) > 0:<tab><tab>for name, expression in self.library.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.library[name]<tab><tab><tab>else:<tab><tab><tab><tab>expression.evaluate()<tab><tab>sleep(0.01)<tab>return",if expression . remove_me == True :,96
1845,"def tamper(payload, **kwargs):<tab>junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`""<tab>retval = """"<tab>for i, char in enumerate(payload, start=1):<tab><tab>amount = random.randint(10, 15)<tab><tab><IF-STMT><tab><tab><tab>retval += "">""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == ""<"":<tab><tab><tab>retval += ""<""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == "" "":<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>else:<tab><tab><tab>retval += char<tab>return retval","if char == "">"" :",200
1846,"def _source_target_path(source, source_path, source_location):<tab>target_path_attr = source.target_path or source.resdef.target_path<tab>if source.preserve_path:<tab><tab><IF-STMT><tab><tab><tab>log.warning(<tab><tab><tab><tab>""target-path '%s' specified with preserve-path - ignoring"",<tab><tab><tab><tab>target_path_attr,<tab><tab><tab>)<tab><tab>return os.path.relpath(os.path.dirname(source_path), source_location)<tab>else:<tab><tab>return target_path_attr or source.resdef.target_path or """"",if target_path_attr :,152
1847,"def _load_user_from_header(self, header):<tab>if self._header_callback:<tab><tab>user = self._header_callback(header)<tab><tab><IF-STMT><tab><tab><tab>app = current_app._get_current_object()<tab><tab><tab>user_loaded_from_header.send(app, user=user)<tab><tab><tab>return user<tab>return None",if user is not None :,92
1848,"def setup(cls):<tab>""Check dependencies and warn about firewalling""<tab>pathCheck(""brctl"", moduleName=""bridge-utils"")<tab># Disable Linux bridge firewalling so that traffic can flow!<tab>for table in ""arp"", ""ip"", ""ip6"":<tab><tab>cmd = ""sysctl net.bridge.bridge-nf-call-%stables"" % table<tab><tab>out = quietRun(cmd).strip()<tab><tab><IF-STMT><tab><tab><tab>warn(""Warning: Linux bridge may not work with"", out, ""\n"")","if out . endswith ( ""1"" ) :",128
1849,"def _browse_your_music(web_client, variant):<tab>if not web_client.logged_in:<tab><tab>return []<tab>if variant in (""tracks"", ""albums""):<tab><tab>items = flatten(<tab><tab><tab>[<tab><tab><tab><tab>page.get(""items"", [])<tab><tab><tab><tab>for page in web_client.get_all(<tab><tab><tab><tab><tab>f""me/{variant}"",<tab><tab><tab><tab><tab>params={""market"": ""from_token"", ""limit"": 50},<tab><tab><tab><tab>)<tab><tab><tab><tab>if page<tab><tab><tab>]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return list(translator.web_to_track_refs(items))<tab><tab>else:<tab><tab><tab>return list(translator.web_to_album_refs(items))<tab>else:<tab><tab>return []","if variant == ""tracks"" :",198
1850,"def reset_styling(self):<tab>for edge in self.fsm_graph.edges_iter():<tab><tab>style_attr = self.fsm_graph.style_attributes.get(""edge"", {}).get(""default"")<tab><tab>edge.attr.update(style_attr)<tab>for node in self.fsm_graph.nodes_iter():<tab><tab><IF-STMT><tab><tab><tab>style_attr = self.fsm_graph.style_attributes.get(""node"", {}).get(""inactive"")<tab><tab><tab>node.attr.update(style_attr)<tab>for sub_graph in self.fsm_graph.subgraphs_iter():<tab><tab>style_attr = self.fsm_graph.style_attributes.get(""graph"", {}).get(""default"")<tab><tab>sub_graph.graph_attr.update(style_attr)","if ""point"" not in node . attr [ ""shape"" ] :",200
1851,"def set_message_type_visibility(self, message_type: MessageType):<tab>try:<tab><tab>rows = {<tab><tab><tab>i<tab><tab><tab>for i, msg in enumerate(self.proto_analyzer.messages)<tab><tab><tab><IF-STMT><tab><tab>}<tab><tab>if message_type.show:<tab><tab><tab>self.ui.tblViewProtocol.show_rows(rows)<tab><tab>else:<tab><tab><tab>self.ui.tblViewProtocol.hide_rows(rows)<tab>except Exception as e:<tab><tab>logger.exception(e)",if msg . message_type == message_type,138
1852,"def POP(cpu, *regs):<tab>for reg in regs:<tab><tab>val = cpu.stack_pop(cpu.address_bit_size // 8)<tab><tab><IF-STMT><tab><tab><tab>cpu._set_mode_by_val(val)<tab><tab><tab>val = val & ~0x1<tab><tab>reg.write(val)","if reg . reg in ( ""PC"" , ""R15"" ) :",89
1853,"def processMovie(self, atom):<tab>for field in atom:<tab><tab>if ""track"" in field:<tab><tab><tab>self.processTrack(field[""track""])<tab><tab><IF-STMT><tab><tab><tab>self.processMovieHeader(field[""movie_hdr""])","if ""movie_hdr"" in field :",69
1854,"def check_update_function(url, folder, update_setter, version_setter, auto):<tab>remote_version = urllib.urlopen(url).read()<tab>if remote_version.isdigit():<tab><tab>local_version = get_local_timestamp(folder)<tab><tab><IF-STMT><tab><tab><tab>if auto:<tab><tab><tab><tab>update_setter.set_value(True)<tab><tab><tab>version_setter.set_value(remote_version)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return False",if remote_version > local_version :,136
1855,"def init(self, view, items=None):<tab>selections = []<tab>if view.sel():<tab><tab>for region in view.sel():<tab><tab><tab>selections.append(view.substr(region))<tab>values = []<tab>for idx, index in enumerate(map(int, items)):<tab><tab>if idx >= len(selections):<tab><tab><tab>break<tab><tab>i = index - 1<tab><tab><IF-STMT><tab><tab><tab>values.append(selections[i])<tab><tab>else:<tab><tab><tab>values.append(None)<tab># fill up<tab>for idx, value in enumerate(selections):<tab><tab>if len(values) + 1 < idx:<tab><tab><tab>values.append(value)<tab>self.stack = values",if i >= 0 and i < len ( selections ) :,178
1856,"def find_int_identifiers(directory):<tab>results = find_rules(directory, has_int_identifier)<tab>print(""Number of rules with integer identifiers: %d"" % len(results))<tab>for result in results:<tab><tab>rule_path = result[0]<tab><tab>product_yaml_path = result[1]<tab><tab>product_yaml = None<tab><tab><IF-STMT><tab><tab><tab>product_yaml = yaml.open_raw(product_yaml_path)<tab><tab>fix_file(rule_path, product_yaml, fix_int_identifier)",if product_yaml_path is not None :,138
1857,"def condition(self):<tab>if self.__condition is None:<tab><tab>if len(self.flat_conditions) == 1:<tab><tab><tab># Avoid an extra indirection in the common case of only one condition.<tab><tab><tab>self.__condition = self.flat_conditions[0]<tab><tab><IF-STMT><tab><tab><tab># Possible, if unlikely, due to filter predicate rewriting<tab><tab><tab>self.__condition = lambda _: True<tab><tab>else:<tab><tab><tab>self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions)<tab>return self.__condition",elif len ( self . flat_conditions ) == 0 :,143
1858,"def get_scene_exceptions_by_season(self, season=-1):<tab>scene_exceptions = []<tab>for scene_exception in self.scene_exceptions:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>scene_name, scene_season = scene_exception.split(""|"")<tab><tab>if season == scene_season:<tab><tab><tab>scene_exceptions.append(scene_name)<tab>return scene_exceptions",if not len ( scene_exception ) == 2 :,121
1859,"def init(self, view, items=None):<tab>selections = []<tab>if view.sel():<tab><tab>for region in view.sel():<tab><tab><tab>selections.append(view.substr(region))<tab>values = []<tab>for idx, index in enumerate(map(int, items)):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>i = index - 1<tab><tab>if i >= 0 and i < len(selections):<tab><tab><tab>values.append(selections[i])<tab><tab>else:<tab><tab><tab>values.append(None)<tab># fill up<tab>for idx, value in enumerate(selections):<tab><tab>if len(values) + 1 < idx:<tab><tab><tab>values.append(value)<tab>self.stack = values",if idx >= len ( selections ) :,178
1860,"def to_tool_path(self, path_or_uri_like, **kwds):<tab>if ""://"" not in path_or_uri_like:<tab><tab>path = path_or_uri_like<tab>else:<tab><tab>uri_like = path_or_uri_like<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Invalid URI passed to get_tool_source"")<tab><tab>scheme, rest = uri_like.split("":"", 2)<tab><tab>if scheme not in self.resolver_classes:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Unknown tool scheme [{}] for URI [{}]"".format(scheme, uri_like)<tab><tab><tab>)<tab><tab>path = self.resolver_classes[scheme]().get_tool_source_path(uri_like)<tab>return path","if "":"" not in path_or_uri_like :",188
1861,def mainWindow():<tab>global MW<tab>if not MW:<tab><tab>for i in qApp.topLevelWidgets():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>MW = i<tab><tab><tab><tab>return MW<tab><tab>return None<tab>else:<tab><tab>return MW,"if i . objectName ( ) == ""MainWindow"" :",78
1862,"def async_get_service(hass, config, discovery_info=None):<tab># pylint: disable=unused-argument<tab>""""""Get the demo notification service.""""""<tab>for account, account_dict in hass.data[DATA_ALEXAMEDIA][""accounts""].items():<tab><tab>for key, _ in account_dict[""devices""][""media_player""].items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_LOGGER.debug(<tab><tab><tab><tab><tab>""%s: Media player %s not loaded yet; delaying load"",<tab><tab><tab><tab><tab>hide_email(account),<tab><tab><tab><tab><tab>hide_serial(key),<tab><tab><tab><tab>)<tab><tab><tab><tab>return False<tab>return AlexaNotificationService(hass)","if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :",182
1863,"def _migrate_bool(self, name: str, true_value: str, false_value: str) -> None:<tab>if name not in self._settings:<tab><tab>return<tab>values = self._settings[name]<tab>if not isinstance(values, dict):<tab><tab>return<tab>for scope, val in values.items():<tab><tab><IF-STMT><tab><tab><tab>new_value = true_value if val else false_value<tab><tab><tab>self._settings[name][scope] = new_value<tab><tab><tab>self.changed.emit()","if isinstance ( val , bool ) :",130
1864,"def send(self, data, flags=0):<tab>self._checkClosed()<tab>if self._sslobj:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""non-zero flags not allowed in calls to send() on %s"" % self.__class__<tab><tab><tab>)<tab><tab>return self._sslobj.write(data)<tab>else:<tab><tab>return socket.send(self, data, flags)",if flags != 0 :,106
1865,"def rec_deps(services, container_by_name, cnt, init_service):<tab>deps = cnt[""_deps""]<tab>for dep in deps.copy():<tab><tab>dep_cnts = services.get(dep)<tab><tab>if not dep_cnts:<tab><tab><tab>continue<tab><tab>dep_cnt = container_by_name.get(dep_cnts[0])<tab><tab><IF-STMT><tab><tab><tab># TODO: avoid creating loops, A->B->A<tab><tab><tab>if init_service and init_service in dep_cnt[""_deps""]:<tab><tab><tab><tab>continue<tab><tab><tab>new_deps = rec_deps(services, container_by_name, dep_cnt, init_service)<tab><tab><tab>deps.update(new_deps)<tab>return deps",if dep_cnt :,181
1866,"def as_dict(path="""", version=""latest"", section=""meta-data""):<tab>result = {}<tab>dirs = dir(path, version, section)<tab>if not dirs:<tab><tab>return None<tab>for item in dirs:<tab><tab>if item.endswith(""/""):<tab><tab><tab>records = as_dict(path + item, version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[item[:-1]] = records<tab><tab><IF-STMT><tab><tab><tab>idx, name = is_dict.match(item).groups()<tab><tab><tab>records = as_dict(path + idx + ""/"", version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[name] = records<tab><tab>else:<tab><tab><tab>result[item] = valueconv(get(path + item, version, section))<tab>return result",elif is_dict . match ( item ) :,197
1867,"def PrintColGroup(col_names, schema):<tab>""""""Print HTML colgroup element, used for JavaScript sorting.""""""<tab>print(""  <colgroup>"")<tab>for i, col in enumerate(col_names):<tab><tab>if col.endswith(""_HREF""):<tab><tab><tab>continue<tab><tab># CSS class is used for sorting<tab><tab><IF-STMT><tab><tab><tab>css_class = ""number""<tab><tab>else:<tab><tab><tab>css_class = ""case-insensitive""<tab><tab># NOTE: id is a comment only; not used<tab><tab>print('<tab><col id=""{}"" type=""{}"" />'.format(col, css_class))<tab>print(""  </colgroup>"")",if schema . IsNumeric ( col ) :,161
1868,"def check_region(self, region):<tab>for other in self.regions:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (other.start < region.start < other.end) or (<tab><tab><tab>other.start < region.end < other.end<tab><tab>):<tab><tab><tab>raise Exception(""%r overlaps with %r"" % (region, other))",if other is region :,89
1869,"def _write_value(self, rng, value, scalar):<tab>if rng.api and value:<tab><tab># it is assumed by this stage that value is a list of lists<tab><tab><IF-STMT><tab><tab><tab>value = value[0][0]<tab><tab>else:<tab><tab><tab>rng = rng.resize(len(value), len(value[0]))<tab><tab>rng.raw_value = value",if scalar :,94
1870,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_cost().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.add_version(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,167
1871,"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None):<tab># This part of function creates faces in SV format<tab># It ignores  boundless super face<tab>sv_faces = []<tab>for i, face in enumerate(dcel_mesh.faces):<tab><tab><IF-STMT><tab><tab><tab>""Face ({}) has inner components! Sverchok cant show polygons with holes."".format(<tab><tab><tab><tab>i<tab><tab><tab>)<tab><tab>if not face.outer or del_flag in face.flags:<tab><tab><tab>continue<tab><tab>if only_select and not face.select:<tab><tab><tab>continue<tab><tab>sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges])<tab>return sv_faces",if face . inners and face . outer :,198
1872,"def _get_x_for_y(self, xValue, x, y):<tab># print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y)<tab>x_value = str(xValue)<tab>for anime in self.xmlMap.findall(""anime""):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(anime.get(y, 0))<tab><tab>except ValueError as e:<tab><tab><tab>continue<tab>return 0","if anime . get ( x , False ) == x_value :",131
1873,"def dir_copy(src_dir, dest_dir, merge_if_exists=True):<tab>try:<tab><tab>if not os.path.exists(dest_dir):<tab><tab><tab>shutil.copytree(src_dir, dest_dir)<tab><tab><IF-STMT><tab><tab><tab>merge_dir(src_dir, dest_dir)<tab>except OSError as e:<tab><tab># If source is not a directory, copy with shutil.copy<tab><tab>if e.errno == errno.ENOTDIR:<tab><tab><tab>shutil.copy(src_dir, dest_dir)<tab><tab>else:<tab><tab><tab>logging.error(""Could not copy %s to %s"", src_dir, dest_dir)",elif merge_if_exists :,166
1874,"def mapping(self):<tab>m = {}<tab>if getGdriveCredentialsFile() is not None:<tab><tab>m[""gdrive""] = """"<tab>unknown = 0<tab>for f in self.scan:<tab><tab>bits = f.split(""#"", 2)<tab><tab>if len(bits) == 1:<tab><tab><tab>label = os.path.basename(f)<tab><tab>else:<tab><tab><tab>label = bits[1]<tab><tab><IF-STMT><tab><tab><tab>label = ""L"" + str(unknown)<tab><tab><tab>unknown += 1<tab><tab>m[label] = bits[0]<tab>return m","if not label or len ( label ) == 0 or label == """" :",153
1875,"def get_tag_values(self, event):<tab>http = event.interfaces.get(""sentry.interfaces.Http"")<tab>if not http:<tab><tab>return []<tab>if not http.headers:<tab><tab>return []<tab>headers = http.headers<tab># XXX: transitional support for workers<tab>if isinstance(headers, dict):<tab><tab>headers = headers.items()<tab>output = []<tab>for key, value in headers:<tab><tab>if key != ""User-Agent"":<tab><tab><tab>continue<tab><tab>ua = Parse(value)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>result = self.get_tag_from_ua(ua)<tab><tab>if result:<tab><tab><tab>output.append(result)<tab>return output",if not ua :,176
1876,"def __iter__(self):<tab>it = DiskHashMerger.__iter__(self)<tab>direct_upstreams = self.direct_upstreams<tab>for k, groups in it:<tab><tab>t = list([[] for _ in range(self.size)])<tab><tab>for i, g in enumerate(groups):<tab><tab><tab>if g:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>t[i] = g<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>g.sort(key=itemgetter(0))<tab><tab><tab><tab><tab>g1 = []<tab><tab><tab><tab><tab>for _, vs in g:<tab><tab><tab><tab><tab><tab>g1.extend(vs)<tab><tab><tab><tab><tab>t[i] = g1<tab><tab>yield k, tuple(t)",if i in direct_upstreams :,185
1877,"def process_question(qtxt):<tab>question = """"<tab>skip = False<tab>for letter in qtxt:<tab><tab><IF-STMT><tab><tab><tab>skip = True<tab><tab>if letter == "">"":<tab><tab><tab>skip = False<tab><tab>if skip:<tab><tab><tab>continue<tab><tab>if letter.isalnum() or letter == "" "":<tab><tab><tab>if letter == "" "":<tab><tab><tab><tab>letter = ""_""<tab><tab><tab>question += letter.lower()<tab>return question","if letter == ""<"" :",110
1878,"def _module_repr_from_spec(spec):<tab>""""""Return the repr to use for the module.""""""<tab># We mostly replicate _module_repr() using the spec attributes.<tab>name = ""?"" if spec.name is None else spec.name<tab>if spec.origin is None:<tab><tab>if spec.loader is None:<tab><tab><tab>return ""<module {!r}>"".format(name)<tab><tab>else:<tab><tab><tab>return ""<module {!r} ({!r})>"".format(name, spec.loader)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return ""<module {!r} from {!r}>"".format(name, spec.origin)<tab><tab>else:<tab><tab><tab>return ""<module {!r} ({})>"".format(spec.name, spec.origin)",if spec . has_location :,180
1879,"def test_row(self, row):<tab>for idx, test in self.patterns.items():<tab><tab>try:<tab><tab><tab>value = row[idx]<tab><tab>except IndexError:<tab><tab><tab>value = """"<tab><tab>result = test(value)<tab><tab>if self.any_match:<tab><tab><tab>if result:<tab><tab><tab><tab>return not self.inverse  # True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.inverse  # False<tab>if self.any_match:<tab><tab>return self.inverse  # False<tab>else:<tab><tab>return not self.inverse  # True",if not result :,149
1880,"def frequent_thread_switches():<tab>""""""Make concurrency bugs more likely to manifest.""""""<tab>interval = None<tab>if not sys.platform.startswith(""java""):<tab><tab><IF-STMT><tab><tab><tab>interval = sys.getswitchinterval()<tab><tab><tab>sys.setswitchinterval(1e-6)<tab><tab>else:<tab><tab><tab>interval = sys.getcheckinterval()<tab><tab><tab>sys.setcheckinterval(1)<tab>try:<tab><tab>yield<tab>finally:<tab><tab>if not sys.platform.startswith(""java""):<tab><tab><tab>if hasattr(sys, ""setswitchinterval""):<tab><tab><tab><tab>sys.setswitchinterval(interval)<tab><tab><tab>else:<tab><tab><tab><tab>sys.setcheckinterval(interval)","if hasattr ( sys , ""getswitchinterval"" ) :",177
1881,"def record_expected_exportable_production(self, ticks):<tab>""""""Record the amount of production that should be transferred to other islands.""""""<tab>for (quota_holder, resource_id), amount in self._low_priority_requests.items():<tab><tab><IF-STMT><tab><tab><tab>self._settlement_manager_id[quota_holder] = WorldObject.get_object_by_id(<tab><tab><tab><tab>int(quota_holder[1:].split("","")[0])<tab><tab><tab>).settlement_manager.worldid<tab><tab>self.trade_storage[self._settlement_manager_id[quota_holder]][resource_id] += (<tab><tab><tab>ticks * amount<tab><tab>)",if quota_holder not in self . _settlement_manager_id :,168
1882,"def _method_events_callback(self, values):<tab>try:<tab><tab>previous_echoed = (<tab><tab><tab>values[""child_result_list""][-1].decode().split(""\n"")[-2].strip()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ""echo foo2\n""<tab><tab>elif previous_echoed.endswith(""foo2""):<tab><tab><tab>return ""echo foo3\n""<tab><tab>elif previous_echoed.endswith(""foo3""):<tab><tab><tab>return ""exit\n""<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected output {0!r}"".format(previous_echoed))<tab>except IndexError:<tab><tab>return ""echo foo1\n""","if previous_echoed . endswith ( ""foo1"" ) :",172
1883,"def describe_cluster_snapshots(self, cluster_identifier=None, snapshot_identifier=None):<tab>if cluster_identifier:<tab><tab>cluster_snapshots = []<tab><tab>for snapshot in self.snapshots.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cluster_snapshots.append(snapshot)<tab><tab>if cluster_snapshots:<tab><tab><tab>return cluster_snapshots<tab>if snapshot_identifier:<tab><tab>if snapshot_identifier in self.snapshots:<tab><tab><tab>return [self.snapshots[snapshot_identifier]]<tab><tab>raise ClusterSnapshotNotFoundError(snapshot_identifier)<tab>return self.snapshots.values()",if snapshot . cluster . cluster_identifier == cluster_identifier :,149
1884,def get_snippet_edit_handler(model):<tab>if model not in SNIPPET_EDIT_HANDLERS:<tab><tab><IF-STMT><tab><tab><tab># use the edit handler specified on the page class<tab><tab><tab>edit_handler = model.edit_handler<tab><tab>else:<tab><tab><tab>panels = extract_panel_definitions_from_model_class(model)<tab><tab><tab>edit_handler = ObjectList(panels)<tab><tab>SNIPPET_EDIT_HANDLERS[model] = edit_handler.bind_to(model=model)<tab>return SNIPPET_EDIT_HANDLERS[model],"if hasattr ( model , ""edit_handler"" ) :",137
1885,"def start():<tab>if os.environ.get(""RUN_MAIN"") != ""true"":<tab><tab>try:<tab><tab><tab>exit_code = restart_with_reloader()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.kill(os.getpid(), -exit_code)<tab><tab><tab>else:<tab><tab><tab><tab>sys.exit(exit_code)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>pass",if exit_code < 0 :,100
1886,"def discover(self, *objlist):<tab>ret = []<tab>for l in self.splitlines():<tab><tab>if len(l) < 5:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>int(l[2])<tab><tab><tab>int(l[3])<tab><tab>except:<tab><tab><tab>continue<tab><tab>#<tab><tab>   ret.append(improve(l[0]))<tab><tab>ret.append(l[0])<tab>ret.sort()<tab>for item in objlist:<tab><tab>ret.append(item)<tab>return ret","if l [ 0 ] == ""Filename"" :",154
1887,"def ipfs_publish(self, lib):<tab>with tempfile.NamedTemporaryFile() as tmp:<tab><tab>self.ipfs_added_albums(lib, tmp.name)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cmd = ""ipfs add --nocopy -q "".split()<tab><tab><tab>else:<tab><tab><tab><tab>cmd = ""ipfs add -q "".split()<tab><tab><tab>cmd.append(tmp.name)<tab><tab><tab>output = util.command_output(cmd)<tab><tab>except (OSError, subprocess.CalledProcessError) as err:<tab><tab><tab>msg = ""Failed to publish library. Error: {0}"".format(err)<tab><tab><tab>self._log.error(msg)<tab><tab><tab>return False<tab><tab>self._log.info(""hash of library: {0}"", output)","if self . config [ ""nocopy"" ] :",188
1888,"def spends(self):<tab># Return spends indexed by hashX<tab>spends = defaultdict(list)<tab>utxos = self.mempool_utxos()<tab>for tx_hash, tx in self.txs.items():<tab><tab>for n, input in enumerate(tx.inputs):<tab><tab><tab>if input.is_generation():<tab><tab><tab><tab>continue<tab><tab><tab>prevout = (input.prev_hash, input.prev_idx)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hashX, value = utxos.pop(prevout)<tab><tab><tab>else:<tab><tab><tab><tab>hashX, value = self.db_utxos[prevout]<tab><tab><tab>spends[hashX].append(prevout)<tab>return spends",if prevout in utxos :,188
1889,"def terminate(self):<tab>if self.returncode is None:<tab><tab>try:<tab><tab><tab>os.kill(self.pid, TERM_SIGNAL)<tab><tab>except OSError as exc:<tab><tab><tab>if getattr(exc, ""errno"", None) != errno.ESRCH:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise",if self . wait ( timeout = 0.1 ) is None :,92
1890,"def _getVolumeScalar(self):<tab>if self._volumeScalar is not None:<tab><tab>return self._volumeScalar<tab># use default<tab>elif self._value in dynamicStrToScalar:<tab><tab>return dynamicStrToScalar[self._value]<tab>else:<tab><tab>thisDynamic = self._value<tab><tab># ignore leading s like in sf<tab><tab><IF-STMT><tab><tab><tab>thisDynamic = thisDynamic[1:]<tab><tab># ignore closing z like in fz<tab><tab>if thisDynamic[-1] == ""z"":<tab><tab><tab>thisDynamic = thisDynamic[:-1]<tab><tab>if thisDynamic in dynamicStrToScalar:<tab><tab><tab>return dynamicStrToScalar[thisDynamic]<tab><tab>else:<tab><tab><tab>return dynamicStrToScalar[None]","if ""s"" in thisDynamic :",183
1891,"def init_values(self):<tab>config = self._raw_config<tab>for valname, value in self.overrides.iteritems():<tab><tab>if ""."" in valname:<tab><tab><tab>realvalname, key = valname.split(""."", 1)<tab><tab><tab>config.setdefault(realvalname, {})[key] = value<tab><tab>else:<tab><tab><tab>config[valname] = value<tab>for name in config:<tab><tab><IF-STMT><tab><tab><tab>self.__dict__[name] = config[name]<tab>del self._raw_config",if name in self . values :,131
1892,"def modified(self):<tab>paths = set()<tab>dictionary_list = []<tab>for op_list in self._operations:<tab><tab>if not isinstance(op_list, list):<tab><tab><tab>op_list = (op_list,)<tab><tab>for item in chain(*op_list):<tab><tab><tab>if item is None:<tab><tab><tab><tab>continue<tab><tab><tab>dictionary = item.dictionary<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>paths.add(dictionary.path)<tab><tab><tab>dictionary_list.append(dictionary)<tab>return dictionary_list",if dictionary . path in paths :,139
1893,"def __getitem__(self, key, _get_mode=False):<tab>if not _get_mode:<tab><tab><IF-STMT><tab><tab><tab>return self._list[key]<tab><tab>elif isinstance(key, slice):<tab><tab><tab>return self.__class__(self._list[key])<tab>ikey = key.lower()<tab>for k, v in self._list:<tab><tab>if k.lower() == ikey:<tab><tab><tab>return v<tab># micro optimization: if we are in get mode we will catch that<tab># exception one stack level down so we can raise a standard<tab># key error instead of our special one.<tab>if _get_mode:<tab><tab>raise KeyError()<tab>raise BadRequestKeyError(key)","if isinstance ( key , ( int , long ) ) :",176
1894,"def _get_items(self, name, target=1):<tab>all_items = self.get_items(name)<tab>items = [o for o in all_items if not o.disabled]<tab>if len(items) < target:<tab><tab><IF-STMT><tab><tab><tab>raise ItemNotFoundError(""insufficient items with name %r"" % name)<tab><tab>else:<tab><tab><tab>raise AttributeError(""insufficient non-disabled items with name %s"" % name)<tab>on = []<tab>off = []<tab>for o in items:<tab><tab>if o.selected:<tab><tab><tab>on.append(o)<tab><tab>else:<tab><tab><tab>off.append(o)<tab>return on, off",if len ( all_items ) < target :,169
1895,"def get_genome_dir(gid, galaxy_dir, data):<tab>""""""Return standard location of genome directories.""""""<tab>if galaxy_dir:<tab><tab>refs = genome.get_refs(gid, None, galaxy_dir, data)<tab><tab>seq_file = tz.get_in([""fasta"", ""base""], refs)<tab><tab><IF-STMT><tab><tab><tab>return os.path.dirname(os.path.dirname(seq_file))<tab>else:<tab><tab>gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid))<tab><tab>if len(gdirs) == 1 and os.path.exists(gdirs[0]):<tab><tab><tab>return gdirs[0]",if seq_file and os . path . exists ( seq_file ) :,190
1896,"def _PrintFuncs(self, names):<tab># type: (List[str]) -> int<tab>status = 0<tab>for name in names:<tab><tab><IF-STMT><tab><tab><tab>print(name)<tab><tab><tab># TODO: Could print LST for -f, or render LST.  Bash does this.  'trap'<tab><tab><tab># could use that too.<tab><tab>else:<tab><tab><tab>status = 1<tab>return status",if name in self . funcs :,110
1897,"def package_files(self):<tab>seen_package_directories = ()<tab>directories = self.distribution.package_dir or {}<tab>empty_directory_exists = """" in directories<tab>packages = self.distribution.packages or []<tab>for package in packages:<tab><tab>if package in directories:<tab><tab><tab>package_directory = directories[package]<tab><tab>elif empty_directory_exists:<tab><tab><tab>package_directory = os.path.join(directories[""""], package)<tab><tab>else:<tab><tab><tab>package_directory = package<tab><tab><IF-STMT><tab><tab><tab>seen_package_directories += (package_directory + ""."",)<tab><tab><tab>yield package_directory",if not package_directory . startswith ( seen_package_directories ) :,164
1898,"def apply_conf_file(fn, conf_filename):<tab>for env in LSF_CONF_ENV:<tab><tab>conf_file = get_conf_file(conf_filename, env)<tab><tab><IF-STMT><tab><tab><tab>with open(conf_file) as conf_handle:<tab><tab><tab><tab>value = fn(conf_handle)<tab><tab><tab>if value:<tab><tab><tab><tab>return value<tab>return None",if conf_file :,101
1899,"def on_text(self, text):<tab>if text != self.chosen_text:<tab><tab>self.fail_test('Expected ""{}"", received ""{}""'.format(self.chosen_text, text))<tab>else:<tab><tab>self.checks_passed += 1<tab><tab><IF-STMT><tab><tab><tab>self.pass_test()<tab><tab>else:<tab><tab><tab>self._select_next_text()",if self . checks_passed >= self . number_of_checks :,103
1900,"def test_field_attr_existence(self):<tab>for name, item in ast.__dict__.items():<tab><tab>if self._is_ast_node(name, item):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Index(value) just returns value now.<tab><tab><tab><tab># The argument is required.<tab><tab><tab><tab>continue<tab><tab><tab>x = item()<tab><tab><tab>if isinstance(x, ast.AST):<tab><tab><tab><tab>self.assertEqual(type(x._fields), tuple)","if name == ""Index"" :",122
1901,"def apply(self, response):<tab>updated_headers = self.update_headers(response)<tab>if updated_headers:<tab><tab>response.headers.update(updated_headers)<tab><tab>warning_header_value = self.warning(response)<tab><tab><IF-STMT><tab><tab><tab>response.headers.update({""Warning"": warning_header_value})<tab>return response",if warning_header_value is not None :,92
1902,"def validate(self):<tab>self.assertEqual(len(self.inputs), len(self.outputs))<tab>for batch_in, batch_out in zip(self.inputs, self.outputs):<tab><tab>self.assertEqual(len(batch_in), len(batch_out))<tab><tab>if self.use_parallel_executor and not self.use_double_buffer:<tab><tab><tab>self.validate_unordered_batch(batch_in, batch_out)<tab><tab>else:<tab><tab><tab>for in_data, out_data in zip(batch_in, batch_out):<tab><tab><tab><tab>self.assertEqual(in_data.shape, out_data.shape)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.assertTrue((in_data == out_data).all())",if not self . use_parallel_executor :,189
1903,def finalize(self):<tab>if self._started:<tab><tab><IF-STMT><tab><tab><tab>self._queue.put(None)<tab><tab><tab>self._queue.join()<tab><tab><tab>self._consumer.join()<tab><tab>self._started = False<tab>self._finalized = True,if not self . _finalized :,70
1904,"def _get_ilo_version(self):<tab>try:<tab><tab>self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>')<tab>except ResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>if e.code == 405:<tab><tab><tab><tab>return 3<tab><tab><tab>if e.code == 501:<tab><tab><tab><tab>return 1<tab><tab>raise<tab>return 2","if hasattr ( e , ""code"" ) :",113
1905,"def _check_data(self, source, expected_bytes, expected_duration):<tab>received_bytes = 0<tab>received_seconds = 0.0<tab>bytes_to_read = 1024<tab>while True:<tab><tab>data = source.get_audio_data(bytes_to_read)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>received_bytes += data.length<tab><tab>received_seconds += data.duration<tab><tab>self.assertEqual(data.length, len(data.data))<tab>self.assertAlmostEqual(expected_duration, received_seconds, places=1)<tab>self.assertAlmostEqual(expected_bytes, received_bytes, delta=5)",if data is None :,154
1906,"def __randomize_interval_task(self):<tab>for job in self.aps_scheduler.get_jobs():<tab><tab><IF-STMT><tab><tab><tab>self.aps_scheduler.modify_job(<tab><tab><tab><tab>job.id,<tab><tab><tab><tab>next_run_time=datetime.now()<tab><tab><tab><tab>+ timedelta(<tab><tab><tab><tab><tab>seconds=randrange(<tab><tab><tab><tab><tab><tab>job.trigger.interval.total_seconds() * 0.75,<tab><tab><tab><tab><tab><tab>job.trigger.interval.total_seconds(),<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>),<tab><tab><tab>)","if isinstance ( job . trigger , IntervalTrigger ) :",153
1907,"def find_approximant(x):<tab>c = 1e-4<tab>it = sympy.ntheory.continued_fraction_convergents(<tab><tab>sympy.ntheory.continued_fraction_iterator(x)<tab>)<tab>for i in it:<tab><tab>p, q = i.as_numer_denom()<tab><tab>tol = c / q ** 2<tab><tab><IF-STMT><tab><tab><tab>return i<tab><tab>if tol < machine_epsilon:<tab><tab><tab>break<tab>return x",if abs ( i - x ) <= tol :,122
1908,"def fix_newlines(lines):<tab>""""""Convert newlines to unix.""""""<tab>for i, line in enumerate(lines):<tab><tab>if line.endswith(""\r\n""):<tab><tab><tab>lines[i] = line[:-2] + ""\n""<tab><tab><IF-STMT><tab><tab><tab>lines[i] = line[:-1] + ""\n""","elif line . endswith ( ""\r"" ) :",83
1909,"def payment_control_render(self, request: HttpRequest, payment: OrderPayment):<tab>template = get_template(""pretixplugins/paypal/control.html"")<tab>sale_id = None<tab>for trans in payment.info_data.get(""transactions"", []):<tab><tab>for res in trans.get(""related_resources"", []):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sale_id = res[""sale""][""id""]<tab>ctx = {<tab><tab>""request"": request,<tab><tab>""event"": self.event,<tab><tab>""settings"": self.settings,<tab><tab>""payment_info"": payment.info_data,<tab><tab>""order"": payment.order,<tab><tab>""sale_id"": sale_id,<tab>}<tab>return template.render(ctx)","if ""sale"" in res and ""id"" in res [ ""sale"" ] :",192
1910,"def for_name(self, name):<tab>try:<tab><tab>name_resources = self._resources[name]<tab>except KeyError:<tab><tab>raise LookupError(name)<tab>else:<tab><tab>for res in name_resources:<tab><tab><tab>try:<tab><tab><tab><tab>inst = res.inst()<tab><tab><tab>except Exception as e:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>log.exception(""error initializing %s"", res)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>log.error(""error initializing %s: %s"", res, e)<tab><tab><tab>else:<tab><tab><tab><tab>yield inst",if log . getEffectiveLevel ( ) <= logging . DEBUG :,154
1911,"def describe(self, done=False):<tab>description = ShellCommand.describe(self, done)<tab>if done:<tab><tab><IF-STMT><tab><tab><tab>description = [""compile""]<tab><tab>description.append(""%d projects"" % self.getStatistic(""projects"", 0))<tab><tab>description.append(""%d files"" % self.getStatistic(""files"", 0))<tab><tab>warnings = self.getStatistic(""warnings"", 0)<tab><tab>if warnings > 0:<tab><tab><tab>description.append(""%d warnings"" % warnings)<tab><tab>errors = self.getStatistic(""errors"", 0)<tab><tab>if errors > 0:<tab><tab><tab>description.append(""%d errors"" % errors)<tab>return description",if not description :,164
1912,"def parse_list(tl):<tab>ls = []<tab>nm = []<tab>while True:<tab><tab>term, nmt, tl = parse_term(tl)<tab><tab>ls.append(term)<tab><tab><IF-STMT><tab><tab><tab>nm.append(nmt)<tab><tab>if tl[0] != "","":<tab><tab><tab>break<tab><tab>tl = tl[1:]<tab>return ls, nm, tl",if nmt is not None :,101
1913,"def infer_dataset_impl(path):<tab>if IndexedRawTextDataset.exists(path):<tab><tab>return ""raw""<tab>elif IndexedDataset.exists(path):<tab><tab>with open(index_file_path(path), ""rb"") as f:<tab><tab><tab>magic = f.read(8)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""cached""<tab><tab><tab>elif magic == MMapIndexedDataset.Index._HDR_MAGIC[:8]:<tab><tab><tab><tab>return ""mmap""<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab>elif FastaDataset.exists(path):<tab><tab>return ""fasta""<tab>else:<tab><tab>return None",if magic == IndexedDataset . _HDR_MAGIC :,167
1914,"def _get(self):<tab>fut = item = None<tab>with self._mutex:<tab><tab># Critical section never blocks.<tab><tab><IF-STMT><tab><tab><tab>fut = Future()<tab><tab><tab>fut.add_done_callback(<tab><tab><tab><tab>lambda f: self._get_complete() if not f.cancelled() else None<tab><tab><tab>)<tab><tab><tab>self._getters.append(fut)<tab><tab>else:<tab><tab><tab>item = self._get_item()<tab><tab><tab>self._get_complete()<tab>return item, fut",if not self . _queue or self . _getters :,142
1915,"def validate(self):<tab>dates = []<tab>for d in self.get(""leave_block_list_dates""):<tab><tab># date is not repeated<tab><tab><IF-STMT><tab><tab><tab>frappe.msgprint(<tab><tab><tab><tab>_(""Date is repeated"") + "":"" + d.block_date, raise_exception=1<tab><tab><tab>)<tab><tab>dates.append(d.block_date)",if d . block_date in dates :,101
1916,"def on_choose_watch_dir_clicked(self):<tab>if self.window().watchfolder_enabled_checkbox.isChecked():<tab><tab>previous_watch_dir = self.window().watchfolder_location_input.text() or """"<tab><tab>watch_dir = QFileDialog.getExistingDirectory(<tab><tab><tab>self.window(),<tab><tab><tab>""Please select the watch folder"",<tab><tab><tab>previous_watch_dir,<tab><tab><tab>QFileDialog.ShowDirsOnly,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.window().watchfolder_location_input.setText(watch_dir)",if not watch_dir :,147
1917,"def log_generator(self, limit=6000, **kwargs):<tab># Generator for show_log_panel<tab>skip = 0<tab>while True:<tab><tab>logs = self.log(limit=limit, skip=skip, **kwargs)<tab><tab>if not logs:<tab><tab><tab>break<tab><tab>for entry in logs:<tab><tab><tab>yield entry<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>skip = skip + limit",if len ( logs ) < limit :,106
1918,"def _setUpClass(cls):<tab>global solver<tab>import pyomo.environ<tab>from pyomo.solvers.tests.io.writer_test_cases import testCases<tab>for test_case in testCases:<tab><tab><IF-STMT><tab><tab><tab>solver[(test_case.name, test_case.io)] = True","if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :",101
1919,"def _get_file_data(self, normpath, normrev):<tab>data = self.client.cat(normpath, normrev)<tab>if has_expanded_svn_keywords(data):<tab><tab># Find out if this file has any keyword expansion set.<tab><tab># If it does, collapse these keywords. This is because SVN<tab><tab># will return the file expanded to us, which would break patching.<tab><tab>keywords = self.client.propget(""svn:keywords"", normpath, normrev, recurse=True)<tab><tab><IF-STMT><tab><tab><tab>data = collapse_svn_keywords(data, force_bytes(keywords[normpath]))<tab>return data",if normpath in keywords :,152
1920,"def add_controller_list(path):<tab>if not os.path.exists(os.path.join(path, ""__init__.py"")):<tab><tab>bb.fatal(""Controllers directory %s exists but is missing __init__.py"" % path)<tab>files = sorted(<tab><tab>[f for f in os.listdir(path) if f.endswith("".py"") and not f.startswith(""_"")]<tab>)<tab>for f in files:<tab><tab>module = ""oeqa.controllers."" + f[:-3]<tab><tab><IF-STMT><tab><tab><tab>controllerslist.append(module)<tab><tab>else:<tab><tab><tab>bb.warn(<tab><tab><tab><tab>""Duplicate controller module found for %s, only one added. Layers should create unique controller module names""<tab><tab><tab><tab>% module<tab><tab><tab>)",if module not in controllerslist :,197
1921,"def on_session2(event):<tab>new_xmpp.get_roster()<tab>new_xmpp.send_presence()<tab>logging.info(roster[0])<tab>data = roster[0][""roster""][""items""]<tab>logging.info(data)<tab>for jid, item in data.items():<tab><tab><IF-STMT><tab><tab><tab>new_xmpp.send_presence(ptype=""subscribe"", pto=jid)<tab><tab>new_xmpp.update_roster(jid, name=item[""name""], groups=item[""groups""])<tab>new_xmpp.disconnect()","if item [ ""subscription"" ] != ""none"" :",145
1922,"def _parse_class_simplified(symbol):<tab>results = {}<tab>name = symbol.name + ""(""<tab>name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases])<tab>name += "")""<tab>for sym in symbol.body:<tab><tab><IF-STMT><tab><tab><tab>result = _parse_function_simplified(sym, symbol.name)<tab><tab><tab>results.update(result)<tab><tab>elif isinstance(sym, ast.ClassDef):<tab><tab><tab>result = _parse_class_simplified(sym)<tab><tab><tab>results.update(result)<tab>lineno = symbol.lineno<tab>for decorator in symbol.decorator_list:<tab><tab>lineno += 1<tab>results[lineno] = (name, ""c"")<tab>return results","if isinstance ( sym , ast . FunctionDef ) :",181
1923,"def check_args(args):<tab>""""""Checks that the args are coherent.""""""<tab>check_args_has_attributes(args)<tab>if args.v:<tab><tab>non_version_attrs = [v for k, v in args.__dict__.items() if k != ""v""]<tab><tab>print(""non_version_attrs"", non_version_attrs)<tab><tab><IF-STMT><tab><tab><tab>fail(""Cannot show the version number with another command."")<tab><tab>return<tab>if args.i is None:<tab><tab>fail(""Cannot draw ER diagram of no database."")<tab>if args.o is None:<tab><tab>fail(""Cannot draw ER diagram with no output file."")",if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,176
1924,"def handle(self, *args, **options):<tab>if not settings.ST_BASE_DIR.endswith(""spirit""):<tab><tab>raise CommandError(<tab><tab><tab>""settings.ST_BASE_DIR is not the spirit root folder, are you overriding it?""<tab><tab>)<tab>for root, dirs, files in os.walk(settings.ST_BASE_DIR):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with utils.pushd(root):<tab><tab><tab>call_command(<tab><tab><tab><tab>""makemessages"", stdout=self.stdout, stderr=self.stderr, **options<tab><tab><tab>)<tab>self.stdout.write(""ok"")","if ""locale"" not in dirs :",160
1925,"def scan(scope):<tab>for s in scope.children:<tab><tab>if s.start_pos <= position <= s.end_pos:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return scan(s) or s<tab><tab><tab>elif s.type in (""suite"", ""decorated""):<tab><tab><tab><tab>return scan(s)<tab>return None","if isinstance ( s , ( tree . Scope , tree . Flow ) ) :",92
1926,def run_sync(self):<tab>count = 0<tab>while count < self.args.num_messages:<tab><tab>batch = self.receiver.fetch_next(max_batch_size=self.args.num_messages - count)<tab><tab><IF-STMT><tab><tab><tab>for msg in batch:<tab><tab><tab><tab>msg.complete()<tab><tab>count += len(batch),if self . args . peeklock :,93
1927,"def __getitem__(self, item):<tab>if self._datas is not None:<tab><tab>ret = []<tab><tab>for data in self._datas:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(data[self._offset])<tab><tab><tab>else:<tab><tab><tab><tab>ret.append(data.iloc[self._offset])<tab><tab>self._offset += 1<tab><tab>return ret<tab>else:<tab><tab>return self._get_data(item)","if isinstance ( data , np . ndarray ) :",115
1928,"def removedir(self, path):<tab># type: (Text) -> None<tab>_path = self.validatepath(path)<tab>if _path == ""/"":<tab><tab>raise errors.RemoveRootError()<tab>with ftp_errors(self, path):<tab><tab>try:<tab><tab><tab>self.ftp.rmd(_encode(_path, self.ftp.encoding))<tab><tab>except error_perm as error:<tab><tab><tab>code, _ = _parse_ftp_error(error)<tab><tab><tab>if code == ""550"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise errors.DirectoryExpected(path)<tab><tab><tab><tab>if not self.isempty(path):<tab><tab><tab><tab><tab>raise errors.DirectoryNotEmpty(path)<tab><tab><tab>raise  # pragma: no cover",if self . isfile ( path ) :,189
1929,"def replaces_in_file(file, replacement_list):<tab>rs = [(re.compile(regexp), repl) for (regexp, repl) in replacement_list]<tab>file_tmp = file + ""."" + str(os.getpid()) + "".tmp""<tab>with open(file, ""r"") as f:<tab><tab>with open(file_tmp, ""w"") as f_tmp:<tab><tab><tab>for line in f:<tab><tab><tab><tab>for r, replace in rs:<tab><tab><tab><tab><tab>match = r.search(line)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>line = replace + ""\n""<tab><tab><tab><tab>f_tmp.write(line)<tab>shutil.move(file_tmp, file)",if match :,172
1930,"def _get_path_check_mem(self, i, size):<tab>if size > 0:<tab><tab><IF-STMT><tab><tab><tab>p = self._get_path(i, -1)<tab><tab>else:<tab><tab><tab>p = self._get_path(i, size)<tab><tab><tab>if p.startswith(""/dev/shm""):<tab><tab><tab><tab>env.meminfo.add(size)<tab>else:<tab><tab>p = self._get_path(i, size)<tab>return p",if env . meminfo . rss + size > env . meminfo . mem_limit_soft :,136
1931,"def find_widget_by_id(self, id, parent=None):<tab>""""""Recursively searches for widget with specified ID""""""<tab>if parent == None:<tab><tab>if id in self:<tab><tab><tab>return self[id]  # Do things fast if possible<tab><tab>parent = self[""editor""]<tab>for c in parent.get_children():<tab><tab><IF-STMT><tab><tab><tab>if c.get_id() == id:<tab><tab><tab><tab>return c<tab><tab>if isinstance(c, Gtk.Container):<tab><tab><tab>r = self.find_widget_by_id(id, c)<tab><tab><tab>if not r is None:<tab><tab><tab><tab>return r<tab>return None","if hasattr ( c , ""get_id"" ) :",167
1932,"def _deserialize(cls, io):<tab>flags = VideoFlags()<tab>flags.byte = U8.read(io)<tab>if flags.bit.type == VIDEO_FRAME_TYPE_COMMAND_FRAME:<tab><tab>data = VideoCommandFrame.deserialize(io)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>data = AVCVideoData.deserialize(io)<tab><tab>else:<tab><tab><tab>data = io.read()<tab>return cls(flags.bit.type, flags.bit.codec, data)",if flags . bit . codec == VIDEO_CODEC_ID_AVC :,134
1933,"def asciiLogData(data, maxlen=64, replace=False):<tab>ellipses = "" ...""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>dd = data[:maxlen] + ellipses<tab><tab>else:<tab><tab><tab>dd = data<tab><tab>return dd.decode(""utf8"", errors=""replace"" if replace else ""strict"")<tab>except:<tab><tab>return ""0x"" + binLogData(data, maxlen)",if len ( data ) > maxlen - len ( ellipses ) :,112
1934,"def _check_units(self, new_unit_system):<tab># If no unit system has been specified for me yet, adopt the incoming<tab># system<tab>if self.unit_system is None:<tab><tab>self.unit_system = new_unit_system<tab>else:<tab><tab># Otherwise, make sure they match<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Unit system mismatch %d v. %d"" % (self.unit_system, new_unit_system)<tab><tab><tab>)",if self . unit_system != new_unit_system :,133
1935,"def command(filenames, dirnames, fix):<tab>for filename in gather_files(dirnames, filenames):<tab><tab>visitor = process_file(filename)<tab><tab><IF-STMT><tab><tab><tab>print(""%s: %s"" % (filename, visitor.get_stats()))<tab><tab><tab>if fix:<tab><tab><tab><tab>print(""Fixing: %s"" % filename)<tab><tab><tab><tab>fix_file(filename)",if visitor . needs_fix ( ) :,100
1936,"def assign_attributes_to_variants(variant_attributes):<tab>for value in variant_attributes:<tab><tab>pk = value[""pk""]<tab><tab>defaults = value[""fields""]<tab><tab>defaults[""variant_id""] = defaults.pop(""variant"")<tab><tab>defaults[""assignment_id""] = defaults.pop(""assignment"")<tab><tab>assigned_values = defaults.pop(""values"")<tab><tab>assoc, created = AssignedVariantAttribute.objects.update_or_create(<tab><tab><tab>pk=pk, defaults=defaults<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assoc.values.set(AttributeValue.objects.filter(pk__in=assigned_values))",if created :,148
1937,"def _info(self, userlist):<tab>for strng in userlist:<tab><tab>group_matched = False<tab><tab>for env in self.base.comps.environments_by_pattern(strng):<tab><tab><tab>self.output.display_groups_in_environment(env)<tab><tab><tab>group_matched = True<tab><tab>for group in self.base.comps.groups_by_pattern(strng):<tab><tab><tab>self.output.display_pkgs_in_groups(group)<tab><tab><tab>group_matched = True<tab><tab><IF-STMT><tab><tab><tab>logger.error(_(""Warning: Group %s does not exist.""), strng)<tab>return 0, []",if not group_matched :,159
1938,"def parse_implements_interfaces(parser):<tab>types = []<tab>if parser.token.value == ""implements"":<tab><tab>advance(parser)<tab><tab>while True:<tab><tab><tab>types.append(parse_named_type(parser))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return types","if not peek ( parser , TokenKind . NAME ) :",81
1939,"def generate():<tab>for leaf in u.leaves:<tab><tab>if isinstance(leaf, Integer):<tab><tab><tab>val = leaf.get_int_value()<tab><tab><tab>if val in (0, 1):<tab><tab><tab><tab>yield val<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>elif isinstance(leaf, Symbol):<tab><tab><tab>if leaf == SymbolTrue:<tab><tab><tab><tab>yield 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield 0<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>else:<tab><tab><tab>raise _NoBoolVector",elif leaf == SymbolFalse :,138
1940,"def update_gstin(context):<tab>dirty = False<tab>for key, value in iteritems(frappe.form_dict):<tab><tab>if key != ""party"":<tab><tab><tab>address_name = frappe.get_value(""Address"", key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>address = frappe.get_doc(""Address"", address_name)<tab><tab><tab><tab>address.gstin = value.upper()<tab><tab><tab><tab>address.save(ignore_permissions=True)<tab><tab><tab><tab>dirty = True<tab>if dirty:<tab><tab>frappe.db.commit()<tab><tab>context.updated = True",if address_name :,151
1941,"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab><IF-STMT><tab><tab><tab>if not everythingIsUnicode(v):<tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>elif isinstance(i, _bytes):<tab><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, _bytes):<tab><tab><tab>return False<tab>return True","if isinstance ( v , dict ) and k != ""headers"" :",158
1942,"def check_graph(graph):  # pragma: no cover<tab>for c in graph:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""cannot have fuse"")<tab><tab>for inp in c.inputs:<tab><tab><tab>if isinstance(inp.op, Fuse):<tab><tab><tab><tab>raise RuntimeError(""cannot have fuse"")","if isinstance ( c . op , Fuse ) :",79
1943,"def __getattr__(self, key):<tab>try:<tab><tab>value = self.__parent.contents[key]<tab>except KeyError:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, _ModuleMarker):<tab><tab><tab><tab>return value.mod_ns<tab><tab><tab>else:<tab><tab><tab><tab>assert isinstance(value, _MultipleClassMarker)<tab><tab><tab><tab>return value.attempt_get(self.__parent.path, key)<tab>raise AttributeError(<tab><tab>""Module %r has no mapped classes ""<tab><tab>""registered under the name %r"" % (self.__parent.name, key)<tab>)",if value is not None :,154
1944,"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None):<tab>assert nw_id != self.nw_id_unknown<tab>ret = []<tab>for port in self.get_ports(dpid):<tab><tab>nw_id_ = port.network_id<tab><tab>if port.port_no == in_port:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>ret.append(port.port_no)<tab><tab>elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external:<tab><tab><tab>ret.append(port.port_no)<tab>return ret",if nw_id_ == nw_id :,167
1945,"def _parse(self, contents):<tab>entries = []<tab>for line in contents.splitlines():<tab><tab>if not len(line.strip()):<tab><tab><tab>entries.append((""blank"", [line]))<tab><tab><tab>continue<tab><tab>(head, tail) = chop_comment(line.strip(), ""#"")<tab><tab><IF-STMT><tab><tab><tab>entries.append((""all_comment"", [line]))<tab><tab><tab>continue<tab><tab>entries.append((""option"", [head.split(None), tail]))<tab>return entries",if not len ( head ) :,121
1946,"def _get_documented_completions(self, table, startswith=None):<tab>names = []<tab>for key, command in table.items():<tab><tab>if getattr(command, ""_UNDOCUMENTED"", False):<tab><tab><tab># Don't tab complete undocumented commands/params<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if getattr(command, ""positional_arg"", False):<tab><tab><tab>continue<tab><tab>names.append(key)<tab>return names",if startswith is not None and not key . startswith ( startswith ) :,118
1947,"def _convert_example(example, use_bfloat16):<tab>""""""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16.""""""<tab>for key in list(example.keys()):<tab><tab>val = example[key]<tab><tab><IF-STMT><tab><tab><tab>val = tf.sparse.to_dense(val)<tab><tab>if val.dtype == tf.int64:<tab><tab><tab>val = tf.cast(val, tf.int32)<tab><tab>if use_bfloat16 and val.dtype == tf.float32:<tab><tab><tab>val = tf.cast(val, tf.bfloat16)<tab><tab>example[key] = val",if tf . keras . backend . is_sparse ( val ) :,166
1948,"def _get_lang_zone(self, lang):<tab>if lang not in self._lang_zone_from_lang:<tab><tab><IF-STMT><tab><tab><tab>self._lang_zone_from_lang[lang] = MultiLangZone(self.mgr, lang)<tab><tab>else:<tab><tab><tab>self._lang_zone_from_lang[lang] = LangZone(self.mgr, lang)<tab>return self._lang_zone_from_lang[lang]",if self . mgr . is_multilang ( lang ) :,119
1949,"def dispatch(self, request, *args, **kwargs):<tab>try:<tab><tab>return super(Handler, self).dispatch(request, *args, **kwargs)<tab>except Http404 as e:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>request.original_path_info = request.path_info<tab><tab><tab><tab>request.path_info = settings.FEINCMS_CMS_404_PAGE<tab><tab><tab><tab>response = super(Handler, self).dispatch(request, *args, **kwargs)<tab><tab><tab><tab>response.status_code = 404<tab><tab><tab><tab>return response<tab><tab><tab>except Http404:<tab><tab><tab><tab>raise e<tab><tab>else:<tab><tab><tab>raise",if settings . FEINCMS_CMS_404_PAGE :,179
1950,"def _maybe_update_dropout(self, step):<tab>for i in range(len(self.dropout_steps)):<tab><tab><IF-STMT><tab><tab><tab>self.model.update_dropout(self.dropout[i])<tab><tab><tab>logger.info(""Updated dropout to %f from step %d"" % (self.dropout[i], step))",if step > 1 and step == self . dropout_steps [ i ] + 1 :,95
1951,"def bulk_move(*args, **kwargs):<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>raise PopupException(_(""Source path and destination path cannot be same""))<tab><tab>request.fs.rename(<tab><tab><tab>urllib.unquote(arg[""src_path""]), urllib.unquote(arg[""dest_path""])<tab><tab>)","if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :",90
1952,"def asisWrite(self, root):<tab>at, c = self, self.c<tab>try:<tab><tab>c.endEditing()<tab><tab>c.init_error_dialogs()<tab><tab>fileName = at.initWriteIvars(root, root.atAsisFileNodeName())<tab><tab><IF-STMT><tab><tab><tab>at.addToOrphanList(root)<tab><tab><tab>return<tab><tab>at.openOutputStream()<tab><tab>for p in root.self_and_subtree(copy=False):<tab><tab><tab>at.writeAsisNode(p)<tab><tab>contents = at.closeOutputStream()<tab><tab>at.replaceFile(contents, at.encoding, fileName, root)<tab>except Exception:<tab><tab>at.writeException(fileName, root)","if not at . precheck ( fileName , root ) :",187
1953,"def next_event(it):<tab>""""""read an event from an eventstream""""""<tab>while True:<tab><tab>try:<tab><tab><tab>line = next(it)<tab><tab>except StopIteration:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return json.loads(line.split("":"", 1)[1])","if line . startswith ( ""data:"" ) :",77
1954,"def process_formdata(self, valuelist):<tab>if valuelist:<tab><tab>if valuelist[0] == ""__None"":<tab><tab><tab>self.data = None<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.data = None<tab><tab><tab><tab>return<tab><tab><tab>try:<tab><tab><tab><tab>obj = self.queryset.get(pk=valuelist[0])<tab><tab><tab><tab>self.data = obj<tab><tab><tab>except DoesNotExist:<tab><tab><tab><tab>self.data = None",if self . queryset is None :,122
1955,"def _setResultsName(self, name, listAllMatches=False):<tab>if __diag__.warn_multiple_tokens_in_named_alternation:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""{}: setting results name {!r} on {} expression ""<tab><tab><tab><tab>""will return a list of all parsed tokens in an And alternative, ""<tab><tab><tab><tab>""in prior versions only the first token was returned"".format(<tab><tab><tab><tab><tab>""warn_multiple_tokens_in_named_alternation"",<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>type(self).__name__,<tab><tab><tab><tab>),<tab><tab><tab><tab>stacklevel=3,<tab><tab><tab>)<tab>return super()._setResultsName(name, listAllMatches)","if any ( isinstance ( e , And ) for e in self . exprs ) :",195
1956,"def add(request):<tab>form_type = ""servers""<tab>if request.method == ""POST"":<tab><tab>form = BookMarkForm(request.POST)<tab><tab>if form.is_valid():<tab><tab><tab>form_type = form.save()<tab><tab><tab>messages.add_message(request, messages.INFO, ""Bookmark created"")<tab><tab>else:<tab><tab><tab>messages.add_message(request, messages.INFO, form.errors)<tab><tab><IF-STMT><tab><tab><tab>url = reverse(""servers"")<tab><tab>else:<tab><tab><tab>url = reverse(""metrics"")<tab><tab>return redirect(url)<tab>else:<tab><tab>return redirect(reverse(""servers""))","if form_type == ""server"" :",164
1957,"def __init__(self, post_id, artist, page, tzInfo=None, dateFormat=None):<tab>self.imageUrls = list()<tab>self.imageResizedUrls = list()<tab>self.imageId = int(post_id)<tab>self._tzInfo = tzInfo<tab>self.dateFormat = dateFormat<tab>if page is not None:<tab><tab>post_json = demjson.decode(page)<tab><tab><IF-STMT><tab><tab><tab>artist_id = post_json[""data""][""item""][""user""][""id""]<tab><tab><tab>self.artist = SketchArtist(artist_id, page, tzInfo, dateFormat)<tab><tab>else:<tab><tab><tab>self.artist = artist<tab><tab>self.parse_post(post_json[""data""][""item""])",if artist is None :,182
1958,"def _create_batch_iterator(<tab>self,<tab>mark_as_delete: Callable[[Any], None],<tab>to_key: Callable[[Any], Any],<tab>to_value: Callable[[Any], Any],<tab>batch: Iterable[EventT],) -> Iterable[Tuple[Any, Any]]:<tab>for event in batch:<tab><tab>key = to_key(event.key)<tab><tab># to delete keys in the table we set the raw value to None<tab><tab><IF-STMT><tab><tab><tab>mark_as_delete(key)<tab><tab><tab>continue<tab><tab>yield key, to_value(event.value)",if event . message . value is None :,150
1959,"def test_lc_numeric_nl_langinfo(self):<tab># Test nl_langinfo against known values<tab>tested = False<tab>for loc in candidate_locales:<tab><tab>try:<tab><tab><tab>setlocale(LC_NUMERIC, loc)<tab><tab><tab>setlocale(LC_CTYPE, loc)<tab><tab>except Error:<tab><tab><tab>continue<tab><tab>for li, lc in ((RADIXCHAR, ""decimal_point""), (THOUSEP, ""thousands_sep"")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tested = True<tab>if not tested:<tab><tab>self.skipTest(""no suitable locales"")","if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :",163
1960,"def _level_up_logging(self):<tab>for handler in self.log.handlers:<tab><tab><IF-STMT><tab><tab><tab>if handler.level != logging.DEBUG:<tab><tab><tab><tab>handler.setLevel(logging.DEBUG)<tab><tab><tab><tab>self.log.debug(""Leveled up log file verbosity"")","if issubclass ( handler . __class__ , logging . FileHandler ) :",80
1961,def _show_axes_changed(self):<tab>marker = self.marker<tab>if (self._vtk_control is not None) and (marker is not None):<tab><tab><IF-STMT><tab><tab><tab>marker.interactor = None<tab><tab><tab>marker.enabled = False<tab><tab>else:<tab><tab><tab>marker.interactor = self.interactor<tab><tab><tab>marker.enabled = True<tab><tab>self.render(),if not self . show_axes :,103
1962,"def handle_keypress(self, rawKey, modifiers, key, *args):<tab>if self.recordKeyboard and self.__delayPassed():<tab><tab><IF-STMT><tab><tab><tab>self.insideKeys = True<tab><tab><tab>self.targetParent.start_key_sequence()<tab><tab>modifierCount = len(modifiers)<tab><tab>if (<tab><tab><tab>modifierCount > 1<tab><tab><tab>or (modifierCount == 1 and Key.SHIFT not in modifiers)<tab><tab><tab>or (Key.SHIFT in modifiers and len(rawKey) > 1)<tab><tab>):<tab><tab><tab>self.targetParent.append_hotkey(rawKey, modifiers)<tab><tab>elif key not in MODIFIERS:<tab><tab><tab>self.targetParent.append_key(key)",if not self . insideKeys :,178
1963,"def transform(self, data):<tab>with timer(""transform %s"" % self.name, logging.DEBUG):<tab><tab>if self.operator in {""lat"", ""latitude""}:<tab><tab><tab>return self.series(data).apply(GeoIP.get_latitude)<tab><tab><IF-STMT><tab><tab><tab>return self.series(data).apply(GeoIP.get_longitude)<tab><tab>elif self.operator in {""acc"", ""accuracy""}:<tab><tab><tab>return self.series(data).apply(GeoIP.get_accuracy)<tab><tab>raise NameError(""Unknown GeoIP operator [lat, lon, acc]: %s"" % self.operator)","elif self . operator in { ""lon"" , ""longitude"" } :",161
1964,"def _get_sidebar_selected(self):<tab>sidebar_selected = None<tab>if self.businessline_id:<tab><tab>sidebar_selected = ""bl_%s"" % self.businessline_id<tab><tab><IF-STMT><tab><tab><tab>sidebar_selected += ""_s_%s"" % self.service_id<tab><tab><tab>if self.environment_id:<tab><tab><tab><tab>sidebar_selected += ""_env_%s"" % self.environment_id<tab>return sidebar_selected",if self . service_id :,113
1965,"def _run_response_middleware(self, request, response, request_name=None):<tab>named_middleware = self.named_response_middleware.get(request_name, deque())<tab>applicable_middleware = self.response_middleware + named_middleware<tab>if applicable_middleware:<tab><tab>for middleware in applicable_middleware:<tab><tab><tab>_response = middleware(request, response)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_response = await _response<tab><tab><tab>if _response:<tab><tab><tab><tab>response = _response<tab><tab><tab><tab>break<tab>return response",if isawaitable ( _response ) :,136
1966,"def populate_obj(self, obj, name):<tab>field = getattr(obj, name, None)<tab>if field is not None:<tab><tab># If field should be deleted, clean it up<tab><tab>if self._should_delete:<tab><tab><tab>field.delete()<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>if not field.grid_id:<tab><tab><tab><tab>func = field.put<tab><tab><tab>else:<tab><tab><tab><tab>func = field.replace<tab><tab><tab>func(<tab><tab><tab><tab>self.data.stream,<tab><tab><tab><tab>filename=self.data.filename,<tab><tab><tab><tab>content_type=self.data.content_type,<tab><tab><tab>)","if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) :",182
1967,"def _import_hash(self, operator):<tab># Import required modules into local namespace so that pipelines<tab># may be evaluated directly<tab>for key in sorted(operator.import_hash.keys()):<tab><tab>module_list = "", "".join(sorted(operator.import_hash[key]))<tab><tab><IF-STMT><tab><tab><tab>exec(""from {} import {}"".format(key[4:], module_list))<tab><tab>else:<tab><tab><tab>exec(""from {} import {}"".format(key, module_list))<tab><tab>for var in operator.import_hash[key]:<tab><tab><tab>self.operators_context[var] = eval(var)","if key . startswith ( ""tpot."" ) :",152
1968,"def remove_files(folder, file_extensions):<tab>for f in os.listdir(folder):<tab><tab>f_path = os.path.join(folder, f)<tab><tab><IF-STMT><tab><tab><tab>extension = os.path.splitext(f_path)[1]<tab><tab><tab>if extension in file_extensions:<tab><tab><tab><tab>os.remove(f_path)",if os . path . isfile ( f_path ) :,96
1969,"def clearBuffer(self):<tab>if self.shouldLose == -1:<tab><tab>return<tab>if self.producer:<tab><tab>self.producer.resumeProducing()<tab>if self.buffer:<tab><tab><IF-STMT><tab><tab><tab>self.logFile.write(""loopback receiving %s\n"" % repr(self.buffer))<tab><tab>buffer = self.buffer<tab><tab>self.buffer = b""""<tab><tab>self.target.dataReceived(buffer)<tab>if self.shouldLose == 1:<tab><tab>self.shouldLose = -1<tab><tab>self.target.connectionLost(failure.Failure(main.CONNECTION_DONE))",if self . logFile :,156
1970,"def write(self, data):<tab>if mock_target._mirror_on_stderr:<tab><tab>if self._write_line:<tab><tab><tab>sys.stderr.write(fn + "": "")<tab><tab>if bytes:<tab><tab><tab>sys.stderr.write(data.decode(""utf8""))<tab><tab>else:<tab><tab><tab>sys.stderr.write(data)<tab><tab><IF-STMT><tab><tab><tab>self._write_line = True<tab><tab>else:<tab><tab><tab>self._write_line = False<tab>super(Buffer, self).write(data)","if ( data [ - 1 ] ) == ""\n"" :",137
1971,def stop(self):<tab>self.queue_com.state_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.queue_com.state = STOPPED<tab><tab><tab>self.remove()<tab><tab><tab>return True<tab><tab>return False<tab>finally:<tab><tab>self.queue_com.state_lock.release(),if self . queue_com . state == RUNNING and self . stop_task ( ) :,97
1972,"def _handle_special_args(self, pyobjects):<tab>if len(pyobjects) == len(self.arguments.args):<tab><tab>if self.arguments.vararg:<tab><tab><tab>pyobjects.append(rope.base.builtins.get_list())<tab><tab><IF-STMT><tab><tab><tab>pyobjects.append(rope.base.builtins.get_dict())",if self . arguments . kwarg :,91
1973,"def go_to_last_edit_location(self):<tab>if self.last_edit_cursor_pos is not None:<tab><tab>filename, position = self.last_edit_cursor_pos<tab><tab>if not osp.isfile(filename):<tab><tab><tab>self.last_edit_cursor_pos = None<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>self.load(filename)<tab><tab><tab>editor = self.get_current_editor()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>editor.set_cursor_position(position)",if position < editor . document ( ) . characterCount ( ) :,135
1974,"def _create_sentence_objects(self):<tab>""""""Returns a list of Sentence objects from the raw text.""""""<tab>sentence_objects = []<tab>sent_tokenizer = SentenceTokenizer(locale=self.language.code)<tab>seq = Sequence(self.raw)<tab>seq = sent_tokenizer.transform(seq)<tab>for start_index, end_index in zip(seq.idx[:-1], seq.idx[1:]):<tab><tab># Sentences share the same models as their parent blob<tab><tab>sent = seq.text[start_index:end_index].strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>s = Sentence(sent, start_index=start_index, end_index=end_index)<tab><tab>s.detected_languages = self.detected_languages<tab><tab>sentence_objects.append(s)<tab>return sentence_objects",if not sent :,196
1975,"def to_json_schema(self, parent=None):<tab>schema = {}<tab>if not parent:<tab><tab>schema[""title""] = self.title<tab><tab><IF-STMT><tab><tab><tab>schema[""description""] = self.description<tab><tab>if self.has_default:<tab><tab><tab>schema[""default""] = self.default<tab><tab>schema[""_required_""] = self.required<tab>if self.null:<tab><tab>schema[""type""] = [""string"", ""null""]<tab>else:<tab><tab>schema[""type""] = ""string""<tab>if self.enum is not None:<tab><tab>schema[""enum""] = self.enum<tab>return schema",if self . description :,150
1976,def rmdir(dirname):<tab>if dirname[-1] == os.sep:<tab><tab>dirname = dirname[:-1]<tab>if os.path.islink(dirname):<tab><tab>return  # do not clear link - we can get out of dir<tab>for f in os.listdir(dirname):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = dirname + os.sep + f<tab><tab>if os.path.isdir(path):<tab><tab><tab>rmdir(path)<tab><tab>else:<tab><tab><tab>os.unlink(path)<tab>os.rmdir(dirname),"if f in ( ""."" , "".."" ) :",137
1977,"def convert_whole_dir(path=Path(""marian_ckpt/"")):<tab>for subdir in tqdm(list(path.ls())):<tab><tab>dest_dir = f""marian_converted/{subdir.name}""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>convert(source_dir, dest_dir)","if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :",85
1978,"def colorformat(text):<tab>if text[0:1] == ""#"":<tab><tab>col = text[1:]<tab><tab>if len(col) == 6:<tab><tab><tab>return col<tab><tab><IF-STMT><tab><tab><tab>return col[0] * 2 + col[1] * 2 + col[2] * 2<tab>elif text == """":<tab><tab>return """"<tab>assert False, ""wrong color format %r"" % text",elif len ( col ) == 3 :,105
1979,"def _init_rel_seek(self):<tab>""Sets the file object's position to the relative location set above.""<tab>rs, fo = self._rel_seek, self._file_obj<tab>if rs == 0.0:<tab><tab>fo.seek(0, os.SEEK_SET)<tab>else:<tab><tab>fo.seek(0, os.SEEK_END)<tab><tab>size = fo.tell()<tab><tab><IF-STMT><tab><tab><tab>self._cur_pos = size<tab><tab>else:<tab><tab><tab>target = int(size * rs)<tab><tab><tab>fo.seek(target, os.SEEK_SET)<tab><tab><tab>self._align_to_newline()<tab><tab><tab>self._cur_pos = fo.tell()",if rs == 1.0 :,176
1980,"def parse_command_line(self, argv=None):<tab>""""""Parse the command line""""""<tab>if self.config:<tab><tab>parser = argparse.ArgumentParser(add_help=False)<tab><tab>self.settings[""config""].add_argument(parser)<tab><tab>opts, _ = parser.parse_known_args(argv)<tab><tab>if opts.config is not None:<tab><tab><tab>self.set(""config"", opts.config)<tab><tab>self.params.update(self.import_from_module())<tab>parser = self.parser()<tab>opts = parser.parse_args(argv)<tab>for k, v in opts.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.set(k.lower(), v)",if v is None :,177
1981,"def process(self, resources, event=None):<tab>client = local_session(self.manager.session_factory).client(<tab><tab>""shield"", region_name=""us-east-1""<tab>)<tab>protections = get_type_protections(client, self.manager.get_model())<tab>protected_resources = {p[""ResourceArn""] for p in protections}<tab>state = self.data.get(""state"", False)<tab>results = []<tab>for arn, r in zip(self.manager.get_arns(resources), resources):<tab><tab>r[""c7n:ShieldProtected""] = shielded = arn in protected_resources<tab><tab><IF-STMT><tab><tab><tab>results.append(r)<tab><tab>elif not shielded and not state:<tab><tab><tab>results.append(r)<tab>return results",if shielded and state :,199
1982,"def removeTrailingWs(self, aList):<tab>i = 0<tab>while i < len(aList):<tab><tab><IF-STMT><tab><tab><tab>j = i<tab><tab><tab>i = self.skip_ws(aList, i)<tab><tab><tab>assert j < i<tab><tab><tab>if i >= len(aList) or aList[i] == ""\n"":<tab><tab><tab><tab># print ""removing trailing ws:"", `i-j`<tab><tab><tab><tab>del aList[j:i]<tab><tab><tab><tab>i = j<tab><tab>else:<tab><tab><tab>i += 1",if self . is_ws ( aList [ i ] ) :,147
1983,"def predict(request: Request):<tab>form = await request.form()<tab>files, entry = convert_input(form)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return JSONResponse(ALL_FEATURES_PRESENT_ERROR, status_code=400)<tab><tab>try:<tab><tab><tab>resp = model.predict(data_dict=[entry]).to_dict(""records"")[0]<tab><tab><tab>return JSONResponse(resp)<tab><tab>except Exception as e:<tab><tab><tab>logger.error(""Error: {}"".format(str(e)))<tab><tab><tab>return JSONResponse(COULD_NOT_RUN_INFERENCE_ERROR, status_code=500)<tab>finally:<tab><tab>for f in files:<tab><tab><tab>os.remove(f.name)",if ( entry . keys ( ) & input_features ) != input_features :,192
1984,"def reset(self):<tab>logger.debug(""Arctic.reset()"")<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self.__conn.close()<tab><tab><tab>self.__conn = None<tab><tab>for _, l in self._library_cache.items():<tab><tab><tab>if hasattr(l, ""_reset"") and callable(l._reset):<tab><tab><tab><tab>logger.debug(""Library reset() %s"" % l)<tab><tab><tab><tab>l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",if self . __conn is not None :,137
1985,"def read(self):<tab>if op.isfile(self.fileName):<tab><tab>with textfile_open(self.fileName, ""rt"") as fid:<tab><tab><tab>items = json.load(fid)<tab><tab><tab># TODO: catch JSON exception...<tab><tab><tab><IF-STMT><tab><tab><tab><tab>items = dict()<tab>else:<tab><tab>items = dict()<tab>self._items.clear()<tab>self._items.update(items)<tab>self._haveReadData = True",if items is None :,115
1986,"def get_django_comment(text: str, i: int) -> str:<tab>end = i + 4<tab>unclosed_end = 0<tab>while end <= len(text):<tab><tab>if text[end - 2 : end] == ""#}"":<tab><tab><tab>return text[i:end]<tab><tab><IF-STMT><tab><tab><tab>unclosed_end = end<tab><tab>end += 1<tab>raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])","if not unclosed_end and text [ end ] == ""<"" :",126
1987,"def _wrap_forwarded(self, key, value):<tab>if isinstance(value, SourceCode) and value.late_binding:<tab><tab># get cached return value if present<tab><tab>value_ = self._late_binding_returnvalues.get(key, KeyError)<tab><tab><IF-STMT><tab><tab><tab># evaluate the late-bound function<tab><tab><tab>value_ = self._eval_late_binding(value)<tab><tab><tab>schema = self.late_bind_schemas.get(key)<tab><tab><tab>if schema is not None:<tab><tab><tab><tab>value_ = schema.validate(value_)<tab><tab><tab># cache result of late bound func<tab><tab><tab>self._late_binding_returnvalues[key] = value_<tab><tab>return value_<tab>else:<tab><tab>return value",if value_ is KeyError :,187
1988,"def connect(*args, **ckwargs):<tab>if ""give_content_type"" in kwargs:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""give_content_type""](args[6][""content-type""])<tab><tab>else:<tab><tab><tab>kwargs[""give_content_type""]("""")<tab>if ""give_connect"" in kwargs:<tab><tab>kwargs[""give_connect""](*args, **ckwargs)<tab>status = code_iter.next()<tab>etag = etag_iter.next()<tab>timestamp = timestamps_iter.next()<tab>if status == -1:<tab><tab>raise HTTPException()<tab>return FakeConn(status, etag, body=kwargs.get(""body"", """"), timestamp=timestamp)","if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :",178
1989,"def _reset(self):<tab>self._handle_connect()<tab>if self.rewarder_session:<tab><tab><IF-STMT><tab><tab><tab>env_id = random.choice(self._sample_env_ids)<tab><tab><tab>logger.info(""Randomly sampled env_id={}"".format(env_id))<tab><tab>else:<tab><tab><tab>env_id = None<tab><tab>self.rewarder_session.reset(env_id=env_id)<tab>else:<tab><tab>logger.info(<tab><tab><tab>""No rewarder session exists, so cannot send a reset via the rewarder channel""<tab><tab>)<tab>self._reset_mask()<tab>return [None] * self.n",if self . _sample_env_ids :,171
1990,"def _create_architecture_list(architectures, current_arch):<tab>if not architectures:<tab><tab>return [_Architecture(build_on=[current_arch])]<tab>build_architectures: List[str] = []<tab>architecture_list: List[_Architecture] = []<tab>for item in architectures:<tab><tab>if isinstance(item, str):<tab><tab><tab>build_architectures.append(item)<tab><tab><IF-STMT><tab><tab><tab>architecture_list.append(<tab><tab><tab><tab>_Architecture(build_on=item.get(""build-on""), run_on=item.get(""run-on""))<tab><tab><tab>)<tab>if build_architectures:<tab><tab>architecture_list.append(_Architecture(build_on=build_architectures))<tab>return architecture_list","if isinstance ( item , dict ) :",196
1991,"def inspect(self, pokemon):<tab># Make sure it was not caught!<tab>for caught_pokemon in self.cache:<tab><tab>same_latitude = ""{0:.4f}"".format(pokemon[""latitude""]) == ""{0:.4f}"".format(<tab><tab><tab>caught_pokemon[""latitude""]<tab><tab>)<tab><tab>same_longitude = ""{0:.4f}"".format(pokemon[""longitude""]) == ""{0:.4f}"".format(<tab><tab><tab>caught_pokemon[""longitude""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return<tab>if len(self.cache) >= 200:<tab><tab>self.cache.pop(0)<tab>self.cache.append(pokemon)",if same_latitude and same_longitude :,185
1992,"def parley(self):<tab>for x in [0, 1]:<tab><tab>a = self.agents[x].act()<tab><tab><IF-STMT><tab><tab><tab>if ""[DONE]"" in a[""text""]:<tab><tab><tab><tab>self.agents[x - 1].observe(<tab><tab><tab><tab><tab>{""id"": ""World"", ""text"": ""The other agent has ended the chat.""}<tab><tab><tab><tab>)<tab><tab><tab><tab>self.episodeDone = True<tab><tab><tab>else:<tab><tab><tab><tab>self.agents[x - 1].observe(a)",if a is not None :,134
1993,"def _prepare_subset(<tab>full_data: torch.Tensor,<tab>full_targets: torch.Tensor,<tab>num_samples: int,<tab>digits: Sequence,):<tab>classes = {d: 0 for d in digits}<tab>indexes = []<tab>for idx, target in enumerate(full_targets):<tab><tab>label = target.item()<tab><tab>if classes.get(label, float(""inf"")) >= num_samples:<tab><tab><tab>continue<tab><tab>indexes.append(idx)<tab><tab>classes[label] += 1<tab><tab><IF-STMT><tab><tab><tab>break<tab>data = full_data[indexes]<tab>targets = full_targets[indexes]<tab>return data, targets",if all ( classes [ k ] >= num_samples for k in classes ) :,174
1994,"def get_work_root(self, flags):<tab>_flags = flags.copy()<tab>_flags[""is_toplevel""] = True<tab>target = self._get_target(_flags)<tab>if target:<tab><tab>_flags[""target""] = target.name<tab><tab>tool = self.get_tool(_flags)<tab><tab><IF-STMT><tab><tab><tab>return target.name + ""-"" + tool<tab><tab>else:<tab><tab><tab>raise SyntaxError(<tab><tab><tab><tab>""Failed to determine work root. Could not resolve tool for target ""<tab><tab><tab><tab>+ target.name<tab><tab><tab>)<tab>else:<tab><tab>raise SyntaxError(""Failed to determine work root. Could not resolve target"")",if tool :,158
1995,"def run_command(self, data):<tab>""""""Run editor commands.""""""<tab>parts = data.split("" "")<tab>cmd = parts[0].lower()<tab>if cmd in self.operations.keys():<tab><tab>return self.run_operation(cmd)<tab>args = "" "".join(parts[1:])<tab>self.logger.debug(""Looking for command '{0}'"".format(cmd))<tab>if cmd in self.modules.modules.keys():<tab><tab>self.logger.debug(""Trying to run command '{0}'"".format(cmd))<tab><tab>self.get_editor().store_action_state(cmd)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>else:<tab><tab>self.set_status(""Command '{0}' not found."".format(cmd))<tab><tab>return False<tab>return True","if not self . run_module ( cmd , args ) :",193
1996,"def get_main_chain_layers(self):<tab>""""""Return a list of layer IDs in the main chain.""""""<tab>main_chain = self.get_main_chain()<tab>ret = []<tab>for u in main_chain:<tab><tab>for v, layer_id in self.adj_list[u]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(layer_id)<tab>return ret",if v in main_chain and u in main_chain :,106
1997,"def hash(self, context):<tab>with context:<tab><tab><IF-STMT><tab><tab><tab>return IECore.MurmurHash()<tab><tab>h = GafferDispatch.TaskNode.hash(self, context)<tab><tab>h.append(self[""fileName""].hash())<tab><tab>h.append(self[""in""].hash())<tab><tab>h.append(self.__parameterHandler.hash())<tab><tab>return h","if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :",116
1998,"def consume_buf():<tab>ty = state[""ty""] - 1<tab>for i in xrange(state[""buf""].shape[1] // N):<tab><tab>tx = x // N + i<tab><tab>src = state[""buf""][:, i * N : (i + 1) * N, :]<tab><tab><IF-STMT><tab><tab><tab>with self.tile_request(tx, ty, readonly=False) as dst:<tab><tab><tab><tab>mypaintlib.tile_convert_rgba8_to_rgba16(src, dst, self.EOTF)<tab>if state[""progress""]:<tab><tab>try:<tab><tab><tab>state[""progress""].completed(ty - ty0)<tab><tab>except Exception:<tab><tab><tab>logger.exception(""Progress.completed() failed"")<tab><tab><tab>state[""progress""] = None","if src [ : , : , 3 ] . any ( ) :",188
1999,"def check_permissions(self, obj):<tab>request = self.context.get(""request"")<tab>for Perm in permissions:<tab><tab>perm = Perm()<tab><tab>if not perm.has_permission(request, self):<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True","if not perm . has_object_permission ( request , self , obj ) :",88
2000,"def _post_order(op):<tab>if isinstance(op, tvm.tir.Allocate):<tab><tab>lift_stmt[-1].append(op)<tab><tab>return op.body<tab>if isinstance(op, tvm.tir.AttrStmt):<tab><tab>if op.attr_key == ""storage_scope"":<tab><tab><tab>lift_stmt[-1].append(op)<tab><tab><tab>return op.body<tab><tab><IF-STMT><tab><tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab><tab>return op<tab>if isinstance(op, tvm.tir.For):<tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab>raise RuntimeError(""not reached"")","if op . attr_key == ""virtual_thread"" :",188
2001,"def task_done(self):<tab>with self._cond:<tab><tab>if not self._unfinished_tasks.acquire(False):<tab><tab><tab>raise ValueError(""task_done() called too many times"")<tab><tab><IF-STMT><tab><tab><tab>self._cond.notify_all()",if self . _unfinished_tasks . _semlock . _is_zero ( ) :,75
2002,"def get_json(self):<tab>if not hasattr(self, ""_json""):<tab><tab>self._json = None<tab><tab><IF-STMT><tab><tab><tab>self._json = json.loads(self.request.body)<tab>return self._json","if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :",74
2003,"def userfullname():<tab>""""""Get the user's full name.""""""<tab>global _userfullname<tab><IF-STMT><tab><tab>uid = os.getuid()<tab><tab>entry = pwd_from_uid(uid)<tab><tab>if entry:<tab><tab><tab>_userfullname = entry[4].split("","")[0] or entry[0]<tab><tab>if not _userfullname:<tab><tab><tab>_userfullname = ""user%d"" % uid<tab>return _userfullname",if not _userfullname :,108
2004,"def test_scatter(self):<tab>for rank in range(self.world_size):<tab><tab>tensor = []<tab><tab><IF-STMT><tab><tab><tab>tensor = [torch.tensor(i) for i in range(self.world_size)]<tab><tab>result = comm.get().scatter(tensor, rank, size=())<tab><tab>self.assertTrue(torch.is_tensor(result))<tab><tab>self.assertEqual(result.item(), self.rank)",if self . rank == rank :,109
2005,"def decompile(decompiler):<tab>for pos, next_pos, opname, arg in decompiler.instructions:<tab><tab>if pos in decompiler.targets:<tab><tab><tab>decompiler.process_target(pos)<tab><tab>method = getattr(decompiler, opname, None)<tab><tab>if method is None:<tab><tab><tab>throw(DecompileError(""Unsupported operation: %s"" % opname))<tab><tab>decompiler.pos = pos<tab><tab>decompiler.next_pos = next_pos<tab><tab>x = method(*arg)<tab><tab><IF-STMT><tab><tab><tab>decompiler.stack.append(x)",if x is not None :,143
2006,"def print_scenario_ran(self, scenario):<tab>if scenario.passed:<tab><tab>self.wrt(""OK"")<tab>elif scenario.failed:<tab><tab>reason = self.scenarios_and_its_fails[scenario]<tab><tab><IF-STMT><tab><tab><tab>self.wrt(""FAILED"")<tab><tab>else:<tab><tab><tab>self.wrt(""ERROR"")<tab>self.wrt(""\n"")","if isinstance ( reason . exception , AssertionError ) :",102
2007,"def detect_ssl_option(self):<tab>for option in self.ssl_options():<tab><tab>if scan_argv(self.argv, option) is not None:<tab><tab><tab>for other_option in self.ssl_options():<tab><tab><tab><tab>if option != other_option:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>raise ConfigurationError(<tab><tab><tab><tab><tab><tab><tab>""Cannot give both %s and %s"" % (option, other_option)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab>return option","if scan_argv ( self . argv , other_option ) is not None :",140
2008,"def print_po_snippet(en_loc_old_lists, context):<tab>for m, localized, old in zip(*en_loc_old_lists):<tab><tab>if m == """":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>localized = old<tab><tab>print(<tab><tab><tab>""#: {file}:{line}\n""<tab><tab><tab>'msgid ""{context}{en_month}""\n'<tab><tab><tab>'msgstr ""{localized_month}""\n'.format(<tab><tab><tab><tab>context=context,<tab><tab><tab><tab>file=filename,<tab><tab><tab><tab>line=print_po_snippet.line,<tab><tab><tab><tab>en_month=m,<tab><tab><tab><tab>localized_month=localized,<tab><tab><tab>)<tab><tab>)<tab><tab>print_po_snippet.line += 1",if m == localized :,190
2009,"def set_status(self, dict_new):<tab>for i, value in dict_new.items():<tab><tab>self.dict_bili[i] = value<tab><tab><IF-STMT><tab><tab><tab>self.dict_bili[""pcheaders""][""cookie""] = value<tab><tab><tab>self.dict_bili[""appheaders""][""cookie""] = value","if i == ""cookie"" :",85
2010,"def makeSomeFiles(pathobj, dirdict):<tab>pathdict = {}<tab>for (key, value) in dirdict.items():<tab><tab>child = pathobj.child(key)<tab><tab><IF-STMT><tab><tab><tab>pathdict[key] = child<tab><tab><tab>child.setContent(value)<tab><tab>elif isinstance(value, dict):<tab><tab><tab>child.createDirectory()<tab><tab><tab>pathdict[key] = makeSomeFiles(child, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""only strings and dicts allowed as values"")<tab>return pathdict","if isinstance ( value , bytes ) :",138
2011,"def _truncate_to_length(generator, len_map=None):<tab>for example in generator:<tab><tab>example = list(example)<tab><tab>if len_map is not None:<tab><tab><tab>for key, max_len in len_map.items():<tab><tab><tab><tab>example_len = example[key].shape<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>example[key] = np.resize(example[key], max_len)<tab><tab>yield tuple(example)",if example_len > max_len :,120
2012,"def check(self, **kw):<tab>if not kw:<tab><tab>return exists(self.strpath)<tab>if len(kw) == 1:<tab><tab>if ""dir"" in kw:<tab><tab><tab>return not kw[""dir""] ^ isdir(self.strpath)<tab><tab><IF-STMT><tab><tab><tab>return not kw[""file""] ^ isfile(self.strpath)<tab>return super(LocalPath, self).check(**kw)","if ""file"" in kw :",106
2013,"def next_instruction_is_function_or_class(lines):<tab>""""""Is the first non-empty, non-commented line of the cell either a function or a class?""""""<tab>parser = StringParser(""python"")<tab>for i, line in enumerate(lines):<tab><tab>if parser.is_quoted():<tab><tab><tab>parser.read_line(line)<tab><tab><tab>continue<tab><tab>parser.read_line(line)<tab><tab>if not line.strip():  # empty line<tab><tab><tab>if i > 0 and not lines[i - 1].strip():<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>if line.startswith(""def "") or line.startswith(""class ""):<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>return False<tab>return False","if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :",194
2014,"def askCheckReadFile(self, localFile, remoteFile):<tab>if not kb.bruteMode:<tab><tab>message = ""do you want confirmation that the remote file '%s' "" % remoteFile<tab><tab>message += ""has been successfully downloaded from the back-end ""<tab><tab>message += ""DBMS file system? [Y/n] ""<tab><tab><IF-STMT><tab><tab><tab>return self._checkFileLength(localFile, remoteFile, True)<tab>return None","if readInput ( message , default = ""Y"" , boolean = True ) :",118
2015,"def process_tag(hive_name, company, company_key, tag, default_arch):<tab>with winreg.OpenKeyEx(company_key, tag) as tag_key:<tab><tab>version = load_version_data(hive_name, company, tag, tag_key)<tab><tab>if version is not None:  # if failed to get version bail<tab><tab><tab>major, minor, _ = version<tab><tab><tab>arch = load_arch_data(hive_name, company, tag, tag_key, default_arch)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>exe_data = load_exe(hive_name, company, company_key, tag)<tab><tab><tab><tab>if exe_data is not None:<tab><tab><tab><tab><tab>exe, args = exe_data<tab><tab><tab><tab><tab>return company, major, minor, arch, exe, args",if arch is not None :,199
2016,"def _get_matching_bracket(self, s, pos):<tab>if s[pos] != ""{"":<tab><tab>return None<tab>end = len(s)<tab>depth = 1<tab>pos += 1<tab>while pos != end:<tab><tab>c = s[pos]<tab><tab>if c == ""{"":<tab><tab><tab>depth += 1<tab><tab><IF-STMT><tab><tab><tab>depth -= 1<tab><tab>if depth == 0:<tab><tab><tab>break<tab><tab>pos += 1<tab>if pos < end and s[pos] == ""}"":<tab><tab>return pos<tab>return None","elif c == ""}"" :",132
2017,"def pred(field, value, item):<tab>for suffix, p in _BUILTIN_PREDS.iteritems():<tab><tab>if field.endswith(suffix):<tab><tab><tab>f = field[: field.index(suffix)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>return p(getattr(item, f), value)<tab>if not hasattr(item, field) or getattr(item, field) is None:<tab><tab>return False<tab>if isinstance(value, type(lambda x: x)):<tab><tab>return value(getattr(item, field))<tab>return getattr(item, field) == value","if not hasattr ( item , f ) or getattr ( item , f ) is None :",155
2018,"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for _, m in self.multi_deconv_layers.named_modules():<tab><tab>if isinstance(m, nn.ConvTranspose2d):<tab><tab><tab>normal_init(m, std=0.001)<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>constant_init(m, 1)<tab>for m in self.multi_final_layers.modules():<tab><tab><IF-STMT><tab><tab><tab>normal_init(m, std=0.001, bias=0)","if isinstance ( m , nn . Conv2d ) :",139
2019,"def test_byteswap(self):<tab>if self.typecode == ""u"":<tab><tab>example = ""\U00100100""<tab>else:<tab><tab>example = self.example<tab>a = array.array(self.typecode, example)<tab>self.assertRaises(TypeError, a.byteswap, 42)<tab>if a.itemsize in (1, 2, 4, 8):<tab><tab>b = array.array(self.typecode, example)<tab><tab>b.byteswap()<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(a, b)<tab><tab>else:<tab><tab><tab>self.assertNotEqual(a, b)<tab><tab>b.byteswap()<tab><tab>self.assertEqual(a, b)",if a . itemsize == 1 :,171
2020,"def _remove_blocks_from_variables(variables):<tab>new_variables = []<tab>for name, variable in variables:<tab><tab><IF-STMT><tab><tab><tab>new_variables.extend(variable.locals)<tab><tab><tab>new_variables.append((name, variable.result))<tab><tab>else:<tab><tab><tab>new_variables.append((name, variable))<tab>return new_variables",if variable . is_block ( ) :,94
2021,def scope(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.scope_ is None:<tab><tab><tab><tab>self.scope_ = Scope()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.scope_,if self . scope_ is None :,84
2022,"def translate():<tab>assert Lex.next() is AttributeList<tab>reader.read()  # Discard attribute list from reader.<tab>attrs = {}<tab>d = AttributeList.match.groupdict()<tab>for k, v in d.items():<tab><tab>if v is not None:<tab><tab><tab>if k == ""attrlist"":<tab><tab><tab><tab>v = subs_attrs(v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>parse_attributes(v, attrs)<tab><tab><tab>else:<tab><tab><tab><tab>AttributeList.attrs[k] = v<tab>AttributeList.subs(attrs)<tab>AttributeList.attrs.update(attrs)",if v :,150
2023,"def parse(self, response):<tab>try:<tab><tab>content = response.content.decode(""utf-8"", ""ignore"")<tab><tab>content = json.loads(content, strict=False)<tab>except:<tab><tab>self.logger.error(""Fail to parse the response in json format"")<tab><tab>return<tab>for item in content[""data""]:<tab><tab><IF-STMT><tab><tab><tab>img_url = self._decode_url(item[""objURL""])<tab><tab>elif ""hoverURL"" in item:<tab><tab><tab>img_url = item[""hoverURL""]<tab><tab>else:<tab><tab><tab>continue<tab><tab>yield dict(file_url=img_url)","if ""objURL"" in item :",158
2024,"def canonicalize_instruction_name(instr):<tab>name = instr.insn_name().upper()<tab># XXX bypass a capstone bug that incorrectly labels some insns as mov<tab>if name == ""MOV"":<tab><tab>if instr.mnemonic.startswith(""lsr""):<tab><tab><tab>return ""LSR""<tab><tab>elif instr.mnemonic.startswith(""lsl""):<tab><tab><tab>return ""LSL""<tab><tab><IF-STMT><tab><tab><tab>return ""ASR""<tab>return OP_NAME_MAP.get(name, name)","elif instr . mnemonic . startswith ( ""asr"" ) :",135
2025,"def _clean_regions(items, region):<tab>""""""Intersect region with target file if it exists""""""<tab>variant_regions = bedutils.population_variant_regions(items, merged=True)<tab>with utils.tmpfile() as tx_out_file:<tab><tab>target = subset_variant_regions(variant_regions, region, tx_out_file, items)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(target, six.string_types) and os.path.isfile(target):<tab><tab><tab><tab>target = _load_regions(target)<tab><tab><tab>else:<tab><tab><tab><tab>target = [target]<tab><tab><tab>return target",if target :,151
2026,def reader_leaves(self):<tab>self.mutex.acquire()<tab>try:<tab><tab>self.active_readers -= 1<tab><tab><IF-STMT><tab><tab><tab>self.active_writers += 1<tab><tab><tab>self.waiting_writers -= 1<tab><tab><tab>self.can_write.release()<tab>finally:<tab><tab>self.mutex.release(),if self . active_readers == 0 and self . waiting_writers != 0 :,101
2027,"def _bpe_to_words(sentence, delimiter=""@@""):<tab>""""""Convert a sequence of bpe words into sentence.""""""<tab>words = []<tab>word = """"<tab>delimiter_len = len(delimiter)<tab>for subwords in sentence:<tab><tab><IF-STMT><tab><tab><tab>word += subwords[:-delimiter_len]<tab><tab>else:<tab><tab><tab>word += subwords<tab><tab><tab>words.append(word)<tab><tab><tab>word = """"<tab>return words",if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,121
2028,"def _make_var_names(exog):<tab>if hasattr(exog, ""name""):<tab><tab>var_names = exog.name<tab>elif hasattr(exog, ""columns""):<tab><tab>var_names = exog.columns<tab>else:<tab><tab>raise ValueError(""exog is not a Series or DataFrame or is unnamed."")<tab>try:<tab><tab>var_names = "" "".join(var_names)<tab>except TypeError:  # cannot have names that are numbers, pandas default<tab><tab>from statsmodels.base.data import _make_exog_names<tab><tab><IF-STMT><tab><tab><tab>var_names = ""x1""<tab><tab>else:<tab><tab><tab>var_names = "" "".join(_make_exog_names(exog))<tab>return var_names",if exog . ndim == 1 :,177
2029,"def __start_element_handler(self, name, attrs):<tab>if name == ""mime-type"":<tab><tab><IF-STMT><tab><tab><tab>for extension in self.extensions:<tab><tab><tab><tab>self[extension] = self.type<tab><tab>self.type = attrs[""type""].lower()<tab><tab>self.extensions = []<tab>elif name == ""glob"":<tab><tab>pattern = attrs[""pattern""]<tab><tab>if pattern.startswith(""*.""):<tab><tab><tab>self.extensions.append(pattern[1:].lower())",if self . type :,120
2030,"def nodes(self, id=None, name=None):<tab>for node_dict in self.node_ls(id=id, name=name):<tab><tab>node_id = node_dict[""ID""]<tab><tab>node = DockerNode(self, node_id, inspect=node_dict)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield node",if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,101
2031,"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab>if type(e) is Argument or type(e) is Option and e.argcount:<tab><tab><tab><tab>if e.value is None:<tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab>elif type(e.value) is not list:<tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>e.value = 0<tab>return self",if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 :,190
2032,"def vi_search(self, rng):<tab>for i in rng:<tab><tab>line_history = self._history.history[i]<tab><tab>pos = line_history.get_line_text().find(self._vi_search_text)<tab><tab><IF-STMT><tab><tab><tab>self._history.history_cursor = i<tab><tab><tab>self.l_buffer.line_buffer = list(line_history.line_buffer)<tab><tab><tab>self.l_buffer.point = pos<tab><tab><tab>self.vi_undo_restart()<tab><tab><tab>return True<tab>self._bell()<tab>return False",if pos >= 0 :,144
2033,"def visitIf(self, node, scope):<tab>for test, body in node.tests:<tab><tab><IF-STMT><tab><tab><tab>if type(test.value) in self._const_types:<tab><tab><tab><tab>if not test.value:<tab><tab><tab><tab><tab>continue<tab><tab>self.visit(test, scope)<tab><tab>self.visit(body, scope)<tab>if node.else_:<tab><tab>self.visit(node.else_, scope)","if isinstance ( test , ast . Const ) :",112
2034,"def collect(self):<tab>for nickname in self.squid_hosts.keys():<tab><tab>squid_host = self.squid_hosts[nickname]<tab><tab>fulldata = self._getData(squid_host[""host""], squid_host[""port""])<tab><tab><IF-STMT><tab><tab><tab>fulldata = fulldata.splitlines()<tab><tab><tab>for data in fulldata:<tab><tab><tab><tab>matches = self.stat_pattern.match(data)<tab><tab><tab><tab>if matches:<tab><tab><tab><tab><tab>self.publish_counter(<tab><tab><tab><tab><tab><tab>""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2))<tab><tab><tab><tab><tab>)",if fulldata is not None :,166
2035,"def convert(x, base, exponents):<tab>out = []<tab>for e in exponents:<tab><tab>d = int(x / (base ** e))<tab><tab>x -= d * (base ** e)<tab><tab>out.append(digits[d])<tab><tab><IF-STMT><tab><tab><tab>break<tab>return out",if x == 0 and e < 0 :,80
2036,"def print_doc(manager, options):<tab>plugin_name = options.doc<tab>plugin = plugins.get(plugin_name, None)<tab>if plugin:<tab><tab><IF-STMT><tab><tab><tab>console(""Plugin %s does not have documentation"" % plugin_name)<tab><tab>else:<tab><tab><tab>console("""")<tab><tab><tab>console(trim(plugin.instance.__doc__))<tab><tab><tab>console("""")<tab>else:<tab><tab>console(""Could not find plugin %s"" % plugin_name)",if not plugin . instance . __doc__ :,120
2037,"def _set_attrs(self, attrs):<tab>for attr in self.ATTRS:<tab><tab>if attr in attrs:<tab><tab><tab>setattr(self, attr, attrs[attr])<tab><tab><tab>del attrs[attr]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(self, attr, NO_DEFAULT)<tab><tab><tab>else:<tab><tab><tab><tab>setattr(self, attr, None)<tab>if attrs:<tab><tab>attrs = sorted(attrs.keys())<tab><tab>raise OptionError(""invalid keyword arguments: %s"" % "", "".join(attrs), self)","if attr == ""default"" :",139
2038,"def _get_set_scope(<tab>ir_set: irast.Set, scope_tree: irast.ScopeTreeNode) -> irast.ScopeTreeNode:<tab>if ir_set.path_scope_id:<tab><tab>new_scope = scope_tree.root.find_by_unique_id(ir_set.path_scope_id)<tab><tab><IF-STMT><tab><tab><tab>raise errors.InternalServerError(<tab><tab><tab><tab>f""dangling scope pointer to node with uid""<tab><tab><tab><tab>f"":{ir_set.path_scope_id} in {ir_set!r}""<tab><tab><tab>)<tab>else:<tab><tab>new_scope = scope_tree<tab>return new_scope",if new_scope is None :,172
2039,"def test_leave_one_out(self):<tab>correct = 0<tab>k = 3<tab>model = kNN.train(xs, ys, k)<tab>predictions = [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1]<tab>for i in range(len(predictions)):<tab><tab>model = kNN.train(xs[:i] + xs[i + 1 :], ys[:i] + ys[i + 1 :], k)<tab><tab>prediction = kNN.classify(model, xs[i])<tab><tab>self.assertEqual(prediction, predictions[i])<tab><tab><IF-STMT><tab><tab><tab>correct += 1<tab>self.assertEqual(correct, 13)",if prediction == ys [ i ] :,177
2040,"def import_files(self, files):<tab>""""""Import a list of MORE (.csv) files.""""""<tab>c = self.c<tab>if files:<tab><tab>changed = False<tab><tab>self.tab_width = c.getTabWidth(c.p)<tab><tab>for fileName in files:<tab><tab><tab>g.setGlobalOpenDir(fileName)<tab><tab><tab>p = self.import_file(fileName)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p.contract()<tab><tab><tab><tab>p.setDirty()<tab><tab><tab><tab>c.setChanged(True)<tab><tab><tab><tab>changed = True<tab><tab>if changed:<tab><tab><tab>c.redraw(p)",if p :,160
2041,"def getPageTemplate(payload, place):<tab>retVal = (kb.originalPage, kb.errorIsNone)<tab>if payload and place:<tab><tab><IF-STMT><tab><tab><tab>page, _, _ = Request.queryPage(payload, place, content=True, raise404=False)<tab><tab><tab>kb.pageTemplates[(payload, place)] = (page, kb.lastParserStatus is None)<tab><tab>retVal = kb.pageTemplates[(payload, place)]<tab>return retVal","if ( payload , place ) not in kb . pageTemplates :",125
2042,"def _skip_trivial(constraint_data):<tab>if skip_trivial_constraints:<tab><tab>if isinstance(constraint_data, LinearCanonicalRepn):<tab><tab><tab>if constraint_data.variables is None:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if constraint_data . body . polynomial_degree ( ) == 0 :,90
2043,"def get_unique_attribute(self, name: str):<tab>feat = None<tab>for f in self.features:<tab><tab>if self._return_feature(f) and hasattr(f, name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise RuntimeError(""The attribute was not unique."")<tab><tab><tab>feat = f<tab>if feat is None:<tab><tab>raise RuntimeError(""The attribute did not exist"")<tab>return getattr(feat, name)",if feat is not None :,106
2044,"def hideEvent(self, event):<tab>""""""Reimplement Qt method""""""<tab>if not self.light:<tab><tab>for plugin in self.widgetlist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>plugin.visibility_changed(True)<tab>QMainWindow.hideEvent(self, event)",if plugin . isAncestorOf ( self . last_focused_widget ) :,87
2045,"def move_stdout_to_stderr(self):<tab>to_remove = []<tab>to_add = []<tab>for consumer_level, consumer in self.consumers:<tab><tab><IF-STMT><tab><tab><tab>to_remove.append((consumer_level, consumer))<tab><tab><tab>to_add.append((consumer_level, sys.stderr))<tab>for item in to_remove:<tab><tab>self.consumers.remove(item)<tab>self.consumers.extend(to_add)",if consumer == sys . stdout :,124
2046,"def create(exported_python_target):<tab>if exported_python_target not in created:<tab><tab>self.context.log.info(<tab><tab><tab>""Creating setup.py project for {}"".format(exported_python_target)<tab><tab>)<tab><tab>subject = self.derived_by_original.get(<tab><tab><tab>exported_python_target, exported_python_target<tab><tab>)<tab><tab>setup_dir, dependencies = self.create_setup_py(subject, dist_dir)<tab><tab>created[exported_python_target] = setup_dir<tab><tab><IF-STMT><tab><tab><tab>for dep in dependencies:<tab><tab><tab><tab>if is_exported_python_target(dep):<tab><tab><tab><tab><tab>create(dep)",if self . _recursive :,172
2047,"def __add__(self, other):<tab>other = ArithmeticExpression.try_unpack_const(other)<tab>if not self.symbolic and type(other) is int:<tab><tab>return SpOffset(self._bits, self._to_signed(self.offset + other))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return SpOffset(self._bits, self.offset + other)<tab><tab>else:<tab><tab><tab>return SpOffset(<tab><tab><tab><tab>self._bits,<tab><tab><tab><tab>ArithmeticExpression(<tab><tab><tab><tab><tab>ArithmeticExpression.Add,<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>self.offset,<tab><tab><tab><tab><tab><tab>other,<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>),<tab><tab><tab>)",if self . symbolic :,180
2048,"def check_connection(conn):<tab>tables = [<tab><tab>r[0]<tab><tab>for r in conn.execute(<tab><tab><tab>""select name from sqlite_master where type='table'""<tab><tab>).fetchall()<tab>]<tab>for table in tables:<tab><tab>try:<tab><tab><tab>conn.execute(<tab><tab><tab><tab>f""PRAGMA table_info({escape_sqlite(table)});"",<tab><tab><tab>)<tab><tab>except sqlite3.OperationalError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise SpatialiteConnectionProblem(e)<tab><tab><tab>else:<tab><tab><tab><tab>raise ConnectionProblem(e)","if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :",161
2049,"def _get_github_client(self) -> ""Github"":<tab>from github import Github<tab>if self.access_token_secret is not None:<tab><tab># If access token secret specified, load it<tab><tab>access_token = Secret(self.access_token_secret).get()<tab>else:<tab><tab># Otherwise, fallback to loading from local secret or environment variable<tab><tab>access_token = prefect.context.get(""secrets"", {}).get(""GITHUB_ACCESS_TOKEN"")<tab><tab><IF-STMT><tab><tab><tab>access_token = os.getenv(""GITHUB_ACCESS_TOKEN"")<tab>return Github(access_token)",if access_token is None :,149
2050,"def make_tab(lists):<tab>if hasattr(lists, ""tolist""):<tab><tab>lists = lists.tolist()<tab>ut = []<tab>for rad in lists:<tab><tab><IF-STMT><tab><tab><tab>ut.append(""\t"".join([""%s"" % x for x in rad]))<tab><tab>else:<tab><tab><tab>ut.append(""%s"" % rad)<tab>return ""\n"".join(ut)","if type ( rad ) in [ list , tuple ] :",102
2051,"def _ensure_ffi_initialized(cls):<tab>with cls._init_lock:<tab><tab><IF-STMT><tab><tab><tab>cls.lib = build_conditional_library(lib, CONDITIONAL_NAMES)<tab><tab><tab>cls._lib_loaded = True<tab><tab><tab># initialize the SSL library<tab><tab><tab>cls.lib.SSL_library_init()<tab><tab><tab># adds all ciphers/digests for EVP<tab><tab><tab>cls.lib.OpenSSL_add_all_algorithms()<tab><tab><tab># loads error strings for libcrypto and libssl functions<tab><tab><tab>cls.lib.SSL_load_error_strings()<tab><tab><tab>cls._register_osrandom_engine()",if not cls . _lib_loaded :,162
2052,def writer_leaves(self):<tab>self.mutex.acquire()<tab>try:<tab><tab>self.active_writers -= 1<tab><tab>if self.waiting_writers != 0:<tab><tab><tab>self.active_writers += 1<tab><tab><tab>self.waiting_writers -= 1<tab><tab><tab>self.can_write.release()<tab><tab><IF-STMT><tab><tab><tab>t = self.waiting_readers<tab><tab><tab>self.waiting_readers = 0<tab><tab><tab>self.active_readers += t<tab><tab><tab>while t > 0:<tab><tab><tab><tab>self.can_read.release()<tab><tab><tab><tab>t -= 1<tab>finally:<tab><tab>self.mutex.release(),elif self . waiting_readers != 0 :,171
2053,"def _spans(self, operands):<tab>spans = {}<tab>k = 0<tab>j = 0<tab>for mode in (self.FLOAT, self.MPMATH):<tab><tab>for i, operand in enumerate(operands[k:]):<tab><tab><tab>if operand[0] > mode:<tab><tab><tab><tab>break<tab><tab><tab>j = i + k + 1<tab><tab><IF-STMT>  # only init state? then ignore.<tab><tab><tab>j = 0<tab><tab>spans[mode] = slice(k, j)<tab><tab>k = j<tab>spans[self.SYMBOLIC] = slice(k, len(operands))<tab>return spans",if k == 0 and j == 1 :,152
2054,"def _report_error(self, completion_routine, response=None, message=None):<tab>if response:<tab><tab># Only include the text in case of error.<tab><tab><IF-STMT><tab><tab><tab>status = location.Status(response.status_code, response.text)<tab><tab>else:<tab><tab><tab>status = location.Status(response.status_code)<tab>else:<tab><tab>status = location.Status(500, message)<tab>if response is None or not response.ok:<tab><tab>if completion_routine:<tab><tab><tab>return completion_routine(status)<tab><tab>raise IOError(response.text)<tab>else:<tab><tab>if completion_routine:<tab><tab><tab>completion_routine(status)<tab>return location.Status(200, response.content)",if not response . ok :,182
2055,"def readinto(self, buf):<tab>if self.current_frame:<tab><tab>n = self.current_frame.readinto(buf)<tab><tab>if n == 0 and len(buf) != 0:<tab><tab><tab>self.current_frame = None<tab><tab><tab>n = len(buf)<tab><tab><tab>buf[:] = self.file_read(n)<tab><tab><tab>return n<tab><tab><IF-STMT><tab><tab><tab>raise UnpicklingError(""pickle exhausted before end of frame"")<tab><tab>return n<tab>else:<tab><tab>n = len(buf)<tab><tab>buf[:] = self.file_read(n)<tab><tab>return n",if n < len ( buf ) :,154
2056,"def __getitem__(self, name, set=set, getattr=getattr, id=id):<tab>visited = set()<tab>mydict = self.basedict<tab>while 1:<tab><tab>value = mydict[name]<tab><tab><IF-STMT><tab><tab><tab>return value<tab><tab>myid = id(mydict)<tab><tab>assert myid not in visited<tab><tab>visited.add(myid)<tab><tab>mydict = mydict.Parent<tab><tab>if mydict is None:<tab><tab><tab>return",if value is not None :,120
2057,"def _handle_Mul(self, expr):<tab>arg0, arg1 = expr.args<tab>expr_0 = self._expr(arg0)<tab>if expr_0 is None:<tab><tab>return None<tab>expr_1 = self._expr(arg1)<tab>if expr_1 is None:<tab><tab>return None<tab>try:<tab><tab><IF-STMT><tab><tab><tab># self.tyenv is not used<tab><tab><tab>mask = (1 << expr.result_size(self.tyenv)) - 1<tab><tab><tab>return (expr_0 * expr_1) & mask<tab><tab>else:<tab><tab><tab>return expr_0 * expr_1<tab>except TypeError as e:<tab><tab>self.l.warning(e)<tab><tab>return None","if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :",191
2058,"def end_request(self, request_id):<tab>""""""Removes the information associated with given request_id.""""""<tab>with self._lock:<tab><tab>del self._request_wsgi_environ[request_id]<tab><tab>del self._request_id_to_server_configuration[request_id]<tab><tab><IF-STMT><tab><tab><tab>del self._request_id_to_instance[request_id]",if request_id in self . _request_id_to_instance :,105
2059,def generate():<tab><IF-STMT><tab><tab>decoder = zlib.decompressobj(16 + zlib.MAX_WBITS)<tab>while True:<tab><tab>chunk = self.raw.read(chunk_size)<tab><tab>if not chunk:<tab><tab><tab>break<tab><tab>if self._gzipped:<tab><tab><tab>chunk = decoder.decompress(chunk)<tab><tab>yield chunk,if self . _gzipped :,87
2060,"def handle(self):<tab>from poetry.utils.env import EnvManager<tab>manager = EnvManager(self.poetry)<tab>current_env = manager.get()<tab>for venv in manager.list():<tab><tab>name = venv.path.name<tab><tab><IF-STMT><tab><tab><tab>name = str(venv.path)<tab><tab>if venv == current_env:<tab><tab><tab>self.line(""<info>{} (Activated)</info>"".format(name))<tab><tab><tab>continue<tab><tab>self.line(name)","if self . option ( ""full-path"" ) :",129
2061,"def addAggregators(sheet, cols, aggrnames):<tab>""Add each aggregator in list of *aggrnames* to each of *cols*.""<tab>for aggrname in aggrnames:<tab><tab>aggrs = vd.aggregators.get(aggrname)<tab><tab>aggrs = aggrs if isinstance(aggrs, list) else [aggrs]<tab><tab>for aggr in aggrs:<tab><tab><tab>for c in cols:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>c.aggregators = []<tab><tab><tab><tab>if aggr and aggr not in c.aggregators:<tab><tab><tab><tab><tab>c.aggregators += [aggr]","if not hasattr ( c , ""aggregators"" ) :",149
2062,"def on_pre_output_coercion(<tab>directive_args: Dict[str, Any],<tab>next_directive: Callable,<tab>value: Any,<tab>ctx: Optional[Any],<tab>info: ""ResolveInfo"",):<tab>value = await next_directive(value, ctx, info)<tab>if value is None:<tab><tab>return value<tab>try:<tab><tab>py_enum = _ENUM_MAP[directive_args[""name""]]<tab><tab><IF-STMT><tab><tab><tab>return [None if item is None else py_enum(item).name for item in value]<tab><tab>return py_enum(value).name<tab>except Exception:<tab><tab>pass<tab>return value","if isinstance ( value , list ) :",163
2063,def cut(sentence):<tab>sentence = strdecode(sentence)<tab>blocks = re_han.split(sentence)<tab>for blk in blocks:<tab><tab><IF-STMT><tab><tab><tab>for word in __cut(blk):<tab><tab><tab><tab>if word not in Force_Split_Words:<tab><tab><tab><tab><tab>yield word<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>for c in word:<tab><tab><tab><tab><tab><tab>yield c<tab><tab>else:<tab><tab><tab>tmp = re_skip.split(blk)<tab><tab><tab>for x in tmp:<tab><tab><tab><tab>if x:<tab><tab><tab><tab><tab>yield x,if re_han . match ( blk ) :,156
2064,"def refresh_archive_action(self):<tab>archive_name = self.selected_archive_name()<tab>if archive_name is not None:<tab><tab>params = BorgInfoArchiveThread.prepare(self.profile(), archive_name)<tab><tab><IF-STMT><tab><tab><tab>thread = BorgInfoArchiveThread(params[""cmd""], params, parent=self.app)<tab><tab><tab>thread.updated.connect(self._set_status)<tab><tab><tab>thread.result.connect(self.refresh_archive_result)<tab><tab><tab>self._toggle_all_buttons(False)<tab><tab><tab>thread.start()","if params [ ""ok"" ] :",143
2065,"def get_resource_public_actions(resource_class):<tab>resource_class_members = inspect.getmembers(resource_class)<tab>resource_methods = {}<tab>for name, member in resource_class_members:<tab><tab>if not name.startswith(""_""):<tab><tab><tab>if not name[0].isupper():<tab><tab><tab><tab>if not name.startswith(""wait_until""):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>resource_methods[name] = member<tab>return resource_methods",if is_resource_action ( member ) :,122
2066,"def _get_compressor(compress_type, compresslevel=None):<tab>if compress_type == ZIP_DEFLATED:<tab><tab><IF-STMT><tab><tab><tab>return zlib.compressobj(compresslevel, zlib.DEFLATED, -15)<tab><tab>return zlib.compressobj(zlib.Z_DEFAULT_COMPRESSION, zlib.DEFLATED, -15)<tab>elif compress_type == ZIP_BZIP2:<tab><tab>if compresslevel is not None:<tab><tab><tab>return bz2.BZ2Compressor(compresslevel)<tab><tab>return bz2.BZ2Compressor()<tab># compresslevel is ignored for ZIP_LZMA<tab>elif compress_type == ZIP_LZMA:<tab><tab>return LZMACompressor()<tab>else:<tab><tab>return None",if compresslevel is not None :,169
2067,"def parse_header(plyfile, ext):<tab># Variables<tab>line = []<tab>properties = []<tab>num_points = None<tab>while b""end_header"" not in line and line != b"""":<tab><tab>line = plyfile.readline()<tab><tab>if b""element"" in line:<tab><tab><tab>line = line.split()<tab><tab><tab>num_points = int(line[2])<tab><tab><IF-STMT><tab><tab><tab>line = line.split()<tab><tab><tab>properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))<tab>return num_points, properties","elif b""property"" in line :",149
2068,"def download_release_artifacts(self, version):<tab>try:<tab><tab>os.mkdir(self.artifacts_dir)<tab>except FileExistsError:<tab><tab>pass<tab>for job_name in self.build_ids:<tab><tab>build_number = self.build_ids.get(job_name)<tab><tab>build_status = self._get_build_status(job_name, build_number)<tab><tab><IF-STMT><tab><tab><tab>self._download_job_artifact(job_name, build_number, version)<tab><tab>else:<tab><tab><tab>print(""Build for {} is not fininished"".format(job_name))<tab><tab><tab>print(""\tRun 'build' action to check status of {}"".format(job_name))","if build_status == ""built"" :",175
2069,"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab>if attrvalue == 0:<tab><tab><tab>continue<tab><tab>if attrname == ""salt_version"":<tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab>elif hasattr(self.metadata, attrname):<tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass","if attrname . startswith ( ""__"" ) :",173
2070,"def check_heuristic_in_sql():<tab>heurs = set()<tab>excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""]<tab>for heur in HEURISTICS:<tab><tab>name = heur[""name""]<tab><tab>if name in excluded:<tab><tab><tab>continue<tab><tab>sql = heur[""sql""]<tab><tab><IF-STMT><tab><tab><tab>print((""SQL command not correctly associated to %s"" % repr(name)))<tab><tab><tab>print(sql)<tab><tab><tab>assert sql.find(name) != -1<tab><tab>heurs.add(name)<tab>print(""Heuristics:"")<tab>import pprint<tab>pprint.pprint(heurs)",if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,171
2071,def gettext(rv):<tab>for child in rv.childNodes:<tab><tab><IF-STMT><tab><tab><tab>yield child.nodeValue<tab><tab>if child.nodeType == child.ELEMENT_NODE:<tab><tab><tab>for item in gettext(child):<tab><tab><tab><tab>yield item,if child . nodeType == child . TEXT_NODE :,73
2072,"def update(self):<tab>""""""Update properties over dbus.""""""<tab>self._check_dbus()<tab>_LOGGER.info(""Updating service information"")<tab>self._services.clear()<tab>try:<tab><tab>systemd_units = await self.sys_dbus.systemd.list_units()<tab><tab>for service_data in systemd_units[0]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self._services.add(ServiceInfo.read_from(service_data))<tab>except (HassioError, IndexError):<tab><tab>_LOGGER.warning(""Can't update host service information!"")","if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :",161
2073,"def filtercomments(source):<tab>""""""NOT USED: strips trailing comments and put them at the top.""""""<tab>trailing_comments = []<tab>comment = True<tab>while comment:<tab><tab><IF-STMT><tab><tab><tab>comment = source[0, source.index(""*/"") + 2]<tab><tab>elif re.search(r""^\s*\/\/"", source):<tab><tab><tab>comment = re.search(r""^\s*\/\/"", source).group(0)<tab><tab>else:<tab><tab><tab>comment = None<tab><tab>if comment:<tab><tab><tab>source = re.sub(r""^\s+"", """", source[len(comment) :])<tab><tab><tab>trailing_comments.append(comment)<tab>return ""\n"".join(trailing_comments) + source","if re . search ( r""^\s*\/\*"" , source ) :",179
2074,"def _getSourceStamp_sync(self, ssid):<tab>if ssid in self.sourcestamps:<tab><tab>ssdict = self.sourcestamps[ssid].copy()<tab><tab>ssdict[""ssid""] = ssid<tab><tab>patchid = ssdict[""patchid""]<tab><tab><IF-STMT><tab><tab><tab>ssdict.update(self.patches[patchid])<tab><tab><tab>ssdict[""patchid""] = patchid<tab><tab>else:<tab><tab><tab>ssdict[""patch_body""] = None<tab><tab><tab>ssdict[""patch_level""] = None<tab><tab><tab>ssdict[""patch_subdir""] = None<tab><tab><tab>ssdict[""patch_author""] = None<tab><tab><tab>ssdict[""patch_comment""] = None<tab><tab>return ssdict<tab>else:<tab><tab>return None",if patchid :,184
2075,"def parseImpl(self, instring, loc, doActions=True):<tab>try:<tab><tab>loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)<tab>except (ParseException, IndexError):<tab><tab>if self.defaultValue is not self.__optionalNotMatched:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tokens = ParseResults([self.defaultValue])<tab><tab><tab><tab>tokens[self.expr.resultsName] = self.defaultValue<tab><tab><tab>else:<tab><tab><tab><tab>tokens = [self.defaultValue]<tab><tab>else:<tab><tab><tab>tokens = []<tab>return loc, tokens",if self . expr . resultsName :,157
2076,"def _find_exceptions():<tab>for _name, obj in iteritems(globals()):<tab><tab>try:<tab><tab><tab>is_http_exception = issubclass(obj, HTTPException)<tab><tab>except TypeError:<tab><tab><tab>is_http_exception = False<tab><tab>if not is_http_exception or obj.code is None:<tab><tab><tab>continue<tab><tab>__all__.append(obj.__name__)<tab><tab>old_obj = default_exceptions.get(obj.code, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>default_exceptions[obj.code] = obj","if old_obj is not None and issubclass ( obj , old_obj ) :",148
2077,"def generator(self, data):<tab>for (proc_as, key_buf_ptr) in data:<tab><tab>key_buf = proc_as.read(key_buf_ptr, 24)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>key = """".join(""%02X"" % ord(k) for k in key_buf)<tab><tab>yield (<tab><tab><tab>0,<tab><tab><tab>[<tab><tab><tab><tab>str(key),<tab><tab><tab>],<tab><tab>)",if not key_buf :,117
2078,"def calculateEnableMargins(self):<tab>self.cnc.resetEnableMargins()<tab>for block in self.blocks:<tab><tab><IF-STMT><tab><tab><tab>CNC.vars[""xmin""] = min(CNC.vars[""xmin""], block.xmin)<tab><tab><tab>CNC.vars[""ymin""] = min(CNC.vars[""ymin""], block.ymin)<tab><tab><tab>CNC.vars[""zmin""] = min(CNC.vars[""zmin""], block.zmin)<tab><tab><tab>CNC.vars[""xmax""] = max(CNC.vars[""xmax""], block.xmax)<tab><tab><tab>CNC.vars[""ymax""] = max(CNC.vars[""ymax""], block.ymax)<tab><tab><tab>CNC.vars[""zmax""] = max(CNC.vars[""zmax""], block.zmax)",if block . enable :,191
2079,"def __init__(self, client, job_id, callback=None):<tab>self.client = client<tab>self.job_id = job_id<tab># If a job event has been received already then we must set an Event<tab># to wait for this job to finish.<tab># Otherwise we create a new stub for the job with the Event for when<tab># the job event arrives to use existing event.<tab>with client._jobs_lock:<tab><tab>job = client._jobs.get(job_id)<tab><tab>self.event = None<tab><tab><IF-STMT><tab><tab><tab>self.event = job.get(""__ready"")<tab><tab>if self.event is None:<tab><tab><tab>self.event = job[""__ready""] = Event()<tab><tab>job[""__callback""] = callback",if job :,180
2080,"def asset(*paths):<tab>for path in paths:<tab><tab>fspath = www_root + ""/assets/"" + path<tab><tab>etag = """"<tab><tab>try:<tab><tab><tab>if env.cache_static:<tab><tab><tab><tab>etag = asset_etag(fspath)<tab><tab><tab>else:<tab><tab><tab><tab>os.stat(fspath)<tab><tab>except FileNotFoundError as e:<tab><tab><tab>if path == paths[-1]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>tell_sentry(e, {})<tab><tab><tab>else:<tab><tab><tab><tab>continue<tab><tab>except Exception as e:<tab><tab><tab>tell_sentry(e, {})<tab><tab>return asset_url + path + (etag and ""?etag="" + etag)","if not os . path . exists ( fspath + "".spt"" ) :",182
2081,"def set_conf():<tab>""""""Collapse all object_trail config into cherrypy.request.config.""""""<tab>base = cherrypy.config.copy()<tab># Note that we merge the config from each node<tab># even if that node was None.<tab>for name, obj, conf, segleft in object_trail:<tab><tab>base.update(conf)<tab><tab><IF-STMT><tab><tab><tab>base[""tools.staticdir.section""] = ""/"" + ""/"".join(<tab><tab><tab><tab>fullpath[0 : fullpath_len - segleft]<tab><tab><tab>)<tab>return base","if ""tools.staticdir.dir"" in conf :",145
2082,"def __init__(self):<tab>self.setLayers(None, None)<tab>self.interface = None<tab>self.event_callbacks = {}<tab>self.__stack = None<tab>self.lock = threading.Lock()<tab>members = inspect.getmembers(self, predicate=inspect.ismethod)<tab>for m in members:<tab><tab><IF-STMT><tab><tab><tab>fname = m[0]<tab><tab><tab>fn = m[1]<tab><tab><tab>self.event_callbacks[fn.event_callback] = getattr(self, fname)","if hasattr ( m [ 1 ] , ""event_callback"" ) :",133
2083,def multi_dev_generator(self):<tab>for data in self._data_loader():<tab><tab><IF-STMT><tab><tab><tab>self._tail_data += data<tab><tab>if len(self._tail_data) == self._base_number:<tab><tab><tab>yield self._tail_data<tab><tab><tab>self._tail_data = [],if len ( self . _tail_data ) < self . _base_number :,91
2084,"def replace_field_to_value(layout, cb):<tab>for i, lo in enumerate(layout.fields):<tab><tab>if isinstance(lo, Field) or issubclass(lo.__class__, Field):<tab><tab><tab>layout.fields[i] = ShowField(<tab><tab><tab><tab>cb, *lo.fields, attrs=lo.attrs, wrapper_class=lo.wrapper_class<tab><tab><tab>)<tab><tab>elif isinstance(lo, basestring):<tab><tab><tab>layout.fields[i] = ShowField(cb, lo)<tab><tab><IF-STMT><tab><tab><tab>replace_field_to_value(lo, cb)","elif hasattr ( lo , ""get_field_names"" ) :",151
2085,"def function_out(*args, **kwargs):<tab>try:<tab><tab>return function_in(*args, **kwargs)<tab>except dbus.exceptions.DBusException as e:<tab><tab>if e.get_dbus_name() == DBUS_UNKNOWN_METHOD:<tab><tab><tab>raise ItemNotFoundException(""Item does not exist!"")<tab><tab>if e.get_dbus_name() == DBUS_NO_SUCH_OBJECT:<tab><tab><tab>raise ItemNotFoundException(e.get_dbus_message())<tab><tab><IF-STMT><tab><tab><tab>raise SecretServiceNotAvailableException(e.get_dbus_message())<tab><tab>raise","if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) :",162
2086,"def results_iter(self):<tab>if self.connection.ops.oracle:<tab><tab>from django.db.models.fields import DateTimeField<tab><tab>fields = [DateTimeField()]<tab>else:<tab><tab>needs_string_cast = self.connection.features.needs_datetime_string_cast<tab>offset = len(self.query.extra_select)<tab>for rows in self.execute_sql(MULTI):<tab><tab>for row in rows:<tab><tab><tab>date = row[offset]<tab><tab><tab>if self.connection.ops.oracle:<tab><tab><tab><tab>date = self.resolve_columns(row, fields)[offset]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>date = typecast_timestamp(str(date))<tab><tab><tab>yield date",elif needs_string_cast :,182
2087,"def handle_label(self, path, **options):<tab>verbosity = int(options.get(""verbosity"", 1))<tab>result = finders.find(path, all=options[""all""])<tab>path = smart_unicode(path)<tab>if result:<tab><tab>if not isinstance(result, (list, tuple)):<tab><tab><tab>result = [result]<tab><tab>output = u""\n  "".join(<tab><tab><tab>(smart_unicode(os.path.realpath(path)) for path in result)<tab><tab>)<tab><tab>self.stdout.write(smart_str(u""Found '%s' here:\n  %s\n"" % (path, output)))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.stderr.write(smart_str(""No matching file found for '%s'.\n"" % path))",if verbosity >= 1 :,193
2088,"def name(self):<tab>""""""Get the enumeration name of this storage class.""""""<tab>if self._name_map is None:<tab><tab>self._name_map = {}<tab><tab>for key, value in list(StorageClass.__dict__.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._name_map[value] = key<tab>return self._name_map[self]","if isinstance ( value , StorageClass ) :",94
2089,"def index(self, value):<tab>if self._growing:<tab><tab>if self._start <= value < self._stop:<tab><tab><tab>q, r = divmod(value - self._start, self._step)<tab><tab><tab>if r == self._zero:<tab><tab><tab><tab>return int(q)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>q, r = divmod(self._start - value, -self._step)<tab><tab><tab>if r == self._zero:<tab><tab><tab><tab>return int(q)<tab>raise ValueError(""{} is not in numeric range"".format(value))",if self . _start >= value > self . _stop :,146
2090,"def extract_cookie(cookie_header, cookie_name):<tab>inx = cookie_header.find(cookie_name)<tab>if inx >= 0:<tab><tab>end_inx = cookie_header.find("";"", inx)<tab><tab><IF-STMT><tab><tab><tab>value = cookie_header[inx:end_inx]<tab><tab>else:<tab><tab><tab>value = cookie_header[inx:]<tab><tab>return value<tab>return """"",if end_inx > 0 :,104
2091,"def get_size(self, shape_info):<tab># The size is the data, that have constant size.<tab>state = np.random.RandomState().get_state()<tab>size = 0<tab>for elem in state:<tab><tab>if isinstance(elem, str):<tab><tab><tab>size += len(elem)<tab><tab><IF-STMT><tab><tab><tab>size += elem.size * elem.itemsize<tab><tab>elif isinstance(elem, int):<tab><tab><tab>size += np.dtype(""int"").itemsize<tab><tab>elif isinstance(elem, float):<tab><tab><tab>size += np.dtype(""float"").itemsize<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab>return size","elif isinstance ( elem , np . ndarray ) :",159
2092,"def createFields(self):<tab>size = self.size / 8<tab>if size > 2:<tab><tab><IF-STMT><tab><tab><tab>yield UInt8(self, ""cs"", ""10ms units, values from 0 to 199"")<tab><tab>yield Bits(self, ""2sec"", 5, ""seconds/2"")<tab><tab>yield Bits(self, ""min"", 6, ""minutes"")<tab><tab>yield Bits(self, ""hour"", 5, ""hours"")<tab>yield Bits(self, ""day"", 5, ""(1-31)"")<tab>yield Bits(self, ""month"", 4, ""(1-12)"")<tab>yield Bits(self, ""year"", 7, ""(0 = 1980, 127 = 2107)"")",if size > 4 :,169
2093,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""incap_ses|visid_incap"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab>retval |= re.search(r""Incapsula"", headers.get(""X-CDN"", """"), re.I) is not None<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,157
2094,"def _get_order_information(self, node_id, timeout=1200, check_interval=5):<tab>mask = {<tab><tab>""billingItem"": """",<tab><tab>""powerState"": """",<tab><tab>""operatingSystem"": {""passwords"": """"},<tab><tab>""provisionDate"": """",<tab>}<tab>for i in range(0, timeout, check_interval):<tab><tab>res = self.connection.request(<tab><tab><tab>""SoftLayer_Virtual_Guest"", ""getObject"", id=node_id, object_mask=mask<tab><tab>).object<tab><tab><IF-STMT><tab><tab><tab>return res<tab><tab>time.sleep(check_interval)<tab>raise SoftLayerException(""Timeout on getting node details"")","if res . get ( ""provisionDate"" , None ) :",170
2095,"def _process_param_change(self, msg):<tab>msg = super(Select, self)._process_param_change(msg)<tab>labels, values = self.labels, self.values<tab>if ""value"" in msg:<tab><tab>msg[""value""] = [<tab><tab><tab>labels[indexOf(v, values)] for v in msg[""value""] if isIn(v, values)<tab><tab>]<tab>if ""options"" in msg:<tab><tab>msg[""options""] = labels<tab><tab><IF-STMT><tab><tab><tab>self.value = [v for v in self.value if isIn(v, values)]<tab>return msg","if any ( not isIn ( v , values ) for v in self . value ) :",161
2096,"def get_object_from_name(self, name, check_symlinks=True):<tab>if not name:<tab><tab>return None<tab>name = name.rstrip(""\\"")<tab>for a, o in self.objects.items():<tab><tab>if not o.name:<tab><tab><tab>continue<tab><tab>if o.name.lower() == name.lower():<tab><tab><tab>return o<tab>if check_symlinks:<tab><tab>m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()]<tab><tab><IF-STMT><tab><tab><tab>name = m[0]<tab><tab>return self.get_object_from_name(name, False)",if m :,156
2097,"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v[""_class""] == ""User"":<tab><tab><tab>if v[""email""] == """":<tab><tab><tab><tab>v[""email""] = None<tab><tab><tab>if v[""ip""] == ""0.0.0.0"":<tab><tab><tab><tab>v[""ip""] = None<tab>return self.objs","if k . startswith ( ""_"" ) :",102
2098,"def _providers(self, descriptor):<tab>res = []<tab>for _md in self.metadata.values():<tab><tab>for ent_id, ent_desc in _md.items():<tab><tab><tab>if descriptor in ent_desc:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># print(""duplicated entity_id: %s"" % res)<tab><tab><tab><tab><tab>pass<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>res.append(ent_id)<tab>return res",if ent_id in res :,118
2099,"def test_add_participant(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>async with self.chat_thread_client:<tab><tab><tab>share_history_time = datetime.utcnow()<tab><tab><tab>share_history_time = share_history_time.replace(tzinfo=TZ_UTC)<tab><tab><tab>new_participant = ChatThreadParticipant(<tab><tab><tab><tab>user=self.new_user,<tab><tab><tab><tab>display_name=""name"",<tab><tab><tab><tab>share_history_time=share_history_time,<tab><tab><tab>)<tab><tab><tab>await self.chat_thread_client.add_participant(new_participant)<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)",if not self . is_playback ( ) :,197
2100,"def url(regex, view, kwargs=None, name=None, prefix=""""):<tab>if isinstance(view, (list, tuple)):<tab><tab># For include(...) processing.<tab><tab>urlconf_module, app_name, namespace = view<tab><tab>return RegexURLResolver(<tab><tab><tab>regex, urlconf_module, kwargs, app_name=app_name, namespace=namespace<tab><tab>)<tab>else:<tab><tab>if isinstance(view, basestring):<tab><tab><tab>if not view:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Empty URL pattern view name not permitted (for pattern %r)"" % regex<tab><tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>view = prefix + ""."" + view<tab><tab>return RegexURLPattern(regex, view, kwargs, name)",if prefix :,183
2101,"def tx():<tab># Sync receiver ready to avoid loss of first packets<tab>while not sub_ready.ready():<tab><tab>pub.send(b""test BEGIN"")<tab><tab>eventlet.sleep(0.005)<tab>for i in range(1, 101):<tab><tab>msg = ""test {0}"".format(i).encode()<tab><tab><IF-STMT><tab><tab><tab>pub.send(msg)<tab><tab>else:<tab><tab><tab>pub.send(b""test LAST"")<tab><tab><tab>sub_last.wait()<tab><tab># XXX: putting a real delay of 1ms here fixes sporadic failures on Travis<tab><tab># just yield eventlet.sleep(0) doesn't cut it<tab><tab>eventlet.sleep(0.001)<tab>pub.send(b""done DONE"")",if i != 50 :,185
2102,"def remove_tmp_snapshot_file(self, files):<tab>for filepath in files:<tab><tab>path = Path(filepath)<tab><tab>if path.is_dir() and path.exists():<tab><tab><tab>shutil.rmtree(path)<tab><tab><IF-STMT><tab><tab><tab>path.unlink()",elif path . is_file ( ) and path . exists ( ) :,78
2103,"def f(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab>if count == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>eol = view.line(s.b).b<tab><tab><tab><tab>return R(s.b, eol)<tab><tab><tab>return s<tab>return s",if view . line ( s . b ) . size ( ) > 0 :,85
2104,"def get_ids(self, **kwargs):<tab>id = []<tab>if ""id"" in kwargs:<tab><tab>id = kwargs[""id""]<tab><tab># Coerce ids to list<tab><tab><IF-STMT><tab><tab><tab>id = id.split("","")<tab><tab># Ensure ids are integers<tab><tab>try:<tab><tab><tab>id = list(map(int, id))<tab><tab>except Exception:<tab><tab><tab>decorators.error(""Invalid id"")<tab>return id","if not isinstance ( id , list ) :",111
2105,"def param_value(self):<tab># This is part of the ""handle quoted extended parameters"" hack.<tab>for token in self:<tab><tab><IF-STMT><tab><tab><tab>return token.stripped_value<tab><tab>if token.token_type == ""quoted-string"":<tab><tab><tab>for token in token:<tab><tab><tab><tab>if token.token_type == ""bare-quoted-string"":<tab><tab><tab><tab><tab>for token in token:<tab><tab><tab><tab><tab><tab>if token.token_type == ""value"":<tab><tab><tab><tab><tab><tab><tab>return token.stripped_value<tab>return """"","if token . token_type == ""value"" :",143
2106,"def get_all_start_methods(self):<tab>if sys.platform == ""win32"":<tab><tab>return [""spawn""]<tab>else:<tab><tab>methods = [""spawn"", ""fork""] if sys.platform == ""darwin"" else [""fork"", ""spawn""]<tab><tab><IF-STMT><tab><tab><tab>methods.append(""forkserver"")<tab><tab>return methods",if reduction . HAVE_SEND_HANDLE :,88
2107,"def _process_watch(self, watched_event):<tab>logger.debug(""process_watch: %r"", watched_event)<tab>with handle_exception(self._tree._error_listeners):<tab><tab><IF-STMT><tab><tab><tab>assert self._parent is None, ""unexpected CREATED on non-root""<tab><tab><tab>self.on_created()<tab><tab>elif watched_event.type == EventType.DELETED:<tab><tab><tab>self.on_deleted()<tab><tab>elif watched_event.type == EventType.CHANGED:<tab><tab><tab>self._refresh_data()<tab><tab>elif watched_event.type == EventType.CHILD:<tab><tab><tab>self._refresh_children()",if watched_event . type == EventType . CREATED :,172
2108,"def assert_open(self, sock, *rest):<tab>if isinstance(sock, fd_types):<tab><tab>self.__assert_fd_open(sock)<tab>else:<tab><tab>fileno = sock.fileno()<tab><tab>assert isinstance(fileno, fd_types), fileno<tab><tab>sockname = sock.getsockname()<tab><tab>assert isinstance(sockname, tuple), sockname<tab><tab><IF-STMT><tab><tab><tab>self.__assert_fd_open(fileno)<tab><tab>else:<tab><tab><tab>self._assert_sock_open(sock)<tab>if rest:<tab><tab>self.assert_open(rest[0], *rest[1:])",if not WIN :,148
2109,"def detype(self):<tab>""""""De-types the instance, allowing it to be exported to the environment.""""""<tab>style = self.style<tab>if self._detyped is None:<tab><tab>self._detyped = "":"".join(<tab><tab><tab>[<tab><tab><tab><tab>key<tab><tab><tab><tab>+ ""=""<tab><tab><tab><tab>+ "";"".join(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>LsColors.target_value<tab><tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>else ansi_color_name_to_escape_code(v, cmap=style)<tab><tab><tab><tab><tab><tab>for v in val<tab><tab><tab><tab><tab>]<tab><tab><tab><tab>)<tab><tab><tab><tab>for key, val in sorted(self._d.items())<tab><tab><tab>]<tab><tab>)<tab>return self._detyped",if key in self . _targets,198
2110,"def gather_metrics(dry_run=False):<tab>today = datetime.date.today()<tab>first = today.replace(day=1)<tab>last_month = first - datetime.timedelta(days=1)<tab>filename = ""form_types_{}.csv"".format(last_month.strftime(""%Y-%m""))<tab>with connection.cursor() as cursor:<tab><tab>cursor.execute(REGISTRATION_METRICS_SQL)<tab><tab><IF-STMT><tab><tab><tab>for row in cursor.fetchall():<tab><tab><tab><tab>logger.info(encode_row(row))<tab><tab>else:<tab><tab><tab>write_raw_data(cursor=cursor, filename=filename)",if dry_run :,154
2111,"def cat(tensors, dim=0):<tab>assert isinstance(tensors, list), ""input to cat must be a list""<tab>if len(tensors) == 1:<tab><tab>return tensors[0]<tab>from .autograd_cryptensor import AutogradCrypTensor<tab>if any(isinstance(t, AutogradCrypTensor) for t in tensors):<tab><tab><IF-STMT><tab><tab><tab>tensors[0] = AutogradCrypTensor(tensors[0], requires_grad=False)<tab><tab>return tensors[0].cat(*tensors[1:], dim=dim)<tab>else:<tab><tab>return get_default_backend().cat(tensors, dim=dim)","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :",166
2112,"def is_installed(self, dlc_title="""") -> bool:<tab>installed = False<tab>if dlc_title:<tab><tab>dlc_version = self.get_dlc_info(""version"", dlc_title)<tab><tab>installed = True if dlc_version else False<tab><tab># Start: Code for compatibility with minigalaxy 1.0<tab><tab>if not installed:<tab><tab><tab>status = self.legacy_get_dlc_status(dlc_title)<tab><tab><tab>installed = True if status in [""installed"", ""updatable""] else False<tab><tab># End: Code for compatibility with minigalaxy 1.0<tab>else:<tab><tab><IF-STMT><tab><tab><tab>installed = True<tab>return installed",if self . install_dir and os . path . exists ( self . install_dir ) :,178
2113,"def on_copy(self):<tab>source_objects = self.__getSelection()<tab>for source in source_objects:<tab><tab><IF-STMT><tab><tab><tab>new_obj = model.Phrase("""", """")<tab><tab>else:<tab><tab><tab>new_obj = model.Script("""", """")<tab><tab>new_obj.copy(source)<tab><tab>self.cutCopiedItems.append(new_obj)","if isinstance ( source , model . Phrase ) :",100
2114,"def FetchFn(type_name):<tab>""""""Fetches all hunt results of a given type.""""""<tab>offset = 0<tab>while True:<tab><tab>results = data_store.REL_DB.ReadHuntResults(<tab><tab><tab>hunt_id, offset=offset, count=self._RESULTS_PAGE_SIZE, with_type=type_name<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>for r in results:<tab><tab><tab>msg = r.AsLegacyGrrMessage()<tab><tab><tab>msg.source_urn = source_urn<tab><tab><tab>yield msg<tab><tab>offset += self._RESULTS_PAGE_SIZE",if not results :,149
2115,"def get_blob_type_declaration_sql(self, column):<tab>length = column.get(""length"")<tab>if length:<tab><tab><IF-STMT><tab><tab><tab>return ""TINYBLOB""<tab><tab>if length <= self.LENGTH_LIMIT_BLOB:<tab><tab><tab>return ""BLOB""<tab><tab>if length <= self.LENGTH_LIMIT_MEDIUMBLOB:<tab><tab><tab>return ""MEDIUMBLOB""<tab>return ""LONGBLOB""",if length <= self . LENGTH_LIMIT_TINYBLOB :,115
2116,"def decode(cls, data):<tab>while data:<tab><tab>(<tab><tab><tab>length,<tab><tab><tab>atype,<tab><tab>) = unpack(cls.Header.PACK, data[: cls.Header.LEN])<tab><tab><IF-STMT><tab><tab><tab>raise AttributesError(""Buffer underrun %d < %d"" % (len(data), length))<tab><tab>payload = data[cls.Header.LEN : length]<tab><tab>yield atype, payload<tab><tab>data = data[int((length + 3) / 4) * 4 :]",if len ( data ) < length :,128
2117,"def test_join_diffs(db, series_of_diffs, expected):<tab>diffs = []<tab>for changes in series_of_diffs:<tab><tab>tracker = DBDiffTracker()<tab><tab>for key, val in changes.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del tracker[key]<tab><tab><tab>else:<tab><tab><tab><tab>tracker[key] = val<tab><tab>diffs.append(tracker.diff())<tab>DBDiff.join(diffs).apply_to(db)<tab>assert db == expected",if val is None :,123
2118,"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab>if col == LAND:<tab><tab><tab><tab>tmp += "".""<tab><tab><tab>elif col == BARRIER:<tab><tab><tab><tab>tmp += ""%""<tab><tab><tab>elif col == FOOD:<tab><tab><tab><tab>tmp += ""*""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",elif col == UNSEEN :,199
2119,"def _report_error(self, completion_routine, response=None, message=None):<tab>if response:<tab><tab># Only include the text in case of error.<tab><tab>if not response.ok:<tab><tab><tab>status = location.Status(response.status_code, response.text)<tab><tab>else:<tab><tab><tab>status = location.Status(response.status_code)<tab>else:<tab><tab>status = location.Status(500, message)<tab>if response is None or not response.ok:<tab><tab><IF-STMT><tab><tab><tab>return completion_routine(status)<tab><tab>raise IOError(response.text)<tab>else:<tab><tab>if completion_routine:<tab><tab><tab>completion_routine(status)<tab>return location.Status(200, response.content)",if completion_routine :,182
2120,"def _generate_examples(self, src_path=None, tgt_path=None, replace_unk=None):<tab>""""""Yields examples.""""""<tab>with tf.io.gfile.GFile(src_path) as f_d, tf.io.gfile.GFile(tgt_path) as f_s:<tab><tab>for i, (doc_text, sum_text) in enumerate(zip(f_d, f_s)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i, {<tab><tab><tab><tab><tab>_DOCUMENT: doc_text.strip().replace(""<unk>"", ""UNK""),<tab><tab><tab><tab><tab>_SUMMARY: sum_text.strip().replace(""<unk>"", ""UNK""),<tab><tab><tab><tab>}<tab><tab><tab>else:<tab><tab><tab><tab>yield i, {_DOCUMENT: doc_text.strip(), _SUMMARY: sum_text.strip()}",if replace_unk :,198
2121,"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab><IF-STMT><tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text",if newline :,170
2122,"def _handle_url_click(self, event):<tab>url = _extract_click_text(self.info_text, event, ""url"")<tab>if url is not None:<tab><tab><IF-STMT><tab><tab><tab>import webbrowser<tab><tab><tab>webbrowser.open(url)<tab><tab>elif os.path.sep in url:<tab><tab><tab>os.makedirs(url, exist_ok=True)<tab><tab><tab>open_path_in_system_file_manager(url)<tab><tab>else:<tab><tab><tab>self._start_show_package_info(url)","if url . startswith ( ""http:"" ) or url . startswith ( ""https:"" ) :",144
2123,"def SConsignFile(self, name="".sconsign"", dbm_module=None):<tab>if name is not None:<tab><tab>name = self.subst(name)<tab><tab><IF-STMT><tab><tab><tab>name = os.path.join(str(self.fs.SConstruct_dir), name)<tab>if name:<tab><tab>name = os.path.normpath(name)<tab><tab>sconsign_dir = os.path.dirname(name)<tab><tab>if sconsign_dir and not os.path.exists(sconsign_dir):<tab><tab><tab>self.Execute(SCons.Defaults.Mkdir(sconsign_dir))<tab>SCons.SConsign.File(name, dbm_module)",if not os . path . isabs ( name ) :,178
2124,"def on_train_start(self, trainer: Trainer, pl_module: LightningModule) -> None:<tab>super().on_train_start(trainer, pl_module)<tab>submodule_dict = dict(pl_module.named_modules())<tab>self._hook_handles = []<tab>for name in self._get_submodule_names(pl_module):<tab><tab><IF-STMT><tab><tab><tab>rank_zero_warn(<tab><tab><tab><tab>f""{name} is not a valid identifier for a submodule in {pl_module.__class__.__name__},""<tab><tab><tab><tab>"" skipping this key.""<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>handle = self._register_hook(name, submodule_dict[name])<tab><tab>self._hook_handles.append(handle)",if name not in submodule_dict :,184
2125,"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]):<tab>super().validate_configuration(configuration)<tab>if configuration is None:<tab><tab>configuration = self.configuration<tab>try:<tab><tab>assert ""value_set"" in configuration.kwargs, ""value_set is required""<tab><tab>assert isinstance(<tab><tab><tab>configuration.kwargs[""value_set""], (list, set, dict)<tab><tab>), ""value_set must be a list or a set""<tab><tab><IF-STMT><tab><tab><tab>assert (<tab><tab><tab><tab>""$PARAMETER"" in configuration.kwargs[""value_set""]<tab><tab><tab>), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key.'<tab>except AssertionError as e:<tab><tab>raise InvalidExpectationConfigurationError(str(e))<tab>return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",191
2126,"def check_refcounts(expected, timeout=10):<tab>start = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>_check_refcounts(expected)<tab><tab><tab>break<tab><tab>except AssertionError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(0.1)",if time . time ( ) - start > timeout :,96
2127,"def pickline(file, key, casefold=1):<tab>try:<tab><tab>f = open(file, ""r"")<tab>except IOError:<tab><tab>return None<tab>pat = re.escape(key) + "":""<tab>prog = re.compile(pat, casefold and re.IGNORECASE)<tab>while 1:<tab><tab>line = f.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if prog.match(line):<tab><tab><tab>text = line[len(key) + 1 :]<tab><tab><tab>while 1:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if not line or not line[0].isspace():<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>text = text + line<tab><tab><tab>return text.strip()<tab>return None",if not line :,182
2128,def _is_perf_file(file_path):<tab>f = get_file(file_path)<tab>for line in f:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>r = event_regexp.search(line)<tab><tab>if r:<tab><tab><tab>f.close()<tab><tab><tab>return True<tab><tab>f.close()<tab><tab>return False,"if line [ 0 ] == ""#"" :",92
2129,"def link_pantsrefs(soups, precomputed):<tab>""""""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">""""""<tab>for (page, soup) in soups.items():<tab><tab>for a in soup.find_all(""a""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>pantsref = a[""pantsref""]<tab><tab><tab>if pantsref not in precomputed.pantsref:<tab><tab><tab><tab>raise TaskError(<tab><tab><tab><tab><tab>f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it'<tab><tab><tab><tab>)<tab><tab><tab>a[""href""] = rel_href(page, precomputed.pantsref[pantsref])","if not a . has_attr ( ""pantsref"" ) :",194
2130,"def __init__(self, querylist=None):<tab>self.query_id = -1<tab>if querylist is None:<tab><tab>self.querylist = []<tab>else:<tab><tab>self.querylist = querylist<tab><tab>for query in self.querylist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.query_id = query.query_id<tab><tab><tab>else:<tab><tab><tab><tab>if self.query_id != query.query_id:<tab><tab><tab><tab><tab>raise ValueError(""query in list must be same query_id"")",if self . query_id == - 1 :,137
2131,"def _draw_number(<tab>screen, x_offset, y_offset, number, token=Token.Clock, transparent=False):<tab>""Write number at position.""<tab>fg = Char("" "", token)<tab>bg = Char("" "", Token)<tab>for y, row in enumerate(_numbers[number]):<tab><tab>screen_row = screen.data_buffer[y + y_offset]<tab><tab>for x, n in enumerate(row):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>screen_row[x + x_offset] = fg<tab><tab><tab>elif not transparent:<tab><tab><tab><tab>screen_row[x + x_offset] = bg","if n == ""#"" :",154
2132,"def init(self):<tab>self.sock.setblocking(True)<tab>if self.parser is None:<tab><tab># wrap the socket if needed<tab><tab><IF-STMT><tab><tab><tab>self.sock = ssl.wrap_socket(<tab><tab><tab><tab>self.sock, server_side=True, **self.cfg.ssl_options<tab><tab><tab>)<tab><tab># initialize the parser<tab><tab>self.parser = http.RequestParser(self.cfg, self.sock)",if self . cfg . is_ssl :,116
2133,"def intersect_face(pt):<tab># todo: rewrite! inefficient!<tab>nonlocal vis_faces2D<tab>for f, vs in vis_faces2D:<tab><tab>v0 = vs[0]<tab><tab>for v1, v2 in iter_pairs(vs[1:], False):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return f<tab>return None","if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :",104
2134,"def IMPORTFROM(self, node):<tab>if node.module == ""__future__"":<tab><tab>if not self.futuresAllowed:<tab><tab><tab>self.report(messages.LateFutureImport, node, [n.name for n in node.names])<tab>else:<tab><tab>self.futuresAllowed = False<tab>for alias in node.names:<tab><tab><IF-STMT><tab><tab><tab>self.scope.importStarred = True<tab><tab><tab>self.report(messages.ImportStarUsed, node, node.module)<tab><tab><tab>continue<tab><tab>name = alias.asname or alias.name<tab><tab>importation = Importation(name, node)<tab><tab>if node.module == ""__future__"":<tab><tab><tab>importation.used = (self.scope, node)<tab><tab>self.addBinding(node, importation)","if alias . name == ""*"" :",190
2135,"def PyObject_Bytes(obj):<tab>if type(obj) == bytes:<tab><tab>return obj<tab>if hasattr(obj, ""__bytes__""):<tab><tab>res = obj.__bytes__()<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""__bytes__ returned non-bytes (type %s)"" % type(res).__name__<tab><tab><tab>)<tab>return PyBytes_FromObject(obj)","if not isinstance ( res , bytes ) :",99
2136,"def on_bt_search_clicked(self, widget):<tab>if self.current_provider is None:<tab><tab>return<tab>query = self.en_query.get_text()<tab>@self.obtain_podcasts_with<tab>def load_data():<tab><tab>if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH:<tab><tab><tab>return self.current_provider.on_search(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_URL:<tab><tab><tab>return self.current_provider.on_url(query)<tab><tab><IF-STMT><tab><tab><tab>return self.current_provider.on_file(query)",elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,172
2137,"def remove(self, name):<tab>for s in [self.__storage(self.__category), self.__storage(None)]:<tab><tab>for i, b in enumerate(s):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del s[i]<tab><tab><tab><tab>if b.persistent:<tab><tab><tab><tab><tab>self.__save()<tab><tab><tab><tab>return<tab>raise KeyError(name)",if b . name == name :,94
2138,"def _wrapper(data, axis=None, keepdims=False):<tab>if not keepdims:<tab><tab>return func(data, axis=axis)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>axis = axis if isinstance(axis, int) else axis[0]<tab><tab><tab>out_shape = list(data.shape)<tab><tab><tab>out_shape[axis] = 1<tab><tab>else:<tab><tab><tab>out_shape = [1 for _ in range(len(data.shape))]<tab><tab>return func(data, axis=axis).reshape(out_shape)",if axis is not None :,135
2139,"def authn_info(self):<tab>res = []<tab>for astat in self.assertion.authn_statement:<tab><tab>context = astat.authn_context<tab><tab>try:<tab><tab><tab>authn_instant = astat.authn_instant<tab><tab>except AttributeError:<tab><tab><tab>authn_instant = """"<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>aclass = context.authn_context_class_ref.text<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>aclass = """"<tab><tab><tab>try:<tab><tab><tab><tab>authn_auth = [a.text for a in context.authenticating_authority]<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>authn_auth = []<tab><tab><tab>res.append((aclass, authn_auth, authn_instant))<tab>return res",if context :,199
2140,"def _persist_metadata(self, dirname, filename):<tab>metadata_path = ""{0}/{1}.json"".format(dirname, filename)<tab>if self.media_metadata or self.comments or self.include_location:<tab><tab>if self.posts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.merge_json({""GraphImages"": self.posts}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphImages"": self.posts}, metadata_path)<tab><tab>if self.stories:<tab><tab><tab>if self.latest:<tab><tab><tab><tab>self.merge_json({""GraphStories"": self.stories}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphStories"": self.stories}, metadata_path)",if self . latest :,190
2141,"def update_record_image_detail(input_image_record, updated_image_detail, session=None):<tab>if not session:<tab><tab>session = db.Session<tab>image_record = {}<tab>image_record.update(input_image_record)<tab>image_record.pop(""created_at"", None)<tab>image_record.pop(""last_updated"", None)<tab>if image_record[""image_type""] == ""docker"":<tab><tab>for tag_record in updated_image_detail:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>image_record[""image_detail""].append(tag_record)<tab><tab><tab><tab>return update_record(image_record, session=session)<tab>return image_record","if tag_record not in image_record [ ""image_detail"" ] :",179
2142,"def backup(self):<tab>for ds in [(""activedirectory"", ""AD""), (""ldap"", ""LDAP""), (""nis"", ""NIS"")]:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>ds_cache = self.middleware.call_sync(""cache.get"", f""{ds[1]}_cache"")<tab><tab><tab><tab>with open(f""/var/db/system/.{ds[1]}_cache_backup"", ""wb"") as f:<tab><tab><tab><tab><tab>pickle.dump(ds_cache, f)<tab><tab><tab>except KeyError:<tab><tab><tab><tab>self.logger.debug(""No cache exists for directory service [%s]."", ds[0])","if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :",175
2143,"def parse_setup_cfg(self):<tab># type: () -> Dict[STRING_TYPE, Any]<tab>if self.setup_cfg is not None and self.setup_cfg.exists():<tab><tab>contents = self.setup_cfg.read_text()<tab><tab>base_dir = self.setup_cfg.absolute().parent.as_posix()<tab><tab>try:<tab><tab><tab>parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix())<tab><tab>except Exception:<tab><tab><tab>if six.PY2:<tab><tab><tab><tab>contents = self.setup_cfg.read_bytes()<tab><tab><tab>parsed = parse_setup_cfg(contents, base_dir)<tab><tab><IF-STMT><tab><tab><tab>return {}<tab><tab>return parsed<tab>return {}",if not parsed :,183
2144,"def parts():<tab>for l in lists.leaves:<tab><tab>head_name = l.get_head_name()<tab><tab><IF-STMT><tab><tab><tab>yield l.leaves<tab><tab>elif head_name != ""System`Missing"":<tab><tab><tab>raise MessageException(""Catenate"", ""invrp"", l)","if head_name == ""System`List"" :",78
2145,"def _get_callback_and_order(self, hook):<tab>if callable(hook):<tab><tab>return hook, None<tab>elif isinstance(hook, tuple) and len(hook) == 2:<tab><tab>callback, order = hook<tab><tab># test that callback is a callable<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Hook callback is not a callable"")<tab><tab># test that number is an int<tab><tab>try:<tab><tab><tab>int(order)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""Hook order is not a number"")<tab><tab>return callback, order<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>""Invalid hook definition, neither a callable nor a 2-tuple (callback, order): {!r}"".format(<tab><tab><tab><tab>hook<tab><tab><tab>)<tab><tab>)",if not callable ( callback ) :,189
2146,"def _resize_masks(self, results):<tab>""""""Resize masks with ``results['scale']``""""""<tab>for key in results.get(""mask_fields"", []):<tab><tab>if results[key] is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>results[key] = results[key].rescale(results[""scale""])<tab><tab>else:<tab><tab><tab>results[key] = results[key].resize(results[""img_shape""][:2])",if self . keep_ratio :,110
2147,"def getDataMax(self):<tab>result = -Double.MAX_VALUE<tab>nCurves = self.chart.getNCurves()<tab>for i in range(nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab>if not c.isVisible():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>nPoints = c.getNPoints()<tab><tab><tab>for j in range(nPoints):<tab><tab><tab><tab>result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY())<tab>if result == -Double.MAX_VALUE:<tab><tab>return Double.NaN<tab>return result",if c . getYAxis ( ) == Y_AXIS :,163
2148,"def _check_token(self):<tab>if settings.app.sso_client_cache and self.server_auth_token:<tab><tab>doc = self.sso_client_cache_collection.find_one(<tab><tab><tab>{<tab><tab><tab><tab>""user_id"": self.user.id,<tab><tab><tab><tab>""server_id"": self.server.id,<tab><tab><tab><tab>""device_id"": self.device_id,<tab><tab><tab><tab>""device_name"": self.device_name,<tab><tab><tab><tab>""auth_token"": self.server_auth_token,<tab><tab><tab>}<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.has_token = True",if doc :,162
2149,"def parse_header(plyfile, ext):<tab># Variables<tab>line = []<tab>properties = []<tab>num_points = None<tab>while b""end_header"" not in line and line != b"""":<tab><tab>line = plyfile.readline()<tab><tab><IF-STMT><tab><tab><tab>line = line.split()<tab><tab><tab>num_points = int(line[2])<tab><tab>elif b""property"" in line:<tab><tab><tab>line = line.split()<tab><tab><tab>properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))<tab>return num_points, properties","if b""element"" in line :",149
2150,"def __codeanalysis_settings_changed(self, current_finfo):<tab>if self.data:<tab><tab>run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled<tab><tab>for finfo in self.data:<tab><tab><tab>self.__update_editor_margins(finfo.editor)<tab><tab><tab>finfo.cleanup_analysis_results()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if current_finfo is not finfo:<tab><tab><tab><tab><tab>finfo.run_code_analysis(run_pyflakes, run_pep8)",if ( run_pyflakes or run_pep8 ) and current_finfo is not None :,148
2151,"def __modules(self):<tab>raw_output = self.__module_avail_output().decode(""utf-8"")<tab>for line in StringIO(raw_output):<tab><tab>line = line and line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>line_modules = line.split()<tab><tab>for module in line_modules:<tab><tab><tab>if module.endswith(self.default_indicator):<tab><tab><tab><tab>module = module[0 : -len(self.default_indicator)].strip()<tab><tab><tab>module_parts = module.split(""/"")<tab><tab><tab>module_version = None<tab><tab><tab>if len(module_parts) == 2:<tab><tab><tab><tab>module_version = module_parts[1]<tab><tab><tab>module_name = module_parts[0]<tab><tab><tab>yield module_name, module_version","if not line or line . startswith ( ""-"" ) :",199
2152,"def _set_trailing_size(self, size):<tab>if self.is_free():<tab><tab>next_chunk = self.next_chunk()<tab><tab><IF-STMT><tab><tab><tab>self.state.memory.store(next_chunk.base, size, self.state.arch.bytes)",if next_chunk is not None :,74
2153,"def _execute_for_all_tables(self, app, bind, operation, skip_tables=False):<tab>app = self.get_app(app)<tab>if bind == ""__all__"":<tab><tab>binds = [None] + list(app.config.get(""SQLALCHEMY_BINDS"") or ())<tab>elif isinstance(bind, string_types) or bind is None:<tab><tab>binds = [bind]<tab>else:<tab><tab>binds = bind<tab>for bind in binds:<tab><tab>extra = {}<tab><tab><IF-STMT><tab><tab><tab>tables = self.get_tables_for_bind(bind)<tab><tab><tab>extra[""tables""] = tables<tab><tab>op = getattr(self.Model.metadata, operation)<tab><tab>op(bind=self.get_engine(app, bind), **extra)",if not skip_tables :,191
2154,"def getFileName():<tab>extension = "".json""<tab>file = ""%s-stats"" % self.clusterName<tab>counter = 0<tab>while True:<tab><tab>suffix = str(counter).zfill(3) + extension<tab><tab>fullName = os.path.join(self.statsPath, file + suffix)<tab><tab><IF-STMT><tab><tab><tab>return fullName<tab><tab>counter += 1",if not os . path . exists ( fullName ) :,98
2155,def logic():<tab># direction<tab>if goRight == ACTIVE:<tab><tab>dir.next = DirType.RIGHT<tab><tab>run.next = True<tab>elif goLeft == ACTIVE:<tab><tab>dir.next = DirType.LEFT<tab><tab>run.next = True<tab># stop<tab>if stop == ACTIVE:<tab><tab>run.next = False<tab># counter action<tab>if run:<tab><tab><IF-STMT><tab><tab><tab>q.next[4:1] = q[3:]<tab><tab><tab>q.next[0] = not q[3]<tab><tab>else:<tab><tab><tab>q.next[3:] = q[4:1]<tab><tab><tab>q.next[3] = not q[0],if dir == DirType . LEFT :,176
2156,"def test_broadcast(self):<tab>""""""Test example broadcast functionality.""""""<tab>self.create_lang_connection(""1000000000"", ""en"")<tab>self.create_lang_connection(""1000000001"", ""en"")<tab>self.create_lang_connection(""1000000002"", ""en"")<tab>self.create_lang_connection(""1000000003"", ""es"")<tab>self.create_lang_connection(""1000000004"", ""es"")<tab>app.lang_broadcast()<tab>self.assertEqual(2, len(self.outbound))<tab>for message in self.outbound:<tab><tab>if message.text == ""hello"":<tab><tab><tab>self.assertEqual(3, len(message.connections))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(2, len(message.connections))","elif message . text == ""hola"" :",187
2157,"def get_ovf_env(dirname):<tab>env_names = (""ovf-env.xml"", ""ovf_env.xml"", ""OVF_ENV.XML"", ""OVF-ENV.XML"")<tab>for fname in env_names:<tab><tab>full_fn = os.path.join(dirname, fname)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>contents = util.load_file(full_fn)<tab><tab><tab><tab>return (fname, contents)<tab><tab><tab>except Exception:<tab><tab><tab><tab>util.logexc(LOG, ""Failed loading ovf file %s"", full_fn)<tab>return (None, False)",if os . path . isfile ( full_fn ) :,164
2158,"def _calc_offsets_children(self, offset, is_last):<tab>if self.elems:<tab><tab>elem_last = self.elems[-1]<tab><tab>for elem in self.elems:<tab><tab><tab>offset = elem._calc_offsets(offset, (elem is elem_last))<tab><tab>offset += _BLOCK_SENTINEL_LENGTH<tab>elif not self.props or self.id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL:<tab><tab><IF-STMT><tab><tab><tab>offset += _BLOCK_SENTINEL_LENGTH<tab>return offset",if not is_last :,134
2159,"def publish_state(cls, payload, state):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if state == action_constants.LIVEACTION_STATUS_REQUESTED:<tab><tab><tab><tab>cls.process(payload)<tab><tab><tab>else:<tab><tab><tab><tab>worker.get_worker().process(payload)<tab>except Exception:<tab><tab>traceback.print_exc()<tab><tab>print(payload)","if isinstance ( payload , LiveActionDB ) :",99
2160,"def log_predictive_density(self, x_test, y_test, Y_metadata=None):<tab>if isinstance(x_test, list):<tab><tab>x_test, y_test, ind = util.multioutput.build_XY(x_test, y_test)<tab><tab><IF-STMT><tab><tab><tab>Y_metadata = {""output_index"": ind, ""trials"": np.ones(ind.shape)}<tab>return super(MultioutputGP, self).log_predictive_density(x_test, y_test, Y_metadata)",if Y_metadata is None :,131
2161,"def minimalBases(classes):<tab>""""""Reduce a list of base classes to its ordered minimum equivalent""""""<tab>if not __python3:  # pragma: no cover<tab><tab>classes = [c for c in classes if c is not ClassType]<tab>candidates = []<tab>for m in classes:<tab><tab>for n in classes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># m has no subclasses in 'classes'<tab><tab><tab>if m in candidates:<tab><tab><tab><tab>candidates.remove(m)  # ensure that we're later in the list<tab><tab><tab>candidates.append(m)<tab>return candidates","if issubclass ( n , m ) and m is not n :",160
2162,"def apply(self, operations, rotations=None, **kwargs):<tab>rotations = rotations or []<tab># apply the circuit operations<tab>for i, operation in enumerate(operations):<tab><tab><IF-STMT><tab><tab><tab>raise DeviceError(<tab><tab><tab><tab>""Operation {} cannot be used after other Operations have already been applied ""<tab><tab><tab><tab>""on a {} device."".format(operation.name, self.short_name)<tab><tab><tab>)<tab>for operation in operations:<tab><tab>self._apply_operation(operation)<tab># store the pre-rotated state<tab>self._pre_rotated_state = self._state<tab># apply the circuit rotations<tab>for operation in rotations:<tab><tab>self._apply_operation(operation)","if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :",186
2163,"def __str__(self):<tab>txt = str(self._called)<tab>if self.call_gas or self.call_value:<tab><tab>gas = f""gas: {self.call_gas}"" if self.call_gas else """"<tab><tab>value = f""value: {self.call_value}"" if self.call_value else """"<tab><tab>salt = f""salt: {self.call_salt}"" if self.call_salt else """"<tab><tab><IF-STMT><tab><tab><tab>options = [gas, value, salt]<tab><tab><tab>txt += ""{"" + "","".join([o for o in options if o != """"]) + ""}""<tab>return txt + ""("" + "","".join([str(a) for a in self._arguments]) + "")""",if gas or value or salt :,183
2164,"def pop(self):<tab>""""""Pop a nonterminal.  (Internal)""""""<tab>popdfa, popstate, popnode = self.stack.pop()<tab>newnode = self.convert(self.grammar, popnode)<tab>if newnode is not None:<tab><tab><IF-STMT><tab><tab><tab>dfa, state, node = self.stack[-1]<tab><tab><tab>node.children.append(newnode)<tab><tab>else:<tab><tab><tab>self.rootnode = newnode",if self . stack :,112
2165,"def pollpacket(self, wait):<tab>self._stage0()<tab>if len(self.buffer) < self.bufneed:<tab><tab>r, w, x = select.select([self.sock.fileno()], [], [], wait)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>try:<tab><tab><tab>s = self.sock.recv(BUFSIZE)<tab><tab>except socket.error:<tab><tab><tab>raise EOFError<tab><tab>if len(s) == 0:<tab><tab><tab>raise EOFError<tab><tab>self.buffer += s<tab><tab>self._stage0()<tab>return self._stage1()",if len ( r ) == 0 :,148
2166,"def increaseToolReach(self):<tab>if self.draggingFace is not None:<tab><tab>d = (1, -1)[self.draggingFace & 1]<tab><tab><IF-STMT>  # xxxxx y<tab><tab><tab>d = -d<tab><tab>self.draggingY += d<tab><tab>x, y, z = self.editor.mainViewport.cameraPosition<tab><tab>pos = [x, y, z]<tab><tab>pos[self.draggingFace >> 1] += d<tab><tab>self.editor.mainViewport.cameraPosition = tuple(pos)<tab>else:<tab><tab>self.cloneCameraDistance = self.editor._incrementReach(self.cloneCameraDistance)<tab>return True",if self . draggingFace >> 1 != 1 :,172
2167,"def selectionToChunks(self, remove=False, add=False):<tab>box = self.selectionBox()<tab>if box:<tab><tab>if box == self.level.bounds:<tab><tab><tab>self.selectedChunks = set(self.level.allChunks)<tab><tab><tab>return<tab><tab>selectedChunks = self.selectedChunks<tab><tab>boxedChunks = set(box.chunkPositions)<tab><tab>if boxedChunks.issubset(selectedChunks):<tab><tab><tab>remove = True<tab><tab><IF-STMT><tab><tab><tab>selectedChunks.difference_update(boxedChunks)<tab><tab>else:<tab><tab><tab>selectedChunks.update(boxedChunks)<tab>self.selectionTool.selectNone()",if remove and not add :,158
2168,"def __init__(self, *args, **kwargs):<tab>super(ProjectForm, self).__init__(*args, **kwargs)<tab>if self.instance.id:<tab><tab><IF-STMT><tab><tab><tab>self.fields[""localfiletype""].widget.attrs[""disabled""] = True<tab><tab><tab>self.fields[""localfiletype""].required = False<tab><tab>if (<tab><tab><tab>self.instance.treestyle != ""auto""<tab><tab><tab>and self.instance.translationproject_set.count()<tab><tab><tab>and self.instance.treestyle == self.instance._detect_treestyle()<tab><tab>):<tab><tab><tab>self.fields[""treestyle""].widget.attrs[""disabled""] = True<tab><tab><tab>self.fields[""treestyle""].required = False",if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,193
2169,"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab>if arg is None:<tab><tab><tab>continue<tab><tab>if isinstance(arg, bytes):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab>if return_type is bytes:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type",if return_type is str :,186
2170,"def deleteDuplicates(gadgets, callback=None):<tab>toReturn = []<tab>inst = set()<tab>count = 0<tab>added = False<tab>len_gadgets = len(gadgets)<tab>for i, gadget in enumerate(gadgets):<tab><tab>inst.add(gadget._gadget)<tab><tab>if len(inst) > count:<tab><tab><tab>count = len(inst)<tab><tab><tab>toReturn.append(gadget)<tab><tab><tab>added = True<tab><tab><IF-STMT><tab><tab><tab>callback(gadget, added, float(i + 1) / (len_gadgets))<tab><tab><tab>added = False<tab>return toReturn",if callback :,164
2171,"def send_all(self, data: bytes):<tab>with self._conflict_detector:<tab><tab><IF-STMT><tab><tab><tab>raise _core.ClosedResourceError(""this pipe is already closed"")<tab><tab>if not data:<tab><tab><tab>await _core.checkpoint()<tab><tab><tab>return<tab><tab>try:<tab><tab><tab>written = await _core.write_overlapped(self._handle_holder.handle, data)<tab><tab>except BrokenPipeError as ex:<tab><tab><tab>raise _core.BrokenResourceError from ex<tab><tab># By my reading of MSDN, this assert is guaranteed to pass so long<tab><tab># as the pipe isn't in nonblocking mode, but... let's just<tab><tab># double-check.<tab><tab>assert written == len(data)",if self . _handle_holder . closed :,181
2172,"def setup_parameter_node(self, param_node):<tab>if param_node.bl_idname == ""SvNumberNode"":<tab><tab><IF-STMT><tab><tab><tab>value = self.sv_get()[0][0]<tab><tab><tab>print(""V"", value)<tab><tab><tab>if isinstance(value, int):<tab><tab><tab><tab>param_node.selected_mode = ""int""<tab><tab><tab><tab>param_node.int_ = value<tab><tab><tab>elif isinstance(value, float):<tab><tab><tab><tab>param_node.selected_mode = ""float""<tab><tab><tab><tab>param_node.float_ = value",if self . use_prop or self . get_prop_name ( ) :,156
2173,"def collect_active_inst_idx_list(inst_beams, word_prob, inst_idx_to_position_map):<tab>active_inst_idx_list = []<tab>for inst_idx, inst_position in inst_idx_to_position_map.items():<tab><tab>is_inst_complete = inst_beams[inst_idx].advance(word_prob[inst_position])<tab><tab><IF-STMT><tab><tab><tab>active_inst_idx_list += [inst_idx]<tab>return active_inst_idx_list",if not is_inst_complete :,129
2174,"def compare_member_req_resp_without_key(self, request, response):<tab>for user_response in resp_json(response)[""data""]:<tab><tab>for user_request in request:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert user_request[""role""] == user_response[""role""]","if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :",86
2175,"def __init__(self, dir):<tab>self.module_names = set()<tab>for name in os.listdir(dir):<tab><tab>if name.endswith("".py""):<tab><tab><tab>self.module_names.add(name[:-3])<tab><tab><IF-STMT><tab><tab><tab>self.module_names.add(name)","elif ""."" not in name :",79
2176,"def _read_filter(self, data):<tab>if data:<tab><tab>if self.expected_inner_sha256:<tab><tab><tab>self.inner_sha.update(data)<tab><tab><IF-STMT><tab><tab><tab>self.inner_md5.update(data)<tab>return data",if self . expected_inner_md5sum :,76
2177,"def _p_basicstr_content(s, content=_basicstr_re):<tab>res = []<tab>while True:<tab><tab>res.append(s.expect_re(content).group(0))<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if s.consume_re(_newline_esc_re):<tab><tab><tab>pass<tab><tab>elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re):<tab><tab><tab>res.append(_chr(int(s.last().group(1), 16)))<tab><tab>else:<tab><tab><tab>s.expect_re(_escapes_re)<tab><tab><tab>res.append(_escapes[s.last().group(0)])<tab>return """".join(res)","if not s . consume ( ""\\"" ) :",179
2178,"def process_response(self, request, response):<tab>if (<tab><tab>response.status_code == 404<tab><tab>and request.path_info.endswith(""/"")<tab><tab>and not is_valid_path(request.path_info)<tab><tab>and is_valid_path(request.path_info[:-1])<tab>):<tab><tab># Use request.path because we munged app/locale in path_info.<tab><tab>newurl = request.path[:-1]<tab><tab><IF-STMT><tab><tab><tab>with safe_query_string(request):<tab><tab><tab><tab>newurl += ""?"" + request.META.get(""QUERY_STRING"", """")<tab><tab>return HttpResponsePermanentRedirect(newurl)<tab>else:<tab><tab>return response",if request . GET :,171
2179,"def convertDict(obj):<tab>obj = dict(obj)<tab>for k, v in obj.items():<tab><tab>del obj[k]<tab><tab><IF-STMT><tab><tab><tab>k = dumps(k)<tab><tab><tab># Keep track of which keys need to be decoded when loading.<tab><tab><tab>if Types.KEYS not in obj:<tab><tab><tab><tab>obj[Types.KEYS] = []<tab><tab><tab>obj[Types.KEYS].append(k)<tab><tab>obj[k] = convertObjects(v)<tab>return obj","if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :",137
2180,"def __repr__(self):<tab>if self._in_repr:<tab><tab>return ""<recursion>""<tab>try:<tab><tab>self._in_repr = True<tab><tab><IF-STMT><tab><tab><tab>status = ""computed, ""<tab><tab><tab>if self.error() is None:<tab><tab><tab><tab>if self.value() is self:<tab><tab><tab><tab><tab>status += ""= self""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>status += ""= "" + repr(self.value())<tab><tab><tab>else:<tab><tab><tab><tab>status += ""error = "" + repr(self.error())<tab><tab>else:<tab><tab><tab>status = ""isn't computed""<tab><tab>return ""%s (%s)"" % (type(self), status)<tab>finally:<tab><tab>self._in_repr = False",if self . is_computed ( ) :,189
2181,"def allocate_network(ipv=""ipv4""):<tab>global dtcd_uuid<tab>global network_pool<tab>global allocations<tab>network = None<tab>try:<tab><tab>cx = httplib.HTTPConnection(""localhost:7623"")<tab><tab>cx.request(""POST"", ""/v1/network/%s/"" % ipv, body=dtcd_uuid)<tab><tab>resp = cx.getresponse()<tab><tab><IF-STMT><tab><tab><tab>network = netaddr.IPNetwork(resp.read().decode(""utf-8""))<tab><tab>cx.close()<tab>except Exception:<tab><tab>pass<tab>if network is None:<tab><tab>network = network_pool[ipv].pop()<tab><tab>allocations[network] = True<tab>return network",if resp . status == 200 :,170
2182,"def change_args_to_dict(string):<tab>if string is None:<tab><tab>return None<tab>ans = []<tab>strings = string.split(""\n"")<tab>ind = 1<tab>start = 0<tab>while ind <= len(strings):<tab><tab>if ind < len(strings) and strings[ind].startswith("" ""):<tab><tab><tab>ind += 1<tab><tab>else:<tab><tab><tab>if start < ind:<tab><tab><tab><tab>ans.append(""\n"".join(strings[start:ind]))<tab><tab><tab>start = ind<tab><tab><tab>ind += 1<tab>d = {}<tab>for line in ans:<tab><tab><IF-STMT><tab><tab><tab>lines = line.split("":"")<tab><tab><tab>d[lines[0]] = lines[1].strip()<tab>return d","if "":"" in line and len ( line ) > 0 :",188
2183,"def kill_members(members, sig, hosts=nodes):<tab>for member in sorted(members):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""killing %s"" % member)<tab><tab><tab>proc = hosts[member][""proc""]<tab><tab><tab># Not sure if cygwin makes sense here...<tab><tab><tab>if sys.platform in (""win32"", ""cygwin""):<tab><tab><tab><tab>os.kill(proc.pid, signal.CTRL_C_EVENT)<tab><tab><tab>else:<tab><tab><tab><tab>os.kill(proc.pid, sig)<tab><tab>except OSError:<tab><tab><tab>if ha_tools_debug:<tab><tab><tab><tab>print(""%s already dead?"" % member)",if ha_tools_debug :,172
2184,"def check(self):<tab>for path in self.paths:<tab><tab>response = self.http_request(<tab><tab><tab>method=""GET"",<tab><tab><tab>path=path,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if any(<tab><tab><tab>map(<tab><tab><tab><tab>lambda x: x in response.text,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>""report.db.server.name"",<tab><tab><tab><tab><tab>""report.db.server.sa.pass"",<tab><tab><tab><tab><tab>""report.db.server.user.pass"",<tab><tab><tab><tab>],<tab><tab><tab>)<tab><tab>):<tab><tab><tab>self.valid = path<tab><tab><tab>return True  # target is vulnerable<tab>return False  # target not vulnerable",if response is None :,184
2185,"def get_to_download_runs_ids(session, headers):<tab>last_date = 0<tab>result = []<tab>while 1:<tab><tab>r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers)<tab><tab>if r.ok:<tab><tab><tab>run_logs = r.json()[""data""][""records""]<tab><tab><tab>result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs])<tab><tab><tab>last_date = r.json()[""data""][""lastTimestamp""]<tab><tab><tab>since_time = datetime.utcfromtimestamp(last_date / 1000)<tab><tab><tab>print(f""pares keep ids data since {since_time}"")<tab><tab><tab>time.sleep(1)  # spider rule<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return result",if not last_date :,199
2186,"def button_press_cb(self, tdw, event):<tab>self._update_zone_and_cursors(tdw, event.x, event.y)<tab>if self._zone in (_EditZone.CREATE_FRAME, _EditZone.REMOVE_FRAME):<tab><tab>button = event.button<tab><tab><IF-STMT><tab><tab><tab>self._click_info = (button, self._zone)<tab><tab><tab>return False<tab>return super(FrameEditMode, self).button_press_cb(tdw, event)",if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,135
2187,"def first_timestep():<tab>assignment = self.has_previous.assign(<tab><tab>value=tf_util.constant(value=True, dtype=""bool""), read_value=False<tab>)<tab>with tf.control_dependencies(control_inputs=(assignment,)):<tab><tab><IF-STMT><tab><tab><tab>current = x<tab><tab>else:<tab><tab><tab>current = tf.expand_dims(input=x, axis=(self.axis + 1))<tab><tab>multiples = tuple(<tab><tab><tab>self.length if dims == self.axis + 1 else 1<tab><tab><tab>for dims in range(self.output_spec().rank + 1)<tab><tab>)<tab><tab>return tf.tile(input=current, multiples=multiples)",if self . concatenate :,167
2188,"def main() -> None:<tab>onefuzz = Onefuzz()<tab>jobs = onefuzz.jobs.list()<tab>for job in jobs:<tab><tab>print(<tab><tab><tab>""job:"",<tab><tab><tab>str(job.job_id)[:8],<tab><tab><tab>"":"".join([job.config.project, job.config.name, job.config.build]),<tab><tab>)<tab><tab>for task in onefuzz.tasks.list(job_id=job.job_id):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>print(<tab><tab><tab><tab>""<tab>"",<tab><tab><tab><tab>str(task.task_id)[:8],<tab><tab><tab><tab>task.config.task.type,<tab><tab><tab><tab>task.config.task.target_exe,<tab><tab><tab>)","if task . state in [ ""stopped"" , ""stopping"" ] :",200
2189,"def update_stack(self, full_name, template_url, parameters, tags):<tab>""""""Updates an existing stack in CloudFormation.""""""<tab>try:<tab><tab>logger.info(""Attempting to update stack %s."", full_name)<tab><tab>self.conn.cloudformation.update_stack(<tab><tab><tab>full_name,<tab><tab><tab>template_url=template_url,<tab><tab><tab>parameters=parameters,<tab><tab><tab>tags=tags,<tab><tab><tab>capabilities=[""CAPABILITY_IAM""],<tab><tab>)<tab><tab>return SUBMITTED<tab>except BotoServerError as e:<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Stack %s did not change, not updating."", full_name)<tab><tab><tab>return SKIPPED<tab><tab>raise","if ""No updates are to be performed."" in e . message :",183
2190,"def header_tag_files(env, files, legal_header, script_files=False):<tab>""""""Apply the legal_header to the list of files""""""<tab>try:<tab><tab>import apply_legal_header<tab>except:<tab><tab>xbc.cdie(""XED ERROR: mfile.py could not find scripts directory"")<tab>for g in files:<tab><tab>print(""G: "", g)<tab><tab>for f in mbuild.glob(g):<tab><tab><tab>print(""F: "", f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>apply_legal_header.apply_header_to_data_file(legal_header, f)<tab><tab><tab>else:<tab><tab><tab><tab>apply_legal_header.apply_header_to_source_file(legal_header, f)",if script_files :,186
2191,"def cleanDataCmd(cmd):<tab>newcmd = ""AbracadabrA ** <?php ""<tab>if cmd[:6] != ""php://"":<tab><tab>if reverseConn not in cmd:<tab><tab><tab>cmds = cmd.split(""&"")<tab><tab><tab>for c in cmds:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>newcmd += ""system('%s');"" % c<tab><tab>else:<tab><tab><tab>b64cmd = base64.b64encode(cmd)<tab><tab><tab>newcmd += ""system(base64_decode('%s'));"" % b64cmd<tab>else:<tab><tab>newcmd += cmd[6:]<tab>newcmd += ""?> **""<tab>return newcmd",if len ( c ) > 0 :,170
2192,"def test_form(self):<tab>n_qubits = 6<tab>random_operator = get_fermion_operator(random_interaction_operator(n_qubits))<tab>chemist_operator = chemist_ordered(random_operator)<tab>for term, _ in chemist_operator.terms.items():<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.assertTrue(term[0][1])<tab><tab><tab>self.assertTrue(term[2][1])<tab><tab><tab>self.assertFalse(term[1][1])<tab><tab><tab>self.assertFalse(term[3][1])<tab><tab><tab>self.assertTrue(term[0][0] > term[2][0])<tab><tab><tab>self.assertTrue(term[1][0] > term[3][0])",if len ( term ) == 2 or not len ( term ) :,199
2193,"def do(server, handler, config, modargs):<tab>data = []<tab>clients = server.get_clients(handler.default_filter)<tab>if not clients:<tab><tab>return<tab>for client in clients:<tab><tab>tags = config.tags(client.node())<tab><tab><IF-STMT><tab><tab><tab>tags.remove(*modargs.remove)<tab><tab>if modargs.add:<tab><tab><tab>tags.add(*modargs.add)<tab><tab>data.append({""ID"": client.node(), ""TAGS"": tags})<tab>config.save(project=modargs.write_project, user=modargs.write_user)<tab>handler.display(Table(data))",if modargs . remove :,160
2194,"def validate(self):<tab>if self.data.get(""state"") == ""enabled"":<tab><tab><IF-STMT><tab><tab><tab>raise PolicyValidationError(<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>""redshift logging enablement requires `bucket` ""<tab><tab><tab><tab><tab>""and `prefix` specification on %s"" % (self.manager.data,)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return self","if ""bucket"" not in self . data :",104
2195,"def renumber(self, x1, y1, x2, y2, dx, dy):<tab>out = []<tab>for part in re.split(""(\w+)"", self.formula):<tab><tab>m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part)<tab><tab><IF-STMT><tab><tab><tab>sx, sy = m.groups()<tab><tab><tab>x = colname2num(sx)<tab><tab><tab>y = int(sy)<tab><tab><tab>if x1 <= x <= x2 and y1 <= y <= y2:<tab><tab><tab><tab>part = cellname(x + dx, y + dy)<tab><tab>out.append(part)<tab>return FormulaCell("""".join(out), self.fmt, self.alignment)",if m is not None :,179
2196,"def update_sysconfig_file(fn, adjustments, allow_empty=False):<tab>if not adjustments:<tab><tab>return<tab>(exists, contents) = read_sysconfig_file(fn)<tab>updated_am = 0<tab>for (k, v) in adjustments.items():<tab><tab>if v is None:<tab><tab><tab>continue<tab><tab>v = str(v)<tab><tab>if len(v) == 0 and not allow_empty:<tab><tab><tab>continue<tab><tab>contents[k] = v<tab><tab>updated_am += 1<tab>if updated_am:<tab><tab>lines = [<tab><tab><tab>str(contents),<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>lines.insert(0, util.make_header())<tab><tab>util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",if not exists :,198
2197,"def getElement(self, aboutUri, namespace, name):<tab>for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""):<tab><tab>if desc.getAttributeNS(RDF_NAMESPACE, ""about"") == aboutUri:<tab><tab><tab>attr = desc.getAttributeNodeNS(namespace, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield attr<tab><tab><tab>for element in desc.getElementsByTagNameNS(namespace, name):<tab><tab><tab><tab>yield element",if attr != None :,113
2198,"def get_store_name_from_connection_string(connection_string):<tab>if is_valid_connection_string(connection_string):<tab><tab>segments = dict(seg.split(""="", 1) for seg in connection_string.split("";""))<tab><tab>endpoint = segments.get(""Endpoint"")<tab><tab><IF-STMT><tab><tab><tab>return endpoint.split(""//"")[1].split(""."")[0]<tab>return None",if endpoint :,93
2199,"def insertLoopTemplate(self, layout):<tab>col = layout.column(align=True)<tab>for socket in self.activeNode.outputs:<tab><tab><IF-STMT><tab><tab><tab>props = col.operator(<tab><tab><tab><tab>""an.insert_loop_for_iterator"",<tab><tab><tab><tab>text=""Loop through {}"".format(repr(socket.getDisplayedName())),<tab><tab><tab><tab>icon=""MOD_ARRAY"",<tab><tab><tab>)<tab><tab><tab>props.nodeIdentifier = self.activeNode.identifier<tab><tab><tab>props.socketIndex = socket.getIndex()",if not socket . hide and isList ( socket . bl_idname ) :,145
2200,"def do_task(self, task):<tab>self.running_task += 1<tab>result = yield gen.Task(self.fetcher.fetch, task)<tab>type, task, response = result.args<tab>self.processor.on_task(task, response)<tab># do with message<tab>while not self.processor.inqueue.empty():<tab><tab>_task, _response = self.processor.inqueue.get()<tab><tab>self.processor.on_task(_task, _response)<tab># do with results<tab>while not self.processor.result_queue.empty():<tab><tab>_task, _result = self.processor.result_queue.get()<tab><tab><IF-STMT><tab><tab><tab>self.result_worker.on_result(_task, _result)<tab>self.running_task -= 1",if self . result_worker :,191
2201,"def _parse_config_result(data):<tab>command_list = "" ; "".join([x.strip() for x in data[0]])<tab>config_result = data[1]<tab>if isinstance(config_result, list):<tab><tab>result = """"<tab><tab><IF-STMT><tab><tab><tab>for key in config_result[0]:<tab><tab><tab><tab>result += config_result[0][key]<tab><tab><tab>config_result = result<tab><tab>else:<tab><tab><tab>config_result = config_result[0]<tab>return [command_list, config_result]","if isinstance ( config_result [ 0 ] , dict ) :",142
2202,"def load_api_handler(self, mod_name):<tab>for name, hdl in API_HANDLERS:<tab><tab>name = name.lower()<tab><tab><IF-STMT><tab><tab><tab>handler = self.mods.get(name)<tab><tab><tab>if not handler:<tab><tab><tab><tab>handler = hdl(self.emu)<tab><tab><tab><tab>self.mods.update({name: handler})<tab><tab><tab>return handler<tab>return None",if mod_name and name == mod_name . lower ( ) :,113
2203,def heal(self):<tab>if not self.doctors:<tab><tab>return<tab>proc_ids = self._get_process_ids()<tab>for proc_id in proc_ids:<tab><tab># get proc every time for latest state<tab><tab>proc = PipelineProcess.objects.get(id=proc_id)<tab><tab>if not proc.is_alive or proc.is_frozen:<tab><tab><tab>continue<tab><tab>for dr in self.doctors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dr.cure(proc)<tab><tab><tab><tab>break,if dr . confirm ( proc ) :,138
2204,"def __new__(cls, *args, **kwargs):<tab>if len(args) == 1:<tab><tab>if len(kwargs):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""You can either use {} with one positional argument or with keyword arguments, not both."".format(<tab><tab><tab><tab><tab>cls.__name__<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return super().__new__(cls)<tab><tab>if isinstance(args[0], cls):<tab><tab><tab>return cls<tab>return super().__new__(cls, *args, **kwargs)",if not args [ 0 ] :,137
2205,"def __lt__(self, other):<tab># 0: clock 1: timestamp 3: process id<tab>try:<tab><tab>A, B = self[0], other[0]<tab><tab># uses logical clock value first<tab><tab><IF-STMT>  # use logical clock if available<tab><tab><tab>if A == B:  # equal clocks use lower process id<tab><tab><tab><tab>return self[2] < other[2]<tab><tab><tab>return A < B<tab><tab>return self[1] < other[1]  # ... or use timestamp<tab>except IndexError:<tab><tab>return NotImplemented",if A and B :,135
2206,"def _get_client(rp_mapping, resource_provider):<tab>for key, value in rp_mapping.items():<tab><tab>if str.lower(key) == str.lower(resource_provider):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return GeneralPrivateEndpointClient(<tab><tab><tab><tab><tab>key,<tab><tab><tab><tab><tab>value[""api_version""],<tab><tab><tab><tab><tab>value[""support_list_or_not""],<tab><tab><tab><tab><tab>value[""resource_get_api_version""],<tab><tab><tab><tab>)<tab><tab><tab>return value()<tab>raise CLIError(<tab><tab>""Resource type must be one of {}"".format("", "".join(rp_mapping.keys()))<tab>)","if isinstance ( value , dict ) :",165
2207,"def test_progressbar_format_pos(runner, pos, length):<tab>with _create_progress(length, length_known=length != 0, pos=pos) as progress:<tab><tab>result = progress.format_pos()<tab><tab><IF-STMT><tab><tab><tab>assert result == f""{pos}/{length}""<tab><tab>else:<tab><tab><tab>assert result == str(pos)",if progress . length_known :,91
2208,"def optimize(self, graph: Graph):<tab>MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE<tab>flag_changed = False<tab>for v in traverse.listup_variables(graph):<tab><tab>if not Placeholder.check_resolved(v.size):<tab><tab><tab>continue<tab><tab>height, width = TextureShape.get(v)<tab><tab>if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>flag_changed = True<tab><tab><tab>v.attributes.add(SplitTarget())<tab>return graph, flag_changed",if not v . has_attribute ( SplitTarget ) :,157
2209,"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += "".""<tab><tab><tab>elif col == BARRIER:<tab><tab><tab><tab>tmp += ""%""<tab><tab><tab>elif col == FOOD:<tab><tab><tab><tab>tmp += ""*""<tab><tab><tab>elif col == UNSEEN:<tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",if col == LAND :,199
2210,"def reset(self):<tab>logger.debug(""Arctic.reset()"")<tab>with self._lock:<tab><tab>if self.__conn is not None:<tab><tab><tab>self.__conn.close()<tab><tab><tab>self.__conn = None<tab><tab>for _, l in self._library_cache.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.debug(""Library reset() %s"" % l)<tab><tab><tab><tab>l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth","if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :",137
2211,"def add_cand_to_check(cands):<tab>for cand in cands:<tab><tab>x = cand.creator<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if x not in fan_out:<tab><tab><tab># `len(fan_out)` is in order to avoid comparing `x`<tab><tab><tab>heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x))<tab><tab>fan_out[x] += 1",if x is None :,111
2212,"def on_task_modify(self, task, config):<tab>for entry in task.entries:<tab><tab><IF-STMT><tab><tab><tab>size = entry[""torrent""].size / 1024 / 1024<tab><tab><tab>log.debug(""%s size: %s MB"" % (entry[""title""], size))<tab><tab><tab>entry[""content_size""] = size","if ""torrent"" in entry :",83
2213,"def get_measurements(self, pipeline, object_name, category):<tab>if self.get_categories(pipeline, object_name) == [category]:<tab><tab>results = []<tab><tab>if self.do_corr_and_slope:<tab><tab><tab>if object_name == ""Image"":<tab><tab><tab><tab>results += [""Correlation"", ""Slope""]<tab><tab><tab>else:<tab><tab><tab><tab>results += [""Correlation""]<tab><tab>if self.do_overlap:<tab><tab><tab>results += [""Overlap"", ""K""]<tab><tab>if self.do_manders:<tab><tab><tab>results += [""Manders""]<tab><tab>if self.do_rwc:<tab><tab><tab>results += [""RWC""]<tab><tab><IF-STMT><tab><tab><tab>results += [""Costes""]<tab><tab>return results<tab>return []",if self . do_costes :,195
2214,"def create_root(cls, site=None, title=""Root"", request=None, **kwargs):<tab>if not site:<tab><tab>site = Site.objects.get_current()<tab>root_nodes = cls.objects.root_nodes().filter(site=site)<tab>if not root_nodes:<tab><tab>article = Article()<tab><tab>revision = ArticleRevision(title=title, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>revision.set_from_request(request)<tab><tab>article.add_revision(revision, save=True)<tab><tab>article.save()<tab><tab>root = cls.objects.create(site=site, article=article)<tab><tab>article.add_object_relation(root)<tab>else:<tab><tab>root = root_nodes[0]<tab>return root",if request :,185
2215,"def get(self, key):<tab>filename = self._get_filename(key)<tab>try:<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>pickle_time = pickle.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pickle.load(f)<tab><tab><tab>else:<tab><tab><tab><tab>os.remove(filename)<tab><tab><tab><tab>return None<tab>except (IOError, OSError, pickle.PickleError):<tab><tab>return None",if pickle_time == 0 or pickle_time >= time ( ) :,122
2216,"def build_message(self, options, target):<tab>message = multipart.MIMEMultipart()<tab>for name, value in list(options.items()):<tab><tab><IF-STMT><tab><tab><tab>self.add_body(message, value)<tab><tab>elif name == ""EMAIL_ATTACHMENT"":<tab><tab><tab>self.add_attachment(message, value)<tab><tab>else:  # From, To, Subject, etc.<tab><tab><tab>self.set_option(message, name, value, target)<tab>return message","if name == ""EMAIL_BODY"" :",126
2217,"def updateVar(name, data, mode=None):<tab>if mode:<tab><tab><IF-STMT><tab><tab><tab>core.config.globalVariables[name].append(data)<tab><tab>elif mode == ""add"":<tab><tab><tab>core.config.globalVariables[name].add(data)<tab>else:<tab><tab>core.config.globalVariables[name] = data","if mode == ""append"" :",91
2218,"def insert_errors(<tab>el,<tab>errors,<tab>form_id=None,<tab>form_index=None,<tab>error_class=""error"",<tab>error_creator=default_error_creator,):<tab>el = _find_form(el, form_id=form_id, form_index=form_index)<tab>for name, error in errors.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for error_el, message in _find_elements_for_name(el, name, error):<tab><tab><tab>assert isinstance(message, (basestring, type(None), ElementBase)), (<tab><tab><tab><tab>""Bad message: %r"" % message<tab><tab><tab>)<tab><tab><tab>_insert_error(error_el, message, error_class, error_creator)",if error is None :,190
2219,"def read(self, item, recursive=False, sort=False):<tab>item = _normalize_path(item)<tab>if item in self._store:<tab><tab><IF-STMT><tab><tab><tab>del self._store[item]<tab><tab><tab>raise KeyError(item)<tab><tab>return PathResult(item, value=self._store[item])<tab>else:<tab><tab>return self._read_dir(item, recursive=recursive, sort=sort)",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,121
2220,"def _stash_splitter(states):<tab>keep, split = [], []<tab>if state_func is not None:<tab><tab>for s in states:<tab><tab><tab>ns = state_func(s)<tab><tab><tab>if isinstance(ns, SimState):<tab><tab><tab><tab>split.append(ns)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>split.extend(ns)<tab><tab><tab>else:<tab><tab><tab><tab>split.append(s)<tab>if stash_func is not None:<tab><tab>split = stash_func(states)<tab>if to_stash is not stash:<tab><tab>keep = states<tab>return keep, split","elif isinstance ( ns , ( list , tuple , set ) ) :",163
2221,"def run(self):<tab>while self.runflag:<tab><tab><IF-STMT><tab><tab><tab>with self.lock:<tab><tab><tab><tab>tasks = list(self.queue)<tab><tab><tab><tab>self.queue.clear()<tab><tab><tab>while len(tasks) > 0:<tab><tab><tab><tab>pathname, remotepath = tasks.pop(0)<tab><tab><tab><tab>self.bcloud_app.upload_page.add_bg_task(pathname, remotepath)<tab><tab><tab>self.last = time()<tab><tab>else:<tab><tab><tab>sleep(1)",if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,142
2222,"def _append_patch(self, patch_dir, patch_files):<tab>for patch in patch_files:<tab><tab><IF-STMT><tab><tab><tab>tmp = patch<tab><tab><tab>patch = {}<tab><tab><tab>for key in tmp.keys():<tab><tab><tab><tab>patch[os.path.join(patch_dir, key)] = tmp[key]<tab><tab><tab>self.patches.append(patch)<tab><tab>else:<tab><tab><tab>self.patches.append(os.path.join(patch_dir, patch))",if type ( patch ) is dict :,125
2223,"def __remote_port(self):<tab>port = 22<tab>if self.git_has_remote:<tab><tab>m = re.match(r""^(.*?)?@([^/:]*):?([0-9]+)?"", self.git_remote.url)<tab><tab>if m:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>port = m.group(3)<tab>return int(port)",if m . group ( 3 ) :,94
2224,"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper:<tab># Prefer creating a new helper when at least one kwarg is specified.<tab>prefer_new = len(kwargs) > 0<tab>kwargs.update(infer_mode=infer_mode)<tab>is_training = not infer_mode if infer_mode is not None else self.training<tab>helper = self._train_helper if is_training else self._infer_helper<tab>if prefer_new or helper is None:<tab><tab>helper = self.create_helper(**kwargs)<tab><tab><IF-STMT><tab><tab><tab>self._train_helper = helper<tab><tab>elif not is_training and self._infer_helper is None:<tab><tab><tab>self._infer_helper = helper<tab>return helper",if is_training and self . _train_helper is None :,195
2225,"def flushChangeClassifications(self, schedulerid, less_than=None):<tab>if less_than is not None:<tab><tab>classifications = self.classifications.setdefault(schedulerid, {})<tab><tab>for changeid in list(classifications):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del classifications[changeid]<tab>else:<tab><tab>self.classifications[schedulerid] = {}<tab>return defer.succeed(None)",if changeid < less_than :,107
2226,"def pid_from_name(name):<tab>processes = []<tab>for pid in os.listdir(""/proc""):<tab><tab>try:<tab><tab><tab>pid = int(pid)<tab><tab><tab>pname, cmdline = SunProcess._name_args(pid)<tab><tab><tab>if name in pname:<tab><tab><tab><tab>return pid<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pid<tab><tab>except:<tab><tab><tab>pass<tab>raise ProcessException(""No process with such name: %s"" % name)","if name in cmdline . split ( "" "" , 1 ) [ 0 ] :",126
2227,"def spew():<tab>seenUID = False<tab>start()<tab>for part in query:<tab><tab><IF-STMT><tab><tab><tab>seenUID = True<tab><tab>if part.type == ""body"":<tab><tab><tab>yield self.spew_body(part, id, msg, write, flush)<tab><tab>else:<tab><tab><tab>f = getattr(self, ""spew_"" + part.type)<tab><tab><tab>yield f(id, msg, write, flush)<tab><tab>if part is not query[-1]:<tab><tab><tab>space()<tab>if uid and not seenUID:<tab><tab>space()<tab><tab>yield self.spew_uid(id, msg, write, flush)<tab>finish()<tab>flush()","if part . type == ""uid"" :",174
2228,"def rx():<tab>while True:<tab><tab>rx_i = rep.recv()<tab><tab><IF-STMT><tab><tab><tab>rep.send(b""done"")<tab><tab><tab>break<tab><tab>rep.send(b""i"")","if rx_i == b""1000"" :",60
2229,"def test_search_incorrect_base_exception_1(self):<tab>self.connection_1c.bind()<tab>try:<tab><tab>result = self.connection_1c.search(<tab><tab><tab>""o=nonexistant"", ""(cn=*)"", search_scope=SUBTREE, attributes=[""cn"", ""sn""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>_, result = self.connection_1c.get_response(result)<tab><tab>self.fail(""exception not raised"")<tab>except LDAPNoSuchObjectResult:<tab><tab>pass",if not self . connection_1c . strategy . sync :,138
2230,"def value_from_datadict(self, data, files, prefix):<tab>count = int(data[""%s-count"" % prefix])<tab>values_with_indexes = []<tab>for i in range(0, count):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>values_with_indexes.append(<tab><tab><tab>(<tab><tab><tab><tab>int(data[""%s-%d-order"" % (prefix, i)]),<tab><tab><tab><tab>self.child_block.value_from_datadict(<tab><tab><tab><tab><tab>data, files, ""%s-%d-value"" % (prefix, i)<tab><tab><tab><tab>),<tab><tab><tab>)<tab><tab>)<tab>values_with_indexes.sort()<tab>return [v for (i, v) in values_with_indexes]","if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :",194
2231,"def _ensure_header_written(self, datasize):<tab>if not self._headerwritten:<tab><tab>if not self._nchannels:<tab><tab><tab>raise Error(""# channels not specified"")<tab><tab>if not self._sampwidth:<tab><tab><tab>raise Error(""sample width not specified"")<tab><tab><IF-STMT><tab><tab><tab>raise Error(""sampling rate not specified"")<tab><tab>self._write_header(datasize)",if not self . _framerate :,99
2232,def wait_til_ready(cls):<tab>while True:<tab><tab>now = time.time()<tab><tab>next_iteration = now // 1.0 + 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>await cls._clock.run_til(next_iteration)<tab><tab>await asyncio.sleep(1.0),if cls . connector . ready :,89
2233,"def lookup_actions(self, resp):<tab>actions = {}<tab>for action, conditions in self.actions.items():<tab><tab>for condition, opts in conditions:<tab><tab><tab>for key, val in condition:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if resp.match(key[:-1], val):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if not resp.match(key, val):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>actions[action] = opts<tab>return actions","if key [ - 1 ] == ""!"" :",138
2234,"def close(self, wait=True, abort=False):<tab>""""""Close the socket connection.""""""<tab>if not self.closed and not self.closing:<tab><tab>self.closing = True<tab><tab>self.server._trigger_event(""disconnect"", self.sid, run_async=False)<tab><tab>if not abort:<tab><tab><tab>self.send(packet.Packet(packet.CLOSE))<tab><tab>self.closed = True<tab><tab>self.queue.put(None)<tab><tab><IF-STMT><tab><tab><tab>self.queue.join()",if wait :,125
2235,"def model_parse(self):<tab>for name, submodel in self.model.named_modules():<tab><tab>for op_type in SUPPORTED_OP_TYPE:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.target_layer[name] = submodel<tab><tab><tab><tab>self.already_pruned[name] = 0","if isinstance ( submodel , op_type ) :",83
2236,"def pack_identifier(self):<tab>""""""Return a combined identifier for the whole pack if this has more than one episode.""""""<tab># Currently only supports ep mode<tab>if self.id_type == ""ep"":<tab><tab><IF-STMT><tab><tab><tab>return ""S%02dE%02d-E%02d"" % (<tab><tab><tab><tab>self.season,<tab><tab><tab><tab>self.episode,<tab><tab><tab><tab>self.episode + self.episodes - 1,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return self.identifier<tab>else:<tab><tab>return self.identifier",if self . episodes > 1 :,143
2237,"def on_data(res):<tab>if terminate.is_set():<tab><tab>return<tab>if args.strings and not args.no_content:<tab><tab>if type(res) == tuple:<tab><tab><tab>f, v = res<tab><tab><tab>if type(f) == unicode:<tab><tab><tab><tab>f = f.encode(""utf-8"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v = v.encode(""utf-8"")<tab><tab><tab>self.success(""{}: {}"".format(f, v))<tab><tab>elif not args.content_only:<tab><tab><tab>self.success(res)<tab>else:<tab><tab>self.success(res)",if type ( v ) == unicode :,158
2238,"def _enable_contours_changed(self, value):<tab>""""""Turns on and off the contours.""""""<tab>if self.module_manager is None:<tab><tab>return<tab>if value:<tab><tab>self.actor.inputs = [self.contour]<tab><tab><IF-STMT><tab><tab><tab>self.actor.mapper.scalar_mode = ""use_cell_data""<tab>else:<tab><tab>self.actor.inputs = [self.grid_plane]<tab><tab>self.actor.mapper.scalar_mode = ""default""<tab>self.render()",if self . contour . filled_contours :,139
2239,"def _apply_abs_paths(data, script_dir):<tab>for flag_data in data.values():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>default = flag_data.get(""default"")<tab><tab>if (<tab><tab><tab>not default<tab><tab><tab>or not isinstance(default, six.string_types)<tab><tab><tab>or os.path.sep not in default<tab><tab>):<tab><tab><tab>continue<tab><tab>abs_path = os.path.join(script_dir, default)<tab><tab>if os.path.exists(abs_path):<tab><tab><tab>flag_data[""default""] = abs_path","if not isinstance ( flag_data , dict ) :",153
2240,"def button_release(self, mapper):<tab>self.pressed = False<tab>if self.waiting_task and self.active is None and not self.action:<tab><tab># In HoldModifier, button released before timeout<tab><tab>mapper.cancel_task(self.waiting_task)<tab><tab>self.waiting_task = None<tab><tab><IF-STMT><tab><tab><tab>self.normalaction.button_press(mapper)<tab><tab><tab>mapper.schedule(0.02, self.normalaction.button_release)<tab>elif self.active:<tab><tab># Released held button<tab><tab>self.active.button_release(mapper)<tab><tab>self.active = None",if self . normalaction :,160
2241,"def goToPrevMarkedHeadline(self, event=None):<tab>""""""Select the next marked node.""""""<tab>c = self<tab>p = c.p<tab>if not p:<tab><tab>return<tab>p.moveToThreadBack()<tab>wrapped = False<tab>while 1:<tab><tab>if p and p.isMarked():<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>p.moveToThreadBack()<tab><tab>elif wrapped:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>wrapped = True<tab><tab><tab>p = c.rootPosition()<tab>if not p:<tab><tab>g.blue(""done"")<tab>c.treeSelectHelper(p)  # Sets focus.",elif p :,164
2242,"def status(self, name, error=""No matching script logs found""):<tab>with self.script_lock:<tab><tab>if self.script_running and self.script_running[1] == name:<tab><tab><tab>return self.script_running[1:]<tab><tab><IF-STMT><tab><tab><tab>return self.script_last[1:]<tab><tab>else:<tab><tab><tab>raise ValueError(error)",elif self . script_last and self . script_last [ 1 ] == name :,107
2243,"def _stderr_supports_color():<tab>try:<tab><tab>if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>curses.setupterm()<tab><tab><tab><tab>if curses.tigetnum(""colors"") > 0:<tab><tab><tab><tab><tab>return True<tab><tab><tab>elif colorama:<tab><tab><tab><tab>if sys.stderr is getattr(<tab><tab><tab><tab><tab>colorama.initialise, ""wrapped_stderr"", object()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>return True<tab>except Exception:<tab><tab># Very broad exception handling because it's always better to<tab><tab># fall back to non-colored logs than to break at startup.<tab><tab>pass<tab>return False",if curses :,170
2244,"def main():<tab>configFilename = ""twitterbot.ini""<tab>if sys.argv[1:]:<tab><tab>configFilename = sys.argv[1]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise Exception()<tab><tab>load_config(configFilename)<tab>except Exception as e:<tab><tab>print(""Error while loading ini file %s"" % (configFilename), file=sys.stderr)<tab><tab>print(e, file=sys.stderr)<tab><tab>print(__doc__, file=sys.stderr)<tab><tab>sys.exit(1)<tab>bot = TwitterBot(configFilename)<tab>return bot.run()",if not os . path . exists ( configFilename ) :,156
2245,def safe_to_kill(request):<tab>if os.path.exists(DRAIN_FILE):<tab><tab>with open(DRAIN_FILE) as f:<tab><tab><tab>dt = datetime.datetime.fromtimestamp(float(f.read()))<tab><tab><tab>delta = datetime.datetime.now() - dt<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return Response(status_int=200)<tab><tab><tab>else:<tab><tab><tab><tab>return Response(status_int=400)<tab>else:<tab><tab>return Response(status_int=400),if delta . seconds > 2 :,131
2246,"def get_class_name(item):<tab>class_name, module_name = None, None<tab>for parent in reversed(item.listchain()):<tab><tab><IF-STMT><tab><tab><tab>class_name = parent.name<tab><tab>elif isinstance(parent, pytest.Module):<tab><tab><tab>module_name = parent.module.__name__<tab><tab><tab>break<tab># heuristic:<tab># - better to group gpu and task tests, since tests from those modules<tab>#   are likely to share caching more<tab># - split up the rest by class name because slow tests tend to be in<tab>#   the same module<tab>if class_name and "".tasks."" not in module_name:<tab><tab>return ""{}.{}"".format(module_name, class_name)<tab>else:<tab><tab>return module_name","if isinstance ( parent , pytest . Class ) :",190
2247,"def getAllFitsLite():<tab>fits = eos.db.getFitListLite()<tab>shipMap = {f.shipID: None for f in fits}<tab>for shipID in shipMap:<tab><tab>ship = eos.db.getItem(shipID)<tab><tab><IF-STMT><tab><tab><tab>shipMap[shipID] = (ship.name, ship.getShortName())<tab>fitsToPurge = set()<tab>for fit in fits:<tab><tab>try:<tab><tab><tab>fit.shipName, fit.shipNameShort = shipMap[fit.shipID]<tab><tab>except (KeyError, TypeError):<tab><tab><tab>fitsToPurge.add(fit)<tab>for fit in fitsToPurge:<tab><tab>fits.remove(fit)<tab>return fits",if ship is not None :,185
2248,"def _process(self, event_data):<tab>self.machine.callbacks(self.machine.prepare_event, event_data)<tab>_LOGGER.debug(<tab><tab>""%sExecuted machine preparation callbacks before conditions."", self.machine.name<tab>)<tab>try:<tab><tab>for trans in self.transitions[event_data.state.name]:<tab><tab><tab>event_data.transition = trans<tab><tab><tab><IF-STMT><tab><tab><tab><tab>event_data.result = True<tab><tab><tab><tab>break<tab>except Exception as err:<tab><tab>event_data.error = err<tab><tab>raise<tab>finally:<tab><tab>self.machine.callbacks(self.machine.finalize_event, event_data)<tab><tab>_LOGGER.debug(""%sExecuted machine finalize callbacks"", self.machine.name)<tab>return event_data.result",if trans . execute ( event_data ) :,200
2249,"def fetch_comments(self, force=False, limit=None):<tab>comments = []<tab>if (force is True) or (self.badges[""comments""] > 0):<tab><tab>query_params = {""filter"": ""commentCard,copyCommentCard""}<tab><tab><IF-STMT><tab><tab><tab>query_params[""limit""] = limit<tab><tab>comments = self.client.fetch_json(<tab><tab><tab>""/cards/"" + self.id + ""/actions"", query_params=query_params<tab><tab>)<tab><tab>return sorted(comments, key=lambda comment: comment[""date""])<tab>return comments",if limit is not None :,140
2250,"def get_changed(self):<tab>if self._is_expression():<tab><tab>result = self._get_node_text(self.ast)<tab><tab>if result == self.source:<tab><tab><tab>return None<tab><tab>return result<tab>else:<tab><tab>collector = codeanalyze.ChangeCollector(self.source)<tab><tab>last_end = -1<tab><tab>for match in self.matches:<tab><tab><tab>start, end = match.get_region()<tab><tab><tab>if start < last_end:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>last_end = end<tab><tab><tab>replacement = self._get_matched_text(match)<tab><tab><tab>collector.add_change(start, end, replacement)<tab><tab>return collector.get_changed()",if not self . _is_expression ( ) :,189
2251,"def _replace_home(x):<tab>if xp.ON_WINDOWS:<tab><tab>home = (<tab><tab><tab>builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab>if builtins.__xonsh__.env.get(""FORCE_POSIX_PATHS""):<tab><tab><tab>x = x.replace(os.sep, os.altsep)<tab><tab>return x<tab>else:<tab><tab>home = builtins.__xonsh__.env[""HOME""]<tab><tab>if x.startswith(home):<tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab>return x",if x . startswith ( home ) :,176
2252,"def project_review(plans):<tab>for plan in plans:<tab><tab>print(""Inspecting {} plan"".format(plan))<tab><tab>branches = get_branches_from_plan(plan)<tab><tab>for branch in branches:<tab><tab><tab>build_results = get_results_from_branch(branch)<tab><tab><tab>for build in build_results:<tab><tab><tab><tab>build_key = build.get(""buildResultKey"") or None<tab><tab><tab><tab>print(""Inspecting build - {}"".format(build_key))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>for status in STATUS_CLEANED_RESULTS:<tab><tab><tab><tab><tab><tab>remove_build_result(build_key=build_key, status=status)",if build_key :,169
2253,"def _check_for_batch_clashes(xs):<tab>""""""Check that batch names do not overlap with sample names.""""""<tab>names = set([x[""description""] for x in xs])<tab>dups = set([])<tab>for x in xs:<tab><tab>batches = tz.get_in((""metadata"", ""batch""), x)<tab><tab>if batches:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>batches = [batches]<tab><tab><tab>for batch in batches:<tab><tab><tab><tab>if batch in names:<tab><tab><tab><tab><tab>dups.add(batch)<tab>if len(dups) > 0:<tab><tab>raise ValueError(<tab><tab><tab>""Batch names must be unique from sample descriptions.\n""<tab><tab><tab>""Clashing batch names: %s"" % sorted(list(dups))<tab><tab>)","if not isinstance ( batches , ( list , tuple ) ) :",192
2254,"def _check_signal(self):<tab>""""""Checks if a signal was received and issues a message.""""""<tab>proc_signal = getattr(self.proc, ""signal"", None)<tab>if proc_signal is None:<tab><tab>return<tab>sig, core = proc_signal<tab>sig_str = SIGNAL_MESSAGES.get(sig)<tab>if sig_str:<tab><tab>if core:<tab><tab><tab>sig_str += "" (core dumped)""<tab><tab>print(sig_str, file=sys.stderr)<tab><tab><IF-STMT><tab><tab><tab>self.errors += sig_str + ""\n""",if self . errors is not None :,146
2255,"def loadLabelFile(self, labelpath):<tab>labeldict = {}<tab>if not os.path.exists(labelpath):<tab><tab>f = open(labelpath, ""w"", encoding=""utf-8"")<tab>else:<tab><tab>with open(labelpath, ""r"", encoding=""utf-8"") as f:<tab><tab><tab>data = f.readlines()<tab><tab><tab>for each in data:<tab><tab><tab><tab>file, label = each.split(""\t"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>label = label.replace(""false"", ""False"")<tab><tab><tab><tab><tab>label = label.replace(""true"", ""True"")<tab><tab><tab><tab><tab>labeldict[file] = eval(label)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>labeldict[file] = []<tab>return labeldict",if label :,191
2256,"def exists_col_to_many(self, select_columns: List[str]) -> bool:<tab>for column in select_columns:<tab><tab><IF-STMT><tab><tab><tab>root_relation = get_column_root_relation(column)<tab><tab><tab>if self.is_relation_many_to_many(<tab><tab><tab><tab>root_relation<tab><tab><tab>) or self.is_relation_one_to_many(root_relation):<tab><tab><tab><tab>return True<tab>return False",if is_column_dotted ( column ) :,120
2257,"def check_sequence_matches(seq, template):<tab>i = 0<tab>for pattern in template:<tab><tab><IF-STMT><tab><tab><tab>pattern = {pattern}<tab><tab>got = set(seq[i : i + len(pattern)])<tab><tab>assert got == pattern<tab><tab>i += len(got)","if not isinstance ( pattern , set ) :",77
2258,"def load_modules(<tab>to_load, load, attr, modules_dict, excluded_aliases, loading_message=None):<tab>if loading_message:<tab><tab>print(loading_message)<tab>for name in to_load:<tab><tab>module = load(name)<tab><tab>if module is None or not hasattr(module, attr):<tab><tab><tab>continue<tab><tab>cls = getattr(module, attr)<tab><tab>if hasattr(cls, ""initialize"") and not cls.initialize():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>for alias in module.aliases():<tab><tab><tab><tab>if alias not in excluded_aliases:<tab><tab><tab><tab><tab>modules_dict[alias] = module<tab><tab>else:<tab><tab><tab>modules_dict[name] = module<tab>if loading_message:<tab><tab>print()","if hasattr ( module , ""aliases"" ) :",195
2259,"def result():<tab># ""global"" does not work here...<tab>R, V = rays, virtual_rays<tab>if V is not None:<tab><tab><IF-STMT><tab><tab><tab>V = normalize_rays(V, lattice)<tab><tab>if check:<tab><tab><tab>R = PointCollection(V, lattice)<tab><tab><tab>V = PointCollection(V, lattice)<tab><tab><tab>d = lattice.dimension()<tab><tab><tab>if len(V) != d - R.dim() or (R + V).dim() != d:<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""virtual rays must be linearly ""<tab><tab><tab><tab><tab>""independent and with other rays span the ambient space.""<tab><tab><tab><tab>)<tab>return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",if normalize :,194
2260,"def communicate(self, _input=None, _timeout=None) -> Tuple[bytes, bytes]:<tab>if parse_args().print_commands:<tab><tab><IF-STMT><tab><tab><tab>print_stderr(<tab><tab><tab><tab>color_line(""=> "", 14) + "" "".join(str(arg) for arg in self.args)<tab><tab><tab>)<tab>stdout, stderr = super().communicate(_input, _timeout)<tab>self.stdout_text = stdout.decode(""utf-8"") if stdout else None<tab>self.stderr_text = stderr.decode(""utf-8"") if stderr else None<tab>return stdout, stderr",if self . args != get_sudo_refresh_command ( ) :,154
2261,"def convert(data):<tab>result = []<tab>for d in data:<tab><tab># noinspection PyCompatibility<tab><tab><IF-STMT><tab><tab><tab>result.append((d[0], None, d[1]))<tab><tab>elif isinstance(d, basestring):<tab><tab><tab>result.append(d)<tab>return result","if isinstance ( d , tuple ) and len ( d ) == 2 :",86
2262,"def validate(self, value):<tab>try:<tab><tab>value = [<tab><tab><tab>datetime.datetime.strptime(range, ""%Y-%m-%d %H:%M:%S"")<tab><tab><tab>for range in value.split("" to "")<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except ValueError:<tab><tab>return False",if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,110
2263,"def rmdir(dirname):<tab>if dirname[-1] == os.sep:<tab><tab>dirname = dirname[:-1]<tab>if os.path.islink(dirname):<tab><tab>return  # do not clear link - we can get out of dir<tab>for f in os.listdir(dirname):<tab><tab>if f in (""."", ""..""):<tab><tab><tab>continue<tab><tab>path = dirname + os.sep + f<tab><tab><IF-STMT><tab><tab><tab>rmdir(path)<tab><tab>else:<tab><tab><tab>os.unlink(path)<tab>os.rmdir(dirname)",if os . path . isdir ( path ) :,137
2264,"def onCompletion(self, text):<tab>res = []<tab>for l in text.split(""\n""):<tab><tab>if not l:<tab><tab><tab>continue<tab><tab>l = l.split("":"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>res.append([l[0].strip(), l[1].strip()])<tab>self.panel.setSlides(res)",if len ( l ) != 2 :,93
2265,"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab>if ""init"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))","if item . nodeid . startswith ( ""tests/infer"" ) :",102
2266,"def build_message(self, options, target):<tab>message = multipart.MIMEMultipart()<tab>for name, value in list(options.items()):<tab><tab>if name == ""EMAIL_BODY"":<tab><tab><tab>self.add_body(message, value)<tab><tab><IF-STMT><tab><tab><tab>self.add_attachment(message, value)<tab><tab>else:  # From, To, Subject, etc.<tab><tab><tab>self.set_option(message, name, value, target)<tab>return message","elif name == ""EMAIL_ATTACHMENT"" :",126
2267,def extend_with_zeroes(b):<tab>try:<tab><tab>for x in b:<tab><tab><tab>x = to_constant(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (x)<tab><tab><tab>else:<tab><tab><tab><tab>yield (0)<tab><tab>for _ in range(32):<tab><tab><tab>yield (0)<tab>except Exception as e:<tab><tab>return,"if isinstance ( x , int ) :",99
2268,"def _start_cluster(*, cleanup_atexit=True):<tab>global _default_cluster<tab>if _default_cluster is None:<tab><tab>cluster_addr = os.environ.get(""EDGEDB_TEST_CLUSTER_ADDR"")<tab><tab><IF-STMT><tab><tab><tab>conn_spec = json.loads(cluster_addr)<tab><tab><tab>_default_cluster = edgedb_cluster.RunningCluster(**conn_spec)<tab><tab>else:<tab><tab><tab>data_dir = os.environ.get(""EDGEDB_TEST_DATA_DIR"")<tab><tab><tab>_default_cluster = _init_cluster(<tab><tab><tab><tab>data_dir=data_dir, cleanup_atexit=cleanup_atexit<tab><tab><tab>)<tab>return _default_cluster",if cluster_addr :,175
2269,"def preprocess_raw_enwik9(input_filename, output_filename):<tab>with open(input_filename, ""r"") as f1:<tab><tab>with open(output_filename, ""w"") as f2:<tab><tab><tab>while True:<tab><tab><tab><tab>line = f1.readline()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>line = list(enwik9_norm_transform([line]))[0]<tab><tab><tab><tab>if line != "" "" and line != """":<tab><tab><tab><tab><tab>if line[0] == "" "":<tab><tab><tab><tab><tab><tab>line = line[1:]<tab><tab><tab><tab><tab>f2.writelines(line + ""\n"")",if not line :,164
2270,"def is_entirely_italic(line):<tab>style = subs.styles.get(line.style, SSAStyle.DEFAULT_STYLE)<tab>for fragment, sty in parse_tags(line.text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",if not sty . italic and fragment and not fragment . isspace ( ) :,128
2271,def __get_all_nodes(self):<tab>nodes = []<tab>next_level = [self.__tree.get_root()]<tab>while len(next_level) != 0:<tab><tab>cur_level = next_level<tab><tab>nodes += next_level<tab><tab>next_level = []<tab><tab>for cur_node in cur_level:<tab><tab><tab>children = cur_node.get_children()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>next_level += children<tab>return nodes,if children is not None :,119
2272,"def _openvpn_stdout(self):<tab>while True:<tab><tab>line = self.process.stdout.readline()<tab><tab>if not line:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>time.sleep(0.05)<tab><tab><tab>continue<tab><tab>yield<tab><tab>try:<tab><tab><tab>self.server.output.push_output(line)<tab><tab>except:<tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Failed to push vpn output"",<tab><tab><tab><tab>""server"",<tab><tab><tab><tab>server_id=self.server.id,<tab><tab><tab>)<tab><tab>yield",if self . process . poll ( ) is not None or self . is_interrupted ( ) :,163
2273,"def payment_received_handler(event):<tab>if isinstance(event.message.action, types.MessageActionPaymentSentMe):<tab><tab>payment: types.MessageActionPaymentSentMe = event.message.action<tab><tab># do something after payment was received<tab><tab>if payment.payload.decode(""UTF-8"") == ""product A"":<tab><tab><tab>await bot.send_message(<tab><tab><tab><tab>event.message.from_id, ""Thank you for buying product A!""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>await bot.send_message(<tab><tab><tab><tab>event.message.from_id, ""Thank you for buying product B!""<tab><tab><tab>)<tab><tab>raise events.StopPropagation","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :",181
2274,"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None):<tab>if next is not None and token.end_mark.line == next.start_mark.line:<tab><tab>spaces = next.start_mark.pointer - token.end_mark.pointer<tab><tab><IF-STMT><tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column, max_desc<tab><tab><tab>)<tab><tab>elif min != -1 and spaces < min:<tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column + 1, min_desc<tab><tab><tab>)",if max != - 1 and spaces > max :,184
2275,"def seek_to_block(self, pos):<tab>baseofs = 0<tab>ofs = 0<tab>for b in self.blocks:<tab><tab><IF-STMT><tab><tab><tab>self.current_block = b<tab><tab><tab>break<tab><tab>baseofs += b.compressed_size<tab><tab>ofs += b.uncompressed_size<tab>else:<tab><tab>self.current_block = None<tab><tab>self.current_stream = BytesIO(b"""")<tab><tab>return<tab>self.current_block_start = ofs<tab>self.stream.seek(self.basepos + baseofs)<tab>buf = BytesIO(self.stream.read(self.current_block.compressed_size))<tab>self.current_stream = self.current_block.decompress(buf)",if ofs + b . uncompressed_size > pos :,190
2276,"def rewrite_hunks(hunks):<tab># type: (List[Hunk]) -> Iterator[Hunk]<tab># Assumes `hunks` are sorted, and from the same file<tab>deltas = (hunk.b_length - hunk.a_length for hunk in hunks)<tab>offsets = accumulate(deltas, initial=0)<tab>for hunk, offset in zip(hunks, offsets):<tab><tab>new_b = hunk.a_start + offset<tab><tab>if hunk_of_additions_only(hunk):<tab><tab><tab>new_b += 1<tab><tab><IF-STMT><tab><tab><tab>new_b -= 1<tab><tab>yield hunk._replace(b_start=new_b)",elif hunk_of_removals_only ( hunk ) :,185
2277,"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab><IF-STMT><tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.append(value)<tab><tab><tab>elif is_iterable(value):<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab>if not is_iterable(value):<tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",if len ( q ) == 1 :,185
2278,"def get_url(token, base_url):<tab>""""""Parse an <url> token.""""""<tab>if token.type == ""url"":<tab><tab>return _get_url_tuple(token.value, base_url)<tab>elif token.type == ""function"":<tab><tab>if token.name == ""attr"":<tab><tab><tab>return check_attr_function(token, ""url"")<tab><tab><IF-STMT><tab><tab><tab># Ignore url modifiers<tab><tab><tab># See https://drafts.csswg.org/css-values-3/#urls<tab><tab><tab>return _get_url_tuple(token.arguments[0].value, base_url)","elif token . name == ""url"" and len ( token . arguments ) in ( 1 , 2 ) :",166
2279,"def read(self, count):<tab>if self.closed:<tab><tab>return self.upstream.read(count)<tab>try:<tab><tab>while len(self.upstream) < count:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with self.buf_in:<tab><tab><tab><tab><tab>self.transport.downstream_recv(self.buf_in)<tab><tab><tab>else:<tab><tab><tab><tab>break<tab><tab>return self.upstream.read(count)<tab>except:<tab><tab>logger.debug(traceback.format_exc())",if self . buf_in or self . _poll_read ( 10 ) :,140
2280,"def get_timestamp_for_block(<tab>self, block_hash: HexBytes, max_tries: Optional[int] = 10) -> int:<tab>counter = 0<tab>block: AttributeDict = None<tab>if block_hash in self._block_cache.keys():<tab><tab>block = self._block_cache.get(block_hash)<tab>else:<tab><tab>while block is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(f""Block hash {block_hash.hex()} does not exist."")<tab><tab><tab>counter += 1<tab><tab><tab>block = self._block_cache.get(block_hash)<tab><tab><tab>await asyncio.sleep(0.5)<tab>return block.get(""timestamp"")",if counter == max_tries :,172
2281,"def reader():<tab>batch_out = []<tab>for video_name in self.video_list:<tab><tab>video_idx = self.video_list.index(video_name)<tab><tab>video_feat = self.load_file(video_name)<tab><tab>batch_out.append((video_feat, video_idx))<tab><tab><IF-STMT><tab><tab><tab>yield batch_out<tab><tab><tab>batch_out = []",if len ( batch_out ) == self . batch_size :,111
2282,"def cleanup():<tab>gscript.message(_(""Erasing temporary files...""))<tab>for temp_map, maptype in temp_maps:<tab><tab><IF-STMT><tab><tab><tab>gscript.run_command(<tab><tab><tab><tab>""g.remove"", flags=""f"", type=maptype, name=temp_map, quiet=True<tab><tab><tab>)","if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :",94
2283,"def run(self):<tab>while True:<tab><tab>try:<tab><tab><tab>with DelayedKeyboardInterrupt():<tab><tab><tab><tab>raw_inputs = self._parent_task_queue.get()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>if self._flow_type == BATCH:<tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab>elif self._flow_type == REALTIME:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=False)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>pass<tab><tab>except KeyboardInterrupt:<tab><tab><tab>continue",if self . _has_stop_signal ( raw_inputs ) :,199
2284,"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab>if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""):<tab><tab><tab>sent += [self.handle_word(w) for w in child]<tab><tab><IF-STMT><tab><tab><tab>sent.append(self.handle_word(child))<tab><tab>elif child.tag not in self.tags_to_ignore:<tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return BNCSentence(elt.attrib[""n""], sent)","elif child . tag in ( ""w"" , ""c"" ) :",141
2285,"def bind_subscribers_to_graphql_type(self, graphql_type):<tab>for field, subscriber in self._subscribers.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Field %s is not defined on type %s"" % (field, self.name))<tab><tab>graphql_type.fields[field].subscribe = subscriber",if field not in graphql_type . fields :,84
2286,"def _get_from_json(self, *, name, version):<tab>url = urljoin(self.url, posixpath.join(name, str(version), ""json""))<tab>async with aiohttp_session(auth=self.auth) as session:<tab><tab>async with session.get(url) as response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise PackageNotFoundError(package=name, url=url)<tab><tab><tab>response.raise_for_status()<tab><tab><tab>response = await response.json()<tab>dist = response[""info""][""requires_dist""] or []<tab>if dist:<tab><tab>return dist<tab># If no requires_dist then package metadata can be broken.<tab># Let's check distribution files.<tab>return await self._get_from_files(response[""urls""])",if response . status == 404 :,186
2287,"def is_active(self):<tab>if not self.pk:<tab><tab>log_level = get_setting(""LOG_MISSING_SWITCHES"")<tab><tab>if log_level:<tab><tab><tab>logger.log(log_level, ""Switch %s not found"", self.name)<tab><tab><IF-STMT><tab><tab><tab>switch, _created = Switch.objects.get_or_create(<tab><tab><tab><tab>name=self.name, defaults={""active"": get_setting(""SWITCH_DEFAULT"")}<tab><tab><tab>)<tab><tab><tab>cache = get_cache()<tab><tab><tab>cache.set(self._cache_key(self.name), switch)<tab><tab>return get_setting(""SWITCH_DEFAULT"")<tab>return self.active","if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :",179
2288,"def add_requirements(self, requirements):<tab>if self._legacy:<tab><tab>self._legacy.add_requirements(requirements)<tab>else:<tab><tab>run_requires = self._data.setdefault(""run_requires"", [])<tab><tab>always = None<tab><tab>for entry in run_requires:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>always = entry<tab><tab><tab><tab>break<tab><tab>if always is None:<tab><tab><tab>always = {""requires"": requirements}<tab><tab><tab>run_requires.insert(0, always)<tab><tab>else:<tab><tab><tab>rset = set(always[""requires""]) | set(requirements)<tab><tab><tab>always[""requires""] = sorted(rset)","if ""environment"" not in entry and ""extra"" not in entry :",171
2289,"def display_failures_for_single_test(result: TestResult) -> None:<tab>""""""Display a failure for a single method / endpoint.""""""<tab>display_subsection(result)<tab>checks = _get_unique_failures(result.checks)<tab>for idx, check in enumerate(checks, 1):<tab><tab>message: Optional[str]<tab><tab>if check.message:<tab><tab><tab>message = f""{idx}. {check.message}""<tab><tab>else:<tab><tab><tab>message = None<tab><tab>example = cast(Case, check.example)  # filtered in `_get_unique_failures`<tab><tab>display_example(example, check.name, message, result.seed)<tab><tab># Display every time except the last check<tab><tab><IF-STMT><tab><tab><tab>click.echo(""\n"")",if idx != len ( checks ) :,188
2290,"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"":<tab>code = frame.f_code<tab>if (<tab><tab>event not in SUPPORTED_EVENTS<tab><tab>or code.co_name == ""trace_types""<tab><tab>or self.should_trace<tab><tab>and not self.should_trace(code)<tab>):<tab><tab>return self<tab>try:<tab><tab>if event == EVENT_CALL:<tab><tab><tab>self.handle_call(frame)<tab><tab><IF-STMT><tab><tab><tab>self.handle_return(frame, arg)<tab><tab>else:<tab><tab><tab>logger.error(""Cannot handle event %s"", event)<tab>except Exception:<tab><tab>logger.exception(""Failed collecting trace"")<tab>return self",elif event == EVENT_RETURN :,185
2291,"def get_maps(test):<tab>pages = set()<tab>for addr in test[""pre""][""memory""].keys():<tab><tab>pages.add(addr >> 12)<tab>for addr in test[""pos""][""memory""].keys():<tab><tab>pages.add(addr >> 12)<tab>maps = []<tab>for p in sorted(pages):<tab><tab><IF-STMT><tab><tab><tab>maps[-1] = (maps[-1][0], maps[-1][1] + 0x1000)<tab><tab>else:<tab><tab><tab>maps.append((p << 12, 0x1000))<tab>return maps",if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,157
2292,"def process_rotate_aes_key(self):<tab>if hasattr(self.options, ""rotate_aes_key"") and isinstance(<tab><tab>self.options.rotate_aes_key, six.string_types<tab>):<tab><tab><IF-STMT><tab><tab><tab>self.options.rotate_aes_key = True<tab><tab>elif self.options.rotate_aes_key.lower() == ""false"":<tab><tab><tab>self.options.rotate_aes_key = False","if self . options . rotate_aes_key . lower ( ) == ""true"" :",122
2293,"def apply_figure(self, figure):<tab>super(legend_text_legend, self).apply_figure(figure)<tab>properties = self.properties.copy()<tab>with suppress(KeyError):<tab><tab>del properties[""margin""]<tab>with suppress(KeyError):<tab><tab>texts = figure._themeable[""legend_text_legend""]<tab><tab>for text in texts:<tab><tab><tab><IF-STMT>  # textarea<tab><tab><tab><tab>text = text._text<tab><tab><tab>text.set(**properties)","if not hasattr ( text , ""_x"" ) :",121
2294,"def tearDown(self):<tab>for i in range(len(self.tree) - 1, -1, -1):<tab><tab>s = os.path.join(self.root, self.tree[i])<tab><tab><IF-STMT><tab><tab><tab>os.rmdir(s)<tab><tab>else:<tab><tab><tab>os.remove(s)<tab>os.rmdir(self.root)","if not ""."" in s :",93
2295,"def _get_id(self, type, id):<tab>fields = id.split("":"")<tab>if len(fields) >= 3:<tab><tab>if type != fields[-2]:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, fields[-2], id<tab><tab><tab>)<tab><tab>return fields[-1]<tab>fields = id.split(""/"")<tab>if len(fields) >= 3:<tab><tab>itype = fields[-2]<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, itype, id<tab><tab><tab>)<tab><tab>return fields[-1].split(""?"")[0]<tab>return id",if type != itype :,178
2296,"def candidates() -> Generator[""Symbol"", None, None]:<tab>s = self<tab>if Symbol.debug_lookup:<tab><tab>Symbol.debug_print(""searching in self:"")<tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>yield s<tab><tab>if recurseInAnon:<tab><tab><tab>yield from s.children_recurse_anon<tab><tab>else:<tab><tab><tab>yield from s._children<tab><tab>if s.siblingAbove is None:<tab><tab><tab>break<tab><tab>s = s.siblingAbove<tab><tab>if Symbol.debug_lookup:<tab><tab><tab>Symbol.debug_print(""searching in sibling:"")<tab><tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")",if matchSelf :,190
2297,"def records(account_id):<tab>""""""Fetch locks data""""""<tab>s = boto3.Session()<tab>table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"")<tab>results = table.scan()<tab>for r in results[""Items""]:<tab><tab>if ""LockDate"" in r:<tab><tab><tab>r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""])<tab><tab><IF-STMT><tab><tab><tab>r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""])<tab>print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))","if ""RevisionDate"" in r :",149
2298,"def _handle_errors(errors):<tab>""""""Log out and possibly reraise errors during import.""""""<tab>if not errors:<tab><tab>return<tab>log_all = True  # pylint: disable=unused-variable<tab>err_msg = ""T2T: skipped importing {num_missing} data_generators modules.""<tab>print(err_msg.format(num_missing=len(errors)))<tab>for module, err in errors:<tab><tab>err_str = str(err)<tab><tab>if log_all:<tab><tab><tab>print(""Did not import module: %s; Cause: %s"" % (module, err_str))<tab><tab><IF-STMT><tab><tab><tab>print(""From module %s"" % module)<tab><tab><tab>raise err","if not _is_import_err_msg ( err_str , module ) :",184
2299,"def find_needle(self, tree, focused=None):<tab>if isinstance(tree, list):<tab><tab>for el in tree:<tab><tab><tab>res = self.find_needle(el, focused)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return res<tab>elif isinstance(tree, dict):<tab><tab>nodes = tree.get(""nodes"", []) + tree.get(""floating_nodes"", [])<tab><tab>if focused:<tab><tab><tab>for node in nodes:<tab><tab><tab><tab>if node[""id""] == focused[""id""]:<tab><tab><tab><tab><tab>return tree<tab><tab>elif tree[""focused""]:<tab><tab><tab>return tree<tab><tab>return self.find_needle(nodes, focused)<tab>return {}",if res :,169
2300,"def available_datasets(self):<tab>""""""Automatically determine datasets provided by this file""""""<tab>res = self.resolution<tab>coordinates = [""pixel_longitude"", ""pixel_latitude""]<tab>for var_name, val in self.file_content.items():<tab><tab>if isinstance(val, netCDF4.Variable):<tab><tab><tab>ds_info = {<tab><tab><tab><tab>""file_type"": self.filetype_info[""file_type""],<tab><tab><tab><tab>""resolution"": res,<tab><tab><tab>}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ds_info[""coordinates""] = coordinates<tab><tab><tab>yield DatasetID(name=var_name, resolution=res), ds_info",if not self . is_geo :,165
2301,"def get_subkeys(self, key):<tab># TODO: once we revamp the registry emulation,<tab># make this better<tab>parent_path = key.get_path()<tab>subkeys = []<tab>for k in self.keys:<tab><tab>test_path = k.get_path()<tab><tab><IF-STMT><tab><tab><tab>sub = test_path[len(parent_path) :]<tab><tab><tab>if sub.startswith(""\\""):<tab><tab><tab><tab>sub = sub[1:]<tab><tab><tab>end_slash = sub.find(""\\"")<tab><tab><tab>if end_slash >= 0:<tab><tab><tab><tab>sub = sub[:end_slash]<tab><tab><tab>if not sub:<tab><tab><tab><tab>continue<tab><tab><tab>subkeys.append(sub)<tab>return subkeys",if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) :,192
2302,"def default(self, o):<tab>try:<tab><tab>if type(o) == datetime.datetime:<tab><tab><tab>return str(o)<tab><tab>else:<tab><tab><tab># remove unwanted attributes from the provider object during conversion to json<tab><tab><tab>if hasattr(o, ""profile""):<tab><tab><tab><tab>del o.profile<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del o.credentials<tab><tab><tab>if hasattr(o, ""metadata_path""):<tab><tab><tab><tab>del o.metadata_path<tab><tab><tab>if hasattr(o, ""services_config""):<tab><tab><tab><tab>del o.services_config<tab><tab><tab>return vars(o)<tab>except Exception as e:<tab><tab>return str(o)","if hasattr ( o , ""credentials"" ) :",172
2303,"def submit(self, fn, *args, **kwargs):<tab>with self._shutdown_lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""cannot schedule new futures after shutdown"")<tab><tab>f = _base.Future()<tab><tab>w = _WorkItem(f, fn, args, kwargs)<tab><tab>self._work_queue.put(w)<tab><tab>self._adjust_thread_count()<tab><tab>return f",if self . _shutdown :,101
2304,"def __viewerKeyPress(viewer, event):<tab>view = viewer.view()<tab>if not isinstance(view, GafferSceneUI.SceneView):<tab><tab>return False<tab>if event == __editSourceKeyPress:<tab><tab>selectedPath = __sceneViewSelectedPath(view)<tab><tab><IF-STMT><tab><tab><tab>__editSourceNode(view.getContext(), view[""in""], selectedPath)<tab><tab>return True<tab>elif event == __editTweaksKeyPress:<tab><tab>selectedPath = __sceneViewSelectedPath(view)<tab><tab>if selectedPath is not None:<tab><tab><tab>__editTweaksNode(view.getContext(), view[""in""], selectedPath)<tab><tab>return True",if selectedPath is not None :,175
2305,"def _split_to_option_groups_and_paths(self, args):<tab>opt_groups = []<tab>current = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>opts = self._arg_parser.parse_args(current)[0]<tab><tab><tab>opt_groups.append(opts)<tab><tab><tab>current = []<tab><tab>else:<tab><tab><tab>current.append(arg)<tab>if opt_groups:<tab><tab>return opt_groups, current<tab>raise ValueError(""Nothing to split"")","if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :",136
2306,"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",if value :,145
2307,"def wait_for_child(pid, timeout=1.0):<tab>deadline = mitogen.core.now() + timeout<tab>while timeout < mitogen.core.now():<tab><tab>try:<tab><tab><tab>target_pid, status = os.waitpid(pid, os.WNOHANG)<tab><tab><tab>if target_pid == pid:<tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>time.sleep(0.05)<tab>assert False, ""wait_for_child() timed out""",if e . args [ 0 ] == errno . ECHILD :,156
2308,"def _get_os_version_lsb_release():<tab>try:<tab><tab>output = subprocess.check_output(""lsb_release -sri"", shell=True)<tab><tab>lines = output.strip().split()<tab><tab>name, version = lines<tab><tab><IF-STMT><tab><tab><tab>version = """"<tab><tab>return name, version<tab>except:<tab><tab>return _get_os_version_uname()","if version . lower ( ) == ""rolling"" :",101
2309,"def _check_snapshot_status_healthy(self, snapshot_uuid):<tab>status = """"<tab>try:<tab><tab>while True:<tab><tab><tab>status, locked = self._get_snapshot_status(snapshot_uuid)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>eventlet.sleep(2)<tab>except Exception:<tab><tab>with excutils.save_and_reraise_exception():<tab><tab><tab>LOG.exception(""Failed to get snapshot status. [%s]"", snapshot_uuid)<tab>LOG.debug(<tab><tab>""Lun [%(snapshot)s], status [%(status)s]."",<tab><tab>{""snapshot"": snapshot_uuid, ""status"": status},<tab>)<tab>return status == ""Healthy""",if not locked :,172
2310,"def CountButtons(self):<tab>""""""Returns the number of visible buttons in the docked pane.""""""<tab>n = 0<tab>if self.HasCaption() or self.HasCaptionLeft():<tab><tab>if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame):<tab><tab><tab>return 1<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>if self.HasMaximizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasMinimizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasPinButton():<tab><tab><tab>n += 1<tab>return n",if self . HasCloseButton ( ) :,149
2311,"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>from .datastructures import iter_multi_items<tab>iterable = iter_multi_items(obj)<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, value in iterable:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not isinstance(key, bytes):<tab><tab><tab>key = text_type(key).encode(charset)<tab><tab>if not isinstance(value, bytes):<tab><tab><tab>value = text_type(value).encode(charset)<tab><tab>yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)",if value is None :,168
2312,"def get_response(self, exc_fmt=None):<tab>self.callback = None<tab>if __debug__:<tab><tab>self.parent._log(3, ""%s:%s.ready.wait"" % (self.name, self.tag))<tab>self.ready.wait()<tab>if self.aborted is not None:<tab><tab>typ, val = self.aborted<tab><tab><IF-STMT><tab><tab><tab>exc_fmt = ""%s - %%s"" % typ<tab><tab>raise typ(exc_fmt % str(val))<tab>return self.response",if exc_fmt is None :,131
2313,"def extract_items(self):<tab>responses = self.fetch()<tab>items = []<tab>for response in responses:<tab><tab>page_key = response.meta.get(""page_key"") or response.url<tab><tab>item = {""key"": page_key, ""items"": None, ""templates"": None}<tab><tab>extracted_items = [<tab><tab><tab>dict(i) for i in self.spider.parse(response) if not isinstance(i, Request)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>item[""items""] = extracted_items<tab><tab><tab>item[""templates""] = [<tab><tab><tab><tab>i[""_template""] for i in extracted_items if i.get(""_template"")<tab><tab><tab>]<tab><tab><tab>items.append(item)<tab>return items",if extracted_items :,182
2314,"def fit_one(self, x):<tab>for i, xi in x.items():<tab><tab>if self.with_centering:<tab><tab><tab>self.median[i].update(xi)<tab><tab><IF-STMT><tab><tab><tab>self.iqr[i].update(xi)<tab>return self",if self . with_scaling :,75
2315,"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab>if left == 0:<tab><tab><tab>done = True<tab><tab><IF-STMT><tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab>if right == len(text):<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[right]):<tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",elif not self . word_boundary_char ( text [ left - 1 ] ) :,159
2316,"def _validate_duplicate_detection_history_time_window(namespace):<tab>if namespace.duplicate_detection_history_time_window:<tab><tab>if iso8601pattern.match(namespace.duplicate_detection_history_time_window):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""--duplicate-detection-history-time-window Value Error : {0} value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min"".format(<tab><tab><tab><tab><tab>namespace.duplicate_detection_history_time_window<tab><tab><tab><tab>)<tab><tab><tab>)",elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,187
2317,"def get_subkeys(self, key):<tab># TODO: once we revamp the registry emulation,<tab># make this better<tab>parent_path = key.get_path()<tab>subkeys = []<tab>for k in self.keys:<tab><tab>test_path = k.get_path()<tab><tab>if test_path.lower().startswith(parent_path.lower()):<tab><tab><tab>sub = test_path[len(parent_path) :]<tab><tab><tab>if sub.startswith(""\\""):<tab><tab><tab><tab>sub = sub[1:]<tab><tab><tab>end_slash = sub.find(""\\"")<tab><tab><tab>if end_slash >= 0:<tab><tab><tab><tab>sub = sub[:end_slash]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>subkeys.append(sub)<tab>return subkeys",if not sub :,192
2318,"def generator(self, data):<tab><IF-STMT><tab><tab>silent_vars = self._get_silent_vars()<tab>for task in data:<tab><tab>for var, val in task.environment_variables():<tab><tab><tab>if self._config.SILENT:<tab><tab><tab><tab>if var in silent_vars:<tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>int(task.UniqueProcessId),<tab><tab><tab><tab><tab>str(task.ImageFileName),<tab><tab><tab><tab><tab>Address(task.Peb.ProcessParameters.Environment),<tab><tab><tab><tab><tab>str(var),<tab><tab><tab><tab><tab>str(val),<tab><tab><tab><tab>],<tab><tab><tab>)",if self . _config . SILENT :,182
2319,"def start_requests(self):<tab>if self.fail_before_yield:<tab><tab>1 / 0<tab>for s in range(100):<tab><tab>qargs = {""total"": 10, ""seed"": s}<tab><tab>url = self.mockserver.url(""/follow?%s"") % urlencode(qargs, doseq=1)<tab><tab>yield Request(url, meta={""seed"": s})<tab><tab><IF-STMT><tab><tab><tab>2 / 0<tab>assert self.seedsseen, ""All start requests consumed before any download happened""",if self . fail_yielding :,127
2320,"def populateGridlines(self):<tab>cTicks = self.getSystemCurve(self.ticksId)<tab>cGridlines = self.getSystemCurve(self.gridlinesId)<tab>cGridlines.clearPoints()<tab>nTicks = cTicks.getNPoints()<tab>for iTick in range(nTicks):<tab><tab><IF-STMT><tab><tab><tab>p = cTicks.getPoint(iTick)<tab><tab><tab>cGridlines.addPoint(p.getX(), p.getY())",if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 :,139
2321,"def handle_before_events(request, event_list):<tab>if not event_list:<tab><tab>return """"<tab>if not hasattr(event_list, ""__iter__""):<tab><tab>project = event_list.project<tab><tab>event_list = [event_list]<tab>else:<tab><tab>projects = set(e.project for e in event_list)<tab><tab><IF-STMT><tab><tab><tab>project = projects.pop()<tab><tab>else:<tab><tab><tab>project = None<tab>for plugin in plugins.for_project(project):<tab><tab>safe_execute(plugin.before_events, request, event_list)<tab>return """"",if len ( projects ) == 1 :,152
2322,"def handle_parse_result(self, ctx, opts, args):<tab>if self.name in opts:<tab><tab><IF-STMT><tab><tab><tab>self._raise_exclusive_error()<tab><tab>if self.multiple and len(set(opts[self.name])) > 1:<tab><tab><tab>self._raise_exclusive_error()<tab>return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",if self . mutually_exclusive . intersection ( opts ) :,108
2323,"def current_word(cursor_offset, line):<tab>""""""the object.attribute.attribute just before or under the cursor""""""<tab>pos = cursor_offset<tab>start = pos<tab>end = pos<tab>word = None<tab>for m in current_word_re.finditer(line):<tab><tab><IF-STMT><tab><tab><tab>start = m.start(1)<tab><tab><tab>end = m.end(1)<tab><tab><tab>word = m.group(1)<tab>if word is None:<tab><tab>return None<tab>return LinePart(start, end, word)",if m . start ( 1 ) < pos and m . end ( 1 ) >= pos :,147
2324,"def query_to_script_path(path, query):<tab>if path != ""*"":<tab><tab>script = os.path.join(path, query.split("" "")[0])<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""Script '{}' not found in script directory"".format(query))<tab><tab>return os.path.join(path, query).split("" "")<tab>return query",if not os . path . exists ( script ) :,93
2325,"def expand(self, pbegin):<tab># TODO(b/151921205): we have to do an identity map for unmodified<tab># PCollections below because otherwise we get an error from beam.<tab>identity_map = ""Identity"" >> beam.Map(lambda x: x)<tab>if self._dataset_key.is_flattened_dataset_key():<tab><tab><IF-STMT><tab><tab><tab>return self._flat_pcollection | identity_map<tab><tab>else:<tab><tab><tab>return list(<tab><tab><tab><tab>self._pcollection_dict.values()<tab><tab><tab>) | ""FlattenAnalysisInputs"" >> beam.Flatten(pipeline=pbegin.pipeline)<tab>else:<tab><tab>return self._pcollection_dict[self._dataset_key] | identity_map",if self . _flat_pcollection :,183
2326,"def processCoords(coords):<tab>newcoords = deque()<tab>for (x, y, z) in coords:<tab><tab>for _dir, offsets in faceDirections:<tab><tab><tab>if _dir == FaceYIncreasing:<tab><tab><tab><tab>continue<tab><tab><tab>dx, dy, dz = offsets<tab><tab><tab>p = (x + dx, y + dy, z + dz)<tab><tab><tab>if p not in box:<tab><tab><tab><tab>continue<tab><tab><tab>nx, ny, nz = p<tab><tab><tab><IF-STMT><tab><tab><tab><tab>level.setBlockAt(nx, ny, nz, waterID)<tab><tab><tab><tab>newcoords.append(p)<tab>return newcoords","if level . blockAt ( nx , ny , nz ) == 0 :",173
2327,"def delete_byfilter(userId, remove=True, session=None, **dbfilter):<tab>if not session:<tab><tab>session = db.Session<tab>ret = False<tab>results = session.query(ObjectStorageMetadata).filter_by(**dbfilter)<tab>if results:<tab><tab>for result in results:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>session.delete(result)<tab><tab><tab>else:<tab><tab><tab><tab>result.update(<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""record_state_key"": ""to_delete"",<tab><tab><tab><tab><tab><tab>""record_state_val"": str(time.time()),<tab><tab><tab><tab><tab>}<tab><tab><tab><tab>)<tab><tab><tab>ret = True<tab>return ret",if remove :,176
2328,"def fields(self, fields):<tab>fields_xml = """"<tab>for field in fields:<tab><tab>field_dict = DEFAULT_FIELD.copy()<tab><tab>field_dict.update(field)<tab><tab><IF-STMT><tab><tab><tab>field_dict[""required""] = ""true""<tab><tab>fields_xml += FIELD_XML_TEMPLATE % field_dict + ""\n""<tab>self.xml = force_unicode(<tab><tab>force_unicode(self.xml).replace(<tab><tab><tab>u""<!-- REPLACE FIELDS -->"", force_unicode(fields_xml)<tab><tab>)<tab>)","if self . unique_key_field == field [ ""name"" ] :",146
2329,"def get_all_users(self, access_token, timeout=None):<tab>if timeout is None:<tab><tab>timeout = DEFAULT_TIMEOUT<tab>headers = self.retrieve_header(access_token)<tab>try:<tab><tab>response = await self.standard_request(<tab><tab><tab>""get"", ""/walkoff/api/users"", timeout=DEFAULT_TIMEOUT, headers=headers<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>resp = await response.json()<tab><tab><tab>return resp, ""Success""<tab><tab>else:<tab><tab><tab>return ""Invalid Credentials""<tab>except asyncio.CancelledError:<tab><tab>return False, ""TimedOut""",if response . status == 200 :,156
2330,"def set_val():<tab>idx = 0<tab>for idx in range(0, len(model)):<tab><tab>row = model[idx]<tab><tab>if value and row[0] == value:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>idx = -1<tab>os_widget.set_active(idx)<tab>if idx == -1:<tab><tab>os_widget.set_active(0)<tab>if idx >= 0:<tab><tab>return row[1]<tab>if self.show_all_os:<tab><tab>return None",if idx == len ( os_widget . get_model ( ) ) - 1 :,142
2331,"def translate_module_name(module: str, relative: int) -> Tuple[str, int]:<tab>for pkg in VENDOR_PACKAGES:<tab><tab>for alt in ""six.moves"", ""six"":<tab><tab><tab>substr = ""{}.{}"".format(pkg, alt)<tab><tab><tab>if module.endswith(""."" + substr) or (module == substr and relative):<tab><tab><tab><tab>return alt, 0<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return alt + ""."" + module.partition(""."" + substr + ""."")[2], 0<tab>return module, relative","if ""."" + substr + ""."" in module :",132
2332,"def escape(m):<tab>all, tail = m.group(0, 1)<tab>assert all.startswith(""\\"")<tab>esc = simple_escapes.get(tail)<tab>if esc is not None:<tab><tab>return esc<tab>if tail.startswith(""x""):<tab><tab>hexes = tail[1:]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""invalid hex string escape ('\\%s')"" % tail)<tab><tab>try:<tab><tab><tab>i = int(hexes, 16)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""invalid hex string escape ('\\%s')"" % tail)<tab>else:<tab><tab>try:<tab><tab><tab>i = int(tail, 8)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""invalid octal string escape ('\\%s')"" % tail)<tab>return chr(i)",if len ( hexes ) < 2 :,198
2333,"def __get_k8s_container_name(self, job_wrapper):<tab># These must follow a specific regex for Kubernetes.<tab>raw_id = job_wrapper.job_destination.id<tab>if isinstance(raw_id, str):<tab><tab>cleaned_id = re.sub(""[^-a-z0-9]"", ""-"", raw_id)<tab><tab><IF-STMT><tab><tab><tab>cleaned_id = ""x%sx"" % cleaned_id<tab><tab>return cleaned_id<tab>return ""job-container""","if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :",131
2334,"def _power_exact(y, xc, yc, xe):<tab>yc, ye = y.int, y.exp<tab>while yc % 10 == 0:<tab><tab>yc //= 10<tab><tab>ye += 1<tab>if xc == 1:<tab><tab>xe *= yc<tab><tab>while xe % 10 == 0:<tab><tab><tab>xe //= 10<tab><tab><tab>ye += 1<tab><tab>if ye < 0:<tab><tab><tab>return None<tab><tab>exponent = xe * 10 ** ye<tab><tab><IF-STMT><tab><tab><tab>xc = exponent<tab><tab>else:<tab><tab><tab>xc = 0<tab><tab>return 5",if y and xe :,144
2335,"def lpush(key, *vals, **kwargs):<tab>ttl = kwargs.get(""ttl"")<tab>cap = kwargs.get(""cap"")<tab>if not ttl and not cap:<tab><tab>_client.lpush(key, *vals)<tab>else:<tab><tab>pipe = _client.pipeline()<tab><tab>pipe.lpush(key, *vals)<tab><tab><IF-STMT><tab><tab><tab>pipe.ltrim(key, 0, cap)<tab><tab>if ttl:<tab><tab><tab>pipe.expire(key, ttl)<tab><tab>pipe.execute()",if cap :,131
2336,"def render_headers(self) -> bytes:<tab>if not hasattr(self, ""_headers""):<tab><tab>parts = [<tab><tab><tab>b""Content-Disposition: form-data; "",<tab><tab><tab>format_form_param(""name"", self.name),<tab><tab>]<tab><tab>if self.filename:<tab><tab><tab>filename = format_form_param(""filename"", self.filename)<tab><tab><tab>parts.extend([b""; "", filename])<tab><tab><IF-STMT><tab><tab><tab>content_type = self.content_type.encode()<tab><tab><tab>parts.extend([b""\r\nContent-Type: "", content_type])<tab><tab>parts.append(b""\r\n\r\n"")<tab><tab>self._headers = b"""".join(parts)<tab>return self._headers",if self . content_type is not None :,189
2337,"def validate_custom_field_data(field_type: int, field_data: ProfileFieldData) -> None:<tab>try:<tab><tab><IF-STMT><tab><tab><tab># Choice type field must have at least have one choice<tab><tab><tab>if len(field_data) < 1:<tab><tab><tab><tab>raise JsonableError(_(""Field must have at least one choice.""))<tab><tab><tab>validate_choice_field_data(field_data)<tab><tab>elif field_type == CustomProfileField.EXTERNAL_ACCOUNT:<tab><tab><tab>validate_external_account_field_data(field_data)<tab>except ValidationError as error:<tab><tab>raise JsonableError(error.message)",if field_type == CustomProfileField . CHOICE :,160
2338,"def get_data(self, path):<tab>""""""Gross hack to contort loader to deal w/ load_*()'s bad API.""""""<tab>if self.file and path == self.path:<tab><tab><IF-STMT><tab><tab><tab>file = self.file<tab><tab>else:<tab><tab><tab>self.file = file = open(self.path, ""r"")<tab><tab>with file:<tab><tab><tab># Technically should be returning bytes, but<tab><tab><tab># SourceLoader.get_code() just passed what is returned to<tab><tab><tab># compile() which can handle str. And converting to bytes would<tab><tab><tab># require figuring out the encoding to decode to and<tab><tab><tab># tokenize.detect_encoding() only accepts bytes.<tab><tab><tab>return file.read()<tab>else:<tab><tab>return super().get_data(path)",if not self . file . closed :,195
2339,"def handle_read(self):<tab>""""""Called when there is data waiting to be read.""""""<tab>try:<tab><tab>chunk = self.recv(self.ac_in_buffer_size)<tab>except RetryError:<tab><tab>pass<tab>except socket.error:<tab><tab>self.handle_error()<tab>else:<tab><tab>self.tot_bytes_received += len(chunk)<tab><tab><IF-STMT><tab><tab><tab>self.transfer_finished = True<tab><tab><tab># self.close()  # <-- asyncore.recv() already do that...<tab><tab><tab>return<tab><tab>if self._data_wrapper is not None:<tab><tab><tab>chunk = self._data_wrapper(chunk)<tab><tab>try:<tab><tab><tab>self.file_obj.write(chunk)<tab><tab>except OSError as err:<tab><tab><tab>raise _FileReadWriteError(err)",if not chunk :,200
2340,"def _swig_extract_dependency_files(self, src):<tab>dep = []<tab>for line in open(src):<tab><tab><IF-STMT><tab><tab><tab>line = line.split("" "")[1].strip(""""""'""\r\n"""""")<tab><tab><tab>if not (""<"" in line or line in dep):<tab><tab><tab><tab>dep.append(line)<tab>return [i for i in dep if os.path.exists(i)]","if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :",111
2341,"def buffer(self, lines, scroll_end=True, scroll_if_editing=False):<tab>""Add data to be displayed in the buffer.""<tab>self.values.extend(lines)<tab>if scroll_end:<tab><tab>if not self.editing:<tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)<tab><tab><IF-STMT><tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)",elif scroll_if_editing :,124
2342,"def test_getline(self):<tab>with tokenize.open(self.file_name) as fp:<tab><tab>for index, line in enumerate(fp):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line += ""\n""<tab><tab><tab>cached_line = linecache.getline(self.file_name, index + 1)<tab><tab><tab>self.assertEqual(line, cached_line)","if not line . endswith ( ""\n"" ) :",97
2343,"def selectRow(self, rowNumber, highlight=None):<tab>if rowNumber == ""h"":<tab><tab>rowNumber = 0<tab>else:<tab><tab>rowNumber = int(rowNumber) + 1<tab>if 1 > rowNumber >= len(self.cells) + 1:<tab><tab>raise Exception(""Invalid row number."")<tab>else:<tab><tab>selected = self.cells[rowNumber][0].selected<tab><tab>for cell in self.cells[rowNumber]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if selected:<tab><tab><tab><tab><tab>cell.deselect()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>cell.select()<tab><tab><tab>else:<tab><tab><tab><tab>if highlight:<tab><tab><tab><tab><tab>cell.mouseEnter()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>cell.mouseLeave()",if highlight is None :,193
2344,"def put(self, session):<tab>with sess_lock:<tab><tab>self.parent.put(session)<tab><tab># Do not store the session if skip paths<tab><tab>for sp in self.skip_paths:<tab><tab><tab>if request.path.startswith(sp):<tab><tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>del self._cache[session.sid]<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass<tab><tab>self._cache[session.sid] = session<tab>self._normalize()",if session . sid in self . _cache :,133
2345,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_status().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.add_doc_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,169
2346,"def extract(self, zip):<tab>max_nb = maxNbFile(self)<tab>for index, field in enumerate(zip.array(""file"")):<tab><tab><IF-STMT><tab><tab><tab>self.warning(<tab><tab><tab><tab>""ZIP archive contains many files, but only first %s files are processed""<tab><tab><tab><tab>% max_nb<tab><tab><tab>)<tab><tab><tab>break<tab><tab>self.processFile(field)",if max_nb is not None and max_nb <= index :,110
2347,"def get_norm(norm, out_channels):<tab>if isinstance(norm, str):<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>norm = {<tab><tab><tab>""BN"": BatchNorm2d,<tab><tab><tab>""GN"": lambda channels: nn.GroupNorm(32, channels),<tab><tab><tab>""nnSyncBN"": nn.SyncBatchNorm,  # keep for debugging<tab><tab><tab>"""": lambda x: x,<tab><tab>}[norm]<tab>return norm(out_channels)",if len ( norm ) == 0 :,118
2348,"def execute(self):<tab>if self._dirty or not self._qr:<tab><tab>model_class = self.model_class<tab><tab>query_meta = self.get_query_meta()<tab><tab>if self._tuples:<tab><tab><tab>ResultWrapper = TuplesQueryResultWrapper<tab><tab>elif self._dicts:<tab><tab><tab>ResultWrapper = DictQueryResultWrapper<tab><tab>elif self._naive or not self._joins or self.verify_naive():<tab><tab><tab>ResultWrapper = NaiveQueryResultWrapper<tab><tab><IF-STMT><tab><tab><tab>ResultWrapper = AggregateQueryResultWrapper<tab><tab>else:<tab><tab><tab>ResultWrapper = ModelQueryResultWrapper<tab><tab>self._qr = ResultWrapper(model_class, self._execute(), query_meta)<tab><tab>self._dirty = False<tab><tab>return self._qr<tab>else:<tab><tab>return self._qr",elif self . _aggregate_rows :,198
2349,"def emitIpToDomainsData(self, data, event):<tab>self.emitRawRirData(data, event)<tab>domains = data.get(""domains"")<tab>if isinstance(domains, list):<tab><tab>for domain in domains:<tab><tab><tab>if self.checkForStop():<tab><tab><tab><tab>return None<tab><tab><tab>domain = domain.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.emitHostname(domain, event)",if domain :,105
2350,"def delete(self):<tab>from weblate.trans.models import Change, Suggestion, Vote<tab>fast_deletes = []<tab>for item in self.fast_deletes:<tab><tab><IF-STMT><tab><tab><tab>fast_deletes.append(Vote.objects.filter(suggestion__in=item))<tab><tab><tab>fast_deletes.append(Change.objects.filter(suggestion__in=item))<tab><tab>fast_deletes.append(item)<tab>self.fast_deletes = fast_deletes<tab>return super().delete()",if item . model is Suggestion :,124
2351,"def token(self):<tab>if not self._token:<tab><tab>try:<tab><tab><tab>cookie_token = self.state[""request""].headers.cookie[CSRF_TOKEN].value<tab><tab>except KeyError:<tab><tab><tab>cookie_token = """"<tab><tab><IF-STMT><tab><tab><tab>self._token = cookie_token<tab><tab>else:<tab><tab><tab>self._token = get_random_string(TOKEN_LENGTH)<tab>return self._token",if len ( cookie_token ) == TOKEN_LENGTH :,113
2352,"def get_logs(last_file=None, last_time=None):<tab>try:<tab><tab>response = client.get_logs(last_file=last_file, last_time=last_time)<tab><tab>get_logs_streamer(<tab><tab><tab>show_timestamp=not hide_time,<tab><tab><tab>all_containers=all_containers,<tab><tab><tab>all_info=all_info,<tab><tab>)(response)<tab><tab>return response<tab>except (ApiException, HTTPError) as e:<tab><tab><IF-STMT><tab><tab><tab>handle_cli_error(<tab><tab><tab><tab>e,<tab><tab><tab><tab>message=""Could not get logs for run `{}`."".format(client.run_uuid),<tab><tab><tab>)<tab><tab><tab>sys.exit(1)",if not follow :,179
2353,"def update(self, targets):<tab>Section.update(self, targets)<tab>outputNames = set()<tab>for target in targets:<tab><tab>g = target.globals()<tab><tab>outputNames.update([k for k in g.keys() if k.startswith(""output:"")])<tab>rows = []<tab>outputNames = sorted(outputNames)<tab>for outputName in outputNames:<tab><tab>row = self.__rows.get(outputName)<tab><tab><IF-STMT><tab><tab><tab>row = _OutputRow(outputName)<tab><tab><tab>self.__rows[outputName] = row<tab><tab>row.update(targets)<tab><tab>row.setAlternate(len(rows) % 2)<tab><tab>rows.append(row)<tab>self._mainColumn()[:] = rows",if row is None :,181
2354,"def getBranches(self):<tab>returned = []<tab>for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout:<tab><tab>if git_branch_line.startswith(""*""):<tab><tab><tab>git_branch_line = git_branch_line[1:]<tab><tab>git_branch_line = git_branch_line.strip()<tab><tab><IF-STMT><tab><tab><tab>alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER)<tab><tab><tab>returned.append(branch.LocalBranchAlias(self, alias_name, aliased))<tab><tab>else:<tab><tab><tab>returned.append(branch.LocalBranch(self, git_branch_line))<tab>return returned",if BRANCH_ALIAS_MARKER in git_branch_line :,178
2355,"def has_bad_headers(self):<tab>headers = [self.sender, self.reply_to] + self.recipients<tab>for header in headers:<tab><tab>if _has_newline(header):<tab><tab><tab>return True<tab>if self.subject:<tab><tab>if _has_newline(self.subject):<tab><tab><tab>for linenum, line in enumerate(self.subject.split(""\r\n"")):<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if _has_newline(line):<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if len(line.strip()) == 0:<tab><tab><tab><tab><tab>return True<tab>return False","if linenum > 0 and line [ 0 ] not in ""\t "" :",186
2356,"def resolve_references(self, note, reflist):<tab>assert len(note[""ids""]) == 1<tab>id = note[""ids""][0]<tab>for ref in reflist:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ref.delattr(""refname"")<tab><tab>ref[""refid""] = id<tab><tab>assert len(ref[""ids""]) == 1<tab><tab>note.add_backref(ref[""ids""][0])<tab><tab>ref.resolved = 1<tab>note.resolved = 1",if ref . resolved :,118
2357,"def pickPath(self, color):<tab>self.path[color] = ()<tab>currentPos = self.starts[color]<tab>while True:<tab><tab>minDist = None<tab><tab>minGuide = None<tab><tab>for guide in self.guides[color]:<tab><tab><tab>guideDist = dist(currentPos, guide)<tab><tab><tab>if minDist == None or guideDist < minDist:<tab><tab><tab><tab>minDist = guideDist<tab><tab><tab><tab>minGuide = guide<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if minGuide == None:<tab><tab><tab>return<tab><tab>self.path[color] = self.path[color] + (minGuide,)<tab><tab>currentPos = minGuide<tab><tab>self.guides[color].remove(minGuide)","if dist ( currentPos , self . ends [ color ] ) == 1 :",192
2358,"def __hierarchyViewKeyPress(hierarchyView, event):<tab>if event == __editSourceKeyPress:<tab><tab>selectedPath = __hierarchyViewSelectedPath(hierarchyView)<tab><tab><IF-STMT><tab><tab><tab>__editSourceNode(<tab><tab><tab><tab>hierarchyView.getContext(), hierarchyView.scene(), selectedPath<tab><tab><tab>)<tab><tab>return True<tab>elif event == __editTweaksKeyPress:<tab><tab>selectedPath = __hierarchyViewSelectedPath(hierarchyView)<tab><tab>if selectedPath is not None:<tab><tab><tab>__editTweaksNode(<tab><tab><tab><tab>hierarchyView.getContext(), hierarchyView.scene(), selectedPath<tab><tab><tab>)<tab><tab>return True",if selectedPath is not None :,173
2359,"def getSubsegments(self):<tab>for num, localdata in self.lfh.LocalData:<tab><tab>for bucket, seginfo in localdata.SegmentInfo:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>yield Win32Subsegment(self.trace, self.heap, seginfo.ActiveSubsegment)",if seginfo . ActiveSubsegment == 0 :,84
2360,"def test_full_hd_bluray(self):<tab>cur_test = ""full_hd_bluray""<tab>cur_qual = common.Quality.FULLHDBLURAY<tab>for name, tests in iteritems(self.test_cases):<tab><tab>for test in tests:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(cur_qual, common.Quality.name_quality(test))<tab><tab><tab>else:<tab><tab><tab><tab>self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",if name == cur_test :,135
2361,"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab>if self.op == ""+"":<tab><tab><tab>self.current += num<tab><tab>elif self.op == ""-"":<tab><tab><tab>self.current -= num<tab><tab>elif self.op == ""*"":<tab><tab><tab>self.current *= num<tab><tab><IF-STMT><tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res","elif self . op == ""/"" :",187
2362,"def strip_export_type(path):<tab>matched = re.search(r""#([a-zA-Z0-9\-]+\\+[a-zA-Z0-9\-]+)?$"", path.encode(""utf-8""))<tab>mime_type = None<tab>if matched:<tab><tab>fragment = matched.group(0)<tab><tab>mime_type = matched.group(1)<tab><tab><IF-STMT><tab><tab><tab>mime_type = mime_type.replace(""+"", ""/"")<tab><tab>path = path[: -len(fragment)]<tab>return (path, mime_type)",if mime_type is not None :,137
2363,"def _save_as_module(file, data, binary=False):<tab>if not data:<tab><tab>return<tab>with open(file, ""w"") as f:<tab><tab>f.write(""DATA="")<tab><tab><IF-STMT><tab><tab><tab>f.write('""')<tab><tab><tab>f.write(base64.b64encode(data).decode(""ascii""))<tab><tab><tab>f.write('""')<tab><tab>else:<tab><tab><tab>f.write(str(data).replace(""\\\\"", ""\\""))<tab><tab>f.flush()",if binary :,120
2364,"def ProcessStringLiteral(self):<tab>if self._lastToken == None or self._lastToken.type == self.OpenBrace:<tab><tab>text = super(JavaScriptBaseLexer, self).text<tab><tab><IF-STMT><tab><tab><tab>if len(self._scopeStrictModes) > 0:<tab><tab><tab><tab>self._scopeStrictModes.pop()<tab><tab><tab>self._useStrictCurrent = True<tab><tab><tab>self._scopeStrictModes.append(self._useStrictCurrent)","if text == '""use strict""' or text == ""'use strict'"" :",124
2365,"def run(self, ttl=None):<tab>self.zeroconf = zeroconf.Zeroconf()<tab>zeroconf.ServiceBrowser(self.zeroconf, self.domain, MDNSHandler(self))<tab>if ttl:<tab><tab>gobject.timeout_add(ttl * 1000, self.shutdown)<tab>self.__running = True<tab>self.__mainloop = gobject.MainLoop()<tab>context = self.__mainloop.get_context()<tab>while self.__running:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>context.iteration(True)<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(0.1)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>break<tab>self.zeroconf.close()<tab>logger.debug(""MDNSListener.run() quit"")",if context . pending ( ) :,187
2366,"def topology_change_notify(self, port_state):<tab>notice = False<tab>if port_state is PORT_STATE_FORWARD:<tab><tab>for port in self.ports.values():<tab><tab><tab>if port.role is DESIGNATED_PORT:<tab><tab><tab><tab>notice = True<tab><tab><tab><tab>break<tab>else:<tab><tab>notice = True<tab>if notice:<tab><tab>self.send_event(EventTopologyChange(self.dp))<tab><tab><IF-STMT><tab><tab><tab>self._transmit_tc_bpdu()<tab><tab>else:<tab><tab><tab>self._transmit_tcn_bpdu()",if self . is_root_bridge :,154
2367,def close_open_fds(keep=None):  # noqa<tab>keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None]<tab>for fd in reversed(range(get_fdmax(default=2048))):<tab><tab>if fd not in keep:<tab><tab><tab>try:<tab><tab><tab><tab>os.close(fd)<tab><tab><tab>except OSError as exc:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise,if exc . errno != errno . EBADF :,120
2368,"def collect_attributes(options, node, master_list):<tab>""""""Collect all attributes""""""<tab>for ii in node.instructions:<tab><tab>if field_check(ii, ""attributes""):<tab><tab><tab>s = getattr(ii, ""attributes"")<tab><tab><tab>if isinstance(s, list):<tab><tab><tab><tab>for x in s:<tab><tab><tab><tab><tab>if x not in master_list:<tab><tab><tab><tab><tab><tab>master_list.append(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>master_list.append(s)<tab>for nxt in node.next.values():<tab><tab>collect_attributes(options, nxt, master_list)",elif s != None and s not in master_list :,161
2369,"def remove_test_run_directories(expiry_time: int = 60 * 60) -> int:<tab>removed = 0<tab>directories = glob.glob(os.path.join(UUID_VAR_DIR, ""test-backend"", ""run_*""))<tab>for test_run in directories:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>shutil.rmtree(test_run)<tab><tab><tab><tab>removed += 1<tab><tab><tab>except FileNotFoundError:<tab><tab><tab><tab>pass<tab>return removed",if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,136
2370,"def read_work_titles(fields):<tab>found = []<tab>if ""240"" in fields:<tab><tab>for line in fields[""240""]:<tab><tab><tab>title = join_subfield_values(line, [""a"", ""m"", ""n"", ""p"", ""r""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found.append(title)<tab>if ""130"" in fields:<tab><tab>for line in fields[""130""]:<tab><tab><tab>title = "" "".join(get_lower_subfields(line))<tab><tab><tab>if title not in found:<tab><tab><tab><tab>found.append(title)<tab>return {""work_titles"": found} if found else {}",if title not in found :,157
2371,"def _process_v1_msg(prot, msg):<tab>header = None<tab>body = msg[1]<tab>if not isinstance(body, (binary_type, mmap, memoryview)):<tab><tab>raise ValidationError(body, ""Body must be a bytestream."")<tab>if len(msg) > 2:<tab><tab>header = msg[2]<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(header, ""Header must be a dict."")<tab><tab>for k, v in header.items():<tab><tab><tab>header[k] = msgpack.unpackb(v)<tab>ctx = MessagePackMethodContext(prot, MessagePackMethodContext.SERVER)<tab>ctx.in_string = [body]<tab>ctx.transport.in_header = header<tab>return ctx","if not isinstance ( header , dict ) :",177
2372,"def find(self, node):<tab>typename = type(node).__name__<tab>method = getattr(self, ""find_{}"".format(typename), None)<tab>if method is None:<tab><tab>fields = getattr(node, ""_fields"", None)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for field in fields:<tab><tab><tab>value = getattr(node, field)<tab><tab><tab>for result in self.find(value):<tab><tab><tab><tab>yield result<tab>else:<tab><tab>for result in method(node):<tab><tab><tab>yield result",if fields is None :,129
2373,"def _str_param_list(self, name):<tab>out = []<tab>if self[name]:<tab><tab>out += self._str_header(name)<tab><tab>for param in self[name]:<tab><tab><tab>parts = []<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts.append(param.name)<tab><tab><tab>if param.type:<tab><tab><tab><tab>parts.append(param.type)<tab><tab><tab>out += ["" : "".join(parts)]<tab><tab><tab>if param.desc and """".join(param.desc).strip():<tab><tab><tab><tab>out += self._str_indent(param.desc)<tab><tab>out += [""""]<tab>return out",if param . name :,157
2374,"def _get_image(self, image_list, source):<tab>if source.startswith(""wx""):<tab><tab>img = wx.ArtProvider_GetBitmap(source, wx.ART_OTHER, _SIZE)<tab>else:<tab><tab>path = os.path.join(_BASE, source)<tab><tab><IF-STMT><tab><tab><tab>img = wx.Image(path, wx.BITMAP_TYPE_GIF).ConvertToBitmap()<tab><tab>else:<tab><tab><tab>img = wx.Image(path, wx.BITMAP_TYPE_PNG).ConvertToBitmap()<tab>return image_list.Add(img)","if source . endswith ( ""gif"" ) :",144
2375,"def change_opacity_function(self, new_f):<tab>self.opacity_function = new_f<tab>dr = self.radius / self.num_levels<tab>sectors = []<tab>for submob in self.submobjects:<tab><tab><IF-STMT><tab><tab><tab>sectors.append(submob)<tab>for (r, submob) in zip(np.arange(0, self.radius, dr), sectors):<tab><tab>if type(submob) != AnnularSector:<tab><tab><tab># it's the shadow, don't dim it<tab><tab><tab>continue<tab><tab>alpha = self.opacity_function(r)<tab><tab>submob.set_fill(opacity=alpha)",if type ( submob ) == AnnularSector :,180
2376,"def _sqlite_post_configure_engine(url, engine, follower_ident):<tab>from sqlalchemy import event<tab>@event.listens_for(engine, ""connect"")<tab>def connect(dbapi_connection, connection_record):<tab><tab># use file DBs in all cases, memory acts kind of strangely<tab><tab># as an attached<tab><tab><IF-STMT><tab><tab><tab>dbapi_connection.execute('ATTACH DATABASE ""test_schema.db"" AS test_schema')<tab><tab>else:<tab><tab><tab>dbapi_connection.execute(<tab><tab><tab><tab>'ATTACH DATABASE ""%s_test_schema.db"" AS test_schema' % follower_ident<tab><tab><tab>)",if not follower_ident :,164
2377,"def apply_conf_file(fn, conf_filename):<tab>for env in LSF_CONF_ENV:<tab><tab>conf_file = get_conf_file(conf_filename, env)<tab><tab>if conf_file:<tab><tab><tab>with open(conf_file) as conf_handle:<tab><tab><tab><tab>value = fn(conf_handle)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value<tab>return None",if value :,101
2378,"def test_call_extern_c_fn(self):<tab>global memcmp<tab>memcmp = cffi_support.ExternCFunction(<tab><tab>""memcmp"",<tab><tab>(""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""),<tab>)<tab>@udf(BooleanVal(FunctionContext, StringVal, StringVal))<tab>def fn(context, a, b):<tab><tab>if a.is_null != b.is_null:<tab><tab><tab>return False<tab><tab>if a is None:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if a.ptr == b.ptr:<tab><tab><tab>return True<tab><tab>return memcmp(a.ptr, b.ptr, a.len) == 0",if len ( a ) != b . len :,199
2379,"def _get_initialized_app(app):<tab>""""""Returns a reference to an initialized App instance.""""""<tab>if app is None:<tab><tab>return firebase_admin.get_app()<tab>if isinstance(app, firebase_admin.App):<tab><tab>initialized_app = firebase_admin.get_app(app.name)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Illegal app argument. App instance not ""<tab><tab><tab><tab>""initialized via the firebase module.""<tab><tab><tab>)<tab><tab>return app<tab>raise ValueError(<tab><tab>""Illegal app argument. Argument must be of type ""<tab><tab>' firebase_admin.App, but given ""{0}"".'.format(type(app))<tab>)",if app is not initialized_app :,177
2380,def compiled_query(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.compiled_query_ is None:<tab><tab><tab><tab>self.compiled_query_ = CompiledQuery()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.compiled_query_,if self . compiled_query_ is None :,96
2381,"def clean_subevent(event, subevent):<tab>if event.has_subevents:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(_(""Subevent cannot be null for event series.""))<tab><tab>if event != subevent.event:<tab><tab><tab>raise ValidationError(_(""The subevent does not belong to this event.""))<tab>else:<tab><tab>if subevent:<tab><tab><tab>raise ValidationError(_(""The subevent does not belong to this event.""))",if not subevent :,102
2382,"def get_blob_type_declaration_sql(self, column):<tab>length = column.get(""length"")<tab>if length:<tab><tab>if length <= self.LENGTH_LIMIT_TINYBLOB:<tab><tab><tab>return ""TINYBLOB""<tab><tab>if length <= self.LENGTH_LIMIT_BLOB:<tab><tab><tab>return ""BLOB""<tab><tab><IF-STMT><tab><tab><tab>return ""MEDIUMBLOB""<tab>return ""LONGBLOB""",if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,115
2383,"def decompress(self, data):<tab>if not data:<tab><tab>return data<tab>if not self._first_try:<tab><tab>return self._obj.decompress(data)<tab>self._data += data<tab>try:<tab><tab>decompressed = self._obj.decompress(data)<tab><tab><IF-STMT><tab><tab><tab>self._first_try = False<tab><tab><tab>self._data = None<tab><tab>return decompressed<tab>except zlib.error:<tab><tab>self._first_try = False<tab><tab>self._obj = zlib.decompressobj(-zlib.MAX_WBITS)<tab><tab>try:<tab><tab><tab>return self.decompress(self._data)<tab><tab>finally:<tab><tab><tab>self._data = None",if decompressed :,163
2384,"def _record_event(self, path, fsevent_handle, filename, events, error):<tab>with self.lock:<tab><tab>self.events[path].append(events)<tab><tab>if events | pyuv.fs.UV_RENAME:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.watches.pop(path).close()",if not os . path . exists ( path ) :,89
2385,"def __init__(self, duration, batch_shape, event_shape, validate_args=None):<tab>if duration is None:<tab><tab><IF-STMT><tab><tab><tab># Infer duration from event_shape.<tab><tab><tab>duration = event_shape[0]<tab>elif duration != event_shape[0]:<tab><tab>if event_shape[0] != 1:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""duration, event_shape mismatch: {} vs {}"".format(duration, event_shape)<tab><tab><tab>)<tab><tab># Infer event_shape from duration.<tab><tab>event_shape = torch.Size((duration,) + event_shape[1:])<tab>self._duration = duration<tab>super().__init__(batch_shape, event_shape, validate_args)",if event_shape [ 0 ] != 1 :,183
2386,"def _CheckPrerequisites(self):<tab>""""""Exits if any of the prerequisites is not met.""""""<tab>if not FLAGS.kubectl:<tab><tab>raise Exception(<tab><tab><tab>""Please provide path to kubectl tool using --kubectl "" ""flag. Exiting.""<tab><tab>)<tab>if not FLAGS.kubeconfig:<tab><tab>raise Exception(<tab><tab><tab>""Please provide path to kubeconfig using --kubeconfig "" ""flag. Exiting.""<tab><tab>)<tab>if self.disk_specs and self.disk_specs[0].disk_type == disk.STANDARD:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Please provide a list of Ceph Monitors using "" ""--ceph_monitors flag.""<tab><tab><tab>)",if not FLAGS . ceph_monitors :,181
2387,"def invalidateDependentSlices(self, iFirstCurve):<tab># only user defined curve can have slice dependency relationships<tab>if self.isSystemCurveIndex(iFirstCurve):<tab><tab>return<tab>nCurves = self.getNCurves()<tab>for i in range(iFirstCurve, nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab><IF-STMT><tab><tab><tab>c.invalidate()<tab><tab>elif i == iFirstCurve:<tab><tab><tab># if first curve isn't a slice,<tab><tab><tab>break<tab><tab><tab># there are no dependent slices","if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",154
2388,"def find_backwards(self, offset):<tab>try:<tab><tab>for _, token_type, token_value in reversed(self.tokens[self.offset : offset]):<tab><tab><tab>if token_type in (""comment"", ""linecomment""):<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>prefix, comment = token_value.split(None, 1)<tab><tab><tab><tab>except ValueError:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return [comment.rstrip()]<tab><tab>return []<tab>finally:<tab><tab>self.offset = offset",if prefix in self . comment_tags :,140
2389,"def parse_column_definitions(self, elem):<tab>for column_elem in elem.findall(""column""):<tab><tab>name = column_elem.get(""name"", None)<tab><tab>assert name is not None, ""Required 'name' attribute missing from column def""<tab><tab>index = column_elem.get(""index"", None)<tab><tab>assert index is not None, ""Required 'index' attribute missing from column def""<tab><tab>index = int(index)<tab><tab>self.columns[name] = index<tab><tab><IF-STMT><tab><tab><tab>self.largest_index = index<tab>assert ""value"" in self.columns, ""Required 'value' column missing from column def""<tab>if ""name"" not in self.columns:<tab><tab>self.columns[""name""] = self.columns[""value""]",if index > self . largest_index :,188
2390,"def __find_smallest(self):<tab>""""""Find the smallest uncovered value in the matrix.""""""<tab>minval = sys.maxsize<tab>for i in range(self.n):<tab><tab>for j in range(self.n):<tab><tab><tab>if (not self.row_covered[i]) and (not self.col_covered[j]):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>minval = self.C[i][j]<tab>return minval",if minval > self . C [ i ] [ j ] :,114
2391,"def includes_tools_for_display_in_tool_panel(self):<tab>if self.includes_tools:<tab><tab>tool_dicts = self.metadata[""tools""]<tab><tab>for tool_dict in tool_dicts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False","if tool_dict . get ( ""add_to_tool_panel"" , True ) :",84
2392,"def commit(self, notify=False):<tab>if self.editing:<tab><tab>text = self._text<tab><tab>if text:<tab><tab><tab>try:<tab><tab><tab><tab>value = self.type(text)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>return<tab><tab><tab>value = self.clamp_value(value)<tab><tab>else:<tab><tab><tab>value = self.empty<tab><tab><tab>if value is NotImplemented:<tab><tab><tab><tab>return<tab><tab>self.value = value<tab><tab>self.insertion_point = None<tab><tab><IF-STMT><tab><tab><tab>self.change_text(unicode(value))<tab><tab>else:<tab><tab><tab>self._text = unicode(value)<tab><tab>self.editing = False<tab>else:<tab><tab>self.insertion_point = None",if notify :,183
2393,"def GeneratePageMetatadata(self, task):<tab>address_space = self.session.GetParameter(""default_address_space"")<tab>for vma in task.mm.mmap.walk_list(""vm_next""):<tab><tab>start = vma.vm_start<tab><tab>end = vma.vm_end<tab><tab># Skip the entire region.<tab><tab>if end < self.plugin_args.start:<tab><tab><tab>continue<tab><tab># Done.<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>for vaddr in utils.xrange(start, end, 0x1000):<tab><tab><tab>if self.plugin_args.start <= vaddr <= self.plugin_args.end:<tab><tab><tab><tab>yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if start > self . plugin_args . end :,195
2394,"def _check_for_duplicate_host_entries(self, task_entries):<tab>non_host_statuses = (<tab><tab>models.HostQueueEntry.Status.PARSING,<tab><tab>models.HostQueueEntry.Status.ARCHIVING,<tab>)<tab>for task_entry in task_entries:<tab><tab>using_host = (<tab><tab><tab>task_entry.host is not None and task_entry.status not in non_host_statuses<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._assert_host_has_no_agent(task_entry)",if using_host :,136
2395,"def get_biggest_wall_time(jsons):<tab>lowest_wall = None<tab>for j in jsons:<tab><tab><IF-STMT><tab><tab><tab>lowest_wall = j[""wall_time""]<tab><tab>if lowest_wall < j[""wall_time""]:<tab><tab><tab>lowest_wall = j[""wall_time""]<tab>return lowest_wall",if lowest_wall is None :,87
2396,"def log_change_report(self, old_value, new_value, include_details=False):<tab>from octoprint.util import map_boolean<tab>with self._check_mutex:<tab><tab>self._logger.info(<tab><tab><tab>""Connectivity changed from {} to {}"".format(<tab><tab><tab><tab>map_boolean(old_value, ""online"", ""offline""),<tab><tab><tab><tab>map_boolean(new_value, ""online"", ""offline""),<tab><tab><tab>)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.log_details()",if include_details :,136
2397,"def _include_block(self, value, context=None):<tab>if hasattr(value, ""render_as_block""):<tab><tab><IF-STMT><tab><tab><tab>new_context = context.get_all()<tab><tab>else:<tab><tab><tab>new_context = {}<tab><tab>return jinja2.Markup(value.render_as_block(context=new_context))<tab>return jinja2.Markup(value)",if context :,96
2398,"def __lt__(self, other):<tab># 0: clock 1: timestamp 3: process id<tab>try:<tab><tab>A, B = self[0], other[0]<tab><tab># uses logical clock value first<tab><tab>if A and B:  # use logical clock if available<tab><tab><tab><IF-STMT>  # equal clocks use lower process id<tab><tab><tab><tab>return self[2] < other[2]<tab><tab><tab>return A < B<tab><tab>return self[1] < other[1]  # ... or use timestamp<tab>except IndexError:<tab><tab>return NotImplemented",if A == B :,135
2399,"def _get_port():<tab>while True:<tab><tab>port = 20000 + random.randint(1, 9999)<tab><tab>for i in range(5):<tab><tab><tab>sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<tab><tab><tab>result = sock.connect_ex((""127.0.0.1"", port))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>return port",if result == 0 :,107
2400,"def fetch_all(self, api_client, fetchstatuslogger, q, targets):<tab>self.fetchstatuslogger = fetchstatuslogger<tab>if targets != None:<tab><tab># Ensure targets is a tuple<tab><tab>if type(targets) != list and type(targets) != tuple:<tab><tab><tab>targets = tuple(<tab><tab><tab><tab>targets,<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>targets = tuple(targets)<tab>for target in targets:<tab><tab>self._fetch_targets(api_client, q, target)",elif type ( targets ) != tuple :,130
2401,"def migrate_node_facts(facts):<tab>""""""Migrate facts from various roles into node""""""<tab>params = {<tab><tab>""common"": (""dns_ip""),<tab>}<tab>if ""node"" not in facts:<tab><tab>facts[""node""] = {}<tab># pylint: disable=consider-iterating-dictionary<tab>for role in params.keys():<tab><tab><IF-STMT><tab><tab><tab>for param in params[role]:<tab><tab><tab><tab>if param in facts[role]:<tab><tab><tab><tab><tab>facts[""node""][param] = facts[role].pop(param)<tab>return facts",if role in facts :,136
2402,"def build_dimension_param(self, dimension, params):<tab>prefix = ""Dimensions.member""<tab>i = 0<tab>for dim_name in dimension:<tab><tab>dim_value = dimension[dim_name]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(dim_value, six.string_types):<tab><tab><tab><tab>dim_value = [dim_value]<tab><tab><tab>for value in dim_value:<tab><tab><tab><tab>params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name<tab><tab><tab><tab>params[""%s.%d.Value"" % (prefix, i + 1)] = value<tab><tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name<tab><tab><tab>i += 1",if dim_value :,192
2403,"def add_if_unique(self, issuer, use, keys):<tab>if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]:<tab><tab>for typ, key in keys:<tab><tab><tab>flag = 1<tab><tab><tab>for _typ, _key in self.issuer_keys[issuer][use]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>flag = 0<tab><tab><tab><tab><tab>break<tab><tab><tab>if flag:<tab><tab><tab><tab>self.issuer_keys[issuer][use].append((typ, key))<tab>else:<tab><tab>self.issuer_keys[issuer][use] = keys",if _typ == typ and key is _key :,158
2404,"def run(self):<tab>while True:<tab><tab>message = self.in_queue.get()<tab><tab><IF-STMT><tab><tab><tab>self.reset()<tab><tab>elif message == EXIT:<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>index, transaction = message<tab><tab><tab>self.results_queue.put((index, self.validate(transaction)))",if message == RESET :,89
2405,"def __run(self):<tab>threads = self.parameters()[""threads""].getTypedValue()<tab>with IECore.tbb_global_control(<tab><tab>IECore.tbb_global_control.parameter.max_allowed_parallelism,<tab><tab>IECore.hardwareConcurrency() if threads == 0 else threads,<tab>):<tab><tab>self._executeStartupFiles(self.root().getName())<tab><tab># Append DEBUG message with process information to all messages<tab><tab>defaultMessageHandler = IECore.MessageHandler.getDefaultHandler()<tab><tab><IF-STMT><tab><tab><tab>IECore.MessageHandler.setDefaultHandler(<tab><tab><tab><tab>Gaffer.ProcessMessageHandler(defaultMessageHandler)<tab><tab><tab>)<tab><tab>return self._run(self.parameters().getValidatedValue())","if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :",194
2406,"def adjust_uri(self, uri, relativeto):<tab>""""""Adjust the given ``uri`` based on the given relative URI.""""""<tab>key = (uri, relativeto)<tab>if key in self._uri_cache:<tab><tab>return self._uri_cache[key]<tab>if uri[0] != ""/"":<tab><tab><IF-STMT><tab><tab><tab>v = self._uri_cache[key] = posixpath.join(<tab><tab><tab><tab>posixpath.dirname(relativeto), uri<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>v = self._uri_cache[key] = ""/"" + uri<tab>else:<tab><tab>v = self._uri_cache[key] = uri<tab>return v",if relativeto is not None :,164
2407,"def decoder(s):<tab>r = []<tab>decode = []<tab>for c in s:<tab><tab><IF-STMT><tab><tab><tab>decode.append(""&"")<tab><tab>elif c == ""-"" and decode:<tab><tab><tab>if len(decode) == 1:<tab><tab><tab><tab>r.append(""&"")<tab><tab><tab>else:<tab><tab><tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab><tab><tab>decode = []<tab><tab>elif decode:<tab><tab><tab>decode.append(c)<tab><tab>else:<tab><tab><tab>r.append(c)<tab>if decode:<tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab>bin_str = """".join(r)<tab>return (bin_str, len(s))","if c == ""&"" and not decode :",188
2408,"def _process_file(self, content):<tab>args = []<tab>for line in content.splitlines():<tab><tab>line = line.strip()<tab><tab>if line.startswith(""-""):<tab><tab><tab>args.extend(self._split_option(line))<tab><tab><IF-STMT><tab><tab><tab>args.append(line)<tab>return args","elif line and not line . startswith ( ""#"" ) :",83
2409,"def _method_events_callback(self, values):<tab>try:<tab><tab>previous_echoed = (<tab><tab><tab>values[""child_result_list""][-1].decode().split(""\n"")[-2].strip()<tab><tab>)<tab><tab>if previous_echoed.endswith(""foo1""):<tab><tab><tab>return ""echo foo2\n""<tab><tab>elif previous_echoed.endswith(""foo2""):<tab><tab><tab>return ""echo foo3\n""<tab><tab><IF-STMT><tab><tab><tab>return ""exit\n""<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected output {0!r}"".format(previous_echoed))<tab>except IndexError:<tab><tab>return ""echo foo1\n""","elif previous_echoed . endswith ( ""foo3"" ) :",172
2410,"def __delete_hook(self, rpc):<tab>try:<tab><tab>rpc.check_success()<tab>except apiproxy_errors.Error:<tab><tab>return None<tab>result = []<tab>for status in rpc.response.delete_status_list():<tab><tab><IF-STMT><tab><tab><tab>result.append(DELETE_SUCCESSFUL)<tab><tab>elif status == MemcacheDeleteResponse.NOT_FOUND:<tab><tab><tab>result.append(DELETE_ITEM_MISSING)<tab><tab>else:<tab><tab><tab>result.append(DELETE_NETWORK_FAILURE)<tab>return result",if status == MemcacheDeleteResponse . DELETED :,139
2411,"def __createRandom(plug):<tab>node = plug.node()<tab>parentNode = node.ancestor(Gaffer.Node)<tab>with Gaffer.UndoScope(node.scriptNode()):<tab><tab>randomNode = Gaffer.Random()<tab><tab>parentNode.addChild(randomNode)<tab><tab><IF-STMT><tab><tab><tab>plug.setInput(randomNode[""outFloat""])<tab><tab>elif isinstance(plug, Gaffer.Color3fPlug):<tab><tab><tab>plug.setInput(randomNode[""outColor""])<tab>GafferUI.NodeEditor.acquire(randomNode)","if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) :",158
2412,"def escapeentities(self, line):<tab>""Escape all Unicode characters to HTML entities.""<tab>result = """"<tab>pos = TextPosition(line)<tab>while not pos.finished():<tab><tab>if ord(pos.current()) > 128:<tab><tab><tab>codepoint = hex(ord(pos.current()))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>codepoint = hex(ord(pos.next()) + 0xF800)<tab><tab><tab>result += ""&#"" + codepoint[1:] + "";""<tab><tab>else:<tab><tab><tab>result += pos.current()<tab><tab>pos.skipcurrent()<tab>return result","if codepoint == ""0xd835"" :",143
2413,def get_and_set_all_aliases(self):<tab>all_aliases = []<tab>for page in self.pages:<tab><tab><IF-STMT><tab><tab><tab>all_aliases.extend(page.relations.aliases_norm)<tab><tab>if page.relations.aliases is not None:<tab><tab><tab>all_aliases.extend(page.relations.aliases)<tab>return set(all_aliases),if page . relations . aliases_norm is not None :,101
2414,"def _list_cases(suite):<tab>for test in suite:<tab><tab><IF-STMT><tab><tab><tab>_list_cases(test)<tab><tab>elif isinstance(test, unittest.TestCase):<tab><tab><tab>if support.match_test(test):<tab><tab><tab><tab>print(test.id())","if isinstance ( test , unittest . TestSuite ) :",75
2415,"def get_next_requests(self, max_n_requests, **kwargs):<tab>next_pages = []<tab>partitions = set(kwargs.pop(""partitions"", []))<tab>for partition_id in range(0, self.queue_partitions):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>results = self.queue.get_next_requests(max_n_requests, partition_id)<tab><tab>next_pages.extend(results)<tab><tab>self.logger.debug(<tab><tab><tab>""Got %d requests for partition id %d"", len(results), partition_id<tab><tab>)<tab>return next_pages",if partition_id not in partitions :,149
2416,"def __iter__(self):<tab>if (self.query is not None) and sqlite.is_read_only_query(self.query):<tab><tab>cur = self.connection.cursor()<tab><tab>results = cur.execute(self.query)<tab><tab><IF-STMT><tab><tab><tab>yield [col[0] for col in cur.description]<tab><tab>for i, row in enumerate(results):<tab><tab><tab>if i >= self.limit:<tab><tab><tab><tab>break<tab><tab><tab>yield [val for val in row]<tab>else:<tab><tab>yield",if self . headers :,131
2417,"def rollback(self):<tab>for operation, values in self.current_transaction_state[::-1]:<tab><tab>if operation == ""insert"":<tab><tab><tab>values.remove()<tab><tab><IF-STMT><tab><tab><tab>old_value, new_value = values<tab><tab><tab>if new_value.full_filename != old_value.full_filename:<tab><tab><tab><tab>os.unlink(new_value.full_filename)<tab><tab><tab>old_value.write()<tab>self._post_xact_cleanup()","elif operation == ""update"" :",121
2418,"def index(self, value):<tab>if self._growing:<tab><tab>if self._start <= value < self._stop:<tab><tab><tab>q, r = divmod(value - self._start, self._step)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(q)<tab>else:<tab><tab>if self._start >= value > self._stop:<tab><tab><tab>q, r = divmod(self._start - value, -self._step)<tab><tab><tab>if r == self._zero:<tab><tab><tab><tab>return int(q)<tab>raise ValueError(""{} is not in numeric range"".format(value))",if r == self . _zero :,146
2419,"def validate_name_and_description(body, check_length=True):<tab>for attribute in [""name"", ""description"", ""display_name"", ""display_description""]:<tab><tab>value = body.get(attribute)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, six.string_types):<tab><tab><tab><tab>body[attribute] = value.strip()<tab><tab><tab>if check_length:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>utils.check_string_length(<tab><tab><tab><tab><tab><tab>body[attribute], attribute, min_length=0, max_length=255<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except exception.InvalidInput as error:<tab><tab><tab><tab><tab>raise webob.exc.HTTPBadRequest(explanation=error.msg)",if value is not None :,184
2420,"def printWiki():<tab>firstHeading = False<tab>for m in protocol:<tab><tab>if m[0] == """":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output(""|}"")<tab><tab><tab>__printWikiHeader(m[1], m[2])<tab><tab><tab>firstHeading = True<tab><tab>else:<tab><tab><tab>output(""|-"")<tab><tab><tab>output(<tab><tab><tab><tab>'| <span style=""white-space:nowrap;""><tt>'<tab><tab><tab><tab>+ m[0]<tab><tab><tab><tab>+ ""</tt></span> || || ""<tab><tab><tab><tab>+ m[1]<tab><tab><tab>)<tab>output(""|}"")",if firstHeading :,155
2421,"def _get_platforms(data):<tab>platform_list = []<tab>for item in data:<tab><tab>if item.startswith(""PlatformEdit.html?""):<tab><tab><tab>parameter_list = item.split(""PlatformEdit.html?"", 1)[1].split(""&"")<tab><tab><tab>for parameter in parameter_list:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>platform_list.append(parameter.split(""="")[1])<tab>return platform_list","if parameter . startswith ( ""platformName"" ) :",110
2422,"def find_scintilla_constants(f):<tab>lexers = []<tab>states = []<tab>for name in f.order:<tab><tab>v = f.features[name]<tab><tab>if v[""Category""] != ""Deprecated"":<tab><tab><tab>if v[""FeatureType""] == ""val"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>states.append((name, v[""Value""]))<tab><tab><tab><tab>elif name.startswith(""SCLEX_""):<tab><tab><tab><tab><tab>lexers.append((name, v[""Value""]))<tab>return (lexers, states)","if name . startswith ( ""SCE_"" ) :",137
2423,"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab>if isinstance(definition, ast.OperationDefinition):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab>if operation:<tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab>elif definition.name and definition.name.value == operation_name:<tab><tab><tab><tab>return definition<tab>return operation",if not operation_name :,186
2424,"def _insertNewItemAtParent(self, targetIndex):<tab>if not self.isContainer(targetIndex):<tab><tab>return<tab>elif not self.isContainerOpen(targetIndex):<tab><tab>uri = self._rows[targetIndex].uri<tab><tab>modelNode = self.getNodeForURI(uri)<tab><tab><IF-STMT><tab><tab><tab>modelNode.markForRefreshing()<tab><tab>return<tab>self.refreshView(targetIndex)",if modelNode :,103
2425,"def _get_trace(self, model, guide, args, kwargs):<tab>model_trace, guide_trace = super()._get_trace(model, guide, args, kwargs)<tab># Mark all sample sites with require_backward to gather enumerated<tab># sites and adjust cond_indep_stack of all sample sites.<tab>for node in model_trace.nodes.values():<tab><tab><IF-STMT><tab><tab><tab>log_prob = node[""packed""][""unscaled_log_prob""]<tab><tab><tab>require_backward(log_prob)<tab>self._saved_state = model, model_trace, guide_trace, args, kwargs<tab>return model_trace, guide_trace","if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :",166
2426,"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>from .datastructures import iter_multi_items<tab>iterable = iter_multi_items(obj)<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, value in iterable:<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab>if not isinstance(key, bytes):<tab><tab><tab>key = text_type(key).encode(charset)<tab><tab><IF-STMT><tab><tab><tab>value = text_type(value).encode(charset)<tab><tab>yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)","if not isinstance ( value , bytes ) :",168
2427,"def handle_parse_result(self, ctx, opts, args):<tab>with augment_usage_errors(ctx, param=self):<tab><tab>value = self.consume_value(ctx, opts)<tab><tab>try:<tab><tab><tab>value = self.full_process_value(ctx, value)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>value = None<tab><tab>if self.callback is not None:<tab><tab><tab>try:<tab><tab><tab><tab>value = invoke_param_callback(self.callback, ctx, self, value)<tab><tab><tab>except Exception:<tab><tab><tab><tab>if not ctx.resilient_parsing:<tab><tab><tab><tab><tab>raise<tab>if self.expose_value:<tab><tab>ctx.params[self.name] = value<tab>return value, args",if not ctx . resilient_parsing :,195
2428,"def word_pattern(pattern, str):<tab>dict = {}<tab>set_value = set()<tab>list_str = str.split()<tab>if len(list_str) != len(pattern):<tab><tab>return False<tab>for i in range(len(pattern)):<tab><tab>if pattern[i] not in dict:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>dict[pattern[i]] = list_str[i]<tab><tab><tab>set_value.add(list_str[i])<tab><tab>else:<tab><tab><tab>if dict[pattern[i]] != list_str[i]:<tab><tab><tab><tab>return False<tab>return True",if list_str [ i ] in set_value :,165
2429,"def create(self, path, wipe=False):<tab># type: (Text, bool) -> bool<tab>_path = self.validatepath(path)<tab>with ftp_errors(self, path):<tab><tab><IF-STMT><tab><tab><tab>empty_file = io.BytesIO()<tab><tab><tab>self.ftp.storbinary(<tab><tab><tab><tab>str(""STOR "") + _encode(_path, self.ftp.encoding), empty_file<tab><tab><tab>)<tab><tab><tab>return True<tab>return False",if wipe or not self . isfile ( path ) :,124
2430,"def build_output_for_item(self, item):<tab>output = []<tab>for field in self.fields:<tab><tab>values = self._get_item(item, field)<tab><tab><IF-STMT><tab><tab><tab>values = [values]<tab><tab>for value in values:<tab><tab><tab>if value:<tab><tab><tab><tab>output.append(self.build_output_for_single_value(value))<tab>return """".join(output)","if not isinstance ( values , list ) :",109
2431,"def get_resource_public_actions(resource_class):<tab>resource_class_members = inspect.getmembers(resource_class)<tab>resource_methods = {}<tab>for name, member in resource_class_members:<tab><tab>if not name.startswith(""_""):<tab><tab><tab>if not name[0].isupper():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if is_resource_action(member):<tab><tab><tab><tab><tab><tab>resource_methods[name] = member<tab>return resource_methods","if not name . startswith ( ""wait_until"" ) :",122
2432,"def get_command(cls):<tab>ifconfig_cmd = ""ifconfig""<tab>for path in [""/sbin"", ""/usr/sbin"", ""/bin"", ""/usr/bin""]:<tab><tab><IF-STMT><tab><tab><tab>ifconfig_cmd = os.path.join(path, ifconfig_cmd)<tab><tab><tab>break<tab>ifconfig_cmd = ifconfig_cmd + "" -a""<tab>return ifconfig_cmd","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :",109
2433,"def main():<tab>base_dir = os.path.join(os.path.split(__file__)[0], "".."", "".."")<tab>for path in PATHS:<tab><tab>path = os.path.join(base_dir, path)<tab><tab>for root, _, files in os.walk(path):<tab><tab><tab>for file in files:<tab><tab><tab><tab>extension = os.path.splitext(file)[1]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>path = os.path.join(root, file)<tab><tab><tab><tab><tab>validate_header(path)",if extension in EXTENSIONS :,137
2434,"def auth_login(request):<tab>form = RegistrationForm(request.POST or None)<tab>if form.is_valid():<tab><tab>authed_user = authenticate(<tab><tab><tab>username=form.cleaned_data[""username""],<tab><tab><tab>password=form.cleaned_data[""password""],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>login(request, authed_user)<tab><tab><tab>return HttpResponse(""Success"")<tab>raise Http404",if authed_user :,110
2435,"def set(self, _key, _new_login=True):<tab>with self.lock:<tab><tab>user = self.users.get(current_user.id, None)<tab><tab>if user is None:<tab><tab><tab>self.users[current_user.id] = dict(session_count=1, key=_key)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>user[""session_count""] += 1<tab><tab><tab>user[""key""] = _key",if _new_login :,116
2436,"def fetch(self, fingerprints):<tab>to_fetch = [f for f in fingerprints if f not in self._cache]<tab>self._logger.debug(""cache size %s"" % len(self._cache))<tab>self._logger.debug(""to fetch %d from %d"" % (len(to_fetch), len(fingerprints)))<tab>[self._redis_pipeline.hgetall(key) for key in to_fetch]<tab>responses = self._redis_pipeline.execute()<tab>for index, key in enumerate(to_fetch):<tab><tab>response = responses[index]<tab><tab><IF-STMT><tab><tab><tab>self._cache[key] = response[FIELD_STATE]<tab><tab>else:<tab><tab><tab>self._cache[key] = self.NOT_CRAWLED",if len ( response ) > 0 and FIELD_STATE in response :,187
2437,"def _append_to_io_queue(self, data, stream_name):<tab># Make sure ANSI CSI codes and object links are stored as separate events<tab># TODO: try to complete previously submitted incomplete code<tab>parts = re.split(OUTPUT_SPLIT_REGEX, data)<tab>for part in parts:<tab><tab>if part:  # split may produce empty string in the beginning or start<tab><tab><tab># split the data so that very long lines separated<tab><tab><tab>for block in re.split(<tab><tab><tab><tab>""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part<tab><tab><tab>):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._queued_io_events.append((block, stream_name))",if block :,174
2438,"def find_file_at_path_with_indexes(self, path, url):<tab>if url.endswith(""/""):<tab><tab>path = os.path.join(path, self.index_file)<tab><tab>return self.get_static_file(path, url)<tab>elif url.endswith(""/"" + self.index_file):<tab><tab><IF-STMT><tab><tab><tab>return self.redirect(url, url[: -len(self.index_file)])<tab>else:<tab><tab>try:<tab><tab><tab>return self.get_static_file(path, url)<tab><tab>except IsDirectoryError:<tab><tab><tab>if os.path.isfile(os.path.join(path, self.index_file)):<tab><tab><tab><tab>return self.redirect(url, url + ""/"")<tab>raise MissingFileError(path)",if os . path . isfile ( path ) :,193
2439,"def module_list(target, fast):<tab>""""""Find the list of modules to be compiled""""""<tab>modules = []<tab>native = native_modules(target)<tab>basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"")<tab>for name in os.listdir(basedir):<tab><tab>module_name, ext = os.path.splitext(name)<tab><tab>if ext == "".py"" or ext == """" and os.path.isdir(os.path.join(basedir, name)):<tab><tab><tab>if module_name not in IGNORE_MODULES and module_name not in native:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>modules.append(module_name)<tab>return set(modules)",if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) :,185
2440,"def housenumber(self):<tab>if self.address:<tab><tab>expression = r""\d+""<tab><tab>pattern = re.compile(expression)<tab><tab>match = pattern.search(self.address)<tab><tab><IF-STMT><tab><tab><tab>return int(match.group(0))",if match :,67
2441,"def get_pip_version(import_path=BASE_IMPORT_PATH):<tab>try:<tab><tab>pip = importlib.import_module(import_path)<tab>except ImportError:<tab><tab><IF-STMT><tab><tab><tab>return get_pip_version(import_path=""pip"")<tab><tab>else:<tab><tab><tab>import subprocess<tab><tab><tab>version = subprocess.check_output([""pip"", ""--version""])<tab><tab><tab>if version:<tab><tab><tab><tab>version = version.decode(""utf-8"").split()[1]<tab><tab><tab><tab>return version<tab><tab><tab>return ""0.0.0""<tab>version = getattr(pip, ""__version__"", None)<tab>return version","if import_path != ""pip"" :",160
2442,"def __animate_progress(self):<tab>""""""Change the status message, mostly used to animate progress.""""""<tab>while True:<tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab>with self.__progress_lock:<tab><tab><tab>if not self.__progress_status:<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__progress_status.update_progress(self.__current_operation_name)<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY<tab><tab><tab>else:<tab><tab><tab><tab>self.__progress_status.show_as_ready()<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab># Allow some time for progress status to be updated.<tab><tab>time.sleep(sleep_time)",elif self . __show_animation :,195
2443,"def range_key_names(self):<tab>keys = [self.range_key_attr]<tab>for index in self.global_indexes:<tab><tab>range_key = None<tab><tab>for key in index.schema:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>range_key = keys.append(key[""AttributeName""])<tab><tab>keys.append(range_key)<tab>return keys","if key [ ""KeyType"" ] == ""RANGE"" :",99
2444,"def run(self):<tab>dist = self.distribution<tab>commands = dist.command_options.keys()<tab>settings = {}<tab>for cmd in commands:<tab><tab>if cmd == ""saveopts"":<tab><tab><tab>continue  # don't save our own options!<tab><tab>for opt, (src, val) in dist.get_option_dict(cmd).items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>settings.setdefault(cmd, {})[opt] = val<tab>edit_config(self.filename, settings, self.dry_run)","if src == ""command line"" :",131
2445,"def parse_move(self, node):<tab>old, new = """", """"<tab>for child in node:<tab><tab>tag, text = child.tag, child.text<tab><tab>text = text.strip() if text else None<tab><tab>if tag == ""Old"" and text:<tab><tab><tab>old = text<tab><tab><IF-STMT><tab><tab><tab>new = text<tab>return Move(old, new)","elif tag == ""New"" and text :",99
2446,"def __codeanalysis_settings_changed(self, current_finfo):<tab>if self.data:<tab><tab>run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled<tab><tab>for finfo in self.data:<tab><tab><tab>self.__update_editor_margins(finfo.editor)<tab><tab><tab>finfo.cleanup_analysis_results()<tab><tab><tab>if (run_pyflakes or run_pep8) and current_finfo is not None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>finfo.run_code_analysis(run_pyflakes, run_pep8)",if current_finfo is not finfo :,148
2447,"def tchg(var, width):<tab>""Convert time string to given length""<tab>ret = ""%2dh%02d"" % (var / 60, var % 60)<tab><IF-STMT><tab><tab>ret = ""%2dh"" % (var / 60)<tab><tab>if len(ret) > width:<tab><tab><tab>ret = ""%2dd"" % (var / 60 / 24)<tab><tab><tab>if len(ret) > width:<tab><tab><tab><tab>ret = ""%2dw"" % (var / 60 / 24 / 7)<tab>return ret",if len ( ret ) > width :,132
2448,"def spider_log_activity(self, messages):<tab>for i in range(0, messages):<tab><tab><IF-STMT><tab><tab><tab>self.sp_sl_p.send(<tab><tab><tab><tab>sha1(str(randint(1, 1000))),<tab><tab><tab><tab>b""http://helloworld.com/way/to/the/sun/"" + b""0"",<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.sp_sl_p.send(<tab><tab><tab><tab>sha1(str(randint(1, 1000))), b""http://way.to.the.sun"" + b""0""<tab><tab><tab>)<tab>self.sp_sl_p.flush()",if i % 2 == 0 :,165
2449,"def decode_serial(self, offset):<tab>serialnum = (<tab><tab>(self.cache[offset + 3] << 24)<tab><tab>+ (self.cache[offset + 2] << 16)<tab><tab>+ (self.cache[offset + 1] << 8)<tab><tab>+ self.cache[offset]<tab>)<tab>serialstr = """"<tab>is_alnum = True<tab>for i in range(4):<tab><tab><IF-STMT><tab><tab><tab>is_alnum = False<tab><tab><tab>break<tab><tab>serialstr += chr(self.cache[offset + 3 - i])<tab>serial = serialstr if is_alnum else str(serialnum)<tab>self.ann_field(offset, offset + 3, ""Serial "" + serial)",if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,182
2450,def gettext(rv):<tab>for child in rv.childNodes:<tab><tab>if child.nodeType == child.TEXT_NODE:<tab><tab><tab>yield child.nodeValue<tab><tab><IF-STMT><tab><tab><tab>for item in gettext(child):<tab><tab><tab><tab>yield item,if child . nodeType == child . ELEMENT_NODE :,73
2451,"def determine_block_hints(self, text):<tab>hints = """"<tab>if text:<tab><tab>if text[0] in "" \n\x85\u2028\u2029"":<tab><tab><tab>hints += str(self.best_indent)<tab><tab>if text[-1] not in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""-""<tab><tab><IF-STMT><tab><tab><tab>hints += ""+""<tab>return hints","elif len ( text ) == 1 or text [ - 2 ] in ""\n\x85\u2028\u2029"" :",132
2452,"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab>if arg is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if return_type is str:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab>if return_type is bytes:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type","if isinstance ( arg , bytes ) :",186
2453,"def as_iconbitmap(cls, rkey):<tab>""""""Get image path for use in iconbitmap property""""""<tab>img = None<tab>if rkey in cls._stock:<tab><tab>data = cls._stock[rkey]<tab><tab><IF-STMT><tab><tab><tab>fpath = data[""filename""]<tab><tab><tab>fname = os.path.basename(fpath)<tab><tab><tab>name, file_ext = os.path.splitext(fname)<tab><tab><tab>file_ext = str(file_ext).lower()<tab><tab><tab>if file_ext in TK_BITMAP_FORMATS:<tab><tab><tab><tab>img = BITMAP_TEMPLATE.format(fpath)<tab>return img","if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :",167
2454,"def anonymize_ip(ip):<tab>if ip:<tab><tab>match = RE_FIRST_THREE_OCTETS_OF_IP.findall(str(ip))<tab><tab><IF-STMT><tab><tab><tab>return ""%s%s"" % (match[0][0], ""0"")<tab>return """"",if match :,69
2455,"def serialize_tail(self):<tab>msg = bytearray()<tab>for v in self.info:<tab><tab><IF-STMT><tab><tab><tab>value = v[""value""].encode(""utf-8"")<tab><tab>elif v[""type""] == BMP_TERM_TYPE_REASON:<tab><tab><tab>value = struct.pack(""!H"", v[""value""])<tab><tab>v[""len""] = len(value)<tab><tab>msg += struct.pack(self._TLV_PACK_STR, v[""type""], v[""len""])<tab><tab>msg += value<tab>return msg","if v [ ""type"" ] == BMP_TERM_TYPE_STRING :",139
2456,"def get_django_comment(text: str, i: int) -> str:<tab>end = i + 4<tab>unclosed_end = 0<tab>while end <= len(text):<tab><tab><IF-STMT><tab><tab><tab>return text[i:end]<tab><tab>if not unclosed_end and text[end] == ""<"":<tab><tab><tab>unclosed_end = end<tab><tab>end += 1<tab>raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])","if text [ end - 2 : end ] == ""#}"" :",126
2457,"def ComboBoxDroppedHeightTest(windows):<tab>""Check if each combobox height is the same as the reference""<tab>bugs = []<tab>for win in windows:<tab><tab>if not win.ref:<tab><tab><tab>continue<tab><tab>if win.Class() != ""ComboBox"" or win.ref.Class() != ""ComboBox"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>bugs.append(<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>win,<tab><tab><tab><tab><tab>],<tab><tab><tab><tab><tab>{},<tab><tab><tab><tab><tab>testname,<tab><tab><tab><tab><tab>0,<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return bugs",if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) :,181
2458,"def testBadModeArgument(self):<tab># verify that we get a sensible error message for bad mode argument<tab>bad_mode = ""qwerty""<tab>try:<tab><tab>f = self.open(TESTFN, bad_mode)<tab>except ValueError as msg:<tab><tab><IF-STMT><tab><tab><tab>s = str(msg)<tab><tab><tab>if TESTFN in s or bad_mode not in s:<tab><tab><tab><tab>self.fail(""bad error message for invalid mode: %s"" % s)<tab><tab># if msg.args[0] == 0, we're probably on Windows where there may be<tab><tab># no obvious way to discover why open() failed.<tab>else:<tab><tab>f.close()<tab><tab>self.fail(""no error for invalid mode: %s"" % bad_mode)",if msg . args [ 0 ] != 0 :,191
2459,"def command_group_expired(self, command_group_name):<tab>try:<tab><tab>deprecate_info = self._command_loader.command_group_table[<tab><tab><tab>command_group_name<tab><tab>].group_kwargs.get(""deprecate_info"", None)<tab><tab><IF-STMT><tab><tab><tab>return deprecate_info.expired()<tab>except AttributeError:<tab><tab># Items with only token presence in the command table will not have any data. They can't be expired.<tab><tab>pass<tab>return False",if deprecate_info :,129
2460,"def test_non_uniform_probabilities_over_elements(self):<tab>param = iap.Choice([0, 1], p=[0.25, 0.75])<tab>samples = param.draw_samples((10000,))<tab>unique, counts = np.unique(samples, return_counts=True)<tab>assert len(unique) == 2<tab>for val, count in zip(unique, counts):<tab><tab>if val == 0:<tab><tab><tab>assert 2500 - 500 < count < 2500 + 500<tab><tab><IF-STMT><tab><tab><tab>assert 7500 - 500 < count < 7500 + 500<tab><tab>else:<tab><tab><tab>assert False",elif val == 1 :,145
2461,"def get_labels(directory):<tab>cache = get_labels.__cache<tab>if directory not in cache:<tab><tab>l = {}<tab><tab>for t in get_visual_configs(directory)[0][LABEL_SECTION]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>Messager.warning(<tab><tab><tab><tab><tab>""In configuration, labels for '%s' defined more than once. Only using the last set.""<tab><tab><tab><tab><tab>% t.storage_form(),<tab><tab><tab><tab><tab>-1,<tab><tab><tab><tab>)<tab><tab><tab># first is storage for, rest are labels.<tab><tab><tab>l[t.storage_form()] = t.terms[1:]<tab><tab>cache[directory] = l<tab>return cache[directory]",if t . storage_form ( ) in l :,179
2462,"def try_split(self, split_text: List[str]):<tab>ret = []<tab>for i in split_text:<tab><tab>if len(i) == 0:<tab><tab><tab>continue<tab><tab>val = int(i, 2)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>ret.append(val)<tab>if len(ret) != 0:<tab><tab>ret = bytes(ret)<tab><tab>logger.debug(f""binary successful, returning {ret.__repr__()}"")<tab><tab>return ret",if val > 255 or val < 0 :,127
2463,"def setCellValue(self, row_idx, col, value):<tab>assert col.id == ""repls-marked""<tab>with self._lock:<tab><tab>rgroup = self.events[row_idx]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>rgroup._marked = value == ""true"" and True or False<tab>if self._tree:<tab><tab>self._tree.invalidateCell(row_idx, col)","if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",113
2464,"def create(cls, settlement_manager, resource_id):<tab>""""""Create a production chain that can produce the given resource.""""""<tab>resource_producer = {}<tab>for abstract_building in AbstractBuilding.buildings.values():<tab><tab>for resource, production_line in abstract_building.lines.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resource_producer[resource] = []<tab><tab><tab>resource_producer[resource].append((production_line, abstract_building))<tab>return ProductionChain(settlement_manager, resource_id, resource_producer)",if resource not in resource_producer :,137
2465,def get_all_partition_sets(self):<tab>partition_sets = []<tab>if self.partitions_handle:<tab><tab>partition_sets.extend(self.partitions_handle.get_partition_sets())<tab>if self.scheduler_handle:<tab><tab>partition_sets.extend(<tab><tab><tab>[<tab><tab><tab><tab>schedule_def.get_partition_set()<tab><tab><tab><tab>for schedule_def in self.scheduler_handle.all_schedule_defs()<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab>)<tab>return partition_sets,"if isinstance ( schedule_def , PartitionScheduleDefinition )",140
2466,"def _sendDatapointsNow(self, datapoints):<tab>metrics = {}<tab>payload_pb = Payload()<tab>for metric, datapoint in datapoints:<tab><tab><IF-STMT><tab><tab><tab>metric_pb = payload_pb.metrics.add()<tab><tab><tab>metric_pb.metric = metric<tab><tab><tab>metrics[metric] = metric_pb<tab><tab>else:<tab><tab><tab>metric_pb = metrics[metric]<tab><tab>point_pb = metric_pb.points.add()<tab><tab>point_pb.timestamp = int(datapoint[0])<tab><tab>point_pb.value = datapoint[1]<tab>self.sendString(payload_pb.SerializeToString())",if metric not in metrics :,159
2467,"def execute(self):<tab>if self._dirty or not self._qr:<tab><tab>model_class = self.model_class<tab><tab>query_meta = self.get_query_meta()<tab><tab>if self._tuples:<tab><tab><tab>ResultWrapper = TuplesQueryResultWrapper<tab><tab><IF-STMT><tab><tab><tab>ResultWrapper = DictQueryResultWrapper<tab><tab>elif self._naive or not self._joins or self.verify_naive():<tab><tab><tab>ResultWrapper = NaiveQueryResultWrapper<tab><tab>elif self._aggregate_rows:<tab><tab><tab>ResultWrapper = AggregateQueryResultWrapper<tab><tab>else:<tab><tab><tab>ResultWrapper = ModelQueryResultWrapper<tab><tab>self._qr = ResultWrapper(model_class, self._execute(), query_meta)<tab><tab>self._dirty = False<tab><tab>return self._qr<tab>else:<tab><tab>return self._qr",elif self . _dicts :,198
2468,"def get_metrics():<tab>classifier, feature_labels = load_classifier()<tab>available_metrics = ImgageMetrics.get_metric_classes()<tab># todo review: DONE IN DOCS<tab>#  effective_metrics isn't used after filling it with values<tab>#  in the loops below<tab>effective_metrics = []<tab>for metric in available_metrics:<tab><tab>for label in feature_labels:<tab><tab><tab>for label_part in metric.get_labels():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>effective_metrics.append(metric)<tab>return (classifier, feature_labels, available_metrics)",if label_part == label and metric not in effective_metrics :,156
2469,"def test_nic_names(self):<tab>p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE)<tab>out = p.communicate()[0]<tab>if PY3:<tab><tab>out = str(out, sys.stdout.encoding)<tab>nics = psutil.net_io_counters(pernic=True).keys()<tab>for nic in nics:<tab><tab>if ""pseudo-interface"" in nic.replace("" "", ""-"").lower():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)",if nic not in out :,145
2470,"def convert_with_key(self, key, value, replace=True):<tab>result = self.configurator.convert(value)<tab># If the converted value is different, save for next time<tab>if value is not result:<tab><tab>if replace:<tab><tab><tab>self[key] = result<tab><tab><IF-STMT><tab><tab><tab>result.parent = self<tab><tab><tab>result.key = key<tab>return result","if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :",111
2471,"def _EvaluateFile(self, test_list, file):<tab>(name, ext) = os.path.splitext(file)<tab>if ext == "".cc"" or ext == "".cpp"" or ext == "".c"":<tab><tab><IF-STMT><tab><tab><tab>logger.SilentLog(""Found native test file %s"" % file)<tab><tab><tab>test_list.append(name)","if re . search ( ""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"" , name ) :",112
2472,"def leading_whitespace(self, inputstring):<tab>""""""Get leading whitespace.""""""<tab>leading_ws = []<tab>for i, c in enumerate(inputstring):<tab><tab><IF-STMT><tab><tab><tab>leading_ws.append(c)<tab><tab>else:<tab><tab><tab>break<tab><tab>if self.indchar is None:<tab><tab><tab>self.indchar = c<tab><tab>elif c != self.indchar:<tab><tab><tab>self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i)<tab>return """".join(leading_ws)",if c in legal_indent_chars :,139
2473,"def ident_values(self):<tab>value = self._ident_values<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab><IF-STMT><tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>idents = getattr(wrapped, ""ident_values"", None)<tab><tab><tab>if idents:<tab><tab><tab><tab>value = [self._wrap_hash(ident) for ident in idents]<tab><tab><tab>##else:<tab><tab><tab>##<tab>ident = self.ident<tab><tab><tab>##<tab>if ident is not None:<tab><tab><tab>##<tab><tab>value = [ident]<tab><tab>self._ident_values = value<tab>return value",if not self . orig_prefix :,200
2474,"def _available_symbols(self, scoperef, expr):<tab>cplns = []<tab>found_names = set()<tab>while scoperef:<tab><tab>elem = self._elem_from_scoperef(scoperef)<tab><tab>for child in elem:<tab><tab><tab>name = child.get(""name"", """")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if name not in found_names:<tab><tab><tab><tab><tab>found_names.add(name)<tab><tab><tab><tab><tab>ilk = child.get(""ilk"") or child.tag<tab><tab><tab><tab><tab>cplns.append((ilk, name))<tab><tab>scoperef = self.parent_scoperef_from_scoperef(scoperef)<tab><tab>if not scoperef:<tab><tab><tab>break<tab>return sorted(cplns, key=operator.itemgetter(1))",if name . startswith ( expr ) :,196
2475,"def pid_from_name(name):<tab># quick and dirty, works with all linux not depending on ps output<tab>for pid in os.listdir(""/proc""):<tab><tab>try:<tab><tab><tab>int(pid)<tab><tab>except:<tab><tab><tab>continue<tab><tab>pname = """"<tab><tab>with open(""/proc/%s/cmdline"" % pid, ""r"") as f:<tab><tab><tab>pname = f.read()<tab><tab><IF-STMT><tab><tab><tab>return int(pid)<tab>raise ProcessException(""No process with such name: %s"" % name)",if name in pname :,134
2476,"def touch(self):<tab>if not self.exists():<tab><tab>try:<tab><tab><tab>self.parent().touch()<tab><tab>except ValueError:<tab><tab><tab>pass<tab><tab>node = self._fs.touch(self.pathnames, {})<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(""Not a folder: %s"" % self.path)<tab><tab>if self.watcher:<tab><tab><tab>self.watcher.emit(""created"", self)",if not node . isdir :,107
2477,"def setUp(self):<tab>BaseTestCase.setUp(self)<tab>self.rawData = []<tab>self.dataByKey = {}<tab>for i in range(1, 11):<tab><tab>stringCol = ""String %d"" % i<tab><tab>fixedCharCol = (""Fixed Char %d"" % i).ljust(40)<tab><tab>rawCol = ""Raw %d"" % i<tab><tab><IF-STMT><tab><tab><tab>nullableCol = ""Nullable %d"" % i<tab><tab>else:<tab><tab><tab>nullableCol = None<tab><tab>dataTuple = (i, stringCol, rawCol, fixedCharCol, nullableCol)<tab><tab>self.rawData.append(dataTuple)<tab><tab>self.dataByKey[i] = dataTuple",if i % 2 :,173
2478,"def GenerateVector(self, hits, vector, level):<tab>""""""Generate possible hit vectors which match the rules.""""""<tab>for item in hits.get(level, []):<tab><tab>if vector:<tab><tab><tab>if item < vector[-1]:<tab><tab><tab><tab>continue<tab><tab><tab>if item > self.max_separation + vector[-1]:<tab><tab><tab><tab>break<tab><tab>new_vector = vector + [item]<tab><tab><IF-STMT><tab><tab><tab>yield new_vector<tab><tab>elif level + 1 < len(hits):<tab><tab><tab>for result in self.GenerateVector(hits, new_vector, level + 1):<tab><tab><tab><tab>yield result",if level + 1 == len ( hits ) :,157
2479,"def __repr__(self):<tab>attrs = []<tab>for k in self.keydata:<tab><tab><IF-STMT><tab><tab><tab>attrs.append(""p(%d)"" % (self.size() + 1,))<tab><tab>elif hasattr(self.key, k):<tab><tab><tab>attrs.append(k)<tab>if self.has_private():<tab><tab>attrs.append(""private"")<tab>return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))","if k == ""p"" :",122
2480,"def autoload(self):<tab>if self._app.config.THEME == ""auto"":<tab><tab><IF-STMT><tab><tab><tab>if get_osx_theme() == 1:<tab><tab><tab><tab>theme = DARK<tab><tab><tab>else:<tab><tab><tab><tab>theme = LIGHT<tab><tab>else:<tab><tab><tab>theme = self.guess_system_theme()<tab><tab><tab>if theme == Dark:<tab><tab><tab><tab>theme = MacOSDark<tab>else:  # user settings have highest priority<tab><tab>theme = self._app.config.THEME<tab>self.load_theme(theme)","if sys . platform == ""darwin"" :",141
2481,"def _get_matching_bracket(self, s, pos):<tab>if s[pos] != ""{"":<tab><tab>return None<tab>end = len(s)<tab>depth = 1<tab>pos += 1<tab>while pos != end:<tab><tab>c = s[pos]<tab><tab>if c == ""{"":<tab><tab><tab>depth += 1<tab><tab>elif c == ""}"":<tab><tab><tab>depth -= 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>pos += 1<tab>if pos < end and s[pos] == ""}"":<tab><tab>return pos<tab>return None",if depth == 0 :,132
2482,"def update_meter(self, output, target, meters={""accuracy""}):<tab>output = self.__to_tensor(output)<tab>target = self.__to_tensor(target)<tab>for meter in meters:<tab><tab><IF-STMT><tab><tab><tab>self.__addmeter(meter)<tab><tab>if meter in [""ap"", ""map"", ""confusion""]:<tab><tab><tab>target_th = self._ver2tensor(target)<tab><tab><tab>self.meter[meter].add(output, target_th)<tab><tab>else:<tab><tab><tab>self.meter[meter].add(output, target)",if meter not in self . meter . keys ( ) :,147
2483,"def _reinit_optimizers_with_oss(self):<tab>optimizers = self.lightning_module.trainer.optimizers<tab>for x, optimizer in enumerate(optimizers):<tab><tab>if is_lightning_optimizer(optimizer):<tab><tab><tab>optimizer = optimizer._optimizer<tab><tab><IF-STMT><tab><tab><tab>optim_class = type(optimizer)<tab><tab><tab>zero_optimizer = OSS(<tab><tab><tab><tab>params=optimizer.param_groups, optim=optim_class, **optimizer.defaults<tab><tab><tab>)<tab><tab><tab>optimizers[x] = zero_optimizer<tab><tab><tab>del optimizer<tab>trainer = self.lightning_module.trainer<tab>trainer.optimizers = optimizers<tab>trainer.convert_to_lightning_optimizers()","if not isinstance ( optimizer , OSS ) :",175
2484,"def OnSelChanged(self, event):<tab>self.item = event.GetItem()<tab>if self.item:<tab><tab>self.log.write(""OnSelChanged: %s"" % self.GetItemText(self.item))<tab><tab><IF-STMT><tab><tab><tab>self.log.write(<tab><tab><tab><tab>"", BoundingRect: %s\n"" % self.GetBoundingRect(self.item, True)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.log.write(""\n"")<tab>event.Skip()","if wx . Platform == ""__WXMSW__"" :",131
2485,"def parse_batch(args):<tab>errmsg = ""Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1).""<tab>if args.batch is not None:<tab><tab>rule, batchdef = parse_key_value_arg(args.batch, errmsg=errmsg)<tab><tab>try:<tab><tab><tab>batch, batches = batchdef.split(""/"")<tab><tab><tab>batch = int(batch)<tab><tab><tab>batches = int(batches)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(errmsg)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(errmsg)<tab><tab>return Batch(rule, batch, batches)<tab>return None",if batch > batches or batch < 1 :,167
2486,"def get_foreign_key_columns(self, engine, table_name):<tab>foreign_keys = set()<tab>table = db_utils.get_table(engine, table_name)<tab>inspector = reflection.Inspector.from_engine(engine)<tab>for column_dict in inspector.get_columns(table_name):<tab><tab>column_name = column_dict[""name""]<tab><tab>column = getattr(table.c, column_name)<tab><tab><IF-STMT><tab><tab><tab>foreign_keys.add(column_name)<tab>return foreign_keys",if column . foreign_keys :,135
2487,"def update(self, t):<tab>l = int(t * self.nr_of_tiles)<tab>for i in range(self.nr_of_tiles):<tab><tab>t = self.tiles_order[i]<tab><tab><IF-STMT><tab><tab><tab>self.turn_off_tile(t)<tab><tab>else:<tab><tab><tab>self.turn_on_tile(t)",if i < l :,93
2488,"def read(self, amt=None):<tab># the _rbuf test is only in this first if for speed.  It's not<tab># logically necessary<tab>if self._rbuf and not amt is None:<tab><tab>L = len(self._rbuf)<tab><tab><IF-STMT><tab><tab><tab>amt -= L<tab><tab>else:<tab><tab><tab>s = self._rbuf[:amt]<tab><tab><tab>self._rbuf = self._rbuf[amt:]<tab><tab><tab>return s<tab>s = self._rbuf + self._raw_read(amt)<tab>self._rbuf = b""""<tab>return s",if amt > L :,153
2489,"def draw_menu_button(self, context, layout, node, text):<tab>if (<tab><tab>hasattr(node.id_data, ""sv_show_socket_menus"")<tab><tab>and node.id_data.sv_show_socket_menus<tab>):<tab><tab><IF-STMT><tab><tab><tab>layout.menu(""SV_MT_SocketOptionsMenu"", text="""", icon=""TRIA_DOWN"")",if self . is_output or self . is_linked or not self . use_prop :,110
2490,"def __enter__(self):<tab>with DB.connection_context():<tab><tab>session_record = SessionRecord()<tab><tab>session_record.f_session_id = self._session_id<tab><tab>session_record.f_engine_name = self._engine_name<tab><tab>session_record.f_engine_type = EngineType.STORAGE<tab><tab># TODO: engine address<tab><tab>session_record.f_engine_address = {}<tab><tab>session_record.f_create_time = current_timestamp()<tab><tab>rows = session_record.save(force_insert=True)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(f""create session record {self._session_id} failed"")<tab><tab>LOGGER.debug(f""save session {self._session_id} record"")<tab>self.create()<tab>return self",if rows != 1 :,195
2491,"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab>if self.server:<tab><tab><tab>self.server.stop(2.0)<tab><tab><IF-STMT><tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",if self . sl_hdlr :,96
2492,"def _dec_device(self, srcdev, dstdev):<tab>if srcdev:<tab><tab>self.srcdevs[srcdev] -= 1<tab><tab><IF-STMT><tab><tab><tab>del self.srcdevs[srcdev]<tab><tab>self._set_limits(""read"", self.srcdevs)<tab>if dstdev:<tab><tab>self.dstdevs[dstdev] -= 1<tab><tab>if self.dstdevs[dstdev] == 0:<tab><tab><tab>del self.dstdevs[dstdev]<tab><tab>self._set_limits(""write"", self.dstdevs)",if self . srcdevs [ srcdev ] == 0 :,141
2493,"def array_for(self, i):<tab>if 0 <= i < self._cnt:<tab><tab><IF-STMT><tab><tab><tab>return self._tail<tab><tab>node = self._root<tab><tab>level = self._shift<tab><tab>while level > 0:<tab><tab><tab>assert isinstance(node, Node)<tab><tab><tab>node = node._array[(i >> level) & 0x01F]<tab><tab><tab>level -= 5<tab><tab>return node._array<tab>affirm(False, u""Index out of Range"")",if i >= self . tailoff ( ) :,125
2494,"def convert_tensor(self, offsets, sizes):<tab>results = []<tab>for b, batch in enumerate(offsets):<tab><tab>utterances = []<tab><tab>for p, utt in enumerate(batch):<tab><tab><tab>size = sizes[b][p]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>utterances.append(utt[0:size])<tab><tab><tab>else:<tab><tab><tab><tab>utterances.append(torch.tensor([], dtype=torch.int))<tab><tab>results.append(utterances)<tab>return results",if sizes [ b ] [ p ] > 0 :,126
2495,"def _predict_proba(self, X, preprocess=True):<tab>if preprocess:<tab><tab>X = self.preprocess(X)<tab>if self.problem_type == REGRESSION:<tab><tab>return self.model.predict(X)<tab>y_pred_proba = self.model.predict_proba(X)<tab>if self.problem_type == BINARY:<tab><tab>if len(y_pred_proba.shape) == 1:<tab><tab><tab>return y_pred_proba<tab><tab><IF-STMT><tab><tab><tab>return y_pred_proba[:, 1]<tab><tab>else:<tab><tab><tab>return y_pred_proba<tab>elif y_pred_proba.shape[1] > 2:<tab><tab>return y_pred_proba<tab>else:<tab><tab>return y_pred_proba[:, 1]",elif y_pred_proba . shape [ 1 ] > 1 :,198
2496,def timeout(self):<tab>now = ptime.time()<tab>dt = now - self.lastPlayTime<tab>if dt < 0:<tab><tab>return<tab>n = int(self.playRate * dt)<tab>if n != 0:<tab><tab>self.lastPlayTime += float(n) / self.playRate<tab><tab><IF-STMT><tab><tab><tab>self.play(0)<tab><tab>self.jumpFrames(n),"if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :",117
2497,"def __init__(self, data, weights=None, ddof=0):<tab>self.data = np.asarray(data)<tab>if weights is None:<tab><tab>self.weights = np.ones(self.data.shape[0])<tab>else:<tab><tab>self.weights = np.asarray(weights).astype(float)<tab><tab># TODO: why squeeze?<tab><tab><IF-STMT><tab><tab><tab>self.weights = self.weights.squeeze()<tab>self.ddof = ddof",if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 :,130
2498,"def writerow(self, row):<tab>unicode_row = []<tab>for col in row:<tab><tab><IF-STMT><tab><tab><tab>unicode_row.append(col.encode(""utf-8"").strip())<tab><tab>else:<tab><tab><tab>unicode_row.append(col)<tab>self.writer.writerow(unicode_row)<tab># Fetch UTF-8 output from the queue ...<tab>data = self.queue.getvalue()<tab>data = data.decode(""utf-8"")<tab># ... and reencode it into the target encoding<tab>data = self.encoder.encode(data)<tab># write to the target stream<tab>self.stream.write(data)<tab># empty queue<tab>self.queue.truncate(0)",if type ( col ) == str or type ( col ) == unicode :,182
2499,"def __init__(self, choices, allow_blank=False, **kwargs):<tab>self.choiceset = choices<tab>self.allow_blank = allow_blank<tab>self._choices = dict()<tab># Unpack grouped choices<tab>for k, v in choices:<tab><tab><IF-STMT><tab><tab><tab>for k2, v2 in v:<tab><tab><tab><tab>self._choices[k2] = v2<tab><tab>else:<tab><tab><tab>self._choices[k] = v<tab>super().__init__(**kwargs)","if type ( v ) in [ list , tuple ] :",127
2500,"def simp_ext(_, expr):<tab>if expr.op.startswith(""zeroExt_""):<tab><tab>arg = expr.args[0]<tab><tab><IF-STMT><tab><tab><tab>return arg<tab><tab>return ExprCompose(arg, ExprInt(0, expr.size - arg.size))<tab>if expr.op.startswith(""signExt_""):<tab><tab>arg = expr.args[0]<tab><tab>add_size = expr.size - arg.size<tab><tab>new_expr = ExprCompose(<tab><tab><tab>arg,<tab><tab><tab>ExprCond(<tab><tab><tab><tab>arg.msb(), ExprInt(size2mask(add_size), add_size), ExprInt(0, add_size)<tab><tab><tab>),<tab><tab>)<tab><tab>return new_expr<tab>return expr",if expr . size == arg . size :,191
2501,"def mark_differences(value: str, compare_against: str):<tab>result = []<tab>for i, char in enumerate(value):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append('<font color=""red"">{}</font>'.format(char))<tab><tab><tab>else:<tab><tab><tab><tab>result.append(char)<tab><tab>except IndexError:<tab><tab><tab>result.append(char)<tab>return """".join(result)",if char != compare_against [ i ] :,111
2502,"def run_query(self, query, user):<tab>url = ""%s%s"" % (self.base_url, ""&"".join(query.split(""\n"")))<tab>error = None<tab>data = None<tab>try:<tab><tab>response = requests.get(url, auth=self.auth, verify=self.verify)<tab><tab><IF-STMT><tab><tab><tab>data = _transform_result(response)<tab><tab>else:<tab><tab><tab>error = ""Failed getting results (%d)"" % response.status_code<tab>except Exception as ex:<tab><tab>data = None<tab><tab>error = str(ex)<tab>return data, error",if response . status_code == 200 :,153
2503,"def on_enter(self):<tab>""""""Fired when mouse enter the bbox of the widget.""""""<tab>if hasattr(self, ""md_bg_color"") and self.focus_behavior:<tab><tab><IF-STMT><tab><tab><tab>self.md_bg_color = self.theme_cls.bg_normal<tab><tab>else:<tab><tab><tab>if not self.focus_color:<tab><tab><tab><tab>self.md_bg_color = App.get_running_app().theme_cls.bg_normal<tab><tab><tab>else:<tab><tab><tab><tab>self.md_bg_color = self.focus_color","if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",154
2504,"def tearDown(self):<tab>if not self.is_playback():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.sms.delete_hosted_service(self.hosted_service_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab>if self.storage_account_name is not None:<tab><tab><tab><tab>self.sms.delete_storage_account(self.storage_account_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab>self.sms.delete_affinity_group(self.affinity_group_name)<tab><tab>except:<tab><tab><tab>pass<tab>return super(LegacyMgmtAffinityGroupTest, self).tearDown()",if self . hosted_service_name is not None :,180
2505,"def name2cp(k):<tab>if k == ""apos"":<tab><tab>return ord(""'"")<tab>if hasattr(htmlentitydefs, ""name2codepoint""):  # requires Python 2.3<tab><tab>return htmlentitydefs.name2codepoint[k]<tab>else:<tab><tab>k = htmlentitydefs.entitydefs[k]<tab><tab><IF-STMT><tab><tab><tab>return int(k[2:-1])  # not in latin-1<tab><tab>return ord(codecs.latin_1_decode(k)[0])","if k . startswith ( ""&#"" ) and k . endswith ( "";"" ) :",125
2506,"def _para_set(self, params, part):<tab>if len(params) == 0:<tab><tab>result = suggest([i.get_name() for i in self._options], part)<tab><tab>return result<tab>elif len(params) == 1:<tab><tab>paramName = params[0]<tab><tab>if paramName not in self._options:<tab><tab><tab>return []<tab><tab>opt = self._options[paramName]<tab><tab>paramType = opt.get_type()<tab><tab><IF-STMT><tab><tab><tab>values = [opt.get_default_value() == ""True"" and ""False"" or ""True""]<tab><tab>else:<tab><tab><tab>values = self._memory[paramName]<tab><tab>return suggest(values, part)<tab>else:<tab><tab>return []","if paramType == ""boolean"" :",186
2507,"def hexcmp(x, y):<tab>try:<tab><tab>a = int(x, 16)<tab><tab>b = int(y, 16)<tab><tab><IF-STMT><tab><tab><tab>return -1<tab><tab>if a > b:<tab><tab><tab>return 1<tab><tab>return 0<tab>except:<tab><tab>return cmp(x, y)",if a < b :,83
2508,"def execute(self, statement, arguments=None):<tab>while True:<tab><tab>try:<tab><tab><tab>if arguments:<tab><tab><tab><tab>self.cursor.execute(statement, arguments)<tab><tab><tab>else:<tab><tab><tab><tab>self.cursor.execute(statement)<tab><tab>except sqlite3.OperationalError as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>break<tab>if statement.lstrip().upper().startswith(""SELECT""):<tab><tab>return self.cursor.fetchall()","if ""locked"" not in getSafeExString ( ex ) :",130
2509,"def _test_forever(self, tests):<tab>while True:<tab><tab>for test_name in tests:<tab><tab><tab>yield test_name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>if self.ns.fail_env_changed and self.environment_changed:<tab><tab><tab><tab>return",if self . bad :,76
2510,"def removeUser(self, username):<tab>hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD<tab>if username in self._users:<tab><tab>user = self._users[username]<tab><tab>if user.room:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hideFromOSD = not constants.SHOW_SAME_ROOM_OSD<tab>if username in self._users:<tab><tab>self._users.pop(username)<tab><tab>message = getMessage(""left-notification"").format(username)<tab><tab>self.ui.showMessage(message, hideFromOSD)<tab><tab>self._client.lastLeftTime = time.time()<tab><tab>self._client.lastLeftUser = username<tab>self.userListChange()",if self . isRoomSame ( user . room ) :,184
2511,"def AutoTest():<tab>with open(sys.argv[1], ""rb"") as f:<tab><tab>for line in f.read().split(b""\n""):<tab><tab><tab>line = BYTES2SYSTEMSTR(line.strip())<tab><tab><tab>if not line:<tab><tab><tab><tab>continue<tab><tab><tab>elif line.startswith(""#""):<tab><tab><tab><tab>print(line)<tab><tab><tab>else:<tab><tab><tab><tab>print("">>> "" + line)<tab><tab><tab><tab>os.system(line)<tab><tab><tab><tab>sys.stdout.write(""\npress enter to continue..."")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>input()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raw_input()<tab><tab><tab><tab>sys.stdout.write(""\n"")",if PY3 :,179
2512,"def get_first_field(layout, clz):<tab>for layout_object in layout.fields:<tab><tab><IF-STMT><tab><tab><tab>return layout_object<tab><tab>elif hasattr(layout_object, ""get_field_names""):<tab><tab><tab>gf = get_first_field(layout_object, clz)<tab><tab><tab>if gf:<tab><tab><tab><tab>return gf","if issubclass ( layout_object . __class__ , clz ) :",94
2513,"def sanitize_event_keys(kwargs, valid_keys):<tab># Sanity check: Don't honor keys that we don't recognize.<tab>for key in list(kwargs.keys()):<tab><tab>if key not in valid_keys:<tab><tab><tab>kwargs.pop(key)<tab># Truncate certain values over 1k<tab>for key in [""play"", ""role"", ""task"", ""playbook""]:<tab><tab>if isinstance(kwargs.get(""event_data"", {}).get(key), str):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars(<tab><tab><tab><tab><tab>1024<tab><tab><tab><tab>)","if len ( kwargs [ ""event_data"" ] [ key ] ) > 1024 :",168
2514,"def visit_productionlist(self, node):<tab>self.new_state()<tab>names = []<tab>for production in node:<tab><tab>names.append(production[""tokenname""])<tab>maxlen = max(len(name) for name in names)<tab>for production in node:<tab><tab><IF-STMT><tab><tab><tab>self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="")<tab><tab><tab>lastname = production[""tokenname""]<tab><tab>else:<tab><tab><tab>self.add_text(""%s<tab>"" % ("" "" * len(lastname)))<tab><tab>self.add_text(production.astext() + self.nl)<tab>self.end_state(wrap=False)<tab>raise nodes.SkipNode","if production [ ""tokenname"" ] :",168
2515,"def uuid(self):<tab>if not getattr(self, ""_uuid"", None):<tab><tab><IF-STMT><tab><tab><tab>self._uuid = self.repository._kp_uuid(<tab><tab><tab><tab>self.path<tab><tab><tab>)  # Use repository UUID (even if None)<tab><tab>else:<tab><tab><tab>self._uuid = str(uuid.uuid4())<tab>return self._uuid",if self . repository is not None :,95
2516,"def remove(self, values):<tab>if not isinstance(values, (list, tuple, set)):<tab><tab>values = [values]<tab>for v in values:<tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>self._definition.pop(v, None)<tab><tab>elif self._definition == ""ANY"":<tab><tab><tab>if v == ""ANY"":<tab><tab><tab><tab>self._definition = []<tab><tab>elif v in self._definition:<tab><tab><tab>self._definition.remove(v)<tab>if (<tab><tab>self._value is not None<tab><tab>and self._value not in self._definition<tab><tab>and self._not_any()<tab>):<tab><tab>raise ConanException(bad_value_msg(self._name, self._value, self.values_range))","if isinstance ( self . _definition , dict ) :",192
2517,"def make(self):<tab>pygments_dir = join(self.dir, ""externals"", ""pygments"")<tab>if exists(pygments_dir):<tab><tab>run_in_dir(""hg pull"", pygments_dir, self.log.info)<tab><tab>run_in_dir(""hg update"", pygments_dir, self.log.info)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dirname(pygments_dir))<tab><tab>run_in_dir(<tab><tab><tab>""hg clone http://dev.pocoo.org/hg/pygments-main %s""<tab><tab><tab>% basename(pygments_dir),<tab><tab><tab>dirname(pygments_dir),<tab><tab><tab>self.log.info,<tab><tab>)",if not exists ( dirname ( pygments_dir ) ) :,177
2518,def set_field(self):<tab>i = 0<tab>for string in self.display_string:<tab><tab><IF-STMT><tab><tab><tab>self.config[self.field + str(i)] = self.conversion_fn(self.str[i])<tab><tab>else:<tab><tab><tab>self.config[self.field + str(i)] = self.str[i]<tab><tab>i = i + 1,if self . conversion_fn :,99
2519,"def cleanup(self):<tab>with self.lock:<tab><tab>for proc in self.processes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>proc.join()<tab><tab><tab>self.processes.remove(proc)<tab><tab><tab>log.debug(""Subprocess %s cleaned up"", proc.name)",if proc . is_alive ( ) :,79
2520,"def setup(self, gen):<tab>Node.setup(self, gen)<tab>for c in self.children:<tab><tab>c.setup(gen)<tab>if not self.accepts_epsilon:<tab><tab># If it's not already accepting epsilon, it might now do so.<tab><tab>for c in self.children:<tab><tab><tab># any non-epsilon means all is non-epsilon<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self.accepts_epsilon = 1<tab><tab><tab>gen.changed()",if not c . accepts_epsilon :,135
2521,"def __call__(self, message):<tab>with self._lock:<tab><tab>self._pending_ack += 1<tab><tab>self.max_pending_ack = max(self.max_pending_ack, self._pending_ack)<tab><tab>self.seen_message_ids.append(int(message.attributes[""seq_num""]))<tab>time.sleep(self._processing_time)<tab>with self._lock:<tab><tab>self._pending_ack -= 1<tab><tab>message.ack()<tab><tab>self.completed_calls += 1<tab><tab>if self.completed_calls >= self._resolve_at_msg_count:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.done_future.set_result(None)",if not self . done_future . done ( ) :,173
2522,"def build_canned_image_list(path):<tab>layers_path = get_bitbake_var(""BBLAYERS"")<tab>canned_wks_layer_dirs = []<tab>if layers_path is not None:<tab><tab>for layer_path in layers_path.split():<tab><tab><tab>for wks_path in (WIC_DIR, SCRIPTS_CANNED_IMAGE_DIR):<tab><tab><tab><tab>cpath = os.path.join(layer_path, wks_path)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>canned_wks_layer_dirs.append(cpath)<tab>cpath = os.path.join(path, CANNED_IMAGE_DIR)<tab>canned_wks_layer_dirs.append(cpath)<tab>return canned_wks_layer_dirs",if os . path . isdir ( cpath ) :,199
2523,"def _recv_loop(self) -> None:<tab>async with self._ws as connection:<tab><tab>self._connected = True<tab><tab>self.connection = connection<tab><tab>while self._connected:<tab><tab><tab>try:<tab><tab><tab><tab>resp = await self.connection.recv()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>await self._on_message(resp)<tab><tab><tab>except (websockets.ConnectionClosed, ConnectionResetError):<tab><tab><tab><tab>logger.info(""connection closed"")<tab><tab><tab><tab>break<tab><tab><tab>await asyncio.sleep(0)<tab>if self._connected:<tab><tab>self._loop.create_task(self.dispose())",if resp :,156
2524,"def _get_between(content, start, end=None):<tab>should_yield = False<tab>for line in content.split(""\n""):<tab><tab>if start in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if should_yield and line:<tab><tab><tab>yield line.strip().split("" "")[0]",if end and end in line :,94
2525,"def handle_parse_result(self, ctx, opts, args):<tab>if self.name in opts:<tab><tab>if self.mutually_exclusive.intersection(opts):<tab><tab><tab>self._raise_exclusive_error()<tab><tab><IF-STMT><tab><tab><tab>self._raise_exclusive_error()<tab>return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,108
2526,"def write(self, s):<tab>if self.interactive:<tab><tab><IF-STMT><tab><tab><tab>self.active_mode.write(s)<tab><tab>else:<tab><tab><tab>component.get(""CmdLine"").add_line(s, False)<tab><tab><tab>self.events.append(s)<tab>else:<tab><tab>print(colors.strip_colors(s))","if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :",110
2527,"def findfiles(path):<tab>files = []<tab>for name in os.listdir(path):<tab><tab># ignore hidden files/dirs and other unwanted files<tab><tab>if name.startswith(""."") or name == ""lastsnap.jpg"":<tab><tab><tab>continue<tab><tab>pathname = os.path.join(path, name)<tab><tab>st = os.lstat(pathname)<tab><tab>mode = st.st_mode<tab><tab><IF-STMT><tab><tab><tab>files.extend(findfiles(pathname))<tab><tab>elif stat.S_ISREG(mode):<tab><tab><tab>files.append((pathname, name, st))<tab>return files",if stat . S_ISDIR ( mode ) :,150
2528,"def _get_documented_completions(self, table, startswith=None):<tab>names = []<tab>for key, command in table.items():<tab><tab>if getattr(command, ""_UNDOCUMENTED"", False):<tab><tab><tab># Don't tab complete undocumented commands/params<tab><tab><tab>continue<tab><tab>if startswith is not None and not key.startswith(startswith):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>names.append(key)<tab>return names","if getattr ( command , ""positional_arg"" , False ) :",118
2529,"def fix_newlines(lines):<tab>""""""Convert newlines to unix.""""""<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>lines[i] = line[:-2] + ""\n""<tab><tab>elif line.endswith(""\r""):<tab><tab><tab>lines[i] = line[:-1] + ""\n""","if line . endswith ( ""\r\n"" ) :",83
2530,"def GeneratePageMetatadata(self, task):<tab>address_space = self.session.GetParameter(""default_address_space"")<tab>for vma in task.mm.mmap.walk_list(""vm_next""):<tab><tab>start = vma.vm_start<tab><tab>end = vma.vm_end<tab><tab># Skip the entire region.<tab><tab>if end < self.plugin_args.start:<tab><tab><tab>continue<tab><tab># Done.<tab><tab>if start > self.plugin_args.end:<tab><tab><tab>break<tab><tab>for vaddr in utils.xrange(start, end, 0x1000):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if self . plugin_args . start <= vaddr <= self . plugin_args . end :,195
2531,"def get_shape_at_node(self, node, assumptions):<tab>for k, v in assumptions.items():<tab><tab><IF-STMT><tab><tab><tab>return v<tab>if node.inputs:<tab><tab>return node.container.shape(<tab><tab><tab>input_shapes=[<tab><tab><tab><tab>self.get_shape_at_node(input_node, assumptions)<tab><tab><tab><tab>for input_node in node.inputs<tab><tab><tab>]<tab><tab>)<tab>else:<tab><tab>return node.container.shape(None)",if k in node . names :,127
2532,"def fix_doc(self, doc):<tab>type = doc.get(""type"", {}).get(""key"")<tab>if type == ""/type/work"":<tab><tab><IF-STMT><tab><tab><tab># some record got empty author records because of an error<tab><tab><tab># temporary hack to fix<tab><tab><tab>doc[""authors""] = [<tab><tab><tab><tab>a for a in doc[""authors""] if ""author"" in a and ""key"" in a[""author""]<tab><tab><tab>]<tab>elif type == ""/type/edition"":<tab><tab># get rid of title_prefix.<tab><tab>if ""title_prefix"" in doc:<tab><tab><tab>title = doc[""title_prefix""].strip() + "" "" + doc.get(""title"", """")<tab><tab><tab>doc[""title""] = title.strip()<tab><tab><tab>del doc[""title_prefix""]<tab>return doc","if doc . get ( ""authors"" ) :",199
2533,"def modify_column(self, column: List[Optional[""Cell""]]):<tab>for i in range(len(column)):<tab><tab>gate = column[i]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(gate, ParityControlCell):<tab><tab><tab># The first parity control to modify the column must merge all<tab><tab><tab># of the other parity controls into itself.<tab><tab><tab>column[i] = None<tab><tab><tab>self._basis_change += gate._basis_change<tab><tab><tab>self.qubits += gate.qubits<tab><tab>elif gate is not None:<tab><tab><tab>column[i] = gate.controlled_by(self.qubits[0])",if gate is self :,164
2534,"def onSync(self, auto=False, reload=True):<tab>if not auto or (<tab><tab>self.pm.profile[""syncKey""] and self.pm.profile[""autoSync""] and not self.safeMode<tab>):<tab><tab>from aqt.sync import SyncManager<tab><tab>if not self.unloadCollection():<tab><tab><tab>return<tab><tab># set a sync state so the refresh timer doesn't fire while deck<tab><tab># unloaded<tab><tab>self.state = ""sync""<tab><tab>self.syncer = SyncManager(self, self.pm)<tab><tab>self.syncer.sync()<tab>if reload:<tab><tab><IF-STMT><tab><tab><tab>self.loadCollection()",if not self . col :,161
2535,"def _has_url_match(self, match, request_url):<tab>url = match[""url""]<tab>if _is_string(url):<tab><tab><IF-STMT><tab><tab><tab>return self._has_strict_url_match(url, request_url)<tab><tab>else:<tab><tab><tab>url_without_qs = request_url.split(""?"", 1)[0]<tab><tab><tab>return url == url_without_qs<tab>elif isinstance(url, re._pattern_type) and url.match(request_url):<tab><tab>return True<tab>else:<tab><tab>return False","if match [ ""match_querystring"" ] :",140
2536,"def pool_image(self, image):<tab>if self.count < self.pool_size:<tab><tab>self.pool.append(image)<tab><tab>self.count += 1<tab><tab>return image<tab>else:<tab><tab>p = random.random()<tab><tab><IF-STMT><tab><tab><tab>random_id = random.randint(0, self.pool_size - 1)<tab><tab><tab>temp = self.pool[random_id]<tab><tab><tab>self.pool[random_id] = image<tab><tab><tab>return temp<tab><tab>else:<tab><tab><tab>return image",if p > 0.5 :,137
2537,"def get_target_dimensions(self):<tab>width, height = self.engine.size<tab>for operation in self.operations:<tab><tab><IF-STMT><tab><tab><tab>width = operation[""right""] - operation[""left""]<tab><tab><tab>height = operation[""bottom""] - operation[""top""]<tab><tab>if operation[""type""] == ""resize"":<tab><tab><tab>width = operation[""width""]<tab><tab><tab>height = operation[""height""]<tab>return (width, height)","if operation [ ""type"" ] == ""crop"" :",112
2538,"def validate_matrix(matrix):<tab>if not matrix:<tab><tab>return None<tab>for key, value in matrix.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>""`{}` defines a non uniform distribution, ""<tab><tab><tab><tab>""and it cannot be used with bayesian optimization."".format(key)<tab><tab><tab>)<tab>return matrix",if value . is_distribution and not value . is_uniform :,98
2539,"def scm_to_conandata(self):<tab>try:<tab><tab>scm_to_conandata = get_env(""CONAN_SCM_TO_CONANDATA"")<tab><tab><IF-STMT><tab><tab><tab>scm_to_conandata = self.get_item(""general.scm_to_conandata"")<tab><tab>return scm_to_conandata.lower() in (""1"", ""true"")<tab>except ConanException:<tab><tab>return False",if scm_to_conandata is None :,124
2540,"def _link_vrf_table(self, vrf_table, rt_list):<tab>route_family = vrf_table.route_family<tab>for rt in rt_list:<tab><tab>rt_rf_id = rt + "":"" + str(route_family)<tab><tab>table_set = self._tables_for_rt.get(rt_rf_id)<tab><tab><IF-STMT><tab><tab><tab>table_set = set()<tab><tab><tab>self._tables_for_rt[rt_rf_id] = table_set<tab><tab>table_set.add(vrf_table)<tab><tab>LOG.debug(""Added VrfTable %s to import RT table list: %s"", vrf_table, rt)",if table_set is None :,172
2541,"def add_tags(<tab>self, cve_results: Dict[str, Dict[str, Dict[str, str]]], file_object: FileObject):<tab># results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}}<tab>for component in cve_results:<tab><tab>for cve_id in cve_results[component]:<tab><tab><tab>entry = cve_results[component][cve_id]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_analysis_tag(<tab><tab><tab><tab><tab>file_object, ""CVE"", ""critical CVE"", TagColor.RED, True<tab><tab><tab><tab>)<tab><tab><tab><tab>return",if self . _entry_has_critical_rating ( entry ) :,180
2542,"def _validate(self):<tab>try:<tab><tab>super(CustomClassifier, self)._validate()<tab>except UnsupportedDataType:<tab><tab>if self.dtype in FACTOR_DTYPES:<tab><tab><tab>raise UnsupportedDataType(<tab><tab><tab><tab>typename=type(self).__name__,<tab><tab><tab><tab>dtype=self.dtype,<tab><tab><tab><tab>hint=""Did you mean to create a CustomFactor?"",<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise UnsupportedDataType(<tab><tab><tab><tab>typename=type(self).__name__,<tab><tab><tab><tab>dtype=self.dtype,<tab><tab><tab><tab>hint=""Did you mean to create a CustomFilter?"",<tab><tab><tab>)<tab><tab>raise",elif self . dtype in FILTER_DTYPES :,167
2543,"def formatMessage(self, record):<tab>recordcopy = copy(record)<tab>levelname = recordcopy.levelname<tab>seperator = "" "" * (8 - len(recordcopy.levelname))<tab>if self.use_colors:<tab><tab>levelname = self.color_level_name(levelname, recordcopy.levelno)<tab><tab><IF-STMT><tab><tab><tab>recordcopy.msg = recordcopy.__dict__[""color_message""]<tab><tab><tab>recordcopy.__dict__[""message""] = recordcopy.getMessage()<tab>recordcopy.__dict__[""levelprefix""] = levelname + "":"" + seperator<tab>return super().formatMessage(recordcopy)","if ""color_message"" in recordcopy . __dict__ :",152
2544,"def dumpregs(self):<tab>for reg in (<tab><tab>list(self.regs.retaddr)<tab><tab>+ list(self.regs.misc)<tab><tab>+ list(self.regs.common)<tab><tab>+ list(self.regs.flags)<tab>):<tab><tab>enum = self.get_reg_enum(reg)<tab><tab><IF-STMT><tab><tab><tab>debug(""# Could not dump register %r"" % reg)<tab><tab><tab>continue<tab><tab>name = ""U.x86_const.UC_X86_REG_%s"" % reg.upper()<tab><tab>value = self.uc.reg_read(enum)<tab><tab>debug(""uc.reg_read(%(name)s) ==> %(value)x"" % locals())",if not reg or enum is None :,177
2545,"def filter(self, lexer, stream):<tab>current_type = None<tab>current_value = None<tab>for ttype, value in stream:<tab><tab>if ttype is current_type:<tab><tab><tab>current_value += value<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield current_type, current_value<tab><tab><tab>current_type = ttype<tab><tab><tab>current_value = value<tab>if current_type is not None:<tab><tab>yield current_type, current_value",if current_type is not None :,121
2546,"def _get_between(content, start, end=None):<tab>should_yield = False<tab>for line in content.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if end and end in line:<tab><tab><tab>return<tab><tab>if should_yield and line:<tab><tab><tab>yield line.strip().split("" "")[0]",if start in line :,94
2547,"def parse_git_config(path):<tab>""""""Parse git config file.""""""<tab>config = dict()<tab>section = None<tab>with open(os.path.join(path, ""config""), ""r"") as f:<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab>if line.startswith(""[""):<tab><tab><tab><tab>section = line[1:-1].strip()<tab><tab><tab><tab>config[section] = dict()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key, value = line.replace("" "", """").split(""="")<tab><tab><tab><tab>config[section][key] = value<tab>return config",elif section :,146
2548,"def test_has_arg(fn, name, accept_all, expected):<tab>if isinstance(fn, str):<tab><tab>context = dict()<tab><tab>try:<tab><tab><tab>exec(""def {}: pass"".format(fn), context)<tab><tab>except SyntaxError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>pytest.skip(""Function is not compatible with Python 2"")<tab><tab># Sometimes exec adds builtins to the context<tab><tab>context.pop(""__builtins__"", None)<tab><tab>(fn,) = context.values()<tab>assert has_arg(fn, name, accept_all) is expected","if sys . version_info >= ( 3 , ) :",147
2549,"def ObjectExpression(self, properties, **kwargs):<tab>data = []<tab>for prop in properties:<tab><tab>self.emit(prop[""value""])<tab><tab><IF-STMT><tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""ECMA 5.1 does not support computed object properties!""<tab><tab><tab>)<tab><tab>data.append((to_key(prop[""key""]), prop[""kind""][0]))<tab>self.emit(""LOAD_OBJECT"", tuple(data))","if prop [ ""computed"" ] :",108
2550,"def run(self):<tab>for domain, locale, po in self.locales:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(""locale"", locale, ""LC_MESSAGES"")<tab><tab>else:<tab><tab><tab>path = os.path.join(self.build_dir, locale, ""LC_MESSAGES"")<tab><tab>mo = os.path.join(path, ""%s.mo"" % domain)<tab><tab>self.mkpath(path)<tab><tab>self.spawn([""msgfmt"", ""-o"", mo, po])",if self . inplace :,128
2551,"def _compute_map(self, first_byte, second_byte=None):<tab>if first_byte != 0x0F:<tab><tab>return ""XED_ILD_MAP0""<tab>else:<tab><tab>if second_byte == None:<tab><tab><tab>return ""XED_ILD_MAP1""<tab><tab>if second_byte == 0x38:<tab><tab><tab>return ""XED_ILD_MAP2""<tab><tab><IF-STMT><tab><tab><tab>return ""XED_ILD_MAP3""<tab><tab>if second_byte == 0x0F and self.amd_enabled:<tab><tab><tab>return ""XED_ILD_MAPAMD""<tab>die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",if second_byte == 0x3A :,181
2552,"def parse_tag(self):<tab>buf = []<tab>escaped = False<tab>for c in self.get_next_chars():<tab><tab><IF-STMT><tab><tab><tab>buf.append(c)<tab><tab>elif c == ""\\"":<tab><tab><tab>escaped = True<tab><tab>elif c == "">"":<tab><tab><tab>return """".join(buf)<tab><tab>else:<tab><tab><tab>buf.append(c)<tab>raise Exception(""Unclosed tag "" + """".join(buf))",if escaped :,110
2553,"def print_pairs(attrs=None, offset_y=0):<tab>fmt = "" ({0}:{1}) ""<tab>fmt_len = len(fmt)<tab>for bg, fg in get_fg_bg():<tab><tab>try:<tab><tab><tab>color = curses.color_pair(pair_number(fg, bg))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for attr in attrs:<tab><tab><tab><tab><tab>color |= attr<tab><tab><tab>screen.addstr(offset_y + bg, fg * fmt_len, fmt.format(fg, bg), color)<tab><tab><tab>pass<tab><tab>except curses.error:<tab><tab><tab>pass",if not attrs is None :,152
2554,"def _impl(inputs, input_types):<tab>data = inputs[0]<tab>axis = None<tab>keepdims = False<tab>if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False<tab><tab><IF-STMT><tab><tab><tab>axis = int(inputs[1])<tab><tab>elif _is_int_seq(inputs[1]):<tab><tab><tab>axis = inputs[1]<tab><tab>else:<tab><tab><tab>axis = list(_infer_shape(inputs[1]))<tab><tab>keepdims = bool(inputs[2])<tab>return get_relay_op(name)(data, axis=axis, keepdims=keepdims)","if isinstance ( inputs [ 1 ] , int ) :",158
2555,"def run(self, args, **kwargs):<tab># Filtering options<tab>if args.trace_tag:<tab><tab>kwargs[""trace_tag""] = args.trace_tag<tab>if args.trigger_instance:<tab><tab>kwargs[""trigger_instance""] = args.trigger_instance<tab>if args.execution:<tab><tab>kwargs[""execution""] = args.execution<tab>if args.rule:<tab><tab>kwargs[""rule""] = args.rule<tab>if args.sort_order:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""sort_asc""] = True<tab><tab>elif args.sort_order in [""desc"", ""descending""]:<tab><tab><tab>kwargs[""sort_desc""] = True<tab>return self.manager.query_with_count(limit=args.last, **kwargs)","if args . sort_order in [ ""asc"" , ""ascending"" ] :",188
2556,def retaddr():<tab>sp = pwndbg.regs.sp<tab>stack = pwndbg.vmmap.find(sp)<tab># Enumerate all return addresses<tab>frame = gdb.newest_frame()<tab>addresses = []<tab>while frame:<tab><tab>addresses.append(frame.pc())<tab><tab>frame = frame.older()<tab># Find all of them on the stack<tab>start = stack.vaddr<tab>stop = start + stack.memsz<tab>while addresses and start < sp < stop:<tab><tab>value = pwndbg.memory.u(sp)<tab><tab><IF-STMT><tab><tab><tab>index = addresses.index(value)<tab><tab><tab>del addresses[:index]<tab><tab><tab>print(pwndbg.chain.format(sp))<tab><tab>sp += pwndbg.arch.ptrsize,if value in addresses :,193
2557,"def update_from_dictio(self, dictio_item):<tab>for index, dictio_payload in enumerate(dictio_item, 1):<tab><tab>fuzz_payload = None<tab><tab>for fuzz_payload in self.payloads[index]:<tab><tab><tab>fuzz_payload.content = dictio_payload.content<tab><tab><tab>fuzz_payload.type = dictio_payload.type<tab><tab># payload generated not used in seed but in filters<tab><tab><IF-STMT><tab><tab><tab>self.add(<tab><tab><tab><tab>{""full_marker"": None, ""word"": None, ""index"": index, ""field"": None},<tab><tab><tab><tab>dictio_item[index - 1],<tab><tab><tab>)",if fuzz_payload is None :,169
2558,"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab><IF-STMT><tab><tab><tab>result = result.encode(""ascii"")<tab><tab>if isinstance(expected, str):<tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab>if contains:<tab><tab><tab>if eline not in rline:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True","if isinstance ( result , str ) :",181
2559,"def execute_sql(self, sql, params=None, commit=True):<tab>try:<tab><tab>cursor = super(RetryOperationalError, self).execute_sql(sql, params, commit)<tab>except OperationalError:<tab><tab>if not self.is_closed():<tab><tab><tab>self.close()<tab><tab>with __exception_wrapper__:<tab><tab><tab>cursor = self.cursor()<tab><tab><tab>cursor.execute(sql, params or ())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.commit()<tab>return cursor",if commit and not self . in_transaction ( ) :,127
2560,"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab>if isinstance(definition, ast.OperationDefinition):<tab><tab><tab>if not operation_name:<tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab>elif definition.name and definition.name.value == operation_name:<tab><tab><tab><tab>return definition<tab>return operation",if operation :,186
2561,"def removeTrailingWs(self, aList):<tab>i = 0<tab>while i < len(aList):<tab><tab>if self.is_ws(aList[i]):<tab><tab><tab>j = i<tab><tab><tab>i = self.skip_ws(aList, i)<tab><tab><tab>assert j < i<tab><tab><tab><IF-STMT><tab><tab><tab><tab># print ""removing trailing ws:"", `i-j`<tab><tab><tab><tab>del aList[j:i]<tab><tab><tab><tab>i = j<tab><tab>else:<tab><tab><tab>i += 1","if i >= len ( aList ) or aList [ i ] == ""\n"" :",147
2562,"def _process_filter(self, query, host_state):<tab>""""""Recursively parse the query structure.""""""<tab>if not query:<tab><tab>return True<tab>cmd = query[0]<tab>method = self.commands[cmd]<tab>cooked_args = []<tab>for arg in query[1:]:<tab><tab><IF-STMT><tab><tab><tab>arg = self._process_filter(arg, host_state)<tab><tab>elif isinstance(arg, basestring):<tab><tab><tab>arg = self._parse_string(arg, host_state)<tab><tab>if arg is not None:<tab><tab><tab>cooked_args.append(arg)<tab>result = method(self, cooked_args)<tab>return result","if isinstance ( arg , list ) :",163
2563,"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab>if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""):<tab><tab><tab>sent += [self.handle_word(w) for w in child]<tab><tab>elif child.tag in (""w"", ""c""):<tab><tab><tab>sent.append(self.handle_word(child))<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return BNCSentence(elt.attrib[""n""], sent)",elif child . tag not in self . tags_to_ignore :,141
2564,"def get_display_price(<tab>base: Union[TaxedMoney, TaxedMoneyRange], display_gross: bool = False) -> Money:<tab>""""""Return the price amount that should be displayed based on settings.""""""<tab>if not display_gross:<tab><tab>display_gross = display_gross_prices()<tab>if isinstance(base, TaxedMoneyRange):<tab><tab><IF-STMT><tab><tab><tab>base = MoneyRange(start=base.start.gross, stop=base.stop.gross)<tab><tab>else:<tab><tab><tab>base = MoneyRange(start=base.start.net, stop=base.stop.net)<tab>if isinstance(base, TaxedMoney):<tab><tab>base = base.gross if display_gross else base.net<tab>return base",if display_gross :,164
2565,"def check_classes(self, node):<tab>if isinstance(node, nodes.Element):<tab><tab>for class_value in node[""classes""][:]:<tab><tab><tab>if class_value in self.strip_classes:<tab><tab><tab><tab>node[""classes""].remove(class_value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 1",if class_value in self . strip_elements :,86
2566,"def validate(outfile=sys.stdout, silent_success=False):<tab>""Validates all installed models.""<tab>try:<tab><tab>num_errors = get_validation_errors(outfile)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>outfile.write(<tab><tab><tab>""%s error%s found.\n"" % (num_errors, num_errors != 1 and ""s"" or """")<tab><tab>)<tab>except ImproperlyConfigured:<tab><tab>outfile.write(""Skipping validation because things aren't configured properly."")",if silent_success and num_errors == 0 :,124
2567,"def check_basename_conflicts(self, targets):<tab>""""""Apps' basenames are used as bundle directory names. Ensure they are all unique.""""""<tab>basename_seen = {}<tab>for target in targets:<tab><tab><IF-STMT><tab><tab><tab>raise self.BasenameConflictError(<tab><tab><tab><tab>""Basename must be unique, found two targets use ""<tab><tab><tab><tab>""the same basename: {}'\n\t{} and \n\t{}"".format(<tab><tab><tab><tab><tab>target.basename,<tab><tab><tab><tab><tab>basename_seen[target.basename].address.spec,<tab><tab><tab><tab><tab>target.address.spec,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>basename_seen[target.basename] = target",if target . basename in basename_seen :,176
2568,"def __init__(self, api_version_str):<tab>try:<tab><tab>self.latest = self.preview = False<tab><tab>self.yyyy = self.mm = self.dd = None<tab><tab><IF-STMT><tab><tab><tab>self.latest = True<tab><tab>else:<tab><tab><tab>if ""preview"" in api_version_str:<tab><tab><tab><tab>self.preview = True<tab><tab><tab>parts = api_version_str.split(""-"")<tab><tab><tab>self.yyyy = int(parts[0])<tab><tab><tab>self.mm = int(parts[1])<tab><tab><tab>self.dd = int(parts[2])<tab>except (ValueError, TypeError):<tab><tab>raise ValueError(<tab><tab><tab>""The API version {} is not in a "" ""supported format"".format(api_version_str)<tab><tab>)","if api_version_str == ""latest"" :",199
2569,"def _osp2ec(self, bytes):<tab>compressed = self._from_bytes(bytes)<tab>y = compressed >> self._bits<tab>x = compressed & (1 << self._bits) - 1<tab>if x == 0:<tab><tab>y = self._curve.b<tab>else:<tab><tab>result = self.sqrtp(<tab><tab><tab>x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>y = result[0]<tab><tab>elif len(result) == 2:<tab><tab><tab>y1, y2 = result<tab><tab><tab>y = y1 if (y1 & 1 == y) else y2<tab><tab>else:<tab><tab><tab>return None<tab>return ec.Point(self._curve, x, y)",if len ( result ) == 1 :,200
2570,"def _visit_import_alike(self, node: Union[cst.Import, cst.ImportFrom]) -> bool:<tab>names = node.names<tab>if isinstance(names, cst.ImportStar):<tab><tab>return False<tab># make sure node.names is Sequence[ImportAlias]<tab>for name in names:<tab><tab>self.provider.set_metadata(name, self.scope)<tab><tab>asname = name.asname<tab><tab><IF-STMT><tab><tab><tab>name_values = _gen_dotted_names(cst.ensure_type(asname.name, cst.Name))<tab><tab>else:<tab><tab><tab>name_values = _gen_dotted_names(name.name)<tab><tab>for name_value, _ in name_values:<tab><tab><tab>self.scope.record_assignment(name_value, node)<tab>return False",if asname is not None :,200
2571,"def test_sanity_no_unmatched_parentheses(CorpusType: Type[ColumnCorpus]):<tab>corpus = CorpusType()<tab>unbalanced_entities = []<tab>for sentence in corpus.get_all_sentences():<tab><tab>entities = sentence.get_spans(""ner"")<tab><tab>for entity in entities:<tab><tab><tab>entity_text = """".join(t.text for t in entity.tokens)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>unbalanced_entities.append(entity_text)<tab>assert unbalanced_entities == []",if not has_balanced_parantheses ( entity_text ) :,128
2572,"def _learn_rate_adjust(self):<tab>if self.learn_rate_decays == 1.0:<tab><tab>return<tab>learn_rate_decays = self._vp(self.learn_rate_decays)<tab>learn_rate_minimums = self._vp(self.learn_rate_minimums)<tab>for index, decay in enumerate(learn_rate_decays):<tab><tab>new_learn_rate = self.net_.learnRates[index] * decay<tab><tab><IF-STMT><tab><tab><tab>self.net_.learnRates[index] = new_learn_rate<tab>if self.verbose >= 2:<tab><tab>print(""Learn rates: {}"".format(self.net_.learnRates))",if new_learn_rate >= learn_rate_minimums [ index ] :,176
2573,"def set_attr_from_xmp_tag(self, attr, xmp_tags, tags, cast=None):<tab>v = self.get_xmp_tag(xmp_tags, tags)<tab>if v is not None:<tab><tab><IF-STMT><tab><tab><tab>setattr(self, attr, v)<tab><tab>else:<tab><tab><tab># Handle fractions<tab><tab><tab>if (cast == float or cast == int) and ""/"" in v:<tab><tab><tab><tab>v = self.try_parse_fraction(v)<tab><tab><tab>setattr(self, attr, cast(v))",if cast is None :,139
2574,"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]:<tab>tokens = list(tokens)<tab>i = 0<tab>while ""e"" in tokens[i + 1 :]:<tab><tab>i = tokens.index(""e"", i + 1)<tab><tab>s = i - 1<tab><tab>e = i + 1<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if re.match(""[+-]"", str(tokens[e])):<tab><tab><tab>e += 1<tab><tab>if re.match(""[0-9]"", str(tokens[e])):<tab><tab><tab>e += 1<tab><tab><tab>tokens[s:e] = ["""".join(tokens[s:e])]<tab><tab><tab>i -= 1<tab>return tokens","if not re . match ( ""[0-9]"" , str ( tokens [ s ] ) ) :",184
2575,"def anypython(request):<tab>name = request.param<tab>executable = getexecutable(name)<tab>if executable is None:<tab><tab><IF-STMT><tab><tab><tab>executable = winpymap.get(name, None)<tab><tab><tab>if executable:<tab><tab><tab><tab>executable = py.path.local(executable)<tab><tab><tab><tab>if executable.check():<tab><tab><tab><tab><tab>return executable<tab><tab>pytest.skip(""no suitable %s found"" % (name,))<tab>return executable","if sys . platform == ""win32"" :",119
2576,"def set_meta(self, dataset, overwrite=True, **kwd):<tab>super().set_meta(dataset, overwrite=overwrite, **kwd)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>with tarfile.open(dataset.file_name, ""r"") as temptar:<tab><tab><tab><tab>dataset.metadata.fast5_count = sum(<tab><tab><tab><tab><tab>1 for f in temptar if f.name.endswith("".fast5"")<tab><tab><tab><tab>)<tab>except Exception as e:<tab><tab>log.warning(""%s, set_meta Exception: %s"", self, e)",if dataset and tarfile . is_tarfile ( dataset . file_name ) :,150
2577,"def run(self):<tab>for k in list(iterkeys(self.objs)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>v = self.objs[k]<tab><tab>if v[""_class""] == ""User"":<tab><tab><tab>self.split_user(k, v)<tab><tab>elif v[""_class""] in [<tab><tab><tab>""Message"",<tab><tab><tab>""PrintJob"",<tab><tab><tab>""Question"",<tab><tab><tab>""Submission"",<tab><tab><tab>""UserTest"",<tab><tab>]:<tab><tab><tab>v[""participation""] = v[""user""]<tab><tab><tab>del v[""user""]<tab>return self.objs","if k . startswith ( ""_"" ) :",150
2578,"def _findInTree(t, n):<tab>ret = []<tab>if type(t) is dict:<tab><tab><IF-STMT><tab><tab><tab>ret.append(t)<tab><tab>for k, v in t.items():<tab><tab><tab>ret += _findInTree(v, n)<tab>if type(t) is list:<tab><tab>for v in t:<tab><tab><tab>ret += _findInTree(v, n)<tab>return ret","if ""_name"" in t and t [ ""_name"" ] == n :",117
2579,"def parseArrayPattern(self):<tab>node = Node()<tab>elements = []<tab>self.expect(""["")<tab>while not self.match(""]""):<tab><tab><IF-STMT><tab><tab><tab>self.lex()<tab><tab><tab>elements.append(null)<tab><tab>else:<tab><tab><tab>if self.match(""...""):<tab><tab><tab><tab>restNode = Node()<tab><tab><tab><tab>self.lex()<tab><tab><tab><tab>rest = self.parseVariableIdentifier()<tab><tab><tab><tab>elements.append(restNode.finishRestElement(rest))<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>elements.append(self.parsePatternWithDefault())<tab><tab><tab>if not self.match(""]""):<tab><tab><tab><tab>self.expect("","")<tab>self.expect(""]"")<tab>return node.finishArrayPattern(elements)","if self . match ( "","" ) :",190
2580,"def _set_log_writer(self):<tab>if self.config[""logging""]:<tab><tab>config = self.config[""log_writer_config""]<tab><tab><IF-STMT><tab><tab><tab>self.log_writer = LogWriter(**config)<tab><tab>elif config[""writer""] == ""tensorboard"":<tab><tab><tab>self.log_writer = TensorBoardWriter(**config)<tab><tab>else:<tab><tab><tab>raise ValueError(f""Unrecognized writer option: {config['writer']}"")<tab>else:<tab><tab>self.log_writer = None","if config [ ""writer"" ] == ""json"" :",127
2581,"def _parse(self, contents):<tab>entries = []<tab>hostnames_found = set()<tab>for line in contents.splitlines():<tab><tab><IF-STMT><tab><tab><tab>entries.append((""blank"", [line]))<tab><tab><tab>continue<tab><tab>(head, tail) = chop_comment(line.strip(), ""#"")<tab><tab>if not len(head):<tab><tab><tab>entries.append((""all_comment"", [line]))<tab><tab><tab>continue<tab><tab>entries.append((""hostname"", [head, tail]))<tab><tab>hostnames_found.add(head)<tab>if len(hostnames_found) > 1:<tab><tab>raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found))<tab>return entries",if not len ( line . strip ( ) ) :,167
2582,"def get_all_values(self, project):<tab>if isinstance(project, models.Model):<tab><tab>project_id = project.id<tab>else:<tab><tab>project_id = project<tab>if project_id not in self.__cache:<tab><tab>cache_key = self._make_key(project_id)<tab><tab>result = cache.get(cache_key)<tab><tab><IF-STMT><tab><tab><tab>result = self.reload_cache(project_id)<tab><tab>else:<tab><tab><tab>self.__cache[project_id] = result<tab>return self.__cache.get(project_id, {})",if result is None :,144
2583,"def needed_libraries(self):<tab>for cmd in self.load_commands_of_type(0xC):  # LC_LOAD_DYLIB<tab><tab>tname = self._get_typename(""dylib_command"")<tab><tab>dylib_command = cmd.cast(tname)<tab><tab>name_addr = cmd.obj_offset + dylib_command.name<tab><tab>dylib_name = self.obj_vm.read(name_addr, 256)<tab><tab><IF-STMT><tab><tab><tab>idx = dylib_name.find(""\x00"")<tab><tab><tab>if idx != -1:<tab><tab><tab><tab>dylib_name = dylib_name[:idx]<tab><tab><tab>yield dylib_name",if dylib_name :,164
2584,"def compress(self, data_list):<tab>warn_untested()<tab>if data_list:<tab><tab><IF-STMT><tab><tab><tab>error = self.error_messages[""invalid_year""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab>if data_list[0] in forms.fields.EMPTY_VALUES:<tab><tab><tab>error = self.error_messages[""invalid_month""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab>year = int(data_list[1])<tab><tab>month = int(data_list[0])<tab><tab># find last day of the month<tab><tab>day = monthrange(year, month)[1]<tab><tab>return date(year, month, day)<tab>return None",if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,181
2585,"def put(self, obj, block=True, timeout=None):<tab>assert not self._closed<tab>if not self._sem.acquire(block, timeout):<tab><tab>raise Full<tab>with self._notempty:<tab><tab>with self._cond:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._start_thread()<tab><tab><tab>self._buffer.append(obj)<tab><tab><tab>self._unfinished_tasks.release()<tab><tab><tab>self._notempty.notify()",if self . _thread is None :,115
2586,"def has_module(self, module, version):<tab>has_module = False<tab>for directory in self.directories:<tab><tab>module_directory = join(directory, module)<tab><tab>has_module_directory = isdir(module_directory)<tab><tab>if not version:<tab><tab><tab>has_module = has_module_directory or exists(<tab><tab><tab><tab>module_directory<tab><tab><tab>)  # could be a bare modulefile<tab><tab>else:<tab><tab><tab>modulefile = join(module_directory, version)<tab><tab><tab>has_modulefile = exists(modulefile)<tab><tab><tab>has_module = has_module_directory and has_modulefile<tab><tab><IF-STMT><tab><tab><tab>break<tab>return has_module",if has_module :,171
2587,"def expanduser(path):<tab>if path[:1] == ""~"":<tab><tab>c = path[1:2]<tab><tab><IF-STMT><tab><tab><tab>return gethome()<tab><tab>if c == os.sep:<tab><tab><tab>return asPyString(File(gethome(), path[2:]).getPath())<tab>return path",if not c :,76
2588,"def mock_touch(self, bearer, version=None, revision=None, **kwargs):<tab>if version:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return self.versions[int(version) - 1]<tab><tab><tab>except (IndexError, ValueError):<tab><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>return None<tab>return file_models.FileVersion()",if self . versions :,95
2589,"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab>if member[0] == key:<tab><tab><tab><tab>field_value = member[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>wildcards = member[1]<tab><tab>if key == ""nw_src"":<tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab>elif key == ""nw_dst"":<tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value","elif member [ 0 ] == ""wildcards"" :",200
2590,"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(result, str):<tab><tab><tab>result = result.encode(""ascii"")<tab><tab>if isinstance(expected, str):<tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab><IF-STMT><tab><tab><tab>if eline not in rline:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True",if contains :,181
2591,"def OnKeyUp(self, event):<tab>if self._properties.modifiable:<tab><tab>if event.GetKeyCode() == wx.WXK_ESCAPE:<tab><tab><tab>self._cancel_editing()<tab><tab><IF-STMT><tab><tab><tab>self._update_value()<tab><tab>elif event.GetKeyCode() == wx.WXK_DELETE:<tab><tab><tab>self.SetValue("""")<tab>if event.GetKeyCode() != wx.WXK_RETURN:<tab><tab># Don't send skip event if enter key is pressed<tab><tab># On some platforms this event is sent too late and causes crash<tab><tab>event.Skip()",elif event . GetKeyCode ( ) == wx . WXK_RETURN :,145
2592,"def load_modules(<tab>to_load, load, attr, modules_dict, excluded_aliases, loading_message=None):<tab>if loading_message:<tab><tab>print(loading_message)<tab>for name in to_load:<tab><tab>module = load(name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>cls = getattr(module, attr)<tab><tab>if hasattr(cls, ""initialize"") and not cls.initialize():<tab><tab><tab>continue<tab><tab>if hasattr(module, ""aliases""):<tab><tab><tab>for alias in module.aliases():<tab><tab><tab><tab>if alias not in excluded_aliases:<tab><tab><tab><tab><tab>modules_dict[alias] = module<tab><tab>else:<tab><tab><tab>modules_dict[name] = module<tab>if loading_message:<tab><tab>print()","if module is None or not hasattr ( module , attr ) :",195
2593,def eventIterator():<tab>while True:<tab><tab>yield eventmodule.wait()<tab><tab>while True:<tab><tab><tab>event = eventmodule.poll()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>yield event,if event . type == NOEVENT :,67
2594,"def _get_state_without_padding(self, state_with_padding, padding):<tab>lean_state = {}<tab>for key, value in state_with_padding.items():<tab><tab><IF-STMT><tab><tab><tab>lean_length = value.numel() - padding<tab><tab><tab>lean_state[key] = value[:lean_length]<tab><tab>else:<tab><tab><tab>lean_state[key] = value<tab>return lean_state",if torch . is_tensor ( value ) :,110
2595,"def _get_validate(data):<tab>""""""Retrieve items to validate, from single samples or from combined joint calls.""""""<tab>if data.get(""vrn_file"") and tz.get_in([""config"", ""algorithm"", ""validate""], data):<tab><tab>return utils.deepish_copy(data)<tab>elif ""group_orig"" in data:<tab><tab>for sub in multi.get_orig_items(data):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub_val = utils.deepish_copy(sub)<tab><tab><tab><tab>sub_val[""vrn_file""] = data[""vrn_file""]<tab><tab><tab><tab>return sub_val<tab>return None","if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :",163
2596,"def OnPopup(self, form, popup_handle):<tab>for num, action_name, menu_name, shortcut in self.actions:<tab><tab><IF-STMT><tab><tab><tab>ida_kernwin.attach_action_to_popup(form, popup_handle, None)<tab><tab>else:<tab><tab><tab>handler = command_handler_t(self, num, 2)<tab><tab><tab>desc = ida_kernwin.action_desc_t(action_name, menu_name, handler, shortcut)<tab><tab><tab>ida_kernwin.attach_dynamic_action_to_popup(form, popup_handle, desc)",if menu_name is None :,153
2597,"def show(self, indent=0):<tab>""""""Pretty print this structure.""""""<tab>if indent == 0:<tab><tab>print(""struct {}"".format(self.name))<tab>for field in self.fields:<tab><tab><IF-STMT><tab><tab><tab>offset = ""0x??""<tab><tab>else:<tab><tab><tab>offset = ""0x{:02x}"".format(field.offset)<tab><tab>print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type))<tab><tab>if isinstance(field.type, Structure):<tab><tab><tab>field.type.show(indent + 1)",if field . offset is None :,143
2598,"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab><IF-STMT><tab><tab><tab>if not operation_name:<tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab>if operation:<tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab>elif definition.name and definition.name.value == operation_name:<tab><tab><tab><tab>return definition<tab>return operation","if isinstance ( definition , ast . OperationDefinition ) :",186
2599,"def getSubMenu(self, callingWindow, context, mainItem, selection, rootMenu, i, pitem):<tab>msw = True if ""wxMSW"" in wx.PlatformInfo else False<tab>self.context = context<tab>self.abilityIds = {}<tab>sub = wx.Menu()<tab>for ability in self.fighter.abilities:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>menuItem = self.addAbility(rootMenu if msw else sub, ability)<tab><tab>sub.Append(menuItem)<tab><tab>menuItem.Check(ability.active)<tab>return sub",if not ability . effect . isImplemented :,143
2600,"def consume(self, event: Dict[str, Any]) -> None:<tab>with self.lock:<tab><tab>logging.debug(""Received missedmessage_emails event: %s"", event)<tab><tab># When we process an event, just put it into the queue and ensure we have a timer going.<tab><tab>user_profile_id = event[""user_profile_id""]<tab><tab><IF-STMT><tab><tab><tab>self.batch_start_by_recipient[user_profile_id] = time.time()<tab><tab>self.events_by_recipient[user_profile_id].append(event)<tab><tab>self.ensure_timer()",if user_profile_id not in self . batch_start_by_recipient :,160
2601,"def __init__(self, start_enabled=False, use_hardware=True):<tab>self._use_hardware = use_hardware<tab>if use_hardware:<tab><tab>self._button = Button(BUTTON_GPIO_PIN)<tab><tab>self._enabled = start_enabled<tab><tab><IF-STMT><tab><tab><tab>self._button.when_pressed = self._enable",if not start_enabled :,87
2602,"def execute(cls, ctx, op: ""DataFrameGroupByAgg""):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab><IF-STMT><tab><tab><tab>cls._execute_map(ctx, op)<tab><tab>elif op.stage == OperandStage.combine:<tab><tab><tab>cls._execute_combine(ctx, op)<tab><tab>elif op.stage == OperandStage.agg:<tab><tab><tab>cls._execute_agg(ctx, op)<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise ValueError(""Aggregation operand not executable"")<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",if op . stage == OperandStage . map :,171
2603,"def load_package(name, path):<tab>if os.path.isdir(path):<tab><tab>extensions = machinery.SOURCE_SUFFIXES[:] + machinery.BYTECODE_SUFFIXES[:]<tab><tab>for extension in extensions:<tab><tab><tab>init_path = os.path.join(path, ""__init__"" + extension)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path = init_path<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>raise ValueError(""{!r} is not a package"".format(path))<tab>spec = util.spec_from_file_location(name, path, submodule_search_locations=[])<tab>if name in sys.modules:<tab><tab>return _exec(spec, sys.modules[name])<tab>else:<tab><tab>return _load(spec)",if os . path . exists ( init_path ) :,187
2604,def setup(level=None):<tab>from pipeline.logging import pipeline_logger as logger<tab>from pipeline.log.handlers import EngineLogHandler<tab>if level in set(logging._levelToName.values()):<tab><tab>logger.setLevel(level)<tab>logging._acquireLock()<tab>try:<tab><tab>for hdl in logger.handlers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>hdl = EngineLogHandler()<tab><tab><tab>hdl.setLevel(logger.level)<tab><tab><tab>logger.addHandler(hdl)<tab>finally:<tab><tab>logging._releaseLock(),"if isinstance ( hdl , EngineLogHandler ) :",150
2605,"def find_approximant(x):<tab>c = 1e-4<tab>it = sympy.ntheory.continued_fraction_convergents(<tab><tab>sympy.ntheory.continued_fraction_iterator(x)<tab>)<tab>for i in it:<tab><tab>p, q = i.as_numer_denom()<tab><tab>tol = c / q ** 2<tab><tab>if abs(i - x) <= tol:<tab><tab><tab>return i<tab><tab><IF-STMT><tab><tab><tab>break<tab>return x",if tol < machine_epsilon :,122
2606,"def resolve(<tab>self, debug: bool = False, silent: bool = False, level: Optional[int] = None) -> bool:<tab>if silent:<tab><tab>spinner = nullcontext(type(""Mock"", (), {}))<tab>else:<tab><tab>spinner = yaspin(text=""resolving..."")<tab>with spinner as spinner:<tab><tab>while True:<tab><tab><tab>resolved = self._resolve(<tab><tab><tab><tab>debug=debug, silent=silent, level=level, spinner=spinner<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self.graph.clear()  # remove unused deps from graph<tab><tab><tab>return resolved",if resolved is None :,158
2607,"def canonicalize_instruction_name(instr):<tab>name = instr.insn_name().upper()<tab># XXX bypass a capstone bug that incorrectly labels some insns as mov<tab>if name == ""MOV"":<tab><tab><IF-STMT><tab><tab><tab>return ""LSR""<tab><tab>elif instr.mnemonic.startswith(""lsl""):<tab><tab><tab>return ""LSL""<tab><tab>elif instr.mnemonic.startswith(""asr""):<tab><tab><tab>return ""ASR""<tab>return OP_NAME_MAP.get(name, name)","if instr . mnemonic . startswith ( ""lsr"" ) :",135
2608,"def run_all(rule_list, defined_variables, defined_actions, stop_on_first_trigger=False):<tab>rule_was_triggered = False<tab>for rule in rule_list:<tab><tab>result = run(rule, defined_variables, defined_actions)<tab><tab>if result:<tab><tab><tab>rule_was_triggered = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return rule_was_triggered",if stop_on_first_trigger :,108
2609,"def get_filters(self, request):<tab>filter_specs = []<tab>if self.lookup_opts.admin.list_filter and not self.opts.one_to_one_field:<tab><tab>filter_fields = [<tab><tab><tab>self.lookup_opts.get_field(field_name)<tab><tab><tab>for field_name in self.lookup_opts.admin.list_filter<tab><tab>]<tab><tab>for f in filter_fields:<tab><tab><tab>spec = FilterSpec.create(f, request, self.params, self.model)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filter_specs.append(spec)<tab>return filter_specs, bool(filter_specs)",if spec and spec . has_output ( ) :,167
2610,"def get_type(type_ref):<tab>kind = type_ref.get(""kind"")<tab>if kind == TypeKind.LIST:<tab><tab>item_ref = type_ref.get(""ofType"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Decorated type deeper than introspection query."")<tab><tab>return GraphQLList(get_type(item_ref))<tab>elif kind == TypeKind.NON_NULL:<tab><tab>nullable_ref = type_ref.get(""ofType"")<tab><tab>if not nullable_ref:<tab><tab><tab>raise Exception(""Decorated type deeper than introspection query."")<tab><tab>return GraphQLNonNull(get_type(nullable_ref))<tab>return get_named_type(type_ref[""name""])",if not item_ref :,171
2611,"def _1_0_cloud_ips_cip_jsjc5_map(self, method, url, body, headers):<tab>if method == ""POST"":<tab><tab>body = json.loads(body)<tab><tab><IF-STMT><tab><tab><tab>return self.test_response(httplib.ACCEPTED, """")<tab><tab>else:<tab><tab><tab>data = '{""error_name"":""bad destination"", ""errors"": [""Bad destination""]}'<tab><tab><tab>return self.test_response(httplib.BAD_REQUEST, data)","if ""destination"" in body :",126
2612,"def _get_prefixed_values(data, prefix):<tab>""""""Collect lines which start with prefix; with trimming""""""<tab>matches = []<tab>for line in data.splitlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>match = line[len(prefix) :]<tab><tab><tab>match = match.strip()<tab><tab><tab>matches.append(match)<tab>return matches",if line . startswith ( prefix ) :,97
2613,"def _power_exact(y, xc, yc, xe):<tab>yc, ye = y.int, y.exp<tab>while yc % 10 == 0:<tab><tab>yc //= 10<tab><tab>ye += 1<tab>if xc == 1:<tab><tab>xe *= yc<tab><tab>while xe % 10 == 0:<tab><tab><tab>xe //= 10<tab><tab><tab>ye += 1<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>exponent = xe * 10 ** ye<tab><tab>if y and xe:<tab><tab><tab>xc = exponent<tab><tab>else:<tab><tab><tab>xc = 0<tab><tab>return 5",if ye < 0 :,144
2614,"def init(self, view, items=None):<tab>selections = []<tab>if view.sel():<tab><tab>for region in view.sel():<tab><tab><tab>selections.append(view.substr(region))<tab>values = []<tab>for idx, index in enumerate(map(int, items)):<tab><tab>if idx >= len(selections):<tab><tab><tab>break<tab><tab>i = index - 1<tab><tab>if i >= 0 and i < len(selections):<tab><tab><tab>values.append(selections[i])<tab><tab>else:<tab><tab><tab>values.append(None)<tab># fill up<tab>for idx, value in enumerate(selections):<tab><tab><IF-STMT><tab><tab><tab>values.append(value)<tab>self.stack = values",if len ( values ) + 1 < idx :,178
2615,"def toggleFactorReload(self, value=None):<tab>self.serviceFittingOptions[""useGlobalForceReload""] = (<tab><tab>value<tab><tab>if value is not None<tab><tab>else not self.serviceFittingOptions[""useGlobalForceReload""]<tab>)<tab>fitIDs = set()<tab>for fit in set(self._loadedFits):<tab><tab>if fit is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""]<tab><tab><tab>fit.clearFactorReloadDependentData()<tab><tab><tab>fitIDs.add(fit.ID)<tab>return fitIDs",if fit . calculated :,149
2616,"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for m in self.predict_layers.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>kaiming_init(m)<tab><tab><IF-STMT><tab><tab><tab>constant_init(m, 1)<tab><tab>elif isinstance(m, nn.Linear):<tab><tab><tab>normal_init(m, std=0.01)","elif isinstance ( m , nn . BatchNorm2d ) :",107
2617,"def _unzip_file(self, filepath, ext):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>zf = zipfile.ZipFile(filepath)<tab><tab><tab>zf.extractall(os.path.dirname(filepath))<tab><tab><tab>zf.close()<tab><tab>elif ext == "".tar"":<tab><tab><tab>tf = tarfile.open(filepath)<tab><tab><tab>tf.extractall(os.path.dirname(filepath))<tab><tab><tab>tf.close()<tab>except Exception as e:<tab><tab>raise ValueError(""Error reading file %r!\n%s"" % (filepath, e))","if ext == "".zip"" :",136
2618,"def add_multiple_tasks(data, parent):<tab>data = json.loads(data)<tab>new_doc = {<tab><tab>""doctype"": ""Task"",<tab><tab>""parent_task"": parent if parent != ""All Tasks"" else """",<tab>}<tab>new_doc[""project""] = frappe.db.get_value(""Task"", {""name"": parent}, ""project"") or """"<tab>for d in data:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>new_doc[""subject""] = d.get(""subject"")<tab><tab>new_task = frappe.get_doc(new_doc)<tab><tab>new_task.insert()","if not d . get ( ""subject"" ) :",158
2619,"def filterSimilarKeywords(keyword, kwdsIterator):<tab>""""""Return a sorted list of keywords similar to the one given.""""""<tab>seenDict = {}<tab>kwdSndx = soundex(keyword.encode(""ascii"", ""ignore""))<tab>matches = []<tab>matchesappend = matches.append<tab>checkContained = False<tab>if len(keyword) > 4:<tab><tab>checkContained = True<tab>for movieID, key in kwdsIterator:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>seenDict[key] = None<tab><tab>if checkContained and keyword in key:<tab><tab><tab>matchesappend(key)<tab><tab><tab>continue<tab><tab>if kwdSndx == soundex(key.encode(""ascii"", ""ignore"")):<tab><tab><tab>matchesappend(key)<tab>return _sortKeywords(keyword, matches)",if key in seenDict :,193
2620,"def visit_If(self, node):<tab>self.newline()<tab>self.write(""if "")<tab>self.visit(node.test)<tab>self.write("":"")<tab>self.body(node.body)<tab>while True:<tab><tab>else_ = node.orelse<tab><tab><IF-STMT><tab><tab><tab>node = else_[0]<tab><tab><tab>self.newline()<tab><tab><tab>self.write(""elif "")<tab><tab><tab>self.visit(node.test)<tab><tab><tab>self.write("":"")<tab><tab><tab>self.body(node.body)<tab><tab>else:<tab><tab><tab>self.newline()<tab><tab><tab>self.write(""else:"")<tab><tab><tab>self.body(else_)<tab><tab><tab>break","if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :",181
2621,"def _eyeLinkHardwareAndSoftwareVersion(self):<tab>try:<tab><tab>tracker_software_ver = 0<tab><tab>eyelink_ver = self._eyelink.getTrackerVersion()<tab><tab><IF-STMT><tab><tab><tab>tvstr = self._eyelink.getTrackerVersionString()<tab><tab><tab>vindex = tvstr.find(""EYELINK CL"")<tab><tab><tab>tracker_software_ver = int(<tab><tab><tab><tab>float(tvstr[(vindex + len(""EYELINK CL"")) :].strip())<tab><tab><tab>)<tab><tab>return eyelink_ver, tracker_software_ver<tab>except Exception:<tab><tab>print2err(""EYELINK Error during _eyeLinkHardwareAndSoftwareVersion:"")<tab><tab>printExceptionDetailsToStdErr()<tab><tab>return EyeTrackerConstants.EYETRACKER_ERROR",if eyelink_ver == 3 :,200
2622,"def execute(self, context):<tab>for monad in context.blend_data.node_groups:<tab><tab>if monad.bl_idname == ""SverchGroupTreeType"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>monad.update_cls()<tab><tab><tab><tab>except Exception as err:<tab><tab><tab><tab><tab>print(err)<tab><tab><tab><tab><tab>print(""{} group class could not be created"".format(monad.name))<tab>return {""FINISHED""}","if not getattr ( bpy . types , monad . cls_bl_idname , None ) :",137
2623,"def word_pattern(pattern, str):<tab>dict = {}<tab>set_value = set()<tab>list_str = str.split()<tab>if len(list_str) != len(pattern):<tab><tab>return False<tab>for i in range(len(pattern)):<tab><tab>if pattern[i] not in dict:<tab><tab><tab>if list_str[i] in set_value:<tab><tab><tab><tab>return False<tab><tab><tab>dict[pattern[i]] = list_str[i]<tab><tab><tab>set_value.add(list_str[i])<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return True",if dict [ pattern [ i ] ] != list_str [ i ] :,165
2624,"def decorator_handle(tokens):<tab>""""""Process decorators.""""""<tab>defs = []<tab>decorates = []<tab>for i, tok in enumerate(tokens):<tab><tab>if ""simple"" in tok and len(tok) == 1:<tab><tab><tab>decorates.append(""@"" + tok[0])<tab><tab><IF-STMT><tab><tab><tab>varname = decorator_var + ""_"" + str(i)<tab><tab><tab>defs.append(varname + "" = "" + tok[0])<tab><tab><tab>decorates.append(""@"" + varname)<tab><tab>else:<tab><tab><tab>raise CoconutInternalException(""invalid decorator tokens"", tok)<tab>return ""\n"".join(defs + decorates) + ""\n""","elif ""test"" in tok and len ( tok ) == 1 :",171
2625,"def wait_impl(self, cpid):<tab>for i in range(10):<tab><tab># wait3() shouldn't hang, but some of the buildbots seem to hang<tab><tab># in the forking tests.  This is an attempt to fix the problem.<tab><tab>spid, status, rusage = os.wait3(os.WNOHANG)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(1.0)<tab>self.assertEqual(spid, cpid)<tab>self.assertEqual(status, 0, ""cause = %d, exit = %d"" % (status & 0xFF, status >> 8))<tab>self.assertTrue(rusage)",if spid == cpid :,163
2626,"def test_non_uniform_probabilities_over_elements(self):<tab>param = iap.Choice([0, 1], p=[0.25, 0.75])<tab>samples = param.draw_samples((10000,))<tab>unique, counts = np.unique(samples, return_counts=True)<tab>assert len(unique) == 2<tab>for val, count in zip(unique, counts):<tab><tab><IF-STMT><tab><tab><tab>assert 2500 - 500 < count < 2500 + 500<tab><tab>elif val == 1:<tab><tab><tab>assert 7500 - 500 < count < 7500 + 500<tab><tab>else:<tab><tab><tab>assert False",if val == 0 :,145
2627,"def dispatch_return(self, frame, arg):<tab>if self.stop_here(frame) or frame == self.returnframe:<tab><tab># Ignore return events in generator except when stepping.<tab><tab>if self.stopframe and frame.f_code.co_flags & CO_GENERATOR:<tab><tab><tab>return self.trace_dispatch<tab><tab>try:<tab><tab><tab>self.frame_returning = frame<tab><tab><tab>self.user_return(frame, arg)<tab><tab>finally:<tab><tab><tab>self.frame_returning = None<tab><tab><IF-STMT><tab><tab><tab>raise BdbQuit<tab><tab># The user issued a 'next' or 'until' command.<tab><tab>if self.stopframe is frame and self.stoplineno != -1:<tab><tab><tab>self._set_stopinfo(None, None)<tab>return self.trace_dispatch",if self . quitting :,199
2628,"def mouse(self, button, mods, x, y):<tab>if button == 1:<tab><tab>for i in range(4):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.hit = i<tab>elif button == -1:<tab><tab>self.hit = None<tab>elif self.hit != None:<tab><tab>self.coords[self.hit] = (x, y)<tab><tab>self.view.dirty()","if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 :",123
2629,"def __init__(self, *commands):<tab>self.all_cmds = list(<tab><tab>map(lambda cmd: cmd[0] if isinstance(cmd, list) else cmd, commands)<tab>)<tab>for command in commands:<tab><tab>self.cmd = command if isinstance(command, list) else [command]<tab><tab>self.cmd_path = pwndbg.which.which(self.cmd[0])<tab><tab><IF-STMT><tab><tab><tab>break",if self . cmd_path :,111
2630,"def _recv_obj(self, suppress_error=False):<tab>""""""Receive a (picklable) object""""""<tab>if self.conn.closed:<tab><tab>raise OSError(""handle is closed"")<tab>try:<tab><tab>buf = self.conn.recv_bytes()<tab>except (ConnectionError, EOFError) as e:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>logger.debug(""receive has failed"", exc_info=e)<tab><tab>try:<tab><tab><tab>self._set_remote_close_cause(e)<tab><tab><tab>raise PipeShutdownError()<tab><tab>finally:<tab><tab><tab>self._close()<tab>obj = RemoteObjectUnpickler.loads(buf, self)<tab>logger.debug(""received %r"", obj)<tab>return obj",if suppress_error :,177
2631,"def act(self, obs):<tab>with chainer.no_backprop_mode():<tab><tab>batch_obs = self.batch_states([obs], self.xp, self.phi)<tab><tab>action_distrib = self.model(batch_obs)<tab><tab><IF-STMT><tab><tab><tab>return chainer.cuda.to_cpu(action_distrib.most_probable.array)[0]<tab><tab>else:<tab><tab><tab>return chainer.cuda.to_cpu(action_distrib.sample().array)[0]",if self . act_deterministically :,126
2632,"def _classify(nodes_by_level):<tab>missing, invalid, downloads = [], [], []<tab>for level in nodes_by_level:<tab><tab>for node in level:<tab><tab><tab>if node.binary == BINARY_MISSING:<tab><tab><tab><tab>missing.append(node)<tab><tab><tab>elif node.binary == BINARY_INVALID:<tab><tab><tab><tab>invalid.append(node)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>downloads.append(node)<tab>return missing, invalid, downloads","elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",126
2633,"def persist(self, *_):<tab>for key, obj in self._objects.items():<tab><tab>try:<tab><tab><tab>state = obj.get_state()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>md5 = hashlib.md5(state).hexdigest()<tab><tab><tab>if self._last_state.get(key) == md5:<tab><tab><tab><tab>continue<tab><tab><tab>self._persist_provider.store(key, state)<tab><tab>except Exception as e:<tab><tab><tab>system_log.exception(""PersistHelper.persist fail"")<tab><tab>else:<tab><tab><tab>self._last_state[key] = md5",if not state :,153
2634,"def enter(self, doc, **kwds):<tab>""""""Enters the mode, arranging for necessary grabs ASAP""""""<tab>super(ColorPickMode, self).enter(doc, **kwds)<tab>if self._started_from_key_press:<tab><tab># Pick now using the last recorded event position<tab><tab>doc = self.doc<tab><tab>tdw = self.doc.tdw<tab><tab>t, x, y = doc.get_last_event_info(tdw)<tab><tab><IF-STMT><tab><tab><tab>self._pick_color_mode(tdw, x, y, self._pickmode)<tab><tab># Start the drag when possible<tab><tab>self._start_drag_on_next_motion_event = True<tab><tab>self._needs_drag_start = True","if None not in ( x , y ) :",187
2635,"def on_profiles_loaded(self, profiles):<tab>cb = self.builder.get_object(""cbProfile"")<tab>model = cb.get_model()<tab>model.clear()<tab>for f in profiles:<tab><tab>name = f.get_basename()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if name.endswith("".sccprofile""):<tab><tab><tab>name = name[0:-11]<tab><tab>model.append((name, f, None))<tab>cb.set_active(0)","if name . endswith ( "".mod"" ) :",122
2636,"def subprocess_post_check(<tab>completed_process: subprocess.CompletedProcess, raise_error: bool = True) -> None:<tab>if completed_process.returncode:<tab><tab>if completed_process.stdout is not None:<tab><tab><tab>print(completed_process.stdout, file=sys.stdout, end="""")<tab><tab><IF-STMT><tab><tab><tab>print(completed_process.stderr, file=sys.stderr, end="""")<tab><tab>if raise_error:<tab><tab><tab>raise PipxError(<tab><tab><tab><tab>f""{' '.join([str(x) for x in completed_process.args])!r} failed""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>logger.info(f""{' '.join(completed_process.args)!r} failed"")",if completed_process . stderr is not None :,185
2637,"def test_connect(<tab>ipaddr, port, device, partition, method, path, headers=None, query_string=None):<tab>if path == ""/a"":<tab><tab>for k, v in headers.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>test_errors.append(""%s: %s not in %s"" % (test_header, test_value, headers))",if k . lower ( ) == test_header . lower ( ) and v == test_value :,116
2638,"def test_stat_result_pickle(self):<tab>result = os.stat(self.fname)<tab>for proto in range(pickle.HIGHEST_PROTOCOL + 1):<tab><tab>p = pickle.dumps(result, proto)<tab><tab>self.assertIn(b""stat_result"", p)<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(b""cos\nstat_result\n"", p)<tab><tab>unpickled = pickle.loads(p)<tab><tab>self.assertEqual(result, unpickled)",if proto < 4 :,118
2639,"def run_sql(sql):<tab>table = sql.split("" "")[5]<tab>logger.info(""Updating table {}"".format(table))<tab>with transaction.atomic():<tab><tab>with connection.cursor() as cursor:<tab><tab><tab>cursor.execute(sql)<tab><tab><tab>rows = cursor.fetchall()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""Sentry notification that {} is migrated"".format(table))",if not rows :,98
2640,"def countbox(self):<tab>self.box = [1000, 1000, -1000, -1000]<tab>for x, y in self.body:<tab><tab>if x < self.box[0]:<tab><tab><tab>self.box[0] = x<tab><tab><IF-STMT><tab><tab><tab>self.box[2] = x<tab><tab>if y < self.box[1]:<tab><tab><tab>self.box[1] = y<tab><tab>if y > self.box[3]:<tab><tab><tab>self.box[3] = y",if x > self . box [ 2 ] :,131
2641,"def _packageFocusOutViaKeyPress(self, row, column, txt):<tab>if txt:<tab><tab>self._set_current_cell(row + 1, column)<tab>else:<tab><tab>widget = self.cellWidget(row + 1, column)<tab><tab><IF-STMT><tab><tab><tab>self._delete_cell(row, column)<tab><tab>new_request = self.get_request()<tab><tab>self.context_model.set_request(new_request)<tab><tab>self._update_request_column(column, self.context_model)","if widget and isinstance ( widget , PackageSelectWidget ) :",140
2642,"def parse_bash_set_output(output):<tab>""""""Parse Bash-like 'set' output""""""<tab>if not sys.platform.startswith(""win""):<tab><tab># Replace ""\""-continued lines in *Linux* environment dumps.<tab><tab># Cannot do this on Windows because a ""\"" at the end of the<tab><tab># line does not imply a continuation.<tab><tab>output = output.replace(""\\\n"", """")<tab>environ = {}<tab>for line in output.splitlines(0):<tab><tab>line = line.rstrip()<tab><tab><IF-STMT><tab><tab><tab>continue  # skip black lines<tab><tab>item = _ParseBashEnvStr(line)<tab><tab>if item:<tab><tab><tab>environ[item[0]] = item[1]<tab>return environ",if not line :,177
2643,"def _get(self, domain):<tab>with self.lock:<tab><tab>try:<tab><tab><tab>record = self.cache[domain]<tab><tab><tab>time_now = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>record = None<tab><tab>except KeyError:<tab><tab><tab>record = None<tab><tab>if not record:<tab><tab><tab>record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0}<tab><tab># self.cache[domain] = record<tab><tab>return record","if time_now - record [ ""update"" ] > self . ttl :",137
2644,"def test_filehash(self):<tab>""""""tests the hashes of the files in data/""""""<tab>fp = self.get_data_path()<tab>for fn in os.listdir(fp):<tab><tab><IF-STMT><tab><tab><tab># file used for something else<tab><tab><tab>continue<tab><tab>expected_hash = fn<tab><tab>fullp = os.path.join(fp, fn)<tab><tab>output = self.run_command(""sha1sum "" + fullp, exitcode=0)<tab><tab>result = output.split("" "")[0]<tab><tab>self.assertEqual(result, expected_hash)","if ""."" in fn :",139
2645,"def test_new_vs_reference_code_stream_read_during_iter(read_idx, read_len, bytecode):<tab>reference = SlowCodeStream(bytecode)<tab>latest = CodeStream(bytecode)<tab>for index, (actual, expected) in enumerate(zip(latest, reference)):<tab><tab>assert actual == expected<tab><tab>if index == read_idx:<tab><tab><tab>readout_actual = latest.read(read_len)<tab><tab><tab>readout_expected = reference.read(read_len)<tab><tab><tab>assert readout_expected == readout_actual<tab><tab><IF-STMT><tab><tab><tab>assert latest.program_counter >= len(reference)<tab><tab>else:<tab><tab><tab>assert latest.program_counter == reference.program_counter",if reference . program_counter >= len ( reference ) :,179
2646,"def setup_logging():<tab>try:<tab><tab>logconfig = config.get(""logging_config_file"")<tab><tab><IF-STMT><tab><tab><tab>logging.config.fileConfig(logconfig, disable_existing_loggers=False)<tab><tab>logger.info(""logging initialized"")<tab><tab>logger.debug(""debug"")<tab>except Exception as e:<tab><tab>print(""Unable to set logging configuration:"", str(e), file=sys.stderr)<tab><tab>raise",if logconfig and os . path . exists ( logconfig ) :,116
2647,"def all_words(filename):<tab>start_char = True<tab>for c in characters(filename):<tab><tab><IF-STMT><tab><tab><tab>word = """"<tab><tab><tab>if c.isalnum():<tab><tab><tab><tab># We found the start of a word<tab><tab><tab><tab>word = c.lower()<tab><tab><tab><tab>start_char = False<tab><tab><tab>else:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>if c.isalnum():<tab><tab><tab><tab>word += c.lower()<tab><tab><tab>else:<tab><tab><tab><tab># We found end of word, emit it<tab><tab><tab><tab>start_char = True<tab><tab><tab><tab>yield word",if start_char == True :,158
2648,"def _get_nonce(self, url, new_nonce_url):<tab>if not self._nonces:<tab><tab>logger.debug(""Requesting fresh nonce"")<tab><tab><IF-STMT><tab><tab><tab>response = self.head(url)<tab><tab>else:<tab><tab><tab># request a new nonce from the acme newNonce endpoint<tab><tab><tab>response = self._check_response(self.head(new_nonce_url), content_type=None)<tab><tab>self._add_nonce(response)<tab>return self._nonces.pop()",if new_nonce_url is None :,131
2649,"def paragraph_is_fully_commented(lines, comment, main_language):<tab>""""""Is the paragraph fully commented?""""""<tab>for i, line in enumerate(lines):<tab><tab>if line.startswith(comment):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if is_magic(line, main_language):<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>return i > 0 and _BLANK_LINE.match(line)<tab>return True",if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,121
2650,"def gvariant_args(args: List[Any]) -> str:<tab>""""""Convert args into gvariant.""""""<tab>gvariant = """"<tab>for arg in args:<tab><tab>if isinstance(arg, bool):<tab><tab><tab>gvariant += "" {}"".format(str(arg).lower())<tab><tab><IF-STMT><tab><tab><tab>gvariant += f"" {arg}""<tab><tab>elif isinstance(arg, str):<tab><tab><tab>gvariant += f' ""{arg}""'<tab><tab>else:<tab><tab><tab>gvariant += f"" {arg!s}""<tab>return gvariant.lstrip()","elif isinstance ( arg , ( int , float ) ) :",139
2651,"def _SkipGroup(buffer, pos, end):<tab>""""""Skip sub-group.  Returns the new position.""""""<tab>while 1:<tab><tab>(tag_bytes, pos) = ReadTag(buffer, pos)<tab><tab>new_pos = SkipField(buffer, pos, end, tag_bytes)<tab><tab><IF-STMT><tab><tab><tab>return pos<tab><tab>pos = new_pos",if new_pos == - 1 :,93
2652,"def update_participants(self, refresh=True):<tab>for participant in list(self.participants_dict):<tab><tab>if participant is None or participant == self.simulator_config.broadcast_part:<tab><tab><tab>continue<tab><tab>self.removeItem(self.participants_dict[participant])<tab><tab>self.participant_items.remove(self.participants_dict[participant])<tab><tab>del self.participants_dict[participant]<tab>for participant in self.simulator_config.participants:<tab><tab><IF-STMT><tab><tab><tab>self.participants_dict[participant].refresh()<tab><tab>else:<tab><tab><tab>self.insert_participant(participant)<tab>if refresh:<tab><tab>self.update_view()",if participant in self . participants_dict :,182
2653,"def feature_reddit(layer_data, graph):<tab>feature = {}<tab>times = {}<tab>indxs = {}<tab>for _type in layer_data:<tab><tab>if len(layer_data[_type]) == 0:<tab><tab><tab>continue<tab><tab>idxs = np.array(list(layer_data[_type].keys()))<tab><tab>tims = np.array(list(layer_data[_type].values()))[:, 1]<tab><tab>feature[_type] = np.array(<tab><tab><tab>list(graph.node_feature[_type].loc[idxs, ""emb""]), dtype=np.float<tab><tab>)<tab><tab>times[_type] = tims<tab><tab>indxs[_type] = idxs<tab><tab><IF-STMT><tab><tab><tab>attr = feature[_type]<tab>return feature, times, indxs, attr","if _type == ""def"" :",195
2654,"def _get_sort_map(tags):<tab>""""""See TAG_TO_SORT""""""<tab>tts = {}<tab>for name, tag in tags.items():<tab><tab>if tag.has_sort:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tts[name] = ""%ssort"" % name<tab><tab><tab>if tag.internal:<tab><tab><tab><tab>tts[""~%s"" % name] = ""~%ssort"" % name<tab>return tts",if tag . user :,111
2655,"def max_radius(iterator):<tab>radius_result = dict()<tab>for k, v in iterator:<tab><tab>if v[0] not in radius_result:<tab><tab><tab>radius_result[v[0]] = v[1]<tab><tab><IF-STMT><tab><tab><tab>radius_result[v[0]] = v[1]<tab>return radius_result",elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,96
2656,"def run(self):<tab>pwd_found = []<tab>if constant.user_dpapi and constant.user_dpapi.unlocked:<tab><tab>main_vault_directory = os.path.join(<tab><tab><tab>constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault""<tab><tab>)<tab><tab>if os.path.exists(main_vault_directory):<tab><tab><tab>for vault_directory in os.listdir(main_vault_directory):<tab><tab><tab><tab>cred = constant.user_dpapi.decrypt_vault(<tab><tab><tab><tab><tab>os.path.join(main_vault_directory, vault_directory)<tab><tab><tab><tab>)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pwd_found.append(cred)<tab>return pwd_found",if cred :,197
2657,"def disconnect_sync(self, connection, close_connection=False):<tab>key = id(connection)<tab>ts = self.in_use.pop(key)<tab>if close_connection:<tab><tab>self.connections_map.pop(key)<tab><tab>self._connection_close_sync(connection)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.connections_map.pop(key)<tab><tab><tab>self._connection_close_sync(connection)<tab><tab>else:<tab><tab><tab>with self._lock_sync:<tab><tab><tab><tab>heapq.heappush(self.connections_sync, (ts, key))",if self . stale_timeout and self . is_stale ( ts ) :,159
2658,"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict):<tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab>elif isinstance(v, bool):<tab><tab><tab>self._populate_bool(element, k, v)<tab><tab>elif isinstance(v, basestring):<tab><tab><tab>self._populate_str(element, k, v)<tab><tab><IF-STMT><tab><tab><tab>self._populate_number(element, k, v)","elif type ( v ) in [ int , float , long , complex ] :",178
2659,"def readframes(self, nframes):<tab>if self._ssnd_seek_needed:<tab><tab>self._ssnd_chunk.seek(0)<tab><tab>dummy = self._ssnd_chunk.read(8)<tab><tab>pos = self._soundpos * self._framesize<tab><tab><IF-STMT><tab><tab><tab>self._ssnd_chunk.seek(pos + 8)<tab><tab>self._ssnd_seek_needed = 0<tab>if nframes == 0:<tab><tab>return """"<tab>data = self._ssnd_chunk.read(nframes * self._framesize)<tab>if self._convert and data:<tab><tab>data = self._convert(data)<tab>self._soundpos = self._soundpos + len(data) / (self._nchannels * self._sampwidth)<tab>return data",if pos :,185
2660,"def target_glob(tgt, hosts):<tab>ret = {}<tab>for host in hosts:<tab><tab><IF-STMT><tab><tab><tab>ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {}))<tab><tab><tab>ret[host].update({""host"": host})<tab><tab><tab>if __opts__.get(""ssh_user""):<tab><tab><tab><tab>ret[host].update({""user"": __opts__[""ssh_user""]})<tab>return ret","if fnmatch . fnmatch ( tgt , host ) :",110
2661,"def get_attribute_value(self, nodeid, attr):<tab>with self._lock:<tab><tab>self.logger.debug(""get attr val: %s %s"", nodeid, attr)<tab><tab>if nodeid not in self._nodes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown)<tab><tab><tab>return dv<tab><tab>node = self._nodes[nodeid]<tab><tab>if attr not in node.attributes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid)<tab><tab><tab>return dv<tab><tab>attval = node.attributes[attr]<tab><tab><IF-STMT><tab><tab><tab>return attval.value_callback()<tab><tab>return attval.value",if attval . value_callback :,200
2662,"def remove_property(self, key):  # type: (str) -> None<tab>with self.secure() as config:<tab><tab>keys = key.split(""."")<tab><tab>current_config = config<tab><tab>for i, key in enumerate(keys):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>if i == len(keys) - 1:<tab><tab><tab><tab>del current_config[key]<tab><tab><tab><tab>break<tab><tab><tab>current_config = current_config[key]",if key not in current_config :,122
2663,"def _class_browser(parent):  # Wrapper for htest<tab>try:<tab><tab>file = __file__<tab>except NameError:<tab><tab>file = sys.argv[0]<tab><tab><IF-STMT><tab><tab><tab>file = sys.argv[1]<tab><tab>else:<tab><tab><tab>file = sys.argv[0]<tab>dir, file = os.path.split(file)<tab>name = os.path.splitext(file)[0]<tab>flist = PyShell.PyShellFileList(parent)<tab>global file_open<tab>file_open = flist.open<tab>ClassBrowser(flist, name, [dir], _htest=True)",if sys . argv [ 1 : ] :,161
2664,"def get_only_text_part(self, msg):<tab>count = 0<tab>only_text_part = None<tab>for part in msg.walk():<tab><tab>if part.is_multipart():<tab><tab><tab>continue<tab><tab>count += 1<tab><tab>mimetype = part.get_content_type() or ""text/plain""<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>only_text_part = part<tab>return only_text_part","if mimetype != ""text/plain"" or count != 1 :",123
2665,"def should_keep_alive(commit_msg):<tab>result = False<tab>ci = get_current_ci() or """"<tab>for line in commit_msg.splitlines():<tab><tab>parts = line.strip(""# "").split("":"", 1)<tab><tab>(key, val) = parts if len(parts) > 1 else (parts[0], """")<tab><tab>if key == ""CI_KEEP_ALIVE"":<tab><tab><tab>ci_names = val.replace("","", "" "").lower().split() if val else []<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab>return result",if len ( ci_names ) == 0 or ci . lower ( ) in ci_names :,150
2666,"def _calc_block_io(self, blkio):<tab>""""""Calculate block IO stats.""""""<tab>for stats in blkio[""io_service_bytes_recursive""]:<tab><tab>if stats[""op""] == ""Read"":<tab><tab><tab>self._blk_read += stats[""value""]<tab><tab><IF-STMT><tab><tab><tab>self._blk_write += stats[""value""]","elif stats [ ""op"" ] == ""Write"" :",92
2667,"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># Oracle doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Oracle backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return six.text_type(value)",if settings . USE_TZ :,134
2668,"def load_state_dict(self, state_dict):<tab>for module_name, module_state_dict in state_dict.items():<tab><tab>if module_name in self.module_pool:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.module_pool[module_name].module.load_state_dict(module_state_dict)<tab><tab><tab>else:<tab><tab><tab><tab>self.module_pool[module_name].load_state_dict(module_state_dict)<tab><tab>else:<tab><tab><tab>logging.info(f""Missing {module_name} in module_pool, skip it.."")","if self . config [ ""dataparallel"" ] :",150
2669,"def _unpack_scales(scales, vidxs):<tab>scaleData = [None, None, None]<tab>for i in range(3):<tab><tab>if i >= min(len(scales), len(vidxs) // 2):<tab><tab><tab>break<tab><tab>scale = scales[i]<tab><tab><IF-STMT><tab><tab><tab>vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1]<tab><tab><tab>scaleData[i] = (int(vidx1), int(vidx2), float(scale))<tab>return scaleData",if not math . isnan ( scale ) :,138
2670,"def __init__(self, factors, contrast_matrices, num_columns):<tab>self.factors = tuple(factors)<tab>factor_set = frozenset(factors)<tab>if not isinstance(contrast_matrices, dict):<tab><tab>raise ValueError(""contrast_matrices must be dict"")<tab>for factor, contrast_matrix in six.iteritems(contrast_matrices):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Unexpected factor in contrast_matrices dict"")<tab><tab>if not isinstance(contrast_matrix, ContrastMatrix):<tab><tab><tab>raise ValueError(""Expected a ContrastMatrix, not %r"" % (contrast_matrix,))<tab>self.contrast_matrices = contrast_matrices<tab>if not isinstance(num_columns, six.integer_types):<tab><tab>raise ValueError(""num_columns must be an integer"")<tab>self.num_columns = num_columns",if factor not in factor_set :,193
2671,"def app(scope, receive, send):<tab>while True:<tab><tab>message = await receive()<tab><tab><IF-STMT><tab><tab><tab>await send({""type"": ""websocket.accept""})<tab><tab>elif message[""type""] == ""websocket.receive"":<tab><tab><tab>pass<tab><tab>elif message[""type""] == ""websocket.disconnect"":<tab><tab><tab>break","if message [ ""type"" ] == ""websocket.connect"" :",93
2672,"def value__set(self, value):<tab>for i, (option, checked) in enumerate(self.options):<tab><tab><IF-STMT><tab><tab><tab>self.selectedIndex = i<tab><tab><tab>break<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>""Option %r not found (from %s)""<tab><tab><tab>% (value, "", "".join([repr(o) for o, c in self.options]))<tab><tab>)",if option == str ( value ) :,106
2673,"def init_links(self):<tab>links = LinkCallback.find_links(self)<tab>callbacks = []<tab>for link, src_plot, tgt_plot in links:<tab><tab>cb = Link._callbacks[""bokeh""][type(link)]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>callbacks.append(cb(self.root, link, src_plot, tgt_plot))<tab>return callbacks",if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,112
2674,"def _validate_scalar_extensions(self) -> List[str]:<tab>errors = []<tab>for extension in [<tab><tab>x for x in self.extensions if isinstance(x, GraphQLScalarTypeExtension)<tab>]:<tab><tab>extended = self.type_definitions.get(extension.name)<tab><tab>ext_errors = _validate_extension(<tab><tab><tab>extended, extension.name, GraphQLScalarType, ""SCALAR""<tab><tab>)<tab><tab>errors.extend(ext_errors)<tab><tab><IF-STMT><tab><tab><tab>errors.extend(_validate_extension_directives(extension, extended, ""SCALAR""))<tab>return errors",if not ext_errors :,149
2675,"def copy_tcltk(src, dest, symlink):<tab>""""""copy tcl/tk libraries on Windows (issue #93)""""""<tab>for libversion in ""8.5"", ""8.6"":<tab><tab>for libname in ""tcl"", ""tk"":<tab><tab><tab>srcdir = join(src, ""tcl"", libname + libversion)<tab><tab><tab>destdir = join(dest, ""tcl"", libname + libversion)<tab><tab><tab># Only copy the dirs from the above combinations that exist<tab><tab><tab><IF-STMT><tab><tab><tab><tab>copyfileordir(srcdir, destdir, symlink)",if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,153
2676,"def parse(self, response):<tab>try:<tab><tab>content = response.content.decode(""utf-8"", ""ignore"")<tab><tab>content = json.loads(content, strict=False)<tab>except:<tab><tab>self.logger.error(""Fail to parse the response in json format"")<tab><tab>return<tab>for item in content[""data""]:<tab><tab>if ""objURL"" in item:<tab><tab><tab>img_url = self._decode_url(item[""objURL""])<tab><tab><IF-STMT><tab><tab><tab>img_url = item[""hoverURL""]<tab><tab>else:<tab><tab><tab>continue<tab><tab>yield dict(file_url=img_url)","elif ""hoverURL"" in item :",158
2677,"def check_and_reload(self):<tab># Check if tables have been modified, if so reload<tab>for table_name, table_version in self._table_versions.items():<tab><tab>table = self.app.tool_data_tables.get(table_name, None)<tab><tab><IF-STMT><tab><tab><tab>return self.reload_genomes()",if table is not None and not table . is_current_version ( table_version ) :,100
2678,"def _get_query_defaults(self, query_defns):<tab>defaults = {}<tab>for k, v in query_defns.items():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>defaults[k] = self._get_default_obj(v[""schema""])<tab><tab><tab>else:<tab><tab><tab><tab>defaults[k] = v[""schema""][""default""]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return defaults","if v [ ""schema"" ] [ ""type"" ] == ""object"" :",114
2679,"def ftp_login(host, port, username=None, password=None, anonymous=False):<tab>ret = False<tab>try:<tab><tab>ftp = ftplib.FTP()<tab><tab>ftp.connect(host, port, timeout=6)<tab><tab><IF-STMT><tab><tab><tab>ftp.login()<tab><tab>else:<tab><tab><tab>ftp.login(username, password)<tab><tab>ret = True<tab><tab>ftp.quit()<tab>except Exception:<tab><tab>pass<tab>return ret",if anonymous :,116
2680,"def _getVolumeScalar(self):<tab>if self._volumeScalar is not None:<tab><tab>return self._volumeScalar<tab># use default<tab>elif self._value in dynamicStrToScalar:<tab><tab>return dynamicStrToScalar[self._value]<tab>else:<tab><tab>thisDynamic = self._value<tab><tab># ignore leading s like in sf<tab><tab>if ""s"" in thisDynamic:<tab><tab><tab>thisDynamic = thisDynamic[1:]<tab><tab># ignore closing z like in fz<tab><tab>if thisDynamic[-1] == ""z"":<tab><tab><tab>thisDynamic = thisDynamic[:-1]<tab><tab><IF-STMT><tab><tab><tab>return dynamicStrToScalar[thisDynamic]<tab><tab>else:<tab><tab><tab>return dynamicStrToScalar[None]",if thisDynamic in dynamicStrToScalar :,183
2681,"def processCoords(coords):<tab>newcoords = deque()<tab>for (x, y, z) in coords:<tab><tab>for _dir, offsets in faceDirections:<tab><tab><tab>if _dir == FaceYIncreasing:<tab><tab><tab><tab>continue<tab><tab><tab>dx, dy, dz = offsets<tab><tab><tab>p = (x + dx, y + dy, z + dz)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>nx, ny, nz = p<tab><tab><tab>if level.blockAt(nx, ny, nz) == 0:<tab><tab><tab><tab>level.setBlockAt(nx, ny, nz, waterID)<tab><tab><tab><tab>newcoords.append(p)<tab>return newcoords",if p not in box :,173
2682,"def _set_property(self, target_widget, pname, value):<tab>if pname == ""text"":<tab><tab>wstate = str(target_widget[""state""])<tab><tab><IF-STMT><tab><tab><tab># change state temporarily<tab><tab><tab>target_widget[""state""] = ""normal""<tab><tab>target_widget.delete(""0"", tk.END)<tab><tab>target_widget.insert(""0"", value)<tab><tab>target_widget[""state""] = wstate<tab>else:<tab><tab>super(EntryBaseBO, self)._set_property(target_widget, pname, value)","if wstate != ""normal"" :",138
2683,"def teardown():<tab>try:<tab><tab>time.sleep(1)<tab>except KeyboardInterrupt:<tab><tab>return<tab>while launchers:<tab><tab>p = launchers.pop()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>p.stop()<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>print(e)<tab><tab><tab><tab>pass<tab><tab>if p.poll() is None:<tab><tab><tab>try:<tab><tab><tab><tab>time.sleep(0.25)<tab><tab><tab>except KeyboardInterrupt:<tab><tab><tab><tab>return<tab><tab>if p.poll() is None:<tab><tab><tab>try:<tab><tab><tab><tab>print(""cleaning up test process..."")<tab><tab><tab><tab>p.signal(SIGKILL)<tab><tab><tab>except:<tab><tab><tab><tab>print(""couldn't shutdown process: "", p)",if p . poll ( ) is None :,198
2684,"def checkAndRemoveDuplicate(self, node):<tab>for bucket in self.buckets:<tab><tab>for n in bucket.getNodes():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.removeContact(n)","if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id :",77
2685,"def toString():<tab>flags = u""""<tab>try:<tab><tab>if this.glob:<tab><tab><tab>flags += u""g""<tab><tab><IF-STMT><tab><tab><tab>flags += u""i""<tab><tab>if this.multiline:<tab><tab><tab>flags += u""m""<tab>except:<tab><tab>pass<tab>v = this.value if this.value else ""(?:)""<tab>return u""/%s/"" % v + flags",if this . ignore_case :,106
2686,"def import_submodules(package_name):<tab>package = sys.modules[package_name]<tab>results = {}<tab>for loader, name, is_pkg in pkgutil.iter_modules(package.__path__):<tab><tab>full_name = package_name + ""."" + name<tab><tab>module = importlib.import_module(full_name)<tab><tab>setattr(sys.modules[__name__], name, module)<tab><tab>results[full_name] = module<tab><tab>if is_pkg:<tab><tab><tab>valid_pkg = import_submodules(full_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.update(valid_pkg)<tab>return results",if valid_pkg :,153
2687,"def _call(self, cmd):<tab>what = cmd[""command""]<tab>if what == ""list"":<tab><tab>name = cmd[""properties""].get(""name"")<tab><tab><IF-STMT><tab><tab><tab>return {""watchers"": [""one"", ""two"", ""three""]}<tab><tab>return {""pids"": [123, 456]}<tab>elif what == ""dstats"":<tab><tab>return {""info"": {""pid"": 789}}<tab>elif what == ""listsockets"":<tab><tab>return {<tab><tab><tab>""status"": ""ok"",<tab><tab><tab>""sockets"": [{""path"": self._unix, ""fd"": 5, ""name"": ""XXXX"", ""backlog"": 2048}],<tab><tab><tab>""time"": 1369647058.967524,<tab><tab>}<tab>raise NotImplementedError(cmd)",if name is None :,182
2688,"def select(self):<tab>e = xlib.XEvent()<tab>while xlib.XPending(self._display):<tab><tab>xlib.XNextEvent(self._display, e)<tab><tab># Key events are filtered by the xlib window event<tab><tab># handler so they get a shot at the prefiltered event.<tab><tab>if e.xany.type not in (xlib.KeyPress, xlib.KeyRelease):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>dispatch = self._window_map[e.xany.window]<tab><tab>except KeyError:<tab><tab><tab>continue<tab><tab>dispatch(e)","if xlib . XFilterEvent ( e , e . xany . window ) :",171
2689,"def translate(self, line):<tab>parsed = self.RE_LINE_PARSER.match(line)<tab>if parsed:<tab><tab>value = parsed.group(3)<tab><tab>stage = parsed.group(1)<tab><tab><IF-STMT>  # query string is rendered here<tab><tab><tab>return ""\n# HTTP Request:\n"" + self.stripslashes(value)<tab><tab>elif stage == ""reply"":<tab><tab><tab>return ""\n\n# HTTP Response:\n"" + self.stripslashes(value)<tab><tab>elif stage == ""header"":<tab><tab><tab>return value + ""\n""<tab><tab>else:<tab><tab><tab>return value<tab>return line","if stage == ""send"" :",156
2690,"def toString():<tab>flags = u""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>flags += u""g""<tab><tab>if this.ignore_case:<tab><tab><tab>flags += u""i""<tab><tab>if this.multiline:<tab><tab><tab>flags += u""m""<tab>except:<tab><tab>pass<tab>v = this.value if this.value else ""(?:)""<tab>return u""/%s/"" % v + flags",if this . glob :,106
2691,"def __exit__(self, *exc_info):<tab>super(WarningsChecker, self).__exit__(*exc_info)<tab># only check if we're not currently handling an exception<tab>if all(a is None for a in exc_info):<tab><tab>if self.expected_warning is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>__tracebackhide__ = True<tab><tab><tab><tab>pytest.fail(""DID NOT WARN"")",if not any ( r . category in self . expected_warning for r in self ) :,115
2692,"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab>if k.startswith(""_""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if v[""email""] == """":<tab><tab><tab><tab>v[""email""] = None<tab><tab><tab>if v[""ip""] == ""0.0.0.0"":<tab><tab><tab><tab>v[""ip""] = None<tab>return self.objs","if v [ ""_class"" ] == ""User"" :",102
2693,"def list_stuff(self, upto=10, start_after=-1):<tab>for i in range(upto):<tab><tab>if i <= start_after:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>if i == 7 and self.count < 4:<tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>yield i",if i == 2 and self . count < 1 :,110
2694,"def check(self):<tab>tcp_client = self.tcp_create()<tab>if tcp_client.connect():<tab><tab>tcp_client.send(b""ABCDE"")<tab><tab>response = tcp_client.recv(5)<tab><tab>tcp_client.close()<tab><tab>if response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.endianness = "">""  # BE<tab><tab><tab>elif response.startswith(b""ScMM""):<tab><tab><tab><tab>self.endianness = ""<""  # LE<tab><tab><tab>return True  # target is vulnerable<tab>return False  # target is not vulnerable","if response . startswith ( b""MMcS"" ) :",148
2695,"def copy_tree(self, src_dir, dst_dir, skip_variables=False):<tab>for src_root, _, files in os.walk(src_dir):<tab><tab>if src_root != src_dir:<tab><tab><tab>rel_root = os.path.relpath(src_root, src_dir)<tab><tab>else:<tab><tab><tab>rel_root = """"<tab><tab>if skip_variables and rel_root.startswith(""variables""):<tab><tab><tab>continue<tab><tab>dst_root = os.path.join(dst_dir, rel_root)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dst_root)<tab><tab>for f in files:<tab><tab><tab>shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",if not os . path . exists ( dst_root ) :,197
2696,"def _set_hostport(self, host, port):<tab>if port is None:<tab><tab>i = host.rfind("":"")<tab><tab>j = host.rfind(""]"")  # ipv6 addresses have [...]<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>port = int(host[i + 1 :])<tab><tab><tab>except ValueError:<tab><tab><tab><tab>raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :])<tab><tab><tab>host = host[:i]<tab><tab>else:<tab><tab><tab>port = self.default_port<tab><tab>if host and host[0] == ""["" and host[-1] == ""]"":<tab><tab><tab>host = host[1:-1]<tab>self.host = host<tab>self.port = port",if i > j :,176
2697,"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab>if member[0] == key:<tab><tab><tab><tab>field_value = member[1]<tab><tab><tab>elif member[0] == ""wildcards"":<tab><tab><tab><tab>wildcards = member[1]<tab><tab><IF-STMT><tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab>elif key == ""nw_dst"":<tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value","if key == ""nw_src"" :",200
2698,"def _clear_storage():<tab>""""""Clear old files from storage.""""""<tab>hacs = get_hacs()<tab>storagefiles = [""hacs""]<tab>for s_f in storagefiles:<tab><tab>path = f""{hacs.core.config_path}/.storage/{s_f}""<tab><tab><IF-STMT><tab><tab><tab>hacs.log.info(f""Cleaning up old storage file {path}"")<tab><tab><tab>os.remove(path)",if os . path . isfile ( path ) :,111
2699,"def action_delete(self, ids):<tab>try:<tab><tab>count = 0<tab><tab># TODO: Optimize me<tab><tab>for pk in ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count += 1<tab><tab>flash(<tab><tab><tab>ngettext(<tab><tab><tab><tab>""Record was successfully deleted."",<tab><tab><tab><tab>""%(count)s records were successfully deleted."",<tab><tab><tab><tab>count,<tab><tab><tab><tab>count=count,<tab><tab><tab>),<tab><tab><tab>""success"",<tab><tab>)<tab>except Exception as ex:<tab><tab>flash(gettext(""Failed to delete records. %(error)s"", error=str(ex)), ""error"")",if self . delete_model ( self . get_one ( pk ) ) :,166
2700,"def test_inclusion(all_values):<tab>for values in [{""guid_2"", ""guid_1""}, {""guid_5"", ""guid_XXX""}, {""guid_2""}]:<tab><tab>test_predicate = in_set(values, ""volume_guid"")<tab><tab>included_values = set()<tab><tab>for val in all_values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>included_values.add(val)<tab><tab>assert included_values == all_values.intersection(values)","if test_predicate . do_include ( { ""volume_guid"" : val } ) :",126
2701,"def _get_attr(sdk_path, mod_attr_path, checked=True):<tab>try:<tab><tab>attr_mod, attr_path = (<tab><tab><tab>mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """")<tab><tab>)<tab><tab>full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path<tab><tab>op = import_module(full_mod_path)<tab><tab>if attr_path:<tab><tab><tab># Only load attributes if needed<tab><tab><tab>for part in attr_path.split("".""):<tab><tab><tab><tab>op = getattr(op, part)<tab><tab>return op<tab>except (ImportError, AttributeError) as ex:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>raise ex",if checked :,191
2702,"def __exit__(self, exc_type, exc_val, exc_tb):<tab>if self.fusefat is not None:<tab><tab>self.fusefat.send_signal(signal.SIGINT)<tab><tab># Allow 1s to return without sending terminate<tab><tab>for count in range(10):<tab><tab><tab>time.sleep(0.1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self.fusefat.terminate()<tab><tab>time.sleep(self.delay)<tab><tab>assert not os.path.exists(self.canary)<tab>self.dev_null.close()<tab>shutil.rmtree(self.tmpdir)",if self . fusefat . poll ( ) is not None :,165
2703,"def check_context_processors(output):<tab>with output.section(""Context processors"") as section:<tab><tab>processors = list(<tab><tab><tab>chain(<tab><tab><tab><tab>*[<tab><tab><tab><tab><tab>template[""OPTIONS""].get(""context_processors"", [])<tab><tab><tab><tab><tab>for template in settings.TEMPLATES<tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>)<tab><tab>required_processors = (""cms.context_processors.cms_settings"",)<tab><tab>for processor in required_processors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>section.error(<tab><tab><tab><tab><tab>""%s context processor must be in TEMPLATES option context_processors""<tab><tab><tab><tab><tab>% processor<tab><tab><tab><tab>)",if processor not in processors :,171
2704,"def test_converters(self):<tab>response = self._get(""datatypes/converters"")<tab>self._assert_status_code_is(response, 200)<tab>converters_list = response.json()<tab>found_fasta_to_tabular = False<tab>for converter in converters_list:<tab><tab>self._assert_has_key(converter, ""source"", ""target"", ""tool_id"")<tab><tab><IF-STMT><tab><tab><tab>found_fasta_to_tabular = True<tab>assert found_fasta_to_tabular","if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :",138
2705,"def remove_pid(self, watcher, pid):<tab>if pid in self._pids[watcher]:<tab><tab>logger.debug(""Removing %d from %s"" % (pid, watcher))<tab><tab>self._pids[watcher].remove(pid)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Stopping the periodic callback for {0}"".format(watcher))<tab><tab><tab>self._callbacks[watcher].stop()",if len ( self . _pids [ watcher ] ) == 0 :,104
2706,"def _fc_layer(self, sess, bottom, name, trainable=True, relu=True):<tab>with tf.variable_scope(name) as scope:<tab><tab>shape = bottom.get_shape().as_list()<tab><tab>dim = 1<tab><tab>for d in shape[1:]:<tab><tab><tab>dim *= d<tab><tab>x = tf.reshape(bottom, [-1, dim])<tab><tab>weight = self._get_fc_weight(sess, name, trainable=trainable)<tab><tab>bias = self._get_bias(sess, name, trainable=trainable)<tab><tab>fc = tf.nn.bias_add(tf.matmul(x, weight), bias)<tab><tab><IF-STMT><tab><tab><tab>fc = tf.nn.relu(fc)<tab><tab>return fc",if relu :,179
2707,"def get_drive(self, root_path="""", volume_guid_path=""""):<tab>for drive in self.drives:<tab><tab>if root_path:<tab><tab><tab>config_root_path = drive.get(""root_path"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return drive<tab><tab>elif volume_guid_path:<tab><tab><tab>config_volume_guid_path = drive.get(""volume_guid_path"")<tab><tab><tab>if config_volume_guid_path and config_volume_guid_path == volume_guid_path:<tab><tab><tab><tab>return drive",if config_root_path and root_path == config_root_path :,148
2708,"def rewire_init(expr):<tab>new_args = []<tab>if expr[0] == HySymbol(""setv""):<tab><tab>pairs = expr[1:]<tab><tab>while len(pairs) > 0:<tab><tab><tab>k, v = (pairs.pop(0), pairs.pop(0))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v.append(HySymbol(""None""))<tab><tab><tab>new_args.append(k)<tab><tab><tab>new_args.append(v)<tab><tab>expr = HyExpression([HySymbol(""setv"")] + new_args).replace(expr)<tab>return expr","if k == HySymbol ( ""__init__"" ) :",149
2709,"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab>if not isinstance(child, minidom.Element):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab>if not isinstance(grandchild, minidom.Element):<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if grandchild.tagName != ""File"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if child . tagName == ""Directory"" :",152
2710,"def _v2_common(self, cfg):<tab>LOG.debug(""v2_common: handling config:\n%s"", cfg)<tab>if ""nameservers"" in cfg:<tab><tab>search = cfg.get(""nameservers"").get(""search"", [])<tab><tab>dns = cfg.get(""nameservers"").get(""addresses"", [])<tab><tab>name_cmd = {""type"": ""nameserver""}<tab><tab><IF-STMT><tab><tab><tab>name_cmd.update({""search"": search})<tab><tab>if len(dns) > 0:<tab><tab><tab>name_cmd.update({""addresses"": dns})<tab><tab>LOG.debug(""v2(nameserver) -> v1(nameserver):\n%s"", name_cmd)<tab><tab>self.handle_nameserver(name_cmd)",if len ( search ) > 0 :,178
2711,"def __start_element_handler(self, name, attrs):<tab>if name == ""mime-type"":<tab><tab>if self.type:<tab><tab><tab>for extension in self.extensions:<tab><tab><tab><tab>self[extension] = self.type<tab><tab>self.type = attrs[""type""].lower()<tab><tab>self.extensions = []<tab>elif name == ""glob"":<tab><tab>pattern = attrs[""pattern""]<tab><tab><IF-STMT><tab><tab><tab>self.extensions.append(pattern[1:].lower())","if pattern . startswith ( ""*."" ) :",120
2712,"def get_attr_by_data_model(self, dmodel, exclude_record=False):<tab>if exclude_record:<tab><tab>return list(<tab><tab><tab>filter(<tab><tab><tab><tab>lambda x: x.data_model == dmodel and x.value == """"<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else False,<tab><tab><tab><tab>self._inferred_intent,<tab><tab><tab>)<tab><tab>)<tab>else:<tab><tab>return list(<tab><tab><tab>filter(<tab><tab><tab><tab>lambda x: x.data_model == dmodel and x.value == """"<tab><tab><tab><tab>if hasattr(x, ""data_model"")<tab><tab><tab><tab>else False,<tab><tab><tab><tab>self._inferred_intent,<tab><tab><tab>)<tab><tab>)","if x . attribute != ""Record"" and hasattr ( x , ""data_model"" )",196
2713,"def general(metadata, value):<tab>if metadata.get(""commands"") and value:<tab><tab>if not metadata.get(""nargs""):<tab><tab><tab>v = quote(value)<tab><tab>else:<tab><tab><tab>v = value<tab><tab>return u""{0} {1}"".format(metadata[""commands""][0], v)<tab>else:<tab><tab>if not value:<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>return quote(value)<tab><tab>else:<tab><tab><tab>return value","elif not metadata . get ( ""nargs"" ) :",122
2714,"def get_images(self):<tab>images = []<tab>try:<tab><tab>tag = MP4(self[""~filename""])<tab>except Exception:<tab><tab>return []<tab>for cover in tag.get(""covr"", []):<tab><tab><IF-STMT><tab><tab><tab>mime = ""image/jpeg""<tab><tab>elif cover.imageformat == MP4Cover.FORMAT_PNG:<tab><tab><tab>mime = ""image/png""<tab><tab>else:<tab><tab><tab>mime = ""image/""<tab><tab>f = get_temp_cover_file(cover)<tab><tab>images.append(EmbeddedImage(f, mime))<tab>return images",if cover . imageformat == MP4Cover . FORMAT_JPEG :,157
2715,"def run_cmd(self, util, value):<tab>state = util.state<tab>if not state.argument_supplied:<tab><tab>state.argument_supplied = True<tab><tab>if value == ""by_four"":<tab><tab><tab>state.argument_value = 4<tab><tab><IF-STMT><tab><tab><tab>state.argument_negative = True<tab><tab>else:<tab><tab><tab>state.argument_value = value<tab>elif value == ""by_four"":<tab><tab>state.argument_value *= 4<tab>elif isinstance(value, int):<tab><tab>state.argument_value *= 10<tab><tab>state.argument_value += value<tab>elif value == ""negative"":<tab><tab>state.argument_value = -state.argument_value","elif value == ""negative"" :",169
2716,"def finish_character_data(self):<tab>if self.character_data:<tab><tab><IF-STMT><tab><tab><tab>line, column = self.character_pos<tab><tab><tab>token = XmlToken(<tab><tab><tab><tab>XML_CHARACTER_DATA, self.character_data, None, line, column<tab><tab><tab>)<tab><tab><tab>self.tokens.append(token)<tab><tab>self.character_data = """"",if not self . skip_ws or not self . character_data . isspace ( ) :,109
2717,"def check_syntax(filename, raise_error=False):<tab>""""""Return True if syntax is okay.""""""<tab>with autopep8.open_with_encoding(filename) as input_file:<tab><tab>try:<tab><tab><tab>compile(input_file.read(), ""<string>"", ""exec"", dont_inherit=True)<tab><tab><tab>return True<tab><tab>except (SyntaxError, TypeError, UnicodeDecodeError):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>return False",if raise_error :,118
2718,"def write(self, file):<tab>if not self._been_written:<tab><tab>self._been_written = True<tab><tab>for attribute, value in self.__dict__.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.write_recursive(value, file)<tab><tab>w = file.write<tab><tab>w(""\t%s = {\n"" % self._id)<tab><tab>w(""\t\tisa = %s;\n"" % self.__class__.__name__)<tab><tab>for attribute, value in self.__dict__.items():<tab><tab><tab>if attribute[0] != ""_"":<tab><tab><tab><tab>w(""\t\t%s = %s;\n"" % (attribute, self.tostring(value)))<tab><tab>w(""\t};\n\n"")","if attribute [ 0 ] != ""_"" :",181
2719,"def update_service_key(kid, name=None, metadata=None):<tab>try:<tab><tab>with db_transaction():<tab><tab><tab>key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get()<tab><tab><tab>if name is not None:<tab><tab><tab><tab>key.name = name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key.metadata.update(metadata)<tab><tab><tab>key.save()<tab>except ServiceKey.DoesNotExist:<tab><tab>raise ServiceKeyDoesNotExist",if metadata is not None :,127
2720,"def fill_buf(self, db, len_=None):<tab>with open(""/dev/urandom"", ""rb"") as rfh:<tab><tab>first = True<tab><tab>for (id_,) in db.query(""SELECT id FROM test""):<tab><tab><tab>if len_ is None and first:<tab><tab><tab><tab>val = b""""  # We always want to check this case<tab><tab><tab><tab>first = False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = rfh.read(random.randint(0, 140))<tab><tab><tab>else:<tab><tab><tab><tab>val = rfh.read(len_)<tab><tab><tab>db.execute(""UPDATE test SET buf=? WHERE id=?"", (val, id_))",elif len_ is None :,164
2721,"def load_category_from_parser(self, parser):<tab>for cate in parser.keys():<tab><tab>id = parser.get_id(cate)<tab><tab><IF-STMT><tab><tab><tab>self._data[""cates""][id] = 0<tab><tab>else:<tab><tab><tab>self._data[""cates""][id] = self.count_unread(id)<tab>self._is_init = False<tab>self.save()",if self . _is_init :,102
2722,"def after_insert(self):<tab>if self.prescription:<tab><tab>frappe.db.set_value(<tab><tab><tab>""Lab Prescription"", self.prescription, ""lab_test_created"", 1<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.invoiced = True<tab>if not self.lab_test_name and self.template:<tab><tab>self.load_test_from_template()<tab><tab>self.reload()","if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :",130
2723,"def sync_terminology(self):<tab>if self.is_source:<tab><tab>return<tab>store = self.store<tab>missing = []<tab>for source in self.component.get_all_sources():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>_unit, add = store.find_unit(source.context, source.source)<tab><tab>except UnitNotFound:<tab><tab><tab>add = True<tab><tab># Unit is already present<tab><tab>if not add:<tab><tab><tab>continue<tab><tab>missing.append((source.context, source.source, """"))<tab>if missing:<tab><tab>self.add_units(None, missing)","if ""terminology"" not in source . all_flags :",166
2724,def refresh(self):<tab>if self._obj:<tab><tab>base = self._db.get_media_from_handle(self._obj.get_reference_handle())<tab><tab><IF-STMT><tab><tab><tab>self._title = base.get_description()<tab><tab><tab>self._value = base.get_path(),if base :,74
2725,"def _set_parse_context(self, tag, tag_attrs):<tab># special case: script or style parse context<tab>if not self._wb_parse_context:<tab><tab>if tag == ""style"":<tab><tab><tab>self._wb_parse_context = ""style""<tab><tab><IF-STMT><tab><tab><tab>if self._allow_js_type(tag_attrs):<tab><tab><tab><tab>self._wb_parse_context = ""script""","elif tag == ""script"" :",106
2726,"def can_read(self):<tab>if hasattr(self.file, ""__iter__""):<tab><tab>iterator = iter(self.file)<tab><tab>head = next(iterator, None)<tab><tab>if head is None:<tab><tab><tab>self.repaired = []<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>self.repaired = itertools.chain([head], iterator)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab># We may have mangled a generator at this point, so just abort<tab><tab><tab>raise IOSourceError(<tab><tab><tab><tab>""Could not open source: %r (mode: %r)""<tab><tab><tab><tab>% (self.file, self.options[""mode""])<tab><tab><tab>)<tab>return False","if isinstance ( head , str ) :",176
2727,"def wrapped_request_method(*args, **kwargs):<tab>""""""Modifies HTTP headers to include a specified user-agent.""""""<tab>if kwargs.get(""headers"") is not None:<tab><tab>if kwargs[""headers""].get(""user-agent""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Save the existing user-agent header and tack on our own.<tab><tab><tab><tab>kwargs[""headers""][""user-agent""] = (<tab><tab><tab><tab><tab>f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}'<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>kwargs[""headers""][""user-agent""] = user_agent<tab>else:<tab><tab>kwargs[""headers""] = {""user-agent"": user_agent}<tab>return request_method(*args, **kwargs)","if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :",191
2728,"def execute(self):<tab>if self._dirty or not self._qr:<tab><tab>model_class = self.model_class<tab><tab>query_meta = self.get_query_meta()<tab><tab>if self._tuples:<tab><tab><tab>ResultWrapper = TuplesQueryResultWrapper<tab><tab>elif self._dicts:<tab><tab><tab>ResultWrapper = DictQueryResultWrapper<tab><tab><IF-STMT><tab><tab><tab>ResultWrapper = NaiveQueryResultWrapper<tab><tab>elif self._aggregate_rows:<tab><tab><tab>ResultWrapper = AggregateQueryResultWrapper<tab><tab>else:<tab><tab><tab>ResultWrapper = ModelQueryResultWrapper<tab><tab>self._qr = ResultWrapper(model_class, self._execute(), query_meta)<tab><tab>self._dirty = False<tab><tab>return self._qr<tab>else:<tab><tab>return self._qr",elif self . _naive or not self . _joins or self . verify_naive ( ) :,198
2729,"def populate_data(apps, schema_editor):<tab>Menu = apps.get_model(""menu"", ""Menu"")<tab>for menu in Menu.objects.all():<tab><tab><IF-STMT><tab><tab><tab>json_str = menu.json_content<tab><tab><tab>while isinstance(json_str, str):<tab><tab><tab><tab>json_str = json.loads(json_str)<tab><tab><tab>menu.json_content_new = json_str<tab><tab><tab>menu.save()","if isinstance ( menu . json_content , str ) :",118
2730,"def virtualenv_exists(self):<tab>if os.path.exists(self.virtualenv_location):<tab><tab><IF-STMT><tab><tab><tab>extra = [""Scripts"", ""activate.bat""]<tab><tab>else:<tab><tab><tab>extra = [""bin"", ""activate""]<tab><tab>return os.path.isfile(os.sep.join([self.virtualenv_location] + extra))<tab>return False","if os . name == ""nt"" :",96
2731,"def get_minkowski_function(name, variable):<tab>fn_name = name + get_postfix(variable)<tab>if hasattr(MEB, fn_name):<tab><tab>return getattr(MEB, fn_name)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""Function {fn_name} not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise ValueError(f""Function {fn_name} not available."")",if variable . is_cuda :,134
2732,"def build_temp_workspace(files):<tab>tempdir = tempfile.mkdtemp(prefix=""yamllint-tests-"")<tab>for path, content in files.items():<tab><tab>path = os.path.join(tempdir, path).encode(""utf-8"")<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(os.path.dirname(path))<tab><tab>if type(content) is list:<tab><tab><tab>os.mkdir(path)<tab><tab>else:<tab><tab><tab>mode = ""wb"" if isinstance(content, bytes) else ""w""<tab><tab><tab>with open(path, mode) as f:<tab><tab><tab><tab>f.write(content)<tab>return tempdir",if not os . path . exists ( os . path . dirname ( path ) ) :,169
2733,"def clean_form(self, request, user, form, cleaned_data):<tab>for field in self.get_fields():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>cleaned_data[field.fieldname] = field.clean(<tab><tab><tab><tab>request, user, cleaned_data[field.fieldname]<tab><tab><tab>)<tab><tab>except ValidationError as e:<tab><tab><tab>form.add_error(field.fieldname, e)<tab>return cleaned_data",if field . fieldname not in cleaned_data :,121
2734,"def setUp(self):<tab>self.realm = service.InMemoryWordsRealm(""realmname"")<tab>self.checker = checkers.InMemoryUsernamePasswordDatabaseDontUse()<tab>self.portal = portal.Portal(self.realm, [self.checker])<tab>self.factory = service.IRCFactory(self.realm, self.portal)<tab>c = []<tab>for nick in self.STATIC_USERS:<tab><tab><IF-STMT><tab><tab><tab>nick = nick.decode(""utf-8"")<tab><tab>c.append(self.realm.createUser(nick))<tab><tab>self.checker.addUser(nick, nick + ""_password"")<tab>return DeferredList(c)","if isinstance ( nick , bytes ) :",165
2735,"def __call__(self, message):<tab>with self._lock:<tab><tab>self._pending_ack += 1<tab><tab>self.max_pending_ack = max(self.max_pending_ack, self._pending_ack)<tab><tab>self.seen_message_ids.append(int(message.attributes[""seq_num""]))<tab>time.sleep(self._processing_time)<tab>with self._lock:<tab><tab>self._pending_ack -= 1<tab><tab>message.ack()<tab><tab>self.completed_calls += 1<tab><tab><IF-STMT><tab><tab><tab>if not self.done_future.done():<tab><tab><tab><tab>self.done_future.set_result(None)",if self . completed_calls >= self . _resolve_at_msg_count :,173
2736,"def fill_in_standard_formats(book):<tab>for x in std_format_code_types.keys():<tab><tab><IF-STMT><tab><tab><tab>ty = std_format_code_types[x]<tab><tab><tab># Note: many standard format codes (mostly CJK date formats) have<tab><tab><tab># format strings that vary by locale; xlrd does not (yet)<tab><tab><tab># handle those; the type (date or numeric) is recorded but the fmt_str will be None.<tab><tab><tab>fmt_str = std_format_strings.get(x)<tab><tab><tab>fmtobj = Format(x, ty, fmt_str)<tab><tab><tab>book.format_map[x] = fmtobj",if x not in book . format_map :,171
2737,"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None):<tab>result = []<tab>for i in range(10):<tab><tab># This line introduces a bug.<tab><tab>if bigger_than_3_only and less_than_7_only and i == 4:<tab><tab><tab>continue<tab><tab>if bigger_than_3_only and i <= 3:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if even_only and i % 2 != 0:<tab><tab><tab>continue<tab><tab>result.append(i)<tab>return result",if less_than_7_only and i >= 7 :,158
2738,"def next_instruction_is_function_or_class(lines):<tab>""""""Is the first non-empty, non-commented line of the cell either a function or a class?""""""<tab>parser = StringParser(""python"")<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>parser.read_line(line)<tab><tab><tab>continue<tab><tab>parser.read_line(line)<tab><tab>if not line.strip():  # empty line<tab><tab><tab>if i > 0 and not lines[i - 1].strip():<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>if line.startswith(""def "") or line.startswith(""class ""):<tab><tab><tab>return True<tab><tab>if line.startswith((""#"", ""@"", "" "", "")"")):<tab><tab><tab>continue<tab><tab>return False<tab>return False",if parser . is_quoted ( ) :,194
2739,"def __getattr__(self, key):<tab>for tag in self.tag.children:<tab><tab>if tag.name not in (""input"",):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation<tab><tab><tab>return DOMImplementation.createHTMLElement(self.doc, tag)<tab>raise AttributeError","if ""name"" in tag . attrs and tag . attrs [ ""name"" ] in ( key , ) :",104
2740,"def process_signature(app, what, name, obj, options, signature, return_annotation):<tab>if signature:<tab><tab># replace Mock function names<tab><tab>signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature)<tab><tab>signature = re.sub(""tensorflow"", ""tf"", signature)<tab><tab># add scope name to layer signatures:<tab><tab><IF-STMT><tab><tab><tab>if obj.use_scope:<tab><tab><tab><tab>signature = signature[0] + ""variable_scope_name, "" + signature[1:]<tab><tab><tab>elif obj.use_scope is None:<tab><tab><tab><tab>signature = signature[0] + ""[variable_scope_name,] "" + signature[1:]<tab># signature: arg list<tab>return signature, return_annotation","if hasattr ( obj , ""use_scope"" ) :",188
2741,"def countbox(self):<tab>self.box = [1000, 1000, -1000, -1000]<tab>for x, y in self.body:<tab><tab>if x < self.box[0]:<tab><tab><tab>self.box[0] = x<tab><tab>if x > self.box[2]:<tab><tab><tab>self.box[2] = x<tab><tab>if y < self.box[1]:<tab><tab><tab>self.box[1] = y<tab><tab><IF-STMT><tab><tab><tab>self.box[3] = y",if y > self . box [ 3 ] :,131
2742,"def find_shell():<tab>global DEFAULT_SHELL<tab>if not DEFAULT_SHELL:<tab><tab>for shell in propose_shell():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>DEFAULT_SHELL = shell<tab><tab><tab><tab>break<tab>if not DEFAULT_SHELL:<tab><tab>DEFAULT_SHELL = ""/bin/sh""<tab>return DEFAULT_SHELL","if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :",110
2743,"def addAggregators(sheet, cols, aggrnames):<tab>""Add each aggregator in list of *aggrnames* to each of *cols*.""<tab>for aggrname in aggrnames:<tab><tab>aggrs = vd.aggregators.get(aggrname)<tab><tab>aggrs = aggrs if isinstance(aggrs, list) else [aggrs]<tab><tab>for aggr in aggrs:<tab><tab><tab>for c in cols:<tab><tab><tab><tab>if not hasattr(c, ""aggregators""):<tab><tab><tab><tab><tab>c.aggregators = []<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>c.aggregators += [aggr]",if aggr and aggr not in c . aggregators :,149
2744,"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>items.append(item.pathAbsoluteFromProjectEncoded())<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",if len ( items ) > 1 :,117
2745,"def social_user(backend, uid, user=None, *args, **kwargs):<tab>provider = backend.name<tab>social = backend.strategy.storage.user.get_social_auth(provider, uid)<tab>if social:<tab><tab><IF-STMT><tab><tab><tab>msg = ""This account is already in use.""<tab><tab><tab>raise AuthAlreadyAssociated(backend, msg)<tab><tab>elif not user:<tab><tab><tab>user = social.user<tab>return {<tab><tab>""social"": social,<tab><tab>""user"": user,<tab><tab>""is_new"": user is None,<tab><tab>""new_association"": social is None,<tab>}",if user and social . user != user :,170
2746,"def _text(bitlist):<tab>out = """"<tab>for typ, text in bitlist:<tab><tab>if not typ:<tab><tab><tab>out += text<tab><tab>elif typ == ""em"":<tab><tab><tab>out += ""\\fI%s\\fR"" % text<tab><tab><IF-STMT><tab><tab><tab>out += ""\\fB%s\\fR"" % text<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected tag %r inside text"" % (typ,))<tab>out = out.strip()<tab>out = re.sub(re.compile(r""^\s+"", re.M), """", out)<tab>return out","elif typ in [ ""strong"" , ""code"" ] :",150
2747,"def OnRadioSelect(self, event):<tab>fitID = self.mainFrame.getActiveFit()<tab>if fitID is not None:<tab><tab>self.mainFrame.command.Submit(<tab><tab><tab>cmd.GuiChangeImplantLocationCommand(<tab><tab><tab><tab>fitID=fitID,<tab><tab><tab><tab>source=ImplantLocation.FIT<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else ImplantLocation.CHARACTER,<tab><tab><tab>)<tab><tab>)",if self . rbFit . GetValue ( ),119
2748,"def hexdump(data):<tab>""""""yield lines with hexdump of data""""""<tab>values = []<tab>ascii = []<tab>offset = 0<tab>for h, a in sixteen(data):<tab><tab><IF-STMT><tab><tab><tab>yield (offset, "" "".join(["""".join(values), """".join(ascii)]))<tab><tab><tab>del values[:]<tab><tab><tab>del ascii[:]<tab><tab><tab>offset += 0x10<tab><tab>else:<tab><tab><tab>values.append(h)<tab><tab><tab>ascii.append(a)",if h is None :,124
2749,"def submit(self):<tab>bot_token = self.config[""bot_token""]<tab>chat_ids = self.config[""chat_id""]<tab>chat_ids = [chat_ids] if isinstance(chat_ids, str) else chat_ids<tab>text = ""\n"".join(super().submit())<tab>if not text:<tab><tab>logger.debug(""Not calling telegram API (no changes)"")<tab><tab>return<tab>result = None<tab>for chunk in chunkstring(text, self.MAX_LENGTH, numbering=True):<tab><tab>for chat_id in chat_ids:<tab><tab><tab>res = self.submitToTelegram(bot_token, chat_id, chunk)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = res<tab>return result",if res . status_code != requests . codes . ok or res is None :,187
2750,"def onMessage(self, payload, isBinary):<tab>if not isBinary:<tab><tab>self.result = ""Expected binary message with payload, but got binary.""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.result = (<tab><tab><tab><tab>""Expected binary message with payload of length %d, but got %d.""<tab><tab><tab><tab>% (self.DATALEN, len(payload))<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>## FIXME : check actual content<tab><tab><tab>##<tab><tab><tab>self.behavior = Case.OK<tab><tab><tab>self.result = ""Received binary message of length %d."" % len(payload)<tab>self.p.createWirelog = True<tab>self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",if len ( payload ) != self . DATALEN :,192
2751,"def verify_output(actual, expected):<tab>actual = _read_file(actual, ""Actual"")<tab>expected = _read_file(join(CURDIR, expected), ""Expected"")<tab>if len(expected) != len(actual):<tab><tab>raise AssertionError(<tab><tab><tab>""Lengths differ. Expected %d lines but got %d""<tab><tab><tab>% (len(expected), len(actual))<tab><tab>)<tab>for exp, act in zip(expected, actual):<tab><tab>tester = fnmatchcase if ""*"" in exp else eq<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>""Lines differ.\nExpected: %s\nActual:   %s"" % (exp, act)<tab><tab><tab>)","if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :",179
2752,"def _in_out_vector_helper(self, name1, name2, ceil):<tab>vector = []<tab>stats = self.record<tab>if ceil is None:<tab><tab>ceil = self._get_max_rate(name1, name2)<tab>maxlen = self.config.get_stats_history_length()<tab>for n in [name1, name2]:<tab><tab>for i in range(maxlen + 1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vector.append(float(stats[i][n]) / ceil)<tab><tab><tab>else:<tab><tab><tab><tab>vector.append(0.0)<tab>return vector",if i < len ( stats ) :,153
2753,"def _init_param(param, mode):<tab>if isinstance(param, str):<tab><tab>param = _resolve(param)<tab>elif isinstance(param, (list, tuple)):<tab><tab>param = [_init_param(p, mode) for p in param]<tab>elif isinstance(param, dict):<tab><tab><IF-STMT><tab><tab><tab>param = from_params(param, mode=mode)<tab><tab>else:<tab><tab><tab>param = {k: _init_param(v, mode) for k, v in param.items()}<tab>return param","if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :",145
2754,"def link_pantsrefs(soups, precomputed):<tab>""""""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">""""""<tab>for (page, soup) in soups.items():<tab><tab>for a in soup.find_all(""a""):<tab><tab><tab>if not a.has_attr(""pantsref""):<tab><tab><tab><tab>continue<tab><tab><tab>pantsref = a[""pantsref""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TaskError(<tab><tab><tab><tab><tab>f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it'<tab><tab><tab><tab>)<tab><tab><tab>a[""href""] = rel_href(page, precomputed.pantsref[pantsref])",if pantsref not in precomputed . pantsref :,194
2755,"def _gridconvvalue(self, value):<tab>if isinstance(value, (str, _tkinter.Tcl_Obj)):<tab><tab>try:<tab><tab><tab>svalue = str(value)<tab><tab><tab>if not svalue:<tab><tab><tab><tab>return None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return getdouble(svalue)<tab><tab><tab>else:<tab><tab><tab><tab>return getint(svalue)<tab><tab>except ValueError:<tab><tab><tab>pass<tab>return value","elif ""."" in svalue :",116
2756,"def default(self, o):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return str(o)<tab><tab>else:<tab><tab><tab># remove unwanted attributes from the provider object during conversion to json<tab><tab><tab>if hasattr(o, ""profile""):<tab><tab><tab><tab>del o.profile<tab><tab><tab>if hasattr(o, ""credentials""):<tab><tab><tab><tab>del o.credentials<tab><tab><tab>if hasattr(o, ""metadata_path""):<tab><tab><tab><tab>del o.metadata_path<tab><tab><tab>if hasattr(o, ""services_config""):<tab><tab><tab><tab>del o.services_config<tab><tab><tab>return vars(o)<tab>except Exception as e:<tab><tab>return str(o)",if type ( o ) == datetime . datetime :,172
2757,"def transform_kwarg(self, name, value, split_single_char_options):<tab>if len(name) == 1:<tab><tab><IF-STMT><tab><tab><tab>return [""-%s"" % name]<tab><tab>elif value not in (False, None):<tab><tab><tab>if split_single_char_options:<tab><tab><tab><tab>return [""-%s"" % name, ""%s"" % value]<tab><tab><tab>else:<tab><tab><tab><tab>return [""-%s%s"" % (name, value)]<tab>else:<tab><tab>if value is True:<tab><tab><tab>return [""--%s"" % dashify(name)]<tab><tab>elif value is not False and value is not None:<tab><tab><tab>return [""--%s=%s"" % (dashify(name), value)]<tab>return []",if value is True :,183
2758,"def handle(self, context, sign, *args):<tab>if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP):<tab><tab>return Infsign[sign]<tab>if sign == 0:<tab><tab><IF-STMT><tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))<tab>if sign == 1:<tab><tab>if context.rounding == ROUND_FLOOR:<tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",if context . rounding == ROUND_CEILING :,184
2759,"def OnLeftUp(self, event):<tab># Stop Drawing<tab>if self.Drawing:<tab><tab>self.Drawing = False<tab><tab><IF-STMT><tab><tab><tab>world_rect = (<tab><tab><tab><tab>self.Canvas.PixelToWorld(self.RBRect[0]),<tab><tab><tab><tab>self.Canvas.ScalePixelToWorld(self.RBRect[1]),<tab><tab><tab>)<tab><tab><tab>wx.CallAfter(self.CallBack, world_rect)<tab>self.RBRect = None",if self . RBRect :,127
2760,"def _map_answers(answers):<tab>result = []<tab>for a in answers.split(""|""):<tab><tab>user_answers = []<tab><tab>result.append(dict(sourcerAnswers=user_answers))<tab><tab>for r in a.split("",""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>user_answers.append(dict(noAnswer=True))<tab><tab><tab>else:<tab><tab><tab><tab>start_, end_ = map(int, r.split("":""))<tab><tab><tab><tab>user_answers.append(dict(s=start_, e=end_))<tab>return result","if r == ""None"" :",138
2761,"def parse_edges(self, pcb):<tab>edges = []<tab>drawings = list(pcb.GetDrawings())<tab>bbox = None<tab>for m in pcb.GetModules():<tab><tab>for g in m.GraphicalItems():<tab><tab><tab>drawings.append(g)<tab>for d in drawings:<tab><tab><IF-STMT><tab><tab><tab>parsed_drawing = self.parse_drawing(d)<tab><tab><tab>if parsed_drawing:<tab><tab><tab><tab>edges.append(parsed_drawing)<tab><tab><tab><tab>if bbox is None:<tab><tab><tab><tab><tab>bbox = d.GetBoundingBox()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>bbox.Merge(d.GetBoundingBox())<tab>if bbox:<tab><tab>bbox.Normalize()<tab>return edges, bbox",if d . GetLayer ( ) == pcbnew . Edge_Cuts :,197
2762,"def get_size(self):<tab>size = self.start_size<tab>for operation in self.ran_operations:<tab><tab><IF-STMT><tab><tab><tab>size = operation[1][0]<tab><tab>elif operation[0] == ""crop"":<tab><tab><tab>crop = operation[1][0]<tab><tab><tab>size = crop[2] - crop[0], crop[3] - crop[1]<tab>return size","if operation [ 0 ] == ""resize"" :",104
2763,"def migrate_account_metadata(account_id):<tab>from inbox.models.session import session_scope<tab>from inbox.models import Account<tab>with session_scope(versioned=False) as db_session:<tab><tab>account = db_session.query(Account).get(account_id)<tab><tab><IF-STMT><tab><tab><tab>create_categories_for_easfoldersyncstatuses(account, db_session)<tab><tab>else:<tab><tab><tab>create_categories_for_folders(account, db_session)<tab><tab>if account.discriminator == ""gmailaccount"":<tab><tab><tab>set_labels_for_imapuids(account, db_session)<tab><tab>db_session.commit()","if account . discriminator == ""easaccount"" :",168
2764,"def OnEndDrag(self, event):<tab>self.StopDragging()<tab>dropTarget = event.GetItem()<tab>if not dropTarget:<tab><tab>dropTarget = self.GetRootItem()<tab>if self.IsValidDropTarget(dropTarget):<tab><tab>self.UnselectAll()<tab><tab><IF-STMT><tab><tab><tab>self.SelectItem(dropTarget)<tab><tab>self.OnDrop(dropTarget, self._dragItem)",if dropTarget != self . GetRootItem ( ) :,109
2765,"def validate(self, frame, value):<tab>if self.sep and isinstance(value, string_types):<tab><tab>value = value.split(self.sep)<tab>if isinstance(value, list):<tab><tab><IF-STMT><tab><tab><tab>return [self.specs[0].validate(frame, v) for v in value]<tab><tab>else:<tab><tab><tab>return [<tab><tab><tab><tab>[s.validate(frame, v) for (v, s) in izip(val, self.specs)]<tab><tab><tab><tab>for val in value<tab><tab><tab>]<tab>raise ValueError(""Invalid MultiSpec data: %r"" % value)",if len ( self . specs ) == 1 :,153
2766,"def __init__(self, action_space=None, network=None, network_kwargs=None, hparams=None):<tab>QNetBase.__init__(self, hparams=hparams)<tab>with tf.variable_scope(self.variable_scope):<tab><tab><IF-STMT><tab><tab><tab>action_space = Space(low=0, high=self._hparams.action_space, dtype=np.int32)<tab><tab>self._action_space = action_space<tab><tab>self._append_output_layer()",if action_space is None :,120
2767,"def n_weights(self):<tab>""""""Return the number of weights (parameters) in this network.""""""<tab>n_weights = 0<tab>for i, w in enumerate(self.all_weights):<tab><tab>n = 1<tab><tab># for s in p.eval().shape:<tab><tab>for s in w.get_shape():<tab><tab><tab>try:<tab><tab><tab><tab>s = int(s)<tab><tab><tab>except:<tab><tab><tab><tab>s = 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n = n * s<tab><tab>n_weights = n_weights + n<tab># print(""num of weights (parameters) %d"" % n_weights)<tab>return n_weights",if s :,161
2768,"def _arg_desc(name, ctx):<tab>for param in ctx.command.params:<tab><tab>if param.name == name:<tab><tab><tab>desc = param.opts[-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>desc = param.human_readable_name<tab><tab><tab>return desc<tab>raise AssertionError(name)","if desc [ 0 ] != ""-"" :",82
2769,"def walk(directory, path_so_far):<tab>for name in sorted(os.listdir(directory)):<tab><tab>if any(fnmatch(name, pattern) for pattern in basename_ignore):<tab><tab><tab>continue<tab><tab>path = path_so_far + ""/"" + name if path_so_far else name<tab><tab>if any(fnmatch(path, pattern) for pattern in path_ignore):<tab><tab><tab>continue<tab><tab>full_name = os.path.join(directory, name)<tab><tab>if os.path.isdir(full_name):<tab><tab><tab>for file_path in walk(full_name, path):<tab><tab><tab><tab>yield file_path<tab><tab><IF-STMT><tab><tab><tab>yield path",elif os . path . isfile ( full_name ) :,172
2770,"def cache_dst(self):<tab>final_dst = None<tab>final_linenb = None<tab>for linenb, assignblk in enumerate(self):<tab><tab>for dst, src in viewitems(assignblk):<tab><tab><tab>if dst.is_id(""IRDst""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(""Multiple destinations!"")<tab><tab><tab><tab>final_dst = src<tab><tab><tab><tab>final_linenb = linenb<tab>self._dst = final_dst<tab>self._dst_linenb = final_linenb<tab>return final_dst",if final_dst is not None :,144
2771,"def run(self, args, **kwargs):<tab>if args.resource_ref or args.policy_type:<tab><tab>filters = {}<tab><tab><IF-STMT><tab><tab><tab>filters[""resource_ref""] = args.resource_ref<tab><tab>if args.policy_type:<tab><tab><tab>filters[""policy_type""] = args.policy_type<tab><tab>filters.update(**kwargs)<tab><tab>return self.manager.query(**filters)<tab>else:<tab><tab>return self.manager.get_all(**kwargs)",if args . resource_ref :,123
2772,"def __init__(self, folders):<tab>self.folders = folders<tab>self.duplicates = {}<tab>for folder, path in folders.items():<tab><tab>duplicates = []<tab><tab>for other_folder, other_path in folders.items():<tab><tab><tab>if other_folder == folder:<tab><tab><tab><tab>continue<tab><tab><tab>if other_path == path:<tab><tab><tab><tab>duplicates.append(other_folder)<tab><tab><IF-STMT><tab><tab><tab>self.duplicates[folder] = duplicates",if len ( duplicates ) :,117
2773,"def limit_clause(self, select, **kw):<tab>text = """"<tab>if select._limit_clause is not None:<tab><tab>text += ""\n LIMIT "" + self.process(select._limit_clause, **kw)<tab>if select._offset_clause is not None:<tab><tab><IF-STMT><tab><tab><tab>text += ""\n LIMIT "" + self.process(sql.literal(-1))<tab><tab>text += "" OFFSET "" + self.process(select._offset_clause, **kw)<tab>else:<tab><tab>text += "" OFFSET "" + self.process(sql.literal(0), **kw)<tab>return text",if select . _limit_clause is None :,150
2774,"def _get_activation(self, act):<tab>""""""Get activation block based on the name.""""""<tab>if isinstance(act, str):<tab><tab>if act.lower() == ""gelu"":<tab><tab><tab>return GELU()<tab><tab><IF-STMT><tab><tab><tab>return GELU(approximate=True)<tab><tab>else:<tab><tab><tab>return gluon.nn.Activation(act)<tab>assert isinstance(act, gluon.Block)<tab>return act","elif act . lower ( ) == ""approx_gelu"" :",112
2775,"def __eq__(self, other):<tab>try:<tab><tab>if self.type != other.type:<tab><tab><tab>return False<tab><tab>if self.type == ""ASK"":<tab><tab><tab>return self.askAnswer == other.askAnswer<tab><tab><IF-STMT><tab><tab><tab>return self.vars == other.vars and self.bindings == other.bindings<tab><tab>else:<tab><tab><tab>return self.graph == other.graph<tab>except:<tab><tab>return False","elif self . type == ""SELECT"" :",116
2776,"def _get_text_nodes(nodes, html_body):<tab>text = []<tab>open_tags = 0<tab>for node in nodes:<tab><tab>if isinstance(node, HtmlTag):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>open_tags += 1<tab><tab><tab>elif node.tag_type == CLOSE_TAG:<tab><tab><tab><tab>open_tags -= 1<tab><tab>elif (<tab><tab><tab>isinstance(node, HtmlDataFragment)<tab><tab><tab>and node.is_text_content<tab><tab><tab>and open_tags == 0<tab><tab>):<tab><tab><tab>text.append(html_body[node.start : node.end])<tab>return text",if node . tag_type == OPEN_TAG :,165
2777,"def test_do_change(self):<tab>""""""Test if VTK object changes when trait is changed.""""""<tab>p = Prop()<tab>p.edge_visibility = not p.edge_visibility<tab>p.representation = ""p""<tab>p.opacity = 0.5<tab>p.color = (0, 1, 0)<tab>p.diffuse_color = (1, 1, 1)<tab>p.specular_color = (1, 1, 0)<tab>for t, g in p._updateable_traits_:<tab><tab>val = getattr(p._vtk_obj, g)()<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(val, getattr(p, t + ""_""))<tab><tab>else:<tab><tab><tab>self.assertEqual(val, getattr(p, t))","if t == ""representation"" :",185
2778,"def update_item(source_doc, target_doc, source_parent):<tab>target_doc.t_warehouse = """"<tab>if source_doc.material_request_item and source_doc.material_request:<tab><tab>add_to_transit = frappe.db.get_value(<tab><tab><tab>""Stock Entry"", source_name, ""add_to_transit""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>warehouse = frappe.get_value(<tab><tab><tab><tab>""Material Request Item"", source_doc.material_request_item, ""warehouse""<tab><tab><tab>)<tab><tab><tab>target_doc.t_warehouse = warehouse<tab>target_doc.s_warehouse = source_doc.t_warehouse<tab>target_doc.qty = source_doc.qty - source_doc.transferred_qty",if add_to_transit :,198
2779,"def get_drive(self, root_path="""", volume_guid_path=""""):<tab>for drive in self.drives:<tab><tab><IF-STMT><tab><tab><tab>config_root_path = drive.get(""root_path"")<tab><tab><tab>if config_root_path and root_path == config_root_path:<tab><tab><tab><tab>return drive<tab><tab>elif volume_guid_path:<tab><tab><tab>config_volume_guid_path = drive.get(""volume_guid_path"")<tab><tab><tab>if config_volume_guid_path and config_volume_guid_path == volume_guid_path:<tab><tab><tab><tab>return drive",if root_path :,148
2780,"def f_freeze(_):<tab>repos = utils.get_repos()<tab>for name, path in repos.items():<tab><tab>url = """"<tab><tab>cp = subprocess.run([""git"", ""remote"", ""-v""], cwd=path, capture_output=True)<tab><tab><IF-STMT><tab><tab><tab>url = cp.stdout.decode(""utf-8"").split(""\n"")[0].split()[1]<tab><tab>print(f""{url},{name},{path}"")",if cp . returncode == 0 :,111
2781,"def conj(self):<tab>dtype = self.dtype<tab>if issubclass(self.dtype.type, np.complexfloating):<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""only contiguous arrays may "" ""be used as arguments to this operation""<tab><tab><tab>)<tab><tab>if self.flags.f_contiguous:<tab><tab><tab>order = ""F""<tab><tab>else:<tab><tab><tab>order = ""C""<tab><tab>result = self._new_like_me(order=order)<tab><tab>func = elementwise.get_conj_kernel(dtype)<tab><tab>func.prepared_async_call(<tab><tab><tab>self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size<tab><tab>)<tab><tab>return result<tab>else:<tab><tab>return self",if not self . flags . forc :,198
2782,"def detect_reentrancy(self, contract):<tab>for function in contract.functions_and_modifiers_declared:<tab><tab>if function.is_implemented:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self._explore(function.entry_point, [])<tab><tab><tab>function.context[self.KEY] = True",if self . KEY in function . context :,87
2783,"def test_default_configuration_no_encoding(self):<tab>transformations = []<tab>for i in range(2):<tab><tab>transformation, original = _test_preprocessing(NoEncoding)<tab><tab>self.assertEqual(transformation.shape, original.shape)<tab><tab>self.assertTrue((transformation == original).all())<tab><tab>transformations.append(transformation)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue((transformations[-1] == transformations[-2]).all())",if len ( transformations ) > 1 :,114
2784,"def main():<tab>""""""main function""""""<tab># todo: lookuo real description<tab>parser = argparse.ArgumentParser(description=""Let a cow speak for you"")<tab>parser.add_argument(""text"", nargs=""*"", default=None, help=""text to say"")<tab>ns = parser.parse_args()<tab>if (ns.text is None) or (len(ns.text) == 0):<tab><tab>text = """"<tab><tab>while True:<tab><tab><tab>inp = sys.stdin.read(4096)<tab><tab><tab>if inp.endswith(""\n""):<tab><tab><tab><tab>inp = inp[:-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>text += inp<tab>else:<tab><tab>text = "" "".join(ns.text)<tab>cow = get_cow(text)<tab>print(cow)",if not inp :,193
2785,"def prehook(self, emu, op, eip):<tab>if op in self.badops:<tab><tab>emu.stopEmu()<tab><tab>raise v_exc.BadOpBytes(op.va)<tab>if op.mnem in STOS:<tab><tab>if self.arch == ""i386"":<tab><tab><tab>reg = emu.getRegister(envi.archs.i386.REG_EDI)<tab><tab>elif self.arch == ""amd64"":<tab><tab><tab>reg = emu.getRegister(envi.archs.amd64.REG_RDI)<tab><tab><IF-STMT><tab><tab><tab>self.vw.makePointer(reg, follow=True)",if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,186
2786,"def get_boarding_status(project):<tab>status = ""Pending""<tab>if project:<tab><tab>doc = frappe.get_doc(""Project"", project)<tab><tab>if flt(doc.percent_complete) > 0.0 and flt(doc.percent_complete) < 100.0:<tab><tab><tab>status = ""In Process""<tab><tab><IF-STMT><tab><tab><tab>status = ""Completed""<tab><tab>return status",elif flt ( doc . percent_complete ) == 100.0 :,116
2787,"def set_weights(self, new_weights):<tab>weights = self.get_weights()<tab>if len(weights) != len(new_weights):<tab><tab>raise ValueError(""len of lists mismatch"")<tab>tuples = []<tab>for w, new_w in zip(weights, new_weights):<tab><tab><IF-STMT><tab><tab><tab>new_w = new_w.reshape(w.shape)<tab><tab>tuples.append((w, new_w))<tab>nn.batch_set_value(tuples)",if len ( w . shape ) != new_w . shape :,129
2788,"def reload_json_api_settings(*args, **kwargs):<tab>django_setting = kwargs[""setting""]<tab>setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """")<tab>value = kwargs[""value""]<tab>if setting in DEFAULTS.keys():<tab><tab><IF-STMT><tab><tab><tab>setattr(json_api_settings, setting, value)<tab><tab>elif hasattr(json_api_settings, setting):<tab><tab><tab>delattr(json_api_settings, setting)",if value is not None :,115
2789,"def knamn(self, sup, cdict):<tab>cname = cdict[sup].class_name<tab>if not cname:<tab><tab>(namesp, tag) = cdict[sup].name.split(""."")<tab><tab><IF-STMT><tab><tab><tab>ctag = self.root.modul[namesp].factory(tag).__class__.__name__<tab><tab><tab>cname = ""%s.%s"" % (namesp, ctag)<tab><tab>else:<tab><tab><tab>cname = tag + ""_""<tab>return cname",if namesp :,117
2790,"def setdefault(self, key, default=None):<tab>try:<tab><tab>o = self.data[key]()<tab>except KeyError:<tab><tab>o = None<tab>if o is None:<tab><tab><IF-STMT><tab><tab><tab>self._commit_removals()<tab><tab>self.data[key] = KeyedRef(default, self._remove, key)<tab><tab>return default<tab>else:<tab><tab>return o",if self . _pending_removals :,104
2791,"def __on_item_activated(self, event):<tab>if self.__module_view:<tab><tab>module = self.get_event_module(event)<tab><tab>self.__module_view.set_selection(module.module_num)<tab><tab><IF-STMT><tab><tab><tab>self.input_list_ctrl.deactivate_active_item()<tab><tab>else:<tab><tab><tab>self.list_ctrl.deactivate_active_item()<tab><tab><tab>for index in range(self.list_ctrl.GetItemCount()):<tab><tab><tab><tab>if self.list_ctrl.IsSelected(index):<tab><tab><tab><tab><tab>self.list_ctrl.Select(index, False)<tab>self.__controller.enable_module_controls_panel_buttons()",if event . EventObject is self . list_ctrl :,181
2792,"def _create_valid_graph(graph):<tab>nodes = graph.nodes()<tab>for i in range(len(nodes)):<tab><tab>for j in range(len(nodes)):<tab><tab><tab>if i == j:<tab><tab><tab><tab>continue<tab><tab><tab>edge = (nodes[i], nodes[j])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>graph.del_edge(edge)<tab><tab><tab>graph.add_edge(edge, 1)",if graph . has_edge ( edge ) :,112
2793,"def _parse_param_value(name, datatype, default):<tab>if datatype == ""bool"":<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif default.lower() == ""false"":<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>_s = ""{}: Invalid default value '{}' for bool parameter {}""<tab><tab><tab>raise SyntaxError(_s.format(self.name, default, p))<tab>elif datatype == ""int"":<tab><tab>if type(default) == int:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return int(default, 0)<tab>elif datatype == ""real"":<tab><tab>if type(default) == float:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return float(default)<tab>else:<tab><tab>return str(default)","if default . lower ( ) == ""true"" :",191
2794,"def get_size(self, shape_info):<tab># The size is the data, that have constant size.<tab>state = np.random.RandomState().get_state()<tab>size = 0<tab>for elem in state:<tab><tab><IF-STMT><tab><tab><tab>size += len(elem)<tab><tab>elif isinstance(elem, np.ndarray):<tab><tab><tab>size += elem.size * elem.itemsize<tab><tab>elif isinstance(elem, int):<tab><tab><tab>size += np.dtype(""int"").itemsize<tab><tab>elif isinstance(elem, float):<tab><tab><tab>size += np.dtype(""float"").itemsize<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab>return size","if isinstance ( elem , str ) :",159
2795,"def _merge_substs(self, subst, new_substs):<tab>subst = subst.copy()<tab>for new_subst in new_substs:<tab><tab>for name, var in new_subst.items():<tab><tab><tab>if name not in subst:<tab><tab><tab><tab>subst[name] = var<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subst[name].PasteVariable(var)<tab>return subst",elif subst [ name ] is not var :,109
2796,"def _load_weights_if_possible(self, model, init_weight_path=None):<tab>""""""Loads model weights when it is provided.""""""<tab>if init_weight_path:<tab><tab>logging.info(""Load weights: {}"".format(init_weight_path))<tab><tab><IF-STMT><tab><tab><tab>checkpoint = tf.train.Checkpoint(<tab><tab><tab><tab>model=model, optimizer=self._create_optimizer()<tab><tab><tab>)<tab><tab><tab>checkpoint.restore(init_weight_path)<tab><tab>else:<tab><tab><tab>model.load_weights(init_weight_path)<tab>else:<tab><tab>logging.info(""Weights not loaded from path:{}"".format(init_weight_path))",if self . use_tpu :,168
2797,"def _cleanup_inactive_receivexlogs(self, site):<tab>if site in self.receivexlogs:<tab><tab>if not self.receivexlogs[site].running:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.receivexlogs[site].join()<tab><tab><tab>del self.receivexlogs[site]",if self . receivexlogs [ site ] . is_alive ( ) :,92
2798,"def get_asset(self, path):<tab>""""""Loads an asset by path.""""""<tab>clean_path = cleanup_path(path).strip(""/"")<tab>nodes = [self.asset_root] + self.theme_asset_roots<tab>for node in nodes:<tab><tab>for piece in clean_path.split(""/""):<tab><tab><tab>node = node.get_child(piece)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>if node is not None:<tab><tab><tab>return node<tab>return None",if node is None :,119
2799,"def palindromic_substrings(s):<tab>if not s:<tab><tab>return [[]]<tab>results = []<tab>for i in range(len(s), 0, -1):<tab><tab>sub = s[:i]<tab><tab><IF-STMT><tab><tab><tab>for rest in palindromic_substrings(s[i:]):<tab><tab><tab><tab>results.append([sub] + rest)<tab>return results",if sub == sub [ : : - 1 ] :,102
2800,"def debug_tree(tree):<tab>l = []<tab>for elt in tree:<tab><tab><IF-STMT><tab><tab><tab>l.append(_names.get(elt, elt))<tab><tab>elif isinstance(elt, str):<tab><tab><tab>l.append(elt)<tab><tab>else:<tab><tab><tab>l.append(debug_tree(elt))<tab>return l","if isinstance ( elt , ( int , long ) ) :",92
2801,"def shared_username(account):<tab>username = os.environ.get(""SHARED_USERNAME"", ""PKKid"")<tab>for user in account.users():<tab><tab><IF-STMT><tab><tab><tab>return username<tab><tab>elif (<tab><tab><tab>user.username<tab><tab><tab>and user.email<tab><tab><tab>and user.id<tab><tab><tab>and username.lower()<tab><tab><tab>in (user.username.lower(), user.email.lower(), str(user.id))<tab><tab>):<tab><tab><tab>return username<tab>pytest.skip(""Shared user %s wasn`t found in your MyPlex account"" % username)",if user . title . lower ( ) == username . lower ( ) :,152
2802,"def process_schema_element(self, e):<tab>if e.name is None:<tab><tab>return<tab>self.debug1(""adding element: %s"", e.name)<tab>t = self.get_type(e.type)<tab>if t:<tab><tab><IF-STMT><tab><tab><tab>del self.pending_elements[e.name]<tab><tab>self.retval[self.tns].elements[e.name] = e<tab>else:<tab><tab>self.pending_elements[e.name] = e",if e . name in self . pending_elements :,129
2803,"def __setitem__(self, key, value):<tab>with self._lock:<tab><tab>try:<tab><tab><tab>link = self._get_link_and_move_to_front_of_ll(key)<tab><tab>except KeyError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._set_key_and_add_to_front_of_ll(key, value)<tab><tab><tab>else:<tab><tab><tab><tab>evicted = self._set_key_and_evict_last_in_ll(key, value)<tab><tab><tab><tab>super(LRI, self).__delitem__(evicted)<tab><tab><tab>super(LRI, self).__setitem__(key, value)<tab><tab>else:<tab><tab><tab>link[VALUE] = value",if len ( self ) < self . max_size :,181
2804,"def __delattr__(self, name):<tab>if name == ""__dict__"":<tab><tab>raise AttributeError(<tab><tab><tab>""%r object attribute '__dict__' is read-only"" % self.__class__.__name__<tab><tab>)<tab>if name in self._local_type_vars:<tab><tab><IF-STMT><tab><tab><tab># A data descriptor, like a property or a slot.<tab><tab><tab>type_attr = getattr(self._local_type, name, _marker)<tab><tab><tab>type(type_attr).__delete__(type_attr, self)<tab><tab><tab>return<tab># Otherwise it goes directly in the dict<tab># Begin inlined function _get_dict()<tab>dct = _local_get_dict(self)<tab>try:<tab><tab>del dct[name]<tab>except KeyError:<tab><tab>raise AttributeError(name)",if name in self . _local_type_del_descriptors :,199
2805,"def update_participants(self, refresh=True):<tab>for participant in list(self.participants_dict):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.removeItem(self.participants_dict[participant])<tab><tab>self.participant_items.remove(self.participants_dict[participant])<tab><tab>del self.participants_dict[participant]<tab>for participant in self.simulator_config.participants:<tab><tab>if participant in self.participants_dict:<tab><tab><tab>self.participants_dict[participant].refresh()<tab><tab>else:<tab><tab><tab>self.insert_participant(participant)<tab>if refresh:<tab><tab>self.update_view()",if participant is None or participant == self . simulator_config . broadcast_part :,182
2806,"def insert_bigger_b_add(node):<tab>if node.op == theano.tensor.add:<tab><tab>inputs = list(node.inputs)<tab><tab><IF-STMT><tab><tab><tab>inputs[-1] = theano.tensor.concatenate((inputs[-1], inputs[-1]))<tab><tab><tab>return [node.op(*inputs)]<tab>return False",if inputs [ - 1 ] . owner is None :,87
2807,"def _activate_cancel_status(self, cancel_status):<tab>if self._cancel_status is not None:<tab><tab>self._cancel_status._tasks.remove(self)<tab>self._cancel_status = cancel_status<tab>if self._cancel_status is not None:<tab><tab>self._cancel_status._tasks.add(self)<tab><tab><IF-STMT><tab><tab><tab>self._attempt_delivery_of_any_pending_cancel()",if self . _cancel_status . effectively_cancelled :,113
2808,"def writeLibraryGeometry(fp, meshes, config, shapes=None):<tab>progress = Progress(len(meshes), None)<tab>fp.write(""\n  <library_geometries>\n"")<tab>for mIdx, mesh in enumerate(meshes):<tab><tab><IF-STMT><tab><tab><tab>shape = None<tab><tab>else:<tab><tab><tab>shape = shapes[mIdx]<tab><tab>writeGeometry(fp, mesh, config, shape)<tab><tab>progress.step()<tab>fp.write(""  </library_geometries>\n"")",if shapes is None :,128
2809,"def init_module_config(module_json, config, config_path=default_config_path):<tab>if ""config"" in module_json[""meta""]:<tab><tab>if module_json[""meta""][""config""]:<tab><tab><tab>if module_json[""name""] not in config:<tab><tab><tab><tab>config.add_section(module_json[""name""])<tab><tab><tab>for config_var in module_json[""meta""][""config""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>config.set(module_json[""name""], config_var, """")<tab>return config","if config_var not in config [ module_json [ ""name"" ] ] :",142
2810,"def get_const_defines(flags, prefix=""""):<tab>defs = []<tab>for k, v in globals().items():<tab><tab>if isinstance(v, int):<tab><tab><tab>if v & flags:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if k.startswith(prefix):<tab><tab><tab><tab><tab><tab>defs.append(k)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>defs.append(k)<tab>return defs",if prefix :,104
2811,"def __init__(self, source, encoding=DEFAULT_ENCODING):<tab>self.data = {}<tab>with open(source, encoding=encoding) as file_:<tab><tab>for line in file_:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>k, v = line.split(""="", 1)<tab><tab><tab>k = k.strip()<tab><tab><tab>v = v.strip()<tab><tab><tab>if len(v) >= 2 and (<tab><tab><tab><tab>(v[0] == ""'"" and v[-1] == ""'"") or (v[0] == '""' and v[-1] == '""')<tab><tab><tab>):<tab><tab><tab><tab>v = v.strip(""'\"""")<tab><tab><tab>self.data[k] = v","if not line or line . startswith ( ""#"" ) or ""="" not in line :",189
2812,"def __detect_console_logger(self):<tab>logger = self.log<tab>while logger:<tab><tab>for handler in logger.handlers[:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if handler.stream in (sys.stdout, sys.stderr):<tab><tab><tab><tab><tab>self.logger_handlers.append(handler)<tab><tab>if logger.root == logger:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>logger = logger.root","if isinstance ( handler , StreamHandler ) :",109
2813,"def check_heuristic_in_sql():<tab>heurs = set()<tab>excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""]<tab>for heur in HEURISTICS:<tab><tab>name = heur[""name""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>sql = heur[""sql""]<tab><tab>if sql.lower().find(name.lower()) == -1:<tab><tab><tab>print((""SQL command not correctly associated to %s"" % repr(name)))<tab><tab><tab>print(sql)<tab><tab><tab>assert sql.find(name) != -1<tab><tab>heurs.add(name)<tab>print(""Heuristics:"")<tab>import pprint<tab>pprint.pprint(heurs)",if name in excluded :,171
2814,"def read(self, size=-1):<tab>buf = bytearray()<tab>while size != 0 and self.cursor < self.maxpos:<tab><tab><IF-STMT><tab><tab><tab>self.seek_to_block(self.cursor)<tab><tab>part = self.current_stream.read(size)<tab><tab>if size > 0:<tab><tab><tab>if len(part) == 0:<tab><tab><tab><tab>raise EOFError()<tab><tab><tab>size -= len(part)<tab><tab>self.cursor += len(part)<tab><tab>buf += part<tab>return bytes(buf)",if not self . in_current_block ( self . cursor ) :,142
2815,"def get_project_dir(env):<tab>project_file = workon_home / env / "".project""<tab>if project_file.exists():<tab><tab>with project_file.open() as f:<tab><tab><tab>project_dir = f.readline().strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return project_dir<tab><tab><tab>else:<tab><tab><tab><tab>err(<tab><tab><tab><tab><tab>""Corrupted or outdated:"",<tab><tab><tab><tab><tab>project_file,<tab><tab><tab><tab><tab>""\nDirectory"",<tab><tab><tab><tab><tab>project_dir,<tab><tab><tab><tab><tab>""doesn't exist."",<tab><tab><tab><tab>)",if os . path . exists ( project_dir ) :,158
2816,"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None):<tab>""""""cache hidden states into memory.""""""<tab>if mem_len is None or mem_len == 0:<tab><tab>return None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>curr_out = curr_out[:reuse_len]<tab><tab>if prev_mem is None:<tab><tab><tab>new_mem = curr_out[-mem_len:]<tab><tab>else:<tab><tab><tab>new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:]<tab>return tf.keras.backend.stop_gradient(new_mem)",if reuse_len is not None and reuse_len > 0 :,165
2817,"def cleanup_channel(self, to_cleanup):<tab>public_key, id_ = to_cleanup<tab># TODO: Maybe run it threaded?<tab>try:<tab><tab>with db_session:<tab><tab><tab>channel = self.session.mds.ChannelMetadata.get_for_update(<tab><tab><tab><tab>public_key=public_key, id_=id_<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>channel.local_version = 0<tab><tab><tab>channel.contents.delete(bulk=True)<tab>except Exception as e:<tab><tab>self._logger.warning(""Exception while cleaning unsubscribed channel: %"", str(e))",if not channel :,159
2818,"def best_image(width, height):<tab># A heuristic for finding closest sized image to required size.<tab>image = images[0]<tab>for img in images:<tab><tab>if img.width == width and img.height == height:<tab><tab><tab># Exact match always used<tab><tab><tab>return img<tab><tab><IF-STMT><tab><tab><tab># At least wide enough, and largest area<tab><tab><tab>image = img<tab>return image",elif img . width >= width and img . width * img . height > image . width * image . height :,120
2819,"def add_peer_to_blob(self, contact: ""KademliaPeer"", key: bytes) -> None:<tab>now = self.loop.time()<tab>if key in self._data_store:<tab><tab>current = list(filter(lambda x: x[0] == contact, self._data_store[key]))<tab><tab><IF-STMT><tab><tab><tab>self._data_store[key][self._data_store[key].index(current[0])] = (<tab><tab><tab><tab>contact,<tab><tab><tab><tab>now,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self._data_store[key].append((contact, now))<tab>else:<tab><tab>self._data_store[key] = [(contact, now)]",if len ( current ) > 0 :,180
2820,"def dump(self):<tab>self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name))<tab>for field in self._fields_:<tab><tab>if isinstance(getattr(self, field[0]), POINTER64):<tab><tab><tab>self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value))<tab><tab>elif isinstance(getattr(self, field[0]), int):<tab><tab><tab>self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0])))<tab><tab><IF-STMT><tab><tab><tab>self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :",188
2821,"def GeneratePageMetatadata(self, task):<tab>address_space = self.session.GetParameter(""default_address_space"")<tab>for vma in task.mm.mmap.walk_list(""vm_next""):<tab><tab>start = vma.vm_start<tab><tab>end = vma.vm_end<tab><tab># Skip the entire region.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Done.<tab><tab>if start > self.plugin_args.end:<tab><tab><tab>break<tab><tab>for vaddr in utils.xrange(start, end, 0x1000):<tab><tab><tab>if self.plugin_args.start <= vaddr <= self.plugin_args.end:<tab><tab><tab><tab>yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if end < self . plugin_args . start :,195
2822,"def _available_symbols(self, scoperef, expr):<tab>cplns = []<tab>found_names = set()<tab>while scoperef:<tab><tab>elem = self._elem_from_scoperef(scoperef)<tab><tab>for child in elem:<tab><tab><tab>name = child.get(""name"", """")<tab><tab><tab>if name.startswith(expr):<tab><tab><tab><tab>if name not in found_names:<tab><tab><tab><tab><tab>found_names.add(name)<tab><tab><tab><tab><tab>ilk = child.get(""ilk"") or child.tag<tab><tab><tab><tab><tab>cplns.append((ilk, name))<tab><tab>scoperef = self.parent_scoperef_from_scoperef(scoperef)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return sorted(cplns, key=operator.itemgetter(1))",if not scoperef :,196
2823,"def get_xenapi_host(self):<tab>""""""Return the xenapi host on which nova-compute runs on.""""""<tab>with self._get_session() as session:<tab><tab><IF-STMT><tab><tab><tab>return session.xenapi.host.get_by_uuid(self.host_uuid)<tab><tab>else:<tab><tab><tab>return session.xenapi.session.get_this_host(session.handle)",if self . host_uuid :,105
2824,"def stream_docker_log(log_stream):<tab>async for line in log_stream:<tab><tab><IF-STMT><tab><tab><tab>logger.debug(line[""stream""].strip())<tab><tab>elif ""status"" in line:<tab><tab><tab>logger.debug(line[""status""].strip())<tab><tab>elif ""error"" in line:<tab><tab><tab>logger.error(line[""error""].strip())<tab><tab><tab>raise DockerBuildError","if ""stream"" in line and line [ ""stream"" ] . strip ( ) :",108
2825,"def test_wildcard_import():<tab>bonobo = __import__(""bonobo"")<tab>assert bonobo.__version__<tab>for name in dir(bonobo):<tab><tab># ignore attributes starting by underscores<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>attr = getattr(bonobo, name)<tab><tab>if inspect.ismodule(attr):<tab><tab><tab>continue<tab><tab>assert name in bonobo.__all__","if name . startswith ( ""_"" ) :",97
2826,"def _coerce_to_bool(self, node, var, true_val=True):<tab>""""""Coerce the values in a variable to bools.""""""<tab>bool_var = self.program.NewVariable()<tab>for b in var.bindings:<tab><tab>v = b.data<tab><tab>if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool):<tab><tab><tab>const = v.pyval is true_val<tab><tab><IF-STMT><tab><tab><tab>const = not true_val<tab><tab>elif not compare.compatible_with(v, False):<tab><tab><tab>const = true_val<tab><tab>else:<tab><tab><tab>const = None<tab><tab>bool_var.AddBinding(self.convert.bool_values[const], {b}, node)<tab>return bool_var","elif not compare . compatible_with ( v , True ) :",192
2827,"def _parse_policies(self, policies_yaml):<tab>for item in policies_yaml:<tab><tab>id_ = required_key(item, ""id"")<tab><tab>controls_ids = required_key(item, ""controls"")<tab><tab>if not isinstance(controls_ids, list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = ""Policy {id_} contains invalid controls list {controls}."".format(<tab><tab><tab><tab><tab>id_=id_, controls=str(controls_ids)<tab><tab><tab><tab>)<tab><tab><tab><tab>raise ValueError(msg)<tab><tab>self.policies[id_] = controls_ids","if controls_ids != ""all"" :",155
2828,"def pong(self, payload: Union[str, bytes] = """") -> None:<tab>if self.trace_enabled and self.ping_pong_trace_enabled:<tab><tab><IF-STMT><tab><tab><tab>payload = payload.decode(""utf-8"")<tab><tab>self.logger.debug(<tab><tab><tab>""Sending a pong data frame ""<tab><tab><tab>f""(session id: {self.session_id}, payload: {payload})""<tab><tab>)<tab>data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PONG)<tab>with self.sock_send_lock:<tab><tab>self.sock.send(data)","if isinstance ( payload , bytes ) :",158
2829,"def _extract_curve_feature_log(arg):<tab>""""""extract sampled curve feature for log items""""""<tab>try:<tab><tab>inp, res = arg<tab><tab>config = inp.config<tab><tab>with inp.target:<tab><tab><tab>sch, args = inp.task.instantiate(config)<tab><tab>fea = feature.get_buffer_curve_sample_flatten(sch, args, sample_n=20)<tab><tab>x = np.concatenate((fea, list(config.get_other_option().values())))<tab><tab><IF-STMT><tab><tab><tab>y = inp.task.flop / np.mean(res.costs)<tab><tab>else:<tab><tab><tab>y = 0.0<tab><tab>return x, y<tab>except Exception:  # pylint: disable=broad-except<tab><tab>return None",if res . error_no == 0 :,192
2830,"def messageSourceStamps(self, source_stamps):<tab>text = """"<tab>for ss in source_stamps:<tab><tab>source = """"<tab><tab>if ss[""branch""]:<tab><tab><tab>source += ""[branch %s] "" % ss[""branch""]<tab><tab><IF-STMT><tab><tab><tab>source += str(ss[""revision""])<tab><tab>else:<tab><tab><tab>source += ""HEAD""<tab><tab>if ss[""patch""] is not None:<tab><tab><tab>source += "" (plus patch)""<tab><tab>discriminator = """"<tab><tab>if ss[""codebase""]:<tab><tab><tab>discriminator = "" '%s'"" % ss[""codebase""]<tab><tab>text += ""Build Source Stamp%s: %s\n"" % (discriminator, source)<tab>return text","if ss [ ""revision"" ] :",176
2831,"def find_repository():<tab>orig_path = path = os.path.realpath(""."")<tab>drive, path = os.path.splitdrive(path)<tab>while path:<tab><tab>current_path = os.path.join(drive, path)<tab><tab>current_repo = LocalRepository(current_path)<tab><tab>if current_repo.isValid():<tab><tab><tab>return current_repo<tab><tab>path, path_tail = os.path.split(current_path)<tab><tab><IF-STMT><tab><tab><tab>raise CannotFindRepository(""Cannot find repository for %s"" % (orig_path,))",if not path_tail :,139
2832,"def compute_indices(text: str, tokens):<tab>indices = []<tab>for i, token in enumerate(tokens):<tab><tab><IF-STMT><tab><tab><tab>current_index = indices[-1] + len(tokens[i - 1][0])<tab><tab><tab>indices.append(current_index + text[current_index:].find(token[0]))<tab><tab>else:<tab><tab><tab>indices.append(text.find(token[0]))<tab>return indices",if 1 <= i :,108
2833,"def _add_defaults_data_files(self):<tab># getting distribution.data_files<tab>if self.distribution.has_data_files():<tab><tab>for item in self.distribution.data_files:<tab><tab><tab>if isinstance(item, str):<tab><tab><tab><tab># plain file<tab><tab><tab><tab>item = convert_path(item)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.filelist.append(item)<tab><tab><tab>else:<tab><tab><tab><tab># a (dirname, filenames) tuple<tab><tab><tab><tab>dirname, filenames = item<tab><tab><tab><tab>for f in filenames:<tab><tab><tab><tab><tab>f = convert_path(f)<tab><tab><tab><tab><tab>if os.path.isfile(f):<tab><tab><tab><tab><tab><tab>self.filelist.append(f)",if os . path . isfile ( item ) :,192
2834,"def libcxx_define(settings):<tab>compiler = _base_compiler(settings)<tab>libcxx = settings.get_safe(""compiler.libcxx"")<tab>if not compiler or not libcxx:<tab><tab>return """"<tab>if str(compiler) in GCC_LIKE:<tab><tab><IF-STMT><tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=0""<tab><tab>elif str(libcxx) == ""libstdc++11"":<tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=1""<tab>return """"","if str ( libcxx ) == ""libstdc++"" :",146
2835,"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict):<tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab>elif isinstance(v, bool):<tab><tab><tab>self._populate_bool(element, k, v)<tab><tab><IF-STMT><tab><tab><tab>self._populate_str(element, k, v)<tab><tab>elif type(v) in [int, float, long, complex]:<tab><tab><tab>self._populate_number(element, k, v)","elif isinstance ( v , basestring ) :",178
2836,"def test_seek(self):<tab><IF-STMT><tab><tab>print(""create large file via seek (may be sparse file) ..."")<tab>with self.open(TESTFN, ""wb"") as f:<tab><tab>f.write(b""z"")<tab><tab>f.seek(0)<tab><tab>f.seek(size)<tab><tab>f.write(b""a"")<tab><tab>f.flush()<tab><tab>if verbose:<tab><tab><tab>print(""check file size with os.fstat"")<tab><tab>self.assertEqual(os.fstat(f.fileno())[stat.ST_SIZE], size + 1)",if verbose :,139
2837,"def serialize_review_url_field(self, obj, **kwargs):<tab>if obj.review_ui:<tab><tab>review_request = obj.get_review_request()<tab><tab><IF-STMT><tab><tab><tab>local_site_name = review_request.local_site.name<tab><tab>else:<tab><tab><tab>local_site_name = None<tab><tab>return local_site_reverse(<tab><tab><tab>""file-attachment"",<tab><tab><tab>local_site_name=local_site_name,<tab><tab><tab>kwargs={<tab><tab><tab><tab>""review_request_id"": review_request.display_id,<tab><tab><tab><tab>""file_attachment_id"": obj.pk,<tab><tab><tab>},<tab><tab>)<tab>return """"",if review_request . local_site_id :,180
2838,"def on_item_down_clicked(self, button):<tab>model = self.treeview.get_model()<tab>for s in self._get_selected():<tab><tab><IF-STMT>  # XXX need model.swap<tab><tab><tab>old = model.get_iter(s[0])<tab><tab><tab>iter = model.insert(s[0] + 2)<tab><tab><tab>for i in range(3):<tab><tab><tab><tab>model.set_value(iter, i, model.get_value(old, i))<tab><tab><tab>model.remove(old)<tab><tab><tab>self.treeview.get_selection().select_iter(iter)<tab>self._update_filter_string()",if s [ 0 ] < len ( model ) - 1 :,167
2839,"def writer(self):<tab>""""""loop forever and copy socket->serial""""""<tab>while self.alive:<tab><tab>try:<tab><tab><tab>data = self.socket.recv(1024)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.serial.write(b"""".join(self.rfc2217.filter(data)))<tab><tab>except socket.error as msg:<tab><tab><tab>self.log.error(""{}"".format(msg))<tab><tab><tab># probably got disconnected<tab><tab><tab>break<tab>self.stop()",if not data :,124
2840,"def __getitem__(self, key):<tab>if key == 1:<tab><tab>return self.get_value()<tab>elif key == 0:<tab><tab>return self.cell[0]<tab>elif isinstance(key, slice):<tab><tab>s = list(self.cell.__getitem__(key))<tab><tab><IF-STMT><tab><tab><tab>s[s.index(self.cell[1])] = self.get_value()<tab><tab>return s<tab>else:<tab><tab>raise IndexError(key)",if self . cell [ 1 ] in s :,120
2841,"def test_error_stream(environ, start_response):<tab>writer = start_response(""200 OK"", [])<tab>wsgi_errors = environ[""wsgi.errors""]<tab>error_msg = None<tab>for method in [<tab><tab>""flush"",<tab><tab>""write"",<tab><tab>""writelines"",<tab>]:<tab><tab><IF-STMT><tab><tab><tab>error_msg = ""wsgi.errors has no '%s' attr"" % method<tab><tab>if not error_msg and not callable(getattr(wsgi_errors, method)):<tab><tab><tab>error_msg = ""wsgi.errors.%s attr is not callable"" % method<tab><tab>if error_msg:<tab><tab><tab>break<tab>return_msg = error_msg or ""success""<tab>writer(return_msg)<tab>return []","if not hasattr ( wsgi_errors , method ) :",185
2842,"def job_rule_modules(app):<tab>rules_module_list = []<tab>for rules_module_name in __job_rule_module_names(app):<tab><tab>rules_module = sys.modules.get(rules_module_name, None)<tab><tab><IF-STMT><tab><tab><tab># if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first<tab><tab><tab># JobWrapper is created<tab><tab><tab>rules_module = importlib.import_module(rules_module_name)<tab><tab>rules_module_list.append(rules_module)<tab>return rules_module_list",if not rules_module :,148
2843,"def discover_hdfstore(f):<tab>d = dict()<tab>for key in f.keys():<tab><tab>d2 = d<tab><tab>key2 = key.lstrip(""/"")<tab><tab>while ""/"" in key2:<tab><tab><tab>group, key2 = key2.split(""/"", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d2[group] = dict()<tab><tab><tab>d2 = d2[group]<tab><tab>d2[key2] = f.get_storer(key)<tab>return discover(d)",if group not in d2 :,128
2844,"def test_update_zone(self):<tab>zone = self.driver.list_zones()[0]<tab>updated_zone = self.driver.update_zone(zone=zone, domain="""", extra={""paused"": True})<tab>self.assertEqual(zone.id, updated_zone.id)<tab>self.assertEqual(zone.domain, updated_zone.domain)<tab>self.assertEqual(zone.type, updated_zone.type)<tab>self.assertEqual(zone.ttl, updated_zone.ttl)<tab>for key in set(zone.extra) | set(updated_zone.extra):<tab><tab><IF-STMT><tab><tab><tab>self.assertNotEqual(zone.extra[key], updated_zone.extra[key])<tab><tab>else:<tab><tab><tab>self.assertEqual(zone.extra[key], updated_zone.extra[key])","if key in ( ""paused"" , ""modified_on"" ) :",199
2845,"def ESP(phrase):<tab>for num, name in enumerate(devname):<tab><tab><IF-STMT><tab><tab><tab>dev = devid[num]<tab><tab><tab>if custom_action_keyword[""Dict""][""On""] in phrase:<tab><tab><tab><tab>ctrl = ""=ON""<tab><tab><tab><tab>say(""Turning On "" + name)<tab><tab><tab>elif custom_action_keyword[""Dict""][""Off""] in phrase:<tab><tab><tab><tab>ctrl = ""=OFF""<tab><tab><tab><tab>say(""Turning Off "" + name)<tab><tab><tab>rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)",if name . lower ( ) in phrase :,153
2846,"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None):<tab>assert nw_id != self.nw_id_unknown<tab>ret = []<tab>for port in self.get_ports(dpid):<tab><tab>nw_id_ = port.network_id<tab><tab>if port.port_no == in_port:<tab><tab><tab>continue<tab><tab>if nw_id_ == nw_id:<tab><tab><tab>ret.append(port.port_no)<tab><tab><IF-STMT><tab><tab><tab>ret.append(port.port_no)<tab>return ret",elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,167
2847,"def tail(filename):<tab>if os.path.isfile(filename):<tab><tab>file = open(filename, ""r"")<tab><tab>st_results = os.stat(filename)<tab><tab>st_size = st_results[6]<tab><tab>file.seek(st_size)<tab><tab>while 1:<tab><tab><tab>where = file.tell()<tab><tab><tab>line = file.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>time.sleep(1)<tab><tab><tab><tab>file.seek(where)<tab><tab><tab>else:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>line,<tab><tab><tab><tab>)  # already has newline<tab>else:<tab><tab>print_error(""File not found, cannot tail."")",if not line :,172
2848,"def proc_day_of_week(d):<tab>if expanded[4][0] != ""*"":<tab><tab>diff_day_of_week = nearest_diff_method(d.isoweekday() % 7, expanded[4], 7)<tab><tab>if diff_day_of_week is not None and diff_day_of_week != 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d += relativedelta(days=diff_day_of_week, hour=23, minute=59, second=59)<tab><tab><tab>else:<tab><tab><tab><tab>d += relativedelta(days=diff_day_of_week, hour=0, minute=0, second=0)<tab><tab><tab>return True, d<tab>return False, d",if is_prev :,175
2849,"def __call__(self):<tab>""""""Run all check_* methods.""""""<tab>if self.on:<tab><tab>oldformatwarning = warnings.formatwarning<tab><tab>warnings.formatwarning = self.formatwarning<tab><tab>try:<tab><tab><tab>for name in dir(self):<tab><tab><tab><tab>if name.startswith(""check_""):<tab><tab><tab><tab><tab>method = getattr(self, name)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>method()<tab><tab>finally:<tab><tab><tab>warnings.formatwarning = oldformatwarning",if method and callable ( method ) :,127
2850,"def get(self, request, *args, **kwargs):<tab>if self.revision:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return send_file(<tab><tab><tab><tab><tab>request,<tab><tab><tab><tab><tab>self.revision.file.path,<tab><tab><tab><tab><tab>self.revision.created,<tab><tab><tab><tab><tab>self.attachment.original_filename,<tab><tab><tab><tab>)<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>return HttpResponseRedirect(self.revision.file.url)<tab>raise Http404",if settings . USE_LOCAL_PATH :,141
2851,"def _close(self):<tab>super(Recording, self)._close()<tab>if self._log_n is not None:<tab><tab>for i in range(self.n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._log_n[i].close()<tab><tab><tab><tab>self._log_n[i] = None",if self . _log_n [ i ] is not None :,88
2852,"def addTags(self, rpcObjects=None):<tab>hosts = self._getOnlyHostObjects(rpcObjects)<tab>if hosts:<tab><tab>title = ""Add Tags""<tab><tab>body = ""What tags should be added?\n\nUse a comma or space between each""<tab><tab>(tags, choice) = self.getText(title, body, """")<tab><tab><IF-STMT><tab><tab><tab>tags = str(tags).replace("" "", "","").split("","")<tab><tab><tab>for host in hosts:<tab><tab><tab><tab>self.cuebotCall(<tab><tab><tab><tab><tab>host.addTags, ""Add Tags to %s Failed"" % host.data.name, tags<tab><tab><tab><tab>)<tab><tab><tab>self._update()",if choice :,167
2853,"def available_datasets(self):<tab>""""""Automatically determine datasets provided by this file""""""<tab>res = self.resolution<tab>coordinates = [""pixel_longitude"", ""pixel_latitude""]<tab>for var_name, val in self.file_content.items():<tab><tab><IF-STMT><tab><tab><tab>ds_info = {<tab><tab><tab><tab>""file_type"": self.filetype_info[""file_type""],<tab><tab><tab><tab>""resolution"": res,<tab><tab><tab>}<tab><tab><tab>if not self.is_geo:<tab><tab><tab><tab>ds_info[""coordinates""] = coordinates<tab><tab><tab>yield DatasetID(name=var_name, resolution=res), ds_info","if isinstance ( val , netCDF4 . Variable ) :",165
2854,"def extract_from_file(fname: PathIsh) -> Iterator[Extraction]:<tab>path = Path(fname)<tab>fallback_dt = file_mtime(path)<tab>p = Parser(path)<tab>for r in p.walk():<tab><tab><IF-STMT><tab><tab><tab>yield r<tab><tab>else:<tab><tab><tab>yield Visit(<tab><tab><tab><tab>url=r.url,<tab><tab><tab><tab>dt=fallback_dt,<tab><tab><tab><tab>locator=Loc.file(fname),  # TODO line number<tab><tab><tab><tab>context=r.context,<tab><tab><tab>)","if isinstance ( r , Exception ) :",141
2855,"def init_module_config(module_json, config, config_path=default_config_path):<tab>if ""config"" in module_json[""meta""]:<tab><tab>if module_json[""meta""][""config""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config.add_section(module_json[""name""])<tab><tab><tab>for config_var in module_json[""meta""][""config""]:<tab><tab><tab><tab>if config_var not in config[module_json[""name""]]:<tab><tab><tab><tab><tab>config.set(module_json[""name""], config_var, """")<tab>return config","if module_json [ ""name"" ] not in config :",142
2856,"def _create_entities(parsed_entities, sidx, eidx):<tab>entities = []<tab>for k, vs in parsed_entities.items():<tab><tab><IF-STMT><tab><tab><tab>vs = [vs]<tab><tab>for value in vs:<tab><tab><tab>entities.append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""entity"": k,<tab><tab><tab><tab><tab>""start"": sidx,<tab><tab><tab><tab><tab>""end"": eidx,  # can't be more specific<tab><tab><tab><tab><tab>""value"": value,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>return entities","if not isinstance ( vs , list ) :",145
2857,"def _telegram_upload_stream(self, stream, **kwargs):<tab>""""""Perform upload defined in a stream.""""""<tab>msg = None<tab>try:<tab><tab>stream.accept()<tab><tab>msg = self._telegram_special_message(<tab><tab><tab>chat_id=stream.identifier.id,<tab><tab><tab>content=stream.raw,<tab><tab><tab>msg_type=stream.stream_type,<tab><tab><tab>**kwargs,<tab><tab>)<tab>except Exception:<tab><tab>log.exception(f""Upload of {stream.name} to {stream.identifier} failed."")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>stream.error()<tab><tab>else:<tab><tab><tab>stream.success()",if msg is None :,166
2858,"def readlines(self, size=-1):<tab>if self._nbr == self._size:<tab><tab>return []<tab># leave all additional logic to our readline method, we just check the size<tab>out = []<tab>nbr = 0<tab>while True:<tab><tab>line = self.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>out.append(line)<tab><tab>if size > -1:<tab><tab><tab>nbr += len(line)<tab><tab><tab>if nbr > size:<tab><tab><tab><tab>break<tab><tab># END handle size constraint<tab># END readline loop<tab>return out",if not line :,145
2859,"def clean_permissions(<tab>cls,<tab>requestor: ""User"",<tab>group: auth_models.Group,<tab>errors: Dict[Optional[str], List[ValidationError]],<tab>cleaned_input: dict,):<tab>field = ""add_permissions""<tab>permission_items = cleaned_input.get(field)<tab>if permission_items:<tab><tab>cleaned_input[field] = get_permissions(permission_items)<tab><tab><IF-STMT><tab><tab><tab>cls.ensure_can_manage_permissions(<tab><tab><tab><tab>requestor, errors, field, permission_items<tab><tab><tab>)",if not requestor . is_superuser :,142
2860,"def _bwd(subj=None, obj=None, seen=None):<tab>seen.add(obj)<tab>for s, o in evalPath(graph, (None, self.path, obj)):<tab><tab><IF-STMT><tab><tab><tab>yield s, o<tab><tab>if self.more:<tab><tab><tab>if s in seen:<tab><tab><tab><tab>continue<tab><tab><tab>for s2, o2 in _bwd(None, s, seen):<tab><tab><tab><tab>yield s2, o",if not subj or subj == s :,120
2861,"def generate_data(self, request):<tab>""""""Generate data for the widget.""""""<tab>uptime = {}<tab>cache_stats = get_cache_stats()<tab>if cache_stats:<tab><tab>for hosts, stats in cache_stats:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60 / 24<tab><tab><tab><tab>uptime[""unit""] = _(""days"")<tab><tab><tab>elif stats[""uptime""] > 3600:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60<tab><tab><tab><tab>uptime[""unit""] = _(""hours"")<tab><tab><tab>else:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60<tab><tab><tab><tab>uptime[""unit""] = _(""minutes"")<tab>return {""cache_stats"": cache_stats, ""uptime"": uptime}","if stats [ ""uptime"" ] > 86400 :",195
2862,def refresh(self):<tab>if self._handle:<tab><tab>source = self._db.get_repository_from_handle(self._handle)<tab><tab><IF-STMT><tab><tab><tab>self._title = str(source.get_type())<tab><tab><tab>self._value = source.get_name(),if source :,70
2863,"def _gridconvvalue(self, value):<tab>if isinstance(value, (str, _tkinter.Tcl_Obj)):<tab><tab>try:<tab><tab><tab>svalue = str(value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>elif ""."" in svalue:<tab><tab><tab><tab>return getdouble(svalue)<tab><tab><tab>else:<tab><tab><tab><tab>return getint(svalue)<tab><tab>except ValueError:<tab><tab><tab>pass<tab>return value",if not svalue :,116
2864,"def parseGrants(self, tree):<tab>for grant in tree.findall("".//Grant""):<tab><tab>grantee = Grantee()<tab><tab>g = grant.find("".//Grantee"")<tab><tab>grantee.xsi_type = g.attrib[""{http://www.w3.org/2001/XMLSchema-instance}type""]<tab><tab>grantee.permission = grant.find(""Permission"").text<tab><tab>for el in g:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>grantee.display_name = el.text<tab><tab><tab>else:<tab><tab><tab><tab>grantee.tag = el.tag<tab><tab><tab><tab>grantee.name = el.text<tab><tab>self.grantees.append(grantee)","if el . tag == ""DisplayName"" :",188
2865,"def __init__(self, name: Optional[str] = None, order: int = 0):<tab>if name is None:<tab><tab>if order == 0:<tab><tab><tab>name = ""std_dev""<tab><tab><IF-STMT><tab><tab><tab>name = ""sample_std_dev""<tab><tab>else:<tab><tab><tab>name = f""std_dev{order})""<tab>super().__init__(name=name, order=order)<tab>self.order = order",elif order == 1 :,109
2866,"def _shouldRollover(self):<tab>if self.maxBytes > 0:  # are we rolling over?<tab><tab>try:<tab><tab><tab>self.stream.seek(0, 2)  # due to non-posix-compliant Windows feature<tab><tab>except IOError:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>self._degrade(False, ""Rotation done or not needed at this time"")<tab>return False",if self . stream . tell ( ) >= self . maxBytes :,124
2867,"def userfullname():<tab>""""""Get the user's full name.""""""<tab>global _userfullname<tab>if not _userfullname:<tab><tab>uid = os.getuid()<tab><tab>entry = pwd_from_uid(uid)<tab><tab><IF-STMT><tab><tab><tab>_userfullname = entry[4].split("","")[0] or entry[0]<tab><tab>if not _userfullname:<tab><tab><tab>_userfullname = ""user%d"" % uid<tab>return _userfullname",if entry :,108
2868,"def drop(self):<tab># mssql<tab>sql = ""if object_id('%s') is not null drop table %s"" % (self.tname, self.tname)<tab>try:<tab><tab>self.execute(sql)<tab>except Exception as e:<tab><tab>self.conn.rollback()<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab># sqlite<tab><tab>sql = ""drop table if exists %s"" % self.tname<tab><tab>self.execute(sql)","if ""syntax error"" not in str ( e ) :",124
2869,"def _find_delimiter(f, block_size=2 ** 16):<tab>delimiter = b""\n""<tab>if f.tell() == 0:<tab><tab>return 0<tab>while True:<tab><tab>b = f.read(block_size)<tab><tab><IF-STMT><tab><tab><tab>return f.tell()<tab><tab>elif delimiter in b:<tab><tab><tab>return f.tell() - len(b) + b.index(delimiter) + 1",if not b :,105
2870,"def _convert(container):<tab>if _value_marker in container:<tab><tab>force_list = False<tab><tab>values = container.pop(_value_marker)<tab><tab><IF-STMT><tab><tab><tab>force_list = True<tab><tab><tab>values.extend(_convert(x[1]) for x in sorted(container.items()))<tab><tab>if not force_list and len(values) == 1:<tab><tab><tab>values = values[0]<tab><tab>if not container:<tab><tab><tab>return values<tab><tab>return _convert(container)<tab>elif container.pop(_list_marker, False):<tab><tab>return [_convert(x[1]) for x in sorted(container.items())]<tab>return dict_cls((k, _convert(v)) for k, v in iteritems(container))","if container . pop ( _list_marker , False ) :",188
2871,"def fitting(self, value):<tab>self._fitting = value<tab>if self._fitting is not None:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.makedirs(dirname(self.checkpoint_path()))<tab><tab><tab>except FileExistsError as ex:<tab><tab><tab><tab>pass  # race to create<tab><tab>if not os.path.exists(dirname(self.tensorboard_path())):<tab><tab><tab>try:<tab><tab><tab><tab>os.makedirs(dirname(self.tensorboard_path()))<tab><tab><tab>except FileExistsError as ex:<tab><tab><tab><tab>pass  # race to create",if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,149
2872,"def _make_headers(self):<tab>libraries = self._df.columns.to_list()<tab>columns = []<tab>for library in libraries:<tab><tab>version = self._package_versions[library]<tab><tab>library_description = self._libraries_description.get(library)<tab><tab><IF-STMT><tab><tab><tab>library += "" {}"".format(library_description)<tab><tab>columns.append(<tab><tab><tab>""{library}<br><small>{version}</small>"".format(<tab><tab><tab><tab>library=library, version=version<tab><tab><tab>)<tab><tab>)<tab>return [""""] + columns",if library_description :,138
2873,"def plugin_on_song_ended(self, song, stopped):<tab>if song is not None:<tab><tab>poll = self.rating_box.poll_vote()<tab><tab><IF-STMT><tab><tab><tab>ups = int(song.get(""~#wins"") or 0)<tab><tab><tab>downs = int(song.get(""~#losses"") or 0)<tab><tab><tab>ups += poll[0]<tab><tab><tab>downs += poll[1]<tab><tab><tab>song[""~#wins""] = ups<tab><tab><tab>song[""~#losses""] = downs<tab><tab><tab>song[""~#rating""] = ups / max((ups + downs), 2)<tab><tab><tab># note: ^^^ Look into implementing w/ confidence intervals!<tab><tab><tab>song[""~#score""] = ups - downs",if poll [ 0 ] >= 1 or poll [ 1 ] >= 1 :,196
2874,"def submit(self, pig_script, params):<tab>workflow = None<tab>try:<tab><tab>workflow = self._create_workflow(pig_script, params)<tab><tab>mapping = dict(<tab><tab><tab>[(param[""name""], param[""value""]) for param in workflow.get_parameters()]<tab><tab>)<tab><tab>oozie_wf = _submit_workflow(self.user, self.fs, self.jt, workflow, mapping)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>workflow.delete(skip_trash=True)<tab>return oozie_wf",if workflow :,131
2875,"def test_parse(self):<tab>correct = 0<tab>for example in EXAMPLES:<tab><tab>try:<tab><tab><tab>schema.parse(example.schema_string)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Invalid schema was parsed: "" + example.schema_string)<tab><tab>except:<tab><tab><tab>if not example.valid:<tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Valid schema failed to parse: "" + example.schema_string)<tab>fail_msg = ""Parse behavior correct on %d out of %d schemas."" % (<tab><tab>correct,<tab><tab>len(EXAMPLES),<tab>)<tab>self.assertEqual(correct, len(EXAMPLES), fail_msg)",if example . valid :,188
2876,"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab>if child.tag in (""wf"", ""punc""):<tab><tab><tab>itm = self.handle_word(child)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sent.extend(itm)<tab><tab><tab>else:<tab><tab><tab><tab>sent.append(itm)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return SemcorSentence(elt.attrib[""snum""], sent)","if self . _unit == ""word"" :",126
2877,"def _set_property(self, target_widget, pname, value):<tab>if pname == ""text"":<tab><tab>state = target_widget.cget(""state"")<tab><tab><IF-STMT><tab><tab><tab>target_widget.configure(state=tk.NORMAL)<tab><tab><tab>target_widget.insert(""0.0"", value)<tab><tab><tab>target_widget.configure(state=tk.DISABLED)<tab><tab>else:<tab><tab><tab>target_widget.insert(""0.0"", value)<tab>else:<tab><tab>super(TKText, self)._set_property(target_widget, pname, value)",if state == tk . DISABLED :,145
2878,"def get_vrf_tables(self, vrf_rf=None):<tab>vrf_tables = {}<tab>for (scope_id, table_id), table in self._tables.items():<tab><tab>if scope_id is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>vrf_tables[(scope_id, table_id)] = table<tab>return vrf_tables",if vrf_rf is not None and table_id != vrf_rf :,112
2879,"def new_f(self, *args, **kwargs):<tab>for obj in f(self, *args, **kwargs):<tab><tab>if self.protected == False:<tab><tab><tab>if ""user"" in obj and obj[""user""][""protected""]:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield obj","elif ""protected"" in obj and obj [ ""protected"" ] :",88
2880,"def draw(self, context):<tab>col = self.layout.column()<tab>col.operator(""node.sv_show_latest_commits"")<tab>if context.scene.sv_new_version:<tab><tab>col_alert = self.layout.column()<tab><tab>col_alert.alert = True<tab><tab>col_alert.operator(""node.sverchok_update_addon"", text=""Upgrade Sverchok addon"")<tab>else:<tab><tab>col.operator(""node.sverchok_check_for_upgrades_wsha"", text=""Check for updates"")<tab>with sv_preferences() as prefs:<tab><tab><IF-STMT><tab><tab><tab>col.operator(""node.sv_run_pydoc"")",if prefs . developer_mode :,173
2881,"def generate_tag_1_data(ids):<tab>if len(ids) != SAMPLE_NUM:<tab><tab>raise ValueError(""len ids should equal to sample number"")<tab>counter = 0<tab>for sample_i in range(SAMPLE_NUM):<tab><tab>one_data = [ids[sample_i]]<tab><tab>valid_set = [x for x in range(TAG_INTERVAL[0], TAG_INTERVAL[1])]<tab><tab>features = np.random.choice(valid_set, FEATURE_NUM, replace=False)<tab><tab>one_data += ["":"".join([x, ""1.0""]) for x in features]<tab><tab>counter += 1<tab><tab><IF-STMT><tab><tab><tab>print(""generate data {}"".format(counter))<tab><tab>yield one_data",if counter % 10000 == 0 :,179
2882,"def handle_api_languages(self, http_context):<tab>mgr = PluginManager.get(aj.context)<tab>languages = set()<tab>for id in mgr:<tab><tab>locale_dir = mgr.get_content_path(id, ""locale"")<tab><tab><IF-STMT><tab><tab><tab>for lang in os.listdir(locale_dir):<tab><tab><tab><tab>if lang != ""app.pot"":<tab><tab><tab><tab><tab>languages.add(lang)<tab>return sorted(list(languages))",if os . path . isdir ( locale_dir ) :,125
2883,"def update(self, t):<tab># direction right - up<tab>for i in range(self.grid.x):<tab><tab>for j in range(self.grid.y):<tab><tab><tab>distance = self.test_func(i, j, t)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.turn_off_tile(i, j)<tab><tab><tab>elif distance < 1:<tab><tab><tab><tab>self.transform_tile(i, j, distance)<tab><tab><tab>else:<tab><tab><tab><tab>self.turn_on_tile(i, j)",if distance == 0 :,135
2884,"def _handle_autocomplete_request_for_text(text):<tab>if not hasattr(text, ""autocompleter""):<tab><tab>if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text():<tab><tab><tab>if isinstance(text, CodeViewText):<tab><tab><tab><tab>text.autocompleter = Completer(text)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text.autocompleter = ShellCompleter(text)<tab><tab><tab>text.bind(""<1>"", text.autocompleter.on_text_click)<tab><tab>else:<tab><tab><tab>return<tab>text.autocompleter.handle_autocomplete_request()","elif isinstance ( text , ShellText ) :",151
2885,"def test_create_repository(repo_name, expected_status, client):<tab>with client_with_identity(""devtable"", client) as cl:<tab><tab>body = {<tab><tab><tab>""namespace"": ""devtable"",<tab><tab><tab>""repository"": repo_name,<tab><tab><tab>""visibility"": ""public"",<tab><tab><tab>""description"": ""foo"",<tab><tab>}<tab><tab>result = conduct_api_call(<tab><tab><tab>client, RepositoryList, ""post"", None, body, expected_code=expected_status<tab><tab>).json<tab><tab><IF-STMT><tab><tab><tab>assert result[""name""] == repo_name<tab><tab><tab>assert (<tab><tab><tab><tab>model.repository.get_repository(""devtable"", repo_name).name == repo_name<tab><tab><tab>)",if expected_status == 201 :,186
2886,"def _apply_filter(filter_item, filter_list):<tab>for filter_method in filter_list:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>except Exception as e:<tab><tab><tab>raise MessageException(<tab><tab><tab><tab>""Toolbox filter exception from '{}': {}."".format(<tab><tab><tab><tab><tab>filter_method.__name__, unicodify(e)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return True","if not filter_method ( context , filter_item ) :",116
2887,"def printsumfp(fp, filename, out=sys.stdout):<tab>m = md5()<tab>try:<tab><tab>while 1:<tab><tab><tab>data = fp.read(bufsize)<tab><tab><tab>if not data:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = data.encode(fp.encoding)<tab><tab><tab>m.update(data)<tab>except IOError as msg:<tab><tab>sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg))<tab><tab>return 1<tab>out.write(""%s %s\n"" % (m.hexdigest(), filename))<tab>return 0","if isinstance ( data , str ) :",159
2888,"def get_block_loc_keys(block):<tab>""""""Extract loc_keys used by @block""""""<tab>symbols = set()<tab>for instr in block.lines:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(instr.raw, list):<tab><tab><tab><tab>for expr in instr.raw:<tab><tab><tab><tab><tab>symbols.update(get_expr_locs(expr))<tab><tab>else:<tab><tab><tab>for arg in instr.args:<tab><tab><tab><tab>symbols.update(get_expr_locs(arg))<tab>return symbols","if isinstance ( instr , AsmRaw ) :",131
2889,"def get_operations(cls, info, operations: List[ProductAttributeAssignInput]):<tab>""""""Resolve all passed global ids into integer PKs of the Attribute type.""""""<tab>product_attrs_pks = []<tab>variant_attrs_pks = []<tab>for operation in operations:<tab><tab>pk = from_global_id_strict_type(<tab><tab><tab>operation.id, only_type=Attribute, field=""operations""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>product_attrs_pks.append(pk)<tab><tab>else:<tab><tab><tab>variant_attrs_pks.append(pk)<tab>return product_attrs_pks, variant_attrs_pks",if operation . type == ProductAttributeType . PRODUCT :,156
2890,"def _collect_manual_intervention_nodes(pipeline_tree):<tab>for act in pipeline_tree[""activities""].values():<tab><tab>if act[""type""] == ""SubProcess"":<tab><tab><tab>_collect_manual_intervention_nodes(act[""pipeline""])<tab><tab><IF-STMT><tab><tab><tab>manual_intervention_nodes.add(act[""id""])","elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :",105
2891,"def prompt_authorization(self, stacks: List[Stack]):<tab>auth_required_per_resource = auth_per_resource(stacks)<tab>for resource, authorization_required in auth_required_per_resource:<tab><tab><IF-STMT><tab><tab><tab>auth_confirm = confirm(<tab><tab><tab><tab>f""\t{self.start_bold}{resource} may not have authorization defined, Is this okay?{self.end_bold}"",<tab><tab><tab><tab>default=False,<tab><tab><tab>)<tab><tab><tab>if not auth_confirm:<tab><tab><tab><tab>raise GuidedDeployFailedError(msg=""Security Constraints Not Satisfied!"")",if not authorization_required :,148
2892,"def get_cloud_credential(self):<tab>""""""Return the credential which is directly tied to the inventory source type.""""""<tab>credential = None<tab>for cred in self.credentials.all():<tab><tab>if self.source in CLOUD_PROVIDERS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># these need to be returned in the API credential field<tab><tab><tab>if cred.credential_type.kind != ""vault"":<tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab>return credential","if cred . kind == self . source . replace ( ""ec2"" , ""aws"" ) :",149
2893,"def validate_party_details(self):<tab>if self.party:<tab><tab>if not frappe.db.exists(self.party_type, self.party):<tab><tab><tab>frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party))<tab><tab><IF-STMT><tab><tab><tab>self.validate_account_type(<tab><tab><tab><tab>self.party_account, [erpnext.get_party_account_type(self.party_type)]<tab><tab><tab>)","if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",140
2894,"def __iter__(self):<tab>it = DiskHashMerger.__iter__(self)<tab>direct_upstreams = self.direct_upstreams<tab>for k, groups in it:<tab><tab>t = list([[] for _ in range(self.size)])<tab><tab>for i, g in enumerate(groups):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if i in direct_upstreams:<tab><tab><tab><tab><tab>t[i] = g<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>g.sort(key=itemgetter(0))<tab><tab><tab><tab><tab>g1 = []<tab><tab><tab><tab><tab>for _, vs in g:<tab><tab><tab><tab><tab><tab>g1.extend(vs)<tab><tab><tab><tab><tab>t[i] = g1<tab><tab>yield k, tuple(t)",if g :,185
2895,"def _unpack_scales(scales, vidxs):<tab>scaleData = [None, None, None]<tab>for i in range(3):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>scale = scales[i]<tab><tab>if not math.isnan(scale):<tab><tab><tab>vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1]<tab><tab><tab>scaleData[i] = (int(vidx1), int(vidx2), float(scale))<tab>return scaleData","if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",138
2896,"def _make_ext_obj(self, obj):<tab>ext = self._get_ext_class(obj.objname)()<tab>for name, val in obj.body:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Error val should be a list, this is a python-opcua bug"",<tab><tab><tab><tab>name,<tab><tab><tab><tab>type(val),<tab><tab><tab><tab>val,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>for attname, v in val:<tab><tab><tab><tab>self._set_attr(ext, attname, v)<tab>return ext","if not isinstance ( val , list ) :",148
2897,"def insertLine(self, refnum, linenum, line):<tab>i = -1<tab>for i, row in enumerate(self.rows):<tab><tab>if row[0] == linenum:<tab><tab><tab>if row[refnum + 1] is None:<tab><tab><tab><tab>row[refnum + 1] = line<tab><tab><tab><tab>return<tab><tab><tab># else keep looking<tab><tab><IF-STMT><tab><tab><tab>break<tab>self.rows.insert(i, self.newRow(linenum, refnum, line))",elif row [ 0 ] > linenum :,125
2898,"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab>if strip_delimiters:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield line","if "","" in line or "";"" in line :",145
2899,"def encodingChanged(self, idx):<tab>encoding = str(self.mode_combo.currentText())<tab>validator = None<tab>if encoding == ""hex"":<tab><tab># only clear the box if there are non-hex chars<tab><tab># before setting the validator.<tab><tab>txt = str(self.data_edit.text())<tab><tab><IF-STMT><tab><tab><tab>self.data_edit.setText("""")<tab><tab>regex = QtCore.QRegExp(""^[0-9A-Fa-f]+$"")<tab><tab>validator = QtGui.QRegExpValidator(regex)<tab>self.data_edit.setValidator(validator)<tab>self.renderMemory()",if not all ( c in string . hexdigits for c in txt ) :,164
2900,"def _compare_single_run(self, compares_done):<tab>try:<tab><tab>compare_id, redo = self.in_queue.get(<tab><tab><tab>timeout=float(self.config[""ExpertSettings""][""block_delay""])<tab><tab>)<tab>except Empty:<tab><tab>pass<tab>else:<tab><tab>if self._decide_whether_to_process(compare_id, redo, compares_done):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.db_interface.delete_old_compare_result(compare_id)<tab><tab><tab>compares_done.add(compare_id)<tab><tab><tab>self._process_compare(compare_id)<tab><tab><tab>if self.callback:<tab><tab><tab><tab>self.callback()",if redo :,177
2901,"def _transform_bin(self, X: DataFrame):<tab>if self._bin_map:<tab><tab><IF-STMT><tab><tab><tab>X = X.copy(deep=True)<tab><tab>with pd.option_context(""mode.chained_assignment"", None):<tab><tab><tab># Pandas complains about SettingWithCopyWarning, but this should be valid.<tab><tab><tab>for column in self._bin_map:<tab><tab><tab><tab>X[column] = binning.bin_column(<tab><tab><tab><tab><tab>series=X[column],<tab><tab><tab><tab><tab>mapping=self._bin_map[column],<tab><tab><tab><tab><tab>dtype=self._astype_map[column],<tab><tab><tab><tab>)<tab>return X",if not self . inplace :,166
2902,"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text","if ""'"" in text :",170
2903,"def read(self):<tab>""""""Reads the robots.txt URL and feeds it to the parser.""""""<tab>try:<tab><tab>f = urllib.request.urlopen(self.url)<tab>except urllib.error.HTTPError as err:<tab><tab><IF-STMT><tab><tab><tab>self.disallow_all = True<tab><tab>elif err.code >= 400 and err.code < 500:<tab><tab><tab>self.allow_all = True<tab>else:<tab><tab>raw = f.read()<tab><tab>self.parse(raw.decode(""utf-8"").splitlines())","if err . code in ( 401 , 403 ) :",134
2904,"def post_create(self, user, billing=None):<tab>from weblate.trans.models import Change<tab>if billing:<tab><tab>billing.projects.add(self)<tab><tab><IF-STMT><tab><tab><tab>self.access_control = Project.ACCESS_PRIVATE<tab><tab>else:<tab><tab><tab>self.access_control = Project.ACCESS_PUBLIC<tab><tab>self.save()<tab>if not user.is_superuser:<tab><tab>self.add_user(user, ""@Administration"")<tab>Change.objects.create(<tab><tab>action=Change.ACTION_CREATE_PROJECT, project=self, user=user, author=user<tab>)",if billing . plan . change_access_control :,158
2905,"def visitConst(self, node):<tab>if self.documentable:<tab><tab><IF-STMT><tab><tab><tab>self.documentable.append(make_docstring(node.value, node.lineno))<tab><tab>else:<tab><tab><tab>self.documentable = None","if type ( node . value ) in ( StringType , UnicodeType ) :",73
2906,"def requires(self):<tab>requires = copy.deepcopy(self._requires)<tab># Auto add dependencies when parameters reference the Ouptuts of<tab># another stack.<tab>parameters = self.parameters<tab>for value in parameters.values():<tab><tab>if isinstance(value, basestring) and ""::"" in value:<tab><tab><tab>stack_name, _ = value.split(""::"")<tab><tab>else:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>requires.add(stack_name)<tab>return requires",if stack_name not in requires :,123
2907,"def __load_protos():<tab>g = globals()<tab>for k, v in g.items():<tab><tab><IF-STMT><tab><tab><tab>name = k[4:]<tab><tab><tab>modname = name.lower()<tab><tab><tab>try:<tab><tab><tab><tab>mod = __import__(modname, g, level=1)<tab><tab><tab><tab>PPP.set_p(v, getattr(mod, name))<tab><tab><tab>except (ImportError, AttributeError):<tab><tab><tab><tab>continue","if k . startswith ( ""PPP_"" ) :",115
2908,"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for m in self.predict_layers.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>kaiming_init(m)<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>constant_init(m, 1)<tab><tab><IF-STMT><tab><tab><tab>normal_init(m, std=0.01)","elif isinstance ( m , nn . Linear ) :",107
2909,"def get_data(self):<tab>""""""get all data from sockets""""""<tab>si = self.inputs<tab>parameters = []<tab>for socket in si:<tab><tab><IF-STMT><tab><tab><tab>parameters.append(socket.sv_get())<tab><tab>else:<tab><tab><tab>parameters.append(socket.sv_get(default=[[]]))<tab>return match_long_repeat(parameters)",if len ( socket . prop_name ) > 0 :,98
2910,"def test_parse_query_params_comparable_field(self):<tab>query_params = {""filter[int_field][gt]"": 42, ""filter[int_field][lte]"": 9000}<tab>fields = self.view.parse_query_params(query_params)<tab>for key, field_name in fields.items():<tab><tab>if field_name[""int_field""][""op""] == ""gt"":<tab><tab><tab>assert_equal(field_name[""int_field""][""value""], 42)<tab><tab><IF-STMT><tab><tab><tab>assert_equal(field_name[""int_field""][""value""], 9000)<tab><tab>else:<tab><tab><tab>self.fail()","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :",168
2911,"def _create_examples(self, lines, set_type):<tab>""""""Creates examples for the training and dev sets.""""""<tab>examples = []<tab>for (i, line) in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>guid = ""%s-%s"" % (set_type, i)<tab><tab>text = line[0]<tab><tab>bbox = line[1]<tab><tab>label = line[2]<tab><tab>examples.append(<tab><tab><tab>DocExample(guid=guid, text_a=text, text_b=None, bbox=bbox, label=label)<tab><tab>)<tab>return examples",if i == 0 :,149
2912,"def _get_attr(sdk_path, mod_attr_path, checked=True):<tab>try:<tab><tab>attr_mod, attr_path = (<tab><tab><tab>mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """")<tab><tab>)<tab><tab>full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path<tab><tab>op = import_module(full_mod_path)<tab><tab><IF-STMT><tab><tab><tab># Only load attributes if needed<tab><tab><tab>for part in attr_path.split("".""):<tab><tab><tab><tab>op = getattr(op, part)<tab><tab>return op<tab>except (ImportError, AttributeError) as ex:<tab><tab>if checked:<tab><tab><tab>return None<tab><tab>raise ex",if attr_path :,191
2913,"def _load_ui_modules(self, modules: Any) -> None:<tab>if isinstance(modules, types.ModuleType):<tab><tab>self._load_ui_modules(dict((n, getattr(modules, n)) for n in dir(modules)))<tab>elif isinstance(modules, list):<tab><tab>for m in modules:<tab><tab><tab>self._load_ui_modules(m)<tab>else:<tab><tab>assert isinstance(modules, dict)<tab><tab>for name, cls in modules.items():<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.ui_modules[name] = cls<tab><tab><tab>except TypeError:<tab><tab><tab><tab>pass","if issubclass ( cls , UIModule ) :",162
2914,"def _remove_obsolete_leafs(input_dict):<tab>if not isinstance(input_dict, dict):<tab><tab>return<tab>if input_dict[LEAF_MARKER]:<tab><tab>bottom_leafs = input_dict[LEAF_MARKER]<tab><tab>for leaf in bottom_leafs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>input_dict[LEAF_MARKER].remove(leaf)<tab>for subtree in input_dict.keys():<tab><tab>_remove_obsolete_leafs(input_dict[subtree])",if leaf in input_dict :,124
2915,"def decode(self, value, force=False):<tab>""Return a unicode string from the bytes-like representation""<tab>if self.decode_responses or force:<tab><tab><IF-STMT><tab><tab><tab>value = value.tobytes()<tab><tab>if isinstance(value, bytes):<tab><tab><tab>value = value.decode(self.encoding, self.encoding_errors)<tab>return value","if isinstance ( value , memoryview ) :",91
2916,"def audit(self, directive):<tab>value = _get_value(directive)<tab>if not value:<tab><tab>return<tab>server_side = directive.name.startswith(""proxy_"")<tab>for var in compile_script(value):<tab><tab>char = """"<tab><tab><IF-STMT><tab><tab><tab>char = ""\\n""<tab><tab>elif not server_side and var.can_contain(""\r""):<tab><tab><tab>char = ""\\r""<tab><tab>else:<tab><tab><tab>continue<tab><tab>reason = 'At least variable ""${var}"" can contain ""{char}""'.format(<tab><tab><tab>var=var.name, char=char<tab><tab>)<tab><tab>self.add_issue(directive=[directive] + var.providers, reason=reason)","if var . can_contain ( ""\n"" ) :",176
2917,"def checkFilename(filename):  # useful in case of drag and drop<tab>while True:<tab><tab>if filename[0] == ""'"":<tab><tab><tab>filename = filename[1:]<tab><tab><IF-STMT><tab><tab><tab>filename = filename[:-1]<tab><tab>if os.path.exists(filename):<tab><tab><tab>return filename<tab><tab>filename = input(<tab><tab><tab>""[!] Cannot find '%s'.\n[*] Enter a valid name of the file containing the paths to test -> ""<tab><tab><tab>% filename<tab><tab>)","if filename [ len ( filename ) - 1 ] == ""'"" :",130
2918,"def findfiles(self, dir, base, rec):<tab>try:<tab><tab>names = os.listdir(dir or os.curdir)<tab>except os.error as msg:<tab><tab>print(msg)<tab><tab>return []<tab>list = []<tab>subdirs = []<tab>for name in names:<tab><tab>fn = os.path.join(dir, name)<tab><tab><IF-STMT><tab><tab><tab>subdirs.append(fn)<tab><tab>else:<tab><tab><tab>if fnmatch.fnmatch(name, base):<tab><tab><tab><tab>list.append(fn)<tab>if rec:<tab><tab>for subdir in subdirs:<tab><tab><tab>list.extend(self.findfiles(subdir, base, rec))<tab>return list",if os . path . isdir ( fn ) :,174
2919,"def loop(handler, obj):<tab>handler.response.write(""<table>"")<tab>for k, v in obj.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>style = ""color: red"" if not v else """"<tab><tab><tab>handler.response.write(<tab><tab><tab><tab>'<tr style=""{}""><td>{}:</td><td>{}</td></tr>'.format(style, k, v)<tab><tab><tab>)<tab>handler.response.write(""</table>"")","if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :",127
2920,"def anypython(request):<tab>name = request.param<tab>executable = getexecutable(name)<tab>if executable is None:<tab><tab>if sys.platform == ""win32"":<tab><tab><tab>executable = winpymap.get(name, None)<tab><tab><tab>if executable:<tab><tab><tab><tab>executable = py.path.local(executable)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return executable<tab><tab>pytest.skip(""no suitable %s found"" % (name,))<tab>return executable",if executable . check ( ) :,119
2921,"def __init__(self, socketpath=None):<tab>if socketpath is None:<tab><tab><IF-STMT><tab><tab><tab>socketpath = ""/var/run/usbmuxd""<tab><tab>else:<tab><tab><tab>socketpath = ""/var/run/usbmuxd""<tab>self.socketpath = socketpath<tab>self.listener = MuxConnection(socketpath, BinaryProtocol)<tab>try:<tab><tab>self.listener.listen()<tab><tab>self.version = 0<tab><tab>self.protoclass = BinaryProtocol<tab>except MuxVersionError:<tab><tab>self.listener = MuxConnection(socketpath, PlistProtocol)<tab><tab>self.listener.listen()<tab><tab>self.protoclass = PlistProtocol<tab><tab>self.version = 1<tab>self.devices = self.listener.devices","if sys . platform == ""darwin"" :",194
2922,"def _validate_distinct_on_different_types_and_field_orders(<tab>self, collection, query, expected_results, get_mock_result):<tab>self.count = 0<tab>self.get_mock_result = get_mock_result<tab>query_iterable = collection.query_items(query, enable_cross_partition_query=True)<tab>results = list(query_iterable)<tab>for i in range(len(expected_results)):<tab><tab><IF-STMT><tab><tab><tab>self.assertDictEqual(results[i], expected_results[i])<tab><tab>elif isinstance(results[i], list):<tab><tab><tab>self.assertListEqual(results[i], expected_results[i])<tab><tab>else:<tab><tab><tab>self.assertEqual(results[i], expected_results[i])<tab>self.count = 0","if isinstance ( results [ i ] , dict ) :",196
2923,"def getRootId(self, id):<tab>with self.connect() as cu:<tab><tab>while True:<tab><tab><tab>stmt = ""select parent_path_id from hierarchy where path_id = ?""<tab><tab><tab>cu.execute(stmt, (id,))<tab><tab><tab>parent_id = cu.fetchone()[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return id<tab><tab><tab>id = parent_id",if parent_id is None or parent_id == id :,109
2924,"def add(self, path):<tab>with self.get_lock(path):<tab><tab><IF-STMT><tab><tab><tab>self.entries[path] = {}<tab><tab><tab>self.entries[path][""lock""] = self.new_locks[path]<tab><tab><tab>del self.new_locks[path]<tab><tab><tab>self.lru.append(path)",if not path in self . entries :,88
2925,"def _get_coordinates_for_dataset_key(self, dsid):<tab>""""""Get the coordinate dataset keys for *dsid*.""""""<tab>ds_info = self.ids[dsid]<tab>cids = []<tab>for cinfo in ds_info.get(""coordinates"", []):<tab><tab>if not isinstance(cinfo, dict):<tab><tab><tab>cinfo = {""name"": cinfo}<tab><tab>cinfo[""resolution""] = ds_info[""resolution""]<tab><tab><IF-STMT><tab><tab><tab>cinfo[""polarization""] = ds_info[""polarization""]<tab><tab>cid = DatasetID(**cinfo)<tab><tab>cids.append(self.get_dataset_key(cid))<tab>return cids","if ""polarization"" in ds_info :",170
2926,"def build_from_gdobj(cls, gdobj, steal=False):<tab># Avoid calling cls.__init__ by first instanciating a placeholder, then<tab># overloading it __class__ to turn it into an instance of the right class<tab>ret = BuiltinInitPlaceholder()<tab>if steal:<tab><tab>assert ffi.typeof(gdobj).kind == ""pointer""<tab><tab>ret._gd_ptr = gdobj<tab>else:<tab><tab><IF-STMT><tab><tab><tab>ret._gd_ptr = cls._copy_gdobj(gdobj)<tab><tab>else:<tab><tab><tab>ret._gd_ptr = cls._copy_gdobj(ffi.addressof(gdobj))<tab>ret.__class__ = cls<tab>return ret","if ffi . typeof ( gdobj ) . kind == ""pointer"" :",182
2927,"def _listen_output(self):<tab>""NB! works in background thread""<tab>try:<tab><tab>while True:<tab><tab><tab>chars = self._proc.read(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>as_bytes = chars.encode(self.encoding)<tab><tab><tab><tab>self._make_output_available(as_bytes)<tab><tab><tab>else:<tab><tab><tab><tab>self._error = ""EOF""<tab><tab><tab><tab>break<tab>except Exception as e:<tab><tab>self._error = str(e)",if len ( chars ) > 0 :,131
2928,"def result(<tab>metrics: Dict[metric_types.MetricKey, Any]) -> Dict[metric_types.AttributionsKey, Dict[Text, Union[float, np.ndarray]]]:<tab>""""""Returns mean attributions.""""""<tab>total_attributions = metrics[total_attributions_key]<tab>weighted_count = metrics[weighted_example_count_key]<tab>attributions = {}<tab>for k, v in total_attributions.items():<tab><tab><IF-STMT><tab><tab><tab>attributions[k] = float(""nan"")<tab><tab>else:<tab><tab><tab>attributions[k] = v / weighted_count<tab>return {key: attributions}","if np . isclose ( weighted_count , 0.0 ) :",162
2929,"def write_if_changed(path, data):<tab>if isinstance(data, str):<tab><tab>data = data.encode()<tab>changed = False<tab>with open(os.open(path, os.O_CREAT | os.O_RDWR), ""wb+"") as f:<tab><tab>f.seek(0)<tab><tab>current = f.read()<tab><tab><IF-STMT><tab><tab><tab>changed = True<tab><tab><tab>f.seek(0)<tab><tab><tab>f.write(data)<tab><tab><tab>f.truncate()<tab><tab>os.fsync(f)<tab>return changed",if current != data :,138
2930,"def detect_ssl_option(self):<tab>for option in self.ssl_options():<tab><tab>if scan_argv(self.argv, option) is not None:<tab><tab><tab>for other_option in self.ssl_options():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if scan_argv(self.argv, other_option) is not None:<tab><tab><tab><tab><tab><tab>raise ConfigurationError(<tab><tab><tab><tab><tab><tab><tab>""Cannot give both %s and %s"" % (option, other_option)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab>return option",if option != other_option :,140
2931,"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(arg, bytes):<tab><tab><tab>if return_type is str:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab>if return_type is bytes:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type",if arg is None :,186
2932,"def _get_app(self, body=None):<tab>app = self._app<tab>if app is None:<tab><tab>try:<tab><tab><tab>tasks = self.tasks.tasks  # is a group<tab><tab>except AttributeError:<tab><tab><tab>tasks = self.tasks<tab><tab><IF-STMT><tab><tab><tab>app = tasks[0]._app<tab><tab>if app is None and body is not None:<tab><tab><tab>app = body._app<tab>return app if app is not None else current_app",if len ( tasks ) :,117
2933,"def add_field(self, field):<tab>self.remove_field(field.name)<tab>self.fields[field.name] = field<tab>self.columns[field.db_column] = field<tab>self._sorted_field_list.insert(field)<tab>self._update_field_lists()<tab>if field.default is not None:<tab><tab>self.defaults[field] = field.default<tab><tab><IF-STMT><tab><tab><tab>self._default_callables[field] = field.default<tab><tab><tab>self._default_callable_list.append((field.name, field.default))<tab><tab>else:<tab><tab><tab>self._default_dict[field] = field.default<tab><tab><tab>self._default_by_name[field.name] = field.default",if callable ( field . default ) :,184
2934,"def _get_families(self):<tab>families = []<tab>for name, ext in self._get_family_dirs():<tab><tab><IF-STMT>  # is a directory<tab><tab><tab>family = self.get_resource(<tab><tab><tab><tab>FileSystemPackageFamilyResource.key, location=self.location, name=name<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>family = self.get_resource(<tab><tab><tab><tab>FileSystemCombinedPackageFamilyResource.key,<tab><tab><tab><tab>location=self.location,<tab><tab><tab><tab>name=name,<tab><tab><tab><tab>ext=ext,<tab><tab><tab>)<tab><tab>families.append(family)<tab>return families",if ext is None :,157
2935,"def test(model, data_loader, device=None):<tab>device = device or torch.device(""cpu"")<tab>model.eval()<tab>correct = 0<tab>total = 0<tab>with torch.no_grad():<tab><tab>for batch_idx, (data, target) in enumerate(data_loader):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>data, target = data.to(device), target.to(device)<tab><tab><tab>outputs = model(data)<tab><tab><tab>_, predicted = torch.max(outputs.data, 1)<tab><tab><tab>total += target.size(0)<tab><tab><tab>correct += (predicted == target).sum().item()<tab>return correct / total",if batch_idx * len ( data ) > TEST_SIZE :,175
2936,"def __animate_progress(self):<tab>""""""Change the status message, mostly used to animate progress.""""""<tab>while True:<tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab>with self.__progress_lock:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab><tab>elif self.__show_animation:<tab><tab><tab><tab>self.__progress_status.update_progress(self.__current_operation_name)<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY<tab><tab><tab>else:<tab><tab><tab><tab>self.__progress_status.show_as_ready()<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab># Allow some time for progress status to be updated.<tab><tab>time.sleep(sleep_time)",if not self . __progress_status :,195
2937,"def _parse_subtitles(self, video_data, url_key):<tab>subtitles = {}<tab>for translation in video_data.get(""translations"", []):<tab><tab>vtt_path = translation.get(url_key)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>lang = translation.get(""language_w3c"") or ISO639Utils.long2short(<tab><tab><tab>translation[""language_medium""]<tab><tab>)<tab><tab>subtitles.setdefault(lang, []).append(<tab><tab><tab>{<tab><tab><tab><tab>""ext"": ""vtt"",<tab><tab><tab><tab>""url"": vtt_path,<tab><tab><tab>}<tab><tab>)<tab>return subtitles",if not vtt_path :,164
2938,"def postprocess_message(self, msg):<tab>if msg[""type""] == ""sample"" and msg[""value""] is not None:<tab><tab>fn, value = msg[""fn""], msg[""value""]<tab><tab>value_batch_ndims = jnp.ndim(value) - fn.event_dim<tab><tab>fn_batch_ndim = len(fn.batch_shape)<tab><tab><IF-STMT><tab><tab><tab>prepend_shapes = (1,) * (value_batch_ndims - fn_batch_ndim)<tab><tab><tab>msg[""fn""] = tree_map(<tab><tab><tab><tab>lambda x: jnp.reshape(x, prepend_shapes + jnp.shape(x)), fn<tab><tab><tab>)",if fn_batch_ndim < value_batch_ndims :,170
2939,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_filename(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,90
2940,"def createError(self, line, pos, description):<tab>global ENABLE_PYIMPORT<tab>msg = ""Line "" + unicode(line) + "": "" + unicode(description)<tab>if ENABLE_JS2PY_ERRORS:<tab><tab><IF-STMT><tab><tab><tab>import js2py.base<tab><tab><tab>return js2py.base.MakeError(""SyntaxError"", msg)<tab><tab>else:<tab><tab><tab>return ENABLE_JS2PY_ERRORS(msg)<tab>else:<tab><tab>return JsSyntaxError(msg)","if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :",129
2941,"def extract(self, page, start_index=0, end_index=None):<tab>items = []<tab>for extractor in self.extractors:<tab><tab>extracted = extractor.extract(<tab><tab><tab>page, start_index, end_index, self.template.ignored_regions<tab><tab>)<tab><tab>for item in arg_to_iter(extracted):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if isinstance(item, (ItemProcessor, dict)):<tab><tab><tab><tab><tab>item[u""_template""] = self.template.id<tab><tab><tab><tab>items.append(item)<tab>return items",if item :,141
2942,"def create_volume(self, volume):<tab>""""""Create a volume.""""""<tab>try:<tab><tab>cmd = [""volume"", ""create"", volume[""name""], ""%sG"" % (volume[""size""])]<tab><tab><IF-STMT><tab><tab><tab>cmd.append(""pool"")<tab><tab><tab>cmd.append(self.configuration.eqlx_pool)<tab><tab>if self.configuration.san_thin_provision:<tab><tab><tab>cmd.append(""thin-provision"")<tab><tab>out = self._eql_execute(*cmd)<tab><tab>self.add_multihost_access(volume)<tab><tab>return self._get_volume_data(out)<tab>except Exception:<tab><tab>with excutils.save_and_reraise_exception():<tab><tab><tab>LOG.error('Failed to create volume ""%s"".', volume[""name""])","if self . configuration . eqlx_pool != ""default"" :",199
2943,"def clean(self):<tab># TODO: check for clashes if the random code is already taken<tab>if not self.code:<tab><tab>self.code = u""static-%s"" % uuid.uuid4()<tab>if not self.site:<tab><tab>placeholders = StaticPlaceholder.objects.filter(<tab><tab><tab>code=self.code, site__isnull=True<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>placeholders = placeholders.exclude(pk=self.pk)<tab><tab>if placeholders.exists():<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""A static placeholder with the same site and code already exists"")<tab><tab><tab>)",if self . pk :,149
2944,"def spawnMenu(self, event):<tab>clickedPos = self.getRowByAbs(event.Position)<tab>self.ensureSelection(clickedPos)<tab>selection = self.getSelectedBoosters()<tab>mainBooster = None<tab>if clickedPos != -1:<tab><tab>try:<tab><tab><tab>booster = self.boosters[clickedPos]<tab><tab>except IndexError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mainBooster = booster<tab>itemContext = None if mainBooster is None else _t(""Booster"")<tab>menu = ContextMenu.getMenu(<tab><tab>self,<tab><tab>mainBooster,<tab><tab>selection,<tab><tab>(""boosterItem"", itemContext),<tab><tab>(""boosterItemMisc"", itemContext),<tab>)<tab>if menu:<tab><tab>self.PopupMenu(menu)",if booster in self . original :,199
2945,"def init_errorhandler():<tab># http error handling<tab>for ex in default_exceptions:<tab><tab><IF-STMT><tab><tab><tab>app.register_error_handler(ex, error_http)<tab><tab>elif ex == 500:<tab><tab><tab>app.register_error_handler(ex, internal_error)<tab>if services.ldap:<tab><tab># Only way of catching the LDAPException upon logging in with LDAP server down<tab><tab>@app.errorhandler(services.ldap.LDAPException)<tab><tab>def handle_exception(e):<tab><tab><tab>log.debug(""LDAP server not accessible while trying to login to opds feed"")<tab><tab><tab>return error_http(FailedDependency())",if ex < 500 :,168
2946,"def reloadCols(self):<tab>self.columns = []<tab>for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr):<tab><tab><IF-STMT><tab><tab><tab>t = anytype<tab><tab>elif ""M"" in fmt:<tab><tab><tab>self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i])))<tab><tab><tab>continue<tab><tab>elif ""i"" in fmt:<tab><tab><tab>t = int<tab><tab>elif ""f"" in fmt:<tab><tab><tab>t = float<tab><tab>else:<tab><tab><tab>t = anytype<tab><tab>self.addColumn(ColumnItem(name, i, type=t))",if shape :,168
2947,"def Proc2(IntParIO):<tab>IntLoc = IntParIO + 10<tab>while True:<tab><tab>if Char1Glob == ""A"":<tab><tab><tab>IntLoc = IntLoc - 1<tab><tab><tab>IntParIO = IntLoc - IntGlob<tab><tab><tab>EnumLoc = Ident1<tab><tab><IF-STMT><tab><tab><tab>break<tab>return IntParIO",if EnumLoc == Ident1 :,90
2948,"def opengroup(self, name=None):<tab>gid = self.groups<tab>self.groupwidths.append(None)<tab>if self.groups > MAXGROUPS:<tab><tab>raise error(""too many groups"")<tab>if name is not None:<tab><tab>ogid = self.groupdict.get(name, None)<tab><tab><IF-STMT><tab><tab><tab>raise error(<tab><tab><tab><tab>""redefinition of group name %r as group %d; ""<tab><tab><tab><tab>""was group %d"" % (name, gid, ogid)<tab><tab><tab>)<tab><tab>self.groupdict[name] = gid<tab>return gid",if ogid is not None :,148
2949,"def __setattr__(self, name: str, val: Any):<tab>if name.startswith(""COMPUTED_""):<tab><tab>if name in self:<tab><tab><tab>old_val = self[name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>raise KeyError(<tab><tab><tab><tab>""Computed attributed '{}' already exists ""<tab><tab><tab><tab>""with a different value! old={}, new={}."".format(name, old_val, val)<tab><tab><tab>)<tab><tab>self[name] = val<tab>else:<tab><tab>super().__setattr__(name, val)",if old_val == val :,137
2950,"def get_all_function_symbols(self, module=""kernel""):<tab>""""""Gets all the function tuples for the given module""""""<tab>ret = []<tab>symtable = self.type_map<tab>if module in symtable:<tab><tab>mod = symtable[module]<tab><tab>for (addr, (name, _sym_types)) in mod.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addr = addr + self.shift_address<tab><tab><tab>ret.append([name, addr])<tab>else:<tab><tab>debug.info(""All symbols requested for non-existent module %s"" % module)<tab>return ret",if self . shift_address and addr :,147
2951,"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"":<tab>code = frame.f_code<tab>if (<tab><tab>event not in SUPPORTED_EVENTS<tab><tab>or code.co_name == ""trace_types""<tab><tab>or self.should_trace<tab><tab>and not self.should_trace(code)<tab>):<tab><tab>return self<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.handle_call(frame)<tab><tab>elif event == EVENT_RETURN:<tab><tab><tab>self.handle_return(frame, arg)<tab><tab>else:<tab><tab><tab>logger.error(""Cannot handle event %s"", event)<tab>except Exception:<tab><tab>logger.exception(""Failed collecting trace"")<tab>return self",if event == EVENT_CALL :,185
2952,"def test_update_topic(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>topic = ""update topic""<tab><tab>async with self.chat_thread_client:<tab><tab><tab>await self.chat_thread_client.update_topic(topic=topic)<tab><tab># delete chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)",if not self . is_playback ( ) :,114
2953,"def render_observation(self):<tab>x = self.read_head_position<tab>label = ""Observation Grid<tab>: ""<tab>x_str = """"<tab>for j in range(-1, self.rows + 1):<tab><tab>if j != -1:<tab><tab><tab>x_str += "" "" * len(label)<tab><tab>for i in range(-2, self.input_width + 2):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True)<tab><tab><tab>else:<tab><tab><tab><tab>x_str += self._get_str_obs((i, j))<tab><tab>x_str += ""\n""<tab>x_str = label + x_str<tab>return x_str",if i == x [ 0 ] and j == x [ 1 ] :,200
2954,"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""QA-ZRE"")<tab>version = None<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,183
2955,"def git_pull(args):<tab>if len(args) <= 1:<tab><tab>repo = _get_repo()<tab><tab>_confirm_dangerous()<tab><tab>url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """")<tab><tab><IF-STMT><tab><tab><tab>origin = url<tab><tab><tab>url = repo.remotes.get(origin)<tab><tab>if url:<tab><tab><tab>repo.pull(origin_uri=url)<tab><tab>else:<tab><tab><tab>print(""No pull URL."")<tab>else:<tab><tab>print(command_help[""git pull""])",if url in repo . remotes :,147
2956,"def FindAndDelete(script, sig):<tab>""""""Consensus critical, see FindAndDelete() in Satoshi codebase""""""<tab>r = b""""<tab>last_sop_idx = sop_idx = 0<tab>skip = True<tab>for (opcode, data, sop_idx) in script.raw_iter():<tab><tab><IF-STMT><tab><tab><tab>r += script[last_sop_idx:sop_idx]<tab><tab>last_sop_idx = sop_idx<tab><tab>if script[sop_idx : sop_idx + len(sig)] == sig:<tab><tab><tab>skip = True<tab><tab>else:<tab><tab><tab>skip = False<tab>if not skip:<tab><tab>r += script[last_sop_idx:]<tab>return CScript(r)",if not skip :,187
2957,"def get_ip_info(ipaddress):<tab>""""""Returns device information by IP address""""""<tab>result = {}<tab>try:<tab><tab>ip = IPAddress.objects.select_related().get(address=ipaddress)<tab>except IPAddress.DoesNotExist:<tab><tab>pass<tab>else:<tab><tab>if ip.venture is not None:<tab><tab><tab>result[""venture_id""] = ip.venture.id<tab><tab>if ip.device is not None:<tab><tab><tab>result[""device_id""] = ip.device.id<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[""venture_id""] = ip.device.venture.id<tab>return result",if ip . device . venture is not None :,162
2958,"def restore(self, state):<tab>""""""Restore the state of a mesh previously saved using save()""""""<tab>import pickle<tab>state = pickle.loads(state)<tab>for k in state:<tab><tab>if isinstance(state[k], list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state[k] = [[v.x(), v.y(), v.z()] for v in state[k]]<tab><tab><tab>state[k] = np.array(state[k])<tab><tab>setattr(self, k, state[k])","if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) :",135
2959,"def get_extra_lines(tup):<tab>ext_name, pyopencl_ver = tup<tab>if ext_name is not None:<tab><tab><IF-STMT><tab><tab><tab># capital letters -> CL version, not extension<tab><tab><tab>yield """"<tab><tab><tab>yield ""<tab>Available with OpenCL %s."" % (ext_name[3:])<tab><tab><tab>yield """"<tab><tab>else:<tab><tab><tab>yield """"<tab><tab><tab>yield ""<tab>Available with the ``%s`` extension."" % ext_name<tab><tab><tab>yield """"<tab>if pyopencl_ver is not None:<tab><tab>yield """"<tab><tab>yield ""<tab>.. versionadded:: %s"" % pyopencl_ver<tab><tab>yield """"","if ext_name . startswith ( ""CL_"" ) :",174
2960,"def _gen_remote_uri(<tab>fileobj: IO[bytes],<tab>remote_uri: Optional[ParseResult],<tab>remote_path_prefix: Optional[str],<tab>remote_path_suffix: Optional[str],<tab>sha256sum: Optional[str],) -> ParseResult:<tab>if remote_uri is None:<tab><tab>assert remote_path_prefix is not None and remote_path_suffix is not None<tab><tab><IF-STMT><tab><tab><tab>sha256sum = _hash_fileobj(fileobj)<tab><tab>return urlparse(<tab><tab><tab>os.path.join(remote_path_prefix, f""{sha256sum}{remote_path_suffix}"")<tab><tab>)<tab>else:<tab><tab>return remote_uri",if sha256sum is None :,171
2961,"def queries(self):<tab>if DEV:<tab><tab>cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s)<tab><tab>if not cmd.check(f""docker check for {self.path.k8s}""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log_cmd = ShellCommand(<tab><tab><tab><tab><tab>""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT<tab><tab><tab><tab>)<tab><tab><tab><tab>if log_cmd.check(f""docker logs for {self.path.k8s}""):<tab><tab><tab><tab><tab>print(cmd.stdout)<tab><tab><tab><tab>pytest.exit(f""container failed to start for {self.path.k8s}"")<tab>return ()",if not cmd . stdout . strip ( ) :,188
2962,"def get_range(self):<tab>present = self.xml.find(""{%s}range"" % self.namespace)<tab>if present is not None:<tab><tab>attributes = present.attrib<tab><tab>return_value = dict()<tab><tab><IF-STMT><tab><tab><tab>return_value[""minimum""] = attributes[""min""]<tab><tab>if ""max"" in attributes:<tab><tab><tab>return_value[""maximum""] = attributes[""max""]<tab><tab>return return_value<tab>return False","if ""min"" in attributes :",113
2963,"def _configuredOn(self, workerid, builderid=None, masterid=None):<tab>cfg = []<tab>for cs in itervalues(self.configured):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>bid, mid = self.db.builders.builder_masters[cs[""buildermasterid""]]<tab><tab>if builderid is not None and bid != builderid:<tab><tab><tab>continue<tab><tab>if masterid is not None and mid != masterid:<tab><tab><tab>continue<tab><tab>cfg.append({""builderid"": bid, ""masterid"": mid})<tab>return cfg","if cs [ ""workerid"" ] != workerid :",143
2964,"def __exit__(self, type, value, traceback):<tab>try:<tab><tab>if type is not None:<tab><tab><tab>return self.exception_handler(type, value, traceback)<tab>finally:<tab><tab>final_contexts = _state.contexts<tab><tab>_state.contexts = self.old_contexts<tab><tab><IF-STMT><tab><tab><tab>raise StackContextInconsistentError(<tab><tab><tab><tab>""stack_context inconsistency (may be caused by yield ""<tab><tab><tab><tab>'within a ""with StackContext"" block)'<tab><tab><tab>)<tab><tab># Break up a reference to itself to allow for faster GC on CPython.<tab><tab>self.new_contexts = None",if final_contexts is not self . new_contexts :,162
2965,"def del_(self, key):<tab>initial_hash = hash_ = self.hash(key)<tab>while True:<tab><tab><IF-STMT><tab><tab><tab># That key was never assigned<tab><tab><tab>return None<tab><tab>elif self._keys[hash_] == key:<tab><tab><tab># key found, assign with deleted sentinel<tab><tab><tab>self._keys[hash_] = self._deleted<tab><tab><tab>self._values[hash_] = self._deleted<tab><tab><tab>self._len -= 1<tab><tab><tab>return<tab><tab>hash_ = self._rehash(hash_)<tab><tab>if initial_hash == hash_:<tab><tab><tab># table is full and wrapped around<tab><tab><tab>return None",if self . _keys [ hash_ ] is self . _empty :,166
2966,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_logout_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,92
2967,"def data_generator():<tab>i = 0<tab>max_batch_index = len(X_train) // batch_size<tab>tot = 0<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>yield (<tab><tab><tab><tab>np.ones([batch_size, input_dim]) * np.nan,<tab><tab><tab><tab>np.ones([batch_size, num_classes]) * np.nan,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield (<tab><tab><tab><tab>X_train[i * batch_size : (i + 1) * batch_size],<tab><tab><tab><tab>y_train[i * batch_size : (i + 1) * batch_size],<tab><tab><tab>)<tab><tab>i += 1<tab><tab>tot += 1<tab><tab>i = i % max_batch_index",if tot > 3 * len ( X_train ) :,198
2968,"def title(self):<tab>ret = theme[""title""]<tab>if isinstance(self.name, six.string_types):<tab><tab>width = self.statwidth()<tab><tab>return (<tab><tab><tab>ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""]<tab><tab>)<tab>for i, name in enumerate(self.name):<tab><tab>width = self.colwidth()<tab><tab>ret = ret + name[0:width].center(width).replace("" "", ""-"")<tab><tab><IF-STMT><tab><tab><tab>if op.color:<tab><tab><tab><tab>ret = ret + theme[""frame""] + char[""dash""] + theme[""title""]<tab><tab><tab>else:<tab><tab><tab><tab>ret = ret + char[""space""]<tab>return ret",if i + 1 != len ( self . vars ) :,188
2969,"def get_container_from_dport(dport, docker_client):<tab>for container in docker_client.containers():<tab><tab>try:<tab><tab><tab>ports = container[""Ports""]<tab><tab><tab>for port in ports:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if port[""PublicPort""] == int(dport):<tab><tab><tab><tab><tab><tab>return container<tab><tab>except KeyError:<tab><tab><tab>print(ports)<tab><tab><tab>pass","if ""PublicPort"" in port :",112
2970,"def _get_parents_data(self, data):<tab>parents = 0<tab>if data[COLUMN_PARENT]:<tab><tab>family = self.db.get_family_from_handle(data[COLUMN_PARENT][0])<tab><tab>if family.get_father_handle():<tab><tab><tab>parents += 1<tab><tab><IF-STMT><tab><tab><tab>parents += 1<tab>return parents",if family . get_mother_handle ( ) :,98
2971,"def wrapper(filename):<tab>mtime = getmtime(filename)<tab>with lock:<tab><tab>if filename in cache:<tab><tab><tab>old_mtime, result = cache.pop(filename)<tab><tab><tab>if old_mtime == mtime:<tab><tab><tab><tab># Move to the end<tab><tab><tab><tab>cache[filename] = old_mtime, result<tab><tab><tab><tab>return result<tab>result = function(filename)<tab>with lock:<tab><tab>cache[filename] = mtime, result  # at the end<tab><tab><IF-STMT><tab><tab><tab>cache.popitem(last=False)<tab>return result",if len ( cache ) > max_size :,144
2972,"def execute(cls, ctx, op: ""DataFrameGroupByAgg""):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab>if op.stage == OperandStage.map:<tab><tab><tab>cls._execute_map(ctx, op)<tab><tab>elif op.stage == OperandStage.combine:<tab><tab><tab>cls._execute_combine(ctx, op)<tab><tab><IF-STMT><tab><tab><tab>cls._execute_agg(ctx, op)<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise ValueError(""Aggregation operand not executable"")<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",elif op . stage == OperandStage . agg :,171
2973,"def FindAndDelete(script, sig):<tab>""""""Consensus critical, see FindAndDelete() in Satoshi codebase""""""<tab>r = b""""<tab>last_sop_idx = sop_idx = 0<tab>skip = True<tab>for (opcode, data, sop_idx) in script.raw_iter():<tab><tab>if not skip:<tab><tab><tab>r += script[last_sop_idx:sop_idx]<tab><tab>last_sop_idx = sop_idx<tab><tab><IF-STMT><tab><tab><tab>skip = True<tab><tab>else:<tab><tab><tab>skip = False<tab>if not skip:<tab><tab>r += script[last_sop_idx:]<tab>return CScript(r)",if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,187
2974,"def extractall(zip: typing.Any, path: str) -> NoneType:<tab>for name in zip.namelist():<tab><tab>member = zip.getinfo(name)<tab><tab>extracted_path = zip._extract_member(member, path, None)<tab><tab>attr = member.external_attr >> 16<tab><tab><IF-STMT><tab><tab><tab>os.chmod(extracted_path, attr)",if attr != 0 :,93
2975,"def find_all_gyptest_files(directory):<tab>result = []<tab>for root, dirs, files in os.walk(directory):<tab><tab><IF-STMT><tab><tab><tab>dirs.remove("".svn"")<tab><tab>result.extend([os.path.join(root, f) for f in files if is_test_name(f)])<tab>result.sort()<tab>return result","if "".svn"" in dirs :",94
2976,"def load(cls, storefile, template_store):<tab># Did we get file or filename?<tab>if not hasattr(storefile, ""read""):<tab><tab>storefile = open(storefile, ""rb"")<tab># Adjust store to have translations<tab>store = cls.convertfile(storefile, template_store)<tab>for unit in store.units:<tab><tab>if unit.isheader():<tab><tab><tab>continue<tab><tab># HTML does this properly on loading, others need it<tab><tab><IF-STMT><tab><tab><tab>unit.target = unit.source<tab><tab><tab>unit.rich_target = unit.rich_source<tab>return store",if cls . needs_target_sync :,152
2977,"def postOptions(self):<tab>_BasicOptions.postOptions(self)<tab>if self[""jobs""]:<tab><tab>conflicts = [""debug"", ""profile"", ""debug-stacktraces"", ""exitfirst""]<tab><tab>for option in conflicts:<tab><tab><tab>if self[option]:<tab><tab><tab><tab>raise usage.UsageError(<tab><tab><tab><tab><tab>""You can't specify --%s when using --jobs"" % option<tab><tab><tab><tab>)<tab>if self[""nopm""]:<tab><tab><IF-STMT><tab><tab><tab>raise usage.UsageError(""You must specify --debug when using "" ""--nopm "")<tab><tab>failure.DO_POST_MORTEM = False","if not self [ ""debug"" ] :",151
2978,"def filterTokenLocation():<tab>i = None<tab>entry = None<tab>token = None<tab>tokens = []<tab>i = 0<tab>while 1:<tab><tab>if not (i < len(extra.tokens)):<tab><tab><tab>break<tab><tab>entry = extra.tokens[i]<tab><tab>token = jsdict(<tab><tab><tab>{<tab><tab><tab><tab>""type"": entry.type,<tab><tab><tab><tab>""value"": entry.value,<tab><tab><tab>}<tab><tab>)<tab><tab>if extra.range:<tab><tab><tab>token.range = entry.range<tab><tab><IF-STMT><tab><tab><tab>token.loc = entry.loc<tab><tab>tokens.append(token)<tab><tab>i += 1<tab>extra.tokens = tokens",if extra . loc :,172
2979,"def on_rebalance_end(self) -> None:<tab>""""""Call when rebalancing is done.""""""<tab>self.rebalancing = False<tab>if self._rebalancing_span:<tab><tab>self._rebalancing_span.finish()<tab>self._rebalancing_span = None<tab>sensor_state = self._rebalancing_sensor_state<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(<tab><tab><tab><tab>""Missing sensor state for rebalance #%s"", self.rebalancing_count<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.sensors.on_rebalance_end(self, sensor_state)<tab>finally:<tab><tab>self._rebalancing_sensor_state = None",if not sensor_state :,184
2980,"def decorator(request, *args, **kwargs):<tab>if CALENDAR_VIEW_PERM:<tab><tab>user = request.user<tab><tab>if not user:<tab><tab><tab>return HttpResponseRedirect(settings.LOGIN_URL)<tab><tab>occurrence, event, calendar = get_objects(request, **kwargs)<tab><tab>if calendar:<tab><tab><tab>allowed = CHECK_CALENDAR_PERM_FUNC(calendar, user)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return HttpResponseRedirect(settings.LOGIN_URL)<tab><tab><tab># all checks passed<tab><tab><tab>return function(request, *args, **kwargs)<tab><tab>return HttpResponseNotFound(""<h1>Page not found</h1>"")<tab>return function(request, *args, **kwargs)",if not allowed :,170
2981,"def reduce_arguments(self, args):<tab>assert isinstance(args, nodes.Arguments)<tab>if args.incorrect_order():<tab><tab>raise InvalidArguments(<tab><tab><tab>""All keyword arguments must be after positional arguments.""<tab><tab>)<tab>reduced_pos = [self.reduce_single(arg) for arg in args.arguments]<tab>reduced_kw = {}<tab>for key in args.kwargs.keys():<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArguments(""Keyword argument name is not a string."")<tab><tab>a = args.kwargs[key]<tab><tab>reduced_kw[key] = self.reduce_single(a)<tab>return (reduced_pos, reduced_kw)","if not isinstance ( key , str ) :",163
2982,"def _encode(n, nbytes, little_endian=False):<tab>retval = []<tab>n = long(n)<tab>for i in range(nbytes):<tab><tab><IF-STMT><tab><tab><tab>retval.append(chr(n & 0xFF))<tab><tab>else:<tab><tab><tab>retval.insert(0, chr(n & 0xFF))<tab><tab>n >>= 8<tab>return """".join(retval)",if little_endian :,96
2983,"def copy_shell(self):<tab>cls = self.__class__<tab>old_id = cls.id<tab>new_i = cls()  # create a new group<tab>new_i.id = self.id  # with the same id<tab>cls.id = old_id  # Reset the Class counter<tab># Copy all properties<tab>for prop in cls.properties:<tab><tab>if prop is not ""members"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = getattr(self, prop)<tab><tab><tab><tab>setattr(new_i, prop, val)<tab># but no members<tab>new_i.members = []<tab>return new_i",if self . has ( prop ) :,156
2984,"def dataspec(config):<tab>master = yield fakemaster.make_master()<tab>data = connector.DataConnector()<tab>data.setServiceParent(master)<tab>if config[""out""] != ""--"":<tab><tab>dirs = os.path.dirname(config[""out""])<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dirs)<tab><tab>f = open(config[""out""], ""w"")<tab>else:<tab><tab>f = sys.stdout<tab>if config[""global""] is not None:<tab><tab>f.write(""window."" + config[""global""] + ""="")<tab>f.write(json.dumps(data.allEndpoints(), indent=2))<tab>f.close()<tab>defer.returnValue(0)",if dirs and not os . path . exists ( dirs ) :,176
2985,"def _parseSCDOCDC(self, src):<tab>""""""[S|CDO|CDC]*""""""<tab>while 1:<tab><tab>src = src.lstrip()<tab><tab><IF-STMT><tab><tab><tab>src = src[4:]<tab><tab>elif src.startswith(""-->""):<tab><tab><tab>src = src[3:]<tab><tab>else:<tab><tab><tab>break<tab>return src","if src . startswith ( ""<!--"" ) :",92
2986,"def command(filenames, dirnames, fix):<tab>for filename in gather_files(dirnames, filenames):<tab><tab>visitor = process_file(filename)<tab><tab>if visitor.needs_fix():<tab><tab><tab>print(""%s: %s"" % (filename, visitor.get_stats()))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""Fixing: %s"" % filename)<tab><tab><tab><tab>fix_file(filename)",if fix :,100
2987,"def shutdown(self):<tab>""""""Shutdown host system.""""""<tab>self._check_dbus(MANAGER)<tab>use_logind = self.sys_dbus.logind.is_connected<tab>_LOGGER.info(""Initialize host power off %s"", ""logind"" if use_logind else ""systemd"")<tab>try:<tab><tab>await self.sys_core.shutdown()<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>await self.sys_dbus.logind.power_off()<tab><tab>else:<tab><tab><tab>await self.sys_dbus.systemd.power_off()",if use_logind :,140
2988,"def _run_split_on_punc(self, text, never_split=None):<tab>""""""Splits punctuation on a piece of text.""""""<tab>if never_split is not None and text in never_split:<tab><tab>return [text]<tab>chars = list(text)<tab>i = 0<tab>start_new_word = True<tab>output = []<tab>while i < len(chars):<tab><tab>char = chars[i]<tab><tab>if _is_punctuation(char):<tab><tab><tab>output.append([char])<tab><tab><tab>start_new_word = True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output.append([])<tab><tab><tab>start_new_word = False<tab><tab><tab>output[-1].append(char)<tab><tab>i += 1<tab>return ["""".join(x) for x in output]",if start_new_word :,199
2989,"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout):<tab>try:<tab><tab>if tp == ""write"":<tab><tab><tab>out.write(msg)<tab><tab><IF-STMT><tab><tab><tab>out.flush()<tab><tab>elif tp == ""write_flush"":<tab><tab><tab>out.write(msg)<tab><tab><tab>out.flush()<tab><tab>elif tp == ""print"":<tab><tab><tab>print(msg, file=out)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported type: "" + tp)<tab>except IOError as e:<tab><tab>logger.critical(""{}: {}"".format(type(e).__name__, ucd(e)))<tab><tab>pass","elif tp == ""flush"" :",160
2990,"def checkClassDeclation(file):<tab>localResult = []<tab>with open(file, ""rb"") as f:<tab><tab>lineNumber = 0<tab><tab>for line in f:<tab><tab><tab>m = re.search(""class\s+[^\(]*:"", line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>localResult.append(<tab><tab><tab><tab><tab>""Old class definition found on {0}"".format(m.group())<tab><tab><tab><tab>)<tab>return localResult",if m :,112
2991,"def _evaluate_local_single(self, iterator):<tab>for batch in iterator:<tab><tab>in_arrays = convert._call_converter(self.converter, batch, self.device)<tab><tab>with function.no_backprop_mode():<tab><tab><tab>if isinstance(in_arrays, tuple):<tab><tab><tab><tab>results = self.calc_local(*in_arrays)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results = self.calc_local(**in_arrays)<tab><tab><tab>else:<tab><tab><tab><tab>results = self.calc_local(in_arrays)<tab><tab>if self._progress_hook:<tab><tab><tab>self._progress_hook(batch)<tab><tab>yield results","elif isinstance ( in_arrays , dict ) :",166
2992,"def check_billing_view(user, permission, obj):<tab>if hasattr(obj, ""all_projects""):<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab># This is a billing object<tab><tab>return any(check_permission(user, permission, prj) for prj in obj.all_projects)<tab>return check_permission(user, permission, obj)",if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,106
2993,"def ensure_output_spaces_contain_the_same_data(self, y, y_ensured):<tab>stride = y.shape[1]<tab>self.assertEqual(y.shape[0] * y.shape[1], y_ensured.shape[0])<tab>self.assertEqual(len(y_ensured.shape), 1)<tab>for row in range(y.shape[0]):<tab><tab>for column in range(y.shape[1]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(y[row, column], y_ensured[row * stride + column])<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(y[row][column], y_ensured[row * stride + column])",if sp . issparse ( y ) :,176
2994,"def train(<tab>self,<tab>training_data: TrainingData,<tab>config: Optional[RasaNLUModelConfig] = None,<tab>**kwargs: Any,) -> None:<tab>""""""Tokenize all training data.""""""<tab>for example in training_data.training_examples:<tab><tab>for attribute in MESSAGE_ATTRIBUTES:<tab><tab><tab>if example.get(attribute) is not None and not example.get(attribute) == """":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>tokens = self._split_name(example, attribute)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>tokens = self.tokenize(example, attribute)<tab><tab><tab><tab>example.set(TOKENS_NAMES[attribute], tokens)","if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] :",183
2995,"def refresh_token(self, strategy, *args, **kwargs):<tab>token = self.extra_data.get(""refresh_token"") or self.extra_data.get(""access_token"")<tab>backend = self.get_backend(strategy)<tab>if token and backend and hasattr(backend, ""refresh_token""):<tab><tab>backend = backend(strategy=strategy)<tab><tab>response = backend.refresh_token(token, *args, **kwargs)<tab><tab>extra_data = backend.extra_data(self, self.uid, response, self.extra_data)<tab><tab><IF-STMT><tab><tab><tab>self.save()",if self . set_extra_data ( extra_data ) :,154
2996,"def _verify_environ(_collected_environ):<tab>try:<tab><tab>yield<tab>finally:<tab><tab>new_environ = dict(os.environ)<tab><tab>current_test = new_environ.pop(""PYTEST_CURRENT_TEST"", None)<tab><tab>old_environ = dict(_collected_environ)<tab><tab>old_environ.pop(""PYTEST_CURRENT_TEST"", None)<tab><tab><IF-STMT><tab><tab><tab>raise DirtyTest(<tab><tab><tab><tab>""Left over environment variables"",<tab><tab><tab><tab>current_test,<tab><tab><tab><tab>_compare_eq_dict(new_environ, old_environ, verbose=2),<tab><tab><tab>)",if new_environ != old_environ :,157
2997,"def clean_len(self, line):<tab>""""""Calculate wisible length of string""""""<tab>if isinstance(line, basestring):<tab><tab>return len(self.screen.markup.clean_markup(line))<tab>elif isinstance(line, tuple) or isinstance(line, list):<tab><tab>markups = self.screen.markup.get_markup_vars()<tab><tab>length = 0<tab><tab>for i in line:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>length += len(i)<tab><tab>return length",if i not in markups :,123
2998,"def _build_merged_dataset_args(datasets):<tab>merged_dataset_args = []<tab>for dataset in datasets:<tab><tab>dataset_code_column = _parse_dataset_code(dataset)<tab><tab>arg = dataset_code_column[""code""]<tab><tab>column_index = dataset_code_column[""column_index""]<tab><tab><IF-STMT><tab><tab><tab>arg = (dataset_code_column[""code""], {""column_index"": [column_index]})<tab><tab>merged_dataset_args.append(arg)<tab>return merged_dataset_args",if column_index is not None :,134
2999,"def update_watch_data_table_paths(self):<tab>if hasattr(self.tool_data_watcher, ""monitored_dirs""):<tab><tab>for tool_data_table_path in self.tool_data_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tool_data_watcher.watch_directory(tool_data_table_path)",if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,107
3000,"def getsource(obj):<tab>""""""Wrapper around inspect.getsource""""""<tab>try:<tab><tab>try:<tab><tab><tab>src = encoding.to_unicode(inspect.getsource(obj))<tab><tab>except TypeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>src = encoding.to_unicode(inspect.getsource(obj.__class__))<tab><tab><tab>else:<tab><tab><tab><tab># Bindings like VTK or ITK require this case<tab><tab><tab><tab>src = getdoc(obj)<tab><tab>return src<tab>except (TypeError, IOError):<tab><tab>return","if hasattr ( obj , ""__class__"" ) :",134
3001,"def __iter__(self):<tab>for model in self.app_config.get_models():<tab><tab>admin_model = AdminModel(model, **self.options)<tab><tab>for model_re in self.model_res:<tab><tab><tab>if model_re.search(admin_model.name):<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield admin_model",if self . model_res :,105
3002,"def run(self):<tab>while True:<tab><tab>try:<tab><tab><tab>with DelayedKeyboardInterrupt():<tab><tab><tab><tab>raw_inputs = self._parent_task_queue.get()<tab><tab><tab><tab>if self._has_stop_signal(raw_inputs):<tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>if self._flow_type == BATCH:<tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=False)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>pass<tab><tab>except KeyboardInterrupt:<tab><tab><tab>continue",elif self . _flow_type == REALTIME :,199
3003,"def dump(self):<tab>self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name))<tab>for field in self._fields_:<tab><tab><IF-STMT><tab><tab><tab>self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value))<tab><tab>elif isinstance(getattr(self, field[0]), int):<tab><tab><tab>self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0])))<tab><tab>elif isinstance(getattr(self, field[0]), bytes):<tab><tab><tab>self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))","if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) :",188
3004,"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]):<tab>""""""Validating that user has inputted a value set and that configuration has been initialized""""""<tab>super().validate_configuration(configuration)<tab>try:<tab><tab>assert ""value_set"" in configuration.kwargs, ""value_set is required""<tab><tab>assert isinstance(<tab><tab><tab>configuration.kwargs[""value_set""], (list, set, dict)<tab><tab>), ""value_set must be a list or a set""<tab><tab><IF-STMT><tab><tab><tab>assert (<tab><tab><tab><tab>""$PARAMETER"" in configuration.kwargs[""value_set""]<tab><tab><tab>), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key'<tab>except AssertionError as e:<tab><tab>raise InvalidExpectationConfigurationError(str(e))<tab>return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",196
3005,def test_one_dead_branch():<tab>with deterministic_PRNG():<tab><tab>seen = set()<tab><tab>@run_to_buffer<tab><tab>def x(data):<tab><tab><tab>i = data.draw_bytes(1)[0]<tab><tab><tab>if i > 0:<tab><tab><tab><tab>data.mark_invalid()<tab><tab><tab>i = data.draw_bytes(1)[0]<tab><tab><tab>if len(seen) < 255:<tab><tab><tab><tab>seen.add(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data.mark_interesting(),elif i not in seen :,138
3006,"def __on_item_activated(self, event):<tab>if self.__module_view:<tab><tab>module = self.get_event_module(event)<tab><tab>self.__module_view.set_selection(module.module_num)<tab><tab>if event.EventObject is self.list_ctrl:<tab><tab><tab>self.input_list_ctrl.deactivate_active_item()<tab><tab>else:<tab><tab><tab>self.list_ctrl.deactivate_active_item()<tab><tab><tab>for index in range(self.list_ctrl.GetItemCount()):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.list_ctrl.Select(index, False)<tab>self.__controller.enable_module_controls_panel_buttons()",if self . list_ctrl . IsSelected ( index ) :,181
3007,"def prime(self, callback):<tab><IF-STMT><tab><tab># import pdb<tab><tab># pdb.set_trace()<tab><tab>self.cbhdl = simulator.register_rwsynch_callback(callback, self)<tab><tab>if self.cbhdl is None:<tab><tab><tab>raise_error(self, ""Unable set up %s Trigger"" % (str(self)))<tab>Trigger.prime(self)",if self . cbhdl is None :,102
3008,"def fstab_configuration(middleware):<tab>for command in (<tab><tab>[<tab><tab><tab>[""systemctl"", ""daemon-reload""],<tab><tab><tab>[""systemctl"", ""restart"", ""local-fs.target""],<tab><tab>]<tab><tab>if osc.IS_LINUX<tab><tab>else [[""mount"", ""-uw"", ""/""]]<tab>):<tab><tab>ret = subprocess.run(command, capture_output=True)<tab><tab><IF-STMT><tab><tab><tab>middleware.logger.debug(<tab><tab><tab><tab>f'Failed to execute ""{"" "".join(command)}"": {ret.stderr.decode()}'<tab><tab><tab>)",if ret . returncode :,148
3009,"def _generate_table(self, fromdesc, todesc, diffs):<tab>if fromdesc or todesc:<tab><tab>yield (<tab><tab><tab>simple_colorize(fromdesc, ""description""),<tab><tab><tab>simple_colorize(todesc, ""description""),<tab><tab>)<tab>for i, line in enumerate(diffs):<tab><tab><IF-STMT><tab><tab><tab># mdiff yields None on separator lines; skip the bogus ones<tab><tab><tab># generated for the first line<tab><tab><tab>if i > 0:<tab><tab><tab><tab>yield (<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield line",if line is None :,170
3010,"def update_completion(self):<tab>""""""Update completion model with exist tags""""""<tab>orig_text = self.widget.text()<tab>text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1])<tab>tags = []<tab>for tag in self.tags_list:<tab><tab>if "","" in orig_text:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tags.append(""%s,%s"" % (text, tag))<tab><tab><tab>tags.append(""%s, %s"" % (text, tag))<tab><tab>else:<tab><tab><tab>tags.append(tag)<tab>if tags != self.completer_model.stringList():<tab><tab>self.completer_model.setStringList(tags)","if orig_text [ - 1 ] not in ( "","" , "" "" ) :",177
3011,"def cart_number_checksum_validation(cls, number):<tab>digits = []<tab>even = False<tab>if not number.isdigit():<tab><tab>return False<tab>for digit in reversed(number):<tab><tab>digit = ord(digit) - ord(""0"")<tab><tab><IF-STMT><tab><tab><tab>digit *= 2<tab><tab><tab>if digit >= 10:<tab><tab><tab><tab>digit = digit % 10 + digit // 10<tab><tab>digits.append(digit)<tab><tab>even = not even<tab>return sum(digits) % 10 == 0 if digits else False",if even :,127
3012,"def __get_param_string__(params):<tab>params_string = []<tab>for key in sorted(params.keys()):<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>value = params[key]<tab><tab>params_string.append("""" if value == ""null"" else str(value))<tab>return ""|"".join(params_string)","if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :",93
3013,"def _map_handlers(self, session, event_class, mapfn):<tab>for event in DOC_EVENTS:<tab><tab>event_handler_name = event.replace(""-"", ""_"")<tab><tab><IF-STMT><tab><tab><tab>event_handler = getattr(self, event_handler_name)<tab><tab><tab>format_string = DOC_EVENTS[event]<tab><tab><tab>num_args = len(format_string.split(""."")) - 2<tab><tab><tab>format_args = (event_class,) + (""*"",) * num_args<tab><tab><tab>event_string = event + format_string % format_args<tab><tab><tab>unique_id = event_class + event_handler_name<tab><tab><tab>mapfn(event_string, event_handler, unique_id)","if hasattr ( self , event_handler_name ) :",180
3014,"def _create_param_lr(self, param_and_grad):<tab># create learning rate variable for every parameter<tab>param = param_and_grad[0]<tab>param_lr = param.optimize_attr[""learning_rate""]<tab>if type(param_lr) == Variable:<tab><tab>return param_lr<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self._global_learning_rate()<tab><tab>else:<tab><tab><tab>with default_main_program()._lr_schedule_guard(<tab><tab><tab><tab>is_with_opt=True<tab><tab><tab>), framework.name_scope(""scale_with_param_lr""):<tab><tab><tab><tab>return self._global_learning_rate() * param_lr",if param_lr == 1.0 :,174
3015,"def __getitem__(self, key):<tab>try:<tab><tab>return self._clsmap[key]<tab>except KeyError as e:<tab><tab><IF-STMT><tab><tab><tab>self._mutex.acquire()<tab><tab><tab>try:<tab><tab><tab><tab>if not self.initialized:<tab><tab><tab><tab><tab>self._init()<tab><tab><tab><tab><tab>self.initialized = True<tab><tab><tab><tab>return self._clsmap[key]<tab><tab><tab>finally:<tab><tab><tab><tab>self._mutex.release()<tab><tab>raise e",if not self . initialized :,125
3016,"def save(self, force=False):<tab>if not force:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if time.time() - self.last_save_time < 10:<tab><tab><tab>return<tab>with self.lock:<tab><tab>with open(self.file_path, ""w"") as fd:<tab><tab><tab>for ip in self.cache:<tab><tab><tab><tab>record = self.cache[ip]<tab><tab><tab><tab>rule = record[""r""]<tab><tab><tab><tab>connect_time = record[""c""]<tab><tab><tab><tab>update_time = record[""update""]<tab><tab><tab><tab>fd.write(""%s %s %d %d\n"" % (ip, rule, connect_time, update_time))<tab>self.last_save_time = time.time()<tab>self.need_save = False",if not self . need_save :,198
3017,"def pick(items, sel):<tab>for x, s in zip(items, sel):<tab><tab><IF-STMT><tab><tab><tab>yield x<tab><tab>elif not x.is_atom() and not s.is_atom():<tab><tab><tab>yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",if match ( s ) :,79
3018,"def isValidFloat(config_param_name, value, constraints):<tab>if isinstance(value, float):<tab><tab>constraints.setdefault(""min"", MIN_VALID_FLOAT_VALUE)<tab><tab>constraints.setdefault(""max"", MAX_VALID_FLOAT_VALUE)<tab><tab>minv = float(constraints.get(""min""))<tab><tab>maxv = float(constraints.get(""max""))<tab><tab><IF-STMT><tab><tab><tab>if value <= maxv:<tab><tab><tab><tab>return value<tab>raise FloatValueError(config_param_name, value, constraints)",if value >= minv :,125
3019,"def get_files(d):<tab>f = []<tab>for root, dirs, files in os.walk(d):<tab><tab>for name in files:<tab><tab><tab>if ""meta-environment"" in root or ""cross-canadian"" in root:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if ""do_build"" not in name and ""do_populate_sdk"" not in name:<tab><tab><tab><tab>f.append(os.path.join(root, name))<tab>return f","if ""qemux86copy-"" in root or ""qemux86-"" in root :",143
3020,"def __get_photo(self, person_or_marriage):<tab>""""""returns the first photo in the media list or None""""""<tab>media_list = person_or_marriage.get_media_list()<tab>for media_ref in media_list:<tab><tab>media_handle = media_ref.get_reference_handle()<tab><tab>media = self.database.get_media_from_handle(media_handle)<tab><tab>mime_type = media.get_mime_type()<tab><tab><IF-STMT><tab><tab><tab>return media<tab>return None","if mime_type and mime_type . startswith ( ""image"" ) :",140
3021,"def filter(this, args):<tab>array = to_object(this, args.space)<tab>callbackfn = get_arg(args, 0)<tab>arr_len = js_arr_length(array)<tab>if not is_callable(callbackfn):<tab><tab>raise MakeError(""TypeError"", ""callbackfn must be a function"")<tab>_this = get_arg(args, 1)<tab>k = 0<tab>res = []<tab>while k < arr_len:<tab><tab>if array.has_property(unicode(k)):<tab><tab><tab>kValue = array.get(unicode(k))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return args.space.ConstructArray(res)","if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :",194
3022,"def optimize(self, graph: Graph):<tab>for v in graph.inputs:<tab><tab>if not v.has_attribute(SplitTarget):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>DumpGraph().optimize(graph)<tab><tab>raise NotImplementedError(<tab><tab><tab>f""Input Variable {v} is too large to handle in WebGL backend""<tab><tab>)<tab>return graph, False",if flags . DEBUG :,94
3023,"def detach_volume(self, volume):<tab># We need to find the node using this volume<tab>for node in self.list_nodes():<tab><tab>if type(node.image) is not list:<tab><tab><tab># This node has only one associated image. It is not the one we<tab><tab><tab># are after.<tab><tab><tab>continue<tab><tab>for disk in node.image:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Node found. We can now detach the volume<tab><tab><tab><tab>disk_id = disk.extra[""disk_id""]<tab><tab><tab><tab>return self._do_detach_volume(node.id, disk_id)<tab>return False",if disk . id == volume . id :,160
3024,"def Yield(value, level=1):<tab>g = greenlet.getcurrent()<tab>while level != 0:<tab><tab>if not isinstance(g, genlet):<tab><tab><tab>raise RuntimeError(""yield outside a genlet"")<tab><tab><IF-STMT><tab><tab><tab>g.parent.set_child(g)<tab><tab>g = g.parent<tab><tab>level -= 1<tab>g.switch(value)",if level > 1 :,96
3025,"def get_all_pipeline_nodes(<tab>pipeline: pipeline_pb2.Pipeline,) -> List[pipeline_pb2.PipelineNode]:<tab>""""""Returns all pipeline nodes in the given pipeline.""""""<tab>result = []<tab>for pipeline_or_node in pipeline.nodes:<tab><tab>which = pipeline_or_node.WhichOneof(""node"")<tab><tab># TODO(goutham): Handle sub-pipelines.<tab><tab># TODO(goutham): Handle system nodes.<tab><tab><IF-STMT><tab><tab><tab>result.append(pipeline_or_node.pipeline_node)<tab><tab>else:<tab><tab><tab>raise NotImplementedError(""Only pipeline nodes supported."")<tab>return result","if which == ""pipeline_node"" :",160
3026,"def __init__(self, **settings):<tab>default_settings = self.get_default_settings()<tab>for name, value in default_settings.items():<tab><tab>if not hasattr(self, name):<tab><tab><tab>setattr(self, name, value)<tab>for name, value in settings.items():<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Invalid setting '{}' for {}"".format(<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>self.__class__.__name__,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>setattr(self, name, value)",if name not in default_settings :,144
3027,"def _check_choice(self):<tab>if self.type == ""choice"":<tab><tab><IF-STMT><tab><tab><tab>raise OptionError(""must supply a list of choices for type 'choice'"", self)<tab><tab>elif type(self.choices) not in (types.TupleType, types.ListType):<tab><tab><tab>raise OptionError(<tab><tab><tab><tab>""choices must be a list of strings ('%s' supplied)""<tab><tab><tab><tab>% str(type(self.choices)).split(""'"")[1],<tab><tab><tab><tab>self,<tab><tab><tab>)<tab>elif self.choices is not None:<tab><tab>raise OptionError(""must not supply choices for type %r"" % self.type, self)",if self . choices is None :,162
3028,"def prepare(self, size=None):<tab>if _is_seekable(self.file):<tab><tab>start_pos = self.file.tell()<tab><tab>self.file.seek(0, 2)<tab><tab>end_pos = self.file.tell()<tab><tab>self.file.seek(start_pos)<tab><tab>fsize = end_pos - start_pos<tab><tab><IF-STMT><tab><tab><tab>self.remain = fsize<tab><tab>else:<tab><tab><tab>self.remain = min(fsize, size)<tab>return self.remain",if size is None :,128
3029,"def _setSitemapTargets():<tab>if not conf.sitemapUrl:<tab><tab>return<tab>infoMsg = ""parsing sitemap '%s'"" % conf.sitemapUrl<tab>logger.info(infoMsg)<tab>found = False<tab>for item in parseSitemap(conf.sitemapUrl):<tab><tab><IF-STMT><tab><tab><tab>found = True<tab><tab><tab>kb.targets.add((item.strip(), None, None, None, None))<tab>if not found and not conf.forms and not conf.crawlDepth:<tab><tab>warnMsg = ""no usable links found (with GET parameters)""<tab><tab>logger.warn(warnMsg)","if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :",159
3030,"def test_CY_decomposition(self, tol):<tab>""""""Tests that the decomposition of the CY gate is correct""""""<tab>op = qml.CY(wires=[0, 1])<tab>res = op.decomposition(op.wires)<tab>mats = []<tab>for i in reversed(res):<tab><tab><IF-STMT><tab><tab><tab>mats.append(np.kron(i.matrix, np.eye(2)))<tab><tab>else:<tab><tab><tab>mats.append(i.matrix)<tab>decomposed_matrix = np.linalg.multi_dot(mats)<tab>assert np.allclose(decomposed_matrix, op.matrix, atol=tol, rtol=0)",if len ( i . wires ) == 1 :,169
3031,"def _line_ranges(statements, lines):<tab>""""""Produce a list of ranges for `format_lines`.""""""<tab>statements = sorted(statements)<tab>lines = sorted(lines)<tab>pairs = []<tab>start = None<tab>lidx = 0<tab>for stmt in statements:<tab><tab>if lidx >= len(lines):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>lidx += 1<tab><tab><tab>if not start:<tab><tab><tab><tab>start = stmt<tab><tab><tab>end = stmt<tab><tab>elif start:<tab><tab><tab>pairs.append((start, end))<tab><tab><tab>start = None<tab>if start:<tab><tab>pairs.append((start, end))<tab>return pairs",if stmt == lines [ lidx ] :,167
3032,"def init_params(net):<tab>""""""Init layer parameters.""""""<tab>for module in net.modules():<tab><tab>if isinstance(module, nn.Conv2d):<tab><tab><tab>init.kaiming_normal(module.weight, mode=""fan_out"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>init.constant(module.bias, 0)<tab><tab>elif isinstance(module, nn.BatchNorm2d):<tab><tab><tab>init.constant(module.weight, 1)<tab><tab><tab>init.constant(module.bias, 0)<tab><tab>elif isinstance(module, nn.Linear):<tab><tab><tab>init.normal(module.weight, std=1e-3)<tab><tab><tab>if module.bias:<tab><tab><tab><tab>init.constant(module.bias, 0)",if module . bias :,180
3033,"def _get_directory_size_in_bytes(directory):<tab>total = 0<tab>try:<tab><tab>for entry in os.scandir(directory):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># if it's a file, use stat() function<tab><tab><tab><tab>total += entry.stat().st_size<tab><tab><tab>elif entry.is_dir():<tab><tab><tab><tab># if it's a directory, recursively call this function<tab><tab><tab><tab>total += _get_directory_size_in_bytes(entry.path)<tab>except NotADirectoryError:<tab><tab># if `directory` isn't a directory, get the file size then<tab><tab>return os.path.getsize(directory)<tab>except PermissionError:<tab><tab># if for whatever reason we can't open the folder, return 0<tab><tab>return 0<tab>return total",if entry . is_file ( ) :,193
3034,"def run_cmd(self, util, to, always_push_mark=False):<tab>if to == ""bof"":<tab><tab>util.push_mark_and_goto_position(0)<tab>elif to == ""eof"":<tab><tab>util.push_mark_and_goto_position(self.view.size())<tab>elif to in (""eow"", ""bow""):<tab><tab>visible = self.view.visible_region()<tab><tab>pos = visible.a if to == ""bow"" else visible.b<tab><tab><IF-STMT><tab><tab><tab>util.push_mark_and_goto_position(pos)<tab><tab>else:<tab><tab><tab>util.set_cursors([sublime.Region(pos)])",if always_push_mark :,170
3035,"def parse_results(cwd):<tab>optimal_dd = None<tab>optimal_measure = numpy.inf<tab>for tup in tools.find_conf_files(cwd):<tab><tab>dd = tup[1]<tab><tab>if ""results.train_y_misclass"" in dd:<tab><tab><tab>if dd[""results.train_y_misclass""] < optimal_measure:<tab><tab><tab><tab>optimal_measure = dd[""results.train_y_misclass""]<tab><tab><tab><tab>optimal_dd = dd<tab>print(""Optimal results.train_y_misclass:"", str(optimal_measure))<tab>for key, value in optimal_dd.items():<tab><tab><IF-STMT><tab><tab><tab>print(key + "": "" + str(value))","if ""hyper_parameters"" in key :",177
3036,"def clean_vc_position(self):<tab>vc_position = self.cleaned_data[""vc_position""]<tab>if self.validate_vc_position:<tab><tab>conflicting_members = Device.objects.filter(<tab><tab><tab>virtual_chassis=self.instance.virtual_chassis, vc_position=vc_position<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(<tab><tab><tab><tab>""A virtual chassis member already exists in position {}."".format(<tab><tab><tab><tab><tab>vc_position<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return vc_position",if conflicting_members . exists ( ) :,148
3037,"def cal_pads(auto_pad, pad_shape):<tab>spatial_size = len(pad_shape)<tab>pads = [0] * spatial_size * 2<tab>for i in range(spatial_size):<tab><tab>if auto_pad == ""SAME_LOWER"":<tab><tab><tab>pads[i + spatial_size] = pad_shape[i] // 2<tab><tab><tab>pads[i] = pad_shape[i] - pads[i + spatial_size]<tab><tab><IF-STMT><tab><tab><tab>pads[i] = pad_shape[i] // 2<tab><tab><tab>pads[i + spatial_size] = pad_shape[i] - pads[i]<tab>return pads","elif auto_pad == ""SAME_UPPER"" :",173
3038,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_presence_response().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,140
3039,"def test_cwl_rnaseq(self, install_test_files):<tab>with install_cwl_test_files() as work_dir:<tab><tab>with utils.chdir(os.path.join(work_dir, ""rnaseq"")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shutil.rmtree(""cromwell_work"")<tab><tab><tab>subprocess.check_call(<tab><tab><tab><tab>[""bcbio_vm.py"", ""cwlrun"", ""cromwell"", ""rnaseq-workflow""]<tab><tab><tab>)","if os . path . exists ( ""cromwell_work"" ) :",139
3040,"def files_per_version(self):<tab>xpath = ""./files/file""<tab>files = self.root.findall(xpath)<tab>versions = {}<tab>for file in files:<tab><tab>vfile = file.findall(""version"")<tab><tab>for version in vfile:<tab><tab><tab>nb = version.attrib[""nb""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>versions[nb] = []<tab><tab><tab>versions[nb].append(file.attrib[""url""])<tab>return versions",if not nb in versions :,117
3041,"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># SQLite doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""SQLite backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return six.text_type(value)",if settings . USE_TZ :,131
3042,"def _toplevelTryFunc(func, *args, status=status, **kwargs):<tab>with ThreadProfiler(threading.current_thread()) as prof:<tab><tab>t = threading.current_thread()<tab><tab>t.name = func.__name__<tab><tab>try:<tab><tab><tab>t.status = func(*args, **kwargs)<tab><tab>except EscapeException as e:  # user aborted<tab><tab><tab>t.status = ""aborted by user""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>status(""%s aborted"" % t.name, priority=2)<tab><tab>except Exception as e:<tab><tab><tab>t.exception = e<tab><tab><tab>t.status = ""exception""<tab><tab><tab>vd.exceptionCaught(e)<tab><tab>if t.sheet:<tab><tab><tab>t.sheet.currentThreads.remove(t)",if status :,193
3043,"def ESP(phrase):<tab>for num, name in enumerate(devname):<tab><tab>if name.lower() in phrase:<tab><tab><tab>dev = devid[num]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ctrl = ""=ON""<tab><tab><tab><tab>say(""Turning On "" + name)<tab><tab><tab>elif custom_action_keyword[""Dict""][""Off""] in phrase:<tab><tab><tab><tab>ctrl = ""=OFF""<tab><tab><tab><tab>say(""Turning Off "" + name)<tab><tab><tab>rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :",153
3044,"def _table_schema(self, table):<tab>rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall()<tab># Build list of fields from table information<tab>result = {}<tab>for _, name, data_type, not_null, _, primary_key in rows:<tab><tab>parts = [data_type]<tab><tab><IF-STMT><tab><tab><tab>parts.append(""PRIMARY KEY"")<tab><tab>if not_null:<tab><tab><tab>parts.append(""NOT NULL"")<tab><tab>result[name] = "" "".join(parts)<tab>return result",if primary_key :,137
3045,"def _validate_forward_input(x, n_in):<tab>if n_in != 1:<tab><tab>if not isinstance(x, (tuple, list)):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>f""Expected input to be a tuple or list; instead got {type(x)}.""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""Input tuple length ({len(x)}) does not equal required ""<tab><tab><tab><tab>f""number of inputs ({n_in}).""<tab><tab><tab>)",if len ( x ) != n_in :,133
3046,"def _table_reprfunc(self, row, col, val):<tab>if self._table.column_names[col].endswith(""Size""):<tab><tab>if isinstance(val, compat.string_types):<tab><tab><tab>return ""  %s"" % val<tab><tab><IF-STMT><tab><tab><tab>return ""  %.1f KB"" % (val / 1024.0 ** 1)<tab><tab>elif val < 1024 ** 3:<tab><tab><tab>return ""  %.1f MB"" % (val / 1024.0 ** 2)<tab><tab>else:<tab><tab><tab>return ""  %.1f GB"" % (val / 1024.0 ** 3)<tab>if col in (0, """"):<tab><tab>return str(val)<tab>else:<tab><tab>return ""  %s"" % val",elif val < 1024 ** 2 :,182
3047,"def get_path_name(self):<tab>if self.is_root():<tab><tab>return ""@"" + self.name<tab>else:<tab><tab>parent_name = self.parent.get_path_name()<tab><tab><IF-STMT><tab><tab><tab>return ""/"".join([parent_name, ""@"" + self.name])<tab><tab>else:<tab><tab><tab>return ""@"" + self.name",if parent_name :,90
3048,"def parse(cls, api, json):<tab>lst = List(api)<tab>setattr(lst, ""_json"", json)<tab>for k, v in json.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(lst, k, User.parse(api, v))<tab><tab>elif k == ""created_at"":<tab><tab><tab>setattr(lst, k, parse_datetime(v))<tab><tab>else:<tab><tab><tab>setattr(lst, k, v)<tab>return lst","if k == ""user"" :",115
3049,"def _bytecode_filenames(self, py_filenames):<tab>bytecode_files = []<tab>for py_file in py_filenames:<tab><tab>if not py_file.endswith("".py""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>bytecode_files.append(py_file + ""c"")<tab><tab>if self.optimize > 0:<tab><tab><tab>bytecode_files.append(py_file + ""o"")<tab>return bytecode_files",if self . compile :,107
3050,"def to_json_dict(self):<tab>d = super().to_json_dict()<tab>d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list)<tab>if self.header is not None:<tab><tab><IF-STMT><tab><tab><tab>d[""header""] = self.header.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""header""] = self.header<tab>if self.subheader is not None:<tab><tab>if isinstance(self.subheader, RenderedContent):<tab><tab><tab>d[""subheader""] = self.subheader.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""subheader""] = self.subheader<tab>return d","if isinstance ( self . header , RenderedContent ) :",172
3051,"def makeSomeFiles(pathobj, dirdict):<tab>pathdict = {}<tab>for (key, value) in dirdict.items():<tab><tab>child = pathobj.child(key)<tab><tab>if isinstance(value, bytes):<tab><tab><tab>pathdict[key] = child<tab><tab><tab>child.setContent(value)<tab><tab><IF-STMT><tab><tab><tab>child.createDirectory()<tab><tab><tab>pathdict[key] = makeSomeFiles(child, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""only strings and dicts allowed as values"")<tab>return pathdict","elif isinstance ( value , dict ) :",138
3052,"def Restore(self):<tab>picker, obj = self._window, self._pObject<tab>value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH)<tab>if value is not None:<tab><tab><IF-STMT><tab><tab><tab>if type(value) == list:<tab><tab><tab><tab>value = value[-1]<tab><tab>picker.SetPath(value)<tab><tab>return True<tab>return False","if issubclass ( picker . __class__ , wx . FileDialog ) :",102
3053,"def recv(self, buffer_size):<tab>try:<tab><tab>return super(SSLConnection, self).recv(buffer_size)<tab>except ssl.SSLError as err:<tab><tab><IF-STMT><tab><tab><tab>return b""""<tab><tab>if err.args[0] in (ssl.SSL_ERROR_EOF, ssl.SSL_ERROR_ZERO_RETURN):<tab><tab><tab>self.handle_close()<tab><tab><tab>return b""""<tab><tab>raise","if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) :",133
3054,"def IncrementErrorCount(self, category):<tab>""""""Bumps the module's error statistic.""""""<tab>self.error_count += 1<tab>if self.counting in (""toplevel"", ""detailed""):<tab><tab><IF-STMT><tab><tab><tab>category = category.split(""/"")[0]<tab><tab>if category not in self.errors_by_category:<tab><tab><tab>self.errors_by_category[category] = 0<tab><tab>self.errors_by_category[category] += 1","if self . counting != ""detailed"" :",115
3055,"def _get_y(self, data_inst):<tab>if self.stratified:<tab><tab>y = [v for i, v in data_inst.mapValues(lambda v: v.label).collect()]<tab><tab><IF-STMT><tab><tab><tab>y = self.transform_regression_label(data_inst)<tab>else:<tab><tab># make dummy y<tab><tab>y = [0] * (data_inst.count())<tab>return y",if self . need_transform :,109
3056,"def test_all_project_files(self):<tab>if sys.platform.startswith(""win""):<tab><tab># XXX something with newlines goes wrong on Windows.<tab><tab>return<tab>for filepath in support.all_project_files():<tab><tab>with open(filepath, ""rb"") as fp:<tab><tab><tab>encoding = tokenize.detect_encoding(fp.readline)[0]<tab><tab>self.assertIsNotNone(encoding, ""can't detect encoding for %s"" % filepath)<tab><tab>with open(filepath, ""r"") as fp:<tab><tab><tab>source = fp.read()<tab><tab><tab>source = source.decode(encoding)<tab><tab>tree = driver.parse_string(source)<tab><tab>new = unicode(tree)<tab><tab><IF-STMT><tab><tab><tab>self.fail(""Idempotency failed: %s"" % filepath)","if diff ( filepath , new , encoding ) :",195
3057,"def test_resource_arn_override_generator(self):<tab>overrides = set()<tab>for k, v in manager.resources.items():<tab><tab>arn_gen = bool(v.__dict__.get(""get_arns"") or v.__dict__.get(""generate_arn""))<tab><tab><IF-STMT><tab><tab><tab>overrides.add(k)<tab>overrides = overrides.difference(<tab><tab>{<tab><tab><tab>""account"",<tab><tab><tab>""s3"",<tab><tab><tab>""hostedzone"",<tab><tab><tab>""log-group"",<tab><tab><tab>""rest-api"",<tab><tab><tab>""redshift-snapshot"",<tab><tab><tab>""rest-stage"",<tab><tab>}<tab>)<tab>if overrides:<tab><tab>raise ValueError(""unknown arn overrides in %s"" % ("", "".join(overrides)))",if arn_gen :,185
3058,"def _check_dsl_runner(self) -> None:<tab>""""""Checks if runner in dsl is Kubeflow V2 runner.""""""<tab>with open(self.flags_dict[labels.PIPELINE_DSL_PATH], ""r"") as f:<tab><tab>dsl_contents = f.read()<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""KubeflowV2DagRunner not found in dsl."")","if ""KubeflowV2DagRunner"" not in dsl_contents :",116
3059,"def create_warehouse(warehouse_name, properties=None, company=None):<tab>if not company:<tab><tab>company = ""_Test Company""<tab>warehouse_id = erpnext.encode_company_abbr(warehouse_name, company)<tab>if not frappe.db.exists(""Warehouse"", warehouse_id):<tab><tab>warehouse = frappe.new_doc(""Warehouse"")<tab><tab>warehouse.warehouse_name = warehouse_name<tab><tab>warehouse.parent_warehouse = ""All Warehouses - _TCUV""<tab><tab>warehouse.company = company<tab><tab>warehouse.account = get_warehouse_account(warehouse_name, company)<tab><tab><IF-STMT><tab><tab><tab>warehouse.update(properties)<tab><tab>warehouse.save()<tab><tab>return warehouse.name<tab>else:<tab><tab>return warehouse_id",if properties :,186
3060,"def _parse(self, contents):<tab>entries = []<tab>hostnames_found = set()<tab>for line in contents.splitlines():<tab><tab>if not len(line.strip()):<tab><tab><tab>entries.append((""blank"", [line]))<tab><tab><tab>continue<tab><tab>(head, tail) = chop_comment(line.strip(), ""#"")<tab><tab><IF-STMT><tab><tab><tab>entries.append((""all_comment"", [line]))<tab><tab><tab>continue<tab><tab>entries.append((""hostname"", [head, tail]))<tab><tab>hostnames_found.add(head)<tab>if len(hostnames_found) > 1:<tab><tab>raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found))<tab>return entries",if not len ( head ) :,167
3061,"def _get_omega(self):<tab>if self._omega is None:<tab><tab>n = self.get_drift_dim() // 2<tab><tab>omg = sympl.calc_omega(n)<tab><tab>if self.oper_dtype == Qobj:<tab><tab><tab>self._omega = Qobj(omg, dims=self.dyn_dims)<tab><tab><tab>self._omega_qobj = self._omega<tab><tab><IF-STMT><tab><tab><tab>self._omega = sp.csr_matrix(omg)<tab><tab>else:<tab><tab><tab>self._omega = omg<tab>return self._omega",elif self . oper_dtype == sp . csr_matrix :,163
3062,"def get_in_inputs(key, data):<tab>if isinstance(data, dict):<tab><tab>for k, v in data.items():<tab><tab><tab>if k == key:<tab><tab><tab><tab>return v<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out = get_in_inputs(key, v)<tab><tab><tab><tab>if out:<tab><tab><tab><tab><tab>return out<tab>elif isinstance(data, (list, tuple)):<tab><tab>out = [get_in_inputs(key, x) for x in data]<tab><tab>out = [x for x in out if x]<tab><tab>if out:<tab><tab><tab>return out[0]","elif isinstance ( v , ( list , tuple , dict ) ) :",160
3063,def visit_binary(binary):<tab>if binary.operator == operators.eq:<tab><tab>cols = util.column_set(chain(*[c.proxy_set for c in columns.difference(omit)]))<tab><tab><IF-STMT><tab><tab><tab>for c in reversed(columns):<tab><tab><tab><tab>if c.shares_lineage(binary.right) and (<tab><tab><tab><tab><tab>not only_synonyms or c.name == binary.left.name<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>omit.add(c)<tab><tab><tab><tab><tab>break,if binary . left in cols and binary . right in cols :,136
3064,"def wait_tasks_or_abort(futures, timeout=60, kill_switch_ev=None):<tab>try:<tab><tab>LazySingletonTasksCoordinator.wait_tasks(<tab><tab><tab>futures, return_when=FIRST_EXCEPTION, raise_exceptions=True<tab><tab>)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab># Used when we want to keep both raise the exception and wait for all tasks to finish<tab><tab><tab>kill_switch_ev.set()<tab><tab><tab>LazySingletonTasksCoordinator.wait_tasks(<tab><tab><tab><tab>futures,<tab><tab><tab><tab>return_when=ALL_COMPLETED,<tab><tab><tab><tab>raise_exceptions=False,<tab><tab><tab><tab>timeout=timeout,<tab><tab><tab>)<tab><tab>raise e",if kill_switch_ev is not None :,187
3065,"def is_valid(sample):<tab>if sample is None:<tab><tab>return False<tab>if isinstance(sample, tuple):<tab><tab>for s in sample:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, np.ndarray) and s.size == 0:<tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, collections.abc.Sequence) and len(s) == 0:<tab><tab><tab><tab>return False<tab>return True",if s is None :,114
3066,"def setVaName(self, va, parent=None):<tab>if parent is None:<tab><tab>parent = self<tab>curname = self.vw.getName(va)<tab>if curname is None:<tab><tab>curname = """"<tab>name, ok = QInputDialog.getText(parent, ""Enter..."", ""Name"", text=curname)<tab>if ok:<tab><tab>name = str(name)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Duplicate Name: %s"" % name)<tab><tab>self.vw.makeName(va, name)",if self . vw . vaByName ( name ) :,142
3067,"def generic_tag_compiler(params, defaults, name, node_class, parser, token):<tab>""Returns a template.Node subclass.""<tab>bits = token.split_contents()[1:]<tab>bmax = len(params)<tab>def_len = defaults and len(defaults) or 0<tab>bmin = bmax - def_len<tab>if len(bits) < bmin or len(bits) > bmax:<tab><tab><IF-STMT><tab><tab><tab>message = ""%s takes %s arguments"" % (name, bmin)<tab><tab>else:<tab><tab><tab>message = ""%s takes between %s and %s arguments"" % (name, bmin, bmax)<tab><tab>raise TemplateSyntaxError(message)<tab>return node_class(bits)",if bmin == bmax :,176
3068,"def extract_segmentation_mask(annotation):<tab>poly_specs = annotation[DensePoseDataRelative.S_KEY]<tab>if isinstance(poly_specs, torch.Tensor):<tab><tab># data is already given as mask tensors, no need to decode<tab><tab>return poly_specs<tab>import pycocotools.mask as mask_utils<tab>segm = torch.zeros((DensePoseDataRelative.MASK_SIZE,) * 2, dtype=torch.float32)<tab>for i in range(DensePoseDataRelative.N_BODY_PARTS):<tab><tab>poly_i = poly_specs[i]<tab><tab><IF-STMT><tab><tab><tab>mask_i = mask_utils.decode(poly_i)<tab><tab><tab>segm[mask_i > 0] = i + 1<tab>return segm",if poly_i :,184
3069,"def module_list(target, fast):<tab>""""""Find the list of modules to be compiled""""""<tab>modules = []<tab>native = native_modules(target)<tab>basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"")<tab>for name in os.listdir(basedir):<tab><tab>module_name, ext = os.path.splitext(name)<tab><tab><IF-STMT><tab><tab><tab>if module_name not in IGNORE_MODULES and module_name not in native:<tab><tab><tab><tab>if not (fast and module_name in KNOWN_PROBLEM_MODULES):<tab><tab><tab><tab><tab>modules.append(module_name)<tab>return set(modules)","if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :",185
3070,"def filelist_from_patterns(pats, rootdir=None):<tab>if rootdir is None:<tab><tab>rootdir = "".""<tab># filelist = []<tab>fileset = set([])<tab>lines = [line.strip() for line in pats]<tab>for line in lines:<tab><tab>pat = line[2:]<tab><tab>newfiles = glob(osp.join(rootdir, pat))<tab><tab>if line.startswith(""+""):<tab><tab><tab>fileset.update(newfiles)<tab><tab><IF-STMT><tab><tab><tab>fileset.difference_update(newfiles)<tab><tab>else:<tab><tab><tab>raise ValueError(""line must start with + or -"")<tab>filelist = list(fileset)<tab>return filelist","elif line . startswith ( ""-"" ) :",165
3071,"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]:<tab>statuses_by_refs = {u: [] for u in upstream}<tab>events = self.events or []  # type: List[V1EventTrigger]<tab>for e in events:<tab><tab>entity_ref = contexts_refs.get_entity_ref(e.ref)<tab><tab>if not entity_ref:<tab><tab><tab>continue<tab><tab>if entity_ref not in statuses_by_refs:<tab><tab><tab>continue<tab><tab>for kind in e.kinds:<tab><tab><tab>status = V1EventKind.events_statuses_mapping.get(kind)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statuses_by_refs[entity_ref].append(status)<tab>return statuses_by_refs",if status :,191
3072,"def __setitem__(self, key, value):<tab>if isinstance(value, (tuple, list)):<tab><tab>info, reference = value<tab><tab><IF-STMT><tab><tab><tab>self._reverse_infos[info] = len(self._infos)<tab><tab><tab>self._infos.append(info)<tab><tab>if reference not in self._reverse_references:<tab><tab><tab>self._reverse_references[reference] = len(self._references)<tab><tab><tab>self._references.append(reference)<tab><tab>self._trails[key] = ""%d,%d"" % (<tab><tab><tab>self._reverse_infos[info],<tab><tab><tab>self._reverse_references[reference],<tab><tab>)<tab>else:<tab><tab>raise Exception(""unsupported type '%s'"" % type(value))",if info not in self . _reverse_infos :,184
3073,"def ChangeStyle(self, combos):<tab>style = 0<tab>for combo in combos:<tab><tab><IF-STMT><tab><tab><tab>if combo.GetLabel() == ""TR_VIRTUAL"":<tab><tab><tab><tab>style = style | HTL.TR_VIRTUAL<tab><tab><tab>else:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>style = style | eval(""wx."" + combo.GetLabel())<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>style = style | eval(""HTL."" + combo.GetLabel())<tab>if self.GetAGWWindowStyleFlag() != style:<tab><tab>self.SetAGWWindowStyleFlag(style)",if combo . GetValue ( ) == 1 :,153
3074,"def _parse_csrf(self, response):<tab>for d in response:<tab><tab>if d.startswith(""Set-Cookie:""):<tab><tab><tab>for c in d.split("":"", 1)[1].split("";""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._CSRFtoken = c.strip("" \r\n"")<tab><tab><tab><tab><tab>log.verbose(""Got new cookie: %s"", self._CSRFtoken)<tab><tab><tab><tab><tab>break<tab><tab><tab>if self._CSRFtoken != None:<tab><tab><tab><tab>break","if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :",135
3075,"def test_page_size_matching_max_returned_rows(<tab>app_client_returned_rows_matches_page_size,):<tab>fetched = []<tab>path = ""/fixtures/no_primary_key.json""<tab>while path:<tab><tab>response = app_client_returned_rows_matches_page_size.get(path)<tab><tab>fetched.extend(response.json[""rows""])<tab><tab>assert len(response.json[""rows""]) in (1, 50)<tab><tab>path = response.json[""next_url""]<tab><tab><IF-STMT><tab><tab><tab>path = path.replace(""http://localhost"", """")<tab>assert 201 == len(fetched)",if path :,155
3076,"def get_mapping_exception_message(mappings: List[Tuple[Text, Text]]):<tab>""""""Return a message given a list of duplicates.""""""<tab>message = """"<tab>for name, action_name in mappings:<tab><tab><IF-STMT><tab><tab><tab>message += ""\n""<tab><tab>message += (<tab><tab><tab>""Intent '{}' is set to trigger action '{}', which is ""<tab><tab><tab>""not defined in the domain."".format(name, action_name)<tab><tab>)<tab>return message",if message :,113
3077,def cut(sentence):<tab>sentence = strdecode(sentence)<tab>blocks = re_han.split(sentence)<tab>for blk in blocks:<tab><tab>if re_han.match(blk):<tab><tab><tab>for word in __cut(blk):<tab><tab><tab><tab>if word not in Force_Split_Words:<tab><tab><tab><tab><tab>yield word<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>for c in word:<tab><tab><tab><tab><tab><tab>yield c<tab><tab>else:<tab><tab><tab>tmp = re_skip.split(blk)<tab><tab><tab>for x in tmp:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield x,if x :,156
3078,"def chop(expr, delta=10.0 ** (-10.0)):<tab>if isinstance(expr, Real):<tab><tab>if -delta < expr.get_float_value() < delta:<tab><tab><tab>return Integer(0)<tab>elif isinstance(expr, Complex) and expr.is_inexact():<tab><tab>real, imag = expr.real, expr.imag<tab><tab>if -delta < real.get_float_value() < delta:<tab><tab><tab>real = Integer(0)<tab><tab><IF-STMT><tab><tab><tab>imag = Integer(0)<tab><tab>return Complex(real, imag)<tab>elif isinstance(expr, Expression):<tab><tab>return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves])<tab>return expr",if - delta < imag . get_float_value ( ) < delta :,186
3079,"def make_row(self):<tab>res = []<tab>for i in range(self.num_cols):<tab><tab>t = sqlite3_column_type(self.stmnt, i)<tab><tab># print(""type"", t)<tab><tab>if t == SQLITE_INTEGER:<tab><tab><tab>res.append(sqlite3_column_int(self.stmnt, i))<tab><tab>elif t == SQLITE_FLOAT:<tab><tab><tab>res.append(sqlite3_column_double(self.stmnt, i))<tab><tab><IF-STMT><tab><tab><tab>res.append(sqlite3_column_text(self.stmnt, i))<tab><tab>else:<tab><tab><tab>raise NotImplementedError<tab>return tuple(res)",elif t == SQLITE_TEXT :,172
3080,"def try_convert(self, string):<tab>string = string.strip()<tab>try:<tab><tab>return int(string)<tab>except:<tab><tab>try:<tab><tab><tab>return float(string)<tab><tab>except:<tab><tab><tab>if string == ""True"":<tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>return string","if string == ""False"" :",93
3081,"def configure_create_table_epilogue(store):<tab>for val in ["""", "" ENGINE=InnoDB""]:<tab><tab>store.config[""create_table_epilogue""] = val<tab><tab>store._set_sql_flavour()<tab><tab><IF-STMT><tab><tab><tab>store.log.info(""create_table_epilogue='%s'"", val)<tab><tab><tab>return<tab>raise Exception(""Can not create a transactional table."")",if store . _test_transaction ( ) :,104
3082,"def _check_rule(self, match, target_dict, cred_dict):<tab>""""""Recursively checks credentials based on the brains rules.""""""<tab>try:<tab><tab>new_match_list = self.rules[match]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>new_match_list = (""rule:%s"" % self.default_rule,)<tab><tab>else:<tab><tab><tab>return False<tab>return self.check(new_match_list, target_dict, cred_dict)",if self . default_rule and match != self . default_rule :,129
3083,"def get_civil_names(self):<tab>congresspeople_ids = self.get_all_congresspeople_ids()<tab>for i, congress_id in enumerate(congresspeople_ids):<tab><tab>if not np.math.isnan(float(congress_id)):<tab><tab><tab>percentage = i / self.total * 100<tab><tab><tab>msg = ""Processed {} out of {} ({:.2f}%)""<tab><tab><tab>print(msg.format(i, self.total, percentage), end=""\r"")<tab><tab><tab>data = self.fetch_data_repository(congress_id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield dict(data)",if data is not None :,160
3084,"def parse_network_whitelist(self, network_whitelist_location):<tab>networks = []<tab>with open(network_whitelist_location, ""r"") as text_file:<tab><tab>for line in text_file:<tab><tab><tab>line = line.strip().strip(""'"").strip('""')<tab><tab><tab><IF-STMT><tab><tab><tab><tab>networks.append(line)<tab>return networks",if isIPv4 ( line ) or isIPv6 ( line ) :,98
3085,"def _pick(self, cum):<tab>if self._isleaf():<tab><tab>return self.bd[0], self.s<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self.left._pick(cum)<tab><tab>else:<tab><tab><tab>return self.right._pick(cum - self.left.s)",if cum < self . left . s :,83
3086,"def serialize_content_range(value):<tab>if isinstance(value, (tuple, list)):<tab><tab>if len(value) not in (2, 3):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""When setting content_range to a list/tuple, it must ""<tab><tab><tab><tab>""be length 2 or 3 (not %r)"" % value<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>begin, end = value<tab><tab><tab>length = None<tab><tab>else:<tab><tab><tab>begin, end, length = value<tab><tab>value = ContentRange(begin, end, length)<tab>value = str(value).strip()<tab>if not value:<tab><tab>return None<tab>return value",if len ( value ) == 2 :,169
3087,"def make_index_fields(rec):<tab>fields = {}<tab>for k, v in rec.iteritems():<tab><tab><IF-STMT><tab><tab><tab>fields[k] = v<tab><tab><tab>continue<tab><tab>if k == ""full_title"":<tab><tab><tab>fields[""title""] = [read_short_title(v)]<tab>return fields","if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :",93
3088,"def _sample_translation(reference, max_len):<tab>translation = reference[:]<tab>while np.random.uniform() < 0.8 and 1 < len(translation) < max_len:<tab><tab>trans_len = len(translation)<tab><tab>ind = np.random.randint(trans_len)<tab><tab>action = np.random.choice(actions)<tab><tab>if action == ""deletion"":<tab><tab><tab>del translation[ind]<tab><tab><IF-STMT><tab><tab><tab>ind_rep = np.random.randint(trans_len)<tab><tab><tab>translation[ind] = translation[ind_rep]<tab><tab>else:<tab><tab><tab>ind_insert = np.random.randint(trans_len)<tab><tab><tab>translation.insert(ind, translation[ind_insert])<tab>return translation","elif action == ""replacement"" :",186
3089,"def __call__(self, text: str) -> str:<tab>for t in self.cleaner_types:<tab><tab>if t == ""tacotron"":<tab><tab><tab>text = tacotron_cleaner.cleaners.custom_english_cleaners(text)<tab><tab>elif t == ""jaconv"":<tab><tab><tab>text = jaconv.normalize(text)<tab><tab><IF-STMT><tab><tab><tab>if vietnamese_cleaners is None:<tab><tab><tab><tab>raise RuntimeError(""Please install underthesea"")<tab><tab><tab>text = vietnamese_cleaners.vietnamese_cleaner(text)<tab><tab>else:<tab><tab><tab>raise RuntimeError(f""Not supported: type={t}"")<tab>return text","elif t == ""vietnamese"" :",174
3090,"def hook_GetVariable(ql, address, params):<tab>if params[""VariableName""] in ql.env:<tab><tab>var = ql.env[params[""VariableName""]]<tab><tab>read_len = read_int64(ql, params[""DataSize""])<tab><tab><IF-STMT><tab><tab><tab>write_int64(ql, params[""Attributes""], 0)<tab><tab>write_int64(ql, params[""DataSize""], len(var))<tab><tab>if read_len < len(var):<tab><tab><tab>return EFI_BUFFER_TOO_SMALL<tab><tab>if params[""Data""] != 0:<tab><tab><tab>ql.mem.write(params[""Data""], var)<tab><tab>return EFI_SUCCESS<tab>return EFI_NOT_FOUND","if params [ ""Attributes"" ] != 0 :",177
3091,"def test_setupapp(self, overrideRootMenu):<tab>""Call setupApp with each possible graphics type.""<tab>root = self.root<tab>flist = FileList(root)<tab>for tktype in alltypes:<tab><tab>with self.subTest(tktype=tktype):<tab><tab><tab>macosx._tk_type = tktype<tab><tab><tab>macosx.setupApp(root, flist)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertTrue(overrideRootMenu.called)<tab><tab><tab>overrideRootMenu.reset_mock()","if tktype in ( ""carbon"" , ""cocoa"" ) :",139
3092,"def names(self, persistent=None):<tab>u = set()<tab>result = []<tab>for s in [<tab><tab>self.__storage(None),<tab><tab>self.__storage(self.__category),<tab>]:<tab><tab>for b in s:<tab><tab><tab>if persistent is not None and b.persistent != persistent:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if b.name not in u:<tab><tab><tab><tab>result.append(b.name)<tab><tab><tab><tab>u.add(b.name)<tab>return result","if b . name . startswith ( ""__"" ) :",139
3093,"def _check_extra_specs(key, value=None):<tab>extra_specs = diff.get(""extra_specs"")<tab>specific_type = extra_specs.get(key) if extra_specs else None<tab>old_type = None<tab>new_type = None<tab>if specific_type:<tab><tab>old_type, new_type = specific_type<tab><tab><IF-STMT><tab><tab><tab>old_type = True if old_type and old_type.upper() == value else False<tab><tab><tab>new_type = True if new_type and new_type.upper() == value else False<tab>return old_type, new_type",if value :,148
3094,"def _write_lock_file(self, repo, force=True):  # type: (Repository, bool) -> None<tab>if force or (self._update and self._write_lock):<tab><tab>updated_lock = self._locker.set_lock_data(self._package, repo.packages)<tab><tab><IF-STMT><tab><tab><tab>self._io.write_line("""")<tab><tab><tab>self._io.write_line(""<info>Writing lock file</>"")",if updated_lock :,109
3095,"def process_message(self, msg):<tab>if msg[""type""] == ""sample"":<tab><tab>batch_shape = msg[""fn""].batch_shape<tab><tab><IF-STMT><tab><tab><tab>batch_shape = [1] * (-self.dim - len(batch_shape)) + list(batch_shape)<tab><tab><tab>batch_shape[self.dim] = self.size<tab><tab><tab>msg[""fn""] = msg[""fn""].expand(torch.Size(batch_shape))",if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size :,133
3096,"def _test_reducibility(self):<tab># make a copy of the graph<tab>graph = networkx.DiGraph(self._graph)<tab># preprocess: make it a super graph<tab>self._make_supergraph(graph)<tab>while True:<tab><tab>changed = False<tab><tab># find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode<tab><tab>changed |= self._remove_self_loop(graph)<tab><tab># find a node that has only one predecessor, and merge it with its predecessor (replace them with a<tab><tab># MultiNode)<tab><tab>changed |= self._merge_single_entry_node(graph)<tab><tab><IF-STMT><tab><tab><tab># a fixed-point is reached<tab><tab><tab>break",if not changed :,178
3097,"def __init__(self, roberta, num_classes=2, dropout=0.0, prefix=None, params=None):<tab>super(RoBERTaClassifier, self).__init__(prefix=prefix, params=params)<tab>self.roberta = roberta<tab>self._units = roberta._units<tab>with self.name_scope():<tab><tab>self.classifier = nn.HybridSequential(prefix=prefix)<tab><tab><IF-STMT><tab><tab><tab>self.classifier.add(nn.Dropout(rate=dropout))<tab><tab>self.classifier.add(nn.Dense(units=self._units, activation=""tanh""))<tab><tab>if dropout:<tab><tab><tab>self.classifier.add(nn.Dropout(rate=dropout))<tab><tab>self.classifier.add(nn.Dense(units=num_classes))",if dropout :,185
3098,"def get_object_from_name(self, name, check_symlinks=True):<tab>if not name:<tab><tab>return None<tab>name = name.rstrip(""\\"")<tab>for a, o in self.objects.items():<tab><tab>if not o.name:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return o<tab>if check_symlinks:<tab><tab>m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()]<tab><tab>if m:<tab><tab><tab>name = m[0]<tab><tab>return self.get_object_from_name(name, False)",if o . name . lower ( ) == name . lower ( ) :,156
3099,"def __call__(self):<tab>""""""Run all check_* methods.""""""<tab>if self.on:<tab><tab>oldformatwarning = warnings.formatwarning<tab><tab>warnings.formatwarning = self.formatwarning<tab><tab>try:<tab><tab><tab>for name in dir(self):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>method = getattr(self, name)<tab><tab><tab><tab><tab>if method and callable(method):<tab><tab><tab><tab><tab><tab>method()<tab><tab>finally:<tab><tab><tab>warnings.formatwarning = oldformatwarning","if name . startswith ( ""check_"" ) :",127
3100,"def __print__(self, defaults=False):<tab>if defaults:<tab><tab>print_func = str<tab>else:<tab><tab>print_func = repr<tab>pieces = []<tab>default_values = self.__defaults__<tab>for k in self.__fields__:<tab><tab>value = getattr(self, k)<tab><tab>if not defaults and value == default_values[k]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>print_func = repr  # keep quotes around strings<tab><tab>pieces.append(""%s=%s"" % (k, print_func(value)))<tab>if pieces or self.__base__:<tab><tab>return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces))<tab>else:<tab><tab>return """"","if isinstance ( value , basestring ) :",178
3101,"def apply(self, **kwargs: Any) -> None:<tab>for node in self.document.traverse(nodes.target):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>""ismod"" in node<tab><tab><tab>and node.parent.__class__ is nodes.section<tab><tab><tab>and<tab><tab><tab># index 0 is the section title node<tab><tab><tab>node.parent.index(node) == 1<tab><tab>):<tab><tab><tab>node.parent[""ids""][0:0] = node[""ids""]<tab><tab><tab>node.parent.remove(node)","if not node [ ""ids"" ] :",139
3102,"def add_special_token_2d(<tab>values: List[List[int]], special_token: int = 0, use_first_value: bool = False) -> List[List[int]]:<tab>results = torch.jit.annotate(List[List[int]], [])<tab>for value in values:<tab><tab>result = torch.jit.annotate(List[int], [])<tab><tab><IF-STMT><tab><tab><tab>special_token = value[0]<tab><tab>result.append(special_token)<tab><tab>result.extend(value)<tab><tab>result.append(special_token)<tab><tab>results.append(result)<tab>return results",if use_first_value and len ( value ) > 0 :,159
3103,"def test_import(self):<tab>TIMEOUT = 5<tab># Test for a deadlock when importing a module that runs the<tab># ThreadedResolver at import-time. See resolve_test.py for<tab># full explanation.<tab>command = [sys.executable, ""-c"", ""import tornado.test.resolve_test_helper""]<tab>start = time.time()<tab>popen = Popen(command, preexec_fn=lambda: signal.alarm(TIMEOUT))<tab>while time.time() - start < TIMEOUT:<tab><tab>return_code = popen.poll()<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(0, return_code)<tab><tab><tab>return  # Success.<tab><tab>time.sleep(0.05)<tab>self.fail(""import timed out"")",if return_code is not None :,183
3104,"def find_item_for_key(self, e):<tab>for item in self._items:<tab><tab>if item.keycode == e.key and item.shift == e.shift and item.alt == e.alt:<tab><tab><tab>focus = get_focus()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self._items.index(item)<tab><tab><tab>else:<tab><tab><tab><tab>return -1<tab>return -1","if self . command_is_enabled ( item , focus ) :",112
3105,"def check_app_config_brackets(self):<tab>for sn, app in cherrypy.tree.apps.items():<tab><tab>if not isinstance(app, cherrypy.Application):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for key in app.config.keys():<tab><tab><tab>if key.startswith(""["") or key.endswith(""]""):<tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab>""The application mounted at %r has config ""<tab><tab><tab><tab><tab>""section names with extraneous brackets: %r. ""<tab><tab><tab><tab><tab>""Config *files* need brackets; config *dicts* ""<tab><tab><tab><tab><tab>""(e.g. passed to tree.mount) do not."" % (sn, key)<tab><tab><tab><tab>)",if not app . config :,186
3106,"def got_arbiter_module_type_defined(self, mod_type):<tab>for a in self.arbiters:<tab><tab># Do like the linkify will do after....<tab><tab>for m in getattr(a, ""modules"", []):<tab><tab><tab># So look at what the arbiter try to call as module<tab><tab><tab>m = m.strip()<tab><tab><tab># Ok, now look in modules...<tab><tab><tab>for mod in self.modules:<tab><tab><tab><tab># try to see if this module is the good type<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># if so, the good name?<tab><tab><tab><tab><tab>if getattr(mod, ""module_name"", """").strip() == m:<tab><tab><tab><tab><tab><tab>return True<tab>return False","if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",199
3107,"def write_config_to_file(self, folder, filename, config):<tab>do_not_write = [""hyperparameter_search_space_updates""]<tab>with open(os.path.join(folder, filename), ""w"") as f:<tab><tab>f.write(<tab><tab><tab>""\n"".join(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>(key + ""="" + str(value))<tab><tab><tab><tab><tab>for (key, value) in sorted(config.items(), key=lambda x: x[0])<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>)",if not key in do_not_write,152
3108,"def parsing(self, parsing):  # type: (bool) -> None<tab>self._parsed = parsing<tab>for k, v in self._body:<tab><tab><IF-STMT><tab><tab><tab>v.value.parsing(parsing)<tab><tab>elif isinstance(v, AoT):<tab><tab><tab>for t in v.body:<tab><tab><tab><tab>t.value.parsing(parsing)","if isinstance ( v , Table ) :",93
3109,"def test_crashers_crash(self):<tab>for fname in glob.glob(CRASHER_FILES):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Some ""crashers"" only trigger an exception rather than a<tab><tab># segfault. Consider that an acceptable outcome.<tab><tab>if test.support.verbose:<tab><tab><tab>print(""Checking crasher:"", fname)<tab><tab>assert_python_failure(fname)",if os . path . basename ( fname ) in infinite_loops :,110
3110,"def __getitem__(self, k) -> ""SimMemView"":<tab>if isinstance(k, slice):<tab><tab>if k.step is not None:<tab><tab><tab>raise ValueError(""Slices with strides are not supported"")<tab><tab>elif k.start is None:<tab><tab><tab>raise ValueError(""Must specify start index"")<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Slices with stop index are not supported"")<tab><tab>else:<tab><tab><tab>addr = k.start<tab>elif self._type is not None and self._type._can_refine_int:<tab><tab>return self._type._refine(self, k)<tab>else:<tab><tab>addr = k<tab>return self._deeper(addr=addr)",elif k . stop is not None :,169
3111,"def get_lowest_wall_time(jsons):<tab>lowest_wall = None<tab>for j in jsons:<tab><tab><IF-STMT><tab><tab><tab>lowest_wall = j[""wall_time""]<tab><tab>if lowest_wall > j[""wall_time""]:<tab><tab><tab>lowest_wall = j[""wall_time""]<tab>return lowest_wall",if lowest_wall is None :,86
3112,"def extract_wav_headers(data):<tab># def search_subchunk(data, subchunk_id):<tab>pos = 12  # The size of the RIFF chunk descriptor<tab>subchunks = []<tab>while pos + 8 <= len(data) and len(subchunks) < 10:<tab><tab>subchunk_id = data[pos : pos + 4]<tab><tab>subchunk_size = struct.unpack_from(""<I"", data[pos + 4 : pos + 8])[0]<tab><tab>subchunks.append(WavSubChunk(subchunk_id, pos, subchunk_size))<tab><tab><IF-STMT><tab><tab><tab># 'data' is the last subchunk<tab><tab><tab>break<tab><tab>pos += subchunk_size + 8<tab>return subchunks","if subchunk_id == b""data"" :",183
3113,"def _any_targets_have_native_sources(self, targets):<tab># TODO(#5949): convert this to checking if the closure of python requirements has any<tab># platform-specific packages (maybe find the platforms there too?).<tab>for tgt in targets:<tab><tab>for type_constraint, target_predicate in self._native_target_matchers.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,115
3114,"def validate_memory(self, value):<tab>for k, v in value.viewitems():<tab><tab>if v is None:  # use NoneType to unset a value<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise serializers.ValidationError(""Process types can only contain [a-z]"")<tab><tab>if not re.match(MEMLIMIT_MATCH, str(v)):<tab><tab><tab>raise serializers.ValidationError(<tab><tab><tab><tab>""Limit format: <number><unit>, where unit = B, K, M or G""<tab><tab><tab>)<tab>return value","if not re . match ( PROCTYPE_MATCH , k ) :",141
3115,"def cart_number_checksum_validation(cls, number):<tab>digits = []<tab>even = False<tab>if not number.isdigit():<tab><tab>return False<tab>for digit in reversed(number):<tab><tab>digit = ord(digit) - ord(""0"")<tab><tab>if even:<tab><tab><tab>digit *= 2<tab><tab><tab><IF-STMT><tab><tab><tab><tab>digit = digit % 10 + digit // 10<tab><tab>digits.append(digit)<tab><tab>even = not even<tab>return sum(digits) % 10 == 0 if digits else False",if digit >= 10 :,127
3116,"def transform(a, cmds):<tab>buf = a.split(""\n"")<tab>for cmd in cmds:<tab><tab>ctype, line, col, char = cmd<tab><tab>if ctype == ""D"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>buf[line] = buf[line][:col] + buf[line][col + len(char) :]<tab><tab><tab>else:<tab><tab><tab><tab>buf[line] = buf[line] + buf[line + 1]<tab><tab><tab><tab>del buf[line + 1]<tab><tab>elif ctype == ""I"":<tab><tab><tab>buf[line] = buf[line][:col] + char + buf[line][col:]<tab><tab>buf = ""\n"".join(buf).split(""\n"")<tab>return ""\n"".join(buf)","if char != ""\n"" :",182
3117,"def get_partners(self) -> Dict[AbstractNode, Set[int]]:<tab>partners = {}  # type: Dict[AbstractNode, Set[int]]<tab>for edge in self.edges:<tab><tab>if edge.is_dangling():<tab><tab><tab>raise ValueError(""Cannot contract copy tensor with dangling edges"")<tab><tab>if self._is_my_trace(edge):<tab><tab><tab>continue<tab><tab>partner_node, shared_axis = self._get_partner(edge)<tab><tab><IF-STMT><tab><tab><tab>partners[partner_node] = set()<tab><tab>partners[partner_node].add(shared_axis)<tab>return partners",if partner_node not in partners :,163
3118,"def _bind_interactive_rez(self):<tab>if config.set_prompt and self.settings.prompt:<tab><tab>stored_prompt = os.getenv(""REZ_STORED_PROMPT_CMD"")<tab><tab>curr_prompt = stored_prompt or os.getenv(""PROMPT"", """")<tab><tab><IF-STMT><tab><tab><tab>self.setenv(""REZ_STORED_PROMPT_CMD"", curr_prompt)<tab><tab>new_prompt = ""%%REZ_ENV_PROMPT%%""<tab><tab>new_prompt = (<tab><tab><tab>(new_prompt + "" %s"") if config.prefix_prompt else (""%s "" + new_prompt)<tab><tab>)<tab><tab>new_prompt = new_prompt % curr_prompt<tab><tab>self._addline(""set PROMPT=%s"" % new_prompt)",if not stored_prompt :,182
3119,"def __listingColumns(self):<tab>columns = []<tab>for name in self.__getColumns():<tab><tab>definition = column(name)<tab><tab>if not definition:<tab><tab><tab>IECore.msg(<tab><tab><tab><tab>IECore.Msg.Level.Error,<tab><tab><tab><tab>""GafferImageUI.CatalogueUI"",<tab><tab><tab><tab>""No column registered with name '%s'"" % name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name)<tab><tab>else:<tab><tab><tab>c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name)<tab><tab>columns.append(c)<tab>return columns","if isinstance ( definition , IconColumn ) :",184
3120,"def _check_invalid_keys(self, section_name, section):<tab>for key in section:<tab><tab>key_name = str(key)<tab><tab>valid_key_names = [s[0] for s in self.keys]<tab><tab>is_valid_key = key_name in valid_key_names<tab><tab><IF-STMT><tab><tab><tab>err_msg = (<tab><tab><tab><tab>""'{0}' is not a valid key name for '{1}'. Must "" ""be one of these: {2}""<tab><tab><tab>).format(key_name, section_name, "", "".join(valid_key_names))<tab><tab><tab>raise InvalidConfig(err_msg)",if not is_valid_key :,160
3121,"def _get_startup_packages(lib_path: Path, packages) -> Set[str]:<tab>names = set()<tab>for path in lib_path.iterdir():<tab><tab>name = path.name<tab><tab>if name == ""__pycache__"":<tab><tab><tab>continue<tab><tab>if name.endswith("".py""):<tab><tab><tab>names.add(name.split(""."")[0])<tab><tab><IF-STMT><tab><tab><tab>names.add(name)<tab>if packages:<tab><tab>packages = {package.lower().replace(""-"", ""_"") for package in packages}<tab><tab>if len(names & packages) == len(packages):<tab><tab><tab>return packages<tab>return names","elif path . is_dir ( ) and ""."" not in name :",159
3122,"def sortkeypicker(keynames):<tab>negate = set()<tab>for i, k in enumerate(keynames):<tab><tab><IF-STMT><tab><tab><tab>keynames[i] = k[1:]<tab><tab><tab>negate.add(k[1:])<tab>def getit(adict):<tab><tab>composite = [adict[k] for k in keynames]<tab><tab>for i, (k, v) in enumerate(zip(keynames, composite)):<tab><tab><tab>if k in negate:<tab><tab><tab><tab>composite[i] = -v<tab><tab>return composite<tab>return getit","if k [ : 1 ] == ""-"" :",140
3123,"def iter_symbols(code):<tab>""""""Yield names and strings used by `code` and its nested code objects""""""<tab>for name in code.co_names:<tab><tab>yield name<tab>for const in code.co_consts:<tab><tab>if isinstance(const, six.string_types):<tab><tab><tab>yield const<tab><tab><IF-STMT><tab><tab><tab>for name in iter_symbols(const):<tab><tab><tab><tab>yield name","elif isinstance ( const , CodeType ) :",104
3124,"def set_study_directions(<tab>self, study_id: int, directions: Sequence[StudyDirection]) -> None:<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>current_directions = self._studies[study_id].directions<tab><tab><tab>if directions == current_directions:<tab><tab><tab><tab>return<tab><tab><tab>elif (<tab><tab><tab><tab>len(current_directions) == 1<tab><tab><tab><tab>and current_directions[0] == StudyDirection.NOT_SET<tab><tab><tab>):<tab><tab><tab><tab>self._studies[study_id].directions = list(directions)<tab><tab><tab><tab>self._backend.set_study_directions(study_id, directions)<tab><tab><tab><tab>return<tab>self._backend.set_study_directions(study_id, directions)",if study_id in self . _studies :,198
3125,"def PreprocessConditionalStatement(self, IfList, ReplacedLine):<tab>while self:<tab><tab><IF-STMT><tab><tab><tab>x = 1<tab><tab>elif not IfList:<tab><tab><tab>if self <= 2:<tab><tab><tab><tab>continue<tab><tab><tab>RegionSizeGuid = 3<tab><tab><tab>if not RegionSizeGuid:<tab><tab><tab><tab>RegionLayoutLine = 5<tab><tab><tab><tab>continue<tab><tab><tab>RegionLayoutLine = self.CurrentLineNumber<tab>return 1",if self . __Token :,111
3126,"def _check_blocking(self, current_time):<tab>if self._switch_flag is False:<tab><tab>active_greenlet = self._active_greenlet<tab><tab><IF-STMT><tab><tab><tab>self._notify_greenlet_blocked(active_greenlet, current_time)<tab>self._switch_flag = False",if active_greenlet is not None and active_greenlet != self . _hub :,90
3127,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(r""BlockDos\.net"", headers.get(HTTP_HEADER.SERVER, """"), re.I)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,109
3128,"def _fastqc_data_section(self, section_name):<tab>out = []<tab>in_section = False<tab>data_file = os.path.join(self._dir, ""fastqc_data.txt"")<tab>if os.path.exists(data_file):<tab><tab>with open(data_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>in_section = True<tab><tab><tab><tab>elif in_section:<tab><tab><tab><tab><tab>if line.startswith("">>END""):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>out.append(line.rstrip(""\r\n""))<tab>return out","if line . startswith ( "">>%s"" % section_name ) :",173
3129,"def shortcut(self, input, ch_out, stride, is_first, name):<tab>ch_in = input.shape[1]<tab>if ch_in != ch_out or stride != 1:<tab><tab><IF-STMT><tab><tab><tab>return self.conv_bn_layer(input, ch_out, 1, stride, name=name)<tab><tab>else:<tab><tab><tab>return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name)<tab>elif is_first:<tab><tab>return self.conv_bn_layer(input, ch_out, 1, stride, name=name)<tab>else:<tab><tab>return input",if is_first or stride == 1 :,162
3130,"def get_value_from_string(self, string_value):<tab>""""""Return internal representation starting from CFN/user-input value.""""""<tab>param_value = self.get_default_value()<tab>try:<tab><tab>if string_value is not None:<tab><tab><tab>string_value = str(string_value).strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>param_value = int(string_value)<tab>except ValueError:<tab><tab>self.pcluster_config.warn(<tab><tab><tab>""Unable to convert the value '{0}' to an Integer. ""<tab><tab><tab>""Using default value for parameter '{1}'"".format(string_value, self.key)<tab><tab>)<tab>return param_value","if string_value != ""NONE"" :",172
3131,"def get_running(workers):<tab>running = []<tab>for worker in workers:<tab><tab>current_test_name = worker.current_test_name<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dt = time.monotonic() - worker.start_time<tab><tab>if dt >= PROGRESS_MIN_TIME:<tab><tab><tab>text = ""%s (%s)"" % (current_test_name, format_duration(dt))<tab><tab><tab>running.append(text)<tab>return running",if not current_test_name :,120
3132,"def generate_data(self, request):<tab>""""""Generate data for the widget.""""""<tab>uptime = {}<tab>cache_stats = get_cache_stats()<tab>if cache_stats:<tab><tab>for hosts, stats in cache_stats:<tab><tab><tab>if stats[""uptime""] > 86400:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60 / 24<tab><tab><tab><tab>uptime[""unit""] = _(""days"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60<tab><tab><tab><tab>uptime[""unit""] = _(""hours"")<tab><tab><tab>else:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60<tab><tab><tab><tab>uptime[""unit""] = _(""minutes"")<tab>return {""cache_stats"": cache_stats, ""uptime"": uptime}","elif stats [ ""uptime"" ] > 3600 :",195
3133,"def add_actors(self):<tab>""""""Adds `self.actors` to the scene.""""""<tab>if not self._actors_added:<tab><tab>self.reader.render_window = self.scene.render_window<tab><tab>self._update_reader()<tab><tab>self._actors_added = True<tab><tab><IF-STMT><tab><tab><tab>self._visible_changed(self.visible)<tab><tab>self.scene.render()",if not self . visible :,103
3134,"def _add_uniqu_suffix(self, titles):<tab>counters = dict()<tab>titles_with_suffix = []<tab>for title in titles:<tab><tab>counters[title] = counters[title] + 1 if title in counters else 1<tab><tab><IF-STMT><tab><tab><tab>title = f""{title} ({counters[title]})""<tab><tab>titles_with_suffix.append(title)<tab>return titles_with_suffix",if counters [ title ] > 1 :,103
3135,"def _verify_udf_resources(self, job, config):<tab>udf_resources = config.get(""userDefinedFunctionResources"", ())<tab>self.assertEqual(len(job.udf_resources), len(udf_resources))<tab>for found, expected in zip(job.udf_resources, udf_resources):<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(found.udf_type, ""resourceUri"")<tab><tab><tab>self.assertEqual(found.value, expected[""resourceUri""])<tab><tab>else:<tab><tab><tab>self.assertEqual(found.udf_type, ""inlineCode"")<tab><tab><tab>self.assertEqual(found.value, expected[""inlineCode""])","if ""resourceUri"" in expected :",157
3136,"def __init__(<tab>self, layout, value=None, string=None, *, dtype: np.dtype = np.float64) -> None:<tab>""""""Constructor.""""""<tab>self.layout = layout<tab>if value is None:<tab><tab><IF-STMT><tab><tab><tab>self.value = np.zeros((self.layout.gaDims,), dtype=dtype)<tab><tab>else:<tab><tab><tab>self.value = layout.parse_multivector(string).value<tab>else:<tab><tab>self.value = np.array(value)<tab><tab>if self.value.shape != (self.layout.gaDims,):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""value must be a sequence of length %s"" % self.layout.gaDims<tab><tab><tab>)",if string is None :,180
3137,"def read_file(filename, print_error=True):<tab>""""""Returns the contents of a file.""""""<tab>try:<tab><tab>for encoding in [""utf-8"", ""latin1""]:<tab><tab><tab>try:<tab><tab><tab><tab>with io.open(filename, encoding=encoding) as fp:<tab><tab><tab><tab><tab>return fp.read()<tab><tab><tab>except UnicodeDecodeError:<tab><tab><tab><tab>pass<tab>except IOError as exception:<tab><tab><IF-STMT><tab><tab><tab>print(exception, file=sys.stderr)<tab><tab>return None",if print_error :,126
3138,"def get_albums_for_iter(self, iter_):<tab>obj = self.get_value(iter_)<tab>if isinstance(obj, AlbumNode):<tab><tab>return {obj.album}<tab>albums = set()<tab>for child_iter, value in self.iterrows(iter_):<tab><tab><IF-STMT><tab><tab><tab>albums.add(value.album)<tab><tab>else:<tab><tab><tab>albums.update(self.get_albums_for_iter(child_iter))<tab>return albums","if isinstance ( value , AlbumNode ) :",120
3139,"def wait_til_ready(cls, connector=None):<tab>if connector is None:<tab><tab>connector = cls.connector<tab>while True:<tab><tab>now = time.time()<tab><tab>next_iteration = now // 1.0 + 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>await cls._clock.run_til(next_iteration)<tab><tab>await asyncio.sleep(1.0)",if connector . ready :,106
3140,"def remove_property(self, key):  # type: (str) -> None<tab>with self.secure() as config:<tab><tab>keys = key.split(""."")<tab><tab>current_config = config<tab><tab>for i, key in enumerate(keys):<tab><tab><tab>if key not in current_config:<tab><tab><tab><tab>return<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del current_config[key]<tab><tab><tab><tab>break<tab><tab><tab>current_config = current_config[key]",if i == len ( keys ) - 1 :,122
3141,"def get(self, hash160, default=None):<tab>v = self.p2s_for_hash(hash160)<tab><IF-STMT><tab><tab>return v<tab>if hash160 not in self._secret_exponent_cache:<tab><tab>v = self.path_for_hash160(hash160)<tab><tab>if v:<tab><tab><tab>fingerprint, path = v<tab><tab><tab>for key in self._secrets.get(fingerprint, []):<tab><tab><tab><tab>subkey = key.subkey_for_path(path)<tab><tab><tab><tab>self._add_key_to_cache(subkey)<tab>return self._secret_exponent_cache.get(hash160, default)",if v :,155
3142,"def fetch_all(self, api_client, fetchstatuslogger, q, targets):<tab>self.fetchstatuslogger = fetchstatuslogger<tab>if targets != None:<tab><tab># Ensure targets is a tuple<tab><tab><IF-STMT><tab><tab><tab>targets = tuple(<tab><tab><tab><tab>targets,<tab><tab><tab>)<tab><tab>elif type(targets) != tuple:<tab><tab><tab>targets = tuple(targets)<tab>for target in targets:<tab><tab>self._fetch_targets(api_client, q, target)",if type ( targets ) != list and type ( targets ) != tuple :,130
3143,"def dgl_mp_batchify_fn(data):<tab>if isinstance(data[0], tuple):<tab><tab>data = zip(*data)<tab><tab>return [dgl_mp_batchify_fn(i) for i in data]<tab>for dt in data:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(dt, dgl.DGLGraph):<tab><tab><tab><tab>return [d for d in data if isinstance(d, dgl.DGLGraph)]<tab><tab><tab>elif isinstance(dt, nd.NDArray):<tab><tab><tab><tab>pad = Pad(axis=(1, 2), num_shards=1, ret_length=False)<tab><tab><tab><tab>data_list = [dt for dt in data if dt is not None]<tab><tab><tab><tab>return pad(data_list)",if dt is not None :,183
3144,"def capture_server(evt, buf, serv):<tab>try:<tab><tab>serv.listen(5)<tab><tab>conn, addr = serv.accept()<tab>except socket.timeout:<tab><tab>pass<tab>else:<tab><tab>n = 200<tab><tab>while n > 0:<tab><tab><tab>r, w, e = select.select([conn], [], [])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = conn.recv(10)<tab><tab><tab><tab># keep everything except for the newline terminator<tab><tab><tab><tab>buf.write(data.replace(""\n"", """"))<tab><tab><tab><tab>if ""\n"" in data:<tab><tab><tab><tab><tab>break<tab><tab><tab>n -= 1<tab><tab><tab>time.sleep(0.01)<tab><tab>conn.close()<tab>finally:<tab><tab>serv.close()<tab><tab>evt.set()",if r :,195
3145,"def elem():<tab>if ints_only:<tab><tab>return random.randint(0, 10000000000)<tab>else:<tab><tab>t = random.randint(0, 2)<tab><tab>if t == 0:<tab><tab><tab>return random.randint(0, 10000000000)<tab><tab>elif t == 1:<tab><tab><tab>return float(random.randint(0, 10000000000))<tab><tab><IF-STMT><tab><tab><tab>return strings[random.randint(0, len(strings) - 1)]<tab><tab>return random_string(random.randint(100, 1000))",elif strings is not None :,132
3146,"def has_changed(self, initial, data):<tab>if self.disabled:<tab><tab>return False<tab>if initial is None:<tab><tab>initial = ["""" for x in range(0, len(data))]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>initial = self.widget.decompress(initial)<tab>for field, initial, data in zip(self.fields, initial, data):<tab><tab>try:<tab><tab><tab>initial = field.to_python(initial)<tab><tab>except ValidationError:<tab><tab><tab>return True<tab><tab>if field.has_changed(initial, data):<tab><tab><tab>return True<tab>return False","if not isinstance ( initial , list ) :",151
3147,"def _load_testfile(filename, package, module_relative):<tab>if module_relative:<tab><tab>package = _normalize_module(package, 3)<tab><tab>filename = _module_relative_path(package, filename)<tab><tab><IF-STMT><tab><tab><tab>if hasattr(package.__loader__, ""get_data""):<tab><tab><tab><tab>file_contents = package.__loader__.get_data(filename)<tab><tab><tab><tab># get_data() opens files as 'rb', so one must do the equivalent<tab><tab><tab><tab># conversion as universal newlines would do.<tab><tab><tab><tab>return file_contents.replace(os.linesep, ""\n""), filename<tab>return open(filename).read(), filename","if hasattr ( package , ""__loader__"" ) :",163
3148,"def release(self):<tab>tid = _thread.get_ident()<tab>with self.lock:<tab><tab>if self.owner != tid:<tab><tab><tab>raise RuntimeError(""cannot release un-acquired lock"")<tab><tab>assert self.count > 0<tab><tab>self.count -= 1<tab><tab>if self.count == 0:<tab><tab><tab>self.owner = None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.waiters -= 1<tab><tab><tab><tab>self.wakeup.release()",if self . waiters :,117
3149,"def stage(<tab>self, x, num_modules, num_blocks, channels, multi_scale_output=True, name=None):<tab>out = x<tab>for i in range(num_modules):<tab><tab><IF-STMT><tab><tab><tab>out = self.high_resolution_module(<tab><tab><tab><tab>out,<tab><tab><tab><tab>num_blocks,<tab><tab><tab><tab>channels,<tab><tab><tab><tab>multi_scale_output=False,<tab><tab><tab><tab>name=name + ""_"" + str(i + 1),<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>out = self.high_resolution_module(<tab><tab><tab><tab>out, num_blocks, channels, name=name + ""_"" + str(i + 1)<tab><tab><tab>)<tab>return out",if i == num_modules - 1 and multi_scale_output == False :,193
3150,"def changeFrontAlteration(intV, alter):<tab># fati = front alteration transpose interval<tab>fati = self.frontAlterationTransposeInterval<tab>if fati:<tab><tab>newFati = interval.add([fati, intV])<tab><tab>self.frontAlterationTransposeInterval = newFati<tab><tab>self.frontAlterationAccidental.alter = (<tab><tab><tab>self.frontAlterationAccidental.alter + alter<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.frontAlterationTransposeInterval = None<tab><tab><tab>self.frontAlterationAccidental = None<tab>else:<tab><tab>self.frontAlterationTransposeInterval = intV<tab><tab>self.frontAlterationAccidental = pitch.Accidental(alter)",if self . frontAlterationAccidental . alter == 0 :,199
3151,"def set_to_train(self):<tab>for T in self.trainable_attributes():<tab><tab>for k, v in T.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c_f.set_requires_grad(v, requires_grad=False)<tab><tab><tab><tab>v.eval()<tab><tab><tab>else:<tab><tab><tab><tab>v.train()<tab>self.maybe_freeze_trunk_batchnorm()",if k in self . freeze_these :,107
3152,"def _migrate(self, sig=None, compact=True):<tab>with self.lock:<tab><tab>sig = sig or self.sig<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if sig in self.WORDS and len(self.WORDS[sig]) > 0:<tab><tab><tab>PostingList.Append(<tab><tab><tab><tab>self.session, sig, self.WORDS[sig], sig=sig, compact=compact<tab><tab><tab>)<tab><tab><tab>del self.WORDS[sig]",if sig in GPL_NEVER_MIGRATE :,123
3153,"def on_prediction_step(self, args, state, control, eval_dataloader=None, **kwargs):<tab>if self.prediction_bar is None:<tab><tab><IF-STMT><tab><tab><tab>self.prediction_bar = self.training_tracker.add_child(len(eval_dataloader))<tab><tab>else:<tab><tab><tab>self.prediction_bar = NotebookProgressBar(len(eval_dataloader))<tab><tab>self.prediction_bar.update(1)<tab>else:<tab><tab>self.prediction_bar.update(self.prediction_bar.value + 1)",if self . training_tracker is not None :,137
3154,"def show(self, indent=0):<tab>""""""Pretty print this structure.""""""<tab>if indent == 0:<tab><tab>print(""struct {}"".format(self.name))<tab>for field in self.fields:<tab><tab>if field.offset is None:<tab><tab><tab>offset = ""0x??""<tab><tab>else:<tab><tab><tab>offset = ""0x{:02x}"".format(field.offset)<tab><tab>print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type))<tab><tab><IF-STMT><tab><tab><tab>field.type.show(indent + 1)","if isinstance ( field . type , Structure ) :",143
3155,"def __exit__(self, exc, value, tb):<tab>for key in self.overrides.keys():<tab><tab>old_value = self.old[key]<tab><tab><IF-STMT><tab><tab><tab>delattr(self.instance, key)<tab><tab>else:<tab><tab><tab>setattr(self.instance, key, old_value)<tab>self.instance.save()",if old_value is NULL :,88
3156,"def complete(self, block):<tab>with self._condition:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if self._complete():<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab>if block:<tab><tab><tab>self._condition.wait_for(self._complete)<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab>return False",if not self . _final :,117
3157,"def parseArguments(self):<tab>args = []<tab>self.expect(""("")<tab>if not self.match("")""):<tab><tab>while self.startIndex < self.length:<tab><tab><tab>args.append(self.isolateCoverGrammar(self.parseAssignmentExpression))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.expectCommaSeparator()<tab>self.expect("")"")<tab>return args","if self . match ( "")"" ) :",95
3158,"def isValidDateString(config_param_name, value, valid_value):<tab>try:<tab><tab>if value == ""DD-MM-YYYY"":<tab><tab><tab>return value<tab><tab>day, month, year = value.split(""-"")<tab><tab><IF-STMT><tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(month) < 1 or int(month) > 12:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(year) < 1900 or int(year) > 2013:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>return value<tab>except Exception:<tab><tab>raise DateStringValueError(config_param_name, value)",if int ( day ) < 1 or int ( day ) > 31 :,187
3159,"def build_tree(path):<tab>tree = Tree()<tab>for basename, entry in trees[path].items():<tab><tab><IF-STMT><tab><tab><tab>mode = stat.S_IFDIR<tab><tab><tab>sha = build_tree(pathjoin(path, basename))<tab><tab>else:<tab><tab><tab>(mode, sha) = entry<tab><tab>tree.add(basename, mode, sha)<tab>object_store.add_object(tree)<tab>return tree.id","if isinstance ( entry , dict ) :",113
3160,"def get_quarantine_count(self):<tab>""""""get obj/container/account quarantine counts""""""<tab>qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0}<tab>qdir = ""quarantined""<tab>for device in os.listdir(self.devices):<tab><tab>for qtype in qcounts:<tab><tab><tab>qtgt = os.path.join(self.devices, device, qdir, qtype)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>linkcount = os.lstat(qtgt).st_nlink<tab><tab><tab><tab>if linkcount > 2:<tab><tab><tab><tab><tab>qcounts[qtype] += linkcount - 2<tab>return qcounts",if os . path . exists ( qtgt ) :,171
3161,"def _is_static_shape(self, shape):<tab>if shape is None or not isinstance(shape, list):<tab><tab>return False<tab>for dim_value in shape:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if dim_value < 0:<tab><tab><tab>raise Exception(""Negative dimension is illegal: %d"" % dim_value)<tab>return True","if not isinstance ( dim_value , int ) :",94
3162,"def BraceDetectAll(words):<tab># type: (List[compound_word]) -> List[word_t]<tab>""""""Return a new list of words, possibly with BracedTree instances.""""""<tab>out = []  # type: List[word_t]<tab>for w in words:<tab><tab># The shortest possible brace expansion is {,}.  This heuristic prevents<tab><tab># a lot of garbage from being created, since otherwise nearly every word<tab><tab># would be checked.  We could be even more precise but this is cheap.<tab><tab>if len(w.parts) >= 3:<tab><tab><tab>brace_tree = _BraceDetect(w)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out.append(brace_tree)<tab><tab><tab><tab>continue<tab><tab>out.append(w)<tab>return out",if brace_tree :,191
3163,"def __init__(original, self, *args, **kwargs):<tab>data = args[0] if len(args) > 0 else kwargs.get(""data"")<tab>if data is not None:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>""cannot gather example input when dataset is loaded from a file.""<tab><tab><tab><tab>)<tab><tab><tab>input_example_info = _InputExampleInfo(<tab><tab><tab><tab>input_example=deepcopy(data[:INPUT_EXAMPLE_SAMPLE_ROWS])<tab><tab><tab>)<tab><tab>except Exception as e:<tab><tab><tab>input_example_info = _InputExampleInfo(error_msg=str(e))<tab><tab>setattr(self, ""input_example_info"", input_example_info)<tab>original(self, *args, **kwargs)","if isinstance ( data , str ) :",198
3164,"def setRow(self, row, vals):<tab>if row > self.rowCount() - 1:<tab><tab>self.setRowCount(row + 1)<tab>for col in range(len(vals)):<tab><tab>val = vals[col]<tab><tab>item = self.itemClass(val, row)<tab><tab>item.setEditable(self.editable)<tab><tab>sortMode = self.sortModes.get(col, None)<tab><tab><IF-STMT><tab><tab><tab>item.setSortMode(sortMode)<tab><tab>format = self._formats.get(col, self._formats[None])<tab><tab>item.setFormat(format)<tab><tab>self.items.append(item)<tab><tab>self.setItem(row, col, item)<tab><tab>item.setValue(val)  # Required--the text-change callback is invoked",if sortMode is not None :,198
3165,"def wakeUp(self):<tab>""""""Write one byte to the pipe, and flush it.""""""<tab># We don't use fdesc.writeToFD since we need to distinguish<tab># between EINTR (try again) and EAGAIN (do nothing).<tab>if self.o is not None:<tab><tab>try:<tab><tab><tab>util.untilConcludes(os.write, self.o, b""x"")<tab><tab>except OSError as e:<tab><tab><tab># XXX There is no unit test for raising the exception<tab><tab><tab># for other errnos. See #4285.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",if e . errno != errno . EAGAIN :,158
3166,"def _setup(self, field_name, owner_model):<tab># Resolve possible name-based model references.<tab>resolved_classes = []<tab>for m in self.model_classes:<tab><tab><IF-STMT><tab><tab><tab>if m == owner_model.__name__:<tab><tab><tab><tab>resolved_classes.append(owner_model)<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>""PolyModelType: Unable to resolve model '{}'."".format(m)<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>resolved_classes.append(m)<tab>self.model_classes = tuple(resolved_classes)<tab>super(PolyModelType, self)._setup(field_name, owner_model)","if isinstance ( m , string_type ) :",176
3167,"def _wrap_forwarded(self, key, value):<tab>if isinstance(value, SourceCode) and value.late_binding:<tab><tab># get cached return value if present<tab><tab>value_ = self._late_binding_returnvalues.get(key, KeyError)<tab><tab>if value_ is KeyError:<tab><tab><tab># evaluate the late-bound function<tab><tab><tab>value_ = self._eval_late_binding(value)<tab><tab><tab>schema = self.late_bind_schemas.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value_ = schema.validate(value_)<tab><tab><tab># cache result of late bound func<tab><tab><tab>self._late_binding_returnvalues[key] = value_<tab><tab>return value_<tab>else:<tab><tab>return value",if schema is not None :,187
3168,"def convert(self, ctx, argument):<tab>arg = argument.replace(""0x"", """").lower()<tab>if arg[0] == ""#"":<tab><tab>arg = arg[1:]<tab>try:<tab><tab>value = int(arg, base=16)<tab><tab><IF-STMT><tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return discord.Colour(value=value)<tab>except ValueError:<tab><tab>arg = arg.replace("" "", ""_"")<tab><tab>method = getattr(discord.Colour, arg, None)<tab><tab>if arg.startswith(""from_"") or method is None or not inspect.ismethod(method):<tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return method()",if not ( 0 <= value <= 0xFFFFFF ) :,172
3169,"def get_versions(*, all=False, quiet=None):<tab>import bonobo<tab>from bonobo.util.pkgs import bonobo_packages<tab>yield _format_version(bonobo, quiet=quiet)<tab>if all:<tab><tab>for name in sorted(bonobo_packages):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>mod = __import__(name.replace(""-"", ""_""))<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>yield _format_version(mod, name=name, quiet=quiet)<tab><tab><tab><tab><tab>except Exception as exc:<tab><tab><tab><tab><tab><tab>yield ""{} ({})"".format(name, exc)<tab><tab><tab><tab>except ImportError as exc:<tab><tab><tab><tab><tab>yield ""{} is not importable ({})."".format(name, exc)","if name != ""bonobo"" :",188
3170,"def assertOperationsInjected(self, plan, **kwargs):<tab>for migration, _backward in plan:<tab><tab>operations = iter(migration.operations)<tab><tab>for operation in operations:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>next_operation = next(operations)<tab><tab><tab><tab>self.assertIsInstance(<tab><tab><tab><tab><tab>next_operation, contenttypes_management.RenameContentType<tab><tab><tab><tab>)<tab><tab><tab><tab>self.assertEqual(next_operation.app_label, migration.app_label)<tab><tab><tab><tab>self.assertEqual(next_operation.old_model, operation.old_name_lower)<tab><tab><tab><tab>self.assertEqual(next_operation.new_model, operation.new_name_lower)","if isinstance ( operation , migrations . RenameModel ) :",177
3171,"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab><IF-STMT><tab><tab><tab>if "","" in line or "";"" in line:<tab><tab><tab><tab>continue<tab><tab>yield line",if strip_delimiters :,145
3172,"def read_lccn(line, is_marc8=False):<tab>found = []<tab>for k, v in get_raw_subfields(line, [""a""]):<tab><tab>lccn = v.strip()<tab><tab>if re_question.match(lccn):<tab><tab><tab>continue<tab><tab>m = re_lccn.search(lccn)<tab><tab>if not m:<tab><tab><tab>continue<tab><tab># remove letters and bad chars<tab><tab>lccn = re_letters_and_bad.sub("""", m.group(1)).strip()<tab><tab><IF-STMT><tab><tab><tab>found.append(lccn)<tab>return found",if lccn :,151
3173,"def test_named_parameters_and_constraints(self):<tab>likelihood = gpytorch.likelihoods.GaussianLikelihood()<tab>model = ExactGPModel(None, None, likelihood)<tab>for name, _param, constraint in model.named_parameters_and_constraints():<tab><tab>if name == ""likelihood.noise_covar.raw_noise"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan)<tab><tab>elif name == ""mean_module.constant"":<tab><tab><tab>self.assertIsNone(constraint)<tab><tab>elif name == ""covar_module.raw_outputscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)","elif name == ""covar_module.base_kernel.raw_lengthscale"" :",192
3174,"def _cleanupSocket(self):<tab>""""""Close the Connection's socket.""""""<tab>try:<tab><tab>self._sock.shutdown(socket.SHUT_WR)<tab>except:<tab><tab>return<tab>try:<tab><tab>while True:<tab><tab><tab>r, w, e = select.select([self._sock], [], [])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>except:<tab><tab>pass<tab>self._sock.close()",if not r or not self . _sock . recv ( 1024 ) :,113
3175,"def fadeIn(self, acts=None, t=None, duration=None):<tab>""""""Gradually switch on the input list of meshes by increasing opacity.""""""<tab>if self.bookingMode:<tab><tab>acts, t, duration, rng = self._parse(acts, t, duration)<tab><tab>for tt in rng:<tab><tab><tab>alpha = linInterpolate(tt, [t, t + duration], [0, 1])<tab><tab><tab>self.events.append((tt, self.fadeIn, acts, alpha))<tab>else:<tab><tab>for a in self._performers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>a.alpha(self._inputvalues)<tab>return self",if a . alpha ( ) >= self . _inputvalues :,172
3176,"def get_config_updates_recursive(self):<tab>config_updates = self.config_updates.copy()<tab>for sr_path, subrunner in self.subrunners.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>update = subrunner.get_config_updates_recursive()<tab><tab>if update:<tab><tab><tab>config_updates[rel_path(self.path, sr_path)] = update<tab>return config_updates","if not is_prefix ( self . path , sr_path ) :",115
3177,"def setArgs(self, **kwargs):<tab>""""""See GridSearchCostGamma""""""<tab>for key, value in list(kwargs.items()):<tab><tab>if key in (""folds"", ""nfolds""):<tab><tab><tab>self._n_folds = int(value)<tab><tab><IF-STMT><tab><tab><tab>self._validator_kwargs[""max_epochs""] = value<tab><tab>else:<tab><tab><tab>GridSearchDOE.setArgs(self, **{key: value})","elif key in ( ""max_epochs"" ) :",111
3178,"def _parse_composite_axis(composite_axis_name: str):<tab>axes_names = [axis for axis in composite_axis_name.split("" "") if len(axis) > 0]<tab>for axis in axes_names:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>assert ""a"" <= axis[0] <= ""z""<tab><tab>for letter in axis:<tab><tab><tab>assert str.isdigit(letter) or ""a"" <= letter <= ""z""<tab>return axes_names","if axis == ""_"" :",117
3179,"def visit_For(self, node, for_branch=""body"", **kwargs):<tab>if for_branch == ""body"":<tab><tab>self.sym_visitor.visit(node.target, store_as_param=True)<tab><tab>branch = node.body<tab>elif for_branch == ""else"":<tab><tab>branch = node.else_<tab>elif for_branch == ""test"":<tab><tab>self.sym_visitor.visit(node.target, store_as_param=True)<tab><tab><IF-STMT><tab><tab><tab>self.sym_visitor.visit(node.test)<tab><tab>return<tab>else:<tab><tab>raise RuntimeError(""Unknown for branch"")<tab>for item in branch or ():<tab><tab>self.sym_visitor.visit(item)",if node . test is not None :,178
3180,def contains_only_whitespace(node):<tab>if is_tag(node):<tab><tab><IF-STMT><tab><tab><tab>if not any([unicode(s).strip() for s in node.contents]):<tab><tab><tab><tab>return True<tab>return False,if not any ( [ not is_text ( s ) for s in node . contents ] ) :,72
3181,"def dir_tag_click(event):<tab>mouse_index = self.path_bar.index(""@%d,%d"" % (event.x, event.y))<tab>lineno = int(float(mouse_index))<tab>if lineno == 1:<tab><tab>self.request_focus_into("""")<tab>else:<tab><tab>assert lineno == 2<tab><tab>dir_range = get_dir_range(event)<tab><tab>if dir_range:<tab><tab><tab>_, end_index = dir_range<tab><tab><tab>path = self.path_bar.get(""2.0"", end_index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path += ""\\""<tab><tab><tab>self.request_focus_into(path)","if path . endswith ( "":"" ) :",168
3182,"def validate_employee_id(self):<tab>if self.employee:<tab><tab>sales_person = frappe.db.get_value(""Sales Person"", {""employee"": self.employee})<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Another Sales Person {0} exists with the same Employee id"").format(<tab><tab><tab><tab><tab>sales_person<tab><tab><tab><tab>)<tab><tab><tab>)",if sales_person and sales_person != self . name :,116
3183,"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/infer""):<tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))","if ""init"" not in item . keywords :",102
3184,"def poll(self, timeout):<tab>if timeout < 0:<tab><tab>timeout = None  # kqueue behaviour<tab>events = self._kqueue.control(None, KqueueLoop.MAX_EVENTS, timeout)<tab>results = defaultdict(lambda: POLL_NULL)<tab>for e in events:<tab><tab>fd = e.ident<tab><tab>if e.filter == select.KQ_FILTER_READ:<tab><tab><tab>results[fd] |= POLL_IN<tab><tab><IF-STMT><tab><tab><tab>results[fd] |= POLL_OUT<tab>return results.items()",elif e . filter == select . KQ_FILTER_WRITE :,142
3185,"def _read_dimensions(self, *dimnames, **kwargs):<tab>path = kwargs.get(""path"", ""/"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return [self.rootgrp.dimensions[dname] for dname in dimnames]<tab><tab>group = self.path2group[path]<tab><tab>return [group.dimensions[dname] for dname in dimnames]<tab>except KeyError:<tab><tab>raise self.Error(<tab><tab><tab>""In file %s:\nError while reading dimensions: `%s` with kwargs: `%s`""<tab><tab><tab>% (self.path, dimnames, kwargs)<tab><tab>)","if path == ""/"" :",150
3186,"def spam_to_me(address):<tab>sock = eventlet.connect(address)<tab>while True:<tab><tab>try:<tab><tab><tab>sock.sendall(b""hello world"")<tab><tab><tab># Arbitrary delay to not use all available CPU, keeps the test<tab><tab><tab># running quickly and reliably under a second<tab><tab><tab>time.sleep(0.001)<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>raise",if get_errno ( e ) == errno . EPIPE :,122
3187,"def has_hash_of(self, destpath, code, package_level):<tab>""""""Determine if a file has the hash of the code.""""""<tab>if destpath is not None and os.path.isfile(destpath):<tab><tab>with univ_open(destpath, ""r"") as opened:<tab><tab><tab>compiled = readfile(opened)<tab><tab>hashash = gethash(compiled)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False","if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :",126
3188,"def insert(self, index, item):<tab>if len(self.lists) == 1:<tab><tab>self.lists[0].insert(index, item)<tab><tab>self._balance_list(0)<tab>else:<tab><tab>list_idx, rel_idx = self._translate_index(index)<tab><tab><IF-STMT><tab><tab><tab>raise IndexError()<tab><tab>self.lists[list_idx].insert(rel_idx, item)<tab><tab>self._balance_list(list_idx)<tab>return",if list_idx is None :,123
3189,"def _parse_class_simplified(symbol):<tab>results = {}<tab>name = symbol.name + ""(""<tab>name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases])<tab>name += "")""<tab>for sym in symbol.body:<tab><tab>if isinstance(sym, ast.FunctionDef):<tab><tab><tab>result = _parse_function_simplified(sym, symbol.name)<tab><tab><tab>results.update(result)<tab><tab><IF-STMT><tab><tab><tab>result = _parse_class_simplified(sym)<tab><tab><tab>results.update(result)<tab>lineno = symbol.lineno<tab>for decorator in symbol.decorator_list:<tab><tab>lineno += 1<tab>results[lineno] = (name, ""c"")<tab>return results","elif isinstance ( sym , ast . ClassDef ) :",181
3190,"def append_vars(pairs, result):<tab>for name, value in sorted(pairs.items()):<tab><tab>if isinstance(value, list):<tab><tab><tab>value = ""[%s]"" % "","".join(value)<tab><tab><IF-STMT><tab><tab><tab>result.append(""%s:%s=%s"" % (package, name, value))<tab><tab>else:<tab><tab><tab>result.append(""%s=%s"" % (name, value))",if package :,99
3191,"def nextEditable(self):<tab>""""""Moves focus of the cursor to the next editable window""""""<tab>if self.currentEditable is None:<tab><tab><IF-STMT><tab><tab><tab>self._currentEditableRef = self._editableChildren[0]<tab>else:<tab><tab>for ref in weakref.getweakrefs(self.currentEditable):<tab><tab><tab>if ref in self._editableChildren:<tab><tab><tab><tab>cei = self._editableChildren.index(ref)<tab><tab><tab><tab>nei = cei + 1<tab><tab><tab><tab>if nei >= len(self._editableChildren):<tab><tab><tab><tab><tab>nei = 0<tab><tab><tab><tab>self._currentEditableRef = self._editableChildren[nei]<tab>return self.currentEditable",if len ( self . _editableChildren ) :,179
3192,"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict) and k != ""headers"":<tab><tab><tab>if not everythingIsUnicode(v):<tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>elif isinstance(i, _bytes):<tab><tab><tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True","elif isinstance ( v , _bytes ) :",158
3193,"def is_valid(sample):<tab>if sample is None:<tab><tab>return False<tab>if isinstance(sample, tuple):<tab><tab>for s in sample:<tab><tab><tab>if s is None:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, collections.abc.Sequence) and len(s) == 0:<tab><tab><tab><tab>return False<tab>return True","elif isinstance ( s , np . ndarray ) and s . size == 0 :",114
3194,"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab>if ""attributes"" in conf[""properties""]:<tab><tab><tab>if ""exp"" in conf[""properties""][""attributes""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED","if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :",82
3195,"def encode(self):<tab>if self.expr in gpregs.expr:<tab><tab>self.value = gpregs.expr.index(self.expr)<tab><tab>self.parent.rot2.value = 0<tab>elif isinstance(self.expr, ExprOp) and self.expr.op == allshifts[3]:<tab><tab>reg, value = self.expr.args<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.value = gpregs.expr.index(reg)<tab><tab>if not isinstance(value, ExprInt):<tab><tab><tab>return False<tab><tab>value = int(value)<tab><tab>if not value in [8, 16, 24]:<tab><tab><tab>return False<tab><tab>self.parent.rot2.value = value // 8<tab>return True",if reg not in gpregs . expr :,192
3196,"def validate_transaction_reference(self):<tab>bank_account = self.paid_to if self.payment_type == ""Receive"" else self.paid_from<tab>bank_account_type = frappe.db.get_value(""Account"", bank_account, ""account_type"")<tab>if bank_account_type == ""Bank"":<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Reference No and Reference Date is mandatory for Bank transaction"")<tab><tab><tab>)",if not self . reference_no or not self . reference_date :,128
3197,"def monad(self):<tab>if not self.cls_bl_idname:<tab><tab>return None<tab>for monad in bpy.data.node_groups:<tab><tab>if hasattr(monad, ""cls_bl_idname""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return monad<tab>return None",if monad . cls_bl_idname == self . cls_bl_idname :,93
3198,"def _create_mask(self, plen):<tab>mask = []<tab>for i in range(16):<tab><tab>if plen >= 8:<tab><tab><tab>mask.append(0xFF)<tab><tab><IF-STMT><tab><tab><tab>mask.append(0xFF >> (8 - plen) << (8 - plen))<tab><tab>else:<tab><tab><tab>mask.append(0x00)<tab><tab>plen -= 8<tab>return mask",elif plen > 0 :,107
3199,"def dataset_to_stream(dataset, input_name):<tab>""""""Takes a tf.Dataset and creates a numpy stream of ready batches.""""""<tab># All input-pipeline processing should be on CPU.<tab>for example in fastmath.dataset_as_numpy(dataset):<tab><tab>features = example[0]<tab><tab>inp, out = features[input_name], example[1]<tab><tab>mask = features[""mask""] if ""mask"" in features else None<tab><tab># Some accelerators don't handle uint8 well, cast to int.<tab><tab><IF-STMT><tab><tab><tab>inp = inp.astype(np.int32)<tab><tab>if isinstance(out, np.uint8):<tab><tab><tab>out = out.astype(np.int32)<tab><tab>yield (inp, out) if mask is None else (inp, out, mask)","if isinstance ( inp , np . uint8 ) :",198
3200,"def _idle_redraw_cb(self):<tab>assert self._idle_redraw_src_id is not None<tab>queue = self._idle_redraw_queue<tab>if len(queue) > 0:<tab><tab>bbox = queue.pop(0)<tab><tab><IF-STMT><tab><tab><tab>super(CanvasRenderer, self).queue_draw()<tab><tab>else:<tab><tab><tab>super(CanvasRenderer, self).queue_draw_area(*bbox)<tab>if len(queue) == 0:<tab><tab>self._idle_redraw_src_id = None<tab><tab>return False<tab>return True",if bbox is None :,138
3201,"def mutated(self, indiv):<tab>""""""mutate some genes of the given individual""""""<tab>res = indiv.copy()<tab># to avoid having a child identical to one of the currentpopulation'''<tab>for i in range(self.numParameters):<tab><tab><IF-STMT><tab><tab><tab>if self.xBound is None:<tab><tab><tab><tab>res[i] = indiv[i] + gauss(0, self.mutationStdDev)<tab><tab><tab>else:<tab><tab><tab><tab>res[i] = max(<tab><tab><tab><tab><tab>min(indiv[i] + gauss(0, self.mutationStdDev), self.maxs[i]),<tab><tab><tab><tab><tab>self.mins[i],<tab><tab><tab><tab>)<tab>return res",if random ( ) < self . mutationProb :,177
3202,"def _justifyDrawParaLine(tx, offset, extraspace, words, last=0):<tab>setXPos(tx, offset)<tab>text = b"" "".join(words)<tab>if last:<tab><tab># last one, left align<tab><tab>tx._textOut(text, 1)<tab>else:<tab><tab>nSpaces = len(words) - 1<tab><tab><IF-STMT><tab><tab><tab>tx.setWordSpace(extraspace / float(nSpaces))<tab><tab><tab>tx._textOut(text, 1)<tab><tab><tab>tx.setWordSpace(0)<tab><tab>else:<tab><tab><tab>tx._textOut(text, 1)<tab>setXPos(tx, -offset)<tab>return offset",if nSpaces :,168
3203,"def _read_0(self, stream):<tab>r = b""""<tab>while True:<tab><tab>c = stream.read(2)<tab><tab><IF-STMT><tab><tab><tab>raise EOFError()<tab><tab>if c == b""\x00\x00"":<tab><tab><tab>break<tab><tab>r += c<tab>return r.decode(self.encoding)",if len ( c ) != 2 :,87
3204,"def run(self, app, editor, args):<tab>line_nums = []<tab>for cursor in editor.cursors:<tab><tab><IF-STMT><tab><tab><tab>line_nums.append(cursor.y)<tab><tab><tab>data = editor.lines[cursor.y].get_data().upper()<tab><tab><tab>editor.lines[cursor.y].set_data(data)",if cursor . y not in line_nums :,94
3205,"def create_default_energy_point_rules():<tab>for rule in get_default_energy_point_rules():<tab><tab># check if any rule for ref. doctype exists<tab><tab>rule_exists = frappe.db.exists(<tab><tab><tab>""Energy Point Rule"", {""reference_doctype"": rule.get(""reference_doctype"")}<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>doc = frappe.get_doc(rule)<tab><tab>doc.insert(ignore_permissions=True)",if rule_exists :,127
3206,"def __new__(cls, *nodes):<tab>if not nodes:<tab><tab>raise TypeError(""DisjunctionNode() requires at least one node"")<tab>elif len(nodes) == 1:<tab><tab>return nodes[0]<tab>self = super(DisjunctionNode, cls).__new__(cls)<tab>self.__nodes = []<tab># TODO: Remove duplicates?<tab>for node in nodes:<tab><tab>if not isinstance(node, Node):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""DisjunctionNode() expects Node instances as arguments;""<tab><tab><tab><tab>"" received a non-Node instance %r"" % node<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.__nodes.extend(node.__nodes)<tab><tab>else:<tab><tab><tab>self.__nodes.append(node)<tab>return self","if isinstance ( node , DisjunctionNode ) :",191
3207,def dfs(v: str) -> Iterator[Set[str]]:<tab>index[v] = len(stack)<tab>stack.append(v)<tab>boundaries.append(index[v])<tab>for w in edges[v]:<tab><tab>if w not in index:<tab><tab><tab>yield from dfs(w)<tab><tab><IF-STMT><tab><tab><tab>while index[w] < boundaries[-1]:<tab><tab><tab><tab>boundaries.pop()<tab>if boundaries[-1] == index[v]:<tab><tab>boundaries.pop()<tab><tab>scc = set(stack[index[v] :])<tab><tab>del stack[index[v] :]<tab><tab>identified.update(scc)<tab><tab>yield scc,elif w not in identified :,162
3208,"def unpack_item_obj(map_uuid_global_id, misp_obj):<tab>obj_meta = get_object_metadata(misp_obj)<tab>obj_id = None<tab>io_content = None<tab>for attribute in misp_obj.attributes:<tab><tab><IF-STMT><tab><tab><tab>obj_id = attribute.value  # # TODO: sanitize<tab><tab><tab>io_content = attribute.data  # # TODO: check if type == io<tab>if obj_id and io_content:<tab><tab>res = Item.create_item(obj_id, obj_meta, io_content)<tab><tab>map_uuid_global_id[misp_obj.uuid] = get_global_id(""item"", obj_id)","if attribute . object_relation == ""raw-data"" :",182
3209,"def parse(self, response):<tab>soup = BeautifulSoup(response.content.decode(""utf-8"", ""ignore""), ""lxml"")<tab>image_divs = soup.find_all(""div"", class_=""imgpt"")<tab>pattern = re.compile(r""murl\"":\""(.*?)\.jpg"")<tab>for div in image_divs:<tab><tab>href_str = html_parser.HTMLParser().unescape(div.a[""m""])<tab><tab>match = pattern.search(href_str)<tab><tab><IF-STMT><tab><tab><tab>name = match.group(1) if six.PY3 else match.group(1).encode(""utf-8"")<tab><tab><tab>img_url = ""{}.jpg"".format(name)<tab><tab><tab>yield dict(file_url=img_url)",if match :,180
3210,"def filter_errors(self, errors: List[str]) -> List[str]:<tab>real_errors: List[str] = list()<tab>current_file = __file__<tab>current_path = os.path.split(current_file)<tab>for line in errors:<tab><tab>line = line.strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>fn, lno, lvl, msg = self.parse_trace_line(line)<tab><tab><IF-STMT><tab><tab><tab>_path = os.path.split(fn)<tab><tab><tab>if _path[-1] != current_path[-1]:<tab><tab><tab><tab>continue<tab><tab>real_errors.append(line)<tab>return real_errors",if fn is not None :,171
3211,"def decompileFormat1(self, reader, otFont):<tab>self.classDefs = classDefs = []<tab>startGlyphID = reader.readUShort()<tab>glyphCount = reader.readUShort()<tab>for i in range(glyphCount):<tab><tab>glyphName = otFont.getglyphName(startGlyphID + i)<tab><tab>classValue = reader.readUShort()<tab><tab><IF-STMT><tab><tab><tab>classDefs.append((glyphName, classValue))",if classValue :,118
3212,"def compress(self, data_list):<tab>if len(data_list) == 2:<tab><tab>value, lookup_expr = data_list<tab><tab><IF-STMT><tab><tab><tab>if lookup_expr not in EMPTY_VALUES:<tab><tab><tab><tab>return Lookup(value=value, lookup_expr=lookup_expr)<tab><tab><tab>else:<tab><tab><tab><tab>raise forms.ValidationError(<tab><tab><tab><tab><tab>self.error_messages[""lookup_required""], code=""lookup_required""<tab><tab><tab><tab>)<tab>return None",if value not in EMPTY_VALUES :,127
3213,"def open_compat(path, mode=""r""):<tab>if mode in [""r"", ""rb""] and not os.path.exists(path):<tab><tab>raise FileNotFoundError(u'The file ""%s"" could not be found' % path)<tab>if sys.version_info >= (3,):<tab><tab>encoding = ""utf-8""<tab><tab>errors = ""replace""<tab><tab><IF-STMT><tab><tab><tab>encoding = None<tab><tab><tab>errors = None<tab><tab>return open(path, mode, encoding=encoding, errors=errors)<tab>else:<tab><tab>return open(path, mode)","if mode in [ ""rb"" , ""wb"" , ""ab"" ] :",145
3214,"def filter_errors(self, errors: List[str]) -> List[str]:<tab>real_errors: List[str] = list()<tab>current_file = __file__<tab>current_path = os.path.split(current_file)<tab>for line in errors:<tab><tab>line = line.strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>fn, lno, lvl, msg = self.parse_trace_line(line)<tab><tab>if fn is not None:<tab><tab><tab>_path = os.path.split(fn)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>real_errors.append(line)<tab>return real_errors",if _path [ - 1 ] != current_path [ - 1 ] :,171
3215,"def filter_by_level(record, level_per_module):<tab>name = record[""name""]<tab>level = 0<tab>if name in level_per_module:<tab><tab>level = level_per_module[name]<tab>elif name is not None:<tab><tab>lookup = """"<tab><tab>if """" in level_per_module:<tab><tab><tab>level = level_per_module[""""]<tab><tab>for n in name.split("".""):<tab><tab><tab>lookup += n<tab><tab><tab><IF-STMT><tab><tab><tab><tab>level = level_per_module[lookup]<tab><tab><tab>lookup += "".""<tab>if level is False:<tab><tab>return False<tab>return record[""level""].no >= level",if lookup in level_per_module :,166
3216,"def CountButtons(self):<tab>""""""Returns the number of visible buttons in the docked pane.""""""<tab>n = 0<tab>if self.HasCaption() or self.HasCaptionLeft():<tab><tab>if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame):<tab><tab><tab>return 1<tab><tab>if self.HasCloseButton():<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>if self.HasMinimizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasPinButton():<tab><tab><tab>n += 1<tab>return n",if self . HasMaximizeButton ( ) :,149
3217,"def search(a, b, desired):<tab>if a == b:<tab><tab>return a<tab>if abs(b - a) < 0.005:<tab><tab>ca = count(a)<tab><tab>cb = count(b)<tab><tab>dista = abs(desired - ca)<tab><tab>distb = abs(desired - cb)<tab><tab><IF-STMT><tab><tab><tab>return a<tab><tab>else:<tab><tab><tab>return b<tab>m = (a + b) / 2.0<tab>cm = count(m)<tab>if desired < cm:<tab><tab>return search(m, b, desired)<tab>else:<tab><tab>return search(a, m, desired)",if dista < distb :,161
3218,"def force_ipv4(self, *args):<tab>""""""only ipv4 localhost in /etc/hosts""""""<tab>logg.debug(""checking /etc/hosts for '::1 localhost'"")<tab>lines = []<tab>for line in open(self.etc_hosts()):<tab><tab><IF-STMT><tab><tab><tab>newline = re.sub(""\\slocalhost\\s"", "" "", line)<tab><tab><tab>if line != newline:<tab><tab><tab><tab>logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip())<tab><tab><tab><tab>line = newline<tab><tab>lines.append(line)<tab>f = open(self.etc_hosts(), ""w"")<tab>for line in lines:<tab><tab>f.write(line)<tab>f.close()","if ""::1"" in line :",182
3219,"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]:<tab>yield ""Core"", ""0""<tab>for _dir in data_manager.cog_data_path().iterdir():<tab><tab>fpath = _dir / ""settings.json""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with fpath.open() as f:<tab><tab><tab>try:<tab><tab><tab><tab>data = json.load(f)<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>continue<tab><tab>if not isinstance(data, dict):<tab><tab><tab>continue<tab><tab>cog_name = _dir.stem<tab><tab>for cog_id, inner in data.items():<tab><tab><tab>if not isinstance(inner, dict):<tab><tab><tab><tab>continue<tab><tab><tab>yield cog_name, cog_id",if not fpath . exists ( ) :,192
3220,"def _get_dbutils():<tab>try:<tab><tab>import IPython<tab><tab>ip_shell = IPython.get_ipython()<tab><tab><IF-STMT><tab><tab><tab>raise _NoDbutilsError<tab><tab>return ip_shell.ns_table[""user_global""][""dbutils""]<tab>except ImportError:<tab><tab>raise _NoDbutilsError<tab>except KeyError:<tab><tab>raise _NoDbutilsError",if ip_shell is None :,97
3221,"def _bytecode_filenames(self, py_filenames):<tab>bytecode_files = []<tab>for py_file in py_filenames:<tab><tab># Since build_py handles package data installation, the<tab><tab># list of outputs can contain more than just .py files.<tab><tab># Make sure we only report bytecode for the .py files.<tab><tab>ext = os.path.splitext(os.path.normcase(py_file))[1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if self.compile:<tab><tab><tab>bytecode_files.append(py_file + ""c"")<tab><tab>if self.optimize > 0:<tab><tab><tab>bytecode_files.append(py_file + ""o"")<tab>return bytecode_files",if ext != PYTHON_SOURCE_EXTENSION :,175
3222,"def compute_distances_mu(line, pts, result, gates, tolerance):<tab>""""""calculate all distances with mathuutils""""""<tab>line_origin = V(line[0])<tab>line_end = V(line[-1])<tab>local_result = [[], [], [], [], []]<tab>for point in pts:<tab><tab>data = compute_distance(V(point), line_origin, line_end, tolerance)<tab><tab>for i, res in enumerate(local_result):<tab><tab><tab>res.append(data[i])<tab>for i, res in enumerate(result):<tab><tab><IF-STMT><tab><tab><tab>res.append(local_result[i])",if gates [ i ] :,153
3223,"def _get_next_segment(self, segment_path, page_size, segment_cursor=None):<tab>if segment_path:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return Segment(self.client, segment_path, page_size, segment_cursor)<tab>return None",if self . end_time and self . _is_later_than_end_time ( segment_path ) :,91
3224,"def _check_number_of_sessions():<tab>nb_desktop_sessions = sessions.get_number_of_desktop_sessions(ignore_gdm=True)<tab>if nb_desktop_sessions > 1:<tab><tab>print(<tab><tab><tab>""WARNING : There are %d other desktop sessions open. The GPU switch will not become effective until you have manually""<tab><tab><tab>"" logged out from ALL desktop sessions.\n""<tab><tab><tab>""Continue ? (y/N)"" % (nb_desktop_sessions - 1)<tab><tab>)<tab><tab>confirmation = ask_confirmation()<tab><tab><IF-STMT><tab><tab><tab>sys.exit(0)",if not confirmation :,149
3225,"def delete_compute_environment(self, compute_environment_name):<tab>if compute_environment_name is None:<tab><tab>raise InvalidParameterValueException(""Missing computeEnvironment parameter"")<tab>compute_env = self.get_compute_environment(compute_environment_name)<tab>if compute_env is not None:<tab><tab># Pop ComputeEnvironment<tab><tab>self._compute_environments.pop(compute_env.arn)<tab><tab># Delete ECS cluster<tab><tab>self.ecs_backend.delete_cluster(compute_env.ecs_name)<tab><tab><IF-STMT><tab><tab><tab># Delete compute environment<tab><tab><tab>instance_ids = [instance.id for instance in compute_env.instances]<tab><tab><tab>self.ec2_backend.terminate_instances(instance_ids)","if compute_env . env_type == ""MANAGED"" :",187
3226,"def run(self):<tab>results = {}<tab>for func_name in [<tab><tab># Execute every function starting with check_*<tab><tab>fn<tab><tab>for fn in self.check_functions<tab><tab># if the user does not specify any name<tab><tab>if not self.args.get(""check"")<tab><tab># of if specify the current function name<tab><tab>or self.args.get(""check"") == fn<tab>]:<tab><tab>function = getattr(self, func_name)<tab><tab>log.warn(function.__doc__)<tab><tab>result = function()<tab><tab><IF-STMT><tab><tab><tab>log.info(""\n"".join(result))<tab><tab><tab>results.update({func_name: result})<tab>return results",if result :,167
3227,"def invalidate(self, layers=None):<tab>if layers is None:<tab><tab>layers = Layer.AllLayers<tab>if layers:<tab><tab>layers = set(layers)<tab><tab>self.invalidLayers.update(layers)<tab><tab>blockRenderers = [<tab><tab><tab>br<tab><tab><tab>for br in self.blockRenderers<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if len(blockRenderers) < len(self.blockRenderers):<tab><tab><tab>self.forgetDisplayLists()<tab><tab>self.blockRenderers = blockRenderers<tab><tab>if self.renderer.showRedraw and Layer.Blocks in layers:<tab><tab><tab>self.needsRedisplay = True",if br . layer is Layer . Blocks or br . layer not in layers,184
3228,"def get_library_dirs(platform, arch=None):<tab>if platform == ""win32"":<tab><tab>jre_home = get_jre_home(platform)<tab><tab>jdk_home = JAVA_HOME<tab><tab><IF-STMT><tab><tab><tab>jre_home = jre_home.decode(""utf-8"")<tab><tab>return [join(jdk_home, ""lib""), join(jdk_home, ""bin"", ""server"")]<tab>elif platform == ""android"":<tab><tab>return [""libs/{}"".format(arch)]<tab>return []","if isinstance ( jre_home , bytes ) :",136
3229,"def save_plugin_options(self):<tab>for name, option_widgets in self._plugin_option_widgets.items():<tab><tab><IF-STMT><tab><tab><tab>self.config[""plugins""][name] = {}<tab><tab>plugin_config = self.config[""plugins""][<tab><tab><tab>name<tab><tab>]  # use or instead of get incase the value is actually None<tab><tab>for option_name, option_widget in option_widgets.items():<tab><tab><tab>plugin_config[option_name] = option_widget.option.get_widget_value(<tab><tab><tab><tab>option_widget.widget<tab><tab><tab>)","if name not in self . config [ ""plugins"" ] :",149
3230,"def _select_block(str_in, start_tag, end_tag):<tab>""""""Select first block delimited by start_tag and end_tag""""""<tab>start_pos = str_in.find(start_tag)<tab>if start_pos < 0:<tab><tab>raise ValueError(""start_tag not found"")<tab>depth = 0<tab>for pos in range(start_pos, len(str_in)):<tab><tab>if str_in[pos] == start_tag:<tab><tab><tab>depth += 1<tab><tab>elif str_in[pos] == end_tag:<tab><tab><tab>depth -= 1<tab><tab><IF-STMT><tab><tab><tab>break<tab>sel = str_in[start_pos + 1 : pos]<tab>return sel",if depth == 0 :,171
3231,"def _coerce_to_bool(self, node, var, true_val=True):<tab>""""""Coerce the values in a variable to bools.""""""<tab>bool_var = self.program.NewVariable()<tab>for b in var.bindings:<tab><tab>v = b.data<tab><tab>if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool):<tab><tab><tab>const = v.pyval is true_val<tab><tab>elif not compare.compatible_with(v, True):<tab><tab><tab>const = not true_val<tab><tab><IF-STMT><tab><tab><tab>const = true_val<tab><tab>else:<tab><tab><tab>const = None<tab><tab>bool_var.AddBinding(self.convert.bool_values[const], {b}, node)<tab>return bool_var","elif not compare . compatible_with ( v , False ) :",192
3232,def multiline_indentation(self):<tab>if self._multiline_indentation is None:<tab><tab>offset = 0<tab><tab><IF-STMT><tab><tab><tab>offset = 2<tab><tab>indentation = make_indentation(3 * self.indent_size + offset)<tab><tab>self._multiline_indentation = indentation<tab>if self.current_rule:<tab><tab>indent_extra = make_indentation(self.indent_size)<tab><tab>return self._multiline_indentation + indent_extra<tab>return self._multiline_indentation,if self . show_aligned_keywords :,120
3233,"def __call__(self, event, data=None):<tab>datatype, delta = event<tab>self.midi_ctrl.delta += delta<tab>if TIMING_CLOCK in datatype and not self.played:<tab><tab>self.midi_ctrl.pulse += 1<tab><tab><IF-STMT><tab><tab><tab>t_master = 60.0<tab><tab><tab>self.midi_ctrl.bpm = round(60.0 / self.midi_ctrl.delta, 0)<tab><tab><tab>self.midi_ctrl.pulse = 0<tab><tab><tab>self.midi_ctrl.delta = 0.0",if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,155
3234,"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab><IF-STMT><tab><tab><tab>itm = self.handle_word(child)<tab><tab><tab>if self._unit == ""word"":<tab><tab><tab><tab>sent.extend(itm)<tab><tab><tab>else:<tab><tab><tab><tab>sent.append(itm)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return SemcorSentence(elt.attrib[""snum""], sent)","if child . tag in ( ""wf"" , ""punc"" ) :",126
3235,"def _handle_def_errors(testdef):<tab># If the test generation had an error, raise<tab>if testdef.error:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(testdef.exception, Exception):<tab><tab><tab><tab>raise testdef.exception<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(testdef.exception)<tab><tab>else:<tab><tab><tab>raise Exception(""Test parse failure"")",if testdef . exception :,100
3236,"def _authorized_sid(self, jid, sid, ifrom, iq):<tab>with self._preauthed_sids_lock:<tab><tab><IF-STMT><tab><tab><tab>del self._preauthed_sids[(jid, sid, ifrom)]<tab><tab><tab>return True<tab><tab>return False","if ( jid , sid , ifrom ) in self . _preauthed_sids :",88
3237,"def wait(self, timeout=None):<tab>if self.returncode is None:<tab><tab><IF-STMT><tab><tab><tab>msecs = _subprocess.INFINITE<tab><tab>else:<tab><tab><tab>msecs = max(0, int(timeout * 1000 + 0.5))<tab><tab>res = _subprocess.WaitForSingleObject(int(self._handle), msecs)<tab><tab>if res == _subprocess.WAIT_OBJECT_0:<tab><tab><tab>code = _subprocess.GetExitCodeProcess(self._handle)<tab><tab><tab>if code == TERMINATE:<tab><tab><tab><tab>code = -signal.SIGTERM<tab><tab><tab>self.returncode = code<tab>return self.returncode",if timeout is None :,154
3238,"def _gen_legal_y_s_t(self):<tab>while True:<tab><tab>y = self._gen_random_scalar()<tab><tab>s = self.tec_arithmetic.mul(<tab><tab><tab>scalar=y, a=self.tec_arithmetic.get_generator()<tab><tab>)  # S = yG<tab><tab>t = self._hash_tec_element(s)<tab><tab><IF-STMT><tab><tab><tab># Both S and T are legal<tab><tab><tab>LOGGER.info(""randomly generated y, S, T"")<tab><tab><tab>return y, s, t",if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int :,160
3239,"def write_out():<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>time.sleep(0.1)<tab><tab><tab>continue<tab><tab>data_str = self.instrument_queue.get()<tab><tab>data_str = data_str.splitlines()<tab><tab>tb.write("""")  # position cursor to end<tab><tab>for line in data_str:<tab><tab><tab>tb.write(line)<tab><tab>tb.write(""\n"")",if self . instrument_queue . empty ( ) :,112
3240,"def _parse_preamble(self):<tab>""""""Parse metadata about query (PRIVATE).""""""<tab>meta = {}<tab>while self.line:<tab><tab>regx = re.search(_RE_QUERY, self.line)<tab><tab>if regx:<tab><tab><tab>self.query_id = regx.group(1)<tab><tab><IF-STMT><tab><tab><tab>self.seq_len = int(self.line.strip().split()[1])<tab><tab>self.line = self.handle.readline().strip()<tab>return meta","if self . line . startswith ( ""Match_columns"" ) :",130
3241,"def init_sequence(self, coll_name, seq_config):<tab>if not isinstance(seq_config, list):<tab><tab>raise Exception('""sequence"" config must be a list')<tab>handlers = []<tab>for entry in seq_config:<tab><tab><IF-STMT><tab><tab><tab>raise Exception('""sequence"" entry must be a dict')<tab><tab>name = entry.get(""name"", """")<tab><tab>handler = self.load_coll(name, entry)<tab><tab>handlers.append(handler)<tab>return HandlerSeq(handlers)","if not isinstance ( entry , dict ) :",126
3242,"def change_args_to_dict(string):<tab>if string is None:<tab><tab>return None<tab>ans = []<tab>strings = string.split(""\n"")<tab>ind = 1<tab>start = 0<tab>while ind <= len(strings):<tab><tab>if ind < len(strings) and strings[ind].startswith("" ""):<tab><tab><tab>ind += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ans.append(""\n"".join(strings[start:ind]))<tab><tab><tab>start = ind<tab><tab><tab>ind += 1<tab>d = {}<tab>for line in ans:<tab><tab>if "":"" in line and len(line) > 0:<tab><tab><tab>lines = line.split("":"")<tab><tab><tab>d[lines[0]] = lines[1].strip()<tab>return d",if start < ind :,188
3243,"def wait(self):<tab>while True:<tab><tab>return_code = self._process.poll()<tab><tab>if return_code is not None:<tab><tab><tab>line = self._process.stdout.readline().decode(""utf-8"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>log.debug(line.strip(""\n""))<tab>return True","if line == """" :",87
3244,"def __getattr__(self, key):<tab>for tag in self.tag.children:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""name"" in tag.attrs and tag.attrs[""name""] in (key,):<tab><tab><tab>from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation<tab><tab><tab>return DOMImplementation.createHTMLElement(self.doc, tag)<tab>raise AttributeError","if tag . name not in ( ""input"" , ) :",104
3245,"def compare_hash(hash_of_gold, path_to_file):<tab>with open(path_to_file, ""rb"") as f:<tab><tab>hash_of_file = hashlib.sha256(f.read()).hexdigest()<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""########## Hash sum of"",<tab><tab><tab><tab>path_to_file,<tab><tab><tab><tab>""differs from the target, the topology will be deleted !!! ##########"",<tab><tab><tab>)<tab><tab><tab>shutil.rmtree(os.path.dirname(path_to_file))",if hash_of_file != hash_of_gold :,147
3246,def on_completed2():<tab>doner[0] = True<tab>if not qr:<tab><tab><IF-STMT><tab><tab><tab>observer.on_next(False)<tab><tab><tab>observer.on_completed()<tab><tab>elif donel[0]:<tab><tab><tab>observer.on_next(True)<tab><tab><tab>observer.on_completed(),if len ( ql ) > 0 :,86
3247,"def get_other(self, data, items):<tab>is_tuple = False<tab>if type(data) == tuple:<tab><tab>data = list(data)<tab><tab>is_tuple = True<tab>if type(data) == list:<tab><tab>m_items = items.copy()<tab><tab>for idx, item in enumerate(items):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>m_items[idx] = len(data) - abs(item)<tab><tab>for i in sorted(set(m_items), reverse=True):<tab><tab><tab>if i < len(data) and i > -1:<tab><tab><tab><tab>del data[i]<tab><tab>if is_tuple:<tab><tab><tab>return tuple(data)<tab><tab>else:<tab><tab><tab>return data<tab>else:<tab><tab>return None",if item < 0 :,191
3248,"def _open_url(cls, url):<tab>if config.browser:<tab><tab>cmd = [config.browser, url]<tab><tab><IF-STMT><tab><tab><tab>print(""running command: %s"" % "" "".join(cmd))<tab><tab>p = Popen(cmd)<tab><tab>p.communicate()<tab>else:<tab><tab>if not config.quiet:<tab><tab><tab>print(""opening URL in browser: %s"" % url)<tab><tab>webbrowser.open_new(url)",if not config . quiet :,117
3249,"def setLabel(self, s, protect=False):<tab>""""""Set the label of the minibuffer.""""""<tab>c, k, w = self.c, self, self.w<tab>if w:<tab><tab># Support for the curses gui.<tab><tab>if hasattr(g.app.gui, ""set_minibuffer_label""):<tab><tab><tab>g.app.gui.set_minibuffer_label(c, s)<tab><tab>w.setAllText(s)<tab><tab>n = len(s)<tab><tab>w.setSelectionRange(n, n, insert=n)<tab><tab><IF-STMT><tab><tab><tab>k.mb_prefix = s",if protect :,151
3250,"def __init__(self, path):<tab>self.symcaches = []<tab>for path in path.split("";""):<tab><tab>if os.path.isdir(path):<tab><tab><tab>self.symcaches.append(SymbolCache(dirname=path))<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>import cobra<tab><tab><tab>self.symcaches.append(cobra.CobraProxy(path))<tab><tab><tab>continue","if path . startswith ( ""cobra://"" ) or path . startswith ( ""cobrassl://"" ) :",111
3251,"def init_params(net):<tab>""""""Init layer parameters.""""""<tab>for module in net.modules():<tab><tab>if isinstance(module, nn.Conv2d):<tab><tab><tab>init.kaiming_normal(module.weight, mode=""fan_out"")<tab><tab><tab>if module.bias:<tab><tab><tab><tab>init.constant(module.bias, 0)<tab><tab><IF-STMT><tab><tab><tab>init.constant(module.weight, 1)<tab><tab><tab>init.constant(module.bias, 0)<tab><tab>elif isinstance(module, nn.Linear):<tab><tab><tab>init.normal(module.weight, std=1e-3)<tab><tab><tab>if module.bias:<tab><tab><tab><tab>init.constant(module.bias, 0)","elif isinstance ( module , nn . BatchNorm2d ) :",180
3252,"def _diff_dict(self, old, new):<tab>diff = {}<tab>removed = []<tab>added = []<tab>for key, value in old.items():<tab><tab><IF-STMT><tab><tab><tab>removed.append(key)<tab><tab>elif old[key] != new[key]:<tab><tab><tab># modified is indicated by a remove and add<tab><tab><tab>removed.append(key)<tab><tab><tab>added.append(key)<tab>for key, value in new.items():<tab><tab>if key not in old:<tab><tab><tab>added.append(key)<tab>if removed:<tab><tab>diff[""removed""] = sorted(removed)<tab>if added:<tab><tab>diff[""added""] = sorted(added)<tab>return diff",if key not in new :,172
3253,"def __init__(self, *args, **kwargs):<tab>_kwargs = {<tab><tab>""max_length"": 20,<tab><tab>""widget"": forms.TextInput(attrs={""autocomplete"": ""off""}),<tab><tab>""label"": _(""Card number""),<tab>}<tab>if ""types"" in kwargs:<tab><tab>self.accepted_cards = set(kwargs.pop(""types""))<tab><tab>difference = self.accepted_cards - VALID_CARDS<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""The following accepted_cards are "" ""unknown: %s"" % difference<tab><tab><tab>)<tab>_kwargs.update(kwargs)<tab>super().__init__(*args, **_kwargs)",if difference :,160
3254,"def dumps(self):<tab>sections = []<tab>for name, env_info in self._dependencies_.items():<tab><tab>sections.append(""[ENV_%s]"" % name)<tab><tab>for var, values in sorted(env_info.vars.items()):<tab><tab><tab>tmp = ""%s="" % var<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""[%s]"" % "","".join(['""%s""' % val for val in values])<tab><tab><tab>else:<tab><tab><tab><tab>tmp += ""%s"" % values<tab><tab><tab>sections.append(tmp)<tab>return ""\n"".join(sections)","if isinstance ( values , list ) :",144
3255,"def air_quality(self):<tab>aqi_data = self._get_aqi_data()<tab>if aqi_data:<tab><tab>if aqi_data.get(""status"") == ""ok"":<tab><tab><tab>aqi_data = self._organize(aqi_data)<tab><tab><tab>aqi_data = self._manipulate(aqi_data)<tab><tab><IF-STMT><tab><tab><tab>self.py3.error(aqi_data.get(""data""))<tab>return {<tab><tab>""cached_until"": self.py3.time_in(self.cache_timeout),<tab><tab>""full_text"": self.py3.safe_format(self.format, aqi_data),<tab>}","elif aqi_data . get ( ""status"" ) == ""error"" :",190
3256,"def _blend(x, y):  # pylint: disable=invalid-name<tab>""""""Implements the ""blend"" strategy for `deep_merge`.""""""<tab>if isinstance(x, (dict, OrderedDict)):<tab><tab>if not isinstance(y, (dict, OrderedDict)):<tab><tab><tab>return y<tab><tab>return _merge(x, y, recursion_func=_blend)<tab>if isinstance(x, (list, tuple)):<tab><tab><IF-STMT><tab><tab><tab>return y<tab><tab>result = [_blend(*i) for i in zip(x, y)]<tab><tab>if len(x) > len(y):<tab><tab><tab>result += x[len(y) :]<tab><tab>elif len(x) < len(y):<tab><tab><tab>result += y[len(x) :]<tab><tab>return result<tab>return y","if not isinstance ( y , ( list , tuple ) ) :",194
3257,"def _rate(cls, sample1, sample2):<tab>""Simple rate""<tab>try:<tab><tab>interval = sample2[0] - sample1[0]<tab><tab><IF-STMT><tab><tab><tab>raise Infinity()<tab><tab>delta = sample2[1] - sample1[1]<tab><tab>if delta < 0:<tab><tab><tab>raise UnknownValue()<tab><tab>return (sample2[0], delta / interval, sample2[2], sample2[3])<tab>except Infinity:<tab><tab>raise<tab>except UnknownValue:<tab><tab>raise<tab>except Exception as e:<tab><tab>raise NaN(e)",if interval == 0 :,146
3258,"def wrapped_request_method(*args, **kwargs):<tab>""""""Modifies HTTP headers to include a specified user-agent.""""""<tab>if kwargs.get(""headers"") is not None:<tab><tab><IF-STMT><tab><tab><tab>if user_agent not in kwargs[""headers""][""user-agent""]:<tab><tab><tab><tab># Save the existing user-agent header and tack on our own.<tab><tab><tab><tab>kwargs[""headers""][""user-agent""] = (<tab><tab><tab><tab><tab>f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}'<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>kwargs[""headers""][""user-agent""] = user_agent<tab>else:<tab><tab>kwargs[""headers""] = {""user-agent"": user_agent}<tab>return request_method(*args, **kwargs)","if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :",191
3259,"def remove_addons(auth, resource_object_list):<tab>for config in AbstractNode.ADDONS_AVAILABLE:<tab><tab>try:<tab><tab><tab>settings_model = config.node_settings<tab><tab>except LookupError:<tab><tab><tab>settings_model = None<tab><tab><IF-STMT><tab><tab><tab>addon_list = settings_model.objects.filter(<tab><tab><tab><tab>owner__in=resource_object_list, is_deleted=False<tab><tab><tab>)<tab><tab><tab>for addon in addon_list:<tab><tab><tab><tab>addon.after_delete(auth.user)",if settings_model :,138
3260,"def Decorator(*args, **kwargs):<tab>delay = 0.2<tab>num_attempts = 15<tab>cur_attempt = 0<tab>while True:<tab><tab>try:<tab><tab><tab>return f(*args, **kwargs)<tab><tab>except exceptions.WebDriverException as e:<tab><tab><tab>logging.warning(""Selenium raised %s"", utils.SmartUnicode(e))<tab><tab><tab>cur_attempt += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>time.sleep(delay)",if cur_attempt == num_attempts :,122
3261,"def _cleanup_parts_dir(parts_dir, local_plugins_dir, parts):<tab>if os.path.exists(parts_dir):<tab><tab>logger.info(""Cleaning up parts directory"")<tab><tab>for subdirectory in os.listdir(parts_dir):<tab><tab><tab>path = os.path.join(parts_dir, subdirectory)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>shutil.rmtree(path)<tab><tab><tab><tab>except NotADirectoryError:<tab><tab><tab><tab><tab>os.remove(path)<tab>for part in parts:<tab><tab>part.mark_cleaned(steps.BUILD)<tab><tab>part.mark_cleaned(steps.PULL)",if path != local_plugins_dir :,165
3262,"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]):<tab>if node_pos[""reach_leaf_node""].all():<tab><tab>return node_pos<tab>for t_idx, tree in enumerate(trees):<tab><tab>cur_node_idx = node_pos[""node_pos""][t_idx]<tab><tab># reach leaf<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree(<tab><tab><tab>tree, sample, cur_node_idx<tab><tab>)<tab><tab>if reach_leaf:<tab><tab><tab>node_pos[""reach_leaf_node""][t_idx] = True<tab><tab>node_pos[""node_pos""][t_idx] = rs<tab>return node_pos",if cur_node_idx == - 1 :,196
3263,"def get_measurements(self, pipeline, object_name, category):<tab>if self.get_categories(pipeline, object_name) == [category]:<tab><tab>results = []<tab><tab>if self.do_corr_and_slope:<tab><tab><tab>if object_name == ""Image"":<tab><tab><tab><tab>results += [""Correlation"", ""Slope""]<tab><tab><tab>else:<tab><tab><tab><tab>results += [""Correlation""]<tab><tab>if self.do_overlap:<tab><tab><tab>results += [""Overlap"", ""K""]<tab><tab><IF-STMT><tab><tab><tab>results += [""Manders""]<tab><tab>if self.do_rwc:<tab><tab><tab>results += [""RWC""]<tab><tab>if self.do_costes:<tab><tab><tab>results += [""Costes""]<tab><tab>return results<tab>return []",if self . do_manders :,195
3264,"def create_connection(self, infos, f2, laddr_infos, protocol):<tab>for family in infos:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for laddr in laddr_infos:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>except OSError:<tab><tab><tab><tab><tab><tab>protocol = ""foo""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>continue<tab><tab>except OSError:<tab><tab><tab>protocol = ""bar""<tab><tab>else:<tab><tab><tab>break<tab>else:<tab><tab>raise<tab>return protocol",if f2 :,139
3265,"def app_middleware(next, root, info, **kwargs):<tab>app_auth_header = ""HTTP_AUTHORIZATION""<tab>prefix = ""bearer""<tab>request = info.context<tab>if request.path == API_PATH:<tab><tab>if not hasattr(request, ""app""):<tab><tab><tab>request.app = None<tab><tab><tab>auth = request.META.get(app_auth_header, """").split()<tab><tab><tab>if len(auth) == 2:<tab><tab><tab><tab>auth_prefix, auth_token = auth<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>request.app = SimpleLazyObject(lambda: get_app(auth_token))<tab>return next(root, info, **kwargs)",if auth_prefix . lower ( ) == prefix :,171
3266,"def when(self, matches, context):<tab>ret = []<tab>for episode in matches.named(""episode"", lambda match: len(match.initiator) == 1):<tab><tab>group = matches.markers.at_match(<tab><tab><tab>episode, lambda marker: marker.name == ""group"", index=0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>if not matches.range(<tab><tab><tab><tab>*group.span, predicate=lambda match: match.name == ""title""<tab><tab><tab>):<tab><tab><tab><tab>ret.append(episode)<tab>return ret",if group :,132
3267,def locate_via_pep514(spec):<tab>with _PY_LOCK:<tab><tab>if not _PY_AVAILABLE:<tab><tab><tab>from . import pep514<tab><tab><tab>_PY_AVAILABLE.extend(pep514.discover_pythons())<tab><tab><tab>_PY_AVAILABLE.append(CURRENT)<tab>for cur_spec in _PY_AVAILABLE:<tab><tab><IF-STMT><tab><tab><tab>return cur_spec.path,if cur_spec . satisfies ( spec ) :,110
3268,"def setCorkImageDefault(self):<tab>if settings.corkBackground[""image""] != """":<tab><tab>i = self.cmbCorkImage.findData(settings.corkBackground[""image""])<tab><tab><IF-STMT><tab><tab><tab>self.cmbCorkImage.setCurrentIndex(i)",if i != - 1 :,72
3269,"def _split_key(key):<tab>if isinstance(key, util.string_types):<tab><tab># coerce fooload('*') into ""default loader strategy""<tab><tab>if key == _WILDCARD_TOKEN:<tab><tab><tab>return (_DEFAULT_TOKEN,)<tab><tab># coerce fooload("".*"") into ""wildcard on default entity""<tab><tab><IF-STMT><tab><tab><tab>key = key[1:]<tab><tab>return key.split(""."")<tab>else:<tab><tab>return (key,)","elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :",122
3270,"def detach_volume(self, volume):<tab># We need to find the node using this volume<tab>for node in self.list_nodes():<tab><tab><IF-STMT><tab><tab><tab># This node has only one associated image. It is not the one we<tab><tab><tab># are after.<tab><tab><tab>continue<tab><tab>for disk in node.image:<tab><tab><tab>if disk.id == volume.id:<tab><tab><tab><tab># Node found. We can now detach the volume<tab><tab><tab><tab>disk_id = disk.extra[""disk_id""]<tab><tab><tab><tab>return self._do_detach_volume(node.id, disk_id)<tab>return False",if type ( node . image ) is not list :,160
3271,"def create(self, private=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Creating private channel %s."", self)<tab><tab><tab>self._bot.api_call(<tab><tab><tab><tab>""conversations.create"", data={""name"": self.name, ""is_private"": True}<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>log.info(""Creating channel %s."", self)<tab><tab><tab>self._bot.api_call(""conversations.create"", data={""name"": self.name})<tab>except SlackAPIResponseError as e:<tab><tab>if e.error == ""user_is_bot"":<tab><tab><tab>raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)",if private :,189
3272,"def test_dataset_has_valid_etag(self, dataset_name):<tab>py_script_path = list(filter(lambda x: x, dataset_name.split(""/"")))[-1] + "".py""<tab>dataset_url = hf_bucket_url(dataset_name, filename=py_script_path, dataset=True)<tab>etag = None<tab>try:<tab><tab>response = requests.head(<tab><tab><tab>dataset_url, allow_redirects=True, proxies=None, timeout=10<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>etag = response.headers.get(""Etag"")<tab>except (EnvironmentError, requests.exceptions.Timeout):<tab><tab>pass<tab>self.assertIsNotNone(etag)",if response . status_code == 200 :,173
3273,"def set_dir_modes(self, dirname, mode):<tab>if not self.is_chmod_supported():<tab><tab>return<tab>for dirpath, dirnames, fnames in os.walk(dirname):<tab><tab>if os.path.islink(dirpath):<tab><tab><tab>continue<tab><tab>log.info(""changing mode of %s to %o"", dirpath, mode)<tab><tab><IF-STMT><tab><tab><tab>os.chmod(dirpath, mode)",if not self . dry_run :,105
3274,"def _clean(self):<tab>logger.info(""Cleaning up..."")<tab>if self._process is not None:<tab><tab><IF-STMT><tab><tab><tab>for _ in range(3):<tab><tab><tab><tab>self._process.terminate()<tab><tab><tab><tab>time.sleep(0.5)<tab><tab><tab><tab>if self._process.poll() is not None:<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self._process.kill()<tab><tab><tab><tab>self._process.wait()<tab><tab><tab><tab>logger.error(""KILLED"")<tab>if os.path.exists(self._tmp_dir):<tab><tab>shutil.rmtree(self._tmp_dir)<tab>self._process = None<tab>self._ws = None<tab>logger.info(""Cleanup complete"")",if self . _process . poll ( ) is None :,189
3275,"def iter_chars_to_words(self, chars):<tab>current_word = []<tab>for char in chars:<tab><tab>if not self.keep_blank_chars and char[""text""].isspace():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield current_word<tab><tab><tab><tab>current_word = []<tab><tab>elif current_word and self.char_begins_new_word(current_word, char):<tab><tab><tab>yield current_word<tab><tab><tab>current_word = [char]<tab><tab>else:<tab><tab><tab>current_word.append(char)<tab>if current_word:<tab><tab>yield current_word",if current_word :,150
3276,"def _lookup(components, specs, provided, name, i, l):<tab>if i < l:<tab><tab>for spec in specs[i].__sro__:<tab><tab><tab>comps = components.get(spec)<tab><tab><tab>if comps:<tab><tab><tab><tab>r = _lookup(comps, specs, provided, name, i + 1, l)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return r<tab>else:<tab><tab>for iface in provided:<tab><tab><tab>comps = components.get(iface)<tab><tab><tab>if comps:<tab><tab><tab><tab>r = comps.get(name)<tab><tab><tab><tab>if r is not None:<tab><tab><tab><tab><tab>return r<tab>return None",if r is not None :,166
3277,"def run(cmd, task=None):<tab>process = subprocess.Popen(<tab><tab>cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True<tab>)<tab>output_lines = []<tab>while True:<tab><tab>line = process.stdout.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>line = line.decode(""utf-8"")<tab><tab>output_lines += [line]<tab><tab>logger.info(line.rstrip(""\n""))<tab>process.stdout.close()<tab>exit_code = process.wait()<tab>if exit_code:<tab><tab>output = """".join(output_lines)<tab><tab>raise subprocess.CalledProcessError(exit_code, cmd, output=output)",if not line :,169
3278,"def process_response(self, request, response):<tab>if (<tab><tab>response.status_code == 404<tab><tab>and request.path_info.endswith(""/"")<tab><tab>and not is_valid_path(request.path_info)<tab><tab>and is_valid_path(request.path_info[:-1])<tab>):<tab><tab># Use request.path because we munged app/locale in path_info.<tab><tab>newurl = request.path[:-1]<tab><tab><IF-STMT><tab><tab><tab>with safe_query_string(request):<tab><tab><tab><tab>newurl += ""?"" + request.META[""QUERY_STRING""]<tab><tab>return HttpResponsePermanentRedirect(newurl)<tab>return response",if request . GET :,163
3279,"def dependencies(self):<tab>deps = []<tab>midx = None<tab>if self.ref is not None:<tab><tab>query = TypeQuery(self.ref)<tab><tab>super = query.execute(self.schema)<tab><tab>if super is None:<tab><tab><tab>log.debug(self.schema)<tab><tab><tab>raise TypeNotFound(self.ref)<tab><tab><IF-STMT><tab><tab><tab>deps.append(super)<tab><tab><tab>midx = 0<tab>return (midx, deps)",if not super . builtin ( ) :,120
3280,"def _get_vtkjs(self):<tab>if self._vtkjs is None and self.object is not None:<tab><tab>if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with open(self.object, ""rb"") as f:<tab><tab><tab><tab><tab>vtkjs = f.read()<tab><tab><tab>else:<tab><tab><tab><tab>data_url = urlopen(self.object)<tab><tab><tab><tab>vtkjs = data_url.read()<tab><tab>elif hasattr(self.object, ""read""):<tab><tab><tab>vtkjs = self.object.read()<tab><tab>self._vtkjs = vtkjs<tab>return self._vtkjs",if isfile ( self . object ) :,180
3281,"def _save(self):<tab>fd, tempname = tempfile.mkstemp()<tab>fd = os.fdopen(fd, ""w"")<tab>json.dump(self._cache, fd, indent=2, separators=("","", "": ""))<tab>fd.close()<tab># Silently ignore errors<tab>try:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(os.path.dirname(self.filename))<tab><tab>shutil.move(tempname, self.filename)<tab>except (IOError, OSError):<tab><tab>os.remove(tempname)",if not os . path . exists ( os . path . dirname ( self . filename ) ) :,139
3282,"def refiner_configs(self):<tab>rv = {}<tab>for refiner in refiner_manager:<tab><tab><IF-STMT><tab><tab><tab>rv[refiner.name] = {k: v for k, v in self.config.items(refiner.name)}<tab>return rv",if self . config . has_section ( refiner . name ) :,78
3283,"def com_slice(self, primary, node, assigning):<tab># short_slice:  [lower_bound] "":"" [upper_bound]<tab>lower = upper = None<tab>if len(node.children) == 2:<tab><tab><IF-STMT><tab><tab><tab>upper = self.com_node(node.children[1])<tab><tab>else:<tab><tab><tab>lower = self.com_node(node.children[0])<tab>elif len(node.children) == 3:<tab><tab>lower = self.com_node(node.children[0])<tab><tab>upper = self.com_node(node.children[2])<tab>return Slice(primary, assigning, lower, upper, lineno=extractLineNo(node))",if node . children [ 0 ] . type == token . COLON :,177
3284,"def close(self, *args, **kwargs):<tab>super(mytqdm, self).close(*args, **kwargs)<tab># If it was not run in a notebook, sp is not assigned, check for it<tab>if hasattr(self, ""sp""):<tab><tab># Try to detect if there was an error or KeyboardInterrupt<tab><tab># in manual mode: if n < total, things probably got wrong<tab><tab>if self.total and self.n < self.total:<tab><tab><tab>self.sp(bar_style=""danger"")<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.sp(bar_style=""success"")<tab><tab><tab>else:<tab><tab><tab><tab>self.sp(close=True)",if self . leave :,167
3285,"def test_alloc(self):<tab>b = bytearray()<tab>alloc = b.__alloc__()<tab>self.assertTrue(alloc >= 0)<tab>seq = [alloc]<tab>for i in range(100):<tab><tab>b += b""x""<tab><tab>alloc = b.__alloc__()<tab><tab>self.assertTrue(alloc >= len(b))<tab><tab><IF-STMT><tab><tab><tab>seq.append(alloc)",if alloc not in seq :,98
3286,"def flush_file(self, key, f):<tab>f.flush()<tab><IF-STMT><tab><tab>f.compress = zlib.compressobj(<tab><tab><tab>9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0<tab><tab>)<tab>if len(self.files) > self.MAX_OPEN_FILES:<tab><tab>if self.compress:<tab><tab><tab>open_files = sum(1 for f in self.files.values() if f.fileobj is not None)<tab><tab><tab>if open_files > self.MAX_OPEN_FILES:<tab><tab><tab><tab>f.fileobj.close()<tab><tab><tab><tab>f.fileobj = None<tab><tab>else:<tab><tab><tab>f.close()<tab><tab><tab>self.files.pop(key)",if self . compress :,183
3287,"def _run(self):<tab># Low-level run method to do the actual scheduling loop.<tab>self.running = True<tab>while self.running:<tab><tab>try:<tab><tab><tab>self.sched.run()<tab><tab>except Exception as x:<tab><tab><tab>logging.error(<tab><tab><tab><tab>""Error during scheduler execution: %s"" % str(x), exc_info=True<tab><tab><tab>)<tab><tab># queue is empty; sleep a short while before checking again<tab><tab><IF-STMT><tab><tab><tab>time.sleep(5)",if self . running :,132
3288,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_max_rows(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 16 :,124
3289,"def check(dbdef):<tab>""drop script must clear the database""<tab>for version in dbdef:<tab><tab>connector = MemConnector().bound(None)<tab><tab>create(dbdef, version, connector)<tab><tab>drop(dbdef, version, connector)<tab><tab>remaining = connector.execute(<tab><tab><tab>""SELECT * FROM sqlite_master WHERE name NOT LIKE 'sqlite_%'""<tab><tab>).fetchall()<tab><tab><IF-STMT><tab><tab><tab>yield ""{0}:drop.sql"".format(version), remaining",if remaining :,120
3290,"def test_open_overwrite_offset_size(self, sftp):<tab>""""""Test writing data at a specific offset""""""<tab>f = None<tab>try:<tab><tab>self._create_file(""file"", ""xxxxyyyy"")<tab><tab>f = yield from sftp.open(""file"", ""r+"")<tab><tab>yield from f.write(""zz"", 3)<tab><tab>yield from f.close()<tab><tab>with open(""file"") as localf:<tab><tab><tab>self.assertEqual(localf.read(), ""xxxzzyyy"")<tab>finally:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>yield from f.close()<tab><tab>remove(""file"")",if f :,155
3291,"def pump():<tab>import sys as _sys<tab>while self.countdown_active():<tab><tab>if not (self.connected(""send"") and other.connected(""recv"")):<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>data = other.recv(timeout=0.05)<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if not data:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>self.send(data)<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab>if not _sys:<tab><tab><tab>return<tab>self.shutdown(""send"")<tab>other.shutdown(""recv"")",if not _sys :,158
3292,"def parse_results(cwd):<tab>optimal_dd = None<tab>optimal_measure = numpy.inf<tab>for tup in tools.find_conf_files(cwd):<tab><tab>dd = tup[1]<tab><tab>if ""results.train_y_misclass"" in dd:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>optimal_measure = dd[""results.train_y_misclass""]<tab><tab><tab><tab>optimal_dd = dd<tab>print(""Optimal results.train_y_misclass:"", str(optimal_measure))<tab>for key, value in optimal_dd.items():<tab><tab>if ""hyper_parameters"" in key:<tab><tab><tab>print(key + "": "" + str(value))","if dd [ ""results.train_y_misclass"" ] < optimal_measure :",177
3293,"def valid(self):<tab>valid = True<tab><IF-STMT><tab><tab>return valid<tab>else:<tab><tab>try:<tab><tab><tab>with io.open(self.pathfile, ""w"", encoding=""utf-8"") as f:<tab><tab><tab><tab>f.close()  # do nothing<tab><tab>except OSError:<tab><tab><tab>valid = False<tab><tab>if os.path.exists(self.pathfile):<tab><tab><tab>os.remove(self.pathfile)<tab><tab>return valid",if os . path . exists ( self . pathfile ) :,124
3294,"def __getitem__(self, key):<tab>try:<tab><tab>value = self.cache[key]<tab>except KeyError:<tab><tab>f = BytesIO(self.dict[key.encode(self.keyencoding)])<tab><tab>value = Unpickler(f).load()<tab><tab><IF-STMT><tab><tab><tab>self.cache[key] = value<tab>return value",if self . writeback :,87
3295,"def hasMenu(cls, callingWindow, mainItem, selection, *fullContexts):<tab>for i, fullContext in enumerate(fullContexts):<tab><tab>srcContext = fullContext[0]<tab><tab>for menuHandler in cls.menus:<tab><tab><tab>m = menuHandler()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>return False","if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :",98
3296,"def lr_read_tables(module=tab_module, optimize=0):<tab>global _lr_action, _lr_goto, _lr_productions, _lr_method<tab>try:<tab><tab>exec(""import %s as parsetab"" % module)<tab><tab>global parsetab  # declare the name of the imported module<tab><tab><IF-STMT><tab><tab><tab>_lr_action = parsetab._lr_action<tab><tab><tab>_lr_goto = parsetab._lr_goto<tab><tab><tab>_lr_productions = parsetab._lr_productions<tab><tab><tab>_lr_method = parsetab._lr_method<tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>return 0<tab>except (ImportError, AttributeError):<tab><tab>return 0",if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,192
3297,"def _Determine_Do(self):<tab>if sys.platform.startswith(""win""):<tab><tab>self.applicable = 1<tab><tab>for opt, optarg in self.chosenOptions:<tab><tab><tab>if opt == ""--moz-tools"":<tab><tab><tab><tab>self.value = os.path.abspath(os.path.normpath(optarg))<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.value = os.environ[self.name]<tab><tab><tab>else:<tab><tab><tab><tab>self.value = None<tab>else:<tab><tab>self.applicable = 0<tab>self.determined = 1",if os . environ . has_key ( self . name ) :,157
3298,"def parse_chunked(self, unreader):<tab>(size, rest) = self.parse_chunk_size(unreader)<tab>while size > 0:<tab><tab>while size > len(rest):<tab><tab><tab>size -= len(rest)<tab><tab><tab>yield rest<tab><tab><tab>rest = unreader.read()<tab><tab><tab>if not rest:<tab><tab><tab><tab>raise NoMoreData()<tab><tab>yield rest[:size]<tab><tab># Remove \r\n after chunk<tab><tab>rest = rest[size:]<tab><tab>while len(rest) < 2:<tab><tab><tab>rest += unreader.read()<tab><tab><IF-STMT><tab><tab><tab>raise ChunkMissingTerminator(rest[:2])<tab><tab>(size, rest) = self.parse_chunk_size(unreader, data=rest[2:])","if rest [ : 2 ] != b""\r\n"" :",197
3299,"def _scroll_down(self, cli):<tab>""Scroll window down.""<tab>info = self.render_info<tab>if self.vertical_scroll < info.content_height - info.window_height:<tab><tab><IF-STMT><tab><tab><tab>self.content.move_cursor_down(cli)<tab><tab>self.vertical_scroll += 1",if info . cursor_position . y <= info . configured_scroll_offsets . top :,96
3300,"def _add_defaults_data_files(self):<tab># getting distribution.data_files<tab>if self.distribution.has_data_files():<tab><tab>for item in self.distribution.data_files:<tab><tab><tab>if isinstance(item, str):<tab><tab><tab><tab># plain file<tab><tab><tab><tab>item = convert_path(item)<tab><tab><tab><tab>if os.path.isfile(item):<tab><tab><tab><tab><tab>self.filelist.append(item)<tab><tab><tab>else:<tab><tab><tab><tab># a (dirname, filenames) tuple<tab><tab><tab><tab>dirname, filenames = item<tab><tab><tab><tab>for f in filenames:<tab><tab><tab><tab><tab>f = convert_path(f)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.filelist.append(f)",if os . path . isfile ( f ) :,192
3301,"def list_stuff(self, upto=10, start_after=-1):<tab>for i in range(upto):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if i == 2 and self.count < 1:<tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>if i == 7 and self.count < 4:<tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>yield i",if i <= start_after :,110
3302,"def is_open(self):<tab>if self.signup_code:<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if self.messages.get(""invalid_signup_code""):<tab><tab><tab><tab>messages.add_message(<tab><tab><tab><tab><tab>self.request,<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""level""],<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""text""].format(<tab><tab><tab><tab><tab><tab>**{<tab><tab><tab><tab><tab><tab><tab>""code"": self.get_code(),<tab><tab><tab><tab><tab><tab>}<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>)<tab>return settings.ACCOUNT_OPEN_SIGNUP",if self . signup_code_present :,172
3303,"def on_delete_from_disk(self, widget, data=None):<tab>model, iter = self.get_selection().get_selected()<tab>if iter:<tab><tab>path = model.get_value(iter, COLUMN_PATH)<tab><tab><IF-STMT><tab><tab><tab>ErrorDialog(_(""Can't delete system item from disk."")).launch()<tab><tab>else:<tab><tab><tab>os.remove(path)<tab>self.update_items()",if self . is_defaultitem ( path ) :,110
3304,"def get_detections_for_batch(self, images):<tab>images = images[..., ::-1]<tab>detected_faces = self.face_detector.detect_from_batch(images.copy())<tab>results = []<tab>for i, d in enumerate(detected_faces):<tab><tab><IF-STMT><tab><tab><tab>results.append(None)<tab><tab><tab>continue<tab><tab>d = d[0]<tab><tab>d = np.clip(d, 0, None)<tab><tab>x1, y1, x2, y2 = map(int, d[:-1])<tab><tab>results.append((x1, y1, x2, y2))<tab>return results",if len ( d ) == 0 :,159
3305,def on_update(self):<tab>#<tab># Calculate maximum # of planes per well<tab>#<tab>self.max_per_well = 0<tab>for pd in list(self.plate_well_site.values()):<tab><tab>for wd in list(pd.values()):<tab><tab><tab>nplanes = sum([len(x) for x in list(wd.values())])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.max_per_well = nplanes<tab>for registrant in self.registrants:<tab><tab>registrant(),if nplanes > self . max_per_well :,137
3306,"def is_writable(self, path):<tab>result = False<tab>while not result:<tab><tab>if os.path.exists(path):<tab><tab><tab>result = os.access(path, os.W_OK)<tab><tab><tab>break<tab><tab>parent = os.path.dirname(path)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>path = parent<tab>return result",if parent == path :,92
3307,"def _check_seed(self, seed):<tab>if seed is not None:<tab><tab><IF-STMT><tab><tab><tab>self._raise_error(<tab><tab><tab><tab>""The random number generator seed value, seed, should be integer type or None.""<tab><tab><tab>)<tab><tab>if seed < 0:<tab><tab><tab>self._raise_error(<tab><tab><tab><tab>""The random number generator seed value, seed, should be non-negative integer or None.""<tab><tab><tab>)",if type ( seed ) != int :,114
3308,"def write(self, x):<tab># try to use backslash and surrogate escape strategies before failing<tab>self._errors = ""backslashescape"" if self.encoding != ""mbcs"" else ""surrogateescape""<tab>try:<tab><tab>return io.TextIOWrapper.write(self, to_text(x, errors=self._errors))<tab>except UnicodeDecodeError:<tab><tab><IF-STMT><tab><tab><tab>self._errors = ""surrogateescape""<tab><tab>else:<tab><tab><tab>self._errors = ""replace""<tab><tab>return io.TextIOWrapper.write(self, to_text(x, errors=self._errors))","if self . _errors != ""surrogateescape"" :",141
3309,"def post(self, request, *args, **kwargs):<tab>validated_session = []<tab>for session_id in request.data:<tab><tab>session = get_object_or_none(Session, id=session_id)<tab><tab><IF-STMT><tab><tab><tab>validated_session.append(session_id)<tab><tab><tab>self.model.objects.create(<tab><tab><tab><tab>name=""kill_session"",<tab><tab><tab><tab>args=session.id,<tab><tab><tab><tab>terminal=session.terminal,<tab><tab><tab>)<tab>return Response({""ok"": validated_session})",if session and not session . is_finished :,141
3310,"def _has_list_or_dict_var_value_before(self, arg_index):<tab>for idx, value in enumerate(self.args):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if variablematcher.is_list_variable(<tab><tab><tab>value<tab><tab>) and not variablematcher.is_list_variable_subitem(value):<tab><tab><tab>return True<tab><tab>if robotapi.is_dict_var(value) and not variablematcher.is_dict_var_access(<tab><tab><tab>value<tab><tab>):<tab><tab><tab>return True<tab>return False",if idx > arg_index :,142
3311,"def test_return_correct_type(self):<tab>for proto in protocols:<tab><tab># Protocol 0 supports only ASCII strings.<tab><tab><IF-STMT><tab><tab><tab>self._check_return_correct_type(""abc"", 0)<tab><tab>else:<tab><tab><tab>for obj in [b""abc\n"", ""abc\n"", -1, -1.1 * 0.1, str]:<tab><tab><tab><tab>self._check_return_correct_type(obj, proto)",if proto == 0 :,113
3312,"def backward_impl(self, inputs, outputs, prop_down, accum):<tab># inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or<tab># [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph]<tab># Args<tab>axis = self.forward_func.info.args[""axis""]<tab># Compute<tab>## w.r.t. dy<tab>if prop_down[-1]:<tab><tab>g_dy = inputs[-1].grad<tab><tab>g_dy_ = F.stack(*[o.grad for o in outputs], axis=axis)<tab><tab><IF-STMT><tab><tab><tab>g_dy += g_dy_<tab><tab>else:<tab><tab><tab>g_dy.copy_from(g_dy_)",if accum [ - 1 ] :,190
3313,"def remove(self, url):<tab>try:<tab><tab>i = self.items.index(url)<tab>except (ValueError, IndexError):<tab><tab>pass<tab>else:<tab><tab>was_selected = i in self.selectedindices()<tab><tab>self.list.delete(i)<tab><tab>del self.items[i]<tab><tab>if not self.items:<tab><tab><tab>self.mp.hidepanel(self.name)<tab><tab>elif was_selected:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>self.list.select_set(i)",if i >= len ( self . items ) :,150
3314,"def prepend(self, value):<tab>""""""prepend value to nodes""""""<tab>root, root_text = self._get_root(value)<tab>for i, tag in enumerate(self):<tab><tab>if not tag.text:<tab><tab><tab>tag.text = """"<tab><tab>if len(root) > 0:<tab><tab><tab>root[-1].tail = tag.text<tab><tab><tab>tag.text = root_text<tab><tab>else:<tab><tab><tab>tag.text = root_text + tag.text<tab><tab><IF-STMT><tab><tab><tab>root = deepcopy(list(root))<tab><tab>tag[:0] = root<tab><tab>root = tag[: len(root)]<tab>return self",if i > 0 :,160
3315,"def _get_tracks_compositors_list():<tab>tracks_list = []<tab>tracks = current_sequence().tracks<tab>compositors = current_sequence().compositors<tab>for track_index in range(1, len(tracks) - 1):<tab><tab>track_compositors = []<tab><tab>for j in range(0, len(compositors)):<tab><tab><tab>comp = compositors[j]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>track_compositors.append(comp)<tab><tab>tracks_list.append(track_compositors)<tab>return tracks_list",if comp . transition . b_track == track_index :,143
3316,"def __getattr__(self, name):<tab>if name in self._sections:<tab><tab>return ""\n"".join(self._sections[name])<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return """"<tab><tab>else:<tab><tab><tab>raise ConanException(""ConfigParser: Unrecognized field '%s'"" % name)",if self . _allowed_fields and name in self . _allowed_fields :,86
3317,"def get_first_param_index(self, group_id, param_group, partition_id):<tab>for index, param in enumerate(param_group):<tab><tab>param_id = self.get_param_id(param)<tab><tab><IF-STMT><tab><tab><tab>return index<tab>return None",if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,90
3318,"def handle_uv_sockets(self, context):<tab>u_socket = self.inputs[""U""]<tab>v_socket = self.inputs[""V""]<tab>if self.cast_mode == ""Sphere"":<tab><tab>u_socket.hide_safe = True<tab><tab>v_socket.hide_safe = True<tab>elif self.cast_mode in [""Cylinder"", ""Prism""]:<tab><tab>v_socket.hide_safe = True<tab><tab><IF-STMT><tab><tab><tab>u_socket.hide_safe = False<tab>else:<tab><tab>if u_socket.hide_safe:<tab><tab><tab>u_socket.hide_safe = False<tab><tab>if v_socket.hide_safe:<tab><tab><tab>v_socket.hide_safe = False",if u_socket . hide_safe :,184
3319,"def _scrub_generated_timestamps(self, target_workdir):<tab>""""""Remove the first line of comment from each file if it contains a timestamp.""""""<tab>for root, _, filenames in safe_walk(target_workdir):<tab><tab>for filename in filenames:<tab><tab><tab>source = os.path.join(root, filename)<tab><tab><tab>with open(source, ""r"") as f:<tab><tab><tab><tab>lines = f.readlines()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>with open(source, ""w"") as f:<tab><tab><tab><tab>if not self._COMMENT_WITH_TIMESTAMP_RE.match(lines[0]):<tab><tab><tab><tab><tab>f.write(lines[0])<tab><tab><tab><tab>for line in lines[1:]:<tab><tab><tab><tab><tab>f.write(line)",if len ( lines ) < 1 :,196
3320,"def inner(request, *args, **kwargs):<tab>page = request.current_page<tab>if page:<tab><tab>if page.login_required and not request.user.is_authenticated:<tab><tab><tab>return redirect_to_login(<tab><tab><tab><tab>urlquote(request.get_full_path()), settings.LOGIN_URL<tab><tab><tab>)<tab><tab>site = get_current_site()<tab><tab><IF-STMT><tab><tab><tab>return _handle_no_page(request)<tab>return func(request, *args, **kwargs)","if not user_can_view_page ( request . user , page , site ) :",141
3321,"def flush(self, *args, **kwargs):<tab>with self._lock:<tab><tab>self._last_updated = time.time()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>mailbox.mbox.flush(self, *args, **kwargs)<tab><tab>except OSError:<tab><tab><tab>if ""_create_temporary"" in traceback.format_exc():<tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab><tab>self._last_updated = time.time()","if kwargs . get ( ""in_place"" , False ) :",157
3322,"def sanitize_event_keys(kwargs, valid_keys):<tab># Sanity check: Don't honor keys that we don't recognize.<tab>for key in list(kwargs.keys()):<tab><tab>if key not in valid_keys:<tab><tab><tab>kwargs.pop(key)<tab># Truncate certain values over 1k<tab>for key in [""play"", ""role"", ""task"", ""playbook""]:<tab><tab><IF-STMT><tab><tab><tab>if len(kwargs[""event_data""][key]) > 1024:<tab><tab><tab><tab>kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars(<tab><tab><tab><tab><tab>1024<tab><tab><tab><tab>)","if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :",168
3323,"def parse_auth(val):<tab>if val is not None:<tab><tab>authtype, params = val.split("" "", 1)<tab><tab><IF-STMT><tab><tab><tab>if authtype == ""Basic"" and '""' not in params:<tab><tab><tab><tab># this is the ""Authentication: Basic XXXXX=="" case<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>params = parse_auth_params(params)<tab><tab>return authtype, params<tab>return val",if authtype in known_auth_schemes :,117
3324,"def _memoized(*args):<tab>now = time.time()<tab>try:<tab><tab>value, last_update = self.cache[args]<tab><tab>age = now - last_update<tab><tab>if self._call_count > self.ctl or age > self.ttl:<tab><tab><tab>self._call_count = 0<tab><tab><tab>raise AttributeError<tab><tab>if self.ctl:<tab><tab><tab>self._call_count += 1<tab><tab>return value<tab>except (KeyError, AttributeError):<tab><tab>value = func(*args)<tab><tab><IF-STMT><tab><tab><tab>self.cache[args] = (value, now)<tab><tab>return value<tab>except TypeError:<tab><tab>return func(*args)",if value :,164
3325,"def _get_md_bg_color_down(self):<tab>t = self.theme_cls<tab>c = self.md_bg_color  # Default to no change on touch<tab># Material design specifies using darker hue when on Dark theme<tab>if t.theme_style == ""Dark"":<tab><tab>if self.md_bg_color == t.primary_color:<tab><tab><tab>c = t.primary_dark<tab><tab><IF-STMT><tab><tab><tab>c = t.accent_dark<tab>return c",elif self . md_bg_color == t . accent_color :,135
3326,def _init_table_h():<tab>_table_h = []<tab>for i in range(256):<tab><tab>part_l = i<tab><tab>part_h = 0<tab><tab>for j in range(8):<tab><tab><tab>rflag = part_l & 1<tab><tab><tab>part_l >>= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>part_l |= 1 << 31<tab><tab><tab>part_h >>= 1<tab><tab><tab>if rflag:<tab><tab><tab><tab>part_h ^= 0xD8000000<tab><tab>_table_h.append(part_h)<tab>return _table_h,if part_h & 1 :,147
3327,"def migrate_Stats(self):<tab>for old_obj in self.session_old.query(self.model_from[""Stats""]):<tab><tab>if not old_obj.summary:<tab><tab><tab>self.entries_count[""Stats""] -= 1<tab><tab><tab>continue<tab><tab>new_obj = self.model_to[""Stats""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>setattr(new_obj, key, getattr(old_obj, key))<tab><tab>self.session_new.add(new_obj)",if key not in old_obj . __table__ . columns :,152
3328,"def get_in_turn_repetition(pred, is_cn=False):<tab>""""""Get in-turn repetition.""""""<tab>if len(pred) == 0:<tab><tab>return 1.0<tab>if isinstance(pred[0], str):<tab><tab>pred = [tok.lower() for tok in pred]<tab><tab>if is_cn:<tab><tab><tab>pred = """".join(pred)<tab>tri_grams = set()<tab>for i in range(len(pred) - 2):<tab><tab>tri_gram = tuple(pred[i : i + 3])<tab><tab><IF-STMT><tab><tab><tab>return 1.0<tab><tab>tri_grams.add(tri_gram)<tab>return 0.0",if tri_gram in tri_grams :,169
3329,"def translate():<tab>assert Lex.next() is AttributeList<tab>reader.read()  # Discard attribute list from reader.<tab>attrs = {}<tab>d = AttributeList.match.groupdict()<tab>for k, v in d.items():<tab><tab>if v is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v = subs_attrs(v)<tab><tab><tab><tab>if v:<tab><tab><tab><tab><tab>parse_attributes(v, attrs)<tab><tab><tab>else:<tab><tab><tab><tab>AttributeList.attrs[k] = v<tab>AttributeList.subs(attrs)<tab>AttributeList.attrs.update(attrs)","if k == ""attrlist"" :",150
3330,"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab>if ""axis"" in self.args:<tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab>if ""momentum"" in self.args:<tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab>if not isinstance(self.momentum, (int, float)):<tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')","if not isinstance ( self . axis , int ) :",157
3331,"def __getattr__(self, attrname):<tab>if attrname in (""visamp"", ""visamperr"", ""visphi"", ""visphierr""):<tab><tab>return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag)<tab>elif attrname in (""cflux"", ""cfluxerr""):<tab><tab><IF-STMT><tab><tab><tab>return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag)<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>raise AttributeError(attrname)","if self . __dict__ [ ""_"" + attrname ] != None :",141
3332,"def draw(self, context):<tab>layout = self.layout<tab>presets.draw_presets_ops(layout, context=context)<tab>for category in presets.get_category_names():<tab><tab><IF-STMT><tab><tab><tab>if category in preset_category_menus:<tab><tab><tab><tab>class_name = preset_category_menus[category].__name__<tab><tab><tab><tab>layout.menu(class_name)",if category in preset_category_menus :,107
3333,"def __setitem__(self, key, value):<tab>if isinstance(value, (tuple, list)):<tab><tab>info, reference = value<tab><tab>if info not in self._reverse_infos:<tab><tab><tab>self._reverse_infos[info] = len(self._infos)<tab><tab><tab>self._infos.append(info)<tab><tab><IF-STMT><tab><tab><tab>self._reverse_references[reference] = len(self._references)<tab><tab><tab>self._references.append(reference)<tab><tab>self._trails[key] = ""%d,%d"" % (<tab><tab><tab>self._reverse_infos[info],<tab><tab><tab>self._reverse_references[reference],<tab><tab>)<tab>else:<tab><tab>raise Exception(""unsupported type '%s'"" % type(value))",if reference not in self . _reverse_references :,184
3334,"def format_bpe_text(symbols, delimiter=b""@@""):<tab>""""""Convert a sequence of bpe words into sentence.""""""<tab>words = []<tab>word = b""""<tab>if isinstance(symbols, str):<tab><tab>symbols = symbols.encode()<tab>delimiter_len = len(delimiter)<tab>for symbol in symbols:<tab><tab><IF-STMT><tab><tab><tab>word += symbol[:-delimiter_len]<tab><tab>else:  # end of a word<tab><tab><tab>word += symbol<tab><tab><tab>words.append(word)<tab><tab><tab>word = b""""<tab>return b"" "".join(words)",if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,154
3335,"def output_type(data, request, response):<tab>accept = request.accept<tab>if accept in ("""", ""*"", ""/""):<tab><tab>handler = default or handlers and next(iter(handlers.values()))<tab>else:<tab><tab>handler = default<tab><tab>accepted = [accept_quality(accept_type) for accept_type in accept.split("","")]<tab><tab>accepted.sort(key=itemgetter(0))<tab><tab>for _quality, accepted_content_type in reversed(accepted):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler = handlers[accepted_content_type]<tab><tab><tab><tab>break<tab>if not handler:<tab><tab>raise falcon.HTTPNotAcceptable(error)<tab>response.content_type = handler.content_type<tab>return handler(data, request=request, response=response)",if accepted_content_type in handlers :,189
3336,"def _render_raw_list(bytes_items):<tab>flatten_items = []<tab>for item in bytes_items:<tab><tab>if item is None:<tab><tab><tab>flatten_items.append(b"""")<tab><tab>elif isinstance(item, bytes):<tab><tab><tab>flatten_items.append(item)<tab><tab><IF-STMT><tab><tab><tab>flatten_items.append(str(item).encode())<tab><tab>elif isinstance(item, list):<tab><tab><tab>flatten_items.append(_render_raw_list(item))<tab>return b""\n"".join(flatten_items)","elif isinstance ( item , int ) :",138
3337,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_mime_type(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_quality(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 8 :,122
3338,"def delete(self, waiters):<tab># Delete flow.<tab>msgs = self.ofctl.get_all_flow(waiters)<tab>for msg in msgs:<tab><tab>for stats in msg.body:<tab><tab><tab>vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.ofctl.delete_flow(stats)<tab>assert len(self.packet_buffer) == 0",if vlan_id == self . vlan_id :,127
3339,def missing_push_allowance(push_allowances: List[PushAllowance]) -> bool:<tab>for push_allowance in push_allowances:<tab><tab># a null databaseId indicates this is not a GitHub App.<tab><tab>if push_allowance.actor.databaseId is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,112
3340,"def _cluster_page(self, htmlpage):<tab>template_cluster, preferred = _CLUSTER_NA, None<tab>if self.clustering:<tab><tab>self.clustering.add_page(htmlpage)<tab><tab><IF-STMT><tab><tab><tab>clt = self.clustering.classify(htmlpage)<tab><tab><tab>if clt != -1:<tab><tab><tab><tab>template_cluster = preferred = self.template_names[clt]<tab><tab><tab>else:<tab><tab><tab><tab>template_cluster = _CLUSTER_OUTLIER<tab>return template_cluster, preferred",if self . clustering . is_fit :,136
3341,"def readlines(self, size=-1):<tab>if self._nbr == self._size:<tab><tab>return []<tab># leave all additional logic to our readline method, we just check the size<tab>out = []<tab>nbr = 0<tab>while True:<tab><tab>line = self.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab>out.append(line)<tab><tab>if size > -1:<tab><tab><tab>nbr += len(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab># END handle size constraint<tab># END readline loop<tab>return out",if nbr > size :,145
3342,"def post_mortem(t=None):<tab># handling the default<tab><IF-STMT><tab><tab># sys.exc_info() returns (type, value, traceback) if an exception is<tab><tab># being handled, otherwise it returns None<tab><tab>t = sys.exc_info()[2]<tab><tab>if t is None:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""A valid traceback must be passed if no exception is being handled.""<tab><tab><tab>)<tab>p = BPdb()<tab>p.reset()<tab>p.interaction(None, t)",if t is None :,132
3343,"def fixup(m):<tab>txt = m.group(0)<tab>if txt[:2] == ""&#"":<tab><tab># character reference<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return unichr(int(txt[3:-1], 16))<tab><tab><tab>else:<tab><tab><tab><tab>return unichr(int(txt[2:-1]))<tab><tab>except ValueError:<tab><tab><tab>pass<tab>else:<tab><tab># named entity<tab><tab>try:<tab><tab><tab>txt = unichr(htmlentitydefs.name2codepoint[txt[1:-1]])<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return txt  # leave as is","if txt [ : 3 ] == ""&#x"" :",157
3344,"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]:<tab>argstr += "",""<tab>args = []<tab>kwargs = {}<tab>for item in _converter_args_re.finditer(argstr):<tab><tab>value = item.group(""stringval"")<tab><tab><IF-STMT><tab><tab><tab>value = item.group(""value"")<tab><tab>value = _pythonize(value)<tab><tab>if not item.group(""name""):<tab><tab><tab>args.append(value)<tab><tab>else:<tab><tab><tab>name = item.group(""name"")<tab><tab><tab>kwargs[name] = value<tab>return tuple(args), kwargs",if value is None :,164
3345,"def IT(cpu):<tab>cc = cpu.instruction.cc<tab>true_case = cpu._evaluate_conditional(cc)<tab># this is incredibly hacky--how else does capstone expose this?<tab># TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13<tab>for c in cpu.instruction.mnemonic[1:]:<tab><tab><IF-STMT><tab><tab><tab>cpu._it_conditional.append(true_case)<tab><tab>elif c == ""e"":<tab><tab><tab>cpu._it_conditional.append(not true_case)","if c == ""t"" :",138
3346,"def flatten(self):<tab># this is similar to fill_messages except it uses a list instead<tab># of a queue to place the messages in.<tab>result = []<tab>channel = await self.messageable._get_channel()<tab>self.channel = channel<tab>while self._get_retrieve():<tab><tab>data = await self._retrieve_messages(self.retrieve)<tab><tab><IF-STMT><tab><tab><tab>self.limit = 0  # terminate the infinite loop<tab><tab>if self.reverse:<tab><tab><tab>data = reversed(data)<tab><tab>if self._filter:<tab><tab><tab>data = filter(self._filter, data)<tab><tab>for element in data:<tab><tab><tab>result.append(self.state.create_message(channel=channel, data=element))<tab>return result",if len ( data ) < 100 :,187
3347,"def _get_beta_accumulators(self):<tab>with tf.init_scope():<tab><tab><IF-STMT><tab><tab><tab>graph = None<tab><tab>else:<tab><tab><tab>graph = tf.get_default_graph()<tab><tab>return (<tab><tab><tab>self._get_non_slot_variable(""beta1_power"", graph=graph),<tab><tab><tab>self._get_non_slot_variable(""beta2_power"", graph=graph),<tab><tab>)",if tf . executing_eagerly ( ) :,113
3348,"def prefixed(self, prefix: _StrType) -> typing.Iterator[""Env""]:<tab>""""""Context manager for parsing envvars with a common prefix.""""""<tab>try:<tab><tab>old_prefix = self._prefix<tab><tab><IF-STMT><tab><tab><tab>self._prefix = prefix<tab><tab>else:<tab><tab><tab>self._prefix = f""{old_prefix}{prefix}""<tab><tab>yield self<tab>finally:<tab><tab># explicitly reset the stored prefix on completion and exceptions<tab><tab>self._prefix = None<tab>self._prefix = old_prefix",if old_prefix is None :,126
3349,"def decode_content(self):<tab>""""""Return the best possible representation of the response body.""""""<tab>ct = self.headers.get(""content-type"")<tab>if ct:<tab><tab>ct, options = parse_options_header(ct)<tab><tab>charset = options.get(""charset"")<tab><tab>if ct in JSON_CONTENT_TYPES:<tab><tab><tab>return self.json(charset)<tab><tab><IF-STMT><tab><tab><tab>return self.text(charset)<tab><tab>elif ct == FORM_URL_ENCODED:<tab><tab><tab>return parse_qsl(self.content.decode(charset), keep_blank_values=True)<tab>return self.content","elif ct . startswith ( ""text/"" ) :",156
3350,"def test_incrementaldecoder(self):<tab>UTF8Writer = codecs.getwriter(""utf-8"")<tab>for sizehint in [None, -1] + list(range(1, 33)) + [64, 128, 256, 512, 1024]:<tab><tab>istream = BytesIO(self.tstring[0])<tab><tab>ostream = UTF8Writer(BytesIO())<tab><tab>decoder = self.incrementaldecoder()<tab><tab>while 1:<tab><tab><tab>data = istream.read(sizehint)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>u = decoder.decode(data)<tab><tab><tab><tab>ostream.write(u)<tab><tab>self.assertEqual(ostream.getvalue(), self.tstring[1])",if not data :,178
3351,"def delete_all(path):<tab>ppath = os.getcwd()<tab>os.chdir(path)<tab>for fn in glob.glob(""*""):<tab><tab>fn_full = os.path.join(path, fn)<tab><tab><IF-STMT><tab><tab><tab>delete_all(fn_full)<tab><tab>elif fn.endswith("".png""):<tab><tab><tab>os.remove(fn_full)<tab><tab>elif fn.endswith("".md""):<tab><tab><tab>os.remove(fn_full)<tab><tab>elif DELETE_ALL_OLD:<tab><tab><tab>os.remove(fn_full)<tab>os.chdir(ppath)<tab>os.rmdir(path)",if os . path . isdir ( fn ) :,158
3352,"def _delete_reason(self):<tab>for i in range(_lib.X509_REVOKED_get_ext_count(self._revoked)):<tab><tab>ext = _lib.X509_REVOKED_get_ext(self._revoked, i)<tab><tab>obj = _lib.X509_EXTENSION_get_object(ext)<tab><tab><IF-STMT><tab><tab><tab>_lib.X509_EXTENSION_free(ext)<tab><tab><tab>_lib.X509_REVOKED_delete_ext(self._revoked, i)<tab><tab><tab>break",if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,158
3353,"def hexcmp(x, y):<tab>try:<tab><tab>a = int(x, 16)<tab><tab>b = int(y, 16)<tab><tab>if a < b:<tab><tab><tab>return -1<tab><tab><IF-STMT><tab><tab><tab>return 1<tab><tab>return 0<tab>except:<tab><tab>return cmp(x, y)",if a > b :,83
3354,"def get_indentation_count(view, start):<tab>indent_count = 0<tab>i = start - 1<tab>while i > 0:<tab><tab>ch = view.substr(i)<tab><tab>scope = view.scope_name(i)<tab><tab># Skip preprocessors, strings, characaters and comments<tab><tab>if ""string.quoted"" in scope or ""comment"" in scope or ""preprocessor"" in scope:<tab><tab><tab>extent = view.extract_scope(i)<tab><tab><tab>i = extent.a - 1<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>i -= 1<tab><tab><IF-STMT><tab><tab><tab>indent_count -= 1<tab><tab>elif ch == ""{"":<tab><tab><tab>indent_count += 1<tab>return indent_count","if ch == ""}"" :",177
3355,"def set(self, name, value, ex=None, px=None, nx=False, xx=False):<tab>if (<tab><tab>(not nx and not xx)<tab><tab>or (nx and self._db.get(name, None) is None)<tab><tab>or (xx and not self._db.get(name, None) is None)<tab>):<tab><tab>if ex > 0:<tab><tab><tab>self._db.expire(name, datetime.now() + timedelta(seconds=ex))<tab><tab><IF-STMT><tab><tab><tab>self._db.expire(name, datetime.now() + timedelta(milliseconds=px))<tab><tab>self._db[name] = str(value)<tab><tab>return True<tab>else:<tab><tab>return None",elif px > 0 :,174
3356,"def _get_between(content, start, end=None):<tab>should_yield = False<tab>for line in content.split(""\n""):<tab><tab>if start in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if end and end in line:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>yield line.strip().split("" "")[0]",if should_yield and line :,94
3357,"def iter_event_handlers(<tab>self,<tab>resource: resources_.Resource,<tab>event: bodies.RawEvent,) -> Iterator[handlers.ResourceWatchingHandler]:<tab>warnings.warn(<tab><tab>""SimpleRegistry.iter_event_handlers() is deprecated; use ""<tab><tab>""ResourceWatchingRegistry.iter_handlers()."",<tab><tab>DeprecationWarning,<tab>)<tab>cause = _create_watching_cause(resource, event)<tab>for handler in self._handlers:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif registries.match(handler=handler, cause=cause, ignore_fields=True):<tab><tab><tab>yield handler","if not isinstance ( handler , handlers . ResourceWatchingHandler ) :",160
3358,"def __enter__(self):<tab>if log_timer:<tab><tab><IF-STMT><tab><tab><tab>self.logger.debug(""%s starting"" % self.name)<tab><tab>else:<tab><tab><tab>print((""[%s starting]..."" % self.name))<tab><tab>self.tstart = time.time()",if self . logger :,74
3359,"def _handle_errors(errors):<tab>""""""Log out and possibly reraise errors during import.""""""<tab>if not errors:<tab><tab>return<tab>log_all = True  # pylint: disable=unused-variable<tab>err_msg = ""T2T: skipped importing {num_missing} data_generators modules.""<tab>print(err_msg.format(num_missing=len(errors)))<tab>for module, err in errors:<tab><tab>err_str = str(err)<tab><tab><IF-STMT><tab><tab><tab>print(""Did not import module: %s; Cause: %s"" % (module, err_str))<tab><tab>if not _is_import_err_msg(err_str, module):<tab><tab><tab>print(""From module %s"" % module)<tab><tab><tab>raise err",if log_all :,184
3360,"def _ungroup(sequence, groups=None):<tab>for v in sequence:<tab><tab>if isinstance(v, (list, tuple)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>groups.append(list(_ungroup(v, groups=None)))<tab><tab><tab>for v in _ungroup(v, groups):<tab><tab><tab><tab>yield v<tab><tab>else:<tab><tab><tab>yield v",if groups is not None :,95
3361,def run(self):<tab>while not self.completed:<tab><tab>if self.block:<tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab>if self.timeout is not None:<tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.stop()<tab><tab>if self.counter == self.count:<tab><tab><tab>self.stop(),if dt > self . timeout :,159
3362,"def dont_let_stderr_buffer():<tab>while True:<tab><tab>line = context.daemon.stderr.readline()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if DEAD_DEPLOYD_WORKER_MESSAGE.encode(""utf-8"") in line:<tab><tab><tab>context.num_workers_crashed += 1<tab><tab>print(f""deployd stderr: {line}"")",if not line :,93
3363,"def mergeHiLo(self, x_stats):<tab>""""""Merge the highs and lows of another accumulator into myself.""""""<tab>if x_stats.firsttime is not None:<tab><tab>if self.firsttime is None or x_stats.firsttime < self.firsttime:<tab><tab><tab>self.firsttime = x_stats.firsttime<tab><tab><tab>self.first = x_stats.first<tab>if x_stats.lasttime is not None:<tab><tab><IF-STMT><tab><tab><tab>self.lasttime = x_stats.lasttime<tab><tab><tab>self.last = x_stats.last",if self . lasttime is None or x_stats . lasttime >= self . lasttime :,157
3364,"def test_rlimit_get(self):<tab>import resource<tab>p = psutil.Process(os.getpid())<tab>names = [x for x in dir(psutil) if x.startswith(""RLIMIT"")]<tab>assert names<tab>for name in names:<tab><tab>value = getattr(psutil, name)<tab><tab>self.assertGreaterEqual(value, 0)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(value, getattr(resource, name))<tab><tab><tab>self.assertEqual(p.rlimit(value), resource.getrlimit(value))<tab><tab>else:<tab><tab><tab>ret = p.rlimit(value)<tab><tab><tab>self.assertEqual(len(ret), 2)<tab><tab><tab>self.assertGreaterEqual(ret[0], -1)<tab><tab><tab>self.assertGreaterEqual(ret[1], -1)",if name in dir ( resource ) :,192
3365,"def _calculate_writes_for_built_in_indices(self, entity):<tab>writes = 0<tab>for prop_name in entity.keys():<tab><tab>if not prop_name in entity.unindexed_properties():<tab><tab><tab>prop_vals = entity[prop_name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>num_prop_vals = len(prop_vals)<tab><tab><tab>else:<tab><tab><tab><tab>num_prop_vals = 1<tab><tab><tab>writes += 2 * num_prop_vals<tab>return writes","if isinstance ( prop_vals , ( list ) ) :",131
3366,"def check_value_check(self, x_data, t_data, use_cudnn):<tab>x = chainer.Variable(x_data)<tab>t = chainer.Variable(t_data)<tab>with chainer.using_config(""use_cudnn"", use_cudnn):<tab><tab><IF-STMT><tab><tab><tab># Check if it throws nothing<tab><tab><tab>functions.softmax_cross_entropy(<tab><tab><tab><tab>x, t, enable_double_backprop=self.enable_double_backprop<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>with self.assertRaises(ValueError):<tab><tab><tab><tab>functions.softmax_cross_entropy(<tab><tab><tab><tab><tab>x, t, enable_double_backprop=self.enable_double_backprop<tab><tab><tab><tab>)",if self . valid :,188
3367,"def get_note_title_file(note):<tab>mo = note_title_re.match(note.get(""content"", """"))<tab>if mo:<tab><tab>fn = mo.groups()[0]<tab><tab>fn = fn.replace("" "", ""_"")<tab><tab>fn = fn.replace(""/"", ""_"")<tab><tab><IF-STMT><tab><tab><tab>return """"<tab><tab>if isinstance(fn, str):<tab><tab><tab>fn = unicode(fn, ""utf-8"")<tab><tab>else:<tab><tab><tab>fn = unicode(fn)<tab><tab>if note_markdown(note):<tab><tab><tab>fn += "".mkdn""<tab><tab>else:<tab><tab><tab>fn += "".txt""<tab><tab>return fn<tab>else:<tab><tab>return """"",if not fn :,169
3368,"def _parseparam(s):<tab>plist = []<tab>while s[:1] == "";"":<tab><tab>s = s[1:]<tab><tab>end = s.find("";"")<tab><tab>while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2:<tab><tab><tab>end = s.find("";"", end + 1)<tab><tab>if end < 0:<tab><tab><tab>end = len(s)<tab><tab>f = s[:end]<tab><tab><IF-STMT><tab><tab><tab>i = f.index(""="")<tab><tab><tab>f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip()<tab><tab>plist.append(f.strip())<tab><tab>s = s[end:]<tab>return plist","if ""="" in f :",177
3369,"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab>if not isinstance(child, minidom.Element):<tab><tab><tab>continue<tab><tab>if child.tagName == ""Directory"":<tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab>if not isinstance(grandchild, minidom.Element):<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if grandchild . tagName != ""File"" :",152
3370,"def date_to_format(value, target_format):<tab>""""""Convert date to specified format""""""<tab>if target_format == str:<tab><tab><IF-STMT><tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab>elif isinstance(value, datetime.datetime):<tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab>elif isinstance(value, datetime.time):<tab><tab><tab>ret = value.strftime(""%H:%M:%S"")<tab>else:<tab><tab>ret = value<tab>return ret","if isinstance ( value , datetime . date ) :",130
3371,"def __listingColumns(self):<tab>columns = []<tab>for name in self.__getColumns():<tab><tab>definition = column(name)<tab><tab><IF-STMT><tab><tab><tab>IECore.msg(<tab><tab><tab><tab>IECore.Msg.Level.Error,<tab><tab><tab><tab>""GafferImageUI.CatalogueUI"",<tab><tab><tab><tab>""No column registered with name '%s'"" % name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>if isinstance(definition, IconColumn):<tab><tab><tab>c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name)<tab><tab>else:<tab><tab><tab>c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name)<tab><tab>columns.append(c)<tab>return columns",if not definition :,184
3372,"def metrics_to_scalars(self, metrics):<tab>new_metrics = {}<tab>for k, v in metrics.items():<tab><tab><IF-STMT><tab><tab><tab>v = v.item()<tab><tab>if isinstance(v, dict):<tab><tab><tab>v = self.metrics_to_scalars(v)<tab><tab>new_metrics[k] = v<tab>return new_metrics","if isinstance ( v , torch . Tensor ) :",95
3373,"def start(self, connection):<tab>try:<tab><tab>if self.client_name:<tab><tab><tab>creds = gssapi.Credentials(name=gssapi.Name(self.client_name))<tab><tab>else:<tab><tab><tab>creds = None<tab><tab>hostname = self.get_hostname(connection)<tab><tab>name = gssapi.Name(<tab><tab><tab>b""@"".join([self.service, hostname]), gssapi.NameType.hostbased_service<tab><tab>)<tab><tab>context = gssapi.SecurityContext(name=name, creds=creds)<tab><tab>return context.step(None)<tab>except gssapi.raw.misc.GSSError:<tab><tab><IF-STMT><tab><tab><tab>return NotImplemented<tab><tab>else:<tab><tab><tab>raise",if self . fail_soft :,186
3374,"def nanmax(self, axis=None, dtype=None, keepdims=None):<tab>ret = self._reduction(<tab><tab>""nanmax"", axis=axis, dtype=dtype, keepdims=keepdims, todense=True<tab>)<tab>if not issparse(ret):<tab><tab><IF-STMT><tab><tab><tab>return ret<tab><tab>xps = get_sparse_module(self.spmatrix)<tab><tab>ret = SparseNDArray(xps.csr_matrix(ret))<tab><tab>return ret<tab>return ret",if get_array_module ( ret ) . isscalar ( ret ) :,120
3375,"def utterance_to_sample(query_data, tagging_scheme, language):<tab>tokens, tags = [], []<tab>current_length = 0<tab>for chunk in query_data:<tab><tab>chunk_tokens = tokenize(chunk[TEXT], language)<tab><tab>tokens += [<tab><tab><tab>Token(t.value, current_length + t.start, current_length + t.end)<tab><tab><tab>for t in chunk_tokens<tab><tab>]<tab><tab>current_length += len(chunk[TEXT])<tab><tab><IF-STMT><tab><tab><tab>tags += negative_tagging(len(chunk_tokens))<tab><tab>else:<tab><tab><tab>tags += positive_tagging(<tab><tab><tab><tab>tagging_scheme, chunk[SLOT_NAME], len(chunk_tokens)<tab><tab><tab>)<tab>return {TOKENS: tokens, TAGS: tags}",if SLOT_NAME not in chunk :,200
3376,"def use_index(<tab>self, term: Union[str, Index], *terms: Union[str, Index]) -> ""QueryBuilder"":<tab>for t in (term, *terms):<tab><tab>if isinstance(t, Index):<tab><tab><tab>self._use_indexes.append(t)<tab><tab><IF-STMT><tab><tab><tab>self._use_indexes.append(Index(t))","elif isinstance ( t , str ) :",94
3377,"def reconfigServiceWithBuildbotConfig(self, new_config):<tab>if new_config.manhole != self.manhole:<tab><tab>if self.manhole:<tab><tab><tab>yield self.manhole.disownServiceParent()<tab><tab><tab>self.manhole = None<tab><tab><IF-STMT><tab><tab><tab>self.manhole = new_config.manhole<tab><tab><tab>yield self.manhole.setServiceParent(self)<tab># chain up<tab>yield service.ReconfigurableServiceMixin.reconfigServiceWithBuildbotConfig(<tab><tab>self, new_config<tab>)",if new_config . manhole :,142
3378,"def cleanup_folder(target_folder):<tab>for file in os.listdir(target_folder):<tab><tab>file_path = os.path.join(target_folder, file)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(file_path)<tab><tab>except Exception as e:<tab><tab><tab>logging.error(e)",if os . path . isfile ( file_path ) :,93
3379,"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab><IF-STMT><tab><tab><tab>return unicode(float_repr(k))<tab><tab>elif ""regex"" in literal_or_identifier:<tab><tab><tab>return compose_regex(k)<tab><tab>elif isinstance(k, bool):<tab><tab><tab>return ""true"" if k else ""false""<tab><tab>elif k is None:<tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)","if isinstance ( k , float ) :",179
3380,"def decompile(decompiler):<tab>for pos, next_pos, opname, arg in decompiler.instructions:<tab><tab>if pos in decompiler.targets:<tab><tab><tab>decompiler.process_target(pos)<tab><tab>method = getattr(decompiler, opname, None)<tab><tab><IF-STMT><tab><tab><tab>throw(DecompileError(""Unsupported operation: %s"" % opname))<tab><tab>decompiler.pos = pos<tab><tab>decompiler.next_pos = next_pos<tab><tab>x = method(*arg)<tab><tab>if x is not None:<tab><tab><tab>decompiler.stack.append(x)",if method is None :,143
3381,"def shutdown(self, timeout, callback=None):<tab>logger.debug(""background worker got shutdown request"")<tab>with self._lock:<tab><tab>if self.is_alive:<tab><tab><tab>self._queue.put_nowait(_TERMINATOR)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._wait_shutdown(timeout, callback)<tab><tab>self._thread = None<tab><tab>self._thread_for_pid = None<tab>logger.debug(""background worker shut down"")",if timeout > 0.0 :,113
3382,"def getDOMImplementation(features=None):<tab>if features:<tab><tab><IF-STMT><tab><tab><tab>features = domreg._parse_feature_string(features)<tab><tab>for f, v in features:<tab><tab><tab>if not Document.implementation.hasFeature(f, v):<tab><tab><tab><tab>return None<tab>return Document.implementation","if isinstance ( features , str ) :",83
3383,"def validate_subevent(self, subevent):<tab>if self.context[""event""].has_subevents:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(""You need to set a subevent."")<tab><tab>if subevent.event != self.context[""event""]:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>""The specified subevent does not belong to this event.""<tab><tab><tab>)<tab>elif subevent:<tab><tab>raise ValidationError(""You cannot set a subevent for this event."")<tab>return subevent",if not subevent :,120
3384,"def einsum(job_id, idx, einsum_expr, data_list):<tab>_, all_parties = session_init(job_id, idx)<tab>with SPDZ():<tab><tab><IF-STMT><tab><tab><tab>x = FixedPointTensor.from_source(""x"", data_list[0])<tab><tab><tab>y = FixedPointTensor.from_source(""y"", all_parties[1])<tab><tab>else:<tab><tab><tab>x = FixedPointTensor.from_source(""x"", all_parties[0])<tab><tab><tab>y = FixedPointTensor.from_source(""y"", data_list[1])<tab><tab>return x.einsum(y, einsum_expr).get()",if idx == 0 :,162
3385,"def slowSorted(qq):<tab>""Reference sort peformed by insertion using only <""<tab>rr = list()<tab>for q in qq:<tab><tab>i = 0<tab><tab>for i in range(len(rr)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rr.insert(i, q)<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>rr.append(q)<tab>return rr",if q < rr [ i ] :,101
3386,"def _format_entry(entry, src):<tab>if entry:<tab><tab>result = []<tab><tab>for x in entry.split("",""):<tab><tab><tab>x = x.strip()<tab><tab><tab>if os.path.exists(os.path.join(src, x)):<tab><tab><tab><tab>result.append(relpath(os.path.join(src, x), src))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(relpath(os.path.abspath(x), src))<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""No entry script %s found"" % x)<tab><tab>return "","".join(result)",elif os . path . exists ( x ) :,153
3387,"def reloadCols(self):<tab>self.columns = []<tab>for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr):<tab><tab>if shape:<tab><tab><tab>t = anytype<tab><tab>elif ""M"" in fmt:<tab><tab><tab>self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i])))<tab><tab><tab>continue<tab><tab>elif ""i"" in fmt:<tab><tab><tab>t = int<tab><tab><IF-STMT><tab><tab><tab>t = float<tab><tab>else:<tab><tab><tab>t = anytype<tab><tab>self.addColumn(ColumnItem(name, i, type=t))","elif ""f"" in fmt :",168
3388,"def tool_lineages(self, trans):<tab>rval = []<tab>for id, tool in self.app.toolbox.tools():<tab><tab><IF-STMT><tab><tab><tab>lineage_dict = tool.lineage.to_dict()<tab><tab>else:<tab><tab><tab>lineage_dict = None<tab><tab>entry = dict(id=id, lineage=lineage_dict)<tab><tab>rval.append(entry)<tab>return rval","if hasattr ( tool , ""lineage"" ) :",102
3389,"def item(self, tensor):<tab>numel = 0<tab>if len(tensor.shape) > 0:<tab><tab>numel = fct.reduce(op.mul, tensor.shape)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""expected tensor with one element, "" f""got {tensor.shape}""<tab><tab><tab>)<tab>if numel == 1:<tab><tab>return tensor[0]<tab>return tensor",if numel != 1 :,105
3390,"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(<tab><tab><tab><tab>self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1<tab><tab><tab>).json()<tab><tab><tab>if ""Version"" in resp:<tab><tab><tab><tab>match = AGENT_VERSION_EXP.search(resp.get(""Version""))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>meta[""ecs_version""] = match.group(1)<tab><tab>except Exception as e:<tab><tab><tab>self.log.debug(""Error getting ECS version: %s"" % str(e))<tab>return meta",if match is not None and len ( match . groups ( ) ) == 1 :,176
3391,"def generate():<tab>for leaf in u.leaves:<tab><tab>if isinstance(leaf, Integer):<tab><tab><tab>val = leaf.get_int_value()<tab><tab><tab>if val in (0, 1):<tab><tab><tab><tab>yield val<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>elif isinstance(leaf, Symbol):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield 1<tab><tab><tab>elif leaf == SymbolFalse:<tab><tab><tab><tab>yield 0<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>else:<tab><tab><tab>raise _NoBoolVector",if leaf == SymbolTrue :,138
3392,"def _test_set_metadata(self, metadata, mask=None):<tab>header = ofproto.OXM_OF_METADATA<tab>match = OFPMatch()<tab>if mask is None:<tab><tab>match.set_metadata(metadata)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>header = ofproto.OXM_OF_METADATA_W<tab><tab>match.set_metadata_masked(metadata, mask)<tab><tab>metadata &= mask<tab>self._test_serialize_and_parser(match, header, metadata, mask)",if ( mask + 1 ) >> 64 != 1 :,134
3393,"def pixbufrenderer(self, column, crp, model, it):<tab>tok = model.get_value(it, 0)<tab>if tok.type == ""class"":<tab><tab>icon = ""class""<tab>else:<tab><tab>if tok.visibility == ""private"":<tab><tab><tab>icon = ""method_priv""<tab><tab><IF-STMT><tab><tab><tab>icon = ""method_prot""<tab><tab>else:<tab><tab><tab>icon = ""method""<tab>crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])","elif tok . visibility == ""protected"" :",132
3394,"def path_sum2(root, s):<tab>if root is None:<tab><tab>return []<tab>res = []<tab>stack = [(root, [root.val])]<tab>while stack:<tab><tab>node, ls = stack.pop()<tab><tab>if node.left is None and node.right is None and sum(ls) == s:<tab><tab><tab>res.append(ls)<tab><tab><IF-STMT><tab><tab><tab>stack.append((node.left, ls + [node.left.val]))<tab><tab>if node.right is not None:<tab><tab><tab>stack.append((node.right, ls + [node.right.val]))<tab>return res",if node . left is not None :,157
3395,"def clear_slot(self, slot_id, trigger_changed):<tab>if self.slots[slot_id] is not None:<tab><tab>old_resource_id = self.slots[slot_id].resource_id<tab><tab><IF-STMT><tab><tab><tab>del self.sell_list[old_resource_id]<tab><tab>else:<tab><tab><tab>del self.buy_list[old_resource_id]<tab>self.slots[slot_id] = None<tab>if trigger_changed:<tab><tab>self._changed()",if self . slots [ slot_id ] . selling :,132
3396,"def OnRightUp(self, event):<tab>self.HandleMouseEvent(event)<tab>self.Unbind(wx.EVT_RIGHT_UP, handler=self.OnRightUp)<tab>self.Unbind(wx.EVT_MOUSE_CAPTURE_LOST, handler=self.OnRightUp)<tab>self._right = False<tab>if not self._left:<tab><tab>self.Unbind(wx.EVT_MOTION, handler=self.OnMotion)<tab><tab>self.SendChangeEvent()<tab><tab>self.SetToolTip(wx.ToolTip(self._tooltip))<tab><tab><IF-STMT><tab><tab><tab>self.ReleaseMouse()",if self . HasCapture ( ) :,150
3397,"def __init__(self, *args, **kwargs):<tab>for arg in args:<tab><tab>for k, v in arg.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>arg[k] = AttrDict(v)<tab><tab><tab>else:<tab><tab><tab><tab>arg[k] = v<tab>super(AttrDict, self).__init__(*args, **kwargs)","if isinstance ( v , dict ) :",89
3398,"def _toplevelTryFunc(func, *args, status=status, **kwargs):<tab>with ThreadProfiler(threading.current_thread()) as prof:<tab><tab>t = threading.current_thread()<tab><tab>t.name = func.__name__<tab><tab>try:<tab><tab><tab>t.status = func(*args, **kwargs)<tab><tab>except EscapeException as e:  # user aborted<tab><tab><tab>t.status = ""aborted by user""<tab><tab><tab>if status:<tab><tab><tab><tab>status(""%s aborted"" % t.name, priority=2)<tab><tab>except Exception as e:<tab><tab><tab>t.exception = e<tab><tab><tab>t.status = ""exception""<tab><tab><tab>vd.exceptionCaught(e)<tab><tab><IF-STMT><tab><tab><tab>t.sheet.currentThreads.remove(t)",if t . sheet :,193
3399,"def comboSelectionChanged(self, index):<tab>text = self.comboBox.cb.itemText(index)<tab>for i in range(self.labelList.count()):<tab><tab>if text == """":<tab><tab><tab>self.labelList.item(i).setCheckState(2)<tab><tab><IF-STMT><tab><tab><tab>self.labelList.item(i).setCheckState(0)<tab><tab>else:<tab><tab><tab>self.labelList.item(i).setCheckState(2)",elif text != self . labelList . item ( i ) . text ( ) :,120
3400,"def __attempt_add_to_linked_match(<tab>self, input_name, hdca, collection_type_description, subcollection_type):<tab>structure = get_structure(<tab><tab>hdca, collection_type_description, leaf_subcollection_type=subcollection_type<tab>)<tab>if not self.linked_structure:<tab><tab>self.linked_structure = structure<tab><tab>self.collections[input_name] = hdca<tab><tab>self.subcollection_types[input_name] = subcollection_type<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise exceptions.MessageException(CANNOT_MATCH_ERROR_MESSAGE)<tab><tab>self.collections[input_name] = hdca<tab><tab>self.subcollection_types[input_name] = subcollection_type",if not self . linked_structure . can_match ( structure ) :,194
3401,"def _wait_for_bot_presense(self, online):<tab>for _ in range(10):<tab><tab>time.sleep(2)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if not online and not self._is_testbot_online():<tab><tab><tab>break<tab>else:<tab><tab>raise AssertionError(<tab><tab><tab>""test bot is still {}"".format(""offline"" if online else ""online"")<tab><tab>)",if online and self . _is_testbot_online ( ) :,111
3402,"def find(self, path):<tab>if os.path.isfile(path) or os.path.islink(path):<tab><tab>self.num_files = self.num_files + 1<tab><tab><IF-STMT><tab><tab><tab>self.files.append(path)<tab>elif os.path.isdir(path):<tab><tab>for content in os.listdir(path):<tab><tab><tab>file = os.path.join(path, content)<tab><tab><tab>if os.path.isfile(file) or os.path.islink(file):<tab><tab><tab><tab>self.num_files = self.num_files + 1<tab><tab><tab><tab>if self.match_function(file):<tab><tab><tab><tab><tab>self.files.append(file)<tab><tab><tab>else:<tab><tab><tab><tab>self.find(file)",if self . match_function ( path ) :,192
3403,"def optimize(self, graph: Graph):<tab>MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE<tab>flag_changed = False<tab>for v in traverse.listup_variables(graph):<tab><tab>if not Placeholder.check_resolved(v.size):<tab><tab><tab>continue<tab><tab>height, width = TextureShape.get(v)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not v.has_attribute(SplitTarget):<tab><tab><tab>flag_changed = True<tab><tab><tab>v.attributes.add(SplitTarget())<tab>return graph, flag_changed",if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE :,157
3404,"def brightness_func(args):<tab>device = _get_device_from_filter(args)<tab>if args.set is None:<tab><tab># Get brightness<tab><tab>if args.raw:<tab><tab><tab>print(str(device.brightness))<tab><tab>else:<tab><tab><tab>print(""Brightness: {0}%"".format(device.brightness))<tab>else:<tab><tab>brightness_value = float(_clamp_u8(args.set))<tab><tab><IF-STMT><tab><tab><tab>print(""Setting brightness to {0}%"".format(brightness_value))<tab><tab>device.brightness = brightness_value",if not args . raw :,139
3405,"def _setup(self, field_name, owner_model):<tab># Resolve possible name-based model reference.<tab>if not self.model_class:<tab><tab><IF-STMT><tab><tab><tab>self.model_class = owner_model<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""ModelType: Unable to resolve model '{}'."".format(self.model_name)<tab><tab><tab>)<tab>super(ModelType, self)._setup(field_name, owner_model)",if self . model_name == owner_model . __name__ :,124
3406,"def build_json_schema_object(cls, parent_builder=None):<tab>builder = builders.ObjectBuilder(cls, parent_builder)<tab>if builder.count_type(builder.type) > 1:<tab><tab>return builder<tab>for _, name, field in cls.iterate_with_name():<tab><tab>if isinstance(field, fields.EmbeddedField):<tab><tab><tab>builder.add_field(name, field, _parse_embedded(field, builder))<tab><tab><IF-STMT><tab><tab><tab>builder.add_field(name, field, _parse_list(field, builder))<tab><tab>else:<tab><tab><tab>builder.add_field(name, field, _create_primitive_field_schema(field))<tab>return builder","elif isinstance ( field , fields . ListField ) :",178
3407,"def filter_module(mod, type_req=None, subclass_req=None):<tab>for name in dir(mod):<tab><tab>val = getattr(mod, name)<tab><tab>if type_req is not None and not isinstance(val, type_req):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield name, val","if subclass_req is not None and not issubclass ( val , subclass_req ) :",97
3408,"def get_icon(self):<tab>if self.icon is not None:<tab><tab># Load it from an absolute filename<tab><tab>if os.path.exists(self.icon):<tab><tab><tab>try:<tab><tab><tab><tab>return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24)<tab><tab><tab>except GObject.GError as ge:<tab><tab><tab><tab>pass<tab><tab># Load it from the current icon theme<tab><tab>(icon_name, extension) = os.path.splitext(os.path.basename(self.icon))<tab><tab>theme = Gtk.IconTheme()<tab><tab><IF-STMT><tab><tab><tab>return theme.load_icon(icon_name, 24, 0)",if theme . has_icon ( icon_name ) :,174
3409,"def sysctlTestAndSet(name, limit):<tab>""Helper function to set sysctl limits""<tab># convert non-directory names into directory names<tab>if ""/"" not in name:<tab><tab>name = ""/proc/sys/"" + name.replace(""."", ""/"")<tab># read limit<tab>with open(name, ""r"") as readFile:<tab><tab>oldLimit = readFile.readline()<tab><tab>if isinstance(limit, int):<tab><tab><tab># compare integer limits before overriding<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with open(name, ""w"") as writeFile:<tab><tab><tab><tab><tab>writeFile.write(""%d"" % limit)<tab><tab>else:<tab><tab><tab># overwrite non-integer limits<tab><tab><tab>with open(name, ""w"") as writeFile:<tab><tab><tab><tab>writeFile.write(limit)",if int ( oldLimit ) < limit :,197
3410,"def _wait_for_bot_presense(self, online):<tab>for _ in range(10):<tab><tab>time.sleep(2)<tab><tab>if online and self._is_testbot_online():<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab>else:<tab><tab>raise AssertionError(<tab><tab><tab>""test bot is still {}"".format(""offline"" if online else ""online"")<tab><tab>)",if not online and not self . _is_testbot_online ( ) :,111
3411,"def handle(self, context, sign, *args):<tab>if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP):<tab><tab>return Infsign[sign]<tab>if sign == 0:<tab><tab>if context.rounding == ROUND_CEILING:<tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))<tab>if sign == 1:<tab><tab><IF-STMT><tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",if context . rounding == ROUND_FLOOR :,184
3412,"def _get_item_columns_panel(items, rows):<tab>hbox = Gtk.HBox(False, 4)<tab>n_item = 0<tab>col_items = 0<tab>vbox = Gtk.VBox()<tab>hbox.pack_start(vbox, False, False, 0)<tab>while n_item < len(items):<tab><tab>item = items[n_item]<tab><tab>vbox.pack_start(item, False, False, 0)<tab><tab>n_item += 1<tab><tab>col_items += 1<tab><tab><IF-STMT><tab><tab><tab>vbox = Gtk.VBox()<tab><tab><tab>hbox.pack_start(vbox, False, False, 0)<tab><tab><tab>col_items = 0<tab>return hbox",if col_items > rows :,179
3413,"def _changed(self):<tab>if self.gtk_range.get_sensitive():<tab><tab><IF-STMT><tab><tab><tab>self.timer.cancel()<tab><tab>self.timer = _Timer(0.5, lambda: GLib.idle_add(self._write))<tab><tab>self.timer.start()",if self . timer :,74
3414,"def unlock_graph(result, callback, interval=1, propagate=False, max_retries=None):<tab>if result.ready():<tab><tab>second_level_res = result.get()<tab><tab><IF-STMT><tab><tab><tab>with allow_join_result():<tab><tab><tab><tab>signature(callback).delay(<tab><tab><tab><tab><tab>list(joinall(second_level_res, propagate=propagate))<tab><tab><tab><tab>)<tab>else:<tab><tab>unlock_graph.retry(countdown=interval, max_retries=max_retries)",if second_level_res . ready ( ) :,131
3415,"def update(self, other=None, /, **kwargs):<tab>if self._pending_removals:<tab><tab>self._commit_removals()<tab>d = self.data<tab>if other is not None:<tab><tab><IF-STMT><tab><tab><tab>other = dict(other)<tab><tab>for key, o in other.items():<tab><tab><tab>d[key] = KeyedRef(o, self._remove, key)<tab>for key, o in kwargs.items():<tab><tab>d[key] = KeyedRef(o, self._remove, key)","if not hasattr ( other , ""items"" ) :",135
3416,"def default(self, o):<tab>try:<tab><tab>if type(o) == datetime.datetime:<tab><tab><tab>return str(o)<tab><tab>else:<tab><tab><tab># remove unwanted attributes from the provider object during conversion to json<tab><tab><tab>if hasattr(o, ""profile""):<tab><tab><tab><tab>del o.profile<tab><tab><tab>if hasattr(o, ""credentials""):<tab><tab><tab><tab>del o.credentials<tab><tab><tab>if hasattr(o, ""metadata_path""):<tab><tab><tab><tab>del o.metadata_path<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del o.services_config<tab><tab><tab>return vars(o)<tab>except Exception as e:<tab><tab>return str(o)","if hasattr ( o , ""services_config"" ) :",172
3417,"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True):<tab>try:<tab><tab>return self._read(count, timeout)<tab>except usb.USBError as e:<tab><tab><IF-STMT><tab><tab><tab>log.info(<tab><tab><tab><tab>""read: e.errno=%s e.strerror=%s e.message=%s repr=%s""<tab><tab><tab><tab>% (e.errno, e.strerror, e.message, repr(e))<tab><tab><tab>)<tab><tab>if ignore_timeouts and is_timeout(e):<tab><tab><tab>return []<tab><tab>if ignore_non_errors and is_noerr(e):<tab><tab><tab>return []<tab><tab>raise",if DEBUG_COMM :,174
3418,def heal(self):<tab>if not self.doctors:<tab><tab>return<tab>proc_ids = self._get_process_ids()<tab>for proc_id in proc_ids:<tab><tab># get proc every time for latest state<tab><tab>proc = PipelineProcess.objects.get(id=proc_id)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for dr in self.doctors:<tab><tab><tab>if dr.confirm(proc):<tab><tab><tab><tab>dr.cure(proc)<tab><tab><tab><tab>break,if not proc . is_alive or proc . is_frozen :,138
3419,"def to_value(self, value):<tab># Tip: 'value' is the object returned by<tab>#<tab>  taiga.projects.history.models.HistoryEntry.values_diff()<tab>ret = {}<tab>for key, val in value.items():<tab><tab><IF-STMT><tab><tab><tab>ret[key] = val<tab><tab>elif key == ""points"":<tab><tab><tab>ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()}<tab><tab>else:<tab><tab><tab>ret[key] = {""from"": val[0], ""to"": val[1]}<tab>return ret","if key in [ ""attachments"" , ""custom_attributes"" , ""description_diff"" ] :",169
3420,"def default_generator(<tab>self, dataset, epochs=1, mode=""fit"", deterministic=True, pad_batches=True):<tab>for epoch in range(epochs):<tab><tab>for (X_b, y_b, w_b, ids_b) in dataset.iterbatches(<tab><tab><tab>batch_size=self.batch_size,<tab><tab><tab>deterministic=deterministic,<tab><tab><tab>pad_batches=pad_batches,<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dropout = np.array(0.0)<tab><tab><tab>else:<tab><tab><tab><tab>dropout = np.array(1.0)<tab><tab><tab>yield ([X_b, dropout], [y_b], [w_b])","if mode == ""predict"" :",172
3421,"def _cygwin_hack_find_addresses(target):<tab>addresses = []<tab>for h in [<tab><tab>target,<tab><tab>""localhost"",<tab><tab>""127.0.0.1"",<tab>]:<tab><tab>try:<tab><tab><tab>addr = get_local_ip_for(h)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addresses.append(addr)<tab><tab>except socket.gaierror:<tab><tab><tab>pass<tab>return defer.succeed(addresses)",if addr not in addresses :,116
3422,"def _get_notify(self, action_node):<tab>if action_node.name not in self._skip_notify_tasks:<tab><tab>if action_node.notify:<tab><tab><tab>task_notify = NotificationsHelper.to_model(action_node.notify)<tab><tab><tab>return task_notify<tab><tab><IF-STMT><tab><tab><tab>return self._chain_notify<tab>return None",elif self . _chain_notify :,95
3423,"def filterTokenLocation():<tab>i = None<tab>entry = None<tab>token = None<tab>tokens = []<tab>i = 0<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>entry = extra.tokens[i]<tab><tab>token = jsdict(<tab><tab><tab>{<tab><tab><tab><tab>""type"": entry.type,<tab><tab><tab><tab>""value"": entry.value,<tab><tab><tab>}<tab><tab>)<tab><tab>if extra.range:<tab><tab><tab>token.range = entry.range<tab><tab>if extra.loc:<tab><tab><tab>token.loc = entry.loc<tab><tab>tokens.append(token)<tab><tab>i += 1<tab>extra.tokens = tokens",if not ( i < len ( extra . tokens ) ) :,172
3424,"def read(self, size=-1):<tab>buf = bytearray()<tab>while size != 0 and self.cursor < self.maxpos:<tab><tab>if not self.in_current_block(self.cursor):<tab><tab><tab>self.seek_to_block(self.cursor)<tab><tab>part = self.current_stream.read(size)<tab><tab><IF-STMT><tab><tab><tab>if len(part) == 0:<tab><tab><tab><tab>raise EOFError()<tab><tab><tab>size -= len(part)<tab><tab>self.cursor += len(part)<tab><tab>buf += part<tab>return bytes(buf)",if size > 0 :,142
3425,"def get_properties_from_model(model_class):<tab>""""""Show properties from a model""""""<tab>properties = []<tab>attr_names = [name for (name, value) in inspect.getmembers(model_class, isprop)]<tab>for attr_name in attr_names:<tab><tab><IF-STMT><tab><tab><tab>attr_names.remove(attr_name)<tab><tab>else:<tab><tab><tab>properties.append(<tab><tab><tab><tab>dict(label=attr_name, name=attr_name.strip(""_"").replace(""_"", "" ""))<tab><tab><tab>)<tab>return sorted(properties, key=lambda k: k[""label""])","if attr_name . endswith ( ""pk"" ) :",151
3426,"def __getitem__(self, name, set=set, getattr=getattr, id=id):<tab>visited = set()<tab>mydict = self.basedict<tab>while 1:<tab><tab>value = mydict[name]<tab><tab>if value is not None:<tab><tab><tab>return value<tab><tab>myid = id(mydict)<tab><tab>assert myid not in visited<tab><tab>visited.add(myid)<tab><tab>mydict = mydict.Parent<tab><tab><IF-STMT><tab><tab><tab>return",if mydict is None :,120
3427,"def multicolumn(self, list, format, cols=4):<tab>""""""Format a list of items into a multi-column list.""""""<tab>result = """"<tab>rows = (len(list) + cols - 1) // cols<tab>for col in range(cols):<tab><tab>result = result + '<td width=""%d%%"" valign=top>' % (100 // cols)<tab><tab>for i in range(rows * col, rows * col + rows):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = result + format(list[i]) + ""<br>\n""<tab><tab>result = result + ""</td>""<tab>return '<table width=""100%%"" summary=""list""><tr>%s</tr></table>' % result",if i < len ( list ) :,167
3428,"def format_exc(exc=None):<tab>""""""Return exc (or sys.exc_info if None), formatted.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>exc = _exc_info()<tab><tab>if exc == (None, None, None):<tab><tab><tab>return """"<tab><tab>import traceback<tab><tab>return """".join(traceback.format_exception(*exc))<tab>finally:<tab><tab>del exc",if exc is None :,98
3429,"def assert_counts(res, lang, files, blank, comment, code):<tab>for line in res:<tab><tab>fields = line.split()<tab><tab>if len(fields) >= 5:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(files, int(fields[1]))<tab><tab><tab><tab>self.assertEqual(blank, int(fields[2]))<tab><tab><tab><tab>self.assertEqual(comment, int(fields[3]))<tab><tab><tab><tab>self.assertEqual(code, int(fields[4]))<tab><tab><tab><tab>return<tab>self.fail(""Found no output line for {}"".format(lang))",if fields [ 0 ] == lang :,147
3430,"def __iter__(self):<tab>for name, value in self.__class__.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(value, flag_value):<tab><tab><tab>yield (name, self._has_flag(value.flag))","if isinstance ( value , alias_flag_value ) :",71
3431,"def optimize_models(args, use_cuda, models):<tab>""""""Optimize ensemble for generation""""""<tab>for model in models:<tab><tab>model.make_generation_fast_(<tab><tab><tab>beamable_mm_beam_size=None if args.no_beamable_mm else args.beam,<tab><tab><tab>need_attn=args.print_alignment,<tab><tab>)<tab><tab>if args.fp16:<tab><tab><tab>model.half()<tab><tab><IF-STMT><tab><tab><tab>model.cuda()",if use_cuda :,122
3432,"def convertstore(self, mydict):<tab>targetheader = self.mypofile.header()<tab>targetheader.addnote(""extracted from web2py"", ""developer"")<tab>for source_str in mydict.keys():<tab><tab>target_str = mydict[source_str]<tab><tab>if target_str == source_str:<tab><tab><tab># a convention with new (untranslated) web2py files<tab><tab><tab>target_str = u""""<tab><tab><IF-STMT><tab><tab><tab># an older convention<tab><tab><tab>target_str = u""""<tab><tab>pounit = self.convertunit(source_str, target_str)<tab><tab>self.mypofile.addunit(pounit)<tab>return self.mypofile","elif target_str . startswith ( u""*** "" ) :",180
3433,"def __sparse_values_set(instances, static_col_indexes: list):<tab>tmp_result = {idx: set() for idx in static_col_indexes}<tab>for _, instance in instances:<tab><tab>data_generator = instance.features.get_all_data()<tab><tab>for idx, value in data_generator:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>tmp_result[idx].add(value)<tab>result = [tmp_result[x] for x in static_col_indexes]<tab>return result",if idx not in tmp_result :,132
3434,def puts(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.puts_ is None:<tab><tab><tab><tab>self.puts_ = PutRequest()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.puts_,if self . puts_ is None :,89
3435,"def run(self, args, **kwargs):<tab>if args.resource_ref or args.policy_type:<tab><tab>filters = {}<tab><tab>if args.resource_ref:<tab><tab><tab>filters[""resource_ref""] = args.resource_ref<tab><tab><IF-STMT><tab><tab><tab>filters[""policy_type""] = args.policy_type<tab><tab>filters.update(**kwargs)<tab><tab>return self.manager.query(**filters)<tab>else:<tab><tab>return self.manager.get_all(**kwargs)",if args . policy_type :,123
3436,"def Get_Gene(self, id):<tab>""""""Retreive the gene name (GN).""""""<tab>entry = self.Get(id)<tab>if not entry:<tab><tab>return None<tab>GN = """"<tab>for line in string.split(entry, ""\n""):<tab><tab>if line[0:5] == ""GN   "":<tab><tab><tab>GN = string.strip(line[5:])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>GN = GN[0:-1]<tab><tab><tab>return GN<tab><tab>if line[0:2] == ""//"":<tab><tab><tab>break<tab>return GN","if GN [ - 1 ] == ""."" :",150
3437,"def processMovie(self, atom):<tab>for field in atom:<tab><tab><IF-STMT><tab><tab><tab>self.processTrack(field[""track""])<tab><tab>if ""movie_hdr"" in field:<tab><tab><tab>self.processMovieHeader(field[""movie_hdr""])","if ""track"" in field :",69
3438,"def get_next_video_frame(self, skip_empty_frame=True):<tab>if not self.video_format:<tab><tab>return<tab>while True:<tab><tab># We skip video packets which are not video frames<tab><tab># This happens in mkv files for the first few frames.<tab><tab>video_packet = self._get_video_packet()<tab><tab><IF-STMT><tab><tab><tab>self._decode_video_packet(video_packet)<tab><tab>if video_packet.image is not None or not skip_empty_frame:<tab><tab><tab>break<tab>if _debug:<tab><tab>print(""Returning"", video_packet)<tab>return video_packet.image",if video_packet . image == 0 :,162
3439,"def get_devices(display=None):<tab>base = ""/dev/input""<tab>for filename in os.listdir(base):<tab><tab>if filename.startswith(""event""):<tab><tab><tab>path = os.path.join(base, filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>try:<tab><tab><tab><tab>_devices[path] = EvdevDevice(display, path)<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass<tab>return list(_devices.values())",if path in _devices :,120
3440,"def _ensure_header_written(self, datasize):<tab>if not self._headerwritten:<tab><tab>if not self._nchannels:<tab><tab><tab>raise Error(""# channels not specified"")<tab><tab><IF-STMT><tab><tab><tab>raise Error(""sample width not specified"")<tab><tab>if not self._framerate:<tab><tab><tab>raise Error(""sampling rate not specified"")<tab><tab>self._write_header(datasize)",if not self . _sampwidth :,99
3441,"def process(self, fuzzresult):<tab>base_url = urljoin(fuzzresult.url, "".."")<tab>for line in fuzzresult.history.content.splitlines():<tab><tab>record = line.split(""/"")<tab><tab>if len(record) == 6 and record[1]:<tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab># Directory<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab><tab>self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))","if record [ 0 ] == ""D"" :",153
3442,"def tearDown(self):<tab>""""""Shutdown the UDP server.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.server.stop(2.0)<tab><tab>if self.sock_hdlr:<tab><tab><tab>self.root_logger.removeHandler(self.sock_hdlr)<tab><tab><tab>self.sock_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",if self . server :,97
3443,"def get_backend(find_library=None):<tab>try:<tab><tab>global _lib, _ctx<tab><tab><IF-STMT><tab><tab><tab>_lib = _load_library(find_library)<tab><tab><tab>_setup_prototypes(_lib)<tab><tab><tab>_ctx = _Context()<tab><tab>_logger.warning(<tab><tab><tab>""OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284)""<tab><tab>)<tab><tab>return _OpenUSB()<tab>except usb.libloader.LibraryException:<tab><tab># exception already logged (if any)<tab><tab>_logger.error(""Error loading OpenUSB backend"", exc_info=False)<tab><tab>return None<tab>except Exception:<tab><tab>_logger.error(""Error loading OpenUSB backend"", exc_info=True)<tab><tab>return None",if _lib is None :,199
3444,"def __init__(self, event, event_info, fields=[]):<tab>_wmi_object.__init__(self, event, fields=fields)<tab>_set(self, ""event_type"", None)<tab>_set(self, ""timestamp"", None)<tab>_set(self, ""previous"", None)<tab>if event_info:<tab><tab>event_type = self.event_type_re.match(event_info.Path_.Class).group(1).lower()<tab><tab>_set(self, ""event_type"", event_type)<tab><tab>if hasattr(event_info, ""TIME_CREATED""):<tab><tab><tab>_set(self, ""timestamp"", from_1601(event_info.TIME_CREATED))<tab><tab><IF-STMT><tab><tab><tab>_set(self, ""previous"", event_info.PreviousInstance)","if hasattr ( event_info , ""PreviousInstance"" ) :",199
3445,"def _getListNextPackagesReadyToBuild():<tab>for pkg in Scheduler.listOfPackagesToBuild:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if constants.rpmCheck or Scheduler._checkNextPackageIsReadyToBuild(pkg):<tab><tab><tab>Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg))<tab><tab><tab>Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",if pkg in Scheduler . listOfPackagesCurrentlyBuilding :,113
3446,"def process_all(self, lines, times=1):<tab>gap = False<tab>for _ in range(times):<tab><tab>for line in lines:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.write("""")<tab><tab><tab>self.process(line)<tab><tab><tab>if not is_command(line):<tab><tab><tab><tab>gap = True<tab>return 0",if gap :,86
3447,"def diff(old, new, display=True):<tab>""""""Nice colored diff implementation""""""<tab>if not isinstance(old, list):<tab><tab>old = decolorize(str(old)).splitlines()<tab>if not isinstance(new, list):<tab><tab>new = decolorize(str(new)).splitlines()<tab>line_types = {"" "": ""%Reset"", ""-"": ""%Red"", ""+"": ""%Green"", ""?"": ""%Pink""}<tab>if display:<tab><tab>for line in difflib.Differ().compare(old, new):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>print(colorize(line_types[line[0]], line))<tab>return old != new","if line . startswith ( ""?"" ) :",155
3448,"def get_limit(self, request):<tab>if self.limit_query_param:<tab><tab>try:<tab><tab><tab>limit = int(request.query_params[self.limit_query_param])<tab><tab><tab>if limit < 0:<tab><tab><tab><tab>raise ValueError()<tab><tab><tab># Enforce maximum page size, if defined<tab><tab><tab>if settings.MAX_PAGE_SIZE:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return settings.MAX_PAGE_SIZE<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return min(limit, settings.MAX_PAGE_SIZE)<tab><tab><tab>return limit<tab><tab>except (KeyError, ValueError):<tab><tab><tab>pass<tab>return self.default_limit",if limit == 0 :,169
3449,"def slice_fill(self, slice_):<tab>""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true""<tab>if isinstance(self.indexes, int):<tab><tab>new_slice_ = [0]<tab><tab>offset = 0<tab>else:<tab><tab>new_slice_ = [slice_[0]]<tab><tab>offset = 1<tab>for i in range(1, len(self.nums)):<tab><tab>if self.squeeze_dims[i]:<tab><tab><tab>new_slice_.append(0)<tab><tab><IF-STMT><tab><tab><tab>new_slice_.append(slice_[offset])<tab><tab><tab>offset += 1<tab>new_slice_ += slice_[offset:]<tab>return new_slice_",elif offset < len ( slice_ ) :,171
3450,"def wrapper(*args, **kw):<tab>instance = args[0]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>ret_dict = instance._create_ret_object(<tab><tab><tab><tab>instance.FAILURE, None, True, instance.MUST_JSON<tab><tab><tab>)<tab><tab><tab>instance.logger.error(instance.MUST_JSON)<tab><tab><tab>return jsonify(ret_dict), 400<tab>except BadRequest:<tab><tab>ret_dict = instance._create_ret_object(<tab><tab><tab>instance.FAILURE, None, True, instance.MUST_JSON<tab><tab>)<tab><tab>instance.logger.error(instance.MUST_JSON)<tab><tab>return jsonify(ret_dict), 400<tab>instance.logger.debug(""JSON is valid"")<tab>return f(*args, **kw)",if request . get_json ( ) is None :,191
3451,"def add_css(self, data):<tab>if data:<tab><tab>for medium, paths in data.items():<tab><tab><tab>for path in paths:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._css.setdefault(medium, []).append(path)",if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,80
3452,"def mangle_template(template: str, template_vars: Set[str]) -> str:<tab>if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template:<tab><tab>raise Exception(""Cannot parse a template containing reserved strings"")<tab>for var in template_vars:<tab><tab>original = f""{{{var}}}""<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>f'Template string is missing a reference to ""{var}"" referred to in kwargs'<tab><tab><tab>)<tab><tab>template = template.replace(original, mangled_name(var))<tab>return template",if original not in template :,135
3453,"def filterSimilarKeywords(keyword, kwdsIterator):<tab>""""""Return a sorted list of keywords similar to the one given.""""""<tab>seenDict = {}<tab>kwdSndx = soundex(keyword.encode(""ascii"", ""ignore""))<tab>matches = []<tab>matchesappend = matches.append<tab>checkContained = False<tab>if len(keyword) > 4:<tab><tab>checkContained = True<tab>for movieID, key in kwdsIterator:<tab><tab>if key in seenDict:<tab><tab><tab>continue<tab><tab>seenDict[key] = None<tab><tab>if checkContained and keyword in key:<tab><tab><tab>matchesappend(key)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>matchesappend(key)<tab>return _sortKeywords(keyword, matches)","if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :",193
3454,"def GetInfo(self):<tab>for k, v in sorted(self.memory_parameters.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not v:<tab><tab><tab>continue<tab><tab>print(""%s: \t%#08x (%s)"" % (k, v, v))<tab>print(""Memory ranges:"")<tab>print(""Start\t\tEnd\t\tLength"")<tab>for start, length in self.runs:<tab><tab>print(""0x%X\t\t0x%X\t\t0x%X"" % (start, start + length, length))","if k . startswith ( ""Pad"" ) :",145
3455,"def Children(self):<tab>""""""Returns a list of all of this object's owned (strong) children.""""""<tab>children = []<tab>for property, attributes in self._schema.iteritems():<tab><tab>(is_list, property_type, is_strong) = attributes[0:3]<tab><tab>if is_strong and property in self._properties:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>children.append(self._properties[property])<tab><tab><tab>else:<tab><tab><tab><tab>children.extend(self._properties[property])<tab>return children",if not is_list :,130
3456,"def normalize_res_identifier(self, emu, cw, val):<tab>mask = (16 ** (emu.get_ptr_size() // 2) - 1) << 16<tab>if val & mask:  # not an INTRESOURCE<tab><tab>name = emu.read_mem_string(val, cw)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>name = int(name[1:])<tab><tab><tab>except Exception:<tab><tab><tab><tab>return 0<tab>else:<tab><tab>name = val<tab>return name","if name [ 0 ] == ""#"" :",132
3457,"def _optimize(self, solutions):<tab>best_a = None<tab>best_silhouette = None<tab>best_k = None<tab>for a, silhouette, k in solutions():<tab><tab>if best_silhouette is None:<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>best_silhouette = silhouette<tab><tab>best_a = a<tab><tab>best_k = k<tab>return best_a, best_silhouette, best_k",elif silhouette <= best_silhouette :,109
3458,"def find_commit_type(sha):<tab>try:<tab><tab>o = obj_store[sha]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>raise<tab>else:<tab><tab>if isinstance(o, Commit):<tab><tab><tab>commits.add(sha)<tab><tab>elif isinstance(o, Tag):<tab><tab><tab>tags.add(sha)<tab><tab><tab>commits.add(o.object[1])<tab><tab>else:<tab><tab><tab>raise KeyError(""Not a commit or a tag: %s"" % sha)",if not ignore_unknown :,127
3459,"def on_search_entry_keypress(self, widget, event):<tab>key = Gdk.keyval_name(event.keyval)<tab>if key == ""Escape"":<tab><tab>self.hide_search_box()<tab>elif key == ""Return"":<tab><tab># Combine with Shift?<tab><tab><IF-STMT><tab><tab><tab>self.search_prev = False<tab><tab><tab>self.do_search(None)<tab><tab>else:<tab><tab><tab>self.search_prev = True",if event . state & Gdk . ModifierType . SHIFT_MASK :,121
3460,"def process_webhook_prop(namespace):<tab>if not isinstance(namespace.webhook_properties, list):<tab><tab>return<tab>result = {}<tab>for each in namespace.webhook_properties:<tab><tab><IF-STMT><tab><tab><tab>if ""="" in each:<tab><tab><tab><tab>key, value = each.split(""="", 1)<tab><tab><tab>else:<tab><tab><tab><tab>key, value = each, """"<tab><tab><tab>result[key] = value<tab>namespace.webhook_properties = result",if each :,111
3461,"def run(self):<tab>global WAITING_BEFORE_START<tab>time.sleep(WAITING_BEFORE_START)<tab>while self.keep_alive:<tab><tab>path_id, module, resolve = self.queue_receive.get()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.lock.acquire()<tab><tab>self.modules[path_id] = module<tab><tab>self.lock.release()<tab><tab>if resolve:<tab><tab><tab>resolution = self._resolve_with_other_modules(resolve)<tab><tab><tab>self._relations[path_id] = []<tab><tab><tab>for package in resolution:<tab><tab><tab><tab>self._relations[path_id].append(resolution[package])<tab><tab><tab>self.queue_send.put((path_id, module, False, resolution))",if path_id is None :,190
3462,"def _get_download_link(self, url, download_type=""torrent""):<tab>links = {<tab><tab>""torrent"": """",<tab><tab>""magnet"": """",<tab>}<tab>try:<tab><tab>data = self.session.get(url).text<tab><tab>with bs4_parser(data) as html:<tab><tab><tab>downloads = html.find(""div"", {""class"": ""download""})<tab><tab><tab>if downloads:<tab><tab><tab><tab>for download in downloads.findAll(""a""):<tab><tab><tab><tab><tab>link = download[""href""]<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>links[""magnet""] = link<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>links[""torrent""] = urljoin(self.urls[""base_url""], link)<tab>except Exception:<tab><tab>pass<tab>return links[download_type]","if link . startswith ( ""magnet"" ) :",200
3463,"def _parse_fields(cls, read):<tab>read = unicode_to_str(read)<tab>if type(read) is not str:<tab><tab>_wrong_type_for_arg(read, ""str"", ""read"")<tab>fields = {}<tab>while read and read[0] != "";"":<tab><tab><IF-STMT><tab><tab><tab>DeserializeError(read, ""does not separate fields with commas"")<tab><tab>read = read[1:]<tab><tab>key, _type, value, read = cls._parse_field(read)<tab><tab>fields[key] = (_type, value)<tab>if read:<tab><tab># read[0] == ';'<tab><tab>read = read[1:]<tab>return fields, read","if read and read [ 0 ] != "","" :",173
3464,"def _convertDict(self, d):<tab>r = {}<tab>for k, v in d.items():<tab><tab><IF-STMT><tab><tab><tab>v = str(v, ""utf-8"")<tab><tab>elif isinstance(v, list) or isinstance(v, tuple):<tab><tab><tab>v = self._convertList(v)<tab><tab>elif isinstance(v, dict):<tab><tab><tab>v = self._convertDict(v)<tab><tab>if isinstance(k, bytes):<tab><tab><tab>k = str(k, ""utf-8"")<tab><tab>r[k] = v<tab>return r","if isinstance ( v , bytes ) :",142
3465,"def wrapper(filename):<tab>mtime = getmtime(filename)<tab>with lock:<tab><tab>if filename in cache:<tab><tab><tab>old_mtime, result = cache.pop(filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Move to the end<tab><tab><tab><tab>cache[filename] = old_mtime, result<tab><tab><tab><tab>return result<tab>result = function(filename)<tab>with lock:<tab><tab>cache[filename] = mtime, result  # at the end<tab><tab>if len(cache) > max_size:<tab><tab><tab>cache.popitem(last=False)<tab>return result",if old_mtime == mtime :,144
3466,def isFinished(self):<tab># returns true if episode timesteps has reached episode length and resets the task<tab>if self.count > self.epiLen:<tab><tab>self.res()<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.pertGlasPos(0)<tab><tab>if self.count == self.epiLen / 2 + 1:<tab><tab><tab>self.env.reset()<tab><tab><tab>self.pertGlasPos(1)<tab><tab>self.count += 1<tab><tab>return False,if self . count == 1 :,132
3467,"def _check_vulnerabilities(self, processed_analysis):<tab>matched_vulnerabilities = list()<tab>for vulnerability in self._rule_base_vulnerabilities:<tab><tab><IF-STMT><tab><tab><tab>vulnerability_data = vulnerability.get_dict()<tab><tab><tab>name = vulnerability_data.pop(""short_name"")<tab><tab><tab>matched_vulnerabilities.append((name, vulnerability_data))<tab>return matched_vulnerabilities","if evaluate ( processed_analysis , vulnerability . rule ) :",100
3468,"def _table_reprfunc(self, row, col, val):<tab>if self._table.column_names[col].endswith(""Size""):<tab><tab><IF-STMT><tab><tab><tab>return ""  %s"" % val<tab><tab>elif val < 1024 ** 2:<tab><tab><tab>return ""  %.1f KB"" % (val / 1024.0 ** 1)<tab><tab>elif val < 1024 ** 3:<tab><tab><tab>return ""  %.1f MB"" % (val / 1024.0 ** 2)<tab><tab>else:<tab><tab><tab>return ""  %.1f GB"" % (val / 1024.0 ** 3)<tab>if col in (0, """"):<tab><tab>return str(val)<tab>else:<tab><tab>return ""  %s"" % val","if isinstance ( val , compat . string_types ) :",182
3469,"def serve_until_stopped(self) -> None:<tab>while True:<tab><tab>rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout)<tab><tab>if rd:<tab><tab><tab>self.handle_request()<tab><tab><IF-STMT><tab><tab><tab>break",if self . event is not None and self . event . is_set ( ) :,83
3470,"def resize(self, *e):<tab>bold = (""helvetica"", -self._size.get(), ""bold"")<tab>helv = (""helvetica"", -self._size.get())<tab>xspace = self._size.get()<tab>yspace = self._size.get()<tab>for widget in self._widgets:<tab><tab>widget[""node_font""] = bold<tab><tab>widget[""leaf_font""] = helv<tab><tab>widget[""xspace""] = xspace<tab><tab>widget[""yspace""] = yspace<tab><tab>if self._size.get() < 20:<tab><tab><tab>widget[""line_width""] = 1<tab><tab><IF-STMT><tab><tab><tab>widget[""line_width""] = 2<tab><tab>else:<tab><tab><tab>widget[""line_width""] = 3<tab>self._layout()",elif self . _size . get ( ) < 30 :,185
3471,"def __assertTilesChangedInRegion(self, t1, t2, region):<tab>for tileOriginTuple in t1.keys():<tab><tab>tileOrigin = imath.V2i(*tileOriginTuple)<tab><tab>tileRegion = imath.Box2i(<tab><tab><tab>tileOrigin, tileOrigin + imath.V2i(GafferImage.ImagePlug.tileSize())<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.assertNotEqual(t1[tileOriginTuple], t2[tileOriginTuple])<tab><tab>else:<tab><tab><tab>self.assertEqual(t1[tileOriginTuple], t2[tileOriginTuple])","if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :",165
3472,"def grouped_by_prefix(args, prefixes):<tab>""""""Group behave args by (directory) scope into multiple test-runs.""""""<tab>group_args = []<tab>current_scope = None<tab>for arg in args.strip().split():<tab><tab>assert not arg.startswith(""-""), ""REQUIRE: arg, not options""<tab><tab>scope = select_prefix_for(arg, prefixes)<tab><tab>if scope != current_scope:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># -- DETECTED GROUP-END:<tab><tab><tab><tab>yield "" "".join(group_args)<tab><tab><tab><tab>group_args = []<tab><tab><tab>current_scope = scope<tab><tab>group_args.append(arg)<tab>if group_args:<tab><tab>yield "" "".join(group_args)",if group_args :,183
3473,"def __print__(self, defaults=False):<tab>if defaults:<tab><tab>print_func = str<tab>else:<tab><tab>print_func = repr<tab>pieces = []<tab>default_values = self.__defaults__<tab>for k in self.__fields__:<tab><tab>value = getattr(self, k)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(value, basestring):<tab><tab><tab>print_func = repr  # keep quotes around strings<tab><tab>pieces.append(""%s=%s"" % (k, print_func(value)))<tab>if pieces or self.__base__:<tab><tab>return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces))<tab>else:<tab><tab>return """"",if not defaults and value == default_values [ k ] :,178
3474,"def setInnerHTML(self, html):<tab>log.HTMLClassifier.classify(<tab><tab>log.ThugLogging.url if log.ThugOpts.local else log.last_url, html<tab>)<tab>self.tag.clear()<tab>for node in bs4.BeautifulSoup(html, ""html.parser"").contents:<tab><tab>self.tag.append(node)<tab><tab>name = getattr(node, ""name"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>handler = getattr(log.DFT, ""handle_%s"" % (name,), None)<tab><tab>if handler:<tab><tab><tab>handler(node)",if name is None :,151
3475,"def createFields(self):<tab>yield Enum(Bits(self, ""class"", 2), self.CLASS_DESC)<tab>yield Enum(Bit(self, ""form""), self.FORM_DESC)<tab>if self[""class""].value == 0:<tab><tab>yield Enum(Bits(self, ""type"", 5), self.TYPE_DESC)<tab>else:<tab><tab>yield Bits(self, ""type"", 5)<tab>yield ASNInteger(self, ""size"", ""Size in bytes"")<tab>size = self[""size""].value<tab>if size:<tab><tab><IF-STMT><tab><tab><tab>for field in self._handler(self, size):<tab><tab><tab><tab>yield field<tab><tab>else:<tab><tab><tab>yield RawBytes(self, ""raw"", size)",if self . _handler :,175
3476,"def _process_service_request(self, pkttype, pktid, packet):<tab>""""""Process a service request""""""<tab># pylint: disable=unused-argument<tab>service = packet.get_string()<tab>packet.check_end()<tab>if service == self._next_service:<tab><tab>self.logger.debug2(""Accepting request for service %s"", service)<tab><tab>self._next_service = None<tab><tab>self.send_packet(MSG_SERVICE_ACCEPT, String(service))<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>self._auth_in_progress = True<tab><tab><tab>self._send_deferred_packets()<tab>else:<tab><tab>raise DisconnectError(<tab><tab><tab>DISC_SERVICE_NOT_AVAILABLE, ""Unexpected service request received""<tab><tab>)",if self . is_server ( ) and service == _USERAUTH_SERVICE :,198
3477,"def _read_fixed_body(<tab>self, content_length: int, delegate: httputil.HTTPMessageDelegate) -> None:<tab>while content_length > 0:<tab><tab>body = await self.stream.read_bytes(<tab><tab><tab>min(self.params.chunk_size, content_length), partial=True<tab><tab>)<tab><tab>content_length -= len(body)<tab><tab><IF-STMT><tab><tab><tab>with _ExceptionLoggingContext(app_log):<tab><tab><tab><tab>ret = delegate.data_received(body)<tab><tab><tab><tab>if ret is not None:<tab><tab><tab><tab><tab>await ret",if not self . _write_finished or self . is_client :,158
3478,"def wait_for_child(pid, timeout=1.0):<tab>deadline = mitogen.core.now() + timeout<tab>while timeout < mitogen.core.now():<tab><tab>try:<tab><tab><tab>target_pid, status = os.waitpid(pid, os.WNOHANG)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>if e.args[0] == errno.ECHILD:<tab><tab><tab><tab>return<tab><tab>time.sleep(0.05)<tab>assert False, ""wait_for_child() timed out""",if target_pid == pid :,156
3479,"def execute(cls, ctx, op: ""DataFrameGroupByAgg""):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab>if op.stage == OperandStage.map:<tab><tab><tab>cls._execute_map(ctx, op)<tab><tab><IF-STMT><tab><tab><tab>cls._execute_combine(ctx, op)<tab><tab>elif op.stage == OperandStage.agg:<tab><tab><tab>cls._execute_agg(ctx, op)<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise ValueError(""Aggregation operand not executable"")<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",elif op . stage == OperandStage . combine :,171
3480,def cut(sentence):<tab>sentence = strdecode(sentence)<tab>blocks = re_han.split(sentence)<tab>for blk in blocks:<tab><tab>if re_han.match(blk):<tab><tab><tab>for word in __cut(blk):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield word<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>for c in word:<tab><tab><tab><tab><tab><tab>yield c<tab><tab>else:<tab><tab><tab>tmp = re_skip.split(blk)<tab><tab><tab>for x in tmp:<tab><tab><tab><tab>if x:<tab><tab><tab><tab><tab>yield x,if word not in Force_Split_Words :,156
3481,"def _iter_tags(self, type=None):<tab>""""""Yield all raw tags (limit to |type| if specified)""""""<tab>for n in itertools.count():<tab><tab>tag = self._get_tag(n)<tab><tab><IF-STMT><tab><tab><tab>yield tag<tab><tab>if tag[""d_tag""] == ""DT_NULL"":<tab><tab><tab>break","if type is None or tag [ ""d_tag"" ] == type :",95
3482,"def reverse_search_history(self, searchfor, startpos=None):<tab>if startpos is None:<tab><tab>startpos = self.history_cursor<tab>if _ignore_leading_spaces:<tab><tab>res = [<tab><tab><tab>(idx, line.lstrip())<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab>if line.lstrip().startswith(searchfor.lstrip())<tab><tab>]<tab>else:<tab><tab>res = [<tab><tab><tab>(idx, line)<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab><IF-STMT><tab><tab>]<tab>if res:<tab><tab>self.history_cursor -= res[0][0]<tab><tab>return res[0][1].get_line_text()<tab>return """"",if line . startswith ( searchfor ),198
3483,"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># Oracle doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Oracle backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return unicode(value)",if settings . USE_TZ :,130
3484,"def _sniff(filename, oxlitype):<tab>try:<tab><tab>with open(filename, ""rb"") as fileobj:<tab><tab><tab>header = fileobj.read(4)<tab><tab><tab>if header == b""OXLI"":<tab><tab><tab><tab>fileobj.read(1)  # skip the version number<tab><tab><tab><tab>ftype = fileobj.read(1)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab>return False<tab>except OSError:<tab><tab>return False",if binascii . hexlify ( ftype ) == oxlitype :,126
3485,"def unget(self, char):<tab># Only one character is allowed to be ungotten at once - it must<tab># be consumed again before any further call to unget<tab>if char is not EOF:<tab><tab><IF-STMT><tab><tab><tab># unget is called quite rarely, so it's a good idea to do<tab><tab><tab># more work here if it saves a bit of work in the frequently<tab><tab><tab># called char and charsUntil.<tab><tab><tab># So, just prepend the ungotten character onto the current<tab><tab><tab># chunk:<tab><tab><tab>self.chunk = char + self.chunk<tab><tab><tab>self.chunkSize += 1<tab><tab>else:<tab><tab><tab>self.chunkOffset -= 1<tab><tab><tab>assert self.chunk[self.chunkOffset] == char",if self . chunkOffset == 0 :,188
3486,"def scan(rule, extensions, paths, ignore_paths=None):<tab>""""""The libsast scan.""""""<tab>try:<tab><tab>options = {<tab><tab><tab>""match_rules"": rule,<tab><tab><tab>""match_extensions"": extensions,<tab><tab><tab>""ignore_paths"": ignore_paths,<tab><tab><tab>""show_progress"": False,<tab><tab>}<tab><tab>scanner = Scanner(options, paths)<tab><tab>res = scanner.scan()<tab><tab><IF-STMT><tab><tab><tab>return format_findings(res[""pattern_matcher""], paths[0])<tab>except Exception:<tab><tab>logger.exception(""libsast scan"")<tab>return {}",if res :,150
3487,"def _getPatternTemplate(pattern, key=None):<tab>if key is None:<tab><tab>key = pattern<tab><tab><IF-STMT><tab><tab><tab>key = pattern.upper()<tab>template = DD_patternCache.get(key)<tab>if not template:<tab><tab>if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""):<tab><tab><tab>template = DateEpoch(lineBeginOnly=(key != ""EPOCH""))<tab><tab>elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""):<tab><tab><tab>template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False))<tab><tab>else:<tab><tab><tab>template = DatePatternRegex(pattern)<tab>DD_patternCache.set(key, template)<tab>return template","if ""%"" not in pattern :",195
3488,"def _forward_response(self, src, dst):<tab>""""""Forward an SCP response between two remote SCP servers""""""<tab># pylint: disable=no-self-use<tab>try:<tab><tab>exc = yield from src.await_response()<tab><tab><IF-STMT><tab><tab><tab>dst.send_error(exc)<tab><tab><tab>return exc<tab><tab>else:<tab><tab><tab>dst.send_ok()<tab><tab><tab>return None<tab>except OSError as exc:<tab><tab>return exc",if exc :,114
3489,"def _maybe_signal_recovery_end() -> None:<tab>if self.in_recovery and not self.active_remaining_total():<tab><tab># apply anything stuck in the buffers<tab><tab>self.flush_buffers()<tab><tab>self._set_recovery_ended()<tab><tab><IF-STMT><tab><tab><tab>self._actives_span.set_tag(""Actives-Ready"", True)<tab><tab>self.signal_recovery_end.set()",if self . _actives_span is not None :,115
3490,"def main():<tab>tmpdir = None<tab>try:<tab><tab># Create a temporary working directory<tab><tab>tmpdir = tempfile.mkdtemp()<tab><tab># Unpack the zipfile into the temporary directory<tab><tab>pip_zip = os.path.join(tmpdir, ""pip.zip"")<tab><tab>with open(pip_zip, ""wb"") as fp:<tab><tab><tab>fp.write(b85decode(DATA.replace(b""\n"", b"""")))<tab><tab># Add the zipfile to sys.path so that we can import it<tab><tab>sys.path.insert(0, pip_zip)<tab><tab># Run the bootstrap<tab><tab>bootstrap(tmpdir=tmpdir)<tab>finally:<tab><tab># Clean up our temporary working directory<tab><tab><IF-STMT><tab><tab><tab>shutil.rmtree(tmpdir, ignore_errors=True)",if tmpdir :,185
3491,"def __init__(self, api_version_str):<tab>try:<tab><tab>self.latest = self.preview = False<tab><tab>self.yyyy = self.mm = self.dd = None<tab><tab>if api_version_str == ""latest"":<tab><tab><tab>self.latest = True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.preview = True<tab><tab><tab>parts = api_version_str.split(""-"")<tab><tab><tab>self.yyyy = int(parts[0])<tab><tab><tab>self.mm = int(parts[1])<tab><tab><tab>self.dd = int(parts[2])<tab>except (ValueError, TypeError):<tab><tab>raise ValueError(<tab><tab><tab>""The API version {} is not in a "" ""supported format"".format(api_version_str)<tab><tab>)","if ""preview"" in api_version_str :",199
3492,"def _merge(self, items, map_id, dep_id, use_disk, meminfo, mem_limit):<tab>combined = self.combined<tab>merge_combiner = self.aggregator.mergeCombiners<tab>for k, v in items:<tab><tab>o = combined.get(k)<tab><tab>combined[k] = merge_combiner(o, v) if o is not None else v<tab><tab><IF-STMT><tab><tab><tab>mem_limit = self._rotate()",if use_disk and meminfo . rss > mem_limit :,120
3493,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_value(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 8 :,90
3494,"def nice(deltat):<tab># singular,plural<tab>times = _(<tab><tab>""second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years""<tab>).split("":"")<tab>d = abs(int(deltat))<tab>for div, time in zip((60, 60, 24, 7, 4, 12, 100), times):<tab><tab><IF-STMT><tab><tab><tab>return ""%s%i %s"" % (deltat < 0 and ""-"" or """", d, time.split("","")[d != 1])<tab><tab>d /= div",if d < div * 5 :,143
3495,"def after_get_object(self, event, view_kwargs):<tab>if event and event.state == ""draft"":<tab><tab><IF-STMT><tab><tab><tab>raise ObjectNotFound({""parameter"": ""{id}""}, ""Event: not found"")","if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :",79
3496,def daemonize_if_required(self):<tab>if self.options.daemon:<tab><tab><IF-STMT><tab><tab><tab># Stop the logging queue listener for the current process<tab><tab><tab># We'll restart it once forked<tab><tab><tab>log.shutdown_multiprocessing_logging_listener(daemonizing=True)<tab><tab># Late import so logging works correctly<tab><tab>salt.utils.process.daemonize()<tab># Setup the multiprocessing log queue listener if enabled<tab>self._setup_mp_logging_listener(),if self . _setup_mp_logging_listener_ is True :,128
3497,"def iter_modules(self, by_clients=False, clients_filter=None):<tab>""""""iterate over all modules""""""<tab>clients = None<tab>if by_clients:<tab><tab>clients = self.get_clients(clients_filter)<tab><tab>if not clients:<tab><tab><tab>return<tab>self._refresh_modules()<tab>for module_name in self.modules:<tab><tab>try:<tab><tab><tab>module = self.get_module(module_name)<tab><tab>except PupyModuleDisabled:<tab><tab><tab>continue<tab><tab>if clients is not None:<tab><tab><tab>for client in clients:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield module<tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield module",if module . is_compatible_with ( client ) :,181
3498,"def _incremental_avg_dp(self, avg, new_el, idx):<tab>for attr in [""coarse_segm"", ""fine_segm"", ""u"", ""v""]:<tab><tab>setattr(<tab><tab><tab>avg, attr, (getattr(avg, attr) * idx + getattr(new_el, attr)) / (idx + 1)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab># Deletion of the > 0 index intermediary values to prevent GPU OOM<tab><tab><tab>setattr(new_el, attr, None)<tab>return avg",if idx :,129
3499,"def run(self, paths=[]):<tab>collapsed = False<tab>for item in SideBarSelection(paths).getSelectedDirectories():<tab><tab>for view in item.views():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>Window().focus_view(view)<tab><tab><tab><tab>self.collapse_sidebar_folder()<tab><tab><tab><tab>collapsed = True<tab><tab><tab>view.close()",if not collapsed :,90
3500,"def test_reductions(expr, rdd):<tab>result = compute(expr, rdd)<tab>expected = compute(expr, data)<tab>if not result == expected:<tab><tab>print(result)<tab><tab>print(expected)<tab><tab><IF-STMT><tab><tab><tab>assert abs(result - expected) < 0.001<tab><tab>else:<tab><tab><tab>assert result == expected","if isinstance ( result , float ) :",93
3501,"def deltask(task, d):<tab>if task[:3] != ""do_"":<tab><tab>task = ""do_"" + task<tab>bbtasks = d.getVar(""__BBTASKS"", False) or []<tab>if task in bbtasks:<tab><tab>bbtasks.remove(task)<tab><tab>d.delVarFlag(task, ""task"")<tab><tab>d.setVar(""__BBTASKS"", bbtasks)<tab>d.delVarFlag(task, ""deps"")<tab>for bbtask in d.getVar(""__BBTASKS"", False) or []:<tab><tab>deps = d.getVarFlag(bbtask, ""deps"", False) or []<tab><tab><IF-STMT><tab><tab><tab>deps.remove(task)<tab><tab><tab>d.setVarFlag(bbtask, ""deps"", deps)",if task in deps :,184
3502,"def _apply_weightnorm(self, list_layers):<tab>""""""Try apply weightnorm for all layer in list_layers.""""""<tab>for i in range(len(list_layers)):<tab><tab>try:<tab><tab><tab>layer_name = list_layers[i].name.lower()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>list_layers[i] = WeightNormalization(list_layers[i])<tab><tab>except Exception:<tab><tab><tab>pass","if ""conv1d"" in layer_name or ""dense"" in layer_name :",120
3503,"def __init__(self, execution_context, aggregate_operators):<tab>super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context)<tab>self._local_aggregators = []<tab>self._results = None<tab>self._result_index = 0<tab>for operator in aggregate_operators:<tab><tab>if operator == ""Average"":<tab><tab><tab>self._local_aggregators.append(_AverageAggregator())<tab><tab>elif operator == ""Count"":<tab><tab><tab>self._local_aggregators.append(_CountAggregator())<tab><tab><IF-STMT><tab><tab><tab>self._local_aggregators.append(_MaxAggregator())<tab><tab>elif operator == ""Min"":<tab><tab><tab>self._local_aggregators.append(_MinAggregator())<tab><tab>elif operator == ""Sum"":<tab><tab><tab>self._local_aggregators.append(_SumAggregator())","elif operator == ""Max"" :",192
3504,"def _conv_layer(self, sess, bottom, name, trainable=True, padding=""SAME"", relu=True):<tab>with tf.variable_scope(name) as scope:<tab><tab>filt = self._get_conv_filter(sess, name, trainable=trainable)<tab><tab>conv_biases = self._get_bias(sess, name, trainable=trainable)<tab><tab>conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=padding)<tab><tab>bias = tf.nn.bias_add(conv, conv_biases)<tab><tab><IF-STMT><tab><tab><tab>bias = tf.nn.relu(bias)<tab><tab>return bias",if relu :,159
3505,"def get_partners(self) -> Dict[AbstractNode, Set[int]]:<tab>partners = {}  # type: Dict[AbstractNode, Set[int]]<tab>for edge in self.edges:<tab><tab>if edge.is_dangling():<tab><tab><tab>raise ValueError(""Cannot contract copy tensor with dangling edges"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>partner_node, shared_axis = self._get_partner(edge)<tab><tab>if partner_node not in partners:<tab><tab><tab>partners[partner_node] = set()<tab><tab>partners[partner_node].add(shared_axis)<tab>return partners",if self . _is_my_trace ( edge ) :,163
3506,"def close(self):<tab>with self._lock:<tab><tab>""""""Close this _MultiFileWatcher object forever.""""""<tab><tab><IF-STMT><tab><tab><tab>self._folder_handlers = {}<tab><tab><tab>LOGGER.debug(<tab><tab><tab><tab>""Stopping observer thread even though there is a non-zero ""<tab><tab><tab><tab>""number of event observers!""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>LOGGER.debug(""Stopping observer thread"")<tab><tab>self._observer.stop()<tab><tab>self._observer.join(timeout=5)",if len ( self . _folder_handlers ) != 0 :,135
3507,"def comboSelectionChanged(self, index):<tab>text = self.comboBox.cb.itemText(index)<tab>for i in range(self.labelList.count()):<tab><tab><IF-STMT><tab><tab><tab>self.labelList.item(i).setCheckState(2)<tab><tab>elif text != self.labelList.item(i).text():<tab><tab><tab>self.labelList.item(i).setCheckState(0)<tab><tab>else:<tab><tab><tab>self.labelList.item(i).setCheckState(2)","if text == """" :",120
3508,"def _get_messages(self):<tab>r = []<tab>try:<tab><tab>self._connect()<tab><tab>self._login()<tab><tab>for message in self._fetch():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r.append(message)<tab><tab>self._connection.expunge()<tab><tab>self._connection.close()<tab><tab>self._connection.logout()<tab>except MailFetcherError as e:<tab><tab>self.log(""error"", str(e))<tab>return r",if message :,114
3509,"def get_current_user(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return config.get(""json_authentication_override"")<tab><tab>tkn_header = self.request.headers[""authorization""]<tab>except KeyError:<tab><tab>raise WebAuthNError(reason=""Missing Authorization Header"")<tab>else:<tab><tab>tkn_str = tkn_header.split("" "")[-1]<tab>try:<tab><tab>tkn = self.jwt_validator(tkn_str)<tab>except AuthenticationError as e:<tab><tab>raise WebAuthNError(reason=e.message)<tab>else:<tab><tab>return tkn","if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :",157
3510,def _get_data(self):<tab>formdata = self._formdata<tab>if formdata:<tab><tab>data = []<tab><tab># TODO: Optimize?<tab><tab>for item in formdata:<tab><tab><tab>model = self.loader.get_one(item) if item else None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data.append(model)<tab><tab><tab>else:<tab><tab><tab><tab>self._invalid_formdata = True<tab><tab>self._set_data(data)<tab>return self._data,if model :,118
3511,"def _getSubstrings(self, va, size, ltyp):<tab># rip through the desired memory range to populate any substrings<tab>subs = set()<tab>end = va + size<tab>for offs in range(va, end, 1):<tab><tab>loc = self.getLocation(offs, range=True)<tab><tab>if loc and loc[L_LTYPE] == LOC_STRING and loc[L_VA] > va:<tab><tab><tab>subs.add((loc[L_VA], loc[L_SIZE]))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subs = subs.union(set(loc[L_TINFO]))<tab>return list(subs)",if loc [ L_TINFO ] :,161
3512,def monad(self):<tab>if not self.cls_bl_idname:<tab><tab>return None<tab>for monad in bpy.data.node_groups:<tab><tab><IF-STMT><tab><tab><tab>if monad.cls_bl_idname == self.cls_bl_idname:<tab><tab><tab><tab>return monad<tab>return None,"if hasattr ( monad , ""cls_bl_idname"" ) :",93
3513,"def _set_peer_statuses(self):<tab>""""""Set peer statuses.""""""<tab>cutoff = time.time() - STALE_SECS<tab>for peer in self.peers:<tab><tab>if peer.bad:<tab><tab><tab>peer.status = PEER_BAD<tab><tab><IF-STMT><tab><tab><tab>peer.status = PEER_GOOD<tab><tab>elif peer.last_good:<tab><tab><tab>peer.status = PEER_STALE<tab><tab>else:<tab><tab><tab>peer.status = PEER_NEVER",elif peer . last_good > cutoff :,128
3514,"def title_by_index(self, trans, index, context):<tab>d_type = self.get_datatype(trans, context)<tab>for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()):<tab><tab>if i == index:<tab><tab><tab>rval = composite_name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rval = ""{} ({})"".format(rval, composite_file.description)<tab><tab><tab>if composite_file.optional:<tab><tab><tab><tab>rval = ""%s [optional]"" % rval<tab><tab><tab>return rval<tab>if index < self.get_file_count(trans, context):<tab><tab>return ""Extra primary file""<tab>return None",if composite_file . description :,167
3515,"def testUiViewServerDump_windowIntM1(self):<tab>device = None<tab>try:<tab><tab>device = MockDevice(version=15, startviewserver=True)<tab><tab>vc = ViewClient(device, device.serialno, adb=TRUE, autodump=False)<tab><tab>vc.dump(window=-1)<tab><tab>vc.findViewByIdOrRaise(""id/home"")<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>device.shutdownMockViewServer()",if device :,116
3516,"def _convertDict(self, d):<tab>r = {}<tab>for k, v in d.items():<tab><tab>if isinstance(v, bytes):<tab><tab><tab>v = str(v, ""utf-8"")<tab><tab>elif isinstance(v, list) or isinstance(v, tuple):<tab><tab><tab>v = self._convertList(v)<tab><tab><IF-STMT><tab><tab><tab>v = self._convertDict(v)<tab><tab>if isinstance(k, bytes):<tab><tab><tab>k = str(k, ""utf-8"")<tab><tab>r[k] = v<tab>return r","elif isinstance ( v , dict ) :",142
3517,"def _testSendmsgTimeout(self):<tab>try:<tab><tab>self.cli_sock.settimeout(0.03)<tab><tab>try:<tab><tab><tab>while True:<tab><tab><tab><tab>self.sendmsgToServer([b""a"" * 512])<tab><tab>except socket.timeout:<tab><tab><tab>pass<tab><tab>except OSError as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab># bpo-33937 the test randomly fails on Travis CI with<tab><tab><tab># ""OSError: [Errno 12] Cannot allocate memory""<tab><tab>else:<tab><tab><tab>self.fail(""socket.timeout not raised"")<tab>finally:<tab><tab>self.misc_event.set()",if exc . errno != errno . ENOMEM :,170
3518,"def addError(self, test, err):<tab>if err[0] is SkipTest:<tab><tab>if self.showAll:<tab><tab><tab>self.stream.writeln(str(err[1]))<tab><tab><IF-STMT><tab><tab><tab>self.stream.write(""s"")<tab><tab><tab>self.stream.flush()<tab><tab>return<tab>_org_AddError(self, test, err)",elif self . dots :,93
3519,"def mouse_down(self, event):<tab>if event.button == 1:<tab><tab>if self.scrolling:<tab><tab><tab>p = event.local<tab><tab><tab>if self.scroll_up_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_up()<tab><tab><tab><tab>return<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.scroll_down()<tab><tab><tab><tab>return<tab>if event.button == 4:<tab><tab>self.scroll_up()<tab>if event.button == 5:<tab><tab>self.scroll_down()<tab>GridView.mouse_down(self, event)",elif self . scroll_down_rect ( ) . collidepoint ( p ) :,160
3520,"def find_file_copyright_notices(fname):<tab>ret = set()<tab>f = open(fname)<tab>lines = f.readlines()<tab>for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines<tab><tab>idx = l.lower().find(""copyright"")<tab><tab>if idx < 0:<tab><tab><tab>continue<tab><tab>copyright = l[idx + 9 :].strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>copyright = sanitise(copyright)<tab><tab># hmm, do a quick check to see if there's a year,<tab><tab># if not, skip it<tab><tab>if not copyright.find(""200"") >= 0 and not copyright.find(""199"") >= 0:<tab><tab><tab>continue<tab><tab>ret.add(copyright)<tab>return ret",if not copyright :,186
3521,"def get_selectable_values(self, request):<tab>shop = lfs.core.utils.get_default_shop(request)<tab>countries = []<tab>for country in shop.shipping_countries.all():<tab><tab><IF-STMT><tab><tab><tab>selected = True<tab><tab>else:<tab><tab><tab>selected = False<tab><tab>countries.append(<tab><tab><tab>{<tab><tab><tab><tab>""id"": country.id,<tab><tab><tab><tab>""name"": country.name,<tab><tab><tab><tab>""selected"": selected,<tab><tab><tab>}<tab><tab>)<tab>return countries",if country in self . value . all ( ) :,139
3522,"def _addItemToLayout(self, sample, label):<tab>col = self.layout.columnCount()<tab>row = self.layout.rowCount()<tab>if row:<tab><tab>row -= 1<tab>nCol = self.columnCount * 2<tab># FIRST ROW FULL<tab>if col == nCol:<tab><tab>for col in range(0, nCol, 2):<tab><tab><tab># FIND RIGHT COLUMN<tab><tab><tab>if not self.layout.itemAt(row, col):<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># MAKE NEW ROW<tab><tab><tab>col = 0<tab><tab><tab>row += 1<tab>self.layout.addItem(sample, row, col)<tab>self.layout.addItem(label, row, col + 1)",if col + 2 == nCol :,185
3523,def contains_only_whitespace(node):<tab>if is_tag(node):<tab><tab>if not any([not is_text(s) for s in node.contents]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,72
3524,"def tokenize_generator(cw):<tab>ret = []<tab>done = {}<tab>for op in ops:<tab><tab>ch = op.symbol[0]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>sops = start_symbols[ch]<tab><tab>cw.write(""case '%s':"" % ch)<tab><tab>for t in gen_tests(sops, 1):<tab><tab><tab>cw.write(t)<tab><tab>done[ch] = True<tab>return ret",if ch in done :,113
3525,"def _convertNbCharsInNbBits(self, nbChars):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbChars is not None:<tab><tab><IF-STMT><tab><tab><tab>nbMinBit = nbChars * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab>if nbChars[0] is not None:<tab><tab><tab><tab>nbMinBit = nbChars[0] * 8<tab><tab><tab>if nbChars[1] is not None:<tab><tab><tab><tab>nbMaxBit = nbChars[1] * 8<tab>return (nbMinBit, nbMaxBit)","if isinstance ( nbChars , int ) :",158
3526,"def init(self, *args, **kwargs):<tab>if ""_state"" not in kwargs:<tab><tab>state = {}<tab><tab># Older versions have the _state entries as individual kwargs<tab><tab>for arg in (""children"", ""windowState"", ""detachedPanels""):<tab><tab><tab>if arg in kwargs:<tab><tab><tab><tab>state[arg] = kwargs[arg]<tab><tab><tab><tab>del kwargs[arg]<tab><tab><IF-STMT><tab><tab><tab>kwargs[""_state""] = state<tab>originalInit(self, *args, **kwargs)",if state :,125
3527,"def spm_decode(tokens: List[str]) -> List[str]:<tab>words = []<tab>pieces: List[str] = []<tab>for t in tokens:<tab><tab><IF-STMT><tab><tab><tab>if len(pieces) > 0:<tab><tab><tab><tab>words.append("""".join(pieces))<tab><tab><tab>pieces = [t[1:]]<tab><tab>else:<tab><tab><tab>pieces.append(t)<tab>if len(pieces) > 0:<tab><tab>words.append("""".join(pieces))<tab>return words",if t [ 0 ] == DecodeMixin . spm_bos_token :,133
3528,"def _compare_dirs(self, dir1: str, dir2: str) -> List[str]:<tab># check that dir1 and dir2 are equivalent,<tab># return the diff<tab>diff = []  # type: List[str]<tab>for root, dirs, files in os.walk(dir1):<tab><tab>for file_ in files:<tab><tab><tab>path = os.path.join(root, file_)<tab><tab><tab>target_path = os.path.join(dir2, os.path.split(path)[-1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diff.append(file_)<tab>return diff",if not os . path . exists ( target_path ) :,155
3529,"def credentials(self):<tab>""""""The session credentials as a dict""""""<tab>creds = {}<tab>if self._creds:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>creds[""aws_access_key_id""] = self._creds.access_key<tab><tab>if self._creds.secret_key:  # pragma: no branch<tab><tab><tab>creds[""aws_secret_access_key""] = self._creds.secret_key<tab><tab>if self._creds.token:<tab><tab><tab>creds[""aws_session_token""] = self._creds.token<tab>if self._session.region_name:<tab><tab>creds[""aws_region""] = self._session.region_name<tab>if self.requester_pays:<tab><tab>creds[""aws_request_payer""] = ""requester""<tab>return creds",if self . _creds . access_key :,194
3530,"def got_arbiter_module_type_defined(self, mod_type):<tab>for a in self.arbiters:<tab><tab># Do like the linkify will do after....<tab><tab>for m in getattr(a, ""modules"", []):<tab><tab><tab># So look at what the arbiter try to call as module<tab><tab><tab>m = m.strip()<tab><tab><tab># Ok, now look in modules...<tab><tab><tab>for mod in self.modules:<tab><tab><tab><tab># try to see if this module is the good type<tab><tab><tab><tab>if getattr(mod, ""module_type"", """").strip() == mod_type.strip():<tab><tab><tab><tab><tab># if so, the good name?<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False","if getattr ( mod , ""module_name"" , """" ) . strip ( ) == m :",199
3531,"def find_file_at_path_with_indexes(self, path, url):<tab>if url.endswith(""/""):<tab><tab>path = os.path.join(path, self.index_file)<tab><tab>return self.get_static_file(path, url)<tab>elif url.endswith(""/"" + self.index_file):<tab><tab>if os.path.isfile(path):<tab><tab><tab>return self.redirect(url, url[: -len(self.index_file)])<tab>else:<tab><tab>try:<tab><tab><tab>return self.get_static_file(path, url)<tab><tab>except IsDirectoryError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.redirect(url, url + ""/"")<tab>raise MissingFileError(path)","if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",193
3532,def _use_full_params(self) -> None:<tab>for p in self.params:<tab><tab>if not p._is_sharded:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert p._fp16_shard.storage().size() != 0<tab><tab><tab><tab>p.data = p._fp16_shard<tab><tab>else:<tab><tab><tab>assert p._full_param_padded.storage().size() != 0<tab><tab><tab>p.data = p._full_param_padded[: p._orig_size.numel()].view(p._orig_size),if self . mixed_precision :,136
3533,"def _attrdata(self, cont, name, *val):<tab>if not name:<tab><tab>return None, False<tab>if isinstance(name, Mapping):<tab><tab>if val:<tab><tab><tab>raise TypeError(""Cannot set a value to %s"" % name)<tab><tab>return name, True<tab>else:<tab><tab>if val:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return {name: val[0]}, True<tab><tab><tab>else:<tab><tab><tab><tab>raise TypeError(""Too may arguments"")<tab><tab>else:<tab><tab><tab>cont = self._extra.get(cont)<tab><tab><tab>return cont.get(name) if cont else None, False",if len ( val ) == 1 :,158
3534,"def evaluate(env, net, device=""cpu""):<tab>obs = env.reset()<tab>reward = 0.0<tab>steps = 0<tab>while True:<tab><tab>obs_v = ptan.agent.default_states_preprocessor([obs]).to(device)<tab><tab>action_v = net(obs_v)<tab><tab>action = action_v.data.cpu().numpy()[0]<tab><tab>obs, r, done, _ = env.step(action)<tab><tab>reward += r<tab><tab>steps += 1<tab><tab><IF-STMT><tab><tab><tab>break<tab>return reward, steps",if done :,137
3535,"def convert_html_js_files(app: Sphinx, config: Config) -> None:<tab>""""""This converts string styled html_js_files to tuple styled one.""""""<tab>html_js_files = []  # type: List[Tuple[str, Dict]]<tab>for entry in config.html_js_files:<tab><tab><IF-STMT><tab><tab><tab>html_js_files.append((entry, {}))<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>filename, attrs = entry<tab><tab><tab><tab>html_js_files.append((filename, attrs))<tab><tab><tab>except Exception:<tab><tab><tab><tab>logger.warning(__(""invalid js_file: %r, ignored""), entry)<tab><tab><tab><tab>continue<tab>config.html_js_files = html_js_files  # type: ignore","if isinstance ( entry , str ) :",193
3536,"def _check_duplications(self, regs):<tab>""""""n^2 loop which verifies that each reg exists only once.""""""<tab>for reg in regs:<tab><tab>count = 0<tab><tab>for r in regs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count += 1<tab><tab>if count > 1:<tab><tab><tab>genutil.die(""reg %s defined more than once"" % reg)",if reg == r :,94
3537,"def PyJsHoisted_vault_(key, forget, this, arguments, var=var):<tab>var = Scope(<tab><tab>{u""this"": this, u""forget"": forget, u""key"": key, u""arguments"": arguments}, var<tab>)<tab>var.registers([u""forget"", u""key""])<tab>if PyJsStrictEq(var.get(u""key""), var.get(u""passkey"")):<tab><tab>return (<tab><tab><tab>var.put(u""secret"", var.get(u""null""))<tab><tab><tab><IF-STMT><tab><tab><tab>else (<tab><tab><tab><tab>var.get(u""secret"")<tab><tab><tab><tab>or var.put(u""secret"", var.get(u""secretCreatorFn"")(var.get(u""object"")))<tab><tab><tab>)<tab><tab>)","if var . get ( u""forget"" )",198
3538,"def sort_nested_dictionary_lists(d):<tab>for k, v in d.items():<tab><tab>if isinstance(v, list):<tab><tab><tab>for i in range(0, len(v)):<tab><tab><tab><tab>if isinstance(v[i], dict):<tab><tab><tab><tab><tab>v[i] = await sort_nested_dictionary_lists(v[i])<tab><tab><tab><tab>d[k] = sorted(v)<tab><tab><IF-STMT><tab><tab><tab>d[k] = await sort_nested_dictionary_lists(v)<tab>return d","if isinstance ( v , dict ) :",134
3539,"def transceiver(self, data):<tab>out = []<tab>for t in range(8):<tab><tab>if data[t] == 0:<tab><tab><tab>continue<tab><tab>value = data[t]<tab><tab>for b in range(8):<tab><tab><tab>if value & 0x80:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>out.append(""(unknown)"")<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>out.append(TRANSCEIVER[t][b])<tab><tab><tab>value <<= 1<tab>self.annotate(""Transceiver compliance"", "", "".join(out))",if len ( TRANSCEIVER [ t ] ) < b + 1 :,155
3540,"def process_string(self, remove_repetitions, sequence):<tab>string = """"<tab>for i, char in enumerate(sequence):<tab><tab>if char != self.int_to_char[self.blank_index]:<tab><tab><tab># if this char is a repetition and remove_repetitions=true,<tab><tab><tab># skip.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>elif char == self.labels[self.space_index]:<tab><tab><tab><tab>string += "" ""<tab><tab><tab>else:<tab><tab><tab><tab>string = string + char<tab>return string",if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,152
3541,"def clean(self):<tab>username = self.cleaned_data.get(""username"")<tab>password = self.cleaned_data.get(""password"")<tab>if username and password:<tab><tab>self.user_cache = authenticate(username=username, password=password)<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(self.error_messages[""invalid_login""])<tab><tab>elif not self.user_cache.is_active:<tab><tab><tab>raise forms.ValidationError(self.error_messages[""inactive""])<tab>self.check_for_test_cookie()<tab>return self.cleaned_data",if self . user_cache is None :,143
3542,"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool:<tab>""""""Check if the conversation is in need for a user message.""""""<tab>tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED)<tab>for i, e in enumerate(reversed(tracker.get(""events"", []))):<tab><tab>if e.get(""event"") == UserUttered.type_name:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return e.get(""name"") == ACTION_LISTEN_NAME<tab>return False","elif e . get ( ""event"" ) == ActionExecuted . type_name :",154
3543,"def getReferences(view, name=""""):<tab>""""""Find all reference definitions.""""""<tab># returns {name -> Region}<tab>refs = []<tab>name = re.escape(name)<tab>if name == """":<tab><tab>refs.extend(view.find_all(r""(?<=^\[)([^\]]+)(?=\]:)"", 0))<tab>else:<tab><tab>refs.extend(view.find_all(r""(?<=^\[)(%s)(?=\]:)"" % name, 0))<tab>regions = refs<tab>ids = {}<tab>for reg in regions:<tab><tab>name = view.substr(reg).strip()<tab><tab>key = name.lower()<tab><tab><IF-STMT><tab><tab><tab>ids[key].regions.append(reg)<tab><tab>else:<tab><tab><tab>ids[key] = Obj(regions=[reg], label=name)<tab>return ids",if key in ids :,199
3544,"def _get_header(self, requester, header_name):<tab>hits = sum([header_name in headers for _, headers in requester.requests])<tab>self.assertEquals(hits, 2 if self.revs_enabled else 1)<tab>for url, headers in requester.requests:<tab><tab><IF-STMT><tab><tab><tab>if self.revs_enabled:<tab><tab><tab><tab>self.assertTrue(url.endswith(""/latest""), msg=url)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertTrue(url.endswith(""/download_urls""), msg=url)<tab><tab><tab>return headers.get(header_name)",if header_name in headers :,143
3545,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_shuffle_name(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,92
3546,"def make_release_tree(self, base_dir, files):<tab>""""""Make the release tree.""""""<tab>self.mkpath(base_dir)<tab>create_tree(base_dir, files, dry_run=self.dry_run)<tab>if not files:<tab><tab>self.log.warning(""no files to distribute -- empty manifest?"")<tab>else:<tab><tab>self.log.info(""copying files to %s..."", base_dir)<tab>for filename in files:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(""'%s' not a regular file -- skipping"", filename)<tab><tab>else:<tab><tab><tab>dest = os.path.join(base_dir, filename)<tab><tab><tab>self.copy_file(filename, dest)<tab>self.distribution.metadata.write_pkg_info(base_dir)",if not os . path . isfile ( filename ) :,199
3547,"def _parse_names_set(feature_names):<tab>""""""Helping function of `_parse_feature_names` that parses a set of feature names.""""""<tab>feature_collection = OrderedDict()<tab>for feature_name in feature_names:<tab><tab><IF-STMT><tab><tab><tab>feature_collection[feature_name] = ...<tab><tab>else:<tab><tab><tab>raise ValueError(""Failed to parse {}, expected string"".format(feature_name))<tab>return feature_collection","if isinstance ( feature_name , str ) :",111
3548,"def get_connection(self, url, proxies=None):<tab>with self.pools.lock:<tab><tab>pool = self.pools.get(url)<tab><tab><IF-STMT><tab><tab><tab>return pool<tab><tab>pool = NpipeHTTPConnectionPool(<tab><tab><tab>self.npipe_path, self.timeout, maxsize=self.max_pool_size<tab><tab>)<tab><tab>self.pools[url] = pool<tab>return pool",if pool :,102
3549,"def _parse_dimensions(dimensions):<tab>arrays = []<tab>names = []<tab>for key in dimensions:<tab><tab>values = [v[""name""] for v in key[""values""]]<tab><tab>role = key.get(""role"", None)<tab><tab><IF-STMT><tab><tab><tab>values = [_fix_quarter_values(v) for v in values]<tab><tab><tab>values = pd.DatetimeIndex(values)<tab><tab>arrays.append(values)<tab><tab>names.append(key[""name""])<tab>midx = pd.MultiIndex.from_product(arrays, names=names)<tab>if len(arrays) == 1 and isinstance(midx, pd.MultiIndex):<tab><tab># Fix for pandas >= 0.21<tab><tab>midx = midx.levels[0]<tab>return midx","if role in ( ""time"" , ""TIME_PERIOD"" ) :",190
3550,"def _add_trials(self, name, spec):<tab>""""""Add trial by invoking TrialRunner.""""""<tab>resource = {}<tab>resource[""trials""] = []<tab>trial_generator = BasicVariantGenerator()<tab>trial_generator.add_configurations({name: spec})<tab>while not trial_generator.is_finished():<tab><tab>trial = trial_generator.next_trial()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>runner.add_trial(trial)<tab><tab>resource[""trials""].append(self._trial_info(trial))<tab>return resource",if not trial :,130
3551,"def _retrieve_key(self):<tab>url = ""http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf""<tab>text = """"<tab>try:<tab><tab>r = requests.get(url, timeout=self.timeout, proxies=self.proxies)<tab><tab>text = r.text<tab>except:<tab><tab>self.error = ""ERROR - URL Connection""<tab>if text:<tab><tab>expression = r""'(....-....-....-....)';""<tab><tab>pattern = re.compile(expression)<tab><tab>match = pattern.search(text)<tab><tab><IF-STMT><tab><tab><tab>self.key = match.group(1)<tab><tab><tab>return self.key<tab><tab>else:<tab><tab><tab>self.error = ""ERROR - No API Key""",if match :,190
3552,"def test_net(net, env, count=10, device=""cpu""):<tab>rewards = 0.0<tab>steps = 0<tab>for _ in range(count):<tab><tab>obs = env.reset()<tab><tab>while True:<tab><tab><tab>obs_v = ptan.agent.float32_preprocessor([obs]).to(device)<tab><tab><tab>mu_v = net(obs_v)[0]<tab><tab><tab>action = mu_v.squeeze(dim=0).data.cpu().numpy()<tab><tab><tab>action = np.clip(action, -1, 1)<tab><tab><tab>obs, reward, done, _ = env.step(action)<tab><tab><tab>rewards += reward<tab><tab><tab>steps += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return rewards / count, steps / count",if done :,190
3553,"def compile(self, filename, obfuscate=False, raw=False, magic=""\x00"" * 8):<tab>body = marshal.dumps(compile(self.visit(self._source_ast), filename, ""exec""))<tab>if obfuscate:<tab><tab>body_len = len(body)<tab><tab>offset = 0 if raw else 8<tab><tab>output = bytearray(body_len + 8)<tab><tab>for i, x in enumerate(body):<tab><tab><tab>output[i + offset] = ord(x) ^ ((2 ** ((65535 - i) % 65535)) % 251)<tab><tab><IF-STMT><tab><tab><tab>for i in xrange(8):<tab><tab><tab><tab>output[i] = 0<tab><tab>return output<tab>elif raw:<tab><tab>return body<tab>else:<tab><tab>return magic + body",if raw :,188
3554,"def _map_saslprep(s):<tab>""""""Map stringprep table B.1 to nothing and C.1.2 to ASCII space""""""<tab>r = []<tab>for c in s:<tab><tab>if stringprep.in_table_c12(c):<tab><tab><tab>r.append("" "")<tab><tab><IF-STMT><tab><tab><tab>r.append(c)<tab>return """".join(r)",elif not stringprep . in_table_b1 ( c ) :,106
3555,"def ensemble(self, pairs, other_preds):<tab>""""""Ensemble the dict with statistical model predictions.""""""<tab>lemmas = []<tab>assert len(pairs) == len(other_preds)<tab>for p, pred in zip(pairs, other_preds):<tab><tab>w, pos = p<tab><tab>if (w, pos) in self.composite_dict:<tab><tab><tab>lemma = self.composite_dict[(w, pos)]<tab><tab><IF-STMT><tab><tab><tab>lemma = self.word_dict[w]<tab><tab>else:<tab><tab><tab>lemma = pred<tab><tab>if lemma is None:<tab><tab><tab>lemma = w<tab><tab>lemmas.append(lemma)<tab>return lemmas",elif w in self . word_dict :,164
3556,"def quiet_f(*args):<tab>vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)}<tab>value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation)<tab>if expect_list:<tab><tab><IF-STMT><tab><tab><tab>value = [extract_pyreal(item) for item in value.leaves]<tab><tab><tab>if any(item is None for item in value):<tab><tab><tab><tab>return None<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>value = extract_pyreal(value)<tab><tab>if value is None or isinf(value) or isnan(value):<tab><tab><tab>return None<tab><tab>return value","if value . has_form ( ""List"" , None ) :",177
3557,"def _copy_package_apps(<tab>local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None:<tab>for src_unresolved in app_paths:<tab><tab>src = src_unresolved.resolve()<tab><tab>app = src.name<tab><tab>dest = Path(local_bin_dir / add_suffix(app, suffix))<tab><tab>if not dest.parent.is_dir():<tab><tab><tab>mkdir(dest.parent)<tab><tab><IF-STMT><tab><tab><tab>logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"")<tab><tab><tab>dest.unlink()<tab><tab>if src.exists():<tab><tab><tab>shutil.copy(src, dest)",if dest . exists ( ) :,177
3558,"def assert_readback(vehicle, values):<tab>i = 10<tab>while i > 0:<tab><tab>time.sleep(0.1)<tab><tab>i -= 0.1<tab><tab>for k, v in values.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>break<tab>if i <= 0:<tab><tab>raise Exception(""Did not match in channels readback %s"" % values)",if vehicle . channels [ k ] != v :,105
3559,"def _get_linode_client(self):<tab>api_key = self.credentials.conf(""key"")<tab>api_version = self.credentials.conf(""version"")<tab>if api_version == """":<tab><tab>api_version = None<tab>if not api_version:<tab><tab>api_version = 3<tab><tab># Match for v4 api key<tab><tab>regex_v4 = re.compile(""^[0-9a-f]{64}$"")<tab><tab>regex_match = regex_v4.match(api_key)<tab><tab><IF-STMT><tab><tab><tab>api_version = 4<tab>else:<tab><tab>api_version = int(api_version)<tab>return _LinodeLexiconClient(api_key, api_version)",if regex_match :,175
3560,"def mergeHiLo(self, x_stats):<tab>""""""Merge the highs and lows of another accumulator into myself.""""""<tab>if x_stats.firsttime is not None:<tab><tab><IF-STMT><tab><tab><tab>self.firsttime = x_stats.firsttime<tab><tab><tab>self.first = x_stats.first<tab>if x_stats.lasttime is not None:<tab><tab>if self.lasttime is None or x_stats.lasttime >= self.lasttime:<tab><tab><tab>self.lasttime = x_stats.lasttime<tab><tab><tab>self.last = x_stats.last",if self . firsttime is None or x_stats . firsttime < self . firsttime :,157
3561,"def _check_good_input(self, X, y=None):<tab>if isinstance(X, dict):<tab><tab>lengths = [len(X1) for X1 in X.values()]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Not all values of X are of equal length."")<tab><tab>x_len = lengths[0]<tab>else:<tab><tab>x_len = len(X)<tab>if y is not None:<tab><tab>if len(y) != x_len:<tab><tab><tab>raise ValueError(""X and y are not of equal length."")<tab>if self.regression and y is not None and y.ndim == 1:<tab><tab>y = y.reshape(-1, 1)<tab>return X, y",if len ( set ( lengths ) ) > 1 :,175
3562,"def set(self, obj, **kwargs):<tab>""""""Check for missing event functions and substitute these with""""""<tab>""""""the ignore method""""""<tab>ignore = getattr(self, ""ignore"")<tab>for k, v in kwargs.iteritems():<tab><tab>setattr(self, k, getattr(obj, v))<tab><tab>if k in self.combinations:<tab><tab><tab>for k1 in self.combinations[k]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>setattr(self, k1, ignore)","if not hasattr ( self , k1 ) :",121
3563,"def _parse_list(self, tokens):<tab># Process left to right, allow descending in sub lists<tab>assert tokens[0] in (""["", ""("")<tab>delim = ""]"" if tokens.pop(0) == ""["" else "")""<tab>expr = ExpressionList()<tab>while tokens and tokens[0] != delim:<tab><tab>item = self._parse(tokens)<tab><tab><IF-STMT><tab><tab><tab>if tokens.pop(0) != "","":<tab><tab><tab><tab>raise ExpressionSyntaxError('Expected: "",""')<tab><tab>expr.append(item)<tab>if not tokens or tokens[0] != delim:<tab><tab>raise ExpressionSyntaxError('Missing: ""%s""' % delim)<tab>else:<tab><tab>tokens.pop(0)<tab>return expr",if tokens and tokens [ 0 ] != delim :,174
3564,"def param_value(self):<tab># This is part of the ""handle quoted extended parameters"" hack.<tab>for token in self:<tab><tab>if token.token_type == ""value"":<tab><tab><tab>return token.stripped_value<tab><tab><IF-STMT><tab><tab><tab>for token in token:<tab><tab><tab><tab>if token.token_type == ""bare-quoted-string"":<tab><tab><tab><tab><tab>for token in token:<tab><tab><tab><tab><tab><tab>if token.token_type == ""value"":<tab><tab><tab><tab><tab><tab><tab>return token.stripped_value<tab>return """"","if token . token_type == ""quoted-string"" :",143
3565,"def paragraph_is_fully_commented(lines, comment, main_language):<tab>""""""Is the paragraph fully commented?""""""<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>if line[len(comment) :].lstrip().startswith(comment):<tab><tab><tab><tab>continue<tab><tab><tab>if is_magic(line, main_language):<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>return i > 0 and _BLANK_LINE.match(line)<tab>return True",if line . startswith ( comment ) :,121
3566,"def lots_connected_to_existing_roads(model):<tab>set = []<tab>for h in model.HarvestCells:<tab><tab>for (i, j) in model.ExistingRoads:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if h not in set:<tab><tab><tab><tab><tab>set.append(h)<tab>return set",if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,108
3567,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""\Abarra_counter_session="",<tab><tab><tab><tab>headers.get(HTTP_HEADER.SET_COOKIE, """"),<tab><tab><tab><tab>re.I,<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab>retval |= (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""(\A|\b)barracuda_"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,194
3568,"def test_files(self):<tab># get names of files to test<tab>dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)<tab>names = []<tab>for d in self.test_directories:<tab><tab>test_dir = os.path.join(dist_dir, d)<tab><tab>for n in os.listdir(test_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.append(os.path.join(test_dir, n))<tab>for filename in names:<tab><tab>if test_support.verbose:<tab><tab><tab>print(""Testing %s"" % filename)<tab><tab>source = read_pyfile(filename)<tab><tab>self.check_roundtrip(source)","if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :",186
3569,"def test_calibrate_target(create_target):<tab>mod, params = testing.synthetic.get_workload()<tab>dataset = get_calibration_dataset(mod, ""data"")<tab>with relay.quantize.qconfig(calibrate_mode=""kl_divergence""):<tab><tab><IF-STMT><tab><tab><tab>with tvm.target.Target(""llvm""):<tab><tab><tab><tab>relay.quantize.quantize(mod, params, dataset)<tab><tab>else:<tab><tab><tab># current_target = None<tab><tab><tab>relay.quantize.quantize(mod, params, dataset)",if create_target :,133
3570,"def _cleanSubmodule(self, _=None):<tab>rc = RC_SUCCESS<tab>if self.submodules:<tab><tab>command = [<tab><tab><tab>""submodule"",<tab><tab><tab>""foreach"",<tab><tab><tab>""--recursive"",<tab><tab><tab>""git"",<tab><tab><tab>""clean"",<tab><tab><tab>""-f"",<tab><tab><tab>""-f"",<tab><tab><tab>""-d"",<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>command.append(""-x"")<tab><tab>rc = yield self._dovccmd(command)<tab>defer.returnValue(rc)","if self . mode == ""full"" and self . method == ""fresh"" :",147
3571,"def screen_length_to_bytes_count(string, screen_length_limit, encoding):<tab>bytes_count = 0<tab>screen_length = 0<tab>for unicode_char in string:<tab><tab>screen_length += screen_len(unicode_char)<tab><tab>char_bytes_count = len(unicode_char.encode(encoding))<tab><tab>bytes_count += char_bytes_count<tab><tab><IF-STMT><tab><tab><tab>bytes_count -= char_bytes_count<tab><tab><tab>break<tab>return bytes_count",if screen_length > screen_length_limit :,129
3572,"def tamper(payload, **kwargs):<tab>junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`""<tab>retval = """"<tab>for i, char in enumerate(payload, start=1):<tab><tab>amount = random.randint(10, 15)<tab><tab>if char == "">"":<tab><tab><tab>retval += "">""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab><IF-STMT><tab><tab><tab>retval += ""<""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == "" "":<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>else:<tab><tab><tab>retval += char<tab>return retval","elif char == ""<"" :",200
3573,"def test_parse(self):<tab>correct = 0<tab>for example in EXAMPLES:<tab><tab>try:<tab><tab><tab>schema.parse(example.schema_string)<tab><tab><tab>if example.valid:<tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Invalid schema was parsed: "" + example.schema_string)<tab><tab>except:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Valid schema failed to parse: "" + example.schema_string)<tab>fail_msg = ""Parse behavior correct on %d out of %d schemas."" % (<tab><tab>correct,<tab><tab>len(EXAMPLES),<tab>)<tab>self.assertEqual(correct, len(EXAMPLES), fail_msg)",if not example . valid :,188
3574,"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab><IF-STMT><tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed","if isinstance ( value , bool ) :",145
3575,"def normalize(d: Dict[Any, Any]) -> Dict[str, Any]:<tab>first_exception = None<tab>for normalizer in normalizers:<tab><tab>try:<tab><tab><tab>normalized = normalizer(d)<tab><tab>except KeyError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>first_exception = e<tab><tab>else:<tab><tab><tab>return normalized<tab>assert first_exception is not None<tab>raise first_exception",if not first_exception :,103
3576,"def gather_callback_args(self, obj, callbacks):<tab>session = sa.orm.object_session(obj)<tab>for callback in callbacks:<tab><tab>backref = callback.backref<tab><tab>root_objs = getdotattr(obj, backref) if backref else obj<tab><tab>if root_objs:<tab><tab><tab>if not isinstance(root_objs, Iterable):<tab><tab><tab><tab>root_objs = [root_objs]<tab><tab><tab>with session.no_autoflush:<tab><tab><tab><tab>for root_obj in root_objs:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>args = self.get_callback_args(root_obj, callback)<tab><tab><tab><tab><tab><tab>if args:<tab><tab><tab><tab><tab><tab><tab>yield args",if root_obj :,182
3577,"def test_opdm_to_oqdm(self):<tab>for file in filter(lambda x: x.endswith("".hdf5""), os.listdir(DATA_DIRECTORY)):<tab><tab>molecule = MolecularData(filename=os.path.join(DATA_DIRECTORY, file))<tab><tab><IF-STMT><tab><tab><tab>test_oqdm = map_one_pdm_to_one_hole_dm(molecule.fci_one_rdm)<tab><tab><tab>true_oqdm = numpy.eye(molecule.n_qubits) - molecule.fci_one_rdm<tab><tab><tab>assert numpy.allclose(test_oqdm, true_oqdm)",if molecule . fci_one_rdm is not None :,171
3578,"def emitSubDomainData(self, subDomainData, event):<tab>self.emitRawRirData(subDomainData, event)<tab>for subDomainElem in subDomainData:<tab><tab>if self.checkForStop():<tab><tab><tab>return None<tab><tab>subDomain = subDomainElem.get(""subdomain"", """").strip()<tab><tab><IF-STMT><tab><tab><tab>self.emitHostname(subDomain, event)",if subDomain :,99
3579,"def download_cve(<tab>download_path: str, years: Optional[List[int]] = None, update: bool = False):<tab>if update:<tab><tab>process_url(CVE_URL.format(""modified""), download_path)<tab>else:<tab><tab>all_cve_urls = get_cve_links(CVE_URL, years)<tab><tab><IF-STMT><tab><tab><tab>raise CveLookupException(""Error: No CVE links found"")<tab><tab>for url in all_cve_urls:<tab><tab><tab>process_url(url, download_path)",if not all_cve_urls :,142
3580,"def is_special(s, i, directive):<tab>""""""Return True if the body text contains the @ directive.""""""<tab># j = skip_line(s,i) ; trace(s[i:j],':',directive)<tab>assert directive and directive[0] == ""@""<tab># 10/23/02: all directives except @others must start the line.<tab>skip_flag = directive in (""@others"", ""@all"")<tab>while i < len(s):<tab><tab>if match_word(s, i, directive):<tab><tab><tab>return True, i<tab><tab>else:<tab><tab><tab>i = skip_line(s, i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i = skip_ws(s, i)<tab>return False, -1",if skip_flag :,178
3581,"def run_async(self, nuke_cursors):<tab># type: (bool) -> None<tab>interface_type = self.view.settings().get(""git_savvy.interface"")<tab>for cls in subclasses:<tab><tab>if cls.interface_type == interface_type:<tab><tab><tab>vid = self.view.id()<tab><tab><tab>interface = interfaces.get(vid, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>interface = interfaces[vid] = cls(view=self.view)<tab><tab><tab>interface.render(nuke_cursors=nuke_cursors)  # type: ignore[union-attr]<tab><tab><tab>break",if not interface :,155
3582,"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if str(conf[""properties""][""sslEnforcement""]).lower() == ""enabled"":<tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED","if ""sslEnforcement"" in conf [ ""properties"" ] :",77
3583,"def do_shorts(<tab>opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str]) -> Tuple[List[Tuple[str, str]], List[str]]:<tab>while optstring != """":<tab><tab>opt, optstring = optstring[0], optstring[1:]<tab><tab>if short_has_arg(opt, shortopts):<tab><tab><tab>if optstring == """":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise GetoptError(""option -%s requires argument"" % opt, opt)<tab><tab><tab><tab>optstring, args = args[0], args[1:]<tab><tab><tab>optarg, optstring = optstring, """"<tab><tab>else:<tab><tab><tab>optarg = """"<tab><tab>opts.append((""-"" + opt, optarg))<tab>return opts, args",if not args :,183
3584,"def release(self):<tab>tid = _thread.get_ident()<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""cannot release un-acquired lock"")<tab><tab>assert self.count > 0<tab><tab>self.count -= 1<tab><tab>if self.count == 0:<tab><tab><tab>self.owner = None<tab><tab><tab>if self.waiters:<tab><tab><tab><tab>self.waiters -= 1<tab><tab><tab><tab>self.wakeup.release()",if self . owner != tid :,117
3585,"def _summarize_kraken(fn):<tab>""""""get the value at species level""""""<tab>kraken = {}<tab>list_sp, list_value = [], []<tab>with open(fn) as handle:<tab><tab>for line in handle:<tab><tab><tab>cols = line.strip().split(""\t"")<tab><tab><tab>sp = cols[5].strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>list_sp.append(sp)<tab><tab><tab><tab>list_value.append(cols[0])<tab>kraken = {""kraken_sp"": list_sp, ""kraken_value"": list_value}<tab>return kraken","if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :",159
3586,"def _sync_remote_run(remote_run):<tab>assert remote_run.remote<tab>remote_name = remote_run.remote.name<tab>pull_args = click_util.Args(remote=remote_name, delete=False)<tab>try:<tab><tab>remote_impl_support.pull_runs([remote_run], pull_args)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab>log.exception(""pull %s from %s"", remote_run.id, remote_name)<tab><tab>else:<tab><tab><tab>log.error(""error pulling %s from %s: %s"", remote_run.id, remote_name, e)",if log . getEffectiveLevel ( ) <= logging . DEBUG :,163
3587,"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x):<tab>sign = None<tab>subseq = []<tab>for i in seq:<tab><tab>ki = key(i)<tab><tab><IF-STMT><tab><tab><tab>subseq.append(i)<tab><tab><tab>if ki != 0:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab>else:<tab><tab><tab>subseq.append(i)<tab><tab><tab>if sign * ki < -slop:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab><tab><tab>yield subseq<tab><tab><tab><tab>subseq = [i]<tab>if subseq:<tab><tab>yield subseq",if sign is None :,167
3588,"def import_til(self):<tab>log(""Importing type libraries..."")<tab>cur = self.db_cursor()<tab>sql = ""select name from diff.program_data where type = 'til'""<tab>cur.execute(sql)<tab>for row in cur.fetchall():<tab><tab>til = row[""name""]<tab><tab><IF-STMT><tab><tab><tab>til = til.decode(""utf-8"")<tab><tab>try:<tab><tab><tab>add_default_til(til)<tab><tab>except:<tab><tab><tab>log(""Error loading til %s: %s"" % (row[""name""], str(sys.exc_info()[1])))<tab>cur.close()<tab>auto_wait()",if type ( til ) is bytes :,168
3589,"def getBranches(self):<tab>returned = []<tab>for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout:<tab><tab><IF-STMT><tab><tab><tab>git_branch_line = git_branch_line[1:]<tab><tab>git_branch_line = git_branch_line.strip()<tab><tab>if BRANCH_ALIAS_MARKER in git_branch_line:<tab><tab><tab>alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER)<tab><tab><tab>returned.append(branch.LocalBranchAlias(self, alias_name, aliased))<tab><tab>else:<tab><tab><tab>returned.append(branch.LocalBranch(self, git_branch_line))<tab>return returned","if git_branch_line . startswith ( ""*"" ) :",178
3590,"def add_include_dirs(self, args):<tab>ids = []<tab>for a in args:<tab><tab># FIXME same hack, forcibly unpack from holder.<tab><tab><IF-STMT><tab><tab><tab>a = a.includedirs<tab><tab>if not isinstance(a, IncludeDirs):<tab><tab><tab>raise InvalidArguments(<tab><tab><tab><tab>""Include directory to be added is not an include directory object.""<tab><tab><tab>)<tab><tab>ids.append(a)<tab>self.include_dirs += ids","if hasattr ( a , ""includedirs"" ) :",120
3591,"def _serialize_feature(self, feature):<tab>name = feature.unique_name()<tab><IF-STMT><tab><tab>self._features_dict[feature.unique_name()] = feature.to_dictionary()<tab><tab>for dependency in feature.get_dependencies(deep=True):<tab><tab><tab>name = dependency.unique_name()<tab><tab><tab>if name not in self._features_dict:<tab><tab><tab><tab>self._features_dict[name] = dependency.to_dictionary()",if name not in self . _features_dict :,117
3592,"def generate_io(chart_type, race_configs, environment):<tab># output JSON structures<tab>structures = []<tab>for race_config in race_configs:<tab><tab><IF-STMT><tab><tab><tab>title = chart_type.format_title(<tab><tab><tab><tab>environment,<tab><tab><tab><tab>race_config.track,<tab><tab><tab><tab>es_license=race_config.es_license,<tab><tab><tab><tab>suffix=""%s-io"" % race_config.label,<tab><tab><tab>)<tab><tab><tab>structures.append(chart_type.io(title, environment, race_config))<tab>return structures","if ""io"" in race_config . charts :",150
3593,"def format_partition(partition, partition_schema):<tab>tokens = []<tab>if isinstance(partition, dict):<tab><tab>for name in partition_schema:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tok = _format_partition_kv(<tab><tab><tab><tab><tab>name, partition[name], partition_schema[name]<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab># dynamic partitioning<tab><tab><tab><tab>tok = name<tab><tab><tab>tokens.append(tok)<tab>else:<tab><tab>for name, value in zip(partition_schema, partition):<tab><tab><tab>tok = _format_partition_kv(name, value, partition_schema[name])<tab><tab><tab>tokens.append(tok)<tab>return ""PARTITION ({})"".format("", "".join(tokens))",if name in partition :,183
3594,"def to_dict(self, validate=True, ignore=(), context=None):<tab>context = context or {}<tab>condition = getattr(self, ""condition"", Undefined)<tab>copy = self  # don't copy unless we need to<tab>if condition is not Undefined:<tab><tab>if isinstance(condition, core.SchemaBase):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>kwds = parse_shorthand(condition[""field""], context.get(""data"", None))<tab><tab><tab>copy = self.copy(deep=[""condition""])<tab><tab><tab>copy.condition.update(kwds)<tab>return super(ValueChannelMixin, copy).to_dict(<tab><tab>validate=validate, ignore=ignore, context=context<tab>)","elif ""field"" in condition and ""type"" not in condition :",175
3595,"def _checkForCommand(self):<tab>prompt = b""cftp> ""<tab>if self._expectingCommand and self._lineBuffer == prompt:<tab><tab>buf = b""\n"".join(self._linesReceived)<tab><tab><IF-STMT><tab><tab><tab>buf = buf[len(prompt) :]<tab><tab>self.clearBuffer()<tab><tab>d, self._expectingCommand = self._expectingCommand, None<tab><tab>d.callback(buf)",if buf . startswith ( prompt ) :,109
3596,"def schedule_logger(job_id=None, delete=False):<tab>if not job_id:<tab><tab>return getLogger(""fate_flow_schedule"")<tab>else:<tab><tab>if delete:<tab><tab><tab>with LoggerFactory.lock:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>for key in LoggerFactory.schedule_logger_dict.keys():<tab><tab><tab><tab><tab><tab>if job_id in key:<tab><tab><tab><tab><tab><tab><tab>del LoggerFactory.schedule_logger_dict[key]<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab><tab>key = job_id + ""schedule""<tab><tab><IF-STMT><tab><tab><tab>return LoggerFactory.schedule_logger_dict[key]<tab><tab>return LoggerFactory.get_schedule_logger(job_id)",if key in LoggerFactory . schedule_logger_dict :,198
3597,"def halfMultipartScore(nzb_name):<tab>try:<tab><tab>wrong_found = 0<tab><tab>for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]:<tab><tab><tab>for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]:<tab><tab><tab><tab>if ""%s%s"" % (wrong, nr) in nzb_name.lower():<tab><tab><tab><tab><tab>wrong_found += 1<tab><tab><IF-STMT><tab><tab><tab>return -30<tab><tab>return 0<tab>except:<tab><tab>log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc())<tab>return 0",if wrong_found == 1 :,183
3598,"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]:<tab>argstr += "",""<tab>args = []<tab>kwargs = {}<tab>for item in _converter_args_re.finditer(argstr):<tab><tab>value = item.group(""stringval"")<tab><tab>if value is None:<tab><tab><tab>value = item.group(""value"")<tab><tab>value = _pythonize(value)<tab><tab><IF-STMT><tab><tab><tab>args.append(value)<tab><tab>else:<tab><tab><tab>name = item.group(""name"")<tab><tab><tab>kwargs[name] = value<tab>return tuple(args), kwargs","if not item . group ( ""name"" ) :",164
3599,"def leaves(self, unique=True):<tab>""""""Get the leaves of the tree starting at this root.""""""<tab>if not self.children:<tab><tab>return [self]<tab>else:<tab><tab>res = list()<tab><tab>for child in self.children:<tab><tab><tab>for sub_child in child.leaves(unique=unique):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>res.append(sub_child)<tab><tab>return res",if not unique or sub_child not in res :,112
3600,"def to_tree(self, tagname=None, idx=None, namespace=None):<tab>axIds = set((ax.axId for ax in self._axes))<tab>for chart in self._charts:<tab><tab>for id, axis in chart._axes.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(self, axis.tagname, axis)<tab><tab><tab><tab>axIds.add(id)<tab>return super(PlotArea, self).to_tree(tagname)",if id not in axIds :,116
3601,"def update_neighbor(neigh_ip_address, changes):<tab>rets = []<tab>for k, v in changes.items():<tab><tab>if k == neighbors.MULTI_EXIT_DISC:<tab><tab><tab>rets.append(_update_med(neigh_ip_address, v))<tab><tab>if k == neighbors.ENABLED:<tab><tab><tab>rets.append(update_neighbor_enabled(neigh_ip_address, v))<tab><tab><IF-STMT><tab><tab><tab>rets.append(_update_connect_mode(neigh_ip_address, v))<tab>return all(rets)",if k == neighbors . CONNECT_MODE :,138
3602,"def close_all_connections():<tab>global _managers, _lock, _in_use, _timer<tab>_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>_timer.cancel()<tab><tab><tab>_timer = None<tab><tab>for domain, managers in _managers.items():<tab><tab><tab>for manager in managers:<tab><tab><tab><tab>manager.close()<tab><tab>_managers = {}<tab>finally:<tab><tab>_lock.release()",if _timer :,109
3603,"def _instrument_model(self, model):<tab>for key, value in list(<tab><tab>model.__dict__.items()<tab>):  # avoid ""dictionary keys changed during iteration""<tab><tab>if isinstance(value, tf.keras.layers.Layer):<tab><tab><tab>new_layer = self._instrument(value)<tab><tab><tab>if new_layer is not value:<tab><tab><tab><tab>setattr(model, key, new_layer)<tab><tab>elif isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value[i] = self._instrument(item)<tab>return model","if isinstance ( item , tf . keras . layers . Layer ) :",164
3604,"def target_glob(tgt, hosts):<tab>ret = {}<tab>for host in hosts:<tab><tab>if fnmatch.fnmatch(tgt, host):<tab><tab><tab>ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {}))<tab><tab><tab>ret[host].update({""host"": host})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret[host].update({""user"": __opts__[""ssh_user""]})<tab>return ret","if __opts__ . get ( ""ssh_user"" ) :",110
3605,"def write(self, data):<tab>if mock_target._mirror_on_stderr:<tab><tab>if self._write_line:<tab><tab><tab>sys.stderr.write(fn + "": "")<tab><tab><IF-STMT><tab><tab><tab>sys.stderr.write(data.decode(""utf8""))<tab><tab>else:<tab><tab><tab>sys.stderr.write(data)<tab><tab>if (data[-1]) == ""\n"":<tab><tab><tab>self._write_line = True<tab><tab>else:<tab><tab><tab>self._write_line = False<tab>super(Buffer, self).write(data)",if bytes :,137
3606,"def task_thread():<tab>while not task_queue.empty():<tab><tab>host, port, username, password = task_queue.get()<tab><tab>logger.info(<tab><tab><tab>""try burst {}:{} use username:{} password:{}"".format(<tab><tab><tab><tab>host, port, username, password<tab><tab><tab>)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>with task_queue.mutex:<tab><tab><tab><tab>task_queue.queue.clear()<tab><tab><tab>result_queue.put((username, password))","if telnet_login ( host , port , username , password ) :",135
3607,"def _format_results(name, ppl, scores, metrics):<tab>""""""Format results.""""""<tab>result_str = """"<tab>if ppl:<tab><tab>result_str = ""%s ppl %.2f"" % (name, ppl)<tab>if scores:<tab><tab>for metric in metrics:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result_str += "", %s %s %.1f"" % (name, metric, scores[metric])<tab><tab><tab>else:<tab><tab><tab><tab>result_str = ""%s %s %.1f"" % (name, metric, scores[metric])<tab>return result_str",if result_str :,142
3608,"def info_query(self, query):<tab>""""""Send a query which only returns 1 row""""""<tab>self._cmysql.query(query)<tab>first_row = ()<tab>if self._cmysql.have_result_set:<tab><tab>first_row = self._cmysql.fetch_row()<tab><tab><IF-STMT><tab><tab><tab>self._cmysql.free_result()<tab><tab><tab>raise errors.InterfaceError(""Query should not return more than 1 row"")<tab>self._cmysql.free_result()<tab>return first_row",if self . _cmysql . fetch_row ( ) :,131
3609,"def reset_class(self):<tab>for f in self.fields_order:<tab><tab><IF-STMT><tab><tab><tab>f.value = int(f.strbits, 2)<tab><tab>elif ""default_val"" in f.kargs:<tab><tab><tab>f.value = int(f.kargs[""default_val""], 2)<tab><tab>else:<tab><tab><tab>f.value = None<tab><tab>if f.fname:<tab><tab><tab>setattr(self, f.fname, f)",if f . strbits and isbin ( f . strbits ) :,123
3610,"def _walk_map_list(self, access_func):<tab>seen = []<tab>cur = self<tab>while cur:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>yield cur<tab><tab>seen.append(cur.obj_offset)<tab><tab># check for signs of infinite looping<tab><tab>if len(seen) > 1024:<tab><tab><tab>break<tab><tab>cur = access_func(cur)",if cur . obj_offset in seen :,102
3611,def bgdel():<tab>q = bgdelq<tab>while True:<tab><tab>name = q.get()<tab><tab>while os.path.exists(name):<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>os.remove(name)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>shutil.rmtree(name)<tab><tab><tab>except:<tab><tab><tab><tab>pass<tab><tab><tab>if os.path.exists(name):<tab><tab><tab><tab>time.sleep(0.1),if os . path . isfile ( name ) :,127
3612,"def _find_all_variables(transfer_variable):<tab>d = {}<tab>for _k, _v in transfer_variable.__dict__.items():<tab><tab>if isinstance(_v, Variable):<tab><tab><tab>d[_v._name] = _v<tab><tab><IF-STMT><tab><tab><tab>d.update(_find_all_variables(_v))<tab>return d","elif isinstance ( _v , BaseTransferVariables ) :",91
3613,"def set_val():<tab>idx = 0<tab>for idx in range(0, len(model)):<tab><tab>row = model[idx]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if idx == len(os_widget.get_model()) - 1:<tab><tab><tab>idx = -1<tab>os_widget.set_active(idx)<tab>if idx == -1:<tab><tab>os_widget.set_active(0)<tab>if idx >= 0:<tab><tab>return row[1]<tab>if self.show_all_os:<tab><tab>return None",if value and row [ 0 ] == value :,142
3614,"def _make_cache_key(group, window, rate, value, methods):<tab>count, period = _split_rate(rate)<tab>safe_rate = ""%d/%ds"" % (count, period)<tab>parts = [group, safe_rate, value, str(window)]<tab>if methods is not None:<tab><tab>if methods == ALL:<tab><tab><tab>methods = """"<tab><tab><IF-STMT><tab><tab><tab>methods = """".join(sorted([m.upper() for m in methods]))<tab><tab>parts.append(methods)<tab>prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"")<tab>return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()","elif isinstance ( methods , ( list , tuple ) ) :",175
3615,"def findfiles(path):<tab>files = []<tab>for name in os.listdir(path):<tab><tab># ignore hidden files/dirs and other unwanted files<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pathname = os.path.join(path, name)<tab><tab>st = os.lstat(pathname)<tab><tab>mode = st.st_mode<tab><tab>if stat.S_ISDIR(mode):<tab><tab><tab>files.extend(findfiles(pathname))<tab><tab>elif stat.S_ISREG(mode):<tab><tab><tab>files.append((pathname, name, st))<tab>return files","if name . startswith ( ""."" ) or name == ""lastsnap.jpg"" :",150
3616,"def __getitem__(self, key):<tab>if isinstance(key, str_types):<tab><tab>keys = self.get_keys()<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(' ""{0}"" is an invalid key'.format(key))<tab><tab>else:<tab><tab><tab>return self[keys.index(key)]<tab>else:<tab><tab>return list.__getitem__(self, key)",if key not in keys :,93
3617,"def test_assert_set_equal(estimate: tp.Iterable[int], message: str) -> None:<tab>reference = {1, 2, 3}<tab>try:<tab><tab>testing.assert_set_equal(estimate, reference)<tab>except AssertionError as error:<tab><tab>if not message:<tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>""An error has been raised while it should not.""<tab><tab><tab>) from error<tab><tab>np.testing.assert_equal(error.args[0].split(""\n"")[1:], message)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(""An error should have been raised."")",if message :,148
3618,"def get_directory_info(prefix, pth, recursive):<tab>res = []<tab>directory = os.listdir(pth)<tab>directory.sort()<tab>for p in directory:<tab><tab><IF-STMT><tab><tab><tab>subp = os.path.join(pth, p)<tab><tab><tab>p = os.path.join(prefix, p)<tab><tab><tab>if recursive and os.path.isdir(subp):<tab><tab><tab><tab>res.append([p, get_directory_info(prefix, subp, 1)])<tab><tab><tab>else:<tab><tab><tab><tab>res.append([p, None])<tab>return res","if p [ 0 ] != ""."" :",148
3619,"def check(self, runner, script, info):<tab>if isinstance(info, ast.FunctionDef):<tab><tab>for arg in info.args.args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if arg.id in script.modelVars:<tab><tab><tab><tab><tab>self.problem(<tab><tab><tab><tab><tab><tab>""Function {0} may shadow model variable {1}"".format(<tab><tab><tab><tab><tab><tab><tab>info.name, arg.id<tab><tab><tab><tab><tab><tab>),<tab><tab><tab><tab><tab><tab>lineno=info.lineno,<tab><tab><tab><tab><tab>)","if isinstance ( arg , ast . Name ) :",137
3620,"def db_lookup(field, key, publish_year=None):<tab>sql = ""select sum(ebook_count) as num from subjects where field=$field and key=$key""<tab>if publish_year:<tab><tab><IF-STMT><tab><tab><tab>sql += "" and publish_year between $y1 and $y2""<tab><tab><tab>(y1, y2) = publish_year<tab><tab>else:<tab><tab><tab>sql += "" and publish_year=$publish_year""<tab>return list(ebook_count_db.query(sql, vars=locals()))[0].num","if isinstance ( publish_year , ( tuple , list ) ) :",141
3621,"def put(self, session):<tab>with sess_lock:<tab><tab>self.parent.put(session)<tab><tab># Do not store the session if skip paths<tab><tab>for sp in self.skip_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>if session.sid in self._cache:<tab><tab><tab>try:<tab><tab><tab><tab>del self._cache[session.sid]<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass<tab><tab>self._cache[session.sid] = session<tab>self._normalize()",if request . path . startswith ( sp ) :,133
3622,"def summarize(self):<tab>if self.bad_commit and self.good_commit:<tab><tab>for subresult in self.subresults.values():<tab><tab><tab>sub = subresult.summarize()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return sub<tab><tab>return ""Detected bad commit in {} repository:\n{} {}"".format(<tab><tab><tab>self.repo_name, self.bad_commit, get_message(self.suite, self.bad_commit)<tab><tab>)<tab>return """"",if sub :,115
3623,def compute_nullable_nonterminals(self):<tab>nullable = {}<tab>num_nullable = 0<tab>while 1:<tab><tab>for p in self.grammar.Productions[1:]:<tab><tab><tab>if p.len == 0:<tab><tab><tab><tab>nullable[p.name] = 1<tab><tab><tab><tab>continue<tab><tab><tab>for t in p.prod:<tab><tab><tab><tab>if not t in nullable:<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>nullable[p.name] = 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>num_nullable = len(nullable)<tab>return nullable,if len ( nullable ) == num_nullable :,153
3624,"def _cast_float64_to_float32(self, feeds):<tab>for input_name, input_type in self.inputs:<tab><tab><IF-STMT><tab><tab><tab>feed = feeds.get(input_name)<tab><tab><tab>if feed is not None and feed.dtype == np.float64:<tab><tab><tab><tab>feeds[input_name] = feed.astype(np.float32)<tab>return feeds","if input_type == ""tensor(float)"" :",103
3625,"def proc_minute(d):<tab>if expanded[0][0] != ""*"":<tab><tab>diff_min = nearest_diff_method(d.minute, expanded[0], 60)<tab><tab><IF-STMT><tab><tab><tab>if is_prev:<tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=59)<tab><tab><tab>else:<tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=0)<tab><tab><tab>return True, d<tab>return False, d",if diff_min is not None and diff_min != 0 :,128
3626,"def detype(self):<tab>if self._detyped is not None:<tab><tab>return self._detyped<tab>ctx = {}<tab>for key, val in self._d.items():<tab><tab>if not isinstance(key, str):<tab><tab><tab>key = str(key)<tab><tab>detyper = self.get_detyper(key)<tab><tab>if detyper is None:<tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>deval = detyper(val)<tab><tab><IF-STMT><tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>ctx[key] = deval<tab>self._detyped = ctx<tab>return ctx",if deval is None :,163
3627,"def get_or_create_user(request, user_data):<tab>try:<tab><tab>user = User.objects.get(sso_id=user_data[""id""])<tab><tab><IF-STMT><tab><tab><tab>update_user(user, user_data)<tab><tab>return user<tab>except User.DoesNotExist:<tab><tab>user = User.objects.create_user(<tab><tab><tab>user_data[""username""],<tab><tab><tab>user_data[""email""],<tab><tab><tab>is_active=user_data.get(""is_active"", True),<tab><tab><tab>sso_id=user_data[""id""],<tab><tab>)<tab><tab>user.update_acl_key()<tab><tab>setup_new_user(request.settings, user)<tab><tab>return user","if user_needs_updating ( user , user_data ) :",185
3628,"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict):<tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab><IF-STMT><tab><tab><tab>self._populate_bool(element, k, v)<tab><tab>elif isinstance(v, basestring):<tab><tab><tab>self._populate_str(element, k, v)<tab><tab>elif type(v) in [int, float, long, complex]:<tab><tab><tab>self._populate_number(element, k, v)","elif isinstance ( v , bool ) :",178
3629,"def load(cls):<tab>if not cls._loaded:<tab><tab>cls.log.debug(""Loading action_sets..."")<tab><tab><IF-STMT><tab><tab><tab>cls._find_action_sets(PATHS.ACTION_SETS_DIRECTORY)<tab><tab>else:<tab><tab><tab>cls.action_sets = JsonDecoder.load(PATHS.ACTION_SETS_JSON_FILE)<tab><tab>cls.log.debug(""Done!"")<tab><tab>cls._loaded = True",if not horizons . globals . fife . use_atlases :,118
3630,"def Resolve(self, updater=None):<tab>if len(self.Conflicts):<tab><tab>for setting, edge in self.Conflicts:<tab><tab><tab>answer = self.AskUser(self.Setting, setting)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = setting.Value.split(""|"")<tab><tab><tab><tab>value.remove(edge)<tab><tab><tab><tab>setting.Value = ""|"".join(value)<tab><tab><tab><tab>if updater:<tab><tab><tab><tab><tab>updater.UpdateSetting(setting)<tab><tab><tab>if answer == Gtk.ResponseType.NO:<tab><tab><tab><tab>return False<tab>return True",if answer == Gtk . ResponseType . YES :,146
3631,"def read_tsv(input_file, quotechar=None):<tab>""""""Reads a tab separated value file.""""""<tab>with open(input_file, ""r"", encoding=""utf-8-sig"") as f:<tab><tab>reader = csv.reader(f, delimiter=""\t"", quotechar=quotechar)<tab><tab>lines = []<tab><tab>for line in reader:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = list(str(cell, ""utf-8"") for cell in line)  # noqa: F821<tab><tab><tab>lines.append(line)<tab><tab>return lines",if sys . version_info [ 0 ] == 2 :,140
3632,"def devd_devfs_hook(middleware, data):<tab>if data.get(""subsystem"") != ""CDEV"":<tab><tab>return<tab>if data[""type""] == ""CREATE"":<tab><tab>disks = await middleware.run_in_thread(<tab><tab><tab>lambda: sysctl.filter(""kern.disks"")[0].value.split()<tab><tab>)<tab><tab># Device notified about is not a disk<tab><tab>if data[""cdev""] not in disks:<tab><tab><tab>return<tab><tab>await added_disk(middleware, data[""cdev""])<tab>elif data[""type""] == ""DESTROY"":<tab><tab># Device notified about is not a disk<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>await remove_disk(middleware, data[""cdev""])","if not RE_ISDISK . match ( data [ ""cdev"" ] ) :",190
3633,"def on_edit_button_clicked(self, event=None, a=None, col=None):<tab>tree, tree_id = self.treeView.get_selection().get_selected()<tab>watchdir_id = str(self.store.get_value(tree_id, 0))<tab>if watchdir_id:<tab><tab><IF-STMT><tab><tab><tab>if self.watchdirs[watchdir_id][""enabled""]:<tab><tab><tab><tab>client.autoadd.disable_watchdir(watchdir_id)<tab><tab><tab>else:<tab><tab><tab><tab>client.autoadd.enable_watchdir(watchdir_id)<tab><tab>else:<tab><tab><tab>self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)","if col and col . get_title ( ) == _ ( ""Active"" ) :",187
3634,"def _execute(self, options, args):<tab>if len(args) < 1:<tab><tab>raise CommandError(_(""Not enough arguments""))<tab>paths = args<tab>songs = [self.load_song(p) for p in paths]<tab>for song in songs:<tab><tab><IF-STMT><tab><tab><tab>raise CommandError(<tab><tab><tab><tab>_(""Image editing not supported for %(file_name)s "" ""(%(file_format)s)"")<tab><tab><tab><tab>% {""file_name"": song(""~filename""), ""file_format"": song(""~format"")}<tab><tab><tab>)<tab>for song in songs:<tab><tab>try:<tab><tab><tab>song.clear_images()<tab><tab>except AudioFileError as e:<tab><tab><tab>raise CommandError(e)",if not song . can_change_images :,176
3635,"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None):<tab>filtered_pricing_rules = []<tab>if doc:<tab><tab>for pricing_rule in pricing_rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>if frappe.safe_eval(pricing_rule.condition, None, doc.as_dict()):<tab><tab><tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab>else:<tab><tab>filtered_pricing_rules = pricing_rules<tab>return filtered_pricing_rules",if pricing_rule . condition :,179
3636,"def ProcessStringLiteral(self):<tab>if self._lastToken == None or self._lastToken.type == self.OpenBrace:<tab><tab>text = super(JavaScriptBaseLexer, self).text<tab><tab>if text == '""use strict""' or text == ""'use strict'"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._scopeStrictModes.pop()<tab><tab><tab>self._useStrictCurrent = True<tab><tab><tab>self._scopeStrictModes.append(self._useStrictCurrent)",if len ( self . _scopeStrictModes ) > 0 :,124
3637,"def _find_remote_inputs(metadata):<tab>out = []<tab>for fr_key in metadata.keys():<tab><tab>if isinstance(fr_key, (list, tuple)):<tab><tab><tab>frs = fr_key<tab><tab>else:<tab><tab><tab>frs = [fr_key]<tab><tab>for fr in frs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out.append(fr)<tab>return out",if objectstore . is_remote ( fr ) :,107
3638,"def sub_paragraph(self, li):<tab>""""""Search for checkbox in sub-paragraph.""""""<tab>found = False<tab>if len(li):<tab><tab>first = list(li)[0]<tab><tab>if first.tag == ""p"" and first.text is not None:<tab><tab><tab>m = RE_CHECKBOX.match(first.text)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>first.text = self.markdown.htmlStash.store(<tab><tab><tab><tab><tab>get_checkbox(m.group(""state"")), safe=True<tab><tab><tab><tab>) + m.group(""line"")<tab><tab><tab><tab>found = True<tab>return found",if m is not None :,152
3639,"def list_files(basedir):<tab>""""""List files in the directory rooted at |basedir|.""""""<tab>if not os.path.isdir(basedir):<tab><tab>raise NoSuchDirectory(basedir)<tab>directories = [""""]<tab>while directories:<tab><tab>d = directories.pop()<tab><tab>for basename in os.listdir(os.path.join(basedir, d)):<tab><tab><tab>filename = os.path.join(d, basename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>directories.append(filename)<tab><tab><tab>elif os.path.exists(os.path.join(basedir, filename)):<tab><tab><tab><tab>yield filename","if os . path . isdir ( os . path . join ( basedir , filename ) ) :",159
3640,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,90
3641,"def _dump(self, fd):<tab>with self.no_unpicklable_properties():<tab><tab><IF-STMT><tab><tab><tab>d = pickle.dumps(self)<tab><tab><tab>module_name = os.path.basename(sys.argv[0]).rsplit(""."", 1)[0]<tab><tab><tab>d = d.replace(b""c__main__"", b""c"" + module_name.encode(""ascii""))<tab><tab><tab>fd.write(d)<tab><tab>else:<tab><tab><tab>pickle.dump(self, fd)","if self . __module__ == ""__main__"" :",128
3642,"def assert_session_stack(classes):<tab>assert len(_SklearnTrainingSession._session_stack) == len(classes)<tab>for idx, (sess, (parent_clazz, clazz)) in enumerate(<tab><tab>zip(_SklearnTrainingSession._session_stack, classes)<tab>):<tab><tab>assert sess.clazz == clazz<tab><tab><IF-STMT><tab><tab><tab>assert sess._parent is None<tab><tab>else:<tab><tab><tab>assert sess._parent.clazz == parent_clazz",if idx == 0 :,118
3643,"def native_color(c):<tab>try:<tab><tab>color = CACHE[c]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>c = NAMED_COLOR[c]<tab><tab>color = Color.FromArgb(<tab><tab><tab>int(c.rgba.a * 255), int(c.rgba.r), int(c.rgba.g), int(c.rgba.b)<tab><tab>)<tab><tab>CACHE[c] = color<tab>return color","if isinstance ( c , str ) :",115
3644,"def callback(name):<tab># XXX: move into Action<tab>for neighbor_name in reactor.configuration.neighbors.keys():<tab><tab>neighbor = reactor.configuration.neighbors.get(neighbor_name, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>neighbor.rib.outgoing.announce_watchdog(name)<tab><tab>yield False<tab>reactor.processes.answer_done(service)",if not neighbor :,97
3645,"def token_producer(source):<tab>token = source.read_uint8()<tab>while token is not None:<tab><tab><IF-STMT><tab><tab><tab>yield DataToken(read_data(token, source))<tab><tab>elif is_small_integer(token):<tab><tab><tab>yield SmallIntegerToken(read_small_integer(token))<tab><tab>else:<tab><tab><tab>yield Token(token)<tab><tab>token = source.read_uint8()",if is_push_data_token ( token ) :,113
3646,"def setattr(self, req, ino, attr, to_set, fi):<tab>print(""setattr:"", ino, to_set)<tab>a = self.attr[ino]<tab>for key in to_set:<tab><tab><IF-STMT><tab><tab><tab># Keep the old file type bit fields<tab><tab><tab>a[""st_mode""] = S_IFMT(a[""st_mode""]) | S_IMODE(attr[""st_mode""])<tab><tab>else:<tab><tab><tab>a[key] = attr[key]<tab>self.attr[ino] = a<tab>self.reply_attr(req, a, 1.0)","if key == ""st_mode"" :",149
3647,"def check_enum_exports(module, eq_callback, only=None):<tab>""""""Make sure module exports all mnemonics from enums""""""<tab>for attr in enumerate_module(module, enum.Enum):<tab><tab><IF-STMT><tab><tab><tab>print(""SKIP"", attr)<tab><tab><tab>continue<tab><tab>for flag, value in attr.__members__.items():<tab><tab><tab>print(module, flag, value)<tab><tab><tab>eq_callback(getattr(module, flag), value)",if only is not None and attr not in only :,118
3648,"def remove_edit_vars_to(self, n):<tab>try:<tab><tab>removals = []<tab><tab>for v, cei in self.edit_var_map.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>removals.append(v)<tab><tab>for v in removals:<tab><tab><tab>self.remove_edit_var(v)<tab><tab>assert len(self.edit_var_map) == n<tab>except ConstraintNotFound:<tab><tab>raise InternalError(""Constraint not found during internal removal"")",if cei . index >= n :,129
3649,"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab>if type(e) is Argument or type(e) is Option and e.argcount:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab>elif type(e.value) is not list:<tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab>if type(e) is Command or type(e) is Option and e.argcount == 0:<tab><tab><tab><tab>e.value = 0<tab>return self",if e . value is None :,190
3650,"def add_I_prefix(current_line: List[str], ner: int, tag: str):<tab>for i in range(0, len(current_line)):<tab><tab>if i == 0:<tab><tab><tab>f.write(line_list[i])<tab><tab><IF-STMT><tab><tab><tab>f.write("" I-"" + tag)<tab><tab>else:<tab><tab><tab>f.write("" "" + current_line[i])<tab>f.write(""\n"")",elif i == ner :,111
3651,def select_word_at_cursor(self):<tab>word_region = None<tab>selection = self.view.sel()<tab>for region in selection:<tab><tab>word_region = self.view.word(region)<tab><tab><IF-STMT><tab><tab><tab>selection.clear()<tab><tab><tab>selection.add(word_region)<tab><tab><tab>return word_region<tab>return word_region,if not word_region . empty ( ) :,96
3652,"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab>if self.op == ""+"":<tab><tab><tab>self.current += num<tab><tab><IF-STMT><tab><tab><tab>self.current -= num<tab><tab>elif self.op == ""*"":<tab><tab><tab>self.current *= num<tab><tab>elif self.op == ""/"":<tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res","elif self . op == ""-"" :",187
3653,"def strip_pod(lines):<tab>in_pod = False<tab>stripped_lines = []<tab>for line in lines:<tab><tab>if re.match(r""^=(?:end|cut)"", line):<tab><tab><tab>in_pod = False<tab><tab>elif re.match(r""^=\w+"", line):<tab><tab><tab>in_pod = True<tab><tab><IF-STMT><tab><tab><tab>stripped_lines.append(line)<tab>return stripped_lines",elif not in_pod :,108
3654,"def __init__(self, patch_files, patch_directories):<tab>files = []<tab>files_data = {}<tab>for filename_data in patch_files:<tab><tab>if isinstance(filename_data, list):<tab><tab><tab>filename, data = filename_data<tab><tab>else:<tab><tab><tab>filename = filename_data<tab><tab><tab>data = None<tab><tab>if not filename.startswith(os.sep):<tab><tab><tab>filename = ""{0}{1}"".format(FakeState.deploy_dir, filename)<tab><tab>files.append(filename)<tab><tab><IF-STMT><tab><tab><tab>files_data[filename] = data<tab>self.files = files<tab>self.files_data = files_data<tab>self.directories = patch_directories",if data :,171
3655,"def loadPerfsFromModule(self, module):<tab>""""""Return a suite of all perfs cases contained in the given module""""""<tab>perfs = []<tab>for name in dir(module):<tab><tab>obj = getattr(module, name)<tab><tab><IF-STMT><tab><tab><tab>perfs.append(self.loadPerfsFromPerfCase(obj))<tab>return self.suiteClass(perfs)","if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :",108
3656,"def download_subtitle(self, subtitle):<tab>if isinstance(subtitle, XSubsSubtitle):<tab><tab># download the subtitle<tab><tab>logger.info(""Downloading subtitle %r"", subtitle)<tab><tab>r = self.session.get(<tab><tab><tab>subtitle.download_link, headers={""Referer"": subtitle.page_link}, timeout=10<tab><tab>)<tab><tab>r.raise_for_status()<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Unable to download subtitle. No data returned from provider"")<tab><tab><tab>return<tab><tab>subtitle.content = fix_line_ending(r.content)",if not r . content :,145
3657,"def get_inlaws(self, person):<tab>inlaws = []<tab>family_handles = person.get_family_handle_list()<tab>for handle in family_handles:<tab><tab>fam = self.database.get_family_from_handle(handle)<tab><tab>if fam.father_handle and not fam.father_handle == person.handle:<tab><tab><tab>inlaws.append(self.database.get_person_from_handle(fam.father_handle))<tab><tab><IF-STMT><tab><tab><tab>inlaws.append(self.database.get_person_from_handle(fam.mother_handle))<tab>return inlaws",elif fam . mother_handle and not fam . mother_handle == person . handle :,180
3658,"def _check_xorg_conf():<tab>if is_there_a_default_xorg_conf_file():<tab><tab>print(<tab><tab><tab>""WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not""<tab><tab><tab>"" create it yourself, it was likely generated by your distribution or by an Nvidia utility.\n""<tab><tab><tab>""This file may contain hard-coded GPU configuration that could interfere with optimus-manager,""<tab><tab><tab>"" so it is recommended that you delete it before proceeding.\n""<tab><tab><tab>""Ignore this warning and proceed with GPU switching ? (y/N)""<tab><tab>)<tab><tab>confirmation = ask_confirmation()<tab><tab><IF-STMT><tab><tab><tab>sys.exit(0)",if not confirmation :,178
3659,"def _make_cache_key(group, window, rate, value, methods):<tab>count, period = _split_rate(rate)<tab>safe_rate = ""%d/%ds"" % (count, period)<tab>parts = [group, safe_rate, value, str(window)]<tab>if methods is not None:<tab><tab><IF-STMT><tab><tab><tab>methods = """"<tab><tab>elif isinstance(methods, (list, tuple)):<tab><tab><tab>methods = """".join(sorted([m.upper() for m in methods]))<tab><tab>parts.append(methods)<tab>prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"")<tab>return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()",if methods == ALL :,175
3660,"def num_of_mapped_volumes(self, initiator):<tab>cnt = 0<tab>for lm_link in self.req(""lun-maps"")[""lun-maps""]:<tab><tab>idx = lm_link[""href""].split(""/"")[-1]<tab><tab># NOTE(geguileo): There can be races so mapped elements retrieved<tab><tab># in the listing may no longer exist.<tab><tab>try:<tab><tab><tab>lm = self.req(""lun-maps"", idx=int(idx))[""content""]<tab><tab>except exception.NotFound:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>cnt += 1<tab>return cnt","if lm [ ""ig-name"" ] == initiator :",157
3661,"def _setAbsoluteY(self, value):<tab>if value is None:<tab><tab>self._absoluteY = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>value = 10<tab><tab>elif value == ""below"":<tab><tab><tab>value = -70<tab><tab>try:<tab><tab><tab>value = common.numToIntOrFloat(value)<tab><tab>except ValueError as ve:<tab><tab><tab>raise TextFormatException(<tab><tab><tab><tab>f""Not a supported absoluteY position: {value!r}""<tab><tab><tab>) from ve<tab><tab>self._absoluteY = value","if value == ""above"" :",137
3662,"def render_markdown(text):<tab>users = {u.username.lower(): u for u in get_mention_users(text)}<tab>parts = MENTION_RE.split(text)<tab>for pos, part in enumerate(parts):<tab><tab>if not part.startswith(""@""):<tab><tab><tab>continue<tab><tab>username = part[1:].lower()<tab><tab><IF-STMT><tab><tab><tab>user = users[username]<tab><tab><tab>parts[pos] = '**[{}]({} ""{}"")**'.format(<tab><tab><tab><tab>part, user.get_absolute_url(), user.get_visible_name()<tab><tab><tab>)<tab>text = """".join(parts)<tab>return mark_safe(MARKDOWN(text))",if username in users :,168
3663,def start_process(self):<tab>with self.thread_lock:<tab><tab><IF-STMT><tab><tab><tab>self.allow_process_request = False<tab><tab><tab>t = threading.Thread(target=self.__start)<tab><tab><tab>t.daemon = True<tab><tab><tab>t.start(),if self . allow_process_request :,75
3664,"def close(self):<tab>if self._fh.closed:<tab><tab>return<tab>self._fh.close()<tab>if os.path.isfile(self._filename):<tab><tab><IF-STMT><tab><tab><tab>salt.utils.win_dacl.copy_security(<tab><tab><tab><tab>source=self._filename, target=self._tmp_filename<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>shutil.copymode(self._filename, self._tmp_filename)<tab><tab><tab>st = os.stat(self._filename)<tab><tab><tab>os.chown(self._tmp_filename, st.st_uid, st.st_gid)<tab>atomic_rename(self._tmp_filename, self._filename)",if salt . utils . win_dacl . HAS_WIN32 :,179
3665,"def _splitSchemaNameDotFieldName(sn_fn, fnRequired=True):<tab>if sn_fn.find(""."") != -1:<tab><tab>schemaName, fieldName = sn_fn.split(""."", 1)<tab><tab>schemaName = schemaName.strip()<tab><tab>fieldName = fieldName.strip()<tab><tab>if schemaName and fieldName:<tab><tab><tab>return (schemaName, fieldName)<tab>elif not fnRequired:<tab><tab>schemaName = sn_fn.strip()<tab><tab><IF-STMT><tab><tab><tab>return (schemaName, None)<tab>controlflow.system_error_exit(<tab><tab>2, f""{sn_fn} is not a valid custom schema.field name.""<tab>)",if schemaName :,164
3666,"def modified(self):<tab>paths = set()<tab>dictionary_list = []<tab>for op_list in self._operations:<tab><tab><IF-STMT><tab><tab><tab>op_list = (op_list,)<tab><tab>for item in chain(*op_list):<tab><tab><tab>if item is None:<tab><tab><tab><tab>continue<tab><tab><tab>dictionary = item.dictionary<tab><tab><tab>if dictionary.path in paths:<tab><tab><tab><tab>continue<tab><tab><tab>paths.add(dictionary.path)<tab><tab><tab>dictionary_list.append(dictionary)<tab>return dictionary_list","if not isinstance ( op_list , list ) :",139
3667,"def apply(self, db, person):<tab>for family_handle in person.get_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab><IF-STMT><tab><tab><tab>for event_ref in family.get_event_ref_list():<tab><tab><tab><tab>if event_ref:<tab><tab><tab><tab><tab>event = db.get_event_from_handle(event_ref.ref)<tab><tab><tab><tab><tab>if not event.get_place_handle():<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab>if not event.get_date_object():<tab><tab><tab><tab><tab><tab>return True<tab>return False",if family :,159
3668,"def test_cleanup_params(self, body, rpc_mock):<tab>res = self._get_resp_post(body)<tab>self.assertEqual(http_client.ACCEPTED, res.status_code)<tab>rpc_mock.assert_called_once_with(self.context, mock.ANY)<tab>cleanup_request = rpc_mock.call_args[0][1]<tab>for key, value in body.items():<tab><tab><IF-STMT><tab><tab><tab>if value is not None:<tab><tab><tab><tab>value = value == ""true""<tab><tab>self.assertEqual(value, getattr(cleanup_request, key))<tab>self.assertEqual(self._expected_services(*SERVICES), res.json)","if key in ( ""disabled"" , ""is_up"" ) :",177
3669,"def get_billable_and_total_duration(activity, start_time, end_time):<tab>precision = frappe.get_precision(""Timesheet Detail"", ""hours"")<tab>activity_duration = time_diff_in_hours(end_time, start_time)<tab>billing_duration = 0.0<tab>if activity.billable:<tab><tab>billing_duration = activity.billing_hours<tab><tab><IF-STMT><tab><tab><tab>billing_duration = (<tab><tab><tab><tab>activity_duration * activity.billing_hours / activity.hours<tab><tab><tab>)<tab>return flt(activity_duration, precision), flt(billing_duration, precision)",if activity_duration != activity . billing_hours :,167
3670,"def cpus(self):<tab>try:<tab><tab>cpus = (<tab><tab><tab>self.inspect[""Spec""][""Resources""][""Reservations""][""NanoCPUs""] / 1000000000.0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>cpus = int(cpus)<tab><tab>return cpus<tab>except TypeError:<tab><tab>return None<tab>except KeyError:<tab><tab>return 0",if cpus == int ( cpus ) :,92
3671,"def _create_object(self, obj_body):<tab>props = obj_body[SYMBOL_PROPERTIES]<tab>for prop_name, prop_value in props.items():<tab><tab><IF-STMT><tab><tab><tab># get the first key as the convert function<tab><tab><tab>func_name = list(prop_value.keys())[0]<tab><tab><tab>if func_name.startswith(""_""):<tab><tab><tab><tab>func = getattr(self, func_name)<tab><tab><tab><tab>props[prop_name] = func(prop_value[func_name])<tab>if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping:<tab><tab>return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props)<tab>else:<tab><tab>return props","if isinstance ( prop_value , dict ) and prop_value :",199
3672,"def _yield_unescaped(self, string):<tab>while ""\\"" in string:<tab><tab>finder = EscapeFinder(string)<tab><tab>yield finder.before + finder.backslashes<tab><tab><IF-STMT><tab><tab><tab>yield self._unescape(finder.text)<tab><tab>else:<tab><tab><tab>yield finder.text<tab><tab>string = finder.after<tab>yield string",if finder . escaped and finder . text :,91
3673,"def _check_matches(rule, matches):<tab>errors = 0<tab>for match in matches:<tab><tab>filematch = _match_to_test_file(match)<tab><tab><IF-STMT><tab><tab><tab>utils.error(<tab><tab><tab><tab>""The match '{}' for rule '{}' points to a non existing test module path: {}"",<tab><tab><tab><tab>match,<tab><tab><tab><tab>rule,<tab><tab><tab><tab>filematch,<tab><tab><tab>)<tab><tab><tab>errors += 1<tab>return errors",if not filematch . exists ( ) :,118
3674,"def focused_windows():<tab>tree = i3.get_tree()<tab>workspaces = tree.workspaces()<tab>for workspace in workspaces:<tab><tab>container = workspace<tab><tab>while container:<tab><tab><tab>if not hasattr(container, ""focus"") or not container.focus:<tab><tab><tab><tab>break<tab><tab><tab>container_id = container.focus[0]<tab><tab><tab>container = container.find_by_id(container_id)<tab><tab><IF-STMT><tab><tab><tab>coname = container.name<tab><tab><tab>wsname = workspace.name<tab><tab><tab>print(""WS"", wsname + "":"", coname)",if container :,146
3675,"def normals(self, value):<tab>if value is not None:<tab><tab>value = np.asanyarray(value, dtype=np.float32)<tab><tab>value = np.ascontiguousarray(value)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Incorrect normals shape"")<tab>self._normals = value",if value . shape != self . positions . shape :,77
3676,"def test_hexdigest(self):<tab>for cons in self.hash_constructors:<tab><tab>h = cons()<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(h.digest(16), bytes)<tab><tab><tab>self.assertEqual(hexstr(h.digest(16)), h.hexdigest(16))<tab><tab>else:<tab><tab><tab>self.assertIsInstance(h.digest(), bytes)<tab><tab><tab>self.assertEqual(hexstr(h.digest()), h.hexdigest())",if h . name in self . shakes :,117
3677,"def _get_cluster_status(self):<tab>try:<tab><tab>return (<tab><tab><tab>self.dataproc_client.projects()<tab><tab><tab>.regions()<tab><tab><tab>.clusters()<tab><tab><tab>.get(<tab><tab><tab><tab>projectId=self.gcloud_project_id,<tab><tab><tab><tab>region=self.dataproc_region,<tab><tab><tab><tab>clusterName=self.dataproc_cluster_name,<tab><tab><tab><tab>fields=""status"",<tab><tab><tab>)<tab><tab><tab>.execute()<tab><tab>)<tab>except HttpError as e:<tab><tab><IF-STMT><tab><tab><tab>return None  # We got a 404 so the cluster doesn't exist<tab><tab>else:<tab><tab><tab>raise e",if e . resp . status == 404 :,175
3678,"def _items_from(self, context):<tab>self._context = context<tab>if self._is_local_variable(self._keyword_name, context):<tab><tab>for item in self._items_from_controller(context):<tab><tab><tab>yield item<tab>else:<tab><tab>for df in context.datafiles:<tab><tab><tab>self._yield_for_other_threads()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for item in self._items_from_datafile(df):<tab><tab><tab><tab><tab>yield item",if self . _items_from_datafile_should_be_checked ( df ) :,135
3679,"def Command(argv, funcs, path_val):<tab>arg, i = COMMAND_SPEC.Parse(argv)<tab>status = 0<tab>if arg.v:<tab><tab>for kind, arg in _ResolveNames(argv[i:], funcs, path_val):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>status = 1  # nothing printed, but we fail<tab><tab><tab>else:<tab><tab><tab><tab># This is for -v, -V is more detailed.<tab><tab><tab><tab>print(arg)<tab>else:<tab><tab>util.warn(""*** command without -v not not implemented ***"")<tab><tab>status = 1<tab>return status",if kind is None :,147
3680,"def delete_doc(elastic_document_id, node, index=None, category=None):<tab>index = index or INDEX<tab>if not category:<tab><tab>if isinstance(node, Preprint):<tab><tab><tab>category = ""preprint""<tab><tab><IF-STMT><tab><tab><tab>category = ""registration""<tab><tab>else:<tab><tab><tab>category = node.project_or_component<tab>client().delete(<tab><tab>index=index,<tab><tab>doc_type=category,<tab><tab>id=elastic_document_id,<tab><tab>refresh=True,<tab><tab>ignore=[404],<tab>)",elif node . is_registration :,143
3681,"def getDictFromTree(tree):<tab>ret_dict = {}<tab>for child in tree.getchildren():<tab><tab><IF-STMT><tab><tab><tab>## Complex-type child. Recurse<tab><tab><tab>content = getDictFromTree(child)<tab><tab>else:<tab><tab><tab>content = child.text<tab><tab>if ret_dict.has_key(child.tag):<tab><tab><tab>if not type(ret_dict[child.tag]) == list:<tab><tab><tab><tab>ret_dict[child.tag] = [ret_dict[child.tag]]<tab><tab><tab>ret_dict[child.tag].append(content or """")<tab><tab>else:<tab><tab><tab>ret_dict[child.tag] = content or """"<tab>return ret_dict",if child . getchildren ( ) :,175
3682,"def get(self, block=True, timeout=None, ack=False):<tab>if not block:<tab><tab>return self.get_nowait()<tab>start_time = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>return self.get_nowait(ack)<tab><tab>except BaseQueue.Empty:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lasted = time.time() - start_time<tab><tab><tab><tab>if timeout > lasted:<tab><tab><tab><tab><tab>time.sleep(min(self.max_timeout, timeout - lasted))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(self.max_timeout)",if timeout :,169
3683,"def rewrite(self, string):<tab>string = super(JSReplaceFuzzy, self).rewrite(string)<tab>cdx = self.url_rewriter.rewrite_opts[""cdx""]<tab>if cdx.get(""is_fuzzy""):<tab><tab>expected = unquote(cdx[""url""])<tab><tab>actual = unquote(self.url_rewriter.wburl.url)<tab><tab>exp_m = self.rx_obj.search(expected)<tab><tab>act_m = self.rx_obj.search(actual)<tab><tab><IF-STMT><tab><tab><tab>result = string.replace(exp_m.group(1), act_m.group(1))<tab><tab><tab>if result != string:<tab><tab><tab><tab>string = result<tab>return string",if exp_m and act_m :,179
3684,"def locate_exe_dir(d, check=True):<tab>exe_dir = os.path.join(d, ""Scripts"") if ON_WINDOWS else os.path.join(d, ""bin"")<tab>if not os.path.isdir(exe_dir):<tab><tab><IF-STMT><tab><tab><tab>bin_dir = os.path.join(d, ""bin"")<tab><tab><tab>if os.path.isdir(bin_dir):<tab><tab><tab><tab>return bin_dir<tab><tab>if check:<tab><tab><tab>raise InvalidVirtualEnv(""Unable to locate executables directory."")<tab>return exe_dir",if ON_WINDOWS :,140
3685,"def _ensuresyspath(self, ensuremode, path):<tab>if ensuremode:<tab><tab>s = str(path)<tab><tab>if ensuremode == ""append"":<tab><tab><tab>if s not in sys.path:<tab><tab><tab><tab>sys.path.append(s)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sys.path.insert(0, s)",if s != sys . path [ 0 ] :,97
3686,"def create_season_banners(self, show_obj):<tab>if self.season_banners and show_obj:<tab><tab>result = []<tab><tab>for season, episodes in show_obj.episodes.iteritems():  # @UnusedVariable<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.log(<tab><tab><tab><tab><tab>u""Metadata provider ""<tab><tab><tab><tab><tab>+ self.name<tab><tab><tab><tab><tab>+ "" creating season banners for ""<tab><tab><tab><tab><tab>+ show_obj.name,<tab><tab><tab><tab><tab>logger.DEBUG,<tab><tab><tab><tab>)<tab><tab><tab><tab>result = result + [self.save_season_banners(show_obj, season)]<tab><tab>return all(result)<tab>return False","if not self . _has_season_banner ( show_obj , season ) :",197
3687,"def validate_nb(self, nb):<tab>super(MetadataValidatorV3, self).validate_nb(nb)<tab>ids = set([])<tab>for cell in nb.cells:<tab><tab>if ""nbgrader"" not in cell.metadata:<tab><tab><tab>continue<tab><tab>grade = cell.metadata[""nbgrader""][""grade""]<tab><tab>solution = cell.metadata[""nbgrader""][""solution""]<tab><tab>locked = cell.metadata[""nbgrader""][""locked""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>grade_id = cell.metadata[""nbgrader""][""grade_id""]<tab><tab>if grade_id in ids:<tab><tab><tab>raise ValidationError(""Duplicate grade id: {}"".format(grade_id))<tab><tab>ids.add(grade_id)",if not grade and not solution and not locked :,186
3688,"def read_version():<tab>regexp = re.compile(r""^__version__\W*=\W*'([\d.abrc]+)'"")<tab>init_py = os.path.join(os.path.dirname(__file__), ""aiopg"", ""__init__.py"")<tab>with open(init_py) as f:<tab><tab>for line in f:<tab><tab><tab>match = regexp.match(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return match.group(1)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""Cannot find version in aiopg/__init__.py"")",if match is not None :,137
3689,"def _column_keys(self):<tab>""""""Get a dictionary of all columns and their case mapping.""""""<tab>if not self.exists:<tab><tab>return {}<tab>with self.db.lock:<tab><tab>if self._columns is None:<tab><tab><tab># Initialise the table if it doesn't exist<tab><tab><tab>table = self.table<tab><tab><tab>self._columns = {}<tab><tab><tab>for column in table.columns:<tab><tab><tab><tab>name = normalize_column_name(column.name)<tab><tab><tab><tab>key = normalize_column_key(name)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>log.warning(""Duplicate column: %s"", name)<tab><tab><tab><tab>self._columns[key] = name<tab><tab>return self._columns",if key in self . _columns :,180
3690,"def find_controller_by_names(self, names, testname):<tab>namestring = ""."".join(names)<tab>if not namestring.startswith(self.name):<tab><tab>return None<tab>if namestring == self.name:<tab><tab>return self<tab>for suite in self.suites:<tab><tab>res = suite.find_controller_by_names(<tab><tab><tab>namestring[len(self.name) + 1 :].split("".""), testname<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return res",if res :,122
3691,"def _volume_x_metadata_get_item(<tab>context, volume_id, key, model, notfound_exec, session=None):<tab>result = (<tab><tab>_volume_x_metadata_get_query(context, volume_id, model, session=session)<tab><tab>.filter_by(key=key)<tab><tab>.first()<tab>)<tab>if not result:<tab><tab><IF-STMT><tab><tab><tab>raise notfound_exec(id=volume_id)<tab><tab>else:<tab><tab><tab>raise notfound_exec(metadata_key=key, volume_id=volume_id)<tab>return result",if model is models . VolumeGlanceMetadata :,155
3692,"def parse_results(cwd):<tab>optimal_dd = None<tab>optimal_measure = numpy.inf<tab>for tup in tools.find_conf_files(cwd):<tab><tab>dd = tup[1]<tab><tab><IF-STMT><tab><tab><tab>if dd[""results.train_y_misclass""] < optimal_measure:<tab><tab><tab><tab>optimal_measure = dd[""results.train_y_misclass""]<tab><tab><tab><tab>optimal_dd = dd<tab>print(""Optimal results.train_y_misclass:"", str(optimal_measure))<tab>for key, value in optimal_dd.items():<tab><tab>if ""hyper_parameters"" in key:<tab><tab><tab>print(key + "": "" + str(value))","if ""results.train_y_misclass"" in dd :",177
3693,"def _stop_by_max_time_mins(self):<tab>""""""Stop optimization process once maximum minutes have elapsed.""""""<tab>if self.max_time_mins:<tab><tab>total_mins_elapsed = (<tab><tab><tab>datetime.now() - self._start_datetime<tab><tab>).total_seconds() / 60.0<tab><tab><IF-STMT><tab><tab><tab>raise KeyboardInterrupt(<tab><tab><tab><tab>""{:.2f} minutes have elapsed. TPOT will close down."".format(<tab><tab><tab><tab><tab>total_mins_elapsed<tab><tab><tab><tab>)<tab><tab><tab>)",if total_mins_elapsed >= self . max_time_mins :,144
3694,"def __new__(meta, cls_name, bases, cls_dict):<tab>func = cls_dict.get(""func"")<tab>monad_cls = super(FuncMonadMeta, meta).__new__(meta, cls_name, bases, cls_dict)<tab>if func:<tab><tab><IF-STMT><tab><tab><tab>functions = func<tab><tab>else:<tab><tab><tab>functions = (func,)<tab><tab>for func in functions:<tab><tab><tab>registered_functions[func] = monad_cls<tab>return monad_cls",if type ( func ) is tuple :,126
3695,"def get_tokens_unprocessed(self, text):<tab>buffered = """"<tab>insertions = []<tab>lng_buffer = []<tab>for i, t, v in self.language_lexer.get_tokens_unprocessed(text):<tab><tab><IF-STMT><tab><tab><tab>if lng_buffer:<tab><tab><tab><tab>insertions.append((len(buffered), lng_buffer))<tab><tab><tab><tab>lng_buffer = []<tab><tab><tab>buffered += v<tab><tab>else:<tab><tab><tab>lng_buffer.append((i, t, v))<tab>if lng_buffer:<tab><tab>insertions.append((len(buffered), lng_buffer))<tab>return do_insertions(insertions, self.root_lexer.get_tokens_unprocessed(buffered))",if t is self . needle :,185
3696,"def get_conditions(filters):<tab>conditions = {""docstatus"": (""="", 1)}<tab>if filters.get(""from_date"") and filters.get(""to_date""):<tab><tab>conditions[""result_date""] = (<tab><tab><tab>""between"",<tab><tab><tab>(filters.get(""from_date""), filters.get(""to_date"")),<tab><tab>)<tab><tab>filters.pop(""from_date"")<tab><tab>filters.pop(""to_date"")<tab>for key, value in filters.items():<tab><tab><IF-STMT><tab><tab><tab>conditions[key] = value<tab>return conditions",if filters . get ( key ) :,140
3697,"def _limit_value(key, value, config):<tab>if config[key].get(""upper_limit""):<tab><tab>limit = config[key][""upper_limit""]<tab><tab># auto handle datetime<tab><tab>if isinstance(value, datetime) and isinstance(limit, timedelta):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if (datetime.now() - limit) > value:<tab><tab><tab><tab><tab>value = datetime.now() - limit<tab><tab><tab>else:<tab><tab><tab><tab>if (datetime.now() + limit) < value:<tab><tab><tab><tab><tab>value = datetime.now() + limit<tab><tab>elif value > limit:<tab><tab><tab>value = limit<tab>return value","if config [ key ] [ ""inverse"" ] is True :",164
3698,"def GetCurrentKeySet(self):<tab>""Return CurrentKeys with 'darwin' modifications.""<tab>result = self.GetKeySet(self.CurrentKeys())<tab>if sys.platform == ""darwin"":<tab><tab># macOS (OS X) Tk variants do not support the ""Alt""<tab><tab># keyboard modifier.  Replace it with ""Option"".<tab><tab># TODO (Ned?): the ""Option"" modifier does not work properly<tab><tab>#<tab> for Cocoa Tk and XQuartz Tk so we should not use it<tab><tab>#<tab> in the default 'OSX' keyset.<tab><tab>for k, v in result.items():<tab><tab><tab>v2 = [x.replace(""<Alt-"", ""<Option-"") for x in v]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[k] = v2<tab>return result",if v != v2 :,200
3699,"def _load_testfile(filename, package, module_relative):<tab>if module_relative:<tab><tab>package = _normalize_module(package, 3)<tab><tab>filename = _module_relative_path(package, filename)<tab><tab>if hasattr(package, ""__loader__""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_contents = package.__loader__.get_data(filename)<tab><tab><tab><tab># get_data() opens files as 'rb', so one must do the equivalent<tab><tab><tab><tab># conversion as universal newlines would do.<tab><tab><tab><tab>return file_contents.replace(os.linesep, ""\n""), filename<tab>return open(filename).read(), filename","if hasattr ( package . __loader__ , ""get_data"" ) :",163
3700,"def iter_from_X_lengths(X, lengths):<tab>if lengths is None:<tab><tab>yield 0, len(X)<tab>else:<tab><tab>n_samples = X.shape[0]<tab><tab>end = np.cumsum(lengths).astype(np.int32)<tab><tab>start = end - lengths<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""more than {:d} samples in lengths array {!s}"".format(<tab><tab><tab><tab><tab>n_samples, lengths<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>for i in range(len(lengths)):<tab><tab><tab>yield start[i], end[i]",if end [ - 1 ] > n_samples :,161
3701,"def change_sel(self):<tab>""""""Change the view's selections.""""""<tab>if self.alter_select and len(self.sels) > 0:<tab><tab><IF-STMT><tab><tab><tab>self.view.show(self.sels[0])<tab><tab>self.view.sel().clear()<tab><tab>self.view.sel().add_all(self.sels)",if self . multi_select is False :,94
3702,"def cb_syncthing_device_data_changed(<tab>self, daemon, nid, address, client_version, inbps, outbps, inbytes, outbytes):<tab>if nid in self.devices:  # Should be always<tab><tab>device = self.devices[nid]<tab><tab># Update strings<tab><tab>device[""address""] = address<tab><tab><IF-STMT><tab><tab><tab>device[""version""] = client_version<tab><tab># Update rates<tab><tab>device[""inbps""] = ""%s/s (%s)"" % (sizeof_fmt(inbps), sizeof_fmt(inbytes))<tab><tab>device[""outbps""] = ""%s/s (%s)"" % (sizeof_fmt(outbps), sizeof_fmt(outbytes))","if client_version not in ( ""?"" , None ) :",184
3703,"def then(self, matches, when_response, context):<tab>if is_iterable(when_response):<tab><tab>ret = []<tab><tab>when_response = list(when_response)<tab><tab>for match in when_response:<tab><tab><tab>if match not in matches:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>match.name = self.match_name<tab><tab><tab><tab>matches.append(match)<tab><tab><tab><tab>ret.append(match)<tab><tab>return ret<tab>if self.match_name:<tab><tab>when_response.name = self.match_name<tab>if when_response not in matches:<tab><tab>matches.append(when_response)<tab><tab>return when_response",if self . match_name :,169
3704,"def __update_parents(self, fileobj, path, delta):<tab>""""""Update all parent atoms with the new size.""""""<tab>if delta == 0:<tab><tab>return<tab>for atom in path:<tab><tab>fileobj.seek(atom.offset)<tab><tab>size = cdata.uint_be(fileobj.read(4))<tab><tab><IF-STMT>  # 64bit<tab><tab><tab># skip name (4B) and read size (8B)<tab><tab><tab>size = cdata.ulonglong_be(fileobj.read(12)[4:])<tab><tab><tab>fileobj.seek(atom.offset + 8)<tab><tab><tab>fileobj.write(cdata.to_ulonglong_be(size + delta))<tab><tab>else:  # 32bit<tab><tab><tab>fileobj.seek(atom.offset)<tab><tab><tab>fileobj.write(cdata.to_uint_be(size + delta))",if size == 1 :,200
3705,"def _fields_to_index(cls):<tab>fields = []<tab>for field in cls._meta.sorted_fields:<tab><tab>if field.primary_key:<tab><tab><tab>continue<tab><tab>requires_index = any(<tab><tab><tab>(field.index, field.unique, isinstance(field, ForeignKeyField))<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>fields.append(field)<tab>return fields",if requires_index :,99
3706,"def __init__(self, value):<tab>""""""Initialize the integer to the given value.""""""<tab>self._mpz_p = new_mpz()<tab>self._initialized = False<tab>if isinstance(value, float):<tab><tab>raise ValueError(""A floating point type is not a natural number"")<tab>self._initialized = True<tab>if isinstance(value, (int, long)):<tab><tab>_gmp.mpz_init(self._mpz_p)<tab><tab>result = _gmp.gmp_sscanf(tobytes(str(value)), b(""%Zd""), self._mpz_p)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Error converting '%d'"" % value)<tab>else:<tab><tab>_gmp.mpz_init_set(self._mpz_p, value._mpz_p)",if result != 1 :,193
3707,"def decode(cls, data):<tab>while data:<tab><tab>length, format_type, control_flags, sequence, pid = unpack(<tab><tab><tab>cls.Header.PACK, data[: cls.Header.LEN]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise NetLinkError(""Buffer underrun"")<tab><tab>yield cls.format(<tab><tab><tab>format_type, control_flags, sequence, pid, data[cls.Header.LEN : length]<tab><tab>)<tab><tab>data = data[length:]",if len ( data ) < length :,125
3708,"def __post_init__(self):<tab>if self._node_id is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""invalid node_id: {}"".format(hexlify(self._node_id).decode())<tab><tab><tab>)<tab>if self.udp_port is not None and not 1 <= self.udp_port <= 65535:<tab><tab>raise ValueError(""invalid udp port"")<tab>if self.tcp_port is not None and not 1 <= self.tcp_port <= 65535:<tab><tab>raise ValueError(""invalid tcp port"")<tab>if not is_valid_public_ipv4(self.address, self.allow_localhost):<tab><tab>raise ValueError(f""invalid ip address: '{self.address}'"")",if not len ( self . _node_id ) == constants . HASH_LENGTH :,185
3709,"def orderUp(self, items):<tab>sel = []  # new selection<tab>undoinfo = []<tab>for bid, lid in items:<tab><tab>if isinstance(lid, int):<tab><tab><tab>undoinfo.append(self.orderUpLineUndo(bid, lid))<tab><tab><tab>sel.append((bid, lid - 1))<tab><tab><IF-STMT><tab><tab><tab>undoinfo.append(self.orderUpBlockUndo(bid))<tab><tab><tab>if bid == 0:<tab><tab><tab><tab>return items<tab><tab><tab>else:<tab><tab><tab><tab>sel.append((bid - 1, None))<tab>self.addUndo(undoinfo, ""Move Up"")<tab>return sel",elif lid is None :,164
3710,"def filter_data(self, min_len, max_len):<tab>logging.info(f""filtering data, min len: {min_len}, max len: {max_len}"")<tab>initial_len = len(self.src)<tab>filtered_src = []<tab>filtered_tgt = []<tab>for src, tgt in zip(self.src, self.tgt):<tab><tab><IF-STMT><tab><tab><tab>filtered_src.append(src)<tab><tab><tab>filtered_tgt.append(tgt)<tab>self.src = filtered_src<tab>self.tgt = filtered_tgt<tab>filtered_len = len(self.src)<tab>logging.info(f""pairs before: {initial_len}, after: {filtered_len}"")",if min_len <= len ( src ) <= max_len and min_len <= len ( tgt ) <= max_len :,193
3711,"def layer_pretrained(self, net, args, options):<tab>model = getattr(torchvision.models, args[0])(pretrained=True)<tab>model.train(True)<tab>if options.layer:<tab><tab>layers = list(model.children())[: options.layer]<tab><tab><IF-STMT><tab><tab><tab>layers[-1] = nn.Sequential(*layers[-1][: options.sublayer])<tab>else:<tab><tab>layers = [model]<tab><tab>print(""List of pretrained layers:"", layers)<tab><tab>raise ValidationException(<tab><tab><tab>""layer=-1 required for pretrained, sublayer=-1 optional.  Layers outputted above.""<tab><tab>)<tab>return nn.Sequential(*layers)",if options . sublayer :,163
3712,"def deleteCalendar(users):<tab>calendarId = normalizeCalendarId(sys.argv[5])<tab>for user in users:<tab><tab>user, cal = buildCalendarGAPIObject(user)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>gapi.call(cal.calendarList(), ""delete"", soft_errors=True, calendarId=calendarId)",if not cal :,84
3713,"def iter_modules(self, by_clients=False, clients_filter=None):<tab>""""""iterate over all modules""""""<tab>clients = None<tab>if by_clients:<tab><tab>clients = self.get_clients(clients_filter)<tab><tab><IF-STMT><tab><tab><tab>return<tab>self._refresh_modules()<tab>for module_name in self.modules:<tab><tab>try:<tab><tab><tab>module = self.get_module(module_name)<tab><tab>except PupyModuleDisabled:<tab><tab><tab>continue<tab><tab>if clients is not None:<tab><tab><tab>for client in clients:<tab><tab><tab><tab>if module.is_compatible_with(client):<tab><tab><tab><tab><tab>yield module<tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield module",if not clients :,181
3714,"def update_me(self):<tab>try:<tab><tab>while 1:<tab><tab><tab>line = self.queue.get_nowait()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.delete(1.0, tk.END)<tab><tab><tab>else:<tab><tab><tab><tab>self.insert(tk.END, str(line))<tab><tab><tab>self.see(tk.END)<tab><tab><tab>self.update_idletasks()<tab>except queue.Empty:<tab><tab>pass<tab>self.after(100, self.update_me)",if line is None :,128
3715,"def request_power_state(self, state, force=False):<tab>if self.current_state != state or force:<tab><tab><IF-STMT><tab><tab><tab>self.request_in_progress = True<tab><tab><tab>logging.info(""Requesting %s"" % state)<tab><tab><tab>cb = PowerManager.Callback(self, state)<tab><tab><tab>rets = self.parent.Plugins.run(<tab><tab><tab><tab>""on_power_state_change_requested"", self, state, cb<tab><tab><tab>)<tab><tab><tab>cb.num_cb = len(rets)<tab><tab><tab>cb.check()<tab><tab>else:<tab><tab><tab>logging.info(""Another request in progress"")",if not self . request_in_progress :,165
3716,"def __getitem__(self, idx):<tab>super(BatchDataset, self).__getitem__(idx)<tab>maxidx = len(self.dataset)<tab>samples = []<tab>for i in range(0, self.batchsize):<tab><tab>j = idx * self.batchsize + i<tab><tab>if j >= maxidx:<tab><tab><tab>break<tab><tab>j = self.perm(j, maxidx)<tab><tab>sample = self.dataset[j]<tab><tab><IF-STMT><tab><tab><tab>samples.append(sample)<tab>samples = self.makebatch(samples)<tab>return samples",if self . filter ( sample ) :,135
3717,"def __call__(self, request, *args, **kwargs):<tab>template_vars = {}<tab>for form_name, form_class in self.forms.iteritems():<tab><tab><IF-STMT><tab><tab><tab>template_vars[form_name] = form_class(request)<tab><tab>else:<tab><tab><tab>template_vars[form_name] = None<tab>if request.method == ""POST"":<tab><tab>action = self.find_post_handler_action(request)<tab><tab>form = self.handlers[action](request, data=request.POST, files=request.FILES)<tab><tab>template_vars.update(form.dispatch(action, request, *args, **kwargs))<tab>return self.GET(template_vars, request, *args, **kwargs)","if form_class . must_display ( request , * args , ** kwargs ) :",191
3718,"def on_show_all(self, widget, another):<tab>if widget.get_active():<tab><tab><IF-STMT><tab><tab><tab>self.treeview.update_items(all=True, comment=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items(all=True)<tab>else:<tab><tab>if another.get_active():<tab><tab><tab>self.treeview.update_items(comment=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items()",if another . get_active ( ) :,121
3719,"def close(self):<tab>if self._closed:<tab><tab>return<tab>self._closed = True<tab>for proto in self._pipes.values():<tab><tab>if proto is None:<tab><tab><tab>continue<tab><tab>proto.pipe.close()<tab>if (<tab><tab>self._proc is not None<tab><tab>and<tab><tab># has the child process finished?<tab><tab>self._returncode is None<tab><tab>and<tab><tab># the child process has finished, but the<tab><tab># transport hasn't been notified yet?<tab><tab>self._proc.poll() is None<tab>):<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""Close running child process: kill %r"", self)<tab><tab>try:<tab><tab><tab>self._proc.kill()<tab><tab>except ProcessLookupError:<tab><tab><tab>pass",if self . _loop . get_debug ( ) :,191
3720,"def runTest(self):<tab>self.poco(text=""wait UI"").click()<tab>bomb_count = 0<tab>while True:<tab><tab>blue_fish = self.poco(""fish_emitter"").child(""blue"")<tab><tab>yellow_fish = self.poco(""fish_emitter"").child(""yellow"")<tab><tab>bomb = self.poco(""fish_emitter"").child(""bomb"")<tab><tab>fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb])<tab><tab>if fish is bomb:<tab><tab><tab>bomb_count += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>fish.click()<tab><tab>time.sleep(2.5)",if bomb_count > 3 :,192
3721,"def load_managers(*, loop, only):<tab>managers = {}<tab>for key in DB_CLASSES:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>params = DB_DEFAULTS.get(key) or {}<tab><tab>params.update(DB_OVERRIDES.get(key) or {})<tab><tab>database = DB_CLASSES[key](**params)<tab><tab>managers[key] = peewee_async.Manager(database, loop=loop)<tab>return managers",if only and key not in only :,112
3722,"def links_extracted(self, request, links):<tab>for link in links:<tab><tab><IF-STMT><tab><tab><tab>r = self._create_request(link.url)<tab><tab><tab>r.meta[b""depth""] = request.meta[b""depth""] + 1<tab><tab><tab>self.schedule(r, self._get_score(r.meta[b""depth""]))<tab><tab><tab>link.meta[b""state""] = States.QUEUED","if link . meta [ b""state"" ] == States . NOT_CRAWLED :",123
3723,"def find_worktree_git_dir(dotgit):<tab>""""""Search for a gitdir for this worktree.""""""<tab>try:<tab><tab>statbuf = os.stat(dotgit)<tab>except OSError:<tab><tab>return None<tab>if not stat.S_ISREG(statbuf.st_mode):<tab><tab>return None<tab>try:<tab><tab>lines = open(dotgit, ""r"").readlines()<tab><tab>for key, value in [line.strip().split("": "") for line in lines]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value<tab>except ValueError:<tab><tab>pass<tab>return None","if key == ""gitdir"" :",147
3724,"def _is_static_shape(self, shape):<tab>if shape is None or not isinstance(shape, list):<tab><tab>return False<tab>for dim_value in shape:<tab><tab>if not isinstance(dim_value, int):<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Negative dimension is illegal: %d"" % dim_value)<tab>return True",if dim_value < 0 :,94
3725,"def init_logger():<tab>configured_loggers = [log_config.get(""root"", {})] + [<tab><tab>logger for logger in log_config.get(""loggers"", {}).values()<tab>]<tab>used_handlers = {<tab><tab>handler for log in configured_loggers for handler in log.get(""handlers"", [])<tab>}<tab>for handler_id, handler in list(log_config[""handlers""].items()):<tab><tab>if handler_id not in used_handlers:<tab><tab><tab>del log_config[""handlers""][handler_id]<tab><tab><IF-STMT><tab><tab><tab>filename = handler[""filename""]<tab><tab><tab>logfile_path = Path(filename).expanduser().resolve()<tab><tab><tab>handler[""filename""] = str(logfile_path)<tab>logging.config.dictConfig(log_config)","elif ""filename"" in handler . keys ( ) :",192
3726,"def __call__(self):<tab>dmin, dmax = self.viewlim_to_dt()<tab>ymin = self.base.le(dmin.year)<tab>ymax = self.base.ge(dmax.year)<tab>ticks = [dmin.replace(year=ymin, **self.replaced)]<tab>while 1:<tab><tab>dt = ticks[-1]<tab><tab><IF-STMT><tab><tab><tab>return date2num(ticks)<tab><tab>year = dt.year + self.base.get_base()<tab><tab>ticks.append(dt.replace(year=year, **self.replaced))",if dt . year >= ymax :,144
3727,"def taiga(request, trigger_id, key):<tab>signature = request.META.get(""HTTP_X_TAIGA_WEBHOOK_SIGNATURE"")<tab># check that the data are ok with the provided signature<tab>if verify_signature(request._request.body, key, signature):<tab><tab>data = data_filter(trigger_id, **request.data)<tab><tab>status = save_data(trigger_id, data)<tab><tab>return (<tab><tab><tab>Response({""message"": ""Success""})<tab><tab><tab><IF-STMT><tab><tab><tab>else Response({""message"": ""Failed!""})<tab><tab>)<tab>Response({""message"": ""Bad request""})",if status,149
3728,"def ParseResponses(<tab>self,<tab>knowledge_base: rdf_client.KnowledgeBase,<tab>responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]:<tab>for response in responses:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(f""Unexpected response type: `{type(response)}`"")<tab><tab># TODO: `st_mode` has to be an `int`, not `StatMode`.<tab><tab>if stat.S_ISDIR(int(response.st_mode)):<tab><tab><tab>homedir = response.pathspec.path<tab><tab><tab>username = os.path.basename(homedir)<tab><tab><tab>if username not in self._ignore_users:<tab><tab><tab><tab>yield rdf_client.User(username=username, homedir=homedir)","if not isinstance ( response , rdf_client_fs . StatEntry ) :",198
3729,"def _iter_lines(path=path, response=response, max_next=options.http_max_next):<tab>path.responses = []<tab>n = 0<tab>while response:<tab><tab>path.responses.append(response)<tab><tab>yield from response.iter_lines(decode_unicode=True)<tab><tab>src = response.links.get(""next"", {}).get(""url"", None)<tab><tab>if not src:<tab><tab><tab>break<tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>vd.warning(f""stopping at max {max_next} pages"")<tab><tab><tab>break<tab><tab>vd.status(f""fetching next page from {src}"")<tab><tab>response = requests.get(src, stream=True)",if n > max_next :,179
3730,"def __enter__(self):<tab>""""""Open a file and read it.""""""<tab>if self.code is None:<tab><tab>LOGGER.info(""File is reading: %s"", self.path)<tab><tab><IF-STMT><tab><tab><tab>self._file = open(self.path, encoding=""utf-8"")<tab><tab>else:<tab><tab><tab>self._file = open(self.path, ""rU"")<tab><tab>self.code = self._file.read()<tab>return self","if sys . version_info >= ( 3 , ) :",117
3731,"def facts_for_oauthclients(self, namespace):<tab>""""""Gathers facts for oauthclients used with logging""""""<tab>self.default_keys_for(""oauthclients"")<tab>a_list = self.oc_command(<tab><tab>""get"", ""oauthclients"", namespace=namespace, add_options=[""-l"", LOGGING_SELECTOR]<tab>)<tab>if len(a_list[""items""]) == 0:<tab><tab>return<tab>for item in a_list[""items""]:<tab><tab>name = item[""metadata""][""name""]<tab><tab>comp = self.comp(name)<tab><tab><IF-STMT><tab><tab><tab>result = dict(redirectURIs=item[""redirectURIs""])<tab><tab><tab>self.add_facts_for(comp, ""oauthclients"", name, result)",if comp is not None :,173
3732,"def get(self, k):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self._data1[k] = self._data2[k]<tab><tab><tab>del self._data2[k]<tab>return self._data1.get(k)",if k not in self . _data1 and k in self . _data2 :,77
3733,"def _parseparam(s):<tab>plist = []<tab>while s[:1] == "";"":<tab><tab>s = s[1:]<tab><tab>end = s.find("";"")<tab><tab>while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2:<tab><tab><tab>end = s.find("";"", end + 1)<tab><tab><IF-STMT><tab><tab><tab>end = len(s)<tab><tab>f = s[:end]<tab><tab>if ""="" in f:<tab><tab><tab>i = f.index(""="")<tab><tab><tab>f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip()<tab><tab>plist.append(f.strip())<tab><tab>s = s[end:]<tab>return plist",if end < 0 :,177
3734,"def __init__(self, **params):<tab>if ""length"" in params:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Supply either length or start and end to Player not both"")<tab><tab>params[""start""] = 0<tab><tab>params[""end""] = params.pop(""length"") - 1<tab>elif params.get(""start"", 0) > 0 and not ""value"" in params:<tab><tab>params[""value""] = params[""start""]<tab>super(Player, self).__init__(**params)","if ""start"" in params or ""end"" in params :",126
3735,"def libcxx_define(settings):<tab>compiler = _base_compiler(settings)<tab>libcxx = settings.get_safe(""compiler.libcxx"")<tab>if not compiler or not libcxx:<tab><tab>return """"<tab>if str(compiler) in GCC_LIKE:<tab><tab>if str(libcxx) == ""libstdc++"":<tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=0""<tab><tab><IF-STMT><tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=1""<tab>return """"","elif str ( libcxx ) == ""libstdc++11"" :",146
3736,"def _get_sort_map(tags):<tab>""""""See TAG_TO_SORT""""""<tab>tts = {}<tab>for name, tag in tags.items():<tab><tab>if tag.has_sort:<tab><tab><tab>if tag.user:<tab><tab><tab><tab>tts[name] = ""%ssort"" % name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tts[""~%s"" % name] = ""~%ssort"" % name<tab>return tts",if tag . internal :,111
3737,"def quiet_f(*args):<tab>vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)}<tab>value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation)<tab>if expect_list:<tab><tab>if value.has_form(""List"", None):<tab><tab><tab>value = [extract_pyreal(item) for item in value.leaves]<tab><tab><tab>if any(item is None for item in value):<tab><tab><tab><tab>return None<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>value = extract_pyreal(value)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return value",if value is None or isinf ( value ) or isnan ( value ) :,177
3738,"def on_action_chosen(self, id, action, mark_changed=True):<tab>before = self.set_action(self.current, id, action)<tab>if mark_changed:<tab><tab><IF-STMT><tab><tab><tab># TODO: Maybe better comparison<tab><tab><tab>self.undo.append(UndoRedo(id, before, action))<tab><tab><tab>self.builder.get_object(""btUndo"").set_sensitive(True)<tab><tab>self.on_profile_modified()<tab>else:<tab><tab>self.on_profile_modified(update_ui=False)<tab>return before",if before . to_string ( ) != action . to_string ( ) :,149
3739,"def setUp(self):<tab>super(OperaterTest, self).setUp()<tab>if is_cli:<tab><tab>import clr<tab><tab>self.load_iron_python_test()<tab><tab><IF-STMT><tab><tab><tab>clr.AddReference(""System.Drawing.Primitives"")<tab><tab>else:<tab><tab><tab>clr.AddReference(""System.Drawing"")",if is_netcoreapp :,93
3740,"def field_to_field_type(field):<tab>field_type = field[""type""]<tab>if isinstance(field_type, dict):<tab><tab>field_type = field_type[""type""]<tab>if isinstance(field_type, list):<tab><tab>field_type_length = len(field_type)<tab><tab>if field_type_length == 0:<tab><tab><tab>raise Exception(""Zero-length type list encountered, invalid CWL?"")<tab><tab><IF-STMT><tab><tab><tab>field_type = field_type[0]<tab>return field_type",elif len ( field_type ) == 1 :,135
3741,"def _flatten(*args):<tab>ahs = set()<tab>if len(args) > 0:<tab><tab>for item in args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ahs.add(item)<tab><tab><tab>elif type(item) in (list, tuple, dict, set):<tab><tab><tab><tab>for ah in item:<tab><tab><tab><tab><tab>if type(ah) is not ActionHandle:  # pragma:nocover<tab><tab><tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(ah))<tab><tab><tab><tab><tab>ahs.add(ah)<tab><tab><tab>else:  # pragma:nocover<tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(item))<tab>return ahs",if type ( item ) is ActionHandle :,183
3742,"def _Determine_Do(self):<tab>self.applicable = 1<tab>configTokens = black.configure.items[""configTokens""].Get()<tab>buildFlavour = black.configure.items[""buildFlavour""].Get()<tab>if buildFlavour == ""full"":<tab><tab>self.value = False<tab>else:<tab><tab>self.value = True<tab>for opt, optarg in self.chosenOptions:<tab><tab><IF-STMT><tab><tab><tab>if not self.value:<tab><tab><tab><tab>configTokens.append(""tests"")<tab><tab><tab>self.value = True<tab><tab>elif opt == ""--without-tests"":<tab><tab><tab>if self.value:<tab><tab><tab><tab>configTokens.append(""notests"")<tab><tab><tab>self.value = False<tab>self.determined = 1","if opt == ""--with-tests"" :",183
3743,"def title_by_index(self, trans, index, context):<tab>d_type = self.get_datatype(trans, context)<tab>for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()):<tab><tab><IF-STMT><tab><tab><tab>rval = composite_name<tab><tab><tab>if composite_file.description:<tab><tab><tab><tab>rval = ""{} ({})"".format(rval, composite_file.description)<tab><tab><tab>if composite_file.optional:<tab><tab><tab><tab>rval = ""%s [optional]"" % rval<tab><tab><tab>return rval<tab>if index < self.get_file_count(trans, context):<tab><tab>return ""Extra primary file""<tab>return None",if i == index :,167
3744,"def func(x, y):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>z = x + 2 * math.sin(y)<tab><tab><tab>return z ** 2<tab><tab>elif x == y:<tab><tab><tab>return 4<tab><tab>else:<tab><tab><tab>return 2 ** 3<tab>except ValueError:<tab><tab>foo = 0<tab><tab>for i in range(4):<tab><tab><tab>foo += i<tab><tab>return foo<tab>except TypeError:<tab><tab>return 42<tab>else:<tab><tab>return 33<tab>finally:<tab><tab>print(""finished"")",if x > y :,134
3745,"def test_suite():<tab>suite = unittest.TestSuite()<tab>for fn in os.listdir(here):<tab><tab><IF-STMT><tab><tab><tab>modname = ""distutils.tests."" + fn[:-3]<tab><tab><tab>__import__(modname)<tab><tab><tab>module = sys.modules[modname]<tab><tab><tab>suite.addTest(module.test_suite())<tab>return suite","if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :",98
3746,"def check_stack_names(self, frame, expected):<tab>names = []<tab>while frame:<tab><tab>name = frame.f_code.co_name<tab><tab># Stop checking frames when we get to our test helper.<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>names.append(name)<tab><tab>frame = frame.f_back<tab>self.assertEqual(names, expected)","if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :",104
3747,"def leave(self, reason=None):<tab>try:<tab><tab>if self.id.startswith(""C""):<tab><tab><tab>log.info(""Leaving channel %s (%s)"", self, self.id)<tab><tab><tab>self._bot.api_call(""conversations.leave"", data={""channel"": self.id})<tab><tab>else:<tab><tab><tab>log.info(""Leaving group %s (%s)"", self, self.id)<tab><tab><tab>self._bot.api_call(""conversations.leave"", data={""channel"": self.id})<tab>except SlackAPIResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>raise RoomError(f""Unable to leave channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)<tab>self._id = None","if e . error == ""user_is_bot"" :",197
3748,"def ident(self):<tab>value = self._ident<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab><IF-STMT><tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>ident = getattr(wrapped, ""ident"", None)<tab><tab><tab>if ident is not None:<tab><tab><tab><tab>value = self._wrap_hash(ident)<tab><tab>self._ident = value<tab>return value",if not self . orig_prefix :,135
3749,"def is_ac_power_connected():<tab>for power_source_path in Path(""/sys/class/power_supply/"").iterdir():<tab><tab>try:<tab><tab><tab>with open(power_source_path / ""type"", ""r"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>with open(power_source_path / ""online"", ""r"") as f:<tab><tab><tab><tab>if f.read(1) == ""1"":<tab><tab><tab><tab><tab>return True<tab><tab>except IOError:<tab><tab><tab>continue<tab>return False","if f . read ( ) . strip ( ) != ""Mains"" :",144
3750,"def _get_pending_by_app_token(self, app_token):<tab>result = []<tab>with self._pending_lock:<tab><tab>self._remove_stale_pending()<tab><tab>for data in self._pending_decisions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(data)<tab>return result",if data . app_token == app_token :,86
3751,"def do_create(specific_tables=None, base=Base):<tab>engine = get_engine()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>logger.info(<tab><tab><tab><tab>""Initializing only a subset of tables as requested: {}"".format(<tab><tab><tab><tab><tab>specific_tables<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>base.metadata.create_all(engine, tables=specific_tables)<tab><tab>else:<tab><tab><tab>base.metadata.create_all(engine)<tab>except Exception as err:<tab><tab>raise Exception(""could not create/re-create DB tables - exception: "" + str(err))",if specific_tables :,152
3752,"def __setitem__(self, ndx, val):<tab>#<tab># Get the expression data object<tab>#<tab>exprdata = None<tab>if ndx in self._data:<tab><tab>exprdata = self._data[ndx]<tab>else:<tab><tab>_ndx = normalize_index(ndx)<tab><tab><IF-STMT><tab><tab><tab>exprdata = self._data[_ndx]<tab>if exprdata is None:<tab><tab>raise KeyError(<tab><tab><tab>""Cannot set the value of Expression '%s' with ""<tab><tab><tab>""invalid index '%s'"" % (self.cname(True), str(ndx))<tab><tab>)<tab>#<tab># Set the value<tab>#<tab>exprdata.set_value(val)",if _ndx in self . _data :,179
3753,"def write(self, *bits):<tab>for bit in bits:<tab><tab><IF-STMT><tab><tab><tab>self.bytestream.append(0)<tab><tab>byte = self.bytestream[self.bytenum]<tab><tab>if self.bitnum == 8:<tab><tab><tab>if self.bytenum == len(self.bytestream) - 1:<tab><tab><tab><tab>byte = 0<tab><tab><tab><tab>self.bytestream += bytes([byte])<tab><tab><tab>self.bytenum += 1<tab><tab><tab>self.bitnum = 0<tab><tab>mask = 2 ** self.bitnum<tab><tab>if bit:<tab><tab><tab>byte |= mask<tab><tab>else:<tab><tab><tab>byte &= ~mask<tab><tab>self.bytestream[self.bytenum] = byte<tab><tab>self.bitnum += 1",if not self . bytestream :,186
3754,"def terminate_subprocess(proc, timeout=0.1, log=None):<tab>if proc.poll() is None:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Sending SIGTERM to %r"", proc)<tab><tab>proc.terminate()<tab><tab>timeout_time = time.time() + timeout<tab><tab>while proc.poll() is None and time.time() < timeout_time:<tab><tab><tab>time.sleep(0.02)<tab><tab>if proc.poll() is None:<tab><tab><tab>if log:<tab><tab><tab><tab>log.info(""Sending SIGKILL to %r"", proc)<tab><tab><tab>proc.kill()<tab>return proc.returncode",if log :,152
3755,"def mkpanel(color, rows, cols, tly, tlx):<tab>win = curses.newwin(rows, cols, tly, tlx)<tab>pan = panel.new_panel(win)<tab>if curses.has_colors():<tab><tab><IF-STMT><tab><tab><tab>fg = curses.COLOR_WHITE<tab><tab>else:<tab><tab><tab>fg = curses.COLOR_BLACK<tab><tab>bg = color<tab><tab>curses.init_pair(color, fg, bg)<tab><tab>win.bkgdset(ord("" ""), curses.color_pair(color))<tab>else:<tab><tab>win.bkgdset(ord("" ""), curses.A_BOLD)<tab>return pan",if color == curses . COLOR_BLUE :,162
3756,"def all_words(filename):<tab>start_char = True<tab>for c in characters(filename):<tab><tab>if start_char == True:<tab><tab><tab>word = """"<tab><tab><tab><IF-STMT><tab><tab><tab><tab># We found the start of a word<tab><tab><tab><tab>word = c.lower()<tab><tab><tab><tab>start_char = False<tab><tab><tab>else:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>if c.isalnum():<tab><tab><tab><tab>word += c.lower()<tab><tab><tab>else:<tab><tab><tab><tab># We found end of word, emit it<tab><tab><tab><tab>start_char = True<tab><tab><tab><tab>yield word",if c . isalnum ( ) :,158
3757,"def get_tf_weights_as_numpy(path=""./ckpt/aeslc/model.ckpt-32000"") -> Dict:<tab>init_vars = tf.train.list_variables(path)<tab>tf_weights = {}<tab>ignore_name = [""Adafactor"", ""global_step""]<tab>for name, shape in tqdm(init_vars, desc=""converting tf checkpoint to dict""):<tab><tab>skip_key = any([pat in name for pat in ignore_name])<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>array = tf.train.load_variable(path, name)<tab><tab>tf_weights[name] = array<tab>return tf_weights",if skip_key :,156
3758,"def app(scope, receive, send):<tab>while True:<tab><tab>message = await receive()<tab><tab>if message[""type""] == ""websocket.connect"":<tab><tab><tab>await send({""type"": ""websocket.accept""})<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif message[""type""] == ""websocket.disconnect"":<tab><tab><tab>break","elif message [ ""type"" ] == ""websocket.receive"" :",93
3759,"def autoload(self):<tab>if self._app.config.THEME == ""auto"":<tab><tab>if sys.platform == ""darwin"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>theme = DARK<tab><tab><tab>else:<tab><tab><tab><tab>theme = LIGHT<tab><tab>else:<tab><tab><tab>theme = self.guess_system_theme()<tab><tab><tab>if theme == Dark:<tab><tab><tab><tab>theme = MacOSDark<tab>else:  # user settings have highest priority<tab><tab>theme = self._app.config.THEME<tab>self.load_theme(theme)",if get_osx_theme ( ) == 1 :,141
3760,"def example_reading_spec(self):<tab>data_fields = {""targets"": tf.VarLenFeature(tf.int64)}<tab><IF-STMT><tab><tab>data_fields[""inputs""] = tf.VarLenFeature(tf.int64)<tab>if self.packed_length:<tab><tab>if self.has_inputs:<tab><tab><tab>data_fields[""inputs_segmentation""] = tf.VarLenFeature(tf.int64)<tab><tab><tab>data_fields[""inputs_position""] = tf.VarLenFeature(tf.int64)<tab><tab>data_fields[""targets_segmentation""] = tf.VarLenFeature(tf.int64)<tab><tab>data_fields[""targets_position""] = tf.VarLenFeature(tf.int64)<tab>data_items_to_decoders = None<tab>return (data_fields, data_items_to_decoders)",if self . has_inputs :,188
3761,"def _prepare_travel_graph(self):<tab>for op in self.op_dict.values():<tab><tab>op.const = False<tab><tab>if op.node.op in [""Const"", ""Placeholder""]:<tab><tab><tab>op.resolved = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>op.const = True<tab><tab>else:<tab><tab><tab>op.resolved = False","if op . node . op == ""Const"" :",96
3762,"def get_filestream_file_items(self):<tab>data = {}<tab>fs_file_updates = self.get_filestream_file_updates()<tab>for k, v in six.iteritems(fs_file_updates):<tab><tab>l = []<tab><tab>for d in v:<tab><tab><tab>offset = d.get(""offset"")<tab><tab><tab>content = d.get(""content"")<tab><tab><tab>assert offset is not None<tab><tab><tab>assert content is not None<tab><tab><tab>assert offset == 0 or offset == len(l), (k, v, l, d)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>l = []<tab><tab><tab>l.extend(map(json.loads, content))<tab><tab>data[k] = l<tab>return data",if not offset :,179
3763,"def _rewrite_exprs(self, table, what):<tab>from ibis.expr.analysis import substitute_parents<tab>what = util.promote_list(what)<tab>all_exprs = []<tab>for expr in what:<tab><tab><IF-STMT><tab><tab><tab>all_exprs.extend(expr.exprs())<tab><tab>else:<tab><tab><tab>bound_expr = ir.bind_expr(table, expr)<tab><tab><tab>all_exprs.append(bound_expr)<tab>return [substitute_parents(x, past_projection=False) for x in all_exprs]","if isinstance ( expr , ir . ExprList ) :",139
3764,"def _group_by_commit_and_time(self, hits):<tab>result = {}<tab>for hit in hits:<tab><tab>source_hit = hit[""_source""]<tab><tab>key = ""%s_%s"" % (source_hit[""commit_info""][""id""], source_hit[""datetime""])<tab><tab>benchmark = self._benchmark_from_es_record(source_hit)<tab><tab><IF-STMT><tab><tab><tab>result[key][""benchmarks""].append(benchmark)<tab><tab>else:<tab><tab><tab>run_info = self._run_info_from_es_record(source_hit)<tab><tab><tab>run_info[""benchmarks""] = [benchmark]<tab><tab><tab>result[key] = run_info<tab>return result",if key in result :,170
3765,"def _build_index(self):<tab>self._index = {}<tab>for start_char, sorted_offsets in self._offsets.items():<tab><tab>self._index[start_char] = {}<tab><tab>for i, offset in enumerate(sorted_offsets.get_offsets()):<tab><tab><tab>identifier = sorted_offsets.get_identifier_by_offset(offset)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._index[start_char][identifier[0 : self.index_depth]] = i",if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,134
3766,"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if ""exp"" in conf[""properties""][""attributes""]:<tab><tab><tab><tab>if conf[""properties""][""attributes""][""exp""]:<tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED","if ""attributes"" in conf [ ""properties"" ] :",82
3767,"def _PatchArtifact(self, artifact: rdf_artifacts.Artifact) -> rdf_artifacts.Artifact:<tab>""""""Patches artifact to not contain byte-string source attributes.""""""<tab>patched = False<tab>for source in artifact.sources:<tab><tab>attributes = source.attributes.ToDict()<tab><tab>unicode_attributes = compatibility.UnicodeJson(attributes)<tab><tab><IF-STMT><tab><tab><tab>source.attributes = unicode_attributes<tab><tab><tab>patched = True<tab>if patched:<tab><tab>self.DeleteArtifact(str(artifact.name))<tab><tab>self.WriteArtifact(artifact)<tab>return artifact",if attributes != unicode_attributes :,139
3768,"def edit_file(self, filename):<tab>import subprocess<tab>editor = self.get_editor()<tab>if self.env:<tab><tab>environ = os.environ.copy()<tab><tab>environ.update(self.env)<tab>else:<tab><tab>environ = None<tab>try:<tab><tab>c = subprocess.Popen('%s ""%s""' % (editor, filename), env=environ, shell=True)<tab><tab>exit_code = c.wait()<tab><tab><IF-STMT><tab><tab><tab>raise ClickException(""%s: Editing failed!"" % editor)<tab>except OSError as e:<tab><tab>raise ClickException(""%s: Editing failed: %s"" % (editor, e))",if exit_code != 0 :,157
3769,"def findControlPointsInMesh(glyph, va, subsegments):<tab>controlPointIndices = np.zeros((len(va), 1))<tab>index = 0<tab>for i, c in enumerate(subsegments):<tab><tab>segmentCount = len(glyph.contours[i].segments) - 1<tab><tab>for j, s in enumerate(c):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if glyph.contours[i].segments[j].type == ""line"":<tab><tab><tab><tab><tab>controlPointIndices[index] = 1<tab><tab><tab>index += s[1]<tab>return controlPointIndices",if j < segmentCount :,143
3770,"def to_representation(self, value):<tab>old_social_string_fields = [""twitter"", ""github"", ""linkedIn""]<tab>request = self.context.get(""request"")<tab>show_old_format = (<tab><tab>request<tab><tab>and is_deprecated(request.version, self.min_version)<tab><tab>and request.method == ""GET""<tab>)<tab>if show_old_format:<tab><tab>social = value.copy()<tab><tab>for key in old_social_string_fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>social[key] = value[key][0]<tab><tab><tab>elif social.get(key) == []:<tab><tab><tab><tab>social[key] = """"<tab><tab>value = social<tab>return super(SocialField, self).to_representation(value)",if social . get ( key ) :,200
3771,"def iter_raw_frames(path, packet_sizes, ctx):<tab>with open(path, ""rb"") as f:<tab><tab>for i, size in enumerate(packet_sizes):<tab><tab><tab>packet = Packet(size)<tab><tab><tab>read_size = f.readinto(packet)<tab><tab><tab>assert size<tab><tab><tab>assert read_size == size<tab><tab><tab>if not read_size:<tab><tab><tab><tab>break<tab><tab><tab>for frame in ctx.decode(packet):<tab><tab><tab><tab>yield frame<tab><tab>while True:<tab><tab><tab>try:<tab><tab><tab><tab>frames = ctx.decode(None)<tab><tab><tab>except EOFError:<tab><tab><tab><tab>break<tab><tab><tab>for frame in frames:<tab><tab><tab><tab>yield frame<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break",if not frames :,189
3772,"def get_shadows_zip(filename):<tab>import zipfile<tab>shadow_pkgs = set()<tab>with zipfile.ZipFile(filename) as lib_zip:<tab><tab>already_test = []<tab><tab>for fname in lib_zip.namelist():<tab><tab><tab>pname, fname = os.path.split(fname)<tab><tab><tab>if fname or (pname and fname):<tab><tab><tab><tab>continue<tab><tab><tab>if pname not in already_test and ""/"" not in pname:<tab><tab><tab><tab>already_test.append(pname)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>shadow_pkgs.add(pname)<tab>return shadow_pkgs",if is_shadowing ( pname ) :,159
3773,"def metrics_to_scalars(self, metrics):<tab>new_metrics = {}<tab>for k, v in metrics.items():<tab><tab>if isinstance(v, torch.Tensor):<tab><tab><tab>v = v.item()<tab><tab><IF-STMT><tab><tab><tab>v = self.metrics_to_scalars(v)<tab><tab>new_metrics[k] = v<tab>return new_metrics","if isinstance ( v , dict ) :",95
3774,"def insert_resets(f):<tab>newsync = dict()<tab>for k, v in f.sync.items():<tab><tab><IF-STMT><tab><tab><tab>newsync[k] = insert_reset(ResetSignal(k), v)<tab><tab>else:<tab><tab><tab>newsync[k] = v<tab>f.sync = newsync",if f . clock_domains [ k ] . rst is not None :,91
3775,"def get_attached_nodes(self, external_account):<tab>for node in self.get_nodes_with_oauth_grants(external_account):<tab><tab>if node is None:<tab><tab><tab>continue<tab><tab>node_settings = node.get_addon(self.oauth_provider.short_name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if node_settings.external_account == external_account:<tab><tab><tab>yield node",if node_settings is None :,110
3776,"def visitIf(self, node, scope):<tab>for test, body in node.tests:<tab><tab>if isinstance(test, ast.Const):<tab><tab><tab>if type(test.value) in self._const_types:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab>self.visit(test, scope)<tab><tab>self.visit(body, scope)<tab>if node.else_:<tab><tab>self.visit(node.else_, scope)",if not test . value :,112
3777,"def flatten(self):<tab># this is similar to fill_messages except it uses a list instead<tab># of a queue to place the messages in.<tab>result = []<tab>channel = await self.messageable._get_channel()<tab>self.channel = channel<tab>while self._get_retrieve():<tab><tab>data = await self._retrieve_messages(self.retrieve)<tab><tab>if len(data) < 100:<tab><tab><tab>self.limit = 0  # terminate the infinite loop<tab><tab><IF-STMT><tab><tab><tab>data = reversed(data)<tab><tab>if self._filter:<tab><tab><tab>data = filter(self._filter, data)<tab><tab>for element in data:<tab><tab><tab>result.append(self.state.create_message(channel=channel, data=element))<tab>return result",if self . reverse :,187
3778,"def compute(self, x, y=None, targets=None):<tab>if targets is None:<tab><tab>targets = self.out_params<tab>in_params = list(self.in_x)<tab>if len(in_params) == 1:<tab><tab>args = [x]<tab>else:<tab><tab>args = list(zip(*x))<tab>if y is None:<tab><tab>pipe = self.pipe<tab>else:<tab><tab>pipe = self.train_pipe<tab><tab><IF-STMT><tab><tab><tab>args.append(y)<tab><tab>else:<tab><tab><tab>args += list(zip(*y))<tab><tab>in_params += self.in_y<tab>return self._compute(*args, pipe=pipe, param_names=in_params, targets=targets)",if len ( self . in_y ) == 1 :,190
3779,"def _import_top_module(self, name):<tab># scan sys.path looking for a location in the filesystem that contains<tab># the module, or an Importer object that can import the module.<tab>for item in sys.path:<tab><tab><IF-STMT><tab><tab><tab>module = self.fs_imp.import_from_dir(item, name)<tab><tab>else:<tab><tab><tab>module = item.import_top(name)<tab><tab>if module:<tab><tab><tab>return module<tab>return None","if isinstance ( item , _StringType ) :",124
3780,"def __getitem__(self, key, _get_mode=False):<tab>if not _get_mode:<tab><tab>if isinstance(key, (int, long)):<tab><tab><tab>return self._list[key]<tab><tab>elif isinstance(key, slice):<tab><tab><tab>return self.__class__(self._list[key])<tab>ikey = key.lower()<tab>for k, v in self._list:<tab><tab><IF-STMT><tab><tab><tab>return v<tab># micro optimization: if we are in get mode we will catch that<tab># exception one stack level down so we can raise a standard<tab># key error instead of our special one.<tab>if _get_mode:<tab><tab>raise KeyError()<tab>raise BadRequestKeyError(key)",if k . lower ( ) == ikey :,176
3781,"def execute(self, arbiter, props):<tab>watcher = self._get_watcher(arbiter, props.pop(""name""))<tab>action = 0<tab>for key, val in props.get(""options"", {}).items():<tab><tab>if key == ""hooks"":<tab><tab><tab>new_action = 0<tab><tab><tab>for name, _val in val.items():<tab><tab><tab><tab>action = watcher.set_opt(""hooks.%s"" % name, _val)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>new_action = 1<tab><tab>else:<tab><tab><tab>new_action = watcher.set_opt(key, val)<tab><tab>if new_action == 1:<tab><tab><tab>action = 1<tab># trigger needed action<tab>return watcher.do_action(action)",if action == 1 :,186
3782,"def OnBodyClick(self, event=None):<tab>try:<tab><tab>c = self.c<tab><tab>p = c.currentPosition()<tab><tab><IF-STMT><tab><tab><tab>self.OnActivateBody(event=event)<tab><tab>g.doHook(""bodyclick2"", c=c, p=p, v=p, event=event)<tab>except:<tab><tab>g.es_event_exception(""bodyclick"")","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",124
3783,"def _class_weights(spec: config.MetricsSpec) -> Optional[Dict[int, float]]:<tab>""""""Returns class weights associated with AggregationOptions at offset.""""""<tab>if spec.aggregate.HasField(""top_k_list""):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""class_weights are not supported when top_k_list used: ""<tab><tab><tab><tab>""spec={}"".format(spec)<tab><tab><tab>)<tab><tab>return None<tab>return dict(spec.aggregate.class_weights) or None",if spec . aggregate . class_weights :,130
3784,"def _is_perf_file(file_path):<tab>f = get_file(file_path)<tab>for line in f:<tab><tab>if line[0] == ""#"":<tab><tab><tab>continue<tab><tab>r = event_regexp.search(line)<tab><tab><IF-STMT><tab><tab><tab>f.close()<tab><tab><tab>return True<tab><tab>f.close()<tab><tab>return False",if r :,92
3785,"def _get_before_insertion_node(self):<tab>if self._nodes_stack.is_empty():<tab><tab>return None<tab>line = self._nodes_stack.parsed_until_line + 1<tab>node = self._new_module.get_last_leaf()<tab>while True:<tab><tab>parent = node.parent<tab><tab><IF-STMT><tab><tab><tab>assert node.end_pos[0] <= line<tab><tab><tab>assert node.end_pos[1] == 0 or ""\n"" in self._prefix<tab><tab><tab>return node<tab><tab>node = parent","if parent . type in ( ""suite"" , ""file_input"" ) :",143
3786,"def PyJsHoisted_parseClassRanges_(this, arguments, var=var):<tab>var = Scope({u""this"": this, u""arguments"": arguments}, var)<tab>var.registers([u""res""])<tab>pass<tab>if var.get(u""current"")(Js(u""]"")):<tab><tab>return Js([])<tab>else:<tab><tab>var.put(u""res"", var.get(u""parseNonemptyClassRanges"")())<tab><tab><IF-STMT><tab><tab><tab>var.get(u""bail"")(Js(u""nonEmptyClassRanges""))<tab><tab>return var.get(u""res"")","if var . get ( u""res"" ) . neg ( ) :",152
3787,"def _recurse_children(self, offset):<tab>""""""Recurses thorugh the available children""""""<tab>while offset < self.obj_offset + self.Length:<tab><tab>item = obj.Object(""VerStruct"", offset=offset, vm=self.obj_vm, parent=self)<tab><tab><IF-STMT><tab><tab><tab>raise StopIteration(<tab><tab><tab><tab>""Could not recover a key for a child at offset {0}"".format(<tab><tab><tab><tab><tab>item.obj_offset<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>yield item.get_key(), item.get_children()<tab><tab>offset = self.offset_pad(offset + item.Length)<tab>raise StopIteration(""No children"")",if item . Length < 1 or item . get_key ( ) == None :,177
3788,"def _adapt_types(self, descr):<tab>names = []<tab>adapted_types = []<tab>for col in descr:<tab><tab>names.append(col[0])<tab><tab>impala_typename = col[1]<tab><tab>typename = udf._impala_to_ibis_type[impala_typename.lower()]<tab><tab><IF-STMT><tab><tab><tab>precision, scale = col[4:6]<tab><tab><tab>adapted_types.append(dt.Decimal(precision, scale))<tab><tab>else:<tab><tab><tab>adapted_types.append(typename)<tab>return names, adapted_types","if typename == ""decimal"" :",144
3789,"def sniff(self, filename):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>with tarfile.open(filename, ""r"") as temptar:<tab><tab><tab><tab>for f in temptar:<tab><tab><tab><tab><tab>if not f.isfile():<tab><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><tab>if f.name.endswith("".fast5""):<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return False<tab>except Exception as e:<tab><tab>log.warning(""%s, sniff Exception: %s"", self, e)<tab>return False",if filename and tarfile . is_tarfile ( filename ) :,149
3790,"def getValue(self):<tab>if getattr(self.object, ""type"", """") != ""CURVE"":<tab><tab>return BezierSpline()<tab>evaluatedObject = getEvaluatedID(self.object)<tab>bSplines = evaluatedObject.data.splines<tab>if len(bSplines) > 0:<tab><tab>spline = createSplineFromBlenderSpline(bSplines[0])<tab><tab># Is None when the spline type is not supported.<tab><tab>if spline is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>spline.transform(evaluatedObject.matrix_world)<tab><tab><tab>return spline<tab>return BezierSpline()",if self . useWorldSpace :,153
3791,"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text","if "">"" in text :",170
3792,"def _get_ilo_version(self):<tab>try:<tab><tab>self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>')<tab>except ResponseError as e:<tab><tab>if hasattr(e, ""code""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 3<tab><tab><tab>if e.code == 501:<tab><tab><tab><tab>return 1<tab><tab>raise<tab>return 2",if e . code == 405 :,113
3793,"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab>if code == Path.MOVETO:<tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab>elif code == Path.CURVE3:<tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab>elif code == Path.CURVE4:<tab><tab><tab>ctx.curve_to(*points)<tab><tab><IF-STMT><tab><tab><tab>ctx.close_path()",elif code == Path . CLOSEPOLY :,172
3794,"def called_by_shrinker():<tab>frame = sys._getframe(0)<tab>while frame:<tab><tab>fname = frame.f_globals.get(""__file__"", """")<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>frame = frame.f_back<tab>return False","if os . path . basename ( fname ) == ""shrinker.py"" :",83
3795,"def _ensuresyspath(self, ensuremode, path):<tab>if ensuremode:<tab><tab>s = str(path)<tab><tab>if ensuremode == ""append"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sys.path.append(s)<tab><tab>else:<tab><tab><tab>if s != sys.path[0]:<tab><tab><tab><tab>sys.path.insert(0, s)",if s not in sys . path :,97
3796,"def get_instances(self, region: str, vpc: str):<tab>try:<tab><tab>await self._cache_instances(region)<tab><tab>return [<tab><tab><tab>instance<tab><tab><tab>for instance in self._instances_cache[region]<tab><tab><tab><IF-STMT><tab><tab>]<tab>except Exception as e:<tab><tab>print_exception(f""Failed to get RDS instances: {e}"")<tab><tab>return []","if instance [ ""VpcId"" ] == vpc",105
3797,def get_and_set_all_disambiguation(self):<tab>all_disambiguations = []<tab>for page in self.pages:<tab><tab>if page.relations.disambiguation_links_norm is not None:<tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links_norm)<tab><tab><IF-STMT><tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links)<tab>return set(all_disambiguations),if page . relations . disambiguation_links is not None :,113
3798,"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.options_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""options%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>return res",if printElemNumber :,119
3799,"def pre_save_task(self, task, credentials, verrors):<tab>if task[""attributes""][""encryption""] not in (None, """", ""AES256""):<tab><tab>verrors.add(""encryption"", 'Encryption should be null or ""AES256""')<tab>if not credentials[""attributes""].get(""skip_region"", False):<tab><tab><IF-STMT><tab><tab><tab>response = await self.middleware.run_in_thread(<tab><tab><tab><tab>self._get_client(credentials).get_bucket_location,<tab><tab><tab><tab>Bucket=task[""attributes""][""bucket""],<tab><tab><tab>)<tab><tab><tab>task[""attributes""][""region""] = response[""LocationConstraint""] or ""us-east-1""","if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :",167
3800,"def get_best_config_reward(self):<tab>""""""Returns the best configuration found so far, as well as the reward associated with this best config.""""""<tab>with self.LOCK:<tab><tab><IF-STMT><tab><tab><tab>config_pkl = max(self._results, key=self._results.get)<tab><tab><tab>return pickle.loads(config_pkl), self._results[config_pkl]<tab><tab>else:<tab><tab><tab>return dict(), self._reward_while_pending()",if self . _results :,112
3801,"def parse_setup_cfg(self):<tab># type: () -> Dict[STRING_TYPE, Any]<tab>if self.setup_cfg is not None and self.setup_cfg.exists():<tab><tab>contents = self.setup_cfg.read_text()<tab><tab>base_dir = self.setup_cfg.absolute().parent.as_posix()<tab><tab>try:<tab><tab><tab>parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix())<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>contents = self.setup_cfg.read_bytes()<tab><tab><tab>parsed = parse_setup_cfg(contents, base_dir)<tab><tab>if not parsed:<tab><tab><tab>return {}<tab><tab>return parsed<tab>return {}",if six . PY2 :,183
3802,"def readall(read_fn, sz):<tab>buff = b""""<tab>have = 0<tab>while have < sz:<tab><tab>chunk = yield from read_fn(sz - have)<tab><tab>have += len(chunk)<tab><tab>buff += chunk<tab><tab><IF-STMT><tab><tab><tab>raise TTransportException(<tab><tab><tab><tab>TTransportException.END_OF_FILE, ""End of file reading from transport""<tab><tab><tab>)<tab>return buff",if len ( chunk ) == 0 :,111
3803,"def _get_use_previous(<tab>f,):  # TODO Sort and group features for DateOffset with two different temporal values<tab>if isinstance(f, AggregationFeature) and f.use_previous is not None:<tab><tab><IF-STMT><tab><tab><tab>return ("""", -1)<tab><tab>else:<tab><tab><tab>unit = list(f.use_previous.times.keys())[0]<tab><tab><tab>value = f.use_previous.times[unit]<tab><tab><tab>return (unit, value)<tab>else:<tab><tab>return ("""", -1)",if len ( f . use_previous . times . keys ( ) ) > 1 :,140
3804,"def istrue(self):<tab>try:<tab><tab>return self._istrue()<tab>except Exception:<tab><tab>self.exc = sys.exc_info()<tab><tab><IF-STMT><tab><tab><tab>msg = [<tab><tab><tab><tab>"" "" * (self.exc[1].offset + 4) + ""^"",<tab><tab><tab>]<tab><tab><tab>msg.append(""SyntaxError: invalid syntax"")<tab><tab>else:<tab><tab><tab>msg = traceback.format_exception_only(*self.exc[:2])<tab><tab>pytest.fail(<tab><tab><tab>""Error evaluating %r expression\n""<tab><tab><tab>""<tab>%s\n""<tab><tab><tab>""%s"" % (self.name, self.expr, ""\n"".join(msg)),<tab><tab><tab>pytrace=False,<tab><tab>)","if isinstance ( self . exc [ 1 ] , SyntaxError ) :",194
3805,"def wait_for_crm_operation(operation, crm):<tab>""""""Poll for cloud resource manager operation until finished.""""""<tab>logger.info(<tab><tab>""wait_for_crm_operation: ""<tab><tab>""Waiting for operation {} to finish..."".format(operation)<tab>)<tab>for _ in range(MAX_POLLS):<tab><tab>result = crm.operations().get(name=operation[""name""]).execute()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(result[""error""])<tab><tab>if ""done"" in result and result[""done""]:<tab><tab><tab>logger.info(""wait_for_crm_operation: Operation done."")<tab><tab><tab>break<tab><tab>time.sleep(POLL_INTERVAL)<tab>return result","if ""error"" in result :",173
3806,"def cb_blob_detail_from_elem_and_buf(self, elem, buf):<tab>if elem.get(""lang"") != buf.lang:  # multi-lang doc<tab><tab>return ""%s Code in %s"" % (elem.get(""lang""), buf.path)<tab>else:<tab><tab>dir, base = os.path.split(buf.path)<tab><tab><IF-STMT><tab><tab><tab>return ""%s (%s)"" % (base, dir)<tab><tab>else:<tab><tab><tab>return base",if dir :,119
3807,"def removedir(self, path):<tab># type: (Text) -> None<tab>_path = self.validatepath(path)<tab>if _path == ""/"":<tab><tab>raise errors.RemoveRootError()<tab>with ftp_errors(self, path):<tab><tab>try:<tab><tab><tab>self.ftp.rmd(_encode(_path, self.ftp.encoding))<tab><tab>except error_perm as error:<tab><tab><tab>code, _ = _parse_ftp_error(error)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.isfile(path):<tab><tab><tab><tab><tab>raise errors.DirectoryExpected(path)<tab><tab><tab><tab>if not self.isempty(path):<tab><tab><tab><tab><tab>raise errors.DirectoryNotEmpty(path)<tab><tab><tab>raise  # pragma: no cover","if code == ""550"" :",189
3808,"def p_clause(self, node, position):<tab>if isinstance(node, Graph):<tab><tab>self.subjectDone(node)<tab><tab><IF-STMT><tab><tab><tab>self.write("" "")<tab><tab>self.write(""{"")<tab><tab>self.depth += 1<tab><tab>serializer = N3Serializer(node, parent=self)<tab><tab>serializer.serialize(self.stream)<tab><tab>self.depth -= 1<tab><tab>self.write(self.indent() + ""}"")<tab><tab>return True<tab>else:<tab><tab>return False",if position is OBJECT :,124
3809,"def get_default_shell_info(shell_name=None, settings=None):<tab>if not shell_name:<tab><tab>settings = settings or load_settings(lazy=True)<tab><tab>shell_name = settings.get(""shell"")<tab><tab>if shell_name:<tab><tab><tab>return shell_name, None<tab><tab>shell_path = os.environ.get(""SHELL"")<tab><tab><IF-STMT><tab><tab><tab>shell_name = basepath(shell_path)<tab><tab>else:<tab><tab><tab>shell_name = DEFAULT_SHELL<tab><tab>return shell_name, shell_path<tab>return shell_name, None",if shell_path :,150
3810,"def GetCategory(self, pidls):<tab>ret = []<tab>for pidl in pidls:<tab><tab># Why don't we just get the size of the PIDL?<tab><tab>val = self.sf.GetDetailsEx(pidl, PKEY_Sample_AreaSize)<tab><tab>val = int(val)  # it probably came in a VT_BSTR variant<tab><tab>if val < 255 // 3:<tab><tab><tab>cid = IDS_SMALL<tab><tab><IF-STMT><tab><tab><tab>cid = IDS_MEDIUM<tab><tab>else:<tab><tab><tab>cid = IDS_LARGE<tab><tab>ret.append(cid)<tab>return ret",elif val < 2 * 255 // 3 :,158
3811,"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab>if item[0]:<tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab>elif item[1]:<tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab>elif item[2]:<tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab><IF-STMT><tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",elif item [ 3 ] :,181
3812,"def add_package_declarations(generated_root_path):<tab>file_names = os.listdir(generated_root_path)<tab>for file_name in file_names:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>full_name = os.path.join(generated_root_path, file_name)<tab><tab>add_package(full_name)","if not file_name . endswith ( "".java"" ) :",93
3813,"def _call_with_retry(out, retry, retry_wait, method, *args, **kwargs):<tab>for counter in range(retry + 1):<tab><tab>try:<tab><tab><tab>return method(*args, **kwargs)<tab><tab>except (<tab><tab><tab>NotFoundException,<tab><tab><tab>ForbiddenException,<tab><tab><tab>AuthenticationException,<tab><tab><tab>RequestErrorException,<tab><tab>):<tab><tab><tab>raise<tab><tab>except ConanException as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>if out:<tab><tab><tab><tab><tab>out.error(exc)<tab><tab><tab><tab><tab>out.info(""Waiting %d seconds to retry..."" % retry_wait)<tab><tab><tab><tab>time.sleep(retry_wait)",if counter == retry :,180
3814,"def to_wburl_str(<tab>url, type=BaseWbUrl.LATEST_REPLAY, mod="""", timestamp="""", end_timestamp=""""):<tab>if WbUrl.is_query_type(type):<tab><tab>tsmod = """"<tab><tab><IF-STMT><tab><tab><tab>tsmod += mod + ""/""<tab><tab>tsmod += timestamp<tab><tab>tsmod += ""*""<tab><tab>tsmod += end_timestamp<tab><tab>tsmod += ""/"" + url<tab><tab>if type == BaseWbUrl.URL_QUERY:<tab><tab><tab>tsmod += ""*""<tab><tab>return tsmod<tab>else:<tab><tab>tsmod = timestamp + mod<tab><tab>if len(tsmod) > 0:<tab><tab><tab>return tsmod + ""/"" + url<tab><tab>else:<tab><tab><tab>return url",if mod :,180
3815,"def _configured_ploidy(items):<tab>ploidies = collections.defaultdict(set)<tab>for data in items:<tab><tab>ploidy = dd.get_ploidy(data)<tab><tab><IF-STMT><tab><tab><tab>for k, v in ploidy.items():<tab><tab><tab><tab>ploidies[k].add(v)<tab><tab>else:<tab><tab><tab>ploidies[""default""].add(ploidy)<tab>out = {}<tab>for k, vs in ploidies.items():<tab><tab>assert len(vs) == 1, ""Multiple ploidies set for group calling: %s %s"" % (<tab><tab><tab>k,<tab><tab><tab>list(vs),<tab><tab>)<tab><tab>out[k] = vs.pop()<tab>return out","if isinstance ( ploidy , dict ) :",187
3816,"def removeUser(self, username):<tab>hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD<tab>if username in self._users:<tab><tab>user = self._users[username]<tab><tab><IF-STMT><tab><tab><tab>if self.isRoomSame(user.room):<tab><tab><tab><tab>hideFromOSD = not constants.SHOW_SAME_ROOM_OSD<tab>if username in self._users:<tab><tab>self._users.pop(username)<tab><tab>message = getMessage(""left-notification"").format(username)<tab><tab>self.ui.showMessage(message, hideFromOSD)<tab><tab>self._client.lastLeftTime = time.time()<tab><tab>self._client.lastLeftUser = username<tab>self.userListChange()",if user . room :,184
3817,"def _thd_cleanup_instance(self):<tab>container_name = self.getContainerName()<tab>instances = self.client.containers(all=1, filters=dict(name=container_name))<tab>for instance in instances:<tab><tab># hyper filtering will match 'hyper12"" if you search for 'hyper1' !<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>self.client.remove_container(instance[""Id""], v=True, force=True)<tab><tab>except NotFound:<tab><tab><tab>pass  # that's a race condition<tab><tab>except docker.errors.APIError as e:<tab><tab><tab>if ""Conflict operation on container"" not in str(e):<tab><tab><tab><tab>raise","if """" . join ( instance [ ""Names"" ] ) . strip ( ""/"" ) != container_name :",182
3818,"def handle_ctcp(self, conn, evt):<tab>args = evt.arguments()<tab>source = evt.source().split(""!"")[0]<tab>if args:<tab><tab>if args[0] == ""VERSION"":<tab><tab><tab>conn.ctcp_reply(source, ""VERSION "" + BOT_VERSION)<tab><tab><IF-STMT><tab><tab><tab>conn.ctcp_reply(source, ""PING"")<tab><tab>elif args[0] == ""CLIENTINFO"":<tab><tab><tab>conn.ctcp_reply(source, ""CLIENTINFO PING VERSION CLIENTINFO"")","elif args [ 0 ] == ""PING"" :",136
3819,"def new_func(self, *args, **kwargs):<tab>obj = self.obj_ref()<tab>attr = self.attr<tab>if obj is not None:<tab><tab>args = tuple(TrackedValue.make(obj, attr, arg) for arg in args)<tab><tab><IF-STMT><tab><tab><tab>kwargs = {<tab><tab><tab><tab>key: TrackedValue.make(obj, attr, value)<tab><tab><tab><tab>for key, value in iteritems(kwargs)<tab><tab><tab>}<tab>result = func(self, *args, **kwargs)<tab>self._changed_()<tab>return result",if kwargs :,138
3820,"def add_doc(target, variables, body_lines):<tab>if isinstance(target, ast.Name):<tab><tab># if it is a variable name add it to the doc<tab><tab>name = target.id<tab><tab><IF-STMT><tab><tab><tab>doc = find_doc_for(target, body_lines)<tab><tab><tab>if doc is not None:<tab><tab><tab><tab>variables[name] = doc<tab>elif isinstance(target, ast.Tuple):<tab><tab># if it is a tuple then iterate the elements<tab><tab># this can happen like this:<tab><tab># a, b = 1, 2<tab><tab>for e in target.elts:<tab><tab><tab>add_doc(e, variables, body_lines)",if name not in variables :,167
3821,"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout):<tab>try:<tab><tab>if tp == ""write"":<tab><tab><tab>out.write(msg)<tab><tab>elif tp == ""flush"":<tab><tab><tab>out.flush()<tab><tab><IF-STMT><tab><tab><tab>out.write(msg)<tab><tab><tab>out.flush()<tab><tab>elif tp == ""print"":<tab><tab><tab>print(msg, file=out)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported type: "" + tp)<tab>except IOError as e:<tab><tab>logger.critical(""{}: {}"".format(type(e).__name__, ucd(e)))<tab><tab>pass","elif tp == ""write_flush"" :",160
3822,"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if os.path.islink(p):<tab><tab><tab>continue<tab><tab>if os.path.isdir(p):<tab><tab><tab>res += get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res",if skip_file ( fname ) :,136
3823,"def _list_outputs(self):<tab>outputs = super(VolSymm, self)._list_outputs()<tab># Have to manually check for the grid files.<tab>if os.path.exists(outputs[""trans_file""]):<tab><tab><IF-STMT><tab><tab><tab>outputs[""output_grid""] = re.sub(<tab><tab><tab><tab>"".(nlxfm|xfm)$"", ""_grid_0.mnc"", outputs[""trans_file""]<tab><tab><tab>)<tab>return outputs","if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :",126
3824,"def _set_texture(self, texture):<tab>if texture.id is not self._texture.id:<tab><tab>self._group = SpriteGroup(<tab><tab><tab>texture, self._group.blend_src, self._group.blend_dest, self._group.parent<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._vertex_list.tex_coords[:] = texture.tex_coords<tab><tab>else:<tab><tab><tab>self._vertex_list.delete()<tab><tab><tab>self._texture = texture<tab><tab><tab>self._create_vertex_list()<tab>else:<tab><tab>self._vertex_list.tex_coords[:] = texture.tex_coords<tab>self._texture = texture",if self . _batch is None :,166
3825,"def got_result(result):<tab>deployment = self.persistence_service.get()<tab>for node in deployment.nodes:<tab><tab><IF-STMT><tab><tab><tab>dataset_ids = [<tab><tab><tab><tab>(m.dataset.deleted, m.dataset.dataset_id)<tab><tab><tab><tab>for m in node.manifestations.values()<tab><tab><tab>]<tab><tab><tab>self.assertIn((True, expected_dataset_id), dataset_ids)<tab><tab><tab>break<tab>else:<tab><tab>self.fail(""Node not found. {}"".format(node.uuid))","if same_node ( node , origin ) :",138
3826,"def check_result(result, func, arguments):<tab>if check_warning(result) and (result.value != ReturnCode.WARN_NODATA):<tab><tab>log.warning(UcanWarning(result, func, arguments))<tab>elif check_error(result):<tab><tab><IF-STMT><tab><tab><tab>raise UcanCmdError(result, func, arguments)<tab><tab>else:<tab><tab><tab>raise UcanError(result, func, arguments)<tab>return result",if check_error_cmd ( result ) :,114
3827,"def _compress_and_sort_bdg_files(out_dir, data):<tab>for fn in glob.glob(os.path.join(out_dir, ""*bdg"")):<tab><tab>out_file = fn + "".gz""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>bedtools = config_utils.get_program(""bedtools"", data)<tab><tab>with file_transaction(out_file) as tx_out_file:<tab><tab><tab>cmd = f""sort -k1,1 -k2,2n {fn} | bgzip -c > {tx_out_file}""<tab><tab><tab>message = f""Compressing and sorting {fn}.""<tab><tab><tab>do.run(cmd, message)",if utils . file_exists ( out_file ) :,176
3828,"def kill_members(members, sig, hosts=nodes):<tab>for member in sorted(members):<tab><tab>try:<tab><tab><tab>if ha_tools_debug:<tab><tab><tab><tab>print(""killing %s"" % member)<tab><tab><tab>proc = hosts[member][""proc""]<tab><tab><tab># Not sure if cygwin makes sense here...<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.kill(proc.pid, signal.CTRL_C_EVENT)<tab><tab><tab>else:<tab><tab><tab><tab>os.kill(proc.pid, sig)<tab><tab>except OSError:<tab><tab><tab>if ha_tools_debug:<tab><tab><tab><tab>print(""%s already dead?"" % member)","if sys . platform in ( ""win32"" , ""cygwin"" ) :",172
3829,"def get_top_level_stats(self):<tab>for func, (cc, nc, tt, ct, callers) in self.stats.items():<tab><tab>self.total_calls += nc<tab><tab>self.prim_calls += cc<tab><tab>self.total_tt += tt<tab><tab><IF-STMT><tab><tab><tab>self.top_level[func] = None<tab><tab>if len(func_std_string(func)) > self.max_name_len:<tab><tab><tab>self.max_name_len = len(func_std_string(func))","if ( ""jprofile"" , 0 , ""profiler"" ) in callers :",141
3830,"def __str__(self):<tab>""""""Only keeps the True values.""""""<tab>result = [""SlicingSpec(""]<tab>if self.entire_dataset:<tab><tab>result.append("" Entire dataset,"")<tab>if self.by_class:<tab><tab>if isinstance(self.by_class, Iterable):<tab><tab><tab>result.append("" Into classes %s,"" % self.by_class)<tab><tab><IF-STMT><tab><tab><tab>result.append("" Up to class %d,"" % self.by_class)<tab><tab>else:<tab><tab><tab>result.append("" By classes,"")<tab>if self.by_percentiles:<tab><tab>result.append("" By percentiles,"")<tab>if self.by_classification_correctness:<tab><tab>result.append("" By classification correctness,"")<tab>result.append("")"")<tab>return ""\n"".join(result)","elif isinstance ( self . by_class , int ) :",197
3831,"def save_params(self):<tab>if self._save_controller:<tab><tab>if not os.path.exists(self._save_controller):<tab><tab><tab>os.makedirs(self._save_controller)<tab><tab>output_dir = self._save_controller<tab>else:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(""./.rlnas_controller"")<tab><tab>output_dir = ""./.rlnas_controller""<tab>with open(os.path.join(output_dir, ""rlnas.params""), ""wb"") as f:<tab><tab>pickle.dump(self._params_dict, f)<tab>_logger.debug(""Save params done"")","if not os . path . exists ( ""./.rlnas_controller"" ) :",166
3832,"def unexport(self, pin):<tab>with self._lock:<tab><tab>self._pin_refs[pin] -= 1<tab><tab><IF-STMT><tab><tab><tab>with io.open(self.path(""unexport""), ""wb"") as f:<tab><tab><tab><tab>f.write(str(pin).encode(""ascii""))",if self . _pin_refs [ pin ] == 0 :,83
3833,"def emit(self, type, info=None):<tab># Overload emit() to send events to the proxy object at the other end<tab>ev = super().emit(type, info)<tab>if self._has_proxy is True and self._session.status > 0:<tab><tab># implicit: and self._disposed is False:<tab><tab>if type in self.__proxy_properties__:<tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])<tab><tab><IF-STMT><tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",elif type in self . __event_types_at_proxy :,161
3834,"def __call__(self, params):<tab>all_errs = {}<tab>for handler in self.handlers:<tab><tab>out_headers, res, errs = handler(params)<tab><tab>all_errs.update(errs)<tab><tab><IF-STMT><tab><tab><tab>return out_headers, res, all_errs<tab>return None, None, all_errs",if res is not None :,84
3835,"def await_test_end(self):<tab>iterations = 0<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>self.log.debug(""Await: iteration limit reached"")<tab><tab><tab>return<tab><tab>status = self.master.get_status()<tab><tab>if status.get(""status"") == ""ENDED"":<tab><tab><tab>return<tab><tab>iterations += 1<tab><tab>time.sleep(1.0)",if iterations > 100 :,100
3836,"def _load(self, path: str):<tab>ds = DataSet()<tab>with open(path, ""r"", encoding=""utf-8"") as f:<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts = line.split(""\t"")<tab><tab><tab><tab>raw_words1 = parts[1]<tab><tab><tab><tab>raw_words2 = parts[2]<tab><tab><tab><tab>target = parts[0]<tab><tab><tab><tab>if raw_words1 and raw_words2 and target:<tab><tab><tab><tab><tab>ds.append(<tab><tab><tab><tab><tab><tab>Instance(<tab><tab><tab><tab><tab><tab><tab>raw_words1=raw_words1, raw_words2=raw_words2, target=target<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>)<tab>return ds",if line :,200
3837,"def avatar_delete(event_id, speaker_id):<tab>if request.method == ""DELETE"":<tab><tab>speaker = (<tab><tab><tab>DataGetter.get_speakers(event_id)<tab><tab><tab>.filter_by(user_id=login.current_user.id, id=speaker_id)<tab><tab><tab>.first()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>speaker.photo = """"<tab><tab><tab>speaker.small = """"<tab><tab><tab>speaker.thumbnail = """"<tab><tab><tab>speaker.icon = """"<tab><tab><tab>save_to_db(speaker)<tab><tab><tab>return jsonify({""status"": ""ok""})<tab><tab>else:<tab><tab><tab>abort(403)",if speaker :,162
3838,"def getline(filename, lineno, *args, **kwargs):<tab>line = py2exe_getline(filename, lineno, *args, **kwargs)<tab>if not line:<tab><tab>try:<tab><tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab><tab>for i, line in enumerate(f):<tab><tab><tab><tab><tab>line = line.decode(""utf-8"")<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>line = """"<tab><tab>except (IOError, OSError):<tab><tab><tab>line = """"<tab>return line",if lineno == i + 1 :,149
3839,"def write(self, data):<tab>if not isinstance(data, (bytes, bytearray, memoryview)):<tab><tab>raise TypeError(""data argument must be byte-ish (%r)"", type(data))<tab>if not data:<tab><tab>return<tab>if self._conn_lost:<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""socket.send() raised exception."")<tab><tab>self._conn_lost += 1<tab><tab>return<tab>if not self._buffer:<tab><tab>self._loop.add_writer(self._sock_fd, self._write_ready)<tab># Add it to the buffer.<tab>self._buffer.extend(data)<tab>self._maybe_pause_protocol()",if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,179
3840,"def _get_x_for_y(self, xValue, x, y):<tab># print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y)<tab>if not self.xmlMap:<tab><tab>return 0<tab>x_value = str(xValue)<tab>for anime in self.xmlMap.findall(""anime""):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(anime.get(y, 0))<tab><tab>except ValueError as e:<tab><tab><tab>continue<tab>return 0","if anime . get ( x , False ) == x_value :",145
3841,"def _RewriteModinfo(<tab>self,<tab>modinfo,<tab>obj_kernel_version,<tab>this_kernel_version,<tab>info_strings=None,<tab>to_remove=None,):<tab>new_modinfo = """"<tab>for line in modinfo.split(""\x00""):<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>if to_remove and line.split(""="")[0] == to_remove:<tab><tab><tab>continue<tab><tab>if info_strings is not None:<tab><tab><tab>info_strings.add(line.split(""="")[0])<tab><tab><IF-STMT><tab><tab><tab>line = line.replace(obj_kernel_version, this_kernel_version)<tab><tab>new_modinfo += line + ""\x00""<tab>return new_modinfo","if line . startswith ( ""vermagic"" ) :",187
3842,"def _score(self, X, y):<tab>for col in self.cols:<tab><tab># Score the column<tab><tab>X[col] = X[col].map(self.mapping[col])<tab><tab># Randomization is meaningful only for training data -> we do it only if y is present<tab><tab><IF-STMT><tab><tab><tab>random_state_generator = check_random_state(self.random_state)<tab><tab><tab>X[col] = X[col] * random_state_generator.normal(<tab><tab><tab><tab>1.0, self.sigma, X[col].shape[0]<tab><tab><tab>)<tab>return X",if self . randomized and y is not None :,155
3843,"def onMouseWheel(self, event):<tab>if self.selectedHuman.isVisible():<tab><tab>zoomOut = event.wheelDelta > 0<tab><tab><IF-STMT><tab><tab><tab>zoomOut = not zoomOut<tab><tab>if event.x is not None:<tab><tab><tab>self.modelCamera.mousePickHumanCenter(event.x, event.y)<tab><tab>if zoomOut:<tab><tab><tab>self.zoomOut()<tab><tab>else:<tab><tab><tab>self.zoomIn()","if self . getSetting ( ""invertMouseWheel"" ) :",121
3844,"def prehook(self, emu, op, eip):<tab>if op in self.badops:<tab><tab>emu.stopEmu()<tab><tab>raise v_exc.BadOpBytes(op.va)<tab>if op.mnem in STOS:<tab><tab>if self.arch == ""i386"":<tab><tab><tab>reg = emu.getRegister(envi.archs.i386.REG_EDI)<tab><tab><IF-STMT><tab><tab><tab>reg = emu.getRegister(envi.archs.amd64.REG_RDI)<tab><tab>if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None:<tab><tab><tab>self.vw.makePointer(reg, follow=True)","elif self . arch == ""amd64"" :",186
3845,"def callback(actions, form, tablename=None):<tab>if actions:<tab><tab>if tablename and isinstance(actions, dict):<tab><tab><tab>actions = actions.get(tablename, [])<tab><tab><IF-STMT><tab><tab><tab>actions = [actions]<tab><tab>[action(form) for action in actions]","if not isinstance ( actions , ( list , tuple ) ) :",80
3846,"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None):<tab>result = []<tab>for i in range(10):<tab><tab># This line introduces a bug.<tab><tab>if bigger_than_3_only and less_than_7_only and i == 4:<tab><tab><tab>continue<tab><tab>if bigger_than_3_only and i <= 3:<tab><tab><tab>continue<tab><tab>if less_than_7_only and i >= 7:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>result.append(i)<tab>return result",if even_only and i % 2 != 0 :,158
3847,"def set_trial_values(self, trial_id: int, values: Sequence[float]) -> None:<tab>with self._lock:<tab><tab>cached_trial = self._get_cached_trial(trial_id)<tab><tab><IF-STMT><tab><tab><tab>self._check_trial_is_updatable(cached_trial)<tab><tab><tab>updates = self._get_updates(trial_id)<tab><tab><tab>cached_trial.values = values<tab><tab><tab>updates.values = values<tab><tab><tab>return<tab>self._backend._update_trial(trial_id, values=values)",if cached_trial is not None :,141
3848,"def _get_label_format(self, workunit):<tab>for label, label_format in self.LABEL_FORMATTING.items():<tab><tab>if workunit.has_label(label):<tab><tab><tab>return label_format<tab># Recursively look for a setting to suppress child label formatting.<tab>if workunit.parent:<tab><tab>label_format = self._get_label_format(workunit.parent)<tab><tab>if label_format == LabelFormat.CHILD_DOT:<tab><tab><tab>return LabelFormat.DOT<tab><tab><IF-STMT><tab><tab><tab>return LabelFormat.SUPPRESS<tab>return LabelFormat.FULL",if label_format == LabelFormat . CHILD_SUPPRESS :,151
3849,"def open_session(self, app, request):<tab>sid = request.cookies.get(app.session_cookie_name)<tab>if sid:<tab><tab>stored_session = self.cls.objects(sid=sid).first()<tab><tab>if stored_session:<tab><tab><tab>expiration = stored_session.expiration<tab><tab><tab>if not expiration.tzinfo:<tab><tab><tab><tab>expiration = expiration.replace(tzinfo=utc)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return MongoEngineSession(<tab><tab><tab><tab><tab>initial=stored_session.data, sid=stored_session.sid<tab><tab><tab><tab>)<tab>return MongoEngineSession(sid=str(uuid.uuid4()))",if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,174
3850,"def _manage_torrent_cache(self):<tab>""""""Carry tracker/peer/file lists over to new torrent list""""""<tab>for torrent in self._torrent_cache:<tab><tab>new_torrent = rtorrentlib.common.find_torrent(torrent.info_hash, self.torrents)<tab><tab><IF-STMT><tab><tab><tab>new_torrent.files = torrent.files<tab><tab><tab>new_torrent.peers = torrent.peers<tab><tab><tab>new_torrent.trackers = torrent.trackers<tab>self._torrent_cache = self.torrents",if new_torrent is not None :,142
3851,"def _clean_regions(items, region):<tab>""""""Intersect region with target file if it exists""""""<tab>variant_regions = bedutils.population_variant_regions(items, merged=True)<tab>with utils.tmpfile() as tx_out_file:<tab><tab>target = subset_variant_regions(variant_regions, region, tx_out_file, items)<tab><tab>if target:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>target = _load_regions(target)<tab><tab><tab>else:<tab><tab><tab><tab>target = [target]<tab><tab><tab>return target","if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :",151
3852,def _get_stdout(self):<tab>while True:<tab><tab>BUFFER_SIZE = 1000<tab><tab>stdout_buffer = self.kernel.process.GetSTDOUT(BUFFER_SIZE)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>yield stdout_buffer,if len ( stdout_buffer ) == 0 :,67
3853,"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab>if len(q) == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(value)<tab><tab><tab>elif is_iterable(value):<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab>if not is_iterable(value):<tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",if key == qkey :,185
3854,"def test_expect_setecho_off(self):<tab>""""""This tests that echo may be toggled off.""""""<tab>p = pexpect.spawn(""cat"", echo=True, timeout=5)<tab>try:<tab><tab>self._expect_echo_toggle(p)<tab>except IOError:<tab><tab><IF-STMT><tab><tab><tab>if hasattr(unittest, ""SkipTest""):<tab><tab><tab><tab>raise unittest.SkipTest(""Not supported on this platform."")<tab><tab><tab>return ""skip""<tab><tab>raise","if sys . platform . lower ( ) . startswith ( ""sunos"" ) :",123
3855,"def _resolve_relative_config(dir, config):<tab># Some code shared between Notebook and NotebookInfo<tab># Resolve icon, can be relative<tab>icon = config.get(""icon"")<tab>if icon:<tab><tab><IF-STMT><tab><tab><tab>icon = File(icon)<tab><tab>else:<tab><tab><tab>icon = dir.resolve_file(icon)<tab># Resolve document_root, can also be relative<tab>document_root = config.get(""document_root"")<tab>if document_root:<tab><tab>if zim.fs.isabs(document_root) or not dir:<tab><tab><tab>document_root = Dir(document_root)<tab><tab>else:<tab><tab><tab>document_root = dir.resolve_dir(document_root)<tab>return icon, document_root",if zim . fs . isabs ( icon ) or not dir :,191
3856,"def _providers(self, descriptor):<tab>res = []<tab>for _md in self.metadata.values():<tab><tab>for ent_id, ent_desc in _md.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ent_id in res:<tab><tab><tab><tab><tab># print(""duplicated entity_id: %s"" % res)<tab><tab><tab><tab><tab>pass<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>res.append(ent_id)<tab>return res",if descriptor in ent_desc :,118
3857,"def poll_ms(self, timeout=-1):<tab>s = bytearray(self.evbuf)<tab>if timeout >= 0:<tab><tab>deadline = utime.ticks_add(utime.ticks_ms(), timeout)<tab>while True:<tab><tab>n = epoll_wait(self.epfd, s, 1, timeout)<tab><tab>if not os.check_error(n):<tab><tab><tab>break<tab><tab>if timeout >= 0:<tab><tab><tab>timeout = utime.ticks_diff(deadline, utime.ticks_ms())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n = 0<tab><tab><tab><tab>break<tab>res = []<tab>if n > 0:<tab><tab>vals = struct.unpack(epoll_event, s)<tab><tab>res.append((vals[1], vals[0]))<tab>return res",if timeout < 0 :,192
3858,"def banned():<tab>if request.endpoint == ""views.themes"":<tab><tab>return<tab>if authed():<tab><tab>user = get_current_user_attrs()<tab><tab>team = get_current_team_attrs()<tab><tab>if user and user.banned:<tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"", error=""You have been banned from this CTF""<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"",<tab><tab><tab><tab><tab>error=""Your team has been banned from this CTF"",<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)",if team and team . banned :,193
3859,"def _update_read(self):<tab>""""""Update state when there is read event""""""<tab>try:<tab><tab>msg = bytes(self._sock.recv(4096))<tab><tab>if msg:<tab><tab><tab>self.on_message(msg)<tab><tab><tab>return True<tab><tab># normal close, remote is closed<tab><tab>self.close()<tab>except socket.error as err:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.on_error(err)<tab>return False","if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",142
3860,"def update_topic_attr_as_not(modeladmin, request, queryset, attr):<tab>for topic in queryset:<tab><tab>if attr == ""sticky"":<tab><tab><tab>topic.sticky = not topic.sticky<tab><tab>elif attr == ""closed"":<tab><tab><tab>topic.closed = not topic.closed<tab><tab><IF-STMT><tab><tab><tab>topic.hidden = not topic.hidden<tab><tab>topic.save()","elif attr == ""hidden"" :",97
3861,"def Startprobe(self, q):<tab>while not self.finished:<tab><tab>try:<tab><tab><tab>sniff(iface=self.interface, count=10, prn=lambda x: q.put(x))<tab><tab>except:<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>break",if self . finished :,73
3862,"def _maybe_female(self, path_elements, female, strict):<tab>if female:<tab><tab><IF-STMT><tab><tab><tab>elements = path_elements + [""female""]<tab><tab><tab>try:<tab><tab><tab><tab>return self._get_file(elements, "".png"", strict=strict)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>if strict:<tab><tab><tab><tab><tab>raise<tab><tab>elif strict:<tab><tab><tab>raise ValueError(""Pokemon %s has no gender differences"" % self.species_id)<tab>return self._get_file(path_elements, "".png"", strict=strict)",if self . has_gender_differences :,146
3863,"def change_args_to_dict(string):<tab>if string is None:<tab><tab>return None<tab>ans = []<tab>strings = string.split(""\n"")<tab>ind = 1<tab>start = 0<tab>while ind <= len(strings):<tab><tab><IF-STMT><tab><tab><tab>ind += 1<tab><tab>else:<tab><tab><tab>if start < ind:<tab><tab><tab><tab>ans.append(""\n"".join(strings[start:ind]))<tab><tab><tab>start = ind<tab><tab><tab>ind += 1<tab>d = {}<tab>for line in ans:<tab><tab>if "":"" in line and len(line) > 0:<tab><tab><tab>lines = line.split("":"")<tab><tab><tab>d[lines[0]] = lines[1].strip()<tab>return d","if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :",188
3864,"def _send_with_auth(self, req_kwargs, desired_auth, rsession):<tab>if desired_auth.oauth:<tab><tab><IF-STMT><tab><tab><tab>self._oauth_creds.refresh(httplib2.Http())<tab><tab>req_kwargs[""headers""] = req_kwargs.get(""headers"", {})<tab><tab>req_kwargs[""headers""][""Authorization""] = (<tab><tab><tab>""Bearer "" + self._oauth_creds.access_token<tab><tab>)<tab>return rsession.request(**req_kwargs)",if self . _oauth_creds . access_token_expired :,130
3865,"def parse_search_response(json_data):<tab>""""""Construct response for any input""""""<tab>if json_data is None:<tab><tab>return {""error"": ""Error parsing empty search engine response""}<tab>try:<tab><tab>return json.loads(json_data)<tab>except json.JSONDecodeError:<tab><tab>logger.exception(""Error parsing search engine response"")<tab><tab>m = re_pre.search(json_data)<tab><tab><IF-STMT><tab><tab><tab>return {""error"": ""Error parsing search engine response""}<tab><tab>error = web.htmlunquote(m.group(1))<tab><tab>solr_error = ""org.apache.lucene.queryParser.ParseException: ""<tab><tab>if error.startswith(solr_error):<tab><tab><tab>error = error[len(solr_error) :]<tab><tab>return {""error"": error}",if m is None :,198
3866,"def wrapper(*args, **kws):<tab>missing = []<tab>saved = getattr(warnings, ""__warningregistry__"", missing).copy()<tab>try:<tab><tab>return func(*args, **kws)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>del warnings.__warningregistry__<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>warnings.__warningregistry__ = saved",if saved is missing :,100
3867,"def parse_expression(self):<tab>""""""Return string containing command to run.""""""<tab>expression_el = self.root.find(""expression"")<tab>if expression_el is not None:<tab><tab>expression_type = expression_el.get(""type"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Unknown expression type [%s] encountered"" % expression_type<tab><tab><tab>)<tab><tab>return expression_el.text<tab>return None","if expression_type != ""ecma5.1"" :",115
3868,"def test_geocode():<tab># look for tweets from New York ; the search radius is larger than NYC<tab># so hopefully we'll find one from New York in the first 500?<tab>count = 0<tab>found = False<tab>for tweet in T.search(None, geocode=""40.7484,-73.9857,1mi""):<tab><tab><IF-STMT><tab><tab><tab>found = True<tab><tab><tab>break<tab><tab>if count > 500:<tab><tab><tab>break<tab><tab>count += 1<tab>assert found","if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :",138
3869,"def __init__(self, name: Optional[str] = None, order: int = 0):<tab>if name is None:<tab><tab><IF-STMT><tab><tab><tab>name = ""std_dev""<tab><tab>elif order == 1:<tab><tab><tab>name = ""sample_std_dev""<tab><tab>else:<tab><tab><tab>name = f""std_dev{order})""<tab>super().__init__(name=name, order=order)<tab>self.order = order",if order == 0 :,109
3870,"def __cmp__(self, other):<tab>if isinstance(other, date) or isinstance(other, datetime):<tab><tab>a = self._d.getTime()<tab><tab>b = other._d.getTime()<tab><tab><IF-STMT><tab><tab><tab>return -1<tab><tab>elif a == b:<tab><tab><tab>return 0<tab>else:<tab><tab>raise TypeError(""expected date or datetime object"")<tab>return 1",if a < b :,98
3871,"def run(self):<tab>tid = self.ident<tab>try:<tab><tab>with self._lock:<tab><tab><tab>_GUIS[tid] = self<tab><tab><tab>self._state(True)<tab><tab>self.new_mail_notifications(summarize=True)<tab><tab>loop_count = 0<tab><tab>while self._sock:<tab><tab><tab>loop_count += 1<tab><tab><tab>self._select_sleep(1)  # FIXME: Lengthen this when possible<tab><tab><tab>self.change_state()<tab><tab><tab><IF-STMT><tab><tab><tab><tab># FIXME: This involves a fair number of set operations,<tab><tab><tab><tab>#<tab><tab>should only do this after new mail has arrived.<tab><tab><tab><tab>self.new_mail_notifications()<tab>finally:<tab><tab>del _GUIS[tid]",if loop_count % 5 == 0 :,200
3872,"def __cache_dimension_masks(self, *args):<tab># cache masks for each feature map we'll need<tab>if len(self.masks) == 0:<tab><tab>for m1 in args:<tab><tab><tab>batch_size, emb_dim, h, w = m1.size()<tab><tab><tab># make mask<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mask = self.feat_size_w_mask(h, m1)<tab><tab><tab><tab>self.masks[h] = mask",if h not in self . masks :,122
3873,"def __call__(self, *flattened_representation):<tab>unflattened_representation = []<tab>for index, subtree in self.children:<tab><tab><IF-STMT><tab><tab><tab>unflattened_representation.append(flattened_representation[index])<tab><tab>else:<tab><tab><tab>sub_representation = flattened_representation[index]<tab><tab><tab>unflattened_representation.append(subtree(*sub_representation))<tab>return self._cls(*unflattened_representation, **self._kwargs)",if subtree is None :,109
3874,"def click_outside(event):<tab>if event not in d:<tab><tab>x, y, z = self.blockFaceUnderCursor[0]<tab><tab>if y == 0:<tab><tab><tab>y = 64<tab><tab>y += 3<tab><tab>gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z<tab><tab><IF-STMT><tab><tab><tab>d.dismiss(""Goto"")",if event . num_clicks == 2 :,100
3875,"def get_mapped_input_keysequences(self, mode=""global"", prefix=u""""):<tab># get all bindings in this mode<tab>globalmaps, modemaps = self.get_keybindings(mode)<tab>candidates = list(globalmaps.keys()) + list(modemaps.keys())<tab>if prefix is not None:<tab><tab>prefixes = prefix + "" ""<tab><tab>cand = [c for c in candidates if c.startswith(prefixes)]<tab><tab><IF-STMT><tab><tab><tab>candidates = cand + [prefix]<tab><tab>else:<tab><tab><tab>candidates = cand<tab>return candidates",if prefix in candidates :,136
3876,"def _set_length(self, length):<tab>with self._cond:<tab><tab>self._length = length<tab><tab><IF-STMT><tab><tab><tab>self._ready = True<tab><tab><tab>self._cond.notify()<tab><tab><tab>del self._cache[self._job]",if self . _index == self . _length :,70
3877,"def _pct_encoded_replace_unreserved(mo):<tab>try:<tab><tab>i = int(mo.group(1), 16)<tab><tab><IF-STMT><tab><tab><tab>return chr(i)<tab><tab>else:<tab><tab><tab>return mo.group().upper()<tab>except ValueError:<tab><tab>return mo.group()",if _unreserved [ i ] :,81
3878,"def is_open(self):<tab>if self.signup_code:<tab><tab>return True<tab>else:<tab><tab>if self.signup_code_present:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>messages.add_message(<tab><tab><tab><tab><tab>self.request,<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""level""],<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""text""].format(<tab><tab><tab><tab><tab><tab>**{<tab><tab><tab><tab><tab><tab><tab>""code"": self.get_code(),<tab><tab><tab><tab><tab><tab>}<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>)<tab>return settings.ACCOUNT_OPEN_SIGNUP","if self . messages . get ( ""invalid_signup_code"" ) :",172
3879,"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>field_value = member[1]<tab><tab><tab>elif member[0] == ""wildcards"":<tab><tab><tab><tab>wildcards = member[1]<tab><tab>if key == ""nw_src"":<tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab>elif key == ""nw_dst"":<tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value",if member [ 0 ] == key :,200
3880,"def move_sender_strings_to_sender_model(apps, schema_editor):<tab>sender_model = apps.get_model(""documents"", ""Sender"")<tab>document_model = apps.get_model(""documents"", ""Document"")<tab># Create the sender and log the relationship with the document<tab>for document in document_model.objects.all():<tab><tab><IF-STMT><tab><tab><tab>(<tab><tab><tab><tab>DOCUMENT_SENDER_MAP[document.pk],<tab><tab><tab><tab>created,<tab><tab><tab>) = sender_model.objects.get_or_create(<tab><tab><tab><tab>name=document.sender, defaults={""slug"": slugify(document.sender)}<tab><tab><tab>)",if document . sender :,160
3881,"def compute_output_shape(self, input_shape):<tab>if None not in input_shape[1:]:<tab><tab><IF-STMT><tab><tab><tab>total = np.prod(input_shape[2:4]) * self.num_anchors<tab><tab>else:<tab><tab><tab>total = np.prod(input_shape[1:3]) * self.num_anchors<tab><tab>return (input_shape[0], total, 4)<tab>else:<tab><tab>return (input_shape[0], None, 4)","if keras . backend . image_data_format ( ) == ""channels_first"" :",135
3882,"def decompress(self, value):<tab>if value:<tab><tab>if type(value) == PhoneNumber:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return [<tab><tab><tab><tab><tab>""+%d"" % value.country_code,<tab><tab><tab><tab><tab>national_significant_number(value),<tab><tab><tab><tab>]<tab><tab>else:<tab><tab><tab>return value.split(""."")<tab>return [None, """"]",if value . country_code and value . national_number :,111
3883,"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab><IF-STMT><tab><tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab><tab>if self.expr is not None:<tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",if other not in self . ignoreExprs :,129
3884,"def mkdir(self, mode=0o777, parents=False, exist_ok=False):<tab>if self._closed:<tab><tab>self._raise_closed()<tab>if not parents:<tab><tab>try:<tab><tab><tab>self._accessor.mkdir(self, mode)<tab><tab>except FileExistsError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab>else:<tab><tab>try:<tab><tab><tab>self._accessor.mkdir(self, mode)<tab><tab>except FileExistsError:<tab><tab><tab>if not exist_ok or not self.is_dir():<tab><tab><tab><tab>raise<tab><tab>except OSError as e:<tab><tab><tab>if e.errno != ENOENT:<tab><tab><tab><tab>raise<tab><tab><tab>self.parent.mkdir(parents=True)<tab><tab><tab>self._accessor.mkdir(self, mode)",if not exist_ok or not self . is_dir ( ) :,199
3885,"def _mark_lcs(mask, dirs, m, n):<tab>while m != 0 and n != 0:<tab><tab>if dirs[m, n] == ""|"":<tab><tab><tab>m -= 1<tab><tab><tab>n -= 1<tab><tab><tab>mask[m] = 1<tab><tab>elif dirs[m, n] == ""^"":<tab><tab><tab>m -= 1<tab><tab><IF-STMT><tab><tab><tab>n -= 1<tab><tab>else:<tab><tab><tab>raise UnboundLocalError(""Illegal move"")<tab>return mask","elif dirs [ m , n ] == ""<"" :",122
3886,"def clean(self, *args, **kwargs):<tab>data = super().clean(*args, **kwargs)<tab>if isinstance(data, File):<tab><tab>filename = data.name<tab><tab>ext = os.path.splitext(filename)[1]<tab><tab>ext = ext.lower()<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(_(""Filetype not allowed!""))<tab>return data",if ext not in self . ext_whitelist :,97
3887,"def get_doc_object(obj, what=None):<tab>if what is None:<tab><tab>if inspect.isclass(obj):<tab><tab><tab>what = ""class""<tab><tab><IF-STMT><tab><tab><tab>what = ""module""<tab><tab>elif callable(obj):<tab><tab><tab>what = ""function""<tab><tab>else:<tab><tab><tab>what = ""object""<tab>if what == ""class"":<tab><tab>return SphinxClassDoc(obj, """", func_doc=SphinxFunctionDoc)<tab>elif what in (""function"", ""method""):<tab><tab>return SphinxFunctionDoc(obj, """")<tab>else:<tab><tab>return SphinxDocString(pydoc.getdoc(obj))",elif inspect . ismodule ( obj ) :,161
3888,"def apply_pssm(val):<tab>if val is not None:<tab><tab>val_c = PSSM_VALUES.get(val, None)<tab><tab><IF-STMT><tab><tab><tab>assert isinstance(<tab><tab><tab><tab>val, tuple(PSSM_VALUES.values())<tab><tab><tab>), ""'store_as' should be one of: %r or an instance of %r not %r"" % (<tab><tab><tab><tab>tuple(PSSM_VALUES.keys()),<tab><tab><tab><tab>tuple(PSSM_VALUES.values()),<tab><tab><tab><tab>val,<tab><tab><tab>)<tab><tab><tab>return val<tab><tab>return val_c()",if val_c is None :,155
3889,"def read_postmaster_opts(self):<tab>""""""returns the list of option names/values from postgres.opts, Empty dict if read failed or no file""""""<tab>result = {}<tab>try:<tab><tab>with open(os.path.join(self._postgresql.data_dir, ""postmaster.opts"")) as f:<tab><tab><tab>data = f.read()<tab><tab><tab>for opt in data.split('"" ""'):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>name, val = opt.split(""="", 1)<tab><tab><tab><tab><tab>result[name.strip(""-"")] = val.rstrip('""\n')<tab>except IOError:<tab><tab>logger.exception(""Error when reading postmaster.opts"")<tab>return result","if ""="" in opt and opt . startswith ( ""--"" ) :",169
3890,"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(r""F5-TrafficShield"", headers.get(HTTP_HEADER.SERVER, """"), re.I)<tab><tab><tab>is not None<tab><tab>)<tab><tab>retval |= (<tab><tab><tab>re.search(r""\AASINFO="", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",if retval :,159
3891,"def on_task_start(self, task, config):<tab>for item in config:<tab><tab>for plugin_name, plugin_config in item.items():<tab><tab><tab>try:<tab><tab><tab><tab>thelist = plugin.get(plugin_name, self).get_list(plugin_config)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>raise PluginError(<tab><tab><tab><tab><tab>""Plugin %s does not support list interface"" % plugin_name<tab><tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise plugin.PluginError(thelist.immutable)",if thelist . immutable :,139
3892,"def nq(t):<tab>p = t[0] if (t and t[0] in ""-+"") else """"<tab>t = t[len(p) :]<tab>if t.startswith(""tag:"") or t.startswith(""in:""):<tab><tab>try:<tab><tab><tab>raw_tag = session.config.get_tag(t.split("":"")[1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>t = ""in:%s"" % raw_tag.slug<tab><tab>except (IndexError, KeyError, TypeError):<tab><tab><tab>pass<tab>return p + t",if raw_tag and raw_tag . hasattr ( slug ) :,139
3893,"def _recur_strip(s):<tab>if is_str(s):<tab><tab><IF-STMT><tab><tab><tab>return "" "".join(s.strip().split())<tab><tab>else:<tab><tab><tab>return "" "".join(s.strip().split()).replace(bos_token + "" "", """")<tab>else:<tab><tab>s_ = [_recur_strip(si) for si in s]<tab><tab>return _maybe_list_to_array(s_, s)","if bos_token == """" :",110
3894,"def __delitem__(self, key):<tab>""Deleting tag[key] deletes all 'key' attributes for the tag.""<tab>for item in self.attrs:<tab><tab><IF-STMT><tab><tab><tab>self.attrs.remove(item)<tab><tab><tab># We don't break because bad HTML can define the same<tab><tab><tab># attribute multiple times.<tab><tab>self._getAttrMap()<tab><tab>if self.attrMap.has_key(key):<tab><tab><tab>del self.attrMap[key]",if item [ 0 ] == key :,119
3895,"def comment_import_help(init_file, out_file):<tab>f_out = open(out_file, ""w"")<tab>output = """"<tab>updated = False<tab>with open(init_file, ""r"") as f_in:<tab><tab>for line in f_in:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>updated = True<tab><tab><tab><tab>line = ""# "" + line<tab><tab><tab>output += line<tab>f_out.write(output)<tab>f_out.close()<tab>return updated","if ""import"" in line and ""_help"" in line and not updated :",136
3896,"def prepare_text(lines):<tab>out = []<tab>for s in lines.split(""|""):<tab><tab>s = s.strip()<tab><tab><IF-STMT><tab><tab><tab># line beginning with '/' is in italics<tab><tab><tab>s = r""{\i1}%s{\i0}"" % s[1:].strip()<tab><tab>out.append(s)<tab>return ""\\N"".join(out)","if s . startswith ( ""/"" ) :",96
3897,"def sqlctx(sc):<tab>pytest.importorskip(""pyspark"")<tab>from odo.backends.sparksql import HiveContext<tab>try:<tab><tab>yield HiveContext(sc)<tab>finally:<tab><tab>dbpath = ""metastore_db""<tab><tab>logpath = ""derby.log""<tab><tab><IF-STMT><tab><tab><tab>assert os.path.isdir(dbpath)<tab><tab><tab>shutil.rmtree(dbpath)<tab><tab>if os.path.exists(logpath):<tab><tab><tab>assert os.path.isfile(logpath)<tab><tab><tab>os.remove(logpath)",if os . path . exists ( dbpath ) :,147
3898,"def _user2dict(self, uid):<tab>usdict = None<tab>if uid in self.users:<tab><tab>usdict = self.users[uid]<tab><tab><IF-STMT><tab><tab><tab>infos = self.users_info[uid]<tab><tab><tab>for attr in infos:<tab><tab><tab><tab>usdict[attr[""attr_type""]] = attr[""attr_data""]<tab><tab>usdict[""uid""] = uid<tab>return usdict",if uid in self . users_info :,109
3899,"def _validate_options(self):<tab>for option in self.options:<tab><tab># if value type is bool or int, then we know the options is set<tab><tab><IF-STMT><tab><tab><tab>if self.options.required[option] is True and not self.options[option]:<tab><tab><tab><tab>if option == Constants.PASSWORD_CLEAR:<tab><tab><tab><tab><tab>option = ""password"".upper()<tab><tab><tab><tab>raise FrameworkException(<tab><tab><tab><tab><tab>""Value required for the '%s' option."" % (option.upper())<tab><tab><tab><tab>)<tab>return","if not type ( self . options [ option ] ) in [ bool , int ] :",148
3900,"def _copy_package_apps(<tab>local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None:<tab>for src_unresolved in app_paths:<tab><tab>src = src_unresolved.resolve()<tab><tab>app = src.name<tab><tab>dest = Path(local_bin_dir / add_suffix(app, suffix))<tab><tab><IF-STMT><tab><tab><tab>mkdir(dest.parent)<tab><tab>if dest.exists():<tab><tab><tab>logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"")<tab><tab><tab>dest.unlink()<tab><tab>if src.exists():<tab><tab><tab>shutil.copy(src, dest)",if not dest . parent . is_dir ( ) :,177
3901,"def truncate_seq_pair(tokens_a, tokens_b, max_length):<tab>""""""Truncates a sequence pair in place to the maximum length.""""""<tab># This is a simple heuristic which will always truncate the longer sequence<tab># one token at a time. This makes more sense than truncating an equal percent<tab># of tokens from each, since if one sequence is very short then each token<tab># that's truncated likely contains more information than a longer sequence.<tab>while True:<tab><tab>total_length = len(tokens_a) + len(tokens_b)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if len(tokens_a) > len(tokens_b):<tab><tab><tab>tokens_a.pop()<tab><tab>else:<tab><tab><tab>tokens_b.pop()",if total_length <= max_length :,185
3902,"def add_channels(cls, voucher, add_channels):<tab>for add_channel in add_channels:<tab><tab>channel = add_channel[""channel""]<tab><tab>defaults = {""currency"": channel.currency_code}<tab><tab>if ""discount_value"" in add_channel.keys():<tab><tab><tab>defaults[""discount_value""] = add_channel.get(""discount_value"")<tab><tab><IF-STMT><tab><tab><tab>defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None)<tab><tab>models.VoucherChannelListing.objects.update_or_create(<tab><tab><tab>voucher=voucher,<tab><tab><tab>channel=channel,<tab><tab><tab>defaults=defaults,<tab><tab>)","if ""min_amount_spent"" in add_channel . keys ( ) :",176
3903,"def services(self, id=None, name=None):<tab>for service_dict in self.service_ls(id=id, name=name):<tab><tab>service_id = service_dict[""ID""]<tab><tab>service_name = service_dict[""NAME""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>task_list = self.service_ps(service_id)<tab><tab>yield DockerService.from_cli(self, service_dict, task_list)",if not service_name . startswith ( self . _name_prefix ) :,121
3904,"def lll(dirname):<tab>for name in os.listdir(dirname):<tab><tab><IF-STMT><tab><tab><tab>full = os.path.join(dirname, name)<tab><tab><tab>if os.path.islink(full):<tab><tab><tab><tab>print(name, ""->"", os.readlink(full))","if name not in ( os . curdir , os . pardir ) :",80
3905,"def convertstore(self, mydict):<tab>targetheader = self.mypofile.header()<tab>targetheader.addnote(""extracted from web2py"", ""developer"")<tab>for source_str in mydict.keys():<tab><tab>target_str = mydict[source_str]<tab><tab><IF-STMT><tab><tab><tab># a convention with new (untranslated) web2py files<tab><tab><tab>target_str = u""""<tab><tab>elif target_str.startswith(u""*** ""):<tab><tab><tab># an older convention<tab><tab><tab>target_str = u""""<tab><tab>pounit = self.convertunit(source_str, target_str)<tab><tab>self.mypofile.addunit(pounit)<tab>return self.mypofile",if target_str == source_str :,180
3906,"def __init__(self, **kwargs):<tab>for k, v in kwargs.items():<tab><tab>setattr(self, k, v)<tab>self.attempted_charsets = set()<tab>request = cherrypy.serving.request<tab>if request.handler is not None:<tab><tab># Replace request.handler with self<tab><tab><IF-STMT><tab><tab><tab>cherrypy.log(""Replacing request.handler"", ""TOOLS.ENCODE"")<tab><tab>self.oldhandler = request.handler<tab><tab>request.handler = self",if self . debug :,128
3907,"def _fastqc_data_section(self, section_name):<tab>out = []<tab>in_section = False<tab>data_file = os.path.join(self._dir, ""fastqc_data.txt"")<tab>if os.path.exists(data_file):<tab><tab>with open(data_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab>if line.startswith("">>%s"" % section_name):<tab><tab><tab><tab><tab>in_section = True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if line.startswith("">>END""):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>out.append(line.rstrip(""\r\n""))<tab>return out",elif in_section :,173
3908,"def bit_length(n):<tab>try:<tab><tab>return n.bit_length()<tab>except AttributeError:<tab><tab>norm = deflate_long(n, False)<tab><tab>hbyte = byte_ord(norm[0])<tab><tab><IF-STMT><tab><tab><tab>return 1<tab><tab>bitlen = len(norm) * 8<tab><tab>while not (hbyte & 0x80):<tab><tab><tab>hbyte <<= 1<tab><tab><tab>bitlen -= 1<tab><tab>return bitlen",if hbyte == 0 :,118
3909,"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>if i == self._skip - 2:<tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab><IF-STMT><tab><tab><tab>break<tab># Note that the observation on the done=True frame<tab># doesn't matter<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",if done :,189
3910,"def _sample_translation(reference, max_len):<tab>translation = reference[:]<tab>while np.random.uniform() < 0.8 and 1 < len(translation) < max_len:<tab><tab>trans_len = len(translation)<tab><tab>ind = np.random.randint(trans_len)<tab><tab>action = np.random.choice(actions)<tab><tab><IF-STMT><tab><tab><tab>del translation[ind]<tab><tab>elif action == ""replacement"":<tab><tab><tab>ind_rep = np.random.randint(trans_len)<tab><tab><tab>translation[ind] = translation[ind_rep]<tab><tab>else:<tab><tab><tab>ind_insert = np.random.randint(trans_len)<tab><tab><tab>translation.insert(ind, translation[ind_insert])<tab>return translation","if action == ""deletion"" :",186
3911,"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x):<tab>sign = None<tab>subseq = []<tab>for i in seq:<tab><tab>ki = key(i)<tab><tab>if sign is None:<tab><tab><tab>subseq.append(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab>else:<tab><tab><tab>subseq.append(i)<tab><tab><tab>if sign * ki < -slop:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab><tab><tab>yield subseq<tab><tab><tab><tab>subseq = [i]<tab>if subseq:<tab><tab>yield subseq",if ki != 0 :,167
3912,def get_dirlist(_rootdir):<tab>dirlist = []<tab>with os.scandir(_rootdir) as rit:<tab><tab>for entry in rit:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dirlist.append(entry.path)<tab><tab><tab><tab>dirlist += get_dirlist(entry.path)<tab>return dirlist,"if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :",91
3913,"def __init__(<tab>self,<tab>fixed: MQTTFixedHeader = None,<tab>variable_header: PublishVariableHeader = None,<tab>payload=None,):<tab>if fixed is None:<tab><tab>header = MQTTFixedHeader(PUBLISH, 0x00)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise HBMQTTException(<tab><tab><tab><tab>""Invalid fixed packet type %s for PublishPacket init""<tab><tab><tab><tab>% fixed.packet_type<tab><tab><tab>)<tab><tab>header = fixed<tab>super().__init__(header)<tab>self.variable_header = variable_header<tab>self.payload = payload",if fixed . packet_type is not PUBLISH :,160
3914,"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if fname == ""PureMVC_Python_1_0"":<tab><tab><tab>continue<tab><tab>if fname[-4:] == "".pyc"":  # ehmm.. no.<tab><tab><tab>continue<tab><tab>if os.path.isdir(p):<tab><tab><tab>get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res","if fname == ""output"" :",162
3915,"def reward(self):<tab>""""""Returns a tuple of sum of raw and processed rewards.""""""<tab>raw_rewards, processed_rewards = 0, 0<tab>for ts in self.time_steps:<tab><tab># NOTE: raw_reward and processed_reward are None for the first time-step.<tab><tab><IF-STMT><tab><tab><tab>raw_rewards += ts.raw_reward<tab><tab>if ts.processed_reward is not None:<tab><tab><tab>processed_rewards += ts.processed_reward<tab>return raw_rewards, processed_rewards",if ts . raw_reward is not None :,134
3916,"def _process_file(self, content):<tab>args = []<tab>for line in content.splitlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>args.extend(self._split_option(line))<tab><tab>elif line and not line.startswith(""#""):<tab><tab><tab>args.append(line)<tab>return args","if line . startswith ( ""-"" ) :",83
3917,"def __on_change_button_clicked(self, widget=None):<tab>""""""compute all primary objects and toggle the 'Change' attribute""""""<tab>self.change_status = not self.change_status<tab>for prim_obj, tmp in self.xobjects:<tab><tab>obj_change = self.top.get_object(""%s_change"" % prim_obj)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.change_entries[prim_obj].set_val(self.change_status)<tab><tab>obj_change.set_active(self.change_status)",if not obj_change . get_sensitive ( ) :,145
3918,"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]:<tab>yield ""Core"", ""0""<tab>for _dir in data_manager.cog_data_path().iterdir():<tab><tab>fpath = _dir / ""settings.json""<tab><tab>if not fpath.exists():<tab><tab><tab>continue<tab><tab>with fpath.open() as f:<tab><tab><tab>try:<tab><tab><tab><tab>data = json.load(f)<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>cog_name = _dir.stem<tab><tab>for cog_id, inner in data.items():<tab><tab><tab>if not isinstance(inner, dict):<tab><tab><tab><tab>continue<tab><tab><tab>yield cog_name, cog_id","if not isinstance ( data , dict ) :",192
3919,"def _verifySubs(self):<tab>for inst in self.subs:<tab><tab>if not isinstance(inst, (_Block, _Instantiator, Cosimulation)):<tab><tab><tab>raise BlockError(_error.ArgType % (self.name,))<tab><tab>if isinstance(inst, (_Block, _Instantiator)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise BlockError(_error.InstanceError % (self.name, inst.callername))",if not inst . modctxt :,110
3920,"def _is_xml(accepts):<tab>if accepts.startswith(b""application/""):<tab><tab>has_xml = accepts.find(b""xml"")<tab><tab>if has_xml > 0:<tab><tab><tab>semicolon = accepts.find(b"";"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",if semicolon < 0 or has_xml < semicolon :,86
3921,"def _accept_with(cls, orm, target):<tab>if target is orm.mapper:<tab><tab>return mapperlib.Mapper<tab>elif isinstance(target, type):<tab><tab><IF-STMT><tab><tab><tab>return target<tab><tab>else:<tab><tab><tab>mapper = _mapper_or_none(target)<tab><tab><tab>if mapper is not None:<tab><tab><tab><tab>return mapper<tab><tab><tab>else:<tab><tab><tab><tab>return _MapperEventsHold(target)<tab>else:<tab><tab>return target","if issubclass ( target , mapperlib . Mapper ) :",123
3922,"def _get_font_afm(self, prop):<tab>key = hash(prop)<tab>font = self.afmfontd.get(key)<tab><IF-STMT><tab><tab>fname = findfont(prop, fontext=""afm"")<tab><tab>font = self.afmfontd.get(fname)<tab><tab>if font is None:<tab><tab><tab>font = AFM(file(findfont(prop, fontext=""afm"")))<tab><tab><tab>self.afmfontd[fname] = font<tab><tab>self.afmfontd[key] = font<tab>return font",if font is None :,142
3923,"def __call__(self, groupby):<tab>normalize_reduction_funcs(self, ndim=groupby.ndim)<tab>df = groupby<tab>while df.op.output_types[0] not in (OutputType.dataframe, OutputType.series):<tab><tab>df = df.inputs[0]<tab>if self.raw_func == ""size"":<tab><tab>self.output_types = [OutputType.series]<tab>else:<tab><tab>self.output_types = (<tab><tab><tab>[OutputType.dataframe]<tab><tab><tab><IF-STMT><tab><tab><tab>else [OutputType.series]<tab><tab>)<tab>if self.output_types[0] == OutputType.dataframe:<tab><tab>return self._call_dataframe(groupby, df)<tab>else:<tab><tab>return self._call_series(groupby, df)",if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby,197
3924,"def save(self):<tab>if self.preferences.get(ENCRYPT_ON_DISK, False):<tab><tab><IF-STMT><tab><tab><tab>return self.storage.write(<tab><tab><tab><tab>self.to_dict(encrypt_password=self.encryption_password)<tab><tab><tab>)<tab><tab>elif not self.is_locked:<tab><tab><tab>log.warning(<tab><tab><tab><tab>""Disk encryption requested but no password available for encryption. ""<tab><tab><tab><tab>""Resetting encryption preferences and saving wallet in an unencrypted state.""<tab><tab><tab>)<tab><tab><tab>self.preferences[ENCRYPT_ON_DISK] = False<tab>return self.storage.write(self.to_dict())",if self . encryption_password is not None :,164
3925,"def isValidDateString(config_param_name, value, valid_value):<tab>try:<tab><tab>if value == ""DD-MM-YYYY"":<tab><tab><tab>return value<tab><tab>day, month, year = value.split(""-"")<tab><tab>if int(day) < 1 or int(day) > 31:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab><IF-STMT><tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(year) < 1900 or int(year) > 2013:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>return value<tab>except Exception:<tab><tab>raise DateStringValueError(config_param_name, value)",if int ( month ) < 1 or int ( month ) > 12 :,187
3926,"def _capture(self, call_name, data=None, **kwargs):<tab>if data is None:<tab><tab>data = self.get_default_context()<tab>else:<tab><tab>default_context = self.get_default_context()<tab><tab><IF-STMT><tab><tab><tab>default_context.update(data)<tab><tab>else:<tab><tab><tab>default_context[""extra""][""extra_data""] = data<tab><tab>data = default_context<tab>client = self.get_sentry_client()<tab>return getattr(client, call_name)(data=data, **kwargs)","if isinstance ( data , dict ) :",139
3927,"def check(input, expected_output=None, expected_ffi_error=False):<tab>import _cffi_backend<tab>ffi = _cffi_backend.FFI()<tab>if not expected_ffi_error:<tab><tab>ct = ffi.typeof(input)<tab><tab>assert isinstance(ct, ffi.CType)<tab><tab>assert ct.cname == (expected_output or input)<tab>else:<tab><tab>e = py.test.raises(ffi.error, ffi.typeof, input)<tab><tab><IF-STMT><tab><tab><tab>assert str(e.value) == expected_ffi_error","if isinstance ( expected_ffi_error , str ) :",157
3928,"def run(self):<tab>""""""Process queries from task queue, stop if processor is None.""""""<tab>while True:<tab><tab>try:<tab><tab><tab>processor, iprot, oprot, otrans, callback = self.queue.get()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>processor.process(iprot, oprot)<tab><tab><tab>callback(True, otrans.getvalue())<tab><tab>except Exception:<tab><tab><tab>logging.exception(""Exception while processing request"")<tab><tab><tab>callback(False, """")",if processor is None :,128
3929,"def search(self, query):<tab>query = query.strip().lower()<tab>results = []<tab>for provider in SidebarItemProvider.all(self.context):<tab><tab>for item in provider.provide():<tab><tab><tab>if ""url"" in item:<tab><tab><tab><tab>search_source = ""$"".join(<tab><tab><tab><tab><tab>[item.get(""id"", """"), item.get(""name"", """")]<tab><tab><tab><tab>).lower()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>results.append(<tab><tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab><tab>""title"": item[""name""],<tab><tab><tab><tab><tab><tab><tab>""icon"": item[""icon""],<tab><tab><tab><tab><tab><tab><tab>""url"": item[""url""],<tab><tab><tab><tab><tab><tab>}<tab><tab><tab><tab><tab>)<tab>return results",if query in search_source :,197
3930,"def handle(self) -> None:<tab>""""""Handles a request ignoring dropped connections.""""""<tab>try:<tab><tab>BaseHTTPRequestHandler.handle(self)<tab>except (ConnectionError, socket.timeout) as e:<tab><tab>self.connection_dropped(e)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab>self.log_error(""SSL error occurred: %s"", e)<tab><tab>else:<tab><tab><tab>raise<tab>if self.server.shutdown_signal:<tab><tab>self.initiate_shutdown()",if self . server . ssl_context is not None and is_ssl_error ( e ) :,137
3931,"def cdn_url_handler(error, endpoint, kwargs):<tab>if endpoint == ""cdn"":<tab><tab>path = kwargs.pop(""path"")<tab><tab># cdn = app.config.get('cdn', 'http://cdn.staticfile.org/')<tab><tab># cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/')<tab><tab>cdn = app.config.get(""cdn"", ""//cdnjscn.b0.upaiyun.com/libs/"")<tab><tab>return urljoin(cdn, path)<tab>else:<tab><tab>exc_type, exc_value, tb = sys.exc_info()<tab><tab><IF-STMT><tab><tab><tab>reraise(exc_type, exc_value, tb)<tab><tab>else:<tab><tab><tab>raise error",if exc_value is error :,186
3932,"def pairs(self):<tab>for path in os.listdir(""src""):<tab><tab>if path == "".svn"":<tab><tab><tab>continue<tab><tab>dep = join(""src"", path)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield dep, join(build_dir, path)",if isdir ( dep ) :,69
3933,"def get_condition(self):<tab>""""""Return the condition element's name.""""""<tab>for child in self.xml:<tab><tab><IF-STMT><tab><tab><tab>cond = child.tag.split(""}"", 1)[-1]<tab><tab><tab>if cond in self.conditions:<tab><tab><tab><tab>return cond<tab>return ""not-authorized""","if ""{%s}"" % self . namespace in child . tag :",85
3934,"def end(self, tag):<tab># call the appropriate end tag handler<tab>try:<tab><tab>f = self.dispatch[tag]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>return  # unknown tag ?<tab><tab>try:<tab><tab><tab>f = self.dispatch[tag.split("":"")[-1]]<tab><tab>except KeyError:<tab><tab><tab>return  # unknown tag ?<tab>return f(self, """".join(self._data))","if "":"" not in tag :",107
3935,"def checkIfSessionCodeExists(self, sessionCode):<tab>if self.emrtFile:<tab><tab>sessionsForExperiment = (<tab><tab><tab>self.emrtFile.root.data_collection.session_meta_data.where(<tab><tab><tab><tab>""experiment_id == %d"" % (self.active_experiment_id,)<tab><tab><tab>)<tab><tab>)<tab><tab>sessionCodeMatch = [<tab><tab><tab>sess for sess in sessionsForExperiment if sess[""code""] == sessionCode<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>return False",if len ( sessionCodeMatch ) > 0 :,145
3936,"def save_bytearray(self, obj):<tab>if self.proto < 5:<tab><tab><IF-STMT>  # bytearray is empty<tab><tab><tab>self.save_reduce(bytearray, (), obj=obj)<tab><tab>else:<tab><tab><tab>self.save_reduce(bytearray, (bytes(obj),), obj=obj)<tab><tab>return<tab>n = len(obj)<tab>if n >= self.framer._FRAME_SIZE_TARGET:<tab><tab>self._write_large_bytes(BYTEARRAY8 + pack(""<Q"", n), obj)<tab>else:<tab><tab>self.write(BYTEARRAY8 + pack(""<Q"", n) + obj)",if not obj :,151
3937,"def _restore_freeze(self, new):<tab>size_change = []<tab>for k, v in six.iteritems(self._freeze_backup):<tab><tab>newv = new.get(k, [])<tab><tab><IF-STMT><tab><tab><tab>size_change.append((self._key_name(k), len(v), len(newv)))<tab>if size_change:<tab><tab>logger.info(<tab><tab><tab>""These collections were modified but restored in {}: {}"".format(<tab><tab><tab><tab>self._name,<tab><tab><tab><tab>"", "".join(map(lambda t: ""({}: {}->{})"".format(*t), size_change)),<tab><tab><tab>)<tab><tab>)<tab>restore_collection(self._freeze_backup)",if len ( v ) != len ( newv ) :,176
3938,"def check_options(self, expr, evaluation, options):<tab>for key in options:<tab><tab>if key != ""System`SameTest"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>evaluation.message(""ContainsOnly"", ""optx"", Symbol(key))<tab><tab><tab>else:<tab><tab><tab><tab>return evaluation.message(""ContainsOnly"", ""optx"", Symbol(key), expr)<tab>return None",if expr is None :,91
3939,"def bundle_directory(self, dirpath):<tab>""""""Bundle all modules/packages in the given directory.""""""<tab>dirpath = os.path.abspath(dirpath)<tab>for nm in os.listdir(dirpath):<tab><tab>nm = _u(nm)<tab><tab>if nm.startswith("".""):<tab><tab><tab>continue<tab><tab>itempath = os.path.join(dirpath, nm)<tab><tab>if os.path.isdir(itempath):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.bundle_package(itempath)<tab><tab>elif nm.endswith("".py""):<tab><tab><tab>self.bundle_module(itempath)","if os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :",160
3940,"def _read_block(self, size):<tab>if self._file_end is not None:<tab><tab>max_size = self._file_end - self._file.tell()<tab><tab><IF-STMT><tab><tab><tab>size = max_size<tab><tab>size = max(min(size, max_size), 0)<tab>return self._file.read(size)",if size == - 1 :,88
3941,"def question_mark(self):<tab>""""""Shows help for this command and it's sub-commands.""""""<tab>ret = []<tab>if self.param_help_msg or len(self.subcommands) == 0:<tab><tab>ret.append(self._quick_help())<tab>if len(self.subcommands) > 0:<tab><tab>for k, _ in sorted(self.subcommands.items()):<tab><tab><tab>command_path, param_help, cmd_help = self._instantiate_subcommand(<tab><tab><tab><tab>k<tab><tab><tab>)._quick_help(nested=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append((command_path, param_help, cmd_help))<tab>return (CommandsResponse(STATUS_OK, self.help_formatter(ret)), self.__class__)",if command_path or param_help or cmd_help :,193
3942,"def list_domains(self, r53, **kwargs):<tab>marker = None<tab>domains = []<tab>while True:<tab><tab>if marker:<tab><tab><tab>response = self.wrap_aws_rate_limited_call(r53.list_domains(Marker=marker))<tab><tab>else:<tab><tab><tab>response = self.wrap_aws_rate_limited_call(r53.list_domains)<tab><tab>for domain in response.get(""Domains""):<tab><tab><tab>domains.append(domain)<tab><tab><IF-STMT><tab><tab><tab>marker = response.get(""NextPageMarker"")<tab><tab>else:<tab><tab><tab>break<tab>return domains","if response . get ( ""NextPageMarker"" ) :",157
3943,"def writer(stream, items):<tab>sep = """"<tab>for item in items:<tab><tab>stream.write(sep)<tab><tab>sep = "" ""<tab><tab>if not isinstance(item, str):<tab><tab><tab>item = str(item)<tab><tab>if not PY3K:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item = str(item)<tab><tab>stream.write(item)<tab>stream.write(""\n"")","if not isinstance ( item , unicode ) :",106
3944,"def f(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab>view.run_command(""toggle_comment"")<tab><tab><IF-STMT><tab><tab><tab>pt = utils.next_non_white_space_char(view, s.a, white_space="" \t"")<tab><tab>else:<tab><tab><tab>pt = utils.next_non_white_space_char(<tab><tab><tab><tab>view, self.view.line(s.a).a, white_space="" \t""<tab><tab><tab>)<tab><tab>return R(pt, pt)<tab>return s","if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :",166
3945,"def _parse_timestamp(value):<tab>if value:<tab><tab>match = _TIMESTAMP_PATTERN.match(value)<tab><tab><IF-STMT><tab><tab><tab>if match.group(2):<tab><tab><tab><tab>format = ""%Y-%m-%d %H:%M:%S.%f""<tab><tab><tab><tab># use the pattern to truncate the value<tab><tab><tab><tab>value = match.group()<tab><tab><tab>else:<tab><tab><tab><tab>format = ""%Y-%m-%d %H:%M:%S""<tab><tab><tab>value = datetime.datetime.strptime(value, format)<tab><tab>else:<tab><tab><tab>raise Exception('Cannot convert ""{}"" into a datetime'.format(value))<tab>else:<tab><tab>value = None<tab>return value",if match :,170
3946,"def _compute_log_r(model_trace, guide_trace):<tab>log_r = MultiFrameTensor()<tab>stacks = get_plate_stacks(model_trace)<tab>for name, model_site in model_trace.nodes.items():<tab><tab>if model_site[""type""] == ""sample"":<tab><tab><tab>log_r_term = model_site[""log_prob""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""]<tab><tab><tab>log_r.add((stacks[name], log_r_term.detach()))<tab>return log_r","if not model_site [ ""is_observed"" ] :",162
3947,"def get_translationproject(self):<tab>""""""returns the translation project belonging to this directory.""""""<tab>if self.is_language() or self.is_project():<tab><tab>return None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self.translationproject<tab><tab>else:<tab><tab><tab>aux_dir = self<tab><tab><tab>while not aux_dir.is_translationproject() and aux_dir.parent is not None:<tab><tab><tab><tab>aux_dir = aux_dir.parent<tab><tab><tab>return aux_dir.translationproject",if self . is_translationproject ( ) :,130
3948,"def get_hosted_content():<tab>try:<tab><tab>scheme, rest = target.split(""://"", 1)<tab><tab>prefix, host_and_port = rest.split("".interactivetool."")<tab><tab>faked_host = rest<tab><tab><IF-STMT><tab><tab><tab>faked_host = rest.split(""/"", 1)[0]<tab><tab>url = ""%s://%s"" % (scheme, host_and_port)<tab><tab>response = requests.get(url, timeout=1, headers={""Host"": faked_host})<tab><tab>return response.text<tab>except Exception as e:<tab><tab>print(e)<tab><tab>return None","if ""/"" in rest :",148
3949,"def install(self):<tab>log.info(self.openssl_cli)<tab>if not self.has_openssl or self.args.force:<tab><tab><IF-STMT><tab><tab><tab>self._download_src()<tab><tab>else:<tab><tab><tab>log.debug(""Already has src {}"".format(self.src_file))<tab><tab>self._unpack_src()<tab><tab>self._build_src()<tab><tab>self._make_install()<tab>else:<tab><tab>log.info(""Already has installation {}"".format(self.install_dir))<tab># validate installation<tab>version = self.openssl_version<tab>if self.version not in version:<tab><tab>raise ValueError(version)",if not self . has_src :,162
3950,"def format(self, formatstr):<tab>pieces = []<tab>for i, piece in enumerate(re_formatchars.split(force_text(formatstr))):<tab><tab>if i % 2:<tab><tab><tab>pieces.append(force_text(getattr(self, piece)()))<tab><tab><IF-STMT><tab><tab><tab>pieces.append(re_escaped.sub(r""\1"", piece))<tab>return """".join(pieces)",elif piece :,99
3951,"def get_current_events_users(calendar):<tab>now = timezone.make_aware(datetime.now(), timezone.get_current_timezone())<tab>result = []<tab>day = Day(calendar.events.all(), now)<tab>for o in day.get_occurrences():<tab><tab><IF-STMT><tab><tab><tab>usernames = o.event.title.split("","")<tab><tab><tab>for username in usernames:<tab><tab><tab><tab>result.append(User.objects.get(username=username.strip()))<tab>return result",if o . start <= now <= o . end :,128
3952,"def from_cfn_params(self, cfn_params):<tab>""""""Initialize param value by parsing CFN input only if the scheduler is awsbatch.""""""<tab>cfn_converter = self.definition.get(""cfn_param_mapping"", None)<tab>if cfn_converter and cfn_params:<tab><tab><IF-STMT><tab><tab><tab># we have the same CFN input parameters for both spot_price and spot_bid_percentage<tab><tab><tab># so the CFN input could be a float<tab><tab><tab>self.value = int(float(get_cfn_param(cfn_params, cfn_converter)))<tab>return self","if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :",165
3953,"def onCompletion(self, text):<tab>res = []<tab>for l in text.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>l = l.split("":"")<tab><tab>if len(l) != 2:<tab><tab><tab>continue<tab><tab>res.append([l[0].strip(), l[1].strip()])<tab>self.panel.setChapters(res)",if not l :,93
3954,"def update_ranges(l, i):<tab>for _range in l:<tab><tab># most common case: extend a range<tab><tab>if i == _range[0] - 1:<tab><tab><tab>_range[0] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>_range[1] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab># somewhere outside of range proximity<tab>l.append([i, i])<tab>l.sort(key=lambda x: x[0])",elif i == _range [ 1 ] + 1 :,145
3955,"def process_dollar(token, state, command_line):<tab>if not state.is_range_start_line_parsed:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.start.append(token)<tab>else:<tab><tab>if command_line.line_range.end:<tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.end.append(token)<tab>return parse_line_ref, command_line",if command_line . line_range . start :,156
3956,"def _parse_description(self, text: str):<tab>result = dict(links=[], versions=[])<tab>for line in text.splitlines():<tab><tab>clean = REX_TAG.sub("""", line.strip())<tab><tab><IF-STMT><tab><tab><tab>result[""severity""] = clean.split()[1]<tab><tab><tab>continue<tab><tab>if clean.startswith(""Affects:""):<tab><tab><tab>result[""name""] = clean.split()[1]<tab><tab><tab>continue<tab><tab>if "" or higher"" in clean:<tab><tab><tab>result[""versions""] = self._get_versions(clean)<tab><tab>result[""links""].extend(REX_LINK.findall(line))<tab>return result","if clean . startswith ( ""Severity:"" ) :",162
3957,"def apply(self, chart, grammar):<tab>for prod in grammar.productions(empty=True):<tab><tab>for index in compat.xrange(chart.num_leaves() + 1):<tab><tab><tab>new_edge = TreeEdge.from_production(prod, index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield new_edge","if chart . insert ( new_edge , ( ) ) :",83
3958,"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab><IF-STMT><tab><tab><tab>self.current += num<tab><tab>elif self.op == ""-"":<tab><tab><tab>self.current -= num<tab><tab>elif self.op == ""*"":<tab><tab><tab>self.current *= num<tab><tab>elif self.op == ""/"":<tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res","if self . op == ""+"" :",187
3959,"def cascade(self, event=None):<tab>""""""Cascade all Leo windows.""""""<tab>x, y, delta = 50, 50, 50<tab>for frame in g.app.windowList:<tab><tab>w = frame and frame.top<tab><tab>if w:<tab><tab><tab>r = w.geometry()  # a Qt.Rect<tab><tab><tab># 2011/10/26: Fix bug 823601: cascade-windows fails.<tab><tab><tab>w.setGeometry(QtCore.QRect(x, y, r.width(), r.height()))<tab><tab><tab># Compute the new offsets.<tab><tab><tab>x += 30<tab><tab><tab>y += 30<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = 10 + delta<tab><tab><tab><tab>y = 40 + delta<tab><tab><tab><tab>delta += 10",if x > 200 :,190
3960,"def redirect(self):<tab>c = self.c<tab>if c.config.getBool(""eval-redirect""):<tab><tab>self.old_stderr = g.stdErrIsRedirected()<tab><tab>self.old_stdout = g.stdOutIsRedirected()<tab><tab><IF-STMT><tab><tab><tab>g.redirectStderr()<tab><tab>if not self.old_stdout:<tab><tab><tab>g.redirectStdout()",if not self . old_stderr :,103
3961,"def on_event(self, c, button, data):<tab>if self.rvGestureGrab.get_reveal_child():<tab><tab><IF-STMT><tab><tab><tab>self.use()<tab><tab>elif button == ""Y"" and data[0] == 0:<tab><tab><tab>self.start_over()","if button == ""A"" and data [ 0 ] == 0 :",83
3962,"def __init__(self, in_feats, out_feats, norm=""both"", bias=True, activation=None):<tab>super(DenseGraphConv, self).__init__()<tab>self._in_feats = in_feats<tab>self._out_feats = out_feats<tab>self._norm = norm<tab>with self.name_scope():<tab><tab>self.weight = self.params.get(<tab><tab><tab>""weight"",<tab><tab><tab>shape=(in_feats, out_feats),<tab><tab><tab>init=mx.init.Xavier(magnitude=math.sqrt(2.0)),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.bias = self.params.get(""bias"", shape=(out_feats,), init=mx.init.Zero())<tab><tab>else:<tab><tab><tab>self.bias = None<tab><tab>self._activation = activation",if bias :,195
3963,"def _import_top_module(self, name):<tab># scan sys.path looking for a location in the filesystem that contains<tab># the module, or an Importer object that can import the module.<tab>for item in sys.path:<tab><tab>if isinstance(item, _StringType):<tab><tab><tab>module = self.fs_imp.import_from_dir(item, name)<tab><tab>else:<tab><tab><tab>module = item.import_top(name)<tab><tab><IF-STMT><tab><tab><tab>return module<tab>return None",if module :,124
3964,"def resolver(schemas, f):<tab>if not callable(f):<tab><tab>return<tab>if not hasattr(f, ""accepts""):<tab><tab>return<tab>new_params = []<tab>for p in f.accepts:<tab><tab><IF-STMT><tab><tab><tab>new_params.append(p.resolve(schemas))<tab><tab>else:<tab><tab><tab>raise ResolverError(""Invalid parameter definition {0}"".format(p))<tab># FIXME: for some reason assigning params (f.accepts = new_params) does not work<tab>f.accepts.clear()<tab>f.accepts.extend(new_params)","if isinstance ( p , ( Patch , Ref , Attribute ) ) :",153
3965,"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab>if fname == ""output"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if fname[-4:] == "".pyc"":  # ehmm.. no.<tab><tab><tab>continue<tab><tab>if os.path.isdir(p):<tab><tab><tab>get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res","if fname == ""PureMVC_Python_1_0"" :",162
3966,"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True):<tab>if leftname in kerning:<tab><tab>for rightname in kerning[leftname]:<tab><tab><tab>if rightname[0] == ""@"":<tab><tab><tab><tab>for rightname2 in groups[rightname]:<tab><tab><tab><tab><tab>rightnames.add(rightname2)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab># TODO: in this case, pick the one rightname that has the highest<tab><tab><tab><tab><tab><tab># ranking in glyphorder<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>rightnames.add(rightname)",if not includeAll :,161
3967,"def migrate_Stats(self):<tab>for old_obj in self.session_old.query(self.model_from[""Stats""]):<tab><tab><IF-STMT><tab><tab><tab>self.entries_count[""Stats""] -= 1<tab><tab><tab>continue<tab><tab>new_obj = self.model_to[""Stats""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab>if key not in old_obj.__table__.columns:<tab><tab><tab><tab>continue<tab><tab><tab>setattr(new_obj, key, getattr(old_obj, key))<tab><tab>self.session_new.add(new_obj)",if not old_obj . summary :,152
3968,"def _readenv(var, msg):<tab>match = _ENV_VAR_PAT.match(var)<tab>if match and match.groups():<tab><tab>envvar = match.groups()[0]<tab><tab><IF-STMT><tab><tab><tab>value = os.environ[envvar]<tab><tab><tab>if six.PY2:<tab><tab><tab><tab>value = value.decode(""utf8"")<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>raise InvalidConfigException(<tab><tab><tab><tab>""{} - environment variable '{}' not set"".format(msg, var)<tab><tab><tab>)<tab>else:<tab><tab>raise InvalidConfigException(<tab><tab><tab>""{} - environment variable name '{}' does not match pattern '{}'"".format(<tab><tab><tab><tab>msg, var, _ENV_VAR_PAT_STR<tab><tab><tab>)<tab><tab>)",if envvar in os . environ :,190
3969,"def __next__(self):<tab>self._parse_reset()<tab>while True:<tab><tab>try:<tab><tab><tab>line = next(self.input_iter)<tab><tab>except StopIteration:<tab><tab><tab># End of input OR exception<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Error(""newline inside string"")<tab><tab><tab>raise<tab><tab>self.line_num += 1<tab><tab>if ""\0"" in line:<tab><tab><tab>raise Error(""line contains NULL byte"")<tab><tab>pos = 0<tab><tab>while pos < len(line):<tab><tab><tab>pos = self._parse_process_char(line, pos)<tab><tab>self._parse_eol()<tab><tab>if self.state == self.START_RECORD:<tab><tab><tab>break<tab>fields = self.fields<tab>self.fields = []<tab>return fields",if len ( self . field ) > 0 :,198
3970,"def createFields(self):<tab>while self.current_size < self.size:<tab><tab>pos = self.stream.searchBytes(<tab><tab><tab>""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8<tab><tab>)  # seek forward by at most 1MB<tab><tab><IF-STMT><tab><tab><tab>padsize = pos - self.current_size<tab><tab><tab>if padsize:<tab><tab><tab><tab>yield PaddingBytes(self, ""pad[]"", padsize // 8)<tab><tab>chunk = Chunk(self, ""chunk[]"")<tab><tab>try:<tab><tab><tab># force chunk to be processed, so that CustomFragments are complete<tab><tab><tab>chunk[""content/data""]<tab><tab>except:<tab><tab><tab>pass<tab><tab>yield chunk",if pos is not None :,184
3971,"def spew():<tab>seenUID = False<tab>start()<tab>for part in query:<tab><tab>if part.type == ""uid"":<tab><tab><tab>seenUID = True<tab><tab><IF-STMT><tab><tab><tab>yield self.spew_body(part, id, msg, write, flush)<tab><tab>else:<tab><tab><tab>f = getattr(self, ""spew_"" + part.type)<tab><tab><tab>yield f(id, msg, write, flush)<tab><tab>if part is not query[-1]:<tab><tab><tab>space()<tab>if uid and not seenUID:<tab><tab>space()<tab><tab>yield self.spew_uid(id, msg, write, flush)<tab>finish()<tab>flush()","if part . type == ""body"" :",174
3972,"def _limit_value(key, value, config):<tab>if config[key].get(""upper_limit""):<tab><tab>limit = config[key][""upper_limit""]<tab><tab># auto handle datetime<tab><tab>if isinstance(value, datetime) and isinstance(limit, timedelta):<tab><tab><tab>if config[key][""inverse""] is True:<tab><tab><tab><tab>if (datetime.now() - limit) > value:<tab><tab><tab><tab><tab>value = datetime.now() - limit<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value = datetime.now() + limit<tab><tab>elif value > limit:<tab><tab><tab>value = limit<tab>return value",if ( datetime . now ( ) + limit ) < value :,164
3973,"def _fix_var_naming(operators, names, mod=""input""):<tab>new_names = []<tab>map = {}<tab>for op in operators:<tab><tab>if mod == ""input"":<tab><tab><tab>iter = op.inputs<tab><tab>else:<tab><tab><tab>iter = op.outputs<tab><tab>for i in iter:<tab><tab><tab>for name in names:<tab><tab><tab><tab>if i.raw_name == name and name not in map:<tab><tab><tab><tab><tab>map[i.raw_name] = i.full_name<tab><tab><IF-STMT><tab><tab><tab>break<tab>for name in names:<tab><tab>new_names.append(map[name])<tab>return new_names",if len ( map ) == len ( names ) :,168
3974,"def traverse(tree):<tab>""""""Generator dropping comment nodes""""""<tab>for entry in tree:<tab><tab># key, values = entry<tab><tab>spaceless = [e for e in entry if not nginxparser.spacey(e)]<tab><tab>if spaceless:<tab><tab><tab>key = spaceless[0]<tab><tab><tab>values = spaceless[1] if len(spaceless) > 1 else None<tab><tab>else:<tab><tab><tab>key = values = """"<tab><tab>if isinstance(key, list):<tab><tab><tab>new = copy.deepcopy(entry)<tab><tab><tab>new[1] = filter_comments(values)<tab><tab><tab>yield new<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield spaceless","if key != ""#"" and spaceless :",173
3975,"def mergeCombiners(self, x, y):<tab>for item in y:<tab><tab><IF-STMT><tab><tab><tab>self.heap.push(x, item)<tab><tab>else:<tab><tab><tab>self.heap.push_pop(x, item)<tab>return x",if len ( x ) < self . heap_limit :,73
3976,"def test_scatter(self, harness: primitive_harness.Harness):<tab>f_name = harness.params[""f_lax""].__name__<tab>dtype = harness.params[""dtype""]<tab>if jtu.device_under_test() == ""tpu"":<tab><tab><IF-STMT><tab><tab><tab>raise unittest.SkipTest(f""TODO: complex {f_name} on TPU fails in JAX"")<tab>self.ConvertAndCompare(harness.dyn_fun, *harness.dyn_args_maker(self.rng()))","if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :",148
3977,"def TryMerge(self, decoder):<tab>while decoder.avail() > 0:<tab><tab>tag = decoder.getVarInt32()<tab><tab>if tag == TAG_BEGIN_ITEM_GROUP:<tab><tab><tab>(type_id, message) = Item.Decode(decoder)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.items[type_id].MergeFrom(Item(message))<tab><tab><tab>else:<tab><tab><tab><tab>self.items[type_id] = Item(message)<tab><tab><tab>continue<tab><tab>if tag == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>decoder.skipData(tag)",if type_id in self . items :,154
3978,"def process_continuations(lines):<tab>global continuation_pattern<tab>olines = []<tab>while len(lines) != 0:<tab><tab>line = no_comments(lines[0])<tab><tab>line = line.strip()<tab><tab>lines.pop(0)<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># combine this line with the next line if the next line exists<tab><tab><tab>line = continuation_pattern.sub("""", line)<tab><tab><tab>if len(lines) >= 1:<tab><tab><tab><tab>combined_lines = [line + lines[0]]<tab><tab><tab><tab>lines.pop(0)<tab><tab><tab><tab>lines = combined_lines + lines<tab><tab><tab><tab>continue<tab><tab>olines.append(line)<tab>del lines<tab>return olines",if continuation_pattern . search ( line ) :,193
3979,"def _getListNextPackagesReadyToBuild():<tab>for pkg in Scheduler.listOfPackagesToBuild:<tab><tab>if pkg in Scheduler.listOfPackagesCurrentlyBuilding:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg))<tab><tab><tab>Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,113
3980,"def process_signature(app, what, name, obj, options, signature, return_annotation):<tab>if signature:<tab><tab># replace Mock function names<tab><tab>signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature)<tab><tab>signature = re.sub(""tensorflow"", ""tf"", signature)<tab><tab># add scope name to layer signatures:<tab><tab>if hasattr(obj, ""use_scope""):<tab><tab><tab>if obj.use_scope:<tab><tab><tab><tab>signature = signature[0] + ""variable_scope_name, "" + signature[1:]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>signature = signature[0] + ""[variable_scope_name,] "" + signature[1:]<tab># signature: arg list<tab>return signature, return_annotation",elif obj . use_scope is None :,188
3981,"def find_distribution_modules(name=__name__, file=__file__):<tab>current_dist_depth = len(name.split(""."")) - 1<tab>current_dist = os.path.join(<tab><tab>os.path.dirname(file), *([os.pardir] * current_dist_depth)<tab>)<tab>abs = os.path.abspath(current_dist)<tab>dist_name = os.path.basename(abs)<tab>for dirpath, dirnames, filenames in os.walk(abs):<tab><tab>package = (dist_name + dirpath[len(abs) :]).replace(""/"", ""."")<tab><tab><IF-STMT><tab><tab><tab>yield package<tab><tab><tab>for filename in filenames:<tab><tab><tab><tab>if filename.endswith("".py"") and filename != ""__init__.py"":<tab><tab><tab><tab><tab>yield ""."".join([package, filename])[:-3]","if ""__init__.py"" in filenames :",198
3982,"def transform_value(i, v, *args):<tab>if i not in converter_functions:<tab><tab># no converter defined on this field, return value as-is<tab><tab>return v<tab>else:<tab><tab>try:<tab><tab><tab>return converter_functions[i](v, *args)<tab><tab>except Exception as e:<tab><tab><tab>if failonerror == ""inline"":<tab><tab><tab><tab>return e<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab><tab><tab>else:<tab><tab><tab><tab>return errorvalue",elif failonerror :,126
3983,"def _get_file(self):<tab>if self._file is None:<tab><tab>self._file = SpooledTemporaryFile(<tab><tab><tab>max_size=self._storage.max_memory_size,<tab><tab><tab>suffix="".S3Boto3StorageFile"",<tab><tab><tab>dir=setting(""FILE_UPLOAD_TEMP_DIR""),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._is_dirty = False<tab><tab><tab>self.obj.download_fileobj(self._file)<tab><tab><tab>self._file.seek(0)<tab><tab>if self._storage.gzip and self.obj.content_encoding == ""gzip"":<tab><tab><tab>self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0)<tab>return self._file","if ""r"" in self . _mode :",184
3984,"def connect(self, host, port, timeout):<tab>fp = Telnet()<tab>for i in range(50):<tab><tab>try:<tab><tab><tab>fp.sock = socket.create_connection(<tab><tab><tab><tab>(host, int(port)), timeout=int(timeout), source_address=("""", 1023 - i)<tab><tab><tab>)<tab><tab><tab>break<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab>self.need_handshake = True<tab>return TCP_Connection(fp)","if ( e . errno , e . strerror ) != ( 98 , ""Address already in use"" ) :",145
3985,"def filtercomments(source):<tab>""""""NOT USED: strips trailing comments and put them at the top.""""""<tab>trailing_comments = []<tab>comment = True<tab>while comment:<tab><tab>if re.search(r""^\s*\/\*"", source):<tab><tab><tab>comment = source[0, source.index(""*/"") + 2]<tab><tab><IF-STMT><tab><tab><tab>comment = re.search(r""^\s*\/\/"", source).group(0)<tab><tab>else:<tab><tab><tab>comment = None<tab><tab>if comment:<tab><tab><tab>source = re.sub(r""^\s+"", """", source[len(comment) :])<tab><tab><tab>trailing_comments.append(comment)<tab>return ""\n"".join(trailing_comments) + source","elif re . search ( r""^\s*\/\/"" , source ) :",179
3986,"def yview(self, mode=None, value=None, units=None):<tab>if type(value) == str:<tab><tab>value = float(value)<tab>if mode is None:<tab><tab>return self.vsb.get()<tab>elif mode == ""moveto"":<tab><tab>frameHeight = self.innerframe.winfo_reqheight()<tab><tab>self._startY = value * float(frameHeight)<tab>else:  # mode == 'scroll'<tab><tab>clipperHeight = self._clipper.winfo_height()<tab><tab><IF-STMT><tab><tab><tab>jump = int(clipperHeight * self._jfraction)<tab><tab>else:<tab><tab><tab>jump = clipperHeight<tab><tab>self._startY = self._startY + value * jump<tab>self.reposition()","if units == ""units"" :",181
3987,"def visit(stmt):<tab>""""""Collect information about VTCM buffers and their alignments.""""""<tab>if isinstance(stmt, tvm.tir.AttrStmt):<tab><tab>if stmt.attr_key == ""storage_scope"" and stmt.value == ""local.vtcm"":<tab><tab><tab>vtcm_buffers.append(stmt.node)<tab><tab><IF-STMT><tab><tab><tab>if not stmt.node in alignments:<tab><tab><tab><tab>alignments[stmt.node] = []<tab><tab><tab>alignments[stmt.node].append(stmt.value)","elif stmt . attr_key == ""storage_alignment"" :",133
3988,"def cost(P):<tab># wda loss<tab>loss_b = 0<tab>loss_w = 0<tab>for i, xi in enumerate(xc):<tab><tab>xi = np.dot(xi, P)<tab><tab>for j, xj in enumerate(xc[i:]):<tab><tab><tab>xj = np.dot(xj, P)<tab><tab><tab>M = dist(xi, xj)<tab><tab><tab>G = sinkhorn(wc[i], wc[j + i], M, reg, k)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>loss_w += np.sum(G * M)<tab><tab><tab>else:<tab><tab><tab><tab>loss_b += np.sum(G * M)<tab># loss inversed because minimization<tab>return loss_w / loss_b",if j == 0 :,187
3989,"def __init__(self, comm, in_channels, out_channels, ksize, pad=1):<tab>super(Block, self).__init__()<tab>with self.init_scope():<tab><tab><IF-STMT><tab><tab><tab>self.conv = ParallelConvolution2D(<tab><tab><tab><tab>comm, in_channels, out_channels, ksize, pad=pad, nobias=True<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.conv = chainer.links.Convolution2D(<tab><tab><tab><tab>in_channels, out_channels, ksize, pad=pad, nobias=True<tab><tab><tab>)<tab><tab>self.bn = L.BatchNormalization(out_channels)",if comm . size <= in_channels :,164
3990,"def halfMultipartScore(nzb_name):<tab>try:<tab><tab>wrong_found = 0<tab><tab>for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]:<tab><tab><tab>for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>wrong_found += 1<tab><tab>if wrong_found == 1:<tab><tab><tab>return -30<tab><tab>return 0<tab>except:<tab><tab>log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc())<tab>return 0","if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :",183
3991,"def should_include(service):<tab>for f in filt:<tab><tab><IF-STMT><tab><tab><tab>state = filt[f]<tab><tab><tab>containers = project.containers([service.name], stopped=True)<tab><tab><tab>if not has_container_with_state(containers, state):<tab><tab><tab><tab>return False<tab><tab>elif f == ""source"":<tab><tab><tab>source = filt[f]<tab><tab><tab>if source == ""image"" or source == ""build"":<tab><tab><tab><tab>if source not in service.options:<tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>raise UserError(""Invalid value for source filter: %s"" % source)<tab><tab>else:<tab><tab><tab>raise UserError(""Invalid filter: %s"" % f)<tab>return True","if f == ""status"" :",184
3992,"def get_blob_type_declaration_sql(self, column):<tab>length = column.get(""length"")<tab>if length:<tab><tab>if length <= self.LENGTH_LIMIT_TINYBLOB:<tab><tab><tab>return ""TINYBLOB""<tab><tab><IF-STMT><tab><tab><tab>return ""BLOB""<tab><tab>if length <= self.LENGTH_LIMIT_MEDIUMBLOB:<tab><tab><tab>return ""MEDIUMBLOB""<tab>return ""LONGBLOB""",if length <= self . LENGTH_LIMIT_BLOB :,115
3993,"def click_outside(event):<tab>if event not in d:<tab><tab>x, y, z = self.blockFaceUnderCursor[0]<tab><tab><IF-STMT><tab><tab><tab>y = 64<tab><tab>y += 3<tab><tab>gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z<tab><tab>if event.num_clicks == 2:<tab><tab><tab>d.dismiss(""Goto"")",if y == 0 :,100
3994,"def check_related_active_jobs(self, obj):<tab>active_jobs = obj.get_active_jobs()<tab>if len(active_jobs) > 0:<tab><tab>raise ActiveJobConflict(active_jobs)<tab>time_cutoff = now() - dateutil.relativedelta.relativedelta(minutes=1)<tab>recent_jobs = obj._get_related_jobs().filter(finished__gte=time_cutoff)<tab>for unified_job in recent_jobs.get_real_instances():<tab><tab><IF-STMT><tab><tab><tab>raise PermissionDenied(<tab><tab><tab><tab>_(""Related job {} is still processing events."").format(<tab><tab><tab><tab><tab>unified_job.log_format<tab><tab><tab><tab>)<tab><tab><tab>)",if not unified_job . event_processing_finished :,176
3995,"def run(self):<tab>self.alive = True<tab>if _log.isEnabledFor(_DEBUG):<tab><tab>_log.debug(""started"")<tab>while self.alive:<tab><tab>task = self.queue.get()<tab><tab><IF-STMT><tab><tab><tab>function, args, kwargs = task<tab><tab><tab>assert function<tab><tab><tab>try:<tab><tab><tab><tab>function(*args, **kwargs)<tab><tab><tab>except:<tab><tab><tab><tab>_log.exception(""calling %s"", function)<tab>if _log.isEnabledFor(_DEBUG):<tab><tab>_log.debug(""stopped"")",if task :,134
3996,"def update_sysconfig_file(fn, adjustments, allow_empty=False):<tab>if not adjustments:<tab><tab>return<tab>(exists, contents) = read_sysconfig_file(fn)<tab>updated_am = 0<tab>for (k, v) in adjustments.items():<tab><tab>if v is None:<tab><tab><tab>continue<tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>contents[k] = v<tab><tab>updated_am += 1<tab>if updated_am:<tab><tab>lines = [<tab><tab><tab>str(contents),<tab><tab>]<tab><tab>if not exists:<tab><tab><tab>lines.insert(0, util.make_header())<tab><tab>util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",if len ( v ) == 0 and not allow_empty :,198
3997,"def wrapper(  # type: ignore<tab>self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]:<tab>if self.request.path.endswith(""/""):<tab><tab>if self.request.method in (""GET"", ""HEAD""):<tab><tab><tab>uri = self.request.path.rstrip(""/"")<tab><tab><tab><IF-STMT>  # don't try to redirect '/' to ''<tab><tab><tab><tab>if self.request.query:<tab><tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)",if uri :,163
3998,def output_handles_from_execution_plan(execution_plan):<tab>output_handles_for_current_run = set()<tab>for step_level in execution_plan.execution_step_levels():<tab><tab>for step in step_level:<tab><tab><tab>for step_input in step.step_inputs:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>output_handles_for_current_run.update(step_input.source_handles)<tab>return output_handles_for_current_run,if step_input . source_handles :,124
3999,"def _read_value(self, item):<tab>item = _normalize_path(item)<tab>if item in self._store:<tab><tab><IF-STMT><tab><tab><tab>del self._store[item]<tab><tab><tab>raise KeyError(item)<tab><tab>return PathResult(item, value=self._store[item])<tab>elif item in self._children:<tab><tab>return PathResult(item, dir=True)<tab>else:<tab><tab>raise KeyError(item)",if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,125
4000,"def _line_ranges(statements, lines):<tab>""""""Produce a list of ranges for `format_lines`.""""""<tab>statements = sorted(statements)<tab>lines = sorted(lines)<tab>pairs = []<tab>start = None<tab>lidx = 0<tab>for stmt in statements:<tab><tab>if lidx >= len(lines):<tab><tab><tab>break<tab><tab>if stmt == lines[lidx]:<tab><tab><tab>lidx += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = stmt<tab><tab><tab>end = stmt<tab><tab>elif start:<tab><tab><tab>pairs.append((start, end))<tab><tab><tab>start = None<tab>if start:<tab><tab>pairs.append((start, end))<tab>return pairs",if not start :,167
4001,"def _update_help_obj_params(help_obj, data_params, params_equal, attr_key_tups):<tab>loaded_params = []<tab>for param_obj in help_obj.parameters:<tab><tab>loaded_param = next(<tab><tab><tab>(n for n in data_params if params_equal(param_obj, n)), None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>BaseHelpLoader._update_obj_from_data_dict(<tab><tab><tab><tab>param_obj, loaded_param, attr_key_tups<tab><tab><tab>)<tab><tab>loaded_params.append(param_obj)<tab>help_obj.parameters = loaded_params",if loaded_param :,159
4002,"def __get_ratio(self):<tab>""""""Return splitter ratio of the main splitter.""""""<tab>c = self.c<tab>free_layout = c.free_layout<tab>if free_layout:<tab><tab>w = free_layout.get_main_splitter()<tab><tab><IF-STMT><tab><tab><tab>aList = w.sizes()<tab><tab><tab>if len(aList) == 2:<tab><tab><tab><tab>n1, n2 = aList<tab><tab><tab><tab># 2017/06/07: guard against division by zero.<tab><tab><tab><tab>ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2)<tab><tab><tab><tab>return ratio<tab>return 0.5",if w :,170
4003,"def _check_required_env_variables(vars):<tab>for var in vars:<tab><tab><IF-STMT><tab><tab><tab>self.tc.logger.error(<tab><tab><tab><tab>""%s is not set. Did you forget to source your build environment setup script?""<tab><tab><tab><tab>% var<tab><tab><tab>)<tab><tab><tab>raise OEQAPreRun",if not os . environ . get ( var ) :,89
4004,"def clean_indexes():<tab>for coll_name in mongo.collection_types.keys():<tab><tab>coll = mongo.get_collection(coll_name)<tab><tab>indexes = coll_indexes[coll_name]<tab><tab>try:<tab><tab><tab>for index in coll.list_indexes():<tab><tab><tab><tab>name = index[""name""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>coll.drop_index(name)<tab><tab>except pymongo.errors.OperationFailure:<tab><tab><tab>pass","if name == ""_id"" or name == ""_id_"" or name in indexes :",140
4005,"def _compare_dirs(self, dir1, dir2):<tab># check that dir1 and dir2 are equivalent,<tab># return the diff<tab>diff = []<tab>for root, dirs, files in os.walk(dir1):<tab><tab>for file_ in files:<tab><tab><tab>path = os.path.join(root, file_)<tab><tab><tab>target_path = os.path.join(dir2, os.path.split(path)[-1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diff.append(file_)<tab>return diff",if not os . path . exists ( target_path ) :,138
4006,"def load_state_dict(self, state_dict, strict=True):<tab>""""""Customized load.""""""<tab>self.language_model.load_state_dict(<tab><tab>state_dict[self._language_model_key], strict=strict<tab>)<tab>if mpu.is_pipeline_last_stage():<tab><tab><IF-STMT><tab><tab><tab>self.multichoice_head.load_state_dict(<tab><tab><tab><tab>state_dict[self._multichoice_head_key], strict=strict<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>print_rank_last(<tab><tab><tab><tab>""***WARNING*** could not find {} in the checkpoint, ""<tab><tab><tab><tab>""initializing to random"".format(self._multichoice_head_key)<tab><tab><tab>)",if self . _multichoice_head_key in state_dict :,197
4007,"def _parse_timedelta(self, value):<tab>try:<tab><tab>sum = datetime.timedelta()<tab><tab>start = 0<tab><tab>while start < len(value):<tab><tab><tab>m = self._TIMEDELTA_PATTERN.match(value, start)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception()<tab><tab><tab>num = float(m.group(1))<tab><tab><tab>units = m.group(2) or ""seconds""<tab><tab><tab>units = self._TIMEDELTA_ABBREV_DICT.get(units, units)<tab><tab><tab>sum += datetime.timedelta(**{units: num})<tab><tab><tab>start = m.end()<tab><tab>return sum<tab>except:<tab><tab>raise",if not m :,165
4008,"def SetChildMenuBar(self, pChild):<tab>if not pChild:<tab><tab># No Child, set Our menu bar back.<tab><tab>if self._pMyMenuBar:<tab><tab><tab>self.SetMenuBar(self._pMyMenuBar)<tab><tab>else:<tab><tab><tab>self.SetMenuBar(self.GetMenuBar())<tab><tab># Make sure we know our menu bar is in use<tab><tab>self._pMyMenuBar = None<tab>else:<tab><tab>if pChild.GetMenuBar() is None:<tab><tab><tab>return<tab><tab># Do we need to save the current bar?<tab><tab><IF-STMT><tab><tab><tab>self._pMyMenuBar = self.GetMenuBar()<tab><tab>self.SetMenuBar(pChild.GetMenuBar())",if self . _pMyMenuBar is None :,188
4009,"def init_weights(self):<tab>""""""Initialize weights of the head.""""""<tab># retinanet_bias_init<tab>bias_cls = bias_init_with_prob(0.01)<tab>normal_init(self.conv_reg, std=0.01)<tab>normal_init(self.conv_centerness, std=0.01)<tab>normal_init(self.conv_cls, std=0.01, bias=bias_cls)<tab>for branch in [self.cls_convs, self.reg_convs]:<tab><tab>for module in branch.modules():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>caffe2_xavier_init(module.conv)","if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :",178
4010,"def handle_exception(self, e, result):<tab>for k in sorted(result.thrift_spec):<tab><tab>if result.thrift_spec[k][1] == ""success"":<tab><tab><tab>continue<tab><tab>_, exc_name, exc_cls, _ = result.thrift_spec[k]<tab><tab><IF-STMT><tab><tab><tab>setattr(result, exc_name, e)<tab><tab><tab>break<tab>else:<tab><tab>raise","if isinstance ( e , exc_cls ) :",115
4011,"def scripts(self):<tab>application_root = current_app.config.get(""APPLICATION_ROOT"")<tab>subdir = application_root != ""/""<tab>scripts = []<tab>for script in get_registered_scripts():<tab><tab><IF-STMT><tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab><tab>elif subdir:<tab><tab><tab>scripts.append(f'<script defer src=""{application_root}/{script}""></script>')<tab><tab>else:<tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab>return markup(""\n"".join(scripts))","if script . startswith ( ""http"" ) :",146
4012,"def test_related_objects_local(self):<tab>result_key = ""get_all_related_objects_with_model_local""<tab>for model, expected in TEST_RESULTS[result_key].items():<tab><tab>objects = [<tab><tab><tab>(field, self._model(model, field))<tab><tab><tab>for field in model._meta.get_fields(include_parents=False)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>self.assertEqual(<tab><tab><tab>sorted(self._map_related_query_names(objects), key=self.key_name),<tab><tab><tab>sorted(expected, key=self.key_name),<tab><tab>)",if field . auto_created and not field . concrete,164
4013,"def setTestOutcome(self, event):<tab>""""""Update outcome, exc_info and reason based on configured mappings""""""<tab>if event.exc_info:<tab><tab>ec, ev, tb = event.exc_info<tab><tab>classname = ec.__name__<tab><tab>if classname in self.treatAsFail:<tab><tab><tab>short, long_ = self.labels(classname)<tab><tab><tab>self._setOutcome(event, ""failed"", short, long_)<tab><tab><IF-STMT><tab><tab><tab>short, long_ = self.labels(classname, upper=False)<tab><tab><tab>self._setOutcome(event, ""skipped"", short, ""%s: '%s'"" % (long_, ev), str(ev))",elif classname in self . treatAsSkip :,169
4014,"def small_count(v):<tab>if not v:<tab><tab>return 0<tab>z = [<tab><tab>(1000000000, _(""b"")),<tab><tab>(1000000, _(""m"")),<tab><tab>(1000, _(""k"")),<tab>]<tab>v = int(v)<tab>for x, y in z:<tab><tab>o, p = divmod(v, x)<tab><tab>if o:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""%d%s"" % (o, y)<tab><tab><tab>return ""%.1f%s"" % (v / float(x), y)<tab>return v",if len ( str ( o ) ) > 2 or not p :,149
4015,"def __read(self, n):<tab>if self._read_watcher is None:<tab><tab>raise UnsupportedOperation(""read"")<tab>while 1:<tab><tab>try:<tab><tab><tab>return _read(self._fileno, n)<tab><tab>except (IOError, OSError) as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>wait_on_watcher(self._read_watcher, None, None, self.hub)",if ex . args [ 0 ] not in ignored_errors :,111
4016,"def locked(self):<tab>inputfiles = set(self.all_inputfiles())<tab>outputfiles = set(self.all_outputfiles())<tab>if os.path.exists(self._lockdir):<tab><tab>for lockfile in self._locks(""input""):<tab><tab><tab>with open(lockfile) as lock:<tab><tab><tab><tab>for f in lock:<tab><tab><tab><tab><tab>f = f.strip()<tab><tab><tab><tab><tab>if f in outputfiles:<tab><tab><tab><tab><tab><tab>return True<tab><tab>for lockfile in self._locks(""output""):<tab><tab><tab>with open(lockfile) as lock:<tab><tab><tab><tab>for f in lock:<tab><tab><tab><tab><tab>f = f.strip()<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False",if f in outputfiles or f in inputfiles :,195
4017,"def _flags_to_int(flags):<tab># Note, that order does not matter, libev has its own predefined order<tab>if not flags:<tab><tab>return 0<tab>if isinstance(flags, integer_types):<tab><tab>return flags<tab>result = 0<tab>try:<tab><tab><IF-STMT><tab><tab><tab>flags = flags.split("","")<tab><tab>for value in flags:<tab><tab><tab>value = value.strip().lower()<tab><tab><tab>if value:<tab><tab><tab><tab>result |= _flags_str2int[value]<tab>except KeyError as ex:<tab><tab>raise ValueError(<tab><tab><tab>""Invalid backend or flag: %s\nPossible values: %s""<tab><tab><tab>% (ex, "", "".join(sorted(_flags_str2int.keys())))<tab><tab>)<tab>return result","if isinstance ( flags , basestring ) :",191
4018,"def setFg(self, colour, override=False):<tab>if not self.ttkFlag:<tab><tab>self.containerStack[-1][""fg""] = colour<tab><tab>gui.SET_WIDGET_FG(self._getContainerProperty(""container""), colour, override)<tab><tab>for child in self._getContainerProperty(""container"").winfo_children():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>gui.SET_WIDGET_FG(child, colour, override)<tab>else:<tab><tab>gui.trace(""In ttk mode - trying to set FG to %s"", colour)<tab><tab>self.ttkStyle.configure(""TLabel"", foreground=colour)<tab><tab>self.ttkStyle.configure(""TFrame"", foreground=colour)",if not self . _isWidgetContainer ( child ) :,178
4019,"def find_scintilla_constants(f):<tab>lexers = []<tab>states = []<tab>for name in f.order:<tab><tab>v = f.features[name]<tab><tab>if v[""Category""] != ""Deprecated"":<tab><tab><tab>if v[""FeatureType""] == ""val"":<tab><tab><tab><tab>if name.startswith(""SCE_""):<tab><tab><tab><tab><tab>states.append((name, v[""Value""]))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>lexers.append((name, v[""Value""]))<tab>return (lexers, states)","elif name . startswith ( ""SCLEX_"" ) :",137
4020,"def extract_error_message(response: requests.Response):<tab>if response.content:<tab><tab>try:<tab><tab><tab>content = json.loads(response.content)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return content[""message""]<tab><tab>except:<tab><tab><tab>logging.debug(f""Failed to parse the response content: {response.content}"")<tab>return response.reason","if ""message"" in content :",94
4021,"def canvas_size(self):<tab>""""""Return the width and height for this sprite canvas""""""<tab>width = height = 0<tab>for image in self.images:<tab><tab>x = image.x + image.absolute_width<tab><tab>y = image.y + image.absolute_height<tab><tab><IF-STMT><tab><tab><tab>width = x<tab><tab>if height < y:<tab><tab><tab>height = y<tab>return round_up(width), round_up(height)",if width < x :,110
4022,"def _load_widgets(self):<tab>logger.info(""Loading plugins preferences widgets"")<tab># Collect the preferences widget for each active plugin<tab>for plugin in self.plugin_manager.get_active_plugins():<tab><tab>plugin_name = plugin.metadata.get(""name"")<tab><tab>try:<tab><tab><tab>preferences_widget = plugin.get_preferences_widget()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._tabs.addTab(preferences_widget, plugin_name)<tab><tab>except Exception as reason:<tab><tab><tab>logger.error(<tab><tab><tab><tab>""Unable to add the preferences widget (%s): %s"", plugin_name, reason<tab><tab><tab>)<tab><tab><tab>continue",if preferences_widget :,162
4023,"def clean_objects(string, common_attributes):<tab>""""""Return object and attribute lists""""""<tab>string = clean_string(string)<tab>words = string.split()<tab>if len(words) > 1:<tab><tab>prefix_words_are_adj = True<tab><tab>for att in words[:-1]:<tab><tab><tab>if att not in common_attributes:<tab><tab><tab><tab>prefix_words_are_adj = False<tab><tab><IF-STMT><tab><tab><tab>return words[-1:], words[:-1]<tab><tab>else:<tab><tab><tab>return [string], []<tab>else:<tab><tab>return [string], []",if prefix_words_are_adj :,148
4024,"def _reader():<tab>if shuffle:<tab><tab>random.shuffle(file_list)<tab>while True:<tab><tab>for fn in file_list:<tab><tab><tab>for line in open(fn, ""r""):<tab><tab><tab><tab>yield self._process_line(line)<tab><tab><IF-STMT><tab><tab><tab>break",if not cycle :,76
4025,"def load(weights, model, K, fsz, dil):<tab>index = 0<tab>layers = model.layers<tab>for layer in layers._layers:<tab><tab><IF-STMT><tab><tab><tab>if layer.W.shape == weights[index].shape:<tab><tab><tab><tab>layer.W[:] = weights[index]<tab><tab><tab>else:<tab><tab><tab><tab>layer.W[:] = dilate(weights[index], K, fsz, dil)<tab><tab><tab>index += 1","if hasattr ( layer , ""W"" ) :",115
4026,"def upgrade(migrate_engine):<tab>print(__doc__)<tab>metadata.bind = migrate_engine<tab>liftoverjobs = dict()<tab>jobs = context.query(DeferredJob).filter_by(plugin=""LiftOverTransferPlugin"").all()<tab>for job in jobs:<tab><tab><IF-STMT><tab><tab><tab>liftoverjobs[job.params[""parentjob""]] = []<tab><tab>liftoverjobs[job.params[""parentjob""]].append(job.id)<tab>for parent in liftoverjobs:<tab><tab>lifts = liftoverjobs[parent]<tab><tab>deferred = context.query(DeferredJob).filter_by(id=parent).first()<tab><tab>deferred.params[""liftover""] = lifts<tab>context.flush()","if job . params [ ""parentjob"" ] not in liftoverjobs :",182
4027,"def get_refs(self, recursive=False):<tab>"""""":see: AbstractExpression.get_refs()""""""<tab>if recursive:<tab><tab>conds_refs = self.refs + sum((c.get_refs(True) for c in self.conds), [])<tab><tab><IF-STMT><tab><tab><tab>conds_refs.extend(self.consequent.get_refs(True))<tab><tab>return conds_refs<tab>else:<tab><tab>return self.refs",if self . consequent :,105
4028,"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab><IF-STMT><tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab>if not isinstance(self.axis, int):<tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab>if ""momentum"" in self.args:<tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab>if not isinstance(self.momentum, (int, float)):<tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')","if ""axis"" in self . args :",157
4029,"def CountMatches(pat, predicate):<tab>num_matches = 0<tab>for i in xrange(256):<tab><tab>b = chr(i)<tab><tab>m = pat.match(b)<tab><tab>left = bool(m)<tab><tab>right = predicate(i)<tab><tab>if left != right:<tab><tab><tab>self.fail(""i = %d, b = %r, match: %s, predicate: %s"" % (i, b, left, right))<tab><tab><IF-STMT><tab><tab><tab>num_matches += 1<tab>return num_matches",if m :,131
4030,"def __new__(cls, *args, **kwargs):<tab>if len(args) == 1:<tab><tab>if len(kwargs):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""You can either use {} with one positional argument or with keyword arguments, not both."".format(<tab><tab><tab><tab><tab>cls.__name__<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>if not args[0]:<tab><tab><tab>return super().__new__(cls)<tab><tab><IF-STMT><tab><tab><tab>return cls<tab>return super().__new__(cls, *args, **kwargs)","if isinstance ( args [ 0 ] , cls ) :",137
4031,"def concatenateCharacterTokens(tokens):<tab>pendingCharacters = []<tab>for token in tokens:<tab><tab>type = token[""type""]<tab><tab>if type in (""Characters"", ""SpaceCharacters""):<tab><tab><tab>pendingCharacters.append(token[""data""])<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)}<tab><tab><tab><tab>pendingCharacters = []<tab><tab><tab>yield token<tab>if pendingCharacters:<tab><tab>yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)}",if pendingCharacters :,130
4032,"def get_ranges_from_func_set(support_set):<tab>pos_start = 0<tab>pos_end = 0<tab>ranges = []<tab>for pos, func in enumerate(network.function):<tab><tab>if func.type in support_set:<tab><tab><tab>pos_end = pos<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ranges.append((pos_start, pos_end))<tab><tab><tab>pos_start = pos + 1<tab>if pos_end >= pos_start:<tab><tab>ranges.append((pos_start, pos_end))<tab>return ranges",if pos_end >= pos_start :,145
4033,"def _visit(self, func):<tab>fname = func[0]<tab>if fname in self._flags:<tab><tab><IF-STMT><tab><tab><tab>logger.critical(""Fatal error! network ins not Dag."")<tab><tab><tab>import sys<tab><tab><tab>sys.exit(-1)<tab><tab>else:<tab><tab><tab>return<tab>else:<tab><tab>if fname not in self._flags:<tab><tab><tab>self._flags[fname] = 1<tab><tab>for output in func[3]:<tab><tab><tab>for f in self._orig:<tab><tab><tab><tab>for input in f[2]:<tab><tab><tab><tab><tab>if output == input:<tab><tab><tab><tab><tab><tab>self._visit(f)<tab>self._flags[fname] = 2<tab>self._sorted.insert(0, func)",if self . _flags [ fname ] == 1 :,188
4034,"def graph_merge_softmax_with_crossentropy_softmax(node):<tab>if node.op == softmax_with_bias:<tab><tab>x, b = node.inputs<tab><tab>for x_client in x.clients:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>big_client = x_client[0]<tab><tab><tab><tab>if big_client in [b_client[0] for b_client in b.clients]:<tab><tab><tab><tab><tab>xx, bb, ll = big_client.inputs<tab><tab><tab><tab><tab>mergeable_client = big_client.op(x, b, ll)<tab><tab><tab><tab><tab>copy_stack_trace(node.outputs[0], mergeable_client[1])<tab><tab><tab><tab><tab>return [mergeable_client[1]]",if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias :,199
4035,"def confidence(self):<tab>if self.bbox:<tab><tab># Units are measured in Kilometers<tab><tab>distance = Distance(self.northeast, self.southwest, units=""km"")<tab><tab>for score, maximum in [<tab><tab><tab>(10, 0.25),<tab><tab><tab>(9, 0.5),<tab><tab><tab>(8, 1),<tab><tab><tab>(7, 5),<tab><tab><tab>(6, 7.5),<tab><tab><tab>(5, 10),<tab><tab><tab>(4, 15),<tab><tab><tab>(3, 20),<tab><tab><tab>(2, 25),<tab><tab>]:<tab><tab><tab>if distance < maximum:<tab><tab><tab><tab>return score<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 1<tab># Cannot determine score<tab>return 0",if distance >= 25 :,192
4036,"def OnListEndLabelEdit(self, std, extra):<tab>item = extra[0]<tab>text = item[4]<tab>if text is None:<tab><tab>return<tab>item_id = self.GetItem(item[0])[6]<tab>from bdb import Breakpoint<tab>for bplist in Breakpoint.bplist.itervalues():<tab><tab>for bp in bplist:<tab><tab><tab>if id(bp) == item_id:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>text = None<tab><tab><tab><tab>bp.cond = text<tab><tab><tab><tab>break<tab>self.RespondDebuggerData()","if text . strip ( ) . lower ( ) == ""none"" :",151
4037,"def _handle_autocomplete_request_for_text(text):<tab>if not hasattr(text, ""autocompleter""):<tab><tab><IF-STMT><tab><tab><tab>if isinstance(text, CodeViewText):<tab><tab><tab><tab>text.autocompleter = Completer(text)<tab><tab><tab>elif isinstance(text, ShellText):<tab><tab><tab><tab>text.autocompleter = ShellCompleter(text)<tab><tab><tab>text.bind(""<1>"", text.autocompleter.on_text_click)<tab><tab>else:<tab><tab><tab>return<tab>text.autocompleter.handle_autocomplete_request()","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :",151
4038,"def visit_Macro(self, node, frame):<tab>macro_frame, macro_ref = self.macro_body(node, frame)<tab>self.newline()<tab>if frame.toplevel:<tab><tab><IF-STMT><tab><tab><tab>self.write(""context.exported_vars.add(%r)"" % node.name)<tab><tab>ref = frame.symbols.ref(node.name)<tab><tab>self.writeline(""context.vars[%r] = "" % node.name)<tab>self.write(""%s = "" % frame.symbols.ref(node.name))<tab>self.macro_def(macro_ref, macro_frame)","if not node . name . startswith ( ""_"" ) :",150
4039,"def execute(cls, ctx, op):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab><IF-STMT><tab><tab><tab>return cls._execute_map(ctx, op)<tab><tab>else:<tab><tab><tab>return cls._execute_combine(ctx, op)<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",if op . stage == OperandStage . map :,113
4040,"def ranges(self, start, end):<tab>try:<tab><tab>iterators = [i.ranges(start, end) for i in self.range_iterators]<tab><tab>starts, ends, values = zip(*[next(i) for i in iterators])<tab><tab>starts = list(starts)<tab><tab>ends = list(ends)<tab><tab>values = list(values)<tab><tab>while start < end:<tab><tab><tab>min_end = min(ends)<tab><tab><tab>yield start, min_end, values<tab><tab><tab>start = min_end<tab><tab><tab>for i, iterator in enumerate(iterators):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>starts[i], ends[i], values[i] = next(iterator)<tab>except StopIteration:<tab><tab>return",if ends [ i ] == min_end :,188
4041,"def get_explanation(self, spec):<tab>""""""Expand an explanation.""""""<tab>if spec:<tab><tab>try:<tab><tab><tab>a = self.dns_txt(spec)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return str(self.expand(to_ascii(a[0]), stripdot=False))<tab><tab>except PermError:<tab><tab><tab># RFC4408 6.2/4 syntax errors cause exp= to be ignored<tab><tab><tab>if self.strict > 1:<tab><tab><tab><tab>raise  # but report in harsh mode for record checking tools<tab><tab><tab>pass<tab>elif self.strict > 1:<tab><tab>raise PermError(""Empty domain-spec on exp="")<tab># RFC4408 6.2/4 empty domain spec is ignored<tab># (unless you give precedence to the grammar).<tab>return None",if len ( a ) == 1 :,200
4042,"def iter_fields(node, *, include_meta=True, exclude_unset=False):<tab>exclude_meta = not include_meta<tab>for field_name, field in node._fields.items():<tab><tab>if exclude_meta and field.meta:<tab><tab><tab>continue<tab><tab>field_val = getattr(node, field_name, _marker)<tab><tab>if field_val is _marker:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if callable(field.default):<tab><tab><tab><tab>default = field.default()<tab><tab><tab>else:<tab><tab><tab><tab>default = field.default<tab><tab><tab>if field_val == default:<tab><tab><tab><tab>continue<tab><tab>yield field_name, field_val",if exclude_unset :,171
4043,"def __setattr__(self, name, value):<tab>try:<tab><tab>field = self._meta.get_field(name)<tab><tab><IF-STMT><tab><tab><tab>value = value[: field.max_length]<tab>except models.fields.FieldDoesNotExist:<tab><tab>pass  # This happens with foreign keys.<tab>super.__setattr__(self, name, value)","if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str :",104
4044,"def create_child(self, value=None, _id=None):<tab>with atomic(savepoint=False):<tab><tab>child_key = self.get_next_child_key()<tab><tab><IF-STMT><tab><tab><tab>value = child_key<tab><tab>child = self.__class__.objects.create(id=_id, key=child_key, value=value)<tab><tab>return child",if value is None :,92
4045,"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None):<tab>stream = self.describe_stream(stream_name)<tab>tags = []<tab>result = {""HasMoreTags"": False, ""Tags"": tags}<tab>for key, val in sorted(stream.tags.items(), key=lambda x: x[0]):<tab><tab><IF-STMT><tab><tab><tab>result[""HasMoreTags""] = True<tab><tab><tab>break<tab><tab>if exclusive_start_tag_key and key < exclusive_start_tag_key:<tab><tab><tab>continue<tab><tab>tags.append({""Key"": key, ""Value"": val})<tab>return result",if limit and len ( tags ) >= limit :,166
4046,"def emit(self, record):<tab>try:<tab><tab>app = get_app()<tab><tab><IF-STMT><tab><tab><tab>msg = self.format(record)<tab><tab><tab>debug_buffer = app.layout.get_buffer_by_name(""debug_buffer"")<tab><tab><tab>current_document = debug_buffer.document.text<tab><tab><tab>if current_document:<tab><tab><tab><tab>msg = ""\n"".join([current_document, msg])<tab><tab><tab>debug_buffer.set_document(Document(text=msg), bypass_readonly=True)<tab><tab>else:<tab><tab><tab>super().emit(record)<tab>except:<tab><tab>self.handleError(record)","if app . is_running and getattr ( app , ""debug"" , False ) :",170
4047,"def worker():<tab>global error<tab>while True:<tab><tab>(num, q) = pq.get()<tab><tab><IF-STMT><tab><tab><tab>pq.task_done()<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>process_one(q)<tab><tab>except Exception as e:<tab><tab><tab>error = e<tab><tab>finally:<tab><tab><tab>pq.task_done()",if q is None or error is not None :,99
4048,"def transceiver(self, data):<tab>out = []<tab>for t in range(8):<tab><tab>if data[t] == 0:<tab><tab><tab>continue<tab><tab>value = data[t]<tab><tab>for b in range(8):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if len(TRANSCEIVER[t]) < b + 1:<tab><tab><tab><tab><tab>out.append(""(unknown)"")<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>out.append(TRANSCEIVER[t][b])<tab><tab><tab>value <<= 1<tab>self.annotate(""Transceiver compliance"", "", "".join(out))",if value & 0x80 :,155
4049,"def skip_to_close_match(self):<tab>nestedCount = 1<tab>while 1:<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab>ttype = tok[""style""]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>elif self.classifier.is_index_op(tok):<tab><tab><tab>tval = tok[""text""]<tab><tab><tab>if self.opHash.has_key(tval):<tab><tab><tab><tab>if self.opHash[tval][1] == 1:<tab><tab><tab><tab><tab>nestedCount += 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>nestedCount -= 1<tab><tab><tab><tab><tab>if nestedCount <= 0:<tab><tab><tab><tab><tab><tab>break",if ttype == SCE_PL_UNUSED :,176
4050,"def GenerateVector(self, hits, vector, level):<tab>""""""Generate possible hit vectors which match the rules.""""""<tab>for item in hits.get(level, []):<tab><tab>if vector:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if item > self.max_separation + vector[-1]:<tab><tab><tab><tab>break<tab><tab>new_vector = vector + [item]<tab><tab>if level + 1 == len(hits):<tab><tab><tab>yield new_vector<tab><tab>elif level + 1 < len(hits):<tab><tab><tab>for result in self.GenerateVector(hits, new_vector, level + 1):<tab><tab><tab><tab>yield result",if item < vector [ - 1 ] :,157
4051,"def __setattr__(self, name, value):<tab>if name == ""path"":<tab><tab><IF-STMT><tab><tab><tab>if value[0] != ""/"":<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>'The page path should always start with a slash (""/"").'<tab><tab><tab><tab>)<tab>elif name == ""load_time"":<tab><tab>if value and not isinstance(value, int):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Page load time must be specified in integer milliseconds.""<tab><tab><tab>)<tab>object.__setattr__(self, name, value)","if value and value != """" :",136
4052,"def awaitTermination(self, timeout=None):<tab>if self.scheduler is None:<tab><tab>raise RuntimeError(""StreamimgContext not started"")<tab>try:<tab><tab>deadline = time.time() + timeout if timeout is not None else None<tab><tab>while True:<tab><tab><tab>is_terminated = self._runOnce()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if self.batchCallback:<tab><tab><tab><tab>self.batchCallback()<tab>except KeyboardInterrupt:<tab><tab>pass<tab>finally:<tab><tab>self.sc.stop()<tab><tab>logger.info(""StreamingContext stopped successfully"")",if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,157
4053,"def stopbutton(self):<tab>if GPIOcontrol:<tab><tab>while mediastopbutton:<tab><tab><tab>time.sleep(0.25)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""Stopped"")<tab><tab><tab><tab>stop()",if not GPIO . input ( stoppushbutton ) :,64
4054,"def test_create_connection_timeout(self):<tab># Issue #9792: create_connection() should not recast timeout errors<tab># as generic socket errors.<tab>with self.mocked_socket_module():<tab><tab>try:<tab><tab><tab>socket.create_connection((HOST, 1234))<tab><tab>except socket.timeout:<tab><tab><tab>pass<tab><tab>except OSError as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>self.fail(""socket.timeout not raised"")",if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT :,135
4055,"def handle_exception_and_die(e):<tab>if hasattr(e, ""kind""):<tab><tab><IF-STMT><tab><tab><tab>sys.stderr.write(""ABORT: "" + e.msg + ""\n"")<tab><tab><tab>sys.exit(e.value)<tab><tab>elif e.kind == ""exit"":<tab><tab><tab>sys.stderr.write(""EXITING\n"")<tab><tab><tab>sys.exit(e.value)<tab>else:<tab><tab>print(str(e))<tab><tab>sys.exit(1)","if e . kind == ""die"" :",128
4056,"def gets(self, key):<tab>with self.client_pool.get_and_release(destroy_on_fail=True) as client:<tab><tab>try:<tab><tab><tab>return client.gets(key)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (None, None)<tab><tab><tab>else:<tab><tab><tab><tab>raise",if self . ignore_exc :,90
4057,"def _execute(self, options, args):<tab>if len(args) < 3:<tab><tab>raise CommandError(_(""Not enough arguments""))<tab>tag = fsn2text(args[0])<tab>value = fsn2text(args[1])<tab>paths = args[2:]<tab>songs = []<tab>for path in paths:<tab><tab>song = self.load_song(path)<tab><tab><IF-STMT><tab><tab><tab>raise CommandError(_(""Can not set %r"") % tag)<tab><tab>self.log(""Add %r to %r"" % (value, tag))<tab><tab>song.add(tag, value)<tab><tab>songs.append(song)<tab>self.save_songs(songs)",if not song . can_change ( tag ) :,169
4058,"def get_place_name(self, place_handle):<tab>""""""Obtain a place name""""""<tab>text = """"<tab>if place_handle:<tab><tab>place = self.dbstate.db.get_place_from_handle(place_handle)<tab><tab>if place:<tab><tab><tab>place_title = place_displayer.display(self.dbstate.db, place)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if len(place_title) > 25:<tab><tab><tab><tab><tab>text = place_title[:24] + ""...""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>text = place_title<tab>return text","if place_title != """" :",153
4059,"def _Determine_Do(self):<tab>self.applicable = 1<tab>self.value = os.environ.get(self.name, None)<tab>if self.value is None and black.configure.items.has_key(""buildType""):<tab><tab>buildType = black.configure.items[""buildType""].Get()<tab><tab><IF-STMT><tab><tab><tab>self.value = ""warn""<tab><tab>else:<tab><tab><tab>self.value = None<tab>self.determined = 1","if buildType == ""debug"" :",115
4060,"def bundle_directory(self, dirpath):<tab>""""""Bundle all modules/packages in the given directory.""""""<tab>dirpath = os.path.abspath(dirpath)<tab>for nm in os.listdir(dirpath):<tab><tab>nm = _u(nm)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>itempath = os.path.join(dirpath, nm)<tab><tab>if os.path.isdir(itempath):<tab><tab><tab>if os.path.exists(os.path.join(itempath, ""__init__.py"")):<tab><tab><tab><tab>self.bundle_package(itempath)<tab><tab>elif nm.endswith("".py""):<tab><tab><tab>self.bundle_module(itempath)","if nm . startswith ( ""."" ) :",160
4061,"def header_fields(self, fields):<tab>headers = dict(self.conn.response.getheaders())<tab>ret = {}<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""%s was not found in response header"" % (field[1]))<tab><tab>try:<tab><tab><tab>ret[field[0]] = int(headers[field[1]])<tab><tab>except ValueError:<tab><tab><tab>ret[field[0]] = headers[field[1]]<tab>return ret",if not headers . has_key ( field [ 1 ] ) :,124
4062,"def caesar_cipher(s, k):<tab>result = """"<tab>for char in s:<tab><tab>n = ord(char)<tab><tab><IF-STMT><tab><tab><tab>n = ((n - 65 + k) % 26) + 65<tab><tab>if 96 < n < 123:<tab><tab><tab>n = ((n - 97 + k) % 26) + 97<tab><tab>result = result + chr(n)<tab>return result",if 64 < n < 91 :,104
4063,"def qtTypeIdent(conn, *args):<tab># We're not using the conn object at the moment, but - we will<tab># modify the<tab># logic to use the server version specific keywords later.<tab>res = None<tab>value = None<tab>for val in args:<tab><tab># DataType doesn't have len function then convert it to string<tab><tab>if not hasattr(val, ""__len__""):<tab><tab><tab>val = str(val)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = val<tab><tab>if Driver.needsQuoting(val, True):<tab><tab><tab>value = value.replace('""', '""""')<tab><tab><tab>value = '""' + value + '""'<tab><tab>res = ((res and res + ""."") or """") + value<tab>return res",if len ( val ) == 0 :,181
4064,"def _parse_timezone(<tab>value: Optional[str], error: Type[Exception]) -> Union[None, int, timezone]:<tab>if value == ""Z"":<tab><tab>return timezone.utc<tab>elif value is not None:<tab><tab>offset_mins = int(value[-2:]) if len(value) > 3 else 0<tab><tab>offset = 60 * int(value[1:3]) + offset_mins<tab><tab><IF-STMT><tab><tab><tab>offset = -offset<tab><tab>try:<tab><tab><tab>return timezone(timedelta(minutes=offset))<tab><tab>except ValueError:<tab><tab><tab>raise error()<tab>else:<tab><tab>return None","if value [ 0 ] == ""-"" :",153
4065,"def indent(elem, level=0):<tab>i = ""\n"" + level * ""  ""<tab>if len(elem):<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab>if level and (not elem.tail or not elem.tail.strip()):<tab><tab><tab>elem.tail = i",if not elem . tail or not elem . tail . strip ( ) :,161
4066,"def _make_slices(<tab>shape: tp.Tuple[int, ...],<tab>axes: tp.Tuple[int, ...],<tab>size: int,<tab>rng: np.random.RandomState,) -> tp.List[slice]:<tab>slices = []<tab>for a, s in enumerate(shape):<tab><tab>if a in axes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Cannot crossover on axis with size 1"")<tab><tab><tab>start = rng.randint(s - size)<tab><tab><tab>slices.append(slice(start, start + size))<tab><tab>else:<tab><tab><tab>slices.append(slice(None))<tab>return slices",if s <= 1 :,154
4067,"def _loadTestsFromTestCase(self, event, testCaseClass):<tab>evt = events.LoadFromTestCaseEvent(event.loader, testCaseClass)<tab>result = self.session.hooks.loadTestsFromTestCase(evt)<tab>if evt.handled:<tab><tab>loaded_suite = result or event.loader.suiteClass()<tab>else:<tab><tab>names = self._getTestCaseNames(event, testCaseClass)<tab><tab><IF-STMT><tab><tab><tab>names = [""runTest""]<tab><tab># FIXME return failure test case if name not in testcase class<tab><tab>loaded_suite = event.loader.suiteClass(map(testCaseClass, names))<tab>if evt.extraTests:<tab><tab>loaded_suite.addTests(evt.extraTests)<tab>return loaded_suite","if not names and hasattr ( testCaseClass , ""runTest"" ) :",185
4068,"def check_settings(self):<tab>if self.settings_dict[""TIME_ZONE""] is not None:<tab><tab>if not settings.USE_TZ:<tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because USE_TZ is ""<tab><tab><tab><tab>""False."" % self.alias<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because its engine ""<tab><tab><tab><tab>""handles time zones conversions natively."" % self.alias<tab><tab><tab>)",elif self . features . supports_timezones :,140
4069,"def collect_conflicting_diffs(path, decisions):<tab>local_conflict_diffs = []<tab>remote_conflict_diffs = []<tab>for d in decisions:<tab><tab><IF-STMT><tab><tab><tab>ld = adjust_patch_level(path, d.common_path, d.local_diff)<tab><tab><tab>rd = adjust_patch_level(path, d.common_path, d.remote_diff)<tab><tab><tab>local_conflict_diffs.extend(ld)<tab><tab><tab>remote_conflict_diffs.extend(rd)<tab>return local_conflict_diffs, remote_conflict_diffs",if d . conflict :,140
4070,"def short_repr(obj):<tab>if isinstance(<tab><tab>obj,<tab><tab>(type, types.ModuleType, types.BuiltinMethodType, types.BuiltinFunctionType),<tab>):<tab><tab>return obj.__name__<tab>if isinstance(obj, types.MethodType):<tab><tab><IF-STMT><tab><tab><tab>return obj.im_func.__name__ + "" (bound)""<tab><tab>else:<tab><tab><tab>return obj.im_func.__name__<tab>if isinstance(obj, (tuple, list, dict, set)):<tab><tab>return ""%d items"" % len(obj)<tab>if isinstance(obj, weakref.ref):<tab><tab>return ""all_weakrefs_are_one""<tab>return repr(obj)[:40]",if obj . im_self is not None :,172
4071,"def _massage_uri(uri):<tab>if uri:<tab><tab><IF-STMT><tab><tab><tab>uri = uri.replace(""hdfs://"", get_defaultfs())<tab><tab>elif uri.startswith(""/""):<tab><tab><tab>uri = get_defaultfs() + uri<tab>return uri","if uri . startswith ( ""hdfs:///"" ) :",68
4072,"def chsub(self, msg, chatid):<tab>(cmd, evt, params) = self.tokenize(msg, 3)<tab>if cmd == ""/sub"":<tab><tab>sql = ""replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?)""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>sql = ""delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1)""  # does not look very elegant, but makes unsub'ing everythign possible<tab><tab>else:<tab><tab><tab>sql = ""delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ?""<tab>with self.bot.database as conn:<tab><tab>conn.execute(sql, [chatid, evt, params])<tab><tab>conn.commit()<tab>return","if evt == ""everything"" :",196
4073,"def undefined_symbols(self):<tab>result = []<tab>for p in self.Productions:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for s in p.prod:<tab><tab><tab>if not s in self.Prodnames and not s in self.Terminals and s != ""error"":<tab><tab><tab><tab>result.append((s, p))<tab>return result",if not p :,88
4074,"def renumber(self, x1, y1, x2, y2, dx, dy):<tab>out = []<tab>for part in re.split(""(\w+)"", self.formula):<tab><tab>m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part)<tab><tab>if m is not None:<tab><tab><tab>sx, sy = m.groups()<tab><tab><tab>x = colname2num(sx)<tab><tab><tab>y = int(sy)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>part = cellname(x + dx, y + dy)<tab><tab>out.append(part)<tab>return FormulaCell("""".join(out), self.fmt, self.alignment)",if x1 <= x <= x2 and y1 <= y <= y2 :,179
4075,"def modify_column(self, column: List[Optional[""Cell""]]):<tab>for i in range(len(column)):<tab><tab>gate = column[i]<tab><tab>if gate is self:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># The first parity control to modify the column must merge all<tab><tab><tab># of the other parity controls into itself.<tab><tab><tab>column[i] = None<tab><tab><tab>self._basis_change += gate._basis_change<tab><tab><tab>self.qubits += gate.qubits<tab><tab>elif gate is not None:<tab><tab><tab>column[i] = gate.controlled_by(self.qubits[0])","elif isinstance ( gate , ParityControlCell ) :",164
4076,"def update_neighbor(neigh_ip_address, changes):<tab>rets = []<tab>for k, v in changes.items():<tab><tab><IF-STMT><tab><tab><tab>rets.append(_update_med(neigh_ip_address, v))<tab><tab>if k == neighbors.ENABLED:<tab><tab><tab>rets.append(update_neighbor_enabled(neigh_ip_address, v))<tab><tab>if k == neighbors.CONNECT_MODE:<tab><tab><tab>rets.append(_update_connect_mode(neigh_ip_address, v))<tab>return all(rets)",if k == neighbors . MULTI_EXIT_DISC :,138
4077,"def writexml(<tab>self,<tab>stream,<tab>indent="""",<tab>addindent="""",<tab>newl="""",<tab>strip=0,<tab>nsprefixes={},<tab>namespace="""",):<tab>w = _streamWriteWrapper(stream)<tab>if self.raw:<tab><tab>val = self.nodeValue<tab><tab>if not isinstance(val, str):<tab><tab><tab>val = str(self.nodeValue)<tab>else:<tab><tab>v = self.nodeValue<tab><tab><IF-STMT><tab><tab><tab>v = str(v)<tab><tab>if strip:<tab><tab><tab>v = "" "".join(v.split())<tab><tab>val = escape(v)<tab>w(val)","if not isinstance ( v , str ) :",164
4078,"def _condition(ct):<tab>for qobj in args:<tab><tab><IF-STMT><tab><tab><tab># normal kwargs are an AND anyway, so just use those for now<tab><tab><tab>for child in qobj.children:<tab><tab><tab><tab>kwargs.update(dict([child]))<tab><tab>else:<tab><tab><tab>raise NotImplementedError(""Unsupported Q object"")<tab>for attr, val in kwargs.items():<tab><tab>if getattr(ct, attr) != val:<tab><tab><tab>return False<tab>return True","if qobj . connector == ""AND"" and not qobj . negated :",127
4079,"def results_iter(self):<tab><IF-STMT><tab><tab>from django.db.models.fields import DateTimeField<tab><tab>fields = [DateTimeField()]<tab>else:<tab><tab>needs_string_cast = self.connection.features.needs_datetime_string_cast<tab>offset = len(self.query.extra_select)<tab>for rows in self.execute_sql(MULTI):<tab><tab>for row in rows:<tab><tab><tab>date = row[offset]<tab><tab><tab>if self.connection.ops.oracle:<tab><tab><tab><tab>date = self.resolve_columns(row, fields)[offset]<tab><tab><tab>elif needs_string_cast:<tab><tab><tab><tab>date = typecast_timestamp(str(date))<tab><tab><tab>yield date",if self . connection . ops . oracle :,182
4080,"def get_job_type(self):<tab>if int(self.job_runtime_conf.get(""dsl_version"", 1)) == 2:<tab><tab>job_type = (<tab><tab><tab>self.job_runtime_conf[""job_parameters""].get(""common"", {}).get(""job_type"")<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"")<tab>else:<tab><tab>job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"")<tab>return job_type",if not job_type :,150
4081,"def validate_assessment_criteria(self):<tab>if self.assessment_criteria:<tab><tab>total_weightage = 0<tab><tab>for criteria in self.assessment_criteria:<tab><tab><tab>total_weightage += criteria.weightage or 0<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Total Weightage of all Assessment Criteria must be 100%""))",if total_weightage != 100 :,97
4082,"def get_list_of_strings_to_mongo_objects(self, notifications_list=None):<tab>result = []<tab>if len(notifications_list) > 0:<tab><tab>for x in notifications_list:<tab><tab><tab>split_provider_id = x.split("":"")  # email:id<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_id = split_provider_id[1]<tab><tab><tab><tab>cursor = self.get_by_id(_id)<tab><tab><tab><tab>if cursor:  # Append if exists<tab><tab><tab><tab><tab>result.append(cursor)<tab>return result",if len ( split_provider_id ) == 2 :,148
4083,"def dump_predictions_to_database(relation, predictions):<tab>judge = ""iepy-run on {}"".format(datetime.now().strftime(""%Y-%m-%d %H:%M""))<tab>for evidence, relation_is_present in predictions.items():<tab><tab>label = (<tab><tab><tab>EvidenceLabel.YESRELATION<tab><tab><tab><IF-STMT><tab><tab><tab>else EvidenceLabel.NORELATION<tab><tab>)<tab><tab>evidence.set_label(relation, label, judge, labeled_by_machine=True)",if relation_is_present,129
4084,"def __init__(self, **kwargs):<tab># We hard-code the `to` argument for ForeignKey.__init__<tab>dfl = get_model_label(self.default_model_class)<tab>if ""to"" in kwargs.keys():  # pragma: no cover<tab><tab>old_to = get_model_label(kwargs.pop(""to""))<tab><tab><IF-STMT><tab><tab><tab>msg = ""%s can only be a ForeignKey to %s; %s passed"" % (<tab><tab><tab><tab>self.__class__.__name__,<tab><tab><tab><tab>dfl,<tab><tab><tab><tab>old_to,<tab><tab><tab>)<tab><tab><tab>warnings.warn(msg, SyntaxWarning)<tab>kwargs[""to""] = dfl<tab>super().__init__(**kwargs)",if old_to . lower ( ) != dfl . lower ( ) :,182
4085,"def reverse(self):<tab>""""""Reverse *IN PLACE*.""""""<tab>li = self.leftindex<tab>lb = self.leftblock<tab>ri = self.rightindex<tab>rb = self.rightblock<tab>for i in range(self.len >> 1):<tab><tab>lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li]<tab><tab>li += 1<tab><tab>if li >= BLOCKLEN:<tab><tab><tab>lb = lb.rightlink<tab><tab><tab>li = 0<tab><tab>ri -= 1<tab><tab><IF-STMT><tab><tab><tab>rb = rb.leftlink<tab><tab><tab>ri = BLOCKLEN - 1",if ri < 0 :,156
4086,"def get_api(user, url):<tab>global API_CACHE<tab>if API_CACHE is None or API_CACHE.get(url) is None:<tab><tab>API_CACHE_LOCK.acquire()<tab><tab>try:<tab><tab><tab>if API_CACHE is None:<tab><tab><tab><tab>API_CACHE = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>API_CACHE[url] = ImpalaDaemonApi(url)<tab><tab>finally:<tab><tab><tab>API_CACHE_LOCK.release()<tab>api = API_CACHE[url]<tab>api.set_user(user)<tab>return api",if API_CACHE . get ( url ) is None :,148
4087,"def invert_index(cls, index, length):<tab>if np.isscalar(index):<tab><tab>return length - index<tab>elif isinstance(index, slice):<tab><tab>start, stop = index.start, index.stop<tab><tab>new_start, new_stop = None, None<tab><tab>if start is not None:<tab><tab><tab>new_stop = length - start<tab><tab><IF-STMT><tab><tab><tab>new_start = length - stop<tab><tab>return slice(new_start - 1, new_stop - 1)<tab>elif isinstance(index, Iterable):<tab><tab>new_index = []<tab><tab>for ind in index:<tab><tab><tab>new_index.append(length - ind)<tab>return new_index",if stop is not None :,168
4088,"def infer_returned_object(pyfunction, args):<tab>""""""Infer the `PyObject` this `PyFunction` returns after calling""""""<tab>object_info = pyfunction.pycore.object_info<tab>result = object_info.get_exact_returned(pyfunction, args)<tab>if result is not None:<tab><tab>return result<tab>result = _infer_returned(pyfunction, args)<tab>if result is not None:<tab><tab><IF-STMT><tab><tab><tab>params = args.get_arguments(pyfunction.get_param_names(special_args=False))<tab><tab><tab>object_info.function_called(pyfunction, params, result)<tab><tab>return result<tab>return object_info.get_returned(pyfunction, args)",if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,187
4089,"def _check_imports(lib):<tab># Make sure no conflicting libraries have been imported.<tab>libs = [""PyQt4"", ""PyQt5"", ""PySide""]<tab>libs.remove(lib)<tab>for lib2 in libs:<tab><tab>lib2 += "".QtCore""<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Refusing to import %s because %s is already "" ""imported."" % (lib, lib2)<tab><tab><tab>)",if lib2 in sys . modules :,116
4090,"def _poll(fds, timeout):<tab>if timeout is not None:<tab><tab>timeout = int(timeout * 1000)  # timeout is in milliseconds<tab>fd_map = {}<tab>pollster = select.poll()<tab>for fd in fds:<tab><tab>pollster.register(fd, select.POLLIN)<tab><tab><IF-STMT><tab><tab><tab>fd_map[fd.fileno()] = fd<tab><tab>else:<tab><tab><tab>fd_map[fd] = fd<tab>ls = []<tab>for fd, event in pollster.poll(timeout):<tab><tab>if event & select.POLLNVAL:<tab><tab><tab>raise ValueError(""invalid file descriptor %i"" % fd)<tab><tab>ls.append(fd_map[fd])<tab>return ls","if hasattr ( fd , ""fileno"" ) :",180
4091,"def default(cls, connection=None):<tab>""""""show the default connection, or make CONNECTION the default""""""<tab>if connection is not None:<tab><tab>target = cls._get_config_filename(connection)<tab><tab><IF-STMT><tab><tab><tab>if os.path.exists(cls._default_symlink):<tab><tab><tab><tab>os.remove(cls._default_symlink)<tab><tab><tab>os.symlink(target, cls._default_symlink)<tab><tab>else:<tab><tab><tab>cls._no_config_file_error(target)<tab>if os.path.exists(cls._default_symlink):<tab><tab>print(""Default connection is "" + cls._default_connection())<tab>else:<tab><tab>print(""There is no default connection set"")",if os . path . exists ( target ) :,175
4092,"def process(self, fuzzresult):<tab>base_url = urljoin(fuzzresult.url, "".."")<tab>for line in fuzzresult.history.content.splitlines():<tab><tab>record = line.split(""/"")<tab><tab><IF-STMT><tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab># Directory<tab><tab><tab>if record[0] == ""D"":<tab><tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab><tab>self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))",if len ( record ) == 6 and record [ 1 ] :,153
4093,"def _GetCSVRow(self, value):<tab>row = []<tab>for type_info in value.__class__.type_infos:<tab><tab><IF-STMT><tab><tab><tab>row.extend(self._GetCSVRow(value.Get(type_info.name)))<tab><tab>elif isinstance(type_info, rdf_structs.ProtoBinary):<tab><tab><tab>row.append(text.Asciify(value.Get(type_info.name)))<tab><tab>else:<tab><tab><tab>row.append(str(value.Get(type_info.name)))<tab>return row","if isinstance ( type_info , rdf_structs . ProtoEmbedded ) :",143
4094,"def get_history(self, state, dict_, passive=PASSIVE_OFF):<tab>if self.key in dict_:<tab><tab>return History.from_scalar_attribute(self, state, dict_[self.key])<tab>else:<tab><tab><IF-STMT><tab><tab><tab>passive ^= INIT_OK<tab><tab>current = self.get(state, dict_, passive=passive)<tab><tab>if current is PASSIVE_NO_RESULT:<tab><tab><tab>return HISTORY_BLANK<tab><tab>else:<tab><tab><tab>return History.from_scalar_attribute(self, state, current)",if passive & INIT_OK :,143
4095,"def _iterate_self_and_parents(self, upto=None):<tab>current = self<tab>result = ()<tab>while current:<tab><tab>result += (current,)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif current._parent is None:<tab><tab><tab>raise sa_exc.InvalidRequestError(<tab><tab><tab><tab>""Transaction %s is not on the active transaction list"" % (upto)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>current = current._parent<tab>return result",if current . _parent is upto :,126
4096,"def get_by_uri(self, uri: str) -> bytes:<tab>userId, bucket, key = self._parse_uri(uri)<tab>try:<tab><tab>with db.session_scope() as dbsession:<tab><tab><tab>result = db_archivedocument.get(userId, bucket, key, session=dbsession)<tab><tab><IF-STMT><tab><tab><tab>return utils.ensure_bytes(self._decode(result))<tab><tab>else:<tab><tab><tab>raise ObjectKeyNotFoundError(userId, bucket, key, caused_by=None)<tab>except Exception as err:<tab><tab>logger.debug(""cannot get data: exception - "" + str(err))<tab><tab>raise err",if result :,158
4097,"def app(scope, receive, send):<tab>while True:<tab><tab>message = await receive()<tab><tab>if message[""type""] == ""websocket.connect"":<tab><tab><tab>await send({""type"": ""websocket.accept""})<tab><tab>elif message[""type""] == ""websocket.receive"":<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>break","elif message [ ""type"" ] == ""websocket.disconnect"" :",93
4098,"def recv_some(p, t=0.1, e=1, tr=5, stderr=0):<tab>if tr < 1:<tab><tab>tr = 1<tab>x = time.time() + t<tab>y = []<tab>r = """"<tab>if stderr:<tab><tab>pr = p.recv_err<tab>else:<tab><tab>pr = p.recv<tab>while time.time() < x or r:<tab><tab>r = pr()<tab><tab>if r is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>y.append(r)<tab><tab>else:<tab><tab><tab>time.sleep(max((x - time.time()) / tr, 0))<tab>return """".join(y)",elif r :,168
4099,"def mouse_down(self, event):<tab>if event.button == 1:<tab><tab><IF-STMT><tab><tab><tab>p = event.local<tab><tab><tab>if self.scroll_up_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_up()<tab><tab><tab><tab>return<tab><tab><tab>elif self.scroll_down_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_down()<tab><tab><tab><tab>return<tab>if event.button == 4:<tab><tab>self.scroll_up()<tab>if event.button == 5:<tab><tab>self.scroll_down()<tab>GridView.mouse_down(self, event)",if self . scrolling :,160
4100,"def copy_from(self, other):<tab>if self is other:<tab><tab>return  # Myself!<tab>self.strictness = other.strictness  # sets behaviors in bulk<tab>for name in self.all_behaviors:<tab><tab>self.set_behavior(name, other.get_behavior(name))<tab>for name in self._plain_attrs:<tab><tab>val = getattr(other, name)<tab><tab>if isinstance(val, set):<tab><tab><tab>val = val.copy()<tab><tab><IF-STMT><tab><tab><tab>val = val.copy()<tab><tab>setattr(self, name, val)","elif decimal and isinstance ( val , decimal . Decimal ) :",148
4101,"def __array_wrap__(self, out_arr, context=None):<tab>if self.dim is None:<tab><tab>return out_arr<tab>else:<tab><tab>this = self[:]<tab><tab><IF-STMT><tab><tab><tab>return Quantity.__array_wrap__(self[:], out_arr, context=context)<tab><tab>else:<tab><tab><tab>return out_arr","if isinstance ( this , Quantity ) :",90
4102,"def _ArgumentListHasDictionaryEntry(self, token):<tab>""""""Check if the function argument list has a dictionary as an arg.""""""<tab>if _IsArgumentToFunction(token):<tab><tab>while token:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>length = token.matching_bracket.total_length - token.total_length<tab><tab><tab><tab>return length + self.stack[-2].indent > self.column_limit<tab><tab><tab>if token.ClosesScope():<tab><tab><tab><tab>break<tab><tab><tab>if token.OpensScope():<tab><tab><tab><tab>token = token.matching_bracket<tab><tab><tab>token = token.next_token<tab>return False","if token . value == ""{"" :",153
4103,"def save_all_changed_extensions(self):<tab>""""""Save configuration changes to the user config file.""""""<tab>has_changes = False<tab>for ext_name in self.extensions:<tab><tab>options = self.extensions[ext_name]<tab><tab>for opt in options:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>has_changes = True<tab>if has_changes:<tab><tab>self.ext_userCfg.Save()","if self . set_extension_value ( ext_name , opt ) :",111
4104,"def to_dict(self):<tab>out = {}<tab>for key in ACTIVITY_KEYS:<tab><tab>attr = getattr(self, key)<tab><tab><IF-STMT><tab><tab><tab>out[key] = str(attr)<tab><tab>else:<tab><tab><tab>out[key] = attr<tab>if self.streak:<tab><tab>out[""streak""] = self.streak<tab>return out","if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :",102
4105,"def clean_publication_date(cls, cleaned_input):<tab>for add_channel in cleaned_input.get(""add_channels"", []):<tab><tab>is_published = add_channel.get(""is_published"")<tab><tab>publication_date = add_channel.get(""publication_date"")<tab><tab><IF-STMT><tab><tab><tab>add_channel[""publication_date""] = datetime.date.today()",if is_published and not publication_date :,98
4106,"def _random_blur(self, batch, sigma_max):<tab>for i in range(len(batch)):<tab><tab><IF-STMT><tab><tab><tab># Random sigma<tab><tab><tab>sigma = random.uniform(0.0, sigma_max)<tab><tab><tab>batch[i] = scipy.ndimage.filters.gaussian_filter(batch[i], sigma)<tab>return batch",if bool ( random . getrandbits ( 1 ) ) :,92
4107,"def conninfo_parse(dsn):<tab>ret = {}<tab>length = len(dsn)<tab>i = 0<tab>while i < length:<tab><tab>if dsn[i].isspace():<tab><tab><tab>i += 1<tab><tab><tab>continue<tab><tab>param_match = PARAMETER_RE.match(dsn[i:])<tab><tab>if not param_match:<tab><tab><tab>return<tab><tab>param = param_match.group(1)<tab><tab>i += param_match.end()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>value, end = read_param_value(dsn[i:])<tab><tab>if value is None:<tab><tab><tab>return<tab><tab>i += end<tab><tab>ret[param] = value<tab>return ret",if i >= length :,175
4108,"def set_environment_vars(env, source_env):<tab>""""""Copy allowed environment variables from |source_env|.""""""<tab>if not source_env:<tab><tab>return<tab>for name, value in six.iteritems(source_env):<tab><tab>if is_forwarded_environment_variable(name):<tab><tab><tab># Avoid creating circular dependencies from importing environment by<tab><tab><tab># using os.getenv.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = file_host.rebase_to_worker_root(value)<tab><tab><tab>env[name] = value","if os . getenv ( ""TRUSTED_HOST"" ) and should_rebase_environment_value ( name ) :",152
4109,"def toterminal(self, tw):<tab># the entries might have different styles<tab>last_style = None<tab>for i, entry in enumerate(self.reprentries):<tab><tab>if entry.style == ""long"":<tab><tab><tab>tw.line("""")<tab><tab>entry.toterminal(tw)<tab><tab><IF-STMT><tab><tab><tab>next_entry = self.reprentries[i + 1]<tab><tab><tab>if (<tab><tab><tab><tab>entry.style == ""long""<tab><tab><tab><tab>or entry.style == ""short""<tab><tab><tab><tab>and next_entry.style == ""long""<tab><tab><tab>):<tab><tab><tab><tab>tw.sep(self.entrysep)<tab>if self.extraline:<tab><tab>tw.line(self.extraline)",if i < len ( self . reprentries ) - 1 :,198
4110,"def __init__(self, loc, tabs=None):<tab>if os.path.isdir(loc):<tab><tab>for item in os.listdir(loc):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>path = os.path.join(loc, item)<tab><tab><tab>self.append(CronTab(user=False, tabfile=path))<tab>elif os.path.isfile(loc):<tab><tab>self.append(CronTab(user=False, tabfile=loc))","if item [ 0 ] == ""."" :",121
4111,"def import_data(self, fname):<tab>""""""Import data in current namespace""""""<tab>if self.count():<tab><tab>nsb = self.currentWidget()<tab><tab>nsb.refresh_table()<tab><tab>nsb.import_data(fname)<tab><tab><IF-STMT><tab><tab><tab>self.dockwidget.setVisible(True)<tab><tab><tab>self.dockwidget.raise_()",if self . dockwidget and not self . ismaximized :,103
4112,"def get_menu_items(node):<tab>aList = []<tab>for child in node.children:<tab><tab>for tag in (""@menu"", ""@item""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = child.h[len(tag) + 1 :].strip()<tab><tab><tab><tab>if tag == ""@menu"":<tab><tab><tab><tab><tab>aList.append((""%s %s"" % (tag, name), get_menu_items(child), None))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>b = g.splitLines("""".join(child.b))<tab><tab><tab><tab><tab>aList.append((tag, name, b[0] if b else """"))<tab><tab><tab><tab>break<tab>return aList",if child . h . startswith ( tag ) :,173
4113,"def __init__(self, *args, **kw):<tab>if len(args) > 1:<tab><tab>raise TypeError(""MultiDict can only be called with one positional "" ""argument"")<tab>if args:<tab><tab>if hasattr(args[0], ""iteritems""):<tab><tab><tab>items = list(args[0].iteritems())<tab><tab><IF-STMT><tab><tab><tab>items = list(args[0].items())<tab><tab>else:<tab><tab><tab>items = list(args[0])<tab><tab>self._items = items<tab>else:<tab><tab>self._items = []<tab>if kw:<tab><tab>self._items.extend(kw.items())","elif hasattr ( args [ 0 ] , ""items"" ) :",156
4114,"def open(self) -> ""KeyValueDb"":<tab>""""""Create a new data base or open existing one""""""<tab>if os.path.exists(self._name):<tab><tab>if not os.path.isfile(self._name):<tab><tab><tab>raise IOError(""%s exists and is not a file"" % self._name)<tab><tab><IF-STMT><tab><tab><tab># ignore empty files<tab><tab><tab>return self<tab><tab>with open(self._name, ""rb"") as _in:  # binary mode<tab><tab><tab>self.set_records(pickle.load(_in))<tab>else:<tab><tab># make sure path exists<tab><tab>mkpath(os.path.dirname(self._name))<tab><tab>self.commit()<tab>return self",if os . path . getsize ( self . _name ) == 0 :,180
4115,"def sortModules(self):<tab>super(NeuronDecomposableNetwork, self).sortModules()<tab>self._constructParameterInfo()<tab># contains a list of lists of indices<tab>self.decompositionIndices = {}<tab>for neuron in self._neuronIterator():<tab><tab>self.decompositionIndices[neuron] = []<tab>for w in range(self.paramdim):<tab><tab>inneuron, outneuron = self.paramInfo[w]<tab><tab><IF-STMT><tab><tab><tab>self.decompositionIndices[inneuron].append(w)<tab><tab>else:<tab><tab><tab>self.decompositionIndices[outneuron].append(w)",if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules :,158
4116,"def visit_Options(self, node: qlast.Options) -> None:<tab>for i, opt in enumerate(node.options.values()):<tab><tab><IF-STMT><tab><tab><tab>self.write("" "")<tab><tab>self.write(opt.name)<tab><tab>if not isinstance(opt, qlast.Flag):<tab><tab><tab>self.write(f"" {opt.val}"")",if i > 0 :,90
4117,"def is_child_of(self, item_hash, possible_child_hash):<tab>if self.get_last(item_hash) != self.get_last(possible_child_hash):<tab><tab>return None<tab>while True:<tab><tab>if possible_child_hash == item_hash:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>possible_child_hash = self.items[possible_child_hash].previous_hash",if possible_child_hash not in self . items :,119
4118,"def __call__(self, text, **kargs):<tab>words = jieba.tokenize(text, mode=""search"")<tab>token = Token()<tab>for (w, start_pos, stop_pos) in words:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>token.original = token.text = w<tab><tab>token.pos = start_pos<tab><tab>token.startchar = start_pos<tab><tab>token.endchar = stop_pos<tab><tab>yield token",if not accepted_chars . match ( w ) and len ( w ) <= 1 :,123
4119,"def test_analysis_jobs_cypher_syntax(neo4j_session):<tab>parameters = {<tab><tab>""AWS_ID"": None,<tab><tab>""UPDATE_TAG"": None,<tab><tab>""OKTA_ORG_ID"": None,<tab>}<tab>for job_name in contents(""cartography.data.jobs.analysis""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>cartography.util.run_analysis_job(job_name, neo4j_session, parameters)<tab><tab>except Exception as e:<tab><tab><tab>pytest.fail(<tab><tab><tab><tab>f""run_analysis_job failed for analysis job '{job_name}' with exception: {e}""<tab><tab><tab>)","if not job_name . endswith ( "".json"" ) :",180
4120,"def _interleave_dataset_results_and_tensors(dataset_results, flat_run_tensors):<tab>flattened_results = []<tab>for idx in range(len(dataset_results) + len(flat_run_tensors)):<tab><tab><IF-STMT><tab><tab><tab>flattened_results.append(dataset_results[idx])<tab><tab>else:<tab><tab><tab>flattened_results.append(flat_run_tensors.pop(0))<tab>return flattened_results",if dataset_results . get ( idx ) :,111
4121,"def test_k_is_stochastic_parameter(self):<tab># k as stochastic parameter<tab>aug = iaa.MedianBlur(k=iap.Choice([3, 5]))<tab>seen = [False, False]<tab>for i in sm.xrange(100):<tab><tab>observed = aug.augment_image(self.base_img)<tab><tab><IF-STMT><tab><tab><tab>seen[0] += True<tab><tab>elif np.array_equal(observed, self.blur5x5):<tab><tab><tab>seen[1] += True<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected result in MedianBlur@2"")<tab><tab>if all(seen):<tab><tab><tab>break<tab>assert np.all(seen)","if np . array_equal ( observed , self . blur3x3 ) :",176
4122,"def pickPath(self, color):<tab>self.path[color] = ()<tab>currentPos = self.starts[color]<tab>while True:<tab><tab>minDist = None<tab><tab>minGuide = None<tab><tab>for guide in self.guides[color]:<tab><tab><tab>guideDist = dist(currentPos, guide)<tab><tab><tab>if minDist == None or guideDist < minDist:<tab><tab><tab><tab>minDist = guideDist<tab><tab><tab><tab>minGuide = guide<tab><tab>if dist(currentPos, self.ends[color]) == 1:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.path[color] = self.path[color] + (minGuide,)<tab><tab>currentPos = minGuide<tab><tab>self.guides[color].remove(minGuide)",if minGuide == None :,192
4123,"def UpdateRepository(self):<tab>if hasattr(self, ""commit_update""):<tab><tab><IF-STMT><tab><tab><tab>if not path.isdir("".git/""):<tab><tab><tab><tab>self.gitZipRepo()<tab><tab><tab>call([""git"", ""reset"", ""--hard"", ""origin/{}"".format(self.getBranch)])<tab><tab><tab>self.ProcessCall_([""git"", ""pull"", ""origin"", self.getBranch])<tab><tab><tab>self.ProcessCall_([""pip"", ""install"", ""-r"", ""requirements.txt""])","if self . commit_update [ ""Updates"" ] != [ ] :",126
4124,"def callback(result=Cr.NS_OK, message=None, success=None):<tab>if success is None:<tab><tab><IF-STMT><tab><tab><tab>success = Ci.koIAsyncCallback.RESULT_SUCCESSFUL<tab><tab>else:<tab><tab><tab>success = Ci.koIAsyncCallback.RESULT_ERROR<tab>data = Namespace(result=result, message=message, _com_interfaces_=[Ci.koIErrorInfo])<tab>self._invoke_activate_callbacks(success, data)",if Cr . NS_SUCCEEDED ( result ) :,121
4125,"def get_location(device):<tab>location = []<tab>node = device<tab>while node:<tab><tab>position = node.get_position() or """"<tab><tab><IF-STMT><tab><tab><tab>position = "" [%s]"" % position<tab><tab>location.append(node.name + position)<tab><tab>node = node.parent<tab>return "" / "".join(reversed(location))",if position :,87
4126,"def load_checkpoint(path, model, optimizer, reset_optimizer):<tab>global global_step<tab>global global_epoch<tab>print(""Load checkpoint from: {}"".format(path))<tab>checkpoint = _load(path)<tab>model.load_state_dict(checkpoint[""state_dict""])<tab>if not reset_optimizer:<tab><tab>optimizer_state = checkpoint[""optimizer""]<tab><tab><IF-STMT><tab><tab><tab>print(""Load optimizer state from {}"".format(path))<tab><tab><tab>optimizer.load_state_dict(checkpoint[""optimizer""])<tab>global_step = checkpoint[""global_step""]<tab>global_epoch = checkpoint[""global_epoch""]<tab>return model",if optimizer_state is not None :,155
4127,"def run_command(self, command: str, data: Dict[str, object]) -> Dict[str, object]:<tab>""""""Run a specific command from the registry.""""""<tab>key = ""cmd_"" + command<tab>method = getattr(self.__class__, key, None)<tab>if method is None:<tab><tab>return {""error"": ""Unrecognized command '%s'"" % command}<tab>else:<tab><tab><IF-STMT><tab><tab><tab># Only the above commands use some error formatting.<tab><tab><tab>del data[""is_tty""]<tab><tab><tab>del data[""terminal_width""]<tab><tab>return method(self, **data)","if command not in { ""check"" , ""recheck"" , ""run"" } :",151
4128,"def call_init(self, node, instance):<tab># Call __init__ on each binding.<tab>for b in instance.bindings:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._initialized_instances.add(b.data)<tab><tab>node = self._call_init_on_binding(node, b)<tab>return node",if b . data in self . _initialized_instances :,89
4129,"def get_request_headers() -> Dict:<tab>url = urlparse(uri)<tab>candidates = [<tab><tab>""%s://%s"" % (url.scheme, url.netloc),<tab><tab>""%s://%s/"" % (url.scheme, url.netloc),<tab><tab>uri,<tab><tab>""*"",<tab>]<tab>for u in candidates:<tab><tab><IF-STMT><tab><tab><tab>headers = dict(DEFAULT_REQUEST_HEADERS)<tab><tab><tab>headers.update(self.config.linkcheck_request_headers[u])<tab><tab><tab>return headers<tab>return {}",if u in self . config . linkcheck_request_headers :,142
4130,"def get_next_video_frame(self, skip_empty_frame=True):<tab>if not self.video_format:<tab><tab>return<tab>while True:<tab><tab># We skip video packets which are not video frames<tab><tab># This happens in mkv files for the first few frames.<tab><tab>video_packet = self._get_video_packet()<tab><tab>if video_packet.image == 0:<tab><tab><tab>self._decode_video_packet(video_packet)<tab><tab><IF-STMT><tab><tab><tab>break<tab>if _debug:<tab><tab>print(""Returning"", video_packet)<tab>return video_packet.image",if video_packet . image is not None or not skip_empty_frame :,162
4131,"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab>if code == Path.MOVETO:<tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab><IF-STMT><tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab>elif code == Path.CURVE4:<tab><tab><tab>ctx.curve_to(*points)<tab><tab>elif code == Path.CLOSEPOLY:<tab><tab><tab>ctx.close_path()",elif code == Path . CURVE3 :,172
4132,"def __init__(<tab>self, layout, value=None, string=None, *, dtype: np.dtype = np.float64) -> None:<tab>""""""Constructor.""""""<tab>self.layout = layout<tab>if value is None:<tab><tab>if string is None:<tab><tab><tab>self.value = np.zeros((self.layout.gaDims,), dtype=dtype)<tab><tab>else:<tab><tab><tab>self.value = layout.parse_multivector(string).value<tab>else:<tab><tab>self.value = np.array(value)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""value must be a sequence of length %s"" % self.layout.gaDims<tab><tab><tab>)","if self . value . shape != ( self . layout . gaDims , ) :",180
4133,"def to_dict(self):<tab>contexts_ = {}<tab>for k, data in self.contexts.items():<tab><tab>data_ = data.copy()<tab><tab>if ""context"" in data_:<tab><tab><tab>del data_[""context""]<tab><tab><IF-STMT><tab><tab><tab>del data_[""loaded""]<tab><tab>contexts_[k] = data_<tab>return dict(contexts=contexts_)","if ""loaded"" in data_ :",94
4134,"def include_module(module):<tab>if not include_these:<tab><tab>return True<tab>result = False<tab>for check in include_these:<tab><tab>if ""/*"" in check:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab>if (os.getcwd() + ""/"" + check + "".py"") == module:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_status(""Including module: "" + module)<tab>return result",if check [ : - 1 ] in module :,122
4135,"def extract_from(msg_body, content_type=""text/plain""):<tab>try:<tab><tab>if content_type == ""text/plain"":<tab><tab><tab>return extract_from_plain(msg_body)<tab><tab><IF-STMT><tab><tab><tab>return extract_from_html(msg_body)<tab>except Exception:<tab><tab>log.exception(""ERROR extracting message"")<tab>return msg_body","elif content_type == ""text/html"" :",100
4136,"def test_list(self):<tab>self._create_locations()<tab>response = self.client.get(self.geojson_boxedlocation_list_url)<tab>self.assertEqual(response.status_code, 200)<tab>self.assertEqual(len(response.data[""features""]), 2)<tab>for feature in response.data[""features""]:<tab><tab>self.assertIn(""bbox"", feature)<tab><tab>fid = feature[""id""]<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent)<tab><tab>elif fid == 2:<tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent)<tab><tab>else:<tab><tab><tab>self.fail(""Unexpected id: {0}"".format(fid))<tab>BoxedLocation.objects.all().delete()",if fid == 1 :,196
4137,"def overrideCommand(self, commandName, func):<tab># Override entries in c.k.masterBindingsDict<tab>k = self<tab>d = k.masterBindingsDict<tab>for key in d:<tab><tab>d2 = d.get(key)<tab><tab>for key2 in d2:<tab><tab><tab>bi = d2.get(key2)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>bi.func = func<tab><tab><tab><tab>d2[key2] = bi",if bi . commandName == commandName :,118
4138,"def _lookup(components, specs, provided, name, i, l):<tab>if i < l:<tab><tab>for spec in specs[i].__sro__:<tab><tab><tab>comps = components.get(spec)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r = _lookup(comps, specs, provided, name, i + 1, l)<tab><tab><tab><tab>if r is not None:<tab><tab><tab><tab><tab>return r<tab>else:<tab><tab>for iface in provided:<tab><tab><tab>comps = components.get(iface)<tab><tab><tab>if comps:<tab><tab><tab><tab>r = comps.get(name)<tab><tab><tab><tab>if r is not None:<tab><tab><tab><tab><tab>return r<tab>return None",if comps :,166
4139,"def to_representation(self, value):<tab>old_social_string_fields = [""twitter"", ""github"", ""linkedIn""]<tab>request = self.context.get(""request"")<tab>show_old_format = (<tab><tab>request<tab><tab>and is_deprecated(request.version, self.min_version)<tab><tab>and request.method == ""GET""<tab>)<tab>if show_old_format:<tab><tab>social = value.copy()<tab><tab>for key in old_social_string_fields:<tab><tab><tab>if social.get(key):<tab><tab><tab><tab>social[key] = value[key][0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>social[key] = """"<tab><tab>value = social<tab>return super(SocialField, self).to_representation(value)",elif social . get ( key ) == [ ] :,200
4140,"def process_ref_attribute(self, node, array_type=None):<tab>ref = qname_attr(node, ""ref"")<tab>if ref:<tab><tab>ref = self._create_qname(ref)<tab><tab># Some wsdl's reference to xs:schema, we ignore that for now. It<tab><tab># might be better in the future to process the actual schema file<tab><tab># so that it is handled correctly<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>return xsd_elements.RefAttribute(<tab><tab><tab>node.tag, ref, self.schema, array_type=array_type<tab><tab>)","if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :",161
4141,"def unescape(text):<tab>""""""Removes '\\' escaping from 'text'.""""""<tab>rv = """"<tab>i = 0<tab>while i < len(text):<tab><tab><IF-STMT><tab><tab><tab>rv += text[i + 1]<tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>rv += text[i]<tab><tab>i += 1<tab>return rv","if i + 1 < len ( text ) and text [ i ] == ""\\"" :",99
4142,"def wait_child_process(signum, frame):<tab>try:<tab><tab>while True:<tab><tab><tab>child_pid, status = os.waitpid(-1, os.WNOHANG)<tab><tab><tab>if child_pid == 0:<tab><tab><tab><tab>stat_logger.info(""no child process was immediately available"")<tab><tab><tab><tab>break<tab><tab><tab>exitcode = status >> 8<tab><tab><tab>stat_logger.info(<tab><tab><tab><tab>""child process %s exit with exitcode %s"", child_pid, exitcode<tab><tab><tab>)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>stat_logger.warning(<tab><tab><tab><tab>""current process has no existing unwaited-for child processes.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise",if e . errno == errno . ECHILD :,190
4143,"def translate_from_sortname(name, sortname):<tab>""""""'Translate' the artist name by reversing the sortname.""""""<tab>for c in name:<tab><tab>ctg = unicodedata.category(c)<tab><tab>if ctg[0] == ""L"" and unicodedata.name(c).find(""LATIN"") == -1:<tab><tab><tab>for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>parts = sortname.split(separator)<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>parts = [sortname]<tab><tab><tab><tab>separator = """"<tab><tab><tab>return separator.join(map(_reverse_sortname, parts))<tab>return name",if separator in sortname :,181
4144,"def python_value(self, value):<tab>if value:<tab><tab><IF-STMT><tab><tab><tab>pp = lambda x: x.time()<tab><tab><tab>return format_date_time(value, self.formats, pp)<tab><tab>elif isinstance(value, datetime.datetime):<tab><tab><tab>return value.time()<tab>if value is not None and isinstance(value, datetime.timedelta):<tab><tab>return (datetime.datetime.min + value).time()<tab>return value","if isinstance ( value , basestring ) :",113
4145,"def __init__(self, fileobj, info):<tab>pages = []<tab>complete = False<tab>while not complete:<tab><tab>page = OggPage(fileobj)<tab><tab><IF-STMT><tab><tab><tab>pages.append(page)<tab><tab><tab>complete = page.complete or (len(page.packets) > 1)<tab>data = OggPage.to_packets(pages)[0][7:]<tab>super(OggTheoraCommentDict, self).__init__(data, framing=False)<tab>self._padding = len(data) - self._size",if page . serial == info . serial :,133
4146,"def configure(self):<tab># hack to configure 'from_' and 'to' and avoid exception<tab>if ""from_"" in self.wmeta.properties:<tab><tab>from_ = float(self.wmeta.properties[""from_""])<tab><tab>to = float(self.wmeta.properties.get(""to"", 0))<tab><tab><IF-STMT><tab><tab><tab>to = from_ + 1<tab><tab><tab>self.wmeta.properties[""to""] = str(to)<tab>super(TKSpinbox, self).configure()",if from_ > to :,123
4147,"def get_error_diagnostics(self):<tab>diagnostics = []<tab>if self.stdout is not None:<tab><tab>with open(self.stdout.name) as fds:<tab><tab><tab>contents = fds.read().strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diagnostics.append(""ab STDOUT:\n"" + contents)<tab>if self.stderr is not None:<tab><tab>with open(self.stderr.name) as fds:<tab><tab><tab>contents = fds.read().strip()<tab><tab><tab>if contents.strip():<tab><tab><tab><tab>diagnostics.append(""ab STDERR:\n"" + contents)<tab>return diagnostics",if contents . strip ( ) :,156
4148,"def set_environment_vars(env, source_env):<tab>""""""Copy allowed environment variables from |source_env|.""""""<tab>if not source_env:<tab><tab>return<tab>for name, value in six.iteritems(source_env):<tab><tab><IF-STMT><tab><tab><tab># Avoid creating circular dependencies from importing environment by<tab><tab><tab># using os.getenv.<tab><tab><tab>if os.getenv(""TRUSTED_HOST"") and should_rebase_environment_value(name):<tab><tab><tab><tab>value = file_host.rebase_to_worker_root(value)<tab><tab><tab>env[name] = value",if is_forwarded_environment_variable ( name ) :,152
4149,"def update_content(self, more_content: StringList) -> None:<tab>if isinstance(self.object, TypeVar):<tab><tab>attrs = [repr(self.object.__name__)]<tab><tab>for constraint in self.object.__constraints__:<tab><tab><tab>attrs.append(stringify_typehint(constraint))<tab><tab>if self.object.__covariant__:<tab><tab><tab>attrs.append(""covariant=True"")<tab><tab><IF-STMT><tab><tab><tab>attrs.append(""contravariant=True"")<tab><tab>more_content.append(_(""alias of TypeVar(%s)"") % "", "".join(attrs), """")<tab><tab>more_content.append("""", """")<tab>super().update_content(more_content)",if self . object . __contravariant__ :,160
4150,"def after(self, event, state):<tab>group = event.group<tab>for plugin in self.get_plugins():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>metrics.incr(""notifications.sent"", instance=plugin.slug)<tab><tab>yield self.future(plugin.rule_notify)","if not safe_execute ( plugin . should_notify , group = group , event = event ) :",87
4151,"def distinct(expr, *on):<tab>fields = frozenset(expr.fields)<tab>_on = []<tab>append = _on.append<tab>for n in on:<tab><tab>if isinstance(n, Field):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n = n._name<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>if not isinstance(n, _strtypes):<tab><tab><tab>raise TypeError(""on must be a name or field, not: {0}"".format(n))<tab><tab>elif n not in fields:<tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>append(n)<tab>return Distinct(expr, tuple(_on))",if n . _child . isidentical ( expr ) :,192
4152,"def build_filter(arg):<tab>filt = {}<tab>if arg is not None:<tab><tab><IF-STMT><tab><tab><tab>raise UserError(""Arguments to --filter should be in form KEY=VAL"")<tab><tab>key, val = arg.split(""="", 1)<tab><tab>filt[key] = val<tab>return filt","if ""="" not in arg :",75
4153,"def pickline(file, key, casefold=1):<tab>try:<tab><tab>f = open(file, ""r"")<tab>except IOError:<tab><tab>return None<tab>pat = re.escape(key) + "":""<tab>prog = re.compile(pat, casefold and re.IGNORECASE)<tab>while 1:<tab><tab>line = f.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>text = line[len(key) + 1 :]<tab><tab><tab>while 1:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if not line or not line[0].isspace():<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>text = text + line<tab><tab><tab>return text.strip()<tab>return None",if prog . match ( line ) :,182
4154,"def delete_doc(elastic_document_id, node, index=None, category=None):<tab>index = index or INDEX<tab>if not category:<tab><tab><IF-STMT><tab><tab><tab>category = ""preprint""<tab><tab>elif node.is_registration:<tab><tab><tab>category = ""registration""<tab><tab>else:<tab><tab><tab>category = node.project_or_component<tab>client().delete(<tab><tab>index=index,<tab><tab>doc_type=category,<tab><tab>id=elastic_document_id,<tab><tab>refresh=True,<tab><tab>ignore=[404],<tab>)","if isinstance ( node , Preprint ) :",143
4155,"def update(self, preds, labels):<tab>if not _is_numpy_(labels):<tab><tab>raise ValueError(""The 'labels' must be a numpy ndarray."")<tab>if not _is_numpy_(preds):<tab><tab>raise ValueError(""The 'predictions' must be a numpy ndarray."")<tab>for i, lbl in enumerate(labels):<tab><tab>value = preds[i, 1]<tab><tab>bin_idx = int(value * self._num_thresholds)<tab><tab>assert bin_idx <= self._num_thresholds<tab><tab><IF-STMT><tab><tab><tab>self._stat_pos[bin_idx] += 1.0<tab><tab>else:<tab><tab><tab>self._stat_neg[bin_idx] += 1.0",if lbl :,163
4156,"def checkStatusClient(self):<tab>if str(self.comboxBoxIPAddress.currentText()) != """":<tab><tab><IF-STMT><tab><tab><tab>self.btnEnable.setEnabled(False)<tab><tab><tab>self.btncancel.setEnabled(True)<tab><tab><tab>return None<tab><tab>self.btnEnable.setEnabled(True)<tab><tab>self.btncancel.setEnabled(False)","if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :",111
4157,"def colorizeDiffs(sheet, col, row, cellval):<tab>if not row or not col:<tab><tab>return None<tab>vcolidx = sheet.visibleCols.index(col)<tab>rowidx = sheet.rows.index(row)<tab>if vcolidx < len(othersheet.visibleCols) and rowidx < len(othersheet.rows):<tab><tab>otherval = othersheet.visibleCols[vcolidx].getDisplayValue(<tab><tab><tab>othersheet.rows[rowidx]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ""color_diff""<tab>else:<tab><tab>return ""color_diff_add""",if cellval . display != otherval :,162
4158,"def identwaf(self, findall=False):<tab>detected = list()<tab>try:<tab><tab>self.attackres = self.performCheck(self.centralAttack)<tab>except RequestBlocked:<tab><tab>return detected<tab>for wafvendor in self.checklist:<tab><tab>self.log.info(""Checking for %s"" % wafvendor)<tab><tab><IF-STMT><tab><tab><tab>detected.append(wafvendor)<tab><tab><tab>if not findall:<tab><tab><tab><tab>break<tab>self.knowledge[""wafname""] = detected<tab>return detected",if self . wafdetections [ wafvendor ] ( self ) :,143
4159,"def get_repository_metadata_by_repository_id_changeset_revision(<tab>app, id, changeset_revision, metadata_only=False):<tab>""""""Get a specified metadata record for a specified repository in the tool shed.""""""<tab>if metadata_only:<tab><tab>repository_metadata = get_repository_metadata_by_changeset_revision(<tab><tab><tab>app, id, changeset_revision<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return repository_metadata.metadata<tab><tab>return None<tab>return get_repository_metadata_by_changeset_revision(app, id, changeset_revision)",if repository_metadata and repository_metadata . metadata :,145
4160,"def getmultiline(self):<tab>line = self.getline()<tab>if line[3:4] == ""-"":<tab><tab>code = line[:3]<tab><tab>while 1:<tab><tab><tab>nextline = self.getline()<tab><tab><tab>line = line + (""\n"" + nextline)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return line","if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :",100
4161,"def _validate_reports(value, *args, **kwargs):<tab>from osf.models import OSFUser<tab>for key, val in value.items():<tab><tab>if not OSFUser.load(key):<tab><tab><tab>raise ValidationValueError(""Keys must be user IDs"")<tab><tab><IF-STMT><tab><tab><tab>raise ValidationTypeError(""Values must be dictionaries"")<tab><tab>if (<tab><tab><tab>""category"" not in val<tab><tab><tab>or ""text"" not in val<tab><tab><tab>or ""date"" not in val<tab><tab><tab>or ""retracted"" not in val<tab><tab>):<tab><tab><tab>raise ValidationValueError(<tab><tab><tab><tab>(""Values must include `date`, `category`, "", ""`text`, `retracted` keys"")<tab><tab><tab>)","if not isinstance ( val , dict ) :",179
4162,"def deselectItem(self, item):<tab>if self.isSelected(item):<tab><tab><IF-STMT><tab><tab><tab>listItem = self._getListItem(item)<tab><tab><tab>selections = self.getSelectedItems()<tab><tab><tab>selections.remove(self.loadHandler.getSelection(listItem))<tab><tab><tab>self.setSelections(selections)<tab><tab>else:<tab><tab><tab>self.deselectAll()",if self . multiSelect :,101
4163,"def __init__(self, **kwargs):<tab>if self.name is None:<tab><tab>raise RuntimeError(""RenderPrimitive cannot be used directly"")<tab>self.option_values = {}<tab>for key, val in kwargs.items():<tab><tab>if not key in self.options:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""primitive `{0}' has no option `{1}'"".format(self.name, key)<tab><tab><tab>)<tab><tab>self.option_values[key] = val<tab># set up defaults<tab>for name, (description, default) in self.options.items():<tab><tab><IF-STMT><tab><tab><tab>self.option_values[name] = default",if not name in self . option_values :,162
4164,"def setup_smart_indent(self, view, lang):<tab># Configure a ""per-view"" instance<tab>if type(view) == gedit.View:<tab><tab><IF-STMT><tab><tab><tab>setattr(view, ""smart_indent_instance"", SmartIndent())<tab><tab><tab>handler_id = view.connect(<tab><tab><tab><tab>""key-press-event"", view.smart_indent_instance.key_press_handler<tab><tab><tab>)<tab><tab><tab>self.handler_ids.append((handler_id, view))<tab><tab>view.smart_indent_instance.set_language(lang, view)","if getattr ( view , ""smart_indent_instance"" , False ) == False :",157
4165,"def get_strings_of_set(word, char_set, threshold=20):<tab>count = 0<tab>letters = """"<tab>strings = []<tab>for char in word:<tab><tab><IF-STMT><tab><tab><tab>letters += char<tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab>if count > threshold:<tab><tab><tab><tab>strings.append(letters)<tab><tab><tab>letters = """"<tab><tab><tab>count = 0<tab>if count > threshold:<tab><tab>strings.append(letters)<tab>return strings",if char in char_set :,125
4166,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_logout_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,92
4167,def __create_table(self):<tab>for i in range(256):<tab><tab>crcreg = i<tab><tab>for j in range(8):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>crcreg = self.__CRCPOLYNOMIAL ^ (crcreg >> 1)<tab><tab><tab>else:<tab><tab><tab><tab>crcreg >>= 1<tab><tab>self.__crctable[i] = crcreg,if ( crcreg & 1 ) != 0 :,100
4168,"def destroy(self):<tab>""""""Flush all entries and empty cache""""""<tab># Note: this method is currently also used for dropping the cache<tab>for i in range(len(self.cached_rows)):<tab><tab>id_ = self.cached_rows[i]<tab><tab>self.cached_rows[i] = None<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>inode = self.attrs[id_]<tab><tab><tab>except KeyError:<tab><tab><tab><tab># We may have deleted that inode<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>del self.attrs[id_]<tab><tab><tab><tab>self.setattr(inode)<tab>assert len(self.attrs) == 0",if id_ is not None :,167
4169,"def set_config(self):<tab>""""""Set configuration options for QTextEdit.""""""<tab>c = self.c<tab>w = self.widget<tab>w.setWordWrapMode(QtGui.QTextOption.NoWrap)<tab>if 0:  # This only works when there is no style sheet.<tab><tab>n = c.config.getInt(""qt-rich-text-zoom-in"")<tab><tab><IF-STMT><tab><tab><tab>w.zoomIn(n)<tab><tab><tab>w.updateMicroFocus()<tab># tab stop in pixels - no config for this (yet)<tab>w.setTabStopWidth(24)","if n not in ( None , 0 ) :",154
4170,"def mouseDragEvent(self, ev):<tab>if self.movable and ev.button() == QtCore.Qt.LeftButton:<tab><tab>if ev.isStart():<tab><tab><tab>self.moving = True<tab><tab><tab>self.cursorOffset = self.pos() - self.mapToParent(ev.buttonDownPos())<tab><tab><tab>self.startPosition = self.pos()<tab><tab>ev.accept()<tab><tab>if not self.moving:<tab><tab><tab>return<tab><tab>self.setPos(self.cursorOffset + self.mapToParent(ev.pos()))<tab><tab>self.sigDragged.emit(self)<tab><tab><IF-STMT><tab><tab><tab>self.moving = False<tab><tab><tab>self.sigPositionChangeFinished.emit(self)",if ev . isFinish ( ) :,178
4171,"def reparentChildren(self, newParent):<tab>if newParent.childNodes:<tab><tab>newParent.childNodes[-1]._element.tail += self._element.text<tab>else:<tab><tab>if not newParent._element.text:<tab><tab><tab>newParent._element.text = """"<tab><tab><IF-STMT><tab><tab><tab>newParent._element.text += self._element.text<tab>self._element.text = """"<tab>base.Node.reparentChildren(self, newParent)",if self . _element . text is not None :,121
4172,"def _no_sp_or_bp(self, bl):<tab>for s in bl.vex.statements:<tab><tab>for e in chain([s], s.expressions):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>reg = self.get_reg_name(self.project.arch, e.offset)<tab><tab><tab><tab>if reg == ""ebp"" or reg == ""esp"":<tab><tab><tab><tab><tab>return False<tab><tab><tab>elif e.tag == ""Ist_Put"":<tab><tab><tab><tab>reg = self.get_reg_name(self.project.arch, e.offset)<tab><tab><tab><tab>if reg == ""ebp"" or reg == ""esp"":<tab><tab><tab><tab><tab>return False<tab>return True","if e . tag == ""Iex_Get"" :",176
4173,"def _get_import_chain(self, *, until=None):<tab>stack = inspect.stack()[2:]<tab>try:<tab><tab>for frameinfo in stack:<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>data = dedent("""".join(frameinfo.code_context))<tab><tab><tab><tab>if data.strip() == until:<tab><tab><tab><tab><tab>raise StopIteration<tab><tab><tab><tab>yield frameinfo.filename, frameinfo.lineno, data.strip()<tab><tab><tab><tab>del data<tab><tab><tab>finally:<tab><tab><tab><tab>del frameinfo<tab>finally:<tab><tab>del stack",if not frameinfo . code_context :,155
4174,"def stream_docker_log(log_stream):<tab>async for line in log_stream:<tab><tab>if ""stream"" in line and line[""stream""].strip():<tab><tab><tab>logger.debug(line[""stream""].strip())<tab><tab>elif ""status"" in line:<tab><tab><tab>logger.debug(line[""status""].strip())<tab><tab><IF-STMT><tab><tab><tab>logger.error(line[""error""].strip())<tab><tab><tab>raise DockerBuildError","elif ""error"" in line :",108
4175,"def get_cycle_path(self, curr_node, goal_node_index):<tab>for dep in curr_node[""deps""]:<tab><tab>if dep == goal_node_index:<tab><tab><tab>return [curr_node[""address""]]<tab>for dep in curr_node[""deps""]:<tab><tab>path = self.get_cycle_path(<tab><tab><tab>self.get_by_address(dep), goal_node_index<tab><tab>)  # self.nodelist[dep], goal_node_index)<tab><tab><IF-STMT><tab><tab><tab>path.insert(0, curr_node[""address""])<tab><tab><tab>return path<tab>return []",if len ( path ) > 0 :,153
4176,"def prompt(default=None):<tab>editor = ""nano""<tab>with tempfile.NamedTemporaryFile(mode=""r+"") as tmpfile:<tab><tab><IF-STMT><tab><tab><tab>tmpfile.write(default)<tab><tab><tab>tmpfile.flush()<tab><tab>child_pid = os.fork()<tab><tab>is_child = child_pid == 0<tab><tab>if is_child:<tab><tab><tab>os.execvp(editor, [editor, tmpfile.name])<tab><tab>else:<tab><tab><tab>os.waitpid(child_pid, 0)<tab><tab><tab>tmpfile.seek(0)<tab><tab><tab>return tmpfile.read().strip()",if default :,143
4177,"def _get_annotated_template(self, template):<tab>changed = False<tab>if template.get(""version"", ""0.12.0"") >= ""0.13.0"":<tab><tab>using_js = self.spider._filter_js_urls(template[""url""])<tab><tab>body = ""rendered_body"" if using_js else ""original_body""<tab><tab><IF-STMT><tab><tab><tab>template[""body""] = body<tab><tab><tab>changed = True<tab>if changed or not template.get(""annotated""):<tab><tab>_build_sample(template)<tab>return template","if template . get ( ""body"" ) != body :",139
4178,"def collect(self, paths):<tab>for path in paths or ():<tab><tab>relpath = os.path.relpath(path, self._artifact_root)<tab><tab>dst = os.path.join(self._directory, relpath)<tab><tab>safe_mkdir(os.path.dirname(dst))<tab><tab><IF-STMT><tab><tab><tab>shutil.copytree(path, dst)<tab><tab>else:<tab><tab><tab>shutil.copy(path, dst)<tab><tab>self._relpaths.add(relpath)",if os . path . isdir ( path ) :,120
4179,"def dependencies(context=None):<tab>""""""Return all dependencies detected by knowit.""""""<tab>deps = OrderedDict([])<tab>try:<tab><tab>initialize(context)<tab><tab>for name, provider_cls in _provider_map.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>deps[name] = available_providers[name].version<tab><tab><tab>else:<tab><tab><tab><tab>deps[name] = {}<tab>except Exception:<tab><tab>pass<tab>return deps",if name in available_providers :,111
4180,"def _getaddrinfo(self, host_bytes, port, family, socktype, proto, flags):<tab>while True:<tab><tab>ares = self.cares<tab><tab>try:<tab><tab><tab>return self.__getaddrinfo(host_bytes, port, family, socktype, proto, flags)<tab><tab>except gaierror:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",if ares is self . cares :,96
4181,"def write_entries(cmd, basename, filename):<tab>ep = cmd.distribution.entry_points<tab>if isinstance(ep, basestring) or ep is None:<tab><tab>data = ep<tab>elif ep is not None:<tab><tab>data = []<tab><tab>for section, contents in ep.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>contents = EntryPoint.parse_group(section, contents)<tab><tab><tab><tab>contents = ""\n"".join(map(str, contents.values()))<tab><tab><tab>data.append(""[%s]\n%s\n\n"" % (section, contents))<tab><tab>data = """".join(data)<tab>cmd.write_or_delete_file(""entry points"", filename, data, True)","if not isinstance ( contents , basestring ) :",174
4182,"def _highlight_do(self):<tab>new_hl_text = self.highlight_text.text()<tab>if new_hl_text != self.hl_text:<tab><tab>self.hl_text = new_hl_text<tab><tab>if self.hl is not None:<tab><tab><tab>self.hl.setDocument(None)<tab><tab><tab>self.hl = None<tab><tab><IF-STMT><tab><tab><tab>self.hl = Highlighter(self.hl_text, parent=self.doc)<tab><tab>self.clear_highlight_button.setEnabled(bool(self.hl))",if self . hl_text :,151
4183,"def traverse(node, functions=[]):<tab>if hasattr(node, ""grad_fn""):<tab><tab>node = node.grad_fn<tab>if hasattr(node, ""variable""):<tab><tab>node = graph.nodes_by_id.get(id(node.variable))<tab><tab><IF-STMT><tab><tab><tab>node.functions = list(functions)<tab><tab><tab>del functions[:]<tab>if hasattr(node, ""next_functions""):<tab><tab>functions.append(type(node).__name__)<tab><tab>for f in node.next_functions:<tab><tab><tab>if f[0]:<tab><tab><tab><tab>functions.append(type(f[0]).__name__)<tab><tab><tab><tab>traverse(f[0], functions)<tab>if hasattr(node, ""saved_tensors""):<tab><tab>for t in node.saved_tensors:<tab><tab><tab>traverse(t)",if node :,195
4184,"def compress(self, data_list):<tab>if data_list:<tab><tab>page_id = data_list[1]<tab><tab>if page_id in EMPTY_VALUES:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>raise forms.ValidationError(self.error_messages[""invalid_page""])<tab><tab>return Page.objects.get(pk=page_id)<tab>return None",if not self . required :,98
4185,"def test_field_attr_existence(self):<tab>for name, item in ast.__dict__.items():<tab><tab>if self._is_ast_node(name, item):<tab><tab><tab>if name == ""Index"":<tab><tab><tab><tab># Index(value) just returns value now.<tab><tab><tab><tab># The argument is required.<tab><tab><tab><tab>continue<tab><tab><tab>x = item()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(type(x._fields), tuple)","if isinstance ( x , ast . AST ) :",122
4186,"def handle_starttag(self, tag, attrs):<tab>if tag == ""base"":<tab><tab>self.base_url = dict(attrs).get(""href"")<tab>if self.scan_tag(tag):<tab><tab>for attr, value in attrs:<tab><tab><tab>if self.scan_attr(attr):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value = strip_html5_whitespace(value)<tab><tab><tab><tab>url = self.process_attr(value)<tab><tab><tab><tab>link = Link(url=url)<tab><tab><tab><tab>self.links.append(link)<tab><tab><tab><tab>self.current_link = link",if self . strip :,151
4187,"def _initialize_asset_map(cls):<tab># Generating a list of acceptable asset files reduces the possibility of<tab># path attacks.<tab>cls._asset_name_to_path = {}<tab>assets = os.listdir(ASSETS_PATH)<tab>for asset in assets:<tab><tab>path = os.path.join(ASSETS_PATH, asset)<tab><tab><IF-STMT><tab><tab><tab>cls._asset_name_to_path[os.path.basename(path)] = path",if os . path . isfile ( path ) :,120
4188,"def dataReceived(self, data):<tab>self.buf += data<tab>if self._paused:<tab><tab>log.startLogging(sys.stderr)<tab><tab>log.msg(""dataReceived while transport paused!"")<tab><tab>self.transport.loseConnection()<tab>else:<tab><tab>self.transport.write(data)<tab><tab><IF-STMT><tab><tab><tab>self.transport.loseConnection()<tab><tab>else:<tab><tab><tab>self.pause()","if self . buf . endswith ( b""\n0\n"" ) :",114
4189,"def test_case_sensitive(self):<tab>with support.EnvironmentVarGuard() as env:<tab><tab>env.unset(""PYTHONCASEOK"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""os.environ changes not reflected in "" ""_os.environ"")<tab><tab>loader = self.find_module()<tab><tab>self.assertIsNone(loader)","if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :",92
4190,"def manifest(self):<tab>""""""The current manifest dictionary.""""""<tab>if self.reload:<tab><tab>if not self.exists(self.manifest_path):<tab><tab><tab>return {}<tab><tab>mtime = self.getmtime(self.manifest_path)<tab><tab><IF-STMT><tab><tab><tab>self._manifest = self.get_manifest()<tab><tab><tab>self._mtime = mtime<tab>return self._manifest",if self . _mtime is None or mtime > self . _mtime :,102
4191,"def test_named_parameters_and_constraints(self):<tab>likelihood = gpytorch.likelihoods.GaussianLikelihood()<tab>model = ExactGPModel(None, None, likelihood)<tab>for name, _param, constraint in model.named_parameters_and_constraints():<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan)<tab><tab>elif name == ""mean_module.constant"":<tab><tab><tab>self.assertIsNone(constraint)<tab><tab>elif name == ""covar_module.raw_outputscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)<tab><tab>elif name == ""covar_module.base_kernel.raw_lengthscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)","if name == ""likelihood.noise_covar.raw_noise"" :",192
4192,"def process_plugin_result(name, result):<tab>if result:<tab><tab>try:<tab><tab><tab>jsonify(test=result)<tab><tab>except Exception:<tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Error while jsonifying settings from plugin {}, please contact the plugin author about this"".format(<tab><tab><tab><tab><tab>name<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del result[""__enabled""]<tab><tab><tab>data[name] = result","if ""__enabled"" in result :",129
4193,"def benchmarking(net, ctx, num_iteration, datashape=300, batch_size=64):<tab>input_shape = (batch_size, 3) + (datashape, datashape)<tab>data = mx.random.uniform(-1.0, 1.0, shape=input_shape, ctx=ctx, dtype=""float32"")<tab>dryrun = 5<tab>for i in range(dryrun + num_iteration):<tab><tab><IF-STMT><tab><tab><tab>tic = time.time()<tab><tab>ids, scores, bboxes = net(data)<tab><tab>ids.asnumpy()<tab><tab>scores.asnumpy()<tab><tab>bboxes.asnumpy()<tab>toc = time.time() - tic<tab>return toc",if i == dryrun :,165
4194,"def merge_weekdays(base_wd, icu_wd):<tab>result = []<tab>for left, right in zip(base_wd, icu_wd):<tab><tab><IF-STMT><tab><tab><tab>result.append(left)<tab><tab><tab>continue<tab><tab>left = set(left.split(""|""))<tab><tab>right = set(right.split(""|""))<tab><tab>result.append(""|"".join(left | right))<tab>return result",if left == right :,104
4195,"def create_key(self, request):<tab>if self._ignored_parameters:<tab><tab>url, body = self._remove_ignored_parameters(request)<tab>else:<tab><tab>url, body = request.url, request.body<tab>key = hashlib.sha256()<tab>key.update(_to_bytes(request.method.upper()))<tab>key.update(_to_bytes(url))<tab>if request.body:<tab><tab>key.update(_to_bytes(body))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>for name, value in sorted(request.headers.items()):<tab><tab><tab><tab>key.update(_to_bytes(name))<tab><tab><tab><tab>key.update(_to_bytes(value))<tab>return key.hexdigest()",if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,190
4196,"def test_invalid_mountinfo(self):<tab>line = (<tab><tab>""20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root""<tab><tab>""rw,errors=remount-ro,data=ordered""<tab>)<tab>elements = line.split()<tab>for i in range(len(elements) + 1):<tab><tab>lines = ["" "".join(elements[0:i])]<tab><tab><IF-STMT><tab><tab><tab>expected = None<tab><tab>else:<tab><tab><tab>expected = (""/dev/mapper/vg0-root"", ""ext4"", ""/"")<tab><tab>self.assertEqual(expected, util.parse_mount_info(""/"", lines))",if i < 10 :,161
4197,"def nested_filter(self, items, mask):<tab>keep_current = self.current_mask(mask)<tab>keep_nested_lookup = self.nested_masks(mask)<tab>for k, v in items:<tab><tab>keep_nested = keep_nested_lookup.get(k)<tab><tab>if k in keep_current:<tab><tab><tab>if keep_nested is not None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield k, dict(self.nested_filter(v.items(), keep_nested))<tab><tab><tab>else:<tab><tab><tab><tab>yield k, v","if isinstance ( v , dict ) :",142
4198,"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]):<tab>if node_pos[""reach_leaf_node""].all():<tab><tab>return node_pos<tab>for t_idx, tree in enumerate(trees):<tab><tab>cur_node_idx = node_pos[""node_pos""][t_idx]<tab><tab># reach leaf<tab><tab>if cur_node_idx == -1:<tab><tab><tab>continue<tab><tab>rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree(<tab><tab><tab>tree, sample, cur_node_idx<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>node_pos[""reach_leaf_node""][t_idx] = True<tab><tab>node_pos[""node_pos""][t_idx] = rs<tab>return node_pos",if reach_leaf :,196
4199,"def _pop_waiting_trial_id(self) -> Optional[int]:<tab># TODO(c-bata): Reduce database query counts for extracting waiting trials.<tab>for trial in self._storage.get_all_trials(self._study_id, deepcopy=False):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not self._storage.set_trial_state(trial._trial_id, TrialState.RUNNING):<tab><tab><tab>continue<tab><tab>_logger.debug(""Trial {} popped from the trial queue."".format(trial.number))<tab><tab>return trial._trial_id<tab>return None",if trial . state != TrialState . WAITING :,150
4200,"def get_step_best(self, step_models):<tab>best_score = None<tab>best_model = """"<tab>for model in step_models:<tab><tab>model_info = self.models_trained[model]<tab><tab>score = model_info.get_score()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if best_score is None or score < best_score:<tab><tab><tab>best_score = score<tab><tab><tab>best_model = model<tab>LOGGER.info(f""step {self.n_step}, best model {best_model}"")<tab>return best_model",if score is None :,142
4201,"def iter_filters(filters, block_end=False):<tab>queue = deque(filters)<tab>while queue:<tab><tab>f = queue.popleft()<tab><tab>if f is not None and f.type in (""or"", ""and"", ""not""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>queue.appendleft(None)<tab><tab><tab>for gf in f.filters:<tab><tab><tab><tab>queue.appendleft(gf)<tab><tab>yield f",if block_end :,105
4202,"def _buffer_decode(self, input, errors, final):<tab>if self.decoder is None:<tab><tab>(output, consumed, byteorder) = codecs.utf_16_ex_decode(input, errors, 0, final)<tab><tab>if byteorder == -1:<tab><tab><tab>self.decoder = codecs.utf_16_le_decode<tab><tab><IF-STMT><tab><tab><tab>self.decoder = codecs.utf_16_be_decode<tab><tab>elif consumed >= 2:<tab><tab><tab>raise UnicodeError(""UTF-16 stream does not start with BOM"")<tab><tab>return (output, consumed)<tab>return self.decoder(input, self.errors, final)",elif byteorder == 1 :,156
4203,"def _load_db(self):<tab>try:<tab><tab>with open(self.db) as db:<tab><tab><tab>content = db.read(8)<tab><tab><tab>db.seek(0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = StringIO()<tab><tab><tab><tab>if self.encryptor:<tab><tab><tab><tab><tab>self.encryptor.decrypt(db, data)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise EncryptionError(<tab><tab><tab><tab><tab><tab>""Encrpyted credential storage: {}"".format(self.db)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>return json.loads(data.getvalue())<tab><tab><tab>else:<tab><tab><tab><tab>return json.load(db)<tab>except:<tab><tab>return {""creds"": []}","if content == ( ""Salted__"" ) :",187
4204,"def _getbytes(self, start, l=1):<tab>out = []<tab>for ad in range(l):<tab><tab>offset = ad + start + self.base_address<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""not enough bytes"")<tab><tab>out.append(int_to_byte(Byte(offset)))<tab>return b"""".join(out)",if not is_mapped ( offset ) :,90
4205,"def cache_sqs_queues_across_accounts() -> bool:<tab>function: str = f""{__name__}.{sys._getframe().f_code.co_name}""<tab># First, get list of accounts<tab>accounts_d: list = async_to_sync(get_account_id_to_name_mapping)()<tab># Second, call tasks to enumerate all the roles across all accounts<tab>for account_id in accounts_d.keys():<tab><tab>if config.get(""environment"") == ""prod"":<tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab>stats.count(f""{function}.success"")<tab>return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",200
4206,"def insertLine(self, refnum, linenum, line):<tab>i = -1<tab>for i, row in enumerate(self.rows):<tab><tab>if row[0] == linenum:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>row[refnum + 1] = line<tab><tab><tab><tab>return<tab><tab><tab># else keep looking<tab><tab>elif row[0] > linenum:<tab><tab><tab>break<tab>self.rows.insert(i, self.newRow(linenum, refnum, line))",if row [ refnum + 1 ] is None :,125
4207,"def __setattr__(self, name, val):<tab>if self.__dict__.get(name, ""hamster_graphics_no_value_really"") == val:<tab><tab>return<tab>Sprite.__setattr__(self, name, val)<tab>if name == ""image_data"":<tab><tab>self._surface = None<tab><tab><IF-STMT><tab><tab><tab>self.__dict__[""width""] = self.image_data.get_width()<tab><tab><tab>self.__dict__[""height""] = self.image_data.get_height()",if self . image_data :,126
4208,"def process_signature(app, what, name, obj, options, signature, return_annotation):<tab>if signature:<tab><tab># replace Mock function names<tab><tab>signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature)<tab><tab>signature = re.sub(""tensorflow"", ""tf"", signature)<tab><tab># add scope name to layer signatures:<tab><tab>if hasattr(obj, ""use_scope""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>signature = signature[0] + ""variable_scope_name, "" + signature[1:]<tab><tab><tab>elif obj.use_scope is None:<tab><tab><tab><tab>signature = signature[0] + ""[variable_scope_name,] "" + signature[1:]<tab># signature: arg list<tab>return signature, return_annotation",if obj . use_scope :,188
4209,"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz * (1 - sqr(tanh(x))),)",if x . type in discrete_types :,124
4210,"def confirm_on_console(topic, msg):<tab>done = False<tab>print(topic)<tab>while not done:<tab><tab>output = raw_input(msg + "":[y/n]"")<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if output.lower() == ""n"":<tab><tab><tab>return False","if output . lower ( ) == ""y"" :",82
4211,"def replace_documentation_for_matching_shape(self, event_name, section, **kwargs):<tab>if self._shape_name == section.context.get(""shape""):<tab><tab>self._replace_documentation(event_name, section)<tab>for section_name in section.available_sections:<tab><tab>sub_section = section.get_section(section_name)<tab><tab><IF-STMT><tab><tab><tab>self._replace_documentation(event_name, sub_section)<tab><tab>else:<tab><tab><tab>self.replace_documentation_for_matching_shape(event_name, sub_section)","if self . _shape_name == sub_section . context . get ( ""shape"" ) :",152
4212,"def confirm_on_console(topic, msg):<tab>done = False<tab>print(topic)<tab>while not done:<tab><tab>output = raw_input(msg + "":[y/n]"")<tab><tab>if output.lower() == ""y"":<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False","if output . lower ( ) == ""n"" :",82
4213,"def __getitem__(self, index):<tab>if self._check():<tab><tab>if isinstance(index, int):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise IndexError(index)<tab><tab><tab>if self.features[index] is None:<tab><tab><tab><tab>feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index)<tab><tab><tab><tab>if feature:<tab><tab><tab><tab><tab>(feature,) = _unpack(""!H"", feature[:2])<tab><tab><tab><tab><tab>self.features[index] = FEATURE[feature]<tab><tab><tab>return self.features[index]<tab><tab>elif isinstance(index, slice):<tab><tab><tab>indices = index.indices(len(self.features))<tab><tab><tab>return [self.__getitem__(i) for i in range(*indices)]",if index < 0 or index >= len ( self . features ) :,195
4214,"def _parse_locator(self, locator):<tab>prefix = None<tab>criteria = locator<tab>if not locator.startswith(""//""):<tab><tab>locator_parts = locator.partition(""="")<tab><tab><IF-STMT><tab><tab><tab>prefix = locator_parts[0]<tab><tab><tab>criteria = locator_parts[2].strip()<tab>return (prefix, criteria)",if len ( locator_parts [ 1 ] ) > 0 :,89
4215,"def trakt_episode_data_generate(self, data):<tab># Find how many unique season we have<tab>uniqueSeasons = []<tab>for season, episode in data:<tab><tab><IF-STMT><tab><tab><tab>uniqueSeasons.append(season)<tab># build the query<tab>seasonsList = []<tab>for searchedSeason in uniqueSeasons:<tab><tab>episodesList = []<tab><tab>for season, episode in data:<tab><tab><tab>if season == searchedSeason:<tab><tab><tab><tab>episodesList.append({""number"": episode})<tab><tab>seasonsList.append({""number"": searchedSeason, ""episodes"": episodesList})<tab>post_data = {""seasons"": seasonsList}<tab>return post_data",if season not in uniqueSeasons :,189
4216,"def __init__(self, data, n_bins):<tab>bin_width = span / n_bins<tab>bins = [0] * n_bins<tab>for x in data:<tab><tab>b = int(mpfloor((x - minimum) / bin_width))<tab><tab><IF-STMT><tab><tab><tab>b = 0<tab><tab>elif b >= n_bins:<tab><tab><tab>b = n_bins - 1<tab><tab>bins[b] += 1<tab>self.bins = bins<tab>self.bin_width = bin_width",if b < 0 :,124
4217,"def infer_context(typ, context=""http://schema.org""):<tab>parsed_context = urlparse(typ)<tab>if parsed_context.netloc:<tab><tab>base = """".join([parsed_context.scheme, ""://"", parsed_context.netloc])<tab><tab><IF-STMT><tab><tab><tab>context = urljoin(base, parsed_context.path)<tab><tab><tab>typ = parsed_context.fragment.strip(""/"")<tab><tab>elif parsed_context.path:<tab><tab><tab>context = base<tab><tab><tab>typ = parsed_context.path.strip(""/"")<tab>return context, typ",if parsed_context . path and parsed_context . fragment :,140
4218,"def parse(self, items):<tab>for index, item in enumerate(items):<tab><tab>keys = self.build_key(item)<tab><tab>if keys is None:<tab><tab><tab>continue<tab><tab># Update `items`<tab><tab>self.items[tuple(keys)] = (index, item)<tab><tab># Update `table`<tab><tab><IF-STMT><tab><tab><tab>log.info(""Unable to update table (keys: %r)"", keys)","if not self . path_set ( self . table , keys , ( index , item ) ) :",120
4219,"def dict_to_XML(tag, dictionary, **kwargs):<tab>""""""Return XML element converting dicts recursively.""""""<tab>elem = Element(tag, **kwargs)<tab>for key, val in dictionary.items():<tab><tab>if tag == ""layers"":<tab><tab><tab>child = dict_to_XML(""layer"", val, name=key)<tab><tab>elif isinstance(val, MutableMapping):<tab><tab><tab>child = dict_to_XML(key, val)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child = Element(""variable"", name=key)<tab><tab><tab>else:<tab><tab><tab><tab>child = Element(key)<tab><tab><tab>child.text = str(val)<tab><tab>elem.append(child)<tab>return elem","if tag == ""config"" :",175
4220,"def _get_config_value(self, section, key):<tab>if section:<tab><tab><IF-STMT><tab><tab><tab>self.log.error(""Error: Config section '%s' not found"", section)<tab><tab><tab>return None<tab><tab>return self.config[section].get(key, self.config[key])<tab>else:<tab><tab>return self.config[key]",if section not in self . config :,93
4221,"def h_line_down(self, input):<tab>end_this_line = self.value.find(""\n"", self.cursor_position)<tab>if end_this_line == -1:<tab><tab>if self.scroll_exit:<tab><tab><tab>self.h_exit_down(None)<tab><tab>else:<tab><tab><tab>self.cursor_position = len(self.value)<tab>else:<tab><tab>self.cursor_position = end_this_line + 1<tab><tab>for x in range(self.cursorx):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>elif self.value[self.cursor_position] == ""\n"":<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self.cursor_position += 1",if self . cursor_position > len ( self . value ) - 1 :,193
4222,"def printsumfp(fp, filename, out=sys.stdout):<tab>m = md5()<tab>try:<tab><tab>while 1:<tab><tab><tab>data = fp.read(bufsize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if isinstance(data, str):<tab><tab><tab><tab>data = data.encode(fp.encoding)<tab><tab><tab>m.update(data)<tab>except IOError as msg:<tab><tab>sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg))<tab><tab>return 1<tab>out.write(""%s %s\n"" % (m.hexdigest(), filename))<tab>return 0",if not data :,159
4223,"def main(input):<tab>logging.info(""Running Azure Cloud Custodian Policy %s"", input)<tab>context = {<tab><tab>""config_file"": join(function_directory, ""config.json""),<tab><tab>""auth_file"": join(function_directory, ""auth.json""),<tab>}<tab>event = None<tab>subscription_id = None<tab>if isinstance(input, QueueMessage):<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>event = input.get_json()<tab><tab>subscription_id = ResourceIdParser.get_subscription_id(event[""subject""])<tab>handler.run(event, context, subscription_id)",if input . dequeue_count > max_dequeue_count :,166
4224,"def maybeExtractTarball(self):<tab>if self.tarball:<tab><tab>tar = self.computeTarballOptions() + [""-xvf"", self.tarball]<tab><tab>res = yield self._Cmd(tar, abandonOnFailure=False)<tab><tab><IF-STMT>  # error with tarball.. erase repo dir and tarball<tab><tab><tab>yield self._Cmd([""rm"", ""-f"", self.tarball], abandonOnFailure=False)<tab><tab><tab>yield self.runRmdir(self.repoDir(), abandonOnFailure=False)",if res :,124
4225,"def execute(self, arbiter, props):<tab>watcher = self._get_watcher(arbiter, props.pop(""name""))<tab>action = 0<tab>for key, val in props.get(""options"", {}).items():<tab><tab><IF-STMT><tab><tab><tab>new_action = 0<tab><tab><tab>for name, _val in val.items():<tab><tab><tab><tab>action = watcher.set_opt(""hooks.%s"" % name, _val)<tab><tab><tab><tab>if action == 1:<tab><tab><tab><tab><tab>new_action = 1<tab><tab>else:<tab><tab><tab>new_action = watcher.set_opt(key, val)<tab><tab>if new_action == 1:<tab><tab><tab>action = 1<tab># trigger needed action<tab>return watcher.do_action(action)","if key == ""hooks"" :",186
4226,"def _import_playlists(self, fns, library):<tab>added = 0<tab>for filename in fns:<tab><tab>name = _name_for(filename)<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>playlist = parse_m3u(f, name, library=library)<tab><tab><tab>elif filename.endswith("".pls""):<tab><tab><tab><tab>playlist = parse_pls(f, name, library=library)<tab><tab><tab>else:<tab><tab><tab><tab>print_w(""Unsupported playlist type for '%s'"" % filename)<tab><tab><tab><tab>continue<tab><tab>self.changed(playlist)<tab><tab>library.add(playlist)<tab><tab>added += 1<tab>return added","if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :",186
4227,"def unwrap_term_buckets(self, timestamp, term_buckets):<tab>for term_data in term_buckets:<tab><tab><IF-STMT><tab><tab><tab>self.unwrap_interval_buckets(<tab><tab><tab><tab>timestamp, term_data[""key""], term_data[""interval_aggs""][""buckets""]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.check_matches(timestamp, term_data[""key""], term_data)","if ""interval_aggs"" in term_data :",108
4228,"def _get_exception(flags, timeout_ms, payload_size):<tab>if flags & FLAG_ERROR:<tab><tab>if flags & FLAG_TIMEOUT:<tab><tab><tab>return SpicommTimeoutError(timeout_ms / 1000.0)<tab><tab><IF-STMT><tab><tab><tab>return SpicommOverflowError(payload_size)<tab><tab>return SpicommError()<tab>return None",if flags & FLAG_OVERFLOW :,99
4229,"def _get_pattern(self, pattern_id):<tab>""""""Get pattern item by id.""""""<tab>for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3):<tab><tab>if key in self.tagged_blocks:<tab><tab><tab>data = self.tagged_blocks.get_data(key)<tab><tab><tab>for pattern in data:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return pattern<tab>return None",if pattern . pattern_id == pattern_id :,110
4230,"def print_quiet(self, context, *args, **kwargs):<tab>for index, (key, value) in enumerate(<tab><tab>itertools.chain(enumerate(args), kwargs.items())<tab>):<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>self.format_quiet(index, key, value, fields=context.get_input_fields())<tab><tab><tab>)","if self . filter ( index , key , value ) :",99
4231,"def complete(self, block):<tab>with self._condition:<tab><tab>if not self._final:<tab><tab><tab>return False<tab><tab>if self._complete():<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>self._condition.wait_for(self._complete)<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab>return False",if block :,117
4232,"def compression_rotator(source, dest):<tab>with open(source, ""rb"") as sf:<tab><tab>with gzip.open(dest, ""wb"") as wf:<tab><tab><tab>while True:<tab><tab><tab><tab>data = sf.read(CHUNK_SIZE)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>wf.write(data)<tab>os.remove(source)",if not data :,100
4233,"def mockup(self, records):<tab>provider = TransipProvider("""", """", """")<tab>_dns_entries = []<tab>for record in records:<tab><tab><IF-STMT><tab><tab><tab>entries_for = getattr(provider, ""_entries_for_{}"".format(record._type))<tab><tab><tab># Root records have '@' as name<tab><tab><tab>name = record.name<tab><tab><tab>if name == """":<tab><tab><tab><tab>name = provider.ROOT_RECORD<tab><tab><tab>_dns_entries.extend(entries_for(name, record))<tab><tab><tab># NS is not supported as a DNS Entry,<tab><tab><tab># so it should cover the if statement<tab><tab><tab>_dns_entries.append(DnsEntry(""@"", ""3600"", ""NS"", ""ns01.transip.nl.""))<tab>self.mockupEntries = _dns_entries",if record . _type in provider . SUPPORTS :,196
4234,"def parse_known_args(self, args=None, namespace=None):<tab>entrypoint = self.prog.split("" "")[0]<tab>try:<tab><tab>defs = get_defaults_for_argparse(entrypoint)<tab><tab>ignore = defs.pop(""Ignore"", None)<tab><tab>self.set_defaults(**defs)<tab><tab><IF-STMT><tab><tab><tab>set_notebook_diff_ignores(ignore)<tab>except ValueError:<tab><tab>pass<tab>return super(ConfigBackedParser, self).parse_known_args(<tab><tab>args=args, namespace=namespace<tab>)",if ignore :,134
4235,"def _maybeRebuildAtlas(self, threshold=4, minlen=1000):<tab>n = len(self.fragmentAtlas)<tab>if (n > minlen) and (n > threshold * len(self.data)):<tab><tab>self.fragmentAtlas.rebuild(<tab><tab><tab>list(zip(*self._style([""symbol"", ""size"", ""pen"", ""brush""])))<tab><tab>)<tab><tab>self.data[""sourceRect""] = 0<tab><tab><IF-STMT><tab><tab><tab>self._sourceQRect.clear()<tab><tab>self.updateSpots()",if _USE_QRECT :,137
4236,"def dispatch_return(self, frame, arg):<tab>if self.stop_here(frame) or frame == self.returnframe:<tab><tab># Ignore return events in generator except when stepping.<tab><tab><IF-STMT><tab><tab><tab>return self.trace_dispatch<tab><tab>try:<tab><tab><tab>self.frame_returning = frame<tab><tab><tab>self.user_return(frame, arg)<tab><tab>finally:<tab><tab><tab>self.frame_returning = None<tab><tab>if self.quitting:<tab><tab><tab>raise BdbQuit<tab><tab># The user issued a 'next' or 'until' command.<tab><tab>if self.stopframe is frame and self.stoplineno != -1:<tab><tab><tab>self._set_stopinfo(None, None)<tab>return self.trace_dispatch",if self . stopframe and frame . f_code . co_flags & CO_GENERATOR :,199
4237,"def tearDown(self):<tab>if not self.is_playback():<tab><tab>try:<tab><tab><tab>if self.hosted_service_name is not None:<tab><tab><tab><tab>self.sms.delete_hosted_service(self.hosted_service_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.sms.delete_storage_account(self.storage_account_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab>self.sms.delete_affinity_group(self.affinity_group_name)<tab><tab>except:<tab><tab><tab>pass<tab>return super(LegacyMgmtAffinityGroupTest, self).tearDown()",if self . storage_account_name is not None :,180
4238,"def make_log_msg(self, msg, *other_messages):<tab>MAX_MESSAGE_LENGTH = 1000<tab>if not other_messages:<tab><tab># assume that msg is a single string<tab><tab>return msg[-MAX_MESSAGE_LENGTH:]<tab>else:<tab><tab>if len(msg):<tab><tab><tab>msg += ""\n...\n""<tab><tab><tab>NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len(msg)<tab><tab>else:<tab><tab><tab>NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH<tab><tab><IF-STMT><tab><tab><tab>msg += other_messages[0][-NEXT_MESSAGE_OFFSET:]<tab><tab><tab>return self.make_log_msg(msg, *other_messages[1:])<tab><tab>else:<tab><tab><tab>return self.make_log_msg(msg)",if NEXT_MESSAGE_OFFSET > 0 :,196
4239,"def wrapper(  # type: ignore<tab>self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]:<tab>if self.request.path.endswith(""/""):<tab><tab>if self.request.method in (""GET"", ""HEAD""):<tab><tab><tab>uri = self.request.path.rstrip(""/"")<tab><tab><tab>if uri:  # don't try to redirect '/' to ''<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)",if self . request . query :,163
4240,"def process_lib(vars_, coreval):<tab>for d in vars_:<tab><tab>var = d.upper()<tab><tab>if var == ""QTCORE"":<tab><tab><tab>continue<tab><tab>value = env[""LIBPATH_"" + var]<tab><tab><IF-STMT><tab><tab><tab>core = env[coreval]<tab><tab><tab>accu = []<tab><tab><tab>for lib in value:<tab><tab><tab><tab>if lib in core:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>accu.append(lib)<tab><tab><tab>env[""LIBPATH_"" + var] = accu",if value :,133
4241,"def _attach_children(self, other, exclude_worldbody, dry_run=False):<tab>for other_child in other.all_children():<tab><tab><IF-STMT><tab><tab><tab>self_child = self.get_children(other_child.spec.name)<tab><tab><tab>self_child._attach(<tab><tab><tab><tab>other_child, exclude_worldbody, dry_run<tab><tab><tab>)  # pylint: disable=protected-access",if not other_child . spec . repeated :,115
4242,"def getDictFromTree(tree):<tab>ret_dict = {}<tab>for child in tree.getchildren():<tab><tab>if child.getchildren():<tab><tab><tab>## Complex-type child. Recurse<tab><tab><tab>content = getDictFromTree(child)<tab><tab>else:<tab><tab><tab>content = child.text<tab><tab><IF-STMT><tab><tab><tab>if not type(ret_dict[child.tag]) == list:<tab><tab><tab><tab>ret_dict[child.tag] = [ret_dict[child.tag]]<tab><tab><tab>ret_dict[child.tag].append(content or """")<tab><tab>else:<tab><tab><tab>ret_dict[child.tag] = content or """"<tab>return ret_dict",if ret_dict . has_key ( child . tag ) :,175
4243,"def nsUriMatch(self, value, wanted, strict=0, tt=type(())):<tab>""""""Return a true value if two namespace uri values match.""""""<tab>if value == wanted or (type(wanted) is tt) and value in wanted:<tab><tab>return 1<tab>if not strict and value is not None:<tab><tab>wanted = type(wanted) is tt and wanted or (wanted,)<tab><tab>value = value[-1:] != ""/"" and value or value[:-1]<tab><tab>for item in wanted:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 1<tab>return 0",if item == value or item [ : - 1 ] == value :,141
4244,"def update_repository(self, ignore_issues=False, force=False):<tab>""""""Update.""""""<tab>if not await self.common_update(ignore_issues, force):<tab><tab>return<tab># Get appdaemon objects.<tab>if self.repository_manifest:<tab><tab><IF-STMT><tab><tab><tab>self.content.path.remote = """"<tab>if self.content.path.remote == ""apps"":<tab><tab>self.data.domain = get_first_directory_in_directory(<tab><tab><tab>self.tree, self.content.path.remote<tab><tab>)<tab><tab>self.content.path.remote = f""apps/{self.data.name}""<tab># Set local path<tab>self.content.path.local = self.localpath",if self . data . content_in_root :,181
4245,"def addOutput(self, data, isAsync=None, **kwargs):<tab>isAsync = _get_async_param(isAsync, **kwargs)<tab>if isAsync:<tab><tab>self.terminal.eraseLine()<tab><tab>self.terminal.cursorBackward(len(self.lineBuffer) + len(self.ps[self.pn]))<tab>self.terminal.write(data)<tab>if isAsync:<tab><tab><IF-STMT><tab><tab><tab>self.terminal.nextLine()<tab><tab>self.terminal.write(self.ps[self.pn])<tab><tab>if self.lineBuffer:<tab><tab><tab>oldBuffer = self.lineBuffer<tab><tab><tab>self.lineBuffer = []<tab><tab><tab>self.lineBufferIndex = 0<tab><tab><tab>self._deliverBuffer(oldBuffer)",if self . _needsNewline ( ) :,188
4246,"def is_installed(self, dlc_title="""") -> bool:<tab>installed = False<tab>if dlc_title:<tab><tab>dlc_version = self.get_dlc_info(""version"", dlc_title)<tab><tab>installed = True if dlc_version else False<tab><tab># Start: Code for compatibility with minigalaxy 1.0<tab><tab><IF-STMT><tab><tab><tab>status = self.legacy_get_dlc_status(dlc_title)<tab><tab><tab>installed = True if status in [""installed"", ""updatable""] else False<tab><tab># End: Code for compatibility with minigalaxy 1.0<tab>else:<tab><tab>if self.install_dir and os.path.exists(self.install_dir):<tab><tab><tab>installed = True<tab>return installed",if not installed :,178
4247,"def close(self):<tab>self.selector.close()<tab>if self.sock:<tab><tab>sockname = None<tab><tab>try:<tab><tab><tab>sockname = self.sock.getsockname()<tab><tab>except (socket.error, OSError):<tab><tab><tab>pass<tab><tab>self.sock.close()<tab><tab><IF-STMT><tab><tab><tab># it was a Unix domain socket, remove it from the filesystem<tab><tab><tab>if os.path.exists(sockname):<tab><tab><tab><tab>os.remove(sockname)<tab>self.sock = None",if type ( sockname ) is str :,128
4248,"def post_file(self, file_path, graph_type=""edges"", file_type=""csv""):<tab>dataset_id = self.dataset_id<tab>tok = self.token<tab>base_path = self.server_base_path<tab>with open(file_path, ""rb"") as file:<tab><tab>out = requests.post(<tab><tab><tab>f""{base_path}/api/v2/upload/datasets/{dataset_id}/{graph_type}/{file_type}"",<tab><tab><tab>verify=self.certificate_validation,<tab><tab><tab>headers={""Authorization"": f""Bearer {tok}""},<tab><tab><tab>data=file.read(),<tab><tab>).json()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(out)<tab><tab>return out","if not out [ ""success"" ] :",176
4249,"def _get_vqa_v2_image_raw_dataset(directory, image_root_url, image_urls):<tab>""""""Extract the VQA V2 image data set to directory unless it's there.""""""<tab>for url in image_urls:<tab><tab>filename = os.path.basename(url)<tab><tab>download_url = os.path.join(image_root_url, url)<tab><tab>path = generator_utils.maybe_download(directory, filename, download_url)<tab><tab>unzip_dir = os.path.join(directory, filename.strip("".zip""))<tab><tab><IF-STMT><tab><tab><tab>zipfile.ZipFile(path, ""r"").extractall(directory)",if not tf . gfile . Exists ( unzip_dir ) :,165
4250,"def __call__(self, environ, start_response):<tab>for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"":<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>request_uri = unquote(environ[key])<tab><tab>script_name = unquote(environ.get(""SCRIPT_NAME"", """"))<tab><tab>if request_uri.startswith(script_name):<tab><tab><tab>environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0]<tab><tab><tab>break<tab>return self.app(environ, start_response)",if key not in environ :,140
4251,"def _instrument_model(self, model):<tab>for key, value in list(<tab><tab>model.__dict__.items()<tab>):  # avoid ""dictionary keys changed during iteration""<tab><tab>if isinstance(value, tf.keras.layers.Layer):<tab><tab><tab>new_layer = self._instrument(value)<tab><tab><tab>if new_layer is not value:<tab><tab><tab><tab>setattr(model, key, new_layer)<tab><tab><IF-STMT><tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, tf.keras.layers.Layer):<tab><tab><tab><tab><tab>value[i] = self._instrument(item)<tab>return model","elif isinstance ( value , list ) :",164
4252,"def __init__(self, parent, dir, mask, with_dirs=True):<tab>filelist = []<tab>dirlist = [""..""]<tab>self.dir = dir<tab>self.file = """"<tab>mask = mask.upper()<tab>pattern = self.MakeRegex(mask)<tab>for i in os.listdir(dir):<tab><tab>if i == ""."" or i == "".."":<tab><tab><tab>continue<tab><tab>path = os.path.join(dir, i)<tab><tab>if os.path.isdir(path):<tab><tab><tab>dirlist.append(i)<tab><tab><tab>continue<tab><tab>path = path.upper()<tab><tab>value = i.upper()<tab><tab><IF-STMT><tab><tab><tab>filelist.append(i)<tab>self.files = filelist<tab>if with_dirs:<tab><tab>self.dirs = dirlist",if pattern . match ( value ) is not None :,199
4253,"def get_text(self, nodelist):<tab>""""""Return a string representation of the motif's properties listed on nodelist .""""""<tab>retlist = []<tab>for node in nodelist:<tab><tab>if node.nodeType == Node.TEXT_NODE:<tab><tab><tab>retlist.append(node.wholeText)<tab><tab><IF-STMT><tab><tab><tab>retlist.append(self.get_text(node.childNodes))<tab>return re.sub(r""\s+"", "" "", """".join(retlist))",elif node . hasChildNodes :,119
4254,"def _persist_metadata(self, dirname, filename):<tab>metadata_path = ""{0}/{1}.json"".format(dirname, filename)<tab>if self.media_metadata or self.comments or self.include_location:<tab><tab>if self.posts:<tab><tab><tab>if self.latest:<tab><tab><tab><tab>self.merge_json({""GraphImages"": self.posts}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphImages"": self.posts}, metadata_path)<tab><tab><IF-STMT><tab><tab><tab>if self.latest:<tab><tab><tab><tab>self.merge_json({""GraphStories"": self.stories}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphStories"": self.stories}, metadata_path)",if self . stories :,190
4255,"def _get_python_wrapper_content(self, job_class, args):<tab>job = job_class([""-r"", ""hadoop""] + list(args))<tab>job.sandbox()<tab>with job.make_runner() as runner:<tab><tab>runner._create_setup_wrapper_scripts()<tab><tab><IF-STMT><tab><tab><tab>with open(runner._spark_python_wrapper_path) as f:<tab><tab><tab><tab>return f.read()<tab><tab>else:<tab><tab><tab>return None",if runner . _spark_python_wrapper_path :,125
4256,"def computeLeadingWhitespaceWidth(s, tab_width):<tab>w = 0<tab>for ch in s:<tab><tab><IF-STMT><tab><tab><tab>w += 1<tab><tab>elif ch == ""\t"":<tab><tab><tab>w += abs(tab_width) - (w % abs(tab_width))<tab><tab>else:<tab><tab><tab>break<tab>return w","if ch == "" "" :",87
4257,def run(self):<tab># if the i3status process dies we want to restart it.<tab># We give up restarting if we have died too often<tab>for _ in range(10):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>self.spawn_i3status()<tab><tab># check if we never worked properly and if so quit now<tab><tab>if not self.ready:<tab><tab><tab>break<tab><tab># limit restart rate<tab><tab>self.lock.wait(5),if not self . py3_wrapper . running :,122
4258,"def translate_len(<tab>builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Optional[Value]:<tab># Special case builtins.len<tab>if len(expr.args) == 1 and expr.arg_kinds == [ARG_POS]:<tab><tab>expr_rtype = builder.node_type(expr.args[0])<tab><tab><IF-STMT><tab><tab><tab># len() of fixed-length tuple can be trivially determined statically,<tab><tab><tab># though we still need to evaluate it.<tab><tab><tab>builder.accept(expr.args[0])<tab><tab><tab>return Integer(len(expr_rtype.types))<tab><tab>else:<tab><tab><tab>obj = builder.accept(expr.args[0])<tab><tab><tab>return builder.builtin_len(obj, -1)<tab>return None","if isinstance ( expr_rtype , RTuple ) :",188
4259,"def parse_auth(val):<tab>if val is not None:<tab><tab>authtype, params = val.split("" "", 1)<tab><tab>if authtype in known_auth_schemes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># this is the ""Authentication: Basic XXXXX=="" case<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>params = parse_auth_params(params)<tab><tab>return authtype, params<tab>return val","if authtype == ""Basic"" and '""' not in params :",117
4260,"def toxml(self):<tab>text = self.value<tab>self.parent.setBidi(getBidiType(text))<tab>if not text.startswith(HTML_PLACEHOLDER_PREFIX):<tab><tab>if self.parent.nodeName == ""p"":<tab><tab><tab>text = text.replace(""\n"", ""\n   "")<tab><tab><IF-STMT><tab><tab><tab>text = ""\n<tab> "" + text.replace(""\n"", ""\n<tab> "")<tab>text = self.doc.normalizeEntities(text)<tab>return text","elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :",148
4261,"def get_all_related_many_to_many_objects(self):<tab>try:  # Try the cache first.<tab><tab>return self._all_related_many_to_many_objects<tab>except AttributeError:<tab><tab>rel_objs = []<tab><tab>for klass in get_models():<tab><tab><tab>for f in klass._meta.many_to_many:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>rel_objs.append(RelatedObject(f.rel.to, klass, f))<tab><tab>self._all_related_many_to_many_objects = rel_objs<tab><tab>return rel_objs",if f . rel and self == f . rel . to . _meta :,158
4262,"def state_highstate(self, state, dirpath):<tab>opts = copy.copy(self.config)<tab>opts[""file_roots""] = dict(base=[dirpath])<tab>HIGHSTATE = HighState(opts)<tab>HIGHSTATE.push_active()<tab>try:<tab><tab>high, errors = HIGHSTATE.render_highstate(state)<tab><tab><IF-STMT><tab><tab><tab>import pprint<tab><tab><tab>pprint.pprint(""\n"".join(errors))<tab><tab><tab>pprint.pprint(high)<tab><tab>out = HIGHSTATE.state.call_high(high)<tab><tab># pprint.pprint(out)<tab>finally:<tab><tab>HIGHSTATE.pop_active()",if errors :,156
4263,"def _update_target_host(self, target, target_host):<tab>""""""Update target host.""""""<tab>target_host = None if target_host == """" else target_host<tab>if not target_host:<tab><tab>for device_type, tgt in target.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>target_host = tgt<tab><tab><tab><tab>break<tab>if not target_host:<tab><tab>target_host = ""llvm"" if tvm.runtime.enabled(""llvm"") else ""stackvm""<tab>if isinstance(target_host, str):<tab><tab>target_host = tvm.target.Target(target_host)<tab>return target_host",if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,171
4264,"def __console_writer(self):<tab>while True:<tab><tab>self.__writer_event.wait()<tab><tab>self.__writer_event.clear()<tab><tab>if self.__console_view:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.debug(""Writing console view to STDOUT"")<tab><tab><tab><tab>sys.stdout.write(self.console_markup.clear)<tab><tab><tab><tab>sys.stdout.write(self.__console_view)<tab><tab><tab><tab>sys.stdout.write(self.console_markup.TOTAL_RESET)",if not self . short_only :,134
4265,"def goToPrevMarkedHeadline(self, event=None):<tab>""""""Select the next marked node.""""""<tab>c = self<tab>p = c.p<tab>if not p:<tab><tab>return<tab>p.moveToThreadBack()<tab>wrapped = False<tab>while 1:<tab><tab>if p and p.isMarked():<tab><tab><tab>break<tab><tab>elif p:<tab><tab><tab>p.moveToThreadBack()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>wrapped = True<tab><tab><tab>p = c.rootPosition()<tab>if not p:<tab><tab>g.blue(""done"")<tab>c.treeSelectHelper(p)  # Sets focus.",elif wrapped :,164
4266,"def delete_map(self, query=None):<tab>query_map = self.interpolated_map(query=query)<tab>for alias, drivers in six.iteritems(query_map.copy()):<tab><tab>for driver, vms in six.iteritems(drivers.copy()):<tab><tab><tab>for vm_name, vm_details in six.iteritems(vms.copy()):<tab><tab><tab><tab>if vm_details == ""Absent"":<tab><tab><tab><tab><tab>query_map[alias][driver].pop(vm_name)<tab><tab><tab>if not query_map[alias][driver]:<tab><tab><tab><tab>query_map[alias].pop(driver)<tab><tab><IF-STMT><tab><tab><tab>query_map.pop(alias)<tab>return query_map",if not query_map [ alias ] :,177
4267,"def get_shadows_zip(filename):<tab>import zipfile<tab>shadow_pkgs = set()<tab>with zipfile.ZipFile(filename) as lib_zip:<tab><tab>already_test = []<tab><tab>for fname in lib_zip.namelist():<tab><tab><tab>pname, fname = os.path.split(fname)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if pname not in already_test and ""/"" not in pname:<tab><tab><tab><tab>already_test.append(pname)<tab><tab><tab><tab>if is_shadowing(pname):<tab><tab><tab><tab><tab>shadow_pkgs.add(pname)<tab>return shadow_pkgs",if fname or ( pname and fname ) :,159
4268,"def make_chains(chains_info):<tab>chains = [[] for _ in chains_info[0][1]]<tab>for i, num_ids in enumerate(chains_info[:-1]):<tab><tab>num, ids = num_ids<tab><tab>for j, ident in enumerate(ids):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>next_chain_info = chains_info[i + 1]<tab><tab><tab><tab>previous = next_chain_info[1][j]<tab><tab><tab><tab>block = SimpleBlock(num, ident, previous)<tab><tab><tab><tab>chains[j].append(block)<tab>chains = {i: make_generator(chain) for i, chain in enumerate(chains)}<tab>return chains","if ident != """" :",164
4269,"def filter_input(mindate, maxdate, files):<tab>mindate = parse(mindate) if mindate is not None else datetime.datetime.min<tab>maxdate = parse(maxdate) if maxdate is not None else datetime.datetime.max<tab>for line in fileinput.input(files):<tab><tab>tweet = json.loads(line)<tab><tab>created_at = parse(tweet[""created_at""])<tab><tab>created_at = created_at.replace(tzinfo=None)<tab><tab><IF-STMT><tab><tab><tab>print(json.dumps(tweet))",if mindate < created_at and maxdate > created_at :,149
4270,"def get(self):<tab>""""""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called.""""""<tab>if self._exception is not _NONE:<tab><tab>if self._exception is None:<tab><tab><tab>return self.value<tab><tab>getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ConcurrentObjectUseError(<tab><tab><tab><tab>""This Waiter is already used by %r"" % (self.greenlet,)<tab><tab><tab>)<tab><tab>self.greenlet = getcurrent()  # pylint:disable=undefined-variable<tab><tab>try:<tab><tab><tab>return self.hub.switch()<tab><tab>finally:<tab><tab><tab>self.greenlet = None",if self . greenlet is not None :,188
4271,"def default_loader(href, parse, encoding=None):<tab>with open(href) as file:<tab><tab><IF-STMT><tab><tab><tab>data = ElementTree.parse(file).getroot()<tab><tab>else:<tab><tab><tab>data = file.read()<tab><tab><tab>if encoding:<tab><tab><tab><tab>data = data.decode(encoding)<tab>return data","if parse == ""xml"" :",86
4272,def is_all_qud(world):<tab>m = True<tab>for obj in world:<tab><tab><IF-STMT><tab><tab><tab>if obj.nice:<tab><tab><tab><tab>m = m and True<tab><tab><tab>else:<tab><tab><tab><tab>m = m and False<tab><tab>else:<tab><tab><tab>m = m and True<tab>return m,if obj . blond :,85
4273,"def run(self, edit):<tab>if not self.has_selection():<tab><tab>region = sublime.Region(0, self.view.size())<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab>if prefixed:<tab><tab><tab>self.view.replace(edit, region, prefixed)<tab><tab>return<tab>for region in self.view.sel():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab>if prefixed:<tab><tab><tab>self.view.replace(edit, region, prefixed)",if region . empty ( ) :,163
4274,"def add_fields(self, params):<tab>for (key, val) in params.iteritems():<tab><tab><IF-STMT><tab><tab><tab>new_params = {}<tab><tab><tab>for k in val:<tab><tab><tab><tab>new_params[""%s__%s"" % (key, k)] = val[k]<tab><tab><tab>self.add_fields(new_params)<tab><tab>else:<tab><tab><tab>self.add_field(key, val)","if isinstance ( val , dict ) :",108
4275,"def find_magic(self, f, pos, magic):<tab>f.seek(pos)<tab>block = f.read(32 * 1024)<tab>if len(block) < len(magic):<tab><tab>return -1<tab>p = block.find(magic)<tab>while p < 0:<tab><tab>pos += len(block) - len(magic) + 1<tab><tab>block = block[1 - len(magic) :] + f.read(32 << 10)<tab><tab><IF-STMT><tab><tab><tab>return -1<tab><tab>p = block.find(magic)<tab>return pos + p",if len ( block ) == len ( magic ) - 1 :,148
4276,"def check_strings(self):<tab>""""""Check that all strings have been consumed.""""""<tab>for i, aList in enumerate(self.string_tokens):<tab><tab><IF-STMT><tab><tab><tab>g.trace(""warning: line %s. unused strings"" % i)<tab><tab><tab>for z in aList:<tab><tab><tab><tab>print(self.dump_token(z))",if aList :,87
4277,"def get_tokens_unprocessed(self, text):<tab>from pygments.lexers._cocoa_builtins import (<tab><tab>COCOA_INTERFACES,<tab><tab>COCOA_PROTOCOLS,<tab><tab>COCOA_PRIMITIVES,<tab>)<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>value in COCOA_INTERFACES<tab><tab><tab><tab>or value in COCOA_PROTOCOLS<tab><tab><tab><tab>or value in COCOA_PRIMITIVES<tab><tab><tab>):<tab><tab><tab><tab>token = Name.Builtin.Pseudo<tab><tab>yield index, token, value",if token is Name or token is Name . Class :,176
4278,"def key_from_key_value_dict(key_info):<tab>res = []<tab>if not ""key_value"" in key_info:<tab><tab>return res<tab>for value in key_info[""key_value""]:<tab><tab><IF-STMT><tab><tab><tab>e = base64_to_long(value[""rsa_key_value""][""exponent""])<tab><tab><tab>m = base64_to_long(value[""rsa_key_value""][""modulus""])<tab><tab><tab>key = RSA.construct((m, e))<tab><tab><tab>res.append(key)<tab>return res","if ""rsa_key_value"" in value :",141
4279,"def run(self, edit):<tab>if not self.has_selection():<tab><tab>region = sublime.Region(0, self.view.size())<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab><IF-STMT><tab><tab><tab>self.view.replace(edit, region, prefixed)<tab><tab>return<tab>for region in self.view.sel():<tab><tab>if region.empty():<tab><tab><tab>continue<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab>if prefixed:<tab><tab><tab>self.view.replace(edit, region, prefixed)",if prefixed :,163
4280,def finalize(self):<tab>if self.ct < 1:<tab><tab>return<tab>elif self.ct == 1:<tab><tab>return 0<tab>total = ct = 0<tab>dtp = None<tab>while self.heap:<tab><tab><IF-STMT><tab><tab><tab>if dtp is None:<tab><tab><tab><tab>dtp = heapq.heappop(self.heap)<tab><tab><tab><tab>continue<tab><tab>dt = heapq.heappop(self.heap)<tab><tab>diff = dt - dtp<tab><tab>ct += 1<tab><tab>total += total_seconds(diff)<tab><tab>dtp = dt<tab>return float(total) / ct,if total == 0 :,150
4281,"def _test_configuration(self):<tab>config_path = self._write_config()<tab>try:<tab><tab>self._log.debug(""testing configuration"")<tab><tab>verboseflag = ""-Q""<tab><tab><IF-STMT><tab><tab><tab>verboseflag = ""-v""<tab><tab>p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path])<tab><tab>if p.wait() != 0:<tab><tab><tab>raise RuntimeError(""configuration test failed"")<tab><tab>self._log.debug(""configuration seems ok"")<tab>finally:<tab><tab>os.remove(config_path)",if self . _log . isEnabledFor ( logging . DEBUG ) :,147
4282,"def exe(self, ret):<tab>if not ret:<tab><tab>self.assertEqual(ret, """")<tab>else:<tab><tab>assert os.path.isabs(ret), ret<tab><tab># Note: os.stat() may return False even if the file is there<tab><tab># hence we skip the test, see:<tab><tab># http://stackoverflow.com/questions/3112546/os-path-exists-lies<tab><tab><IF-STMT><tab><tab><tab>assert os.path.isfile(ret), ret<tab><tab><tab>if hasattr(os, ""access"") and hasattr(os, ""X_OK""):<tab><tab><tab><tab># XXX may fail on OSX<tab><tab><tab><tab>self.assertTrue(os.access(ret, os.X_OK))",if POSIX :,171
4283,"def _do_cleanup(sg_name, device_id):<tab>masking_view_list = self.rest.get_masking_views_from_storage_group(array, sg_name)<tab>for masking_view in masking_view_list:<tab><tab><IF-STMT><tab><tab><tab>self.rest.delete_masking_view(array, masking_view)<tab><tab><tab>self.rest.remove_vol_from_sg(array, sg_name, device_id, extra_specs)<tab><tab><tab>self.rest.delete_volume(array, device_id)<tab><tab><tab>self.rest.delete_storage_group(array, sg_name)","if ""STG-"" in masking_view :",159
4284,"def hide_tooltip_if_necessary(self, key):<tab>""""""Hide calltip when necessary""""""<tab>try:<tab><tab>calltip_char = self.get_character(self.calltip_position)<tab><tab>before = self.is_cursor_before(self.calltip_position, char_offset=1)<tab><tab>other = key in (Qt.Key_ParenRight, Qt.Key_Period, Qt.Key_Tab)<tab><tab><IF-STMT><tab><tab><tab>QToolTip.hideText()<tab>except (IndexError, TypeError):<tab><tab>QToolTip.hideText()","if calltip_char not in ( ""?"" , ""("" ) or before or other :",148
4285,"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None):<tab>stream = self.describe_stream(stream_name)<tab>tags = []<tab>result = {""HasMoreTags"": False, ""Tags"": tags}<tab>for key, val in sorted(stream.tags.items(), key=lambda x: x[0]):<tab><tab>if limit and len(tags) >= limit:<tab><tab><tab>result[""HasMoreTags""] = True<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>tags.append({""Key"": key, ""Value"": val})<tab>return result",if exclusive_start_tag_key and key < exclusive_start_tag_key :,166
4286,"def parametrize_function_name(request, function_name):<tab>suffixes = []<tab>if ""parametrize"" in request.keywords:<tab><tab>argnames = request.keywords[""parametrize""].args[::2]<tab><tab>argnames = [x.strip() for names in argnames for x in names.split("","")]<tab><tab>for name in argnames:<tab><tab><tab>value = request.getfuncargvalue(name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.__name__<tab><tab><tab>suffixes.append(""{}={}"".format(name, value))<tab>return ""+"".join([function_name] + suffixes)",if inspect . isclass ( value ) :,145
4287,"def add_entities(self, positions):<tab>e1 = EntityFactory()<tab>for p in positions:<tab><tab><IF-STMT><tab><tab><tab>start, length = p<tab><tab>else:<tab><tab><tab>start, length = p, 1<tab><tab>EntityOccurrenceFactory(<tab><tab><tab>document=self.doc,<tab><tab><tab>entity=e1,<tab><tab><tab>offset=start,<tab><tab><tab>offset_end=start + length,<tab><tab><tab>alias=""AB"",<tab><tab>)","if isinstance ( p , tuple ) :",119
4288,"def transform_value(value):<tab>if isinstance(value, collections.MutableMapping):<tab><tab><IF-STMT><tab><tab><tab>return DBRef(value[""_ns""], transform_value(value[""_id""]))<tab><tab>else:<tab><tab><tab>return transform_dict(SON(value))<tab>elif isinstance(value, list):<tab><tab>return [transform_value(v) for v in value]<tab>return value","if ""_id"" in value and ""_ns"" in value :",103
4289,"def remove(self, items):<tab>""""""Remove messages from lease management.""""""<tab>with self._add_remove_lock:<tab><tab># Remove the ack ID from lease management, and decrement the<tab><tab># byte counter.<tab><tab>for item in items:<tab><tab><tab>if self._leased_messages.pop(item.ack_id, None) is not None:<tab><tab><tab><tab>self._bytes -= item.byte_size<tab><tab><tab>else:<tab><tab><tab><tab>_LOGGER.debug(""Item %s was not managed."", item.ack_id)<tab><tab><IF-STMT><tab><tab><tab>_LOGGER.debug(""Bytes was unexpectedly negative: %d"", self._bytes)<tab><tab><tab>self._bytes = 0",if self . _bytes < 0 :,172
4290,"def parse_hgsub(lines):<tab>""""""Fills OrderedDict with hgsub file content passed as list of lines""""""<tab>rv = OrderedDict()<tab>for l in lines:<tab><tab>ls = l.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>name, value = l.split(""="", 1)<tab><tab>rv[name.strip()] = value.strip()<tab>return rv","if not ls or ls [ 0 ] == ""#"" :",98
4291,"def del_(self, key):<tab>initial_hash = hash_ = self.hash(key)<tab>while True:<tab><tab>if self._keys[hash_] is self._empty:<tab><tab><tab># That key was never assigned<tab><tab><tab>return None<tab><tab>elif self._keys[hash_] == key:<tab><tab><tab># key found, assign with deleted sentinel<tab><tab><tab>self._keys[hash_] = self._deleted<tab><tab><tab>self._values[hash_] = self._deleted<tab><tab><tab>self._len -= 1<tab><tab><tab>return<tab><tab>hash_ = self._rehash(hash_)<tab><tab><IF-STMT><tab><tab><tab># table is full and wrapped around<tab><tab><tab>return None",if initial_hash == hash_ :,166
4292,"def atom(token, no_symbol=False):<tab>try:<tab><tab>return int(token)<tab>except ValueError:<tab><tab>try:<tab><tab><tab>return float(token)<tab><tab>except ValueError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return token[1:-1]<tab><tab><tab>elif no_symbol:<tab><tab><tab><tab>return token<tab><tab><tab>else:<tab><tab><tab><tab>return Symbol(token)","if token . startswith ( ""'"" ) or token . startswith ( '""' ) :",107
4293,"def __Suffix_Noun_Step1b(self, token):<tab>for suffix in self.__suffix_noun_step1b:<tab><tab><IF-STMT><tab><tab><tab>token = token[:-1]<tab><tab><tab>self.suffixe_noun_step1b_success = True<tab><tab><tab>break<tab>return token",if token . endswith ( suffix ) and len ( token ) > 5 :,87
4294,"def _guardAgainstUnicode(self, data):<tab># Only accept byte strings or ascii unicode values, otherwise<tab># there is no way to correctly decode the data into bytes.<tab>if _pythonMajorVersion < 3:<tab><tab><IF-STMT><tab><tab><tab>data = data.encode(""utf8"")<tab>else:<tab><tab>if isinstance(data, str):<tab><tab><tab># Only accept ascii unicode values.<tab><tab><tab>try:<tab><tab><tab><tab>return data.encode(""ascii"")<tab><tab><tab>except UnicodeEncodeError:<tab><tab><tab><tab>pass<tab><tab><tab>raise ValueError(""pyDes can only work with encoded strings, not Unicode."")<tab>return data","if isinstance ( data , unicode ) :",154
4295,"def populate_resource_parameters(self, tool_source):<tab>root = getattr(tool_source, ""root"", None)<tab>if (<tab><tab>root is not None<tab><tab>and hasattr(self.app, ""job_config"")<tab><tab>and hasattr(self.app.job_config, ""get_tool_resource_xml"")<tab>):<tab><tab>resource_xml = self.app.job_config.get_tool_resource_xml(<tab><tab><tab>root.get(""id""), self.tool_type<tab><tab>)<tab><tab>if resource_xml is not None:<tab><tab><tab>inputs = root.find(""inputs"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>inputs = parse_xml_string(""<inputs/>"")<tab><tab><tab><tab>root.append(inputs)<tab><tab><tab>inputs.append(resource_xml)",if inputs is None :,194
4296,"def test_arguments_regex(self):<tab>argument_matches = (<tab><tab>(""pip=1.1"", (""pip"", ""1.1"")),<tab><tab>(""pip==1.1"", None),<tab><tab>(""pip=1.2=1"", (""pip"", ""1.2=1"")),<tab>)<tab>for argument, match in argument_matches:<tab><tab><IF-STMT><tab><tab><tab>self.assertIsNone(salt.utils.args.KWARG_REGEX.match(argument))<tab><tab>else:<tab><tab><tab>self.assertEqual(<tab><tab><tab><tab>salt.utils.args.KWARG_REGEX.match(argument).groups(), match<tab><tab><tab>)",if match is None :,157
4297,"def _get_sidebar_selected(self):<tab>sidebar_selected = None<tab>if self.businessline_id:<tab><tab>sidebar_selected = ""bl_%s"" % self.businessline_id<tab><tab>if self.service_id:<tab><tab><tab>sidebar_selected += ""_s_%s"" % self.service_id<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sidebar_selected += ""_env_%s"" % self.environment_id<tab>return sidebar_selected",if self . environment_id :,113
4298,"def get_ip_info(ipaddress):<tab>""""""Returns device information by IP address""""""<tab>result = {}<tab>try:<tab><tab>ip = IPAddress.objects.select_related().get(address=ipaddress)<tab>except IPAddress.DoesNotExist:<tab><tab>pass<tab>else:<tab><tab>if ip.venture is not None:<tab><tab><tab>result[""venture_id""] = ip.venture.id<tab><tab><IF-STMT><tab><tab><tab>result[""device_id""] = ip.device.id<tab><tab><tab>if ip.device.venture is not None:<tab><tab><tab><tab>result[""venture_id""] = ip.device.venture.id<tab>return result",if ip . device is not None :,162
4299,"def apply(self, db, person):<tab>for family_handle in person.get_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>for event_ref in family.get_event_ref_list():<tab><tab><tab><tab>if event_ref:<tab><tab><tab><tab><tab>event = db.get_event_from_handle(event_ref.ref)<tab><tab><tab><tab><tab>if not event.get_place_handle():<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False",if not event . get_date_object ( ) :,159
4300,"def killIfDead():<tab>if not self._isalive:<tab><tab>self.log.debug(<tab><tab><tab>""WampLongPoll: killing inactive WAMP session with transport '{0}'"".format(<tab><tab><tab><tab>self._transport_id<tab><tab><tab>)<tab><tab>)<tab><tab>self.onClose(False, 5000, ""session inactive"")<tab><tab>self._receive._kill()<tab><tab><IF-STMT><tab><tab><tab>del self._parent._transports[self._transport_id]<tab>else:<tab><tab>self.log.debug(<tab><tab><tab>""WampLongPoll: transport '{0}' is still alive"".format(self._transport_id)<tab><tab>)<tab><tab>self._isalive = False<tab><tab>self.reactor.callLater(killAfter, killIfDead)",if self . _transport_id in self . _parent . _transports :,196
4301,"def offsets(self):<tab>offsets = {}<tab>offset_so_far = 0<tab>for name, ty in self.fields.items():<tab><tab><IF-STMT><tab><tab><tab>l.warning(<tab><tab><tab><tab>""Found a bottom field in struct %s. Ignore and increment the offset using the default ""<tab><tab><tab><tab>""element size."",<tab><tab><tab><tab>self.name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>if not self._pack:<tab><tab><tab>align = ty.alignment<tab><tab><tab>if offset_so_far % align != 0:<tab><tab><tab><tab>offset_so_far += align - offset_so_far % align<tab><tab>offsets[name] = offset_so_far<tab><tab>offset_so_far += ty.size // self._arch.byte_width<tab>return offsets","if isinstance ( ty , SimTypeBottom ) :",196
4302,"def get_override_css(self):<tab>""""""handls allow_css_overrides setting.""""""<tab>if self.settings.get(""allow_css_overrides""):<tab><tab>filename = self.view.file_name()<tab><tab>filetypes = self.settings.get(""markdown_filetypes"")<tab><tab><IF-STMT><tab><tab><tab>for filetype in filetypes:<tab><tab><tab><tab>if filename.endswith(filetype):<tab><tab><tab><tab><tab>css_filename = filename.rpartition(filetype)[0] + "".css""<tab><tab><tab><tab><tab>if os.path.isfile(css_filename):<tab><tab><tab><tab><tab><tab>return u""<style>%s</style>"" % load_utf8(css_filename)<tab>return """"",if filename and filetypes :,165
4303,"def setFullCSSSource(self, fullsrc, inline=False):<tab>self.fullsrc = fullsrc<tab>if type(self.fullsrc) == six.binary_type:<tab><tab>self.fullsrc = six.text_type(self.fullsrc, ""utf-8"")<tab>if inline:<tab><tab>self.inline = inline<tab>if self.fullsrc:<tab><tab>self.srcFullIdx = self.fullsrc.find(self.src)<tab><tab>if self.srcFullIdx < 0:<tab><tab><tab>del self.srcFullIdx<tab><tab>self.ctxsrcFullIdx = self.fullsrc.find(self.ctxsrc)<tab><tab><IF-STMT><tab><tab><tab>del self.ctxsrcFullIdx",if self . ctxsrcFullIdx < 0 :,175
4304,"def title(self):<tab>ret = theme[""title""]<tab>if isinstance(self.name, six.string_types):<tab><tab>width = self.statwidth()<tab><tab>return (<tab><tab><tab>ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""]<tab><tab>)<tab>for i, name in enumerate(self.name):<tab><tab>width = self.colwidth()<tab><tab>ret = ret + name[0:width].center(width).replace("" "", ""-"")<tab><tab>if i + 1 != len(self.vars):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = ret + theme[""frame""] + char[""dash""] + theme[""title""]<tab><tab><tab>else:<tab><tab><tab><tab>ret = ret + char[""space""]<tab>return ret",if op . color :,188
4305,"def _get_requested_databases(self):<tab>""""""Returns a list of databases requested, not including ignored dbs""""""<tab>requested_databases = []<tab>if (self._requested_namespaces is not None) and (self._requested_namespaces != []):<tab><tab>for requested_namespace in self._requested_namespaces:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return []<tab><tab><tab>elif requested_namespace[0] not in IGNORE_DBS:<tab><tab><tab><tab>requested_databases.append(requested_namespace[0])<tab>return requested_databases","if requested_namespace [ 0 ] is ""*"" :",131
4306,"def add_channels(cls, voucher, add_channels):<tab>for add_channel in add_channels:<tab><tab>channel = add_channel[""channel""]<tab><tab>defaults = {""currency"": channel.currency_code}<tab><tab><IF-STMT><tab><tab><tab>defaults[""discount_value""] = add_channel.get(""discount_value"")<tab><tab>if ""min_amount_spent"" in add_channel.keys():<tab><tab><tab>defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None)<tab><tab>models.VoucherChannelListing.objects.update_or_create(<tab><tab><tab>voucher=voucher,<tab><tab><tab>channel=channel,<tab><tab><tab>defaults=defaults,<tab><tab>)","if ""discount_value"" in add_channel . keys ( ) :",176
4307,"def read_xml(path):<tab>with tf.gfile.GFile(path) as f:<tab><tab>root = etree.fromstring(f.read())<tab>annotations = {}<tab>for node in root.getchildren():<tab><tab>key, val = node2dict(node)<tab><tab># If `key` is object, it's actually a list.<tab><tab><IF-STMT><tab><tab><tab>annotations.setdefault(key, []).append(val)<tab><tab>else:<tab><tab><tab>annotations[key] = val<tab>return annotations","if key == ""object"" :",123
4308,"def get_ip_info(ipaddress):<tab>""""""Returns device information by IP address""""""<tab>result = {}<tab>try:<tab><tab>ip = IPAddress.objects.select_related().get(address=ipaddress)<tab>except IPAddress.DoesNotExist:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>result[""venture_id""] = ip.venture.id<tab><tab>if ip.device is not None:<tab><tab><tab>result[""device_id""] = ip.device.id<tab><tab><tab>if ip.device.venture is not None:<tab><tab><tab><tab>result[""venture_id""] = ip.device.venture.id<tab>return result",if ip . venture is not None :,162
4309,"def test_large_headers(self):<tab>with ExpectLog(gen_log, ""Unsatisfiable read"", required=False):<tab><tab>try:<tab><tab><tab>self.fetch(""/"", headers={""X-Filler"": ""a"" * 1000}, raise_error=True)<tab><tab><tab>self.fail(""did not raise expected exception"")<tab><tab>except HTTPError as e:<tab><tab><tab># 431 is ""Request Header Fields Too Large"", defined in RFC<tab><tab><tab># 6585. However, many implementations just close the<tab><tab><tab># connection in this case, resulting in a missing response.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertIn(e.response.code, (431, 599))",if e . response is not None :,167
4310,"def validate_reserved_serial_no_consumption(self):<tab>for item in self.items:<tab><tab>if item.s_warehouse and not item.t_warehouse and item.serial_no:<tab><tab><tab>for sr in get_serial_nos(item.serial_no):<tab><tab><tab><tab>sales_order = frappe.db.get_value(""Serial No"", sr, ""sales_order"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>msg = _(<tab><tab><tab><tab><tab><tab>""(Serial No: {0}) cannot be consumed as it's reserverd to fullfill Sales Order {1}.""<tab><tab><tab><tab><tab>).format(sr, sales_order)<tab><tab><tab><tab><tab>frappe.throw(_(""Item {0} {1}"").format(item.item_code, msg))",if sales_order :,190
4311,"def force_decode(string, encoding):<tab>if isinstance(string, str):<tab><tab><IF-STMT><tab><tab><tab>string = string.decode(encoding)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab># try decoding with utf-8, should only work for real UTF-8<tab><tab><tab><tab>string = string.decode(""utf-8"")<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab># last resort -- can't fail<tab><tab><tab><tab>string = string.decode(""latin1"")<tab>return string",if encoding :,121
4312,"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None):<tab>new_parameters = []<tab>for hp in sub_cs.get_hyperparameters():<tab><tab>new_parameter = copy.deepcopy(hp)<tab><tab># Allow for an empty top-level parameter<tab><tab>if new_parameter.name == """":<tab><tab><tab>new_parameter.name = prefix<tab><tab><IF-STMT><tab><tab><tab>new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name)<tab><tab>new_parameters.append(new_parameter)<tab>for hp in new_parameters:<tab><tab>_add_hp(master_cs, hp)","elif not prefix == """" :",162
4313,"def __call__(self, *args, **kwargs):<tab>if self.log_file is not None:<tab><tab>kwargs[""file""] = self.log_file<tab><tab>print(*args, **kwargs)<tab><tab><IF-STMT><tab><tab><tab># get immediate feedback<tab><tab><tab>self.log_file.flush()<tab>elif self.log_func is not None:<tab><tab>self.log_func(*args, **kwargs)","if hasattr ( self . log_file , ""flush"" ) :",109
4314,"def df_index_expr(self, length_expr=None, as_range=False):<tab>""""""Generate expression to get or create index of DF""""""<tab>if isinstance(self.index, types.NoneType):<tab><tab><IF-STMT><tab><tab><tab>length_expr = df_length_expr(self)<tab><tab>if as_range:<tab><tab><tab>return f""range({length_expr})""<tab><tab>else:<tab><tab><tab>return f""numpy.arange({length_expr})""<tab>return ""self._index""",if length_expr is None :,123
4315,"def _setWeight(self, value):<tab>if value is None:<tab><tab>self._fontWeight = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise TextFormatException(f""Not a supported fontWeight: {value}"")<tab><tab>self._fontWeight = value.lower()","if value . lower ( ) not in ( ""normal"" , ""bold"" ) :",78
4316,"def _test_configuration(self):<tab>config_path = self._write_config()<tab>try:<tab><tab>self._log.debug(""testing configuration"")<tab><tab>verboseflag = ""-Q""<tab><tab>if self._log.isEnabledFor(logging.DEBUG):<tab><tab><tab>verboseflag = ""-v""<tab><tab>p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path])<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""configuration test failed"")<tab><tab>self._log.debug(""configuration seems ok"")<tab>finally:<tab><tab>os.remove(config_path)",if p . wait ( ) != 0 :,147
4317,"def filter_queryset(self, request, queryset, view):<tab>kwargs = {}<tab>for field in view.filterset_fields:<tab><tab>value = request.GET.get(field)<tab><tab>if not value:<tab><tab><tab>continue<tab><tab>if field == ""node_id"":<tab><tab><tab>value = get_object_or_none(Node, pk=value)<tab><tab><tab>kwargs[""node""] = value<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>field = ""asset""<tab><tab>kwargs[field] = value<tab>if kwargs:<tab><tab>queryset = queryset.filter(**kwargs)<tab>logger.debug(""Filter {}"".format(kwargs))<tab>return queryset","elif field == ""asset_id"" :",162
4318,"def _find_closing_brace(string, start_pos):<tab>""""""Finds the corresponding closing brace after start_pos.""""""<tab>bracks_open = 1<tab>for idx, char in enumerate(string[start_pos:]):<tab><tab>if char == ""("":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>bracks_open += 1<tab><tab>elif char == "")"":<tab><tab><tab>if string[idx + start_pos - 1] != ""\\"":<tab><tab><tab><tab>bracks_open -= 1<tab><tab><tab>if not bracks_open:<tab><tab><tab><tab>return start_pos + idx + 1","if string [ idx + start_pos - 1 ] != ""\\"" :",145
4319,"def _set_hostport(self, host, port):<tab>if port is None:<tab><tab>i = host.rfind("":"")<tab><tab>j = host.rfind(""]"")  # ipv6 addresses have [...]<tab><tab>if i > j:<tab><tab><tab>try:<tab><tab><tab><tab>port = int(host[i + 1 :])<tab><tab><tab>except ValueError:<tab><tab><tab><tab>raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :])<tab><tab><tab>host = host[:i]<tab><tab>else:<tab><tab><tab>port = self.default_port<tab><tab><IF-STMT><tab><tab><tab>host = host[1:-1]<tab>self.host = host<tab>self.port = port","if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :",176
4320,"def __getstate__(self):<tab>state = {}<tab>for cls in type(self).mro():<tab><tab>cls_slots = getattr(cls, ""__slots__"", ())<tab><tab>for slot in cls_slots:<tab><tab><tab>if slot != ""__weakref__"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>state[slot] = getattr(self, slot)<tab>state[""_cookiejar_cookies""] = list(self.cookiejar)<tab>del state[""cookiejar""]<tab>return state","if hasattr ( self , slot ) :",113
4321,"def _evp_pkey_from_der_traditional_key(self, bio_data, password):<tab>key = self._lib.d2i_PrivateKey_bio(bio_data.bio, self._ffi.NULL)<tab>if key != self._ffi.NULL:<tab><tab>key = self._ffi.gc(key, self._lib.EVP_PKEY_free)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""Password was given but private key is not encrypted."")<tab><tab>return key<tab>else:<tab><tab>self._consume_errors()<tab><tab>return None",if password is not None :,142
4322,"def is_special(s, i, directive):<tab>""""""Return True if the body text contains the @ directive.""""""<tab># j = skip_line(s,i) ; trace(s[i:j],':',directive)<tab>assert directive and directive[0] == ""@""<tab># 10/23/02: all directives except @others must start the line.<tab>skip_flag = directive in (""@others"", ""@all"")<tab>while i < len(s):<tab><tab><IF-STMT><tab><tab><tab>return True, i<tab><tab>else:<tab><tab><tab>i = skip_line(s, i)<tab><tab><tab>if skip_flag:<tab><tab><tab><tab>i = skip_ws(s, i)<tab>return False, -1","if match_word ( s , i , directive ) :",178
4323,"def _decorator(coro_func):<tab>fut = asyncio.ensure_future(coro_func())<tab>self._tests.append((coro_func.__name__, fut))<tab>if timeout_sec is not None:<tab><tab>timeout_at = self._loop.time() + timeout_sec<tab><tab>handle = self.MASTER_LOOP.call_at(<tab><tab><tab>timeout_at, self._set_exception_if_not_done, fut, asyncio.TimeoutError()<tab><tab>)<tab><tab>fut.add_done_callback(lambda *args: handle.cancel())<tab><tab><IF-STMT><tab><tab><tab>self._global_timeout_at = timeout_at<tab>return coro_func",if timeout_at > self . _global_timeout_at :,171
4324,"def _load(self, db, owner):<tab>self.__init(owner)<tab>db_result = db(<tab><tab>""SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ?"",<tab><tab>self.owner.worldid,<tab>)<tab>for (<tab><tab>ship_id,<tab><tab>state_id,<tab>) in db_result:<tab><tab>ship = WorldObject.get_object_by_id(ship_id)<tab><tab>state = self.shipStates[state_id]<tab><tab># add move callbacks corresponding to given state<tab><tab><IF-STMT><tab><tab><tab>ship.add_move_callback(Callback(BehaviorMoveCallback._arrived, ship))<tab><tab>self.add_new_unit(ship, state)",if state == self . shipStates . moving :,188
4325,"def addError(self, test, err):<tab>if err[0] is SkipTest:<tab><tab><IF-STMT><tab><tab><tab>self.stream.writeln(str(err[1]))<tab><tab>elif self.dots:<tab><tab><tab>self.stream.write(""s"")<tab><tab><tab>self.stream.flush()<tab><tab>return<tab>_org_AddError(self, test, err)",if self . showAll :,93
4326,"def _construct(self, node):<tab>self.flatten_mapping(node)<tab>ret = self.construct_pairs(node)<tab>keys = [d[0] for d in ret]<tab>keys_sorted = sorted(keys, key=_natsort_key)<tab>for key in keys:<tab><tab>expected = keys_sorted.pop(0)<tab><tab><IF-STMT><tab><tab><tab>raise ConstructorError(<tab><tab><tab><tab>None,<tab><tab><tab><tab>None,<tab><tab><tab><tab>""keys out of order: ""<tab><tab><tab><tab>""expected {} got {} at {}"".format(expected, key, node.start_mark),<tab><tab><tab>)<tab>return dict(ret)",if key != expected :,159
4327,"def sample_pos_items_for_u(u, num):<tab># sample num pos items for u-th user<tab>pos_items = self.train_items[u]<tab>n_pos_items = len(pos_items)<tab>pos_batch = []<tab>while True:<tab><tab>if len(pos_batch) == num:<tab><tab><tab>break<tab><tab>pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0]<tab><tab>pos_i_id = pos_items[pos_id]<tab><tab><IF-STMT><tab><tab><tab>pos_batch.append(pos_i_id)<tab>return pos_batch",if pos_i_id not in pos_batch :,171
4328,"def _get_id(self, type, id):<tab>fields = id.split("":"")<tab>if len(fields) >= 3:<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, fields[-2], id<tab><tab><tab>)<tab><tab>return fields[-1]<tab>fields = id.split(""/"")<tab>if len(fields) >= 3:<tab><tab>itype = fields[-2]<tab><tab>if type != itype:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, itype, id<tab><tab><tab>)<tab><tab>return fields[-1].split(""?"")[0]<tab>return id",if type != fields [ - 2 ] :,178
4329,"def uninstall_environments(self, environments):<tab>environments = [<tab><tab>env<tab><tab>if not env.startswith(self.conda_context.envs_path)<tab><tab>else os.path.basename(env)<tab><tab>for env in environments<tab>]<tab>return_codes = [self.conda_context.exec_remove([env]) for env in environments]<tab>final_return_code = 0<tab>for env, return_code in zip(environments, return_codes):<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Conda environment '%s' successfully removed."" % env)<tab><tab>else:<tab><tab><tab>log.debug(""Conda environment '%s' could not be removed."" % env)<tab><tab><tab>final_return_code = return_code<tab>return final_return_code",if return_code == 0 :,191
4330,"def _add_hit_offset(self, context_list, string_name, original_offset, value):<tab>for context in context_list:<tab><tab>hits_by_context_dict = self.hits_by_context.setdefault(context, {})<tab><tab><IF-STMT><tab><tab><tab>hits_by_context_dict[string_name] = (<tab><tab><tab><tab>original_offset,<tab><tab><tab><tab>value.encode(""base64""),<tab><tab><tab>)",if string_name not in hits_by_context_dict :,119
4331,"def detab(self, text, length=None):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>if length is None:<tab><tab>length = self.tab_length<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab>if line.startswith("" "" * length):<tab><tab><tab>newtext.append(line[length:])<tab><tab><IF-STMT><tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",elif not line . strip ( ) :,147
4332,"def dump(self):<tab>print(self.package_name)<tab>for package, value in self.entries:<tab><tab>print(str(package.version))<tab><tab><IF-STMT><tab><tab><tab>print(""<tab>[FILTERED]"")<tab><tab>elif isinstance(value, list):<tab><tab><tab>variants = value<tab><tab><tab>for variant in variants:<tab><tab><tab><tab>print(""<tab>%s"" % str(variant))<tab><tab>else:<tab><tab><tab>print(""<tab>%s"" % str(package))",if value is None :,125
4333,"def __lexical_scope(*args, **kwargs):<tab>try:<tab><tab>scope = Scope(quasi)<tab><tab><IF-STMT><tab><tab><tab>binding_name_set_stack[-1].add_child(scope)<tab><tab>binding_name_set_stack.append(scope)<tab><tab>return func(*args, **kwargs)<tab>finally:<tab><tab>if binding_name_set_stack[-1] is scope:<tab><tab><tab>binding_name_set_stack.pop()",if quasi :,114
4334,"def getnotes(self, origin=None):<tab>if origin is None:<tab><tab>result = self.translator_comments<tab><tab><IF-STMT><tab><tab><tab>if result:<tab><tab><tab><tab>result += ""\n"" + self.developer_comments<tab><tab><tab>else:<tab><tab><tab><tab>result = self.developer_comments<tab><tab>return result<tab>elif origin == ""translator"":<tab><tab>return self.translator_comments<tab>elif origin in (""programmer"", ""developer"", ""source code""):<tab><tab>return self.developer_comments<tab>else:<tab><tab>raise ValueError(""Comment type not valid"")",if self . developer_comments :,141
4335,"def fix_datetime_fields(data: TableData, table: TableName) -> None:<tab>for item in data[table]:<tab><tab>for field_name in DATE_FIELDS[table]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item[field_name] = datetime.datetime.fromtimestamp(<tab><tab><tab><tab><tab>item[field_name], tz=datetime.timezone.utc<tab><tab><tab><tab>)",if item [ field_name ] is not None :,102
4336,"def _check_for_cart_error(cart):<tab>if cart._safe_get_element(""Cart.Request.Errors"") is not None:<tab><tab>error = cart._safe_get_element(""Cart.Request.Errors.Error.Code"").text<tab><tab><IF-STMT><tab><tab><tab>raise CartInfoMismatchException(<tab><tab><tab><tab>""CartGet failed: AWS.ECommerceService.CartInfoMismatch ""<tab><tab><tab><tab>""make sure AssociateTag, CartId and HMAC are correct ""<tab><tab><tab><tab>""(dont use URLEncodedHMAC!!!)""<tab><tab><tab>)<tab><tab>raise CartException(""CartGet failed: "" + error)","if error == ""AWS.ECommerceService.CartInfoMismatch"" :",165
4337,"def check_bounds(geometry):<tab>if isinstance(geometry[0], (list, tuple)):<tab><tab>return list(map(check_bounds, geometry))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Longitude is out of bounds, check your JSON format or data""<tab><tab><tab>)<tab><tab>if geometry[1] > 90 or geometry[1] < -90:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Latitude is out of bounds, check your JSON format or data""<tab><tab><tab>)",if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,143
4338,"def _mapper_output_protocol(self, step_num, step_map):<tab>map_key = self._step_key(step_num, ""mapper"")<tab>if map_key in step_map:<tab><tab><IF-STMT><tab><tab><tab>return self.output_protocol()<tab><tab>else:<tab><tab><tab>return self.internal_protocol()<tab>else:<tab><tab># mapper is not a script substep, so protocols don't apply at all<tab><tab>return RawValueProtocol()",if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,130
4339,"def asset(*paths):<tab>for path in paths:<tab><tab>fspath = www_root + ""/assets/"" + path<tab><tab>etag = """"<tab><tab>try:<tab><tab><tab>if env.cache_static:<tab><tab><tab><tab>etag = asset_etag(fspath)<tab><tab><tab>else:<tab><tab><tab><tab>os.stat(fspath)<tab><tab>except FileNotFoundError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not os.path.exists(fspath + "".spt""):<tab><tab><tab><tab><tab>tell_sentry(e, {})<tab><tab><tab>else:<tab><tab><tab><tab>continue<tab><tab>except Exception as e:<tab><tab><tab>tell_sentry(e, {})<tab><tab>return asset_url + path + (etag and ""?etag="" + etag)",if path == paths [ - 1 ] :,182
4340,"def ping(self, payload: Union[str, bytes] = """") -> None:<tab>if self.trace_enabled and self.ping_pong_trace_enabled:<tab><tab><IF-STMT><tab><tab><tab>payload = payload.decode(""utf-8"")<tab><tab>self.logger.debug(<tab><tab><tab>""Sending a ping data frame ""<tab><tab><tab>f""(session id: {self.session_id}, payload: {payload})""<tab><tab>)<tab>data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PING)<tab>with self.sock_send_lock:<tab><tab>self.sock.send(data)","if isinstance ( payload , bytes ) :",155
4341,"def is_ac_power_connected():<tab>for power_source_path in Path(""/sys/class/power_supply/"").iterdir():<tab><tab>try:<tab><tab><tab>with open(power_source_path / ""type"", ""r"") as f:<tab><tab><tab><tab>if f.read().strip() != ""Mains"":<tab><tab><tab><tab><tab>continue<tab><tab><tab>with open(power_source_path / ""online"", ""r"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab>except IOError:<tab><tab><tab>continue<tab>return False","if f . read ( 1 ) == ""1"" :",144
4342,"def handle_noargs(self, **options):<tab>self.style = color_style()<tab>print(""Running Django's own validation:"")<tab>self.validate(display_num_errors=True)<tab>for model in loading.get_models():<tab><tab><IF-STMT><tab><tab><tab>self.validate_base_model(model)<tab><tab>if hasattr(model, ""_feincms_content_models""):<tab><tab><tab>self.validate_content_type(model)","if hasattr ( model , ""_create_content_base"" ) :",117
4343,"def _init_weights(self, module):<tab>if isinstance(module, nn.Linear):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab><IF-STMT><tab><tab><tab>module.bias.data.zero_()<tab>elif isinstance(module, nn.Embedding):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab>if module.padding_idx is not None:<tab><tab><tab>module.weight.data[module.padding_idx].zero_()",if module . bias is not None :,141
4344,"def walk(msg, callback, data):<tab>partnum = 0<tab>for part in msg.walk():<tab><tab># multipart/* are just containers<tab><tab>if part.get_content_maintype() == ""multipart"":<tab><tab><tab>continue<tab><tab>ctype = part.get_content_type()<tab><tab><IF-STMT><tab><tab><tab>ctype = OCTET_TYPE<tab><tab>filename = part.get_filename()<tab><tab>if not filename:<tab><tab><tab>filename = PART_FN_TPL % (partnum)<tab><tab>headers = dict(part)<tab><tab>LOG.debug(headers)<tab><tab>headers[""Content-Type""] = ctype<tab><tab>payload = util.fully_decoded_payload(part)<tab><tab>callback(data, filename, payload, headers)<tab><tab>partnum = partnum + 1",if ctype is None :,190
4345,"def _mark_lcs(mask, dirs, m, n):<tab>while m != 0 and n != 0:<tab><tab>if dirs[m, n] == ""|"":<tab><tab><tab>m -= 1<tab><tab><tab>n -= 1<tab><tab><tab>mask[m] = 1<tab><tab><IF-STMT><tab><tab><tab>m -= 1<tab><tab>elif dirs[m, n] == ""<"":<tab><tab><tab>n -= 1<tab><tab>else:<tab><tab><tab>raise UnboundLocalError(""Illegal move"")<tab>return mask","elif dirs [ m , n ] == ""^"" :",122
4346,"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab>if strip_delimiters:<tab><tab><tab>if "","" in line or "";"" in line:<tab><tab><tab><tab>continue<tab><tab>yield line","if line == """" :",145
4347,"def fetch(self, *tileables, **kw):<tab>ret_list = False<tab>if len(tileables) == 1 and isinstance(tileables[0], (tuple, list)):<tab><tab>ret_list = True<tab><tab>tileables = tileables[0]<tab>elif len(tileables) > 1:<tab><tab>ret_list = True<tab>result = self._sess.fetch(*tileables, **kw)<tab>ret = []<tab>for r, t in zip(result, tileables):<tab><tab><IF-STMT><tab><tab><tab>ret.append(r.item())<tab><tab>else:<tab><tab><tab>ret.append(r)<tab>if ret_list:<tab><tab>return ret<tab>return ret[0]","if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :",183
4348,"def _convert(container):<tab>if _value_marker in container:<tab><tab>force_list = False<tab><tab>values = container.pop(_value_marker)<tab><tab>if container.pop(_list_marker, False):<tab><tab><tab>force_list = True<tab><tab><tab>values.extend(_convert(x[1]) for x in sorted(container.items()))<tab><tab><IF-STMT><tab><tab><tab>values = values[0]<tab><tab>if not container:<tab><tab><tab>return values<tab><tab>return _convert(container)<tab>elif container.pop(_list_marker, False):<tab><tab>return [_convert(x[1]) for x in sorted(container.items())]<tab>return dict_cls((k, _convert(v)) for k, v in iteritems(container))",if not force_list and len ( values ) == 1 :,188
4349,"def _transform_init_kwargs(cls, kwargs):<tab>transformed = []<tab>for field in list(kwargs.keys()):<tab><tab>prop = getattr(cls, field, None)<tab><tab><IF-STMT><tab><tab><tab>value = kwargs.pop(field)<tab><tab><tab>_transform_single_init_kwarg(prop, field, value, kwargs)<tab><tab><tab>transformed.append((field, value))<tab>return transformed","if isinstance ( prop , MoneyProperty ) :",102
4350,"def haslayer(self, cls):<tab>""""""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax.""""""<tab>if self.__class__ == cls or self.__class__.__name__ == cls:<tab><tab>return 1<tab>for f in self.packetfields:<tab><tab>fvalue_gen = self.getfieldval(f.name)<tab><tab>if fvalue_gen is None:<tab><tab><tab>continue<tab><tab>if not f.islist:<tab><tab><tab>fvalue_gen = SetGen(fvalue_gen, _iterpacket=0)<tab><tab>for fvalue in fvalue_gen:<tab><tab><tab>if isinstance(fvalue, Packet):<tab><tab><tab><tab>ret = fvalue.haslayer(cls)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return ret<tab>return self.payload.haslayer(cls)",if ret :,199
4351,def insert_broken_add_sometimes(node):<tab>if node.op == theano.tensor.add:<tab><tab>last_time_replaced[0] = not last_time_replaced[0]<tab><tab><IF-STMT><tab><tab><tab>return [off_by_half(*node.inputs)]<tab>return False,if last_time_replaced [ 0 ] :,78
4352,"def testReadChunk10(self):<tab># ""Test BZ2File.read() in chunks of 10 bytes""<tab>self.createTempFile()<tab>with BZ2File(self.filename) as bz2f:<tab><tab>text = """"<tab><tab>while 1:<tab><tab><tab>str = bz2f.read(10)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>text += str<tab><tab>self.assertEqual(text, self.TEXT)",if not str :,111
4353,"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None):<tab># This part of function creates faces in SV format<tab># It ignores  boundless super face<tab>sv_faces = []<tab>for i, face in enumerate(dcel_mesh.faces):<tab><tab>if face.inners and face.outer:<tab><tab><tab>""Face ({}) has inner components! Sverchok cant show polygons with holes."".format(<tab><tab><tab><tab>i<tab><tab><tab>)<tab><tab>if not face.outer or del_flag in face.flags:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges])<tab>return sv_faces",if only_select and not face . select :,198
4354,"def __check_dict_contains(dct, dict_name, keys, comment="""", result=True):<tab>for key in keys:<tab><tab><IF-STMT><tab><tab><tab>result = False<tab><tab><tab>comment = __append_comment(<tab><tab><tab><tab>""Missing {0} in {1}"".format(key, dict_name), comment<tab><tab><tab>)<tab>return result, comment",if key not in six . iterkeys ( dct ) :,95
4355,"def _dump_arg_defaults(kwargs):<tab>""""""Inject default arguments for dump functions.""""""<tab>if current_app:<tab><tab>kwargs.setdefault(""cls"", current_app.json_encoder)<tab><tab><IF-STMT><tab><tab><tab>kwargs.setdefault(""ensure_ascii"", False)<tab><tab>kwargs.setdefault(""sort_keys"", current_app.config[""JSON_SORT_KEYS""])<tab>else:<tab><tab>kwargs.setdefault(""sort_keys"", True)<tab><tab>kwargs.setdefault(""cls"", JSONEncoder)","if not current_app . config [ ""JSON_AS_ASCII"" ] :",129
4356,"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",elif len ( value ) != 0 :,145
4357,"def parse_win_proxy(val):<tab>proxies = []<tab>for p in val.split("";""):<tab><tab><IF-STMT><tab><tab><tab>tab = p.split(""="", 1)<tab><tab><tab>if tab[0] == ""socks"":<tab><tab><tab><tab>tab[0] = ""SOCKS4""<tab><tab><tab>proxies.append(<tab><tab><tab><tab>(tab[0].upper(), tab[1], None, None)<tab><tab><tab>)  # type, addr:port, username, password<tab><tab>else:<tab><tab><tab>proxies.append((""HTTP"", p, None, None))<tab>return proxies","if ""="" in p :",142
4358,"def predict(collect_dir, keys):<tab>run_all = len(keys) == 0<tab>validate_keys(keys)<tab>for exp_cfg in cfg:<tab><tab><IF-STMT><tab><tab><tab>key = exp_cfg[""key""]<tab><tab><tab>_predict(key, exp_cfg[""sample_img""], collect_dir)","if run_all or exp_cfg [ ""key"" ] in keys :",89
4359,"def convert_port_bindings(port_bindings):<tab>result = {}<tab>for k, v in six.iteritems(port_bindings):<tab><tab>key = str(k)<tab><tab><IF-STMT><tab><tab><tab>key += ""/tcp""<tab><tab>if isinstance(v, list):<tab><tab><tab>result[key] = [_convert_port_binding(binding) for binding in v]<tab><tab>else:<tab><tab><tab>result[key] = [_convert_port_binding(v)]<tab>return result","if ""/"" not in key :",119
4360,"def assert_conll_writer_output(<tab>dataset: InternalBioNerDataset,<tab>expected_output: List[str],<tab>sentence_splitter: SentenceSplitter = None,):<tab>outfile_path = tempfile.mkstemp()[1]<tab>try:<tab><tab>sentence_splitter = (<tab><tab><tab>sentence_splitter<tab><tab><tab><IF-STMT><tab><tab><tab>else NoSentenceSplitter(tokenizer=SpaceTokenizer())<tab><tab>)<tab><tab>writer = CoNLLWriter(sentence_splitter=sentence_splitter)<tab><tab>writer.write_to_conll(dataset, Path(outfile_path))<tab><tab>contents = [l.strip() for l in open(outfile_path).readlines() if l.strip()]<tab>finally:<tab><tab>os.remove(outfile_path)<tab>assert contents == expected_output",if sentence_splitter,175
4361,"def post(self, request, *args, **kwargs):<tab>self.comment_obj = get_object_or_404(Comment, id=request.POST.get(""commentid""))<tab>if request.user == self.comment_obj.commented_by:<tab><tab>form = LeadCommentForm(request.POST, instance=self.comment_obj)<tab><tab><IF-STMT><tab><tab><tab>return self.form_valid(form)<tab><tab>return self.form_invalid(form)<tab>data = {""error"": ""You don't have permission to edit this comment.""}<tab>return JsonResponse(data)",if form . is_valid ( ) :,142
4362,"def trivia_list(self, ctx: commands.Context):<tab>""""""List available trivia categories.""""""<tab>lists = set(p.stem for p in self._all_lists())<tab>if await ctx.embed_requested():<tab><tab>await ctx.send(<tab><tab><tab>embed=discord.Embed(<tab><tab><tab><tab>title=_(""Available trivia lists""),<tab><tab><tab><tab>colour=await ctx.embed_colour(),<tab><tab><tab><tab>description="", "".join(sorted(lists)),<tab><tab><tab>)<tab><tab>)<tab>else:<tab><tab>msg = box(bold(_(""Available trivia lists"")) + ""\n\n"" + "", "".join(sorted(lists)))<tab><tab><IF-STMT><tab><tab><tab>await ctx.author.send(msg)<tab><tab>else:<tab><tab><tab>await ctx.send(msg)",if len ( msg ) > 1000 :,193
4363,"def validate(self):<tab>result = validators.SUCCESS<tab>msgs = []<tab>for validator in self._validators:<tab><tab>res, err = validator.validate()<tab><tab>if res == validators.ERROR:<tab><tab><tab>result = res<tab><tab>elif res == validators.WARNING and result != validators.ERROR:<tab><tab><tab>result = res<tab><tab><IF-STMT><tab><tab><tab>msgs.append(err)<tab>return result, ""\n"".join(msgs)",if len ( err ) > 0 :,111
4364,"def get_code(self, fullname=None):<tab>fullname = self._fix_name(fullname)<tab>if self.code is None:<tab><tab>mod_type = self.etc[2]<tab><tab>if mod_type == imp.PY_SOURCE:<tab><tab><tab>source = self.get_source(fullname)<tab><tab><tab>self.code = compile(source, self.filename, ""exec"")<tab><tab><IF-STMT><tab><tab><tab>self._reopen()<tab><tab><tab>try:<tab><tab><tab><tab>self.code = read_code(self.file)<tab><tab><tab>finally:<tab><tab><tab><tab>self.file.close()<tab><tab>elif mod_type == imp.PKG_DIRECTORY:<tab><tab><tab>self.code = self._get_delegate().get_code()<tab>return self.code",elif mod_type == imp . PY_COMPILED :,196
4365,"def flush_file(self, key, f):<tab>f.flush()<tab>if self.compress:<tab><tab>f.compress = zlib.compressobj(<tab><tab><tab>9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0<tab><tab>)<tab>if len(self.files) > self.MAX_OPEN_FILES:<tab><tab>if self.compress:<tab><tab><tab>open_files = sum(1 for f in self.files.values() if f.fileobj is not None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.fileobj.close()<tab><tab><tab><tab>f.fileobj = None<tab><tab>else:<tab><tab><tab>f.close()<tab><tab><tab>self.files.pop(key)",if open_files > self . MAX_OPEN_FILES :,183
4366,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.add_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,90
4367,"def init_author_file(self):<tab>self.author_map = {}<tab>if self.ui.config(""git"", ""authors""):<tab><tab>f = open(self.repo.wjoin(self.ui.config(""git"", ""authors"")))<tab><tab>try:<tab><tab><tab>for line in f:<tab><tab><tab><tab>line = line.strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>from_, to = RE_AUTHOR_FILE.split(line, 2)<tab><tab><tab><tab>self.author_map[from_] = to<tab><tab>finally:<tab><tab><tab>f.close()","if not line or line . startswith ( ""#"" ) :",152
4368,"def decode_imsi(self, imsi):<tab>new_imsi = """"<tab>for a in imsi:<tab><tab>c = hex(a)<tab><tab><IF-STMT><tab><tab><tab>new_imsi += str(c[3]) + str(c[2])<tab><tab>else:<tab><tab><tab>new_imsi += str(c[2]) + ""0""<tab>mcc = new_imsi[1:4]<tab>mnc = new_imsi[4:6]<tab>return new_imsi, mcc, mnc",if len ( c ) == 4 :,136
4369,"def _get_infoset(self, prefname):<tab>""""""Return methods with the name starting with prefname.""""""<tab>infoset = []<tab>excludes = (""%sinfoset"" % prefname,)<tab>preflen = len(prefname)<tab>for name in dir(self.__class__):<tab><tab>if name.startswith(prefname) and name not in excludes:<tab><tab><tab>member = getattr(self.__class__, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>infoset.append(name[preflen:].replace(""_"", "" ""))<tab>return infoset","if isinstance ( member , MethodType ) :",133
4370,"def skip_to_close_match(self):<tab>nestedCount = 1<tab>while 1:<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab>ttype = tok[""style""]<tab><tab>if ttype == SCE_PL_UNUSED:<tab><tab><tab>return<tab><tab>elif self.classifier.is_index_op(tok):<tab><tab><tab>tval = tok[""text""]<tab><tab><tab>if self.opHash.has_key(tval):<tab><tab><tab><tab>if self.opHash[tval][1] == 1:<tab><tab><tab><tab><tab>nestedCount += 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>nestedCount -= 1<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break",if nestedCount <= 0 :,176
4371,"def findMarkForUnitTestNodes(self):<tab>""""""return the position of *all* non-ignored @mark-for-unit-test nodes.""""""<tab>c = self.c<tab>p, result, seen = c.rootPosition(), [], []<tab>while p:<tab><tab><IF-STMT><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab>else:<tab><tab><tab>seen.append(p.v)<tab><tab><tab>if g.match_word(p.h, 0, ""@ignore""):<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab>elif p.h.startswith(""@mark-for-unit-tests""):<tab><tab><tab><tab>result.append(p.copy())<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab>else:<tab><tab><tab><tab>p.moveToThreadNext()<tab>return result",if p . v in seen :,200
4372,"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint):<tab>cleaned_parts = []<tab>for earlier in earlier_parts:<tab><tab>earlier_part = earlier[""part""]<tab><tab>earlier_step = earlier[""step""]<tab><tab>found = False<tab><tab>for current in current_parts:<tab><tab><tab>if earlier_part == current[""part""] and earlier_step == current[""step""]:<tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>cleaned_parts.append(dict(part=earlier_part, step=earlier_step))<tab>self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint)<tab>for expected in expected_parts:<tab><tab>self.assertThat(cleaned_parts, Contains(expected), hint)",if not found :,194
4373,"def unmark_first_parents(event=None):<tab>""""""Mark the node and all its parents.""""""<tab>c = event.get(""c"")<tab>if not c:<tab><tab>return<tab>changed = []<tab>for parent in c.p.self_and_parents():<tab><tab><IF-STMT><tab><tab><tab>parent.v.clearMarked()<tab><tab><tab>parent.setAllAncestorAtFileNodesDirty()<tab><tab><tab>changed.append(parent.copy())<tab>if changed:<tab><tab># g.es(""unmarked: "" + ', '.join([z.h for z in changed]))<tab><tab>c.setChanged()<tab><tab>c.redraw()<tab>return changed",if parent . isMarked ( ) :,164
4374,"def stop(self):<tab>self._log(""Monitor stop"")<tab>self._stop_requested = True<tab>try:<tab><tab><IF-STMT><tab><tab><tab>fd = os.open(self.fifo_path, os.O_WRONLY)<tab><tab><tab>os.write(fd, b""X"")<tab><tab><tab>os.close(fd)<tab>except Exception as e:<tab><tab>self._log(""err while closing: {0}"".format(str(e)))<tab>if self._thread:<tab><tab>self._thread.join()<tab><tab>self._thread = None",if os . path . exists ( self . fifo_path ) :,141
4375,"def DeleteEmptyCols(self):<tab>cols2delete = []<tab>for c in range(0, self.GetCols()):<tab><tab>f = True<tab><tab>for r in range(0, self.GetRows()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f = False<tab><tab>if f:<tab><tab><tab>cols2delete.append(c)<tab>for i in range(0, len(cols2delete)):<tab><tab>self.ShiftColsLeft(cols2delete[i] + 1)<tab><tab>cols2delete = [x - 1 for x in cols2delete]","if self . FindItemAtPosition ( ( r , c ) ) is not None :",150
4376,"def _load_objects(self, obj_id_zset, limit, chunk_size=1000):<tab>ct = i = 0<tab>while True:<tab><tab>id_chunk = obj_id_zset[i : i + chunk_size]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>i += chunk_size<tab><tab>for raw_data in self._data[id_chunk]:<tab><tab><tab>if not raw_data:<tab><tab><tab><tab>continue<tab><tab><tab>if self._use_json:<tab><tab><tab><tab>yield json.loads(decode(raw_data))<tab><tab><tab>else:<tab><tab><tab><tab>yield raw_data<tab><tab><tab>ct += 1<tab><tab><tab>if limit and ct == limit:<tab><tab><tab><tab>return",if not id_chunk :,178
4377,"def _convert_example(example, use_bfloat16):<tab>""""""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16.""""""<tab>for key in list(example.keys()):<tab><tab>val = example[key]<tab><tab>if tf.keras.backend.is_sparse(val):<tab><tab><tab>val = tf.sparse.to_dense(val)<tab><tab><IF-STMT><tab><tab><tab>val = tf.cast(val, tf.int32)<tab><tab>if use_bfloat16 and val.dtype == tf.float32:<tab><tab><tab>val = tf.cast(val, tf.bfloat16)<tab><tab>example[key] = val",if val . dtype == tf . int64 :,166
4378,"def print_callees(self, *amount):<tab>width, list = self.get_print_list(amount)<tab>if list:<tab><tab>self.calc_callees()<tab><tab>self.print_call_heading(width, ""called..."")<tab><tab>for func in list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.print_call_line(width, func, self.all_callees[func])<tab><tab><tab>else:<tab><tab><tab><tab>self.print_call_line(width, func, {})<tab><tab>print >>self.stream<tab><tab>print >>self.stream<tab>return self",if func in self . all_callees :,147
4379,"def on_task_input(self, task, config):<tab>if config is False:<tab><tab>return<tab>for entry in task.entries:<tab><tab><IF-STMT><tab><tab><tab>log_once(<tab><tab><tab><tab>""Corrected `%s` url (replaced &amp; with &)"" % entry[""title""],<tab><tab><tab><tab>logger=log,<tab><tab><tab>)<tab><tab><tab>entry[""url""] = entry[""url""].replace(""&amp;"", ""&"")","if ""&amp;"" in entry [ ""url"" ] :",112
4380,"def function(self, inputs, outputs, ignore_empty=False):<tab>f = function(inputs, outputs, mode=self.mode)<tab>if self.mode is not None or theano.config.mode != ""FAST_COMPILE"":<tab><tab>topo = f.maker.fgraph.toposort()<tab><tab>topo_ = [node for node in topo if not isinstance(node.op, self.ignore_topo)]<tab><tab>if ignore_empty:<tab><tab><tab>assert len(topo_) <= 1, topo_<tab><tab>else:<tab><tab><tab>assert len(topo_) == 1, topo_<tab><tab><IF-STMT><tab><tab><tab>assert type(topo_[0].op) is self.op<tab>return f",if len ( topo_ ) > 0 :,165
4381,"def _get_env_command(self) -> Sequence[str]:<tab>""""""Get command sequence for `env` with configured flags.""""""<tab>env_list = [""env""]<tab># Pass through configurable environment variables.<tab>for key in [""http_proxy"", ""https_proxy""]:<tab><tab>value = self.build_provider_flags.get(key)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Ensure item is treated as string and append it.<tab><tab>value = str(value)<tab><tab>env_list.append(f""{key}={value}"")<tab>return env_list",if not value :,136
4382,"def _compare_single_run(self, compares_done):<tab>try:<tab><tab>compare_id, redo = self.in_queue.get(<tab><tab><tab>timeout=float(self.config[""ExpertSettings""][""block_delay""])<tab><tab>)<tab>except Empty:<tab><tab>pass<tab>else:<tab><tab>if self._decide_whether_to_process(compare_id, redo, compares_done):<tab><tab><tab>if redo:<tab><tab><tab><tab>self.db_interface.delete_old_compare_result(compare_id)<tab><tab><tab>compares_done.add(compare_id)<tab><tab><tab>self._process_compare(compare_id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.callback()",if self . callback :,177
4383,"def clean(self):<tab># TODO: check for clashes if the random code is already taken<tab>if not self.code:<tab><tab>self.code = u""static-%s"" % uuid.uuid4()<tab>if not self.site:<tab><tab>placeholders = StaticPlaceholder.objects.filter(<tab><tab><tab>code=self.code, site__isnull=True<tab><tab>)<tab><tab>if self.pk:<tab><tab><tab>placeholders = placeholders.exclude(pk=self.pk)<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""A static placeholder with the same site and code already exists"")<tab><tab><tab>)",if placeholders . exists ( ) :,149
4384,"def load_parser(self):<tab>result = OrderedDict()<tab>for name, flags in self.filenames:<tab><tab>filename = self.get_filename(name)<tab><tab>for match in sorted(glob(filename), key=self.file_key):<tab><tab><tab># Needed to allow overlapping globs, more specific first<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>result[match] = TextParser(match, os.path.relpath(match, self.base), flags)<tab>return result",if match in result :,119
4385,"def __init__(self, selectable, name=None):<tab>baseselectable = selectable<tab>while isinstance(baseselectable, Alias):<tab><tab>baseselectable = baseselectable.element<tab>self.original = baseselectable<tab>self.supports_execution = baseselectable.supports_execution<tab>if self.supports_execution:<tab><tab>self._execution_options = baseselectable._execution_options<tab>self.element = selectable<tab>if name is None:<tab><tab><IF-STMT><tab><tab><tab>name = getattr(self.original, ""name"", None)<tab><tab>name = _anonymous_label(""%%(%d %s)s"" % (id(self), name or ""anon""))<tab>self.name = name",if self . original . named_with_column :,165
4386,"def load_tour(self, tour_id):<tab>for tour_dir in self.tour_directories:<tab><tab>tour_path = os.path.join(tour_dir, tour_id + "".yaml"")<tab><tab>if not os.path.exists(tour_path):<tab><tab><tab>tour_path = os.path.join(tour_dir, tour_id + "".yml"")<tab><tab><IF-STMT><tab><tab><tab>return self._load_tour_from_path(tour_path)",if os . path . exists ( tour_path ) :,122
4387,"def _get_md_bg_color_down(self):<tab>t = self.theme_cls<tab>c = self.md_bg_color  # Default to no change on touch<tab># Material design specifies using darker hue when on Dark theme<tab>if t.theme_style == ""Dark"":<tab><tab><IF-STMT><tab><tab><tab>c = t.primary_dark<tab><tab>elif self.md_bg_color == t.accent_color:<tab><tab><tab>c = t.accent_dark<tab>return c",if self . md_bg_color == t . primary_color :,135
4388,"def get_data(self, state=None, request=None):<tab>if self.load_in_memory:<tab><tab>data, shapes = self._in_memory_get_data(state, request)<tab>else:<tab><tab>data, shapes = self._out_of_memory_get_data(state, request)<tab>for i in range(len(data)):<tab><tab>if shapes[i] is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[i] = data[i].reshape(shapes[i])<tab><tab><tab>else:<tab><tab><tab><tab>for j in range(len(data[i])):<tab><tab><tab><tab><tab>data[i][j] = data[i][j].reshape(shapes[i][j])<tab>return tuple(data)","if isinstance ( request , numbers . Integral ) :",187
4389,"def onClicked(event):<tab>if not self.path:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(mh.getPath(""render""))<tab><tab>self.path = mh.getPath(""render"")<tab>filename, ftype = mh.getSaveFileName(<tab><tab>os.path.splitext(self.path)[0],<tab><tab>""PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*)"",<tab>)<tab>if filename:<tab><tab>if ""Thumbnail"" in ftype:<tab><tab><tab>self.image.save(filename, iformat=""PNG"")<tab><tab>else:<tab><tab><tab>self.image.save(filename)<tab><tab>self.path = os.path.dirname(filename)","if not os . path . exists ( mh . getPath ( ""render"" ) ) :",187
4390,"def _build_dom(cls, content, mode):<tab>assert mode in (""html"", ""xml"")<tab>if mode == ""html"":<tab><tab><IF-STMT><tab><tab><tab>THREAD_STORAGE.html_parser = HTMLParser()<tab><tab>dom = defusedxml.lxml.parse(<tab><tab><tab>StringIO(content), parser=THREAD_STORAGE.html_parser<tab><tab>)<tab><tab>return dom.getroot()<tab>else:<tab><tab>if not hasattr(THREAD_STORAGE, ""xml_parser""):<tab><tab><tab>THREAD_STORAGE.xml_parser = XMLParser()<tab><tab>dom = defusedxml.lxml.parse(BytesIO(content), parser=THREAD_STORAGE.xml_parser)<tab><tab>return dom.getroot()","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :",175
4391,"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab><IF-STMT><tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab>elif code == Path.CURVE3:<tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab>elif code == Path.CURVE4:<tab><tab><tab>ctx.curve_to(*points)<tab><tab>elif code == Path.CLOSEPOLY:<tab><tab><tab>ctx.close_path()",if code == Path . MOVETO :,172
4392,"def _targets(self, sigmaparser):<tab># build list of matching target mappings<tab>targets = set()<tab>for condfield in self.conditions:<tab><tab>if condfield in sigmaparser.values:<tab><tab><tab>rulefieldvalues = sigmaparser.values[condfield]<tab><tab><tab>for condvalue in self.conditions[condfield]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>targets.update(self.conditions[condfield][condvalue])<tab>return targets",if condvalue in rulefieldvalues :,115
4393,"def create_image_upload():<tab>if request.method == ""POST"":<tab><tab>image = request.form[""image""]<tab><tab><IF-STMT><tab><tab><tab>image_file = uploaded_file(file_content=image)<tab><tab><tab>image_url = upload_local(<tab><tab><tab><tab>image_file, UPLOAD_PATHS[""temp""][""image""].format(uuid=uuid4())<tab><tab><tab>)<tab><tab><tab>return jsonify({""status"": ""ok"", ""image_url"": image_url})<tab><tab>else:<tab><tab><tab>return jsonify({""status"": ""no_image""})",if image :,135
4394,"def lookup_actions(self, resp):<tab>actions = {}<tab>for action, conditions in self.actions.items():<tab><tab>for condition, opts in conditions:<tab><tab><tab>for key, val in condition:<tab><tab><tab><tab>if key[-1] == ""!"":<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if not resp.match(key, val):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>actions[action] = opts<tab>return actions","if resp . match ( key [ : - 1 ] , val ) :",138
4395,"def accept_quality(accept, default=1):<tab>""""""Separates out the quality score from the accepted content_type""""""<tab>quality = default<tab>if accept and "";"" in accept:<tab><tab>accept, rest = accept.split("";"", 1)<tab><tab>accept_quality = RE_ACCEPT_QUALITY.search(rest)<tab><tab><IF-STMT><tab><tab><tab>quality = float(accept_quality.groupdict().get(""quality"", quality).strip())<tab>return (quality, accept.strip())",if accept_quality :,113
4396,"def save(self, session=None, to=None, pickler=None):<tab>if to and pickler:<tab><tab>self._save_to = (pickler, to)<tab>if self._save_to and len(self) > 0:<tab><tab>with self._lock:<tab><tab><tab>pickler, fn = self._save_to<tab><tab><tab><IF-STMT><tab><tab><tab><tab>session.ui.mark(_(""Saving %s state to %s"") % (self, fn))<tab><tab><tab>pickler(self, fn)",if session :,123
4397,"def get_safe_settings():<tab>""Returns a dictionary of the settings module, with sensitive settings blurred out.""<tab>settings_dict = {}<tab>for k in dir(settings):<tab><tab>if k.isupper():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>settings_dict[k] = ""********************""<tab><tab><tab>else:<tab><tab><tab><tab>settings_dict[k] = getattr(settings, k)<tab>return settings_dict",if HIDDEN_SETTINGS . search ( k ) :,109
4398,def _init_table_h():<tab>_table_h = []<tab>for i in range(256):<tab><tab>part_l = i<tab><tab>part_h = 0<tab><tab>for j in range(8):<tab><tab><tab>rflag = part_l & 1<tab><tab><tab>part_l >>= 1<tab><tab><tab>if part_h & 1:<tab><tab><tab><tab>part_l |= 1 << 31<tab><tab><tab>part_h >>= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>part_h ^= 0xD8000000<tab><tab>_table_h.append(part_h)<tab>return _table_h,if rflag :,147
4399,"def dns_query(server, timeout, protocol, qname, qtype, qclass):<tab>request = dns.message.make_query(qname, qtype, qclass)<tab>if protocol == ""tcp"":<tab><tab>response = dns.query.tcp(<tab><tab><tab>request, server, timeout=timeout, one_rr_per_rrset=True<tab><tab>)<tab>else:<tab><tab>response = dns.query.udp(<tab><tab><tab>request, server, timeout=timeout, one_rr_per_rrset=True<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>response = dns.query.tcp(<tab><tab><tab><tab>request, server, timeout=timeout, one_rr_per_rrset=True<tab><tab><tab>)<tab>return response",if response . flags & dns . flags . TC :,184
4400,"def sum_and_divide(self, losses):<tab>if self.total_divisor != 0:<tab><tab>output = torch.sum(losses) / self.total_divisor<tab><tab><IF-STMT><tab><tab><tab># remove from autograd graph if necessary<tab><tab><tab>self.total_divisor = self.total_divisor.item()<tab><tab>return output<tab>return torch.sum(losses * 0)",if torch . is_tensor ( self . total_divisor ) :,102
4401,"def __iter__(self):<tab>for chunk in self.source:<tab><tab>if chunk is not None:<tab><tab><tab>self.wait_counter = 0<tab><tab><tab>yield chunk<tab><tab><IF-STMT><tab><tab><tab>self.wait_counter += 1<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Data poller has been receiving no data for {} seconds.\n""<tab><tab><tab><tab>""Closing data poller"".format(self.wait_cntr_max * self.poll_period)<tab><tab><tab>)<tab><tab><tab>break<tab><tab>time.sleep(self.poll_period)",elif self . wait_counter < self . wait_cntr_max :,156
4402,"def test_find_directive_from_block(self):<tab>blocks = self.config.parser_root.find_blocks(""virtualhost"")<tab>found = False<tab>for vh in blocks:<tab><tab><IF-STMT><tab><tab><tab>servername = vh.find_directives(""servername"")<tab><tab><tab>self.assertEqual(servername[0].parameters[0], ""certbot.demo"")<tab><tab><tab>found = True<tab>self.assertTrue(found)","if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :",118
4403,"def assign_products(request, discount_id):<tab>""""""Assign products to given property group with given property_group_id.""""""<tab>discount = lfs_get_object_or_404(Discount, pk=discount_id)<tab>for temp_id in request.POST.keys():<tab><tab><IF-STMT><tab><tab><tab>temp_id = temp_id.split(""-"")[1]<tab><tab><tab>product = Product.objects.get(pk=temp_id)<tab><tab><tab>discount.products.add(product)<tab>html = [[""#products-inline"", products_inline(request, discount_id, as_string=True)]]<tab>result = json.dumps(<tab><tab>{""html"": html, ""message"": _(u""Products have been assigned."")}, cls=LazyEncoder<tab>)<tab>return HttpResponse(result, content_type=""application/json"")","if temp_id . startswith ( ""product"" ) :",199
4404,"def ChangeStyle(self, combos):<tab>style = 0<tab>for combo in combos:<tab><tab>if combo.GetValue() == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>style = style | HTL.TR_VIRTUAL<tab><tab><tab>else:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>style = style | eval(""wx."" + combo.GetLabel())<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>style = style | eval(""HTL."" + combo.GetLabel())<tab>if self.GetAGWWindowStyleFlag() != style:<tab><tab>self.SetAGWWindowStyleFlag(style)","if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",153
4405,"def _set_autocomplete(self, notebook):<tab>if notebook:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>notebook = NotebookInfo(notebook)<tab><tab><tab>obj, x = build_notebook(notebook)<tab><tab><tab>self.form.widgets[""namespace""].notebook = obj<tab><tab><tab>self.form.widgets[""page""].notebook = obj<tab><tab><tab>logger.debug(""Notebook for autocomplete: %s (%s)"", obj, notebook)<tab><tab>except:<tab><tab><tab>logger.exception(""Could not set notebook: %s"", notebook)<tab>else:<tab><tab>self.form.widgets[""namespace""].notebook = None<tab><tab>self.form.widgets[""page""].notebook = None<tab><tab>logger.debug(""Notebook for autocomplete unset"")","if isinstance ( notebook , str ) :",178
4406,"def emitSubDomainData(self, subDomainData, event):<tab>self.emitRawRirData(subDomainData, event)<tab>for subDomainElem in subDomainData:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>subDomain = subDomainElem.get(""subdomain"", """").strip()<tab><tab>if subDomain:<tab><tab><tab>self.emitHostname(subDomain, event)",if self . checkForStop ( ) :,99
4407,"def get_all_subnets(self, subnet_ids=None, filters=None):<tab># Extract a list of all subnets<tab>matches = itertools.chain(*[x.values() for x in self.subnets.values()])<tab>if subnet_ids:<tab><tab>matches = [sn for sn in matches if sn.id in subnet_ids]<tab><tab><IF-STMT><tab><tab><tab>unknown_ids = set(subnet_ids) - set(matches)<tab><tab><tab>raise InvalidSubnetIdError(unknown_ids)<tab>if filters:<tab><tab>matches = generic_filter(filters, matches)<tab>return matches",if len ( subnet_ids ) > len ( matches ) :,152
4408,"def _compat_map(self, avs):<tab>apps = {}<tab>for av in avs:<tab><tab>av.version = self<tab><tab>app_id = av.application<tab><tab><IF-STMT><tab><tab><tab>apps[amo.APP_IDS[app_id]] = av<tab>return apps",if app_id in amo . APP_IDS :,80
4409,"def generator(self, data):<tab>if self._config.SILENT:<tab><tab>silent_vars = self._get_silent_vars()<tab>for task in data:<tab><tab>for var, val in task.environment_variables():<tab><tab><tab>if self._config.SILENT:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>int(task.UniqueProcessId),<tab><tab><tab><tab><tab>str(task.ImageFileName),<tab><tab><tab><tab><tab>Address(task.Peb.ProcessParameters.Environment),<tab><tab><tab><tab><tab>str(var),<tab><tab><tab><tab><tab>str(val),<tab><tab><tab><tab>],<tab><tab><tab>)",if var in silent_vars :,182
4410,"def warn_if_repeatable_read(self):<tab>if ""mysql"" in self.current_engine().lower():<tab><tab>cursor = self.connection_for_read().cursor()<tab><tab>if cursor.execute(""SELECT @@tx_isolation""):<tab><tab><tab>isolation = cursor.fetchone()[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab>TxIsolationWarning(<tab><tab><tab><tab><tab><tab>""Polling results with transaction isolation level ""<tab><tab><tab><tab><tab><tab>""repeatable-read within the same transaction ""<tab><tab><tab><tab><tab><tab>""may give outdated results. Be sure to commit the ""<tab><tab><tab><tab><tab><tab>""transaction for each poll iteration.""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)","if isolation == ""REPEATABLE-READ"" :",182
4411,"def filter_by_level(record, level_per_module):<tab>name = record[""name""]<tab>level = 0<tab>if name in level_per_module:<tab><tab>level = level_per_module[name]<tab>elif name is not None:<tab><tab>lookup = """"<tab><tab><IF-STMT><tab><tab><tab>level = level_per_module[""""]<tab><tab>for n in name.split("".""):<tab><tab><tab>lookup += n<tab><tab><tab>if lookup in level_per_module:<tab><tab><tab><tab>level = level_per_module[lookup]<tab><tab><tab>lookup += "".""<tab>if level is False:<tab><tab>return False<tab>return record[""level""].no >= level","if """" in level_per_module :",166
4412,"def _readStream(self, handle: str, path: str) -> None:<tab>eof = False<tab>file = Path(path)<tab>with file.open(""w"") as f:<tab><tab>while not eof:<tab><tab><tab>response = await self._client.send(""IO.read"", {""handle"": handle})<tab><tab><tab>eof = response.get(""eof"", False)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.write(response.get(""data"", """"))<tab>await self._client.send(""IO.close"", {""handle"": handle})",if path :,128
4413,"def sendall(self, data, flags=0):<tab>if self._sslobj:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""non-zero flags not allowed in calls to sendall() on %s""<tab><tab><tab><tab>% self.__class__<tab><tab><tab>)<tab><tab>amount = len(data)<tab><tab>count = 0<tab><tab>while count < amount:<tab><tab><tab>v = self.send(data[count:])<tab><tab><tab>count += v<tab><tab>return amount<tab>else:<tab><tab>return socket.sendall(self, data, flags)",if flags != 0 :,141
4414,"def run(self):<tab>utils.assert_main_thread()<tab># As a convenience, we'll set up the connection<tab># if there isn't one. So F5 (etc) can be hit<tab># to get started.<tab>if not channel:<tab><tab><IF-STMT><tab><tab><tab>SwiDebugStartChromeCommand.run(self)<tab><tab>else:<tab><tab><tab>self.window.run_command(""swi_debug_start"")<tab>elif paused:<tab><tab>logger.info(""Resuming..."")<tab><tab>channel.send(webkit.Debugger.resume())<tab>else:<tab><tab>logger.info(""Pausing..."")<tab><tab>channel.send(webkit.Debugger.setSkipAllPauses(False))<tab><tab>channel.send(webkit.Debugger.pause())",if not chrome_launched ( ) :,190
4415,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_presence_response().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,140
4416,"def _replace_home(x):<tab>if xp.ON_WINDOWS:<tab><tab>home = (<tab><tab><tab>builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0]<tab><tab>)<tab><tab>if x.startswith(home):<tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab><IF-STMT><tab><tab><tab>x = x.replace(os.sep, os.altsep)<tab><tab>return x<tab>else:<tab><tab>home = builtins.__xonsh__.env[""HOME""]<tab><tab>if x.startswith(home):<tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab>return x","if builtins . __xonsh__ . env . get ( ""FORCE_POSIX_PATHS"" ) :",176
4417,"def semanticTags(self, semanticTags):<tab>if semanticTags is None:<tab><tab>self.__semanticTags = OrderedDict()<tab># check<tab>for key, value in list(semanticTags.items()):<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""At least one key is not a valid int position"")<tab><tab>if not isinstance(value, list):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab>)<tab><tab>for x in value:<tab><tab><tab>if not isinstance(x, str):<tab><tab><tab><tab>raise TypeError(<tab><tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab><tab>)<tab>self.__semanticTags = semanticTags","if not isinstance ( key , int ) :",184
4418,"def _recv():<tab>try:<tab><tab>return sock.recv(bufsize)<tab>except SSLWantReadError:<tab><tab>pass<tab>except socket.error as exc:<tab><tab>error_code = extract_error_code(exc)<tab><tab>if error_code is None:<tab><tab><tab>raise<tab><tab><IF-STMT><tab><tab><tab>raise<tab>r, w, e = select.select((sock,), (), (), sock.gettimeout())<tab>if r:<tab><tab>return sock.recv(bufsize)",if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,139
4419,"def _authenticate(self):<tab>oauth_token = self.options.get(""oauth_token"")<tab>if oauth_token and not self.api.oauth_token:<tab><tab>self.logger.info(""Attempting to authenticate using OAuth token"")<tab><tab>self.api.oauth_token = oauth_token<tab><tab>user = self.api.user(schema=_user_schema)<tab><tab><IF-STMT><tab><tab><tab>self.logger.info(""Successfully logged in as {0}"", user)<tab><tab>else:<tab><tab><tab>self.logger.error(<tab><tab><tab><tab>""Failed to authenticate, the access token "" ""is not valid""<tab><tab><tab>)<tab>else:<tab><tab>return JustinTVPluginBase._authenticate(self)",if user :,168
4420,"def reverse(self, *args):<tab>assert self._path is not None, ""Cannot reverse url regex "" + self.regex.pattern<tab>assert len(args) == self._group_count, ""required number of arguments "" ""not found""<tab>if not len(args):<tab><tab>return self._path<tab>converted_args = []<tab>for a in args:<tab><tab><IF-STMT><tab><tab><tab>a = str(a)<tab><tab>converted_args.append(escape.url_escape(utf8(a), plus=False))<tab>return self._path % tuple(converted_args)","if not isinstance ( a , ( unicode_type , bytes ) ) :",147
4421,"def determine_block_hints(self, text):<tab>hints = """"<tab>if text:<tab><tab><IF-STMT><tab><tab><tab>hints += str(self.best_indent)<tab><tab>if text[-1] not in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""-""<tab><tab>elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""+""<tab>return hints","if text [ 0 ] in "" \n\x85\u2028\u2029"" :",132
4422,"def find_package_modules(package, mask):<tab>import fnmatch<tab>if hasattr(package, ""__loader__"") and hasattr(package.__loader__, ""_files""):<tab><tab>path = package.__name__.replace(""."", os.path.sep)<tab><tab>mask = os.path.join(path, mask)<tab><tab>for fnm in package.__loader__._files.iterkeys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield os.path.splitext(fnm)[0].replace(os.path.sep, ""."")<tab>else:<tab><tab>path = package.__path__[0]<tab><tab>for fnm in os.listdir(path):<tab><tab><tab>if fnmatch.fnmatchcase(fnm, mask):<tab><tab><tab><tab>yield ""%s.%s"" % (package.__name__, os.path.splitext(fnm)[0])","if fnmatch . fnmatchcase ( fnm , mask ) :",191
4423,"def _condition(ct):<tab>for qobj in args:<tab><tab>if qobj.connector == ""AND"" and not qobj.negated:<tab><tab><tab># normal kwargs are an AND anyway, so just use those for now<tab><tab><tab>for child in qobj.children:<tab><tab><tab><tab>kwargs.update(dict([child]))<tab><tab>else:<tab><tab><tab>raise NotImplementedError(""Unsupported Q object"")<tab>for attr, val in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True","if getattr ( ct , attr ) != val :",127
4424,"def process(self, resources):<tab>session = local_session(self.manager.session_factory)<tab>client = session.client(""logs"")<tab>state = self.data.get(""state"", True)<tab>key = self.resolve_key(self.data.get(""kms-key""))<tab>for r in resources:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>client.associate_kms_key(logGroupName=r[""logGroupName""], kmsKeyId=key)<tab><tab><tab>else:<tab><tab><tab><tab>client.disassociate_kms_key(logGroupName=r[""logGroupName""])<tab><tab>except client.exceptions.ResourceNotFoundException:<tab><tab><tab>continue",if state :,153
4425,"def get_xmm(env, ii):<tab>if is_gather(ii):<tab><tab><IF-STMT><tab><tab><tab>return gen_reg_simd_unified(env, ""xmm_evex"", True)<tab><tab>return gen_reg_simd_unified(env, ""xmm"", False)<tab>if ii.space == ""evex"":<tab><tab>return gen_reg(env, ""xmm_evex"")<tab>return gen_reg(env, ""xmm"")","if ii . space == ""evex"" :",119
4426,"def parent(self):<tab>""""""Return the parent device.""""""<tab>if self._has_parent is None:<tab><tab>_parent = self._ctx.backend.get_parent(self._ctx.dev)<tab><tab>self._has_parent = _parent is not None<tab><tab><IF-STMT><tab><tab><tab>self._parent = Device(_parent, self._ctx.backend)<tab><tab>else:<tab><tab><tab>self._parent = None<tab>return self._parent",if self . _has_parent :,109
4427,"def cascade(self, event=None):<tab>""""""Cascade all Leo windows.""""""<tab>x, y, delta = 50, 50, 50<tab>for frame in g.app.windowList:<tab><tab>w = frame and frame.top<tab><tab><IF-STMT><tab><tab><tab>r = w.geometry()  # a Qt.Rect<tab><tab><tab># 2011/10/26: Fix bug 823601: cascade-windows fails.<tab><tab><tab>w.setGeometry(QtCore.QRect(x, y, r.width(), r.height()))<tab><tab><tab># Compute the new offsets.<tab><tab><tab>x += 30<tab><tab><tab>y += 30<tab><tab><tab>if x > 200:<tab><tab><tab><tab>x = 10 + delta<tab><tab><tab><tab>y = 40 + delta<tab><tab><tab><tab>delta += 10",if w :,190
4428,"def _GetGoodDispatchAndUserName(IDispatch, userName, clsctx):<tab># Get a dispatch object, and a 'user name' (ie, the name as<tab># displayed to the user in repr() etc.<tab>if userName is None:<tab><tab>if isinstance(IDispatch, str):<tab><tab><tab>userName = IDispatch<tab><tab><IF-STMT><tab><tab><tab># We always want the displayed name to be a real string<tab><tab><tab>userName = IDispatch.encode(""ascii"", ""replace"")<tab>elif type(userName) == unicode:<tab><tab># As above - always a string...<tab><tab>userName = userName.encode(""ascii"", ""replace"")<tab>else:<tab><tab>userName = str(userName)<tab>return (_GetGoodDispatch(IDispatch, clsctx), userName)","elif isinstance ( IDispatch , unicode ) :",200
4429,"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab>if arg is None:<tab><tab><tab>continue<tab><tab>if isinstance(arg, bytes):<tab><tab><tab>if return_type is str:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type",if return_type is bytes :,186
4430,"def test_ESPnetDataset_h5file_1(h5file_1):<tab>dataset = IterableESPnetDataset(<tab><tab>path_name_type_list=[(h5file_1, ""data4"", ""hdf5"")],<tab><tab>preprocess=preprocess,<tab>)<tab>for key, data in dataset:<tab><tab>if key == ""a"":<tab><tab><tab>assert data[""data4""].shape == (<tab><tab><tab><tab>100,<tab><tab><tab><tab>80,<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assert data[""data4""].shape == (<tab><tab><tab><tab>150,<tab><tab><tab><tab>80,<tab><tab><tab>)","if key == ""b"" :",157
4431,"def iter_fields(node, *, include_meta=True, exclude_unset=False):<tab>exclude_meta = not include_meta<tab>for field_name, field in node._fields.items():<tab><tab>if exclude_meta and field.meta:<tab><tab><tab>continue<tab><tab>field_val = getattr(node, field_name, _marker)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if exclude_unset:<tab><tab><tab>if callable(field.default):<tab><tab><tab><tab>default = field.default()<tab><tab><tab>else:<tab><tab><tab><tab>default = field.default<tab><tab><tab>if field_val == default:<tab><tab><tab><tab>continue<tab><tab>yield field_name, field_val",if field_val is _marker :,171
4432,"def then(self, matches, when_response, context):<tab>if is_iterable(when_response):<tab><tab>ret = []<tab><tab>when_response = list(when_response)<tab><tab>for match in when_response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.match_name:<tab><tab><tab><tab><tab>match.name = self.match_name<tab><tab><tab><tab>matches.append(match)<tab><tab><tab><tab>ret.append(match)<tab><tab>return ret<tab>if self.match_name:<tab><tab>when_response.name = self.match_name<tab>if when_response not in matches:<tab><tab>matches.append(when_response)<tab><tab>return when_response",if match not in matches :,169
4433,"def _set_chat_ids(self, chat_id: SLT[int]) -> None:<tab>with self.__lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""Can't set {self.chat_id_name} in conjunction with (already set) ""<tab><tab><tab><tab>f""{self.username_name}s.""<tab><tab><tab>)<tab><tab>self._chat_ids = self._parse_chat_id(chat_id)",if chat_id and self . _usernames :,118
4434,"def discover(self, *objlist):<tab>ret = []<tab>for l in self.splitlines():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if l[0] == ""Filename"":<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>int(l[2])<tab><tab><tab>int(l[3])<tab><tab>except:<tab><tab><tab>continue<tab><tab>#<tab><tab>   ret.append(improve(l[0]))<tab><tab>ret.append(l[0])<tab>ret.sort()<tab>for item in objlist:<tab><tab>ret.append(item)<tab>return ret",if len ( l ) < 5 :,154
4435,"def get_changed_module(self):<tab>source = self.resource.read()<tab>change_collector = codeanalyze.ChangeCollector(source)<tab>if self.replacement is not None:<tab><tab>change_collector.add_change(self.skip_start, self.skip_end, self.replacement)<tab>for occurrence in self.occurrence_finder.find_occurrences(self.resource):<tab><tab>start, end = occurrence.get_primary_range()<tab><tab><IF-STMT><tab><tab><tab>self.handle.occurred_inside_skip(change_collector, occurrence)<tab><tab>else:<tab><tab><tab>self.handle.occurred_outside_skip(change_collector, occurrence)<tab>result = change_collector.get_changed()<tab>if result is not None and result != source:<tab><tab>return result",if self . skip_start <= start < self . skip_end :,198
4436,"def hpat_pandas_series_var_impl(<tab>self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None):<tab>if skipna is None:<tab><tab>skipna = True<tab>if skipna:<tab><tab>valuable_length = len(self._data) - numpy.sum(numpy.isnan(self._data))<tab><tab><IF-STMT><tab><tab><tab>return numpy.nan<tab><tab>return (<tab><tab><tab>numpy_like.nanvar(self._data) * valuable_length / (valuable_length - ddof)<tab><tab>)<tab>if len(self._data) <= ddof:<tab><tab>return numpy.nan<tab>return self._data.var() * len(self._data) / (len(self._data) - ddof)",if valuable_length <= ddof :,188
4437,"def to_dict(self, validate=True, ignore=(), context=None):<tab>context = context or {}<tab>condition = getattr(self, ""condition"", Undefined)<tab>copy = self  # don't copy unless we need to<tab>if condition is not Undefined:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif ""field"" in condition and ""type"" not in condition:<tab><tab><tab>kwds = parse_shorthand(condition[""field""], context.get(""data"", None))<tab><tab><tab>copy = self.copy(deep=[""condition""])<tab><tab><tab>copy.condition.update(kwds)<tab>return super(ValueChannelMixin, copy).to_dict(<tab><tab>validate=validate, ignore=ignore, context=context<tab>)","if isinstance ( condition , core . SchemaBase ) :",175
4438,"def get_field_result(self, result, field_name):<tab>if isinstance(result.field, models.ImageField):<tab><tab><IF-STMT><tab><tab><tab>img = getattr(result.obj, field_name)<tab><tab><tab>result.text = mark_safe(<tab><tab><tab><tab>'<a href=""%s"" target=""_blank"" title=""%s"" data-gallery=""gallery""><img src=""%s"" class=""field_img""/></a>'<tab><tab><tab><tab>% (img.url, result.label, img.url)<tab><tab><tab>)<tab><tab><tab>self.include_image = True<tab>return result",if result . value :,148
4439,"def run(self):<tab>try:<tab><tab>while True:<tab><tab><tab>dp = self.queue_get_stoppable(self.inq)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab># cannot ignore None here. will lead to unsynced send/recv<tab><tab><tab>obj = self.func(dp)<tab><tab><tab>self.queue_put_stoppable(self.outq, obj)<tab>except Exception:<tab><tab>if self.stopped():<tab><tab><tab>pass  # skip duplicated error messages<tab><tab>else:<tab><tab><tab>raise<tab>finally:<tab><tab>self.stop()",if self . stopped ( ) :,148
4440,"def _evaluate_local_single(self, iterator):<tab>for batch in iterator:<tab><tab>in_arrays = convert._call_converter(self.converter, batch, self.device)<tab><tab>with function.no_backprop_mode():<tab><tab><tab>if isinstance(in_arrays, tuple):<tab><tab><tab><tab>results = self.calc_local(*in_arrays)<tab><tab><tab>elif isinstance(in_arrays, dict):<tab><tab><tab><tab>results = self.calc_local(**in_arrays)<tab><tab><tab>else:<tab><tab><tab><tab>results = self.calc_local(in_arrays)<tab><tab><IF-STMT><tab><tab><tab>self._progress_hook(batch)<tab><tab>yield results",if self . _progress_hook :,166
4441,"def merge(self, other):<tab>d = self._name2ft<tab>for name, (f, t) in other._name2ft.items():<tab><tab><IF-STMT><tab><tab><tab># Don't print here by default, since doing<tab><tab><tab>#<tab> so breaks some of the buildbots<tab><tab><tab># print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \<tab><tab><tab>#<tab>"" testers; summing outcomes.""<tab><tab><tab>f2, t2 = d[name]<tab><tab><tab>f = f + f2<tab><tab><tab>t = t + t2<tab><tab>d[name] = f, t",if name in d :,157
4442,"def _addSettingsToPanels(self, category, left, right):<tab>count = len(profile.getSubCategoriesFor(category)) + len(<tab><tab>profile.getSettingsForCategory(category)<tab>)<tab>p = left<tab>n = 0<tab>for title in profile.getSubCategoriesFor(category):<tab><tab>n += 1 + len(profile.getSettingsForCategory(category, title))<tab><tab><IF-STMT><tab><tab><tab>p = right<tab><tab>configBase.TitleRow(p, _(title))<tab><tab>for s in profile.getSettingsForCategory(category, title):<tab><tab><tab>configBase.SettingRow(p, s.getName())",if n > count / 2 :,159
4443,"def __init__(self, parent, dir, mask, with_dirs=True):<tab>filelist = []<tab>dirlist = [""..""]<tab>self.dir = dir<tab>self.file = """"<tab>mask = mask.upper()<tab>pattern = self.MakeRegex(mask)<tab>for i in os.listdir(dir):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = os.path.join(dir, i)<tab><tab>if os.path.isdir(path):<tab><tab><tab>dirlist.append(i)<tab><tab><tab>continue<tab><tab>path = path.upper()<tab><tab>value = i.upper()<tab><tab>if pattern.match(value) is not None:<tab><tab><tab>filelist.append(i)<tab>self.files = filelist<tab>if with_dirs:<tab><tab>self.dirs = dirlist","if i == ""."" or i == "".."" :",199
4444,def check_network_private(test_network):<tab>test_net = ipaddress.IPNetwork(test_network)<tab>test_start = test_net.network<tab>test_end = test_net.broadcast<tab>for network in settings.vpn.safe_priv_subnets:<tab><tab>network = ipaddress.IPNetwork(network)<tab><tab>net_start = network.network<tab><tab>net_end = network.broadcast<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False,if test_start >= net_start and test_end <= net_end :,128
4445,"def _end_description(self):<tab>if self._summaryKey == ""content"":<tab><tab>self._end_content()<tab>else:<tab><tab>value = self.popContent(""description"")<tab><tab>context = self._getContext()<tab><tab><IF-STMT><tab><tab><tab>context[""textinput""][""description""] = value<tab><tab>elif self.inimage:<tab><tab><tab>context[""image""][""description""] = value<tab>self._summaryKey = None",if self . intextinput :,107
4446,def compute_nullable_nonterminals(self):<tab>nullable = {}<tab>num_nullable = 0<tab>while 1:<tab><tab>for p in self.grammar.Productions[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nullable[p.name] = 1<tab><tab><tab><tab>continue<tab><tab><tab>for t in p.prod:<tab><tab><tab><tab>if not t in nullable:<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>nullable[p.name] = 1<tab><tab>if len(nullable) == num_nullable:<tab><tab><tab>break<tab><tab>num_nullable = len(nullable)<tab>return nullable,if p . len == 0 :,153
4447,"def process_bind_param(self, value, dialect):<tab>if value is not None:<tab><tab>if MAX_METADATA_VALUE_SIZE is not None:<tab><tab><tab>for k, v in list(value.items()):<tab><tab><tab><tab>sz = total_size(v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del value[k]<tab><tab><tab><tab><tab>log.warning(<tab><tab><tab><tab><tab><tab>""Refusing to bind metadata key {} due to size ({})"".format(<tab><tab><tab><tab><tab><tab><tab>k, sz<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>)<tab><tab>value = json_encoder.encode(value).encode()<tab>return value",if sz > MAX_METADATA_VALUE_SIZE :,168
4448,"def process_input_line(self, line, store_history=True):<tab>""""""process the input, capturing stdout""""""<tab>stdout = sys.stdout<tab>splitter = self.IP.input_splitter<tab>try:<tab><tab>sys.stdout = self.cout<tab><tab>splitter.push(line)<tab><tab>more = splitter.push_accepts_more()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>source_raw = splitter.source_raw_reset()[1]<tab><tab><tab>except:<tab><tab><tab><tab># recent ipython #4504<tab><tab><tab><tab>source_raw = splitter.raw_reset()<tab><tab><tab>self.IP.run_cell(source_raw, store_history=store_history)<tab>finally:<tab><tab>sys.stdout = stdout",if not more :,186
4449,"def _dump_section(self, name, values, f):<tab>doc = ""__doc__""<tab><IF-STMT><tab><tab>print(""# %s"" % values[doc], file=f)<tab>print(""%s("" % name, file=f)<tab>for k, v in values.items():<tab><tab>if k.endswith(""__doc__""):<tab><tab><tab>continue<tab><tab>doc = k + ""__doc__""<tab><tab>if doc in values:<tab><tab><tab>print(""<tab># %s"" % values[doc], file=f)<tab><tab>print(""<tab>%s = %s,"" % (k, pprint.pformat(v, indent=8)), file=f)<tab>print("")\n"", file=f)",if doc in values :,168
4450,"def open_session(self, app, request):<tab>sid = request.cookies.get(app.session_cookie_name)<tab>if sid:<tab><tab>stored_session = self.cls.objects(sid=sid).first()<tab><tab>if stored_session:<tab><tab><tab>expiration = stored_session.expiration<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expiration = expiration.replace(tzinfo=utc)<tab><tab><tab>if expiration > datetime.datetime.utcnow().replace(tzinfo=utc):<tab><tab><tab><tab>return MongoEngineSession(<tab><tab><tab><tab><tab>initial=stored_session.data, sid=stored_session.sid<tab><tab><tab><tab>)<tab>return MongoEngineSession(sid=str(uuid.uuid4()))",if not expiration . tzinfo :,174
4451,"def table_entry(mode1, bind_type1, mode2, bind_type2):<tab>with sock(mode1) as sock1:<tab><tab>bind(sock1, bind_type1)<tab><tab>try:<tab><tab><tab>with sock(mode2) as sock2:<tab><tab><tab><tab>bind(sock2, bind_type2)<tab><tab>except OSError as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""INUSE""<tab><tab><tab>elif exc.winerror == errno.WSAEACCES:<tab><tab><tab><tab>return ""ACCESS""<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>return ""Success""",if exc . winerror == errno . WSAEADDRINUSE :,160
4452,"def __init__(self, ruleset):<tab># Organize rules by path<tab>self.ruleset = ruleset<tab>self.rules = {}<tab>for filename in self.ruleset.rules:<tab><tab>for rule in self.ruleset.rules[filename]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>manage_dictionary(self.rules, rule.path, [])<tab><tab><tab>self.rules[rule.path].append(rule)",if not rule . enabled :,111
4453,"def talk(self, words):<tab>if self.writeSentence(words) == 0:<tab><tab>return<tab>r = []<tab>while 1:<tab><tab>i = self.readSentence()<tab><tab>if len(i) == 0:<tab><tab><tab>continue<tab><tab>reply = i[0]<tab><tab>attrs = {}<tab><tab>for w in i[1:]:<tab><tab><tab>j = w.find(""="", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>attrs[w] = """"<tab><tab><tab>else:<tab><tab><tab><tab>attrs[w[:j]] = w[j + 1 :]<tab><tab>r.append((reply, attrs))<tab><tab>if reply == ""!done"":<tab><tab><tab>return r",if j == - 1 :,169
4454,"def _check_decorator_overload(name: str, old: str, new: str) -> int:<tab>""""""Conditions for a decorator to overload an existing one.""""""<tab>properties = _property_decorators(name)<tab>if old == new:<tab><tab>return _MERGE<tab>elif old in properties and new in properties:<tab><tab>p_old, p_new = properties[old].precedence, properties[new].precedence<tab><tab><IF-STMT><tab><tab><tab>return _DISCARD<tab><tab>elif p_old == p_new:<tab><tab><tab>return _MERGE<tab><tab>else:<tab><tab><tab>return _REPLACE<tab>raise OverloadedDecoratorError(name, """")",if p_old > p_new :,158
4455,"def validate_pk(self):<tab>try:<tab><tab>self._key = serialization.load_pem_private_key(<tab><tab><tab>self.key, password=None, backend=default_backend()<tab><tab>)<tab><tab>if self._key.key_size > 2048:<tab><tab><tab>AWSValidationException(<tab><tab><tab><tab>""The private key length is not supported. Only 1024-bit and 2048-bit are allowed.""<tab><tab><tab>)<tab>except Exception as err:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>raise AWSValidationException(<tab><tab><tab>""The private key is not PEM-encoded or is not valid.""<tab><tab>)","if isinstance ( err , AWSValidationException ) :",157
4456,"def _add_custom_statement(self, custom_statements):<tab>if custom_statements is None:<tab><tab>return<tab>self.resource_policy[""Version""] = ""2012-10-17""<tab>if self.resource_policy.get(""Statement"") is None:<tab><tab>self.resource_policy[""Statement""] = custom_statements<tab>else:<tab><tab><IF-STMT><tab><tab><tab>custom_statements = [custom_statements]<tab><tab>statement = self.resource_policy[""Statement""]<tab><tab>if not isinstance(statement, list):<tab><tab><tab>statement = [statement]<tab><tab>for s in custom_statements:<tab><tab><tab>if s not in statement:<tab><tab><tab><tab>statement.append(s)<tab><tab>self.resource_policy[""Statement""] = statement","if not isinstance ( custom_statements , list ) :",184
4457,"def load(self, repn):<tab>for key in repn:<tab><tab>tmp = self._convert(key)<tab><tab><IF-STMT><tab><tab><tab>self.declare(tmp)<tab><tab>item = dict.__getitem__(self, tmp)<tab><tab>item._active = True<tab><tab>item.load(repn[key])",if tmp not in self :,80
4458,"def on_press_release(x):<tab>""""""Keyboard callback function.""""""<tab>global is_recording, enable_trigger_record<tab>press = keyboard.KeyboardEvent(""down"", 28, ""space"")<tab>release = keyboard.KeyboardEvent(""up"", 28, ""space"")<tab>if x.event_type == ""down"" and x.name == press.name:<tab><tab>if (not is_recording) and enable_trigger_record:<tab><tab><tab>sys.stdout.write(""Start Recording ... "")<tab><tab><tab>sys.stdout.flush()<tab><tab><tab>is_recording = True<tab>if x.event_type == ""up"" and x.name == release.name:<tab><tab><IF-STMT><tab><tab><tab>is_recording = False",if is_recording == True :,173
4459,"def apply_mask(self, mask, data_t, data_f):<tab>ind_t, ind_f = 0, 0<tab>out = []<tab>for m in cycle(mask):<tab><tab>if m:<tab><tab><tab>if ind_t == len(data_t):<tab><tab><tab><tab>return out<tab><tab><tab>out.append(data_t[ind_t])<tab><tab><tab>ind_t += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return out<tab><tab><tab>out.append(data_f[ind_f])<tab><tab><tab>ind_f += 1<tab>return out",if ind_f == len ( data_f ) :,154
4460,"def oo_contains_rule(source, apiGroups, resources, verbs):<tab>""""""Return true if the specified rule is contained within the provided source""""""<tab>rules = source[""rules""]<tab>if rules:<tab><tab>for rule in rules:<tab><tab><tab>if set(rule[""apiGroups""]) == set(apiGroups):<tab><tab><tab><tab>if set(rule[""resources""]) == set(resources):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False","if set ( rule [ ""verbs"" ] ) == set ( verbs ) :",118
4461,"def _maybe_commit_artifact(self, artifact_id):<tab>artifact_status = self._artifacts[artifact_id]<tab>if artifact_status[""pending_count""] == 0 and artifact_status[""commit_requested""]:<tab><tab>for callback in artifact_status[""pre_commit_callbacks""]:<tab><tab><tab>callback()<tab><tab><IF-STMT><tab><tab><tab>self._api.commit_artifact(artifact_id)<tab><tab>for callback in artifact_status[""post_commit_callbacks""]:<tab><tab><tab>callback()","if artifact_status [ ""finalize"" ] :",121
4462,"def shuffler(iterator, pool_size=10 ** 5, refill_threshold=0.9):<tab>yields_between_refills = round(pool_size * (1 - refill_threshold))<tab># initialize pool; this step may or may not exhaust the iterator.<tab>pool = take_n(pool_size, iterator)<tab>while True:<tab><tab>random.shuffle(pool)<tab><tab>for i in range(yields_between_refills):<tab><tab><tab>yield pool.pop()<tab><tab>next_batch = take_n(yields_between_refills, iterator)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>pool.extend(next_batch)<tab># finish consuming whatever's left - no need for further randomization.<tab>yield from pool",if not next_batch :,186
4463,"def __getitem__(self, key, _get_mode=False):<tab>if not _get_mode:<tab><tab>if isinstance(key, (int, long)):<tab><tab><tab>return self._list[key]<tab><tab><IF-STMT><tab><tab><tab>return self.__class__(self._list[key])<tab>ikey = key.lower()<tab>for k, v in self._list:<tab><tab>if k.lower() == ikey:<tab><tab><tab>return v<tab># micro optimization: if we are in get mode we will catch that<tab># exception one stack level down so we can raise a standard<tab># key error instead of our special one.<tab>if _get_mode:<tab><tab>raise KeyError()<tab>raise BadRequestKeyError(key)","elif isinstance ( key , slice ) :",176
4464,"def find(self, path):<tab>if os.path.isfile(path) or os.path.islink(path):<tab><tab>self.num_files = self.num_files + 1<tab><tab>if self.match_function(path):<tab><tab><tab>self.files.append(path)<tab>elif os.path.isdir(path):<tab><tab>for content in os.listdir(path):<tab><tab><tab>file = os.path.join(path, content)<tab><tab><tab>if os.path.isfile(file) or os.path.islink(file):<tab><tab><tab><tab>self.num_files = self.num_files + 1<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.files.append(file)<tab><tab><tab>else:<tab><tab><tab><tab>self.find(file)",if self . match_function ( file ) :,192
4465,"def validate_nb(self, nb):<tab>super(MetadataValidatorV3, self).validate_nb(nb)<tab>ids = set([])<tab>for cell in nb.cells:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>grade = cell.metadata[""nbgrader""][""grade""]<tab><tab>solution = cell.metadata[""nbgrader""][""solution""]<tab><tab>locked = cell.metadata[""nbgrader""][""locked""]<tab><tab>if not grade and not solution and not locked:<tab><tab><tab>continue<tab><tab>grade_id = cell.metadata[""nbgrader""][""grade_id""]<tab><tab>if grade_id in ids:<tab><tab><tab>raise ValidationError(""Duplicate grade id: {}"".format(grade_id))<tab><tab>ids.add(grade_id)","if ""nbgrader"" not in cell . metadata :",186
4466,"def _skip_start(self):<tab>start, stop = self.start, self.stop<tab>for chunk in self.app_iter:<tab><tab>self._pos += len(chunk)<tab><tab>if self._pos < start:<tab><tab><tab>continue<tab><tab>elif self._pos == start:<tab><tab><tab>return b""""<tab><tab>else:<tab><tab><tab>chunk = chunk[start - self._pos :]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>chunk = chunk[: stop - self._pos]<tab><tab><tab><tab>assert len(chunk) == stop - start<tab><tab><tab>return chunk<tab>else:<tab><tab>raise StopIteration()",if stop is not None and self . _pos > stop :,156
4467,"def _SetUser(self, users):<tab>for user in users.items():<tab><tab>username = user[0]<tab><tab>settings = user[1]<tab><tab>room = settings[""room""][""name""] if ""room"" in settings else None<tab><tab>file_ = settings[""file""] if ""file"" in settings else None<tab><tab>if ""event"" in settings:<tab><tab><tab>if ""joined"" in settings[""event""]:<tab><tab><tab><tab>self._client.userlist.addUser(username, room, file_)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._client.removeUser(username)<tab><tab>else:<tab><tab><tab>self._client.userlist.modUser(username, room, file_)","elif ""left"" in settings [ ""event"" ] :",170
4468,"def run_tests():<tab># type: () -> None<tab>x = 5<tab>with switch(x) as case:<tab><tab>if case(0):<tab><tab><tab>print(""zero"")<tab><tab><tab>print(""zero"")<tab><tab><IF-STMT><tab><tab><tab>print(""one or two"")<tab><tab>elif case(3, 4):<tab><tab><tab>print(""three or four"")<tab><tab>else:<tab><tab><tab>print(""default"")<tab><tab><tab>print(""another"")","elif case ( 1 , 2 ) :",114
4469,"def _populate():<tab>for fname in glob.glob(os.path.join(os.path.dirname(__file__), ""data"", ""*.json"")):<tab><tab>with open(fname) as inf:<tab><tab><tab>data = json.load(inf)<tab><tab><tab>data = data[list(data.keys())[0]]<tab><tab><tab>data = data[list(data.keys())[0]]<tab><tab><tab>for item in data:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>LOGGER.warning(""Repeated emoji {}"".format(item[""key""]))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>TABLE[item[""key""]] = item[""value""]","if item [ ""key"" ] in TABLE :",157
4470,"def slot_to_material(bobject: bpy.types.Object, slot: bpy.types.MaterialSlot):<tab>mat = slot.material<tab># Pick up backed material if present<tab>if mat is not None:<tab><tab>baked_mat = mat.name + ""_"" + bobject.name + ""_baked""<tab><tab><IF-STMT><tab><tab><tab>mat = bpy.data.materials[baked_mat]<tab>return mat",if baked_mat in bpy . data . materials :,111
4471,"def __keyPress(self, widget, event):<tab>if event.key == ""G"" and event.modifiers & event.Modifiers.Control:<tab><tab>if not all(hasattr(p, ""isGanged"") for p in self.getPlugs()):<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>self.__ungang()<tab><tab>else:<tab><tab><tab>self.__gang()<tab><tab>return True<tab>return False",if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,123
4472,"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(result, str):<tab><tab><tab>result = result.encode(""ascii"")<tab><tab><IF-STMT><tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab>if contains:<tab><tab><tab>if eline not in rline:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True","if isinstance ( expected , str ) :",181
4473,"def hosts_to_domains(self, hosts, exclusions=[]):<tab>domains = []<tab>for host in hosts:<tab><tab>elements = host.split(""."")<tab><tab># recursively walk through the elements<tab><tab># extracting all possible (sub)domains<tab><tab>while len(elements) >= 2:<tab><tab><tab># account for domains stored as hosts<tab><tab><tab>if len(elements) == 2:<tab><tab><tab><tab>domain = ""."".join(elements)<tab><tab><tab>else:<tab><tab><tab><tab># drop the host element<tab><tab><tab><tab>domain = ""."".join(elements[1:])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>domains.append(domain)<tab><tab><tab>del elements[0]<tab>return domains",if domain not in domains + exclusions :,167
4474,"def hsconn_sender(self):<tab>while not self.stop_event.is_set():<tab><tab>try:<tab><tab><tab># Block, but timeout, so that we can exit the loop gracefully<tab><tab><tab>request = self.send_queue.get(True, 6.0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Socket got closed and set to None in another thread...<tab><tab><tab><tab>self.socket.sendall(request)<tab><tab><tab>if self.send_queue is not None:<tab><tab><tab><tab>self.send_queue.task_done()<tab><tab>except queue.Empty:<tab><tab><tab>pass<tab><tab>except OSError:<tab><tab><tab>self.stop_event.set()",if self . socket is not None :,168
4475,"def get_url_args(self, item):<tab>if self.url_args:<tab><tab><IF-STMT><tab><tab><tab>url_args = self.url_args(item)<tab><tab>else:<tab><tab><tab>url_args = dict(self.url_args)<tab><tab>url_args[""id""] = item.id<tab><tab>return url_args<tab>else:<tab><tab>return dict(operation=self.label, id=item.id)","if hasattr ( self . url_args , ""__call__"" ) :",115
4476,"def list_projects(self):<tab>projects = []<tab>page = 1<tab>while True:<tab><tab>repos = self._client.get(<tab><tab><tab>""/user/repos"", {""sort"": ""full_name"", ""page"": page, ""per_page"": 100}<tab><tab>)<tab><tab>page += 1<tab><tab>for repo in repos:<tab><tab><tab>projects.append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""id"": repo[""full_name""],<tab><tab><tab><tab><tab>""name"": repo[""full_name""],<tab><tab><tab><tab><tab>""description"": repo[""description""],<tab><tab><tab><tab><tab>""is_private"": repo[""private""],<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return projects",if len ( repos ) < 100 :,185
4477,"def scripts(self):<tab>application_root = current_app.config.get(""APPLICATION_ROOT"")<tab>subdir = application_root != ""/""<tab>scripts = []<tab>for script in get_registered_scripts():<tab><tab>if script.startswith(""http""):<tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab><tab><IF-STMT><tab><tab><tab>scripts.append(f'<script defer src=""{application_root}/{script}""></script>')<tab><tab>else:<tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab>return markup(""\n"".join(scripts))",elif subdir :,146
4478,"def print_map(node, l):<tab>if node.title not in l:<tab><tab>l[node.title] = []<tab>for n in node.children:<tab><tab><IF-STMT><tab><tab><tab>w = {n.title: []}<tab><tab><tab>l[node.title].append(w)<tab><tab><tab>print_map(n, w)<tab><tab>else:<tab><tab><tab>l[node.title].append(n.title)",if len ( n . children ) > 0 :,112
4479,"def _validate_distinct_on_different_types_and_field_orders(<tab>self, collection, query, expected_results, get_mock_result):<tab>self.count = 0<tab>self.get_mock_result = get_mock_result<tab>query_iterable = collection.query_items(query, enable_cross_partition_query=True)<tab>results = list(query_iterable)<tab>for i in range(len(expected_results)):<tab><tab>if isinstance(results[i], dict):<tab><tab><tab>self.assertDictEqual(results[i], expected_results[i])<tab><tab><IF-STMT><tab><tab><tab>self.assertListEqual(results[i], expected_results[i])<tab><tab>else:<tab><tab><tab>self.assertEqual(results[i], expected_results[i])<tab>self.count = 0","elif isinstance ( results [ i ] , list ) :",196
4480,"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>v[""_class""] == ""Question""<tab><tab><tab>or v[""_class""] == ""Message""<tab><tab><tab>or v[""_class""] == ""Announcement""<tab><tab>):<tab><tab><tab>v[""admin""] = None<tab>return self.objs","if k . startswith ( ""_"" ) :",99
4481,"def qvec(self):<tab>#<tab><tab>if self.polrep != 'stokes':<tab>#<tab><tab><tab>raise Exception(""qvec is not defined unless self.polrep=='stokes'"")<tab>qvec = np.array([])<tab>if self.polrep == ""stokes"":<tab><tab>qvec = self._imdict[""Q""]<tab>elif self.polrep == ""circ"":<tab><tab><IF-STMT><tab><tab><tab>qvec = np.real(0.5 * (self.lrvec + self.rlvec))<tab>return qvec",if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 :,159
4482,"def display_value(self, key, w):<tab>if key == ""vdevices"":<tab><tab># Very special case<tab><tab>nids = [n[""deviceID""] for n in self.get_value(""devices"")]<tab><tab>for device in self.app.devices.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>b = Gtk.CheckButton(device.get_title(), False)<tab><tab><tab><tab>b.set_tooltip_text(device[""id""])<tab><tab><tab><tab>self[""vdevices""].pack_start(b, False, False, 0)<tab><tab><tab><tab>b.set_active(device[""id""] in nids)<tab><tab>self[""vdevices""].show_all()<tab>else:<tab><tab>EditorDialog.display_value(self, key, w)","if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :",197
4483,"def _set_xflux_setting(self, **kwargs):<tab>for key, value in kwargs.items():<tab><tab>if key in self._settings_map:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._set_xflux_screen_color(value)<tab><tab><tab><tab>self._current_color = str(value)<tab><tab><tab><tab># hackish - changing the current color unpauses xflux,<tab><tab><tab><tab># must reflect that with state change<tab><tab><tab><tab>if self.state == self.states[""PAUSED""]:<tab><tab><tab><tab><tab>self.state = self.states[""RUNNING""]<tab><tab><tab>else:<tab><tab><tab><tab>self._xflux.sendline(self._settings_map[key] + str(value))<tab><tab><tab>self._c()","if key == ""color"" :",187
4484,"def apply_acceleration(self, veh_ids, acc):<tab>""""""See parent class.""""""<tab># to hand the case of a single vehicle<tab>if type(veh_ids) == str:<tab><tab>veh_ids = [veh_ids]<tab><tab>acc = [acc]<tab>for i, vid in enumerate(veh_ids):<tab><tab><IF-STMT><tab><tab><tab>this_vel = self.get_speed(vid)<tab><tab><tab>next_vel = max([this_vel + acc[i] * self.sim_step, 0])<tab><tab><tab>self.kernel_api.vehicle.slowDown(vid, next_vel, 1e-3)",if acc [ i ] is not None and vid in self . get_ids ( ) :,172
4485,"def largest_factor_relatively_prime(a, b):<tab>""""""Return the largest factor of a relatively prime to b.""""""<tab>while 1:<tab><tab>d = gcd(a, b)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>b = d<tab><tab>while 1:<tab><tab><tab>q, r = divmod(a, d)<tab><tab><tab>if r > 0:<tab><tab><tab><tab>break<tab><tab><tab>a = q<tab>return a",if d <= 1 :,111
4486,"def check_status(self):<tab>try:<tab><tab>du = psutil.disk_usage(""/"")<tab><tab><IF-STMT><tab><tab><tab>raise ServiceWarning(<tab><tab><tab><tab>""{host} {percent}% disk usage exceeds {disk_usage}%"".format(<tab><tab><tab><tab><tab>host=host, percent=du.percent, disk_usage=DISK_USAGE_MAX<tab><tab><tab><tab>)<tab><tab><tab>)<tab>except ValueError as e:<tab><tab>self.add_error(ServiceReturnedUnexpectedResult(""ValueError""), e)",if DISK_USAGE_MAX and du . percent >= DISK_USAGE_MAX :,136
4487,"def build_reply(self, msg, text=None, private=False, threaded=False):<tab>response = self.build_message(text)<tab>if msg.is_group:<tab><tab><IF-STMT><tab><tab><tab>response.frm = self.bot_identifier<tab><tab><tab>response.to = IRCPerson(str(msg.frm))<tab><tab>else:<tab><tab><tab>response.frm = IRCRoomOccupant(str(self.bot_identifier), msg.frm.room)<tab><tab><tab>response.to = msg.frm.room<tab>else:<tab><tab>response.frm = self.bot_identifier<tab><tab>response.to = msg.frm<tab>return response",if private :,159
4488,"def _dict_refs(obj, named):<tab>""""""Return key and value objects of a dict/proxy.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for k, v in _items(obj):<tab><tab><tab><tab>s = str(k)<tab><tab><tab><tab>yield _NamedRef(""[K] "" + s, k)<tab><tab><tab><tab>yield _NamedRef(""[V] "" + s + "": "" + _repr(v), v)<tab><tab>else:<tab><tab><tab>for k, v in _items(obj):<tab><tab><tab><tab>yield k<tab><tab><tab><tab>yield v<tab>except (KeyError, ReferenceError, TypeError) as x:<tab><tab>warnings.warn(""Iterating '%s': %r"" % (_classof(obj), x))",if named :,172
4489,"def fetch_images():<tab>images = []<tab>marker = None<tab>while True:<tab><tab>batch = image_service.detail(<tab><tab><tab>context,<tab><tab><tab>filters=filters,<tab><tab><tab>marker=marker,<tab><tab><tab>sort_key=""created_at"",<tab><tab><tab>sort_dir=""desc"",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>images += batch<tab><tab>marker = batch[-1][""id""]<tab>return images",if not batch :,113
4490,"def compress(self, data_list):<tab>warn_untested()<tab>if data_list:<tab><tab>if data_list[1] in forms.fields.EMPTY_VALUES:<tab><tab><tab>error = self.error_messages[""invalid_year""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab><IF-STMT><tab><tab><tab>error = self.error_messages[""invalid_month""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab>year = int(data_list[1])<tab><tab>month = int(data_list[0])<tab><tab># find last day of the month<tab><tab>day = monthrange(year, month)[1]<tab><tab>return date(year, month, day)<tab>return None",if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,181
4491,"def _diff_dict(self, old, new):<tab>diff = {}<tab>removed = []<tab>added = []<tab>for key, value in old.items():<tab><tab>if key not in new:<tab><tab><tab>removed.append(key)<tab><tab><IF-STMT><tab><tab><tab># modified is indicated by a remove and add<tab><tab><tab>removed.append(key)<tab><tab><tab>added.append(key)<tab>for key, value in new.items():<tab><tab>if key not in old:<tab><tab><tab>added.append(key)<tab>if removed:<tab><tab>diff[""removed""] = sorted(removed)<tab>if added:<tab><tab>diff[""added""] = sorted(added)<tab>return diff",elif old [ key ] != new [ key ] :,172
4492,"def add_filters(self, function):<tab>try:<tab><tab>subscription = self.exists(function)<tab><tab><IF-STMT><tab><tab><tab>response = self._sns.call(<tab><tab><tab><tab>""set_subscription_attributes"",<tab><tab><tab><tab>SubscriptionArn=subscription[""SubscriptionArn""],<tab><tab><tab><tab>AttributeName=""FilterPolicy"",<tab><tab><tab><tab>AttributeValue=json.dumps(self.filters),<tab><tab><tab>)<tab><tab><tab>kappa.event_source.sns.LOG.debug(response)<tab>except Exception:<tab><tab>kappa.event_source.sns.LOG.exception(<tab><tab><tab>""Unable to add filters for SNS topic %s"", self.arn<tab><tab>)",if subscription :,165
4493,"def init_weights(self, pretrained=None):<tab>if isinstance(pretrained, str):<tab><tab>logger = logging.getLogger()<tab><tab>load_checkpoint(self, pretrained, strict=False, logger=logger)<tab>elif pretrained is None:<tab><tab>for m in self.modules():<tab><tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab><tab>kaiming_init(m)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>constant_init(m, 1)<tab>else:<tab><tab>raise TypeError(""pretrained must be a str or None"")","elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) :",141
4494,def test_is_native_login(self):<tab>for campaign in self.campaign_lists:<tab><tab>native = campaigns.is_native_login(campaign)<tab><tab><IF-STMT><tab><tab><tab>assert_true(native)<tab><tab>else:<tab><tab><tab>assert_false(native)<tab>native = campaigns.is_proxy_login(self.invalid_campaign)<tab>assert_true(native is None),"if campaign == ""prereg"" or campaign == ""erpc"" :",132
4495,"def _process_filter(self, query, host_state):<tab>""""""Recursively parse the query structure.""""""<tab>if not query:<tab><tab>return True<tab>cmd = query[0]<tab>method = self.commands[cmd]<tab>cooked_args = []<tab>for arg in query[1:]:<tab><tab>if isinstance(arg, list):<tab><tab><tab>arg = self._process_filter(arg, host_state)<tab><tab><IF-STMT><tab><tab><tab>arg = self._parse_string(arg, host_state)<tab><tab>if arg is not None:<tab><tab><tab>cooked_args.append(arg)<tab>result = method(self, cooked_args)<tab>return result","elif isinstance ( arg , basestring ) :",163
4496,"def find_go_files_mtime(app_files):<tab>files, mtime = [], 0<tab>for f, mt in app_files.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if APP_CONFIG.nobuild_files.match(f):<tab><tab><tab>continue<tab><tab>files.append(f)<tab><tab>mtime = max(mtime, mt)<tab>return files, mtime","if not f . endswith ( "".go"" ) :",100
4497,"def ExcludePath(self, path):<tab>""""""Check to see if this is a service url and matches inbound_services.""""""<tab>skip = False<tab>for reserved_path in self.reserved_paths.keys():<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>not self.inbound_services<tab><tab><tab><tab>or self.reserved_paths[reserved_path] not in self.inbound_services<tab><tab><tab>):<tab><tab><tab><tab>return (True, self.reserved_paths[reserved_path])<tab>return (False, None)",if path . startswith ( reserved_path ) :,132
4498,"def param_cov(self) -> DataFrame:<tab>""""""Parameter covariance""""""<tab>if self._param_cov is not None:<tab><tab>param_cov = self._param_cov<tab>else:<tab><tab>params = np.asarray(self.params)<tab><tab><IF-STMT><tab><tab><tab>param_cov = self.model.compute_param_cov(params)<tab><tab>else:<tab><tab><tab>param_cov = self.model.compute_param_cov(params, robust=False)<tab>return DataFrame(param_cov, columns=self._names, index=self._names)","if self . cov_type == ""robust"" :",141
4499,"def test_calculate_all_attentions(module, atype):<tab>m = importlib.import_module(module)<tab>args = make_arg(atype=atype)<tab><IF-STMT><tab><tab>batch = prepare_inputs(""pytorch"")<tab>else:<tab><tab>raise NotImplementedError<tab>model = m.E2E(6, 5, args)<tab>with chainer.no_backprop_mode():<tab><tab>if ""pytorch"" in module:<tab><tab><tab>att_ws = model.calculate_all_attentions(*batch)[0]<tab><tab>else:<tab><tab><tab>raise NotImplementedError<tab><tab>print(att_ws.shape)","if ""pytorch"" in module :",149
4500,"def __eq__(self, other):<tab>try:<tab><tab>if self.type != other.type:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return self.askAnswer == other.askAnswer<tab><tab>elif self.type == ""SELECT"":<tab><tab><tab>return self.vars == other.vars and self.bindings == other.bindings<tab><tab>else:<tab><tab><tab>return self.graph == other.graph<tab>except:<tab><tab>return False","if self . type == ""ASK"" :",116
4501,"def validate_memory(self, value):<tab>for k, v in value.viewitems():<tab><tab>if v is None:  # use NoneType to unset a value<tab><tab><tab>continue<tab><tab>if not re.match(PROCTYPE_MATCH, k):<tab><tab><tab>raise serializers.ValidationError(""Process types can only contain [a-z]"")<tab><tab><IF-STMT><tab><tab><tab>raise serializers.ValidationError(<tab><tab><tab><tab>""Limit format: <number><unit>, where unit = B, K, M or G""<tab><tab><tab>)<tab>return value","if not re . match ( MEMLIMIT_MATCH , str ( v ) ) :",141
4502,"def get_connections(data_about):<tab>data = data_about.find(""h3"", text=""Connections"").findNext()<tab>connections = {}<tab>for row in data.find_all(""tr""):<tab><tab>key = row.find_all(""td"")[0].text<tab><tab>value = row.find_all(""td"")[1]<tab><tab><IF-STMT><tab><tab><tab>connections[key] = get_all_links(value)<tab><tab>else:<tab><tab><tab>connections[key] = value.text<tab>return connections","if ""Teams"" in key :",129
4503,"def _compute_map(self, first_byte, second_byte=None):<tab>if first_byte != 0x0F:<tab><tab>return ""XED_ILD_MAP0""<tab>else:<tab><tab>if second_byte == None:<tab><tab><tab>return ""XED_ILD_MAP1""<tab><tab>if second_byte == 0x38:<tab><tab><tab>return ""XED_ILD_MAP2""<tab><tab>if second_byte == 0x3A:<tab><tab><tab>return ""XED_ILD_MAP3""<tab><tab><IF-STMT><tab><tab><tab>return ""XED_ILD_MAPAMD""<tab>die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",if second_byte == 0x0F and self . amd_enabled :,181
4504,"def compress(self, data_list):<tab>if data_list:<tab><tab>page_id = data_list[1]<tab><tab><IF-STMT><tab><tab><tab>if not self.required:<tab><tab><tab><tab>return None<tab><tab><tab>raise forms.ValidationError(self.error_messages[""invalid_page""])<tab><tab>return Page.objects.get(pk=page_id)<tab>return None",if page_id in EMPTY_VALUES :,98
4505,"def find_module(self, fullname, path=None):<tab>path = path or self.path_entry<tab># print('looking for ""%s"" in %s ...' % (fullname, path))<tab>for _ext in [""js"", ""pyj"", ""py""]:<tab><tab>_filepath = os.path.join(self.path_entry, ""%s.%s"" % (fullname, _ext))<tab><tab><IF-STMT><tab><tab><tab>print(""module found at %s:%s"" % (_filepath, fullname))<tab><tab><tab>return VFSModuleLoader(_filepath, fullname)<tab>print(""module %s not found"" % fullname)<tab>raise ImportError()<tab>return None",if _filepath in VFS :,158
4506,"def __decToBin(self, myDec):<tab>n = 0<tab>binOfDec = """"<tab>while myDec > 2 ** n:<tab><tab>n = n + 1<tab>if (myDec < 2 ** n) & (myDec != 0):<tab><tab>n = n - 1<tab>while n >= 0:<tab><tab><IF-STMT><tab><tab><tab>myDec = myDec - 2 ** n<tab><tab><tab>binOfDec = binOfDec + ""1""<tab><tab>else:<tab><tab><tab>binOfDec = binOfDec + ""0""<tab><tab>n = n - 1<tab>return binOfDec",if myDec >= 2 ** n :,148
4507,"def __str__(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>NVMLError._errcode_to_string[self.value] = str(nvmlErrorString(self.value))<tab><tab>return NVMLError._errcode_to_string[self.value]<tab>except NVMLError_Uninitialized:<tab><tab>return ""NVML Error with code %d"" % self.value",if self . value not in NVMLError . _errcode_to_string :,101
4508,"def abspath(pathdir: str) -> str:<tab>if Path is not None and isinstance(pathdir, Path):<tab><tab>return pathdir.abspath()<tab>else:<tab><tab>pathdir = path.abspath(pathdir)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>pathdir = pathdir.decode(fs_encoding)<tab><tab><tab>except UnicodeDecodeError as exc:<tab><tab><tab><tab>raise UnicodeDecodeError(<tab><tab><tab><tab><tab>""multibyte filename not supported on ""<tab><tab><tab><tab><tab>""this filesystem encoding ""<tab><tab><tab><tab><tab>""(%r)"" % fs_encoding<tab><tab><tab><tab>) from exc<tab><tab>return pathdir","if isinstance ( pathdir , bytes ) :",156
4509,"def _get_vtkjs(self):<tab>if self._vtkjs is None and self.object is not None:<tab><tab><IF-STMT><tab><tab><tab>if isfile(self.object):<tab><tab><tab><tab>with open(self.object, ""rb"") as f:<tab><tab><tab><tab><tab>vtkjs = f.read()<tab><tab><tab>else:<tab><tab><tab><tab>data_url = urlopen(self.object)<tab><tab><tab><tab>vtkjs = data_url.read()<tab><tab>elif hasattr(self.object, ""read""):<tab><tab><tab>vtkjs = self.object.read()<tab><tab>self._vtkjs = vtkjs<tab>return self._vtkjs","if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :",180
4510,"def _set_uid(self, val):<tab>if val is not None:<tab><tab>if pwd is None:<tab><tab><tab>self.bus.log(""pwd module not available; ignoring uid."", level=30)<tab><tab><tab>val = None<tab><tab><IF-STMT><tab><tab><tab>val = pwd.getpwnam(val)[2]<tab>self._uid = val","elif isinstance ( val , text_or_bytes ) :",92
4511,"def get_attached_nodes(self, external_account):<tab>for node in self.get_nodes_with_oauth_grants(external_account):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>node_settings = node.get_addon(self.oauth_provider.short_name)<tab><tab>if node_settings is None:<tab><tab><tab>continue<tab><tab>if node_settings.external_account == external_account:<tab><tab><tab>yield node",if node is None :,110
4512,"def from_obj(cls, py_obj):<tab>if not isinstance(py_obj, Image):<tab><tab>raise TypeError(""py_obj must be a wandb.Image"")<tab>else:<tab><tab>if hasattr(py_obj, ""_boxes"") and py_obj._boxes:<tab><tab><tab>box_keys = list(py_obj._boxes.keys())<tab><tab>else:<tab><tab><tab>box_keys = []<tab><tab><IF-STMT><tab><tab><tab>mask_keys = list(py_obj.masks.keys())<tab><tab>else:<tab><tab><tab>mask_keys = []<tab><tab>return cls(box_keys, mask_keys)","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :",164
4513,"def write(self, *bits):<tab>for bit in bits:<tab><tab>if not self.bytestream:<tab><tab><tab>self.bytestream.append(0)<tab><tab>byte = self.bytestream[self.bytenum]<tab><tab>if self.bitnum == 8:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>byte = 0<tab><tab><tab><tab>self.bytestream += bytes([byte])<tab><tab><tab>self.bytenum += 1<tab><tab><tab>self.bitnum = 0<tab><tab>mask = 2 ** self.bitnum<tab><tab>if bit:<tab><tab><tab>byte |= mask<tab><tab>else:<tab><tab><tab>byte &= ~mask<tab><tab>self.bytestream[self.bytenum] = byte<tab><tab>self.bitnum += 1",if self . bytenum == len ( self . bytestream ) - 1 :,186
4514,"def destroy(self, wipe=False):<tab>if self.state == self.UP:<tab><tab>image = self.image()<tab><tab><IF-STMT><tab><tab><tab>return self.confirm_destroy(image, self.full_name, abort=False)<tab><tab>else:<tab><tab><tab>self.warn(""tried to destroy {0} which didn't exist"".format(self.full_name))<tab>return True",if image :,95
4515,"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(<tab><tab><tab><tab>self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1<tab><tab><tab>).json()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>match = AGENT_VERSION_EXP.search(resp.get(""Version""))<tab><tab><tab><tab>if match is not None and len(match.groups()) == 1:<tab><tab><tab><tab><tab>meta[""ecs_version""] = match.group(1)<tab><tab>except Exception as e:<tab><tab><tab>self.log.debug(""Error getting ECS version: %s"" % str(e))<tab>return meta","if ""Version"" in resp :",176
4516,"def _path_type(st, lst):<tab>parts = []<tab>if st:<tab><tab><IF-STMT><tab><tab><tab>parts.append(""file"")<tab><tab>elif stat.S_ISDIR(st.st_mode):<tab><tab><tab>parts.append(""dir"")<tab><tab>else:<tab><tab><tab>parts.append(""other"")<tab>if lst:<tab><tab>if stat.S_ISLNK(lst.st_mode):<tab><tab><tab>parts.append(""link"")<tab>return "" "".join(parts)",if stat . S_ISREG ( st . st_mode ) :,130
4517,"def changed(self, action):<tab># Something was changed in the 'files' list<tab>if len(action.key) >= 1 and action.key[0].lower() == ""files"":<tab><tab># Refresh project files model<tab><tab><IF-STMT><tab><tab><tab># Don't clear the existing items if only inserting new things<tab><tab><tab>self.update_model(clear=False)<tab><tab>else:<tab><tab><tab># Clear existing items<tab><tab><tab>self.update_model(clear=True)","if action . type == ""insert"" :",120
4518,"def process(self, resources, event=None):<tab>client = local_session(self.manager.session_factory).client(""es"")<tab>for r in resources:<tab><tab><IF-STMT><tab><tab><tab>result = self.manager.retry(<tab><tab><tab><tab>client.describe_elasticsearch_domain_config,<tab><tab><tab><tab>DomainName=r[""DomainName""],<tab><tab><tab><tab>ignore_err_codes=(""ResourceNotFoundException"",),<tab><tab><tab>)<tab><tab><tab>if result:<tab><tab><tab><tab>r[self.policy_attribute] = json.loads(<tab><tab><tab><tab><tab>result.get(""DomainConfig"").get(""AccessPolicies"").get(""Options"")<tab><tab><tab><tab>)<tab>return super().process(resources)",if self . policy_attribute not in r :,175
4519,"def line_items(self):<tab>line_items = []<tab>for line in self.lines_str:<tab><tab>line = line.split(""|"")<tab><tab>line = line[1:-1]  # del first and last empty item (consequence of split)<tab><tab>items = []<tab><tab>for item in line:<tab><tab><tab>i = re.search(r""(\S+([ \t]+\S+)*)+"", item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>items.append(i.group())<tab><tab><tab>else:<tab><tab><tab><tab>items.append("" "")<tab><tab>line_items.append(items)<tab>return line_items",if i :,151
4520,"def on_data(res):<tab>if terminate.is_set():<tab><tab>return<tab>if args.strings and not args.no_content:<tab><tab>if type(res) == tuple:<tab><tab><tab>f, v = res<tab><tab><tab>if type(f) == unicode:<tab><tab><tab><tab>f = f.encode(""utf-8"")<tab><tab><tab>if type(v) == unicode:<tab><tab><tab><tab>v = v.encode(""utf-8"")<tab><tab><tab>self.success(""{}: {}"".format(f, v))<tab><tab><IF-STMT><tab><tab><tab>self.success(res)<tab>else:<tab><tab>self.success(res)",elif not args . content_only :,158
4521,"def get_servers(self, detail=True, search_opts=None):<tab>rel_url = ""/servers/detail"" if detail else ""/servers""<tab>if search_opts is not None:<tab><tab>qparams = {}<tab><tab>for opt, val in search_opts.iteritems():<tab><tab><tab>qparams[opt] = val<tab><tab><IF-STMT><tab><tab><tab>query_string = ""?%s"" % urllib.urlencode(qparams)<tab><tab><tab>rel_url += query_string<tab>return self.api_get(rel_url)[""servers""]",if qparams :,130
4522,"def run(self):<tab>while not self.__exit__:<tab><tab><IF-STMT><tab><tab><tab>sleep(10)<tab><tab><tab>continue<tab><tab>o = self.playlist[0]<tab><tab>self.playlist.remove(o)<tab><tab>obj = json.loads(o)<tab><tab>if not ""args"" in obj:<tab><tab><tab>obj[""args""] = {""ua"": """", ""header"": """", ""title"": """", ""referer"": """"}<tab><tab>obj[""play""] = False<tab><tab>self.handle = launch_player(obj[""urls""], obj[""ext""], **obj[""args""])<tab><tab>self.handle.wait()",if len ( self . playlist ) == 0 :,151
4523,"def get_to_download_runs_ids(session, headers):<tab>last_date = 0<tab>result = []<tab>while 1:<tab><tab>r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers)<tab><tab><IF-STMT><tab><tab><tab>run_logs = r.json()[""data""][""records""]<tab><tab><tab>result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs])<tab><tab><tab>last_date = r.json()[""data""][""lastTimestamp""]<tab><tab><tab>since_time = datetime.utcfromtimestamp(last_date / 1000)<tab><tab><tab>print(f""pares keep ids data since {since_time}"")<tab><tab><tab>time.sleep(1)  # spider rule<tab><tab><tab>if not last_date:<tab><tab><tab><tab>break<tab>return result",if r . ok :,199
4524,"def __saveWork(self, work, results):<tab>""""""Stores the resulting last log line to the cache with the proxy key""""""<tab>del work<tab># pylint: disable=broad-except<tab>try:<tab><tab><IF-STMT><tab><tab><tab>__cached = self.__cache[results[0]]<tab><tab><tab>__cached[self.__TIME] = time.time()<tab><tab><tab>__cached[self.__LINE] = results[1]<tab><tab><tab>__cached[self.__LLU] = results[2]<tab>except KeyError as e:<tab><tab># Could happen while switching jobs with work in the queue<tab><tab>pass<tab>except Exception as e:<tab><tab>list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if results :,170
4525,"def read_notes(rec):<tab>found = []<tab>for tag in range(500, 595):<tab><tab>if tag in (505, 520):<tab><tab><tab>continue<tab><tab>fields = rec.get_fields(str(tag))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for f in fields:<tab><tab><tab>x = f.get_lower_subfields()<tab><tab><tab>if x:<tab><tab><tab><tab>found.append("" "".join(x).strip("" ""))<tab>if found:<tab><tab>return ""\n\n"".join(found)",if not fields :,134
4526,"def serialize_to(self, stream, alternate_script=None):<tab>stream.write(self.txo_ref.tx_ref.hash)<tab>stream.write_uint32(self.txo_ref.position)<tab>if alternate_script is not None:<tab><tab>stream.write_string(alternate_script)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>stream.write_string(self.coinbase)<tab><tab>else:<tab><tab><tab>stream.write_string(self.script.source)<tab>stream.write_uint32(self.sequence)",if self . is_coinbase :,142
4527,"def func_named(self, arg):<tab>result = None<tab>target = ""do_"" + arg<tab>if target in dir(self):<tab><tab>result = target<tab>else:<tab><tab><IF-STMT>  # accept shortened versions of commands<tab><tab><tab>funcs = [fname for fname in self.keywords if fname.startswith(arg)]<tab><tab><tab>if len(funcs) == 1:<tab><tab><tab><tab>result = ""do_"" + funcs[0]<tab>return result",if self . abbrev :,110
4528,"def static_login(self, token, *, bot):<tab># Necessary to get aiohttp to stop complaining about session creation<tab>self.__session = aiohttp.ClientSession(<tab><tab>connector=self.connector, ws_response_class=DiscordClientWebSocketResponse<tab>)<tab>old_token, old_bot = self.token, self.bot_token<tab>self._token(token, bot=bot)<tab>try:<tab><tab>data = await self.request(Route(""GET"", ""/users/@me""))<tab>except HTTPException as exc:<tab><tab>self._token(old_token, bot=old_bot)<tab><tab><IF-STMT><tab><tab><tab>raise LoginFailure(""Improper token has been passed."") from exc<tab><tab>raise<tab>return data",if exc . response . status == 401 :,179
4529,"def render_buttons(self):<tab>for x, button in enumerate(self.button_list):<tab><tab>gcolor = Gdk.color_parse(self.color_list[x])<tab><tab><IF-STMT><tab><tab><tab>fgcolor = Gdk.color_parse(""#FFFFFF"")<tab><tab>else:<tab><tab><tab>fgcolor = Gdk.color_parse(""#000000"")<tab><tab>button.set_label(self.color_list[x])<tab><tab>button.set_sensitive(True)<tab><tab>button.modify_bg(Gtk.StateType.NORMAL, gcolor)<tab><tab>button.modify_fg(Gtk.StateType.NORMAL, fgcolor)","if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :",170
4530,"def _set_text(self, data):<tab>lines = []<tab>for key, value in data.items():<tab><tab>lines.append("""")<tab><tab>txt = yaml.dump({key: value}, default_flow_style=False)<tab><tab>title = self.titles.get(key)<tab><tab><IF-STMT><tab><tab><tab>lines.append(""# %s"" % title)<tab><tab>lines.append(txt.rstrip())<tab>txt = ""\n"".join(lines) + ""\n""<tab>txt = txt.lstrip()<tab>self.edit.setPlainText(txt)",if title :,134
4531,"def build_path(self):<tab>for variable in re_path_template.findall(self.path):<tab><tab>name = variable.strip(""{}"")<tab><tab><IF-STMT><tab><tab><tab># No 'user' parameter provided, fetch it from Auth instead.<tab><tab><tab>value = self.api.auth.get_username()<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>value = quote(self.session.params[name])<tab><tab><tab>except KeyError:<tab><tab><tab><tab>raise TweepError(<tab><tab><tab><tab><tab>""No parameter value found for path variable: %s"" % name<tab><tab><tab><tab>)<tab><tab><tab>del self.session.params[name]<tab><tab>self.path = self.path.replace(variable, value)","if name == ""user"" and ""user"" not in self . session . params and self . api . auth :",197
4532,"def _calculate_writes_for_built_in_indices(self, entity):<tab>writes = 0<tab>for prop_name in entity.keys():<tab><tab><IF-STMT><tab><tab><tab>prop_vals = entity[prop_name]<tab><tab><tab>if isinstance(prop_vals, (list)):<tab><tab><tab><tab>num_prop_vals = len(prop_vals)<tab><tab><tab>else:<tab><tab><tab><tab>num_prop_vals = 1<tab><tab><tab>writes += 2 * num_prop_vals<tab>return writes",if not prop_name in entity . unindexed_properties ( ) :,131
4533,"def create_connection(self, address, protocol_factory=None, **kw):<tab>""""""Helper method for creating a connection to an ``address``.""""""<tab>protocol_factory = protocol_factory or self.create_protocol<tab>if isinstance(address, tuple):<tab><tab>host, port = address<tab><tab><IF-STMT><tab><tab><tab>self.logger.debug(""Create connection %s:%s"", host, port)<tab><tab>_, protocol = await self._loop.create_connection(<tab><tab><tab>protocol_factory, host, port, **kw<tab><tab>)<tab><tab>await protocol.event(""connection_made"")<tab>else:<tab><tab>raise NotImplementedError(""Could not connect to %s"" % str(address))<tab>return protocol",if self . debug :,165
4534,def _increment_bracket_num(self):<tab>self._current_bracket -= 1<tab>if self._current_bracket < 0:<tab><tab>self._current_bracket = self._get_num_brackets() - 1<tab><tab>self._current_iteration += 1<tab><tab><IF-STMT><tab><tab><tab>self._current_bracket = 0,if self . _current_iteration > self . hyperband_iterations :,88
4535,"def get_cycle_path(self, curr_node, goal_node_index):<tab>for dep in curr_node[""deps""]:<tab><tab><IF-STMT><tab><tab><tab>return [curr_node[""address""]]<tab>for dep in curr_node[""deps""]:<tab><tab>path = self.get_cycle_path(<tab><tab><tab>self.get_by_address(dep), goal_node_index<tab><tab>)  # self.nodelist[dep], goal_node_index)<tab><tab>if len(path) > 0:<tab><tab><tab>path.insert(0, curr_node[""address""])<tab><tab><tab>return path<tab>return []",if dep == goal_node_index :,153
4536,"def as_dict(path="""", version=""latest"", section=""meta-data""):<tab>result = {}<tab>dirs = dir(path, version, section)<tab>if not dirs:<tab><tab>return None<tab>for item in dirs:<tab><tab>if item.endswith(""/""):<tab><tab><tab>records = as_dict(path + item, version, section)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[item[:-1]] = records<tab><tab>elif is_dict.match(item):<tab><tab><tab>idx, name = is_dict.match(item).groups()<tab><tab><tab>records = as_dict(path + idx + ""/"", version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[name] = records<tab><tab>else:<tab><tab><tab>result[item] = valueconv(get(path + item, version, section))<tab>return result",if records :,197
4537,"def preprocess_raw_enwik9(input_filename, output_filename):<tab>with open(input_filename, ""r"") as f1:<tab><tab>with open(output_filename, ""w"") as f2:<tab><tab><tab>while True:<tab><tab><tab><tab>line = f1.readline()<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>line = list(enwik9_norm_transform([line]))[0]<tab><tab><tab><tab>if line != "" "" and line != """":<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>line = line[1:]<tab><tab><tab><tab><tab>f2.writelines(line + ""\n"")","if line [ 0 ] == "" "" :",164
4538,"def _handle_unsubscribe(self, web_sock):<tab>index = None<tab>with await self._subscriber_lock:<tab><tab>for i, (subscriber_web_sock, _) in enumerate(self._subscribers):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>index = i<tab><tab><tab><tab>break<tab><tab>if index is not None:<tab><tab><tab>del self._subscribers[index]<tab><tab>if not self._subscribers:<tab><tab><tab>asyncio.ensure_future(self._unregister_subscriptions())",if subscriber_web_sock == web_sock :,124
4539,"def formatmonthname(self, theyear, themonth, withyear=True):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab>s = month_name[themonth]<tab><tab>if encoding is not None:<tab><tab><tab>s = s.decode(encoding)<tab><tab><IF-STMT><tab><tab><tab>s = ""%s %s"" % (s, theyear)<tab><tab>return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",if withyear :,115
4540,"def generate_sitemaps(filename):<tab>rows = (line.strip().split(""\t"") for line in open(filename))<tab>for sortkey, chunk in itertools.groupby(rows, lambda row: row[0]):<tab><tab>things = []<tab><tab>_chunk = list(chunk)<tab><tab>for segment in _chunk:<tab><tab><tab>sortkey = segment.pop(0)<tab><tab><tab>last_modified = segment.pop(-1)<tab><tab><tab>path = """".join(segment)<tab><tab><tab>things.append(web.storage(path=path, last_modified=last_modified))<tab><tab><IF-STMT><tab><tab><tab>write(""sitemaps/sitemap_%s.xml.gz"" % sortkey, sitemap(things))",if things :,165
4541,"def use_index(<tab>self, term: Union[str, Index], *terms: Union[str, Index]) -> ""QueryBuilder"":<tab>for t in (term, *terms):<tab><tab><IF-STMT><tab><tab><tab>self._use_indexes.append(t)<tab><tab>elif isinstance(t, str):<tab><tab><tab>self._use_indexes.append(Index(t))","if isinstance ( t , Index ) :",94
4542,"def get_changed(self):<tab>if self._is_expression():<tab><tab>result = self._get_node_text(self.ast)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return result<tab>else:<tab><tab>collector = codeanalyze.ChangeCollector(self.source)<tab><tab>last_end = -1<tab><tab>for match in self.matches:<tab><tab><tab>start, end = match.get_region()<tab><tab><tab>if start < last_end:<tab><tab><tab><tab>if not self._is_expression():<tab><tab><tab><tab><tab>continue<tab><tab><tab>last_end = end<tab><tab><tab>replacement = self._get_matched_text(match)<tab><tab><tab>collector.add_change(start, end, replacement)<tab><tab>return collector.get_changed()",if result == self . source :,189
4543,"def quiet_f(*args):<tab>vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)}<tab>value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation)<tab>if expect_list:<tab><tab>if value.has_form(""List"", None):<tab><tab><tab>value = [extract_pyreal(item) for item in value.leaves]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>value = extract_pyreal(value)<tab><tab>if value is None or isinf(value) or isnan(value):<tab><tab><tab>return None<tab><tab>return value",if any ( item is None for item in value ) :,177
4544,"def _reemit_nested_event(self, event: Event):<tab>source_index = self.index(event.source)<tab>for attr in (""index"", ""new_index""):<tab><tab><IF-STMT><tab><tab><tab>src_index = ensure_tuple_index(event.index)<tab><tab><tab>setattr(event, attr, (source_index,) + src_index)<tab>if not hasattr(event, ""index""):<tab><tab>setattr(event, ""index"", source_index)<tab># reemit with this object's EventEmitter of the same type if present<tab># otherwise just emit with the EmitterGroup itself<tab>getattr(self.events, event.type, self.events)(event)","if hasattr ( event , attr ) :",163
4545,"def check(self):<tab>""""""Perform required checks to conclude if it's safe to operate""""""<tab>if self.interpreter.manual is None:<tab><tab><IF-STMT><tab><tab><tab>self.error = self.process.error<tab><tab><tab>self.tip = self.process.tip<tab><tab><tab>return False<tab>start = time.time()<tab>while not self._status():<tab><tab>if time.time() - start >= 2:  # 2s<tab><tab><tab>self.error = ""can't connect to the minserver on {}:{}"".format(<tab><tab><tab><tab>self.interpreter.host, self.interpreter.port<tab><tab><tab>)<tab><tab><tab>self.tip = ""check your vagrant machine is running""<tab><tab><tab>return False<tab><tab>time.sleep(0.1)<tab>return True",if not self . process . healthy :,189
4546,"def apply(self):<tab>new_block = self.block.copy()<tab>new_block.clear()<tab>for inst in self.block.body:<tab><tab><IF-STMT><tab><tab><tab>const_assign = self._assign_const(inst)<tab><tab><tab>new_block.append(const_assign)<tab><tab><tab>inst = self._assign_getitem(inst, index=const_assign.target)<tab><tab>new_block.append(inst)<tab>return new_block","if isinstance ( inst , Assign ) and inst . value in self . getattrs :",126
4547,"def _get_orientation(self):<tab>if self.state:<tab><tab>rotation = [0] * 9<tab><tab>inclination = [0] * 9<tab><tab>gravity = []<tab><tab>geomagnetic = []<tab><tab>gravity = self.listener_a.values<tab><tab>geomagnetic = self.listener_m.values<tab><tab><IF-STMT><tab><tab><tab>ff_state = SensorManager.getRotationMatrix(<tab><tab><tab><tab>rotation, inclination, gravity, geomagnetic<tab><tab><tab>)<tab><tab><tab>if ff_state:<tab><tab><tab><tab>values = [0, 0, 0]<tab><tab><tab><tab>values = SensorManager.getOrientation(rotation, values)<tab><tab><tab>return values",if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None :,187
4548,def getFirstSubGraph(graph):<tab>if len(graph) == 0:<tab><tab>return None<tab>subg = {}<tab>todo = [graph.keys()[0]]<tab>while len(todo) > 0:<tab><tab><IF-STMT><tab><tab><tab>subg[todo[0]] = graph[todo[0]]<tab><tab><tab>todo.extend(graph[todo[0]])<tab><tab><tab>del graph[todo[0]]<tab><tab>del todo[0]<tab>return subg,if todo [ 0 ] in graph . keys ( ) :,120
4549,"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if ""Last-Modified"" not in rv.headers:<tab><tab>try:<tab><tab><tab>result = date<tab><tab><tab>if callable(result):<tab><tab><tab><tab>result = result(rv)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>from werkzeug.http import http_date<tab><tab><tab><tab>result = http_date(result)<tab><tab><tab>if result:<tab><tab><tab><tab>rv.headers[""Last-Modified""] = result<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the lastmodified value for response {!r}"".format(<tab><tab><tab><tab><tab>rv<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return rv","if not isinstance ( result , basestring ) :",189
4550,"def set_invoice_details(self, row):<tab>invoice_details = self.invoice_details.get(row.voucher_no, {})<tab>if row.due_date:<tab><tab>invoice_details.pop(""due_date"", None)<tab>row.update(invoice_details)<tab>if row.voucher_type == ""Sales Invoice"":<tab><tab><IF-STMT><tab><tab><tab>self.set_delivery_notes(row)<tab><tab>if self.filters.show_sales_person and row.sales_team:<tab><tab><tab>row.sales_person = "", "".join(row.sales_team)<tab><tab><tab>del row[""sales_team""]",if self . filters . show_delivery_notes :,160
4551,"def process(output):<tab>modules = {}<tab>for line in output:<tab><tab>name, size, instances, depends, state, _ = line.split("" "", 5)<tab><tab>instances = int(instances)<tab><tab>module = {<tab><tab><tab>""size"": size,<tab><tab><tab>""instances"": instances,<tab><tab><tab>""state"": state,<tab><tab>}<tab><tab><IF-STMT><tab><tab><tab>module[""depends""] = [value for value in depends.split("","") if value]<tab><tab>modules[name] = module<tab>return modules","if depends != ""-"" :",127
4552,"def _get_host_from_zc_service_info(service_info: zeroconf.ServiceInfo):<tab>""""""Get hostname or IP + port from zeroconf service_info.""""""<tab>host = None<tab>port = None<tab>if (<tab><tab>service_info<tab><tab>and service_info.port<tab><tab>and (service_info.server or len(service_info.addresses) > 0)<tab>):<tab><tab><IF-STMT><tab><tab><tab>host = socket.inet_ntoa(service_info.addresses[0])<tab><tab>else:<tab><tab><tab>host = service_info.server.lower()<tab><tab>port = service_info.port<tab>return (host, port)",if len ( service_info . addresses ) > 0 :,170
4553,"def _init_weights(self, module):<tab>if isinstance(module, nn.Linear):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab>if module.bias is not None:<tab><tab><tab>module.bias.data.zero_()<tab>elif isinstance(module, nn.Embedding):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab><IF-STMT><tab><tab><tab>module.weight.data[module.padding_idx].zero_()",if module . padding_idx is not None :,141
4554,"def visitFromImport(self, import_stmt, import_info):<tab>new_pairs = []<tab>if not import_info.is_star_import():<tab><tab>for name, alias in import_info.names_and_aliases:<tab><tab><tab>try:<tab><tab><tab><tab>pyname = self.pymodule[alias or name]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>except exceptions.AttributeNotFoundError:<tab><tab><tab><tab>pass<tab><tab><tab>new_pairs.append((name, alias))<tab>return importinfo.FromImport(import_info.module_name, import_info.level, new_pairs)","if occurrences . same_pyname ( self . pyname , pyname ) :",162
4555,"def _apply_patches(self):<tab>try:<tab><tab>s = Subprocess(<tab><tab><tab>log=self.logfile, cwd=self.build_dir, verbose=self.options.verbose<tab><tab>)<tab><tab>for patch in self.patches:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for ed, source in patch.items():<tab><tab><tab><tab><tab>s.shell(""ed - %s < %s"" % (source, ed))<tab><tab><tab>else:<tab><tab><tab><tab>s.shell(""patch -p0 < %s"" % patch)<tab>except:<tab><tab>logger.error(""Failed to patch `%s`.\n%s"" % (self.build_dir, sys.exc_info()[1]))<tab><tab>sys.exit(1)",if type ( patch ) is dict :,183
4556,"def __init__(self, parent, dir, mask, with_dirs=True):<tab>filelist = []<tab>dirlist = [""..""]<tab>self.dir = dir<tab>self.file = """"<tab>mask = mask.upper()<tab>pattern = self.MakeRegex(mask)<tab>for i in os.listdir(dir):<tab><tab>if i == ""."" or i == "".."":<tab><tab><tab>continue<tab><tab>path = os.path.join(dir, i)<tab><tab><IF-STMT><tab><tab><tab>dirlist.append(i)<tab><tab><tab>continue<tab><tab>path = path.upper()<tab><tab>value = i.upper()<tab><tab>if pattern.match(value) is not None:<tab><tab><tab>filelist.append(i)<tab>self.files = filelist<tab>if with_dirs:<tab><tab>self.dirs = dirlist",if os . path . isdir ( path ) :,199
4557,"def remove_invalid_dirs(paths, bp_dir, module_name):<tab>ret = []<tab>for path in paths:<tab><tab><IF-STMT><tab><tab><tab>ret.append(path)<tab><tab>else:<tab><tab><tab>logging.warning('Dir ""%s"" of module ""%s"" does not exist', path, module_name)<tab>return ret","if os . path . isdir ( os . path . join ( bp_dir , path ) ) :",98
4558,"def update_sockets(self):<tab>inputs = self.inputs<tab>inputs_n = ""ABabcd""<tab>penta_sockets = pentagon_dict[self.grid_type].input_sockets<tab>for socket in inputs_n:<tab><tab>if socket in penta_sockets:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>inputs[socket].hide_safe = False<tab><tab>else:<tab><tab><tab>inputs[socket].hide_safe = True",if inputs [ socket ] . hide_safe :,113
4559,"def __cut(sentence):<tab>global emit_P<tab>prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P)<tab>begin, nexti = 0, 0<tab># print pos_list, sentence<tab>for i, char in enumerate(sentence):<tab><tab>pos = pos_list[i]<tab><tab>if pos == ""B"":<tab><tab><tab>begin = i<tab><tab>elif pos == ""E"":<tab><tab><tab>yield sentence[begin : i + 1]<tab><tab><tab>nexti = i + 1<tab><tab><IF-STMT><tab><tab><tab>yield char<tab><tab><tab>nexti = i + 1<tab>if nexti < len(sentence):<tab><tab>yield sentence[nexti:]","elif pos == ""S"" :",174
4560,"def validate(self):<tab>if self.data.get(""encrypted"", True):<tab><tab>key = self.data.get(""target_key"")<tab><tab><IF-STMT><tab><tab><tab>raise PolicyValidationError(<tab><tab><tab><tab>""Encrypted snapshot copy requires kms key on %s"" % (self.manager.data,)<tab><tab><tab>)<tab>return self",if not key :,82
4561,"def __init__(self, patch_files, patch_directories):<tab>files = []<tab>files_data = {}<tab>for filename_data in patch_files:<tab><tab>if isinstance(filename_data, list):<tab><tab><tab>filename, data = filename_data<tab><tab>else:<tab><tab><tab>filename = filename_data<tab><tab><tab>data = None<tab><tab><IF-STMT><tab><tab><tab>filename = ""{0}{1}"".format(FakeState.deploy_dir, filename)<tab><tab>files.append(filename)<tab><tab>if data:<tab><tab><tab>files_data[filename] = data<tab>self.files = files<tab>self.files_data = files_data<tab>self.directories = patch_directories",if not filename . startswith ( os . sep ) :,171
4562,"def validate_name_and_description(body, check_length=True):<tab>for attribute in [""name"", ""description"", ""display_name"", ""display_description""]:<tab><tab>value = body.get(attribute)<tab><tab>if value is not None:<tab><tab><tab>if isinstance(value, six.string_types):<tab><tab><tab><tab>body[attribute] = value.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>utils.check_string_length(<tab><tab><tab><tab><tab><tab>body[attribute], attribute, min_length=0, max_length=255<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except exception.InvalidInput as error:<tab><tab><tab><tab><tab>raise webob.exc.HTTPBadRequest(explanation=error.msg)",if check_length :,184
4563,"def pick(items, sel):<tab>for x, s in zip(items, sel):<tab><tab>if match(s):<tab><tab><tab>yield x<tab><tab><IF-STMT><tab><tab><tab>yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",elif not x . is_atom ( ) and not s . is_atom ( ) :,79
4564,"def wait_or_kill(self):<tab>""""""Wait for the program to terminate, or kill it after 5s.""""""<tab>if self.instance.poll() is None:<tab><tab># We try one more time to kill gracefully using Ctrl-C.<tab><tab>logger.info(""Interrupting %s and waiting..."", self.coord)<tab><tab>self.instance.send_signal(signal.SIGINT)<tab><tab># FIXME on py3 this becomes self.instance.wait(timeout=5)<tab><tab>t = monotonic_time()<tab><tab>while monotonic_time() - t < 5:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.info(""Terminated %s."", self.coord)<tab><tab><tab><tab>break<tab><tab><tab>time.sleep(0.1)<tab><tab>else:<tab><tab><tab>self.kill()",if self . instance . poll ( ) is not None :,194
4565,"def sort_collection(self, models, many):<tab>ordering = self.ordering<tab>if not many or not ordering:<tab><tab>return models<tab>for key in reversed(ordering):<tab><tab>reverse = key[0] == ""-""<tab><tab><IF-STMT><tab><tab><tab>key = key[1:]<tab><tab>models = sorted(models, key=partial(deep_getattr, key=key), reverse=reverse)<tab>return models",if reverse :,98
4566,"def get_palette_for_custom_classes(self, class_names, palette=None):<tab>if self.label_map is not None:<tab><tab># return subset of palette<tab><tab>palette = []<tab><tab>for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>palette.append(self.PALETTE[old_id])<tab><tab>palette = type(self.PALETTE)(palette)<tab>elif palette is None:<tab><tab>if self.PALETTE is None:<tab><tab><tab>palette = np.random.randint(0, 255, size=(len(class_names), 3))<tab><tab>else:<tab><tab><tab>palette = self.PALETTE<tab>return palette",if new_id != - 1 :,194
4567,"def _find_tcl_dir():<tab>lib_dirs = [os.path.dirname(_x) for _x in sys.path if _x.lower().endswith(""lib"")]<tab>for lib_dir in lib_dirs:<tab><tab>base_dir = os.path.join(lib_dir, TclLibrary.FOLDER)<tab><tab><IF-STMT><tab><tab><tab>for root, _, files in os.walk(base_dir):<tab><tab><tab><tab>if TclLibrary.INIT_TCL in files:<tab><tab><tab><tab><tab>return root",if os . path . exists ( base_dir ) :,133
4568,"def __next__(self):<tab>""""""Special paging functionality""""""<tab>if self.iter is None:<tab><tab>self.iter = iter(self.objs)<tab>try:<tab><tab>return next(self.iter)<tab>except StopIteration:<tab><tab>self.iter = None<tab><tab>self.objs = []<tab><tab><IF-STMT><tab><tab><tab>self.page += 1<tab><tab><tab>self._connection.get_response(self.action, self.params, self.page, self)<tab><tab><tab>return next(self)<tab><tab>else:<tab><tab><tab>raise",if int ( self . page ) < int ( self . total_pages ) :,144
4569,"def parse(cls, api, json):<tab>lst = List(api)<tab>setattr(lst, ""_json"", json)<tab>for k, v in json.items():<tab><tab>if k == ""user"":<tab><tab><tab>setattr(lst, k, User.parse(api, v))<tab><tab><IF-STMT><tab><tab><tab>setattr(lst, k, parse_datetime(v))<tab><tab>else:<tab><tab><tab>setattr(lst, k, v)<tab>return lst","elif k == ""created_at"" :",115
4570,"def real_type(self):<tab># Find the real type representation by updating it as required<tab>real_type = self.type<tab>if self.flag_indicator:<tab><tab>real_type = ""#""<tab>if self.is_vector:<tab><tab><IF-STMT><tab><tab><tab>real_type = ""Vector<{}>"".format(real_type)<tab><tab>else:<tab><tab><tab>real_type = ""vector<{}>"".format(real_type)<tab>if self.is_generic:<tab><tab>real_type = ""!{}"".format(real_type)<tab>if self.is_flag:<tab><tab>real_type = ""flags.{}?{}"".format(self.flag_index, real_type)<tab>return real_type",if self . use_vector_id :,171
4571,"def check_fs(path):<tab>with open(path, ""rb"") as f:<tab><tab>code = python_bytes_to_unicode(f.read(), errors=""replace"")<tab><tab><IF-STMT><tab><tab><tab>module = _load_module(evaluator, path, code)<tab><tab><tab>module_name = sys_path.dotted_path_in_sys_path(<tab><tab><tab><tab>evaluator.project.sys_path, path<tab><tab><tab>)<tab><tab><tab>if module_name is not None:<tab><tab><tab><tab>add_module(evaluator, module_name, module)<tab><tab><tab>return module",if name in code :,143
4572,"def infoCalendar(users):<tab>calendarId = normalizeCalendarId(sys.argv[5], checkPrimary=True)<tab>i = 0<tab>count = len(users)<tab>for user in users:<tab><tab>i += 1<tab><tab>user, cal = buildCalendarGAPIObject(user)<tab><tab>if not cal:<tab><tab><tab>continue<tab><tab>result = gapi.call(<tab><tab><tab>cal.calendarList(), ""get"", soft_errors=True, calendarId=calendarId<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>print(f""User: {user}, Calendar:{display.current_count(i, count)}"")<tab><tab><tab>_showCalendar(result, 1, 1)",if result :,163
4573,"def set_hidestate_input_sockets_to_cope_with_switchnum(self):<tab>tndict = get_indices_that_should_be_visible(self.node_state)<tab>for key, value in tndict.items():<tab><tab>socket = self.inputs[key]<tab><tab>desired_hide_state = not (value)<tab><tab><IF-STMT><tab><tab><tab>socket.hide_safe = desired_hide_state",if not socket . hide == desired_hide_state :,111
4574,"def get_class_name(item):<tab>class_name, module_name = None, None<tab>for parent in reversed(item.listchain()):<tab><tab>if isinstance(parent, pytest.Class):<tab><tab><tab>class_name = parent.name<tab><tab><IF-STMT><tab><tab><tab>module_name = parent.module.__name__<tab><tab><tab>break<tab># heuristic:<tab># - better to group gpu and task tests, since tests from those modules<tab>#   are likely to share caching more<tab># - split up the rest by class name because slow tests tend to be in<tab>#   the same module<tab>if class_name and "".tasks."" not in module_name:<tab><tab>return ""{}.{}"".format(module_name, class_name)<tab>else:<tab><tab>return module_name","elif isinstance ( parent , pytest . Module ) :",190
4575,"def run(self):<tab>versions = versioneer.get_versions()<tab>tempdir = tempfile.mkdtemp()<tab>generated = os.path.join(tempdir, ""rundemo"")<tab>with open(generated, ""wb"") as f:<tab><tab>for line in open(""src/rundemo-template"", ""rb""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.write((""versions = %r\n"" % (versions,)).encode(""ascii""))<tab><tab><tab>else:<tab><tab><tab><tab>f.write(line)<tab>self.scripts = [generated]<tab>rc = build_scripts.run(self)<tab>os.unlink(generated)<tab>os.rmdir(tempdir)<tab>return rc","if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :",172
4576,"def get_user_context(request, escape=False):<tab>if isinstance(request, HttpRequest):<tab><tab>user = getattr(request, ""user"", None)<tab><tab>result = {""ip_address"": request.META[""REMOTE_ADDR""]}<tab><tab><IF-STMT><tab><tab><tab>result.update(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""email"": user.email,<tab><tab><tab><tab><tab>""id"": user.id,<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><tab>if user.name:<tab><tab><tab><tab>result[""name""] = user.name<tab>else:<tab><tab>result = {}<tab>return mark_safe(json.dumps(result))",if user and user . is_authenticated ( ) :,163
4577,"def tokens_to_spans() -> Iterable[Tuple[str, Optional[Style]]]:<tab>""""""Convert tokens to spans.""""""<tab>tokens = iter(line_tokenize())<tab>line_no = 0<tab>_line_start = line_start - 1<tab># Skip over tokens until line start<tab>while line_no < _line_start:<tab><tab>_token_type, token = next(tokens)<tab><tab>yield (token, None)<tab><tab><IF-STMT><tab><tab><tab>line_no += 1<tab># Generate spans until line end<tab>for token_type, token in tokens:<tab><tab>yield (token, _get_theme_style(token_type))<tab><tab>if token.endswith(""\n""):<tab><tab><tab>line_no += 1<tab><tab><tab>if line_no >= line_end:<tab><tab><tab><tab>break","if token . endswith ( ""\n"" ) :",194
4578,"def encode(self, encodeFun, value, defMode, maxChunkSize):<tab>substrate, isConstructed = self.encodeValue(encodeFun, value, defMode, maxChunkSize)<tab>tagSet = value.getTagSet()<tab>if tagSet:<tab><tab><IF-STMT>  # primitive form implies definite mode<tab><tab><tab>defMode = 1<tab><tab>return (<tab><tab><tab>self.encodeTag(tagSet[-1], isConstructed)<tab><tab><tab>+ self.encodeLength(len(substrate), defMode)<tab><tab><tab>+ substrate<tab><tab><tab>+ self._encodeEndOfOctets(encodeFun, defMode)<tab><tab>)<tab>else:<tab><tab>return substrate  # untagged value",if not isConstructed :,175
4579,def _run(self):<tab>while True:<tab><tab>request = self._requests.get()<tab><tab><IF-STMT><tab><tab><tab>self.shutdown()<tab><tab><tab>break<tab><tab>self.process(request)<tab><tab>self._requests.task_done(),if request is None :,64
4580,"def _decode_payload(self, payload):<tab># we need to decrypt it<tab>if payload[""enc""] == ""aes"":<tab><tab>try:<tab><tab><tab>payload[""load""] = self.crypticle.loads(payload[""load""])<tab><tab>except salt.crypt.AuthenticationError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>payload[""load""] = self.crypticle.loads(payload[""load""])<tab>return payload",if not self . _update_aes ( ) :,107
4581,"def test_row(self, row):<tab>for idx, test in self.patterns.items():<tab><tab>try:<tab><tab><tab>value = row[idx]<tab><tab>except IndexError:<tab><tab><tab>value = """"<tab><tab>result = test(value)<tab><tab>if self.any_match:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return not self.inverse  # True<tab><tab>else:<tab><tab><tab>if not result:<tab><tab><tab><tab>return self.inverse  # False<tab>if self.any_match:<tab><tab>return self.inverse  # False<tab>else:<tab><tab>return not self.inverse  # True",if result :,149
4582,"def setup_parameter_node(self, param_node):<tab>if param_node.bl_idname == ""SvNumberNode"":<tab><tab>if self.use_prop or self.get_prop_name():<tab><tab><tab>value = self.sv_get()[0][0]<tab><tab><tab>print(""V"", value)<tab><tab><tab>if isinstance(value, int):<tab><tab><tab><tab>param_node.selected_mode = ""int""<tab><tab><tab><tab>param_node.int_ = value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>param_node.selected_mode = ""float""<tab><tab><tab><tab>param_node.float_ = value","elif isinstance ( value , float ) :",156
4583,"def iter_modules(self, by_clients=False, clients_filter=None):<tab>""""""iterate over all modules""""""<tab>clients = None<tab>if by_clients:<tab><tab>clients = self.get_clients(clients_filter)<tab><tab>if not clients:<tab><tab><tab>return<tab>self._refresh_modules()<tab>for module_name in self.modules:<tab><tab>try:<tab><tab><tab>module = self.get_module(module_name)<tab><tab>except PupyModuleDisabled:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>for client in clients:<tab><tab><tab><tab>if module.is_compatible_with(client):<tab><tab><tab><tab><tab>yield module<tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield module",if clients is not None :,181
4584,"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None):<tab>filtered_pricing_rules = []<tab>if doc:<tab><tab>for pricing_rule in pricing_rules:<tab><tab><tab>if pricing_rule.condition:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab>else:<tab><tab>filtered_pricing_rules = pricing_rules<tab>return filtered_pricing_rules","if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :",179
4585,"def build_query_string(kv_data, ignore_none=True):<tab># {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test""<tab>query_string = """"<tab>for k, v in kv_data.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if query_string != """":<tab><tab><tab>query_string += ""&""<tab><tab>else:<tab><tab><tab>query_string = ""?""<tab><tab>query_string += k + ""="" + str(v)<tab>return query_string",if ignore_none is True and kv_data [ k ] is None :,140
4586,"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = {}<tab>ret.update(self.data)<tab>kwspaces = self.kwspaces<tab>kwspaces.update(config)<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for k, v in kwspaces.items():<tab><tab>if k in striped_keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub_config = _strip_config_space(config, prefix=k)<tab><tab><tab><tab>ret[k] = v.sample(**sub_config)<tab><tab><tab>else:<tab><tab><tab><tab>ret[k] = v<tab>return ret","if isinstance ( v , NestedSpace ) :",172
4587,"def task_failed(self, task_id, hostname, reason):<tab>logger.debug(""task %d failed with message %s"", task_id, str(reason))<tab>if hostname in self.host_dict:<tab><tab>host_status = self.host_dict[hostname]<tab><tab>host_status.task_failed(task_id)<tab><tab><IF-STMT><tab><tab><tab>self.task_host_failed_dict[task_id] = set()<tab><tab>self.task_host_failed_dict[task_id].add(hostname)",if task_id not in self . task_host_failed_dict :,141
4588,"def match(path):<tab>for pat, _type, _property, default_title in patterns:<tab><tab>m = web.re_compile(""^"" + pat).match(path)<tab><tab><IF-STMT><tab><tab><tab>prefix = m.group()<tab><tab><tab>extra = web.lstrips(path, prefix)<tab><tab><tab>tokens = extra.split(""/"", 2)<tab><tab><tab># `extra` starts with ""/"". So first token is always empty.<tab><tab><tab>middle = web.listget(tokens, 1, """")<tab><tab><tab>suffix = web.listget(tokens, 2, """")<tab><tab><tab>if suffix:<tab><tab><tab><tab>suffix = ""/"" + suffix<tab><tab><tab>return _type, _property, default_title, prefix, middle, suffix<tab>return None, None, None, None, None, None",if m :,187
4589,"def _get_cached_resources(self, ids):<tab>key = self.get_cache_key(None)<tab>if self._cache.load():<tab><tab>resources = self._cache.get(key)<tab><tab><IF-STMT><tab><tab><tab>self.log.debug(""Using cached results for get_resources"")<tab><tab><tab>m = self.get_model()<tab><tab><tab>id_set = set(ids)<tab><tab><tab>return [r for r in resources if r[m.id] in id_set]<tab>return None",if resources is not None :,127
4590,"def has_api_behaviour(self, protocol):<tab>config = get_config()<tab>try:<tab><tab>r = self.session.get(<tab><tab><tab>f""{protocol}://{self.event.host}:{self.event.port}"",<tab><tab><tab>timeout=config.network_timeout,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>except requests.exceptions.SSLError:<tab><tab>logger.debug(<tab><tab><tab>f""{[protocol]} protocol not accepted on {self.event.host}:{self.event.port}""<tab><tab>)<tab>except Exception:<tab><tab>logger.debug(<tab><tab><tab>f""Failed probing {self.event.host}:{self.event.port}"", exc_info=True<tab><tab>)","if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :",200
4591,"def get_file_type(self, context, parent_context=None):<tab>file_type = context.get(self.file_type_name, None)<tab>if file_type == """":<tab><tab><IF-STMT><tab><tab><tab>file_type = parent_context.get(self.file_type_name, self.default_file_type)<tab><tab>else:<tab><tab><tab>file_type = self.default_file_type<tab>return file_type",if parent_context :,110
4592,"def selectionToChunks(self, remove=False, add=False):<tab>box = self.selectionBox()<tab>if box:<tab><tab>if box == self.level.bounds:<tab><tab><tab>self.selectedChunks = set(self.level.allChunks)<tab><tab><tab>return<tab><tab>selectedChunks = self.selectedChunks<tab><tab>boxedChunks = set(box.chunkPositions)<tab><tab><IF-STMT><tab><tab><tab>remove = True<tab><tab>if remove and not add:<tab><tab><tab>selectedChunks.difference_update(boxedChunks)<tab><tab>else:<tab><tab><tab>selectedChunks.update(boxedChunks)<tab>self.selectionTool.selectNone()",if boxedChunks . issubset ( selectedChunks ) :,158
4593,"def _run_split_on_punc(self, text, never_split=None):<tab>""""""Splits punctuation on a piece of text.""""""<tab>if never_split is not None and text in never_split:<tab><tab>return [text]<tab>chars = list(text)<tab>i = 0<tab>start_new_word = True<tab>output = []<tab>while i < len(chars):<tab><tab>char = chars[i]<tab><tab><IF-STMT><tab><tab><tab>output.append([char])<tab><tab><tab>start_new_word = True<tab><tab>else:<tab><tab><tab>if start_new_word:<tab><tab><tab><tab>output.append([])<tab><tab><tab>start_new_word = False<tab><tab><tab>output[-1].append(char)<tab><tab>i += 1<tab>return ["""".join(x) for x in output]",if _is_punctuation ( char ) :,199
4594,"def _save_images(notebook):<tab>if os.getenv(""NB_NO_IMAGES"") == ""1"":<tab><tab>return<tab>logged = False<tab>for filename, img_bytes in _iter_notebook_images(notebook):<tab><tab><IF-STMT><tab><tab><tab>log.info(""Saving images"")<tab><tab><tab>logged = True<tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab>f.write(img_bytes)",if not logged :,104
4595,"def pickPath(self, color):<tab>self.path[color] = ()<tab>currentPos = self.starts[color]<tab>while True:<tab><tab>minDist = None<tab><tab>minGuide = None<tab><tab>for guide in self.guides[color]:<tab><tab><tab>guideDist = dist(currentPos, guide)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>minDist = guideDist<tab><tab><tab><tab>minGuide = guide<tab><tab>if dist(currentPos, self.ends[color]) == 1:<tab><tab><tab>return<tab><tab>if minGuide == None:<tab><tab><tab>return<tab><tab>self.path[color] = self.path[color] + (minGuide,)<tab><tab>currentPos = minGuide<tab><tab>self.guides[color].remove(minGuide)",if minDist == None or guideDist < minDist :,192
4596,"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>out.write(msg)<tab><tab>elif tp == ""flush"":<tab><tab><tab>out.flush()<tab><tab>elif tp == ""write_flush"":<tab><tab><tab>out.write(msg)<tab><tab><tab>out.flush()<tab><tab>elif tp == ""print"":<tab><tab><tab>print(msg, file=out)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported type: "" + tp)<tab>except IOError as e:<tab><tab>logger.critical(""{}: {}"".format(type(e).__name__, ucd(e)))<tab><tab>pass","if tp == ""write"" :",160
4597,"def __new__(mcs, name, bases, attrs):<tab>include_profile = include_trace = include_garbage = True<tab>bases = list(bases)<tab>if name == ""SaltLoggingClass"":<tab><tab>for base in bases:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>include_trace = False<tab><tab><tab>if hasattr(base, ""garbage""):<tab><tab><tab><tab>include_garbage = False<tab>if include_profile:<tab><tab>bases.append(LoggingProfileMixin)<tab>if include_trace:<tab><tab>bases.append(LoggingTraceMixin)<tab>if include_garbage:<tab><tab>bases.append(LoggingGarbageMixin)<tab>return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)","if hasattr ( base , ""trace"" ) :",176
4598,"def generatePidEncryptionTable():<tab>table = []<tab>for counter1 in range(0, 0x100):<tab><tab>value = counter1<tab><tab>for counter2 in range(0, 8):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value >> 1<tab><tab><tab>else:<tab><tab><tab><tab>value = value >> 1<tab><tab><tab><tab>value = value ^ 0xEDB88320<tab><tab>table.append(value)<tab>return table",if value & 1 == 0 :,109
4599,"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/params""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab>if ""init"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))","if ""stage"" not in item . keywords :",102
4600,"def python_value(self, value):<tab>if value:<tab><tab>if isinstance(value, basestring):<tab><tab><tab>pp = lambda x: x.time()<tab><tab><tab>return format_date_time(value, self.formats, pp)<tab><tab><IF-STMT><tab><tab><tab>return value.time()<tab>if value is not None and isinstance(value, datetime.timedelta):<tab><tab>return (datetime.datetime.min + value).time()<tab>return value","elif isinstance ( value , datetime . datetime ) :",113
4601,"def list_interesting_hosts(self):<tab>hosts = []<tab>targets = self.target[""other""]<tab>for target in targets:<tab><tab><IF-STMT><tab><tab><tab>hosts.append(<tab><tab><tab><tab>{""ip"": target.ip, ""description"": target.domain + "" / "" + target.name}<tab><tab><tab>)<tab>return hosts",if self . is_interesting ( target ) and target . status and target . status != 400 :,99
4602,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_cost().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.add_version(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 24 :,167
4603,"def _wait_for_finish(self) -> PollExitResponse:<tab>while True:<tab><tab>if self._backend:<tab><tab><tab>poll_exit_resp = self._backend.interface.communicate_poll_exit()<tab><tab>logger.info(""got exit ret: %s"", poll_exit_resp)<tab><tab>if poll_exit_resp:<tab><tab><tab>done = poll_exit_resp.done<tab><tab><tab>pusher_stats = poll_exit_resp.pusher_stats<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._on_finish_progress(pusher_stats, done)<tab><tab><tab>if done:<tab><tab><tab><tab>return poll_exit_resp<tab><tab>time.sleep(2)",if pusher_stats :,170
4604,"def listing_items(method):<tab>marker = None<tab>once = True<tab>items = []<tab>while once or items:<tab><tab>for i in items:<tab><tab><tab>yield i<tab><tab>if once or marker:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>items = method(parms={""marker"": marker})<tab><tab><tab>else:<tab><tab><tab><tab>items = method()<tab><tab><tab>if len(items) == 10000:<tab><tab><tab><tab>marker = items[-1]<tab><tab><tab>else:<tab><tab><tab><tab>marker = None<tab><tab><tab>once = False<tab><tab>else:<tab><tab><tab>items = []",if marker :,145
4605,"def call(monad, *args):<tab>for arg, name in izip(args, (""hour"", ""minute"", ""second"", ""microsecond"")):<tab><tab>if not isinstance(arg, NumericMixin) or arg.type is not int:<tab><tab><tab>throw(<tab><tab><tab><tab>TypeError,<tab><tab><tab><tab>""'%s' argument of time(...) function must be of 'int' type. Got: %r""<tab><tab><tab><tab>% (name, type2str(arg.type)),<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>throw(NotImplementedError)<tab>return ConstMonad.new(time(*tuple(arg.value for arg in args)))","if not isinstance ( arg , ConstMonad ) :",157
4606,"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x):<tab>sign = None<tab>subseq = []<tab>for i in seq:<tab><tab>ki = key(i)<tab><tab>if sign is None:<tab><tab><tab>subseq.append(i)<tab><tab><tab>if ki != 0:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab>else:<tab><tab><tab>subseq.append(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab><tab><tab>yield subseq<tab><tab><tab><tab>subseq = [i]<tab>if subseq:<tab><tab>yield subseq",if sign * ki < - slop :,167
4607,"def walk_links(self):<tab>link_info_list = []<tab>for item in self.content:<tab><tab><IF-STMT><tab><tab><tab>link_info = LinkInfo(link=item, name=item.name, sections=())<tab><tab><tab>link_info_list.append(link_info)<tab><tab>else:<tab><tab><tab>link_info_list.extend(item.walk_links())<tab>return link_info_list","if isinstance ( item , Link ) :",106
4608,"def get_subkeys(self, key):<tab># TODO: once we revamp the registry emulation,<tab># make this better<tab>parent_path = key.get_path()<tab>subkeys = []<tab>for k in self.keys:<tab><tab>test_path = k.get_path()<tab><tab>if test_path.lower().startswith(parent_path.lower()):<tab><tab><tab>sub = test_path[len(parent_path) :]<tab><tab><tab>if sub.startswith(""\\""):<tab><tab><tab><tab>sub = sub[1:]<tab><tab><tab>end_slash = sub.find(""\\"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub = sub[:end_slash]<tab><tab><tab>if not sub:<tab><tab><tab><tab>continue<tab><tab><tab>subkeys.append(sub)<tab>return subkeys",if end_slash >= 0 :,192
4609,"def load_dict(dict_path, reverse=False):<tab>word_dict = {}<tab>with open(dict_path, ""rb"") as fdict:<tab><tab>for idx, line in enumerate(fdict):<tab><tab><tab>line = cpt.to_text(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>word_dict[idx] = line.strip(""\n"")<tab><tab><tab>else:<tab><tab><tab><tab>word_dict[line.strip(""\n"")] = idx<tab>return word_dict",if reverse :,118
4610,"def test_network(coords, feats, model, batch_sizes, forward_only=True):<tab>for batch_size in batch_sizes:<tab><tab>bcoords = batched_coordinates([coords for i in range(batch_size)])<tab><tab>bfeats = torch.cat([feats for i in range(batch_size)], 0)<tab><tab><IF-STMT><tab><tab><tab>with torch.no_grad():<tab><tab><tab><tab>time, length = forward(bcoords, bfeats, model)<tab><tab>else:<tab><tab><tab>time, length = train(bcoords, bfeats, model)<tab><tab>print(f""{net.__name__}\t{voxel_size}\t{batch_size}\t{length}\t{time}"")<tab><tab>torch.cuda.empty_cache()",if forward_only :,181
4611,"def markUVs(self, indices=None):<tab>if isinstance(indices, tuple):<tab><tab>indices = indices[0]<tab>ntexco = len(self.texco)<tab>if indices is None:<tab><tab>self.utexc = True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.utexc = np.zeros(ntexco, dtype=bool)<tab><tab>if self.utexc is not True:<tab><tab><tab>self.utexc[indices] = True",if self . utexc is False :,120
4612,"def has_module(self, module, version):<tab>has_module = False<tab>for directory in self.directories:<tab><tab>module_directory = join(directory, module)<tab><tab>has_module_directory = isdir(module_directory)<tab><tab><IF-STMT><tab><tab><tab>has_module = has_module_directory or exists(<tab><tab><tab><tab>module_directory<tab><tab><tab>)  # could be a bare modulefile<tab><tab>else:<tab><tab><tab>modulefile = join(module_directory, version)<tab><tab><tab>has_modulefile = exists(modulefile)<tab><tab><tab>has_module = has_module_directory and has_modulefile<tab><tab>if has_module:<tab><tab><tab>break<tab>return has_module",if not version :,171
4613,"def get_editops(self):<tab>if not self._editops:<tab><tab><IF-STMT><tab><tab><tab>self._editops = editops(self._opcodes, self._str1, self._str2)<tab><tab>else:<tab><tab><tab>self._editops = editops(self._str1, self._str2)<tab>return self._editops",if self . _opcodes :,86
4614,"def to_representation(self, data):<tab>value = super(CredentialTypeSerializer, self).to_representation(data)<tab># translate labels and help_text for credential fields ""managed by Tower""<tab>if value.get(""managed_by_tower""):<tab><tab>value[""name""] = _(value[""name""])<tab><tab>for field in value.get(""inputs"", {}).get(""fields"", []):<tab><tab><tab>field[""label""] = _(field[""label""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>field[""help_text""] = _(field[""help_text""])<tab>return value","if ""help_text"" in field :",140
4615,"def sort_nested_dictionary_lists(d):<tab>for k, v in d.items():<tab><tab>if isinstance(v, list):<tab><tab><tab>for i in range(0, len(v)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>v[i] = await sort_nested_dictionary_lists(v[i])<tab><tab><tab><tab>d[k] = sorted(v)<tab><tab>if isinstance(v, dict):<tab><tab><tab>d[k] = await sort_nested_dictionary_lists(v)<tab>return d","if isinstance ( v [ i ] , dict ) :",134
4616,"def messageSourceStamps(self, source_stamps):<tab>text = """"<tab>for ss in source_stamps:<tab><tab>source = """"<tab><tab>if ss[""branch""]:<tab><tab><tab>source += ""[branch %s] "" % ss[""branch""]<tab><tab>if ss[""revision""]:<tab><tab><tab>source += str(ss[""revision""])<tab><tab>else:<tab><tab><tab>source += ""HEAD""<tab><tab><IF-STMT><tab><tab><tab>source += "" (plus patch)""<tab><tab>discriminator = """"<tab><tab>if ss[""codebase""]:<tab><tab><tab>discriminator = "" '%s'"" % ss[""codebase""]<tab><tab>text += ""Build Source Stamp%s: %s\n"" % (discriminator, source)<tab>return text","if ss [ ""patch"" ] is not None :",176
4617,"def fit_one(self, x):<tab>for i, xi in x.items():<tab><tab><IF-STMT><tab><tab><tab>self.median[i].update(xi)<tab><tab>if self.with_scaling:<tab><tab><tab>self.iqr[i].update(xi)<tab>return self",if self . with_centering :,75
4618,"def start_response(self, status, headers, exc_info=None):<tab>if exc_info:<tab><tab>try:<tab><tab><tab>if self.started:<tab><tab><tab><tab>six.reraise(exc_info[0], exc_info[1], exc_info[2])<tab><tab>finally:<tab><tab><tab>exc_info = None<tab>self.request.status = int(status[:3])<tab>for key, val in headers:<tab><tab><IF-STMT><tab><tab><tab>self.request.set_content_length(int(val))<tab><tab>elif key.lower() == ""content-type"":<tab><tab><tab>self.request.content_type = val<tab><tab>else:<tab><tab><tab>self.request.headers_out.add(key, val)<tab>return self.write","if key . lower ( ) == ""content-length"" :",191
4619,"def _osp2ec(self, bytes):<tab>compressed = self._from_bytes(bytes)<tab>y = compressed >> self._bits<tab>x = compressed & (1 << self._bits) - 1<tab>if x == 0:<tab><tab>y = self._curve.b<tab>else:<tab><tab>result = self.sqrtp(<tab><tab><tab>x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p<tab><tab>)<tab><tab>if len(result) == 1:<tab><tab><tab>y = result[0]<tab><tab><IF-STMT><tab><tab><tab>y1, y2 = result<tab><tab><tab>y = y1 if (y1 & 1 == y) else y2<tab><tab>else:<tab><tab><tab>return None<tab>return ec.Point(self._curve, x, y)",elif len ( result ) == 2 :,200
4620,"def trace(self, ee, rname):<tab>print(type(self))<tab>self.traceIndent()<tab>guess = """"<tab>if self.inputState.guessing > 0:<tab><tab>guess = "" [guessing]""<tab>print((ee + rname + guess))<tab>for i in xrange(1, self.k + 1):<tab><tab>if i != 1:<tab><tab><tab>print("", "")<tab><tab><IF-STMT><tab><tab><tab>v = self.LT(i).getText()<tab><tab>else:<tab><tab><tab>v = ""null""<tab><tab>print(""LA(%s) == %s"" % (i, v))<tab>print(""\n"")",if self . LT ( i ) :,158
4621,"def _table_schema(self, table):<tab>rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall()<tab># Build list of fields from table information<tab>result = {}<tab>for _, name, data_type, not_null, _, primary_key in rows:<tab><tab>parts = [data_type]<tab><tab>if primary_key:<tab><tab><tab>parts.append(""PRIMARY KEY"")<tab><tab><IF-STMT><tab><tab><tab>parts.append(""NOT NULL"")<tab><tab>result[name] = "" "".join(parts)<tab>return result",if not_null :,137
4622,"def _parse_csrf(self, response):<tab>for d in response:<tab><tab>if d.startswith(""Set-Cookie:""):<tab><tab><tab>for c in d.split("":"", 1)[1].split("";""):<tab><tab><tab><tab>if c.strip().startswith(""CSRF-Token-""):<tab><tab><tab><tab><tab>self._CSRFtoken = c.strip("" \r\n"")<tab><tab><tab><tab><tab>log.verbose(""Got new cookie: %s"", self._CSRFtoken)<tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break",if self . _CSRFtoken != None :,135
4623,"def _update_from_item(self, row, download_item):<tab>progress_stats = download_item.progress_stats<tab>for key in self.columns:<tab><tab>column = self.columns[key][0]<tab><tab><IF-STMT><tab><tab><tab># Not the best place but we build the playlist status here<tab><tab><tab>status = ""{0} {1}/{2}"".format(<tab><tab><tab><tab>progress_stats[""status""],<tab><tab><tab><tab>progress_stats[""playlist_index""],<tab><tab><tab><tab>progress_stats[""playlist_size""],<tab><tab><tab>)<tab><tab><tab>self.SetStringItem(row, column, status)<tab><tab>else:<tab><tab><tab>self.SetStringItem(row, column, progress_stats[key])","if key == ""status"" and progress_stats [ ""playlist_index"" ] :",183
4624,"def unmarshal_package_repositories(cls, data: Any) -> List[""PackageRepository""]:<tab>repositories = list()<tab>if data is not None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(f""invalid package-repositories: {data!r}"")<tab><tab>for repository in data:<tab><tab><tab>package_repo = cls.unmarshal(repository)<tab><tab><tab>repositories.append(package_repo)<tab>return repositories","if not isinstance ( data , list ) :",114
4625,"def remove_message(e=None):<tab>itop = scanbox.nearest(0)<tab>sel = scanbox.curselection()<tab>if not sel:<tab><tab>dialog(<tab><tab><tab>root,<tab><tab><tab>""No Message To Remove"",<tab><tab><tab>""Please select a message to remove"",<tab><tab><tab>"""",<tab><tab><tab>0,<tab><tab><tab>""OK"",<tab><tab>)<tab><tab>return<tab>todo = []<tab>for i in sel:<tab><tab>line = scanbox.get(i)<tab><tab><IF-STMT><tab><tab><tab>todo.append(string.atoi(scanparser.group(1)))<tab>mhf.removemessages(todo)<tab>rescan()<tab>fixfocus(min(todo), itop)",if scanparser . match ( line ) >= 0 :,182
4626,"def test_patches():<tab>print(<tab><tab>""Botocore version: {} aiohttp version: {}"".format(<tab><tab><tab>botocore.__version__, aiohttp.__version__<tab><tab>)<tab>)<tab>success = True<tab>for obj, digests in chain(_AIOHTTP_DIGESTS.items(), _API_DIGESTS.items()):<tab><tab>digest = hashlib.sha1(getsource(obj).encode(""utf-8"")).hexdigest()<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""Digest of {}:{} not found in: {}"".format(<tab><tab><tab><tab><tab>obj.__qualname__, digest, digests<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>success = False<tab>assert success",if digest not in digests :,167
4627,"def sample_admin_user():<tab>""""""List of iris messages""""""<tab>with iris_ctl.db_from_config(sample_db_config) as (conn, cursor):<tab><tab>cursor.execute(<tab><tab><tab>""SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1""<tab><tab>)<tab><tab>result = cursor.fetchone()<tab><tab><IF-STMT><tab><tab><tab>return result[0]",if result :,123
4628,"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True):<tab>if leftname in kerning:<tab><tab>for rightname in kerning[leftname]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for rightname2 in groups[rightname]:<tab><tab><tab><tab><tab>rightnames.add(rightname2)<tab><tab><tab><tab><tab>if not includeAll:<tab><tab><tab><tab><tab><tab># TODO: in this case, pick the one rightname that has the highest<tab><tab><tab><tab><tab><tab># ranking in glyphorder<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>rightnames.add(rightname)","if rightname [ 0 ] == ""@"" :",161
4629,"def build(self, input_shape):<tab>if isinstance(input_shape, list) and len(input_shape) == 2:<tab><tab>self.data_mode = ""disjoint""<tab><tab>self.F = input_shape[0][-1]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.data_mode = ""single""<tab><tab>else:<tab><tab><tab>self.data_mode = ""batch""<tab><tab>self.F = input_shape[-1]",if len ( input_shape ) == 2 :,120
4630,"def update_ranges(l, i):<tab>for _range in l:<tab><tab># most common case: extend a range<tab><tab><IF-STMT><tab><tab><tab>_range[0] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab><tab>elif i == _range[1] + 1:<tab><tab><tab>_range[1] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab># somewhere outside of range proximity<tab>l.append([i, i])<tab>l.sort(key=lambda x: x[0])",if i == _range [ 0 ] - 1 :,145
4631,"def transform(a, cmds):<tab>buf = a.split(""\n"")<tab>for cmd in cmds:<tab><tab>ctype, line, col, char = cmd<tab><tab><IF-STMT><tab><tab><tab>if char != ""\n"":<tab><tab><tab><tab>buf[line] = buf[line][:col] + buf[line][col + len(char) :]<tab><tab><tab>else:<tab><tab><tab><tab>buf[line] = buf[line] + buf[line + 1]<tab><tab><tab><tab>del buf[line + 1]<tab><tab>elif ctype == ""I"":<tab><tab><tab>buf[line] = buf[line][:col] + char + buf[line][col:]<tab><tab>buf = ""\n"".join(buf).split(""\n"")<tab>return ""\n"".join(buf)","if ctype == ""D"" :",182
4632,"def _media_files_drag_received(widget, context, x, y, data, info, timestamp):<tab>uris = data.get_uris()<tab>files = []<tab>for uri in uris:<tab><tab>try:<tab><tab><tab>uri_tuple = GLib.filename_from_uri(uri)<tab><tab>except:<tab><tab><tab>continue<tab><tab>uri, unused = uri_tuple<tab><tab>if os.path.exists(uri) == True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>files.append(uri)<tab>if len(files) == 0:<tab><tab>return<tab>open_dropped_files(files)",if utils . is_media_file ( uri ) == True :,159
4633,"def __walk_proceed_remote_dir_act(self, r, args):<tab>dirjs, filejs = args<tab>j = r.json()<tab>if ""list"" not in j:<tab><tab>self.pd(<tab><tab><tab>""Key 'list' not found in the response of directory listing request:\n{}"".format(<tab><tab><tab><tab>j<tab><tab><tab>)<tab><tab>)<tab><tab>return const.ERequestFailed<tab>paths = j[""list""]<tab>for path in paths:<tab><tab><IF-STMT><tab><tab><tab>dirjs.append(path)<tab><tab>else:<tab><tab><tab>filejs.append(path)<tab>return const.ENoError","if path [ ""isdir"" ] :",159
4634,"def TaskUpdatesVerbose(task, progress):<tab>if isinstance(task.info.progress, int):<tab><tab>info = task.info<tab><tab><IF-STMT><tab><tab><tab>progress = ""%d%% (%s)"" % (info.progress, info.state)<tab><tab>print(<tab><tab><tab>""Task %s (key:%s, desc:%s) - %s""<tab><tab><tab>% (info.name.info.name, info.key, info.description, progress)<tab><tab>)","if not isinstance ( progress , str ) :",118
4635,"def dump_constants(header):<tab>output = StringIO.StringIO()<tab>output.write(header)<tab>for attribute in dir(FSEvents):<tab><tab>value = getattr(FSEvents, attribute)<tab><tab><IF-STMT><tab><tab><tab>output.write(""<tab>%s = %s\n"" % (attribute, hex(value)))<tab>content = output.getvalue()<tab>output.close()<tab>return content","if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :",112
4636,"def _ensure_data_is_loaded(<tab>self,<tab>sql_object,<tab>input_params,<tab>stdin_file,<tab>stdin_filename=""-"",<tab>stop_after_analysis=False,):<tab>data_loads = []<tab># Get each ""table name"" which is actually the file name<tab>for filename in sql_object.qtable_names:<tab><tab>data_load = self._load_data(<tab><tab><tab>filename,<tab><tab><tab>input_params,<tab><tab><tab>stdin_file=stdin_file,<tab><tab><tab>stdin_filename=stdin_filename,<tab><tab><tab>stop_after_analysis=stop_after_analysis,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>data_loads.append(data_load)<tab>return data_loads",if data_load is not None :,189
4637,"def _get_instantiation(self):<tab>if self._data is None:<tab><tab>f, l, c, o = c_object_p(), c_uint(), c_uint(), c_uint()<tab><tab>SourceLocation_loc(self, byref(f), byref(l), byref(c), byref(o))<tab><tab><IF-STMT><tab><tab><tab>f = File(f)<tab><tab>else:<tab><tab><tab>f = None<tab><tab>self._data = (f, int(l.value), int(c.value), int(c.value))<tab>return self._data",if f :,136
4638,"def _get_all_info_lines(data):<tab>infos = []<tab>for row in data:<tab><tab>splitrow = row.split()<tab><tab><IF-STMT><tab><tab><tab>if splitrow[0] == ""INFO:"":<tab><tab><tab><tab>infos.append("" "".join(splitrow[1:]))<tab>return infos",if len ( splitrow ) > 0 :,82
4639,"def _brush_modified_cb(self, settings):<tab>""""""Updates the brush's base setting adjustments on brush changes""""""<tab>for cname in settings:<tab><tab>adj = self.brush_adjustment.get(cname, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = self.brush.get_base_value(cname)<tab><tab>adj.set_value(value)",if adj is None :,92
4640,"def migrate_node_facts(facts):<tab>""""""Migrate facts from various roles into node""""""<tab>params = {<tab><tab>""common"": (""dns_ip""),<tab>}<tab>if ""node"" not in facts:<tab><tab>facts[""node""] = {}<tab># pylint: disable=consider-iterating-dictionary<tab>for role in params.keys():<tab><tab>if role in facts:<tab><tab><tab>for param in params[role]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>facts[""node""][param] = facts[role].pop(param)<tab>return facts",if param in facts [ role ] :,136
4641,"def serialize_content_range(value):<tab>if isinstance(value, (tuple, list)):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""When setting content_range to a list/tuple, it must ""<tab><tab><tab><tab>""be length 2 or 3 (not %r)"" % value<tab><tab><tab>)<tab><tab>if len(value) == 2:<tab><tab><tab>begin, end = value<tab><tab><tab>length = None<tab><tab>else:<tab><tab><tab>begin, end, length = value<tab><tab>value = ContentRange(begin, end, length)<tab>value = str(value).strip()<tab>if not value:<tab><tab>return None<tab>return value","if len ( value ) not in ( 2 , 3 ) :",169
4642,"def clean(self):<tab>data = super().clean()<tab>if data.get(""expires""):<tab><tab><IF-STMT><tab><tab><tab>data[""expires""] = make_aware(<tab><tab><tab><tab>datetime.combine(data[""expires""], time(hour=23, minute=59, second=59)),<tab><tab><tab><tab>self.instance.event.timezone,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>data[""expires""] = data[""expires""].replace(hour=23, minute=59, second=59)<tab><tab>if data[""expires""] < now():<tab><tab><tab>raise ValidationError(_(""The new expiry date needs to be in the future.""))<tab>return data","if isinstance ( data [ ""expires"" ] , date ) :",158
4643,"def _build(self, obj, stream, context):<tab>if self.include_name:<tab><tab>name, obj = obj<tab><tab>for sc in self.subcons:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sc._build(obj, stream, context)<tab><tab><tab><tab>return<tab>else:<tab><tab>for sc in self.subcons:<tab><tab><tab>stream2 = BytesIO()<tab><tab><tab>context2 = context.__copy__()<tab><tab><tab>try:<tab><tab><tab><tab>sc._build(obj, stream2, context2)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>context.__update__(context2)<tab><tab><tab><tab>stream.write(stream2.getvalue())<tab><tab><tab><tab>return<tab>raise SelectError(""no subconstruct matched"", obj)",if sc . name == name :,195
4644,"def records(account_id):<tab>""""""Fetch locks data""""""<tab>s = boto3.Session()<tab>table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"")<tab>results = table.scan()<tab>for r in results[""Items""]:<tab><tab><IF-STMT><tab><tab><tab>r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""])<tab><tab>if ""RevisionDate"" in r:<tab><tab><tab>r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""])<tab>print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))","if ""LockDate"" in r :",149
4645,"def visitIf(self, node, scope):<tab>for test, body in node.tests:<tab><tab>if isinstance(test, ast.Const):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not test.value:<tab><tab><tab><tab><tab>continue<tab><tab>self.visit(test, scope)<tab><tab>self.visit(body, scope)<tab>if node.else_:<tab><tab>self.visit(node.else_, scope)",if type ( test . value ) in self . _const_types :,112
4646,"def validate_max_discount(self):<tab>if self.rate_or_discount == ""Discount Percentage"" and self.get(""items""):<tab><tab>for d in self.items:<tab><tab><tab>max_discount = frappe.get_cached_value(""Item"", d.item_code, ""max_discount"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>throw(<tab><tab><tab><tab><tab>_(""Max discount allowed for item: {0} is {1}%"").format(<tab><tab><tab><tab><tab><tab>self.item_code, max_discount<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,158
4647,"def has_invalid_cce(yaml_file, product_yaml=None):<tab>rule = yaml.open_and_macro_expand(yaml_file, product_yaml)<tab>if ""identifiers"" in rule and rule[""identifiers""] is not None:<tab><tab>for i_type, i_value in rule[""identifiers""].items():<tab><tab><tab>if i_type[0:3] == ""cce"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>return False","if not checks . is_cce_value_valid ( ""CCE-"" + str ( i_value ) ) :",134
4648,"def parse_calendar_eras(data, calendar):<tab>eras = data.setdefault(""eras"", {})<tab>for width in calendar.findall(""eras/*""):<tab><tab>width_type = NAME_MAP[width.tag]<tab><tab>widths = eras.setdefault(width_type, {})<tab><tab>for elem in width.getiterator():<tab><tab><tab>if elem.tag == ""era"":<tab><tab><tab><tab>_import_type_text(widths, elem, type=int(elem.attrib.get(""type"")))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>eras[width_type] = Alias(<tab><tab><tab><tab><tab>_translate_alias([""eras"", width_type], elem.attrib[""path""])<tab><tab><tab><tab>)","elif elem . tag == ""alias"" :",170
4649,"def validate_grammar() -> None:<tab>for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE:<tab><tab>fn_productions = get_productions(fn)<tab><tab>if all(p.name == fn_productions[0].name for p in fn_productions):<tab><tab><tab># all the production names are the same, ensure that the `convert_` function<tab><tab><tab># is named correctly<tab><tab><tab>production_name = fn_productions[0].name<tab><tab><tab>expected_name = f""convert_{production_name}""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>f""The conversion function for '{production_name}' ""<tab><tab><tab><tab><tab>+ f""must be called '{expected_name}', not '{fn.__name__}'.""<tab><tab><tab><tab>)",if fn . __name__ != expected_name :,189
4650,"def split_ratio(row):<tab>if float(row[""Numerator""]) > 0:<tab><tab><IF-STMT><tab><tab><tab>n, m = row[""Splitratio""].split("":"")<tab><tab><tab>return float(m) / float(n)<tab><tab>else:<tab><tab><tab>return eval(row[""Splitratio""])<tab>else:<tab><tab>return 1","if "":"" in row [ ""Splitratio"" ] :",87
4651,"def _handle_def_errors(testdef):<tab># If the test generation had an error, raise<tab>if testdef.error:<tab><tab>if testdef.exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise testdef.exception<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(testdef.exception)<tab><tab>else:<tab><tab><tab>raise Exception(""Test parse failure"")","if isinstance ( testdef . exception , Exception ) :",100
4652,"def _get_quota_availability(self):<tab>quotas_ok = defaultdict(int)<tab>qa = QuotaAvailability()<tab>qa.queue(*[k for k, v in self._quota_diff.items() if v > 0])<tab>qa.compute(now_dt=self.now_dt)<tab>for quota, count in self._quota_diff.items():<tab><tab>if count <= 0:<tab><tab><tab>quotas_ok[quota] = 0<tab><tab><tab>break<tab><tab>avail = qa.results[quota]<tab><tab><IF-STMT><tab><tab><tab>quotas_ok[quota] = min(count, avail[1])<tab><tab>else:<tab><tab><tab>quotas_ok[quota] = count<tab>return quotas_ok",if avail [ 1 ] is not None and avail [ 1 ] < count :,182
4653,"def reverse(self):<tab>""""""Reverse *IN PLACE*.""""""<tab>li = self.leftindex<tab>lb = self.leftblock<tab>ri = self.rightindex<tab>rb = self.rightblock<tab>for i in range(self.len >> 1):<tab><tab>lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li]<tab><tab>li += 1<tab><tab><IF-STMT><tab><tab><tab>lb = lb.rightlink<tab><tab><tab>li = 0<tab><tab>ri -= 1<tab><tab>if ri < 0:<tab><tab><tab>rb = rb.leftlink<tab><tab><tab>ri = BLOCKLEN - 1",if li >= BLOCKLEN :,156
4654,"def __manipulate_item(self, item):<tab>if self._Cursor__manipulate:<tab><tab>db = self._Cursor__collection.database<tab><tab>son = db._fix_outgoing(item, self._Cursor__collection)<tab>else:<tab><tab>son = item<tab>if self.__wrap is not None:<tab><tab><IF-STMT><tab><tab><tab>return getattr(self._Cursor__collection, son[self.__wrap.type_field])(son)<tab><tab>return self.__wrap(son, collection=self._Cursor__collection)<tab>else:<tab><tab>return son",if self . __wrap . type_field in son :,140
4655,"def apply_transforms(self):<tab>""""""Apply all of the stored transforms, in priority order.""""""<tab>self.document.reporter.attach_observer(self.document.note_transform_message)<tab>while self.transforms:<tab><tab><IF-STMT><tab><tab><tab># Unsorted initially, and whenever a transform is added.<tab><tab><tab>self.transforms.sort()<tab><tab><tab>self.transforms.reverse()<tab><tab><tab>self.sorted = 1<tab><tab>priority, transform_class, pending, kwargs = self.transforms.pop()<tab><tab>transform = transform_class(self.document, startnode=pending)<tab><tab>transform.apply(**kwargs)<tab><tab>self.applied.append((priority, transform_class, pending, kwargs))",if not self . sorted :,169
4656,"def format_sql(sql, params):<tab>rv = []<tab>if isinstance(params, dict):<tab><tab># convert sql with named parameters to sql with unnamed parameters<tab><tab>conv = _FormatConverter(params)<tab><tab><IF-STMT><tab><tab><tab>sql = sql_to_string(sql)<tab><tab><tab>sql = sql % conv<tab><tab><tab>params = conv.params<tab><tab>else:<tab><tab><tab>params = ()<tab>for param in params or ():<tab><tab>if param is None:<tab><tab><tab>rv.append(""NULL"")<tab><tab>param = safe_repr(param)<tab><tab>rv.append(param)<tab>return sql, rv",if params :,151
4657,"def on_execution_item(self, cpath, execution):<tab>if not isinstance(execution, dict):<tab><tab>return<tab>if ""executor"" in execution and execution.get(""executor"") != ""jmeter"":<tab><tab>return<tab>scenario = execution.get(""scenario"", None)<tab><IF-STMT><tab><tab>return<tab>if isinstance(scenario, str):<tab><tab>scenario_name = scenario<tab><tab>scenario = self.get_named_scenario(scenario_name)<tab><tab>if not scenario:<tab><tab><tab>scenario = None<tab><tab>scenario_path = Path(""scenarios"", scenario_name)<tab>else:<tab><tab>scenario_path = cpath.copy()<tab><tab>scenario_path.add_component(""scenario"")<tab>if scenario is not None:<tab><tab>self.check_jmeter_scenario(scenario_path, scenario)",if not scenario :,192
4658,"def _poll_ipc_requests(self) -> None:<tab>try:<tab><tab>if self._ipc_requests.empty():<tab><tab><tab>return<tab><tab>while not self._ipc_requests.empty():<tab><tab><tab>args = self._ipc_requests.get()<tab><tab><tab>try:<tab><tab><tab><tab>for filename in args:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.get_editor_notebook().show_file(filename)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>logger.exception(""Problem processing ipc request"", exc_info=e)<tab><tab>self.become_active_window()<tab>finally:<tab><tab>self.after(50, self._poll_ipc_requests)",if os . path . isfile ( filename ) :,180
4659,"def get_scroll_distance_to_element(driver, element):<tab>try:<tab><tab>scroll_position = driver.execute_script(""return window.scrollY;"")<tab><tab>element_location = None<tab><tab>element_location = element.location[""y""]<tab><tab>element_location = element_location - 130<tab><tab><IF-STMT><tab><tab><tab>element_location = 0<tab><tab>distance = element_location - scroll_position<tab><tab>return distance<tab>except Exception:<tab><tab>return 0",if element_location < 0 :,118
4660,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_access_token(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_expiration_time(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 16 :,124
4661,"def _validate_and_define(params, key, value):<tab>(key, force_generic) = _validate_key(_unescape(key))<tab>if key in params:<tab><tab>raise SyntaxError(f'duplicate key ""{key}""')<tab>cls = _class_for_key.get(key, GenericParam)<tab>emptiness = cls.emptiness()<tab>if value is None:<tab><tab>if emptiness == Emptiness.NEVER:<tab><tab><tab>raise SyntaxError(""value cannot be empty"")<tab><tab>value = cls.from_value(value)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>value = cls.from_wire_parser(dns.wire.Parser(_unescape(value)))<tab><tab>else:<tab><tab><tab>value = cls.from_value(value)<tab>params[key] = value",if force_generic :,194
4662,"def iter_fields(node, *, include_meta=True, exclude_unset=False):<tab>exclude_meta = not include_meta<tab>for field_name, field in node._fields.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>field_val = getattr(node, field_name, _marker)<tab><tab>if field_val is _marker:<tab><tab><tab>continue<tab><tab>if exclude_unset:<tab><tab><tab>if callable(field.default):<tab><tab><tab><tab>default = field.default()<tab><tab><tab>else:<tab><tab><tab><tab>default = field.default<tab><tab><tab>if field_val == default:<tab><tab><tab><tab>continue<tab><tab>yield field_name, field_val",if exclude_meta and field . meta :,171
4663,"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab>if self.server:<tab><tab><tab>self.server.stop()<tab><tab><IF-STMT><tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",if self . sl_hdlr :,92
4664,"def _wait_for_async_copy(self, share_name, file_path):<tab>count = 0<tab>share_client = self.fsc.get_share_client(share_name)<tab>file_client = share_client.get_file_client(file_path)<tab>properties = file_client.get_file_properties()<tab>while properties.copy.status != ""success"":<tab><tab>count = count + 1<tab><tab><IF-STMT><tab><tab><tab>self.fail(""Timed out waiting for async copy to complete."")<tab><tab>self.sleep(6)<tab><tab>properties = file_client.get_file_properties()<tab>self.assertEqual(properties.copy.status, ""success"")",if count > 10 :,165
4665,"def __new__(<tab>cls,<tab>message_type: OrderBookMessageType,<tab>content: Dict[str, any],<tab>timestamp: Optional[float] = None,<tab>*args,<tab>**kwargs,):<tab>if timestamp is None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""timestamp must not be None when initializing snapshot messages.""<tab><tab><tab>)<tab><tab>timestamp = int(time.time())<tab>return super(KucoinOrderBookMessage, cls).__new__(<tab><tab>cls, message_type, content, timestamp=timestamp, *args, **kwargs<tab>)",if message_type is OrderBookMessageType . SNAPSHOT :,152
4666,"def _drop_unique_features(<tab>X: DataFrame, feature_metadata: FeatureMetadata, max_unique_ratio) -> list:<tab>features_to_drop = []<tab>X_len = len(X)<tab>max_unique_value_count = X_len * max_unique_ratio<tab>for column in X:<tab><tab>unique_value_count = len(X[column].unique())<tab><tab><IF-STMT><tab><tab><tab>features_to_drop.append(column)<tab><tab>elif feature_metadata.get_feature_type_raw(column) in [<tab><tab><tab>R_CATEGORY,<tab><tab><tab>R_OBJECT,<tab><tab>] and (unique_value_count > max_unique_value_count):<tab><tab><tab>features_to_drop.append(column)<tab>return features_to_drop",if unique_value_count == 1 :,197
4667,"def get_src_findex_by_pad(s, S, padding_mode, align_corners):<tab>if padding_mode == ""zero"":<tab><tab>return get_src_findex_with_zero_pad(s, S)<tab>elif padding_mode == ""reflect"":<tab><tab><IF-STMT><tab><tab><tab>return get_src_findex_with_reflect_pad(s, S, True)<tab><tab>else:<tab><tab><tab>sf = get_src_findex_with_reflect_pad(s, S, False)<tab><tab><tab>return get_src_findex_with_repeat_pad(sf, S)<tab>elif padding_mode == ""repeat"":<tab><tab>return get_src_findex_with_repeat_pad(s, S)",if align_corners :,175
4668,"def _iterate_self_and_parents(self, upto=None):<tab>current = self<tab>result = ()<tab>while current:<tab><tab>result += (current,)<tab><tab>if current._parent is upto:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise sa_exc.InvalidRequestError(<tab><tab><tab><tab>""Transaction %s is not on the active transaction list"" % (upto)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>current = current._parent<tab>return result",elif current . _parent is None :,126
4669,"def __setattr__(self, name: str, val: Any):<tab>if name.startswith(""COMPUTED_""):<tab><tab><IF-STMT><tab><tab><tab>old_val = self[name]<tab><tab><tab>if old_val == val:<tab><tab><tab><tab>return<tab><tab><tab>raise KeyError(<tab><tab><tab><tab>""Computed attributed '{}' already exists ""<tab><tab><tab><tab>""with a different value! old={}, new={}."".format(name, old_val, val)<tab><tab><tab>)<tab><tab>self[name] = val<tab>else:<tab><tab>super().__setattr__(name, val)",if name in self :,137
4670,"def get_fnlist(bbhandler, pkg_pn, preferred):<tab>""""""Get all recipe file names""""""<tab><IF-STMT><tab><tab>(latest_versions, preferred_versions) = bb.providers.findProviders(<tab><tab><tab>bbhandler.config_data, bbhandler.cooker.recipecaches[""""], pkg_pn<tab><tab>)<tab>fn_list = []<tab>for pn in sorted(pkg_pn):<tab><tab>if preferred:<tab><tab><tab>fn_list.append(preferred_versions[pn][1])<tab><tab>else:<tab><tab><tab>fn_list.extend(pkg_pn[pn])<tab>return fn_list",if preferred :,150
4671,"def links_extracted(self, _, links):<tab>links_deduped = {}<tab>for link in links:<tab><tab>link_fingerprint = link.meta[FIELD_FINGERPRINT]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>links_deduped[link_fingerprint] = link<tab>[<tab><tab>self._redis_pipeline.hmset(fingerprint, self._create_link_extracted(link))<tab><tab>for (fingerprint, link) in links_deduped.items()<tab>]<tab>self._redis_pipeline.execute()",if link_fingerprint in links_deduped :,138
4672,"def __call__(self, name, rawtext, text, lineno, inliner, options=None, content=None):<tab>options = options or {}<tab>content = content or []<tab>issue_nos = [each.strip() for each in utils.unescape(text).split("","")]<tab>config = inliner.document.settings.env.app.config<tab>ret = []<tab>for i, issue_no in enumerate(issue_nos):<tab><tab>node = self.make_node(name, issue_no, config, options=options)<tab><tab>ret.append(node)<tab><tab><IF-STMT><tab><tab><tab>sep = nodes.raw(text="", "", format=""html"")<tab><tab><tab>ret.append(sep)<tab>return ret, []",if i != len ( issue_nos ) - 1 :,176
4673,"def init_messengers(messengers):<tab>for messenger in messengers:<tab><tab><IF-STMT><tab><tab><tab>module_path = messenger[""type""]<tab><tab><tab>messenger[""type""] = messenger[""type""].split(""."")[-1]<tab><tab>else:<tab><tab><tab>module_path = ""oncall.messengers."" + messenger[""type""]<tab><tab>instance = getattr(importlib.import_module(module_path), messenger[""type""])(<tab><tab><tab>messenger<tab><tab>)<tab><tab>for transport in instance.supports:<tab><tab><tab>_active_messengers[transport].append(instance)","if ""."" in messenger [ ""type"" ] :",141
4674,"def _process_enum_definition(self, tok):<tab>fields = []<tab>for field in tok.fields:<tab><tab><IF-STMT><tab><tab><tab>expression = self.expression_parser.parse(field.expression)<tab><tab>else:<tab><tab><tab>expression = None<tab><tab>fields.append(c_ast.CEnumField(name=field.name.first, value=expression))<tab>name = tok.enum_name<tab>if name:<tab><tab>name = ""enum %s"" % tok.enum_name.first<tab>else:<tab><tab>name = self._make_anonymous_type(""enum"")<tab>return c_ast.CTypeDefinition(<tab><tab>name=name,<tab><tab>type_definition=c_ast.CEnum(<tab><tab><tab>attributes=tok.attributes, fields=fields, name=name<tab><tab>),<tab>)",if field . expression :,199
4675,def result_iterator():<tab>try:<tab><tab># reverse to keep finishing order<tab><tab>fs.reverse()<tab><tab>while fs:<tab><tab><tab># Careful not to keep a reference to the popped future<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield fs.pop().result()<tab><tab><tab>else:<tab><tab><tab><tab>yield fs.pop().result(end_time - time.time())<tab>finally:<tab><tab>for future in fs:<tab><tab><tab>future.cancel(),if timeout is None :,117
4676,"def has_encrypted_ssh_key_data(self):<tab>try:<tab><tab>ssh_key_data = self.get_input(""ssh_key_data"")<tab>except AttributeError:<tab><tab>return False<tab>try:<tab><tab>pem_objects = validate_ssh_private_key(ssh_key_data)<tab><tab>for pem_object in pem_objects:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>except ValidationError:<tab><tab>pass<tab>return False","if pem_object . get ( ""key_enc"" , False ) :",123
4677,"def test_seq_object_transcription_method(self):<tab>for nucleotide_seq in test_seqs:<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(<tab><tab><tab><tab>repr(Seq.transcribe(nucleotide_seq)),<tab><tab><tab><tab>repr(nucleotide_seq.transcribe()),<tab><tab><tab>)","if isinstance ( nucleotide_seq , Seq . Seq ) :",96
4678,"def max_elevation(self):<tab>max_el = None<tab>for y in xrange(self.height):<tab><tab>for x in xrange(self.width):<tab><tab><tab>el = self.elevation[""data""][y][x]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>max_el = el<tab>return max_el",if max_el is None or el > max_el :,91
4679,"def stress(mapping, index):<tab>for count in range(OPERATIONS):<tab><tab>function = random.choice(functions)<tab><tab>function(mapping, index)<tab><tab><IF-STMT><tab><tab><tab>print(""\r"", len(mapping), "" "" * 7, end="""")<tab>print()",if count % 1000 == 0 :,72
4680,"def sync_terminology(self):<tab>if self.is_source:<tab><tab>return<tab>store = self.store<tab>missing = []<tab>for source in self.component.get_all_sources():<tab><tab>if ""terminology"" not in source.all_flags:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>_unit, add = store.find_unit(source.context, source.source)<tab><tab>except UnitNotFound:<tab><tab><tab>add = True<tab><tab># Unit is already present<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>missing.append((source.context, source.source, """"))<tab>if missing:<tab><tab>self.add_units(None, missing)",if not add :,166
4681,"def get_generators(self):<tab>""""""Get a dict with all registered generators, indexed by name""""""<tab>generators = {}<tab>for core in self.db.find():<tab><tab><IF-STMT><tab><tab><tab>_generators = core.get_generators({})<tab><tab><tab>if _generators:<tab><tab><tab><tab>generators[str(core.name)] = _generators<tab>return generators","if hasattr ( core , ""get_generators"" ) :",93
4682,"def act(self, state):<tab>if self.body.env.clock.frame < self.training_start_step:<tab><tab>return policy_util.random(state, self, self.body).cpu().squeeze().numpy()<tab>else:<tab><tab>action = self.action_policy(state, self, self.body)<tab><tab><IF-STMT><tab><tab><tab>action = self.scale_action(torch.tanh(action))  # continuous action bound<tab><tab>return action.cpu().squeeze().numpy()",if not self . body . is_discrete :,124
4683,"def try_open_completions_event(self, event=None):<tab>""(./) Open completion list after pause with no movement.""<tab>lastchar = self.text.get(""insert-1c"")<tab>if lastchar in TRIGGERS:<tab><tab>args = TRY_A if lastchar == ""."" else TRY_F<tab><tab>self._delayed_completion_index = self.text.index(""insert"")<tab><tab><IF-STMT><tab><tab><tab>self.text.after_cancel(self._delayed_completion_id)<tab><tab>self._delayed_completion_id = self.text.after(<tab><tab><tab>self.popupwait, self._delayed_open_completions, args<tab><tab>)",if self . _delayed_completion_id is not None :,167
4684,"def token_is_available(self):<tab>if self.token:<tab><tab>try:<tab><tab><tab>resp = requests.get(<tab><tab><tab><tab>""https://api.shodan.io/account/profile?key={0}"".format(self.token)<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>except Exception as ex:<tab><tab><tab>logger.error(str(ex))<tab>return False","if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :",121
4685,"def next_bar_(self, event):<tab>bars = event.bar_dict<tab>self._current_minute = self._minutes_since_midnight(<tab><tab>self.ucontext.now.hour, self.ucontext.now.minute<tab>)<tab>for day_rule, time_rule, func in self._registry:<tab><tab><IF-STMT><tab><tab><tab>with ExecutionContext(EXECUTION_PHASE.SCHEDULED):<tab><tab><tab><tab>with ModifyExceptionFromType(EXC_TYPE.USER_EXC):<tab><tab><tab><tab><tab>func(self.ucontext, bars)<tab>self._last_minute = self._current_minute",if day_rule ( ) and time_rule ( ) :,156
4686,"def decoder(s):<tab>r = []<tab>decode = []<tab>for c in s:<tab><tab>if c == ""&"" and not decode:<tab><tab><tab>decode.append(""&"")<tab><tab><IF-STMT><tab><tab><tab>if len(decode) == 1:<tab><tab><tab><tab>r.append(""&"")<tab><tab><tab>else:<tab><tab><tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab><tab><tab>decode = []<tab><tab>elif decode:<tab><tab><tab>decode.append(c)<tab><tab>else:<tab><tab><tab>r.append(c)<tab>if decode:<tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab>bin_str = """".join(r)<tab>return (bin_str, len(s))","elif c == ""-"" and decode :",188
4687,"def admin_audit_get(admin_id):<tab>if settings.app.demo_mode:<tab><tab>resp = utils.demo_get_cache()<tab><tab><IF-STMT><tab><tab><tab>return utils.jsonify(resp)<tab>if not flask.g.administrator.super_user:<tab><tab>return utils.jsonify(<tab><tab><tab>{<tab><tab><tab><tab>""error"": REQUIRES_SUPER_USER,<tab><tab><tab><tab>""error_msg"": REQUIRES_SUPER_USER_MSG,<tab><tab><tab>},<tab><tab><tab>400,<tab><tab>)<tab>admin = auth.get_by_id(admin_id)<tab>resp = admin.get_audit_events()<tab>if settings.app.demo_mode:<tab><tab>utils.demo_set_cache(resp)<tab>return utils.jsonify(resp)",if resp :,190
4688,"def vjp(self, argnum, outgrad, ans, vs, gvs, args, kwargs):<tab>try:<tab><tab>return self.vjps[argnum](outgrad, ans, vs, gvs, *args, **kwargs)<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>errstr = ""Gradient of {0} not yet implemented.""<tab><tab>else:<tab><tab><tab>errstr = ""Gradient of {0} w.r.t. arg number {1} not yet implemented.""<tab><tab>raise NotImplementedError(errstr.format(self.fun.__name__, argnum))",if self . vjps == { } :,143
4689,"def update(self, *args, **kwargs):<tab>assert not self.readonly<tab>longest_key = 0<tab>_dict = self._dict<tab>reverse = self.reverse<tab>casereverse = self.casereverse<tab>for iterable in args + (kwargs,):<tab><tab><IF-STMT><tab><tab><tab>iterable = iterable.items()<tab><tab>for key, value in iterable:<tab><tab><tab>longest_key = max(longest_key, len(key))<tab><tab><tab>_dict[key] = value<tab><tab><tab>reverse[value].append(key)<tab><tab><tab>casereverse[value.lower()][value] += 1<tab>self._longest_key = max(self._longest_key, longest_key)","if isinstance ( iterable , ( dict , StenoDictionary ) ) :",172
4690,"def update_ui(self, window):<tab>view = window.get_active_view()<tab>self.set_status(view)<tab>lang = ""plain_text""<tab>if view:<tab><tab>buf = view.get_buffer()<tab><tab>language = buf.get_language()<tab><tab><IF-STMT><tab><tab><tab>lang = language.get_id()<tab><tab>self.setup_smart_indent(view, lang)",if language :,101
4691,"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in self.unops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)","if hasattr ( a , name ) :",187
4692,"def _getItemHeight(self, item, ctrl=None):<tab>""""""Returns the full height of the item to be inserted in the form""""""<tab>if type(ctrl) == psychopy.visual.TextBox2:<tab><tab>return ctrl.size[1]<tab>if type(ctrl) == psychopy.visual.Slider:<tab><tab># Set radio button layout<tab><tab><IF-STMT><tab><tab><tab>return 0.03 + ctrl.labelHeight * 3<tab><tab>elif item[""layout""] == ""vert"":<tab><tab><tab># for vertical take into account the nOptions<tab><tab><tab>return ctrl.labelHeight * len(item[""options""])","if item [ ""layout"" ] == ""horiz"" :",155
4693,"def test_cleanup_params(self, body, rpc_mock):<tab>res = self._get_resp_post(body)<tab>self.assertEqual(http_client.ACCEPTED, res.status_code)<tab>rpc_mock.assert_called_once_with(self.context, mock.ANY)<tab>cleanup_request = rpc_mock.call_args[0][1]<tab>for key, value in body.items():<tab><tab>if key in (""disabled"", ""is_up""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value == ""true""<tab><tab>self.assertEqual(value, getattr(cleanup_request, key))<tab>self.assertEqual(self._expected_services(*SERVICES), res.json)",if value is not None :,177
4694,"def _read_json_content(self, body_is_optional=False):<tab>if ""content-length"" not in self.headers:<tab><tab>return self.send_error(411) if not body_is_optional else {}<tab>try:<tab><tab>content_length = int(self.headers.get(""content-length""))<tab><tab>if content_length == 0 and body_is_optional:<tab><tab><tab>return {}<tab><tab>request = json.loads(self.rfile.read(content_length).decode(""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>return request<tab>except Exception:<tab><tab>logger.exception(""Bad request"")<tab>self.send_error(400)","if isinstance ( request , dict ) and ( request or body_is_optional ) :",176
4695,"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None:<tab>modules = getattr(env, ""_viewcode_modules"", {})<tab>for modname, entry in list(modules.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>code, tags, used, refname = entry<tab><tab>for fullname in list(used):<tab><tab><tab>if used[fullname] == docname:<tab><tab><tab><tab>used.pop(fullname)<tab><tab>if len(used) == 0:<tab><tab><tab>modules.pop(modname)",if entry is False :,133
4696,"def frames(self):<tab>""""""an array of all the frames (including iframes) in the current window""""""<tab>from thug.DOM.W3C.HTML.HTMLCollection import HTMLCollection<tab>frames = set()<tab>for frame in self._findAll([""frame"", ""iframe""]):<tab><tab><IF-STMT><tab><tab><tab>from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation<tab><tab><tab>DOMImplementation.createHTMLElement(self.window.doc, frame)<tab><tab>frames.add(frame._node)<tab>return HTMLCollection(self.doc, list(frames))","if not getattr ( frame , ""_node"" , None ) :",145
4697,"def check(self, **kw):<tab>if not kw:<tab><tab>return exists(self.strpath)<tab>if len(kw) == 1:<tab><tab><IF-STMT><tab><tab><tab>return not kw[""dir""] ^ isdir(self.strpath)<tab><tab>if ""file"" in kw:<tab><tab><tab>return not kw[""file""] ^ isfile(self.strpath)<tab>return super(LocalPath, self).check(**kw)","if ""dir"" in kw :",106
4698,"def __init__(self, folders):<tab>self.folders = folders<tab>self.duplicates = {}<tab>for folder, path in folders.items():<tab><tab>duplicates = []<tab><tab>for other_folder, other_path in folders.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if other_path == path:<tab><tab><tab><tab>duplicates.append(other_folder)<tab><tab>if len(duplicates):<tab><tab><tab>self.duplicates[folder] = duplicates",if other_folder == folder :,117
4699,"def next(self, buf, pos):<tab>if pos >= len(buf):<tab><tab>return EOF, """", pos<tab>mo = self.tokens_re.match(buf, pos)<tab>if mo:<tab><tab>text = mo.group()<tab><tab>type, regexp, test_lit = self.tokens[mo.lastindex - 1]<tab><tab>pos = mo.end()<tab><tab><IF-STMT><tab><tab><tab>type = self.literals.get(text, type)<tab><tab>return type, text, pos<tab>else:<tab><tab>c = buf[pos]<tab><tab>return self.symbols.get(c, None), c, pos + 1",if test_lit :,153
4700,"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab><IF-STMT><tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab>if done:<tab><tab><tab>break<tab># Note that the observation on the done=True frame<tab># doesn't matter<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",if i == self . _skip - 2 :,189
4701,"def convert(self, ctx, argument):<tab>arg = argument.replace(""0x"", """").lower()<tab>if arg[0] == ""#"":<tab><tab>arg = arg[1:]<tab>try:<tab><tab>value = int(arg, base=16)<tab><tab>if not (0 <= value <= 0xFFFFFF):<tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return discord.Colour(value=value)<tab>except ValueError:<tab><tab>arg = arg.replace("" "", ""_"")<tab><tab>method = getattr(discord.Colour, arg, None)<tab><tab><IF-STMT><tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return method()","if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",172
4702,"def run(self, **inputs):<tab>if self.inputs.copy_inputs:<tab><tab>self.inputs.subjects_dir = os.getcwd()<tab><tab><IF-STMT><tab><tab><tab>inputs[""subjects_dir""] = self.inputs.subjects_dir<tab><tab>for originalfile in [self.inputs.in_file, self.inputs.in_norm]:<tab><tab><tab>copy2subjdir(self, originalfile, folder=""mri"")<tab>return super(SegmentCC, self).run(**inputs)","if ""subjects_dir"" in inputs :",122
4703,"def get_queryset(self):<tab>if not hasattr(self, ""_queryset""):<tab><tab><IF-STMT><tab><tab><tab>qs = self.queryset<tab><tab>else:<tab><tab><tab>qs = self.model._default_manager.get_queryset()<tab><tab># If the queryset isn't already ordered we need to add an<tab><tab># artificial ordering here to make sure that all formsets<tab><tab># constructed from this queryset have the same form order.<tab><tab>if not qs.ordered:<tab><tab><tab>qs = qs.order_by(self.model._meta.pk.name)<tab><tab># Removed queryset limiting here. As per discussion re: #13023<tab><tab># on django-dev, max_num should not prevent existing<tab><tab># related objects/inlines from being displayed.<tab><tab>self._queryset = qs<tab>return self._queryset",if self . queryset is not None :,197
4704,"def visit_simple_stmt(self, node: Node) -> Iterator[Line]:<tab>""""""Visit a statement without nested statements.""""""<tab>is_suite_like = node.parent and node.parent.type in STATEMENT<tab>if is_suite_like:<tab><tab><IF-STMT><tab><tab><tab>yield from self.visit_default(node)<tab><tab>else:<tab><tab><tab>yield from self.line(+1)<tab><tab><tab>yield from self.visit_default(node)<tab><tab><tab>yield from self.line(-1)<tab>else:<tab><tab>if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):<tab><tab><tab>yield from self.line()<tab><tab>yield from self.visit_default(node)",if self . is_pyi and is_stub_body ( node ) :,189
4705,"def rawDataReceived(self, data):<tab>if self.timeout > 0:<tab><tab>self.resetTimeout()<tab>self._pendingSize -= len(data)<tab>if self._pendingSize > 0:<tab><tab>self._pendingBuffer.write(data)<tab>else:<tab><tab>passon = b""""<tab><tab><IF-STMT><tab><tab><tab>data, passon = data[: self._pendingSize], data[self._pendingSize :]<tab><tab>self._pendingBuffer.write(data)<tab><tab>rest = self._pendingBuffer<tab><tab>self._pendingBuffer = None<tab><tab>self._pendingSize = None<tab><tab>rest.seek(0, 0)<tab><tab>self._parts.append(rest.read())<tab><tab>self.setLineMode(passon.lstrip(b""\r\n""))",if self . _pendingSize < 0 :,189
4706,"def handle(self, *args, **options):<tab>app_name = options.get(""app_name"")<tab>job_name = options.get(""job_name"")<tab># hack since we are using job_name nargs='?' for -l to work<tab>if app_name and not job_name:<tab><tab>job_name = app_name<tab><tab>app_name = None<tab>if options.get(""list_jobs""):<tab><tab>print_jobs(only_scheduled=False, show_when=True, show_appname=True)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>print(""Run a single maintenance job. Please specify the name of the job."")<tab><tab><tab>return<tab><tab>self.runjob(app_name, job_name, options)",if not job_name :,184
4707,"def _exportReceived(self, content, error=False, server=None, context={}, **kwargs):<tab>if error:<tab><tab><IF-STMT><tab><tab><tab>self.error.emit(content[""message""], True)<tab><tab>else:<tab><tab><tab>self.error.emit(""Can't export the project from the server"", True)<tab><tab>self.finished.emit()<tab><tab>return<tab>self.finished.emit()",if content :,97
4708,"def __iter__(self):<tab>n = self.n<tab>k = self.k<tab>j = int(np.ceil(n / k))<tab>for i in range(k):<tab><tab>test_index = np.zeros(n, dtype=bool)<tab><tab><IF-STMT><tab><tab><tab>test_index[i * j : (i + 1) * j] = True<tab><tab>else:<tab><tab><tab>test_index[i * j :] = True<tab><tab>train_index = np.logical_not(test_index)<tab><tab>yield train_index, test_index",if i < k - 1 :,140
4709,"def addType(self, graphene_type):<tab>meta = get_meta(graphene_type)<tab>if meta:<tab><tab><IF-STMT><tab><tab><tab>self._typeMap[meta.name] = graphene_type<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Type {typeName} already exists in the registry."".format(<tab><tab><tab><tab><tab>typeName=meta.name<tab><tab><tab><tab>)<tab><tab><tab>)<tab>else:<tab><tab>raise Exception(""Cannot add unnamed type or a non-type to registry."")",if not graphene_type in self . _typeMap :,135
4710,"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab><IF-STMT><tab><tab><tab>bsize = 8<tab><tab>elif size <= 9:<tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64MIME.base64_len(""x"" * size), bsize)",elif size <= 6 :,160
4711,"def _asStringList(self, sep=""""):<tab>out = []<tab>for item in self._toklist:<tab><tab><IF-STMT><tab><tab><tab>out.append(sep)<tab><tab>if isinstance(item, ParseResults):<tab><tab><tab>out += item._asStringList()<tab><tab>else:<tab><tab><tab>out.append(str(item))<tab>return out",if out and sep :,88
4712,"def open_file_input(cli_parsed):<tab>files = glob.glob(os.path.join(cli_parsed.d, ""*report.html""))<tab>if len(files) > 0:<tab><tab>print(""\n[*] Done! Report written in the "" + cli_parsed.d + "" folder!"")<tab><tab>print(""Would you like to open the report now? [Y/n]"")<tab><tab>while True:<tab><tab><tab>try:<tab><tab><tab><tab>response = input().lower()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return strtobool(response)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>print(""Please respond with y or n"")<tab>else:<tab><tab>print(""[*] No report files found to open, perhaps no hosts were successful"")<tab><tab>return False","if response == """" :",200
4713,"def init_values(self):<tab>config = self._raw_config<tab>for valname, value in self.overrides.iteritems():<tab><tab><IF-STMT><tab><tab><tab>realvalname, key = valname.split(""."", 1)<tab><tab><tab>config.setdefault(realvalname, {})[key] = value<tab><tab>else:<tab><tab><tab>config[valname] = value<tab>for name in config:<tab><tab>if name in self.values:<tab><tab><tab>self.__dict__[name] = config[name]<tab>del self._raw_config","if ""."" in valname :",131
4714,"def get_result(self):<tab>result_list = []<tab>exc_info = None<tab>for f in self.children:<tab><tab>try:<tab><tab><tab>result_list.append(f.get_result())<tab><tab>except Exception as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>exc_info = sys.exc_info()<tab><tab><tab>else:<tab><tab><tab><tab>if not isinstance(e, self.quiet_exceptions):<tab><tab><tab><tab><tab>app_log.error(""Multiple exceptions in yield list"", exc_info=True)<tab>if exc_info is not None:<tab><tab>raise_exc_info(exc_info)<tab>if self.keys is not None:<tab><tab>return dict(zip(self.keys, result_list))<tab>else:<tab><tab>return list(result_list)",if exc_info is None :,196
4715,"def test01e_json(self):<tab>""Testing GeoJSON input/output.""<tab>if not GEOJSON:<tab><tab>return<tab>for g in self.geometries.json_geoms:<tab><tab>geom = OGRGeometry(g.wkt)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(g.json, geom.json)<tab><tab><tab>self.assertEqual(g.json, geom.geojson)<tab><tab>self.assertEqual(OGRGeometry(g.wkt), OGRGeometry(geom.json))","if not hasattr ( g , ""not_equal"" ) :",133
4716,"def __init__(self, hub=None):  # pylint: disable=unused-argument<tab>if resolver._resolver is None:<tab><tab>_resolver = resolver._resolver = _DualResolver()<tab><tab><IF-STMT><tab><tab><tab>_resolver.network_resolver.nameservers[:] = config.resolver_nameservers<tab><tab>if config.resolver_timeout:<tab><tab><tab>_resolver.network_resolver.lifetime = config.resolver_timeout<tab># Different hubs in different threads could be sharing the same<tab># resolver.<tab>assert isinstance(resolver._resolver, _DualResolver)<tab>self._resolver = resolver._resolver",if config . resolver_nameservers :,147
4717,"def __iadd__(self, term):<tab>if isinstance(term, (int, long)):<tab><tab><IF-STMT><tab><tab><tab>_gmp.mpz_add_ui(self._mpz_p, self._mpz_p, c_ulong(term))<tab><tab><tab>return self<tab><tab>if -65535 < term < 0:<tab><tab><tab>_gmp.mpz_sub_ui(self._mpz_p, self._mpz_p, c_ulong(-term))<tab><tab><tab>return self<tab><tab>term = Integer(term)<tab>_gmp.mpz_add(self._mpz_p, self._mpz_p, term._mpz_p)<tab>return self",if 0 <= term < 65536 :,170
4718,"def copy(dst, src):<tab>for (k, v) in src.iteritems():<tab><tab><IF-STMT><tab><tab><tab>d = {}<tab><tab><tab>dst[k] = d<tab><tab><tab>copy(d, v)<tab><tab>else:<tab><tab><tab>dst[k] = v","if isinstance ( v , dict ) :",73
4719,"def generator(self, data):<tab>self.procs = OrderedDict()<tab>for task in data:<tab><tab>self.recurse_task(task, 0, 0, self.procs)<tab>for offset, name, level, pid, ppid, uid, euid, gid in self.procs.values():<tab><tab><IF-STMT><tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>Address(offset),<tab><tab><tab><tab><tab>str(name),<tab><tab><tab><tab><tab>str(level),<tab><tab><tab><tab><tab>int(pid),<tab><tab><tab><tab><tab>int(ppid),<tab><tab><tab><tab><tab>int(uid),<tab><tab><tab><tab><tab>int(gid),<tab><tab><tab><tab><tab>int(euid),<tab><tab><tab><tab>],<tab><tab><tab>)",if offset :,186
4720,"def apply(self, db, person):<tab>families = person.get_parent_family_handle_list()<tab>if families == []:<tab><tab>return True<tab>for family_handle in person.get_parent_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab><IF-STMT><tab><tab><tab>father_handle = family.get_father_handle()<tab><tab><tab>mother_handle = family.get_mother_handle()<tab><tab><tab>if not father_handle:<tab><tab><tab><tab>return True<tab><tab><tab>if not mother_handle:<tab><tab><tab><tab>return True<tab>return False",if family :,157
4721,"def _arctic_task_exec(request):<tab>request.start_time = time.time()<tab>logging.debug(<tab><tab>""Executing asynchronous request for {}/{}"".format(<tab><tab><tab>request.library, request.symbol<tab><tab>)<tab>)<tab>result = None<tab>try:<tab><tab>request.is_running = True<tab><tab><IF-STMT><tab><tab><tab>result = mongo_retry(request.fun)(*request.args, **request.kwargs)<tab><tab>else:<tab><tab><tab>result = request.fun(*request.args, **request.kwargs)<tab>except Exception as e:<tab><tab>request.exception = e<tab>finally:<tab><tab>request.data = result<tab><tab>request.end_time = time.time()<tab><tab>request.is_running = False<tab>return result",if request . mongo_retry :,191
4722,"def _setup_styles(self):<tab>for ttype, ndef in self.style:<tab><tab>escape = EscapeSequence()<tab><tab><IF-STMT><tab><tab><tab>escape.fg = self._color_index(ndef[""color""])<tab><tab>if ndef[""bgcolor""]:<tab><tab><tab>escape.bg = self._color_index(ndef[""bgcolor""])<tab><tab>if self.usebold and ndef[""bold""]:<tab><tab><tab>escape.bold = True<tab><tab>if self.useunderline and ndef[""underline""]:<tab><tab><tab>escape.underline = True<tab><tab>self.style_string[str(ttype)] = (escape.color_string(), escape.reset_string())","if ndef [ ""color"" ] :",156
4723,"def process_string(self, remove_repetitions, sequence):<tab>string = """"<tab>for i, char in enumerate(sequence):<tab><tab>if char != self.int_to_char[self.blank_index]:<tab><tab><tab># if this char is a repetition and remove_repetitions=true,<tab><tab><tab># skip.<tab><tab><tab>if remove_repetitions and i != 0 and char == sequence[i - 1]:<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>string += "" ""<tab><tab><tab>else:<tab><tab><tab><tab>string = string + char<tab>return string",elif char == self . labels [ self . space_index ] :,152
4724,"def arith_expr(self, nodelist):<tab>node = self.com_node(nodelist[0])<tab>for i in range(2, len(nodelist), 2):<tab><tab>right = self.com_node(nodelist[i])<tab><tab><IF-STMT><tab><tab><tab>node = Add(node, right, lineno=nodelist[1].context)<tab><tab>elif nodelist[i - 1].type == token.MINUS:<tab><tab><tab>node = Sub(node, right, lineno=nodelist[1].context)<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected token: %s"" % nodelist[i - 1][0])<tab>return node",if nodelist [ i - 1 ] . type == token . PLUS :,160
4725,"def invert_index(cls, index, length):<tab>if np.isscalar(index):<tab><tab>return length - index<tab>elif isinstance(index, slice):<tab><tab>start, stop = index.start, index.stop<tab><tab>new_start, new_stop = None, None<tab><tab><IF-STMT><tab><tab><tab>new_stop = length - start<tab><tab>if stop is not None:<tab><tab><tab>new_start = length - stop<tab><tab>return slice(new_start - 1, new_stop - 1)<tab>elif isinstance(index, Iterable):<tab><tab>new_index = []<tab><tab>for ind in index:<tab><tab><tab>new_index.append(length - ind)<tab>return new_index",if start is not None :,168
4726,"def getRoots(job):<tab>if job not in visited:<tab><tab>visited.add(job)<tab><tab><IF-STMT><tab><tab><tab>list(map(lambda p: getRoots(p), job._directPredecessors))<tab><tab>else:<tab><tab><tab>roots.add(job)<tab><tab># The following call ensures we explore all successor edges.<tab><tab>list(map(lambda c: getRoots(c), job._children + job._followOns))",if len ( job . _directPredecessors ) > 0 :,120
4727,"def visit_filter_projection(self, node, value):<tab>base = self.visit(node[""children""][0], value)<tab>if not isinstance(base, list):<tab><tab>return None<tab>comparator_node = node[""children""][2]<tab>collected = []<tab>for element in base:<tab><tab><IF-STMT><tab><tab><tab>current = self.visit(node[""children""][1], element)<tab><tab><tab>if current is not None:<tab><tab><tab><tab>collected.append(current)<tab>return collected","if self . _is_true ( self . visit ( comparator_node , element ) ) :",132
4728,"def func(x, y):<tab>try:<tab><tab>if x > y:<tab><tab><tab>z = x + 2 * math.sin(y)<tab><tab><tab>return z ** 2<tab><tab><IF-STMT><tab><tab><tab>return 4<tab><tab>else:<tab><tab><tab>return 2 ** 3<tab>except ValueError:<tab><tab>foo = 0<tab><tab>for i in range(4):<tab><tab><tab>foo += i<tab><tab>return foo<tab>except TypeError:<tab><tab>return 42<tab>else:<tab><tab>return 33<tab>finally:<tab><tab>print(""finished"")",elif x == y :,134
4729,"def set_filter(self, dataset_opt):<tab>""""""This function create and set the pre_filter to the obj as attributes""""""<tab>self.pre_filter = None<tab>for key_name in dataset_opt.keys():<tab><tab><IF-STMT><tab><tab><tab>new_name = key_name.replace(""filters"", ""filter"")<tab><tab><tab>try:<tab><tab><tab><tab>filt = instantiate_filters(getattr(dataset_opt, key_name))<tab><tab><tab>except Exception:<tab><tab><tab><tab>log.exception(<tab><tab><tab><tab><tab>""Error trying to create {}, {}"".format(<tab><tab><tab><tab><tab><tab>new_name, getattr(dataset_opt, key_name)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab><tab>continue<tab><tab><tab>setattr(self, new_name, filt)","if ""filter"" in key_name :",195
4730,"def _add_states_to_lookup(<tab>self, trackers_as_states, trackers_as_actions, domain, online=False):<tab>""""""Add states to lookup dict""""""<tab>for states in trackers_as_states:<tab><tab>active_form = self._get_active_form_name(states[-1])<tab><tab><IF-STMT><tab><tab><tab># modify the states<tab><tab><tab>states = self._modified_states(states)<tab><tab><tab>feature_key = self._create_feature_key(states)<tab><tab><tab># even if there are two identical feature keys<tab><tab><tab># their form will be the same<tab><tab><tab># because of `active_form_...` feature<tab><tab><tab>self.lookup[feature_key] = active_form",if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,192
4731,"def list_loaded_payloads(self):<tab>print(helpers.color(""\n [*] Available Payloads:\n""))<tab>lastBase = None<tab>x = 1<tab>for name in sorted(self.active_payloads.keys()):<tab><tab>parts = name.split(""/"")<tab><tab><IF-STMT><tab><tab><tab>print()<tab><tab>lastBase = parts[0]<tab><tab>print(""\t%s)\t%s"" % (x, ""{0: <24}"".format(name)))<tab><tab>x += 1<tab>print(""\n"")<tab>return",if lastBase and parts [ 0 ] != lastBase :,136
4732,"def reprSmart(vw, item):<tab>ptype = type(item)<tab>if ptype is int:<tab><tab>if -1024 < item < 1024:<tab><tab><tab>return str(item)<tab><tab><IF-STMT><tab><tab><tab>return vw.reprPointer(item)<tab><tab>else:<tab><tab><tab>return hex(item)<tab>elif ptype in (list, tuple):<tab><tab>return reprComplex(vw, item)  # recurse<tab>elif ptype is dict:<tab><tab>return ""{%s}"" % "","".join(<tab><tab><tab>[""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()]<tab><tab>)<tab>else:<tab><tab>return repr(item)",elif vw . isValidPointer ( item ) :,183
4733,"def ConfigSectionMap(section):<tab>config = ConfigParser.RawConfigParser()<tab>configurations = config_manager()  # Class from mkchromecast.config<tab>configf = configurations.configf<tab>config.read(configf)<tab>dict1 = {}<tab>options = config.options(section)<tab>for option in options:<tab><tab>try:<tab><tab><tab>dict1[option] = config.get(section, option)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>DebugPrint(""skip: %s"" % option)<tab><tab>except:<tab><tab><tab>print(""Exception on %s!"" % option)<tab><tab><tab>dict1[option] = None<tab>return dict1",if dict1 [ option ] == - 1 :,162
4734,"def on_success(result):<tab>subtasks = {}<tab>if result:<tab><tab>subtasks = {<tab><tab><tab>self.nodes_keys.inverse[s[""node_id""]]: s.get(""subtask_id"")<tab><tab><tab>for s in result<tab><tab><tab><IF-STMT><tab><tab>}<tab>if subtasks:<tab><tab>print(""subtask finished"")<tab><tab>self.next()<tab>else:<tab><tab>print(""waiting for a subtask to finish"")<tab><tab>time.sleep(10)","if s . get ( ""status"" ) == ""Failure""",129
4735,"def redirect_aware_commmunicate(p, sys=_sys):<tab>""""""Variant of process.communicate that works with in process I/O redirection.""""""<tab>assert sys is not None<tab>out, err = p.communicate()<tab>if redirecting_io(sys=sys):<tab><tab>if out:<tab><tab><tab># We don't unicodify in Python2 because sys.stdout may be a<tab><tab><tab># cStringIO.StringIO object, which does not accept Unicode strings<tab><tab><tab>out = unicodify(out)<tab><tab><tab>sys.stdout.write(out)<tab><tab><tab>out = None<tab><tab><IF-STMT><tab><tab><tab>err = unicodify(err)<tab><tab><tab>sys.stderr.write(err)<tab><tab><tab>err = None<tab>return out, err",if err :,177
4736,"def __exit__(self, *args, **kwargs):<tab>self._samples_cache = {}<tab>if is_validation_enabled() and isinstance(self.prior, dict):<tab><tab>extra = set(self.prior) - self._param_hits<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""pyro.module prior did not find params ['{}']. ""<tab><tab><tab><tab>""Did you instead mean one of ['{}']?"".format(<tab><tab><tab><tab><tab>""', '"".join(extra), ""', '"".join(self._param_misses)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return super().__exit__(*args, **kwargs)",if extra :,156
4737,def __download_thread(self):<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>self.__current_download = self.__queue.get()<tab><tab><tab>self.__download_file(self.__current_download)<tab><tab>time.sleep(0.1),if not self . __queue . empty ( ) :,68
4738,"def plot_timer_command(args):<tab>import nnabla.monitor as M<tab>format_unit = dict(<tab><tab>s=""seconds"",<tab><tab>m=""minutes"",<tab><tab>h=""hours"",<tab><tab>d=""days"",<tab>)<tab>if not args.ylabel:<tab><tab><IF-STMT><tab><tab><tab>args.ylabel = ""Total elapsed time [{}]"".format(format_unit[args.time_unit])<tab><tab>else:<tab><tab><tab>args.ylabel = ""Elapsed time [{}/iter]"".format(format_unit[args.time_unit])<tab>plot_any_command(<tab><tab>args, M.plot_time_elapsed, dict(elapsed=args.elapsed, unit=args.time_unit)<tab>)<tab>return True",if args . elapsed :,177
4739,"def resolve_page(root: ChannelContext[models.MenuItem], info, **kwargs):<tab>if root.node.page_id:<tab><tab>requestor = get_user_or_app_from_context(info.context)<tab><tab>requestor_has_access_to_all = requestor.is_active and requestor.has_perm(<tab><tab><tab>PagePermissions.MANAGE_PAGES<tab><tab>)<tab><tab>return (<tab><tab><tab>PageByIdLoader(info.context)<tab><tab><tab>.load(root.node.page_id)<tab><tab><tab>.then(<tab><tab><tab><tab>lambda page: page<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else None<tab><tab><tab>)<tab><tab>)<tab>return None",if requestor_has_access_to_all or page . is_visible,177
4740,"def find(self, pattern):<tab>""""""Find pages in database.""""""<tab>results = self._search_keyword(pattern)<tab>pat = re.compile(""(.*?)(%s)(.*?)( \(.*\))?$"" % re.escape(pattern), re.I)<tab>if results:<tab><tab>for name, keyword, url in results:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keyword = pat.sub(<tab><tab><tab><tab><tab>r""\1\033[1;31m\2\033[0m\3\033[1;33m\4\033[0m"", keyword<tab><tab><tab><tab>)<tab><tab><tab>print(""%s - %s"" % (keyword, name))<tab>else:<tab><tab>raise RuntimeError(""%s: nothing appropriate."" % pattern)",if os . isatty ( sys . stdout . fileno ( ) ) :,184
4741,"def _certonly_new_request_common(self, mock_client, args=None):<tab>with mock.patch(<tab><tab>""certbot._internal.main._find_lineage_for_domains_and_certname""<tab>) as mock_renewal:<tab><tab>mock_renewal.return_value = (""newcert"", None)<tab><tab>with mock.patch(""certbot._internal.main._init_le_client"") as mock_init:<tab><tab><tab>mock_init.return_value = mock_client<tab><tab><tab><IF-STMT><tab><tab><tab><tab>args = []<tab><tab><tab>args += ""-d foo.bar -a standalone certonly"".split()<tab><tab><tab>self._call(args)",if args is None :,169
4742,"def __init__(self, *args, **kw):<tab>if len(args) > 1:<tab><tab>raise TypeError(""MultiDict can only be called with one positional "" ""argument"")<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>items = list(args[0].iteritems())<tab><tab>elif hasattr(args[0], ""items""):<tab><tab><tab>items = list(args[0].items())<tab><tab>else:<tab><tab><tab>items = list(args[0])<tab><tab>self._items = items<tab>else:<tab><tab>self._items = []<tab>if kw:<tab><tab>self._items.extend(kw.items())","if hasattr ( args [ 0 ] , ""iteritems"" ) :",156
4743,"def test08_ExceptionTypes(self):<tab>self.assertTrue(issubclass(db.DBError, Exception))<tab>for i, j in db.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(issubclass(j, db.DBError), msg=i)<tab><tab><tab>if i not in (""DBKeyEmptyError"", ""DBNotFoundError""):<tab><tab><tab><tab>self.assertFalse(issubclass(j, KeyError), msg=i)<tab># This two exceptions have two bases<tab>self.assertTrue(issubclass(db.DBKeyEmptyError, KeyError))<tab>self.assertTrue(issubclass(db.DBNotFoundError, KeyError))","if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :",154
4744,"def _delegate_to_sinks(self, value: Any) -> None:<tab>for sink in self._sinks:<tab><tab>if isinstance(sink, AgentT):<tab><tab><tab>await sink.send(value=value)<tab><tab><IF-STMT><tab><tab><tab>await cast(TopicT, sink).send(value=value)<tab><tab>else:<tab><tab><tab>await maybe_async(cast(Callable, sink)(value))","elif isinstance ( sink , ChannelT ) :",103
4745,"def _select_block(str_in, start_tag, end_tag):<tab>""""""Select first block delimited by start_tag and end_tag""""""<tab>start_pos = str_in.find(start_tag)<tab>if start_pos < 0:<tab><tab>raise ValueError(""start_tag not found"")<tab>depth = 0<tab>for pos in range(start_pos, len(str_in)):<tab><tab>if str_in[pos] == start_tag:<tab><tab><tab>depth += 1<tab><tab><IF-STMT><tab><tab><tab>depth -= 1<tab><tab>if depth == 0:<tab><tab><tab>break<tab>sel = str_in[start_pos + 1 : pos]<tab>return sel",elif str_in [ pos ] == end_tag :,171
4746,"def confirm(request):<tab>details = request.session.get(""reauthenticate"")<tab>if not details:<tab><tab>return redirect(""home"")<tab># Monkey patch request<tab>request.user = User.objects.get(pk=details[""user_pk""])<tab>if request.method == ""POST"":<tab><tab>confirm_form = PasswordConfirmForm(request, request.POST)<tab><tab><IF-STMT><tab><tab><tab>request.session.pop(""reauthenticate"")<tab><tab><tab>request.session[""reauthenticate_done""] = True<tab><tab><tab>return redirect(""social:complete"", backend=details[""backend""])<tab>else:<tab><tab>confirm_form = PasswordConfirmForm(request)<tab>context = {""confirm_form"": confirm_form}<tab>context.update(details)<tab>return render(request, ""accounts/confirm.html"", context)",if confirm_form . is_valid ( ) :,195
4747,"def verify_credentials(self):<tab>if self.enabled:<tab><tab>response = requests.get(<tab><tab><tab>""https://api.exotel.com/v1/Accounts/{sid}"".format(sid=self.account_sid),<tab><tab><tab>auth=(self.api_key, self.api_token),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Invalid credentials""))",if response . status_code != 200 :,103
4748,"def pixbufrenderer(self, column, crp, model, it):<tab>tok = model.get_value(it, 0)<tab>if tok.type == ""class"":<tab><tab>icon = ""class""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>icon = ""method_priv""<tab><tab>elif tok.visibility == ""protected"":<tab><tab><tab>icon = ""method_prot""<tab><tab>else:<tab><tab><tab>icon = ""method""<tab>crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])","if tok . visibility == ""private"" :",132
4749,"def _omit_keywords(self, context):<tab>omitted_kws = 0<tab>for event, elem in context:<tab><tab># Teardowns aren't omitted to allow checking suite teardown status.<tab><tab>omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown""<tab><tab>start = event == ""start""<tab><tab>if omit and start:<tab><tab><tab>omitted_kws += 1<tab><tab>if not omitted_kws:<tab><tab><tab>yield event, elem<tab><tab><IF-STMT><tab><tab><tab>elem.clear()<tab><tab>if omit and not start:<tab><tab><tab>omitted_kws -= 1",elif not start :,144
4750,"def on_double_click(self, event):<tab># TODO: don't act when the click happens below last item<tab>path = self.get_selected_path()<tab>kind = self.get_selected_kind()<tab>name = self.get_selected_name()<tab>if kind == ""file"":<tab><tab><IF-STMT><tab><tab><tab>self.open_file(path)<tab><tab>else:<tab><tab><tab>self.open_path_with_system_app(path)<tab>elif kind == ""dir"":<tab><tab>self.request_focus_into(path)<tab>return ""break""",if self . should_open_name_in_thonny ( name ) :,152
4751,"def search_cve(db: DatabaseInterface, product: Product) -> dict:<tab>result = {}<tab>for query_result in db.fetch_multiple(QUERIES[""cve_lookup""]):<tab><tab>cve_entry = CveDbEntry(*query_result)<tab><tab><IF-STMT><tab><tab><tab>result[cve_entry.cve_id] = {<tab><tab><tab><tab>""score2"": cve_entry.cvss_v2_score,<tab><tab><tab><tab>""score3"": cve_entry.cvss_v3_score,<tab><tab><tab><tab>""cpe_version"": build_version_string(cve_entry),<tab><tab><tab>}<tab>return result","if _product_matches_cve ( product , cve_entry ) :",174
4752,"def find_go_files_mtime(app_files):<tab>files, mtime = [], 0<tab>for f, mt in app_files.items():<tab><tab>if not f.endswith("".go""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>files.append(f)<tab><tab>mtime = max(mtime, mt)<tab>return files, mtime",if APP_CONFIG . nobuild_files . match ( f ) :,100
4753,"def wrapper(filename):<tab>mtime = getmtime(filename)<tab>with lock:<tab><tab><IF-STMT><tab><tab><tab>old_mtime, result = cache.pop(filename)<tab><tab><tab>if old_mtime == mtime:<tab><tab><tab><tab># Move to the end<tab><tab><tab><tab>cache[filename] = old_mtime, result<tab><tab><tab><tab>return result<tab>result = function(filename)<tab>with lock:<tab><tab>cache[filename] = mtime, result  # at the end<tab><tab>if len(cache) > max_size:<tab><tab><tab>cache.popitem(last=False)<tab>return result",if filename in cache :,144
4754,"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab><IF-STMT><tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab>elif item[1]:<tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab>elif item[2]:<tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab>elif item[3]:<tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",if item [ 0 ] :,181
4755,"def _show_encoders(self, *args, **kwargs):<tab>if issubclass(self.current_module.__class__, BasePayload):<tab><tab>encoders = self.current_module.get_encoders()<tab><tab><IF-STMT><tab><tab><tab>headers = (""Encoder"", ""Name"", ""Description"")<tab><tab><tab>print_table(headers, *encoders, max_column_length=100)<tab><tab><tab>return<tab>print_error(""No encoders available"")",if encoders :,109
4756,"def __init__(self):<tab>Builder.__init__(self, commandName=""VCExpress.exe"", formatName=""msvcProject"")<tab>for key in [""VS90COMNTOOLS"", ""VC80COMNTOOLS"", ""VC71COMNTOOLS""]:<tab><tab><IF-STMT><tab><tab><tab>self.programDir = os.path.join(os.environ[key], "".."", ""IDE"")<tab>if self.programDir is None:<tab><tab>for version in [""9.0"", ""8"", "".NET 2003""]:<tab><tab><tab>msvcDir = (<tab><tab><tab><tab>""C:\\Program Files\\Microsoft Visual Studio %s\\Common7\\IDE"" % version<tab><tab><tab>)<tab><tab><tab>if os.path.exists(msvcDir):<tab><tab><tab><tab>self.programDir = msvcDir",if os . environ . has_key ( key ) :,192
4757,"def _inner(*args, **kwargs):<tab>component_manager = args[0].component_manager<tab>for condition_name in condition_names:<tab><tab>condition_result, err_msg = component_manager.evaluate_condition(condition_name)<tab><tab><IF-STMT><tab><tab><tab>raise ComponentStartConditionNotMetError(err_msg)<tab>if not component_manager.all_components_running(*components):<tab><tab>raise ComponentsNotStartedError(<tab><tab><tab>f""the following required components have not yet started: {json.dumps(components)}""<tab><tab>)<tab>return method(*args, **kwargs)",if not condition_result :,144
4758,"def _gridconvvalue(self, value):<tab>if isinstance(value, (str, _tkinter.Tcl_Obj)):<tab><tab>try:<tab><tab><tab>svalue = str(value)<tab><tab><tab>if not svalue:<tab><tab><tab><tab>return None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.tk.getdouble(svalue)<tab><tab><tab>else:<tab><tab><tab><tab>return self.tk.getint(svalue)<tab><tab>except (ValueError, TclError):<tab><tab><tab>pass<tab>return value","elif ""."" in svalue :",129
4759,"def check_songs():<tab>desc = numeric_phrase(""%d song"", ""%d songs"", len(songs))<tab>with Task(_(""Rescan songs""), desc) as task:<tab><tab>task.copool(check_songs)<tab><tab>for i, song in enumerate(songs):<tab><tab><tab>song = song._song<tab><tab><tab><IF-STMT><tab><tab><tab><tab>app.library.reload(song)<tab><tab><tab>task.update((float(i) + 1) / len(songs))<tab><tab><tab>yield",if song in app . library :,121
4760,"def initialize(self):<tab>nn.init.xavier_uniform_(self.linear.weight.data)<tab>if self.linear.bias is not None:<tab><tab>self.linear.bias.data.uniform_(-1.0, 1.0)<tab>if self.self_layer:<tab><tab>nn.init.xavier_uniform_(self.linear_self.weight.data)<tab><tab><IF-STMT><tab><tab><tab>self.linear_self.bias.data.uniform_(-1.0, 1.0)",if self . linear_self . bias is not None :,126
4761,"def test_row(self, row):<tab>for idx, test in self.patterns.items():<tab><tab>try:<tab><tab><tab>value = row[idx]<tab><tab>except IndexError:<tab><tab><tab>value = """"<tab><tab>result = test(value)<tab><tab><IF-STMT><tab><tab><tab>if result:<tab><tab><tab><tab>return not self.inverse  # True<tab><tab>else:<tab><tab><tab>if not result:<tab><tab><tab><tab>return self.inverse  # False<tab>if self.any_match:<tab><tab>return self.inverse  # False<tab>else:<tab><tab>return not self.inverse  # True",if self . any_match :,149
4762,"def toterminal(self, tw):<tab>for element in self.chain:<tab><tab>element[0].toterminal(tw)<tab><tab><IF-STMT><tab><tab><tab>tw.line("""")<tab><tab><tab>tw.line(element[2], yellow=True)<tab>super(ExceptionChainRepr, self).toterminal(tw)",if element [ 2 ] is not None :,88
4763,"def runMainLoop(self):<tab>""""""The curses gui main loop.""""""<tab># pylint: disable=no-member<tab>#<tab># Do NOT change g.app!<tab>self.curses_app = LeoApp()<tab>stdscr = curses.initscr()<tab>if 1:  # Must follow initscr.<tab><tab>self.dump_keys()<tab>try:<tab><tab>self.curses_app.run()<tab><tab># run calls CApp.main(), which calls CGui.run().<tab>finally:<tab><tab>curses.nocbreak()<tab><tab>stdscr.keypad(0)<tab><tab>curses.echo()<tab><tab>curses.endwin()<tab><tab><IF-STMT><tab><tab><tab>g.pr(""Exiting Leo..."")","if ""shutdown"" in g . app . debug :",179
4764,"def test_chunkcoding(self):<tab>for native, utf8 in zip(*[StringIO(f).readlines() for f in self.tstring]):<tab><tab>u = self.decode(native)[0]<tab><tab>self.assertEqual(u, utf8.decode(""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(native, self.encode(u)[0])",if self . roundtriptest :,93
4765,"def reload_sanitize_allowlist(self, explicit=True):<tab>self.sanitize_allowlist = []<tab>try:<tab><tab>with open(self.sanitize_allowlist_file) as f:<tab><tab><tab>for line in f.readlines():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.sanitize_allowlist.append(line.strip())<tab>except OSError:<tab><tab>if explicit:<tab><tab><tab>log.warning(<tab><tab><tab><tab>""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."",<tab><tab><tab><tab>self.sanitize_allowlist_file,<tab><tab><tab>)","if not line . startswith ( ""#"" ) :",149
4766,"def get_all_extensions(subtree=None):<tab>if subtree is None:<tab><tab>subtree = full_extension_tree()<tab>result = []<tab>if isinstance(subtree, dict):<tab><tab>for value in subtree.values():<tab><tab><tab>if isinstance(value, dict):<tab><tab><tab><tab>result += get_all_extensions(value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result += value.extensions<tab><tab><tab>elif isinstance(value, (list, tuple)):<tab><tab><tab><tab>result += value<tab>elif isinstance(subtree, (ContentTypeMapping, ContentTypeDetector)):<tab><tab>result = subtree.extensions<tab>elif isinstance(subtree, (list, tuple)):<tab><tab>result = subtree<tab>return result","elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :",172
4767,"def _configuration_dict_to_commandlist(name, config_dict):<tab>command_list = [""config:%s"" % name]<tab>for key, value in config_dict.items():<tab><tab><IF-STMT><tab><tab><tab>if value:<tab><tab><tab><tab>b = ""true""<tab><tab><tab>else:<tab><tab><tab><tab>b = ""false""<tab><tab><tab>command_list.append(""%s:%s"" % (key, b))<tab><tab>else:<tab><tab><tab>command_list.append(""%s:%s"" % (key, value))<tab>return command_list",if type ( value ) is bool :,140
4768,"def _RewriteModinfo(<tab>self,<tab>modinfo,<tab>obj_kernel_version,<tab>this_kernel_version,<tab>info_strings=None,<tab>to_remove=None,):<tab>new_modinfo = """"<tab>for line in modinfo.split(""\x00""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if to_remove and line.split(""="")[0] == to_remove:<tab><tab><tab>continue<tab><tab>if info_strings is not None:<tab><tab><tab>info_strings.add(line.split(""="")[0])<tab><tab>if line.startswith(""vermagic""):<tab><tab><tab>line = line.replace(obj_kernel_version, this_kernel_version)<tab><tab>new_modinfo += line + ""\x00""<tab>return new_modinfo",if not line :,187
4769,"def zip_random_open_test(self, f, compression):<tab>self.make_test_archive(f, compression)<tab># Read the ZIP archive<tab>with zipfile.ZipFile(f, ""r"", compression) as zipfp:<tab><tab>zipdata1 = []<tab><tab>with zipfp.open(TESTFN) as zipopen1:<tab><tab><tab>while True:<tab><tab><tab><tab>read_data = zipopen1.read(randint(1, 1024))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>zipdata1.append(read_data)<tab><tab>testdata = """".join(zipdata1)<tab><tab>self.assertEqual(len(testdata), len(self.data))<tab><tab>self.assertEqual(testdata, self.data)",if not read_data :,182
4770,"def _memoized(*args):<tab>now = time.time()<tab>try:<tab><tab>value, last_update = self.cache[args]<tab><tab>age = now - last_update<tab><tab><IF-STMT><tab><tab><tab>self._call_count = 0<tab><tab><tab>raise AttributeError<tab><tab>if self.ctl:<tab><tab><tab>self._call_count += 1<tab><tab>return value<tab>except (KeyError, AttributeError):<tab><tab>value = func(*args)<tab><tab>if value:<tab><tab><tab>self.cache[args] = (value, now)<tab><tab>return value<tab>except TypeError:<tab><tab>return func(*args)",if self . _call_count > self . ctl or age > self . ttl :,164
4771,"def on_data(res):<tab>if terminate.is_set():<tab><tab>return<tab>if args.strings and not args.no_content:<tab><tab>if type(res) == tuple:<tab><tab><tab>f, v = res<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f = f.encode(""utf-8"")<tab><tab><tab>if type(v) == unicode:<tab><tab><tab><tab>v = v.encode(""utf-8"")<tab><tab><tab>self.success(""{}: {}"".format(f, v))<tab><tab>elif not args.content_only:<tab><tab><tab>self.success(res)<tab>else:<tab><tab>self.success(res)",if type ( f ) == unicode :,158
4772,"def _finalize_setup_keywords(self):<tab>for ep in pkg_resources.iter_entry_points(""distutils.setup_keywords""):<tab><tab>value = getattr(self, ep.name, None)<tab><tab><IF-STMT><tab><tab><tab>ep.require(installer=self.fetch_build_egg)<tab><tab><tab>ep.load()(self, ep.name, value)",if value is not None :,90
4773,"def test_attributes_types(self):<tab>if not self.connection.strategy.pooled:<tab><tab><IF-STMT><tab><tab><tab>self.connection.refresh_server_info()<tab><tab>self.assertEqual(<tab><tab><tab>type(self.connection.server.schema.attribute_types[""cn""]), AttributeTypeInfo<tab><tab>)",if not self . connection . server . info :,82
4774,"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab>if isinstance(k, float):<tab><tab><tab>return unicode(float_repr(k))<tab><tab>elif ""regex"" in literal_or_identifier:<tab><tab><tab>return compose_regex(k)<tab><tab><IF-STMT><tab><tab><tab>return ""true"" if k else ""false""<tab><tab>elif k is None:<tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)","elif isinstance ( k , bool ) :",179
4775,"def list2rec(x, test=False):<tab>if test:<tab><tab>vid = ""{}_{:06d}_{:06d}"".format(x[0], int(x[1]), int(x[2]))<tab><tab>label = -1  # label unknown<tab><tab>return vid, label<tab>else:<tab><tab>vid = ""{}_{:06d}_{:06d}"".format(x[1], int(x[2]), int(x[3]))<tab><tab><IF-STMT><tab><tab><tab>vid = ""{}/{}"".format(convert_label(x[0]), vid)<tab><tab>else:<tab><tab><tab>assert level == 1<tab><tab>label = class_mapping[convert_label(x[0])]<tab><tab>return vid, label",if level == 2 :,169
4776,"def _expand_env(self, snapcraft_yaml):<tab>environment_keys = [""name"", ""version""]<tab>for key in snapcraft_yaml:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>replacements = environment_to_replacements(<tab><tab><tab>get_snapcraft_global_environment(self.project)<tab><tab>)<tab><tab>snapcraft_yaml[key] = replace_attr(snapcraft_yaml[key], replacements)<tab>return snapcraft_yaml",if any ( ( key == env_key for env_key in environment_keys ) ) :,124
4777,"def enableCtrls(self):<tab># Check if each ctrl has a requirement or an incompatibility,<tab># look it up, and enable/disable if so<tab>for data in self.storySettingsData:<tab><tab>name = data[""name""]<tab><tab><IF-STMT><tab><tab><tab>if ""requires"" in data:<tab><tab><tab><tab>set = self.getSetting(data[""requires""])<tab><tab><tab><tab>for i in self.ctrls[name]:<tab><tab><tab><tab><tab>i.Enable(set not in [""off"", ""false"", ""0""])",if name in self . ctrls :,133
4778,"def __init__(self, *args, **kwargs):<tab>super(ChallengePhaseCreateSerializer, self).__init__(*args, **kwargs)<tab>context = kwargs.get(""context"")<tab>if context:<tab><tab>challenge = context.get(""challenge"")<tab><tab><IF-STMT><tab><tab><tab>kwargs[""data""][""challenge""] = challenge.pk<tab><tab>test_annotation = context.get(""test_annotation"")<tab><tab>if test_annotation:<tab><tab><tab>kwargs[""data""][""test_annotation""] = test_annotation",if challenge :,119
4779,def set_inactive(self):<tab>for title in self.gramplet_map:<tab><tab>if self.gramplet_map[title].pui:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.gramplet_map[title].pui.active = False,"if self . gramplet_map [ title ] . gstate != ""detached"" :",81
4780,"def authenticate(username, password):<tab>try:<tab><tab>u = User.objects.get(username=username)<tab><tab><IF-STMT><tab><tab><tab>userLogger.info(""User logged in : %s"", username)<tab><tab><tab>return u<tab><tab>else:<tab><tab><tab>userLogger.warn(""Attempt to log in to : %s"", username)<tab><tab><tab>return False<tab>except DoesNotExist:<tab><tab>return False","if check_password_hash ( u . password , password ) :",109
4781,def _check_date(self):<tab>if not self.value:<tab><tab>return None<tab>if not self.allow_date_in_past:<tab><tab>if self.value < self.date_or_datetime().today():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.value = self.date_or_datetime().today()<tab><tab><tab>else:<tab><tab><tab><tab>self.value = self.date_or_datetime().today() + datetime.timedelta(1),if self . allow_todays_date :,119
4782,"def update(self, E=None, **F):<tab>if E:<tab><tab><IF-STMT><tab><tab><tab># Update with `E` dictionary<tab><tab><tab>for k in E:<tab><tab><tab><tab>self[k] = E[k]<tab><tab>else:<tab><tab><tab># Update with `E` items<tab><tab><tab>for (k, v) in E:<tab><tab><tab><tab>self[k] = v<tab># Update with `F` dictionary<tab>for k in F:<tab><tab>self[k] = F[k]","if hasattr ( E , ""keys"" ) :",131
4783,"def _get_quota_availability(self):<tab>quotas_ok = defaultdict(int)<tab>qa = QuotaAvailability()<tab>qa.queue(*[k for k, v in self._quota_diff.items() if v > 0])<tab>qa.compute(now_dt=self.now_dt)<tab>for quota, count in self._quota_diff.items():<tab><tab><IF-STMT><tab><tab><tab>quotas_ok[quota] = 0<tab><tab><tab>break<tab><tab>avail = qa.results[quota]<tab><tab>if avail[1] is not None and avail[1] < count:<tab><tab><tab>quotas_ok[quota] = min(count, avail[1])<tab><tab>else:<tab><tab><tab>quotas_ok[quota] = count<tab>return quotas_ok",if count <= 0 :,182
4784,"def gen_env_vars():<tab>for fd_id, fd in zip(STDIO_DESCRIPTORS, (stdin, stdout, stderr)):<tab><tab>is_atty = fd.isatty()<tab><tab>yield (cls.TTY_ENV_TMPL.format(fd_id), cls.encode_env_var_value(int(is_atty)))<tab><tab><IF-STMT><tab><tab><tab>yield (cls.TTY_PATH_ENV.format(fd_id), os.ttyname(fd.fileno()) or b"""")",if is_atty :,123
4785,"def _convertDict(self, d):<tab>r = {}<tab>for k, v in d.items():<tab><tab>if isinstance(v, bytes):<tab><tab><tab>v = str(v, ""utf-8"")<tab><tab>elif isinstance(v, list) or isinstance(v, tuple):<tab><tab><tab>v = self._convertList(v)<tab><tab>elif isinstance(v, dict):<tab><tab><tab>v = self._convertDict(v)<tab><tab><IF-STMT><tab><tab><tab>k = str(k, ""utf-8"")<tab><tab>r[k] = v<tab>return r","if isinstance ( k , bytes ) :",142
4786,"def get_attribute_value(self, nodeid, attr):<tab>with self._lock:<tab><tab>self.logger.debug(""get attr val: %s %s"", nodeid, attr)<tab><tab>if nodeid not in self._nodes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown)<tab><tab><tab>return dv<tab><tab>node = self._nodes[nodeid]<tab><tab><IF-STMT><tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid)<tab><tab><tab>return dv<tab><tab>attval = node.attributes[attr]<tab><tab>if attval.value_callback:<tab><tab><tab>return attval.value_callback()<tab><tab>return attval.value",if attr not in node . attributes :,200
4787,"def conninfo_parse(dsn):<tab>ret = {}<tab>length = len(dsn)<tab>i = 0<tab>while i < length:<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>continue<tab><tab>param_match = PARAMETER_RE.match(dsn[i:])<tab><tab>if not param_match:<tab><tab><tab>return<tab><tab>param = param_match.group(1)<tab><tab>i += param_match.end()<tab><tab>if i >= length:<tab><tab><tab>return<tab><tab>value, end = read_param_value(dsn[i:])<tab><tab>if value is None:<tab><tab><tab>return<tab><tab>i += end<tab><tab>ret[param] = value<tab>return ret",if dsn [ i ] . isspace ( ) :,175
4788,"def connect(self, buttons):<tab>for button in buttons:<tab><tab>assert button is not None<tab><tab>handled = False<tab><tab>for handler_idx in range(0, len(self.__signal_handlers)):<tab><tab><tab>(obj_class, signal, handler, handler_id) = self.__signal_handlers[<tab><tab><tab><tab>handler_idx<tab><tab><tab>]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler_id = button.connect(signal, handler)<tab><tab><tab><tab>handled = True<tab><tab><tab>self.__signal_handlers[handler_idx] = (<tab><tab><tab><tab>obj_class,<tab><tab><tab><tab>signal,<tab><tab><tab><tab>handler,<tab><tab><tab><tab>handler_id,<tab><tab><tab>)<tab><tab>assert handled","if isinstance ( button , obj_class ) :",182
4789,"def _parse_display(display):<tab>""""""Parse an X11 display value""""""<tab>try:<tab><tab>host, dpynum = display.rsplit("":"", 1)<tab><tab>if host.startswith(""["") and host.endswith(""]""):<tab><tab><tab>host = host[1:-1]<tab><tab>idx = dpynum.find(""."")<tab><tab><IF-STMT><tab><tab><tab>screen = int(dpynum[idx + 1 :])<tab><tab><tab>dpynum = dpynum[:idx]<tab><tab>else:<tab><tab><tab>screen = 0<tab>except (ValueError, UnicodeEncodeError):<tab><tab>raise ValueError(""Invalid X11 display"") from None<tab>return host, dpynum, screen",if idx >= 0 :,156
4790,"def delete_all(path):<tab>ppath = os.getcwd()<tab>os.chdir(path)<tab>for fn in glob.glob(""*""):<tab><tab>fn_full = os.path.join(path, fn)<tab><tab>if os.path.isdir(fn):<tab><tab><tab>delete_all(fn_full)<tab><tab><IF-STMT><tab><tab><tab>os.remove(fn_full)<tab><tab>elif fn.endswith("".md""):<tab><tab><tab>os.remove(fn_full)<tab><tab>elif DELETE_ALL_OLD:<tab><tab><tab>os.remove(fn_full)<tab>os.chdir(ppath)<tab>os.rmdir(path)","elif fn . endswith ( "".png"" ) :",158
4791,"def _sync_get(self, identifier, *args, **kw):<tab>self._mutex.acquire()<tab>try:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self._values[identifier]<tab><tab><tab>else:<tab><tab><tab><tab>self._values[identifier] = value = self.creator(identifier, *args, **kw)<tab><tab><tab><tab>return value<tab><tab>except KeyError:<tab><tab><tab>self._values[identifier] = value = self.creator(identifier, *args, **kw)<tab><tab><tab>return value<tab>finally:<tab><tab>self._mutex.release()",if identifier in self . _values :,148
4792,"def _query_fd(self):<tab>if self.stream is None:<tab><tab>self._last_stat = None, None<tab>else:<tab><tab>try:<tab><tab><tab>st = os.stat(self._filename)<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>self._last_stat = None, None<tab><tab>else:<tab><tab><tab>self._last_stat = st[stat.ST_DEV], st[stat.ST_INO]",if e . errno != errno . ENOENT :,137
4793,"def get_place_name(self, place_handle):<tab>""""""Obtain a place name""""""<tab>text = """"<tab>if place_handle:<tab><tab>place = self.dbstate.db.get_place_from_handle(place_handle)<tab><tab><IF-STMT><tab><tab><tab>place_title = place_displayer.display(self.dbstate.db, place)<tab><tab><tab>if place_title != """":<tab><tab><tab><tab>if len(place_title) > 25:<tab><tab><tab><tab><tab>text = place_title[:24] + ""...""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>text = place_title<tab>return text",if place :,153
4794,"def test_decoder_state(self):<tab># Check that getstate() and setstate() handle the state properly<tab>u = ""abc123""<tab>for encoding in all_unicode_encodings:<tab><tab><IF-STMT><tab><tab><tab>self.check_state_handling_decode(encoding, u, u.encode(encoding))<tab><tab><tab>self.check_state_handling_encode(encoding, u, u.encode(encoding))",if encoding not in broken_unicode_with_stateful :,110
4795,"def cleanup(self):<tab>if os.path.exists(self.meta_gui_dir):<tab><tab>for f in os.listdir(self.meta_gui_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(os.path.join(self.meta_gui_dir, f))","if os . path . splitext ( f ) [ 1 ] == "".desktop"" :",85
4796,"def _have_applied_incense(self):<tab>for applied_item in inventory.applied_items().all():<tab><tab>self.logger.info(applied_item)<tab><tab><IF-STMT><tab><tab><tab>mins = format_time(applied_item.expire_ms * 1000)<tab><tab><tab>self.logger.info(<tab><tab><tab><tab>""Not applying incense, currently active: %s, %s minutes remaining"",<tab><tab><tab><tab>applied_item.item.name,<tab><tab><tab><tab>mins,<tab><tab><tab>)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>self.logger.info("""")<tab><tab><tab>return False<tab>return False",if applied_item . expire_ms > 0 :,162
4797,"def get_closest_point(self, point):<tab>point = to_point(point)<tab>cp, cd = None, None<tab>for p0, p1 in iter_pairs(self.pts, self.connected):<tab><tab>diff = p1 - p0<tab><tab>l = diff.length<tab><tab>d = diff / l<tab><tab>pp = p0 + d * max(0, min(l, (point - p0).dot(d)))<tab><tab>dist = (point - pp).length<tab><tab><IF-STMT><tab><tab><tab>cp, cd = pp, dist<tab>return cp",if not cp or dist < cd :,143
4798,"def process_return(lines):<tab>for line in lines:<tab><tab>m = re.fullmatch(r""(?P<param>\w+)\s+:\s+(?P<type>[\w.]+)"", line)<tab><tab><IF-STMT><tab><tab><tab># Once this is in scanpydoc, we can use the fancy hover stuff<tab><tab><tab>yield f'**{m[""param""]}** : :class:`~{m[""type""]}`'<tab><tab>else:<tab><tab><tab>yield line",if m :,106
4799,"def _classify(nodes_by_level):<tab>missing, invalid, downloads = [], [], []<tab>for level in nodes_by_level:<tab><tab>for node in level:<tab><tab><tab>if node.binary == BINARY_MISSING:<tab><tab><tab><tab>missing.append(node)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>invalid.append(node)<tab><tab><tab>elif node.binary in (BINARY_UPDATE, BINARY_DOWNLOAD):<tab><tab><tab><tab>downloads.append(node)<tab>return missing, invalid, downloads",elif node . binary == BINARY_INVALID :,126
4800,"def safe_parse_date(date_hdr):<tab>""""""Parse a Date: or Received: header into a unix timestamp.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>date_hdr = date_hdr.split("";"")[-1].strip()<tab><tab>msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr)))<tab><tab>if (msg_ts > (time.time() + 24 * 3600)) or (msg_ts < 1):<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>return msg_ts<tab>except (ValueError, TypeError, OverflowError):<tab><tab>return None","if "";"" in date_hdr :",150
4801,"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",if value != 1 :,145
4802,"def _rewrite_prepend_append(self, string, prepend, append=None):<tab>if append is None:<tab><tab>append = prepend<tab>if not isinstance(string, StringElem):<tab><tab>string = StringElem(string)<tab>string.sub.insert(0, prepend)<tab>if unicode(string).endswith(u""\n""):<tab><tab># Try and remove the last character from the tree<tab><tab>try:<tab><tab><tab>lastnode = string.flatten()[-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lastnode.sub[-1] = lastnode.sub[-1].rstrip(u""\n"")<tab><tab>except IndexError:<tab><tab><tab>pass<tab><tab>string.sub.append(append + u""\n"")<tab>else:<tab><tab>string.sub.append(append)<tab>return string","if isinstance ( lastnode . sub [ - 1 ] , unicode ) :",197
4803,"def parse_indentless_sequence_entry(self):<tab>if self.check_token(BlockEntryToken):<tab><tab>token = self.get_token()<tab><tab><IF-STMT><tab><tab><tab>self.states.append(self.parse_indentless_sequence_entry)<tab><tab><tab>return self.parse_block_node()<tab><tab>else:<tab><tab><tab>self.state = self.parse_indentless_sequence_entry<tab><tab><tab>return self.process_empty_scalar(token.end_mark)<tab>token = self.peek_token()<tab>event = SequenceEndEvent(token.start_mark, token.start_mark)<tab>self.state = self.states.pop()<tab>return event","if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :",184
4804,"def walk_directory(directory, verbose=False):<tab>""""""Iterates a directory's text files and their contents.""""""<tab>for dir_path, _, filenames in os.walk(directory):<tab><tab>for filename in filenames:<tab><tab><tab>file_path = os.path.join(dir_path, filename)<tab><tab><tab>if os.path.isfile(file_path) and not filename.startswith("".""):<tab><tab><tab><tab>with io.open(file_path, ""r"", encoding=""utf-8"") as file:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>print(""Reading {}"".format(filename))<tab><tab><tab><tab><tab>doc_text = file.read()<tab><tab><tab><tab><tab>yield filename, doc_text",if verbose :,166
4805,"def set_bounds(self, x, y, width, height):<tab>if self.native:<tab><tab># Root level widgets may require vertical adjustment to<tab><tab># account for toolbars, etc.<tab><tab><IF-STMT><tab><tab><tab>vertical_shift = self.frame.vertical_shift<tab><tab>else:<tab><tab><tab>vertical_shift = 0<tab><tab>self.native.Size = Size(width, height)<tab><tab>self.native.Location = Point(x, y + vertical_shift)",if self . interface . parent is None :,122
4806,"def _check_x11(self, command=None, *, exc=None, exit_status=None, **kwargs):<tab>""""""Check requesting X11 forwarding""""""<tab>with (yield from self.connect()) as conn:<tab><tab><IF-STMT><tab><tab><tab>with self.assertRaises(exc):<tab><tab><tab><tab>yield from _create_x11_process(conn, command, **kwargs)<tab><tab>else:<tab><tab><tab>proc = yield from _create_x11_process(conn, command, **kwargs)<tab><tab><tab>yield from proc.wait()<tab><tab><tab>self.assertEqual(proc.exit_status, exit_status)<tab>yield from conn.wait_closed()",if exc :,156
4807,"def repr(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>from infogami.infobase.utils import prepr<tab><tab><tab>return prepr(self.obj)<tab><tab>else:<tab><tab><tab>return repr(self.obj)<tab>except:<tab><tab>return ""failed""<tab>return render_template(""admin/memory/object"", self.obj)","if isinstance ( self . obj , ( dict , web . threadeddict ) ) :",100
4808,"def add(self, tag, values):<tab>if tag not in self.different:<tab><tab>if tag not in self:<tab><tab><tab>self[tag] = values<tab><tab><IF-STMT><tab><tab><tab>self.different.add(tag)<tab><tab><tab>self[tag] = [""""]<tab>self.counts[tag] += 1",elif self [ tag ] != values :,82
4809,"def _on_geturl(self, event):<tab>selected = self._status_list.get_selected()<tab>if selected != -1:<tab><tab>object_id = self._status_list.GetItemData(selected)<tab><tab>download_item = self._download_list.get_item(object_id)<tab><tab>url = download_item.url<tab><tab><IF-STMT><tab><tab><tab>clipdata = wx.TextDataObject()<tab><tab><tab>clipdata.SetText(url)<tab><tab><tab>wx.TheClipboard.Open()<tab><tab><tab>wx.TheClipboard.SetData(clipdata)<tab><tab><tab>wx.TheClipboard.Close()",if not wx . TheClipboard . IsOpened ( ) :,163
4810,"def escape2null(text):<tab>""""""Return a string with escape-backslashes converted to nulls.""""""<tab>parts = []<tab>start = 0<tab>while True:<tab><tab>found = text.find(""\\"", start)<tab><tab><IF-STMT><tab><tab><tab>parts.append(text[start:])<tab><tab><tab>return """".join(parts)<tab><tab>parts.append(text[start:found])<tab><tab>parts.append(""\x00"" + text[found + 1 : found + 2])<tab><tab>start = found + 2  # skip character after escape",if found == - 1 :,129
4811,def _process_inner_views(self):<tab>for view in self.baseviews:<tab><tab>for inner_class in view.get_uninit_inner_views():<tab><tab><tab>for v in self.baseviews:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>view.get_init_inner_views().append(v),"if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :",99
4812,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_app_version_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_method(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 34:<tab><tab><tab>self.set_queue(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 18 :,184
4813,"def test_sample_output():<tab>comment = ""SAMPLE OUTPUT""<tab>skip_files = [""__init__.py""]<tab>errors = []<tab>for _file in sorted(MODULE_PATH.iterdir()):<tab><tab>if _file.suffix == "".py"" and _file.name not in skip_files:<tab><tab><tab>with _file.open() as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>errors.append((comment, _file))<tab>if errors:<tab><tab>line = ""Missing sample error(s) detected!\n\n""<tab><tab>for error in errors:<tab><tab><tab>line += ""`{}` is not in module `{}`\n"".format(*error)<tab><tab>print(line[:-1])<tab><tab>assert False",if comment not in f . read ( ) :,174
4814,"def _get_planner(name, path, source):<tab>for klass in _planners:<tab><tab><IF-STMT><tab><tab><tab>LOG.debug(""%r accepted %r (filename %r)"", klass, name, path)<tab><tab><tab>return klass<tab><tab>LOG.debug(""%r rejected %r"", klass, name)<tab>raise ansible.errors.AnsibleError(NO_METHOD_MSG + repr(invocation))","if klass . detect ( path , source ) :",100
4815,"def _to_string_infix(self, ostream, idx, verbose):<tab>if verbose:<tab><tab>ostream.write("" , "")<tab>else:<tab><tab>hasConst = not (<tab><tab><tab>self._const.__class__ in native_numeric_types and self._const == 0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>idx -= 1<tab><tab>_l = self._coef[id(self._args[idx])]<tab><tab>_lt = _l.__class__<tab><tab>if _lt is _NegationExpression or (_lt in native_numeric_types and _l < 0):<tab><tab><tab>ostream.write("" - "")<tab><tab>else:<tab><tab><tab>ostream.write("" + "")",if hasConst :,169
4816,"def cluster_info_query(self):<tab>if self._major_version >= 90600:<tab><tab>extra = (<tab><tab><tab>"", CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END,""<tab><tab><tab>"" slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver()""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>extra = ""timeline_id"" + extra + "", pg_catalog.pg_control_checkpoint()""<tab><tab>else:<tab><tab><tab>extra = ""0"" + extra<tab>else:<tab><tab>extra = ""0, NULL, NULL, NULL""<tab>return (""SELECT "" + self.TL_LSN + "", {2}"").format(<tab><tab>self.wal_name, self.lsn_name, extra<tab>)","if self . role == ""standby_leader"" :",199
4817,"def __init__(self, *args, **kwargs):<tab>self.country = kwargs.pop(""country"")<tab>self.fields_needed = kwargs.pop(""fields_needed"", [])<tab>super(DynamicManagedAccountForm, self).__init__(*args, **kwargs)<tab># build our form using the country specific fields and falling<tab># back to our default set<tab>for f in self.fields_needed:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>field_name, field = FIELDS_BY_COUNTRY[self.country][f]<tab><tab><tab>self.fields[field_name] = field","if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :",155
4818,"def delete_map(self, query=None):<tab>query_map = self.interpolated_map(query=query)<tab>for alias, drivers in six.iteritems(query_map.copy()):<tab><tab>for driver, vms in six.iteritems(drivers.copy()):<tab><tab><tab>for vm_name, vm_details in six.iteritems(vms.copy()):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>query_map[alias][driver].pop(vm_name)<tab><tab><tab>if not query_map[alias][driver]:<tab><tab><tab><tab>query_map[alias].pop(driver)<tab><tab>if not query_map[alias]:<tab><tab><tab>query_map.pop(alias)<tab>return query_map","if vm_details == ""Absent"" :",177
4819,"def on_strokes_edited(self):<tab>strokes = self._strokes()<tab>if strokes:<tab><tab>translation = self._engine.raw_lookup(strokes)<tab><tab><IF-STMT><tab><tab><tab>fmt = _(""{strokes} maps to {translation}"")<tab><tab>else:<tab><tab><tab>fmt = _(""{strokes} is not in the dictionary"")<tab><tab>info = self._format_label(fmt, (strokes,), translation)<tab>else:<tab><tab>info = """"<tab>self.strokes_info.setText(info)",if translation is not None :,123
4820,"def release(self):<tab>tid = _thread.get_ident()<tab>with self.lock:<tab><tab>if self.owner != tid:<tab><tab><tab>raise RuntimeError(""cannot release un-acquired lock"")<tab><tab>assert self.count > 0<tab><tab>self.count -= 1<tab><tab><IF-STMT><tab><tab><tab>self.owner = None<tab><tab><tab>if self.waiters:<tab><tab><tab><tab>self.waiters -= 1<tab><tab><tab><tab>self.wakeup.release()",if self . count == 0 :,117
4821,"def _cat_blob(self, gcs_uri):<tab>"""""":py:meth:`cat_file`, minus decompression.""""""<tab>blob = self._get_blob(gcs_uri)<tab>if not blob:<tab><tab>return  # don't cat nonexistent files<tab>start = 0<tab>while True:<tab><tab>end = start + _CAT_CHUNK_SIZE<tab><tab>try:<tab><tab><tab>chunk = blob.download_as_string(start=start, end=end)<tab><tab>except google.api_core.exceptions.RequestRangeNotSatisfiable:<tab><tab><tab>return<tab><tab>yield chunk<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>start = end",if len ( chunk ) < _CAT_CHUNK_SIZE :,168
4822,"def device_iter(**kwargs):<tab>for dev in backend.enumerate_devices():<tab><tab>d = Device(dev, backend)<tab><tab>tests = (val == _try_getattr(d, key) for key, val in kwargs.items())<tab><tab><IF-STMT><tab><tab><tab>yield d",if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,88
4823,"def _get_vtkjs(self):<tab>if self._vtkjs is None and self.object is not None:<tab><tab>if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""):<tab><tab><tab>if isfile(self.object):<tab><tab><tab><tab>with open(self.object, ""rb"") as f:<tab><tab><tab><tab><tab>vtkjs = f.read()<tab><tab><tab>else:<tab><tab><tab><tab>data_url = urlopen(self.object)<tab><tab><tab><tab>vtkjs = data_url.read()<tab><tab><IF-STMT><tab><tab><tab>vtkjs = self.object.read()<tab><tab>self._vtkjs = vtkjs<tab>return self._vtkjs","elif hasattr ( self . object , ""read"" ) :",180
4824,"def _execute_with_error(command, error, message):<tab>try:<tab><tab>cli.invocation = cli.invocation_cls(<tab><tab><tab>cli_ctx=cli,<tab><tab><tab>parser_cls=cli.parser_cls,<tab><tab><tab>commands_loader_cls=cli.commands_loader_cls,<tab><tab><tab>help_cls=cli.help_cls,<tab><tab>)<tab><tab>cli.invocation.execute(command.split())<tab>except CLIError as ex:<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>""{}\nExpected: {}\nActual: {}"".format(message, error, ex)<tab><tab><tab>)<tab><tab>return<tab>except Exception as ex:<tab><tab>raise ex<tab>raise AssertionError(""exception not raised for '{0}'"".format(message))",if error not in str ( ex ) :,193
4825,"def ray_intersection(self, p, line):<tab>p = Vector(center(line.sites))<tab>min_r = BIG_FLOAT<tab>nearest = None<tab>for v_i, v_j in self.edges:<tab><tab>bound = LineEquation2D.from_two_points(v_i, v_j)<tab><tab>intersection = bound.intersect_with_line(line)<tab><tab>if intersection is not None:<tab><tab><tab>r = (p - intersection).length<tab><tab><tab># info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nearest = intersection<tab><tab><tab><tab>min_r = r<tab>return nearest",if r < min_r :,187
4826,"def CalculateChecksum(data):<tab># The checksum is just a sum of all the bytes. I swear.<tab>if isinstance(data, bytearray):<tab><tab>total = sum(data)<tab>elif isinstance(data, bytes):<tab><tab><IF-STMT><tab><tab><tab># Python 2 bytes (str) index as single-character strings.<tab><tab><tab>total = sum(map(ord, data))<tab><tab>else:<tab><tab><tab># Python 3 bytes index as numbers (and PY2 empty strings sum() to 0)<tab><tab><tab>total = sum(data)<tab>else:<tab><tab># Unicode strings (should never see?)<tab><tab>total = sum(map(ord, data))<tab>return total & 0xFFFFFFFF","if data and isinstance ( data [ 0 ] , bytes ) :",172
4827,"def __mul__(self, other: Union[""Tensor"", float]) -> ""Tensor"":<tab>if isinstance(other, Tensor):<tab><tab><IF-STMT><tab><tab><tab>errstr = (<tab><tab><tab><tab>f""Given backens are inconsistent. Found '{self.backend.name}'""<tab><tab><tab><tab>f""and '{other.backend.name}'""<tab><tab><tab>)<tab><tab><tab>raise ValueError(errstr)<tab><tab>other = other.array<tab>array = self.backend.multiply(self.array, other)<tab>return Tensor(array, backend=self.backend)",if self . backend . name != other . backend . name :,140
4828,"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab><IF-STMT><tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab>if i >= len(self.items):<tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab>if self.select(i):<tab><tab><tab>break<tab><tab>i += direction<tab><tab>if start < 0:<tab><tab><tab>start = 0",if i == start :,194
4829,"def resolve_none(self, data):<tab># replace None to '_'<tab>for tok_idx in range(len(data)):<tab><tab>for feat_idx in range(len(data[tok_idx])):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[tok_idx][feat_idx] = ""_""<tab>return data",if data [ tok_idx ] [ feat_idx ] is None :,87
4830,"def distinct(expr, *on):<tab>fields = frozenset(expr.fields)<tab>_on = []<tab>append = _on.append<tab>for n in on:<tab><tab>if isinstance(n, Field):<tab><tab><tab>if n._child.isidentical(expr):<tab><tab><tab><tab>n = n._name<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>if not isinstance(n, _strtypes):<tab><tab><tab>raise TypeError(""on must be a name or field, not: {0}"".format(n))<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>append(n)<tab>return Distinct(expr, tuple(_on))",elif n not in fields :,192
4831,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_cost().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.add_version(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 10 :,167
4832,"def func_std_string(func_name):  # match what old profile produced<tab>if func_name[:2] == (""~"", 0):<tab><tab># special case for built-in functions<tab><tab>name = func_name[2]<tab><tab><IF-STMT><tab><tab><tab>return ""{%s}"" % name[1:-1]<tab><tab>else:<tab><tab><tab>return name<tab>else:<tab><tab>return ""%s:%d(%s)"" % func_name","if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :",115
4833,"def f():<tab>try:<tab><tab># Intra-buffer read then buffer-flushing read<tab><tab>for n in cycle([1, 19]):<tab><tab><tab>s = bufio.read(n)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab># list.append() is atomic<tab><tab><tab>results.append(s)<tab>except Exception as e:<tab><tab>errors.append(e)<tab><tab>raise",if not s :,104
4834,"def stop(self):<tab># Try to shut the connection down, but if we get any sort of<tab># errors, go ahead and ignore them.. as we're shutting down anyway<tab>try:<tab><tab>self.rpcserver.stop()<tab><tab>if self.backend_rpcserver:<tab><tab><tab>self.backend_rpcserver.stop()<tab><tab><IF-STMT><tab><tab><tab>self.cluster_rpcserver.stop()<tab>except Exception:<tab><tab>pass<tab>if self.coordination:<tab><tab>try:<tab><tab><tab>coordination.COORDINATOR.stop()<tab><tab>except Exception:<tab><tab><tab>pass<tab>super(Service, self).stop(graceful=True)",if self . cluster_rpcserver :,171
4835,"def download(cls, architecture, path=""./""):<tab>if cls.sanity_check(architecture):<tab><tab>architecture_file = download_file(<tab><tab><tab>cls.architecture_map[architecture], directory=path<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>print(""Coreml model {} is saved in [{}]"".format(architecture, path))<tab><tab>return architecture_file<tab>else:<tab><tab>return None",if not architecture_file :,107
4836,"def opps_output_converter(kpt_list):<tab>kpts = []<tab>mpii_keys = to_opps_converter.keys()<tab>for mpii_idx in range(0, 16):<tab><tab><IF-STMT><tab><tab><tab>model_idx = to_opps_converter[mpii_idx]<tab><tab><tab>x, y = kpt_list[model_idx]<tab><tab><tab>if x < 0 or y < 0:<tab><tab><tab><tab>kpts += [0.0, 0.0, -1.0]<tab><tab><tab>else:<tab><tab><tab><tab>kpts += [x, y, 1.0]<tab><tab>else:<tab><tab><tab>kpts += [0.0, 0.0, -1.0]<tab>return kpts",if mpii_idx in mpii_keys :,188
4837,"def _get_headers(self, headers=None):<tab>request_headers = headers or {}<tab># Auth headers if access_token is present<tab>if self._client.client.config:<tab><tab>config = self._client.client.config<tab><tab>if ""Authorization"" not in request_headers and config.token:<tab><tab><tab>request_headers.update(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""Authorization"": ""{} {}"".format(<tab><tab><tab><tab><tab><tab>config.authentication_type, config.token<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>request_headers.update({config.header: config.header_service})<tab>return request_headers",if config . header and config . header_service :,176
4838,"def get_last_traded_prices(cls, trading_pairs: List[str]) -> Dict[str, float]:<tab>results = dict()<tab>async with aiohttp.ClientSession() as client:<tab><tab>resp = await client.get(f""{constants.REST_URL}/tickers"")<tab><tab>resp_json = await resp.json()<tab><tab>for trading_pair in trading_pairs:<tab><tab><tab>resp_record = [<tab><tab><tab><tab>o<tab><tab><tab><tab>for o in resp_json<tab><tab><tab><tab><IF-STMT><tab><tab><tab>][0]<tab><tab><tab>results[trading_pair] = float(resp_record[""price""])<tab>return results","if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )",181
4839,"def reset_two_factor_hotp():<tab>uid = request.form[""uid""]<tab>otp_secret = request.form.get(""otp_secret"", None)<tab>if otp_secret:<tab><tab>user = Journalist.query.get(uid)<tab><tab><IF-STMT><tab><tab><tab>return render_template(""admin_edit_hotp_secret.html"", uid=uid)<tab><tab>db.session.commit()<tab><tab>return redirect(url_for(""admin.new_user_two_factor"", uid=uid))<tab>else:<tab><tab>return render_template(""admin_edit_hotp_secret.html"", uid=uid)","if not validate_hotp_secret ( user , otp_secret ) :",166
4840,"def ctx_for_video(self, vurl):<tab>""Get a context dict for a given video URL""<tab>ctx = self.get_context_dict()<tab>for portal, match, context_fn in self.PORTALS:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>ctx.update(context_fn(vurl))<tab><tab><tab><tab>ctx[""portal""] = portal<tab><tab><tab><tab>break<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>continue<tab>return ctx",if match . search ( vurl ) :,122
4841,"def get(self):<tab>name = request.args.get(""filename"")<tab>if name is not None:<tab><tab>opts = dict()<tab><tab>opts[""type""] = ""episode""<tab><tab>result = guessit(name, options=opts)<tab><tab>res = dict()<tab><tab>if ""episode"" in result:<tab><tab><tab>res[""episode""] = result[""episode""]<tab><tab>else:<tab><tab><tab>res[""episode""] = 0<tab><tab>if ""season"" in result:<tab><tab><tab>res[""season""] = result[""season""]<tab><tab>else:<tab><tab><tab>res[""season""] = 0<tab><tab><IF-STMT><tab><tab><tab>res[""subtitle_language""] = str(result[""subtitle_language""])<tab><tab>return jsonify(data=res)<tab>else:<tab><tab>return """", 400","if ""subtitle_language"" in result :",196
4842,"def package_files(package_path, directory_name):<tab>paths = []<tab>directory_path = os.path.join(package_path, directory_name)<tab>for (path, directories, filenames) in os.walk(directory_path):<tab><tab>relative_path = os.path.relpath(path, package_path)<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>paths.append(os.path.join(relative_path, filename))<tab>return paths","if filename [ 0 ] == ""."" :",126
4843,"def parse_simple(d, data):<tab>units = {}<tab>for v in data[d]:<tab><tab>key = v[""name""]<tab><tab>if not key:<tab><tab><tab>continue<tab><tab>key_to_insert = make_key(key)<tab><tab><IF-STMT><tab><tab><tab>index = 2<tab><tab><tab>tmp = f""{key_to_insert}_{index}""<tab><tab><tab>while tmp in units:<tab><tab><tab><tab>index += 1<tab><tab><tab><tab>tmp = f""{key_to_insert}_{index}""<tab><tab><tab>key_to_insert = tmp<tab><tab>units[key_to_insert] = v[""id""]<tab>return units",if key_to_insert in units :,160
4844,"def parse_clademodelc(branch_type_no, line_floats, site_classes):<tab>""""""Parse results specific to the clade model C.""""""<tab>if not site_classes or len(line_floats) == 0:<tab><tab>return<tab>for n in range(len(line_floats)):<tab><tab><IF-STMT><tab><tab><tab>site_classes[n][""branch types""] = {}<tab><tab>site_classes[n][""branch types""][branch_type_no] = line_floats[n]<tab>return site_classes","if site_classes [ n ] . get ( ""branch types"" ) is None :",134
4845,"def track_modules(self, *modules):<tab>""""""Add module names to the tracked list.""""""<tab>already_tracked = self.session.GetParameter(""autodetect_build_local_tracked"") or []<tab>needed = set(modules)<tab>if not needed.issubset(already_tracked):<tab><tab>needed.update(already_tracked)<tab><tab>with self.session as session:<tab><tab><tab>session.SetParameter(""autodetect_build_local_tracked"", needed)<tab><tab><tab>for module_name in modules:<tab><tab><tab><tab>module_obj = self.GetModuleByName(module_name)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># Clear the module's profile. This will force it to<tab><tab><tab><tab><tab># reload a new profile.<tab><tab><tab><tab><tab>module_obj.profile = None",if module_obj :,196
4846,"def set_job_on_hold(self, value, blocking=True):<tab>trigger = False<tab># don't run any locking code beyond this...<tab>if not self._job_on_hold.acquire(blocking=blocking):<tab><tab>return False<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self._job_on_hold.set()<tab><tab>else:<tab><tab><tab>self._job_on_hold.clear()<tab><tab><tab>if self._job_on_hold.counter == 0:<tab><tab><tab><tab>trigger = True<tab>finally:<tab><tab>self._job_on_hold.release()<tab># locking code is now safe to run again<tab>if trigger:<tab><tab>self._continue_sending()<tab>return True",if value :,172
4847,"def moveToThreadNext(self):<tab>""""""Move a position to threadNext position.""""""<tab>p = self<tab>if p.v:<tab><tab><IF-STMT><tab><tab><tab>p.moveToFirstChild()<tab><tab>elif p.hasNext():<tab><tab><tab>p.moveToNext()<tab><tab>else:<tab><tab><tab>p.moveToParent()<tab><tab><tab>while p:<tab><tab><tab><tab>if p.hasNext():<tab><tab><tab><tab><tab>p.moveToNext()<tab><tab><tab><tab><tab>break  # found<tab><tab><tab><tab>p.moveToParent()<tab><tab><tab># not found.<tab>return p",if p . v . children :,150
4848,"def best_image(width, height):<tab># A heuristic for finding closest sized image to required size.<tab>image = images[0]<tab>for img in images:<tab><tab><IF-STMT><tab><tab><tab># Exact match always used<tab><tab><tab>return img<tab><tab>elif img.width >= width and img.width * img.height > image.width * image.height:<tab><tab><tab># At least wide enough, and largest area<tab><tab><tab>image = img<tab>return image",if img . width == width and img . height == height :,120
4849,"def _check_input_types(self):<tab>if len(self.base_features) == 0:<tab><tab>return True<tab>input_types = self.primitive.input_types<tab>if input_types is not None:<tab><tab><IF-STMT><tab><tab><tab>input_types = [input_types]<tab><tab>for t in input_types:<tab><tab><tab>zipped = list(zip(t, self.base_features))<tab><tab><tab>if all([issubclass(f.variable_type, v) for v, f in zipped]):<tab><tab><tab><tab>return True<tab>else:<tab><tab>return True<tab>return False",if type ( input_types [ 0 ] ) != list :,154
4850,"def get_result(self):<tab>result_list = []<tab>exc_info = None<tab>for f in self.children:<tab><tab>try:<tab><tab><tab>result_list.append(f.get_result())<tab><tab>except Exception as e:<tab><tab><tab>if exc_info is None:<tab><tab><tab><tab>exc_info = sys.exc_info()<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>app_log.error(""Multiple exceptions in yield list"", exc_info=True)<tab>if exc_info is not None:<tab><tab>raise_exc_info(exc_info)<tab>if self.keys is not None:<tab><tab>return dict(zip(self.keys, result_list))<tab>else:<tab><tab>return list(result_list)","if not isinstance ( e , self . quiet_exceptions ) :",196
4851,"def _update_learning_params(self):<tab>model = self.model<tab>hparams = self.hparams<tab>fd = self.runner.feed_dict<tab>step_num = self.step_num<tab>if hparams.model_type == ""resnet_tf"":<tab><tab>if step_num < hparams.lrn_step:<tab><tab><tab>lrn_rate = hparams.mom_lrn<tab><tab><IF-STMT><tab><tab><tab>lrn_rate = hparams.mom_lrn / 10<tab><tab>elif step_num < 35000:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 100<tab><tab>else:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 1000<tab><tab>fd[model.lrn_rate] = lrn_rate",elif step_num < 30000 :,190
4852,"def topic_exists(self, arn):<tab>response = self._conn.get_all_topics()<tab>topics = response[""ListTopicsResponse""][""ListTopicsResult""][""Topics""]<tab>current_topics = []<tab>if len(topics) > 0:<tab><tab>for topic in topics:<tab><tab><tab>topic_arn = topic[""TopicArn""]<tab><tab><tab>current_topics.append(topic_arn)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",if arn in current_topics :,115
4853,"def assertStartsWith(self, expectedPrefix, text, msg=None):<tab>if not text.startswith(expectedPrefix):<tab><tab><IF-STMT><tab><tab><tab>text = text[: len(expectedPrefix) + 5] + ""...""<tab><tab>standardMsg = ""{} not found at the start of {}"".format(<tab><tab><tab>repr(expectedPrefix), repr(text)<tab><tab>)<tab><tab>self.fail(self._formatMessage(msg, standardMsg))",if len ( expectedPrefix ) + 5 < len ( text ) :,112
4854,"def validate_memory(self, value):<tab>for k, v in value.viewitems():<tab><tab><IF-STMT>  # use NoneType to unset a value<tab><tab><tab>continue<tab><tab>if not re.match(PROCTYPE_MATCH, k):<tab><tab><tab>raise serializers.ValidationError(""Process types can only contain [a-z]"")<tab><tab>if not re.match(MEMLIMIT_MATCH, str(v)):<tab><tab><tab>raise serializers.ValidationError(<tab><tab><tab><tab>""Limit format: <number><unit>, where unit = B, K, M or G""<tab><tab><tab>)<tab>return value",if v is None :,141
4855,"def open(self) -> ""KeyValueJsonDb"":<tab>""""""Create a new data base or open existing one""""""<tab>if os.path.exists(self._name):<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""%s exists and is not a file"" % self._name)<tab><tab>try:<tab><tab><tab>with open(self._name, ""r"") as _in:<tab><tab><tab><tab>self.set_records(json.load(_in))<tab><tab>except json.JSONDecodeError:<tab><tab><tab># file corrupted, reset it.<tab><tab><tab>self.commit()<tab>else:<tab><tab># make sure path exists<tab><tab>mkpath(os.path.dirname(self._name))<tab><tab>self.commit()<tab>return self",if not os . path . isfile ( self . _name ) :,180
4856,"def _calculate(self):<tab>before = self.before.data<tab>after = self.after.data<tab>self.deleted = {}<tab>self.updated = {}<tab>self.created = after.copy()<tab>for path, f in before.items():<tab><tab><IF-STMT><tab><tab><tab>self.deleted[path] = f<tab><tab><tab>continue<tab><tab>del self.created[path]<tab><tab>if f.mtime < after[path].mtime:<tab><tab><tab>self.updated[path] = after[path]",if path not in after :,125
4857,"def cache_sqs_queues_across_accounts() -> bool:<tab>function: str = f""{__name__}.{sys._getframe().f_code.co_name}""<tab># First, get list of accounts<tab>accounts_d: list = async_to_sync(get_account_id_to_name_mapping)()<tab># Second, call tasks to enumerate all the roles across all accounts<tab>for account_id in accounts_d.keys():<tab><tab><IF-STMT><tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab><tab>else:<tab><tab><tab>if account_id in config.get(""celery.test_account_ids"", []):<tab><tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab>stats.count(f""{function}.success"")<tab>return True","if config . get ( ""environment"" ) == ""prod"" :",200
4858,"def remove(self, path, config=None, error_on_path=False, defaults=None):<tab>if not path:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>return<tab>if config is not None or defaults is not None:<tab><tab><IF-STMT><tab><tab><tab>config = self._config<tab><tab>if defaults is None:<tab><tab><tab>defaults = dict(self._map.parents)<tab><tab>chain = HierarchicalChainMap(config, defaults)<tab>else:<tab><tab>chain = self._map<tab>try:<tab><tab>chain.del_by_path(path)<tab><tab>self._mark_dirty()<tab>except KeyError:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>pass",if config is None :,184
4859,"def PopulateProjectId(project_id=None):<tab>""""""Fills in a project_id from the boto config file if one is not provided.""""""<tab>if not project_id:<tab><tab>default_id = boto.config.get_value(""GSUtil"", ""default_project_id"")<tab><tab><IF-STMT><tab><tab><tab>raise ProjectIdException(""MissingProjectId"")<tab><tab>return default_id<tab>return project_id",if not default_id :,101
4860,"def set(self, name, value):<tab>with self._object_cache_lock:<tab><tab>old_value = self._object_cache.get(name)<tab><tab>ret = not old_value or int(old_value.metadata.resource_version) < int(<tab><tab><tab>value.metadata.resource_version<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._object_cache[name] = value<tab>return ret, old_value",if ret :,106
4861,"def remove(self, url):<tab>try:<tab><tab>i = self.items.index(url)<tab>except (ValueError, IndexError):<tab><tab>pass<tab>else:<tab><tab>was_selected = i in self.selectedindices()<tab><tab>self.list.delete(i)<tab><tab>del self.items[i]<tab><tab>if not self.items:<tab><tab><tab>self.mp.hidepanel(self.name)<tab><tab><IF-STMT><tab><tab><tab>if i >= len(self.items):<tab><tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>self.list.select_set(i)",elif was_selected :,150
4862,"def add_directory_csv_files(dir_path, paths=None):<tab>if not paths:<tab><tab>paths = []<tab>for p in listdir(dir_path):<tab><tab>path = join(dir_path, p)<tab><tab><IF-STMT><tab><tab><tab># call recursively for each dir<tab><tab><tab>paths = add_directory_csv_files(path, paths)<tab><tab>elif isfile(path) and path.endswith("".csv""):<tab><tab><tab># add every file to the list<tab><tab><tab>paths.append(path)<tab>return paths",if isdir ( path ) :,130
4863,"def _get_client(rp_mapping, resource_provider):<tab>for key, value in rp_mapping.items():<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, dict):<tab><tab><tab><tab>return GeneralPrivateEndpointClient(<tab><tab><tab><tab><tab>key,<tab><tab><tab><tab><tab>value[""api_version""],<tab><tab><tab><tab><tab>value[""support_list_or_not""],<tab><tab><tab><tab><tab>value[""resource_get_api_version""],<tab><tab><tab><tab>)<tab><tab><tab>return value()<tab>raise CLIError(<tab><tab>""Resource type must be one of {}"".format("", "".join(rp_mapping.keys()))<tab>)",if str . lower ( key ) == str . lower ( resource_provider ) :,165
4864,"def compute_rule_hash(self, rule):<tab>buf = ""%d-%d-%s-"" % (<tab><tab>rule.get(""FromPort"", 0) or 0,<tab><tab>rule.get(""ToPort"", 0) or 0,<tab><tab>rule.get(""IpProtocol"", ""-1"") or ""-1"",<tab>)<tab>for a, ke in self.RULE_ATTRS:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ev = [e[ke] for e in rule[a]]<tab><tab>ev.sort()<tab><tab>for e in ev:<tab><tab><tab>buf += ""%s-"" % e<tab># mask to generate the same numeric value across all Python versions<tab>return zlib.crc32(buf.encode(""ascii"")) & 0xFFFFFFFF",if a not in rule :,176
4865,"def analysis_sucess_metrics(analysis_time: float, allow_exception=False):<tab>try:<tab><tab>anchore_engine.subsys.metrics.counter_inc(name=""anchore_analysis_success"")<tab><tab>anchore_engine.subsys.metrics.histogram_observe(<tab><tab><tab>""anchore_analysis_time_seconds"",<tab><tab><tab>analysis_time,<tab><tab><tab>buckets=ANALYSIS_TIME_SECONDS_BUCKETS,<tab><tab><tab>status=""success"",<tab><tab>)<tab>except:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing""<tab><tab><tab>)",if allow_exception :,179
4866,"def decide_file_icon(file):<tab>if file.state == File.ERROR:<tab><tab>return FileItem.icon_error<tab>elif isinstance(file.parent, Track):<tab><tab><IF-STMT><tab><tab><tab>return FileItem.icon_saved<tab><tab>elif file.state == File.PENDING:<tab><tab><tab>return FileItem.match_pending_icons[int(file.similarity * 5 + 0.5)]<tab><tab>else:<tab><tab><tab>return FileItem.match_icons[int(file.similarity * 5 + 0.5)]<tab>elif file.state == File.PENDING:<tab><tab>return FileItem.icon_file_pending<tab>else:<tab><tab>return FileItem.icon_file",if file . state == File . NORMAL :,169
4867,"def deleteMenu(self, menuName):<tab>try:<tab><tab>menu = self.getMenu(menuName)<tab><tab><IF-STMT><tab><tab><tab>self.destroy(menu)<tab><tab><tab>self.destroyMenu(menuName)<tab><tab>else:<tab><tab><tab>g.es(""can't delete menu:"", menuName)<tab>except Exception:<tab><tab>g.es(""exception deleting"", menuName, ""menu"")<tab><tab>g.es_exception()",if menu :,106
4868,"def parser(cls, buf):<tab>(type_, code, csum) = struct.unpack_from(cls._PACK_STR, buf)<tab>msg = cls(type_, code, csum)<tab>offset = cls._MIN_LEN<tab>if len(buf) > offset:<tab><tab>cls_ = cls._ICMPV6_TYPES.get(type_, None)<tab><tab><IF-STMT><tab><tab><tab>msg.data = cls_.parser(buf, offset)<tab><tab>else:<tab><tab><tab>msg.data = buf[offset:]<tab>return msg, None, None",if cls_ :,133
4869,"def _load_dataset_area(self, dsid, file_handlers, coords):<tab>""""""Get the area for *dsid*.""""""<tab>try:<tab><tab>return self._load_area_def(dsid, file_handlers)<tab>except NotImplementedError:<tab><tab>if any(x is None for x in coords):<tab><tab><tab>logger.warning(""Failed to load coordinates for '{}'"".format(dsid))<tab><tab><tab>return None<tab><tab>area = self._make_area_from_coords(coords)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""No coordinates found for %s"", str(dsid))<tab><tab>return area",if area is None :,148
4870,"def __getattr__(self, name):<tab>if Popen.verbose:<tab><tab>sys.stdout.write(""Getattr: %s..."" % name)<tab>if name in Popen.__slots__:<tab><tab>return object.__getattribute__(self, name)<tab>else:<tab><tab>if self.popen is not None:<tab><tab><tab>if Popen.verbose:<tab><tab><tab><tab>print(""from Popen"")<tab><tab><tab>return getattr(self.popen, name)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.emu_wait<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""subprocess emulation: not implemented: %s"" % name)","if name == ""wait"" :",156
4871,"def update(self, time_delta):<tab>super().update(time_delta)<tab>n = self.menu.selected_option<tab>if n == self.last:<tab><tab>return<tab>self.last = n<tab>s = """"<tab>for i in range(len(self.files)):<tab><tab><IF-STMT><tab><tab><tab>for l in open(self.files[i][1]):<tab><tab><tab><tab>x = l.strip()<tab><tab><tab><tab>if len(x) > 1 and x[0] == ""#"":<tab><tab><tab><tab><tab>x = ""<b><u>"" + x[1:] + "" </u></b>""<tab><tab><tab><tab>s += x + ""<br>""<tab>self.set_text(s)",if self . files [ i ] [ 0 ] == n :,178
4872,"def wrapper(*args, **kwargs):<tab>list_args, empty = _apply_defaults(func, args, kwargs)<tab>if len(dimensions) > len(list_args):<tab><tab>raise TypeError(<tab><tab><tab>""%s takes %i parameters, but %i dimensions were passed""<tab><tab><tab>% (func.__name__, len(list_args), len(dimensions))<tab><tab>)<tab>for dim, value in zip(dimensions, list_args):<tab><tab>if dim is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>val_dim = ureg.get_dimensionality(value)<tab><tab><tab>raise DimensionalityError(value, ""a quantity of"", val_dim, dim)<tab>return func(*args, **kwargs)",if not ureg . Quantity ( value ) . check ( dim ) :,182
4873,"def _check(self, name, size=None, *extra):<tab>func = getattr(imageop, name)<tab>for height in VALUES:<tab><tab>for width in VALUES:<tab><tab><tab>strlen = abs(width * height)<tab><tab><tab>if size:<tab><tab><tab><tab>strlen *= size<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = ""A"" * strlen<tab><tab><tab>else:<tab><tab><tab><tab>data = AAAAA<tab><tab><tab>if size:<tab><tab><tab><tab>arguments = (data, size, width, height) + extra<tab><tab><tab>else:<tab><tab><tab><tab>arguments = (data, width, height) + extra<tab><tab><tab>try:<tab><tab><tab><tab>func(*arguments)<tab><tab><tab>except (ValueError, imageop.error):<tab><tab><tab><tab>pass",if strlen < MAX_LEN :,188
4874,"def wait_send_all_might_not_block(self) -> None:<tab>with self._send_conflict_detector:<tab><tab><IF-STMT><tab><tab><tab>raise trio.ClosedResourceError(""file was already closed"")<tab><tab>try:<tab><tab><tab>await trio.lowlevel.wait_writable(self._fd_holder.fd)<tab><tab>except BrokenPipeError as e:<tab><tab><tab># kqueue: raises EPIPE on wait_writable instead<tab><tab><tab># of sending, which is annoying<tab><tab><tab>raise trio.BrokenResourceError from e",if self . _fd_holder . closed :,135
4875,"def parse_win_proxy(val):<tab>proxies = []<tab>for p in val.split("";""):<tab><tab>if ""="" in p:<tab><tab><tab>tab = p.split(""="", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tab[0] = ""SOCKS4""<tab><tab><tab>proxies.append(<tab><tab><tab><tab>(tab[0].upper(), tab[1], None, None)<tab><tab><tab>)  # type, addr:port, username, password<tab><tab>else:<tab><tab><tab>proxies.append((""HTTP"", p, None, None))<tab>return proxies","if tab [ 0 ] == ""socks"" :",142
4876,"def _super_function(args):<tab>passed_class, passed_self = args.get_arguments([""type"", ""self""])<tab>if passed_self is None:<tab><tab>return passed_class<tab>else:<tab><tab># pyclass = passed_self.get_type()<tab><tab>pyclass = passed_class<tab><tab>if isinstance(pyclass, pyobjects.AbstractClass):<tab><tab><tab>supers = pyclass.get_superclasses()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pyobjects.PyObject(supers[0])<tab><tab>return passed_self",if supers :,132
4877,"def update_output_mintime(job):<tab>try:<tab><tab>return output_mintime[job]<tab>except KeyError:<tab><tab>for job_ in chain([job], self.depending[job]):<tab><tab><tab>try:<tab><tab><tab><tab>t = output_mintime[job_]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>t = job_.output_mintime<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output_mintime[job] = t<tab><tab><tab><tab>return<tab><tab>output_mintime[job] = None",if t is not None :,136
4878,"def get_list_of_strings_to_mongo_objects(self, notifications_list=None):<tab>result = []<tab>if len(notifications_list) > 0:<tab><tab>for x in notifications_list:<tab><tab><tab>split_provider_id = x.split("":"")  # email:id<tab><tab><tab>if len(split_provider_id) == 2:<tab><tab><tab><tab>_id = split_provider_id[1]<tab><tab><tab><tab>cursor = self.get_by_id(_id)<tab><tab><tab><tab><IF-STMT>  # Append if exists<tab><tab><tab><tab><tab>result.append(cursor)<tab>return result",if cursor :,148
4879,"def stop(self):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.task_queue.put(None)<tab><tab>self.result_queue.put(None)<tab><tab>process = self.process<tab><tab>self.process = None<tab><tab>self.task_queue = None<tab><tab>self.result_queue = None<tab>process.join(timeout=0.1)<tab>if process.exitcode is None:<tab><tab>os.kill(process.pid, signal.SIGKILL)<tab><tab>process.join()",if not self . process :,132
4880,"def on_api_command(self, command, data):<tab>if command == ""select"":<tab><tab>if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can():<tab><tab><tab>return flask.abort(403, ""Insufficient permissions"")<tab><tab><IF-STMT><tab><tab><tab>return flask.abort(409, ""No active prompt"")<tab><tab>choice = data[""choice""]<tab><tab>if not isinstance(choice, int) or not self._prompt.validate_choice(choice):<tab><tab><tab>return flask.abort(<tab><tab><tab><tab>400, ""{!r} is not a valid value for choice"".format(choice)<tab><tab><tab>)<tab><tab>self._answer_prompt(choice)",if self . _prompt is None :,164
4881,"def application_openFiles_(self, nsapp, filenames):<tab># logging.info('[osx] file open')<tab># logging.info('[osx] file : %s' % (filenames))<tab>for filename in filenames:<tab><tab>logging.info(""[osx] receiving from macOS : %s"", filename)<tab><tab><IF-STMT><tab><tab><tab>if sabnzbd.filesystem.get_ext(filename) in VALID_ARCHIVES + VALID_NZB_FILES:<tab><tab><tab><tab>sabnzbd.add_nzbfile(filename, keep=True)",if os . path . exists ( filename ) :,136
4882,"def test_error_through_destructor(self):<tab># Test that the exception state is not modified by a destructor,<tab># even if close() fails.<tab>rawio = self.CloseFailureIO()<tab>with support.catch_unraisable_exception() as cm:<tab><tab>with self.assertRaises(AttributeError):<tab><tab><tab>self.tp(rawio).xyzzy<tab><tab><IF-STMT><tab><tab><tab>self.assertIsNone(cm.unraisable)<tab><tab>elif cm.unraisable is not None:<tab><tab><tab>self.assertEqual(cm.unraisable.exc_type, OSError)",if not IOBASE_EMITS_UNRAISABLE :,157
4883,"def http_wrapper(self, url, postdata={}):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>f = urllib.urlopen(url, postdata)<tab><tab>else:<tab><tab><tab>f = urllib.urlopen(url)<tab><tab>response = f.read()<tab>except:<tab><tab>import traceback<tab><tab>import logging, sys<tab><tab>cla, exc, tb = sys.exc_info()<tab><tab>logging.error(url)<tab><tab>if postdata:<tab><tab><tab>logging.error(""with post data"")<tab><tab>else:<tab><tab><tab>logging.error(""without post data"")<tab><tab>logging.error(exc.args)<tab><tab>logging.error(traceback.format_tb(tb))<tab><tab>response = """"<tab>return response",if postdata != { } :,178
4884,"def check_single_file(fn, fetchuri):<tab>""""""Determine if a single downloaded file is something we can't handle""""""<tab>with open(fn, ""r"", errors=""surrogateescape"") as f:<tab><tab><IF-STMT><tab><tab><tab>logger.error(<tab><tab><tab><tab>'Fetching ""%s"" returned a single HTML page - check the URL is correct and functional'<tab><tab><tab><tab>% fetchuri<tab><tab><tab>)<tab><tab><tab>sys.exit(1)","if ""<html"" in f . read ( 100 ) . lower ( ) :",117
4885,"def update_properties(self, update_dict):<tab>signed_attribute_changed = False<tab>for k, value in update_dict.items():<tab><tab>if getattr(self, k) != value:<tab><tab><tab>setattr(self, k, value)<tab><tab><tab>signed_attribute_changed = signed_attribute_changed or (<tab><tab><tab><tab>k in self.payload_arguments<tab><tab><tab>)<tab>if signed_attribute_changed:<tab><tab><IF-STMT><tab><tab><tab>self.status = UPDATED<tab><tab>self.timestamp = clock.tick()<tab><tab>self.sign()<tab>return self",if self . status != NEW :,145
4886,"def clean_items(event, items, variations):<tab>for item in items:<tab><tab>if event != item.event:<tab><tab><tab>raise ValidationError(_(""One or more items do not belong to this event.""))<tab><tab>if item.has_variations:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(<tab><tab><tab><tab><tab><tab>""One or more items has variations but none of these are in the variations list.""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",if not any ( var . item == item for var in variations ) :,127
4887,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_status().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.add_doc_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,169
4888,"def connections(self):<tab># Connections look something like this:<tab># socket:[102422]<tab>fds = self.open_files<tab>socket = ""socket:[""<tab>result = []<tab>functions = [pwndbg.net.tcp, pwndbg.net.unix, pwndbg.net.netlink]<tab>for fd, path in fds.items():<tab><tab>if socket not in path:<tab><tab><tab>continue<tab><tab>inode = path[len(socket) : -1]<tab><tab>inode = int(inode)<tab><tab>for func in functions:<tab><tab><tab>for x in func():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>x.fd = fd<tab><tab><tab><tab><tab>result.append(x)<tab>return tuple(result)",if x . inode == inode :,184
4889,"def _movement_finished(self):<tab>if self.in_ship_map:<tab><tab># if the movement somehow stops, the position sticks, and the unit isn't at next_target any more<tab><tab><IF-STMT><tab><tab><tab>ship = self.session.world.ship_map.get(self._next_target.to_tuple())<tab><tab><tab>if ship is not None and ship() is self:<tab><tab><tab><tab>del self.session.world.ship_map[self._next_target.to_tuple()]<tab>super()._movement_finished()",if self . _next_target is not None :,136
4890,"def print_addresses(self):<tab>p = 3<tab>tmp_str = ""[""<tab>if self.get_len() >= 7:  # at least one complete IP address<tab><tab>while 1:<tab><tab><tab>if p + 1 == self.get_ptr():<tab><tab><tab><tab>tmp_str += ""#""<tab><tab><tab>tmp_str += self.get_ip_address(p)<tab><tab><tab>p += 4<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>tmp_str += "", ""<tab>tmp_str += ""] ""<tab>if self.get_ptr() % 4:  # ptr field should be a multiple of 4<tab><tab>tmp_str += ""nonsense ptr field: %d "" % self.get_ptr()<tab>return tmp_str",if p >= self . get_len ( ) :,191
4891,"def source_shapes(self):<tab>""""""Prints debug information about the sources in this provider.""""""<tab>if logger.isEnabledFor(logging.DEBUG):<tab><tab>for i, source in enumerate(self.sources):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = ""anonymous""<tab><tab><tab>else:<tab><tab><tab><tab>name = self.keys[i]<tab><tab><tab>try:<tab><tab><tab><tab>shape = source.shape()<tab><tab><tab>except NotImplementedError:<tab><tab><tab><tab>shape = ""N/A""<tab><tab><tab>logger.debug(<tab><tab><tab><tab>'Data source ""%s"": entries=%s, shape=%s', name, len(source), shape<tab><tab><tab>)",if self . keys is None :,161
4892,def swap_actions(actions):<tab>for mutexgroup in mutex_groups:<tab><tab>mutex_actions = mutexgroup._group_actions<tab><tab><IF-STMT><tab><tab><tab># make a best guess as to where we should store the group<tab><tab><tab>targetindex = actions.index(mutexgroup._group_actions[0])<tab><tab><tab># insert the _ArgumentGroup container<tab><tab><tab>actions[targetindex] = mutexgroup<tab><tab><tab># remove the duplicated individual actions<tab><tab><tab>actions = [action for action in actions if action not in mutex_actions]<tab>return actions,"if contains_actions ( mutex_actions , actions ) :",147
4893,"def rec_deps(services, container_by_name, cnt, init_service):<tab>deps = cnt[""_deps""]<tab>for dep in deps.copy():<tab><tab>dep_cnts = services.get(dep)<tab><tab>if not dep_cnts:<tab><tab><tab>continue<tab><tab>dep_cnt = container_by_name.get(dep_cnts[0])<tab><tab>if dep_cnt:<tab><tab><tab># TODO: avoid creating loops, A->B->A<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>new_deps = rec_deps(services, container_by_name, dep_cnt, init_service)<tab><tab><tab>deps.update(new_deps)<tab>return deps","if init_service and init_service in dep_cnt [ ""_deps"" ] :",181
4894,"def make_dump_list_by_name_list(name_list):<tab>info_list = []<tab>for info_name in name_list:<tab><tab>info = next((x for x in DUMP_LIST if x.info_name == info_name), None)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError('Unknown info name: ""{}""'.format(info_name))<tab><tab>info_list.append(info)<tab>return info_list",if not info :,106
4895,"def create(self, private=False):<tab>try:<tab><tab>if private:<tab><tab><tab>log.info(""Creating private channel %s."", self)<tab><tab><tab>self._bot.api_call(<tab><tab><tab><tab>""conversations.create"", data={""name"": self.name, ""is_private"": True}<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>log.info(""Creating channel %s."", self)<tab><tab><tab>self._bot.api_call(""conversations.create"", data={""name"": self.name})<tab>except SlackAPIResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)","if e . error == ""user_is_bot"" :",189
4896,"def talk(self, words):<tab>if self.writeSentence(words) == 0:<tab><tab>return<tab>r = []<tab>while 1:<tab><tab>i = self.readSentence()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>reply = i[0]<tab><tab>attrs = {}<tab><tab>for w in i[1:]:<tab><tab><tab>j = w.find(""="", 1)<tab><tab><tab>if j == -1:<tab><tab><tab><tab>attrs[w] = """"<tab><tab><tab>else:<tab><tab><tab><tab>attrs[w[:j]] = w[j + 1 :]<tab><tab>r.append((reply, attrs))<tab><tab>if reply == ""!done"":<tab><tab><tab>return r",if len ( i ) == 0 :,169
4897,"def _load_logfile(self, lfn):<tab>enc_key = self.decryption_key_func()<tab>with open(os.path.join(self.logdir, lfn)) as fd:<tab><tab><IF-STMT><tab><tab><tab>with DecryptingStreamer(<tab><tab><tab><tab>fd, mep_key=enc_key, name=""EventLog/DS(%s)"" % lfn<tab><tab><tab>) as streamer:<tab><tab><tab><tab>lines = streamer.read()<tab><tab><tab><tab>streamer.verify(_raise=IOError)<tab><tab>else:<tab><tab><tab>lines = fd.read()<tab><tab>if lines:<tab><tab><tab>for line in lines.splitlines():<tab><tab><tab><tab>event = Event.Parse(line.strip())<tab><tab><tab><tab>self._events[event.event_id] = event",if enc_key :,191
4898,"def set_ok_port(self, cookie, request):<tab>if cookie.port_specified:<tab><tab>req_port = request_port(request)<tab><tab>if req_port is None:<tab><tab><tab>req_port = ""80""<tab><tab>else:<tab><tab><tab>req_port = str(req_port)<tab><tab>for p in cookie.port.split("",""):<tab><tab><tab>try:<tab><tab><tab><tab>int(p)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>debug(""   bad port %s (not numeric)"", p)<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>debug(""   request port (%s) not found in %s"", req_port, cookie.port)<tab><tab><tab>return False<tab>return True",if p == req_port :,195
4899,"def get_attribute_value(self, nodeid, attr):<tab>with self._lock:<tab><tab>self.logger.debug(""get attr val: %s %s"", nodeid, attr)<tab><tab><IF-STMT><tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown)<tab><tab><tab>return dv<tab><tab>node = self._nodes[nodeid]<tab><tab>if attr not in node.attributes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid)<tab><tab><tab>return dv<tab><tab>attval = node.attributes[attr]<tab><tab>if attval.value_callback:<tab><tab><tab>return attval.value_callback()<tab><tab>return attval.value",if nodeid not in self . _nodes :,200
4900,"def data_logging_status(self, trail_name, trail_details, api_client):<tab>for es in api_client.get_event_selectors(TrailName=trail_name)[""EventSelectors""]:<tab><tab>has_wildcard = {<tab><tab><tab>u""Values"": [u""arn:aws:s3:::""],<tab><tab><tab>u""Type"": u""AWS::S3::Object"",<tab><tab>} in es[""DataResources""]<tab><tab>is_logging = trail_details[""IsLogging""]<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,149
4901,"def pytest_deselected(items):<tab>if sb_config.dashboard:<tab><tab>sb_config.item_count -= len(items)<tab><tab>for item in items:<tab><tab><tab>test_id, display_id = _get_test_ids_(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sb_config._results.pop(test_id)",if test_id in sb_config . _results . keys ( ) :,96
4902,"def _visit(self, func):<tab>fname = func[0]<tab>if fname in self._flags:<tab><tab>if self._flags[fname] == 1:<tab><tab><tab>logger.critical(""Fatal error! network ins not Dag."")<tab><tab><tab>import sys<tab><tab><tab>sys.exit(-1)<tab><tab>else:<tab><tab><tab>return<tab>else:<tab><tab>if fname not in self._flags:<tab><tab><tab>self._flags[fname] = 1<tab><tab>for output in func[3]:<tab><tab><tab>for f in self._orig:<tab><tab><tab><tab>for input in f[2]:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self._visit(f)<tab>self._flags[fname] = 2<tab>self._sorted.insert(0, func)",if output == input :,188
4903,"def printWiki():<tab>firstHeading = False<tab>for m in protocol:<tab><tab><IF-STMT><tab><tab><tab>if firstHeading:<tab><tab><tab><tab>output(""|}"")<tab><tab><tab>__printWikiHeader(m[1], m[2])<tab><tab><tab>firstHeading = True<tab><tab>else:<tab><tab><tab>output(""|-"")<tab><tab><tab>output(<tab><tab><tab><tab>'| <span style=""white-space:nowrap;""><tt>'<tab><tab><tab><tab>+ m[0]<tab><tab><tab><tab>+ ""</tt></span> || || ""<tab><tab><tab><tab>+ m[1]<tab><tab><tab>)<tab>output(""|}"")","if m [ 0 ] == """" :",155
4904,"def test_getitem(self):<tab>n = 200<tab>d = deque(range(n))<tab>l = list(range(n))<tab>for i in range(n):<tab><tab>d.popleft()<tab><tab>l.pop(0)<tab><tab><IF-STMT><tab><tab><tab>d.append(i)<tab><tab><tab>l.append(i)<tab><tab>for j in range(1 - len(l), len(l)):<tab><tab><tab>assert d[j] == l[j]<tab>d = deque(""superman"")<tab>self.assertEqual(d[0], ""s"")<tab>self.assertEqual(d[-1], ""n"")<tab>d = deque()<tab>self.assertRaises(IndexError, d.__getitem__, 0)<tab>self.assertRaises(IndexError, d.__getitem__, -1)",if random . random ( ) < 0.5 :,193
4905,"def get_num(line, char_ptr, num_chars):<tab>char_ptr = char_ptr + 1<tab>numstr = """"<tab>good = ""-.0123456789""<tab>while char_ptr < num_chars:<tab><tab>digit = line[char_ptr]<tab><tab><IF-STMT><tab><tab><tab>numstr = numstr + digit<tab><tab><tab>char_ptr = char_ptr + 1<tab><tab>else:<tab><tab><tab>break<tab>return numstr",if good . find ( digit ) != - 1 :,116
4906,"def read_digits(source, start, first_code):<tab>body = source.body<tab>position = start<tab>code = first_code<tab>if code is not None and 48 <= code <= 57:  # 0 - 9<tab><tab>while True:<tab><tab><tab>position += 1<tab><tab><tab>code = char_code_at(body, position)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>return position<tab>raise GraphQLSyntaxError(<tab><tab>source,<tab><tab>position,<tab><tab>u""Invalid number, expected digit but got: {}."".format(print_char_code(code)),<tab>)",if not ( code is not None and 48 <= code <= 57 ) :,155
4907,"def get_aws_metadata(headers, provider=None):<tab>if not provider:<tab><tab>provider = boto.provider.get_default()<tab>metadata_prefix = provider.metadata_prefix<tab>metadata = {}<tab>for hkey in headers.keys():<tab><tab><IF-STMT><tab><tab><tab>val = urllib.unquote_plus(headers[hkey])<tab><tab><tab>try:<tab><tab><tab><tab>metadata[hkey[len(metadata_prefix) :]] = unicode(val, ""utf-8"")<tab><tab><tab>except UnicodeDecodeError:<tab><tab><tab><tab>metadata[hkey[len(metadata_prefix) :]] = val<tab><tab><tab>del headers[hkey]<tab>return metadata",if hkey . lower ( ) . startswith ( metadata_prefix ) :,164
4908,"def _process_rtdest(self):<tab>LOG.debug(""Processing RT NLRI destination..."")<tab>if self._rtdest_queue.is_empty():<tab><tab>return<tab>else:<tab><tab>processed_any = False<tab><tab>while not self._rtdest_queue.is_empty():<tab><tab><tab># We process the first destination in the queue.<tab><tab><tab>next_dest = self._rtdest_queue.pop_first()<tab><tab><tab>if next_dest:<tab><tab><tab><tab>next_dest.process()<tab><tab><tab><tab>processed_any = True<tab><tab><IF-STMT><tab><tab><tab># Since RT destination were updated we update RT filters<tab><tab><tab>self._core_service.update_rtfilters()",if processed_any :,171
4909,"def _get_header(self, requester, header_name):<tab>hits = sum([header_name in headers for _, headers in requester.requests])<tab>self.assertEquals(hits, 2 if self.revs_enabled else 1)<tab>for url, headers in requester.requests:<tab><tab>if header_name in headers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertTrue(url.endswith(""/latest""), msg=url)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertTrue(url.endswith(""/download_urls""), msg=url)<tab><tab><tab>return headers.get(header_name)",if self . revs_enabled :,143
4910,"def add_external_deps(self, deps):<tab>for dep in deps:<tab><tab>if hasattr(dep, ""el""):<tab><tab><tab>dep = dep.el<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArguments(""Argument is not an external dependency"")<tab><tab>self.external_deps.append(dep)<tab><tab>if isinstance(dep, dependencies.Dependency):<tab><tab><tab>self.process_sourcelist(dep.get_sources())","if not isinstance ( dep , dependencies . Dependency ) :",109
4911,"def _consume_msg(self):<tab>ws = self._ws<tab>try:<tab><tab>while True:<tab><tab><tab>r = await ws.recv()<tab><tab><tab>if isinstance(r, bytes):<tab><tab><tab><tab>r = r.decode(""utf-8"")<tab><tab><tab>msg = json.loads(r)<tab><tab><tab>stream = msg.get(""stream"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await self._dispatch(stream, msg)<tab>except websockets.WebSocketException as wse:<tab><tab>logging.warn(wse)<tab><tab>await self.close()<tab><tab>asyncio.ensure_future(self._ensure_ws())",if stream is not None :,158
4912,"def generate_and_check_random():<tab>random_size = 256<tab>while True:<tab><tab>random = os.urandom(random_size)<tab><tab>a = int.from_bytes(random, ""big"")<tab><tab>A = pow(g, a, p)<tab><tab><IF-STMT><tab><tab><tab>a_for_hash = big_num_for_hash(A)<tab><tab><tab>u = int.from_bytes(sha256(a_for_hash, b_for_hash), ""big"")<tab><tab><tab>if u > 0:<tab><tab><tab><tab>return (a, a_for_hash, u)","if is_good_mod_exp_first ( A , p ) :",158
4913,"def write(self, datagram, address):<tab>""""""Write a datagram.""""""<tab>try:<tab><tab>return self.socket.sendto(datagram, address)<tab>except OSError as se:<tab><tab>no = se.args[0]<tab><tab>if no == EINTR:<tab><tab><tab>return self.write(datagram, address)<tab><tab>elif no == EMSGSIZE:<tab><tab><tab>raise error.MessageLengthError(""message too long"")<tab><tab><IF-STMT><tab><tab><tab># oh, well, drop the data. The only difference from UDP<tab><tab><tab># is that UDP won't ever notice.<tab><tab><tab># TODO: add TCP-like buffering<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise",elif no == EAGAIN :,176
4914,"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if child.tagName == ""Directory"":<tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab>if not isinstance(grandchild, minidom.Element):<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if grandchild.tagName != ""File"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))","if not isinstance ( child , minidom . Element ) :",152
4915,"def add_reversed_tensor(i, X, reversed_X):<tab># Do not keep tensors that should stop the mapping.<tab>if X in stop_mapping_at_tensors:<tab><tab>return<tab>if X not in reversed_tensors:<tab><tab>reversed_tensors[X] = {""id"": (nid, i), ""tensor"": reversed_X}<tab>else:<tab><tab>tmp = reversed_tensors[X]<tab><tab>if ""tensor"" in tmp and ""tensors"" in tmp:<tab><tab><tab>raise Exception(""Wrong order, tensors already aggregated!"")<tab><tab><IF-STMT><tab><tab><tab>tmp[""tensors""] = [tmp[""tensor""], reversed_X]<tab><tab><tab>del tmp[""tensor""]<tab><tab>else:<tab><tab><tab>tmp[""tensors""].append(reversed_X)","if ""tensor"" in tmp :",183
4916,"def walk(source, path, default, delimiter="".""):<tab>""""""Walk the sourch hash given the path and return the value or default if not found""""""<tab>if not isinstance(source, dict):<tab><tab>raise RuntimeError(<tab><tab><tab>""The source is not a walkable dict: {} path: {}"".format(source, path)<tab><tab>)<tab>keys = path.split(delimiter)<tab>max_depth = len(keys)<tab>cur_depth = 0<tab>while cur_depth < max_depth:<tab><tab><IF-STMT><tab><tab><tab>source = source[keys[cur_depth]]<tab><tab><tab>cur_depth = cur_depth + 1<tab><tab>else:<tab><tab><tab>return default<tab>return source",if keys [ cur_depth ] in source :,171
4917,"def _from_txt_get_vulns(self):<tab>file_vulns = []<tab>vuln_regex = (<tab><tab>'SQL injection in a .*? was found at: ""(.*?)""'<tab><tab>', using HTTP method (.*?). The sent .*?data was: ""(.*?)""'<tab>)<tab>vuln_re = re.compile(vuln_regex)<tab>for line in file(self.OUTPUT_FILE):<tab><tab>mo = vuln_re.search(line)<tab><tab><IF-STMT><tab><tab><tab>v = MockVuln(""TestCase"", None, ""High"", 1, ""plugin"")<tab><tab><tab>v.set_url(URL(mo.group(1)))<tab><tab><tab>v.set_method(mo.group(2))<tab><tab><tab>file_vulns.append(v)<tab>return file_vulns",if mo :,194
4918,"def __get__(self, instance, instance_type=None):<tab>if instance:<tab><tab>if self.att_name not in instance._obj_cache:<tab><tab><tab>rel_obj = self.get_obj(instance)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>instance._obj_cache[self.att_name] = rel_obj<tab><tab>return instance._obj_cache.get(self.att_name)<tab>return self",if rel_obj :,105
4919,"def get_ranges_from_func_set(support_set):<tab>pos_start = 0<tab>pos_end = 0<tab>ranges = []<tab>for pos, func in enumerate(network.function):<tab><tab><IF-STMT><tab><tab><tab>pos_end = pos<tab><tab>else:<tab><tab><tab>if pos_end >= pos_start:<tab><tab><tab><tab>ranges.append((pos_start, pos_end))<tab><tab><tab>pos_start = pos + 1<tab>if pos_end >= pos_start:<tab><tab>ranges.append((pos_start, pos_end))<tab>return ranges",if func . type in support_set :,145
4920,"def get_all_active_plugins(self) -> List[BotPlugin]:<tab>""""""This returns the list of plugins in the callback ordered defined from the config.""""""<tab>all_plugins = []<tab>for name in self.plugins_callback_order:<tab><tab># None is a placeholder for any plugin not having a defined order<tab><tab>if name is None:<tab><tab><tab>all_plugins += [<tab><tab><tab><tab>plugin<tab><tab><tab><tab>for name, plugin in self.plugins.items()<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab>else:<tab><tab><tab>plugin = self.plugins[name]<tab><tab><tab>if plugin.is_activated:<tab><tab><tab><tab>all_plugins.append(plugin)<tab>return all_plugins",if name not in self . plugins_callback_order and plugin . is_activated,186
4921,"def render_token_list(self, tokens):<tab>result = []<tab>vars = []<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>result.append(token.contents.replace(""%"", ""%%""))<tab><tab>elif token.token_type == TOKEN_VAR:<tab><tab><tab>result.append(""%%(%s)s"" % token.contents)<tab><tab><tab>vars.append(token.contents)<tab>msg = """".join(result)<tab>if self.trimmed:<tab><tab>msg = translation.trim_whitespace(msg)<tab>return msg, vars",if token . token_type == TOKEN_TEXT :,139
4922,"def test_build_root_config_overwrite(self):<tab>cfg = build_root_config(""tests.files.settings_overwrite"")<tab>for key, val in DEFAULT_SPIDER_GLOBAL_CONFIG.items():<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(cfg[""global""][key], [""zzz""])<tab><tab>else:<tab><tab><tab>self.assertEqual(cfg[""global""][key], val)","if key == ""spider_modules"" :",98
4923,"def get_limit(self, request):<tab>if self.limit_query_param:<tab><tab>try:<tab><tab><tab>limit = int(request.query_params[self.limit_query_param])<tab><tab><tab>if limit < 0:<tab><tab><tab><tab>raise ValueError()<tab><tab><tab># Enforce maximum page size, if defined<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if limit == 0:<tab><tab><tab><tab><tab>return settings.MAX_PAGE_SIZE<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return min(limit, settings.MAX_PAGE_SIZE)<tab><tab><tab>return limit<tab><tab>except (KeyError, ValueError):<tab><tab><tab>pass<tab>return self.default_limit",if settings . MAX_PAGE_SIZE :,169
4924,"def track_handler(handler):<tab>tid = handler.request.tid<tab>for event in events_monitored:<tab><tab><IF-STMT><tab><tab><tab>e = Event(event, handler.request.execution_time)<tab><tab><tab>State.tenant_state[tid].RecentEventQ.append(e)<tab><tab><tab>State.tenant_state[tid].EventQ.append(e)<tab><tab><tab>break","if event [ ""handler_check"" ] ( handler ) :",105
4925,"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_subscription().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",if tt == 0 :,138
4926,"def GetCreateInstanceBinder(self, info):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>return self._createInstanceBinders[info]<tab><tab>b = runtime.SymplCreateInstanceBinder(info)<tab><tab>self._createInstanceBinders[info] = b<tab>return b",if self . _createInstanceBinders . ContainsKey ( info ) :,83
4927,"def process_task(self, body, message):<tab>if ""control"" in body:<tab><tab>try:<tab><tab><tab>return self.control(body, message)<tab><tab>except Exception:<tab><tab><tab>logger.exception(""Exception handling control message:"")<tab><tab><tab>return<tab>if len(self.pool):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>queue = UUID(body[""uuid""]).int % len(self.pool)<tab><tab><tab>except Exception:<tab><tab><tab><tab>queue = self.total_messages % len(self.pool)<tab><tab>else:<tab><tab><tab>queue = self.total_messages % len(self.pool)<tab>else:<tab><tab>queue = 0<tab>self.pool.write(queue, body)<tab>self.total_messages += 1<tab>message.ack()","if ""uuid"" in body and body [ ""uuid"" ] :",199
4928,"def is_defined_in_base_class(self, var: Var) -> bool:<tab>if var.info:<tab><tab>for base in var.info.mro[1:]:<tab><tab><tab>if base.get(var.name) is not None:<tab><tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",if var . info . fallback_to_any :,90
4929,"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab>if col == LAND:<tab><tab><tab><tab>tmp += "".""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""%""<tab><tab><tab>elif col == FOOD:<tab><tab><tab><tab>tmp += ""*""<tab><tab><tab>elif col == UNSEEN:<tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",elif col == BARRIER :,199
4930,"def prompt_for_resume(config):<tab>logger = logging.getLogger(""changeme"")<tab>logger.error(<tab><tab>""A previous scan was interrupted. Type R to resume or F to start a fresh scan""<tab>)<tab>answer = """"<tab>while not (answer == ""R"" or answer == ""F""):<tab><tab>prompt = ""(R/F)> ""<tab><tab>answer = """"<tab><tab>try:<tab><tab><tab>answer = raw_input(prompt)<tab><tab>except NameError:<tab><tab><tab>answer = input(prompt)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Forcing a fresh scan"")<tab><tab>elif answer.upper() == ""R"":<tab><tab><tab>logger.debug(""Resuming previous scan"")<tab><tab><tab>config.resume = True<tab>return config.resume","if answer . upper ( ) == ""F"" :",189
4931,"def f(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab><IF-STMT><tab><tab><tab>if view.line(s.b).size() > 0:<tab><tab><tab><tab>eol = view.line(s.b).b<tab><tab><tab><tab>return R(s.b, eol)<tab><tab><tab>return s<tab>return s",if count == 1 :,85
4932,"def flush(self):<tab>if not self.cuts:<tab><tab>return<tab>for move, (x, y, z), cent in douglas(self.cuts, self.tolerance, self.plane):<tab><tab><IF-STMT><tab><tab><tab>self.write(""%s X%.4f Y%.4f Z%.4f %s"" % (move, x, y, z, cent))<tab><tab><tab>self.lastgcode = None<tab><tab><tab>self.lastx = x<tab><tab><tab>self.lasty = y<tab><tab><tab>self.lastz = z<tab><tab>else:<tab><tab><tab>self.move_common(x, y, z, gcode=""G1"")<tab>self.cuts = []",if cent :,167
4933,"def copy_shell(self):<tab>cls = self.__class__<tab>old_id = cls.id<tab>new_i = cls()  # create a new group<tab>new_i.id = self.id  # with the same id<tab>cls.id = old_id  # Reset the Class counter<tab># Copy all properties<tab>for prop in cls.properties:<tab><tab><IF-STMT><tab><tab><tab>if self.has(prop):<tab><tab><tab><tab>val = getattr(self, prop)<tab><tab><tab><tab>setattr(new_i, prop, val)<tab># but no members<tab>new_i.members = []<tab>return new_i","if prop is not ""members"" :",156
4934,"def find_region_by_value(key, value):<tab>for region in cognitoidp_backends:<tab><tab>backend = cognitoidp_backends[region]<tab><tab>for user_pool in backend.user_pools.values():<tab><tab><tab>if key == ""client_id"" and value in user_pool.clients:<tab><tab><tab><tab>return region<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return region<tab># If we can't find the `client_id` or `access_token`, we just pass<tab># back a default backend region, which will raise the appropriate<tab># error message (e.g. NotAuthorized or NotFound).<tab>return list(cognitoidp_backends)[0]","if key == ""access_token"" and value in user_pool . access_tokens :",184
4935,"def __init__(<tab>self, fixed: MQTTFixedHeader = None, variable_header: PacketIdVariableHeader = None):<tab>if fixed is None:<tab><tab>header = MQTTFixedHeader(PUBREL, 0x02)  # [MQTT-3.6.1-1]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise HBMQTTException(<tab><tab><tab><tab>""Invalid fixed packet type %s for PubrelPacket init"" % fixed.packet_type<tab><tab><tab>)<tab><tab>header = fixed<tab>super().__init__(header)<tab>self.variable_header = variable_header<tab>self.payload = None",if fixed . packet_type is not PUBREL :,163
4936,"def _on_event_MetadataStatisticsUpdated(self, event, data):<tab>with self._selectedFileMutex:<tab><tab><IF-STMT><tab><tab><tab>self._setJobData(<tab><tab><tab><tab>self._selectedFile[""filename""],<tab><tab><tab><tab>self._selectedFile[""filesize""],<tab><tab><tab><tab>self._selectedFile[""sd""],<tab><tab><tab><tab>self._selectedFile[""user""],<tab><tab><tab>)",if self . _selectedFile :,99
4937,"def _validate_parameter_range(self, value_hp, parameter_range):<tab>""""""Placeholder docstring""""""<tab>for (<tab><tab>parameter_range_key,<tab><tab>parameter_range_value,<tab>) in parameter_range.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Categorical ranges<tab><tab>if isinstance(parameter_range_value, list):<tab><tab><tab>for categorical_value in parameter_range_value:<tab><tab><tab><tab>value_hp.validate(categorical_value)<tab><tab># Continuous, Integer ranges<tab><tab>else:<tab><tab><tab>value_hp.validate(parameter_range_value)","if parameter_range_key == ""scaling_type"" :",159
4938,"def visit_filter_projection(self, node, value):<tab>base = self.visit(node[""children""][0], value)<tab>if not isinstance(base, list):<tab><tab>return None<tab>comparator_node = node[""children""][2]<tab>collected = []<tab>for element in base:<tab><tab>if self._is_true(self.visit(comparator_node, element)):<tab><tab><tab>current = self.visit(node[""children""][1], element)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>collected.append(current)<tab>return collected",if current is not None :,132
4939,"def _getSubstrings(self, va, size, ltyp):<tab># rip through the desired memory range to populate any substrings<tab>subs = set()<tab>end = va + size<tab>for offs in range(va, end, 1):<tab><tab>loc = self.getLocation(offs, range=True)<tab><tab><IF-STMT><tab><tab><tab>subs.add((loc[L_VA], loc[L_SIZE]))<tab><tab><tab>if loc[L_TINFO]:<tab><tab><tab><tab>subs = subs.union(set(loc[L_TINFO]))<tab>return list(subs)",if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,161
4940,"def run(self):<tab>while not self._stopped:<tab><tab>try:<tab><tab><tab>try:<tab><tab><tab><tab>test_name = next(self.pending)<tab><tab><tab>except StopIteration:<tab><tab><tab><tab>break<tab><tab><tab>mp_result = self._runtest(test_name)<tab><tab><tab>self.output.put((False, mp_result))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>except ExitThread:<tab><tab><tab>break<tab><tab>except BaseException:<tab><tab><tab>self.output.put((True, traceback.format_exc()))<tab><tab><tab>break","if must_stop ( mp_result . result , self . ns ) :",151
4941,"def get_in_inputs(key, data):<tab>if isinstance(data, dict):<tab><tab>for k, v in data.items():<tab><tab><tab>if k == key:<tab><tab><tab><tab>return v<tab><tab><tab>elif isinstance(v, (list, tuple, dict)):<tab><tab><tab><tab>out = get_in_inputs(key, v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return out<tab>elif isinstance(data, (list, tuple)):<tab><tab>out = [get_in_inputs(key, x) for x in data]<tab><tab>out = [x for x in out if x]<tab><tab>if out:<tab><tab><tab>return out[0]",if out :,160
4942,"def act_mapping(self, items, actions, mapping):<tab>""""""Executes all the actions on the list of pods.""""""<tab>success = True<tab>for action in actions:<tab><tab>for key, method in mapping.items():<tab><tab><tab>if key in action:<tab><tab><tab><tab>params = action.get(key)<tab><tab><tab><tab>ret = method(items, params)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>success = False<tab>return success",if not ret :,109
4943,"def _apply(self, plan):<tab>desired = plan.desired<tab>changes = plan.changes<tab>self.log.debug(""_apply: zone=%s, len(changes)=%d"", desired.name, len(changes))<tab>domain_name = desired.name[:-1]<tab>try:<tab><tab>nsone_zone = self._client.loadZone(domain_name)<tab>except ResourceException as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>self.log.debug(""_apply:   no matching zone, creating"")<tab><tab>nsone_zone = self._client.createZone(domain_name)<tab>for change in changes:<tab><tab>class_name = change.__class__.__name__<tab><tab>getattr(self, ""_apply_{}"".format(class_name))(nsone_zone, change)",if e . message != self . ZONE_NOT_FOUND_MESSAGE :,198
4944,"def split_artists(self, json):<tab>if len(json) == 0:<tab><tab>([], [])<tab>elif len(json) == 1:<tab><tab>artist = Artist.query.filter_by(name=json[0][""name""]).first()<tab><tab>return ([artist], [])<tab>my_artists = []<tab>other_artists = []<tab>for artist_dict in json:<tab><tab>artist = Artist.query.filter_by(name=artist_dict[""name""])<tab><tab><IF-STMT><tab><tab><tab>my_artists.append(artist.first())<tab><tab>else:<tab><tab><tab>del artist_dict[""thumb_url""]<tab><tab><tab>other_artists.append(artist_dict)<tab>return (my_artists, other_artists)",if artist . count ( ) :,176
4945,"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab>if attrname.startswith(""__""):<tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if attrname == ""salt_version"":<tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab>elif hasattr(self.metadata, attrname):<tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass",if attrvalue == 0 :,173
4946,"def close(self, code=errno.ECONNRESET):<tab>with self.shutdown_lock:<tab><tab><IF-STMT><tab><tab><tab>super(RemoteIPRoute, self).close(code=code)<tab><tab><tab>self.closed = True<tab><tab><tab>try:<tab><tab><tab><tab>self._mitogen_call.get()<tab><tab><tab>except mitogen.core.ChannelError:<tab><tab><tab><tab>pass<tab><tab><tab>if self._mitogen_broker is not None:<tab><tab><tab><tab>self._mitogen_broker.shutdown()<tab><tab><tab><tab>self._mitogen_broker.join()",if not self . closed :,142
4947,"def untokenize(self, iterable):<tab>for t in iterable:<tab><tab><IF-STMT><tab><tab><tab>self.compat(t, iterable)<tab><tab><tab>break<tab><tab>tok_type, token, start, end, line = t<tab><tab>self.add_whitespace(start)<tab><tab>self.tokens.append(token)<tab><tab>self.prev_row, self.prev_col = end<tab><tab>if tok_type in (NEWLINE, NL):<tab><tab><tab>self.prev_row += 1<tab><tab><tab>self.prev_col = 0<tab>return """".join(self.tokens)",if len ( t ) == 2 :,143
4948,"def __call__(self, x, uttid=None):<tab>if self.utt2spk is not None:<tab><tab>spk = self.utt2spk[uttid]<tab>else:<tab><tab>spk = uttid<tab>if not self.reverse:<tab><tab>if self.norm_means:<tab><tab><tab>x = np.add(x, self.bias[spk])<tab><tab><IF-STMT><tab><tab><tab>x = np.multiply(x, self.scale[spk])<tab>else:<tab><tab>if self.norm_vars:<tab><tab><tab>x = np.divide(x, self.scale[spk])<tab><tab>if self.norm_means:<tab><tab><tab>x = np.subtract(x, self.bias[spk])<tab>return x",if self . norm_vars :,189
4949,"def get_party_total(self, args):<tab>self.party_total = frappe._dict()<tab>for d in self.receivables:<tab><tab>self.init_party_total(d)<tab><tab># Add all amount columns<tab><tab>for k in list(self.party_total[d.party]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.party_total[d.party][k] += d.get(k, 0.0)<tab><tab># set territory, customer_group, sales person etc<tab><tab>self.set_party_details(d)","if k not in [ ""currency"" , ""sales_person"" ] :",150
4950,"def get_databases(request):<tab>dbs = {}<tab>global_env = globals()<tab>for (key, value) in global_env.items():<tab><tab>try:<tab><tab><tab>cond = isinstance(value, GQLDB)<tab><tab>except:<tab><tab><tab>cond = isinstance(value, SQLDB)<tab><tab><IF-STMT><tab><tab><tab>dbs[key] = value<tab>return dbs",if cond :,97
4951,"def check_twobit_file(dbkey, GALAXY_DATA_INDEX_DIR):<tab>twobit_file = ""%s/twobit.loc"" % GALAXY_DATA_INDEX_DIR<tab>twobit_path = """"<tab>twobits = {}<tab>for i, line in enumerate(open(twobit_file)):<tab><tab>line = line.rstrip(""\r\n"")<tab><tab>if line and not line.startswith(""#""):<tab><tab><tab>fields = line.split(""\t"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>twobits[(fields[0])] = fields[1]<tab>if dbkey in twobits:<tab><tab>twobit_path = twobits[(dbkey)]<tab>return twobit_path",if len ( fields ) < 2 :,177
4952,"def action(scheduler, _):<tab>nonlocal state<tab>nonlocal has_result<tab>nonlocal result<tab>nonlocal first<tab>nonlocal time<tab><IF-STMT><tab><tab>observer.on_next(result)<tab>try:<tab><tab>if first:<tab><tab><tab>first = False<tab><tab>else:<tab><tab><tab>state = iterate(state)<tab><tab>has_result = condition(state)<tab><tab>if has_result:<tab><tab><tab>result = state<tab><tab><tab>time = time_mapper(state)<tab>except Exception as e:  # pylint: disable=broad-except<tab><tab>observer.on_error(e)<tab><tab>return<tab>if has_result:<tab><tab>mad.disposable = scheduler.schedule_relative(time, action)<tab>else:<tab><tab>observer.on_completed()",if has_result :,187
4953,def orthogonalEnd(self):<tab>if self.type == Segment.LINE:<tab><tab>O = self.AB.orthogonal()<tab><tab>O.norm()<tab><tab>return O<tab>else:<tab><tab>O = self.B - self.C<tab><tab>O.norm()<tab><tab><IF-STMT><tab><tab><tab>return -O<tab><tab>else:<tab><tab><tab>return O,if self . type == Segment . CCW :,97
4954,"def remove(self, values):<tab>if not isinstance(values, (list, tuple, set)):<tab><tab>values = [values]<tab>for v in values:<tab><tab>v = str(v)<tab><tab>if isinstance(self._definition, dict):<tab><tab><tab>self._definition.pop(v, None)<tab><tab>elif self._definition == ""ANY"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._definition = []<tab><tab>elif v in self._definition:<tab><tab><tab>self._definition.remove(v)<tab>if (<tab><tab>self._value is not None<tab><tab>and self._value not in self._definition<tab><tab>and self._not_any()<tab>):<tab><tab>raise ConanException(bad_value_msg(self._name, self._value, self.values_range))","if v == ""ANY"" :",192
4955,"def __enter__(self) -> None:<tab>try:<tab><tab><IF-STMT><tab><tab><tab>signal.signal(signal.SIGALRM, self.handle_timeout)<tab><tab><tab>signal.alarm(self.seconds)<tab>except ValueError as ex:<tab><tab>logger.warning(""timeout can't be used in the current context"")<tab><tab>logger.exception(ex)",if threading . current_thread ( ) == threading . main_thread ( ) :,98
4956,"def __init__(self, fixed: MQTTFixedHeader = None):<tab>if fixed is None:<tab><tab>header = MQTTFixedHeader(PINGRESP, 0x00)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise HBMQTTException(<tab><tab><tab><tab>""Invalid fixed packet type %s for PingRespPacket init""<tab><tab><tab><tab>% fixed.packet_type<tab><tab><tab>)<tab><tab>header = fixed<tab>super().__init__(header)<tab>self.variable_header = None<tab>self.payload = None",if fixed . packet_type is not PINGRESP :,140
4957,"def _put_nowait(self, data, *, sender):<tab>if not self._running:<tab><tab>logger.warning(""Pub/Sub listener message after stop: %r, %r"", sender, data)<tab><tab>return<tab>self._queue.put_nowait((sender, data))<tab>if self._waiter is not None:<tab><tab>fut, self._waiter = self._waiter, None<tab><tab><IF-STMT><tab><tab><tab>assert fut.cancelled(), (""Waiting future is in wrong state"", self, fut)<tab><tab><tab>return<tab><tab>fut.set_result(None)",if fut . done ( ) :,139
4958,"def OnAssignBuiltin(self, cmd_val):<tab># type: (cmd_value__Assign) -> None<tab>buf = self._ShTraceBegin()<tab>if not buf:<tab><tab>return<tab>for i, arg in enumerate(cmd_val.argv):<tab><tab><IF-STMT><tab><tab><tab>buf.write("" "")<tab><tab>buf.write(arg)<tab>for pair in cmd_val.pairs:<tab><tab>buf.write("" "")<tab><tab>buf.write(pair.var_name)<tab><tab>buf.write(""="")<tab><tab>if pair.rval:<tab><tab><tab>_PrintShValue(pair.rval, buf)<tab>buf.write(""\n"")<tab>self.f.write(buf.getvalue())",if i != 0 :,169
4959,"def convertDict(obj):<tab>obj = dict(obj)<tab>for k, v in obj.items():<tab><tab>del obj[k]<tab><tab>if not (isinstance(k, str) or isinstance(k, unicode)):<tab><tab><tab>k = dumps(k)<tab><tab><tab># Keep track of which keys need to be decoded when loading.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>obj[Types.KEYS] = []<tab><tab><tab>obj[Types.KEYS].append(k)<tab><tab>obj[k] = convertObjects(v)<tab>return obj",if Types . KEYS not in obj :,137
4960,"def _ArgumentListHasDictionaryEntry(self, token):<tab>""""""Check if the function argument list has a dictionary as an arg.""""""<tab>if _IsArgumentToFunction(token):<tab><tab>while token:<tab><tab><tab>if token.value == ""{"":<tab><tab><tab><tab>length = token.matching_bracket.total_length - token.total_length<tab><tab><tab><tab>return length + self.stack[-2].indent > self.column_limit<tab><tab><tab>if token.ClosesScope():<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = token.matching_bracket<tab><tab><tab>token = token.next_token<tab>return False",if token . OpensScope ( ) :,153
4961,"def get_editable_dict(self):<tab>ret = {}<tab>for ref, ws_package in self._workspace_packages.items():<tab><tab>path = ws_package.root_folder<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(path, CONANFILE)<tab><tab>ret[ref] = {""path"": path, ""layout"": ws_package.layout}<tab>return ret",if os . path . isdir ( path ) :,100
4962,"def serialize(self, name=None):<tab>data = super(WebLink, self).serialize(name)<tab>data[""contentType""] = self.contentType<tab>if self.width:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidWidthException(self.width)<tab><tab>data[""inputOptions""] = {}<tab><tab>data[""width""] = self.width<tab>data.update({""content"": {""url"": self.linkUrl, ""text"": self.linkText}})<tab>return data","if self . width not in [ 100 , 50 , 33 , 25 ] :",122
4963,"def callback(lexer, match, context):<tab>text = match.group()<tab>extra = """"<tab>if start:<tab><tab>context.next_indent = len(text)<tab><tab><IF-STMT><tab><tab><tab>while context.next_indent < context.indent:<tab><tab><tab><tab>context.indent = context.indent_stack.pop()<tab><tab><tab>if context.next_indent > context.indent:<tab><tab><tab><tab>extra = text[context.indent :]<tab><tab><tab><tab>text = text[: context.indent]<tab>else:<tab><tab>context.next_indent += len(text)<tab>if text:<tab><tab>yield match.start(), TokenClass, text<tab>if extra:<tab><tab>yield match.start() + len(text), TokenClass.Error, extra<tab>context.pos = match.end()",if context . next_indent < context . indent :,196
4964,"def _handle_unsubscribe(self, web_sock):<tab>index = None<tab>with await self._subscriber_lock:<tab><tab>for i, (subscriber_web_sock, _) in enumerate(self._subscribers):<tab><tab><tab>if subscriber_web_sock == web_sock:<tab><tab><tab><tab>index = i<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>del self._subscribers[index]<tab><tab>if not self._subscribers:<tab><tab><tab>asyncio.ensure_future(self._unregister_subscriptions())",if index is not None :,124
4965,"def test_missing_dict_param():<tab>expected_err = ""params dictionary did not contain value for placeholder""<tab>try:<tab><tab>substitute_params(<tab><tab><tab>""SELECT * FROM cust WHERE salesrep = %(name)s"", {""foobar"": ""John Doe""}<tab><tab>)<tab><tab>assert False, ""expected exception b/c dict did not contain replacement value""<tab>except ValueError as exc:<tab><tab><IF-STMT><tab><tab><tab>raise",if expected_err not in str ( exc ) :,110
4966,"def one_gpr_reg_one_mem_scalable(ii):<tab>n, r = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>elif op_gprv(op):<tab><tab><tab>r += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and r == 1","if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ ""v"" ] ) :",113
4967,"def on_enter(self):<tab>""""""Fired when mouse enter the bbox of the widget.""""""<tab>if hasattr(self, ""md_bg_color"") and self.focus_behavior:<tab><tab>if hasattr(self, ""theme_cls"") and not self.focus_color:<tab><tab><tab>self.md_bg_color = self.theme_cls.bg_normal<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.md_bg_color = App.get_running_app().theme_cls.bg_normal<tab><tab><tab>else:<tab><tab><tab><tab>self.md_bg_color = self.focus_color",if not self . focus_color :,154
4968,"def __init__(self, *args, **kwargs):<tab>BaseCellExporter.__init__(self, *args, **kwargs)<tab>self.comment = ""#""<tab>for key in [""cell_marker""]:<tab><tab><IF-STMT><tab><tab><tab>self.metadata[key] = self.unfiltered_metadata[key]<tab>if self.fmt.get(""rst2md""):<tab><tab>raise ValueError(<tab><tab><tab>""The 'rst2md' option is a read only option. The reverse conversion is not ""<tab><tab><tab>""implemented. Please either deactivate the option, or save to another format.""<tab><tab>)  # pragma: no cover",if key in self . unfiltered_metadata :,150
4969,"def sendQueryQueueByAfterNate(self):<tab>for i in range(10):<tab><tab>queryQueueByAfterNateRsp = self.session.httpClint.send(urls.get(""queryQueue""))<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>"""".join(queryQueueByAfterNateRsp.get(""messages""))<tab><tab><tab><tab>or queryQueueByAfterNateRsp.get(""validateMessages"")<tab><tab><tab>)<tab><tab><tab>time.sleep(1)<tab><tab>else:<tab><tab><tab>sendEmail(ticket.WAIT_ORDER_SUCCESS)<tab><tab><tab>sendServerChan(ticket.WAIT_ORDER_SUCCESS)<tab><tab><tab>raise ticketIsExitsException(ticket.WAIT_AFTER_NATE_SUCCESS)","if not queryQueueByAfterNateRsp . get ( ""status"" ) :",190
4970,"def filter_errors(self, errors: List[str]) -> List[str]:<tab>real_errors: List[str] = list()<tab>current_file = __file__<tab>current_path = os.path.split(current_file)<tab>for line in errors:<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>fn, lno, lvl, msg = self.parse_trace_line(line)<tab><tab>if fn is not None:<tab><tab><tab>_path = os.path.split(fn)<tab><tab><tab>if _path[-1] != current_path[-1]:<tab><tab><tab><tab>continue<tab><tab>real_errors.append(line)<tab>return real_errors",if not line :,171
4971,"def pretty(self, n, comment=True):<tab>if isinstance(n, (str, bytes, list, tuple, dict)):<tab><tab>r = repr(n)<tab><tab>if not comment:  # then it can be inside a comment!<tab><tab><tab>r = r.replace(""*/"", r""\x2a/"")<tab><tab>return r<tab>if not isinstance(n, six.integer_types):<tab><tab>return n<tab>if isinstance(n, constants.Constant):<tab><tab><IF-STMT><tab><tab><tab>return ""%s /* %s */"" % (n, self.pretty(int(n)))<tab><tab>else:<tab><tab><tab>return ""%s (%s)"" % (n, self.pretty(int(n)))<tab>elif abs(n) < 10:<tab><tab>return str(n)<tab>else:<tab><tab>return hex(n)",if comment :,194
4972,"def get_pricings(self, subscription_id: str):<tab>try:<tab><tab>client = self.get_client(subscription_id)<tab><tab>pricings_list = await run_concurrently(lambda: client.pricings.list())<tab><tab><IF-STMT><tab><tab><tab>return pricings_list.value<tab><tab>else:<tab><tab><tab>return []<tab>except Exception as e:<tab><tab>print_exception(f""Failed to retrieve pricings: {e}"")<tab><tab>return []","if hasattr ( pricings_list , ""value"" ) :",131
4973,"def add_doc(target, variables, body_lines):<tab>if isinstance(target, ast.Name):<tab><tab># if it is a variable name add it to the doc<tab><tab>name = target.id<tab><tab>if name not in variables:<tab><tab><tab>doc = find_doc_for(target, body_lines)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>variables[name] = doc<tab>elif isinstance(target, ast.Tuple):<tab><tab># if it is a tuple then iterate the elements<tab><tab># this can happen like this:<tab><tab># a, b = 1, 2<tab><tab>for e in target.elts:<tab><tab><tab>add_doc(e, variables, body_lines)",if doc is not None :,167
4974,"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab>if left == 0:<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[left - 1]):<tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab><IF-STMT><tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[right]):<tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",if right == len ( text ) :,159
4975,"def pxrun_nodes(self, *args, **kwargs):<tab>cell = self._px_cell<tab>if re.search(r""^\s*%autopx\b"", cell):<tab><tab>self._disable_autopx()<tab><tab>return False<tab>else:<tab><tab>try:<tab><tab><tab>result = self.view.execute(cell, silent=False, block=False)<tab><tab>except:<tab><tab><tab>self.shell.showtraceback()<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>result.get()<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>self.shell.showtraceback()<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>result.display_outputs()<tab><tab><tab>return False",if self . view . block :,198
4976,"def candidates() -> Generator[""Symbol"", None, None]:<tab>s = self<tab>if Symbol.debug_lookup:<tab><tab>Symbol.debug_print(""searching in self:"")<tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")<tab>while True:<tab><tab>if matchSelf:<tab><tab><tab>yield s<tab><tab>if recurseInAnon:<tab><tab><tab>yield from s.children_recurse_anon<tab><tab>else:<tab><tab><tab>yield from s._children<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>s = s.siblingAbove<tab><tab>if Symbol.debug_lookup:<tab><tab><tab>Symbol.debug_print(""searching in sibling:"")<tab><tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")",if s . siblingAbove is None :,190
4977,"def decTaskGen():<tab>cnt = intbv(0, min=-n, max=n)<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>cnt[:] = 0<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab># print count<tab><tab><tab>decTaskFunc(cnt, enable, reset, n)<tab><tab><tab>count.next = cnt",if reset == ACTIVE_LOW :,107
4978,"def __call__(self, *args, **kwargs):<tab>if not NET_INITTED:<tab><tab>return self.raw(*args, **kwargs)<tab>for stack in traceback.walk_stack(None):<tab><tab><IF-STMT><tab><tab><tab>layer = stack[0].f_locals[""self""]<tab><tab><tab>if layer in layer_names:<tab><tab><tab><tab>log.pytorch_layer_name = layer_names[layer]<tab><tab><tab><tab>print(layer_names[layer])<tab><tab><tab><tab>break<tab>out = self.obj(self.raw, *args, **kwargs)<tab># if isinstance(out,Variable):<tab>#<tab> out=[out]<tab>return out","if ""self"" in stack [ 0 ] . f_locals :",173
4979,"def to_json_dict(self):<tab>d = super().to_json_dict()<tab>d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list)<tab>if self.header is not None:<tab><tab>if isinstance(self.header, RenderedContent):<tab><tab><tab>d[""header""] = self.header.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""header""] = self.header<tab>if self.subheader is not None:<tab><tab><IF-STMT><tab><tab><tab>d[""subheader""] = self.subheader.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""subheader""] = self.subheader<tab>return d","if isinstance ( self . subheader , RenderedContent ) :",172
4980,"def add(request):<tab>form_type = ""servers""<tab>if request.method == ""POST"":<tab><tab>form = BookMarkForm(request.POST)<tab><tab><IF-STMT><tab><tab><tab>form_type = form.save()<tab><tab><tab>messages.add_message(request, messages.INFO, ""Bookmark created"")<tab><tab>else:<tab><tab><tab>messages.add_message(request, messages.INFO, form.errors)<tab><tab>if form_type == ""server"":<tab><tab><tab>url = reverse(""servers"")<tab><tab>else:<tab><tab><tab>url = reverse(""metrics"")<tab><tab>return redirect(url)<tab>else:<tab><tab>return redirect(reverse(""servers""))",if form . is_valid ( ) :,164
4981,"def fee_amount_in_quote(self, trading_pair: str, price: Decimal, order_amount: Decimal):<tab>fee_amount = Decimal(""0"")<tab>if self.percent > 0:<tab><tab>fee_amount = (price * order_amount) * self.percent<tab>base, quote = trading_pair.split(""-"")<tab>for flat_fee in self.flat_fees:<tab><tab>if interchangeable(flat_fee[0], base):<tab><tab><tab>fee_amount += flat_fee[1] * price<tab><tab><IF-STMT><tab><tab><tab>fee_amount += flat_fee[1]<tab>return fee_amount","elif interchangeable ( flat_fee [ 0 ] , quote ) :",163
4982,"def load_batch(fpath):<tab>with open(fpath, ""rb"") as f:<tab><tab><IF-STMT><tab><tab><tab># Python3<tab><tab><tab>d = pickle.load(f, encoding=""latin1"")<tab><tab>else:<tab><tab><tab># Python2<tab><tab><tab>d = pickle.load(f)<tab>data = d[""data""]<tab>labels = d[""labels""]<tab>return data, labels","if sys . version_info > ( 3 , 0 ) :",106
4983,"def clear_entries(options):<tab>""""""Clear pending entries""""""<tab>with Session() as session:<tab><tab>query = session.query(db.PendingEntry).filter(db.PendingEntry.approved == False)<tab><tab><IF-STMT><tab><tab><tab>query = query.filter(db.PendingEntry.task_name == options.task_name)<tab><tab>deleted = query.delete()<tab><tab>console(""Successfully deleted %i pending entries"" % deleted)",if options . task_name :,110
4984,"def attribute_table(self, attribute):<tab>""""""Return a tuple (schema, table) for attribute.""""""<tab>dimension = attribute.dimension<tab>if dimension:<tab><tab>schema = self.naming.dimension_schema or self.naming.schema<tab><tab><IF-STMT><tab><tab><tab>table = self.fact_name<tab><tab>else:<tab><tab><tab>table = self.naming.dimension_table_name(dimension)<tab>else:<tab><tab>table = self.fact_name<tab><tab>schema = self.naming.schema<tab>return (schema, table)",if dimension . is_flat and not dimension . has_details :,137
4985,"def remove_rating(self, songs, librarian):<tab>count = len(songs)<tab>if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""):<tab><tab>parent = qltk.get_menu_item_top_parent(self)<tab><tab>dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None)<tab><tab>if dialog.run() != Gtk.ResponseType.YES:<tab><tab><tab>return<tab>reset = []<tab>for song in songs:<tab><tab><IF-STMT><tab><tab><tab>del song[""~#rating""]<tab><tab><tab>reset.append(song)<tab>librarian.changed(reset)","if ""~#rating"" in song :",159
4986,"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab>if left == 0:<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[left - 1]):<tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab>if right == len(text):<tab><tab><tab>done = True<tab><tab><IF-STMT><tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",elif not self . word_boundary_char ( text [ right ] ) :,159
4987,"def handle_read(self):<tab>""""""Called when there is data waiting to be read.""""""<tab>try:<tab><tab>chunk = self.recv(self.ac_in_buffer_size)<tab>except RetryError:<tab><tab>pass<tab>except socket.error:<tab><tab>self.handle_error()<tab>else:<tab><tab>self.tot_bytes_received += len(chunk)<tab><tab>if not chunk:<tab><tab><tab>self.transfer_finished = True<tab><tab><tab># self.close()  # <-- asyncore.recv() already do that...<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>chunk = self._data_wrapper(chunk)<tab><tab>try:<tab><tab><tab>self.file_obj.write(chunk)<tab><tab>except OSError as err:<tab><tab><tab>raise _FileReadWriteError(err)",if self . _data_wrapper is not None :,200
4988,"def toggle(self, event=None):<tab>if self.absolute:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 100<tab><tab>if self.split > 20:<tab><tab><tab>self.save = self.split<tab><tab><tab>self.split = 1<tab><tab>else:<tab><tab><tab>self.split = self.save<tab>else:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 0.3<tab><tab>if self.split <= self.min or self.split >= self.max:<tab><tab><tab>self.split = self.save<tab><tab><IF-STMT><tab><tab><tab>self.split = self.min<tab><tab>else:<tab><tab><tab>self.split = self.max<tab>self.placeChilds()",elif self . split < 0.5 :,189
4989,"def readAtOffset(self, offset, size, shortok=False):<tab>ret = b""""<tab>self.fd.seek(offset)<tab>while len(ret) != size:<tab><tab>rlen = size - len(ret)<tab><tab>x = self.fd.read(rlen)<tab><tab>if x == b"""":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>return ret<tab><tab>ret += x<tab>return ret",if not shortok :,111
4990,"def webfinger(environ, start_response, _):<tab>query = parse_qs(environ[""QUERY_STRING""])<tab>try:<tab><tab>rel = query[""rel""]<tab><tab>resource = query[""resource""][0]<tab>except KeyError:<tab><tab>resp = BadRequest(""Missing parameter in request"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>resp = BadRequest(""Bad issuer in request"")<tab><tab>else:<tab><tab><tab>wf = WebFinger()<tab><tab><tab>resp = Response(wf.response(subject=resource, base=OAS.baseurl))<tab>return resp(environ, start_response)",if rel != [ OIC_ISSUER ] :,152
4991,"def _tokenize(self, text):<tab>if format_text(text) == EMPTY_TEXT:<tab><tab>return [self.additional_special_tokens[0]]<tab>split_tokens = []<tab>if self.do_basic_tokenize:<tab><tab>for token in self.basic_tokenizer.tokenize(<tab><tab><tab>text, never_split=self.all_special_tokens<tab><tab>):<tab><tab><tab># If the token is part of the never_split set<tab><tab><tab><IF-STMT><tab><tab><tab><tab>split_tokens.append(token)<tab><tab><tab>else:<tab><tab><tab><tab>split_tokens += self.wordpiece_tokenizer.tokenize(token)<tab>else:<tab><tab>split_tokens = self.wordpiece_tokenizer.tokenize(text)<tab>return split_tokens",if token in self . basic_tokenizer . never_split :,189
4992,"def send_packed_command(self, command, check_health=True):<tab>if not self._sock:<tab><tab>self.connect()<tab>try:<tab><tab>if isinstance(command, str):<tab><tab><tab>command = [command]<tab><tab>for item in command:<tab><tab><tab>self._sock.sendall(item)<tab>except socket.error as e:<tab><tab>self.disconnect()<tab><tab><IF-STMT><tab><tab><tab>_errno, errmsg = ""UNKNOWN"", e.args[0]<tab><tab>else:<tab><tab><tab>_errno, errmsg = e.args<tab><tab>raise ConnectionError(<tab><tab><tab>""Error %s while writing to socket. %s."" % (_errno, errmsg)<tab><tab>)<tab>except Exception:<tab><tab>self.disconnect()<tab><tab>raise",if len ( e . args ) == 1 :,188
4993,"def to_value(self, value):<tab># Tip: 'value' is the object returned by<tab>#<tab>  taiga.projects.history.models.HistoryEntry.values_diff()<tab>ret = {}<tab>for key, val in value.items():<tab><tab>if key in [""attachments"", ""custom_attributes"", ""description_diff""]:<tab><tab><tab>ret[key] = val<tab><tab><IF-STMT><tab><tab><tab>ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()}<tab><tab>else:<tab><tab><tab>ret[key] = {""from"": val[0], ""to"": val[1]}<tab>return ret","elif key == ""points"" :",169
4994,"def to_child(cls, key=None, process=None):<tab>if process is not None:<tab><tab>if type(process) is not dict:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>'Invalid value provided for ""process"" parameter, expected a dictionary'<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab># Merge class `__process__` parameters with provided parameters<tab><tab><tab>result = {}<tab><tab><tab>result.update(deepcopy(cls.__process__))<tab><tab><tab>result.update(process)<tab><tab><tab>process = result<tab>class Child(cls):<tab><tab>__key__ = key<tab><tab>__process__ = process<tab><tab>__root__ = False<tab>Child.__name__ = cls.__name__<tab>return Child",if cls . __process__ :,173
4995,"def _super_function(args):<tab>passed_class, passed_self = args.get_arguments([""type"", ""self""])<tab>if passed_self is None:<tab><tab>return passed_class<tab>else:<tab><tab># pyclass = passed_self.get_type()<tab><tab>pyclass = passed_class<tab><tab><IF-STMT><tab><tab><tab>supers = pyclass.get_superclasses()<tab><tab><tab>if supers:<tab><tab><tab><tab>return pyobjects.PyObject(supers[0])<tab><tab>return passed_self","if isinstance ( pyclass , pyobjects . AbstractClass ) :",132
4996,"def get_data(row):<tab>data = []<tab>for field_name, field_xpath in fields:<tab><tab>result = row.xpath(field_xpath)<tab><tab><IF-STMT><tab><tab><tab>result = "" "".join(<tab><tab><tab><tab>text<tab><tab><tab><tab>for text in map(<tab><tab><tab><tab><tab>six.text_type.strip, map(six.text_type, map(unescape, result))<tab><tab><tab><tab>)<tab><tab><tab><tab>if text<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>result = None<tab><tab>data.append(result)<tab>return data",if result :,142
4997,"def say(jarvis, s):<tab>""""""Reads what is typed.""""""<tab>if not s:<tab><tab>jarvis.say(""What should I say?"")<tab>else:<tab><tab>voice_state = jarvis.is_voice_enabled()<tab><tab>jarvis.enable_voice()<tab><tab>jarvis.say(s)<tab><tab><IF-STMT><tab><tab><tab>jarvis.disable_voice()",if not voice_state :,99
4998,"def __import__(name, globals=None, locals=None, fromlist=(), level=0):<tab>module = orig___import__(name, globals, locals, fromlist, level)<tab>if fromlist and module.__name__ in modules:<tab><tab><IF-STMT><tab><tab><tab>fromlist = list(fromlist)<tab><tab><tab>fromlist.remove(""*"")<tab><tab><tab>fromlist.extend(getattr(module, ""__all__"", []))<tab><tab>for x in fromlist:<tab><tab><tab>if isinstance(getattr(module, x, None), types.ModuleType):<tab><tab><tab><tab>from_name = ""{}.{}"".format(module.__name__, x)<tab><tab><tab><tab>if from_name in modules:<tab><tab><tab><tab><tab>importlib.import_module(from_name)<tab>return module","if ""*"" in fromlist :",175
4999,"def _read_pricing_file(self, region=None, pricing_file=None):<tab>if not self.__pricing_file_cache:<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Reading pricing file..."")<tab><tab><tab>with open(pricing_file) as data_file:<tab><tab><tab><tab>self.__pricing_file_cache = json.load(data_file)<tab><tab>else:<tab><tab><tab>self.__pricing_file_cache = self._download_pricing_file(region)<tab>return self.__pricing_file_cache",if pricing_file :,130
