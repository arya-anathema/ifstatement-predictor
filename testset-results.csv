input function,match?,expected,predicted,codeBleu,Bleu-4,F1
"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True):<tab>try:<tab><tab>return self._read(count, timeout)<tab>except usb.USBError as e:<tab><tab>if DEBUG_COMM:<tab><tab><tab>log.info(<tab><tab><tab><tab>""read: e.errno=%s e.strerror=%s e.message=%s repr=%s""<tab><tab><tab><tab>% (e.errno, e.strerror, e.message, repr(e))<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return []<tab><tab>if ignore_non_errors and is_noerr(e):<tab><tab><tab>return []<tab><tab>raise",0,if ignore_timeouts and is_timeout ( e ) :,if ignore_timeouts and is_timeouts ( e ) :,0.5014622369176811,73.48889200874659,1.0
"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None):<tab>""""""cache hidden states into memory.""""""<tab>if mem_len is None or mem_len == 0:<tab><tab>return None<tab>else:<tab><tab>if reuse_len is not None and reuse_len > 0:<tab><tab><tab>curr_out = curr_out[:reuse_len]<tab><tab><IF-STMT><tab><tab><tab>new_mem = curr_out[-mem_len:]<tab><tab>else:<tab><tab><tab>new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:]<tab>new_mem.stop_gradient = True<tab>return new_mem",1,if prev_mem is None :,if prev_mem is None :,0.75,100.00000000000004,1.0
def filtered(gen):<tab>for example in gen:<tab><tab>example_len = length_fn(example)<tab><tab># Checking max length boundary.<tab><tab>if max_length is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab># Checking min length boundary.<tab><tab>if min_length is not None:<tab><tab><tab>if example_len < min_length:<tab><tab><tab><tab>continue<tab><tab># Within bounds.<tab><tab>yield example,1,if example_len > max_length :,if example_len > max_length :,0.75,100.00000000000004,1.0
"def search(self, query):<tab># ""Search.ashx?query="" + query + filterVal<tab>if not query:<tab><tab>logger.debug(""Empty search query"")<tab><tab>return []<tab>logger.debug('Searching TuneIn for ""%s""' % query)<tab>args = ""&query="" + query<tab>search_results = self._tunein(""Search.ashx"", args)<tab>results = []<tab>for item in self._flatten(search_results):<tab><tab><IF-STMT><tab><tab><tab># Only return stations<tab><tab><tab>self._stations[item[""guide_id""]] = item<tab><tab><tab>results.append(item)<tab>return results",0,"if item . get ( ""type"" , """" ) == ""audio"" :","if ""guide_id"" in item :",0.010805043283377891,2.6227541263820755,0.4
"def _check_script(self, script, directive):<tab>for var in compile_script(script):<tab><tab><IF-STMT><tab><tab><tab># Skip variable checks<tab><tab><tab>return False<tab><tab>if var.can_contain("".""):<tab><tab><tab># Yay! Our variable can contain any symbols!<tab><tab><tab>reason = (<tab><tab><tab><tab>'At least variable ""${var}"" can contain untrusted user input'.format(<tab><tab><tab><tab><tab>var=var.name<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>self.add_issue(directive=[directive] + var.providers, reason=reason)<tab><tab><tab>return True<tab>return False",0,"if var . must_contain ( ""/"" ) :",if not var . is_trusted :,0.03715698634619789,8.423555525647696,0.4772727272727273
"def getAllDataLinkIDs():<tab>linkDataIDs = set()<tab>dataType = _forestData.dataTypeBySocket<tab>for socketID, linkedIDs in _forestData.linkedSockets.items():<tab><tab>for linkedID in linkedIDs:<tab><tab><tab><IF-STMT>  # check which one is origin/target<tab><tab><tab><tab>linkDataIDs.add(<tab><tab><tab><tab><tab>(socketID, linkedID, dataType[socketID], dataType[linkedID])<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>linkDataIDs.add(<tab><tab><tab><tab><tab>(linkedID, socketID, dataType[linkedID], dataType[socketID])<tab><tab><tab><tab>)<tab>return linkDataIDs",0,if socketID [ 1 ] :,"if linkedID == ""origin"" :",0.02713659235259708,6.567274736060395,0.37142857142857144
"def _stderr_supports_color():<tab>try:<tab><tab>if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty():<tab><tab><tab>if curses:<tab><tab><tab><tab>curses.setupterm()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab>elif colorama:<tab><tab><tab><tab>if sys.stderr is getattr(<tab><tab><tab><tab><tab>colorama.initialise, ""wrapped_stderr"", object()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>return True<tab>except Exception:<tab><tab># Very broad exception handling because it's always better to<tab><tab># fall back to non-colored logs than to break at startup.<tab><tab>pass<tab>return False",0,"if curses . tigetnum ( ""colors"" ) > 0 :",elif curses . getupterm ( ) == 0 :,0.03381004182941506,10.753659580649467,0.42857142857142855
"def offsets(self):<tab>offsets = {}<tab>offset_so_far = 0<tab>for name, ty in self.fields.items():<tab><tab>if isinstance(ty, SimTypeBottom):<tab><tab><tab>l.warning(<tab><tab><tab><tab>""Found a bottom field in struct %s. Ignore and increment the offset using the default ""<tab><tab><tab><tab>""element size."",<tab><tab><tab><tab>self.name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>if not self._pack:<tab><tab><tab>align = ty.alignment<tab><tab><tab><IF-STMT><tab><tab><tab><tab>offset_so_far += align - offset_so_far % align<tab><tab>offsets[name] = offset_so_far<tab><tab>offset_so_far += ty.size // self._arch.byte_width<tab>return offsets",0,if offset_so_far % align != 0 :,if align :,0.0218511966470955,1e-10,0.7222222222222222
"def Restore(self):<tab>picker, obj = self._window, self._pObject<tab>value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH)<tab>if value is not None:<tab><tab>if issubclass(picker.__class__, wx.FileDialog):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value[-1]<tab><tab>picker.SetPath(value)<tab><tab>return True<tab>return False",0,if type ( value ) == list :,"if isinstance ( value [ - 1 ] , tuple ) :",0.030649819819333343,8.516593018819643,0.3666666666666667
"def dt_s_tup_to_string(dt_s_tup):<tab>dt_string = dt_s_tup[0]  # string for identifying the file to parse.<tab>if dt_s_tup[1] > 0:  # if there are seasons in the model<tab><tab><IF-STMT><tab><tab><tab>dt_string = dt_string[:2] + ""s"" + dt_string[2:]<tab><tab>else:<tab><tab><tab>dt_string = ""s"" + dt_string<tab>return dt_string",0,"if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",if len ( dt_string ) > 2 :,0.01079993947912768,3.959981382356705,0.30392156862745096
"def writer(stream, items):<tab>sep = """"<tab>for item in items:<tab><tab>stream.write(sep)<tab><tab>sep = "" ""<tab><tab><IF-STMT><tab><tab><tab>item = str(item)<tab><tab>if not PY3K:<tab><tab><tab>if not isinstance(item, unicode):<tab><tab><tab><tab>item = str(item)<tab><tab>stream.write(item)<tab>stream.write(""\n"")",0,"if not isinstance ( item , str ) :","if not isinstance ( item , unicode ) :",0.5818820875411705,66.06328636027612,0.7142857142857143
"def _get_result_keys(self, config):<tab>result_key = config.get(""result_key"")<tab>if result_key is not None:<tab><tab><IF-STMT><tab><tab><tab>result_key = [result_key]<tab><tab>result_key = [jmespath.compile(rk) for rk in result_key]<tab><tab>return result_key",1,"if not isinstance ( result_key , list ) :","if not isinstance ( result_key , list ) :",0.75,100.00000000000004,1.0
"def _download_build_artifacts(self, build: Dict[str, Any]) -> None:<tab>arch = build[""arch_tag""]<tab>snap_build = self._lp_load_url(build[""self_link""])<tab>urls = snap_build.getFileUrls()<tab>if not urls:<tab><tab>logger.error(f""Snap file not available for arch {arch!r}."")<tab><tab>return<tab>for url in urls:<tab><tab>file_name = _get_url_basename(url)<tab><tab>self._download_file(url=url, dst=file_name)<tab><tab><IF-STMT><tab><tab><tab>logger.info(f""Snapped {file_name}"")<tab><tab>else:<tab><tab><tab>logger.info(f""Fetched {file_name}"")",0,"if file_name . endswith ( "".snap"" ) :","if arch == ""snap"" :",0.01858685153282265,7.433761660133445,0.5
"def _add_custom_statement(self, custom_statements):<tab>if custom_statements is None:<tab><tab>return<tab>self.resource_policy[""Version""] = ""2012-10-17""<tab>if self.resource_policy.get(""Statement"") is None:<tab><tab>self.resource_policy[""Statement""] = custom_statements<tab>else:<tab><tab>if not isinstance(custom_statements, list):<tab><tab><tab>custom_statements = [custom_statements]<tab><tab>statement = self.resource_policy[""Statement""]<tab><tab>if not isinstance(statement, list):<tab><tab><tab>statement = [statement]<tab><tab>for s in custom_statements:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statement.append(s)<tab><tab>self.resource_policy[""Statement""] = statement",1,if s not in statement :,if s not in statement :,0.75,100.00000000000004,1.0
"def display_failures_for_single_test(result: TestResult) -> None:<tab>""""""Display a failure for a single method / endpoint.""""""<tab>display_subsection(result)<tab>checks = _get_unique_failures(result.checks)<tab>for idx, check in enumerate(checks, 1):<tab><tab>message: Optional[str]<tab><tab><IF-STMT><tab><tab><tab>message = f""{idx}. {check.message}""<tab><tab>else:<tab><tab><tab>message = None<tab><tab>example = cast(Case, check.example)  # filtered in `_get_unique_failures`<tab><tab>display_example(example, check.name, message, result.seed)<tab><tab># Display every time except the last check<tab><tab>if idx != len(checks):<tab><tab><tab>click.echo(""\n"")",0,if check . message :,if check . message is not None :,0.3514988343435983,36.55552228545123,0.5102040816326531
"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""qangaroo"")<tab>version = ""v1.1""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100.00000000000004,1.0
"def call(self, step_input, states):<tab>new_states = []<tab>for i in range(self.num_layers):<tab><tab>out, new_state = self.lstm_cells[i](step_input, states[i])<tab><tab>step_input = (<tab><tab><tab>layers.dropout(<tab><tab><tab><tab>out, self.dropout_prob, dropout_implementation=""upscale_in_train""<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab>else out<tab><tab>)<tab><tab>new_states.append(new_state)<tab>return step_input, new_states",0,if self . dropout_prob > 0.0,if self . dropout_prob,0.2845900623517831,71.65313105737896,1.0
"def jupyter_progress_bar(min=0, max=1.0):<tab>""""""Returns an ipywidget progress bar or None if we can't import it""""""<tab>widgets = wandb.util.get_module(""ipywidgets"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab># TODO: this currently works in iPython but it's deprecated since 4.0<tab><tab><tab>from IPython.html import widgets  # type: ignore<tab><tab>assert hasattr(widgets, ""VBox"")<tab><tab>assert hasattr(widgets, ""Label"")<tab><tab>assert hasattr(widgets, ""FloatProgress"")<tab><tab>return ProgressWidget(widgets, min=min, max=max)<tab>except (ImportError, AssertionError):<tab><tab>return None",0,if widgets is None :,"if hasattr ( widgets , ""ProgressWidget"" ) :",0.028001459970687266,5.522397783539471,0.3148148148148148
"def _record_event(self, path, fsevent_handle, filename, events, error):<tab>with self.lock:<tab><tab>self.events[path].append(events)<tab><tab><IF-STMT><tab><tab><tab>if not os.path.exists(path):<tab><tab><tab><tab>self.watches.pop(path).close()",0,if events | pyuv . fs . UV_RENAME :,if self . watches :,0.0793380461076173,4.234348806659263,0.27272727272727276
"def _get_v1_id_from_tags(self, tags_obj, tag):<tab>""""""Get image id from array of tags""""""<tab>if isinstance(tags_obj, dict):<tab><tab>try:<tab><tab><tab>return tags_obj[tag]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>elif isinstance(tags_obj, []):<tab><tab>try:<tab><tab><tab>for tag_dict in tags_obj:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return tag_dict[""layer""]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return """"",0,"if tag_dict [ ""name"" ] == tag :","if ""layer"" in tag_dict :",0.019907917998500824,14.06401411379081,0.5
"def query_lister(domain, query="""", max_items=None, attr_names=None):<tab>more_results = True<tab>num_results = 0<tab>next_token = None<tab>while more_results:<tab><tab>rs = domain.connection.query_with_attributes(<tab><tab><tab>domain, query, attr_names, next_token=next_token<tab><tab>)<tab><tab>for item in rs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if num_results == max_items:<tab><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>yield item<tab><tab><tab>num_results += 1<tab><tab>next_token = rs.next_token<tab><tab>more_results = next_token != None",0,if max_items :,if max_items is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def filter(this, args):<tab>array = to_object(this, args.space)<tab>callbackfn = get_arg(args, 0)<tab>arr_len = js_arr_length(array)<tab>if not is_callable(callbackfn):<tab><tab>raise MakeError(""TypeError"", ""callbackfn must be a function"")<tab>_this = get_arg(args, 1)<tab>k = 0<tab>res = []<tab>while k < arr_len:<tab><tab><IF-STMT><tab><tab><tab>kValue = array.get(unicode(k))<tab><tab><tab>if to_boolean(callbackfn.call(_this, (kValue, float(k), array))):<tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return args.space.ConstructArray(res)",1,if array . has_property ( unicode ( k ) ) :,if array . has_property ( unicode ( k ) ) :,0.75,100.00000000000004,1.0
"def every_one_is(self, dst):<tab>msg = ""all members of %r should be %r, but the %dth is %r""<tab>for index, item in enumerate(self._src):<tab><tab>if self._range:<tab><tab><tab>if index < self._range[0] or index > self._range[1]:<tab><tab><tab><tab>continue<tab><tab>error = msg % (self._src, dst, index, item)<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(error)<tab>return True",0,if item != dst :,"if isinstance ( error , AssertionError ) :",0.026407399022921448,6.567274736060395,0.2698412698412698
"def schedule_logger(job_id=None, delete=False):<tab>if not job_id:<tab><tab>return getLogger(""fate_flow_schedule"")<tab>else:<tab><tab>if delete:<tab><tab><tab>with LoggerFactory.lock:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>for key in LoggerFactory.schedule_logger_dict.keys():<tab><tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab><tab>del LoggerFactory.schedule_logger_dict[key]<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab><tab>key = job_id + ""schedule""<tab><tab>if key in LoggerFactory.schedule_logger_dict:<tab><tab><tab>return LoggerFactory.schedule_logger_dict[key]<tab><tab>return LoggerFactory.get_schedule_logger(job_id)",0,if job_id in key :,if key in LoggerFactory . schedule_logger_dict :,0.15618134377087764,5.604233375480572,0.37142857142857144
"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab>if item[0]:<tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab>elif item[1]:<tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab><IF-STMT><tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab>elif item[3]:<tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",1,elif item [ 2 ] :,elif item [ 2 ] :,0.75,100.00000000000004,1.0
"def _read_data_from_all_categories(self, directory, config, categories):<tab>lines = []<tab>for category in categories:<tab><tab>data_file = os.path.join(directory, _DATASET_VERSION, category, config)<tab><tab><IF-STMT><tab><tab><tab>with open(data_file) as f:<tab><tab><tab><tab>ls = f.read().split(""\n"")<tab><tab><tab><tab>for l in ls[::-1]:<tab><tab><tab><tab><tab>if not l:<tab><tab><tab><tab><tab><tab>ls.remove(l)<tab><tab><tab><tab>lines.extend(ls)<tab>return lines",1,if os . path . exists ( data_file ) :,if os . path . exists ( data_file ) :,0.75,100.00000000000004,1.0
"def find_handlers(self, forms):<tab>handlers = {}<tab>for form in forms.itervalues():<tab><tab>for action_name, _action_label in form.actions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handlers[action_name] = form<tab><tab><tab>else:<tab><tab><tab><tab>raise HandlerError(<tab><tab><tab><tab><tab>""More than one form defines the handler %s"" % action_name<tab><tab><tab><tab>)<tab>return handlers",0,if action_name not in handlers :,if action_name in self . handlers :,0.20901565715061327,36.88939732334405,0.5
"def get_story_task_completed_body(payload: Dict[str, Any]) -> Optional[str]:<tab>action = get_action_with_primary_id(payload)<tab>kwargs = {<tab><tab>""task_description"": action[""description""],<tab>}<tab>story_id = action[""story_id""]<tab>for ref in payload[""references""]:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""name_template""] = STORY_NAME_TEMPLATE.format(<tab><tab><tab><tab>name=ref[""name""],<tab><tab><tab><tab>app_url=ref[""app_url""],<tab><tab><tab>)<tab>if action[""changes""][""complete""][""new""]:<tab><tab>return STORY_TASK_COMPLETED_TEMPLATE.format(**kwargs)<tab>else:<tab><tab>return None",0,"if ref [ ""id"" ] == story_id :","if ref [ ""story_id"" ] == story_id :",0.5014622369176811,72.41577342575832,1.0
"def _create_valid_graph(graph):<tab>nodes = graph.nodes()<tab>for i in range(len(nodes)):<tab><tab>for j in range(len(nodes)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>edge = (nodes[i], nodes[j])<tab><tab><tab>if graph.has_edge(edge):<tab><tab><tab><tab>graph.del_edge(edge)<tab><tab><tab>graph.add_edge(edge, 1)",1,if i == j :,if i == j :,0.75,100.00000000000004,1.0
"def _post_order(op):<tab>if isinstance(op, tvm.tir.Allocate):<tab><tab>lift_stmt[-1].append(op)<tab><tab>return op.body<tab>if isinstance(op, tvm.tir.AttrStmt):<tab><tab><IF-STMT><tab><tab><tab>lift_stmt[-1].append(op)<tab><tab><tab>return op.body<tab><tab>if op.attr_key == ""virtual_thread"":<tab><tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab><tab>return op<tab>if isinstance(op, tvm.tir.For):<tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab>raise RuntimeError(""not reached"")",0,"if op . attr_key == ""storage_scope"" :","if op . attr_key == ""virtual_thread"" :",0.574113272471593,65.91844162499147,1.0
"def format_lazy_import(names):<tab>""""""Formats lazy import lines""""""<tab>lines = """"<tab>for _, name, asname in names:<tab><tab>pkg, _, _ = name.partition(""."")<tab><tab><IF-STMT><tab><tab><tab>line = ""{pkg} = _LazyModule.load({pkg!r}, {mod!r})\n""<tab><tab>else:<tab><tab><tab>line = ""{asname} = _LazyModule.load({pkg!r}, {mod!r}, {asname!r})\n""<tab><tab>lines += line.format(pkg=pkg, mod=name, asname=asname)<tab>return lines",1,if asname is None :,if asname is None :,0.75,100.00000000000004,1.0
"def evaluateWord(self, argument):<tab>wildcard_count = argument[0].count(""*"")<tab>if wildcard_count > 0:<tab><tab>if wildcard_count == 1 and argument[0].startswith(""*""):<tab><tab><tab>return self.GetWordWildcard(argument[0][1:], method=""endswith"")<tab><tab>if wildcard_count == 1 and argument[0].endswith(""*""):<tab><tab><tab>return self.GetWordWildcard(argument[0][:-1], method=""startswith"")<tab><tab>else:<tab><tab><tab>_regex = argument[0].replace(""*"", "".+"")<tab><tab><tab>matched = False<tab><tab><tab>for w in self.words:<tab><tab><tab><tab>matched = bool(re.search(_regex, w))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>return matched<tab>return self.GetWord(argument[0])",1,if matched :,if matched :,0.5311706625951745,1e-10,1.0
"def setup(self, ir: ""IR"", aconf: Config) -> bool:<tab>if self.kind == ""ConsulResolver"":<tab><tab>self.resolve_with = ""consul""<tab><tab><IF-STMT><tab><tab><tab>self.post_error(""ConsulResolver is required to have a datacenter"")<tab><tab><tab>return False<tab>elif self.kind == ""KubernetesServiceResolver"":<tab><tab>self.resolve_with = ""k8s""<tab>elif self.kind == ""KubernetesEndpointResolver"":<tab><tab>self.resolve_with = ""k8s""<tab>else:<tab><tab>self.post_error(f""Resolver kind {self.kind} unknown"")<tab><tab>return False<tab>return True",0,"if not self . get ( ""datacenter"" ) :","elif self . kind == ""datacenter"" :",0.02935892474714758,18.60045401920258,0.12987012987012986
"def get_success_url(self):<tab>""""""Continue to the flow index or redirect according `?back` parameter.""""""<tab>if ""back"" in self.request.GET:<tab><tab>back_url = self.request.GET[""back""]<tab><tab><IF-STMT><tab><tab><tab>back_url = ""/""<tab><tab>return back_url<tab>return reverse(self.success_url)",0,"if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :","if not back_url . endswith ( ""/"" ) :",0.013855548120951737,4.506693101226436,0.42016806722689076
"def download_main(<tab>download, download_playlist, urls, playlist, output_dir, merge, info_only):<tab>for url in urls:<tab><tab>if url.startswith(""https://""):<tab><tab><tab>url = url[8:]<tab><tab><IF-STMT><tab><tab><tab>url = ""http://"" + url<tab><tab>if playlist:<tab><tab><tab>download_playlist(<tab><tab><tab><tab>url, output_dir=output_dir, merge=merge, info_only=info_only<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>download(url, output_dir=output_dir, merge=merge, info_only=info_only)",0,"if not url . startswith ( ""http://"" ) :","if not url . startswith ( ""http"" ) :",0.5818820875411705,61.91566827062977,1.0
"def __str__(self):<tab>buf = [""""]<tab>if self.fileName:<tab><tab>buf.append(self.fileName + "":"")<tab>if self.line != -1:<tab><tab><IF-STMT><tab><tab><tab>buf.append(""line "")<tab><tab>buf.append(str(self.line))<tab><tab>if self.column != -1:<tab><tab><tab>buf.append("":"" + str(self.column))<tab><tab>buf.append("":"")<tab>buf.append("" "")<tab>return str("""").join(buf)",0,if not self . fileName :,if self . line != - 1 :,0.04432760343703879,11.339582221952005,0.2857142857142857
"def parse_bash_set_output(output):<tab>""""""Parse Bash-like 'set' output""""""<tab>if not sys.platform.startswith(""win""):<tab><tab># Replace ""\""-continued lines in *Linux* environment dumps.<tab><tab># Cannot do this on Windows because a ""\"" at the end of the<tab><tab># line does not imply a continuation.<tab><tab>output = output.replace(""\\\n"", """")<tab>environ = {}<tab>for line in output.splitlines(0):<tab><tab>line = line.rstrip()<tab><tab>if not line:<tab><tab><tab>continue  # skip black lines<tab><tab>item = _ParseBashEnvStr(line)<tab><tab><IF-STMT><tab><tab><tab>environ[item[0]] = item[1]<tab>return environ",1,if item :,if item :,0.5311706625951745,1e-10,1.0
"def remove_selected(self):<tab>""""""Removes selected items from list.""""""<tab>to_delete = []<tab>for i in range(len(self)):<tab><tab>if self[i].selected:<tab><tab><tab>to_delete.append(i)<tab>to_delete.reverse()<tab>for i in to_delete:<tab><tab>self.pop(i)<tab>if len(to_delete) > 0:<tab><tab>first_to_delete = to_delete[-1]<tab><tab><IF-STMT><tab><tab><tab>self[0].selected = True<tab><tab>elif first_to_delete > 0:<tab><tab><tab>self[first_to_delete - 1].selected = True",0,if first_to_delete == 0 and len ( self ) > 0 :,if first_to_delete == 0 :,0.13953446830532912,46.21246966669783,0.40277777777777773
"def update(self, update_tracks=True):<tab>self.enable_update_metadata_images(False)<tab>old_album_title = self.metadata[""album""]<tab>self.metadata[""album""] = config.setting[""nat_name""]<tab>for track in self.tracks:<tab><tab><IF-STMT><tab><tab><tab>track.metadata[""album""] = self.metadata[""album""]<tab><tab>for file in track.linked_files:<tab><tab><tab>track.update_file_metadata(file)<tab>self.enable_update_metadata_images(True)<tab>super().update(update_tracks)",0,"if old_album_title == track . metadata [ ""album"" ] :",if track . title == old_album_title :,0.08031118527626907,31.45828435509219,0.6
"def on_input(self, target, message):<tab>if message.strip() == """":<tab><tab>self.panel(""No commit message provided"")<tab><tab>return<tab>if target:<tab><tab>command = [""git"", ""add""]<tab><tab><IF-STMT><tab><tab><tab>command.append(""--all"")<tab><tab>else:<tab><tab><tab>command.extend((""--"", target))<tab><tab>self.run_command(command, functools.partial(self.add_done, message))<tab>else:<tab><tab>self.add_done(message, """")",0,"if target == ""*"" :","if target == """" :",0.39477865547525276,61.29752413741059,1.0
"def go_to_last_edit_location(self):<tab>if self.last_edit_cursor_pos is not None:<tab><tab>filename, position = self.last_edit_cursor_pos<tab><tab><IF-STMT><tab><tab><tab>self.last_edit_cursor_pos = None<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>self.load(filename)<tab><tab><tab>editor = self.get_current_editor()<tab><tab><tab>if position < editor.document().characterCount():<tab><tab><tab><tab>editor.set_cursor_position(position)",0,if not osp . isfile ( filename ) :,if filename is None :,0.0168380461076173,6.316906128202129,0.2361111111111111
"def returnByType(self, results):<tab>new_results = {}<tab>for r in results:<tab><tab>type_name = r.get(""type"", ""movie"") + ""s""<tab><tab><IF-STMT><tab><tab><tab>new_results[type_name] = []<tab><tab>new_results[type_name].append(r)<tab># Combine movies, needs a cleaner way..<tab>if ""movies"" in new_results:<tab><tab>new_results[""movies""] = self.combineOnIMDB(new_results[""movies""])<tab>return new_results",1,if type_name not in new_results :,if type_name not in new_results :,0.75,100.00000000000004,1.0
"def cache_sns_topics_across_accounts() -> bool:<tab>function: str = f""{__name__}.{sys._getframe().f_code.co_name}""<tab># First, get list of accounts<tab>accounts_d: list = async_to_sync(get_account_id_to_name_mapping)()<tab>for account_id in accounts_d.keys():<tab><tab>if config.get(""environment"") == ""prod"":<tab><tab><tab>cache_sns_topics_for_account.delay(account_id)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cache_sns_topics_for_account.delay(account_id)<tab>stats.count(f""{function}.success"")<tab>return True",0,"if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",if account_id not in accounts_d . keys ( ) :,0.1345774348712745,12.63053821392549,0.2857142857142857
"def get(self, subject, topic):<tab>""""""Handles GET requests.""""""<tab>if subject in feconf.AVAILABLE_LANDING_PAGES:<tab><tab><IF-STMT><tab><tab><tab>self.render_template(""topic-landing-page.mainpage.html"")<tab><tab>else:<tab><tab><tab>raise self.PageNotFoundException<tab>else:<tab><tab>raise self.PageNotFoundException",0,if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,if topic in feconf . available_LANDING_PAGES [ subject ] . mainpage :,0.4240739088042924,61.47881529512643,0.8461538461538461
"def callback(compiled):<tab><IF-STMT><tab><tab>logger.show_tabulated(<tab><tab><tab>""Compiled"", showpath(codepath), ""without writing to file.""<tab><tab>)<tab>else:<tab><tab>with univ_open(destpath, ""w"") as opened:<tab><tab><tab>writefile(opened, compiled)<tab><tab>logger.show_tabulated(""Compiled to"", showpath(destpath), ""."")<tab>if self.show:<tab><tab>print(compiled)<tab>if run:<tab><tab>if destpath is None:<tab><tab><tab>self.execute(compiled, path=codepath, allow_show=False)<tab><tab>else:<tab><tab><tab>self.execute_file(destpath)",0,if destpath is None :,if self . show :,0.03412306583404374,12.703318703865365,0.23809523809523808
"def _find_start_index(self, string, start, end):<tab>while True:<tab><tab>index = string.find(""{"", start, end) - 1<tab><tab>if index < 0:<tab><tab><tab>return -1<tab><tab><IF-STMT><tab><tab><tab>return index<tab><tab>start = index + 2",0,"if self . _start_index_is_ok ( string , index ) :","if string [ index ] == ""}"" :",0.015805905348207437,3.071855691538747,0.38461538461538464
"def _get_nlu_target_format(export_path: Text) -> Text:<tab>guessed_format = loading.guess_format(export_path)<tab>if guessed_format not in {MARKDOWN, RASA, RASA_YAML}:<tab><tab>if rasa.shared.data.is_likely_json_file(export_path):<tab><tab><tab>guessed_format = RASA<tab><tab>elif rasa.shared.data.is_likely_markdown_file(export_path):<tab><tab><tab>guessed_format = MARKDOWN<tab><tab><IF-STMT><tab><tab><tab>guessed_format = RASA_YAML<tab>return guessed_format",1,elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,0.75,100.00000000000004,1.0
"def moveToThreadNext(self):<tab>""""""Move a position to threadNext position.""""""<tab>p = self<tab>if p.v:<tab><tab>if p.v.children:<tab><tab><tab>p.moveToFirstChild()<tab><tab>el<IF-STMT><tab><tab><tab>p.moveToNext()<tab><tab>else:<tab><tab><tab>p.moveToParent()<tab><tab><tab>while p:<tab><tab><tab><tab>if p.hasNext():<tab><tab><tab><tab><tab>p.moveToNext()<tab><tab><tab><tab><tab>break  # found<tab><tab><tab><tab>p.moveToParent()<tab><tab><tab># not found.<tab>return p",1,if p . hasNext ( ) :,if p . hasNext ( ) :,0.75,100.00000000000004,1.0
"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None):<tab>for attr in attributes:<tab><tab>value = getattr(obj, attr, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>name = name_fmt % attr<tab><tab>if formatter is not None:<tab><tab><tab>value = formatter(attr, value)<tab><tab>info_add(name, value)",1,if value is None :,if value is None :,0.75,100.00000000000004,1.0
"def getElement(self, aboutUri, namespace, name):<tab>for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""):<tab><tab><IF-STMT><tab><tab><tab>attr = desc.getAttributeNodeNS(namespace, name)<tab><tab><tab>if attr != None:<tab><tab><tab><tab>yield attr<tab><tab><tab>for element in desc.getElementsByTagNameNS(namespace, name):<tab><tab><tab><tab>yield element",0,"if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :","if desc . getAttributeNS ( namespace , name ) == aboutUri :",0.2742963054628733,43.542673021606866,0.5510204081632654
def run(self):<tab>while not self.completed:<tab><tab>if self.block:<tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab><IF-STMT><tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab>if dt > self.timeout:<tab><tab><tab><tab>self.stop()<tab><tab>if self.counter == self.count:<tab><tab><tab>self.stop(),0,if self . timeout is not None :,if self . counter == self . count :,0.1132346497660848,16.784459625186194,0.2804232804232804
"def _parse_fixits(message, titer, line):<tab>""""""Parses fixit messages.""""""<tab>while (<tab><tab>OutputParser.message_line_re.match(line) is None<tab><tab>and OutputParser.note_line_re.match(line) is None<tab>):<tab><tab>message_text = line.strip()<tab><tab><IF-STMT><tab><tab><tab>message.fixits.append(<tab><tab><tab><tab>Note(<tab><tab><tab><tab><tab>message.path,<tab><tab><tab><tab><tab>message.line,<tab><tab><tab><tab><tab>line.find(message_text) + 1,<tab><tab><tab><tab><tab>message_text,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>line = next(titer)<tab>return line",0,"if message_text != """" :",if message_text :,0.06767423853569741,1e-10,1.0
"def _connect_db(self, force_reconnect=False):<tab>thread_id = thread.get_ident()<tab>if force_reconnect and thread_id in ENGINES:<tab><tab>del ENGINES[thread_id]<tab>conn = None<tab>try:<tab><tab>engine = ENGINES[thread_id]<tab><tab>conn = engine.connect()<tab><tab>_test = conn.execute(""SELECT 1"")<tab><tab>_test.fetchall()<tab>except (KeyError, MySQLdb.OperationalError):<tab><tab><IF-STMT><tab><tab><tab>conn.close()<tab><tab>engine = sqla.create_engine(self.db_url, pool_recycle=3600)<tab><tab>ENGINES[thread_id] = engine<tab><tab>conn = engine.connect()<tab>return conn",1,if conn :,if conn :,0.5311706625951745,1e-10,1.0
"def read(self, n):<tab>if self.current_frame:<tab><tab>data = self.current_frame.read(n)<tab><tab><IF-STMT><tab><tab><tab>self.current_frame = None<tab><tab><tab>return self.file_read(n)<tab><tab>if len(data) < n:<tab><tab><tab>raise UnpicklingError(""pickle exhausted before end of frame"")<tab><tab>return data<tab>else:<tab><tab>return self.file_read(n)",0,if not data and n != 0 :,if not data :,0.07898193091364736,18.306026428729766,0.5102040816326531
"def __setLoadCmd(self):<tab>base = self.__rawLoadCmd<tab>for _ in range(self.__machHeader.ncmds):<tab><tab>command = LOAD_COMMAND.from_buffer_copy(base)<tab><tab><IF-STMT><tab><tab><tab>segment = SEGMENT_COMMAND.from_buffer_copy(base)<tab><tab><tab>self.__setSections(segment, base[56:], 32)<tab><tab>elif command.cmd == MACHOFlags.LC_SEGMENT_64:<tab><tab><tab>segment = SEGMENT_COMMAND64.from_buffer_copy(base)<tab><tab><tab>self.__setSections(segment, base[72:], 64)<tab><tab>base = base[command.cmdsize :]",0,if command . cmd == MACHOFlags . LC_SEGMENT :,if command . cmd == MACHOFlags . LC_SEGMENT_128 :,0.62709085524794,77.4403141014203,1.0
"def emit_post_sync_signal(created_models, verbosity, interactive, db):<tab># Emit the post_sync signal for every application.<tab>for app in models.get_apps():<tab><tab>app_name = app.__name__.split(""."")[-2]<tab><tab><IF-STMT><tab><tab><tab>print(""Running post-sync handlers for application %s"" % app_name)<tab><tab>models.signals.post_syncdb.send(<tab><tab><tab>sender=app,<tab><tab><tab>app=app,<tab><tab><tab>created_models=created_models,<tab><tab><tab>verbosity=verbosity,<tab><tab><tab>interactive=interactive,<tab><tab><tab>db=db,<tab><tab>)",0,if verbosity >= 2 :,if verbosity > 1 :,0.31497877230811644,34.98330125272253,0.6
"def git_pull(args):<tab>if len(args) <= 1:<tab><tab>repo = _get_repo()<tab><tab>_confirm_dangerous()<tab><tab>url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """")<tab><tab>if url in repo.remotes:<tab><tab><tab>origin = url<tab><tab><tab>url = repo.remotes.get(origin)<tab><tab><IF-STMT><tab><tab><tab>repo.pull(origin_uri=url)<tab><tab>else:<tab><tab><tab>print(""No pull URL."")<tab>else:<tab><tab>print(command_help[""git pull""])",1,if url :,if url :,0.5311706625951745,1e-10,1.0
"def version(self):<tab>try:<tab><tab>return self._version<tab>except AttributeError:<tab><tab>for line in self._get_metadata(self.PKG_INFO):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._version = safe_version(line.split("":"", 1)[1].strip())<tab><tab><tab><tab>return self._version<tab><tab>else:<tab><tab><tab>tmpl = ""Missing 'Version:' header and/or %s file""<tab><tab><tab>raise ValueError(tmpl % self.PKG_INFO, self)",0,"if line . lower ( ) . startswith ( ""version:"" ) :","if line . startswith ( ""version:"" ) :",0.3019421647848402,62.813344649844524,0.5882352941176471
"def increment(self, metric, labels, delta):<tab>""""""Increment a value by |delta|.""""""<tab>with self._lock:<tab><tab>key = self._get_key(metric.name, labels)<tab><tab><IF-STMT><tab><tab><tab>start_time = self._store[key].start_time<tab><tab><tab>value = self._store[key].value + delta<tab><tab>else:<tab><tab><tab>start_time = time.time()<tab><tab><tab>value = metric.default_value + delta<tab><tab>self._store[key] = _StoreValue(metric, labels, start_time, value)",1,if key in self . _store :,if key in self . _store :,0.75,100.00000000000004,1.0
"def get_current_connections(session):<tab>""""""Retrieves open connections using the the given session""""""<tab># Use Show process list to count the open sesions.<tab>res = session.sql(""SHOW PROCESSLIST"").execute()<tab>rows = res.fetch_all()<tab>connections = {}<tab>for row in rows:<tab><tab><IF-STMT><tab><tab><tab>connections[row.get_string(""User"")] = [row.get_string(""Host"")]<tab><tab>else:<tab><tab><tab>connections[row.get_string(""User"")].append(row.get_string(""Host""))<tab>return connections",0,"if row . get_string ( ""User"" ) not in connections :","if ""User"" not in connections :",0.2126844880253655,21.550647307815467,0.32051282051282054
"def asset(*paths):<tab>for path in paths:<tab><tab>fspath = www_root + ""/assets/"" + path<tab><tab>etag = """"<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>etag = asset_etag(fspath)<tab><tab><tab>else:<tab><tab><tab><tab>os.stat(fspath)<tab><tab>except FileNotFoundError as e:<tab><tab><tab>if path == paths[-1]:<tab><tab><tab><tab>if not os.path.exists(fspath + "".spt""):<tab><tab><tab><tab><tab>tell_sentry(e, {})<tab><tab><tab>else:<tab><tab><tab><tab>continue<tab><tab>except Exception as e:<tab><tab><tab>tell_sentry(e, {})<tab><tab>return asset_url + path + (etag and ""?etag="" + etag)",0,if env . cache_static :,"if os . path . exists ( fspath + "".etag"" ) :",0.02446681277480503,3.4585921141027356,0.2605042016806723
def thread_loop(self) -> None:<tab>while not self.stop_event.is_set():<tab><tab>time.sleep(1)<tab><tab>new_trials = self.study.trials<tab><tab>with self.lock:<tab><tab><tab>need_to_add_callback = self.new_trials is None<tab><tab><tab>self.new_trials = new_trials<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.doc.add_next_tick_callback(self.update_callback),1,if need_to_add_callback :,if need_to_add_callback :,0.5311706625951745,1e-10,1.0
"def _cache_db_tables_iterator(tables, cache_alias, db_alias):<tab>no_tables = not tables<tab>cache_aliases = settings.CACHES if cache_alias is None else (cache_alias,)<tab>db_aliases = settings.DATABASES if db_alias is None else (db_alias,)<tab>for db_alias in db_aliases:<tab><tab>if no_tables:<tab><tab><tab>tables = connections[db_alias].introspection.table_names()<tab><tab><IF-STMT><tab><tab><tab>for cache_alias in cache_aliases:<tab><tab><tab><tab>yield cache_alias, db_alias, tables",0,if tables :,if cache_aliases :,0.3197504490129165,1e-10,0.5555555555555555
"def remove_subscriber(self, topic, subscriber):<tab>if subscriber in self.subscribers[topic]:<tab><tab>if hasattr(subscriber, ""_pyroRelease""):<tab><tab><tab>subscriber._pyroRelease()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>proxy = self.proxy_cache[subscriber._pyroUri]<tab><tab><tab><tab>proxy._pyroRelease()<tab><tab><tab><tab>del self.proxy_cache[subscriber._pyroUri]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab>self.subscribers[topic].discard(subscriber)",0,"if hasattr ( subscriber , ""_pyroUri"" ) :","elif hasattr ( subscriber , ""_pyroUri"" ) :",0.40018302522632676,89.31539818068698,0.6
"def test_constructor(job_id):<tab>with patch(""apscheduler.job.Job._modify"") as _modify:<tab><tab>scheduler_mock = MagicMock(BaseScheduler)<tab><tab>job = Job(scheduler_mock, id=job_id)<tab><tab>assert job._scheduler is scheduler_mock<tab><tab>assert job._jobstore_alias is None<tab><tab>modify_kwargs = _modify.call_args[1]<tab><tab><IF-STMT><tab><tab><tab>assert len(modify_kwargs[""id""]) == 32<tab><tab>else:<tab><tab><tab>assert modify_kwargs[""id""] == job_id",0,if job_id is None :,"if modify_kwargs [ ""id"" ] is None :",0.1102731445124358,14.991106946711685,1.0
"def get_connection(self):<tab>if self.config.proxy_host != """":<tab><tab>return httplib.HTTPConnection(self.config.proxy_host, self.config.proxy_port)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return httplib.HTTPSConnection(self.config.simpledb_host)<tab><tab>else:<tab><tab><tab>return httplib.HTTPConnection(self.config.simpledb_host)",0,if self . config . use_https :,"if self . config . simpledb_host == """" :",0.2800330458634526,31.455601883230702,1.0
"def notify_login(self, ipaddress=""""):<tab>if app.NOTIFY_ON_LOGIN:<tab><tab>update_text = common.notifyStrings[common.NOTIFY_LOGIN_TEXT]<tab><tab>title = common.notifyStrings[common.NOTIFY_LOGIN]<tab><tab><IF-STMT><tab><tab><tab>self._notify_pht(title, update_text.format(ipaddress))",0,if update_text and title and ipaddress :,if update_text :,0.03885753308224148,1e-10,0.3
"def _getItemHeight(self, item, ctrl=None):<tab>""""""Returns the full height of the item to be inserted in the form""""""<tab>if type(ctrl) == psychopy.visual.TextBox2:<tab><tab>return ctrl.size[1]<tab>if type(ctrl) == psychopy.visual.Slider:<tab><tab># Set radio button layout<tab><tab>if item[""layout""] == ""horiz"":<tab><tab><tab>return 0.03 + ctrl.labelHeight * 3<tab><tab><IF-STMT><tab><tab><tab># for vertical take into account the nOptions<tab><tab><tab>return ctrl.labelHeight * len(item[""options""])",0,"elif item [ ""layout"" ] == ""vert"" :","elif item [ ""layout"" ] == ""horizontal"" :",0.8535533905932737,79.10665071754353,1.0
"def _get_errors_lines(self):<tab>""""""Return the number of lines that contains errors to highlight.""""""<tab>errors_lines = []<tab>block = self.document().begin()<tab>while block.isValid():<tab><tab>user_data = get_user_data(block)<tab><tab><IF-STMT><tab><tab><tab>errors_lines.append(block.blockNumber())<tab><tab>block = block.next()<tab>return errors_lines",0,if user_data . error :,if not user_data . errors :,0.060348847821073665,38.260294162784454,0.37142857142857144
"def set_pbar_fraction(self, frac, progress, stage=None):<tab>gtk.gdk.threads_enter()<tab>try:<tab><tab>self.is_pulsing = False<tab><tab>self.set_stage_text(stage or _(""Processing...""))<tab><tab>self.pbar.set_text(progress)<tab><tab>if frac > 1:<tab><tab><tab>frac = 1.0<tab><tab><IF-STMT><tab><tab><tab>frac = 0<tab><tab>self.pbar.set_fraction(frac)<tab>finally:<tab><tab>gtk.gdk.threads_leave()",0,if frac < 0 :,elif frac == 0 :,0.058575650843433,17.965205598154213,0.6
"def list_files(basedir):<tab>""""""List files in the directory rooted at |basedir|.""""""<tab>if not os.path.isdir(basedir):<tab><tab>raise NoSuchDirectory(basedir)<tab>directories = [""""]<tab>while directories:<tab><tab>d = directories.pop()<tab><tab>for basename in os.listdir(os.path.join(basedir, d)):<tab><tab><tab>filename = os.path.join(d, basename)<tab><tab><tab>if os.path.isdir(os.path.join(basedir, filename)):<tab><tab><tab><tab>directories.append(filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield filename",0,"elif os . path . exists ( os . path . join ( basedir , filename ) ) :","elif os . path . isfile ( os . path . join ( d , filename ) ) :",0.844418252673328,68.8836505346656,0.6
"def assistive(self):<tab>""""""Detects if item can be used as assistance""""""<tab># Make sure we cache results<tab>if self.__assistive is None:<tab><tab>assistive = False<tab><tab># Go through all effects and find first assistive<tab><tab>for effect in self.effects.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab># If we find one, stop and mark item as assistive<tab><tab><tab><tab>assistive = True<tab><tab><tab><tab>break<tab><tab>self.__assistive = assistive<tab>return self.__assistive",0,if effect . isAssistance is True :,if effect . assistive :,0.1445322911044803,28.641904579795423,0.38095238095238093
"def closest_unseen(self, row1, col1, filter=None):<tab># find the closest unseen from this row/col<tab>min_dist = maxint<tab>closest_unseen = None<tab>for row in range(self.height):<tab><tab>for col in range(self.width):<tab><tab><tab>if filter is None or (row, col) not in filter:<tab><tab><tab><tab>if self.map[row][col] == UNSEEN:<tab><tab><tab><tab><tab>dist = self.distance(row1, col1, row, col)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab><tab><tab>closest_unseen = (row, col)<tab>return closest_unseen",1,if dist < min_dist :,if dist < min_dist :,0.75,100.00000000000004,1.0
"def _maybe_has_default_route(self):<tab>for route in self.iter_routes():<tab><tab><IF-STMT><tab><tab><tab>return True<tab>for iface in self.iter_interfaces():<tab><tab>for subnet in iface.get(""subnets"", []):<tab><tab><tab>for route in subnet.get(""routes"", []):<tab><tab><tab><tab>if self._is_default_route(route):<tab><tab><tab><tab><tab>return True<tab>return False",1,if self . _is_default_route ( route ) :,if self . _is_default_route ( route ) :,0.75,100.00000000000004,1.0
"def data(self, data):<tab>if data is None:<tab><tab>raise Exception(""Data cannot be None"")<tab>val = []<tab>for d in data:<tab><tab>if isinstance(d, str):<tab><tab><tab>val.append(bytes(d, ""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>val.append(d)<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Invalid type, data can only be an str or a bytes not {}: {}"".format(<tab><tab><tab><tab><tab>type(data), d<tab><tab><tab><tab>)<tab><tab><tab>)<tab>self.__data = val",1,"elif isinstance ( d , bytes ) :","elif isinstance ( d , bytes ) :",0.75,100.00000000000004,1.0
"def get_one_segment_function(data, context, echoerr):<tab>ext = data[""ext""]<tab>function_name = context[-2][1].get(""function"")<tab>if function_name:<tab><tab>module, function_name = get_function_strings(function_name, context, ext)<tab><tab>func = import_segment(function_name, data, context, echoerr, module=module)<tab><tab><IF-STMT><tab><tab><tab>yield func",1,if func :,if func :,0.5311706625951745,1e-10,1.0
"def generic_visit(self, node, parents=None):<tab>parents = (parents or []) + [node]<tab>for field, value in iter_fields(node):<tab><tab>if isinstance(value, list):<tab><tab><tab>for item in value:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.visit(item, parents)<tab><tab>elif isinstance(value, AST):<tab><tab><tab>self.visit(value, parents)",1,"if isinstance ( item , AST ) :","if isinstance ( item , AST ) :",0.75,100.00000000000004,1.0
"def find_scintilla_constants(f):<tab>lexers = []<tab>states = []<tab>for name in f.order:<tab><tab>v = f.features[name]<tab><tab><IF-STMT><tab><tab><tab>if v[""FeatureType""] == ""val"":<tab><tab><tab><tab>if name.startswith(""SCE_""):<tab><tab><tab><tab><tab>states.append((name, v[""Value""]))<tab><tab><tab><tab>elif name.startswith(""SCLEX_""):<tab><tab><tab><tab><tab>lexers.append((name, v[""Value""]))<tab>return (lexers, states)",0,"if v [ ""Category"" ] != ""Deprecated"" :","if v [ ""FeatureType"" ] == ""constant"" :",0.32991956560314195,28.917849332325716,1.0
"def things(self, query):<tab>limit = query.pop(""limit"", 100)<tab>offset = query.pop(""offset"", 0)<tab>keys = set(self.docs)<tab>for k, v in query.items():<tab><tab><IF-STMT><tab><tab><tab># query keys need to be flattened properly,<tab><tab><tab># this corrects any nested keys that have been included<tab><tab><tab># in values.<tab><tab><tab>flat = common.flatten_dict(v)[0]<tab><tab><tab>k += ""."" + web.rstrips(flat[0], "".key"")<tab><tab><tab>v = flat[1]<tab><tab>keys = set(k for k in self.filter_index(self.index, k, v) if k in keys)<tab>keys = sorted(keys)<tab>return keys[offset : offset + limit]",1,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,100.00000000000004,1.0
"def del_(self, key):<tab>initial_hash = hash_ = self.hash(key)<tab>while True:<tab><tab>if self._keys[hash_] is self._empty:<tab><tab><tab># That key was never assigned<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab># key found, assign with deleted sentinel<tab><tab><tab>self._keys[hash_] = self._deleted<tab><tab><tab>self._values[hash_] = self._deleted<tab><tab><tab>self._len -= 1<tab><tab><tab>return<tab><tab>hash_ = self._rehash(hash_)<tab><tab>if initial_hash == hash_:<tab><tab><tab># table is full and wrapped around<tab><tab><tab>return None",0,elif self . _keys [ hash_ ] == key :,if self . _keys [ hash_ ] == self . _deleted :,0.2984500999858346,59.687741756345,0.3333333333333333
"def test_204_invalid_content_length(self):<tab># 204 status with non-zero content length is malformed<tab>with ExpectLog(gen_log, "".*Response with code 204 should not have body""):<tab><tab>response = self.fetch(""/?error=1"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""requires HTTP/1.x"")<tab><tab>if self.http_client.configured_class != SimpleAsyncHTTPClient:<tab><tab><tab>self.skipTest(""curl client accepts invalid headers"")<tab><tab>self.assertEqual(response.code, 599)",0,if not self . http1 :,if response is None :,0.02713659235259708,10.400597689005304,0.25
"def __str__(self) -> str:<tab>text = ""\n""<tab>for k, r in self.result.items():<tab><tab>text += ""{}\n"".format(""#"" * 40)<tab><tab><IF-STMT><tab><tab><tab>text += ""# {} (failed)\n"".format(k)<tab><tab>else:<tab><tab><tab>text += ""# {} (succeeded)\n"".format(k)<tab><tab>text += ""{}\n"".format(""#"" * 40)<tab><tab>for sub_r in r:<tab><tab><tab>text += ""**** {}\n"".format(sub_r.name)<tab><tab><tab>text += ""{}\n"".format(sub_r)<tab>return text",0,if r . failed :,if len ( r ) == 0 :,0.028001459970687266,6.27465531099474,0.3148148148148148
"def DeleteTask():<tab>oid = request.form.get(""oid"", """")<tab>if oid:<tab><tab>result = Mongo.coll[""Task""].delete_one({""_id"": ObjectId(oid)})<tab><tab><IF-STMT><tab><tab><tab>result = Mongo.coll[""Result""].delete_many({""task_id"": ObjectId(oid)})<tab><tab><tab>if result:<tab><tab><tab><tab>return ""success""<tab>return ""fail""",0,if result . deleted_count > 0 :,if result :,0.03885753308224148,1e-10,0.7222222222222222
"def _replace_vars(self, line, extracted, env_variables):<tab>for e in extracted:<tab><tab><IF-STMT><tab><tab><tab>value = env_variables.get(e)<tab><tab><tab>if isinstance(value, dict) or isinstance(value, list):<tab><tab><tab><tab>value = pprint.pformat(value)<tab><tab><tab>decorated = self._decorate_var(e)<tab><tab><tab>line = line.replace(decorated, str(value))<tab>return line",1,if e in env_variables :,if e in env_variables :,0.75,100.00000000000004,1.0
"def should_include(service):<tab>for f in filt:<tab><tab>if f == ""status"":<tab><tab><tab>state = filt[f]<tab><tab><tab>containers = project.containers([service.name], stopped=True)<tab><tab><tab>if not has_container_with_state(containers, state):<tab><tab><tab><tab>return False<tab><tab>elif f == ""source"":<tab><tab><tab>source = filt[f]<tab><tab><tab>if source == ""image"" or source == ""build"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>raise UserError(""Invalid value for source filter: %s"" % source)<tab><tab>else:<tab><tab><tab>raise UserError(""Invalid filter: %s"" % f)<tab>return True",0,if source not in service . options :,"if not has_image_with_build ( containers , source ) :",0.019030985543513193,3.716499092256817,0.21875
def state_callback_loop():<tab>if usercallback:<tab><tab>when = 1<tab><tab>while (<tab><tab><tab>when<tab><tab><tab>and not self.future_removed.done()<tab><tab><tab>and not self.session.shutdownstarttime<tab><tab>):<tab><tab><tab>result = usercallback(self.get_state())<tab><tab><tab>when = (await result) if iscoroutine(result) else result<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await sleep(when),0,if when > 0.0 and not self . session . shutdownstarttime :,if when :,0.014772183860219557,1e-10,0.3333333333333333
"def __get_new_timeout(self, timeout):<tab>""""""When using --timeout_multiplier=#.#""""""<tab>self.__check_scope()<tab>try:<tab><tab>timeout_multiplier = float(self.timeout_multiplier)<tab><tab><IF-STMT><tab><tab><tab>timeout_multiplier = 0.5<tab><tab>timeout = int(math.ceil(timeout_multiplier * timeout))<tab><tab>return timeout<tab>except Exception:<tab><tab># Wrong data type for timeout_multiplier (expecting int or float)<tab><tab>return timeout",0,if timeout_multiplier <= 0.5 :,if timeout_multiplier < 0 :,0.06497877230811641,55.780028607687655,0.6190476190476191
"def readexactly(self, n):<tab>buf = b""""<tab>while n:<tab><tab>yield IORead(self.s)<tab><tab>res = self.s.read(n)<tab><tab>assert res is not None<tab><tab><IF-STMT><tab><tab><tab>yield IOReadDone(self.s)<tab><tab><tab>break<tab><tab>buf += res<tab><tab>n -= len(res)<tab>return buf",0,if not res :,if len ( res ) == 0 :,0.03661176184600709,6.27465531099474,0.48148148148148145
"def contract_rendering_pane(event):<tab>""""""Expand the rendering pane.""""""<tab>c = event.get(""c"")<tab>if c:<tab><tab>vr = c.frame.top.findChild(QtWidgets.QWidget, ""viewrendered_pane"")<tab><tab><IF-STMT><tab><tab><tab>vr.contract()<tab><tab>else:<tab><tab><tab># Just open the pane.<tab><tab><tab>viewrendered(event)",1,if vr :,if vr :,0.5311706625951745,1e-10,1.0
"def translate_headers(self, environ):<tab>""""""Translate CGI-environ header names to HTTP header names.""""""<tab>for cgiName in environ:<tab><tab># We assume all incoming header keys are uppercase already.<tab><tab><IF-STMT><tab><tab><tab>yield self.headerNames[cgiName], environ[cgiName]<tab><tab>elif cgiName[:5] == ""HTTP_"":<tab><tab><tab># Hackish attempt at recovering original header names.<tab><tab><tab>translatedHeader = cgiName[5:].replace(""_"", ""-"")<tab><tab><tab>yield translatedHeader, environ[cgiName]",1,if cgiName in self . headerNames :,if cgiName in self . headerNames :,0.75,100.00000000000004,1.0
"def get_value_from_string(self, string_value):<tab>""""""Return internal representation starting from CFN/user-input value.""""""<tab>param_value = self.get_default_value()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>string_value = str(string_value).strip()<tab><tab><tab>if string_value != ""NONE"":<tab><tab><tab><tab>param_value = int(string_value)<tab>except ValueError:<tab><tab>self.pcluster_config.warn(<tab><tab><tab>""Unable to convert the value '{0}' to an Integer. ""<tab><tab><tab>""Using default value for parameter '{1}'"".format(string_value, self.key)<tab><tab>)<tab>return param_value",0,if string_value is not None :,if string_value :,0.050438393472541504,1e-10,0.3142857142857143
"def monitor_filter(self):<tab>""""""Return filtered service objects list""""""<tab>services = self.client.services.list(filters={""label"": ""com.ouroboros.enable""})<tab>monitored_services = []<tab>for service in services:<tab><tab>ouro_label = service.attrs[""Spec""][""Labels""].get(""com.ouroboros.enable"")<tab><tab><IF-STMT><tab><tab><tab>monitored_services.append(service)<tab>self.data_manager.monitored_containers[self.socket] = len(monitored_services)<tab>self.data_manager.set(self.socket)<tab>return monitored_services",0,"if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",if ouro_label and ouro_label not in self . data_manager . monitored_containers :,0.13915164811268088,7.476943135957513,0.2142857142857143
"def nextEditable(self):<tab>""""""Moves focus of the cursor to the next editable window""""""<tab>if self.currentEditable is None:<tab><tab>if len(self._editableChildren):<tab><tab><tab>self._currentEditableRef = self._editableChildren[0]<tab>else:<tab><tab>for ref in weakref.getweakrefs(self.currentEditable):<tab><tab><tab>if ref in self._editableChildren:<tab><tab><tab><tab>cei = self._editableChildren.index(ref)<tab><tab><tab><tab>nei = cei + 1<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>nei = 0<tab><tab><tab><tab>self._currentEditableRef = self._editableChildren[nei]<tab>return self.currentEditable",1,if nei >= len ( self . _editableChildren ) :,if nei >= len ( self . _editableChildren ) :,0.75,100.00000000000004,1.0
"def linkify_cm_by_tp(self, timeperiods):<tab>for rm in self:<tab><tab>mtp_name = rm.modulation_period.strip()<tab><tab># The new member list, in id<tab><tab>mtp = timeperiods.find_by_name(mtp_name)<tab><tab><IF-STMT><tab><tab><tab>err = (<tab><tab><tab><tab>""Error: the business impact modulation '%s' got an unknown ""<tab><tab><tab><tab>""modulation_period '%s'"" % (rm.get_name(), mtp_name)<tab><tab><tab>)<tab><tab><tab>rm.configuration_errors.append(err)<tab><tab>rm.modulation_period = mtp",0,"if mtp_name != """" and mtp is None :",if mtp is None :,0.23422139662651506,15.340817918113808,0.3148148148148148
def close_open_fds(keep=None):  # noqa<tab>keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None]<tab>for fd in reversed(range(get_fdmax(default=2048))):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.close(fd)<tab><tab><tab>except OSError as exc:<tab><tab><tab><tab>if exc.errno != errno.EBADF:<tab><tab><tab><tab><tab>raise,1,if fd not in keep :,if fd not in keep :,0.75,100.00000000000004,1.0
"def _append_child_from_unparsed_xml(father_node, unparsed_xml):<tab>""""""Append child xml nodes to a node.""""""<tab>dom_tree = parseString(unparsed_xml)<tab>if dom_tree.hasChildNodes():<tab><tab>first_child = dom_tree.childNodes[0]<tab><tab><IF-STMT><tab><tab><tab>child_nodes = first_child.childNodes<tab><tab><tab>for _ in range(len(child_nodes)):<tab><tab><tab><tab>childNode = child_nodes.item(0)<tab><tab><tab><tab>father_node.appendChild(childNode)<tab><tab><tab>return<tab>raise DistutilsInternalError(<tab><tab>""Could not Append append elements to "" ""the Windows msi descriptor.""<tab>)",0,if first_child . hasChildNodes ( ) :,if first_child . nodeType == Node . ELEMENT_NODE :,0.07853087956397244,27.824623288353134,0.38461538461538464
"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab><IF-STMT><tab><tab><tab>body = six.ensure_str(request.body)<tab><tab><tab>if old in body:<tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",0,if is_text_payload ( request ) and request . body :,if request . body :,0.13897580794314457,11.688396478408103,0.5
"def __init__(self, **options):<tab>self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True)<tab>self.disabled_modules = get_list_opt(options, ""disabled_modules"", [])<tab>self._functions = set()<tab>if self.func_name_highlighting:<tab><tab>from pygments.lexers._luabuiltins import MODULES<tab><tab>for mod, func in MODULES.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._functions.update(func)<tab>RegexLexer.__init__(self, **options)",1,if mod not in self . disabled_modules :,if mod not in self . disabled_modules :,0.75,100.00000000000004,1.0
"def GetBestSizeForParentSize(self, parentSize):<tab>""""""Finds the best width and height given the parent's width and height.""""""<tab>if len(self.GetChildren()) == 1:<tab><tab>win = self.GetChildren()[0]<tab><tab><IF-STMT><tab><tab><tab>temp_dc = wx.ClientDC(self)<tab><tab><tab>childSize = win.GetBestSizeForParentSize(parentSize)<tab><tab><tab>clientParentSize = self._art.GetPanelClientSize(<tab><tab><tab><tab>temp_dc, self, wx.Size(*parentSize), None<tab><tab><tab>)<tab><tab><tab>overallSize = self._art.GetPanelSize(<tab><tab><tab><tab>temp_dc, self, wx.Size(*clientParentSize), None<tab><tab><tab>)<tab><tab><tab>return overallSize<tab>return self.GetSize()",0,"if isinstance ( win , RibbonControl ) :",if win . IsShown ( ) :,0.03836215687039321,14.31720073264775,0.3148148148148148
"def pid_from_name(name):<tab>processes = []<tab>for pid in os.listdir(""/proc""):<tab><tab>try:<tab><tab><tab>pid = int(pid)<tab><tab><tab>pname, cmdline = SunProcess._name_args(pid)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pid<tab><tab><tab>if name in cmdline.split("" "", 1)[0]:<tab><tab><tab><tab>return pid<tab><tab>except:<tab><tab><tab>pass<tab>raise ProcessException(""No process with such name: %s"" % name)",0,if name in pname :,if name in cmdline :,0.39477865547525276,42.72870063962342,0.6666666666666666
"def __get_file_by_num(self, num, file_list, idx=0):<tab>for element in file_list:<tab><tab>if idx == num:<tab><tab><tab>return element<tab><tab><IF-STMT><tab><tab><tab>i = self.__get_file_by_num(num, element[3], idx + 1)<tab><tab><tab>if not isinstance(i, int):<tab><tab><tab><tab>return i<tab><tab><tab>idx = i<tab><tab>else:<tab><tab><tab>idx += 1<tab>return idx",0,if element [ 3 ] and element [ 4 ] :,"elif element [ 0 ] == ""file"" :",0.14796966020170874,8.913765521398126,0.1794871794871795
"def scan_block_scalar_indentation(self):<tab># See the specification for details.<tab>chunks = []<tab>max_indent = 0<tab>end_mark = self.get_mark()<tab>while self.peek() in "" \r\n\x85\u2028\u2029"":<tab><tab>if self.peek() != "" "":<tab><tab><tab>chunks.append(self.scan_line_break())<tab><tab><tab>end_mark = self.get_mark()<tab><tab>else:<tab><tab><tab>self.forward()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>max_indent = self.column<tab>return chunks, max_indent, end_mark",1,if self . column > max_indent :,if self . column > max_indent :,0.75,100.00000000000004,1.0
"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab>if col == LAND:<tab><tab><tab><tab>tmp += "".""<tab><tab><tab>elif col == BARRIER:<tab><tab><tab><tab>tmp += ""%""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""*""<tab><tab><tab>elif col == UNSEEN:<tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",0,elif col == FOOD :,elif col == LEGAL :,0.6428720214849399,53.7284965911771,0.6
"def prepare_data(entry):<tab>branch_wise_entries = {}<tab>gross_pay = 0<tab>for d in entry:<tab><tab>gross_pay += d.gross_pay<tab><tab><IF-STMT><tab><tab><tab>branch_wise_entries[d.branch][d.mode_of_payment] = d.net_pay<tab><tab>else:<tab><tab><tab>branch_wise_entries.setdefault(d.branch, {}).setdefault(<tab><tab><tab><tab>d.mode_of_payment, d.net_pay<tab><tab><tab>)<tab>return branch_wise_entries, gross_pay",0,if branch_wise_entries . get ( d . branch ) :,if d . branch in branch_wise_entries :,0.06410035254389929,37.773311868264216,0.3333333333333333
"def __init__(self, uuid=None, cluster_state=None, children=None, **kwargs):<tab>self.uuid = uuid<tab>self.cluster_state = cluster_state<tab>if self.cluster_state is not None:<tab><tab>self.children = WeakSet(<tab><tab><tab>self.cluster_state.tasks.get(task_id)<tab><tab><tab>for task_id in children or ()<tab><tab><tab><IF-STMT><tab><tab>)<tab>else:<tab><tab>self.children = WeakSet()<tab>self._serializer_handlers = {<tab><tab>""children"": self._serializable_children,<tab><tab>""root"": self._serializable_root,<tab><tab>""parent"": self._serializable_parent,<tab>}<tab>if kwargs:<tab><tab>self.__dict__.update(kwargs)",0,if task_id in self . cluster_state . tasks,if task_id is not None,0.14019547252112605,20.126703311713307,0.25
"def listdir(self, d):<tab>try:<tab><tab>return [<tab><tab><tab>p<tab><tab><tab>for p in os.listdir(d)<tab><tab><tab><IF-STMT><tab><tab>]<tab>except OSError:<tab><tab>return []",0,"if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )","if os . path . isdir ( os . path . join ( d , p ) )",0.4798319800272495,45.94258240359268,0.2657142857142857
"def send_packed_command(self, command, check_health=True):<tab>if not self._sock:<tab><tab>self.connect()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>command = [command]<tab><tab>for item in command:<tab><tab><tab>self._sock.sendall(item)<tab>except socket.error as e:<tab><tab>self.disconnect()<tab><tab>if len(e.args) == 1:<tab><tab><tab>_errno, errmsg = ""UNKNOWN"", e.args[0]<tab><tab>else:<tab><tab><tab>_errno, errmsg = e.args<tab><tab>raise ConnectionError(<tab><tab><tab>""Error %s while writing to socket. %s."" % (_errno, errmsg)<tab><tab>)<tab>except Exception:<tab><tab>self.disconnect()<tab><tab>raise",0,"if isinstance ( command , str ) :","if isinstance ( command , list ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def run(self):<tab>""""""Start the scanner""""""<tab>logging.info(""Dirscanner starting up"")<tab>self.shutdown = False<tab>while not self.shutdown:<tab><tab># Wait to be woken up or triggered<tab><tab>with self.loop_condition:<tab><tab><tab>self.loop_condition.wait(self.dirscan_speed)<tab><tab><IF-STMT><tab><tab><tab>self.scan()",0,if self . dirscan_speed and not self . shutdown :,if self . shutdown :,0.20098530533352493,20.73625029909464,0.398989898989899
"def __aexit__(<tab>self, exc_type: type, exc_value: BaseException, tb: TracebackType) -> None:<tab>if exc_type is not None:<tab><tab>await self.close()<tab>await self._task<tab>while not self._receive_queue.empty():<tab><tab>data = await self._receive_queue.get()<tab><tab>if isinstance(data, bytes):<tab><tab><tab>self.response_data.extend(data)<tab><tab><IF-STMT><tab><tab><tab>raise data",0,"elif not isinstance ( data , HTTPDisconnect ) :","elif isinstance ( data , Exception ) :",0.26982669155652367,37.70794596593207,0.2698412698412698
"def f(msg):<tab>text = extractor(msg)<tab>for px in prefix:<tab><tab><IF-STMT><tab><tab><tab>chunks = text[len(px) :].split(separator)<tab><tab><tab>return chunks[0], (chunks[1:],) if pass_args else ()<tab>return ((None,),)  # to distinguish with `None`",1,if text . startswith ( px ) :,if text . startswith ( px ) :,0.75,100.00000000000004,1.0
"def _flatten(*args):<tab>ahs = set()<tab>if len(args) > 0:<tab><tab>for item in args:<tab><tab><tab>if type(item) is ActionHandle:<tab><tab><tab><tab>ahs.add(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for ah in item:<tab><tab><tab><tab><tab>if type(ah) is not ActionHandle:  # pragma:nocover<tab><tab><tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(ah))<tab><tab><tab><tab><tab>ahs.add(ah)<tab><tab><tab>else:  # pragma:nocover<tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(item))<tab>return ahs",0,"elif type ( item ) in ( list , tuple , dict , set ) :",elif type ( item ) is list :,0.18540524051439924,20.687381245863396,0.4842105263157895
"def find_class(self, module, name):<tab># Subclasses may override this.<tab>sys.audit(""pickle.find_class"", module, name)<tab>if self.proto < 3 and self.fix_imports:<tab><tab>if (module, name) in _compat_pickle.NAME_MAPPING:<tab><tab><tab>module, name = _compat_pickle.NAME_MAPPING[(module, name)]<tab><tab><IF-STMT><tab><tab><tab>module = _compat_pickle.IMPORT_MAPPING[module]<tab>__import__(module, level=0)<tab>if self.proto >= 4:<tab><tab>return _getattribute(sys.modules[module], name)[0]<tab>else:<tab><tab>return getattr(sys.modules[module], name)",1,elif module in _compat_pickle . IMPORT_MAPPING :,elif module in _compat_pickle . IMPORT_MAPPING :,0.75,100.00000000000004,1.0
"def _send_until_done(self, data):<tab>while True:<tab><tab>try:<tab><tab><tab>return self.connection.send(data)<tab><tab>except OpenSSL.SSL.WantWriteError:<tab><tab><tab>wr = util.wait_for_write(self.socket, self.socket.gettimeout())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise timeout()<tab><tab><tab>continue<tab><tab>except OpenSSL.SSL.SysCallError as e:<tab><tab><tab>raise SocketError(str(e))",0,if not wr :,if wr is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def __new__(cls, *args, **kwargs):<tab>""""""Hack to ensure method defined as async are implemented as such.""""""<tab>coroutines = inspect.getmembers(BaseManager, predicate=inspect.iscoroutinefunction)<tab>for coroutine in coroutines:<tab><tab>implemented_method = getattr(cls, coroutine[0])<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""The method %s must be a coroutine"" % implemented_method)<tab>return super().__new__(cls, *args, **kwargs)",0,if not inspect . iscoroutinefunction ( implemented_method ) :,"if not hasattr ( implemented_method , ""__call__"" ) :",0.04471782256315008,19.345299022826193,0.48484848484848486
"def add_directive(self, name, obj, content=None, arguments=None, **options):<tab>if isinstance(obj, clstypes) and issubclass(obj, Directive):<tab><tab><IF-STMT><tab><tab><tab>raise ExtensionError(<tab><tab><tab><tab>""when adding directive classes, no "" ""additional arguments may be given""<tab><tab><tab>)<tab><tab>directives.register_directive(name, directive_dwim(obj))<tab>else:<tab><tab>obj.content = content<tab><tab>obj.arguments = arguments<tab><tab>obj.options = options<tab><tab>directives.register_directive(name, obj)",0,if content or arguments or options :,if arguments is None :,0.1905133180863203,9.423716574733431,0.1875
"def create(self, w):<tab>if w.use_eventloop:<tab><tab># does not use dedicated timer thread.<tab><tab>w.timer = _Timer(max_interval=10.0)<tab>else:<tab><tab><IF-STMT><tab><tab><tab># Default Timer is set by the pool, as for example, the<tab><tab><tab># eventlet pool needs a custom timer implementation.<tab><tab><tab>w.timer_cls = w.pool_cls.Timer<tab><tab>w.timer = self.instantiate(<tab><tab><tab>w.timer_cls,<tab><tab><tab>max_interval=w.timer_precision,<tab><tab><tab>on_error=self.on_timer_error,<tab><tab><tab>on_tick=self.on_timer_tick,<tab><tab>)",0,if not w . timer_cls :,if w . timer_cls is None :,0.10494632798085189,48.54917717073236,0.30952380952380953
"def _config(_molecule_file, request):<tab>with open(_molecule_file) as f:<tab><tab>d = util.safe_load(f)<tab>if hasattr(request, ""param""):<tab><tab><IF-STMT><tab><tab><tab>d2 = util.safe_load(request.getfixturevalue(request.param))<tab><tab>else:<tab><tab><tab>d2 = request.getfixturevalue(request.param)<tab><tab># print(100, d)<tab><tab># print(200, d2)<tab><tab>d = util.merge_dicts(d, d2)<tab><tab># print(300, d)<tab>return d",0,"if isinstance ( request . getfixturevalue ( request . param ) , str ) :","if isinstance ( request . param , str ) :",0.2809647783282895,47.65082587109519,0.5079365079365079
"def _instrument_model(self, model):<tab>for key, value in list(<tab><tab>model.__dict__.items()<tab>):  # avoid ""dictionary keys changed during iteration""<tab><tab><IF-STMT><tab><tab><tab>new_layer = self._instrument(value)<tab><tab><tab>if new_layer is not value:<tab><tab><tab><tab>setattr(model, key, new_layer)<tab><tab>elif isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, tf.keras.layers.Layer):<tab><tab><tab><tab><tab>value[i] = self._instrument(item)<tab>return model",1,"if isinstance ( value , tf . keras . layers . Layer ) :","if isinstance ( value , tf . keras . layers . Layer ) :",0.75,100.00000000000004,1.0
"def is_accepted_drag_event(self, event):<tab>if event.source() == self.table:<tab><tab>return True<tab>mime = event.mimeData()<tab>if mime.hasUrls():<tab><tab>for url in mime.urls():<tab><tab><tab># Only support local files.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab># And only allow supported extensions.<tab><tab><tab>filename = url.toLocalFile()<tab><tab><tab>extension = os.path.splitext(filename)[1].lower()[1:]<tab><tab><tab>if extension not in _dictionary_formats():<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return True<tab>return False",0,if not url . isLocalFile ( ) :,if not url . hasLocalFile ( ) :,0.5014622369176811,50.000000000000014,0.6666666666666666
"def explain(self, other, depth=0):<tab>exp = super(UnionType, self).explain(other, depth)<tab>for ndx, subtype in enumerate(self.params[""allowed_types""]):<tab><tab><IF-STMT><tab><tab><tab>exp += ""\n{}and"".format("""".join([""\t""] * depth))<tab><tab>exp += ""\n"" + subtype.explain(other, depth=depth + 1)<tab>return exp",1,if ndx > 0 :,if ndx > 0 :,0.75,100.00000000000004,1.0
"def test_k_is_stochastic_parameter(self):<tab># k as stochastic parameter<tab>aug = iaa.MedianBlur(k=iap.Choice([3, 5]))<tab>seen = [False, False]<tab>for i in sm.xrange(100):<tab><tab>observed = aug.augment_image(self.base_img)<tab><tab>if np.array_equal(observed, self.blur3x3):<tab><tab><tab>seen[0] += True<tab><tab><IF-STMT><tab><tab><tab>seen[1] += True<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected result in MedianBlur@2"")<tab><tab>if all(seen):<tab><tab><tab>break<tab>assert np.all(seen)",1,"elif np . array_equal ( observed , self . blur5x5 ) :","elif np . array_equal ( observed , self . blur5x5 ) :",0.75,100.00000000000004,1.0
"def test_get_message(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>async with self.chat_thread_client:<tab><tab><tab>message_id = await self._send_message()<tab><tab><tab>message = await self.chat_thread_client.get_message(message_id)<tab><tab><tab>assert message.id == message_id<tab><tab><tab>assert message.type == ChatMessageType.TEXT<tab><tab><tab>assert message.content.message == ""hello world""<tab><tab># delete chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)",1,if not self . is_playback ( ) :,if not self . is_playback ( ) :,0.75,100.00000000000004,1.0
"def do_write_property(self, device, callback=None):<tab>try:<tab><tab>iocb = (<tab><tab><tab>device<tab><tab><tab><IF-STMT><tab><tab><tab>else self.form_iocb(device, request_type=""writeProperty"")<tab><tab>)<tab><tab>deferred(self.request_io, iocb)<tab><tab>self.requests_in_progress.update({iocb: {""callback"": callback}})<tab><tab>iocb.add_callback(self.__general_cb)<tab>except Exception as error:<tab><tab>log.exception(""exception: %r"", error)",0,"if isinstance ( device , IOCB )",if device is not None,0.02225082504991546,8.51528917838043,0.225
"def fit(self, dataset, force_retrain):<tab>if force_retrain:<tab><tab>self.sub_unit_1[""fitted""] = True<tab><tab>self.sub_unit_1[""calls""] += 1<tab><tab>self.sub_unit_2[""fitted""] = True<tab><tab>self.sub_unit_2[""calls""] += 1<tab>else:<tab><tab>if not self.sub_unit_1[""fitted""]:<tab><tab><tab>self.sub_unit_1[""fitted""] = True<tab><tab><tab>self.sub_unit_1[""calls""] += 1<tab><tab><IF-STMT><tab><tab><tab>self.sub_unit_2[""fitted""] = True<tab><tab><tab>self.sub_unit_2[""calls""] += 1<tab>return self",1,"if not self . sub_unit_2 [ ""fitted"" ] :","if not self . sub_unit_2 [ ""fitted"" ] :",0.75,100.00000000000004,1.0
"def _insert_with_loop(self):<tab>id_list = []<tab>last_id = None<tab>return_id_list = self._return_id_list<tab>for row in self._rows:<tab><tab>last_id = InsertQuery(self.model_class, row).upsert(self._upsert).execute()<tab><tab><IF-STMT><tab><tab><tab>id_list.append(last_id)<tab>if return_id_list:<tab><tab>return id_list<tab>else:<tab><tab>return last_id",0,if return_id_list :,if last_id :,0.3197504490129165,1e-10,1.0
"def merge_block(self):<tab>""""""merges a block in the map""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>c = self.block.get(i, j)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.map[(i + self.block.pos.x, j + self.block.pos.y)] = c",0,if c :,if c is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def configure_plex(config):<tab>core.PLEX_SSL = int(config[""Plex""][""plex_ssl""])<tab>core.PLEX_HOST = config[""Plex""][""plex_host""]<tab>core.PLEX_PORT = config[""Plex""][""plex_port""]<tab>core.PLEX_TOKEN = config[""Plex""][""plex_token""]<tab>plex_section = config[""Plex""][""plex_sections""] or []<tab>if plex_section:<tab><tab><IF-STMT><tab><tab><tab>plex_section = "","".join(plex_section)  # fix in case this imported as list.<tab><tab>plex_section = [tuple(item.split("","")) for item in plex_section.split(""|"")]<tab>core.PLEX_SECTION = plex_section",0,"if isinstance ( plex_section , list ) :","if ""|"" in plex_section :",0.019907917998500824,18.04438612975343,0.38181818181818183
"def select(self):<tab>e = xlib.XEvent()<tab>while xlib.XPending(self._display):<tab><tab>xlib.XNextEvent(self._display, e)<tab><tab># Key events are filtered by the xlib window event<tab><tab># handler so they get a shot at the prefiltered event.<tab><tab><IF-STMT><tab><tab><tab>if xlib.XFilterEvent(e, e.xany.window):<tab><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>dispatch = self._window_map[e.xany.window]<tab><tab>except KeyError:<tab><tab><tab>continue<tab><tab>dispatch(e)",0,"if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) :","if xlib . XFilterEvent ( e , xany . window ) :",0.06783094135618604,8.084561438850239,0.15
"def format_message(self):<tab>bits = [self.message]<tab>if self.possibilities:<tab><tab><IF-STMT><tab><tab><tab>bits.append(""Did you mean %s?"" % self.possibilities[0])<tab><tab>else:<tab><tab><tab>possibilities = sorted(self.possibilities)<tab><tab><tab>bits.append(""(Possible options: %s)"" % "", "".join(possibilities))<tab>return ""  "".join(bits)",1,if len ( self . possibilities ) == 1 :,if len ( self . possibilities ) == 1 :,0.75,100.00000000000004,1.0
"def _collect_logs(model):<tab>page_token = None<tab>all_logs = []<tab>while True:<tab><tab>paginated_logs = model.lookup_logs(now, later, page_token=page_token)<tab><tab>page_token = paginated_logs.next_page_token<tab><tab>all_logs.extend(paginated_logs.logs)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return all_logs",0,if page_token is None :,if not paginated_logs . logs :,0.030286782520570012,7.267884212102741,0.3333333333333333
"def run(self):<tab>while True:<tab><tab>context_id_list_tuple = self._inflated_addresses.get(block=True)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>c_id, inflated_address_list = context_id_list_tuple<tab><tab>inflated_value_map = dict(inflated_address_list)<tab><tab>if c_id in self._contexts:<tab><tab><tab>self._contexts[c_id].set_from_tree(inflated_value_map)",0,if context_id_list_tuple is _SHUTDOWN_SENTINEL :,if context_id_list_tuple is None :,0.39477865547525276,61.44118374261937,0.7
"def _setup_prefix(self):<tab># we assume here that our metadata may be nested inside a ""basket""<tab># of multiple eggs; that's why we use module_path instead of .archive<tab>path = self.module_path<tab>old = None<tab>while path != old:<tab><tab><IF-STMT><tab><tab><tab>self.egg_name = os.path.basename(path)<tab><tab><tab>self.egg_info = os.path.join(path, ""EGG-INFO"")<tab><tab><tab>self.egg_root = path<tab><tab><tab>break<tab><tab>old = path<tab><tab>path, base = os.path.split(path)",0,"if path . lower ( ) . endswith ( "".egg"" ) :",if os . path . isdir ( path ) :,0.03012138375431745,8.27951003977077,0.2761904761904762
"def get_filename(self, prompt):<tab>okay = False<tab>val = """"<tab>while not okay:<tab><tab>val = raw_input(""%s: %s"" % (prompt, val))<tab><tab>val = os.path.expanduser(val)<tab><tab>if os.path.isfile(val):<tab><tab><tab>okay = True<tab><tab><IF-STMT><tab><tab><tab>path = val<tab><tab><tab>val = self.choose_from_list(os.listdir(path))<tab><tab><tab>if val:<tab><tab><tab><tab>val = os.path.join(path, val)<tab><tab><tab><tab>okay = True<tab><tab><tab>else:<tab><tab><tab><tab>val = """"<tab><tab>else:<tab><tab><tab>print(""Invalid value: %s"" % val)<tab><tab><tab>val = """"<tab>return val",1,elif os . path . isdir ( val ) :,elif os . path . isdir ( val ) :,0.75,100.00000000000004,1.0
"def versions(self, sitename, data):<tab># handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}}<tab>if ""query"" in data:<tab><tab>q = json.loads(data[""query""])<tab><tab>itemid = self._get_itemid(q.get(""key""))<tab><tab><IF-STMT><tab><tab><tab>key = q[""key""]<tab><tab><tab>return json.dumps([self.dummy_edit(key)])<tab># if not just go the default way<tab>return ConnectionMiddleware.versions(self, sitename, data)",0,if itemid :,if itemid is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def read_stanza(self):<tab>while True:<tab><tab>try:<tab><tab><tab>stanza_end = self._buffer.index(b""\n"")<tab><tab><tab>stanza = self.decoder.decode(self._buffer[:stanza_end])<tab><tab><tab>self._buffer = self._buffer[stanza_end + 1 :]<tab><tab><tab>colon = stanza.index("":"")<tab><tab><tab>return stanza[:colon], stanza[colon + 1 :]<tab><tab>except ValueError:<tab><tab><tab>bytes = self.read_bytes()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>self._buffer += bytes",1,if not bytes :,if not bytes :,0.75,100.00000000000004,1.0
def decodeattrs(attrs):<tab>names = []<tab>for bit in range(16):<tab><tab>mask = 1 << bit<tab><tab><IF-STMT><tab><tab><tab>if attrnames.has_key(mask):<tab><tab><tab><tab>names.append(attrnames[mask])<tab><tab><tab>else:<tab><tab><tab><tab>names.append(hex(mask))<tab>return names,0,if attrs & mask :,if attrs & ( 1 << bit ) :,0.10522622320176984,16.784459625186194,0.48484848484848486
"def _set_http_cookie():<tab>if conf.cookie:<tab><tab><IF-STMT><tab><tab><tab>conf.http_headers[HTTP_HEADER.COOKIE] = ""; "".join(<tab><tab><tab><tab>map(lambda x: ""="".join(x), conf.cookie.items())<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>conf.http_headers[HTTP_HEADER.COOKIE] = conf.cookie",1,"if isinstance ( conf . cookie , dict ) :","if isinstance ( conf . cookie , dict ) :",0.75,100.00000000000004,1.0
"def __ne__(self, other):<tab>if isinstance(other, WeakMethod):<tab><tab><IF-STMT><tab><tab><tab>return self is not other<tab><tab>return weakref.ref.__ne__(self, other) or self._func_ref != other._func_ref<tab>return True",0,if not self . _alive or not other . _alive :,if self . _func_ref is other . _func_ref :,0.17117719636613637,17.678748653651848,0.2619047619047619
"def update_unread(self, order_id, reset=False):<tab>conn = Database.connect_database(self.PATH)<tab>with conn:<tab><tab>cursor = conn.cursor()<tab><tab><IF-STMT><tab><tab><tab>cursor.execute(<tab><tab><tab><tab>""""""UPDATE sales SET unread = unread + 1 WHERE id=?;"""""", (order_id,)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>cursor.execute(""""""UPDATE sales SET unread=0 WHERE id=?;"""""", (order_id,))<tab><tab>conn.commit()<tab>conn.close()",0,if reset is False :,if reset :,0.06767423853569741,1e-10,0.5
"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab>if member[0] == key:<tab><tab><tab><tab>field_value = member[1]<tab><tab><tab>elif member[0] == ""wildcards"":<tab><tab><tab><tab>wildcards = member[1]<tab><tab>if key == ""nw_src"":<tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab><IF-STMT><tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value",1,"elif key == ""nw_dst"" :","elif key == ""nw_dst"" :",1.0,100.00000000000004,1.0
"def nested_filter(self, items, mask):<tab>keep_current = self.current_mask(mask)<tab>keep_nested_lookup = self.nested_masks(mask)<tab>for k, v in items:<tab><tab>keep_nested = keep_nested_lookup.get(k)<tab><tab><IF-STMT><tab><tab><tab>if keep_nested is not None:<tab><tab><tab><tab>if isinstance(v, dict):<tab><tab><tab><tab><tab>yield k, dict(self.nested_filter(v.items(), keep_nested))<tab><tab><tab>else:<tab><tab><tab><tab>yield k, v",0,if k in keep_current :,if keep_current is not None and keep_nested != v :,0.025806626984353938,11.114924776032012,0.19191919191919193
"def goToPrevMarkedHeadline(self, event=None):<tab>""""""Select the next marked node.""""""<tab>c = self<tab>p = c.p<tab>if not p:<tab><tab>return<tab>p.moveToThreadBack()<tab>wrapped = False<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif p:<tab><tab><tab>p.moveToThreadBack()<tab><tab>elif wrapped:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>wrapped = True<tab><tab><tab>p = c.rootPosition()<tab>if not p:<tab><tab>g.blue(""done"")<tab>c.treeSelectHelper(p)  # Sets focus.",0,if p and p . isMarked ( ) :,if p and p . marked :,0.5544243029444583,48.35447404743731,0.6666666666666666
"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = {}<tab>ret.update(self.data)<tab>kwspaces = self.kwspaces<tab>kwspaces.update(config)<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for k, v in kwspaces.items():<tab><tab><IF-STMT><tab><tab><tab>if isinstance(v, NestedSpace):<tab><tab><tab><tab>sub_config = _strip_config_space(config, prefix=k)<tab><tab><tab><tab>ret[k] = v.sample(**sub_config)<tab><tab><tab>else:<tab><tab><tab><tab>ret[k] = v<tab>return ret",0,if k in striped_keys :,if k in stripped_keys :,0.39477865547525276,41.11336169005196,1.0
"def update_gradients_full(self, dL_dK, X, X2=None):<tab>if self.ARD:<tab><tab>phi1 = self.phi(X)<tab><tab><IF-STMT><tab><tab><tab>self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi1)<tab><tab>else:<tab><tab><tab>phi2 = self.phi(X2)<tab><tab><tab>self.variance.gradient = np.einsum(""ij,iq,jq->q"", dL_dK, phi1, phi2)<tab>else:<tab><tab>self.variance.gradient = np.einsum(""ij,ij"", dL_dK, self._K(X, X2)) * self.beta",0,if X2 is None or X is X2 :,if X2 is None :,0.16279282519794364,31.772355751081438,0.5238095238095238
"def post(self):<tab>host_json = json.loads(request.data)<tab>host_os = host_json.get(""os"")<tab>if host_os:<tab><tab>result = get_monkey_executable(host_os.get(""type""), host_os.get(""machine""))<tab><tab>if result:<tab><tab><tab># change resulting from new base path<tab><tab><tab>executable_filename = result[""filename""]<tab><tab><tab>real_path = MonkeyDownload.get_executable_full_path(executable_filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[""size""] = os.path.getsize(real_path)<tab><tab><tab><tab>return result<tab>return {}",0,if os . path . isfile ( real_path ) :,if real_path :,0.011515134196748902,1e-10,0.36
"def _encode_data(<tab>self,<tab>data,<tab>content_type,):<tab>if content_type is MULTIPART_CONTENT:<tab><tab>return encode_multipart(BOUNDARY, data)<tab>else:<tab><tab># Encode the content so that the byte representation is correct.<tab><tab>match = CONTENT_TYPE_RE.match(content_type)<tab><tab><IF-STMT><tab><tab><tab>charset = match.group(1)<tab><tab>else:<tab><tab><tab>charset = settings.DEFAULT_CHARSET<tab><tab>return force_bytes(data, encoding=charset)",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]:<tab>tokens = list(tokens)<tab>i = 0<tab>while ""e"" in tokens[i + 1 :]:<tab><tab>i = tokens.index(""e"", i + 1)<tab><tab>s = i - 1<tab><tab>e = i + 1<tab><tab>if not re.match(""[0-9]"", str(tokens[s])):<tab><tab><tab>continue<tab><tab>if re.match(""[+-]"", str(tokens[e])):<tab><tab><tab>e += 1<tab><tab><IF-STMT><tab><tab><tab>e += 1<tab><tab><tab>tokens[s:e] = ["""".join(tokens[s:e])]<tab><tab><tab>i -= 1<tab>return tokens",0,"if re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :","elif re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :",0.5598220061167304,95.10699415570296,0.75
"def convert_with_key(self, key, value, replace=True):<tab>result = self.configurator.convert(value)<tab># If the converted value is different, save for next time<tab>if value is not result:<tab><tab><IF-STMT><tab><tab><tab>self[key] = result<tab><tab>if type(result) in (ConvertingDict, ConvertingList, ConvertingTuple):<tab><tab><tab>result.parent = self<tab><tab><tab>result.key = key<tab>return result",1,if replace :,if replace :,0.5311706625951745,1e-10,1.0
"def OnListEndLabelEdit(self, std, extra):<tab>item = extra[0]<tab>text = item[4]<tab>if text is None:<tab><tab>return<tab>item_id = self.GetItem(item[0])[6]<tab>from bdb import Breakpoint<tab>for bplist in Breakpoint.bplist.itervalues():<tab><tab>for bp in bplist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if text.strip().lower() == ""none"":<tab><tab><tab><tab><tab>text = None<tab><tab><tab><tab>bp.cond = text<tab><tab><tab><tab>break<tab>self.RespondDebuggerData()",0,if id ( bp ) == item_id :,if bp . id == item_id :,0.08409425058774654,51.7679965241078,0.5
"def add(self, url: str, future_nzo: NzbObject, when: Optional[int] = None):<tab>""""""Add an URL to the URLGrabber queue, 'when' is seconds from now""""""<tab>if future_nzo and when:<tab><tab># Always increase counter<tab><tab>future_nzo.url_tries += 1<tab><tab># Too many tries? Cancel<tab><tab><IF-STMT><tab><tab><tab>self.fail_to_history(future_nzo, url, T(""Maximum retries""))<tab><tab><tab>return<tab><tab>future_nzo.url_wait = time.time() + when<tab>self.queue.put((url, future_nzo))",0,if future_nzo . url_tries > cfg . max_url_retries ( ) :,if future_nzo . url_tries > self . max_retries :,0.2377064286797049,52.78890511109627,0.5
def _is_datetime_string(series):<tab>if series.dtype == object:<tab><tab>not_numeric = False<tab><tab>try:<tab><tab><tab>pd.to_numeric(series)<tab><tab>except Exception as e:<tab><tab><tab>not_numeric = True<tab><tab>datetime_col = None<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>datetime_col = pd.to_datetime(series)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>return False<tab><tab>if datetime_col is not None:<tab><tab><tab>return True<tab>return False,1,if not_numeric :,if not_numeric :,0.5311706625951745,1e-10,1.0
"def _getEventAndObservers(self, event):<tab>if isinstance(event, xpath.XPathQuery):<tab><tab># Treat as xpath<tab><tab>observers = self._xpathObservers<tab>else:<tab><tab><IF-STMT><tab><tab><tab># Treat as event<tab><tab><tab>observers = self._eventObservers<tab><tab>else:<tab><tab><tab># Treat as xpath<tab><tab><tab>event = xpath.internQuery(event)<tab><tab><tab>observers = self._xpathObservers<tab>return event, observers",0,if self . prefix == event [ : len ( self . prefix ) ] :,"if isinstance ( event , xpath . XPathEvent ) :",0.07220383903670627,3.2612121198882003,0.2111111111111111
"def test_wildcard_import():<tab>bonobo = __import__(""bonobo"")<tab>assert bonobo.__version__<tab>for name in dir(bonobo):<tab><tab># ignore attributes starting by underscores<tab><tab>if name.startswith(""_""):<tab><tab><tab>continue<tab><tab>attr = getattr(bonobo, name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>assert name in bonobo.__all__",0,if inspect . ismodule ( attr ) :,"if not hasattr ( attr , ""__call__"" ) :",0.04194115706415645,7.8594386815106,0.42857142857142855
"def relint_views(wid=None):<tab>windows = [sublime.Window(wid)] if wid else sublime.windows()<tab>for window in windows:<tab><tab>for view in window.views():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hit(view, ""relint_views"")",0,if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,"if view . get ( ""type"" ) == ""view"" and view . get ( ""type"" ) == ""view"" :",0.3032047066966284,9.373243163672917,0.35714285714285715
def _check_for_unknown_gender(self):<tab>if self.obj.get_gender() == Person.UNKNOWN:<tab><tab>d = GenderDialog(parent=self.window)<tab><tab>gender = d.run()<tab><tab>d.destroy()<tab><tab><IF-STMT><tab><tab><tab>self.obj.set_gender(gender),0,if gender >= 0 :,if gender is not None :,0.0574290063711522,17.965205598154213,0.35714285714285715
"def add_to_path(self, fnames):<tab>""""""Add fnames to path""""""<tab>indexes = []<tab>for path in fnames:<tab><tab>project = self.get_source_project(path)<tab><tab><IF-STMT><tab><tab><tab>self.parent_widget.emit(SIGNAL(""pythonpath_changed()""))<tab><tab><tab>indexes.append(self.get_index(path))<tab>if indexes:<tab><tab>self.reset_icon_provider()<tab><tab>for index in indexes:<tab><tab><tab>self.update(index)",0,if project . add_to_pythonpath ( path ) :,if project and project . is_dir ( ) :,0.04807281337608586,12.320255516768906,0.5151515151515151
"def validate(self, value):<tab>if value.grid_id is not None:<tab><tab>if not isinstance(value, self.proxy_class):<tab><tab><tab>self.error(""FileField only accepts GridFSProxy values"")<tab><tab><IF-STMT><tab><tab><tab>self.error(""Invalid GridFSProxy value"")",0,"if not isinstance ( value . grid_id , ObjectId ) :","elif not isinstance ( value , self . proxy_class ) :",0.1443187255716887,25.450938600202846,0.5
"def shortcut(self, input, ch_out, stride, name, if_first=False):<tab>ch_in = input.shape[1]<tab>if ch_in != ch_out or stride != 1:<tab><tab><IF-STMT><tab><tab><tab>return self.conv_bn_layer(input, ch_out, 1, stride, name=name)<tab><tab>else:<tab><tab><tab>return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name)<tab>else:<tab><tab>return input",1,if if_first :,if if_first :,0.5311706625951745,1e-10,1.0
"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab>if code == Path.MOVETO:<tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab>elif code == Path.CURVE3:<tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>ctx.curve_to(*points)<tab><tab>elif code == Path.CLOSEPOLY:<tab><tab><tab>ctx.close_path()",1,elif code == Path . CURVE4 :,elif code == Path . CURVE4 :,0.75,100.00000000000004,1.0
"def _get_build_status(self, job_name, build_number):<tab>try:<tab><tab>build_info = self.server.get_build_info(job_name, build_number)<tab><tab><IF-STMT><tab><tab><tab>return ""building""<tab><tab>else:<tab><tab><tab>return ""built""<tab>except jenkins.NotFoundException:<tab><tab>return ""not found""",0,"if build_info [ ""building"" ] :","if build_info . get ( ""building"" ) :",0.04432760343703879,31.702331385234313,0.6410256410256411
"def _parse_param_value(name, datatype, default):<tab>if datatype == ""bool"":<tab><tab>if default.lower() == ""true"":<tab><tab><tab>return True<tab><tab>elif default.lower() == ""false"":<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>_s = ""{}: Invalid default value '{}' for bool parameter {}""<tab><tab><tab>raise SyntaxError(_s.format(self.name, default, p))<tab>elif datatype == ""int"":<tab><tab>if type(default) == int:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return int(default, 0)<tab>elif datatype == ""real"":<tab><tab><IF-STMT><tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return float(default)<tab>else:<tab><tab>return str(default)",1,if type ( default ) == float :,if type ( default ) == float :,0.75,100.00000000000004,1.0
"def get_fills(self, exchange_order_id):<tab>async with aiohttp.ClientSession() as client:<tab><tab>response: aiohttp.ClientResponse = await client.get(<tab><tab><tab>f""{BASE_URL}{FILLS_ROUTE}"",<tab><tab><tab>params={""orderId"": exchange_order_id, ""limit"": 100},<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>msg = await response.json()<tab><tab><tab>except ValueError:<tab><tab><tab><tab>msg = await response.text()<tab><tab><tab>raise DydxAsyncAPIError(response.status, msg)<tab><tab>return await response.json()",0,if response . status >= 300 :,if response . status != 200 :,0.4711135200865855,38.260294162784454,0.6666666666666666
"def semanticTags(self, semanticTags):<tab>if semanticTags is None:<tab><tab>self.__semanticTags = OrderedDict()<tab># check<tab>for key, value in list(semanticTags.items()):<tab><tab>if not isinstance(key, int):<tab><tab><tab>raise TypeError(""At least one key is not a valid int position"")<tab><tab>if not isinstance(value, list):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab>)<tab><tab>for x in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(<tab><tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab><tab>)<tab>self.__semanticTags = semanticTags",1,"if not isinstance ( x , str ) :","if not isinstance ( x , str ) :",0.75,100.00000000000004,1.0
"def start_cutting_tool(self, event, axis, direction):<tab>toggle = event.EventObject<tab>self.cutting = toggle.Value<tab>if toggle.Value:<tab><tab># Disable the other toggles<tab><tab>for child in self.cutsizer.Children:<tab><tab><tab>child = child.Window<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child.Value = False<tab><tab>self.cutting_axis = axis<tab><tab>self.cutting_direction = direction<tab>else:<tab><tab>self.cutting_axis = None<tab><tab>self.cutting_direction = None<tab>self.cutting_dist = None",0,if child != toggle :,if child . IsShown ( ) :,0.05286931595839166,14.535768424205482,0.6
"def decoration_helper(self, patched, args, keywargs):<tab>extra_args = []<tab>with contextlib.ExitStack() as exit_stack:<tab><tab>for patching in patched.patchings:<tab><tab><tab>arg = exit_stack.enter_context(patching)<tab><tab><tab>if patching.attribute_name is not None:<tab><tab><tab><tab>keywargs.update(arg)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extra_args.append(arg)<tab><tab>args += tuple(extra_args)<tab><tab>yield (args, keywargs)",0,elif patching . new is DEFAULT :,"elif isinstance ( patching . attribute_name , str ) :",0.03181789699609364,8.054496384843702,0.23863636363636365
def decodeattrs(attrs):<tab>names = []<tab>for bit in range(16):<tab><tab>mask = 1 << bit<tab><tab>if attrs & mask:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.append(attrnames[mask])<tab><tab><tab>else:<tab><tab><tab><tab>names.append(hex(mask))<tab>return names,0,if attrnames . has_key ( mask ) :,if mask in attrnames :,0.020977836961063236,5.557509463743763,0.37777777777777777
"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/params""):<tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))",1,"if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",0.75,100.00000000000004,1.0
"def handle_socket(self, request):<tab>conn = request.connection<tab>while True:<tab><tab>chunk = conn.recv(4)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>slen = struct.unpack("">L"", chunk)[0]<tab><tab>chunk = conn.recv(slen)<tab><tab>while len(chunk) < slen:<tab><tab><tab>chunk = chunk + conn.recv(slen - len(chunk))<tab><tab>obj = pickle.loads(chunk)<tab><tab>record = logging.makeLogRecord(obj)<tab><tab>self.log_output += record.msg + ""\n""<tab><tab>self.handled.release()",0,if len ( chunk ) < 4 :,if not chunk :,0.019930835999227993,7.733712583165139,0.48148148148148145
"def on_source_foreach(self, model, path, iter, id):<tab>m_id = model.get_value(iter, self.COLUMN_ID)<tab>if m_id == id:<tab><tab>if self._foreach_mode == ""get"":<tab><tab><tab>self._foreach_take = model.get_value(iter, self.COLUMN_ENABLED)<tab><tab><IF-STMT><tab><tab><tab>self._foreach_take = iter",1,"elif self . _foreach_mode == ""set"" :","elif self . _foreach_mode == ""set"" :",1.0,100.00000000000004,1.0
"def parts():<tab>for l in lists.leaves:<tab><tab>head_name = l.get_head_name()<tab><tab>if head_name == ""System`List"":<tab><tab><tab>yield l.leaves<tab><tab><IF-STMT><tab><tab><tab>raise MessageException(""Catenate"", ""invrp"", l)",0,"elif head_name != ""System`Missing"" :","elif head_name == ""System`List"" and l . get_head_name ( ) == ""System`List"" :",0.04052640335832356,17.70409459493363,0.4772727272727273
"def __fill_counter_values(self, command: str):<tab>result = []<tab>regex = r""(item[0-9]+\.counter_value)""<tab>for token in re.split(regex, command):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>result.append(str(self.simulator_config.item_dict[token].value))<tab><tab><tab>except (KeyError, ValueError, AttributeError):<tab><tab><tab><tab>logger.error(""Could not get counter value for "" + token)<tab><tab>else:<tab><tab><tab>result.append(token)<tab>return """".join(result)",0,"if re . match ( regex , token ) is not None :",if token in self . simulator_config . item_dict :,0.09487827524051641,4.368583925857938,0.15584415584415587
"def IMPORTFROM(self, node):<tab><IF-STMT><tab><tab>if not self.futuresAllowed:<tab><tab><tab>self.report(messages.LateFutureImport, node, [n.name for n in node.names])<tab>else:<tab><tab>self.futuresAllowed = False<tab>for alias in node.names:<tab><tab>if alias.name == ""*"":<tab><tab><tab>self.scope.importStarred = True<tab><tab><tab>self.report(messages.ImportStarUsed, node, node.module)<tab><tab><tab>continue<tab><tab>name = alias.asname or alias.name<tab><tab>importation = Importation(name, node)<tab><tab>if node.module == ""__future__"":<tab><tab><tab>importation.used = (self.scope, node)<tab><tab>self.addBinding(node, importation)",1,"if node . module == ""__future__"" :","if node . module == ""__future__"" :",0.75,100.00000000000004,1.0
"def _split_batch_list(args, batch_list):<tab>new_list = []<tab>for batch in batch_list.batches:<tab><tab>new_list.append(batch)<tab><tab><IF-STMT><tab><tab><tab>yield batch_pb2.BatchList(batches=new_list)<tab><tab><tab>new_list = []<tab>if new_list:<tab><tab>yield batch_pb2.BatchList(batches=new_list)",0,if len ( new_list ) == args . batch_size_limit :,if len ( new_list ) == 0 :,0.37593058057733264,46.7751969423698,0.6
"def get_branch_or_use_upstream(branch_name, arg, repo):<tab>if not branch_name:  # use upstream branch<tab><tab>current_b = repo.current_branch<tab><tab>upstream_b = current_b.upstream<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""No {0} branch specified and the current branch has no upstream ""<tab><tab><tab><tab>""branch set"".format(arg)<tab><tab><tab>)<tab><tab>ret = current_b.upstream<tab>else:<tab><tab>ret = get_branch(branch_name, repo)<tab>return ret",0,if not upstream_b :,if upstream_b is None :,0.045150550804307965,27.77619034011791,0.36
"def __init__(self, **settings):<tab>default_settings = self.get_default_settings()<tab>for name, value in default_settings.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(self, name, value)<tab>for name, value in settings.items():<tab><tab>if name not in default_settings:<tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Invalid setting '{}' for {}"".format(<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>self.__class__.__name__,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>setattr(self, name, value)",0,"if not hasattr ( self , name ) :",if name not in settings :,0.017951424116240698,6.962210312500384,0.25
"def _declare(self, name, obj, included=False, quals=0):<tab>if name in self._declarations:<tab><tab>prevobj, prevquals = self._declarations[name]<tab><tab>if prevobj is obj and prevquals == quals:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>raise api.FFIError(<tab><tab><tab><tab>""multiple declarations of %s (for interactive usage, ""<tab><tab><tab><tab>""try cdef(xx, override=True))"" % (name,)<tab><tab><tab>)<tab>assert ""__dotdotdot__"" not in name.split()<tab>self._declarations[name] = (obj, quals)<tab>if included:<tab><tab>self._included_declarations.add(obj)",0,if not self . _override :,elif prevquals is obj :,0.019979895918037657,7.16047614494885,0.1
"def include_file(name, fdir=tmp_dir, b64=False):<tab>try:<tab><tab>if fdir is None:<tab><tab><tab>fdir = """"<tab><tab><IF-STMT><tab><tab><tab>with io.open(os.path.join(fdir, name), ""rb"") as f:<tab><tab><tab><tab>return base64.b64encode(f.read()).decode(""utf-8"")<tab><tab>else:<tab><tab><tab>with io.open(os.path.join(fdir, name), ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>return f.read()<tab>except (OSError, IOError) as e:<tab><tab>logger.error(""Could not include file '{}': {}"".format(name, e))",1,if b64 :,if b64 :,0.5311706625951745,1e-10,1.0
"def to_raw_json(self):<tab>parts = {}<tab>for p in self.parts:<tab><tab><IF-STMT><tab><tab><tab>parts[p[0]] = []<tab><tab>parts[p[0]].append({""value"": p[2], ""parameters"": p[1]})<tab>children = [x.to_raw_json() for x in self.children]<tab>return {<tab><tab>""type"": self.__class__.__name__,<tab><tab>""children"": children,<tab><tab>""parts"": parts,<tab>}",1,if p [ 0 ] not in parts :,if p [ 0 ] not in parts :,0.75,100.00000000000004,1.0
"def process_output(<tab>output: str, filename: str, start_line: int) -> Tuple[Optional[str], bool]:<tab>error_found = False<tab>for line in output.splitlines():<tab><tab>t = get_revealed_type(line, filename, start_line)<tab><tab><IF-STMT><tab><tab><tab>return t, error_found<tab><tab>elif ""error:"" in line:<tab><tab><tab>error_found = True<tab>return None, True  # finding no reveal_type is an error",0,if t :,if t is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def __init__(<tab>self, resize_keyboard=None, one_time_keyboard=None, selective=None, row_width=3):<tab>if row_width > self.max_row_keys:<tab><tab># Todo: Will be replaced with Exception in future releases<tab><tab><IF-STMT><tab><tab><tab>logger.error(<tab><tab><tab><tab>""Telegram does not support reply keyboard row width over %d.""<tab><tab><tab><tab>% self.max_row_keys<tab><tab><tab>)<tab><tab>row_width = self.max_row_keys<tab>self.resize_keyboard = resize_keyboard<tab>self.one_time_keyboard = one_time_keyboard<tab>self.selective = selective<tab>self.row_width = row_width<tab>self.keyboard = []",0,if not DISABLE_KEYLEN_ERROR :,if one_time_keyboard is not None :,0.16590500542243855,6.27465531099474,0.3333333333333333
"def realizeElementExpressions(innerElement):<tab>elementHasBeenRealized = False<tab>for exp in innerElement.expressions:<tab><tab>if not hasattr(exp, ""realize""):<tab><tab><tab>continue<tab><tab># else:<tab><tab>before, during, after = exp.realize(innerElement)<tab><tab>elementHasBeenRealized = True<tab><tab>for n in before:<tab><tab><tab>newStream.append(n)<tab><tab><IF-STMT><tab><tab><tab>newStream.append(during)<tab><tab>for n in after:<tab><tab><tab>newStream.append(n)<tab>if elementHasBeenRealized is False:<tab><tab>newStream.append(innerElement)",0,if during is not None :,if not elementHasBeenRealized :,0.0806440934254144,12.750736437345598,0.21428571428571427
"def lex_number(self, pos):<tab># numeric literal<tab>start = pos<tab>found_dot = False<tab>while pos < len(self.string) and (<tab><tab>self.string[pos].isdigit() or self.string[pos] == "".""<tab>):<tab><tab><IF-STMT><tab><tab><tab>if found_dot is True:<tab><tab><tab><tab>raise ValueError(""Invalid number. Found multiple '.'"")<tab><tab><tab>found_dot = True<tab><tab># technically we allow more than one ""."" and let float()'s parsing<tab><tab># complain later<tab><tab>pos += 1<tab>val = self.string[start:pos]<tab>return Token(TokenType.LNUM, val, len(val))",1,"if self . string [ pos ] == ""."" :","if self . string [ pos ] == ""."" :",0.75,100.00000000000004,1.0
"def rename(src, dst):<tab># Try atomic or pseudo-atomic rename<tab>if _rename(src, dst):<tab><tab>return<tab># Fall back to ""move away and replace""<tab>try:<tab><tab>os.rename(src, dst)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>old = ""%s-%08x"" % (dst, random.randint(0, sys.maxsize))<tab><tab>os.rename(dst, old)<tab><tab>os.rename(src, dst)<tab><tab>try:<tab><tab><tab>os.unlink(old)<tab><tab>except Exception:<tab><tab><tab>pass",1,if e . errno != errno . EEXIST :,if e . errno != errno . EEXIST :,1.0,100.00000000000004,1.0
"def _the_callback(widget, event_id):<tab>point = widget.GetCenter()<tab>index = widget.WIDGET_INDEX<tab>if hasattr(callback, ""__call__""):<tab><tab>if num > 1:<tab><tab><tab>args = [point, index]<tab><tab>else:<tab><tab><tab>args = [point]<tab><tab><IF-STMT><tab><tab><tab>args.append(widget)<tab><tab>try_callback(callback, *args)<tab>return",0,if pass_widget :,if num == 1 :,0.051944022748897464,1e-10,0.41666666666666663
"def run(self):<tab>for _ in range(self.n):<tab><tab>error = True<tab><tab>try:<tab><tab><tab>self.collection.insert_one({""test"": ""insert""})<tab><tab><tab>error = False<tab><tab>except:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>if self.expect_exception:<tab><tab><tab>assert error",0,if not self . expect_exception :,if self . fail_silently :,0.054520976303194774,14.31720073264775,0.4642857142857143
"def handle(self, *args: Any, **options: Any) -> None:<tab>realm = self.get_realm(options)<tab>if options[""all""]:<tab><tab><IF-STMT><tab><tab><tab>raise CommandError(<tab><tab><tab><tab>""You must specify a realm if you choose the --all option.""<tab><tab><tab>)<tab><tab>self.fix_all_users(realm)<tab><tab>return<tab>self.fix_emails(realm, options[""emails""])",0,if realm is None :,if not realm :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def recv_tdi(self, nbits, pos):<tab>bits = 0<tab>for n in range(nbits * 2):<tab><tab>yield from self._wait_for_tck()<tab><tab><IF-STMT><tab><tab><tab>bits = (bits << 1) | (yield self.tdi.o)<tab>return bits",1,if ( yield self . tck . o ) == pos :,if ( yield self . tck . o ) == pos :,0.75,100.00000000000004,1.0
"def _split_head(self):<tab>if not hasattr(self, ""_severed_head""):<tab><tab><IF-STMT><tab><tab><tab>tree = self._tree.copy()<tab><tab><tab>head = tree.get_heading_text()<tab><tab><tab>tree.remove_heading()<tab><tab><tab>self._severed_head = (head, tree)<tab><tab>else:<tab><tab><tab>self._severed_head = (None, None)<tab>return self._severed_head",1,if self . _tree :,if self . _tree :,0.75,100.00000000000004,1.0
"def buildSearchTrie(self, choices):<tab>searchtrie = trie.Trie()<tab>for choice in choices:<tab><tab>for token in self.tokenizeChoice(choice):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>searchtrie[token] = []<tab><tab><tab>searchtrie[token].append(choice)<tab>return searchtrie",0,if not searchtrie . has_key ( token ) :,if token not in searchtrie :,0.018728518225177467,5.274846355723257,0.3148148148148148
"def format_sql(sql, params):<tab>rv = []<tab>if isinstance(params, dict):<tab><tab># convert sql with named parameters to sql with unnamed parameters<tab><tab>conv = _FormatConverter(params)<tab><tab>if params:<tab><tab><tab>sql = sql_to_string(sql)<tab><tab><tab>sql = sql % conv<tab><tab><tab>params = conv.params<tab><tab>else:<tab><tab><tab>params = ()<tab>for param in params or ():<tab><tab><IF-STMT><tab><tab><tab>rv.append(""NULL"")<tab><tab>param = safe_repr(param)<tab><tab>rv.append(param)<tab>return sql, rv",1,if param is None :,if param is None :,0.75,100.00000000000004,1.0
def on_completed2():<tab>doner[0] = True<tab>if not qr:<tab><tab>if len(ql) > 0:<tab><tab><tab>observer.on_next(False)<tab><tab><tab>observer.on_completed()<tab><tab><IF-STMT><tab><tab><tab>observer.on_next(True)<tab><tab><tab>observer.on_completed(),0,elif donel [ 0 ] :,elif len ( doner ) > 0 :,0.02257100471915708,7.267884212102741,0.3148148148148148
"def notify_digest(self, frequency, changes):<tab>notifications = defaultdict(list)<tab>users = {}<tab>for change in changes:<tab><tab>for user in self.get_users(frequency, change):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>notifications[user.pk].append(change)<tab><tab><tab><tab>users[user.pk] = user<tab>for user in users.values():<tab><tab>self.send_digest(<tab><tab><tab>user.profile.language,<tab><tab><tab>user.email,<tab><tab><tab>notifications[user.pk],<tab><tab><tab>subscription=user.current_subscription,<tab><tab>)",0,if change . project is None or user . can_access_project ( change . project ) :,if user . email not in notifications [ user . pk ] :,0.13079451765577477,4.534086576963962,0.2
"def _any_listener_using(self, target_group_arn):<tab>for load_balancer in self.load_balancers.values():<tab><tab>for listener in load_balancer.listeners.values():<tab><tab><tab>for rule in listener.rules:<tab><tab><tab><tab>for action in rule.actions:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False",0,"if action . data . get ( ""target_group_arn"" ) == target_group_arn :",if action . arn == target_group_arn :,0.11279327831055866,30.030707552685943,0.4901960784313726
"def train_dict(self, triples):<tab>""""""Train a dict lemmatizer given training (word, pos, lemma) triples.""""""<tab># accumulate counter<tab>ctr = Counter()<tab>ctr.update([(p[0], p[1], p[2]) for p in triples])<tab># find the most frequent mappings<tab>for p, _ in ctr.most_common():<tab><tab>w, pos, l = p<tab><tab>if (w, pos) not in self.composite_dict:<tab><tab><tab>self.composite_dict[(w, pos)] = l<tab><tab><IF-STMT><tab><tab><tab>self.word_dict[w] = l<tab>return",0,if w not in self . word_dict :,"if ( w , pos ) not in self . word_dict :",0.503195612270201,54.3742768222752,0.4175824175824176
"def parse_git_config(path):<tab>""""""Parse git config file.""""""<tab>config = dict()<tab>section = None<tab>with open(os.path.join(path, ""config""), ""r"") as f:<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>section = line[1:-1].strip()<tab><tab><tab><tab>config[section] = dict()<tab><tab><tab>elif section:<tab><tab><tab><tab>key, value = line.replace("" "", """").split(""="")<tab><tab><tab><tab>config[section][key] = value<tab>return config",0,"if line . startswith ( ""["" ) :",if section is None :,0.01858685153282265,4.673289785800722,0.2698412698412698
"def send_signal(self, pid, signum):<tab>if pid in self.processes:<tab><tab>process = self.processes[pid]<tab><tab>hook_result = self.call_hook(""before_signal"", pid=pid, signum=signum)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(<tab><tab><tab><tab>""before_signal hook didn't return True ""<tab><tab><tab><tab>""=> signal %i is not sent to %i"" % (signum, pid)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>process.send_signal(signum)<tab><tab>self.call_hook(""after_signal"", pid=pid, signum=signum)<tab>else:<tab><tab>logger.debug(""process %s does not exist"" % pid)",0,if signum != signal . SIGKILL and not hook_result :,if not hook_result :,0.05451338893552124,24.764986882297123,0.23809523809523808
"def validate_pos_return(self):<tab>if self.is_pos and self.is_return:<tab><tab>total_amount_in_payments = 0<tab><tab>for payment in self.payments:<tab><tab><tab>total_amount_in_payments += payment.amount<tab><tab>invoice_total = self.rounded_total or self.grand_total<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Total payments amount can't be greater than {}"").format(<tab><tab><tab><tab><tab>-invoice_total<tab><tab><tab><tab>)<tab><tab><tab>)",0,if total_amount_in_payments < invoice_total :,if total_amount_in_payments > invoice_total :,0.08141502097923063,76.11606003349888,1.0
"def delete(key, inner_key=None):<tab>if inner_key is not None:<tab><tab>try:<tab><tab><tab>del cache[key][inner_key]<tab><tab><tab>del use_count[key][inner_key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del cache[key]<tab><tab><tab><tab>del use_count[key]<tab><tab><tab>wrapper.cache_size -= 1<tab><tab>except KeyError:<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return True<tab>else:<tab><tab>try:<tab><tab><tab>wrapper.cache_size -= len(cache[key])<tab><tab><tab>del cache[key]<tab><tab><tab>del use_count[key]<tab><tab>except KeyError:<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return True",1,if not cache [ key ] :,if not cache [ key ] :,0.75,100.00000000000004,1.0
"def insertionsort(array):<tab>size = array.getsize()<tab>array.reset(""Insertion sort"")<tab>for i in range(1, size):<tab><tab>j = i - 1<tab><tab>while j >= 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>array.swap(j, j + 1)<tab><tab><tab>j = j - 1<tab>array.message(""Sorted"")",0,"if array . compare ( j , j + 1 ) <= 0 :","if array . compare ( j , size - 1 ) < 0 :",0.5120552419689438,53.36129799268556,0.8333333333333333
"def publish_state(cls, payload, state):<tab>try:<tab><tab>if isinstance(payload, LiveActionDB):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls.process(payload)<tab><tab><tab>else:<tab><tab><tab><tab>worker.get_worker().process(payload)<tab>except Exception:<tab><tab>traceback.print_exc()<tab><tab>print(payload)",0,if state == action_constants . LIVEACTION_STATUS_REQUESTED :,"if state == ""running"" :",0.09453229110448028,17.267606045625936,1.0
"def change_opacity_function(self, new_f):<tab>self.opacity_function = new_f<tab>dr = self.radius / self.num_levels<tab>sectors = []<tab>for submob in self.submobjects:<tab><tab>if type(submob) == AnnularSector:<tab><tab><tab>sectors.append(submob)<tab>for (r, submob) in zip(np.arange(0, self.radius, dr), sectors):<tab><tab><IF-STMT><tab><tab><tab># it's the shadow, don't dim it<tab><tab><tab>continue<tab><tab>alpha = self.opacity_function(r)<tab><tab>submob.set_fill(opacity=alpha)",0,if type ( submob ) != AnnularSector :,if self . opacity_function is None :,0.018333424761606272,5.669791110976001,0.25
"def is_suppressed_warning(<tab>type: str, subtype: str, suppress_warnings: List[str]) -> bool:<tab>""""""Check the warning is suppressed or not.""""""<tab>if type is None:<tab><tab>return False<tab>for warning_type in suppress_warnings:<tab><tab><IF-STMT><tab><tab><tab>target, subtarget = warning_type.split(""."", 1)<tab><tab>else:<tab><tab><tab>target, subtarget = warning_type, None<tab><tab>if target == type:<tab><tab><tab>if (<tab><tab><tab><tab>subtype is None<tab><tab><tab><tab>or subtarget is None<tab><tab><tab><tab>or subtarget == subtype<tab><tab><tab><tab>or subtarget == ""*""<tab><tab><tab>):<tab><tab><tab><tab>return True<tab>return False",1,"if ""."" in warning_type :","if ""."" in warning_type :",0.75,100.00000000000004,1.0
"def set_many(self, mapping, timeout=None):<tab>timeout = self._normalize_timeout(timeout)<tab># Use transaction=False to batch without calling redis MULTI<tab># which is not supported by twemproxy<tab>pipe = self._client.pipeline(transaction=False)<tab>for key, value in _items(mapping):<tab><tab>dump = self.dump_object(value)<tab><tab><IF-STMT><tab><tab><tab>pipe.set(name=self.key_prefix + key, value=dump)<tab><tab>else:<tab><tab><tab>pipe.setex(name=self.key_prefix + key, value=dump, time=timeout)<tab>return pipe.execute()",0,if timeout == - 1 :,if timeout is None :,0.051719732411378776,15.848738972120703,0.4666666666666666
"def maybe_relative_path(path):<tab>if not os.path.isabs(path):<tab><tab>return path  # already relative<tab>dir = path<tab>names = []<tab>while True:<tab><tab>prevdir = dir<tab><tab>dir, name = os.path.split(prevdir)<tab><tab>if dir == prevdir or not dir:<tab><tab><tab>return path  # failed to make it relative<tab><tab>names.append(name)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.reverse()<tab><tab><tab><tab>return os.path.join(*names)<tab><tab>except OSError:<tab><tab><tab>pass",0,"if samefile ( dir , os . curdir ) :",if len ( names ) > 1 :,0.015805905348207437,6.082317172853824,0.21212121212121213
"def word_range(word):<tab>for ind in range(len(word)):<tab><tab>temp = word[ind]<tab><tab>for c in [chr(x) for x in range(ord(""a""), ord(""z"") + 1)]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield word[:ind] + c + word[ind + 1 :]",0,if c != temp :,if c in temp :,0.08141502097923063,24.736929544091932,0.5333333333333333
"def validate(self):<tab>self.update_soil_edit(""sand_composition"")<tab>for soil_type in self.soil_types:<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""{0} should be a value between 0 and 100"").format(soil_type))<tab>if sum(self.get(soil_type) for soil_type in self.soil_types) != 100:<tab><tab>frappe.throw(_(""Soil compositions do not add up to 100""))",0,if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,if sum ( self . get ( soil_type ) for soil_type in self . soil_types ) != 0 :,0.44670773874666836,37.27951040217874,0.3
"def on_click(self, event):<tab>run = self._is_running()<tab>if event[""button""] == self.button_activate:<tab><tab>self.py3.command_run([""xscreensaver-command"", ""-activate""])<tab>if event[""button""] == self.button_toggle:<tab><tab><IF-STMT><tab><tab><tab>self.py3.command_run([""xscreensaver-command"", ""-exit""])<tab><tab>else:<tab><tab><tab># Because we want xscreensaver to continue running after<tab><tab><tab># exit, we instead use preexec_fn=setpgrp here.<tab><tab><tab>Popen(<tab><tab><tab><tab>[""xscreensaver"", ""-no-splash"", ""-no-capture-stderr""],<tab><tab><tab><tab>stdout=PIPE,<tab><tab><tab><tab>stderr=PIPE,<tab><tab><tab><tab>preexec_fn=setpgrp,<tab><tab><tab>)",1,if run :,if run :,0.5311706625951745,1e-10,1.0
"def maybe_relative_path(path):<tab>if not os.path.isabs(path):<tab><tab>return path  # already relative<tab>dir = path<tab>names = []<tab>while True:<tab><tab>prevdir = dir<tab><tab>dir, name = os.path.split(prevdir)<tab><tab><IF-STMT><tab><tab><tab>return path  # failed to make it relative<tab><tab>names.append(name)<tab><tab>try:<tab><tab><tab>if samefile(dir, os.curdir):<tab><tab><tab><tab>names.reverse()<tab><tab><tab><tab>return os.path.join(*names)<tab><tab>except OSError:<tab><tab><tab>pass",0,if dir == prevdir or not dir :,if not os . path . isfile ( dir ) :,0.01721726452019353,5.300156689756295,0.2962962962962963
"def _format_micros(self, datestring):<tab>parts = datestring[:-1].split(""."")<tab>if len(parts) == 1:<tab><tab><IF-STMT><tab><tab><tab>return datestring[:-1] + "".000000Z""<tab><tab>else:<tab><tab><tab>return datestring + "".000000Z""<tab>else:<tab><tab>micros = parts[-1][:6] if len(parts[-1]) > 6 else parts[-1]<tab><tab>return ""."".join(parts[:-1] + [""{:06d}"".format(int(micros))]) + ""Z""",0,"if datestring . endswith ( ""Z"" ) :",if len ( parts [ - 1 ] ) > 6 :,0.016574810992149695,4.789232204309912,0.234375
"def preprocess_raw_enwik9(input_filename, output_filename):<tab>with open(input_filename, ""r"") as f1:<tab><tab>with open(output_filename, ""w"") as f2:<tab><tab><tab>while True:<tab><tab><tab><tab>line = f1.readline()<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>line = list(enwik9_norm_transform([line]))[0]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if line[0] == "" "":<tab><tab><tab><tab><tab><tab>line = line[1:]<tab><tab><tab><tab><tab>f2.writelines(line + ""\n"")",0,"if line != "" "" and line != """" :",if line :,0.020477126045913657,1e-10,0.6309523809523809
"def set(self, item, data):<tab>if not type(item) is slice:<tab><tab>item = slice(item, item + len(data), None)<tab>virt_item = self.item2virtitem(item)<tab>if not virt_item:<tab><tab>return<tab>off = 0<tab>for s, n_item in virt_item:<tab><tab><IF-STMT><tab><tab><tab>i = slice(off, n_item.stop + off - n_item.start, n_item.step)<tab><tab><tab>data_slice = data.__getitem__(i)<tab><tab><tab>s.content.__setitem__(n_item, data_slice)<tab><tab><tab>off = i.stop<tab><tab>else:<tab><tab><tab>raise ValueError(""TODO XXX"")<tab>return",0,"if isinstance ( s , ProgBits ) :",if type ( n_item ) is slice :,0.020373036588449148,5.934202609760488,0.25
"def walk(msg, callback, data):<tab>partnum = 0<tab>for part in msg.walk():<tab><tab># multipart/* are just containers<tab><tab>if part.get_content_maintype() == ""multipart"":<tab><tab><tab>continue<tab><tab>ctype = part.get_content_type()<tab><tab>if ctype is None:<tab><tab><tab>ctype = OCTET_TYPE<tab><tab>filename = part.get_filename()<tab><tab><IF-STMT><tab><tab><tab>filename = PART_FN_TPL % (partnum)<tab><tab>headers = dict(part)<tab><tab>LOG.debug(headers)<tab><tab>headers[""Content-Type""] = ctype<tab><tab>payload = util.fully_decoded_payload(part)<tab><tab>callback(data, filename, payload, headers)<tab><tab>partnum = partnum + 1",0,if not filename :,if filename is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def _run_wes(args):<tab>""""""Run CWL using a Workflow Execution Service (WES) endpoint""""""<tab>main_file, json_file, project_name = _get_main_and_json(args.directory)<tab>main_file = _pack_cwl(main_file)<tab>if args.host and ""stratus"" in args.host:<tab><tab>_run_wes_stratus(args, main_file, json_file)<tab>else:<tab><tab>opts = [""--no-wait""]<tab><tab><IF-STMT><tab><tab><tab>opts += [""--host"", args.host]<tab><tab>if args.auth:<tab><tab><tab>opts += [""--auth"", args.auth]<tab><tab>cmd = [""wes-client""] + opts + [main_file, json_file]<tab><tab>_run_tool(cmd)",1,if args . host :,if args . host :,0.75,100.00000000000004,1.0
"def insertTestData(self, rows):<tab>for row in rows:<tab><tab>if isinstance(row, Worker):<tab><tab><tab>self.workers[row.id] = dict(<tab><tab><tab><tab>id=row.id, name=row.name, paused=0, graceful=0, info=row.info<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>row.id = row.buildermasterid * 10000 + row.workerid<tab><tab><tab>self.configured[row.id] = dict(<tab><tab><tab><tab>buildermasterid=row.buildermasterid, workerid=row.workerid<tab><tab><tab>)<tab><tab>elif isinstance(row, ConnectedWorker):<tab><tab><tab>self.connected[row.id] = dict(masterid=row.masterid, workerid=row.workerid)",0,"elif isinstance ( row , ConfiguredWorker ) :","elif isinstance ( row , BuilderMasterWorker ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def local_shape_to_shape_i(node):<tab>if node.op == T.shape:<tab><tab># This optimization needs ShapeOpt and fgraph.shape_feature<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>shape_feature = node.fgraph.shape_feature<tab><tab>ret = shape_feature.make_vector_shape(node.inputs[0])<tab><tab># We need to copy over stack trace from input to output<tab><tab>copy_stack_trace(node.outputs[0], ret)<tab><tab>return [ret]",0,"if not hasattr ( node . fgraph , ""shape_feature"" ) :",if node . fgraph . shape_feature is None :,0.10540056778274157,17.52592436173078,0.25
"def get_config():<tab>""""""Get INI parser with version.ini data.""""""<tab># TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`.<tab>ini_path = os.path.join(THIS_DIRECTORY, ""version.ini"")<tab><IF-STMT><tab><tab>ini_path = os.path.join(THIS_DIRECTORY, ""../../version.ini"")<tab><tab>if not os.path.exists(ini_path):<tab><tab><tab>raise RuntimeError(""Couldn't find version.ini"")<tab>config = configparser.ConfigParser()<tab>config.read(ini_path)<tab>return config",1,if not os . path . exists ( ini_path ) :,if not os . path . exists ( ini_path ) :,0.75,100.00000000000004,1.0
"def init_weights(self, pretrained=None):<tab>if isinstance(pretrained, str):<tab><tab>logger = logging.getLogger()<tab><tab>load_checkpoint(self, pretrained, strict=False, logger=logger)<tab>elif pretrained is None:<tab><tab>for m in self.modules():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kaiming_init(m)<tab><tab><tab>elif isinstance(m, (_BatchNorm, nn.GroupNorm)):<tab><tab><tab><tab>constant_init(m, 1)<tab>else:<tab><tab>raise TypeError(""pretrained must be a str or None"")",1,"if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . Conv2d ) :",0.75,100.00000000000004,1.0
"def isValidDateString(config_param_name, value, valid_value):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return value<tab><tab>day, month, year = value.split(""-"")<tab><tab>if int(day) < 1 or int(day) > 31:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(month) < 1 or int(month) > 12:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(year) < 1900 or int(year) > 2013:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>return value<tab>except Exception:<tab><tab>raise DateStringValueError(config_param_name, value)",0,"if value == ""DD-MM-YYYY"" :",if valid_value :,0.03549272049582243,1e-10,0.6190476190476191
"def from_obj(cls, py_obj):<tab>if not isinstance(py_obj, Image):<tab><tab>raise TypeError(""py_obj must be a wandb.Image"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>box_keys = list(py_obj._boxes.keys())<tab><tab>else:<tab><tab><tab>box_keys = []<tab><tab>if hasattr(py_obj, ""masks"") and py_obj.masks:<tab><tab><tab>mask_keys = list(py_obj.masks.keys())<tab><tab>else:<tab><tab><tab>mask_keys = []<tab><tab>return cls(box_keys, mask_keys)",1,"if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :",1.0,100.00000000000004,1.0
"def _path_type(st, lst):<tab>parts = []<tab>if st:<tab><tab>if stat.S_ISREG(st.st_mode):<tab><tab><tab>parts.append(""file"")<tab><tab><IF-STMT><tab><tab><tab>parts.append(""dir"")<tab><tab>else:<tab><tab><tab>parts.append(""other"")<tab>if lst:<tab><tab>if stat.S_ISLNK(lst.st_mode):<tab><tab><tab>parts.append(""link"")<tab>return "" "".join(parts)",1,elif stat . S_ISDIR ( st . st_mode ) :,elif stat . S_ISDIR ( st . st_mode ) :,0.75,100.00000000000004,1.0
"def is_destructive(queries):<tab>""""""Returns if any of the queries in *queries* is destructive.""""""<tab>keywords = (""drop"", ""shutdown"", ""delete"", ""truncate"", ""alter"")<tab>for query in sqlparse.split(queries):<tab><tab>if query:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>elif query_starts_with(<tab><tab><tab><tab>query, [""update""]<tab><tab><tab>) is True and not query_has_where_clause(query):<tab><tab><tab><tab>return True<tab>return False",0,"if query_starts_with ( query , keywords ) is True :",if query in keywords :,0.015145994590617124,4.199688916946863,0.4155844155844156
"def _store_gsuite_membership_post(self):<tab>""""""Flush storing gsuite memberships.""""""<tab>if not self.member_cache:<tab><tab>return<tab>self.session.flush()<tab># session.execute automatically flushes<tab>if self.membership_items:<tab><tab><IF-STMT><tab><tab><tab># SQLite doesn't support bulk insert<tab><tab><tab>for item in self.membership_items:<tab><tab><tab><tab>stmt = self.dao.TBL_MEMBERSHIP.insert(item)<tab><tab><tab><tab>self.session.execute(stmt)<tab><tab>else:<tab><tab><tab>stmt = self.dao.TBL_MEMBERSHIP.insert(self.membership_items)<tab><tab><tab>self.session.execute(stmt)",0,"if get_sql_dialect ( self . session ) == ""sqlite"" :","if sys . platform == ""sqlite"" :",0.1035129719768228,27.586495836430913,0.3333333333333333
"def forward(self, inputs: paddle.Tensor):<tab>outputs = []<tab>blocks = self.block(inputs)<tab>route = None<tab>for i, block in enumerate(blocks):<tab><tab><IF-STMT><tab><tab><tab>block = paddle.concat([route, block], axis=1)<tab><tab>route, tip = self.yolo_blocks[i](block)<tab><tab>block_out = self.block_outputs[i](tip)<tab><tab>outputs.append(block_out)<tab><tab>if i < 2:<tab><tab><tab>route = self.route_blocks_2[i](route)<tab><tab><tab>route = self.upsample(route)<tab>return outputs",0,if i > 0 :,if i < 2 :,0.31497877230811644,23.643540225079384,0.6
"def deep_dict(self, root=None):<tab>if root is None:<tab><tab>root = self<tab>result = {}<tab>for key, value in root.items():<tab><tab><IF-STMT><tab><tab><tab>result[key] = self.deep_dict(root=self.__class__._get_next(key, root))<tab><tab>else:<tab><tab><tab>result[key] = value<tab>return result",1,"if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",0.75,100.00000000000004,1.0
"def _parse_param_list(self, content):<tab>r = Reader(content)<tab>params = []<tab>while not r.eof():<tab><tab>header = r.read().strip()<tab><tab><IF-STMT><tab><tab><tab>arg_name, arg_type = header.split("" : "")[:2]<tab><tab>else:<tab><tab><tab>arg_name, arg_type = header, """"<tab><tab>desc = r.read_to_next_unindented_line()<tab><tab>desc = dedent_lines(desc)<tab><tab>params.append((arg_name, arg_type, desc))<tab>return params",1,"if "" : "" in header :","if "" : "" in header :",0.75,100.00000000000004,1.0
"def _ungroup(sequence, groups=None):<tab>for v in sequence:<tab><tab><IF-STMT><tab><tab><tab>if groups is not None:<tab><tab><tab><tab>groups.append(list(_ungroup(v, groups=None)))<tab><tab><tab>for v in _ungroup(v, groups):<tab><tab><tab><tab>yield v<tab><tab>else:<tab><tab><tab>yield v",0,"if isinstance ( v , ( list , tuple ) ) :","if isinstance ( v , list ) :",0.19029013543631623,37.28878639930421,0.8222222222222223
"def _add_resource_group(obj):<tab>if isinstance(obj, list):<tab><tab>for array_item in obj:<tab><tab><tab>_add_resource_group(array_item)<tab>elif isinstance(obj, dict):<tab><tab>try:<tab><tab><tab>if ""resourcegroup"" not in [x.lower() for x in obj.keys()]:<tab><tab><tab><tab>if obj[""id""]:<tab><tab><tab><tab><tab>obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""]<tab><tab>except (KeyError, IndexError, TypeError):<tab><tab><tab>pass<tab><tab>for item_key in obj:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_add_resource_group(obj[item_key])",0,"if item_key != ""sourceVault"" :","if item_key in ( ""resourcegroup"" , ""resourcegroup"" ) :",0.04757349237680735,18.92240568795936,0.6444444444444445
"def haslayer(self, cls):<tab>""""""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax.""""""<tab>if self.__class__ == cls or self.__class__.__name__ == cls:<tab><tab>return 1<tab>for f in self.packetfields:<tab><tab>fvalue_gen = self.getfieldval(f.name)<tab><tab>if fvalue_gen is None:<tab><tab><tab>continue<tab><tab>if not f.islist:<tab><tab><tab>fvalue_gen = SetGen(fvalue_gen, _iterpacket=0)<tab><tab>for fvalue in fvalue_gen:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = fvalue.haslayer(cls)<tab><tab><tab><tab>if ret:<tab><tab><tab><tab><tab>return ret<tab>return self.payload.haslayer(cls)",0,"if isinstance ( fvalue , Packet ) :",if fvalue . islayer :,0.019907917998500824,7.715486568024961,0.3148148148148148
"def _post_attachment(self, message, channel, color, sub_fields=None):<tab>if channel is None:<tab><tab>message_channels = self.channels<tab>else:<tab><tab>message_channels = [channel]<tab>for message_channel in message_channels:<tab><tab>attachment = {<tab><tab><tab>""fallback"": message,<tab><tab><tab>""text"": message,<tab><tab><tab>""color"": color,<tab><tab>}<tab><tab><IF-STMT><tab><tab><tab>attachment[""fields""] = sub_fields<tab><tab>self.slack_client.api_call(<tab><tab><tab>""chat.postMessage"",<tab><tab><tab>channel=message_channel,<tab><tab><tab>attachments=[attachment],<tab><tab><tab>as_user=True,<tab><tab>)",0,if sub_fields is not None :,if sub_fields :,0.050438393472541504,1e-10,0.3142857142857143
"def create(cls, repository, args):<tab>key = cls()<tab>passphrase = os.environ.get(""ATTIC_PASSPHRASE"")<tab>if passphrase is not None:<tab><tab>passphrase2 = passphrase<tab>else:<tab><tab>passphrase, passphrase2 = 1, 2<tab>while passphrase != passphrase2:<tab><tab>passphrase = getpass(""Enter passphrase: "")<tab><tab><IF-STMT><tab><tab><tab>print(""Passphrase must not be blank"")<tab><tab><tab>continue<tab><tab>passphrase2 = getpass(""Enter same passphrase again: "")<tab><tab>if passphrase != passphrase2:<tab><tab><tab>print(""Passphrases do not match"")<tab>key.init(repository, passphrase)<tab>if passphrase:<tab><tab>print(""Remember your passphrase. Your data will be inaccessible without it."")<tab>return key",0,if not passphrase :,if passphrase is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def _generate_create_date(self):<tab>if self.timezone is not None:<tab><tab># First, assume correct capitalization<tab><tab>tzinfo = tz.gettz(self.timezone)<tab><tab><IF-STMT><tab><tab><tab># Fall back to uppercase<tab><tab><tab>tzinfo = tz.gettz(self.timezone.upper())<tab><tab>if tzinfo is None:<tab><tab><tab>raise util.CommandError(""Can't locate timezone: %s"" % self.timezone)<tab><tab>create_date = (<tab><tab><tab>datetime.datetime.utcnow().replace(tzinfo=tz.tzutc()).astimezone(tzinfo)<tab><tab>)<tab>else:<tab><tab>create_date = datetime.datetime.now()<tab>return create_date",1,if tzinfo is None :,if tzinfo is None :,0.75,100.00000000000004,1.0
"def _read_header_lines(fp):<tab>""""""Read lines with headers until the start of body""""""<tab>lines = deque()<tab>for line in fp:<tab><tab>if is_empty(line):<tab><tab><tab>break<tab><tab># tricky case if it's not a header and not an empty line<tab><tab># usually means that user forgot to separate the body and newlines<tab><tab># so ""unread"" this line here, what means to treat it like a body<tab><tab><IF-STMT><tab><tab><tab>fp.seek(fp.tell() - len(line))<tab><tab><tab>break<tab><tab>lines.append(line)<tab>return lines",0,if not _RE_HEADER . match ( line ) :,"if not line . endswith ( ""\n"" ) :",0.04168260765390195,11.016798394984653,0.5
"def _media_files_drag_received(widget, context, x, y, data, info, timestamp):<tab>uris = data.get_uris()<tab>files = []<tab>for uri in uris:<tab><tab>try:<tab><tab><tab>uri_tuple = GLib.filename_from_uri(uri)<tab><tab>except:<tab><tab><tab>continue<tab><tab>uri, unused = uri_tuple<tab><tab><IF-STMT><tab><tab><tab>if utils.is_media_file(uri) == True:<tab><tab><tab><tab>files.append(uri)<tab>if len(files) == 0:<tab><tab>return<tab>open_dropped_files(files)",0,if os . path . exists ( uri ) == True :,if uri :,0.008307009447911351,1e-10,0.25
"def remove_importlib(frame, options):<tab>if frame is None:<tab><tab>return None<tab>for child in frame.children:<tab><tab>remove_importlib(child, options=options)<tab><tab><IF-STMT><tab><tab><tab># remove this node, moving the self_time and children up to the parent<tab><tab><tab>frame.self_time += child.self_time<tab><tab><tab>frame.add_children(child.children, after=child)<tab><tab><tab>child.remove_from_parent()<tab>return frame",0,"if ""<frozen importlib._bootstrap"" in child . file_path :","if hasattr ( child , ""children"" ) :",0.019345087832959386,3.443603847153095,0.6
"def __call__(self, graph):<tab>for layer_name, data in self.params:<tab><tab><IF-STMT><tab><tab><tab>node = graph.get_node(layer_name)<tab><tab><tab>node.data = self.adjust_parameters(node, data)<tab><tab>else:<tab><tab><tab>print_stderr(""Ignoring parameters for non-existent layer: %s"" % layer_name)<tab>return graph",0,if layer_name in graph :,if graph . has_node ( layer_name ) :,0.029323260600185464,14.991106946711685,0.4772727272727273
"def test_with_three_points(self):<tab>cba = ia.Polygon([(1, 2), (3, 4), (5, 5)])<tab>for i, xy in enumerate(cba):<tab><tab>assert i in [0, 1, 2]<tab><tab>if i == 0:<tab><tab><tab>assert np.allclose(xy, (1, 2))<tab><tab><IF-STMT><tab><tab><tab>assert np.allclose(xy, (3, 4))<tab><tab>elif i == 2:<tab><tab><tab>assert np.allclose(xy, (5, 5))<tab>assert i == 2",1,elif i == 1 :,elif i == 1 :,1.0,100.00000000000004,1.0
"def _serve(self):<tab>self._conn = self.manager.request(REQUEST_DNS_LISTENER, self.domain)<tab>conn = MsgPackMessages(self._conn)<tab>while self.active:<tab><tab>request = conn.recv()<tab><tab>if not request:<tab><tab><tab>logger.warning(""DNS: Recieved empty request. Shutdown"")<tab><tab><tab>self.stop()<tab><tab><tab>break<tab><tab>now = time.time()<tab><tab>response = self.handler.process(request)<tab><tab>if not response:<tab><tab><tab>response = []<tab><tab>used = time.time() - now<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""DNS: Slow processing speed (%s)s"", used)<tab><tab>conn.send(response)",0,if used > 1 :,if used > self . _speed :,0.11726065783135259,22.089591134157878,0.6
"def read(cls, fp, **kwargs):<tab>major_version, minor_version, count = read_fmt(""2HI"", fp)<tab>items = []<tab>for _ in range(count):<tab><tab>length = read_fmt(""I"", fp)[0] - 4<tab><tab><IF-STMT><tab><tab><tab>with io.BytesIO(fp.read(length)) as f:<tab><tab><tab><tab>items.append(Annotation.read(f))<tab>return cls(major_version=major_version, minor_version=minor_version, items=items)",1,if length > 0 :,if length > 0 :,0.75,100.00000000000004,1.0
"def save_uploaded_files():<tab>files = []<tab>unzip = bool(request.form.get(""unzip"") in [""true"", ""on""])<tab>for uploaded_file in request.files.getlist(""files""):<tab><tab><IF-STMT><tab><tab><tab>with zipfile.ZipFile(uploaded_file, ""r"") as zf:<tab><tab><tab><tab>for info in zf.infolist():<tab><tab><tab><tab><tab>name = info.filename<tab><tab><tab><tab><tab>size = info.file_size<tab><tab><tab><tab><tab>data = zf.read(name)<tab><tab><tab><tab><tab>if size > 0:<tab><tab><tab><tab><tab><tab>files.append(save_file(data, filename=name.split(""/"")[-1]))<tab><tab>else:<tab><tab><tab>files.append(save_file(uploaded_file))<tab>return files",0,if unzip and zipfile . is_zipfile ( uploaded_file ) :,if unzip :,0.020477126045913657,1e-10,0.5714285714285714
"def analyze_string_content(self, string, line_num, filename):<tab>output = {}<tab>if self.keyword_exclude and self.keyword_exclude.search(string):<tab><tab>return output<tab>for identifier in self.secret_generator(<tab><tab>string,<tab><tab>filetype=determine_file_type(filename),<tab>):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>secret = PotentialSecret(<tab><tab><tab>self.secret_type,<tab><tab><tab>filename,<tab><tab><tab>identifier,<tab><tab><tab>line_num,<tab><tab>)<tab><tab>output[secret] = secret<tab>return output",0,if self . is_secret_false_positive ( identifier ) :,if identifier is None :,0.019907917998500824,2.497149970415641,0.3148148148148148
"def _validate_and_set_default_hyperparameters(self):<tab>""""""Placeholder docstring""""""<tab># Check if all the required hyperparameters are set. If there is a default value<tab># for one, set it.<tab>for name, definition in self.hyperparameter_definitions.items():<tab><tab>if name not in self.hyperparam_dict:<tab><tab><tab>spec = definition[""spec""]<tab><tab><tab>if ""DefaultValue"" in spec:<tab><tab><tab><tab>self.hyperparam_dict[name] = spec[""DefaultValue""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Required hyperparameter: %s is not set"" % name)",0,"elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :",elif name not in self . hyperparam_dict :,0.08548998635897431,3.701773936489291,0.25
"def get_code(self, fullname=None):<tab>fullname = self._fix_name(fullname)<tab>if self.code is None:<tab><tab>mod_type = self.etc[2]<tab><tab>if mod_type == imp.PY_SOURCE:<tab><tab><tab>source = self.get_source(fullname)<tab><tab><tab>self.code = compile(source, self.filename, ""exec"")<tab><tab>elif mod_type == imp.PY_COMPILED:<tab><tab><tab>self._reopen()<tab><tab><tab>try:<tab><tab><tab><tab>self.code = read_code(self.file)<tab><tab><tab>finally:<tab><tab><tab><tab>self.file.close()<tab><tab><IF-STMT><tab><tab><tab>self.code = self._get_delegate().get_code()<tab>return self.code",0,elif mod_type == imp . PKG_DIRECTORY :,elif self . _get_delegate is not None :,0.020006902369987596,5.117229509364272,0.23809523809523808
"def eigh_abstract_eval(operand, lower):<tab>if isinstance(operand, ShapedArray):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Argument to symmetric eigendecomposition must have shape [..., n, n],""<tab><tab><tab><tab>""got shape {}"".format(operand.shape)<tab><tab><tab>)<tab><tab>batch_dims = operand.shape[:-2]<tab><tab>n = operand.shape[-1]<tab><tab>v = ShapedArray(batch_dims + (n, n), operand.dtype)<tab><tab>w = ShapedArray(batch_dims + (n,), lax.lax._complex_basetype(operand.dtype))<tab>else:<tab><tab>v, w = operand, operand<tab>return v, w",0,if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,if lower . shape != operand . shape :,0.07786844713792541,11.863723935473883,0.2
"def conninfo_parse(dsn):<tab>ret = {}<tab>length = len(dsn)<tab>i = 0<tab>while i < length:<tab><tab>if dsn[i].isspace():<tab><tab><tab>i += 1<tab><tab><tab>continue<tab><tab>param_match = PARAMETER_RE.match(dsn[i:])<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>param = param_match.group(1)<tab><tab>i += param_match.end()<tab><tab>if i >= length:<tab><tab><tab>return<tab><tab>value, end = read_param_value(dsn[i:])<tab><tab>if value is None:<tab><tab><tab>return<tab><tab>i += end<tab><tab>ret[param] = value<tab>return ret",0,if not param_match :,if param_match is None :,0.045150550804307965,27.77619034011791,0.36
"def load_weights_from_unsupervised(self, unsupervised_model):<tab>update_state_dict = copy.deepcopy(self.network.state_dict())<tab>for param, weights in unsupervised_model.network.state_dict().items():<tab><tab>if param.startswith(""encoder""):<tab><tab><tab># Convert encoder's layers name to match<tab><tab><tab>new_param = ""tabnet."" + param<tab><tab>else:<tab><tab><tab>new_param = param<tab><tab><IF-STMT><tab><tab><tab># update only common layers<tab><tab><tab>update_state_dict[new_param] = weights<tab>self.network.load_state_dict(update_state_dict)",0,if self . network . state_dict ( ) . get ( new_param ) is not None :,if new_param in weights :,0.061596088874225824,3.759098586913923,0.18333333333333335
"def viewer_setup(self):<tab>for key, value in DEFAULT_CAMERA_CONFIG.items():<tab><tab><IF-STMT><tab><tab><tab>getattr(self.viewer.cam, key)[:] = value<tab><tab>else:<tab><tab><tab>setattr(self.viewer.cam, key, value)",0,"if isinstance ( value , np . ndarray ) :","if isinstance ( value , list ) :",0.23202903606635522,46.307771619910305,0.5584415584415584
"def colormap_changed(change):<tab>if change[""new""]:<tab><tab>cmap_colors = [<tab><tab><tab>color[1:] for color in cmap.step.__dict__[""_schemes""][colormap.value]<tab><tab>]<tab><tab>palette.value = "", "".join(cmap_colors)<tab><tab>colorbar = getattr(cmap.step, colormap.value)<tab><tab>colorbar_output = self.colorbar_widget<tab><tab>with colorbar_output:<tab><tab><tab>colorbar_output.clear_output()<tab><tab><tab>display(colorbar)<tab><tab><IF-STMT><tab><tab><tab>labels = [f""Class {i+1}"" for i in range(len(palette.value.split("","")))]<tab><tab><tab>legend_labels.value = "", "".join(labels)",0,"if len ( palette . value ) > 0 and "","" in palette . value :","if change [ ""old"" ] :",0.00684420197912045,2.2375594425769316,0.18518518518518517
"def invalidate(self, layers=None):<tab>if layers is None:<tab><tab>layers = Layer.AllLayers<tab>if layers:<tab><tab>layers = set(layers)<tab><tab>self.invalidLayers.update(layers)<tab><tab>blockRenderers = [<tab><tab><tab>br<tab><tab><tab>for br in self.blockRenderers<tab><tab><tab>if br.layer is Layer.Blocks or br.layer not in layers<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>self.forgetDisplayLists()<tab><tab>self.blockRenderers = blockRenderers<tab><tab>if self.renderer.showRedraw and Layer.Blocks in layers:<tab><tab><tab>self.needsRedisplay = True",0,if len ( blockRenderers ) < len ( self . blockRenderers ) :,if len ( blockRenderers ) == 0 :,0.21530161030784029,29.95197100101507,0.5347222222222222
"def fromstring(cls, input):<tab>productions = []<tab>for linenum, line in enumerate(input.split(""\n"")):<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>productions += _read_dependency_production(line)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""Unable to parse line %s: %s"" % (linenum, line))<tab>if len(productions) == 0:<tab><tab>raise ValueError(""No productions found!"")<tab>return DependencyGrammar(productions)",0,"if line . startswith ( ""#"" ) or line == """" :",if not line :,0.010023274633399372,1.0466441829132096,0.3125
"def repl(m, base_path, rel_path=None):<tab>if m.group(""comments""):<tab><tab>tag = m.group(""comments"")<tab>else:<tab><tab>tag = m.group(""open"")<tab><tab><IF-STMT><tab><tab><tab>tag += RE_TAG_LINK_ATTR.sub(<tab><tab><tab><tab>lambda m2: repl_absolute(m2, base_path), m.group(""attr"")<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>tag += RE_TAG_LINK_ATTR.sub(<tab><tab><tab><tab>lambda m2: repl_relative(m2, base_path, rel_path), m.group(""attr"")<tab><tab><tab>)<tab><tab>tag += m.group(""close"")<tab>return tag",1,if rel_path is None :,if rel_path is None :,0.75,100.00000000000004,1.0
"def encode(path):<tab>if isinstance(path, str_cls):<tab><tab>try:<tab><tab><tab>path = path.encode(fs_encoding, ""strict"")<tab><tab>except UnicodeEncodeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>path = path.encode(fs_fallback_encoding, ""strict"")<tab>return path",0,if not platform . is_linux ( ) :,if path == fs_fallback_encoding :,0.01858685153282265,5.522397783539471,0.38181818181818183
"def __iter__(self):<tab>base_iterator = super(ProcessIterable, self).__iter__()<tab>if getattr(self.queryset, ""_coerced"", False):<tab><tab>for process in base_iterator:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>process = coerce_to_related_instance(<tab><tab><tab><tab><tab>process, process.flow_class.process_class<tab><tab><tab><tab>)<tab><tab><tab>yield process<tab>else:<tab><tab>for process in base_iterator:<tab><tab><tab>yield process",0,"if isinstance ( process , self . queryset . model ) :","if hasattr ( process , ""flow_class"" ) :",0.056761586636113734,16.59038701421971,0.35
"def footnotes_under(n: Element) -> Iterator[nodes.footnote]:<tab>if isinstance(n, nodes.footnote):<tab><tab>yield n<tab>else:<tab><tab>for c in n.children:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>elif isinstance(c, nodes.Element):<tab><tab><tab><tab>yield from footnotes_under(c)",0,"if isinstance ( c , addnodes . start_of_file ) :","if isinstance ( c , nodes . footnote ) :",0.485600785330624,31.313195073576246,0.5584415584415584
"def _process_submissions(self) -> None:<tab>""""""Process all submissions which have not been processed yet.""""""<tab>while self._to_be_processed:<tab><tab>job = self._to_be_processed[0]<tab><tab>job.process()  # trigger computation<tab><tab><IF-STMT><tab><tab><tab>heapq.heappush(<tab><tab><tab><tab>self._steady_priority_queue,<tab><tab><tab><tab>OrderedJobs(job.release_time, self._order, job),<tab><tab><tab>)<tab><tab>self._to_be_processed.popleft()  # remove right after it is added to the heap queue<tab><tab>self._order += 1",0,if not self . batch_mode :,if job . release_time is not None :,0.02492724325929667,6.27465531099474,0.25
"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab>if strip_delimiters:<tab><tab><tab>if "","" in line or "";"" in line:<tab><tab><tab><tab>continue<tab><tab>yield line",0,if match :,if not match :,0.11348623737539229,1e-10,0.41666666666666663
"def _get_payload_hash(self, method, data=None):<tab>if method in (""POST"", ""PUT""):<tab><tab>if data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># File upload; don't try to read the entire payload<tab><tab><tab><tab>return UNSIGNED_PAYLOAD<tab><tab><tab>return _hash(data)<tab><tab>else:<tab><tab><tab>return UNSIGNED_PAYLOAD<tab>else:<tab><tab>return _hash("""")",0,"if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :",if os . path . isfile ( data ) :,0.021529344013264076,3.420086125151574,0.24342105263157893
"def get_download_info(self):<tab>try:<tab><tab>download_info = self.api.get_download_info(self.game)<tab><tab>result = True<tab>except NoDownloadLinkFound as e:<tab><tab>print(e)<tab><tab><IF-STMT><tab><tab><tab>Config.unset(""current_download"")<tab><tab>GLib.idle_add(<tab><tab><tab>self.parent.parent.show_error,<tab><tab><tab>_(""Download error""),<tab><tab><tab>_(<tab><tab><tab><tab>""There was an error when trying to fetch the download link!\n{}"".format(<tab><tab><tab><tab><tab>e<tab><tab><tab><tab>)<tab><tab><tab>),<tab><tab>)<tab><tab>download_info = False<tab><tab>result = False<tab>return result, download_info",0,"if Config . get ( ""current_download"" ) == self . game . id :",if self . parent . show_error :,0.10174047936913004,4.131145058582203,0.23026315789473684
"def find_id(self, doc_id):<tab>self._lock.acquire()<tab>try:<tab><tab>doc = self._docs.get(doc_id)<tab><tab><IF-STMT><tab><tab><tab>doc = copy.deepcopy(doc)<tab><tab><tab>doc[""id""] = doc_id<tab><tab><tab>return doc<tab>finally:<tab><tab>self._lock.release()",1,if doc :,if doc :,0.5311706625951745,1e-10,1.0
"def assign_art(self, session, task):<tab>""""""Place the discovered art in the filesystem.""""""<tab>if task in self.art_candidates:<tab><tab>candidate = self.art_candidates.pop(task)<tab><tab>self._set_art(task.album, candidate, not self.src_removed)<tab><tab><IF-STMT><tab><tab><tab>task.prune(candidate.path)",1,if self . src_removed :,if self . src_removed :,0.75,100.00000000000004,1.0
"def _replace_named(self, named, replace_scalar):<tab>for item in named:<tab><tab>for name, value in self._get_replaced_named(item, replace_scalar):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise DataError(""Argument names must be strings."")<tab><tab><tab>yield name, value",0,if not is_string ( name ) :,"if not isinstance ( name , str ) :",0.0526546569220252,16.51582159006904,0.4666666666666666
"def qtTypeIdent(conn, *args):<tab># We're not using the conn object at the moment, but - we will<tab># modify the<tab># logic to use the server version specific keywords later.<tab>res = None<tab>value = None<tab>for val in args:<tab><tab># DataType doesn't have len function then convert it to string<tab><tab>if not hasattr(val, ""__len__""):<tab><tab><tab>val = str(val)<tab><tab>if len(val) == 0:<tab><tab><tab>continue<tab><tab>value = val<tab><tab><IF-STMT><tab><tab><tab>value = value.replace('""', '""""')<tab><tab><tab>value = '""' + value + '""'<tab><tab>res = ((res and res + ""."") or """") + value<tab>return res",0,"if Driver . needsQuoting ( val , True ) :","if isinstance ( value , str ) :",0.09182110869048599,10.816059393812111,0.21212121212121213
"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops):<tab>for n in tileable_graph:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>tiled_n = get_tiled(n)<tab><tab>if has_unknown_shape(tiled_n):<tab><tab><tab>if any(c.key not in chunk_result for c in tiled_n.chunks):<tab><tab><tab><tab># some of the chunks has been fused<tab><tab><tab><tab>continue<tab><tab><tab>new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result)<tab><tab><tab>for node in (n, tiled_n):<tab><tab><tab><tab>node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits))<tab><tab><tab>tiled_n._nsplits = new_nsplits",0,if n . op in failed_ops :,if n in failed_ops :,0.10920018001916708,53.137468984124546,0.5714285714285714
"def _read_filter(self, data):<tab>if data:<tab><tab><IF-STMT><tab><tab><tab>self.inner_sha.update(data)<tab><tab>if self.expected_inner_md5sum:<tab><tab><tab>self.inner_md5.update(data)<tab>return data",0,if self . expected_inner_sha256 :,if self . expected_inner_sha :,0.39477865547525276,75.06238537503395,1.0
"def find_previous_editable(self, *args):<tab>if self.editw == 0:<tab><tab>if self._active_page > 0:<tab><tab><tab>self.switch_page(self._active_page - 1)<tab>if not self.editw == 0:<tab><tab># remember that xrange does not return the 'last' value,<tab><tab># so go to -1, not 0! (fence post error in reverse)<tab><tab>for n in range(self.editw - 1, -1, -1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.editw = n<tab><tab><tab><tab>break",0,if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,if args [ n ] == 0 :,0.02369564393158333,3.049741524256861,0.24814814814814815
"def _get_event_for_message(self, message_id):<tab>with self.event_lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Event for message[{}] should have been created before accessing"".format(<tab><tab><tab><tab><tab>message_id<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>return self._events[message_id]",1,if message_id not in self . _events :,if message_id not in self . _events :,0.75,100.00000000000004,1.0
"def _get_deepest(self, t):<tab>if isinstance(t, list):<tab><tab>if len(t) == 1:<tab><tab><tab>return t[0]<tab><tab>else:<tab><tab><tab>for part in t:<tab><tab><tab><tab>res = self._get_deepest(part)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return res<tab><tab><tab>return None<tab>return None",1,if res :,if res :,0.5311706625951745,1e-10,1.0
"def _get_notify(self, action_node):<tab>if action_node.name not in self._skip_notify_tasks:<tab><tab><IF-STMT><tab><tab><tab>task_notify = NotificationsHelper.to_model(action_node.notify)<tab><tab><tab>return task_notify<tab><tab>elif self._chain_notify:<tab><tab><tab>return self._chain_notify<tab>return None",1,if action_node . notify :,if action_node . notify :,0.75,100.00000000000004,1.0
"def __init__(self, centered=None, shape_params=()):<tab>assert centered is None or isinstance(centered, (float, torch.Tensor))<tab>assert isinstance(shape_params, (tuple, list))<tab>assert all(isinstance(name, str) for name in shape_params)<tab>if is_validation_enabled():<tab><tab>if isinstance(centered, float):<tab><tab><tab>assert 0 <= centered and centered <= 1<tab><tab><IF-STMT><tab><tab><tab>assert (0 <= centered).all()<tab><tab><tab>assert (centered <= 1).all()<tab><tab>else:<tab><tab><tab>assert centered is None<tab>self.centered = centered<tab>self.shape_params = shape_params",1,"elif isinstance ( centered , torch . Tensor ) :","elif isinstance ( centered , torch . Tensor ) :",0.75,100.00000000000004,1.0
"def collect(self):<tab>for nickname in self.squid_hosts.keys():<tab><tab>squid_host = self.squid_hosts[nickname]<tab><tab>fulldata = self._getData(squid_host[""host""], squid_host[""port""])<tab><tab>if fulldata is not None:<tab><tab><tab>fulldata = fulldata.splitlines()<tab><tab><tab>for data in fulldata:<tab><tab><tab><tab>matches = self.stat_pattern.match(data)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.publish_counter(<tab><tab><tab><tab><tab><tab>""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2))<tab><tab><tab><tab><tab>)",0,if matches :,if matches is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab><IF-STMT><tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64MIME.base64_len(""x"" * size), bsize)",0,elif size <= 9 :,elif size <= 7 :,0.39287202148494,53.7284965911771,0.6
"def wait_for_initial_conf(self, timeout=1.0):<tab>logger.info(""Waiting for initial configuration"")<tab>cur_timeout = timeout<tab># Arbiter do not already set our have_conf param<tab>while not self.new_conf and not self.interrupted:<tab><tab>elapsed, _, _ = self.handleRequests(cur_timeout)<tab><tab>if elapsed:<tab><tab><tab>cur_timeout -= elapsed<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>cur_timeout = timeout<tab><tab>sys.stdout.write(""."")<tab><tab>sys.stdout.flush()",0,if cur_timeout > 0 :,if cur_timeout <= 0 :,0.33141502097923065,41.11336169005198,1.0
"def __init__(self, querylist=None):<tab>self.query_id = -1<tab>if querylist is None:<tab><tab>self.querylist = []<tab>else:<tab><tab>self.querylist = querylist<tab><tab>for query in self.querylist:<tab><tab><tab>if self.query_id == -1:<tab><tab><tab><tab>self.query_id = query.query_id<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(""query in list must be same query_id"")",0,if self . query_id != query . query_id :,if self . query_id != - 1 :,0.3029139744467516,53.209625959695856,0.6
"def candidates() -> Generator[""Symbol"", None, None]:<tab>s = self<tab>if Symbol.debug_lookup:<tab><tab>Symbol.debug_print(""searching in self:"")<tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")<tab>while True:<tab><tab>if matchSelf:<tab><tab><tab>yield s<tab><tab><IF-STMT><tab><tab><tab>yield from s.children_recurse_anon<tab><tab>else:<tab><tab><tab>yield from s._children<tab><tab>if s.siblingAbove is None:<tab><tab><tab>break<tab><tab>s = s.siblingAbove<tab><tab>if Symbol.debug_lookup:<tab><tab><tab>Symbol.debug_print(""searching in sibling:"")<tab><tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")",0,if recurseInAnon :,"elif isinstance ( s , Anon ) :",0.029927115465652444,1e-10,0.1142857142857143
"def get_default_params(problem_type: str, penalty: str):<tab># TODO: get seed from seeds provider<tab>if problem_type == REGRESSION:<tab><tab>default_params = {""C"": None, ""random_state"": 0, ""fit_intercept"": True}<tab><tab><IF-STMT><tab><tab><tab>default_params[""solver""] = ""auto""<tab>else:<tab><tab>default_params = {<tab><tab><tab>""C"": None,<tab><tab><tab>""random_state"": 0,<tab><tab><tab>""solver"": _get_solver(problem_type),<tab><tab><tab>""n_jobs"": -1,<tab><tab><tab>""fit_intercept"": True,<tab><tab>}<tab>model_params = list(default_params.keys())<tab>return model_params, default_params",0,if penalty == L2 :,"if penalty == ""auto"" :",0.14477865547525276,36.55552228545123,0.7
"def _UploadDirectory(local_dir: str, gcs_bucket: storage.Bucket, gcs_dir: str):<tab>""""""Upload the contents of a local directory to a GCS Bucket.""""""<tab>for file_name in os.listdir(local_dir):<tab><tab>path = os.path.join(local_dir, file_name)<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Skipping %s as it's not a file."", path)<tab><tab><tab>continue<tab><tab>logging.info(""Uploading: %s"", path)<tab><tab>gcs_blob = gcs_bucket.blob(f""{gcs_dir}/{file_name}"")<tab><tab>gcs_blob.upload_from_filename(path)",1,if not os . path . isfile ( path ) :,if not os . path . isfile ( path ) :,1.0,100.00000000000004,1.0
"def decode_query_ids(self, trans, conditional):<tab>if conditional.operator == ""and"":<tab><tab>self.decode_query_ids(trans, conditional.left)<tab><tab>self.decode_query_ids(trans, conditional.right)<tab>else:<tab><tab>left_base = conditional.left.split(""."")[0]<tab><tab>if left_base in self.FIELDS:<tab><tab><tab>field = self.FIELDS[left_base]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>conditional.right = trans.security.decode_id(conditional.right)",0,if field . id_decode :,"if field == ""id"" :",0.06497877230811641,13.134549472120788,1.0
"def data_dir(self) -> Path:<tab>try:<tab><tab>from appdirs import user_data_dir<tab>except ImportError:<tab><tab># linux<tab><tab>path = Path.home() / "".local"" / ""share""<tab><tab><IF-STMT><tab><tab><tab>return path / ""dephell""<tab><tab># mac os<tab><tab>path = Path.home() / ""Library"" / ""Application Support""<tab><tab>if path.exists():<tab><tab><tab>return path / ""dephell""<tab><tab>self.pip_main([""install"", ""appdirs""])<tab><tab>from appdirs import user_data_dir<tab>return Path(user_data_dir(""dephell""))",1,if path . exists ( ) :,if path . exists ( ) :,0.75,100.00000000000004,1.0
"def setGameCard(self, isGameCard=False):<tab>if isGameCard:<tab><tab>targetValue = 1<tab>else:<tab><tab>targetValue = 0<tab>for nca in self:<tab><tab>if isinstance(nca, Nca):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>Print.info(""writing isGameCard for %s, %d"" % (str(nca._path), targetValue))<tab><tab><tab>nca.header.setIsGameCard(targetValue)",0,if nca . header . getIsGameCard ( ) == targetValue :,if nca . header . isGameCard :,0.18736757193714082,31.499993000872454,0.5604395604395604
"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab>if mode == ""start"":<tab><tab><tab>if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""key""<tab><tab><IF-STMT><tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab>elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",0,"elif mode == ""key"" :","elif ""END RSA PRIVATE KEY"" in s :",0.024231488401191333,5.934202609760488,0.23809523809523808
"def register_aggregate_groups(conn, *groups):<tab>seen = set()<tab>for group in groups:<tab><tab>klasses = AGGREGATE_COLLECTION[group]<tab><tab>for klass in klasses:<tab><tab><tab>name = getattr(klass, ""name"", klass.__name__)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>seen.add(name)<tab><tab><tab><tab>conn.create_aggregate(name, -1, klass)",1,if name not in seen :,if name not in seen :,0.75,100.00000000000004,1.0
"def _impl(inputs, input_types):<tab>data = inputs[0]<tab>axis = None<tab>keepdims = False<tab>if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False<tab><tab>if isinstance(inputs[1], int):<tab><tab><tab>axis = int(inputs[1])<tab><tab><IF-STMT><tab><tab><tab>axis = inputs[1]<tab><tab>else:<tab><tab><tab>axis = list(_infer_shape(inputs[1]))<tab><tab>keepdims = bool(inputs[2])<tab>return get_relay_op(name)(data, axis=axis, keepdims=keepdims)",0,elif _is_int_seq ( inputs [ 1 ] ) :,"elif isinstance ( inputs [ 1 ] , torch . Tensor ) :",0.34366608471825716,31.843164596791894,0.2605042016806723
"def walks_generator():<tab>if filelist is not None:<tab><tab>bucket = []<tab><tab>for filename in filelist:<tab><tab><tab>with io.open(filename) as inf:<tab><tab><tab><tab>for line in inf:<tab><tab><tab><tab><tab>walk = [int(x) for x in line.strip(""\n"").split("" "")]<tab><tab><tab><tab><tab>bucket.append(walk)<tab><tab><tab><tab><tab>if len(bucket) == batch_size:<tab><tab><tab><tab><tab><tab>yield bucket<tab><tab><tab><tab><tab><tab>bucket = []<tab><tab><IF-STMT><tab><tab><tab>yield bucket<tab>else:<tab><tab>for _ in range(epoch):<tab><tab><tab>for nodes in graph.node_batch_iter(batch_size):<tab><tab><tab><tab>walks = graph.random_walk(nodes, walk_len)<tab><tab><tab><tab>yield walks",1,if len ( bucket ) :,if len ( bucket ) :,0.75,100.00000000000004,1.0
"def _calculate_runtimes(states):<tab>results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0}<tab>for state, resultset in states.items():<tab><tab><IF-STMT><tab><tab><tab># Count the pass vs failures<tab><tab><tab>if resultset[""result""]:<tab><tab><tab><tab>results[""num_passed_states""] += 1<tab><tab><tab>else:<tab><tab><tab><tab>results[""num_failed_states""] += 1<tab><tab><tab># Count durations<tab><tab><tab>results[""runtime""] += resultset[""duration""]<tab>log.debug(""Parsed state metrics: {}"".format(results))<tab>return results",0,"if isinstance ( resultset , dict ) and ""duration"" in resultset :","if resultset [ ""state"" ] == state :",0.01198879490978343,4.2665050358928855,0.2142857142857143
"def _replicator_primary_device() -> snt_replicator.Replicator:<tab># NOTE: The explicit device list is required since currently Replicator<tab># only considers CPU and GPU devices. This means on TPU by default we only<tab># mirror on the local CPU.<tab>for device_type in (""TPU"", ""GPU"", ""CPU""):<tab><tab>devices = tf.config.experimental.list_logical_devices(device_type=device_type)<tab><tab><IF-STMT><tab><tab><tab>devices = [d.name for d in devices]<tab><tab><tab>logging.info(""Replicating over %s"", devices)<tab><tab><tab>return snt_replicator.Replicator(devices=devices)<tab>assert False, ""No TPU/GPU or CPU found""",1,if devices :,if devices :,0.5311706625951745,1e-10,1.0
"def get_tag_values(self, event):<tab>http = event.interfaces.get(""sentry.interfaces.Http"")<tab>if not http:<tab><tab>return []<tab>if not http.headers:<tab><tab>return []<tab>headers = http.headers<tab># XXX: transitional support for workers<tab>if isinstance(headers, dict):<tab><tab>headers = headers.items()<tab>output = []<tab>for key, value in headers:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ua = Parse(value)<tab><tab>if not ua:<tab><tab><tab>continue<tab><tab>result = self.get_tag_from_ua(ua)<tab><tab>if result:<tab><tab><tab>output.append(result)<tab>return output",0,"if key != ""User-Agent"" :","if key . lower ( ) != ""content-type"" :",0.04975840882008457,18.52797255583095,0.7307692307692308
"def general(metadata, value):<tab>if metadata.get(""commands"") and value:<tab><tab><IF-STMT><tab><tab><tab>v = quote(value)<tab><tab>else:<tab><tab><tab>v = value<tab><tab>return u""{0} {1}"".format(metadata[""commands""][0], v)<tab>else:<tab><tab>if not value:<tab><tab><tab>return None<tab><tab>elif not metadata.get(""nargs""):<tab><tab><tab>return quote(value)<tab><tab>else:<tab><tab><tab>return value",1,"if not metadata . get ( ""nargs"" ) :","if not metadata . get ( ""nargs"" ) :",0.75,100.00000000000004,1.0
"def _actions_read(self, c):<tab>self.action_input.handle_read(c)<tab>if c in [curses.KEY_ENTER, util.KEY_ENTER2]:<tab><tab># take action<tab><tab>if self.action_input.selected_index == 0:  # Cancel<tab><tab><tab>self.back_to_parent()<tab><tab>elif self.action_input.selected_index == 1:  # Apply<tab><tab><tab>self._apply_prefs()<tab><tab><tab>client.core.get_config().addCallback(self._update_preferences)<tab><tab><IF-STMT>  # OK<tab><tab><tab>self._apply_prefs()<tab><tab><tab>self.back_to_parent()",1,elif self . action_input . selected_index == 2 :,elif self . action_input . selected_index == 2 :,1.0,100.00000000000004,1.0
def logic():<tab>if reset == 1:<tab><tab>lfsr.next = 1<tab>else:<tab><tab><IF-STMT><tab><tab><tab># lfsr.next[24:1] = lfsr[23:0]<tab><tab><tab>lfsr.next = lfsr << 1<tab><tab><tab>lfsr.next[0] = lfsr[23] ^ lfsr[22] ^ lfsr[21] ^ lfsr[16],0,if enable :,if reset == 0 :,0.051944022748897464,1e-10,0.36
"def action_delete(self, request, attachments):<tab>deleted_attachments = []<tab>desynced_posts = []<tab>for attachment in attachments:<tab><tab><IF-STMT><tab><tab><tab>deleted_attachments.append(attachment.pk)<tab><tab><tab>desynced_posts.append(attachment.post_id)<tab>if desynced_posts:<tab><tab>with transaction.atomic():<tab><tab><tab>for post in Post.objects.filter(id__in=desynced_posts):<tab><tab><tab><tab>self.delete_from_cache(post, deleted_attachments)<tab>for attachment in attachments:<tab><tab>attachment.delete()<tab>message = _(""Selected attachments have been deleted."")<tab>messages.success(request, message)",0,if attachment . post :,if attachment . pk :,0.39477865547525276,42.72870063962342,0.6
"def __getitem__(self, index):<tab>if self._check():<tab><tab>if isinstance(index, int):<tab><tab><tab>if index < 0 or index >= len(self.features):<tab><tab><tab><tab>raise IndexError(index)<tab><tab><tab>if self.features[index] is None:<tab><tab><tab><tab>feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index)<tab><tab><tab><tab>if feature:<tab><tab><tab><tab><tab>(feature,) = _unpack(""!H"", feature[:2])<tab><tab><tab><tab><tab>self.features[index] = FEATURE[feature]<tab><tab><tab>return self.features[index]<tab><tab><IF-STMT><tab><tab><tab>indices = index.indices(len(self.features))<tab><tab><tab>return [self.__getitem__(i) for i in range(*indices)]",0,"elif isinstance ( index , slice ) :",elif self . features [ index ] is not None :,0.06534098432178827,4.9323515694897075,0.17272727272727273
"def _skip_start(self):<tab>start, stop = self.start, self.stop<tab>for chunk in self.app_iter:<tab><tab>self._pos += len(chunk)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif self._pos == start:<tab><tab><tab>return b""""<tab><tab>else:<tab><tab><tab>chunk = chunk[start - self._pos :]<tab><tab><tab>if stop is not None and self._pos > stop:<tab><tab><tab><tab>chunk = chunk[: stop - self._pos]<tab><tab><tab><tab>assert len(chunk) == stop - start<tab><tab><tab>return chunk<tab>else:<tab><tab>raise StopIteration()",1,if self . _pos < start :,if self . _pos < start :,0.75,100.00000000000004,1.0
"def get_files(d):<tab>f = []<tab>for root, dirs, files in os.walk(d):<tab><tab>for name in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if ""qemux86copy-"" in root or ""qemux86-"" in root:<tab><tab><tab><tab>continue<tab><tab><tab>if ""do_build"" not in name and ""do_populate_sdk"" not in name:<tab><tab><tab><tab>f.append(os.path.join(root, name))<tab>return f",0,"if ""meta-environment"" in root or ""cross-canadian"" in root :","if ""qemux86"" in root or ""qemux86"" in root :",0.6048262086007482,52.664038784792666,1.0
"def _load_windows_store_certs(self, storename, purpose):<tab>certs = bytearray()<tab>try:<tab><tab>for cert, encoding, trust in enum_certificates(storename):<tab><tab><tab># CA certs are never PKCS#7 encoded<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if trust is True or purpose.oid in trust:<tab><tab><tab><tab><tab>certs.extend(cert)<tab>except PermissionError:<tab><tab>warnings.warn(""unable to enumerate Windows certificate store"")<tab>if certs:<tab><tab>self.load_verify_locations(cadata=certs)<tab>return certs",0,"if encoding == ""x509_asn"" :",if len ( cert ) > 0 :,0.026407399022921448,5.11459870708889,0.3
"def test_tokenizer_identifier_with_correct_config(self):<tab>for tokenizer_class in [BertTokenizer, BertTokenizerFast, AutoTokenizer]:<tab><tab>tokenizer = tokenizer_class.from_pretrained(""wietsedv/bert-base-dutch-cased"")<tab><tab>self.assertIsInstance(tokenizer, (BertTokenizer, BertTokenizerFast))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(tokenizer.basic_tokenizer.do_lower_case, False)<tab><tab>else:<tab><tab><tab>self.assertEqual(tokenizer.do_lower_case, False)<tab><tab>self.assertEqual(tokenizer.model_max_length, 512)",0,"if isinstance ( tokenizer , BertTokenizer ) :",if tokenizer . basic_tokenizer is not None :,0.019345087832959386,5.522397783539471,0.23214285714285715
"def run(self):<tab>global WAITING_BEFORE_START<tab>time.sleep(WAITING_BEFORE_START)<tab>while self.keep_alive:<tab><tab>path_id, module, resolve = self.queue_receive.get()<tab><tab>if path_id is None:<tab><tab><tab>continue<tab><tab>self.lock.acquire()<tab><tab>self.modules[path_id] = module<tab><tab>self.lock.release()<tab><tab><IF-STMT><tab><tab><tab>resolution = self._resolve_with_other_modules(resolve)<tab><tab><tab>self._relations[path_id] = []<tab><tab><tab>for package in resolution:<tab><tab><tab><tab>self._relations[path_id].append(resolution[package])<tab><tab><tab>self.queue_send.put((path_id, module, False, resolution))",1,if resolve :,if resolve :,0.5311706625951745,1e-10,1.0
"def __new__(mcs, name, bases, attrs):<tab>include_profile = include_trace = include_garbage = True<tab>bases = list(bases)<tab>if name == ""SaltLoggingClass"":<tab><tab>for base in bases:<tab><tab><tab>if hasattr(base, ""trace""):<tab><tab><tab><tab>include_trace = False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>include_garbage = False<tab>if include_profile:<tab><tab>bases.append(LoggingProfileMixin)<tab>if include_trace:<tab><tab>bases.append(LoggingTraceMixin)<tab>if include_garbage:<tab><tab>bases.append(LoggingGarbageMixin)<tab>return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)",1,"if hasattr ( base , ""garbage"" ) :","if hasattr ( base , ""garbage"" ) :",0.75,100.00000000000004,1.0
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_owner_:<tab><tab>res += prefix + (""owner: %s\n"" % self.DebugFormatString(self.owner_))<tab>cnt = 0<tab>for e in self.entries_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""entries%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>return res",1,if printElemNumber :,if printElemNumber :,0.5311706625951745,1e-10,1.0
"def parse_tag(self):<tab>buf = []<tab>escaped = False<tab>for c in self.get_next_chars():<tab><tab>if escaped:<tab><tab><tab>buf.append(c)<tab><tab>elif c == ""\\"":<tab><tab><tab>escaped = True<tab><tab><IF-STMT><tab><tab><tab>return """".join(buf)<tab><tab>else:<tab><tab><tab>buf.append(c)<tab>raise Exception(""Unclosed tag "" + """".join(buf))",0,"elif c == "">"" :","elif c == ""\\"" :",0.6428720214849399,51.33450480401705,1.0
"def get_batches(train_nodes, train_labels, batch_size=64, shuffle=True):<tab>if shuffle:<tab><tab>random.shuffle(train_nodes)<tab>total = train_nodes.shape[0]<tab>for i in range(0, total, batch_size):<tab><tab><IF-STMT><tab><tab><tab>cur_nodes = train_nodes[i : i + batch_size]<tab><tab><tab>cur_labels = train_labels[cur_nodes]<tab><tab><tab>yield cur_nodes, cur_labels",0,if i + batch_size <= total :,if i + batch_size < total :,0.24627283061723432,71.89393375176813,1.0
"def _get_all_info_lines(data):<tab>infos = []<tab>for row in data:<tab><tab>splitrow = row.split()<tab><tab>if len(splitrow) > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>infos.append("" "".join(splitrow[1:]))<tab>return infos",0,"if splitrow [ 0 ] == ""INFO:"" :","if splitrow [ 0 ] == ""info"" :",0.605621305873661,67.74702029865007,1.0
"def _validate_client_public_key(self, username, key_data):<tab>""""""Validate a client public key for the specified user""""""<tab>try:<tab><tab>key = decode_ssh_public_key(key_data)<tab>except KeyImportError:<tab><tab>return None<tab>options = None<tab>if self._client_keys:<tab><tab>options = self._client_keys.validate(key, self._peer_addr)<tab>if options is None:<tab><tab>result = self._owner.validate_public_key(username, key)<tab><tab>if asyncio.iscoroutine(result):<tab><tab><tab>result = yield from result<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>options = {}<tab>self._key_options = options<tab>return key",1,if not result :,if not result :,0.75,100.00000000000004,1.0
"def attach_related_versions(addons, addon_dict=None):<tab>if addon_dict is None:<tab><tab>addon_dict = {addon.id: addon for addon in addons}<tab>all_ids = set(filter(None, (addon._current_version_id for addon in addons)))<tab>versions = list(Version.objects.filter(id__in=all_ids).order_by())<tab>for version in versions:<tab><tab>try:<tab><tab><tab>addon = addon_dict[version.addon_id]<tab><tab>except KeyError:<tab><tab><tab>log.info(""Version %s has an invalid add-on id."" % version.id)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>addon._current_version = version<tab><tab>version.addon = addon",0,if addon . _current_version_id == version . id :,if addon . _current_version is None :,0.13008931074158556,40.06940865888289,0.42857142857142855
"def move_view(obj, evt):<tab>position = obj.GetCurrentCursorPosition()<tab>for other_axis, axis_number in self._axis_names.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ipw3d = getattr(self, ""ipw_3d_%s"" % other_axis)<tab><tab>ipw3d.ipw.slice_position = position[axis_number]",0,if other_axis == axis_name :,if axis_number not in position :,0.030286782520570012,10.229197414177778,0.3142857142857143
"def func_wrapper(*args, **kwargs):<tab>warnings.simplefilter(""always"", DeprecationWarning)  # turn off filter<tab>for old, new in arg_mapping.items():<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>f""Keyword argument '{old}' has been ""<tab><tab><tab><tab>f""deprecated in favour of '{new}'. ""<tab><tab><tab><tab>f""'{old}' will be removed in a future version."",<tab><tab><tab><tab>category=DeprecationWarning,<tab><tab><tab><tab>stacklevel=2,<tab><tab><tab>)<tab><tab><tab>val = kwargs.pop(old)<tab><tab><tab>kwargs[new] = val<tab># reset filter<tab>warnings.simplefilter(""default"", DeprecationWarning)<tab>return func(*args, **kwargs)",1,if old in kwargs :,if old in kwargs :,0.75,100.00000000000004,1.0
"def inner_connection_checker(self, *args, **kwargs):<tab>LOG.debug(""in _connection_checker"")<tab>for attempts in range(5):<tab><tab>try:<tab><tab><tab>return func(self, *args, **kwargs)<tab><tab>except exception.VolumeBackendAPIException as e:<tab><tab><tab>pattern = re.compile(r"".*Session id expired$"")<tab><tab><tab>matches = pattern.match(six.text_type(e))<tab><tab><tab>if matches:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>LOG.debug(""Session might have expired."" "" Trying to relogin"")<tab><tab><tab><tab><tab>self._login()<tab><tab><tab><tab><tab>continue<tab><tab><tab>LOG.error(""Re-throwing Exception %s"", e)<tab><tab><tab>raise",0,if attempts < 4 :,if matches [ 1 ] [ 0 ] == attempts :,0.02506468314974991,4.456882760699063,0.2653061224489796
"def set(self, pcount):<tab>""""""Set channel prefetch_count setting.""""""<tab>if pcount != self.prev:<tab><tab>new_value = pcount<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""QoS: Disabled: prefetch_count exceeds %r"", PREFETCH_COUNT_MAX<tab><tab><tab>)<tab><tab><tab>new_value = 0<tab><tab>logger.debug(""basic.qos: prefetch_count->%s"", new_value)<tab><tab>self.callback(prefetch_count=new_value)<tab><tab>self.prev = pcount<tab>return pcount",0,if pcount > PREFETCH_COUNT_MAX :,if new_value > PREFETCH_COUNT_MAX :,0.39477865547525276,59.00468726392806,0.6190476190476191
"def _build_gcs_object_key(self, key):<tab>if self.platform_specific_separator:<tab><tab><IF-STMT><tab><tab><tab>gcs_object_key = os.path.join(<tab><tab><tab><tab>self.prefix, self._convert_key_to_filepath(key)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>gcs_object_key = self._convert_key_to_filepath(key)<tab>else:<tab><tab>if self.prefix:<tab><tab><tab>gcs_object_key = ""/"".join((self.prefix, self._convert_key_to_filepath(key)))<tab><tab>else:<tab><tab><tab>gcs_object_key = self._convert_key_to_filepath(key)<tab>return gcs_object_key",1,if self . prefix :,if self . prefix :,0.75,100.00000000000004,1.0
"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab><IF-STMT><tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in self.unops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)",1,if name not in skip :,if name not in skip :,0.75,100.00000000000004,1.0
def isCurveMonotonic(set_):<tab>for i in range(len(set_) - 1):<tab><tab># ==== added by zli =======<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab># ==== added by zli =======<tab><tab># ==== added by zli =======<tab><tab># if set_[i][1] > set_[i + 1][1]:<tab><tab>if set_[i][1] >= set_[i + 1][1]:<tab><tab><tab># ==== added by zli =======<tab><tab><tab>return False<tab>return True,0,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,if set_ [ i ] [ 1 ] <= set_ [ i + 1 ] [ 1 ] :,0.8014582419870431,66.43548861507487,0.7
"def show_topics():<tab>""""""prints all available miscellaneous help topics.""""""<tab>print(_stash.text_color(""Miscellaneous Topics:"", ""yellow""))<tab>for pp in PAGEPATHS:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>content = os.listdir(pp)<tab><tab>for pn in content:<tab><tab><tab>if ""."" in pn:<tab><tab><tab><tab>name = pn[: pn.index(""."")]<tab><tab><tab>else:<tab><tab><tab><tab>name = pn<tab><tab><tab>print(name)",1,if not os . path . isdir ( pp ) :,if not os . path . isdir ( pp ) :,0.75,100.00000000000004,1.0
"def test_send_error(self):<tab>allow_transfer_encoding_codes = (205, 304)<tab>for code in (101, 102, 204, 205, 304):<tab><tab>self.con.request(""SEND_ERROR"", ""/{}"".format(code))<tab><tab>res = self.con.getresponse()<tab><tab>self.assertEqual(code, res.status)<tab><tab>self.assertEqual(None, res.getheader(""Content-Length""))<tab><tab>self.assertEqual(None, res.getheader(""Content-Type""))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(None, res.getheader(""Transfer-Encoding""))<tab><tab>data = res.read()<tab><tab>self.assertEqual(b"""", data)",0,if code not in allow_transfer_encoding_codes :,if code in allow_transfer_encoding_codes :,0.23319028329115196,77.72460244048297,0.5599999999999999
"def _length_hint(obj):<tab>""""""Returns the length hint of an object.""""""<tab>try:<tab><tab>return len(obj)<tab>except (AttributeError, TypeError):<tab><tab>try:<tab><tab><tab>get_hint = type(obj).__length_hint__<tab><tab>except AttributeError:<tab><tab><tab>return None<tab><tab>try:<tab><tab><tab>hint = get_hint(obj)<tab><tab>except TypeError:<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return hint",0,"if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 :",if hint is None :,0.16009580403291257,2.5983349617896914,0.31315789473684214
"def _rmtree(self, path):<tab># Essentially a stripped down version of shutil.rmtree.  We can't<tab># use globals because they may be None'ed out at shutdown.<tab>for name in self._listdir(path):<tab><tab>fullname = self._path_join(path, name)<tab><tab>try:<tab><tab><tab>isdir = self._isdir(fullname)<tab><tab>except self._os_error:<tab><tab><tab>isdir = False<tab><tab><IF-STMT><tab><tab><tab>self._rmtree(fullname)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>self._remove(fullname)<tab><tab><tab>except self._os_error:<tab><tab><tab><tab>pass<tab>try:<tab><tab>self._rmdir(path)<tab>except self._os_error:<tab><tab>pass",1,if isdir :,if isdir :,0.5311706625951745,1e-10,1.0
"def get_sources(self, sources=None):<tab>""""""Returns all sources from this provider.""""""<tab>self._load()<tab>if sources is None:<tab><tab>sources = list(self.data.keys())<tab>elif not isinstance(sources, (list, tuple)):<tab><tab>sources = [sources]<tab>for source in sources:<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(<tab><tab><tab><tab>""Invalid data key: {}. Valid keys are: {}"".format(<tab><tab><tab><tab><tab>source, "", "".join(str(k) for k in self.data)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return {k: self.data[k] for k in sources}",1,if source not in self . data :,if source not in self . data :,0.75,100.00000000000004,1.0
"def do_shorts(<tab>opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str]) -> Tuple[List[Tuple[str, str]], List[str]]:<tab>while optstring != """":<tab><tab>opt, optstring = optstring[0], optstring[1:]<tab><tab>if short_has_arg(opt, shortopts):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not args:<tab><tab><tab><tab><tab>raise GetoptError(""option -%s requires argument"" % opt, opt)<tab><tab><tab><tab>optstring, args = args[0], args[1:]<tab><tab><tab>optarg, optstring = optstring, """"<tab><tab>else:<tab><tab><tab>optarg = """"<tab><tab>opts.append((""-"" + opt, optarg))<tab>return opts, args",1,"if optstring == """" :","if optstring == """" :",0.75,100.00000000000004,1.0
"def _sanitize_dict(self, config_dict, allow_val_change=None, ignore_keys: set = None):<tab>sanitized = {}<tab>for k, v in six.iteritems(config_dict):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>k, v = self._sanitize(k, v, allow_val_change)<tab><tab>sanitized[k] = v<tab>return sanitized",0,if ignore_keys and k in ignore_keys :,if k in ignore_keys :,0.23093026462960747,47.486944442513455,0.37142857142857144
def x(data):<tab>count = 0<tab>while count < 10:<tab><tab>data.start_example(SOME_LABEL)<tab><tab>b = data.draw_bits(1)<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>data.stop_example(discard=not b)<tab>data.mark_interesting(),0,if b :,if not b :,0.11348623737539229,1e-10,0.41666666666666663
"def prompt_for_resume(config):<tab>logger = logging.getLogger(""changeme"")<tab>logger.error(<tab><tab>""A previous scan was interrupted. Type R to resume or F to start a fresh scan""<tab>)<tab>answer = """"<tab>while not (answer == ""R"" or answer == ""F""):<tab><tab>prompt = ""(R/F)> ""<tab><tab>answer = """"<tab><tab>try:<tab><tab><tab>answer = raw_input(prompt)<tab><tab>except NameError:<tab><tab><tab>answer = input(prompt)<tab><tab>if answer.upper() == ""F"":<tab><tab><tab>logger.debug(""Forcing a fresh scan"")<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Resuming previous scan"")<tab><tab><tab>config.resume = True<tab>return config.resume",1,"elif answer . upper ( ) == ""R"" :","elif answer . upper ( ) == ""R"" :",0.75,100.00000000000004,1.0
"def _evaluate_local_single(self, iterator):<tab>for batch in iterator:<tab><tab>in_arrays = convert._call_converter(self.converter, batch, self.device)<tab><tab>with function.no_backprop_mode():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results = self.calc_local(*in_arrays)<tab><tab><tab>elif isinstance(in_arrays, dict):<tab><tab><tab><tab>results = self.calc_local(**in_arrays)<tab><tab><tab>else:<tab><tab><tab><tab>results = self.calc_local(in_arrays)<tab><tab>if self._progress_hook:<tab><tab><tab>self._progress_hook(batch)<tab><tab>yield results",0,"if isinstance ( in_arrays , tuple ) :","if isinstance ( in_arrays , list ) :",0.5490406812970063,70.71067811865478,0.6
"def _send_until_done(self, data):<tab>while True:<tab><tab>try:<tab><tab><tab>return self.connection.send(data)<tab><tab>except OpenSSL.SSL.WantWriteError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise timeout()<tab><tab><tab>continue<tab><tab>except OpenSSL.SSL.SysCallError as e:<tab><tab><tab>raise SocketError(str(e))",0,"if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :",if self . timeout is not None :,0.08357226831059397,2.1298083743436025,0.19166666666666665
"def _read_jtl_chunk(self, jtl):<tab>data = jtl.read(1024 * 1024 * 10)<tab>if data:<tab><tab>parts = data.rsplit(""\n"", 1)<tab><tab><IF-STMT><tab><tab><tab>ready_chunk = self.buffer + parts[0] + ""\n""<tab><tab><tab>self.buffer = parts[1]<tab><tab><tab>df = string_to_df(ready_chunk)<tab><tab><tab>self.stat_queue.put(df)<tab><tab><tab>return df<tab><tab>else:<tab><tab><tab>self.buffer += parts[0]<tab>else:<tab><tab>if self.jmeter_finished:<tab><tab><tab>self.agg_finished = True<tab><tab>jtl.readline()<tab>return None",0,if len ( parts ) > 1 :,if len ( parts ) == 2 :,0.5241515189640744,46.713797772819994,0.6666666666666666
"def __new__(mcl, classname, bases, dictionary):<tab>slots = list(dictionary.get(""__slots__"", []))<tab>for getter_name in [key for key in dictionary if key.startswith(""get_"")]:<tab><tab>name = getter_name<tab><tab>slots.append(""__"" + name)<tab><tab>getter = dictionary.pop(getter_name)<tab><tab>setter = dictionary.get(setter_name, None)<tab><tab><IF-STMT><tab><tab><tab>del dictionary[setter_name]<tab><tab>dictionary[name] = property(getter.setter)<tab><tab>dictionary[""__slots__""] = tuple(slots)<tab><tab>return super().__new__(mcl, classname, bases, dictionary)",0,"if setter is not None and isinstance ( setter , collections . Callable ) :",if getter is None :,0.1441729990365241,2.044493475827058,0.23863636363636365
"def tex_coords(self):<tab>""""""Array of texture coordinate data.""""""<tab>if ""multi_tex_coords"" not in self.domain.attribute_names:<tab><tab><IF-STMT><tab><tab><tab>domain = self.domain<tab><tab><tab>attribute = domain.attribute_names[""tex_coords""]<tab><tab><tab>self._tex_coords_cache = attribute.get_region(<tab><tab><tab><tab>attribute.buffer, self.start, self.count<tab><tab><tab>)<tab><tab><tab>self._tex_coords_cache_version = domain._version<tab><tab>region = self._tex_coords_cache<tab><tab>region.invalidate()<tab><tab>return region.array<tab>else:<tab><tab>return None",0,if self . _tex_coords_cache_version != self . domain . _version :,if self . _tex_coords_cache is None :,0.10238255554306046,37.44131164809384,0.4444444444444444
"def index(self, sub, start=0):<tab>""""""Returns the index of the closing bracket""""""<tab>br = ""([{<""["")]}>"".index(sub)]<tab>count = 0<tab>for i in range(start, len(self.string)):<tab><tab>char = self.string[i]<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>elif char == sub:<tab><tab><tab>if count > 0:<tab><tab><tab><tab>count -= 1<tab><tab><tab>else:<tab><tab><tab><tab>return i<tab>err = ""Closing bracket {!r} missing in string {!r}"".format(<tab><tab>sub, """".join(self.original)<tab>)<tab>raise ParseError(err)",0,if char == br :,if char in br :,0.1443059992830803,24.736929544091932,0.5333333333333333
"def test_createFile(self):<tab>text = ""This is a test!""<tab>path = tempfile.mktemp()<tab>try:<tab><tab>koDoc = self._koDocFromPath(path, load=False)<tab><tab>koDoc.buffer = text<tab><tab>koDoc.save(0)<tab><tab>del koDoc<tab><tab>koDoc2 = self._koDocFromPath(path)<tab><tab>assert koDoc2.buffer == text<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(path)  # clean up",1,if os . path . exists ( path ) :,if os . path . exists ( path ) :,1.0,100.00000000000004,1.0
"def __editScopeHasEdit(self, attributeHistory):<tab>with attributeHistory.context:<tab><tab>tweak = GafferScene.EditScopeAlgo.acquireParameterEdit(<tab><tab><tab>attributeHistory.scene.node(),<tab><tab><tab>attributeHistory.context[""scene:path""],<tab><tab><tab>attributeHistory.attributeName,<tab><tab><tab>IECoreScene.ShaderNetwork.Parameter("""", self.__parameter),<tab><tab><tab>createIfNecessary=False,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>return tweak[""enabled""].getValue()",0,if tweak is None :,"if ""enabled"" not in tweak :",0.15729470354711872,7.267884212102741,0.2857142857142857
"def mail_migrator(app, schema_editor):<tab>Event_SettingsStore = app.get_model(""pretixbase"", ""Event_SettingsStore"")<tab>for ss in Event_SettingsStore.objects.filter(<tab><tab>key__in=[<tab><tab><tab>""mail_text_order_approved"",<tab><tab><tab>""mail_text_order_placed"",<tab><tab><tab>""mail_text_order_placed_require_approval"",<tab><tab>]<tab>):<tab><tab>chgd = ss.value.replace(""{date}"", ""{expire_date}"")<tab><tab><IF-STMT><tab><tab><tab>ss.value = chgd<tab><tab><tab>ss.save()<tab><tab><tab>cache.delete(""hierarkey_{}_{}"".format(""event"", ss.object_id))",0,if chgd != ss . value :,if chgd :,0.03885753308224148,1e-10,0.55
"def __get_limits(self):<tab>dimension = len(self.__tree.get_root().data)<tab>nodes = self.__get_all_nodes()<tab>max, min = [float(""-inf"")] * dimension, [float(""+inf"")] * dimension<tab>for node in nodes:<tab><tab>for d in range(dimension):<tab><tab><tab>if max[d] < node.data[d]:<tab><tab><tab><tab>max[d] = node.data[d]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>min[d] = node.data[d]<tab>return min, max",1,if min [ d ] > node . data [ d ] :,if min [ d ] > node . data [ d ] :,1.0,100.00000000000004,1.0
"def get_complete_position(self, context: UserContext) -> int:<tab># Check member prefix pattern.<tab>for prefix_pattern in convert2list(<tab><tab>self.get_filetype_var(context[""filetype""], ""prefix_patterns"")<tab>):<tab><tab>m = re.search(self._object_pattern + prefix_pattern + r""\w*$"", context[""input""])<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._prefix = re.sub(r""\w*$"", """", m.group(0))<tab><tab>m = re.search(r""\w*$"", context[""input""])<tab><tab>if m:<tab><tab><tab>return m.start()<tab>return -1",0,"if m is None or prefix_pattern == """" :",if not m :,0.016468505645792976,2.215745752614824,0.2571428571428572
"def _stderr_supports_color():<tab>try:<tab><tab>if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty():<tab><tab><tab>if curses:<tab><tab><tab><tab>curses.setupterm()<tab><tab><tab><tab>if curses.tigetnum(""colors"") > 0:<tab><tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if sys.stderr is getattr(<tab><tab><tab><tab><tab>colorama.initialise, ""wrapped_stderr"", object()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>return True<tab>except Exception:<tab><tab># Very broad exception handling because it's always better to<tab><tab># fall back to non-colored logs than to break at startup.<tab><tab>pass<tab>return False",1,elif colorama :,elif colorama :,0.5143161313935813,1e-10,1.0
"def setLabelColumnWidth(self, panel, width):<tab>for child in panel.GetChildren():<tab><tab><IF-STMT><tab><tab><tab>size = child.GetSize()<tab><tab><tab>size[0] = width<tab><tab><tab>child.SetBestSize(size)",0,"if isinstance ( child , wx . lib . stattext . GenStaticText ) :","if hasattr ( child , ""GetSize"" ) and child . GetSize ( ) > width :",0.04177722485789183,9.880782578056978,0.2222222222222222
"def update(self, other):<tab>if other.M is None:<tab><tab><IF-STMT><tab><tab><tab>self.items.update(other.items)<tab><tab>else:<tab><tab><tab>for i in other.items:<tab><tab><tab><tab>self.add(i)<tab><tab>return<tab>if self.M is None:<tab><tab>self.convert()<tab>self.M = array.array(""B"", list(map(max, list(zip(self.M, other.M)))))",0,if self . M is None :,"if isinstance ( other . items , list ) :",0.018941002751756135,5.522397783539471,0.2
"def on_end_epoch(self, state):<tab>if self.write_epoch_metrics:<tab><tab><IF-STMT><tab><tab><tab>self.writer.add_text(<tab><tab><tab><tab>""epoch"",<tab><tab><tab><tab>""<h4>Epoch {}</h4>"".format(state[torchbearer.EPOCH])<tab><tab><tab><tab>+ self.table_formatter(str(state[torchbearer.METRICS])),<tab><tab><tab><tab>1,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.writer.add_text(<tab><tab><tab><tab>""epoch"",<tab><tab><tab><tab>self.table_formatter(str(state[torchbearer.METRICS])),<tab><tab><tab><tab>state[torchbearer.EPOCH],<tab><tab><tab>)",0,if self . visdom :,if state [ torchbearer . EPOCH ] :,0.028001459970687266,7.267884212102741,0.2698412698412698
"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool:<tab>""""""Check if the conversation is in need for a user message.""""""<tab>tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED)<tab>for i, e in enumerate(reversed(tracker.get(""events"", []))):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>elif e.get(""event"") == ActionExecuted.type_name:<tab><tab><tab>return e.get(""name"") == ACTION_LISTEN_NAME<tab>return False",0,"if e . get ( ""event"" ) == UserUttered . type_name :","if e . get ( ""event"" ) == ActionExecuted . type_unknown :",0.5761951180754087,70.85876411943929,0.6666666666666666
"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None):<tab>assert nw_id != self.nw_id_unknown<tab>ret = []<tab>for port in self.get_ports(dpid):<tab><tab>nw_id_ = port.network_id<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if nw_id_ == nw_id:<tab><tab><tab>ret.append(port.port_no)<tab><tab>elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external:<tab><tab><tab>ret.append(port.port_no)<tab>return ret",0,if port . port_no == in_port :,if in_port is not None and nw_id_ != in_port :,0.03368239519893852,22.61216470320596,0.25274725274725274
"def next_month(billing_cycle_anchor: datetime, dt: datetime) -> datetime:<tab>estimated_months = round((dt - billing_cycle_anchor).days * 12.0 / 365)<tab>for months in range(max(estimated_months - 1, 0), estimated_months + 2):<tab><tab>proposed_next_month = add_months(billing_cycle_anchor, months)<tab><tab><IF-STMT><tab><tab><tab>return proposed_next_month<tab>raise AssertionError(<tab><tab>""Something wrong in next_month calculation with ""<tab><tab>f""billing_cycle_anchor: {billing_cycle_anchor}, dt: {dt}""<tab>)",0,if 20 < ( proposed_next_month - dt ) . days < 40 :,if proposed_next_month :,0.007241875771263273,1e-10,0.3
"def wait_complete(self):<tab>""""""Wait for futures complete done.""""""<tab>for future in concurrent.futures.as_completed(self._futures.keys()):<tab><tab>try:<tab><tab><tab>error = future.exception()<tab><tab>except concurrent.futures.CancelledError:<tab><tab><tab>break<tab><tab>name = self._futures[future]<tab><tab><IF-STMT><tab><tab><tab>err_msg = 'Extracting ""{0}"", got: {1}'.format(name, error)<tab><tab><tab>logger.error(err_msg)",0,if error is not None :,if error :,0.050438393472541504,1e-10,0.39999999999999997
"def _accept_with(cls, orm, target):<tab>if target is orm.mapper:<tab><tab>return mapperlib.Mapper<tab>elif isinstance(target, type):<tab><tab>if issubclass(target, mapperlib.Mapper):<tab><tab><tab>return target<tab><tab>else:<tab><tab><tab>mapper = _mapper_or_none(target)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return mapper<tab><tab><tab>else:<tab><tab><tab><tab>return _MapperEventsHold(target)<tab>else:<tab><tab>return target",1,if mapper is not None :,if mapper is not None :,0.75,100.00000000000004,1.0
"def gvariant_args(args: List[Any]) -> str:<tab>""""""Convert args into gvariant.""""""<tab>gvariant = """"<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>gvariant += "" {}"".format(str(arg).lower())<tab><tab>elif isinstance(arg, (int, float)):<tab><tab><tab>gvariant += f"" {arg}""<tab><tab>elif isinstance(arg, str):<tab><tab><tab>gvariant += f' ""{arg}""'<tab><tab>else:<tab><tab><tab>gvariant += f"" {arg!s}""<tab>return gvariant.lstrip()",0,"if isinstance ( arg , bool ) :","if isinstance ( arg , str ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def _list_cases(suite):<tab>for test in suite:<tab><tab>if isinstance(test, unittest.TestSuite):<tab><tab><tab>_list_cases(test)<tab><tab><IF-STMT><tab><tab><tab>if support.match_test(test):<tab><tab><tab><tab>print(test.id())",1,"elif isinstance ( test , unittest . TestCase ) :","elif isinstance ( test , unittest . TestCase ) :",0.75,100.00000000000004,1.0
def get_and_set_all_disambiguation(self):<tab>all_disambiguations = []<tab>for page in self.pages:<tab><tab><IF-STMT><tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links_norm)<tab><tab>if page.relations.disambiguation_links is not None:<tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links)<tab>return set(all_disambiguations),1,if page . relations . disambiguation_links_norm is not None :,if page . relations . disambiguation_links_norm is not None :,0.75,100.00000000000004,1.0
"def test_decode_invalid(self):<tab>testcases = [<tab><tab>(b""xn--w&"", ""strict"", UnicodeError()),<tab><tab>(b""xn--w&"", ""ignore"", ""xn-""),<tab>]<tab>for puny, errors, expected in testcases:<tab><tab>with self.subTest(puny=puny, errors=errors):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertRaises(UnicodeError, puny.decode, ""punycode"", errors)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(puny.decode(""punycode"", errors), expected)",0,"if isinstance ( expected , Exception ) :",if expected is None :,0.019907917998500824,7.715486568024961,0.2857142857142857
"def find_globs(walker, patterns, matches):<tab>for root, dirs, files in walker:<tab><tab>for d in dirs:<tab><tab><tab>d = join(root, d)<tab><tab><tab>for pattern in patterns:<tab><tab><tab><tab>for p in Path(d).glob(pattern):<tab><tab><tab><tab><tab>matches.add(str(p))<tab><tab>sub_files = set()<tab><tab>for p in matches:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for f in files:<tab><tab><tab><tab><tab>sub_files.add(join(root, f))<tab><tab>matches.update(sub_files)",0,if root . startswith ( p ) :,if p . is_file ( ) :,0.03976571592938584,12.549310621989482,0.36
"def parse_stack_trace(self, it, line):<tab>""""""Iterate over lines and parse stack traces.""""""<tab>events = []<tab>stack_traces = []<tab>while self.stack_trace_re.match(line):<tab><tab>event = self.parse_stack_trace_line(line)<tab><tab><IF-STMT><tab><tab><tab>events.append(event)<tab><tab>stack_traces.append(line)<tab><tab>line = get_next(it)<tab>events.reverse()<tab>return stack_traces, events, line",1,if event :,if event :,0.5311706625951745,1e-10,1.0
"def process(self):<tab>""""""Do processing necessary, storing result in feature.""""""<tab>summation = 0  # count of all<tab>histo = self.data[""flat.notes.quarterLengthHistogram""]<tab>if not histo:<tab><tab>raise NativeFeatureException(""input lacks notes"")<tab>maxKey = 0  # max found for any one key<tab>for key in histo:<tab><tab># all defined keys should be greater than zero, but just in case<tab><tab>if histo[key] > 0:<tab><tab><tab>summation += histo[key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>maxKey = histo[key]<tab>self.feature.vector[0] = maxKey / summation",0,if histo [ key ] >= maxKey :,if histo [ key ] > maxKey :,0.5490406812970063,67.5291821812656,1.0
"def load_resource(name):<tab>""""""return file contents for files within the package root folder""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return sublime.load_resource(""Packages/Markdown Preview/{0}"".format(name))<tab><tab>else:<tab><tab><tab>filename = os.path.join(<tab><tab><tab><tab>sublime.packages_path(), INSTALLED_DIRECTORY, os.path.normpath(name)<tab><tab><tab>)<tab><tab><tab>return load_utf8(filename)<tab>except:<tab><tab>print(""Error while load_resource('%s')"" % name)<tab><tab>traceback.print_exc()<tab><tab>return """"",0,if is_ST3 ( ) :,"if name . endswith ( "".py"" ) :",0.05214495056051539,8.913765521398126,0.45833333333333337
"def get_password(self, service, repo_url):<tab>if self.is_unlocked:<tab><tab>asyncio.set_event_loop(asyncio.new_event_loop())<tab><tab>collection = secretstorage.get_default_collection(self.connection)<tab><tab>attributes = {""application"": ""Vorta"", ""service"": service, ""repo_url"": repo_url}<tab><tab>items = list(collection.search_items(attributes))<tab><tab>logger.debug(""Found %i passwords matching repo URL."", len(items))<tab><tab><IF-STMT><tab><tab><tab>return items[0].get_secret().decode(""utf-8"")<tab>return None",0,if len ( items ) > 0 :,if len ( items ) == 1 :,0.5241515189640744,46.713797772819994,0.6666666666666666
"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab>if fname == ""output"":<tab><tab><tab>continue<tab><tab>if fname == ""PureMVC_Python_1_0"":<tab><tab><tab>continue<tab><tab>if fname[-4:] == "".pyc"":  # ehmm.. no.<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res",1,if os . path . isdir ( p ) :,if os . path . isdir ( p ) :,0.75,100.00000000000004,1.0
"def test_nic_names(self):<tab>p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE)<tab>out = p.communicate()[0]<tab>if PY3:<tab><tab>out = str(out, sys.stdout.encoding)<tab>nics = psutil.net_io_counters(pernic=True).keys()<tab>for nic in nics:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if nic not in out:<tab><tab><tab>self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)",0,"if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :","if nic == ""all"" :",0.00604053331867027,1.6260790483370455,0.3148148148148148
"def vexop_to_simop(op, extended=True, fp=True):<tab>res = operations.get(op)<tab>if res is None and extended:<tab><tab>attrs = op_attrs(op)<tab><tab><IF-STMT><tab><tab><tab>raise UnsupportedIROpError(""Operation not implemented"")<tab><tab>res = SimIROp(op, **attrs)<tab>if res is None:<tab><tab>raise UnsupportedIROpError(""Operation not implemented"")<tab>if res._float and not fp:<tab><tab>raise UnsupportedIROpError(""Floating point support disabled"")<tab>return res",1,if attrs is None :,if attrs is None :,0.75,100.00000000000004,1.0
"def rule_builder_add_value(self, value, screenshot_name=None):<tab>rule_builder = self.components.rule_builder<tab>rule_builder.menu_button_column.wait_for_and_click()<tab>with self.rule_builder_rule_editor(""add-column-value"") as editor_element:<tab><tab>filter_input = editor_element.find_element_by_css_selector(""input[type='text']"")<tab><tab>filter_input.clear()<tab><tab>filter_input.send_keys(value)<tab><tab><IF-STMT><tab><tab><tab>self.screenshot(screenshot_name)",1,if screenshot_name :,if screenshot_name :,0.5311706625951745,1e-10,1.0
"def make_open_socket(self):<tab>s = socket.socket()<tab>try:<tab><tab>s.bind(DEFAULT_BIND_ADDR_TUPLE)<tab><tab><IF-STMT><tab><tab><tab># Windows and linux (with psutil) doesn't show as open until<tab><tab><tab># we call listen (linux with lsof accepts either)<tab><tab><tab>s.listen(1)<tab><tab>self.assert_open(s, s.fileno())<tab>except:<tab><tab>s.close()<tab><tab>s = None<tab><tab>raise<tab>return s",0,if WIN or greentest . LINUX :,"if sys . platform == ""win32"" :",0.022864976965351443,5.522397783539471,0.20833333333333331
"def handle_ray_task_error(e):<tab>for s in e.traceback_str.split(""\n"")[::-1]:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>raise getattr(builtins, s.split("":"")[0])("""".join(s.split("":"")[1:]))<tab><tab><tab>except AttributeError as att_err:<tab><tab><tab><tab>if ""module"" in str(att_err) and builtins.__name__ in str(att_err):<tab><tab><tab><tab><tab>pass<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise att_err<tab>raise e",0,"if ""Error"" in s or ""Exception"" in s :","if "":"" in s :",0.06668418984860812,20.74856543476741,0.6
"def compare_multiple_events(i, expected_results, actual_results):<tab>events_in_a_row = []<tab>j = i<tab>while j < len(expected_results) and isinstance(<tab><tab>actual_results[j], actual_results[i].__class__<tab>):<tab><tab>events_in_a_row.append(actual_results[j])<tab><tab>j += 1<tab>message = """"<tab>for event in events_in_a_row:<tab><tab>for k in range(i, j):<tab><tab><tab>passed, message = compare_events(expected_results[k], event)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expected_results[k] = None<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return i, False, message<tab>return j, True, """"",0,if passed :,if not passed :,0.11348623737539229,1e-10,0.41666666666666663
"def ListSubscriptions(self, params):<tab>queryreturn = sqlQuery(""""""SELECT label, address, enabled FROM subscriptions"""""")<tab>data = '{""subscriptions"":['<tab>for row in queryreturn:<tab><tab>label, address, enabled = row<tab><tab>label = shared.fixPotentiallyInvalidUTF8Data(label)<tab><tab><IF-STMT><tab><tab><tab>data += "",""<tab><tab>data += json.dumps(<tab><tab><tab>{<tab><tab><tab><tab>""label"": label.encode(""base64""),<tab><tab><tab><tab>""address"": address,<tab><tab><tab><tab>""enabled"": enabled == 1,<tab><tab><tab>},<tab><tab><tab>indent=4,<tab><tab><tab>separators=("","", "": ""),<tab><tab>)<tab>data += ""]}""<tab>return data",0,if len ( data ) > 20 :,if data :,0.017267079824235865,1e-10,0.36
"def compile(self, args):<tab>compiled_args = {}<tab>for key, value in six.iteritems(args):<tab><tab><IF-STMT><tab><tab><tab>compiled_args[key] = str(value)<tab><tab>else:<tab><tab><tab>compiled_args[key] = sjson_dumps(value)<tab>return self._minified_code % compiled_args",0,if key in self . clean_args :,"if isinstance ( value , six . string_types ) :",0.018941002751756135,4.789232204309912,0.25
"def insert(self, pack_id, data):<tab>if (pack_id not in self.queue) and pack_id > self.begin_id:<tab><tab>self.queue[pack_id] = PacketInfo(data)<tab><tab>if self.end_id == pack_id:<tab><tab><tab>self.end_id = pack_id + 1<tab><tab><IF-STMT><tab><tab><tab>eid = self.end_id<tab><tab><tab>while eid < pack_id:<tab><tab><tab><tab>self.miss_queue.add(eid)<tab><tab><tab><tab>eid += 1<tab><tab><tab>self.end_id = pack_id + 1<tab><tab>else:<tab><tab><tab>self.miss_queue.remove(pack_id)",0,elif self . end_id < pack_id :,elif self . end_id > pack_id :,0.4944615112174505,70.16879391277372,1.0
"def _target_generator(self):<tab># since we do not have predictions yet, so we ignore sampling here<tab>if self._internal_target_generator is None:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>from ....model_zoo.ssd.target import SSDTargetGenerator<tab><tab>self._internal_target_generator = SSDTargetGenerator(<tab><tab><tab>iou_thresh=self._iou_thresh,<tab><tab><tab>stds=self._box_norm,<tab><tab><tab>negative_mining_ratio=-1,<tab><tab><tab>**self._kwargs<tab><tab>)<tab><tab>return self._internal_target_generator<tab>else:<tab><tab>return self._internal_target_generator",0,if self . _anchors_none :,if self . _iou_thresh == 0 :,0.11726065783135259,25.965358893403383,0.7222222222222222
"def test_heapsort(self):<tab># Exercise everything with repeated heapsort checks<tab>for trial in range(100):<tab><tab>size = random.randrange(50)<tab><tab>data = [random.randrange(25) for i in range(size)]<tab><tab><IF-STMT>  # Half of the time, use heapify<tab><tab><tab>heap = data[:]<tab><tab><tab>self.module.heapify(heap)<tab><tab>else:  # The rest of the time, use heappush<tab><tab><tab>heap = []<tab><tab><tab>for item in data:<tab><tab><tab><tab>self.module.heappush(heap, item)<tab><tab>heap_sorted = [self.module.heappop(heap) for i in range(size)]<tab><tab>self.assertEqual(heap_sorted, sorted(data))",0,if trial & 1 :,if trial == 0 :,0.31497877230811644,17.965205598154213,0.6
"def wait(self, timeout=None):<tab>if self.returncode is None:<tab><tab>if timeout is None:<tab><tab><tab>msecs = _subprocess.INFINITE<tab><tab>else:<tab><tab><tab>msecs = max(0, int(timeout * 1000 + 0.5))<tab><tab>res = _subprocess.WaitForSingleObject(int(self._handle), msecs)<tab><tab><IF-STMT><tab><tab><tab>code = _subprocess.GetExitCodeProcess(self._handle)<tab><tab><tab>if code == TERMINATE:<tab><tab><tab><tab>code = -signal.SIGTERM<tab><tab><tab>self.returncode = code<tab>return self.returncode",0,if res == _subprocess . WAIT_OBJECT_0 :,if res :,0.03885753308224148,1e-10,1.0
"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",1,elif value is None :,elif value is None :,0.75,100.00000000000004,1.0
"def isnotsurplus(self, item: T) -> bool:<tab>if not self.matchers:<tab><tab><IF-STMT><tab><tab><tab>self.mismatch_description.append_text(<tab><tab><tab><tab>""not matched: ""<tab><tab><tab>).append_description_of(item)<tab><tab>return False<tab>return True",1,if self . mismatch_description :,if self . mismatch_description :,0.75,100.00000000000004,1.0
"def resolve_env_secrets(config, environ):<tab>""""""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ""""""<tab>if isinstance(config, dict):<tab><tab><IF-STMT><tab><tab><tab>return environ.get(list(config.values())[0])<tab><tab>elif list(config.keys()) == [""$file""]:<tab><tab><tab>return open(list(config.values())[0]).read()<tab><tab>else:<tab><tab><tab>return {<tab><tab><tab><tab>key: resolve_env_secrets(value, environ)<tab><tab><tab><tab>for key, value in config.items()<tab><tab><tab>}<tab>elif isinstance(config, list):<tab><tab>return [resolve_env_secrets(value, environ) for value in config]<tab>else:<tab><tab>return config",1,"if list ( config . keys ( ) ) == [ ""$env"" ] :","if list ( config . keys ( ) ) == [ ""$env"" ] :",0.75,100.00000000000004,1.0
"def __open__(filename, *args, **kwargs):<tab>if os.path.isfile(filename):<tab><tab>return __realopen__(filename, *args, **kwargs)<tab>if not os.path.isabs(filename):<tab><tab>datafilename = __papplet__.dataPath(filename)<tab><tab><IF-STMT><tab><tab><tab>return __realopen__(datafilename, *args, **kwargs)<tab><tab>sketchfilename = __papplet__.sketchPath(filename)<tab>if os.path.isfile(sketchfilename):<tab><tab>return __realopen__(sketchfilename, *args, **kwargs)<tab># Fail naturally<tab>return __realopen__(filename, *args, **kwargs)",1,if os . path . isfile ( datafilename ) :,if os . path . isfile ( datafilename ) :,0.75,100.00000000000004,1.0
def run(self):<tab>while not self.completed:<tab><tab><IF-STMT><tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab>if self.timeout is not None:<tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab>if dt > self.timeout:<tab><tab><tab><tab>self.stop()<tab><tab>if self.counter == self.count:<tab><tab><tab>self.stop(),0,if self . block :,if self . counter == 0 :,0.11726065783135259,22.089591134157878,0.4761904761904762
"def remove(self, path, config=None, error_on_path=False, defaults=None):<tab>if not path:<tab><tab><IF-STMT><tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>return<tab>if config is not None or defaults is not None:<tab><tab>if config is None:<tab><tab><tab>config = self._config<tab><tab>if defaults is None:<tab><tab><tab>defaults = dict(self._map.parents)<tab><tab>chain = HierarchicalChainMap(config, defaults)<tab>else:<tab><tab>chain = self._map<tab>try:<tab><tab>chain.del_by_path(path)<tab><tab>self._mark_dirty()<tab>except KeyError:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>pass",1,if error_on_path :,if error_on_path :,0.5311706625951745,1e-10,1.0
"def structured_dot_grad(sparse_A, dense_B, ga):<tab>if sparse_A.type.format in (""csc"", ""csr""):<tab><tab><IF-STMT><tab><tab><tab>sdgcsx = sdg_csc<tab><tab><tab>CSx = CSC<tab><tab>else:<tab><tab><tab>sdgcsx = sdg_csr<tab><tab><tab>CSx = CSR<tab><tab>g_A_data = sdgcsx(csm_indices(sparse_A), csm_indptr(sparse_A), dense_B, ga)<tab><tab>return CSx(<tab><tab><tab>g_A_data, csm_indices(sparse_A), csm_indptr(sparse_A), csm_shape(sparse_A)<tab><tab>)<tab>else:<tab><tab>raise NotImplementedError()",0,"if sparse_A . type . format == ""csc"" :","if sparse_B . type . format == ""csc"" :",0.62709085524794,78.25422900366432,1.0
"def step_async(self, actions):<tab>listify = True<tab>try:<tab><tab><IF-STMT><tab><tab><tab>listify = False<tab>except TypeError:<tab><tab>pass<tab>if not listify:<tab><tab>self.actions = actions<tab>else:<tab><tab>assert (<tab><tab><tab>self.num_envs == 1<tab><tab>), f""actions {actions} is either not a list or has a wrong size - cannot match to {self.num_envs} environments""<tab><tab>self.actions = [actions]",0,if len ( actions ) == self . num_envs :,if len ( actions ) < self . num_envs :,0.5803088707179008,67.61304462994481,1.0
"def tempFailureRetry(func, *args, **kwargs):<tab>while True:<tab><tab>try:<tab><tab><tab>return func(*args, **kwargs)<tab><tab>except (os.error, IOError) as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>raise",1,if ex . errno == errno . EINTR :,if ex . errno == errno . EINTR :,1.0,100.00000000000004,1.0
"def test_learning_always_changes_generation(chars, order):<tab>learner = LStar(lambda s: len(s) == 1 and s[0] in chars)<tab>for c in order:<tab><tab>prev = learner.generation<tab><tab>s = bytes([c])<tab><tab><IF-STMT><tab><tab><tab>learner.learn(s)<tab><tab><tab>assert learner.generation > prev",0,if learner . dfa . matches ( s ) != learner . member ( s ) :,if len ( s ) > 0 :,0.09294461468344647,6.691863570734902,0.20202020202020204
"def test_costs_5D_noisy_names(signal_bkps_5D_noisy, cost_name):<tab>signal, bkps = signal_bkps_5D_noisy<tab>cost = cost_factory(cost_name)<tab>cost.fit(signal)<tab>cost.error(0, 100)<tab>cost.error(100, signal.shape[0])<tab>cost.error(10, 50)<tab>cost.sum_of_costs(bkps)<tab>with pytest.raises(NotEnoughPoints):<tab><tab><IF-STMT><tab><tab><tab>cost.min_size = 4<tab><tab><tab>cost.error(1, 2)<tab><tab>else:<tab><tab><tab>cost.error(1, 2)",1,"if cost_name == ""cosine"" :","if cost_name == ""cosine"" :",0.75,100.00000000000004,1.0
"def remove_empty_dirs(dirname):<tab>logger.debug(""remove_empty_dirs '%s'"" % (dirname))<tab>try:<tab><tab><IF-STMT><tab><tab><tab>dirname = dirname.encode(""utf-8"")<tab><tab>os.removedirs(dirname)<tab><tab>logger.debug(""remove_empty_dirs '%s' done"" % (dirname))<tab>except OSError as exc:  # Python >2.5<tab><tab>if exc.errno == errno.ENOTEMPTY:<tab><tab><tab>logger.debug(""remove_empty_dirs '%s' not empty"" % (dirname))<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise<tab>except Exception as e:<tab><tab>logger.exception(e)<tab><tab>logger.error(""remove_empty_dirs exception: "" + dirname)<tab><tab>raise e",0,"if not isinstance ( dirname , str ) :","if isinstance ( dirname , str ) :",0.38125480330051975,76.72796459606589,0.3148148148148148
"def get_unique_attribute(self, name: str):<tab>feat = None<tab>for f in self.features:<tab><tab><IF-STMT><tab><tab><tab>if feat is not None:<tab><tab><tab><tab>raise RuntimeError(""The attribute was not unique."")<tab><tab><tab>feat = f<tab>if feat is None:<tab><tab>raise RuntimeError(""The attribute did not exist"")<tab>return getattr(feat, name)",0,"if self . _return_feature ( f ) and hasattr ( f , name ) :",if f . name == name :,0.2593330986225633,2.365931054820936,0.2631578947368421
"def get_allocated_address(<tab>self, config: ActorPoolConfig, allocated: allocated_type) -> str:<tab>addresses = config.get_external_addresses(label=self.label)<tab>for addr in addresses:<tab><tab>occupied = False<tab><tab>for strategy, _ in allocated.get(addr, dict()).values():<tab><tab><tab>if strategy == self:<tab><tab><tab><tab>occupied = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return addr<tab>raise NoIdleSlot(<tab><tab>f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}""<tab>)",1,if not occupied :,if not occupied :,0.75,100.00000000000004,1.0
"def __deepcopy__(self, memo):<tab>cls = self.__class__<tab>result = cls.__new__(cls)<tab>memo[id(self)] = result<tab>for key, value in self.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(result, key, copy.copy(value))<tab><tab>else:<tab><tab><tab>setattr(result, key, copy.deepcopy(value, memo))<tab>return result",0,if key in cls . dynamic_methods :,"if isinstance ( value , dict ) :",0.019801326568637086,5.795599612995366,0.25
def restore_forward(model):<tab>for child in model.children():<tab><tab># leaf node<tab><tab><IF-STMT><tab><tab><tab>child.forward = child.old_forward<tab><tab><tab>child.old_forward = None<tab><tab>else:<tab><tab><tab>restore_forward(child),0,"if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :","if hasattr ( child , ""old_forward"" ) :",0.2421719693206163,51.53305363125253,0.37777777777777777
"def add(self, obj, allow_duplicates=False):<tab>if allow_duplicates or obj not in self._constants:<tab><tab>self._constant_pool.append(obj)<tab><tab>self._constants[obj] = len(self)<tab><tab><IF-STMT><tab><tab><tab>self._constant_pool.append(None)",0,"if obj . __class__ in ( Double , Long ) :",if self . _constant_pool [ obj ] > self . _max_constant :,0.07585640514949166,6.0745880708766835,0.2761904761904762
"def find_file_copyright_notices(fname):<tab>ret = set()<tab>f = open(fname)<tab>lines = f.readlines()<tab>for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines<tab><tab>idx = l.lower().find(""copyright"")<tab><tab>if idx < 0:<tab><tab><tab>continue<tab><tab>copyright = l[idx + 9 :].strip()<tab><tab>if not copyright:<tab><tab><tab>continue<tab><tab>copyright = sanitise(copyright)<tab><tab># hmm, do a quick check to see if there's a year,<tab><tab># if not, skip it<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ret.add(copyright)<tab>return ret",0,"if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :","if not copyright . startswith ( ""hmm"" ) :",0.08039117443610111,7.623918892287741,0.38988095238095233
"def callback(lexer, match, context):<tab>text = match.group()<tab>extra = """"<tab>if start:<tab><tab>context.next_indent = len(text)<tab><tab>if context.next_indent < context.indent:<tab><tab><tab>while context.next_indent < context.indent:<tab><tab><tab><tab>context.indent = context.indent_stack.pop()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extra = text[context.indent :]<tab><tab><tab><tab>text = text[: context.indent]<tab>else:<tab><tab>context.next_indent += len(text)<tab>if text:<tab><tab>yield match.start(), TokenClass, text<tab>if extra:<tab><tab>yield match.start() + len(text), TokenClass.Error, extra<tab>context.pos = match.end()",1,if context . next_indent > context . indent :,if context . next_indent > context . indent :,1.0,100.00000000000004,1.0
"def queries(self):<tab>if DEV:<tab><tab>cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s)<tab><tab>if not cmd.check(f""docker check for {self.path.k8s}""):<tab><tab><tab>if not cmd.stdout.strip():<tab><tab><tab><tab>log_cmd = ShellCommand(<tab><tab><tab><tab><tab>""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT<tab><tab><tab><tab>)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>print(cmd.stdout)<tab><tab><tab><tab>pytest.exit(f""container failed to start for {self.path.k8s}"")<tab>return ()",0,"if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",if not log_cmd . run ( ) :,0.03125482343654026,10.11076417836026,0.2761904761904762
"def nodes(self):<tab>if not self._nodes:<tab><tab>nodes = self.cluster_group.instances()<tab><tab>self._nodes = []<tab><tab>master = self.master_node<tab><tab>nodeid = 1<tab><tab>for node in nodes:<tab><tab><tab>if node.state not in [""pending"", ""running""]:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._nodes.insert(0, master)<tab><tab><tab><tab>continue<tab><tab><tab>self._nodes.append(Node(node, self.key_location, ""node%.3d"" % nodeid))<tab><tab><tab>nodeid += 1<tab>else:<tab><tab>for node in self._nodes:<tab><tab><tab>log.debug(""refreshing instance %s"" % node.id)<tab><tab><tab>node.update()<tab>return self._nodes",0,if node . id == master . id :,if node . master_node == master :,0.1433922660661427,27.301208627090666,0.5599999999999999
"def match(cls, agent_name, guid, uri, media=None):<tab># Retrieve `Agent` for provided `guid`<tab>agent = Agents.get(agent_name)<tab>if agent is None:<tab><tab><IF-STMT><tab><tab><tab># First occurrence of unsupported agent<tab><tab><tab>log.warn(""Unsupported metadata agent: %s"" % agent_name)<tab><tab><tab># Mark unsupported agent as ""seen""<tab><tab><tab>unsupported_agents[agent_name] = True<tab><tab><tab>return False<tab><tab># Duplicate occurrence of unsupported agent<tab><tab>log.warn(<tab><tab><tab>""Unsupported metadata agent: %s"" % agent_name, extra={""duplicate"": True}<tab><tab>)<tab><tab>return False<tab># Fill `guid` with details from agent<tab>return agent.fill(guid, uri, media)",1,if agent_name not in unsupported_agents :,if agent_name not in unsupported_agents :,0.75,100.00000000000004,1.0
"def __createRandom(plug):<tab>node = plug.node()<tab>parentNode = node.ancestor(Gaffer.Node)<tab>with Gaffer.UndoScope(node.scriptNode()):<tab><tab>randomNode = Gaffer.Random()<tab><tab>parentNode.addChild(randomNode)<tab><tab>if isinstance(plug, (Gaffer.FloatPlug, Gaffer.IntPlug)):<tab><tab><tab>plug.setInput(randomNode[""outFloat""])<tab><tab><IF-STMT><tab><tab><tab>plug.setInput(randomNode[""outColor""])<tab>GafferUI.NodeEditor.acquire(randomNode)",0,"elif isinstance ( plug , Gaffer . Color3fPlug ) :","if isinstance ( plug , Gaffer . ColorPlug ) :",0.29071536848410967,58.14307369682194,0.5
"def post_arrow(self, arr: pa.Table, graph_type: str, opts: str = """"):<tab>dataset_id = self.dataset_id<tab>tok = self.token<tab>sub_path = f""api/v2/upload/datasets/{dataset_id}/{graph_type}/arrow""<tab>try:<tab><tab>resp = self.post_arrow_generic(sub_path, tok, arr, opts)<tab><tab>out = resp.json()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""No success indicator in server response"")<tab><tab>return out<tab>except Exception as e:<tab><tab>logger.error(""Failed to post arrow to %s"", sub_path, exc_info=True)<tab><tab>raise e",0,"if not ( ""success"" in out ) or not out [ ""success"" ] :","if ""success"" not in out :",0.07364771763745251,8.329134759167514,0.6928104575163397
"def dict_to_XML(tag, dictionary, **kwargs):<tab>""""""Return XML element converting dicts recursively.""""""<tab>elem = Element(tag, **kwargs)<tab>for key, val in dictionary.items():<tab><tab><IF-STMT><tab><tab><tab>child = dict_to_XML(""layer"", val, name=key)<tab><tab>elif isinstance(val, MutableMapping):<tab><tab><tab>child = dict_to_XML(key, val)<tab><tab>else:<tab><tab><tab>if tag == ""config"":<tab><tab><tab><tab>child = Element(""variable"", name=key)<tab><tab><tab>else:<tab><tab><tab><tab>child = Element(key)<tab><tab><tab>child.text = str(val)<tab><tab>elem.append(child)<tab>return elem",0,"if tag == ""layers"" :","if isinstance ( val , MutableLayer ) :",0.026407399022921448,6.567274736060395,0.3
"def apply_incpaths_ml(self):<tab>inc_lst = self.includes.split()<tab>lst = self.incpaths_lst<tab>for dir in inc_lst:<tab><tab>node = self.path.find_dir(dir)<tab><tab><IF-STMT><tab><tab><tab>error(""node not found: "" + str(dir))<tab><tab><tab>continue<tab><tab>if not node in lst:<tab><tab><tab>lst.append(node)<tab><tab>self.bld_incpaths_lst.append(node)",0,if not node :,if node is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def _table_reprfunc(self, row, col, val):<tab>if self._table.column_names[col].endswith(""Size""):<tab><tab>if isinstance(val, compat.string_types):<tab><tab><tab>return ""  %s"" % val<tab><tab>elif val < 1024 ** 2:<tab><tab><tab>return ""  %.1f KB"" % (val / 1024.0 ** 1)<tab><tab><IF-STMT><tab><tab><tab>return ""  %.1f MB"" % (val / 1024.0 ** 2)<tab><tab>else:<tab><tab><tab>return ""  %.1f GB"" % (val / 1024.0 ** 3)<tab>if col in (0, """"):<tab><tab>return str(val)<tab>else:<tab><tab>return ""  %s"" % val",0,elif val < 1024 ** 3 :,elif val > 1024 ** 3 :,0.4944615112174505,59.4603557501361,1.0
"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None):<tab>""""""cache hidden states into memory.""""""<tab>if mem_len is None or mem_len == 0:<tab><tab>return None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>curr_out = curr_out[:reuse_len]<tab><tab>if prev_mem is None:<tab><tab><tab>new_mem = curr_out[-mem_len:]<tab><tab>else:<tab><tab><tab>new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:]<tab>new_mem.stop_gradient = True<tab>return new_mem",0,if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None :,0.38801046869250244,41.06951993704473,0.6857142857142857
"def GROUP_CONCAT(builder, distinct, expr, sep=None):<tab>assert distinct in (None, True, False)<tab>result = distinct and ""GROUP_CONCAT(DISTINCT "" or ""GROUP_CONCAT("", builder(expr)<tab>if sep is not None:<tab><tab><IF-STMT><tab><tab><tab>result = result, "" SEPARATOR "", builder(sep)<tab><tab>else:<tab><tab><tab>result = result, "", "", builder(sep)<tab>return result, "")""",0,"if builder . provider . dialect == ""MySQL"" :","if sep == "","" :",0.0168380461076173,16.409149280404737,0.3055555555555556
"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab>self.custom_fields = []<tab>self.obj_type = ContentType.objects.get_for_model(self.model)<tab># Add all applicable CustomFields to the form<tab>custom_fields = CustomField.objects.filter(content_types=self.obj_type)<tab>for cf in custom_fields:<tab><tab># Annotate non-required custom fields as nullable<tab><tab><IF-STMT><tab><tab><tab>self.nullable_fields.append(cf.name)<tab><tab>self.fields[cf.name] = cf.to_form_field(<tab><tab><tab>set_initial=False, enforce_required=False<tab><tab>)<tab><tab># Annotate this as a custom field<tab><tab>self.custom_fields.append(cf.name)",1,if not cf . required :,if not cf . required :,0.75,100.00000000000004,1.0
"def is_child_of(self, item_hash, possible_child_hash):<tab>if self.get_last(item_hash) != self.get_last(possible_child_hash):<tab><tab>return None<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if possible_child_hash not in self.items:<tab><tab><tab>return False<tab><tab>possible_child_hash = self.items[possible_child_hash].previous_hash",0,if possible_child_hash == item_hash :,if self . items [ possible_child_hash ] . previous_hash != item_hash :,0.045390644187933274,34.82207361953904,0.475
"def validate(self):<tab>self.assertEqual(len(self.inputs), len(self.outputs))<tab>for batch_in, batch_out in zip(self.inputs, self.outputs):<tab><tab>self.assertEqual(len(batch_in), len(batch_out))<tab><tab><IF-STMT><tab><tab><tab>self.validate_unordered_batch(batch_in, batch_out)<tab><tab>else:<tab><tab><tab>for in_data, out_data in zip(batch_in, batch_out):<tab><tab><tab><tab>self.assertEqual(in_data.shape, out_data.shape)<tab><tab><tab><tab>if not self.use_parallel_executor:<tab><tab><tab><tab><tab>self.assertTrue((in_data == out_data).all())",0,if self . use_parallel_executor and not self . use_double_buffer :,if not self . use_parallel_executor :,0.1547089404632504,36.100365922673745,0.3666666666666667
"def add_cells(self, cells):<tab>for cell in cells:<tab><tab><IF-STMT><tab><tab><tab>id = len(self.cell_id_map)<tab><tab><tab>self.cell_id_map[cell] = id<tab><tab><tab>self.id_cell_map[id] = cell",1,if cell not in self . cell_id_map :,if cell not in self . cell_id_map :,0.75,100.00000000000004,1.0
"def _verify_out(marker="">>""):<tab>if shared:<tab><tab>self.assertIn(""libapp_lib.dylib"", self.client.out)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(""libapp_lib.a"", self.client.out)<tab><tab>else:  # Incremental build not the same msg<tab><tab><tab>self.assertIn(""Built target app_lib"", self.client.out)<tab>out = str(self.client.out).splitlines()<tab>for k, v in vals.items():<tab><tab>self.assertIn(""%s %s: %s"" % (marker, k, v), out)",0,"if marker == "">>"" :","if sys . platform == ""win32"" :",0.029730601197949243,20.556680845025987,0.37777777777777777
"def Visit_expr(self, node):  # pylint: disable=invalid-name<tab># expr ::= xor_expr ('|' xor_expr)*<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)",0,"if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :","if isinstance ( child , pytree . Leaf ) and isinstance ( child . value , pytree . Leaf ) :",0.5815386252631012,50.97960527136183,0.6711956521739131
"def fill_members(self):<tab>if self._get_retrieve():<tab><tab>after = self.after.id if self.after else None<tab><tab>data = await self.get_members(self.guild.id, self.retrieve, after)<tab><tab>if not data:<tab><tab><tab># no data, terminate<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self.limit = 0  # terminate loop<tab><tab>self.after = Object(id=int(data[-1][""user""][""id""]))<tab><tab>for element in reversed(data):<tab><tab><tab>await self.members.put(self.create_member(element))",0,if len ( data ) < 1000 :,if len ( data ) > 1 :,0.5241515189640744,54.10822690539397,0.6666666666666666
"def assert_warns(expected):<tab>with warnings.catch_warnings(record=True) as w:<tab><tab>warnings.simplefilter(""always"")<tab><tab>yield<tab># Python 2 does not raise warnings multiple times from the same stack<tab># frame.<tab>if sys.version_info >= (3, 0):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>exc_name = expected.__name__<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>exc_name = str(expected)<tab><tab><tab>raise AssertionError(""%s not triggerred"" % exc_name)",0,"if not any ( isinstance ( m . message , expected ) for m in w ) :",if expected is not None :,0.006096293474845492,1.5534791020152603,0.13076923076923078
"def __init__(self, measures):<tab>""""""Constructs a ContingencyMeasures given a NgramAssocMeasures class""""""<tab>self.__class__.__name__ = ""Contingency"" + measures.__class__.__name__<tab>for k in dir(measures):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>v = getattr(measures, k)<tab><tab>if not k.startswith(""_""):<tab><tab><tab>v = self._make_contingency_fn(measures, v)<tab><tab>setattr(self, k, v)",0,"if k . startswith ( ""__"" ) :","if k . startswith ( ""_"" ) :",0.5490406812970063,80.45268749630647,1.0
"def _omit_keywords(self, context):<tab>omitted_kws = 0<tab>for event, elem in context:<tab><tab># Teardowns aren't omitted to allow checking suite teardown status.<tab><tab>omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown""<tab><tab>start = event == ""start""<tab><tab><IF-STMT><tab><tab><tab>omitted_kws += 1<tab><tab>if not omitted_kws:<tab><tab><tab>yield event, elem<tab><tab>elif not start:<tab><tab><tab>elem.clear()<tab><tab>if omit and not start:<tab><tab><tab>omitted_kws -= 1",1,if omit and start :,if omit and start :,0.75,100.00000000000004,1.0
"def read_block(buffer, i):<tab>offset = i * BLOCK_LENGTH % config.CAPTURE_BUFFER<tab>while True:<tab><tab>if buffer[offset] == BLOCK_MARKER.END:<tab><tab><tab>return None<tab><tab>while buffer[offset] == BLOCK_MARKER.WRITE:<tab><tab><tab>time.sleep(SHORT_SENSOR_SLEEP_TIME)<tab><tab>buffer[offset] = BLOCK_MARKER.READ<tab><tab>buffer.seek(offset + 1)<tab><tab>length = struct.unpack(""=H"", buffer.read(2))[0]<tab><tab>retval = buffer.read(length)<tab><tab><IF-STMT><tab><tab><tab>break<tab>buffer[offset] = BLOCK_MARKER.NOP<tab>return retval",0,if buffer [ offset ] == BLOCK_MARKER . READ :,if not retval :,0.012921387555106882,2.002152301552759,0.27472527472527475
def _start(self):<tab>try:<tab><tab>instance_info = self._get_instance_info()<tab><tab><IF-STMT><tab><tab><tab>self._multipass_cmd.start(instance_name=self.instance_name)<tab>except errors.ProviderInfoError as instance_error:<tab><tab># Until we have proper multipass error codes to know if this<tab><tab># was a communication error we should keep this error tracking<tab><tab># and generation here.<tab><tab>raise errors.ProviderInstanceNotFoundError(<tab><tab><tab>instance_name=self.instance_name<tab><tab>) from instance_error,0,if not instance_info . is_running ( ) :,if instance_info is not None and instance_info . instance_name != self . instance_name :,0.02882195245941782,12.6254971485354,0.2571428571428572
"def _river_driver(self):<tab>if self._cached_river_driver:<tab><tab>return self._cached_river_driver<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._cached_river_driver = MsSqlDriver(<tab><tab><tab><tab>self.workflow, self.wokflow_object_class, self.field_name<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self._cached_river_driver = OrmDriver(<tab><tab><tab><tab>self.workflow, self.wokflow_object_class, self.field_name<tab><tab><tab>)<tab><tab>return self._cached_river_driver",0,if app_config . IS_MSSQL :,if self . is_sql :,0.28654024892898816,6.979367151952678,0.6190476190476191
"def __LazyMap__(self, attr):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>debug_attr_print(<tab><tab><tab><tab>""%s.__LazyMap__(%s) added something"" % (self._username_, attr)<tab><tab><tab>)<tab><tab><tab>return 1<tab>except AttributeError:<tab><tab>return 0",0,if self . _LazyAddAttr_ ( attr ) :,if self . _username_ != attr :,0.08112608455670559,30.213753973567687,1.0
"def prepare(self, data=None, user=None):<tab>""""""Prepare activation for execution.""""""<tab>super(ManagedStartViewActivation, self).prepare.original()<tab>self.task.owner = user<tab>management_form_class = self.get_management_form_class()<tab>self.management_form = management_form_class(data=data, instance=self.task)<tab>if data:<tab><tab><IF-STMT><tab><tab><tab>raise FlowRuntimeError(<tab><tab><tab><tab>""Activation metadata is broken {}"".format(self.management_form.errors)<tab><tab><tab>)<tab><tab>self.task = self.management_form.save(commit=False)",0,if not self . management_form . is_valid ( ) :,if self . management_form . errors :,0.1500170882436275,36.21513850221006,0.4
"def PreprocessConditionalStatement(self, IfList, ReplacedLine):<tab>while self:<tab><tab>if self.__Token:<tab><tab><tab>x = 1<tab><tab>elif not IfList:<tab><tab><tab>if self <= 2:<tab><tab><tab><tab>continue<tab><tab><tab>RegionSizeGuid = 3<tab><tab><tab><IF-STMT><tab><tab><tab><tab>RegionLayoutLine = 5<tab><tab><tab><tab>continue<tab><tab><tab>RegionLayoutLine = self.CurrentLineNumber<tab>return 1",0,if not RegionSizeGuid :,if self <= 3 :,0.04240785919217091,9.652434877402245,0.3333333333333333
"def _get_completion(self, document):<tab>try:<tab><tab>completion_header = document.xpath(""//div[@id='complete_day']"")[0]<tab><tab>completion_message = completion_header.getchildren()[0]<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>elif ""day_complete_message"" in completion_message.classes:<tab><tab><tab>return True<tab>except IndexError:<tab><tab>return False  # Who knows, probably not my diary.",0,"if ""day_incomplete_message"" in completion_message . classes :",if completion_message is None :,0.02384665141965364,8.858009236942326,0.3333333333333333
"def run(self):<tab>DISPATCH_SYNC = components.interfaces.nsIEventTarget.DISPATCH_SYNC<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for match in findlib2.find_all_matches(self.regex, self.text):<tab><tab><tab>if self._stopped:<tab><tab><tab><tab>return<tab><tab><tab>self.target.dispatch(lambda: self.callback(match), DISPATCH_SYNC)<tab><tab><tab>if self._stopped:<tab><tab><tab><tab>return<tab><tab>self.target.dispatch(lambda: self.callback(None), DISPATCH_SYNC)<tab>finally:<tab><tab>self.callback = None<tab><tab>self.target = None",1,if self . _stopped :,if self . _stopped :,0.75,100.00000000000004,1.0
"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab>if isinstance(k, float):<tab><tab><tab>return unicode(float_repr(k))<tab><tab><IF-STMT><tab><tab><tab>return compose_regex(k)<tab><tab>elif isinstance(k, bool):<tab><tab><tab>return ""true"" if k else ""false""<tab><tab>elif k is None:<tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)",1,"elif ""regex"" in literal_or_identifier :","elif ""regex"" in literal_or_identifier :",0.75,100.00000000000004,1.0
"def process_image_pre_creation(sender, instance: Image, **kwargs):<tab># FIXME(winkidney): May have issue on determining if it<tab>#  is created or not<tab>if instance.pk is not None:<tab><tab>return<tab>for plugin in _plugin_instances:<tab><tab>process_fn = getattr(plugin, ""process_image_pre_creation"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>process_fn(<tab><tab><tab><tab>django_settings=settings,<tab><tab><tab><tab>image_instance=instance,<tab><tab><tab>)<tab><tab>except Exception:<tab><tab><tab>logging.exception(<tab><tab><tab><tab>""Error occurs while trying to access plugin's pin_pre_save ""<tab><tab><tab><tab>""for plugin %s"" % plugin<tab><tab><tab>)",1,if process_fn is None :,if process_fn is None :,0.75,100.00000000000004,1.0
"def check_screenshots(self):<tab># If we arrive here, there have not been any failures yet<tab>if self.interactive:<tab><tab>self._commit_screenshots()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._validate_screenshots()<tab><tab><tab># Always commit the screenshots here. They can be used for the next test run.<tab><tab><tab># If reference screenshots were already present and there was a mismatch, it should<tab><tab><tab># have failed above.<tab><tab><tab>self._commit_screenshots()<tab><tab>elif self.allow_missing_screenshots:<tab><tab><tab>warnings.warn(""No committed reference screenshots available. Ignoring."")<tab><tab>else:<tab><tab><tab>self.fail(<tab><tab><tab><tab>""No committed reference screenshots available. Run interactive first.""<tab><tab><tab>)",0,if self . _has_reference_screenshots ( ) :,if self . allow_screenshots :,0.09453229110448028,15.749996500436227,1.0
"def on_task_abort(self, task, config):<tab>if ""abort"" in config:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>log.debug(""sending abort notification"")<tab><tab>self.send_notification(<tab><tab><tab>config[""abort""][""title""],<tab><tab><tab>config[""abort""][""message""],<tab><tab><tab>config[""abort""][""via""],<tab><tab><tab>template_renderer=task.render,<tab><tab>)",0,if task . silent_abort :,"if config [ ""abort"" ] [ ""message"" ] is None :",0.0237537216033675,3.4585921141027356,0.3125
"def block_users(self, user_ids):<tab>broken_items = []<tab>self.logger.info(""Going to block %d users."" % len(user_ids))<tab>for user_id in tqdm(user_ids):<tab><tab><IF-STMT><tab><tab><tab>self.error_delay()<tab><tab><tab>broken_items = user_ids[user_ids.index(user_id) :]<tab><tab><tab>break<tab>self.logger.info(""DONE: Total blocked %d users."" % self.total[""blocks""])<tab>return broken_items",0,if not self . block ( user_id ) :,"if len ( user_ids ) >= self . total [ ""blocks"" ] :",0.028103528259171725,11.306082351602983,0.42857142857142855
"def find_widget_by_id(self, id, parent=None):<tab>""""""Recursively searches for widget with specified ID""""""<tab>if parent == None:<tab><tab>if id in self:<tab><tab><tab>return self[id]  # Do things fast if possible<tab><tab>parent = self[""editor""]<tab>for c in parent.get_children():<tab><tab>if hasattr(c, ""get_id""):<tab><tab><tab>if c.get_id() == id:<tab><tab><tab><tab>return c<tab><tab>if isinstance(c, Gtk.Container):<tab><tab><tab>r = self.find_widget_by_id(id, c)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return r<tab>return None",0,if not r is None :,if r :,0.028363593025821247,1e-10,0.2333333333333333
"def addClasses(self, name):<tab># Result: void - None<tab># In: name: string<tab>for n in name.split():<tab><tab>try:<tab><tab><tab>k, method = n.split(""."")<tab><tab>except ValueError:<tab><tab><tab>k = n<tab><tab><tab>method = None<tab><tab>self.classes[k] = 1<tab><tab><IF-STMT><tab><tab><tab>self.methods.setdefault(k, {})[method] = 1",1,if method is not None :,if method is not None :,0.75,100.00000000000004,1.0
"def Read(self, lex_mode):<tab>while True:<tab><tab>t = self._Read(lex_mode)<tab><tab>self.was_line_cont = t.id == Id.Ignored_LineCont<tab><tab># TODO: Change to ALL IGNORED types, once you have SPACE_TOK.  This means<tab><tab># we don't have to handle them in the VS_1/VS_2/etc. states.<tab><tab><IF-STMT><tab><tab><tab>break<tab># log('Read() Returning %s', t)<tab>return t",0,if t . id != Id . Ignored_LineCont :,if self . was_line_cont :,0.0793380461076173,4.8312524369621626,0.3666666666666667
"def _dir_guildfile(dir, ctx):<tab>from guild import guildfile<tab>try:<tab><tab>return guildfile.for_dir(dir)<tab>except guildfile.NoModels:<tab><tab><IF-STMT><tab><tab><tab>help_suffix = "" or '%s' for help"" % click_util.cmd_help(ctx)<tab><tab>else:<tab><tab><tab>help_suffix = """"<tab><tab>cli.error(<tab><tab><tab>""%s does not contain a Guild file (guild.yml)\n""<tab><tab><tab>""Try specifying a project path or package name%s.""<tab><tab><tab>% (cwd_desc(dir), help_suffix)<tab><tab>)<tab>except guildfile.GuildfileError as e:<tab><tab>cli.error(str(e))",1,if ctx :,if ctx :,0.5311706625951745,1e-10,1.0
"def check_response(self, response):<tab>""""""Specialized version of check_response().""""""<tab>for line in response:<tab><tab># Skip blank lines:<tab><tab>if not line.strip():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>elif line.startswith(b""Benutzer/Passwort Fehler""):<tab><tab><tab>raise BadLogin(line)<tab><tab>else:<tab><tab><tab>raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))",0,"if line . startswith ( b""OK"" ) :","elif line . startswith ( b""http"" ) :",0.2456586942207979,58.77283725105324,0.6
"def ParseResponses(<tab>self,<tab>knowledge_base: rdf_client.KnowledgeBase,<tab>responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]:<tab>for response in responses:<tab><tab>if not isinstance(response, rdf_client_fs.StatEntry):<tab><tab><tab>raise TypeError(f""Unexpected response type: `{type(response)}`"")<tab><tab># TODO: `st_mode` has to be an `int`, not `StatMode`.<tab><tab><IF-STMT><tab><tab><tab>homedir = response.pathspec.path<tab><tab><tab>username = os.path.basename(homedir)<tab><tab><tab>if username not in self._ignore_users:<tab><tab><tab><tab>yield rdf_client.User(username=username, homedir=homedir)",0,if stat . S_ISDIR ( int ( response . st_mode ) ) :,"if isinstance ( response . pathspec , rdf_client . PathSpec ) :",0.08388539428631175,12.066209970920308,0.2773109243697479
"def __call__(self, x, uttid=None):<tab>if self.utt2spk is not None:<tab><tab>spk = self.utt2spk[uttid]<tab>else:<tab><tab>spk = uttid<tab>if not self.reverse:<tab><tab><IF-STMT><tab><tab><tab>x = np.add(x, self.bias[spk])<tab><tab>if self.norm_vars:<tab><tab><tab>x = np.multiply(x, self.scale[spk])<tab>else:<tab><tab>if self.norm_vars:<tab><tab><tab>x = np.divide(x, self.scale[spk])<tab><tab>if self.norm_means:<tab><tab><tab>x = np.subtract(x, self.bias[spk])<tab>return x",1,if self . norm_means :,if self . norm_means :,0.75,100.00000000000004,1.0
"def hasFixtures(self, ctx_callback=None):<tab>context = self.context<tab>if context is None:<tab><tab>return False<tab>if self.implementsAnyFixture(context, ctx_callback=ctx_callback):<tab><tab>return True<tab># My context doesn't have any, but its ancestors might<tab>factory = self.factory<tab>if factory:<tab><tab>ancestors = factory.context.get(self, [])<tab><tab>for ancestor in ancestors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,"if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :",if ancestor . hasFixtures ( ctx_callback = ctx_callback ) :,0.4867863419468337,56.6066245608455,0.3235294117647059
def UpdateControlState(self):<tab>active = self.demoModules.GetActiveID()<tab># Update the radio/restore buttons<tab>for moduleID in self.radioButtons:<tab><tab>btn = self.radioButtons[moduleID]<tab><tab>if moduleID == active:<tab><tab><tab>btn.SetValue(True)<tab><tab>else:<tab><tab><tab>btn.SetValue(False)<tab><tab>if self.demoModules.Exists(moduleID):<tab><tab><tab>btn.Enable(True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.btnRestore.Enable(True)<tab><tab>else:<tab><tab><tab>btn.Enable(False)<tab><tab><tab>if moduleID == modModified:<tab><tab><tab><tab>self.btnRestore.Enable(False),0,if moduleID == modModified :,if moduleID == moduleModified :,0.39477865547525276,53.7284965911771,0.6
"def ignore_proxy_host(self):<tab>""""""Check if self.host is in the $no_proxy ignore list.""""""<tab>if urllib.proxy_bypass(self.host):<tab><tab>return True<tab>no_proxy = os.environ.get(""no_proxy"")<tab>if no_proxy:<tab><tab>entries = [parse_host_port(x) for x in no_proxy.split("","")]<tab><tab>for host, port in entries:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,if host . lower ( ) == self . host and port == self . port :,if parse_host_port ( self . host ) == port :,0.04345893952651459,15.844917324845158,0.25170068027210885
"def run(self, _):<tab>view = self.view<tab>if not view.settings().get(""terminus_view""):<tab><tab>return<tab>terminal = Terminal.from_id(view.id())<tab>if terminal:<tab><tab>terminal.close()<tab><tab>panel_name = terminal.panel_name<tab><tab><IF-STMT><tab><tab><tab>window = panel_window(view)<tab><tab><tab>if window:<tab><tab><tab><tab>window.destroy_output_panel(panel_name)<tab><tab>else:<tab><tab><tab>view.close()",1,if panel_name :,if panel_name :,0.5311706625951745,1e-10,1.0
"def get_docname_for_node(self, node: Node) -> str:<tab>while node:<tab><tab><IF-STMT><tab><tab><tab>return self.env.path2doc(node[""source""])<tab><tab>elif isinstance(node, addnodes.start_of_file):<tab><tab><tab>return node[""docname""]<tab><tab>else:<tab><tab><tab>node = node.parent<tab>return None  # never reached here. only for type hinting",0,"if isinstance ( node , nodes . document ) :","if isinstance ( node , addnodes . start_of_file ) :",0.485600785330624,31.61487584488944,0.5584415584415584
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.add_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def _maybe_female(self, path_elements, female, strict):<tab>if female:<tab><tab>if self.has_gender_differences:<tab><tab><tab>elements = path_elements + [""female""]<tab><tab><tab>try:<tab><tab><tab><tab>return self._get_file(elements, "".png"", strict=strict)<tab><tab><tab>except ValueError:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise<tab><tab>elif strict:<tab><tab><tab>raise ValueError(""Pokemon %s has no gender differences"" % self.species_id)<tab>return self._get_file(path_elements, "".png"", strict=strict)",0,if strict :,if self .species_id not in path_elements :,0.04579081141525348,1e-10,0.2916666666666667
"def OnKeyUp(self, event):<tab>if self._properties.modifiable:<tab><tab>if event.GetKeyCode() == wx.WXK_ESCAPE:<tab><tab><tab>self._cancel_editing()<tab><tab>elif event.GetKeyCode() == wx.WXK_RETURN:<tab><tab><tab>self._update_value()<tab><tab><IF-STMT><tab><tab><tab>self.SetValue("""")<tab>if event.GetKeyCode() != wx.WXK_RETURN:<tab><tab># Don't send skip event if enter key is pressed<tab><tab># On some platforms this event is sent too late and causes crash<tab><tab>event.Skip()",0,elif event . GetKeyCode ( ) == wx . WXK_DELETE :,elif event . GetKeyCode ( ) == wx . WXK_ESCAPE :,0.653527863746399,85.5526185871245,1.0
"def sync_up_to_new_location(self, worker_ip):<tab>if worker_ip != self.worker_ip:<tab><tab>logger.debug(""Setting new worker IP to %s"", worker_ip)<tab><tab>self.set_worker_ip(worker_ip)<tab><tab>self.reset()<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""Sync up to new location skipped. This should not occur."")<tab>else:<tab><tab>logger.warning(""Sync attempted to same IP %s."", worker_ip)",0,if not self . sync_up ( ) :,if self . sync_up_to_new_location :,0.03730445553501224,31.455601883230702,0.4772727272727273
"def _get_download_link(self, url, download_type=""torrent""):<tab>links = {<tab><tab>""torrent"": """",<tab><tab>""magnet"": """",<tab>}<tab>try:<tab><tab>data = self.session.get(url).text<tab><tab>with bs4_parser(data) as html:<tab><tab><tab>downloads = html.find(""div"", {""class"": ""download""})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for download in downloads.findAll(""a""):<tab><tab><tab><tab><tab>link = download[""href""]<tab><tab><tab><tab><tab>if link.startswith(""magnet""):<tab><tab><tab><tab><tab><tab>links[""magnet""] = link<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>links[""torrent""] = urljoin(self.urls[""base_url""], link)<tab>except Exception:<tab><tab>pass<tab>return links[download_type]",1,if downloads :,if downloads :,0.5311706625951745,1e-10,1.0
"def force_ipv4(self, *args):<tab>""""""only ipv4 localhost in /etc/hosts""""""<tab>logg.debug(""checking /etc/hosts for '::1 localhost'"")<tab>lines = []<tab>for line in open(self.etc_hosts()):<tab><tab>if ""::1"" in line:<tab><tab><tab>newline = re.sub(""\\slocalhost\\s"", "" "", line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip())<tab><tab><tab><tab>line = newline<tab><tab>lines.append(line)<tab>f = open(self.etc_hosts(), ""w"")<tab>for line in lines:<tab><tab>f.write(line)<tab>f.close()",0,if line != newline :,if newline :,0.06767423853569741,1e-10,0.45
"def prepare(self):<tab># Maybe the brok is a old daemon one or was already prepared<tab># if so, the data is already ok<tab>if hasattr(self, ""prepared"") and not self.prepared:<tab><tab>self.data = SafeUnpickler.loads(self.data)<tab><tab><IF-STMT><tab><tab><tab>self.data[""instance_id""] = self.instance_id<tab>self.prepared = True",0,"if hasattr ( self , ""instance_id"" ) :",if self . instance_id :,0.019907917998500824,14.231728394642222,0.4772727272727273
"def _test_compute_q0(self):<tab># Stub code to search a logq space and figure out logq0 by eyeballing<tab># results. This code does not run with the tests. Remove underscore to run.<tab>sigma = 15<tab>order = 250<tab>logqs = np.arange(-290, -270, 1)<tab>count = 0<tab>for logq in logqs:<tab><tab>count += 1<tab><tab>sys.stdout.write(<tab><tab><tab>""\t%0.5g: %0.10g"" % (logq, pate.rdp_gaussian(logq, sigma, order))<tab><tab>)<tab><tab>sys.stdout.flush()<tab><tab><IF-STMT><tab><tab><tab>print("""")",0,if count % 5 == 0 :,if count % 100 == 0 :,0.3884893899276739,50.000000000000014,0.6666666666666666
"def valid_fieldnames(fieldnames):<tab>""""""check if fieldnames are valid""""""<tab>for fieldname in fieldnames:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif fieldname in fieldname_map and fieldname_map[fieldname] == ""source"":<tab><tab><tab>return True<tab>return False",0,"if fieldname in canonical_field_names and fieldname == ""source"" :","if fieldname == ""name"" :",0.09999927568871111,16.620830006469276,0.4787878787878788
"def ns_provide(self, id_):<tab>global controllers, layouts<tab>if id_ == ""_leo_viewrendered"":<tab><tab>c = self.c<tab><tab>vr = controllers.get(c.hash()) or ViewRenderedController(c)<tab><tab>h = c.hash()<tab><tab>controllers[h] = vr<tab><tab><IF-STMT><tab><tab><tab>layouts[h] = c.db.get(""viewrendered_default_layouts"", (None, None))<tab><tab># return ViewRenderedController(self.c)<tab><tab>return vr",0,if not layouts . get ( h ) :,if layouts is not None :,0.017951424116240698,6.962210312500384,0.25
"def remove(self, path, config=None, error_on_path=False, defaults=None):<tab>if not path:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>return<tab>if config is not None or defaults is not None:<tab><tab>if config is None:<tab><tab><tab>config = self._config<tab><tab><IF-STMT><tab><tab><tab>defaults = dict(self._map.parents)<tab><tab>chain = HierarchicalChainMap(config, defaults)<tab>else:<tab><tab>chain = self._map<tab>try:<tab><tab>chain.del_by_path(path)<tab><tab>self._mark_dirty()<tab>except KeyError:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>pass",1,if defaults is None :,if defaults is None :,0.75,100.00000000000004,1.0
"def _mongo_query_and(self, queries):<tab>if len(queries) == 1:<tab><tab>return queries[0]<tab>query = {}<tab>for q in queries:<tab><tab>for k, v in q.items():<tab><tab><tab>if k not in query:<tab><tab><tab><tab>query[k] = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab># TODO check exists of k in query, may be it should be update<tab><tab><tab><tab>query[k] = v<tab><tab><tab>else:<tab><tab><tab><tab>query[k].update(v)<tab>return query",0,"if isinstance ( v , list ) :","elif isinstance ( query [ k ] , dict ) :",0.034744687998385794,11.208466750961147,0.2136752136752137
"def write(self, data):<tab>self.size -= len(data)<tab>passon = None<tab>if self.size > 0:<tab><tab>self.data.append(data)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>data, passon = data[: self.size], data[self.size :]<tab><tab>else:<tab><tab><tab>passon = b""""<tab><tab>if data:<tab><tab><tab>self.data.append(data)<tab>return passon",0,if self . size :,if len ( data ) > self . size :,0.329550504480265,27.77619034011791,0.3055555555555556
"def updateVar(name, data, mode=None):<tab>if mode:<tab><tab>if mode == ""append"":<tab><tab><tab>core.config.globalVariables[name].append(data)<tab><tab><IF-STMT><tab><tab><tab>core.config.globalVariables[name].add(data)<tab>else:<tab><tab>core.config.globalVariables[name] = data",0,"elif mode == ""add"" :","elif mode == ""append_append"" :",0.6428720214849399,45.180100180492246,1.0
"def vi_pos_back_short(line, index=0, count=1):<tab>line = vi_list(line)<tab>try:<tab><tab>for i in range(count):<tab><tab><tab>index -= 1<tab><tab><tab>while vi_is_space(line[index]):<tab><tab><tab><tab>index -= 1<tab><tab><tab>in_word = vi_is_word(line[index])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>while vi_is_word(line[index]):<tab><tab><tab><tab><tab>index -= 1<tab><tab><tab>else:<tab><tab><tab><tab>while not vi_is_word_or_space(line[index]):<tab><tab><tab><tab><tab>index -= 1<tab><tab>return index + 1<tab>except IndexError:<tab><tab>return 0",1,if in_word :,if in_word :,0.5311706625951745,1e-10,1.0
"def _truncate_to_length(generator, len_map=None):<tab>for example in generator:<tab><tab>example = list(example)<tab><tab><IF-STMT><tab><tab><tab>for key, max_len in len_map.items():<tab><tab><tab><tab>example_len = example[key].shape<tab><tab><tab><tab>if example_len > max_len:<tab><tab><tab><tab><tab>example[key] = np.resize(example[key], max_len)<tab><tab>yield tuple(example)",0,if len_map is not None :,if len_map :,0.050438393472541504,1e-10,0.3142857142857143
"def decorate(f):<tab># call-signature of f is exposed via __wrapped__.<tab># we want it to mimic Obj.__init__<tab>f.__wrapped__ = Obj.__init__<tab>f._uses_signature = Obj<tab># Supplement the docstring of f with information from Obj<tab>if Obj.__doc__:<tab><tab>doclines = Obj.__doc__.splitlines()<tab><tab><IF-STMT><tab><tab><tab>doc = f.__doc__ + ""\n"".join(doclines[1:])<tab><tab>else:<tab><tab><tab>doc = ""\n"".join(doclines)<tab><tab>try:<tab><tab><tab>f.__doc__ = doc<tab><tab>except AttributeError:<tab><tab><tab># __doc__ is not modifiable for classes in Python < 3.3<tab><tab><tab>pass<tab>return f",0,if f . __doc__ :,if len ( doclines ) > 1 :,0.026407399022921448,5.795599612995366,0.3
"def IncrementErrorCount(self, category):<tab>""""""Bumps the module's error statistic.""""""<tab>self.error_count += 1<tab>if self.counting in (""toplevel"", ""detailed""):<tab><tab>if self.counting != ""detailed"":<tab><tab><tab>category = category.split(""/"")[0]<tab><tab><IF-STMT><tab><tab><tab>self.errors_by_category[category] = 0<tab><tab>self.errors_by_category[category] += 1",1,if category not in self . errors_by_category :,if category not in self . errors_by_category :,0.75,100.00000000000004,1.0
"def _delete_fields(self, data):<tab>data = self._del(<tab><tab>data, [""speaker_ids"", ""track_id"", ""microlocation_id"", ""session_type_id""]<tab>)<tab># convert datetime fields<tab>for _ in [""start_time_tz"", ""end_time_tz""]:<tab><tab><IF-STMT><tab><tab><tab>data[_] = SESSION_POST[_[0:-3]].from_str(data[_])<tab><tab><tab>data[_[0:-3]] = data.pop(_)<tab>return data",0,if _ in data :,if _ in SESSION_POST :,0.39477865547525276,26.269098944241588,0.7
"def get_strings_of_set(word, char_set, threshold=20):<tab>count = 0<tab>letters = """"<tab>strings = []<tab>for char in word:<tab><tab>if char in char_set:<tab><tab><tab>letters += char<tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strings.append(letters)<tab><tab><tab>letters = """"<tab><tab><tab>count = 0<tab>if count > threshold:<tab><tab>strings.append(letters)<tab>return strings",1,if count > threshold :,if count > threshold :,0.75,100.00000000000004,1.0
"def _ArgumentListHasDictionaryEntry(self, token):<tab>""""""Check if the function argument list has a dictionary as an arg.""""""<tab>if _IsArgumentToFunction(token):<tab><tab>while token:<tab><tab><tab>if token.value == ""{"":<tab><tab><tab><tab>length = token.matching_bracket.total_length - token.total_length<tab><tab><tab><tab>return length + self.stack[-2].indent > self.column_limit<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if token.OpensScope():<tab><tab><tab><tab>token = token.matching_bracket<tab><tab><tab>token = token.next_token<tab>return False",0,if token . ClosesScope ( ) :,"elif token . value == ""}"" :",0.03658781210053504,9.287528999566801,0.3333333333333333
"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab>if mode == ""start"":<tab><tab><tab>if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""key""<tab><tab>elif mode == ""key"":<tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",0,"elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :","elif mode == ""encrypt"" :",0.13400303224774532,2.8730831956184355,0.25
"def main(self):<tab>self.model.clear()<tab>self.callman.unregister_all()<tab>active_handle = self.get_active(""Person"")<tab>if active_handle:<tab><tab>active = self.dbstate.db.get_person_from_handle(active_handle)<tab><tab><IF-STMT><tab><tab><tab>self.callman.register_obj(active)<tab><tab><tab>self.display_citations(active)<tab><tab>else:<tab><tab><tab>self.set_has_data(False)<tab>else:<tab><tab>self.set_has_data(False)",1,if active :,if active :,0.5311706625951745,1e-10,1.0
"def _validate(self) -> None:<tab># Paren validation and such<tab>super(Tuple, self)._validate()<tab>if len(self.elements) == 0:<tab><tab><IF-STMT>  # assumes len(lpar) == len(rpar), via superclass<tab><tab><tab>raise CSTValidationError(<tab><tab><tab><tab>""A zero-length tuple must be wrapped in parentheses.""<tab><tab><tab>)",0,if len ( self . lpar ) == 0 :,"if isinstance ( lpar , tuple ) and isinstance ( rpar , tuple ) :",0.013342940969318819,3.9297193407553004,0.18235294117647058
"def _session_from_arg(self, session_obj, lock_type=None):<tab>if not isinstance(session_obj, self.ISession):<tab><tab>vm = self._machine_from_arg(session_obj)<tab><tab>lock_type = lock_type or self.LockType.null<tab><tab><IF-STMT><tab><tab><tab>return vm.create_session(lock_type)<tab><tab>return None<tab>return session_obj",0,if vm :,if vm is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def _decorator(cls):<tab>for name, meth in inspect.getmembers(cls, inspect.isroutine):<tab><tab>if name not in cls.__dict__:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if not private and name.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab>if name in butnot:<tab><tab><tab>continue<tab><tab>setattr(cls, name, decorator(meth))<tab>return cls",0,"if name != ""__init__"" :",if inspect . isclass ( meth ) :,0.026407399022921448,3.983253478176822,0.3
"def pdb(message=""""):<tab>""""""Fall into pdb.""""""<tab>import pdb  # Required: we have just defined pdb as a function!<tab>if app and not app.useIpython:<tab><tab># from leo.core.leoQt import QtCore<tab><tab># This is more portable.<tab><tab>try:<tab><tab><tab>import PyQt5.QtCore as QtCore<tab><tab>except ImportError:<tab><tab><tab>try:<tab><tab><tab><tab>import PyQt4.QtCore as QtCore<tab><tab><tab>except ImportError:<tab><tab><tab><tab>QtCore = None<tab><tab><IF-STMT><tab><tab><tab># pylint: disable=no-member<tab><tab><tab>QtCore.pyqtRemoveInputHook()<tab>if message:<tab><tab>print(message)<tab>pdb.set_trace()",0,if QtCore :,if QtCore is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def get_s3_bucket_locations(buckets, self_log=False):<tab>""""""return (bucket_name, prefix) for all s3 logging targets""""""<tab>for b in buckets:<tab><tab>if b.get(""Logging""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if b[""Name""] != b[""Logging""][""TargetBucket""]:<tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""])<tab><tab>if not self_log and b[""Name""].startswith(""cf-templates-""):<tab><tab><tab>yield (b[""Name""], """")",0,if self_log :,"if ""TargetPrefix"" in b [ ""Logging"" ] :",0.04422835593777517,1e-10,0.45833333333333337
"def prepare_fields(self):<tab># See clean()<tab>for k, v in self.fields.items():<tab><tab>v._required = v.required<tab><tab>v.required = False<tab><tab>v.widget.is_required = False<tab><tab><IF-STMT><tab><tab><tab>v._required = v.one_required<tab><tab><tab>v.one_required = False<tab><tab><tab>v.widget.enabled_locales = self.locales",0,"if isinstance ( v , I18nFormField ) :","if hasattr ( v , ""one_required"" ) :",0.09166808520089226,16.59038701421971,0.48148148148148145
"def __pack__(self):<tab>new_values = []<tab>for i in xrange(len(self.__unpacked_data_elms__)):<tab><tab>for key in self.__keys__[i]:<tab><tab><tab>new_val = getattr(self, key)<tab><tab><tab>old_val = self.__unpacked_data_elms__[i]<tab><tab><tab># In the case of Unions, when the first changed value<tab><tab><tab># is picked the loop is exited<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>new_values.append(new_val)<tab>return struct.pack(self.__format__, *new_values)",1,if new_val != old_val :,if new_val != old_val :,0.75,100.00000000000004,1.0
"def run(self):<tab>pwd_found = []<tab>if constant.user_dpapi and constant.user_dpapi.unlocked:<tab><tab>main_vault_directory = os.path.join(<tab><tab><tab>constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>for vault_directory in os.listdir(main_vault_directory):<tab><tab><tab><tab>cred = constant.user_dpapi.decrypt_vault(<tab><tab><tab><tab><tab>os.path.join(main_vault_directory, vault_directory)<tab><tab><tab><tab>)<tab><tab><tab><tab>if cred:<tab><tab><tab><tab><tab>pwd_found.append(cred)<tab>return pwd_found",1,if os . path . exists ( main_vault_directory ) :,if os . path . exists ( main_vault_directory ) :,0.75,100.00000000000004,1.0
"def on_revision_plugin_revision_pre_save(**kwargs):<tab>instance = kwargs[""instance""]<tab>if kwargs.get(""created"", False):<tab><tab>update_previous_revision = (<tab><tab><tab>not instance.previous_revision<tab><tab><tab>and instance.plugin<tab><tab><tab>and instance.plugin.current_revision<tab><tab><tab>and instance.plugin.current_revision != instance<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>instance.previous_revision = instance.plugin.current_revision<tab>if not instance.revision_number:<tab><tab>try:<tab><tab><tab>previous_revision = instance.plugin.revision_set.latest()<tab><tab><tab>instance.revision_number = previous_revision.revision_number + 1<tab><tab>except RevisionPluginRevision.DoesNotExist:<tab><tab><tab>instance.revision_number = 1",1,if update_previous_revision :,if update_previous_revision :,0.5311706625951745,1e-10,1.0
"def __setattr__(self, name, value):<tab>super().__setattr__(name, value)<tab>field = self._fields.get(name)<tab>if field:<tab><tab>self.check_field_type(field, value)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(f""cannot set immutable {name} on {self!r}"")",0,if name in self . __ast_frozen_fields__ :,elif field . immutable :,0.01947850851540961,1.719207234832579,0.10714285714285714
"def _check_for_req_data(data):<tab>required_args = [""columns""]<tab>for arg in required_args:<tab><tab><IF-STMT><tab><tab><tab>return True, make_json_response(<tab><tab><tab><tab>status=400,<tab><tab><tab><tab>success=0,<tab><tab><tab><tab>errormsg=gettext(""Could not find required parameter ({})."").format(arg),<tab><tab><tab>)<tab>return False, """"",0,"if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :",if arg in data :,0.06519890862408206,0.32112755670249143,0.18355855855855854
"def train_dict(self, triples):<tab>""""""Train a dict lemmatizer given training (word, pos, lemma) triples.""""""<tab># accumulate counter<tab>ctr = Counter()<tab>ctr.update([(p[0], p[1], p[2]) for p in triples])<tab># find the most frequent mappings<tab>for p, _ in ctr.most_common():<tab><tab>w, pos, l = p<tab><tab><IF-STMT><tab><tab><tab>self.composite_dict[(w, pos)] = l<tab><tab>if w not in self.word_dict:<tab><tab><tab>self.word_dict[w] = l<tab>return",1,"if ( w , pos ) not in self . composite_dict :","if ( w , pos ) not in self . composite_dict :",0.75,100.00000000000004,1.0
"def render(type_, obj, context):<tab>if type_ == ""foreign_key"":<tab><tab>return None<tab>if type_ == ""column"":<tab><tab>if obj.name == ""y"":<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return ""col(%s)"" % obj.name<tab>if type_ == ""type"" and isinstance(obj, MySpecialType):<tab><tab>context.imports.add(""from mypackage import MySpecialType"")<tab><tab>return ""MySpecialType()""<tab>return ""render:%s"" % type_",0,"elif obj . name == ""q"" :","elif obj . name == ""y"" :",0.8217294420803809,70.71067811865478,1.0
"def test_knows_when_stepping_back_possible(self):<tab>iterator = bidirectional_iterator.BidirectionalIterator([0, 1, 2, 3])<tab>commands = [0, 1, 0, 0, 1, 1, 0, 0, 0, 0]<tab>command_count = 0<tab>results = []<tab>for _ in iterator:<tab><tab><IF-STMT><tab><tab><tab>iterator.step_back_on_next_iteration()<tab><tab>results.append(iterator.can_step_back())<tab><tab>command_count += 1<tab>assert results == [False, True, False, True, True, True, False, True, True, True]",0,if commands [ command_count ] :,if iterator . can_step_back ( ) :,0.023878899402271555,4.9323515694897075,0.5
"def flask_debug_true(context):<tab>if context.is_module_imported_like(""flask""):<tab><tab>if context.call_function_name_qual.endswith("".run""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return bandit.Issue(<tab><tab><tab><tab><tab>severity=bandit.HIGH,<tab><tab><tab><tab><tab>confidence=bandit.MEDIUM,<tab><tab><tab><tab><tab>text=""A Flask app appears to be run with debug=True, ""<tab><tab><tab><tab><tab>""which exposes the Werkzeug debugger and allows ""<tab><tab><tab><tab><tab>""the execution of arbitrary code."",<tab><tab><tab><tab><tab>lineno=context.get_lineno_for_call_arg(""debug""),<tab><tab><tab><tab>)",0,"if context . check_call_arg_value ( ""debug"" , ""True"" ) :","if context . get_lineno_for_call_arg ( ""debug"" ) :",0.07884551967319325,34.800798664720084,1.0
"def __exit__(self, exc_type, exc_val, exc_tb):<tab>if self._should_meta_profile:<tab><tab>end_time = timezone.now()<tab><tab>exception_raised = exc_type is not None<tab><tab>if exception_raised:<tab><tab><tab>Logger.error(<tab><tab><tab><tab>""Exception when performing meta profiling, dumping trace below""<tab><tab><tab>)<tab><tab><tab>traceback.print_exception(exc_type, exc_val, exc_tb)<tab><tab>request = getattr(DataCollector().local, ""request"", None)<tab><tab><IF-STMT><tab><tab><tab>curr = request.meta_time or 0<tab><tab><tab>request.meta_time = curr + _time_taken(self.start_time, end_time)",0,if request :,if request is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def get_job_offer(ja_list):<tab>ja_joff_map = {}<tab>offers = frappe.get_all(<tab><tab>""Job Offer"",<tab><tab>filters=[[""job_applicant"", ""IN"", ja_list]],<tab><tab>fields=[""name"", ""job_applicant"", ""status"", ""offer_date"", ""designation""],<tab>)<tab>for offer in offers:<tab><tab><IF-STMT><tab><tab><tab>ja_joff_map[offer.job_applicant] = [offer]<tab><tab>else:<tab><tab><tab>ja_joff_map[offer.job_applicant].append(offer)<tab>return ja_joff_map",0,if offer . job_applicant not in ja_joff_map . keys ( ) :,if offer . job_applicant not inja_joff_map :,0.29146097489314826,46.63449625549861,0.6458333333333334
"def _get_deepest(self, t):<tab>if isinstance(t, list):<tab><tab><IF-STMT><tab><tab><tab>return t[0]<tab><tab>else:<tab><tab><tab>for part in t:<tab><tab><tab><tab>res = self._get_deepest(part)<tab><tab><tab><tab>if res:<tab><tab><tab><tab><tab>return res<tab><tab><tab>return None<tab>return None",1,if len ( t ) == 1 :,if len ( t ) == 1 :,0.75,100.00000000000004,1.0
"def test_main(self):<tab>root = os.path.dirname(mutagen.__path__[0])<tab>skip = [os.path.join(root, ""docs""), os.path.join(root, ""venv"")]<tab>for dirpath, dirnames, filenames in os.walk(root):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for filename in filenames:<tab><tab><tab>if filename.endswith("".py""):<tab><tab><tab><tab>path = os.path.join(dirpath, filename)<tab><tab><tab><tab>self._check_encoding(path)",0,if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,if dirpath in skip :,0.02882376120868726,0.4028448990408853,0.140625
"def xview(self, mode=None, value=None, units=None):<tab>if type(value) == str:<tab><tab>value = float(value)<tab>if mode is None:<tab><tab>return self.hsb.get()<tab>elif mode == ""moveto"":<tab><tab>frameWidth = self.innerframe.winfo_reqwidth()<tab><tab>self._startX = value * float(frameWidth)<tab>else:  # mode == 'scroll'<tab><tab>clipperWidth = self._clipper.winfo_width()<tab><tab><IF-STMT><tab><tab><tab>jump = int(clipperWidth * self._jfraction)<tab><tab>else:<tab><tab><tab>jump = clipperWidth<tab><tab>self._startX = self._startX + value * jump<tab>self.reposition()",0,"if units == ""units"" :",if self . _jfraction is not None :,0.026407399022921448,5.669791110976001,0.23809523809523808
"def test_training_script_with_max_history_set(tmpdir):<tab>train_dialogue_model(<tab><tab>DEFAULT_DOMAIN_PATH,<tab><tab>DEFAULT_STORIES_FILE,<tab><tab>tmpdir.strpath,<tab><tab>interpreter=RegexInterpreter(),<tab><tab>policy_config=""data/test_config/max_hist_config.yml"",<tab><tab>kwargs={},<tab>)<tab>agent = Agent.load(tmpdir.strpath)<tab>for policy in agent.policy_ensemble.policies:<tab><tab><IF-STMT><tab><tab><tab>if type(policy) == FormPolicy:<tab><tab><tab><tab>assert policy.featurizer.max_history == 2<tab><tab><tab>else:<tab><tab><tab><tab>assert policy.featurizer.max_history == 5",0,"if hasattr ( policy . featurizer , ""max_history"" ) :",if policy . featurizer is not None :,0.062006595483074536,11.033017809693943,0.225
"def generate_auto_complete(self, base, iterable_var):<tab>sugg = []<tab>for entry in iterable_var:<tab><tab>compare_entry = entry<tab><tab>compare_base = base<tab><tab><IF-STMT><tab><tab><tab>compare_entry = compare_entry.lower()<tab><tab><tab>compare_base = compare_base.lower()<tab><tab>if self.compare_entries(compare_entry, compare_base):<tab><tab><tab>if entry not in sugg:<tab><tab><tab><tab>sugg.append(entry)<tab>return sugg",0,if self . settings . get ( IGNORE_CASE_SETTING ) :,"if isinstance ( compare_entry , str ) :",0.028107316037741373,7.073666451977357,0.27472527472527475
"def marker_expr(remaining):<tab>if remaining and remaining[0] == ""("":<tab><tab>result, remaining = marker(remaining[1:].lstrip())<tab><tab><IF-STMT><tab><tab><tab>raise SyntaxError(""unterminated parenthesis: %s"" % remaining)<tab><tab>remaining = remaining[1:].lstrip()<tab>else:<tab><tab>lhs, remaining = marker_var(remaining)<tab><tab>while remaining:<tab><tab><tab>m = MARKER_OP.match(remaining)<tab><tab><tab>if not m:<tab><tab><tab><tab>break<tab><tab><tab>op = m.groups()[0]<tab><tab><tab>remaining = remaining[m.end() :]<tab><tab><tab>rhs, remaining = marker_var(remaining)<tab><tab><tab>lhs = {""op"": op, ""lhs"": lhs, ""rhs"": rhs}<tab><tab>result = lhs<tab>return result, remaining",0,"if remaining [ 0 ] != "")"" :","elif remaining [ 0 ] == "")"" :",0.1956586942207979,58.77283725105324,0.6
"def __repr__(self):<tab>""""""Dump the class data in the format of a .netrc file.""""""<tab>rep = """"<tab>for host in self.hosts.keys():<tab><tab>attrs = self.hosts[host]<tab><tab>rep = rep + ""machine "" + host + ""\n\tlogin "" + repr(attrs[0]) + ""\n""<tab><tab><IF-STMT><tab><tab><tab>rep = rep + ""account "" + repr(attrs[1])<tab><tab>rep = rep + ""\tpassword "" + repr(attrs[2]) + ""\n""<tab>for macro in self.macros.keys():<tab><tab>rep = rep + ""macdef "" + macro + ""\n""<tab><tab>for line in self.macros[macro]:<tab><tab><tab>rep = rep + line<tab><tab>rep = rep + ""\n""<tab>return rep",1,if attrs [ 1 ] :,if attrs [ 1 ] :,0.75,100.00000000000004,1.0
"def _parse_policies(self, policies_yaml):<tab>for item in policies_yaml:<tab><tab>id_ = required_key(item, ""id"")<tab><tab>controls_ids = required_key(item, ""controls"")<tab><tab><IF-STMT><tab><tab><tab>if controls_ids != ""all"":<tab><tab><tab><tab>msg = ""Policy {id_} contains invalid controls list {controls}."".format(<tab><tab><tab><tab><tab>id_=id_, controls=str(controls_ids)<tab><tab><tab><tab>)<tab><tab><tab><tab>raise ValueError(msg)<tab><tab>self.policies[id_] = controls_ids",0,"if not isinstance ( controls_ids , list ) :",if id_ and controls_ids :,0.0168380461076173,16.0529461904344,0.3055555555555556
"def __set__(self, obj, value):  # noqa<tab>if (<tab><tab>value is not None<tab><tab>and self.field._currency_field.null<tab><tab>and not isinstance(value, MONEY_CLASSES + (Decimal,))<tab>):<tab><tab># For nullable fields we need either both NULL amount and currency or both NOT NULL<tab><tab>raise ValueError(""Missing currency value"")<tab>if isinstance(value, BaseExpression):<tab><tab><IF-STMT><tab><tab><tab>value = self.prepare_value(obj, value.value)<tab><tab>elif not isinstance(value, Func):<tab><tab><tab>validate_money_expression(obj, value)<tab><tab><tab>prepare_expression(value)<tab>else:<tab><tab>value = self.prepare_value(obj, value)<tab>obj.__dict__[self.field.name] = value",0,"if isinstance ( value , Value ) :","if hasattr ( value , ""value"" ) :",0.09166808520089226,20.556680845025987,0.5111111111111111
"def Children(self):<tab>""""""Returns a list of all of this object's owned (strong) children.""""""<tab>children = []<tab>for property, attributes in self._schema.iteritems():<tab><tab>(is_list, property_type, is_strong) = attributes[0:3]<tab><tab><IF-STMT><tab><tab><tab>if not is_list:<tab><tab><tab><tab>children.append(self._properties[property])<tab><tab><tab>else:<tab><tab><tab><tab>children.extend(self._properties[property])<tab>return children",0,if is_strong and property in self . _properties :,if is_strong :,0.024814632707681465,1e-10,0.27777777777777773
"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab>if i == start:<tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab>if i >= len(self.items):<tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab>if self.select(i):<tab><tab><tab>break<tab><tab>i += direction<tab><tab><IF-STMT><tab><tab><tab>start = 0",0,if start < 0 :,if i == len ( self . items ) - 1 :,0.023213484734668336,3.673526562988939,0.2
"def setup_displace(self):<tab>self.displace_mod = None<tab>self.displace_strength = 0.020<tab>for mod in self.obj.modifiers:<tab><tab><IF-STMT><tab><tab><tab>self.displace_mod = mod<tab><tab><tab>self.displace_strength = mod.strength<tab>if not self.displace_mod:<tab><tab>bpy.ops.object.modifier_add(type=""DISPLACE"")<tab><tab>self.displace_mod = self.obj.modifiers[-1]<tab><tab>self.displace_mod.show_expanded = False<tab><tab>self.displace_mod.strength = self.displace_strength<tab><tab>self.displace_mod.show_render = False<tab><tab>self.displace_mod.show_viewport = False",1,"if mod . type == ""DISPLACE"" :","if mod . type == ""DISPLACE"" :",0.75,100.00000000000004,1.0
"def set_json_body(cls, request_builder):<tab>old_body = request_builder.info.pop(""data"", {})<tab>if isinstance(old_body, abc.Mapping):<tab><tab>body = request_builder.info.setdefault(""json"", {})<tab><tab>for path in old_body:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls._sequence_path_resolver(path, old_body[path], body)<tab><tab><tab>else:<tab><tab><tab><tab>body[path] = old_body[path]<tab>else:<tab><tab>request_builder.info.setdefault(""json"", old_body)",0,"if isinstance ( path , tuple ) :","if isinstance ( old_body [ path ] , abc . Mapping ) :",0.07385196392688638,13.380161378318954,0.5630252100840336
"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""DBLL"")<tab>version = None<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100.00000000000004,1.0
"def test_prefix_lm(self):<tab>num_tries = 100<tab>original = ""This is a long test with lots of words to see if it works ok.""<tab>dataset = tf.data.Dataset.from_tensor_slices({""text"": [original] * num_tries})<tab>dataset = prep.prefix_lm(dataset)<tab>for data in test_utils.dataset_as_text(dataset):<tab><tab>inputs = data[""inputs""].replace(""prefix: "", """")<tab><tab>targets = data[""targets""]<tab><tab>reconstructed = """".join(inputs)<tab><tab><IF-STMT><tab><tab><tab>reconstructed += "" ""<tab><tab>reconstructed += """".join(targets)<tab><tab>self.assertEqual(reconstructed, original)",0,if inputs :,if len ( reconstructed ) > 0 :,0.04422835593777517,1e-10,0.3
"def leading_whitespace(self, inputstring):<tab>""""""Get leading whitespace.""""""<tab>leading_ws = []<tab>for i, c in enumerate(inputstring):<tab><tab>if c in legal_indent_chars:<tab><tab><tab>leading_ws.append(c)<tab><tab>else:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>self.indchar = c<tab><tab>elif c != self.indchar:<tab><tab><tab>self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i)<tab>return """".join(leading_ws)",0,if self . indchar is None :,if i == 0 :,0.02225082504991546,8.170609724417774,0.20833333333333331
"def __init__(self, text):<tab>self.mappings = {}<tab>self.attributes = collections.defaultdict(set)<tab>for stanza in _ParseTextProperties(text):<tab><tab>processor_id, single_values, multiple_values = self._ParseStanza(stanza)<tab><tab>if processor_id is None:  # can be 0<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>logging.warn(""Processor id %s seen twice in %s"", processor_id, text)<tab><tab><tab>continue<tab><tab>self.mappings[processor_id] = single_values<tab><tab>for key, value in multiple_values.items():<tab><tab><tab>self.attributes[key].add(value)",1,if processor_id in self . mappings :,if processor_id in self . mappings :,0.75,100.00000000000004,1.0
"def __iter__(self):<tab>for chunk in self.source:<tab><tab><IF-STMT><tab><tab><tab>self.wait_counter = 0<tab><tab><tab>yield chunk<tab><tab>elif self.wait_counter < self.wait_cntr_max:<tab><tab><tab>self.wait_counter += 1<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Data poller has been receiving no data for {} seconds.\n""<tab><tab><tab><tab>""Closing data poller"".format(self.wait_cntr_max * self.poll_period)<tab><tab><tab>)<tab><tab><tab>break<tab><tab>time.sleep(self.poll_period)",0,if chunk is not None :,if self . wait_counter == 0 :,0.023878899402271555,4.990049701936832,0.20833333333333331
"def download(self, prefetch=False):<tab>while self.running:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>(path, start, end) = self.prefetch_queue.get(<tab><tab><tab><tab><tab>True, 1<tab><tab><tab><tab>)  # 1 second time-out<tab><tab><tab>else:<tab><tab><tab><tab>(path, start, end) = self.download_queue.get(<tab><tab><tab><tab><tab>True, 1<tab><tab><tab><tab>)  # 1 second time-out<tab><tab><tab>self.download_data(path, start, end)<tab><tab><tab>if prefetch:<tab><tab><tab><tab>self.prefetch_queue.task_done()<tab><tab><tab>else:<tab><tab><tab><tab>self.download_queue.task_done()<tab><tab>except Queue.Empty:<tab><tab><tab>pass",1,if prefetch :,if prefetch :,0.5311706625951745,1e-10,1.0
"def process_messages(self, found_files, messages):<tab>for message in messages:<tab><tab><IF-STMT><tab><tab><tab>message.to_absolute_path(self.config.workdir)<tab><tab>else:<tab><tab><tab>message.to_relative_path(self.config.workdir)<tab>if self.config.blending:<tab><tab>messages = blender.blend(messages)<tab>filepaths = found_files.iter_module_paths(abspath=False)<tab>return postfilter.filter_messages(filepaths, self.config.workdir, messages)",0,if self . config . absolute_paths :,if self . config . absolute :,0.574113272471593,63.191456189157286,0.7714285714285715
"def set_indentation_params(self, ispythonsource, guess=1):<tab>if guess and ispythonsource:<tab><tab>i = self.guess_indent()<tab><tab><IF-STMT><tab><tab><tab>self.indentwidth = i<tab><tab>if self.indentwidth != self.tabwidth:<tab><tab><tab>self.usetabs = 0<tab>self.editwin.set_tabwidth(self.tabwidth)",0,if 2 <= i <= 8 :,if i > 0 :,0.02384665141965364,6.316906128202129,0.30952380952380953
"def to_tree(self, tagname=None, value=None, namespace=None):<tab>namespace = getattr(self, ""namespace"", namespace)<tab>if value is not None:<tab><tab><IF-STMT><tab><tab><tab>tagname = ""{%s}%s"" % (namespace, tagname)<tab><tab>el = Element(tagname)<tab><tab>el.text = safe_string(value)<tab><tab>return el",1,if namespace is not None :,if namespace is not None :,0.75,100.00000000000004,1.0
"def execute(self, argv: List) -> bool:<tab>if not argv:<tab><tab>print(""ERROR: You must give at least one module to download."")<tab><tab>return False<tab>for _arg in argv:<tab><tab>result = module_server.search_module(_arg)<tab><tab>CacheUpdater(""hub_download"", _arg).start()<tab><tab><IF-STMT><tab><tab><tab>url = result[0][""url""]<tab><tab><tab>with log.ProgressBar(""Download {}"".format(url)) as bar:<tab><tab><tab><tab>for file, ds, ts in utils.download_with_progress(url):<tab><tab><tab><tab><tab>bar.update(float(ds) / ts)<tab><tab>else:<tab><tab><tab>print(""ERROR: Could not find a HubModule named {}"".format(_arg))<tab>return True",1,if result :,if result :,0.5311706625951745,1e-10,1.0
"def visit_type_type(self, t: TypeType) -> ProperType:<tab>if isinstance(self.s, TypeType):<tab><tab>typ = self.meet(t.item, self.s.item)<tab><tab><IF-STMT><tab><tab><tab>typ = TypeType.make_normalized(typ, line=t.line)<tab><tab>return typ<tab>elif isinstance(self.s, Instance) and self.s.type.fullname == ""builtins.type"":<tab><tab>return t<tab>elif isinstance(self.s, CallableType):<tab><tab>return self.meet(t, self.s)<tab>else:<tab><tab>return self.default(self.s)",0,"if not isinstance ( typ , NoneType ) :","if isinstance ( typ , TypeType ) :",0.1884566599936256,37.70794596593207,0.2698412698412698
"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>items.append(item.name())<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",1,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,100.00000000000004,1.0
"def get_icon(self):<tab>if self.icon is not None:<tab><tab># Load it from an absolute filename<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24)<tab><tab><tab>except GObject.GError as ge:<tab><tab><tab><tab>pass<tab><tab># Load it from the current icon theme<tab><tab>(icon_name, extension) = os.path.splitext(os.path.basename(self.icon))<tab><tab>theme = Gtk.IconTheme()<tab><tab>if theme.has_icon(icon_name):<tab><tab><tab>return theme.load_icon(icon_name, 24, 0)",0,if os . path . exists ( self . icon ) :,if os . path . isabs ( self . icon ) :,0.6184795558138385,73.48889200874659,0.75
"def setup_logger():<tab>""""""Set up logger and add stdout handler""""""<tab>logging.setLoggerClass(IPDLogger)<tab>logger = logging.getLogger(""icloudpd"")<tab>has_stdout_handler = False<tab>for handler in logger.handlers:<tab><tab><IF-STMT><tab><tab><tab>has_stdout_handler = True<tab>if not has_stdout_handler:<tab><tab>formatter = logging.Formatter(<tab><tab><tab>fmt=""%(asctime)s %(levelname)-8s %(message)s"", datefmt=""%Y-%m-%d %H:%M:%S""<tab><tab>)<tab><tab>stdout_handler = logging.StreamHandler(stream=sys.stdout)<tab><tab>stdout_handler.setFormatter(formatter)<tab><tab>stdout_handler.name = ""stdoutLogger""<tab><tab>logger.addHandler(stdout_handler)<tab>return logger",1,"if handler . name == ""stdoutLogger"" :","if handler . name == ""stdoutLogger"" :",0.75,100.00000000000004,1.0
"def process_extra_fields(self):<tab>if self.instance.pk is not None:<tab><tab>if self.cleaned_data.get(""initialize"", None):<tab><tab><tab>self.instance.initialize()<tab><tab><IF-STMT><tab><tab><tab>self.instance.update_from_templates()",0,"if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :","if self . cleaned_data . get ( ""update_from_templates"" , None ) :",0.2554106801269208,46.5684173837697,0.44791666666666663
"def testFunctions(self):<tab>from zim.formats.wiki import match_url, is_url<tab>for input, input_is_url, tail in self.examples:<tab><tab>if input_is_url:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(match_url(input), input[: -len(tail)])<tab><tab><tab><tab>self.assertFalse(is_url(input))<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(match_url(input), input)<tab><tab><tab><tab>self.assertTrue(is_url(input))<tab><tab>else:<tab><tab><tab>self.assertEqual(match_url(input), None)<tab><tab><tab>self.assertFalse(is_url(input))",1,if tail :,if tail :,0.5311706625951745,1e-10,1.0
"def _SetUser(self, users):<tab>for user in users.items():<tab><tab>username = user[0]<tab><tab>settings = user[1]<tab><tab>room = settings[""room""][""name""] if ""room"" in settings else None<tab><tab>file_ = settings[""file""] if ""file"" in settings else None<tab><tab><IF-STMT><tab><tab><tab>if ""joined"" in settings[""event""]:<tab><tab><tab><tab>self._client.userlist.addUser(username, room, file_)<tab><tab><tab>elif ""left"" in settings[""event""]:<tab><tab><tab><tab>self._client.removeUser(username)<tab><tab>else:<tab><tab><tab>self._client.userlist.modUser(username, room, file_)",0,"if ""event"" in settings :","if ""room"" in settings :",0.39477865547525276,48.892302243490086,1.0
"def restoreTerminals(self, state):<tab>for name in list(self.terminals.keys()):<tab><tab><IF-STMT><tab><tab><tab>self.removeTerminal(name)<tab>for name, opts in state.items():<tab><tab>if name in self.terminals:<tab><tab><tab>term = self[name]<tab><tab><tab>term.setOpts(**opts)<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>opts = strDict(opts)<tab><tab><tab>self.addTerminal(name, **opts)<tab><tab>except:<tab><tab><tab>printExc(""Error restoring terminal %s (%s):"" % (str(name), str(opts)))",0,if name not in state :,if name in self . terminals :,0.19763179448162052,15.619699684601283,0.375
"def htmlify(path, text):<tab>fname = os.path.basename(path)<tab>if any((fnmatch.fnmatchcase(fname, p) for p in _patterns)):<tab><tab># Get file_id, skip if not in database<tab><tab>sql = ""SELECT files.id FROM files WHERE path = ? LIMIT 1""<tab><tab>row = _conn.execute(sql, (path,)).fetchone()<tab><tab><IF-STMT><tab><tab><tab>return ClangHtmlifier(_tree, _conn, path, text, row[0])<tab>return None",1,if row :,if row :,0.5311706625951745,1e-10,1.0
"def autoformat_filter_conv2d(fsize, in_depth, out_depth):<tab>if isinstance(fsize, int):<tab><tab>return [fsize, fsize, in_depth, out_depth]<tab>elif isinstance(fsize, (tuple, list, tf.TensorShape)):<tab><tab><IF-STMT><tab><tab><tab>return [fsize[0], fsize[1], in_depth, out_depth]<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""filter length error: ""<tab><tab><tab><tab>+ str(len(fsize))<tab><tab><tab><tab>+ "", only a length of 2 is supported.""<tab><tab><tab>)<tab>else:<tab><tab>raise Exception(""filter format error: "" + str(type(fsize)))",1,if len ( fsize ) == 2 :,if len ( fsize ) == 2 :,0.75,100.00000000000004,1.0
"def _rle_encode(string):<tab>new = b""""<tab>count = 0<tab>for cur in string:<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab>if count:<tab><tab><tab><tab>new += b""\0"" + bytes([count])<tab><tab><tab><tab>count = 0<tab><tab><tab>new += bytes([cur])<tab>return new",0,if not cur :,"if cur == b""\x00"" :",0.045150550804307965,5.522397783539471,0.45
"def is_clean(self):<tab>acceptable_statuses = {""external"", ""unversioned""}<tab>root = self._capture_output(""status"", ""--quiet"")<tab>for elem in root.findall(""./target/entry""):<tab><tab>status = elem.find(""./wc-status"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>log.debug(""Path %s is %s"", elem.get(""path""), status.get(""item""))<tab><tab>return False<tab>return True",0,"if status . get ( ""item"" , None ) in acceptable_statuses :","if status . get ( ""item"" ) in acceptable_statuses :",0.3212616666156257,74.97153770440843,0.6555555555555556
"def process(self, body, message):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>'Received an unexpected type ""%s"" for payload.' % type(body)<tab><tab><tab>)<tab><tab>response = self._handler.pre_ack_process(body)<tab><tab>self._dispatcher.dispatch(self._process_message, response)<tab>except:<tab><tab>LOG.exception(""%s failed to process message: %s"", self.__class__.__name__, body)<tab>finally:<tab><tab># At this point we will always ack a message.<tab><tab>message.ack()",0,"if not isinstance ( body , self . _handler . message_type ) :","if not isinstance ( body , self . _handler ) :",0.45467345168596496,62.14030503606604,1.0
"def page_file(self, page):<tab>try:<tab><tab>page = self.notebook.get_page(page)<tab><tab><IF-STMT><tab><tab><tab>return page.source<tab><tab>else:<tab><tab><tab>return None<tab>except PageNotFoundError:<tab><tab>return None",0,"if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :",if page . source :,0.055869504382620644,2.7474047213893553,0.22282608695652173
"def _optimize(self, solutions):<tab>best_a = None<tab>best_silhouette = None<tab>best_k = None<tab>for a, silhouette, k in solutions():<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif silhouette <= best_silhouette:<tab><tab><tab>break<tab><tab>best_silhouette = silhouette<tab><tab>best_a = a<tab><tab>best_k = k<tab>return best_a, best_silhouette, best_k",0,if best_silhouette is None :,if a > best_a and k > best_k :,0.0252788731101473,7.347053125977879,0.27272727272727276
"def _cancel_tasks_for_partitions(self, to_cancel_partitions):<tab># type: (Iterable[str]) -> None<tab>with self._lock:<tab><tab>_LOGGER.debug(<tab><tab><tab>""EventProcessor %r tries to cancel partitions %r"",<tab><tab><tab>self._id,<tab><tab><tab>to_cancel_partitions,<tab><tab>)<tab><tab>for partition_id in to_cancel_partitions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._consumers[partition_id].stop = True<tab><tab><tab><tab>_LOGGER.info(<tab><tab><tab><tab><tab>""EventProcessor %r has cancelled partition %r"",<tab><tab><tab><tab><tab>self._id,<tab><tab><tab><tab><tab>partition_id,<tab><tab><tab><tab>)",1,if partition_id in self . _consumers :,if partition_id in self . _consumers :,0.75,100.00000000000004,1.0
"def get_intersect_all(self, refine=False):<tab>result = None<tab>for source, parts in self._per_source.items():<tab><tab><IF-STMT><tab><tab><tab>result = parts<tab><tab>else:<tab><tab><tab>result.intersection_update(parts)<tab>if not result:<tab><tab>return None<tab>elif len(result) == 1:<tab><tab>return list(result)[0].item<tab>else:<tab><tab>solids = [p.item for p in result]<tab><tab>solid = solids[0].fuse(solids[1:])<tab><tab>if refine:<tab><tab><tab>solid = solid.removeSplitter()<tab><tab>return solid",1,if result is None :,if result is None :,0.75,100.00000000000004,1.0
"def geli_detach(self, pool, clear=False):<tab>failed = 0<tab>for ed in self.middleware.call_sync(<tab><tab>""datastore.query"",<tab><tab>""storage.encrypteddisk"",<tab><tab>[(""encrypted_volume"", ""="", pool[""id""])],<tab>):<tab><tab>dev = ed[""encrypted_provider""]<tab><tab>try:<tab><tab><tab>self.geli_detach_single(dev)<tab><tab>except Exception as ee:<tab><tab><tab>self.logger.warn(str(ee))<tab><tab><tab>failed += 1<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.geli_clear(dev)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>self.logger.warn(""Failed to clear %s: %s"", dev, e)<tab>return failed",1,if clear :,if clear :,0.5311706625951745,1e-10,1.0
def compute_lengths(batch_sizes):<tab>tmp_batch_sizes = np.copy(batch_sizes)<tab>lengths = []<tab>while True:<tab><tab>c = np.count_nonzero(tmp_batch_sizes > 0)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>lengths.append(c)<tab><tab>tmp_batch_sizes = np.array([b - 1 for b in tmp_batch_sizes])<tab>return np.array(lengths),1,if c == 0 :,if c == 0 :,0.75,100.00000000000004,1.0
"def _render_raw_list(bytes_items):<tab>flatten_items = []<tab>for item in bytes_items:<tab><tab><IF-STMT><tab><tab><tab>flatten_items.append(b"""")<tab><tab>elif isinstance(item, bytes):<tab><tab><tab>flatten_items.append(item)<tab><tab>elif isinstance(item, int):<tab><tab><tab>flatten_items.append(str(item).encode())<tab><tab>elif isinstance(item, list):<tab><tab><tab>flatten_items.append(_render_raw_list(item))<tab>return b""\n"".join(flatten_items)",1,if item is None :,if item is None :,0.75,100.00000000000004,1.0
"def update(self, new_config):<tab>jsonschema.validate(new_config, self.schema)<tab>config = {}<tab>for k, v in new_config.items():<tab><tab><IF-STMT><tab><tab><tab>config[k] = self[k]<tab><tab>else:<tab><tab><tab>config[k] = v<tab>self._config = config<tab>self.changed()",0,"if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :",if k in self :,0.04774506646739051,1.5818524479871872,0.5384615384615385
"def _encode_numpy(values, uniques=None, encode=False, check_unknown=True):<tab># only used in _encode below, see docstring there for details<tab>if uniques is None:<tab><tab>if encode:<tab><tab><tab>uniques, encoded = np.unique(values, return_inverse=True)<tab><tab><tab>return uniques, encoded<tab><tab>else:<tab><tab><tab># unique sorts<tab><tab><tab>return np.unique(values)<tab>if encode:<tab><tab><IF-STMT><tab><tab><tab>diff = _encode_check_unknown(values, uniques)<tab><tab><tab>if diff:<tab><tab><tab><tab>raise ValueError(""y contains previously unseen labels: %s"" % str(diff))<tab><tab>encoded = np.searchsorted(uniques, values)<tab><tab>return uniques, encoded<tab>else:<tab><tab>return uniques",1,if check_unknown :,if check_unknown :,0.5311706625951745,1e-10,1.0
"def restore_dtype_and_merge(arr, input_dtype):<tab>if isinstance(arr, list):<tab><tab>arr = [restore_dtype_and_merge(arr_i, input_dtype) for arr_i in arr]<tab><tab>shapes = [arr_i.shape for arr_i in arr]<tab><tab><IF-STMT><tab><tab><tab>arr = np.array(arr)<tab>if ia.is_np_array(arr):<tab><tab>arr = iadt.restore_dtypes_(arr, input_dtype)<tab>return arr",0,if len ( set ( shapes ) ) == 1 :,if len ( shapes ) == 0 :,0.15974423575173982,28.146399662233012,0.4175824175824176
"def proc_minute(d):<tab>if expanded[0][0] != ""*"":<tab><tab>diff_min = nearest_diff_method(d.minute, expanded[0], 60)<tab><tab>if diff_min is not None and diff_min != 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=59)<tab><tab><tab>else:<tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=0)<tab><tab><tab>return True, d<tab>return False, d",0,if is_prev :,"if expanded [ 0 ] [ 0 ] == ""*"" :",0.04157467851822123,1e-10,0.45588235294117646
"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab><IF-STMT><tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab>elif isinstance(v, bool):<tab><tab><tab>self._populate_bool(element, k, v)<tab><tab>elif isinstance(v, basestring):<tab><tab><tab>self._populate_str(element, k, v)<tab><tab>elif type(v) in [int, float, long, complex]:<tab><tab><tab>self._populate_number(element, k, v)",1,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,100.00000000000004,1.0
"def __createItemAttribute(self, item, function, preload):<tab>""""""Create the new widget, add it, and remove the old one""""""<tab>try:<tab><tab>self.__stack.addWidget(function(item, preload))<tab><tab># Remove the widget<tab><tab><IF-STMT><tab><tab><tab>oldWidget = self.__stack.widget(0)<tab><tab><tab>self.__stack.removeWidget(oldWidget)<tab><tab><tab>oldWidget.setParent(QtWidgets.QWidget())<tab>except Exception as e:<tab><tab>list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",0,if self . __stack . count ( ) > 1 :,if preload == 1 :,0.02208245887228144,5.594422941553801,0.32222222222222224
"def download_main(<tab>download, download_playlist, urls, playlist, output_dir, merge, info_only):<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>url = url[8:]<tab><tab>if not url.startswith(""http://""):<tab><tab><tab>url = ""http://"" + url<tab><tab>if playlist:<tab><tab><tab>download_playlist(<tab><tab><tab><tab>url, output_dir=output_dir, merge=merge, info_only=info_only<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>download(url, output_dir=output_dir, merge=merge, info_only=info_only)",0,"if url . startswith ( ""https://"" ) :","if url . startswith ( ""http"" ) :",0.5490406812970063,48.74858042804567,1.0
"def add_enc_zero(obj, enc_zero):<tab>if isinstance(obj, np.ndarray):<tab><tab>return obj + enc_zero<tab>elif isinstance(obj, Iterable):<tab><tab>return type(obj)(<tab><tab><tab>EncryptModeCalculator.add_enc_zero(o, enc_zero)<tab><tab><tab><IF-STMT><tab><tab><tab>else o + enc_zero<tab><tab><tab>for o in obj<tab><tab>)<tab>else:<tab><tab>return obj + enc_zero",0,"if isinstance ( o , Iterable )",if o is None,0.02282639622597323,8.9730240870212,0.2857142857142857
"def ensemble(self, pairs, other_preds):<tab>""""""Ensemble the dict with statistical model predictions.""""""<tab>lemmas = []<tab>assert len(pairs) == len(other_preds)<tab>for p, pred in zip(pairs, other_preds):<tab><tab>w, pos = p<tab><tab>if (w, pos) in self.composite_dict:<tab><tab><tab>lemma = self.composite_dict[(w, pos)]<tab><tab>elif w in self.word_dict:<tab><tab><tab>lemma = self.word_dict[w]<tab><tab>else:<tab><tab><tab>lemma = pred<tab><tab><IF-STMT><tab><tab><tab>lemma = w<tab><tab>lemmas.append(lemma)<tab>return lemmas",0,if lemma is None :,elif pred is None :,0.24887241987834818,39.76353643835252,0.42857142857142855
"def replace_to_6hex(color):<tab>""""""Validate and replace 3hex colors to 6hex ones.""""""<tab>if match(r""^#(?:[0-9a-fA-F]{3}){1,2}$"", color):<tab><tab><IF-STMT><tab><tab><tab>color = ""#{0}{0}{1}{1}{2}{2}"".format(color[1], color[2], color[3])<tab><tab>return color<tab>else:<tab><tab>exit(_(""Invalid color {}"").format(color))",1,if len ( color ) == 4 :,if len ( color ) == 4 :,0.75,100.00000000000004,1.0
"def computeMachineName(self):<tab>""""""Return the name of the current machine, i.e, HOSTNAME.""""""<tab># This is prepended to leoSettings.leo or myLeoSettings.leo<tab># to give the machine-specific setting name.<tab># How can this be worth doing??<tab>try:<tab><tab>import os<tab><tab>name = os.getenv(""HOSTNAME"")<tab><tab><IF-STMT><tab><tab><tab>name = os.getenv(""COMPUTERNAME"")<tab><tab>if not name:<tab><tab><tab>import socket<tab><tab><tab>name = socket.gethostname()<tab>except Exception:<tab><tab>name = """"<tab>return name",1,if not name :,if not name :,0.75,100.00000000000004,1.0
"def _git_dirty_working_directory(q, include_untracked):<tab>try:<tab><tab>cmd = [""git"", ""status"", ""--porcelain""]<tab><tab>if include_untracked:<tab><tab><tab>cmd += [""--untracked-files=normal""]<tab><tab>else:<tab><tab><tab>cmd += [""--untracked-files=no""]<tab><tab>status = _run_git_cmd(cmd)<tab><tab><IF-STMT><tab><tab><tab>q.put(bool(status))<tab><tab>else:<tab><tab><tab>q.put(None)<tab>except (subprocess.CalledProcessError, OSError, FileNotFoundError):<tab><tab>q.put(None)",0,if status is not None :,if status :,0.050438393472541504,1e-10,0.39999999999999997
"def runAndWaitWork(server, work):<tab>work.touch()<tab>thr = threading.Thread(target=workThread, args=(server, work))<tab>thr.setDaemon(True)<tab>thr.start()<tab># Wait around for done or timeout<tab>while True:<tab><tab>if work.isTimedOut():<tab><tab><tab>break<tab><tab># If the thread is done, lets get out.<tab><tab>if not thr.isAlive():<tab><tab><tab>break<tab><tab># If our parent, or some thread closes stdin,<tab><tab># time to pack up and go.<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(2)",0,if sys . stdin . closed :,if not thr . isAlive ( ) :,0.021135835738089467,7.267884212102741,0.25
"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True):<tab>try:<tab><tab>return self._read(count, timeout)<tab>except usb.USBError as e:<tab><tab>if DEBUG_COMM:<tab><tab><tab>log.info(<tab><tab><tab><tab>""read: e.errno=%s e.strerror=%s e.message=%s repr=%s""<tab><tab><tab><tab>% (e.errno, e.strerror, e.message, repr(e))<tab><tab><tab>)<tab><tab>if ignore_timeouts and is_timeout(e):<tab><tab><tab>return []<tab><tab><IF-STMT><tab><tab><tab>return []<tab><tab>raise",0,if ignore_non_errors and is_noerr ( e ) :,elif ignore_non_errors and is_error ( e ) :,0.26708726564936935,69.97522298221911,0.6
"def PrintHeader(self):  # print the header array<tab>if self.draw == False:<tab><tab>return<tab>for val in self.parent.header:<tab><tab>self.SetPrintFont(val[""Font""])<tab><tab>header_indent = val[""Indent""] * self.pwidth<tab><tab>text = val[""Text""]<tab><tab>htype = val[""Type""]<tab><tab><IF-STMT><tab><tab><tab>addtext = self.GetDate()<tab><tab>elif htype == ""Date & Time"":<tab><tab><tab>addtext = self.GetDateTime()<tab><tab>else:<tab><tab><tab>addtext = """"<tab><tab>self.OutTextPageWidth(<tab><tab><tab>text + addtext, self.pheader_margin, val[""Align""], header_indent, True<tab><tab>)",0,"if htype == ""Date"" :","if htype == ""Date & Time"" :",0.3672606578313526,58.14307369682194,1.0
"def get_intersect_all(self, refine=False):<tab>result = None<tab>for source, parts in self._per_source.items():<tab><tab>if result is None:<tab><tab><tab>result = parts<tab><tab>else:<tab><tab><tab>result.intersection_update(parts)<tab>if not result:<tab><tab>return None<tab>elif len(result) == 1:<tab><tab>return list(result)[0].item<tab>else:<tab><tab>solids = [p.item for p in result]<tab><tab>solid = solids[0].fuse(solids[1:])<tab><tab><IF-STMT><tab><tab><tab>solid = solid.removeSplitter()<tab><tab>return solid",1,if refine :,if refine :,0.5311706625951745,1e-10,1.0
"def captured_updateNode(self, context):<tab>if not self.updating_name_from_pointer:<tab><tab>font_datablock = self.get_bpy_data_from_name(self.fontname, bpy.data.fonts)<tab><tab><IF-STMT><tab><tab><tab>self.font_pointer = font_datablock<tab><tab><tab>updateNode(self, context)",0,if font_datablock :,if font_datablock is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def __add__(self, other):<tab>if isinstance(other, Vector2):<tab><tab># Vector + Vector -> Vector<tab><tab># Vector + Point -> Point<tab><tab># Point + Point -> Vector<tab><tab><IF-STMT><tab><tab><tab>_class = Vector2<tab><tab>else:<tab><tab><tab>_class = Point2<tab><tab>return _class(self.x + other.x, self.y + other.y)<tab>else:<tab><tab>assert hasattr(other, ""__len__"") and len(other) == 2<tab><tab>return Vector2(self.x + other[0], self.y + other[1])",1,if self . __class__ is other . __class__ :,if self . __class__ is other . __class__ :,0.75,100.00000000000004,1.0
"def _flatten_settings_from_form(self, settings, form, form_values):<tab>""""""Take a nested dict and return a flat dict of setting values.""""""<tab>setting_values = {}<tab>for field in form.c:<tab><tab><IF-STMT><tab><tab><tab>setting_values.update(<tab><tab><tab><tab>self._flatten_settings_from_form(<tab><tab><tab><tab><tab>settings, field, form_values[field._name]<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>elif field._name in settings:<tab><tab><tab>setting_values[field._name] = form_values[field._name]<tab>return setting_values",0,"if isinstance ( field , _ContainerMixin ) :",if field . _name in settings :,0.019627455172827622,6.892168295481103,0.3148148148148148
"def add_include_dirs(self, args):<tab>ids = []<tab>for a in args:<tab><tab># FIXME same hack, forcibly unpack from holder.<tab><tab>if hasattr(a, ""includedirs""):<tab><tab><tab>a = a.includedirs<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArguments(<tab><tab><tab><tab>""Include directory to be added is not an include directory object.""<tab><tab><tab>)<tab><tab>ids.append(a)<tab>self.include_dirs += ids",0,"if not isinstance ( a , IncludeDirs ) :","if not isinstance ( a , Directory ) :",0.5818820875411705,66.06328636027612,0.7142857142857143
"def _clip_array(array, config):<tab>if ""threshold"" in config.keys():<tab><tab>threshold = config[""threshold""]<tab>else:<tab><tab>abs_array = np.max(np.abs(array))<tab><tab><IF-STMT><tab><tab><tab>return array<tab><tab>threshold = np.percentile(np.abs(array), 99.99)<tab>return np.clip(array, -threshold, threshold)",0,if abs_array < 1.0 :,if abs_array == 0 :,0.06497877230811641,36.55552228545123,0.6190476190476191
def dfs(v: str) -> Iterator[Set[str]]:<tab>index[v] = len(stack)<tab>stack.append(v)<tab>boundaries.append(index[v])<tab>for w in edges[v]:<tab><tab><IF-STMT><tab><tab><tab>yield from dfs(w)<tab><tab>elif w not in identified:<tab><tab><tab>while index[w] < boundaries[-1]:<tab><tab><tab><tab>boundaries.pop()<tab>if boundaries[-1] == index[v]:<tab><tab>boundaries.pop()<tab><tab>scc = set(stack[index[v] :])<tab><tab>del stack[index[v] :]<tab><tab>identified.update(scc)<tab><tab>yield scc,0,if w not in index :,if w in identified :,0.054520976303194774,20.80119537801062,0.38095238095238093
"def create_balancer(<tab>self, name, members, protocol=""http"", port=80, algorithm=DEFAULT_ALGORITHM):<tab>balancer = self.ex_create_balancer_nowait(name, members, protocol, port, algorithm)<tab>timeout = 60 * 20<tab>waittime = 0<tab>interval = 2 * 15<tab>if balancer.id is not None:<tab><tab>return balancer<tab>else:<tab><tab>while waittime < timeout:<tab><tab><tab>balancers = self.list_balancers()<tab><tab><tab>for i in balancers:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return i<tab><tab><tab>waittime += interval<tab><tab><tab>time.sleep(interval)<tab>raise Exception(""Failed to get id"")",0,if i . name == balancer . name and i . id is not None :,if i . id is not None :,0.26799666825782675,30.70373468463369,0.2333333333333333
"def handle(self, scope: Scope, receive: Receive, send: Send) -> None:<tab>if self.methods and scope[""method""] not in self.methods:<tab><tab><IF-STMT><tab><tab><tab>raise HTTPException(status_code=405)<tab><tab>else:<tab><tab><tab>response = PlainTextResponse(""Method Not Allowed"", status_code=405)<tab><tab>await response(scope, receive, send)<tab>else:<tab><tab>await self.app(scope, receive, send)",0,"if ""app"" in scope :","if scope [ ""method"" ] in self . methods :",0.026964759067697196,5.300156689756295,0.3055555555555556
"def convert(data):<tab>result = []<tab>for d in data:<tab><tab># noinspection PyCompatibility<tab><tab>if isinstance(d, tuple) and len(d) == 2:<tab><tab><tab>result.append((d[0], None, d[1]))<tab><tab><IF-STMT><tab><tab><tab>result.append(d)<tab>return result",0,"elif isinstance ( d , basestring ) :","elif isinstance ( d , str ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def register_adapters():<tab>global adapters_registered<tab>if adapters_registered is True:<tab><tab>return<tab>try:<tab><tab>import pkg_resources<tab><tab>packageDir = pkg_resources.resource_filename(""pyamf"", ""adapters"")<tab>except:<tab><tab>packageDir = os.path.dirname(__file__)<tab>for f in glob.glob(os.path.join(packageDir, ""*.py"")):<tab><tab>mod = os.path.basename(f).split(os.path.extsep, 1)[0]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>register_adapter(mod[1:].replace(""_"", "".""), PackageImporter(mod))<tab><tab>except ImportError:<tab><tab><tab>pass<tab>adapters_registered = True",0,"if mod == ""__init__"" or not mod . startswith ( ""_"" ) :","if not mod . startswith ( ""__"" ) :",0.17405336926166268,35.684717380938594,0.3125
"def load_modules(<tab>to_load, load, attr, modules_dict, excluded_aliases, loading_message=None):<tab>if loading_message:<tab><tab>print(loading_message)<tab>for name in to_load:<tab><tab>module = load(name)<tab><tab>if module is None or not hasattr(module, attr):<tab><tab><tab>continue<tab><tab>cls = getattr(module, attr)<tab><tab>if hasattr(cls, ""initialize"") and not cls.initialize():<tab><tab><tab>continue<tab><tab>if hasattr(module, ""aliases""):<tab><tab><tab>for alias in module.aliases():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>modules_dict[alias] = module<tab><tab>else:<tab><tab><tab>modules_dict[name] = module<tab>if loading_message:<tab><tab>print()",0,if alias not in excluded_aliases :,if alias in excluded_aliases :,0.23319028329115196,61.29752413741059,0.5599999999999999
"def clean_items(event, items, variations):<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(_(""One or more items do not belong to this event.""))<tab><tab>if item.has_variations:<tab><tab><tab>if not any(var.item == item for var in variations):<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(<tab><tab><tab><tab><tab><tab>""One or more items has variations but none of these are in the variations list.""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",0,if event != item . event :,if not item . has_event :,0.04378500688306847,16.515821590069027,0.5714285714285714
"def __get_file_by_num(self, num, file_list, idx=0):<tab>for element in file_list:<tab><tab><IF-STMT><tab><tab><tab>return element<tab><tab>if element[3] and element[4]:<tab><tab><tab>i = self.__get_file_by_num(num, element[3], idx + 1)<tab><tab><tab>if not isinstance(i, int):<tab><tab><tab><tab>return i<tab><tab><tab>idx = i<tab><tab>else:<tab><tab><tab>idx += 1<tab>return idx",0,if idx == num :,if idx >= num :,0.33141502097923065,37.99178428257963,1.0
"def check(chip, xeddb, chipdb):<tab>all_inst = []<tab>undoc = []<tab>for inst in xeddb.recs:<tab><tab><IF-STMT><tab><tab><tab>if inst.undocumented:<tab><tab><tab><tab>undoc.append(inst)<tab><tab><tab>else:<tab><tab><tab><tab>all_inst.append(inst)<tab>return (all_inst, undoc)",0,if inst . isa_set in chipdb [ chip ] :,if inst . name == chip . name :,0.0974768160419002,14.530346490115708,0.42857142857142855
"def get_all_topic_src_files(self):<tab>""""""Retrieves the file paths of all the topics in directory""""""<tab>topic_full_paths = []<tab>topic_names = os.listdir(self.topic_dir)<tab>for topic_name in topic_names:<tab><tab># Do not try to load hidden files.<tab><tab><IF-STMT><tab><tab><tab>topic_full_path = os.path.join(self.topic_dir, topic_name)<tab><tab><tab># Ignore the JSON Index as it is stored with topic files.<tab><tab><tab>if topic_full_path != self.index_file:<tab><tab><tab><tab>topic_full_paths.append(topic_full_path)<tab>return topic_full_paths",0,"if not topic_name . startswith ( ""."" ) :","if topic_name . endswith ( "".json"" ) :",0.04084739796645766,36.6022984812999,0.38461538461538464
"def _get_element(dom_msi, tag_name, name=None, id_=None):<tab>""""""Get a xml element defined on Product.""""""<tab>product = dom_msi.getElementsByTagName(""Product"")[0]<tab>elements = product.getElementsByTagName(tag_name)<tab>for element in elements:<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>element.getAttribute(""Name"") == name<tab><tab><tab><tab>and element.getAttribute(""Id"") == id_<tab><tab><tab>):<tab><tab><tab><tab>return element<tab><tab>elif id_:<tab><tab><tab>if element.getAttribute(""Id"") == id_:<tab><tab><tab><tab>return element",0,if name and id_ :,if name :,0.06767423853569741,1e-10,0.7
"def __init__(self, *models):<tab>super().__init__()<tab>self.models = ModuleList(models)<tab>for m in models:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs)""<tab><tab><tab>)<tab>self.likelihood = LikelihoodList(*[m.likelihood for m in models])",0,"if not hasattr ( m , ""likelihood"" ) :",if m . likelihood is None :,0.017062028772160696,5.244835934727967,0.2361111111111111
"def _sniff(filename, oxlitype):<tab>try:<tab><tab>with open(filename, ""rb"") as fileobj:<tab><tab><tab>header = fileobj.read(4)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fileobj.read(1)  # skip the version number<tab><tab><tab><tab>ftype = fileobj.read(1)<tab><tab><tab><tab>if binascii.hexlify(ftype) == oxlitype:<tab><tab><tab><tab><tab>return True<tab><tab>return False<tab>except OSError:<tab><tab>return False",0,"if header == b""OXLI"" :","if header [ 0 ] == ""version"" :",0.05214495056051539,13.492767333412544,0.7272727272727273
"def convert_port_bindings(port_bindings):<tab>result = {}<tab>for k, v in six.iteritems(port_bindings):<tab><tab>key = str(k)<tab><tab>if ""/"" not in key:<tab><tab><tab>key += ""/tcp""<tab><tab><IF-STMT><tab><tab><tab>result[key] = [_convert_port_binding(binding) for binding in v]<tab><tab>else:<tab><tab><tab>result[key] = [_convert_port_binding(v)]<tab>return result",1,"if isinstance ( v , list ) :","if isinstance ( v , list ) :",0.75,100.00000000000004,1.0
"def input_data(self):<tab>gen = self.config.generator<tab># don't try running the generator if we specify an output file explicitly,<tab># otherwise generator may segfault and we end up returning the output file anyway<tab>if gen and (not self.config[""out""] or not self.config[""in""]):<tab><tab><IF-STMT><tab><tab><tab>self._run_generator(gen, args=self.config.generator_args)<tab><tab>if self._generated[0]:<tab><tab><tab>return self._generated[0]<tab># in file is optional<tab>return (<tab><tab>self._normalize(self.problem.problem_data[self.config[""in""]])<tab><tab>if self.config[""in""]<tab><tab>else b""""<tab>)",0,if self . _generated is None :,if self . config . generator :,0.14056531419355517,22.772101321113862,0.42857142857142855
"def __new__(cls, *tasks, **kwargs):<tab># This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z`<tab>if not kwargs and tasks:<tab><tab><IF-STMT><tab><tab><tab>tasks = tasks[0] if len(tasks) == 1 else tasks<tab><tab><tab>return reduce(operator.or_, tasks)<tab>return super(chain, cls).__new__(cls, *tasks, **kwargs)",0,if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,"if isinstance ( tasks , tuple ) :",0.01873097386782352,4.175853655216358,0.2804232804232804
"def get_file_sources():<tab>global _file_sources<tab>if _file_sources is None:<tab><tab>from galaxy.files import ConfiguredFileSources<tab><tab>file_sources = None<tab><tab>if os.path.exists(""file_sources.json""):<tab><tab><tab>file_sources_as_dict = None<tab><tab><tab>with open(""file_sources.json"", ""r"") as f:<tab><tab><tab><tab>file_sources_as_dict = json.load(f)<tab><tab><tab>if file_sources_as_dict is not None:<tab><tab><tab><tab>file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict)<tab><tab><IF-STMT><tab><tab><tab>ConfiguredFileSources.from_dict([])<tab><tab>_file_sources = file_sources<tab>return _file_sources",0,if file_sources is None :,if file_sources is not None :,0.2721091316413796,59.4603557501361,0.5599999999999999
"def InitializeColours(self):<tab>""""""Initializes the 16 custom colours in :class:`CustomPanel`.""""""<tab>curr = self._colourData.GetColour()<tab>self._colourSelection = -1<tab>for i in range(16):<tab><tab>c = self._colourData.GetCustomColour(i)<tab><tab><IF-STMT><tab><tab><tab>self._customColours[i] = self._colourData.GetCustomColour(i)<tab><tab>else:<tab><tab><tab>self._customColours[i] = wx.WHITE<tab><tab>if c == curr:<tab><tab><tab>self._colourSelection = i",0,if c . IsOk ( ) :,if c == curr :,0.04240600921794552,15.207218222740094,0.6
"def convert_obj_into_marshallable(self, obj):<tab>if isinstance(obj, self.marshalable_types):<tab><tab>return obj<tab>if isinstance(obj, array.array):<tab><tab>if obj.typecode == ""c"":<tab><tab><tab>return obj.tostring()<tab><tab><IF-STMT><tab><tab><tab>return obj.tounicode()<tab><tab>return obj.tolist()<tab>return self.class_to_dict(obj)",0,"if obj . typecode == ""u"" :","elif obj . typecode == ""b"" :",0.20574838742430368,58.14307369682194,0.6
"def run(self):<tab>self.run_command(""egg_info"")<tab>from glob import glob<tab>for pattern in self.match:<tab><tab>pattern = self.distribution.get_name() + ""*"" + pattern<tab><tab>files = glob(os.path.join(self.dist_dir, pattern))<tab><tab>files = [(os.path.getmtime(f), f) for f in files]<tab><tab>files.sort()<tab><tab>files.reverse()<tab><tab>log.info(""%d file(s) matching %s"", len(files), pattern)<tab><tab>files = files[self.keep :]<tab><tab>for (t, f) in files:<tab><tab><tab>log.info(""Deleting %s"", f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.unlink(f)",0,if not self . dry_run :,if os . path . isfile ( f ) :,0.021554938761049226,5.522397783539471,0.22916666666666669
"def render_token_list(self, tokens):<tab>result = []<tab>vars = []<tab>for token in tokens:<tab><tab>if token.token_type == TOKEN_TEXT:<tab><tab><tab>result.append(token.contents.replace(""%"", ""%%""))<tab><tab><IF-STMT><tab><tab><tab>result.append(""%%(%s)s"" % token.contents)<tab><tab><tab>vars.append(token.contents)<tab>return """".join(result), vars",1,elif token . token_type == TOKEN_VAR :,elif token . token_type == TOKEN_VAR :,1.0,100.00000000000004,1.0
"def _handle_raise(self, values, is_NAs, origins):<tab>for is_NA, origin in zip(is_NAs, origins):<tab><tab><IF-STMT><tab><tab><tab>msg = (<tab><tab><tab><tab>""Missing values detected. If you want rows with missing ""<tab><tab><tab><tab>""values to be automatically deleted in a list-wise ""<tab><tab><tab><tab>""manner (not recommended), please set dropna=True in ""<tab><tab><tab><tab>""the Bambi Model initialization.""<tab><tab><tab>)<tab><tab><tab>raise PatsyError(msg, origin)<tab>return values",0,if np . any ( is_NA ) :,if not values :,0.01860756028419845,4.238556455648295,0.3333333333333333
"def add_node_data(node_array, ntwk):<tab>node_ntwk = nx.Graph()<tab>newdata = {}<tab>for idx, data in ntwk.nodes(data=True):<tab><tab><IF-STMT><tab><tab><tab>newdata[""value""] = node_array[int(idx) - 1]<tab><tab><tab>data.update(newdata)<tab><tab><tab>node_ntwk.add_node(int(idx), **data)<tab>return node_ntwk",0,if not int ( idx ) == 0 :,if int ( idx ) < len ( node_array ) :,0.21447221805245478,21.401603033752977,0.27472527472527475
"def safe_parse_date(date_hdr):<tab>""""""Parse a Date: or Received: header into a unix timestamp.""""""<tab>try:<tab><tab>if "";"" in date_hdr:<tab><tab><tab>date_hdr = date_hdr.split("";"")[-1].strip()<tab><tab>msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr)))<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>return msg_ts<tab>except (ValueError, TypeError, OverflowError):<tab><tab>return None",0,if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,if msg_ts < 0 :,0.027705460322664216,2.6131505234865924,0.23310810810810811
"def _route_db(self, model, **hints):<tab>chosen_db = None<tab>for router in self.routers:<tab><tab>try:<tab><tab><tab>method = getattr(router, action)<tab><tab>except AttributeError:<tab><tab><tab># If the router doesn't have a method, skip to the next one.<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>chosen_db = method(model, **hints)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return chosen_db<tab>try:<tab><tab>return hints[""instance""]._state.db or DEFAULT_DB_ALIAS<tab>except KeyError:<tab><tab>return DEFAULT_DB_ALIAS",0,if chosen_db :,if chosen_db is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def get_keys(struct, ignore_first_level=False):<tab>res = []<tab>if isinstance(struct, dict):<tab><tab>if not ignore_first_level:<tab><tab><tab>keys = [x.split(""("")[0] for x in struct.keys()]<tab><tab><tab>res.extend(keys)<tab><tab>for key in struct:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logging.debug(""Ignored: %s: %s"", key, struct[key])<tab><tab><tab><tab>continue<tab><tab><tab>res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL))<tab>elif isinstance(struct, list):<tab><tab>for item in struct:<tab><tab><tab>res.extend(get_keys(item))<tab>return res",0,if key in IGNORED_KEYS :,if key in IGNORED_LEVEL :,0.39477865547525276,64.34588841607616,1.0
"def launch_app(self, fs_id):<tab>if fs_id in self.app_infos:<tab><tab>row = self.get_row_by_fsid(fs_id)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>app_info = self.app_infos[fs_id]<tab><tab>filepath = os.path.join(row[SAVEDIR_COL], row[SAVENAME_COL])<tab><tab>gfile = Gio.File.new_for_path(filepath)<tab><tab>app_info.launch(<tab><tab><tab>[<tab><tab><tab><tab>gfile,<tab><tab><tab>],<tab><tab><tab>None,<tab><tab>)<tab><tab>self.app_infos.pop(fs_id, None)",0,if not row :,if row is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def create_skipfile(files_changed, skipfile):<tab># File is likely to contain some garbage values at start,<tab># only the corresponding json should be parsed.<tab>json_pattern = re.compile(r""^\{.*\}"")<tab>for line in files_changed.readlines():<tab><tab><IF-STMT><tab><tab><tab>for filename in json.loads(line):<tab><tab><tab><tab>if ""/COMMIT_MSG"" in filename:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>skipfile.write(""+*/%s\n"" % filename)<tab>skipfile.write(""-*\n"")",0,"if re . match ( json_pattern , line ) :",if json_pattern . search ( line ) :,0.06630091485200443,23.801761257033814,0.32051282051282054
"def zscore(self, client, request, N):<tab>check_input(request, N != 2)<tab>key = request[1]<tab>db = client.db<tab>value = db.get(key)<tab>if value is None:<tab><tab>client.reply_bulk(None)<tab>elif not isinstance(value, self.zset_type):<tab><tab>client.reply_wrongtype()<tab>else:<tab><tab>score = value.score(request[2], None)<tab><tab><IF-STMT><tab><tab><tab>score = str(score).encode(""utf-8"")<tab><tab>client.reply_bulk(score)",0,if score is not None :,"if isinstance ( score , str ) :",0.023749771747382555,7.267884212102741,0.23214285714285715
"def _list_cases(suite):<tab>for test in suite:<tab><tab>if isinstance(test, unittest.TestSuite):<tab><tab><tab>_list_cases(test)<tab><tab>elif isinstance(test, unittest.TestCase):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(test.id())",0,if support . match_test ( test ) :,if test . id ( ) :,0.03976571592938584,11.260801105802155,0.4
"def Run(self):<tab>""""""The main run method of the client.""""""<tab>for thread in self._threads.values():<tab><tab>thread.start()<tab>logging.info(START_STRING)<tab>while True:<tab><tab>dead_threads = [tn for (tn, t) in self._threads.items() if not t.isAlive()]<tab><tab><IF-STMT><tab><tab><tab>raise FatalError(<tab><tab><tab><tab>""These threads are dead: %r. Shutting down..."" % dead_threads<tab><tab><tab>)<tab><tab>time.sleep(10)",1,if dead_threads :,if dead_threads :,0.5311706625951745,1e-10,1.0
"def _slice_queryset(queryset, order_by, per_page, start):<tab>page_len = int(per_page) + 1<tab>if start:<tab><tab><IF-STMT><tab><tab><tab>filter_name = ""%s__lte"" % order_by[1:]<tab><tab>else:<tab><tab><tab>filter_name = ""%s__gte"" % order_by<tab><tab>return queryset.filter(**{filter_name: start})[:page_len]<tab>return queryset[:page_len]",0,"if order_by . startswith ( ""-"" ) :","if order_by . startswith ( ""+"" ) :",0.5490406812970063,73.48889200874659,1.0
"def compute_timer_precision(timer):<tab>precision = None<tab>points = 0<tab>timeout = timeout_timer() + 1.0<tab>previous = timer()<tab>while timeout_timer() < timeout or points < 5:<tab><tab>for _ in XRANGE(10):<tab><tab><tab>t1 = timer()<tab><tab><tab>t2 = timer()<tab><tab><tab>dt = t2 - t1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>dt = t2 - previous<tab><tab><tab>if dt <= 0.0:<tab><tab><tab><tab>continue<tab><tab>if precision is not None:<tab><tab><tab>precision = min(precision, dt)<tab><tab>else:<tab><tab><tab>precision = dt<tab><tab>points += 1<tab><tab>previous = timer()<tab>return precision",0,if 0 < dt :,if dt <= 0.0 :,0.03654024892898815,11.478744233307168,0.45
"def findWorkingDir():<tab>frozen = getattr(sys, ""frozen"", """")<tab>if not frozen:<tab><tab>path = os.path.dirname(__file__)<tab>elif frozen in (""dll"", ""console_exe"", ""windows_exe"", ""macosx_app""):<tab><tab>path = os.path.dirname(<tab><tab><tab>os.path.dirname(os.path.dirname(os.path.dirname(__file__)))<tab><tab>)<tab>elif frozen:  # needed for PyInstaller<tab><tab><IF-STMT><tab><tab><tab>path = getattr(sys, ""_MEIPASS"", """")  # --onefile<tab><tab>else:<tab><tab><tab>path = os.path.dirname(sys.executable)  # --onedir<tab>else:<tab><tab>path = """"<tab>return path",0,"if getattr ( sys , ""_MEIPASS"" , """" ) is not None :","if hasattr ( sys , ""_MEIPASS"" ) :",0.1114294606777486,37.580522525232894,0.3529411764705882
"def CreateDataType(vmodlName, wsdlName, parent, version, props):<tab>with _lazyLock:<tab><tab>dic = [vmodlName, wsdlName, parent, version, props]<tab><tab>names = vmodlName.split(""."")<tab><tab><IF-STMT><tab><tab><tab>vmodlName = ""."".join(name[0].lower() + name[1:] for name in names)<tab><tab>_AddToDependencyMap(names)<tab><tab>typeNs = GetWsdlNamespace(version)<tab><tab>_dataDefMap[vmodlName] = dic<tab><tab>_wsdlDefMap[(typeNs, wsdlName)] = dic<tab><tab>_wsdlTypeMapNSs.add(typeNs)",0,if _allowCapitalizedNames :,if len ( names ) > 1 :,0.04422835593777517,1e-10,0.34545454545454546
"def ParseResponses(<tab>self,<tab>knowledge_base: rdf_client.KnowledgeBase,<tab>responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]:<tab>for response in responses:<tab><tab>if not isinstance(response, rdf_client_fs.StatEntry):<tab><tab><tab>raise TypeError(f""Unexpected response type: `{type(response)}`"")<tab><tab># TODO: `st_mode` has to be an `int`, not `StatMode`.<tab><tab>if stat.S_ISDIR(int(response.st_mode)):<tab><tab><tab>homedir = response.pathspec.path<tab><tab><tab>username = os.path.basename(homedir)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield rdf_client.User(username=username, homedir=homedir)",0,if username not in self . _ignore_users :,if username != knowledge_base . username :,0.03676852316447079,9.548450962056531,0.40277777777777773
"def process_question(qtxt):<tab>question = """"<tab>skip = False<tab>for letter in qtxt:<tab><tab>if letter == ""<"":<tab><tab><tab>skip = True<tab><tab>if letter == "">"":<tab><tab><tab>skip = False<tab><tab>if skip:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if letter == "" "":<tab><tab><tab><tab>letter = ""_""<tab><tab><tab>question += letter.lower()<tab>return question",0,"if letter . isalnum ( ) or letter == "" "" :",if not skip :,0.009434731772909408,2.002152301552759,0.26785714285714285
"def process_all(self, lines, times=1):<tab>gap = False<tab>for _ in range(times):<tab><tab>for line in lines:<tab><tab><tab>if gap:<tab><tab><tab><tab>self.write("""")<tab><tab><tab>self.process(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>gap = True<tab>return 0",0,if not is_command ( line ) :,"elif line . endswith ( ""\n"" ) :",0.03601197170986277,8.913765521398126,0.16666666666666666
"def _get(self, domain):<tab>with self.lock:<tab><tab>try:<tab><tab><tab>record = self.cache[domain]<tab><tab><tab>time_now = time.time()<tab><tab><tab>if time_now - record[""update""] > self.ttl:<tab><tab><tab><tab>record = None<tab><tab>except KeyError:<tab><tab><tab>record = None<tab><tab><IF-STMT><tab><tab><tab>record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0}<tab><tab># self.cache[domain] = record<tab><tab>return record",0,if not record :,if record is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def gen_constant_folding(cw):<tab>types = [""Int32"", ""Double"", ""BigInteger"", ""Complex""]<tab>for cur_type in types:<tab><tab>cw.enter_block(""if (constLeft.Value.GetType() == typeof(%s))"" % (cur_type,))<tab><tab>cw.enter_block(""switch (_op)"")<tab><tab>for op in ops:<tab><tab><tab>gen = getattr(op, ""genConstantFolding"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>gen(cw, cur_type)<tab><tab>cw.exit_block()<tab><tab>cw.exit_block()",1,if gen is not None :,if gen is not None :,0.75,100.00000000000004,1.0
"def unreferenced_dummy(self):<tab>for g, base in zip(self.evgroups, self.evbases):<tab><tab>for ind, j in enumerate(g):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>debug_print(<tab><tab><tab><tab><tab>""replacing unreferenced %d %s with dummy"" % ((base + ind), g[ind])<tab><tab><tab><tab>)<tab><tab><tab><tab>g[ind] = ""dummy""<tab><tab><tab><tab>self.evnum[base + ind] = ""dummy""",0,if not self . indexobj [ base + ind ] :,if j == base + ind :,0.054629663835327316,16.0529461904344,0.22916666666666669
"def handle_signature(self, sig: str, signode: desc_signature) -> Tuple[str, str]:<tab>for cls in self.__class__.__mro__:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""PyDecoratorMixin is deprecated. ""<tab><tab><tab><tab>""Please check the implementation of %s"" % cls,<tab><tab><tab><tab>RemovedInSphinx50Warning,<tab><tab><tab><tab>stacklevel=2,<tab><tab><tab>)<tab><tab><tab>break<tab>else:<tab><tab>warnings.warn(<tab><tab><tab>""PyDecoratorMixin is deprecated"", RemovedInSphinx50Warning, stacklevel=2<tab><tab>)<tab>ret = super().handle_signature(sig, signode)  # type: ignore<tab>signode.insert(0, addnodes.desc_addname(""@"", ""@""))<tab>return ret",0,"if cls . __name__ != ""DirectiveAdapter"" :","if cls . __name__ . startswith ( ""@"" ) :",0.24437377795063242,47.95482798967691,0.7333333333333334
"def _iter_lines(path=path, response=response, max_next=options.http_max_next):<tab>path.responses = []<tab>n = 0<tab>while response:<tab><tab>path.responses.append(response)<tab><tab>yield from response.iter_lines(decode_unicode=True)<tab><tab>src = response.links.get(""next"", {}).get(""url"", None)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>n += 1<tab><tab>if n > max_next:<tab><tab><tab>vd.warning(f""stopping at max {max_next} pages"")<tab><tab><tab>break<tab><tab>vd.status(f""fetching next page from {src}"")<tab><tab>response = requests.get(src, stream=True)",1,if not src :,if not src :,0.75,100.00000000000004,1.0
"def ordered_indices(self):<tab>with data_utils.numpy_seed(self.seed, self.epoch):<tab><tab># Used to store the order of indices of each dataset to use<tab><tab>indices = [<tab><tab><tab>np.random.permutation(len(dataset)) for dataset in self.datasets.values()<tab><tab>]<tab><tab># Keep track of which samples we've  used for each dataset<tab><tab>counters = [0 for _ in self.datasets]<tab><tab>sampled_indices = [<tab><tab><tab>self._sample(indices, counters) for _ in range(self.total_num_instances)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>sampled_indices.sort(key=lambda i: self.num_tokens(i))<tab><tab>return np.array(sampled_indices, dtype=np.int64)",0,if self . sort_indices :,if self . shuffle :,0.39477865547525276,28.641904579795423,0.7
"def _build_columns(self):<tab>self.columns = [Column() for col in self.keys]<tab>for row in self:<tab><tab>for (col_idx, col_val) in enumerate(row):<tab><tab><tab>col = self.columns[col_idx]<tab><tab><tab>col.append(col_val)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>col.is_quantity = False<tab>for (idx, key_name) in enumerate(self.keys):<tab><tab>self.columns[idx].name = key_name<tab>self.x = Column()<tab>self.ys = []",0,if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,if col . is_quantity :,0.00668934303836217,3.4106484601338583,0.2619047619047619
"def tearDown(self):<tab>subprocess_list = self.subprocess_list<tab>processes = subprocess_list.processes<tab>self.schedule.reset()<tab>del self.schedule<tab>for proc in processes:<tab><tab><IF-STMT><tab><tab><tab>terminate_process(proc.pid, kill_children=True, slow_stop=True)<tab>subprocess_list.cleanup()<tab>processes = subprocess_list.processes<tab>if processes:<tab><tab>for proc in processes:<tab><tab><tab>if proc.is_alive():<tab><tab><tab><tab>terminate_process(proc.pid, kill_children=True, slow_stop=False)<tab><tab>subprocess_list.cleanup()<tab>processes = subprocess_list.processes<tab>if processes:<tab><tab>log.warning(""Processes left running: %s"", processes)",1,if proc . is_alive ( ) :,if proc . is_alive ( ) :,0.75,100.00000000000004,1.0
"def colorNetwork(cls, network, nodesInNetwork, nodeByID=None):<tab>for node in nodesInNetwork:<tab><tab>node.use_custom_color = True<tab><tab>neededCopies = sum(socket.execution.neededCopies for socket in node.outputs)<tab><tab><IF-STMT><tab><tab><tab>color = (0.7, 0.9, 0.7)<tab><tab>else:<tab><tab><tab>color = (1.0, 0.3, 0.3)<tab><tab>node.color = color",0,if neededCopies == 0 :,if neededCopies > 0 :,0.33141502097923065,24.736929544091932,1.0
"def _init_warmup_scheduler(self, optimizer, states):<tab>updates_so_far = states.get(""number_training_updates"", 0)<tab>if self.warmup_updates > 0 and (<tab><tab>updates_so_far <= self.warmup_updates or self.hard_reset<tab>):<tab><tab>self.warmup_scheduler = optim.lr_scheduler.LambdaLR(optimizer, self._warmup_lr)<tab><tab><IF-STMT><tab><tab><tab>self.warmup_scheduler.load_state_dict(states[""warmup_scheduler""])<tab>else:<tab><tab>self.warmup_scheduler = None",0,"if states . get ( ""warmup_scheduler"" ) :","if ""warmup_scheduler"" in states :",0.020977836961063236,35.967895947086795,0.4
"def inner(self, *iargs, **ikwargs):<tab>try:<tab><tab>return getattr(super(VEXResilienceMixin, self), func)(*iargs, **ikwargs)<tab>except excs as e:<tab><tab>for exc, handler in zip(excs, handlers):<tab><tab><tab>if isinstance(e, exc):<tab><tab><tab><tab>v = getattr(self, handler)(*iargs, **ikwargs)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise<tab><tab><tab><tab>return v<tab><tab>assert False, ""this should be unreachable if Python is working correctly""",0,if v is raiseme :,if v is None :,0.39477865547525276,42.72870063962342,0.6666666666666666
"def unwrap_envelope(self, data, many):<tab>if many:<tab><tab>if data[""items""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.context[""total""] = len(data)<tab><tab><tab><tab>return data<tab><tab><tab>else:<tab><tab><tab><tab>self.context[""total""] = data[""total""]<tab><tab>else:<tab><tab><tab>self.context[""total""] = 0<tab><tab><tab>data = {""items"": []}<tab><tab>return data[""items""]<tab>return data",0,"if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :","if data [ ""total"" ] == 0 :",0.008876209527514672,3.4286942462594507,0.21710526315789475
"def __subclasscheck__(self, cls):<tab>if self.__origin__ is not None:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Parameterized generics cannot be used with class "" ""or instance checks""<tab><tab><tab>)<tab><tab>return False<tab>if self is Generic:<tab><tab>raise TypeError(<tab><tab><tab>""Class %r cannot be used with class "" ""or instance checks"" % self<tab><tab>)<tab>return super().__subclasscheck__(cls)",0,"if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :",if self is Parameterized :,0.004395308712033435,0.046975141313942724,0.21863799283154123
"def __init__(self, pyversions, coverage_service):<tab>build_matrix = """"<tab>for version in pyversions:<tab><tab>build_matrix += ""\n<tab>{},"".format(<tab><tab><tab>version<tab><tab><tab><IF-STMT><tab><tab><tab>else ""py{}"".format("""".join(version.split(""."")))<tab><tab>)<tab>coverage_package = """"<tab>if coverage_service:<tab><tab>coverage_package += ""\n<tab>{}"".format(coverage_service.package)<tab>coverage_package += ""\n""<tab>super(Tox, self).__init__(<tab><tab>""tox.ini"",<tab><tab>TEMPLATE.format(build_matrix=build_matrix, coverage_package=coverage_package),<tab>)",0,"if version . startswith ( ""pypy"" )","if ""."" not in version",0.02225082504991546,7.379782263475772,0.30952380952380953
"def _get_app(self, body=None):<tab>app = self._app<tab>if app is None:<tab><tab>try:<tab><tab><tab>tasks = self.tasks.tasks  # is a group<tab><tab>except AttributeError:<tab><tab><tab>tasks = self.tasks<tab><tab>if len(tasks):<tab><tab><tab>app = tasks[0]._app<tab><tab><IF-STMT><tab><tab><tab>app = body._app<tab>return app if app is not None else current_app",0,if app is None and body is not None :,elif body is not None :,0.35447568669451235,39.01126486653949,0.1111111111111111
"def logic():<tab>for v in [True, False, None, 0, True, None, None, 1]:<tab><tab>yield clk.posedge<tab><tab>xd.next = v<tab><tab><IF-STMT><tab><tab><tab>yd.next = zd.next = None<tab><tab>elif v:<tab><tab><tab>yd.next = zd.next = 11<tab><tab>else:<tab><tab><tab>yd.next = zd.next = 0",0,if v is None :,if v :,0.06767423853569741,1e-10,0.5
"def run(self):<tab>eid = self.start_episode()<tab>obs = self.env.reset()<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>action = self.env.action_space.sample()<tab><tab><tab>self.log_action(eid, obs, action)<tab><tab>else:<tab><tab><tab>action = self.get_action(eid, obs)<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>self.log_returns(eid, reward, info=info)<tab><tab>if done:<tab><tab><tab>self.end_episode(eid, obs)<tab><tab><tab>obs = self.env.reset()<tab><tab><tab>eid = self.start_episode()",0,if random . random ( ) < self . off_pol_frac :,if self . env . action_space :,0.07583277308746253,6.443030905386945,0.38666666666666666
"def tearDown(self):<tab>os.chdir(self.orig_working_dir)<tab>sys.argv = self.orig_argv<tab>sys.stdout = self.orig_stdout<tab>sys.stderr = self.orig_stderr<tab>for dirname in [""lv_LV"", ""ja_JP""]:<tab><tab>locale_dir = os.path.join(self.datadir, ""project"", ""i18n"", dirname)<tab><tab><IF-STMT><tab><tab><tab>shutil.rmtree(locale_dir)",1,if os . path . isdir ( locale_dir ) :,if os . path . isdir ( locale_dir ) :,0.75,100.00000000000004,1.0
"def sentry_set_scope(process_context, entity, project, email=None, url=None):<tab># Using GLOBAL_HUB means these tags will persist between threads.<tab># Normally there is one hub per thread.<tab>with sentry_sdk.hub.GLOBAL_HUB.configure_scope() as scope:<tab><tab>scope.set_tag(""process_context"", process_context)<tab><tab>scope.set_tag(""entity"", entity)<tab><tab>scope.set_tag(""project"", project)<tab><tab><IF-STMT><tab><tab><tab>scope.user = {""email"": email}<tab><tab>if url:<tab><tab><tab>scope.set_tag(""url"", url)",1,if email :,if email :,0.5311706625951745,1e-10,1.0
"def getDataMax(self):<tab>result = -Double.MAX_VALUE<tab>nCurves = self.chart.getNCurves()<tab>for i in range(nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if c.getYAxis() == Y_AXIS:<tab><tab><tab>nPoints = c.getNPoints()<tab><tab><tab>for j in range(nPoints):<tab><tab><tab><tab>result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY())<tab>if result == -Double.MAX_VALUE:<tab><tab>return Double.NaN<tab>return result",1,if not c . isVisible ( ) :,if not c . isVisible ( ) :,0.75,100.00000000000004,1.0
"def handle_starttag(self, tag, attrs):<tab>if tag == ""link"" and (""rel"", ""icon"") in attrs or (""rel"", ""shortcut icon"") in attrs:<tab><tab>href = None<tab><tab>icon_type = None<tab><tab>for attr, value in attrs:<tab><tab><tab>if attr == ""href"":<tab><tab><tab><tab>href = value<tab><tab><tab>elif attr == ""type"":<tab><tab><tab><tab>icon_type = value<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>mimetype = extension_to_mimetype(href.rpartition(""."")[2])<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>icon_type = mimetype<tab><tab><tab>if icon_type:<tab><tab><tab><tab>self.icons.append((href, icon_type))",0,if href :,"elif attr == ""mimetype"" :",0.03641519202841723,1e-10,0.2
"def get_version(version_file=STATIC_VERSION_FILE):<tab>version_info = get_static_version_info(version_file)<tab>version = version_info[""version""]<tab>if version == ""__use_git__"":<tab><tab>version = get_version_from_git()<tab><tab><IF-STMT><tab><tab><tab>version = get_version_from_git_archive(version_info)<tab><tab>if not version:<tab><tab><tab>version = Version(""unknown"", None, None)<tab><tab>return pep440_format(version)<tab>else:<tab><tab>return version",1,if not version :,if not version :,0.75,100.00000000000004,1.0
"def _Sleep(self, seconds):<tab>if threading.current_thread() is not self._worker_thread:<tab><tab>return self._original_sleep(seconds)<tab>self._time += seconds<tab>self._budget -= seconds<tab>while self._budget < 0:<tab><tab>self._worker_thread_turn.clear()<tab><tab>self._owner_thread_turn.set()<tab><tab>self._worker_thread_turn.wait()<tab><tab><IF-STMT><tab><tab><tab>raise FakeTimeline._WorkerThreadExit()",0,if self . _worker_thread_done :,if self . _owner_thread_exit :,0.39477865547525276,39.281465090051285,1.0
"def validate_attributes(self):<tab>if not (self.has_variants or self.variant_of):<tab><tab>return<tab>if not self.variant_based_on:<tab><tab>self.variant_based_on = ""Item Attribute""<tab>if self.variant_based_on == ""Item Attribute"":<tab><tab>attributes = []<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Attribute table is mandatory""))<tab><tab>for d in self.attributes:<tab><tab><tab>if d.attribute in attributes:<tab><tab><tab><tab>frappe.throw(<tab><tab><tab><tab><tab>_(<tab><tab><tab><tab><tab><tab>""Attribute {0} selected multiple times in Attributes Table""<tab><tab><tab><tab><tab>).format(d.attribute)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>attributes.append(d.attribute)",1,if not self . attributes :,if not self . attributes :,0.75,100.00000000000004,1.0
"def check_digest_auth(user, passwd):<tab>""""""Check user authentication using HTTP Digest auth""""""<tab>if request.headers.get(""Authorization""):<tab><tab>credentails = parse_authorization_header(request.headers.get(""Authorization""))<tab><tab>if not credentails:<tab><tab><tab>return<tab><tab>response_hash = response(<tab><tab><tab>credentails,<tab><tab><tab>passwd,<tab><tab><tab>dict(<tab><tab><tab><tab>uri=request.script_root + request.path,<tab><tab><tab><tab>body=request.data,<tab><tab><tab><tab>method=request.method,<tab><tab><tab>),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,"if credentails . get ( ""response"" ) == response_hash :","if response_hash == ""success"" :",0.015145994590617124,13.798394807255413,0.46875
"def _get_index_type(return_index_type, ctx):<tab>if return_index_type is None:  # pragma: no cover<tab><tab>if ctx.running_mode == RunningMode.local:<tab><tab><tab>return_index_type = ""object""<tab><tab><IF-STMT><tab><tab><tab>return_index_type = ""filename""<tab><tab>else:<tab><tab><tab>return_index_type = ""bytes""<tab>return return_index_type",0,elif ctx . running_mode == RunningMode . local_cluster :,elif ctx . running_mode == RunningMode . file :,0.6253119268751697,69.963138207288,0.7818181818181819
"def iter_event_handlers(<tab>self,<tab>resource: resources_.Resource,<tab>event: bodies.RawEvent,) -> Iterator[handlers.ResourceWatchingHandler]:<tab>warnings.warn(<tab><tab>""SimpleRegistry.iter_event_handlers() is deprecated; use ""<tab><tab>""ResourceWatchingRegistry.iter_handlers()."",<tab><tab>DeprecationWarning,<tab>)<tab>cause = _create_watching_cause(resource, event)<tab>for handler in self._handlers:<tab><tab>if not isinstance(handler, handlers.ResourceWatchingHandler):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>yield handler",0,"elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",elif not handler . is_watching_cause ( cause ) :,0.014190767473742502,5.251797049517794,0.22916666666666669
"def subprocess_post_check(<tab>completed_process: subprocess.CompletedProcess, raise_error: bool = True) -> None:<tab>if completed_process.returncode:<tab><tab><IF-STMT><tab><tab><tab>print(completed_process.stdout, file=sys.stdout, end="""")<tab><tab>if completed_process.stderr is not None:<tab><tab><tab>print(completed_process.stderr, file=sys.stderr, end="""")<tab><tab>if raise_error:<tab><tab><tab>raise PipxError(<tab><tab><tab><tab>f""{' '.join([str(x) for x in completed_process.args])!r} failed""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>logger.info(f""{' '.join(completed_process.args)!r} failed"")",1,if completed_process . stdout is not None :,if completed_process . stdout is not None :,0.75,100.00000000000004,1.0
"def __pow__(self, power):<tab>if power == 1:<tab><tab>return self<tab>if power == -1:<tab><tab># HACK: break cycle<tab><tab>from cirq.devices import line_qubit<tab><tab>decomposed = protocols.decompose_once_with_qubits(<tab><tab><tab>self, qubits=line_qubit.LineQid.for_gate(self), default=None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return NotImplemented<tab><tab>inverse_decomposed = protocols.inverse(decomposed, None)<tab><tab>if inverse_decomposed is None:<tab><tab><tab>return NotImplemented<tab><tab>return _InverseCompositeGate(self)<tab>return NotImplemented",1,if decomposed is None :,if decomposed is None :,0.75,100.00000000000004,1.0
"def tearDown(self):<tab>""""""Close the application after tests""""""<tab># set it back to it's old position so not to annoy users :-)<tab>self.old_pos = self.dlg.rectangle<tab># close the application<tab>self.dlg.menu_select(""File->Exit"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.app.UntitledNotepad[""Do&n't Save""].click()<tab><tab><tab>self.app.UntitledNotepad.wait_not(""visible"")<tab>except Exception:<tab><tab>pass<tab>finally:<tab><tab>self.app.kill()",0,"if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :","if self . app . UntitledNotepad [ ""Do&n"" ] . isVisible ( ) :",0.5177050604353614,63.12184805498121,0.7142857142857143
"def terminate_subprocess(proc, timeout=0.1, log=None):<tab><IF-STMT><tab><tab>if log:<tab><tab><tab>log.info(""Sending SIGTERM to %r"", proc)<tab><tab>proc.terminate()<tab><tab>timeout_time = time.time() + timeout<tab><tab>while proc.poll() is None and time.time() < timeout_time:<tab><tab><tab>time.sleep(0.02)<tab><tab>if proc.poll() is None:<tab><tab><tab>if log:<tab><tab><tab><tab>log.info(""Sending SIGKILL to %r"", proc)<tab><tab><tab>proc.kill()<tab>return proc.returncode",0,if proc . poll ( ) is None :,if proc . poll ( ) is not None :,0.5026338000327998,70.71067811865478,0.6984126984126985
"def validate(self, detection, expectation):<tab>config = SigmaConfiguration()<tab>self.basic_rule[""detection""] = detection<tab>with patch(""yaml.safe_load_all"", return_value=[self.basic_rule]):<tab><tab>parser = SigmaCollectionParser(""any sigma io"", config, None)<tab><tab>backend = SQLiteBackend(config, self.table)<tab><tab>assert len(parser.parsers) == 1<tab><tab>for p in parser.parsers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(expectation, backend.generate(p))<tab><tab><tab>elif isinstance(expectation, Exception):<tab><tab><tab><tab>self.assertRaises(type(expectation), backend.generate, p)",1,"if isinstance ( expectation , str ) :","if isinstance ( expectation , str ) :",0.75,100.00000000000004,1.0
"def makelist(d):<tab>""""""Convert d into a list if all the keys of d are integers.""""""<tab>if isinstance(d, dict):<tab><tab><IF-STMT><tab><tab><tab>return [makelist(d[k]) for k in sorted(d, key=int)]<tab><tab>else:<tab><tab><tab>return web.storage((k, makelist(v)) for k, v in d.items())<tab>else:<tab><tab>return d",0,if all ( isint ( k ) for k in d ) :,"if isinstance ( d , list ) :",0.02049586036594714,7.433761660133445,0.17142857142857143
"def __share_local_dir(self, lpath, rpath, fast):<tab>result = const.ENoError<tab>for walk in self.__walk_normal_file(lpath):<tab><tab>(dirpath, dirnames, filenames) = walk<tab><tab>for filename in filenames:<tab><tab><tab>rpart = os.path.relpath(dirpath, lpath)<tab><tab><tab>if rpart == ""."":<tab><tab><tab><tab>rpart = """"<tab><tab><tab>subr = self.__share_local_file(<tab><tab><tab><tab>joinpath(dirpath, filename),<tab><tab><tab><tab>posixpath.join(rpath, rpart, filename),<tab><tab><tab><tab>fast,<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = subr<tab>return result",1,if subr != const . ENoError :,if subr != const . ENoError :,0.75,100.00000000000004,1.0
"def _targets(self, sigmaparser):<tab># build list of matching target mappings<tab>targets = set()<tab>for condfield in self.conditions:<tab><tab><IF-STMT><tab><tab><tab>rulefieldvalues = sigmaparser.values[condfield]<tab><tab><tab>for condvalue in self.conditions[condfield]:<tab><tab><tab><tab>if condvalue in rulefieldvalues:<tab><tab><tab><tab><tab>targets.update(self.conditions[condfield][condvalue])<tab>return targets",1,if condfield in sigmaparser . values :,if condfield in sigmaparser . values :,0.75,100.00000000000004,1.0
"def _wrapped_view(request, *args, **kwargs):<tab># based on authority/decorators.py<tab>user = request.user<tab>if user.is_authenticated():<tab><tab>obj = _resolve_lookup(obj_lookup, kwargs)<tab><tab>perm_obj = _resolve_lookup(perm_obj_lookup, kwargs)<tab><tab>granted = access.has_perm_or_owns(user, perm, obj, perm_obj, owner_attr)<tab><tab><IF-STMT><tab><tab><tab>return view_func(request, *args, **kwargs)<tab># In all other cases, permission denied<tab>return HttpResponseForbidden()",0,if granted or user . has_perm ( perm ) :,if not granted :,0.01378824683147838,2.845073863275343,0.2619047619047619
"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint):<tab>cleaned_parts = []<tab>for earlier in earlier_parts:<tab><tab>earlier_part = earlier[""part""]<tab><tab>earlier_step = earlier[""step""]<tab><tab>found = False<tab><tab>for current in current_parts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab>if not found:<tab><tab><tab>cleaned_parts.append(dict(part=earlier_part, step=earlier_step))<tab>self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint)<tab>for expected in expected_parts:<tab><tab>self.assertThat(cleaned_parts, Contains(expected), hint)",0,"if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :",if current . part == earlier_part and current . step == earlier_step :,0.1366830038878682,16.956954218081997,0.39999999999999997
"def show_image(self, wnd_name, img):<tab>if wnd_name in self.named_windows:<tab><tab>if self.named_windows[wnd_name] == 0:<tab><tab><tab>self.named_windows[wnd_name] = 1<tab><tab><tab>self.on_create_window(wnd_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.capture_mouse(wnd_name)<tab><tab>self.on_show_image(wnd_name, img)<tab>else:<tab><tab>print(""show_image: named_window "", wnd_name, "" not found."")",0,if wnd_name in self . capture_mouse_windows :,if self . named_windows [ wnd_name ] == 1 :,0.03674787882433662,15.310245441182436,0.4
"def readlines(self, hint=None):<tab># Again, allow hint but ignore<tab>body = self._get_body()<tab>rest = body[self.position :]<tab>self.position = len(body)<tab>result = []<tab>while 1:<tab><tab>next = rest.find(""\r\n"")<tab><tab><IF-STMT><tab><tab><tab>result.append(rest)<tab><tab><tab>break<tab><tab>result.append(rest[: next + 2])<tab><tab>rest = rest[next + 2 :]<tab>return result",0,if next == - 1 :,if next < 0 :,0.051719732411378776,15.848738972120703,0.6
"def __lt__(self, other):<tab>olen = len(other)<tab>for i in range(olen):<tab><tab>try:<tab><tab><tab>c = self[i] < other[i]<tab><tab>except IndexError:<tab><tab><tab># self must be shorter<tab><tab><tab>return True<tab><tab>if c:<tab><tab><tab>return c<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return len(self) < olen",0,elif other [ i ] < self [ i ] :,elif other [ i ] != c :,0.30977141736350605,37.40548510898885,0.5982905982905983
"def social_user(backend, uid, user=None, *args, **kwargs):<tab>provider = backend.name<tab>social = backend.strategy.storage.user.get_social_auth(provider, uid)<tab>if social:<tab><tab>if user and social.user != user:<tab><tab><tab>msg = ""This account is already in use.""<tab><tab><tab>raise AuthAlreadyAssociated(backend, msg)<tab><tab><IF-STMT><tab><tab><tab>user = social.user<tab>return {<tab><tab>""social"": social,<tab><tab>""user"": user,<tab><tab>""is_new"": user is None,<tab><tab>""new_association"": social is None,<tab>}",0,elif not user :,if user is None :,0.16356362769640292,12.703318703865365,0.09523809523809523
"def markUVs(self, indices=None):<tab>if isinstance(indices, tuple):<tab><tab>indices = indices[0]<tab>ntexco = len(self.texco)<tab>if indices is None:<tab><tab>self.utexc = True<tab>else:<tab><tab>if self.utexc is False:<tab><tab><tab>self.utexc = np.zeros(ntexco, dtype=bool)<tab><tab><IF-STMT><tab><tab><tab>self.utexc[indices] = True",0,if self . utexc is not True :,elif indices not in self . utexc :,0.15766756237181095,23.356898886410015,0.1
"def destination(self, type, name, arglist):<tab>classname = ""ResFunction""<tab>listname = ""functions""<tab>if arglist:<tab><tab>t, n, m = arglist[0]<tab><tab><IF-STMT><tab><tab><tab>classname = ""ResMethod""<tab><tab><tab>listname = ""resmethods""<tab>return classname, listname",0,"if t == ""Handle"" and m == ""InMode"" :","if t == ""ResMethod"" and m == ""InMode"" :",0.7998893192644195,80.03203203845001,1.0
"def select(self, regions, register):<tab>self.view.sel().clear()<tab>to_store = []<tab>for r in regions:<tab><tab>self.view.sel().add(r)<tab><tab>if register:<tab><tab><tab>to_store.append(self.view.substr(self.view.full_line(r)))<tab>if register:<tab><tab>text = """".join(to_store)<tab><tab><IF-STMT><tab><tab><tab>text = text + ""\n""<tab><tab>state = State(self.view)<tab><tab>state.registers[register] = [text]",0,"if not text . endswith ( ""\n"" ) :",if self . view . full_line ( r ) :,0.030873964193229592,8.516593018819643,0.25
"def _skip_start(self):<tab>start, stop = self.start, self.stop<tab>for chunk in self.app_iter:<tab><tab>self._pos += len(chunk)<tab><tab>if self._pos < start:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return b""""<tab><tab>else:<tab><tab><tab>chunk = chunk[start - self._pos :]<tab><tab><tab>if stop is not None and self._pos > stop:<tab><tab><tab><tab>chunk = chunk[: stop - self._pos]<tab><tab><tab><tab>assert len(chunk) == stop - start<tab><tab><tab>return chunk<tab>else:<tab><tab>raise StopIteration()",0,elif self . _pos == start :,if start is None and self . _pos >= stop :,0.12293842844661548,22.242469397936766,0.07407407407407407
"def start(self):<tab>self.on_config_change()<tab>self.start_config_watch()<tab>try:<tab><tab>if self.config[""MITMf""][""DNS""][""tcp""].lower() == ""on"":<tab><tab><tab>self.startTCP()<tab><tab>else:<tab><tab><tab>self.startUDP()<tab>except socket.error as e:<tab><tab><IF-STMT><tab><tab><tab>shutdown(<tab><tab><tab><tab>""\n[DNS] Unable to start DNS server on port {}: port already in use"".format(<tab><tab><tab><tab><tab>self.config[""MITMf""][""DNS""][""port""]<tab><tab><tab><tab>)<tab><tab><tab>)",0,"if ""Address already in use"" in e :",if e . errno == errno . EADDRINUSE :,0.01809616860937894,5.522397783539471,0.2857142857142857
"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab>if other not in self.ignoreExprs:<tab><tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",1,if self . expr is not None :,if self . expr is not None :,0.75,100.00000000000004,1.0
"def test_relative_deploy_path_override():<tab>s = Site(TEST_SITE_ROOT)<tab>s.load()<tab>res = s.content.resource_from_relative_path(<tab><tab>""blog/2010/december/merry-christmas.html""<tab>)<tab>res.relative_deploy_path = ""blog/2010/december/happy-holidays.html""<tab>for page in s.content.walk_resources():<tab><tab><IF-STMT><tab><tab><tab>assert page.relative_deploy_path == ""blog/2010/december/happy-holidays.html""<tab><tab>else:<tab><tab><tab>assert page.relative_deploy_path == Folder(page.relative_path)",0,if res . source_file == page . source_file :,"if page . relative_deploy_path == ""/"" :",0.09584510318274436,9.55204080682377,0.4807692307692308
"def _parser(cls, buf):<tab>tlvs = []<tab>while buf:<tab><tab>tlv_type = LLDPBasicTLV.get_type(buf)<tab><tab>tlv = cls._tlv_parsers[tlv_type](buf)<tab><tab>tlvs.append(tlv)<tab><tab>offset = LLDP_TLV_SIZE + tlv.len<tab><tab>buf = buf[offset:]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>assert len(buf) > 0<tab>lldp_pkt = cls(tlvs)<tab>assert lldp_pkt._tlvs_len_valid()<tab>assert lldp_pkt._tlvs_valid()<tab>return lldp_pkt, None, buf",0,if tlv . tlv_type == LLDP_TLV_END :,if len ( tlvs ) == 0 :,0.021135835738089467,6.506124089578341,0.3
"def _do_pull(self, repo, pull_kwargs, silent, ignore_pull_failures):<tab>try:<tab><tab>output = self.client.pull(repo, **pull_kwargs)<tab><tab>if silent:<tab><tab><tab>with open(os.devnull, ""w"") as devnull:<tab><tab><tab><tab>yield from stream_output(output, devnull)<tab><tab>else:<tab><tab><tab>yield from stream_output(output, sys.stdout)<tab>except (StreamOutputError, NotFound) as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>log.error(str(e))",0,if not ignore_pull_failures :,if ignore_pull_failures :,0.09648852821835877,1e-10,0.6
def _collect_bytecode(ordered_code):<tab>bytecode_blocks = []<tab>stack = [ordered_code]<tab>while stack:<tab><tab>code = stack.pop()<tab><tab>bytecode_blocks.append(code.co_code)<tab><tab>for const in code.co_consts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>stack.append(const)<tab>return bytecode_blocks,0,"if isinstance ( const , blocks . OrderedCode ) :",if const . co_code == ordered_code :,0.06608611332628242,4.789232204309912,0.2948717948717949
"def displayhook(value):<tab>if value is None:<tab><tab>return<tab>builtins = modules[""builtins""]<tab># Set '_' to None to avoid recursion<tab>builtins._ = None<tab>text = repr(value)<tab>try:<tab><tab>local_stdout = stdout<tab>except NameError as e:<tab><tab>raise RuntimeError(""lost sys.stdout"") from e<tab>try:<tab><tab>local_stdout.write(text)<tab>except UnicodeEncodeError:<tab><tab>bytes = text.encode(local_stdout.encoding, ""backslashreplace"")<tab><tab><IF-STMT><tab><tab><tab>local_stdout.buffer.write(bytes)<tab><tab>else:<tab><tab><tab>text = bytes.decode(local_stdout.encoding, ""strict"")<tab><tab><tab>local_stdout.write(text)<tab>local_stdout.write(""\n"")<tab>builtins._ = value",1,"if hasattr ( local_stdout , ""buffer"" ) :","if hasattr ( local_stdout , ""buffer"" ) :",0.75,100.00000000000004,1.0
"def _analyze(self):<tab>lines = open(self.log_path, ""r"").readlines()<tab>prev_line = None<tab>for line in lines:<tab><tab>if line.startswith(""ERROR:"") and prev_line and prev_line.startswith(""=""):<tab><tab><tab>self.errors.append(line[len(""ERROR:"") :].strip())<tab><tab><IF-STMT><tab><tab><tab>self.failures.append(line[len(""FAIL:"") :].strip())<tab><tab>prev_line = line",1,"elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :","elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :",1.0,100.00000000000004,1.0
"def _flush(self):<tab>if self._data:<tab><tab>if self._last is not None:<tab><tab><tab>text = """".join(self._data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert self._last.tail is None, ""internal error (tail)""<tab><tab><tab><tab>self._last.tail = text<tab><tab><tab>else:<tab><tab><tab><tab>assert self._last.text is None, ""internal error (text)""<tab><tab><tab><tab>self._last.text = text<tab><tab>self._data = []",0,if self . _tail :,if self . tail :,0.39477865547525276,40.93653765389909,0.7
"def write(self, chunk):<tab>consumer = self._current_consumer<tab>server_side = consumer.server_side<tab>if server_side:<tab><tab>server_side.data_received(chunk)<tab>else:<tab><tab>consumer.message += chunk<tab><tab>assert consumer.in_parser.execute(chunk, len(chunk)) == len(chunk)<tab><tab><IF-STMT><tab><tab><tab>consumer.finished()",0,if consumer . in_parser . is_message_complete ( ) :,if consumer . finished :,0.06668418984860812,5.78270080339587,0.7307692307692308
"def _api_change_cat(name, output, kwargs):<tab>""""""API: accepts output, value(=nzo_id), value2(=category)""""""<tab>value = kwargs.get(""value"")<tab>value2 = kwargs.get(""value2"")<tab>if value and value2:<tab><tab>nzo_id = value<tab><tab>cat = value2<tab><tab><IF-STMT><tab><tab><tab>cat = None<tab><tab>result = sabnzbd.NzbQueue.change_cat(nzo_id, cat)<tab><tab>return report(output, keyword=""status"", data=bool(result > 0))<tab>else:<tab><tab>return report(output, _MSG_NO_VALUE)",0,"if cat == ""None"" :",if cat is None :,0.06497877230811641,13.943458243384402,0.5
"def get_allocated_address(<tab>self, config: ActorPoolConfig, allocated: allocated_type) -> str:<tab>addresses = config.get_external_addresses(label=self.label)<tab>for addr in addresses:<tab><tab>occupied = False<tab><tab>for strategy, _ in allocated.get(addr, dict()).values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>occupied = True<tab><tab><tab><tab>break<tab><tab>if not occupied:<tab><tab><tab>return addr<tab>raise NoIdleSlot(<tab><tab>f""No idle slot for creating actor "" f""with label {self.label}, mark {self.mark}""<tab>)",0,if strategy == self :,if strategy == self . strategy :,0.28545691328288475,54.10822690539397,0.8809523809523809
"def schedule_logger(job_id=None, delete=False):<tab>if not job_id:<tab><tab>return getLogger(""fate_flow_schedule"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>with LoggerFactory.lock:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>for key in LoggerFactory.schedule_logger_dict.keys():<tab><tab><tab><tab><tab><tab>if job_id in key:<tab><tab><tab><tab><tab><tab><tab>del LoggerFactory.schedule_logger_dict[key]<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab><tab>key = job_id + ""schedule""<tab><tab>if key in LoggerFactory.schedule_logger_dict:<tab><tab><tab>return LoggerFactory.schedule_logger_dict[key]<tab><tab>return LoggerFactory.get_schedule_logger(job_id)",1,if delete :,if delete :,0.5311706625951745,1e-10,1.0
"def quick_load(tool_file, async_load=True):<tab>try:<tab><tab>tool = self.load_tool(tool_file, tool_cache_data_dir)<tab><tab>self.__add_tool(tool, load_panel_dict, elems)<tab><tab># Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file.<tab><tab>key = ""tool_%s"" % str(tool.id)<tab><tab>integrated_elems[key] = tool<tab><tab><IF-STMT><tab><tab><tab>self._load_tool_panel()<tab><tab><tab>self._save_integrated_tool_panel()<tab><tab>return tool.id<tab>except Exception:<tab><tab>log.exception(""Failed to load potential tool %s."", tool_file)<tab><tab>return None",1,if async_load :,if async_load :,0.5311706625951745,1e-10,1.0
"def _get_default_ordering(self):<tab>try:<tab><tab>ordering = super(DocumentChangeList, self)._get_default_ordering()<tab>except AttributeError:<tab><tab>ordering = []<tab><tab>if self.model_admin.ordering:<tab><tab><tab>ordering = self.model_admin.ordering<tab><tab><IF-STMT><tab><tab><tab>ordering = self.lookup_opts.ordering<tab>return ordering",0,elif self . lookup_opts . ordering :,elif self . lookup_opts and self . lookup_opts . ordering :,0.5593353110930667,55.12003357447276,0.5047619047619047
"def names(self, persistent=None):<tab>u = set()<tab>result = []<tab>for s in [<tab><tab>self.__storage(None),<tab><tab>self.__storage(self.__category),<tab>]:<tab><tab>for b in s:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if b.name.startswith(""__""):<tab><tab><tab><tab>continue<tab><tab><tab>if b.name not in u:<tab><tab><tab><tab>result.append(b.name)<tab><tab><tab><tab>u.add(b.name)<tab>return result",0,if persistent is not None and b . persistent != persistent :,if b . name is None :,0.08628261598133793,7.335725659408425,0.2888888888888889
"def common_check_get_messages_query(<tab>self, query_params: Dict[str, object], expected: str) -> None:<tab>user_profile = self.example_user(""hamlet"")<tab>request = POSTRequestMock(query_params, user_profile)<tab>with queries_captured() as queries:<tab><tab>get_messages_backend(request, user_profile)<tab>for query in queries:<tab><tab><IF-STMT><tab><tab><tab>sql = str(query[""sql""]).replace("" /* get_messages */"", """")<tab><tab><tab>self.assertEqual(sql, expected)<tab><tab><tab>return<tab>raise AssertionError(""get_messages query not found"")",0,"if ""/* get_messages */"" in query [ ""sql"" ] :","if query [ ""sql"" ] :",0.20943904012107384,24.909923021496894,0.48333333333333334
"def _activate_only_current_top_active():<tab>for i in range(0, len(current_sequence().tracks) - 1):<tab><tab><IF-STMT><tab><tab><tab>current_sequence().tracks[i].active = True<tab><tab>else:<tab><tab><tab>current_sequence().tracks[i].active = False<tab>gui.tline_column.widget.queue_draw()",0,if i == current_sequence ( ) . get_first_active_track ( ) . id :,if current_sequence ( ) . tracks [ i ] . tracks [ i ] . active :,0.19581512399120354,24.783601560424714,0.3133333333333333
"def http_wrapper(self, url, postdata={}):<tab>try:<tab><tab>if postdata != {}:<tab><tab><tab>f = urllib.urlopen(url, postdata)<tab><tab>else:<tab><tab><tab>f = urllib.urlopen(url)<tab><tab>response = f.read()<tab>except:<tab><tab>import traceback<tab><tab>import logging, sys<tab><tab>cla, exc, tb = sys.exc_info()<tab><tab>logging.error(url)<tab><tab><IF-STMT><tab><tab><tab>logging.error(""with post data"")<tab><tab>else:<tab><tab><tab>logging.error(""without post data"")<tab><tab>logging.error(exc.args)<tab><tab>logging.error(traceback.format_tb(tb))<tab><tab>response = """"<tab>return response",0,if postdata :,if exc . args [ 0 ] == 404 :,0.04224510045373539,1e-10,0.25274725274725274
"def frequent_thread_switches():<tab>""""""Make concurrency bugs more likely to manifest.""""""<tab>interval = None<tab><IF-STMT><tab><tab>if hasattr(sys, ""getswitchinterval""):<tab><tab><tab>interval = sys.getswitchinterval()<tab><tab><tab>sys.setswitchinterval(1e-6)<tab><tab>else:<tab><tab><tab>interval = sys.getcheckinterval()<tab><tab><tab>sys.setcheckinterval(1)<tab>try:<tab><tab>yield<tab>finally:<tab><tab>if not sys.platform.startswith(""java""):<tab><tab><tab>if hasattr(sys, ""setswitchinterval""):<tab><tab><tab><tab>sys.setswitchinterval(interval)<tab><tab><tab>else:<tab><tab><tab><tab>sys.setcheckinterval(interval)",1,"if not sys . platform . startswith ( ""java"" ) :","if not sys . platform . startswith ( ""java"" ) :",0.75,100.00000000000004,1.0
"def iter_filters(filters, block_end=False):<tab>queue = deque(filters)<tab>while queue:<tab><tab>f = queue.popleft()<tab><tab><IF-STMT><tab><tab><tab>if block_end:<tab><tab><tab><tab>queue.appendleft(None)<tab><tab><tab>for gf in f.filters:<tab><tab><tab><tab>queue.appendleft(gf)<tab><tab>yield f",0,"if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :","if isinstance ( f , Filter ) :",0.01365921845727935,1.9672023367516605,0.16205533596837943
"def smartsplit(code):<tab>""""""Split `code` at "" symbol, only if it is not escaped.""""""<tab>strings = []<tab>pos = 0<tab>while pos < len(code):<tab><tab><IF-STMT><tab><tab><tab>word = """"  # new word<tab><tab><tab>pos += 1<tab><tab><tab>while pos < len(code):<tab><tab><tab><tab>if code[pos] == '""':<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>if code[pos] == ""\\"":<tab><tab><tab><tab><tab>word += ""\\""<tab><tab><tab><tab><tab>pos += 1<tab><tab><tab><tab>word += code[pos]<tab><tab><tab><tab>pos += 1<tab><tab><tab>strings.append('""%s""' % word)<tab><tab>pos += 1<tab>return strings",0,"if code [ pos ] == '""' :","if code [ pos ] == ""\\"" :",0.41812130587366103,54.91004867761124,1.0
"def get_folder_content(cls, name):<tab>""""""Return (folders, files) for the given folder in the root dir.""""""<tab>folders = set()<tab>files = set()<tab>for path in cls.LAYOUT:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>parts = path.split(""/"")<tab><tab>if len(parts) == 2:<tab><tab><tab>files.add(parts[1])<tab><tab>else:<tab><tab><tab>folders.add(parts[1])<tab>folders = list(folders)<tab>folders.sort()<tab>files = list(files)<tab>files.sort()<tab>return (folders, files)",0,"if not path . startswith ( name + ""/"" ) :",if not path . startswith ( name ) :,0.3710114460528901,51.51425457345961,1.0
"def array_for(self, i):<tab>if 0 <= i < self._cnt:<tab><tab><IF-STMT><tab><tab><tab>return self._tail<tab><tab>node = self._root<tab><tab>level = self._shift<tab><tab>while level > 0:<tab><tab><tab>assert isinstance(node, Node)<tab><tab><tab>node = node._array[(i >> level) & 0x01F]<tab><tab><tab>level -= 5<tab><tab>assert isinstance(node, Node)<tab><tab>return node._array<tab>affirm(False, u""Index out of Range"")",0,if i >= self . tailoff ( ) :,if self . _tail :,0.03153300650124795,9.911450612811139,0.3666666666666667
"def __or__(self, other) -> ""MultiVector"":<tab>r""""""``self | other``, the inner product :math:`M \cdot N`""""""<tab>other, mv = self._checkOther(other)<tab>if mv:<tab><tab>newValue = self.layout.imt_func(self.value, other.value)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>obj = self.__array__()<tab><tab><tab>return obj | other<tab><tab># l * M = M * l = 0 for scalar l<tab><tab>return self._newMV(dtype=np.result_type(self.value.dtype, other))<tab>return self._newMV(newValue)",0,"if isinstance ( other , np . ndarray ) :",if self . layout . imt_func ( other . value ) :,0.08233528809661435,8.889175589171739,0.2222222222222222
"def parse_bzr_stats(status):<tab>stats = RepoStats()<tab>statustype = ""changed""<tab>for statusline in status:<tab><tab>if statusline[:2] == ""  "":<tab><tab><tab>setattr(stats, statustype, getattr(stats, statustype) + 1)<tab><tab><IF-STMT><tab><tab><tab>statustype = ""staged""<tab><tab>elif statusline == ""unknown:"":<tab><tab><tab>statustype = ""new""<tab><tab>else:  # removed, missing, renamed, modified or kind changed<tab><tab><tab>statustype = ""changed""<tab>return stats",0,"elif statusline == ""added:"" :","elif statusline == ""staged:"" :",0.6428720214849399,59.694917920196445,1.0
"def write(self, timestamps, actualValues, predictedValues, predictionStep=1):<tab>assert len(timestamps) == len(actualValues) == len(predictedValues)<tab>for index in range(len(self.names)):<tab><tab>timestamp = timestamps[index]<tab><tab>actual = actualValues[index]<tab><tab>prediction = predictedValues[index]<tab><tab>writer = self.outputWriters[index]<tab><tab><IF-STMT><tab><tab><tab>outputRow = [timestamp, actual, prediction]<tab><tab><tab>writer.writerow(outputRow)<tab><tab><tab>self.lineCounts[index] += 1",0,if timestamp is not None :,if writer is not None :,0.5212518808542342,53.7284965911771,0.7142857142857143
"def clean(self):<tab>""""""Delete old files in ""tmp"".""""""<tab>now = time.time()<tab>for entry in os.listdir(os.path.join(self._path, ""tmp"")):<tab><tab>path = os.path.join(self._path, ""tmp"", entry)<tab><tab><IF-STMT>  # 60 * 60 * 36<tab><tab><tab>os.remove(path)",0,if now - os . path . getatime ( path ) > 129600 :,if os . path . isfile ( path ) and ( time . time ( ) - now ) > 60 * 60 :,0.4774774198607009,17.059573701616802,0.1696969696969697
"def _get_info(self, path):<tab>info = OrderedDict()<tab>if not self._is_mac() or self._has_xcode_tools():<tab><tab>stdout = None<tab><tab>try:<tab><tab><tab>stdout, stderr = Popen(<tab><tab><tab><tab>[self._find_binary(), ""info"", os.path.realpath(path)],<tab><tab><tab><tab>stdout=PIPE,<tab><tab><tab><tab>stderr=PIPE,<tab><tab><tab>).communicate()<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for line in stdout.splitlines():<tab><tab><tab><tab><tab>line = u(line).split("": "", 1)<tab><tab><tab><tab><tab>if len(line) == 2:<tab><tab><tab><tab><tab><tab>info[line[0]] = line[1]<tab>return info",1,if stdout :,if stdout :,0.5311706625951745,1e-10,1.0
"def add(meta_list, info_list=None):<tab>if not info_list:<tab><tab>info_list = meta_list<tab>if not isinstance(meta_list, (list, tuple)):<tab><tab>meta_list = (meta_list,)<tab>if not isinstance(info_list, (list, tuple)):<tab><tab>info_list = (info_list,)<tab>for info_f in info_list:<tab><tab><IF-STMT><tab><tab><tab>for meta_f in meta_list:<tab><tab><tab><tab>metadata[meta_f] = info[info_f]<tab><tab><tab>break",0,if info . get ( info_f ) is not None :,if info_f not in metadata :,0.09694048262338388,14.481023414005424,0.20370370370370372
"def _compute_log_r(model_trace, guide_trace):<tab>log_r = MultiFrameTensor()<tab>stacks = get_plate_stacks(model_trace)<tab>for name, model_site in model_trace.nodes.items():<tab><tab><IF-STMT><tab><tab><tab>log_r_term = model_site[""log_prob""]<tab><tab><tab>if not model_site[""is_observed""]:<tab><tab><tab><tab>log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""]<tab><tab><tab>log_r.add((stacks[name], log_r_term.detach()))<tab>return log_r",0,"if model_site [ ""type"" ] == ""sample"" :","if ""log_prob"" in model_site :",0.019907917998500824,11.985825441691155,0.6410256410256411
"def pickline(file, key, casefold=1):<tab>try:<tab><tab>f = open(file, ""r"")<tab>except IOError:<tab><tab>return None<tab>pat = re.escape(key) + "":""<tab>prog = re.compile(pat, casefold and re.IGNORECASE)<tab>while 1:<tab><tab>line = f.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab>if prog.match(line):<tab><tab><tab>text = line[len(key) + 1 :]<tab><tab><tab>while 1:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>text = text + line<tab><tab><tab>return text.strip()<tab>return None",0,if not line or not line [ 0 ] . isspace ( ) :,if not line :,0.02997757883318023,5.2447643832804935,0.43417366946778707
"def build_iterator(data, infinite=True):<tab>""""""Build the iterator for inputs.""""""<tab>index = 0<tab>size = len(data[0])<tab>while True:<tab><tab>if index + batch_size > size:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>index = 0<tab><tab><tab>else:<tab><tab><tab><tab>return<tab><tab>yield data[0][index : index + batch_size], data[1][index : index + batch_size]<tab><tab>index += batch_size",1,if infinite :,if infinite :,0.5311706625951745,1e-10,1.0
"def checkall(g, bg, dst_nodes, include_dst_in_src=True):<tab>for etype in g.etypes:<tab><tab>ntype = g.to_canonical_etype(etype)[2]<tab><tab><IF-STMT><tab><tab><tab>check(g, bg, ntype, etype, dst_nodes[ntype], include_dst_in_src)<tab><tab>else:<tab><tab><tab>check(g, bg, ntype, etype, None, include_dst_in_src)",0,if dst_nodes is not None and ntype in dst_nodes :,if ntype in dst_nodes :,0.3056424746098112,30.93485033266056,0.2
"def minimalBases(classes):<tab>""""""Reduce a list of base classes to its ordered minimum equivalent""""""<tab>if not __python3:  # pragma: no cover<tab><tab>classes = [c for c in classes if c is not ClassType]<tab>candidates = []<tab>for m in classes:<tab><tab>for n in classes:<tab><tab><tab>if issubclass(n, m) and m is not n:<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># m has no subclasses in 'classes'<tab><tab><tab><IF-STMT><tab><tab><tab><tab>candidates.remove(m)  # ensure that we're later in the list<tab><tab><tab>candidates.append(m)<tab>return candidates",0,if m in candidates :,if m not in candidates :,0.14710913164137962,37.99178428257963,0.4444444444444444
"def __keep_songs_enable(self, enabled):<tab>config.set(""memory"", ""queue_keep_songs"", enabled)<tab>if enabled:<tab><tab>self.queue.set_first_column_type(CurrentColumn)<tab>else:<tab><tab>for col in self.queue.get_columns():<tab><tab><tab># Remove the CurrentColum if it exists<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.queue.set_first_column_type(None)<tab><tab><tab><tab>break",0,"if isinstance ( col , CurrentColumn ) :",if col . name == CurrentColum . name :,0.01809616860937894,5.522397783539471,0.2698412698412698
"def outlineView_heightOfRowByItem_(self, tree, item) -> float:<tab>default_row_height = self.rowHeight<tab>if item is self:<tab><tab>return default_row_height<tab>heights = [default_row_height]<tab>for column in self.tableColumns:<tab><tab>value = getattr(item.attrs[""node""], str(column.identifier))<tab><tab><IF-STMT><tab><tab><tab># if the cell value is a widget, use its height<tab><tab><tab>heights.append(value._impl.native.intrinsicContentSize().height)<tab>return max(heights)",0,"if isinstance ( value , toga . Widget ) :","if isinstance ( value , Widget ) :",0.2682544298578143,53.849523560640876,0.6515151515151515
"def condition(self):<tab>if self.__condition is None:<tab><tab><IF-STMT><tab><tab><tab># Avoid an extra indirection in the common case of only one condition.<tab><tab><tab>self.__condition = self.flat_conditions[0]<tab><tab>elif len(self.flat_conditions) == 0:<tab><tab><tab># Possible, if unlikely, due to filter predicate rewriting<tab><tab><tab>self.__condition = lambda _: True<tab><tab>else:<tab><tab><tab>self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions)<tab>return self.__condition",1,if len ( self . flat_conditions ) == 1 :,if len ( self . flat_conditions ) == 1 :,0.75,100.00000000000004,1.0
"def _find_delimiter(f, block_size=2 ** 16):<tab>delimiter = b""\n""<tab>if f.tell() == 0:<tab><tab>return 0<tab>while True:<tab><tab>b = f.read(block_size)<tab><tab>if not b:<tab><tab><tab>return f.tell()<tab><tab><IF-STMT><tab><tab><tab>return f.tell() - len(b) + b.index(delimiter) + 1",0,elif delimiter in b :,if b . index ( delimiter ) < len ( b ) :,0.022789671369718288,4.065425428798724,0.109375
"def serialize(self, name=None):<tab>data = super(SimpleText, self).serialize(name)<tab>data[""contentType""] = self.contentType<tab>data[""content""] = self.content<tab>if self.width:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidWidthException(self.width)<tab><tab>data[""inputOptions""] = {}<tab><tab>data[""width""] = self.width<tab>return data",0,"if self . width not in [ 100 , 50 , 33 , 25 ] :",if self . width < 0 :,0.07437932149408083,12.01799094826536,0.3397129186602871
"def inference(self):<tab>self.attention_weight_dim = self.input_dims[0][-1]<tab>if self.keep_dim:<tab><tab>self.output_dim = copy.deepcopy(self.input_dims[0])<tab>else:<tab><tab>self.output_dim = []<tab><tab>for idx, dim in enumerate(self.input_dims[0]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.output_dim.append(dim)<tab>super(<tab><tab>LinearAttentionConf, self<tab>).inference()  # PUT THIS LINE AT THE END OF inference()",0,if idx != len ( self . input_dims [ 0 ] ) - 2 :,if idx == self . attention_weight_dim :,0.019737100564710286,6.682025998431122,0.40816326530612246
"def __delete_hook(self, rpc):<tab>try:<tab><tab>rpc.check_success()<tab>except apiproxy_errors.Error:<tab><tab>return None<tab>result = []<tab>for status in rpc.response.delete_status_list():<tab><tab>if status == MemcacheDeleteResponse.DELETED:<tab><tab><tab>result.append(DELETE_SUCCESSFUL)<tab><tab><IF-STMT><tab><tab><tab>result.append(DELETE_ITEM_MISSING)<tab><tab>else:<tab><tab><tab>result.append(DELETE_NETWORK_FAILURE)<tab>return result",0,elif status == MemcacheDeleteResponse . NOT_FOUND :,elif status == MemcacheDeleteResponse . MISSING :,0.5717294420803809,55.0695314903184,0.7714285714285715
def identify_page_at_cursor(self):<tab>for region in self.view.sel():<tab><tab>text_on_cursor = None<tab><tab>pos = region.begin()<tab><tab>scope_region = self.view.extract_scope(pos)<tab><tab><IF-STMT><tab><tab><tab>text_on_cursor = self.view.substr(scope_region)<tab><tab><tab>return text_on_cursor.strip(string.punctuation)<tab>return None,0,if not scope_region . empty ( ) :,if scope_region :,0.017267079824235865,1e-10,0.45833333333333337
"def from_elem(cls, parent, when_elem):<tab>""""""Loads the proper when by attributes of elem""""""<tab>when_value = when_elem.get(""value"", None)<tab><IF-STMT><tab><tab>return ValueToolOutputActionConditionalWhen(parent, when_elem, when_value)<tab>else:<tab><tab>when_value = when_elem.get(""datatype_isinstance"", None)<tab><tab>if when_value is not None:<tab><tab><tab>return DatatypeIsInstanceToolOutputActionConditionalWhen(<tab><tab><tab><tab>parent, when_elem, when_value<tab><tab><tab>)<tab>raise TypeError(""When type not implemented"")",1,if when_value is not None :,if when_value is not None :,0.75,100.00000000000004,1.0
"def test_insert_entity_empty_string_rk(<tab>self, tables_cosmos_account_name, tables_primary_cosmos_account_key):<tab># Arrange<tab>await self._set_up(tables_cosmos_account_name, tables_primary_cosmos_account_key)<tab>try:<tab><tab>entity = {""PartitionKey"": ""pk"", ""RowKey"": """"}<tab><tab># Act<tab><tab>with pytest.raises(HttpResponseError):<tab><tab><tab>await self.table.create_entity(entity=entity)<tab><tab><tab># Assert<tab><tab>#  assert resp is None<tab>finally:<tab><tab>await self._tear_down()<tab><tab><IF-STMT><tab><tab><tab>sleep(SLEEP_DELAY)",1,if self . is_live :,if self . is_live :,0.75,100.00000000000004,1.0
"def provider_uris(self):<tab>login_urls = {}<tab>continue_url = self.request.get(""continue_url"")<tab>for provider in self.provider_info:<tab><tab><IF-STMT><tab><tab><tab>login_url = self.uri_for(<tab><tab><tab><tab>""social-login"", provider_name=provider, continue_url=continue_url<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>login_url = self.uri_for(""social-login"", provider_name=provider)<tab><tab>login_urls[provider] = login_url<tab>return login_urls",0,if continue_url :,"if provider == ""default"" :",0.051944022748897464,1e-10,0.6190476190476191
"def expand_extensions(existing):<tab>for name in extension_names:<tab><tab>ext = (<tab><tab><tab>im(""lizard_ext.lizard"" + name.lower()).LizardExtension()<tab><tab><tab><IF-STMT><tab><tab><tab>else name<tab><tab>)<tab><tab>existing.insert(<tab><tab><tab>len(existing) if not hasattr(ext, ""ordering_index"") else ext.ordering_index,<tab><tab><tab>ext,<tab><tab>)<tab>return existing",1,"if isinstance ( name , str )","if isinstance ( name , str )",0.75,100.00000000000004,1.0
"def wrapper(self, *args, **kwargs):<tab>if not self.request.path.endswith(""/""):<tab><tab>if self.request.method in (""GET"", ""HEAD""):<tab><tab><tab>uri = self.request.path + ""/""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab>return<tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)",1,if self . request . query :,if self . request . query :,0.75,100.00000000000004,1.0
"def subword_map_by_joiner(subwords, marker=SubwordMarker.JOINER):<tab>""""""Return word id for each subword token (annotate by joiner).""""""<tab>flags = [0] * len(subwords)<tab>for i, tok in enumerate(subwords):<tab><tab><IF-STMT><tab><tab><tab>flags[i] = 1<tab><tab>if tok.startswith(marker):<tab><tab><tab>assert i >= 1 and flags[i - 1] != 1, ""Sentence `{}` not correct!"".format(<tab><tab><tab><tab>"" "".join(subwords)<tab><tab><tab>)<tab><tab><tab>flags[i - 1] = 1<tab>marker_acc = list(accumulate([0] + flags[:-1]))<tab>word_group = [(i - maker_sofar) for i, maker_sofar in enumerate(marker_acc)]<tab>return word_group",0,if tok . endswith ( marker ) :,if tok . startswith ( marker ) :,0.5014622369176811,50.000000000000014,0.6666666666666666
"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab>if i == start:<tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab>if i >= len(self.items):<tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>i += direction<tab><tab>if start < 0:<tab><tab><tab>start = 0",0,if self . select ( i ) :,if i >= len ( self . items ) :,0.042314974777694817,12.192091596713041,0.27272727272727276
"def get_config(cls):<tab># FIXME: Replace this as soon as we have a config module<tab>config = {}<tab># Try to get iflytek_yuyin config from config<tab>profile_path = dingdangpath.config(""profile.yml"")<tab>if os.path.exists(profile_path):<tab><tab>with open(profile_path, ""r"") as f:<tab><tab><tab>profile = yaml.safe_load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ""vid"" in profile[""iflytek_yuyin""]:<tab><tab><tab><tab><tab>config[""vid""] = profile[""iflytek_yuyin""][""vid""]<tab>return config",1,"if ""iflytek_yuyin"" in profile :","if ""iflytek_yuyin"" in profile :",0.75,100.00000000000004,1.0
"def get_signed_in_user(test_case):<tab>playback = not (test_case.is_live or test_case.in_recording)<tab>if playback:<tab><tab>return MOCKED_USER_NAME<tab>else:<tab><tab>account_info = test_case.cmd(""account show"").get_output_in_json()<tab><tab><IF-STMT><tab><tab><tab>return account_info[""user""][""name""]<tab>return None",0,"if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :",if account_info :,0.01723333651944375,1e-10,1.0
"def rename_project(self, project, new_name):<tab>""""""Rename project, update the related projects if necessary""""""<tab>old_name = project.name<tab>for proj in self.projects:<tab><tab>relproj = proj.get_related_projects()<tab><tab><IF-STMT><tab><tab><tab>relproj[relproj.index(old_name)] = new_name<tab><tab><tab>proj.set_related_projects(relproj)<tab>project.rename(new_name)<tab>self.save()",1,if old_name in relproj :,if old_name in relproj :,0.75,100.00000000000004,1.0
"def test_call_extern_c_fn(self):<tab>global memcmp<tab>memcmp = cffi_support.ExternCFunction(<tab><tab>""memcmp"",<tab><tab>(""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""),<tab>)<tab>@udf(BooleanVal(FunctionContext, StringVal, StringVal))<tab>def fn(context, a, b):<tab><tab>if a.is_null != b.is_null:<tab><tab><tab>return False<tab><tab>if a is None:<tab><tab><tab>return True<tab><tab>if len(a) != b.len:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>return memcmp(a.ptr, b.ptr, a.len) == 0",0,if a . ptr == b . ptr :,if len ( a ) != len ( b ) :,0.2658615023290767,5.063996506781411,0.3333333333333333
"def parse_variable(self):<tab>begin = self._pos<tab>while True:<tab><tab>ch = self.read()<tab><tab><IF-STMT><tab><tab><tab>return ScriptVariable(self._text[begin : self._pos - 1])<tab><tab>elif ch is None:<tab><tab><tab>self.__raise_eof()<tab><tab>elif not isidentif(ch) and ch != "":"":<tab><tab><tab>self.__raise_char(ch)",0,"if ch == ""%"" :",if isidentif ( ch ) :,0.032294703547118726,7.654112967106117,0.4642857142857143
"def h_file(self):<tab>filename = self.abspath()<tab>st = os.stat(filename)<tab>cache = self.ctx.hashes_md5_tstamp<tab>if filename in cache and cache[filename][0] == st.st_mtime:<tab><tab>return cache[filename][1]<tab>if STRONGEST:<tab><tab>ret = Utils.h_file(filename)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""Not a file"")<tab><tab>ret = Utils.md5(str((st.st_mtime, st.st_size)).encode()).digest()<tab>cache[filename] = (st.st_mtime, ret)<tab>return ret",0,if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,if st . st_size < 0 :,0.0527314959463077,2.9309777488533775,0.3894736842105263
"def add_widgets(self, *widgets_or_spacings):<tab>""""""Add widgets/spacing to dialog vertical layout""""""<tab>layout = self.layout()<tab>for widget_or_spacing in widgets_or_spacings:<tab><tab><IF-STMT><tab><tab><tab>layout.addSpacing(widget_or_spacing)<tab><tab>else:<tab><tab><tab>layout.addWidget(widget_or_spacing)",0,"if isinstance ( widget_or_spacing , int ) :","if isinstance ( widget_or_spacing , ( list , tuple ) ) :",0.23111061767006794,55.54570250728591,0.4901960784313726
"def _str_index(self):<tab>idx = self[""index""]<tab>out = []<tab>if len(idx) == 0:<tab><tab>return out<tab>out += ["".. index:: %s"" % idx.get(""default"", """")]<tab>for section, references in idx.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif section == ""refguide"":<tab><tab><tab>out += [""   single: %s"" % ("", "".join(references))]<tab><tab>else:<tab><tab><tab>out += [""   %s: %s"" % (section, "","".join(references))]<tab>return out",1,"if section == ""default"" :","if section == ""default"" :",0.75,100.00000000000004,1.0
"def dictify_CPPDEFINES(env):<tab>cppdefines = env.get(""CPPDEFINES"", {})<tab>if cppdefines is None:<tab><tab>return {}<tab>if SCons.Util.is_Sequence(cppdefines):<tab><tab>result = {}<tab><tab>for c in cppdefines:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[c[0]] = c[1]<tab><tab><tab>else:<tab><tab><tab><tab>result[c] = None<tab><tab>return result<tab>if not SCons.Util.is_Dict(cppdefines):<tab><tab>return {cppdefines: None}<tab>return cppdefines",0,if SCons . Util . is_Sequence ( c ) :,if SCons . Util . is_Dict ( c ) :,0.5803088707179008,73.48889200874659,1.0
"def decoder(s):<tab>r = []<tab>decode = []<tab>for c in s:<tab><tab>if c == ""&"" and not decode:<tab><tab><tab>decode.append(""&"")<tab><tab>elif c == ""-"" and decode:<tab><tab><tab>if len(decode) == 1:<tab><tab><tab><tab>r.append(""&"")<tab><tab><tab>else:<tab><tab><tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab><tab><tab>decode = []<tab><tab><IF-STMT><tab><tab><tab>decode.append(c)<tab><tab>else:<tab><tab><tab>r.append(c)<tab>if decode:<tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab>bin_str = """".join(r)<tab>return (bin_str, len(s))",0,elif decode :,elif len ( c ) == 1 :,0.03798808867010255,1e-10,0.3
"def optimize(self, graph: Graph):<tab>MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE<tab>flag_changed = False<tab>for v in traverse.listup_variables(graph):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>height, width = TextureShape.get(v)<tab><tab>if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE:<tab><tab><tab>continue<tab><tab>if not v.has_attribute(SplitTarget):<tab><tab><tab>flag_changed = True<tab><tab><tab>v.attributes.add(SplitTarget())<tab>return graph, flag_changed",0,if not Placeholder . check_resolved ( v . size ) :,"if not isinstance ( v , GraphVariable ) :",0.0357328861027945,10.589620902360299,0.5
"def one_gpr_reg_one_mem_scalable(ii):<tab>n, r = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_agen(op) or (op_mem(op) and op.oc2 in [""v""]):<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>r += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and r == 1",0,elif op_gprv ( op ) :,elif op_gpr32 ( op ) or op_gpr64 ( op ) or op_gpr64 ( op ) or op_gpr64 ( op ) :,0.2643751855051021,11.649949409622417,0.553125
"def get_genome_dir(gid, galaxy_dir, data):<tab>""""""Return standard location of genome directories.""""""<tab>if galaxy_dir:<tab><tab>refs = genome.get_refs(gid, None, galaxy_dir, data)<tab><tab>seq_file = tz.get_in([""fasta"", ""base""], refs)<tab><tab>if seq_file and os.path.exists(seq_file):<tab><tab><tab>return os.path.dirname(os.path.dirname(seq_file))<tab>else:<tab><tab>gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid))<tab><tab><IF-STMT><tab><tab><tab>return gdirs[0]",0,if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) :,if gdirs :,0.003870800285598434,1e-10,0.17142857142857143
"def __modules(self):<tab>raw_output = self.__module_avail_output().decode(""utf-8"")<tab>for line in StringIO(raw_output):<tab><tab>line = line and line.strip()<tab><tab>if not line or line.startswith(""-""):<tab><tab><tab>continue<tab><tab>line_modules = line.split()<tab><tab>for module in line_modules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>module = module[0 : -len(self.default_indicator)].strip()<tab><tab><tab>module_parts = module.split(""/"")<tab><tab><tab>module_version = None<tab><tab><tab>if len(module_parts) == 2:<tab><tab><tab><tab>module_version = module_parts[1]<tab><tab><tab>module_name = module_parts[0]<tab><tab><tab>yield module_name, module_version",1,if module . endswith ( self . default_indicator ) :,if module . endswith ( self . default_indicator ) :,0.75,100.00000000000004,1.0
"def save(self):<tab>updates = self.cinder_obj_get_changes()<tab>if updates:<tab><tab><IF-STMT><tab><tab><tab>metadata = updates.pop(""metadata"", None)<tab><tab><tab>self.metadata = db.backup_metadata_update(<tab><tab><tab><tab>self._context, self.id, metadata, True<tab><tab><tab>)<tab><tab>updates.pop(""parent"", None)<tab><tab>db.backup_update(self._context, self.id, updates)<tab>self.obj_reset_changes()",1,"if ""metadata"" in updates :","if ""metadata"" in updates :",0.75,100.00000000000004,1.0
"def test_set_tag(association_obj, sagemaker_session):<tab>tag = {""Key"": ""foo"", ""Value"": ""bar""}<tab>association_obj.set_tag(tag)<tab>while True:<tab><tab>actual_tags = sagemaker_session.sagemaker_client.list_tags(<tab><tab><tab>ResourceArn=association_obj.source_arn<tab><tab>)[""Tags""]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(5)<tab># When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints,<tab># length of actual tags will be greater than 1<tab>assert len(actual_tags) > 0<tab>assert actual_tags[0] == tag",1,if actual_tags :,if actual_tags :,0.5311706625951745,1e-10,1.0
"def test_error_stream(environ, start_response):<tab>writer = start_response(""200 OK"", [])<tab>wsgi_errors = environ[""wsgi.errors""]<tab>error_msg = None<tab>for method in [<tab><tab>""flush"",<tab><tab>""write"",<tab><tab>""writelines"",<tab>]:<tab><tab>if not hasattr(wsgi_errors, method):<tab><tab><tab>error_msg = ""wsgi.errors has no '%s' attr"" % method<tab><tab><IF-STMT><tab><tab><tab>error_msg = ""wsgi.errors.%s attr is not callable"" % method<tab><tab>if error_msg:<tab><tab><tab>break<tab>return_msg = error_msg or ""success""<tab>writer(return_msg)<tab>return []",0,"if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :",elif not callable ( wsgi_errors [ method ] ) :,0.1368469772837384,19.069363427734363,0.18859649122807015
"def current_dict(cursor_offset, line):<tab>""""""If in dictionary completion, return the dict that should be used""""""<tab>for m in current_dict_re.finditer(line):<tab><tab><IF-STMT><tab><tab><tab>return LinePart(m.start(1), m.end(1), m.group(1))<tab>return None",0,if m . start ( 2 ) <= cursor_offset and m . end ( 2 ) >= cursor_offset :,if m . start ( 1 ) <= cursor_offset and m . end ( 1 ) >= cursor_offset :,0.8452924387611908,77.49224723289701,0.75
"def show_file_browser(self):<tab>""""""Show/hide the file browser.""""""<tab>if self.show_file_browser_action.isChecked():<tab><tab>sizes = self.panel.sizes()<tab><tab><IF-STMT><tab><tab><tab>sizes[0] = sum(sizes) // 4<tab><tab><tab>self.panel.setSizes(sizes)<tab><tab>self.file_browser.show()<tab>else:<tab><tab>self.file_browser.hide()",0,if sizes [ 0 ] == 0 :,if sizes :,0.030705692522937138,1e-10,0.7
"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>items.append(item.nameEncoded())<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",1,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,100.00000000000004,1.0
"def prepend(self, value):<tab>""""""prepend value to nodes""""""<tab>root, root_text = self._get_root(value)<tab>for i, tag in enumerate(self):<tab><tab><IF-STMT><tab><tab><tab>tag.text = """"<tab><tab>if len(root) > 0:<tab><tab><tab>root[-1].tail = tag.text<tab><tab><tab>tag.text = root_text<tab><tab>else:<tab><tab><tab>tag.text = root_text + tag.text<tab><tab>if i > 0:<tab><tab><tab>root = deepcopy(list(root))<tab><tab>tag[:0] = root<tab><tab>root = tag[: len(root)]<tab>return self",0,if not tag . text :,"if tag . text == """" :",0.10494632798085189,20.164945583740657,0.37142857142857144
"def getLabel(self, address=None):<tab>if address is None:<tab><tab>address = self.address<tab>label = address<tab>if shared.config.has_section(address):<tab><tab>label = shared.config.get(address, ""label"")<tab>queryreturn = sqlQuery(""""""select label from addressbook where address=?"""""", address)<tab><IF-STMT><tab><tab>for row in queryreturn:<tab><tab><tab>(label,) = row<tab>else:<tab><tab>queryreturn = sqlQuery(<tab><tab><tab>""""""select label from subscriptions where address=?"""""", address<tab><tab>)<tab><tab>if queryreturn != []:<tab><tab><tab>for row in queryreturn:<tab><tab><tab><tab>(label,) = row<tab>return label",1,if queryreturn != [ ] :,if queryreturn != [ ] :,0.75,100.00000000000004,1.0
"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab>if ""axis"" in self.args:<tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab>if not isinstance(self.axis, int):<tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab><IF-STMT><tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab>if not isinstance(self.momentum, (int, float)):<tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')",1,"if ""momentum"" in self . args :","if ""momentum"" in self . args :",0.75,100.00000000000004,1.0
"def urlquote(*args, **kwargs):<tab>new_kwargs = dict(kwargs)<tab>if not PY3:<tab><tab>new_kwargs = dict(kwargs)<tab><tab>if ""encoding"" in new_kwargs:<tab><tab><tab>del new_kwargs[""encoding""]<tab><tab><IF-STMT><tab><tab><tab>del new_kwargs[""errors""]<tab>return quote(*args, **new_kwargs)",0,"if ""errors"" in kwargs :","if ""errors"" in new_kwargs :",0.39477865547525276,51.33450480401705,0.7
"def setNextFormPrevious(self, backup=STARTING_FORM):<tab>try:<tab><tab>if self._THISFORM.FORM_NAME == self._FORM_VISIT_LIST[-1]:<tab><tab><tab>self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list<tab><tab><IF-STMT><tab><tab><tab># take no action if it looks as if someone has already set the next form.<tab><tab><tab>self.setNextForm(<tab><tab><tab><tab>self._FORM_VISIT_LIST.pop()<tab><tab><tab>)  # Switch to the previous form if one exists<tab>except IndexError:<tab><tab>self.setNextForm(backup)",0,if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM :,if self . _FORM_VISIT_LIST [ - 1 ] == backup :,0.10490626761046898,19.032892442937786,0.52
"def iter_chars_to_words(self, chars):<tab>current_word = []<tab>for char in chars:<tab><tab>if not self.keep_blank_chars and char[""text""].isspace():<tab><tab><tab>if current_word:<tab><tab><tab><tab>yield current_word<tab><tab><tab><tab>current_word = []<tab><tab><IF-STMT><tab><tab><tab>yield current_word<tab><tab><tab>current_word = [char]<tab><tab>else:<tab><tab><tab>current_word.append(char)<tab>if current_word:<tab><tab>yield current_word",0,"elif current_word and self . char_begins_new_word ( current_word , char ) :","elif char [ ""text"" ] . isspace ( ) :",0.024554403703959712,3.8739065266517896,0.3235294117647059
"def get(self):<tab>""""""return a secret by name""""""<tab>results = self._get(""secrets"", self.name)<tab>results[""decoded""] = {}<tab>results[""exists""] = False<tab>if results[""returncode""] == 0 and results[""results""][0]:<tab><tab>results[""exists""] = True<tab><tab><IF-STMT><tab><tab><tab>if ""data"" in results[""results""][0]:<tab><tab><tab><tab>for sname, value in results[""results""][0][""data""].items():<tab><tab><tab><tab><tab>results[""decoded""][sname] = base64.b64decode(value)<tab>if results[""returncode""] != 0 and '""%s"" not found' % self.name in results[""stderr""]:<tab><tab>results[""returncode""] = 0<tab>return results",0,if self . decode :,"if results [ ""exists"" ] :",0.030286782520570012,6.567274736060395,0.37142857142857144
"def insert_use(self, edit):<tab>if self.is_first_use():<tab><tab>for location in [r""^\s*namespace\s+[\w\\]+[;{]"", r""<\?php""]:<tab><tab><tab>inserted = self.insert_first_use(location, edit)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>else:<tab><tab>self.insert_use_among_others(edit)",1,if inserted :,if inserted :,0.5311706625951745,1e-10,1.0
"def _new_rsa_key(spec):<tab>if ""name"" not in spec:<tab><tab><IF-STMT><tab><tab><tab>(head, tail) = os.path.split(spec[""key""])<tab><tab><tab>spec[""path""] = head<tab><tab><tab>spec[""name""] = tail<tab><tab>else:<tab><tab><tab>spec[""name""] = spec[""key""]<tab>return rsa_init(spec)",0,"if ""/"" in spec [ ""key"" ] :","if spec [ ""key"" ] :",0.2813400460866964,52.734307450329375,0.4772727272727273
"def mimeData(self, indexes):<tab>if len(indexes) == 1:<tab><tab>index = indexes[0]<tab><tab>model = song = index.data(Qt.UserRole)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>model = song.album<tab><tab><tab>except (ProviderIOError, Exception):<tab><tab><tab><tab>model = None<tab><tab>return ModelMimeData(model)",0,if index . column ( ) == Column . album :,if model is None :,0.011636451275277468,3.1325998243558226,0.2403846153846154
"def get(self, url, **kwargs):<tab>app, url = self._prepare_call(url, kwargs)<tab>if app:<tab><tab>if url.endswith(""ping"") and self._first_ping:<tab><tab><tab>self._first_ping = False<tab><tab><tab>return EmptyCapabilitiesResponse()<tab><tab><IF-STMT><tab><tab><tab>return ErrorApiResponse()<tab><tab>else:<tab><tab><tab>response = app.get(url, **kwargs)<tab><tab><tab>return TestingResponse(response)<tab>else:<tab><tab>return requests.get(url, **kwargs)",0,"elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :","elif url . endswith ( ""error"" ) :",0.010003692109746703,2.551084474780675,0.2619047619047619
"def handle_noargs(self, **options):<tab>self.style = color_style()<tab>print(""Running Django's own validation:"")<tab>self.validate(display_num_errors=True)<tab>for model in loading.get_models():<tab><tab>if hasattr(model, ""_create_content_base""):<tab><tab><tab>self.validate_base_model(model)<tab><tab><IF-STMT><tab><tab><tab>self.validate_content_type(model)",0,"if hasattr ( model , ""_feincms_content_models"" ) :","if hasattr ( model , ""_create_content_type"" ) :",0.5490406812970063,57.73502691896262,1.0
"def test_rules_widget(self):<tab>subreddit = self.reddit.subreddit(pytest.placeholders.test_subreddit)<tab>widgets = subreddit.widgets<tab>with self.use_cassette(""TestSubredditWidgets.fetch_widgets""):<tab><tab>rules = None<tab><tab>for widget in widgets.sidebar:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rules = widget<tab><tab><tab><tab>break<tab><tab>assert isinstance(rules, RulesWidget)<tab><tab>assert rules == rules<tab><tab>assert rules.id == rules<tab><tab>assert rules.display<tab><tab>assert len(rules) > 0<tab><tab>assert subreddit == rules.subreddit",1,"if isinstance ( widget , RulesWidget ) :","if isinstance ( widget , RulesWidget ) :",0.75,100.00000000000004,1.0
"def __init__(self, exception):<tab>message = str(exception)<tab>with contextlib.suppress(IndexError):<tab><tab>underlying_exception = exception.args[0]<tab><tab><IF-STMT><tab><tab><tab>message = (<tab><tab><tab><tab>""maximum retries exceeded trying to reach the store.\n""<tab><tab><tab><tab>""Check your network connection, and check the store ""<tab><tab><tab><tab>""status at {}"".format(_STORE_STATUS_URL)<tab><tab><tab>)<tab>super().__init__(message=message)",0,"if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :","if underlying_exception . __name__ == ""Retry"" and _STORE_STATUS_URL is not None :",0.054353401547137255,6.394766688900896,0.2
"def wrapped(self, request):<tab>try:<tab><tab>return self._finished<tab>except AttributeError:<tab><tab>if self.node_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.debug(<tab><tab><tab><tab><tab>""%s is still going to be used, not terminating it. ""<tab><tab><tab><tab><tab>""Still in use on:\n%s"",<tab><tab><tab><tab><tab>self,<tab><tab><tab><tab><tab>pprint.pformat(list(self.node_ids)),<tab><tab><tab><tab>)<tab><tab><tab><tab>return<tab><tab>log.debug(""Finish called on %s"", self)<tab><tab>try:<tab><tab><tab>return func(request)<tab><tab>finally:<tab><tab><tab>self._finished = True",0,if not request . session . shouldfail and not request . session . shouldstop :,if not self . _finished :,0.015042740594249034,4.981224652850502,0.25054466230936817
"def get_min_vertical_scroll() -> int:<tab># Make sure that the cursor line is not below the bottom.<tab># (Calculate how many lines can be shown between the cursor and the .)<tab>used_height = 0<tab>prev_lineno = ui_content.cursor_position.y<tab>for lineno in range(ui_content.cursor_position.y, -1, -1):<tab><tab>used_height += get_line_height(lineno)<tab><tab><IF-STMT><tab><tab><tab>return prev_lineno<tab><tab>else:<tab><tab><tab>prev_lineno = lineno<tab>return 0",0,if used_height > height - scroll_offsets_bottom :,if used_height >= scroll_height :,0.10490600921794552,35.640596364430706,0.6363636363636364
"def cookies(self):<tab># strip cookie_suffix from all cookies in the request, return result<tab>cookies = flask.Request.cookies.__get__(self)<tab>result = {}<tab>desuffixed = {}<tab>for key, value in cookies.items():<tab><tab><IF-STMT><tab><tab><tab>desuffixed[key[: -len(self.cookie_suffix)]] = value<tab><tab>else:<tab><tab><tab>result[key] = value<tab>result.update(desuffixed)<tab>return result",1,if key . endswith ( self . cookie_suffix ) :,if key . endswith ( self . cookie_suffix ) :,0.75,100.00000000000004,1.0
"def update_vars(state1, state2):<tab>ops = []<tab>for name in state1._fields:<tab><tab>state1_vs = getattr(state1, name)<tab><tab><IF-STMT><tab><tab><tab>ops += [<tab><tab><tab><tab>tf.assign(_v1, _v2)<tab><tab><tab><tab>for _v1, _v2 in zip(state1_vs, getattr(state2, name))<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>ops += [tf.assign(state1_vs, getattr(state2, name))]<tab>return tf.group(*ops)",0,"if isinstance ( state1_vs , list ) :","if isinstance ( state1_vs , tf . Tensor ) :",0.2633400423728968,57.067457770559976,0.4871794871794872
"def manifest(self):<tab>""""""The current manifest dictionary.""""""<tab>if self.reload:<tab><tab><IF-STMT><tab><tab><tab>return {}<tab><tab>mtime = self.getmtime(self.manifest_path)<tab><tab>if self._mtime is None or mtime > self._mtime:<tab><tab><tab>self._manifest = self.get_manifest()<tab><tab><tab>self._mtime = mtime<tab>return self._manifest",0,if not self . exists ( self . manifest_path ) :,if self . manifest_path is None :,0.11712966383532732,31.128780276284857,0.27472527472527475
"def csvtitle(self):<tab>if isinstance(self.name, six.string_types):<tab><tab>return '""' + self.name + '""' + char[""sep""] * (len(self.nick) - 1)<tab>else:<tab><tab>ret = """"<tab><tab>for i, name in enumerate(self.name):<tab><tab><tab>ret = ret + '""' + name + '""' + char[""sep""] * (len(self.nick) - 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = ret + char[""sep""]<tab><tab>return ret",0,if i + 1 != len ( self . name ) :,if i != len ( self . name ) - 1 :,0.40800515460662345,64.00572202540577,0.42857142857142855
"def cache_dst(self):<tab>final_dst = None<tab>final_linenb = None<tab>for linenb, assignblk in enumerate(self):<tab><tab>for dst, src in viewitems(assignblk):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if final_dst is not None:<tab><tab><tab><tab><tab>raise ValueError(""Multiple destinations!"")<tab><tab><tab><tab>final_dst = src<tab><tab><tab><tab>final_linenb = linenb<tab>self._dst = final_dst<tab>self._dst_linenb = final_linenb<tab>return final_dst",0,"if dst . is_id ( ""IRDst"" ) :",if dst == final_dst :,0.0354018406734773,7.966506956353643,1.0
"def _ProcessName(self, name, dependencies):<tab>""""""Retrieve a module name from a node name.""""""<tab>module_name, dot, base_name = name.rpartition(""."")<tab>if dot:<tab><tab><IF-STMT><tab><tab><tab>if module_name in dependencies:<tab><tab><tab><tab>dependencies[module_name].add(base_name)<tab><tab><tab>else:<tab><tab><tab><tab>dependencies[module_name] = {base_name}<tab><tab>else:<tab><tab><tab># If we have a relative import that did not get qualified (usually due<tab><tab><tab># to an empty package_name), don't insert module_name='' into the<tab><tab><tab># dependencies; we get a better error message if we filter it out here<tab><tab><tab># and fail later on.<tab><tab><tab>logging.warning(""Empty package name: %s"", name)",0,if module_name :,"if name . endswith ( "".py"" ) :",0.04422835593777517,1e-10,0.45833333333333337
"def get_aa_from_codonre(re_aa):<tab>aas = []<tab>m = 0<tab>for i in re_aa:<tab><tab>if i == ""["":<tab><tab><tab>m = -1<tab><tab><tab>aas.append("""")<tab><tab>elif i == ""]"":<tab><tab><tab>m = 0<tab><tab><tab>continue<tab><tab>elif m == -1:<tab><tab><tab>aas[-1] = aas[-1] + i<tab><tab><IF-STMT><tab><tab><tab>aas.append(i)<tab>return aas",0,elif m == 0 :,elif m == 1 :,0.6428720214849399,53.7284965911771,0.6
"def logic():<tab>count = intbv(0, min=0, max=MAXVAL + 1)<tab>while True:<tab><tab>yield clock.posedge, reset.posedge<tab><tab>if reset == 1:<tab><tab><tab>count[:] = 0<tab><tab>else:<tab><tab><tab>flag.next = 0<tab><tab><tab><IF-STMT><tab><tab><tab><tab>flag.next = 1<tab><tab><tab><tab>count[:] = 0<tab><tab><tab>else:<tab><tab><tab><tab>count += 1",0,if count == MAXVAL :,if enable :,0.03549272049582243,1e-10,0.36
"def _history_define_metric(<tab>self, hkey: str) -> Optional[wandb_internal_pb2.MetricRecord]:<tab>""""""check for hkey match in glob metrics, return defined metric.""""""<tab># Dont define metric for internal metrics<tab>if hkey.startswith(""_""):<tab><tab>return None<tab>for k, mglob in six.iteritems(self._metric_globs):<tab><tab>if k.endswith(""*""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>m = wandb_internal_pb2.MetricRecord()<tab><tab><tab><tab>m.CopyFrom(mglob)<tab><tab><tab><tab>m.ClearField(""glob_name"")<tab><tab><tab><tab>m.name = hkey<tab><tab><tab><tab>return m<tab>return None",0,if hkey . startswith ( k [ : - 1 ] ) :,"if mglob . HasField ( ""glob_name"" ) :",0.021071541928911645,7.835643838636099,0.2361111111111111
"def optimize_models(args, use_cuda, models):<tab>""""""Optimize ensemble for generation""""""<tab>for model in models:<tab><tab>model.make_generation_fast_(<tab><tab><tab>beamable_mm_beam_size=None if args.no_beamable_mm else args.beam,<tab><tab><tab>need_attn=args.print_alignment,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>model.half()<tab><tab>if use_cuda:<tab><tab><tab>model.cuda()",0,if args . fp16 :,if args . use_half :,0.39477865547525276,26.269098944241588,0.7
"def _Dynamic_Rollback(self, transaction, transaction_response):<tab>txid = transaction.handle()<tab>self.__local_tx_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise apiproxy_errors.ApplicationError(<tab><tab><tab><tab>datastore_pb.Error.BAD_REQUEST, ""Transaction %d not found."" % (txid,)<tab><tab><tab>)<tab><tab>txdata = self.__transactions[txid]<tab><tab>assert (<tab><tab><tab>txdata.thread_id == thread.get_ident()<tab><tab>), ""Transactions are single-threaded.""<tab><tab>del self.__transactions[txid]<tab>finally:<tab><tab>self.__local_tx_lock.release()",1,if txid not in self . __transactions :,if txid not in self . __transactions :,0.75,100.00000000000004,1.0
"def get_job_dirs(path):<tab>regex = re.compile(""[1-9][0-9]*-"")<tab>jobdirs = []<tab>for d in os.listdir(path):<tab><tab># skip directories not matching the job result dir pattern<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d = os.path.join(options.resultsdir, d)<tab><tab>if os.path.isdir(d) and not os.path.exists(os.path.join(d, PUBLISH_FLAGFILE)):<tab><tab><tab>jobdirs.append(d)<tab>return jobdirs",0,if not regex . match ( d ) :,if not regex . search ( d ) :,0.38322265259775284,59.694917920196445,0.7142857142857143
"def traverse(node, functions=[]):<tab>if hasattr(node, ""grad_fn""):<tab><tab>node = node.grad_fn<tab>if hasattr(node, ""variable""):<tab><tab>node = graph.nodes_by_id.get(id(node.variable))<tab><tab>if node:<tab><tab><tab>node.functions = list(functions)<tab><tab><tab>del functions[:]<tab>if hasattr(node, ""next_functions""):<tab><tab>functions.append(type(node).__name__)<tab><tab>for f in node.next_functions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(type(f[0]).__name__)<tab><tab><tab><tab>traverse(f[0], functions)<tab>if hasattr(node, ""saved_tensors""):<tab><tab>for t in node.saved_tensors:<tab><tab><tab>traverse(t)",0,if f [ 0 ] :,"if hasattr ( f , 0 ) :",0.02492724325929667,7.809849842300637,0.37777777777777777
"def get_all_snap_points(self, forts):<tab>points = []<tab>radius = Constants.MAX_DISTANCE_FORT_IS_REACHABLE<tab>for i in range(0, len(forts)):<tab><tab>for j in range(i + 1, len(forts)):<tab><tab><tab>c1, c2 = self.get_enclosing_circles(forts[i], forts[j], radius)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>points.append((c1, c2, forts[i], forts[j]))<tab>return points",0,if c1 and c2 :,if c1 != c2 :,0.08141502097923063,22.957488466614336,0.5333333333333333
"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab>if not isinstance(child, minidom.Element):<tab><tab><tab>continue<tab><tab>if child.tagName == ""Directory"":<tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if grandchild.tagName != ""File"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",0,"if not isinstance ( grandchild , minidom . Element ) :","if not grandchild . hasAttribute ( ""Source"" ) :",0.09580802294094523,12.192091596713041,0.3541666666666667
"def computeLeadingWhitespaceWidth(s, tab_width):<tab>w = 0<tab>for ch in s:<tab><tab>if ch == "" "":<tab><tab><tab>w += 1<tab><tab><IF-STMT><tab><tab><tab>w += abs(tab_width) - (w % abs(tab_width))<tab><tab>else:<tab><tab><tab>break<tab>return w",1,"elif ch == ""\t"" :","elif ch == ""\t"" :",1.0,100.00000000000004,1.0
"def test_avg_group_by(self):<tab>ret = (<tab><tab>await Book.annotate(avg=Avg(""rating""))<tab><tab>.group_by(""author_id"")<tab><tab>.values(""author_id"", ""avg"")<tab>)<tab>for item in ret:<tab><tab>author_id = item.get(""author_id"")<tab><tab>avg = item.get(""avg"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(avg, 4.5)<tab><tab>elif author_id == self.a2.pk:<tab><tab><tab>self.assertEqual(avg, 2.0)",1,if author_id == self . a1 . pk :,if author_id == self . a1 . pk :,0.75,100.00000000000004,1.0
"def open_session(self, app, request):<tab>sid = request.cookies.get(app.session_cookie_name)<tab>if sid:<tab><tab>stored_session = self.cls.objects(sid=sid).first()<tab><tab><IF-STMT><tab><tab><tab>expiration = stored_session.expiration<tab><tab><tab>if not expiration.tzinfo:<tab><tab><tab><tab>expiration = expiration.replace(tzinfo=utc)<tab><tab><tab>if expiration > datetime.datetime.utcnow().replace(tzinfo=utc):<tab><tab><tab><tab>return MongoEngineSession(<tab><tab><tab><tab><tab>initial=stored_session.data, sid=stored_session.sid<tab><tab><tab><tab>)<tab>return MongoEngineSession(sid=str(uuid.uuid4()))",1,if stored_session :,if stored_session :,0.5311706625951745,1e-10,1.0
"def one_line_description(self):<tab>MAX_LINE_LENGTH = 120<tab>desc = util.remove_html_tags(self.description or """")<tab>desc = re.sub(""\s+"", "" "", desc).strip()<tab>if not desc:<tab><tab>return _(""No description available"")<tab>else:<tab><tab># Decode the description to avoid gPodder bug 1277<tab><tab>desc = util.convert_bytes(desc).strip()<tab><tab><IF-STMT><tab><tab><tab>return desc[:MAX_LINE_LENGTH] + ""...""<tab><tab>else:<tab><tab><tab>return desc",1,if len ( desc ) > MAX_LINE_LENGTH :,if len ( desc ) > MAX_LINE_LENGTH :,0.75,100.00000000000004,1.0
"def setInnerHTML(self, html):<tab>log.HTMLClassifier.classify(<tab><tab>log.ThugLogging.url if log.ThugOpts.local else log.last_url, html<tab>)<tab>self.tag.clear()<tab>for node in bs4.BeautifulSoup(html, ""html.parser"").contents:<tab><tab>self.tag.append(node)<tab><tab>name = getattr(node, ""name"", None)<tab><tab>if name is None:<tab><tab><tab>continue<tab><tab>handler = getattr(log.DFT, ""handle_%s"" % (name,), None)<tab><tab><IF-STMT><tab><tab><tab>handler(node)",0,if handler :,if handler is not None :,0.09036476851692153,1e-10,0.39999999999999997
def get_supported_period_type_map(cls):<tab>if cls.supported_period_map is None:<tab><tab>cls.supported_period_map = {}<tab><tab>cls.supported_period_map.update(cls.period_type_map)<tab><tab>try:<tab><tab><tab>from dateutil import relativedelta<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls.supported_period_map.update(cls.optional_period_type_map)<tab><tab>except Exception:<tab><tab><tab>pass<tab>return cls.supported_period_map,0,if relativedelta is not None :,if relativedelta ( cls . optional_period_type_map ) is not None :,0.3208227547074841,17.02602472176709,0.4155844155844156
"def _compare_single_run(self, compares_done):<tab>try:<tab><tab>compare_id, redo = self.in_queue.get(<tab><tab><tab>timeout=float(self.config[""ExpertSettings""][""block_delay""])<tab><tab>)<tab>except Empty:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if redo:<tab><tab><tab><tab>self.db_interface.delete_old_compare_result(compare_id)<tab><tab><tab>compares_done.add(compare_id)<tab><tab><tab>self._process_compare(compare_id)<tab><tab><tab>if self.callback:<tab><tab><tab><tab>self.callback()",0,"if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :",if compare_id :,0.008307009447911351,1e-10,0.475
"def _get_field_actual(cant_be_number, raw_string, field_names):<tab>for line in raw_string.splitlines():<tab><tab>for field_name in field_names:<tab><tab><tab>field_name = field_name.lower()<tab><tab><tab>if "":"" in line:<tab><tab><tab><tab>left, right = line.split("":"", 1)<tab><tab><tab><tab>left = left.strip().lower()<tab><tab><tab><tab>right = right.strip()<tab><tab><tab><tab>if left == field_name and len(right) > 0:<tab><tab><tab><tab><tab>if cant_be_number:<tab><tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab><tab>return right<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return right<tab>return None",0,if not right . isdigit ( ) :,if len ( right ) == 1 :,0.021251794891640776,7.129384882260374,0.42857142857142855
"def _p_basicstr_content(s, content=_basicstr_re):<tab>res = []<tab>while True:<tab><tab>res.append(s.expect_re(content).group(0))<tab><tab>if not s.consume(""\\""):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re):<tab><tab><tab>res.append(_chr(int(s.last().group(1), 16)))<tab><tab>else:<tab><tab><tab>s.expect_re(_escapes_re)<tab><tab><tab>res.append(_escapes[s.last().group(0)])<tab>return """".join(res)",0,if s . consume_re ( _newline_esc_re ) :,"elif s . consume ( ""\\"" ) :",0.04180120886450045,12.763038103777827,0.38181818181818183
"def removedir(self, path):<tab># type: (Text) -> None<tab>_path = self.validatepath(path)<tab>if _path == ""/"":<tab><tab>raise errors.RemoveRootError()<tab>with ftp_errors(self, path):<tab><tab>try:<tab><tab><tab>self.ftp.rmd(_encode(_path, self.ftp.encoding))<tab><tab>except error_perm as error:<tab><tab><tab>code, _ = _parse_ftp_error(error)<tab><tab><tab>if code == ""550"":<tab><tab><tab><tab>if self.isfile(path):<tab><tab><tab><tab><tab>raise errors.DirectoryExpected(path)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise errors.DirectoryNotEmpty(path)<tab><tab><tab>raise  # pragma: no cover",0,if not self . isempty ( path ) :,elif self . isdir ( path ) :,0.29664910369441866,36.28241434631104,0.1111111111111111
"def _normalize_store_path(self, resource_store):<tab>if resource_store[""type""] == ""filesystem"":<tab><tab><IF-STMT><tab><tab><tab>resource_store[""base_directory""] = os.path.join(<tab><tab><tab><tab>self.root_directory, resource_store[""base_directory""]<tab><tab><tab>)<tab>return resource_store",0,"if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :","if resource_store [ ""base_directory"" ] :",0.13954230759438063,43.367978688929774,0.30303030303030304
"def _apply_nested(name, val, nested):<tab>parts = name.split(""."")<tab>cur = nested<tab>for i in range(0, len(parts) - 1):<tab><tab>cur = cur.setdefault(parts[i], {})<tab><tab><IF-STMT><tab><tab><tab>conflicts_with = ""."".join(parts[0 : i + 1])<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""%r cannot be nested: conflicts with {%r: %s}""<tab><tab><tab><tab>% (name, conflicts_with, cur)<tab><tab><tab>)<tab>cur[parts[-1]] = val",0,"if not isinstance ( cur , dict ) :",if cur is not val :,0.017951424116240698,6.962210312500384,0.25
"def build_packages(targeted_packages, distribution_directory, is_dev_build=False):<tab># run the build and distribution<tab>for package_root in targeted_packages:<tab><tab>service_hierarchy = os.path.join(os.path.basename(package_root))<tab><tab><IF-STMT><tab><tab><tab>verify_update_package_requirement(package_root)<tab><tab>print(""Generating Package Using Python {}"".format(sys.version))<tab><tab>run_check_call(<tab><tab><tab>[<tab><tab><tab><tab>sys.executable,<tab><tab><tab><tab>build_packing_script_location,<tab><tab><tab><tab>""--dest"",<tab><tab><tab><tab>os.path.join(distribution_directory, service_hierarchy),<tab><tab><tab><tab>package_root,<tab><tab><tab>],<tab><tab><tab>root_dir,<tab><tab>)",1,if is_dev_build :,if is_dev_build :,0.5311706625951745,1e-10,1.0
"def resolve_root_node_address(self, root_node):<tab>if ""["" in root_node:<tab><tab>name, numbers = root_node.split(""["", maxsplit=1)<tab><tab>number = numbers.split("","", maxsplit=1)[0]<tab><tab><IF-STMT><tab><tab><tab>number = number.split(""-"")[0]<tab><tab>number = re.sub(""[^0-9]"", """", number)<tab><tab>root_node = name + number<tab>return root_node",1,"if ""-"" in number :","if ""-"" in number :",0.75,100.00000000000004,1.0
"def _map_args(maps: dict, **kwargs):<tab># maps: key=old name, value= new name<tab>output = {}<tab>for name, val in kwargs.items():<tab><tab>if name in maps:<tab><tab><tab>assert isinstance(maps[name], str)<tab><tab><tab>output.update({maps[name]: val})<tab><tab>else:<tab><tab><tab>output.update({name: val})<tab>for keys in maps.keys():<tab><tab><IF-STMT><tab><tab><tab>pass<tab>return output",0,if keys not in output . keys ( ) :,"if isinstance ( keys , str ) and keys [ 0 ] == name :",0.06379762099434429,3.8275613602956104,0.2159090909090909
"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab>if i == start:<tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab>if self.select(i):<tab><tab><tab>break<tab><tab>i += direction<tab><tab>if start < 0:<tab><tab><tab>start = 0",0,if i >= len ( self . items ) :,if i > len ( self . items ) - 1 :,0.4383598227819626,54.52469119630866,0.8461538461538461
"def detect_reentrancy(self, contract):<tab>for function in contract.functions_and_modifiers_declared:<tab><tab><IF-STMT><tab><tab><tab>if self.KEY in function.context:<tab><tab><tab><tab>continue<tab><tab><tab>self._explore(function.entry_point, [])<tab><tab><tab>function.context[self.KEY] = True",0,if function . is_implemented :,"if isinstance ( function , contract . contract_declarer ) :",0.026964759067697196,5.063996506781411,0.37142857142857144
"def load_model(self):<tab>if not os.path.exists(self.get_filename(absolute=True)):<tab><tab><IF-STMT><tab><tab><tab>return {}, {}<tab><tab>error(<tab><tab><tab>""Model file with pre-trained convolution layers not found. Download it here..."",<tab><tab><tab>""https://github.com/alexjc/neural-enhance/releases/download/v%s/%s""<tab><tab><tab>% (__version__, self.get_filename()),<tab><tab>)<tab>print(""  - Loaded file `{}` with trained model."".format(self.get_filename()))<tab>return pickle.load(bz2.open(self.get_filename(), ""rb""))",0,if args . train :,if self . get_trained ( ) :,0.029730601197949243,6.27465531099474,0.37777777777777777
"def get_nonexisting_check_definition_extends(definition, indexed_oval_defs):<tab># TODO: handle multiple levels of referrals.<tab># OVAL checks that go beyond one level of extend_definition won't be properly identified<tab>for extdefinition in definition.findall("".//{%s}extend_definition"" % oval_ns):<tab><tab># Verify each extend_definition in the definition<tab><tab>extdefinitionref = extdefinition.get(""definition_ref"")<tab><tab># Search the OVAL tree for a definition with the referred ID<tab><tab>referreddefinition = indexed_oval_defs.get(extdefinitionref)<tab><tab><IF-STMT><tab><tab><tab># There is no oval satisfying the extend_definition referal<tab><tab><tab>return extdefinitionref<tab>return None",0,if referreddefinition is None :,ifferreddefinition is not None :,0.183575650843433,23.643540225079384,0.2857142857142857
"def pause(self):<tab>if self.is_playing:<tab><tab>self.state = MusicPlayerState.PAUSED<tab><tab><IF-STMT><tab><tab><tab>self._current_player.pause()<tab><tab>self.emit(""pause"", player=self, entry=self.current_entry)<tab><tab>return<tab>elif self.is_paused:<tab><tab>return<tab>raise ValueError(""Cannot pause a MusicPlayer in state %s"" % self.state)",0,if self . _current_player :,if self . _current_player is not None :,0.3514988343435983,59.00468726392806,0.4444444444444444
"def setNextFormPrevious(self, backup=STARTING_FORM):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self._FORM_VISIT_LIST.pop()  # Remove the current form. if it is at the end of the list<tab><tab>if self._THISFORM.FORM_NAME == self.NEXT_ACTIVE_FORM:<tab><tab><tab># take no action if it looks as if someone has already set the next form.<tab><tab><tab>self.setNextForm(<tab><tab><tab><tab>self._FORM_VISIT_LIST.pop()<tab><tab><tab>)  # Switch to the previous form if one exists<tab>except IndexError:<tab><tab>self.setNextForm(backup)",0,if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,if self . _THISFORM .FORM_NAME == self . NEXT_ACTIVE_FORM :,0.46747238311644324,54.95528514675272,0.7391304347826086
"def get_expr_referrers(schema: s_schema.Schema, obj: so.Object) -> Dict[so.Object, str]:<tab>""""""Return schema referrers with refs in expressions.""""""<tab>refs = schema.get_referrers_ex(obj)<tab>result = {}<tab>for (mcls, fn), referrers in refs.items():<tab><tab>field = mcls.get_field(fn)<tab><tab><IF-STMT><tab><tab><tab>result.update({ref: fn for ref in referrers})<tab>return result",0,"if issubclass ( field . type , ( Expression , ExpressionList ) ) :",if field is not None :,0.00899532177506067,2.8157908010020885,0.19411764705882353
"def _fields_to_index(cls):<tab>fields = []<tab>for field in cls._meta.sorted_fields:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>requires_index = any(<tab><tab><tab>(field.index, field.unique, isinstance(field, ForeignKeyField))<tab><tab>)<tab><tab>if requires_index:<tab><tab><tab>fields.append(field)<tab>return fields",0,if field . primary_key :,"if not isinstance ( field , ForeignKeyField ) :",0.02675254074710682,6.27465531099474,0.2878787878787879
"def ident_values(self):<tab>value = self._ident_values<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab>if not self.orig_prefix:<tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>idents = getattr(wrapped, ""ident_values"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = [self._wrap_hash(ident) for ident in idents]<tab><tab><tab>##else:<tab><tab><tab>##<tab>ident = self.ident<tab><tab><tab>##<tab>if ident is not None:<tab><tab><tab>##<tab><tab>value = [ident]<tab><tab>self._ident_values = value<tab>return value",0,if idents :,if idents is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def apply_incpaths_ml(self):<tab>inc_lst = self.includes.split()<tab>lst = self.incpaths_lst<tab>for dir in inc_lst:<tab><tab>node = self.path.find_dir(dir)<tab><tab>if not node:<tab><tab><tab>error(""node not found: "" + str(dir))<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>lst.append(node)<tab><tab>self.bld_incpaths_lst.append(node)",0,if not node in lst :,if node not in lst :,0.3701405707067377,35.930411196308434,0.6666666666666666
"def application_openFiles_(self, nsapp, filenames):<tab># logging.info('[osx] file open')<tab># logging.info('[osx] file : %s' % (filenames))<tab>for filename in filenames:<tab><tab>logging.info(""[osx] receiving from macOS : %s"", filename)<tab><tab>if os.path.exists(filename):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sabnzbd.add_nzbfile(filename, keep=True)",0,if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES :,"if nsapp == ""mac"" :",0.007888856279547486,1.1412212286076961,0.2653061224489796
"def check(self, xp, nout):<tab>input = xp.asarray(self.x).astype(numpy.float32)<tab>with warnings.catch_warnings():<tab><tab>if self.ignore_warning:<tab><tab><tab>warnings.simplefilter(""ignore"", self.ignore_warning)<tab><tab><IF-STMT><tab><tab><tab>self.check_positive(xp, self.func, input, self.eps, nout)<tab><tab>else:<tab><tab><tab>self.check_negative(xp, self.func, input, self.eps, nout)",0,if self . result :,if self . use_positive :,0.39477865547525276,26.269098944241588,0.7
"def _set_scheme(url, newscheme):<tab>scheme = _get_scheme(url)<tab>newscheme = newscheme or """"<tab>newseparator = "":"" if newscheme in COLON_SEPARATED_SCHEMES else ""://""<tab>if scheme == """":  # Protocol relative URL.<tab><tab>url = ""%s:%s"" % (newscheme, url)<tab>elif scheme is None and url:  # No scheme.<tab><tab>url = """".join([newscheme, newseparator, url])<tab>elif scheme:  # Existing scheme.<tab><tab>remainder = url[len(scheme) :]<tab><tab><IF-STMT><tab><tab><tab>remainder = remainder[3:]<tab><tab>elif remainder.startswith("":""):<tab><tab><tab>remainder = remainder[1:]<tab><tab>url = """".join([newscheme, newseparator, remainder])<tab>return url",1,"if remainder . startswith ( ""://"" ) :","if remainder . startswith ( ""://"" ) :",0.75,100.00000000000004,1.0
"def parquet(tables, data_directory, ignore_missing_dependency, **params):<tab>try:<tab><tab>import pyarrow as pa  # noqa: F401<tab><tab>import pyarrow.parquet as pq  # noqa: F401<tab>except ImportError:<tab><tab>msg = ""PyArrow dependency is missing""<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""Ignored: %s"", msg)<tab><tab><tab>return 0<tab><tab>else:<tab><tab><tab>raise click.ClickException(msg)<tab>data_directory = Path(data_directory)<tab>for table, df in read_tables(tables, data_directory):<tab><tab>arrow_table = pa.Table.from_pandas(df)<tab><tab>target_path = data_directory / ""{}.parquet"".format(table)<tab><tab>pq.write_table(arrow_table, str(target_path))",1,if ignore_missing_dependency :,if ignore_missing_dependency :,0.5311706625951745,1e-10,1.0
"def h2i(self, pkt, s):<tab>t = ()<tab>if type(s) is str:<tab><tab>t = time.strptime(s)<tab><tab>t = t[:2] + t[2:-3]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>y, m, d, h, min, sec, rest, rest, rest = time.gmtime(time.time())<tab><tab><tab>t = (y, m, d, h, min, sec)<tab><tab>else:<tab><tab><tab>t = s<tab>return t",0,if not s :,if type ( s ) is int :,0.03661176184600709,7.267884212102741,0.39285714285714285
"def filter_episodes(self, batch, cross_entropy):<tab>""""""Filter the episodes for the cross_entropy method""""""<tab>accumulated_reward = [sum(rewards) for rewards in batch[""rewards""]]<tab>percentile = cross_entropy * 100<tab>reward_bound = np.percentile(accumulated_reward, percentile)<tab># we save the batch with reward above the bound<tab>result = {k: [] for k in self.data_keys}<tab>episode_kept = 0<tab>for i in range(len(accumulated_reward)):<tab><tab><IF-STMT><tab><tab><tab>for k in self.data_keys:<tab><tab><tab><tab>result[k].append(batch[k][i])<tab><tab><tab>episode_kept += 1<tab>return result",0,if accumulated_reward [ i ] >= reward_bound :,if reward_bound > episode_kept :,0.019907917998500824,14.06401411379081,0.6410256410256411
"def _readenv(var, msg):<tab>match = _ENV_VAR_PAT.match(var)<tab>if match and match.groups():<tab><tab>envvar = match.groups()[0]<tab><tab>if envvar in os.environ:<tab><tab><tab>value = os.environ[envvar]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.decode(""utf8"")<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>raise InvalidConfigException(<tab><tab><tab><tab>""{} - environment variable '{}' not set"".format(msg, var)<tab><tab><tab>)<tab>else:<tab><tab>raise InvalidConfigException(<tab><tab><tab>""{} - environment variable name '{}' does not match pattern '{}'"".format(<tab><tab><tab><tab>msg, var, _ENV_VAR_PAT_STR<tab><tab><tab>)<tab><tab>)",0,if six . PY2 :,"if isinstance ( value , bytes ) :",0.026407399022921448,6.567274736060395,0.2698412698412698
"def _allocate_nbd(self):<tab>if not os.path.exists(""/sys/block/nbd0""):<tab><tab>self.error = _(""nbd unavailable: module not loaded"")<tab><tab>return None<tab>while True:<tab><tab>if not self._DEVICES:<tab><tab><tab># really want to log this info, not raise<tab><tab><tab>self.error = _(""No free nbd devices"")<tab><tab><tab>return None<tab><tab>device = self._DEVICES.pop()<tab><tab><IF-STMT><tab><tab><tab>break<tab>return device",0,"if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :",if device is None :,0.004621595234959633,0.09472565111320143,0.1814814814814815
"def _expand_deps_java_generation(self):<tab>""""""Ensure that all multilingual dependencies such as proto_library generate java code.""""""<tab>queue = collections.deque(self.deps)<tab>keys = set()<tab>while queue:<tab><tab>k = queue.popleft()<tab><tab><IF-STMT><tab><tab><tab>keys.add(k)<tab><tab><tab>dep = self.target_database[k]<tab><tab><tab>if ""generate_java"" in dep.attr:  # Has this attribute<tab><tab><tab><tab>dep.attr[""generate_java""] = True<tab><tab><tab><tab>queue.extend(dep.deps)",1,if k not in keys :,if k not in keys :,0.75,100.00000000000004,1.0
"def load_syntax(syntax):<tab>context = _create_scheme() or {}<tab>partition_scanner = PartitionScanner(syntax.get(""partitions"", []))<tab>scanners = {}<tab>for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()):<tab><tab>scanners[part_name] = Scanner(part_scanner)<tab>formats = []<tab>for fname, fstyle in list(syntax.get(""formats"", {}).items()):<tab><tab>if isinstance(fstyle, basestring):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key = fstyle[2:-2]<tab><tab><tab><tab>fstyle = context[key]<tab><tab><tab>else:<tab><tab><tab><tab>fstyle = fstyle % context<tab><tab>formats.append((fname, fstyle))<tab>return partition_scanner, scanners, formats",0,"if fstyle . startswith ( ""%("" ) and fstyle . endswith ( "")s"" ) :","if fstyle . startswith ( ""--"" ) :",0.21995662454692788,21.904149145918822,0.5873015873015873
"def rollback(self):<tab>for operation, values in self.current_transaction_state[::-1]:<tab><tab><IF-STMT><tab><tab><tab>values.remove()<tab><tab>elif operation == ""update"":<tab><tab><tab>old_value, new_value = values<tab><tab><tab>if new_value.full_filename != old_value.full_filename:<tab><tab><tab><tab>os.unlink(new_value.full_filename)<tab><tab><tab>old_value.write()<tab>self._post_xact_cleanup()",0,"if operation == ""insert"" :","if operation == ""delete"" :",0.39477865547525276,59.4603557501361,1.0
"def _buildOffsets(offsetDict, localeData, indexStart):<tab>o = indexStart<tab>for key in localeData:<tab><tab><IF-STMT><tab><tab><tab>for k in key.split(""|""):<tab><tab><tab><tab>offsetDict[k] = o<tab><tab>else:<tab><tab><tab>offsetDict[key] = o<tab><tab>o += 1",1,"if ""|"" in key :","if ""|"" in key :",0.75,100.00000000000004,1.0
"def _check_start_pipeline_execution_errors(<tab>graphene_info, execution_params, execution_plan):<tab>if execution_params.step_keys:<tab><tab>for step_key in execution_params.step_keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise UserFacingGraphQLError(<tab><tab><tab><tab><tab>graphene_info.schema.type_named(""InvalidStepError"")(<tab><tab><tab><tab><tab><tab>invalid_step_key=step_key<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",0,if not execution_plan . has_step ( step_key ) :,if step_key not in execution_plan . step_keys :,0.034348430522436114,27.392758081541032,0.7307692307692308
"def __setattr__(self, option_name, option_value):<tab>if option_name in self._options:<tab><tab># type checking<tab><tab>sort = self.OPTIONS[self.arch.name][option_name][0]<tab><tab><IF-STMT><tab><tab><tab>self._options[option_name] = option_value<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>'Value for option ""%s"" must be of type %s' % (option_name, sort)<tab><tab><tab>)<tab>else:<tab><tab>super(CFGArchOptions, self).__setattr__(option_name, option_value)",0,"if sort is None or isinstance ( option_value , sort ) :","if sort == ""all"" :",0.01921438599541026,5.773772066582297,0.3333333333333333
"def value(self):<tab>quote = False<tab>if self.defects:<tab><tab>quote = True<tab>else:<tab><tab>for x in self:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>quote = True<tab>if quote:<tab><tab>pre = post = """"<tab><tab>if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"":<tab><tab><tab>pre = "" ""<tab><tab>if self[-1].token_type == ""cfws"" or self[-1][-1].token_type == ""cfws"":<tab><tab><tab>post = "" ""<tab><tab>return pre + quote_string(self.display_name) + post<tab>else:<tab><tab>return super(DisplayName, self).value",0,"if x . token_type == ""quoted-string"" :","if x . token_type == ""quote"" :",0.574113272471593,76.91605673134588,1.0
"def __init__(self, patch_files, patch_directories):<tab>files = []<tab>files_data = {}<tab>for filename_data in patch_files:<tab><tab><IF-STMT><tab><tab><tab>filename, data = filename_data<tab><tab>else:<tab><tab><tab>filename = filename_data<tab><tab><tab>data = None<tab><tab>if not filename.startswith(os.sep):<tab><tab><tab>filename = ""{0}{1}"".format(FakeState.deploy_dir, filename)<tab><tab>files.append(filename)<tab><tab>if data:<tab><tab><tab>files_data[filename] = data<tab>self.files = files<tab>self.files_data = files_data<tab>self.directories = patch_directories",0,"if isinstance ( filename_data , list ) :","if isinstance ( filename_data , tuple ) :",0.5490406812970063,70.71067811865478,0.6
"def _evaluateStack(s):<tab>op = s.pop()<tab>if op in ""+-*/@^"":<tab><tab>op2 = _evaluateStack(s)<tab><tab>op1 = _evaluateStack(s)<tab><tab>result = opn[op](op1, op2)<tab><tab><IF-STMT><tab><tab><tab>print(result)<tab><tab>return result<tab>else:<tab><tab>return op",0,if debug_flag :,if opn [ op ] :,0.048107739435423735,1e-10,0.4375
"def reconnect_user(self, user_id, host_id, server_id):<tab>if host_id == settings.local.host_id:<tab><tab>return<tab>if server_id and self.server.id != server_id:<tab><tab>return<tab>for client in self.clients.find({""user_id"": user_id}):<tab><tab>self.clients.update_id(<tab><tab><tab>client[""id""],<tab><tab><tab>{<tab><tab><tab><tab>""ignore_routes"": True,<tab><tab><tab>},<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.instance.disconnect_wg(client[""id""])<tab><tab>else:<tab><tab><tab>self.instance_com.client_kill(client[""id""])",1,"if len ( client [ ""id"" ] ) > 32 :","if len ( client [ ""id"" ] ) > 32 :",0.75,100.00000000000004,1.0
"def _get_library(self, name, args):<tab>library_database = self._library_manager.get_new_connection_to_library_database()<tab>try:<tab><tab>last_updated = library_database.get_library_last_updated(name, args)<tab><tab>if last_updated:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._library_manager.fetch_keywords(<tab><tab><tab><tab><tab>name, args, self._libraries_need_refresh_listener<tab><tab><tab><tab>)<tab><tab><tab>return library_database.fetch_library_keywords(name, args)<tab><tab>return self._library_manager.get_and_insert_keywords(name, args)<tab>finally:<tab><tab>library_database.close()",0,if time . time ( ) - last_updated > 10.0 :,if last_updated > self . _libraries_need_refresh_listener :,0.025832773087462534,17.609282679116177,0.4852941176470588
"def get_paths(self, path, commit):<tab>""""""Return a generator of all filepaths under path at commit.""""""<tab>_check_path_is_repo_relative(path)<tab>git_path = _get_git_path(path)<tab>tree = self.gl_repo.git_repo[commit.tree[git_path].id]<tab>assert tree.type == pygit2.GIT_OBJ_TREE<tab>for tree_entry in tree:<tab><tab>tree_entry_path = os.path.join(path, tree_entry.name)<tab><tab><IF-STMT><tab><tab><tab>for fp in self.get_paths(tree_entry_path, commit):<tab><tab><tab><tab>yield fp<tab><tab>else:<tab><tab><tab>yield tree_entry_path",0,"if tree_entry . type == ""tree"" :",if os . path . isdir ( tree_entry_path ) :,0.08144100275175614,12.571192676522521,0.30952380952380953
"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab>if ""attributes"" in conf[""properties""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if conf[""properties""][""attributes""][""exp""]:<tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",1,"if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",0.75,100.00000000000004,1.0
"def _set_parse_context(self, tag, tag_attrs):<tab># special case: script or style parse context<tab>if not self._wb_parse_context:<tab><tab>if tag == ""style"":<tab><tab><tab>self._wb_parse_context = ""style""<tab><tab>elif tag == ""script"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._wb_parse_context = ""script""",0,if self . _allow_js_type ( tag_attrs ) :,"if self . _wb_parse_context == ""script"" :",0.07775595958652023,18.92240568795936,1.0
"def modified(self):<tab>paths = set()<tab>dictionary_list = []<tab>for op_list in self._operations:<tab><tab>if not isinstance(op_list, list):<tab><tab><tab>op_list = (op_list,)<tab><tab>for item in chain(*op_list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>dictionary = item.dictionary<tab><tab><tab>if dictionary.path in paths:<tab><tab><tab><tab>continue<tab><tab><tab>paths.add(dictionary.path)<tab><tab><tab>dictionary_list.append(dictionary)<tab>return dictionary_list",1,if item is None :,if item is None :,0.75,100.00000000000004,1.0
def preorder(root):<tab>res = []<tab>if not root:<tab><tab>return res<tab>stack = []<tab>stack.append(root)<tab>while stack:<tab><tab>root = stack.pop()<tab><tab>res.append(root.val)<tab><tab><IF-STMT><tab><tab><tab>stack.append(root.right)<tab><tab>if root.left:<tab><tab><tab>stack.append(root.left)<tab>return res,1,if root . right :,if root . right :,0.75,100.00000000000004,1.0
"def create(exported_python_target):<tab>if exported_python_target not in created:<tab><tab>self.context.log.info(<tab><tab><tab>""Creating setup.py project for {}"".format(exported_python_target)<tab><tab>)<tab><tab>subject = self.derived_by_original.get(<tab><tab><tab>exported_python_target, exported_python_target<tab><tab>)<tab><tab>setup_dir, dependencies = self.create_setup_py(subject, dist_dir)<tab><tab>created[exported_python_target] = setup_dir<tab><tab>if self._recursive:<tab><tab><tab>for dep in dependencies:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>create(dep)",0,if is_exported_python_target ( dep ) :,if dep not in created :,0.028043015323814018,3.9297526283216277,0.39999999999999997
"def test_array_interface(self, data):<tab>result = np.array(data)<tab>np.testing.assert_array_equal(result[0], data[0])<tab>result = np.array(data, dtype=object)<tab>expected = np.array(list(data), dtype=object)<tab>for a1, a2 in zip(result, expected):<tab><tab><IF-STMT><tab><tab><tab>assert np.isnan(a1) and np.isnan(a2)<tab><tab>else:<tab><tab><tab>tm.assert_numpy_array_equal(a2, a1)",0,if np . isscalar ( a1 ) :,"if isinstance ( a1 , np . ndarray ) :",0.04682921751904999,15.106876986783844,0.27272727272727276
"def valueChanged(plug):<tab>changed = plug.getInput() is not None<tab>if not changed and isinstance(plug, Gaffer.ValuePlug):<tab><tab><IF-STMT><tab><tab><tab>changed = not Gaffer.NodeAlgo.isSetToUserDefault(plug)<tab><tab>else:<tab><tab><tab>changed = not plug.isSetToDefault()<tab>return changed",1,if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,0.75,100.00000000000004,1.0
"def process_tag(hive_name, company, company_key, tag, default_arch):<tab>with winreg.OpenKeyEx(company_key, tag) as tag_key:<tab><tab>version = load_version_data(hive_name, company, tag, tag_key)<tab><tab><IF-STMT>  # if failed to get version bail<tab><tab><tab>major, minor, _ = version<tab><tab><tab>arch = load_arch_data(hive_name, company, tag, tag_key, default_arch)<tab><tab><tab>if arch is not None:<tab><tab><tab><tab>exe_data = load_exe(hive_name, company, company_key, tag)<tab><tab><tab><tab>if exe_data is not None:<tab><tab><tab><tab><tab>exe, args = exe_data<tab><tab><tab><tab><tab>return company, major, minor, arch, exe, args",1,if version is not None :,if version is not None :,0.75,100.00000000000004,1.0
"def __iter__(self):<tab>for name, value in self.__class__.__dict__.items():<tab><tab>if isinstance(value, alias_flag_value):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield (name, self._has_flag(value.flag))",0,"if isinstance ( value , flag_value ) :","if hasattr ( value , ""flag"" ) and value . flag :",0.06702404264166083,13.508625657351418,0.3523809523809524
"def connect(self):<tab>self.sock = sockssocket()<tab>self.sock.setproxy(*proxy_args)<tab>if type(self.timeout) in (int, float):<tab><tab>self.sock.settimeout(self.timeout)<tab>self.sock.connect((self.host, self.port))<tab>if isinstance(self, compat_http_client.HTTPSConnection):<tab><tab><IF-STMT>  # Python > 2.6<tab><tab><tab>self.sock = self._context.wrap_socket(self.sock, server_hostname=self.host)<tab><tab>else:<tab><tab><tab>self.sock = ssl.wrap_socket(self.sock)",0,"if hasattr ( self , ""_context"" ) :","if hasattr ( self . _context , ""wrap_socket"" ) :",0.18923832013822933,28.977907494497117,1.0
"def frequent_thread_switches():<tab>""""""Make concurrency bugs more likely to manifest.""""""<tab>interval = None<tab>if not sys.platform.startswith(""java""):<tab><tab>if hasattr(sys, ""getswitchinterval""):<tab><tab><tab>interval = sys.getswitchinterval()<tab><tab><tab>sys.setswitchinterval(1e-6)<tab><tab>else:<tab><tab><tab>interval = sys.getcheckinterval()<tab><tab><tab>sys.setcheckinterval(1)<tab>try:<tab><tab>yield<tab>finally:<tab><tab>if not sys.platform.startswith(""java""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sys.setswitchinterval(interval)<tab><tab><tab>else:<tab><tab><tab><tab>sys.setcheckinterval(interval)",1,"if hasattr ( sys , ""setswitchinterval"" ) :","if hasattr ( sys , ""setswitchinterval"" ) :",0.75,100.00000000000004,1.0
"def vars(self):<tab>ret = []<tab>if op.intlist:<tab><tab>varlist = op.intlist<tab>else:<tab><tab>varlist = self.discover<tab><tab>for name in varlist:<tab><tab><tab>if name in (""0"", ""1"", ""2"", ""8"", ""CPU0"", ""ERR"", ""LOC"", ""MIS"", ""NMI""):<tab><tab><tab><tab>varlist.remove(name)<tab><tab>if not op.full and len(varlist) > 3:<tab><tab><tab>varlist = varlist[-3:]<tab>for name in varlist:<tab><tab>if name in self.discover:<tab><tab><tab>ret.append(name)<tab><tab><IF-STMT><tab><tab><tab>ret.append(self.intmap[name.lower()])<tab>return ret",0,elif name . lower ( ) in self . intmap :,if name . lower ( ) in self . intmap :,0.4822912766177204,89.31539818068698,0.75
"def deleteDuplicates(gadgets, callback=None):<tab>toReturn = []<tab>inst = set()<tab>count = 0<tab>added = False<tab>len_gadgets = len(gadgets)<tab>for i, gadget in enumerate(gadgets):<tab><tab>inst.add(gadget._gadget)<tab><tab><IF-STMT><tab><tab><tab>count = len(inst)<tab><tab><tab>toReturn.append(gadget)<tab><tab><tab>added = True<tab><tab>if callback:<tab><tab><tab>callback(gadget, added, float(i + 1) / (len_gadgets))<tab><tab><tab>added = False<tab>return toReturn",0,if len ( inst ) > count :,if count > len_gadgets :,0.020977836961063236,8.513058489093439,0.36
"def ident(self):<tab>value = self._ident<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab>if not self.orig_prefix:<tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>ident = getattr(wrapped, ""ident"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = self._wrap_hash(ident)<tab><tab>self._ident = value<tab>return value",1,if ident is not None :,if ident is not None :,0.75,100.00000000000004,1.0
"def _flatten_settings_from_form(self, settings, form, form_values):<tab>""""""Take a nested dict and return a flat dict of setting values.""""""<tab>setting_values = {}<tab>for field in form.c:<tab><tab>if isinstance(field, _ContainerMixin):<tab><tab><tab>setting_values.update(<tab><tab><tab><tab>self._flatten_settings_from_form(<tab><tab><tab><tab><tab>settings, field, form_values[field._name]<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>setting_values[field._name] = form_values[field._name]<tab>return setting_values",0,elif field . _name in settings :,elif field . _name in form_values :,0.5717294420803809,53.7284965911771,0.7714285714285715
"def _decorator(cls):<tab>for name, meth in inspect.getmembers(cls, inspect.isroutine):<tab><tab>if name not in cls.__dict__:<tab><tab><tab>continue<tab><tab>if name != ""__init__"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>if name in butnot:<tab><tab><tab>continue<tab><tab>setattr(cls, name, decorator(meth))<tab>return cls",0,"if not private and name . startswith ( ""_"" ) :",if not inspect . isclass ( meth ) :,0.03134720083849852,9.568802664841456,0.2909090909090909
"def _do_cmp(f1, f2):<tab>bufsize = BUFSIZE<tab>with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2:<tab><tab>while True:<tab><tab><tab>b1 = fp1.read(bufsize)<tab><tab><tab>b2 = fp2.read(bufsize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>if not b1:<tab><tab><tab><tab>return True",0,if b1 != b2 :,if not b1 or not b2 :,0.05544914160509713,15.619699684601283,0.2333333333333333
"def _memoized(*args):<tab>now = time.time()<tab>try:<tab><tab>value, last_update = self.cache[args]<tab><tab>age = now - last_update<tab><tab>if self._call_count > self.ctl or age > self.ttl:<tab><tab><tab>self._call_count = 0<tab><tab><tab>raise AttributeError<tab><tab><IF-STMT><tab><tab><tab>self._call_count += 1<tab><tab>return value<tab>except (KeyError, AttributeError):<tab><tab>value = func(*args)<tab><tab>if value:<tab><tab><tab>self.cache[args] = (value, now)<tab><tab>return value<tab>except TypeError:<tab><tab>return func(*args)",0,if self . ctl :,if value :,0.03549272049582243,1e-10,0.36
"def check(self, hyperlinks: Dict[str, Hyperlink]) -> Generator[CheckResult, None, None]:<tab>self.invoke_threads()<tab>total_links = 0<tab>for hyperlink in hyperlinks.values():<tab><tab><IF-STMT><tab><tab><tab>yield CheckResult(<tab><tab><tab><tab>hyperlink.uri, hyperlink.docname, hyperlink.lineno, ""ignored"", """", 0<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, hyperlink), False)<tab><tab><tab>total_links += 1<tab>done = 0<tab>while done < total_links:<tab><tab>yield self.rqueue.get()<tab><tab>done += 1<tab>self.shutdown_threads()",0,if self . is_ignored_uri ( hyperlink . uri ) :,if hyperlink . is_external :,0.026933810325055336,11.835764736093042,0.37142857142857144
"def remove_subscriber(self, topic, subscriber):<tab>if subscriber in self.subscribers[topic]:<tab><tab><IF-STMT><tab><tab><tab>subscriber._pyroRelease()<tab><tab>if hasattr(subscriber, ""_pyroUri""):<tab><tab><tab>try:<tab><tab><tab><tab>proxy = self.proxy_cache[subscriber._pyroUri]<tab><tab><tab><tab>proxy._pyroRelease()<tab><tab><tab><tab>del self.proxy_cache[subscriber._pyroUri]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab>self.subscribers[topic].discard(subscriber)",0,"if hasattr ( subscriber , ""_pyroRelease"" ) :","if hasattr ( subscriber , ""_pyroUri"" ) :",0.5490406812970063,70.16879391277372,1.0
"def delete_arc(collection, document, origin, target, type):<tab>directory = collection<tab>real_dir = real_directory(directory)<tab>mods = ModificationTracker()<tab>projectconf = ProjectConfiguration(real_dir)<tab>document = path_join(real_dir, document)<tab>with TextAnnotations(document) as ann_obj:<tab><tab># bail as quick as possible if read-only<tab><tab><IF-STMT><tab><tab><tab>raise AnnotationsIsReadOnlyError(ann_obj.get_document())<tab><tab>_delete_arc_with_ann(origin, target, type, mods, ann_obj, projectconf)<tab><tab>mods_json = mods.json_response()<tab><tab>mods_json[""annotations""] = _json_from_ann(ann_obj)<tab><tab>return mods_json",0,if ann_obj . _read_only :,if ann_obj . get_document ( ) . is_read_only ( ) :,0.09840553831147811,32.59481888833584,1.0
"def _select_from(self, parent_path, is_dir, exists, listdir):<tab>if not is_dir(parent_path):<tab><tab>return<tab>with _cached(listdir) as listdir:<tab><tab>yielded = set()<tab><tab>try:<tab><tab><tab>successor_select = self.successor._select_from<tab><tab><tab>for starting_point in self._iterate_directories(<tab><tab><tab><tab>parent_path, is_dir, listdir<tab><tab><tab>):<tab><tab><tab><tab>for p in successor_select(starting_point, is_dir, exists, listdir):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield p<tab><tab><tab><tab><tab><tab>yielded.add(p)<tab><tab>finally:<tab><tab><tab>yielded.clear()",1,if p not in yielded :,if p not in yielded :,0.75,100.00000000000004,1.0
"def _fractional_part(self, n, expr, evaluation):<tab>n_sympy = n.to_sympy()<tab>if n_sympy.is_constant():<tab><tab><IF-STMT><tab><tab><tab>positive_integer_part = (<tab><tab><tab><tab>Expression(""Floor"", n).evaluate(evaluation).to_python()<tab><tab><tab>)<tab><tab><tab>result = n - positive_integer_part<tab><tab>else:<tab><tab><tab>negative_integer_part = (<tab><tab><tab><tab>Expression(""Ceiling"", n).evaluate(evaluation).to_python()<tab><tab><tab>)<tab><tab><tab>result = n - negative_integer_part<tab>else:<tab><tab>return expr<tab>return from_python(result)",0,if n_sympy >= 0 :,if evaluation . is_constant ( ) :,0.027969854500399755,6.27465531099474,0.5
"def check_bounds(geometry):<tab>if isinstance(geometry[0], (list, tuple)):<tab><tab>return list(map(check_bounds, geometry))<tab>else:<tab><tab>if geometry[0] > 180 or geometry[0] < -180:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Longitude is out of bounds, check your JSON format or data""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Latitude is out of bounds, check your JSON format or data""<tab><tab><tab>)",0,if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 :,if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,0.5781208940115203,23.17511932071925,0.5
"def get_absolute_path(self, root, path):<tab># find the first absolute path that exists<tab>self.root = self.roots[0]<tab>for root in self.roots:<tab><tab>abspath = os.path.abspath(os.path.join(root, path))<tab><tab><IF-STMT><tab><tab><tab>self.root = root  # make sure all the other methods in the base class know how to find the file<tab><tab><tab>break<tab>return abspath",1,if os . path . exists ( abspath ) :,if os . path . exists ( abspath ) :,0.75,100.00000000000004,1.0
"def do_setflow(self, l=""""):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>l = str(self.flow_slider.GetValue())<tab><tab>else:<tab><tab><tab>l = l.lower()<tab><tab>flow = int(l)<tab><tab>if self.p.online:<tab><tab><tab>self.p.send_now(""M221 S"" + l)<tab><tab><tab>self.log(_(""Setting print flow factor to %d%%."") % flow)<tab><tab>else:<tab><tab><tab>self.logError(_(""Printer is not online.""))<tab>except Exception as x:<tab><tab>self.logError(_(""You must enter a flow. (%s)"") % (repr(x),))",0,"if not isinstance ( l , str ) or not len ( l ) :",if self . flow_slider . GetValue ( ) :,0.01705629655576207,6.196349981371174,0.16666666666666666
"def sources():<tab>for d in os.listdir(base):<tab><tab>#<tab><tab>if d.startswith('talis'):<tab><tab>#<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if d == ""indcat"":<tab><tab><tab>continue<tab><tab>if not os.path.isdir(base + d):<tab><tab><tab>continue<tab><tab>yield d",0,"if d . endswith ( ""old"" ) :",if not os . path . isfile ( base + d ) :,0.03065277000387358,8.130850857597444,0.19444444444444445
"def create_accumulator(self) -> tf_metric_accumulators.TFCompilableMetricsAccumulator:<tab>configs = zip(self._metric_configs, self._loss_configs)<tab>padding_options = None<tab>if self._eval_config is not None:<tab><tab>model_spec = model_util.get_model_spec(self._eval_config, self._model_name)<tab><tab><IF-STMT><tab><tab><tab>padding_options = model_spec.padding_options<tab>return tf_metric_accumulators.TFCompilableMetricsAccumulator(<tab><tab>padding_options,<tab><tab>[len(m) + len(l) for m, l in configs],<tab><tab>desired_batch_size=self._desired_batch_size,<tab>)",0,"if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :",if model_spec . padding_options is not None :,0.15037095807957096,25.185051117461814,0.6964285714285714
"def parseImpl(self, instring, loc, doActions=True):<tab>try:<tab><tab>loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)<tab>except (ParseException, IndexError):<tab><tab><IF-STMT><tab><tab><tab>if self.expr.resultsName:<tab><tab><tab><tab>tokens = ParseResults([self.defaultValue])<tab><tab><tab><tab>tokens[self.expr.resultsName] = self.defaultValue<tab><tab><tab>else:<tab><tab><tab><tab>tokens = [self.defaultValue]<tab><tab>else:<tab><tab><tab>tokens = []<tab>return loc, tokens",0,if self . defaultValue is not self . __optionalNotMatched :,if self . expr . default is not None :,0.1796253783189406,17.491650626361267,0.2804232804232804
"def handleConnection(self):<tab># connection handshake<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>self.csock.close()<tab>except:<tab><tab>ex_t, ex_v, ex_tb = sys.exc_info()<tab><tab>tb = util.formatTraceback(ex_t, ex_v, ex_tb)<tab><tab>log.warning(""error during connect/handshake: %s; %s"", ex_v, ""\n"".join(tb))<tab><tab>self.csock.close()<tab>return False",0,if self . daemon . _handshake ( self . csock ) :,if self . csock . handshake ( ) :,0.16098041806937208,22.39432166577063,0.43333333333333335
"def getProc(su, innerTarget):<tab>if len(su) == 1:  # have a one element wedge<tab><tab>proc = (""first"", ""last"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>proc = (""first"", ""last"")  # same element can be first and last<tab><tab>elif su.isFirst(innerTarget):<tab><tab><tab>proc = (""first"",)<tab><tab>elif su.isLast(innerTarget):<tab><tab><tab>proc = (""last"",)<tab><tab>else:<tab><tab><tab>proc = ()<tab>return proc",0,if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,if su . first == innerTarget :,0.0350980795480919,9.736604043215582,0.38888888888888884
"def get_color_dtype(data, column_names):<tab>has_color = all(column in data[""points""] for column in column_names)<tab>if has_color:<tab><tab>color_data_types = [<tab><tab><tab>data[""points""][column_name].dtype for column_name in column_names<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>f""Data types of color values are inconsistent: got {color_data_types}""<tab><tab><tab>)<tab><tab>color_data_type = color_data_types[0]<tab>else:<tab><tab>color_data_type = None<tab>return color_data_type",0,if len ( set ( color_data_types ) ) > 1 :,if len ( color_data_types ) != 1 :,0.15974423575173982,52.30193450457853,0.5866666666666667
"def close(self):<tab>children = []<tab>for children_part, line_offset, last_line_offset_leaf in self.children_groups:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>_update_positions(children_part, line_offset, last_line_offset_leaf)<tab><tab><tab>except _PositionUpdatingFinished:<tab><tab><tab><tab>pass<tab><tab>children += children_part<tab>self.tree_node.children = children<tab># Reset the parents<tab>for node in children:<tab><tab>node.parent = self.tree_node",0,if line_offset != 0 :,if children_part :,0.03549272049582243,1e-10,0.6190476190476191
"def get_multi(self, keys, index=None):<tab>with self._lmdb.begin() as txn:<tab><tab>result = []<tab><tab>for key in keys:<tab><tab><tab>packed = txn.get(key.encode())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append((key, cbor.loads(packed)))<tab>return result",1,if packed is not None :,if packed is not None :,0.75,100.00000000000004,1.0
"def get_directory_info(prefix, pth, recursive):<tab>res = []<tab>directory = os.listdir(pth)<tab>directory.sort()<tab>for p in directory:<tab><tab>if p[0] != ""."":<tab><tab><tab>subp = os.path.join(pth, p)<tab><tab><tab>p = os.path.join(prefix, p)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append([p, get_directory_info(prefix, subp, 1)])<tab><tab><tab>else:<tab><tab><tab><tab>res.append([p, None])<tab>return res",0,if recursive and os . path . isdir ( subp ) :,if recursive :,0.014772183860219553,1e-10,0.3333333333333333
"def __schedule(self, workflow_scheduler_id, workflow_scheduler):<tab>invocation_ids = self.__active_invocation_ids(workflow_scheduler_id)<tab>for invocation_id in invocation_ids:<tab><tab>log.debug(""Attempting to schedule workflow invocation [%s]"", invocation_id)<tab><tab>self.__attempt_schedule(invocation_id, workflow_scheduler)<tab><tab><IF-STMT><tab><tab><tab>return",0,if not self . monitor_running :,if not self . is_scheduled_invocation ( invocation_id ) :,0.2991635861874485,18.20705281109213,1.0
"def write(self, data):<tab>self.size -= len(data)<tab>passon = None<tab>if self.size > 0:<tab><tab>self.data.append(data)<tab>else:<tab><tab>if self.size:<tab><tab><tab>data, passon = data[: self.size], data[self.size :]<tab><tab>else:<tab><tab><tab>passon = b""""<tab><tab><IF-STMT><tab><tab><tab>self.data.append(data)<tab>return passon",1,if data :,if data :,0.5311706625951745,1e-10,1.0
"def __getstate__(self):<tab>try:<tab><tab>store_func, load_func = self.store_function, self.load_function<tab><tab>self.store_function, self.load_function = None, None<tab><tab># ignore analyses. we re-initialize analyses when restoring from pickling so that we do not lose any newly<tab><tab># added analyses classes<tab><tab>d = dict(<tab><tab><tab>(k, v)<tab><tab><tab>for k, v in self.__dict__.items()<tab><tab><tab><IF-STMT><tab><tab><tab>not in {<tab><tab><tab><tab>""analyses"",<tab><tab><tab>}<tab><tab>)<tab><tab>return d<tab>finally:<tab><tab>self.store_function, self.load_function = store_func, load_func",0,if k,"if not k . startswith ( ""_"" )",0.1777148960460076,1e-10,0.36
"def mouse_down(self, event):<tab>if event.button == 1:<tab><tab>if self.scrolling:<tab><tab><tab>p = event.local<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.scroll_up()<tab><tab><tab><tab>return<tab><tab><tab>elif self.scroll_down_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_down()<tab><tab><tab><tab>return<tab>if event.button == 4:<tab><tab>self.scroll_up()<tab>if event.button == 5:<tab><tab>self.scroll_down()<tab>GridView.mouse_down(self, event)",1,if self . scroll_up_rect ( ) . collidepoint ( p ) :,if self . scroll_up_rect ( ) . collidepoint ( p ) :,0.75,100.00000000000004,1.0
"def on_api_command(self, command, data):<tab>if command == ""select"":<tab><tab>if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can():<tab><tab><tab>return flask.abort(403, ""Insufficient permissions"")<tab><tab>if self._prompt is None:<tab><tab><tab>return flask.abort(409, ""No active prompt"")<tab><tab>choice = data[""choice""]<tab><tab><IF-STMT><tab><tab><tab>return flask.abort(<tab><tab><tab><tab>400, ""{!r} is not a valid value for choice"".format(choice)<tab><tab><tab>)<tab><tab>self._answer_prompt(choice)",0,"if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) :",if not self . _prompt . can ( choice ) :,0.1593102976501964,29.06333384992301,0.2777777777777778
"def register_predictors(self, model_data_arr):<tab>for integration in self._get_integrations():<tab><tab><IF-STMT><tab><tab><tab>integration.register_predictors(model_data_arr)<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>f""There is no connection to {integration.name}. predictor wouldn't be registred.""<tab><tab><tab>)",0,if integration . check_connection ( ) :,if integration . name in model_data_arr :,0.09056531419355518,15.851165692617148,0.55
"def _pack_shears(shearData):<tab>shears = list()<tab>vidxs = list()<tab>for e_idx, entry in enumerate(shearData):<tab><tab># Should be 3 entries<tab><tab><IF-STMT><tab><tab><tab>shears.extend([float(""nan""), float(""nan"")])<tab><tab><tab>vidxs.extend([0, 0])<tab><tab>else:<tab><tab><tab>vidx1, vidx2, shear1, shear2 = entry<tab><tab><tab>shears.extend([shear1, shear2])<tab><tab><tab>vidxs.extend([vidx1, vidx2])<tab>return (np.asarray(shears, dtype=np.float32), np.asarray(vidxs, dtype=np.uint32))",0,if entry is None :,if e_idx == 3 :,0.03412306583404374,6.567274736060395,0.25
"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]:<tab>yield ""Core"", ""0""<tab>for _dir in data_manager.cog_data_path().iterdir():<tab><tab>fpath = _dir / ""settings.json""<tab><tab>if not fpath.exists():<tab><tab><tab>continue<tab><tab>with fpath.open() as f:<tab><tab><tab>try:<tab><tab><tab><tab>data = json.load(f)<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>continue<tab><tab>if not isinstance(data, dict):<tab><tab><tab>continue<tab><tab>cog_name = _dir.stem<tab><tab>for cog_id, inner in data.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>yield cog_name, cog_id",0,"if not isinstance ( inner , dict ) :",if not inner . startswith ( cog_name ) :,0.040407114065131935,11.731175160263996,0.4126984126984127
"def subFeaName(m, newNames, state):<tab>try:<tab><tab>int(m[3], 16)<tab>except:<tab><tab>return m[0]<tab>name = m[2]<tab>if name in newNames:<tab><tab># print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4]))<tab><tab><IF-STMT><tab><tab><tab>print(""sub %r => %r"" % (m[0], m[1] + newNames[name] + m[4]))<tab><tab>state[""didChange""] = True<tab><tab>return m[1] + newNames[name] + m[4]<tab>return m[0]",0,"if name == ""uni0402"" :",elif name in state :,0.029764206438018782,6.9717291216921975,0.25
"def log_graph(self, model: LightningModule, input_array=None):<tab>if self._log_graph:<tab><tab>if input_array is None:<tab><tab><tab>input_array = model.example_input_array<tab><tab><IF-STMT><tab><tab><tab>input_array = model._apply_batch_transfer_handler(input_array)<tab><tab><tab>self.experiment.add_graph(model, input_array)<tab><tab>else:<tab><tab><tab>rank_zero_warn(<tab><tab><tab><tab>""Could not log computational graph since the""<tab><tab><tab><tab>"" `model.example_input_array` attribute is not set""<tab><tab><tab><tab>"" or `input_array` was not given"",<tab><tab><tab><tab>UserWarning,<tab><tab><tab>)",0,if input_array is not None :,elif model . _apply_batch_transfer_handler is not None :,0.29823359503547475,17.395797375642243,0.12244897959183673
"def apply(self, db, person):<tab>for family_handle in person.get_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>for event_ref in family.get_event_ref_list():<tab><tab><tab><tab>if event_ref:<tab><tab><tab><tab><tab>event = db.get_event_from_handle(event_ref.ref)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab>if not event.get_date_object():<tab><tab><tab><tab><tab><tab>return True<tab>return False",0,if not event . get_place_handle ( ) :,if not event :,0.07898193091364736,8.64715459852499,1.0
"def format(m):<tab>if m > 1000:<tab><tab><IF-STMT><tab><tab><tab>return (str(int(m / 1000)), ""km"")<tab><tab>else:<tab><tab><tab>return (str(round(m / 1000, 1)), ""km"")<tab>return (str(m), ""m"")",1,if m % 1000 == 0 :,if m % 1000 == 0 :,0.75,100.00000000000004,1.0
"def previous(self):<tab>try:<tab><tab>idx = _jump_list_index<tab><tab>next_index = idx + 1<tab><tab><IF-STMT><tab><tab><tab>next_index = 100<tab><tab>next_index = min(len(_jump_list) - 1, next_index)<tab><tab>_jump_list_index = next_index<tab><tab>return _jump_list[next_index]<tab>except (IndexError, KeyError) as e:<tab><tab>return None",0,if next_index > 100 :,if len ( _jump_list ) > 100 :,0.1102731445124358,15.851165692617148,0.4772727272727273
"def _validate_and_set_default_hyperparameters(self):<tab>""""""Placeholder docstring""""""<tab># Check if all the required hyperparameters are set. If there is a default value<tab># for one, set it.<tab>for name, definition in self.hyperparameter_definitions.items():<tab><tab>if name not in self.hyperparam_dict:<tab><tab><tab>spec = definition[""spec""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.hyperparam_dict[name] = spec[""DefaultValue""]<tab><tab><tab>elif ""IsRequired"" in spec and spec[""IsRequired""]:<tab><tab><tab><tab>raise ValueError(""Required hyperparameter: %s is not set"" % name)",1,"if ""DefaultValue"" in spec :","if ""DefaultValue"" in spec :",0.75,100.00000000000004,1.0
"def _actions_read(self, c):<tab>self.action_input.handle_read(c)<tab>if c in [curses.KEY_ENTER, util.KEY_ENTER2]:<tab><tab># take action<tab><tab>if self.action_input.selected_index == 0:  # Cancel<tab><tab><tab>self.back_to_parent()<tab><tab><IF-STMT>  # Apply<tab><tab><tab>self._apply_prefs()<tab><tab><tab>client.core.get_config().addCallback(self._update_preferences)<tab><tab>elif self.action_input.selected_index == 2:  # OK<tab><tab><tab>self._apply_prefs()<tab><tab><tab>self.back_to_parent()",1,elif self . action_input . selected_index == 1 :,elif self . action_input . selected_index == 1 :,1.0,100.00000000000004,1.0
"def _split_anonymous_function(s):<tab># Regex is not sufficient to handle differences between anonymous<tab># functions and YAML encoded lists. We perform a sniff test to see<tab># if it might be an anonymous function and then confirm by<tab># decoding it as YAML and testing the result.<tab>if s[:1] == ""["" and s[-1:] == ""]"" and "":"" in s:<tab><tab>try:<tab><tab><tab>l = yaml_util.decode_yaml(s)<tab><tab>except Exception:<tab><tab><tab>return None, s[1:-1]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None, s[1:-1]<tab>return None",0,"if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :","if l . startswith ( ""["" ) or l . startswith ( ""]"" ) :",0.2618023327827335,4.069734591315274,0.15625
"def test_source_address(self):<tab>for addr, is_ipv6 in VALID_SOURCE_ADDRESSES:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(""No IPv6 support: skipping."", NoIPv6Warning)<tab><tab><tab>continue<tab><tab>pool = HTTPConnectionPool(<tab><tab><tab>self.host, self.port, source_address=addr, retries=False<tab><tab>)<tab><tab>self.addCleanup(pool.close)<tab><tab>r = pool.request(""GET"", ""/source_address"")<tab><tab>self.assertEqual(r.data, b(addr[0]))",0,if is_ipv6 and not HAS_IPV6_AND_DNS :,if not is_ipv6 :,0.08233567403482892,9.471153562668167,0.4642857142857143
"def vim_G(self):<tab>""""""Put the cursor on the last character of the file.""""""<tab>if self.is_text_wrapper(self.w):<tab><tab><IF-STMT><tab><tab><tab>self.do(""end-of-buffer-extend-selection"")<tab><tab>else:<tab><tab><tab>self.do(""end-of-buffer"")<tab><tab>self.done()<tab>else:<tab><tab>self.quit()",1,"if self . state == ""visual"" :","if self . state == ""visual"" :",0.75,100.00000000000004,1.0
"def backend_supported(module, manager, **kwargs):<tab>if CollectionNodeModule.backend_supported(module, manager, **kwargs):<tab><tab>if ""tid"" not in kwargs:<tab><tab><tab>return True<tab><tab>conn = manager.connection(did=kwargs[""did""])<tab><tab>template_path = ""partitions/sql/{0}/#{0}#{1}#"".format(<tab><tab><tab>manager.server_type, manager.version<tab><tab>)<tab><tab>SQL = render_template(<tab><tab><tab>""/"".join([template_path, ""backend_support.sql""]), tid=kwargs[""tid""]<tab><tab>)<tab><tab>status, res = conn.execute_scalar(SQL)<tab><tab># check if any errors<tab><tab><IF-STMT><tab><tab><tab>return internal_server_error(errormsg=res)<tab><tab>return res",0,if not status :,if status != 200 :,0.045150550804307965,10.682175159905853,0.4
"def _get_regex_config(self, data_asset_name: Optional[str] = None) -> dict:<tab>regex_config: dict = copy.deepcopy(self._default_regex)<tab>asset: Optional[Asset] = None<tab>if data_asset_name:<tab><tab>asset = self._get_asset(data_asset_name=data_asset_name)<tab>if asset is not None:<tab><tab># Override the defaults<tab><tab><IF-STMT><tab><tab><tab>regex_config[""pattern""] = asset.pattern<tab><tab>if asset.group_names:<tab><tab><tab>regex_config[""group_names""] = asset.group_names<tab>return regex_config",1,if asset . pattern :,if asset . pattern :,0.75,100.00000000000004,1.0
"def resolve(self, other):<tab>if other == ANY_TYPE:<tab><tab>return self<tab>elif isinstance(other, ComplexType):<tab><tab>f = self.first.resolve(other.first)<tab><tab>s = self.second.resolve(other.second)<tab><tab><IF-STMT><tab><tab><tab>return ComplexType(f, s)<tab><tab>else:<tab><tab><tab>return None<tab>elif self == ANY_TYPE:<tab><tab>return other<tab>else:<tab><tab>return None",0,if f and s :,if f is not None and s is not None :,0.05737859180434831,11.208466750961147,0.28125
"def collect_pages(app):<tab>new_images = {}<tab>for full_path, basename in app.builder.images.iteritems():<tab><tab>base, ext = os.path.splitext(full_path)<tab><tab>retina_path = base + ""@2x"" + ext<tab><tab><IF-STMT><tab><tab><tab>new_images[retina_path] = app.env.images[retina_path][1]<tab>app.builder.images.update(new_images)<tab>return []",1,if retina_path in app . env . images :,if retina_path in app . env . images :,0.75,100.00000000000004,1.0
"def has_bad_headers(self):<tab>headers = [self.sender, self.reply_to] + self.recipients<tab>for header in headers:<tab><tab>if _has_newline(header):<tab><tab><tab>return True<tab>if self.subject:<tab><tab>if _has_newline(self.subject):<tab><tab><tab>for linenum, line in enumerate(self.subject.split(""\r\n"")):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if linenum > 0 and line[0] not in ""\t "":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if _has_newline(line):<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if len(line.strip()) == 0:<tab><tab><tab><tab><tab>return True<tab>return False",0,if not line :,if linenum == 0 :,0.04240785919217091,9.652434877402245,0.3333333333333333
"def reader():<tab>try:<tab><tab>imgs = mp4_loader(video_path, seg_num, seglen, mode)<tab><tab><IF-STMT><tab><tab><tab>logger.error(<tab><tab><tab><tab>""{} frame length {} less than 1."".format(video_path, len(imgs))<tab><tab><tab>)<tab><tab><tab>yield None, None<tab>except:<tab><tab>logger.error(""Error when loading {}"".format(mp4_path))<tab><tab>yield None, None<tab>imgs_ret = imgs_transform(<tab><tab>imgs, mode, seg_num, seglen, short_size, target_size, img_mean, img_std<tab>)<tab>label_ret = video_path<tab>yield imgs_ret, label_ret",0,if len ( imgs ) < 1 :,if len ( imgs ) > 1 :,0.5490406812970063,59.4603557501361,1.0
"def translate_from_sortname(name, sortname):<tab>""""""'Translate' the artist name by reversing the sortname.""""""<tab>for c in name:<tab><tab>ctg = unicodedata.category(c)<tab><tab><IF-STMT><tab><tab><tab>for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""):<tab><tab><tab><tab>if separator in sortname:<tab><tab><tab><tab><tab>parts = sortname.split(separator)<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>parts = [sortname]<tab><tab><tab><tab>separator = """"<tab><tab><tab>return separator.join(map(_reverse_sortname, parts))<tab>return name",0,"if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :","if cg != ""y"" :",0.003549742659956715,1.0060502397876319,0.16363636363636364
"def _to_local_path(path):<tab>""""""Convert local path to SFTP path""""""<tab>if sys.platform == ""win32"":  # pragma: no cover<tab><tab>path = os.fsdecode(path)<tab><tab><IF-STMT><tab><tab><tab>path = path[1:]<tab><tab>path = path.replace(""/"", ""\\"")<tab>return path",0,"if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :","if path [ 0 ] == ""\\"" :",0.03196731530050978,12.571299163620896,0.3141025641025641
"def __call__(self, text: str) -> str:<tab>for t in self.cleaner_types:<tab><tab>if t == ""tacotron"":<tab><tab><tab>text = tacotron_cleaner.cleaners.custom_english_cleaners(text)<tab><tab><IF-STMT><tab><tab><tab>text = jaconv.normalize(text)<tab><tab>elif t == ""vietnamese"":<tab><tab><tab>if vietnamese_cleaners is None:<tab><tab><tab><tab>raise RuntimeError(""Please install underthesea"")<tab><tab><tab>text = vietnamese_cleaners.vietnamese_cleaner(text)<tab><tab>else:<tab><tab><tab>raise RuntimeError(f""Not supported: type={t}"")<tab>return text",1,"elif t == ""jaconv"" :","elif t == ""jaconv"" :",1.0,100.00000000000004,1.0
"def cb_syncthing_system_data(self, daemon, mem, cpu, d_failed, d_total):<tab>if self.daemon.get_my_id() in self.devices:<tab><tab># Update my device display<tab><tab>device = self.devices[self.daemon.get_my_id()]<tab><tab>device[""ram""] = sizeof_fmt(mem)<tab><tab>device[""cpu""] = ""%3.2f%%"" % (cpu)<tab><tab><IF-STMT><tab><tab><tab>device[""announce""] = _(""disabled"")<tab><tab>else:<tab><tab><tab>device[""announce""] = ""%s/%s"" % (d_total - d_failed, d_total)",0,if d_total == 0 :,if d_failed == 0 :,0.39477865547525276,50.000000000000014,1.0
"def update_kls(self, sampled_kls):<tab>for i, kl in enumerate(sampled_kls):<tab><tab><IF-STMT><tab><tab><tab>self.kl_coeff_val[i] *= 0.5<tab><tab>elif kl > 1.5 * self.kl_target:<tab><tab><tab>self.kl_coeff_val[i] *= 2.0<tab>return self.kl_coeff_val",0,if kl < self . kl_target / 1.5 :,if kl < 0.5 * self . kl_target :,0.1048262086007482,48.326978309062206,1.0
"def DeleteEmptyCols(self):<tab>cols2delete = []<tab>for c in range(0, self.GetCols()):<tab><tab>f = True<tab><tab>for r in range(0, self.GetRows()):<tab><tab><tab>if self.FindItemAtPosition((r, c)) is not None:<tab><tab><tab><tab>f = False<tab><tab><IF-STMT><tab><tab><tab>cols2delete.append(c)<tab>for i in range(0, len(cols2delete)):<tab><tab>self.ShiftColsLeft(cols2delete[i] + 1)<tab><tab>cols2delete = [x - 1 for x in cols2delete]",1,if f :,if f :,0.5311706625951745,1e-10,1.0
"def get_session(self):<tab>if self._session is None:<tab><tab>session = super(ChildResourceManager, self).get_session()<tab><tab><IF-STMT><tab><tab><tab>session = session.get_session_for_resource(self.resource_type.resource)<tab><tab>self._session = session<tab>return self._session",0,if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY :,"if hasattr ( session , ""get_session_for_resource"" ) :",0.012500875711412129,3.377811044913357,0.2761904761904762
"def _get_master_authorized_networks_config(self, raw_cluster):<tab>if raw_cluster.get(""masterAuthorizedNetworksConfig""):<tab><tab>config = raw_cluster.get(""masterAuthorizedNetworksConfig"")<tab><tab>config[""includes_public_cidr""] = False<tab><tab>for block in config[""cidrBlocks""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config[""includes_public_cidr""] = True<tab><tab>return config<tab>else:<tab><tab>return {""enabled"": False, ""cidrBlocks"": [], ""includes_public_cidr"": False}",0,"if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :","if block . get ( ""enabled"" ) :",0.03440097137874616,6.4005180884547785,0.7272727272727273
"def scan_folder(folder):<tab>scanned_files = []<tab>for root, dirs, files in os.walk(folder):<tab><tab>dirs[:] = [d for d in dirs if d != ""__pycache__""]<tab><tab>relative_path = os.path.relpath(root, folder)<tab><tab>for f in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>relative_name = os.path.normpath(os.path.join(relative_path, f)).replace(<tab><tab><tab><tab>""\\"", ""/""<tab><tab><tab>)<tab><tab><tab>scanned_files.append(relative_name)<tab>return sorted(scanned_files)",0,"if f . endswith ( "".pyc"" ) :","if f == ""__pycache__"" :",0.0354018406734773,8.516593018819643,0.7272727272727273
"def read_progress(self):<tab>while True:<tab><tab>processed_file = self.queue.get()<tab><tab>self.threading_completed.append(processed_file)<tab><tab>total_number = len(self.file_list)<tab><tab>completed_number = len(self.threading_completed)<tab><tab># Just for the record, this slows down book searching by about 20%<tab><tab>if _progress_emitter:  # Skip update in reading mode<tab><tab><tab>_progress_emitter.update_progress(completed_number * 100 // total_number)<tab><tab><IF-STMT><tab><tab><tab>break",0,if total_number == completed_number :,if completed_number >= total_number :,0.28849878646896243,34.018746665856,1.0
"def next_instruction_is_function_or_class(lines):<tab>""""""Is the first non-empty, non-commented line of the cell either a function or a class?""""""<tab>parser = StringParser(""python"")<tab>for i, line in enumerate(lines):<tab><tab>if parser.is_quoted():<tab><tab><tab>parser.read_line(line)<tab><tab><tab>continue<tab><tab>parser.read_line(line)<tab><tab>if not line.strip():  # empty line<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>if line.startswith(""def "") or line.startswith(""class ""):<tab><tab><tab>return True<tab><tab>if line.startswith((""#"", ""@"", "" "", "")"")):<tab><tab><tab>continue<tab><tab>return False<tab>return False",0,if i > 0 and not lines [ i - 1 ] . strip ( ) :,if parser . is_quoted ( ) :,0.05162328205935975,8.290056966884416,0.16956521739130434
def __next__(self):<tab>try:<tab><tab>data = next(self.iter_loader)<tab>except StopIteration:<tab><tab>self._epoch += 1<tab><tab><IF-STMT><tab><tab><tab>self._dataloader.sampler.set_epoch(self._epoch)<tab><tab>self.iter_loader = iter(self._dataloader)<tab><tab>data = next(self.iter_loader)<tab>return data,0,"if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :",if self . _dataloader is not None :,0.04949642924785472,13.579714487002688,0.24166666666666667
"def dgl_mp_batchify_fn(data):<tab>if isinstance(data[0], tuple):<tab><tab>data = zip(*data)<tab><tab>return [dgl_mp_batchify_fn(i) for i in data]<tab>for dt in data:<tab><tab>if dt is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return [d for d in data if isinstance(d, dgl.DGLGraph)]<tab><tab><tab>elif isinstance(dt, nd.NDArray):<tab><tab><tab><tab>pad = Pad(axis=(1, 2), num_shards=1, ret_length=False)<tab><tab><tab><tab>data_list = [dt for dt in data if dt is not None]<tab><tab><tab><tab>return pad(data_list)",1,"if isinstance ( dt , dgl . DGLGraph ) :","if isinstance ( dt , dgl . DGLGraph ) :",0.75,100.00000000000004,1.0
"def f(self, info):<tab>for k in keys:<tab><tab><IF-STMT><tab><tab><tab>for k2 in list(info.keys()):<tab><tab><tab><tab>if k(k2):<tab><tab><tab><tab><tab>info.pop(k2)<tab><tab>else:<tab><tab><tab>info.pop(k, None)",0,if callable ( k ) :,"if isinstance ( info , dict ) :",0.04432760343703879,13.134549472120788,0.2698412698412698
"def create(path, binary=False):<tab>for i in range(10):<tab><tab>try:<tab><tab><tab>os.makedirs(os.path.dirname(path), exist_ok=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return open(path, ""wb"")<tab><tab><tab>else:<tab><tab><tab><tab>return open(path, ""w"", encoding=""utf-8"")<tab><tab><tab>if i > 0:<tab><tab><tab><tab>log(True, f""Created {path} at attempt {i + 1}"")<tab><tab>except:<tab><tab><tab>time.sleep(0.5)<tab>else:<tab><tab>raise Error(f""Failed to create {path}"")",1,if binary :,if binary :,0.5311706625951745,1e-10,1.0
"def validate_update(self, update_query):<tab>structure = DotCollapsedDict(self.doc_class.structure)<tab>for op, fields in update_query.iteritems():<tab><tab>for field in fields:<tab><tab><tab>if op != ""$unset"" and op != ""$rename"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise UpdateQueryError(<tab><tab><tab><tab><tab><tab>""'%s' not found in %s's structure""<tab><tab><tab><tab><tab><tab>% (field, self.doc_class.__name__)<tab><tab><tab><tab><tab>)",1,if field not in structure :,if field not in structure :,0.75,100.00000000000004,1.0
"def check_enums_ATLAS_ISAEXT(lines):<tab>for i, isaext in enumerate(ATLAS_ISAEXT):<tab><tab>got = lines.pop(0).strip()<tab><tab><IF-STMT><tab><tab><tab>expect = ""none: 1""<tab><tab>else:<tab><tab><tab>expect = ""{0}: {1}"".format(isaext, 1 << i)<tab><tab>if got != expect:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""ATLAS_ISAEXT mismatch at position ""<tab><tab><tab><tab>+ str(i)<tab><tab><tab><tab>+ "": got >>""<tab><tab><tab><tab>+ got<tab><tab><tab><tab>+ ""<<, expected >>""<tab><tab><tab><tab>+ expect<tab><tab><tab><tab>+ ""<<""<tab><tab><tab>)",0,if i == 0 :,"if isaext == """" :",0.03654024892898815,15.619699684601283,0.36
"def _test_export_session_csv(self, test_session=None):<tab>with self.app.test_request_context():<tab><tab><IF-STMT><tab><tab><tab>test_session = SessionFactory()<tab><tab>field_data = export_sessions_csv([test_session])<tab><tab>session_row = field_data[1]<tab><tab>self.assertEqual(session_row[0], ""example (accepted)"")<tab><tab>self.assertEqual(session_row[9], ""accepted"")",0,if not test_session :,if test_session is None :,0.045150550804307965,27.77619034011791,0.36
"def get_report_to_platform(self, args, scan_reports):<tab>if self.bc_api_key:<tab><tab><IF-STMT><tab><tab><tab>repo_id = self.get_repository(args)<tab><tab><tab>self.setup_bridgecrew_credentials(<tab><tab><tab><tab>bc_api_key=self.bc_api_key, repo_id=repo_id<tab><tab><tab>)<tab><tab>if self.is_integration_configured():<tab><tab><tab>self._upload_run(args, scan_reports)",0,if args . directory :,if self . is_bridgecrew_configured ( ) :,0.029730601197949243,4.9323515694897075,0.37777777777777777
"def test_fvalue(self):<tab>if not getattr(self, ""skip_f"", False):<tab><tab>rtol = getattr(self, ""rtol"", 1e-10)<tab><tab>assert_allclose(self.res1.fvalue, self.res2.F, rtol=rtol)<tab><tab><IF-STMT><tab><tab><tab># only available with ivreg2<tab><tab><tab>assert_allclose(self.res1.f_pvalue, self.res2.Fp, rtol=rtol)<tab>else:<tab><tab>raise pytest.skip(""TODO: document why this test is skipped"")",0,"if hasattr ( self . res2 , ""Fp"" ) :",if self . use_ivreg2 :,0.026933810325055336,7.64649370538093,0.37142857142857144
"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab>if type(e) is Argument or type(e) is Option and e.argcount:<tab><tab><tab><tab>if e.value is None:<tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab>if type(e) is Command or type(e) is Option and e.argcount == 0:<tab><tab><tab><tab>e.value = 0<tab>return self",1,elif type ( e . value ) is not list :,elif type ( e . value ) is not list :,0.75,100.00000000000004,1.0
"def touch(self):<tab>if not self.exists():<tab><tab>try:<tab><tab><tab>self.parent().touch()<tab><tab>except ValueError:<tab><tab><tab>pass<tab><tab>node = self._fs.touch(self.pathnames, {})<tab><tab>if not node.isdir:<tab><tab><tab>raise AssertionError(""Not a folder: %s"" % self.path)<tab><tab><IF-STMT><tab><tab><tab>self.watcher.emit(""created"", self)",1,if self . watcher :,if self . watcher :,0.75,100.00000000000004,1.0
"def __init__(self, _inf=None, _tzinfos=None):<tab>if _inf:<tab><tab>self._tzinfos = _tzinfos<tab><tab>self._utcoffset, self._dst, self._tzname = _inf<tab>else:<tab><tab>_tzinfos = {}<tab><tab>self._tzinfos = _tzinfos<tab><tab>self._utcoffset, self._dst, self._tzname = self._transition_info[0]<tab><tab>_tzinfos[self._transition_info[0]] = self<tab><tab>for inf in self._transition_info[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_tzinfos[inf] = self.__class__(inf, _tzinfos)",0,if not _tzinfos . has_key ( inf ) :,if inf not in _tzinfos :,0.018728518225177467,8.462236332847391,0.38181818181818183
"def test_sample_output():<tab>comment = ""SAMPLE OUTPUT""<tab>skip_files = [""__init__.py""]<tab>errors = []<tab>for _file in sorted(MODULE_PATH.iterdir()):<tab><tab><IF-STMT><tab><tab><tab>with _file.open() as f:<tab><tab><tab><tab>if comment not in f.read():<tab><tab><tab><tab><tab>errors.append((comment, _file))<tab>if errors:<tab><tab>line = ""Missing sample error(s) detected!\n\n""<tab><tab>for error in errors:<tab><tab><tab>line += ""`{}` is not in module `{}`\n"".format(*error)<tab><tab>print(line[:-1])<tab><tab>assert False",0,"if _file . suffix == "".py"" and _file . name not in skip_files :","if _file . suffix == "".py"" and _file . suffix in skip_files :",0.7455942465972385,82.5349877279405,0.515406162464986
"def http_get(url, target):<tab>req = requests.get(url, stream=True)<tab>content_length = req.headers.get(""Content-Length"")<tab>total = int(content_length) if content_length is not None else None<tab>progress = tqdm(unit=""B"", total=total)<tab>with open(target, ""wb"") as target_file:<tab><tab>for chunk in req.iter_content(chunk_size=1024):<tab><tab><tab><IF-STMT>  # filter out keep-alive new chunks<tab><tab><tab><tab>progress.update(len(chunk))<tab><tab><tab><tab>target_file.write(chunk)<tab>progress.close()",1,if chunk :,if chunk :,0.5311706625951745,1e-10,1.0
"def _elements_to_datasets(self, elements, level=0):<tab>for element in elements:<tab><tab>extra_kwds = {""identifier_%d"" % level: element[""name""]}<tab><tab><IF-STMT><tab><tab><tab>for inner_element in self._elements_to_datasets(<tab><tab><tab><tab>element[""elements""], level=level + 1<tab><tab><tab>):<tab><tab><tab><tab>dataset = extra_kwds.copy()<tab><tab><tab><tab>dataset.update(inner_element)<tab><tab><tab><tab>yield dataset<tab><tab>else:<tab><tab><tab>dataset = extra_kwds<tab><tab><tab>extra_kwds.update(element)<tab><tab><tab>yield extra_kwds",1,"if ""elements"" in element :","if ""elements"" in element :",0.75,100.00000000000004,1.0
"def update_dict(a, b):<tab>for key, value in b.items():<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>a[key] = value<tab><tab>elif isinstance(a[key], dict) and isinstance(value, dict):<tab><tab><tab>update_dict(a[key], value)<tab><tab>elif isinstance(a[key], list):<tab><tab><tab>a[key].append(value)<tab><tab>else:<tab><tab><tab>a[key] = [a[key], value]",0,if key not in a :,elif key not in a :,0.45714399765700364,75.98356856515926,0.7142857142857143
"def scan(self, targets):<tab>for target in targets:<tab><tab>target.print_infos()<tab><tab>if self.is_interesting(target):<tab><tab><tab>self.target[""other""].append(target)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return target<tab>return None",0,if self . match ( target ) :,if self . scan_target ( target ) :,0.5014622369176811,37.99178428257963,0.5777777777777777
"def printConnections(switches):<tab>""Compactly print connected nodes to each switch""<tab>for sw in switches:<tab><tab>output(""%s: "" % sw)<tab><tab>for intf in sw.intfList():<tab><tab><tab>link = intf.link<tab><tab><tab><IF-STMT><tab><tab><tab><tab>intf1, intf2 = link.intf1, link.intf2<tab><tab><tab><tab>remote = intf1 if intf1.node != sw else intf2<tab><tab><tab><tab>output(""%s(%s) "" % (remote.node, sw.ports[intf]))<tab><tab>output(""\n"")",1,if link :,if link :,0.5311706625951745,1e-10,1.0
"def __cut(sentence):<tab>global emit_P<tab>prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P)<tab>begin, nexti = 0, 0<tab># print pos_list, sentence<tab>for i, char in enumerate(sentence):<tab><tab>pos = pos_list[i]<tab><tab>if pos == ""B"":<tab><tab><tab>begin = i<tab><tab><IF-STMT><tab><tab><tab>yield sentence[begin : i + 1]<tab><tab><tab>nexti = i + 1<tab><tab>elif pos == ""S"":<tab><tab><tab>yield char<tab><tab><tab>nexti = i + 1<tab>if nexti < len(sentence):<tab><tab>yield sentence[nexti:]",0,"elif pos == ""E"" :","elif pos == ""A"" :",0.6428720214849399,59.4603557501361,1.0
"def check_files(self, paths=None):<tab>""""""Run all checks on the paths.""""""<tab>if paths is None:<tab><tab>paths = self.paths<tab>report = self.options.report<tab>runner = self.runner<tab>report.start()<tab>try:<tab><tab>for path in paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.input_dir(path)<tab><tab><tab>elif not self.excluded(path):<tab><tab><tab><tab>runner(path)<tab>except KeyboardInterrupt:<tab><tab>print(""... stopped"")<tab>report.stop()<tab>return report",1,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,100.00000000000004,1.0
"def verts_of_loop(edge_loop):<tab>verts = []<tab>for e0, e1 in iter_pairs(edge_loop, False):<tab><tab><IF-STMT><tab><tab><tab>v0 = e0.shared_vert(e1)<tab><tab><tab>verts += [e0.other_vert(v0), v0]<tab><tab>verts += [e1.other_vert(verts[-1])]<tab>if len(verts) > 1 and verts[0] == verts[-1]:<tab><tab>return verts[:-1]<tab>return verts",0,if not verts :,if e0 . shared_vert ( e0 ) == e1 :,0.03270893689700884,3.673526562988939,0.32051282051282054
"def generator(self, data):<tab>for task in data:<tab><tab># Do we scan everything or just /bin/bash instances?<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for bucket in task.bash_hash_entries():<tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>int(task.p_pid),<tab><tab><tab><tab><tab>str(task.p_comm),<tab><tab><tab><tab><tab>int(bucket.times_found),<tab><tab><tab><tab><tab>str(bucket.key),<tab><tab><tab><tab><tab>str(bucket.data.path),<tab><tab><tab><tab>],<tab><tab><tab>)",0,"if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :",if not task . p_comm :,0.025576619408502477,5.718420601952916,0.41379310344827586
"def __get_ratio(self):<tab>""""""Return splitter ratio of the main splitter.""""""<tab>c = self.c<tab>free_layout = c.free_layout<tab>if free_layout:<tab><tab>w = free_layout.get_main_splitter()<tab><tab>if w:<tab><tab><tab>aList = w.sizes()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n1, n2 = aList<tab><tab><tab><tab># 2017/06/07: guard against division by zero.<tab><tab><tab><tab>ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2)<tab><tab><tab><tab>return ratio<tab>return 0.5",0,if len ( aList ) == 2 :,if len ( aList ) == 3 :,0.605621305873661,75.06238537503395,0.6666666666666666
"def geterrors(self):<tab>""""""Get all error messages.""""""<tab>notes = self.getnotes(origin=""translator"").split(""\n"")<tab>errordict = {}<tab>for note in notes:<tab><tab><IF-STMT><tab><tab><tab>error = note.replace(""(pofilter) "", """")<tab><tab><tab>errorname, errortext = error.split("": "", 1)<tab><tab><tab>errordict[errorname] = errortext<tab>return errordict",0,"if ""(pofilter) "" in note :","if note . startswith ( ""pofilter"" ) :",0.023749771747382555,7.056995965394887,0.4
"def rename_path(self, path, new_path):<tab>logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path))<tab>dirs = self.readdir(path)<tab>for d in dirs:<tab><tab>if d in [""."", ""..""]:<tab><tab><tab>continue<tab><tab>d_path = """".join([path, ""/"", d])<tab><tab>d_new_path = """".join([new_path, ""/"", d])<tab><tab>attr = self.getattr(d_path)<tab><tab><IF-STMT><tab><tab><tab>self.rename_path(d_path, d_new_path)<tab><tab>else:<tab><tab><tab>self.rename_item(d_path, d_new_path)<tab>self.rename_item(path, new_path, dir=True)",0,"if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :",if attr is None :,0.012417879185700129,1.2753613517831104,0.32222222222222224
"def index(self, url_id: int) -> FlaskResponse:  # pylint: disable=no-self-use<tab>url = db.session.query(models.Url).get(url_id)<tab>if url and url.url:<tab><tab>explore_url = ""//superset/explore/?""<tab><tab><IF-STMT><tab><tab><tab>explore_url += f""r={url_id}""<tab><tab><tab>return redirect(explore_url[1:])<tab><tab>return redirect(url.url[1:])<tab>flash(""URL to nowhere..."", ""danger"")<tab>return redirect(""/"")",0,if url . url . startswith ( explore_url ) :,"if url . url . startswith ( ""http"" ) :",0.6549399806880458,57.067457770559976,1.0
"def testShortCircuit(self):<tab>""""""Test that creation short-circuits to reuse existing references""""""<tab>sd = {}<tab>for s in self.ss:<tab><tab>sd[s] = 1<tab>for t in self.ts:<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(sd.has_key(safeRef(t.x)))<tab><tab><tab>self.assertTrue(safeRef(t.x) in sd)<tab><tab>else:<tab><tab><tab>self.assertTrue(sd.has_key(safeRef(t)))<tab><tab><tab>self.assertTrue(safeRef(t) in sd)",1,"if hasattr ( t , ""x"" ) :","if hasattr ( t , ""x"" ) :",0.75,100.00000000000004,1.0
"def wrapped(request, *args, **kwargs):<tab>if not request.user.is_authenticated():<tab><tab>request.session[""_next""] = request.get_full_path()<tab><tab><IF-STMT><tab><tab><tab>redirect_uri = reverse(<tab><tab><tab><tab>""sentry-auth-organization"", args=[kwargs[""organization_slug""]]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>redirect_uri = get_login_url()<tab><tab>return HttpResponseRedirect(redirect_uri)<tab>return func(request, *args, **kwargs)",1,"if ""organization_slug"" in kwargs :","if ""organization_slug"" in kwargs :",0.75,100.00000000000004,1.0
"def read_info(reader, dump=None):<tab>line_number_table_length = reader.read_u2()<tab><IF-STMT><tab><tab>reader.debug(<tab><tab><tab>""<tab>"" * dump, ""Line numbers (%s total):"" % line_number_table_length<tab><tab>)<tab>line_numbers = []<tab>for i in range(0, line_number_table_length):<tab><tab>start_pc = reader.read_u2()<tab><tab>line_number = reader.read_u2()<tab><tab>if dump is not None:<tab><tab><tab>reader.debug(""<tab>"" * (dump + 1), ""%s: %s"" % (start_pc, line_number))<tab><tab>line_numbers.append((start_pc, line_number))<tab>return LineNumberTable(line_numbers)",1,if dump is not None :,if dump is not None :,0.75,100.00000000000004,1.0
"def compute_timer_precision(timer):<tab>precision = None<tab>points = 0<tab>timeout = timeout_timer() + 1.0<tab>previous = timer()<tab>while timeout_timer() < timeout or points < 5:<tab><tab>for _ in XRANGE(10):<tab><tab><tab>t1 = timer()<tab><tab><tab>t2 = timer()<tab><tab><tab>dt = t2 - t1<tab><tab><tab>if 0 < dt:<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>dt = t2 - previous<tab><tab><tab>if dt <= 0.0:<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>precision = min(precision, dt)<tab><tab>else:<tab><tab><tab>precision = dt<tab><tab>points += 1<tab><tab>previous = timer()<tab>return precision",1,if precision is not None :,if precision is not None :,0.75,100.00000000000004,1.0
def get_hi_lineno(self):<tab>lineno = Node.get_hi_lineno(self)<tab>if self.expr1 is None:<tab><tab>pass<tab>else:<tab><tab>lineno = self.expr1.get_hi_lineno()<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>lineno = self.expr2.get_hi_lineno()<tab><tab><tab>if self.expr3 is None:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>lineno = self.expr3.get_hi_lineno()<tab>return lineno,1,if self . expr2 is None :,if self . expr2 is None :,0.75,100.00000000000004,1.0
"def validate_cluster_resource_group(cmd, namespace):<tab>if namespace.cluster_resource_group is not None:<tab><tab>client = get_mgmt_service_client(<tab><tab><tab>cmd.cli_ctx, ResourceType.MGMT_RESOURCE_RESOURCES<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArgumentValueError(<tab><tab><tab><tab>""Invalid --cluster-resource-group '%s': resource group must not exist.""<tab><tab><tab><tab>% namespace.cluster_resource_group<tab><tab><tab>)",0,if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,if not client . exists ( namespace . cluster_resource_group ) :,0.2453469213351983,49.19625503668661,0.3125
"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab><IF-STMT><tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[left - 1]):<tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab>if right == len(text):<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[right]):<tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",1,if left == 0 :,if left == 0 :,0.75,100.00000000000004,1.0
"def _check_good_input(self, X, y=None):<tab>if isinstance(X, dict):<tab><tab>lengths = [len(X1) for X1 in X.values()]<tab><tab>if len(set(lengths)) > 1:<tab><tab><tab>raise ValueError(""Not all values of X are of equal length."")<tab><tab>x_len = lengths[0]<tab>else:<tab><tab>x_len = len(X)<tab>if y is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""X and y are not of equal length."")<tab>if self.regression and y is not None and y.ndim == 1:<tab><tab>y = y.reshape(-1, 1)<tab>return X, y",0,if len ( y ) != x_len :,if x_len != len ( X ) :,0.1404063814862116,22.416933501922287,0.6
"def _get_text_nodes(nodes, html_body):<tab>text = []<tab>open_tags = 0<tab>for node in nodes:<tab><tab>if isinstance(node, HtmlTag):<tab><tab><tab>if node.tag_type == OPEN_TAG:<tab><tab><tab><tab>open_tags += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>open_tags -= 1<tab><tab>elif (<tab><tab><tab>isinstance(node, HtmlDataFragment)<tab><tab><tab>and node.is_text_content<tab><tab><tab>and open_tags == 0<tab><tab>):<tab><tab><tab>text.append(html_body[node.start : node.end])<tab>return text",1,elif node . tag_type == CLOSE_TAG :,elif node . tag_type == CLOSE_TAG :,1.0,100.00000000000004,1.0
"def _get_spyne_type(cls_name, k, v):<tab>try:<tab><tab>v = NATIVE_MAP.get(v, v)<tab>except TypeError:<tab><tab>return<tab>try:<tab><tab>subc = issubclass(v, ModelBase) or issubclass(v, SelfReference)<tab>except:<tab><tab>subc = False<tab>if subc:<tab><tab>if issubclass(v, Array) and len(v._type_info) != 1:<tab><tab><tab>raise Exception(""Invalid Array definition in %s.%s."" % (cls_name, k))<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Please specify the number of dimensions"")<tab><tab>return v",0,"elif issubclass ( v , Point ) and v . Attributes . dim is None :",elif len ( v . _type_info ) != 1 :,0.094762144445753,7.705829865251781,0.19444444444444442
"def customize(cls, **kwargs):<tab>""""""return a class with some existing attributes customized""""""<tab>for name, value in kwargs.iteritems():<tab><tab><IF-STMT><tab><tab><tab>raise TransportError(<tab><tab><tab><tab>""you cannot customize the protected attribute %s"" % name<tab><tab><tab>)<tab><tab>if not hasattr(cls, name):<tab><tab><tab>raise TransportError(""Transport has no attribute %s"" % name)<tab>NewSubClass = type(""Customized_{}"".format(cls.__name__), (cls,), kwargs)<tab>return NewSubClass",0,"if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :","if name == ""protected"" :",0.013264132286865363,1.6586964297308333,0.74
"def test_UNrelativize(self):<tab>import URIlib<tab>relative = self.relative + self.full_relativize<tab>for base, rel, fullpath, common in relative:<tab><tab>URI = uriparse.UnRelativizeURL(base, rel)<tab><tab>fullURI = URIlib.URIParser(URI)<tab><tab># We need to canonicalize the result from unrelativize<tab><tab># compared to the original full path we expect to see.<tab><tab><IF-STMT><tab><tab><tab>fullpath = fullpath[:-1]<tab><tab>self.failUnlessSamePath(<tab><tab><tab>os.path.normcase(fullURI.path), os.path.normcase(fullpath)<tab><tab>)",0,"if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :","if fullpath . endswith ( ""/"" ) :",0.0287313104176123,18.473424219567708,0.49122807017543857
"def get_release_info(file_path=RELEASE_FILE):<tab>RELEASE_TYPE_REGEX = re.compile(r""^[Rr]elease [Tt]ype: (major|minor|patch)$"")<tab>with open(file_path, ""r"") as f:<tab><tab>line = f.readline()<tab><tab>match = RELEASE_TYPE_REGEX.match(line)<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""The file RELEASE.md should start with `Release type` ""<tab><tab><tab><tab>""and specify one of the following values: major, minor or patch.""<tab><tab><tab>)<tab><tab><tab>sys.exit(1)<tab><tab>type_ = match.group(1)<tab><tab>changelog = """".join([line for line in f.readlines()]).strip()<tab>return type_, changelog",0,if not match :,if match is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def _get_next_history_entry(self):<tab>if self._history:<tab><tab>hist_len = len(self._history) - 1<tab><tab>self.history_index = min(hist_len, self.history_index + 1)<tab><tab>index = self.history_index<tab><tab><IF-STMT><tab><tab><tab>self.history_index += 1<tab><tab>return self._history[index]<tab>return """"",0,if self . history_index == hist_len :,if self . history_index < hist_len :,0.24627283061723432,64.07117598241614,1.0
"def star_op(self):<tab>""""""Put a '*' op, with special cases for *args.""""""<tab>val = ""*""<tab>if self.paren_level:<tab><tab>i = len(self.code_list) - 1<tab><tab>if self.code_list[i].kind == ""blank"":<tab><tab><tab>i -= 1<tab><tab>token = self.code_list[i]<tab><tab><IF-STMT><tab><tab><tab>self.op_no_blanks(val)<tab><tab>elif token.value == "","":<tab><tab><tab>self.blank()<tab><tab><tab>self.add_token(""op-no-blanks"", val)<tab><tab>else:<tab><tab><tab>self.op(val)<tab>else:<tab><tab>self.op(val)",0,"if token . kind == ""lt"" :","if token . value == ""*"" :",0.3444789340715307,29.84745896009822,0.6
"def get_safe_settings():<tab>""Returns a dictionary of the settings module, with sensitive settings blurred out.""<tab>settings_dict = {}<tab>for k in dir(settings):<tab><tab><IF-STMT><tab><tab><tab>if HIDDEN_SETTINGS.search(k):<tab><tab><tab><tab>settings_dict[k] = ""********************""<tab><tab><tab>else:<tab><tab><tab><tab>settings_dict[k] = getattr(settings, k)<tab>return settings_dict",0,if k . isupper ( ) :,"if not k . startswith ( ""_"" ) :",0.04757885349413095,11.731175160263996,0.3181818181818182
"def nextEditable(self):<tab>""""""Moves focus of the cursor to the next editable window""""""<tab>if self.currentEditable is None:<tab><tab>if len(self._editableChildren):<tab><tab><tab>self._currentEditableRef = self._editableChildren[0]<tab>else:<tab><tab>for ref in weakref.getweakrefs(self.currentEditable):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cei = self._editableChildren.index(ref)<tab><tab><tab><tab>nei = cei + 1<tab><tab><tab><tab>if nei >= len(self._editableChildren):<tab><tab><tab><tab><tab>nei = 0<tab><tab><tab><tab>self._currentEditableRef = self._editableChildren[nei]<tab>return self.currentEditable",1,if ref in self . _editableChildren :,if ref in self . _editableChildren :,0.75,100.00000000000004,1.0
"def _handle_dependents_type(types, type_str, type_name, rel_name, row):<tab>if types[type_str[0]] is None:<tab><tab><IF-STMT><tab><tab><tab>type_name = ""index""<tab><tab><tab>rel_name = row[""indname""] + "" ON "" + rel_name<tab><tab>elif type_str[0] == ""o"":<tab><tab><tab>type_name = ""operator""<tab><tab><tab>rel_name = row[""relname""]<tab>else:<tab><tab>type_name = types[type_str[0]]<tab>return type_name, rel_name",1,"if type_str [ 0 ] == ""i"" :","if type_str [ 0 ] == ""i"" :",0.75,100.00000000000004,1.0
"def streamErrorHandler(self, conn, error):<tab>name, text = ""error"", error.getData()<tab>for tag in error.getChildren():<tab><tab><IF-STMT><tab><tab><tab>if tag.getName() == ""text"":<tab><tab><tab><tab>text = tag.getData()<tab><tab><tab>else:<tab><tab><tab><tab>name = tag.getName()<tab>if name in stream_exceptions.keys():<tab><tab>exc = stream_exceptions[name]<tab>else:<tab><tab>exc = StreamError<tab>raise exc((name, text))",0,if tag . getNamespace ( ) == NS_XMPP_STREAMS :,"if isinstance ( tag , StreamTag ) :",0.01863539218224563,3.9007608550932686,0.3181818181818182
"def _validate_names(self, settings: _SettingsType) -> None:<tab>""""""Make sure all settings exist.""""""<tab>unknown = []<tab>for name in settings:<tab><tab><IF-STMT><tab><tab><tab>unknown.append(name)<tab>if unknown:<tab><tab>errors = [<tab><tab><tab>configexc.ConfigErrorDesc(<tab><tab><tab><tab>""While loading options"", ""Unknown option {}"".format(e)<tab><tab><tab>)<tab><tab><tab>for e in sorted(unknown)<tab><tab>]<tab><tab>raise configexc.ConfigFileErrors(""autoconfig.yml"", errors)",0,if name not in configdata . DATA :,"if not name . startswith ( ""_"" ) :",0.01983274868265512,5.604233375480572,0.21875
"def can_haz(self, target, credentials):<tab>""""""Check whether key-values in target are present in credentials.""""""<tab># TODO(termie): handle ANDs, probably by providing a tuple instead of a<tab>#<tab><tab><tab>   string<tab>for requirement in target:<tab><tab>key, match = requirement.split("":"", 1)<tab><tab>check = credentials.get(key)<tab><tab><IF-STMT><tab><tab><tab>check = [check]<tab><tab>if match in check:<tab><tab><tab>return True",0,"if check is None or isinstance ( check , basestring ) :","if not isinstance ( check , tuple ) :",0.13433404209365904,26.432408210372945,0.17272727272727273
"def _recursive_fx_apply(input: dict, fx):<tab>for k, v in input.items():<tab><tab><IF-STMT><tab><tab><tab>v = torch.tensor(v)<tab><tab>if isinstance(v, torch.Tensor):<tab><tab><tab>v = fx(v.float())<tab><tab><tab>input[k] = v<tab><tab>else:<tab><tab><tab>_recursive_fx_apply(v, fx)",0,"if isinstance ( v , list ) :","if isinstance ( v , torch . Tensor ) :",0.2633400423728968,45.180100180492246,0.5584415584415584
"def get(self, url, **kwargs):<tab>app, url = self._prepare_call(url, kwargs)<tab>if app:<tab><tab><IF-STMT><tab><tab><tab>self._first_ping = False<tab><tab><tab>return EmptyCapabilitiesResponse()<tab><tab>elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url:<tab><tab><tab>return ErrorApiResponse()<tab><tab>else:<tab><tab><tab>response = app.get(url, **kwargs)<tab><tab><tab>return TestingResponse(response)<tab>else:<tab><tab>return requests.get(url, **kwargs)",0,"if url . endswith ( ""ping"" ) and self . _first_ping :",if self . _first_ping :,0.10400131924210887,28.22664073782293,0.30392156862745096
"def server_thread_fn():<tab>server_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)<tab>server_ctx.load_cert_chain(""trio-test-1.pem"")<tab>server = server_ctx.wrap_socket(<tab><tab>server_sock,<tab><tab>server_side=True,<tab><tab>suppress_ragged_eofs=False,<tab>)<tab>while True:<tab><tab>data = server.recv(4096)<tab><tab>print(""server got:"", data)<tab><tab><IF-STMT><tab><tab><tab>print(""server waiting for client to finish everything"")<tab><tab><tab>client_done.wait()<tab><tab><tab>print(""server attempting to send back close-notify"")<tab><tab><tab>server.unwrap()<tab><tab><tab>print(""server ok"")<tab><tab><tab>break<tab><tab>server.sendall(data)",1,if not data :,if not data :,0.75,100.00000000000004,1.0
"def find_hostnames(data):<tab># sends back an array of hostnames<tab>hostnames = []<tab>for i in re.finditer(hostname_regex, data):<tab><tab>h = string.lower(i.group(1))<tab><tab>tld = h.split(""."")[-1:][0]<tab><tab><IF-STMT><tab><tab><tab>hostnames.append(h)<tab>return hostnames",0,if tld in tlds :,if tld not in hostnames and tld not in hostnames :,0.1715331060687605,8.913765521398126,0.23958333333333331
"def Validate(self, win):<tab>textCtrl = self.GetWindow()<tab>text = textCtrl.GetValue().strip()<tab>sChar = Character.getInstance()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(_t(""You must supply a name for the Character!""))<tab><tab>elif text in [x.name for x in sChar.getCharacterList()]:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>_t(""Character name already in use, please choose another."")<tab><tab><tab>)<tab><tab>return True<tab>except ValueError as e:<tab><tab>pyfalog.error(e)<tab><tab>wx.MessageBox(""{}"".format(e), _t(""Error""))<tab><tab>textCtrl.SetFocus()<tab><tab>return False",0,if len ( text ) == 0 :,if sChar is None :,0.01858685153282265,5.70796903405875,0.25
def get_random_user_agent(agent_list=UA_CACHE):<tab>if not len(agent_list):<tab><tab>ua_file = file(UA_FILE)<tab><tab>for line in ua_file:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>agent_list.append(line)<tab>ua = random.choice(UA_CACHE)<tab>return ua,0,if line :,"if line and not line . startswith ( ""#"" ) :",0.2025077721101191,1e-10,0.3968253968253968
"def _validate_action_like_for_prefixes(self, key):<tab>for statement in self._statements:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(statement[key], string_types):<tab><tab><tab><tab>self._validate_action_prefix(statement[key])<tab><tab><tab>else:<tab><tab><tab><tab>for action in statement[key]:<tab><tab><tab><tab><tab>self._validate_action_prefix(action)",1,if key in statement :,if key in statement :,0.75,100.00000000000004,1.0
"def predict(self, X):<tab>if self.regression:<tab><tab>return self.predict_proba(X)<tab>else:<tab><tab>y_pred = np.argmax(self.predict_proba(X), axis=1)<tab><tab><IF-STMT><tab><tab><tab>y_pred = self.enc_.inverse_transform(y_pred)<tab><tab>return y_pred",0,if self . use_label_encoder :,if self . enc_ :,0.39477865547525276,20.82186541080652,1.0
"def _threaded_request_tracker(self, builder):<tab>while True:<tab><tab>event_type = self._read_q.get()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>payload = {""body"": b""""}<tab><tab>request_id = builder.build_record(event_type, payload, """")<tab><tab>self._write_q.put_nowait(request_id)",0,if event_type is False :,if event_type is None :,0.39477865547525276,64.34588841607616,0.6
"def __call__(self, value):<tab>try:<tab><tab>super(EmailValidator, self).__call__(value)<tab>except ValidationError as e:<tab><tab># Trivial case failed. Try for possible IDN domain-part<tab><tab><IF-STMT><tab><tab><tab>parts = value.split(""@"")<tab><tab><tab>try:<tab><tab><tab><tab>parts[-1] = parts[-1].encode(""idna"").decode(""ascii"")<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab>raise e<tab><tab><tab>super(EmailValidator, self).__call__(""@"".join(parts))<tab><tab>else:<tab><tab><tab>raise",0,"if value and ""@"" in value :","if ""@"" in value :",0.23093026462960747,63.191456189157286,0.3333333333333333
"def PreprocessConditionalStatement(self, IfList, ReplacedLine):<tab>while self:<tab><tab>if self.__Token:<tab><tab><tab>x = 1<tab><tab><IF-STMT><tab><tab><tab>if self <= 2:<tab><tab><tab><tab>continue<tab><tab><tab>RegionSizeGuid = 3<tab><tab><tab>if not RegionSizeGuid:<tab><tab><tab><tab>RegionLayoutLine = 5<tab><tab><tab><tab>continue<tab><tab><tab>RegionLayoutLine = self.CurrentLineNumber<tab>return 1",0,elif not IfList :,if x == 1 :,0.03242801628908409,8.116697886877475,0.14285714285714285
"def _arg_with_type(self):<tab>for t in self.d[""Args""]:<tab><tab>m = re.search(""([A-Za-z0-9_-]+)\s{0,4}(\(.+\))\s{0,4}:"", t)<tab><tab><IF-STMT><tab><tab><tab>self.args[m.group(1)] = m.group(2)<tab>return self.args",1,if m :,if m :,0.5311706625951745,1e-10,1.0
"def get_palette_for_custom_classes(self, class_names, palette=None):<tab>if self.label_map is not None:<tab><tab># return subset of palette<tab><tab>palette = []<tab><tab>for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]):<tab><tab><tab>if new_id != -1:<tab><tab><tab><tab>palette.append(self.PALETTE[old_id])<tab><tab>palette = type(self.PALETTE)(palette)<tab>elif palette is None:<tab><tab><IF-STMT><tab><tab><tab>palette = np.random.randint(0, 255, size=(len(class_names), 3))<tab><tab>else:<tab><tab><tab>palette = self.PALETTE<tab>return palette",0,if self . PALETTE is None :,if len ( class_names ) > 1 :,0.019801326568637086,4.990049701936832,0.21875
"def Visit_star_expr(self, node):  # pylint: disable=invalid-name<tab># star_expr ::= '*' expr<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.UNARY_OPERATOR)<tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.VARARGS_STAR)",1,"if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :",1.0,100.00000000000004,1.0
"def create_if_compatible(cls, typ: Type, *, root: ""RootNode"") -> Optional[""Node""]:<tab>if cls.compatible_types:<tab><tab>target_type: Type = typ<tab><tab><IF-STMT><tab><tab><tab>target_type = getattr(typ, ""__origin__"", None) or typ<tab><tab>if cls._issubclass(target_type, cls.compatible_types):<tab><tab><tab>return cls(typ, root=root)<tab>return None",0,if cls . use_origin :,"if issubclass ( target_type , Type ) :",0.026407399022921448,5.522397783539471,0.38181818181818183
"def grep_full_py_identifiers(tokens):<tab>global pykeywords<tab>tokens = list(tokens)<tab>i = 0<tab>while i < len(tokens):<tab><tab>tokentype, token = tokens[i]<tab><tab>i += 1<tab><tab>if tokentype != ""id"":<tab><tab><tab>continue<tab><tab>while (<tab><tab><tab>i + 1 < len(tokens)<tab><tab><tab>and tokens[i] == (""op"", ""."")<tab><tab><tab>and tokens[i + 1][0] == ""id""<tab><tab>):<tab><tab><tab>token += ""."" + tokens[i + 1][1]<tab><tab><tab>i += 2<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if token in pykeywords:<tab><tab><tab>continue<tab><tab>if token[0] in "".0123456789"":<tab><tab><tab>continue<tab><tab>yield token",0,"if token == """" :","if tokentype != ""op"" :",0.28412306583404373,16.515821590069027,0.5
"def create_config_filepath(cls, visibility=None):<tab>if cls.is_local(visibility):<tab><tab># Local to this directory<tab><tab>base_path = os.path.join(""."")<tab><tab><IF-STMT><tab><tab><tab># Add it to the current ""./.polyaxon""<tab><tab><tab>base_path = os.path.join(base_path, "".polyaxon"")<tab><tab><tab>cls._create_dir(base_path)<tab>elif cls.CONFIG_PATH:  # Custom path<tab><tab>pass<tab>else:  # Handle both global and all cases<tab><tab>base_path = polyaxon_user_path()<tab><tab>cls._create_dir(base_path)",0,if cls . IS_POLYAXON_DIR :,"if base_path . endswith ( "".polyaxon"" ) :",0.028001459970687266,4.368583925857938,0.5
"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab><IF-STMT><tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab>elif size <= 9:<tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64MIME.base64_len(""x"" * size), bsize)",0,elif size <= 3 :,elif size <= 5 :,0.39287202148494,53.7284965911771,0.6
"def as_dict(path="""", version=""latest"", section=""meta-data""):<tab>result = {}<tab>dirs = dir(path, version, section)<tab>if not dirs:<tab><tab>return None<tab>for item in dirs:<tab><tab><IF-STMT><tab><tab><tab>records = as_dict(path + item, version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[item[:-1]] = records<tab><tab>elif is_dict.match(item):<tab><tab><tab>idx, name = is_dict.match(item).groups()<tab><tab><tab>records = as_dict(path + idx + ""/"", version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[name] = records<tab><tab>else:<tab><tab><tab>result[item] = valueconv(get(path + item, version, section))<tab>return result",0,"if item . endswith ( ""/"" ) :",if is_dict . match ( item ) :,0.03916858170756418,11.044795567078939,0.4
"def api_read(self):<tab>result = {}<tab>files = [""my.cnf"", ""debian.cnf""]<tab>directory_list = self.exec_payload(""mysql_config_directory"")[""directory""]<tab>for _file in files:<tab><tab>for directory in directory_list:<tab><tab><tab>mysql_conf = directory + _file<tab><tab><tab>content = self.shell.read(mysql_conf)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[mysql_conf] = content<tab>return result",1,if content :,if content :,0.5311706625951745,1e-10,1.0
"def generate(self, count=100):<tab>self.pre_generate()<tab>counter = iter(range(count))<tab>created = 0<tab>while True:<tab><tab>batch = list(islice(counter, self.batch_size))<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>self.do_generate(batch, self.batch_size)<tab><tab>from_size = created<tab><tab>created += len(batch)<tab><tab>print(""Generate %s: %s-%s"" % (self.resource, from_size, created))<tab>self.after_generate()",0,if not batch :,if len ( batch ) == 0 :,0.03661176184600709,6.27465531099474,0.48148148148148145
"def _normalize_fields(self, document, loader):<tab># type: (Dict[Text, Text], Loader) -> None<tab># Normalize fields which are prefixed or full URIn to vocabulary terms<tab>for d in list(document.keys()):<tab><tab>d2 = loader.expand_url(d, u"""", scoped_id=False, vocab_term=True)<tab><tab><IF-STMT><tab><tab><tab>document[d2] = document[d]<tab><tab><tab>del document[d]",0,if d != d2 :,if d2 in document :,0.03654024892898815,11.51015341649912,0.27777777777777773
"def load_cache(filename, get_key=mangle_key):<tab>cache = {}<tab>if not os.path.exists(filename):<tab><tab>return cache<tab>f = open(filename, ""rb"")<tab>l = 0<tab>for line in f.readlines():<tab><tab>l += 1<tab><tab>fields = line.split(b"" "")<tab><tab><IF-STMT><tab><tab><tab>sys.stderr.write(""Invalid file format in [%s], line %d\n"" % (filename, l))<tab><tab><tab>continue<tab><tab># put key:value in cache, key without ^:<tab><tab>cache[get_key(fields[0][1:])] = fields[1].split(b""\n"")[0]<tab>f.close()<tab>return cache",0,"if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :",if len ( fields ) != 2 :,0.08383633614147466,3.604179790223565,0.17272727272727273
"def __lshift__(self, other):<tab>if not self.symbolic and type(other) is int:<tab><tab>return RegisterOffset(<tab><tab><tab>self._bits, self.reg, self._to_signed(self.offset << other)<tab><tab>)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return RegisterOffset(self._bits, self.reg, self.offset << other)<tab><tab>else:<tab><tab><tab>return RegisterOffset(<tab><tab><tab><tab>self._bits,<tab><tab><tab><tab>self.reg,<tab><tab><tab><tab>ArithmeticExpression(<tab><tab><tab><tab><tab>ArithmeticExpression.LShift,<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>self.offset,<tab><tab><tab><tab><tab><tab>other,<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>),<tab><tab><tab>)",1,if self . symbolic :,if self . symbolic :,0.75,100.00000000000004,1.0
"def SaveSettings(self, force=False):<tab>if self.config is not None:<tab><tab>frame.ShellFrameMixin.SaveSettings(self)<tab><tab><IF-STMT><tab><tab><tab>frame.Frame.SaveSettings(self, self.config)<tab><tab><tab>self.shell.SaveSettings(self.config)",0,if self . autoSaveSettings or force :,if force :,0.03885753308224148,1e-10,0.2619047619047619
"def _parse_gene(element):<tab>for genename_element in element:<tab><tab>if ""type"" in genename_element.attrib:<tab><tab><tab>ann_key = ""gene_%s_%s"" % (<tab><tab><tab><tab>genename_element.tag.replace(NS, """"),<tab><tab><tab><tab>genename_element.attrib[""type""],<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.ParsedSeqRecord.annotations[ann_key] = genename_element.text<tab><tab><tab>else:<tab><tab><tab><tab>append_to_annotations(ann_key, genename_element.text)",0,"if genename_element . attrib [ ""type"" ] == ""primary"" :","if genename_element . attrib [ ""annotation"" ] :",0.3194395139048507,45.26273966718318,1.0
"def _write_pkg_file(self, file):<tab>with TemporaryFile(mode=""w+"") as tmpfd:<tab><tab>_write_pkg_file_orig(self, tmpfd)<tab><tab>tmpfd.seek(0)<tab><tab>for line in tmpfd:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file.write(""Metadata-Version: 2.1\n"")<tab><tab><tab>elif line.startswith(""Description: ""):<tab><tab><tab><tab>file.write(<tab><tab><tab><tab><tab>""Description-Content-Type: %s; charset=UTF-8\n""<tab><tab><tab><tab><tab>% long_description_content_type<tab><tab><tab><tab>)<tab><tab><tab><tab>file.write(line)<tab><tab><tab>else:<tab><tab><tab><tab>file.write(line)",0,"if line . startswith ( ""Metadata-Version: "" ) :","if line . startswith ( ""Metadata: "" ) :",0.5498893192644195,70.16879391277372,1.0
"def get(self):<tab>""""""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called.""""""<tab>if self._exception is not _NONE:<tab><tab><IF-STMT><tab><tab><tab>return self.value<tab><tab>getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable<tab>else:<tab><tab>if self.greenlet is not None:<tab><tab><tab>raise ConcurrentObjectUseError(<tab><tab><tab><tab>""This Waiter is already used by %r"" % (self.greenlet,)<tab><tab><tab>)<tab><tab>self.greenlet = getcurrent()  # pylint:disable=undefined-variable<tab><tab>try:<tab><tab><tab>return self.hub.switch()<tab><tab>finally:<tab><tab><tab>self.greenlet = None",0,if self . _exception is None :,if self . value is not _NONE :,0.23709053828519988,21.10534063187263,0.40816326530612246
"def connect(self, *args):<tab>""""""connects to the dropbox. args[0] is the username.""""""<tab>if len(args) != 1:<tab><tab>return ""expected one argument!""<tab>try:<tab><tab>dbci = get_dropbox_client(args[0], False, None, None)<tab>except Exception as e:<tab><tab>return e.message<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return ""No Dropbox configured for '{u}'."".format(u=args[0])<tab><tab>else:<tab><tab><tab>self.client = dbci<tab><tab>return True",0,if dbci is None :,if not dbci :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text",1,"if ""\n"" in text :","if ""\n"" in text :",0.75,100.00000000000004,1.0
def t(ret):<tab>with IPDB() as ipdb:<tab><tab>with ipdb.eventqueue() as evq:<tab><tab><tab>for msg in evq:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ret.append(msg)<tab><tab><tab><tab><tab>return,0,"if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :",if msg not in ret :,0.026294072955114864,2.058073185415509,0.4615384615384615
"def check_stmt(self, stmt):<tab>if is_future(stmt):<tab><tab>for name, asname in stmt.names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.found[name] = 1<tab><tab><tab>else:<tab><tab><tab><tab>raise SyntaxError(""future feature %s is not defined"" % name)<tab><tab>stmt.valid_future = 1<tab><tab>return 1<tab>return 0",0,if name in self . features :,if name in self . found :,0.574113272471593,64.34588841607616,0.7142857142857143
"def process_pypi_option(option, option_str, option_value, parser):<tab>if option_str.startswith(""--no""):<tab><tab>setattr(parser.values, option.dest, [])<tab>else:<tab><tab>indexes = getattr(parser.values, option.dest, [])<tab><tab><IF-STMT><tab><tab><tab>indexes.append(_PYPI)<tab><tab>setattr(parser.values, option.dest, indexes)",0,if _PYPI not in indexes :,"if option_str . startswith ( ""--python"" ) :",0.022316443924793247,4.456882760699063,0.3
"def modify_address(self, name, address, domain):<tab>if not self.get_entries_by_name(name, domain):<tab><tab>raise exception.NotFound<tab>infile = open(self.filename, ""r"")<tab>outfile = tempfile.NamedTemporaryFile(""w"", delete=False)<tab>for line in infile:<tab><tab>entry = self.parse_line(line)<tab><tab><IF-STMT><tab><tab><tab>outfile.write(<tab><tab><tab><tab>""%s   %s   %s\n"" % (address, self.qualify(name, domain), entry[""type""])<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>outfile.write(line)<tab>infile.close()<tab>outfile.close()<tab>shutil.move(outfile.name, self.filename)",0,"if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :","if entry [ ""name"" ] == name :",0.06454502808333495,12.461040751039663,0.2752752752752753
"def tms_to_quadkey(self, tms, google=False):<tab>quadKey = """"<tab>x, y, z = tms<tab># this algorithm works with google tiles, rather than tms, so convert<tab># to those first.<tab>if not google:<tab><tab>y = (2 ** z - 1) - y<tab>for i in range(z, 0, -1):<tab><tab>digit = 0<tab><tab>mask = 1 << (i - 1)<tab><tab>if (x & mask) != 0:<tab><tab><tab>digit += 1<tab><tab><IF-STMT><tab><tab><tab>digit += 2<tab><tab>quadKey += str(digit)<tab>return quadKey",1,if ( y & mask ) != 0 :,if ( y & mask ) != 0 :,0.75,100.00000000000004,1.0
"def add_if_unique(self, issuer, use, keys):<tab>if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]:<tab><tab>for typ, key in keys:<tab><tab><tab>flag = 1<tab><tab><tab>for _typ, _key in self.issuer_keys[issuer][use]:<tab><tab><tab><tab>if _typ == typ and key is _key:<tab><tab><tab><tab><tab>flag = 0<tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.issuer_keys[issuer][use].append((typ, key))<tab>else:<tab><tab>self.issuer_keys[issuer][use] = keys",1,if flag :,if flag :,0.5311706625951745,1e-10,1.0
"def scan_error(self):<tab>""A string describing why the last scan failed, or None if it didn't.""<tab>self.acquire_lock()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self._load_buf_data_once()<tab><tab><tab>except NotFoundInDatabase:<tab><tab><tab><tab>pass<tab><tab>return self._scan_error_cache<tab>finally:<tab><tab>self.release_lock()",0,if self . _scan_error_cache is None :,if self . _scan_error_cache is not None :,0.475427584671977,79.10665071754353,0.6428571428571429
"def _query(self):<tab>if self._mongo_query is None:<tab><tab>self._mongo_query = self._query_obj.to_query(self._document)<tab><tab><IF-STMT><tab><tab><tab>if ""_cls"" in self._mongo_query:<tab><tab><tab><tab>self._mongo_query = {""$and"": [self._cls_query, self._mongo_query]}<tab><tab><tab>else:<tab><tab><tab><tab>self._mongo_query.update(self._cls_query)<tab>return self._mongo_query",0,if self . _cls_query :,if self . _cls_query is not None :,0.3514988343435983,59.00468726392806,0.4444444444444444
"def CountButtons(self):<tab>""""""Returns the number of visible buttons in the docked pane.""""""<tab>n = 0<tab>if self.HasCaption() or self.HasCaptionLeft():<tab><tab>if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame):<tab><tab><tab>return 1<tab><tab>if self.HasCloseButton():<tab><tab><tab>n += 1<tab><tab>if self.HasMaximizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasMinimizeButton():<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab>return n",0,if self . HasPinButton ( ) :,if self . HasMinimizeButton ( ) :,0.3884893899276739,41.11336169005196,0.6
"def testBind(self):<tab>try:<tab><tab>with socket.socket(socket.PF_CAN, socket.SOCK_DGRAM, socket.CAN_J1939) as s:<tab><tab><tab>addr = (<tab><tab><tab><tab>self.interface,<tab><tab><tab><tab>socket.J1939_NO_NAME,<tab><tab><tab><tab>socket.J1939_NO_PGN,<tab><tab><tab><tab>socket.J1939_NO_ADDR,<tab><tab><tab>)<tab><tab><tab>s.bind(addr)<tab><tab><tab>self.assertEqual(s.getsockname(), addr)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""network interface `%s` does not exist"" % self.interface)<tab><tab>else:<tab><tab><tab>raise",0,if e . errno == errno . ENODEV :,if e . errno == errno . EEXIST :,0.87709085524794,78.25422900366438,0.6666666666666666
"def createFields(self):<tab>while self.current_size < self.size:<tab><tab>pos = self.stream.searchBytes(<tab><tab><tab>""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8<tab><tab>)  # seek forward by at most 1MB<tab><tab>if pos is not None:<tab><tab><tab>padsize = pos - self.current_size<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield PaddingBytes(self, ""pad[]"", padsize // 8)<tab><tab>chunk = Chunk(self, ""chunk[]"")<tab><tab>try:<tab><tab><tab># force chunk to be processed, so that CustomFragments are complete<tab><tab><tab>chunk[""content/data""]<tab><tab>except:<tab><tab><tab>pass<tab><tab>yield chunk",0,if padsize :,if padsize > 0 :,0.09791453445388575,1e-10,0.7
"def index_modulemd_files(repo_path):<tab>merger = Modulemd.ModuleIndexMerger()<tab>for fn in sorted(os.listdir(repo_path)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yaml_path = os.path.join(repo_path, fn)<tab><tab>mmd = Modulemd.ModuleIndex()<tab><tab>mmd.update_from_file(yaml_path, strict=True)<tab><tab>merger.associate_index(mmd, 0)<tab>return merger.resolve()",0,"if not fn . endswith ( "".yaml"" ) :","if fn . endswith ( "".py"" ) :",0.1884566599936256,55.097857671324185,0.38181818181818183
"def set_visible(self, visible=True):<tab>self._visible = visible<tab>if self._nswindow is not None:<tab><tab><IF-STMT><tab><tab><tab># Not really sure why on_resize needs to be here,<tab><tab><tab># but it's what pyglet wants.<tab><tab><tab>self.dispatch_event(""on_resize"", self._width, self._height)<tab><tab><tab>self.dispatch_event(""on_show"")<tab><tab><tab>self.dispatch_event(""on_expose"")<tab><tab><tab>self._nswindow.makeKeyAndOrderFront_(None)<tab><tab>else:<tab><tab><tab>self._nswindow.orderOut_(None)",1,if visible :,if visible :,0.5311706625951745,1e-10,1.0
"def __repr__(self):<tab>if self._in_repr:<tab><tab>return ""<recursion>""<tab>try:<tab><tab>self._in_repr = True<tab><tab>if self.is_computed():<tab><tab><tab>status = ""computed, ""<tab><tab><tab>if self.error() is None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>status += ""= self""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>status += ""= "" + repr(self.value())<tab><tab><tab>else:<tab><tab><tab><tab>status += ""error = "" + repr(self.error())<tab><tab>else:<tab><tab><tab>status = ""isn't computed""<tab><tab>return ""%s (%s)"" % (type(self), status)<tab>finally:<tab><tab>self._in_repr = False",0,if self . value ( ) is self :,if self . value ( ) is None :,0.62709085524794,75.06238537503395,0.7777777777777777
"def _individual_get(self, segment, index_type, index, strictdoc):<tab>if index_type == ""val"":<tab><tab>for key, value in segment.items():<tab><tab><tab>if key == index[0]:<tab><tab><tab><tab>return value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if key.text == index[0]:<tab><tab><tab><tab><tab>return value<tab><tab>raise Exception(""Invalid state"")<tab>elif index_type == ""index"":<tab><tab>return segment[index]<tab>elif index_type == ""textslice"":<tab><tab>return segment[index[0] : index[1]]<tab>elif index_type == ""key"":<tab><tab>return index[1] if strictdoc else index[0]<tab>else:<tab><tab>raise Exception(""Invalid state"")",0,"if hasattr ( key , ""text"" ) :",elif strictdoc :,0.011639758255926284,1e-10,0.15151515151515152
"def _makeSafeAbsoluteURI(base, rel=None):<tab># bail if ACCEPTABLE_URI_SCHEMES is empty<tab>if not ACCEPTABLE_URI_SCHEMES:<tab><tab>return _urljoin(base, rel or u"""")<tab>if not base:<tab><tab>return rel or u""""<tab>if not rel:<tab><tab>try:<tab><tab><tab>scheme = urlparse.urlparse(base)[0]<tab><tab>except ValueError:<tab><tab><tab>return u""""<tab><tab><IF-STMT><tab><tab><tab>return base<tab><tab>return u""""<tab>uri = _urljoin(base, rel)<tab>if uri.strip().split("":"", 1)[0] not in ACCEPTABLE_URI_SCHEMES:<tab><tab>return u""""<tab>return uri",0,if not scheme or scheme in ACCEPTABLE_URI_SCHEMES :,if scheme in ACCEPTABLE_URI_SCHEMES :,0.3355249856331465,63.70964381207869,0.2619047619047619
"def _write_packet(self, packet):<tab># Immediately writes the given packet to the network. The caller must<tab># have the write lock acquired before calling this method.<tab>try:<tab><tab>for listener in self.early_outgoing_packet_listeners:<tab><tab><tab>listener.call_packet(packet)<tab><tab><IF-STMT><tab><tab><tab>packet.write(self.socket, self.options.compression_threshold)<tab><tab>else:<tab><tab><tab>packet.write(self.socket)<tab><tab>for listener in self.outgoing_packet_listeners:<tab><tab><tab>listener.call_packet(packet)<tab>except IgnorePacket:<tab><tab>pass",0,if self . options . compression_enabled :,if self . options . compression_threshold > 0 :,0.2800330458634526,59.00468726392806,0.7818181818181819
"def rangelist_to_set(rangelist):<tab>result = set()<tab>if not rangelist:<tab><tab>return result<tab>for x in rangelist.split("",""):<tab><tab><IF-STMT><tab><tab><tab>result.add(int(x))<tab><tab><tab>continue<tab><tab>m = re.match(r""^(\d+)-(\d+)$"", x)<tab><tab>if m:<tab><tab><tab>start = int(m.group(1))<tab><tab><tab>end = int(m.group(2))<tab><tab><tab>result.update(set(range(start, end + 1)))<tab><tab><tab>continue<tab><tab>msg = ""Cannot understand data input: %s %s"" % (x, rangelist)<tab><tab>raise ValueError(msg)<tab>return result",0,"if re . match ( r""^(\d+)$"" , x ) :",if x . isdigit ( ) :,0.030311185276269064,3.113082773188573,0.32051282051282054
"def test_device_property_logfile_isinstance(self):<tab>mock = MagicMock()<tab>with patch(builtin_string + "".open"", mock):<tab><tab><IF-STMT><tab><tab><tab>builtin_file = ""io.TextIOWrapper""<tab><tab>else:<tab><tab><tab>builtin_file = builtin_string + "".file""<tab><tab>with patch(builtin_file, MagicMock):<tab><tab><tab>handle = open(""filename"", ""r"")<tab><tab><tab>self.dev.logfile = handle<tab><tab><tab>self.assertEqual(self.dev.logfile, handle)",0,"if sys . version > ""3"" :","if sys . platform == ""win32"" :",0.3405653141935552,20.556680845025987,0.6
"def _line_ranges(statements, lines):<tab>""""""Produce a list of ranges for `format_lines`.""""""<tab>statements = sorted(statements)<tab>lines = sorted(lines)<tab>pairs = []<tab>start = None<tab>lidx = 0<tab>for stmt in statements:<tab><tab>if lidx >= len(lines):<tab><tab><tab>break<tab><tab>if stmt == lines[lidx]:<tab><tab><tab>lidx += 1<tab><tab><tab>if not start:<tab><tab><tab><tab>start = stmt<tab><tab><tab>end = stmt<tab><tab><IF-STMT><tab><tab><tab>pairs.append((start, end))<tab><tab><tab>start = None<tab>if start:<tab><tab>pairs.append((start, end))<tab>return pairs",0,elif start :,if start and end :,0.04570375548122485,1e-10,0.25
"def reset_parameters(self):<tab>initialize = layers.get_initializer(self._hparams.initializer)<tab>if initialize is not None:<tab><tab># Do not re-initialize LayerNorm modules.<tab><tab>for name, param in self.named_parameters():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>initialize(param)",0,"if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :","if isinstance ( param , LayerNorm ) :",0.006564481135192819,0.6410715135581041,0.16783216783216784
"def billing_invoice_show_validator(namespace):<tab>from azure.cli.core.azclierror import (<tab><tab>RequiredArgumentMissingError,<tab><tab>MutuallyExclusiveArgumentError,<tab>)<tab>valid_combs = (<tab><tab>""only --account-name, --name / --name / --name, --by-subscription is valid""<tab>)<tab>if namespace.account_name is not None:<tab><tab>if namespace.by_subscription is not None:<tab><tab><tab>raise MutuallyExclusiveArgumentError(valid_combs)<tab><tab><IF-STMT><tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")<tab>if namespace.by_subscription is not None:<tab><tab>if namespace.name is None:<tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")",1,if namespace . name is None :,if namespace . name is None :,0.75,100.00000000000004,1.0
"def DeleteDocuments(self, document_ids, response):<tab>""""""Deletes documents for the given document_ids.""""""<tab>for document_id in document_ids:<tab><tab><IF-STMT><tab><tab><tab>document = self._documents[document_id]<tab><tab><tab>self._inverted_index.RemoveDocument(document)<tab><tab><tab>del self._documents[document_id]<tab><tab>delete_status = response.add_status()<tab><tab>delete_status.set_code(search_service_pb.SearchServiceError.OK)",1,if document_id in self . _documents :,if document_id in self . _documents :,0.75,100.00000000000004,1.0
"def generate_new_element(items, prefix, numeric=False):<tab>""""""Creates a random string with prefix, that is not in 'items' list.""""""<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>candidate = prefix + generate_random_numeric(8)<tab><tab>else:<tab><tab><tab>candidate = prefix + generate_random_alphanumeric(8)<tab><tab>if not candidate in items:<tab><tab><tab>return candidate<tab><tab>LOG.debug(""Random collision on %s"" % candidate)",1,if numeric :,if numeric :,0.5311706625951745,1e-10,1.0
"def generate_text_for_vocab(self, data_dir, tmp_dir):<tab>for i, sample in enumerate(<tab><tab>self.generate_samples(data_dir, tmp_dir, problem.DatasetSplit.TRAIN)<tab>):<tab><tab>if self.has_inputs:<tab><tab><tab>yield sample[""inputs""]<tab><tab>yield sample[""targets""]<tab><tab><IF-STMT><tab><tab><tab>break",0,if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,if i >= self . num_samples - 1 :,0.040160300889938966,7.551080103492646,0.31666666666666665
"def _get_ccp(config=None, config_path=None, saltenv=""base""):<tab>"""""" """"""<tab>if config_path:<tab><tab>config = __salt__[""cp.get_file_str""](config_path, saltenv=saltenv)<tab><tab><IF-STMT><tab><tab><tab>raise SaltException(""{} is not available"".format(config_path))<tab>if isinstance(config, six.string_types):<tab><tab>config = config.splitlines()<tab>ccp = ciscoconfparse.CiscoConfParse(config)<tab>return ccp",0,if config is False :,if not config :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def rpush(key, *vals, **kwargs):<tab>ttl = kwargs.get(""ttl"")<tab>cap = kwargs.get(""cap"")<tab>if not ttl and not cap:<tab><tab>_client.rpush(key, *vals)<tab>else:<tab><tab>pipe = _client.pipeline()<tab><tab>pipe.rpush(key, *vals)<tab><tab><IF-STMT><tab><tab><tab>pipe.ltrim(key, 0, cap)<tab><tab>if ttl:<tab><tab><tab>pipe.expire(key, ttl)<tab><tab>pipe.execute()",1,if cap :,if cap :,0.5311706625951745,1e-10,1.0
"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""key""<tab><tab>elif mode == ""key"":<tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab>elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",1,"if mode == ""start"" :","if mode == ""start"" :",0.75,100.00000000000004,1.0
"def _add_communication_type(apps, schema_editor, communication_type):<tab>Worker = apps.get_model(""orchestra"", ""Worker"")<tab>CommunicationPreference = apps.get_model(""orchestra"", ""CommunicationPreference"")<tab>for worker in Worker.objects.all():<tab><tab>(<tab><tab><tab>communication_preference,<tab><tab><tab>created,<tab><tab>) = CommunicationPreference.objects.get_or_create(<tab><tab><tab>worker=worker, communication_type=communication_type<tab><tab>)<tab><tab># By default set both Slack and Email notifications to True<tab><tab><IF-STMT><tab><tab><tab>communication_preference.methods.slack = True<tab><tab><tab>communication_preference.methods.email = True<tab><tab>communication_preference.save()",1,if created :,if created :,0.5311706625951745,1e-10,1.0
"def get_postgresql_driver_name():<tab># pylint: disable=unused-variable<tab>try:<tab><tab>driver = os.getenv(""CODECHECKER_DB_DRIVER"")<tab><tab><IF-STMT><tab><tab><tab>return driver<tab><tab>try:<tab><tab><tab># pylint: disable=W0611<tab><tab><tab>import psycopg2<tab><tab><tab>return ""psycopg2""<tab><tab>except Exception:<tab><tab><tab># pylint: disable=W0611<tab><tab><tab>import pg8000<tab><tab><tab>return ""pg8000""<tab>except Exception as ex:<tab><tab>LOG.error(str(ex))<tab><tab>LOG.error(""Failed to import psycopg2 or pg8000 module."")<tab><tab>raise",1,if driver :,if driver :,0.5311706625951745,1e-10,1.0
"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None:<tab>modules = getattr(env, ""_viewcode_modules"", {})<tab>for modname, entry in list(modules.items()):<tab><tab>if entry is False:<tab><tab><tab>continue<tab><tab>code, tags, used, refname = entry<tab><tab>for fullname in list(used):<tab><tab><tab>if used[fullname] == docname:<tab><tab><tab><tab>used.pop(fullname)<tab><tab><IF-STMT><tab><tab><tab>modules.pop(modname)",0,if len ( used ) == 0 :,if fullname not in modules :,0.018517117658868813,5.854497694024015,0.20634920634920637
"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab>if len(q) == 1:<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.append(value)<tab><tab><tab>elif is_iterable(value):<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",0,if not is_iterable ( value ) :,if len ( q ) == 0 :,0.022224573773363735,6.742555929751843,0.2698412698412698
"def _get_bucket_for_key(self, key: bytes) -> Optional[_DBValueTuple]:<tab>dbs: Iterable[PartitionDB]<tab>try:<tab><tab>partition = self._key_index[key]<tab><tab>dbs = [PartitionDB(partition, self._dbs[partition])]<tab>except KeyError:<tab><tab>dbs = cast(Iterable[PartitionDB], self._dbs.items())<tab>for partition, db in dbs:<tab><tab>if db.key_may_exist(key)[0]:<tab><tab><tab>value = db.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._key_index[key] = partition<tab><tab><tab><tab>return _DBValueTuple(db, value)<tab>return None",1,if value is not None :,if value is not None :,0.75,100.00000000000004,1.0
"def _clean(self):<tab>logger.info(""Cleaning up..."")<tab>if self._process is not None:<tab><tab>if self._process.poll() is None:<tab><tab><tab>for _ in range(3):<tab><tab><tab><tab>self._process.terminate()<tab><tab><tab><tab>time.sleep(0.5)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self._process.kill()<tab><tab><tab><tab>self._process.wait()<tab><tab><tab><tab>logger.error(""KILLED"")<tab>if os.path.exists(self._tmp_dir):<tab><tab>shutil.rmtree(self._tmp_dir)<tab>self._process = None<tab>self._ws = None<tab>logger.info(""Cleanup complete"")",1,if self . _process . poll ( ) is not None :,if self . _process . poll ( ) is not None :,0.75,100.00000000000004,1.0
"def _calculate_runtimes(states):<tab>results = {""runtime"": 0.00, ""num_failed_states"": 0, ""num_passed_states"": 0}<tab>for state, resultset in states.items():<tab><tab>if isinstance(resultset, dict) and ""duration"" in resultset:<tab><tab><tab># Count the pass vs failures<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results[""num_passed_states""] += 1<tab><tab><tab>else:<tab><tab><tab><tab>results[""num_failed_states""] += 1<tab><tab><tab># Count durations<tab><tab><tab>results[""runtime""] += resultset[""duration""]<tab>log.debug(""Parsed state metrics: {}"".format(results))<tab>return results",0,"if resultset [ ""result"" ] :","if resultset [ ""pass"" ] :",0.37826709512211065,50.000000000000014,1.0
"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None):<tab>if next is not None and token.end_mark.line == next.start_mark.line:<tab><tab>spaces = next.start_mark.pointer - token.end_mark.pointer<tab><tab>if max != -1 and spaces > max:<tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column, max_desc<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column + 1, min_desc<tab><tab><tab>)",0,elif min != - 1 and spaces < min :,if min != - 1 and spaces < min :,0.6900558683966966,89.31539818068698,0.7142857142857143
"def getfileinfo(name):<tab>finfo = FInfo()<tab>with io.open(name, ""rb"") as fp:<tab><tab># Quick check for textfile<tab><tab>data = fp.read(512)<tab><tab><IF-STMT><tab><tab><tab>finfo.Type = ""TEXT""<tab><tab>fp.seek(0, 2)<tab><tab>dsize = fp.tell()<tab>dir, file = os.path.split(name)<tab>file = file.replace("":"", ""-"", 1)<tab>return file, finfo, dsize, 0",0,if 0 not in data :,if len ( data ) == 0 :,0.02492724325929667,6.742555929751843,0.2653061224489796
"def dict_to_XML(tag, dictionary, **kwargs):<tab>""""""Return XML element converting dicts recursively.""""""<tab>elem = Element(tag, **kwargs)<tab>for key, val in dictionary.items():<tab><tab>if tag == ""layers"":<tab><tab><tab>child = dict_to_XML(""layer"", val, name=key)<tab><tab><IF-STMT><tab><tab><tab>child = dict_to_XML(key, val)<tab><tab>else:<tab><tab><tab>if tag == ""config"":<tab><tab><tab><tab>child = Element(""variable"", name=key)<tab><tab><tab>else:<tab><tab><tab><tab>child = Element(key)<tab><tab><tab>child.text = str(val)<tab><tab>elem.append(child)<tab>return elem",0,"elif isinstance ( val , MutableMapping ) :","elif isinstance ( val , dict ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def _read_bytes(self, length):<tab>buffer = b""""<tab>while length:<tab><tab>chunk = self.request.recv(length)<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Connection closed"")<tab><tab><tab>return False<tab><tab>length -= len(chunk)<tab><tab>buffer += chunk<tab>return buffer",0,"if chunk == b"""" :",if not chunk :,0.03944961859844226,7.733712583165139,0.45
"def rec_deps(services, container_by_name, cnt, init_service):<tab>deps = cnt[""_deps""]<tab>for dep in deps.copy():<tab><tab>dep_cnts = services.get(dep)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dep_cnt = container_by_name.get(dep_cnts[0])<tab><tab>if dep_cnt:<tab><tab><tab># TODO: avoid creating loops, A->B->A<tab><tab><tab>if init_service and init_service in dep_cnt[""_deps""]:<tab><tab><tab><tab>continue<tab><tab><tab>new_deps = rec_deps(services, container_by_name, dep_cnt, init_service)<tab><tab><tab>deps.update(new_deps)<tab>return deps",1,if not dep_cnts :,if not dep_cnts :,0.75,100.00000000000004,1.0
"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if e.value is None:<tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab>elif type(e.value) is not list:<tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab>if type(e) is Command or type(e) is Option and e.argcount == 0:<tab><tab><tab><tab>e.value = 0<tab>return self",0,if type ( e ) is Argument or type ( e ) is Option and e . argcount :,if type ( e ) is Argument or type ( e ) is Option and e . argcount == 0 :,0.8849554077912051,81.51678595510181,0.9030303030303031
"def do_cli(manager, options):<tab>header = [""Name"", ""Description""]<tab>table_data = [header]<tab>for filter_name, filter in get_filters():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>filter_doc = inspect.getdoc(filter) or """"<tab><tab>table_data.append([filter_name, filter_doc])<tab>try:<tab><tab>table = TerminalTable(options.table_type, table_data)<tab>except TerminalTableError as e:<tab><tab>console(""ERROR: %s"" % str(e))<tab>else:<tab><tab>console(table.output)",0,if options . name and not options . name in filter_name :,if filter is None :,0.04585542520567507,2.3238598963754593,0.16666666666666666
"def _do_cmp(f1, f2):<tab>bufsize = BUFSIZE<tab>with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2:<tab><tab>while True:<tab><tab><tab>b1 = fp1.read(bufsize)<tab><tab><tab>b2 = fp2.read(bufsize)<tab><tab><tab>if b1 != b2:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True",0,if not b1 :,if b1 == b2 :,0.045150550804307965,10.682175159905853,0.4
"def apply(self, db, person):<tab>families = person.get_parent_family_handle_list()<tab>if families == []:<tab><tab>return True<tab>for family_handle in person.get_parent_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>father_handle = family.get_father_handle()<tab><tab><tab>mother_handle = family.get_mother_handle()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>if not mother_handle:<tab><tab><tab><tab>return True<tab>return False",0,if not father_handle :,if not father_handle or not mother_handle :,0.15073976469762834,41.72261448611506,0.6041666666666666
"def caesar_cipher(s, k):<tab>result = """"<tab>for char in s:<tab><tab>n = ord(char)<tab><tab>if 64 < n < 91:<tab><tab><tab>n = ((n - 65 + k) % 26) + 65<tab><tab><IF-STMT><tab><tab><tab>n = ((n - 97 + k) % 26) + 97<tab><tab>result = result + chr(n)<tab>return result",0,if 96 < n < 123 :,elif 32 < n < 57 :,0.08314356137060366,26.269098944241588,0.25
"def title_by_index(self, trans, index, context):<tab>d_type = self.get_datatype(trans, context)<tab>for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()):<tab><tab>if i == index:<tab><tab><tab>rval = composite_name<tab><tab><tab>if composite_file.description:<tab><tab><tab><tab>rval = ""{} ({})"".format(rval, composite_file.description)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rval = ""%s [optional]"" % rval<tab><tab><tab>return rval<tab>if index < self.get_file_count(trans, context):<tab><tab>return ""Extra primary file""<tab>return None",0,if composite_file . optional :,"if ""optional"" in rval :",0.03412306583404374,8.643019616048525,0.36
"def __str__(self):<tab>t = ""<tab>""<tab>if self._name != ""root"":<tab><tab>r = f""{t * (self._level-1)}{self._name}:\n""<tab>else:<tab><tab>r = """"<tab>level = self._level<tab>for i, (k, v) in enumerate(self._pointer.items()):<tab><tab><IF-STMT><tab><tab><tab>r += f""{t * (self._level)}{v}\n""<tab><tab><tab>self._level += 1<tab><tab>else:<tab><tab><tab>r += f""{t * (self._level)}{k}: {v} ({type(v).__name__})\n""<tab><tab>self._level = level<tab>return r[:-1]",0,"if isinstance ( v , Config ) :",if i == level :,0.01858685153282265,6.916271812933183,0.2698412698412698
"def __get_securitygroups(vm_):<tab>vm_securitygroups = config.get_cloud_config_value(<tab><tab>""securitygroups"", vm_, __opts__, search_global=False<tab>)<tab>if not vm_securitygroups:<tab><tab>return []<tab>securitygroups = list_securitygroups()<tab>for i in range(len(vm_securitygroups)):<tab><tab>vm_securitygroups[i] = six.text_type(vm_securitygroups[i])<tab><tab><IF-STMT><tab><tab><tab>raise SaltCloudNotFound(<tab><tab><tab><tab>""The specified securitygroups '{0}' could not be found."".format(<tab><tab><tab><tab><tab>vm_securitygroups[i]<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return vm_securitygroups",0,if vm_securitygroups [ i ] not in securitygroups :,if vm_securitygroups [ i ] not inSecurityGroups :,0.3618723018637402,70.80735452207037,0.5555555555555556
"def assert_walk_snapshot(<tab>self, field, filespecs_or_globs, paths, ignore_patterns=None, prepare=None):<tab>with self.mk_project_tree(ignore_patterns=ignore_patterns) as project_tree:<tab><tab>scheduler = self.mk_scheduler(<tab><tab><tab>rules=create_fs_rules(), project_tree=project_tree<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>prepare(project_tree)<tab><tab>result = self.execute(scheduler, Snapshot, self.specs(filespecs_or_globs))[0]<tab><tab>self.assertEqual(sorted(getattr(result, field)), sorted(paths))",0,if prepare :,if prepare is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def _parse_rowids(self, rowids):<tab>xploded = []<tab>rowids = [x.strip() for x in rowids.split("","")]<tab>for rowid in rowids:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = int(rowid.split(""-"")[0].strip())<tab><tab><tab><tab>end = int(rowid.split(""-"")[-1].strip())<tab><tab><tab><tab>xploded += range(start, end + 1)<tab><tab><tab>else:<tab><tab><tab><tab>xploded.append(int(rowid))<tab><tab>except ValueError:<tab><tab><tab>continue<tab>return sorted(list(set(xploded)))",1,"if ""-"" in rowid :","if ""-"" in rowid :",0.75,100.00000000000004,1.0
"def ensemble(self, pairs, other_preds):<tab>""""""Ensemble the dict with statistical model predictions.""""""<tab>lemmas = []<tab>assert len(pairs) == len(other_preds)<tab>for p, pred in zip(pairs, other_preds):<tab><tab>w, pos = p<tab><tab><IF-STMT><tab><tab><tab>lemma = self.composite_dict[(w, pos)]<tab><tab>elif w in self.word_dict:<tab><tab><tab>lemma = self.word_dict[w]<tab><tab>else:<tab><tab><tab>lemma = pred<tab><tab>if lemma is None:<tab><tab><tab>lemma = w<tab><tab>lemmas.append(lemma)<tab>return lemmas",1,"if ( w , pos ) in self . composite_dict :","if ( w , pos ) in self . composite_dict :",0.75,100.00000000000004,1.0
"def selectionToChunks(self, remove=False, add=False):<tab>box = self.selectionBox()<tab>if box:<tab><tab><IF-STMT><tab><tab><tab>self.selectedChunks = set(self.level.allChunks)<tab><tab><tab>return<tab><tab>selectedChunks = self.selectedChunks<tab><tab>boxedChunks = set(box.chunkPositions)<tab><tab>if boxedChunks.issubset(selectedChunks):<tab><tab><tab>remove = True<tab><tab>if remove and not add:<tab><tab><tab>selectedChunks.difference_update(boxedChunks)<tab><tab>else:<tab><tab><tab>selectedChunks.update(boxedChunks)<tab>self.selectionTool.selectNone()",0,if box == self . level . bounds :,if remove and add :,0.015736078468693036,4.673289785800722,0.20987654320987653
"def _ensure_max_size(cls, image, max_size, interpolation):<tab>if max_size is not None:<tab><tab>size = max(image.shape[0], image.shape[1])<tab><tab><IF-STMT><tab><tab><tab>resize_factor = max_size / size<tab><tab><tab>new_height = int(image.shape[0] * resize_factor)<tab><tab><tab>new_width = int(image.shape[1] * resize_factor)<tab><tab><tab>image = ia.imresize_single_image(<tab><tab><tab><tab>image, (new_height, new_width), interpolation=interpolation<tab><tab><tab>)<tab>return image",0,if size > max_size :,if size != max_size :,0.33141502097923065,41.11336169005198,1.0
"def _1_0_cloud_ips(self, method, url, body, headers):<tab>if method == ""GET"":<tab><tab>return self.test_response(httplib.OK, self.fixtures.load(""list_cloud_ips.json""))<tab>elif method == ""POST"":<tab><tab><IF-STMT><tab><tab><tab>body = json.loads(body)<tab><tab>node = json.loads(self.fixtures.load(""create_cloud_ip.json""))<tab><tab>if ""reverse_dns"" in body:<tab><tab><tab>node[""reverse_dns""] = body[""reverse_dns""]<tab><tab>return self.test_response(httplib.ACCEPTED, json.dumps(node))",1,if body :,if body :,0.5311706625951745,1e-10,1.0
"def get_formatted_stats(self):<tab>""""""Get percentage or number of rar's done""""""<tab>if self.cur_setname and self.cur_setname in self.total_volumes:<tab><tab># This won't work on obfuscated posts<tab><tab><IF-STMT><tab><tab><tab>return ""%02d/%02d"" % (self.cur_volume, self.total_volumes[self.cur_setname])<tab>return self.cur_volume",0,if self . total_volumes [ self . cur_setname ] >= self . cur_volume and self . cur_volume :,if self . cur_setname in self . total_volumes :,0.11533319798691459,22.07061200651185,0.517948717948718
"def wdayset(self, year, month, day):<tab># We need to handle cross-year weeks here.<tab>dset = [None] * (self.yearlen + 7)<tab>i = datetime.date(year, month, day).toordinal() - self.yearordinal<tab>start = i<tab>for j in range(7):<tab><tab>dset[i] = i<tab><tab>i += 1<tab><tab># if (not (0 <= i < self.yearlen) or<tab><tab>#<tab>self.wdaymask[i] == self.rrule._wkst):<tab><tab># This will cross the year boundary, if necessary.<tab><tab><IF-STMT><tab><tab><tab>break<tab>return dset, start, i",0,if self . wdaymask [ i ] == self . rrule . _wkst :,if i >= self . wdaymask [ i ] :,0.5241125255070584,35.89495197714159,0.3235294117647059
"def do_acquire_read_lock(self, wait=True):<tab>self.condition.acquire()<tab>try:<tab><tab># see if a synchronous operation is waiting to start<tab><tab># or is already running, in which case we wait (or just<tab><tab># give up and return)<tab><tab><IF-STMT><tab><tab><tab>while self.current_sync_operation is not None:<tab><tab><tab><tab>self.condition.wait()<tab><tab>else:<tab><tab><tab>if self.current_sync_operation is not None:<tab><tab><tab><tab>return False<tab><tab>self.asynch += 1<tab>finally:<tab><tab>self.condition.release()<tab>if not wait:<tab><tab>return True",1,if wait :,if wait :,0.5311706625951745,1e-10,1.0
"def _blend(x, y):  # pylint: disable=invalid-name<tab>""""""Implements the ""blend"" strategy for `deep_merge`.""""""<tab>if isinstance(x, (dict, OrderedDict)):<tab><tab><IF-STMT><tab><tab><tab>return y<tab><tab>return _merge(x, y, recursion_func=_blend)<tab>if isinstance(x, (list, tuple)):<tab><tab>if not isinstance(y, (list, tuple)):<tab><tab><tab>return y<tab><tab>result = [_blend(*i) for i in zip(x, y)]<tab><tab>if len(x) > len(y):<tab><tab><tab>result += x[len(y) :]<tab><tab>elif len(x) < len(y):<tab><tab><tab>result += y[len(x) :]<tab><tab>return result<tab>return y",0,"if not isinstance ( y , ( dict , OrderedDict ) ) :","if not isinstance ( y , dict ) :",0.2220412049535349,43.624306402227546,0.8476190476190476
"def update_forum_nums_topic_post(modeladmin, request, queryset):<tab>for forum in queryset:<tab><tab>forum.num_topics = forum.count_nums_topic()<tab><tab>forum.num_posts = forum.count_nums_post()<tab><tab><IF-STMT><tab><tab><tab>forum.last_post = forum.topic_set.order_by(""-last_reply_on"")[0].last_post<tab><tab>else:<tab><tab><tab>forum.last_post = """"<tab><tab>forum.save()",0,if forum . num_topics :,if forum . topic_set :,0.39477865547525276,27.77619034011791,1.0
"def get_docname_for_node(self, node: Node) -> str:<tab>while node:<tab><tab>if isinstance(node, nodes.document):<tab><tab><tab>return self.env.path2doc(node[""source""])<tab><tab><IF-STMT><tab><tab><tab>return node[""docname""]<tab><tab>else:<tab><tab><tab>node = node.parent<tab>return None  # never reached here. only for type hinting",0,"elif isinstance ( node , addnodes . start_of_file ) :","elif isinstance ( node , nodes . name ) :",0.35856898886410005,31.313195073576246,0.5584415584415584
"def _selected_machines(self, virtual_machines):<tab>selected_machines = []<tab>for machine in virtual_machines:<tab><tab>if self._args.host and self._args.host == machine.name:<tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.tags and self._tags_match(machine.tags, self.tags):<tab><tab><tab>selected_machines.append(machine)<tab><tab><IF-STMT><tab><tab><tab>selected_machines.append(machine)<tab>return selected_machines",0,if self . locations and machine . location in self . locations :,"if self . _tags_match ( machine . tags , self . tags ) :",0.05709146654224981,12.936981168384865,0.25213675213675213
"def transform_kwarg(self, name, value, split_single_char_options):<tab>if len(name) == 1:<tab><tab>if value is True:<tab><tab><tab>return [""-%s"" % name]<tab><tab><IF-STMT><tab><tab><tab>if split_single_char_options:<tab><tab><tab><tab>return [""-%s"" % name, ""%s"" % value]<tab><tab><tab>else:<tab><tab><tab><tab>return [""-%s%s"" % (name, value)]<tab>else:<tab><tab>if value is True:<tab><tab><tab>return [""--%s"" % dashify(name)]<tab><tab>elif value is not False and value is not None:<tab><tab><tab>return [""--%s=%s"" % (dashify(name), value)]<tab>return []",0,"elif value not in ( False , None ) :","elif isinstance ( value , str ) :",0.2440219864271585,11.320467831315831,0.2
"def indent(elem, level=0):<tab>i = ""\n"" + level * ""  ""<tab>if len(elem):<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i",1,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,1.0,100.00000000000004,1.0
"def _run_instances_op(self, op, instance_ids, **kwargs):<tab>while instance_ids:<tab><tab>try:<tab><tab><tab>return self.manager.retry(op, InstanceIds=instance_ids, **kwargs)<tab><tab>except ClientError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>instance_ids.remove(extract_instance_id(e))<tab><tab><tab>raise",0,"if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :","if e . response [ ""Error"" ] [ ""Code"" ] == ""ResourceNotFoundException"" :",0.6722061395603371,87.39351325046809,1.0
"def runTest(self):<tab>self.poco(text=""wait UI"").click()<tab>bomb_count = 0<tab>while True:<tab><tab>blue_fish = self.poco(""fish_emitter"").child(""blue"")<tab><tab>yellow_fish = self.poco(""fish_emitter"").child(""yellow"")<tab><tab>bomb = self.poco(""fish_emitter"").child(""bomb"")<tab><tab>fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb])<tab><tab><IF-STMT><tab><tab><tab>bomb_count += 1<tab><tab><tab>if bomb_count > 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>fish.click()<tab><tab>time.sleep(2.5)",0,if fish is bomb :,iffish is not None :,0.15476420643801878,12.703318703865365,0.125
"def lineWidth(self, lw=None):<tab>""""""Set/get width of mesh edges. Same as `lw()`.""""""<tab>if lw is not None:<tab><tab><IF-STMT><tab><tab><tab>self.GetProperty().EdgeVisibilityOff()<tab><tab><tab>self.GetProperty().SetRepresentationToSurface()<tab><tab><tab>return self<tab><tab>self.GetProperty().EdgeVisibilityOn()<tab><tab>self.GetProperty().SetLineWidth(lw)<tab>else:<tab><tab>return self.GetProperty().GetLineWidth()<tab>return self",0,if lw == 0 :,if self . GetProperty ( ) . GetLineWidth ( ) == lw :,0.024996097796421927,7.141816289329644,0.2698412698412698
"def _current_date_updater(doc, field_name, value):<tab>if isinstance(doc, dict):<tab><tab><IF-STMT><tab><tab><tab># TODO(juannyg): get_current_timestamp should also be using helpers utcnow,<tab><tab><tab># as it currently using time.time internally<tab><tab><tab>doc[field_name] = helpers.get_current_timestamp()<tab><tab>else:<tab><tab><tab>doc[field_name] = mongomock.utcnow()",0,"if value == { ""$type"" : ""timestamp"" } :",if value :,0.07481463270768146,1e-10,1.0
"def fill_members(self):<tab>if self._get_retrieve():<tab><tab>after = self.after.id if self.after else None<tab><tab>data = await self.get_members(self.guild.id, self.retrieve, after)<tab><tab><IF-STMT><tab><tab><tab># no data, terminate<tab><tab><tab>return<tab><tab>if len(data) < 1000:<tab><tab><tab>self.limit = 0  # terminate loop<tab><tab>self.after = Object(id=int(data[-1][""user""][""id""]))<tab><tab>for element in reversed(data):<tab><tab><tab>await self.members.put(self.create_member(element))",1,if not data :,if not data :,0.75,100.00000000000004,1.0
"def extract(self, page, start_index=0, end_index=None):<tab>items = []<tab>for extractor in self.extractors:<tab><tab>extracted = extractor.extract(<tab><tab><tab>page, start_index, end_index, self.template.ignored_regions<tab><tab>)<tab><tab>for item in arg_to_iter(extracted):<tab><tab><tab>if item:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>item[u""_template""] = self.template.id<tab><tab><tab><tab>items.append(item)<tab>return items",0,"if isinstance ( item , ( ItemProcessor , dict ) ) :","if u""_template"" not in item :",0.011387185973035771,4.521356896113449,0.24166666666666667
"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any:<tab>fields = self.config[fields_key]<tab>node_tags = self.provider.node_tags(node_id)<tab>if TAG_RAY_USER_NODE_TYPE in node_tags:<tab><tab>node_type = node_tags[TAG_RAY_USER_NODE_TYPE]<tab><tab>if node_type not in self.available_node_types:<tab><tab><tab>raise ValueError(f""Unknown node type tag: {node_type}."")<tab><tab>node_specific_config = self.available_node_types[node_type]<tab><tab><IF-STMT><tab><tab><tab>fields = node_specific_config[fields_key]<tab>return fields",1,if fields_key in node_specific_config :,if fields_key in node_specific_config :,0.75,100.00000000000004,1.0
"def _write_all(self, writer):<tab>""""""Writes messages and insert comments here and there.""""""<tab># Note: we make no assumptions about the length of original_messages and original_comments<tab>for msg, comment in zip_longest(<tab><tab>self.original_messages, self.original_comments, fillvalue=None<tab>):<tab><tab># msg and comment might be None<tab><tab><IF-STMT><tab><tab><tab>print(""writing comment: "", comment)<tab><tab><tab>writer.log_event(comment)  # we already know that this method exists<tab><tab>if msg is not None:<tab><tab><tab>print(""writing message: "", msg)<tab><tab><tab>writer(msg)",1,if comment is not None :,if comment is not None :,0.75,100.00000000000004,1.0
"def run_tests():<tab># type: () -> None<tab>x = 5<tab>with switch(x) as case:<tab><tab><IF-STMT><tab><tab><tab>print(""zero"")<tab><tab><tab>print(""zero"")<tab><tab>elif case(1, 2):<tab><tab><tab>print(""one or two"")<tab><tab>elif case(3, 4):<tab><tab><tab>print(""three or four"")<tab><tab>else:<tab><tab><tab>print(""default"")<tab><tab><tab>print(""another"")",0,if case ( 0 ) :,"if case ( 0 , 1 ) :",0.31635217409296834,41.11336169005198,0.7777777777777778
"def date_to_format(value, target_format):<tab>""""""Convert date to specified format""""""<tab>if target_format == str:<tab><tab>if isinstance(value, datetime.date):<tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab><IF-STMT><tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab>elif isinstance(value, datetime.time):<tab><tab><tab>ret = value.strftime(""%H:%M:%S"")<tab>else:<tab><tab>ret = value<tab>return ret",1,"elif isinstance ( value , datetime . datetime ) :","elif isinstance ( value , datetime . datetime ) :",1.0,100.00000000000004,1.0
"def database_app(request):<tab>if request.param == ""postgres_app"":<tab><tab>if not which(""initdb""):<tab><tab><tab>pytest.skip(""initdb must be on PATH for postgresql fixture"")<tab><tab><IF-STMT><tab><tab><tab>pytest.skip(""psycopg2 must be installed for postgresql fixture"")<tab>if request.param == ""sqlite_rabbitmq_app"":<tab><tab>if not os.environ.get(""GALAXY_TEST_AMQP_INTERNAL_CONNECTION""):<tab><tab><tab>pytest.skip(<tab><tab><tab><tab>""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset""<tab><tab><tab>)<tab>return request.getfixturevalue(request.param)",0,if not psycopg2 :,"if not which ( ""psycopg2"" ) :",0.06818083849749242,11.339582221952005,0.6
"def poll_ms(self, timeout=-1):<tab>s = bytearray(self.evbuf)<tab><IF-STMT><tab><tab>deadline = utime.ticks_add(utime.ticks_ms(), timeout)<tab>while True:<tab><tab>n = epoll_wait(self.epfd, s, 1, timeout)<tab><tab>if not os.check_error(n):<tab><tab><tab>break<tab><tab>if timeout >= 0:<tab><tab><tab>timeout = utime.ticks_diff(deadline, utime.ticks_ms())<tab><tab><tab>if timeout < 0:<tab><tab><tab><tab>n = 0<tab><tab><tab><tab>break<tab>res = []<tab>if n > 0:<tab><tab>vals = struct.unpack(epoll_event, s)<tab><tab>res.append((vals[1], vals[0]))<tab>return res",1,if timeout >= 0 :,if timeout >= 0 :,0.75,100.00000000000004,1.0
"def get_all_active_plugins(self) -> List[BotPlugin]:<tab>""""""This returns the list of plugins in the callback ordered defined from the config.""""""<tab>all_plugins = []<tab>for name in self.plugins_callback_order:<tab><tab># None is a placeholder for any plugin not having a defined order<tab><tab>if name is None:<tab><tab><tab>all_plugins += [<tab><tab><tab><tab>plugin<tab><tab><tab><tab>for name, plugin in self.plugins.items()<tab><tab><tab><tab>if name not in self.plugins_callback_order and plugin.is_activated<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>plugin = self.plugins[name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_plugins.append(plugin)<tab>return all_plugins",1,if plugin . is_activated :,if plugin . is_activated :,0.75,100.00000000000004,1.0
"def get_expected_sql(self):<tab>sql_base_path = path.join(path.dirname(path.realpath(__file__)), ""sql"")<tab># Iterate the version mapping directories.<tab>for version_mapping in get_version_mapping_directories(self.server[""type""]):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>complete_path = path.join(sql_base_path, version_mapping[""name""])<tab><tab>if not path.exists(complete_path):<tab><tab><tab>continue<tab><tab>break<tab>data_sql = """"<tab>with open(path.join(complete_path, ""test_sql_output.sql"")) as fp:<tab><tab>data_sql = fp.read()<tab>return data_sql",0,"if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :","if ""name"" not in version_mapping :",0.010091055973079834,5.261190768564949,0.3904761904761905
"def _validate_headers(self, headers):<tab>if headers is None:<tab><tab>return headers<tab>res = {}<tab>for key, value in headers.items():<tab><tab>if isinstance(value, (int, float)):<tab><tab><tab>value = str(value)<tab><tab><IF-STMT><tab><tab><tab>raise ScriptError(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""message"": ""headers must be a table""<tab><tab><tab><tab><tab>"" with strings as keys and values.""<tab><tab><tab><tab><tab>""Header: `{!r}:{!r}` is not valid"".format(key, value)<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab>res[key] = value<tab>return res",0,"if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) :","if not isinstance ( key , str ) :",0.12215992264097808,13.065661823585266,0.4579124579124579
"def _get_literal_value(self, pyval):<tab>if pyval == self.vm.lookup_builtin(""builtins.True""):<tab><tab>return True<tab>elif pyval == self.vm.lookup_builtin(""builtins.False""):<tab><tab>return False<tab>elif isinstance(pyval, str):<tab><tab>prefix, value = parser_constants.STRING_RE.match(pyval).groups()[:2]<tab><tab>value = value[1:-1]  # remove quotation marks<tab><tab><IF-STMT><tab><tab><tab>value = compat.bytestring(value)<tab><tab>elif ""u"" in prefix and self.vm.PY2:<tab><tab><tab>value = compat.UnicodeType(value)<tab><tab>return value<tab>else:<tab><tab>return pyval",0,"if ""b"" in prefix and not self . vm . PY2 :","if ""x"" in prefix and self . vm . PY1 :",0.30464528793366347,40.304968802021214,0.48888888888888893
"def decode_query_ids(self, trans, conditional):<tab>if conditional.operator == ""and"":<tab><tab>self.decode_query_ids(trans, conditional.left)<tab><tab>self.decode_query_ids(trans, conditional.right)<tab>else:<tab><tab>left_base = conditional.left.split(""."")[0]<tab><tab><IF-STMT><tab><tab><tab>field = self.FIELDS[left_base]<tab><tab><tab>if field.id_decode:<tab><tab><tab><tab>conditional.right = trans.security.decode_id(conditional.right)",0,if left_base in self . FIELDS :,if left_base in self .FIELDS :,0.4761337782760353,100.00000000000004,0.7714285714285715
"def testLastPhrases(self):<tab>for day in (11, 12, 13, 14, 15, 16, 17):<tab><tab>start = datetime.datetime(2012, 11, day, 9, 0, 0)<tab><tab>(yr, mth, dy, _, _, _, wd, yd, isdst) = start.timetuple()<tab><tab>n = 4 - wd<tab><tab><IF-STMT><tab><tab><tab>n -= 7<tab><tab>target = start + datetime.timedelta(days=n)<tab><tab>self.assertExpectedResult(<tab><tab><tab>self.cal.parse(""last friday"", start.timetuple()),<tab><tab><tab>(target.timetuple(), 1),<tab><tab><tab>dateOnly=True,<tab><tab>)",0,if n >= 0 :,if isdst :,0.03549272049582243,1e-10,0.36
"def _convertNbCharsInNbBits(self, nbChars):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbChars is not None:<tab><tab>if isinstance(nbChars, int):<tab><tab><tab>nbMinBit = nbChars * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nbMinBit = nbChars[0] * 8<tab><tab><tab>if nbChars[1] is not None:<tab><tab><tab><tab>nbMaxBit = nbChars[1] * 8<tab>return (nbMinBit, nbMaxBit)",1,if nbChars [ 0 ] is not None :,if nbChars [ 0 ] is not None :,0.75,100.00000000000004,1.0
"def getpystone():<tab># Start calculation<tab>maxpystone = 0<tab># Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second<tab>for pyseed in [1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000]:<tab><tab>duration, pystonefloat = pystones(pyseed)<tab><tab>maxpystone = max(maxpystone, int(pystonefloat))<tab><tab># Stop when pystone() has been running for at least 0.1 second<tab><tab><IF-STMT><tab><tab><tab>break<tab>return maxpystone",1,if duration > 0.1 :,if duration > 0.1 :,0.75,100.00000000000004,1.0
"def _append_to_io_queue(self, data, stream_name):<tab># Make sure ANSI CSI codes and object links are stored as separate events<tab># TODO: try to complete previously submitted incomplete code<tab>parts = re.split(OUTPUT_SPLIT_REGEX, data)<tab>for part in parts:<tab><tab><IF-STMT>  # split may produce empty string in the beginning or start<tab><tab><tab># split the data so that very long lines separated<tab><tab><tab>for block in re.split(<tab><tab><tab><tab>""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part<tab><tab><tab>):<tab><tab><tab><tab>if block:<tab><tab><tab><tab><tab>self._queued_io_events.append((block, stream_name))",1,if part :,if part :,0.5311706625951745,1e-10,1.0
"def qtTypeIdent(conn, *args):<tab># We're not using the conn object at the moment, but - we will<tab># modify the<tab># logic to use the server version specific keywords later.<tab>res = None<tab>value = None<tab>for val in args:<tab><tab># DataType doesn't have len function then convert it to string<tab><tab><IF-STMT><tab><tab><tab>val = str(val)<tab><tab>if len(val) == 0:<tab><tab><tab>continue<tab><tab>value = val<tab><tab>if Driver.needsQuoting(val, True):<tab><tab><tab>value = value.replace('""', '""""')<tab><tab><tab>value = '""' + value + '""'<tab><tab>res = ((res and res + ""."") or """") + value<tab>return res",0,"if not hasattr ( val , ""__len__"" ) :","if isinstance ( val , int ) :",0.08038725729605721,11.277832374502772,0.2857142857142857
"def SetVerbose(self, level):<tab>""""""Sets the verbose level.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>level = int(level)<tab><tab>if (level >= 0) and (level <= 3):<tab><tab><tab>self._verbose = level<tab><tab><tab>return<tab>except ValueError:<tab><tab>pass<tab>self.Error(""Verbose level (%s) must be between 0 and 3 inclusive."" % level)",0,if type ( level ) != types . IntType :,"if not isinstance ( level , int ) :",0.029205697404072792,9.600960275119885,0.2222222222222222
"def step(self) -> None:<tab>""""""Performs a single optimization step.""""""<tab>for group in self.param_groups:<tab><tab>for p in group[""params""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>p.add_(p.grad, alpha=(-group[""lr""] * self.num_data))<tab>return None",1,if p . grad is None :,if p . grad is None :,0.75,100.00000000000004,1.0
"def fill(self, values):<tab>if lupa.lua_type(values) != ""table"":<tab><tab>raise ScriptError(<tab><tab><tab>{<tab><tab><tab><tab>""argument"": ""values"",<tab><tab><tab><tab>""message"": ""element:fill values is not a table"",<tab><tab><tab><tab>""splash_method"": ""fill"",<tab><tab><tab>}<tab><tab>)<tab># marking all tables as arrays by default<tab>for key, value in values.items():<tab><tab><IF-STMT><tab><tab><tab>_mark_table_as_array(self.lua, value)<tab>values = self.lua.lua2python(values)<tab>return self.element.fill(values)",0,"if lupa . lua_type ( value ) == ""table"" :","if isinstance ( value , np . ndarray ) :",0.030023989933691802,6.699007141691558,0.40476190476190477
"def _gen_repr(self, buf):<tab>print >> buf, ""<tab>def __repr__(self):""<tab>if self.argnames:<tab><tab>fmt = COMMA.join([""%s""] * self.nargs)<tab><tab><IF-STMT><tab><tab><tab>fmt = ""(%s)"" % fmt<tab><tab>vals = [""repr(self.%s)"" % name for name in self.argnames]<tab><tab>vals = COMMA.join(vals)<tab><tab>if self.nargs == 1:<tab><tab><tab>vals = vals + "",""<tab><tab>print >> buf, '<tab><tab>return ""%s(%s)"" %% (%s)' % (self.name, fmt, vals)<tab>else:<tab><tab>print >> buf, '<tab><tab>return ""%s()""' % self.name",0,"if ""("" in self . args :",if self . nargs == 1 :,0.04282569298264552,11.59119922599073,0.2857142857142857
"def render_observation(self):<tab>x = self.read_head_position<tab>label = ""Observation Grid<tab>: ""<tab>x_str = """"<tab>for j in range(-1, self.rows + 1):<tab><tab><IF-STMT><tab><tab><tab>x_str += "" "" * len(label)<tab><tab>for i in range(-2, self.input_width + 2):<tab><tab><tab>if i == x[0] and j == x[1]:<tab><tab><tab><tab>x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True)<tab><tab><tab>else:<tab><tab><tab><tab>x_str += self._get_str_obs((i, j))<tab><tab>x_str += ""\n""<tab>x_str = label + x_str<tab>return x_str",0,if j != - 1 :,if x_str :,0.026485502076288185,1e-10,0.4375
"def get_module_comment(self, attrname: str) -> Optional[List[str]]:<tab>try:<tab><tab>analyzer = ModuleAnalyzer.for_module(self.modname)<tab><tab>analyzer.analyze()<tab><tab>key = ("""", attrname)<tab><tab><IF-STMT><tab><tab><tab>return list(analyzer.attr_docs[key])<tab>except PycodeError:<tab><tab>pass<tab>return None",1,if key in analyzer . attr_docs :,if key in analyzer . attr_docs :,0.75,100.00000000000004,1.0
"def tms_to_quadkey(self, tms, google=False):<tab>quadKey = """"<tab>x, y, z = tms<tab># this algorithm works with google tiles, rather than tms, so convert<tab># to those first.<tab>if not google:<tab><tab>y = (2 ** z - 1) - y<tab>for i in range(z, 0, -1):<tab><tab>digit = 0<tab><tab>mask = 1 << (i - 1)<tab><tab><IF-STMT><tab><tab><tab>digit += 1<tab><tab>if (y & mask) != 0:<tab><tab><tab>digit += 2<tab><tab>quadKey += str(digit)<tab>return quadKey",1,if ( x & mask ) != 0 :,if ( x & mask ) != 0 :,0.75,100.00000000000004,1.0
"def test_enumerate(app):<tab>async with new_stream(app) as stream:<tab><tab>for i in range(100):<tab><tab><tab>await stream.channel.deliver(message(key=i, value=i * 4))<tab><tab>async for i, value in stream.enumerate():<tab><tab><tab>current_event = stream.current_event<tab><tab><tab>assert i == current_event.key<tab><tab><tab>assert value == i * 4<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>assert await channel_empty(stream.channel)",0,if i >= 99 :,if current_event . key == 0 :,0.027969854500399755,5.522397783539471,0.3333333333333333
"def print_messages(self):<tab>output_reports = self.config.get_output_report()<tab>for report in output_reports:<tab><tab>output_format, output_files = report<tab><tab>self.summary[""formatter""] = output_format<tab><tab>formatter = FORMATTERS[output_format](<tab><tab><tab>self.summary, self.messages, self.config.profile<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.write_to(formatter, sys.stdout)<tab><tab>for output_file in output_files:<tab><tab><tab>with open(output_file, ""w+"") as target:<tab><tab><tab><tab>self.write_to(formatter, target)",0,if not output_files :,if formatter is not None :,0.16590500542243855,10.682175159905853,0.2333333333333333
"def eval_metrics(self):<tab>for task in self.task_list:<tab><tab><IF-STMT><tab><tab><tab>return [<tab><tab><tab><tab>metrics.Metrics.ACC,<tab><tab><tab><tab>metrics.Metrics.NEG_LOG_PERPLEXITY,<tab><tab><tab><tab>metrics.Metrics.ROUGE_2_F,<tab><tab><tab><tab>metrics.Metrics.ROUGE_L_F,<tab><tab><tab>]<tab>return [<tab><tab>metrics.Metrics.ACC,<tab><tab>metrics.Metrics.NEG_LOG_PERPLEXITY,<tab>]",0,"if ""summarize"" in task . name :",if task . task_id == self . task_id :,0.03713496019763296,6.754312828675707,0.3181818181818182
"def _getBuildRequestForBrdict(self, brdict):<tab># Turn a brdict into a BuildRequest into a brdict. This is useful<tab># for API like 'nextBuild', which operate on BuildRequest objects.<tab>breq = self.breqCache.get(brdict[""buildrequestid""])<tab>if not breq:<tab><tab>breq = yield BuildRequest.fromBrdict(self.master, brdict)<tab><tab><IF-STMT><tab><tab><tab>self.breqCache[brdict[""buildrequestid""]] = breq<tab>defer.returnValue(breq)",1,if breq :,if breq :,0.5311706625951745,1e-10,1.0
"def _stash_splitter(states):<tab>keep, split = [], []<tab>if state_func is not None:<tab><tab>for s in states:<tab><tab><tab>ns = state_func(s)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>split.append(ns)<tab><tab><tab>elif isinstance(ns, (list, tuple, set)):<tab><tab><tab><tab>split.extend(ns)<tab><tab><tab>else:<tab><tab><tab><tab>split.append(s)<tab>if stash_func is not None:<tab><tab>split = stash_func(states)<tab>if to_stash is not stash:<tab><tab>keep = states<tab>return keep, split",0,"if isinstance ( ns , SimState ) :","if isinstance ( ns , str ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def sequence_to_text(sequence):<tab>""""""Converts a sequence of IDs back to a string""""""<tab>result = """"<tab>for symbol_id in sequence:<tab><tab><IF-STMT><tab><tab><tab>s = _id_to_symbol[symbol_id]<tab><tab><tab># Enclose ARPAbet back in curly braces:<tab><tab><tab>if len(s) > 1 and s[0] == ""@"":<tab><tab><tab><tab>s = ""{%s}"" % s[1:]<tab><tab><tab>result += s<tab>return result.replace(""}{"", "" "")",1,if symbol_id in _id_to_symbol :,if symbol_id in _id_to_symbol :,0.75,100.00000000000004,1.0
"def get_code(self, fullname=None):<tab>fullname = self._fix_name(fullname)<tab>if self.code is None:<tab><tab>mod_type = self.etc[2]<tab><tab><IF-STMT><tab><tab><tab>source = self.get_source(fullname)<tab><tab><tab>self.code = compile(source, self.filename, ""exec"")<tab><tab>elif mod_type == imp.PY_COMPILED:<tab><tab><tab>self._reopen()<tab><tab><tab>try:<tab><tab><tab><tab>self.code = read_code(self.file)<tab><tab><tab>finally:<tab><tab><tab><tab>self.file.close()<tab><tab>elif mod_type == imp.PKG_DIRECTORY:<tab><tab><tab>self.code = self._get_delegate().get_code()<tab>return self.code",0,if mod_type == imp . PY_SOURCE :,if mod_type == imp . PY_COMPILED :,0.574113272471593,82.651681837938,1.0
"def identwaf(self, findall=False):<tab>detected = list()<tab>try:<tab><tab>self.attackres = self.performCheck(self.centralAttack)<tab>except RequestBlocked:<tab><tab>return detected<tab>for wafvendor in self.checklist:<tab><tab>self.log.info(""Checking for %s"" % wafvendor)<tab><tab>if self.wafdetections[wafvendor](self):<tab><tab><tab>detected.append(wafvendor)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>self.knowledge[""wafname""] = detected<tab>return detected",1,if not findall :,if not findall :,0.75,100.00000000000004,1.0
"def SessionId(self):<tab>""""""Returns the Session ID of the process""""""<tab>if self.Session.is_valid():<tab><tab>process_space = self.get_process_address_space()<tab><tab><IF-STMT><tab><tab><tab>return obj.Object(<tab><tab><tab><tab>""_MM_SESSION_SPACE"", offset=self.Session, vm=process_space<tab><tab><tab>).SessionId<tab>return obj.NoneObject(""Cannot find process session"")",1,if process_space :,if process_space :,0.5311706625951745,1e-10,1.0
"def _convert_java_pattern_to_python(pattern):<tab>""""""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`.""""""<tab>s = list(pattern)<tab>i = 0<tab>while i < len(s) - 1:<tab><tab>c = s[i]<tab><tab>if c == ""$"" and s[i + 1] in ""0123456789"":<tab><tab><tab>s[i] = ""\\""<tab><tab><IF-STMT><tab><tab><tab>s[i] = """"<tab><tab><tab>i += 1<tab><tab>i += 1<tab>return pattern[:0].join(s)",0,"elif c == ""\\"" and s [ i + 1 ] == ""$"" :","elif c == ""\\"" and s [ i + 1 ] in ""0123456789"" :",0.6788682371737682,73.79570919166834,0.8666666666666667
"def __init__(self, coverage):<tab>self.coverage = coverage<tab>self.config = self.coverage.config<tab>self.source_paths = set()<tab>if self.config.source:<tab><tab>for src in self.config.source:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not self.config.relative_files:<tab><tab><tab><tab><tab>src = files.canonical_filename(src)<tab><tab><tab><tab>self.source_paths.add(src)<tab>self.packages = {}<tab>self.xml_out = None",0,if os . path . exists ( src ) :,"if src . endswith ( "".py"" ) :",0.030390516601639946,10.252286118120933,0.2619047619047619
"def populate_vol_format(self):<tab>rhel6_file_whitelist = [""raw"", ""qcow2"", ""qed""]<tab>model = self.widget(""vol-format"").get_model()<tab>model.clear()<tab>formats = self.vol_class.formats<tab>if hasattr(self.vol_class, ""create_formats""):<tab><tab>formats = getattr(self.vol_class, ""create_formats"")<tab>if self.vol_class == Storage.FileVolume and not self.conn.rhel6_defaults_caps():<tab><tab>newfmts = []<tab><tab>for f in rhel6_file_whitelist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>newfmts.append(f)<tab><tab>formats = newfmts<tab>for f in formats:<tab><tab>model.append([f, f])",0,if f in formats :,if f not in formats :,0.14710913164137962,37.99178428257963,0.4444444444444444
"def get_file_sources():<tab>global _file_sources<tab>if _file_sources is None:<tab><tab>from galaxy.files import ConfiguredFileSources<tab><tab>file_sources = None<tab><tab><IF-STMT><tab><tab><tab>file_sources_as_dict = None<tab><tab><tab>with open(""file_sources.json"", ""r"") as f:<tab><tab><tab><tab>file_sources_as_dict = json.load(f)<tab><tab><tab>if file_sources_as_dict is not None:<tab><tab><tab><tab>file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict)<tab><tab>if file_sources is None:<tab><tab><tab>ConfiguredFileSources.from_dict([])<tab><tab>_file_sources = file_sources<tab>return _file_sources",0,"if os . path . exists ( ""file_sources.json"" ) :","if os . path . isfile ( ""file_sources.json"" ) :",0.5803088707179008,81.53551038173119,0.6666666666666666
"def _blend(x, y):  # pylint: disable=invalid-name<tab>""""""Implements the ""blend"" strategy for `deep_merge`.""""""<tab>if isinstance(x, (dict, OrderedDict)):<tab><tab>if not isinstance(y, (dict, OrderedDict)):<tab><tab><tab>return y<tab><tab>return _merge(x, y, recursion_func=_blend)<tab>if isinstance(x, (list, tuple)):<tab><tab>if not isinstance(y, (list, tuple)):<tab><tab><tab>return y<tab><tab>result = [_blend(*i) for i in zip(x, y)]<tab><tab><IF-STMT><tab><tab><tab>result += x[len(y) :]<tab><tab>elif len(x) < len(y):<tab><tab><tab>result += y[len(x) :]<tab><tab>return result<tab>return y",0,if len ( x ) > len ( y ) :,if len ( x ) < len ( y ) :,0.8520019333126669,70.16879391277372,1.0
"def copy_dicts(dct):<tab>if ""_remote_data"" in dct:<tab><tab>dsindex = dct[""_remote_data""][""_content""].dsindex<tab><tab>newdct = dct.copy()<tab><tab>newdct[""_remote_data""] = {""_content"": dsindex}<tab><tab>return list(newdct.items())<tab>elif ""_data"" in dct:<tab><tab>newdct = dct.copy()<tab><tab>newdata = copy_dicts(dct[""_data""])<tab><tab><IF-STMT><tab><tab><tab>newdct[""_data""] = newdata<tab><tab>return list(newdct.items())<tab>return None",1,if newdata :,if newdata :,0.5311706625951745,1e-10,1.0
"def _import_epic_activity(self, project_data, taiga_epic, epic, options):<tab>offset = 0<tab>while True:<tab><tab>activities = self._client.get(<tab><tab><tab>""/projects/{}/epics/{}/activity"".format(<tab><tab><tab><tab>project_data[""id""],<tab><tab><tab><tab>epic[""id""],<tab><tab><tab>),<tab><tab><tab>{""envelope"": ""true"", ""limit"": 300, ""offset"": offset},<tab><tab>)<tab><tab>offset += 300<tab><tab>for activity in activities[""data""]:<tab><tab><tab>self._import_activity(taiga_epic, activity, options)<tab><tab><IF-STMT><tab><tab><tab>break",0,"if len ( activities [ ""data"" ] ) < 300 :","if not activities [ ""data"" ] :",0.13248888069121056,40.471107853347405,0.48888888888888893
"def __get__(self, instance, instance_type=None):<tab>if instance:<tab><tab><IF-STMT><tab><tab><tab>rel_obj = self.get_obj(instance)<tab><tab><tab>if rel_obj:<tab><tab><tab><tab>instance._obj_cache[self.att_name] = rel_obj<tab><tab>return instance._obj_cache.get(self.att_name)<tab>return self",1,if self . att_name not in instance . _obj_cache :,if self . att_name not in instance . _obj_cache :,0.75,100.00000000000004,1.0
"def download_main(<tab>download, download_playlist, urls, playlist, output_dir, merge, info_only):<tab>for url in urls:<tab><tab>if url.startswith(""https://""):<tab><tab><tab>url = url[8:]<tab><tab>if not url.startswith(""http://""):<tab><tab><tab>url = ""http://"" + url<tab><tab><IF-STMT><tab><tab><tab>download_playlist(<tab><tab><tab><tab>url, output_dir=output_dir, merge=merge, info_only=info_only<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>download(url, output_dir=output_dir, merge=merge, info_only=info_only)",1,if playlist :,if playlist :,0.5311706625951745,1e-10,1.0
"def _mksubs(self):<tab>self._subs = {}<tab>commit_dir = CommitDir(self, "".commit"")<tab>self._subs["".commit""] = commit_dir<tab>tag_dir = TagDir(self, "".tag"")<tab>self._subs["".tag""] = tag_dir<tab>for (name, sha) in git.list_refs():<tab><tab><IF-STMT><tab><tab><tab>name = name[11:]<tab><tab><tab>date = git.rev_get_date(sha.encode(""hex""))<tab><tab><tab>n1 = BranchList(self, name, sha)<tab><tab><tab>n1.ctime = n1.mtime = date<tab><tab><tab>self._subs[name] = n1",0,"if name . startswith ( ""refs/heads/"" ) :","if name . startswith ( ""HEAD"" ) :",0.5490406812970063,48.74858042804567,1.0
"def readAtOffset(self, offset, size, shortok=False):<tab>ret = b""""<tab>self.fd.seek(offset)<tab>while len(ret) != size:<tab><tab>rlen = size - len(ret)<tab><tab>x = self.fd.read(rlen)<tab><tab><IF-STMT><tab><tab><tab>if not shortok:<tab><tab><tab><tab>return None<tab><tab><tab>return ret<tab><tab>ret += x<tab>return ret",1,"if x == b"""" :","if x == b"""" :",0.75,100.00000000000004,1.0
"def remove_indent(self):<tab>""""""Remove one tab-width of blanks from the previous token.""""""<tab>w = abs(self.tab_width)<tab>if self.result:<tab><tab>s = self.result[-1]<tab><tab><IF-STMT><tab><tab><tab>self.result.pop()<tab><tab><tab>s = s.replace(""\t"", "" "" * w)<tab><tab><tab>if s.startswith(""\n""):<tab><tab><tab><tab>s2 = s[1:]<tab><tab><tab><tab>self.result.append(""\n"" + s2[:-w])<tab><tab><tab>else:<tab><tab><tab><tab>self.result.append(s[:-w])",0,if s . isspace ( ) :,"if s . startswith ( ""\t"" ) :",0.09981588323865592,18.36028134946796,0.6
"def flush(self, *args, **kwargs):<tab>with self._lock:<tab><tab>self._last_updated = time.time()<tab><tab>try:<tab><tab><tab>if kwargs.get(""in_place"", False):<tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>mailbox.mbox.flush(self, *args, **kwargs)<tab><tab>except OSError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab><tab>self._last_updated = time.time()",0,"if ""_create_temporary"" in traceback . format_exc ( ) :","if kwargs . get ( ""in_place"" , False ) :",0.030873964193229592,8.527902588160915,0.27472527472527475
"def _collect_manual_intervention_nodes(pipeline_tree):<tab>for act in pipeline_tree[""activities""].values():<tab><tab><IF-STMT><tab><tab><tab>_collect_manual_intervention_nodes(act[""pipeline""])<tab><tab>elif act[""component""][""code""] in MANUAL_INTERVENTION_COMP_CODES:<tab><tab><tab>manual_intervention_nodes.add(act[""id""])",0,"if act [ ""type"" ] == ""SubProcess"" :","if act [ ""type"" ] == ""pipeline"" :",0.605621305873661,79.10665071754353,1.0
"def banned():<tab>if request.endpoint == ""views.themes"":<tab><tab>return<tab>if authed():<tab><tab>user = get_current_user_attrs()<tab><tab>team = get_current_team_attrs()<tab><tab><IF-STMT><tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"", error=""You have been banned from this CTF""<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)<tab><tab>if team and team.banned:<tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"",<tab><tab><tab><tab><tab>error=""Your team has been banned from this CTF"",<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)",1,if user and user . banned :,if user and user . banned :,0.75,100.00000000000004,1.0
"def remove(self, values):<tab>if not isinstance(values, (list, tuple, set)):<tab><tab>values = [values]<tab>for v in values:<tab><tab>v = str(v)<tab><tab>if isinstance(self._definition, dict):<tab><tab><tab>self._definition.pop(v, None)<tab><tab>elif self._definition == ""ANY"":<tab><tab><tab>if v == ""ANY"":<tab><tab><tab><tab>self._definition = []<tab><tab><IF-STMT><tab><tab><tab>self._definition.remove(v)<tab>if (<tab><tab>self._value is not None<tab><tab>and self._value not in self._definition<tab><tab>and self._not_any()<tab>):<tab><tab>raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",1,elif v in self . _definition :,elif v in self . _definition :,0.75,100.00000000000004,1.0
"def save(self, learner, file_name):<tab>""""""Save the model to location specified in file_name.""""""<tab>with open(file_name, ""wb"") as f:<tab><tab><IF-STMT><tab><tab><tab># don't store the large inference cache!<tab><tab><tab>learner.inference_cache_, tmp = (None, learner.inference_cache_)<tab><tab><tab>pickle.dump(learner, f, -1)<tab><tab><tab>learner.inference_cache_ = tmp<tab><tab>else:<tab><tab><tab>pickle.dump(learner, f, -1)",0,"if hasattr ( learner , ""inference_cache_"" ) :",if learner . inference_cache_ is not None :,0.019345087832959386,22.499268274284365,0.25
"def __init__(self, exprs, savelist=False):<tab>super(ParseExpression, self).__init__(savelist)<tab>if isinstance(exprs, _generatorType):<tab><tab>exprs = list(exprs)<tab>if isinstance(exprs, basestring):<tab><tab>self.exprs = [ParserElement._literalStringClass(exprs)]<tab>elif isinstance(exprs, collections.Iterable):<tab><tab>exprs = list(exprs)<tab><tab># if sequence of strings provided, wrap with Literal<tab><tab><IF-STMT><tab><tab><tab>exprs = map(ParserElement._literalStringClass, exprs)<tab><tab>self.exprs = list(exprs)<tab>else:<tab><tab>try:<tab><tab><tab>self.exprs = list(exprs)<tab><tab>except TypeError:<tab><tab><tab>self.exprs = [exprs]<tab>self.callPreparse = False",0,"if all ( isinstance ( expr , basestring ) for expr in exprs ) :","if isinstance ( exprs , ( list , tuple ) ) :",0.024071764561394246,9.136248401161414,0.1590909090909091
"def find(self, back=False):<tab>flags = 0<tab><IF-STMT><tab><tab>flags = QTextDocument.FindBackward<tab>if self.csBox.isChecked():<tab><tab>flags = flags | QTextDocument.FindCaseSensitively<tab>text = self.searchEdit.text()<tab>if not self.findMain(text, flags):<tab><tab>if text in self.editBoxes[self.ind].toPlainText():<tab><tab><tab>cursor = self.editBoxes[self.ind].textCursor()<tab><tab><tab>if back:<tab><tab><tab><tab>cursor.movePosition(QTextCursor.End)<tab><tab><tab>else:<tab><tab><tab><tab>cursor.movePosition(QTextCursor.Start)<tab><tab><tab>self.editBoxes[self.ind].setTextCursor(cursor)<tab><tab><tab>self.findMain(text, flags)",1,if back :,if back :,0.5311706625951745,1e-10,1.0
"def _load_storage(self):<tab>self._storage = {}<tab>for row in self(""SELECT object, resource, amount FROM storage""):<tab><tab>ownerid = int(row[0])<tab><tab><IF-STMT><tab><tab><tab>self._storage[ownerid].append(row[1:])<tab><tab>else:<tab><tab><tab>self._storage[ownerid] = [row[1:]]",1,if ownerid in self . _storage :,if ownerid in self . _storage :,0.75,100.00000000000004,1.0
"def parse_chunked(self, unreader):<tab>(size, rest) = self.parse_chunk_size(unreader)<tab>while size > 0:<tab><tab>while size > len(rest):<tab><tab><tab>size -= len(rest)<tab><tab><tab>yield rest<tab><tab><tab>rest = unreader.read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise NoMoreData()<tab><tab>yield rest[:size]<tab><tab># Remove \r\n after chunk<tab><tab>rest = rest[size:]<tab><tab>while len(rest) < 2:<tab><tab><tab>rest += unreader.read()<tab><tab>if rest[:2] != b""\r\n"":<tab><tab><tab>raise ChunkMissingTerminator(rest[:2])<tab><tab>(size, rest) = self.parse_chunk_size(unreader, data=rest[2:])",0,if not rest :,if size == 0 :,0.04240785919217091,9.652434877402245,0.3333333333333333
"def _augment_batch_(self, batch, random_state, parents, hooks):<tab>for column in batch.columns:<tab><tab><IF-STMT><tab><tab><tab>for i, cbaoi in enumerate(column.value):<tab><tab><tab><tab>column.value[i] = cbaoi.clip_out_of_image_()<tab>return batch",0,"if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :","if isinstance ( column . value , ( list , tuple ) ) :",0.01910332507787709,2.953456226863489,0.2111111111111111
"def to_nim(self):<tab>if self.is_pointer == 2:<tab><tab>s = ""cstringArray"" if self.type == ""GLchar"" else ""ptr pointer""<tab>else:<tab><tab>s = self.type<tab><tab><IF-STMT><tab><tab><tab>default = ""ptr "" + s<tab><tab><tab>s = self.NIM_POINTER_MAP.get(s, default)<tab>return s",0,if self . is_pointer == 1 :,if s in self . NIM_POINTER_MAP :,0.04282569298264552,9.425159511373677,0.30952380952380953
"def find(self, path):<tab>if os.path.isfile(path) or os.path.islink(path):<tab><tab>self.num_files = self.num_files + 1<tab><tab>if self.match_function(path):<tab><tab><tab>self.files.append(path)<tab>elif os.path.isdir(path):<tab><tab>for content in os.listdir(path):<tab><tab><tab>file = os.path.join(path, content)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.num_files = self.num_files + 1<tab><tab><tab><tab>if self.match_function(file):<tab><tab><tab><tab><tab>self.files.append(file)<tab><tab><tab>else:<tab><tab><tab><tab>self.find(file)",1,if os . path . isfile ( file ) or os . path . islink ( file ) :,if os . path . isfile ( file ) or os . path . islink ( file ) :,1.0,100.00000000000004,1.0
"def remove(self, event):<tab>try:<tab><tab>self._events_current_sweep.remove(event)<tab><tab><IF-STMT><tab><tab><tab>assert event.in_sweep == True<tab><tab><tab>assert event.other.in_sweep == True<tab><tab><tab>event.in_sweep = False<tab><tab><tab>event.other.in_sweep = False<tab><tab>return True<tab>except KeyError:<tab><tab>if USE_DEBUG:<tab><tab><tab>assert event.in_sweep == False<tab><tab><tab>assert event.other.in_sweep == False<tab><tab>return False",1,if USE_DEBUG :,if USE_DEBUG :,0.5311706625951745,1e-10,1.0
"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab>if attrname.startswith(""__""):<tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab>if attrvalue == 0:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab>elif hasattr(self.metadata, attrname):<tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass",0,"if attrname == ""salt_version"" :","if attrname == ""version"" :",0.39477865547525276,53.849523560640876,1.0
"def _init_auxiliary_head(self, auxiliary_head):<tab>""""""Initialize ``auxiliary_head``""""""<tab>if auxiliary_head is not None:<tab><tab><IF-STMT><tab><tab><tab>self.auxiliary_head = nn.ModuleList()<tab><tab><tab>for head_cfg in auxiliary_head:<tab><tab><tab><tab>self.auxiliary_head.append(builder.build_head(head_cfg))<tab><tab>else:<tab><tab><tab>self.auxiliary_head = builder.build_head(auxiliary_head)",0,"if isinstance ( auxiliary_head , list ) :","if isinstance ( auxiliary_head , nn . ModuleList ) :",0.2633400423728968,57.067457770559976,0.4871794871794872
"def _str_param_list(self, name):<tab>out = []<tab>if self[name]:<tab><tab>out += self._str_header(name)<tab><tab>for param in self[name]:<tab><tab><tab>parts = []<tab><tab><tab>if param.name:<tab><tab><tab><tab>parts.append(param.name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts.append(param.type)<tab><tab><tab>out += ["" : "".join(parts)]<tab><tab><tab>if param.desc and """".join(param.desc).strip():<tab><tab><tab><tab>out += self._str_indent(param.desc)<tab><tab>out += [""""]<tab>return out",1,if param . type :,if param . type :,0.75,100.00000000000004,1.0
"def _set_handler(<tab>self, name, handle=None, obj=None, constructor_args=(), constructor_kwds={}):<tab>if handle is None:<tab><tab>handle = obj is not None<tab>if handle:<tab><tab>handler_class = self.handler_classes[name]<tab><tab><IF-STMT><tab><tab><tab>newhandler = handler_class(obj)<tab><tab>else:<tab><tab><tab>newhandler = handler_class(*constructor_args, **constructor_kwds)<tab>else:<tab><tab>newhandler = None<tab>self._replace_handler(name, newhandler)",1,if obj is not None :,if obj is not None :,0.75,100.00000000000004,1.0
"def _extract_subtitles(src):<tab>subtitles = {}<tab>for caption in try_get(src, lambda x: x[""captions""], list) or []:<tab><tab>subtitle_url = url_or_none(caption.get(""uri""))<tab><tab><IF-STMT><tab><tab><tab>lang = caption.get(""language"", ""deu"")<tab><tab><tab>subtitles.setdefault(lang, []).append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""url"": subtitle_url,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>return subtitles",1,if subtitle_url :,if subtitle_url :,0.5311706625951745,1e-10,1.0
"def get_keys(struct, ignore_first_level=False):<tab>res = []<tab>if isinstance(struct, dict):<tab><tab><IF-STMT><tab><tab><tab>keys = [x.split(""("")[0] for x in struct.keys()]<tab><tab><tab>res.extend(keys)<tab><tab>for key in struct:<tab><tab><tab>if key in IGNORED_KEYS:<tab><tab><tab><tab>logging.debug(""Ignored: %s: %s"", key, struct[key])<tab><tab><tab><tab>continue<tab><tab><tab>res.extend(get_keys(struct[key], key in IGNORED_FIRST_LEVEL))<tab>elif isinstance(struct, list):<tab><tab>for item in struct:<tab><tab><tab>res.extend(get_keys(item))<tab>return res",0,if not ignore_first_level :,if ignore_first_level :,0.09648852821835877,1e-10,0.6
"def create_dir(path):<tab>curr_path = None<tab>for p in path:<tab><tab>if curr_path is None:<tab><tab><tab>curr_path = os.path.abspath(p)<tab><tab>else:<tab><tab><tab>curr_path = os.path.join(curr_path, p)<tab><tab><IF-STMT><tab><tab><tab>os.mkdir(curr_path)",1,if not os . path . exists ( curr_path ) :,if not os . path . exists ( curr_path ) :,0.75,100.00000000000004,1.0
"def dataToDumpFile(dumpFile, data):<tab>try:<tab><tab>dumpFile.write(data)<tab><tab>dumpFile.flush()<tab>except IOError as ex:<tab><tab>if ""No space left"" in getUnicode(ex):<tab><tab><tab>errMsg = ""no space left on output device""<tab><tab><tab>logger.error(errMsg)<tab><tab><IF-STMT><tab><tab><tab>errMsg = ""permission denied when flushing dump data""<tab><tab><tab>logger.error(errMsg)<tab><tab>else:<tab><tab><tab>errMsg = (<tab><tab><tab><tab>""error occurred when writing dump data to file ('%s')"" % getUnicode(ex)<tab><tab><tab>)<tab><tab><tab>logger.error(errMsg)",0,"elif ""Permission denied"" in getUnicode ( ex ) :","elif ""permission denied"" in getUnicode ( ex ) :",0.6253119268751697,74.19446627365011,1.0
"def elements(self, top):<tab>res = []<tab># try:<tab>#<tab> string = ""== %s (%s)"" % (self.name,self.__class__)<tab># except AttributeError:<tab>#<tab> string = ""== (%s)"" % (self.__class__,)<tab># print(string)<tab>for part in self.parts:<tab><tab><IF-STMT><tab><tab><tab>res.append(name_or_ref(part, top))<tab><tab>else:<tab><tab><tab>if isinstance(part, Extension):<tab><tab><tab><tab>res.append(part.base)<tab><tab><tab>res.extend(part.elements(top))<tab>return res",0,"if isinstance ( part , Element ) :","if isinstance ( part , Name ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def _parse_param_value(name, datatype, default):<tab>if datatype == ""bool"":<tab><tab>if default.lower() == ""true"":<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>_s = ""{}: Invalid default value '{}' for bool parameter {}""<tab><tab><tab>raise SyntaxError(_s.format(self.name, default, p))<tab>elif datatype == ""int"":<tab><tab>if type(default) == int:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return int(default, 0)<tab>elif datatype == ""real"":<tab><tab>if type(default) == float:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return float(default)<tab>else:<tab><tab>return str(default)",1,"elif default . lower ( ) == ""false"" :","elif default . lower ( ) == ""false"" :",0.75,100.00000000000004,1.0
"def dvmethod(c, dx, doAST=False):<tab>for m in c.get_methods():<tab><tab>mx = dx.get_method(m)<tab><tab>ms = DvMethod(mx)<tab><tab>ms.process(doAST=doAST)<tab><tab><IF-STMT><tab><tab><tab>assert ms.get_ast() is not None<tab><tab><tab>assert isinstance(ms.get_ast(), dict)<tab><tab><tab>assert ""body"" in ms.get_ast()<tab><tab>else:<tab><tab><tab>assert ms.get_source() is not None",1,if doAST :,if doAST :,0.5311706625951745,1e-10,1.0
"def _repr_pretty_(self, p, cycle):<tab>if cycle:<tab><tab>return ""{{...}""<tab>with p.group(2, ""{"", ""}""):<tab><tab>p.breakable("""")<tab><tab>for idx, key in enumerate(self._items):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p.text("","")<tab><tab><tab><tab>p.breakable()<tab><tab><tab>value = self._items[key]<tab><tab><tab>p.pretty(key)<tab><tab><tab>p.text("": "")<tab><tab><tab>if isinstance(value, bytes):<tab><tab><tab><tab>value = trimmed_repr(value)<tab><tab><tab>p.pretty(value)<tab><tab>p.breakable("""")",0,if idx :,if idx > 0 :,0.09791453445388575,1e-10,0.7
"def remove_rating(self, songs, librarian):<tab>count = len(songs)<tab>if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""):<tab><tab>parent = qltk.get_menu_item_top_parent(self)<tab><tab>dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None)<tab><tab><IF-STMT><tab><tab><tab>return<tab>reset = []<tab>for song in songs:<tab><tab>if ""~#rating"" in song:<tab><tab><tab>del song[""~#rating""]<tab><tab><tab>reset.append(song)<tab>librarian.changed(reset)",0,if dialog . run ( ) != Gtk . ResponseType . YES :,if not dialog . is_valid ( ) :,0.025961669659690878,8.804351806809393,0.22794117647058823
"def get_or_create_place(self, place_name):<tab>""Return the requested place object tuple-packed with a new indicator.""<tab>LOG.debug(""get_or_create_place: looking for: %s"", place_name)<tab>for place_handle in self.db.iter_place_handles():<tab><tab>place = self.db.get_place_from_handle(place_handle)<tab><tab>place_title = place_displayer.display(self.db, place)<tab><tab><IF-STMT><tab><tab><tab>return (0, place)<tab>place = Place()<tab>place.set_title(place_name)<tab>place.name = PlaceName(value=place_name)<tab>self.db.add_place(place, self.trans)<tab>return (1, place)",0,if place_title == place_name :,if place_title is None :,0.06497877230811641,28.319415510892387,0.41666666666666663
def _skip_trivial(constraint_data):<tab>if skip_trivial_constraints:<tab><tab><IF-STMT><tab><tab><tab>if constraint_data.variables is None:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>if constraint_data.body.polynomial_degree() == 0:<tab><tab><tab><tab>return True<tab>return False,0,"if isinstance ( constraint_data , LinearCanonicalRepn ) :","if hasattr ( constraint_data , ""body"" ) :",0.09166808520089226,37.70063804549471,0.38181818181818183
"def get_other(self, data, items):<tab>is_tuple = False<tab>if type(data) == tuple:<tab><tab>data = list(data)<tab><tab>is_tuple = True<tab>if type(data) == list:<tab><tab>m_items = items.copy()<tab><tab>for idx, item in enumerate(items):<tab><tab><tab>if item < 0:<tab><tab><tab><tab>m_items[idx] = len(data) - abs(item)<tab><tab>for i in sorted(set(m_items), reverse=True):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del data[i]<tab><tab>if is_tuple:<tab><tab><tab>return tuple(data)<tab><tab>else:<tab><tab><tab>return data<tab>else:<tab><tab>return None",0,if i < len ( data ) and i > - 1 :,if data [ i ] == item :,0.011365275735938669,4.32319463004898,0.225
"def test_case_insensitivity(self):<tab>with support.EnvironmentVarGuard() as env:<tab><tab>env.set(""PYTHONCASEOK"", ""1"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""os.environ changes not reflected in "" ""_os.environ"")<tab><tab>loader = self.find_module()<tab><tab>self.assertTrue(hasattr(loader, ""load_module""))",0,"if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :","if ""PYTHONCASEOK"" not in _os . environ :",0.27388083064980157,56.535241047007,1.0
def field_spec(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.field_spec_ is None:<tab><tab><tab><tab>self.field_spec_ = FieldSpec()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.field_spec_,1,if self . field_spec_ is None :,if self . field_spec_ is None :,0.75,100.00000000000004,1.0
"def reduce(self, f, init):<tab>for x in range(self._idx, rt.count(self._w_array)):<tab><tab><IF-STMT><tab><tab><tab>return rt.deref(init)<tab><tab>init = f.invoke([init, rt.nth(self._w_array, rt.wrap(x))])<tab>return init",1,if rt . reduced_QMARK_ ( init ) :,if rt . reduced_QMARK_ ( init ) :,0.75,100.00000000000004,1.0
"def _find(event: E) -> None:<tab># We first check values after the selected value, then all values.<tab>values = list(self.values)<tab>for value in values[self._selected_index + 1 :] + values:<tab><tab>text = fragment_list_to_text(to_formatted_text(value[1])).lower()<tab><tab><IF-STMT><tab><tab><tab>self._selected_index = self.values.index(value)<tab><tab><tab>return",0,if text . startswith ( event . data . lower ( ) ) :,if text in self . values :,0.0176691247947516,5.746166391236874,0.29411764705882354
"def check_permissions():<tab>if platform_os() != ""Windows"":<tab><tab><IF-STMT><tab><tab><tab>print(localization.lang_check_permissions[""permissions_granted""])<tab><tab>else:<tab><tab><tab>print(localization.lang_check_permissions[""permissions_denied""])<tab><tab><tab>exit()<tab>else:<tab><tab>print(localization.lang_check_permissions[""windows_warning""])<tab><tab>exit()",0,if getuid ( ) == 0 :,"if platform_os ( ) == ""Windows"" :",0.1944789340715307,23.462350320527996,0.45
"def _ProcessName(self, name, dependencies):<tab>""""""Retrieve a module name from a node name.""""""<tab>module_name, dot, base_name = name.rpartition(""."")<tab>if dot:<tab><tab>if module_name:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dependencies[module_name].add(base_name)<tab><tab><tab>else:<tab><tab><tab><tab>dependencies[module_name] = {base_name}<tab><tab>else:<tab><tab><tab># If we have a relative import that did not get qualified (usually due<tab><tab><tab># to an empty package_name), don't insert module_name='' into the<tab><tab><tab># dependencies; we get a better error message if we filter it out here<tab><tab><tab># and fail later on.<tab><tab><tab>logging.warning(""Empty package name: %s"", name)",1,if module_name in dependencies :,if module_name in dependencies :,0.75,100.00000000000004,1.0
"def _load_db(self):<tab>try:<tab><tab>with open(self.db) as db:<tab><tab><tab>content = db.read(8)<tab><tab><tab>db.seek(0)<tab><tab><tab>if content == (""Salted__""):<tab><tab><tab><tab>data = StringIO()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.encryptor.decrypt(db, data)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise EncryptionError(<tab><tab><tab><tab><tab><tab>""Encrpyted credential storage: {}"".format(self.db)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>return json.loads(data.getvalue())<tab><tab><tab>else:<tab><tab><tab><tab>return json.load(db)<tab>except:<tab><tab>return {""creds"": []}",1,if self . encryptor :,if self . encryptor :,0.75,100.00000000000004,1.0
"def _parse(self, stream, context):<tab>obj = []<tab>try:<tab><tab>context_for_subcon = context<tab><tab>if self.subcon.conflags & self.FLAG_COPY_CONTEXT:<tab><tab><tab>context_for_subcon = context.__copy__()<tab><tab>while True:<tab><tab><tab>subobj = self.subcon._parse(stream, context_for_subcon)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>obj.append(subobj)<tab>except ConstructError as ex:<tab><tab>raise ArrayError(""missing terminator"", ex)<tab>return obj",0,"if self . predicate ( subobj , context ) :",if subobj is None :,0.014393212535568477,5.171845311465849,0.23863636363636365
"def is_active_for_user(self, user):<tab>is_active = super(AbstractUserFlag, self).is_active_for_user(user)<tab>if is_active:<tab><tab>return is_active<tab>user_ids = self._get_user_ids()<tab>if hasattr(user, ""pk"") and user.pk in user_ids:<tab><tab>return True<tab>if hasattr(user, ""groups""):<tab><tab>group_ids = self._get_group_ids()<tab><tab>if group_ids:<tab><tab><tab>user_groups = set(user.groups.all().values_list(""pk"", flat=True))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return None",0,if group_ids . intersection ( user_groups ) :,if user_groups and user_groups . intersection ( user_ids ) :,0.2707754333023606,34.46073377034663,0.48333333333333334
"def lookup_member(self, member_name):<tab>document_choices = self.choices or []<tab>for document_choice in document_choices:<tab><tab>doc_and_subclasses = [document_choice] + document_choice.__subclasses__()<tab><tab>for doc_type in doc_and_subclasses:<tab><tab><tab>field = doc_type._fields.get(member_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return field",0,if field :,if field is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def apply(self, db, person):<tab>families = person.get_parent_family_handle_list()<tab>if families == []:<tab><tab>return True<tab>for family_handle in person.get_parent_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>father_handle = family.get_father_handle()<tab><tab><tab>mother_handle = family.get_mother_handle()<tab><tab><tab>if not father_handle:<tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,if not mother_handle :,if not mother_handle and father_handle == families [ - 1 ] :,0.12946863245302795,22.407508680204355,0.4705882352941176
"def init_weights(self):<tab>for m in self.modules():<tab><tab>if isinstance(m, nn.Linear):<tab><tab><tab>normal_init(m, std=0.01)<tab><tab>if isinstance(m, nn.Conv3d):<tab><tab><tab>xavier_init(m, distribution=""uniform"")<tab><tab><IF-STMT><tab><tab><tab>constant_init(m, 1)",1,"if isinstance ( m , nn . BatchNorm3d ) :","if isinstance ( m , nn . BatchNorm3d ) :",0.75,100.00000000000004,1.0
"def _update_learning_params(self):<tab>model = self.model<tab>hparams = self.hparams<tab>fd = self.runner.feed_dict<tab>step_num = self.step_num<tab>if hparams.model_type == ""resnet_tf"":<tab><tab><IF-STMT><tab><tab><tab>lrn_rate = hparams.mom_lrn<tab><tab>elif step_num < 30000:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 10<tab><tab>elif step_num < 35000:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 100<tab><tab>else:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 1000<tab><tab>fd[model.lrn_rate] = lrn_rate",0,if step_num < hparams . lrn_step :,if step_num < 20000 :,0.09453229110448028,36.337289265247364,0.5
"def token_producer(source):<tab>token = source.read_uint8()<tab>while token is not None:<tab><tab>if is_push_data_token(token):<tab><tab><tab>yield DataToken(read_data(token, source))<tab><tab><IF-STMT><tab><tab><tab>yield SmallIntegerToken(read_small_integer(token))<tab><tab>else:<tab><tab><tab>yield Token(token)<tab><tab>token = source.read_uint8()",0,elif is_small_integer ( token ) :,elif is_push_small_integer_token ( token ) :,0.5186424829558856,42.718025135819786,1.0
"def user_info(oicsrv, userdb, sub, client_id="""", user_info_claims=None):<tab>identity = userdb[sub]<tab>if user_info_claims:<tab><tab>result = {}<tab><tab>for key, restr in user_info_claims[""claims""].items():<tab><tab><tab>try:<tab><tab><tab><tab>result[key] = identity[key]<tab><tab><tab>except KeyError:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise Exception(""Missing property '%s'"" % key)<tab>else:<tab><tab>result = identity<tab>return OpenIDSchema(**result)",0,"if restr == { ""essential"" : True } :",if restr is None :,0.029942750698461862,5.830425236335824,0.48484848484848486
"def _helpSlot(self, *args):<tab>help_text = ""Filters are applied to packets in both direction.\n\n""<tab>filter_nb = 0<tab>for filter in self._filters:<tab><tab>help_text += ""{}: {}"".format(filter[""name""], filter[""description""])<tab><tab>filter_nb += 1<tab><tab><IF-STMT><tab><tab><tab>help_text += ""\n\n""<tab>QtWidgets.QMessageBox.information(self, ""Help for filters"", help_text)",0,if len ( self . _filters ) != filter_nb :,if filter_nb % 100 == 0 :,0.014969815225505462,12.451233733093902,0.3333333333333333
"def find_user_theme(self, name: str) -> Theme:<tab>""""""Find a theme named as *name* from latex_theme_path.""""""<tab>for theme_path in self.theme_paths:<tab><tab>config_path = path.join(theme_path, name, ""theme.conf"")<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return UserTheme(name, config_path)<tab><tab><tab>except ThemeError as exc:<tab><tab><tab><tab>logger.warning(exc)<tab>return None",0,if path . isfile ( config_path ) :,if path . exists ( config_path ) :,0.5014622369176811,65.80370064762461,0.6
"def decompress(self, value):<tab>if value:<tab><tab><IF-STMT><tab><tab><tab>if value.country_code and value.national_number:<tab><tab><tab><tab>return [<tab><tab><tab><tab><tab>""+%d"" % value.country_code,<tab><tab><tab><tab><tab>national_significant_number(value),<tab><tab><tab><tab>]<tab><tab>else:<tab><tab><tab>return value.split(""."")<tab>return [None, """"]",0,if type ( value ) == PhoneNumber :,"if ""."" in value :",0.019907917998500824,6.495032985064742,0.48148148148148145
"def update_prevdoc_status(self, flag):<tab>for quotation in list(set([d.prevdoc_docname for d in self.get(""items"")])):<tab><tab><IF-STMT><tab><tab><tab>doc = frappe.get_doc(""Quotation"", quotation)<tab><tab><tab>if doc.docstatus == 2:<tab><tab><tab><tab>frappe.throw(_(""Quotation {0} is cancelled"").format(quotation))<tab><tab><tab>doc.set_status(update=True)<tab><tab><tab>doc.update_opportunity()",0,if quotation :,if flag :,0.3197504490129165,1e-10,0.5
"def map(item):<tab>if item.deleted:<tab><tab>return<tab>exploration = exp_fetchers.get_exploration_from_model(item)<tab>for state_name, state in exploration.states.items():<tab><tab>hints_length = len(state.interaction.hints)<tab><tab><IF-STMT><tab><tab><tab>exp_and_state_key = ""%s %s"" % (item.id, state_name.encode(""utf-8""))<tab><tab><tab>yield (python_utils.UNICODE(hints_length), exp_and_state_key)",1,if hints_length > 0 :,if hints_length > 0 :,0.75,100.00000000000004,1.0
"def _selected_machines(self, virtual_machines):<tab>selected_machines = []<tab>for machine in virtual_machines:<tab><tab>if self._args.host and self._args.host == machine.name:<tab><tab><tab>selected_machines.append(machine)<tab><tab><IF-STMT><tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.locations and machine.location in self.locations:<tab><tab><tab>selected_machines.append(machine)<tab>return selected_machines",0,"if self . tags and self . _tags_match ( machine . tags , self . tags ) :",if self . _args . port and self . _args . port == machine . port :,0.3050525499555605,19.74796996024034,0.5353383458646617
"def _ripple_trim_compositors_move(self, delta):<tab>comp_ids = self.multi_data.moved_compositors_destroy_ids<tab>tracks_compositors = _get_tracks_compositors_list()<tab>track_moved = self.multi_data.track_affected<tab>for i in range(1, len(current_sequence().tracks) - 1):<tab><tab>if not track_moved[i - 1]:<tab><tab><tab>continue<tab><tab>track_comps = tracks_compositors[i - 1]<tab><tab>for comp in track_comps:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>comp.move(delta)",0,if comp . destroy_id in comp_ids :,if comp . id in comp_ids :,0.3884893899276739,59.86908497649472,0.5714285714285714
"def stream_docker_log(log_stream):<tab>async for line in log_stream:<tab><tab>if ""stream"" in line and line[""stream""].strip():<tab><tab><tab>logger.debug(line[""stream""].strip())<tab><tab><IF-STMT><tab><tab><tab>logger.debug(line[""status""].strip())<tab><tab>elif ""error"" in line:<tab><tab><tab>logger.error(line[""error""].strip())<tab><tab><tab>raise DockerBuildError",0,"elif ""status"" in line :","elif ""status"" in line and line [ ""status"" ] . strip ( ) :",0.2237724894149746,27.499775953224148,0.5847953216374269
"def create_keyfile(self, keyfile, size=64, force=False):<tab>if force or not os.path.exists(keyfile):<tab><tab>keypath = os.path.dirname(keyfile)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(keypath)<tab><tab>subprocess.run(<tab><tab><tab>[""dd"", ""if=/dev/random"", f""of={keyfile}"", f""bs={size}"", ""count=1""],<tab><tab><tab>check=True,<tab><tab><tab>stdout=subprocess.DEVNULL,<tab><tab><tab>stderr=subprocess.DEVNULL,<tab><tab>)",0,if not os . path . exists ( keypath ) :,if not os . path . exists ( keyfile ) :,0.6221967289603358,74.19446627365011,0.75
"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab>if self.op == ""+"":<tab><tab><tab>self.current += num<tab><tab>elif self.op == ""-"":<tab><tab><tab>self.current -= num<tab><tab><IF-STMT><tab><tab><tab>self.current *= num<tab><tab>elif self.op == ""/"":<tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res",1,"elif self . op == ""*"" :","elif self . op == ""*"" :",1.0,100.00000000000004,1.0
"def chop(expr, delta=10.0 ** (-10.0)):<tab>if isinstance(expr, Real):<tab><tab>if -delta < expr.get_float_value() < delta:<tab><tab><tab>return Integer(0)<tab>elif isinstance(expr, Complex) and expr.is_inexact():<tab><tab>real, imag = expr.real, expr.imag<tab><tab><IF-STMT><tab><tab><tab>real = Integer(0)<tab><tab>if -delta < imag.get_float_value() < delta:<tab><tab><tab>imag = Integer(0)<tab><tab>return Complex(real, imag)<tab>elif isinstance(expr, Expression):<tab><tab>return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves])<tab>return expr",1,if - delta < real . get_float_value ( ) < delta :,if - delta < real . get_float_value ( ) < delta :,1.0,100.00000000000004,1.0
"def get_file_sources():<tab>global _file_sources<tab>if _file_sources is None:<tab><tab>from galaxy.files import ConfiguredFileSources<tab><tab>file_sources = None<tab><tab>if os.path.exists(""file_sources.json""):<tab><tab><tab>file_sources_as_dict = None<tab><tab><tab>with open(""file_sources.json"", ""r"") as f:<tab><tab><tab><tab>file_sources_as_dict = json.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_sources = ConfiguredFileSources.from_dict(file_sources_as_dict)<tab><tab>if file_sources is None:<tab><tab><tab>ConfiguredFileSources.from_dict([])<tab><tab>_file_sources = file_sources<tab>return _file_sources",1,if file_sources_as_dict is not None :,if file_sources_as_dict is not None :,0.75,100.00000000000004,1.0
"def _get_sort_map(tags):<tab>""""""See TAG_TO_SORT""""""<tab>tts = {}<tab>for name, tag in tags.items():<tab><tab><IF-STMT><tab><tab><tab>if tag.user:<tab><tab><tab><tab>tts[name] = ""%ssort"" % name<tab><tab><tab>if tag.internal:<tab><tab><tab><tab>tts[""~%s"" % name] = ""~%ssort"" % name<tab>return tts",0,if tag . has_sort :,"if name . startswith ( ""sort_"" ) :",0.028001459970687266,5.604233375480572,0.38181818181818183
"def __init__(self, **kwargs):<tab>if self.name is None:<tab><tab>raise RuntimeError(""RenderPrimitive cannot be used directly"")<tab>self.option_values = {}<tab>for key, val in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""primitive `{0}' has no option `{1}'"".format(self.name, key)<tab><tab><tab>)<tab><tab>self.option_values[key] = val<tab># set up defaults<tab>for name, (description, default) in self.options.items():<tab><tab>if not name in self.option_values:<tab><tab><tab>self.option_values[name] = default",0,if not key in self . options :,if key not in self . options :,0.5407153684841097,58.14307369682194,0.7142857142857143
"def modify_bottle_params(self, output_stride=None):<tab>if output_stride is not None and output_stride % 2 != 0:<tab><tab>raise Exception(""output stride must to be even number"")<tab>if output_stride is None:<tab><tab>return<tab>else:<tab><tab>stride = 2<tab><tab>for i, _cfg in enumerate(self.cfg):<tab><tab><tab>stride = stride * _cfg[-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>s = 1<tab><tab><tab><tab>self.cfg[i][-1] = s",1,if stride > output_stride :,if stride > output_stride :,0.75,100.00000000000004,1.0
"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab>if len(q) == 1:<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.append(value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab>if not is_iterable(value):<tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",0,elif is_iterable ( value ) :,"elif isinstance ( value , list ) :",0.15423386776768006,16.515821590069027,0.36
"def make_shares(self, plaintext):<tab>share_arrays = []<tab>for i, p in enumerate(plaintext):<tab><tab>share_array = self.make_byte_shares(p)<tab><tab>for sa in share_array:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>share_arrays.append(array.array(""H""))<tab><tab><tab>current_share_array = sa<tab><tab><tab>current_share_array.append(sa)<tab>return share_arrays",0,if i == 0 :,if sa not in current_share_array :,0.030286782520570012,4.990049701936832,0.2571428571428572
"def populate(self, item):<tab># log.message('populate: %s', item)<tab>path = self.getItemPath(item)<tab># log.message('populate: path=%s', path)<tab>value = self.getValue(path)<tab>for name in sorted(value.__dict__.keys()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>child = getattr(value, name, None)<tab><tab>if hasattr(child, ""__dict__""):<tab><tab><tab>item.addChild(name, True)<tab><tab>else:<tab><tab><tab>item.addChild(name, False)",0,"if name [ : 2 ] == ""__"" and name [ - 2 : ] == ""__"" :","if name . startswith ( ""_"" ) :",0.012085357945655795,2.9347210312237455,0.4259259259259259
"def __repr__(self):<tab>try:<tab><tab>if self._semlock._is_mine():<tab><tab><tab>name = current_process().name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name += ""|"" + threading.current_thread().name<tab><tab>elif self._semlock._get_value() == 1:<tab><tab><tab>name = ""None""<tab><tab>elif self._semlock._count() > 0:<tab><tab><tab>name = ""SomeOtherThread""<tab><tab>else:<tab><tab><tab>name = ""SomeOtherProcess""<tab>except Exception:<tab><tab>name = ""unknown""<tab>return ""<Lock(owner=%s)>"" % name",0,"if threading . current_thread ( ) . name != ""MainThread"" :",if threading . current_thread ( ) is not None :,0.32917191099545223,45.25291017958982,0.40816326530612246
"def buffer(self, lines, scroll_end=True, scroll_if_editing=False):<tab>""Add data to be displayed in the buffer.""<tab>self.values.extend(lines)<tab>if scroll_end:<tab><tab><IF-STMT><tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)<tab><tab>elif scroll_if_editing:<tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)",0,if not self . editing :,if scroll_if_editing :,0.1098188354096215,1e-10,0.3142857142857143
"def warehouses(self) -> tuple:<tab>from ..repositories import WarehouseBaseRepo<tab>repos = dict()<tab>for dep in chain(self.dependencies, [self]):<tab><tab>if dep.repo is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for repo in dep.repo.repos:<tab><tab><tab>if repo.from_config:<tab><tab><tab><tab>continue<tab><tab><tab>repos[repo.name] = repo<tab>return tuple(repos.values())",1,"if not isinstance ( dep . repo , WarehouseBaseRepo ) :","if not isinstance ( dep . repo , WarehouseBaseRepo ) :",0.75,100.00000000000004,1.0
"def _apply_flag_attrs(src_flag, dest_flag):<tab># Use a baseline flag def to get default values for empty data.<tab>baseline_flag = FlagDef("""", {}, None)<tab>for name in dir(src_flag):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dest_val = getattr(dest_flag, name, None)<tab><tab>baseline_val = getattr(baseline_flag, name, None)<tab><tab>if dest_val == baseline_val:<tab><tab><tab>setattr(dest_flag, name, getattr(src_flag, name))",0,"if name [ : 1 ] == ""_"" :","if name . startswith ( ""_"" ) :",0.0317660291754507,16.830386789031852,0.6
"def out(parent, attr, indent=0):<tab>val = getattr(parent, attr)<tab>prefix = ""%s%s:"" % ("" "" * indent, attr.replace(""_"", ""-""))<tab>if val is None:<tab><tab>cli.out(prefix)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>val = [flag_util.encode_flag_val(c.value) for c in val]<tab><tab>cli.out(""%s %s"" % (prefix, flag_util.encode_flag_val(val)))",0,"if attr == ""choices"" :","if isinstance ( val , list ) :",0.026407399022921448,6.567274736060395,0.3
"def add_cand_to_check(cands):<tab>for cand in cands:<tab><tab>x = cand.creator<tab><tab>if x is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># `len(fan_out)` is in order to avoid comparing `x`<tab><tab><tab>heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x))<tab><tab>fan_out[x] += 1",0,if x not in fan_out :,if len ( fan_out ) == len ( cand_funcs ) :,0.020812994926445203,10.343603005129705,0.32222222222222224
"def task_tree_lines(task=None):<tab>if task is None:<tab><tab>task = current_root_task()<tab>rendered_children = []<tab>nurseries = list(task.child_nurseries)<tab>while nurseries:<tab><tab>nursery = nurseries.pop()<tab><tab>nursery_children = _rendered_nursery_children(nursery)<tab><tab><IF-STMT><tab><tab><tab>nested = _render_subtree(""(nested nursery)"", rendered_children)<tab><tab><tab>nursery_children.append(nested)<tab><tab>rendered_children = nursery_children<tab>return _render_subtree(task.name, rendered_children)",0,if rendered_children :,if nursery_children :,0.3197504490129165,1e-10,1.0
"def lock_workspace(build_dir):<tab>_BUILDING_LOCK_FILE = "".blade.building.lock""<tab>lock_file_fd, ret_code = lock_file(os.path.join(build_dir, _BUILDING_LOCK_FILE))<tab>if lock_file_fd == -1:<tab><tab><IF-STMT><tab><tab><tab>console.fatal(""There is already an active building in current workspace."")<tab><tab>else:<tab><tab><tab>console.fatal(""Lock exception, please try it later."")<tab>return lock_file_fd",0,if ret_code == errno . EAGAIN :,if ret_code == 1 :,0.09453229110448028,55.0695314903184,0.37777777777777777
"def test_list(self):<tab>self._create_locations()<tab>response = self.client.get(self.geojson_boxedlocation_list_url)<tab>self.assertEqual(response.status_code, 200)<tab>self.assertEqual(len(response.data[""features""]), 2)<tab>for feature in response.data[""features""]:<tab><tab>self.assertIn(""bbox"", feature)<tab><tab>fid = feature[""id""]<tab><tab>if fid == 1:<tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent)<tab><tab>else:<tab><tab><tab>self.fail(""Unexpected id: {0}"".format(fid))<tab>BoxedLocation.objects.all().delete()",1,elif fid == 2 :,elif fid == 2 :,1.0,100.00000000000004,1.0
"def result():<tab># ""global"" does not work here...<tab>R, V = rays, virtual_rays<tab>if V is not None:<tab><tab>if normalize:<tab><tab><tab>V = normalize_rays(V, lattice)<tab><tab>if check:<tab><tab><tab>R = PointCollection(V, lattice)<tab><tab><tab>V = PointCollection(V, lattice)<tab><tab><tab>d = lattice.dimension()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""virtual rays must be linearly ""<tab><tab><tab><tab><tab>""independent and with other rays span the ambient space.""<tab><tab><tab><tab>)<tab>return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",0,if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,if d < 1 :,0.003115871643981409,0.14131406583082426,0.19883040935672514
"def search_host(self, search_string):<tab>results = []<tab>for host_entry in self.config_data:<tab><tab>if host_entry.get(""type"") != ""entry"":<tab><tab><tab>continue<tab><tab>if host_entry.get(""host"") == ""*"":<tab><tab><tab>continue<tab><tab>searchable_information = host_entry.get(""host"")<tab><tab>for key, value in six.iteritems(host_entry.get(""options"")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = "" "".join(value)<tab><tab><tab>if isinstance(value, int):<tab><tab><tab><tab>value = str(value)<tab><tab><tab>searchable_information += "" "" + value<tab><tab>if search_string in searchable_information:<tab><tab><tab>results.append(host_entry)<tab>return results",1,"if isinstance ( value , list ) :","if isinstance ( value , list ) :",0.75,100.00000000000004,1.0
"def test_async_iterator(app):<tab>async with new_stream(app) as stream:<tab><tab>for i in range(100):<tab><tab><tab>await stream.channel.deliver(message(key=i, value=i))<tab><tab>received = 0<tab><tab>async for value in stream:<tab><tab><tab>assert value == received<tab><tab><tab>received += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>assert await channel_empty(stream.channel)",0,if received >= 100 :,if received >= 10 :,0.39477865547525276,53.7284965911771,0.6
"def has_google_credentials():<tab>global _HAS_GOOGLE_CREDENTIALS<tab>if _HAS_GOOGLE_CREDENTIALS is None:<tab><tab>provider = Provider(""google"")<tab><tab><IF-STMT><tab><tab><tab>_HAS_GOOGLE_CREDENTIALS = False<tab><tab>else:<tab><tab><tab>_HAS_GOOGLE_CREDENTIALS = True<tab>return _HAS_GOOGLE_CREDENTIALS",0,if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,if provider . has_credentials ( ) :,0.07853239551412775,4.102728696930985,0.40277777777777773
"def __cmp__(self, other):<tab>if isinstance(other, date) or isinstance(other, datetime):<tab><tab>a = self._d.getTime()<tab><tab>b = other._d.getTime()<tab><tab>if a < b:<tab><tab><tab>return -1<tab><tab><IF-STMT><tab><tab><tab>return 0<tab>else:<tab><tab>raise TypeError(""expected date or datetime object"")<tab>return 1",0,elif a == b :,elif a > b :,0.08034284189446517,24.736929544091932,1.0
"def validate_weight(self, weight):<tab>try:<tab><tab>add_acl_to_obj(self.context[""user_acl""], self.category)<tab>except AttributeError:<tab><tab>return weight  # don't validate weight further if category failed<tab>if weight > self.category.acl.get(""can_pin_threads"", 0):<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""You don't have permission to pin threads globally ""<tab><tab><tab><tab><tab>""in this category.""<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""You don't have permission to pin threads in this category."")<tab><tab><tab>)<tab>return weight",0,if weight == 2 :,"if self . category . acl . get ( ""active"" , False ) :",0.0223960376005435,2.908317710573757,0.2046783625730994
"def effective(line):<tab>for b in line:<tab><tab>if not b.cond:<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>val = 5<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if b.ignore:<tab><tab><tab><tab><tab><tab>b.ignore -= 1<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return (b, True)<tab><tab><tab>except:<tab><tab><tab><tab>return (b, False)<tab>return",0,if val :,if b . cond ( val ) :,0.046522600101893324,1e-10,0.36
"def wheelEvent(self, event):<tab>""""""Handle a wheel event.""""""<tab>if QtCore.Qt.ControlModifier & event.modifiers():<tab><tab>d = {""c"": self.leo_c}<tab><tab>if isQt5:<tab><tab><tab>point = event.angleDelta()<tab><tab><tab>delta = point.y() or point.x()<tab><tab>else:<tab><tab><tab>delta = event.delta()<tab><tab><IF-STMT><tab><tab><tab>zoom_out(d)<tab><tab>else:<tab><tab><tab>zoom_in(d)<tab><tab>event.accept()<tab><tab>return<tab>QtWidgets.QTextBrowser.wheelEvent(self, event)",0,if delta < 0 :,if delta > 0 :,0.33141502097923065,30.213753973567677,1.0
"def test_evname_in_mp_events_testcases():<tab>ok = True<tab>for evname in ins.mp_events:<tab><tab>if evname == ""version"":<tab><tab><tab>continue<tab><tab>for i, args in enumerate(ins.mp_events[evname][""test_cases""]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = ""Error, for evname %s the testase #%d does not match evname""<tab><tab><tab><tab>print(msg % (evname, i))<tab><tab><tab><tab>ok = False<tab>if ok:<tab><tab>print(""test_evname_in_mp_events_testcases: passed"")",0,if evname != args [ 0 ] :,if args [ 0 ] != evname :,0.2680668084502599,39.281465090051306,0.4
"def check_database():<tab>if len(EmailAddress.objects.all()) > 0:<tab><tab>print(<tab><tab><tab>""Are you sure you want to wipe the existing development database and reseed it? (Y/N)""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>destroy_database()<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return True",0,"if raw_input ( ) . lower ( ) == ""y"" :",ifEmailAddress . objects . all ( ) . count ( ) > 0 :,0.12309336441989308,12.060275498773779,0.10714285714285714
"def _get_requested_databases(self):<tab>""""""Returns a list of databases requested, not including ignored dbs""""""<tab>requested_databases = []<tab>if (self._requested_namespaces is not None) and (self._requested_namespaces != []):<tab><tab>for requested_namespace in self._requested_namespaces:<tab><tab><tab>if requested_namespace[0] is ""*"":<tab><tab><tab><tab>return []<tab><tab><tab><IF-STMT><tab><tab><tab><tab>requested_databases.append(requested_namespace[0])<tab>return requested_databases",0,elif requested_namespace [ 0 ] not in IGNORE_DBS :,"elif requested_namespace [ 0 ] not in [ ""*"" , ""*"" ] :",0.43424054263958345,43.59493824807389,1.0
"def decorated(self, *args, **kwargs):<tab>start_time = time.perf_counter()<tab>stderr = """"<tab>saved_exception = None<tab>try:<tab><tab>yield from fn(self, *args, **kwargs)<tab>except GitSavvyError as e:<tab><tab>stderr = e.stderr<tab><tab>saved_exception = e<tab>finally:<tab><tab>end_time = time.perf_counter()<tab><tab>util.debug.log_git(args, None, ""<SNIP>"", stderr, end_time - start_time)<tab><tab><IF-STMT><tab><tab><tab>raise saved_exception from None",1,if saved_exception :,if saved_exception :,0.5311706625951745,1e-10,1.0
"def is_suppressed_warning(<tab>type: str, subtype: str, suppress_warnings: List[str]) -> bool:<tab>""""""Check the warning is suppressed or not.""""""<tab>if type is None:<tab><tab>return False<tab>for warning_type in suppress_warnings:<tab><tab>if ""."" in warning_type:<tab><tab><tab>target, subtarget = warning_type.split(""."", 1)<tab><tab>else:<tab><tab><tab>target, subtarget = warning_type, None<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>subtype is None<tab><tab><tab><tab>or subtarget is None<tab><tab><tab><tab>or subtarget == subtype<tab><tab><tab><tab>or subtarget == ""*""<tab><tab><tab>):<tab><tab><tab><tab>return True<tab>return False",1,if target == type :,if target == type :,0.75,100.00000000000004,1.0
"def talk(self, words):<tab>if self.writeSentence(words) == 0:<tab><tab>return<tab>r = []<tab>while 1:<tab><tab>i = self.readSentence()<tab><tab>if len(i) == 0:<tab><tab><tab>continue<tab><tab>reply = i[0]<tab><tab>attrs = {}<tab><tab>for w in i[1:]:<tab><tab><tab>j = w.find(""="", 1)<tab><tab><tab>if j == -1:<tab><tab><tab><tab>attrs[w] = """"<tab><tab><tab>else:<tab><tab><tab><tab>attrs[w[:j]] = w[j + 1 :]<tab><tab>r.append((reply, attrs))<tab><tab><IF-STMT><tab><tab><tab>return r",0,"if reply == ""!done"" :",if len ( r ) == self . length :,0.025806626984353938,8.913765521398126,0.25274725274725274
"def encrypt(self, plaintext):<tab>encrypted = []<tab>for p in _string_to_bytes(plaintext):<tab><tab><IF-STMT><tab><tab><tab>self._remaining_block = self._aes.encrypt(self._last_precipherblock)<tab><tab><tab>self._last_precipherblock = []<tab><tab>precipherbyte = self._remaining_block.pop(0)<tab><tab>self._last_precipherblock.append(precipherbyte)<tab><tab>cipherbyte = p ^ precipherbyte<tab><tab>encrypted.append(cipherbyte)<tab>return _bytes_to_string(encrypted)",1,if len ( self . _remaining_block ) == 0 :,if len ( self . _remaining_block ) == 0 :,0.75,100.00000000000004,1.0
"def find_symbol(self, r, globally=False):<tab>query = self.view.substr(self.view.word(r))<tab>fname = self.view.file_name().replace(""\\"", ""/"")<tab>locations = self.view.window().lookup_symbol_in_index(query)<tab>if not locations:<tab><tab>return<tab>try:<tab><tab><IF-STMT><tab><tab><tab>location = [hit[2] for hit in locations if fname.endswith(hit[1])][0]<tab><tab><tab>return location[0] - 1, location[1] - 1<tab><tab>else:<tab><tab><tab># TODO: There might be many symbols with the same name.<tab><tab><tab>return locations[0]<tab>except IndexError:<tab><tab>return",0,if not globally :,if globally :,0.09648852821835877,1e-10,0.41666666666666663
"def __getslice__(self, i, j):<tab>try:<tab><tab><IF-STMT><tab><tab><tab># handle the case where the right bound is unspecified<tab><tab><tab>j = len(self)<tab><tab>if i < 0 or j < 0:<tab><tab><tab>raise dns.exception.FormError<tab><tab># If it's not an empty slice, access left and right bounds<tab><tab># to make sure they're valid<tab><tab>if i != j:<tab><tab><tab>super(WireData, self).__getitem__(i)<tab><tab><tab>super(WireData, self).__getitem__(j - 1)<tab><tab>return WireData(super(WireData, self).__getslice__(i, j))<tab>except IndexError:<tab><tab>raise dns.exception.FormError",0,if j == sys . maxint :,if j > len ( self ) :,0.03758542150700932,12.22307556087252,0.42857142857142855
"def main():<tab>r = redis.StrictRedis()<tab>curr_memory = prev_memory = r.info()[""used_memory""]<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""Delta Memory : %d, Total Memory : %d""<tab><tab><tab><tab>% ((curr_memory - prev_memory), curr_memory)<tab><tab><tab>)<tab><tab>time.sleep(1)<tab><tab>prev_memory = curr_memory<tab><tab>curr_memory = r.info()[""used_memory""]",0,if prev_memory != curr_memory :,if curr_memory > prev_memory :,0.28849878646896243,33.584386823726156,1.0
"def _visit(self, func):<tab>fname = func[0]<tab>if fname in self._flags:<tab><tab>if self._flags[fname] == 1:<tab><tab><tab>logger.critical(""Fatal error! network ins not Dag."")<tab><tab><tab>import sys<tab><tab><tab>sys.exit(-1)<tab><tab>else:<tab><tab><tab>return<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._flags[fname] = 1<tab><tab>for output in func[3]:<tab><tab><tab>for f in self._orig:<tab><tab><tab><tab>for input in f[2]:<tab><tab><tab><tab><tab>if output == input:<tab><tab><tab><tab><tab><tab>self._visit(f)<tab>self._flags[fname] = 2<tab>self._sorted.insert(0, func)",1,if fname not in self . _flags :,if fname not in self . _flags :,0.75,100.00000000000004,1.0
"def urls(self, version=None):<tab>""""""Returns all URLS that are mapped to this interface""""""<tab>urls = []<tab>for _base_url, routes in self.api.http.routes.items():<tab><tab>for url, methods in routes.items():<tab><tab><tab>for _method, versions in methods.items():<tab><tab><tab><tab>for interface_version, interface in versions.items():<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>if not url in urls:<tab><tab><tab><tab><tab><tab><tab>urls.append(<tab><tab><tab><tab><tab><tab><tab><tab>(""/v{0}"".format(version) if version else """") + url<tab><tab><tab><tab><tab><tab><tab>)<tab>return urls",0,if interface_version == version and interface == self :,if interface_version == version :,0.15738542682294496,46.53786298485943,0.4545454545454546
"def _handle_data(self, text):<tab>if self._translate:<tab><tab><IF-STMT><tab><tab><tab>self._data.append(text)<tab><tab>else:<tab><tab><tab>self._translate = False<tab><tab><tab>self._data = []<tab><tab><tab>self._comments = []",0,"if not text . startswith ( ""gtk-"" ) :",if text not in self . _data :,0.08113539218224564,5.708765135015525,0.2698412698412698
"def set_dir_modes(self, dirname, mode):<tab>if not self.is_chmod_supported():<tab><tab>return<tab>for dirpath, dirnames, fnames in os.walk(dirname):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>log.info(""changing mode of %s to %o"", dirpath, mode)<tab><tab>if not self.dry_run:<tab><tab><tab>os.chmod(dirpath, mode)",0,if os . path . islink ( dirpath ) :,if not os . path . isfile ( dirpath ) or not os . path . isfile ( dirpath ) :,0.3448769023162872,23.41812326184748,0.19111111111111112
"def language(self):<tab>if self.lang_data:<tab><tab>lang_data = [s if s != ""None"" else None for s in self.lang_data]<tab><tab><IF-STMT><tab><tab><tab>return Language(lang_data[0], country=lang_data[1], script=lang_data[2])",0,if lang_data [ 0 ] :,if lang_data :,0.050438393472541504,1e-10,0.6296296296296297
"def _addItemToLayout(self, sample, label):<tab>col = self.layout.columnCount()<tab>row = self.layout.rowCount()<tab>if row:<tab><tab>row -= 1<tab>nCol = self.columnCount * 2<tab># FIRST ROW FULL<tab>if col == nCol:<tab><tab>for col in range(0, nCol, 2):<tab><tab><tab># FIND RIGHT COLUMN<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>if col + 2 == nCol:<tab><tab><tab># MAKE NEW ROW<tab><tab><tab>col = 0<tab><tab><tab>row += 1<tab>self.layout.addItem(sample, row, col)<tab>self.layout.addItem(label, row, col + 1)",0,"if not self . layout . itemAt ( row , col ) :","if self . layout . addItem ( sample , col , nCol ) :",0.13376204425867735,25.400289715190983,0.18181818181818182
"def align_comments(tlist):<tab>tidx, token = tlist.token_next_by(i=sql.Comment)<tab>while token:<tab><tab>pidx, prev_ = tlist.token_prev(tidx)<tab><tab><IF-STMT><tab><tab><tab>tlist.group_tokens(sql.TokenList, pidx, tidx, extend=True)<tab><tab><tab>tidx = pidx<tab><tab>tidx, token = tlist.token_next_by(i=sql.Comment, idx=tidx)",0,"if isinstance ( prev_ , sql . TokenList ) :",if prev_ is token :,0.014393212535568477,8.389861810900507,0.27472527472527475
"def hook_GetVariable(ql, address, params):<tab>if params[""VariableName""] in ql.env:<tab><tab>var = ql.env[params[""VariableName""]]<tab><tab>read_len = read_int64(ql, params[""DataSize""])<tab><tab>if params[""Attributes""] != 0:<tab><tab><tab>write_int64(ql, params[""Attributes""], 0)<tab><tab>write_int64(ql, params[""DataSize""], len(var))<tab><tab><IF-STMT><tab><tab><tab>return EFI_BUFFER_TOO_SMALL<tab><tab>if params[""Data""] != 0:<tab><tab><tab>ql.mem.write(params[""Data""], var)<tab><tab>return EFI_SUCCESS<tab>return EFI_NOT_FOUND",0,if read_len < len ( var ) :,if read_len > 0 :,0.0354018406734773,28.319415510892387,0.38181818181818183
"def _PromptMySQL(self, config):<tab>""""""Prompts the MySQL configuration, retrying if the configuration is invalid.""""""<tab>while True:<tab><tab>self._PromptMySQLOnce(config)<tab><tab>if self._CheckMySQLConnection():<tab><tab><tab>print(""Successfully connected to MySQL with the given configuration."")<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>print(""Error: Could not connect to MySQL with the given configuration."")<tab><tab><tab>retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ConfigInitError()",1,if not retry :,if not retry :,0.75,100.00000000000004,1.0
"def split_long_line_with_indent(line, max_per_line, indent):<tab>""""""Split the `line` so that it doesn't go over `max_per_line` and adds `indent` to new lines.""""""<tab>words = line.split("" "")<tab>lines = []<tab>current_line = words[0]<tab>for word in words[1:]:<tab><tab><IF-STMT><tab><tab><tab>lines.append(current_line)<tab><tab><tab>current_line = "" "" * indent + word<tab><tab>else:<tab><tab><tab>current_line = f""{current_line} {word}""<tab>lines.append(current_line)<tab>return ""\n"".join(lines)",0,"if len ( f""{current_line} {word}"" ) > max_per_line :",if len ( word ) > max_per_line :,0.22052701951210865,32.64049764900211,0.7307692307692308
"def gen_cli(docs_dir):<tab>with open(os.path.join(docs_dir, ""CLI_template.md""), ""r"") as cli_temp_file:<tab><tab>temp_lines = cli_temp_file.readlines()<tab>lines = []<tab>for line in temp_lines:<tab><tab>matched = re.match(r""{onnx-tf.*}"", line)<tab><tab><IF-STMT><tab><tab><tab>command = matched.string.strip()[1:-1]<tab><tab><tab>output = subprocess.check_output(command.split("" "")).decode(""UTF-8"")<tab><tab><tab>lines.append(output)<tab><tab>else:<tab><tab><tab>lines.append(line)<tab>with open(os.path.join(docs_dir, ""CLI.md""), ""w"") as cli_file:<tab><tab>cli_file.writelines(lines)",1,if matched :,if matched :,0.5311706625951745,1e-10,1.0
"def read(self, size=None):<tab>if size == 0:<tab><tab>return """"<tab>data = list()<tab>while size is None or size > 0:<tab><tab>line = self.readline(size or -1)<tab><tab>if not line:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>size -= len(line)<tab><tab>data.append(line)<tab>return """".join(data)",0,if size is not None :,if len ( line ) > size :,0.023749771747382555,7.267884212102741,0.23214285714285715
"def _get_format_and_pattern(file_path):<tab>file_path = Path(file_path)<tab>with file_path.open() as f:<tab><tab>first_line = f.readline().strip()<tab><tab>match = re.match(r""format *: *(.+)"", first_line)<tab><tab><IF-STMT><tab><tab><tab>return ""gztar"", first_line, 1<tab><tab>return match.group(1), f.readline().strip(), 2",1,if match is None :,if match is None :,0.75,100.00000000000004,1.0
"def remove_old_snapshot(install_dir):<tab>logging.info(""Removing any old files in {}"".format(install_dir))<tab>for file in glob.glob(""{}/*"".format(install_dir)):<tab><tab>try:<tab><tab><tab>if os.path.isfile(file):<tab><tab><tab><tab>os.unlink(file)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shutil.rmtree(file)<tab><tab>except Exception as error:<tab><tab><tab>logging.error(""Error: {}"".format(error))<tab><tab><tab>sys.exit(1)",1,elif os . path . isdir ( file ) :,elif os . path . isdir ( file ) :,0.75,100.00000000000004,1.0
"def _test_forever(self, tests):<tab>while True:<tab><tab>for test_name in tests:<tab><tab><tab>yield test_name<tab><tab><tab>if self.bad:<tab><tab><tab><tab>return<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return",0,if self . ns . fail_env_changed and self . environment_changed :,if not self . _test_name ( test_name ) :,0.02511493990760435,6.270144942040139,0.30952380952380953
"def _swig_extract_dependency_files(self, src):<tab>dep = []<tab>for line in open(src):<tab><tab>if line.startswith(""#include"") or line.startswith(""%include""):<tab><tab><tab>line = line.split("" "")[1].strip(""""""'""\r\n"""""")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dep.append(line)<tab>return [i for i in dep if os.path.exists(i)]",0,"if not ( ""<"" in line or line in dep ) :","if line and not line . startswith ( ""#"" ) :",0.025280259847608906,9.908525714904282,0.2
"def update_service_key(kid, name=None, metadata=None):<tab>try:<tab><tab>with db_transaction():<tab><tab><tab>key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key.name = name<tab><tab><tab>if metadata is not None:<tab><tab><tab><tab>key.metadata.update(metadata)<tab><tab><tab>key.save()<tab>except ServiceKey.DoesNotExist:<tab><tab>raise ServiceKeyDoesNotExist",1,if name is not None :,if name is not None :,0.75,100.00000000000004,1.0
"def range(self, dimension, data_range=True, dimension_range=True):<tab>if self.nodes and dimension in self.nodes.dimensions():<tab><tab>node_range = self.nodes.range(dimension, data_range, dimension_range)<tab><tab><IF-STMT><tab><tab><tab>path_range = self._edgepaths.range(dimension, data_range, dimension_range)<tab><tab><tab>return max_range([node_range, path_range])<tab><tab>return node_range<tab>return super(Graph, self).range(dimension, data_range, dimension_range)",1,if self . _edgepaths :,if self . _edgepaths :,0.75,100.00000000000004,1.0
"def handler(chan, host, port):<tab>sock = socket()<tab>try:<tab><tab>sock.connect((host, port))<tab>except Exception as e:<tab><tab>if verbose == True:<tab><tab><tab>print(e)<tab><tab>return<tab>while True:<tab><tab>r, w, x = select.select([sock, chan], [], [])<tab><tab>if sock in r:<tab><tab><tab>data = sock.recv(1024)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>chan.send(data)<tab><tab>if chan in r:<tab><tab><tab>data = chan.recv(1024)<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>break<tab><tab><tab>sock.send(data)<tab>chan.close()<tab>sock.close()",1,if len ( data ) == 0 :,if len ( data ) == 0 :,0.75,100.00000000000004,1.0
"def output_layer(self, features, **kwargs):<tab>""""""Project features to the vocabulary size.""""""<tab>if self.adaptive_softmax is None:<tab><tab># project back to size of vocabulary<tab><tab><IF-STMT><tab><tab><tab>return F.linear(features, self.embed_tokens.weight)<tab><tab>else:<tab><tab><tab>return F.linear(features, self.embed_out)<tab>else:<tab><tab>return features",0,if self . share_input_output_embed :,if self . embed_tokens . weight > 0 :,0.10522622320176984,16.59038701421971,0.5666666666666667
"def generate(self, dest, vars):<tab>util.ensure_dir(dest)<tab>for relpath, src, template in self._file_templates:<tab><tab>file_dest = os.path.join(dest, relpath)<tab><tab>util.ensure_dir(os.path.dirname(file_dest))<tab><tab><IF-STMT><tab><tab><tab>shutil.copyfile(src, file_dest)<tab><tab>else:<tab><tab><tab>_render_template(template, vars, file_dest)",1,if template is None :,if template is None :,0.75,100.00000000000004,1.0
"def _py_matching_callback(self, context, result, sender, device):<tab>d = HIDDevice.get_device(c_void_p(device))<tab>if d not in self.devices:<tab><tab>self.devices.add(d)<tab><tab>for x in self.matching_observers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x.device_discovered(d)",1,"if hasattr ( x , ""device_discovered"" ) :","if hasattr ( x , ""device_discovered"" ) :",0.75,100.00000000000004,1.0
"def urlquote(*args, **kwargs):<tab>new_kwargs = dict(kwargs)<tab>if not PY3:<tab><tab>new_kwargs = dict(kwargs)<tab><tab><IF-STMT><tab><tab><tab>del new_kwargs[""encoding""]<tab><tab>if ""errors"" in kwargs:<tab><tab><tab>del new_kwargs[""errors""]<tab>return quote(*args, **new_kwargs)",0,"if ""encoding"" in new_kwargs :","if ""encoding"" in kwargs :",0.39477865547525276,53.137468984124546,0.7
"def Set(self, attr, value):<tab>hook = getattr(self, ""_set_%s"" % attr, None)<tab>if hook:<tab><tab># If there is a set hook we must use the context manager.<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Can only update attribute %s using the context manager."" % attr<tab><tab><tab>)<tab><tab>if attr not in self._pending_hooks:<tab><tab><tab>self._pending_hooks.append(attr)<tab><tab>self._pending_parameters[attr] = value<tab>else:<tab><tab>super(Configuration, self).Set(attr, value)",0,if self . _lock > 0 :,if attr not in self . _pending_parameters :,0.03952150193806378,15.851165692617148,0.25
"def on_profiles_loaded(self, profiles):<tab>cb = self.builder.get_object(""cbProfile"")<tab>model = cb.get_model()<tab>model.clear()<tab>for f in profiles:<tab><tab>name = f.get_basename()<tab><tab>if name.endswith("".mod""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>name = name[0:-11]<tab><tab>model.append((name, f, None))<tab>cb.set_active(0)",0,"if name . endswith ( "".sccprofile"" ) :","if name . endswith ( "".py"" ) :",0.5490406812970063,70.16879391277372,1.0
"def get_eval_task(self, worker_id):<tab>""""""Return next evaluation (task_id, Task) tuple""""""<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>return -1, None<tab><tab>self._task_id += 1<tab><tab>task = self._eval_todo.pop()<tab><tab>self._doing[self._task_id] = (worker_id, task, time.time())<tab><tab>return self._task_id, task",0,if not self . _eval_todo :,if self . _task_id in self . _eval_todo :,0.21583025285411514,41.374412020518825,0.38181818181818183
"def queries(self):<tab>if DEV:<tab><tab>cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s)<tab><tab><IF-STMT><tab><tab><tab>if not cmd.stdout.strip():<tab><tab><tab><tab>log_cmd = ShellCommand(<tab><tab><tab><tab><tab>""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT<tab><tab><tab><tab>)<tab><tab><tab><tab>if log_cmd.check(f""docker logs for {self.path.k8s}""):<tab><tab><tab><tab><tab>print(cmd.stdout)<tab><tab><tab><tab>pytest.exit(f""container failed to start for {self.path.k8s}"")<tab>return ()",0,"if not cmd . check ( f""docker check for {self.path.k8s}"" ) :",if cmd . check ( ) :,0.12673775963850165,6.87682893933032,0.3
"def disjoined(data):<tab># create marginalized distributions and multiple them together<tab>data_disjoined = None<tab>dim = len(data.shape)<tab>for d in range(dim):<tab><tab>axes = list(range(dim))<tab><tab>axes.remove(d)<tab><tab>data1d = multisum(data, axes)<tab><tab>shape = [1 for k in range(dim)]<tab><tab>shape[d] = len(data1d)<tab><tab>data1d = data1d.reshape(tuple(shape))<tab><tab><IF-STMT><tab><tab><tab>data_disjoined = data1d<tab><tab>else:<tab><tab><tab>data_disjoined = data_disjoined * data1d<tab>return data_disjoined",0,if d == 0 :,if data_disjoined is None :,0.03412306583404374,7.809849842300637,0.3333333333333333
"def safe_repr(val):<tab>try:<tab><tab><IF-STMT><tab><tab><tab># We special case dicts to have a sorted repr. This makes testing<tab><tab><tab># significantly easier<tab><tab><tab>val = _obj_with_safe_repr(val)<tab><tab>ret = repr(val)<tab><tab>if six.PY2:<tab><tab><tab>ret = ret.decode(""utf-8"")<tab>except UnicodeEncodeError:<tab><tab>ret = red(""a %r that cannot be represented"" % type(val))<tab>else:<tab><tab>ret = green(ret)<tab>return ret",1,"if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",0.75,100.00000000000004,1.0
"def wrapper(*args, **kwargs):<tab>resp = view_func(*args, **kwargs)<tab>if isinstance(resp, dict):<tab><tab>ctx_params = request.environ.get(""webrec.template_params"")<tab><tab><IF-STMT><tab><tab><tab>resp.update(ctx_params)<tab><tab>template = self.jinja_env.jinja_env.get_or_select_template(template_name)<tab><tab>return template.render(**resp)<tab>else:<tab><tab>return resp",1,if ctx_params :,if ctx_params :,0.5311706625951745,1e-10,1.0
"def post(self, request, *args, **kwargs):<tab>contact_id = kwargs.get(""pk"")<tab>self.object = get_object_or_404(Contact, id=contact_id)<tab>if (<tab><tab>self.request.user.role != ""ADMIN""<tab><tab>and not self.request.user.is_superuser<tab><tab>and self.request.user != self.object.created_by<tab>) or self.object.company != self.request.company:<tab><tab>raise PermissionDenied<tab>else:<tab><tab>if self.object.address_id:<tab><tab><tab>self.object.address.delete()<tab><tab>self.object.delete()<tab><tab><IF-STMT><tab><tab><tab>return JsonResponse({""error"": False})<tab><tab>return redirect(""contacts:list"")",0,if self . request . is_ajax ( ) :,if request . user . is_authenticated :,0.03334510318274436,19.437571020720103,0.4
"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text",1,"if ""<"" in text :","if ""<"" in text :",0.75,100.00000000000004,1.0
"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict) and k != ""headers"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>elif isinstance(i, _bytes):<tab><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, _bytes):<tab><tab><tab>return False<tab>return True",1,if not everythingIsUnicode ( v ) :,if not everythingIsUnicode ( v ) :,0.75,100.00000000000004,1.0
"def fill(self):<tab>try:<tab><tab>while (<tab><tab><tab>not self.stopping.wait(self.sample_wait)<tab><tab><tab>and len(self.queue) < self.queue.maxlen<tab><tab>):<tab><tab><tab>self.queue.append(self.parent._read())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.parent._fire_events()<tab><tab>self.full.set()<tab><tab>while not self.stopping.wait(self.sample_wait):<tab><tab><tab>self.queue.append(self.parent._read())<tab><tab><tab>if isinstance(self.parent, EventsMixin):<tab><tab><tab><tab>self.parent._fire_events()<tab>except ReferenceError:<tab><tab># Parent is dead; time to die!<tab><tab>pass",0,"if self . partial and isinstance ( self . parent , EventsMixin ) :","if isinstance ( self . parent , EventsMixin ) :",0.4187109811742144,60.57025366576469,0.225
"def _SetListviewTextItems(self, items):<tab>self.listview.DeleteAllItems()<tab>index = -1<tab>for item in items:<tab><tab>index = self.listview.InsertItem(index + 1, item[0])<tab><tab>data = item[1]<tab><tab><IF-STMT><tab><tab><tab>data = """"<tab><tab>self.listview.SetItemText(index, 1, data)",0,if data is None :,if not data :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab>if is_text_payload(request) and request.body:<tab><tab><tab>body = six.ensure_str(request.body)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",0,if old in body :,if body :,0.06767423853569741,1e-10,0.3
"def serialize(cls, value, *args, **kwargs):<tab>if value is None:<tab><tab>return """"<tab>value_as_string = six.text_type(value)<tab>if SHOULD_NOT_USE_LOCALE:<tab><tab>return value_as_string<tab>else:<tab><tab>grouping = kwargs.get(""grouping"", None)<tab><tab>has_decimal_places = value_as_string.find(""."") != -1<tab><tab><IF-STMT><tab><tab><tab>string_format = ""%d""<tab><tab>else:<tab><tab><tab>decimal_places = len(value_as_string.split(""."")[1])<tab><tab><tab>string_format = ""%.{}f"".format(decimal_places)<tab><tab>return locale.format(string_format, value, grouping=grouping)",0,if not has_decimal_places :,if has_decimal_places :,0.09648852821835877,1e-10,0.6
"def review_link(request, path_obj):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if check_permission(""translate"", request):<tab><tab><tab><tab>text = _(""Review Suggestions"")<tab><tab><tab>else:<tab><tab><tab><tab>text = _(""View Suggestions"")<tab><tab><tab>return {<tab><tab><tab><tab>""href"": dispatch.translate(<tab><tab><tab><tab><tab>request, path_obj.pootle_path, matchnames=[""hassuggestion""]<tab><tab><tab><tab>),<tab><tab><tab><tab>""text"": text,<tab><tab><tab>}<tab>except IOError:<tab><tab>pass",0,if path_obj . has_suggestions ( ) :,if request . user . is_authenticated ( ) :,0.1442540687224559,16.59038701421971,0.4642857142857143
"def _migrate_key(self, key):<tab>""""""migrate key from old .dat file""""""<tab>key_path = os.path.join(self.home_path, ""keys.dat"")<tab>if os.path.exists(key_path):<tab><tab>try:<tab><tab><tab>key_data = json.loads(open(key_path, ""rb"").read())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_key(key, key_data.get(key))<tab><tab>except:<tab><tab><tab>self.error(f""Corrupt key file. Manual migration of '{key}' required."")",1,if key_data . get ( key ) :,if key_data . get ( key ) :,0.75,100.00000000000004,1.0
"def gather_callback_args(self, obj, callbacks):<tab>session = sa.orm.object_session(obj)<tab>for callback in callbacks:<tab><tab>backref = callback.backref<tab><tab>root_objs = getdotattr(obj, backref) if backref else obj<tab><tab>if root_objs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>root_objs = [root_objs]<tab><tab><tab>with session.no_autoflush:<tab><tab><tab><tab>for root_obj in root_objs:<tab><tab><tab><tab><tab>if root_obj:<tab><tab><tab><tab><tab><tab>args = self.get_callback_args(root_obj, callback)<tab><tab><tab><tab><tab><tab>if args:<tab><tab><tab><tab><tab><tab><tab>yield args",0,"if not isinstance ( root_objs , Iterable ) :","if not isinstance ( root_objs , list ) :",0.5818820875411705,74.19446627365011,0.6666666666666666
"def GetDefFile(self, gyp_to_build_path):<tab>""""""Returns the .def file from sources, if any.  Otherwise returns None.""""""<tab>spec = self.spec<tab>if spec[""type""] in (""shared_library"", ""loadable_module"", ""executable""):<tab><tab>def_files = [s for s in spec.get(""sources"", []) if s.endswith("".def"")]<tab><tab><IF-STMT><tab><tab><tab>return gyp_to_build_path(def_files[0])<tab><tab>elif len(def_files) > 1:<tab><tab><tab>raise Exception(""Multiple .def files"")<tab>return None",1,if len ( def_files ) == 1 :,if len ( def_files ) == 1 :,0.75,100.00000000000004,1.0
"def _validate_gallery(images):<tab>for image in images:<tab><tab>image_path = image.get(""image_path"", """")<tab><tab>if image_path:<tab><tab><tab>if not isfile(image_path):<tab><tab><tab><tab>raise TypeError(f""{image_path!r} is not a valid image path."")<tab><tab>else:<tab><tab><tab>raise TypeError(""'image_path' is required."")<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""Caption must be 180 characters or less."")",0,"if not len ( image . get ( ""caption"" , """" ) ) <= 180 :",if len ( image_path ) > 180 :,0.019392026746390515,7.859505256643257,0.2670807453416149
"def VType(self):<tab>if ""DW_AT_type"" in self.attributes:<tab><tab>target = self.types[self.type_id]<tab><tab>target_type = target.VType()<tab><tab><IF-STMT><tab><tab><tab>target_type = [target_type, None]<tab><tab>return [""Pointer"", dict(target=target_type[0], target_args=target_type[1])]<tab>return [""Pointer"", dict(target=""Void"")]",1,"if not isinstance ( target_type , list ) :","if not isinstance ( target_type , list ) :",0.75,100.00000000000004,1.0
"def addInPlace(self, value1, value2):<tab>for group in value2:<tab><tab>for key in value2[group]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value1[group][key] = value2[group][key]<tab><tab><tab>else:<tab><tab><tab><tab>value1[group][key] += value2[group][key]<tab>return value1",1,if key not in value1 [ group ] :,if key not in value1 [ group ] :,0.75,100.00000000000004,1.0
"def _mongo_query_and(self, queries):<tab>if len(queries) == 1:<tab><tab>return queries[0]<tab>query = {}<tab>for q in queries:<tab><tab>for k, v in q.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>query[k] = {}<tab><tab><tab>if isinstance(v, list):<tab><tab><tab><tab># TODO check exists of k in query, may be it should be update<tab><tab><tab><tab>query[k] = v<tab><tab><tab>else:<tab><tab><tab><tab>query[k].update(v)<tab>return query",1,if k not in query :,if k not in query :,0.75,100.00000000000004,1.0
"def _handled_eventtype(self, eventtype, handler):<tab>if eventtype not in known_events:<tab><tab>log.error('The event ""%s"" is not known', eventtype)<tab><tab>return False<tab>if known_events[eventtype].__module__.startswith(""deluge.event""):<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>log.error(<tab><tab><tab>""You cannot register custom notification providers ""<tab><tab><tab>""for built-in event types.""<tab><tab>)<tab><tab>return False<tab>return True",0,if handler . __self__ is self :,if handler . __name__ in known_events [ eventtype ] . __dict__ :,0.21929418194895478,19.228544753133768,0.42857142857142855
"def get_ax_arg(uri):<tab>if not ax_ns:<tab><tab>return u""""<tab>prefix = ""openid."" + ax_ns + "".type.""<tab>ax_name = None<tab>for name, values in self.request.arguments.iteritems():<tab><tab><IF-STMT><tab><tab><tab>part = name[len(prefix) :]<tab><tab><tab>ax_name = ""openid."" + ax_ns + "".value."" + part<tab><tab><tab>break<tab>if not ax_name:<tab><tab>return u""""<tab>return self.get_argument(ax_name, u"""")",0,if values [ - 1 ] == uri and name . startswith ( prefix ) :,if name . startswith ( prefix ) :,0.24320951650366568,28.22664073782293,0.2
"def handle_starttag(self, tag, attrs):<tab>if tag == ""base"":<tab><tab>self.base_url = dict(attrs).get(""href"")<tab>if self.scan_tag(tag):<tab><tab>for attr, value in attrs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.strip:<tab><tab><tab><tab><tab>value = strip_html5_whitespace(value)<tab><tab><tab><tab>url = self.process_attr(value)<tab><tab><tab><tab>link = Link(url=url)<tab><tab><tab><tab>self.links.append(link)<tab><tab><tab><tab>self.current_link = link",0,if self . scan_attr ( attr ) :,"if attr == ""href"" :",0.019907917998500824,5.660233915657916,0.4772727272727273
"def test_long_steadystate_queue_popright(self):<tab>for size in (0, 1, 2, 100, 1000):<tab><tab>d = deque(reversed(range(size)))<tab><tab>append, pop = d.appendleft, d.pop<tab><tab>for i in range(size, BIG):<tab><tab><tab>append(i)<tab><tab><tab>x = pop()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(x, i - size)<tab><tab>self.assertEqual(list(reversed(list(d))), list(range(BIG - size, BIG)))",1,if x != i - size :,if x != i - size :,0.75,100.00000000000004,1.0
"def _update_read(self):<tab>""""""Update state when there is read event""""""<tab>try:<tab><tab>msg = bytes(self._sock.recv(4096))<tab><tab><IF-STMT><tab><tab><tab>self.on_message(msg)<tab><tab><tab>return True<tab><tab># normal close, remote is closed<tab><tab>self.close()<tab>except socket.error as err:<tab><tab>if err.args[0] in (errno.EAGAIN, errno.EWOULDBLOCK):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.on_error(err)<tab>return False",1,if msg :,if msg :,0.5311706625951745,1e-10,1.0
"def prepend(self, value):<tab>""""""prepend value to nodes""""""<tab>root, root_text = self._get_root(value)<tab>for i, tag in enumerate(self):<tab><tab>if not tag.text:<tab><tab><tab>tag.text = """"<tab><tab><IF-STMT><tab><tab><tab>root[-1].tail = tag.text<tab><tab><tab>tag.text = root_text<tab><tab>else:<tab><tab><tab>tag.text = root_text + tag.text<tab><tab>if i > 0:<tab><tab><tab>root = deepcopy(list(root))<tab><tab>tag[:0] = root<tab><tab>root = tag[: len(root)]<tab>return self",0,if len ( root ) > 0 :,elif i == 0 :,0.028858540664499777,11.631736348831648,0.12698412698412698
"def cmp(self, other):<tab>v_is_ptr = not isinstance(self, CTypesGenericPrimitive)<tab>w_is_ptr = isinstance(other, CTypesData) and not isinstance(<tab><tab>other, CTypesGenericPrimitive<tab>)<tab>if v_is_ptr and w_is_ptr:<tab><tab>return cmpfunc(self._convert_to_address(None), other._convert_to_address(None))<tab>elif v_is_ptr or w_is_ptr:<tab><tab>return NotImplemented<tab>else:<tab><tab>if isinstance(self, CTypesGenericPrimitive):<tab><tab><tab>self = self._value<tab><tab><IF-STMT><tab><tab><tab>other = other._value<tab><tab>return cmpfunc(self, other)",0,"if isinstance ( other , CTypesGenericPrimitive ) :","elif isinstance ( other , CTypesGenericPrimitive ) :",0.40018302522632676,84.08964152537145,0.6666666666666666
"def get_external_addresses(self, label=None) -> List[str]:<tab>result = []<tab>for c in self._conf[""pools""].values():<tab><tab><IF-STMT><tab><tab><tab>if label == c[""label""]:<tab><tab><tab><tab>result.append(c[""external_address""][0])<tab><tab>else:<tab><tab><tab>result.append(c[""external_address""][0])<tab>return result",0,if label is not None :,"if ""external_address"" in c :",0.02713659235259708,5.669791110976001,0.1875
"def coerce_text(v):<tab>if not isinstance(v, basestring_):<tab><tab><IF-STMT><tab><tab><tab>attr = ""__unicode__""<tab><tab>else:<tab><tab><tab>attr = ""__str__""<tab><tab>if hasattr(v, attr):<tab><tab><tab>return unicode(v)<tab><tab>else:<tab><tab><tab>return bytes(v)<tab>return v",0,if sys . version_info [ 0 ] < 3 :,if six . PY2 :,0.014393212535568477,3.466791587270993,0.27472527472527475
"def check_localhost(self):<tab>""""""Warn if any socket_host is 'localhost'. See #711.""""""<tab>for k, v in cherrypy.config.items():<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""The use of 'localhost' as a socket host can ""<tab><tab><tab><tab>""cause problems on newer systems, since ""<tab><tab><tab><tab>""'localhost' can map to either an IPv4 or an ""<tab><tab><tab><tab>""IPv6 address. You should use '127.0.0.1' ""<tab><tab><tab><tab>""or '[::1]' instead.""<tab><tab><tab>)",0,"if k == ""server.socket_host"" and v == ""localhost"" :","if k == ""socket_host"" and v == ""localhost"" :",0.7998893192644195,79.46548462807742,1.0
"def add_songs(self, filenames, library):<tab>changed = []<tab>for i in range(len(self)):<tab><tab><IF-STMT><tab><tab><tab>song = library[self._list[i]]<tab><tab><tab>self._list[i] = song<tab><tab><tab>changed.append(song)<tab>if changed:<tab><tab>self._emit_changed(changed, msg=""add"")<tab>return bool(changed)",0,"if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :",if self . _list [ i ] not in filenames :,0.1779052595925446,30.67245280371671,0.18333333333333335
"def _expand_deps_java_generation(self):<tab>""""""Ensure that all multilingual dependencies such as proto_library generate java code.""""""<tab>queue = collections.deque(self.deps)<tab>keys = set()<tab>while queue:<tab><tab>k = queue.popleft()<tab><tab>if k not in keys:<tab><tab><tab>keys.add(k)<tab><tab><tab>dep = self.target_database[k]<tab><tab><tab><IF-STMT>  # Has this attribute<tab><tab><tab><tab>dep.attr[""generate_java""] = True<tab><tab><tab><tab>queue.extend(dep.deps)",0,"if ""generate_java"" in dep . attr :","if ""generate_java"" not in dep . attr :",0.325427584671977,73.48889200874659,0.30952380952380953
"def get(self):<tab>name = request.args.get(""filename"")<tab>if name is not None:<tab><tab>opts = dict()<tab><tab>opts[""type""] = ""episode""<tab><tab>result = guessit(name, options=opts)<tab><tab>res = dict()<tab><tab><IF-STMT><tab><tab><tab>res[""episode""] = result[""episode""]<tab><tab>else:<tab><tab><tab>res[""episode""] = 0<tab><tab>if ""season"" in result:<tab><tab><tab>res[""season""] = result[""season""]<tab><tab>else:<tab><tab><tab>res[""season""] = 0<tab><tab>if ""subtitle_language"" in result:<tab><tab><tab>res[""subtitle_language""] = str(result[""subtitle_language""])<tab><tab>return jsonify(data=res)<tab>else:<tab><tab>return """", 400",1,"if ""episode"" in result :","if ""episode"" in result :",0.75,100.00000000000004,1.0
def _get_error_file(self) -> Optional[str]:<tab>error_file = None<tab>min_timestamp = sys.maxsize<tab>for replicas in self.role_replicas.values():<tab><tab>for replica in replicas:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>mtime = os.path.getmtime(replica.error_file)<tab><tab><tab>if mtime < min_timestamp:<tab><tab><tab><tab>min_timestamp = mtime<tab><tab><tab><tab>error_file = replica.error_file<tab>return error_file,0,if not os . path . exists ( replica . error_file ) :,if replica . error_file is None :,0.10586620446275179,24.925978674400294,0.20833333333333334
"def findChapterNameForPosition(self, p):<tab>""""""Return the name of a chapter containing p or None if p does not exist.""""""<tab>cc, c = self, self.c<tab>if not p or not c.positionExists(p):<tab><tab>return None<tab>for name in cc.chaptersDict:<tab><tab><IF-STMT><tab><tab><tab>theChapter = cc.chaptersDict.get(name)<tab><tab><tab>if theChapter.positionIsInChapter(p):<tab><tab><tab><tab>return name<tab>return ""main""",0,"if name != ""main"" :",if name . startswith ( p ) :,0.04979441971690225,12.22307556087252,0.5599999999999999
"def remove_files(folder, file_extensions):<tab>for f in os.listdir(folder):<tab><tab>f_path = os.path.join(folder, f)<tab><tab>if os.path.isfile(f_path):<tab><tab><tab>extension = os.path.splitext(f_path)[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(f_path)",1,if extension in file_extensions :,if extension in file_extensions :,0.75,100.00000000000004,1.0
"def execute_uncomment(self, event):<tab>cursor = self._editor.GetCurrentPos()<tab>line, pos = self._editor.GetCurLine()<tab>spaces = "" "" * self._tab_size<tab>comment = ""Comment"" + spaces<tab>cpos = cursor - len(comment)<tab>lenline = len(line)<tab>if lenline > 0:<tab><tab>idx = 0<tab><tab>while idx < lenline and line[idx] == "" "":<tab><tab><tab>idx += 1<tab><tab><IF-STMT><tab><tab><tab>self._editor.DeleteRange(cursor - pos + idx, len(comment))<tab><tab><tab>self._editor.SetCurrentPos(cpos)<tab><tab><tab>self._editor.SetSelection(cpos, cpos)<tab><tab><tab>self.store_position()",0,if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,if idx < lenline :,0.003292192552198769,0.21081581353052783,0.23026315789473684
"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell(<tab>critical_suite_with_citations, empty_data_context):<tab>obs = SuiteEditNotebookRenderer.from_data_context(empty_data_context).render(<tab><tab>critical_suite_with_citations, {""path"": ""./foo/data""}<tab>)<tab>assert isinstance(obs, dict)<tab>found_expected = False<tab>for cell in obs[""cells""]:<tab><tab><IF-STMT><tab><tab><tab>source_code = cell[""source""]<tab><tab><tab>if 'batch_kwargs = {""path"": ""../.././foo/data""}' in source_code:<tab><tab><tab><tab>found_expected = True<tab><tab><tab><tab>break<tab>assert found_expected",1,"if cell [ ""cell_type"" ] == ""code"" :","if cell [ ""cell_type"" ] == ""code"" :",0.75,100.00000000000004,1.0
"def _get_file(self):<tab>if self._file is None:<tab><tab>self._file = SpooledTemporaryFile(<tab><tab><tab>max_size=self._storage.max_memory_size,<tab><tab><tab>suffix="".S3Boto3StorageFile"",<tab><tab><tab>dir=setting(""FILE_UPLOAD_TEMP_DIR""),<tab><tab>)<tab><tab>if ""r"" in self._mode:<tab><tab><tab>self._is_dirty = False<tab><tab><tab>self.obj.download_fileobj(self._file)<tab><tab><tab>self._file.seek(0)<tab><tab><IF-STMT><tab><tab><tab>self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0)<tab>return self._file",0,"if self . _storage . gzip and self . obj . content_encoding == ""gzip"" :","elif ""w"" in self . _mode :",0.06345316199592865,6.183099685926281,0.10714285714285714
"def _parse_filters(f_strs):<tab>filters = []<tab>if not f_strs:<tab><tab>return filters<tab>for f_str in f_strs:<tab><tab><IF-STMT><tab><tab><tab>fname, fopts = f_str.split("":"", 1)<tab><tab><tab>filters.append((fname, _parse_options([fopts])))<tab><tab>else:<tab><tab><tab>filters.append((f_str, {}))<tab>return filters",1,"if "":"" in f_str :","if "":"" in f_str :",0.75,100.00000000000004,1.0
"def update_completion(self):<tab>""""""Update completion model with exist tags""""""<tab>orig_text = self.widget.text()<tab>text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1])<tab>tags = []<tab>for tag in self.tags_list:<tab><tab><IF-STMT><tab><tab><tab>if orig_text[-1] not in ("","", "" ""):<tab><tab><tab><tab>tags.append(""%s,%s"" % (text, tag))<tab><tab><tab>tags.append(""%s, %s"" % (text, tag))<tab><tab>else:<tab><tab><tab>tags.append(tag)<tab>if tags != self.completer_model.stringList():<tab><tab>self.completer_model.setStringList(tags)",0,"if "","" in orig_text :",if tag not in tags :,0.032294703547118726,6.4790667469036025,0.2333333333333333
"def _get_startup_packages(lib_path: Path, packages) -> Set[str]:<tab>names = set()<tab>for path in lib_path.iterdir():<tab><tab>name = path.name<tab><tab>if name == ""__pycache__"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>names.add(name.split(""."")[0])<tab><tab>elif path.is_dir() and ""."" not in name:<tab><tab><tab>names.add(name)<tab>if packages:<tab><tab>packages = {package.lower().replace(""-"", ""_"") for package in packages}<tab><tab>if len(names & packages) == len(packages):<tab><tab><tab>return packages<tab>return names",0,"if name . endswith ( "".py"" ) :","elif path . is_file ( ) and ""."" in name :",0.016429748565953358,7.432998184513635,0.10714285714285714
"def get_cloud_credential(self):<tab>""""""Return the credential which is directly tied to the inventory source type.""""""<tab>credential = None<tab>for cred in self.credentials.all():<tab><tab><IF-STMT><tab><tab><tab>if cred.kind == self.source.replace(""ec2"", ""aws""):<tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># these need to be returned in the API credential field<tab><tab><tab>if cred.credential_type.kind != ""vault"":<tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab>return credential",0,if self . source in CLOUD_PROVIDERS :,if self . source :,0.28093026462960746,31.772355751081438,0.7714285714285715
"def newickize(clade):<tab>""""""Convert a node tree to a Newick tree string, recursively.""""""<tab>label = clade.name or """"<tab>if label:<tab><tab>unquoted_label = re.match(token_dict[""unquoted node label""], label)<tab><tab><IF-STMT><tab><tab><tab>label = ""'%s'"" % label.replace(""\\"", ""\\\\"").replace(""'"", ""\\'"")<tab>if clade.is_terminal():  # terminal<tab><tab>return label + make_info_string(clade, terminal=True)<tab>else:<tab><tab>subtrees = (newickize(sub) for sub in clade)<tab><tab>return ""(%s)%s"" % ("","".join(subtrees), label + make_info_string(clade))",0,if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) :,if unquoted_label :,0.004127987352981445,1e-10,0.26267281105990786
"def __iter__(self):<tab>for name, value in self._vars.store.data.items():<tab><tab>source = self._sources[name]<tab><tab>prefix = self._get_prefix(value)<tab><tab>name = u""{0}{{{1}}}"".format(prefix, name)<tab><tab><IF-STMT><tab><tab><tab>yield ArgumentInfo(name, value)<tab><tab>else:<tab><tab><tab>yield VariableInfo(name, value, source)",0,if source == self . ARGUMENT_SOURCE :,if source is None :,0.04240600921794552,8.697972365316721,0.4761904761904762
"def filepath_enumerate(paths):<tab>""""""Enumerate the file paths of all subfiles of the list of paths""""""<tab>out = []<tab>for path in paths:<tab><tab><IF-STMT><tab><tab><tab>out.append(path)<tab><tab>else:<tab><tab><tab>for root, dirs, files in os.walk(path):<tab><tab><tab><tab>for name in files:<tab><tab><tab><tab><tab>out.append(os.path.normpath(os.path.join(root, name)))<tab>return out",0,if os . path . isfile ( path ) :,if os . path . isdir ( path ) :,0.8303088707179008,65.80370064762461,0.6666666666666666
"def del_(self, key):<tab>hash_ = self.hash(key)<tab>node_ = self._table[hash_]<tab>pre_node = None<tab>while node_ is not None:<tab><tab><IF-STMT><tab><tab><tab>if pre_node is None:<tab><tab><tab><tab>self._table[hash_] = node_.next<tab><tab><tab>else:<tab><tab><tab><tab>pre_node.next = node_.next<tab><tab><tab>self._len -= 1<tab><tab>pre_node = node_<tab><tab>node_ = node_.next",1,if node_ . key == key :,if node_ . key == key :,1.0,100.00000000000004,1.0
"def _recurse(self, base_path, rel_source, rel_zip):<tab>submodules_path = Path(base_path) / ""submodules""<tab>if not submodules_path.is_dir():<tab><tab>return<tab>for submodule in submodules_path.iterdir():<tab><tab>source_path = submodule / rel_source<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>output_path = submodule / rel_zip<tab><tab>self._build_lambdas(source_path, output_path)<tab><tab>self._recurse(submodule, rel_source, rel_zip)",0,if not source_path . is_dir ( ) :,if not source_path . is_file ( ) :,0.5014622369176811,73.48889200874659,1.0
"def find_test_functions(collections):<tab>if not isinstance(collections, list):<tab><tab>collections = [collections]<tab>functions = []<tab>for collection in collections:<tab><tab>if not isinstance(collection, dict):<tab><tab><tab>collection = vars(collection)<tab><tab>keys = collection.keys()<tab><tab>keys.sort()<tab><tab>for key in keys:<tab><tab><tab>value = collection[key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(value)<tab>return functions",0,"if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",if callable ( value ) :,0.015151315925389718,2.780868806737642,0.27214170692431566
"def __init__(<tab>self,<tab>classifier,<tab>layer_name=None,<tab>transpose=None,<tab>distance=None,<tab>copy_weights=True,):<tab>super().__init__()<tab>self.copy_weights = copy_weights<tab>### set layer weights ###<tab>if layer_name is not None:<tab><tab>self.set_weights(getattr(classifier, layer_name))<tab>else:<tab><tab>for x in self.possible_layer_names:<tab><tab><tab>layer = getattr(classifier, x, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.set_weights(layer)<tab><tab><tab><tab>break<tab>### set distance measure ###<tab>self.distance = classifier.distance if distance is None else distance<tab>self.transpose = transpose",1,if layer is not None :,if layer is not None :,0.75,100.00000000000004,1.0
def multi_dev_generator(self):<tab>for data in self._data_loader():<tab><tab>if len(self._tail_data) < self._base_number:<tab><tab><tab>self._tail_data += data<tab><tab><IF-STMT><tab><tab><tab>yield self._tail_data<tab><tab><tab>self._tail_data = [],1,if len ( self . _tail_data ) == self . _base_number :,if len ( self . _tail_data ) == self . _base_number :,1.0,100.00000000000004,1.0
"def Resolve(self, updater=None):<tab>if len(self.Conflicts):<tab><tab>for setting, edge in self.Conflicts:<tab><tab><tab>answer = self.AskUser(self.Setting, setting)<tab><tab><tab>if answer == Gtk.ResponseType.YES:<tab><tab><tab><tab>value = setting.Value.split(""|"")<tab><tab><tab><tab>value.remove(edge)<tab><tab><tab><tab>setting.Value = ""|"".join(value)<tab><tab><tab><tab>if updater:<tab><tab><tab><tab><tab>updater.UpdateSetting(setting)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return True",0,if answer == Gtk . ResponseType . NO :,elif answer == Gtk . ResponseType . NO :,0.5377127708701797,88.01117367933934,0.7142857142857143
"def _post_process_ttl(zone):<tab>for name in zone:<tab><tab>for record_type in zone[name]:<tab><tab><tab>records = zone[name][record_type]<tab><tab><tab>if isinstance(records, list):<tab><tab><tab><tab>ttl = min([x[""ttl""] for x in records])<tab><tab><tab><tab>for record in records:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>logger.warning(<tab><tab><tab><tab><tab><tab><tab>""Using lowest TTL {} for the record set. Ignoring value {}"".format(<tab><tab><tab><tab><tab><tab><tab><tab>ttl, record[""ttl""]<tab><tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>record[""ttl""] = ttl",0,"if record [ ""ttl"" ] != ttl :","if ttl < record [ ""ttl"" ] :",0.26248055641091705,51.7679965241078,0.5
"def __init__(self, cmds, env, cleanup=[]):<tab>self.handle = None<tab>self.cmds = cmds<tab>self.env = env<tab>if cleanup:<tab><tab><IF-STMT><tab><tab><tab>cleanup = [cleanup]<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>cleanup = [c for c in cleanup if callable(c)]<tab><tab><tab>except:<tab><tab><tab><tab>cleanup = []<tab>self.cleanup = cleanup",0,if callable ( cleanup ) :,"if isinstance ( cleanup , list ) :",0.05486085687309722,16.515821590069027,0.48148148148148145
"def _parse_data_of_birth(cls, data_of_birth_string):<tab>if data_of_birth_string:<tab><tab>format = ""%m/%d/%Y""<tab><tab>try:<tab><tab><tab>parsed_date = datetime.datetime.strptime(data_of_birth_string, format)<tab><tab><tab>return parsed_date<tab><tab>except ValueError:<tab><tab><tab># Facebook sometimes provides a partial date format<tab><tab><tab># ie 04/07 (ignore those)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",0,"if data_of_birth_string . count ( ""/"" ) != 1 :",if len ( data_of_birth_string ) < 2 :,0.016488471117058152,33.87481880733319,0.3333333333333333
"def process_lib(vars_, coreval):<tab>for d in vars_:<tab><tab>var = d.upper()<tab><tab>if var == ""QTCORE"":<tab><tab><tab>continue<tab><tab>value = env[""LIBPATH_"" + var]<tab><tab>if value:<tab><tab><tab>core = env[coreval]<tab><tab><tab>accu = []<tab><tab><tab>for lib in value:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>accu.append(lib)<tab><tab><tab>env[""LIBPATH_"" + var] = accu",0,if lib in core :,if lib == core :,0.08141502097923063,22.957488466614336,0.5333333333333333
"def throttle_status(server=None):<tab>result = AmonStruct()<tab>result.allow = False<tab>last_check = server.get(""last_check"")<tab>server_check_period = server.get(""check_every"", 60)<tab>if last_check:<tab><tab>period_since_last_check = unix_utc_now() - last_check<tab><tab># Add 15 seconds buffer, for statsd<tab><tab>period_since_last_check = period_since_last_check + 15<tab><tab><IF-STMT><tab><tab><tab>result.allow = True<tab>else:<tab><tab>result.allow = True  # Never checked<tab>return result",1,if period_since_last_check >= server_check_period :,if period_since_last_check >= server_check_period :,0.75,100.00000000000004,1.0
"def fetch_scatter_outputs(self, task):<tab>scatteroutputs = []<tab>for var in task[""body""]:<tab><tab># TODO variable support<tab><tab>if var.startswith(""call""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for output in self.tasks_dictionary[task[""body""][var][""task""]][<tab><tab><tab><tab><tab>""outputs""<tab><tab><tab><tab>]:<tab><tab><tab><tab><tab>scatteroutputs.append(<tab><tab><tab><tab><tab><tab>{""task"": task[""body""][var][""alias""], ""output"": output[0]}<tab><tab><tab><tab><tab>)<tab>return scatteroutputs",0,"if ""outputs"" in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :","if self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :",0.4221850124594693,81.01272766229768,0.32758620689655177
"def _add_constant_node(self, source_node):<tab>parent_ids = range(len(source_node.in_edges))<tab>for idx in parent_ids:<tab><tab>parent_node = self.tf_graph.get_node(source_node.in_edges[idx])<tab><tab><IF-STMT><tab><tab><tab>self._rename_Const(parent_node)",0,"if parent_node . type == ""Const"" :",if parent_node is not None :,0.041553059925636515,22.17204504793461,0.2916666666666667
"def enableCtrls(self):<tab># Check if each ctrl has a requirement or an incompatibility,<tab># look it up, and enable/disable if so<tab>for data in self.storySettingsData:<tab><tab>name = data[""name""]<tab><tab>if name in self.ctrls:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>set = self.getSetting(data[""requires""])<tab><tab><tab><tab>for i in self.ctrls[name]:<tab><tab><tab><tab><tab>i.Enable(set not in [""off"", ""false"", ""0""])",0,"if ""requires"" in data :","if data [ ""requires"" ] :",0.03393665105741328,24.446151121745064,0.4642857142857143
"def update_realtime(self, stdout="""", stderr="""", delete=False):<tab>wooey_cache = wooey_settings.WOOEY_REALTIME_CACHE<tab>if delete == False and wooey_cache is None:<tab><tab>self.stdout = stdout<tab><tab>self.stderr = stderr<tab><tab>self.save()<tab>elif wooey_cache is not None:<tab><tab>cache = django_cache[wooey_cache]<tab><tab><IF-STMT><tab><tab><tab>cache.delete(self.get_realtime_key())<tab><tab>else:<tab><tab><tab>cache.set(<tab><tab><tab><tab>self.get_realtime_key(),<tab><tab><tab><tab>json.dumps({""stdout"": stdout, ""stderr"": stderr}),<tab><tab><tab>)",1,if delete :,if delete :,0.5311706625951745,1e-10,1.0
"def _check_for_batch_clashes(xs):<tab>""""""Check that batch names do not overlap with sample names.""""""<tab>names = set([x[""description""] for x in xs])<tab>dups = set([])<tab>for x in xs:<tab><tab>batches = tz.get_in((""metadata"", ""batch""), x)<tab><tab>if batches:<tab><tab><tab>if not isinstance(batches, (list, tuple)):<tab><tab><tab><tab>batches = [batches]<tab><tab><tab>for batch in batches:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dups.add(batch)<tab>if len(dups) > 0:<tab><tab>raise ValueError(<tab><tab><tab>""Batch names must be unique from sample descriptions.\n""<tab><tab><tab>""Clashing batch names: %s"" % sorted(list(dups))<tab><tab>)",0,if batch in names :,if len ( names ) == len ( batch ) :,0.02616748853192985,4.789232204309912,0.32051282051282054
"def toggle(self, event=None):<tab>if self.absolute:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 100<tab><tab>if self.split > 20:<tab><tab><tab>self.save = self.split<tab><tab><tab>self.split = 1<tab><tab>else:<tab><tab><tab>self.split = self.save<tab>else:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 0.3<tab><tab><IF-STMT><tab><tab><tab>self.split = self.save<tab><tab>elif self.split < 0.5:<tab><tab><tab>self.split = self.min<tab><tab>else:<tab><tab><tab>self.split = self.max<tab>self.placeChilds()",0,if self . split <= self . min or self . split >= self . max :,if self . save > 0.5 :,0.09027663634109459,5.0022783410134535,0.2583333333333333
"def can_read(self):<tab>if hasattr(self.file, ""__iter__""):<tab><tab>iterator = iter(self.file)<tab><tab>head = next(iterator, None)<tab><tab><IF-STMT><tab><tab><tab>self.repaired = []<tab><tab><tab>return True<tab><tab>if isinstance(head, str):<tab><tab><tab>self.repaired = itertools.chain([head], iterator)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab># We may have mangled a generator at this point, so just abort<tab><tab><tab>raise IOSourceError(<tab><tab><tab><tab>""Could not open source: %r (mode: %r)""<tab><tab><tab><tab>% (self.file, self.options[""mode""])<tab><tab><tab>)<tab>return False",1,if head is None :,if head is None :,0.75,100.00000000000004,1.0
"def _print_message_content(self, peer, data):<tab>inheaders = 1<tab>lines = data.splitlines()<tab>for line in lines:<tab><tab># headers first<tab><tab>if inheaders and not line:<tab><tab><tab>peerheader = ""X-Peer: "" + peer[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab># decoded_data=false; make header match other binary output<tab><tab><tab><tab>peerheader = repr(peerheader.encode(""utf-8""))<tab><tab><tab>print(peerheader)<tab><tab><tab>inheaders = 0<tab><tab>if not isinstance(data, str):<tab><tab><tab># Avoid spurious 'str on bytes instance' warning.<tab><tab><tab>line = repr(line)<tab><tab>print(line)",0,"if not isinstance ( data , str ) :","if not isinstance ( peerheader , str ) :",0.5498893192644195,59.694917920196445,0.7142857142857143
"def connect(self):<tab># Makes connection with MySQL server<tab>try:<tab><tab><IF-STMT><tab><tab><tab>connection = pymysql.connect(read_default_file=""/etc/mysql/conf.d/my.cnf"")<tab><tab>else:<tab><tab><tab>connection = pymysql.connect(read_default_file=""~/.my.cnf"")<tab><tab>return connection<tab>except ValueError as e:<tab><tab>Log.debug(self, str(e))<tab><tab>raise MySQLConnectionError<tab>except pymysql.err.InternalError as e:<tab><tab>Log.debug(self, str(e))<tab><tab>raise MySQLConnectionError",0,"if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :","if sys . platform == ""win32"" :",0.06496981522550546,1.7100430625757868,0.27472527472527475
"def _copy_package_apps(<tab>local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None:<tab>for src_unresolved in app_paths:<tab><tab>src = src_unresolved.resolve()<tab><tab>app = src.name<tab><tab>dest = Path(local_bin_dir / add_suffix(app, suffix))<tab><tab>if not dest.parent.is_dir():<tab><tab><tab>mkdir(dest.parent)<tab><tab>if dest.exists():<tab><tab><tab>logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"")<tab><tab><tab>dest.unlink()<tab><tab><IF-STMT><tab><tab><tab>shutil.copy(src, dest)",0,if src . exists ( ) :,elif src . is_file ( ) :,0.09729240548623488,22.31618068926665,0.37777777777777777
"def update(self, x, who=None, metadata=None):<tab>self._retain_refs(metadata)<tab>y = self._get_key(x)<tab>if self.keep == ""last"":<tab><tab># remove key if already present so that emitted value<tab><tab># will reflect elements' actual relative ordering<tab><tab>self._buffer.pop(y, None)<tab><tab>self._metadata_buffer.pop(y, None)<tab><tab>self._buffer[y] = x<tab><tab>self._metadata_buffer[y] = metadata<tab>else:  # self.keep == ""first""<tab><tab><IF-STMT><tab><tab><tab>self._buffer[y] = x<tab><tab><tab>self._metadata_buffer[y] = metadata<tab>return self.last",0,if y not in self . _buffer :,"if self . keep == ""first"" :",0.03676852316447079,9.980099403873663,0.25
"def resolve_credential_keys(m_keys, keys):<tab>res = []<tab>for k in m_keys:<tab><tab>if k[""c7n:match-type""] == ""credential"":<tab><tab><tab>c_date = parse_date(k[""last_rotated""])<tab><tab><tab>for ak in keys:<tab><tab><tab><tab>if c_date == ak[""CreateDate""]:<tab><tab><tab><tab><tab>ak = dict(ak)<tab><tab><tab><tab><tab>ak[""c7n:match-type""] = ""access""<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>res.append(ak)<tab><tab>elif k not in res:<tab><tab><tab>res.append(k)<tab>return res",0,if ak not in res :,if k in ak :,0.03065939806501017,12.368464772045972,0.23809523809523808
"def _apply_flag_attrs(src_flag, dest_flag):<tab># Use a baseline flag def to get default values for empty data.<tab>baseline_flag = FlagDef("""", {}, None)<tab>for name in dir(src_flag):<tab><tab>if name[:1] == ""_"":<tab><tab><tab>continue<tab><tab>dest_val = getattr(dest_flag, name, None)<tab><tab>baseline_val = getattr(baseline_flag, name, None)<tab><tab><IF-STMT><tab><tab><tab>setattr(dest_flag, name, getattr(src_flag, name))",0,if dest_val == baseline_val :,if dest_val is None or baseline_val is None :,0.04975840882008457,28.917849332325716,0.3090909090909091
"def _ws_keep_reading(self):<tab>import websockets.exceptions<tab>while not self._reader_stopped:<tab><tab>try:<tab><tab><tab>data = await self._ws.recv()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = data.encode(""UTF-8"")<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>self._error = ""EOF""<tab><tab><tab><tab>break<tab><tab>except websockets.exceptions.ConnectionClosedError:<tab><tab><tab># TODO: try to reconnect in case of Ctrl+D<tab><tab><tab>self._error = ""EOF""<tab><tab><tab>break<tab><tab>self.num_bytes_received += len(data)<tab><tab>self._make_output_available(data, block=False)",1,"if isinstance ( data , str ) :","if isinstance ( data , str ) :",0.75,100.00000000000004,1.0
"def to_dict(self) -> Dict[str, Any]:<tab>result = {}<tab>for field_name in self.API_FIELDS:<tab><tab><IF-STMT><tab><tab><tab>result[""stream_id""] = self.id<tab><tab><tab>continue<tab><tab>elif field_name == ""date_created"":<tab><tab><tab>result[""date_created""] = datetime_to_timestamp(self.date_created)<tab><tab><tab>continue<tab><tab>result[field_name] = getattr(self, field_name)<tab>result[""is_announcement_only""] = (<tab><tab>self.stream_post_policy == Stream.STREAM_POST_POLICY_ADMINS<tab>)<tab>return result",0,"if field_name == ""id"" :","if field_name == ""stream_id"" :",0.39477865547525276,63.40466277046863,1.0
"def all_masks(<tab>cls,<tab>images,<tab>run,<tab>run_key,<tab>step,):<tab>all_mask_groups = []<tab>for image in images:<tab><tab><IF-STMT><tab><tab><tab>mask_group = {}<tab><tab><tab>for k in image._masks:<tab><tab><tab><tab>mask = image._masks[k]<tab><tab><tab><tab>mask_group[k] = mask.to_json(run)<tab><tab><tab>all_mask_groups.append(mask_group)<tab><tab>else:<tab><tab><tab>all_mask_groups.append(None)<tab>if all_mask_groups and not all(x is None for x in all_mask_groups):<tab><tab>return all_mask_groups<tab>else:<tab><tab>return False",0,if image . _masks :,if image . _masks is not None :,0.3514988343435983,46.713797772819994,0.4444444444444444
"def disconnect_all(listener):<tab>""""""Disconnect from all signals""""""<tab>for emitter in listener._signal_data.emitters:<tab><tab>for signal in emitter._signal_data.listeners:<tab><tab><tab>emitter._signal_data.listeners[signal] = [<tab><tab><tab><tab>i<tab><tab><tab><tab>for i in emitter._signal_data.listeners[signal]<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]",0,"if getattr ( i , ""__self__"" , None ) != listener",if i is not None,0.012417879185700125,1.044177559991939,0.25
"def wait(self, timeout=None):<tab>if self.returncode is None:<tab><tab>if timeout is None:<tab><tab><tab>msecs = _subprocess.INFINITE<tab><tab>else:<tab><tab><tab>msecs = max(0, int(timeout * 1000 + 0.5))<tab><tab>res = _subprocess.WaitForSingleObject(int(self._handle), msecs)<tab><tab>if res == _subprocess.WAIT_OBJECT_0:<tab><tab><tab>code = _subprocess.GetExitCodeProcess(self._handle)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>code = -signal.SIGTERM<tab><tab><tab>self.returncode = code<tab>return self.returncode",0,if code == TERMINATE :,if code == signal . EINTR :,0.11726065783135259,36.55552228545123,0.4761904761904762
"def set_pbar_fraction(self, frac, progress, stage=None):<tab>gtk.gdk.threads_enter()<tab>try:<tab><tab>self.is_pulsing = False<tab><tab>self.set_stage_text(stage or _(""Processing...""))<tab><tab>self.pbar.set_text(progress)<tab><tab><IF-STMT><tab><tab><tab>frac = 1.0<tab><tab>if frac < 0:<tab><tab><tab>frac = 0<tab><tab>self.pbar.set_fraction(frac)<tab>finally:<tab><tab>gtk.gdk.threads_leave()",0,if frac > 1 :,if frac is None :,0.06497877230811641,23.643540225079384,0.4444444444444444
"def get_aa_from_codonre(re_aa):<tab>aas = []<tab>m = 0<tab>for i in re_aa:<tab><tab>if i == ""["":<tab><tab><tab>m = -1<tab><tab><tab>aas.append("""")<tab><tab><IF-STMT><tab><tab><tab>m = 0<tab><tab><tab>continue<tab><tab>elif m == -1:<tab><tab><tab>aas[-1] = aas[-1] + i<tab><tab>elif m == 0:<tab><tab><tab>aas.append(i)<tab>return aas",1,"elif i == ""]"" :","elif i == ""]"" :",1.0,100.00000000000004,1.0
"def link(token, base_url):<tab>""""""Validation for ``link``.""""""<tab>if get_keyword(token) == ""none"":<tab><tab>return ""none""<tab>parsed_url = get_url(token, base_url)<tab>if parsed_url:<tab><tab>return parsed_url<tab>function = parse_function(token)<tab>if function:<tab><tab>name, args = function<tab><tab>prototype = (name, [a.type for a in args])<tab><tab>args = [getattr(a, ""value"", a) for a in args]<tab><tab><IF-STMT><tab><tab><tab>return (""attr()"", args[0])",0,"if prototype == ( ""attr"" , [ ""ident"" ] ) :",if len ( args ) == 1 :,0.014690094413619983,5.765477373590325,0.3125
"def on_bt_search_clicked(self, widget):<tab>if self.current_provider is None:<tab><tab>return<tab>query = self.en_query.get_text()<tab>@self.obtain_podcasts_with<tab>def load_data():<tab><tab>if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH:<tab><tab><tab>return self.current_provider.on_search(query)<tab><tab><IF-STMT><tab><tab><tab>return self.current_provider.on_url(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_FILE:<tab><tab><tab>return self.current_provider.on_file(query)",0,elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,elif self . current_provider . kind == directory . Provider .PROVIDER_URL :,0.628588575094944,100.00000000000004,1.0
"def test_handle_single(self):<tab>self.skipTest(<tab><tab>""Pops up windows and needs user input.. so disabled.""<tab><tab>""Still worth keeping whilst we don't have unit tests ""<tab><tab>""for all plugins.""<tab>)<tab># Ignored...<tab>for id_, plugin in self.plugins.items():<tab><tab><IF-STMT><tab><tab><tab>self.h.plugin_enable(plugin, None)<tab><tab><tab>self.h.handle(id_, self.lib, self.parent, SONGS)<tab><tab><tab>self.h.plugin_disable(plugin)",0,if self . h . plugin_handle ( plugin ) :,if self . h . is_plugin_enabled ( plugin ) :,0.5803088707179008,48.41524713034602,1.0
"def __repr__(self):<tab>attrs = []<tab>for k in self._keydata:<tab><tab><IF-STMT><tab><tab><tab>attrs.append(""p(%d)"" % (self.size() + 1,))<tab><tab>elif hasattr(self, k):<tab><tab><tab>attrs.append(k)<tab>if self.has_private():<tab><tab>attrs.append(""private"")<tab># PY3K: This is meant to be text, do not change to bytes (data)<tab>return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))",1,"if k == ""p"" :","if k == ""p"" :",0.75,100.00000000000004,1.0
"def apply(self, node, code, required):<tab>yield ""try:""<tab>yield from self.iterIndented(code)<tab>yield ""<tab>pass""<tab>yield ""except {}:"".format(self.exceptionString)<tab>outputVariables = node.getOutputSocketVariables()<tab>for i, s in enumerate(node.outputs):<tab><tab><IF-STMT><tab><tab><tab>if hasattr(s, ""getDefaultValueCode""):<tab><tab><tab><tab>yield f""<tab>{outputVariables[s.identifier]} = {s.getDefaultValueCode()}""<tab><tab><tab>else:<tab><tab><tab><tab>yield f""<tab>{outputVariables[s.identifier]} = self.outputs[{i}].getDefaultValue()""<tab>yield ""<tab>pass""",0,if s . identifier in required :,if s . identifier in outputVariables :,0.574113272471593,64.34588841607616,0.7142857142857143
"def __import__(name, globals=None, locals=None, fromlist=(), level=0):<tab>module = orig___import__(name, globals, locals, fromlist, level)<tab>if fromlist and module.__name__ in modules:<tab><tab>if ""*"" in fromlist:<tab><tab><tab>fromlist = list(fromlist)<tab><tab><tab>fromlist.remove(""*"")<tab><tab><tab>fromlist.extend(getattr(module, ""__all__"", []))<tab><tab>for x in fromlist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>from_name = ""{}.{}"".format(module.__name__, x)<tab><tab><tab><tab>if from_name in modules:<tab><tab><tab><tab><tab>importlib.import_module(from_name)<tab>return module",0,"if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :",if x != module . __name__ :,0.04339816210773184,3.3383922484634225,0.19806763285024154
"def _consume_msg(self):<tab>ws = self._ws<tab>try:<tab><tab>while True:<tab><tab><tab>r = await ws.recv()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r = r.decode(""utf-8"")<tab><tab><tab>msg = json.loads(r)<tab><tab><tab>stream = msg.get(""stream"")<tab><tab><tab>if stream is not None:<tab><tab><tab><tab>await self._dispatch(stream, msg)<tab>except websockets.WebSocketException as wse:<tab><tab>logging.warn(wse)<tab><tab>await self.close()<tab><tab>asyncio.ensure_future(self._ensure_ws())",1,"if isinstance ( r , bytes ) :","if isinstance ( r , bytes ) :",0.75,100.00000000000004,1.0
"def add_source(self, source, name=None):<tab>""""""Adds a new data source to an existing provider.""""""<tab>if self.randomize:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Cannot add a non-shuffleable source to an ""<tab><tab><tab><tab>""already shuffled provider.""<tab><tab><tab>)<tab>super().add_source(source, name=name)<tab>if self.randomize is True:<tab><tab>self._shuffle_len = self.entries",0,if not source . can_shuffle ( ) :,if source in self . entries :,0.020676460041600547,6.050259138270144,0.25
"def __str__(self):<tab>buf = [""""]<tab>if self.fileName:<tab><tab>buf.append(self.fileName + "":"")<tab>if self.line != -1:<tab><tab>if not self.fileName:<tab><tab><tab>buf.append(""line "")<tab><tab>buf.append(str(self.line))<tab><tab><IF-STMT><tab><tab><tab>buf.append("":"" + str(self.column))<tab><tab>buf.append("":"")<tab>buf.append("" "")<tab>return str("""").join(buf)",1,if self . column != - 1 :,if self . column != - 1 :,0.75,100.00000000000004,1.0
"def has_bad_headers(self):<tab>headers = [self.sender, self.reply_to] + self.recipients<tab>for header in headers:<tab><tab>if _has_newline(header):<tab><tab><tab>return True<tab>if self.subject:<tab><tab>if _has_newline(self.subject):<tab><tab><tab>for linenum, line in enumerate(self.subject.split(""\r\n"")):<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if linenum > 0 and line[0] not in ""\t "":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if _has_newline(line):<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>return False",0,if len ( line . strip ( ) ) == 0 :,"if linenum == 0 and line [ 0 ] not in ""\t"" :",0.022534555098719624,10.123734869668828,0.1769230769230769
"def scanHexEscape(self, prefix):<tab>code = 0<tab>leng = 4 if (prefix == ""u"") else 2<tab>for i in xrange(leng):<tab><tab><IF-STMT><tab><tab><tab>ch = self.source[self.index]<tab><tab><tab>self.index += 1<tab><tab><tab>code = code * 16 + HEX_CONV[ch]<tab><tab>else:<tab><tab><tab>return """"<tab>return unichr(code)",0,if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,if self . index < len ( self . source ) :,0.46075748118399973,27.272095638120035,0.3111111111111111
"def _get_table_info(self, table_name):<tab>table_addr = self.addr_space.profile.get_symbol(table_name)<tab>table_size = self._get_table_info_distorm()<tab><IF-STMT><tab><tab>table_size = self._get_table_info_other(table_addr, table_name)<tab><tab>if table_size == 0:<tab><tab><tab>debug.error(""Unable to get system call table size"")<tab>return [table_addr, table_size]",1,if table_size == 0 :,if table_size == 0 :,0.75,100.00000000000004,1.0
"def format_file_path(filepath):<tab>""""""Formats a path as absolute and with the correct platform separator.""""""<tab>try:<tab><tab>is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN.match(filepath)<tab><tab>filepath = os.path.realpath(os.path.abspath(filepath))<tab><tab>filepath = re.sub(BACKSLASH_REPLACE_PATTERN, ""/"", filepath)<tab><tab>is_windows_drive = WINDOWS_DRIVE_PATTERN.match(filepath)<tab><tab><IF-STMT><tab><tab><tab>filepath = filepath.capitalize()<tab><tab>if is_windows_network_mount:<tab><tab><tab># Add back a / to the front, since the previous modifications<tab><tab><tab># will have replaced any double slashes with single<tab><tab><tab>filepath = ""/"" + filepath<tab>except:<tab><tab>pass<tab>return filepath",1,if is_windows_drive :,if is_windows_drive :,0.5311706625951745,1e-10,1.0
"def _match(self, cre, s):<tab># Run compiled regular expression match method on 's'.<tab># Save result, return success.<tab>self.mo = cre.match(s)<tab>if __debug__:<tab><tab><IF-STMT><tab><tab><tab>self._mesg(""\tmatched r'%r' => %r"" % (cre.pattern, self.mo.groups()))<tab>return self.mo is not None",0,if self . mo is not None and self . debug >= 5 :,if self . mo is not None :,0.35772979857325127,36.24372413507827,0.6333333333333333
"def reload_sanitize_allowlist(self, explicit=True):<tab>self.sanitize_allowlist = []<tab>try:<tab><tab>with open(self.sanitize_allowlist_file) as f:<tab><tab><tab>for line in f.readlines():<tab><tab><tab><tab>if not line.startswith(""#""):<tab><tab><tab><tab><tab>self.sanitize_allowlist.append(line.strip())<tab>except OSError:<tab><tab><IF-STMT><tab><tab><tab>log.warning(<tab><tab><tab><tab>""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."",<tab><tab><tab><tab>self.sanitize_allowlist_file,<tab><tab><tab>)",1,if explicit :,if explicit :,0.5311706625951745,1e-10,1.0
"def conj(self):<tab>dtype = self.dtype<tab>if issubclass(self.dtype.type, np.complexfloating):<tab><tab>if not self.flags.forc:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""only contiguous arrays may "" ""be used as arguments to this operation""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>order = ""F""<tab><tab>else:<tab><tab><tab>order = ""C""<tab><tab>result = self._new_like_me(order=order)<tab><tab>func = elementwise.get_conj_kernel(dtype)<tab><tab>func.prepared_async_call(<tab><tab><tab>self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size<tab><tab>)<tab><tab>return result<tab>else:<tab><tab>return self",0,if self . flags . f_contiguous :,if self . flags . f :,0.574113272471593,63.191456189157286,0.7714285714285715
"def scan_spec_conf(self, conf):<tab>if ""metadata"" in conf:<tab><tab>if ""annotations"" in conf[""metadata""] and conf[""metadata""].get(""annotations""):<tab><tab><tab>for annotation in conf[""metadata""][""annotations""]:<tab><tab><tab><tab>for key in annotation:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>if (<tab><tab><tab><tab><tab><tab><tab>""docker/default"" in annotation[key]<tab><tab><tab><tab><tab><tab><tab>or ""runtime/default"" in annotation[key]<tab><tab><tab><tab><tab><tab>):<tab><tab><tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",0,"if ""seccomp.security.alpha.kubernetes.io/defaultProfileName"" in key :","if key . startswith ( ""docker"" ) :",0.028001459970687266,3.2612121198882003,0.4
"def test_error_through_destructor(self):<tab># Test that the exception state is not modified by a destructor,<tab># even if close() fails.<tab>rawio = self.CloseFailureIO()<tab>with support.catch_unraisable_exception() as cm:<tab><tab>with self.assertRaises(AttributeError):<tab><tab><tab>self.tp(rawio).xyzzy<tab><tab>if not IOBASE_EMITS_UNRAISABLE:<tab><tab><tab>self.assertIsNone(cm.unraisable)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(cm.unraisable.exc_type, OSError)",1,elif cm . unraisable is not None :,elif cm . unraisable is not None :,0.75,100.00000000000004,1.0
"def _dumpf(frame):<tab>if frame is None:<tab><tab>return ""<None>""<tab>else:<tab><tab>addn = ""(with trace!)""<tab><tab><IF-STMT><tab><tab><tab>addn = "" **No Trace Set **""<tab><tab>return ""Frame at %d, file %s, line: %d%s"" % (<tab><tab><tab>id(frame),<tab><tab><tab>frame.f_code.co_filename,<tab><tab><tab>frame.f_lineno,<tab><tab><tab>addn,<tab><tab>)",0,if frame . f_trace is None :,if frame . f_trace :,0.28093026462960746,63.191456189157286,0.55
"def containsBadbytes(self, value, bytecount=4):<tab>for b in self.badbytes:<tab><tab>tmp = value<tab><tab><IF-STMT><tab><tab><tab>b = ord(b)<tab><tab>for i in range(bytecount):<tab><tab><tab>if (tmp & 0xFF) == b:<tab><tab><tab><tab>return True<tab><tab><tab>tmp >>= 8<tab>return False",0,if type ( b ) == str :,"if isinstance ( b , int ) :",0.03779162928217515,12.256200970377108,0.42857142857142855
"def _set_peer_statuses(self):<tab>""""""Set peer statuses.""""""<tab>cutoff = time.time() - STALE_SECS<tab>for peer in self.peers:<tab><tab><IF-STMT><tab><tab><tab>peer.status = PEER_BAD<tab><tab>elif peer.last_good > cutoff:<tab><tab><tab>peer.status = PEER_GOOD<tab><tab>elif peer.last_good:<tab><tab><tab>peer.status = PEER_STALE<tab><tab>else:<tab><tab><tab>peer.status = PEER_NEVER",0,if peer . bad :,if not peer . last_good :,0.060348847821073665,13.134549472120788,0.4
"def afterTest(self, test):<tab>try:<tab><tab># If the browser window is still open, close it now.<tab><tab>self.driver.quit()<tab>except AttributeError:<tab><tab>pass<tab>except Exception:<tab><tab>pass<tab>if self.options.headless:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.display.stop()<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",0,if self . headless_active :,if self . display :,0.39477865547525276,28.641904579795423,0.7
"def _written_variables_in_proxy(self, contract):<tab>variables = []<tab>if contract.is_upgradeable:<tab><tab>variables_name_written_in_proxy = self._variable_written_in_proxy()<tab><tab><IF-STMT><tab><tab><tab>variables_in_contract = [<tab><tab><tab><tab>contract.get_state_variable_from_name(v)<tab><tab><tab><tab>for v in variables_name_written_in_proxy<tab><tab><tab>]<tab><tab><tab>variables_in_contract = [v for v in variables_in_contract if v]<tab><tab><tab>variables += variables_in_contract<tab>return list(set(variables))",0,if variables_name_written_in_proxy :,if variables_name_written_in_proxy is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def _available_symbols(self, scoperef, expr):<tab>cplns = []<tab>found_names = set()<tab>while scoperef:<tab><tab>elem = self._elem_from_scoperef(scoperef)<tab><tab>for child in elem:<tab><tab><tab>name = child.get(""name"", """")<tab><tab><tab>if name.startswith(expr):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>found_names.add(name)<tab><tab><tab><tab><tab>ilk = child.get(""ilk"") or child.tag<tab><tab><tab><tab><tab>cplns.append((ilk, name))<tab><tab>scoperef = self.parent_scoperef_from_scoperef(scoperef)<tab><tab>if not scoperef:<tab><tab><tab>break<tab>return sorted(cplns, key=operator.itemgetter(1))",1,if name not in found_names :,if name not in found_names :,0.75,100.00000000000004,1.0
"def get_resource_public_actions(resource_class):<tab>resource_class_members = inspect.getmembers(resource_class)<tab>resource_methods = {}<tab>for name, member in resource_class_members:<tab><tab>if not name.startswith(""_""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not name.startswith(""wait_until""):<tab><tab><tab><tab><tab>if is_resource_action(member):<tab><tab><tab><tab><tab><tab>resource_methods[name] = member<tab>return resource_methods",0,if not name [ 0 ] . isupper ( ) :,if inspect . isclass ( member ) :,0.02612309242726822,9.545138913210204,0.2136752136752137
def UpdateControlState(self):<tab>active = self.demoModules.GetActiveID()<tab># Update the radio/restore buttons<tab>for moduleID in self.radioButtons:<tab><tab>btn = self.radioButtons[moduleID]<tab><tab><IF-STMT><tab><tab><tab>btn.SetValue(True)<tab><tab>else:<tab><tab><tab>btn.SetValue(False)<tab><tab>if self.demoModules.Exists(moduleID):<tab><tab><tab>btn.Enable(True)<tab><tab><tab>if moduleID == modModified:<tab><tab><tab><tab>self.btnRestore.Enable(True)<tab><tab>else:<tab><tab><tab>btn.Enable(False)<tab><tab><tab>if moduleID == modModified:<tab><tab><tab><tab>self.btnRestore.Enable(False),1,if moduleID == active :,if moduleID == active :,0.75,100.00000000000004,1.0
"def test_controlcharacters(self):<tab>for i in range(128):<tab><tab>c = chr(i)<tab><tab>testString = ""string containing %s"" % c<tab><tab>if i >= 32 or c in ""\r\n\t"":<tab><tab><tab># \r, \n and \t are the only legal control chars in XML<tab><tab><tab>data = plistlib.dumps(testString, fmt=plistlib.FMT_XML)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(plistlib.loads(data), testString)<tab><tab>else:<tab><tab><tab>with self.assertRaises(ValueError):<tab><tab><tab><tab>plistlib.dumps(testString, fmt=plistlib.FMT_XML)<tab><tab>plistlib.dumps(testString, fmt=plistlib.FMT_BINARY)",0,"if c != ""\r"" :",if data :,0.03549272049582243,1e-10,0.5
"def remove_usernames(self, username: SLT[str]) -> None:<tab>with self.__lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""Can't set {self.username_name} in conjunction with (already set) ""<tab><tab><tab><tab>f""{self.chat_id_name}s.""<tab><tab><tab>)<tab><tab>parsed_username = self._parse_username(username)<tab><tab>self._usernames -= parsed_username",0,if self . _chat_ids :,if self . _usernames :,0.39477865547525276,38.49815007763549,1.0
"def get_size(self, shape_info):<tab># The size is the data, that have constant size.<tab>state = np.random.RandomState().get_state()<tab>size = 0<tab>for elem in state:<tab><tab>if isinstance(elem, str):<tab><tab><tab>size += len(elem)<tab><tab>elif isinstance(elem, np.ndarray):<tab><tab><tab>size += elem.size * elem.itemsize<tab><tab><IF-STMT><tab><tab><tab>size += np.dtype(""int"").itemsize<tab><tab>elif isinstance(elem, float):<tab><tab><tab>size += np.dtype(""float"").itemsize<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab>return size",1,"elif isinstance ( elem , int ) :","elif isinstance ( elem , int ) :",0.75,100.00000000000004,1.0
"def before_step(self, step, feed_dict):<tab>if step == 0:<tab><tab>for _type, mem in self.memories.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.gan.session.run(tf.assign(mem[""var""], mem[""source""]))",1,"if ""var"" in mem and ""source"" in mem :","if ""var"" in mem and ""source"" in mem :",1.0,100.00000000000004,1.0
"def write(self, *bits):<tab>for bit in bits:<tab><tab>if not self.bytestream:<tab><tab><tab>self.bytestream.append(0)<tab><tab>byte = self.bytestream[self.bytenum]<tab><tab><IF-STMT><tab><tab><tab>if self.bytenum == len(self.bytestream) - 1:<tab><tab><tab><tab>byte = 0<tab><tab><tab><tab>self.bytestream += bytes([byte])<tab><tab><tab>self.bytenum += 1<tab><tab><tab>self.bitnum = 0<tab><tab>mask = 2 ** self.bitnum<tab><tab>if bit:<tab><tab><tab>byte |= mask<tab><tab>else:<tab><tab><tab>byte &= ~mask<tab><tab>self.bytestream[self.bytenum] = byte<tab><tab>self.bitnum += 1",0,if self . bitnum == 8 :,if byte :,0.020447728119319098,1e-10,0.2916666666666667
"def _validate_parameter_range(self, value_hp, parameter_range):<tab>""""""Placeholder docstring""""""<tab>for (<tab><tab>parameter_range_key,<tab><tab>parameter_range_value,<tab>) in parameter_range.__dict__.items():<tab><tab>if parameter_range_key == ""scaling_type"":<tab><tab><tab>continue<tab><tab># Categorical ranges<tab><tab><IF-STMT><tab><tab><tab>for categorical_value in parameter_range_value:<tab><tab><tab><tab>value_hp.validate(categorical_value)<tab><tab># Continuous, Integer ranges<tab><tab>else:<tab><tab><tab>value_hp.validate(parameter_range_value)",0,"if isinstance ( parameter_range_value , list ) :","elif isinstance ( parameter_range_value , list ) :",0.40018302522632676,90.36020036098445,0.6
"def _trackA(self, tracks):<tab>try:<tab><tab>track, start, end = self.featureA<tab><tab>assert track in tracks<tab><tab>return track<tab>except TypeError:<tab><tab>for track in tracks:<tab><tab><tab>for feature_set in track.get_sets():<tab><tab><tab><tab>if hasattr(feature_set, ""features""):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return track<tab><tab>return None",0,if self . featureA in feature_set . features . values ( ) :,if feature_set . features == self . featureA :,0.12589106180243456,34.91665073071338,0.26785714285714285
"def walk(directory, path_so_far):<tab>for name in sorted(os.listdir(directory)):<tab><tab>if any(fnmatch(name, pattern) for pattern in basename_ignore):<tab><tab><tab>continue<tab><tab>path = path_so_far + ""/"" + name if path_so_far else name<tab><tab>if any(fnmatch(path, pattern) for pattern in path_ignore):<tab><tab><tab>continue<tab><tab>full_name = os.path.join(directory, name)<tab><tab><IF-STMT><tab><tab><tab>for file_path in walk(full_name, path):<tab><tab><tab><tab>yield file_path<tab><tab>elif os.path.isfile(full_name):<tab><tab><tab>yield path",1,if os . path . isdir ( full_name ) :,if os . path . isdir ( full_name ) :,0.75,100.00000000000004,1.0
"def _poll_ipc_requests(self) -> None:<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>while not self._ipc_requests.empty():<tab><tab><tab>args = self._ipc_requests.get()<tab><tab><tab>try:<tab><tab><tab><tab>for filename in args:<tab><tab><tab><tab><tab>if os.path.isfile(filename):<tab><tab><tab><tab><tab><tab>self.get_editor_notebook().show_file(filename)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>logger.exception(""Problem processing ipc request"", exc_info=e)<tab><tab>self.become_active_window()<tab>finally:<tab><tab>self.after(50, self._poll_ipc_requests)",1,if self . _ipc_requests . empty ( ) :,if self . _ipc_requests . empty ( ) :,0.75,100.00000000000004,1.0
"def test_read1(self):<tab>self.test_write()<tab>blocks = []<tab>nread = 0<tab>with gzip.GzipFile(self.filename, ""r"") as f:<tab><tab>while True:<tab><tab><tab>d = f.read1()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>blocks.append(d)<tab><tab><tab>nread += len(d)<tab><tab><tab># Check that position was updated correctly (see issue10791).<tab><tab><tab>self.assertEqual(f.tell(), nread)<tab>self.assertEqual(b"""".join(blocks), data1 * 50)",1,if not d :,if not d :,0.75,100.00000000000004,1.0
"def _target_generator(self):<tab>if self._internal_target_generator is None:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>from ....model_zoo.rcnn.rpn.rpn_target import RPNTargetGenerator<tab><tab>self._internal_target_generator = RPNTargetGenerator(<tab><tab><tab>num_sample=self._num_sample,<tab><tab><tab>pos_iou_thresh=self._pos_iou_thresh,<tab><tab><tab>neg_iou_thresh=self._neg_iou_thresh,<tab><tab><tab>pos_ratio=self._pos_ratio,<tab><tab><tab>stds=self._box_norm,<tab><tab><tab>**self._kwargs<tab><tab>)<tab><tab>return self._internal_target_generator<tab>else:<tab><tab>return self._internal_target_generator",0,if self . _net_none :,if self . _num_sample == 0 :,0.11726065783135259,25.965358893403383,0.7222222222222222
"def time_left(self):<tab>""""""Return how many seconds are left until the timeout expires""""""<tab>if self.is_non_blocking:<tab><tab>return 0<tab>elif self.is_infinite:<tab><tab>return None<tab>else:<tab><tab>delta = self.target_time - self.TIME()<tab><tab><IF-STMT><tab><tab><tab># clock jumped, recalculate<tab><tab><tab>self.target_time = self.TIME() + self.duration<tab><tab><tab>return self.duration<tab><tab>else:<tab><tab><tab>return max(0, delta)",0,if delta > self . duration :,if delta < 0 :,0.04240600921794552,15.848738972120703,0.4761904761904762
"def _decorator(cls):<tab>for name, meth in inspect.getmembers(cls, inspect.isroutine):<tab><tab>if name not in cls.__dict__:<tab><tab><tab>continue<tab><tab>if name != ""__init__"":<tab><tab><tab>if not private and name.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>setattr(cls, name, decorator(meth))<tab>return cls",0,if name in butnot :,if not inspect . isclass ( meth ) :,0.0252788731101473,5.669791110976001,0.20987654320987653
"def load_vocab(vocab_file: str) -> List:<tab>""""""Loads a vocabulary file into a dictionary.""""""<tab>vocab = collections.OrderedDict()<tab>with io.open(vocab_file, ""r"", encoding=""UTF-8"") as file:<tab><tab>for num, line in enumerate(file):<tab><tab><tab>items = convert_to_unicode(line.strip()).split(""\t"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>token = items[0]<tab><tab><tab>index = items[1] if len(items) == 2 else num<tab><tab><tab>token = token.strip()<tab><tab><tab>vocab[token] = int(index)<tab><tab>return vocab",1,if len ( items ) > 2 :,if len ( items ) > 2 :,0.75,100.00000000000004,1.0
"def slice_fill(self, slice_):<tab>""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true""<tab>if isinstance(self.indexes, int):<tab><tab>new_slice_ = [0]<tab><tab>offset = 0<tab>else:<tab><tab>new_slice_ = [slice_[0]]<tab><tab>offset = 1<tab>for i in range(1, len(self.nums)):<tab><tab><IF-STMT><tab><tab><tab>new_slice_.append(0)<tab><tab>elif offset < len(slice_):<tab><tab><tab>new_slice_.append(slice_[offset])<tab><tab><tab>offset += 1<tab>new_slice_ += slice_[offset:]<tab>return new_slice_",0,if self . squeeze_dims [ i ] :,if slice_ [ i ] == 0 :,0.07991956560314192,18.575057999133595,0.4
"def check_update_function(url, folder, update_setter, version_setter, auto):<tab>remote_version = urllib.urlopen(url).read()<tab>if remote_version.isdigit():<tab><tab>local_version = get_local_timestamp(folder)<tab><tab>if remote_version > local_version:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>update_setter.set_value(True)<tab><tab><tab>version_setter.set_value(remote_version)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return False",1,if auto :,if auto :,0.5311706625951745,1e-10,1.0
"def iter_content(self, chunk_size_bytes):<tab>while True:<tab><tab>try:<tab><tab><tab>data = self._fp.read(chunk_size_bytes)<tab><tab>except IOError as e:<tab><tab><tab>raise Fetcher.PermanentError(<tab><tab><tab><tab>""Problem reading chunk from {}: {}"".format(self._fp.name, e)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>yield data",1,if not data :,if not data :,0.75,100.00000000000004,1.0
"def gvariant_args(args: List[Any]) -> str:<tab>""""""Convert args into gvariant.""""""<tab>gvariant = """"<tab>for arg in args:<tab><tab>if isinstance(arg, bool):<tab><tab><tab>gvariant += "" {}"".format(str(arg).lower())<tab><tab>elif isinstance(arg, (int, float)):<tab><tab><tab>gvariant += f"" {arg}""<tab><tab><IF-STMT><tab><tab><tab>gvariant += f' ""{arg}""'<tab><tab>else:<tab><tab><tab>gvariant += f"" {arg!s}""<tab>return gvariant.lstrip()",1,"elif isinstance ( arg , str ) :","elif isinstance ( arg , str ) :",0.75,100.00000000000004,1.0
"def _element_keywords(cls, backend, elements=None):<tab>""Returns a dictionary of element names to allowed keywords""<tab>if backend not in Store.loaded_backends():<tab><tab>return {}<tab>mapping = {}<tab>backend_options = Store.options(backend)<tab>elements = elements if elements is not None else backend_options.keys()<tab>for element in elements:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>element = element if isinstance(element, tuple) else (element,)<tab><tab>element_keywords = []<tab><tab>options = backend_options[""."".join(element)]<tab><tab>for group in Options._option_groups:<tab><tab><tab>element_keywords.extend(options[group].allowed_keywords)<tab><tab>mapping[element[0]] = element_keywords<tab>return mapping",0,"if ""."" in element :","if isinstance ( element , str ) :",0.028001459970687266,7.267884212102741,0.48148148148148145
"def setup_parameter_node(self, param_node):<tab>if param_node.bl_idname == ""SvNumberNode"":<tab><tab>if self.use_prop or self.get_prop_name():<tab><tab><tab>value = self.sv_get()[0][0]<tab><tab><tab>print(""V"", value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>param_node.selected_mode = ""int""<tab><tab><tab><tab>param_node.int_ = value<tab><tab><tab>elif isinstance(value, float):<tab><tab><tab><tab>param_node.selected_mode = ""float""<tab><tab><tab><tab>param_node.float_ = value",1,"if isinstance ( value , int ) :","if isinstance ( value , int ) :",0.75,100.00000000000004,1.0
"def _get_oshape(indices_shape, depth, axis):<tab>oshape = []<tab>true_axis = len(indices_shape) if axis == -1 else axis<tab>ndim = len(indices_shape) + 1<tab>indices_index = 0<tab>for i in range(0, ndim):<tab><tab><IF-STMT><tab><tab><tab>oshape.append(depth)<tab><tab>else:<tab><tab><tab>oshape.append(indices_shape[indices_index])<tab><tab><tab>indices_index += 1<tab>return oshape",0,if i == true_axis :,if indices_shape [ indices_index ] == true_axis :,0.1102731445124358,33.64932442330152,0.6410256410256411
"def check(self, value):<tab>value = String.check(self, value)<tab>if isinstance(value, str):<tab><tab>value = value.upper()<tab><tab>for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]):<tab><tab><tab># e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value[len(prefix) :]<tab><tab><tab>value = value.lstrip(""_"")<tab><tab>if hasattr(self.group, value):<tab><tab><tab>return getattr(self.group, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""No such constant: %s_%s"" % (self.prefix, value))<tab>else:<tab><tab>return value",1,if value . startswith ( prefix ) :,if value . startswith ( prefix ) :,0.75,100.00000000000004,1.0
"def shuffle_unison_inplace(list_of_lists, random_state=None):<tab>if list_of_lists:<tab><tab>assert all(len(l) == len(list_of_lists[0]) for l in list_of_lists)<tab><tab><IF-STMT><tab><tab><tab>random_state.permutation(len(list_of_lists[0]))<tab><tab>else:<tab><tab><tab>p = np.random.permutation(len(list_of_lists[0]))<tab><tab>return [l[p] for l in list_of_lists]<tab>return None",0,if random_state is not None :,if random_state :,0.050438393472541504,1e-10,0.3142857142857143
"def _load_module(self):<tab>spec = self.default_module_spec<tab>module_identifier = self.module_identifier<tab>if module_identifier:<tab><tab>impls = self.get_module_implementation_map()<tab><tab><IF-STMT><tab><tab><tab>raise ModuleNotFound(<tab><tab><tab><tab>""Invalid module identifier %r in %s""<tab><tab><tab><tab>% (module_identifier, force_ascii(repr(self)))<tab><tab><tab>)<tab><tab>spec = impls[module_identifier]<tab>cls = load(<tab><tab>spec, context_explanation=""Loading module for %s"" % force_ascii(repr(self))<tab>)<tab>options = getattr(self, self.module_options_field, None) or {}<tab>return cls(self, options)",1,if module_identifier not in impls :,if module_identifier not in impls :,0.75,100.00000000000004,1.0
"def get_data(self, state=None, request=None):<tab>if self.load_in_memory:<tab><tab>data, shapes = self._in_memory_get_data(state, request)<tab>else:<tab><tab>data, shapes = self._out_of_memory_get_data(state, request)<tab>for i in range(len(data)):<tab><tab><IF-STMT><tab><tab><tab>if isinstance(request, numbers.Integral):<tab><tab><tab><tab>data[i] = data[i].reshape(shapes[i])<tab><tab><tab>else:<tab><tab><tab><tab>for j in range(len(data[i])):<tab><tab><tab><tab><tab>data[i][j] = data[i][j].reshape(shapes[i][j])<tab>return tuple(data)",0,if shapes [ i ] is not None :,if i in shapes :,0.017732312663147662,6.787957387517878,0.21875
"def resolve_credential_keys(m_keys, keys):<tab>res = []<tab>for k in m_keys:<tab><tab>if k[""c7n:match-type""] == ""credential"":<tab><tab><tab>c_date = parse_date(k[""last_rotated""])<tab><tab><tab>for ak in keys:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ak = dict(ak)<tab><tab><tab><tab><tab>ak[""c7n:match-type""] = ""access""<tab><tab><tab><tab><tab>if ak not in res:<tab><tab><tab><tab><tab><tab>res.append(ak)<tab><tab>elif k not in res:<tab><tab><tab>res.append(k)<tab>return res",0,"if c_date == ak [ ""CreateDate"" ] :","if isinstance ( ak , dict ) andak [ ""c7n:match-type"" ] == ""access"" :",0.07924686361870635,6.962249700749937,0.30952380952380953
"def _is_legacy_mode(self, node):<tab>""""""Checks if the ``ast.Call`` node's keywords signal using legacy mode.""""""<tab>script_mode = False<tab>py_version = ""py2""<tab>for kw in node.keywords:<tab><tab><IF-STMT><tab><tab><tab>script_mode = (<tab><tab><tab><tab>bool(kw.value.value) if isinstance(kw.value, ast.NameConstant) else True<tab><tab><tab>)<tab><tab>if kw.arg == ""py_version"":<tab><tab><tab>py_version = kw.value.s if isinstance(kw.value, ast.Str) else ""py3""<tab>return not (py_version.startswith(""py3"") or script_mode)",0,"if kw . arg == ""script_mode"" :","if isinstance ( kw . value , ast . Name ) :",0.09526719556548166,8.054496384843702,0.225
"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]:<tab>statuses_by_refs = {u: [] for u in upstream}<tab>events = self.events or []  # type: List[V1EventTrigger]<tab>for e in events:<tab><tab>entity_ref = contexts_refs.get_entity_ref(e.ref)<tab><tab>if not entity_ref:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for kind in e.kinds:<tab><tab><tab>status = V1EventKind.events_statuses_mapping.get(kind)<tab><tab><tab>if status:<tab><tab><tab><tab>statuses_by_refs[entity_ref].append(status)<tab>return statuses_by_refs",0,if entity_ref not in statuses_by_refs :,if entity_ref in statuses_by_refs :,0.23319028329115196,74.26141117870938,0.4642857142857143
"def items(self):<tab>dict = {}<tab>for userdir in self.XDG_DIRS.keys():<tab><tab>prefix = self.get(userdir).strip('""').split(""/"")[0]<tab><tab><IF-STMT><tab><tab><tab>path = (<tab><tab><tab><tab>os.getenv(""HOME"")<tab><tab><tab><tab>+ ""/""<tab><tab><tab><tab>+ ""/"".join(self.get(userdir).strip('""').split(""/"")[1:])<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>path = self.get(userdir).strip('""')<tab><tab>dict[userdir] = path<tab>return dict.items()",0,if prefix :,"if prefix == ""/"" :",0.09791453445388575,1e-10,1.0
"def clean_objects(string, common_attributes):<tab>""""""Return object and attribute lists""""""<tab>string = clean_string(string)<tab>words = string.split()<tab>if len(words) > 1:<tab><tab>prefix_words_are_adj = True<tab><tab>for att in words[:-1]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prefix_words_are_adj = False<tab><tab>if prefix_words_are_adj:<tab><tab><tab>return words[-1:], words[:-1]<tab><tab>else:<tab><tab><tab>return [string], []<tab>else:<tab><tab>return [string], []",1,if att not in common_attributes :,if att not in common_attributes :,0.75,100.00000000000004,1.0
"def extract_custom(extractor, *args, **kw):<tab>for match in extractor(*args, **kw):<tab><tab>msg = match[2]<tab><tab><IF-STMT><tab><tab><tab>unused = (<tab><tab><tab><tab>""<unused singular (hash=%s)>"" % md5(msg[1].encode(""utf8"")).hexdigest()<tab><tab><tab>)<tab><tab><tab>msg = (unused, msg[1], msg[2])<tab><tab><tab>match = (match[0], match[1], msg, match[3])<tab><tab>yield match",0,"if isinstance ( msg , tuple ) and msg [ 0 ] == """" :","if isinstance ( msg , tuple ) :",0.28184453892234934,28.22664073782293,0.6441102756892231
"def test_convex_decomposition(self):<tab>mesh = g.get_mesh(""quadknot.obj"")<tab>engines = [(""vhacd"", g.trimesh.interfaces.vhacd.exists)]<tab>for engine, exists in engines:<tab><tab><IF-STMT><tab><tab><tab>g.log.warning(""skipping convex decomposition engine %s"", engine)<tab><tab><tab>continue<tab><tab>g.log.info(""Testing convex decomposition with engine %s"", engine)<tab><tab>meshes = mesh.convex_decomposition(engine=engine)<tab><tab>self.assertTrue(len(meshes) > 1)<tab><tab>for m in meshes:<tab><tab><tab>self.assertTrue(m.is_watertight)<tab><tab>g.log.info(""convex decomposition succeeded with %s"", engine)",1,if not exists :,if not exists :,0.75,100.00000000000004,1.0
"def _to_string_infix(self, ostream, idx, verbose):<tab>if verbose:<tab><tab>ostream.write("" , "")<tab>else:<tab><tab>hasConst = not (<tab><tab><tab>self._const.__class__ in native_numeric_types and self._const == 0<tab><tab>)<tab><tab>if hasConst:<tab><tab><tab>idx -= 1<tab><tab>_l = self._coef[id(self._args[idx])]<tab><tab>_lt = _l.__class__<tab><tab><IF-STMT><tab><tab><tab>ostream.write("" - "")<tab><tab>else:<tab><tab><tab>ostream.write("" + "")",0,if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,if _lt == _l :,0.013887228846722825,4.14888267155728,0.2546583850931677
"def get_other(self, data, items):<tab>is_tuple = False<tab>if type(data) == tuple:<tab><tab>data = list(data)<tab><tab>is_tuple = True<tab>if type(data) == list:<tab><tab>m_items = items.copy()<tab><tab>for idx, item in enumerate(items):<tab><tab><tab>if item < 0:<tab><tab><tab><tab>m_items[idx] = len(data) - abs(item)<tab><tab>for i in sorted(set(m_items), reverse=True):<tab><tab><tab>if i < len(data) and i > -1:<tab><tab><tab><tab>del data[i]<tab><tab><IF-STMT><tab><tab><tab>return tuple(data)<tab><tab>else:<tab><tab><tab>return data<tab>else:<tab><tab>return None",1,if is_tuple :,if is_tuple :,0.5311706625951745,1e-10,1.0
"def process_error(self, data):<tab>if data.get(""error""):<tab><tab><IF-STMT><tab><tab><tab>raise AuthCanceled(self, data.get(""error_description"", """"))<tab><tab>raise AuthFailed(self, data.get(""error_description"") or data[""error""])<tab>elif ""denied"" in data:<tab><tab>raise AuthCanceled(self, data[""denied""])",0,"if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :","if ""cancelled"" in data :",0.030511277430735256,7.191374415443219,0.638095238095238
"def tamper(payload, **kwargs):<tab>junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`""<tab>retval = """"<tab>for i, char in enumerate(payload, start=1):<tab><tab>amount = random.randint(10, 15)<tab><tab>if char == "">"":<tab><tab><tab>retval += "">""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == ""<"":<tab><tab><tab>retval += ""<""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab><IF-STMT><tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>else:<tab><tab><tab>retval += char<tab>return retval",0,"elif char == "" "" :","elif char == "">"" :",0.6152978271954442,59.4603557501361,1.0
"def retry_http_digest_auth(self, req, auth):<tab>token, challenge = auth.split("" "", 1)<tab>chal = parse_keqv_list(parse_http_list(challenge))<tab>auth = self.get_authorization(req, chal)<tab>if auth:<tab><tab>auth_val = ""Digest %s"" % auth<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>req.add_unredirected_header(self.auth_header, auth_val)<tab><tab>resp = self.parent.open(req)<tab><tab>return resp",1,"if req . headers . get ( self . auth_header , None ) == auth_val :","if req . headers . get ( self . auth_header , None ) == auth_val :",0.75,100.00000000000004,1.0
"def close(self):<tab>self.selector.close()<tab>if self.sock:<tab><tab>sockname = None<tab><tab>try:<tab><tab><tab>sockname = self.sock.getsockname()<tab><tab>except (socket.error, OSError):<tab><tab><tab>pass<tab><tab>self.sock.close()<tab><tab>if type(sockname) is str:<tab><tab><tab># it was a Unix domain socket, remove it from the filesystem<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(sockname)<tab>self.sock = None",0,if os . path . exists ( sockname ) :,if os . path . isfile ( sockname ) :,0.5803088707179008,65.80370064762461,0.7142857142857143
"def to_nurbs(self, curves):<tab>result = []<tab>for i, c in enumerate(curves):<tab><tab>nurbs = SvNurbsCurve.to_nurbs(c)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(f""Curve #{i} - {c} - can not be converted to NURBS!"")<tab><tab>result.append(nurbs)<tab>return result",1,if nurbs is None :,if nurbs is None :,0.75,100.00000000000004,1.0
"def handle_1_roomid_raffle(self, i):<tab>if i[1] in [""handle_1_room_TV"", ""handle_1_room_captain""]:<tab><tab><IF-STMT><tab><tab><tab>await self.notify(""post_watching_history"", i[0])<tab><tab><tab>await self.notify(i[1], i[0], i[2])<tab>else:<tab><tab>print(""hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh"", i)",0,"if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :","if i [ 2 ] == ""post_watching_history"" :",0.045646369438102186,3.9302710530468823,0.20370370370370372
"def init_ps_var_partition(self):<tab>ps_vars = {}<tab>for v in self._non_embed_vars.values():<tab><tab>if v.name not in self._var_to_ps:<tab><tab><tab>self._var_to_ps[v.name] = string_to_id(v.name, self._ps_num)<tab><tab>ps_id = self._var_to_ps[v.name]<tab><tab><IF-STMT><tab><tab><tab>ps_vars[ps_id] = [v]<tab><tab>else:<tab><tab><tab>ps_vars[ps_id].append(v)<tab>self._ps_vars = ps_vars",1,if ps_id not in ps_vars :,if ps_id not in ps_vars :,0.75,100.00000000000004,1.0
"def get_files(d):<tab>f = []<tab>for root, dirs, files in os.walk(d):<tab><tab>for name in files:<tab><tab><tab>if ""meta-environment"" in root or ""cross-canadian"" in root:<tab><tab><tab><tab>continue<tab><tab><tab>if ""qemux86copy-"" in root or ""qemux86-"" in root:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.append(os.path.join(root, name))<tab>return f",0,"if ""do_build"" not in name and ""do_populate_sdk"" not in name :","if name . endswith ( "".py"" ) :",0.0133745220801175,2.2578913865716657,0.22077922077922077
"def setSelectedLabelState(self, p):  # selected, disabled<tab>c = self.c<tab># g.trace(p,c.edit_widget(p))<tab>if p and c.edit_widget(p):<tab><tab><IF-STMT><tab><tab><tab>g.trace(self.trace_n, c.edit_widget(p), p)<tab><tab><tab># g.trace(g.callers(6))<tab><tab><tab>self.trace_n += 1<tab><tab>self.setDisabledHeadlineColors(p)",0,if 0 :,if self . trace_n < self . trace_count :,0.04309983002500103,1e-10,0.4807692307692308
"def filter_tasks(self, task_types=None, task_states=None, task_text=None):<tab>tasks = self.api.tasks(self.id).get(""tasks"", {})<tab>if tasks and tasks.get(""task""):<tab><tab>return [<tab><tab><tab>Task(self, task)<tab><tab><tab>for task in tasks.get(""task"", [])<tab><tab><tab><IF-STMT><tab><tab><tab>and (not task_states or task[""state""].lower() in task_states)<tab><tab><tab>and (not task_text or task_text.lower() in str(task).lower())<tab><tab>]<tab>else:<tab><tab>return []",0,"if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )","if task [ ""type"" ] . lower ( ) in task_types",0.3913978186576946,59.03987157780682,0.27272727272727276
"def GenerateVector(self, hits, vector, level):<tab>""""""Generate possible hit vectors which match the rules.""""""<tab>for item in hits.get(level, []):<tab><tab><IF-STMT><tab><tab><tab>if item < vector[-1]:<tab><tab><tab><tab>continue<tab><tab><tab>if item > self.max_separation + vector[-1]:<tab><tab><tab><tab>break<tab><tab>new_vector = vector + [item]<tab><tab>if level + 1 == len(hits):<tab><tab><tab>yield new_vector<tab><tab>elif level + 1 < len(hits):<tab><tab><tab>for result in self.GenerateVector(hits, new_vector, level + 1):<tab><tab><tab><tab>yield result",1,if vector :,if vector :,0.5311706625951745,1e-10,1.0
def _transmit_from_storage(self) -> None:<tab>for blob in self.storage.gets():<tab><tab># give a few more seconds for blob lease operation<tab><tab># to reduce the chance of race (for perf consideration)<tab><tab>if blob.lease(self._timeout + 5):<tab><tab><tab>envelopes = [TelemetryItem(**x) for x in blob.get()]<tab><tab><tab>result = self._transmit(list(envelopes))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>blob.lease(1)<tab><tab><tab>else:<tab><tab><tab><tab>blob.delete(),0,if result == ExportResult . FAILED_RETRYABLE :,if result :,0.03885753308224148,1e-10,0.7222222222222222
"def load_dictionary(file):<tab>oui = {}<tab>with open(file, ""r"") as f:<tab><tab>for line in f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = line.split(""(hex)"")<tab><tab><tab><tab>key = data[0].replace(""-"", "":"").lower().strip()<tab><tab><tab><tab>company = data[1].strip()<tab><tab><tab><tab>oui[key] = company<tab>return oui",0,"if ""(hex)"" in line :","if line . startswith ( ""company"" ) :",0.028001459970687266,6.8253021567726675,0.4
"def _yield_minibatches_idx(self, rgen, n_batches, data_ary, shuffle=True):<tab>indices = np.arange(data_ary.shape[0])<tab>if shuffle:<tab><tab>indices = rgen.permutation(indices)<tab>if n_batches > 1:<tab><tab>remainder = data_ary.shape[0] % n_batches<tab><tab><IF-STMT><tab><tab><tab>minis = np.array_split(indices[:-remainder], n_batches)<tab><tab><tab>minis[-1] = np.concatenate((minis[-1], indices[-remainder:]), axis=0)<tab><tab>else:<tab><tab><tab>minis = np.array_split(indices, n_batches)<tab>else:<tab><tab>minis = (indices,)<tab>for idx_batch in minis:<tab><tab>yield idx_batch",0,if remainder :,if len ( indices ) > n_batches :,0.04422835593777517,1e-10,0.38181818181818183
"def canonical_custom_headers(self, headers):<tab>hoi = []<tab>custom_headers = {}<tab>for key in headers:<tab><tab>lk = key.lower()<tab><tab>if headers[key] is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>custom_headers[lk] = "","".join(v.strip() for v in headers.get_all(key))<tab>sorted_header_keys = sorted(custom_headers.keys())<tab>for key in sorted_header_keys:<tab><tab>hoi.append(""%s:%s"" % (key, custom_headers[key]))<tab>return ""\n"".join(hoi)",0,"if lk . startswith ( ""x-amz-"" ) :",if lk not in custom_headers :,0.03526460512979883,9.51934081834847,0.48148148148148145
"def validate(self, data):<tab>if not data.get(""reason""):<tab><tab># If reason is not provided, message is required and can not be<tab><tab># null or blank.<tab><tab>message = data.get(""message"")<tab><tab>if not message:<tab><tab><tab>if ""message"" not in data:<tab><tab><tab><tab>msg = serializers.Field.default_error_messages[""required""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = serializers.Field.default_error_messages[""null""]<tab><tab><tab>else:<tab><tab><tab><tab>msg = serializers.CharField.default_error_messages[""blank""]<tab><tab><tab>raise serializers.ValidationError({""message"": [msg]})<tab>return data",0,elif message is None :,"elif ""message"" not in data :",0.1531108718988399,7.267884212102741,0.25
def tearDown(self):<tab>try:<tab><tab>os.chdir(self.cwd)<tab><tab><IF-STMT><tab><tab><tab>os.remove(self.pythonexe)<tab><tab>test_support.rmtree(self.parent_dir)<tab>finally:<tab><tab>BaseTestCase.tearDown(self),0,if self . pythonexe != sys . executable :,if os . path . isfile ( self . pythonexe ) :,0.12413305271283916,14.991106946711685,0.2136752136752137
"def update(self, value, label):<tab>if self._disabled:<tab><tab>return<tab>try:<tab><tab>self._progress.value = value<tab><tab>self._label.value = label<tab><tab><IF-STMT><tab><tab><tab>self._displayed = True<tab><tab><tab>display_widget(self._widget)<tab>except Exception as e:<tab><tab>self._disabled = True<tab><tab>logger.exception(e)<tab><tab>wandb.termwarn(""Unable to render progress bar, see the user log for details"")",0,if not self . _displayed :,if self . _widget is not None :,0.046132297882334555,21.10534063187263,0.2916666666666667
"def GetBinaryOperationBinder(self, op):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>return self._binaryOperationBinders[op]<tab><tab>b = runtime.SymplBinaryOperationBinder(op)<tab><tab>self._binaryOperationBinders[op] = b<tab>return b",0,if self . _binaryOperationBinders . ContainsKey ( op ) :,if op in self . _binaryOperationBinders :,0.06410035254389929,27.329052280893862,0.3333333333333333
"def apply(self, l, b, evaluation):<tab>""FromDigits[l_, b_]""<tab>if l.get_head_name() == ""System`List"":<tab><tab>value = Integer(0)<tab><tab>for leaf in l.leaves:<tab><tab><tab>value = Expression(""Plus"", Expression(""Times"", value, b), leaf)<tab><tab>return value<tab>elif isinstance(l, String):<tab><tab>value = FromDigits._parse_string(l.get_string_value(), b)<tab><tab><IF-STMT><tab><tab><tab>evaluation.message(""FromDigits"", ""nlst"")<tab><tab>else:<tab><tab><tab>return value<tab>else:<tab><tab>evaluation.message(""FromDigits"", ""nlst"")",0,if value is None :,if value == Integer ( 0 ) :,0.04979441971690225,10.552670315936318,0.42857142857142855
"def hsconn_sender(self):<tab>while not self.stop_event.is_set():<tab><tab>try:<tab><tab><tab># Block, but timeout, so that we can exit the loop gracefully<tab><tab><tab>request = self.send_queue.get(True, 6.0)<tab><tab><tab>if self.socket is not None:<tab><tab><tab><tab># Socket got closed and set to None in another thread...<tab><tab><tab><tab>self.socket.sendall(request)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.send_queue.task_done()<tab><tab>except queue.Empty:<tab><tab><tab>pass<tab><tab>except OSError:<tab><tab><tab>self.stop_event.set()",0,if self . send_queue is not None :,if request is not None :,0.31689611060104994,27.585129929794586,0.7142857142857143
"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(result, str):<tab><tab><tab>result = result.encode(""ascii"")<tab><tab>if isinstance(expected, str):<tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab>if contains:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True",0,if eline not in rline :,if not rline . startswith ( eline ) :,0.024523051316242297,7.129384882260374,0.2857142857142857
"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for _, m in self.multi_deconv_layers.named_modules():<tab><tab><IF-STMT><tab><tab><tab>normal_init(m, std=0.001)<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>constant_init(m, 1)<tab>for m in self.multi_final_layers.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>normal_init(m, std=0.001, bias=0)",1,"if isinstance ( m , nn . ConvTranspose2d ) :","if isinstance ( m , nn . ConvTranspose2d ) :",0.75,100.00000000000004,1.0
"def filter_rel_attrs(field_name, **rel_attrs):<tab>clean_dict = {}<tab>for k, v in rel_attrs.items():<tab><tab><IF-STMT><tab><tab><tab>splitted_key = k.split(""__"")<tab><tab><tab>key = ""__"".join(splitted_key[1:])<tab><tab><tab>clean_dict[key] = v<tab><tab>else:<tab><tab><tab>clean_dict[k] = v<tab>return clean_dict",0,"if k . startswith ( field_name + ""__"" ) :","if ""__"" in k :",0.015145994590617124,16.5759081092516,0.4
"def cancel(self):<tab>with self._condition:<tab><tab><IF-STMT><tab><tab><tab>self._squash(<tab><tab><tab><tab>state_root=self._previous_state_hash,<tab><tab><tab><tab>context_ids=[self._previous_context_id],<tab><tab><tab><tab>persist=False,<tab><tab><tab><tab>clean_up=True,<tab><tab><tab>)<tab><tab>self._cancelled = True<tab><tab>self._condition.notify_all()",0,if not self . _cancelled and not self . _final and self . _previous_context_id :,if not self . _cancelled :,0.13413872650705572,9.86532662092106,0.5807017543859649
"def _get_level(levels, level_ref):<tab>if level_ref in levels:<tab><tab>return levels.index(level_ref)<tab>if isinstance(level_ref, six.integer_types):<tab><tab><IF-STMT><tab><tab><tab>level_ref += len(levels)<tab><tab>if not (0 <= level_ref < len(levels)):<tab><tab><tab>raise PatsyError(""specified level %r is out of range"" % (level_ref,))<tab><tab>return level_ref<tab>raise PatsyError(""specified level %r not found"" % (level_ref,))",1,if level_ref < 0 :,if level_ref < 0 :,0.75,100.00000000000004,1.0
"def parse_node(self, node, alias_map=None, conv=None):<tab>sql, params, unknown = self._parse(node, alias_map, conv)<tab>if unknown and conv and params:<tab><tab>params = [conv.db_value(i) for i in params]<tab>if isinstance(node, Node):<tab><tab>if node._negated:<tab><tab><tab>sql = ""NOT %s"" % sql<tab><tab><IF-STMT><tab><tab><tab>sql = "" "".join((sql, ""AS"", node._alias))<tab><tab>if node._ordering:<tab><tab><tab>sql = "" "".join((sql, node._ordering))<tab>return sql, params",1,if node . _alias :,if node . _alias :,0.75,100.00000000000004,1.0
"def parse_object_id(_, values):<tab>if values:<tab><tab>for key in values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = values[key]<tab><tab><tab><tab>if len(val) > 10:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>values[key] = utils.ObjectIdSilent(val)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>values[key] = None",0,"if key . endswith ( ""_id"" ) :","if isinstance ( values [ key ] , basestring ) :",0.0318578261816963,9.425159511373677,0.2653061224489796
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_max_rows(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def has_invalid_cce(yaml_file, product_yaml=None):<tab>rule = yaml.open_and_macro_expand(yaml_file, product_yaml)<tab>if ""identifiers"" in rule and rule[""identifiers""] is not None:<tab><tab>for i_type, i_value in rule[""identifiers""].items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not checks.is_cce_value_valid(""CCE-"" + str(i_value)):<tab><tab><tab><tab><tab>return True<tab>return False",0,"if i_type [ 0 : 3 ] == ""cce"" :","if i_type == ""product"" :",0.026933810325055336,25.681706510882123,0.46875
"def _generate_table(self, fromdesc, todesc, diffs):<tab>if fromdesc or todesc:<tab><tab>yield (<tab><tab><tab>simple_colorize(fromdesc, ""description""),<tab><tab><tab>simple_colorize(todesc, ""description""),<tab><tab>)<tab>for i, line in enumerate(diffs):<tab><tab>if line is None:<tab><tab><tab># mdiff yields None on separator lines; skip the bogus ones<tab><tab><tab># generated for the first line<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield line",0,if i > 0 :,if i < len ( diffs ) - 1 :,0.04589139340883146,9.287528999566801,0.40476190476190477
"def _getPatternTemplate(pattern, key=None):<tab>if key is None:<tab><tab>key = pattern<tab><tab>if ""%"" not in pattern:<tab><tab><tab>key = pattern.upper()<tab>template = DD_patternCache.get(key)<tab>if not template:<tab><tab>if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""):<tab><tab><tab>template = DateEpoch(lineBeginOnly=(key != ""EPOCH""))<tab><tab><IF-STMT><tab><tab><tab>template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False))<tab><tab>else:<tab><tab><tab>template = DatePatternRegex(pattern)<tab>DD_patternCache.set(key, template)<tab>return template",0,"elif key in ( ""TAI64N"" , ""{^LN-BEG}TAI64N"" , ""^TAI64N"" ) :","elif key == ""TAI64N"" :",0.0220258522937641,4.701299981230894,0.7352941176470589
"def ref_max_pooling_2d(x, kernel, stride, ignore_border, pad):<tab>y = []<tab>for xx in x.reshape((-1,) + x.shape[-3:]):<tab><tab><IF-STMT><tab><tab><tab>xx = xx[np.newaxis]<tab><tab>y += [<tab><tab><tab>refs.pooling_2d(xx, ""max"", kernel, stride, pad, ignore_border)[np.newaxis]<tab><tab>]<tab>y = np.vstack(y)<tab>if x.ndim == 2:<tab><tab>y = np.squeeze(y, 1)<tab>return y.reshape(x.shape[:-3] + y.shape[1:])",1,if xx . ndim == 2 :,if xx . ndim == 2 :,0.75,100.00000000000004,1.0
"def show_topics():<tab>""""""prints all available miscellaneous help topics.""""""<tab>print(_stash.text_color(""Miscellaneous Topics:"", ""yellow""))<tab>for pp in PAGEPATHS:<tab><tab>if not os.path.isdir(pp):<tab><tab><tab>continue<tab><tab>content = os.listdir(pp)<tab><tab>for pn in content:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = pn[: pn.index(""."")]<tab><tab><tab>else:<tab><tab><tab><tab>name = pn<tab><tab><tab>print(name)",1,"if ""."" in pn :","if ""."" in pn :",0.75,100.00000000000004,1.0
"def justify_toggle_auto(self, event=None):<tab>c = self<tab>if c.editCommands.autojustify == 0:<tab><tab>c.editCommands.autojustify = abs(c.config.getInt(""autojustify"") or 0)<tab><tab><IF-STMT><tab><tab><tab>g.es(""Autojustify on, @int autojustify == %s"" % c.editCommands.autojustify)<tab><tab>else:<tab><tab><tab>g.es(""Set @int autojustify in @settings"")<tab>else:<tab><tab>c.editCommands.autojustify = 0<tab><tab>g.es(""Autojustify off"")",1,if c . editCommands . autojustify :,if c . editCommands . autojustify :,0.75,100.00000000000004,1.0
"def render_token_list(self, tokens):<tab>result = []<tab>vars = []<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>result.append(token.contents.replace(""%"", ""%%""))<tab><tab>elif token.token_type == TOKEN_VAR:<tab><tab><tab>result.append(""%%(%s)s"" % token.contents)<tab><tab><tab>vars.append(token.contents)<tab>return """".join(result), vars",1,if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_TEXT :,0.75,100.00000000000004,1.0
"def get_target_dimensions(self):<tab>width, height = self.engine.size<tab>for operation in self.operations:<tab><tab>if operation[""type""] == ""crop"":<tab><tab><tab>width = operation[""right""] - operation[""left""]<tab><tab><tab>height = operation[""bottom""] - operation[""top""]<tab><tab><IF-STMT><tab><tab><tab>width = operation[""width""]<tab><tab><tab>height = operation[""height""]<tab>return (width, height)",0,"if operation [ ""type"" ] == ""resize"" :","elif operation [ ""type"" ] == ""crop"" :",0.25750132287221017,70.16035864257111,0.5
"def get_eval_matcher(self):<tab>if isinstance(self.data[""match""], str):<tab><tab><IF-STMT><tab><tab><tab>values = [""explicitDeny"", ""implicitDeny""]<tab><tab>else:<tab><tab><tab>values = [""allowed""]<tab><tab>vf = ValueFilter(<tab><tab><tab>{""type"": ""value"", ""key"": ""EvalDecision"", ""value"": values, ""op"": ""in""}<tab><tab>)<tab>else:<tab><tab>vf = ValueFilter(self.data[""match""])<tab>vf.annotate = False<tab>return vf",0,"if self . data [ ""match"" ] == ""denied"" :","if self . data [ ""match"" ] . endswith ( ""explicitDeny"" ) :",0.3896161892216288,51.54458901398172,0.7894736842105263
"def test_training(self):<tab>if not self.model_tester.is_training:<tab><tab>return<tab>config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()<tab>config.return_dict = True<tab>for model_class in self.all_model_classes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>model = model_class(config)<tab><tab>model.to(torch_device)<tab><tab>model.train()<tab><tab>inputs = self._prepare_for_class(inputs_dict, model_class, return_labels=True)<tab><tab>loss = model(**inputs).loss<tab><tab>loss.backward()",0,if model_class in MODEL_MAPPING . values ( ) :,"if model_class . __name__ . startswith ( ""torch"" ) :",0.03802826689136664,17.694975149532556,0.38666666666666666
"def prehook(self, emu, op, eip):<tab>if op in self.badops:<tab><tab>emu.stopEmu()<tab><tab>raise v_exc.BadOpBytes(op.va)<tab>if op.mnem in STOS:<tab><tab><IF-STMT><tab><tab><tab>reg = emu.getRegister(envi.archs.i386.REG_EDI)<tab><tab>elif self.arch == ""amd64"":<tab><tab><tab>reg = emu.getRegister(envi.archs.amd64.REG_RDI)<tab><tab>if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None:<tab><tab><tab>self.vw.makePointer(reg, follow=True)",1,"if self . arch == ""i386"" :","if self . arch == ""i386"" :",0.75,100.00000000000004,1.0
"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab><IF-STMT><tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab>elif size <= 9:<tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64mime.base64_len(""x"" * size), bsize)",1,if size == 0 :,if size == 0 :,0.75,100.00000000000004,1.0
"def __new__(cls, dependencies):<tab>deps = check.list_param(dependencies, ""dependencies"", of_type=DependencyDefinition)<tab>seen = {}<tab>for dep in deps:<tab><tab>key = dep.solid + "":"" + dep.output<tab><tab><IF-STMT><tab><tab><tab>raise DagsterInvalidDefinitionError(<tab><tab><tab><tab>'Duplicate dependencies on solid ""{dep.solid}"" output ""{dep.output}"" '<tab><tab><tab><tab>""used in the same MultiDependencyDefinition."".format(dep=dep)<tab><tab><tab>)<tab><tab>seen[key] = True<tab>return super(MultiDependencyDefinition, cls).__new__(cls, deps)",1,if key in seen :,if key in seen :,0.75,100.00000000000004,1.0
"def get_explanation(self, spec):<tab>""""""Expand an explanation.""""""<tab>if spec:<tab><tab>try:<tab><tab><tab>a = self.dns_txt(spec)<tab><tab><tab>if len(a) == 1:<tab><tab><tab><tab>return str(self.expand(to_ascii(a[0]), stripdot=False))<tab><tab>except PermError:<tab><tab><tab># RFC4408 6.2/4 syntax errors cause exp= to be ignored<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise  # but report in harsh mode for record checking tools<tab><tab><tab>pass<tab>elif self.strict > 1:<tab><tab>raise PermError(""Empty domain-spec on exp="")<tab># RFC4408 6.2/4 empty domain spec is ignored<tab># (unless you give precedence to the grammar).<tab>return None",0,if self . strict > 1 :,if self . strict == 0 :,0.4711135200865855,36.55552228545123,0.6666666666666666
"def build(self):<tab>if self.args.get(""sle_id""):<tab><tab>self.process_sle_against_current_voucher()<tab>else:<tab><tab>entries_to_fix = self.get_future_entries_to_fix()<tab><tab>i = 0<tab><tab>while i < len(entries_to_fix):<tab><tab><tab>sle = entries_to_fix[i]<tab><tab><tab>i += 1<tab><tab><tab>self.process_sle(sle)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.get_dependent_entries_to_fix(entries_to_fix, sle)<tab>if self.exceptions:<tab><tab>self.raise_exceptions()<tab>self.update_bin()",0,if sle . dependant_sle_voucher_detail_no :,"if self . args . get ( ""dependent"" ) :",0.025806626984353938,4.100530090638892,0.30952380952380953
"def ValidateStopLatitude(self, problems):<tab>if self.stop_lat is not None:<tab><tab>value = self.stop_lat<tab><tab>try:<tab><tab><tab>if not isinstance(value, (float, int)):<tab><tab><tab><tab>self.stop_lat = util.FloatStringToFloat(value, problems)<tab><tab>except (ValueError, TypeError):<tab><tab><tab>problems.InvalidValue(""stop_lat"", value)<tab><tab><tab>del self.stop_lat<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>problems.InvalidValue(""stop_lat"", value)",0,if self . stop_lat > 90 or self . stop_lat < - 90 :,if self . stop_lat > self . stop_lat :,0.4949357965598957,52.860405135231765,0.46842105263157896
"def set(self, obj, **kwargs):<tab>""""""Check for missing event functions and substitute these with""""""<tab>""""""the ignore method""""""<tab>ignore = getattr(self, ""ignore"")<tab>for k, v in kwargs.iteritems():<tab><tab>setattr(self, k, getattr(obj, v))<tab><tab><IF-STMT><tab><tab><tab>for k1 in self.combinations[k]:<tab><tab><tab><tab>if not hasattr(self, k1):<tab><tab><tab><tab><tab>setattr(self, k1, ignore)",1,if k in self . combinations :,if k in self . combinations :,0.75,100.00000000000004,1.0
"def split(self, duration, include_remainder=True):<tab># Convert seconds to timedelta, if appropriate.<tab>duration = _seconds_or_timedelta(duration)<tab>if duration <= timedelta(seconds=0):<tab><tab>raise ValueError(""cannot call split with a non-positive timedelta"")<tab>start = self.start<tab>while start < self.end:<tab><tab>if start + duration <= self.end:<tab><tab><tab>yield MayaInterval(start, start + duration)<tab><tab><IF-STMT><tab><tab><tab>yield MayaInterval(start, self.end)<tab><tab>start += duration",0,elif include_remainder :,if include_remainder :,0.11293884852539707,1e-10,0.3333333333333333
"def get_first_field(layout, clz):<tab>for layout_object in layout.fields:<tab><tab>if issubclass(layout_object.__class__, clz):<tab><tab><tab>return layout_object<tab><tab><IF-STMT><tab><tab><tab>gf = get_first_field(layout_object, clz)<tab><tab><tab>if gf:<tab><tab><tab><tab>return gf",0,"elif hasattr ( layout_object , ""get_field_names"" ) :","if hasattr ( layout_object , ""fields"" ) :",0.20556680845025985,45.43142611141303,0.5
"def _getPatternTemplate(pattern, key=None):<tab>if key is None:<tab><tab>key = pattern<tab><tab>if ""%"" not in pattern:<tab><tab><tab>key = pattern.upper()<tab>template = DD_patternCache.get(key)<tab>if not template:<tab><tab><IF-STMT><tab><tab><tab>template = DateEpoch(lineBeginOnly=(key != ""EPOCH""))<tab><tab>elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""):<tab><tab><tab>template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False))<tab><tab>else:<tab><tab><tab>template = DatePatternRegex(pattern)<tab>DD_patternCache.set(key, template)<tab>return template",0,"if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :","if key == ""EPOCH"" :",0.023216713144679484,4.701299981230894,0.7352941176470589
"def findOwningViewController(self, object):<tab>while object:<tab><tab><IF-STMT><tab><tab><tab>description = fb.evaluateExpressionValue(object).GetObjectDescription()<tab><tab><tab>print(""Found the owning view controller.\n{}"".format(description))<tab><tab><tab>cmd = 'echo {} | tr -d ""\n"" | pbcopy'.format(object)<tab><tab><tab>os.system(cmd)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>object = self.nextResponder(object)<tab>print(""Could not find an owning view controller"")",0,if self . isViewController ( object ) :,if self . isOwningViewController ( object ) :,0.5014622369176811,50.000000000000014,0.6666666666666666
"def __get_file_by_num(self, num, file_list, idx=0):<tab>for element in file_list:<tab><tab>if idx == num:<tab><tab><tab>return element<tab><tab>if element[3] and element[4]:<tab><tab><tab>i = self.__get_file_by_num(num, element[3], idx + 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return i<tab><tab><tab>idx = i<tab><tab>else:<tab><tab><tab>idx += 1<tab>return idx",0,"if not isinstance ( i , int ) :","if isinstance ( i , int ) :",0.38217665481248053,76.72796459606589,0.3148148148148148
"def promtool(**kwargs):<tab>key = ""prometheus:promtool""<tab>try:<tab><tab>path = pathlib.Path(util.setting(key))<tab>except TypeError:<tab><tab>yield checks.Warning(<tab><tab><tab>""Missing setting for %s in %s "" % (key, settings.PROMGEN_CONFIG_FILE),<tab><tab><tab>id=""promgen.W001"",<tab><tab>)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>yield checks.Warning(""Unable to execute file %s"" % path, id=""promgen.W003"")",0,"if not os . access ( path , os . X_OK ) :",if not util . file_exists ( path ) :,0.13011436427633546,9.697811808581424,0.4107142857142857
"def parse_config(schema, config):<tab>schemaparser = ConfigParser()<tab>schemaparser.readfp(StringIO(schema))<tab>cfgparser = ConfigParser()<tab>cfgparser.readfp(StringIO(config))<tab>result = {}<tab>for section in cfgparser.sections():<tab><tab>result_section = {}<tab><tab>schema = {}<tab><tab><IF-STMT><tab><tab><tab>schema = dict(schemaparser.items(section))<tab><tab>for key, value in cfgparser.items(section):<tab><tab><tab>converter = converters[schema.get(key, ""string"")]<tab><tab><tab>result_section[key] = converter(value)<tab><tab>result[section] = result_section<tab>return result",0,if section in schemaparser . sections ( ) :,"if section == ""schema"" :",0.029942750698461862,10.786826322527466,0.4545454545454546
"def validate_arguments(args):<tab>if args.num_pss < 1:<tab><tab>print(""Value error: must have ore than one parameter servers."")<tab><tab>exit(1)<tab>if not GPU_IDS:<tab><tab>num_cpus = multiprocessing.cpu_count()<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""Value error: there are %s available CPUs but you are requiring %s.""<tab><tab><tab><tab>% (num_cpus, args.cpu_trainers)<tab><tab><tab>)<tab><tab><tab>exit(1)<tab>if not os.path.isfile(args.file):<tab><tab>print(""Value error: model trainning file does not exist"")<tab><tab>exit(1)",0,if args . cpu_trainers > num_cpus :,if num_cpus != args . cpu_trainers :,0.09792678674024619,44.833867003844574,1.0
"def infer_dataset_impl(path):<tab>if IndexedRawTextDataset.exists(path):<tab><tab>return ""raw""<tab>elif IndexedDataset.exists(path):<tab><tab>with open(index_file_path(path), ""rb"") as f:<tab><tab><tab>magic = f.read(8)<tab><tab><tab>if magic == IndexedDataset._HDR_MAGIC:<tab><tab><tab><tab>return ""cached""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""mmap""<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab>elif FastaDataset.exists(path):<tab><tab>return ""fasta""<tab>else:<tab><tab>return None",0,elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,elif magic == FastaDataset . _MAGIC :,0.08321646185022315,16.58011393376885,0.4126984126984127
"def _add_resource_group(obj):<tab>if isinstance(obj, list):<tab><tab>for array_item in obj:<tab><tab><tab>_add_resource_group(array_item)<tab>elif isinstance(obj, dict):<tab><tab>try:<tab><tab><tab>if ""resourcegroup"" not in [x.lower() for x in obj.keys()]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""]<tab><tab>except (KeyError, IndexError, TypeError):<tab><tab><tab>pass<tab><tab>for item_key in obj:<tab><tab><tab>if item_key != ""sourceVault"":<tab><tab><tab><tab>_add_resource_group(obj[item_key])",0,"if obj [ ""id"" ] :","if ""resource-group"" not in obj :",0.028043015323814018,8.25791079503452,0.3333333333333333
"def reformatBody(self, event=None):<tab>""""""Reformat all paragraphs in the body.""""""<tab>c, p = self, self.p<tab>undoType = ""reformat-body""<tab>w = c.frame.body.wrapper<tab>c.undoer.beforeChangeGroup(p, undoType)<tab>w.setInsertPoint(0)<tab>while 1:<tab><tab>progress = w.getInsertPoint()<tab><tab>c.reformatParagraph(event, undoType=undoType)<tab><tab>ins = w.getInsertPoint()<tab><tab>s = w.getAllText()<tab><tab>w.setInsertPoint(ins)<tab><tab><IF-STMT><tab><tab><tab>break<tab>c.undoer.afterChangeGroup(p, undoType)",0,if ins <= progress or ins >= len ( s ) :,if not s :,0.010023274633399372,1.7256245272235644,0.2142857142857143
"def make_sources(project: RootDependency) -> str:<tab>content = []<tab>if project.readme:<tab><tab>content.append(project.readme.path.name)<tab><tab><IF-STMT><tab><tab><tab>content.append(project.readme.to_rst().path.name)<tab>path = project.package.path<tab>for fname in (""setup.cfg"", ""setup.py""):<tab><tab>if (path / fname).exists():<tab><tab><tab>content.append(fname)<tab>for package in chain(project.package.packages, project.package.data):<tab><tab>for fpath in package:<tab><tab><tab>fpath = fpath.relative_to(project.package.path)<tab><tab><tab>content.append(""/"".join(fpath.parts))<tab>return ""\n"".join(content)",0,"if project . readme . markup != ""rst"" :",if project . readme . to_rst :,0.24192430294445827,34.787005545423945,0.7818181818181819
"def __init__(self, response):<tab>error = ""{} {}"".format(response.status_code, response.reason)<tab>extra = []<tab>try:<tab><tab>response_json = response.json()<tab><tab><IF-STMT><tab><tab><tab>error = "" "".join(error[""message""] for error in response_json[""error_list""])<tab><tab><tab>extra = [<tab><tab><tab><tab>error[""extra""]<tab><tab><tab><tab>for error in response_json[""error_list""]<tab><tab><tab><tab>if ""extra"" in error<tab><tab><tab>]<tab>except JSONDecodeError:<tab><tab>pass<tab>super().__init__(response=response, error=error, extra=extra)",1,"if ""error_list"" in response_json :","if ""error_list"" in response_json :",0.75,100.00000000000004,1.0
"def handle_event(self, fileno=None, events=None):<tab>if self._state == RUN:<tab><tab><IF-STMT><tab><tab><tab>self._it = self._process_result(0)  # non-blocking<tab><tab>try:<tab><tab><tab>next(self._it)<tab><tab>except (StopIteration, CoroStop):<tab><tab><tab>self._it = None",1,if self . _it is None :,if self . _it is None :,0.75,100.00000000000004,1.0
"def find_query(self, needle, haystack):<tab>try:<tab><tab>import pinyin<tab><tab>haystack_py = pinyin.get_initial(haystack, """")<tab><tab>needle_len = len(needle)<tab><tab>start = 0<tab><tab>result = []<tab><tab>while True:<tab><tab><tab>found = haystack_py.find(needle, start)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>result.append((found, needle_len))<tab><tab><tab>start = found + needle_len<tab><tab>return result<tab>except:<tab><tab>return None",0,if found < 0 :,if found == - 1 :,0.0574290063711522,14.535768424205482,0.6
"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if ""Last-Modified"" not in rv.headers:<tab><tab>try:<tab><tab><tab>result = date<tab><tab><tab>if callable(result):<tab><tab><tab><tab>result = result(rv)<tab><tab><tab>if not isinstance(result, basestring):<tab><tab><tab><tab>from werkzeug.http import http_date<tab><tab><tab><tab>result = http_date(result)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.headers[""Last-Modified""] = result<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the lastmodified value for response {!r}"".format(<tab><tab><tab><tab><tab>rv<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return rv",0,if result :,if result is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def check_require(require_modules, require_lines):<tab>for require_module in require_modules:<tab><tab>st = try_import(require_module)<tab><tab>if st == 0:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""installed {}: {}\n"".format(<tab><tab><tab><tab><tab>require_module, require_lines[require_module]<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>elif st == 2:<tab><tab><tab>print(<tab><tab><tab><tab>""failed installed {}: {}\n"".format(<tab><tab><tab><tab><tab>require_module, require_lines[require_module]<tab><tab><tab><tab>)<tab><tab><tab>)",1,elif st == 1 :,elif st == 1 :,1.0,100.00000000000004,1.0
"def bundle_directory(self, dirpath):<tab>""""""Bundle all modules/packages in the given directory.""""""<tab>dirpath = os.path.abspath(dirpath)<tab>for nm in os.listdir(dirpath):<tab><tab>nm = _u(nm)<tab><tab>if nm.startswith("".""):<tab><tab><tab>continue<tab><tab>itempath = os.path.join(dirpath, nm)<tab><tab>if os.path.isdir(itempath):<tab><tab><tab>if os.path.exists(os.path.join(itempath, ""__init__.py"")):<tab><tab><tab><tab>self.bundle_package(itempath)<tab><tab><IF-STMT><tab><tab><tab>self.bundle_module(itempath)",0,"elif nm . endswith ( "".py"" ) :","elif os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :",0.0669010606233818,11.434338200880834,0.20164609053497942
"def _find_root():<tab>test_dirs = [""Src"", ""Build"", ""Package"", ""Tests"", ""Util""]<tab>root = os.getcwd()<tab>test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs])<tab>while not test:<tab><tab>last_root = root<tab><tab>root = os.path.dirname(root)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Root not found"")<tab><tab>test = all([os.path.exists(os.path.join(root, x)) for x in test_dirs])<tab>return root",1,if root == last_root :,if root == last_root :,0.75,100.00000000000004,1.0
"def findMarkForUnitTestNodes(self):<tab>""""""return the position of *all* non-ignored @mark-for-unit-test nodes.""""""<tab>c = self.c<tab>p, result, seen = c.rootPosition(), [], []<tab>while p:<tab><tab>if p.v in seen:<tab><tab><tab>p.moveToNodeAfterTree()<tab><tab>else:<tab><tab><tab>seen.append(p.v)<tab><tab><tab>if g.match_word(p.h, 0, ""@ignore""):<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(p.copy())<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab>else:<tab><tab><tab><tab>p.moveToThreadNext()<tab>return result",0,"elif p . h . startswith ( ""@mark-for-unit-tests"" ) :","elif g . match_word ( p . h , 0 , ""@mark"" ) :",0.1035909203496424,15.593439508212386,0.2781954887218045
"def startTagFrameset(self, token):<tab>self.parser.parseError(""unexpected-start-tag"", {""name"": ""frameset""})<tab>if len(self.tree.openElements) == 1 or self.tree.openElements[1].name != ""body"":<tab><tab>assert self.parser.innerHTML<tab>elif not self.parser.framesetOK:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.tree.openElements[1].parent.removeChild(self.tree.openElements[1])<tab><tab>while self.tree.openElements[-1].name != ""html"":<tab><tab><tab>self.tree.openElements.pop()<tab><tab>self.tree.insertElement(token)<tab><tab>self.parser.phase = self.parser.phases[""inFrameset""]",0,if self . tree . openElements [ 1 ] . parent :,"if self . tree . openElements [ 1 ] . name == ""html"" :",0.5477344576701013,55.81600587827485,0.75
"def try_split(self, split_text: List[str]):<tab>ret = []<tab>for i in split_text:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>val = int(i, 2)<tab><tab>if val > 255 or val < 0:<tab><tab><tab>return None<tab><tab>ret.append(val)<tab>if len(ret) != 0:<tab><tab>ret = bytes(ret)<tab><tab>logger.debug(f""binary successful, returning {ret.__repr__()}"")<tab><tab>return ret",0,if len ( i ) == 0 :,"if i == """" :",0.020977836961063236,12.411264901419441,0.36
"def generator(self, data):<tab>for sock in data:<tab><tab><IF-STMT><tab><tab><tab>offset = sock.obj_offset<tab><tab>else:<tab><tab><tab>offset = sock.obj_vm.vtop(sock.obj_offset)<tab><tab>yield (<tab><tab><tab>0,<tab><tab><tab>[<tab><tab><tab><tab>Address(offset),<tab><tab><tab><tab>int(sock.Pid),<tab><tab><tab><tab>int(sock.LocalPort),<tab><tab><tab><tab>int(sock.Protocol),<tab><tab><tab><tab>str(protos.protos.get(sock.Protocol.v(), ""-"")),<tab><tab><tab><tab>str(sock.LocalIpAddress),<tab><tab><tab><tab>str(sock.CreateTime),<tab><tab><tab>],<tab><tab>)",0,if not self . _config . PHYSICAL_OFFSET :,"if hasattr ( sock , ""obj_offset"" ) :",0.018078277067547346,4.456882760699063,0.3333333333333333
"def __init__(self, num_bits=4, always_apply=False, p=0.5):<tab>super(Posterize, self).__init__(always_apply, p)<tab>if isinstance(num_bits, (list, tuple)):<tab><tab><IF-STMT><tab><tab><tab>self.num_bits = [to_tuple(i, 0) for i in num_bits]<tab><tab>else:<tab><tab><tab>self.num_bits = to_tuple(num_bits, 0)<tab>else:<tab><tab>self.num_bits = to_tuple(num_bits, num_bits)",0,if len ( num_bits ) == 3 :,if len ( num_bits ) == 2 :,0.605621305873661,80.70557274927978,0.6
"def tearDown(self):<tab>""""""Just in case yn00 creates some junk files, do a clean-up.""""""<tab>del_files = [self.out_file, ""2YN.dN"", ""2YN.dS"", ""2YN.t"", ""rst"", ""rst1"", ""rub""]<tab>for filename in del_files:<tab><tab><IF-STMT><tab><tab><tab>os.remove(filename)<tab>if os.path.exists(self.working_dir):<tab><tab>for filename in os.listdir(self.working_dir):<tab><tab><tab>filepath = os.path.join(self.working_dir, filename)<tab><tab><tab>os.remove(filepath)<tab><tab>os.rmdir(self.working_dir)",1,if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,0.75,100.00000000000004,1.0
"def reverse_search_history(self, searchfor, startpos=None):<tab>if startpos is None:<tab><tab>startpos = self.history_cursor<tab>if _ignore_leading_spaces:<tab><tab>res = [<tab><tab><tab>(idx, line.lstrip())<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab><IF-STMT><tab><tab>]<tab>else:<tab><tab>res = [<tab><tab><tab>(idx, line)<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab>if line.startswith(searchfor)<tab><tab>]<tab>if res:<tab><tab>self.history_cursor -= res[0][0]<tab><tab>return res[0][1].get_line_text()<tab>return """"",0,if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),if line . startswith ( searchfor ),0.11018402673569849,18.962297349534435,0.48333333333333334
"def ComboBoxDroppedHeightTest(windows):<tab>""Check if each combobox height is the same as the reference""<tab>bugs = []<tab>for win in windows:<tab><tab>if not win.ref:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if win.DroppedRect().height() != win.ref.DroppedRect().height():<tab><tab><tab>bugs.append(<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>win,<tab><tab><tab><tab><tab>],<tab><tab><tab><tab><tab>{},<tab><tab><tab><tab><tab>testname,<tab><tab><tab><tab><tab>0,<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return bugs",0,"if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :","if not hasattr ( win , ""DroppedRect"" ) :",0.0071545988334159065,1.7072998005661324,0.2361111111111111
"def get_changed(self):<tab>if self._is_expression():<tab><tab>result = self._get_node_text(self.ast)<tab><tab>if result == self.source:<tab><tab><tab>return None<tab><tab>return result<tab>else:<tab><tab>collector = codeanalyze.ChangeCollector(self.source)<tab><tab>last_end = -1<tab><tab>for match in self.matches:<tab><tab><tab>start, end = match.get_region()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not self._is_expression():<tab><tab><tab><tab><tab>continue<tab><tab><tab>last_end = end<tab><tab><tab>replacement = self._get_matched_text(match)<tab><tab><tab>collector.add_change(start, end, replacement)<tab><tab>return collector.get_changed()",0,if start < last_end :,if end < last_end :,0.39477865547525276,64.34588841607616,0.5
"def unpickle_from_file(file_path, gzip=False):<tab>""""""Unpickle obj from file_path with gzipping.""""""<tab>with tf.io.gfile.GFile(file_path, ""rb"") as f:<tab><tab><IF-STMT><tab><tab><tab>obj = pickle.load(f)<tab><tab>else:<tab><tab><tab>with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:<tab><tab><tab><tab>obj = pickle.load(gzipf)<tab>return obj",0,if not gzip :,if gzip :,0.09648852821835877,1e-10,0.41666666666666663
"def get_user_context(request, escape=False):<tab>if isinstance(request, HttpRequest):<tab><tab>user = getattr(request, ""user"", None)<tab><tab>result = {""ip_address"": request.META[""REMOTE_ADDR""]}<tab><tab>if user and user.is_authenticated():<tab><tab><tab>result.update(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""email"": user.email,<tab><tab><tab><tab><tab>""id"": user.id,<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[""name""] = user.name<tab>else:<tab><tab>result = {}<tab>return mark_safe(json.dumps(result))",0,if user . name :,if escape :,0.03549272049582243,1e-10,0.36
"def get_item_address(self, item):<tab>""""""Get an item's address as a collection of names""""""<tab>result = []<tab>while True:<tab><tab>name = self.tree_ctrl.GetItemPyData(item)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>result.insert(0, name)<tab><tab><tab>item = self.tree_ctrl.GetItemParent(item)<tab>return result",1,if name is None :,if name is None :,0.75,100.00000000000004,1.0
"def closest_unseen(self, row1, col1, filter=None):<tab># find the closest unseen from this row/col<tab>min_dist = maxint<tab>closest_unseen = None<tab>for row in range(self.height):<tab><tab>for col in range(self.width):<tab><tab><tab>if filter is None or (row, col) not in filter:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dist = self.distance(row1, col1, row, col)<tab><tab><tab><tab><tab>if dist < min_dist:<tab><tab><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab><tab><tab>closest_unseen = (row, col)<tab>return closest_unseen",0,if self . map [ row ] [ col ] == UNSEEN :,if self . distance is not None :,0.04274029108635068,10.434384015500639,0.2727272727272727
"def log_graph(self, model: LightningModule, input_array=None):<tab>if self._log_graph:<tab><tab><IF-STMT><tab><tab><tab>input_array = model.example_input_array<tab><tab>if input_array is not None:<tab><tab><tab>input_array = model._apply_batch_transfer_handler(input_array)<tab><tab><tab>self.experiment.add_graph(model, input_array)<tab><tab>else:<tab><tab><tab>rank_zero_warn(<tab><tab><tab><tab>""Could not log computational graph since the""<tab><tab><tab><tab>"" `model.example_input_array` attribute is not set""<tab><tab><tab><tab>"" or `input_array` was not given"",<tab><tab><tab><tab>UserWarning,<tab><tab><tab>)",1,if input_array is None :,if input_array is None :,0.75,100.00000000000004,1.0
"def get_scene_exceptions_by_season(self, season=-1):<tab>scene_exceptions = []<tab>for scene_exception in self.scene_exceptions:<tab><tab>if not len(scene_exception) == 2:<tab><tab><tab>continue<tab><tab>scene_name, scene_season = scene_exception.split(""|"")<tab><tab><IF-STMT><tab><tab><tab>scene_exceptions.append(scene_name)<tab>return scene_exceptions",0,if season == scene_season :,if scene_season == season :,0.2901714209472326,39.28146509005134,1.0
def _clean_temp_files():<tab>for pattern in _temp_files:<tab><tab>for path in glob.glob(pattern):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(path)<tab><tab><tab>else:<tab><tab><tab><tab>shutil.rmtree(path),0,if os . path . islink ( path ) or os . path . isfile ( path ) :,if os . path . isfile ( path ) :,0.4171984521463991,40.656965974059936,0.4451345755693582
"def wait_for_completion(self, job_id, offset, max_results, start_time, timeout):<tab>""""""Wait for job completion and return the first page.""""""<tab>while True:<tab><tab>result = self.get_query_results(<tab><tab><tab>job_id=job_id, page_token=None, start_index=offset, max_results=max_results<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return result<tab><tab>if (time.time() - start_time) > timeout:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Timeout: the query doesn't finish within %d seconds."" % timeout<tab><tab><tab>)<tab><tab>time.sleep(1)",0,"if result [ ""jobComplete"" ] :",if result :,0.050438393472541504,1e-10,1.0
"def get_data(self, element, ranges, style):<tab><IF-STMT><tab><tab>groups = element.groupby(element.kdims).items()<tab>else:<tab><tab>groups = [(element.label, element)]<tab>plots = []<tab>axis = ""x"" if self.invert_axes else ""y""<tab>for key, group in groups:<tab><tab>if element.kdims:<tab><tab><tab>label = "","".join([d.pprint_value(v) for d, v in zip(element.kdims, key)])<tab><tab>else:<tab><tab><tab>label = key<tab><tab>data = {axis: group.dimension_values(group.vdims[0]), ""name"": label}<tab><tab>plots.append(data)<tab>return plots",0,if element . kdims :,if self . invert_axes :,0.28654024892898816,8.643019616048525,0.36
"def get_files(self, dirname):<tab>if not self._data.has_key(dirname):<tab><tab>self._create(dirname)<tab>else:<tab><tab>new_time = self._changed(dirname)<tab><tab><IF-STMT><tab><tab><tab>self._update(dirname, new_time)<tab><tab><tab>dcLog.debug(""==> "" + ""\t\n"".join(self._data[dirname][""flist""]))<tab>return self._data[dirname][""flist""]",0,if new_time :,if new_time is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def __init__(self, dir):<tab>self.module_names = set()<tab>for name in os.listdir(dir):<tab><tab><IF-STMT><tab><tab><tab>self.module_names.add(name[:-3])<tab><tab>elif ""."" not in name:<tab><tab><tab>self.module_names.add(name)",1,"if name . endswith ( "".py"" ) :","if name . endswith ( "".py"" ) :",0.75,100.00000000000004,1.0
"def logic():<tab>for i in range(100):<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>count.next = (count + 1) % n<tab>raise StopSimulation",1,if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,0.75,100.00000000000004,1.0
"def sortkeypicker(keynames):<tab>negate = set()<tab>for i, k in enumerate(keynames):<tab><tab>if k[:1] == ""-"":<tab><tab><tab>keynames[i] = k[1:]<tab><tab><tab>negate.add(k[1:])<tab>def getit(adict):<tab><tab>composite = [adict[k] for k in keynames]<tab><tab>for i, (k, v) in enumerate(zip(keynames, composite)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>composite[i] = -v<tab><tab>return composite<tab>return getit",0,if k in negate :,if not negate [ i ] :,0.029730601197949243,8.643019616048525,0.2857142857142857
"def show_image(self, wnd_name, img):<tab>if wnd_name in self.named_windows:<tab><tab><IF-STMT><tab><tab><tab>self.named_windows[wnd_name] = 1<tab><tab><tab>self.on_create_window(wnd_name)<tab><tab><tab>if wnd_name in self.capture_mouse_windows:<tab><tab><tab><tab>self.capture_mouse(wnd_name)<tab><tab>self.on_show_image(wnd_name, img)<tab>else:<tab><tab>print(""show_image: named_window "", wnd_name, "" not found."")",0,if self . named_windows [ wnd_name ] == 0 :,if not self . named_windows [ wnd_name ] :,0.28250213095764426,66.06312130196142,0.4
"def check_action_permitted(self):<tab>if (<tab><tab>self._action == ""sts:GetCallerIdentity""<tab>):  # always allowed, even if there's an explicit Deny for it<tab><tab>return True<tab>policies = self._access_key.collect_policies()<tab>permitted = False<tab>for policy in policies:<tab><tab>iam_policy = IAMPolicy(policy)<tab><tab>permission_result = iam_policy.is_action_permitted(self._action)<tab><tab>if permission_result == PermissionResult.DENIED:<tab><tab><tab>self._raise_access_denied()<tab><tab><IF-STMT><tab><tab><tab>permitted = True<tab>if not permitted:<tab><tab>self._raise_access_denied()",0,elif permission_result == PermissionResult . PERMITTED :,elif permission_result == PermissionResult . ACCESS_DENIED :,0.5717294420803809,63.15552371794033,0.7222222222222222
"def _limit_value(key, value, config):<tab>if config[key].get(""upper_limit""):<tab><tab>limit = config[key][""upper_limit""]<tab><tab># auto handle datetime<tab><tab>if isinstance(value, datetime) and isinstance(limit, timedelta):<tab><tab><tab>if config[key][""inverse""] is True:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value = datetime.now() - limit<tab><tab><tab>else:<tab><tab><tab><tab>if (datetime.now() + limit) < value:<tab><tab><tab><tab><tab>value = datetime.now() + limit<tab><tab>elif value > limit:<tab><tab><tab>value = limit<tab>return value",1,if ( datetime . now ( ) - limit ) > value :,if ( datetime . now ( ) - limit ) > value :,0.75,100.00000000000004,1.0
"def replace_dataset_ids(path, key, value):<tab>""""""Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job.""""""<tab>current_case = input_values<tab>if key == ""id"":<tab><tab>for i, p in enumerate(path):<tab><tab><tab>if isinstance(current_case, (list, dict)):<tab><tab><tab><tab>current_case = current_case[p]<tab><tab><IF-STMT><tab><tab><tab>return key, translate_values.get(current_case[""id""], value)<tab>return key, value",0,"if src == current_case . get ( ""src"" ) :","if i == 0 and ""id"" in current_case :",0.015744526211108195,14.335111586503956,0.22916666666666669
"def load_ext(name, funcs):<tab>ExtModule = namedtuple(""ExtModule"", funcs)<tab>ext_list = []<tab>lib_root = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))<tab>for fun in funcs:<tab><tab><IF-STMT><tab><tab><tab>ext_list.append(extension.load(fun, name, lib_dir=lib_root).op)<tab><tab>else:<tab><tab><tab>ext_list.append(extension.load(fun, name, lib_dir=lib_root).op_)<tab>return ExtModule(*ext_list)",0,"if fun in [ ""nms"" , ""softnms"" ] :","if fun == ""__init__"" :",0.029942750698461862,7.835643838636099,0.7307692307692308
"def execute_action(self):<tab>selected_actions = self.model_action.get_selected_results_with_index()<tab>if selected_actions and self.args_for_action:<tab><tab>for name, _, act_idx in selected_actions:<tab><tab><tab>try:<tab><tab><tab><tab>action = self.actions[act_idx]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>action.act([arg for arg, _, _ in self.args_for_action], self)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>debug.log(""execute_action"", e)",0,if action :,if action . act :,0.09791453445388575,1e-10,0.7
"def __getattr__(self, attr):<tab>proxy = self.__proxy<tab>if proxy and hasattr(proxy, attr):<tab><tab>return getattr(proxy, attr)<tab>attrmap = self.__attrmap<tab>if attr in attrmap:<tab><tab>source = attrmap[attr]<tab><tab><IF-STMT><tab><tab><tab>value = source()<tab><tab>else:<tab><tab><tab>value = _import_object(source)<tab><tab>setattr(self, attr, value)<tab><tab>self.__log.debug(""loaded lazy attr %r: %r"", attr, value)<tab><tab>return value<tab>raise AttributeError(""'module' object has no attribute '%s'"" % (attr,))",1,if callable ( source ) :,if callable ( source ) :,0.75,100.00000000000004,1.0
"def forward(self, x):<tab># BxT -> BxCxT<tab>x = x.unsqueeze(1)<tab>for conv in self.conv_layers:<tab><tab>residual = x<tab><tab>x = conv(x)<tab><tab><IF-STMT><tab><tab><tab>tsz = x.size(2)<tab><tab><tab>r_tsz = residual.size(2)<tab><tab><tab>residual = residual[..., :: r_tsz // tsz][..., :tsz]<tab><tab><tab>x = (x + residual) * self.residual_scale<tab>if self.log_compression:<tab><tab>x = x.abs()<tab><tab>x = x + 1<tab><tab>x = x.log()<tab>return x",0,if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,if len ( residual ) > 0 :,0.0068289025973464704,1.4350097235151493,0.18
"def __Prefix_Step2a(self, token):<tab>for prefix in self.__prefix_step2a:<tab><tab><IF-STMT><tab><tab><tab>token = token[len(prefix) :]<tab><tab><tab>self.prefix_step2a_success = True<tab><tab><tab>break<tab>return token",0,if token . startswith ( prefix ) and len ( token ) > 5 :,if token . startswith ( prefix ) :,0.28184453892234934,36.24372413507827,0.5555555555555556
"def is_valid(sample):<tab>if sample is None:<tab><tab>return False<tab>if isinstance(sample, tuple):<tab><tab>for s in sample:<tab><tab><tab>if s is None:<tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, np.ndarray) and s.size == 0:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return True",0,"elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :","elif isinstance ( s , np . ndarray ) and s . size > 0 :",0.23478864263164645,24.559903655373162,0.2651821862348178
"def get_all_comments(self, gallery_id, post_no, comment_cnt):<tab>comment_page_cnt = (comment_cnt - 1) // self.options.comments_per_page + 1<tab>comments = []<tab>headers = {""X-Requested-With"": ""XMLHttpRequest""}<tab>data = {""ci_t"": self._session.cookies[""ci_c""], ""id"": gallery_id, ""no"": post_no}<tab>for i in range(comment_page_cnt):<tab><tab>data[""comment_page""] = i + 1<tab><tab>response = self.request_comment(headers, data)<tab><tab>batch = self.parse_comments(response.text)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>comments = batch + comments<tab>return comments",1,if not batch :,if not batch :,0.75,100.00000000000004,1.0
def run_on_module(self):<tab>try:<tab><tab>self.module_base.disable(self.opts.module_spec)<tab>except dnf.exceptions.MarkingErrors as e:<tab><tab><IF-STMT><tab><tab><tab>if e.no_match_group_specs or e.error_group_specs:<tab><tab><tab><tab>raise e<tab><tab><tab>if (<tab><tab><tab><tab>e.module_depsolv_errors<tab><tab><tab><tab>and e.module_depsolv_errors[1]<tab><tab><tab><tab>!= libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS<tab><tab><tab>):<tab><tab><tab><tab>raise e<tab><tab>logger.error(str(e)),0,if self . base . conf . strict :,if self . opts . module_spec :,0.17051630776378876,20.164945583740657,0.39999999999999997
"def find_field_notnull_differ(self, meta, table_description, table_name):<tab>if not self.can_detect_notnull_differ:<tab><tab>return<tab>for field in all_local_fields(meta):<tab><tab>attname = field.db_column or field.attname<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>null = self.get_field_db_nullable(field, table_name)<tab><tab>if field.null != null:<tab><tab><tab>action = field.null and ""DROP"" or ""SET""<tab><tab><tab>self.add_difference(""notnull-differ"", table_name, attname, action)",0,"if ( table_name , attname ) in self . new_db_fields :",if attname is None :,0.012417879185700129,1.2753613517831104,0.42857142857142855
"def _change_moving_module(self, changes, dest):<tab>if not self.source.is_folder():<tab><tab>pymodule = self.pycore.resource_to_pyobject(self.source)<tab><tab>source = self.import_tools.relatives_to_absolutes(pymodule)<tab><tab>pymodule = self.tools.new_pymodule(pymodule, source)<tab><tab>source = self._change_occurrences_in_module(dest, pymodule)<tab><tab>source = self.tools.new_source(pymodule, source)<tab><tab><IF-STMT><tab><tab><tab>changes.add_change(ChangeContents(self.source, source))",0,if source != self . source . read ( ) :,if source != dest :,0.04909737062145379,19.765609300943975,0.42063492063492064
"def get(quality_name):<tab>""""""Returns a quality object based on canonical quality name.""""""<tab>found_components = {}<tab>for part in quality_name.lower().split():<tab><tab>component = _registry.get(part)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""`%s` is not a valid quality string"" % part)<tab><tab>if component.type in found_components:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""`%s` cannot be defined twice in a quality"" % component.type<tab><tab><tab>)<tab><tab>found_components[component.type] = component<tab>if not found_components:<tab><tab>raise ValueError(""No quality specified"")<tab>result = Quality()<tab>for type, component in found_components.items():<tab><tab>setattr(result, type, component)<tab>return result",1,if not component :,if not component :,0.75,100.00000000000004,1.0
def _unselected(self):<tab>selected = self._selected<tab>k = 0<tab>z = selected[k]<tab>k += 1<tab>for i in range(self._n):<tab><tab>if i == z:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>z = selected[k]<tab><tab><tab><tab>k += 1<tab><tab><tab>else:<tab><tab><tab><tab>z = -1<tab><tab>else:<tab><tab><tab>yield i,0,if k < len ( selected ) :,if selected [ k ] != - 1 :,0.019030985543513193,5.934202609760488,0.3333333333333333
"def render_headers(self) -> bytes:<tab>if not hasattr(self, ""_headers""):<tab><tab>parts = [<tab><tab><tab>b""Content-Disposition: form-data; "",<tab><tab><tab>format_form_param(""name"", self.name),<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>filename = format_form_param(""filename"", self.filename)<tab><tab><tab>parts.extend([b""; "", filename])<tab><tab>if self.content_type is not None:<tab><tab><tab>content_type = self.content_type.encode()<tab><tab><tab>parts.extend([b""\r\nContent-Type: "", content_type])<tab><tab>parts.append(b""\r\n\r\n"")<tab><tab>self._headers = b"""".join(parts)<tab>return self._headers",0,if self . filename :,if self . filename is not None :,0.3514988343435983,36.55552228545123,0.5102040816326531
"def app_middleware(next, root, info, **kwargs):<tab>app_auth_header = ""HTTP_AUTHORIZATION""<tab>prefix = ""bearer""<tab>request = info.context<tab>if request.path == API_PATH:<tab><tab>if not hasattr(request, ""app""):<tab><tab><tab>request.app = None<tab><tab><tab>auth = request.META.get(app_auth_header, """").split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>auth_prefix, auth_token = auth<tab><tab><tab><tab>if auth_prefix.lower() == prefix:<tab><tab><tab><tab><tab>request.app = SimpleLazyObject(lambda: get_app(auth_token))<tab>return next(root, info, **kwargs)",1,if len ( auth ) == 2 :,if len ( auth ) == 2 :,0.75,100.00000000000004,1.0
"def _shortest_hypernym_paths(self, simulate_root):<tab>if self.offset == ""00000000"":<tab><tab>return {self: 0}<tab>queue = deque([(self, 0)])<tab>path = {}<tab>while queue:<tab><tab>s, depth = queue.popleft()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path[s] = depth<tab><tab>depth += 1<tab><tab>queue.extend((hyp, depth) for hyp in s._hypernyms())<tab>if simulate_root:<tab><tab>root = Synset(self._wordnet_corpus_reader, None, self.pos(), ""00000000"", """")<tab><tab>path[root] = max(path.values()) + 1<tab>return path",0,if s in path :,if s is None :,0.31497877230811644,23.643540225079384,0.42857142857142855
"def _populate_class_variables():<tab>lookup = {}<tab>reverse_lookup = {}<tab>characters_for_re = []<tab>for codepoint, name in list(codepoint2name.items()):<tab><tab>character = chr(codepoint)<tab><tab><IF-STMT><tab><tab><tab># There's no point in turning the quotation mark into<tab><tab><tab># &quot;, unless it happens within an attribute value, which<tab><tab><tab># is handled elsewhere.<tab><tab><tab>characters_for_re.append(character)<tab><tab><tab>lookup[character] = name<tab><tab># But we do want to turn &quot; into the quotation mark.<tab><tab>reverse_lookup[name] = character<tab>re_definition = ""[%s]"" % """".join(characters_for_re)<tab>return lookup, reverse_lookup, re.compile(re_definition)",0,if codepoint != 34 :,if character not in lookup :,0.030286782520570012,9.652434877402245,0.1875
"def prepare_data_status(self, view: sublime.View, data: Dict[str, Any]) -> Any:<tab>""""""Prepare the returned data for status""""""<tab>if (<tab><tab>data[""success""]<tab><tab>and ""No docstring"" not in data[""doc""]<tab><tab>and data[""doc""] != ""list\n""<tab>):<tab><tab>self.signature = data[""doc""]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self.signature = self.signature.splitlines()[2]<tab><tab>except KeyError:<tab><tab><tab>return<tab><tab>return self._show_status(view)",0,if self . _signature_excluded ( self . signature ) :,if self . signature is None :,0.08139431521582222,15.5131710174841,0.4292929292929293
"def _setup_once_tables(cls):<tab>if cls.run_define_tables == ""once"":<tab><tab>cls.define_tables(cls.metadata)<tab><tab><IF-STMT><tab><tab><tab>cls.metadata.create_all(cls.bind)<tab><tab>cls.tables.update(cls.metadata.tables)",1,"if cls . run_create_tables == ""once"" :","if cls . run_create_tables == ""once"" :",0.75,100.00000000000004,1.0
"def _send_recursive(self, files):<tab>for base in files:<tab><tab><IF-STMT><tab><tab><tab># filename mixed into the bunch<tab><tab><tab>self._send_files([base])<tab><tab><tab>continue<tab><tab>last_dir = asbytes(base)<tab><tab>for root, dirs, fls in os.walk(base):<tab><tab><tab>self._chdir(last_dir, asbytes(root))<tab><tab><tab>self._send_files([os.path.join(root, f) for f in fls])<tab><tab><tab>last_dir = asbytes(root)<tab><tab># back out of the directory<tab><tab>for i in range(len(os.path.split(last_dir))):<tab><tab><tab>self._send_popd()",0,if not os . path . isdir ( base ) :,"if base . endswith ( "".py"" ) :",0.02707344218606997,10.252286118120933,0.22115384615384615
"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab># Automatically register models if required.<tab>if not is_registered(self.model):<tab><tab>inline_fields = ()<tab><tab>for inline in self.inlines:<tab><tab><tab>inline_model, follow_field = self._reversion_introspect_inline_admin(inline)<tab><tab><tab>if inline_model:<tab><tab><tab><tab>self._reversion_autoregister(inline_model, ())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>inline_fields += (follow_field,)<tab><tab>self._reversion_autoregister(self.model, inline_fields)",1,if follow_field :,if follow_field :,0.5311706625951745,1e-10,1.0
"def dispatch_hook(key, hooks, hook_data, **kwargs):<tab>""""""Dispatches a hook dictionary on a given piece of data.""""""<tab>hooks = hooks or dict()<tab>hooks = hooks.get(key)<tab>if hooks:<tab><tab>if hasattr(hooks, ""__call__""):<tab><tab><tab>hooks = [hooks]<tab><tab>for hook in hooks:<tab><tab><tab>_hook_data = hook(hook_data, **kwargs)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hook_data = _hook_data<tab>return hook_data",1,if _hook_data is not None :,if _hook_data is not None :,0.75,100.00000000000004,1.0
"def __call__(self, image, crop=True):<tab>if isinstance(image, PTensor):<tab><tab>return self.crop_to_output(<tab><tab><tab>numpy_to_paddle(self(paddle_to_numpy(image), crop=False))<tab><tab>)<tab>else:<tab><tab>warp = cv.warpAffine(<tab><tab><tab>image,<tab><tab><tab>self.transform_matrix,<tab><tab><tab>image.shape[1::-1],<tab><tab><tab>borderMode=cv.BORDER_REPLICATE,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return self.crop_to_output(warp)<tab><tab>else:<tab><tab><tab>return warp",1,if crop :,if crop :,0.5311706625951745,1e-10,1.0
"def _analyze(self):<tab>lines = open(self.log_path, ""r"").readlines()<tab>prev_line = None<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>self.errors.append(line[len(""ERROR:"") :].strip())<tab><tab>elif line.startswith(""FAIL:"") and prev_line and prev_line.startswith(""=""):<tab><tab><tab>self.failures.append(line[len(""FAIL:"") :].strip())<tab><tab>prev_line = line",0,"if line . startswith ( ""ERROR:"" ) and prev_line and prev_line . startswith ( ""="" ) :","if line . startswith ( ""ERROR:"" ) and line . startswith ( ""="" ) :",0.6918816262563711,67.60409905684749,0.8666666666666666
"def end(self, name):<tab>self.soup.endData()<tab>completed_tag = self.soup.tagStack[-1]<tab>namespace, name = self._getNsTag(name)<tab>nsprefix = None<tab>if namespace is not None:<tab><tab>for inverted_nsmap in reversed(self.nsmaps):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nsprefix = inverted_nsmap[namespace]<tab><tab><tab><tab>break<tab>self.soup.handle_endtag(name, nsprefix)<tab>if len(self.nsmaps) > 1:<tab><tab># This tag, or one of its parents, introduced a namespace<tab><tab># mapping, so pop it off the stack.<tab><tab>self.nsmaps.pop()",0,if inverted_nsmap is not None and namespace in inverted_nsmap :,if namespace in inverted_nsmap :,0.3056424746098112,30.93485033266056,0.2
"def _bind_parameters(operation, parameters):<tab># inspired by MySQL Python Connector (conversion.py)<tab>string_parameters = {}<tab>for (name, value) in parameters.iteritems():<tab><tab>if value is None:<tab><tab><tab>string_parameters[name] = ""NULL""<tab><tab><IF-STMT><tab><tab><tab>string_parameters[name] = ""'"" + _escape(value) + ""'""<tab><tab>else:<tab><tab><tab>string_parameters[name] = str(value)<tab>return operation % string_parameters",0,"elif isinstance ( value , basestring ) :","elif isinstance ( value , str ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def plugin_on_song_ended(self, song, skipped):<tab>if song is not None:<tab><tab>rating = song(""~#rating"")<tab><tab>invrating = 1.0 - rating<tab><tab>delta = min(rating, invrating) / 2.0<tab><tab><IF-STMT><tab><tab><tab>rating -= delta<tab><tab>else:<tab><tab><tab>rating += delta<tab><tab>song[""~#rating""] = rating",0,if skipped :,if delta > invrating :,0.051944022748897464,1e-10,0.36
"def on_activated_async(self, view):<tab>if settings[""modified_lines_only""]:<tab><tab>self.freeze_last_version(view)<tab>if settings[""enabled""]:<tab><tab>match_trailing_spaces(view)<tab><tab># continuously watch view for changes to the visible region<tab><tab><IF-STMT><tab><tab><tab># track<tab><tab><tab>active_views[view.id()] = view.visible_region()<tab><tab><tab>self.update_on_region_change(view)",0,if not view . id ( ) in active_views :,if view . visible_region ( ) :,0.03604627719470489,11.113458655312735,0.2948717948717949
"def _notin_text(term, text, verbose=False):<tab>index = text.find(term)<tab>head = text[:index]<tab>tail = text[index + len(term) :]<tab>correct_text = head + tail<tab>diff = _diff_text(correct_text, text, verbose)<tab>newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)]<tab>for line in diff:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(u(""- "")):<tab><tab><tab>continue<tab><tab>if line.startswith(u(""+ "")):<tab><tab><tab>newdiff.append(u(""  "") + line[2:])<tab><tab>else:<tab><tab><tab>newdiff.append(line)<tab>return newdiff",0,"if line . startswith ( u ( ""Skipping"" ) ) :",if not line :,0.011687056796749884,2.215745752614824,0.32222222222222224
"def delete_all(path):<tab>ppath = os.getcwd()<tab>os.chdir(path)<tab>for fn in glob.glob(""*""):<tab><tab>fn_full = os.path.join(path, fn)<tab><tab>if os.path.isdir(fn):<tab><tab><tab>delete_all(fn_full)<tab><tab>elif fn.endswith("".png""):<tab><tab><tab>os.remove(fn_full)<tab><tab><IF-STMT><tab><tab><tab>os.remove(fn_full)<tab><tab>elif DELETE_ALL_OLD:<tab><tab><tab>os.remove(fn_full)<tab>os.chdir(ppath)<tab>os.rmdir(path)",0,"elif fn . endswith ( "".md"" ) :","elif fn . endswith ( "".png"" ) :",0.5473017787506802,70.16879391277372,1.0
"def reward(self):<tab>""""""Returns a tuple of sum of raw and processed rewards.""""""<tab>raw_rewards, processed_rewards = 0, 0<tab>for ts in self.time_steps:<tab><tab># NOTE: raw_reward and processed_reward are None for the first time-step.<tab><tab>if ts.raw_reward is not None:<tab><tab><tab>raw_rewards += ts.raw_reward<tab><tab><IF-STMT><tab><tab><tab>processed_rewards += ts.processed_reward<tab>return raw_rewards, processed_rewards",1,if ts . processed_reward is not None :,if ts . processed_reward is not None :,0.75,100.00000000000004,1.0
"def formatmonthname(self, theyear, themonth, withyear=True):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab>s = month_name[themonth]<tab><tab><IF-STMT><tab><tab><tab>s = s.decode(encoding)<tab><tab>if withyear:<tab><tab><tab>s = ""%s %s"" % (s, theyear)<tab><tab>return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",0,if encoding is not None :,if encoding :,0.050438393472541504,1e-10,0.39999999999999997
"def check_digest_auth(user, passwd):<tab>""""""Check user authentication using HTTP Digest auth""""""<tab>if request.headers.get(""Authorization""):<tab><tab>credentails = parse_authorization_header(request.headers.get(""Authorization""))<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>response_hash = response(<tab><tab><tab>credentails,<tab><tab><tab>passwd,<tab><tab><tab>dict(<tab><tab><tab><tab>uri=request.script_root + request.path,<tab><tab><tab><tab>body=request.data,<tab><tab><tab><tab>method=request.method,<tab><tab><tab>),<tab><tab>)<tab><tab>if credentails.get(""response"") == response_hash:<tab><tab><tab>return True<tab>return False",1,if not credentails :,if not credentails :,0.75,100.00000000000004,1.0
"def wrapped(self, request):<tab>try:<tab><tab>return self._finished<tab>except AttributeError:<tab><tab><IF-STMT><tab><tab><tab>if not request.session.shouldfail and not request.session.shouldstop:<tab><tab><tab><tab>log.debug(<tab><tab><tab><tab><tab>""%s is still going to be used, not terminating it. ""<tab><tab><tab><tab><tab>""Still in use on:\n%s"",<tab><tab><tab><tab><tab>self,<tab><tab><tab><tab><tab>pprint.pformat(list(self.node_ids)),<tab><tab><tab><tab>)<tab><tab><tab><tab>return<tab><tab>log.debug(""Finish called on %s"", self)<tab><tab>try:<tab><tab><tab>return func(request)<tab><tab>finally:<tab><tab><tab>self._finished = True",0,if self . node_ids :,if self . _finished :,0.39477865547525276,29.05925408079185,1.0
"def run_tests():<tab># type: () -> None<tab>x = 5<tab>with switch(x) as case:<tab><tab>if case(0):<tab><tab><tab>print(""zero"")<tab><tab><tab>print(""zero"")<tab><tab>elif case(1, 2):<tab><tab><tab>print(""one or two"")<tab><tab><IF-STMT><tab><tab><tab>print(""three or four"")<tab><tab>else:<tab><tab><tab>print(""default"")<tab><tab><tab>print(""another"")",1,"elif case ( 3 , 4 ) :","elif case ( 3 , 4 ) :",0.75,100.00000000000004,1.0
"def task_done(self):<tab>with self._cond:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""task_done() called too many times"")<tab><tab>if self._unfinished_tasks._semlock._is_zero():<tab><tab><tab>self._cond.notify_all()",0,if not self . _unfinished_tasks . acquire ( False ) :,if self . _unfinished_tasks . _semlock . _is_zero ( ) :,0.1517185239268402,38.05371078682543,0.3
"def _set_uid(self, val):<tab>if val is not None:<tab><tab><IF-STMT><tab><tab><tab>self.bus.log(""pwd module not available; ignoring uid."", level=30)<tab><tab><tab>val = None<tab><tab>elif isinstance(val, text_or_bytes):<tab><tab><tab>val = pwd.getpwnam(val)[2]<tab>self._uid = val",1,if pwd is None :,if pwd is None :,0.75,100.00000000000004,1.0
"def process_tag(hive_name, company, company_key, tag, default_arch):<tab>with winreg.OpenKeyEx(company_key, tag) as tag_key:<tab><tab>version = load_version_data(hive_name, company, tag, tag_key)<tab><tab>if version is not None:  # if failed to get version bail<tab><tab><tab>major, minor, _ = version<tab><tab><tab>arch = load_arch_data(hive_name, company, tag, tag_key, default_arch)<tab><tab><tab>if arch is not None:<tab><tab><tab><tab>exe_data = load_exe(hive_name, company, company_key, tag)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>exe, args = exe_data<tab><tab><tab><tab><tab>return company, major, minor, arch, exe, args",1,if exe_data is not None :,if exe_data is not None :,0.75,100.00000000000004,1.0
"def run(algs):<tab>for alg in algs:<tab><tab>vcs = alg.get(""variantcaller"")<tab><tab>if vcs:<tab><tab><tab>if isinstance(vcs, dict):<tab><tab><tab><tab>vcs = reduce(operator.add, vcs.values())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vcs = [vcs]<tab><tab><tab>return any(vc.startswith(prefix) for vc in vcs if vc)",0,"if not isinstance ( vcs , ( list , tuple ) ) :","elif isinstance ( vcs , list ) :",0.11305433449504623,22.871025343125112,0.109375
"def wrapper(self, *args, **kwargs):<tab>if not self.request.path.endswith(""/""):<tab><tab><IF-STMT><tab><tab><tab>uri = self.request.path + ""/""<tab><tab><tab>if self.request.query:<tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab>return<tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)",0,"if self . request . method in ( ""GET"" , ""HEAD"" ) :","if self . request . method == ""GET"" :",0.20698550511616517,35.9448917857391,0.823529411764706
"def check_response(self, response):<tab>""""""Specialized version of check_response().""""""<tab>for line in response:<tab><tab># Skip blank lines:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(b""OK""):<tab><tab><tab>return<tab><tab>elif line.startswith(b""Benutzer/Passwort Fehler""):<tab><tab><tab>raise BadLogin(line)<tab><tab>else:<tab><tab><tab>raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))",0,if not line . strip ( ) :,if not line :,0.07898193091364736,23.50540321304655,0.7777777777777778
"def Walk(self, hMenu=None):<tab>if not hMenu:<tab><tab>hMenu = self.handle<tab>n = user32.GetMenuItemCount(hMenu)<tab>mi = MENUITEMINFO()<tab>for i in range(n):<tab><tab>mi.fMask = 2  #  MIIM_ID<tab><tab>user32.GetMenuItemInfoA(hMenu, i, 1, byref(mi))<tab><tab>handle = user32.GetSubMenu(hMenu, i)<tab><tab><IF-STMT><tab><tab><tab>yield handle, self.ListItems(handle)<tab><tab><tab>for i in self.Walk(handle):<tab><tab><tab><tab>yield i",1,if handle :,if handle :,0.5311706625951745,1e-10,1.0
"def setSelection(self, labels):<tab>input = self.__validateInput(labels)<tab>if len(input) == 0 and not self.__allowEmptySelection:<tab><tab>return<tab>if self.__allowMultipleSelection:<tab><tab>self.__selectedLabels[:] = input<tab><tab>self.__selectionChanged()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Parameter must be single item or a list with one element.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.__selectedLabels[:] = input<tab><tab><tab>self.__selectionChanged()<tab># Remove all selected labels that are not in the menu, emit signals if necessary and update the button.<tab>self.__validateState()",0,if len ( input ) > 1 :,"if not isinstance ( input , list ) :",0.03526816862684217,11.99014838091355,0.2361111111111111
"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab>if ""axis"" in self.args:<tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab>if not isinstance(self.axis, int):<tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab>if ""momentum"" in self.args:<tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')",0,"if not isinstance ( self . momentum , ( int , float ) ) :","if not isinstance ( self . momentum , int ) :",0.37102555405745824,52.81951634615037,0.8676470588235294
"def get_order(self, aBuf):<tab>if not aBuf:<tab><tab>return -1, 1<tab># find out current char's byte length<tab>first_char = wrap_ord(aBuf[0])<tab>if (0x81 <= first_char <= 0x9F) or (0xE0 <= first_char <= 0xFC):<tab><tab>charLen = 2<tab>else:<tab><tab>charLen = 1<tab># return its order if it is hiragana<tab>if len(aBuf) > 1:<tab><tab>second_char = wrap_ord(aBuf[1])<tab><tab><IF-STMT><tab><tab><tab>return second_char - 0x9F, charLen<tab>return -1, charLen",0,if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,if 0x80 <= second_char <= 0x9F :,0.09883022218498905,22.951947096869965,0.27272727272727276
"def saveSpecial(self, **kwargs):<tab>for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST:<tab><tab>item = config.get_config(""misc"", kw)<tab><tab>value = kwargs.get(kw)<tab><tab>msg = item.set(value)<tab><tab><IF-STMT><tab><tab><tab>return badParameterResponse(msg)<tab>config.save_config()<tab>raise Raiser(self.__root)",1,if msg :,if msg :,0.5311706625951745,1e-10,1.0
"def sanitize_event_keys(kwargs, valid_keys):<tab># Sanity check: Don't honor keys that we don't recognize.<tab>for key in list(kwargs.keys()):<tab><tab><IF-STMT><tab><tab><tab>kwargs.pop(key)<tab># Truncate certain values over 1k<tab>for key in [""play"", ""role"", ""task"", ""playbook""]:<tab><tab>if isinstance(kwargs.get(""event_data"", {}).get(key), str):<tab><tab><tab>if len(kwargs[""event_data""][key]) > 1024:<tab><tab><tab><tab>kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars(<tab><tab><tab><tab><tab>1024<tab><tab><tab><tab>)",0,if key not in valid_keys :,if key in valid_keys :,0.23319028329115196,61.29752413741059,0.5599999999999999
"def toggleFactorReload(self, value=None):<tab>self.serviceFittingOptions[""useGlobalForceReload""] = (<tab><tab>value<tab><tab>if value is not None<tab><tab>else not self.serviceFittingOptions[""useGlobalForceReload""]<tab>)<tab>fitIDs = set()<tab>for fit in set(self._loadedFits):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if fit.calculated:<tab><tab><tab>fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""]<tab><tab><tab>fit.clearFactorReloadDependentData()<tab><tab><tab>fitIDs.add(fit.ID)<tab>return fitIDs",1,if fit is None :,if fit is None :,0.75,100.00000000000004,1.0
"def closest_unseen(self, row1, col1, filter=None):<tab># find the closest unseen from this row/col<tab>min_dist = maxint<tab>closest_unseen = None<tab>for row in range(self.height):<tab><tab>for col in range(self.width):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.map[row][col] == UNSEEN:<tab><tab><tab><tab><tab>dist = self.distance(row1, col1, row, col)<tab><tab><tab><tab><tab>if dist < min_dist:<tab><tab><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab><tab><tab>closest_unseen = (row, col)<tab>return closest_unseen",0,"if filter is None or ( row , col ) not in filter :",if filter is not None and self . map [ row ] [ col ] == filter :,0.20221772758799528,10.975762213309226,0.2641025641025641
"def getAlphaClone(lookfor, eager=None):<tab>if isinstance(lookfor, int):<tab><tab><IF-STMT><tab><tab><tab>item = get_gamedata_session().query(AlphaClone).get(lookfor)<tab><tab>else:<tab><tab><tab>item = (<tab><tab><tab><tab>get_gamedata_session()<tab><tab><tab><tab>.query(AlphaClone)<tab><tab><tab><tab>.options(*processEager(eager))<tab><tab><tab><tab>.filter(AlphaClone.ID == lookfor)<tab><tab><tab><tab>.first()<tab><tab><tab>)<tab>else:<tab><tab>raise TypeError(""Need integer as argument"")<tab>return item",1,if eager is None :,if eager is None :,0.75,100.00000000000004,1.0
"def _rle_encode(string):<tab>new = b""""<tab>count = 0<tab>for cur in string:<tab><tab>if not cur:<tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new += b""\0"" + bytes([count])<tab><tab><tab><tab>count = 0<tab><tab><tab>new += bytes([cur])<tab>return new",1,if count :,if count :,0.5311706625951745,1e-10,1.0
def result_iterator():<tab>try:<tab><tab>for future in fs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield future.result()<tab><tab><tab>else:<tab><tab><tab><tab>yield future.result(end_time - time.time())<tab>finally:<tab><tab>for future in fs:<tab><tab><tab>future.cancel(),0,if timeout is None :,if end_time is None :,0.39477865547525276,26.269098944241588,0.3333333333333333
"def _individual_get(self, segment, index_type, index, strictdoc):<tab>if index_type == ""val"":<tab><tab>for key, value in segment.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value<tab><tab><tab>if hasattr(key, ""text""):<tab><tab><tab><tab>if key.text == index[0]:<tab><tab><tab><tab><tab>return value<tab><tab>raise Exception(""Invalid state"")<tab>elif index_type == ""index"":<tab><tab>return segment[index]<tab>elif index_type == ""textslice"":<tab><tab>return segment[index[0] : index[1]]<tab>elif index_type == ""key"":<tab><tab>return index[1] if strictdoc else index[0]<tab>else:<tab><tab>raise Exception(""Invalid state"")",0,if key == index [ 0 ] :,if strictdoc and key . text == index [ 0 ] :,0.35736227893686767,50.08718428920986,0.22115384615384615
"def _reset_sequences(self, db_name):<tab>conn = connections[db_name]<tab>if conn.features.supports_sequence_reset:<tab><tab>sql_list = conn.ops.sequence_reset_by_name_sql(<tab><tab><tab>no_style(), conn.introspection.sequence_list()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>cursor = conn.cursor()<tab><tab><tab><tab>for sql in sql_list:<tab><tab><tab><tab><tab>cursor.execute(sql)<tab><tab><tab>except Exception:<tab><tab><tab><tab>transaction.rollback_unless_managed(using=db_name)<tab><tab><tab><tab>raise<tab><tab><tab>transaction.commit_unless_managed(using=db_name)",1,if sql_list :,if sql_list :,0.5311706625951745,1e-10,1.0
"def translate_to_statements(self, statements, conditional_write_vars):<tab>lines = []<tab>for stmt in statements:<tab><tab><IF-STMT><tab><tab><tab>self.temporary_vars.add((stmt.var, stmt.dtype))<tab><tab>line = self.translate_statement(stmt)<tab><tab>if stmt.var in conditional_write_vars:<tab><tab><tab>subs = {}<tab><tab><tab>condvar = conditional_write_vars[stmt.var]<tab><tab><tab>lines.append(""if %s:"" % condvar)<tab><tab><tab>lines.append(indent(line))<tab><tab>else:<tab><tab><tab>lines.append(line)<tab>return lines",0,"if stmt . op == "":="" and not stmt . var in self . variables :",if stmt . var not in self . temporary_vars :,0.19058096237010858,14.095879498999276,0.24166666666666664
"def _bytecode_filenames(self, py_filenames):<tab>bytecode_files = []<tab>for py_file in py_filenames:<tab><tab># Since build_py handles package data installation, the<tab><tab># list of outputs can contain more than just .py files.<tab><tab># Make sure we only report bytecode for the .py files.<tab><tab>ext = os.path.splitext(os.path.normcase(py_file))[1]<tab><tab>if ext != PYTHON_SOURCE_EXTENSION:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>bytecode_files.append(py_file + ""c"")<tab><tab>if self.optimize > 0:<tab><tab><tab>bytecode_files.append(py_file + ""o"")<tab>return bytecode_files",0,if self . compile :,if self . optimize > 0 :,0.11726065783135259,26.269098944241588,0.4761904761904762
"def logic():<tab>for i in range(100):<tab><tab>yield clock.posedge, reset.negedge<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count.next = (count + 1) % n<tab>raise StopSimulation",1,if enable :,if enable :,0.5311706625951745,1e-10,1.0
"def _is_subnet_of(a, b):<tab>try:<tab><tab># Always false if one is v4 and the other is v6.<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""%s and %s are not of the same version"" % (a, b))<tab><tab>return (<tab><tab><tab>b.network_address <= a.network_address<tab><tab><tab>and b.broadcast_address >= a.broadcast_address<tab><tab>)<tab>except AttributeError:<tab><tab>raise TypeError(<tab><tab><tab>""Unable to test subnet containment "" ""between %s and %s"" % (a, b)<tab><tab>)",0,if a . _version != b . _version :,if a . version != b . version :,0.6048262086007482,47.269442068339785,0.5599999999999999
"def _filter_paths(basename, path, is_dir, exclude):<tab>"""""".gitignore style file filtering.""""""<tab>for item in exclude:<tab><tab># Items ending in '/' apply only to directories.<tab><tab>if item.endswith(""/"") and not is_dir:<tab><tab><tab>continue<tab><tab># Items starting with '/' apply to the whole path.<tab><tab># In any other cases just the basename is used.<tab><tab>match = path if item.startswith(""/"") else basename<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,"if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",if match . lower ( ) == basename . lower ( ) :,0.2707756452612007,6.676728207062619,0.24342105263157893
"def __recv_null(self):<tab>""""""Receive a null byte.""""""<tab>while 1:<tab><tab>c = self.sock.recv(1)<tab><tab>if c == """":<tab><tab><tab>self.close()<tab><tab><tab>raise EOFError(""Socket Closed"")<tab><tab><IF-STMT><tab><tab><tab>return",0,"if c == ""\0"" :","if c == """" :",0.39477865547525276,53.137468984124546,1.0
"def onMessage(self, payload, isBinary):<tab>if isBinary:<tab><tab>self.result = ""Expected text message with payload, but got binary.""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.result = (<tab><tab><tab><tab>""Expected text message with payload of length %d, but got %d.""<tab><tab><tab><tab>% (self.DATALEN, len(payload))<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>## FIXME : check actual content<tab><tab><tab>##<tab><tab><tab>self.behavior = Case.OK<tab><tab><tab>self.result = ""Received text message of length %d."" % len(payload)<tab>self.p.createWirelog = True<tab>self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",1,if len ( payload ) != self . DATALEN :,if len ( payload ) != self . DATALEN :,0.75,100.00000000000004,1.0
"def rename_path(self, path, new_path):<tab>logger.debug(""rename_path '%s' -> '%s'"" % (path, new_path))<tab>dirs = self.readdir(path)<tab>for d in dirs:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d_path = """".join([path, ""/"", d])<tab><tab>d_new_path = """".join([new_path, ""/"", d])<tab><tab>attr = self.getattr(d_path)<tab><tab>if stat.S_ISDIR(attr[""st_mode""]):<tab><tab><tab>self.rename_path(d_path, d_new_path)<tab><tab>else:<tab><tab><tab>self.rename_item(d_path, d_new_path)<tab>self.rename_item(path, new_path, dir=True)",0,"if d in [ ""."" , "".."" ] :","if d . startswith ( ""."" ) :",0.0317660291754507,14.320952289897711,0.6
"def dir_box_click(self, double):<tab>if double:<tab><tab>name = self.list_box.get_selected_name()<tab><tab>path = os.path.join(self.directory, name)<tab><tab>suffix = os.path.splitext(name)[1]<tab><tab><IF-STMT><tab><tab><tab>self.directory = path<tab><tab>else:<tab><tab><tab>self.double_click_file(name)<tab>self.update()",0,if suffix not in self . suffixes and os . path . isdir ( path ) :,"if suffix == "".py"" :",0.010741756026245422,4.661841620661271,0.23376623376623373
"def __getattr__(self, key):<tab>try:<tab><tab>value = self.__parent.contents[key]<tab>except KeyError:<tab><tab>pass<tab>else:<tab><tab>if value is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value.mod_ns<tab><tab><tab>else:<tab><tab><tab><tab>assert isinstance(value, _MultipleClassMarker)<tab><tab><tab><tab>return value.attempt_get(self.__parent.path, key)<tab>raise AttributeError(<tab><tab>""Module %r has no mapped classes ""<tab><tab>""registered under the name %r"" % (self.__parent.name, key)<tab>)",0,"if isinstance ( value , _ModuleMarker ) :","if hasattr ( value , ""mod_ns"" ) :",0.09166808520089226,17.242221289766636,0.6
"def poll_thread():<tab>time.sleep(0.5)<tab>if process.wait() and process_state:<tab><tab>time.sleep(0.25)<tab><tab><IF-STMT><tab><tab><tab>stdout, stderr = process._communicate(None)<tab><tab><tab>logger.error(<tab><tab><tab><tab>""Web server process exited unexpectedly"",<tab><tab><tab><tab>""app"",<tab><tab><tab><tab>stdout=stdout,<tab><tab><tab><tab>stderr=stderr,<tab><tab><tab>)<tab><tab><tab>time.sleep(1)<tab><tab><tab>restart_server(1)",0,if not check_global_interrupt ( ) :,if process . poll ( ) :,0.10072898142194478,17.112717058426785,0.37777777777777777
"def apply_dateparser_timezone(utc_datetime, offset_or_timezone_abb):<tab>for name, info in _tz_offsets:<tab><tab><IF-STMT><tab><tab><tab>tz = StaticTzInfo(name, info[""offset""])<tab><tab><tab>return utc_datetime.astimezone(tz)",0,"if info [ ""regex"" ] . search ( "" %s"" % offset_or_timezone_abb ) :","if offset_or_timezone_abb and info [ ""offset"" ] is not None :",0.06225632804037144,32.636882853921946,0.23026315789473684
"def _load_wordlist(filename):<tab>if filename is None:<tab><tab>return {}<tab>path = None<tab>for dir in (CONFIG_DIR, ASSETS_DIR):<tab><tab>path = os.path.realpath(os.path.join(dir, filename))<tab><tab><IF-STMT><tab><tab><tab>break<tab>words = {}<tab>with open(path, encoding=""utf-8"") as f:<tab><tab>pairs = [word.strip().rsplit("" "", 1) for word in f]<tab><tab>pairs.sort(reverse=True, key=lambda x: int(x[1]))<tab><tab>words = {p[0]: int(p[1]) for p in pairs}<tab>return words",0,if os . path . exists ( path ) :,if not os . path . exists ( path ) :,0.6776644327756607,80.70557274927978,0.3181818181818182
"def terminate_processes_matching_names(match_strings, kill=False):<tab>""""""Terminates processes matching particular names (case sensitive).""""""<tab>if isinstance(match_strings, str):<tab><tab>match_strings = [match_strings]<tab>for process in psutil.process_iter():<tab><tab>try:<tab><tab><tab>process_info = process.as_dict(attrs=[""name"", ""pid""])<tab><tab><tab>process_name = process_info[""name""]<tab><tab>except (psutil.AccessDenied, psutil.NoSuchProcess, OSError):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>terminate_process(process_info[""pid""], kill)",0,if any ( x == process_name for x in match_strings ) :,if process_name in match_strings :,0.08285136745619912,18.897243358570165,0.2916666666666667
"def has_scheme(self, inp):<tab>if ""://"" in inp:<tab><tab>return True<tab>else:<tab><tab>authority = inp.replace(""/"", ""#"").replace(""?"", ""#"").split(""#"")[0]<tab><tab><IF-STMT><tab><tab><tab>_, host_or_port = authority.split("":"", 1)<tab><tab><tab># Assert it's not a port number<tab><tab><tab>if re.match(r""^\d+$"", host_or_port):<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",1,"if "":"" in authority :","if "":"" in authority :",0.75,100.00000000000004,1.0
"def close(self):<tab>with BrowserContext._BROWSER_LOCK:<tab><tab>BrowserContext._BROWSER_REFCNT -= 1<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Destroying browser main loop"")<tab><tab><tab>BrowserContext._BROWSER_LOOP.destroy()<tab><tab><tab>BrowserContext._BROWSER_LOOP = None",1,if BrowserContext . _BROWSER_REFCNT == 0 :,if BrowserContext . _BROWSER_REFCNT == 0 :,0.75,100.00000000000004,1.0
"def _mock_get_merge_ticks(self, order_book_id_list, trading_date, last_dt=None):<tab>for tick in self._ticks:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>self.env.data_proxy.get_future_trading_date(tick.datetime).date()<tab><tab><tab>!= trading_date.date()<tab><tab>):<tab><tab><tab>continue<tab><tab>if last_dt and tick.datetime <= last_dt:<tab><tab><tab>continue<tab><tab>yield tick",0,if tick . order_book_id not in order_book_id_list :,if self . env . data_proxy . get_order_book_id ( tick . book_id ) in order_book_id_list :,0.06646794608715817,37.83230776309825,0.27950310559006214
"def messageSourceStamps(self, source_stamps):<tab>text = """"<tab>for ss in source_stamps:<tab><tab>source = """"<tab><tab><IF-STMT><tab><tab><tab>source += ""[branch %s] "" % ss[""branch""]<tab><tab>if ss[""revision""]:<tab><tab><tab>source += str(ss[""revision""])<tab><tab>else:<tab><tab><tab>source += ""HEAD""<tab><tab>if ss[""patch""] is not None:<tab><tab><tab>source += "" (plus patch)""<tab><tab>discriminator = """"<tab><tab>if ss[""codebase""]:<tab><tab><tab>discriminator = "" '%s'"" % ss[""codebase""]<tab><tab>text += ""Build Source Stamp%s: %s\n"" % (discriminator, source)<tab>return text",1,"if ss [ ""branch"" ] :","if ss [ ""branch"" ] :",0.75,100.00000000000004,1.0
"def test_open_read_bytes(self, sftp):<tab>""""""Test reading bytes from a file""""""<tab>f = None<tab>try:<tab><tab>self._create_file(""file"", ""xxx"")<tab><tab>f = yield from sftp.open(""file"", ""rb"")<tab><tab>self.assertEqual((yield from f.read()), b""xxx"")<tab>finally:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>yield from f.close()<tab><tab>remove(""file"")",1,if f :,if f :,0.5311706625951745,1e-10,1.0
"def handler(chan, host, port):<tab>sock = socket()<tab>try:<tab><tab>sock.connect((host, port))<tab>except Exception as e:<tab><tab>if verbose == True:<tab><tab><tab>print(e)<tab><tab>return<tab>while True:<tab><tab>r, w, x = select.select([sock, chan], [], [])<tab><tab>if sock in r:<tab><tab><tab>data = sock.recv(1024)<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>break<tab><tab><tab>chan.send(data)<tab><tab><IF-STMT><tab><tab><tab>data = chan.recv(1024)<tab><tab><tab>if len(data) == 0:<tab><tab><tab><tab>break<tab><tab><tab>sock.send(data)<tab>chan.close()<tab>sock.close()",1,if chan in r :,if chan in r :,0.75,100.00000000000004,1.0
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = re.search(r""url\('/ks-waf-error\.png'\)"", page, re.I) is not None<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.5311706625951745,1e-10,1.0
"def __init__(self, raw):<tab>ticker_ticks = {}<tab>for tick in raw[""results""]:<tab><tab><IF-STMT><tab><tab><tab>ticker_ticks[tick[""T""]].append(tick)<tab><tab>else:<tab><tab><tab>ticker_ticks[tick[""T""]] = [tick]<tab>super().__init__(<tab><tab>{ticker: Aggsv2({""results"": ticks}) for ticker, ticks in ticker_ticks.items()}<tab>)",0,"if ticker_ticks . get ( tick [ ""T"" ] ) :","if tick [ ""T"" ] in ticker_ticks :",0.1882214844111194,43.48783281197403,0.4
"def _makefiles(self, f):<tab>if isinstance(f, dict):<tab><tab>for k, v in list(f.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.makedir(dirname=k, content=v)<tab><tab><tab>elif isinstance(v, str):<tab><tab><tab><tab>self.make_file(filename=k, content=v)<tab><tab><tab>else:  # pragma: nocover<tab><tab><tab><tab>raise ValueError(""Unexpected:"", k, v)<tab>elif isinstance(f, str):<tab><tab>self._make_empty_file(f)<tab>elif isinstance(f, list):<tab><tab>self.make_list(f)<tab>else:  # pragma: nocover<tab><tab>raise ValueError(""Unknown type:"", f)",0,"if isinstance ( v , list ) :","if isinstance ( v , str ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def migrate_command_storage(apps, schema_editor):<tab>model = apps.get_model(""terminal"", ""CommandStorage"")<tab>init_storage_data(model)<tab>setting = get_setting(apps, schema_editor, ""TERMINAL_COMMAND_STORAGE"")<tab>if not setting:<tab><tab>return<tab>values = get_storage_data(setting)<tab>for name, meta in values.items():<tab><tab>tp = meta.pop(""TYPE"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>model.objects.create(name=name, type=tp, meta=meta)",0,"if not tp or name in [ ""default"" , ""null"" ] :",if not tp :,0.03951964558718501,3.1811104014284406,0.5428571428571428
"def build_vertices(self, ulines):<tab>vertex_idx = 0<tab>vertices = collections.OrderedDict()<tab>for line in ulines:<tab><tab>for vt in line:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>new_vertex = (vt.u, vt.v, 0.0)<tab><tab><tab>if new_vertex in vertices:<tab><tab><tab><tab>continue<tab><tab><tab>vt.index = vertex_idx<tab><tab><tab>vertex_idx += 1<tab><tab><tab>vertices[new_vertex] = 1<tab>return vertex_idx, list(vertices.keys())",0,if vt . replacement is not None :,if vt . index == vertex_idx :,0.07775595958652023,16.784459625186194,0.3214285714285714
"def get_quarantine_count(self):<tab>""""""get obj/container/account quarantine counts""""""<tab>qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0}<tab>qdir = ""quarantined""<tab>for device in os.listdir(self.devices):<tab><tab>for qtype in qcounts:<tab><tab><tab>qtgt = os.path.join(self.devices, device, qdir, qtype)<tab><tab><tab>if os.path.exists(qtgt):<tab><tab><tab><tab>linkcount = os.lstat(qtgt).st_nlink<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>qcounts[qtype] += linkcount - 2<tab>return qcounts",1,if linkcount > 2 :,if linkcount > 2 :,0.75,100.00000000000004,1.0
"def _format_arg(self, name, trait_spec, value):<tab>if name == ""mask_file"":<tab><tab>return """"<tab>if name == ""op_string"":<tab><tab><IF-STMT><tab><tab><tab>if isdefined(self.inputs.mask_file):<tab><tab><tab><tab>return self.inputs.op_string % self.inputs.mask_file<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""-k %s option in op_string requires mask_file"")<tab>return super(ImageStats, self)._format_arg(name, trait_spec, value)",0,"if ""-k %s"" in self . inputs . op_string :",if self . inputs . op_string :,0.27520494391006745,45.64995457685804,0.38461538461538464
"def _update_theme_style(self, *args):<tab>self.line_color_normal = self.theme_cls.divider_color<tab>if not any([self.error, self._text_len_error]):<tab><tab>if not self.focus:<tab><tab><tab>self._current_hint_text_color = self.theme_cls.disabled_hint_text_color<tab><tab><tab>self._current_right_lbl_color = self.theme_cls.disabled_hint_text_color<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._current_error_color = self.theme_cls.disabled_hint_text_color",0,"if self . helper_text_mode == ""persistent"" :",if not self . focus :,0.04378500688306847,5.0887084190633125,0.35
"def createFields(self):<tab>for item in self.format:<tab><tab><IF-STMT><tab><tab><tab>yield item[0](self, *item[1:-1], **item[-1])<tab><tab>else:<tab><tab><tab>yield item[0](self, *item[1:])",0,"if isinstance ( item [ - 1 ] , dict ) :",if len ( item ) > 1 :,0.024253488432045528,8.816389211763417,0.5619047619047619
"def execute(self, statement, arguments=None):<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.cursor.execute(statement, arguments)<tab><tab><tab>else:<tab><tab><tab><tab>self.cursor.execute(statement)<tab><tab>except sqlite3.OperationalError as ex:<tab><tab><tab>if ""locked"" not in getSafeExString(ex):<tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>break<tab>if statement.lstrip().upper().startswith(""SELECT""):<tab><tab>return self.cursor.fetchall()",1,if arguments :,if arguments :,0.5311706625951745,1e-10,1.0
"def set_income_account_for_fixed_assets(self):<tab>disposal_account = depreciation_cost_center = None<tab>for d in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>if not disposal_account:<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>disposal_account,<tab><tab><tab><tab><tab>depreciation_cost_center,<tab><tab><tab><tab>) = get_disposal_account_and_cost_center(self.company)<tab><tab><tab>d.income_account = disposal_account<tab><tab><tab>if not d.cost_center:<tab><tab><tab><tab>d.cost_center = depreciation_cost_center",1,if d . is_fixed_asset :,if d . is_fixed_asset :,0.75,100.00000000000004,1.0
"def _convertNbCharsInNbBits(self, nbChars):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbChars is not None:<tab><tab>if isinstance(nbChars, int):<tab><tab><tab>nbMinBit = nbChars * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab>if nbChars[0] is not None:<tab><tab><tab><tab>nbMinBit = nbChars[0] * 8<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nbMaxBit = nbChars[1] * 8<tab>return (nbMinBit, nbMaxBit)",1,if nbChars [ 1 ] is not None :,if nbChars [ 1 ] is not None :,0.75,100.00000000000004,1.0
"def _get_service_full_name(self, name, help_command_table):<tab>if help_command_table and name not in self._NON_SERVICE_COMMANDS:<tab><tab><IF-STMT><tab><tab><tab>return self._HIGH_LEVEL_SERVICE_FULL_NAMES[name]<tab><tab>service = help_command_table.get(name)<tab><tab>if service:<tab><tab><tab>return service.service_model.metadata[""serviceFullName""]",1,if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,0.75,100.00000000000004,1.0
"def print_addresses(self):<tab>p = 3<tab>tmp_str = ""[""<tab>if self.get_len() >= 7:  # at least one complete IP address<tab><tab>while 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp_str += ""#""<tab><tab><tab>tmp_str += self.get_ip_address(p)<tab><tab><tab>p += 4<tab><tab><tab>if p >= self.get_len():<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>tmp_str += "", ""<tab>tmp_str += ""] ""<tab>if self.get_ptr() % 4:  # ptr field should be a multiple of 4<tab><tab>tmp_str += ""nonsense ptr field: %d "" % self.get_ptr()<tab>return tmp_str",0,if p + 1 == self . get_ptr ( ) :,if self . get_ptr ( ) % 4 :,0.27937309534637156,46.26266998613165,0.32222222222222224
"def run(self):<tab>for _ in range(self.n):<tab><tab>error = True<tab><tab>try:<tab><tab><tab>self.collection.insert_one({""test"": ""insert""})<tab><tab><tab>error = False<tab><tab>except:<tab><tab><tab>if not self.expect_exception:<tab><tab><tab><tab>raise<tab><tab><IF-STMT><tab><tab><tab>assert error",0,if self . expect_exception :,if self . verbose > 1 :,0.11726065783135259,26.269098944241588,0.55
"def create_composite_mounter_by_args(args):<tab>""""""Creates a CompositeMounter by the images in given args.""""""<tab>logging.info(""Mount images..."")<tab>mounter = composite_mounter.CompositeMounter()<tab>for partition in composite_mounter.SUPPORTED_PARTITIONS:<tab><tab>image_source = vars(args)[partition]<tab><tab><IF-STMT><tab><tab><tab>logging.info(""  %s=%s"", partition, image_source)<tab><tab><tab>mounter.add_by_mount_target(partition, image_source)<tab>if mounter.is_empty():<tab><tab>raise RuntimeError(""Must give at least one image source."")<tab>return mounter",0,if image_source :,if image_source is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def _get_containing_class(self, pyname):<tab>if isinstance(pyname, pynames.DefinedName):<tab><tab>scope = pyname.get_object().get_scope()<tab><tab>parent = scope.parent<tab><tab><IF-STMT><tab><tab><tab>return parent.pyobject",0,"if parent is not None and parent . get_kind ( ) == ""Class"" :","if parent and isinstance ( parent . pyobject , pyobjects . Class ) :",0.16226291321610725,6.883021523637864,0.22027972027972031
"def test_chunkcoding(self):<tab>tstring_lines = []<tab>for b in self.tstring:<tab><tab>lines = b.split(b""\n"")<tab><tab>last = lines.pop()<tab><tab>assert last == b""""<tab><tab>lines = [line + b""\n"" for line in lines]<tab><tab>tstring_lines.append(lines)<tab>for native, utf8 in zip(*tstring_lines):<tab><tab>u = self.decode(native)[0]<tab><tab>self.assertEqual(u, utf8.decode(""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(native, self.encode(u)[0])",0,if self . roundtriptest :,if self . use_utf8 :,0.39477865547525276,26.269098944241588,0.7
"def set_default_variants(apps, schema_editor):<tab>Product = apps.get_model(""product"", ""Product"")<tab>for product in Product.objects.iterator():<tab><tab>first_variant = product.variants.first()<tab><tab><IF-STMT><tab><tab><tab>product.default_variant = first_variant<tab><tab><tab>product.save(update_fields=[""default_variant"", ""updated_at""])",1,if first_variant :,if first_variant :,0.5311706625951745,1e-10,1.0
"def json(self):<tab>try:<tab><tab>if self.is_json():<tab><tab><tab>raw_data = self.raw_data()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raw_data = raw_data.decode(""utf-8"")<tab><tab><tab>return json.loads(raw_data)<tab>except ValueError:<tab><tab>pass",0,"if not isinstance ( raw_data , text_type ) :","if isinstance ( raw_data , bytes ) :",0.1884566599936256,44.360636895626136,0.4
"def clear_react(self, message: discord.Message, emoji: MutableMapping = None) -> None:<tab>try:<tab><tab>await message.clear_reactions()<tab>except discord.Forbidden:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>with contextlib.suppress(discord.HTTPException):<tab><tab><tab>async for key in AsyncIter(emoji.values(), delay=0.2):<tab><tab><tab><tab>await message.remove_reaction(key, self.bot.user)<tab>except discord.HTTPException:<tab><tab>return",0,if not emoji :,if self . bot . user is None :,0.03356366646827448,5.669791110976001,0.18518518518518517
"def check(self, value):<tab>value = String.check(self, value)<tab>if isinstance(value, str):<tab><tab>value = value.upper()<tab><tab>for prefix in (self.prefix, self.prefix.split(""_"", 1)[1]):<tab><tab><tab># e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD<tab><tab><tab>if value.startswith(prefix):<tab><tab><tab><tab>value = value[len(prefix) :]<tab><tab><tab>value = value.lstrip(""_"")<tab><tab><IF-STMT><tab><tab><tab>return getattr(self.group, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""No such constant: %s_%s"" % (self.prefix, value))<tab>else:<tab><tab>return value",1,"if hasattr ( self . group , value ) :","if hasattr ( self . group , value ) :",0.75,100.00000000000004,1.0
"def value(self):<tab>quote = False<tab>if self.defects:<tab><tab>quote = True<tab>else:<tab><tab>for x in self:<tab><tab><tab>if x.token_type == ""quoted-string"":<tab><tab><tab><tab>quote = True<tab>if quote:<tab><tab>pre = post = """"<tab><tab>if self[0].token_type == ""cfws"" or self[0][0].token_type == ""cfws"":<tab><tab><tab>pre = "" ""<tab><tab><IF-STMT><tab><tab><tab>post = "" ""<tab><tab>return pre + quote_string(self.display_name) + post<tab>else:<tab><tab>return super(DisplayName, self).value",0,"if self [ - 1 ] . token_type == ""cfws"" or self [ - 1 ] [ - 1 ] . token_type == ""cfws"" :","if self [ 0 ] . token_type == ""cfws"" or self [ 0 ] [ 0 ] . token_type == ""cfws"" :",0.6332054209965478,68.34938524258672,0.6666666666666666
"def get_drive(self, root_path="""", volume_guid_path=""""):<tab>for drive in self.drives:<tab><tab>if root_path:<tab><tab><tab>config_root_path = drive.get(""root_path"")<tab><tab><tab>if config_root_path and root_path == config_root_path:<tab><tab><tab><tab>return drive<tab><tab><IF-STMT><tab><tab><tab>config_volume_guid_path = drive.get(""volume_guid_path"")<tab><tab><tab>if config_volume_guid_path and config_volume_guid_path == volume_guid_path:<tab><tab><tab><tab>return drive",0,elif volume_guid_path :,if volume_guid_path :,0.11293884852539707,1e-10,0.3333333333333333
"def parse_edges(self, pcb):<tab>edges = []<tab>drawings = list(pcb.GetDrawings())<tab>bbox = None<tab>for m in pcb.GetModules():<tab><tab>for g in m.GraphicalItems():<tab><tab><tab>drawings.append(g)<tab>for d in drawings:<tab><tab>if d.GetLayer() == pcbnew.Edge_Cuts:<tab><tab><tab>parsed_drawing = self.parse_drawing(d)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>edges.append(parsed_drawing)<tab><tab><tab><tab>if bbox is None:<tab><tab><tab><tab><tab>bbox = d.GetBoundingBox()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>bbox.Merge(d.GetBoundingBox())<tab>if bbox:<tab><tab>bbox.Normalize()<tab>return edges, bbox",1,if parsed_drawing :,if parsed_drawing :,0.5311706625951745,1e-10,1.0
"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab>if isinstance(k, float):<tab><tab><tab>return unicode(float_repr(k))<tab><tab>elif ""regex"" in literal_or_identifier:<tab><tab><tab>return compose_regex(k)<tab><tab>elif isinstance(k, bool):<tab><tab><tab>return ""true"" if k else ""false""<tab><tab><IF-STMT><tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)",1,elif k is None :,elif k is None :,0.75,100.00000000000004,1.0
"def find_multiple_stats(stats, name, _found=None, _on_found=None):<tab>if _found is None:<tab><tab>_found = []<tab>for child_stats in stats:<tab><tab>if child_stats.name == name:<tab><tab><tab>_found.append(child_stats)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_on_found(_found)<tab><tab>find_multiple_stats(child_stats, name, _found)<tab>return _found",0,if callable ( _on_found ) :,if _on_found is not None :,0.028043015323814018,33.03164318013809,0.27777777777777773
"def _run_generated_code(<tab>self,<tab>code,<tab>globs,<tab>locs,<tab>fails_under_py3k=True,):<tab>import warnings<tab>from zope.interface._compat import PYTHON3<tab>with warnings.catch_warnings(record=True) as log:<tab><tab>warnings.resetwarnings()<tab><tab><IF-STMT><tab><tab><tab>exec(code, globs, locs)<tab><tab><tab>self.assertEqual(len(log), 0)  # no longer warn<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>exec(code, globs, locs)<tab><tab><tab>except TypeError:<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>if fails_under_py3k:<tab><tab><tab><tab><tab>self.fail(""Didn't raise TypeError"")",0,if not PYTHON3 :,if PYTHON3 :,0.09648852821835877,1e-10,0.41666666666666663
"def _get_node(self, node_id):<tab>self.non_terminated_nodes({})  # Side effect: updates cache<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>return self.cached_nodes[node_id]<tab><tab>instance = (<tab><tab><tab>self.compute.instances()<tab><tab><tab>.get(<tab><tab><tab><tab>project=self.provider_config[""project_id""],<tab><tab><tab><tab>zone=self.provider_config[""availability_zone""],<tab><tab><tab><tab>instance=node_id,<tab><tab><tab>)<tab><tab><tab>.execute()<tab><tab>)<tab><tab>return instance",1,if node_id in self . cached_nodes :,if node_id in self . cached_nodes :,0.75,100.00000000000004,1.0
"def skip_to_close_match(self):<tab>nestedCount = 1<tab>while 1:<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab>ttype = tok[""style""]<tab><tab>if ttype == SCE_PL_UNUSED:<tab><tab><tab>return<tab><tab>elif self.classifier.is_index_op(tok):<tab><tab><tab>tval = tok[""text""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.opHash[tval][1] == 1:<tab><tab><tab><tab><tab>nestedCount += 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>nestedCount -= 1<tab><tab><tab><tab><tab>if nestedCount <= 0:<tab><tab><tab><tab><tab><tab>break",0,if self . opHash . has_key ( tval ) :,if ttype == SCE_PL_HASH :,0.013468035777437931,4.521356896113449,0.30952380952380953
"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper:<tab># Prefer creating a new helper when at least one kwarg is specified.<tab>prefer_new = len(kwargs) > 0<tab>kwargs.update(infer_mode=infer_mode)<tab>is_training = not infer_mode if infer_mode is not None else self.training<tab>helper = self._train_helper if is_training else self._infer_helper<tab>if prefer_new or helper is None:<tab><tab>helper = self.create_helper(**kwargs)<tab><tab>if is_training and self._train_helper is None:<tab><tab><tab>self._train_helper = helper<tab><tab><IF-STMT><tab><tab><tab>self._infer_helper = helper<tab>return helper",0,elif not is_training and self . _infer_helper is None :,if is_infer and self . _infer_helper is None :,0.5165889769697404,67.71111323098607,0.1111111111111111
"def get_ldset(self, ldsets):<tab>ldset = None<tab>if self._properties[""ldset_name""] == """":<tab><tab>nldset = len(ldsets)<tab><tab>if nldset == 0:<tab><tab><tab>msg = _(""Logical Disk Set could not be found."")<tab><tab><tab>raise exception.NotFound(msg)<tab><tab>else:<tab><tab><tab>ldset = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>msg = (<tab><tab><tab><tab>_(""Logical Disk Set `%s` could not be found."")<tab><tab><tab><tab>% self._properties[""ldset_name""]<tab><tab><tab>)<tab><tab><tab>raise exception.NotFound(msg)<tab><tab>ldset = ldsets[self._properties[""ldset_name""]]<tab>return ldset",0,"if self . _properties [ ""ldset_name"" ] not in ldsets :",if nldset != len ( ldsets ) :,0.0133745220801175,2.882738686795162,0.2403846153846154
"def calc_fractal_serial(q, maxiter):<tab># calculate z using pure python on a numpy array<tab># note that, unlike the other two implementations,<tab># the number of iterations per point is NOT constant<tab>z = np.zeros(q.shape, complex)<tab>output = np.resize(<tab><tab>np.array(<tab><tab><tab>0,<tab><tab>),<tab><tab>q.shape,<tab>)<tab>for i in range(len(q)):<tab><tab>for iter in range(maxiter):<tab><tab><tab>z[i] = z[i] * z[i] + q[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output[i] = iter<tab><tab><tab><tab>break<tab>return output",0,if abs ( z [ i ] ) > 2.0 :,if iter < maxiter :,0.011636451275277468,3.8261660656802645,0.2761904761904762
"def _verifySubs(self):<tab>for inst in self.subs:<tab><tab>if not isinstance(inst, (_Block, _Instantiator, Cosimulation)):<tab><tab><tab>raise BlockError(_error.ArgType % (self.name,))<tab><tab><IF-STMT><tab><tab><tab>if not inst.modctxt:<tab><tab><tab><tab>raise BlockError(_error.InstanceError % (self.name, inst.callername))",0,"if isinstance ( inst , ( _Block , _Instantiator ) ) :",if inst . callername :,0.010805043283377891,2.3238598963754593,0.4
"def walks_generator():<tab>if filelist is not None:<tab><tab>bucket = []<tab><tab>for filename in filelist:<tab><tab><tab>with io.open(filename) as inf:<tab><tab><tab><tab>for line in inf:<tab><tab><tab><tab><tab>walk = [int(x) for x in line.strip(""\n"").split("" "")]<tab><tab><tab><tab><tab>bucket.append(walk)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield bucket<tab><tab><tab><tab><tab><tab>bucket = []<tab><tab>if len(bucket):<tab><tab><tab>yield bucket<tab>else:<tab><tab>for _ in range(epoch):<tab><tab><tab>for nodes in graph.node_batch_iter(batch_size):<tab><tab><tab><tab>walks = graph.random_walk(nodes, walk_len)<tab><tab><tab><tab>yield walks",1,if len ( bucket ) == batch_size :,if len ( bucket ) == batch_size :,0.75,100.00000000000004,1.0
def _traverse(op):<tab>if op in visited:<tab><tab>return<tab>visited.add(op)<tab>if tag.is_injective(op.tag):<tab><tab>if op not in s.outputs:<tab><tab><tab>s[op].compute_inline()<tab><tab>for tensor in op.input_tensors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_traverse(tensor.op)<tab>callback(op),0,"if isinstance ( tensor . op , tvm . te . ComputeOp ) :","if isinstance ( tensor . op , Tensor ) :",0.3130970844858226,47.39878501170795,0.5677083333333333
"def unwatch_run(self, run_id, handler):<tab>with self._dict_lock:<tab><tab><IF-STMT><tab><tab><tab>self._handlers_dict[run_id] = [<tab><tab><tab><tab>(start_cursor, callback)<tab><tab><tab><tab>for (start_cursor, callback) in self._handlers_dict[run_id]<tab><tab><tab><tab>if callback != handler<tab><tab><tab>]<tab><tab>if not self._handlers_dict[run_id]:<tab><tab><tab>del self._handlers_dict[run_id]<tab><tab><tab>run_id_dict = self._run_id_dict<tab><tab><tab>del run_id_dict[run_id]<tab><tab><tab>self._run_id_dict = run_id_dict",0,if run_id in self . _run_id_dict :,if run_id not in self . _handlers_dict :,0.22481588323865592,44.06401630925027,0.37777777777777777
"def _PromptMySQL(self, config):<tab>""""""Prompts the MySQL configuration, retrying if the configuration is invalid.""""""<tab>while True:<tab><tab>self._PromptMySQLOnce(config)<tab><tab><IF-STMT><tab><tab><tab>print(""Successfully connected to MySQL with the given configuration."")<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>print(""Error: Could not connect to MySQL with the given configuration."")<tab><tab><tab>retry = RetryBoolQuestion(""Do you want to retry MySQL configuration?"", True)<tab><tab><tab>if not retry:<tab><tab><tab><tab>raise ConfigInitError()",0,if self . _CheckMySQLConnection ( ) :,if self . _IsConnected ( ) :,0.3884893899276739,50.000000000000014,1.0
"def get_courses_without_topic(topic):<tab>data = []<tab>for entry in frappe.db.get_all(""Course""):<tab><tab>course = frappe.get_doc(""Course"", entry.name)<tab><tab>topics = [t.topic for t in course.topics]<tab><tab><IF-STMT><tab><tab><tab>data.append(course.name)<tab>return data",0,if not topics or topic not in topics :,if topic not in topics :,0.4291271377681715,48.23560797692261,0.19999999999999998
"def _error_handler(action, **keywords):<tab>if keywords:<tab><tab>file_type = keywords.get(""file_type"", None)<tab><tab>if file_type:<tab><tab><tab>raise exceptions.FileTypeNotSupported(<tab><tab><tab><tab>constants.FILE_TYPE_NOT_SUPPORTED_FMT % (file_type, action)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keywords.pop(""on_demand"")<tab><tab><tab>msg = ""Please check if there were typos in ""<tab><tab><tab>msg += ""function parameters: %s. Otherwise ""<tab><tab><tab>msg += ""unrecognized parameters were given.""<tab><tab><tab>raise exceptions.UnknownParameters(msg % keywords)<tab>else:<tab><tab>raise exceptions.UnknownParameters(""No parameters found!"")",1,"if ""on_demand"" in keywords :","if ""on_demand"" in keywords :",0.75,100.00000000000004,1.0
"def select(self, regions, register):<tab>self.view.sel().clear()<tab>to_store = []<tab>for r in regions:<tab><tab>self.view.sel().add(r)<tab><tab><IF-STMT><tab><tab><tab>to_store.append(self.view.substr(self.view.full_line(r)))<tab>if register:<tab><tab>text = """".join(to_store)<tab><tab>if not text.endswith(""\n""):<tab><tab><tab>text = text + ""\n""<tab><tab>state = State(self.view)<tab><tab>state.registers[register] = [text]",0,if register :,if self . view . full_line ( r ) :,0.04224510045373539,1e-10,0.30952380952380953
"def has_actor(self, message: HasActorMessage) -> ResultMessage:<tab>actor_ref = message.actor_ref<tab># lookup allocated<tab>for address, item in self._allocated_actors.items():<tab><tab>ref = create_actor_ref(address, actor_ref.uid)<tab><tab><IF-STMT><tab><tab><tab>return ResultMessage(message.message_id, True, protocol=message.protocol)<tab>return ResultMessage(message.message_id, False, protocol=message.protocol)",0,if ref in item :,if item . ref == ref :,0.031181343770877636,7.809849842300637,0.4
"def toggleMetaButton(self, event):<tab>""""""Process clicks on toggle buttons""""""<tab>clickedBtn = event.EventObject<tab>if wx.GetMouseState().GetModifiers() == wx.MOD_CONTROL:<tab><tab>activeBtns = [btn for btn in self.metaButtons if btn.GetValue()]<tab><tab><IF-STMT><tab><tab><tab>clickedBtn.setUserSelection(clickedBtn.GetValue())<tab><tab><tab>self.itemView.filterItemStore()<tab><tab>else:<tab><tab><tab># Do 'nothing' if we're trying to turn last active button off<tab><tab><tab># Keep button in the same state<tab><tab><tab>clickedBtn.setUserSelection(True)<tab>else:<tab><tab>for btn in self.metaButtons:<tab><tab><tab>btn.setUserSelection(btn == clickedBtn)<tab><tab>self.itemView.filterItemStore()",1,if activeBtns :,if activeBtns :,0.5311706625951745,1e-10,1.0
"def __init__(self, hub=None):  # pylint: disable=unused-argument<tab>if resolver._resolver is None:<tab><tab>_resolver = resolver._resolver = _DualResolver()<tab><tab>if config.resolver_nameservers:<tab><tab><tab>_resolver.network_resolver.nameservers[:] = config.resolver_nameservers<tab><tab><IF-STMT><tab><tab><tab>_resolver.network_resolver.lifetime = config.resolver_timeout<tab># Different hubs in different threads could be sharing the same<tab># resolver.<tab>assert isinstance(resolver._resolver, _DualResolver)<tab>self._resolver = resolver._resolver",1,if config . resolver_timeout :,if config . resolver_timeout :,0.75,100.00000000000004,1.0
"def sub_paragraph(self, li):<tab>""""""Search for checkbox in sub-paragraph.""""""<tab>found = False<tab>if len(li):<tab><tab>first = list(li)[0]<tab><tab><IF-STMT><tab><tab><tab>m = RE_CHECKBOX.match(first.text)<tab><tab><tab>if m is not None:<tab><tab><tab><tab>first.text = self.markdown.htmlStash.store(<tab><tab><tab><tab><tab>get_checkbox(m.group(""state"")), safe=True<tab><tab><tab><tab>) + m.group(""line"")<tab><tab><tab><tab>found = True<tab>return found",0,"if first . tag == ""p"" and first . text is not None :",if first . text :,0.04517906980366361,5.3941217755126925,0.2546296296296296
"def _check_mswin_locale(locale):<tab>msloc = None<tab>try:<tab><tab>msloc = _LOCALE_NAMES[locale[:5]][:2]<tab><tab>locale = locale[:5]<tab>except KeyError:<tab><tab>try:<tab><tab><tab>msloc = _LOCALE_NAMES[locale[:2]][:2]<tab><tab><tab>locale = locale[:2]<tab><tab>except KeyError:<tab><tab><tab># US English is the outlier, all other English locales want<tab><tab><tab># real English:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (""en_GB"", ""1252"")<tab><tab><tab>return (None, None)<tab>return (locale, msloc)",0,"if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :","if locale == ""en_GB"" :",0.009312218135768806,6.989525368951739,0.4222222222222222
"def setLabel(self, s, protect=False):<tab>""""""Set the label of the minibuffer.""""""<tab>c, k, w = self.c, self, self.w<tab>if w:<tab><tab># Support for the curses gui.<tab><tab><IF-STMT><tab><tab><tab>g.app.gui.set_minibuffer_label(c, s)<tab><tab>w.setAllText(s)<tab><tab>n = len(s)<tab><tab>w.setSelectionRange(n, n, insert=n)<tab><tab>if protect:<tab><tab><tab>k.mb_prefix = s",0,"if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :","if g . app . gui . is_minibuffer ( c , s ) :",0.26778695230900135,27.830016834556396,0.2426470588235294
"def getProc(su, innerTarget):<tab>if len(su) == 1:  # have a one element wedge<tab><tab>proc = (""first"", ""last"")<tab>else:<tab><tab>if su.isFirst(innerTarget) and su.isLast(innerTarget):<tab><tab><tab>proc = (""first"", ""last"")  # same element can be first and last<tab><tab><IF-STMT><tab><tab><tab>proc = (""first"",)<tab><tab>elif su.isLast(innerTarget):<tab><tab><tab>proc = (""last"",)<tab><tab>else:<tab><tab><tab>proc = ()<tab>return proc",1,elif su . isFirst ( innerTarget ) :,elif su . isFirst ( innerTarget ) :,0.75,100.00000000000004,1.0
"def await_test_end(self):<tab>iterations = 0<tab>while True:<tab><tab>if iterations > 100:<tab><tab><tab>self.log.debug(""Await: iteration limit reached"")<tab><tab><tab>return<tab><tab>status = self.master.get_status()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>iterations += 1<tab><tab>time.sleep(1.0)",0,"if status . get ( ""status"" ) == ""ENDED"" :","if status == ""RUNNING"" :",0.026933810325055336,12.59496650349099,0.7333333333333334
"def _handle_autocomplete_request_for_text(text):<tab>if not hasattr(text, ""autocompleter""):<tab><tab>if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text.autocompleter = Completer(text)<tab><tab><tab>elif isinstance(text, ShellText):<tab><tab><tab><tab>text.autocompleter = ShellCompleter(text)<tab><tab><tab>text.bind(""<1>"", text.autocompleter.on_text_click)<tab><tab>else:<tab><tab><tab>return<tab>text.autocompleter.handle_autocomplete_request()",1,"if isinstance ( text , CodeViewText ) :","if isinstance ( text , CodeViewText ) :",0.75,100.00000000000004,1.0
"def validate_party_details(self):<tab>if self.party:<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party))<tab><tab>if self.party_account and self.party_type in (""Customer"", ""Supplier""):<tab><tab><tab>self.validate_account_type(<tab><tab><tab><tab>self.party_account, [erpnext.get_party_account_type(self.party_type)]<tab><tab><tab>)",0,"if not frappe . db . exists ( self . party_type , self . party ) :","if self . party_type not in [ ""Customer"" , ""Supplier"" ] :",0.1358528983371166,22.0294066346937,0.20202020202020204
"def format(self, formatstr):<tab>pieces = []<tab>for i, piece in enumerate(re_formatchars.split(force_text(formatstr))):<tab><tab><IF-STMT><tab><tab><tab>pieces.append(force_text(getattr(self, piece)()))<tab><tab>elif piece:<tab><tab><tab>pieces.append(re_escaped.sub(r""\1"", piece))<tab>return """".join(pieces)",0,if i % 2 :,if i == 0 :,0.31497877230811644,17.965205598154213,0.6
"def _convert_java_pattern_to_python(pattern):<tab>""""""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`.""""""<tab>s = list(pattern)<tab>i = 0<tab>while i < len(s) - 1:<tab><tab>c = s[i]<tab><tab><IF-STMT><tab><tab><tab>s[i] = ""\\""<tab><tab>elif c == ""\\"" and s[i + 1] == ""$"":<tab><tab><tab>s[i] = """"<tab><tab><tab>i += 1<tab><tab>i += 1<tab>return pattern[:0].join(s)",0,"if c == ""$"" and s [ i + 1 ] in ""0123456789"" :","if c == ""\\"" :",0.06873169436917037,16.898959014073654,0.34210526315789475
"def download(self, url, filename, **kwargs):<tab>try:<tab><tab>r = self.get(url, timeout=10, stream=True, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab>for chunk in r.iter_content(chunk_size=1024):<tab><tab><tab><tab>if chunk:<tab><tab><tab><tab><tab>f.write(chunk)<tab><tab>helpers.chmod_as_parent(filename)<tab>except Exception as e:<tab><tab>sickrage.app.log.debug(<tab><tab><tab>""Failed to download file from {} - ERROR: {}"".format(url, e)<tab><tab>)<tab><tab>if os.path.exists(filename):<tab><tab><tab>os.remove(filename)<tab><tab>return False<tab>return True",0,if r . status_code >= 400 :,if not r :,0.024483625633697423,4.690733795095046,0.4
"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedFilesWithExtension(""js""):<tab><tab>items.append(<tab><tab><tab>'<script type=""text/javascript"" src=""'<tab><tab><tab>+ item.pathAbsoluteFromProjectEncoded()<tab><tab><tab>+ '""></script>'<tab><tab>)<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",1,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,100.00000000000004,1.0
"def work(self):<tab>while True:<tab><tab>timeout = self.timeout<tab><tab>if idle.is_set():<tab><tab><tab>timeout = self.idle_timeout<tab><tab>log.debug(""Wait for {}"".format(timeout))<tab><tab>fetch.wait(timeout)<tab><tab><IF-STMT><tab><tab><tab>log.info(""Stop fetch worker"")<tab><tab><tab>break<tab><tab>self.fetch()",0,if shutting_down . is_set ( ) :,if fetch . is_set ( ) :,0.574113272471593,60.10525952194528,0.6363636363636364
"def check_apns_certificate(ss):<tab>mode = ""start""<tab>for s in ss.split(""\n""):<tab><tab>if mode == ""start"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mode = ""key""<tab><tab>elif mode == ""key"":<tab><tab><tab>if ""END RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s:<tab><tab><tab><tab>mode = ""end""<tab><tab><tab><tab>break<tab><tab><tab>elif s.startswith(""Proc-Type"") and ""ENCRYPTED"" in s:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Encrypted APNS private keys are not supported""<tab><tab><tab><tab>)<tab>if mode != ""end"":<tab><tab>raise ImproperlyConfigured(""The APNS certificate doesn't contain a private key"")",0,"if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s :","if ""RSA PRIVATE KEY"" in s or ""END RSA PRIVATE KEY"" in s :",0.8163445780948632,68.99302125555486,0.5
"def compare_lists(self, l1, l2, key):<tab>l2_lookup = {o.get(key): o for o in l2}<tab>for obj1 in l1:<tab><tab>obj2 = l2_lookup.get(obj1.get(key))<tab><tab>for k in obj1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(obj1.get(k), obj2.get(k))",0,"if k not in ""id"" and obj1 . get ( k ) :",if k in l2_lookup :,0.017683240570122077,4.981224652850502,0.29166666666666663
"def before_get_object(self, view_kwargs):<tab>if view_kwargs.get(""id"") is not None:<tab><tab>try:<tab><tab><tab>user_favourite_event = find_user_favourite_event_by_id(<tab><tab><tab><tab>event_id=view_kwargs[""id""]<tab><tab><tab>)<tab><tab>except NoResultFound:<tab><tab><tab>raise ObjectNotFound(<tab><tab><tab><tab>{""source"": ""/data/relationships/event""}, ""Object: not found""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>view_kwargs[""id""] = user_favourite_event.id<tab><tab><tab>else:<tab><tab><tab><tab>view_kwargs[""id""] = None",0,if user_favourite_event is not None :,if user_favourite_event :,0.050438393472541504,1e-10,0.3142857142857143
"def close(self):<tab>super().close()<tab>if not sys.is_finalizing():<tab><tab>for sig in list(self._signal_handlers):<tab><tab><tab>self.remove_signal_handler(sig)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>f""Closing the loop {self!r} ""<tab><tab><tab><tab>f""on interpreter shutdown ""<tab><tab><tab><tab>f""stage, skipping signal handlers removal"",<tab><tab><tab><tab>ResourceWarning,<tab><tab><tab><tab>source=self,<tab><tab><tab>)<tab><tab><tab>self._signal_handlers.clear()",0,if self . _signal_handlers :,if self . _shutdown :,0.39477865547525276,38.49815007763549,1.0
"def install_script(self, script, install_options=None):<tab>try:<tab><tab>fname = utils.do_script(<tab><tab><tab>script,<tab><tab><tab>python_exe=osp.join(self.target, ""python.exe""),<tab><tab><tab>architecture=self.architecture,<tab><tab><tab>verbose=self.verbose,<tab><tab><tab>install_options=install_options,<tab><tab>)<tab>except RuntimeError:<tab><tab><IF-STMT><tab><tab><tab>print(""Failed!"")<tab><tab><tab>raise",0,if not self . verbose :,if self . verbose :,0.281663156243144,57.89300674674101,0.36
"def GetRouterForUser(self, username):<tab>""""""Returns a router corresponding to a given username.""""""<tab>for index, router in enumerate(self.routers):<tab><tab>router_id = str(index)<tab><tab><IF-STMT><tab><tab><tab>logging.debug(<tab><tab><tab><tab>""Matched router %s to user %s"", router.__class__.__name__, username<tab><tab><tab>)<tab><tab><tab>return router<tab>logging.debug(<tab><tab>""No router ACL rule match for user %s. Using default "" ""router %s"",<tab><tab>username,<tab><tab>self.default_router.__class__.__name__,<tab>)<tab>return self.default_router",0,"if self . auth_manager . CheckPermissions ( username , router_id ) :",if router . id == username or router . id == router_id :,0.06312617935417404,10.878661088699644,0.35
"def charset(self):<tab>""""""The charset from the content type.""""""<tab>header = self.environ.get(""CONTENT_TYPE"")<tab>if header:<tab><tab>ct, options = parse_options_header(header)<tab><tab>charset = options.get(""charset"")<tab><tab><IF-STMT><tab><tab><tab>if is_known_charset(charset):<tab><tab><tab><tab>return charset<tab><tab><tab>return self.unknown_charset(charset)<tab>return self.default_charset",1,if charset :,if charset :,0.5311706625951745,1e-10,1.0
def isFinished(self):<tab># returns true if episode timesteps has reached episode length and resets the task<tab>if self.count > self.epiLen:<tab><tab>self.res()<tab><tab>return True<tab>else:<tab><tab>if self.count == 1:<tab><tab><tab>self.pertGlasPos(0)<tab><tab><IF-STMT><tab><tab><tab>self.env.reset()<tab><tab><tab>self.pertGlasPos(1)<tab><tab>self.count += 1<tab><tab>return False,0,if self . count == self . epiLen / 2 + 1 :,elif self . count == 2 :,0.22330517853272236,26.563123324397914,0.30833333333333335
"def mtimes_of_files(dirnames: List[str], suffix: str) -> Iterator[float]:<tab>for dirname in dirnames:<tab><tab>for root, dirs, files in os.walk(dirname):<tab><tab><tab>for sfile in files:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>yield path.getmtime(path.join(root, sfile))<tab><tab><tab><tab><tab>except OSError:<tab><tab><tab><tab><tab><tab>pass",1,if sfile . endswith ( suffix ) :,if sfile . endswith ( suffix ) :,0.75,100.00000000000004,1.0
"def get_all_hashes(self):<tab>event_hashes = []<tab>sample_hashes = []<tab>for a in self.event.attributes:<tab><tab>h = None<tab><tab>if a.type in (""md5"", ""sha1"", ""sha256""):<tab><tab><tab>h = a.value<tab><tab><tab>event_hashes.append(h)<tab><tab>elif a.type in (""filename|md5"", ""filename|sha1"", ""filename|sha256""):<tab><tab><tab>h = a.value.split(""|"")[1]<tab><tab><tab>event_hashes.append(h)<tab><tab><IF-STMT><tab><tab><tab>h = a.value.split(""|"")[1]<tab><tab><tab>sample_hashes.append(h)<tab>return event_hashes, sample_hashes",0,"elif a . type == ""malware-sample"" :","elif a . type in ( ""sample"" , ""sample"" ) :",0.2207012554905024,18.92240568795936,0.7866666666666667
"def _validate(self, event):<tab>if self.type is None:<tab><tab>return<tab>new = self.value<tab>if not isinstance(new, self.type) and new is not None:<tab><tab><IF-STMT><tab><tab><tab>self.value = event.old<tab><tab>types = repr(self.type) if isinstance(self.type, tuple) else self.type.__name__<tab><tab>raise ValueError(<tab><tab><tab>""LiteralInput expected %s type but value %s ""<tab><tab><tab>""is of type %s."" % (types, new, type(new).__name__)<tab><tab>)",0,if event :,if event . old is not None :,0.08273018186267159,1e-10,0.35714285714285715
"def update_dict(a, b):<tab>for key, value in b.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if key not in a:<tab><tab><tab>a[key] = value<tab><tab>elif isinstance(a[key], dict) and isinstance(value, dict):<tab><tab><tab>update_dict(a[key], value)<tab><tab>elif isinstance(a[key], list):<tab><tab><tab>a[key].append(value)<tab><tab>else:<tab><tab><tab>a[key] = [a[key], value]",0,if value is None :,"if key == ""__class__"" :",0.03412306583404374,4.02724819242185,0.25
"def on_pre_save(self, view):<tab>extOrClause = ""|"".join(s.get(""format_on_save_extensions""))<tab>extRegex = ""\\.("" + extOrClause + "")$""<tab>if s.get(""format_on_save"") and re.search(extRegex, view.file_name()):<tab><tab># only auto-format on save if there are no ""lint errors""<tab><tab># here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3<tab><tab>lints_regions = [""lint-keyword-underline"", ""lint-keyword-outline""]<tab><tab>for linter in lints_regions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>view.run_command(""js_format"")",0,if len ( view . get_regions ( linter ) ) :,"if linter . run_command ( ""js_format"" ) :",0.02707344218606997,7.768562846380172,0.375
"def readMemory(self, va, size):<tab>for mva, mmaxva, mmap, mbytes in self._map_defs:<tab><tab>if mva <= va < mmaxva:<tab><tab><tab>mva, msize, mperms, mfname = mmap<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise envi.SegmentationViolation(va)<tab><tab><tab>offset = va - mva<tab><tab><tab>return mbytes[offset : offset + size]<tab>raise envi.SegmentationViolation(va)",0,if not mperms & MM_READ :,if not mperms :,0.121601635792411,23.50540321304655,1.0
"def assertFilepathsEqual(self, p1, p2):<tab>if sys.platform == ""win32"":<tab><tab><IF-STMT><tab><tab><tab>p1 = [normcase(normpath(x)) for x in p1]<tab><tab><tab>p2 = [normcase(normpath(x)) for x in p2]<tab><tab>else:<tab><tab><tab>assert isinstance(p1, (str, unicode))<tab><tab><tab>p1 = normcase(normpath(p1))<tab><tab><tab>p2 = normcase(normpath(p2))<tab>self.assertEqual(p1, p2)",0,"if isinstance ( p1 , ( list , tuple ) ) :","if isinstance ( p1 , ( str , unicode ) ) :",0.5242963054628733,54.52469119630866,0.5
"def add_directory_csv_files(dir_path, paths=None):<tab>if not paths:<tab><tab>paths = []<tab>for p in listdir(dir_path):<tab><tab>path = join(dir_path, p)<tab><tab>if isdir(path):<tab><tab><tab># call recursively for each dir<tab><tab><tab>paths = add_directory_csv_files(path, paths)<tab><tab><IF-STMT><tab><tab><tab># add every file to the list<tab><tab><tab>paths.append(path)<tab>return paths",0,"elif isfile ( path ) and path . endswith ( "".csv"" ) :",elif os . path . isfile ( path ) :,0.16231357249836365,20.062095993750134,0.41904761904761906
"def _verifySubs(self):<tab>for inst in self.subs:<tab><tab><IF-STMT><tab><tab><tab>raise BlockError(_error.ArgType % (self.name,))<tab><tab>if isinstance(inst, (_Block, _Instantiator)):<tab><tab><tab>if not inst.modctxt:<tab><tab><tab><tab>raise BlockError(_error.InstanceError % (self.name, inst.callername))",0,"if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :","if not isinstance ( inst , _Arg ) :",0.17976077982523364,30.904141058621136,0.8253968253968255
"def __annotations_bytes(self):<tab>if self.annotations:<tab><tab>a = []<tab><tab>for k, v in self.annotations.items():<tab><tab><tab>if len(k) != 4:<tab><tab><tab><tab>raise errors.ProtocolError(""annotation key must be of length 4"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>k = k.encode(""ASCII"")<tab><tab><tab>a.append(struct.pack(""!4sH"", k, len(v)))<tab><tab><tab>a.append(v)<tab><tab>return b"""".join(a)<tab>return b""""",0,"if sys . version_info >= ( 3 , 0 ) :","if isinstance ( k , str ) :",0.02612309242726822,6.560271639619885,0.25
"def session(self, profile: str = ""default"", region: str = None) -> boto3.Session:<tab>region = self._get_region(region, profile)<tab>try:<tab><tab>session = self._cache_lookup(<tab><tab><tab>self._session_cache,<tab><tab><tab>[profile, region],<tab><tab><tab>self._boto3.Session,<tab><tab><tab>[],<tab><tab><tab>{""region_name"": region, ""profile_name"": profile},<tab><tab>)<tab>except ProfileNotFound:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>session = self._boto3.Session(region_name=region)<tab><tab>self._cache_set(self._session_cache, [profile, region], session)<tab>return session",0,"if profile != ""default"" :",if region is None :,0.03412306583404374,6.9717291216921975,0.25
"def spans_score(gold_spans, system_spans):<tab>correct, gi, si = 0, 0, 0<tab>while gi < len(gold_spans) and si < len(system_spans):<tab><tab>if system_spans[si].start < gold_spans[gi].start:<tab><tab><tab>si += 1<tab><tab><IF-STMT><tab><tab><tab>gi += 1<tab><tab>else:<tab><tab><tab>correct += gold_spans[gi].end == system_spans[si].end<tab><tab><tab>si += 1<tab><tab><tab>gi += 1<tab>return Score(len(gold_spans), len(system_spans), correct)",0,elif gold_spans [ gi ] . start < system_spans [ si ] . start :,elif system_spans [ si ] . end > gold_spans [ gi ] . end :,0.7574866101628968,63.745429466413455,0.3333333333333333
"def to_api(tag, raw_value):<tab>try:<tab><tab>api_tag, converter = _QL_TO_SC[tag] if tag else (""q"", None)<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>raise self.error(<tab><tab><tab><tab>""Unsupported '%s' tag. Try: %s"" % (tag, "", "".join(SUPPORTED))<tab><tab><tab>)<tab><tab>return None, None<tab>else:<tab><tab>value = str(converter(raw_value) if converter else raw_value)<tab><tab>return api_tag, value",0,if tag not in SUPPORTED :,if tag in SUPPORTED :,0.23319028329115196,40.93653765389909,0.4444444444444444
"def unpack(self, buf):<tab>dpkt.Packet.unpack(self, buf)<tab>buf = buf[self.__hdr_len__ :]<tab># single-byte IE<tab>if self.type & 0x80:<tab><tab>self.len = 0<tab><tab>self.data = b""""<tab># multi-byte IE<tab>else:<tab><tab># special PER-encoded UUIE<tab><tab><IF-STMT><tab><tab><tab>self.len = struct.unpack("">H"", buf[:2])[0]<tab><tab><tab>buf = buf[2:]<tab><tab># normal TLV-like IE<tab><tab>else:<tab><tab><tab>self.len = struct.unpack(""B"", buf[:1])[0]<tab><tab><tab>buf = buf[1:]<tab><tab>self.data = buf[: self.len]",0,if self . type == USER_TO_USER :,if len ( buf ) > 2 :,0.019801326568637086,3.983253478176822,0.2698412698412698
"def on_bt_search_clicked(self, widget):<tab>if self.current_provider is None:<tab><tab>return<tab>query = self.en_query.get_text()<tab>@self.obtain_podcasts_with<tab>def load_data():<tab><tab><IF-STMT><tab><tab><tab>return self.current_provider.on_search(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_URL:<tab><tab><tab>return self.current_provider.on_url(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_FILE:<tab><tab><tab>return self.current_provider.on_file(query)",0,if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,if self . current_provider . kind == directory . Provider .PROVIDER_SEARCH :,0.6305728540921773,100.00000000000004,1.0
"def _text(bitlist):<tab>out = """"<tab>for typ, text in bitlist:<tab><tab>if not typ:<tab><tab><tab>out += text<tab><tab><IF-STMT><tab><tab><tab>out += ""\\fI%s\\fR"" % text<tab><tab>elif typ in [""strong"", ""code""]:<tab><tab><tab>out += ""\\fB%s\\fR"" % text<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected tag %r inside text"" % (typ,))<tab>out = out.strip()<tab>out = re.sub(re.compile(r""^\s+"", re.M), """", out)<tab>return out",0,"elif typ == ""em"" :","elif typ in [ ""i"" , ""img"" ] :",0.04546639155283771,7.768562846380176,0.7307692307692308
"def process(self, buckets):<tab>with self.executor_factory(max_workers=3) as w:<tab><tab>futures = {}<tab><tab>results = []<tab><tab>for b in buckets:<tab><tab><tab>futures[w.submit(self.process_bucket, b)] = b<tab><tab>for f in as_completed(futures):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>b = futures[f]<tab><tab><tab><tab>self.log.error(<tab><tab><tab><tab><tab>""error modifying bucket:%s\n%s"", b[""Name""], f.exception()<tab><tab><tab><tab>)<tab><tab><tab>results += filter(None, [f.result()])<tab><tab>return results",1,if f . exception ( ) :,if f . exception ( ) :,0.75,100.00000000000004,1.0
"def check_settings(self):<tab>if self.settings_dict[""TIME_ZONE""] is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because USE_TZ is ""<tab><tab><tab><tab>""False."" % self.alias<tab><tab><tab>)<tab><tab>elif self.features.supports_timezones:<tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because its engine ""<tab><tab><tab><tab>""handles time zones conversions natively."" % self.alias<tab><tab><tab>)",0,if not settings . USE_TZ :,"if self . settings_dict [ "" USE_TZ"" ] is True :",0.020812994926445203,11.251329738544614,0.2761904761904762
"def process_webhook_prop(namespace):<tab>if not isinstance(namespace.webhook_properties, list):<tab><tab>return<tab>result = {}<tab>for each in namespace.webhook_properties:<tab><tab>if each:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key, value = each.split(""="", 1)<tab><tab><tab>else:<tab><tab><tab><tab>key, value = each, """"<tab><tab><tab>result[key] = value<tab>namespace.webhook_properties = result",1,"if ""="" in each :","if ""="" in each :",0.75,100.00000000000004,1.0
"def _expand_query_values(original_query_list):<tab>query_list = []<tab>for key, value in original_query_list:<tab><tab><IF-STMT><tab><tab><tab>query_list.append((key, value))<tab><tab>else:<tab><tab><tab>key_fmt = key + ""[%s]""<tab><tab><tab>value_list = _to_kv_list(value)<tab><tab><tab>query_list.extend((key_fmt % k, v) for k, v in value_list)<tab>return query_list",0,"if isinstance ( value , basestring ) :","if isinstance ( value , list ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def tags():<tab>""""""Return a dictionary of all tags in the form {hash: [tag_names, ...]}.""""""<tab>tags = {}<tab>for (n, c) in list_refs():<tab><tab>if n.startswith(""refs/tags/""):<tab><tab><tab>name = n[10:]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tags[c] = []<tab><tab><tab>tags[c].append(name)  # more than one tag can point at 'c'<tab>return tags",0,if not c in tags :,if c not in tags :,0.2201405707067377,35.930411196308434,0.6666666666666666
"def test_colorspiral(self):<tab>""""""Set of 625 colours, with jitter, using get_colors().""""""<tab>boxedge = 20<tab>boxes_per_row = 25<tab>rows = 0<tab>for i, c in enumerate(get_colors(625)):<tab><tab>self.c.setFillColor(c)<tab><tab>x1 = boxedge * (i % boxes_per_row)<tab><tab>y1 = rows * boxedge<tab><tab>self.c.rect(x1, y1, boxedge, boxedge, fill=1, stroke=0)<tab><tab><IF-STMT><tab><tab><tab>rows += 1<tab>self.finish()",0,if not ( i + 1 ) % boxes_per_row :,if i % boxes_per_row == 0 :,0.029245312147464356,39.085161980674464,0.32051282051282054
"def oldest_pending_update_in_days():<tab>""""""Return the datestamp of the oldest pending update""""""<tab>pendingupdatespath = os.path.join(<tab><tab>prefs.pref(""ManagedInstallDir""), ""UpdateNotificationTracking.plist""<tab>)<tab>try:<tab><tab>pending_updates = FoundationPlist.readPlist(pendingupdatespath)<tab>except FoundationPlist.NSPropertyListSerializationException:<tab><tab>return 0<tab>oldest_date = now = NSDate.date()<tab>for category in pending_updates:<tab><tab>for name in pending_updates[category]:<tab><tab><tab>this_date = pending_updates[category][name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>oldest_date = this_date<tab>return now.timeIntervalSinceDate_(oldest_date) / (24 * 60 * 60)",0,if this_date < oldest_date :,if this_date > oldest_date :,0.08141502097923063,59.694917920196445,1.0
"def _try_read_gpg(path):<tab>path = os.path.expanduser(path)<tab>cmd = _gpg_cmd() + [path]<tab>log.debug(""gpg cmd: %s"", cmd)<tab>try:<tab><tab>p = subprocess.Popen(<tab><tab><tab>cmd, env=os.environ, stdout=subprocess.PIPE, stderr=subprocess.PIPE<tab><tab>)<tab>except OSError as e:<tab><tab>log.error(""cannot decode %s with command '%s' (%s)"", path, "" "".join(cmd), e)<tab>else:<tab><tab>out, err = p.communicate()<tab><tab><IF-STMT><tab><tab><tab>log.error(err.decode(errors=""replace"").strip())<tab><tab><tab>return None<tab><tab>return out.decode(errors=""replace"")",0,if p . returncode != 0 :,if err :,0.020447728119319098,1e-10,0.2916666666666667
"def sort_nested_dictionary_lists(d):<tab>for k, v in d.items():<tab><tab><IF-STMT><tab><tab><tab>for i in range(0, len(v)):<tab><tab><tab><tab>if isinstance(v[i], dict):<tab><tab><tab><tab><tab>v[i] = await sort_nested_dictionary_lists(v[i])<tab><tab><tab><tab>d[k] = sorted(v)<tab><tab>if isinstance(v, dict):<tab><tab><tab>d[k] = await sort_nested_dictionary_lists(v)<tab>return d",1,"if isinstance ( v , list ) :","if isinstance ( v , list ) :",0.75,100.00000000000004,1.0
"def _the_callback(widget, event_id):<tab>point = widget.GetCenter()<tab>index = widget.WIDGET_INDEX<tab>if hasattr(callback, ""__call__""):<tab><tab><IF-STMT><tab><tab><tab>args = [point, index]<tab><tab>else:<tab><tab><tab>args = [point]<tab><tab>if pass_widget:<tab><tab><tab>args.append(widget)<tab><tab>try_callback(callback, *args)<tab>return",0,if num > 1 :,if pass_widget :,0.03549272049582243,1e-10,0.41666666666666663
"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None):<tab>new_parameters = []<tab>for hp in sub_cs.get_hyperparameters():<tab><tab>new_parameter = copy.deepcopy(hp)<tab><tab># Allow for an empty top-level parameter<tab><tab><IF-STMT><tab><tab><tab>new_parameter.name = prefix<tab><tab>elif not prefix == """":<tab><tab><tab>new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name)<tab><tab>new_parameters.append(new_parameter)<tab>for hp in new_parameters:<tab><tab>_add_hp(master_cs, hp)",0,"if new_parameter . name == """" :",if new_parameter . name . endswith ( delimiter ) :,0.24437377795063242,43.36189090348677,0.5714285714285714
"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.server.stop()<tab><tab>if self.sl_hdlr:<tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",1,if self . server :,if self . server :,0.75,100.00000000000004,1.0
"def app_uninstall_all(self, excludes=[], verbose=False):<tab>""""""Uninstall all apps""""""<tab>our_apps = [""com.github.uiautomator"", ""com.github.uiautomator.test""]<tab>output, _ = self.shell([""pm"", ""list"", ""packages"", ""-3""])<tab>pkgs = re.findall(r""package:([^\s]+)"", output)<tab>pkgs = set(pkgs).difference(our_apps + excludes)<tab>pkgs = list(pkgs)<tab>for pkg_name in pkgs:<tab><tab><IF-STMT><tab><tab><tab>print(""uninstalling"", pkg_name, "" "", end="""", flush=True)<tab><tab>ok = self.app_uninstall(pkg_name)<tab><tab>if verbose:<tab><tab><tab>print(""OK"" if ok else ""FAIL"")<tab>return pkgs",1,if verbose :,if verbose :,0.5311706625951745,1e-10,1.0
"def httpapi(self, arg, opts):<tab>sc = HttpAPIStatsCollector()<tab>headers = [""#Item"", ""Value""]<tab>table = []<tab>for k, v in sc.get().getStats().items():<tab><tab>if isinstance(v, dict):<tab><tab><tab>v = json.dumps(v)<tab><tab>row = []<tab><tab>row.append(""#%s"" % k)<tab><tab><IF-STMT><tab><tab><tab>row.append(formatDateTime(v))<tab><tab>else:<tab><tab><tab>row.append(v)<tab><tab>table.append(row)<tab>self.protocol.sendData(<tab><tab>tabulate(table, headers, tablefmt=""plain"", numalign=""left"").encode(""ascii"")<tab>)",0,"if k [ - 3 : ] == ""_at"" :","if k == ""date"" :",0.026933810325055336,14.27196680985931,0.7333333333333334
"def Get_Gene(self, id):<tab>""""""Retreive the gene name (GN).""""""<tab>entry = self.Get(id)<tab>if not entry:<tab><tab>return None<tab>GN = """"<tab>for line in string.split(entry, ""\n""):<tab><tab><IF-STMT><tab><tab><tab>GN = string.strip(line[5:])<tab><tab><tab>if GN[-1] == ""."":<tab><tab><tab><tab>GN = GN[0:-1]<tab><tab><tab>return GN<tab><tab>if line[0:2] == ""//"":<tab><tab><tab>break<tab>return GN",0,"if line [ 0 : 5 ] == ""GN   "" :","if line [ 0 : 5 ] == ""GN "" :",0.75,100.00000000000004,1.0
"def replace_dir_vars(path, d):<tab>""""""Replace common directory paths with appropriate variable references (e.g. /etc becomes ${sysconfdir})""""""<tab>dirvars = {}<tab># Sort by length so we get the variables we're interested in first<tab>for var in sorted(list(d.keys()), key=len):<tab><tab>if var.endswith(""dir"") and var.lower() == var:<tab><tab><tab>value = d.getVar(var)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dirvars[value] = var<tab>for dirpath in sorted(list(dirvars.keys()), reverse=True):<tab><tab>path = path.replace(dirpath, ""${%s}"" % dirvars[dirpath])<tab>return path",0,"if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :",if value is not None :,0.16115510987198903,1.13544432449426,0.21315789473684213
"def _scrub_generated_timestamps(self, target_workdir):<tab>""""""Remove the first line of comment from each file if it contains a timestamp.""""""<tab>for root, _, filenames in safe_walk(target_workdir):<tab><tab>for filename in filenames:<tab><tab><tab>source = os.path.join(root, filename)<tab><tab><tab>with open(source, ""r"") as f:<tab><tab><tab><tab>lines = f.readlines()<tab><tab><tab>if len(lines) < 1:<tab><tab><tab><tab>return<tab><tab><tab>with open(source, ""w"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>f.write(lines[0])<tab><tab><tab><tab>for line in lines[1:]:<tab><tab><tab><tab><tab>f.write(line)",0,if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,if len ( lines ) == 1 :,0.019051245413724494,3.1605687987917257,0.20987654320987653
"def get_all_active_plugins(self) -> List[BotPlugin]:<tab>""""""This returns the list of plugins in the callback ordered defined from the config.""""""<tab>all_plugins = []<tab>for name in self.plugins_callback_order:<tab><tab># None is a placeholder for any plugin not having a defined order<tab><tab><IF-STMT><tab><tab><tab>all_plugins += [<tab><tab><tab><tab>plugin<tab><tab><tab><tab>for name, plugin in self.plugins.items()<tab><tab><tab><tab>if name not in self.plugins_callback_order and plugin.is_activated<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>plugin = self.plugins[name]<tab><tab><tab>if plugin.is_activated:<tab><tab><tab><tab>all_plugins.append(plugin)<tab>return all_plugins",1,if name is None :,if name is None :,0.75,100.00000000000004,1.0
"def test_query_level(self):<tab>""Tests querying at a level other than max""<tab># level 2<tab>l2 = set()<tab>for p in self.tile_paths:<tab><tab>l2.add(p[0:2])<tab>for path in iterate_base4(2):<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(self.tree.query_path(path))<tab><tab>else:<tab><tab><tab>self.assertFalse(self.tree.query_path(path))<tab># level 1:<tab>self.assertTrue(self.tree.query_path((0,)))<tab>self.assertTrue(self.tree.query_path((1,)))<tab>self.assertTrue(self.tree.query_path((2,)))<tab>self.assertFalse(self.tree.query_path((3,)))",1,if path in l2 :,if path in l2 :,0.75,100.00000000000004,1.0
"def program_exists(name):<tab>paths = (os.getenv(""PATH"") or os.defpath).split(os.pathsep)<tab>for p in paths:<tab><tab>fn = ""%s/%s"" % (p, name)<tab><tab><IF-STMT><tab><tab><tab>return not os.path.isdir(fn) and os.access(fn, os.X_OK)",1,if os . path . exists ( fn ) :,if os . path . exists ( fn ) :,0.75,100.00000000000004,1.0
"def decoration_helper(self, patched, args, keywargs):<tab>extra_args = []<tab>with contextlib.ExitStack() as exit_stack:<tab><tab>for patching in patched.patchings:<tab><tab><tab>arg = exit_stack.enter_context(patching)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keywargs.update(arg)<tab><tab><tab>elif patching.new is DEFAULT:<tab><tab><tab><tab>extra_args.append(arg)<tab><tab>args += tuple(extra_args)<tab><tab>yield (args, keywargs)",0,if patching . attribute_name is not None :,if patching . new is keywargs :,0.20612608455670559,18.094495256969623,0.375
"def update_neighbor(neigh_ip_address, changes):<tab>rets = []<tab>for k, v in changes.items():<tab><tab>if k == neighbors.MULTI_EXIT_DISC:<tab><tab><tab>rets.append(_update_med(neigh_ip_address, v))<tab><tab><IF-STMT><tab><tab><tab>rets.append(update_neighbor_enabled(neigh_ip_address, v))<tab><tab>if k == neighbors.CONNECT_MODE:<tab><tab><tab>rets.append(_update_connect_mode(neigh_ip_address, v))<tab>return all(rets)",0,if k == neighbors . ENABLED :,if k == neighbors . ENABLED_DISC :,0.574113272471593,66.06328636027612,0.7714285714285715
"def calcUniqueStates(self):<tab># Here we show which colors can be relied on to map to an<tab># internal state.  The current position will be at the first<tab># character in the buffer styled that color, so this might not<tab># work in all cases.<tab>self.uniqueStates = {}<tab>for k in self.holdUniqueStates.keys():<tab><tab>v = self.holdUniqueStates[k]<tab><tab><IF-STMT><tab><tab><tab>self.uniqueStates[k] = v.keys()[0]<tab><tab><tab>log.debug(""Map style [%s] to state [%s]"", k, v.keys()[0])<tab><tab>log.debug(""Style [%s] maps to states [%s]"", k, "", "".join(v.keys()))<tab>self.holdUniqueStates = None",0,if len ( v . keys ( ) ) == 1 :,"if isinstance ( v , dict ) :",0.023405416318388987,7.433761660133445,0.3666666666666667
"def init_logger():<tab>configured_loggers = [log_config.get(""root"", {})] + [<tab><tab>logger for logger in log_config.get(""loggers"", {}).values()<tab>]<tab>used_handlers = {<tab><tab>handler for log in configured_loggers for handler in log.get(""handlers"", [])<tab>}<tab>for handler_id, handler in list(log_config[""handlers""].items()):<tab><tab><IF-STMT><tab><tab><tab>del log_config[""handlers""][handler_id]<tab><tab>elif ""filename"" in handler.keys():<tab><tab><tab>filename = handler[""filename""]<tab><tab><tab>logfile_path = Path(filename).expanduser().resolve()<tab><tab><tab>handler[""filename""] = str(logfile_path)<tab>logging.config.dictConfig(log_config)",0,if handler_id not in used_handlers :,if handler_id in used_handlers :,0.23319028329115196,66.90484408935988,0.4642857142857143
"def _selected_machines(self, virtual_machines):<tab>selected_machines = []<tab>for machine in virtual_machines:<tab><tab><IF-STMT><tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.tags and self._tags_match(machine.tags, self.tags):<tab><tab><tab>selected_machines.append(machine)<tab><tab>if self.locations and machine.location in self.locations:<tab><tab><tab>selected_machines.append(machine)<tab>return selected_machines",0,if self . _args . host and self . _args . host == machine . name :,if machine not in selected_machines :,0.056584375918072846,1.7426130460477305,0.20202020202020204
"def init(self):<tab>r = self.get_redis()<tab>if r:<tab><tab>key = ""pocsuite_target""<tab><tab>info_msg = ""[PLUGIN] try fetch targets from redis...""<tab><tab>logger.info(info_msg)<tab><tab>targets = r.get(key)<tab><tab>count = 0<tab><tab>if targets:<tab><tab><tab>for target in targets:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>count += 1<tab><tab>info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count)<tab><tab>logger.info(info_msg)",0,if self . add_target ( target ) :,"if r . get ( key , target ) :",0.07301587394120382,18.575057999133595,0.2619047619047619
"def tearDown(self):<tab>suffix = str(os.getgid())<tab>cli = monitoring_v3.MetricServiceClient()<tab>for md in cli.list_metric_descriptors(""projects/{}"".format(PROJECT)):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>cli.delete_metric_descriptor(md.name)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",0,"if ""OpenCensus"" in md . name and suffix in md . name :",if md . name . endswith ( suffix ) :,0.04878634469755696,11.708995388048033,0.20833333333333331
"def InitializeColours(self):<tab>""""""Initializes the 16 custom colours in :class:`CustomPanel`.""""""<tab>curr = self._colourData.GetColour()<tab>self._colourSelection = -1<tab>for i in range(16):<tab><tab>c = self._colourData.GetCustomColour(i)<tab><tab>if c.IsOk():<tab><tab><tab>self._customColours[i] = self._colourData.GetCustomColour(i)<tab><tab>else:<tab><tab><tab>self._customColours[i] = wx.WHITE<tab><tab><IF-STMT><tab><tab><tab>self._colourSelection = i",0,if c == curr :,if curr == c :,0.2901714209472326,21.3643503198117,0.5
"def __getitem__(self, index):<tab>if self._check():<tab><tab>if isinstance(index, int):<tab><tab><tab>if index < 0 or index >= len(self.features):<tab><tab><tab><tab>raise IndexError(index)<tab><tab><tab>if self.features[index] is None:<tab><tab><tab><tab>feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>(feature,) = _unpack(""!H"", feature[:2])<tab><tab><tab><tab><tab>self.features[index] = FEATURE[feature]<tab><tab><tab>return self.features[index]<tab><tab>elif isinstance(index, slice):<tab><tab><tab>indices = index.indices(len(self.features))<tab><tab><tab>return [self.__getitem__(i) for i in range(*indices)]",0,if feature :,if len ( feature ) > 2 :,0.046522600101893324,1e-10,0.36
"def _get_data_from_buffer(obj):<tab>try:<tab><tab>view = memoryview(obj)<tab>except TypeError:<tab><tab># try to use legacy buffer protocol if 2.7, otherwise re-raise<tab><tab><IF-STMT><tab><tab><tab>view = memoryview(buffer(obj))<tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""using old buffer interface to unpack %s; ""<tab><tab><tab><tab>""this leads to unpacking errors if slicing is used and ""<tab><tab><tab><tab>""will be removed in a future version"" % type(obj),<tab><tab><tab><tab>RuntimeWarning,<tab><tab><tab><tab>stacklevel=3,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise<tab>if view.itemsize != 1:<tab><tab>raise ValueError(""cannot unpack from multi-byte object"")<tab>return view",0,if PY2 :,"if hasattr ( obj , ""slicing"" ) :",0.04422835593777517,1e-10,0.38181818181818183
"def import_modules(modules, safe=True):<tab>""""""Safely import a list of *modules*""""""<tab>all = []<tab>for mname in modules:<tab><tab>if mname.endswith("".*""):<tab><tab><tab>to_load = expand_star(mname)<tab><tab>else:<tab><tab><tab>to_load = [mname]<tab><tab>for module in to_load:<tab><tab><tab>try:<tab><tab><tab><tab>all.append(import_module(module))<tab><tab><tab>except ImportError:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise<tab>return all",1,if not safe :,if not safe :,0.75,100.00000000000004,1.0
"def pack(types, *args):<tab>if len(types) != len(args):<tab><tab>raise Exception(""number of arguments does not match format string"")<tab>port = StringIO()<tab>for (type, value) in zip(types, args):<tab><tab>if type == ""V"":<tab><tab><tab>write_vuint(port, value)<tab><tab><IF-STMT><tab><tab><tab>write_vint(port, value)<tab><tab>elif type == ""s"":<tab><tab><tab>write_bvec(port, value)<tab><tab>else:<tab><tab><tab>raise Exception('unknown xpack format string item ""' + type + '""')<tab>return port.getvalue()",1,"elif type == ""v"" :","elif type == ""v"" :",1.0,100.00000000000004,1.0
"def create_local_app_folder(local_app_path):<tab>if exists(local_app_path):<tab><tab>raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path)<tab>for folder in subfolders(local_app_path):<tab><tab><IF-STMT><tab><tab><tab>os.mkdir(folder)<tab><tab><tab>init_path = join(folder, ""__init__.py"")<tab><tab><tab>if not exists(init_path):<tab><tab><tab><tab>create_file(init_path)",1,if not exists ( folder ) :,if not exists ( folder ) :,0.75,100.00000000000004,1.0
"def _get_node_type_specific_fields(self, node_id: str, fields_key: str) -> Any:<tab>fields = self.config[fields_key]<tab>node_tags = self.provider.node_tags(node_id)<tab>if TAG_RAY_USER_NODE_TYPE in node_tags:<tab><tab>node_type = node_tags[TAG_RAY_USER_NODE_TYPE]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(f""Unknown node type tag: {node_type}."")<tab><tab>node_specific_config = self.available_node_types[node_type]<tab><tab>if fields_key in node_specific_config:<tab><tab><tab>fields = node_specific_config[fields_key]<tab>return fields",1,if node_type not in self . available_node_types :,if node_type not in self . available_node_types :,0.75,100.00000000000004,1.0
"def _maybe_fix_sequence_in_union(<tab>aliases: List[Alias], typecst: cst.SubscriptElement) -> cst.SubscriptElement:<tab>slc = typecst.slice<tab>if isinstance(slc, cst.Index):<tab><tab>val = slc.value<tab><tab><IF-STMT><tab><tab><tab>return cst.ensure_type(<tab><tab><tab><tab>typecst.deep_replace(val, _get_clean_type_from_subscript(aliases, val)),<tab><tab><tab><tab>cst.SubscriptElement,<tab><tab><tab>)<tab>return typecst",0,"if isinstance ( val , cst . Subscript ) :","if isinstance ( val , cst . Union ) :",0.6049399806880458,70.71067811865478,0.7142857142857143
"def cancel_download(self, downloads):<tab># Make sure we're always dealing with a list<tab>if isinstance(downloads, Download):<tab><tab>downloads = [downloads]<tab>for download in downloads:<tab><tab><IF-STMT><tab><tab><tab>self.cancel_current_download()<tab><tab>else:<tab><tab><tab>self.__paused = True<tab><tab><tab>new_queue = queue.Queue()<tab><tab><tab>while not self.__queue.empty():<tab><tab><tab><tab>queued_download = self.__queue.get()<tab><tab><tab><tab>if download == queued_download:<tab><tab><tab><tab><tab>download.cancel()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>new_queue.put(queued_download)<tab><tab><tab>self.__queue = new_queue<tab><tab><tab>self.__paused = False",0,if download == self . __current_download :,if not self . __paused :,0.04378500688306847,23.206041459353074,0.6
"def migrate_account_metadata(account_id):<tab>from inbox.models.session import session_scope<tab>from inbox.models import Account<tab>with session_scope(versioned=False) as db_session:<tab><tab>account = db_session.query(Account).get(account_id)<tab><tab>if account.discriminator == ""easaccount"":<tab><tab><tab>create_categories_for_easfoldersyncstatuses(account, db_session)<tab><tab>else:<tab><tab><tab>create_categories_for_folders(account, db_session)<tab><tab><IF-STMT><tab><tab><tab>set_labels_for_imapuids(account, db_session)<tab><tab>db_session.commit()",0,"if account . discriminator == ""gmailaccount"" :","if account . discriminator == ""imapuids"" :",0.574113272471593,70.71067811865478,1.0
"def __init__(self, fmt=None, *args):<tab>if not isinstance(fmt, BaseException):<tab><tab>Error.__init__(self, fmt, *args)<tab>else:<tab><tab>e = fmt<tab><tab>cls = e.__class__<tab><tab>fmt = ""%s.%s: %s"" % (cls.__module__, cls.__name__, e)<tab><tab>tb = sys.exc_info()[2]<tab><tab><IF-STMT><tab><tab><tab>fmt += ""\n""<tab><tab><tab>fmt += """".join(traceback.format_tb(tb))<tab><tab>Error.__init__(self, fmt)",0,if tb :,if fmt :,0.3197504490129165,1e-10,0.5
"def setLabel(self, label):<tab>if label is None:<tab><tab><IF-STMT><tab><tab><tab>self.label.scene().removeItem(self.label)<tab><tab><tab>self.label = None<tab>else:<tab><tab>if self.label is None:<tab><tab><tab>self.label = TextItem()<tab><tab><tab>self.label.setParentItem(self)<tab><tab>self.label.setText(label)<tab><tab>self._updateLabel()",1,if self . label is not None :,if self . label is not None :,0.75,100.00000000000004,1.0
"def serve_until_stopped(self) -> None:<tab>while True:<tab><tab>rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout)<tab><tab><IF-STMT><tab><tab><tab>self.handle_request()<tab><tab>if self.event is not None and self.event.is_set():<tab><tab><tab>break",1,if rd :,if rd :,0.5311706625951745,1e-10,1.0
"def generateCompressedFile(inputfile, outputfile, formatstring):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>in_file = open(inputfile, ""rb"")<tab><tab><tab>in_data = in_file.read()<tab><tab><tab>out_file = open(inputfile + "".xz"", ""wb"")<tab><tab><tab>out_file.write(xz.compress(in_data))<tab><tab><tab>in_file.close()<tab><tab><tab>out_file.close()<tab><tab>else:<tab><tab><tab>tarout = tarfile.open(outputfile, formatstring)<tab><tab><tab>tarout.add(inputfile, arcname=os.path.basename(inputfile))<tab><tab><tab>tarout.close()<tab>except Exception as e:<tab><tab>print(e)<tab><tab>return False<tab>return True",0,"if formatstring == ""w:xz"" :","if formatstring == ""gzip"" :",0.39477865547525276,46.307771619910305,1.0
"def _datastore_get_handler(signal, sender, keys, **kwargs):<tab>txn = current_transaction()<tab>if txn:<tab><tab>for key in keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise PreventedReadError(<tab><tab><tab><tab><tab>""Attempted to read key (%s:%s) inside a transaction ""<tab><tab><tab><tab><tab>""where it was marked protected"" % (key.kind(), key.id_or_name())<tab><tab><tab><tab>)<tab><tab>txn._fetched_keys.update(set(keys))",0,if key in txn . _protected_keys :,if key . kind ( ) in txn . _fetched_keys :,0.08528109340833795,28.65612242047131,0.4871794871794872
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_access_token(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_expiration_time(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def write_vuint(port, x):<tab>if x < 0:<tab><tab>raise Exception(""vuints must not be negative"")<tab>elif x == 0:<tab><tab>port.write(""\0"")<tab>else:<tab><tab>while x:<tab><tab><tab>seven_bits = x & 0x7F<tab><tab><tab>x >>= 7<tab><tab><tab><IF-STMT><tab><tab><tab><tab>port.write(chr(0x80 | seven_bits))<tab><tab><tab>else:<tab><tab><tab><tab>port.write(chr(seven_bits))",0,if x :,if x & 0x80 :,0.09791453445388575,1e-10,0.7
"def _expand_srcs(self):<tab>""""""Expand src to [(src, full_path)]""""""<tab>result = []<tab>for src in self.srcs:<tab><tab>full_path = self._source_file_path(src)<tab><tab><IF-STMT><tab><tab><tab># Assume generated<tab><tab><tab>full_path = self._target_file_path(src)<tab><tab>result.append((src, full_path))<tab>return result",0,if not os . path . exists ( full_path ) :,"if full_path == ""."" :",0.012417879185700129,13.76074141597786,0.2916666666666667
"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/ops""):<tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))",1,"if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",0.75,100.00000000000004,1.0
"def set_shape(self, shape):<tab>""""""Sets a shape.""""""<tab>if self._shape is not None:<tab><tab>logger.warning('Modifying the shape of Placeholder ""%s"".', self.name)<tab>if not isinstance(shape, (list, tuple)):<tab><tab>shape = (shape,)<tab>shape = tuple(x if x != ""None"" else None for x in shape)<tab>for x in shape:<tab><tab><IF-STMT><tab><tab><tab>raise ParsingError(<tab><tab><tab><tab>'All entries in ""shape"" must be integers, or in special '<tab><tab><tab><tab>""cases None. Shape is: {}"".format(shape)<tab><tab><tab>)<tab>self._shape = shape",0,"if not isinstance ( x , ( int , type ( None ) ) ) :","if not isinstance ( x , int ) :",0.17057097110343122,31.25818143926065,0.7375
"def _get_field_actual(cant_be_number, raw_string, field_names):<tab>for line in raw_string.splitlines():<tab><tab>for field_name in field_names:<tab><tab><tab>field_name = field_name.lower()<tab><tab><tab>if "":"" in line:<tab><tab><tab><tab>left, right = line.split("":"", 1)<tab><tab><tab><tab>left = left.strip().lower()<tab><tab><tab><tab>right = right.strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if cant_be_number:<tab><tab><tab><tab><tab><tab>if not right.isdigit():<tab><tab><tab><tab><tab><tab><tab>return right<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return right<tab>return None",0,if left == field_name and len ( right ) > 0 :,if left == field_name :,0.10400131924210887,36.24372413507827,0.39285714285714285
"def validate_attributes(self):<tab>for attribute in self.get_all_attributes():<tab><tab>value = getattr(self, attribute.code, None)<tab><tab>if value is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code}<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>attribute.validate_value(value)<tab><tab><tab>except ValidationError as e:<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e}<tab><tab><tab><tab>)",0,if attribute . required :,if not self . blank :,0.032294703547118726,10.682175159905853,0.2571428571428572
"def append(self, s):<tab>buf = self.buf<tab>if buf is None:<tab><tab>strbuf = self.strbuf<tab><tab><IF-STMT><tab><tab><tab>self.strbuf = strbuf + s<tab><tab><tab>return<tab><tab>buf = self._create_buffer()<tab>buf.append(s)<tab># use buf.__len__ rather than len(buf) FBO of not getting<tab># OverflowError on Python 2<tab>sz = buf.__len__()<tab>if not self.overflowed:<tab><tab>if sz >= self.overflow:<tab><tab><tab>self._set_large_buffer()",0,if len ( strbuf ) + len ( s ) < STRBUF_LIMIT :,if strbuf :,0.007241875771263273,1e-10,0.3684210526315789
"def billing_invoice_show_validator(namespace):<tab>from azure.cli.core.azclierror import (<tab><tab>RequiredArgumentMissingError,<tab><tab>MutuallyExclusiveArgumentError,<tab>)<tab>valid_combs = (<tab><tab>""only --account-name, --name / --name / --name, --by-subscription is valid""<tab>)<tab>if namespace.account_name is not None:<tab><tab><IF-STMT><tab><tab><tab>raise MutuallyExclusiveArgumentError(valid_combs)<tab><tab>if namespace.name is None:<tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")<tab>if namespace.by_subscription is not None:<tab><tab>if namespace.name is None:<tab><tab><tab>raise RequiredArgumentMissingError(""--name is also required"")",0,if namespace . by_subscription is not None :,if namespace . name not in valid_combs :,0.32991956560314195,18.575057999133595,0.5
"def Handle(self, args, context=None):<tab>for client_id in args.client_ids:<tab><tab>cid = str(client_id)<tab><tab>data_store.REL_DB.RemoveClientLabels(cid, context.username, args.labels)<tab><tab>labels_to_remove = set(args.labels)<tab><tab>existing_labels = data_store.REL_DB.ReadClientLabels(cid)<tab><tab>for label in existing_labels:<tab><tab><tab>labels_to_remove.discard(label.name)<tab><tab><IF-STMT><tab><tab><tab>idx = client_index.ClientIndex()<tab><tab><tab>idx.RemoveClientLabels(cid, labels_to_remove)",1,if labels_to_remove :,if labels_to_remove :,0.5311706625951745,1e-10,1.0
"def delete_snapshot(self, snapshot):<tab>snap_name = self._get_snap_name(snapshot[""id""])<tab>LOG.debug(""Deleting snapshot (%s)"", snapshot[""id""])<tab>self.client_login()<tab>try:<tab><tab>self.client.delete_snapshot(snap_name, self.backend_type)<tab>except exception.DotHillRequestError as ex:<tab><tab># if the volume wasn't found, ignore the error<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>LOG.exception(""Deleting snapshot %s failed"", snapshot[""id""])<tab><tab>raise exception.Invalid(ex)<tab>finally:<tab><tab>self.client_logout()",0,"if ""The volume was not found on this system."" in ex . args :",if ex . status == 404 :,0.017178396846665406,4.264163893764324,0.12087912087912088
"def jobs(self):<tab># How many jobs have we done?<tab>total_processed = 0<tab>for jobEntity in self.jobItems.query_entities():<tab><tab># Process the items in the page<tab><tab>yield AzureJob.fromEntity(jobEntity)<tab><tab>total_processed += 1<tab><tab><IF-STMT><tab><tab><tab># Produce some feedback for the user, because this can take<tab><tab><tab># a long time on, for example, Azure<tab><tab><tab>logger.debug(""Processed %d total jobs"" % total_processed)<tab>logger.debug(""Processed %d total jobs"" % total_processed)",0,if total_processed % 1000 == 0 :,if total_processed % 10000 == 0 :,0.3884893899276739,65.80370064762461,0.6
def run(self):<tab>while not self.completed:<tab><tab>if self.block:<tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab>if self.timeout is not None:<tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab>if dt > self.timeout:<tab><tab><tab><tab>self.stop()<tab><tab><IF-STMT><tab><tab><tab>self.stop(),0,if self . counter == self . count :,elif dt < self . timeout :,0.02732155802770842,9.469167282754096,0.1111111111111111
"def get_instance(cls, pool_size=None):<tab>if cls._instance is not None:<tab><tab>return cls._instance<tab># Lazy init<tab>with cls._SINGLETON_LOCK:<tab><tab><IF-STMT><tab><tab><tab>cls._instance = cls(<tab><tab><tab><tab>ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size<tab><tab><tab>)<tab>return cls._instance",1,if cls . _instance is None :,if cls . _instance is None :,0.75,100.00000000000004,1.0
"def set_state(self, state):<tab>if self._inhibit_play:<tab><tab># PLAYING, PAUSED change the state for after buffering is finished,<tab><tab># everything else aborts buffering<tab><tab><IF-STMT><tab><tab><tab># abort<tab><tab><tab>self.__set_inhibit_play(False)<tab><tab><tab>self.bin.set_state(state)<tab><tab><tab>return<tab><tab>self._wanted_state = state<tab>else:<tab><tab>self.bin.set_state(state)",0,"if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :",if state == PAUSED :,0.010190386757789579,2.6126300161123828,0.27445652173913043
"def seen_add(options):<tab>seen_name = options.add_value<tab>if is_imdb_url(seen_name):<tab><tab>console(""IMDB url detected, try to parse ID"")<tab><tab>imdb_id = extract_id(seen_name)<tab><tab><IF-STMT><tab><tab><tab>seen_name = imdb_id<tab><tab>else:<tab><tab><tab>console(""Could not parse IMDB ID"")<tab>db.add(seen_name, ""cli_add"", {""cli_add"": seen_name})<tab>console(""Added %s as seen. This will affect all tasks."" % seen_name)",1,if imdb_id :,if imdb_id :,0.5311706625951745,1e-10,1.0
"def test_204_invalid_content_length(self):<tab># 204 status with non-zero content length is malformed<tab>with ExpectLog(gen_log, "".*Response with code 204 should not have body""):<tab><tab>response = self.fetch(""/?error=1"")<tab><tab>if not self.http1:<tab><tab><tab>self.skipTest(""requires HTTP/1.x"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""curl client accepts invalid headers"")<tab><tab>self.assertEqual(response.code, 599)",0,if self . http_client . configured_class != SimpleAsyncHTTPClient :,if not self . http2 :,0.031922647886786996,5.0887084190633125,0.3181818181818182
"def set_related_perm(_mapper: Mapper, _connection: Connection, target: Slice) -> None:<tab>src_class = target.cls_model<tab>id_ = target.datasource_id<tab>if id_:<tab><tab>ds = db.session.query(src_class).filter_by(id=int(id_)).first()<tab><tab><IF-STMT><tab><tab><tab>target.perm = ds.perm<tab><tab><tab>target.schema_perm = ds.schema_perm",1,if ds :,if ds :,0.5311706625951745,1e-10,1.0
"def on_modified_async(self, view):<tab>if self.is_command_line(view):<tab><tab><IF-STMT><tab><tab><tab>view.run_command(""text_pastry_selection_preview"")",0,"if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :","if view . get_command ( ""text_pastry_selection_preview"" ) :",0.013436629686425393,4.693585490589575,0.22176308539944903
"def _improve_answer_span(<tab>doc_tokens, input_start, input_end, tokenizer, orig_answer_text):<tab>""""""Returns tokenized answer spans that better match the annotated answer.""""""<tab>tok_answer_text = "" "".join(tokenizer.tokenize(orig_answer_text))<tab>for new_start in range(input_start, input_end + 1):<tab><tab>for new_end in range(input_end, new_start - 1, -1):<tab><tab><tab>text_span = "" "".join(doc_tokens[new_start : (new_end + 1)])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return new_start, new_end<tab>return input_start, input_end",1,if text_span == tok_answer_text :,if text_span == tok_answer_text :,0.75,100.00000000000004,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_app_version_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_method(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 34:<tab><tab><tab>self.set_queue(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def _add_resource_group(obj):<tab>if isinstance(obj, list):<tab><tab>for array_item in obj:<tab><tab><tab>_add_resource_group(array_item)<tab>elif isinstance(obj, dict):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if obj[""id""]:<tab><tab><tab><tab><tab>obj[""resourceGroup""] = _parse_id(obj[""id""])[""resource-group""]<tab><tab>except (KeyError, IndexError, TypeError):<tab><tab><tab>pass<tab><tab>for item_key in obj:<tab><tab><tab>if item_key != ""sourceVault"":<tab><tab><tab><tab>_add_resource_group(obj[item_key])",0,"if ""resourcegroup"" not in [ x . lower ( ) for x in obj . keys ( ) ] :","if ""resource-group"" not in obj :",0.07373656448490115,5.250363174428416,0.3817663817663818
"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], DECODE)<tab>version = DECODE_VERSION<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100.00000000000004,1.0
"def toterminal(self, tw):<tab># the entries might have different styles<tab>last_style = None<tab>for i, entry in enumerate(self.reprentries):<tab><tab><IF-STMT><tab><tab><tab>tw.line("""")<tab><tab>entry.toterminal(tw)<tab><tab>if i < len(self.reprentries) - 1:<tab><tab><tab>next_entry = self.reprentries[i + 1]<tab><tab><tab>if (<tab><tab><tab><tab>entry.style == ""long""<tab><tab><tab><tab>or entry.style == ""short""<tab><tab><tab><tab>and next_entry.style == ""long""<tab><tab><tab>):<tab><tab><tab><tab>tw.sep(self.entrysep)<tab>if self.extraline:<tab><tab>tw.line(self.extraline)",0,"if entry . style == ""long"" :",if entry . style == last_style :,0.38661327247159305,53.7284965911771,1.0
"def reposition_division(f1):<tab>lines = f1.splitlines()<tab>if lines[2] == division:<tab><tab>lines.pop(2)<tab>found = 0<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>found += 1<tab><tab><tab>if found == 2:<tab><tab><tab><tab>if division in ""\n"".join(lines):<tab><tab><tab><tab><tab>break  # already in the right place<tab><tab><tab><tab>lines.insert(i + 1, """")<tab><tab><tab><tab>lines.insert(i + 2, division)<tab><tab><tab><tab>break<tab>return ""\n"".join(lines)",0,"if line . startswith ( '""""""' ) :",if line . startswith ( division ) :,0.29904068129700634,36.06452879987793,0.7777777777777778
def run_on_module(self):<tab>try:<tab><tab>self.module_base.disable(self.opts.module_spec)<tab>except dnf.exceptions.MarkingErrors as e:<tab><tab>if self.base.conf.strict:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab><tab><tab>if (<tab><tab><tab><tab>e.module_depsolv_errors<tab><tab><tab><tab>and e.module_depsolv_errors[1]<tab><tab><tab><tab>!= libdnf.module.ModulePackageContainer.ModuleErrorType_ERROR_IN_DEFAULTS<tab><tab><tab>):<tab><tab><tab><tab>raise e<tab><tab>logger.error(str(e)),0,if e . no_match_group_specs or e . error_group_specs :,if self . base . conf . strict :,0.08910379478096775,2.2196021319769197,0.2361111111111111
"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64mime.base64_len(""hello""), len(base64mime.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab>elif size <= 6:<tab><tab><tab>bsize = 8<tab><tab><IF-STMT><tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64mime.base64_len(""x"" * size), bsize)",0,elif size <= 9 :,elif size <= 7 :,0.39287202148494,53.7284965911771,0.6
"def is_valid(self):<tab>""""""Determines whether file is valid for this reader""""""<tab>blocklist = self.open()<tab>valid = True<tab>for line in blocklist:<tab><tab>line = decode_bytes(line)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>(start, end) = self.parse(line)<tab><tab><tab><tab>if not re.match(r""^(\d{1,3}\.){4}$"", start + ""."") or not re.match(<tab><tab><tab><tab><tab>r""^(\d{1,3}\.){4}$"", end + "".""<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>valid = False<tab><tab><tab>except Exception:<tab><tab><tab><tab>valid = False<tab><tab><tab>break<tab>blocklist.close()<tab>return valid",0,if not self . is_ignored ( line ) :,if line :,0.07645429344094938,1e-10,0.3666666666666667
"def next(self):<tab>while self.index < len(self.data):<tab><tab>uid = self._read_next_word()<tab><tab>dont_care = self._read_next_word()<tab><tab>entry = self._read_next_string()<tab><tab>total_size = int(4 + 4 + len(entry))<tab><tab>count = int(total_size / self.SIZE)<tab><tab>if count == 0:<tab><tab><tab>mod = self.SIZE - total_size<tab><tab>else:<tab><tab><tab>mod = self.SIZE - int(total_size - (count * self.SIZE))<tab><tab><IF-STMT><tab><tab><tab>remainder = self._read_next_block(mod)<tab><tab>yield (uid, entry)",0,if mod > 0 :,if dont_care :,0.03549272049582243,1e-10,0.41666666666666663
"def _str_param_list(self, name):<tab>out = []<tab>if self[name]:<tab><tab>out += self._str_header(name)<tab><tab>for param in self[name]:<tab><tab><tab>parts = []<tab><tab><tab>if param.name:<tab><tab><tab><tab>parts.append(param.name)<tab><tab><tab>if param.type:<tab><tab><tab><tab>parts.append(param.type)<tab><tab><tab>out += ["" : "".join(parts)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out += self._str_indent(param.desc)<tab><tab>out += [""""]<tab>return out",0,"if param . desc and """" . join ( param . desc ) . strip ( ) :",if param . desc :,0.08353308051112926,4.299920764667028,0.44761904761904764
"def assert_backend(self, expected_translated, language=""cs""):<tab>""""""Check that backend has correct data.""""""<tab>translation = self.get_translation(language)<tab>translation.commit_pending(""test"", None)<tab>store = translation.component.file_format_cls(translation.get_filename(), None)<tab>messages = set()<tab>translated = 0<tab>for unit in store.content_units:<tab><tab>id_hash = unit.id_hash<tab><tab>self.assertFalse(id_hash in messages, ""Duplicate string in in backend file!"")<tab><tab><IF-STMT><tab><tab><tab>translated += 1<tab>self.assertEqual(<tab><tab>translated,<tab><tab>expected_translated,<tab><tab>""Did not found expected number of translations ({} != {})."".format(<tab><tab><tab>translated, expected_translated<tab><tab>),<tab>)",0,if unit . is_translated ( ) :,if id_hash != expected_translated :,0.02225082504991546,9.980099403873663,0.6363636363636364
"def status(self, name, error=""No matching script logs found""):<tab>with self.script_lock:<tab><tab><IF-STMT><tab><tab><tab>return self.script_running[1:]<tab><tab>elif self.script_last and self.script_last[1] == name:<tab><tab><tab>return self.script_last[1:]<tab><tab>else:<tab><tab><tab>raise ValueError(error)",1,if self . script_running and self . script_running [ 1 ] == name :,if self . script_running and self . script_running [ 1 ] == name :,0.75,100.00000000000004,1.0
"def dict_no_value_from_proto_list(obj_list):<tab>d = dict()<tab>for item in obj_list:<tab><tab>possible_dict = json.loads(item.value_json)<tab><tab><IF-STMT><tab><tab><tab># (tss) TODO: This is protecting against legacy 'wandb_version' field.<tab><tab><tab># Should investigate why the config payload even has 'wandb_version'.<tab><tab><tab>logger.warning(""key '{}' has no 'value' attribute"".format(item.key))<tab><tab><tab>continue<tab><tab>d[item.key] = possible_dict[""value""]<tab>return d",0,"if not isinstance ( possible_dict , dict ) or ""value"" not in possible_dict :","if ""value"" not in possible_dict :",0.2266319458061565,33.241660012938524,0.34920634920634924
"def visit(self, node):<tab>""""""dispatcher on node's class/bases name.""""""<tab>cls = node.__class__<tab>try:<tab><tab>visitmethod = self.cache[cls]<tab>except KeyError:<tab><tab>for subclass in cls.__mro__:<tab><tab><tab>visitmethod = getattr(self, subclass.__name__, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>visitmethod = self.__object<tab><tab>self.cache[cls] = visitmethod<tab>visitmethod(node)",0,if visitmethod is not None :,if visitmethod is None :,0.23319028329115196,40.93653765389909,0.611111111111111
"def _get_adapter(<tab>mcls,<tab>reversed_mro: Tuple[type, ...],<tab>collection: Dict[Any, Dict[type, Adapter]],<tab>kwargs: Dict[str, Any],) -> Optional[Adapter]:<tab>registry_key = mcls.get_registry_key(kwargs)<tab>adapters = collection.get(registry_key)<tab>if adapters is None:<tab><tab>return None<tab>result = None<tab>seen: Set[Adapter] = set()<tab>for base in reversed_mro:<tab><tab>for adaptee, adapter in adapters.items():<tab><tab><tab>found = mcls._match_adapter(base, adaptee, adapter)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = found<tab><tab><tab><tab>seen.add(found)<tab>return result",0,if found and found not in seen :,if found not in seen :,0.511766594272831,60.25286104785454,0.3095238095238095
"def test_pt_BR_rg(self):<tab>for _ in range(100):<tab><tab>to_test = self.fake.rg()<tab><tab><IF-STMT><tab><tab><tab>assert re.search(r""^\d{8}X"", to_test)<tab><tab>else:<tab><tab><tab>assert re.search(r""^\d{9}$"", to_test)",0,"if ""X"" in to_test :","if sys . platform == ""win32"" :",0.027969854500399755,5.934202609760488,0.37777777777777777
"def get_user_extra_data_by_client_id(self, client_id, username):<tab>extra_data = {}<tab>current_client = self.clients.get(client_id, None)<tab>if current_client:<tab><tab>for readable_field in current_client.get_readable_fields():<tab><tab><tab>attribute = list(<tab><tab><tab><tab>filter(<tab><tab><tab><tab><tab>lambda f: f[""Name""] == readable_field,<tab><tab><tab><tab><tab>self.users.get(username).attributes,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extra_data.update({attribute[0][""Name""]: attribute[0][""Value""]})<tab>return extra_data",0,if len ( attribute ) > 0 :,if attribute :,0.017267079824235865,1e-10,0.36
"def augment(self, resources):<tab>super().augment(resources)<tab>for r in resources:<tab><tab>md = r.get(""SAMLMetadataDocument"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>root = sso_metadata(md)<tab><tab>r[""IDPSSODescriptor""] = root[""IDPSSODescriptor""]<tab>return resources",1,if not md :,if not md :,0.75,100.00000000000004,1.0
"def __init__(self, mode=0, decode=None):<tab>self.regex = self.REGEX[mode]<tab>self.decode = decode<tab>if decode:<tab><tab>self.header = _(<tab><tab><tab>""### This log has been decoded with automatic search pattern\n""<tab><tab><tab>""### If some paths are not decoded you can manually decode them with:\n""<tab><tab>)<tab><tab>self.header += ""### 'backintime --quiet ""<tab><tab><IF-STMT><tab><tab><tab>self.header += '--profile ""%s"" ' % decode.config.profileName()<tab><tab>self.header += ""--decode <path>'\n\n""<tab>else:<tab><tab>self.header = """"",0,if int ( decode . config . currentProfile ( ) ) > 1 :,"if hasattr ( decode . config , ""profileName"" ) :",0.13300223078672438,20.640765449620034,0.4861111111111111
"def _get_dynamic_attr(self, attname, obj, default=None):<tab>try:<tab><tab>attr = getattr(self, attname)<tab>except AttributeError:<tab><tab>return default<tab>if callable(attr):<tab><tab># Check co_argcount rather than try/excepting the function and<tab><tab># catching the TypeError, because something inside the function<tab><tab># may raise the TypeError. This technique is more accurate.<tab><tab>try:<tab><tab><tab>code = six.get_function_code(attr)<tab><tab>except AttributeError:<tab><tab><tab>code = six.get_function_code(attr.__call__)<tab><tab><IF-STMT>  # one argument is 'self'<tab><tab><tab>return attr(obj)<tab><tab>else:<tab><tab><tab>return attr()<tab>return attr",0,if code . co_argcount == 2 :,if code == 1 :,0.044701560545953894,12.462989337200145,0.6
"def grep_full_py_identifiers(tokens):<tab>global pykeywords<tab>tokens = list(tokens)<tab>i = 0<tab>while i < len(tokens):<tab><tab>tokentype, token = tokens[i]<tab><tab>i += 1<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>while (<tab><tab><tab>i + 1 < len(tokens)<tab><tab><tab>and tokens[i] == (""op"", ""."")<tab><tab><tab>and tokens[i + 1][0] == ""id""<tab><tab>):<tab><tab><tab>token += ""."" + tokens[i + 1][1]<tab><tab><tab>i += 2<tab><tab>if token == """":<tab><tab><tab>continue<tab><tab>if token in pykeywords:<tab><tab><tab>continue<tab><tab>if token[0] in "".0123456789"":<tab><tab><tab>continue<tab><tab>yield token",0,"if tokentype != ""id"" :","if tokentype != ""identifier"" :",0.39477865547525276,59.4603557501361,1.0
"def _add_disk_config(self, context, images):<tab>for image in images:<tab><tab>metadata = image[""metadata""]<tab><tab><IF-STMT><tab><tab><tab>raw_value = metadata[INTERNAL_DISK_CONFIG]<tab><tab><tab>value = utils.bool_from_str(raw_value)<tab><tab><tab>image[API_DISK_CONFIG] = disk_config_to_api(value)",0,if INTERNAL_DISK_CONFIG in metadata :,ifINTERNAL_DISK_CONFIG in metadata :,0.259813404456229,74.20884818558928,0.2
"def test_edgeql_expr_valid_setop_07(self):<tab>expected_error_msg = ""cannot be applied to operands""<tab># IF ELSE with every scalar as the condition<tab>for val in get_test_values():<tab><tab>query = f""""""SELECT 1 IF {val} ELSE 2;""""""<tab><tab><IF-STMT><tab><tab><tab>await self.assert_query_result(query, [1])<tab><tab>else:<tab><tab><tab># every other combination must produce an error<tab><tab><tab>with self.assertRaisesRegex(<tab><tab><tab><tab>edgedb.QueryError, expected_error_msg, msg=query<tab><tab><tab>):<tab><tab><tab><tab>async with self.con.transaction():<tab><tab><tab><tab><tab>await self.con.execute(query)",0,"if val == ""<bool>True"" :",if val == 1 :,0.14477865547525276,23.350308364304226,0.7
"def get_all_url_infos() -> Dict[str, UrlInfo]:<tab>""""""Returns dict associating URL to UrlInfo.""""""<tab>url_infos = {}<tab>for path in _checksum_paths().values():<tab><tab>dataset_url_infos = load_url_infos(path)<tab><tab>for url, url_info in dataset_url_infos.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab><tab>""URL {} is registered with 2+ distinct size/checksum tuples. ""<tab><tab><tab><tab><tab>""{} vs {}"".format(url, url_info, url_infos[url])<tab><tab><tab><tab>)<tab><tab>url_infos.update(dataset_url_infos)<tab>return url_infos",0,"if url_infos . get ( url , url_info ) != url_info :",if len ( url_infos ) != 2 :,0.024253488432045528,13.266956365187978,0.3333333333333333
"def global_fixes():<tab>""""""Yield multiple (code, function) tuples.""""""<tab>for function in list(globals().values()):<tab><tab><IF-STMT><tab><tab><tab>arguments = _get_parameters(function)<tab><tab><tab>if arguments[:1] != [""source""]:<tab><tab><tab><tab>continue<tab><tab><tab>code = extract_code_from_function(function)<tab><tab><tab>if code:<tab><tab><tab><tab>yield (code, function)",0,if inspect . isfunction ( function ) :,"if isinstance ( function , types . FunctionType ) :",0.041059843312028034,13.134549472120794,0.23863636363636365
"def createSocket(self):<tab>skt = Port.createSocket(self)<tab>if self.listenMultiple:<tab><tab>skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)<tab><tab><IF-STMT><tab><tab><tab>skt.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)<tab>return skt",0,"if hasattr ( socket , ""SO_REUSEPORT"" ) :",if self . listenTCP :,0.01858685153282265,3.1325998243558226,0.3333333333333333
"def _asStringList(self, sep=""""):<tab>out = []<tab>for item in self._toklist:<tab><tab>if out and sep:<tab><tab><tab>out.append(sep)<tab><tab><IF-STMT><tab><tab><tab>out += item._asStringList()<tab><tab>else:<tab><tab><tab>out.append(str(item))<tab>return out",0,"if isinstance ( item , ParseResults ) :","elif isinstance ( item , Token ) :",0.1956586942207979,41.11336169005198,0.42857142857142855
"def parse_c_comments(lexer, tok, ntok):<tab>if tok != ""/"" or ntok != ""*"":<tab><tab>return False<tab>quotes = lexer.quotes<tab>lexer.quotes = """"<tab>while True:<tab><tab>tok = lexer.get_token()<tab><tab>ntok = lexer.get_token()<tab><tab><IF-STMT><tab><tab><tab>lexer.quotes = quotes<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>lexer.push_token(ntok)<tab>return True",0,"if tok == ""*"" and ntok == ""/"" :","if tok == ""\\"" :",0.10239847556289383,26.356013563443188,0.5666666666666667
"def doWorkForFindAll(self, v, target, partialMatch):<tab>sibling = self<tab>while sibling:<tab><tab>c1 = partialMatch and sibling.equalsTreePartial(target)<tab><tab>if c1:<tab><tab><tab>v.append(sibling)<tab><tab>else:<tab><tab><tab>c2 = not partialMatch and sibling.equalsTree(target)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v.append(sibling)<tab><tab>### regardless of match or not, check any children for matches<tab><tab>if sibling.getFirstChild():<tab><tab><tab>sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch)<tab><tab>sibling = sibling.getNextSibling()",1,if c2 :,if c2 :,0.5311706625951745,1e-10,1.0
"def __view_beside(self, onsideof, **kwargs):<tab>bounds = self.info[""bounds""]<tab>min_dist, found = -1, None<tab>for ui in UiObject(self.session, Selector(**kwargs)):<tab><tab>dist = onsideof(bounds, ui.info[""bounds""])<tab><tab><IF-STMT><tab><tab><tab>min_dist, found = dist, ui<tab>return found",0,if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,if dist < min_dist :,0.033766279079555185,11.039212850851191,0.4047619047619047
"def __eq__(self, other):<tab>if isinstance(other, numeric_range):<tab><tab>empty_self = not bool(self)<tab><tab>empty_other = not bool(other)<tab><tab><IF-STMT><tab><tab><tab>return empty_self and empty_other  # True if both empty<tab><tab>else:<tab><tab><tab>return (<tab><tab><tab><tab>self._start == other._start<tab><tab><tab><tab>and self._step == other._step<tab><tab><tab><tab>and self._get_by_index(-1) == other._get_by_index(-1)<tab><tab><tab>)<tab>else:<tab><tab>return False",0,if empty_self or empty_other :,if not empty_self and not empty_other :,0.18044914160509712,35.08439695638686,0.35
"def _buffered_generator(self, size):<tab>buf = []<tab>c_size = 0<tab>push = buf.append<tab>while 1:<tab><tab>try:<tab><tab><tab>while c_size < size:<tab><tab><tab><tab>c = next(self._gen)<tab><tab><tab><tab>push(c)<tab><tab><tab><tab>if c:<tab><tab><tab><tab><tab>c_size += 1<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>yield concat(buf)<tab><tab>del buf[:]<tab><tab>c_size = 0",0,if not c_size :,if c_size >= size :,0.045150550804307965,25.848657697858535,0.5
"def connect(self):<tab>with self._conn_lock:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Error, database not properly initialized "" ""before opening connection""<tab><tab><tab>)<tab><tab>with self.exception_wrapper():<tab><tab><tab>self.__local.conn = self._connect(self.database, **self.connect_kwargs)<tab><tab><tab>self.__local.closed = False<tab><tab><tab>self.initialize_connection(self.__local.conn)",0,if self . deferred :,if self . closed :,0.39477865547525276,42.72870063962342,0.6
"def _merge_substs(self, subst, new_substs):<tab>subst = subst.copy()<tab>for new_subst in new_substs:<tab><tab>for name, var in new_subst.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subst[name] = var<tab><tab><tab>elif subst[name] is not var:<tab><tab><tab><tab>subst[name].PasteVariable(var)<tab>return subst",1,if name not in subst :,if name not in subst :,0.75,100.00000000000004,1.0
"def remove(self, tag):<tab>""""""Removes a tag recursively from all containers.""""""<tab>new_contents = []<tab>self.content_size = 0<tab>for element in self.contents:<tab><tab>if element.name != tag:<tab><tab><tab>new_contents.append(element)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>element.remove(tag)<tab><tab><tab>self.content_size += element.size()<tab>self.contents = new_contents",0,"if isinstance ( element , Container ) :","if isinstance ( element , containers . Container ) :",0.30420588704217844,52.53819788848316,0.6515151515151515
"def _create_object(self, obj_body):<tab>props = obj_body[SYMBOL_PROPERTIES]<tab>for prop_name, prop_value in props.items():<tab><tab>if isinstance(prop_value, dict) and prop_value:<tab><tab><tab># get the first key as the convert function<tab><tab><tab>func_name = list(prop_value.keys())[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>func = getattr(self, func_name)<tab><tab><tab><tab>props[prop_name] = func(prop_value[func_name])<tab>if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping:<tab><tab>return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props)<tab>else:<tab><tab>return props",0,"if func_name . startswith ( ""_"" ) :",if func_name in prop_value :,0.0354018406734773,23.668206578270116,0.5
"def visit_try_stmt(self, o: ""mypy.nodes.TryStmt"") -> str:<tab>a = [o.body]  # type: List[Any]<tab>for i in range(len(o.vars)):<tab><tab>a.append(o.types[i])<tab><tab><IF-STMT><tab><tab><tab>a.append(o.vars[i])<tab><tab>a.append(o.handlers[i])<tab>if o.else_body:<tab><tab>a.append((""Else"", o.else_body.body))<tab>if o.finally_body:<tab><tab>a.append((""Finally"", o.finally_body.body))<tab>return self.dump(a, o)",1,if o . vars [ i ] :,if o . vars [ i ] :,0.75,100.00000000000004,1.0
"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict) and k != ""headers"":<tab><tab><tab>if not everythingIsUnicode(v):<tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, _bytes):<tab><tab><tab>return False<tab>return True",0,"elif isinstance ( i , _bytes ) :","elif not all ( [ isinstance ( i , unicode ) for i in v ] ) :",0.2483653248480059,16.61742929957894,0.16956521739130434
"def msg_ser(inst, sformat, lev=0):<tab>if sformat in [""urlencoded"", ""json""]:<tab><tab>if isinstance(inst, Message):<tab><tab><tab>res = inst.serialize(sformat, lev)<tab><tab>else:<tab><tab><tab>res = inst<tab>elif sformat == ""dict"":<tab><tab>if isinstance(inst, Message):<tab><tab><tab>res = inst.serialize(sformat, lev)<tab><tab><IF-STMT><tab><tab><tab>res = inst<tab><tab>elif isinstance(inst, str):  # Iff ID Token<tab><tab><tab>res = inst<tab><tab>else:<tab><tab><tab>raise MessageException(""Wrong type: %s"" % type(inst))<tab>else:<tab><tab>raise PyoidcError(""Unknown sformat"", inst)<tab>return res",0,"elif isinstance ( inst , dict ) :","elif isinstance ( inst , int ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def start_container_if_stopped(self, container, attach_logs=False, quiet=False):<tab>if not container.is_running:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Starting %s"" % container.name)<tab><tab>if attach_logs:<tab><tab><tab>container.attach_log_stream()<tab><tab>return self.start_container(container)",0,if not quiet :,if quiet :,0.09648852821835877,1e-10,0.41666666666666663
"def layer_op(self, input_image, mask=None):<tab>if not isinstance(input_image, dict):<tab><tab>self._set_full_border(input_image)<tab><tab>input_image = np.pad(input_image, self.full_border, mode=self.mode)<tab><tab>return input_image, mask<tab>for name, image in input_image.items():<tab><tab>self._set_full_border(image)<tab><tab><IF-STMT><tab><tab><tab>tf.logging.warning(<tab><tab><tab><tab>""could not pad, dict name %s not in %s"", name, self.image_name<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>input_image[name] = np.pad(image, self.full_border, mode=self.mode)<tab>return input_image, mask",1,if name not in self . image_name :,if name not in self . image_name :,0.75,100.00000000000004,1.0
"def __Suffix_Noun_Step2b(self, token):<tab>for suffix in self.__suffix_noun_step2b:<tab><tab><IF-STMT><tab><tab><tab>token = token[:-2]<tab><tab><tab>self.suffix_noun_step2b_success = True<tab><tab><tab>break<tab>return token",0,if token . endswith ( suffix ) and len ( token ) >= 5 :,if token . endswith ( suffix ) :,0.28184453892234934,31.984974287337113,0.5555555555555556
"def replace_header_items(ps, replacments):<tab>match = read_while(ps, header_item_or_end_re.match, lambda match: match is None)<tab>while not ps.current_line.startswith(""*/""):<tab><tab>match = header_item_re.match(ps.current_line)<tab><tab><IF-STMT><tab><tab><tab>key = match.groupdict()[""key""]<tab><tab><tab>if key in replacments:<tab><tab><tab><tab>ps.current_line = match.expand(<tab><tab><tab><tab><tab>""\g<key>\g<space>%s\n"" % replacments[key]<tab><tab><tab><tab>)<tab><tab>ps.read_line()",0,if match is not None :,if match :,0.050438393472541504,1e-10,0.39999999999999997
"def __projectBookmark(widget, location):<tab>script = None<tab>while widget is not None:<tab><tab><IF-STMT><tab><tab><tab>script = widget.scriptNode()<tab><tab><tab>if isinstance(script, Gaffer.ScriptNode):<tab><tab><tab><tab>break<tab><tab>widget = widget.parent()<tab>if script is not None:<tab><tab>p = script.context().substitute(location)<tab><tab>if not os.path.exists(p):<tab><tab><tab>try:<tab><tab><tab><tab>os.makedirs(p)<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass<tab><tab>return p<tab>else:<tab><tab>return os.getcwd()",0,"if hasattr ( widget , ""scriptNode"" ) :","if isinstance ( widget , Gaffer . Script ) :",0.08080534754184812,20.556680845025987,0.40476190476190477
"def events_to_str(event_field, all_events):<tab>result = []<tab>for (flag, string) in all_events:<tab><tab>c_flag = flag<tab><tab>if event_field & c_flag:<tab><tab><tab>result.append(string)<tab><tab><tab>event_field = event_field & (~c_flag)<tab><tab><IF-STMT><tab><tab><tab>break<tab>if event_field:<tab><tab>result.append(hex(event_field))<tab>return ""|"".join(result)",1,if not event_field :,if not event_field :,0.75,100.00000000000004,1.0
"def get_s3_bucket_locations(buckets, self_log=False):<tab>""""""return (bucket_name, prefix) for all s3 logging targets""""""<tab>for b in buckets:<tab><tab>if b.get(""Logging""):<tab><tab><tab>if self_log:<tab><tab><tab><tab>if b[""Name""] != b[""Logging""][""TargetBucket""]:<tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (b[""Logging""][""TargetBucket""], b[""Logging""][""TargetPrefix""])<tab><tab><IF-STMT><tab><tab><tab>yield (b[""Name""], """")",0,"if not self_log and b [ ""Name"" ] . startswith ( ""cf-templates-"" ) :","elif b . get ( ""Name"" ) :",0.08096233094988145,10.980266522628492,0.1125
"def extract_file(tgz, tarinfo, dst_path, buffer_size=10 << 20, log_function=None):<tab>""""""Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'.""""""<tab>src = tgz.extractfile(tarinfo)<tab>if src is None:<tab><tab>return<tab>dst = tf.compat.v1.gfile.GFile(dst_path, ""wb"")<tab>while 1:<tab><tab>buf = src.read(buffer_size)<tab><tab>if not buf:<tab><tab><tab>break<tab><tab>dst.write(buf)<tab><tab><IF-STMT><tab><tab><tab>log_function(len(buf))<tab>dst.close()<tab>src.close()",0,if log_function is not None :,if log_function :,0.050438393472541504,1e-10,0.3142857142857143
"def make_index_fields(rec):<tab>fields = {}<tab>for k, v in rec.iteritems():<tab><tab>if k in (""lccn"", ""oclc"", ""isbn""):<tab><tab><tab>fields[k] = v<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>fields[""title""] = [read_short_title(v)]<tab>return fields",0,"if k == ""full_title"" :","if k == ""title"" :",0.39477865547525276,53.849523560640876,1.0
"def disconnect_application(self):<tab>if not self.is_app_running(self.APP_BACKDROP):<tab><tab>self.socket.send(commands.CloseCommand(destination_id=False))<tab><tab>start_time = time.time()<tab><tab>while not self.is_app_running(None):<tab><tab><tab>try:<tab><tab><tab><tab>self.socket.send_and_wait(commands.StatusCommand())<tab><tab><tab>except cast_socket.ConnectionTerminatedException:<tab><tab><tab><tab>break<tab><tab><tab>current_time = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TimeoutException()<tab><tab><tab>time.sleep(self.WAIT_INTERVAL)<tab>else:<tab><tab>logger.debug(""Closing not necessary. Backdrop is running ..."")",1,if current_time - start_time > self . timeout :,if current_time - start_time > self . timeout :,0.75,100.00000000000004,1.0
"def matches(self, cursor_offset, line, **kwargs):<tab>cs = lineparts.current_string(cursor_offset, line)<tab>if cs is None:<tab><tab>return None<tab>matches = set()<tab>username = cs.word.split(os.path.sep, 1)[0]<tab>user_dir = os.path.expanduser(username)<tab>for filename in self.safe_glob(os.path.expanduser(cs.word)):<tab><tab>if os.path.isdir(filename):<tab><tab><tab>filename += os.path.sep<tab><tab><IF-STMT><tab><tab><tab>filename = username + filename[len(user_dir) :]<tab><tab>matches.add(filename)<tab>return matches",0,"if cs . word . startswith ( ""~"" ) :",elif filename . startswith ( user_dir ) :,0.06384317643531578,16.080471747592078,0.13186813186813187
"def eventFilter(self, obj, event):<tab>if event.type() == QEvent.MouseButtonPress:<tab><tab>button = event.button()<tab><tab><IF-STMT><tab><tab><tab>self._app.browser.back()<tab><tab><tab>return True<tab><tab>elif button == Qt.ForwardButton:<tab><tab><tab>self._app.browser.forward()<tab><tab><tab>return True<tab>return False",1,if button == Qt . BackButton :,if button == Qt . BackButton :,0.75,100.00000000000004,1.0
"def reset_parameters(self):<tab>for m in self.modules():<tab><tab>if isinstance(m, nn.Embedding):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>nn.init.constant_(m.weight, 0.1)<tab><tab><tab>nn.init.constant_(m.bias, 0)<tab><tab>else:<tab><tab><tab>for p in m.parameters():<tab><tab><tab><tab>nn.init.normal_(p, 0, 0.1)",0,"elif isinstance ( m , nn . LayerNorm ) :","if isinstance ( m , nn . BatchNorm ) :",0.29071536848410967,58.14307369682194,0.5
"def get_scalding_core(self):<tab>lib_dir = os.path.join(self.scalding_home, ""lib"")<tab>for j in os.listdir(lib_dir):<tab><tab><IF-STMT><tab><tab><tab>p = os.path.join(lib_dir, j)<tab><tab><tab>logger.debug(""Found scalding-core: %s"", p)<tab><tab><tab>return p<tab>raise luigi.contrib.hadoop.HadoopJobError(""Could not find scalding-core."")",0,"if j . startswith ( ""scalding-core-"" ) :","if j . endswith ( "".scalding-core"" ) :",0.34166808520089226,26.65837681702885,0.6
"def save(self):<tab>""""""Saves a new set of golden output frames to disk.""""""<tab>for pixels, (relative_to_assets, filename) in zip(<tab><tab>self.iter_render(), self._iter_paths()<tab>):<tab><tab>full_directory_path = os.path.join(self._ASSETS_DIR, relative_to_assets)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(full_directory_path)<tab><tab>path = os.path.join(full_directory_path, filename)<tab><tab>_save_pixels(pixels, path)",1,if not os . path . exists ( full_directory_path ) :,if not os . path . exists ( full_directory_path ) :,0.75,100.00000000000004,1.0
"def _fix_var_naming(operators, names, mod=""input""):<tab>new_names = []<tab>map = {}<tab>for op in operators:<tab><tab><IF-STMT><tab><tab><tab>iter = op.inputs<tab><tab>else:<tab><tab><tab>iter = op.outputs<tab><tab>for i in iter:<tab><tab><tab>for name in names:<tab><tab><tab><tab>if i.raw_name == name and name not in map:<tab><tab><tab><tab><tab>map[i.raw_name] = i.full_name<tab><tab>if len(map) == len(names):<tab><tab><tab>break<tab>for name in names:<tab><tab>new_names.append(map[name])<tab>return new_names",0,"if mod == ""input"" :","if hasattr ( op , ""inputs"" ) :",0.026407399022921448,5.934202609760488,0.38181818181818183
"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab>if item[0]:<tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab><IF-STMT><tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab>elif item[2]:<tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab>elif item[3]:<tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",1,elif item [ 1 ] :,elif item [ 1 ] :,0.75,100.00000000000004,1.0
"def init_errorhandler():<tab># http error handling<tab>for ex in default_exceptions:<tab><tab>if ex < 500:<tab><tab><tab>app.register_error_handler(ex, error_http)<tab><tab><IF-STMT><tab><tab><tab>app.register_error_handler(ex, internal_error)<tab>if services.ldap:<tab><tab># Only way of catching the LDAPException upon logging in with LDAP server down<tab><tab>@app.errorhandler(services.ldap.LDAPException)<tab><tab>def handle_exception(e):<tab><tab><tab>log.debug(""LDAP server not accessible while trying to login to opds feed"")<tab><tab><tab>return error_http(FailedDependency())",0,elif ex == 500 :,"elif ex . endswith ( ""internal error"" ) :",0.04546639155283771,8.29519350710986,0.6
"def decode(self, ids):<tab>ids = pad_decr(ids)<tab>tokens = []<tab>for int_id in ids:<tab><tab><IF-STMT><tab><tab><tab>tokens.append(self._vocab_list[int_id])<tab><tab>else:<tab><tab><tab>tokens.append(self._oov_token)<tab>return self._decode_token_separator.join(tokens)",0,if int_id < len ( self . _vocab_list ) :,if int_id in self . _vocab_list :,0.07093870120674986,50.57032536203352,0.6
"def remove_contest(contest_id):<tab>with SessionGen() as session:<tab><tab>contest = session.query(Contest).filter(Contest.id == contest_id).first()<tab><tab>if not contest:<tab><tab><tab>print(""No contest with id %s found."" % contest_id)<tab><tab><tab>return False<tab><tab>contest_name = contest.name<tab><tab><IF-STMT><tab><tab><tab>print(""Not removing contest `%s'."" % contest_name)<tab><tab><tab>return False<tab><tab>session.delete(contest)<tab><tab>session.commit()<tab><tab>print(""Contest `%s' removed."" % contest_name)<tab>return True",0,if not ask ( contest ) :,if contest_name != contest_name :,0.02225082504991546,5.522397783539471,0.3333333333333333
def get_hi_lineno(self):<tab>lineno = Node.get_hi_lineno(self)<tab>if self.expr1 is None:<tab><tab>pass<tab>else:<tab><tab>lineno = self.expr1.get_hi_lineno()<tab><tab>if self.expr2 is None:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>lineno = self.expr2.get_hi_lineno()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>lineno = self.expr3.get_hi_lineno()<tab>return lineno,1,if self . expr3 is None :,if self . expr3 is None :,0.75,100.00000000000004,1.0
"def _send_internal(self, bytes_):<tab># buffering<tab>if self.pendings:<tab><tab>self.pendings += bytes_<tab><tab>bytes_ = self.pendings<tab>try:<tab><tab># reconnect if possible<tab><tab>self._reconnect()<tab><tab># send message<tab><tab>self.socket.sendall(bytes_)<tab><tab># send finished<tab><tab>self.pendings = None<tab>except Exception:  # pylint: disable=broad-except<tab><tab># close socket<tab><tab>self._close()<tab><tab># clear buffer if it exceeds max bufer size<tab><tab><IF-STMT><tab><tab><tab># TODO: add callback handler here<tab><tab><tab>self.pendings = None<tab><tab>else:<tab><tab><tab>self.pendings = bytes_",0,if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,if bytes_ > self . _max_bfer :,0.05415478625080855,8.388648362860879,0.3171428571428571
"def _unpack(self, fmt, byt):<tab>d = unpack(self._header[""byteorder""] + fmt, byt)[0]<tab>if fmt[-1] in self.MISSING_VALUES:<tab><tab>nmin, nmax = self.MISSING_VALUES[fmt[-1]]<tab><tab>if d < nmin or d > nmax:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return StataMissingValue(nmax, d)<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab>return d",0,if self . _missing_values :,"if fmt [ - 1 ] == ""stata"" :",0.0252788731101473,4.02724819242185,0.38461538461538464
"def tuple_iter(self):<tab>for x in range(<tab><tab>self.center.x - self.max_radius, self.center.x + self.max_radius + 1<tab>):<tab><tab>for y in range(<tab><tab><tab>self.center.y - self.max_radius, self.center.y + self.max_radius + 1<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (x, y)",0,"if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :","if ( x , y ) < self . radius :",0.11657388758007622,10.478444497879707,0.23790322580645162
"def _parse_gene(element):<tab>for genename_element in element:<tab><tab><IF-STMT><tab><tab><tab>ann_key = ""gene_%s_%s"" % (<tab><tab><tab><tab>genename_element.tag.replace(NS, """"),<tab><tab><tab><tab>genename_element.attrib[""type""],<tab><tab><tab>)<tab><tab><tab>if genename_element.attrib[""type""] == ""primary"":<tab><tab><tab><tab>self.ParsedSeqRecord.annotations[ann_key] = genename_element.text<tab><tab><tab>else:<tab><tab><tab><tab>append_to_annotations(ann_key, genename_element.text)",0,"if ""type"" in genename_element . attrib :","if genename_element . tag . startswith ( ""ann"" ) :",0.03532742722429465,21.142141714303076,0.3333333333333333
"def invalidateDependentSlices(self, iFirstCurve):<tab># only user defined curve can have slice dependency relationships<tab>if self.isSystemCurveIndex(iFirstCurve):<tab><tab>return<tab>nCurves = self.getNCurves()<tab>for i in range(iFirstCurve, nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab>if isinstance(c.getSymbol().getSymbolType(), SymbolType.PieSliceSymbolType):<tab><tab><tab>c.invalidate()<tab><tab><IF-STMT><tab><tab><tab># if first curve isn't a slice,<tab><tab><tab>break<tab><tab><tab># there are no dependent slices",0,elif i == iFirstCurve :,elif not c . isDependent ( ) :,0.024231488401191333,6.567274736060395,0.2698412698412698
"def gen_app_versions(self):<tab>for app_config in apps.get_app_configs():<tab><tab>name = app_config.verbose_name<tab><tab>app = app_config.module<tab><tab>version = self.get_app_version(app)<tab><tab><IF-STMT><tab><tab><tab>yield app.__name__, name, version",0,if version :,if version is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def verify_relative_valid_path(root, path):<tab>if len(path) < 1:<tab><tab>raise PackagerError(""Empty chown path"")<tab>checkpath = root<tab>parts = path.split(os.sep)<tab>for part in parts:<tab><tab>if part in (""."", ""..""):<tab><tab><tab>raise PackagerError("". and .. is not allowed in chown path"")<tab><tab>checkpath = os.path.join(checkpath, part)<tab><tab>relpath = checkpath[len(root) + 1 :]<tab><tab><IF-STMT><tab><tab><tab>raise PackagerError(f""chown path {relpath} does not exist"")<tab><tab>if os.path.islink(checkpath):<tab><tab><tab>raise PackagerError(f""chown path {relpath} is a soft link"")",1,if not os . path . exists ( checkpath ) :,if not os . path . exists ( checkpath ) :,0.75,100.00000000000004,1.0
"def create_or_update_tag_at_scope(cmd, resource_id=None, tags=None, tag_name=None):<tab>rcf = _resource_client_factory(cmd.cli_ctx)<tab>if resource_id is not None:<tab><tab><IF-STMT><tab><tab><tab>raise IncorrectUsageError(""Tags could not be empty."")<tab><tab>Tags = cmd.get_models(""Tags"")<tab><tab>tag_obj = Tags(tags=tags)<tab><tab>return rcf.tags.create_or_update_at_scope(scope=resource_id, properties=tag_obj)<tab>return rcf.tags.create_or_update(tag_name=tag_name)",0,if not tags :,if tags is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def generate_auto_complete(self, base, iterable_var):<tab>sugg = []<tab>for entry in iterable_var:<tab><tab>compare_entry = entry<tab><tab>compare_base = base<tab><tab>if self.settings.get(IGNORE_CASE_SETTING):<tab><tab><tab>compare_entry = compare_entry.lower()<tab><tab><tab>compare_base = compare_base.lower()<tab><tab><IF-STMT><tab><tab><tab>if entry not in sugg:<tab><tab><tab><tab>sugg.append(entry)<tab>return sugg",0,"if self . compare_entries ( compare_entry , compare_base ) :",if compare_entry == compare_base :,0.015145994590617124,15.491846006709249,0.6470588235294118
"def createFields(self):<tab>yield String(self, ""dict_start"", 2)<tab>while not self.eof:<tab><tab>addr = self.absolute_address + self.current_size<tab><tab><IF-STMT><tab><tab><tab>for field in parsePDFType(self):<tab><tab><tab><tab>yield field<tab><tab>else:<tab><tab><tab>break<tab>yield String(self, ""dict_end"", 2)",0,"if self . stream . readBytes ( addr , 2 ) != "">>"" :",if addr < self . pdf_address :,0.018407146035796716,4.410929085933151,0.2631578947368421
"def Visit_and_test(self, node):  # pylint: disable=invalid-name<tab># and_test ::= not_test ('and' not_test)*<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)",1,"if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :",1.0,100.00000000000004,1.0
"def getfiledata(directories):<tab>columns = None<tab>data = []<tab>counter = 1<tab>for directory in directories:<tab><tab>for f in os.listdir(directory):<tab><tab><tab>if not os.path.isfile(os.path.join(directory, f)):<tab><tab><tab><tab>continue<tab><tab><tab>counter += 1<tab><tab><tab>st = os.stat(os.path.join(directory, f))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>columns = [""rowid"", ""name"", ""directory""] + [<tab><tab><tab><tab><tab>x for x in dir(st) if x.startswith(""st_"")<tab><tab><tab><tab>]<tab><tab><tab>data.append([counter, f, directory] + [getattr(st, x) for x in columns[3:]])<tab>return columns, data",1,if columns is None :,if columns is None :,0.75,100.00000000000004,1.0
"def copy_attributes(info_add, obj, name_fmt, attributes, formatter=None):<tab>for attr in attributes:<tab><tab>value = getattr(obj, attr, None)<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab>name = name_fmt % attr<tab><tab><IF-STMT><tab><tab><tab>value = formatter(attr, value)<tab><tab>info_add(name, value)",1,if formatter is not None :,if formatter is not None :,0.75,100.00000000000004,1.0
"def main(args):<tab>ap = argparse.ArgumentParser()<tab>ap.add_argument(""job_ids"", nargs=""+"", type=int, help=""ID of a running job"")<tab>ns = ap.parse_args(args)<tab>_stash = globals()[""_stash""]<tab>"""""":type : StaSh""""""<tab>for job_id in ns.job_ids:<tab><tab><IF-STMT><tab><tab><tab>print(""killing job {} ..."".format(job_id))<tab><tab><tab>worker = _stash.runtime.worker_registry.get_worker(job_id)<tab><tab><tab>worker.kill()<tab><tab><tab>time.sleep(1)<tab><tab>else:<tab><tab><tab>print(""error: no such job with id: {}"".format(job_id))<tab><tab><tab>break",0,if job_id in _stash . runtime . worker_registry :,if ns . is_running ( job_id ) :,0.01786335094255824,13.188274750399428,0.38461538461538464
"def _check_choice(self):<tab>if self.type == ""choice"":<tab><tab>if self.choices is None:<tab><tab><tab>raise OptionError(""must supply a list of choices for type 'choice'"", self)<tab><tab><IF-STMT><tab><tab><tab>raise OptionError(<tab><tab><tab><tab>""choices must be a list of strings ('%s' supplied)""<tab><tab><tab><tab>% str(type(self.choices)).split(""'"")[1],<tab><tab><tab><tab>self,<tab><tab><tab>)<tab>elif self.choices is not None:<tab><tab>raise OptionError(""must not supply choices for type %r"" % self.type, self)",0,"elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :","elif not isinstance ( self . choices , str ) :",0.16991075906179592,14.921115647284694,0.15151515151515152
"def add_file(pipe, srcpath, tgtpath):<tab>with open(srcpath, ""rb"") as handle:<tab><tab><IF-STMT><tab><tab><tab>write(pipe, enc(""M 100755 inline %s\n"" % tgtpath))<tab><tab>else:<tab><tab><tab>write(pipe, enc(""M 100644 inline %s\n"" % tgtpath))<tab><tab>data = handle.read()<tab><tab>write(pipe, enc(""data %d\n"" % len(data)))<tab><tab>write(pipe, enc(data))<tab><tab>write(pipe, enc(""\n""))",0,"if os . access ( srcpath , os . X_OK ) :","if sys . platform == ""win32"" :",0.0617661330751997,3.701773936489291,0.26785714285714285
"def cdf(self, x):<tab>if x == numpy.inf:<tab><tab>return 1.0<tab>else:  # Inefficient sum.<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Invalid value."")<tab><tab>c = 0.0<tab><tab>for i in xrange(x + 1):<tab><tab><tab>c += self.probability(i)<tab><tab>return c",0,if x != int ( x ) :,if numpy . isnan ( x ) or numpy . isnan ( x ) :,0.4369064377413584,18.20705281109213,0.3253968253968254
"def convert_to_strings(self, out, seq_len):<tab>results = []<tab>for b, batch in enumerate(out):<tab><tab>utterances = []<tab><tab>for p, utt in enumerate(batch):<tab><tab><tab>size = seq_len[b][p]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>transcript = """".join(<tab><tab><tab><tab><tab>map(lambda x: self.int_to_char[x.item()], utt[0:size])<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>transcript = """"<tab><tab><tab>utterances.append(transcript)<tab><tab>results.append(utterances)<tab>return results",1,if size > 0 :,if size > 0 :,0.75,100.00000000000004,1.0
"def get_date_range(self):<tab>if not hasattr(self, ""start"") or not hasattr(self, ""end""):<tab><tab>args = (self.today.year, self.today.month)<tab><tab>form = self.get_form()<tab><tab><IF-STMT><tab><tab><tab>args = (int(form.cleaned_data[""year""]), int(form.cleaned_data[""month""]))<tab><tab>self.start = self.get_start(*args)<tab><tab>self.end = self.get_end(*args)<tab>return self.start, self.end",0,if form . is_valid ( ) :,if form . cleaned_data :,0.09453229110448028,20.873176328735713,1.0
"def save_stats(self):<tab>LOGGER.info(""Saving task-level statistics."")<tab>has_headers = os.path.isfile(paths.TABLE_COUNT_PATH)<tab>with open(paths.TABLE_COUNT_PATH, ""a"") as csvfile:<tab><tab>headers = [""start_time"", ""database_name"", ""number_tables""]<tab><tab>writer = csv.DictWriter(<tab><tab><tab>csvfile, delimiter="","", lineterminator=""\n"", fieldnames=headers<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>writer.writeheader()<tab><tab>writer.writerow(<tab><tab><tab>{<tab><tab><tab><tab>""start_time"": self.start_time,<tab><tab><tab><tab>""database_name"": self.database_name,<tab><tab><tab><tab>""number_tables"": self.count,<tab><tab><tab>}<tab><tab>)",0,if not has_headers :,if has_headers :,0.09648852821835877,1e-10,0.6
"def _CheckCanaryCommand(self):<tab><IF-STMT>  # fast path<tab><tab>return<tab>with self._lock:<tab><tab>if OpenStackVirtualMachine.command_works:<tab><tab><tab>return<tab><tab>logging.info(""Testing OpenStack CLI command is installed and working"")<tab><tab>cmd = os_utils.OpenStackCLICommand(self, ""image"", ""list"")<tab><tab>stdout, stderr, _ = cmd.Issue()<tab><tab>if stderr:<tab><tab><tab>raise errors.Config.InvalidValue(<tab><tab><tab><tab>""OpenStack CLI test command failed. Please make sure the OpenStack ""<tab><tab><tab><tab>""CLI client is installed and properly configured""<tab><tab><tab>)<tab><tab>OpenStackVirtualMachine.command_works = True",1,if OpenStackVirtualMachine . command_works :,if OpenStackVirtualMachine . command_works :,0.75,100.00000000000004,1.0
"def test_windows_hidden(self):<tab>if not sys.platform == ""win32"":<tab><tab>self.skipTest(""sys.platform is not windows"")<tab><tab>return<tab># FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation.<tab>hidden_mask = 2<tab>with tempfile.NamedTemporaryFile() as f:<tab><tab># Hide the file using<tab><tab>success = ctypes.windll.kernel32.SetFileAttributesW(f.name, hidden_mask)<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""unable to set file attributes"")<tab><tab>self.assertTrue(hidden.is_hidden(f.name))",1,if not success :,if not success :,0.75,100.00000000000004,1.0
"def recv_some(p, t=0.1, e=1, tr=5, stderr=0):<tab>if tr < 1:<tab><tab>tr = 1<tab>x = time.time() + t<tab>y = []<tab>r = """"<tab>if stderr:<tab><tab>pr = p.recv_err<tab>else:<tab><tab>pr = p.recv<tab>while time.time() < x or r:<tab><tab>r = pr()<tab><tab>if r is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>y.append(r)<tab><tab>else:<tab><tab><tab>time.sleep(max((x - time.time()) / tr, 0))<tab>return b"""".join(y)",0,elif r :,if e :,0.05340548416168749,1e-10,0.2
"def _is_xml(accepts):<tab>if accepts.startswith(b""application/""):<tab><tab>has_xml = accepts.find(b""xml"")<tab><tab><IF-STMT><tab><tab><tab>semicolon = accepts.find(b"";"")<tab><tab><tab>if semicolon < 0 or has_xml < semicolon:<tab><tab><tab><tab>return True<tab>return False",1,if has_xml > 0 :,if has_xml > 0 :,0.75,100.00000000000004,1.0
"def times(self, value: int):<tab>if value is None:<tab><tab>self._times = None<tab>else:<tab><tab>try:<tab><tab><tab>candidate = int(value)<tab><tab>except ValueError:<tab><tab><tab># pylint: disable:raise-missing-from<tab><tab><tab>raise BarException(f""cannot set repeat times to: {value!r}"")<tab><tab>if candidate < 0:<tab><tab><tab>raise BarException(<tab><tab><tab><tab>f""cannot set repeat times to a value less than zero: {value}""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise BarException(""cannot set repeat times on a start Repeat"")<tab><tab>self._times = candidate",0,"if self . direction == ""start"" :",if candidate > self . _interval :,0.04282569298264552,10.229197414177778,0.4
"def __call__(self, *args, **kwargs):<tab>if not NET_INITTED:<tab><tab>return self.raw(*args, **kwargs)<tab>for stack in traceback.walk_stack(None):<tab><tab>if ""self"" in stack[0].f_locals:<tab><tab><tab>layer = stack[0].f_locals[""self""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.pytorch_layer_name = layer_names[layer]<tab><tab><tab><tab>print(layer_names[layer])<tab><tab><tab><tab>break<tab>out = self.obj(self.raw, *args, **kwargs)<tab># if isinstance(out,Variable):<tab>#<tab> out=[out]<tab>return out",1,if layer in layer_names :,if layer in layer_names :,0.75,100.00000000000004,1.0
"def do_begin(self, byte):<tab>if byte.isspace():<tab><tab>return<tab>if byte != ""<"":<tab><tab><IF-STMT><tab><tab><tab>self._leadingBodyData = byte<tab><tab><tab>return ""bodydata""<tab><tab>self._parseError(""First char of document [{!r}] wasn't <"".format(byte))<tab>return ""tagstart""",0,if self . beExtremelyLenient :,if self . _leadingBodyData is None :,0.2005939911646859,22.089591134157878,0.4761904761904762
"def pretty(self, n, comment=True):<tab>if isinstance(n, (str, bytes, list, tuple, dict)):<tab><tab>r = repr(n)<tab><tab><IF-STMT>  # then it can be inside a comment!<tab><tab><tab>r = r.replace(""*/"", r""\x2a/"")<tab><tab>return r<tab>if not isinstance(n, six.integer_types):<tab><tab>return n<tab>if isinstance(n, constants.Constant):<tab><tab>if comment:<tab><tab><tab>return ""%s /* %s */"" % (n, self.pretty(int(n)))<tab><tab>else:<tab><tab><tab>return ""%s (%s)"" % (n, self.pretty(int(n)))<tab>elif abs(n) < 10:<tab><tab>return str(n)<tab>else:<tab><tab>return hex(n)",0,if not comment :,if comment :,0.09648852821835877,1e-10,0.41666666666666663
"def test_training_script_with_max_history_set(tmpdir):<tab>train_dialogue_model(<tab><tab>DEFAULT_DOMAIN_PATH,<tab><tab>DEFAULT_STORIES_FILE,<tab><tab>tmpdir.strpath,<tab><tab>interpreter=RegexInterpreter(),<tab><tab>policy_config=""data/test_config/max_hist_config.yml"",<tab><tab>kwargs={},<tab>)<tab>agent = Agent.load(tmpdir.strpath)<tab>for policy in agent.policy_ensemble.policies:<tab><tab>if hasattr(policy.featurizer, ""max_history""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert policy.featurizer.max_history == 2<tab><tab><tab>else:<tab><tab><tab><tab>assert policy.featurizer.max_history == 5",0,if type ( policy ) == FormPolicy :,if policy . featurizer . max_history == 1 :,0.019030985543513193,8.516593018819643,0.2857142857142857
"def cli_uninstall_distro():<tab>distro_list = install_distro_list()<tab>if distro_list is not None:<tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab>log(str(index) + ""  --->>  "" + _distro_dir)<tab><tab>user_input = read_input_uninstall()<tab><tab><IF-STMT><tab><tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab><tab>if index == user_input:<tab><tab><tab><tab><tab>config.uninstall_distro_dir_name = _distro_dir<tab><tab><tab><tab><tab>unin_distro()<tab>else:<tab><tab>log(""No distro installed on "" + config.usb_disk)",0,if user_input is not False :,if user_input is not None :,0.5212518808542342,70.71067811865478,0.6666666666666666
"def set_random_avatar(user):<tab>galleries = get_available_galleries(include_default=True)<tab>if not galleries:<tab><tab>raise RuntimeError(""no avatar galleries are set"")<tab>avatars_list = []<tab>for gallery in galleries:<tab><tab><IF-STMT><tab><tab><tab>avatars_list = gallery[""images""]<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>avatars_list += gallery[""images""]<tab>random_avatar = random.choice(avatars_list)<tab>store.store_new_avatar(user, Image.open(random_avatar.image))",0,"if gallery [ ""name"" ] == DEFAULT_GALLERY :","if len ( gallery [ ""images"" ] ) == 0 :",0.09545805487236919,16.544619993389986,0.375
"def make_query(self, key, filters):<tab>meta = self.get_meta(key)<tab>q = {meta.facet_key: self.normalize_key(meta.path)}<tab>if filters:<tab><tab>if filters.get(""has_fulltext"") == ""true"":<tab><tab><tab>q[""has_fulltext""] = ""true""<tab><tab><IF-STMT><tab><tab><tab>q[""publish_year""] = filters[""publish_year""]<tab>return q",0,"if filters . get ( ""publish_year"" ) :","if ""publish_year"" in filters :",0.020977836961063236,35.967895947086795,0.4
"def test_named_parameters_and_constraints(self):<tab>likelihood = gpytorch.likelihoods.GaussianLikelihood()<tab>model = ExactGPModel(None, None, likelihood)<tab>for name, _param, constraint in model.named_parameters_and_constraints():<tab><tab>if name == ""likelihood.noise_covar.raw_noise"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan)<tab><tab><IF-STMT><tab><tab><tab>self.assertIsNone(constraint)<tab><tab>elif name == ""covar_module.raw_outputscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)<tab><tab>elif name == ""covar_module.base_kernel.raw_lengthscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)",0,"elif name == ""mean_module.constant"" :","elif name == ""likelihood.noise_covar.raw_bias"" :",0.6428720214849399,28.039501199940027,1.0
"def _test_pooling(input_shape, **kwargs):<tab>_test_pooling_iteration(input_shape, **kwargs)<tab>if is_gpu_available():<tab><tab><IF-STMT><tab><tab><tab>input_shape = [input_shape[ii] for ii in (0, 3, 1, 2)]<tab><tab><tab>kwargs[""data_format""] = ""NCHW""<tab><tab><tab>_test_pooling_iteration(input_shape, **kwargs)",0,if len ( input_shape ) == 4 :,"if isinstance ( input_shape , list ) :",0.03779162928217515,27.3385351346167,0.3333333333333333
"def init(self):<tab>r = self.get_redis()<tab>if r:<tab><tab>key = ""pocsuite_target""<tab><tab>info_msg = ""[PLUGIN] try fetch targets from redis...""<tab><tab>logger.info(info_msg)<tab><tab>targets = r.get(key)<tab><tab>count = 0<tab><tab><IF-STMT><tab><tab><tab>for target in targets:<tab><tab><tab><tab>if self.add_target(target):<tab><tab><tab><tab><tab>count += 1<tab><tab>info_msg = ""[PLUGIN] get {0} target(s) from redis"".format(count)<tab><tab>logger.info(info_msg)",1,if targets :,if targets :,0.5311706625951745,1e-10,1.0
"def reload_json_api_settings(*args, **kwargs):<tab>django_setting = kwargs[""setting""]<tab>setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """")<tab>value = kwargs[""value""]<tab>if setting in DEFAULTS.keys():<tab><tab>if value is not None:<tab><tab><tab>setattr(json_api_settings, setting, value)<tab><tab><IF-STMT><tab><tab><tab>delattr(json_api_settings, setting)",1,"elif hasattr ( json_api_settings , setting ) :","elif hasattr ( json_api_settings , setting ) :",0.75,100.00000000000004,1.0
"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab>if attrname.startswith(""__""):<tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab>if attrvalue == 0:<tab><tab><tab>continue<tab><tab>if attrname == ""salt_version"":<tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass",1,"elif hasattr ( self . metadata , attrname ) :","elif hasattr ( self . metadata , attrname ) :",0.75,100.00000000000004,1.0
"def test_02_looking_at_listdir_path_(name):<tab>for dline in listdir.json():<tab><tab><IF-STMT><tab><tab><tab>assert dline[""type""] in (""DIRECTORY"", ""FILE""), listdir.text<tab><tab><tab>assert dline[""uid""] == 0, listdir.text<tab><tab><tab>assert dline[""gid""] == 0, listdir.text<tab><tab><tab>assert dline[""name""] == name, listdir.text<tab><tab><tab>break<tab>else:<tab><tab>raise AssertionError(f""/{path}/{name} not found"")",0,"if dline [ ""path"" ] == f""{path}/{name}"" :","if dline [ ""name"" ] == name :",0.14166808520089225,21.892591076610394,0.7272727272727273
"def DeletePlugin():<tab>oid = request.form.get(""oid"", """")<tab>if oid:<tab><tab>result = Mongo.coll[""Plugin""].find_one_and_delete(<tab><tab><tab>{""_id"": ObjectId(oid)}, remove=True<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>result[""filename""] = result[""filename""] + "".py""<tab><tab>if os.path.exists(file_path + result[""filename""]):<tab><tab><tab>os.remove(file_path + result[""filename""])<tab><tab><tab>return ""success""<tab>return ""fail""",0,"if not result [ ""filename"" ] . find ( ""."" ) > - 1 :",if result :,0.005751264022174607,1e-10,0.3115942028985507
"def iterparent(self, node):<tab>""""""Iterator wrapper to get allowed parent and child all at once.""""""<tab># We do not allow the marker inside a header as that<tab># would causes an enless loop of placing a new TOC<tab># inside previously generated TOC.<tab>for child in node:<tab><tab><IF-STMT><tab><tab><tab>yield node, child<tab><tab><tab>yield from self.iterparent(child)",0,"if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :","if isinstance ( child , TOC ) :",0.008635008168185063,0.9292405863554505,0.162534435261708
"def _get_matched_layout(command):<tab># don't use command.split_script here because a layout mismatch will likely<tab># result in a non-splitable script as per shlex<tab>cmd = command.script.split("" "")<tab>for source_layout in source_layouts:<tab><tab>is_all_match = True<tab><tab>for cmd_part in cmd:<tab><tab><tab>if not all([ch in source_layout or ch in ""-_"" for ch in cmd_part]):<tab><tab><tab><tab>is_all_match = False<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return source_layout",1,if is_all_match :,if is_all_match :,0.5311706625951745,1e-10,1.0
"def _update_tileable_and_chunk_shape(self, tileable_graph, chunk_result, failed_ops):<tab>for n in tileable_graph:<tab><tab>if n.op in failed_ops:<tab><tab><tab>continue<tab><tab>tiled_n = get_tiled(n)<tab><tab>if has_unknown_shape(tiled_n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># some of the chunks has been fused<tab><tab><tab><tab>continue<tab><tab><tab>new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result)<tab><tab><tab>for node in (n, tiled_n):<tab><tab><tab><tab>node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits))<tab><tab><tab>tiled_n._nsplits = new_nsplits",0,if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,if chunk_result is not None :,0.06919946667078399,4.8137325696777085,0.15454545454545454
"def _get_items(self, name, target=1):<tab>all_items = self.get_items(name)<tab>items = [o for o in all_items if not o.disabled]<tab>if len(items) < target:<tab><tab>if len(all_items) < target:<tab><tab><tab>raise ItemNotFoundError(""insufficient items with name %r"" % name)<tab><tab>else:<tab><tab><tab>raise AttributeError(""insufficient non-disabled items with name %s"" % name)<tab>on = []<tab>off = []<tab>for o in items:<tab><tab><IF-STMT><tab><tab><tab>on.append(o)<tab><tab>else:<tab><tab><tab>off.append(o)<tab>return on, off",0,if o . selected :,if o . disabled :,0.39477865547525276,42.72870063962342,0.6
def parse_flow_sequence_entry_mapping_value(self):<tab>if self.check_token(ValueToken):<tab><tab>token = self.get_token()<tab><tab><IF-STMT><tab><tab><tab>self.states.append(self.parse_flow_sequence_entry_mapping_end)<tab><tab><tab>return self.parse_flow_node()<tab><tab>else:<tab><tab><tab>self.state = self.parse_flow_sequence_entry_mapping_end<tab><tab><tab>return self.process_empty_scalar(token.end_mark)<tab>else:<tab><tab>self.state = self.parse_flow_sequence_entry_mapping_end<tab><tab>token = self.peek_token()<tab><tab>return self.process_empty_scalar(token.start_mark),0,"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :",if self . check_token ( FlowSequenceEntryMappingEndToken ) :,0.14852865108020535,44.360636895626136,0.2653061224489796
"def serialize_config(self, session, key, tid, language):<tab>cache_key = gen_cache_key(key, tid, language)<tab>cache_obj = None<tab>if cache_key not in self.cache:<tab><tab><IF-STMT><tab><tab><tab>cache_obj = db_admin_serialize_node(session, tid, language)<tab><tab>elif key == ""notification"":<tab><tab><tab>cache_obj = db_get_notification(session, tid, language)<tab><tab>self.cache[cache_key] = cache_obj<tab>return self.cache[cache_key]",1,"if key == ""node"" :","if key == ""node"" :",0.75,100.00000000000004,1.0
"def get_lldp_neighbors(self):<tab>commands = [""show lldp neighbors""]<tab>output = self.device.run_commands(commands)[0][""lldpNeighbors""]<tab>lldp = {}<tab>for n in output:<tab><tab><IF-STMT><tab><tab><tab>lldp[n[""port""]] = []<tab><tab>lldp[n[""port""]].append(<tab><tab><tab>{""hostname"": n[""neighborDevice""], ""port"": n[""neighborPort""]}<tab><tab>)<tab>return lldp",0,"if n [ ""port"" ] not in lldp . keys ( ) :","if ""port"" not in lldp :",0.10549687919075776,15.486472386328535,0.26785714285714285
"def handle(self):<tab>from poetry.utils.env import EnvManager<tab>manager = EnvManager(self.poetry)<tab>current_env = manager.get()<tab>for venv in manager.list():<tab><tab>name = venv.path.name<tab><tab>if self.option(""full-path""):<tab><tab><tab>name = str(venv.path)<tab><tab><IF-STMT><tab><tab><tab>self.line(""<info>{} (Activated)</info>"".format(name))<tab><tab><tab>continue<tab><tab>self.line(name)",0,if venv == current_env :,if name in current_env :,0.06497877230811641,37.68499164492418,0.36
"def resolve_env_secrets(config, environ):<tab>""""""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ""""""<tab>if isinstance(config, dict):<tab><tab>if list(config.keys()) == [""$env""]:<tab><tab><tab>return environ.get(list(config.values())[0])<tab><tab><IF-STMT><tab><tab><tab>return open(list(config.values())[0]).read()<tab><tab>else:<tab><tab><tab>return {<tab><tab><tab><tab>key: resolve_env_secrets(value, environ)<tab><tab><tab><tab>for key, value in config.items()<tab><tab><tab>}<tab>elif isinstance(config, list):<tab><tab>return [resolve_env_secrets(value, environ) for value in config]<tab>else:<tab><tab>return config",0,"elif list ( config . keys ( ) ) == [ ""$file"" ] :","elif list ( config . keys ( ) ) == [ ""$env"" ] :",0.6545533557851106,83.94327083733333,1.0
"def _is_valid_16bit_as_path(cls, buf):<tab>two_byte_as_size = struct.calcsize(""!H"")<tab>while buf:<tab><tab>(type_, num_as) = struct.unpack_from(<tab><tab><tab>cls._SEG_HDR_PACK_STR, six.binary_type(buf)<tab><tab>)<tab><tab>if type_ is not cls._AS_SET and type_ is not cls._AS_SEQUENCE:<tab><tab><tab>return False<tab><tab>buf = buf[struct.calcsize(cls._SEG_HDR_PACK_STR) :]<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>buf = buf[num_as * two_byte_as_size :]<tab>return True",0,if len ( buf ) < num_as * two_byte_as_size :,if num_as < two_byte_as_size :,0.028080277472408426,47.57708354525859,0.46875
"def reparentChildren(self, newParent):<tab>if newParent.childNodes:<tab><tab>newParent.childNodes[-1]._element.tail += self._element.text<tab>else:<tab><tab><IF-STMT><tab><tab><tab>newParent._element.text = """"<tab><tab>if self._element.text is not None:<tab><tab><tab>newParent._element.text += self._element.text<tab>self._element.text = """"<tab>base.Node.reparentChildren(self, newParent)",0,if not newParent . _element . text :,if newParent . _element . text is None :,0.2636028267164803,55.55238068023578,0.2698412698412698
"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab>if isinstance(definition, ast.OperationDefinition):<tab><tab><tab>if not operation_name:<tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab>if operation:<tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return definition<tab>return operation",0,elif definition . name and definition . name . value == operation_name :,elif definition . name == operation_name :,0.27467112905245267,43.11625024848288,0.5138888888888888
"def reprSmart(vw, item):<tab>ptype = type(item)<tab>if ptype is int:<tab><tab><IF-STMT><tab><tab><tab>return str(item)<tab><tab>elif vw.isValidPointer(item):<tab><tab><tab>return vw.reprPointer(item)<tab><tab>else:<tab><tab><tab>return hex(item)<tab>elif ptype in (list, tuple):<tab><tab>return reprComplex(vw, item)  # recurse<tab>elif ptype is dict:<tab><tab>return ""{%s}"" % "","".join(<tab><tab><tab>[""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()]<tab><tab>)<tab>else:<tab><tab>return repr(item)",0,if - 1024 < item < 1024 :,if vw . isValidString ( item ) :,0.019345087832959386,7.267884212102741,0.3333333333333333
"def cleanDataCmd(cmd):<tab>newcmd = ""AbracadabrA ** <?php ""<tab>if cmd[:6] != ""php://"":<tab><tab><IF-STMT><tab><tab><tab>cmds = cmd.split(""&"")<tab><tab><tab>for c in cmds:<tab><tab><tab><tab>if len(c) > 0:<tab><tab><tab><tab><tab>newcmd += ""system('%s');"" % c<tab><tab>else:<tab><tab><tab>b64cmd = base64.b64encode(cmd)<tab><tab><tab>newcmd += ""system(base64_decode('%s'));"" % b64cmd<tab>else:<tab><tab>newcmd += cmd[6:]<tab>newcmd += ""?> **""<tab>return newcmd",0,if reverseConn not in cmd :,"if ""&"" in cmd :",0.11529782719544424,26.269098944241588,0.25
"def render_tasks(self) -> List:<tab>results = []<tab>for task in self.tasks.values():<tab><tab>job_entry = self.jobs.get(task.job_id)<tab><tab><IF-STMT><tab><tab><tab>if not self.should_render_job(job_entry):<tab><tab><tab><tab>continue<tab><tab>files = self.get_file_counts([task])<tab><tab>entry = (<tab><tab><tab>task.job_id,<tab><tab><tab>task.task_id,<tab><tab><tab>task.state,<tab><tab><tab>task.type.name,<tab><tab><tab>task.target,<tab><tab><tab>files,<tab><tab><tab>task.pool,<tab><tab><tab>task.end_time,<tab><tab>)<tab><tab>results.append(entry)<tab>return results",1,if job_entry :,if job_entry :,0.5311706625951745,1e-10,1.0
"def __call__(self, environ, start_response):<tab>for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"":<tab><tab>if key not in environ:<tab><tab><tab>continue<tab><tab>request_uri = unquote(environ[key])<tab><tab>script_name = unquote(environ.get(""SCRIPT_NAME"", """"))<tab><tab><IF-STMT><tab><tab><tab>environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0]<tab><tab><tab>break<tab>return self.app(environ, start_response)",1,if request_uri . startswith ( script_name ) :,if request_uri . startswith ( script_name ) :,0.75,100.00000000000004,1.0
"def _add_role_information(self, function_dict, role_id):<tab># Make it easier to build rules based on policies attached to execution roles<tab>function_dict[""role_arn""] = role_id<tab>role_name = role_id.split(""/"")[-1]<tab>function_dict[<tab><tab>""execution_role""<tab>] = await self.facade.awslambda.get_role_with_managed_policies(role_name)<tab>if function_dict.get(""execution_role""):<tab><tab>statements = []<tab><tab>for policy in function_dict[""execution_role""].get(""policies""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statements += policy[""Document""][""Statement""]<tab><tab>function_dict[""execution_role""][""policy_statements""] = statements",0,"if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :","if policy [ ""PolicyArn"" ] == role_name :",0.023405416318388987,10.706109099319784,0.35
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_ts(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def format_counts(results, json_output=False, human_readable=False):<tab>if json_output:<tab><tab>for result in results:<tab><tab><tab>yield json.dumps(result)<tab>else:<tab><tab>for result in results:<tab><tab><tab>space_consumed = result.get(""spaceConsumed"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>space_consumed = _sizeof_fmt(int(result.get(""spaceConsumed"")))<tab><tab><tab>yield ""%12s %12s %18s %s"" % (<tab><tab><tab><tab>result.get(""directoryCount""),<tab><tab><tab><tab>result.get(""fileCount""),<tab><tab><tab><tab>space_consumed,<tab><tab><tab><tab>result.get(""path""),<tab><tab><tab>)",1,if human_readable :,if human_readable :,0.5311706625951745,1e-10,1.0
"def parse_edges(self, pcb):<tab>edges = []<tab>drawings = list(pcb.GetDrawings())<tab>bbox = None<tab>for m in pcb.GetModules():<tab><tab>for g in m.GraphicalItems():<tab><tab><tab>drawings.append(g)<tab>for d in drawings:<tab><tab>if d.GetLayer() == pcbnew.Edge_Cuts:<tab><tab><tab>parsed_drawing = self.parse_drawing(d)<tab><tab><tab>if parsed_drawing:<tab><tab><tab><tab>edges.append(parsed_drawing)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>bbox = d.GetBoundingBox()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>bbox.Merge(d.GetBoundingBox())<tab>if bbox:<tab><tab>bbox.Normalize()<tab>return edges, bbox",1,if bbox is None :,if bbox is None :,0.75,100.00000000000004,1.0
"def __getitem__(self, k) -> ""SimMemView"":<tab>if isinstance(k, slice):<tab><tab>if k.step is not None:<tab><tab><tab>raise ValueError(""Slices with strides are not supported"")<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Must specify start index"")<tab><tab>elif k.stop is not None:<tab><tab><tab>raise ValueError(""Slices with stop index are not supported"")<tab><tab>else:<tab><tab><tab>addr = k.start<tab>elif self._type is not None and self._type._can_refine_int:<tab><tab>return self._type._refine(self, k)<tab>else:<tab><tab>addr = k<tab>return self._deeper(addr=addr)",1,elif k . start is None :,elif k . start is None :,0.75,100.00000000000004,1.0
"def _parse(self, stream, context):<tab>obj = []<tab>try:<tab><tab>if self.subcon.conflags & self.FLAG_COPY_CONTEXT:<tab><tab><tab>while True:<tab><tab><tab><tab>subobj = self.subcon._parse(stream, context.__copy__())<tab><tab><tab><tab>obj.append(subobj)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>while True:<tab><tab><tab><tab>subobj = self.subcon._parse(stream, context)<tab><tab><tab><tab>obj.append(subobj)<tab><tab><tab><tab>if self.predicate(subobj, context):<tab><tab><tab><tab><tab>break<tab>except ConstructError as ex:<tab><tab>raise ArrayError(""missing terminator"", ex)<tab>return obj",1,"if self . predicate ( subobj , context ) :","if self . predicate ( subobj , context ) :",0.75,100.00000000000004,1.0
"def before_run(self, run_context):<tab>if ""featurizer"" in self.model_portion and (<tab><tab>self.need_to_refresh or self.refresh_base_model<tab>):<tab><tab><IF-STMT><tab><tab><tab>self.refresh_base_model = True<tab><tab>self.init_fn(<tab><tab><tab>None, run_context.session, self.model_portion, self.refresh_base_model<tab><tab>)<tab><tab>self.need_to_refresh = False<tab><tab>self.refresh_base_model = False",0,"if self . model_portion == ""whole_featurizer"" :",if self . refresh_base_model :,0.09453229110448028,12.58503278125222,1.0
"def run(self):<tab>while True:<tab><tab>task = self.requestQueue.get()<tab><tab>if task is None:<tab><tab><tab># The ""None"" value is used as a sentinel by<tab><tab><tab># ThreadPool.cleanup().  This indicates that there<tab><tab><tab># are no more tasks, so we should quit.<tab><tab><tab>break<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise SCons.Errors.BuildError(task.targets[0], errstr=interrupt_msg)<tab><tab><tab>task.execute()<tab><tab>except:<tab><tab><tab>task.exception_set()<tab><tab><tab>ok = False<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.resultsQueue.put((task, ok))",0,if self . interrupted ( ) :,if task . targets :,0.02384665141965364,9.423716574733431,0.3333333333333333
"def get_overdue_evergreen_documents(*, db_session) -> List[Optional[Document]]:<tab>""""""Returns all documents that have need had a recent evergreen notification.""""""<tab>documents = (<tab><tab>db_session.query(Document).filter(Document.evergreen == True)<tab>).all()  # noqa<tab>overdue_documents = []<tab>now = datetime.utcnow()<tab>for d in documents:<tab><tab>next_reminder = d.evergreen_last_reminder_at + timedelta(<tab><tab><tab>days=d.evergreen_reminder_interval<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>overdue_documents.append(d)<tab>return overdue_documents",0,if now > next_reminder :,if next_reminder < now :,0.038498786468962445,29.071536848410968,1.0
"def create_local_app_folder(local_app_path):<tab>if exists(local_app_path):<tab><tab>raise ValueError(""There is already a '%s' folder! Aborting!"" % local_app_path)<tab>for folder in subfolders(local_app_path):<tab><tab>if not exists(folder):<tab><tab><tab>os.mkdir(folder)<tab><tab><tab>init_path = join(folder, ""__init__.py"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>create_file(init_path)",0,if not exists ( init_path ) :,if exists ( init_path ) :,0.33154408599183977,76.72796459606589,0.4722222222222222
"def generate():<tab>for leaf in u.leaves:<tab><tab><IF-STMT><tab><tab><tab>val = leaf.get_int_value()<tab><tab><tab>if val in (0, 1):<tab><tab><tab><tab>yield val<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>elif isinstance(leaf, Symbol):<tab><tab><tab>if leaf == SymbolTrue:<tab><tab><tab><tab>yield 1<tab><tab><tab>elif leaf == SymbolFalse:<tab><tab><tab><tab>yield 0<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>else:<tab><tab><tab>raise _NoBoolVector",1,"if isinstance ( leaf , Integer ) :","if isinstance ( leaf , Integer ) :",0.75,100.00000000000004,1.0
"def replace(self, old, new):<tab>v_m = self.var_map<tab>size = v_m[self.size]<tab>if not (size.is_const() or size.is_ident()):<tab><tab>size.replace(old, new)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>v_m[new.value()] = new<tab><tab><tab>self.size = new.value()<tab><tab>else:<tab><tab><tab>v_m[old] = new",1,if new . is_ident ( ) :,if new . is_ident ( ) :,0.75,100.00000000000004,1.0
"def method_for_doctype(doctype):<tab>method = ""xhtml""<tab>if doctype:<tab><tab>if doctype.startswith(""html""):<tab><tab><tab>method = ""html""<tab><tab><IF-STMT><tab><tab><tab>method = ""xhtml""<tab><tab>elif doctype.startswith(""svg""):<tab><tab><tab>method = ""xml""<tab><tab>else:<tab><tab><tab>method = ""xhtml""<tab>return method",1,"elif doctype . startswith ( ""xhtml"" ) :","elif doctype . startswith ( ""xhtml"" ) :",0.75,100.00000000000004,1.0
"def delete(self, trans, **kwd):<tab>idnum = kwd[self.tagged_item_id]<tab>item = self._get_item_from_id(trans, idnum, check_writable=True)<tab>if item is not None:<tab><tab>ex_obj = self.get_item_extended_metadata_obj(trans, item)<tab><tab><IF-STMT><tab><tab><tab>self.unset_item_extended_metadata_obj(trans, item)<tab><tab><tab>self.delete_extended_metadata(trans, ex_obj)",1,if ex_obj is not None :,if ex_obj is not None :,0.75,100.00000000000004,1.0
"def check_testv(self, testv):<tab>test_good = True<tab>f = open(self.home, ""rb+"")<tab>for (offset, length, operator, specimen) in testv:<tab><tab>data = self._read_share_data(f, offset, length)<tab><tab><IF-STMT><tab><tab><tab>test_good = False<tab><tab><tab>break<tab>f.close()<tab>return test_good",0,"if not testv_compare ( data , operator , specimen ) :",if not data :,0.02182019517687131,4.004304603105518,0.6428571428571429
"def get_history_user(self, instance):<tab>""""""Get the modifying user from instance or middleware.""""""<tab>try:<tab><tab>return instance._history_user<tab>except AttributeError:<tab><tab>request = None<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>request = self.thread.request<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return self.get_user(instance=instance, request=request)",0,if self . thread . request . user . is_authenticated :,if self . thread :,0.16138948280279303,14.276239697197271,0.6428571428571429
"def _check(self, name, size=None, *extra):<tab>func = getattr(imageop, name)<tab>for height in VALUES:<tab><tab>for width in VALUES:<tab><tab><tab>strlen = abs(width * height)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strlen *= size<tab><tab><tab>if strlen < MAX_LEN:<tab><tab><tab><tab>data = ""A"" * strlen<tab><tab><tab>else:<tab><tab><tab><tab>data = AAAAA<tab><tab><tab>if size:<tab><tab><tab><tab>arguments = (data, size, width, height) + extra<tab><tab><tab>else:<tab><tab><tab><tab>arguments = (data, width, height) + extra<tab><tab><tab>try:<tab><tab><tab><tab>func(*arguments)<tab><tab><tab>except (ValueError, imageop.error):<tab><tab><tab><tab>pass",1,if size :,if size :,0.5311706625951745,1e-10,1.0
"def __setattr__(self, name, value):<tab>if name == ""path"":<tab><tab>if value and value != """":<tab><tab><tab>if value[0] != ""/"":<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>'The page path should always start with a slash (""/"").'<tab><tab><tab><tab>)<tab>elif name == ""load_time"":<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Page load time must be specified in integer milliseconds.""<tab><tab><tab>)<tab>object.__setattr__(self, name, value)",0,"if value and not isinstance ( value , int ) :","if not isinstance ( value , int ) :",0.3879258020486436,71.19674182275,0.2571428571428572
"def __repr__(self):<tab>if self._in_repr:<tab><tab>return ""<recursion>""<tab>try:<tab><tab>self._in_repr = True<tab><tab>if self.is_computed():<tab><tab><tab>status = ""computed, ""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.value() is self:<tab><tab><tab><tab><tab>status += ""= self""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>status += ""= "" + repr(self.value())<tab><tab><tab>else:<tab><tab><tab><tab>status += ""error = "" + repr(self.error())<tab><tab>else:<tab><tab><tab>status = ""isn't computed""<tab><tab>return ""%s (%s)"" % (type(self), status)<tab>finally:<tab><tab>self._in_repr = False",0,if self . error ( ) is None :,if self . error ( ) is not None :,0.5026338000327998,70.71067811865478,0.6984126984126985
"def _exclude_node(self, name):<tab>if ""exclude_nodes"" in self.node_filters:<tab><tab><IF-STMT><tab><tab><tab>self.loggit.info('Excluding node ""{0}"" due to node_filters'.format(name))<tab><tab><tab>return True<tab>return False",0,"if name in self . node_filters [ ""exclude_nodes"" ] :","if self . node_filters [ ""exclude_nodes"" ] [ name ] :",0.35601076459218384,72.97627709554281,0.38666666666666666
"def enumerate_projects():<tab>""""""List projects in _DEFAULT_APP_DIR.""""""<tab>src_path = os.path.join(_DEFAULT_APP_DIR, ""src"")<tab>projects = {}<tab>for project in os.listdir(src_path):<tab><tab>projects[project] = []<tab><tab>project_path = os.path.join(src_path, project)<tab><tab>for file in os.listdir(project_path):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>projects[project].append(file[:-8])<tab>return projects",0,"if file . endswith ( "".gwt.xml"" ) :","if file . endswith ( "".py"" ) and file . endswith ( "".py"" ) :",0.346128782629825,34.82207361953904,0.638095238095238
"def zip_readline_read_test(self, f, compression):<tab>self.make_test_archive(f, compression)<tab># Read the ZIP archive<tab>with zipfile.ZipFile(f, ""r"") as zipfp, zipfp.open(TESTFN) as zipopen:<tab><tab>data = b""""<tab><tab>while True:<tab><tab><tab>read = zipopen.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>data += read<tab><tab><tab>read = zipopen.read(100)<tab><tab><tab>if not read:<tab><tab><tab><tab>break<tab><tab><tab>data += read<tab>self.assertEqual(data, self.data)",1,if not read :,if not read :,0.75,100.00000000000004,1.0
"def f(view, s):<tab>if mode == modes.NORMAL:<tab><tab>return sublime.Region(0)<tab>elif mode == modes.VISUAL:<tab><tab><IF-STMT><tab><tab><tab>return sublime.Region(s.a + 1, 0)<tab><tab>else:<tab><tab><tab>return sublime.Region(s.a, 0)<tab>elif mode == modes.INTERNAL_NORMAL:<tab><tab>return sublime.Region(view.full_line(s.b).b, 0)<tab>elif mode == modes.VISUAL_LINE:<tab><tab>if s.a < s.b:<tab><tab><tab>return sublime.Region(0, s.b)<tab><tab>else:<tab><tab><tab>return sublime.Region(0, s.a)<tab>return s",1,if s . a < s . b :,if s . a < s . b :,0.75,100.00000000000004,1.0
def response(self):<tab>try:<tab><tab>response = requests.get(str(self))<tab><tab>rjson = response.json()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(response.text)<tab><tab>return rjson<tab>except Exception as e:<tab><tab>raise ResponseFanartError(str(e)),0,"if not isinstance ( rjson , dict ) :","if ""error"" in rjson :",0.0168380461076173,6.495032985064742,0.2571428571428572
"def __get_type(self, cexpr):<tab>""""""Returns one of the following types: 'R' - read value, 'W' - write value, 'A' - function argument""""""<tab>child = cexpr<tab>for p in reversed(self.parents):<tab><tab>assert p, ""Failed to get type at "" + helper.to_hex(self.__function_address)<tab><tab>if p.cexpr.op == idaapi.cot_call:<tab><tab><tab>return ""Arg""<tab><tab>if not p.is_expr():<tab><tab><tab>return ""R""<tab><tab>if p.cexpr.op == idaapi.cot_asg:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""W""<tab><tab><tab>return ""R""<tab><tab>child = p.cexpr",0,if p . cexpr . x == child :,if not child . is_expr ( ) :,0.01786335094255824,5.934202609760488,0.2571428571428572
"def _extract_lemma(self, parse: Parse) -> str:<tab>special_feats = [x for x in self.SPECIAL_FEATURES if x in parse.tag]<tab>if len(special_feats) == 0:<tab><tab>return parse.normal_form<tab># here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly<tab>for other in parse.lexeme:<tab><tab>tag = other.tag<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>tag.case == ""nomn""<tab><tab><tab>and tag.gender == parse.tag.gender<tab><tab><tab>and tag.number == ""sing""<tab><tab>):<tab><tab><tab>return other.word<tab>return parse.normal_form",0,if any ( x not in tag for x in special_feats ) :,if tag . case in special_feats :,0.06993093042951729,17.625328548379716,0.1794871794871795
"def evaluateWord(self, argument):<tab>wildcard_count = argument[0].count(""*"")<tab>if wildcard_count > 0:<tab><tab>if wildcard_count == 1 and argument[0].startswith(""*""):<tab><tab><tab>return self.GetWordWildcard(argument[0][1:], method=""endswith"")<tab><tab><IF-STMT><tab><tab><tab>return self.GetWordWildcard(argument[0][:-1], method=""startswith"")<tab><tab>else:<tab><tab><tab>_regex = argument[0].replace(""*"", "".+"")<tab><tab><tab>matched = False<tab><tab><tab>for w in self.words:<tab><tab><tab><tab>matched = bool(re.search(_regex, w))<tab><tab><tab><tab>if matched:<tab><tab><tab><tab><tab>break<tab><tab><tab>return matched<tab>return self.GetWord(argument[0])",0,"if wildcard_count == 1 and argument [ 0 ] . endswith ( ""*"" ) :","elif wildcard_count == 2 and argument [ 0 ] . endswith ( ""*"" ) :",0.50648566402329,80.3154665668484,0.5555555555555556
def getAllEntries(self):<tab>entries = []<tab>for bucket in self.buckets:<tab><tab>last = None<tab><tab>for entry in bucket.entries:<tab><tab><tab>if last is not None:<tab><tab><tab><tab>last.size = entry.virtualOffset - last.virtualOffset<tab><tab><tab>last = entry<tab><tab><tab>entries.append(entry)<tab><tab><IF-STMT><tab><tab><tab>entries[-1].size = bucket.endOffset - entries[-1].virtualOffset<tab>return entries,0,if len ( entries ) != 0 :,if len ( entries ) > 1 :,0.5241515189640744,47.750342648354646,0.6666666666666666
def clean(self):<tab>if self._ctx:<tab><tab><IF-STMT><tab><tab><tab>libcrypto.EVP_CIPHER_CTX_cleanup(self._ctx)<tab><tab>else:<tab><tab><tab>libcrypto.EVP_CIPHER_CTX_reset(self._ctx)<tab><tab>libcrypto.EVP_CIPHER_CTX_free(self._ctx),0,"if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :",if libcrypto . EVP_CIPHER_CTX_cleanup :,0.019907917998500824,39.60111677234155,0.4772727272727273
"def _addTab(self, name, label, idx=None):<tab>label = getLanguageString(label)<tab>tab = Tab(self, name, label)<tab>tab.idx = self._makeTab(tab, idx)<tab>if idx != None:<tab><tab># Update index list when inserting tabs at arbitrary positions<tab><tab>newIdxList = {}<tab><tab>for tIdx, t in list(self._tabs_by_idx.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>t.idx += 1<tab><tab><tab>newIdxList[t.idx] = t<tab><tab>self._tabs_by_idx = newIdxList<tab>self._tabs_by_idx[tab.idx] = tab<tab>self._tabs_by_name[tab.name] = tab<tab>return tab",0,if int ( tIdx ) >= idx :,if t . idx != idx :,0.03364361311250231,19.493995755254467,0.4444444444444444
"def set(self, _key, _new_login=True):<tab>with self.lock:<tab><tab>user = self.users.get(current_user.id, None)<tab><tab><IF-STMT><tab><tab><tab>self.users[current_user.id] = dict(session_count=1, key=_key)<tab><tab>else:<tab><tab><tab>if _new_login:<tab><tab><tab><tab>user[""session_count""] += 1<tab><tab><tab>user[""key""] = _key",1,if user is None :,if user is None :,0.75,100.00000000000004,1.0
"def stop(self):<tab># Try to shut the connection down, but if we get any sort of<tab># errors, go ahead and ignore them.. as we're shutting down anyway<tab>try:<tab><tab>self.rpcserver.stop()<tab><tab><IF-STMT><tab><tab><tab>self.backend_rpcserver.stop()<tab><tab>if self.cluster_rpcserver:<tab><tab><tab>self.cluster_rpcserver.stop()<tab>except Exception:<tab><tab>pass<tab>if self.coordination:<tab><tab>try:<tab><tab><tab>coordination.COORDINATOR.stop()<tab><tab>except Exception:<tab><tab><tab>pass<tab>super(Service, self).stop(graceful=True)",1,if self . backend_rpcserver :,if self . backend_rpcserver :,0.75,100.00000000000004,1.0
"def __genmenuOnlyAllocated(menu):<tab>for submenu in menu.Submenus:<tab><tab>__genmenuOnlyAllocated(submenu)<tab>if menu.OnlyUnallocated == True:<tab><tab>tmp[""cache""].addMenuEntries(menu.AppDirs)<tab><tab>menuentries = []<tab><tab>for rule in menu.Rules:<tab><tab><tab>menuentries = rule.do(<tab><tab><tab><tab>tmp[""cache""].getMenuEntries(menu.AppDirs), rule.Type, 2<tab><tab><tab>)<tab><tab>for menuentry in menuentries:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>menuentry.Parents.append(menu)<tab><tab><tab><tab>#   menuentry.Add = False<tab><tab><tab><tab>#   menuentry.Allocated = True<tab><tab><tab><tab>menu.MenuEntries.append(menuentry)",1,if menuentry . Add == True :,if menuentry . Add == True :,0.75,100.00000000000004,1.0
"def __init__(self, **options):<tab>self.func_name_highlighting = get_bool_opt(options, ""func_name_highlighting"", True)<tab>self.disabled_modules = get_list_opt(options, ""disabled_modules"", [])<tab>self._functions = set()<tab>if self.func_name_highlighting:<tab><tab>from pygments.lexers._lua_builtins import MODULES<tab><tab>for mod, func in iteritems(MODULES):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._functions.update(func)<tab>RegexLexer.__init__(self, **options)",1,if mod not in self . disabled_modules :,if mod not in self . disabled_modules :,0.75,100.00000000000004,1.0
"def recv_some(p, t=0.1, e=1, tr=5, stderr=0):<tab>if tr < 1:<tab><tab>tr = 1<tab>x = time.time() + t<tab>y = []<tab>r = """"<tab>if stderr:<tab><tab>pr = p.recv_err<tab>else:<tab><tab>pr = p.recv<tab>while time.time() < x or r:<tab><tab>r = pr()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif r:<tab><tab><tab>y.append(r)<tab><tab>else:<tab><tab><tab>time.sleep(max((x - time.time()) / tr, 0))<tab>return """".join(y)",0,if r is None :,if e :,0.03549272049582243,1e-10,0.25
"def get_menu_items(node):<tab>aList = []<tab>for child in node.children:<tab><tab>for tag in (""@menu"", ""@item""):<tab><tab><tab>if child.h.startswith(tag):<tab><tab><tab><tab>name = child.h[len(tag) + 1 :].strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>aList.append((""%s %s"" % (tag, name), get_menu_items(child), None))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>b = g.splitLines("""".join(child.b))<tab><tab><tab><tab><tab>aList.append((tag, name, b[0] if b else """"))<tab><tab><tab><tab>break<tab>return aList",0,"if tag == ""@menu"" :",if name :,0.03549272049582243,1e-10,0.5
"def import_suffix_generator(a_block, datatype=False):<tab>if datatype is False:<tab><tab>for name, suffix in iteritems(a_block.component_map(Suffix)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield name, suffix<tab>else:<tab><tab>for name, suffix in iteritems(a_block.component_map(Suffix)):<tab><tab><tab>if (suffix.import_enabled() is True) and (<tab><tab><tab><tab>suffix.get_datatype() is datatype<tab><tab><tab>):<tab><tab><tab><tab>yield name, suffix",1,if suffix . import_enabled ( ) is True :,if suffix . import_enabled ( ) is True :,0.75,100.00000000000004,1.0
"def verify_relative_valid_path(root, path):<tab>if len(path) < 1:<tab><tab>raise PackagerError(""Empty chown path"")<tab>checkpath = root<tab>parts = path.split(os.sep)<tab>for part in parts:<tab><tab>if part in (""."", ""..""):<tab><tab><tab>raise PackagerError("". and .. is not allowed in chown path"")<tab><tab>checkpath = os.path.join(checkpath, part)<tab><tab>relpath = checkpath[len(root) + 1 :]<tab><tab>if not os.path.exists(checkpath):<tab><tab><tab>raise PackagerError(f""chown path {relpath} does not exist"")<tab><tab><IF-STMT><tab><tab><tab>raise PackagerError(f""chown path {relpath} is a soft link"")",0,if os . path . islink ( checkpath ) :,"if part == ""soft"" :",0.013468035777437931,5.11459870708889,0.25274725274725274
"def load_syntax(syntax):<tab>context = _create_scheme() or {}<tab>partition_scanner = PartitionScanner(syntax.get(""partitions"", []))<tab>scanners = {}<tab>for part_name, part_scanner in list(syntax.get(""scanner"", {}).items()):<tab><tab>scanners[part_name] = Scanner(part_scanner)<tab>formats = []<tab>for fname, fstyle in list(syntax.get(""formats"", {}).items()):<tab><tab><IF-STMT><tab><tab><tab>if fstyle.startswith(""%("") and fstyle.endswith("")s""):<tab><tab><tab><tab>key = fstyle[2:-2]<tab><tab><tab><tab>fstyle = context[key]<tab><tab><tab>else:<tab><tab><tab><tab>fstyle = fstyle % context<tab><tab>formats.append((fname, fstyle))<tab>return partition_scanner, scanners, formats",0,"if isinstance ( fstyle , basestring ) :","if isinstance ( fstyle , str ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def should_keep_alive(commit_msg):<tab>result = False<tab>ci = get_current_ci() or """"<tab>for line in commit_msg.splitlines():<tab><tab>parts = line.strip(""# "").split("":"", 1)<tab><tab>(key, val) = parts if len(parts) > 1 else (parts[0], """")<tab><tab><IF-STMT><tab><tab><tab>ci_names = val.replace("","", "" "").lower().split() if val else []<tab><tab><tab>if len(ci_names) == 0 or ci.lower() in ci_names:<tab><tab><tab><tab>result = True<tab>return result",0,"if key == ""CI_KEEP_ALIVE"" :","if key == ""alive"" :",0.39477865547525276,36.06452879987793,1.0
"def get_note_title_file(note):<tab>mo = note_title_re.match(note.get(""content"", """"))<tab>if mo:<tab><tab>fn = mo.groups()[0]<tab><tab>fn = fn.replace("" "", ""_"")<tab><tab>fn = fn.replace(""/"", ""_"")<tab><tab>if not fn:<tab><tab><tab>return """"<tab><tab><IF-STMT><tab><tab><tab>fn = unicode(fn, ""utf-8"")<tab><tab>else:<tab><tab><tab>fn = unicode(fn)<tab><tab>if note_markdown(note):<tab><tab><tab>fn += "".mkdn""<tab><tab>else:<tab><tab><tab>fn += "".txt""<tab><tab>return fn<tab>else:<tab><tab>return """"",0,"if isinstance ( fn , str ) :","if sys . version_info < ( 3 , 0 ) :",0.0318578261816963,7.768562846380176,0.25
"def post(self, orgname, teamname):<tab>if _syncing_setup_allowed(orgname):<tab><tab>try:<tab><tab><tab>team = model.team.get_organization_team(orgname, teamname)<tab><tab>except model.InvalidTeamException:<tab><tab><tab>raise NotFound()<tab><tab>config = request.get_json()<tab><tab># Ensure that the specified config points to a valid group.<tab><tab>status, err = authentication.check_group_lookup_args(config)<tab><tab><IF-STMT><tab><tab><tab>raise InvalidRequest(""Could not sync to group: %s"" % err)<tab><tab># Set the team's syncing config.<tab><tab>model.team.set_team_syncing(team, authentication.federated_service, config)<tab><tab>return team_view(orgname, team)<tab>raise Unauthorized()",0,if not status :,if status != 200 :,0.045150550804307965,10.682175159905853,0.4
"def _marshalData(self):<tab>if self._cache == None:<tab><tab>d = self._data<tab><tab>s = """"<tab><tab>s = time.strftime(""%H:%M:%S"", (0, 0, 0) + d + (0, 0, -1))<tab><tab>f = d[2] - int(d[2])<tab><tab><IF-STMT><tab><tab><tab>s += (""%g"" % f)[1:]<tab><tab>s += ""Z""<tab><tab>self._cache = s<tab>return self._cache",0,if f != 0 :,if f > 0 :,0.33141502097923065,24.736929544091932,1.0
"def _get_level(levels, level_ref):<tab>if level_ref in levels:<tab><tab>return levels.index(level_ref)<tab>if isinstance(level_ref, six.integer_types):<tab><tab>if level_ref < 0:<tab><tab><tab>level_ref += len(levels)<tab><tab><IF-STMT><tab><tab><tab>raise PatsyError(""specified level %r is out of range"" % (level_ref,))<tab><tab>return level_ref<tab>raise PatsyError(""specified level %r not found"" % (level_ref,))",0,if not ( 0 <= level_ref < len ( levels ) ) :,if level_ref >= len ( levels ) :,0.18223874796362236,24.645080904880025,0.3148148148148148
"def iterfieldselect(source, field, where, complement, missing):<tab>it = iter(source)<tab>hdr = next(it)<tab>yield tuple(hdr)<tab>indices = asindices(hdr, field)<tab>getv = operator.itemgetter(*indices)<tab>for row in it:<tab><tab>try:<tab><tab><tab>v = getv(row)<tab><tab>except IndexError:<tab><tab><tab>v = missing<tab><tab><IF-STMT>  # XOR<tab><tab><tab>yield tuple(row)",0,if bool ( where ( v ) ) != complement :,if v == where :,0.013055717236343255,4.465061041725592,0.4761904761904762
"def _test_wait_read_invalid_switch(self, sleep):<tab>sock1, sock2 = socket.socketpair()<tab>try:<tab><tab>p = gevent.spawn(<tab><tab><tab>util.wrap_errors(<tab><tab><tab><tab>AssertionError, socket.wait_read<tab><tab><tab>),  # pylint:disable=no-member<tab><tab><tab>sock1.fileno(),<tab><tab>)<tab><tab>gevent.get_hub().loop.run_callback(switch_None, p)<tab><tab><IF-STMT><tab><tab><tab>gevent.sleep(sleep)<tab><tab>result = p.get()<tab><tab>assert isinstance(result, AssertionError), result<tab><tab>assert ""Invalid switch"" in str(result), repr(str(result))<tab>finally:<tab><tab>sock1.close()<tab><tab>sock2.close()",0,if sleep is not None :,if sleep :,0.050438393472541504,1e-10,0.39999999999999997
"def train(config, args):<tab>gan = setup_gan(config, inputs, args)<tab>test_batches = []<tab>for i in range(args.steps):<tab><tab>gan.step()<tab><tab><IF-STMT><tab><tab><tab>correct_prediction = 0<tab><tab><tab>total = 0<tab><tab><tab>for (x, y) in gan.inputs.testdata():<tab><tab><tab><tab>prediction = gan.generator(x)<tab><tab><tab><tab>correct_prediction += (<tab><tab><tab><tab><tab>torch.argmax(prediction, 1) == torch.argmax(y, 1)<tab><tab><tab><tab>).sum()<tab><tab><tab><tab>total += y.shape[0]<tab><tab><tab>accuracy = (float(correct_prediction) / total) * 100<tab><tab><tab>print(""accuracy: "", accuracy)<tab>return sum_metrics",0,if i % args . sample_every == 0 and i > 0 :,if i % args . steps == 0 :,0.2893132295417031,30.861946272099846,0.5034013605442177
"def process_response(self, request, response, spider):<tab>if not response.body:<tab><tab>return response<tab>for fmt, func in six.iteritems(self._formats):<tab><tab>new_response = func(response)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(<tab><tab><tab><tab>""Decompressed response with format: %(responsefmt)s"",<tab><tab><tab><tab>{""responsefmt"": fmt},<tab><tab><tab><tab>extra={""spider"": spider},<tab><tab><tab>)<tab><tab><tab>return new_response<tab>return response",0,if new_response :,if new_response is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def detect_ssl_option(self):<tab>for option in self.ssl_options():<tab><tab><IF-STMT><tab><tab><tab>for other_option in self.ssl_options():<tab><tab><tab><tab>if option != other_option:<tab><tab><tab><tab><tab>if scan_argv(self.argv, other_option) is not None:<tab><tab><tab><tab><tab><tab>raise ConfigurationError(<tab><tab><tab><tab><tab><tab><tab>""Cannot give both %s and %s"" % (option, other_option)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab>return option",0,"if scan_argv ( self . argv , option ) is not None :",if option is not None :,0.172056202381818,12.547530994780285,0.23214285714285715
"def load(cls, storefile, template_store):<tab># Did we get file or filename?<tab>if not hasattr(storefile, ""read""):<tab><tab>storefile = open(storefile, ""rb"")<tab># Adjust store to have translations<tab>store = cls.convertfile(storefile, template_store)<tab>for unit in store.units:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># HTML does this properly on loading, others need it<tab><tab>if cls.needs_target_sync:<tab><tab><tab>unit.target = unit.source<tab><tab><tab>unit.rich_target = unit.rich_source<tab>return store",0,if unit . isheader ( ) :,if unit . is_html :,0.09453229110448028,26.269098944241588,0.7222222222222222
"def _pre_get_table(self, _ctx, table_name):<tab>vsctl_table = self._get_table(table_name)<tab>schema_helper = self.schema_helper<tab>schema_helper.register_table(vsctl_table.table_name)<tab>for row_id in vsctl_table.row_ids:<tab><tab><IF-STMT><tab><tab><tab>schema_helper.register_table(row_id.table)<tab><tab>if row_id.name_column:<tab><tab><tab>schema_helper.register_columns(row_id.table, [row_id.name_column])<tab><tab>if row_id.uuid_column:<tab><tab><tab>schema_helper.register_columns(row_id.table, [row_id.uuid_column])<tab>return vsctl_table",1,if row_id . table :,if row_id . table :,0.75,100.00000000000004,1.0
"def __init__(self, pin=None, pull_up=False):<tab>super(InputDevice, self).__init__(pin)<tab>try:<tab><tab>self.pin.function = ""input""<tab><tab>pull = ""up"" if pull_up else ""down""<tab><tab><IF-STMT><tab><tab><tab>self.pin.pull = pull<tab>except:<tab><tab>self.close()<tab><tab>raise<tab>self._active_state = False if pull_up else True<tab>self._inactive_state = True if pull_up else False",0,if self . pin . pull != pull :,if pull :,0.024814632707681465,1e-10,0.34545454545454546
"def _increment_operations_count(self, operation, executed):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self._executed_operations += 1<tab><tab><tab>self._executed[operation.job_type] += 1<tab><tab>else:<tab><tab><tab>self._skipped[operation.job_type] += 1",0,if executed :,if operation . job_type in self . _executed :,0.04309983002500103,1e-10,0.3055555555555556
"def emit(self, type, info=None):<tab># Overload emit() to send events to the proxy object at the other end<tab>ev = super().emit(type, info)<tab>if self._has_proxy is True and self._session.status > 0:<tab><tab># implicit: and self._disposed is False:<tab><tab><IF-STMT><tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])<tab><tab>elif type in self.__event_types_at_proxy:<tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",0,if type in self . __proxy_properties__ :,if type in self . __event_types_at_proxy :,0.574113272471593,47.587330964125215,1.0
"def validate_pull_secret(namespace):<tab>if namespace.pull_secret is None:<tab><tab># TODO: add aka.ms link here<tab><tab>warning = (<tab><tab><tab>""No --pull-secret provided: cluster will not include samples or operators from ""<tab><tab><tab>+ ""Red Hat or from certified partners.""<tab><tab>)<tab><tab>logger.warning(warning)<tab>else:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception()<tab><tab>except:<tab><tab><tab>raise InvalidArgumentValueError(""Invalid --pull-secret."")",0,"if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :",if namespace . pull_secret != namespace . pull_secret :,0.07137420937475873,22.4687979920349,0.2272727272727273
"def pack(types, *args):<tab>if len(types) != len(args):<tab><tab>raise Exception(""number of arguments does not match format string"")<tab>port = StringIO()<tab>for (type, value) in zip(types, args):<tab><tab>if type == ""V"":<tab><tab><tab>write_vuint(port, value)<tab><tab>elif type == ""v"":<tab><tab><tab>write_vint(port, value)<tab><tab><IF-STMT><tab><tab><tab>write_bvec(port, value)<tab><tab>else:<tab><tab><tab>raise Exception('unknown xpack format string item ""' + type + '""')<tab>return port.getvalue()",0,"elif type == ""s"" :","elif type == ""bvec"" :",0.6428720214849399,59.4603557501361,1.0
"def data(self):<tab>if self._data is not None:<tab><tab>return self._data<tab>else:<tab><tab><IF-STMT><tab><tab><tab>with open(self.path, ""rb"") as jsonfile:<tab><tab><tab><tab>data = jsonfile.read().decode(""utf8"")<tab><tab><tab><tab>data = json.loads(data)<tab><tab><tab><tab>self._data = data<tab><tab><tab><tab>return self._data<tab><tab>else:<tab><tab><tab>return dict()",1,if os . path . exists ( self . path ) :,if os . path . exists ( self . path ) :,1.0,100.00000000000004,1.0
"def interact(self):<tab>self.output.write(""\n"")<tab>while True:<tab><tab>try:<tab><tab><tab>request = self.getline(""help> "")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>except (KeyboardInterrupt, EOFError):<tab><tab><tab>break<tab><tab>request = strip(request)<tab><tab># Make sure significant trailing quotation marks of literals don't<tab><tab># get deleted while cleaning input<tab><tab>if (<tab><tab><tab>len(request) > 2<tab><tab><tab>and request[0] == request[-1] in (""'"", '""')<tab><tab><tab>and request[0] not in request[1:-1]<tab><tab>):<tab><tab><tab>request = request[1:-1]<tab><tab>if lower(request) in (""q"", ""quit""):<tab><tab><tab>break<tab><tab>self.help(request)",1,if not request :,if not request :,0.75,100.00000000000004,1.0
"def api_attachment_metadata(self):<tab>resp = []<tab>for part in self.parts:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>k = {<tab><tab><tab>""content_type"": part.block.content_type,<tab><tab><tab>""size"": part.block.size,<tab><tab><tab>""filename"": part.block.filename,<tab><tab><tab>""id"": part.block.public_id,<tab><tab>}<tab><tab>content_id = part.content_id<tab><tab>if content_id:<tab><tab><tab>if content_id[0] == ""<"" and content_id[-1] == "">"":<tab><tab><tab><tab>content_id = content_id[1:-1]<tab><tab><tab>k[""content_id""] = content_id<tab><tab>resp.append(k)<tab>return resp",0,if not part . is_attachment :,if not part . block :,0.5212518808542342,38.49815007763549,0.76
"def _notin_text(term, text, verbose=False):<tab>index = text.find(term)<tab>head = text[:index]<tab>tail = text[index + len(term) :]<tab>correct_text = head + tail<tab>diff = _diff_text(correct_text, text, verbose)<tab>newdiff = [u(""%s is contained here:"") % py.io.saferepr(term, maxsize=42)]<tab>for line in diff:<tab><tab>if line.startswith(u(""Skipping"")):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(u(""+ "")):<tab><tab><tab>newdiff.append(u(""  "") + line[2:])<tab><tab>else:<tab><tab><tab>newdiff.append(line)<tab>return newdiff",0,"if line . startswith ( u ( ""- "" ) ) :","if line . startswith ( u ( ""#"" ) ) :",0.5706348890957453,76.11606003349888,1.0
"def get_api(user, url):<tab>global API_CACHE<tab>if API_CACHE is None or API_CACHE.get(url) is None:<tab><tab>API_CACHE_LOCK.acquire()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>API_CACHE = {}<tab><tab><tab>if API_CACHE.get(url) is None:<tab><tab><tab><tab>API_CACHE[url] = ImpalaDaemonApi(url)<tab><tab>finally:<tab><tab><tab>API_CACHE_LOCK.release()<tab>api = API_CACHE[url]<tab>api.set_user(user)<tab>return api",1,if API_CACHE is None :,if API_CACHE is None :,0.75,100.00000000000004,1.0
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_index_name_:<tab><tab>res += prefix + (""index_name: %s\n"" % self.DebugFormatString(self.index_name_))<tab>cnt = 0<tab>for e in self.prefix_value_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""prefix_value%s: %s\n"" % (elm, self.DebugFormatString(e)))<tab><tab>cnt += 1<tab>if self.has_value_prefix_:<tab><tab>res += prefix + (<tab><tab><tab>""value_prefix: %s\n"" % self.DebugFormatBool(self.value_prefix_)<tab><tab>)<tab>return res",1,if printElemNumber :,if printElemNumber :,0.5311706625951745,1e-10,1.0
"def add_group(x, nl, in_group, mw):<tab>if len(x) == 0:<tab><tab>return x<tab>if len(x) > 1 and not in_group:<tab><tab><IF-STMT><tab><tab><tab>return [""[[""] + x + [""]]""]<tab><tab>mw.warn(<tab><tab><tab>""Equation will multiplex and may produce inaccurate results (see manual)""<tab><tab>)<tab>return [""[""] + x + [""]""]",0,"if supports_group ( x , nl ) :",if nl :,0.017267079824235865,1e-10,0.4772727272727273
"def unfulfilled_items(self):<tab>unfulfilled_items = 0<tab>for order_item in self.items.all():<tab><tab><IF-STMT><tab><tab><tab>aggr = order_item.deliver_item.aggregate(delivered=Sum(""quantity""))<tab><tab><tab>unfulfilled_items += order_item.quantity - (aggr[""delivered""] or 0)<tab>return unfulfilled_items",0,if not order_item . canceled :,if order_item . quantity :,0.054520976303194774,39.44243648327556,0.37142857142857144
"def _get_pattern(self, pattern_id):<tab>""""""Get pattern item by id.""""""<tab>for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3):<tab><tab><IF-STMT><tab><tab><tab>data = self.tagged_blocks.get_data(key)<tab><tab><tab>for pattern in data:<tab><tab><tab><tab>if pattern.pattern_id == pattern_id:<tab><tab><tab><tab><tab>return pattern<tab>return None",0,if key in self . tagged_blocks :,if self .tagged_blocks . has_key ( key ) :,0.021739616412259796,29.89950354998137,0.38181818181818183
"def query_lister(domain, query="""", max_items=None, attr_names=None):<tab>more_results = True<tab>num_results = 0<tab>next_token = None<tab>while more_results:<tab><tab>rs = domain.connection.query_with_attributes(<tab><tab><tab>domain, query, attr_names, next_token=next_token<tab><tab>)<tab><tab>for item in rs:<tab><tab><tab>if max_items:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>yield item<tab><tab><tab>num_results += 1<tab><tab>next_token = rs.next_token<tab><tab>more_results = next_token != None",0,if num_results == max_items :,if num_results >= max_items :,0.33141502097923065,65.80370064762461,1.0
"def find_deprecated_settings(source):  # pragma: no cover<tab>from celery.utils import deprecated<tab>for name, opt in flatten(NAMESPACES):<tab><tab><IF-STMT><tab><tab><tab>deprecated.warn(<tab><tab><tab><tab>description=""The {0!r} setting"".format(name),<tab><tab><tab><tab>deprecation=opt.deprecate_by,<tab><tab><tab><tab>removal=opt.remove_by,<tab><tab><tab><tab>alternative=""Use the {0.alt} instead"".format(opt),<tab><tab><tab>)<tab>return source",0,"if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) :",if opt . deprecated_by is not None :,0.061204978209110986,3.3661975796884764,0.22843822843822845
"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.server.stop(2.0)<tab><tab>if self.sl_hdlr:<tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",1,if self . server :,if self . server :,0.75,100.00000000000004,1.0
"def broadcast_events(self, events):<tab>LOGGER.debug(""Broadcasting events: %s"", events)<tab>with self._subscribers_cv:<tab><tab># Copy the subscribers<tab><tab>subscribers = {conn: sub.copy() for conn, sub in self._subscribers.items()}<tab>if subscribers:<tab><tab>for connection_id, subscriber in subscribers.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subscriber_events = [<tab><tab><tab><tab><tab>event for event in events if subscriber.is_subscribed(event)<tab><tab><tab><tab>]<tab><tab><tab><tab>event_list = EventList(events=subscriber_events)<tab><tab><tab><tab>self._send(connection_id, event_list.SerializeToString())",0,if subscriber . is_listening ( ) :,if events :,0.020447728119319098,1e-10,0.5
"def _get_info(self, path):<tab>info = OrderedDict()<tab>if not self._is_mac() or self._has_xcode_tools():<tab><tab>stdout = None<tab><tab>try:<tab><tab><tab>stdout, stderr = Popen(<tab><tab><tab><tab>[self._find_binary(), ""info"", os.path.realpath(path)],<tab><tab><tab><tab>stdout=PIPE,<tab><tab><tab><tab>stderr=PIPE,<tab><tab><tab>).communicate()<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>if stdout:<tab><tab><tab><tab>for line in stdout.splitlines():<tab><tab><tab><tab><tab>line = u(line).split("": "", 1)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>info[line[0]] = line[1]<tab>return info",1,if len ( line ) == 2 :,if len ( line ) == 2 :,0.75,100.00000000000004,1.0
"def test_call_extern_c_fn(self):<tab>global memcmp<tab>memcmp = cffi_support.ExternCFunction(<tab><tab>""memcmp"",<tab><tab>(""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""),<tab>)<tab>@udf(BooleanVal(FunctionContext, StringVal, StringVal))<tab>def fn(context, a, b):<tab><tab>if a.is_null != b.is_null:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if len(a) != b.len:<tab><tab><tab>return False<tab><tab>if a.ptr == b.ptr:<tab><tab><tab>return True<tab><tab>return memcmp(a.ptr, b.ptr, a.len) == 0",0,if a is None :,if a . ptr == b . ptr :,0.04757349237680735,9.287528999566801,0.4126984126984127
"def _flatten(*args):<tab>ahs = set()<tab>if len(args) > 0:<tab><tab>for item in args:<tab><tab><tab>if type(item) is ActionHandle:<tab><tab><tab><tab>ahs.add(item)<tab><tab><tab>elif type(item) in (list, tuple, dict, set):<tab><tab><tab><tab>for ah in item:<tab><tab><tab><tab><tab><IF-STMT>  # pragma:nocover<tab><tab><tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(ah))<tab><tab><tab><tab><tab>ahs.add(ah)<tab><tab><tab>else:  # pragma:nocover<tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(item))<tab>return ahs",0,if type ( ah ) is not ActionHandle :,if type ( ah ) is ActionHandle :,0.41888016042697734,67.5291821812656,0.6938775510204083
"def startElement(self, name, attrs, connection):<tab>if name == ""Parameter"":<tab><tab><IF-STMT><tab><tab><tab>self[self._current_param.name] = self._current_param<tab><tab>self._current_param = Parameter(self)<tab><tab>return self._current_param",0,if self . _current_param :,if self . _current_param is not None :,0.3514988343435983,59.00468726392806,0.4444444444444444
"def _find_class_in_descendants(self, search_key):<tab>for cls in self.primitive_classes:<tab><tab>cls_key = (cls.__name__, cls.__module__)<tab><tab>self.class_cache[cls_key] = cls<tab><tab><IF-STMT><tab><tab><tab>return cls",1,if cls_key == search_key :,if cls_key == search_key :,0.75,100.00000000000004,1.0
"def doWorkForFindAll(self, v, target, partialMatch):<tab>sibling = self<tab>while sibling:<tab><tab>c1 = partialMatch and sibling.equalsTreePartial(target)<tab><tab>if c1:<tab><tab><tab>v.append(sibling)<tab><tab>else:<tab><tab><tab>c2 = not partialMatch and sibling.equalsTree(target)<tab><tab><tab>if c2:<tab><tab><tab><tab>v.append(sibling)<tab><tab>### regardless of match or not, check any children for matches<tab><tab><IF-STMT><tab><tab><tab>sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch)<tab><tab>sibling = sibling.getNextSibling()",1,if sibling . getFirstChild ( ) :,if sibling . getFirstChild ( ) :,0.75,100.00000000000004,1.0
"def forward(self, inputs: paddle.Tensor):<tab>outputs = []<tab>blocks = self.block(inputs)<tab>route = None<tab>for i, block in enumerate(blocks):<tab><tab>if i > 0:<tab><tab><tab>block = paddle.concat([route, block], axis=1)<tab><tab>route, tip = self.yolo_blocks[i](block)<tab><tab>block_out = self.block_outputs[i](tip)<tab><tab>outputs.append(block_out)<tab><tab><IF-STMT><tab><tab><tab>route = self.route_blocks_2[i](route)<tab><tab><tab>route = self.upsample(route)<tab>return outputs",0,if i < 2 :,if i < len ( blocks ) - 1 :,0.10140375635431143,16.784459625186194,0.40476190476190477
"def _filter_paths(basename, path, is_dir, exclude):<tab>"""""".gitignore style file filtering.""""""<tab>for item in exclude:<tab><tab># Items ending in '/' apply only to directories.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Items starting with '/' apply to the whole path.<tab><tab># In any other cases just the basename is used.<tab><tab>match = path if item.startswith(""/"") else basename<tab><tab>if fnmatch.fnmatch(match, item.strip(""/"")):<tab><tab><tab>return True<tab>return False",0,"if item . endswith ( ""/"" ) and not is_dir :","if is_dir and item . startswith ( ""/"" ) :",0.2355441302737843,38.84637341996162,0.27472527472527475
"def reposition_division(f1):<tab>lines = f1.splitlines()<tab>if lines[2] == division:<tab><tab>lines.pop(2)<tab>found = 0<tab>for i, line in enumerate(lines):<tab><tab>if line.startswith('""""""'):<tab><tab><tab>found += 1<tab><tab><tab>if found == 2:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break  # already in the right place<tab><tab><tab><tab>lines.insert(i + 1, """")<tab><tab><tab><tab>lines.insert(i + 2, division)<tab><tab><tab><tab>break<tab>return ""\n"".join(lines)",0,"if division in ""\n"" . join ( lines ) :",if i + 1 == len ( lines ) :,0.20588377191557825,20.684088400488974,0.3333333333333333
"def buildImage(opt):<tab>dpath = os.path.join(opt[""datapath""], ""COCO-IMG-2015"")<tab>version = ""1""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building image data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES[:1]:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100.00000000000004,1.0
"def colorformat(text):<tab>if text[0:1] == ""#"":<tab><tab>col = text[1:]<tab><tab><IF-STMT><tab><tab><tab>return col<tab><tab>elif len(col) == 3:<tab><tab><tab>return col[0] * 2 + col[1] * 2 + col[2] * 2<tab>elif text == """":<tab><tab>return """"<tab>assert False, ""wrong color format %r"" % text",0,if len ( col ) == 6 :,if len ( col ) == 2 :,0.605621305873661,75.06238537503395,0.6666666666666666
"def tree_print(tree):<tab>for key in tree:<tab><tab>print(key, end="" "")  # end=' ' prevents a newline character<tab><tab>tree_element = tree[key]  # multiple lookups is expensive, even amortized O(1)!<tab><tab>for subElem in tree_element:<tab><tab><tab>print("" -> "", subElem, end="" "")<tab><tab><tab><IF-STMT>  # OP wants indenting after digits<tab><tab><tab><tab>print(""\n "")  # newline and a space to match indenting<tab><tab>print()  # forces a newline",0,if type ( subElem ) != str :,"if subElem == ""\n"" :",0.019907917998500824,6.742555929751843,0.36
"def is_dse_cluster(path):<tab>try:<tab><tab>with open(os.path.join(path, ""CURRENT""), ""r"") as f:<tab><tab><tab>name = f.readline().strip()<tab><tab><tab>cluster_path = os.path.join(path, name)<tab><tab><tab>filename = os.path.join(cluster_path, ""cluster.conf"")<tab><tab><tab>with open(filename, ""r"") as f:<tab><tab><tab><tab>data = yaml.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>except IOError:<tab><tab>return False",0,"if ""dse_dir"" in data :","if data [ ""name"" ] == ""dse"" :",0.028001459970687266,8.130850857597444,0.4772727272727273
"def delete_old_target_output_files(classpath_prefix):<tab>""""""Delete existing output files or symlinks for target.""""""<tab>directory, basename = os.path.split(classpath_prefix)<tab>pattern = re.compile(<tab><tab>r""^{basename}(([0-9]+)(\.jar)?|classpath\.txt)$"".format(<tab><tab><tab>basename=re.escape(basename)<tab><tab>)<tab>)<tab>files = [filename for filename in os.listdir(directory) if pattern.match(filename)]<tab>for rel_path in files:<tab><tab>path = os.path.join(directory, rel_path)<tab><tab><IF-STMT><tab><tab><tab>safe_delete(path)",0,if os . path . islink ( path ) or os . path . isfile ( path ) :,if os . path . isfile ( path ) :,0.4171984521463991,40.656965974059936,0.4451345755693582
"def test_files(self):<tab># get names of files to test<tab>dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)<tab>names = []<tab>for d in self.test_directories:<tab><tab>test_dir = os.path.join(dist_dir, d)<tab><tab>for n in os.listdir(test_dir):<tab><tab><tab>if n.endswith("".py"") and not n.startswith(""bad""):<tab><tab><tab><tab>names.append(os.path.join(test_dir, n))<tab>for filename in names:<tab><tab><IF-STMT><tab><tab><tab>print(""Testing %s"" % filename)<tab><tab>source = read_pyfile(filename)<tab><tab>self.check_roundtrip(source)",0,if test_support . verbose :,"if filename . endswith ( "".py"" ) :",0.028001459970687266,4.9323515694897075,0.38181818181818183
"def __str__(self):<tab>if self.HasError():<tab><tab>return self.ErrorAsStr()<tab>else:<tab><tab># Format is: {action} ""{target}"" ({filename}:{lineno})<tab><tab>string = self._action<tab><tab>if self._target is not None:<tab><tab><tab>string += ' ""{target}""'.format(target=self._target)<tab><tab><IF-STMT><tab><tab><tab>path = self._filename<tab><tab><tab>if self._lineno is not None:<tab><tab><tab><tab>path += "":{lineno}"".format(lineno=self._lineno)<tab><tab><tab>string += "" ({path})"".format(path=path)<tab><tab>return string",1,if self . _filename is not None :,if self . _filename is not None :,0.75,100.00000000000004,1.0
"def extra_action_out(self, input_dict, state_batches, model, action_dist):<tab>with self._no_grad_context():<tab><tab><IF-STMT><tab><tab><tab>stats_dict = extra_action_out_fn(<tab><tab><tab><tab>self, input_dict, state_batches, model, action_dist<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>stats_dict = parent_cls.extra_action_out(<tab><tab><tab><tab>self, input_dict, state_batches, model, action_dist<tab><tab><tab>)<tab><tab>return self._convert_to_non_torch_type(stats_dict)",1,if extra_action_out_fn :,if extra_action_out_fn :,0.5311706625951745,1e-10,1.0
"def _retract_bindings(fstruct, inv_bindings, fs_class, visited):<tab># Visit each node only once:<tab>if id(fstruct) in visited:<tab><tab>return<tab>visited.add(id(fstruct))<tab>if _is_mapping(fstruct):<tab><tab>items = fstruct.items()<tab>elif _is_sequence(fstruct):<tab><tab>items = enumerate(fstruct)<tab>else:<tab><tab>raise ValueError(""Expected mapping or sequence"")<tab>for (fname, fval) in items:<tab><tab>if isinstance(fval, fs_class):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fstruct[fname] = inv_bindings[id(fval)]<tab><tab><tab>_retract_bindings(fval, inv_bindings, fs_class, visited)",1,if id ( fval ) in inv_bindings :,if id ( fval ) in inv_bindings :,0.75,100.00000000000004,1.0
"def warehouses(self) -> tuple:<tab>from ..repositories import WarehouseBaseRepo<tab>repos = dict()<tab>for dep in chain(self.dependencies, [self]):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not isinstance(dep.repo, WarehouseBaseRepo):<tab><tab><tab>continue<tab><tab>for repo in dep.repo.repos:<tab><tab><tab>if repo.from_config:<tab><tab><tab><tab>continue<tab><tab><tab>repos[repo.name] = repo<tab>return tuple(repos.values())",1,if dep . repo is None :,if dep . repo is None :,0.75,100.00000000000004,1.0
"def detype(self):<tab>if self._detyped is not None:<tab><tab>return self._detyped<tab>ctx = {}<tab>for key, val in self._d.items():<tab><tab>if not isinstance(key, str):<tab><tab><tab>key = str(key)<tab><tab>detyper = self.get_detyper(key)<tab><tab><IF-STMT><tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>deval = detyper(val)<tab><tab>if deval is None:<tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>ctx[key] = deval<tab>self._detyped = ctx<tab>return ctx",1,if detyper is None :,if detyper is None :,0.75,100.00000000000004,1.0
"def populate_obj(self, obj, name):<tab>field = getattr(obj, name, None)<tab>if field is not None:<tab><tab># If field should be deleted, clean it up<tab><tab><IF-STMT><tab><tab><tab>field.delete()<tab><tab><tab>return<tab><tab>if isinstance(self.data, FileStorage) and not is_empty(self.data.stream):<tab><tab><tab>if not field.grid_id:<tab><tab><tab><tab>func = field.put<tab><tab><tab>else:<tab><tab><tab><tab>func = field.replace<tab><tab><tab>func(<tab><tab><tab><tab>self.data.stream,<tab><tab><tab><tab>filename=self.data.filename,<tab><tab><tab><tab>content_type=self.data.content_type,<tab><tab><tab>)",0,if self . _should_delete :,if self . data . deleted :,0.2005939911646859,22.772101321113862,0.55
"def _load(container):<tab>if isinstance(container, str):<tab><tab># If container is a filename.<tab><tab><IF-STMT><tab><tab><tab>with open(container, ""rb"") as f:<tab><tab><tab><tab>return pickle.load(f)<tab><tab># If container is a pickle string.<tab><tab>else:<tab><tab><tab>return pickle.loads(container)<tab># If container is an open file<tab>elif isinstance(container, IOBase):<tab><tab>return pickle.load(container)<tab># What else could it be?<tab>else:<tab><tab>l.error(""Cannot unpickle container of type %s"", type(container))<tab><tab>return None",0,if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,if os . path . isfile ( container ) :,0.17420930662398432,14.746212096418224,0.11538461538461539
"def append_row(self, row):<tab>self.allocate_future_payments(row)<tab>self.set_invoice_details(row)<tab>self.set_party_details(row)<tab>self.set_ageing(row)<tab>if self.filters.get(""group_by_party""):<tab><tab>self.update_sub_total_row(row, row.party)<tab><tab><IF-STMT><tab><tab><tab>self.append_subtotal_row(self.previous_party)<tab><tab>self.previous_party = row.party<tab>self.data.append(row)",0,if self . previous_party and ( self . previous_party != row . party ) :,if self . previous_party :,0.10712127205835761,13.127910466261701,0.41414141414141414
"def gg1():<tab>while 1:<tab><tab>tt = 3<tab><tab>while tt > 0:<tab><tab><tab>trace.append(tt)<tab><tab><tab>val = yield<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tt = 10  # <= uncomment this line<tab><tab><tab><tab>trace.append(""breaking early..."")<tab><tab><tab><tab>break<tab><tab><tab>tt -= 1<tab><tab>trace.append(""try!"")",1,if val is not None :,if val is not None :,0.75,100.00000000000004,1.0
"def migrate_common_facts(facts):<tab>""""""Migrate facts from various roles into common""""""<tab>params = {""node"": (""portal_net""), ""master"": (""portal_net"")}<tab>if ""common"" not in facts:<tab><tab>facts[""common""] = {}<tab># pylint: disable=consider-iterating-dictionary<tab>for role in params.keys():<tab><tab>if role in facts:<tab><tab><tab>for param in params[role]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>facts[""common""][param] = facts[role].pop(param)<tab>return facts",1,if param in facts [ role ] :,if param in facts [ role ] :,0.75,100.00000000000004,1.0
"def get_measurements(self, pipeline, object_name, category):<tab>if self.get_categories(pipeline, object_name) == [category]:<tab><tab>results = []<tab><tab><IF-STMT><tab><tab><tab>if object_name == ""Image"":<tab><tab><tab><tab>results += [""Correlation"", ""Slope""]<tab><tab><tab>else:<tab><tab><tab><tab>results += [""Correlation""]<tab><tab>if self.do_overlap:<tab><tab><tab>results += [""Overlap"", ""K""]<tab><tab>if self.do_manders:<tab><tab><tab>results += [""Manders""]<tab><tab>if self.do_rwc:<tab><tab><tab>results += [""RWC""]<tab><tab>if self.do_costes:<tab><tab><tab>results += [""Costes""]<tab><tab>return results<tab>return []",0,if self . do_corr_and_slope :,if self . do_correlation :,0.39477865547525276,36.337289265247364,1.0
"def access_modes(self):<tab>""""""access_modes property""""""<tab>if self._access_modes is None:<tab><tab>self._access_modes = self.get_access_modes()<tab><tab><IF-STMT><tab><tab><tab>self._access_modes = list(self._access_modes)<tab>return self._access_modes",0,"if not isinstance ( self . _access_modes , list ) :","if isinstance ( self . _access_modes , list ) :",0.4074990052689752,86.17038791239612,0.32051282051282054
"def unwrap_envelope(self, data, many):<tab>if many:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(data, InstrumentedList) or isinstance(data, list):<tab><tab><tab><tab>self.context[""total""] = len(data)<tab><tab><tab><tab>return data<tab><tab><tab>else:<tab><tab><tab><tab>self.context[""total""] = data[""total""]<tab><tab>else:<tab><tab><tab>self.context[""total""] = 0<tab><tab><tab>data = {""items"": []}<tab><tab>return data[""items""]<tab>return data",0,"if data [ ""items"" ] :","if ""total"" in data :",0.029084142862704995,8.513058489093439,0.4642857142857143
"def to_string(self, fmt=""{:.4f}""):<tab>result_str = """"<tab>for key in self.measures:<tab><tab>result = self.m_dict[key][0]()<tab><tab>result_str += (<tab><tab><tab>"","".join(fmt.format(x) for x in result)<tab><tab><tab><IF-STMT><tab><tab><tab>else fmt.format(result)<tab><tab>)<tab><tab>result_str += "",""<tab>return result_str[:-1]  # trim the last comma",0,"if isinstance ( result , tuple )","if isinstance ( result , list )",0.574113272471593,64.34588841607616,0.6666666666666666
"def on_torrent_created(self, result):<tab>if not result:<tab><tab>return<tab>self.dialog_widget.btn_create.setEnabled(True)<tab>self.dialog_widget.edit_channel_create_torrent_progress_label.setText(<tab><tab>""Created torrent""<tab>)<tab>if ""torrent"" in result:<tab><tab>self.create_torrent_notification.emit({""msg"": ""Torrent successfully created""})<tab><tab><IF-STMT><tab><tab><tab>self.add_torrent_to_channel(result[""torrent""])<tab><tab>self.close_dialog()",0,if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,"elif ""torrent"" in result :",0.008406657794468862,1.18271569172795,0.14285714285714285
"def save(self):<tab>for var_name in self.default_config:<tab><tab><IF-STMT><tab><tab><tab>if var_name in self.file_config:<tab><tab><tab><tab>del self.file_config[var_name]<tab><tab>else:<tab><tab><tab>self.file_config[var_name] = getattr(self, var_name)<tab>with open(self.config_path, ""w"") as f:<tab><tab>f.write(json.dumps(self.file_config, indent=2))",0,"if getattr ( self , var_name , None ) == self . default_config [ var_name ] :","if not hasattr ( self , var_name ) :",0.07900377329321838,15.673284956309823,0.27999999999999997
"def get_class_parameters(kwarg):<tab>ret = {""attrs"": []}<tab>for key in (""rsc"", ""fsc"", ""usc""):<tab><tab><IF-STMT><tab><tab><tab>ret[""attrs""].append(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>""TCA_HFSC_%s"" % key.upper(),<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""m1"": get_rate(kwarg[key].get(""m1"", 0)),<tab><tab><tab><tab><tab><tab>""d"": get_time(kwarg[key].get(""d"", 0)),<tab><tab><tab><tab><tab><tab>""m2"": get_rate(kwarg[key].get(""m2"", 0)),<tab><tab><tab><tab><tab>},<tab><tab><tab><tab>]<tab><tab><tab>)<tab>return ret",1,if key in kwarg :,if key in kwarg :,0.75,100.00000000000004,1.0
"def forward(self, x):<tab>f_x = x<tab>if self.exp:<tab><tab>f_x = self.exp_swish(self.exp_bn(self.exp(f_x)))<tab>f_x = self.dwise_swish(self.dwise_bn(self.dwise(f_x)))<tab>f_x = self.se(f_x)<tab>f_x = self.lin_proj_bn(self.lin_proj(f_x))<tab>if self.has_skip:<tab><tab><IF-STMT><tab><tab><tab>f_x = drop_connect(f_x, effnet_cfg.EN.DC_RATIO)<tab><tab>f_x = x + f_x<tab>return f_x",0,if self . training and effnet_cfg . EN . DC_RATIO > 0.0 :,if self . use_deterministically :,0.0651732786244846,6.656592803413299,0.47368421052631576
"def cli_uninstall_distro():<tab>distro_list = install_distro_list()<tab>if distro_list is not None:<tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab>log(str(index) + ""  --->>  "" + _distro_dir)<tab><tab>user_input = read_input_uninstall()<tab><tab>if user_input is not False:<tab><tab><tab>for index, _distro_dir in enumerate(distro_list):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>config.uninstall_distro_dir_name = _distro_dir<tab><tab><tab><tab><tab>unin_distro()<tab>else:<tab><tab>log(""No distro installed on "" + config.usb_disk)",0,if index == user_input :,if user_input == _distro_dir :,0.28849878646896243,19.081654556856684,0.6190476190476191
"def IMPORTFROM(self, node):<tab>if node.module == ""__future__"":<tab><tab><IF-STMT><tab><tab><tab>self.report(messages.LateFutureImport, node, [n.name for n in node.names])<tab>else:<tab><tab>self.futuresAllowed = False<tab>for alias in node.names:<tab><tab>if alias.name == ""*"":<tab><tab><tab>self.scope.importStarred = True<tab><tab><tab>self.report(messages.ImportStarUsed, node, node.module)<tab><tab><tab>continue<tab><tab>name = alias.asname or alias.name<tab><tab>importation = Importation(name, node)<tab><tab>if node.module == ""__future__"":<tab><tab><tab>importation.used = (self.scope, node)<tab><tab>self.addBinding(node, importation)",0,if not self . futuresAllowed :,if self .uturesAllowed :,0.030644093425414395,20.80119537801062,0.3333333333333333
"def _split_and_load(batch, ctx_list):<tab>""""""Split data to 1 batch each device.""""""<tab>new_batch = []<tab>for _, data in enumerate(batch):<tab><tab><IF-STMT><tab><tab><tab>new_data = [x.as_in_context(ctx) for x, ctx in zip(data, ctx_list)]<tab><tab>else:<tab><tab><tab>new_data = [data.as_in_context(ctx_list[0])]<tab><tab>new_batch.append(new_data)<tab>return new_batch",0,"if isinstance ( data , ( list , tuple ) ) :","if isinstance ( data , tuple ) :",0.222424676858406,43.58579201328629,0.6555555555555556
"def wait_success(self, timeout=60 * 10):<tab>for i in range(timeout // 10):<tab><tab>time.sleep(10)<tab><tab>status = self.query_job()<tab><tab>print(""job {} status is {}"".format(self.job_id, status))<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if status and status in [<tab><tab><tab>StatusSet.CANCELED,<tab><tab><tab>StatusSet.TIMEOUT,<tab><tab><tab>StatusSet.FAILED,<tab><tab>]:<tab><tab><tab>return False<tab>return False",0,if status and status == StatusSet . SUCCESS :,if status :,0.024814632707681465,1e-10,0.37777777777777777
"def copy_tree(self, src_dir, dst_dir, skip_variables=False):<tab>for src_root, _, files in os.walk(src_dir):<tab><tab><IF-STMT><tab><tab><tab>rel_root = os.path.relpath(src_root, src_dir)<tab><tab>else:<tab><tab><tab>rel_root = """"<tab><tab>if skip_variables and rel_root.startswith(""variables""):<tab><tab><tab>continue<tab><tab>dst_root = os.path.join(dst_dir, rel_root)<tab><tab>if not os.path.exists(dst_root):<tab><tab><tab>os.makedirs(dst_root)<tab><tab>for f in files:<tab><tab><tab>shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",0,if src_root != src_dir :,"if src_root . endswith ( "".py"" ) :",0.04979441971690225,20.448007360218387,0.6410256410256411
"def _make_padded_shapes(self, dataset, decoders):<tab>padded_shapes = dataset.output_shapes<tab>for i, hparams_i in enumerate(self._hparams.datasets):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not hparams_i[""pad_to_max_seq_length""]:<tab><tab><tab>continue<tab><tab>text_and_id_shapes = MonoTextData._make_padded_text_and_id_shapes(<tab><tab><tab>dataset, hparams_i, decoders[i], self.text_name(i), self.text_id_name(i)<tab><tab>)<tab><tab>padded_shapes.update(text_and_id_shapes)<tab>return padded_shapes",0,"if not _is_text_data ( hparams_i [ ""data_type"" ] ) :","if ""pad_to_max_seq_length"" not in hparams_i :",0.015568334202127164,9.570392090740222,0.7333333333333334
"def format_errors(messages):<tab>errors = {}<tab>for k, v in messages.items():<tab><tab>key = camelize(k, uppercase_first_letter=False)<tab><tab><IF-STMT><tab><tab><tab>errors[key] = format_errors(v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>errors[key] = v[0]<tab>return errors",1,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,100.00000000000004,1.0
"def generic_visit(self, node, parents=None):<tab>parents = (parents or []) + [node]<tab>for field, value in iter_fields(node):<tab><tab><IF-STMT><tab><tab><tab>for item in value:<tab><tab><tab><tab>if isinstance(item, AST):<tab><tab><tab><tab><tab>self.visit(item, parents)<tab><tab>elif isinstance(value, AST):<tab><tab><tab>self.visit(value, parents)",1,"if isinstance ( value , list ) :","if isinstance ( value , list ) :",0.75,100.00000000000004,1.0
"def get_override_css(self):<tab>""""""handls allow_css_overrides setting.""""""<tab>if self.settings.get(""allow_css_overrides""):<tab><tab>filename = self.view.file_name()<tab><tab>filetypes = self.settings.get(""markdown_filetypes"")<tab><tab>if filename and filetypes:<tab><tab><tab>for filetype in filetypes:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>css_filename = filename.rpartition(filetype)[0] + "".css""<tab><tab><tab><tab><tab>if os.path.isfile(css_filename):<tab><tab><tab><tab><tab><tab>return u""<style>%s</style>"" % load_utf8(css_filename)<tab>return """"",1,if filename . endswith ( filetype ) :,if filename . endswith ( filetype ) :,0.75,100.00000000000004,1.0
"def clean(self):<tab>super().clean()<tab># If the Cluster is assigned to a Site, all Devices must be assigned to that Site.<tab>if self.cluster.site is not None:<tab><tab>for device in self.cleaned_data.get(""devices"", []):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""devices"": ""{} belongs to a different site ({}) than the cluster ({})"".format(<tab><tab><tab><tab><tab><tab><tab>device, device.site, self.cluster.site<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>}<tab><tab><tab><tab>)",1,if device . site != self . cluster . site :,if device . site != self . cluster . site :,1.0,100.00000000000004,1.0
"def _setProcessPriority(process, nice_val, disable_gc):<tab>org_nice_val = Computer._process_original_nice_value<tab>try:<tab><tab>process.nice(nice_val)<tab><tab>Computer.in_high_priority_mode = nice_val != org_nice_val<tab><tab><IF-STMT><tab><tab><tab>gc.disable()<tab><tab>else:<tab><tab><tab>gc.enable()<tab><tab>return True<tab>except psutil.AccessDenied:<tab><tab>print2err(<tab><tab><tab>""WARNING: Could not set process {} priority ""<tab><tab><tab>""to {}"".format(process.pid, nice_val)<tab><tab>)<tab><tab>return False",1,if disable_gc :,if disable_gc :,0.5311706625951745,1e-10,1.0
"def _setResultsName(self, name, listAllMatches=False):<tab>if __diag__.warn_multiple_tokens_in_named_alternation:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""{}: setting results name {!r} on {} expression ""<tab><tab><tab><tab>""may only return a single token for an And alternative, ""<tab><tab><tab><tab>""in future will return the full list of tokens"".format(<tab><tab><tab><tab><tab>""warn_multiple_tokens_in_named_alternation"",<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>type(self).__name__,<tab><tab><tab><tab>),<tab><tab><tab><tab>stacklevel=3,<tab><tab><tab>)<tab>return super()._setResultsName(name, listAllMatches)",0,"if any ( isinstance ( e , And ) for e in self . exprs ) :","if name in [ ""and"" , ""alternative"" ] :",0.007877340902708075,3.211527255344238,0.1515151515151515
"def make_sources(project: RootDependency) -> str:<tab>content = []<tab>if project.readme:<tab><tab>content.append(project.readme.path.name)<tab><tab>if project.readme.markup != ""rst"":<tab><tab><tab>content.append(project.readme.to_rst().path.name)<tab>path = project.package.path<tab>for fname in (""setup.cfg"", ""setup.py""):<tab><tab><IF-STMT><tab><tab><tab>content.append(fname)<tab>for package in chain(project.package.packages, project.package.data):<tab><tab>for fpath in package:<tab><tab><tab>fpath = fpath.relative_to(project.package.path)<tab><tab><tab>content.append(""/"".join(fpath.parts))<tab>return ""\n"".join(content)",0,if ( path / fname ) . exists ( ) :,if fname . startswith ( path ) :,0.033212016042168675,12.347293198886947,0.3333333333333333
"def findControlPointsInMesh(glyph, va, subsegments):<tab>controlPointIndices = np.zeros((len(va), 1))<tab>index = 0<tab>for i, c in enumerate(subsegments):<tab><tab>segmentCount = len(glyph.contours[i].segments) - 1<tab><tab>for j, s in enumerate(c):<tab><tab><tab>if j < segmentCount:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>controlPointIndices[index] = 1<tab><tab><tab>index += s[1]<tab>return controlPointIndices",0,"if glyph . contours [ i ] . segments [ j ] . type == ""line"" :",if s [ 0 ] == va :,0.008095673467752225,3.696711021882758,0.16996047430830039
"def MergeFrom(self, other):<tab>if self.message_class is not None:<tab><tab>if other.Parse(self.message_class):<tab><tab><tab>self.message.MergeFrom(other.message)<tab>elif other.message_class is not None:<tab><tab><IF-STMT><tab><tab><tab>self.message = other.message_class()<tab><tab><tab>self.message_class = other.message_class<tab><tab>self.message.MergeFrom(other.message)<tab>else:<tab><tab>self.message += other.message",0,if not self . Parse ( other . message_class ) :,if not self . message :,0.1873544696225729,18.817320787862926,0.5604395604395604
"def remove_old_snapshot(install_dir):<tab>logging.info(""Removing any old files in {}"".format(install_dir))<tab>for file in glob.glob(""{}/*"".format(install_dir)):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.unlink(file)<tab><tab><tab>elif os.path.isdir(file):<tab><tab><tab><tab>shutil.rmtree(file)<tab><tab>except Exception as error:<tab><tab><tab>logging.error(""Error: {}"".format(error))<tab><tab><tab>sys.exit(1)",1,if os . path . isfile ( file ) :,if os . path . isfile ( file ) :,0.75,100.00000000000004,1.0
"def writexml(<tab>self,<tab>stream,<tab>indent="""",<tab>addindent="""",<tab>newl="""",<tab>strip=0,<tab>nsprefixes={},<tab>namespace="""",):<tab>w = _streamWriteWrapper(stream)<tab>if self.raw:<tab><tab>val = self.nodeValue<tab><tab>if not isinstance(val, str):<tab><tab><tab>val = str(self.nodeValue)<tab>else:<tab><tab>v = self.nodeValue<tab><tab>if not isinstance(v, str):<tab><tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>v = "" "".join(v.split())<tab><tab>val = escape(v)<tab>w(val)",0,if strip :,"if isinstance ( v , str ) :",0.04422835593777517,1e-10,0.3
"def validate_attributes(self):<tab>for attribute in self.get_all_attributes():<tab><tab>value = getattr(self, attribute.code, None)<tab><tab><IF-STMT><tab><tab><tab>if attribute.required:<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute cannot be blank"") % {""attr"": attribute.code}<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>attribute.validate_value(value)<tab><tab><tab>except ValidationError as e:<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(""%(attr)s attribute %(err)s"") % {""attr"": attribute.code, ""err"": e}<tab><tab><tab><tab>)",1,if value is None :,if value is None :,0.75,100.00000000000004,1.0
"def PyJsHoisted_BinaryExpression_(node, parent, this, arguments, var=var):<tab>var = Scope(<tab><tab>{u""node"": node, u""this"": this, u""arguments"": arguments, u""parent"": parent}, var<tab>)<tab>var.registers([u""node"", u""parent""])<tab>if PyJsStrictEq(var.get(u""node"").get(u""operator""), Js(u""in"")):<tab><tab><IF-STMT><tab><tab><tab>return var.get(u""true"")<tab><tab>if var.get(u""t"").callprop(u""isFor"", var.get(u""parent"")):<tab><tab><tab>return var.get(u""true"")<tab>return Js(False)",0,"if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :","if var . get ( u""t"" ) . callprop ( u""isFor"" , var . get ( u""parent"" ) ) :",0.9294152013155808,90.61874434879648,1.0
"def distinct(expr, *on):<tab>fields = frozenset(expr.fields)<tab>_on = []<tab>append = _on.append<tab>for n in on:<tab><tab>if isinstance(n, Field):<tab><tab><tab>if n._child.isidentical(expr):<tab><tab><tab><tab>n = n._name<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""on must be a name or field, not: {0}"".format(n))<tab><tab>elif n not in fields:<tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>append(n)<tab>return Distinct(expr, tuple(_on))",0,"if not isinstance ( n , _strtypes ) :",elif n not in fields :,0.015343964665956476,5.484411595600381,0.1111111111111111
"def encode(self, msg):<tab>""""""Encodes the message to the stream encoding.""""""<tab>stream = self.stream<tab>rv = msg + ""\n""<tab>if (PY2 and is_unicode(rv)) or not (<tab><tab>PY2 or is_unicode(rv) or _is_text_stream(stream)<tab>):<tab><tab>enc = self.encoding<tab><tab><IF-STMT><tab><tab><tab>enc = getattr(stream, ""encoding"", None) or ""utf-8""<tab><tab>rv = rv.encode(enc, ""replace"")<tab>return rv",0,if enc is None :,if not enc :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def color_convert(self, to_color_space, preserve_alpha=True):<tab>if to_color_space == self.color_space and preserve_alpha:<tab><tab>return self<tab>else:<tab><tab>pixels = pixels_as_float(self.pixels)<tab><tab>converted = convert_color(<tab><tab><tab>pixels, self.color_space, to_color_space, preserve_alpha<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return Image(converted, to_color_space)",1,if converted is None :,if converted is None :,0.75,100.00000000000004,1.0
"def seek(self, pos):<tab>if self.closed:<tab><tab>raise IOError(""Cannot seek on a closed file"")<tab>for n, idx in enumerate(self._indexes[::-1]):<tab><tab>if idx.offset <= pos:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._idxiter = iter(self._indexes[-(n + 1) :])<tab><tab><tab><tab>self._nextidx()<tab><tab><tab>break<tab>else:<tab><tab>raise Exception(""Cannot seek to pos"")<tab>self._curfile.seek(pos - self._curidx.offset)",0,if idx != self . _curidx :,if n < len ( self . _indexes ) - 1 :,0.03276719556548166,13.065113298388567,0.26785714285714285
"def load_from_json(self, node_data: dict, import_version: float):<tab>if import_version <= 0.08:<tab><tab>self.image_pointer = unpack_pointer_property_name(<tab><tab><tab>bpy.data.images, node_data, ""image_name""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>proposed_name = node_data.get(""image_name"")<tab><tab><tab>self.info(f""image data not found in current {proposed_name}"")",0,if not self . image_pointer :,if self . image_pointer is not None :,0.10094060174500757,44.17918226831576,0.2916666666666667
"def __init__(self, execution_context, aggregate_operators):<tab>super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context)<tab>self._local_aggregators = []<tab>self._results = None<tab>self._result_index = 0<tab>for operator in aggregate_operators:<tab><tab>if operator == ""Average"":<tab><tab><tab>self._local_aggregators.append(_AverageAggregator())<tab><tab><IF-STMT><tab><tab><tab>self._local_aggregators.append(_CountAggregator())<tab><tab>elif operator == ""Max"":<tab><tab><tab>self._local_aggregators.append(_MaxAggregator())<tab><tab>elif operator == ""Min"":<tab><tab><tab>self._local_aggregators.append(_MinAggregator())<tab><tab>elif operator == ""Sum"":<tab><tab><tab>self._local_aggregators.append(_SumAggregator())",1,"elif operator == ""Count"" :","elif operator == ""Count"" :",1.0,100.00000000000004,1.0
"def attrgetter(item):<tab>items = [None] * len(attribute)<tab>for i, attribute_part in enumerate(attribute):<tab><tab>item_i = item<tab><tab>for part in attribute_part:<tab><tab><tab>item_i = environment.getitem(item_i, part)<tab><tab><IF-STMT><tab><tab><tab>item_i = postprocess(item_i)<tab><tab>items[i] = item_i<tab>return items",0,if postprocess is not None :,if postprocess :,0.050438393472541504,1e-10,0.39999999999999997
"def work(self):<tab>while True:<tab><tab>timeout = self.timeout<tab><tab><IF-STMT><tab><tab><tab>timeout = self.idle_timeout<tab><tab>log.debug(""Wait for {}"".format(timeout))<tab><tab>fetch.wait(timeout)<tab><tab>if shutting_down.is_set():<tab><tab><tab>log.info(""Stop fetch worker"")<tab><tab><tab>break<tab><tab>self.fetch()",0,if idle . is_set ( ) :,if self . idle_timeout is not None :,0.021135835738089467,6.567274736060395,0.23809523809523808
"def testCoreInterfaceIntInputData():<tab>result_testing = False<tab>for _ in range(10):<tab><tab>hsyncnet_instance = hsyncnet(<tab><tab><tab>[[1], [2], [3], [20], [21], [22]], 2, initial_type.EQUIPARTITION, ccore=True<tab><tab>)<tab><tab>analyser = hsyncnet_instance.process()<tab><tab><IF-STMT><tab><tab><tab>result_testing = True<tab><tab><tab>break<tab>assert result_testing",0,if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,if analyser == initial_type . EQUIPARTITION :,0.011531715363016518,6.299668402986177,0.3245614035087719
"def _gen():<tab>buf = []<tab>iterable = dataset()<tab>try:<tab><tab>while len(buf) < buffer_size:<tab><tab><tab>buf.append(next(iterable))<tab><tab>while 1:<tab><tab><tab>i = random.randint(0, buffer_size - 1)<tab><tab><tab>n = next(iterable)<tab><tab><tab>yield buf[i]<tab><tab><tab>buf[i] = n<tab>except StopIteration:<tab><tab><IF-STMT><tab><tab><tab>random.shuffle(buf)<tab><tab><tab>for i in buf:<tab><tab><tab><tab>yield i",0,if len ( buf ) :,if shuffle :,0.026485502076288185,1e-10,0.37142857142857144
"def debug_tree(tree):<tab>l = []<tab>for elt in tree:<tab><tab>if isinstance(elt, (int, long)):<tab><tab><tab>l.append(_names.get(elt, elt))<tab><tab><IF-STMT><tab><tab><tab>l.append(elt)<tab><tab>else:<tab><tab><tab>l.append(debug_tree(elt))<tab>return l",1,"elif isinstance ( elt , str ) :","elif isinstance ( elt , str ) :",0.75,100.00000000000004,1.0
"def reverse_code(apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None:<tab>PreregistrationUser = apps.get_model(""zerver"", ""PreregistrationUser"")<tab>for user in PreregistrationUser.objects.all():<tab><tab><IF-STMT>  # PreregistrationUser.INVITE_AS['REALM_ADMIN']<tab><tab><tab>user.invited_as_admin = True<tab><tab>else:  # PreregistrationUser.INVITE_AS['MEMBER']<tab><tab><tab>user.invited_as_admin = False<tab><tab>user.save(update_fields=[""invited_as_admin""])",0,if user . invited_as == 2 :,if user . invited_as_admin :,0.09453229110448028,54.627576446464936,0.7222222222222222
"def _fastqc_data_section(self, section_name):<tab>out = []<tab>in_section = False<tab>data_file = os.path.join(self._dir, ""fastqc_data.txt"")<tab>if os.path.exists(data_file):<tab><tab>with open(data_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab>if line.startswith("">>%s"" % section_name):<tab><tab><tab><tab><tab>in_section = True<tab><tab><tab><tab>elif in_section:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>out.append(line.rstrip(""\r\n""))<tab>return out",0,"if line . startswith ( "">>END"" ) :",if not line :,0.019930835999227993,2.845073863275343,0.4
"def determine_block_hints(self, text):<tab>hints = """"<tab>if text:<tab><tab>if text[0] in "" \n\x85\u2028\u2029"":<tab><tab><tab>hints += str(self.best_indent)<tab><tab><IF-STMT><tab><tab><tab>hints += ""-""<tab><tab>elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""+""<tab>return hints",0,"if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :","elif text [ 0 ] in "" \n\x85\u2028\u2029"" :",0.027163948451459488,64.87662298067647,0.23863636363636365
"def database_app(request):<tab>if request.param == ""postgres_app"":<tab><tab>if not which(""initdb""):<tab><tab><tab>pytest.skip(""initdb must be on PATH for postgresql fixture"")<tab><tab>if not psycopg2:<tab><tab><tab>pytest.skip(""psycopg2 must be installed for postgresql fixture"")<tab>if request.param == ""sqlite_rabbitmq_app"":<tab><tab><IF-STMT><tab><tab><tab>pytest.skip(<tab><tab><tab><tab>""rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset""<tab><tab><tab>)<tab>return request.getfixturevalue(request.param)",0,"if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :",if settings . GALAXY_TEST_AMQP_INTERNAL_CONNECTION is not None :,0.014083696926176809,41.141770231182534,0.2222222222222222
"def do_rollout(agent, env, num_steps, render=False):<tab>total_rew = 0<tab>ob = env.reset()<tab>for t in range(num_steps):<tab><tab>a = agent.act(ob)<tab><tab>(ob, reward, done, _info) = env.step(a)<tab><tab>total_rew += reward<tab><tab><IF-STMT><tab><tab><tab>env.render()<tab><tab>if done:<tab><tab><tab>break<tab>return total_rew, t + 1",0,if render and t % 3 == 0 :,if render :,0.024814632707681465,1e-10,0.37142857142857144
"def _handle_subrepos(self, ctx, dirty_trees):<tab>substate = util.parse_hgsubstate(ctx["".hgsubstate""].data().splitlines())<tab>sub = util.OrderedDict()<tab>if "".hgsub"" in ctx:<tab><tab>sub = util.parse_hgsub(ctx["".hgsub""].data().splitlines())<tab>for path, sha in substate.iteritems():<tab><tab># Ignore non-Git repositories keeping state in .hgsubstate.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d = os.path.dirname(path)<tab><tab>dirty_trees.add(d)<tab><tab>tree = self._dirs.setdefault(d, dulobjs.Tree())<tab><tab>tree.add(os.path.basename(path), dulobjs.S_IFGITLINK, sha)",0,"if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :",if path in dirty_trees :,0.13742026297182128,4.101080379386836,0.42083333333333334
"def get_property_file_image_choices(self, pipeline):<tab>columns = pipeline.get_measurement_columns()<tab>image_names = []<tab>for column in columns:<tab><tab>object_name, feature, coltype = column[:3]<tab><tab>choice = feature[(len(C_FILE_NAME) + 1) :]<tab><tab><IF-STMT><tab><tab><tab>image_names.append(choice)<tab>return image_names",0,"if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :",if choice . startswith ( C_FILE_NAME ) :,0.21309271938308982,30.754858697597314,0.3253968253968254
"def check_all_decorator_order():<tab>""""""Check that in all test files, the slow decorator is always last.""""""<tab>errors = []<tab>for fname in os.listdir(PATH_TO_TESTS):<tab><tab><IF-STMT><tab><tab><tab>filename = os.path.join(PATH_TO_TESTS, fname)<tab><tab><tab>new_errors = check_decorator_order(filename)<tab><tab><tab>errors += [f""- {filename}, line {i}"" for i in new_errors]<tab>if len(errors) > 0:<tab><tab>msg = ""\n"".join(errors)<tab><tab>raise ValueError(<tab><tab><tab>f""The parameterized decorator (and its variants) should always be first, but this is not the case in the following files:\n{msg}""<tab><tab>)",1,"if fname . endswith ( "".py"" ) :","if fname . endswith ( "".py"" ) :",0.75,100.00000000000004,1.0
"def on_edit_button_clicked(self, event=None, a=None, col=None):<tab>tree, tree_id = self.treeView.get_selection().get_selected()<tab>watchdir_id = str(self.store.get_value(tree_id, 0))<tab>if watchdir_id:<tab><tab>if col and col.get_title() == _(""Active""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>client.autoadd.disable_watchdir(watchdir_id)<tab><tab><tab>else:<tab><tab><tab><tab>client.autoadd.enable_watchdir(watchdir_id)<tab><tab>else:<tab><tab><tab>self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)",0,"if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :",if client . autoadd . get_active ( watchdir_id ) :,0.06408603889837566,11.704569597597914,0.3333333333333333
"def get_conv_output_size(input_size, kernel_size, stride, padding, dilation):<tab>ndim = len(input_size)<tab>output_size = []<tab>for i in range(ndim):<tab><tab>size = (<tab><tab><tab>input_size[i] + 2 * padding[i] - dilation[i] * (kernel_size[i] - 1) - 1<tab><tab>) // stride[i] + 1<tab><tab><IF-STMT><tab><tab><tab>output_size.append(1)<tab><tab>else:<tab><tab><tab>output_size.append(size)<tab>return output_size",0,if kernel_size [ i ] == - 1 :,if size == 0 :,0.0168380461076173,7.509307647752128,0.3333333333333333
"def from_location(cls, location, basename, metadata=None, **kw):<tab>project_name, version, py_version, platform = [None] * 4<tab>basename, ext = os.path.splitext(basename)<tab>if ext.lower() in ("".egg"", "".egg-info""):<tab><tab>match = EGG_NAME(basename)<tab><tab><IF-STMT><tab><tab><tab>project_name, version, py_version, platform = match.group(<tab><tab><tab><tab>""name"", ""ver"", ""pyver"", ""plat""<tab><tab><tab>)<tab>return cls(<tab><tab>location,<tab><tab>metadata,<tab><tab>project_name=project_name,<tab><tab>version=version,<tab><tab>py_version=py_version,<tab><tab>platform=platform,<tab><tab>**kw<tab>)",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def __new__(metacls, typename, bases, namespace):<tab>annotations = namespace.get(""__annotations__"", {})<tab>for t in annotations.values():<tab><tab><IF-STMT><tab><tab><tab>for ut in t.__args__:<tab><tab><tab><tab>_assert_tensorizer_type(ut)<tab><tab>else:<tab><tab><tab>_assert_tensorizer_type(t)<tab>return super().__new__(metacls, typename, bases, namespace)",0,"if getattr ( t , ""__origin__"" , """" ) is Union :","if hasattr ( t , ""__args__"" ) :",0.05128988341246617,34.61976544419769,0.4107142857142857
"def decode_content(self):<tab>""""""Return the best possible representation of the response body.""""""<tab>ct = self.headers.get(""content-type"")<tab>if ct:<tab><tab>ct, options = parse_options_header(ct)<tab><tab>charset = options.get(""charset"")<tab><tab><IF-STMT><tab><tab><tab>return self.json(charset)<tab><tab>elif ct.startswith(""text/""):<tab><tab><tab>return self.text(charset)<tab><tab>elif ct == FORM_URL_ENCODED:<tab><tab><tab>return parse_qsl(self.content.decode(charset), keep_blank_values=True)<tab>return self.content",0,if ct in JSON_CONTENT_TYPES :,"if ct . startswith ( ""json/"" ) :",0.04979441971690225,8.29519350710986,0.6
"def get_full_path(path):<tab>if ""://"" not in path:<tab><tab>path = os.path.join(self.AUTO_COLL_TEMPL, path, """")<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(abs_path, path)<tab>return path",0,if abs_path :,if os . path . isabs ( path ) :,0.04224510045373539,1e-10,0.34285714285714286
"def __getitem__(self, name_or_path):<tab>if isinstance(name_or_path, integer_types):<tab><tab>return list.__getitem__(self, name_or_path)<tab>elif isinstance(name_or_path, tuple):<tab><tab>try:<tab><tab><tab>val = self<tab><tab><tab>for fid in name_or_path:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise KeyError  # path contains base value<tab><tab><tab><tab>val = val[fid]<tab><tab><tab>return val<tab><tab>except (KeyError, IndexError):<tab><tab><tab>raise KeyError(name_or_path)<tab>else:<tab><tab>raise TypeError(self._INDEX_ERROR % name_or_path)",0,"if not isinstance ( val , FeatStruct ) :",if fid not in val :,0.017951424116240698,6.962210312500384,0.25
"def scan(scope):<tab>for s in scope.children:<tab><tab>if s.start_pos <= position <= s.end_pos:<tab><tab><tab>if isinstance(s, (tree.Scope, tree.Flow)):<tab><tab><tab><tab>return scan(s) or s<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return scan(s)<tab>return None",0,"elif s . type in ( ""suite"" , ""decorated"" ) :","elif isinstance ( s , tree . Scope ) :",0.0988692277563085,6.962210312500384,0.2403846153846154
"def _get_key(self):<tab>if not self.key:<tab><tab>self._channel.send(u""pake"", self.msg1)<tab><tab>pake_msg = self._channel.get(u""pake"")<tab><tab>self.key = self.sp.finish(pake_msg)<tab><tab>self.verifier = self.derive_key(u""wormhole:verifier"")<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>confkey = self.derive_key(u""wormhole:confirmation"")<tab><tab>nonce = os.urandom(CONFMSG_NONCE_LENGTH)<tab><tab>confmsg = make_confmsg(confkey, nonce)<tab><tab>self._channel.send(u""_confirm"", confmsg)",0,if not self . _send_confirm :,if not self . verifier :,0.5212518808542342,32.58798048281462,0.76
"def executeScript(self, script):<tab>if len(script) > 0:<tab><tab>commands = []<tab><tab>for l in script:<tab><tab><tab>extracted = self.extract_command(l)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>commands.append(extracted)<tab><tab>for command in commands:<tab><tab><tab>cmd, argv = command<tab><tab><tab>self.dispatch_command(cmd, argv)",0,if extracted :,if extracted is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def create_path(n, fullname, meta):<tab>if meta:<tab><tab>meta.create_path(fullname)<tab>else:<tab><tab># These fallbacks are important -- meta could be null if, for<tab><tab># example, save created a ""fake"" item, i.e. a new strip/graft<tab><tab># path element, etc.  You can find cases like that by<tab><tab># searching for ""Metadata()"".<tab><tab>unlink(fullname)<tab><tab>if stat.S_ISDIR(n.mode):<tab><tab><tab>mkdirp(fullname)<tab><tab><IF-STMT><tab><tab><tab>os.symlink(n.readlink(), fullname)",0,elif stat . S_ISLNK ( n . mode ) :,elif stat . S_ISDIR ( n . mode ) :,0.5790185032381231,73.48889200874659,1.0
def get_cycle(self):<tab>if self.has_cycle():<tab><tab>cross_node = self.path[-1]<tab><tab><IF-STMT><tab><tab><tab>return self.path[self.path.index(cross_node) :]<tab><tab>else:<tab><tab><tab>return self.path<tab>return [],0,if self . path . count ( cross_node ) > 1 :,if cross_node in self . path :,0.05029410941621809,18.402097851927994,0.2761904761904762
"def _select_block(str_in, start_tag, end_tag):<tab>""""""Select first block delimited by start_tag and end_tag""""""<tab>start_pos = str_in.find(start_tag)<tab>if start_pos < 0:<tab><tab>raise ValueError(""start_tag not found"")<tab>depth = 0<tab>for pos in range(start_pos, len(str_in)):<tab><tab><IF-STMT><tab><tab><tab>depth += 1<tab><tab>elif str_in[pos] == end_tag:<tab><tab><tab>depth -= 1<tab><tab>if depth == 0:<tab><tab><tab>break<tab>sel = str_in[start_pos + 1 : pos]<tab>return sel",1,if str_in [ pos ] == start_tag :,if str_in [ pos ] == start_tag :,0.75,100.00000000000004,1.0
"def device(self):<tab>""""""Device on which the data array of this variable reside.""""""<tab># lazy initialization for performance<tab>if self._device is None:<tab><tab><IF-STMT><tab><tab><tab>self._device = backend.CpuDevice()<tab><tab>else:<tab><tab><tab>self._device = backend.get_device_from_array(self._data[0])<tab>return self._device",1,if self . _data [ 0 ] is None :,if self . _data [ 0 ] is None :,0.75,100.00000000000004,1.0
"def function_out(*args, **kwargs):<tab>try:<tab><tab>return function_in(*args, **kwargs)<tab>except dbus.exceptions.DBusException as e:<tab><tab>if e.get_dbus_name() == DBUS_UNKNOWN_METHOD:<tab><tab><tab>raise ItemNotFoundException(""Item does not exist!"")<tab><tab><IF-STMT><tab><tab><tab>raise ItemNotFoundException(e.get_dbus_message())<tab><tab>if e.get_dbus_name() in (DBUS_NO_REPLY, DBUS_NOT_SUPPORTED):<tab><tab><tab>raise SecretServiceNotAvailableException(e.get_dbus_message())<tab><tab>raise",0,if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT :,if e . get_dbus_name ( ) == DBUS_NOT_FOUND :,0.62709085524794,69.97150369717171,1.0
"def run(self):<tab>""""""Continual loop evaluating when_statements""""""<tab>while len(self.library) > 0:<tab><tab>for name, expression in self.library.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.library[name]<tab><tab><tab>else:<tab><tab><tab><tab>expression.evaluate()<tab><tab>sleep(0.01)<tab>return",0,if expression . remove_me == True :,"if isinstance ( expression , WhenStatement ) :",0.021135835738089467,5.660233915657916,0.3148148148148148
"def tamper(payload, **kwargs):<tab>junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`""<tab>retval = """"<tab>for i, char in enumerate(payload, start=1):<tab><tab>amount = random.randint(10, 15)<tab><tab><IF-STMT><tab><tab><tab>retval += "">""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == ""<"":<tab><tab><tab>retval += ""<""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == "" "":<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>else:<tab><tab><tab>retval += char<tab>return retval",1,"if char == "">"" :","if char == "">"" :",0.75,100.00000000000004,1.0
"def _source_target_path(source, source_path, source_location):<tab>target_path_attr = source.target_path or source.resdef.target_path<tab>if source.preserve_path:<tab><tab><IF-STMT><tab><tab><tab>log.warning(<tab><tab><tab><tab>""target-path '%s' specified with preserve-path - ignoring"",<tab><tab><tab><tab>target_path_attr,<tab><tab><tab>)<tab><tab>return os.path.relpath(os.path.dirname(source_path), source_location)<tab>else:<tab><tab>return target_path_attr or source.resdef.target_path or """"",0,if target_path_attr :,if target_path_attr != source_path :,0.09791453445388575,1e-10,1.0
"def _load_user_from_header(self, header):<tab>if self._header_callback:<tab><tab>user = self._header_callback(header)<tab><tab><IF-STMT><tab><tab><tab>app = current_app._get_current_object()<tab><tab><tab>user_loaded_from_header.send(app, user=user)<tab><tab><tab>return user<tab>return None",1,if user is not None :,if user is not None :,0.75,100.00000000000004,1.0
"def setup(cls):<tab>""Check dependencies and warn about firewalling""<tab>pathCheck(""brctl"", moduleName=""bridge-utils"")<tab># Disable Linux bridge firewalling so that traffic can flow!<tab>for table in ""arp"", ""ip"", ""ip6"":<tab><tab>cmd = ""sysctl net.bridge.bridge-nf-call-%stables"" % table<tab><tab>out = quietRun(cmd).strip()<tab><tab><IF-STMT><tab><tab><tab>warn(""Warning: Linux bridge may not work with"", out, ""\n"")",0,"if out . endswith ( ""1"" ) :",if out :,0.030705692522937138,1e-10,0.7272727272727273
"def _browse_your_music(web_client, variant):<tab>if not web_client.logged_in:<tab><tab>return []<tab>if variant in (""tracks"", ""albums""):<tab><tab>items = flatten(<tab><tab><tab>[<tab><tab><tab><tab>page.get(""items"", [])<tab><tab><tab><tab>for page in web_client.get_all(<tab><tab><tab><tab><tab>f""me/{variant}"",<tab><tab><tab><tab><tab>params={""market"": ""from_token"", ""limit"": 50},<tab><tab><tab><tab>)<tab><tab><tab><tab>if page<tab><tab><tab>]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return list(translator.web_to_track_refs(items))<tab><tab>else:<tab><tab><tab>return list(translator.web_to_album_refs(items))<tab>else:<tab><tab>return []",1,"if variant == ""tracks"" :","if variant == ""tracks"" :",0.75,100.00000000000004,1.0
"def reset_styling(self):<tab>for edge in self.fsm_graph.edges_iter():<tab><tab>style_attr = self.fsm_graph.style_attributes.get(""edge"", {}).get(""default"")<tab><tab>edge.attr.update(style_attr)<tab>for node in self.fsm_graph.nodes_iter():<tab><tab><IF-STMT><tab><tab><tab>style_attr = self.fsm_graph.style_attributes.get(""node"", {}).get(""inactive"")<tab><tab><tab>node.attr.update(style_attr)<tab>for sub_graph in self.fsm_graph.subgraphs_iter():<tab><tab>style_attr = self.fsm_graph.style_attributes.get(""graph"", {}).get(""default"")<tab><tab>sub_graph.graph_attr.update(style_attr)",0,"if ""point"" not in node . attr [ ""shape"" ] :","if node . state == ""RUNNING"" :",0.060484466895781824,6.699007141691558,0.2653061224489796
"def set_message_type_visibility(self, message_type: MessageType):<tab>try:<tab><tab>rows = {<tab><tab><tab>i<tab><tab><tab>for i, msg in enumerate(self.proto_analyzer.messages)<tab><tab><tab><IF-STMT><tab><tab>}<tab><tab>if message_type.show:<tab><tab><tab>self.ui.tblViewProtocol.show_rows(rows)<tab><tab>else:<tab><tab><tab>self.ui.tblViewProtocol.hide_rows(rows)<tab>except Exception as e:<tab><tab>logger.exception(e)",0,if msg . message_type == message_type,"if isinstance ( msg , Message )",0.023878899402271555,4.410363736106611,0.35
"def POP(cpu, *regs):<tab>for reg in regs:<tab><tab>val = cpu.stack_pop(cpu.address_bit_size // 8)<tab><tab><IF-STMT><tab><tab><tab>cpu._set_mode_by_val(val)<tab><tab><tab>val = val & ~0x1<tab><tab>reg.write(val)",0,"if reg . reg in ( ""PC"" , ""R15"" ) :",if cpu . address_bit_size % 8 == 0 :,0.013411254602005974,3.479789360876994,0.2857142857142857
"def processMovie(self, atom):<tab>for field in atom:<tab><tab>if ""track"" in field:<tab><tab><tab>self.processTrack(field[""track""])<tab><tab><IF-STMT><tab><tab><tab>self.processMovieHeader(field[""movie_hdr""])",1,"if ""movie_hdr"" in field :","if ""movie_hdr"" in field :",0.75,100.00000000000004,1.0
"def check_update_function(url, folder, update_setter, version_setter, auto):<tab>remote_version = urllib.urlopen(url).read()<tab>if remote_version.isdigit():<tab><tab>local_version = get_local_timestamp(folder)<tab><tab><IF-STMT><tab><tab><tab>if auto:<tab><tab><tab><tab>update_setter.set_value(True)<tab><tab><tab>version_setter.set_value(remote_version)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return False",0,if remote_version > local_version :,if local_version != remote_version :,0.28849878646896243,33.031643180138055,1.0
"def init(self, view, items=None):<tab>selections = []<tab>if view.sel():<tab><tab>for region in view.sel():<tab><tab><tab>selections.append(view.substr(region))<tab>values = []<tab>for idx, index in enumerate(map(int, items)):<tab><tab>if idx >= len(selections):<tab><tab><tab>break<tab><tab>i = index - 1<tab><tab><IF-STMT><tab><tab><tab>values.append(selections[i])<tab><tab>else:<tab><tab><tab>values.append(None)<tab># fill up<tab>for idx, value in enumerate(selections):<tab><tab>if len(values) + 1 < idx:<tab><tab><tab>values.append(value)<tab>self.stack = values",0,if i >= 0 and i < len ( selections ) :,if i >= 0 :,0.13177909701988666,24.764986882297123,0.48299319727891155
"def find_int_identifiers(directory):<tab>results = find_rules(directory, has_int_identifier)<tab>print(""Number of rules with integer identifiers: %d"" % len(results))<tab>for result in results:<tab><tab>rule_path = result[0]<tab><tab>product_yaml_path = result[1]<tab><tab>product_yaml = None<tab><tab><IF-STMT><tab><tab><tab>product_yaml = yaml.open_raw(product_yaml_path)<tab><tab>fix_file(rule_path, product_yaml, fix_int_identifier)",1,if product_yaml_path is not None :,if product_yaml_path is not None :,0.75,100.00000000000004,1.0
"def condition(self):<tab>if self.__condition is None:<tab><tab>if len(self.flat_conditions) == 1:<tab><tab><tab># Avoid an extra indirection in the common case of only one condition.<tab><tab><tab>self.__condition = self.flat_conditions[0]<tab><tab><IF-STMT><tab><tab><tab># Possible, if unlikely, due to filter predicate rewriting<tab><tab><tab>self.__condition = lambda _: True<tab><tab>else:<tab><tab><tab>self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions)<tab>return self.__condition",0,elif len ( self . flat_conditions ) == 0 :,"elif isinstance ( self . flat_conditions [ 0 ] , Condition ) :",0.24273515334809964,36.787632499277755,0.5630252100840336
"def get_scene_exceptions_by_season(self, season=-1):<tab>scene_exceptions = []<tab>for scene_exception in self.scene_exceptions:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>scene_name, scene_season = scene_exception.split(""|"")<tab><tab>if season == scene_season:<tab><tab><tab>scene_exceptions.append(scene_name)<tab>return scene_exceptions",0,if not len ( scene_exception ) == 2 :,"if ""-"" not in scene_exception :",0.017951424116240698,15.20797122409784,0.48484848484848486
"def init(self, view, items=None):<tab>selections = []<tab>if view.sel():<tab><tab>for region in view.sel():<tab><tab><tab>selections.append(view.substr(region))<tab>values = []<tab>for idx, index in enumerate(map(int, items)):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>i = index - 1<tab><tab>if i >= 0 and i < len(selections):<tab><tab><tab>values.append(selections[i])<tab><tab>else:<tab><tab><tab>values.append(None)<tab># fill up<tab>for idx, value in enumerate(selections):<tab><tab>if len(values) + 1 < idx:<tab><tab><tab>values.append(value)<tab>self.stack = values",0,if idx >= len ( selections ) :,if index < 0 :,0.01858685153282265,5.70796903405875,0.2698412698412698
"def to_tool_path(self, path_or_uri_like, **kwds):<tab>if ""://"" not in path_or_uri_like:<tab><tab>path = path_or_uri_like<tab>else:<tab><tab>uri_like = path_or_uri_like<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Invalid URI passed to get_tool_source"")<tab><tab>scheme, rest = uri_like.split("":"", 2)<tab><tab>if scheme not in self.resolver_classes:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Unknown tool scheme [{}] for URI [{}]"".format(scheme, uri_like)<tab><tab><tab>)<tab><tab>path = self.resolver_classes[scheme]().get_tool_source_path(uri_like)<tab>return path",0,"if "":"" not in path_or_uri_like :","if "":"" not in uri_like :",0.5212518808542342,52.6623069750211,1.0
def mainWindow():<tab>global MW<tab>if not MW:<tab><tab>for i in qApp.topLevelWidgets():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>MW = i<tab><tab><tab><tab>return MW<tab><tab>return None<tab>else:<tab><tab>return MW,0,"if i . objectName ( ) == ""MainWindow"" :",if i . isVisible ( ) :,0.18089226606614267,15.749996500436227,0.6
"def async_get_service(hass, config, discovery_info=None):<tab># pylint: disable=unused-argument<tab>""""""Get the demo notification service.""""""<tab>for account, account_dict in hass.data[DATA_ALEXAMEDIA][""accounts""].items():<tab><tab>for key, _ in account_dict[""devices""][""media_player""].items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_LOGGER.debug(<tab><tab><tab><tab><tab>""%s: Media player %s not loaded yet; delaying load"",<tab><tab><tab><tab><tab>hide_email(account),<tab><tab><tab><tab><tab>hide_serial(key),<tab><tab><tab><tab>)<tab><tab><tab><tab>return False<tab>return AlexaNotificationService(hass)",0,"if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :","if not hass . data [ DATA_ALEXAMEDIA ] [ ""loaded"" ] :",0.06115948801489887,13.547860618301662,0.2857142857142857
"def _migrate_bool(self, name: str, true_value: str, false_value: str) -> None:<tab>if name not in self._settings:<tab><tab>return<tab>values = self._settings[name]<tab>if not isinstance(values, dict):<tab><tab>return<tab>for scope, val in values.items():<tab><tab><IF-STMT><tab><tab><tab>new_value = true_value if val else false_value<tab><tab><tab>self._settings[name][scope] = new_value<tab><tab><tab>self.changed.emit()",1,"if isinstance ( val , bool ) :","if isinstance ( val , bool ) :",0.75,100.00000000000004,1.0
"def send(self, data, flags=0):<tab>self._checkClosed()<tab>if self._sslobj:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""non-zero flags not allowed in calls to send() on %s"" % self.__class__<tab><tab><tab>)<tab><tab>return self._sslobj.write(data)<tab>else:<tab><tab>return socket.send(self, data, flags)",1,if flags != 0 :,if flags != 0 :,0.75,100.00000000000004,1.0
"def rec_deps(services, container_by_name, cnt, init_service):<tab>deps = cnt[""_deps""]<tab>for dep in deps.copy():<tab><tab>dep_cnts = services.get(dep)<tab><tab>if not dep_cnts:<tab><tab><tab>continue<tab><tab>dep_cnt = container_by_name.get(dep_cnts[0])<tab><tab><IF-STMT><tab><tab><tab># TODO: avoid creating loops, A->B->A<tab><tab><tab>if init_service and init_service in dep_cnt[""_deps""]:<tab><tab><tab><tab>continue<tab><tab><tab>new_deps = rec_deps(services, container_by_name, dep_cnt, init_service)<tab><tab><tab>deps.update(new_deps)<tab>return deps",1,if dep_cnt :,if dep_cnt :,0.5311706625951745,1e-10,1.0
"def as_dict(path="""", version=""latest"", section=""meta-data""):<tab>result = {}<tab>dirs = dir(path, version, section)<tab>if not dirs:<tab><tab>return None<tab>for item in dirs:<tab><tab>if item.endswith(""/""):<tab><tab><tab>records = as_dict(path + item, version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[item[:-1]] = records<tab><tab><IF-STMT><tab><tab><tab>idx, name = is_dict.match(item).groups()<tab><tab><tab>records = as_dict(path + idx + ""/"", version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[name] = records<tab><tab>else:<tab><tab><tab>result[item] = valueconv(get(path + item, version, section))<tab>return result",1,elif is_dict . match ( item ) :,elif is_dict . match ( item ) :,0.75,100.00000000000004,1.0
"def PrintColGroup(col_names, schema):<tab>""""""Print HTML colgroup element, used for JavaScript sorting.""""""<tab>print(""  <colgroup>"")<tab>for i, col in enumerate(col_names):<tab><tab>if col.endswith(""_HREF""):<tab><tab><tab>continue<tab><tab># CSS class is used for sorting<tab><tab><IF-STMT><tab><tab><tab>css_class = ""number""<tab><tab>else:<tab><tab><tab>css_class = ""case-insensitive""<tab><tab># NOTE: id is a comment only; not used<tab><tab>print('<tab><col id=""{}"" type=""{}"" />'.format(col, css_class))<tab>print(""  </colgroup>"")",0,if schema . IsNumeric ( col ) :,if i == 0 :,0.01858685153282265,6.916271812933183,0.2698412698412698
"def check_region(self, region):<tab>for other in self.regions:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (other.start < region.start < other.end) or (<tab><tab><tab>other.start < region.end < other.end<tab><tab>):<tab><tab><tab>raise Exception(""%r overlaps with %r"" % (region, other))",0,if other is region :,if region . start == other . start and region . end == other . end :,0.023569742477749067,2.8629993657668873,0.2125
"def _write_value(self, rng, value, scalar):<tab>if rng.api and value:<tab><tab># it is assumed by this stage that value is a list of lists<tab><tab><IF-STMT><tab><tab><tab>value = value[0][0]<tab><tab>else:<tab><tab><tab>rng = rng.resize(len(value), len(value[0]))<tab><tab>rng.raw_value = value",1,if scalar :,if scalar :,0.5311706625951745,1e-10,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_cost().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.add_version(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None):<tab># This part of function creates faces in SV format<tab># It ignores  boundless super face<tab>sv_faces = []<tab>for i, face in enumerate(dcel_mesh.faces):<tab><tab><IF-STMT><tab><tab><tab>""Face ({}) has inner components! Sverchok cant show polygons with holes."".format(<tab><tab><tab><tab>i<tab><tab><tab>)<tab><tab>if not face.outer or del_flag in face.flags:<tab><tab><tab>continue<tab><tab>if only_select and not face.select:<tab><tab><tab>continue<tab><tab>sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges])<tab>return sv_faces",0,if face . inners and face . outer :,if del_flag is None :,0.05145036418297875,5.868924818816531,0.20833333333333331
"def _get_x_for_y(self, xValue, x, y):<tab># print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y)<tab>x_value = str(xValue)<tab>for anime in self.xmlMap.findall(""anime""):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(anime.get(y, 0))<tab><tab>except ValueError as e:<tab><tab><tab>continue<tab>return 0",0,"if anime . get ( x , False ) == x_value :","if anime . get ( x , 0 ) == x_value :",0.3684795558138385,80.03203203845001,0.7142857142857143
"def dir_copy(src_dir, dest_dir, merge_if_exists=True):<tab>try:<tab><tab>if not os.path.exists(dest_dir):<tab><tab><tab>shutil.copytree(src_dir, dest_dir)<tab><tab><IF-STMT><tab><tab><tab>merge_dir(src_dir, dest_dir)<tab>except OSError as e:<tab><tab># If source is not a directory, copy with shutil.copy<tab><tab>if e.errno == errno.ENOTDIR:<tab><tab><tab>shutil.copy(src_dir, dest_dir)<tab><tab>else:<tab><tab><tab>logging.error(""Could not copy %s to %s"", src_dir, dest_dir)",0,elif merge_if_exists :,if merge_if_exists :,0.11293884852539707,1e-10,0.3333333333333333
"def mapping(self):<tab>m = {}<tab>if getGdriveCredentialsFile() is not None:<tab><tab>m[""gdrive""] = """"<tab>unknown = 0<tab>for f in self.scan:<tab><tab>bits = f.split(""#"", 2)<tab><tab>if len(bits) == 1:<tab><tab><tab>label = os.path.basename(f)<tab><tab>else:<tab><tab><tab>label = bits[1]<tab><tab><IF-STMT><tab><tab><tab>label = ""L"" + str(unknown)<tab><tab><tab>unknown += 1<tab><tab>m[label] = bits[0]<tab>return m",0,"if not label or len ( label ) == 0 or label == """" :","if label == ""L"" :",0.013887228846722825,12.241977696855177,0.23308270676691728
"def get_tag_values(self, event):<tab>http = event.interfaces.get(""sentry.interfaces.Http"")<tab>if not http:<tab><tab>return []<tab>if not http.headers:<tab><tab>return []<tab>headers = http.headers<tab># XXX: transitional support for workers<tab>if isinstance(headers, dict):<tab><tab>headers = headers.items()<tab>output = []<tab>for key, value in headers:<tab><tab>if key != ""User-Agent"":<tab><tab><tab>continue<tab><tab>ua = Parse(value)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>result = self.get_tag_from_ua(ua)<tab><tab>if result:<tab><tab><tab>output.append(result)<tab>return output",1,if not ua :,if not ua :,0.75,100.00000000000004,1.0
"def __iter__(self):<tab>it = DiskHashMerger.__iter__(self)<tab>direct_upstreams = self.direct_upstreams<tab>for k, groups in it:<tab><tab>t = list([[] for _ in range(self.size)])<tab><tab>for i, g in enumerate(groups):<tab><tab><tab>if g:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>t[i] = g<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>g.sort(key=itemgetter(0))<tab><tab><tab><tab><tab>g1 = []<tab><tab><tab><tab><tab>for _, vs in g:<tab><tab><tab><tab><tab><tab>g1.extend(vs)<tab><tab><tab><tab><tab>t[i] = g1<tab><tab>yield k, tuple(t)",0,if i in direct_upstreams :,if len ( g ) == len ( direct_upstreams ) :,0.02506468314974991,12.011055432195764,0.32222222222222224
"def process_question(qtxt):<tab>question = """"<tab>skip = False<tab>for letter in qtxt:<tab><tab><IF-STMT><tab><tab><tab>skip = True<tab><tab>if letter == "">"":<tab><tab><tab>skip = False<tab><tab>if skip:<tab><tab><tab>continue<tab><tab>if letter.isalnum() or letter == "" "":<tab><tab><tab>if letter == "" "":<tab><tab><tab><tab>letter = ""_""<tab><tab><tab>question += letter.lower()<tab>return question",1,"if letter == ""<"" :","if letter == ""<"" :",0.75,100.00000000000004,1.0
"def _module_repr_from_spec(spec):<tab>""""""Return the repr to use for the module.""""""<tab># We mostly replicate _module_repr() using the spec attributes.<tab>name = ""?"" if spec.name is None else spec.name<tab>if spec.origin is None:<tab><tab>if spec.loader is None:<tab><tab><tab>return ""<module {!r}>"".format(name)<tab><tab>else:<tab><tab><tab>return ""<module {!r} ({!r})>"".format(name, spec.loader)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return ""<module {!r} from {!r}>"".format(name, spec.origin)<tab><tab>else:<tab><tab><tab>return ""<module {!r} ({})>"".format(spec.name, spec.origin)",0,if spec . has_location :,if spec . loader is None :,0.2005939911646859,26.269098944241588,0.42857142857142855
"def test_row(self, row):<tab>for idx, test in self.patterns.items():<tab><tab>try:<tab><tab><tab>value = row[idx]<tab><tab>except IndexError:<tab><tab><tab>value = """"<tab><tab>result = test(value)<tab><tab>if self.any_match:<tab><tab><tab>if result:<tab><tab><tab><tab>return not self.inverse  # True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.inverse  # False<tab>if self.any_match:<tab><tab>return self.inverse  # False<tab>else:<tab><tab>return not self.inverse  # True",1,if not result :,if not result :,0.75,100.00000000000004,1.0
"def frequent_thread_switches():<tab>""""""Make concurrency bugs more likely to manifest.""""""<tab>interval = None<tab>if not sys.platform.startswith(""java""):<tab><tab><IF-STMT><tab><tab><tab>interval = sys.getswitchinterval()<tab><tab><tab>sys.setswitchinterval(1e-6)<tab><tab>else:<tab><tab><tab>interval = sys.getcheckinterval()<tab><tab><tab>sys.setcheckinterval(1)<tab>try:<tab><tab>yield<tab>finally:<tab><tab>if not sys.platform.startswith(""java""):<tab><tab><tab>if hasattr(sys, ""setswitchinterval""):<tab><tab><tab><tab>sys.setswitchinterval(interval)<tab><tab><tab>else:<tab><tab><tab><tab>sys.setcheckinterval(interval)",0,"if hasattr ( sys , ""getswitchinterval"" ) :","if hasattr ( sys , ""setswitchinterval"" ) :",0.5490406812970063,65.80370064762461,1.0
"def record_expected_exportable_production(self, ticks):<tab>""""""Record the amount of production that should be transferred to other islands.""""""<tab>for (quota_holder, resource_id), amount in self._low_priority_requests.items():<tab><tab><IF-STMT><tab><tab><tab>self._settlement_manager_id[quota_holder] = WorldObject.get_object_by_id(<tab><tab><tab><tab>int(quota_holder[1:].split("","")[0])<tab><tab><tab>).settlement_manager.worldid<tab><tab>self.trade_storage[self._settlement_manager_id[quota_holder]][resource_id] += (<tab><tab><tab>ticks * amount<tab><tab>)",1,if quota_holder not in self . _settlement_manager_id :,if quota_holder not in self . _settlement_manager_id :,0.75,100.00000000000004,1.0
"def _method_events_callback(self, values):<tab>try:<tab><tab>previous_echoed = (<tab><tab><tab>values[""child_result_list""][-1].decode().split(""\n"")[-2].strip()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ""echo foo2\n""<tab><tab>elif previous_echoed.endswith(""foo2""):<tab><tab><tab>return ""echo foo3\n""<tab><tab>elif previous_echoed.endswith(""foo3""):<tab><tab><tab>return ""exit\n""<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected output {0!r}"".format(previous_echoed))<tab>except IndexError:<tab><tab>return ""echo foo1\n""",1,"if previous_echoed . endswith ( ""foo1"" ) :","if previous_echoed . endswith ( ""foo1"" ) :",0.75,100.00000000000004,1.0
"def describe_cluster_snapshots(self, cluster_identifier=None, snapshot_identifier=None):<tab>if cluster_identifier:<tab><tab>cluster_snapshots = []<tab><tab>for snapshot in self.snapshots.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cluster_snapshots.append(snapshot)<tab><tab>if cluster_snapshots:<tab><tab><tab>return cluster_snapshots<tab>if snapshot_identifier:<tab><tab>if snapshot_identifier in self.snapshots:<tab><tab><tab>return [self.snapshots[snapshot_identifier]]<tab><tab>raise ClusterSnapshotNotFoundError(snapshot_identifier)<tab>return self.snapshots.values()",0,if snapshot . cluster . cluster_identifier == cluster_identifier :,if snapshot . identifier == cluster_identifier :,0.1533711111796332,52.6623069750211,0.6
def get_snippet_edit_handler(model):<tab>if model not in SNIPPET_EDIT_HANDLERS:<tab><tab><IF-STMT><tab><tab><tab># use the edit handler specified on the page class<tab><tab><tab>edit_handler = model.edit_handler<tab><tab>else:<tab><tab><tab>panels = extract_panel_definitions_from_model_class(model)<tab><tab><tab>edit_handler = ObjectList(panels)<tab><tab>SNIPPET_EDIT_HANDLERS[model] = edit_handler.bind_to(model=model)<tab>return SNIPPET_EDIT_HANDLERS[model],1,"if hasattr ( model , ""edit_handler"" ) :","if hasattr ( model , ""edit_handler"" ) :",0.75,100.00000000000004,1.0
"def start():<tab>if os.environ.get(""RUN_MAIN"") != ""true"":<tab><tab>try:<tab><tab><tab>exit_code = restart_with_reloader()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.kill(os.getpid(), -exit_code)<tab><tab><tab>else:<tab><tab><tab><tab>sys.exit(exit_code)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>pass",0,if exit_code < 0 :,if exit_code != 0 :,0.33141502097923065,41.11336169005198,1.0
"def discover(self, *objlist):<tab>ret = []<tab>for l in self.splitlines():<tab><tab>if len(l) < 5:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>int(l[2])<tab><tab><tab>int(l[3])<tab><tab>except:<tab><tab><tab>continue<tab><tab>#<tab><tab>   ret.append(improve(l[0]))<tab><tab>ret.append(l[0])<tab>ret.sort()<tab>for item in objlist:<tab><tab>ret.append(item)<tab>return ret",0,"if l [ 0 ] == ""Filename"" :",if len ( l ) < 4 :,0.019345087832959386,4.995138898472386,0.3148148148148148
"def ipfs_publish(self, lib):<tab>with tempfile.NamedTemporaryFile() as tmp:<tab><tab>self.ipfs_added_albums(lib, tmp.name)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cmd = ""ipfs add --nocopy -q "".split()<tab><tab><tab>else:<tab><tab><tab><tab>cmd = ""ipfs add -q "".split()<tab><tab><tab>cmd.append(tmp.name)<tab><tab><tab>output = util.command_output(cmd)<tab><tab>except (OSError, subprocess.CalledProcessError) as err:<tab><tab><tab>msg = ""Failed to publish library. Error: {0}"".format(err)<tab><tab><tab>self._log.error(msg)<tab><tab><tab>return False<tab><tab>self._log.info(""hash of library: {0}"", output)",0,"if self . config [ ""nocopy"" ] :",if lib == lib :,0.01858685153282265,4.955725306405571,0.4
"def spends(self):<tab># Return spends indexed by hashX<tab>spends = defaultdict(list)<tab>utxos = self.mempool_utxos()<tab>for tx_hash, tx in self.txs.items():<tab><tab>for n, input in enumerate(tx.inputs):<tab><tab><tab>if input.is_generation():<tab><tab><tab><tab>continue<tab><tab><tab>prevout = (input.prev_hash, input.prev_idx)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hashX, value = utxos.pop(prevout)<tab><tab><tab>else:<tab><tab><tab><tab>hashX, value = self.db_utxos[prevout]<tab><tab><tab>spends[hashX].append(prevout)<tab>return spends",0,if prevout in utxos :,if n == len ( utxos ) - 1 :,0.025806626984353938,4.9323515694897075,0.36363636363636365
"def terminate(self):<tab>if self.returncode is None:<tab><tab>try:<tab><tab><tab>os.kill(self.pid, TERM_SIGNAL)<tab><tab>except OSError as exc:<tab><tab><tab>if getattr(exc, ""errno"", None) != errno.ESRCH:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise",0,if self . wait ( timeout = 0.1 ) is None :,if exc . errno != errno . ESRCH :,0.13709918799270282,4.85851417160653,0.19230769230769232
"def _getVolumeScalar(self):<tab>if self._volumeScalar is not None:<tab><tab>return self._volumeScalar<tab># use default<tab>elif self._value in dynamicStrToScalar:<tab><tab>return dynamicStrToScalar[self._value]<tab>else:<tab><tab>thisDynamic = self._value<tab><tab># ignore leading s like in sf<tab><tab><IF-STMT><tab><tab><tab>thisDynamic = thisDynamic[1:]<tab><tab># ignore closing z like in fz<tab><tab>if thisDynamic[-1] == ""z"":<tab><tab><tab>thisDynamic = thisDynamic[:-1]<tab><tab>if thisDynamic in dynamicStrToScalar:<tab><tab><tab>return dynamicStrToScalar[thisDynamic]<tab><tab>else:<tab><tab><tab>return dynamicStrToScalar[None]",0,"if ""s"" in thisDynamic :","if thisDynamic [ 0 ] == ""sf"" :",0.028001459970687266,5.604233375480572,0.4
"def init_values(self):<tab>config = self._raw_config<tab>for valname, value in self.overrides.iteritems():<tab><tab>if ""."" in valname:<tab><tab><tab>realvalname, key = valname.split(""."", 1)<tab><tab><tab>config.setdefault(realvalname, {})[key] = value<tab><tab>else:<tab><tab><tab>config[valname] = value<tab>for name in config:<tab><tab><IF-STMT><tab><tab><tab>self.__dict__[name] = config[name]<tab>del self._raw_config",0,if name in self . values :,if name in self . overrides :,0.574113272471593,64.34588841607616,0.7142857142857143
"def modified(self):<tab>paths = set()<tab>dictionary_list = []<tab>for op_list in self._operations:<tab><tab>if not isinstance(op_list, list):<tab><tab><tab>op_list = (op_list,)<tab><tab>for item in chain(*op_list):<tab><tab><tab>if item is None:<tab><tab><tab><tab>continue<tab><tab><tab>dictionary = item.dictionary<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>paths.add(dictionary.path)<tab><tab><tab>dictionary_list.append(dictionary)<tab>return dictionary_list",1,if dictionary . path in paths :,if dictionary . path in paths :,0.75,100.00000000000004,1.0
"def __getitem__(self, key, _get_mode=False):<tab>if not _get_mode:<tab><tab><IF-STMT><tab><tab><tab>return self._list[key]<tab><tab>elif isinstance(key, slice):<tab><tab><tab>return self.__class__(self._list[key])<tab>ikey = key.lower()<tab>for k, v in self._list:<tab><tab>if k.lower() == ikey:<tab><tab><tab>return v<tab># micro optimization: if we are in get mode we will catch that<tab># exception one stack level down so we can raise a standard<tab># key error instead of our special one.<tab>if _get_mode:<tab><tab>raise KeyError()<tab>raise BadRequestKeyError(key)",0,"if isinstance ( key , ( int , long ) ) :",if key in self . _list :,0.011144772446387376,4.408194605881708,0.24166666666666667
"def _get_items(self, name, target=1):<tab>all_items = self.get_items(name)<tab>items = [o for o in all_items if not o.disabled]<tab>if len(items) < target:<tab><tab><IF-STMT><tab><tab><tab>raise ItemNotFoundError(""insufficient items with name %r"" % name)<tab><tab>else:<tab><tab><tab>raise AttributeError(""insufficient non-disabled items with name %s"" % name)<tab>on = []<tab>off = []<tab>for o in items:<tab><tab>if o.selected:<tab><tab><tab>on.append(o)<tab><tab>else:<tab><tab><tab>off.append(o)<tab>return on, off",0,if len ( all_items ) < target :,if len ( items ) == target :,0.34166808520089226,23.341653606491416,0.5777777777777777
"def get_genome_dir(gid, galaxy_dir, data):<tab>""""""Return standard location of genome directories.""""""<tab>if galaxy_dir:<tab><tab>refs = genome.get_refs(gid, None, galaxy_dir, data)<tab><tab>seq_file = tz.get_in([""fasta"", ""base""], refs)<tab><tab><IF-STMT><tab><tab><tab>return os.path.dirname(os.path.dirname(seq_file))<tab>else:<tab><tab>gdirs = glob.glob(os.path.join(_get_data_dir(), ""genomes"", ""*"", gid))<tab><tab>if len(gdirs) == 1 and os.path.exists(gdirs[0]):<tab><tab><tab>return gdirs[0]",0,if seq_file and os . path . exists ( seq_file ) :,if seq_file :,0.014772183860219557,1e-10,0.2962962962962963
"def _PrintFuncs(self, names):<tab># type: (List[str]) -> int<tab>status = 0<tab>for name in names:<tab><tab><IF-STMT><tab><tab><tab>print(name)<tab><tab><tab># TODO: Could print LST for -f, or render LST.  Bash does this.  'trap'<tab><tab><tab># could use that too.<tab><tab>else:<tab><tab><tab>status = 1<tab>return status",0,if name in self . funcs :,"if name . endswith ( ""-f"" ) :",0.03952150193806378,9.980099403873663,0.39285714285714285
"def package_files(self):<tab>seen_package_directories = ()<tab>directories = self.distribution.package_dir or {}<tab>empty_directory_exists = """" in directories<tab>packages = self.distribution.packages or []<tab>for package in packages:<tab><tab>if package in directories:<tab><tab><tab>package_directory = directories[package]<tab><tab>elif empty_directory_exists:<tab><tab><tab>package_directory = os.path.join(directories[""""], package)<tab><tab>else:<tab><tab><tab>package_directory = package<tab><tab><IF-STMT><tab><tab><tab>seen_package_directories += (package_directory + ""."",)<tab><tab><tab>yield package_directory",0,if not package_directory . startswith ( seen_package_directories ) :,if package_directory not in seen_package_directories :,0.018728518225177467,35.758619990303956,0.6
"def apply_conf_file(fn, conf_filename):<tab>for env in LSF_CONF_ENV:<tab><tab>conf_file = get_conf_file(conf_filename, env)<tab><tab><IF-STMT><tab><tab><tab>with open(conf_file) as conf_handle:<tab><tab><tab><tab>value = fn(conf_handle)<tab><tab><tab>if value:<tab><tab><tab><tab>return value<tab>return None",0,if conf_file :,if os . path . exists ( conf_file ) :,0.044327767115559996,1e-10,0.36
"def on_text(self, text):<tab>if text != self.chosen_text:<tab><tab>self.fail_test('Expected ""{}"", received ""{}""'.format(self.chosen_text, text))<tab>else:<tab><tab>self.checks_passed += 1<tab><tab><IF-STMT><tab><tab><tab>self.pass_test()<tab><tab>else:<tab><tab><tab>self._select_next_text()",0,if self . checks_passed >= self . number_of_checks :,if self . checks_passed >= self . max_checks :,0.87709085524794,67.83686168526629,1.0
"def test_field_attr_existence(self):<tab>for name, item in ast.__dict__.items():<tab><tab>if self._is_ast_node(name, item):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Index(value) just returns value now.<tab><tab><tab><tab># The argument is required.<tab><tab><tab><tab>continue<tab><tab><tab>x = item()<tab><tab><tab>if isinstance(x, ast.AST):<tab><tab><tab><tab>self.assertEqual(type(x._fields), tuple)",0,"if name == ""Index"" :","if isinstance ( item , int ) :",0.026407399022921448,6.567274736060395,0.3
"def apply(self, response):<tab>updated_headers = self.update_headers(response)<tab>if updated_headers:<tab><tab>response.headers.update(updated_headers)<tab><tab>warning_header_value = self.warning(response)<tab><tab><IF-STMT><tab><tab><tab>response.headers.update({""Warning"": warning_header_value})<tab>return response",0,if warning_header_value is not None :,if warning_header_value :,0.050438393472541504,1e-10,0.3142857142857143
"def validate(self):<tab>self.assertEqual(len(self.inputs), len(self.outputs))<tab>for batch_in, batch_out in zip(self.inputs, self.outputs):<tab><tab>self.assertEqual(len(batch_in), len(batch_out))<tab><tab>if self.use_parallel_executor and not self.use_double_buffer:<tab><tab><tab>self.validate_unordered_batch(batch_in, batch_out)<tab><tab>else:<tab><tab><tab>for in_data, out_data in zip(batch_in, batch_out):<tab><tab><tab><tab>self.assertEqual(in_data.shape, out_data.shape)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.assertTrue((in_data == out_data).all())",0,if not self . use_parallel_executor :,if self . use_parallel_executor and not self . use_parallel_executor :,0.4682677530835593,46.24892603869298,0.3666666666666667
def finalize(self):<tab>if self._started:<tab><tab><IF-STMT><tab><tab><tab>self._queue.put(None)<tab><tab><tab>self._queue.join()<tab><tab><tab>self._consumer.join()<tab><tab>self._started = False<tab>self._finalized = True,1,if not self . _finalized :,if not self . _finalized :,0.75,100.00000000000004,1.0
"def _get_ilo_version(self):<tab>try:<tab><tab>self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>')<tab>except ResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>if e.code == 405:<tab><tab><tab><tab>return 3<tab><tab><tab>if e.code == 501:<tab><tab><tab><tab>return 1<tab><tab>raise<tab>return 2",0,"if hasattr ( e , ""code"" ) :","if e . code . startswith ( ""HTTP Error"" ) :",0.0318578261816963,14.694106251955755,0.32222222222222224
"def _check_data(self, source, expected_bytes, expected_duration):<tab>received_bytes = 0<tab>received_seconds = 0.0<tab>bytes_to_read = 1024<tab>while True:<tab><tab>data = source.get_audio_data(bytes_to_read)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>received_bytes += data.length<tab><tab>received_seconds += data.duration<tab><tab>self.assertEqual(data.length, len(data.data))<tab>self.assertAlmostEqual(expected_duration, received_seconds, places=1)<tab>self.assertAlmostEqual(expected_bytes, received_bytes, delta=5)",0,if data is None :,if not data :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def __randomize_interval_task(self):<tab>for job in self.aps_scheduler.get_jobs():<tab><tab><IF-STMT><tab><tab><tab>self.aps_scheduler.modify_job(<tab><tab><tab><tab>job.id,<tab><tab><tab><tab>next_run_time=datetime.now()<tab><tab><tab><tab>+ timedelta(<tab><tab><tab><tab><tab>seconds=randrange(<tab><tab><tab><tab><tab><tab>job.trigger.interval.total_seconds() * 0.75,<tab><tab><tab><tab><tab><tab>job.trigger.interval.total_seconds(),<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>),<tab><tab><tab>)",0,"if isinstance ( job . trigger , IntervalTrigger ) :",if job . trigger :,0.059382556937524214,16.62083000646927,0.3055555555555556
"def find_approximant(x):<tab>c = 1e-4<tab>it = sympy.ntheory.continued_fraction_convergents(<tab><tab>sympy.ntheory.continued_fraction_iterator(x)<tab>)<tab>for i in it:<tab><tab>p, q = i.as_numer_denom()<tab><tab>tol = c / q ** 2<tab><tab><IF-STMT><tab><tab><tab>return i<tab><tab>if tol < machine_epsilon:<tab><tab><tab>break<tab>return x",0,if abs ( i - x ) <= tol :,if tol > machine_epsilon :,0.05605987920223514,4.880869806051147,0.2948717948717949
"def fix_newlines(lines):<tab>""""""Convert newlines to unix.""""""<tab>for i, line in enumerate(lines):<tab><tab>if line.endswith(""\r\n""):<tab><tab><tab>lines[i] = line[:-2] + ""\n""<tab><tab><IF-STMT><tab><tab><tab>lines[i] = line[:-1] + ""\n""",0,"elif line . endswith ( ""\r"" ) :","elif line . endswith ( ""\n"" ) :",0.5473017787506802,70.16879391277372,1.0
"def payment_control_render(self, request: HttpRequest, payment: OrderPayment):<tab>template = get_template(""pretixplugins/paypal/control.html"")<tab>sale_id = None<tab>for trans in payment.info_data.get(""transactions"", []):<tab><tab>for res in trans.get(""related_resources"", []):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sale_id = res[""sale""][""id""]<tab>ctx = {<tab><tab>""request"": request,<tab><tab>""event"": self.event,<tab><tab>""settings"": self.settings,<tab><tab>""payment_info"": payment.info_data,<tab><tab>""order"": payment.order,<tab><tab>""sale_id"": sale_id,<tab>}<tab>return template.render(ctx)",1,"if ""sale"" in res and ""id"" in res [ ""sale"" ] :","if ""sale"" in res and ""id"" in res [ ""sale"" ] :",1.0,100.00000000000004,1.0
"def for_name(self, name):<tab>try:<tab><tab>name_resources = self._resources[name]<tab>except KeyError:<tab><tab>raise LookupError(name)<tab>else:<tab><tab>for res in name_resources:<tab><tab><tab>try:<tab><tab><tab><tab>inst = res.inst()<tab><tab><tab>except Exception as e:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>log.exception(""error initializing %s"", res)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>log.error(""error initializing %s: %s"", res, e)<tab><tab><tab>else:<tab><tab><tab><tab>yield inst",0,if log . getEffectiveLevel ( ) <= logging . DEBUG :,if self . debug :,0.06241787918570013,3.466791587270993,0.2653061224489796
"def describe(self, done=False):<tab>description = ShellCommand.describe(self, done)<tab>if done:<tab><tab><IF-STMT><tab><tab><tab>description = [""compile""]<tab><tab>description.append(""%d projects"" % self.getStatistic(""projects"", 0))<tab><tab>description.append(""%d files"" % self.getStatistic(""files"", 0))<tab><tab>warnings = self.getStatistic(""warnings"", 0)<tab><tab>if warnings > 0:<tab><tab><tab>description.append(""%d warnings"" % warnings)<tab><tab>errors = self.getStatistic(""errors"", 0)<tab><tab>if errors > 0:<tab><tab><tab>description.append(""%d errors"" % errors)<tab>return description",0,if not description :,"if description == ""compile"" :",0.045150550804307965,7.267884212102741,0.45
"def parse_list(tl):<tab>ls = []<tab>nm = []<tab>while True:<tab><tab>term, nmt, tl = parse_term(tl)<tab><tab>ls.append(term)<tab><tab><IF-STMT><tab><tab><tab>nm.append(nmt)<tab><tab>if tl[0] != "","":<tab><tab><tab>break<tab><tab>tl = tl[1:]<tab>return ls, nm, tl",0,if nmt is not None :,if nmt :,0.050438393472541504,1e-10,0.39999999999999997
"def infer_dataset_impl(path):<tab>if IndexedRawTextDataset.exists(path):<tab><tab>return ""raw""<tab>elif IndexedDataset.exists(path):<tab><tab>with open(index_file_path(path), ""rb"") as f:<tab><tab><tab>magic = f.read(8)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""cached""<tab><tab><tab>elif magic == MMapIndexedDataset.Index._HDR_MAGIC[:8]:<tab><tab><tab><tab>return ""mmap""<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab>elif FastaDataset.exists(path):<tab><tab>return ""fasta""<tab>else:<tab><tab>return None",0,if magic == IndexedDataset . _HDR_MAGIC :,if magic == IndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,0.34326065239385783,49.62822700197381,0.6481481481481481
"def _get(self):<tab>fut = item = None<tab>with self._mutex:<tab><tab># Critical section never blocks.<tab><tab><IF-STMT><tab><tab><tab>fut = Future()<tab><tab><tab>fut.add_done_callback(<tab><tab><tab><tab>lambda f: self._get_complete() if not f.cancelled() else None<tab><tab><tab>)<tab><tab><tab>self._getters.append(fut)<tab><tab>else:<tab><tab><tab>item = self._get_item()<tab><tab><tab>self._get_complete()<tab>return item, fut",0,if not self . _queue or self . _getters :,if self . _getters is None :,0.09756059102444184,23.206041459353074,0.27272727272727276
"def validate(self):<tab>dates = []<tab>for d in self.get(""leave_block_list_dates""):<tab><tab># date is not repeated<tab><tab><IF-STMT><tab><tab><tab>frappe.msgprint(<tab><tab><tab><tab>_(""Date is repeated"") + "":"" + d.block_date, raise_exception=1<tab><tab><tab>)<tab><tab>dates.append(d.block_date)",1,if d . block_date in dates :,if d . block_date in dates :,0.75,100.00000000000004,1.0
"def on_choose_watch_dir_clicked(self):<tab>if self.window().watchfolder_enabled_checkbox.isChecked():<tab><tab>previous_watch_dir = self.window().watchfolder_location_input.text() or """"<tab><tab>watch_dir = QFileDialog.getExistingDirectory(<tab><tab><tab>self.window(),<tab><tab><tab>""Please select the watch folder"",<tab><tab><tab>previous_watch_dir,<tab><tab><tab>QFileDialog.ShowDirsOnly,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.window().watchfolder_location_input.setText(watch_dir)",1,if not watch_dir :,if not watch_dir :,0.75,100.00000000000004,1.0
"def log_generator(self, limit=6000, **kwargs):<tab># Generator for show_log_panel<tab>skip = 0<tab>while True:<tab><tab>logs = self.log(limit=limit, skip=skip, **kwargs)<tab><tab>if not logs:<tab><tab><tab>break<tab><tab>for entry in logs:<tab><tab><tab>yield entry<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>skip = skip + limit",0,if len ( logs ) < limit :,if skip >= limit :,0.0354018406734773,12.872632311973014,0.3148148148148148
"def _setUpClass(cls):<tab>global solver<tab>import pyomo.environ<tab>from pyomo.solvers.tests.io.writer_test_cases import testCases<tab>for test_case in testCases:<tab><tab><IF-STMT><tab><tab><tab>solver[(test_case.name, test_case.io)] = True",0,"if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :","if hasattr ( test_case , ""io"" ) and hasattr ( test_case , ""name"" ) :",0.020541078618213093,22.140914876645844,0.2114695340501792
"def _get_file_data(self, normpath, normrev):<tab>data = self.client.cat(normpath, normrev)<tab>if has_expanded_svn_keywords(data):<tab><tab># Find out if this file has any keyword expansion set.<tab><tab># If it does, collapse these keywords. This is because SVN<tab><tab># will return the file expanded to us, which would break patching.<tab><tab>keywords = self.client.propget(""svn:keywords"", normpath, normrev, recurse=True)<tab><tab><IF-STMT><tab><tab><tab>data = collapse_svn_keywords(data, force_bytes(keywords[normpath]))<tab>return data",1,if normpath in keywords :,if normpath in keywords :,0.75,100.00000000000004,1.0
"def add_controller_list(path):<tab>if not os.path.exists(os.path.join(path, ""__init__.py"")):<tab><tab>bb.fatal(""Controllers directory %s exists but is missing __init__.py"" % path)<tab>files = sorted(<tab><tab>[f for f in os.listdir(path) if f.endswith("".py"") and not f.startswith(""_"")]<tab>)<tab>for f in files:<tab><tab>module = ""oeqa.controllers."" + f[:-3]<tab><tab><IF-STMT><tab><tab><tab>controllerslist.append(module)<tab><tab>else:<tab><tab><tab>bb.warn(<tab><tab><tab><tab>""Duplicate controller module found for %s, only one added. Layers should create unique controller module names""<tab><tab><tab><tab>% module<tab><tab><tab>)",0,if module not in controllerslist :,if os . path . exists ( module ) :,0.021554938761049226,5.522397783539471,0.2222222222222222
"def on_session2(event):<tab>new_xmpp.get_roster()<tab>new_xmpp.send_presence()<tab>logging.info(roster[0])<tab>data = roster[0][""roster""][""items""]<tab>logging.info(data)<tab>for jid, item in data.items():<tab><tab><IF-STMT><tab><tab><tab>new_xmpp.send_presence(ptype=""subscribe"", pto=jid)<tab><tab>new_xmpp.update_roster(jid, name=item[""name""], groups=item[""groups""])<tab>new_xmpp.disconnect()",0,"if item [ ""subscription"" ] != ""none"" :","if item [ ""ptype"" ] == ""subscribe"" :",0.32991956560314195,28.917849332325716,1.0
"def _parse_class_simplified(symbol):<tab>results = {}<tab>name = symbol.name + ""(""<tab>name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases])<tab>name += "")""<tab>for sym in symbol.body:<tab><tab><IF-STMT><tab><tab><tab>result = _parse_function_simplified(sym, symbol.name)<tab><tab><tab>results.update(result)<tab><tab>elif isinstance(sym, ast.ClassDef):<tab><tab><tab>result = _parse_class_simplified(sym)<tab><tab><tab>results.update(result)<tab>lineno = symbol.lineno<tab>for decorator in symbol.decorator_list:<tab><tab>lineno += 1<tab>results[lineno] = (name, ""c"")<tab>return results",1,"if isinstance ( sym , ast . FunctionDef ) :","if isinstance ( sym , ast . FunctionDef ) :",0.75,100.00000000000004,1.0
"def check_args(args):<tab>""""""Checks that the args are coherent.""""""<tab>check_args_has_attributes(args)<tab>if args.v:<tab><tab>non_version_attrs = [v for k, v in args.__dict__.items() if k != ""v""]<tab><tab>print(""non_version_attrs"", non_version_attrs)<tab><tab><IF-STMT><tab><tab><tab>fail(""Cannot show the version number with another command."")<tab><tab>return<tab>if args.i is None:<tab><tab>fail(""Cannot draw ER diagram of no database."")<tab>if args.o is None:<tab><tab>fail(""Cannot draw ER diagram with no output file."")",0,if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,if len ( non_version_attrs ) > 1 :,0.025396122898395185,16.493457938929108,0.20685111989459815
"def handle(self, *args, **options):<tab>if not settings.ST_BASE_DIR.endswith(""spirit""):<tab><tab>raise CommandError(<tab><tab><tab>""settings.ST_BASE_DIR is not the spirit root folder, are you overriding it?""<tab><tab>)<tab>for root, dirs, files in os.walk(settings.ST_BASE_DIR):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with utils.pushd(root):<tab><tab><tab>call_command(<tab><tab><tab><tab>""makemessages"", stdout=self.stdout, stderr=self.stderr, **options<tab><tab><tab>)<tab>self.stdout.write(""ok"")",0,"if ""locale"" not in dirs :","if ""spirit"" not in files :",0.30253150069759704,27.054113452696992,0.6666666666666666
"def scan(scope):<tab>for s in scope.children:<tab><tab>if s.start_pos <= position <= s.end_pos:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return scan(s) or s<tab><tab><tab>elif s.type in (""suite"", ""decorated""):<tab><tab><tab><tab>return scan(s)<tab>return None",0,"if isinstance ( s , ( tree . Scope , tree . Flow ) ) :","if s . type in ( ""suite"" , ""decorated"" ) :",0.11807088131632196,6.725321874176006,0.20634920634920637
def run_sync(self):<tab>count = 0<tab>while count < self.args.num_messages:<tab><tab>batch = self.receiver.fetch_next(max_batch_size=self.args.num_messages - count)<tab><tab><IF-STMT><tab><tab><tab>for msg in batch:<tab><tab><tab><tab>msg.complete()<tab><tab>count += len(batch),0,if self . args . peeklock :,if len ( batch ) > 0 :,0.019801326568637086,6.567274736060395,0.25
"def __getitem__(self, item):<tab>if self._datas is not None:<tab><tab>ret = []<tab><tab>for data in self._datas:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(data[self._offset])<tab><tab><tab>else:<tab><tab><tab><tab>ret.append(data.iloc[self._offset])<tab><tab>self._offset += 1<tab><tab>return ret<tab>else:<tab><tab>return self._get_data(item)",0,"if isinstance ( data , np . ndarray ) :",if self . _offset < len ( data ) :,0.08570474244991637,11.731175160263996,0.23863636363636365
"def removedir(self, path):<tab># type: (Text) -> None<tab>_path = self.validatepath(path)<tab>if _path == ""/"":<tab><tab>raise errors.RemoveRootError()<tab>with ftp_errors(self, path):<tab><tab>try:<tab><tab><tab>self.ftp.rmd(_encode(_path, self.ftp.encoding))<tab><tab>except error_perm as error:<tab><tab><tab>code, _ = _parse_ftp_error(error)<tab><tab><tab>if code == ""550"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise errors.DirectoryExpected(path)<tab><tab><tab><tab>if not self.isempty(path):<tab><tab><tab><tab><tab>raise errors.DirectoryNotEmpty(path)<tab><tab><tab>raise  # pragma: no cover",0,if self . isfile ( path ) :,if self . isdir ( path ) :,0.5014622369176811,50.000000000000014,0.6666666666666666
"def replaces_in_file(file, replacement_list):<tab>rs = [(re.compile(regexp), repl) for (regexp, repl) in replacement_list]<tab>file_tmp = file + ""."" + str(os.getpid()) + "".tmp""<tab>with open(file, ""r"") as f:<tab><tab>with open(file_tmp, ""w"") as f_tmp:<tab><tab><tab>for line in f:<tab><tab><tab><tab>for r, replace in rs:<tab><tab><tab><tab><tab>match = r.search(line)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>line = replace + ""\n""<tab><tab><tab><tab>f_tmp.write(line)<tab>shutil.move(file_tmp, file)",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def _get_path_check_mem(self, i, size):<tab>if size > 0:<tab><tab><IF-STMT><tab><tab><tab>p = self._get_path(i, -1)<tab><tab>else:<tab><tab><tab>p = self._get_path(i, size)<tab><tab><tab>if p.startswith(""/dev/shm""):<tab><tab><tab><tab>env.meminfo.add(size)<tab>else:<tab><tab>p = self._get_path(i, size)<tab>return p",0,if env . meminfo . rss + size > env . meminfo . mem_limit_soft :,if size == 1 :,0.0074589697276959644,1.2237376376462188,0.2571428571428572
"def find_widget_by_id(self, id, parent=None):<tab>""""""Recursively searches for widget with specified ID""""""<tab>if parent == None:<tab><tab>if id in self:<tab><tab><tab>return self[id]  # Do things fast if possible<tab><tab>parent = self[""editor""]<tab>for c in parent.get_children():<tab><tab><IF-STMT><tab><tab><tab>if c.get_id() == id:<tab><tab><tab><tab>return c<tab><tab>if isinstance(c, Gtk.Container):<tab><tab><tab>r = self.find_widget_by_id(id, c)<tab><tab><tab>if not r is None:<tab><tab><tab><tab>return r<tab>return None",0,"if hasattr ( c , ""get_id"" ) :","if isinstance ( c , Gtk . Widget ) :",0.08080534754184812,16.830386789031852,0.40476190476190477
"def _deserialize(cls, io):<tab>flags = VideoFlags()<tab>flags.byte = U8.read(io)<tab>if flags.bit.type == VIDEO_FRAME_TYPE_COMMAND_FRAME:<tab><tab>data = VideoCommandFrame.deserialize(io)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>data = AVCVideoData.deserialize(io)<tab><tab>else:<tab><tab><tab>data = io.read()<tab>return cls(flags.bit.type, flags.bit.codec, data)",0,if flags . bit . codec == VIDEO_CODEC_ID_AVC :,if flags . bit . type == AVC_DATA_TYPE :,0.4953297362933152,29.677347795910823,0.6666666666666666
"def asciiLogData(data, maxlen=64, replace=False):<tab>ellipses = "" ...""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>dd = data[:maxlen] + ellipses<tab><tab>else:<tab><tab><tab>dd = data<tab><tab>return dd.decode(""utf8"", errors=""replace"" if replace else ""strict"")<tab>except:<tab><tab>return ""0x"" + binLogData(data, maxlen)",0,if len ( data ) > maxlen - len ( ellipses ) :,if len ( data ) > maxlen :,0.3984219693206163,46.53786298485943,0.7569444444444443
"def _check_units(self, new_unit_system):<tab># If no unit system has been specified for me yet, adopt the incoming<tab># system<tab>if self.unit_system is None:<tab><tab>self.unit_system = new_unit_system<tab>else:<tab><tab># Otherwise, make sure they match<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Unit system mismatch %d v. %d"" % (self.unit_system, new_unit_system)<tab><tab><tab>)",1,if self . unit_system != new_unit_system :,if self . unit_system != new_unit_system :,0.75,100.00000000000004,1.0
"def command(filenames, dirnames, fix):<tab>for filename in gather_files(dirnames, filenames):<tab><tab>visitor = process_file(filename)<tab><tab><IF-STMT><tab><tab><tab>print(""%s: %s"" % (filename, visitor.get_stats()))<tab><tab><tab>if fix:<tab><tab><tab><tab>print(""Fixing: %s"" % filename)<tab><tab><tab><tab>fix_file(filename)",0,if visitor . needs_fix ( ) :,if visitor :,0.03885753308224148,1e-10,1.0
"def assign_attributes_to_variants(variant_attributes):<tab>for value in variant_attributes:<tab><tab>pk = value[""pk""]<tab><tab>defaults = value[""fields""]<tab><tab>defaults[""variant_id""] = defaults.pop(""variant"")<tab><tab>defaults[""assignment_id""] = defaults.pop(""assignment"")<tab><tab>assigned_values = defaults.pop(""values"")<tab><tab>assoc, created = AssignedVariantAttribute.objects.update_or_create(<tab><tab><tab>pk=pk, defaults=defaults<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assoc.values.set(AttributeValue.objects.filter(pk__in=assigned_values))",1,if created :,if created :,0.5311706625951745,1e-10,1.0
"def _info(self, userlist):<tab>for strng in userlist:<tab><tab>group_matched = False<tab><tab>for env in self.base.comps.environments_by_pattern(strng):<tab><tab><tab>self.output.display_groups_in_environment(env)<tab><tab><tab>group_matched = True<tab><tab>for group in self.base.comps.groups_by_pattern(strng):<tab><tab><tab>self.output.display_pkgs_in_groups(group)<tab><tab><tab>group_matched = True<tab><tab><IF-STMT><tab><tab><tab>logger.error(_(""Warning: Group %s does not exist.""), strng)<tab>return 0, []",0,if not group_matched :,if group_matched :,0.09648852821835877,1e-10,0.6
"def parse_implements_interfaces(parser):<tab>types = []<tab>if parser.token.value == ""implements"":<tab><tab>advance(parser)<tab><tab>while True:<tab><tab><tab>types.append(parse_named_type(parser))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return types",0,"if not peek ( parser , TokenKind . NAME ) :",if len ( types ) == 0 :,0.014083696926176809,5.3990167242108145,0.18333333333333335
"def generate():<tab>for leaf in u.leaves:<tab><tab>if isinstance(leaf, Integer):<tab><tab><tab>val = leaf.get_int_value()<tab><tab><tab>if val in (0, 1):<tab><tab><tab><tab>yield val<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>elif isinstance(leaf, Symbol):<tab><tab><tab>if leaf == SymbolTrue:<tab><tab><tab><tab>yield 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield 0<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>else:<tab><tab><tab>raise _NoBoolVector",1,elif leaf == SymbolFalse :,elif leaf == SymbolFalse :,1.0,100.00000000000004,1.0
"def update_gstin(context):<tab>dirty = False<tab>for key, value in iteritems(frappe.form_dict):<tab><tab>if key != ""party"":<tab><tab><tab>address_name = frappe.get_value(""Address"", key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>address = frappe.get_doc(""Address"", address_name)<tab><tab><tab><tab>address.gstin = value.upper()<tab><tab><tab><tab>address.save(ignore_permissions=True)<tab><tab><tab><tab>dirty = True<tab>if dirty:<tab><tab>frappe.db.commit()<tab><tab>context.updated = True",1,if address_name :,if address_name :,0.5311706625951745,1e-10,1.0
"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab><IF-STMT><tab><tab><tab>if not everythingIsUnicode(v):<tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>elif isinstance(i, _bytes):<tab><tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, _bytes):<tab><tab><tab>return False<tab>return True",0,"if isinstance ( v , dict ) and k != ""headers"" :","if isinstance ( v , dict ) :",0.3941108903198516,36.24372413507827,0.6938775510204083
"def check_graph(graph):  # pragma: no cover<tab>for c in graph:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""cannot have fuse"")<tab><tab>for inp in c.inputs:<tab><tab><tab>if isinstance(inp.op, Fuse):<tab><tab><tab><tab>raise RuntimeError(""cannot have fuse"")",1,"if isinstance ( c . op , Fuse ) :","if isinstance ( c . op , Fuse ) :",0.75,100.00000000000004,1.0
"def __getattr__(self, key):<tab>try:<tab><tab>value = self.__parent.contents[key]<tab>except KeyError:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, _ModuleMarker):<tab><tab><tab><tab>return value.mod_ns<tab><tab><tab>else:<tab><tab><tab><tab>assert isinstance(value, _MultipleClassMarker)<tab><tab><tab><tab>return value.attempt_get(self.__parent.path, key)<tab>raise AttributeError(<tab><tab>""Module %r has no mapped classes ""<tab><tab>""registered under the name %r"" % (self.__parent.name, key)<tab>)",0,if value is not None :,if self . __parent . mapped :,0.023878899402271555,5.669791110976001,0.20833333333333331
"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None):<tab>assert nw_id != self.nw_id_unknown<tab>ret = []<tab>for port in self.get_ports(dpid):<tab><tab>nw_id_ = port.network_id<tab><tab>if port.port_no == in_port:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>ret.append(port.port_no)<tab><tab>elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external:<tab><tab><tab>ret.append(port.port_no)<tab>return ret",0,if nw_id_ == nw_id :,if allow_nw_id_external is None and nw_id_ == allow_nw_id :,0.21642507548675122,31.573558123189937,0.3538461538461538
"def _parse(self, contents):<tab>entries = []<tab>for line in contents.splitlines():<tab><tab>if not len(line.strip()):<tab><tab><tab>entries.append((""blank"", [line]))<tab><tab><tab>continue<tab><tab>(head, tail) = chop_comment(line.strip(), ""#"")<tab><tab><IF-STMT><tab><tab><tab>entries.append((""all_comment"", [line]))<tab><tab><tab>continue<tab><tab>entries.append((""option"", [head.split(None), tail]))<tab>return entries",0,if not len ( head ) :,if head is None :,0.02384665141965364,9.423716574733431,0.2857142857142857
"def _get_documented_completions(self, table, startswith=None):<tab>names = []<tab>for key, command in table.items():<tab><tab>if getattr(command, ""_UNDOCUMENTED"", False):<tab><tab><tab># Don't tab complete undocumented commands/params<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if getattr(command, ""positional_arg"", False):<tab><tab><tab>continue<tab><tab>names.append(key)<tab>return names",0,if startswith is not None and not key . startswith ( startswith ) :,if startswith and key . startswith ( startswith ) :,0.7244072045451067,48.663863137761844,0.25
"def _convert_example(example, use_bfloat16):<tab>""""""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16.""""""<tab>for key in list(example.keys()):<tab><tab>val = example[key]<tab><tab><IF-STMT><tab><tab><tab>val = tf.sparse.to_dense(val)<tab><tab>if val.dtype == tf.int64:<tab><tab><tab>val = tf.cast(val, tf.int32)<tab><tab>if use_bfloat16 and val.dtype == tf.float32:<tab><tab><tab>val = tf.cast(val, tf.bfloat16)<tab><tab>example[key] = val",0,if tf . keras . backend . is_sparse ( val ) :,"if isinstance ( val , tf . sparse . Tensor ) :",0.11735533313692806,10.989600891745964,0.2136752136752137
"def _get_lang_zone(self, lang):<tab>if lang not in self._lang_zone_from_lang:<tab><tab><IF-STMT><tab><tab><tab>self._lang_zone_from_lang[lang] = MultiLangZone(self.mgr, lang)<tab><tab>else:<tab><tab><tab>self._lang_zone_from_lang[lang] = LangZone(self.mgr, lang)<tab>return self._lang_zone_from_lang[lang]",0,if self . mgr . is_multilang ( lang ) :,if lang in self . _lang_zone_from_lang :,0.029245312147464356,7.474875887495341,0.3333333333333333
"def dispatch(self, request, *args, **kwargs):<tab>try:<tab><tab>return super(Handler, self).dispatch(request, *args, **kwargs)<tab>except Http404 as e:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>request.original_path_info = request.path_info<tab><tab><tab><tab>request.path_info = settings.FEINCMS_CMS_404_PAGE<tab><tab><tab><tab>response = super(Handler, self).dispatch(request, *args, **kwargs)<tab><tab><tab><tab>response.status_code = 404<tab><tab><tab><tab>return response<tab><tab><tab>except Http404:<tab><tab><tab><tab>raise e<tab><tab>else:<tab><tab><tab>raise",0,if settings . FEINCMS_CMS_404_PAGE :,if settings .FEINCMS_CMS_404_PAGE :,0.3201524444874984,100.00000000000004,1.0
"def _maybe_update_dropout(self, step):<tab>for i in range(len(self.dropout_steps)):<tab><tab><IF-STMT><tab><tab><tab>self.model.update_dropout(self.dropout[i])<tab><tab><tab>logger.info(""Updated dropout to %f from step %d"" % (self.dropout[i], step))",0,if step > 1 and step == self . dropout_steps [ i ] + 1 :,if self . dropout_steps [ i ] == step :,0.2186387037204534,41.15908586401038,0.2571428571428572
"def bulk_move(*args, **kwargs):<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>raise PopupException(_(""Source path and destination path cannot be same""))<tab><tab>request.fs.rename(<tab><tab><tab>urllib.unquote(arg[""src_path""]), urllib.unquote(arg[""dest_path""])<tab><tab>)",0,"if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :","if arg [ ""src_path"" ] != arg [ ""dest_path"" ] :",0.8520019333126669,85.78928092681438,1.0
"def asisWrite(self, root):<tab>at, c = self, self.c<tab>try:<tab><tab>c.endEditing()<tab><tab>c.init_error_dialogs()<tab><tab>fileName = at.initWriteIvars(root, root.atAsisFileNodeName())<tab><tab><IF-STMT><tab><tab><tab>at.addToOrphanList(root)<tab><tab><tab>return<tab><tab>at.openOutputStream()<tab><tab>for p in root.self_and_subtree(copy=False):<tab><tab><tab>at.writeAsisNode(p)<tab><tab>contents = at.closeOutputStream()<tab><tab>at.replaceFile(contents, at.encoding, fileName, root)<tab>except Exception:<tab><tab>at.writeException(fileName, root)",0,"if not at . precheck ( fileName , root ) :",if fileName is None :,0.012417879185700129,4.234348806659263,0.20370370370370372
"def next_event(it):<tab>""""""read an event from an eventstream""""""<tab>while True:<tab><tab>try:<tab><tab><tab>line = next(it)<tab><tab>except StopIteration:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return json.loads(line.split("":"", 1)[1])",0,"if line . startswith ( ""data:"" ) :",if line :,0.030705692522937138,1e-10,0.7272727272727273
"def process_formdata(self, valuelist):<tab>if valuelist:<tab><tab>if valuelist[0] == ""__None"":<tab><tab><tab>self.data = None<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.data = None<tab><tab><tab><tab>return<tab><tab><tab>try:<tab><tab><tab><tab>obj = self.queryset.get(pk=valuelist[0])<tab><tab><tab><tab>self.data = obj<tab><tab><tab>except DoesNotExist:<tab><tab><tab><tab>self.data = None",1,if self . queryset is None :,if self . queryset is None :,0.75,100.00000000000004,1.0
"def _setResultsName(self, name, listAllMatches=False):<tab>if __diag__.warn_multiple_tokens_in_named_alternation:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""{}: setting results name {!r} on {} expression ""<tab><tab><tab><tab>""will return a list of all parsed tokens in an And alternative, ""<tab><tab><tab><tab>""in prior versions only the first token was returned"".format(<tab><tab><tab><tab><tab>""warn_multiple_tokens_in_named_alternation"",<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>type(self).__name__,<tab><tab><tab><tab>),<tab><tab><tab><tab>stacklevel=3,<tab><tab><tab>)<tab>return super()._setResultsName(name, listAllMatches)",0,"if any ( isinstance ( e , And ) for e in self . exprs ) :",if not listAllMatches :,0.005013195074070194,0.736550669835346,0.13888888888888887
"def add(request):<tab>form_type = ""servers""<tab>if request.method == ""POST"":<tab><tab>form = BookMarkForm(request.POST)<tab><tab>if form.is_valid():<tab><tab><tab>form_type = form.save()<tab><tab><tab>messages.add_message(request, messages.INFO, ""Bookmark created"")<tab><tab>else:<tab><tab><tab>messages.add_message(request, messages.INFO, form.errors)<tab><tab><IF-STMT><tab><tab><tab>url = reverse(""servers"")<tab><tab>else:<tab><tab><tab>url = reverse(""metrics"")<tab><tab>return redirect(url)<tab>else:<tab><tab>return redirect(reverse(""servers""))",0,"if form_type == ""server"" :","if form_type == ""metrics"" :",0.39477865547525276,70.71067811865478,1.0
"def __init__(self, post_id, artist, page, tzInfo=None, dateFormat=None):<tab>self.imageUrls = list()<tab>self.imageResizedUrls = list()<tab>self.imageId = int(post_id)<tab>self._tzInfo = tzInfo<tab>self.dateFormat = dateFormat<tab>if page is not None:<tab><tab>post_json = demjson.decode(page)<tab><tab><IF-STMT><tab><tab><tab>artist_id = post_json[""data""][""item""][""user""][""id""]<tab><tab><tab>self.artist = SketchArtist(artist_id, page, tzInfo, dateFormat)<tab><tab>else:<tab><tab><tab>self.artist = artist<tab><tab>self.parse_post(post_json[""data""][""item""])",0,if artist is None :,"if ""user"" in post_json [ ""data"" ] :",0.026407399022921448,3.377156414337854,0.3
"def _create_batch_iterator(<tab>self,<tab>mark_as_delete: Callable[[Any], None],<tab>to_key: Callable[[Any], Any],<tab>to_value: Callable[[Any], Any],<tab>batch: Iterable[EventT],) -> Iterable[Tuple[Any, Any]]:<tab>for event in batch:<tab><tab>key = to_key(event.key)<tab><tab># to delete keys in the table we set the raw value to None<tab><tab><IF-STMT><tab><tab><tab>mark_as_delete(key)<tab><tab><tab>continue<tab><tab>yield key, to_value(event.value)",0,if event . message . value is None :,if not mark_as_delete :,0.015402160966973673,5.795599612995366,0.2
"def test_lc_numeric_nl_langinfo(self):<tab># Test nl_langinfo against known values<tab>tested = False<tab>for loc in candidate_locales:<tab><tab>try:<tab><tab><tab>setlocale(LC_NUMERIC, loc)<tab><tab><tab>setlocale(LC_CTYPE, loc)<tab><tab>except Error:<tab><tab><tab>continue<tab><tab>for li, lc in ((RADIXCHAR, ""decimal_point""), (THOUSEP, ""thousands_sep"")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tested = True<tab>if not tested:<tab><tab>self.skipTest(""no suitable locales"")",0,"if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :","if self . numeric_tester ( li , lc ) :",0.14223633943888267,22.101596143315827,0.8266666666666667
"def _level_up_logging(self):<tab>for handler in self.log.handlers:<tab><tab><IF-STMT><tab><tab><tab>if handler.level != logging.DEBUG:<tab><tab><tab><tab>handler.setLevel(logging.DEBUG)<tab><tab><tab><tab>self.log.debug(""Leveled up log file verbosity"")",0,"if issubclass ( handler . __class__ , logging . FileHandler ) :","if isinstance ( handler , logging . FileHandler ) :",0.3291579839440192,32.86316809332552,0.7142857142857143
def _show_axes_changed(self):<tab>marker = self.marker<tab>if (self._vtk_control is not None) and (marker is not None):<tab><tab><IF-STMT><tab><tab><tab>marker.interactor = None<tab><tab><tab>marker.enabled = False<tab><tab>else:<tab><tab><tab>marker.interactor = self.interactor<tab><tab><tab>marker.enabled = True<tab><tab>self.render(),0,if not self . show_axes :,if self . interactor is None :,0.047631794481620526,13.540372457315735,0.23809523809523808
"def handle_keypress(self, rawKey, modifiers, key, *args):<tab>if self.recordKeyboard and self.__delayPassed():<tab><tab><IF-STMT><tab><tab><tab>self.insideKeys = True<tab><tab><tab>self.targetParent.start_key_sequence()<tab><tab>modifierCount = len(modifiers)<tab><tab>if (<tab><tab><tab>modifierCount > 1<tab><tab><tab>or (modifierCount == 1 and Key.SHIFT not in modifiers)<tab><tab><tab>or (Key.SHIFT in modifiers and len(rawKey) > 1)<tab><tab>):<tab><tab><tab>self.targetParent.append_hotkey(rawKey, modifiers)<tab><tab>elif key not in MODIFIERS:<tab><tab><tab>self.targetParent.append_key(key)",0,if not self . insideKeys :,if key in MODIFIERS :,0.02713659235259708,10.400597689005304,0.25
"def transform(self, data):<tab>with timer(""transform %s"" % self.name, logging.DEBUG):<tab><tab>if self.operator in {""lat"", ""latitude""}:<tab><tab><tab>return self.series(data).apply(GeoIP.get_latitude)<tab><tab><IF-STMT><tab><tab><tab>return self.series(data).apply(GeoIP.get_longitude)<tab><tab>elif self.operator in {""acc"", ""accuracy""}:<tab><tab><tab>return self.series(data).apply(GeoIP.get_accuracy)<tab><tab>raise NameError(""Unknown GeoIP operator [lat, lon, acc]: %s"" % self.operator)",0,"elif self . operator in { ""lon"" , ""longitude"" } :","elif self . operator in { ""lon"" , ""latitude"" } :",0.6209723313682505,80.03203203845001,1.0
"def _get_sidebar_selected(self):<tab>sidebar_selected = None<tab>if self.businessline_id:<tab><tab>sidebar_selected = ""bl_%s"" % self.businessline_id<tab><tab><IF-STMT><tab><tab><tab>sidebar_selected += ""_s_%s"" % self.service_id<tab><tab><tab>if self.environment_id:<tab><tab><tab><tab>sidebar_selected += ""_env_%s"" % self.environment_id<tab>return sidebar_selected",1,if self . service_id :,if self . service_id :,0.75,100.00000000000004,1.0
"def _run_response_middleware(self, request, response, request_name=None):<tab>named_middleware = self.named_response_middleware.get(request_name, deque())<tab>applicable_middleware = self.response_middleware + named_middleware<tab>if applicable_middleware:<tab><tab>for middleware in applicable_middleware:<tab><tab><tab>_response = middleware(request, response)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_response = await _response<tab><tab><tab>if _response:<tab><tab><tab><tab>response = _response<tab><tab><tab><tab>break<tab>return response",0,if isawaitable ( _response ) :,if asyncio . iscoroutine ( _response ) :,0.2908194450899196,46.713797772819994,0.38181818181818183
"def populate_obj(self, obj, name):<tab>field = getattr(obj, name, None)<tab>if field is not None:<tab><tab># If field should be deleted, clean it up<tab><tab>if self._should_delete:<tab><tab><tab>field.delete()<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>if not field.grid_id:<tab><tab><tab><tab>func = field.put<tab><tab><tab>else:<tab><tab><tab><tab>func = field.replace<tab><tab><tab>func(<tab><tab><tab><tab>self.data.stream,<tab><tab><tab><tab>filename=self.data.filename,<tab><tab><tab><tab>content_type=self.data.content_type,<tab><tab><tab>)",0,"if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) :","if hasattr ( field , ""put"" ) :",0.01120497820911098,3.1784032193777274,0.15824915824915825
"def _import_hash(self, operator):<tab># Import required modules into local namespace so that pipelines<tab># may be evaluated directly<tab>for key in sorted(operator.import_hash.keys()):<tab><tab>module_list = "", "".join(sorted(operator.import_hash[key]))<tab><tab><IF-STMT><tab><tab><tab>exec(""from {} import {}"".format(key[4:], module_list))<tab><tab>else:<tab><tab><tab>exec(""from {} import {}"".format(key, module_list))<tab><tab>for var in operator.import_hash[key]:<tab><tab><tab>self.operators_context[var] = eval(var)",0,"if key . startswith ( ""tpot."" ) :","if key . startswith ( ""module_"" ) :",0.5490406812970063,58.77283725105324,1.0
"def remove_files(folder, file_extensions):<tab>for f in os.listdir(folder):<tab><tab>f_path = os.path.join(folder, f)<tab><tab><IF-STMT><tab><tab><tab>extension = os.path.splitext(f_path)[1]<tab><tab><tab>if extension in file_extensions:<tab><tab><tab><tab>os.remove(f_path)",1,if os . path . isfile ( f_path ) :,if os . path . isfile ( f_path ) :,0.75,100.00000000000004,1.0
"def clearBuffer(self):<tab>if self.shouldLose == -1:<tab><tab>return<tab>if self.producer:<tab><tab>self.producer.resumeProducing()<tab>if self.buffer:<tab><tab><IF-STMT><tab><tab><tab>self.logFile.write(""loopback receiving %s\n"" % repr(self.buffer))<tab><tab>buffer = self.buffer<tab><tab>self.buffer = b""""<tab><tab>self.target.dataReceived(buffer)<tab>if self.shouldLose == 1:<tab><tab>self.shouldLose = -1<tab><tab>self.target.connectionLost(failure.Failure(main.CONNECTION_DONE))",1,if self . logFile :,if self . logFile :,0.75,100.00000000000004,1.0
"def write(self, data):<tab>if mock_target._mirror_on_stderr:<tab><tab>if self._write_line:<tab><tab><tab>sys.stderr.write(fn + "": "")<tab><tab>if bytes:<tab><tab><tab>sys.stderr.write(data.decode(""utf8""))<tab><tab>else:<tab><tab><tab>sys.stderr.write(data)<tab><tab><IF-STMT><tab><tab><tab>self._write_line = True<tab><tab>else:<tab><tab><tab>self._write_line = False<tab>super(Buffer, self).write(data)",0,"if ( data [ - 1 ] ) == ""\n"" :","elif isinstance ( data , str ) :",0.02296966020170873,5.4752948205155585,0.13333333333333333
def stop(self):<tab>self.queue_com.state_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.queue_com.state = STOPPED<tab><tab><tab>self.remove()<tab><tab><tab>return True<tab><tab>return False<tab>finally:<tab><tab>self.queue_com.state_lock.release(),0,if self . queue_com . state == RUNNING and self . stop_task ( ) :,if self . queue_com . state == PAUSED :,0.26674767936873056,42.434788372432536,0.5095238095238095
"def _handle_special_args(self, pyobjects):<tab>if len(pyobjects) == len(self.arguments.args):<tab><tab>if self.arguments.vararg:<tab><tab><tab>pyobjects.append(rope.base.builtins.get_list())<tab><tab><IF-STMT><tab><tab><tab>pyobjects.append(rope.base.builtins.get_dict())",0,if self . arguments . kwarg :,elif self . arguments . argdict :,0.20574838742430368,43.47208719449914,0.42857142857142855
"def go_to_last_edit_location(self):<tab>if self.last_edit_cursor_pos is not None:<tab><tab>filename, position = self.last_edit_cursor_pos<tab><tab>if not osp.isfile(filename):<tab><tab><tab>self.last_edit_cursor_pos = None<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>self.load(filename)<tab><tab><tab>editor = self.get_current_editor()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>editor.set_cursor_position(position)",0,if position < editor . document ( ) . characterCount ( ) :,if editor is not None :,0.010091055973079834,3.3264637832151163,0.2222222222222222
"def _create_sentence_objects(self):<tab>""""""Returns a list of Sentence objects from the raw text.""""""<tab>sentence_objects = []<tab>sent_tokenizer = SentenceTokenizer(locale=self.language.code)<tab>seq = Sequence(self.raw)<tab>seq = sent_tokenizer.transform(seq)<tab>for start_index, end_index in zip(seq.idx[:-1], seq.idx[1:]):<tab><tab># Sentences share the same models as their parent blob<tab><tab>sent = seq.text[start_index:end_index].strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>s = Sentence(sent, start_index=start_index, end_index=end_index)<tab><tab>s.detected_languages = self.detected_languages<tab><tab>sentence_objects.append(s)<tab>return sentence_objects",1,if not sent :,if not sent :,0.75,100.00000000000004,1.0
"def to_json_schema(self, parent=None):<tab>schema = {}<tab>if not parent:<tab><tab>schema[""title""] = self.title<tab><tab><IF-STMT><tab><tab><tab>schema[""description""] = self.description<tab><tab>if self.has_default:<tab><tab><tab>schema[""default""] = self.default<tab><tab>schema[""_required_""] = self.required<tab>if self.null:<tab><tab>schema[""type""] = [""string"", ""null""]<tab>else:<tab><tab>schema[""type""] = ""string""<tab>if self.enum is not None:<tab><tab>schema[""enum""] = self.enum<tab>return schema",0,if self . description :,if self . description is not None :,0.3514988343435983,36.55552228545123,0.5102040816326531
def rmdir(dirname):<tab>if dirname[-1] == os.sep:<tab><tab>dirname = dirname[:-1]<tab>if os.path.islink(dirname):<tab><tab>return  # do not clear link - we can get out of dir<tab>for f in os.listdir(dirname):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = dirname + os.sep + f<tab><tab>if os.path.isdir(path):<tab><tab><tab>rmdir(path)<tab><tab>else:<tab><tab><tab>os.unlink(path)<tab>os.rmdir(dirname),0,"if f in ( ""."" , "".."" ) :","if f == ""__init__.py"" :",0.029942750698461862,7.474875887495341,0.7307692307692308
"def convert_whole_dir(path=Path(""marian_ckpt/"")):<tab>for subdir in tqdm(list(path.ls())):<tab><tab>dest_dir = f""marian_converted/{subdir.name}""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>convert(source_dir, dest_dir)",0,"if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :",if not os . path . exists ( dest_dir ) :,0.06979848135464167,20.17182530512868,0.3
"def colorformat(text):<tab>if text[0:1] == ""#"":<tab><tab>col = text[1:]<tab><tab>if len(col) == 6:<tab><tab><tab>return col<tab><tab><IF-STMT><tab><tab><tab>return col[0] * 2 + col[1] * 2 + col[2] * 2<tab>elif text == """":<tab><tab>return """"<tab>assert False, ""wrong color format %r"" % text",1,elif len ( col ) == 3 :,elif len ( col ) == 3 :,0.75,100.00000000000004,1.0
"def _init_rel_seek(self):<tab>""Sets the file object's position to the relative location set above.""<tab>rs, fo = self._rel_seek, self._file_obj<tab>if rs == 0.0:<tab><tab>fo.seek(0, os.SEEK_SET)<tab>else:<tab><tab>fo.seek(0, os.SEEK_END)<tab><tab>size = fo.tell()<tab><tab><IF-STMT><tab><tab><tab>self._cur_pos = size<tab><tab>else:<tab><tab><tab>target = int(size * rs)<tab><tab><tab>fo.seek(target, os.SEEK_SET)<tab><tab><tab>self._align_to_newline()<tab><tab><tab>self._cur_pos = fo.tell()",0,if rs == 1.0 :,if rs == 0.0 :,0.39477865547525276,53.7284965911771,1.0
"def parse_command_line(self, argv=None):<tab>""""""Parse the command line""""""<tab>if self.config:<tab><tab>parser = argparse.ArgumentParser(add_help=False)<tab><tab>self.settings[""config""].add_argument(parser)<tab><tab>opts, _ = parser.parse_known_args(argv)<tab><tab>if opts.config is not None:<tab><tab><tab>self.set(""config"", opts.config)<tab><tab>self.params.update(self.import_from_module())<tab>parser = self.parser()<tab>opts = parser.parse_args(argv)<tab>for k, v in opts.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.set(k.lower(), v)",0,if v is None :,"if k . startswith ( ""_"" ) :",0.026407399022921448,4.990049701936832,0.2698412698412698
"def process(self, resources, event=None):<tab>client = local_session(self.manager.session_factory).client(<tab><tab>""shield"", region_name=""us-east-1""<tab>)<tab>protections = get_type_protections(client, self.manager.get_model())<tab>protected_resources = {p[""ResourceArn""] for p in protections}<tab>state = self.data.get(""state"", False)<tab>results = []<tab>for arn, r in zip(self.manager.get_arns(resources), resources):<tab><tab>r[""c7n:ShieldProtected""] = shielded = arn in protected_resources<tab><tab><IF-STMT><tab><tab><tab>results.append(r)<tab><tab>elif not shielded and not state:<tab><tab><tab>results.append(r)<tab>return results",1,if shielded and state :,if shielded and state :,0.75,100.00000000000004,1.0
"def removeTrailingWs(self, aList):<tab>i = 0<tab>while i < len(aList):<tab><tab><IF-STMT><tab><tab><tab>j = i<tab><tab><tab>i = self.skip_ws(aList, i)<tab><tab><tab>assert j < i<tab><tab><tab>if i >= len(aList) or aList[i] == ""\n"":<tab><tab><tab><tab># print ""removing trailing ws:"", `i-j`<tab><tab><tab><tab>del aList[j:i]<tab><tab><tab><tab>i = j<tab><tab>else:<tab><tab><tab>i += 1",0,if self . is_ws ( aList [ i ] ) :,"if aList [ i ] == ""\r"" :",0.18399274652140313,21.586404366478295,0.38666666666666666
"def predict(request: Request):<tab>form = await request.form()<tab>files, entry = convert_input(form)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return JSONResponse(ALL_FEATURES_PRESENT_ERROR, status_code=400)<tab><tab>try:<tab><tab><tab>resp = model.predict(data_dict=[entry]).to_dict(""records"")[0]<tab><tab><tab>return JSONResponse(resp)<tab><tab>except Exception as e:<tab><tab><tab>logger.error(""Error: {}"".format(str(e)))<tab><tab><tab>return JSONResponse(COULD_NOT_RUN_INFERENCE_ERROR, status_code=500)<tab>finally:<tab><tab>for f in files:<tab><tab><tab>os.remove(f.name)",0,if ( entry . keys ( ) & input_features ) != input_features :,if not entry :,0.008694401990451434,0.6348217867467392,0.4
"def reset(self):<tab>logger.debug(""Arctic.reset()"")<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self.__conn.close()<tab><tab><tab>self.__conn = None<tab><tab>for _, l in self._library_cache.items():<tab><tab><tab>if hasattr(l, ""_reset"") and callable(l._reset):<tab><tab><tab><tab>logger.debug(""Library reset() %s"" % l)<tab><tab><tab><tab>l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",1,if self . __conn is not None :,if self . __conn is not None :,0.75,100.00000000000004,1.0
"def read(self):<tab>if op.isfile(self.fileName):<tab><tab>with textfile_open(self.fileName, ""rt"") as fid:<tab><tab><tab>items = json.load(fid)<tab><tab><tab># TODO: catch JSON exception...<tab><tab><tab><IF-STMT><tab><tab><tab><tab>items = dict()<tab>else:<tab><tab>items = dict()<tab>self._items.clear()<tab>self._items.update(items)<tab>self._haveReadData = True",0,if items is None :,if len ( items ) == 0 :,0.028001459970687266,6.27465531099474,0.2857142857142857
"def get_django_comment(text: str, i: int) -> str:<tab>end = i + 4<tab>unclosed_end = 0<tab>while end <= len(text):<tab><tab>if text[end - 2 : end] == ""#}"":<tab><tab><tab>return text[i:end]<tab><tab><IF-STMT><tab><tab><tab>unclosed_end = end<tab><tab>end += 1<tab>raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])",0,"if not unclosed_end and text [ end ] == ""<"" :",if unclosed_end == 0 :,0.013055717236343255,10.343690622931698,0.2571428571428572
"def _wrap_forwarded(self, key, value):<tab>if isinstance(value, SourceCode) and value.late_binding:<tab><tab># get cached return value if present<tab><tab>value_ = self._late_binding_returnvalues.get(key, KeyError)<tab><tab><IF-STMT><tab><tab><tab># evaluate the late-bound function<tab><tab><tab>value_ = self._eval_late_binding(value)<tab><tab><tab>schema = self.late_bind_schemas.get(key)<tab><tab><tab>if schema is not None:<tab><tab><tab><tab>value_ = schema.validate(value_)<tab><tab><tab># cache result of late bound func<tab><tab><tab>self._late_binding_returnvalues[key] = value_<tab><tab>return value_<tab>else:<tab><tab>return value",0,if value_ is KeyError :,if value_ is None :,0.39477865547525276,53.7284965911771,0.6
"def connect(*args, **ckwargs):<tab>if ""give_content_type"" in kwargs:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""give_content_type""](args[6][""content-type""])<tab><tab>else:<tab><tab><tab>kwargs[""give_content_type""]("""")<tab>if ""give_connect"" in kwargs:<tab><tab>kwargs[""give_connect""](*args, **ckwargs)<tab>status = code_iter.next()<tab>etag = etag_iter.next()<tab>timestamp = timestamps_iter.next()<tab>if status == -1:<tab><tab>raise HTTPException()<tab>return FakeConn(status, etag, body=kwargs.get(""body"", """"), timestamp=timestamp)",0,"if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :","if args [ 6 ] [ ""content-type"" ] :",0.09794459074207762,13.229147212652599,0.21710526315789475
"def _reset(self):<tab>self._handle_connect()<tab>if self.rewarder_session:<tab><tab><IF-STMT><tab><tab><tab>env_id = random.choice(self._sample_env_ids)<tab><tab><tab>logger.info(""Randomly sampled env_id={}"".format(env_id))<tab><tab>else:<tab><tab><tab>env_id = None<tab><tab>self.rewarder_session.reset(env_id=env_id)<tab>else:<tab><tab>logger.info(<tab><tab><tab>""No rewarder session exists, so cannot send a reset via the rewarder channel""<tab><tab>)<tab>self._reset_mask()<tab>return [None] * self.n",0,if self . _sample_env_ids :,if self . _sample_env_ids is not None :,0.3514988343435983,66.52049901111006,0.4444444444444444
"def _create_architecture_list(architectures, current_arch):<tab>if not architectures:<tab><tab>return [_Architecture(build_on=[current_arch])]<tab>build_architectures: List[str] = []<tab>architecture_list: List[_Architecture] = []<tab>for item in architectures:<tab><tab>if isinstance(item, str):<tab><tab><tab>build_architectures.append(item)<tab><tab><IF-STMT><tab><tab><tab>architecture_list.append(<tab><tab><tab><tab>_Architecture(build_on=item.get(""build-on""), run_on=item.get(""run-on""))<tab><tab><tab>)<tab>if build_architectures:<tab><tab>architecture_list.append(_Architecture(build_on=build_architectures))<tab>return architecture_list",0,"if isinstance ( item , dict ) :","elif isinstance ( item , dict ) :",0.40018302522632676,84.08964152537145,0.6666666666666666
"def inspect(self, pokemon):<tab># Make sure it was not caught!<tab>for caught_pokemon in self.cache:<tab><tab>same_latitude = ""{0:.4f}"".format(pokemon[""latitude""]) == ""{0:.4f}"".format(<tab><tab><tab>caught_pokemon[""latitude""]<tab><tab>)<tab><tab>same_longitude = ""{0:.4f}"".format(pokemon[""longitude""]) == ""{0:.4f}"".format(<tab><tab><tab>caught_pokemon[""longitude""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return<tab>if len(self.cache) >= 200:<tab><tab>self.cache.pop(0)<tab>self.cache.append(pokemon)",0,if same_latitude and same_longitude :,if same_latitude and not same_longitude :,0.2721091316413796,65.80370064762461,0.7142857142857143
"def parley(self):<tab>for x in [0, 1]:<tab><tab>a = self.agents[x].act()<tab><tab><IF-STMT><tab><tab><tab>if ""[DONE]"" in a[""text""]:<tab><tab><tab><tab>self.agents[x - 1].observe(<tab><tab><tab><tab><tab>{""id"": ""World"", ""text"": ""The other agent has ended the chat.""}<tab><tab><tab><tab>)<tab><tab><tab><tab>self.episodeDone = True<tab><tab><tab>else:<tab><tab><tab><tab>self.agents[x - 1].observe(a)",0,if a is not None :,"if a [ ""id"" ] == ""World"" :",0.04223373009149452,6.837203339116283,0.4444444444444444
"def _prepare_subset(<tab>full_data: torch.Tensor,<tab>full_targets: torch.Tensor,<tab>num_samples: int,<tab>digits: Sequence,):<tab>classes = {d: 0 for d in digits}<tab>indexes = []<tab>for idx, target in enumerate(full_targets):<tab><tab>label = target.item()<tab><tab>if classes.get(label, float(""inf"")) >= num_samples:<tab><tab><tab>continue<tab><tab>indexes.append(idx)<tab><tab>classes[label] += 1<tab><tab><IF-STMT><tab><tab><tab>break<tab>data = full_data[indexes]<tab>targets = full_targets[indexes]<tab>return data, targets",0,if all ( classes [ k ] >= num_samples for k in classes ) :,if classes [ label ] >= num_samples :,0.09210295628634425,29.059130342609063,0.21710526315789475
"def get_work_root(self, flags):<tab>_flags = flags.copy()<tab>_flags[""is_toplevel""] = True<tab>target = self._get_target(_flags)<tab>if target:<tab><tab>_flags[""target""] = target.name<tab><tab>tool = self.get_tool(_flags)<tab><tab><IF-STMT><tab><tab><tab>return target.name + ""-"" + tool<tab><tab>else:<tab><tab><tab>raise SyntaxError(<tab><tab><tab><tab>""Failed to determine work root. Could not resolve tool for target ""<tab><tab><tab><tab>+ target.name<tab><tab><tab>)<tab>else:<tab><tab>raise SyntaxError(""Failed to determine work root. Could not resolve target"")",1,if tool :,if tool :,0.5311706625951745,1e-10,1.0
"def run_command(self, data):<tab>""""""Run editor commands.""""""<tab>parts = data.split("" "")<tab>cmd = parts[0].lower()<tab>if cmd in self.operations.keys():<tab><tab>return self.run_operation(cmd)<tab>args = "" "".join(parts[1:])<tab>self.logger.debug(""Looking for command '{0}'"".format(cmd))<tab>if cmd in self.modules.modules.keys():<tab><tab>self.logger.debug(""Trying to run command '{0}'"".format(cmd))<tab><tab>self.get_editor().store_action_state(cmd)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>else:<tab><tab>self.set_status(""Command '{0}' not found."".format(cmd))<tab><tab>return False<tab>return True",0,"if not self . run_module ( cmd , args ) :",elif cmd in self . modules . modules :,0.02303985184826439,7.270717733704594,0.10101010101010101
"def get_main_chain_layers(self):<tab>""""""Return a list of layer IDs in the main chain.""""""<tab>main_chain = self.get_main_chain()<tab>ret = []<tab>for u in main_chain:<tab><tab>for v, layer_id in self.adj_list[u]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(layer_id)<tab>return ret",0,if v in main_chain and u in main_chain :,if layer_id not in ret :,0.19561338086197916,4.18031138310865,0.3020833333333333
"def hash(self, context):<tab>with context:<tab><tab><IF-STMT><tab><tab><tab>return IECore.MurmurHash()<tab><tab>h = GafferDispatch.TaskNode.hash(self, context)<tab><tab>h.append(self[""fileName""].hash())<tab><tab>h.append(self[""in""].hash())<tab><tab>h.append(self.__parameterHandler.hash())<tab><tab>return h",0,"if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :",if self . __parameterHandler is None :,0.0039617219902578675,0.5235532762795567,0.2105263157894737
"def consume_buf():<tab>ty = state[""ty""] - 1<tab>for i in xrange(state[""buf""].shape[1] // N):<tab><tab>tx = x // N + i<tab><tab>src = state[""buf""][:, i * N : (i + 1) * N, :]<tab><tab><IF-STMT><tab><tab><tab>with self.tile_request(tx, ty, readonly=False) as dst:<tab><tab><tab><tab>mypaintlib.tile_convert_rgba8_to_rgba16(src, dst, self.EOTF)<tab>if state[""progress""]:<tab><tab>try:<tab><tab><tab>state[""progress""].completed(ty - ty0)<tab><tab>except Exception:<tab><tab><tab>logger.exception(""Progress.completed() failed"")<tab><tab><tab>state[""progress""] = None",0,"if src [ : , : , 3 ] . any ( ) :",if self . tile_request :,0.008376751410488981,3.1795892263857453,0.3181818181818182
"def check_permissions(self, obj):<tab>request = self.context.get(""request"")<tab>for Perm in permissions:<tab><tab>perm = Perm()<tab><tab>if not perm.has_permission(request, self):<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",0,"if not perm . has_object_permission ( request , self , obj ) :","if not perm . has_access ( request , obj ) :",0.2981732932805182,48.901978132725134,0.7047619047619048
"def _post_order(op):<tab>if isinstance(op, tvm.tir.Allocate):<tab><tab>lift_stmt[-1].append(op)<tab><tab>return op.body<tab>if isinstance(op, tvm.tir.AttrStmt):<tab><tab>if op.attr_key == ""storage_scope"":<tab><tab><tab>lift_stmt[-1].append(op)<tab><tab><tab>return op.body<tab><tab><IF-STMT><tab><tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab><tab>return op<tab>if isinstance(op, tvm.tir.For):<tab><tab>return _merge_block(lift_stmt.pop() + [op], op.body)<tab>raise RuntimeError(""not reached"")",0,"if op . attr_key == ""virtual_thread"" :","if isinstance ( op , tvm . tir . For ) :",0.08092634817706429,4.053997537205932,0.25
"def task_done(self):<tab>with self._cond:<tab><tab>if not self._unfinished_tasks.acquire(False):<tab><tab><tab>raise ValueError(""task_done() called too many times"")<tab><tab><IF-STMT><tab><tab><tab>self._cond.notify_all()",0,if self . _unfinished_tasks . _semlock . _is_zero ( ) :,if self . _unfinished_tasks . acquire ( False ) :,0.25415939867425624,42.63196214931616,0.575
"def get_json(self):<tab>if not hasattr(self, ""_json""):<tab><tab>self._json = None<tab><tab><IF-STMT><tab><tab><tab>self._json = json.loads(self.request.body)<tab>return self._json",0,"if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :","if self . request . method == ""POST"" :",0.15466024613505475,11.10310128232865,0.4910714285714286
"def userfullname():<tab>""""""Get the user's full name.""""""<tab>global _userfullname<tab><IF-STMT><tab><tab>uid = os.getuid()<tab><tab>entry = pwd_from_uid(uid)<tab><tab>if entry:<tab><tab><tab>_userfullname = entry[4].split("","")[0] or entry[0]<tab><tab>if not _userfullname:<tab><tab><tab>_userfullname = ""user%d"" % uid<tab>return _userfullname",1,if not _userfullname :,if not _userfullname :,0.75,100.00000000000004,1.0
"def test_scatter(self):<tab>for rank in range(self.world_size):<tab><tab>tensor = []<tab><tab><IF-STMT><tab><tab><tab>tensor = [torch.tensor(i) for i in range(self.world_size)]<tab><tab>result = comm.get().scatter(tensor, rank, size=())<tab><tab>self.assertTrue(torch.is_tensor(result))<tab><tab>self.assertEqual(result.item(), self.rank)",0,if self . rank == rank :,if rank % 2 == 0 :,0.024082656944055907,13.888095170058955,0.3333333333333333
"def decompile(decompiler):<tab>for pos, next_pos, opname, arg in decompiler.instructions:<tab><tab>if pos in decompiler.targets:<tab><tab><tab>decompiler.process_target(pos)<tab><tab>method = getattr(decompiler, opname, None)<tab><tab>if method is None:<tab><tab><tab>throw(DecompileError(""Unsupported operation: %s"" % opname))<tab><tab>decompiler.pos = pos<tab><tab>decompiler.next_pos = next_pos<tab><tab>x = method(*arg)<tab><tab><IF-STMT><tab><tab><tab>decompiler.stack.append(x)",1,if x is not None :,if x is not None :,0.75,100.00000000000004,1.0
"def print_scenario_ran(self, scenario):<tab>if scenario.passed:<tab><tab>self.wrt(""OK"")<tab>elif scenario.failed:<tab><tab>reason = self.scenarios_and_its_fails[scenario]<tab><tab><IF-STMT><tab><tab><tab>self.wrt(""FAILED"")<tab><tab>else:<tab><tab><tab>self.wrt(""ERROR"")<tab>self.wrt(""\n"")",0,"if isinstance ( reason . exception , AssertionError ) :",if reason is not None :,0.01478624383023101,5.484411595600381,0.2222222222222222
"def detect_ssl_option(self):<tab>for option in self.ssl_options():<tab><tab>if scan_argv(self.argv, option) is not None:<tab><tab><tab>for other_option in self.ssl_options():<tab><tab><tab><tab>if option != other_option:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>raise ConfigurationError(<tab><tab><tab><tab><tab><tab><tab>""Cannot give both %s and %s"" % (option, other_option)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab>return option",0,"if scan_argv ( self . argv , other_option ) is not None :",if option != other_option :,0.009477309133734894,7.582874853312503,0.2222222222222222
"def print_po_snippet(en_loc_old_lists, context):<tab>for m, localized, old in zip(*en_loc_old_lists):<tab><tab>if m == """":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>localized = old<tab><tab>print(<tab><tab><tab>""#: {file}:{line}\n""<tab><tab><tab>'msgid ""{context}{en_month}""\n'<tab><tab><tab>'msgstr ""{localized_month}""\n'.format(<tab><tab><tab><tab>context=context,<tab><tab><tab><tab>file=filename,<tab><tab><tab><tab>line=print_po_snippet.line,<tab><tab><tab><tab>en_month=m,<tab><tab><tab><tab>localized_month=localized,<tab><tab><tab>)<tab><tab>)<tab><tab>print_po_snippet.line += 1",0,if m == localized :,if localized == m :,0.2901714209472326,21.3643503198117,0.5
"def set_status(self, dict_new):<tab>for i, value in dict_new.items():<tab><tab>self.dict_bili[i] = value<tab><tab><IF-STMT><tab><tab><tab>self.dict_bili[""pcheaders""][""cookie""] = value<tab><tab><tab>self.dict_bili[""appheaders""][""cookie""] = value",0,"if i == ""cookie"" :","if ""pcheaders"" in self . dict_bili :",0.027969854500399755,5.300156689756295,0.37777777777777777
"def makeSomeFiles(pathobj, dirdict):<tab>pathdict = {}<tab>for (key, value) in dirdict.items():<tab><tab>child = pathobj.child(key)<tab><tab><IF-STMT><tab><tab><tab>pathdict[key] = child<tab><tab><tab>child.setContent(value)<tab><tab>elif isinstance(value, dict):<tab><tab><tab>child.createDirectory()<tab><tab><tab>pathdict[key] = makeSomeFiles(child, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""only strings and dicts allowed as values"")<tab>return pathdict",0,"if isinstance ( value , bytes ) :","if isinstance ( value , str ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def _truncate_to_length(generator, len_map=None):<tab>for example in generator:<tab><tab>example = list(example)<tab><tab>if len_map is not None:<tab><tab><tab>for key, max_len in len_map.items():<tab><tab><tab><tab>example_len = example[key].shape<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>example[key] = np.resize(example[key], max_len)<tab><tab>yield tuple(example)",1,if example_len > max_len :,if example_len > max_len :,0.75,100.00000000000004,1.0
"def check(self, **kw):<tab>if not kw:<tab><tab>return exists(self.strpath)<tab>if len(kw) == 1:<tab><tab>if ""dir"" in kw:<tab><tab><tab>return not kw[""dir""] ^ isdir(self.strpath)<tab><tab><IF-STMT><tab><tab><tab>return not kw[""file""] ^ isfile(self.strpath)<tab>return super(LocalPath, self).check(**kw)",1,"if ""file"" in kw :","if ""file"" in kw :",0.75,100.00000000000004,1.0
"def next_instruction_is_function_or_class(lines):<tab>""""""Is the first non-empty, non-commented line of the cell either a function or a class?""""""<tab>parser = StringParser(""python"")<tab>for i, line in enumerate(lines):<tab><tab>if parser.is_quoted():<tab><tab><tab>parser.read_line(line)<tab><tab><tab>continue<tab><tab>parser.read_line(line)<tab><tab>if not line.strip():  # empty line<tab><tab><tab>if i > 0 and not lines[i - 1].strip():<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>if line.startswith(""def "") or line.startswith(""class ""):<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>return False<tab>return False",0,"if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :","if line . startswith ( ""function "" ) :",0.12136695317816781,14.262067559546713,1.0
"def askCheckReadFile(self, localFile, remoteFile):<tab>if not kb.bruteMode:<tab><tab>message = ""do you want confirmation that the remote file '%s' "" % remoteFile<tab><tab>message += ""has been successfully downloaded from the back-end ""<tab><tab>message += ""DBMS file system? [Y/n] ""<tab><tab><IF-STMT><tab><tab><tab>return self._checkFileLength(localFile, remoteFile, True)<tab>return None",0,"if readInput ( message , default = ""Y"" , boolean = True ) :","if message == ""Y/n"" :",0.007897657894486383,10.954389364441846,0.2571428571428572
"def process_tag(hive_name, company, company_key, tag, default_arch):<tab>with winreg.OpenKeyEx(company_key, tag) as tag_key:<tab><tab>version = load_version_data(hive_name, company, tag, tag_key)<tab><tab>if version is not None:  # if failed to get version bail<tab><tab><tab>major, minor, _ = version<tab><tab><tab>arch = load_arch_data(hive_name, company, tag, tag_key, default_arch)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>exe_data = load_exe(hive_name, company, company_key, tag)<tab><tab><tab><tab>if exe_data is not None:<tab><tab><tab><tab><tab>exe, args = exe_data<tab><tab><tab><tab><tab>return company, major, minor, arch, exe, args",1,if arch is not None :,if arch is not None :,0.75,100.00000000000004,1.0
"def _get_matching_bracket(self, s, pos):<tab>if s[pos] != ""{"":<tab><tab>return None<tab>end = len(s)<tab>depth = 1<tab>pos += 1<tab>while pos != end:<tab><tab>c = s[pos]<tab><tab>if c == ""{"":<tab><tab><tab>depth += 1<tab><tab><IF-STMT><tab><tab><tab>depth -= 1<tab><tab>if depth == 0:<tab><tab><tab>break<tab><tab>pos += 1<tab>if pos < end and s[pos] == ""}"":<tab><tab>return pos<tab>return None",1,"elif c == ""}"" :","elif c == ""}"" :",1.0,100.00000000000004,1.0
"def pred(field, value, item):<tab>for suffix, p in _BUILTIN_PREDS.iteritems():<tab><tab>if field.endswith(suffix):<tab><tab><tab>f = field[: field.index(suffix)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>return p(getattr(item, f), value)<tab>if not hasattr(item, field) or getattr(item, field) is None:<tab><tab>return False<tab>if isinstance(value, type(lambda x: x)):<tab><tab>return value(getattr(item, field))<tab>return getattr(item, field) == value",0,"if not hasattr ( item , f ) or getattr ( item , f ) is None :","if not hasattr ( item , f ) :",0.31117632875396495,32.70962178059004,0.5033333333333333
"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for _, m in self.multi_deconv_layers.named_modules():<tab><tab>if isinstance(m, nn.ConvTranspose2d):<tab><tab><tab>normal_init(m, std=0.001)<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>constant_init(m, 1)<tab>for m in self.multi_final_layers.modules():<tab><tab><IF-STMT><tab><tab><tab>normal_init(m, std=0.001, bias=0)",0,"if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . Linear ) :",0.6049399806880458,70.71067811865478,0.7142857142857143
"def test_byteswap(self):<tab>if self.typecode == ""u"":<tab><tab>example = ""\U00100100""<tab>else:<tab><tab>example = self.example<tab>a = array.array(self.typecode, example)<tab>self.assertRaises(TypeError, a.byteswap, 42)<tab>if a.itemsize in (1, 2, 4, 8):<tab><tab>b = array.array(self.typecode, example)<tab><tab>b.byteswap()<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(a, b)<tab><tab>else:<tab><tab><tab>self.assertNotEqual(a, b)<tab><tab>b.byteswap()<tab><tab>self.assertEqual(a, b)",0,if a . itemsize == 1 :,elif a . itemsize == 1 :,0.3829408981789566,84.08964152537145,0.6666666666666666
"def _remove_blocks_from_variables(variables):<tab>new_variables = []<tab>for name, variable in variables:<tab><tab><IF-STMT><tab><tab><tab>new_variables.extend(variable.locals)<tab><tab><tab>new_variables.append((name, variable.result))<tab><tab>else:<tab><tab><tab>new_variables.append((name, variable))<tab>return new_variables",0,if variable . is_block ( ) :,"if isinstance ( variable , Block ) :",0.04118257290339881,12.256200970377108,0.36
def scope(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.scope_ is None:<tab><tab><tab><tab>self.scope_ = Scope()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.scope_,1,if self . scope_ is None :,if self . scope_ is None :,0.75,100.00000000000004,1.0
"def translate():<tab>assert Lex.next() is AttributeList<tab>reader.read()  # Discard attribute list from reader.<tab>attrs = {}<tab>d = AttributeList.match.groupdict()<tab>for k, v in d.items():<tab><tab>if v is not None:<tab><tab><tab>if k == ""attrlist"":<tab><tab><tab><tab>v = subs_attrs(v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>parse_attributes(v, attrs)<tab><tab><tab>else:<tab><tab><tab><tab>AttributeList.attrs[k] = v<tab>AttributeList.subs(attrs)<tab>AttributeList.attrs.update(attrs)",0,if v :,"elif k == ""attributes"" :",0.03641519202841723,1e-10,0.2
"def parse(self, response):<tab>try:<tab><tab>content = response.content.decode(""utf-8"", ""ignore"")<tab><tab>content = json.loads(content, strict=False)<tab>except:<tab><tab>self.logger.error(""Fail to parse the response in json format"")<tab><tab>return<tab>for item in content[""data""]:<tab><tab><IF-STMT><tab><tab><tab>img_url = self._decode_url(item[""objURL""])<tab><tab>elif ""hoverURL"" in item:<tab><tab><tab>img_url = item[""hoverURL""]<tab><tab>else:<tab><tab><tab>continue<tab><tab>yield dict(file_url=img_url)",1,"if ""objURL"" in item :","if ""objURL"" in item :",0.75,100.00000000000004,1.0
"def canonicalize_instruction_name(instr):<tab>name = instr.insn_name().upper()<tab># XXX bypass a capstone bug that incorrectly labels some insns as mov<tab>if name == ""MOV"":<tab><tab>if instr.mnemonic.startswith(""lsr""):<tab><tab><tab>return ""LSR""<tab><tab>elif instr.mnemonic.startswith(""lsl""):<tab><tab><tab>return ""LSL""<tab><tab><IF-STMT><tab><tab><tab>return ""ASR""<tab>return OP_NAME_MAP.get(name, name)",1,"elif instr . mnemonic . startswith ( ""asr"" ) :","elif instr . mnemonic . startswith ( ""asr"" ) :",0.75,100.00000000000004,1.0
"def _clean_regions(items, region):<tab>""""""Intersect region with target file if it exists""""""<tab>variant_regions = bedutils.population_variant_regions(items, merged=True)<tab>with utils.tmpfile() as tx_out_file:<tab><tab>target = subset_variant_regions(variant_regions, region, tx_out_file, items)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(target, six.string_types) and os.path.isfile(target):<tab><tab><tab><tab>target = _load_regions(target)<tab><tab><tab>else:<tab><tab><tab><tab>target = [target]<tab><tab><tab>return target",0,if target :,if target is not None :,0.09036476851692153,1e-10,0.39999999999999997
def reader_leaves(self):<tab>self.mutex.acquire()<tab>try:<tab><tab>self.active_readers -= 1<tab><tab><IF-STMT><tab><tab><tab>self.active_writers += 1<tab><tab><tab>self.waiting_writers -= 1<tab><tab><tab>self.can_write.release()<tab>finally:<tab><tab>self.mutex.release(),0,if self . active_readers == 0 and self . waiting_writers != 0 :,if self . active_readers == 0 and self . waiting_writers == 0 :,0.8250670785908863,84.92326635760686,1.0
"def _bpe_to_words(sentence, delimiter=""@@""):<tab>""""""Convert a sequence of bpe words into sentence.""""""<tab>words = []<tab>word = """"<tab>delimiter_len = len(delimiter)<tab>for subwords in sentence:<tab><tab><IF-STMT><tab><tab><tab>word += subwords[:-delimiter_len]<tab><tab>else:<tab><tab><tab>word += subwords<tab><tab><tab>words.append(word)<tab><tab><tab>word = """"<tab>return words",0,if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,if len ( subwords ) > delimiter_len :,0.16363745948652983,21.410896227989312,0.591111111111111
"def _make_var_names(exog):<tab>if hasattr(exog, ""name""):<tab><tab>var_names = exog.name<tab>elif hasattr(exog, ""columns""):<tab><tab>var_names = exog.columns<tab>else:<tab><tab>raise ValueError(""exog is not a Series or DataFrame or is unnamed."")<tab>try:<tab><tab>var_names = "" "".join(var_names)<tab>except TypeError:  # cannot have names that are numbers, pandas default<tab><tab>from statsmodels.base.data import _make_exog_names<tab><tab><IF-STMT><tab><tab><tab>var_names = ""x1""<tab><tab>else:<tab><tab><tab>var_names = "" "".join(_make_exog_names(exog))<tab>return var_names",0,if exog . ndim == 1 :,"if isinstance ( exog , np . ndarray ) :",0.08236607224087547,5.934202609760488,0.23863636363636365
"def __start_element_handler(self, name, attrs):<tab>if name == ""mime-type"":<tab><tab><IF-STMT><tab><tab><tab>for extension in self.extensions:<tab><tab><tab><tab>self[extension] = self.type<tab><tab>self.type = attrs[""type""].lower()<tab><tab>self.extensions = []<tab>elif name == ""glob"":<tab><tab>pattern = attrs[""pattern""]<tab><tab>if pattern.startswith(""*.""):<tab><tab><tab>self.extensions.append(pattern[1:].lower())",0,if self . type :,if self . extensions :,0.39477865547525276,42.72870063962342,0.6
"def nodes(self, id=None, name=None):<tab>for node_dict in self.node_ls(id=id, name=name):<tab><tab>node_id = node_dict[""ID""]<tab><tab>node = DockerNode(self, node_id, inspect=node_dict)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield node",0,if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,if node . is_valid ( ) :,0.016807938853821838,3.2737451753202267,0.21875
"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab>if type(e) is Argument or type(e) is Option and e.argcount:<tab><tab><tab><tab>if e.value is None:<tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab>elif type(e.value) is not list:<tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>e.value = 0<tab>return self",0,if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 :,elif type ( e ) is Option and e . argcount == 0 :,0.4531847661466543,58.03027094519479,0.20584795321637425
"def vi_search(self, rng):<tab>for i in rng:<tab><tab>line_history = self._history.history[i]<tab><tab>pos = line_history.get_line_text().find(self._vi_search_text)<tab><tab><IF-STMT><tab><tab><tab>self._history.history_cursor = i<tab><tab><tab>self.l_buffer.line_buffer = list(line_history.line_buffer)<tab><tab><tab>self.l_buffer.point = pos<tab><tab><tab>self.vi_undo_restart()<tab><tab><tab>return True<tab>self._bell()<tab>return False",0,if pos >= 0 :,if pos != - 1 :,0.0574290063711522,15.619699684601283,0.6
"def visitIf(self, node, scope):<tab>for test, body in node.tests:<tab><tab><IF-STMT><tab><tab><tab>if type(test.value) in self._const_types:<tab><tab><tab><tab>if not test.value:<tab><tab><tab><tab><tab>continue<tab><tab>self.visit(test, scope)<tab><tab>self.visit(body, scope)<tab>if node.else_:<tab><tab>self.visit(node.else_, scope)",0,"if isinstance ( test , ast . Const ) :","if isinstance ( test , ast . If ) :",0.6049399806880458,70.71067811865478,0.7777777777777777
"def collect(self):<tab>for nickname in self.squid_hosts.keys():<tab><tab>squid_host = self.squid_hosts[nickname]<tab><tab>fulldata = self._getData(squid_host[""host""], squid_host[""port""])<tab><tab><IF-STMT><tab><tab><tab>fulldata = fulldata.splitlines()<tab><tab><tab>for data in fulldata:<tab><tab><tab><tab>matches = self.stat_pattern.match(data)<tab><tab><tab><tab>if matches:<tab><tab><tab><tab><tab>self.publish_counter(<tab><tab><tab><tab><tab><tab>""%s.%s"" % (nickname, matches.group(1)), float(matches.group(2))<tab><tab><tab><tab><tab>)",0,if fulldata is not None :,if fulldata :,0.050438393472541504,1e-10,0.39999999999999997
"def convert(x, base, exponents):<tab>out = []<tab>for e in exponents:<tab><tab>d = int(x / (base ** e))<tab><tab>x -= d * (base ** e)<tab><tab>out.append(digits[d])<tab><tab><IF-STMT><tab><tab><tab>break<tab>return out",0,if x == 0 and e < 0 :,if d == 0 :,0.08749927568871112,19.505632433269746,0.3333333333333333
"def print_doc(manager, options):<tab>plugin_name = options.doc<tab>plugin = plugins.get(plugin_name, None)<tab>if plugin:<tab><tab><IF-STMT><tab><tab><tab>console(""Plugin %s does not have documentation"" % plugin_name)<tab><tab>else:<tab><tab><tab>console("""")<tab><tab><tab>console(trim(plugin.instance.__doc__))<tab><tab><tab>console("""")<tab>else:<tab><tab>console(""Could not find plugin %s"" % plugin_name)",0,if not plugin . instance . __doc__ :,if plugin . instance . __doc__ is None :,0.2636028267164803,68.12455364200612,0.2698412698412698
"def _set_attrs(self, attrs):<tab>for attr in self.ATTRS:<tab><tab>if attr in attrs:<tab><tab><tab>setattr(self, attr, attrs[attr])<tab><tab><tab>del attrs[attr]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(self, attr, NO_DEFAULT)<tab><tab><tab>else:<tab><tab><tab><tab>setattr(self, attr, None)<tab>if attrs:<tab><tab>attrs = sorted(attrs.keys())<tab><tab>raise OptionError(""invalid keyword arguments: %s"" % "", "".join(attrs), self)",1,"if attr == ""default"" :","if attr == ""default"" :",0.75,100.00000000000004,1.0
"def _get_set_scope(<tab>ir_set: irast.Set, scope_tree: irast.ScopeTreeNode) -> irast.ScopeTreeNode:<tab>if ir_set.path_scope_id:<tab><tab>new_scope = scope_tree.root.find_by_unique_id(ir_set.path_scope_id)<tab><tab><IF-STMT><tab><tab><tab>raise errors.InternalServerError(<tab><tab><tab><tab>f""dangling scope pointer to node with uid""<tab><tab><tab><tab>f"":{ir_set.path_scope_id} in {ir_set!r}""<tab><tab><tab>)<tab>else:<tab><tab>new_scope = scope_tree<tab>return new_scope",1,if new_scope is None :,if new_scope is None :,0.75,100.00000000000004,1.0
"def test_leave_one_out(self):<tab>correct = 0<tab>k = 3<tab>model = kNN.train(xs, ys, k)<tab>predictions = [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1]<tab>for i in range(len(predictions)):<tab><tab>model = kNN.train(xs[:i] + xs[i + 1 :], ys[:i] + ys[i + 1 :], k)<tab><tab>prediction = kNN.classify(model, xs[i])<tab><tab>self.assertEqual(prediction, predictions[i])<tab><tab><IF-STMT><tab><tab><tab>correct += 1<tab>self.assertEqual(correct, 13)",0,if prediction == ys [ i ] :,if i % 2 == 0 :,0.020676460041600547,12.256200970377108,0.2857142857142857
"def import_files(self, files):<tab>""""""Import a list of MORE (.csv) files.""""""<tab>c = self.c<tab>if files:<tab><tab>changed = False<tab><tab>self.tab_width = c.getTabWidth(c.p)<tab><tab>for fileName in files:<tab><tab><tab>g.setGlobalOpenDir(fileName)<tab><tab><tab>p = self.import_file(fileName)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p.contract()<tab><tab><tab><tab>p.setDirty()<tab><tab><tab><tab>c.setChanged(True)<tab><tab><tab><tab>changed = True<tab><tab>if changed:<tab><tab><tab>c.redraw(p)",0,if p :,if self . contract :,0.051944022748897464,1e-10,0.36
"def getPageTemplate(payload, place):<tab>retVal = (kb.originalPage, kb.errorIsNone)<tab>if payload and place:<tab><tab><IF-STMT><tab><tab><tab>page, _, _ = Request.queryPage(payload, place, content=True, raise404=False)<tab><tab><tab>kb.pageTemplates[(payload, place)] = (page, kb.lastParserStatus is None)<tab><tab>retVal = kb.pageTemplates[(payload, place)]<tab>return retVal",1,"if ( payload , place ) not in kb . pageTemplates :","if ( payload , place ) not in kb . pageTemplates :",0.75,100.00000000000004,1.0
"def _skip_trivial(constraint_data):<tab>if skip_trivial_constraints:<tab><tab>if isinstance(constraint_data, LinearCanonicalRepn):<tab><tab><tab>if constraint_data.variables is None:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,if constraint_data . body . polynomial_degree ( ) == 0 :,"if isinstance ( constraint_data . variables , LinearCanonicalRepn ) :",0.06874471782983438,18.065141676274923,0.2761904761904762
"def get_unique_attribute(self, name: str):<tab>feat = None<tab>for f in self.features:<tab><tab>if self._return_feature(f) and hasattr(f, name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise RuntimeError(""The attribute was not unique."")<tab><tab><tab>feat = f<tab>if feat is None:<tab><tab>raise RuntimeError(""The attribute did not exist"")<tab>return getattr(feat, name)",0,if feat is not None :,if f . unique :,0.02713659235259708,10.400597689005304,0.1875
"def hideEvent(self, event):<tab>""""""Reimplement Qt method""""""<tab>if not self.light:<tab><tab>for plugin in self.widgetlist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>plugin.visibility_changed(True)<tab>QMainWindow.hideEvent(self, event)",0,if plugin . isAncestorOf ( self . last_focused_widget ) :,"if hasattr ( plugin , ""visibility_changed"" ) :",0.029321108690485986,7.545339613823573,0.32051282051282054
"def move_stdout_to_stderr(self):<tab>to_remove = []<tab>to_add = []<tab>for consumer_level, consumer in self.consumers:<tab><tab><IF-STMT><tab><tab><tab>to_remove.append((consumer_level, consumer))<tab><tab><tab>to_add.append((consumer_level, sys.stderr))<tab>for item in to_remove:<tab><tab>self.consumers.remove(item)<tab>self.consumers.extend(to_add)",0,if consumer == sys . stdout :,if consumer not in sys . stdout :,0.226825479233639,41.11336169005198,0.38095238095238093
"def create(exported_python_target):<tab>if exported_python_target not in created:<tab><tab>self.context.log.info(<tab><tab><tab>""Creating setup.py project for {}"".format(exported_python_target)<tab><tab>)<tab><tab>subject = self.derived_by_original.get(<tab><tab><tab>exported_python_target, exported_python_target<tab><tab>)<tab><tab>setup_dir, dependencies = self.create_setup_py(subject, dist_dir)<tab><tab>created[exported_python_target] = setup_dir<tab><tab><IF-STMT><tab><tab><tab>for dep in dependencies:<tab><tab><tab><tab>if is_exported_python_target(dep):<tab><tab><tab><tab><tab>create(dep)",0,if self . _recursive :,if dependencies :,0.03549272049582243,1e-10,0.5
"def __add__(self, other):<tab>other = ArithmeticExpression.try_unpack_const(other)<tab>if not self.symbolic and type(other) is int:<tab><tab>return SpOffset(self._bits, self._to_signed(self.offset + other))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return SpOffset(self._bits, self.offset + other)<tab><tab>else:<tab><tab><tab>return SpOffset(<tab><tab><tab><tab>self._bits,<tab><tab><tab><tab>ArithmeticExpression(<tab><tab><tab><tab><tab>ArithmeticExpression.Add,<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>self.offset,<tab><tab><tab><tab><tab><tab>other,<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>),<tab><tab><tab>)",1,if self . symbolic :,if self . symbolic :,0.75,100.00000000000004,1.0
"def check_connection(conn):<tab>tables = [<tab><tab>r[0]<tab><tab>for r in conn.execute(<tab><tab><tab>""select name from sqlite_master where type='table'""<tab><tab>).fetchall()<tab>]<tab>for table in tables:<tab><tab>try:<tab><tab><tab>conn.execute(<tab><tab><tab><tab>f""PRAGMA table_info({escape_sqlite(table)});"",<tab><tab><tab>)<tab><tab>except sqlite3.OperationalError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise SpatialiteConnectionProblem(e)<tab><tab><tab>else:<tab><tab><tab><tab>raise ConnectionProblem(e)",0,"if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :",if e . errno == errno . EEXIST :,0.0952753020587299,10.208145602370278,0.375
"def _get_github_client(self) -> ""Github"":<tab>from github import Github<tab>if self.access_token_secret is not None:<tab><tab># If access token secret specified, load it<tab><tab>access_token = Secret(self.access_token_secret).get()<tab>else:<tab><tab># Otherwise, fallback to loading from local secret or environment variable<tab><tab>access_token = prefect.context.get(""secrets"", {}).get(""GITHUB_ACCESS_TOKEN"")<tab><tab><IF-STMT><tab><tab><tab>access_token = os.getenv(""GITHUB_ACCESS_TOKEN"")<tab>return Github(access_token)",1,if access_token is None :,if access_token is None :,0.75,100.00000000000004,1.0
"def make_tab(lists):<tab>if hasattr(lists, ""tolist""):<tab><tab>lists = lists.tolist()<tab>ut = []<tab>for rad in lists:<tab><tab><IF-STMT><tab><tab><tab>ut.append(""\t"".join([""%s"" % x for x in rad]))<tab><tab>else:<tab><tab><tab>ut.append(""%s"" % rad)<tab>return ""\n"".join(ut)",0,"if type ( rad ) in [ list , tuple ] :","if isinstance ( rad , list ) :",0.025016225425363702,9.1627840649916,0.35714285714285715
"def _ensure_ffi_initialized(cls):<tab>with cls._init_lock:<tab><tab><IF-STMT><tab><tab><tab>cls.lib = build_conditional_library(lib, CONDITIONAL_NAMES)<tab><tab><tab>cls._lib_loaded = True<tab><tab><tab># initialize the SSL library<tab><tab><tab>cls.lib.SSL_library_init()<tab><tab><tab># adds all ciphers/digests for EVP<tab><tab><tab>cls.lib.OpenSSL_add_all_algorithms()<tab><tab><tab># loads error strings for libcrypto and libssl functions<tab><tab><tab>cls.lib.SSL_load_error_strings()<tab><tab><tab>cls._register_osrandom_engine()",1,if not cls . _lib_loaded :,if not cls . _lib_loaded :,0.75,100.00000000000004,1.0
def writer_leaves(self):<tab>self.mutex.acquire()<tab>try:<tab><tab>self.active_writers -= 1<tab><tab>if self.waiting_writers != 0:<tab><tab><tab>self.active_writers += 1<tab><tab><tab>self.waiting_writers -= 1<tab><tab><tab>self.can_write.release()<tab><tab><IF-STMT><tab><tab><tab>t = self.waiting_readers<tab><tab><tab>self.waiting_readers = 0<tab><tab><tab>self.active_readers += t<tab><tab><tab>while t > 0:<tab><tab><tab><tab>self.can_read.release()<tab><tab><tab><tab>t -= 1<tab>finally:<tab><tab>self.mutex.release(),0,elif self . waiting_readers != 0 :,if self . waiting_readers != 0 :,0.40455335578511065,88.01117367933934,0.6
"def _spans(self, operands):<tab>spans = {}<tab>k = 0<tab>j = 0<tab>for mode in (self.FLOAT, self.MPMATH):<tab><tab>for i, operand in enumerate(operands[k:]):<tab><tab><tab>if operand[0] > mode:<tab><tab><tab><tab>break<tab><tab><tab>j = i + k + 1<tab><tab><IF-STMT>  # only init state? then ignore.<tab><tab><tab>j = 0<tab><tab>spans[mode] = slice(k, j)<tab><tab>k = j<tab>spans[self.SYMBOLIC] = slice(k, len(operands))<tab>return spans",0,if k == 0 and j == 1 :,if j > len ( operands ) - 1 :,0.029623952782067205,9.030367376343264,0.20987654320987653
"def _report_error(self, completion_routine, response=None, message=None):<tab>if response:<tab><tab># Only include the text in case of error.<tab><tab><IF-STMT><tab><tab><tab>status = location.Status(response.status_code, response.text)<tab><tab>else:<tab><tab><tab>status = location.Status(response.status_code)<tab>else:<tab><tab>status = location.Status(500, message)<tab>if response is None or not response.ok:<tab><tab>if completion_routine:<tab><tab><tab>return completion_routine(status)<tab><tab>raise IOError(response.text)<tab>else:<tab><tab>if completion_routine:<tab><tab><tab>completion_routine(status)<tab>return location.Status(200, response.content)",0,if not response . ok :,if response . ok :,0.281663156243144,57.89300674674101,0.36
"def readinto(self, buf):<tab>if self.current_frame:<tab><tab>n = self.current_frame.readinto(buf)<tab><tab>if n == 0 and len(buf) != 0:<tab><tab><tab>self.current_frame = None<tab><tab><tab>n = len(buf)<tab><tab><tab>buf[:] = self.file_read(n)<tab><tab><tab>return n<tab><tab><IF-STMT><tab><tab><tab>raise UnpicklingError(""pickle exhausted before end of frame"")<tab><tab>return n<tab>else:<tab><tab>n = len(buf)<tab><tab>buf[:] = self.file_read(n)<tab><tab>return n",0,if n < len ( buf ) :,elif n > len ( buf ) :,0.25750132287221017,54.10822690539397,0.6666666666666666
"def __getitem__(self, name, set=set, getattr=getattr, id=id):<tab>visited = set()<tab>mydict = self.basedict<tab>while 1:<tab><tab>value = mydict[name]<tab><tab><IF-STMT><tab><tab><tab>return value<tab><tab>myid = id(mydict)<tab><tab>assert myid not in visited<tab><tab>visited.add(myid)<tab><tab>mydict = mydict.Parent<tab><tab>if mydict is None:<tab><tab><tab>return",1,if value is not None :,if value is not None :,0.75,100.00000000000004,1.0
"def _handle_Mul(self, expr):<tab>arg0, arg1 = expr.args<tab>expr_0 = self._expr(arg0)<tab>if expr_0 is None:<tab><tab>return None<tab>expr_1 = self._expr(arg1)<tab>if expr_1 is None:<tab><tab>return None<tab>try:<tab><tab><IF-STMT><tab><tab><tab># self.tyenv is not used<tab><tab><tab>mask = (1 << expr.result_size(self.tyenv)) - 1<tab><tab><tab>return (expr_0 * expr_1) & mask<tab><tab>else:<tab><tab><tab>return expr_0 * expr_1<tab>except TypeError as e:<tab><tab>self.l.warning(e)<tab><tab>return None",0,"if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :",if self . tyenv is not None :,0.007907432592091115,1.6604670898042333,0.2
"def end_request(self, request_id):<tab>""""""Removes the information associated with given request_id.""""""<tab>with self._lock:<tab><tab>del self._request_wsgi_environ[request_id]<tab><tab>del self._request_id_to_server_configuration[request_id]<tab><tab><IF-STMT><tab><tab><tab>del self._request_id_to_instance[request_id]",1,if request_id in self . _request_id_to_instance :,if request_id in self . _request_id_to_instance :,0.75,100.00000000000004,1.0
def generate():<tab><IF-STMT><tab><tab>decoder = zlib.decompressobj(16 + zlib.MAX_WBITS)<tab>while True:<tab><tab>chunk = self.raw.read(chunk_size)<tab><tab>if not chunk:<tab><tab><tab>break<tab><tab>if self._gzipped:<tab><tab><tab>chunk = decoder.decompress(chunk)<tab><tab>yield chunk,1,if self . _gzipped :,if self . _gzipped :,0.75,100.00000000000004,1.0
"def handle(self):<tab>from poetry.utils.env import EnvManager<tab>manager = EnvManager(self.poetry)<tab>current_env = manager.get()<tab>for venv in manager.list():<tab><tab>name = venv.path.name<tab><tab><IF-STMT><tab><tab><tab>name = str(venv.path)<tab><tab>if venv == current_env:<tab><tab><tab>self.line(""<info>{} (Activated)</info>"".format(name))<tab><tab><tab>continue<tab><tab>self.line(name)",0,"if self . option ( ""full-path"" ) :",if not name :,0.01860756028419845,4.238556455648295,0.3333333333333333
"def addAggregators(sheet, cols, aggrnames):<tab>""Add each aggregator in list of *aggrnames* to each of *cols*.""<tab>for aggrname in aggrnames:<tab><tab>aggrs = vd.aggregators.get(aggrname)<tab><tab>aggrs = aggrs if isinstance(aggrs, list) else [aggrs]<tab><tab>for aggr in aggrs:<tab><tab><tab>for c in cols:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>c.aggregators = []<tab><tab><tab><tab>if aggr and aggr not in c.aggregators:<tab><tab><tab><tab><tab>c.aggregators += [aggr]",1,"if not hasattr ( c , ""aggregators"" ) :","if not hasattr ( c , ""aggregators"" ) :",0.75,100.00000000000004,1.0
"def on_pre_output_coercion(<tab>directive_args: Dict[str, Any],<tab>next_directive: Callable,<tab>value: Any,<tab>ctx: Optional[Any],<tab>info: ""ResolveInfo"",):<tab>value = await next_directive(value, ctx, info)<tab>if value is None:<tab><tab>return value<tab>try:<tab><tab>py_enum = _ENUM_MAP[directive_args[""name""]]<tab><tab><IF-STMT><tab><tab><tab>return [None if item is None else py_enum(item).name for item in value]<tab><tab>return py_enum(value).name<tab>except Exception:<tab><tab>pass<tab>return value",1,"if isinstance ( value , list ) :","if isinstance ( value , list ) :",0.75,100.00000000000004,1.0
def cut(sentence):<tab>sentence = strdecode(sentence)<tab>blocks = re_han.split(sentence)<tab>for blk in blocks:<tab><tab><IF-STMT><tab><tab><tab>for word in __cut(blk):<tab><tab><tab><tab>if word not in Force_Split_Words:<tab><tab><tab><tab><tab>yield word<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>for c in word:<tab><tab><tab><tab><tab><tab>yield c<tab><tab>else:<tab><tab><tab>tmp = re_skip.split(blk)<tab><tab><tab>for x in tmp:<tab><tab><tab><tab>if x:<tab><tab><tab><tab><tab>yield x,0,if re_han . match ( blk ) :,if blk :,0.017267079824235865,1e-10,0.4772727272727273
"def refresh_archive_action(self):<tab>archive_name = self.selected_archive_name()<tab>if archive_name is not None:<tab><tab>params = BorgInfoArchiveThread.prepare(self.profile(), archive_name)<tab><tab><IF-STMT><tab><tab><tab>thread = BorgInfoArchiveThread(params[""cmd""], params, parent=self.app)<tab><tab><tab>thread.updated.connect(self._set_status)<tab><tab><tab>thread.result.connect(self.refresh_archive_result)<tab><tab><tab>self._toggle_all_buttons(False)<tab><tab><tab>thread.start()",0,"if params [ ""ok"" ] :",if params is not None :,0.04986831674574446,12.872632311973014,0.39999999999999997
"def get_resource_public_actions(resource_class):<tab>resource_class_members = inspect.getmembers(resource_class)<tab>resource_methods = {}<tab>for name, member in resource_class_members:<tab><tab>if not name.startswith(""_""):<tab><tab><tab>if not name[0].isupper():<tab><tab><tab><tab>if not name.startswith(""wait_until""):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>resource_methods[name] = member<tab>return resource_methods",0,if is_resource_action ( member ) :,if inspect . isclass ( member ) :,0.2908194450899196,28.46946938149361,0.36
"def _get_compressor(compress_type, compresslevel=None):<tab>if compress_type == ZIP_DEFLATED:<tab><tab><IF-STMT><tab><tab><tab>return zlib.compressobj(compresslevel, zlib.DEFLATED, -15)<tab><tab>return zlib.compressobj(zlib.Z_DEFAULT_COMPRESSION, zlib.DEFLATED, -15)<tab>elif compress_type == ZIP_BZIP2:<tab><tab>if compresslevel is not None:<tab><tab><tab>return bz2.BZ2Compressor(compresslevel)<tab><tab>return bz2.BZ2Compressor()<tab># compresslevel is ignored for ZIP_LZMA<tab>elif compress_type == ZIP_LZMA:<tab><tab>return LZMACompressor()<tab>else:<tab><tab>return None",1,if compresslevel is not None :,if compresslevel is not None :,0.75,100.00000000000004,1.0
"def parse_header(plyfile, ext):<tab># Variables<tab>line = []<tab>properties = []<tab>num_points = None<tab>while b""end_header"" not in line and line != b"""":<tab><tab>line = plyfile.readline()<tab><tab>if b""element"" in line:<tab><tab><tab>line = line.split()<tab><tab><tab>num_points = int(line[2])<tab><tab><IF-STMT><tab><tab><tab>line = line.split()<tab><tab><tab>properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))<tab>return num_points, properties",0,"elif b""property"" in line :","elif b""properties"" in line :",0.19287202148493998,50.000000000000014,1.0
"def download_release_artifacts(self, version):<tab>try:<tab><tab>os.mkdir(self.artifacts_dir)<tab>except FileExistsError:<tab><tab>pass<tab>for job_name in self.build_ids:<tab><tab>build_number = self.build_ids.get(job_name)<tab><tab>build_status = self._get_build_status(job_name, build_number)<tab><tab><IF-STMT><tab><tab><tab>self._download_job_artifact(job_name, build_number, version)<tab><tab>else:<tab><tab><tab>print(""Build for {} is not fininished"".format(job_name))<tab><tab><tab>print(""\tRun 'build' action to check status of {}"".format(job_name))",0,"if build_status == ""built"" :","if build_status == ""complete"" :",0.39477865547525276,70.71067811865478,1.0
"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab>if attrvalue == 0:<tab><tab><tab>continue<tab><tab>if attrname == ""salt_version"":<tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab>elif hasattr(self.metadata, attrname):<tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass",1,"if attrname . startswith ( ""__"" ) :","if attrname . startswith ( ""__"" ) :",0.75,100.00000000000004,1.0
"def check_heuristic_in_sql():<tab>heurs = set()<tab>excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""]<tab>for heur in HEURISTICS:<tab><tab>name = heur[""name""]<tab><tab>if name in excluded:<tab><tab><tab>continue<tab><tab>sql = heur[""sql""]<tab><tab><IF-STMT><tab><tab><tab>print((""SQL command not correctly associated to %s"" % repr(name)))<tab><tab><tab>print(sql)<tab><tab><tab>assert sql.find(name) != -1<tab><tab>heurs.add(name)<tab>print(""Heuristics:"")<tab>import pprint<tab>pprint.pprint(heurs)",0,if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,if sql is not None :,0.009756119626074315,1.7421213399416402,0.2923076923076923
def gettext(rv):<tab>for child in rv.childNodes:<tab><tab><IF-STMT><tab><tab><tab>yield child.nodeValue<tab><tab>if child.nodeType == child.ELEMENT_NODE:<tab><tab><tab>for item in gettext(child):<tab><tab><tab><tab>yield item,1,if child . nodeType == child . TEXT_NODE :,if child . nodeType == child . TEXT_NODE :,1.0,100.00000000000004,1.0
"def update(self):<tab>""""""Update properties over dbus.""""""<tab>self._check_dbus()<tab>_LOGGER.info(""Updating service information"")<tab>self._services.clear()<tab>try:<tab><tab>systemd_units = await self.sys_dbus.systemd.list_units()<tab><tab>for service_data in systemd_units[0]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self._services.add(ServiceInfo.read_from(service_data))<tab>except (HassioError, IndexError):<tab><tab>_LOGGER.warning(""Can't update host service information!"")",0,"if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :","if service_data == """" :",0.0050224808156713804,2.9227098302811174,0.26267281105990786
"def filtercomments(source):<tab>""""""NOT USED: strips trailing comments and put them at the top.""""""<tab>trailing_comments = []<tab>comment = True<tab>while comment:<tab><tab><IF-STMT><tab><tab><tab>comment = source[0, source.index(""*/"") + 2]<tab><tab>elif re.search(r""^\s*\/\/"", source):<tab><tab><tab>comment = re.search(r""^\s*\/\/"", source).group(0)<tab><tab>else:<tab><tab><tab>comment = None<tab><tab>if comment:<tab><tab><tab>source = re.sub(r""^\s+"", """", source[len(comment) :])<tab><tab><tab>trailing_comments.append(comment)<tab>return ""\n"".join(trailing_comments) + source",0,"if re . search ( r""^\s*\/\*"" , source ) :","if ""*"" in source :",0.014393212535568477,2.6986626561701814,0.32051282051282054
"def _getSourceStamp_sync(self, ssid):<tab>if ssid in self.sourcestamps:<tab><tab>ssdict = self.sourcestamps[ssid].copy()<tab><tab>ssdict[""ssid""] = ssid<tab><tab>patchid = ssdict[""patchid""]<tab><tab><IF-STMT><tab><tab><tab>ssdict.update(self.patches[patchid])<tab><tab><tab>ssdict[""patchid""] = patchid<tab><tab>else:<tab><tab><tab>ssdict[""patch_body""] = None<tab><tab><tab>ssdict[""patch_level""] = None<tab><tab><tab>ssdict[""patch_subdir""] = None<tab><tab><tab>ssdict[""patch_author""] = None<tab><tab><tab>ssdict[""patch_comment""] = None<tab><tab>return ssdict<tab>else:<tab><tab>return None",0,if patchid :,if patchid in self . patches :,0.08580507810416099,1e-10,0.42857142857142855
"def parseImpl(self, instring, loc, doActions=True):<tab>try:<tab><tab>loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)<tab>except (ParseException, IndexError):<tab><tab>if self.defaultValue is not self.__optionalNotMatched:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tokens = ParseResults([self.defaultValue])<tab><tab><tab><tab>tokens[self.expr.resultsName] = self.defaultValue<tab><tab><tab>else:<tab><tab><tab><tab>tokens = [self.defaultValue]<tab><tab>else:<tab><tab><tab>tokens = []<tab>return loc, tokens",0,if self . expr . resultsName :,if self . expr . resultsName is not None :,0.4695453452913714,53.7284965911771,0.5833333333333333
"def _find_exceptions():<tab>for _name, obj in iteritems(globals()):<tab><tab>try:<tab><tab><tab>is_http_exception = issubclass(obj, HTTPException)<tab><tab>except TypeError:<tab><tab><tab>is_http_exception = False<tab><tab>if not is_http_exception or obj.code is None:<tab><tab><tab>continue<tab><tab>__all__.append(obj.__name__)<tab><tab>old_obj = default_exceptions.get(obj.code, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>default_exceptions[obj.code] = obj",0,"if old_obj is not None and issubclass ( obj , old_obj ) :",if old_obj is not obj :,0.2756276309532466,23.735681011089778,0.475
"def generator(self, data):<tab>for (proc_as, key_buf_ptr) in data:<tab><tab>key_buf = proc_as.read(key_buf_ptr, 24)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>key = """".join(""%02X"" % ord(k) for k in key_buf)<tab><tab>yield (<tab><tab><tab>0,<tab><tab><tab>[<tab><tab><tab><tab>str(key),<tab><tab><tab>],<tab><tab>)",1,if not key_buf :,if not key_buf :,0.75,100.00000000000004,1.0
"def calculateEnableMargins(self):<tab>self.cnc.resetEnableMargins()<tab>for block in self.blocks:<tab><tab><IF-STMT><tab><tab><tab>CNC.vars[""xmin""] = min(CNC.vars[""xmin""], block.xmin)<tab><tab><tab>CNC.vars[""ymin""] = min(CNC.vars[""ymin""], block.ymin)<tab><tab><tab>CNC.vars[""zmin""] = min(CNC.vars[""zmin""], block.zmin)<tab><tab><tab>CNC.vars[""xmax""] = max(CNC.vars[""xmax""], block.xmax)<tab><tab><tab>CNC.vars[""ymax""] = max(CNC.vars[""ymax""], block.ymax)<tab><tab><tab>CNC.vars[""zmax""] = max(CNC.vars[""zmax""], block.zmax)",0,if block . enable :,if block . enabled :,0.39477865547525276,42.72870063962342,0.6
"def __init__(self, client, job_id, callback=None):<tab>self.client = client<tab>self.job_id = job_id<tab># If a job event has been received already then we must set an Event<tab># to wait for this job to finish.<tab># Otherwise we create a new stub for the job with the Event for when<tab># the job event arrives to use existing event.<tab>with client._jobs_lock:<tab><tab>job = client._jobs.get(job_id)<tab><tab>self.event = None<tab><tab><IF-STMT><tab><tab><tab>self.event = job.get(""__ready"")<tab><tab>if self.event is None:<tab><tab><tab>self.event = job[""__ready""] = Event()<tab><tab>job[""__callback""] = callback",0,if job :,"if isinstance ( job , dict ) :",0.046522600101893324,1e-10,0.36
"def asset(*paths):<tab>for path in paths:<tab><tab>fspath = www_root + ""/assets/"" + path<tab><tab>etag = """"<tab><tab>try:<tab><tab><tab>if env.cache_static:<tab><tab><tab><tab>etag = asset_etag(fspath)<tab><tab><tab>else:<tab><tab><tab><tab>os.stat(fspath)<tab><tab>except FileNotFoundError as e:<tab><tab><tab>if path == paths[-1]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>tell_sentry(e, {})<tab><tab><tab>else:<tab><tab><tab><tab>continue<tab><tab>except Exception as e:<tab><tab><tab>tell_sentry(e, {})<tab><tab>return asset_url + path + (etag and ""?etag="" + etag)",0,"if not os . path . exists ( fspath + "".spt"" ) :",if e . errno == errno . ENOENT :,0.011544941907183082,3.2567594431760947,0.19333333333333333
"def set_conf():<tab>""""""Collapse all object_trail config into cherrypy.request.config.""""""<tab>base = cherrypy.config.copy()<tab># Note that we merge the config from each node<tab># even if that node was None.<tab>for name, obj, conf, segleft in object_trail:<tab><tab>base.update(conf)<tab><tab><IF-STMT><tab><tab><tab>base[""tools.staticdir.section""] = ""/"" + ""/"".join(<tab><tab><tab><tab>fullpath[0 : fullpath_len - segleft]<tab><tab><tab>)<tab>return base",0,"if ""tools.staticdir.dir"" in conf :",if segleft > 0 :,0.03412306583404374,3.8261660656802645,0.3333333333333333
"def __init__(self):<tab>self.setLayers(None, None)<tab>self.interface = None<tab>self.event_callbacks = {}<tab>self.__stack = None<tab>self.lock = threading.Lock()<tab>members = inspect.getmembers(self, predicate=inspect.ismethod)<tab>for m in members:<tab><tab><IF-STMT><tab><tab><tab>fname = m[0]<tab><tab><tab>fn = m[1]<tab><tab><tab>self.event_callbacks[fn.event_callback] = getattr(self, fname)",0,"if hasattr ( m [ 1 ] , ""event_callback"" ) :","if isinstance ( m , tuple ) :",0.03219593007528923,7.205893226533905,0.42857142857142855
def multi_dev_generator(self):<tab>for data in self._data_loader():<tab><tab><IF-STMT><tab><tab><tab>self._tail_data += data<tab><tab>if len(self._tail_data) == self._base_number:<tab><tab><tab>yield self._tail_data<tab><tab><tab>self._tail_data = [],0,if len ( self . _tail_data ) < self . _base_number :,if len ( data ) > 0 :,0.04949642924785473,7.751133278997488,0.5
"def replace_field_to_value(layout, cb):<tab>for i, lo in enumerate(layout.fields):<tab><tab>if isinstance(lo, Field) or issubclass(lo.__class__, Field):<tab><tab><tab>layout.fields[i] = ShowField(<tab><tab><tab><tab>cb, *lo.fields, attrs=lo.attrs, wrapper_class=lo.wrapper_class<tab><tab><tab>)<tab><tab>elif isinstance(lo, basestring):<tab><tab><tab>layout.fields[i] = ShowField(cb, lo)<tab><tab><IF-STMT><tab><tab><tab>replace_field_to_value(lo, cb)",0,"elif hasattr ( lo , ""get_field_names"" ) :","elif isinstance ( lo , Field ) :",0.17379421373944987,12.779458309114789,0.48148148148148145
"def function_out(*args, **kwargs):<tab>try:<tab><tab>return function_in(*args, **kwargs)<tab>except dbus.exceptions.DBusException as e:<tab><tab>if e.get_dbus_name() == DBUS_UNKNOWN_METHOD:<tab><tab><tab>raise ItemNotFoundException(""Item does not exist!"")<tab><tab>if e.get_dbus_name() == DBUS_NO_SUCH_OBJECT:<tab><tab><tab>raise ItemNotFoundException(e.get_dbus_message())<tab><tab><IF-STMT><tab><tab><tab>raise SecretServiceNotAvailableException(e.get_dbus_message())<tab><tab>raise",0,"if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) :",if e . get_dbus_name ( ) == DBUS_SECRET_SERVICE_NOT_AVAILABLE :,0.28472022483660975,45.38520603721475,0.7380952380952381
"def results_iter(self):<tab>if self.connection.ops.oracle:<tab><tab>from django.db.models.fields import DateTimeField<tab><tab>fields = [DateTimeField()]<tab>else:<tab><tab>needs_string_cast = self.connection.features.needs_datetime_string_cast<tab>offset = len(self.query.extra_select)<tab>for rows in self.execute_sql(MULTI):<tab><tab>for row in rows:<tab><tab><tab>date = row[offset]<tab><tab><tab>if self.connection.ops.oracle:<tab><tab><tab><tab>date = self.resolve_columns(row, fields)[offset]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>date = typecast_timestamp(str(date))<tab><tab><tab>yield date",0,elif needs_string_cast :,if needs_string_cast :,0.11293884852539707,1e-10,0.3333333333333333
"def handle_label(self, path, **options):<tab>verbosity = int(options.get(""verbosity"", 1))<tab>result = finders.find(path, all=options[""all""])<tab>path = smart_unicode(path)<tab>if result:<tab><tab>if not isinstance(result, (list, tuple)):<tab><tab><tab>result = [result]<tab><tab>output = u""\n  "".join(<tab><tab><tab>(smart_unicode(os.path.realpath(path)) for path in result)<tab><tab>)<tab><tab>self.stdout.write(smart_str(u""Found '%s' here:\n  %s\n"" % (path, output)))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.stderr.write(smart_str(""No matching file found for '%s'.\n"" % path))",1,if verbosity >= 1 :,if verbosity >= 1 :,0.75,100.00000000000004,1.0
"def name(self):<tab>""""""Get the enumeration name of this storage class.""""""<tab>if self._name_map is None:<tab><tab>self._name_map = {}<tab><tab>for key, value in list(StorageClass.__dict__.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._name_map[value] = key<tab>return self._name_map[self]",1,"if isinstance ( value , StorageClass ) :","if isinstance ( value , StorageClass ) :",0.75,100.00000000000004,1.0
"def index(self, value):<tab>if self._growing:<tab><tab>if self._start <= value < self._stop:<tab><tab><tab>q, r = divmod(value - self._start, self._step)<tab><tab><tab>if r == self._zero:<tab><tab><tab><tab>return int(q)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>q, r = divmod(self._start - value, -self._step)<tab><tab><tab>if r == self._zero:<tab><tab><tab><tab>return int(q)<tab>raise ValueError(""{} is not in numeric range"".format(value))",0,if self . _start >= value > self . _stop :,if self . _start >= value < self . _stop :,0.8520019333126669,78.25422900366432,1.0
"def extract_cookie(cookie_header, cookie_name):<tab>inx = cookie_header.find(cookie_name)<tab>if inx >= 0:<tab><tab>end_inx = cookie_header.find("";"", inx)<tab><tab><IF-STMT><tab><tab><tab>value = cookie_header[inx:end_inx]<tab><tab>else:<tab><tab><tab>value = cookie_header[inx:]<tab><tab>return value<tab>return """"",0,if end_inx > 0 :,if end_inx >= 0 :,0.33141502097923065,59.4603557501361,1.0
"def get_size(self, shape_info):<tab># The size is the data, that have constant size.<tab>state = np.random.RandomState().get_state()<tab>size = 0<tab>for elem in state:<tab><tab>if isinstance(elem, str):<tab><tab><tab>size += len(elem)<tab><tab><IF-STMT><tab><tab><tab>size += elem.size * elem.itemsize<tab><tab>elif isinstance(elem, int):<tab><tab><tab>size += np.dtype(""int"").itemsize<tab><tab>elif isinstance(elem, float):<tab><tab><tab>size += np.dtype(""float"").itemsize<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab>return size",0,"elif isinstance ( elem , np . ndarray ) :","elif isinstance ( elem , torch . Tensor ) :",0.48356898886410005,46.713797772819994,0.5
"def createFields(self):<tab>size = self.size / 8<tab>if size > 2:<tab><tab><IF-STMT><tab><tab><tab>yield UInt8(self, ""cs"", ""10ms units, values from 0 to 199"")<tab><tab>yield Bits(self, ""2sec"", 5, ""seconds/2"")<tab><tab>yield Bits(self, ""min"", 6, ""minutes"")<tab><tab>yield Bits(self, ""hour"", 5, ""hours"")<tab>yield Bits(self, ""day"", 5, ""(1-31)"")<tab>yield Bits(self, ""month"", 4, ""(1-12)"")<tab>yield Bits(self, ""year"", 7, ""(0 = 1980, 127 = 2107)"")",0,if size > 4 :,if size % 2 == 0 :,0.136202649291725,12.22307556087252,0.4761904761904762
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""incap_ses|visid_incap"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab>retval |= re.search(r""Incapsula"", headers.get(""X-CDN"", """"), re.I) is not None<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.5311706625951745,1e-10,1.0
"def _get_order_information(self, node_id, timeout=1200, check_interval=5):<tab>mask = {<tab><tab>""billingItem"": """",<tab><tab>""powerState"": """",<tab><tab>""operatingSystem"": {""passwords"": """"},<tab><tab>""provisionDate"": """",<tab>}<tab>for i in range(0, timeout, check_interval):<tab><tab>res = self.connection.request(<tab><tab><tab>""SoftLayer_Virtual_Guest"", ""getObject"", id=node_id, object_mask=mask<tab><tab>).object<tab><tab><IF-STMT><tab><tab><tab>return res<tab><tab>time.sleep(check_interval)<tab>raise SoftLayerException(""Timeout on getting node details"")",0,"if res . get ( ""provisionDate"" , None ) :",if res :,0.020477126045913657,1e-10,0.5714285714285714
"def _process_param_change(self, msg):<tab>msg = super(Select, self)._process_param_change(msg)<tab>labels, values = self.labels, self.values<tab>if ""value"" in msg:<tab><tab>msg[""value""] = [<tab><tab><tab>labels[indexOf(v, values)] for v in msg[""value""] if isIn(v, values)<tab><tab>]<tab>if ""options"" in msg:<tab><tab>msg[""options""] = labels<tab><tab><IF-STMT><tab><tab><tab>self.value = [v for v in self.value if isIn(v, values)]<tab>return msg",0,"if any ( not isIn ( v , values ) for v in self . value ) :",if self . value is not None :,0.08373872051346834,7.003939561149077,0.13360323886639677
"def get_object_from_name(self, name, check_symlinks=True):<tab>if not name:<tab><tab>return None<tab>name = name.rstrip(""\\"")<tab>for a, o in self.objects.items():<tab><tab>if not o.name:<tab><tab><tab>continue<tab><tab>if o.name.lower() == name.lower():<tab><tab><tab>return o<tab>if check_symlinks:<tab><tab>m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()]<tab><tab><IF-STMT><tab><tab><tab>name = m[0]<tab><tab>return self.get_object_from_name(name, False)",0,if m :,if len ( m ) == 1 :,0.046522600101893324,1e-10,0.36
"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v[""_class""] == ""User"":<tab><tab><tab>if v[""email""] == """":<tab><tab><tab><tab>v[""email""] = None<tab><tab><tab>if v[""ip""] == ""0.0.0.0"":<tab><tab><tab><tab>v[""ip""] = None<tab>return self.objs",1,"if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",0.75,100.00000000000004,1.0
"def _providers(self, descriptor):<tab>res = []<tab>for _md in self.metadata.values():<tab><tab>for ent_id, ent_desc in _md.items():<tab><tab><tab>if descriptor in ent_desc:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># print(""duplicated entity_id: %s"" % res)<tab><tab><tab><tab><tab>pass<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>res.append(ent_id)<tab>return res",1,if ent_id in res :,if ent_id in res :,0.75,100.00000000000004,1.0
"def test_add_participant(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>async with self.chat_thread_client:<tab><tab><tab>share_history_time = datetime.utcnow()<tab><tab><tab>share_history_time = share_history_time.replace(tzinfo=TZ_UTC)<tab><tab><tab>new_participant = ChatThreadParticipant(<tab><tab><tab><tab>user=self.new_user,<tab><tab><tab><tab>display_name=""name"",<tab><tab><tab><tab>share_history_time=share_history_time,<tab><tab><tab>)<tab><tab><tab>await self.chat_thread_client.add_participant(new_participant)<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)",0,if not self . is_playback ( ) :,if self . is_playback ( ) :,0.36108324016767335,79.56371661921447,0.4772727272727273
"def url(regex, view, kwargs=None, name=None, prefix=""""):<tab>if isinstance(view, (list, tuple)):<tab><tab># For include(...) processing.<tab><tab>urlconf_module, app_name, namespace = view<tab><tab>return RegexURLResolver(<tab><tab><tab>regex, urlconf_module, kwargs, app_name=app_name, namespace=namespace<tab><tab>)<tab>else:<tab><tab>if isinstance(view, basestring):<tab><tab><tab>if not view:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>""Empty URL pattern view name not permitted (for pattern %r)"" % regex<tab><tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>view = prefix + ""."" + view<tab><tab>return RegexURLPattern(regex, view, kwargs, name)",1,if prefix :,if prefix :,0.5311706625951745,1e-10,1.0
"def tx():<tab># Sync receiver ready to avoid loss of first packets<tab>while not sub_ready.ready():<tab><tab>pub.send(b""test BEGIN"")<tab><tab>eventlet.sleep(0.005)<tab>for i in range(1, 101):<tab><tab>msg = ""test {0}"".format(i).encode()<tab><tab><IF-STMT><tab><tab><tab>pub.send(msg)<tab><tab>else:<tab><tab><tab>pub.send(b""test LAST"")<tab><tab><tab>sub_last.wait()<tab><tab># XXX: putting a real delay of 1ms here fixes sporadic failures on Travis<tab><tab># just yield eventlet.sleep(0) doesn't cut it<tab><tab>eventlet.sleep(0.001)<tab>pub.send(b""done DONE"")",0,if i != 50 :,"if msg != b""DONE"" :",0.03654024892898815,11.339582221952005,0.36
"def remove_tmp_snapshot_file(self, files):<tab>for filepath in files:<tab><tab>path = Path(filepath)<tab><tab>if path.is_dir() and path.exists():<tab><tab><tab>shutil.rmtree(path)<tab><tab><IF-STMT><tab><tab><tab>path.unlink()",0,elif path . is_file ( ) and path . exists ( ) :,elif path . is_file ( ) and path . is_file ( ) :,0.8805803001674946,69.64705665515706,0.7882352941176471
"def f(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab>if count == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>eol = view.line(s.b).b<tab><tab><tab><tab>return R(s.b, eol)<tab><tab><tab>return s<tab>return s",0,if view . line ( s . b ) . size ( ) > 0 :,if view . line ( s . b ) . b != s . b :,0.39547021581622155,55.81600587827485,0.6384803921568627
"def get_ids(self, **kwargs):<tab>id = []<tab>if ""id"" in kwargs:<tab><tab>id = kwargs[""id""]<tab><tab># Coerce ids to list<tab><tab><IF-STMT><tab><tab><tab>id = id.split("","")<tab><tab># Ensure ids are integers<tab><tab>try:<tab><tab><tab>id = list(map(int, id))<tab><tab>except Exception:<tab><tab><tab>decorators.error(""Invalid id"")<tab>return id",0,"if not isinstance ( id , list ) :","if "","" in id :",0.0168380461076173,6.979367151952678,0.2571428571428572
"def param_value(self):<tab># This is part of the ""handle quoted extended parameters"" hack.<tab>for token in self:<tab><tab><IF-STMT><tab><tab><tab>return token.stripped_value<tab><tab>if token.token_type == ""quoted-string"":<tab><tab><tab>for token in token:<tab><tab><tab><tab>if token.token_type == ""bare-quoted-string"":<tab><tab><tab><tab><tab>for token in token:<tab><tab><tab><tab><tab><tab>if token.token_type == ""value"":<tab><tab><tab><tab><tab><tab><tab>return token.stripped_value<tab>return """"",1,"if token . token_type == ""value"" :","if token . token_type == ""value"" :",0.75,100.00000000000004,1.0
"def get_all_start_methods(self):<tab>if sys.platform == ""win32"":<tab><tab>return [""spawn""]<tab>else:<tab><tab>methods = [""spawn"", ""fork""] if sys.platform == ""darwin"" else [""fork"", ""spawn""]<tab><tab><IF-STMT><tab><tab><tab>methods.append(""forkserver"")<tab><tab>return methods",0,if reduction . HAVE_SEND_HANDLE :,"if sys . platform == ""win32"" :",0.029730601197949243,5.522397783539471,0.37777777777777777
"def _process_watch(self, watched_event):<tab>logger.debug(""process_watch: %r"", watched_event)<tab>with handle_exception(self._tree._error_listeners):<tab><tab><IF-STMT><tab><tab><tab>assert self._parent is None, ""unexpected CREATED on non-root""<tab><tab><tab>self.on_created()<tab><tab>elif watched_event.type == EventType.DELETED:<tab><tab><tab>self.on_deleted()<tab><tab>elif watched_event.type == EventType.CHANGED:<tab><tab><tab>self._refresh_data()<tab><tab>elif watched_event.type == EventType.CHILD:<tab><tab><tab>self._refresh_children()",0,if watched_event . type == EventType . CREATED :,if watched_event . type == EventType .CREATED :,0.5618723018637402,100.00000000000004,0.7818181818181819
"def assert_open(self, sock, *rest):<tab>if isinstance(sock, fd_types):<tab><tab>self.__assert_fd_open(sock)<tab>else:<tab><tab>fileno = sock.fileno()<tab><tab>assert isinstance(fileno, fd_types), fileno<tab><tab>sockname = sock.getsockname()<tab><tab>assert isinstance(sockname, tuple), sockname<tab><tab><IF-STMT><tab><tab><tab>self.__assert_fd_open(fileno)<tab><tab>else:<tab><tab><tab>self._assert_sock_open(sock)<tab>if rest:<tab><tab>self.assert_open(rest[0], *rest[1:])",0,if not WIN :,if fileno :,0.05063871203029889,1e-10,0.3333333333333333
"def detype(self):<tab>""""""De-types the instance, allowing it to be exported to the environment.""""""<tab>style = self.style<tab>if self._detyped is None:<tab><tab>self._detyped = "":"".join(<tab><tab><tab>[<tab><tab><tab><tab>key<tab><tab><tab><tab>+ ""=""<tab><tab><tab><tab>+ "";"".join(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>LsColors.target_value<tab><tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>else ansi_color_name_to_escape_code(v, cmap=style)<tab><tab><tab><tab><tab><tab>for v in val<tab><tab><tab><tab><tab>]<tab><tab><tab><tab>)<tab><tab><tab><tab>for key, val in sorted(self._d.items())<tab><tab><tab>]<tab><tab>)<tab>return self._detyped",0,if key in self . _targets,if LsColors . target_value is not None,0.19054556606893822,6.27465531099474,0.2
"def gather_metrics(dry_run=False):<tab>today = datetime.date.today()<tab>first = today.replace(day=1)<tab>last_month = first - datetime.timedelta(days=1)<tab>filename = ""form_types_{}.csv"".format(last_month.strftime(""%Y-%m""))<tab>with connection.cursor() as cursor:<tab><tab>cursor.execute(REGISTRATION_METRICS_SQL)<tab><tab><IF-STMT><tab><tab><tab>for row in cursor.fetchall():<tab><tab><tab><tab>logger.info(encode_row(row))<tab><tab>else:<tab><tab><tab>write_raw_data(cursor=cursor, filename=filename)",1,if dry_run :,if dry_run :,0.5311706625951745,1e-10,1.0
"def cat(tensors, dim=0):<tab>assert isinstance(tensors, list), ""input to cat must be a list""<tab>if len(tensors) == 1:<tab><tab>return tensors[0]<tab>from .autograd_cryptensor import AutogradCrypTensor<tab>if any(isinstance(t, AutogradCrypTensor) for t in tensors):<tab><tab><IF-STMT><tab><tab><tab>tensors[0] = AutogradCrypTensor(tensors[0], requires_grad=False)<tab><tab>return tensors[0].cat(*tensors[1:], dim=dim)<tab>else:<tab><tab>return get_default_backend().cat(tensors, dim=dim)",0,"if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :","if isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :",0.4665946607126695,83.52052074548166,0.27472527472527475
"def is_installed(self, dlc_title="""") -> bool:<tab>installed = False<tab>if dlc_title:<tab><tab>dlc_version = self.get_dlc_info(""version"", dlc_title)<tab><tab>installed = True if dlc_version else False<tab><tab># Start: Code for compatibility with minigalaxy 1.0<tab><tab>if not installed:<tab><tab><tab>status = self.legacy_get_dlc_status(dlc_title)<tab><tab><tab>installed = True if status in [""installed"", ""updatable""] else False<tab><tab># End: Code for compatibility with minigalaxy 1.0<tab>else:<tab><tab><IF-STMT><tab><tab><tab>installed = True<tab>return installed",0,if self . install_dir and os . path . exists ( self . install_dir ) :,if self . legacy_is_installed ( dlc_title ) :,0.0381633083417995,9.73885220662316,0.34989648033126297
"def on_copy(self):<tab>source_objects = self.__getSelection()<tab>for source in source_objects:<tab><tab><IF-STMT><tab><tab><tab>new_obj = model.Phrase("""", """")<tab><tab>else:<tab><tab><tab>new_obj = model.Script("""", """")<tab><tab>new_obj.copy(source)<tab><tab>self.cutCopiedItems.append(new_obj)",0,"if isinstance ( source , model . Phrase ) :",if len ( source ) == 0 :,0.029321108690485986,10.729256185679601,0.36363636363636365
"def FetchFn(type_name):<tab>""""""Fetches all hunt results of a given type.""""""<tab>offset = 0<tab>while True:<tab><tab>results = data_store.REL_DB.ReadHuntResults(<tab><tab><tab>hunt_id, offset=offset, count=self._RESULTS_PAGE_SIZE, with_type=type_name<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>for r in results:<tab><tab><tab>msg = r.AsLegacyGrrMessage()<tab><tab><tab>msg.source_urn = source_urn<tab><tab><tab>yield msg<tab><tab>offset += self._RESULTS_PAGE_SIZE",1,if not results :,if not results :,0.75,100.00000000000004,1.0
"def get_blob_type_declaration_sql(self, column):<tab>length = column.get(""length"")<tab>if length:<tab><tab><IF-STMT><tab><tab><tab>return ""TINYBLOB""<tab><tab>if length <= self.LENGTH_LIMIT_BLOB:<tab><tab><tab>return ""BLOB""<tab><tab>if length <= self.LENGTH_LIMIT_MEDIUMBLOB:<tab><tab><tab>return ""MEDIUMBLOB""<tab>return ""LONGBLOB""",1,if length <= self . LENGTH_LIMIT_TINYBLOB :,if length <= self . LENGTH_LIMIT_TINYBLOB :,0.75,100.00000000000004,1.0
"def decode(cls, data):<tab>while data:<tab><tab>(<tab><tab><tab>length,<tab><tab><tab>atype,<tab><tab>) = unpack(cls.Header.PACK, data[: cls.Header.LEN])<tab><tab><IF-STMT><tab><tab><tab>raise AttributesError(""Buffer underrun %d < %d"" % (len(data), length))<tab><tab>payload = data[cls.Header.LEN : length]<tab><tab>yield atype, payload<tab><tab>data = data[int((length + 3) / 4) * 4 :]",0,if len ( data ) < length :,if length < cls . Header .LEN :,0.020373036588449148,6.742555929751843,0.2857142857142857
"def test_join_diffs(db, series_of_diffs, expected):<tab>diffs = []<tab>for changes in series_of_diffs:<tab><tab>tracker = DBDiffTracker()<tab><tab>for key, val in changes.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del tracker[key]<tab><tab><tab>else:<tab><tab><tab><tab>tracker[key] = val<tab><tab>diffs.append(tracker.diff())<tab>DBDiff.join(diffs).apply_to(db)<tab>assert db == expected",0,if val is None :,if key in tracker :,0.28412306583404373,12.703318703865365,0.25
"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab>if col == LAND:<tab><tab><tab><tab>tmp += "".""<tab><tab><tab>elif col == BARRIER:<tab><tab><tab><tab>tmp += ""%""<tab><tab><tab>elif col == FOOD:<tab><tab><tab><tab>tmp += ""*""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",0,elif col == UNSEEN :,elif col == LEGAL :,0.6428720214849399,53.7284965911771,0.6
"def _report_error(self, completion_routine, response=None, message=None):<tab>if response:<tab><tab># Only include the text in case of error.<tab><tab>if not response.ok:<tab><tab><tab>status = location.Status(response.status_code, response.text)<tab><tab>else:<tab><tab><tab>status = location.Status(response.status_code)<tab>else:<tab><tab>status = location.Status(500, message)<tab>if response is None or not response.ok:<tab><tab><IF-STMT><tab><tab><tab>return completion_routine(status)<tab><tab>raise IOError(response.text)<tab>else:<tab><tab>if completion_routine:<tab><tab><tab>completion_routine(status)<tab>return location.Status(200, response.content)",1,if completion_routine :,if completion_routine :,0.5311706625951745,1e-10,1.0
"def _generate_examples(self, src_path=None, tgt_path=None, replace_unk=None):<tab>""""""Yields examples.""""""<tab>with tf.io.gfile.GFile(src_path) as f_d, tf.io.gfile.GFile(tgt_path) as f_s:<tab><tab>for i, (doc_text, sum_text) in enumerate(zip(f_d, f_s)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i, {<tab><tab><tab><tab><tab>_DOCUMENT: doc_text.strip().replace(""<unk>"", ""UNK""),<tab><tab><tab><tab><tab>_SUMMARY: sum_text.strip().replace(""<unk>"", ""UNK""),<tab><tab><tab><tab>}<tab><tab><tab>else:<tab><tab><tab><tab>yield i, {_DOCUMENT: doc_text.strip(), _SUMMARY: sum_text.strip()}",1,if replace_unk :,if replace_unk :,0.5311706625951745,1e-10,1.0
"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab><IF-STMT><tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text",1,if newline :,if newline :,0.5311706625951745,1e-10,1.0
"def _handle_url_click(self, event):<tab>url = _extract_click_text(self.info_text, event, ""url"")<tab>if url is not None:<tab><tab><IF-STMT><tab><tab><tab>import webbrowser<tab><tab><tab>webbrowser.open(url)<tab><tab>elif os.path.sep in url:<tab><tab><tab>os.makedirs(url, exist_ok=True)<tab><tab><tab>open_path_in_system_file_manager(url)<tab><tab>else:<tab><tab><tab>self._start_show_package_info(url)",0,"if url . startswith ( ""http:"" ) or url . startswith ( ""https:"" ) :",if os . path . isfile ( url ) :,0.01934434502375581,3.820942032434038,0.32675438596491224
"def SConsignFile(self, name="".sconsign"", dbm_module=None):<tab>if name is not None:<tab><tab>name = self.subst(name)<tab><tab><IF-STMT><tab><tab><tab>name = os.path.join(str(self.fs.SConstruct_dir), name)<tab>if name:<tab><tab>name = os.path.normpath(name)<tab><tab>sconsign_dir = os.path.dirname(name)<tab><tab>if sconsign_dir and not os.path.exists(sconsign_dir):<tab><tab><tab>self.Execute(SCons.Defaults.Mkdir(sconsign_dir))<tab>SCons.SConsign.File(name, dbm_module)",0,if not os . path . isabs ( name ) :,if self . fs . SConstruct_dir is not None :,0.014692570747722835,5.063996506781411,0.18181818181818182
"def on_train_start(self, trainer: Trainer, pl_module: LightningModule) -> None:<tab>super().on_train_start(trainer, pl_module)<tab>submodule_dict = dict(pl_module.named_modules())<tab>self._hook_handles = []<tab>for name in self._get_submodule_names(pl_module):<tab><tab><IF-STMT><tab><tab><tab>rank_zero_warn(<tab><tab><tab><tab>f""{name} is not a valid identifier for a submodule in {pl_module.__class__.__name__},""<tab><tab><tab><tab>"" skipping this key.""<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>handle = self._register_hook(name, submodule_dict[name])<tab><tab>self._hook_handles.append(handle)",1,if name not in submodule_dict :,if name not in submodule_dict :,0.75,100.00000000000004,1.0
"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]):<tab>super().validate_configuration(configuration)<tab>if configuration is None:<tab><tab>configuration = self.configuration<tab>try:<tab><tab>assert ""value_set"" in configuration.kwargs, ""value_set is required""<tab><tab>assert isinstance(<tab><tab><tab>configuration.kwargs[""value_set""], (list, set, dict)<tab><tab>), ""value_set must be a list or a set""<tab><tab><IF-STMT><tab><tab><tab>assert (<tab><tab><tab><tab>""$PARAMETER"" in configuration.kwargs[""value_set""]<tab><tab><tab>), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key.'<tab>except AssertionError as e:<tab><tab>raise InvalidExpectationConfigurationError(str(e))<tab>return True",0,"if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if ""value_set"" in configuration . kwargs :",0.04491670711297176,28.75683693213116,0.5630252100840336
"def check_refcounts(expected, timeout=10):<tab>start = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>_check_refcounts(expected)<tab><tab><tab>break<tab><tab>except AssertionError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(0.1)",0,if time . time ( ) - start > timeout :,if time . time ( ) - start >= timeout :,0.8721967289603358,76.91605673134588,1.0
"def pickline(file, key, casefold=1):<tab>try:<tab><tab>f = open(file, ""r"")<tab>except IOError:<tab><tab>return None<tab>pat = re.escape(key) + "":""<tab>prog = re.compile(pat, casefold and re.IGNORECASE)<tab>while 1:<tab><tab>line = f.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if prog.match(line):<tab><tab><tab>text = line[len(key) + 1 :]<tab><tab><tab>while 1:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if not line or not line[0].isspace():<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>text = text + line<tab><tab><tab>return text.strip()<tab>return None",0,if not line :,if not line or line [ 0 ] . isspace ( ) :,0.12747950955459003,12.35622127262679,0.4880952380952381
def _is_perf_file(file_path):<tab>f = get_file(file_path)<tab>for line in f:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>r = event_regexp.search(line)<tab><tab>if r:<tab><tab><tab>f.close()<tab><tab><tab>return True<tab><tab>f.close()<tab><tab>return False,0,"if line [ 0 ] == ""#"" :","if line . startswith ( ""#"" ) :",0.03622895148520873,18.60045401920258,0.6
"def link_pantsrefs(soups, precomputed):<tab>""""""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">""""""<tab>for (page, soup) in soups.items():<tab><tab>for a in soup.find_all(""a""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>pantsref = a[""pantsref""]<tab><tab><tab>if pantsref not in precomputed.pantsref:<tab><tab><tab><tab>raise TaskError(<tab><tab><tab><tab><tab>f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it'<tab><tab><tab><tab>)<tab><tab><tab>a[""href""] = rel_href(page, precomputed.pantsref[pantsref])",0,"if not a . has_attr ( ""pantsref"" ) :","if ""href"" not in a :",0.017951424116240698,4.626275026403788,0.5818181818181818
"def __init__(self, querylist=None):<tab>self.query_id = -1<tab>if querylist is None:<tab><tab>self.querylist = []<tab>else:<tab><tab>self.querylist = querylist<tab><tab>for query in self.querylist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.query_id = query.query_id<tab><tab><tab>else:<tab><tab><tab><tab>if self.query_id != query.query_id:<tab><tab><tab><tab><tab>raise ValueError(""query in list must be same query_id"")",0,if self . query_id == - 1 :,if query . query_id is not - 1 :,0.0854868942093372,35.08439695638686,0.2571428571428572
"def _draw_number(<tab>screen, x_offset, y_offset, number, token=Token.Clock, transparent=False):<tab>""Write number at position.""<tab>fg = Char("" "", token)<tab>bg = Char("" "", Token)<tab>for y, row in enumerate(_numbers[number]):<tab><tab>screen_row = screen.data_buffer[y + y_offset]<tab><tab>for x, n in enumerate(row):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>screen_row[x + x_offset] = fg<tab><tab><tab>elif not transparent:<tab><tab><tab><tab>screen_row[x + x_offset] = bg",0,"if n == ""#"" :",if n == number :,0.14477865547525276,38.49815007763549,0.7
"def init(self):<tab>self.sock.setblocking(True)<tab>if self.parser is None:<tab><tab># wrap the socket if needed<tab><tab><IF-STMT><tab><tab><tab>self.sock = ssl.wrap_socket(<tab><tab><tab><tab>self.sock, server_side=True, **self.cfg.ssl_options<tab><tab><tab>)<tab><tab># initialize the parser<tab><tab>self.parser = http.RequestParser(self.cfg, self.sock)",0,if self . cfg . is_ssl :,if self . cfg . ssl_options :,0.574113272471593,50.197242487957936,1.0
"def intersect_face(pt):<tab># todo: rewrite! inefficient!<tab>nonlocal vis_faces2D<tab>for f, vs in vis_faces2D:<tab><tab>v0 = vs[0]<tab><tab>for v1, v2 in iter_pairs(vs[1:], False):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return f<tab>return None",0,"if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :",if v0 == v1 and v0 == v2 and pt == v0 :,0.013126179354174042,3.377811044913357,0.23809523809523808
"def IMPORTFROM(self, node):<tab>if node.module == ""__future__"":<tab><tab>if not self.futuresAllowed:<tab><tab><tab>self.report(messages.LateFutureImport, node, [n.name for n in node.names])<tab>else:<tab><tab>self.futuresAllowed = False<tab>for alias in node.names:<tab><tab><IF-STMT><tab><tab><tab>self.scope.importStarred = True<tab><tab><tab>self.report(messages.ImportStarUsed, node, node.module)<tab><tab><tab>continue<tab><tab>name = alias.asname or alias.name<tab><tab>importation = Importation(name, node)<tab><tab>if node.module == ""__future__"":<tab><tab><tab>importation.used = (self.scope, node)<tab><tab>self.addBinding(node, importation)",0,"if alias . name == ""*"" :",if alias . asstarred is None :,0.09056531419355518,17.112717058426785,0.38095238095238093
"def PyObject_Bytes(obj):<tab>if type(obj) == bytes:<tab><tab>return obj<tab>if hasattr(obj, ""__bytes__""):<tab><tab>res = obj.__bytes__()<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""__bytes__ returned non-bytes (type %s)"" % type(res).__name__<tab><tab><tab>)<tab>return PyBytes_FromObject(obj)",1,"if not isinstance ( res , bytes ) :","if not isinstance ( res , bytes ) :",0.75,100.00000000000004,1.0
"def on_bt_search_clicked(self, widget):<tab>if self.current_provider is None:<tab><tab>return<tab>query = self.en_query.get_text()<tab>@self.obtain_podcasts_with<tab>def load_data():<tab><tab>if self.current_provider.kind == directory.Provider.PROVIDER_SEARCH:<tab><tab><tab>return self.current_provider.on_search(query)<tab><tab>elif self.current_provider.kind == directory.Provider.PROVIDER_URL:<tab><tab><tab>return self.current_provider.on_url(query)<tab><tab><IF-STMT><tab><tab><tab>return self.current_provider.on_file(query)",0,elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,elif self . current_provider . kind == directory . Provider .PROVIDER_FILE :,0.628588575094944,100.00000000000004,1.0
"def remove(self, name):<tab>for s in [self.__storage(self.__category), self.__storage(None)]:<tab><tab>for i, b in enumerate(s):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del s[i]<tab><tab><tab><tab>if b.persistent:<tab><tab><tab><tab><tab>self.__save()<tab><tab><tab><tab>return<tab>raise KeyError(name)",1,if b . name == name :,if b . name == name :,1.0,100.00000000000004,1.0
"def _wrapper(data, axis=None, keepdims=False):<tab>if not keepdims:<tab><tab>return func(data, axis=axis)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>axis = axis if isinstance(axis, int) else axis[0]<tab><tab><tab>out_shape = list(data.shape)<tab><tab><tab>out_shape[axis] = 1<tab><tab>else:<tab><tab><tab>out_shape = [1 for _ in range(len(data.shape))]<tab><tab>return func(data, axis=axis).reshape(out_shape)",1,if axis is not None :,if axis is not None :,0.75,100.00000000000004,1.0
"def authn_info(self):<tab>res = []<tab>for astat in self.assertion.authn_statement:<tab><tab>context = astat.authn_context<tab><tab>try:<tab><tab><tab>authn_instant = astat.authn_instant<tab><tab>except AttributeError:<tab><tab><tab>authn_instant = """"<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>aclass = context.authn_context_class_ref.text<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>aclass = """"<tab><tab><tab>try:<tab><tab><tab><tab>authn_auth = [a.text for a in context.authenticating_authority]<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>authn_auth = []<tab><tab><tab>res.append((aclass, authn_auth, authn_instant))<tab>return res",0,if context :,if authn_instant :,0.3197504490129165,1e-10,0.5555555555555555
"def _persist_metadata(self, dirname, filename):<tab>metadata_path = ""{0}/{1}.json"".format(dirname, filename)<tab>if self.media_metadata or self.comments or self.include_location:<tab><tab>if self.posts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.merge_json({""GraphImages"": self.posts}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphImages"": self.posts}, metadata_path)<tab><tab>if self.stories:<tab><tab><tab>if self.latest:<tab><tab><tab><tab>self.merge_json({""GraphStories"": self.stories}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphStories"": self.stories}, metadata_path)",1,if self . latest :,if self . latest :,0.75,100.00000000000004,1.0
"def update_record_image_detail(input_image_record, updated_image_detail, session=None):<tab>if not session:<tab><tab>session = db.Session<tab>image_record = {}<tab>image_record.update(input_image_record)<tab>image_record.pop(""created_at"", None)<tab>image_record.pop(""last_updated"", None)<tab>if image_record[""image_type""] == ""docker"":<tab><tab>for tag_record in updated_image_detail:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>image_record[""image_detail""].append(tag_record)<tab><tab><tab><tab>return update_record(image_record, session=session)<tab>return image_record",1,"if tag_record not in image_record [ ""image_detail"" ] :","if tag_record not in image_record [ ""image_detail"" ] :",0.75,100.00000000000004,1.0
"def backup(self):<tab>for ds in [(""activedirectory"", ""AD""), (""ldap"", ""LDAP""), (""nis"", ""NIS"")]:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>ds_cache = self.middleware.call_sync(""cache.get"", f""{ds[1]}_cache"")<tab><tab><tab><tab>with open(f""/var/db/system/.{ds[1]}_cache_backup"", ""wb"") as f:<tab><tab><tab><tab><tab>pickle.dump(ds_cache, f)<tab><tab><tab>except KeyError:<tab><tab><tab><tab>self.logger.debug(""No cache exists for directory service [%s]."", ds[0])",0,"if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :","if self . middleware . call_sync ( ""cache.exists"" , f""{ds[1]}_cache"" ) :",0.244968472480517,42.22380239418518,1.0
"def parse_setup_cfg(self):<tab># type: () -> Dict[STRING_TYPE, Any]<tab>if self.setup_cfg is not None and self.setup_cfg.exists():<tab><tab>contents = self.setup_cfg.read_text()<tab><tab>base_dir = self.setup_cfg.absolute().parent.as_posix()<tab><tab>try:<tab><tab><tab>parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix())<tab><tab>except Exception:<tab><tab><tab>if six.PY2:<tab><tab><tab><tab>contents = self.setup_cfg.read_bytes()<tab><tab><tab>parsed = parse_setup_cfg(contents, base_dir)<tab><tab><IF-STMT><tab><tab><tab>return {}<tab><tab>return parsed<tab>return {}",0,if not parsed :,if parsed is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def parts():<tab>for l in lists.leaves:<tab><tab>head_name = l.get_head_name()<tab><tab><IF-STMT><tab><tab><tab>yield l.leaves<tab><tab>elif head_name != ""System`Missing"":<tab><tab><tab>raise MessageException(""Catenate"", ""invrp"", l)",0,"if head_name == ""System`List"" :","if head_name == ""List"" :",0.39477865547525276,64.32188699036833,1.0
"def _get_callback_and_order(self, hook):<tab>if callable(hook):<tab><tab>return hook, None<tab>elif isinstance(hook, tuple) and len(hook) == 2:<tab><tab>callback, order = hook<tab><tab># test that callback is a callable<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Hook callback is not a callable"")<tab><tab># test that number is an int<tab><tab>try:<tab><tab><tab>int(order)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""Hook order is not a number"")<tab><tab>return callback, order<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>""Invalid hook definition, neither a callable nor a 2-tuple (callback, order): {!r}"".format(<tab><tab><tab><tab>hook<tab><tab><tab>)<tab><tab>)",1,if not callable ( callback ) :,if not callable ( callback ) :,0.75,100.00000000000004,1.0
"def _resize_masks(self, results):<tab>""""""Resize masks with ``results['scale']``""""""<tab>for key in results.get(""mask_fields"", []):<tab><tab>if results[key] is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>results[key] = results[key].rescale(results[""scale""])<tab><tab>else:<tab><tab><tab>results[key] = results[key].resize(results[""img_shape""][:2])",0,if self . keep_ratio :,"if results [ key ] . get ( ""scale"" ) is not None :",0.023562158811158227,3.21858262703621,0.1929824561403509
"def getDataMax(self):<tab>result = -Double.MAX_VALUE<tab>nCurves = self.chart.getNCurves()<tab>for i in range(nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab>if not c.isVisible():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>nPoints = c.getNPoints()<tab><tab><tab>for j in range(nPoints):<tab><tab><tab><tab>result = self.maxIgnoreNaNAndMaxValue(result, c.getPoint(j).getY())<tab>if result == -Double.MAX_VALUE:<tab><tab>return Double.NaN<tab>return result",0,if c . getYAxis ( ) == Y_AXIS :,if c . isVisible ( ) :,0.18089226606614267,15.749996500436227,0.6
"def _check_token(self):<tab>if settings.app.sso_client_cache and self.server_auth_token:<tab><tab>doc = self.sso_client_cache_collection.find_one(<tab><tab><tab>{<tab><tab><tab><tab>""user_id"": self.user.id,<tab><tab><tab><tab>""server_id"": self.server.id,<tab><tab><tab><tab>""device_id"": self.device_id,<tab><tab><tab><tab>""device_name"": self.device_name,<tab><tab><tab><tab>""auth_token"": self.server_auth_token,<tab><tab><tab>}<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.has_token = True",1,if doc :,if doc :,0.5311706625951745,1e-10,1.0
"def parse_header(plyfile, ext):<tab># Variables<tab>line = []<tab>properties = []<tab>num_points = None<tab>while b""end_header"" not in line and line != b"""":<tab><tab>line = plyfile.readline()<tab><tab><IF-STMT><tab><tab><tab>line = line.split()<tab><tab><tab>num_points = int(line[2])<tab><tab>elif b""property"" in line:<tab><tab><tab>line = line.split()<tab><tab><tab>properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))<tab>return num_points, properties",0,"if b""element"" in line :","if b""num_points"" in line :",0.39477865547525276,37.99178428257963,1.0
"def __codeanalysis_settings_changed(self, current_finfo):<tab>if self.data:<tab><tab>run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled<tab><tab>for finfo in self.data:<tab><tab><tab>self.__update_editor_margins(finfo.editor)<tab><tab><tab>finfo.cleanup_analysis_results()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if current_finfo is not finfo:<tab><tab><tab><tab><tab>finfo.run_code_analysis(run_pyflakes, run_pep8)",0,if ( run_pyflakes or run_pep8 ) and current_finfo is not None :,if run_pyflakes and run_pep8 :,0.12292794241721641,12.151662434083685,0.25
"def __modules(self):<tab>raw_output = self.__module_avail_output().decode(""utf-8"")<tab>for line in StringIO(raw_output):<tab><tab>line = line and line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>line_modules = line.split()<tab><tab>for module in line_modules:<tab><tab><tab>if module.endswith(self.default_indicator):<tab><tab><tab><tab>module = module[0 : -len(self.default_indicator)].strip()<tab><tab><tab>module_parts = module.split(""/"")<tab><tab><tab>module_version = None<tab><tab><tab>if len(module_parts) == 2:<tab><tab><tab><tab>module_version = module_parts[1]<tab><tab><tab>module_name = module_parts[0]<tab><tab><tab>yield module_name, module_version",0,"if not line or line . startswith ( ""-"" ) :",if not line :,0.04614409468537624,6.734410772670761,0.5726495726495727
"def _set_trailing_size(self, size):<tab>if self.is_free():<tab><tab>next_chunk = self.next_chunk()<tab><tab><IF-STMT><tab><tab><tab>self.state.memory.store(next_chunk.base, size, self.state.arch.bytes)",1,if next_chunk is not None :,if next_chunk is not None :,0.75,100.00000000000004,1.0
"def _execute_for_all_tables(self, app, bind, operation, skip_tables=False):<tab>app = self.get_app(app)<tab>if bind == ""__all__"":<tab><tab>binds = [None] + list(app.config.get(""SQLALCHEMY_BINDS"") or ())<tab>elif isinstance(bind, string_types) or bind is None:<tab><tab>binds = [bind]<tab>else:<tab><tab>binds = bind<tab>for bind in binds:<tab><tab>extra = {}<tab><tab><IF-STMT><tab><tab><tab>tables = self.get_tables_for_bind(bind)<tab><tab><tab>extra[""tables""] = tables<tab><tab>op = getattr(self.Model.metadata, operation)<tab><tab>op(bind=self.get_engine(app, bind), **extra)",0,if not skip_tables :,if skip_tables :,0.09648852821835877,1e-10,0.6
"def getFileName():<tab>extension = "".json""<tab>file = ""%s-stats"" % self.clusterName<tab>counter = 0<tab>while True:<tab><tab>suffix = str(counter).zfill(3) + extension<tab><tab>fullName = os.path.join(self.statsPath, file + suffix)<tab><tab><IF-STMT><tab><tab><tab>return fullName<tab><tab>counter += 1",0,if not os . path . exists ( fullName ) :,if os . path . exists ( fullName ) :,0.4074990052689752,81.76129038784515,0.27272727272727276
def logic():<tab># direction<tab>if goRight == ACTIVE:<tab><tab>dir.next = DirType.RIGHT<tab><tab>run.next = True<tab>elif goLeft == ACTIVE:<tab><tab>dir.next = DirType.LEFT<tab><tab>run.next = True<tab># stop<tab>if stop == ACTIVE:<tab><tab>run.next = False<tab># counter action<tab>if run:<tab><tab><IF-STMT><tab><tab><tab>q.next[4:1] = q[3:]<tab><tab><tab>q.next[0] = not q[3]<tab><tab>else:<tab><tab><tab>q.next[3:] = q[4:1]<tab><tab><tab>q.next[3] = not q[0],0,if dir == DirType . LEFT :,if q [ 0 ] :,0.021817413581977953,6.916271812933183,0.2653061224489796
"def test_broadcast(self):<tab>""""""Test example broadcast functionality.""""""<tab>self.create_lang_connection(""1000000000"", ""en"")<tab>self.create_lang_connection(""1000000001"", ""en"")<tab>self.create_lang_connection(""1000000002"", ""en"")<tab>self.create_lang_connection(""1000000003"", ""es"")<tab>self.create_lang_connection(""1000000004"", ""es"")<tab>app.lang_broadcast()<tab>self.assertEqual(2, len(self.outbound))<tab>for message in self.outbound:<tab><tab>if message.text == ""hello"":<tab><tab><tab>self.assertEqual(3, len(message.connections))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(2, len(message.connections))",0,"elif message . text == ""hola"" :","elif message . text == ""hello2"" :",0.8217294420803809,70.71067811865478,1.0
"def get_ovf_env(dirname):<tab>env_names = (""ovf-env.xml"", ""ovf_env.xml"", ""OVF_ENV.XML"", ""OVF-ENV.XML"")<tab>for fname in env_names:<tab><tab>full_fn = os.path.join(dirname, fname)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>contents = util.load_file(full_fn)<tab><tab><tab><tab>return (fname, contents)<tab><tab><tab>except Exception:<tab><tab><tab><tab>util.logexc(LOG, ""Failed loading ovf file %s"", full_fn)<tab>return (None, False)",1,if os . path . isfile ( full_fn ) :,if os . path . isfile ( full_fn ) :,0.75,100.00000000000004,1.0
"def _calc_offsets_children(self, offset, is_last):<tab>if self.elems:<tab><tab>elem_last = self.elems[-1]<tab><tab>for elem in self.elems:<tab><tab><tab>offset = elem._calc_offsets(offset, (elem is elem_last))<tab><tab>offset += _BLOCK_SENTINEL_LENGTH<tab>elif not self.props or self.id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL:<tab><tab><IF-STMT><tab><tab><tab>offset += _BLOCK_SENTINEL_LENGTH<tab>return offset",1,if not is_last :,if not is_last :,0.75,100.00000000000004,1.0
"def publish_state(cls, payload, state):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if state == action_constants.LIVEACTION_STATUS_REQUESTED:<tab><tab><tab><tab>cls.process(payload)<tab><tab><tab>else:<tab><tab><tab><tab>worker.get_worker().process(payload)<tab>except Exception:<tab><tab>traceback.print_exc()<tab><tab>print(payload)",0,"if isinstance ( payload , LiveActionDB ) :",if state != action_constants . LIVEACTION_STATUS_RUNNING :,0.018333424761606272,3.377156414337854,0.3
"def log_predictive_density(self, x_test, y_test, Y_metadata=None):<tab>if isinstance(x_test, list):<tab><tab>x_test, y_test, ind = util.multioutput.build_XY(x_test, y_test)<tab><tab><IF-STMT><tab><tab><tab>Y_metadata = {""output_index"": ind, ""trials"": np.ones(ind.shape)}<tab>return super(MultioutputGP, self).log_predictive_density(x_test, y_test, Y_metadata)",1,if Y_metadata is None :,if Y_metadata is None :,0.75,100.00000000000004,1.0
"def minimalBases(classes):<tab>""""""Reduce a list of base classes to its ordered minimum equivalent""""""<tab>if not __python3:  # pragma: no cover<tab><tab>classes = [c for c in classes if c is not ClassType]<tab>candidates = []<tab>for m in classes:<tab><tab>for n in classes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># m has no subclasses in 'classes'<tab><tab><tab>if m in candidates:<tab><tab><tab><tab>candidates.remove(m)  # ensure that we're later in the list<tab><tab><tab>candidates.append(m)<tab>return candidates",0,"if issubclass ( n , m ) and m is not n :",if m == n :,0.017683240570122077,6.011598678897526,0.27976190476190477
"def apply(self, operations, rotations=None, **kwargs):<tab>rotations = rotations or []<tab># apply the circuit operations<tab>for i, operation in enumerate(operations):<tab><tab><IF-STMT><tab><tab><tab>raise DeviceError(<tab><tab><tab><tab>""Operation {} cannot be used after other Operations have already been applied ""<tab><tab><tab><tab>""on a {} device."".format(operation.name, self.short_name)<tab><tab><tab>)<tab>for operation in operations:<tab><tab>self._apply_operation(operation)<tab># store the pre-rotated state<tab>self._pre_rotated_state = self._state<tab># apply the circuit rotations<tab>for operation in rotations:<tab><tab>self._apply_operation(operation)",0,"if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :","if self . _apply_operations ( operation , ** kwargs ) :",0.08646215192514164,12.044026117975157,0.16363636363636364
"def __str__(self):<tab>txt = str(self._called)<tab>if self.call_gas or self.call_value:<tab><tab>gas = f""gas: {self.call_gas}"" if self.call_gas else """"<tab><tab>value = f""value: {self.call_value}"" if self.call_value else """"<tab><tab>salt = f""salt: {self.call_salt}"" if self.call_salt else """"<tab><tab><IF-STMT><tab><tab><tab>options = [gas, value, salt]<tab><tab><tab>txt += ""{"" + "","".join([o for o in options if o != """"]) + ""}""<tab>return txt + ""("" + "","".join([str(a) for a in self._arguments]) + "")""",0,if gas or value or salt :,if self . call_gas :,0.02225082504991546,8.643019616048525,0.19047619047619047
"def pop(self):<tab>""""""Pop a nonterminal.  (Internal)""""""<tab>popdfa, popstate, popnode = self.stack.pop()<tab>newnode = self.convert(self.grammar, popnode)<tab>if newnode is not None:<tab><tab><IF-STMT><tab><tab><tab>dfa, state, node = self.stack[-1]<tab><tab><tab>node.children.append(newnode)<tab><tab>else:<tab><tab><tab>self.rootnode = newnode",1,if self . stack :,if self . stack :,0.75,100.00000000000004,1.0
"def pollpacket(self, wait):<tab>self._stage0()<tab>if len(self.buffer) < self.bufneed:<tab><tab>r, w, x = select.select([self.sock.fileno()], [], [], wait)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>try:<tab><tab><tab>s = self.sock.recv(BUFSIZE)<tab><tab>except socket.error:<tab><tab><tab>raise EOFError<tab><tab>if len(s) == 0:<tab><tab><tab>raise EOFError<tab><tab>self.buffer += s<tab><tab>self._stage0()<tab>return self._stage1()",1,if len ( r ) == 0 :,if len ( r ) == 0 :,0.75,100.00000000000004,1.0
"def increaseToolReach(self):<tab>if self.draggingFace is not None:<tab><tab>d = (1, -1)[self.draggingFace & 1]<tab><tab><IF-STMT>  # xxxxx y<tab><tab><tab>d = -d<tab><tab>self.draggingY += d<tab><tab>x, y, z = self.editor.mainViewport.cameraPosition<tab><tab>pos = [x, y, z]<tab><tab>pos[self.draggingFace >> 1] += d<tab><tab>self.editor.mainViewport.cameraPosition = tuple(pos)<tab>else:<tab><tab>self.cloneCameraDistance = self.editor._incrementReach(self.cloneCameraDistance)<tab>return True",0,if self . draggingFace >> 1 != 1 :,if self . draggingFace >> 1 == 0 :,0.5584858117105135,60.767958081376904,0.7777777777777777
"def selectionToChunks(self, remove=False, add=False):<tab>box = self.selectionBox()<tab>if box:<tab><tab>if box == self.level.bounds:<tab><tab><tab>self.selectedChunks = set(self.level.allChunks)<tab><tab><tab>return<tab><tab>selectedChunks = self.selectedChunks<tab><tab>boxedChunks = set(box.chunkPositions)<tab><tab>if boxedChunks.issubset(selectedChunks):<tab><tab><tab>remove = True<tab><tab><IF-STMT><tab><tab><tab>selectedChunks.difference_update(boxedChunks)<tab><tab>else:<tab><tab><tab>selectedChunks.update(boxedChunks)<tab>self.selectionTool.selectNone()",0,if remove and not add :,if add :,0.050438393472541504,1e-10,0.2333333333333333
"def __init__(self, *args, **kwargs):<tab>super(ProjectForm, self).__init__(*args, **kwargs)<tab>if self.instance.id:<tab><tab><IF-STMT><tab><tab><tab>self.fields[""localfiletype""].widget.attrs[""disabled""] = True<tab><tab><tab>self.fields[""localfiletype""].required = False<tab><tab>if (<tab><tab><tab>self.instance.treestyle != ""auto""<tab><tab><tab>and self.instance.translationproject_set.count()<tab><tab><tab>and self.instance.treestyle == self.instance._detect_treestyle()<tab><tab>):<tab><tab><tab>self.fields[""treestyle""].widget.attrs[""disabled""] = True<tab><tab><tab>self.fields[""treestyle""].required = False",0,if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,"if self . instance . localfiletype != ""auto"" and self . instance . localfiletype == ""default"" :",0.2573479278884505,8.066974340737671,0.19523809523809524
"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab>if arg is None:<tab><tab><tab>continue<tab><tab>if isinstance(arg, bytes):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab>if return_type is bytes:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type",0,if return_type is str :,if return_type is bytes :,0.39477865547525276,64.34588841607616,0.6
"def deleteDuplicates(gadgets, callback=None):<tab>toReturn = []<tab>inst = set()<tab>count = 0<tab>added = False<tab>len_gadgets = len(gadgets)<tab>for i, gadget in enumerate(gadgets):<tab><tab>inst.add(gadget._gadget)<tab><tab>if len(inst) > count:<tab><tab><tab>count = len(inst)<tab><tab><tab>toReturn.append(gadget)<tab><tab><tab>added = True<tab><tab><IF-STMT><tab><tab><tab>callback(gadget, added, float(i + 1) / (len_gadgets))<tab><tab><tab>added = False<tab>return toReturn",0,if callback :,if callback is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def send_all(self, data: bytes):<tab>with self._conflict_detector:<tab><tab><IF-STMT><tab><tab><tab>raise _core.ClosedResourceError(""this pipe is already closed"")<tab><tab>if not data:<tab><tab><tab>await _core.checkpoint()<tab><tab><tab>return<tab><tab>try:<tab><tab><tab>written = await _core.write_overlapped(self._handle_holder.handle, data)<tab><tab>except BrokenPipeError as ex:<tab><tab><tab>raise _core.BrokenResourceError from ex<tab><tab># By my reading of MSDN, this assert is guaranteed to pass so long<tab><tab># as the pipe isn't in nonblocking mode, but... let's just<tab><tab># double-check.<tab><tab>assert written == len(data)",0,if self . _handle_holder . closed :,if self . _closed :,0.15703229110448028,31.02451704053729,0.7222222222222222
"def setup_parameter_node(self, param_node):<tab>if param_node.bl_idname == ""SvNumberNode"":<tab><tab><IF-STMT><tab><tab><tab>value = self.sv_get()[0][0]<tab><tab><tab>print(""V"", value)<tab><tab><tab>if isinstance(value, int):<tab><tab><tab><tab>param_node.selected_mode = ""int""<tab><tab><tab><tab>param_node.int_ = value<tab><tab><tab>elif isinstance(value, float):<tab><tab><tab><tab>param_node.selected_mode = ""float""<tab><tab><tab><tab>param_node.float_ = value",0,if self . use_prop or self . get_prop_name ( ) :,if self . sv_get ( ) :,0.17380972890875196,13.185679291149079,0.6354166666666666
"def collect_active_inst_idx_list(inst_beams, word_prob, inst_idx_to_position_map):<tab>active_inst_idx_list = []<tab>for inst_idx, inst_position in inst_idx_to_position_map.items():<tab><tab>is_inst_complete = inst_beams[inst_idx].advance(word_prob[inst_position])<tab><tab><IF-STMT><tab><tab><tab>active_inst_idx_list += [inst_idx]<tab>return active_inst_idx_list",0,if not is_inst_complete :,if is_inst_complete :,0.09648852821835877,1e-10,0.6
"def compare_member_req_resp_without_key(self, request, response):<tab>for user_response in resp_json(response)[""data""]:<tab><tab>for user_request in request:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert user_request[""role""] == user_response[""role""]",0,"if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :","if ""role"" in user_request :",0.012417879185700129,4.142904542920855,0.6491228070175438
"def __init__(self, dir):<tab>self.module_names = set()<tab>for name in os.listdir(dir):<tab><tab>if name.endswith("".py""):<tab><tab><tab>self.module_names.add(name[:-3])<tab><tab><IF-STMT><tab><tab><tab>self.module_names.add(name)",0,"elif ""."" not in name :","elif os . path . isfile ( os . path . join ( dir , name ) ) :",0.066782330593239,2.8629993657668873,0.18
"def _read_filter(self, data):<tab>if data:<tab><tab>if self.expected_inner_sha256:<tab><tab><tab>self.inner_sha.update(data)<tab><tab><IF-STMT><tab><tab><tab>self.inner_md5.update(data)<tab>return data",0,if self . expected_inner_md5sum :,if self . expected_inner_md5 :,0.39477865547525276,75.06238537503395,1.0
"def _p_basicstr_content(s, content=_basicstr_re):<tab>res = []<tab>while True:<tab><tab>res.append(s.expect_re(content).group(0))<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if s.consume_re(_newline_esc_re):<tab><tab><tab>pass<tab><tab>elif s.consume_re(_short_uni_re) or s.consume_re(_long_uni_re):<tab><tab><tab>res.append(_chr(int(s.last().group(1), 16)))<tab><tab>else:<tab><tab><tab>s.expect_re(_escapes_re)<tab><tab><tab>res.append(_escapes[s.last().group(0)])<tab>return """".join(res)",0,"if not s . consume ( ""\\"" ) :",if not s . last ( ) :,0.2509566599936256,25.9162669876144,0.6666666666666666
"def process_response(self, request, response):<tab>if (<tab><tab>response.status_code == 404<tab><tab>and request.path_info.endswith(""/"")<tab><tab>and not is_valid_path(request.path_info)<tab><tab>and is_valid_path(request.path_info[:-1])<tab>):<tab><tab># Use request.path because we munged app/locale in path_info.<tab><tab>newurl = request.path[:-1]<tab><tab><IF-STMT><tab><tab><tab>with safe_query_string(request):<tab><tab><tab><tab>newurl += ""?"" + request.META.get(""QUERY_STRING"", """")<tab><tab>return HttpResponsePermanentRedirect(newurl)<tab>else:<tab><tab>return response",1,if request . GET :,if request . GET :,0.75,100.00000000000004,1.0
"def convertDict(obj):<tab>obj = dict(obj)<tab>for k, v in obj.items():<tab><tab>del obj[k]<tab><tab><IF-STMT><tab><tab><tab>k = dumps(k)<tab><tab><tab># Keep track of which keys need to be decoded when loading.<tab><tab><tab>if Types.KEYS not in obj:<tab><tab><tab><tab>obj[Types.KEYS] = []<tab><tab><tab>obj[Types.KEYS].append(k)<tab><tab>obj[k] = convertObjects(v)<tab>return obj",0,"if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :","if isinstance ( k , str ) :",0.2442263857587956,21.923515613839378,0.22282608695652173
"def __repr__(self):<tab>if self._in_repr:<tab><tab>return ""<recursion>""<tab>try:<tab><tab>self._in_repr = True<tab><tab><IF-STMT><tab><tab><tab>status = ""computed, ""<tab><tab><tab>if self.error() is None:<tab><tab><tab><tab>if self.value() is self:<tab><tab><tab><tab><tab>status += ""= self""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>status += ""= "" + repr(self.value())<tab><tab><tab>else:<tab><tab><tab><tab>status += ""error = "" + repr(self.error())<tab><tab>else:<tab><tab><tab>status = ""isn't computed""<tab><tab>return ""%s (%s)"" % (type(self), status)<tab>finally:<tab><tab>self._in_repr = False",0,if self . is_computed ( ) :,if self . computed :,0.09453229110448028,20.300727612812874,0.7222222222222222
"def allocate_network(ipv=""ipv4""):<tab>global dtcd_uuid<tab>global network_pool<tab>global allocations<tab>network = None<tab>try:<tab><tab>cx = httplib.HTTPConnection(""localhost:7623"")<tab><tab>cx.request(""POST"", ""/v1/network/%s/"" % ipv, body=dtcd_uuid)<tab><tab>resp = cx.getresponse()<tab><tab><IF-STMT><tab><tab><tab>network = netaddr.IPNetwork(resp.read().decode(""utf-8""))<tab><tab>cx.close()<tab>except Exception:<tab><tab>pass<tab>if network is None:<tab><tab>network = network_pool[ipv].pop()<tab><tab>allocations[network] = True<tab>return network",0,if resp . status == 200 :,if resp . status_code == 200 :,0.3884893899276739,52.53819788848316,0.5714285714285714
"def change_args_to_dict(string):<tab>if string is None:<tab><tab>return None<tab>ans = []<tab>strings = string.split(""\n"")<tab>ind = 1<tab>start = 0<tab>while ind <= len(strings):<tab><tab>if ind < len(strings) and strings[ind].startswith("" ""):<tab><tab><tab>ind += 1<tab><tab>else:<tab><tab><tab>if start < ind:<tab><tab><tab><tab>ans.append(""\n"".join(strings[start:ind]))<tab><tab><tab>start = ind<tab><tab><tab>ind += 1<tab>d = {}<tab>for line in ans:<tab><tab><IF-STMT><tab><tab><tab>lines = line.split("":"")<tab><tab><tab>d[lines[0]] = lines[1].strip()<tab>return d",0,"if "":"" in line and len ( line ) > 0 :","if "":"" in line :",0.10400131924210887,30.93485033266056,0.48299319727891155
"def kill_members(members, sig, hosts=nodes):<tab>for member in sorted(members):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""killing %s"" % member)<tab><tab><tab>proc = hosts[member][""proc""]<tab><tab><tab># Not sure if cygwin makes sense here...<tab><tab><tab>if sys.platform in (""win32"", ""cygwin""):<tab><tab><tab><tab>os.kill(proc.pid, signal.CTRL_C_EVENT)<tab><tab><tab>else:<tab><tab><tab><tab>os.kill(proc.pid, sig)<tab><tab>except OSError:<tab><tab><tab>if ha_tools_debug:<tab><tab><tab><tab>print(""%s already dead?"" % member)",1,if ha_tools_debug :,if ha_tools_debug :,0.5311706625951745,1e-10,1.0
"def check(self):<tab>for path in self.paths:<tab><tab>response = self.http_request(<tab><tab><tab>method=""GET"",<tab><tab><tab>path=path,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if any(<tab><tab><tab>map(<tab><tab><tab><tab>lambda x: x in response.text,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>""report.db.server.name"",<tab><tab><tab><tab><tab>""report.db.server.sa.pass"",<tab><tab><tab><tab><tab>""report.db.server.user.pass"",<tab><tab><tab><tab>],<tab><tab><tab>)<tab><tab>):<tab><tab><tab>self.valid = path<tab><tab><tab>return True  # target is vulnerable<tab>return False  # target not vulnerable",1,if response is None :,if response is None :,0.75,100.00000000000004,1.0
"def get_to_download_runs_ids(session, headers):<tab>last_date = 0<tab>result = []<tab>while 1:<tab><tab>r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers)<tab><tab>if r.ok:<tab><tab><tab>run_logs = r.json()[""data""][""records""]<tab><tab><tab>result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs])<tab><tab><tab>last_date = r.json()[""data""][""lastTimestamp""]<tab><tab><tab>since_time = datetime.utcfromtimestamp(last_date / 1000)<tab><tab><tab>print(f""pares keep ids data since {since_time}"")<tab><tab><tab>time.sleep(1)  # spider rule<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return result",0,if not last_date :,if since_time > last_date :,0.08029029484721717,31.55984539112946,0.6190476190476191
"def button_press_cb(self, tdw, event):<tab>self._update_zone_and_cursors(tdw, event.x, event.y)<tab>if self._zone in (_EditZone.CREATE_FRAME, _EditZone.REMOVE_FRAME):<tab><tab>button = event.button<tab><tab><IF-STMT><tab><tab><tab>self._click_info = (button, self._zone)<tab><tab><tab>return False<tab>return super(FrameEditMode, self).button_press_cb(tdw, event)",0,if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,if button is not None :,0.06989501268941836,2.058073185415509,0.2352941176470588
"def first_timestep():<tab>assignment = self.has_previous.assign(<tab><tab>value=tf_util.constant(value=True, dtype=""bool""), read_value=False<tab>)<tab>with tf.control_dependencies(control_inputs=(assignment,)):<tab><tab><IF-STMT><tab><tab><tab>current = x<tab><tab>else:<tab><tab><tab>current = tf.expand_dims(input=x, axis=(self.axis + 1))<tab><tab>multiples = tuple(<tab><tab><tab>self.length if dims == self.axis + 1 else 1<tab><tab><tab>for dims in range(self.output_spec().rank + 1)<tab><tab>)<tab><tab>return tf.tile(input=current, multiples=multiples)",0,if self . concatenate :,if self . axis == 0 :,0.11726065783135259,22.089591134157878,0.4761904761904762
"def main() -> None:<tab>onefuzz = Onefuzz()<tab>jobs = onefuzz.jobs.list()<tab>for job in jobs:<tab><tab>print(<tab><tab><tab>""job:"",<tab><tab><tab>str(job.job_id)[:8],<tab><tab><tab>"":"".join([job.config.project, job.config.name, job.config.build]),<tab><tab>)<tab><tab>for task in onefuzz.tasks.list(job_id=job.job_id):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>print(<tab><tab><tab><tab>""<tab>"",<tab><tab><tab><tab>str(task.task_id)[:8],<tab><tab><tab><tab>task.config.task.type,<tab><tab><tab><tab>task.config.task.target_exe,<tab><tab><tab>)",0,"if task . state in [ ""stopped"" , ""stopping"" ] :",if task . task_id == 0 :,0.052382555543060455,10.180289369384242,0.48888888888888893
"def update_stack(self, full_name, template_url, parameters, tags):<tab>""""""Updates an existing stack in CloudFormation.""""""<tab>try:<tab><tab>logger.info(""Attempting to update stack %s."", full_name)<tab><tab>self.conn.cloudformation.update_stack(<tab><tab><tab>full_name,<tab><tab><tab>template_url=template_url,<tab><tab><tab>parameters=parameters,<tab><tab><tab>tags=tags,<tab><tab><tab>capabilities=[""CAPABILITY_IAM""],<tab><tab>)<tab><tab>return SUBMITTED<tab>except BotoServerError as e:<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Stack %s did not change, not updating."", full_name)<tab><tab><tab>return SKIPPED<tab><tab>raise",0,"if ""No updates are to be performed."" in e . message :",if e . status == 404 :,0.02201808967453111,5.4752948205155585,0.1515151515151515
"def header_tag_files(env, files, legal_header, script_files=False):<tab>""""""Apply the legal_header to the list of files""""""<tab>try:<tab><tab>import apply_legal_header<tab>except:<tab><tab>xbc.cdie(""XED ERROR: mfile.py could not find scripts directory"")<tab>for g in files:<tab><tab>print(""G: "", g)<tab><tab>for f in mbuild.glob(g):<tab><tab><tab>print(""F: "", f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>apply_legal_header.apply_header_to_data_file(legal_header, f)<tab><tab><tab>else:<tab><tab><tab><tab>apply_legal_header.apply_header_to_source_file(legal_header, f)",1,if script_files :,if script_files :,0.5311706625951745,1e-10,1.0
"def cleanDataCmd(cmd):<tab>newcmd = ""AbracadabrA ** <?php ""<tab>if cmd[:6] != ""php://"":<tab><tab>if reverseConn not in cmd:<tab><tab><tab>cmds = cmd.split(""&"")<tab><tab><tab>for c in cmds:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>newcmd += ""system('%s');"" % c<tab><tab>else:<tab><tab><tab>b64cmd = base64.b64encode(cmd)<tab><tab><tab>newcmd += ""system(base64_decode('%s'));"" % b64cmd<tab>else:<tab><tab>newcmd += cmd[6:]<tab>newcmd += ""?> **""<tab>return newcmd",0,if len ( c ) > 0 :,if c . isdigit ( ) :,0.021572626131656978,8.513058489093439,0.3148148148148148
"def test_form(self):<tab>n_qubits = 6<tab>random_operator = get_fermion_operator(random_interaction_operator(n_qubits))<tab>chemist_operator = chemist_ordered(random_operator)<tab>for term, _ in chemist_operator.terms.items():<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.assertTrue(term[0][1])<tab><tab><tab>self.assertTrue(term[2][1])<tab><tab><tab>self.assertFalse(term[1][1])<tab><tab><tab>self.assertFalse(term[3][1])<tab><tab><tab>self.assertTrue(term[0][0] > term[2][0])<tab><tab><tab>self.assertTrue(term[1][0] > term[3][0])",0,if len ( term ) == 2 or not len ( term ) :,if len ( term ) == n_qubits :,0.2699950242670695,41.016750098594244,0.43417366946778707
"def do(server, handler, config, modargs):<tab>data = []<tab>clients = server.get_clients(handler.default_filter)<tab>if not clients:<tab><tab>return<tab>for client in clients:<tab><tab>tags = config.tags(client.node())<tab><tab><IF-STMT><tab><tab><tab>tags.remove(*modargs.remove)<tab><tab>if modargs.add:<tab><tab><tab>tags.add(*modargs.add)<tab><tab>data.append({""ID"": client.node(), ""TAGS"": tags})<tab>config.save(project=modargs.write_project, user=modargs.write_user)<tab>handler.display(Table(data))",1,if modargs . remove :,if modargs . remove :,0.75,100.00000000000004,1.0
"def validate(self):<tab>if self.data.get(""state"") == ""enabled"":<tab><tab><IF-STMT><tab><tab><tab>raise PolicyValidationError(<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>""redshift logging enablement requires `bucket` ""<tab><tab><tab><tab><tab>""and `prefix` specification on %s"" % (self.manager.data,)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return self",0,"if ""bucket"" not in self . data :","if ""bucket"" not in self . data or ""prefix"" not in self . data :",0.5356349940769797,48.2457299495954,0.619047619047619
"def renumber(self, x1, y1, x2, y2, dx, dy):<tab>out = []<tab>for part in re.split(""(\w+)"", self.formula):<tab><tab>m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part)<tab><tab><IF-STMT><tab><tab><tab>sx, sy = m.groups()<tab><tab><tab>x = colname2num(sx)<tab><tab><tab>y = int(sy)<tab><tab><tab>if x1 <= x <= x2 and y1 <= y <= y2:<tab><tab><tab><tab>part = cellname(x + dx, y + dy)<tab><tab>out.append(part)<tab>return FormulaCell("""".join(out), self.fmt, self.alignment)",0,if m is not None :,if m :,0.050438393472541504,1e-10,0.39999999999999997
"def update_sysconfig_file(fn, adjustments, allow_empty=False):<tab>if not adjustments:<tab><tab>return<tab>(exists, contents) = read_sysconfig_file(fn)<tab>updated_am = 0<tab>for (k, v) in adjustments.items():<tab><tab>if v is None:<tab><tab><tab>continue<tab><tab>v = str(v)<tab><tab>if len(v) == 0 and not allow_empty:<tab><tab><tab>continue<tab><tab>contents[k] = v<tab><tab>updated_am += 1<tab>if updated_am:<tab><tab>lines = [<tab><tab><tab>str(contents),<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>lines.insert(0, util.make_header())<tab><tab>util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",1,if not exists :,if not exists :,0.75,100.00000000000004,1.0
"def getElement(self, aboutUri, namespace, name):<tab>for desc in self.rdfRoot.getElementsByTagNameNS(RDF_NAMESPACE, ""Description""):<tab><tab>if desc.getAttributeNS(RDF_NAMESPACE, ""about"") == aboutUri:<tab><tab><tab>attr = desc.getAttributeNodeNS(namespace, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield attr<tab><tab><tab>for element in desc.getElementsByTagNameNS(namespace, name):<tab><tab><tab><tab>yield element",0,if attr != None :,if attr is not None :,0.07176727921103726,22.957488466614336,0.4166666666666667
"def get_store_name_from_connection_string(connection_string):<tab>if is_valid_connection_string(connection_string):<tab><tab>segments = dict(seg.split(""="", 1) for seg in connection_string.split("";""))<tab><tab>endpoint = segments.get(""Endpoint"")<tab><tab><IF-STMT><tab><tab><tab>return endpoint.split(""//"")[1].split(""."")[0]<tab>return None",1,if endpoint :,if endpoint :,0.5311706625951745,1e-10,1.0
"def insertLoopTemplate(self, layout):<tab>col = layout.column(align=True)<tab>for socket in self.activeNode.outputs:<tab><tab><IF-STMT><tab><tab><tab>props = col.operator(<tab><tab><tab><tab>""an.insert_loop_for_iterator"",<tab><tab><tab><tab>text=""Loop through {}"".format(repr(socket.getDisplayedName())),<tab><tab><tab><tab>icon=""MOD_ARRAY"",<tab><tab><tab>)<tab><tab><tab>props.nodeIdentifier = self.activeNode.identifier<tab><tab><tab>props.socketIndex = socket.getIndex()",0,if not socket . hide and isList ( socket . bl_idname ) :,"if socket . getInputType ( ) == ""loop"" :",0.022184656120119994,6.942047568179753,0.21875
"def do_task(self, task):<tab>self.running_task += 1<tab>result = yield gen.Task(self.fetcher.fetch, task)<tab>type, task, response = result.args<tab>self.processor.on_task(task, response)<tab># do with message<tab>while not self.processor.inqueue.empty():<tab><tab>_task, _response = self.processor.inqueue.get()<tab><tab>self.processor.on_task(_task, _response)<tab># do with results<tab>while not self.processor.result_queue.empty():<tab><tab>_task, _result = self.processor.result_queue.get()<tab><tab><IF-STMT><tab><tab><tab>self.result_worker.on_result(_task, _result)<tab>self.running_task -= 1",0,if self . result_worker :,if _result is not None :,0.030286782520570012,9.287528999566801,0.27777777777777773
"def _parse_config_result(data):<tab>command_list = "" ; "".join([x.strip() for x in data[0]])<tab>config_result = data[1]<tab>if isinstance(config_result, list):<tab><tab>result = """"<tab><tab><IF-STMT><tab><tab><tab>for key in config_result[0]:<tab><tab><tab><tab>result += config_result[0][key]<tab><tab><tab>config_result = result<tab><tab>else:<tab><tab><tab>config_result = config_result[0]<tab>return [command_list, config_result]",0,"if isinstance ( config_result [ 0 ] , dict ) :",if len ( config_result ) == 1 :,0.02612309242726822,22.499268274284365,0.2761904761904762
"def load_api_handler(self, mod_name):<tab>for name, hdl in API_HANDLERS:<tab><tab>name = name.lower()<tab><tab><IF-STMT><tab><tab><tab>handler = self.mods.get(name)<tab><tab><tab>if not handler:<tab><tab><tab><tab>handler = hdl(self.emu)<tab><tab><tab><tab>self.mods.update({name: handler})<tab><tab><tab>return handler<tab>return None",0,if mod_name and name == mod_name . lower ( ) :,if name in mod_name :,0.07555571723634326,8.036914931946859,0.32222222222222224
def heal(self):<tab>if not self.doctors:<tab><tab>return<tab>proc_ids = self._get_process_ids()<tab>for proc_id in proc_ids:<tab><tab># get proc every time for latest state<tab><tab>proc = PipelineProcess.objects.get(id=proc_id)<tab><tab>if not proc.is_alive or proc.is_frozen:<tab><tab><tab>continue<tab><tab>for dr in self.doctors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dr.cure(proc)<tab><tab><tab><tab>break,0,if dr . confirm ( proc ) :,if dr . can_cure ( proc ) :,0.5014622369176811,37.99178428257963,0.5777777777777777
"def __new__(cls, *args, **kwargs):<tab>if len(args) == 1:<tab><tab>if len(kwargs):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""You can either use {} with one positional argument or with keyword arguments, not both."".format(<tab><tab><tab><tab><tab>cls.__name__<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return super().__new__(cls)<tab><tab>if isinstance(args[0], cls):<tab><tab><tab>return cls<tab>return super().__new__(cls, *args, **kwargs)",0,if not args [ 0 ] :,"if isinstance ( args [ 0 ] , cls ) :",0.1803475549695341,25.965358893403383,0.5604395604395604
"def __lt__(self, other):<tab># 0: clock 1: timestamp 3: process id<tab>try:<tab><tab>A, B = self[0], other[0]<tab><tab># uses logical clock value first<tab><tab><IF-STMT>  # use logical clock if available<tab><tab><tab>if A == B:  # equal clocks use lower process id<tab><tab><tab><tab>return self[2] < other[2]<tab><tab><tab>return A < B<tab><tab>return self[1] < other[1]  # ... or use timestamp<tab>except IndexError:<tab><tab>return NotImplemented",0,if A and B :,if A is not None and B is not None :,0.05737859180434831,11.208466750961147,0.28125
"def _get_client(rp_mapping, resource_provider):<tab>for key, value in rp_mapping.items():<tab><tab>if str.lower(key) == str.lower(resource_provider):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return GeneralPrivateEndpointClient(<tab><tab><tab><tab><tab>key,<tab><tab><tab><tab><tab>value[""api_version""],<tab><tab><tab><tab><tab>value[""support_list_or_not""],<tab><tab><tab><tab><tab>value[""resource_get_api_version""],<tab><tab><tab><tab>)<tab><tab><tab>return value()<tab>raise CLIError(<tab><tab>""Resource type must be one of {}"".format("", "".join(rp_mapping.keys()))<tab>)",0,"if isinstance ( value , dict ) :","if ""resource_get_api_version"" in value :",0.019907917998500824,4.065425428798724,0.48148148148148145
"def test_progressbar_format_pos(runner, pos, length):<tab>with _create_progress(length, length_known=length != 0, pos=pos) as progress:<tab><tab>result = progress.format_pos()<tab><tab><IF-STMT><tab><tab><tab>assert result == f""{pos}/{length}""<tab><tab>else:<tab><tab><tab>assert result == str(pos)",0,if progress . length_known :,if length :,0.03549272049582243,1e-10,0.5
"def optimize(self, graph: Graph):<tab>MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE<tab>flag_changed = False<tab>for v in traverse.listup_variables(graph):<tab><tab>if not Placeholder.check_resolved(v.size):<tab><tab><tab>continue<tab><tab>height, width = TextureShape.get(v)<tab><tab>if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>flag_changed = True<tab><tab><tab>v.attributes.add(SplitTarget())<tab>return graph, flag_changed",0,if not v . has_attribute ( SplitTarget ) :,if v . attributes :,0.03153300650124795,7.652332131360532,0.3181818181818182
"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += "".""<tab><tab><tab>elif col == BARRIER:<tab><tab><tab><tab>tmp += ""%""<tab><tab><tab>elif col == FOOD:<tab><tab><tab><tab>tmp += ""*""<tab><tab><tab>elif col == UNSEEN:<tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",0,if col == LAND :,"if col == ""."" :",0.14477865547525276,36.55552228545123,0.7
"def reset(self):<tab>logger.debug(""Arctic.reset()"")<tab>with self._lock:<tab><tab>if self.__conn is not None:<tab><tab><tab>self.__conn.close()<tab><tab><tab>self.__conn = None<tab><tab>for _, l in self._library_cache.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.debug(""Library reset() %s"" % l)<tab><tab><tab><tab>l._reset()  # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",0,"if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :",if l is not None :,0.008063669327166617,1.2237376376462188,0.21637426900584794
"def add_cand_to_check(cands):<tab>for cand in cands:<tab><tab>x = cand.creator<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if x not in fan_out:<tab><tab><tab># `len(fan_out)` is in order to avoid comparing `x`<tab><tab><tab>heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x))<tab><tab>fan_out[x] += 1",1,if x is None :,if x is None :,0.75,100.00000000000004,1.0
"def on_task_modify(self, task, config):<tab>for entry in task.entries:<tab><tab><IF-STMT><tab><tab><tab>size = entry[""torrent""].size / 1024 / 1024<tab><tab><tab>log.debug(""%s size: %s MB"" % (entry[""title""], size))<tab><tab><tab>entry[""content_size""] = size",0,"if ""torrent"" in entry :","if ""torrent"" in entry and ""content_size"" in entry :",0.3040520855322211,40.016016019225006,0.6
"def get_measurements(self, pipeline, object_name, category):<tab>if self.get_categories(pipeline, object_name) == [category]:<tab><tab>results = []<tab><tab>if self.do_corr_and_slope:<tab><tab><tab>if object_name == ""Image"":<tab><tab><tab><tab>results += [""Correlation"", ""Slope""]<tab><tab><tab>else:<tab><tab><tab><tab>results += [""Correlation""]<tab><tab>if self.do_overlap:<tab><tab><tab>results += [""Overlap"", ""K""]<tab><tab>if self.do_manders:<tab><tab><tab>results += [""Manders""]<tab><tab>if self.do_rwc:<tab><tab><tab>results += [""RWC""]<tab><tab><IF-STMT><tab><tab><tab>results += [""Costes""]<tab><tab>return results<tab>return []",1,if self . do_costes :,if self . do_costes :,0.75,100.00000000000004,1.0
"def create_root(cls, site=None, title=""Root"", request=None, **kwargs):<tab>if not site:<tab><tab>site = Site.objects.get_current()<tab>root_nodes = cls.objects.root_nodes().filter(site=site)<tab>if not root_nodes:<tab><tab>article = Article()<tab><tab>revision = ArticleRevision(title=title, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>revision.set_from_request(request)<tab><tab>article.add_revision(revision, save=True)<tab><tab>article.save()<tab><tab>root = cls.objects.create(site=site, article=article)<tab><tab>article.add_object_relation(root)<tab>else:<tab><tab>root = root_nodes[0]<tab>return root",1,if request :,if request :,0.5311706625951745,1e-10,1.0
"def get(self, key):<tab>filename = self._get_filename(key)<tab>try:<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>pickle_time = pickle.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pickle.load(f)<tab><tab><tab>else:<tab><tab><tab><tab>os.remove(filename)<tab><tab><tab><tab>return None<tab>except (IOError, OSError, pickle.PickleError):<tab><tab>return None",0,if pickle_time == 0 or pickle_time >= time ( ) :,if pickle_time < time . time ( ) :,0.39439770079508024,28.009266907237098,0.38666666666666666
"def build_message(self, options, target):<tab>message = multipart.MIMEMultipart()<tab>for name, value in list(options.items()):<tab><tab><IF-STMT><tab><tab><tab>self.add_body(message, value)<tab><tab>elif name == ""EMAIL_ATTACHMENT"":<tab><tab><tab>self.add_attachment(message, value)<tab><tab>else:  # From, To, Subject, etc.<tab><tab><tab>self.set_option(message, name, value, target)<tab>return message",0,"if name == ""EMAIL_BODY"" :","if name == ""BODY"" :",0.39477865547525276,53.849523560640876,1.0
"def updateVar(name, data, mode=None):<tab>if mode:<tab><tab><IF-STMT><tab><tab><tab>core.config.globalVariables[name].append(data)<tab><tab>elif mode == ""add"":<tab><tab><tab>core.config.globalVariables[name].add(data)<tab>else:<tab><tab>core.config.globalVariables[name] = data",1,"if mode == ""append"" :","if mode == ""append"" :",0.75,100.00000000000004,1.0
"def insert_errors(<tab>el,<tab>errors,<tab>form_id=None,<tab>form_index=None,<tab>error_class=""error"",<tab>error_creator=default_error_creator,):<tab>el = _find_form(el, form_id=form_id, form_index=form_index)<tab>for name, error in errors.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for error_el, message in _find_elements_for_name(el, name, error):<tab><tab><tab>assert isinstance(message, (basestring, type(None), ElementBase)), (<tab><tab><tab><tab>""Bad message: %r"" % message<tab><tab><tab>)<tab><tab><tab>_insert_error(error_el, message, error_class, error_creator)",1,if error is None :,if error is None :,0.75,100.00000000000004,1.0
"def read(self, item, recursive=False, sort=False):<tab>item = _normalize_path(item)<tab>if item in self._store:<tab><tab><IF-STMT><tab><tab><tab>del self._store[item]<tab><tab><tab>raise KeyError(item)<tab><tab>return PathResult(item, value=self._store[item])<tab>else:<tab><tab>return self._read_dir(item, recursive=recursive, sort=sort)",0,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if recursive :,0.0037168888914905036,1e-10,0.1954022988505747
"def _stash_splitter(states):<tab>keep, split = [], []<tab>if state_func is not None:<tab><tab>for s in states:<tab><tab><tab>ns = state_func(s)<tab><tab><tab>if isinstance(ns, SimState):<tab><tab><tab><tab>split.append(ns)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>split.extend(ns)<tab><tab><tab>else:<tab><tab><tab><tab>split.append(s)<tab>if stash_func is not None:<tab><tab>split = stash_func(states)<tab>if to_stash is not stash:<tab><tab>keep = states<tab>return keep, split",0,"elif isinstance ( ns , ( list , tuple , set ) ) :","elif isinstance ( ns , list ) :",0.21413852973112468,29.040536047560465,0.6984126984126985
"def run(self):<tab>while self.runflag:<tab><tab><IF-STMT><tab><tab><tab>with self.lock:<tab><tab><tab><tab>tasks = list(self.queue)<tab><tab><tab><tab>self.queue.clear()<tab><tab><tab>while len(tasks) > 0:<tab><tab><tab><tab>pathname, remotepath = tasks.pop(0)<tab><tab><tab><tab>self.bcloud_app.upload_page.add_bg_task(pathname, remotepath)<tab><tab><tab>self.last = time()<tab><tab>else:<tab><tab><tab>sleep(1)",0,if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,if time ( ) > self . last :,0.13836451191962423,17.01839371676374,0.4962962962962963
"def _append_patch(self, patch_dir, patch_files):<tab>for patch in patch_files:<tab><tab><IF-STMT><tab><tab><tab>tmp = patch<tab><tab><tab>patch = {}<tab><tab><tab>for key in tmp.keys():<tab><tab><tab><tab>patch[os.path.join(patch_dir, key)] = tmp[key]<tab><tab><tab>self.patches.append(patch)<tab><tab>else:<tab><tab><tab>self.patches.append(os.path.join(patch_dir, patch))",0,if type ( patch ) is dict :,"if isinstance ( patch , dict ) :",0.03916858170756418,14.535768424205482,0.40816326530612246
"def __remote_port(self):<tab>port = 22<tab>if self.git_has_remote:<tab><tab>m = re.match(r""^(.*?)?@([^/:]*):?([0-9]+)?"", self.git_remote.url)<tab><tab>if m:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>port = m.group(3)<tab>return int(port)",1,if m . group ( 3 ) :,if m . group ( 3 ) :,0.75,100.00000000000004,1.0
"def _create_or_get_helper(self, infer_mode: Optional[bool] = None, **kwargs) -> Helper:<tab># Prefer creating a new helper when at least one kwarg is specified.<tab>prefer_new = len(kwargs) > 0<tab>kwargs.update(infer_mode=infer_mode)<tab>is_training = not infer_mode if infer_mode is not None else self.training<tab>helper = self._train_helper if is_training else self._infer_helper<tab>if prefer_new or helper is None:<tab><tab>helper = self.create_helper(**kwargs)<tab><tab><IF-STMT><tab><tab><tab>self._train_helper = helper<tab><tab>elif not is_training and self._infer_helper is None:<tab><tab><tab>self._infer_helper = helper<tab>return helper",1,if is_training and self . _train_helper is None :,if is_training and self . _train_helper is None :,0.75,100.00000000000004,1.0
"def flushChangeClassifications(self, schedulerid, less_than=None):<tab>if less_than is not None:<tab><tab>classifications = self.classifications.setdefault(schedulerid, {})<tab><tab>for changeid in list(classifications):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del classifications[changeid]<tab>else:<tab><tab>self.classifications[schedulerid] = {}<tab>return defer.succeed(None)",0,if changeid < less_than :,if less_than [ changeid ] < less_than [ changeid ] :,0.048249452160582657,18.92240568795936,0.869281045751634
"def pid_from_name(name):<tab>processes = []<tab>for pid in os.listdir(""/proc""):<tab><tab>try:<tab><tab><tab>pid = int(pid)<tab><tab><tab>pname, cmdline = SunProcess._name_args(pid)<tab><tab><tab>if name in pname:<tab><tab><tab><tab>return pid<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pid<tab><tab>except:<tab><tab><tab>pass<tab>raise ProcessException(""No process with such name: %s"" % name)",0,"if name in cmdline . split ( "" "" , 1 ) [ 0 ] :",elif name in cmdline :,0.08588262975822814,4.73447498358895,0.4285714285714286
"def spew():<tab>seenUID = False<tab>start()<tab>for part in query:<tab><tab><IF-STMT><tab><tab><tab>seenUID = True<tab><tab>if part.type == ""body"":<tab><tab><tab>yield self.spew_body(part, id, msg, write, flush)<tab><tab>else:<tab><tab><tab>f = getattr(self, ""spew_"" + part.type)<tab><tab><tab>yield f(id, msg, write, flush)<tab><tab>if part is not query[-1]:<tab><tab><tab>space()<tab>if uid and not seenUID:<tab><tab>space()<tab><tab>yield self.spew_uid(id, msg, write, flush)<tab>finish()<tab>flush()",0,"if part . type == ""uid"" :",if part . uid and not seenUID :,0.0835778008746384,18.190371142855746,0.3214285714285714
"def rx():<tab>while True:<tab><tab>rx_i = rep.recv()<tab><tab><IF-STMT><tab><tab><tab>rep.send(b""done"")<tab><tab><tab>break<tab><tab>rep.send(b""i"")",0,"if rx_i == b""1000"" :","if rx_i == b""1"" :",0.39477865547525276,74.19446627365011,1.0
"def test_search_incorrect_base_exception_1(self):<tab>self.connection_1c.bind()<tab>try:<tab><tab>result = self.connection_1c.search(<tab><tab><tab>""o=nonexistant"", ""(cn=*)"", search_scope=SUBTREE, attributes=[""cn"", ""sn""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>_, result = self.connection_1c.get_response(result)<tab><tab>self.fail(""exception not raised"")<tab>except LDAPNoSuchObjectResult:<tab><tab>pass",0,if not self . connection_1c . strategy . sync :,if self . connection_1c . get_response :,0.1500170882436275,45.305163015763085,0.2948717948717949
"def value_from_datadict(self, data, files, prefix):<tab>count = int(data[""%s-count"" % prefix])<tab>values_with_indexes = []<tab>for i in range(0, count):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>values_with_indexes.append(<tab><tab><tab>(<tab><tab><tab><tab>int(data[""%s-%d-order"" % (prefix, i)]),<tab><tab><tab><tab>self.child_block.value_from_datadict(<tab><tab><tab><tab><tab>data, files, ""%s-%d-value"" % (prefix, i)<tab><tab><tab><tab>),<tab><tab><tab>)<tab><tab>)<tab>values_with_indexes.sort()<tab>return [v for (i, v) in values_with_indexes]",0,"if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :",if i == count - 1 :,0.011766133075199699,2.3595365419339505,0.2857142857142857
"def _ensure_header_written(self, datasize):<tab>if not self._headerwritten:<tab><tab>if not self._nchannels:<tab><tab><tab>raise Error(""# channels not specified"")<tab><tab>if not self._sampwidth:<tab><tab><tab>raise Error(""sample width not specified"")<tab><tab><IF-STMT><tab><tab><tab>raise Error(""sampling rate not specified"")<tab><tab>self._write_header(datasize)",0,if not self . _framerate :,if not self . _samprate :,0.5212518808542342,64.34588841607616,1.0
def wait_til_ready(cls):<tab>while True:<tab><tab>now = time.time()<tab><tab>next_iteration = now // 1.0 + 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>await cls._clock.run_til(next_iteration)<tab><tab>await asyncio.sleep(1.0),0,if cls . connector . ready :,if cls . _clock . is_running ( ) :,0.08175406872245589,14.323145079400492,0.5666666666666667
"def lookup_actions(self, resp):<tab>actions = {}<tab>for action, conditions in self.actions.items():<tab><tab>for condition, opts in conditions:<tab><tab><tab>for key, val in condition:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if resp.match(key[:-1], val):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if not resp.match(key, val):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>actions[action] = opts<tab>return actions",0,"if key [ - 1 ] == ""!"" :","if key . endswith ( ""_"" ) :",0.030159602731355914,8.639795714750207,0.6
"def close(self, wait=True, abort=False):<tab>""""""Close the socket connection.""""""<tab>if not self.closed and not self.closing:<tab><tab>self.closing = True<tab><tab>self.server._trigger_event(""disconnect"", self.sid, run_async=False)<tab><tab>if not abort:<tab><tab><tab>self.send(packet.Packet(packet.CLOSE))<tab><tab>self.closed = True<tab><tab>self.queue.put(None)<tab><tab><IF-STMT><tab><tab><tab>self.queue.join()",1,if wait :,if wait :,0.5311706625951745,1e-10,1.0
"def model_parse(self):<tab>for name, submodel in self.model.named_modules():<tab><tab>for op_type in SUPPORTED_OP_TYPE:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.target_layer[name] = submodel<tab><tab><tab><tab>self.already_pruned[name] = 0",0,"if isinstance ( submodel , op_type ) :",if op_type in self . target_layer and name in self . target_layer :,0.015318209101651175,8.562365224473284,0.21875
"def pack_identifier(self):<tab>""""""Return a combined identifier for the whole pack if this has more than one episode.""""""<tab># Currently only supports ep mode<tab>if self.id_type == ""ep"":<tab><tab><IF-STMT><tab><tab><tab>return ""S%02dE%02d-E%02d"" % (<tab><tab><tab><tab>self.season,<tab><tab><tab><tab>self.episode,<tab><tab><tab><tab>self.episode + self.episodes - 1,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return self.identifier<tab>else:<tab><tab>return self.identifier",0,if self . episodes > 1 :,if self . episode > 1 :,0.3884893899276739,41.11336169005196,0.6666666666666666
"def on_data(res):<tab>if terminate.is_set():<tab><tab>return<tab>if args.strings and not args.no_content:<tab><tab>if type(res) == tuple:<tab><tab><tab>f, v = res<tab><tab><tab>if type(f) == unicode:<tab><tab><tab><tab>f = f.encode(""utf-8"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v = v.encode(""utf-8"")<tab><tab><tab>self.success(""{}: {}"".format(f, v))<tab><tab>elif not args.content_only:<tab><tab><tab>self.success(res)<tab>else:<tab><tab>self.success(res)",1,if type ( v ) == unicode :,if type ( v ) == unicode :,0.75,100.00000000000004,1.0
"def _enable_contours_changed(self, value):<tab>""""""Turns on and off the contours.""""""<tab>if self.module_manager is None:<tab><tab>return<tab>if value:<tab><tab>self.actor.inputs = [self.contour]<tab><tab><IF-STMT><tab><tab><tab>self.actor.mapper.scalar_mode = ""use_cell_data""<tab>else:<tab><tab>self.actor.inputs = [self.grid_plane]<tab><tab>self.actor.mapper.scalar_mode = ""default""<tab>self.render()",0,if self . contour . filled_contours :,if self . contour . grid_plane is None :,0.4050330458634526,38.16330911371339,0.6333333333333333
"def _apply_abs_paths(data, script_dir):<tab>for flag_data in data.values():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>default = flag_data.get(""default"")<tab><tab>if (<tab><tab><tab>not default<tab><tab><tab>or not isinstance(default, six.string_types)<tab><tab><tab>or os.path.sep not in default<tab><tab>):<tab><tab><tab>continue<tab><tab>abs_path = os.path.join(script_dir, default)<tab><tab>if os.path.exists(abs_path):<tab><tab><tab>flag_data[""default""] = abs_path",0,"if not isinstance ( flag_data , dict ) :","if ""default"" not in flag_data :",0.017951424116240698,16.807407519804237,0.48484848484848486
"def button_release(self, mapper):<tab>self.pressed = False<tab>if self.waiting_task and self.active is None and not self.action:<tab><tab># In HoldModifier, button released before timeout<tab><tab>mapper.cancel_task(self.waiting_task)<tab><tab>self.waiting_task = None<tab><tab><IF-STMT><tab><tab><tab>self.normalaction.button_press(mapper)<tab><tab><tab>mapper.schedule(0.02, self.normalaction.button_release)<tab>elif self.active:<tab><tab># Released held button<tab><tab>self.active.button_release(mapper)<tab><tab>self.active = None",1,if self . normalaction :,if self . normalaction :,0.75,100.00000000000004,1.0
"def goToPrevMarkedHeadline(self, event=None):<tab>""""""Select the next marked node.""""""<tab>c = self<tab>p = c.p<tab>if not p:<tab><tab>return<tab>p.moveToThreadBack()<tab>wrapped = False<tab>while 1:<tab><tab>if p and p.isMarked():<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>p.moveToThreadBack()<tab><tab>elif wrapped:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>wrapped = True<tab><tab><tab>p = c.rootPosition()<tab>if not p:<tab><tab>g.blue(""done"")<tab>c.treeSelectHelper(p)  # Sets focus.",1,elif p :,elif p :,0.5143161313935813,1e-10,1.0
"def status(self, name, error=""No matching script logs found""):<tab>with self.script_lock:<tab><tab>if self.script_running and self.script_running[1] == name:<tab><tab><tab>return self.script_running[1:]<tab><tab><IF-STMT><tab><tab><tab>return self.script_last[1:]<tab><tab>else:<tab><tab><tab>raise ValueError(error)",1,elif self . script_last and self . script_last [ 1 ] == name :,elif self . script_last and self . script_last [ 1 ] == name :,1.0,100.00000000000004,1.0
"def _stderr_supports_color():<tab>try:<tab><tab>if hasattr(sys.stderr, ""isatty"") and sys.stderr.isatty():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>curses.setupterm()<tab><tab><tab><tab>if curses.tigetnum(""colors"") > 0:<tab><tab><tab><tab><tab>return True<tab><tab><tab>elif colorama:<tab><tab><tab><tab>if sys.stderr is getattr(<tab><tab><tab><tab><tab>colorama.initialise, ""wrapped_stderr"", object()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>return True<tab>except Exception:<tab><tab># Very broad exception handling because it's always better to<tab><tab># fall back to non-colored logs than to break at startup.<tab><tab>pass<tab>return False",1,if curses :,if curses :,0.5311706625951745,1e-10,1.0
"def main():<tab>configFilename = ""twitterbot.ini""<tab>if sys.argv[1:]:<tab><tab>configFilename = sys.argv[1]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise Exception()<tab><tab>load_config(configFilename)<tab>except Exception as e:<tab><tab>print(""Error while loading ini file %s"" % (configFilename), file=sys.stderr)<tab><tab>print(e, file=sys.stderr)<tab><tab>print(__doc__, file=sys.stderr)<tab><tab>sys.exit(1)<tab>bot = TwitterBot(configFilename)<tab>return bot.run()",1,if not os . path . exists ( configFilename ) :,if not os . path . exists ( configFilename ) :,0.75,100.00000000000004,1.0
def safe_to_kill(request):<tab>if os.path.exists(DRAIN_FILE):<tab><tab>with open(DRAIN_FILE) as f:<tab><tab><tab>dt = datetime.datetime.fromtimestamp(float(f.read()))<tab><tab><tab>delta = datetime.datetime.now() - dt<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return Response(status_int=200)<tab><tab><tab>else:<tab><tab><tab><tab>return Response(status_int=400)<tab>else:<tab><tab>return Response(status_int=400),0,if delta . seconds > 2 :,if delta < today ( ) :,0.04066031774849872,14.535768424205482,0.4761904761904762
"def get_class_name(item):<tab>class_name, module_name = None, None<tab>for parent in reversed(item.listchain()):<tab><tab><IF-STMT><tab><tab><tab>class_name = parent.name<tab><tab>elif isinstance(parent, pytest.Module):<tab><tab><tab>module_name = parent.module.__name__<tab><tab><tab>break<tab># heuristic:<tab># - better to group gpu and task tests, since tests from those modules<tab>#   are likely to share caching more<tab># - split up the rest by class name because slow tests tend to be in<tab>#   the same module<tab>if class_name and "".tasks."" not in module_name:<tab><tab>return ""{}.{}"".format(module_name, class_name)<tab>else:<tab><tab>return module_name",1,"if isinstance ( parent , pytest . Class ) :","if isinstance ( parent , pytest . Class ) :",0.75,100.00000000000004,1.0
"def getAllFitsLite():<tab>fits = eos.db.getFitListLite()<tab>shipMap = {f.shipID: None for f in fits}<tab>for shipID in shipMap:<tab><tab>ship = eos.db.getItem(shipID)<tab><tab><IF-STMT><tab><tab><tab>shipMap[shipID] = (ship.name, ship.getShortName())<tab>fitsToPurge = set()<tab>for fit in fits:<tab><tab>try:<tab><tab><tab>fit.shipName, fit.shipNameShort = shipMap[fit.shipID]<tab><tab>except (KeyError, TypeError):<tab><tab><tab>fitsToPurge.add(fit)<tab>for fit in fitsToPurge:<tab><tab>fits.remove(fit)<tab>return fits",0,if ship is not None :,if ship :,0.050438393472541504,1e-10,0.39999999999999997
"def _process(self, event_data):<tab>self.machine.callbacks(self.machine.prepare_event, event_data)<tab>_LOGGER.debug(<tab><tab>""%sExecuted machine preparation callbacks before conditions."", self.machine.name<tab>)<tab>try:<tab><tab>for trans in self.transitions[event_data.state.name]:<tab><tab><tab>event_data.transition = trans<tab><tab><tab><IF-STMT><tab><tab><tab><tab>event_data.result = True<tab><tab><tab><tab>break<tab>except Exception as err:<tab><tab>event_data.error = err<tab><tab>raise<tab>finally:<tab><tab>self.machine.callbacks(self.machine.finalize_event, event_data)<tab><tab>_LOGGER.debug(""%sExecuted machine finalize callbacks"", self.machine.name)<tab>return event_data.result",0,if trans . execute ( event_data ) :,if event_data . state . name in self . states :,0.01721726452019353,13.674406678232565,0.19658119658119658
"def fetch_comments(self, force=False, limit=None):<tab>comments = []<tab>if (force is True) or (self.badges[""comments""] > 0):<tab><tab>query_params = {""filter"": ""commentCard,copyCommentCard""}<tab><tab><IF-STMT><tab><tab><tab>query_params[""limit""] = limit<tab><tab>comments = self.client.fetch_json(<tab><tab><tab>""/cards/"" + self.id + ""/actions"", query_params=query_params<tab><tab>)<tab><tab>return sorted(comments, key=lambda comment: comment[""date""])<tab>return comments",1,if limit is not None :,if limit is not None :,0.75,100.00000000000004,1.0
"def get_changed(self):<tab>if self._is_expression():<tab><tab>result = self._get_node_text(self.ast)<tab><tab>if result == self.source:<tab><tab><tab>return None<tab><tab>return result<tab>else:<tab><tab>collector = codeanalyze.ChangeCollector(self.source)<tab><tab>last_end = -1<tab><tab>for match in self.matches:<tab><tab><tab>start, end = match.get_region()<tab><tab><tab>if start < last_end:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>last_end = end<tab><tab><tab>replacement = self._get_matched_text(match)<tab><tab><tab>collector.add_change(start, end, replacement)<tab><tab>return collector.get_changed()",0,if not self . _is_expression ( ) :,if end > last_end :,0.01858685153282265,4.880869806051147,0.38181818181818183
"def _replace_home(x):<tab>if xp.ON_WINDOWS:<tab><tab>home = (<tab><tab><tab>builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab>if builtins.__xonsh__.env.get(""FORCE_POSIX_PATHS""):<tab><tab><tab>x = x.replace(os.sep, os.altsep)<tab><tab>return x<tab>else:<tab><tab>home = builtins.__xonsh__.env[""HOME""]<tab><tab>if x.startswith(home):<tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab>return x",1,if x . startswith ( home ) :,if x . startswith ( home ) :,0.75,100.00000000000004,1.0
"def project_review(plans):<tab>for plan in plans:<tab><tab>print(""Inspecting {} plan"".format(plan))<tab><tab>branches = get_branches_from_plan(plan)<tab><tab>for branch in branches:<tab><tab><tab>build_results = get_results_from_branch(branch)<tab><tab><tab>for build in build_results:<tab><tab><tab><tab>build_key = build.get(""buildResultKey"") or None<tab><tab><tab><tab>print(""Inspecting build - {}"".format(build_key))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>for status in STATUS_CLEANED_RESULTS:<tab><tab><tab><tab><tab><tab>remove_build_result(build_key=build_key, status=status)",1,if build_key :,if build_key :,0.5311706625951745,1e-10,1.0
"def _check_for_batch_clashes(xs):<tab>""""""Check that batch names do not overlap with sample names.""""""<tab>names = set([x[""description""] for x in xs])<tab>dups = set([])<tab>for x in xs:<tab><tab>batches = tz.get_in((""metadata"", ""batch""), x)<tab><tab>if batches:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>batches = [batches]<tab><tab><tab>for batch in batches:<tab><tab><tab><tab>if batch in names:<tab><tab><tab><tab><tab>dups.add(batch)<tab>if len(dups) > 0:<tab><tab>raise ValueError(<tab><tab><tab>""Batch names must be unique from sample descriptions.\n""<tab><tab><tab>""Clashing batch names: %s"" % sorted(list(dups))<tab><tab>)",0,"if not isinstance ( batches , ( list , tuple ) ) :","if not isinstance ( batches , list ) :",0.2220412049535349,43.624306402227546,0.8476190476190476
"def _check_signal(self):<tab>""""""Checks if a signal was received and issues a message.""""""<tab>proc_signal = getattr(self.proc, ""signal"", None)<tab>if proc_signal is None:<tab><tab>return<tab>sig, core = proc_signal<tab>sig_str = SIGNAL_MESSAGES.get(sig)<tab>if sig_str:<tab><tab>if core:<tab><tab><tab>sig_str += "" (core dumped)""<tab><tab>print(sig_str, file=sys.stderr)<tab><tab><IF-STMT><tab><tab><tab>self.errors += sig_str + ""\n""",0,if self . errors is not None :,if self . errors :,0.2343345094426703,38.80684294761701,0.5102040816326531
"def loadLabelFile(self, labelpath):<tab>labeldict = {}<tab>if not os.path.exists(labelpath):<tab><tab>f = open(labelpath, ""w"", encoding=""utf-8"")<tab>else:<tab><tab>with open(labelpath, ""r"", encoding=""utf-8"") as f:<tab><tab><tab>data = f.readlines()<tab><tab><tab>for each in data:<tab><tab><tab><tab>file, label = each.split(""\t"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>label = label.replace(""false"", ""False"")<tab><tab><tab><tab><tab>label = label.replace(""true"", ""True"")<tab><tab><tab><tab><tab>labeldict[file] = eval(label)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>labeldict[file] = []<tab>return labeldict",0,if label :,"if ""true"" in label :",0.09791453445388575,1e-10,0.45
"def exists_col_to_many(self, select_columns: List[str]) -> bool:<tab>for column in select_columns:<tab><tab><IF-STMT><tab><tab><tab>root_relation = get_column_root_relation(column)<tab><tab><tab>if self.is_relation_many_to_many(<tab><tab><tab><tab>root_relation<tab><tab><tab>) or self.is_relation_one_to_many(root_relation):<tab><tab><tab><tab>return True<tab>return False",0,if is_column_dotted ( column ) :,if self . is_column_relation ( column ) :,0.2908194450899196,43.66835442847811,0.4772727272727273
"def check_sequence_matches(seq, template):<tab>i = 0<tab>for pattern in template:<tab><tab><IF-STMT><tab><tab><tab>pattern = {pattern}<tab><tab>got = set(seq[i : i + len(pattern)])<tab><tab>assert got == pattern<tab><tab>i += len(got)",0,"if not isinstance ( pattern , set ) :","if isinstance ( pattern , str ) :",0.1884566599936256,37.70794596593207,0.2698412698412698
"def load_modules(<tab>to_load, load, attr, modules_dict, excluded_aliases, loading_message=None):<tab>if loading_message:<tab><tab>print(loading_message)<tab>for name in to_load:<tab><tab>module = load(name)<tab><tab>if module is None or not hasattr(module, attr):<tab><tab><tab>continue<tab><tab>cls = getattr(module, attr)<tab><tab>if hasattr(cls, ""initialize"") and not cls.initialize():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>for alias in module.aliases():<tab><tab><tab><tab>if alias not in excluded_aliases:<tab><tab><tab><tab><tab>modules_dict[alias] = module<tab><tab>else:<tab><tab><tab>modules_dict[name] = module<tab>if loading_message:<tab><tab>print()",1,"if hasattr ( module , ""aliases"" ) :","if hasattr ( module , ""aliases"" ) :",0.75,100.00000000000004,1.0
"def result():<tab># ""global"" does not work here...<tab>R, V = rays, virtual_rays<tab>if V is not None:<tab><tab><IF-STMT><tab><tab><tab>V = normalize_rays(V, lattice)<tab><tab>if check:<tab><tab><tab>R = PointCollection(V, lattice)<tab><tab><tab>V = PointCollection(V, lattice)<tab><tab><tab>d = lattice.dimension()<tab><tab><tab>if len(V) != d - R.dim() or (R + V).dim() != d:<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""virtual rays must be linearly ""<tab><tab><tab><tab><tab>""independent and with other rays span the ambient space.""<tab><tab><tab><tab>)<tab>return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",1,if normalize :,if normalize :,0.5311706625951745,1e-10,1.0
"def communicate(self, _input=None, _timeout=None) -> Tuple[bytes, bytes]:<tab>if parse_args().print_commands:<tab><tab><IF-STMT><tab><tab><tab>print_stderr(<tab><tab><tab><tab>color_line(""=> "", 14) + "" "".join(str(arg) for arg in self.args)<tab><tab><tab>)<tab>stdout, stderr = super().communicate(_input, _timeout)<tab>self.stdout_text = stdout.decode(""utf-8"") if stdout else None<tab>self.stderr_text = stderr.decode(""utf-8"") if stderr else None<tab>return stdout, stderr",0,if self . args != get_sudo_refresh_command ( ) :,if self . args :,0.16279282519794364,7.834966465489322,1.0
"def convert(data):<tab>result = []<tab>for d in data:<tab><tab># noinspection PyCompatibility<tab><tab><IF-STMT><tab><tab><tab>result.append((d[0], None, d[1]))<tab><tab>elif isinstance(d, basestring):<tab><tab><tab>result.append(d)<tab>return result",0,"if isinstance ( d , tuple ) and len ( d ) == 2 :","if isinstance ( d , tuple ) :",0.28184453892234934,31.984974287337113,0.5555555555555556
"def validate(self, value):<tab>try:<tab><tab>value = [<tab><tab><tab>datetime.datetime.strptime(range, ""%Y-%m-%d %H:%M:%S"")<tab><tab><tab>for range in value.split("" to "")<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except ValueError:<tab><tab>return False",0,if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,if len ( value ) == 2 :,0.16062149926016334,14.601126233589126,0.5423387096774194
"def rmdir(dirname):<tab>if dirname[-1] == os.sep:<tab><tab>dirname = dirname[:-1]<tab>if os.path.islink(dirname):<tab><tab>return  # do not clear link - we can get out of dir<tab>for f in os.listdir(dirname):<tab><tab>if f in (""."", ""..""):<tab><tab><tab>continue<tab><tab>path = dirname + os.sep + f<tab><tab><IF-STMT><tab><tab><tab>rmdir(path)<tab><tab>else:<tab><tab><tab>os.unlink(path)<tab>os.rmdir(dirname)",1,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,100.00000000000004,1.0
"def onCompletion(self, text):<tab>res = []<tab>for l in text.split(""\n""):<tab><tab>if not l:<tab><tab><tab>continue<tab><tab>l = l.split("":"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>res.append([l[0].strip(), l[1].strip()])<tab>self.panel.setSlides(res)",0,if len ( l ) != 2 :,if len ( l ) < 2 :,0.5490406812970063,52.47357977607325,1.0
"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab>if ""init"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))",0,"if item . nodeid . startswith ( ""tests/infer"" ) :","if ""test"" in item . keywords :",0.02803563209318722,7.200209897263065,0.2857142857142857
"def build_message(self, options, target):<tab>message = multipart.MIMEMultipart()<tab>for name, value in list(options.items()):<tab><tab>if name == ""EMAIL_BODY"":<tab><tab><tab>self.add_body(message, value)<tab><tab><IF-STMT><tab><tab><tab>self.add_attachment(message, value)<tab><tab>else:  # From, To, Subject, etc.<tab><tab><tab>self.set_option(message, name, value, target)<tab>return message",0,"elif name == ""EMAIL_ATTACHMENT"" :","elif name == ""EMAIL_ATTEMPTS"" :",0.6428720214849399,70.71067811865478,1.0
def extend_with_zeroes(b):<tab>try:<tab><tab>for x in b:<tab><tab><tab>x = to_constant(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (x)<tab><tab><tab>else:<tab><tab><tab><tab>yield (0)<tab><tab>for _ in range(32):<tab><tab><tab>yield (0)<tab>except Exception as e:<tab><tab>return,0,"if isinstance ( x , int ) :",if is_constant ( x ) :,0.044514103254184964,16.515821590069027,0.36
"def _start_cluster(*, cleanup_atexit=True):<tab>global _default_cluster<tab>if _default_cluster is None:<tab><tab>cluster_addr = os.environ.get(""EDGEDB_TEST_CLUSTER_ADDR"")<tab><tab><IF-STMT><tab><tab><tab>conn_spec = json.loads(cluster_addr)<tab><tab><tab>_default_cluster = edgedb_cluster.RunningCluster(**conn_spec)<tab><tab>else:<tab><tab><tab>data_dir = os.environ.get(""EDGEDB_TEST_DATA_DIR"")<tab><tab><tab>_default_cluster = _init_cluster(<tab><tab><tab><tab>data_dir=data_dir, cleanup_atexit=cleanup_atexit<tab><tab><tab>)<tab>return _default_cluster",1,if cluster_addr :,if cluster_addr :,0.5311706625951745,1e-10,1.0
"def preprocess_raw_enwik9(input_filename, output_filename):<tab>with open(input_filename, ""r"") as f1:<tab><tab>with open(output_filename, ""w"") as f2:<tab><tab><tab>while True:<tab><tab><tab><tab>line = f1.readline()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>line = list(enwik9_norm_transform([line]))[0]<tab><tab><tab><tab>if line != "" "" and line != """":<tab><tab><tab><tab><tab>if line[0] == "" "":<tab><tab><tab><tab><tab><tab>line = line[1:]<tab><tab><tab><tab><tab>f2.writelines(line + ""\n"")",1,if not line :,if not line :,0.75,100.00000000000004,1.0
"def is_entirely_italic(line):<tab>style = subs.styles.get(line.style, SSAStyle.DEFAULT_STYLE)<tab>for fragment, sty in parse_tags(line.text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",0,if not sty . italic and fragment and not fragment . isspace ( ) :,"if sty . startswith ( ""italic"" ) :",0.021294518039953168,8.27951003977077,0.17647058823529413
def __get_all_nodes(self):<tab>nodes = []<tab>next_level = [self.__tree.get_root()]<tab>while len(next_level) != 0:<tab><tab>cur_level = next_level<tab><tab>nodes += next_level<tab><tab>next_level = []<tab><tab>for cur_node in cur_level:<tab><tab><tab>children = cur_node.get_children()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>next_level += children<tab>return nodes,0,if children is not None :,if children :,0.050438393472541504,1e-10,0.39999999999999997
"def _openvpn_stdout(self):<tab>while True:<tab><tab>line = self.process.stdout.readline()<tab><tab>if not line:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>time.sleep(0.05)<tab><tab><tab>continue<tab><tab>yield<tab><tab>try:<tab><tab><tab>self.server.output.push_output(line)<tab><tab>except:<tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Failed to push vpn output"",<tab><tab><tab><tab>""server"",<tab><tab><tab><tab>server_id=self.server.id,<tab><tab><tab>)<tab><tab>yield",0,if self . process . poll ( ) is not None or self . is_interrupted ( ) :,if self . process . poll ( ) is None :,0.31438044114457486,36.468663398043724,0.6137566137566137
"def payment_received_handler(event):<tab>if isinstance(event.message.action, types.MessageActionPaymentSentMe):<tab><tab>payment: types.MessageActionPaymentSentMe = event.message.action<tab><tab># do something after payment was received<tab><tab>if payment.payload.decode(""UTF-8"") == ""product A"":<tab><tab><tab>await bot.send_message(<tab><tab><tab><tab>event.message.from_id, ""Thank you for buying product A!""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>await bot.send_message(<tab><tab><tab><tab>event.message.from_id, ""Thank you for buying product B!""<tab><tab><tab>)<tab><tab>raise events.StopPropagation",1,"elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :",0.75,100.00000000000004,1.0
"def spaces_after(token, prev, next, min=-1, max=-1, min_desc=None, max_desc=None):<tab>if next is not None and token.end_mark.line == next.start_mark.line:<tab><tab>spaces = next.start_mark.pointer - token.end_mark.pointer<tab><tab><IF-STMT><tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column, max_desc<tab><tab><tab>)<tab><tab>elif min != -1 and spaces < min:<tab><tab><tab>return LintProblem(<tab><tab><tab><tab>token.start_mark.line + 1, next.start_mark.column + 1, min_desc<tab><tab><tab>)",1,if max != - 1 and spaces > max :,if max != - 1 and spaces > max :,1.0,100.00000000000004,1.0
"def seek_to_block(self, pos):<tab>baseofs = 0<tab>ofs = 0<tab>for b in self.blocks:<tab><tab><IF-STMT><tab><tab><tab>self.current_block = b<tab><tab><tab>break<tab><tab>baseofs += b.compressed_size<tab><tab>ofs += b.uncompressed_size<tab>else:<tab><tab>self.current_block = None<tab><tab>self.current_stream = BytesIO(b"""")<tab><tab>return<tab>self.current_block_start = ofs<tab>self.stream.seek(self.basepos + baseofs)<tab>buf = BytesIO(self.stream.read(self.current_block.compressed_size))<tab>self.current_stream = self.current_block.decompress(buf)",0,if ofs + b . uncompressed_size > pos :,if b . position == pos :,0.13965423395541948,11.35114710927891,0.5
"def rewrite_hunks(hunks):<tab># type: (List[Hunk]) -> Iterator[Hunk]<tab># Assumes `hunks` are sorted, and from the same file<tab>deltas = (hunk.b_length - hunk.a_length for hunk in hunks)<tab>offsets = accumulate(deltas, initial=0)<tab>for hunk, offset in zip(hunks, offsets):<tab><tab>new_b = hunk.a_start + offset<tab><tab>if hunk_of_additions_only(hunk):<tab><tab><tab>new_b += 1<tab><tab><IF-STMT><tab><tab><tab>new_b -= 1<tab><tab>yield hunk._replace(b_start=new_b)",1,elif hunk_of_removals_only ( hunk ) :,elif hunk_of_removals_only ( hunk ) :,0.75,100.00000000000004,1.0
"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab><IF-STMT><tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.append(value)<tab><tab><tab>elif is_iterable(value):<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab>if not is_iterable(value):<tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",0,if len ( q ) == 1 :,"if isinstance ( value , ( list , tuple ) ) :",0.016574810992149695,4.789232204309912,0.21481481481481482
"def get_url(token, base_url):<tab>""""""Parse an <url> token.""""""<tab>if token.type == ""url"":<tab><tab>return _get_url_tuple(token.value, base_url)<tab>elif token.type == ""function"":<tab><tab>if token.name == ""attr"":<tab><tab><tab>return check_attr_function(token, ""url"")<tab><tab><IF-STMT><tab><tab><tab># Ignore url modifiers<tab><tab><tab># See https://drafts.csswg.org/css-values-3/#urls<tab><tab><tab>return _get_url_tuple(token.arguments[0].value, base_url)",0,"elif token . name == ""url"" and len ( token . arguments ) in ( 1 , 2 ) :","elif token . name == ""modifiers"" :",0.19701189159951155,18.54238005123115,0.34074074074074073
"def read(self, count):<tab>if self.closed:<tab><tab>return self.upstream.read(count)<tab>try:<tab><tab>while len(self.upstream) < count:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with self.buf_in:<tab><tab><tab><tab><tab>self.transport.downstream_recv(self.buf_in)<tab><tab><tab>else:<tab><tab><tab><tab>break<tab><tab>return self.upstream.read(count)<tab>except:<tab><tab>logger.debug(traceback.format_exc())",0,if self . buf_in or self . _poll_read ( 10 ) :,if self . buf_in :,0.13525131924210887,20.15216974557266,0.4980392156862745
"def get_timestamp_for_block(<tab>self, block_hash: HexBytes, max_tries: Optional[int] = 10) -> int:<tab>counter = 0<tab>block: AttributeDict = None<tab>if block_hash in self._block_cache.keys():<tab><tab>block = self._block_cache.get(block_hash)<tab>else:<tab><tab>while block is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(f""Block hash {block_hash.hex()} does not exist."")<tab><tab><tab>counter += 1<tab><tab><tab>block = self._block_cache.get(block_hash)<tab><tab><tab>await asyncio.sleep(0.5)<tab>return block.get(""timestamp"")",0,if counter == max_tries :,if counter >= max_tries :,0.33141502097923065,59.4603557501361,1.0
"def reader():<tab>batch_out = []<tab>for video_name in self.video_list:<tab><tab>video_idx = self.video_list.index(video_name)<tab><tab>video_feat = self.load_file(video_name)<tab><tab>batch_out.append((video_feat, video_idx))<tab><tab><IF-STMT><tab><tab><tab>yield batch_out<tab><tab><tab>batch_out = []",1,if len ( batch_out ) == self . batch_size :,if len ( batch_out ) == self . batch_size :,0.75,100.00000000000004,1.0
"def cleanup():<tab>gscript.message(_(""Erasing temporary files...""))<tab>for temp_map, maptype in temp_maps:<tab><tab><IF-STMT><tab><tab><tab>gscript.run_command(<tab><tab><tab><tab>""g.remove"", flags=""f"", type=maptype, name=temp_map, quiet=True<tab><tab><tab>)",0,"if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :",if os . path . exists ( temp_map ) :,0.01875687588660047,11.90927538332778,0.25
"def run(self):<tab>while True:<tab><tab>try:<tab><tab><tab>with DelayedKeyboardInterrupt():<tab><tab><tab><tab>raw_inputs = self._parent_task_queue.get()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>if self._flow_type == BATCH:<tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab>elif self._flow_type == REALTIME:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=False)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>pass<tab><tab>except KeyboardInterrupt:<tab><tab><tab>continue",0,if self . _has_stop_signal ( raw_inputs ) :,if raw_inputs is not None :,0.01983074478100545,9.736604043215582,0.3
"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab>if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""):<tab><tab><tab>sent += [self.handle_word(w) for w in child]<tab><tab><IF-STMT><tab><tab><tab>sent.append(self.handle_word(child))<tab><tab>elif child.tag not in self.tags_to_ignore:<tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return BNCSentence(elt.attrib[""n""], sent)",0,"elif child . tag in ( ""w"" , ""c"" ) :","elif child . tag == ""w"" :",0.12914925635699234,23.825412935547586,0.7866666666666667
"def bind_subscribers_to_graphql_type(self, graphql_type):<tab>for field, subscriber in self._subscribers.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Field %s is not defined on type %s"" % (field, self.name))<tab><tab>graphql_type.fields[field].subscribe = subscriber",1,if field not in graphql_type . fields :,if field not in graphql_type . fields :,0.75,100.00000000000004,1.0
"def _get_from_json(self, *, name, version):<tab>url = urljoin(self.url, posixpath.join(name, str(version), ""json""))<tab>async with aiohttp_session(auth=self.auth) as session:<tab><tab>async with session.get(url) as response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise PackageNotFoundError(package=name, url=url)<tab><tab><tab>response.raise_for_status()<tab><tab><tab>response = await response.json()<tab>dist = response[""info""][""requires_dist""] or []<tab>if dist:<tab><tab>return dist<tab># If no requires_dist then package metadata can be broken.<tab># Let's check distribution files.<tab>return await self._get_from_files(response[""urls""])",0,if response . status == 404 :,if response . status_code == 404 :,0.3884893899276739,52.53819788848316,0.5714285714285714
"def is_active(self):<tab>if not self.pk:<tab><tab>log_level = get_setting(""LOG_MISSING_SWITCHES"")<tab><tab>if log_level:<tab><tab><tab>logger.log(log_level, ""Switch %s not found"", self.name)<tab><tab><IF-STMT><tab><tab><tab>switch, _created = Switch.objects.get_or_create(<tab><tab><tab><tab>name=self.name, defaults={""active"": get_setting(""SWITCH_DEFAULT"")}<tab><tab><tab>)<tab><tab><tab>cache = get_cache()<tab><tab><tab>cache.set(self._cache_key(self.name), switch)<tab><tab>return get_setting(""SWITCH_DEFAULT"")<tab>return self.active",0,"if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :","if hasattr ( Switch , ""objects"" ) :",0.04432760343703879,12.451233733093902,0.45833333333333337
"def add_requirements(self, requirements):<tab>if self._legacy:<tab><tab>self._legacy.add_requirements(requirements)<tab>else:<tab><tab>run_requires = self._data.setdefault(""run_requires"", [])<tab><tab>always = None<tab><tab>for entry in run_requires:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>always = entry<tab><tab><tab><tab>break<tab><tab>if always is None:<tab><tab><tab>always = {""requires"": requirements}<tab><tab><tab>run_requires.insert(0, always)<tab><tab>else:<tab><tab><tab>rset = set(always[""requires""]) | set(requirements)<tab><tab><tab>always[""requires""] = sorted(rset)",0,"if ""environment"" not in entry and ""extra"" not in entry :",if entry . startswith ( requirements ) :,0.0133745220801175,3.0297048914466935,0.2
"def display_failures_for_single_test(result: TestResult) -> None:<tab>""""""Display a failure for a single method / endpoint.""""""<tab>display_subsection(result)<tab>checks = _get_unique_failures(result.checks)<tab>for idx, check in enumerate(checks, 1):<tab><tab>message: Optional[str]<tab><tab>if check.message:<tab><tab><tab>message = f""{idx}. {check.message}""<tab><tab>else:<tab><tab><tab>message = None<tab><tab>example = cast(Case, check.example)  # filtered in `_get_unique_failures`<tab><tab>display_example(example, check.name, message, result.seed)<tab><tab># Display every time except the last check<tab><tab><IF-STMT><tab><tab><tab>click.echo(""\n"")",0,if idx != len ( checks ) :,if idx > 0 :,0.0354018406734773,10.62372743739878,0.48148148148148145
"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"":<tab>code = frame.f_code<tab>if (<tab><tab>event not in SUPPORTED_EVENTS<tab><tab>or code.co_name == ""trace_types""<tab><tab>or self.should_trace<tab><tab>and not self.should_trace(code)<tab>):<tab><tab>return self<tab>try:<tab><tab>if event == EVENT_CALL:<tab><tab><tab>self.handle_call(frame)<tab><tab><IF-STMT><tab><tab><tab>self.handle_return(frame, arg)<tab><tab>else:<tab><tab><tab>logger.error(""Cannot handle event %s"", event)<tab>except Exception:<tab><tab>logger.exception(""Failed collecting trace"")<tab>return self",1,elif event == EVENT_RETURN :,elif event == EVENT_RETURN :,1.0,100.00000000000004,1.0
"def get_maps(test):<tab>pages = set()<tab>for addr in test[""pre""][""memory""].keys():<tab><tab>pages.add(addr >> 12)<tab>for addr in test[""pos""][""memory""].keys():<tab><tab>pages.add(addr >> 12)<tab>maps = []<tab>for p in sorted(pages):<tab><tab><IF-STMT><tab><tab><tab>maps[-1] = (maps[-1][0], maps[-1][1] + 0x1000)<tab><tab>else:<tab><tab><tab>maps.append((p << 12, 0x1000))<tab>return maps",0,if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,if p == 0 :,0.01664482667949099,0.28037993823818674,0.19696969696969696
"def process_rotate_aes_key(self):<tab>if hasattr(self.options, ""rotate_aes_key"") and isinstance(<tab><tab>self.options.rotate_aes_key, six.string_types<tab>):<tab><tab><IF-STMT><tab><tab><tab>self.options.rotate_aes_key = True<tab><tab>elif self.options.rotate_aes_key.lower() == ""false"":<tab><tab><tab>self.options.rotate_aes_key = False",1,"if self . options . rotate_aes_key . lower ( ) == ""true"" :","if self . options . rotate_aes_key . lower ( ) == ""true"" :",0.75,100.00000000000004,1.0
"def apply_figure(self, figure):<tab>super(legend_text_legend, self).apply_figure(figure)<tab>properties = self.properties.copy()<tab>with suppress(KeyError):<tab><tab>del properties[""margin""]<tab>with suppress(KeyError):<tab><tab>texts = figure._themeable[""legend_text_legend""]<tab><tab>for text in texts:<tab><tab><tab><IF-STMT>  # textarea<tab><tab><tab><tab>text = text._text<tab><tab><tab>text.set(**properties)",0,"if not hasattr ( text , ""_x"" ) :","if hasattr ( text , ""_text"" ) :",0.1884566599936256,55.097857671324185,0.38181818181818183
"def tearDown(self):<tab>for i in range(len(self.tree) - 1, -1, -1):<tab><tab>s = os.path.join(self.root, self.tree[i])<tab><tab><IF-STMT><tab><tab><tab>os.rmdir(s)<tab><tab>else:<tab><tab><tab>os.remove(s)<tab>os.rmdir(self.root)",0,"if not ""."" in s :",if os . path . isdir ( s ) :,0.021554938761049226,5.934202609760488,0.23863636363636365
"def _get_id(self, type, id):<tab>fields = id.split("":"")<tab>if len(fields) >= 3:<tab><tab>if type != fields[-2]:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, fields[-2], id<tab><tab><tab>)<tab><tab>return fields[-1]<tab>fields = id.split(""/"")<tab>if len(fields) >= 3:<tab><tab>itype = fields[-2]<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, itype, id<tab><tab><tab>)<tab><tab>return fields[-1].split(""?"")[0]<tab>return id",0,if type != itype :,if itype != type :,0.2901714209472326,21.3643503198117,0.5
"def candidates() -> Generator[""Symbol"", None, None]:<tab>s = self<tab>if Symbol.debug_lookup:<tab><tab>Symbol.debug_print(""searching in self:"")<tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>yield s<tab><tab>if recurseInAnon:<tab><tab><tab>yield from s.children_recurse_anon<tab><tab>else:<tab><tab><tab>yield from s._children<tab><tab>if s.siblingAbove is None:<tab><tab><tab>break<tab><tab>s = s.siblingAbove<tab><tab>if Symbol.debug_lookup:<tab><tab><tab>Symbol.debug_print(""searching in sibling:"")<tab><tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")",0,if matchSelf :,if recurseInAnon is None :,0.051944022748897464,1e-10,0.25
"def records(account_id):<tab>""""""Fetch locks data""""""<tab>s = boto3.Session()<tab>table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"")<tab>results = table.scan()<tab>for r in results[""Items""]:<tab><tab>if ""LockDate"" in r:<tab><tab><tab>r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""])<tab><tab><IF-STMT><tab><tab><tab>r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""])<tab>print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))",1,"if ""RevisionDate"" in r :","if ""RevisionDate"" in r :",0.75,100.00000000000004,1.0
"def _handle_errors(errors):<tab>""""""Log out and possibly reraise errors during import.""""""<tab>if not errors:<tab><tab>return<tab>log_all = True  # pylint: disable=unused-variable<tab>err_msg = ""T2T: skipped importing {num_missing} data_generators modules.""<tab>print(err_msg.format(num_missing=len(errors)))<tab>for module, err in errors:<tab><tab>err_str = str(err)<tab><tab>if log_all:<tab><tab><tab>print(""Did not import module: %s; Cause: %s"" % (module, err_str))<tab><tab><IF-STMT><tab><tab><tab>print(""From module %s"" % module)<tab><tab><tab>raise err",0,"if not _is_import_err_msg ( err_str , module ) :",elif module in data_generators :,0.01368058718002997,1.7955716566806617,0.16666666666666666
"def find_needle(self, tree, focused=None):<tab>if isinstance(tree, list):<tab><tab>for el in tree:<tab><tab><tab>res = self.find_needle(el, focused)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return res<tab>elif isinstance(tree, dict):<tab><tab>nodes = tree.get(""nodes"", []) + tree.get(""floating_nodes"", [])<tab><tab>if focused:<tab><tab><tab>for node in nodes:<tab><tab><tab><tab>if node[""id""] == focused[""id""]:<tab><tab><tab><tab><tab>return tree<tab><tab>elif tree[""focused""]:<tab><tab><tab>return tree<tab><tab>return self.find_needle(nodes, focused)<tab>return {}",1,if res :,if res :,0.5311706625951745,1e-10,1.0
"def available_datasets(self):<tab>""""""Automatically determine datasets provided by this file""""""<tab>res = self.resolution<tab>coordinates = [""pixel_longitude"", ""pixel_latitude""]<tab>for var_name, val in self.file_content.items():<tab><tab>if isinstance(val, netCDF4.Variable):<tab><tab><tab>ds_info = {<tab><tab><tab><tab>""file_type"": self.filetype_info[""file_type""],<tab><tab><tab><tab>""resolution"": res,<tab><tab><tab>}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ds_info[""coordinates""] = coordinates<tab><tab><tab>yield DatasetID(name=var_name, resolution=res), ds_info",0,if not self . is_geo :,if len ( coordinates ) > 0 :,0.022316443924793247,6.567274736060395,0.2698412698412698
"def get_subkeys(self, key):<tab># TODO: once we revamp the registry emulation,<tab># make this better<tab>parent_path = key.get_path()<tab>subkeys = []<tab>for k in self.keys:<tab><tab>test_path = k.get_path()<tab><tab><IF-STMT><tab><tab><tab>sub = test_path[len(parent_path) :]<tab><tab><tab>if sub.startswith(""\\""):<tab><tab><tab><tab>sub = sub[1:]<tab><tab><tab>end_slash = sub.find(""\\"")<tab><tab><tab>if end_slash >= 0:<tab><tab><tab><tab>sub = sub[:end_slash]<tab><tab><tab>if not sub:<tab><tab><tab><tab>continue<tab><tab><tab>subkeys.append(sub)<tab>return subkeys",0,if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) :,if test_path . startswith ( parent_path ) :,0.11246149143008767,39.58936700221689,0.4807692307692308
"def default(self, o):<tab>try:<tab><tab>if type(o) == datetime.datetime:<tab><tab><tab>return str(o)<tab><tab>else:<tab><tab><tab># remove unwanted attributes from the provider object during conversion to json<tab><tab><tab>if hasattr(o, ""profile""):<tab><tab><tab><tab>del o.profile<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del o.credentials<tab><tab><tab>if hasattr(o, ""metadata_path""):<tab><tab><tab><tab>del o.metadata_path<tab><tab><tab>if hasattr(o, ""services_config""):<tab><tab><tab><tab>del o.services_config<tab><tab><tab>return vars(o)<tab>except Exception as e:<tab><tab>return str(o)",1,"if hasattr ( o , ""credentials"" ) :","if hasattr ( o , ""credentials"" ) :",0.75,100.00000000000004,1.0
"def submit(self, fn, *args, **kwargs):<tab>with self._shutdown_lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""cannot schedule new futures after shutdown"")<tab><tab>f = _base.Future()<tab><tab>w = _WorkItem(f, fn, args, kwargs)<tab><tab>self._work_queue.put(w)<tab><tab>self._adjust_thread_count()<tab><tab>return f",1,if self . _shutdown :,if self . _shutdown :,0.75,100.00000000000004,1.0
"def __viewerKeyPress(viewer, event):<tab>view = viewer.view()<tab>if not isinstance(view, GafferSceneUI.SceneView):<tab><tab>return False<tab>if event == __editSourceKeyPress:<tab><tab>selectedPath = __sceneViewSelectedPath(view)<tab><tab><IF-STMT><tab><tab><tab>__editSourceNode(view.getContext(), view[""in""], selectedPath)<tab><tab>return True<tab>elif event == __editTweaksKeyPress:<tab><tab>selectedPath = __sceneViewSelectedPath(view)<tab><tab>if selectedPath is not None:<tab><tab><tab>__editTweaksNode(view.getContext(), view[""in""], selectedPath)<tab><tab>return True",1,if selectedPath is not None :,if selectedPath is not None :,0.75,100.00000000000004,1.0
"def _split_to_option_groups_and_paths(self, args):<tab>opt_groups = []<tab>current = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>opts = self._arg_parser.parse_args(current)[0]<tab><tab><tab>opt_groups.append(opts)<tab><tab><tab>current = []<tab><tab>else:<tab><tab><tab>current.append(arg)<tab>if opt_groups:<tab><tab>return opt_groups, current<tab>raise ValueError(""Nothing to split"")",0,"if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :","if isinstance ( current , list ) :",0.0068289025973464704,0.9862667979327593,0.18888888888888888
"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",0,if value :,if value != 0 :,0.09791453445388575,1e-10,0.7
"def wait_for_child(pid, timeout=1.0):<tab>deadline = mitogen.core.now() + timeout<tab>while timeout < mitogen.core.now():<tab><tab>try:<tab><tab><tab>target_pid, status = os.waitpid(pid, os.WNOHANG)<tab><tab><tab>if target_pid == pid:<tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>time.sleep(0.05)<tab>assert False, ""wait_for_child() timed out""",0,if e . args [ 0 ] == errno . ECHILD :,if e . errno == errno . EINTR :,0.1755415832491244,29.10042507378281,0.3653846153846154
"def _get_os_version_lsb_release():<tab>try:<tab><tab>output = subprocess.check_output(""lsb_release -sri"", shell=True)<tab><tab>lines = output.strip().split()<tab><tab>name, version = lines<tab><tab><IF-STMT><tab><tab><tab>version = """"<tab><tab>return name, version<tab>except:<tab><tab>return _get_os_version_uname()",0,"if version . lower ( ) == ""rolling"" :","if version == """" :",0.03153300650124795,17.58943312560456,0.7307692307692308
"def _check_snapshot_status_healthy(self, snapshot_uuid):<tab>status = """"<tab>try:<tab><tab>while True:<tab><tab><tab>status, locked = self._get_snapshot_status(snapshot_uuid)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>eventlet.sleep(2)<tab>except Exception:<tab><tab>with excutils.save_and_reraise_exception():<tab><tab><tab>LOG.exception(""Failed to get snapshot status. [%s]"", snapshot_uuid)<tab>LOG.debug(<tab><tab>""Lun [%(snapshot)s], status [%(status)s]."",<tab><tab>{""snapshot"": snapshot_uuid, ""status"": status},<tab>)<tab>return status == ""Healthy""",0,if not locked :,if locked :,0.09648852821835877,1e-10,0.41666666666666663
"def CountButtons(self):<tab>""""""Returns the number of visible buttons in the docked pane.""""""<tab>n = 0<tab>if self.HasCaption() or self.HasCaptionLeft():<tab><tab>if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame):<tab><tab><tab>return 1<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>if self.HasMaximizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasMinimizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasPinButton():<tab><tab><tab>n += 1<tab>return n",0,if self . HasCloseButton ( ) :,if self . HasMinimizeButton ( ) :,0.3884893899276739,41.11336169005196,0.6
"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>from .datastructures import iter_multi_items<tab>iterable = iter_multi_items(obj)<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, value in iterable:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not isinstance(key, bytes):<tab><tab><tab>key = text_type(key).encode(charset)<tab><tab>if not isinstance(value, bytes):<tab><tab><tab>value = text_type(value).encode(charset)<tab><tab>yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)",0,if value is None :,if not encode_keys :,0.03675197809660419,9.652434877402245,0.25
"def get_response(self, exc_fmt=None):<tab>self.callback = None<tab>if __debug__:<tab><tab>self.parent._log(3, ""%s:%s.ready.wait"" % (self.name, self.tag))<tab>self.ready.wait()<tab>if self.aborted is not None:<tab><tab>typ, val = self.aborted<tab><tab><IF-STMT><tab><tab><tab>exc_fmt = ""%s - %%s"" % typ<tab><tab>raise typ(exc_fmt % str(val))<tab>return self.response",1,if exc_fmt is None :,if exc_fmt is None :,0.75,100.00000000000004,1.0
"def extract_items(self):<tab>responses = self.fetch()<tab>items = []<tab>for response in responses:<tab><tab>page_key = response.meta.get(""page_key"") or response.url<tab><tab>item = {""key"": page_key, ""items"": None, ""templates"": None}<tab><tab>extracted_items = [<tab><tab><tab>dict(i) for i in self.spider.parse(response) if not isinstance(i, Request)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>item[""items""] = extracted_items<tab><tab><tab>item[""templates""] = [<tab><tab><tab><tab>i[""_template""] for i in extracted_items if i.get(""_template"")<tab><tab><tab>]<tab><tab><tab>items.append(item)<tab>return items",0,if extracted_items :,if len ( extracted_items ) > 0 :,0.046522600101893324,1e-10,0.45833333333333337
"def fit_one(self, x):<tab>for i, xi in x.items():<tab><tab>if self.with_centering:<tab><tab><tab>self.median[i].update(xi)<tab><tab><IF-STMT><tab><tab><tab>self.iqr[i].update(xi)<tab>return self",0,if self . with_scaling :,elif self . with_centering :,0.058575650843433,43.47208719449914,0.5
"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab>if left == 0:<tab><tab><tab>done = True<tab><tab><IF-STMT><tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab>if right == len(text):<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[right]):<tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",0,elif not self . word_boundary_char ( text [ left - 1 ] ) :,elif self . word_boundary_char ( text [ left ] ) :,0.3041486508431215,66.66467303030575,0.2698412698412698
"def _validate_duplicate_detection_history_time_window(namespace):<tab>if namespace.duplicate_detection_history_time_window:<tab><tab>if iso8601pattern.match(namespace.duplicate_detection_history_time_window):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""--duplicate-detection-history-time-window Value Error : {0} value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min"".format(<tab><tab><tab><tab><tab>namespace.duplicate_detection_history_time_window<tab><tab><tab><tab>)<tab><tab><tab>)",0,elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,elif durationpattern . match ( namespace . duplicate_detection_history_time_window ) :,0.6412711450183218,89.15993127600096,0.6666666666666666
"def get_subkeys(self, key):<tab># TODO: once we revamp the registry emulation,<tab># make this better<tab>parent_path = key.get_path()<tab>subkeys = []<tab>for k in self.keys:<tab><tab>test_path = k.get_path()<tab><tab>if test_path.lower().startswith(parent_path.lower()):<tab><tab><tab>sub = test_path[len(parent_path) :]<tab><tab><tab>if sub.startswith(""\\""):<tab><tab><tab><tab>sub = sub[1:]<tab><tab><tab>end_slash = sub.find(""\\"")<tab><tab><tab>if end_slash >= 0:<tab><tab><tab><tab>sub = sub[:end_slash]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>subkeys.append(sub)<tab>return subkeys",0,if not sub :,"if sub . startswith ( ""\\"" ) :",0.03661176184600709,4.9323515694897075,0.4
"def generator(self, data):<tab><IF-STMT><tab><tab>silent_vars = self._get_silent_vars()<tab>for task in data:<tab><tab>for var, val in task.environment_variables():<tab><tab><tab>if self._config.SILENT:<tab><tab><tab><tab>if var in silent_vars:<tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>int(task.UniqueProcessId),<tab><tab><tab><tab><tab>str(task.ImageFileName),<tab><tab><tab><tab><tab>Address(task.Peb.ProcessParameters.Environment),<tab><tab><tab><tab><tab>str(var),<tab><tab><tab><tab><tab>str(val),<tab><tab><tab><tab>],<tab><tab><tab>)",0,if self . _config . SILENT :,if self . _config . SLENT :,0.574113272471593,70.71067811865478,0.6
"def start_requests(self):<tab>if self.fail_before_yield:<tab><tab>1 / 0<tab>for s in range(100):<tab><tab>qargs = {""total"": 10, ""seed"": s}<tab><tab>url = self.mockserver.url(""/follow?%s"") % urlencode(qargs, doseq=1)<tab><tab>yield Request(url, meta={""seed"": s})<tab><tab><IF-STMT><tab><tab><tab>2 / 0<tab>assert self.seedsseen, ""All start requests consumed before any download happened""",0,if self . fail_yielding :,if self . fail_before_yield :,0.39477865547525276,46.713797772819994,1.0
"def populateGridlines(self):<tab>cTicks = self.getSystemCurve(self.ticksId)<tab>cGridlines = self.getSystemCurve(self.gridlinesId)<tab>cGridlines.clearPoints()<tab>nTicks = cTicks.getNPoints()<tab>for iTick in range(nTicks):<tab><tab><IF-STMT><tab><tab><tab>p = cTicks.getPoint(iTick)<tab><tab><tab>cGridlines.addPoint(p.getX(), p.getY())",0,if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 :,if cTicks . hasPoint ( iTick ) :,0.017906483884352176,5.34741036489421,0.17777777777777776
"def handle_before_events(request, event_list):<tab>if not event_list:<tab><tab>return """"<tab>if not hasattr(event_list, ""__iter__""):<tab><tab>project = event_list.project<tab><tab>event_list = [event_list]<tab>else:<tab><tab>projects = set(e.project for e in event_list)<tab><tab><IF-STMT><tab><tab><tab>project = projects.pop()<tab><tab>else:<tab><tab><tab>project = None<tab>for plugin in plugins.for_project(project):<tab><tab>safe_execute(plugin.before_events, request, event_list)<tab>return """"",0,if len ( projects ) == 1 :,if len ( projects ) > 0 :,0.5241515189640744,47.750342648354646,0.6666666666666666
"def handle_parse_result(self, ctx, opts, args):<tab>if self.name in opts:<tab><tab><IF-STMT><tab><tab><tab>self._raise_exclusive_error()<tab><tab>if self.multiple and len(set(opts[self.name])) > 1:<tab><tab><tab>self._raise_exclusive_error()<tab>return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",0,if self . mutually_exclusive . intersection ( opts ) :,if self . exclusive and len ( set ( opts [ self . name ] ) ) > 1 :,0.10442365656062855,10.380235015651325,0.22144522144522147
"def current_word(cursor_offset, line):<tab>""""""the object.attribute.attribute just before or under the cursor""""""<tab>pos = cursor_offset<tab>start = pos<tab>end = pos<tab>word = None<tab>for m in current_word_re.finditer(line):<tab><tab><IF-STMT><tab><tab><tab>start = m.start(1)<tab><tab><tab>end = m.end(1)<tab><tab><tab>word = m.group(1)<tab>if word is None:<tab><tab>return None<tab>return LinePart(start, end, word)",0,if m . start ( 1 ) < pos and m . end ( 1 ) >= pos :,if m . start ( 1 ) == start :,0.5123289028648212,26.81283864255185,0.47282608695652173
"def query_to_script_path(path, query):<tab>if path != ""*"":<tab><tab>script = os.path.join(path, query.split("" "")[0])<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""Script '{}' not found in script directory"".format(query))<tab><tab>return os.path.join(path, query).split("" "")<tab>return query",1,if not os . path . exists ( script ) :,if not os . path . exists ( script ) :,0.75,100.00000000000004,1.0
"def expand(self, pbegin):<tab># TODO(b/151921205): we have to do an identity map for unmodified<tab># PCollections below because otherwise we get an error from beam.<tab>identity_map = ""Identity"" >> beam.Map(lambda x: x)<tab>if self._dataset_key.is_flattened_dataset_key():<tab><tab><IF-STMT><tab><tab><tab>return self._flat_pcollection | identity_map<tab><tab>else:<tab><tab><tab>return list(<tab><tab><tab><tab>self._pcollection_dict.values()<tab><tab><tab>) | ""FlattenAnalysisInputs"" >> beam.Flatten(pipeline=pbegin.pipeline)<tab>else:<tab><tab>return self._pcollection_dict[self._dataset_key] | identity_map",0,if self . _flat_pcollection :,if self . _pcollection_dict is None :,0.2005939911646859,32.46679154750989,0.55
"def processCoords(coords):<tab>newcoords = deque()<tab>for (x, y, z) in coords:<tab><tab>for _dir, offsets in faceDirections:<tab><tab><tab>if _dir == FaceYIncreasing:<tab><tab><tab><tab>continue<tab><tab><tab>dx, dy, dz = offsets<tab><tab><tab>p = (x + dx, y + dy, z + dz)<tab><tab><tab>if p not in box:<tab><tab><tab><tab>continue<tab><tab><tab>nx, ny, nz = p<tab><tab><tab><IF-STMT><tab><tab><tab><tab>level.setBlockAt(nx, ny, nz, waterID)<tab><tab><tab><tab>newcoords.append(p)<tab>return newcoords",0,"if level . blockAt ( nx , ny , nz ) == 0 :",if nz > 0 :,0.015612968593192996,3.4384144696651595,0.2222222222222222
"def delete_byfilter(userId, remove=True, session=None, **dbfilter):<tab>if not session:<tab><tab>session = db.Session<tab>ret = False<tab>results = session.query(ObjectStorageMetadata).filter_by(**dbfilter)<tab>if results:<tab><tab>for result in results:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>session.delete(result)<tab><tab><tab>else:<tab><tab><tab><tab>result.update(<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""record_state_key"": ""to_delete"",<tab><tab><tab><tab><tab><tab>""record_state_val"": str(time.time()),<tab><tab><tab><tab><tab>}<tab><tab><tab><tab>)<tab><tab><tab>ret = True<tab>return ret",1,if remove :,if remove :,0.5311706625951745,1e-10,1.0
"def fields(self, fields):<tab>fields_xml = """"<tab>for field in fields:<tab><tab>field_dict = DEFAULT_FIELD.copy()<tab><tab>field_dict.update(field)<tab><tab><IF-STMT><tab><tab><tab>field_dict[""required""] = ""true""<tab><tab>fields_xml += FIELD_XML_TEMPLATE % field_dict + ""\n""<tab>self.xml = force_unicode(<tab><tab>force_unicode(self.xml).replace(<tab><tab><tab>u""<!-- REPLACE FIELDS -->"", force_unicode(fields_xml)<tab><tab>)<tab>)",0,"if self . unique_key_field == field [ ""name"" ] :","if ""required"" not in field_dict :",0.01382317964277637,3.2612121198882003,0.3333333333333333
"def get_all_users(self, access_token, timeout=None):<tab>if timeout is None:<tab><tab>timeout = DEFAULT_TIMEOUT<tab>headers = self.retrieve_header(access_token)<tab>try:<tab><tab>response = await self.standard_request(<tab><tab><tab>""get"", ""/walkoff/api/users"", timeout=DEFAULT_TIMEOUT, headers=headers<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>resp = await response.json()<tab><tab><tab>return resp, ""Success""<tab><tab>else:<tab><tab><tab>return ""Invalid Credentials""<tab>except asyncio.CancelledError:<tab><tab>return False, ""TimedOut""",1,if response . status == 200 :,if response . status == 200 :,0.75,100.00000000000004,1.0
"def set_val():<tab>idx = 0<tab>for idx in range(0, len(model)):<tab><tab>row = model[idx]<tab><tab>if value and row[0] == value:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>idx = -1<tab>os_widget.set_active(idx)<tab>if idx == -1:<tab><tab>os_widget.set_active(0)<tab>if idx >= 0:<tab><tab>return row[1]<tab>if self.show_all_os:<tab><tab>return None",0,if idx == len ( os_widget . get_model ( ) ) - 1 :,if idx == len ( model ) - 1 :,0.22489789254305714,34.72495173503991,0.6578947368421052
"def translate_module_name(module: str, relative: int) -> Tuple[str, int]:<tab>for pkg in VENDOR_PACKAGES:<tab><tab>for alt in ""six.moves"", ""six"":<tab><tab><tab>substr = ""{}.{}"".format(pkg, alt)<tab><tab><tab>if module.endswith(""."" + substr) or (module == substr and relative):<tab><tab><tab><tab>return alt, 0<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return alt + ""."" + module.partition(""."" + substr + ""."")[2], 0<tab>return module, relative",0,"if ""."" + substr + ""."" in module :","elif module . endswith ( ""."" + substr ) or ( module == substr and relative ) :",0.12927151923168448,19.1208175750425,0.0782608695652174
"def escape(m):<tab>all, tail = m.group(0, 1)<tab>assert all.startswith(""\\"")<tab>esc = simple_escapes.get(tail)<tab>if esc is not None:<tab><tab>return esc<tab>if tail.startswith(""x""):<tab><tab>hexes = tail[1:]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""invalid hex string escape ('\\%s')"" % tail)<tab><tab>try:<tab><tab><tab>i = int(hexes, 16)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""invalid hex string escape ('\\%s')"" % tail)<tab>else:<tab><tab>try:<tab><tab><tab>i = int(tail, 8)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(""invalid octal string escape ('\\%s')"" % tail)<tab>return chr(i)",0,if len ( hexes ) < 2 :,if not hexes :,0.019930835999227993,7.733712583165139,0.48148148148148145
"def __get_k8s_container_name(self, job_wrapper):<tab># These must follow a specific regex for Kubernetes.<tab>raw_id = job_wrapper.job_destination.id<tab>if isinstance(raw_id, str):<tab><tab>cleaned_id = re.sub(""[^-a-z0-9]"", ""-"", raw_id)<tab><tab><IF-STMT><tab><tab><tab>cleaned_id = ""x%sx"" % cleaned_id<tab><tab>return cleaned_id<tab>return ""job-container""",0,"if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :","if not cleaned_id . startswith ( ""x"" ) :",0.15099780977026916,27.445520985188047,0.32608695652173914
"def _power_exact(y, xc, yc, xe):<tab>yc, ye = y.int, y.exp<tab>while yc % 10 == 0:<tab><tab>yc //= 10<tab><tab>ye += 1<tab>if xc == 1:<tab><tab>xe *= yc<tab><tab>while xe % 10 == 0:<tab><tab><tab>xe //= 10<tab><tab><tab>ye += 1<tab><tab>if ye < 0:<tab><tab><tab>return None<tab><tab>exponent = xe * 10 ** ye<tab><tab><IF-STMT><tab><tab><tab>xc = exponent<tab><tab>else:<tab><tab><tab>xc = 0<tab><tab>return 5",0,if y and xe :,if exponent > 0 :,0.03412306583404374,12.703318703865365,0.23809523809523808
"def lpush(key, *vals, **kwargs):<tab>ttl = kwargs.get(""ttl"")<tab>cap = kwargs.get(""cap"")<tab>if not ttl and not cap:<tab><tab>_client.lpush(key, *vals)<tab>else:<tab><tab>pipe = _client.pipeline()<tab><tab>pipe.lpush(key, *vals)<tab><tab><IF-STMT><tab><tab><tab>pipe.ltrim(key, 0, cap)<tab><tab>if ttl:<tab><tab><tab>pipe.expire(key, ttl)<tab><tab>pipe.execute()",1,if cap :,if cap :,0.5311706625951745,1e-10,1.0
"def render_headers(self) -> bytes:<tab>if not hasattr(self, ""_headers""):<tab><tab>parts = [<tab><tab><tab>b""Content-Disposition: form-data; "",<tab><tab><tab>format_form_param(""name"", self.name),<tab><tab>]<tab><tab>if self.filename:<tab><tab><tab>filename = format_form_param(""filename"", self.filename)<tab><tab><tab>parts.extend([b""; "", filename])<tab><tab><IF-STMT><tab><tab><tab>content_type = self.content_type.encode()<tab><tab><tab>parts.extend([b""\r\nContent-Type: "", content_type])<tab><tab>parts.append(b""\r\n\r\n"")<tab><tab>self._headers = b"""".join(parts)<tab>return self._headers",0,if self . content_type is not None :,if self . content_type :,0.2343345094426703,54.77927682341229,0.4444444444444444
"def validate_custom_field_data(field_type: int, field_data: ProfileFieldData) -> None:<tab>try:<tab><tab><IF-STMT><tab><tab><tab># Choice type field must have at least have one choice<tab><tab><tab>if len(field_data) < 1:<tab><tab><tab><tab>raise JsonableError(_(""Field must have at least one choice.""))<tab><tab><tab>validate_choice_field_data(field_data)<tab><tab>elif field_type == CustomProfileField.EXTERNAL_ACCOUNT:<tab><tab><tab>validate_external_account_field_data(field_data)<tab>except ValidationError as error:<tab><tab>raise JsonableError(error.message)",0,if field_type == CustomProfileField . CHOICE :,if field_type == CustomProfileField . ChoiceType :,0.574113272471593,78.25422900366438,0.6
"def get_data(self, path):<tab>""""""Gross hack to contort loader to deal w/ load_*()'s bad API.""""""<tab>if self.file and path == self.path:<tab><tab><IF-STMT><tab><tab><tab>file = self.file<tab><tab>else:<tab><tab><tab>self.file = file = open(self.path, ""r"")<tab><tab>with file:<tab><tab><tab># Technically should be returning bytes, but<tab><tab><tab># SourceLoader.get_code() just passed what is returned to<tab><tab><tab># compile() which can handle str. And converting to bytes would<tab><tab><tab># require figuring out the encoding to decode to and<tab><tab><tab># tokenize.detect_encoding() only accepts bytes.<tab><tab><tab>return file.read()<tab>else:<tab><tab>return super().get_data(path)",0,if not self . file . closed :,"if isinstance ( self . file , str ) :",0.07054132944044117,17.747405280050266,0.5
"def handle_read(self):<tab>""""""Called when there is data waiting to be read.""""""<tab>try:<tab><tab>chunk = self.recv(self.ac_in_buffer_size)<tab>except RetryError:<tab><tab>pass<tab>except socket.error:<tab><tab>self.handle_error()<tab>else:<tab><tab>self.tot_bytes_received += len(chunk)<tab><tab><IF-STMT><tab><tab><tab>self.transfer_finished = True<tab><tab><tab># self.close()  # <-- asyncore.recv() already do that...<tab><tab><tab>return<tab><tab>if self._data_wrapper is not None:<tab><tab><tab>chunk = self._data_wrapper(chunk)<tab><tab>try:<tab><tab><tab>self.file_obj.write(chunk)<tab><tab>except OSError as err:<tab><tab><tab>raise _FileReadWriteError(err)",0,if not chunk :,if self . transfer_finished :,0.04240785919217091,7.809849842300637,0.36
"def _swig_extract_dependency_files(self, src):<tab>dep = []<tab>for line in open(src):<tab><tab><IF-STMT><tab><tab><tab>line = line.split("" "")[1].strip(""""""'""\r\n"""""")<tab><tab><tab>if not (""<"" in line or line in dep):<tab><tab><tab><tab>dep.append(line)<tab>return [i for i in dep if os.path.exists(i)]",0,"if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :","if "" "" in line :",0.008063669327166617,0.9962897853127464,0.30952380952380953
"def buffer(self, lines, scroll_end=True, scroll_if_editing=False):<tab>""Add data to be displayed in the buffer.""<tab>self.values.extend(lines)<tab>if scroll_end:<tab><tab>if not self.editing:<tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)<tab><tab><IF-STMT><tab><tab><tab>self.start_display_at = len(self.values) - len(self._my_widgets)",0,elif scroll_if_editing :,elif self . editing :,0.04570375548122485,1e-10,0.41666666666666663
"def test_getline(self):<tab>with tokenize.open(self.file_name) as fp:<tab><tab>for index, line in enumerate(fp):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line += ""\n""<tab><tab><tab>cached_line = linecache.getline(self.file_name, index + 1)<tab><tab><tab>self.assertEqual(line, cached_line)",1,"if not line . endswith ( ""\n"" ) :","if not line . endswith ( ""\n"" ) :",0.75,100.00000000000004,1.0
"def selectRow(self, rowNumber, highlight=None):<tab>if rowNumber == ""h"":<tab><tab>rowNumber = 0<tab>else:<tab><tab>rowNumber = int(rowNumber) + 1<tab>if 1 > rowNumber >= len(self.cells) + 1:<tab><tab>raise Exception(""Invalid row number."")<tab>else:<tab><tab>selected = self.cells[rowNumber][0].selected<tab><tab>for cell in self.cells[rowNumber]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if selected:<tab><tab><tab><tab><tab>cell.deselect()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>cell.select()<tab><tab><tab>else:<tab><tab><tab><tab>if highlight:<tab><tab><tab><tab><tab>cell.mouseEnter()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>cell.mouseLeave()",0,if highlight is None :,if cell . selected :,0.03412306583404374,12.703318703865365,0.23809523809523808
"def put(self, session):<tab>with sess_lock:<tab><tab>self.parent.put(session)<tab><tab># Do not store the session if skip paths<tab><tab>for sp in self.skip_paths:<tab><tab><tab>if request.path.startswith(sp):<tab><tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>del self._cache[session.sid]<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass<tab><tab>self._cache[session.sid] = session<tab>self._normalize()",1,if session . sid in self . _cache :,if session . sid in self . _cache :,0.75,100.00000000000004,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_status().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.add_doc_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100.00000000000004,1.0
"def extract(self, zip):<tab>max_nb = maxNbFile(self)<tab>for index, field in enumerate(zip.array(""file"")):<tab><tab><IF-STMT><tab><tab><tab>self.warning(<tab><tab><tab><tab>""ZIP archive contains many files, but only first %s files are processed""<tab><tab><tab><tab>% max_nb<tab><tab><tab>)<tab><tab><tab>break<tab><tab>self.processFile(field)",0,if max_nb is not None and max_nb <= index :,if len ( field ) > max_nb :,0.01500732869315577,10.764345432696361,0.19191919191919193
"def get_norm(norm, out_channels):<tab>if isinstance(norm, str):<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>norm = {<tab><tab><tab>""BN"": BatchNorm2d,<tab><tab><tab>""GN"": lambda channels: nn.GroupNorm(32, channels),<tab><tab><tab>""nnSyncBN"": nn.SyncBatchNorm,  # keep for debugging<tab><tab><tab>"""": lambda x: x,<tab><tab>}[norm]<tab>return norm(out_channels)",0,if len ( norm ) == 0 :,"if norm == ""None"" :",0.020977836961063236,12.256200970377108,0.36
"def execute(self):<tab>if self._dirty or not self._qr:<tab><tab>model_class = self.model_class<tab><tab>query_meta = self.get_query_meta()<tab><tab>if self._tuples:<tab><tab><tab>ResultWrapper = TuplesQueryResultWrapper<tab><tab>elif self._dicts:<tab><tab><tab>ResultWrapper = DictQueryResultWrapper<tab><tab>elif self._naive or not self._joins or self.verify_naive():<tab><tab><tab>ResultWrapper = NaiveQueryResultWrapper<tab><tab><IF-STMT><tab><tab><tab>ResultWrapper = AggregateQueryResultWrapper<tab><tab>else:<tab><tab><tab>ResultWrapper = ModelQueryResultWrapper<tab><tab>self._qr = ResultWrapper(model_class, self._execute(), query_meta)<tab><tab>self._dirty = False<tab><tab>return self._qr<tab>else:<tab><tab>return self._qr",0,elif self . _aggregate_rows :,elif self . _aggregate or not self . verify_aggregate ( ) :,0.17741622492977271,26.760322756637922,0.4980392156862745
"def emitIpToDomainsData(self, data, event):<tab>self.emitRawRirData(data, event)<tab>domains = data.get(""domains"")<tab>if isinstance(domains, list):<tab><tab>for domain in domains:<tab><tab><tab>if self.checkForStop():<tab><tab><tab><tab>return None<tab><tab><tab>domain = domain.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.emitHostname(domain, event)",1,if domain :,if domain :,0.5311706625951745,1e-10,1.0
"def delete(self):<tab>from weblate.trans.models import Change, Suggestion, Vote<tab>fast_deletes = []<tab>for item in self.fast_deletes:<tab><tab><IF-STMT><tab><tab><tab>fast_deletes.append(Vote.objects.filter(suggestion__in=item))<tab><tab><tab>fast_deletes.append(Change.objects.filter(suggestion__in=item))<tab><tab>fast_deletes.append(item)<tab>self.fast_deletes = fast_deletes<tab>return super().delete()",0,if item . model is Suggestion :,if item . applies_to_vote ( ) :,0.09056531419355518,14.991106946711685,0.42857142857142855
"def token(self):<tab>if not self._token:<tab><tab>try:<tab><tab><tab>cookie_token = self.state[""request""].headers.cookie[CSRF_TOKEN].value<tab><tab>except KeyError:<tab><tab><tab>cookie_token = """"<tab><tab><IF-STMT><tab><tab><tab>self._token = cookie_token<tab><tab>else:<tab><tab><tab>self._token = get_random_string(TOKEN_LENGTH)<tab>return self._token",0,if len ( cookie_token ) == TOKEN_LENGTH :,if cookie_token :,0.017267079824235865,1e-10,0.6410256410256411
"def get_logs(last_file=None, last_time=None):<tab>try:<tab><tab>response = client.get_logs(last_file=last_file, last_time=last_time)<tab><tab>get_logs_streamer(<tab><tab><tab>show_timestamp=not hide_time,<tab><tab><tab>all_containers=all_containers,<tab><tab><tab>all_info=all_info,<tab><tab>)(response)<tab><tab>return response<tab>except (ApiException, HTTPError) as e:<tab><tab><IF-STMT><tab><tab><tab>handle_cli_error(<tab><tab><tab><tab>e,<tab><tab><tab><tab>message=""Could not get logs for run `{}`."".format(client.run_uuid),<tab><tab><tab>)<tab><tab><tab>sys.exit(1)",0,if not follow :,if show_cli_error :,0.05063871203029889,1e-10,0.375
"def update(self, targets):<tab>Section.update(self, targets)<tab>outputNames = set()<tab>for target in targets:<tab><tab>g = target.globals()<tab><tab>outputNames.update([k for k in g.keys() if k.startswith(""output:"")])<tab>rows = []<tab>outputNames = sorted(outputNames)<tab>for outputName in outputNames:<tab><tab>row = self.__rows.get(outputName)<tab><tab><IF-STMT><tab><tab><tab>row = _OutputRow(outputName)<tab><tab><tab>self.__rows[outputName] = row<tab><tab>row.update(targets)<tab><tab>row.setAlternate(len(rows) % 2)<tab><tab>rows.append(row)<tab>self._mainColumn()[:] = rows",1,if row is None :,if row is None :,0.75,100.00000000000004,1.0
"def getBranches(self):<tab>returned = []<tab>for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout:<tab><tab>if git_branch_line.startswith(""*""):<tab><tab><tab>git_branch_line = git_branch_line[1:]<tab><tab>git_branch_line = git_branch_line.strip()<tab><tab><IF-STMT><tab><tab><tab>alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER)<tab><tab><tab>returned.append(branch.LocalBranchAlias(self, alias_name, aliased))<tab><tab>else:<tab><tab><tab>returned.append(branch.LocalBranch(self, git_branch_line))<tab>return returned",1,if BRANCH_ALIAS_MARKER in git_branch_line :,if BRANCH_ALIAS_MARKER in git_branch_line :,0.75,100.00000000000004,1.0
"def has_bad_headers(self):<tab>headers = [self.sender, self.reply_to] + self.recipients<tab>for header in headers:<tab><tab>if _has_newline(header):<tab><tab><tab>return True<tab>if self.subject:<tab><tab>if _has_newline(self.subject):<tab><tab><tab>for linenum, line in enumerate(self.subject.split(""\r\n"")):<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if _has_newline(line):<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if len(line.strip()) == 0:<tab><tab><tab><tab><tab>return True<tab>return False",0,"if linenum > 0 and line [ 0 ] not in ""\t "" :",if linenum == 0 :,0.043390746370970776,3.6462189126393114,0.4215686274509804
"def resolve_references(self, note, reflist):<tab>assert len(note[""ids""]) == 1<tab>id = note[""ids""][0]<tab>for ref in reflist:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ref.delattr(""refname"")<tab><tab>ref[""refid""] = id<tab><tab>assert len(ref[""ids""]) == 1<tab><tab>note.add_backref(ref[""ids""][0])<tab><tab>ref.resolved = 1<tab>note.resolved = 1",0,if ref . resolved :,"if ref [ ""refid"" ] == id :",0.04979441971690225,8.29519350710986,0.6
"def pickPath(self, color):<tab>self.path[color] = ()<tab>currentPos = self.starts[color]<tab>while True:<tab><tab>minDist = None<tab><tab>minGuide = None<tab><tab>for guide in self.guides[color]:<tab><tab><tab>guideDist = dist(currentPos, guide)<tab><tab><tab>if minDist == None or guideDist < minDist:<tab><tab><tab><tab>minDist = guideDist<tab><tab><tab><tab>minGuide = guide<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if minGuide == None:<tab><tab><tab>return<tab><tab>self.path[color] = self.path[color] + (minGuide,)<tab><tab>currentPos = minGuide<tab><tab>self.guides[color].remove(minGuide)",0,"if dist ( currentPos , self . ends [ color ] ) == 1 :",if minGuide is None :,0.00703680708675088,1.407567834071592,0.16746411483253587
"def __hierarchyViewKeyPress(hierarchyView, event):<tab>if event == __editSourceKeyPress:<tab><tab>selectedPath = __hierarchyViewSelectedPath(hierarchyView)<tab><tab><IF-STMT><tab><tab><tab>__editSourceNode(<tab><tab><tab><tab>hierarchyView.getContext(), hierarchyView.scene(), selectedPath<tab><tab><tab>)<tab><tab>return True<tab>elif event == __editTweaksKeyPress:<tab><tab>selectedPath = __hierarchyViewSelectedPath(hierarchyView)<tab><tab>if selectedPath is not None:<tab><tab><tab>__editTweaksNode(<tab><tab><tab><tab>hierarchyView.getContext(), hierarchyView.scene(), selectedPath<tab><tab><tab>)<tab><tab>return True",1,if selectedPath is not None :,if selectedPath is not None :,0.75,100.00000000000004,1.0
"def getSubsegments(self):<tab>for num, localdata in self.lfh.LocalData:<tab><tab>for bucket, seginfo in localdata.SegmentInfo:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>yield Win32Subsegment(self.trace, self.heap, seginfo.ActiveSubsegment)",0,if seginfo . ActiveSubsegment == 0 :,if not seginfo . ActiveSubsegment :,0.09662402516463689,24.598127518343304,0.3333333333333333
"def test_full_hd_bluray(self):<tab>cur_test = ""full_hd_bluray""<tab>cur_qual = common.Quality.FULLHDBLURAY<tab>for name, tests in iteritems(self.test_cases):<tab><tab>for test in tests:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(cur_qual, common.Quality.name_quality(test))<tab><tab><tab>else:<tab><tab><tab><tab>self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",1,if name == cur_test :,if name == cur_test :,0.75,100.00000000000004,1.0
"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab>if self.op == ""+"":<tab><tab><tab>self.current += num<tab><tab>elif self.op == ""-"":<tab><tab><tab>self.current -= num<tab><tab>elif self.op == ""*"":<tab><tab><tab>self.current *= num<tab><tab><IF-STMT><tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res",1,"elif self . op == ""/"" :","elif self . op == ""/"" :",1.0,100.00000000000004,1.0
"def strip_export_type(path):<tab>matched = re.search(r""#([a-zA-Z0-9\-]+\\+[a-zA-Z0-9\-]+)?$"", path.encode(""utf-8""))<tab>mime_type = None<tab>if matched:<tab><tab>fragment = matched.group(0)<tab><tab>mime_type = matched.group(1)<tab><tab><IF-STMT><tab><tab><tab>mime_type = mime_type.replace(""+"", ""/"")<tab><tab>path = path[: -len(fragment)]<tab>return (path, mime_type)",0,if mime_type is not None :,"if fragment . endswith ( ""/"" ) :",0.022316443924793247,4.990049701936832,0.2698412698412698
"def _save_as_module(file, data, binary=False):<tab>if not data:<tab><tab>return<tab>with open(file, ""w"") as f:<tab><tab>f.write(""DATA="")<tab><tab><IF-STMT><tab><tab><tab>f.write('""')<tab><tab><tab>f.write(base64.b64encode(data).decode(""ascii""))<tab><tab><tab>f.write('""')<tab><tab>else:<tab><tab><tab>f.write(str(data).replace(""\\\\"", ""\\""))<tab><tab>f.flush()",1,if binary :,if binary :,0.5311706625951745,1e-10,1.0
"def ProcessStringLiteral(self):<tab>if self._lastToken == None or self._lastToken.type == self.OpenBrace:<tab><tab>text = super(JavaScriptBaseLexer, self).text<tab><tab><IF-STMT><tab><tab><tab>if len(self._scopeStrictModes) > 0:<tab><tab><tab><tab>self._scopeStrictModes.pop()<tab><tab><tab>self._useStrictCurrent = True<tab><tab><tab>self._scopeStrictModes.append(self._useStrictCurrent)",0,"if text == '""use strict""' or text == ""'use strict'"" :","if text . startswith ( ""'"" ) :",0.02378363723418389,5.909802422297369,0.52
"def run(self, ttl=None):<tab>self.zeroconf = zeroconf.Zeroconf()<tab>zeroconf.ServiceBrowser(self.zeroconf, self.domain, MDNSHandler(self))<tab>if ttl:<tab><tab>gobject.timeout_add(ttl * 1000, self.shutdown)<tab>self.__running = True<tab>self.__mainloop = gobject.MainLoop()<tab>context = self.__mainloop.get_context()<tab>while self.__running:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>context.iteration(True)<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(0.1)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>break<tab>self.zeroconf.close()<tab>logger.debug(""MDNSListener.run() quit"")",0,if context . pending ( ) :,if context :,0.03885753308224148,1e-10,0.7222222222222222
"def topology_change_notify(self, port_state):<tab>notice = False<tab>if port_state is PORT_STATE_FORWARD:<tab><tab>for port in self.ports.values():<tab><tab><tab>if port.role is DESIGNATED_PORT:<tab><tab><tab><tab>notice = True<tab><tab><tab><tab>break<tab>else:<tab><tab>notice = True<tab>if notice:<tab><tab>self.send_event(EventTopologyChange(self.dp))<tab><tab><IF-STMT><tab><tab><tab>self._transmit_tc_bpdu()<tab><tab>else:<tab><tab><tab>self._transmit_tcn_bpdu()",0,if self . is_root_bridge :,if port_state is PORT_STATE_FORWARD :,0.03412306583404374,5.604233375480572,0.5
def close_open_fds(keep=None):  # noqa<tab>keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None]<tab>for fd in reversed(range(get_fdmax(default=2048))):<tab><tab>if fd not in keep:<tab><tab><tab>try:<tab><tab><tab><tab>os.close(fd)<tab><tab><tab>except OSError as exc:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise,0,if exc . errno != errno . EBADF :,if exc . errno != errno . ENOTCONN :,0.87709085524794,78.25422900366438,0.6666666666666666
"def collect_attributes(options, node, master_list):<tab>""""""Collect all attributes""""""<tab>for ii in node.instructions:<tab><tab>if field_check(ii, ""attributes""):<tab><tab><tab>s = getattr(ii, ""attributes"")<tab><tab><tab>if isinstance(s, list):<tab><tab><tab><tab>for x in s:<tab><tab><tab><tab><tab>if x not in master_list:<tab><tab><tab><tab><tab><tab>master_list.append(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>master_list.append(s)<tab>for nxt in node.next.values():<tab><tab>collect_attributes(options, nxt, master_list)",0,elif s != None and s not in master_list :,"elif isinstance ( s , dict ) :",0.15295030381929178,3.8902180856807296,0.18518518518518517
"def remove_test_run_directories(expiry_time: int = 60 * 60) -> int:<tab>removed = 0<tab>directories = glob.glob(os.path.join(UUID_VAR_DIR, ""test-backend"", ""run_*""))<tab>for test_run in directories:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>shutil.rmtree(test_run)<tab><tab><tab><tab>removed += 1<tab><tab><tab>except FileNotFoundError:<tab><tab><tab><tab>pass<tab>return removed",0,if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,if os . path . exists ( test_run ) and expiry_time >= time . time ( ) :,0.5000088378444603,44.40498994643096,0.2222222222222222
"def read_work_titles(fields):<tab>found = []<tab>if ""240"" in fields:<tab><tab>for line in fields[""240""]:<tab><tab><tab>title = join_subfield_values(line, [""a"", ""m"", ""n"", ""p"", ""r""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found.append(title)<tab>if ""130"" in fields:<tab><tab>for line in fields[""130""]:<tab><tab><tab>title = "" "".join(get_lower_subfields(line))<tab><tab><tab>if title not in found:<tab><tab><tab><tab>found.append(title)<tab>return {""work_titles"": found} if found else {}",1,if title not in found :,if title not in found :,0.75,100.00000000000004,1.0
"def _process_v1_msg(prot, msg):<tab>header = None<tab>body = msg[1]<tab>if not isinstance(body, (binary_type, mmap, memoryview)):<tab><tab>raise ValidationError(body, ""Body must be a bytestream."")<tab>if len(msg) > 2:<tab><tab>header = msg[2]<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(header, ""Header must be a dict."")<tab><tab>for k, v in header.items():<tab><tab><tab>header[k] = msgpack.unpackb(v)<tab>ctx = MessagePackMethodContext(prot, MessagePackMethodContext.SERVER)<tab>ctx.in_string = [body]<tab>ctx.transport.in_header = header<tab>return ctx",1,"if not isinstance ( header , dict ) :","if not isinstance ( header , dict ) :",0.75,100.00000000000004,1.0
"def find(self, node):<tab>typename = type(node).__name__<tab>method = getattr(self, ""find_{}"".format(typename), None)<tab>if method is None:<tab><tab>fields = getattr(node, ""_fields"", None)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for field in fields:<tab><tab><tab>value = getattr(node, field)<tab><tab><tab>for result in self.find(value):<tab><tab><tab><tab>yield result<tab>else:<tab><tab>for result in method(node):<tab><tab><tab>yield result",1,if fields is None :,if fields is None :,0.75,100.00000000000004,1.0
"def _str_param_list(self, name):<tab>out = []<tab>if self[name]:<tab><tab>out += self._str_header(name)<tab><tab>for param in self[name]:<tab><tab><tab>parts = []<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts.append(param.name)<tab><tab><tab>if param.type:<tab><tab><tab><tab>parts.append(param.type)<tab><tab><tab>out += ["" : "".join(parts)]<tab><tab><tab>if param.desc and """".join(param.desc).strip():<tab><tab><tab><tab>out += self._str_indent(param.desc)<tab><tab>out += [""""]<tab>return out",1,if param . name :,if param . name :,0.75,100.00000000000004,1.0
"def _get_image(self, image_list, source):<tab>if source.startswith(""wx""):<tab><tab>img = wx.ArtProvider_GetBitmap(source, wx.ART_OTHER, _SIZE)<tab>else:<tab><tab>path = os.path.join(_BASE, source)<tab><tab><IF-STMT><tab><tab><tab>img = wx.Image(path, wx.BITMAP_TYPE_GIF).ConvertToBitmap()<tab><tab>else:<tab><tab><tab>img = wx.Image(path, wx.BITMAP_TYPE_PNG).ConvertToBitmap()<tab>return image_list.Add(img)",0,"if source . endswith ( ""gif"" ) :",if os . path . exists ( path ) :,0.03335693520311296,10.552670315936318,0.2619047619047619
"def change_opacity_function(self, new_f):<tab>self.opacity_function = new_f<tab>dr = self.radius / self.num_levels<tab>sectors = []<tab>for submob in self.submobjects:<tab><tab><IF-STMT><tab><tab><tab>sectors.append(submob)<tab>for (r, submob) in zip(np.arange(0, self.radius, dr), sectors):<tab><tab>if type(submob) != AnnularSector:<tab><tab><tab># it's the shadow, don't dim it<tab><tab><tab>continue<tab><tab>alpha = self.opacity_function(r)<tab><tab>submob.set_fill(opacity=alpha)",1,if type ( submob ) == AnnularSector :,if type ( submob ) == AnnularSector :,0.75,100.00000000000004,1.0
"def _sqlite_post_configure_engine(url, engine, follower_ident):<tab>from sqlalchemy import event<tab>@event.listens_for(engine, ""connect"")<tab>def connect(dbapi_connection, connection_record):<tab><tab># use file DBs in all cases, memory acts kind of strangely<tab><tab># as an attached<tab><tab><IF-STMT><tab><tab><tab>dbapi_connection.execute('ATTACH DATABASE ""test_schema.db"" AS test_schema')<tab><tab>else:<tab><tab><tab>dbapi_connection.execute(<tab><tab><tab><tab>'ATTACH DATABASE ""%s_test_schema.db"" AS test_schema' % follower_ident<tab><tab><tab>)",0,if not follower_ident :,"if follower_ident == ""sqlite"" :",0.045150550804307965,17.747405280050266,0.6190476190476191
"def apply_conf_file(fn, conf_filename):<tab>for env in LSF_CONF_ENV:<tab><tab>conf_file = get_conf_file(conf_filename, env)<tab><tab>if conf_file:<tab><tab><tab>with open(conf_file) as conf_handle:<tab><tab><tab><tab>value = fn(conf_handle)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value<tab>return None",0,if value :,if value is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def test_call_extern_c_fn(self):<tab>global memcmp<tab>memcmp = cffi_support.ExternCFunction(<tab><tab>""memcmp"",<tab><tab>(""int memcmp ( const uint8_t * ptr1, "" ""const uint8_t * ptr2, size_t num )""),<tab>)<tab>@udf(BooleanVal(FunctionContext, StringVal, StringVal))<tab>def fn(context, a, b):<tab><tab>if a.is_null != b.is_null:<tab><tab><tab>return False<tab><tab>if a is None:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if a.ptr == b.ptr:<tab><tab><tab>return True<tab><tab>return memcmp(a.ptr, b.ptr, a.len) == 0",0,if len ( a ) != b . len :,if b is None :,0.014393212535568477,4.234348806659263,0.27272727272727276
"def _get_initialized_app(app):<tab>""""""Returns a reference to an initialized App instance.""""""<tab>if app is None:<tab><tab>return firebase_admin.get_app()<tab>if isinstance(app, firebase_admin.App):<tab><tab>initialized_app = firebase_admin.get_app(app.name)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Illegal app argument. App instance not ""<tab><tab><tab><tab>""initialized via the firebase module.""<tab><tab><tab>)<tab><tab>return app<tab>raise ValueError(<tab><tab>""Illegal app argument. Argument must be of type ""<tab><tab>' firebase_admin.App, but given ""{0}"".'.format(type(app))<tab>)",0,if app is not initialized_app :,if not initialized_app :,0.171601635792411,56.98363775444274,0.3333333333333333
def compiled_query(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.compiled_query_ is None:<tab><tab><tab><tab>self.compiled_query_ = CompiledQuery()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.compiled_query_,1,if self . compiled_query_ is None :,if self . compiled_query_ is None :,0.75,100.00000000000004,1.0
"def clean_subevent(event, subevent):<tab>if event.has_subevents:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(_(""Subevent cannot be null for event series.""))<tab><tab>if event != subevent.event:<tab><tab><tab>raise ValidationError(_(""The subevent does not belong to this event.""))<tab>else:<tab><tab>if subevent:<tab><tab><tab>raise ValidationError(_(""The subevent does not belong to this event.""))",0,if not subevent :,if subevent is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def get_blob_type_declaration_sql(self, column):<tab>length = column.get(""length"")<tab>if length:<tab><tab>if length <= self.LENGTH_LIMIT_TINYBLOB:<tab><tab><tab>return ""TINYBLOB""<tab><tab>if length <= self.LENGTH_LIMIT_BLOB:<tab><tab><tab>return ""BLOB""<tab><tab><IF-STMT><tab><tab><tab>return ""MEDIUMBLOB""<tab>return ""LONGBLOB""",1,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,0.75,100.00000000000004,1.0
"def decompress(self, data):<tab>if not data:<tab><tab>return data<tab>if not self._first_try:<tab><tab>return self._obj.decompress(data)<tab>self._data += data<tab>try:<tab><tab>decompressed = self._obj.decompress(data)<tab><tab><IF-STMT><tab><tab><tab>self._first_try = False<tab><tab><tab>self._data = None<tab><tab>return decompressed<tab>except zlib.error:<tab><tab>self._first_try = False<tab><tab>self._obj = zlib.decompressobj(-zlib.MAX_WBITS)<tab><tab>try:<tab><tab><tab>return self.decompress(self._data)<tab><tab>finally:<tab><tab><tab>self._data = None",0,if decompressed :,if decompressed is None :,0.09791453445388575,1e-10,0.5
"def _record_event(self, path, fsevent_handle, filename, events, error):<tab>with self.lock:<tab><tab>self.events[path].append(events)<tab><tab>if events | pyuv.fs.UV_RENAME:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.watches.pop(path).close()",0,if not os . path . exists ( path ) :,if path in self . watches :,0.013929296510807567,5.244835934727967,0.21212121212121213
"def __init__(self, duration, batch_shape, event_shape, validate_args=None):<tab>if duration is None:<tab><tab><IF-STMT><tab><tab><tab># Infer duration from event_shape.<tab><tab><tab>duration = event_shape[0]<tab>elif duration != event_shape[0]:<tab><tab>if event_shape[0] != 1:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""duration, event_shape mismatch: {} vs {}"".format(duration, event_shape)<tab><tab><tab>)<tab><tab># Infer event_shape from duration.<tab><tab>event_shape = torch.Size((duration,) + event_shape[1:])<tab>self._duration = duration<tab>super().__init__(batch_shape, event_shape, validate_args)",0,if event_shape [ 0 ] != 1 :,"if isinstance ( event_shape , tuple ) :",0.019345087832959386,16.058516370438436,0.3333333333333333
"def _CheckPrerequisites(self):<tab>""""""Exits if any of the prerequisites is not met.""""""<tab>if not FLAGS.kubectl:<tab><tab>raise Exception(<tab><tab><tab>""Please provide path to kubectl tool using --kubectl "" ""flag. Exiting.""<tab><tab>)<tab>if not FLAGS.kubeconfig:<tab><tab>raise Exception(<tab><tab><tab>""Please provide path to kubeconfig using --kubeconfig "" ""flag. Exiting.""<tab><tab>)<tab>if self.disk_specs and self.disk_specs[0].disk_type == disk.STANDARD:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Please provide a list of Ceph Monitors using "" ""--ceph_monitors flag.""<tab><tab><tab>)",0,if not FLAGS . ceph_monitors :,if not FLAGS . Ceph_monitors :,0.5212518808542342,50.000000000000014,1.0
"def invalidateDependentSlices(self, iFirstCurve):<tab># only user defined curve can have slice dependency relationships<tab>if self.isSystemCurveIndex(iFirstCurve):<tab><tab>return<tab>nCurves = self.getNCurves()<tab>for i in range(iFirstCurve, nCurves):<tab><tab>c = self.getSystemCurve(i)<tab><tab><IF-STMT><tab><tab><tab>c.invalidate()<tab><tab>elif i == iFirstCurve:<tab><tab><tab># if first curve isn't a slice,<tab><tab><tab>break<tab><tab><tab># there are no dependent slices",0,"if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",if c . isDependent ( ) :,0.10030648816952623,4.726210391502949,0.20512820512820515
"def find_backwards(self, offset):<tab>try:<tab><tab>for _, token_type, token_value in reversed(self.tokens[self.offset : offset]):<tab><tab><tab>if token_type in (""comment"", ""linecomment""):<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>prefix, comment = token_value.split(None, 1)<tab><tab><tab><tab>except ValueError:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return [comment.rstrip()]<tab><tab>return []<tab>finally:<tab><tab>self.offset = offset",0,if prefix in self . comment_tags :,if comment :,0.020447728119319098,1e-10,0.2916666666666667
"def parse_column_definitions(self, elem):<tab>for column_elem in elem.findall(""column""):<tab><tab>name = column_elem.get(""name"", None)<tab><tab>assert name is not None, ""Required 'name' attribute missing from column def""<tab><tab>index = column_elem.get(""index"", None)<tab><tab>assert index is not None, ""Required 'index' attribute missing from column def""<tab><tab>index = int(index)<tab><tab>self.columns[name] = index<tab><tab><IF-STMT><tab><tab><tab>self.largest_index = index<tab>assert ""value"" in self.columns, ""Required 'value' column missing from column def""<tab>if ""name"" not in self.columns:<tab><tab>self.columns[""name""] = self.columns[""value""]",0,if index > self . largest_index :,"if name == ""largest"" :",0.02225082504991546,6.413885305524152,0.37777777777777777
"def __find_smallest(self):<tab>""""""Find the smallest uncovered value in the matrix.""""""<tab>minval = sys.maxsize<tab>for i in range(self.n):<tab><tab>for j in range(self.n):<tab><tab><tab>if (not self.row_covered[i]) and (not self.col_covered[j]):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>minval = self.C[i][j]<tab>return minval",0,if minval > self . C [ i ] [ j ] :,if self . C [ i ] [ j ] < minval :,0.47396047516965045,69.62269175492561,0.2857142857142857
"def includes_tools_for_display_in_tool_panel(self):<tab>if self.includes_tools:<tab><tab>tool_dicts = self.metadata[""tools""]<tab><tab>for tool_dict in tool_dicts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,"if tool_dict . get ( ""add_to_tool_panel"" , True ) :","if tool_dict . get ( ""display_in_tool_panel"" ) :",0.23202903606635522,57.0062318840941,0.7333333333333334
"def commit(self, notify=False):<tab>if self.editing:<tab><tab>text = self._text<tab><tab>if text:<tab><tab><tab>try:<tab><tab><tab><tab>value = self.type(text)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>return<tab><tab><tab>value = self.clamp_value(value)<tab><tab>else:<tab><tab><tab>value = self.empty<tab><tab><tab>if value is NotImplemented:<tab><tab><tab><tab>return<tab><tab>self.value = value<tab><tab>self.insertion_point = None<tab><tab><IF-STMT><tab><tab><tab>self.change_text(unicode(value))<tab><tab>else:<tab><tab><tab>self._text = unicode(value)<tab><tab>self.editing = False<tab>else:<tab><tab>self.insertion_point = None",1,if notify :,if notify :,0.5311706625951745,1e-10,1.0
"def GeneratePageMetatadata(self, task):<tab>address_space = self.session.GetParameter(""default_address_space"")<tab>for vma in task.mm.mmap.walk_list(""vm_next""):<tab><tab>start = vma.vm_start<tab><tab>end = vma.vm_end<tab><tab># Skip the entire region.<tab><tab>if end < self.plugin_args.start:<tab><tab><tab>continue<tab><tab># Done.<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>for vaddr in utils.xrange(start, end, 0x1000):<tab><tab><tab>if self.plugin_args.start <= vaddr <= self.plugin_args.end:<tab><tab><tab><tab>yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",0,if start > self . plugin_args . end :,if start >= self . plugin_args . end :,0.5818820875411704,73.48889200874659,1.0
"def _check_for_duplicate_host_entries(self, task_entries):<tab>non_host_statuses = (<tab><tab>models.HostQueueEntry.Status.PARSING,<tab><tab>models.HostQueueEntry.Status.ARCHIVING,<tab>)<tab>for task_entry in task_entries:<tab><tab>using_host = (<tab><tab><tab>task_entry.host is not None and task_entry.status not in non_host_statuses<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._assert_host_has_no_agent(task_entry)",1,if using_host :,if using_host :,0.5311706625951745,1e-10,1.0
"def get_biggest_wall_time(jsons):<tab>lowest_wall = None<tab>for j in jsons:<tab><tab><IF-STMT><tab><tab><tab>lowest_wall = j[""wall_time""]<tab><tab>if lowest_wall < j[""wall_time""]:<tab><tab><tab>lowest_wall = j[""wall_time""]<tab>return lowest_wall",1,if lowest_wall is None :,if lowest_wall is None :,0.75,100.00000000000004,1.0
"def log_change_report(self, old_value, new_value, include_details=False):<tab>from octoprint.util import map_boolean<tab>with self._check_mutex:<tab><tab>self._logger.info(<tab><tab><tab>""Connectivity changed from {} to {}"".format(<tab><tab><tab><tab>map_boolean(old_value, ""online"", ""offline""),<tab><tab><tab><tab>map_boolean(new_value, ""online"", ""offline""),<tab><tab><tab>)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.log_details()",1,if include_details :,if include_details :,0.5311706625951745,1e-10,1.0
"def _include_block(self, value, context=None):<tab>if hasattr(value, ""render_as_block""):<tab><tab><IF-STMT><tab><tab><tab>new_context = context.get_all()<tab><tab>else:<tab><tab><tab>new_context = {}<tab><tab>return jinja2.Markup(value.render_as_block(context=new_context))<tab>return jinja2.Markup(value)",1,if context :,if context :,0.5311706625951745,1e-10,1.0
"def __lt__(self, other):<tab># 0: clock 1: timestamp 3: process id<tab>try:<tab><tab>A, B = self[0], other[0]<tab><tab># uses logical clock value first<tab><tab>if A and B:  # use logical clock if available<tab><tab><tab><IF-STMT>  # equal clocks use lower process id<tab><tab><tab><tab>return self[2] < other[2]<tab><tab><tab>return A < B<tab><tab>return self[1] < other[1]  # ... or use timestamp<tab>except IndexError:<tab><tab>return NotImplemented",1,if A == B :,if A == B :,0.75,100.00000000000004,1.0
"def _get_port():<tab>while True:<tab><tab>port = 20000 + random.randint(1, 9999)<tab><tab>for i in range(5):<tab><tab><tab>sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<tab><tab><tab>result = sock.connect_ex((""127.0.0.1"", port))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>return port",0,if result == 0 :,if not result :,0.03944961859844226,12.750736437345598,0.4
"def fetch_all(self, api_client, fetchstatuslogger, q, targets):<tab>self.fetchstatuslogger = fetchstatuslogger<tab>if targets != None:<tab><tab># Ensure targets is a tuple<tab><tab>if type(targets) != list and type(targets) != tuple:<tab><tab><tab>targets = tuple(<tab><tab><tab><tab>targets,<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>targets = tuple(targets)<tab>for target in targets:<tab><tab>self._fetch_targets(api_client, q, target)",0,elif type ( targets ) != tuple :,elif type ( targets ) != list and type ( targets ) != tuple :,0.49396832741031305,47.9676449968321,0.4444444444444445
"def migrate_node_facts(facts):<tab>""""""Migrate facts from various roles into node""""""<tab>params = {<tab><tab>""common"": (""dns_ip""),<tab>}<tab>if ""node"" not in facts:<tab><tab>facts[""node""] = {}<tab># pylint: disable=consider-iterating-dictionary<tab>for role in params.keys():<tab><tab><IF-STMT><tab><tab><tab>for param in params[role]:<tab><tab><tab><tab>if param in facts[role]:<tab><tab><tab><tab><tab>facts[""node""][param] = facts[role].pop(param)<tab>return facts",1,if role in facts :,if role in facts :,0.75,100.00000000000004,1.0
"def build_dimension_param(self, dimension, params):<tab>prefix = ""Dimensions.member""<tab>i = 0<tab>for dim_name in dimension:<tab><tab>dim_value = dimension[dim_name]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(dim_value, six.string_types):<tab><tab><tab><tab>dim_value = [dim_value]<tab><tab><tab>for value in dim_value:<tab><tab><tab><tab>params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name<tab><tab><tab><tab>params[""%s.%d.Value"" % (prefix, i + 1)] = value<tab><tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>params[""%s.%d.Name"" % (prefix, i + 1)] = dim_name<tab><tab><tab>i += 1",0,if dim_value :,if dim_value is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def add_if_unique(self, issuer, use, keys):<tab>if use in self.issuer_keys[issuer] and self.issuer_keys[issuer][use]:<tab><tab>for typ, key in keys:<tab><tab><tab>flag = 1<tab><tab><tab>for _typ, _key in self.issuer_keys[issuer][use]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>flag = 0<tab><tab><tab><tab><tab>break<tab><tab><tab>if flag:<tab><tab><tab><tab>self.issuer_keys[issuer][use].append((typ, key))<tab>else:<tab><tab>self.issuer_keys[issuer][use] = keys",0,if _typ == typ and key is _key :,if typ == key :,0.01849683607118619,14.628187563941417,0.4666666666666666
"def run(self):<tab>while True:<tab><tab>message = self.in_queue.get()<tab><tab><IF-STMT><tab><tab><tab>self.reset()<tab><tab>elif message == EXIT:<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>index, transaction = message<tab><tab><tab>self.results_queue.put((index, self.validate(transaction)))",0,if message == RESET :,if message == SUCCESS :,0.39477865547525276,53.7284965911771,0.6
"def __run(self):<tab>threads = self.parameters()[""threads""].getTypedValue()<tab>with IECore.tbb_global_control(<tab><tab>IECore.tbb_global_control.parameter.max_allowed_parallelism,<tab><tab>IECore.hardwareConcurrency() if threads == 0 else threads,<tab>):<tab><tab>self._executeStartupFiles(self.root().getName())<tab><tab># Append DEBUG message with process information to all messages<tab><tab>defaultMessageHandler = IECore.MessageHandler.getDefaultHandler()<tab><tab><IF-STMT><tab><tab><tab>IECore.MessageHandler.setDefaultHandler(<tab><tab><tab><tab>Gaffer.ProcessMessageHandler(defaultMessageHandler)<tab><tab><tab>)<tab><tab>return self._run(self.parameters().getValidatedValue())",0,"if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :",if defaultMessageHandler is not None :,0.013607149290050547,4.988641679706251,0.21212121212121213
"def adjust_uri(self, uri, relativeto):<tab>""""""Adjust the given ``uri`` based on the given relative URI.""""""<tab>key = (uri, relativeto)<tab>if key in self._uri_cache:<tab><tab>return self._uri_cache[key]<tab>if uri[0] != ""/"":<tab><tab><IF-STMT><tab><tab><tab>v = self._uri_cache[key] = posixpath.join(<tab><tab><tab><tab>posixpath.dirname(relativeto), uri<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>v = self._uri_cache[key] = ""/"" + uri<tab>else:<tab><tab>v = self._uri_cache[key] = uri<tab>return v",0,if relativeto is not None :,"if relativeto . startswith ( ""/"" ) :",0.04223373009149452,9.287528999566801,0.39285714285714285
"def decoder(s):<tab>r = []<tab>decode = []<tab>for c in s:<tab><tab><IF-STMT><tab><tab><tab>decode.append(""&"")<tab><tab>elif c == ""-"" and decode:<tab><tab><tab>if len(decode) == 1:<tab><tab><tab><tab>r.append(""&"")<tab><tab><tab>else:<tab><tab><tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab><tab><tab>decode = []<tab><tab>elif decode:<tab><tab><tab>decode.append(c)<tab><tab>else:<tab><tab><tab>r.append(c)<tab>if decode:<tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab>bin_str = """".join(r)<tab>return (bin_str, len(s))",0,"if c == ""&"" and not decode :","if c == ""+"" and not decode :",0.5014622369176811,70.16879391277372,1.0
"def _process_file(self, content):<tab>args = []<tab>for line in content.splitlines():<tab><tab>line = line.strip()<tab><tab>if line.startswith(""-""):<tab><tab><tab>args.extend(self._split_option(line))<tab><tab><IF-STMT><tab><tab><tab>args.append(line)<tab>return args",0,"elif line and not line . startswith ( ""#"" ) :","elif not line . startswith ( ""#"" ) :",0.5714745451264986,76.26264731696685,0.3055555555555556
"def _method_events_callback(self, values):<tab>try:<tab><tab>previous_echoed = (<tab><tab><tab>values[""child_result_list""][-1].decode().split(""\n"")[-2].strip()<tab><tab>)<tab><tab>if previous_echoed.endswith(""foo1""):<tab><tab><tab>return ""echo foo2\n""<tab><tab>elif previous_echoed.endswith(""foo2""):<tab><tab><tab>return ""echo foo3\n""<tab><tab><IF-STMT><tab><tab><tab>return ""exit\n""<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected output {0!r}"".format(previous_echoed))<tab>except IndexError:<tab><tab>return ""echo foo1\n""",0,"elif previous_echoed . endswith ( ""foo3"" ) :","elif previous_echoed . endswith ( ""exit"" ) :",0.5473017787506802,73.48889200874659,1.0
"def __delete_hook(self, rpc):<tab>try:<tab><tab>rpc.check_success()<tab>except apiproxy_errors.Error:<tab><tab>return None<tab>result = []<tab>for status in rpc.response.delete_status_list():<tab><tab><IF-STMT><tab><tab><tab>result.append(DELETE_SUCCESSFUL)<tab><tab>elif status == MemcacheDeleteResponse.NOT_FOUND:<tab><tab><tab>result.append(DELETE_ITEM_MISSING)<tab><tab>else:<tab><tab><tab>result.append(DELETE_NETWORK_FAILURE)<tab>return result",0,if status == MemcacheDeleteResponse . DELETED :,if status == MemcacheDeleteResponse . SUCCESS :,0.574113272471593,70.71067811865478,0.6666666666666666
"def __createRandom(plug):<tab>node = plug.node()<tab>parentNode = node.ancestor(Gaffer.Node)<tab>with Gaffer.UndoScope(node.scriptNode()):<tab><tab>randomNode = Gaffer.Random()<tab><tab>parentNode.addChild(randomNode)<tab><tab><IF-STMT><tab><tab><tab>plug.setInput(randomNode[""outFloat""])<tab><tab>elif isinstance(plug, Gaffer.Color3fPlug):<tab><tab><tab>plug.setInput(randomNode[""outColor""])<tab>GafferUI.NodeEditor.acquire(randomNode)",0,"if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) :","if isinstance ( plug , Gaffer . Float3fPlug ) :",0.16210707792260573,30.861946272099846,0.5708333333333333
"def escapeentities(self, line):<tab>""Escape all Unicode characters to HTML entities.""<tab>result = """"<tab>pos = TextPosition(line)<tab>while not pos.finished():<tab><tab>if ord(pos.current()) > 128:<tab><tab><tab>codepoint = hex(ord(pos.current()))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>codepoint = hex(ord(pos.next()) + 0xF800)<tab><tab><tab>result += ""&#"" + codepoint[1:] + "";""<tab><tab>else:<tab><tab><tab>result += pos.current()<tab><tab>pos.skipcurrent()<tab>return result",0,"if codepoint == ""0xd835"" :",elif pos . next ( ) < 0xF800 :,0.01759156453926403,4.767707020457095,0.11904761904761905
def get_and_set_all_aliases(self):<tab>all_aliases = []<tab>for page in self.pages:<tab><tab><IF-STMT><tab><tab><tab>all_aliases.extend(page.relations.aliases_norm)<tab><tab>if page.relations.aliases is not None:<tab><tab><tab>all_aliases.extend(page.relations.aliases)<tab>return set(all_aliases),1,if page . relations . aliases_norm is not None :,if page . relations . aliases_norm is not None :,0.75,100.00000000000004,1.0
"def _list_cases(suite):<tab>for test in suite:<tab><tab><IF-STMT><tab><tab><tab>_list_cases(test)<tab><tab>elif isinstance(test, unittest.TestCase):<tab><tab><tab>if support.match_test(test):<tab><tab><tab><tab>print(test.id())",1,"if isinstance ( test , unittest . TestSuite ) :","if isinstance ( test , unittest . TestSuite ) :",0.75,100.00000000000004,1.0
"def get_next_requests(self, max_n_requests, **kwargs):<tab>next_pages = []<tab>partitions = set(kwargs.pop(""partitions"", []))<tab>for partition_id in range(0, self.queue_partitions):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>results = self.queue.get_next_requests(max_n_requests, partition_id)<tab><tab>next_pages.extend(results)<tab><tab>self.logger.debug(<tab><tab><tab>""Got %d requests for partition id %d"", len(results), partition_id<tab><tab>)<tab>return next_pages",1,if partition_id not in partitions :,if partition_id not in partitions :,0.75,100.00000000000004,1.0
"def __iter__(self):<tab>if (self.query is not None) and sqlite.is_read_only_query(self.query):<tab><tab>cur = self.connection.cursor()<tab><tab>results = cur.execute(self.query)<tab><tab><IF-STMT><tab><tab><tab>yield [col[0] for col in cur.description]<tab><tab>for i, row in enumerate(results):<tab><tab><tab>if i >= self.limit:<tab><tab><tab><tab>break<tab><tab><tab>yield [val for val in row]<tab>else:<tab><tab>yield",0,if self . headers :,if cur . description is not None :,0.1113347933040206,7.267884212102741,0.1746031746031746
"def rollback(self):<tab>for operation, values in self.current_transaction_state[::-1]:<tab><tab>if operation == ""insert"":<tab><tab><tab>values.remove()<tab><tab><IF-STMT><tab><tab><tab>old_value, new_value = values<tab><tab><tab>if new_value.full_filename != old_value.full_filename:<tab><tab><tab><tab>os.unlink(new_value.full_filename)<tab><tab><tab>old_value.write()<tab>self._post_xact_cleanup()",0,"elif operation == ""update"" :","elif operation == ""replace"" :",0.6428720214849399,59.4603557501361,1.0
"def index(self, value):<tab>if self._growing:<tab><tab>if self._start <= value < self._stop:<tab><tab><tab>q, r = divmod(value - self._start, self._step)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(q)<tab>else:<tab><tab>if self._start >= value > self._stop:<tab><tab><tab>q, r = divmod(self._start - value, -self._step)<tab><tab><tab>if r == self._zero:<tab><tab><tab><tab>return int(q)<tab>raise ValueError(""{} is not in numeric range"".format(value))",1,if r == self . _zero :,if r == self . _zero :,0.75,100.00000000000004,1.0
"def validate_name_and_description(body, check_length=True):<tab>for attribute in [""name"", ""description"", ""display_name"", ""display_description""]:<tab><tab>value = body.get(attribute)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, six.string_types):<tab><tab><tab><tab>body[attribute] = value.strip()<tab><tab><tab>if check_length:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>utils.check_string_length(<tab><tab><tab><tab><tab><tab>body[attribute], attribute, min_length=0, max_length=255<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except exception.InvalidInput as error:<tab><tab><tab><tab><tab>raise webob.exc.HTTPBadRequest(explanation=error.msg)",1,if value is not None :,if value is not None :,0.75,100.00000000000004,1.0
"def printWiki():<tab>firstHeading = False<tab>for m in protocol:<tab><tab>if m[0] == """":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output(""|}"")<tab><tab><tab>__printWikiHeader(m[1], m[2])<tab><tab><tab>firstHeading = True<tab><tab>else:<tab><tab><tab>output(""|-"")<tab><tab><tab>output(<tab><tab><tab><tab>'| <span style=""white-space:nowrap;""><tt>'<tab><tab><tab><tab>+ m[0]<tab><tab><tab><tab>+ ""</tt></span> || || ""<tab><tab><tab><tab>+ m[1]<tab><tab><tab>)<tab>output(""|}"")",1,if firstHeading :,if firstHeading :,0.5311706625951745,1e-10,1.0
"def _get_platforms(data):<tab>platform_list = []<tab>for item in data:<tab><tab>if item.startswith(""PlatformEdit.html?""):<tab><tab><tab>parameter_list = item.split(""PlatformEdit.html?"", 1)[1].split(""&"")<tab><tab><tab>for parameter in parameter_list:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>platform_list.append(parameter.split(""="")[1])<tab>return platform_list",0,"if parameter . startswith ( ""platformName"" ) :","if parameter . startswith ( ""platform"" ) :",0.5490406812970063,65.80370064762461,1.0
"def find_scintilla_constants(f):<tab>lexers = []<tab>states = []<tab>for name in f.order:<tab><tab>v = f.features[name]<tab><tab>if v[""Category""] != ""Deprecated"":<tab><tab><tab>if v[""FeatureType""] == ""val"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>states.append((name, v[""Value""]))<tab><tab><tab><tab>elif name.startswith(""SCLEX_""):<tab><tab><tab><tab><tab>lexers.append((name, v[""Value""]))<tab>return (lexers, states)",0,"if name . startswith ( ""SCE_"" ) :","if name . startswith ( ""SCINTilla_"" ) :",0.5490406812970063,70.16879391277372,1.0
"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab>if isinstance(definition, ast.OperationDefinition):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab>if operation:<tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab>elif definition.name and definition.name.value == operation_name:<tab><tab><tab><tab>return definition<tab>return operation",0,if not operation_name :,if operation_name is None :,0.045150550804307965,27.77619034011791,0.36
"def _insertNewItemAtParent(self, targetIndex):<tab>if not self.isContainer(targetIndex):<tab><tab>return<tab>elif not self.isContainerOpen(targetIndex):<tab><tab>uri = self._rows[targetIndex].uri<tab><tab>modelNode = self.getNodeForURI(uri)<tab><tab><IF-STMT><tab><tab><tab>modelNode.markForRefreshing()<tab><tab>return<tab>self.refreshView(targetIndex)",0,if modelNode :,if nodeType is not None :,0.048107739435423735,1e-10,0.19999999999999998
"def _get_trace(self, model, guide, args, kwargs):<tab>model_trace, guide_trace = super()._get_trace(model, guide, args, kwargs)<tab># Mark all sample sites with require_backward to gather enumerated<tab># sites and adjust cond_indep_stack of all sample sites.<tab>for node in model_trace.nodes.values():<tab><tab><IF-STMT><tab><tab><tab>log_prob = node[""packed""][""unscaled_log_prob""]<tab><tab><tab>require_backward(log_prob)<tab>self._saved_state = model, model_trace, guide_trace, args, kwargs<tab>return model_trace, guide_trace",0,"if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :","if ""packed"" in node and ""unscaled_log_prob"" in node :",0.26095189820777676,2.857442839101438,0.3235294117647059
"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>from .datastructures import iter_multi_items<tab>iterable = iter_multi_items(obj)<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, value in iterable:<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab>if not isinstance(key, bytes):<tab><tab><tab>key = text_type(key).encode(charset)<tab><tab><IF-STMT><tab><tab><tab>value = text_type(value).encode(charset)<tab><tab>yield _fast_url_quote_plus(key) + ""="" + _fast_url_quote_plus(value)",1,"if not isinstance ( value , bytes ) :","if not isinstance ( value , bytes ) :",0.75,100.00000000000004,1.0
"def handle_parse_result(self, ctx, opts, args):<tab>with augment_usage_errors(ctx, param=self):<tab><tab>value = self.consume_value(ctx, opts)<tab><tab>try:<tab><tab><tab>value = self.full_process_value(ctx, value)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>value = None<tab><tab>if self.callback is not None:<tab><tab><tab>try:<tab><tab><tab><tab>value = invoke_param_callback(self.callback, ctx, self, value)<tab><tab><tab>except Exception:<tab><tab><tab><tab>if not ctx.resilient_parsing:<tab><tab><tab><tab><tab>raise<tab>if self.expose_value:<tab><tab>ctx.params[self.name] = value<tab>return value, args",1,if not ctx . resilient_parsing :,if not ctx . resilient_parsing :,0.75,100.00000000000004,1.0
"def word_pattern(pattern, str):<tab>dict = {}<tab>set_value = set()<tab>list_str = str.split()<tab>if len(list_str) != len(pattern):<tab><tab>return False<tab>for i in range(len(pattern)):<tab><tab>if pattern[i] not in dict:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>dict[pattern[i]] = list_str[i]<tab><tab><tab>set_value.add(list_str[i])<tab><tab>else:<tab><tab><tab>if dict[pattern[i]] != list_str[i]:<tab><tab><tab><tab>return False<tab>return True",0,if list_str [ i ] in set_value :,if set_value . add ( list_str [ i ] ) :,0.2513688853154318,43.33207865423753,0.4
"def create(self, path, wipe=False):<tab># type: (Text, bool) -> bool<tab>_path = self.validatepath(path)<tab>with ftp_errors(self, path):<tab><tab><IF-STMT><tab><tab><tab>empty_file = io.BytesIO()<tab><tab><tab>self.ftp.storbinary(<tab><tab><tab><tab>str(""STOR "") + _encode(_path, self.ftp.encoding), empty_file<tab><tab><tab>)<tab><tab><tab>return True<tab>return False",0,if wipe or not self . isfile ( path ) :,if wipe :,0.04501111429722153,1e-10,0.3269230769230769
"def build_output_for_item(self, item):<tab>output = []<tab>for field in self.fields:<tab><tab>values = self._get_item(item, field)<tab><tab><IF-STMT><tab><tab><tab>values = [values]<tab><tab>for value in values:<tab><tab><tab>if value:<tab><tab><tab><tab>output.append(self.build_output_for_single_value(value))<tab>return """".join(output)",1,"if not isinstance ( values , list ) :","if not isinstance ( values , list ) :",0.75,100.00000000000004,1.0
"def get_resource_public_actions(resource_class):<tab>resource_class_members = inspect.getmembers(resource_class)<tab>resource_methods = {}<tab>for name, member in resource_class_members:<tab><tab>if not name.startswith(""_""):<tab><tab><tab>if not name[0].isupper():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if is_resource_action(member):<tab><tab><tab><tab><tab><tab>resource_methods[name] = member<tab>return resource_methods",0,"if not name . startswith ( ""wait_until"" ) :",if inspect . isclass ( member ) :,0.03313893421568771,7.433761660133445,0.25
"def get_command(cls):<tab>ifconfig_cmd = ""ifconfig""<tab>for path in [""/sbin"", ""/usr/sbin"", ""/bin"", ""/usr/bin""]:<tab><tab><IF-STMT><tab><tab><tab>ifconfig_cmd = os.path.join(path, ifconfig_cmd)<tab><tab><tab>break<tab>ifconfig_cmd = ifconfig_cmd + "" -a""<tab>return ifconfig_cmd",0,"if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :",if os . path . exists ( path ) :,0.3326831377858849,24.98609756475043,0.6577777777777778
"def main():<tab>base_dir = os.path.join(os.path.split(__file__)[0], "".."", "".."")<tab>for path in PATHS:<tab><tab>path = os.path.join(base_dir, path)<tab><tab>for root, _, files in os.walk(path):<tab><tab><tab>for file in files:<tab><tab><tab><tab>extension = os.path.splitext(file)[1]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>path = os.path.join(root, file)<tab><tab><tab><tab><tab>validate_header(path)",0,if extension in EXTENSIONS :,"if extension == "".py"" :",0.06497877230811641,10.552670315936318,0.5
"def auth_login(request):<tab>form = RegistrationForm(request.POST or None)<tab>if form.is_valid():<tab><tab>authed_user = authenticate(<tab><tab><tab>username=form.cleaned_data[""username""],<tab><tab><tab>password=form.cleaned_data[""password""],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>login(request, authed_user)<tab><tab><tab>return HttpResponse(""Success"")<tab>raise Http404",1,if authed_user :,if authed_user :,0.5311706625951745,1e-10,1.0
"def set(self, _key, _new_login=True):<tab>with self.lock:<tab><tab>user = self.users.get(current_user.id, None)<tab><tab>if user is None:<tab><tab><tab>self.users[current_user.id] = dict(session_count=1, key=_key)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>user[""session_count""] += 1<tab><tab><tab>user[""key""] = _key",1,if _new_login :,if _new_login :,0.5311706625951745,1e-10,1.0
"def fetch(self, fingerprints):<tab>to_fetch = [f for f in fingerprints if f not in self._cache]<tab>self._logger.debug(""cache size %s"" % len(self._cache))<tab>self._logger.debug(""to fetch %d from %d"" % (len(to_fetch), len(fingerprints)))<tab>[self._redis_pipeline.hgetall(key) for key in to_fetch]<tab>responses = self._redis_pipeline.execute()<tab>for index, key in enumerate(to_fetch):<tab><tab>response = responses[index]<tab><tab><IF-STMT><tab><tab><tab>self._cache[key] = response[FIELD_STATE]<tab><tab>else:<tab><tab><tab>self._cache[key] = self.NOT_CRAWLED",0,if len ( response ) > 0 and FIELD_STATE in response :,if response . get ( RESPONSE_STATE ) :,0.04093961060689246,7.69443236290179,0.2142857142857143
"def _append_to_io_queue(self, data, stream_name):<tab># Make sure ANSI CSI codes and object links are stored as separate events<tab># TODO: try to complete previously submitted incomplete code<tab>parts = re.split(OUTPUT_SPLIT_REGEX, data)<tab>for part in parts:<tab><tab>if part:  # split may produce empty string in the beginning or start<tab><tab><tab># split the data so that very long lines separated<tab><tab><tab>for block in re.split(<tab><tab><tab><tab>""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part<tab><tab><tab>):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._queued_io_events.append((block, stream_name))",1,if block :,if block :,0.5311706625951745,1e-10,1.0
"def find_file_at_path_with_indexes(self, path, url):<tab>if url.endswith(""/""):<tab><tab>path = os.path.join(path, self.index_file)<tab><tab>return self.get_static_file(path, url)<tab>elif url.endswith(""/"" + self.index_file):<tab><tab><IF-STMT><tab><tab><tab>return self.redirect(url, url[: -len(self.index_file)])<tab>else:<tab><tab>try:<tab><tab><tab>return self.get_static_file(path, url)<tab><tab>except IsDirectoryError:<tab><tab><tab>if os.path.isfile(os.path.join(path, self.index_file)):<tab><tab><tab><tab>return self.redirect(url, url + ""/"")<tab>raise MissingFileError(path)",0,if os . path . isfile ( path ) :,if url . endswith ( self . index_file ) :,0.08002398993369181,8.91376552139813,0.23863636363636365
"def module_list(target, fast):<tab>""""""Find the list of modules to be compiled""""""<tab>modules = []<tab>native = native_modules(target)<tab>basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"")<tab>for name in os.listdir(basedir):<tab><tab>module_name, ext = os.path.splitext(name)<tab><tab>if ext == "".py"" or ext == """" and os.path.isdir(os.path.join(basedir, name)):<tab><tab><tab>if module_name not in IGNORE_MODULES and module_name not in native:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>modules.append(module_name)<tab>return set(modules)",0,if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) :,if fast and module_name not in IGNORE_MODULES :,0.06630091485200443,29.252268260558086,0.5
"def housenumber(self):<tab>if self.address:<tab><tab>expression = r""\d+""<tab><tab>pattern = re.compile(expression)<tab><tab>match = pattern.search(self.address)<tab><tab><IF-STMT><tab><tab><tab>return int(match.group(0))",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def get_pip_version(import_path=BASE_IMPORT_PATH):<tab>try:<tab><tab>pip = importlib.import_module(import_path)<tab>except ImportError:<tab><tab><IF-STMT><tab><tab><tab>return get_pip_version(import_path=""pip"")<tab><tab>else:<tab><tab><tab>import subprocess<tab><tab><tab>version = subprocess.check_output([""pip"", ""--version""])<tab><tab><tab>if version:<tab><tab><tab><tab>version = version.decode(""utf-8"").split()[1]<tab><tab><tab><tab>return version<tab><tab><tab>return ""0.0.0""<tab>version = getattr(pip, ""__version__"", None)<tab>return version",0,"if import_path != ""pip"" :","if sys . platform == ""win32"" :",0.027969854500399755,12.549310621989482,0.45
"def __animate_progress(self):<tab>""""""Change the status message, mostly used to animate progress.""""""<tab>while True:<tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab>with self.__progress_lock:<tab><tab><tab>if not self.__progress_status:<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__progress_status.update_progress(self.__current_operation_name)<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY<tab><tab><tab>else:<tab><tab><tab><tab>self.__progress_status.show_as_ready()<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab># Allow some time for progress status to be updated.<tab><tab>time.sleep(sleep_time)",0,elif self . __show_animation :,elif self . __current_operation_name :,0.39287202148494,38.16330911371339,1.0
"def range_key_names(self):<tab>keys = [self.range_key_attr]<tab>for index in self.global_indexes:<tab><tab>range_key = None<tab><tab>for key in index.schema:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>range_key = keys.append(key[""AttributeName""])<tab><tab>keys.append(range_key)<tab>return keys",0,"if key [ ""KeyType"" ] == ""RANGE"" :","if key [ ""Type"" ] == ""RangeKey"" :",0.34166808520089226,52.664038784792666,1.0
"def run(self):<tab>dist = self.distribution<tab>commands = dist.command_options.keys()<tab>settings = {}<tab>for cmd in commands:<tab><tab>if cmd == ""saveopts"":<tab><tab><tab>continue  # don't save our own options!<tab><tab>for opt, (src, val) in dist.get_option_dict(cmd).items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>settings.setdefault(cmd, {})[opt] = val<tab>edit_config(self.filename, settings, self.dry_run)",0,"if src == ""command line"" :","if src == ""default"" :",0.36529782719544424,52.47357977607325,1.0
"def parse_move(self, node):<tab>old, new = """", """"<tab>for child in node:<tab><tab>tag, text = child.tag, child.text<tab><tab>text = text.strip() if text else None<tab><tab>if tag == ""Old"" and text:<tab><tab><tab>old = text<tab><tab><IF-STMT><tab><tab><tab>new = text<tab>return Move(old, new)",1,"elif tag == ""New"" and text :","elif tag == ""New"" and text :",1.0,100.00000000000004,1.0
"def __codeanalysis_settings_changed(self, current_finfo):<tab>if self.data:<tab><tab>run_pyflakes, run_pep8 = self.pyflakes_enabled, self.pep8_enabled<tab><tab>for finfo in self.data:<tab><tab><tab>self.__update_editor_margins(finfo.editor)<tab><tab><tab>finfo.cleanup_analysis_results()<tab><tab><tab>if (run_pyflakes or run_pep8) and current_finfo is not None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>finfo.run_code_analysis(run_pyflakes, run_pep8)",0,if current_finfo is not finfo :,if current_finfo is finfo :,0.23319028329115196,61.29752413741059,0.5599999999999999
"def tchg(var, width):<tab>""Convert time string to given length""<tab>ret = ""%2dh%02d"" % (var / 60, var % 60)<tab><IF-STMT><tab><tab>ret = ""%2dh"" % (var / 60)<tab><tab>if len(ret) > width:<tab><tab><tab>ret = ""%2dd"" % (var / 60 / 24)<tab><tab><tab>if len(ret) > width:<tab><tab><tab><tab>ret = ""%2dw"" % (var / 60 / 24 / 7)<tab>return ret",1,if len ( ret ) > width :,if len ( ret ) > width :,0.75,100.00000000000004,1.0
"def spider_log_activity(self, messages):<tab>for i in range(0, messages):<tab><tab><IF-STMT><tab><tab><tab>self.sp_sl_p.send(<tab><tab><tab><tab>sha1(str(randint(1, 1000))),<tab><tab><tab><tab>b""http://helloworld.com/way/to/the/sun/"" + b""0"",<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.sp_sl_p.send(<tab><tab><tab><tab>sha1(str(randint(1, 1000))), b""http://way.to.the.sun"" + b""0""<tab><tab><tab>)<tab>self.sp_sl_p.flush()",0,if i % 2 == 0 :,if i == 0 :,0.1717001800191671,43.29820146406896,0.5714285714285714
"def decode_serial(self, offset):<tab>serialnum = (<tab><tab>(self.cache[offset + 3] << 24)<tab><tab>+ (self.cache[offset + 2] << 16)<tab><tab>+ (self.cache[offset + 1] << 8)<tab><tab>+ self.cache[offset]<tab>)<tab>serialstr = """"<tab>is_alnum = True<tab>for i in range(4):<tab><tab><IF-STMT><tab><tab><tab>is_alnum = False<tab><tab><tab>break<tab><tab>serialstr += chr(self.cache[offset + 3 - i])<tab>serial = serialstr if is_alnum else str(serialnum)<tab>self.ann_field(offset, offset + 3, ""Serial "" + serial)",0,if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,if self . cache [ offset + 3 - i ] == 0 :,0.3490473331549671,46.968008400977354,0.17424242424242423
def gettext(rv):<tab>for child in rv.childNodes:<tab><tab>if child.nodeType == child.TEXT_NODE:<tab><tab><tab>yield child.nodeValue<tab><tab><IF-STMT><tab><tab><tab>for item in gettext(child):<tab><tab><tab><tab>yield item,0,if child . nodeType == child . ELEMENT_NODE :,elif child . nodeType == child . ELEMENT_NODE :,0.7252127708701797,90.36020036098445,0.6
"def determine_block_hints(self, text):<tab>hints = """"<tab>if text:<tab><tab>if text[0] in "" \n\x85\u2028\u2029"":<tab><tab><tab>hints += str(self.best_indent)<tab><tab>if text[-1] not in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""-""<tab><tab><IF-STMT><tab><tab><tab>hints += ""+""<tab>return hints",0,"elif len ( text ) == 1 or text [ - 2 ] in ""\n\x85\u2028\u2029"" :","if text [ - 2 ] not in ""\n\x85\u2028\u2029"" :",0.14863516305743762,54.74154767270124,0.08421052631578947
"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab>if arg is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if return_type is str:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab>if return_type is bytes:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type",1,"if isinstance ( arg , bytes ) :","if isinstance ( arg , bytes ) :",0.75,100.00000000000004,1.0
"def as_iconbitmap(cls, rkey):<tab>""""""Get image path for use in iconbitmap property""""""<tab>img = None<tab>if rkey in cls._stock:<tab><tab>data = cls._stock[rkey]<tab><tab><IF-STMT><tab><tab><tab>fpath = data[""filename""]<tab><tab><tab>fname = os.path.basename(fpath)<tab><tab><tab>name, file_ext = os.path.splitext(fname)<tab><tab><tab>file_ext = str(file_ext).lower()<tab><tab><tab>if file_ext in TK_BITMAP_FORMATS:<tab><tab><tab><tab>img = BITMAP_TEMPLATE.format(fpath)<tab>return img",0,"if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :","if ""filename"" in data :",0.007809362672887758,1.0453215315463866,0.391304347826087
"def anonymize_ip(ip):<tab>if ip:<tab><tab>match = RE_FIRST_THREE_OCTETS_OF_IP.findall(str(ip))<tab><tab><IF-STMT><tab><tab><tab>return ""%s%s"" % (match[0][0], ""0"")<tab>return """"",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def serialize_tail(self):<tab>msg = bytearray()<tab>for v in self.info:<tab><tab><IF-STMT><tab><tab><tab>value = v[""value""].encode(""utf-8"")<tab><tab>elif v[""type""] == BMP_TERM_TYPE_REASON:<tab><tab><tab>value = struct.pack(""!H"", v[""value""])<tab><tab>v[""len""] = len(value)<tab><tab>msg += struct.pack(self._TLV_PACK_STR, v[""type""], v[""len""])<tab><tab>msg += value<tab>return msg",1,"if v [ ""type"" ] == BMP_TERM_TYPE_STRING :","if v [ ""type"" ] == BMP_TERM_TYPE_STRING :",0.75,100.00000000000004,1.0
"def get_django_comment(text: str, i: int) -> str:<tab>end = i + 4<tab>unclosed_end = 0<tab>while end <= len(text):<tab><tab><IF-STMT><tab><tab><tab>return text[i:end]<tab><tab>if not unclosed_end and text[end] == ""<"":<tab><tab><tab>unclosed_end = end<tab><tab>end += 1<tab>raise TokenizationException(""Unclosed comment"", text[i:unclosed_end])",0,"if text [ end - 2 : end ] == ""#}"" :","if text [ end ] == "">"" :",0.15568422049486322,39.601116772341584,0.7083333333333333
"def ComboBoxDroppedHeightTest(windows):<tab>""Check if each combobox height is the same as the reference""<tab>bugs = []<tab>for win in windows:<tab><tab>if not win.ref:<tab><tab><tab>continue<tab><tab>if win.Class() != ""ComboBox"" or win.ref.Class() != ""ComboBox"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>bugs.append(<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>win,<tab><tab><tab><tab><tab>],<tab><tab><tab><tab><tab>{},<tab><tab><tab><tab><tab>testname,<tab><tab><tab><tab><tab>0,<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return bugs",0,if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) :,if win . droppedHeight ( ) != win . ref . droppedHeight ( ) :,0.49008944245758557,37.168692129881705,0.3482142857142857
"def testBadModeArgument(self):<tab># verify that we get a sensible error message for bad mode argument<tab>bad_mode = ""qwerty""<tab>try:<tab><tab>f = self.open(TESTFN, bad_mode)<tab>except ValueError as msg:<tab><tab><IF-STMT><tab><tab><tab>s = str(msg)<tab><tab><tab>if TESTFN in s or bad_mode not in s:<tab><tab><tab><tab>self.fail(""bad error message for invalid mode: %s"" % s)<tab><tab># if msg.args[0] == 0, we're probably on Windows where there may be<tab><tab># no obvious way to discover why open() failed.<tab>else:<tab><tab>f.close()<tab><tab>self.fail(""no error for invalid mode: %s"" % bad_mode)",0,if msg . args [ 0 ] != 0 :,if msg . args [ 0 ] == 0 :,0.6049399806880458,70.16879391277372,1.0
"def command_group_expired(self, command_group_name):<tab>try:<tab><tab>deprecate_info = self._command_loader.command_group_table[<tab><tab><tab>command_group_name<tab><tab>].group_kwargs.get(""deprecate_info"", None)<tab><tab><IF-STMT><tab><tab><tab>return deprecate_info.expired()<tab>except AttributeError:<tab><tab># Items with only token presence in the command table will not have any data. They can't be expired.<tab><tab>pass<tab>return False",1,if deprecate_info :,if deprecate_info :,0.5311706625951745,1e-10,1.0
"def test_non_uniform_probabilities_over_elements(self):<tab>param = iap.Choice([0, 1], p=[0.25, 0.75])<tab>samples = param.draw_samples((10000,))<tab>unique, counts = np.unique(samples, return_counts=True)<tab>assert len(unique) == 2<tab>for val, count in zip(unique, counts):<tab><tab>if val == 0:<tab><tab><tab>assert 2500 - 500 < count < 2500 + 500<tab><tab><IF-STMT><tab><tab><tab>assert 7500 - 500 < count < 7500 + 500<tab><tab>else:<tab><tab><tab>assert False",1,elif val == 1 :,elif val == 1 :,1.0,100.00000000000004,1.0
"def get_labels(directory):<tab>cache = get_labels.__cache<tab>if directory not in cache:<tab><tab>l = {}<tab><tab>for t in get_visual_configs(directory)[0][LABEL_SECTION]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>Messager.warning(<tab><tab><tab><tab><tab>""In configuration, labels for '%s' defined more than once. Only using the last set.""<tab><tab><tab><tab><tab>% t.storage_form(),<tab><tab><tab><tab><tab>-1,<tab><tab><tab><tab>)<tab><tab><tab># first is storage for, rest are labels.<tab><tab><tab>l[t.storage_form()] = t.terms[1:]<tab><tab>cache[directory] = l<tab>return cache[directory]",0,if t . storage_form ( ) in l :,if t . terms [ 0 ] == 1 :,0.06264703276255601,14.991106946711685,0.36363636363636365
"def try_split(self, split_text: List[str]):<tab>ret = []<tab>for i in split_text:<tab><tab>if len(i) == 0:<tab><tab><tab>continue<tab><tab>val = int(i, 2)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>ret.append(val)<tab>if len(ret) != 0:<tab><tab>ret = bytes(ret)<tab><tab>logger.debug(f""binary successful, returning {ret.__repr__()}"")<tab><tab>return ret",0,if val > 255 or val < 0 :,if val == 0 :,0.037499275688711114,13.924420625000767,0.38888888888888884
"def setCellValue(self, row_idx, col, value):<tab>assert col.id == ""repls-marked""<tab>with self._lock:<tab><tab>rgroup = self.events[row_idx]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>rgroup._marked = value == ""true"" and True or False<tab>if self._tree:<tab><tab>self._tree.invalidateCell(row_idx, col)",0,"if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",if rgroup . _marked :,0.013055717236343255,4.988641679706251,0.2448979591836735
"def create(cls, settlement_manager, resource_id):<tab>""""""Create a production chain that can produce the given resource.""""""<tab>resource_producer = {}<tab>for abstract_building in AbstractBuilding.buildings.values():<tab><tab>for resource, production_line in abstract_building.lines.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resource_producer[resource] = []<tab><tab><tab>resource_producer[resource].append((production_line, abstract_building))<tab>return ProductionChain(settlement_manager, resource_id, resource_producer)",1,if resource not in resource_producer :,if resource not in resource_producer :,0.75,100.00000000000004,1.0
def get_all_partition_sets(self):<tab>partition_sets = []<tab>if self.partitions_handle:<tab><tab>partition_sets.extend(self.partitions_handle.get_partition_sets())<tab>if self.scheduler_handle:<tab><tab>partition_sets.extend(<tab><tab><tab>[<tab><tab><tab><tab>schedule_def.get_partition_set()<tab><tab><tab><tab>for schedule_def in self.scheduler_handle.all_schedule_defs()<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab>)<tab>return partition_sets,1,"if isinstance ( schedule_def , PartitionScheduleDefinition )","if isinstance ( schedule_def , PartitionScheduleDefinition )",0.75,100.00000000000004,1.0
"def _sendDatapointsNow(self, datapoints):<tab>metrics = {}<tab>payload_pb = Payload()<tab>for metric, datapoint in datapoints:<tab><tab><IF-STMT><tab><tab><tab>metric_pb = payload_pb.metrics.add()<tab><tab><tab>metric_pb.metric = metric<tab><tab><tab>metrics[metric] = metric_pb<tab><tab>else:<tab><tab><tab>metric_pb = metrics[metric]<tab><tab>point_pb = metric_pb.points.add()<tab><tab>point_pb.timestamp = int(datapoint[0])<tab><tab>point_pb.value = datapoint[1]<tab>self.sendString(payload_pb.SerializeToString())",1,if metric not in metrics :,if metric not in metrics :,0.75,100.00000000000004,1.0
"def execute(self):<tab>if self._dirty or not self._qr:<tab><tab>model_class = self.model_class<tab><tab>query_meta = self.get_query_meta()<tab><tab>if self._tuples:<tab><tab><tab>ResultWrapper = TuplesQueryResultWrapper<tab><tab><IF-STMT><tab><tab><tab>ResultWrapper = DictQueryResultWrapper<tab><tab>elif self._naive or not self._joins or self.verify_naive():<tab><tab><tab>ResultWrapper = NaiveQueryResultWrapper<tab><tab>elif self._aggregate_rows:<tab><tab><tab>ResultWrapper = AggregateQueryResultWrapper<tab><tab>else:<tab><tab><tab>ResultWrapper = ModelQueryResultWrapper<tab><tab>self._qr = ResultWrapper(model_class, self._execute(), query_meta)<tab><tab>self._dirty = False<tab><tab>return self._qr<tab>else:<tab><tab>return self._qr",1,elif self . _dicts :,elif self . _dicts :,0.75,100.00000000000004,1.0
"def get_metrics():<tab>classifier, feature_labels = load_classifier()<tab>available_metrics = ImgageMetrics.get_metric_classes()<tab># todo review: DONE IN DOCS<tab>#  effective_metrics isn't used after filling it with values<tab>#  in the loops below<tab>effective_metrics = []<tab>for metric in available_metrics:<tab><tab>for label in feature_labels:<tab><tab><tab>for label_part in metric.get_labels():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>effective_metrics.append(metric)<tab>return (classifier, feature_labels, available_metrics)",0,if label_part == label and metric not in effective_metrics :,if label_part not in effective_metrics :,0.15913925665260759,47.65082587109519,0.24675324675324675
"def test_nic_names(self):<tab>p = subprocess.Popen([""ipconfig"", ""/all""], stdout=subprocess.PIPE)<tab>out = p.communicate()[0]<tab>if PY3:<tab><tab>out = str(out, sys.stdout.encoding)<tab>nics = psutil.net_io_counters(pernic=True).keys()<tab>for nic in nics:<tab><tab>if ""pseudo-interface"" in nic.replace("" "", ""-"").lower():<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.fail(""%r nic wasn't found in 'ipconfig /all' output"" % nic)",1,if nic not in out :,if nic not in out :,0.75,100.00000000000004,1.0
"def convert_with_key(self, key, value, replace=True):<tab>result = self.configurator.convert(value)<tab># If the converted value is different, save for next time<tab>if value is not result:<tab><tab>if replace:<tab><tab><tab>self[key] = result<tab><tab><IF-STMT><tab><tab><tab>result.parent = self<tab><tab><tab>result.key = key<tab>return result",0,"if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :",elif result . parent is None :,0.007600664124009017,2.8730831956184355,0.07291666666666667
"def _EvaluateFile(self, test_list, file):<tab>(name, ext) = os.path.splitext(file)<tab>if ext == "".cc"" or ext == "".cpp"" or ext == "".c"":<tab><tab><IF-STMT><tab><tab><tab>logger.SilentLog(""Found native test file %s"" % file)<tab><tab><tab>test_list.append(name)",0,"if re . search ( ""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"" , name ) :",if os . path . exists ( file ) :,0.028970913427444248,0.8662159283620904,0.21212121212121213
"def leading_whitespace(self, inputstring):<tab>""""""Get leading whitespace.""""""<tab>leading_ws = []<tab>for i, c in enumerate(inputstring):<tab><tab><IF-STMT><tab><tab><tab>leading_ws.append(c)<tab><tab>else:<tab><tab><tab>break<tab><tab>if self.indchar is None:<tab><tab><tab>self.indchar = c<tab><tab>elif c != self.indchar:<tab><tab><tab>self.strict_err_or_warn(""found mixing of tabs and spaces"", inputstring, i)<tab>return """".join(leading_ws)",0,if c in legal_indent_chars :,if c . isspace ( ) :,0.05286931595839166,10.923299908191149,0.6
"def ident_values(self):<tab>value = self._ident_values<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab><IF-STMT><tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>idents = getattr(wrapped, ""ident_values"", None)<tab><tab><tab>if idents:<tab><tab><tab><tab>value = [self._wrap_hash(ident) for ident in idents]<tab><tab><tab>##else:<tab><tab><tab>##<tab>ident = self.ident<tab><tab><tab>##<tab>if ident is not None:<tab><tab><tab>##<tab><tab>value = [ident]<tab><tab>self._ident_values = value<tab>return value",0,if not self . orig_prefix :,if self . orig_prefix is not None :,0.10094060174500757,44.17918226831576,0.2916666666666667
"def _available_symbols(self, scoperef, expr):<tab>cplns = []<tab>found_names = set()<tab>while scoperef:<tab><tab>elem = self._elem_from_scoperef(scoperef)<tab><tab>for child in elem:<tab><tab><tab>name = child.get(""name"", """")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if name not in found_names:<tab><tab><tab><tab><tab>found_names.add(name)<tab><tab><tab><tab><tab>ilk = child.get(""ilk"") or child.tag<tab><tab><tab><tab><tab>cplns.append((ilk, name))<tab><tab>scoperef = self.parent_scoperef_from_scoperef(scoperef)<tab><tab>if not scoperef:<tab><tab><tab>break<tab>return sorted(cplns, key=operator.itemgetter(1))",0,if name . startswith ( expr ) :,"if isinstance ( child , expr ) :",0.07991956560314192,23.356898886410015,0.42857142857142855
"def pid_from_name(name):<tab># quick and dirty, works with all linux not depending on ps output<tab>for pid in os.listdir(""/proc""):<tab><tab>try:<tab><tab><tab>int(pid)<tab><tab>except:<tab><tab><tab>continue<tab><tab>pname = """"<tab><tab>with open(""/proc/%s/cmdline"" % pid, ""r"") as f:<tab><tab><tab>pname = f.read()<tab><tab><IF-STMT><tab><tab><tab>return int(pid)<tab>raise ProcessException(""No process with such name: %s"" % name)",0,if name in pname :,if pname == name :,0.038498786468962445,11.478744233307168,0.3333333333333333
"def touch(self):<tab>if not self.exists():<tab><tab>try:<tab><tab><tab>self.parent().touch()<tab><tab>except ValueError:<tab><tab><tab>pass<tab><tab>node = self._fs.touch(self.pathnames, {})<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(""Not a folder: %s"" % self.path)<tab><tab>if self.watcher:<tab><tab><tab>self.watcher.emit(""created"", self)",0,if not node . isdir :,if not node . exists ( ) :,0.3116527784232529,36.55552228545123,0.6666666666666666
"def setUp(self):<tab>BaseTestCase.setUp(self)<tab>self.rawData = []<tab>self.dataByKey = {}<tab>for i in range(1, 11):<tab><tab>stringCol = ""String %d"" % i<tab><tab>fixedCharCol = (""Fixed Char %d"" % i).ljust(40)<tab><tab>rawCol = ""Raw %d"" % i<tab><tab><IF-STMT><tab><tab><tab>nullableCol = ""Nullable %d"" % i<tab><tab>else:<tab><tab><tab>nullableCol = None<tab><tab>dataTuple = (i, stringCol, rawCol, fixedCharCol, nullableCol)<tab><tab>self.rawData.append(dataTuple)<tab><tab>self.dataByKey[i] = dataTuple",1,if i % 2 :,if i % 2 :,0.75,100.00000000000004,1.0
"def GenerateVector(self, hits, vector, level):<tab>""""""Generate possible hit vectors which match the rules.""""""<tab>for item in hits.get(level, []):<tab><tab>if vector:<tab><tab><tab>if item < vector[-1]:<tab><tab><tab><tab>continue<tab><tab><tab>if item > self.max_separation + vector[-1]:<tab><tab><tab><tab>break<tab><tab>new_vector = vector + [item]<tab><tab><IF-STMT><tab><tab><tab>yield new_vector<tab><tab>elif level + 1 < len(hits):<tab><tab><tab>for result in self.GenerateVector(hits, new_vector, level + 1):<tab><tab><tab><tab>yield result",1,if level + 1 == len ( hits ) :,if level + 1 == len ( hits ) :,0.75,100.00000000000004,1.0
"def __repr__(self):<tab>attrs = []<tab>for k in self.keydata:<tab><tab><IF-STMT><tab><tab><tab>attrs.append(""p(%d)"" % (self.size() + 1,))<tab><tab>elif hasattr(self.key, k):<tab><tab><tab>attrs.append(k)<tab>if self.has_private():<tab><tab>attrs.append(""private"")<tab>return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))",1,"if k == ""p"" :","if k == ""p"" :",0.75,100.00000000000004,1.0
"def autoload(self):<tab>if self._app.config.THEME == ""auto"":<tab><tab><IF-STMT><tab><tab><tab>if get_osx_theme() == 1:<tab><tab><tab><tab>theme = DARK<tab><tab><tab>else:<tab><tab><tab><tab>theme = LIGHT<tab><tab>else:<tab><tab><tab>theme = self.guess_system_theme()<tab><tab><tab>if theme == Dark:<tab><tab><tab><tab>theme = MacOSDark<tab>else:  # user settings have highest priority<tab><tab>theme = self._app.config.THEME<tab>self.load_theme(theme)",0,"if sys . platform == ""darwin"" :","if sys . platform == ""win32"" :",0.574113272471593,70.71067811865478,1.0
"def _get_matching_bracket(self, s, pos):<tab>if s[pos] != ""{"":<tab><tab>return None<tab>end = len(s)<tab>depth = 1<tab>pos += 1<tab>while pos != end:<tab><tab>c = s[pos]<tab><tab>if c == ""{"":<tab><tab><tab>depth += 1<tab><tab>elif c == ""}"":<tab><tab><tab>depth -= 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>pos += 1<tab>if pos < end and s[pos] == ""}"":<tab><tab>return pos<tab>return None",0,if depth == 0 :,elif depth == 0 :,0.31152264354151193,75.98356856515926,0.6
"def update_meter(self, output, target, meters={""accuracy""}):<tab>output = self.__to_tensor(output)<tab>target = self.__to_tensor(target)<tab>for meter in meters:<tab><tab><IF-STMT><tab><tab><tab>self.__addmeter(meter)<tab><tab>if meter in [""ap"", ""map"", ""confusion""]:<tab><tab><tab>target_th = self._ver2tensor(target)<tab><tab><tab>self.meter[meter].add(output, target_th)<tab><tab>else:<tab><tab><tab>self.meter[meter].add(output, target)",0,if meter not in self . meter . keys ( ) :,if meter not in self . meter :,0.3802220014309627,52.734307450329375,0.8441558441558442
"def _reinit_optimizers_with_oss(self):<tab>optimizers = self.lightning_module.trainer.optimizers<tab>for x, optimizer in enumerate(optimizers):<tab><tab>if is_lightning_optimizer(optimizer):<tab><tab><tab>optimizer = optimizer._optimizer<tab><tab><IF-STMT><tab><tab><tab>optim_class = type(optimizer)<tab><tab><tab>zero_optimizer = OSS(<tab><tab><tab><tab>params=optimizer.param_groups, optim=optim_class, **optimizer.defaults<tab><tab><tab>)<tab><tab><tab>optimizers[x] = zero_optimizer<tab><tab><tab>del optimizer<tab>trainer = self.lightning_module.trainer<tab>trainer.optimizers = optimizers<tab>trainer.convert_to_lightning_optimizers()",0,"if not isinstance ( optimizer , OSS ) :","if isinstance ( optimizer , OSS ) :",0.38125480330051975,76.72796459606589,0.3148148148148148
"def OnSelChanged(self, event):<tab>self.item = event.GetItem()<tab>if self.item:<tab><tab>self.log.write(""OnSelChanged: %s"" % self.GetItemText(self.item))<tab><tab><IF-STMT><tab><tab><tab>self.log.write(<tab><tab><tab><tab>"", BoundingRect: %s\n"" % self.GetBoundingRect(self.item, True)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.log.write(""\n"")<tab>event.Skip()",0,"if wx . Platform == ""__WXMSW__"" :",if self . GetBoundingRect :,0.02384665141965364,2.3238598963754593,0.3333333333333333
"def parse_batch(args):<tab>errmsg = ""Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1).""<tab>if args.batch is not None:<tab><tab>rule, batchdef = parse_key_value_arg(args.batch, errmsg=errmsg)<tab><tab>try:<tab><tab><tab>batch, batches = batchdef.split(""/"")<tab><tab><tab>batch = int(batch)<tab><tab><tab>batches = int(batches)<tab><tab>except ValueError:<tab><tab><tab>raise ValueError(errmsg)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(errmsg)<tab><tab>return Batch(rule, batch, batches)<tab>return None",0,if batch > batches or batch < 1 :,if len ( batch ) < 1 :,0.0700803134814309,20.612390921238426,0.25
"def get_foreign_key_columns(self, engine, table_name):<tab>foreign_keys = set()<tab>table = db_utils.get_table(engine, table_name)<tab>inspector = reflection.Inspector.from_engine(engine)<tab>for column_dict in inspector.get_columns(table_name):<tab><tab>column_name = column_dict[""name""]<tab><tab>column = getattr(table.c, column_name)<tab><tab><IF-STMT><tab><tab><tab>foreign_keys.add(column_name)<tab>return foreign_keys",0,if column . foreign_keys :,if column . foreign_key :,0.39477865547525276,64.34588841607616,1.0
"def update(self, t):<tab>l = int(t * self.nr_of_tiles)<tab>for i in range(self.nr_of_tiles):<tab><tab>t = self.tiles_order[i]<tab><tab><IF-STMT><tab><tab><tab>self.turn_off_tile(t)<tab><tab>else:<tab><tab><tab>self.turn_on_tile(t)",0,if i < l :,if i % l == 0 :,0.05544914160509713,13.134549472120788,0.7714285714285715
"def read(self, amt=None):<tab># the _rbuf test is only in this first if for speed.  It's not<tab># logically necessary<tab>if self._rbuf and not amt is None:<tab><tab>L = len(self._rbuf)<tab><tab><IF-STMT><tab><tab><tab>amt -= L<tab><tab>else:<tab><tab><tab>s = self._rbuf[:amt]<tab><tab><tab>self._rbuf = self._rbuf[amt:]<tab><tab><tab>return s<tab>s = self._rbuf + self._raw_read(amt)<tab>self._rbuf = b""""<tab>return s",1,if amt > L :,if amt > L :,0.75,100.00000000000004,1.0
"def draw_menu_button(self, context, layout, node, text):<tab>if (<tab><tab>hasattr(node.id_data, ""sv_show_socket_menus"")<tab><tab>and node.id_data.sv_show_socket_menus<tab>):<tab><tab><IF-STMT><tab><tab><tab>layout.menu(""SV_MT_SocketOptionsMenu"", text="""", icon=""TRIA_DOWN"")",0,if self . is_output or self . is_linked or not self . use_prop :,if node . id_data . sv_show_socket_menus == 1 :,0.010504279961031569,3.126017514958335,0.25396825396825395
"def __enter__(self):<tab>with DB.connection_context():<tab><tab>session_record = SessionRecord()<tab><tab>session_record.f_session_id = self._session_id<tab><tab>session_record.f_engine_name = self._engine_name<tab><tab>session_record.f_engine_type = EngineType.STORAGE<tab><tab># TODO: engine address<tab><tab>session_record.f_engine_address = {}<tab><tab>session_record.f_create_time = current_timestamp()<tab><tab>rows = session_record.save(force_insert=True)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(f""create session record {self._session_id} failed"")<tab><tab>LOGGER.debug(f""save session {self._session_id} record"")<tab>self.create()<tab>return self",0,if rows != 1 :,if not rows :,0.03944961859844226,12.750736437345598,0.4
"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab>if self.server:<tab><tab><tab>self.server.stop(2.0)<tab><tab><IF-STMT><tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",1,if self . sl_hdlr :,if self . sl_hdlr :,0.75,100.00000000000004,1.0
"def _dec_device(self, srcdev, dstdev):<tab>if srcdev:<tab><tab>self.srcdevs[srcdev] -= 1<tab><tab><IF-STMT><tab><tab><tab>del self.srcdevs[srcdev]<tab><tab>self._set_limits(""read"", self.srcdevs)<tab>if dstdev:<tab><tab>self.dstdevs[dstdev] -= 1<tab><tab>if self.dstdevs[dstdev] == 0:<tab><tab><tab>del self.dstdevs[dstdev]<tab><tab>self._set_limits(""write"", self.dstdevs)",1,if self . srcdevs [ srcdev ] == 0 :,if self . srcdevs [ srcdev ] == 0 :,0.75,100.00000000000004,1.0
"def array_for(self, i):<tab>if 0 <= i < self._cnt:<tab><tab><IF-STMT><tab><tab><tab>return self._tail<tab><tab>node = self._root<tab><tab>level = self._shift<tab><tab>while level > 0:<tab><tab><tab>assert isinstance(node, Node)<tab><tab><tab>node = node._array[(i >> level) & 0x01F]<tab><tab><tab>level -= 5<tab><tab>return node._array<tab>affirm(False, u""Index out of Range"")",0,if i >= self . tailoff ( ) :,if self . _tail :,0.03153300650124795,9.911450612811139,0.3666666666666667
"def convert_tensor(self, offsets, sizes):<tab>results = []<tab>for b, batch in enumerate(offsets):<tab><tab>utterances = []<tab><tab>for p, utt in enumerate(batch):<tab><tab><tab>size = sizes[b][p]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>utterances.append(utt[0:size])<tab><tab><tab>else:<tab><tab><tab><tab>utterances.append(torch.tensor([], dtype=torch.int))<tab><tab>results.append(utterances)<tab>return results",0,if sizes [ b ] [ p ] > 0 :,if size > 0 :,0.04909737062145379,12.869637315183779,0.2653061224489796
"def _predict_proba(self, X, preprocess=True):<tab>if preprocess:<tab><tab>X = self.preprocess(X)<tab>if self.problem_type == REGRESSION:<tab><tab>return self.model.predict(X)<tab>y_pred_proba = self.model.predict_proba(X)<tab>if self.problem_type == BINARY:<tab><tab>if len(y_pred_proba.shape) == 1:<tab><tab><tab>return y_pred_proba<tab><tab><IF-STMT><tab><tab><tab>return y_pred_proba[:, 1]<tab><tab>else:<tab><tab><tab>return y_pred_proba<tab>elif y_pred_proba.shape[1] > 2:<tab><tab>return y_pred_proba<tab>else:<tab><tab>return y_pred_proba[:, 1]",0,elif y_pred_proba . shape [ 1 ] > 1 :,elif len ( y_pred_proba . shape ) == 2 :,0.0593420260976049,42.61082723917019,0.3333333333333333
def timeout(self):<tab>now = ptime.time()<tab>dt = now - self.lastPlayTime<tab>if dt < 0:<tab><tab>return<tab>n = int(self.playRate * dt)<tab>if n != 0:<tab><tab>self.lastPlayTime += float(n) / self.playRate<tab><tab><IF-STMT><tab><tab><tab>self.play(0)<tab><tab>self.jumpFrames(n),0,"if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :",if self . lastPlayTime >= self . playbackLimit :,0.2681396679255828,5.822464699665066,0.2257142857142857
"def __init__(self, data, weights=None, ddof=0):<tab>self.data = np.asarray(data)<tab>if weights is None:<tab><tab>self.weights = np.ones(self.data.shape[0])<tab>else:<tab><tab>self.weights = np.asarray(weights).astype(float)<tab><tab># TODO: why squeeze?<tab><tab><IF-STMT><tab><tab><tab>self.weights = self.weights.squeeze()<tab>self.ddof = ddof",0,if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 :,"if hasattr ( self . weights , ""squeeze"" ) :",0.09589853647925564,11.518272556484067,0.34156378600823045
"def writerow(self, row):<tab>unicode_row = []<tab>for col in row:<tab><tab><IF-STMT><tab><tab><tab>unicode_row.append(col.encode(""utf-8"").strip())<tab><tab>else:<tab><tab><tab>unicode_row.append(col)<tab>self.writer.writerow(unicode_row)<tab># Fetch UTF-8 output from the queue ...<tab>data = self.queue.getvalue()<tab>data = data.decode(""utf-8"")<tab># ... and reencode it into the target encoding<tab>data = self.encoder.encode(data)<tab># write to the target stream<tab>self.stream.write(data)<tab># empty queue<tab>self.queue.truncate(0)",0,if type ( col ) == str or type ( col ) == unicode :,"if isinstance ( col , unicode ) :",0.017906483884352176,4.719073083867901,0.3055555555555556
"def __init__(self, choices, allow_blank=False, **kwargs):<tab>self.choiceset = choices<tab>self.allow_blank = allow_blank<tab>self._choices = dict()<tab># Unpack grouped choices<tab>for k, v in choices:<tab><tab><IF-STMT><tab><tab><tab>for k2, v2 in v:<tab><tab><tab><tab>self._choices[k2] = v2<tab><tab>else:<tab><tab><tab>self._choices[k] = v<tab>super().__init__(**kwargs)",0,"if type ( v ) in [ list , tuple ] :","if isinstance ( v , ( list , tuple ) ) :",0.06050062173908079,17.827531042796263,0.3653846153846154
"def simp_ext(_, expr):<tab>if expr.op.startswith(""zeroExt_""):<tab><tab>arg = expr.args[0]<tab><tab><IF-STMT><tab><tab><tab>return arg<tab><tab>return ExprCompose(arg, ExprInt(0, expr.size - arg.size))<tab>if expr.op.startswith(""signExt_""):<tab><tab>arg = expr.args[0]<tab><tab>add_size = expr.size - arg.size<tab><tab>new_expr = ExprCompose(<tab><tab><tab>arg,<tab><tab><tab>ExprCond(<tab><tab><tab><tab>arg.msb(), ExprInt(size2mask(add_size), add_size), ExprInt(0, add_size)<tab><tab><tab>),<tab><tab>)<tab><tab>return new_expr<tab>return expr",0,if expr . size == arg . size :,if arg . size == 0 :,0.15869765835455005,36.827215283744195,0.4259259259259259
"def mark_differences(value: str, compare_against: str):<tab>result = []<tab>for i, char in enumerate(value):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append('<font color=""red"">{}</font>'.format(char))<tab><tab><tab>else:<tab><tab><tab><tab>result.append(char)<tab><tab>except IndexError:<tab><tab><tab>result.append(char)<tab>return """".join(result)",0,if char != compare_against [ i ] :,if compare_against [ i ] :,0.2717023828753995,59.755798910891144,0.4772727272727273
"def run_query(self, query, user):<tab>url = ""%s%s"" % (self.base_url, ""&"".join(query.split(""\n"")))<tab>error = None<tab>data = None<tab>try:<tab><tab>response = requests.get(url, auth=self.auth, verify=self.verify)<tab><tab><IF-STMT><tab><tab><tab>data = _transform_result(response)<tab><tab>else:<tab><tab><tab>error = ""Failed getting results (%d)"" % response.status_code<tab>except Exception as ex:<tab><tab>data = None<tab><tab>error = str(ex)<tab>return data, error",1,if response . status_code == 200 :,if response . status_code == 200 :,0.75,100.00000000000004,1.0
"def on_enter(self):<tab>""""""Fired when mouse enter the bbox of the widget.""""""<tab>if hasattr(self, ""md_bg_color"") and self.focus_behavior:<tab><tab><IF-STMT><tab><tab><tab>self.md_bg_color = self.theme_cls.bg_normal<tab><tab>else:<tab><tab><tab>if not self.focus_color:<tab><tab><tab><tab>self.md_bg_color = App.get_running_app().theme_cls.bg_normal<tab><tab><tab>else:<tab><tab><tab><tab>self.md_bg_color = self.focus_color",0,"if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",if not self . focus_color :,0.14230896044355595,21.982929910091713,0.4150326797385621
"def tearDown(self):<tab>if not self.is_playback():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.sms.delete_hosted_service(self.hosted_service_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab>if self.storage_account_name is not None:<tab><tab><tab><tab>self.sms.delete_storage_account(self.storage_account_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab>self.sms.delete_affinity_group(self.affinity_group_name)<tab><tab>except:<tab><tab><tab>pass<tab>return super(LegacyMgmtAffinityGroupTest, self).tearDown()",1,if self . hosted_service_name is not None :,if self . hosted_service_name is not None :,0.75,100.00000000000004,1.0
"def name2cp(k):<tab>if k == ""apos"":<tab><tab>return ord(""'"")<tab>if hasattr(htmlentitydefs, ""name2codepoint""):  # requires Python 2.3<tab><tab>return htmlentitydefs.name2codepoint[k]<tab>else:<tab><tab>k = htmlentitydefs.entitydefs[k]<tab><tab><IF-STMT><tab><tab><tab>return int(k[2:-1])  # not in latin-1<tab><tab>return ord(codecs.latin_1_decode(k)[0])",0,"if k . startswith ( ""&#"" ) and k . endswith ( "";"" ) :","if k . startswith ( ""latin_"" ) :",0.21995662454692788,25.93252515852421,0.5873015873015873
"def _para_set(self, params, part):<tab>if len(params) == 0:<tab><tab>result = suggest([i.get_name() for i in self._options], part)<tab><tab>return result<tab>elif len(params) == 1:<tab><tab>paramName = params[0]<tab><tab>if paramName not in self._options:<tab><tab><tab>return []<tab><tab>opt = self._options[paramName]<tab><tab>paramType = opt.get_type()<tab><tab><IF-STMT><tab><tab><tab>values = [opt.get_default_value() == ""True"" and ""False"" or ""True""]<tab><tab>else:<tab><tab><tab>values = self._memory[paramName]<tab><tab>return suggest(values, part)<tab>else:<tab><tab>return []",0,"if paramType == ""boolean"" :","if dataType == ""boolean"" :",0.39477865547525276,70.71067811865478,0.5
"def hexcmp(x, y):<tab>try:<tab><tab>a = int(x, 16)<tab><tab>b = int(y, 16)<tab><tab><IF-STMT><tab><tab><tab>return -1<tab><tab>if a > b:<tab><tab><tab>return 1<tab><tab>return 0<tab>except:<tab><tab>return cmp(x, y)",1,if a < b :,if a < b :,0.75,100.00000000000004,1.0
"def execute(self, statement, arguments=None):<tab>while True:<tab><tab>try:<tab><tab><tab>if arguments:<tab><tab><tab><tab>self.cursor.execute(statement, arguments)<tab><tab><tab>else:<tab><tab><tab><tab>self.cursor.execute(statement)<tab><tab>except sqlite3.OperationalError as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>break<tab>if statement.lstrip().upper().startswith(""SELECT""):<tab><tab>return self.cursor.fetchall()",0,"if ""locked"" not in getSafeExString ( ex ) :",if ex . errno != errno . EINTR :,0.016784918517629303,4.996872151825361,0.25
"def _test_forever(self, tests):<tab>while True:<tab><tab>for test_name in tests:<tab><tab><tab>yield test_name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>if self.ns.fail_env_changed and self.environment_changed:<tab><tab><tab><tab>return",0,if self . bad :,if not self . _test_name ( test_name ) :,0.04975840882008457,6.754312828675707,0.4
"def removeUser(self, username):<tab>hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD<tab>if username in self._users:<tab><tab>user = self._users[username]<tab><tab>if user.room:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hideFromOSD = not constants.SHOW_SAME_ROOM_OSD<tab>if username in self._users:<tab><tab>self._users.pop(username)<tab><tab>message = getMessage(""left-notification"").format(username)<tab><tab>self.ui.showMessage(message, hideFromOSD)<tab><tab>self._client.lastLeftTime = time.time()<tab><tab>self._client.lastLeftUser = username<tab>self.userListChange()",0,if self . isRoomSame ( user . room ) :,if self . _users [ username ] . room . isOpen ( ) :,0.11723236347696858,14.865996369027277,0.375
"def AutoTest():<tab>with open(sys.argv[1], ""rb"") as f:<tab><tab>for line in f.read().split(b""\n""):<tab><tab><tab>line = BYTES2SYSTEMSTR(line.strip())<tab><tab><tab>if not line:<tab><tab><tab><tab>continue<tab><tab><tab>elif line.startswith(""#""):<tab><tab><tab><tab>print(line)<tab><tab><tab>else:<tab><tab><tab><tab>print("">>> "" + line)<tab><tab><tab><tab>os.system(line)<tab><tab><tab><tab>sys.stdout.write(""\npress enter to continue..."")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>input()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raw_input()<tab><tab><tab><tab>sys.stdout.write(""\n"")",0,if PY3 :,if sys . argv [ 1 ] :,0.04422835593777517,1e-10,0.3
"def get_first_field(layout, clz):<tab>for layout_object in layout.fields:<tab><tab><IF-STMT><tab><tab><tab>return layout_object<tab><tab>elif hasattr(layout_object, ""get_field_names""):<tab><tab><tab>gf = get_first_field(layout_object, clz)<tab><tab><tab>if gf:<tab><tab><tab><tab>return gf",0,"if issubclass ( layout_object . __class__ , clz ) :",if layout_object . clz == clz :,0.07924531214746436,16.581659750776073,0.6666666666666666
"def sanitize_event_keys(kwargs, valid_keys):<tab># Sanity check: Don't honor keys that we don't recognize.<tab>for key in list(kwargs.keys()):<tab><tab>if key not in valid_keys:<tab><tab><tab>kwargs.pop(key)<tab># Truncate certain values over 1k<tab>for key in [""play"", ""role"", ""task"", ""playbook""]:<tab><tab>if isinstance(kwargs.get(""event_data"", {}).get(key), str):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars(<tab><tab><tab><tab><tab>1024<tab><tab><tab><tab>)",0,"if len ( kwargs [ ""event_data"" ] [ key ] ) > 1024 :",if key not in valid_keys :,0.00899532177506067,2.2375594425769316,0.24342105263157893
"def visit_productionlist(self, node):<tab>self.new_state()<tab>names = []<tab>for production in node:<tab><tab>names.append(production[""tokenname""])<tab>maxlen = max(len(name) for name in names)<tab>for production in node:<tab><tab><IF-STMT><tab><tab><tab>self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="")<tab><tab><tab>lastname = production[""tokenname""]<tab><tab>else:<tab><tab><tab>self.add_text(""%s<tab>"" % ("" "" * len(lastname)))<tab><tab>self.add_text(production.astext() + self.nl)<tab>self.end_state(wrap=False)<tab>raise nodes.SkipNode",1,"if production [ ""tokenname"" ] :","if production [ ""tokenname"" ] :",0.75,100.00000000000004,1.0
"def uuid(self):<tab>if not getattr(self, ""_uuid"", None):<tab><tab><IF-STMT><tab><tab><tab>self._uuid = self.repository._kp_uuid(<tab><tab><tab><tab>self.path<tab><tab><tab>)  # Use repository UUID (even if None)<tab><tab>else:<tab><tab><tab>self._uuid = str(uuid.uuid4())<tab>return self._uuid",0,if self . repository is not None :,if self . repository :,0.2343345094426703,38.80684294761701,0.5102040816326531
"def remove(self, values):<tab>if not isinstance(values, (list, tuple, set)):<tab><tab>values = [values]<tab>for v in values:<tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>self._definition.pop(v, None)<tab><tab>elif self._definition == ""ANY"":<tab><tab><tab>if v == ""ANY"":<tab><tab><tab><tab>self._definition = []<tab><tab>elif v in self._definition:<tab><tab><tab>self._definition.remove(v)<tab>if (<tab><tab>self._value is not None<tab><tab>and self._value not in self._definition<tab><tab>and self._not_any()<tab>):<tab><tab>raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",0,"if isinstance ( self . _definition , dict ) :",if self . _definition :,0.059382556937524214,24.439253249722206,0.37142857142857144
"def make(self):<tab>pygments_dir = join(self.dir, ""externals"", ""pygments"")<tab>if exists(pygments_dir):<tab><tab>run_in_dir(""hg pull"", pygments_dir, self.log.info)<tab><tab>run_in_dir(""hg update"", pygments_dir, self.log.info)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dirname(pygments_dir))<tab><tab>run_in_dir(<tab><tab><tab>""hg clone http://dev.pocoo.org/hg/pygments-main %s""<tab><tab><tab>% basename(pygments_dir),<tab><tab><tab>dirname(pygments_dir),<tab><tab><tab>self.log.info,<tab><tab>)",1,if not exists ( dirname ( pygments_dir ) ) :,if not exists ( dirname ( pygments_dir ) ) :,0.75,100.00000000000004,1.0
def set_field(self):<tab>i = 0<tab>for string in self.display_string:<tab><tab><IF-STMT><tab><tab><tab>self.config[self.field + str(i)] = self.conversion_fn(self.str[i])<tab><tab>else:<tab><tab><tab>self.config[self.field + str(i)] = self.str[i]<tab><tab>i = i + 1,1,if self . conversion_fn :,if self . conversion_fn :,0.75,100.00000000000004,1.0
"def cleanup(self):<tab>with self.lock:<tab><tab>for proc in self.processes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>proc.join()<tab><tab><tab>self.processes.remove(proc)<tab><tab><tab>log.debug(""Subprocess %s cleaned up"", proc.name)",1,if proc . is_alive ( ) :,if proc . is_alive ( ) :,0.75,100.00000000000004,1.0
"def setup(self, gen):<tab>Node.setup(self, gen)<tab>for c in self.children:<tab><tab>c.setup(gen)<tab>if not self.accepts_epsilon:<tab><tab># If it's not already accepting epsilon, it might now do so.<tab><tab>for c in self.children:<tab><tab><tab># any non-epsilon means all is non-epsilon<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self.accepts_epsilon = 1<tab><tab><tab>gen.changed()",0,if not c . accepts_epsilon :,if c . accepts_epsilon :,0.281663156243144,72.89545183625967,0.4642857142857143
"def __call__(self, message):<tab>with self._lock:<tab><tab>self._pending_ack += 1<tab><tab>self.max_pending_ack = max(self.max_pending_ack, self._pending_ack)<tab><tab>self.seen_message_ids.append(int(message.attributes[""seq_num""]))<tab>time.sleep(self._processing_time)<tab>with self._lock:<tab><tab>self._pending_ack -= 1<tab><tab>message.ack()<tab><tab>self.completed_calls += 1<tab><tab>if self.completed_calls >= self._resolve_at_msg_count:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.done_future.set_result(None)",0,if not self . done_future . done ( ) :,if self . done_future is not None :,0.06426811787137493,36.17085516890759,0.27272727272727276
"def build_canned_image_list(path):<tab>layers_path = get_bitbake_var(""BBLAYERS"")<tab>canned_wks_layer_dirs = []<tab>if layers_path is not None:<tab><tab>for layer_path in layers_path.split():<tab><tab><tab>for wks_path in (WIC_DIR, SCRIPTS_CANNED_IMAGE_DIR):<tab><tab><tab><tab>cpath = os.path.join(layer_path, wks_path)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>canned_wks_layer_dirs.append(cpath)<tab>cpath = os.path.join(path, CANNED_IMAGE_DIR)<tab>canned_wks_layer_dirs.append(cpath)<tab>return canned_wks_layer_dirs",1,if os . path . isdir ( cpath ) :,if os . path . isdir ( cpath ) :,0.75,100.00000000000004,1.0
"def _recv_loop(self) -> None:<tab>async with self._ws as connection:<tab><tab>self._connected = True<tab><tab>self.connection = connection<tab><tab>while self._connected:<tab><tab><tab>try:<tab><tab><tab><tab>resp = await self.connection.recv()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>await self._on_message(resp)<tab><tab><tab>except (websockets.ConnectionClosed, ConnectionResetError):<tab><tab><tab><tab>logger.info(""connection closed"")<tab><tab><tab><tab>break<tab><tab><tab>await asyncio.sleep(0)<tab>if self._connected:<tab><tab>self._loop.create_task(self.dispose())",1,if resp :,if resp :,0.5311706625951745,1e-10,1.0
"def _get_between(content, start, end=None):<tab>should_yield = False<tab>for line in content.split(""\n""):<tab><tab>if start in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if should_yield and line:<tab><tab><tab>yield line.strip().split("" "")[0]",0,if end and end in line :,if end in line :,0.41481738538569646,50.93330917854971,0.3611111111111111
"def handle_parse_result(self, ctx, opts, args):<tab>if self.name in opts:<tab><tab>if self.mutually_exclusive.intersection(opts):<tab><tab><tab>self._raise_exclusive_error()<tab><tab><IF-STMT><tab><tab><tab>self._raise_exclusive_error()<tab>return super(MutuallyExclusiveOption, self).handle_parse_result(ctx, opts, args)",0,if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,elif self . exclusive . intersection ( opts ) :,0.033819851002880694,5.021776686519537,0.11282051282051284
"def write(self, s):<tab>if self.interactive:<tab><tab><IF-STMT><tab><tab><tab>self.active_mode.write(s)<tab><tab>else:<tab><tab><tab>component.get(""CmdLine"").add_line(s, False)<tab><tab><tab>self.events.append(s)<tab>else:<tab><tab>print(colors.strip_colors(s))",0,"if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :",if self . active_mode :,0.018743214288174263,7.845605491344882,0.1954022988505747
"def findfiles(path):<tab>files = []<tab>for name in os.listdir(path):<tab><tab># ignore hidden files/dirs and other unwanted files<tab><tab>if name.startswith(""."") or name == ""lastsnap.jpg"":<tab><tab><tab>continue<tab><tab>pathname = os.path.join(path, name)<tab><tab>st = os.lstat(pathname)<tab><tab>mode = st.st_mode<tab><tab><IF-STMT><tab><tab><tab>files.extend(findfiles(pathname))<tab><tab>elif stat.S_ISREG(mode):<tab><tab><tab>files.append((pathname, name, st))<tab>return files",0,if stat . S_ISDIR ( mode ) :,if stat . S_ISLNK ( mode ) :,0.5014622369176811,65.80370064762461,1.0
"def _get_documented_completions(self, table, startswith=None):<tab>names = []<tab>for key, command in table.items():<tab><tab>if getattr(command, ""_UNDOCUMENTED"", False):<tab><tab><tab># Don't tab complete undocumented commands/params<tab><tab><tab>continue<tab><tab>if startswith is not None and not key.startswith(startswith):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>names.append(key)<tab>return names",0,"if getattr ( command , ""positional_arg"" , False ) :","if key . startswith ( ""_"" ) :",0.028107316037741373,7.69443236290179,0.27472527472527475
"def fix_newlines(lines):<tab>""""""Convert newlines to unix.""""""<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>lines[i] = line[:-2] + ""\n""<tab><tab>elif line.endswith(""\r""):<tab><tab><tab>lines[i] = line[:-1] + ""\n""",0,"if line . endswith ( ""\r\n"" ) :","if line . endswith ( ""\n"" ) :",0.5490406812970063,75.33808072882876,1.0
"def GeneratePageMetatadata(self, task):<tab>address_space = self.session.GetParameter(""default_address_space"")<tab>for vma in task.mm.mmap.walk_list(""vm_next""):<tab><tab>start = vma.vm_start<tab><tab>end = vma.vm_end<tab><tab># Skip the entire region.<tab><tab>if end < self.plugin_args.start:<tab><tab><tab>continue<tab><tab># Done.<tab><tab>if start > self.plugin_args.end:<tab><tab><tab>break<tab><tab>for vaddr in utils.xrange(start, end, 0x1000):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",1,if self . plugin_args . start <= vaddr <= self . plugin_args . end :,if self . plugin_args . start <= vaddr <= self . plugin_args . end :,1.0,100.00000000000004,1.0
"def get_shape_at_node(self, node, assumptions):<tab>for k, v in assumptions.items():<tab><tab><IF-STMT><tab><tab><tab>return v<tab>if node.inputs:<tab><tab>return node.container.shape(<tab><tab><tab>input_shapes=[<tab><tab><tab><tab>self.get_shape_at_node(input_node, assumptions)<tab><tab><tab><tab>for input_node in node.inputs<tab><tab><tab>]<tab><tab>)<tab>else:<tab><tab>return node.container.shape(None)",0,if k in node . names :,"if k == ""shape"" :",0.04240600921794552,12.22307556087252,0.42857142857142855
"def fix_doc(self, doc):<tab>type = doc.get(""type"", {}).get(""key"")<tab>if type == ""/type/work"":<tab><tab><IF-STMT><tab><tab><tab># some record got empty author records because of an error<tab><tab><tab># temporary hack to fix<tab><tab><tab>doc[""authors""] = [<tab><tab><tab><tab>a for a in doc[""authors""] if ""author"" in a and ""key"" in a[""author""]<tab><tab><tab>]<tab>elif type == ""/type/edition"":<tab><tab># get rid of title_prefix.<tab><tab>if ""title_prefix"" in doc:<tab><tab><tab>title = doc[""title_prefix""].strip() + "" "" + doc.get(""title"", """")<tab><tab><tab>doc[""title""] = title.strip()<tab><tab><tab>del doc[""title_prefix""]<tab>return doc",0,"if doc . get ( ""authors"" ) :","if ""authors"" in doc :",0.020977836961063236,18.938334565508196,0.4
"def modify_column(self, column: List[Optional[""Cell""]]):<tab>for i in range(len(column)):<tab><tab>gate = column[i]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(gate, ParityControlCell):<tab><tab><tab># The first parity control to modify the column must merge all<tab><tab><tab># of the other parity controls into itself.<tab><tab><tab>column[i] = None<tab><tab><tab>self._basis_change += gate._basis_change<tab><tab><tab>self.qubits += gate.qubits<tab><tab>elif gate is not None:<tab><tab><tab>column[i] = gate.controlled_by(self.qubits[0])",0,if gate is self :,if gate is None :,0.39477865547525276,42.72870063962342,0.6666666666666666
"def onSync(self, auto=False, reload=True):<tab>if not auto or (<tab><tab>self.pm.profile[""syncKey""] and self.pm.profile[""autoSync""] and not self.safeMode<tab>):<tab><tab>from aqt.sync import SyncManager<tab><tab>if not self.unloadCollection():<tab><tab><tab>return<tab><tab># set a sync state so the refresh timer doesn't fire while deck<tab><tab># unloaded<tab><tab>self.state = ""sync""<tab><tab>self.syncer = SyncManager(self, self.pm)<tab><tab>self.syncer.sync()<tab>if reload:<tab><tab><IF-STMT><tab><tab><tab>self.loadCollection()",0,if not self . col :,if self . safeMode :,0.054520976303194774,20.80119537801062,0.3
"def _has_url_match(self, match, request_url):<tab>url = match[""url""]<tab>if _is_string(url):<tab><tab><IF-STMT><tab><tab><tab>return self._has_strict_url_match(url, request_url)<tab><tab>else:<tab><tab><tab>url_without_qs = request_url.split(""?"", 1)[0]<tab><tab><tab>return url == url_without_qs<tab>elif isinstance(url, re._pattern_type) and url.match(request_url):<tab><tab>return True<tab>else:<tab><tab>return False",0,"if match [ ""match_querystring"" ] :",if self . strict :,0.02713659235259708,4.673289785800722,0.37142857142857144
"def pool_image(self, image):<tab>if self.count < self.pool_size:<tab><tab>self.pool.append(image)<tab><tab>self.count += 1<tab><tab>return image<tab>else:<tab><tab>p = random.random()<tab><tab><IF-STMT><tab><tab><tab>random_id = random.randint(0, self.pool_size - 1)<tab><tab><tab>temp = self.pool[random_id]<tab><tab><tab>self.pool[random_id] = image<tab><tab><tab>return temp<tab><tab>else:<tab><tab><tab>return image",0,if p > 0.5 :,if p < self . pool_size :,0.05286931595839166,10.552670315936318,0.7222222222222222
"def get_target_dimensions(self):<tab>width, height = self.engine.size<tab>for operation in self.operations:<tab><tab><IF-STMT><tab><tab><tab>width = operation[""right""] - operation[""left""]<tab><tab><tab>height = operation[""bottom""] - operation[""top""]<tab><tab>if operation[""type""] == ""resize"":<tab><tab><tab>width = operation[""width""]<tab><tab><tab>height = operation[""height""]<tab>return (width, height)",0,"if operation [ ""type"" ] == ""crop"" :","if operation [ ""type"" ] == ""resize"" :",0.605621305873661,79.10665071754353,1.0
"def validate_matrix(matrix):<tab>if not matrix:<tab><tab>return None<tab>for key, value in matrix.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>""`{}` defines a non uniform distribution, ""<tab><tab><tab><tab>""and it cannot be used with bayesian optimization."".format(key)<tab><tab><tab>)<tab>return matrix",0,if value . is_distribution and not value . is_uniform :,"if key == ""uniform"" :",0.013468035777437931,3.4331054109918173,0.2948717948717949
"def scm_to_conandata(self):<tab>try:<tab><tab>scm_to_conandata = get_env(""CONAN_SCM_TO_CONANDATA"")<tab><tab><IF-STMT><tab><tab><tab>scm_to_conandata = self.get_item(""general.scm_to_conandata"")<tab><tab>return scm_to_conandata.lower() in (""1"", ""true"")<tab>except ConanException:<tab><tab>return False",0,if scm_to_conandata is None :,if not scm_to_conandata :,0.03944961859844226,49.62644776757999,0.36
"def _link_vrf_table(self, vrf_table, rt_list):<tab>route_family = vrf_table.route_family<tab>for rt in rt_list:<tab><tab>rt_rf_id = rt + "":"" + str(route_family)<tab><tab>table_set = self._tables_for_rt.get(rt_rf_id)<tab><tab><IF-STMT><tab><tab><tab>table_set = set()<tab><tab><tab>self._tables_for_rt[rt_rf_id] = table_set<tab><tab>table_set.add(vrf_table)<tab><tab>LOG.debug(""Added VrfTable %s to import RT table list: %s"", vrf_table, rt)",1,if table_set is None :,if table_set is None :,0.75,100.00000000000004,1.0
"def add_tags(<tab>self, cve_results: Dict[str, Dict[str, Dict[str, str]]], file_object: FileObject):<tab># results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}}<tab>for component in cve_results:<tab><tab>for cve_id in cve_results[component]:<tab><tab><tab>entry = cve_results[component][cve_id]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_analysis_tag(<tab><tab><tab><tab><tab>file_object, ""CVE"", ""critical CVE"", TagColor.RED, True<tab><tab><tab><tab>)<tab><tab><tab><tab>return",0,if self . _entry_has_critical_rating ( entry ) :,"if entry [ ""score2"" ] == ""6.4"" :",0.019345087832959386,3.4857116957065437,0.4772727272727273
"def _validate(self):<tab>try:<tab><tab>super(CustomClassifier, self)._validate()<tab>except UnsupportedDataType:<tab><tab>if self.dtype in FACTOR_DTYPES:<tab><tab><tab>raise UnsupportedDataType(<tab><tab><tab><tab>typename=type(self).__name__,<tab><tab><tab><tab>dtype=self.dtype,<tab><tab><tab><tab>hint=""Did you mean to create a CustomFactor?"",<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise UnsupportedDataType(<tab><tab><tab><tab>typename=type(self).__name__,<tab><tab><tab><tab>dtype=self.dtype,<tab><tab><tab><tab>hint=""Did you mean to create a CustomFilter?"",<tab><tab><tab>)<tab><tab>raise",1,elif self . dtype in FILTER_DTYPES :,elif self . dtype in FILTER_DTYPES :,0.75,100.00000000000004,1.0
"def formatMessage(self, record):<tab>recordcopy = copy(record)<tab>levelname = recordcopy.levelname<tab>seperator = "" "" * (8 - len(recordcopy.levelname))<tab>if self.use_colors:<tab><tab>levelname = self.color_level_name(levelname, recordcopy.levelno)<tab><tab><IF-STMT><tab><tab><tab>recordcopy.msg = recordcopy.__dict__[""color_message""]<tab><tab><tab>recordcopy.__dict__[""message""] = recordcopy.getMessage()<tab>recordcopy.__dict__[""levelprefix""] = levelname + "":"" + seperator<tab>return super().formatMessage(recordcopy)",0,"if ""color_message"" in recordcopy . __dict__ :",if recordcopy . msg is None :,0.04282569298264552,4.981224652850502,0.23809523809523808
"def dumpregs(self):<tab>for reg in (<tab><tab>list(self.regs.retaddr)<tab><tab>+ list(self.regs.misc)<tab><tab>+ list(self.regs.common)<tab><tab>+ list(self.regs.flags)<tab>):<tab><tab>enum = self.get_reg_enum(reg)<tab><tab><IF-STMT><tab><tab><tab>debug(""# Could not dump register %r"" % reg)<tab><tab><tab>continue<tab><tab>name = ""U.x86_const.UC_X86_REG_%s"" % reg.upper()<tab><tab>value = self.uc.reg_read(enum)<tab><tab>debug(""uc.reg_read(%(name)s) ==> %(value)x"" % locals())",0,if not reg or enum is None :,if enum is None :,0.19460115769714778,38.80684294761701,0.175
"def filter(self, lexer, stream):<tab>current_type = None<tab>current_value = None<tab>for ttype, value in stream:<tab><tab>if ttype is current_type:<tab><tab><tab>current_value += value<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield current_type, current_value<tab><tab><tab>current_type = ttype<tab><tab><tab>current_value = value<tab>if current_type is not None:<tab><tab>yield current_type, current_value",1,if current_type is not None :,if current_type is not None :,0.75,100.00000000000004,1.0
"def _get_between(content, start, end=None):<tab>should_yield = False<tab>for line in content.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if end and end in line:<tab><tab><tab>return<tab><tab>if should_yield and line:<tab><tab><tab>yield line.strip().split("" "")[0]",0,if start in line :,if start and start in line :,0.43174341584494813,46.713797772820016,0.3611111111111111
"def parse_git_config(path):<tab>""""""Parse git config file.""""""<tab>config = dict()<tab>section = None<tab>with open(os.path.join(path, ""config""), ""r"") as f:<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab>if line.startswith(""[""):<tab><tab><tab><tab>section = line[1:-1].strip()<tab><tab><tab><tab>config[section] = dict()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key, value = line.replace("" "", """").split(""="")<tab><tab><tab><tab>config[section][key] = value<tab>return config",1,elif section :,elif section :,0.5143161313935813,1e-10,1.0
"def test_has_arg(fn, name, accept_all, expected):<tab>if isinstance(fn, str):<tab><tab>context = dict()<tab><tab>try:<tab><tab><tab>exec(""def {}: pass"".format(fn), context)<tab><tab>except SyntaxError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>pytest.skip(""Function is not compatible with Python 2"")<tab><tab># Sometimes exec adds builtins to the context<tab><tab>context.pop(""__builtins__"", None)<tab><tab>(fn,) = context.values()<tab>assert has_arg(fn, name, accept_all) is expected",0,"if sys . version_info >= ( 3 , ) :",if sys . version_info [ 0 ] != 3 :,0.19026235852945703,42.11813371894876,0.5846153846153846
"def ObjectExpression(self, properties, **kwargs):<tab>data = []<tab>for prop in properties:<tab><tab>self.emit(prop[""value""])<tab><tab><IF-STMT><tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""ECMA 5.1 does not support computed object properties!""<tab><tab><tab>)<tab><tab>data.append((to_key(prop[""key""]), prop[""kind""][0]))<tab>self.emit(""LOAD_OBJECT"", tuple(data))",0,"if prop [ ""computed"" ] :","if ""kind"" not in prop :",0.028043015323814018,8.25791079503452,0.3333333333333333
"def run(self):<tab>for domain, locale, po in self.locales:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(""locale"", locale, ""LC_MESSAGES"")<tab><tab>else:<tab><tab><tab>path = os.path.join(self.build_dir, locale, ""LC_MESSAGES"")<tab><tab>mo = os.path.join(path, ""%s.mo"" % domain)<tab><tab>self.mkpath(path)<tab><tab>self.spawn([""msgfmt"", ""-o"", mo, po])",0,if self . inplace :,"if domain == ""default"" :",0.03412306583404374,6.567274736060395,0.36
"def _compute_map(self, first_byte, second_byte=None):<tab>if first_byte != 0x0F:<tab><tab>return ""XED_ILD_MAP0""<tab>else:<tab><tab>if second_byte == None:<tab><tab><tab>return ""XED_ILD_MAP1""<tab><tab>if second_byte == 0x38:<tab><tab><tab>return ""XED_ILD_MAP2""<tab><tab><IF-STMT><tab><tab><tab>return ""XED_ILD_MAP3""<tab><tab>if second_byte == 0x0F and self.amd_enabled:<tab><tab><tab>return ""XED_ILD_MAPAMD""<tab>die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",0,if second_byte == 0x3A :,if second_byte == 0x40 and self . amd_enabled :,0.18855955653510317,36.362270465000705,0.3055555555555556
"def parse_tag(self):<tab>buf = []<tab>escaped = False<tab>for c in self.get_next_chars():<tab><tab><IF-STMT><tab><tab><tab>buf.append(c)<tab><tab>elif c == ""\\"":<tab><tab><tab>escaped = True<tab><tab>elif c == "">"":<tab><tab><tab>return """".join(buf)<tab><tab>else:<tab><tab><tab>buf.append(c)<tab>raise Exception(""Unclosed tag "" + """".join(buf))",1,if escaped :,if escaped :,0.5311706625951745,1e-10,1.0
"def print_pairs(attrs=None, offset_y=0):<tab>fmt = "" ({0}:{1}) ""<tab>fmt_len = len(fmt)<tab>for bg, fg in get_fg_bg():<tab><tab>try:<tab><tab><tab>color = curses.color_pair(pair_number(fg, bg))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for attr in attrs:<tab><tab><tab><tab><tab>color |= attr<tab><tab><tab>screen.addstr(offset_y + bg, fg * fmt_len, fmt.format(fg, bg), color)<tab><tab><tab>pass<tab><tab>except curses.error:<tab><tab><tab>pass",0,if not attrs is None :,if attrs is not None :,0.31756000774035176,25.40663740773074,0.5
"def _impl(inputs, input_types):<tab>data = inputs[0]<tab>axis = None<tab>keepdims = False<tab>if len(inputs) > 2:  # default, torch have only data, axis=None, keepdims=False<tab><tab><IF-STMT><tab><tab><tab>axis = int(inputs[1])<tab><tab>elif _is_int_seq(inputs[1]):<tab><tab><tab>axis = inputs[1]<tab><tab>else:<tab><tab><tab>axis = list(_infer_shape(inputs[1]))<tab><tab>keepdims = bool(inputs[2])<tab>return get_relay_op(name)(data, axis=axis, keepdims=keepdims)",0,"if isinstance ( inputs [ 1 ] , int ) :",if _is_int_seq ( inputs [ 1 ] ) :,0.26944389264150637,32.55964126200301,0.30952380952380953
"def run(self, args, **kwargs):<tab># Filtering options<tab>if args.trace_tag:<tab><tab>kwargs[""trace_tag""] = args.trace_tag<tab>if args.trigger_instance:<tab><tab>kwargs[""trigger_instance""] = args.trigger_instance<tab>if args.execution:<tab><tab>kwargs[""execution""] = args.execution<tab>if args.rule:<tab><tab>kwargs[""rule""] = args.rule<tab>if args.sort_order:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""sort_asc""] = True<tab><tab>elif args.sort_order in [""desc"", ""descending""]:<tab><tab><tab>kwargs[""sort_desc""] = True<tab>return self.manager.query_with_count(limit=args.last, **kwargs)",0,"if args . sort_order in [ ""asc"" , ""ascending"" ] :","if args . sort_order in [ ""asc"" , ""descending"" ] :",0.6221967289603358,82.82477531331043,1.0
def retaddr():<tab>sp = pwndbg.regs.sp<tab>stack = pwndbg.vmmap.find(sp)<tab># Enumerate all return addresses<tab>frame = gdb.newest_frame()<tab>addresses = []<tab>while frame:<tab><tab>addresses.append(frame.pc())<tab><tab>frame = frame.older()<tab># Find all of them on the stack<tab>start = stack.vaddr<tab>stop = start + stack.memsz<tab>while addresses and start < sp < stop:<tab><tab>value = pwndbg.memory.u(sp)<tab><tab><IF-STMT><tab><tab><tab>index = addresses.index(value)<tab><tab><tab>del addresses[:index]<tab><tab><tab>print(pwndbg.chain.format(sp))<tab><tab>sp += pwndbg.arch.ptrsize,1,if value in addresses :,if value in addresses :,0.75,100.00000000000004,1.0
"def update_from_dictio(self, dictio_item):<tab>for index, dictio_payload in enumerate(dictio_item, 1):<tab><tab>fuzz_payload = None<tab><tab>for fuzz_payload in self.payloads[index]:<tab><tab><tab>fuzz_payload.content = dictio_payload.content<tab><tab><tab>fuzz_payload.type = dictio_payload.type<tab><tab># payload generated not used in seed but in filters<tab><tab><IF-STMT><tab><tab><tab>self.add(<tab><tab><tab><tab>{""full_marker"": None, ""word"": None, ""index"": index, ""field"": None},<tab><tab><tab><tab>dictio_item[index - 1],<tab><tab><tab>)",0,if fuzz_payload is None :,if fuzz_payload is not None :,0.2721091316413796,59.4603557501361,0.5599999999999999
"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab><IF-STMT><tab><tab><tab>result = result.encode(""ascii"")<tab><tab>if isinstance(expected, str):<tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab>if contains:<tab><tab><tab>if eline not in rline:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True",1,"if isinstance ( result , str ) :","if isinstance ( result , str ) :",0.75,100.00000000000004,1.0
"def execute_sql(self, sql, params=None, commit=True):<tab>try:<tab><tab>cursor = super(RetryOperationalError, self).execute_sql(sql, params, commit)<tab>except OperationalError:<tab><tab>if not self.is_closed():<tab><tab><tab>self.close()<tab><tab>with __exception_wrapper__:<tab><tab><tab>cursor = self.cursor()<tab><tab><tab>cursor.execute(sql, params or ())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.commit()<tab>return cursor",0,if commit and not self . in_transaction ( ) :,if not self . is_commitable ( ) :,0.149319208537004,23.11111848486415,0.3055555555555556
"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab>if isinstance(definition, ast.OperationDefinition):<tab><tab><tab>if not operation_name:<tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab>elif definition.name and definition.name.value == operation_name:<tab><tab><tab><tab>return definition<tab>return operation",0,if operation :,if operation is None :,0.09791453445388575,1e-10,0.5
"def removeTrailingWs(self, aList):<tab>i = 0<tab>while i < len(aList):<tab><tab>if self.is_ws(aList[i]):<tab><tab><tab>j = i<tab><tab><tab>i = self.skip_ws(aList, i)<tab><tab><tab>assert j < i<tab><tab><tab><IF-STMT><tab><tab><tab><tab># print ""removing trailing ws:"", `i-j`<tab><tab><tab><tab>del aList[j:i]<tab><tab><tab><tab>i = j<tab><tab>else:<tab><tab><tab>i += 1",0,"if i >= len ( aList ) or aList [ i ] == ""\n"" :",if aList [ j ] == aList [ j - 1 ] :,0.14845208389458722,9.73885220662316,0.30514705882352944
"def _process_filter(self, query, host_state):<tab>""""""Recursively parse the query structure.""""""<tab>if not query:<tab><tab>return True<tab>cmd = query[0]<tab>method = self.commands[cmd]<tab>cooked_args = []<tab>for arg in query[1:]:<tab><tab><IF-STMT><tab><tab><tab>arg = self._process_filter(arg, host_state)<tab><tab>elif isinstance(arg, basestring):<tab><tab><tab>arg = self._parse_string(arg, host_state)<tab><tab>if arg is not None:<tab><tab><tab>cooked_args.append(arg)<tab>result = method(self, cooked_args)<tab>return result",1,"if isinstance ( arg , list ) :","if isinstance ( arg , list ) :",0.75,100.00000000000004,1.0
"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab>if child.tag in (""mw"", ""hi"", ""corr"", ""trunc""):<tab><tab><tab>sent += [self.handle_word(w) for w in child]<tab><tab>elif child.tag in (""w"", ""c""):<tab><tab><tab>sent.append(self.handle_word(child))<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return BNCSentence(elt.attrib[""n""], sent)",0,elif child . tag not in self . tags_to_ignore :,"elif ""n"" not in elt . attrib :",0.028411306884570386,7.073666451977357,0.20987654320987653
"def get_display_price(<tab>base: Union[TaxedMoney, TaxedMoneyRange], display_gross: bool = False) -> Money:<tab>""""""Return the price amount that should be displayed based on settings.""""""<tab>if not display_gross:<tab><tab>display_gross = display_gross_prices()<tab>if isinstance(base, TaxedMoneyRange):<tab><tab><IF-STMT><tab><tab><tab>base = MoneyRange(start=base.start.gross, stop=base.stop.gross)<tab><tab>else:<tab><tab><tab>base = MoneyRange(start=base.start.net, stop=base.stop.net)<tab>if isinstance(base, TaxedMoney):<tab><tab>base = base.gross if display_gross else base.net<tab>return base",1,if display_gross :,if display_gross :,0.5311706625951745,1e-10,1.0
"def check_classes(self, node):<tab>if isinstance(node, nodes.Element):<tab><tab>for class_value in node[""classes""][:]:<tab><tab><tab>if class_value in self.strip_classes:<tab><tab><tab><tab>node[""classes""].remove(class_value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 1",0,if class_value in self . strip_elements :,"if len ( node [ ""classes"" ] ) == 0 :",0.017147649149083143,3.377156414337854,0.2761904761904762
"def validate(outfile=sys.stdout, silent_success=False):<tab>""Validates all installed models.""<tab>try:<tab><tab>num_errors = get_validation_errors(outfile)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>outfile.write(<tab><tab><tab>""%s error%s found.\n"" % (num_errors, num_errors != 1 and ""s"" or """")<tab><tab>)<tab>except ImproperlyConfigured:<tab><tab>outfile.write(""Skipping validation because things aren't configured properly."")",0,if silent_success and num_errors == 0 :,if silent_success and num_errors == 1 :,0.574113272471593,82.651681837938,0.6
"def check_basename_conflicts(self, targets):<tab>""""""Apps' basenames are used as bundle directory names. Ensure they are all unique.""""""<tab>basename_seen = {}<tab>for target in targets:<tab><tab><IF-STMT><tab><tab><tab>raise self.BasenameConflictError(<tab><tab><tab><tab>""Basename must be unique, found two targets use ""<tab><tab><tab><tab>""the same basename: {}'\n\t{} and \n\t{}"".format(<tab><tab><tab><tab><tab>target.basename,<tab><tab><tab><tab><tab>basename_seen[target.basename].address.spec,<tab><tab><tab><tab><tab>target.address.spec,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>basename_seen[target.basename] = target",1,if target . basename in basename_seen :,if target . basename in basename_seen :,0.75,100.00000000000004,1.0
"def __init__(self, api_version_str):<tab>try:<tab><tab>self.latest = self.preview = False<tab><tab>self.yyyy = self.mm = self.dd = None<tab><tab><IF-STMT><tab><tab><tab>self.latest = True<tab><tab>else:<tab><tab><tab>if ""preview"" in api_version_str:<tab><tab><tab><tab>self.preview = True<tab><tab><tab>parts = api_version_str.split(""-"")<tab><tab><tab>self.yyyy = int(parts[0])<tab><tab><tab>self.mm = int(parts[1])<tab><tab><tab>self.dd = int(parts[2])<tab>except (ValueError, TypeError):<tab><tab>raise ValueError(<tab><tab><tab>""The API version {} is not in a "" ""supported format"".format(api_version_str)<tab><tab>)",0,"if api_version_str == ""latest"" :","if api_version_str == """" :",0.39477865547525276,77.72460244048297,1.0
"def _osp2ec(self, bytes):<tab>compressed = self._from_bytes(bytes)<tab>y = compressed >> self._bits<tab>x = compressed & (1 << self._bits) - 1<tab>if x == 0:<tab><tab>y = self._curve.b<tab>else:<tab><tab>result = self.sqrtp(<tab><tab><tab>x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>y = result[0]<tab><tab>elif len(result) == 2:<tab><tab><tab>y1, y2 = result<tab><tab><tab>y = y1 if (y1 & 1 == y) else y2<tab><tab>else:<tab><tab><tab>return None<tab>return ec.Point(self._curve, x, y)",1,if len ( result ) == 1 :,if len ( result ) == 1 :,0.75,100.00000000000004,1.0
"def _visit_import_alike(self, node: Union[cst.Import, cst.ImportFrom]) -> bool:<tab>names = node.names<tab>if isinstance(names, cst.ImportStar):<tab><tab>return False<tab># make sure node.names is Sequence[ImportAlias]<tab>for name in names:<tab><tab>self.provider.set_metadata(name, self.scope)<tab><tab>asname = name.asname<tab><tab><IF-STMT><tab><tab><tab>name_values = _gen_dotted_names(cst.ensure_type(asname.name, cst.Name))<tab><tab>else:<tab><tab><tab>name_values = _gen_dotted_names(name.name)<tab><tab>for name_value, _ in name_values:<tab><tab><tab>self.scope.record_assignment(name_value, node)<tab>return False",1,if asname is not None :,if asname is not None :,0.75,100.00000000000004,1.0
"def test_sanity_no_unmatched_parentheses(CorpusType: Type[ColumnCorpus]):<tab>corpus = CorpusType()<tab>unbalanced_entities = []<tab>for sentence in corpus.get_all_sentences():<tab><tab>entities = sentence.get_spans(""ner"")<tab><tab>for entity in entities:<tab><tab><tab>entity_text = """".join(t.text for t in entity.tokens)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>unbalanced_entities.append(entity_text)<tab>assert unbalanced_entities == []",0,if not has_balanced_parantheses ( entity_text ) :,if entity_text not in unbalanced_entities :,0.024622118794093276,14.301399262246576,0.7222222222222222
"def _learn_rate_adjust(self):<tab>if self.learn_rate_decays == 1.0:<tab><tab>return<tab>learn_rate_decays = self._vp(self.learn_rate_decays)<tab>learn_rate_minimums = self._vp(self.learn_rate_minimums)<tab>for index, decay in enumerate(learn_rate_decays):<tab><tab>new_learn_rate = self.net_.learnRates[index] * decay<tab><tab><IF-STMT><tab><tab><tab>self.net_.learnRates[index] = new_learn_rate<tab>if self.verbose >= 2:<tab><tab>print(""Learn rates: {}"".format(self.net_.learnRates))",0,if new_learn_rate >= learn_rate_minimums [ index ] :,if new_learn_rate > self . net_learnRates [ index ] :,0.18362520158236956,50.95172447616117,0.48333333333333334
"def set_attr_from_xmp_tag(self, attr, xmp_tags, tags, cast=None):<tab>v = self.get_xmp_tag(xmp_tags, tags)<tab>if v is not None:<tab><tab><IF-STMT><tab><tab><tab>setattr(self, attr, v)<tab><tab>else:<tab><tab><tab># Handle fractions<tab><tab><tab>if (cast == float or cast == int) and ""/"" in v:<tab><tab><tab><tab>v = self.try_parse_fraction(v)<tab><tab><tab>setattr(self, attr, cast(v))",1,if cast is None :,if cast is None :,0.75,100.00000000000004,1.0
"def _merge_scientific_float_tokens(tokens: Iterable[str]) -> List[str]:<tab>tokens = list(tokens)<tab>i = 0<tab>while ""e"" in tokens[i + 1 :]:<tab><tab>i = tokens.index(""e"", i + 1)<tab><tab>s = i - 1<tab><tab>e = i + 1<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if re.match(""[+-]"", str(tokens[e])):<tab><tab><tab>e += 1<tab><tab>if re.match(""[0-9]"", str(tokens[e])):<tab><tab><tab>e += 1<tab><tab><tab>tokens[s:e] = ["""".join(tokens[s:e])]<tab><tab><tab>i -= 1<tab>return tokens",0,"if not re . match ( ""[0-9]"" , str ( tokens [ s ] ) ) :","if e == ""e"" :",0.005718208455946098,1.197679263629884,0.2
"def anypython(request):<tab>name = request.param<tab>executable = getexecutable(name)<tab>if executable is None:<tab><tab><IF-STMT><tab><tab><tab>executable = winpymap.get(name, None)<tab><tab><tab>if executable:<tab><tab><tab><tab>executable = py.path.local(executable)<tab><tab><tab><tab>if executable.check():<tab><tab><tab><tab><tab>return executable<tab><tab>pytest.skip(""no suitable %s found"" % (name,))<tab>return executable",0,"if sys . platform == ""win32"" :",if name in winpymap :,0.02225082504991546,4.673289785800722,0.2653061224489796
"def set_meta(self, dataset, overwrite=True, **kwd):<tab>super().set_meta(dataset, overwrite=overwrite, **kwd)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>with tarfile.open(dataset.file_name, ""r"") as temptar:<tab><tab><tab><tab>dataset.metadata.fast5_count = sum(<tab><tab><tab><tab><tab>1 for f in temptar if f.name.endswith("".fast5"")<tab><tab><tab><tab>)<tab>except Exception as e:<tab><tab>log.warning(""%s, set_meta Exception: %s"", self, e)",0,if dataset and tarfile . is_tarfile ( dataset . file_name ) :,if overwrite :,0.00788391111257661,1e-10,0.30392156862745096
"def run(self):<tab>for k in list(iterkeys(self.objs)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>v = self.objs[k]<tab><tab>if v[""_class""] == ""User"":<tab><tab><tab>self.split_user(k, v)<tab><tab>elif v[""_class""] in [<tab><tab><tab>""Message"",<tab><tab><tab>""PrintJob"",<tab><tab><tab>""Question"",<tab><tab><tab>""Submission"",<tab><tab><tab>""UserTest"",<tab><tab>]:<tab><tab><tab>v[""participation""] = v[""user""]<tab><tab><tab>del v[""user""]<tab>return self.objs",1,"if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",0.75,100.00000000000004,1.0
"def _findInTree(t, n):<tab>ret = []<tab>if type(t) is dict:<tab><tab><IF-STMT><tab><tab><tab>ret.append(t)<tab><tab>for k, v in t.items():<tab><tab><tab>ret += _findInTree(v, n)<tab>if type(t) is list:<tab><tab>for v in t:<tab><tab><tab>ret += _findInTree(v, n)<tab>return ret",0,"if ""_name"" in t and t [ ""_name"" ] == n :",if len ( t ) == n :,0.04949642924785472,10.873785310674286,0.36054421768707484
"def parseArrayPattern(self):<tab>node = Node()<tab>elements = []<tab>self.expect(""["")<tab>while not self.match(""]""):<tab><tab><IF-STMT><tab><tab><tab>self.lex()<tab><tab><tab>elements.append(null)<tab><tab>else:<tab><tab><tab>if self.match(""...""):<tab><tab><tab><tab>restNode = Node()<tab><tab><tab><tab>self.lex()<tab><tab><tab><tab>rest = self.parseVariableIdentifier()<tab><tab><tab><tab>elements.append(restNode.finishRestElement(rest))<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>elements.append(self.parsePatternWithDefault())<tab><tab><tab>if not self.match(""]""):<tab><tab><tab><tab>self.expect("","")<tab>self.expect(""]"")<tab>return node.finishArrayPattern(elements)",0,"if self . match ( "","" ) :","if self . match ( ""]"" ) :",0.5490406812970063,65.80370064762461,1.0
"def _set_log_writer(self):<tab>if self.config[""logging""]:<tab><tab>config = self.config[""log_writer_config""]<tab><tab><IF-STMT><tab><tab><tab>self.log_writer = LogWriter(**config)<tab><tab>elif config[""writer""] == ""tensorboard"":<tab><tab><tab>self.log_writer = TensorBoardWriter(**config)<tab><tab>else:<tab><tab><tab>raise ValueError(f""Unrecognized writer option: {config['writer']}"")<tab>else:<tab><tab>self.log_writer = None",0,"if config [ ""writer"" ] == ""json"" :","if config [ ""writer"" ] == ""log"" :",0.605621305873661,79.10665071754353,1.0
"def _parse(self, contents):<tab>entries = []<tab>hostnames_found = set()<tab>for line in contents.splitlines():<tab><tab><IF-STMT><tab><tab><tab>entries.append((""blank"", [line]))<tab><tab><tab>continue<tab><tab>(head, tail) = chop_comment(line.strip(), ""#"")<tab><tab>if not len(head):<tab><tab><tab>entries.append((""all_comment"", [line]))<tab><tab><tab>continue<tab><tab>entries.append((""hostname"", [head, tail]))<tab><tab>hostnames_found.add(head)<tab>if len(hostnames_found) > 1:<tab><tab>raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found))<tab>return entries",0,if not len ( line . strip ( ) ) :,if not line :,0.02182019517687131,6.6019821735025035,0.4761904761904762
"def get_all_values(self, project):<tab>if isinstance(project, models.Model):<tab><tab>project_id = project.id<tab>else:<tab><tab>project_id = project<tab>if project_id not in self.__cache:<tab><tab>cache_key = self._make_key(project_id)<tab><tab>result = cache.get(cache_key)<tab><tab><IF-STMT><tab><tab><tab>result = self.reload_cache(project_id)<tab><tab>else:<tab><tab><tab>self.__cache[project_id] = result<tab>return self.__cache.get(project_id, {})",1,if result is None :,if result is None :,0.75,100.00000000000004,1.0
"def needed_libraries(self):<tab>for cmd in self.load_commands_of_type(0xC):  # LC_LOAD_DYLIB<tab><tab>tname = self._get_typename(""dylib_command"")<tab><tab>dylib_command = cmd.cast(tname)<tab><tab>name_addr = cmd.obj_offset + dylib_command.name<tab><tab>dylib_name = self.obj_vm.read(name_addr, 256)<tab><tab><IF-STMT><tab><tab><tab>idx = dylib_name.find(""\x00"")<tab><tab><tab>if idx != -1:<tab><tab><tab><tab>dylib_name = dylib_name[:idx]<tab><tab><tab>yield dylib_name",1,if dylib_name :,if dylib_name :,0.5311706625951745,1e-10,1.0
"def compress(self, data_list):<tab>warn_untested()<tab>if data_list:<tab><tab><IF-STMT><tab><tab><tab>error = self.error_messages[""invalid_year""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab>if data_list[0] in forms.fields.EMPTY_VALUES:<tab><tab><tab>error = self.error_messages[""invalid_month""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab>year = int(data_list[1])<tab><tab>month = int(data_list[0])<tab><tab># find last day of the month<tab><tab>day = monthrange(year, month)[1]<tab><tab>return date(year, month, day)<tab>return None",1,if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,0.75,100.00000000000004,1.0
"def put(self, obj, block=True, timeout=None):<tab>assert not self._closed<tab>if not self._sem.acquire(block, timeout):<tab><tab>raise Full<tab>with self._notempty:<tab><tab>with self._cond:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._start_thread()<tab><tab><tab>self._buffer.append(obj)<tab><tab><tab>self._unfinished_tasks.release()<tab><tab><tab>self._notempty.notify()",1,if self . _thread is None :,if self . _thread is None :,0.75,100.00000000000004,1.0
"def has_module(self, module, version):<tab>has_module = False<tab>for directory in self.directories:<tab><tab>module_directory = join(directory, module)<tab><tab>has_module_directory = isdir(module_directory)<tab><tab>if not version:<tab><tab><tab>has_module = has_module_directory or exists(<tab><tab><tab><tab>module_directory<tab><tab><tab>)  # could be a bare modulefile<tab><tab>else:<tab><tab><tab>modulefile = join(module_directory, version)<tab><tab><tab>has_modulefile = exists(modulefile)<tab><tab><tab>has_module = has_module_directory and has_modulefile<tab><tab><IF-STMT><tab><tab><tab>break<tab>return has_module",1,if has_module :,if has_module :,0.5311706625951745,1e-10,1.0
"def expanduser(path):<tab>if path[:1] == ""~"":<tab><tab>c = path[1:2]<tab><tab><IF-STMT><tab><tab><tab>return gethome()<tab><tab>if c == os.sep:<tab><tab><tab>return asPyString(File(gethome(), path[2:]).getPath())<tab>return path",0,if not c :,if c == os . path . home ( ) :,0.033674985025069736,4.456882760699063,0.2653061224489796
"def mock_touch(self, bearer, version=None, revision=None, **kwargs):<tab>if version:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return self.versions[int(version) - 1]<tab><tab><tab>except (IndexError, ValueError):<tab><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>return None<tab>return file_models.FileVersion()",0,if self . versions :,if int ( version ) > 0 :,0.026407399022921448,6.567274736060395,0.2698412698412698
"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab>if member[0] == key:<tab><tab><tab><tab>field_value = member[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>wildcards = member[1]<tab><tab>if key == ""nw_src"":<tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab>elif key == ""nw_dst"":<tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value",0,"elif member [ 0 ] == ""wildcards"" :",elif len ( member ) == 2 :,0.019640732545025658,9.600960275119885,0.3148148148148148
"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(result, str):<tab><tab><tab>result = result.encode(""ascii"")<tab><tab>if isinstance(expected, str):<tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab><IF-STMT><tab><tab><tab>if eline not in rline:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True",1,if contains :,if contains :,0.5311706625951745,1e-10,1.0
"def OnKeyUp(self, event):<tab>if self._properties.modifiable:<tab><tab>if event.GetKeyCode() == wx.WXK_ESCAPE:<tab><tab><tab>self._cancel_editing()<tab><tab><IF-STMT><tab><tab><tab>self._update_value()<tab><tab>elif event.GetKeyCode() == wx.WXK_DELETE:<tab><tab><tab>self.SetValue("""")<tab>if event.GetKeyCode() != wx.WXK_RETURN:<tab><tab># Don't send skip event if enter key is pressed<tab><tab># On some platforms this event is sent too late and causes crash<tab><tab>event.Skip()",0,elif event . GetKeyCode ( ) == wx . WXK_RETURN :,elif event . GetKeyCode ( ) == wx . WXK_UPDATE :,0.653527863746399,85.5526185871245,1.0
"def load_modules(<tab>to_load, load, attr, modules_dict, excluded_aliases, loading_message=None):<tab>if loading_message:<tab><tab>print(loading_message)<tab>for name in to_load:<tab><tab>module = load(name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>cls = getattr(module, attr)<tab><tab>if hasattr(cls, ""initialize"") and not cls.initialize():<tab><tab><tab>continue<tab><tab>if hasattr(module, ""aliases""):<tab><tab><tab>for alias in module.aliases():<tab><tab><tab><tab>if alias not in excluded_aliases:<tab><tab><tab><tab><tab>modules_dict[alias] = module<tab><tab>else:<tab><tab><tab>modules_dict[name] = module<tab>if loading_message:<tab><tab>print()",0,"if module is None or not hasattr ( module , attr ) :",if not module :,0.009102728460279921,2.3809737623256155,0.1746031746031746
def eventIterator():<tab>while True:<tab><tab>yield eventmodule.wait()<tab><tab>while True:<tab><tab><tab>event = eventmodule.poll()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>yield event,0,if event . type == NOEVENT :,if event is None :,0.04240600921794552,12.975849993980741,0.42857142857142855
"def _get_state_without_padding(self, state_with_padding, padding):<tab>lean_state = {}<tab>for key, value in state_with_padding.items():<tab><tab><IF-STMT><tab><tab><tab>lean_length = value.numel() - padding<tab><tab><tab>lean_state[key] = value[:lean_length]<tab><tab>else:<tab><tab><tab>lean_state[key] = value<tab>return lean_state",0,if torch . is_tensor ( value ) :,if len ( value ) > padding :,0.14241956560314192,18.190371142855746,0.48148148148148145
"def _get_validate(data):<tab>""""""Retrieve items to validate, from single samples or from combined joint calls.""""""<tab>if data.get(""vrn_file"") and tz.get_in([""config"", ""algorithm"", ""validate""], data):<tab><tab>return utils.deepish_copy(data)<tab>elif ""group_orig"" in data:<tab><tab>for sub in multi.get_orig_items(data):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub_val = utils.deepish_copy(sub)<tab><tab><tab><tab>sub_val[""vrn_file""] = data[""vrn_file""]<tab><tab><tab><tab>return sub_val<tab>return None",0,"if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :","if sub . get ( ""vrn_file"" ) and data [ ""vrn_file"" ] :",0.023761003125560023,9.846107951428584,0.2698412698412698
"def OnPopup(self, form, popup_handle):<tab>for num, action_name, menu_name, shortcut in self.actions:<tab><tab><IF-STMT><tab><tab><tab>ida_kernwin.attach_action_to_popup(form, popup_handle, None)<tab><tab>else:<tab><tab><tab>handler = command_handler_t(self, num, 2)<tab><tab><tab>desc = ida_kernwin.action_desc_t(action_name, menu_name, handler, shortcut)<tab><tab><tab>ida_kernwin.attach_dynamic_action_to_popup(form, popup_handle, desc)",0,if menu_name is None :,if num == 0 :,0.03412306583404374,8.170609724417774,0.3333333333333333
"def show(self, indent=0):<tab>""""""Pretty print this structure.""""""<tab>if indent == 0:<tab><tab>print(""struct {}"".format(self.name))<tab>for field in self.fields:<tab><tab><IF-STMT><tab><tab><tab>offset = ""0x??""<tab><tab>else:<tab><tab><tab>offset = ""0x{:02x}"".format(field.offset)<tab><tab>print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type))<tab><tab>if isinstance(field.type, Structure):<tab><tab><tab>field.type.show(indent + 1)",1,if field . offset is None :,if field . offset is None :,0.75,100.00000000000004,1.0
"def get_operation_ast(document_ast, operation_name=None):<tab>operation = None<tab>for definition in document_ast.definitions:<tab><tab><IF-STMT><tab><tab><tab>if not operation_name:<tab><tab><tab><tab># If no operation name is provided, only return an Operation if it is the only one present in the<tab><tab><tab><tab># document. This means that if we've encountered a second operation as we were iterating over the<tab><tab><tab><tab># definitions in the document, there are more than one Operation defined, and we should return None.<tab><tab><tab><tab>if operation:<tab><tab><tab><tab><tab>return None<tab><tab><tab><tab>operation = definition<tab><tab><tab>elif definition.name and definition.name.value == operation_name:<tab><tab><tab><tab>return definition<tab>return operation",0,"if isinstance ( definition , ast . OperationDefinition ) :",if definition . name and definition . name . value == operation_name :,0.06365099987387574,3.4585921141027365,0.20634920634920637
"def getSubMenu(self, callingWindow, context, mainItem, selection, rootMenu, i, pitem):<tab>msw = True if ""wxMSW"" in wx.PlatformInfo else False<tab>self.context = context<tab>self.abilityIds = {}<tab>sub = wx.Menu()<tab>for ability in self.fighter.abilities:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>menuItem = self.addAbility(rootMenu if msw else sub, ability)<tab><tab>sub.Append(menuItem)<tab><tab>menuItem.Check(ability.active)<tab>return sub",0,if not ability . effect . isImplemented :,if ability . disabled :,0.03730445553501224,13.943458243384402,0.25
"def consume(self, event: Dict[str, Any]) -> None:<tab>with self.lock:<tab><tab>logging.debug(""Received missedmessage_emails event: %s"", event)<tab><tab># When we process an event, just put it into the queue and ensure we have a timer going.<tab><tab>user_profile_id = event[""user_profile_id""]<tab><tab><IF-STMT><tab><tab><tab>self.batch_start_by_recipient[user_profile_id] = time.time()<tab><tab>self.events_by_recipient[user_profile_id].append(event)<tab><tab>self.ensure_timer()",1,if user_profile_id not in self . batch_start_by_recipient :,if user_profile_id not in self . batch_start_by_recipient :,0.75,100.00000000000004,1.0
"def __init__(self, start_enabled=False, use_hardware=True):<tab>self._use_hardware = use_hardware<tab>if use_hardware:<tab><tab>self._button = Button(BUTTON_GPIO_PIN)<tab><tab>self._enabled = start_enabled<tab><tab><IF-STMT><tab><tab><tab>self._button.when_pressed = self._enable",0,if not start_enabled :,if self . _enabled :,0.04240785919217091,32.46679154750991,0.5
"def execute(cls, ctx, op: ""DataFrameGroupByAgg""):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab><IF-STMT><tab><tab><tab>cls._execute_map(ctx, op)<tab><tab>elif op.stage == OperandStage.combine:<tab><tab><tab>cls._execute_combine(ctx, op)<tab><tab>elif op.stage == OperandStage.agg:<tab><tab><tab>cls._execute_agg(ctx, op)<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise ValueError(""Aggregation operand not executable"")<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",1,if op . stage == OperandStage . map :,if op . stage == OperandStage . map :,0.75,100.00000000000004,1.0
"def load_package(name, path):<tab>if os.path.isdir(path):<tab><tab>extensions = machinery.SOURCE_SUFFIXES[:] + machinery.BYTECODE_SUFFIXES[:]<tab><tab>for extension in extensions:<tab><tab><tab>init_path = os.path.join(path, ""__init__"" + extension)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path = init_path<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>raise ValueError(""{!r} is not a package"".format(path))<tab>spec = util.spec_from_file_location(name, path, submodule_search_locations=[])<tab>if name in sys.modules:<tab><tab>return _exec(spec, sys.modules[name])<tab>else:<tab><tab>return _load(spec)",0,if os . path . exists ( init_path ) :,if os . path . isfile ( init_path ) :,0.5803088707179008,73.48889200874659,0.6666666666666666
def setup(level=None):<tab>from pipeline.logging import pipeline_logger as logger<tab>from pipeline.log.handlers import EngineLogHandler<tab>if level in set(logging._levelToName.values()):<tab><tab>logger.setLevel(level)<tab>logging._acquireLock()<tab>try:<tab><tab>for hdl in logger.handlers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>hdl = EngineLogHandler()<tab><tab><tab>hdl.setLevel(logger.level)<tab><tab><tab>logger.addHandler(hdl)<tab>finally:<tab><tab>logging._releaseLock(),0,"if isinstance ( hdl , EngineLogHandler ) :",if hdl . level == logger . level :,0.01809616860937894,5.522397783539471,0.2698412698412698
"def find_approximant(x):<tab>c = 1e-4<tab>it = sympy.ntheory.continued_fraction_convergents(<tab><tab>sympy.ntheory.continued_fraction_iterator(x)<tab>)<tab>for i in it:<tab><tab>p, q = i.as_numer_denom()<tab><tab>tol = c / q ** 2<tab><tab>if abs(i - x) <= tol:<tab><tab><tab>return i<tab><tab><IF-STMT><tab><tab><tab>break<tab>return x",0,if tol < machine_epsilon :,if abs ( p - x ) >= tol :,0.025806626984353938,4.9323515694897075,0.2948717948717949
"def resolve(<tab>self, debug: bool = False, silent: bool = False, level: Optional[int] = None) -> bool:<tab>if silent:<tab><tab>spinner = nullcontext(type(""Mock"", (), {}))<tab>else:<tab><tab>spinner = yaspin(text=""resolving..."")<tab>with spinner as spinner:<tab><tab>while True:<tab><tab><tab>resolved = self._resolve(<tab><tab><tab><tab>debug=debug, silent=silent, level=level, spinner=spinner<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self.graph.clear()  # remove unused deps from graph<tab><tab><tab>return resolved",1,if resolved is None :,if resolved is None :,0.75,100.00000000000004,1.0
"def canonicalize_instruction_name(instr):<tab>name = instr.insn_name().upper()<tab># XXX bypass a capstone bug that incorrectly labels some insns as mov<tab>if name == ""MOV"":<tab><tab><IF-STMT><tab><tab><tab>return ""LSR""<tab><tab>elif instr.mnemonic.startswith(""lsl""):<tab><tab><tab>return ""LSL""<tab><tab>elif instr.mnemonic.startswith(""asr""):<tab><tab><tab>return ""ASR""<tab>return OP_NAME_MAP.get(name, name)",1,"if instr . mnemonic . startswith ( ""lsr"" ) :","if instr . mnemonic . startswith ( ""lsr"" ) :",0.75,100.00000000000004,1.0
"def run_all(rule_list, defined_variables, defined_actions, stop_on_first_trigger=False):<tab>rule_was_triggered = False<tab>for rule in rule_list:<tab><tab>result = run(rule, defined_variables, defined_actions)<tab><tab>if result:<tab><tab><tab>rule_was_triggered = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return rule_was_triggered",1,if stop_on_first_trigger :,if stop_on_first_trigger :,0.5311706625951745,1e-10,1.0
"def get_filters(self, request):<tab>filter_specs = []<tab>if self.lookup_opts.admin.list_filter and not self.opts.one_to_one_field:<tab><tab>filter_fields = [<tab><tab><tab>self.lookup_opts.get_field(field_name)<tab><tab><tab>for field_name in self.lookup_opts.admin.list_filter<tab><tab>]<tab><tab>for f in filter_fields:<tab><tab><tab>spec = FilterSpec.create(f, request, self.params, self.model)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filter_specs.append(spec)<tab>return filter_specs, bool(filter_specs)",0,if spec and spec . has_output ( ) :,if spec :,0.024814632707681465,1e-10,0.625
"def get_type(type_ref):<tab>kind = type_ref.get(""kind"")<tab>if kind == TypeKind.LIST:<tab><tab>item_ref = type_ref.get(""ofType"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Decorated type deeper than introspection query."")<tab><tab>return GraphQLList(get_type(item_ref))<tab>elif kind == TypeKind.NON_NULL:<tab><tab>nullable_ref = type_ref.get(""ofType"")<tab><tab>if not nullable_ref:<tab><tab><tab>raise Exception(""Decorated type deeper than introspection query."")<tab><tab>return GraphQLNonNull(get_type(nullable_ref))<tab>return get_named_type(type_ref[""name""])",1,if not item_ref :,if not item_ref :,0.75,100.00000000000004,1.0
"def _1_0_cloud_ips_cip_jsjc5_map(self, method, url, body, headers):<tab>if method == ""POST"":<tab><tab>body = json.loads(body)<tab><tab><IF-STMT><tab><tab><tab>return self.test_response(httplib.ACCEPTED, """")<tab><tab>else:<tab><tab><tab>data = '{""error_name"":""bad destination"", ""errors"": [""Bad destination""]}'<tab><tab><tab>return self.test_response(httplib.BAD_REQUEST, data)",0,"if ""destination"" in body :","if body [ ""status"" ] == ""accepted"" :",0.028001459970687266,4.6192151051305474,0.4772727272727273
"def _get_prefixed_values(data, prefix):<tab>""""""Collect lines which start with prefix; with trimming""""""<tab>matches = []<tab>for line in data.splitlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>match = line[len(prefix) :]<tab><tab><tab>match = match.strip()<tab><tab><tab>matches.append(match)<tab>return matches",1,if line . startswith ( prefix ) :,if line . startswith ( prefix ) :,0.75,100.00000000000004,1.0
"def _power_exact(y, xc, yc, xe):<tab>yc, ye = y.int, y.exp<tab>while yc % 10 == 0:<tab><tab>yc //= 10<tab><tab>ye += 1<tab>if xc == 1:<tab><tab>xe *= yc<tab><tab>while xe % 10 == 0:<tab><tab><tab>xe //= 10<tab><tab><tab>ye += 1<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>exponent = xe * 10 ** ye<tab><tab>if y and xe:<tab><tab><tab>xc = exponent<tab><tab>else:<tab><tab><tab>xc = 0<tab><tab>return 5",0,if ye < 0 :,if ye == 1 :,0.31497877230811644,17.965205598154213,0.6
"def init(self, view, items=None):<tab>selections = []<tab>if view.sel():<tab><tab>for region in view.sel():<tab><tab><tab>selections.append(view.substr(region))<tab>values = []<tab>for idx, index in enumerate(map(int, items)):<tab><tab>if idx >= len(selections):<tab><tab><tab>break<tab><tab>i = index - 1<tab><tab>if i >= 0 and i < len(selections):<tab><tab><tab>values.append(selections[i])<tab><tab>else:<tab><tab><tab>values.append(None)<tab># fill up<tab>for idx, value in enumerate(selections):<tab><tab><IF-STMT><tab><tab><tab>values.append(value)<tab>self.stack = values",0,if len ( values ) + 1 < idx :,if idx >= 0 and idx < len ( selections ) :,0.028026154952658866,8.450310992782928,0.2777777777777778
"def toggleFactorReload(self, value=None):<tab>self.serviceFittingOptions[""useGlobalForceReload""] = (<tab><tab>value<tab><tab>if value is not None<tab><tab>else not self.serviceFittingOptions[""useGlobalForceReload""]<tab>)<tab>fitIDs = set()<tab>for fit in set(self._loadedFits):<tab><tab>if fit is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>fit.factorReload = self.serviceFittingOptions[""useGlobalForceReload""]<tab><tab><tab>fit.clearFactorReloadDependentData()<tab><tab><tab>fitIDs.add(fit.ID)<tab>return fitIDs",0,if fit . calculated :,if fit . useGlobalForceReload :,0.39477865547525276,42.72870063962342,0.6
"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for m in self.predict_layers.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>kaiming_init(m)<tab><tab><IF-STMT><tab><tab><tab>constant_init(m, 1)<tab><tab>elif isinstance(m, nn.Linear):<tab><tab><tab>normal_init(m, std=0.01)",1,"elif isinstance ( m , nn . BatchNorm2d ) :","elif isinstance ( m , nn . BatchNorm2d ) :",0.75,100.00000000000004,1.0
"def _unzip_file(self, filepath, ext):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>zf = zipfile.ZipFile(filepath)<tab><tab><tab>zf.extractall(os.path.dirname(filepath))<tab><tab><tab>zf.close()<tab><tab>elif ext == "".tar"":<tab><tab><tab>tf = tarfile.open(filepath)<tab><tab><tab>tf.extractall(os.path.dirname(filepath))<tab><tab><tab>tf.close()<tab>except Exception as e:<tab><tab>raise ValueError(""Error reading file %r!\n%s"" % (filepath, e))",1,"if ext == "".zip"" :","if ext == "".zip"" :",0.75,100.00000000000004,1.0
"def add_multiple_tasks(data, parent):<tab>data = json.loads(data)<tab>new_doc = {<tab><tab>""doctype"": ""Task"",<tab><tab>""parent_task"": parent if parent != ""All Tasks"" else """",<tab>}<tab>new_doc[""project""] = frappe.db.get_value(""Task"", {""name"": parent}, ""project"") or """"<tab>for d in data:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>new_doc[""subject""] = d.get(""subject"")<tab><tab>new_task = frappe.get_doc(new_doc)<tab><tab>new_task.insert()",0,"if not d . get ( ""subject"" ) :","if ""subject"" not in d :",0.018728518225177467,17.461709500462998,0.5
"def filterSimilarKeywords(keyword, kwdsIterator):<tab>""""""Return a sorted list of keywords similar to the one given.""""""<tab>seenDict = {}<tab>kwdSndx = soundex(keyword.encode(""ascii"", ""ignore""))<tab>matches = []<tab>matchesappend = matches.append<tab>checkContained = False<tab>if len(keyword) > 4:<tab><tab>checkContained = True<tab>for movieID, key in kwdsIterator:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>seenDict[key] = None<tab><tab>if checkContained and keyword in key:<tab><tab><tab>matchesappend(key)<tab><tab><tab>continue<tab><tab>if kwdSndx == soundex(key.encode(""ascii"", ""ignore"")):<tab><tab><tab>matchesappend(key)<tab>return _sortKeywords(keyword, matches)",1,if key in seenDict :,if key in seenDict :,0.75,100.00000000000004,1.0
"def visit_If(self, node):<tab>self.newline()<tab>self.write(""if "")<tab>self.visit(node.test)<tab>self.write("":"")<tab>self.body(node.body)<tab>while True:<tab><tab>else_ = node.orelse<tab><tab><IF-STMT><tab><tab><tab>node = else_[0]<tab><tab><tab>self.newline()<tab><tab><tab>self.write(""elif "")<tab><tab><tab>self.visit(node.test)<tab><tab><tab>self.write("":"")<tab><tab><tab>self.body(node.body)<tab><tab>else:<tab><tab><tab>self.newline()<tab><tab><tab>self.write(""else:"")<tab><tab><tab>self.body(else_)<tab><tab><tab>break",0,"if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :","if isinstance ( else_ , tuple ) :",0.03293482945492029,10.05403140773399,0.1891025641025641
"def _eyeLinkHardwareAndSoftwareVersion(self):<tab>try:<tab><tab>tracker_software_ver = 0<tab><tab>eyelink_ver = self._eyelink.getTrackerVersion()<tab><tab><IF-STMT><tab><tab><tab>tvstr = self._eyelink.getTrackerVersionString()<tab><tab><tab>vindex = tvstr.find(""EYELINK CL"")<tab><tab><tab>tracker_software_ver = int(<tab><tab><tab><tab>float(tvstr[(vindex + len(""EYELINK CL"")) :].strip())<tab><tab><tab>)<tab><tab>return eyelink_ver, tracker_software_ver<tab>except Exception:<tab><tab>print2err(""EYELINK Error during _eyeLinkHardwareAndSoftwareVersion:"")<tab><tab>printExceptionDetailsToStdErr()<tab><tab>return EyeTrackerConstants.EYETRACKER_ERROR",0,if eyelink_ver == 3 :,if eyelink_ver is None :,0.06497877230811641,37.68499164492418,0.36
"def execute(self, context):<tab>for monad in context.blend_data.node_groups:<tab><tab>if monad.bl_idname == ""SverchGroupTreeType"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>monad.update_cls()<tab><tab><tab><tab>except Exception as err:<tab><tab><tab><tab><tab>print(err)<tab><tab><tab><tab><tab>print(""{} group class could not be created"".format(monad.name))<tab>return {""FINISHED""}",0,"if not getattr ( bpy . types , monad . cls_bl_idname , None ) :",if monad . create_cls :,0.07638722884672283,3.113082773188573,0.22023809523809523
"def word_pattern(pattern, str):<tab>dict = {}<tab>set_value = set()<tab>list_str = str.split()<tab>if len(list_str) != len(pattern):<tab><tab>return False<tab>for i in range(len(pattern)):<tab><tab>if pattern[i] not in dict:<tab><tab><tab>if list_str[i] in set_value:<tab><tab><tab><tab>return False<tab><tab><tab>dict[pattern[i]] = list_str[i]<tab><tab><tab>set_value.add(list_str[i])<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return True",0,if dict [ pattern [ i ] ] != list_str [ i ] :,if set_value . issubset ( set_value ) :,0.2591492025154218,2.9381581998927433,0.30952380952380953
"def decorator_handle(tokens):<tab>""""""Process decorators.""""""<tab>defs = []<tab>decorates = []<tab>for i, tok in enumerate(tokens):<tab><tab>if ""simple"" in tok and len(tok) == 1:<tab><tab><tab>decorates.append(""@"" + tok[0])<tab><tab><IF-STMT><tab><tab><tab>varname = decorator_var + ""_"" + str(i)<tab><tab><tab>defs.append(varname + "" = "" + tok[0])<tab><tab><tab>decorates.append(""@"" + varname)<tab><tab>else:<tab><tab><tab>raise CoconutInternalException(""invalid decorator tokens"", tok)<tab>return ""\n"".join(defs + decorates) + ""\n""",0,"elif ""test"" in tok and len ( tok ) == 1 :","elif ""var"" in tok and len ( tok ) == 1 :",0.91325840918969,82.42367502646057,1.0
"def wait_impl(self, cpid):<tab>for i in range(10):<tab><tab># wait3() shouldn't hang, but some of the buildbots seem to hang<tab><tab># in the forking tests.  This is an attempt to fix the problem.<tab><tab>spid, status, rusage = os.wait3(os.WNOHANG)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(1.0)<tab>self.assertEqual(spid, cpid)<tab>self.assertEqual(status, 0, ""cause = %d, exit = %d"" % (status & 0xFF, status >> 8))<tab>self.assertTrue(rusage)",1,if spid == cpid :,if spid == cpid :,0.75,100.00000000000004,1.0
"def test_non_uniform_probabilities_over_elements(self):<tab>param = iap.Choice([0, 1], p=[0.25, 0.75])<tab>samples = param.draw_samples((10000,))<tab>unique, counts = np.unique(samples, return_counts=True)<tab>assert len(unique) == 2<tab>for val, count in zip(unique, counts):<tab><tab><IF-STMT><tab><tab><tab>assert 2500 - 500 < count < 2500 + 500<tab><tab>elif val == 1:<tab><tab><tab>assert 7500 - 500 < count < 7500 + 500<tab><tab>else:<tab><tab><tab>assert False",1,if val == 0 :,if val == 0 :,0.75,100.00000000000004,1.0
"def dispatch_return(self, frame, arg):<tab>if self.stop_here(frame) or frame == self.returnframe:<tab><tab># Ignore return events in generator except when stepping.<tab><tab>if self.stopframe and frame.f_code.co_flags & CO_GENERATOR:<tab><tab><tab>return self.trace_dispatch<tab><tab>try:<tab><tab><tab>self.frame_returning = frame<tab><tab><tab>self.user_return(frame, arg)<tab><tab>finally:<tab><tab><tab>self.frame_returning = None<tab><tab><IF-STMT><tab><tab><tab>raise BdbQuit<tab><tab># The user issued a 'next' or 'until' command.<tab><tab>if self.stopframe is frame and self.stoplineno != -1:<tab><tab><tab>self._set_stopinfo(None, None)<tab>return self.trace_dispatch",1,if self . quitting :,if self . quitting :,0.75,100.00000000000004,1.0
"def mouse(self, button, mods, x, y):<tab>if button == 1:<tab><tab>for i in range(4):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.hit = i<tab>elif button == -1:<tab><tab>self.hit = None<tab>elif self.hit != None:<tab><tab>self.coords[self.hit] = (x, y)<tab><tab>self.view.dirty()",0,"if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 :","if self . coords [ i ] == ( x , y ) :",0.16603827890926282,15.719010513286515,0.1662971175166297
"def __init__(self, *commands):<tab>self.all_cmds = list(<tab><tab>map(lambda cmd: cmd[0] if isinstance(cmd, list) else cmd, commands)<tab>)<tab>for command in commands:<tab><tab>self.cmd = command if isinstance(command, list) else [command]<tab><tab>self.cmd_path = pwndbg.which.which(self.cmd[0])<tab><tab><IF-STMT><tab><tab><tab>break",0,if self . cmd_path :,if self . cmd_path is None :,0.36879024661621806,61.04735835807847,0.55
"def _recv_obj(self, suppress_error=False):<tab>""""""Receive a (picklable) object""""""<tab>if self.conn.closed:<tab><tab>raise OSError(""handle is closed"")<tab>try:<tab><tab>buf = self.conn.recv_bytes()<tab>except (ConnectionError, EOFError) as e:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>logger.debug(""receive has failed"", exc_info=e)<tab><tab>try:<tab><tab><tab>self._set_remote_close_cause(e)<tab><tab><tab>raise PipeShutdownError()<tab><tab>finally:<tab><tab><tab>self._close()<tab>obj = RemoteObjectUnpickler.loads(buf, self)<tab>logger.debug(""received %r"", obj)<tab>return obj",1,if suppress_error :,if suppress_error :,0.5311706625951745,1e-10,1.0
"def act(self, obs):<tab>with chainer.no_backprop_mode():<tab><tab>batch_obs = self.batch_states([obs], self.xp, self.phi)<tab><tab>action_distrib = self.model(batch_obs)<tab><tab><IF-STMT><tab><tab><tab>return chainer.cuda.to_cpu(action_distrib.most_probable.array)[0]<tab><tab>else:<tab><tab><tab>return chainer.cuda.to_cpu(action_distrib.sample().array)[0]",1,if self . act_deterministically :,if self . act_deterministically :,0.75,100.00000000000004,1.0
"def _classify(nodes_by_level):<tab>missing, invalid, downloads = [], [], []<tab>for level in nodes_by_level:<tab><tab>for node in level:<tab><tab><tab>if node.binary == BINARY_MISSING:<tab><tab><tab><tab>missing.append(node)<tab><tab><tab>elif node.binary == BINARY_INVALID:<tab><tab><tab><tab>invalid.append(node)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>downloads.append(node)<tab>return missing, invalid, downloads",0,"elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",elif node . binary == BINARY_DOWNLOADING :,0.15910901181912807,19.692104496063724,0.7866666666666667
"def persist(self, *_):<tab>for key, obj in self._objects.items():<tab><tab>try:<tab><tab><tab>state = obj.get_state()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>md5 = hashlib.md5(state).hexdigest()<tab><tab><tab>if self._last_state.get(key) == md5:<tab><tab><tab><tab>continue<tab><tab><tab>self._persist_provider.store(key, state)<tab><tab>except Exception as e:<tab><tab><tab>system_log.exception(""PersistHelper.persist fail"")<tab><tab>else:<tab><tab><tab>self._last_state[key] = md5",1,if not state :,if not state :,0.75,100.00000000000004,1.0
"def enter(self, doc, **kwds):<tab>""""""Enters the mode, arranging for necessary grabs ASAP""""""<tab>super(ColorPickMode, self).enter(doc, **kwds)<tab>if self._started_from_key_press:<tab><tab># Pick now using the last recorded event position<tab><tab>doc = self.doc<tab><tab>tdw = self.doc.tdw<tab><tab>t, x, y = doc.get_last_event_info(tdw)<tab><tab><IF-STMT><tab><tab><tab>self._pick_color_mode(tdw, x, y, self._pickmode)<tab><tab># Start the drag when possible<tab><tab>self._start_drag_on_next_motion_event = True<tab><tab>self._needs_drag_start = True",0,"if None not in ( x , y ) :",if self . _pickmode is not None :,0.08723447677677887,6.033504141761816,0.20987654320987653
"def on_profiles_loaded(self, profiles):<tab>cb = self.builder.get_object(""cbProfile"")<tab>model = cb.get_model()<tab>model.clear()<tab>for f in profiles:<tab><tab>name = f.get_basename()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if name.endswith("".sccprofile""):<tab><tab><tab>name = name[0:-11]<tab><tab>model.append((name, f, None))<tab>cb.set_active(0)",0,"if name . endswith ( "".mod"" ) :",if not name :,0.019930835999227993,3.6531471527995247,0.4
"def subprocess_post_check(<tab>completed_process: subprocess.CompletedProcess, raise_error: bool = True) -> None:<tab>if completed_process.returncode:<tab><tab>if completed_process.stdout is not None:<tab><tab><tab>print(completed_process.stdout, file=sys.stdout, end="""")<tab><tab><IF-STMT><tab><tab><tab>print(completed_process.stderr, file=sys.stderr, end="""")<tab><tab>if raise_error:<tab><tab><tab>raise PipxError(<tab><tab><tab><tab>f""{' '.join([str(x) for x in completed_process.args])!r} failed""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>logger.info(f""{' '.join(completed_process.args)!r} failed"")",1,if completed_process . stderr is not None :,if completed_process . stderr is not None :,0.75,100.00000000000004,1.0
"def test_connect(<tab>ipaddr, port, device, partition, method, path, headers=None, query_string=None):<tab>if path == ""/a"":<tab><tab>for k, v in headers.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>test_errors.append(""%s: %s not in %s"" % (test_header, test_value, headers))",0,if k . lower ( ) == test_header . lower ( ) and v == test_value :,if k == test_header and v == test_value :,0.1301466071388924,44.99803681491503,0.4861111111111111
"def test_stat_result_pickle(self):<tab>result = os.stat(self.fname)<tab>for proto in range(pickle.HIGHEST_PROTOCOL + 1):<tab><tab>p = pickle.dumps(result, proto)<tab><tab>self.assertIn(b""stat_result"", p)<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(b""cos\nstat_result\n"", p)<tab><tab>unpickled = pickle.loads(p)<tab><tab>self.assertEqual(result, unpickled)",0,if proto < 4 :,if proto % 2 == 0 :,0.136202649291725,12.22307556087252,0.4761904761904762
"def run_sql(sql):<tab>table = sql.split("" "")[5]<tab>logger.info(""Updating table {}"".format(table))<tab>with transaction.atomic():<tab><tab>with connection.cursor() as cursor:<tab><tab><tab>cursor.execute(sql)<tab><tab><tab>rows = cursor.fetchall()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""Sentry notification that {} is migrated"".format(table))",1,if not rows :,if not rows :,0.75,100.00000000000004,1.0
"def countbox(self):<tab>self.box = [1000, 1000, -1000, -1000]<tab>for x, y in self.body:<tab><tab>if x < self.box[0]:<tab><tab><tab>self.box[0] = x<tab><tab><IF-STMT><tab><tab><tab>self.box[2] = x<tab><tab>if y < self.box[1]:<tab><tab><tab>self.box[1] = y<tab><tab>if y > self.box[3]:<tab><tab><tab>self.box[3] = y",1,if x > self . box [ 2 ] :,if x > self . box [ 2 ] :,0.75,100.00000000000004,1.0
"def _packageFocusOutViaKeyPress(self, row, column, txt):<tab>if txt:<tab><tab>self._set_current_cell(row + 1, column)<tab>else:<tab><tab>widget = self.cellWidget(row + 1, column)<tab><tab><IF-STMT><tab><tab><tab>self._delete_cell(row, column)<tab><tab>new_request = self.get_request()<tab><tab>self.context_model.set_request(new_request)<tab><tab>self._update_request_column(column, self.context_model)",0,"if widget and isinstance ( widget , PackageSelectWidget ) :",if widget is None :,0.09702372492488695,8.697972365316721,0.30833333333333335
"def parse_bash_set_output(output):<tab>""""""Parse Bash-like 'set' output""""""<tab>if not sys.platform.startswith(""win""):<tab><tab># Replace ""\""-continued lines in *Linux* environment dumps.<tab><tab># Cannot do this on Windows because a ""\"" at the end of the<tab><tab># line does not imply a continuation.<tab><tab>output = output.replace(""\\\n"", """")<tab>environ = {}<tab>for line in output.splitlines(0):<tab><tab>line = line.rstrip()<tab><tab><IF-STMT><tab><tab><tab>continue  # skip black lines<tab><tab>item = _ParseBashEnvStr(line)<tab><tab>if item:<tab><tab><tab>environ[item[0]] = item[1]<tab>return environ",0,if not line :,"if not line or line . startswith ( ""#"" ) :",0.13188464517775386,12.35622127262679,0.5726495726495727
"def _get(self, domain):<tab>with self.lock:<tab><tab>try:<tab><tab><tab>record = self.cache[domain]<tab><tab><tab>time_now = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>record = None<tab><tab>except KeyError:<tab><tab><tab>record = None<tab><tab>if not record:<tab><tab><tab>record = {""r"": ""unknown"", ""dns"": {}, ""g"": 1, ""query_count"": 0}<tab><tab># self.cache[domain] = record<tab><tab>return record",0,"if time_now - record [ ""update"" ] > self . ttl :",if time_now > self . cache_max_age :,0.11815958155835826,22.9585358002991,0.37777777777777777
"def test_filehash(self):<tab>""""""tests the hashes of the files in data/""""""<tab>fp = self.get_data_path()<tab>for fn in os.listdir(fp):<tab><tab><IF-STMT><tab><tab><tab># file used for something else<tab><tab><tab>continue<tab><tab>expected_hash = fn<tab><tab>fullp = os.path.join(fp, fn)<tab><tab>output = self.run_command(""sha1sum "" + fullp, exitcode=0)<tab><tab>result = output.split("" "")[0]<tab><tab>self.assertEqual(result, expected_hash)",0,"if ""."" in fn :","if fn . endswith ( "".py"" ) :",0.028001459970687266,9.864703138979419,0.4
"def test_new_vs_reference_code_stream_read_during_iter(read_idx, read_len, bytecode):<tab>reference = SlowCodeStream(bytecode)<tab>latest = CodeStream(bytecode)<tab>for index, (actual, expected) in enumerate(zip(latest, reference)):<tab><tab>assert actual == expected<tab><tab>if index == read_idx:<tab><tab><tab>readout_actual = latest.read(read_len)<tab><tab><tab>readout_expected = reference.read(read_len)<tab><tab><tab>assert readout_expected == readout_actual<tab><tab><IF-STMT><tab><tab><tab>assert latest.program_counter >= len(reference)<tab><tab>else:<tab><tab><tab>assert latest.program_counter == reference.program_counter",0,if reference . program_counter >= len ( reference ) :,if index == read_idx :,0.013468035777437931,4.18031138310865,0.37142857142857144
"def setup_logging():<tab>try:<tab><tab>logconfig = config.get(""logging_config_file"")<tab><tab><IF-STMT><tab><tab><tab>logging.config.fileConfig(logconfig, disable_existing_loggers=False)<tab><tab>logger.info(""logging initialized"")<tab><tab>logger.debug(""debug"")<tab>except Exception as e:<tab><tab>print(""Unable to set logging configuration:"", str(e), file=sys.stderr)<tab><tab>raise",0,if logconfig and os . path . exists ( logconfig ) :,if logconfig :,0.014772183860219557,1e-10,0.3333333333333333
"def all_words(filename):<tab>start_char = True<tab>for c in characters(filename):<tab><tab><IF-STMT><tab><tab><tab>word = """"<tab><tab><tab>if c.isalnum():<tab><tab><tab><tab># We found the start of a word<tab><tab><tab><tab>word = c.lower()<tab><tab><tab><tab>start_char = False<tab><tab><tab>else:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>if c.isalnum():<tab><tab><tab><tab>word += c.lower()<tab><tab><tab>else:<tab><tab><tab><tab># We found end of word, emit it<tab><tab><tab><tab>start_char = True<tab><tab><tab><tab>yield word",0,if start_char == True :,if start_char :,0.06767423853569741,1e-10,0.6190476190476191
"def _get_nonce(self, url, new_nonce_url):<tab>if not self._nonces:<tab><tab>logger.debug(""Requesting fresh nonce"")<tab><tab><IF-STMT><tab><tab><tab>response = self.head(url)<tab><tab>else:<tab><tab><tab># request a new nonce from the acme newNonce endpoint<tab><tab><tab>response = self._check_response(self.head(new_nonce_url), content_type=None)<tab><tab>self._add_nonce(response)<tab>return self._nonces.pop()",1,if new_nonce_url is None :,if new_nonce_url is None :,0.75,100.00000000000004,1.0
"def paragraph_is_fully_commented(lines, comment, main_language):<tab>""""""Is the paragraph fully commented?""""""<tab>for i, line in enumerate(lines):<tab><tab>if line.startswith(comment):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if is_magic(line, main_language):<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>return i > 0 and _BLANK_LINE.match(line)<tab>return True",0,if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,if _BLANK_LINE . match ( line ) :,0.06256093166610993,4.766871975246856,0.23214285714285715
"def gvariant_args(args: List[Any]) -> str:<tab>""""""Convert args into gvariant.""""""<tab>gvariant = """"<tab>for arg in args:<tab><tab>if isinstance(arg, bool):<tab><tab><tab>gvariant += "" {}"".format(str(arg).lower())<tab><tab><IF-STMT><tab><tab><tab>gvariant += f"" {arg}""<tab><tab>elif isinstance(arg, str):<tab><tab><tab>gvariant += f' ""{arg}""'<tab><tab>else:<tab><tab><tab>gvariant += f"" {arg!s}""<tab>return gvariant.lstrip()",0,"elif isinstance ( arg , ( int , float ) ) :",elif arg is True :,0.08072018263363925,3.466791587270993,0.24166666666666667
"def _SkipGroup(buffer, pos, end):<tab>""""""Skip sub-group.  Returns the new position.""""""<tab>while 1:<tab><tab>(tag_bytes, pos) = ReadTag(buffer, pos)<tab><tab>new_pos = SkipField(buffer, pos, end, tag_bytes)<tab><tab><IF-STMT><tab><tab><tab>return pos<tab><tab>pos = new_pos",0,if new_pos == - 1 :,if new_pos == end :,0.11529782719544424,62.401954419369176,0.5
"def update_participants(self, refresh=True):<tab>for participant in list(self.participants_dict):<tab><tab>if participant is None or participant == self.simulator_config.broadcast_part:<tab><tab><tab>continue<tab><tab>self.removeItem(self.participants_dict[participant])<tab><tab>self.participant_items.remove(self.participants_dict[participant])<tab><tab>del self.participants_dict[participant]<tab>for participant in self.simulator_config.participants:<tab><tab><IF-STMT><tab><tab><tab>self.participants_dict[participant].refresh()<tab><tab>else:<tab><tab><tab>self.insert_participant(participant)<tab>if refresh:<tab><tab>self.update_view()",0,if participant in self . participants_dict :,if participant in self . participant_items :,0.574113272471593,48.54917717073236,1.0
"def feature_reddit(layer_data, graph):<tab>feature = {}<tab>times = {}<tab>indxs = {}<tab>for _type in layer_data:<tab><tab>if len(layer_data[_type]) == 0:<tab><tab><tab>continue<tab><tab>idxs = np.array(list(layer_data[_type].keys()))<tab><tab>tims = np.array(list(layer_data[_type].values()))[:, 1]<tab><tab>feature[_type] = np.array(<tab><tab><tab>list(graph.node_feature[_type].loc[idxs, ""emb""]), dtype=np.float<tab><tab>)<tab><tab>times[_type] = tims<tab><tab>indxs[_type] = idxs<tab><tab><IF-STMT><tab><tab><tab>attr = feature[_type]<tab>return feature, times, indxs, attr",0,"if _type == ""def"" :",if len ( feature ) > 0 :,0.026407399022921448,5.795599612995366,0.34545454545454546
"def _get_sort_map(tags):<tab>""""""See TAG_TO_SORT""""""<tab>tts = {}<tab>for name, tag in tags.items():<tab><tab>if tag.has_sort:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tts[name] = ""%ssort"" % name<tab><tab><tab>if tag.internal:<tab><tab><tab><tab>tts[""~%s"" % name] = ""~%ssort"" % name<tab>return tts",0,if tag . user :,if tag . internal :,0.39477865547525276,42.72870063962342,0.6
"def max_radius(iterator):<tab>radius_result = dict()<tab>for k, v in iterator:<tab><tab>if v[0] not in radius_result:<tab><tab><tab>radius_result[v[0]] = v[1]<tab><tab><IF-STMT><tab><tab><tab>radius_result[v[0]] = v[1]<tab>return radius_result",0,elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,elif v [ 1 ] not in radius_result :,0.32050419309148126,28.009266907237098,0.5238095238095238
"def run(self):<tab>pwd_found = []<tab>if constant.user_dpapi and constant.user_dpapi.unlocked:<tab><tab>main_vault_directory = os.path.join(<tab><tab><tab>constant.profile[""APPDATA""], u"".."", u""Local"", u""Microsoft"", u""Vault""<tab><tab>)<tab><tab>if os.path.exists(main_vault_directory):<tab><tab><tab>for vault_directory in os.listdir(main_vault_directory):<tab><tab><tab><tab>cred = constant.user_dpapi.decrypt_vault(<tab><tab><tab><tab><tab>os.path.join(main_vault_directory, vault_directory)<tab><tab><tab><tab>)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pwd_found.append(cred)<tab>return pwd_found",1,if cred :,if cred :,0.5311706625951745,1e-10,1.0
"def disconnect_sync(self, connection, close_connection=False):<tab>key = id(connection)<tab>ts = self.in_use.pop(key)<tab>if close_connection:<tab><tab>self.connections_map.pop(key)<tab><tab>self._connection_close_sync(connection)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.connections_map.pop(key)<tab><tab><tab>self._connection_close_sync(connection)<tab><tab>else:<tab><tab><tab>with self._lock_sync:<tab><tab><tab><tab>heapq.heappush(self.connections_sync, (ts, key))",0,if self . stale_timeout and self . is_stale ( ts ) :,if ts == 0 :,0.010805043283377891,2.017602272943647,0.3125
"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict):<tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab>elif isinstance(v, bool):<tab><tab><tab>self._populate_bool(element, k, v)<tab><tab>elif isinstance(v, basestring):<tab><tab><tab>self._populate_str(element, k, v)<tab><tab><IF-STMT><tab><tab><tab>self._populate_number(element, k, v)",0,"elif type ( v ) in [ int , float , long , complex ] :","elif isinstance ( v , int ) :",0.06604792596358247,5.55750946374376,0.27999999999999997
"def readframes(self, nframes):<tab>if self._ssnd_seek_needed:<tab><tab>self._ssnd_chunk.seek(0)<tab><tab>dummy = self._ssnd_chunk.read(8)<tab><tab>pos = self._soundpos * self._framesize<tab><tab><IF-STMT><tab><tab><tab>self._ssnd_chunk.seek(pos + 8)<tab><tab>self._ssnd_seek_needed = 0<tab>if nframes == 0:<tab><tab>return """"<tab>data = self._ssnd_chunk.read(nframes * self._framesize)<tab>if self._convert and data:<tab><tab>data = self._convert(data)<tab>self._soundpos = self._soundpos + len(data) / (self._nchannels * self._sampwidth)<tab>return data",1,if pos :,if pos :,0.5311706625951745,1e-10,1.0
"def target_glob(tgt, hosts):<tab>ret = {}<tab>for host in hosts:<tab><tab><IF-STMT><tab><tab><tab>ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {}))<tab><tab><tab>ret[host].update({""host"": host})<tab><tab><tab>if __opts__.get(""ssh_user""):<tab><tab><tab><tab>ret[host].update({""user"": __opts__[""ssh_user""]})<tab>return ret",0,"if fnmatch . fnmatch ( tgt , host ) :","if ""__opts__"" in __opts__ :",0.013468035777437931,3.1251907639724417,0.2948717948717949
"def get_attribute_value(self, nodeid, attr):<tab>with self._lock:<tab><tab>self.logger.debug(""get attr val: %s %s"", nodeid, attr)<tab><tab>if nodeid not in self._nodes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown)<tab><tab><tab>return dv<tab><tab>node = self._nodes[nodeid]<tab><tab>if attr not in node.attributes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid)<tab><tab><tab>return dv<tab><tab>attval = node.attributes[attr]<tab><tab><IF-STMT><tab><tab><tab>return attval.value_callback()<tab><tab>return attval.value",1,if attval . value_callback :,if attval . value_callback :,0.75,100.00000000000004,1.0
"def remove_property(self, key):  # type: (str) -> None<tab>with self.secure() as config:<tab><tab>keys = key.split(""."")<tab><tab>current_config = config<tab><tab>for i, key in enumerate(keys):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>if i == len(keys) - 1:<tab><tab><tab><tab>del current_config[key]<tab><tab><tab><tab>break<tab><tab><tab>current_config = current_config[key]",1,if key not in current_config :,if key not in current_config :,0.75,100.00000000000004,1.0
"def _class_browser(parent):  # Wrapper for htest<tab>try:<tab><tab>file = __file__<tab>except NameError:<tab><tab>file = sys.argv[0]<tab><tab><IF-STMT><tab><tab><tab>file = sys.argv[1]<tab><tab>else:<tab><tab><tab>file = sys.argv[0]<tab>dir, file = os.path.split(file)<tab>name = os.path.splitext(file)[0]<tab>flist = PyShell.PyShellFileList(parent)<tab>global file_open<tab>file_open = flist.open<tab>ClassBrowser(flist, name, [dir], _htest=True)",0,if sys . argv [ 1 : ] :,if sys . argv [ 1 ] :,0.385546827093644,67.5291821812656,1.0
"def get_only_text_part(self, msg):<tab>count = 0<tab>only_text_part = None<tab>for part in msg.walk():<tab><tab>if part.is_multipart():<tab><tab><tab>continue<tab><tab>count += 1<tab><tab>mimetype = part.get_content_type() or ""text/plain""<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>only_text_part = part<tab>return only_text_part",0,"if mimetype != ""text/plain"" or count != 1 :","if mimetype != ""text/plain"" :",0.21279282519794362,54.80623193671364,0.4545454545454546
"def should_keep_alive(commit_msg):<tab>result = False<tab>ci = get_current_ci() or """"<tab>for line in commit_msg.splitlines():<tab><tab>parts = line.strip(""# "").split("":"", 1)<tab><tab>(key, val) = parts if len(parts) > 1 else (parts[0], """")<tab><tab>if key == ""CI_KEEP_ALIVE"":<tab><tab><tab>ci_names = val.replace("","", "" "").lower().split() if val else []<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab>return result",0,if len ( ci_names ) == 0 or ci . lower ( ) in ci_names :,if ci in ci_names :,0.027312937596670035,9.050415858572288,0.2272727272727273
"def _calc_block_io(self, blkio):<tab>""""""Calculate block IO stats.""""""<tab>for stats in blkio[""io_service_bytes_recursive""]:<tab><tab>if stats[""op""] == ""Read"":<tab><tab><tab>self._blk_read += stats[""value""]<tab><tab><IF-STMT><tab><tab><tab>self._blk_write += stats[""value""]",1,"elif stats [ ""op"" ] == ""Write"" :","elif stats [ ""op"" ] == ""Write"" :",1.0,100.00000000000004,1.0
"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># Oracle doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Oracle backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return six.text_type(value)",1,if settings . USE_TZ :,if settings . USE_TZ :,0.75,100.00000000000004,1.0
"def load_state_dict(self, state_dict):<tab>for module_name, module_state_dict in state_dict.items():<tab><tab>if module_name in self.module_pool:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.module_pool[module_name].module.load_state_dict(module_state_dict)<tab><tab><tab>else:<tab><tab><tab><tab>self.module_pool[module_name].load_state_dict(module_state_dict)<tab><tab>else:<tab><tab><tab>logging.info(f""Missing {module_name} in module_pool, skip it.."")",0,"if self . config [ ""dataparallel"" ] :","if isinstance ( self . module_pool [ module_name ] . module , Module ) :",0.09153911044003499,5.32864224277779,0.3181818181818182
"def _unpack_scales(scales, vidxs):<tab>scaleData = [None, None, None]<tab>for i in range(3):<tab><tab>if i >= min(len(scales), len(vidxs) // 2):<tab><tab><tab>break<tab><tab>scale = scales[i]<tab><tab><IF-STMT><tab><tab><tab>vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1]<tab><tab><tab>scaleData[i] = (int(vidx1), int(vidx2), float(scale))<tab>return scaleData",0,if not math . isnan ( scale ) :,if scale > 0 :,0.0168380461076173,6.316906128202129,0.2571428571428572
"def __init__(self, factors, contrast_matrices, num_columns):<tab>self.factors = tuple(factors)<tab>factor_set = frozenset(factors)<tab>if not isinstance(contrast_matrices, dict):<tab><tab>raise ValueError(""contrast_matrices must be dict"")<tab>for factor, contrast_matrix in six.iteritems(contrast_matrices):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Unexpected factor in contrast_matrices dict"")<tab><tab>if not isinstance(contrast_matrix, ContrastMatrix):<tab><tab><tab>raise ValueError(""Expected a ContrastMatrix, not %r"" % (contrast_matrix,))<tab>self.contrast_matrices = contrast_matrices<tab>if not isinstance(num_columns, six.integer_types):<tab><tab>raise ValueError(""num_columns must be an integer"")<tab>self.num_columns = num_columns",1,if factor not in factor_set :,if factor not in factor_set :,0.75,100.00000000000004,1.0
"def app(scope, receive, send):<tab>while True:<tab><tab>message = await receive()<tab><tab><IF-STMT><tab><tab><tab>await send({""type"": ""websocket.accept""})<tab><tab>elif message[""type""] == ""websocket.receive"":<tab><tab><tab>pass<tab><tab>elif message[""type""] == ""websocket.disconnect"":<tab><tab><tab>break",0,"if message [ ""type"" ] == ""websocket.connect"" :","if ""type"" in message :",0.020977836961063236,9.271103732443692,0.4772727272727273
"def value__set(self, value):<tab>for i, (option, checked) in enumerate(self.options):<tab><tab><IF-STMT><tab><tab><tab>self.selectedIndex = i<tab><tab><tab>break<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>""Option %r not found (from %s)""<tab><tab><tab>% (value, "", "".join([repr(o) for o, c in self.options]))<tab><tab>)",0,if option == str ( value ) :,if checked and option == value :,0.03836215687039321,21.573652645054953,0.2653061224489796
"def init_links(self):<tab>links = LinkCallback.find_links(self)<tab>callbacks = []<tab>for link, src_plot, tgt_plot in links:<tab><tab>cb = Link._callbacks[""bokeh""][type(link)]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>callbacks.append(cb(self.root, link, src_plot, tgt_plot))<tab>return callbacks",0,if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,if not cb :,0.006402003792394382,0.21102530003841274,0.1929824561403509
"def _validate_scalar_extensions(self) -> List[str]:<tab>errors = []<tab>for extension in [<tab><tab>x for x in self.extensions if isinstance(x, GraphQLScalarTypeExtension)<tab>]:<tab><tab>extended = self.type_definitions.get(extension.name)<tab><tab>ext_errors = _validate_extension(<tab><tab><tab>extended, extension.name, GraphQLScalarType, ""SCALAR""<tab><tab>)<tab><tab>errors.extend(ext_errors)<tab><tab><IF-STMT><tab><tab><tab>errors.extend(_validate_extension_directives(extension, extended, ""SCALAR""))<tab>return errors",0,if not ext_errors :,if extended :,0.05063871203029889,1e-10,0.5
"def copy_tcltk(src, dest, symlink):<tab>""""""copy tcl/tk libraries on Windows (issue #93)""""""<tab>for libversion in ""8.5"", ""8.6"":<tab><tab>for libname in ""tcl"", ""tk"":<tab><tab><tab>srcdir = join(src, ""tcl"", libname + libversion)<tab><tab><tab>destdir = join(dest, ""tcl"", libname + libversion)<tab><tab><tab># Only copy the dirs from the above combinations that exist<tab><tab><tab><IF-STMT><tab><tab><tab><tab>copyfileordir(srcdir, destdir, symlink)",0,if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,if os . path . exists ( srcdir ) :,0.3777306445730935,34.23503955179095,0.5277777777777778
"def parse(self, response):<tab>try:<tab><tab>content = response.content.decode(""utf-8"", ""ignore"")<tab><tab>content = json.loads(content, strict=False)<tab>except:<tab><tab>self.logger.error(""Fail to parse the response in json format"")<tab><tab>return<tab>for item in content[""data""]:<tab><tab>if ""objURL"" in item:<tab><tab><tab>img_url = self._decode_url(item[""objURL""])<tab><tab><IF-STMT><tab><tab><tab>img_url = item[""hoverURL""]<tab><tab>else:<tab><tab><tab>continue<tab><tab>yield dict(file_url=img_url)",1,"elif ""hoverURL"" in item :","elif ""hoverURL"" in item :",0.75,100.00000000000004,1.0
"def check_and_reload(self):<tab># Check if tables have been modified, if so reload<tab>for table_name, table_version in self._table_versions.items():<tab><tab>table = self.app.tool_data_tables.get(table_name, None)<tab><tab><IF-STMT><tab><tab><tab>return self.reload_genomes()",0,if table is not None and not table . is_current_version ( table_version ) :,if table and table . version == table_version :,0.18383785102718742,10.399769989211284,0.2875
"def _get_query_defaults(self, query_defns):<tab>defaults = {}<tab>for k, v in query_defns.items():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>defaults[k] = self._get_default_obj(v[""schema""])<tab><tab><tab>else:<tab><tab><tab><tab>defaults[k] = v[""schema""][""default""]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return defaults",0,"if v [ ""schema"" ] [ ""type"" ] == ""object"" :","if isinstance ( v [ ""schema"" ] , dict ) :",0.18316641880123513,27.838424262216993,0.375
"def ftp_login(host, port, username=None, password=None, anonymous=False):<tab>ret = False<tab>try:<tab><tab>ftp = ftplib.FTP()<tab><tab>ftp.connect(host, port, timeout=6)<tab><tab><IF-STMT><tab><tab><tab>ftp.login()<tab><tab>else:<tab><tab><tab>ftp.login(username, password)<tab><tab>ret = True<tab><tab>ftp.quit()<tab>except Exception:<tab><tab>pass<tab>return ret",1,if anonymous :,if anonymous :,0.5311706625951745,1e-10,1.0
"def _getVolumeScalar(self):<tab>if self._volumeScalar is not None:<tab><tab>return self._volumeScalar<tab># use default<tab>elif self._value in dynamicStrToScalar:<tab><tab>return dynamicStrToScalar[self._value]<tab>else:<tab><tab>thisDynamic = self._value<tab><tab># ignore leading s like in sf<tab><tab>if ""s"" in thisDynamic:<tab><tab><tab>thisDynamic = thisDynamic[1:]<tab><tab># ignore closing z like in fz<tab><tab>if thisDynamic[-1] == ""z"":<tab><tab><tab>thisDynamic = thisDynamic[:-1]<tab><tab><IF-STMT><tab><tab><tab>return dynamicStrToScalar[thisDynamic]<tab><tab>else:<tab><tab><tab>return dynamicStrToScalar[None]",1,if thisDynamic in dynamicStrToScalar :,if thisDynamic in dynamicStrToScalar :,0.75,100.00000000000004,1.0
"def processCoords(coords):<tab>newcoords = deque()<tab>for (x, y, z) in coords:<tab><tab>for _dir, offsets in faceDirections:<tab><tab><tab>if _dir == FaceYIncreasing:<tab><tab><tab><tab>continue<tab><tab><tab>dx, dy, dz = offsets<tab><tab><tab>p = (x + dx, y + dy, z + dz)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>nx, ny, nz = p<tab><tab><tab>if level.blockAt(nx, ny, nz) == 0:<tab><tab><tab><tab>level.setBlockAt(nx, ny, nz, waterID)<tab><tab><tab><tab>newcoords.append(p)<tab>return newcoords",0,if p not in box :,if len ( p ) == 0 :,0.023749771747382555,6.27465531099474,0.23214285714285715
"def _set_property(self, target_widget, pname, value):<tab>if pname == ""text"":<tab><tab>wstate = str(target_widget[""state""])<tab><tab><IF-STMT><tab><tab><tab># change state temporarily<tab><tab><tab>target_widget[""state""] = ""normal""<tab><tab>target_widget.delete(""0"", tk.END)<tab><tab>target_widget.insert(""0"", value)<tab><tab>target_widget[""state""] = wstate<tab>else:<tab><tab>super(EntryBaseBO, self)._set_property(target_widget, pname, value)",0,"if wstate != ""normal"" :",if wstate != tk . END :,0.11726065783135259,36.55552228545123,0.55
"def teardown():<tab>try:<tab><tab>time.sleep(1)<tab>except KeyboardInterrupt:<tab><tab>return<tab>while launchers:<tab><tab>p = launchers.pop()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>p.stop()<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>print(e)<tab><tab><tab><tab>pass<tab><tab>if p.poll() is None:<tab><tab><tab>try:<tab><tab><tab><tab>time.sleep(0.25)<tab><tab><tab>except KeyboardInterrupt:<tab><tab><tab><tab>return<tab><tab>if p.poll() is None:<tab><tab><tab>try:<tab><tab><tab><tab>print(""cleaning up test process..."")<tab><tab><tab><tab>p.signal(SIGKILL)<tab><tab><tab>except:<tab><tab><tab><tab>print(""couldn't shutdown process: "", p)",0,if p . poll ( ) is None :,if p . isAlive ( ) :,0.2058922660661427,24.177237023718654,0.39999999999999997
"def checkAndRemoveDuplicate(self, node):<tab>for bucket in self.buckets:<tab><tab>for n in bucket.getNodes():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.removeContact(n)",0,"if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id :",if n . getName ( ) == node . getName ( ) :,0.13705036929154354,6.637719527486757,0.25213675213675213
"def toString():<tab>flags = u""""<tab>try:<tab><tab>if this.glob:<tab><tab><tab>flags += u""g""<tab><tab><IF-STMT><tab><tab><tab>flags += u""i""<tab><tab>if this.multiline:<tab><tab><tab>flags += u""m""<tab>except:<tab><tab>pass<tab>v = this.value if this.value else ""(?:)""<tab>return u""/%s/"" % v + flags",0,if this . ignore_case :,if this . strict :,0.3954739241427606,28.641904579795423,0.7
"def import_submodules(package_name):<tab>package = sys.modules[package_name]<tab>results = {}<tab>for loader, name, is_pkg in pkgutil.iter_modules(package.__path__):<tab><tab>full_name = package_name + ""."" + name<tab><tab>module = importlib.import_module(full_name)<tab><tab>setattr(sys.modules[__name__], name, module)<tab><tab>results[full_name] = module<tab><tab>if is_pkg:<tab><tab><tab>valid_pkg = import_submodules(full_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.update(valid_pkg)<tab>return results",1,if valid_pkg :,if valid_pkg :,0.5311706625951745,1e-10,1.0
"def _call(self, cmd):<tab>what = cmd[""command""]<tab>if what == ""list"":<tab><tab>name = cmd[""properties""].get(""name"")<tab><tab><IF-STMT><tab><tab><tab>return {""watchers"": [""one"", ""two"", ""three""]}<tab><tab>return {""pids"": [123, 456]}<tab>elif what == ""dstats"":<tab><tab>return {""info"": {""pid"": 789}}<tab>elif what == ""listsockets"":<tab><tab>return {<tab><tab><tab>""status"": ""ok"",<tab><tab><tab>""sockets"": [{""path"": self._unix, ""fd"": 5, ""name"": ""XXXX"", ""backlog"": 2048}],<tab><tab><tab>""time"": 1369647058.967524,<tab><tab>}<tab>raise NotImplementedError(cmd)",0,if name is None :,"if name == ""watchers"" :",0.06497877230811641,12.22307556087252,0.5
"def select(self):<tab>e = xlib.XEvent()<tab>while xlib.XPending(self._display):<tab><tab>xlib.XNextEvent(self._display, e)<tab><tab># Key events are filtered by the xlib window event<tab><tab># handler so they get a shot at the prefiltered event.<tab><tab>if e.xany.type not in (xlib.KeyPress, xlib.KeyRelease):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>dispatch = self._window_map[e.xany.window]<tab><tab>except KeyError:<tab><tab><tab>continue<tab><tab>dispatch(e)",0,"if xlib . XFilterEvent ( e , e . xany . window ) :",if e . xany . window not in self . _window_map :,0.15313902460203743,27.668736912821906,0.2
"def translate(self, line):<tab>parsed = self.RE_LINE_PARSER.match(line)<tab>if parsed:<tab><tab>value = parsed.group(3)<tab><tab>stage = parsed.group(1)<tab><tab><IF-STMT>  # query string is rendered here<tab><tab><tab>return ""\n# HTTP Request:\n"" + self.stripslashes(value)<tab><tab>elif stage == ""reply"":<tab><tab><tab>return ""\n\n# HTTP Response:\n"" + self.stripslashes(value)<tab><tab>elif stage == ""header"":<tab><tab><tab>return value + ""\n""<tab><tab>else:<tab><tab><tab>return value<tab>return line",0,"if stage == ""send"" :","if stage == ""query"" :",0.39477865547525276,59.4603557501361,1.0
"def toString():<tab>flags = u""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>flags += u""g""<tab><tab>if this.ignore_case:<tab><tab><tab>flags += u""i""<tab><tab>if this.multiline:<tab><tab><tab>flags += u""m""<tab>except:<tab><tab>pass<tab>v = this.value if this.value else ""(?:)""<tab>return u""/%s/"" % v + flags",0,if this . glob :,if this . strict :,0.3954739241427606,42.72870063962342,0.6
"def __exit__(self, *exc_info):<tab>super(WarningsChecker, self).__exit__(*exc_info)<tab># only check if we're not currently handling an exception<tab>if all(a is None for a in exc_info):<tab><tab>if self.expected_warning is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>__tracebackhide__ = True<tab><tab><tab><tab>pytest.fail(""DID NOT WARN"")",0,if not any ( r . category in self . expected_warning for r in self ) :,if self . expected_warning is not None :,0.06198200419971216,17.96191510244705,0.1515151515151515
"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab>if k.startswith(""_""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if v[""email""] == """":<tab><tab><tab><tab>v[""email""] = None<tab><tab><tab>if v[""ip""] == ""0.0.0.0"":<tab><tab><tab><tab>v[""ip""] = None<tab>return self.objs",0,"if v [ ""_class"" ] == ""User"" :","if isinstance ( v , dict ) :",0.019345087832959386,3.4331054109918173,0.36
"def list_stuff(self, upto=10, start_after=-1):<tab>for i in range(upto):<tab><tab>if i <= start_after:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>if i == 7 and self.count < 4:<tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>yield i",0,if i == 2 and self . count < 1 :,if i == 6 and self . count < 4 :,0.49338632565018925,54.52469119630866,0.6
"def check(self):<tab>tcp_client = self.tcp_create()<tab>if tcp_client.connect():<tab><tab>tcp_client.send(b""ABCDE"")<tab><tab>response = tcp_client.recv(5)<tab><tab>tcp_client.close()<tab><tab>if response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.endianness = "">""  # BE<tab><tab><tab>elif response.startswith(b""ScMM""):<tab><tab><tab><tab>self.endianness = ""<""  # LE<tab><tab><tab>return True  # target is vulnerable<tab>return False  # target is not vulnerable",0,"if response . startswith ( b""MMcS"" ) :","if response . startswith ( b""ScMM"" ) :",0.5490406812970063,70.16879391277372,1.0
"def copy_tree(self, src_dir, dst_dir, skip_variables=False):<tab>for src_root, _, files in os.walk(src_dir):<tab><tab>if src_root != src_dir:<tab><tab><tab>rel_root = os.path.relpath(src_root, src_dir)<tab><tab>else:<tab><tab><tab>rel_root = """"<tab><tab>if skip_variables and rel_root.startswith(""variables""):<tab><tab><tab>continue<tab><tab>dst_root = os.path.join(dst_dir, rel_root)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dst_root)<tab><tab>for f in files:<tab><tab><tab>shutil.copy(os.path.join(src_root, f), os.path.join(dst_root, f))",1,if not os . path . exists ( dst_root ) :,if not os . path . exists ( dst_root ) :,0.75,100.00000000000004,1.0
"def _set_hostport(self, host, port):<tab>if port is None:<tab><tab>i = host.rfind("":"")<tab><tab>j = host.rfind(""]"")  # ipv6 addresses have [...]<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>port = int(host[i + 1 :])<tab><tab><tab>except ValueError:<tab><tab><tab><tab>raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :])<tab><tab><tab>host = host[:i]<tab><tab>else:<tab><tab><tab>port = self.default_port<tab><tab>if host and host[0] == ""["" and host[-1] == ""]"":<tab><tab><tab>host = host[1:-1]<tab>self.host = host<tab>self.port = port",0,if i > j :,if i >= 0 and j >= 0 :,0.04975840882008457,15.851165692617148,0.4444444444444444
"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab>if member[0] == key:<tab><tab><tab><tab>field_value = member[1]<tab><tab><tab>elif member[0] == ""wildcards"":<tab><tab><tab><tab>wildcards = member[1]<tab><tab><IF-STMT><tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab>elif key == ""nw_dst"":<tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value",1,"if key == ""nw_src"" :","if key == ""nw_src"" :",0.75,100.00000000000004,1.0
"def _clear_storage():<tab>""""""Clear old files from storage.""""""<tab>hacs = get_hacs()<tab>storagefiles = [""hacs""]<tab>for s_f in storagefiles:<tab><tab>path = f""{hacs.core.config_path}/.storage/{s_f}""<tab><tab><IF-STMT><tab><tab><tab>hacs.log.info(f""Cleaning up old storage file {path}"")<tab><tab><tab>os.remove(path)",0,if os . path . isfile ( path ) :,if os . path . exists ( path ) :,0.8303088707179008,65.80370064762461,0.6666666666666666
"def action_delete(self, ids):<tab>try:<tab><tab>count = 0<tab><tab># TODO: Optimize me<tab><tab>for pk in ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count += 1<tab><tab>flash(<tab><tab><tab>ngettext(<tab><tab><tab><tab>""Record was successfully deleted."",<tab><tab><tab><tab>""%(count)s records were successfully deleted."",<tab><tab><tab><tab>count,<tab><tab><tab><tab>count=count,<tab><tab><tab>),<tab><tab><tab>""success"",<tab><tab>)<tab>except Exception as ex:<tab><tab>flash(gettext(""Failed to delete records. %(error)s"", error=str(ex)), ""error"")",0,if self . delete_model ( self . get_one ( pk ) ) :,if self . _get_record_deleted ( pk ) :,0.15453041884326196,17.876373514334833,0.6535087719298245
"def test_inclusion(all_values):<tab>for values in [{""guid_2"", ""guid_1""}, {""guid_5"", ""guid_XXX""}, {""guid_2""}]:<tab><tab>test_predicate = in_set(values, ""volume_guid"")<tab><tab>included_values = set()<tab><tab>for val in all_values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>included_values.add(val)<tab><tab>assert included_values == all_values.intersection(values)",0,"if test_predicate . do_include ( { ""volume_guid"" : val } ) :",if test_predicate . search ( val ) :,0.05854665611377268,17.69859637293783,0.48684210526315785
"def _get_attr(sdk_path, mod_attr_path, checked=True):<tab>try:<tab><tab>attr_mod, attr_path = (<tab><tab><tab>mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """")<tab><tab>)<tab><tab>full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path<tab><tab>op = import_module(full_mod_path)<tab><tab>if attr_path:<tab><tab><tab># Only load attributes if needed<tab><tab><tab>for part in attr_path.split("".""):<tab><tab><tab><tab>op = getattr(op, part)<tab><tab>return op<tab>except (ImportError, AttributeError) as ex:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>raise ex",1,if checked :,if checked :,0.5311706625951745,1e-10,1.0
"def __exit__(self, exc_type, exc_val, exc_tb):<tab>if self.fusefat is not None:<tab><tab>self.fusefat.send_signal(signal.SIGINT)<tab><tab># Allow 1s to return without sending terminate<tab><tab>for count in range(10):<tab><tab><tab>time.sleep(0.1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self.fusefat.terminate()<tab><tab>time.sleep(self.delay)<tab><tab>assert not os.path.exists(self.canary)<tab>self.dev_null.close()<tab>shutil.rmtree(self.tmpdir)",0,if self . fusefat . poll ( ) is not None :,if count == 1 :,0.01014113949138936,3.550932348642477,0.17142857142857143
"def check_context_processors(output):<tab>with output.section(""Context processors"") as section:<tab><tab>processors = list(<tab><tab><tab>chain(<tab><tab><tab><tab>*[<tab><tab><tab><tab><tab>template[""OPTIONS""].get(""context_processors"", [])<tab><tab><tab><tab><tab>for template in settings.TEMPLATES<tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>)<tab><tab>required_processors = (""cms.context_processors.cms_settings"",)<tab><tab>for processor in required_processors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>section.error(<tab><tab><tab><tab><tab>""%s context processor must be in TEMPLATES option context_processors""<tab><tab><tab><tab><tab>% processor<tab><tab><tab><tab>)",1,if processor not in processors :,if processor not in processors :,0.75,100.00000000000004,1.0
"def test_converters(self):<tab>response = self._get(""datatypes/converters"")<tab>self._assert_status_code_is(response, 200)<tab>converters_list = response.json()<tab>found_fasta_to_tabular = False<tab>for converter in converters_list:<tab><tab>self._assert_has_key(converter, ""source"", ""target"", ""tool_id"")<tab><tab><IF-STMT><tab><tab><tab>found_fasta_to_tabular = True<tab>assert found_fasta_to_tabular",0,"if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :","if converter [ ""target"" ] == ""fasta"" :",0.21692736116749667,37.78550596618641,0.6458333333333333
"def remove_pid(self, watcher, pid):<tab>if pid in self._pids[watcher]:<tab><tab>logger.debug(""Removing %d from %s"" % (pid, watcher))<tab><tab>self._pids[watcher].remove(pid)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Stopping the periodic callback for {0}"".format(watcher))<tab><tab><tab>self._callbacks[watcher].stop()",0,if len ( self . _pids [ watcher ] ) == 0 :,if watcher in self . _callbacks :,0.020506611992481792,10.19067192997668,0.2773109243697479
"def _fc_layer(self, sess, bottom, name, trainable=True, relu=True):<tab>with tf.variable_scope(name) as scope:<tab><tab>shape = bottom.get_shape().as_list()<tab><tab>dim = 1<tab><tab>for d in shape[1:]:<tab><tab><tab>dim *= d<tab><tab>x = tf.reshape(bottom, [-1, dim])<tab><tab>weight = self._get_fc_weight(sess, name, trainable=trainable)<tab><tab>bias = self._get_bias(sess, name, trainable=trainable)<tab><tab>fc = tf.nn.bias_add(tf.matmul(x, weight), bias)<tab><tab><IF-STMT><tab><tab><tab>fc = tf.nn.relu(fc)<tab><tab>return fc",1,if relu :,if relu :,0.5311706625951745,1e-10,1.0
"def get_drive(self, root_path="""", volume_guid_path=""""):<tab>for drive in self.drives:<tab><tab>if root_path:<tab><tab><tab>config_root_path = drive.get(""root_path"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return drive<tab><tab>elif volume_guid_path:<tab><tab><tab>config_volume_guid_path = drive.get(""volume_guid_path"")<tab><tab><tab>if config_volume_guid_path and config_volume_guid_path == volume_guid_path:<tab><tab><tab><tab>return drive",0,if config_root_path and root_path == config_root_path :,if config_root_path and config_root_path == volume_guid_path :,0.3479267867402462,65.14613449066714,1.0
"def rewire_init(expr):<tab>new_args = []<tab>if expr[0] == HySymbol(""setv""):<tab><tab>pairs = expr[1:]<tab><tab>while len(pairs) > 0:<tab><tab><tab>k, v = (pairs.pop(0), pairs.pop(0))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v.append(HySymbol(""None""))<tab><tab><tab>new_args.append(k)<tab><tab><tab>new_args.append(v)<tab><tab>expr = HyExpression([HySymbol(""setv"")] + new_args).replace(expr)<tab>return expr",0,"if k == HySymbol ( ""__init__"" ) :","if isinstance ( v , HySymbol ) :",0.03779162928217515,5.789419402078114,0.3148148148148148
"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab>if not isinstance(child, minidom.Element):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab>if not isinstance(grandchild, minidom.Element):<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if grandchild.tagName != ""File"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",1,"if child . tagName == ""Directory"" :","if child . tagName == ""Directory"" :",0.75,100.00000000000004,1.0
"def _v2_common(self, cfg):<tab>LOG.debug(""v2_common: handling config:\n%s"", cfg)<tab>if ""nameservers"" in cfg:<tab><tab>search = cfg.get(""nameservers"").get(""search"", [])<tab><tab>dns = cfg.get(""nameservers"").get(""addresses"", [])<tab><tab>name_cmd = {""type"": ""nameserver""}<tab><tab><IF-STMT><tab><tab><tab>name_cmd.update({""search"": search})<tab><tab>if len(dns) > 0:<tab><tab><tab>name_cmd.update({""addresses"": dns})<tab><tab>LOG.debug(""v2(nameserver) -> v1(nameserver):\n%s"", name_cmd)<tab><tab>self.handle_nameserver(name_cmd)",1,if len ( search ) > 0 :,if len ( search ) > 0 :,0.75,100.00000000000004,1.0
"def __start_element_handler(self, name, attrs):<tab>if name == ""mime-type"":<tab><tab>if self.type:<tab><tab><tab>for extension in self.extensions:<tab><tab><tab><tab>self[extension] = self.type<tab><tab>self.type = attrs[""type""].lower()<tab><tab>self.extensions = []<tab>elif name == ""glob"":<tab><tab>pattern = attrs[""pattern""]<tab><tab><IF-STMT><tab><tab><tab>self.extensions.append(pattern[1:].lower())",0,"if pattern . startswith ( ""*."" ) :","if pattern and pattern [ 0 ] == ""."" :",0.03049794507067536,9.669265690880861,0.4166666666666667
"def get_attr_by_data_model(self, dmodel, exclude_record=False):<tab>if exclude_record:<tab><tab>return list(<tab><tab><tab>filter(<tab><tab><tab><tab>lambda x: x.data_model == dmodel and x.value == """"<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else False,<tab><tab><tab><tab>self._inferred_intent,<tab><tab><tab>)<tab><tab>)<tab>else:<tab><tab>return list(<tab><tab><tab>filter(<tab><tab><tab><tab>lambda x: x.data_model == dmodel and x.value == """"<tab><tab><tab><tab>if hasattr(x, ""data_model"")<tab><tab><tab><tab>else False,<tab><tab><tab><tab>self._inferred_intent,<tab><tab><tab>)<tab><tab>)",0,"if x . attribute != ""Record"" and hasattr ( x , ""data_model"" )","if hasattr ( x , ""data_model"" )",0.19274437030682928,40.35921041825187,0.30392156862745096
"def general(metadata, value):<tab>if metadata.get(""commands"") and value:<tab><tab>if not metadata.get(""nargs""):<tab><tab><tab>v = quote(value)<tab><tab>else:<tab><tab><tab>v = value<tab><tab>return u""{0} {1}"".format(metadata[""commands""][0], v)<tab>else:<tab><tab>if not value:<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>return quote(value)<tab><tab>else:<tab><tab><tab>return value",0,"elif not metadata . get ( ""nargs"" ) :","elif metadata . get ( ""nargs"" ) :",0.3794758749277496,81.76129038784515,0.38181818181818183
"def get_images(self):<tab>images = []<tab>try:<tab><tab>tag = MP4(self[""~filename""])<tab>except Exception:<tab><tab>return []<tab>for cover in tag.get(""covr"", []):<tab><tab><IF-STMT><tab><tab><tab>mime = ""image/jpeg""<tab><tab>elif cover.imageformat == MP4Cover.FORMAT_PNG:<tab><tab><tab>mime = ""image/png""<tab><tab>else:<tab><tab><tab>mime = ""image/""<tab><tab>f = get_temp_cover_file(cover)<tab><tab>images.append(EmbeddedImage(f, mime))<tab>return images",1,if cover . imageformat == MP4Cover . FORMAT_JPEG :,if cover . imageformat == MP4Cover . FORMAT_JPEG :,0.75,100.00000000000004,1.0
"def run_cmd(self, util, value):<tab>state = util.state<tab>if not state.argument_supplied:<tab><tab>state.argument_supplied = True<tab><tab>if value == ""by_four"":<tab><tab><tab>state.argument_value = 4<tab><tab><IF-STMT><tab><tab><tab>state.argument_negative = True<tab><tab>else:<tab><tab><tab>state.argument_value = value<tab>elif value == ""by_four"":<tab><tab>state.argument_value *= 4<tab>elif isinstance(value, int):<tab><tab>state.argument_value *= 10<tab><tab>state.argument_value += value<tab>elif value == ""negative"":<tab><tab>state.argument_value = -state.argument_value",1,"elif value == ""negative"" :","elif value == ""negative"" :",1.0,100.00000000000004,1.0
"def finish_character_data(self):<tab>if self.character_data:<tab><tab><IF-STMT><tab><tab><tab>line, column = self.character_pos<tab><tab><tab>token = XmlToken(<tab><tab><tab><tab>XML_CHARACTER_DATA, self.character_data, None, line, column<tab><tab><tab>)<tab><tab><tab>self.tokens.append(token)<tab><tab>self.character_data = """"",0,if not self . skip_ws or not self . character_data . isspace ( ) :,if self . character_pos :,0.013887228846722825,8.194094675927117,0.29365079365079366
"def check_syntax(filename, raise_error=False):<tab>""""""Return True if syntax is okay.""""""<tab>with autopep8.open_with_encoding(filename) as input_file:<tab><tab>try:<tab><tab><tab>compile(input_file.read(), ""<string>"", ""exec"", dont_inherit=True)<tab><tab><tab>return True<tab><tab>except (SyntaxError, TypeError, UnicodeDecodeError):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>return False",1,if raise_error :,if raise_error :,0.5311706625951745,1e-10,1.0
"def write(self, file):<tab>if not self._been_written:<tab><tab>self._been_written = True<tab><tab>for attribute, value in self.__dict__.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.write_recursive(value, file)<tab><tab>w = file.write<tab><tab>w(""\t%s = {\n"" % self._id)<tab><tab>w(""\t\tisa = %s;\n"" % self.__class__.__name__)<tab><tab>for attribute, value in self.__dict__.items():<tab><tab><tab>if attribute[0] != ""_"":<tab><tab><tab><tab>w(""\t\t%s = %s;\n"" % (attribute, self.tostring(value)))<tab><tab>w(""\t};\n\n"")",0,"if attribute [ 0 ] != ""_"" :","if attribute [ 0 ] == ""_"" :",0.5490406812970063,70.16879391277372,1.0
"def update_service_key(kid, name=None, metadata=None):<tab>try:<tab><tab>with db_transaction():<tab><tab><tab>key = db_for_update(ServiceKey.select().where(ServiceKey.kid == kid)).get()<tab><tab><tab>if name is not None:<tab><tab><tab><tab>key.name = name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key.metadata.update(metadata)<tab><tab><tab>key.save()<tab>except ServiceKey.DoesNotExist:<tab><tab>raise ServiceKeyDoesNotExist",1,if metadata is not None :,if metadata is not None :,0.75,100.00000000000004,1.0
"def fill_buf(self, db, len_=None):<tab>with open(""/dev/urandom"", ""rb"") as rfh:<tab><tab>first = True<tab><tab>for (id_,) in db.query(""SELECT id FROM test""):<tab><tab><tab>if len_ is None and first:<tab><tab><tab><tab>val = b""""  # We always want to check this case<tab><tab><tab><tab>first = False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = rfh.read(random.randint(0, 140))<tab><tab><tab>else:<tab><tab><tab><tab>val = rfh.read(len_)<tab><tab><tab>db.execute(""UPDATE test SET buf=? WHERE id=?"", (val, id_))",1,elif len_ is None :,elif len_ is None :,0.75,100.00000000000004,1.0
"def load_category_from_parser(self, parser):<tab>for cate in parser.keys():<tab><tab>id = parser.get_id(cate)<tab><tab><IF-STMT><tab><tab><tab>self._data[""cates""][id] = 0<tab><tab>else:<tab><tab><tab>self._data[""cates""][id] = self.count_unread(id)<tab>self._is_init = False<tab>self.save()",0,if self . _is_init :,"if id not in self . _data [ ""cates"" ] :",0.04653310606876049,12.011055432195764,0.3
"def after_insert(self):<tab>if self.prescription:<tab><tab>frappe.db.set_value(<tab><tab><tab>""Lab Prescription"", self.prescription, ""lab_test_created"", 1<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.invoiced = True<tab>if not self.lab_test_name and self.template:<tab><tab>self.load_test_from_template()<tab><tab>self.reload()",0,"if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :",if not self . invoiced :,0.01226147020172297,1.2005861999569136,0.245
"def sync_terminology(self):<tab>if self.is_source:<tab><tab>return<tab>store = self.store<tab>missing = []<tab>for source in self.component.get_all_sources():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>_unit, add = store.find_unit(source.context, source.source)<tab><tab>except UnitNotFound:<tab><tab><tab>add = True<tab><tab># Unit is already present<tab><tab>if not add:<tab><tab><tab>continue<tab><tab>missing.append((source.context, source.source, """"))<tab>if missing:<tab><tab>self.add_units(None, missing)",0,"if ""terminology"" not in source . all_flags :",if source . context is None :,0.12010185649780411,7.64649370538093,0.23214285714285715
def refresh(self):<tab>if self._obj:<tab><tab>base = self._db.get_media_from_handle(self._obj.get_reference_handle())<tab><tab><IF-STMT><tab><tab><tab>self._title = base.get_description()<tab><tab><tab>self._value = base.get_path(),1,if base :,if base :,0.5311706625951745,1e-10,1.0
"def _set_parse_context(self, tag, tag_attrs):<tab># special case: script or style parse context<tab>if not self._wb_parse_context:<tab><tab>if tag == ""style"":<tab><tab><tab>self._wb_parse_context = ""style""<tab><tab><IF-STMT><tab><tab><tab>if self._allow_js_type(tag_attrs):<tab><tab><tab><tab>self._wb_parse_context = ""script""",1,"elif tag == ""script"" :","elif tag == ""script"" :",1.0,100.00000000000004,1.0
"def can_read(self):<tab>if hasattr(self.file, ""__iter__""):<tab><tab>iterator = iter(self.file)<tab><tab>head = next(iterator, None)<tab><tab>if head is None:<tab><tab><tab>self.repaired = []<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>self.repaired = itertools.chain([head], iterator)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab># We may have mangled a generator at this point, so just abort<tab><tab><tab>raise IOSourceError(<tab><tab><tab><tab>""Could not open source: %r (mode: %r)""<tab><tab><tab><tab>% (self.file, self.options[""mode""])<tab><tab><tab>)<tab>return False",0,"if isinstance ( head , str ) :","elif isinstance ( head , list ) :",0.1956586942207979,41.11336169005198,0.42857142857142855
"def wrapped_request_method(*args, **kwargs):<tab>""""""Modifies HTTP headers to include a specified user-agent.""""""<tab>if kwargs.get(""headers"") is not None:<tab><tab>if kwargs[""headers""].get(""user-agent""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Save the existing user-agent header and tack on our own.<tab><tab><tab><tab>kwargs[""headers""][""user-agent""] = (<tab><tab><tab><tab><tab>f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}'<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>kwargs[""headers""][""user-agent""] = user_agent<tab>else:<tab><tab>kwargs[""headers""] = {""user-agent"": user_agent}<tab>return request_method(*args, **kwargs)",0,"if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :","if user_agent not in kwargs [ ""headers"" ] :",0.48747904663455105,66.30164262051262,1.0
"def execute(self):<tab>if self._dirty or not self._qr:<tab><tab>model_class = self.model_class<tab><tab>query_meta = self.get_query_meta()<tab><tab>if self._tuples:<tab><tab><tab>ResultWrapper = TuplesQueryResultWrapper<tab><tab>elif self._dicts:<tab><tab><tab>ResultWrapper = DictQueryResultWrapper<tab><tab><IF-STMT><tab><tab><tab>ResultWrapper = NaiveQueryResultWrapper<tab><tab>elif self._aggregate_rows:<tab><tab><tab>ResultWrapper = AggregateQueryResultWrapper<tab><tab>else:<tab><tab><tab>ResultWrapper = ModelQueryResultWrapper<tab><tab>self._qr = ResultWrapper(model_class, self._execute(), query_meta)<tab><tab>self._dirty = False<tab><tab>return self._qr<tab>else:<tab><tab>return self._qr",0,elif self . _naive or not self . _joins or self . verify_naive ( ) :,elif self . _naive :,0.08089228341137716,7.711896755350043,0.45652173913043476
"def populate_data(apps, schema_editor):<tab>Menu = apps.get_model(""menu"", ""Menu"")<tab>for menu in Menu.objects.all():<tab><tab><IF-STMT><tab><tab><tab>json_str = menu.json_content<tab><tab><tab>while isinstance(json_str, str):<tab><tab><tab><tab>json_str = json.loads(json_str)<tab><tab><tab>menu.json_content_new = json_str<tab><tab><tab>menu.save()",1,"if isinstance ( menu . json_content , str ) :","if isinstance ( menu . json_content , str ) :",0.75,100.00000000000004,1.0
"def virtualenv_exists(self):<tab>if os.path.exists(self.virtualenv_location):<tab><tab><IF-STMT><tab><tab><tab>extra = [""Scripts"", ""activate.bat""]<tab><tab>else:<tab><tab><tab>extra = [""bin"", ""activate""]<tab><tab>return os.path.isfile(os.sep.join([self.virtualenv_location] + extra))<tab>return False",0,"if os . name == ""nt"" :","if sys . platform == ""win32"" :",0.2740826569440559,21.36435031981171,0.3333333333333333
"def get_minkowski_function(name, variable):<tab>fn_name = name + get_postfix(variable)<tab>if hasattr(MEB, fn_name):<tab><tab>return getattr(MEB, fn_name)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""Function {fn_name} not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise ValueError(f""Function {fn_name} not available."")",0,if variable . is_cuda :,if torch . cuda . is_available ( ) :,0.02675254074710682,16.59038701421971,0.38461538461538464
"def build_temp_workspace(files):<tab>tempdir = tempfile.mkdtemp(prefix=""yamllint-tests-"")<tab>for path, content in files.items():<tab><tab>path = os.path.join(tempdir, path).encode(""utf-8"")<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(os.path.dirname(path))<tab><tab>if type(content) is list:<tab><tab><tab>os.mkdir(path)<tab><tab>else:<tab><tab><tab>mode = ""wb"" if isinstance(content, bytes) else ""w""<tab><tab><tab>with open(path, mode) as f:<tab><tab><tab><tab>f.write(content)<tab>return tempdir",0,if not os . path . exists ( os . path . dirname ( path ) ) :,if type ( path ) is dict :,0.06363175483668304,6.691863570734902,0.18181818181818182
"def clean_form(self, request, user, form, cleaned_data):<tab>for field in self.get_fields():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>cleaned_data[field.fieldname] = field.clean(<tab><tab><tab><tab>request, user, cleaned_data[field.fieldname]<tab><tab><tab>)<tab><tab>except ValidationError as e:<tab><tab><tab>form.add_error(field.fieldname, e)<tab>return cleaned_data",0,if field . fieldname not in cleaned_data :,if field . hidden :,0.12055598522870314,15.719010513286515,0.39285714285714285
"def setUp(self):<tab>self.realm = service.InMemoryWordsRealm(""realmname"")<tab>self.checker = checkers.InMemoryUsernamePasswordDatabaseDontUse()<tab>self.portal = portal.Portal(self.realm, [self.checker])<tab>self.factory = service.IRCFactory(self.realm, self.portal)<tab>c = []<tab>for nick in self.STATIC_USERS:<tab><tab><IF-STMT><tab><tab><tab>nick = nick.decode(""utf-8"")<tab><tab>c.append(self.realm.createUser(nick))<tab><tab>self.checker.addUser(nick, nick + ""_password"")<tab>return DeferredList(c)",1,"if isinstance ( nick , bytes ) :","if isinstance ( nick , bytes ) :",0.75,100.00000000000004,1.0
"def __call__(self, message):<tab>with self._lock:<tab><tab>self._pending_ack += 1<tab><tab>self.max_pending_ack = max(self.max_pending_ack, self._pending_ack)<tab><tab>self.seen_message_ids.append(int(message.attributes[""seq_num""]))<tab>time.sleep(self._processing_time)<tab>with self._lock:<tab><tab>self._pending_ack -= 1<tab><tab>message.ack()<tab><tab>self.completed_calls += 1<tab><tab><IF-STMT><tab><tab><tab>if not self.done_future.done():<tab><tab><tab><tab>self.done_future.set_result(None)",0,if self . completed_calls >= self . _resolve_at_msg_count :,if self . done_future is not None :,0.12967697280747226,7.21555652598855,0.41111111111111115
"def fill_in_standard_formats(book):<tab>for x in std_format_code_types.keys():<tab><tab><IF-STMT><tab><tab><tab>ty = std_format_code_types[x]<tab><tab><tab># Note: many standard format codes (mostly CJK date formats) have<tab><tab><tab># format strings that vary by locale; xlrd does not (yet)<tab><tab><tab># handle those; the type (date or numeric) is recorded but the fmt_str will be None.<tab><tab><tab>fmt_str = std_format_strings.get(x)<tab><tab><tab>fmtobj = Format(x, ty, fmt_str)<tab><tab><tab>book.format_map[x] = fmtobj",0,if x not in book . format_map :,if x in std_format_strings :,0.03730445553501224,13.354339892249618,0.4583333333333333
"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None):<tab>result = []<tab>for i in range(10):<tab><tab># This line introduces a bug.<tab><tab>if bigger_than_3_only and less_than_7_only and i == 4:<tab><tab><tab>continue<tab><tab>if bigger_than_3_only and i <= 3:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if even_only and i % 2 != 0:<tab><tab><tab>continue<tab><tab>result.append(i)<tab>return result",1,if less_than_7_only and i >= 7 :,if less_than_7_only and i >= 7 :,0.75,100.00000000000004,1.0
"def next_instruction_is_function_or_class(lines):<tab>""""""Is the first non-empty, non-commented line of the cell either a function or a class?""""""<tab>parser = StringParser(""python"")<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>parser.read_line(line)<tab><tab><tab>continue<tab><tab>parser.read_line(line)<tab><tab>if not line.strip():  # empty line<tab><tab><tab>if i > 0 and not lines[i - 1].strip():<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>if line.startswith(""def "") or line.startswith(""class ""):<tab><tab><tab>return True<tab><tab>if line.startswith((""#"", ""@"", "" "", "")"")):<tab><tab><tab>continue<tab><tab>return False<tab>return False",0,if parser . is_quoted ( ) :,if not line . strip ( ) :,0.08709053828519989,20.612390921238426,0.3
"def __getattr__(self, key):<tab>for tag in self.tag.children:<tab><tab>if tag.name not in (""input"",):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation<tab><tab><tab>return DOMImplementation.createHTMLElement(self.doc, tag)<tab>raise AttributeError",0,"if ""name"" in tag . attrs and tag . attrs [ ""name"" ] in ( key , ) :",if tag . name == key :,0.011429598825377921,2.22913228475959,0.225
"def process_signature(app, what, name, obj, options, signature, return_annotation):<tab>if signature:<tab><tab># replace Mock function names<tab><tab>signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature)<tab><tab>signature = re.sub(""tensorflow"", ""tf"", signature)<tab><tab># add scope name to layer signatures:<tab><tab><IF-STMT><tab><tab><tab>if obj.use_scope:<tab><tab><tab><tab>signature = signature[0] + ""variable_scope_name, "" + signature[1:]<tab><tab><tab>elif obj.use_scope is None:<tab><tab><tab><tab>signature = signature[0] + ""[variable_scope_name,] "" + signature[1:]<tab># signature: arg list<tab>return signature, return_annotation",0,"if hasattr ( obj , ""use_scope"" ) :","if name == ""scope"" :",0.01858685153282265,8.423555525647696,0.38181818181818183
"def countbox(self):<tab>self.box = [1000, 1000, -1000, -1000]<tab>for x, y in self.body:<tab><tab>if x < self.box[0]:<tab><tab><tab>self.box[0] = x<tab><tab>if x > self.box[2]:<tab><tab><tab>self.box[2] = x<tab><tab>if y < self.box[1]:<tab><tab><tab>self.box[1] = y<tab><tab><IF-STMT><tab><tab><tab>self.box[3] = y",1,if y > self . box [ 3 ] :,if y > self . box [ 3 ] :,0.75,100.00000000000004,1.0
"def find_shell():<tab>global DEFAULT_SHELL<tab>if not DEFAULT_SHELL:<tab><tab>for shell in propose_shell():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>DEFAULT_SHELL = shell<tab><tab><tab><tab>break<tab>if not DEFAULT_SHELL:<tab><tab>DEFAULT_SHELL = ""/bin/sh""<tab>return DEFAULT_SHELL",0,"if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :",if os . path . isfile ( shell ) :,0.27604950265628736,25.361941085726006,0.6226851851851851
"def addAggregators(sheet, cols, aggrnames):<tab>""Add each aggregator in list of *aggrnames* to each of *cols*.""<tab>for aggrname in aggrnames:<tab><tab>aggrs = vd.aggregators.get(aggrname)<tab><tab>aggrs = aggrs if isinstance(aggrs, list) else [aggrs]<tab><tab>for aggr in aggrs:<tab><tab><tab>for c in cols:<tab><tab><tab><tab>if not hasattr(c, ""aggregators""):<tab><tab><tab><tab><tab>c.aggregators = []<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>c.aggregators += [aggr]",0,if aggr and aggr not in c . aggregators :,"if not hasattr ( c , ""aggregators"" ) :",0.046994526211108195,5.604233375480572,0.16666666666666666
"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>items.append(item.pathAbsoluteFromProjectEncoded())<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item copied"")",1,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,100.00000000000004,1.0
"def social_user(backend, uid, user=None, *args, **kwargs):<tab>provider = backend.name<tab>social = backend.strategy.storage.user.get_social_auth(provider, uid)<tab>if social:<tab><tab><IF-STMT><tab><tab><tab>msg = ""This account is already in use.""<tab><tab><tab>raise AuthAlreadyAssociated(backend, msg)<tab><tab>elif not user:<tab><tab><tab>user = social.user<tab>return {<tab><tab>""social"": social,<tab><tab>""user"": user,<tab><tab>""is_new"": user is None,<tab><tab>""new_association"": social is None,<tab>}",0,if user and social . user != user :,if social . user :,0.07697997421843797,18.393972058572114,0.3333333333333333
"def _text(bitlist):<tab>out = """"<tab>for typ, text in bitlist:<tab><tab>if not typ:<tab><tab><tab>out += text<tab><tab>elif typ == ""em"":<tab><tab><tab>out += ""\\fI%s\\fR"" % text<tab><tab><IF-STMT><tab><tab><tab>out += ""\\fB%s\\fR"" % text<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected tag %r inside text"" % (typ,))<tab>out = out.strip()<tab>out = re.sub(re.compile(r""^\s+"", re.M), """", out)<tab>return out",0,"elif typ in [ ""strong"" , ""code"" ] :","elif typ == ""b"" :",0.028155587320909295,7.433761660133445,0.7307692307692308
"def OnRadioSelect(self, event):<tab>fitID = self.mainFrame.getActiveFit()<tab>if fitID is not None:<tab><tab>self.mainFrame.command.Submit(<tab><tab><tab>cmd.GuiChangeImplantLocationCommand(<tab><tab><tab><tab>fitID=fitID,<tab><tab><tab><tab>source=ImplantLocation.FIT<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else ImplantLocation.CHARACTER,<tab><tab><tab>)<tab><tab>)",0,if self . rbFit . GetValue ( ),if fitID is not None,0.0167545042016483,5.862502026550896,0.20634920634920637
"def hexdump(data):<tab>""""""yield lines with hexdump of data""""""<tab>values = []<tab>ascii = []<tab>offset = 0<tab>for h, a in sixteen(data):<tab><tab><IF-STMT><tab><tab><tab>yield (offset, "" "".join(["""".join(values), """".join(ascii)]))<tab><tab><tab>del values[:]<tab><tab><tab>del ascii[:]<tab><tab><tab>offset += 0x10<tab><tab>else:<tab><tab><tab>values.append(h)<tab><tab><tab>ascii.append(a)",0,if h is None :,"if h == """" :",0.06497877230811641,14.535768424205482,0.5
"def submit(self):<tab>bot_token = self.config[""bot_token""]<tab>chat_ids = self.config[""chat_id""]<tab>chat_ids = [chat_ids] if isinstance(chat_ids, str) else chat_ids<tab>text = ""\n"".join(super().submit())<tab>if not text:<tab><tab>logger.debug(""Not calling telegram API (no changes)"")<tab><tab>return<tab>result = None<tab>for chunk in chunkstring(text, self.MAX_LENGTH, numbering=True):<tab><tab>for chat_id in chat_ids:<tab><tab><tab>res = self.submitToTelegram(bot_token, chat_id, chunk)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = res<tab>return result",0,if res . status_code != requests . codes . ok or res is None :,if res :,0.010227354392330742,1e-10,0.2553606237816764
"def onMessage(self, payload, isBinary):<tab>if not isBinary:<tab><tab>self.result = ""Expected binary message with payload, but got binary.""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.result = (<tab><tab><tab><tab>""Expected binary message with payload of length %d, but got %d.""<tab><tab><tab><tab>% (self.DATALEN, len(payload))<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>## FIXME : check actual content<tab><tab><tab>##<tab><tab><tab>self.behavior = Case.OK<tab><tab><tab>self.result = ""Received binary message of length %d."" % len(payload)<tab>self.p.createWirelog = True<tab>self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",1,if len ( payload ) != self . DATALEN :,if len ( payload ) != self . DATALEN :,0.75,100.00000000000004,1.0
"def verify_output(actual, expected):<tab>actual = _read_file(actual, ""Actual"")<tab>expected = _read_file(join(CURDIR, expected), ""Expected"")<tab>if len(expected) != len(actual):<tab><tab>raise AssertionError(<tab><tab><tab>""Lengths differ. Expected %d lines but got %d""<tab><tab><tab>% (len(expected), len(actual))<tab><tab>)<tab>for exp, act in zip(expected, actual):<tab><tab>tester = fnmatchcase if ""*"" in exp else eq<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>""Lines differ.\nExpected: %s\nActual:   %s"" % (exp, act)<tab><tab><tab>)",0,"if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :",if nottester ( act ) :,0.015151315925389718,3.8810150592173795,0.22916666666666669
"def _in_out_vector_helper(self, name1, name2, ceil):<tab>vector = []<tab>stats = self.record<tab>if ceil is None:<tab><tab>ceil = self._get_max_rate(name1, name2)<tab>maxlen = self.config.get_stats_history_length()<tab>for n in [name1, name2]:<tab><tab>for i in range(maxlen + 1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vector.append(float(stats[i][n]) / ceil)<tab><tab><tab>else:<tab><tab><tab><tab>vector.append(0.0)<tab>return vector",0,if i < len ( stats ) :,if stats [ i ] [ n ] > ceil :,0.01721726452019353,5.300156689756295,0.27472527472527475
"def _init_param(param, mode):<tab>if isinstance(param, str):<tab><tab>param = _resolve(param)<tab>elif isinstance(param, (list, tuple)):<tab><tab>param = [_init_param(p, mode) for p in param]<tab>elif isinstance(param, dict):<tab><tab><IF-STMT><tab><tab><tab>param = from_params(param, mode=mode)<tab><tab>else:<tab><tab><tab>param = {k: _init_param(v, mode) for k, v in param.items()}<tab>return param",0,"if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :","if isinstance ( param , list ) :",0.016243639774773097,1.4189245065793463,0.42857142857142855
"def link_pantsrefs(soups, precomputed):<tab>""""""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">""""""<tab>for (page, soup) in soups.items():<tab><tab>for a in soup.find_all(""a""):<tab><tab><tab>if not a.has_attr(""pantsref""):<tab><tab><tab><tab>continue<tab><tab><tab>pantsref = a[""pantsref""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TaskError(<tab><tab><tab><tab><tab>f'Page {page} has pantsref ""{pantsref}"" and I cannot find pantsmark for it'<tab><tab><tab><tab>)<tab><tab><tab>a[""href""] = rel_href(page, precomputed.pantsref[pantsref])",1,if pantsref not in precomputed . pantsref :,if pantsref not in precomputed . pantsref :,0.75,100.00000000000004,1.0
"def _gridconvvalue(self, value):<tab>if isinstance(value, (str, _tkinter.Tcl_Obj)):<tab><tab>try:<tab><tab><tab>svalue = str(value)<tab><tab><tab>if not svalue:<tab><tab><tab><tab>return None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return getdouble(svalue)<tab><tab><tab>else:<tab><tab><tab><tab>return getint(svalue)<tab><tab>except ValueError:<tab><tab><tab>pass<tab>return value",0,"elif ""."" in svalue :",elif svalue . isdigit ( ) :,0.07854569132828848,9.287528999566801,0.4
"def default(self, o):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return str(o)<tab><tab>else:<tab><tab><tab># remove unwanted attributes from the provider object during conversion to json<tab><tab><tab>if hasattr(o, ""profile""):<tab><tab><tab><tab>del o.profile<tab><tab><tab>if hasattr(o, ""credentials""):<tab><tab><tab><tab>del o.credentials<tab><tab><tab>if hasattr(o, ""metadata_path""):<tab><tab><tab><tab>del o.metadata_path<tab><tab><tab>if hasattr(o, ""services_config""):<tab><tab><tab><tab>del o.services_config<tab><tab><tab>return vars(o)<tab>except Exception as e:<tab><tab>return str(o)",0,if type ( o ) == datetime . datetime :,"if isinstance ( o , basestring ) :",0.029321108690485986,9.545138913210204,0.4155844155844156
"def transform_kwarg(self, name, value, split_single_char_options):<tab>if len(name) == 1:<tab><tab><IF-STMT><tab><tab><tab>return [""-%s"" % name]<tab><tab>elif value not in (False, None):<tab><tab><tab>if split_single_char_options:<tab><tab><tab><tab>return [""-%s"" % name, ""%s"" % value]<tab><tab><tab>else:<tab><tab><tab><tab>return [""-%s%s"" % (name, value)]<tab>else:<tab><tab>if value is True:<tab><tab><tab>return [""--%s"" % dashify(name)]<tab><tab>elif value is not False and value is not None:<tab><tab><tab>return [""--%s=%s"" % (dashify(name), value)]<tab>return []",0,if value is True :,"if value in ( True , None ) :",0.04975840882008457,11.339582221952005,0.5555555555555556
"def handle(self, context, sign, *args):<tab>if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP):<tab><tab>return Infsign[sign]<tab>if sign == 0:<tab><tab><IF-STMT><tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))<tab>if sign == 1:<tab><tab>if context.rounding == ROUND_FLOOR:<tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",0,if context . rounding == ROUND_CEILING :,if context . rounding == ROUND_FLOOR :,0.574113272471593,78.25422900366438,1.0
"def OnLeftUp(self, event):<tab># Stop Drawing<tab>if self.Drawing:<tab><tab>self.Drawing = False<tab><tab><IF-STMT><tab><tab><tab>world_rect = (<tab><tab><tab><tab>self.Canvas.PixelToWorld(self.RBRect[0]),<tab><tab><tab><tab>self.Canvas.ScalePixelToWorld(self.RBRect[1]),<tab><tab><tab>)<tab><tab><tab>wx.CallAfter(self.CallBack, world_rect)<tab>self.RBRect = None",0,if self . RBRect :,if self . RBRect is not None :,0.3514988343435983,36.55552228545123,0.5102040816326531
"def _map_answers(answers):<tab>result = []<tab>for a in answers.split(""|""):<tab><tab>user_answers = []<tab><tab>result.append(dict(sourcerAnswers=user_answers))<tab><tab>for r in a.split("",""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>user_answers.append(dict(noAnswer=True))<tab><tab><tab>else:<tab><tab><tab><tab>start_, end_ = map(int, r.split("":""))<tab><tab><tab><tab>user_answers.append(dict(s=start_, e=end_))<tab>return result",0,"if r == ""None"" :","if "":"" not in r :",0.032294703547118726,13.888095170058955,0.3333333333333333
"def parse_edges(self, pcb):<tab>edges = []<tab>drawings = list(pcb.GetDrawings())<tab>bbox = None<tab>for m in pcb.GetModules():<tab><tab>for g in m.GraphicalItems():<tab><tab><tab>drawings.append(g)<tab>for d in drawings:<tab><tab><IF-STMT><tab><tab><tab>parsed_drawing = self.parse_drawing(d)<tab><tab><tab>if parsed_drawing:<tab><tab><tab><tab>edges.append(parsed_drawing)<tab><tab><tab><tab>if bbox is None:<tab><tab><tab><tab><tab>bbox = d.GetBoundingBox()<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>bbox.Merge(d.GetBoundingBox())<tab>if bbox:<tab><tab>bbox.Normalize()<tab>return edges, bbox",0,if d . GetLayer ( ) == pcbnew . Edge_Cuts :,"if isinstance ( d , dict ) :",0.014690094413619983,3.9007608550932686,0.2857142857142857
"def get_size(self):<tab>size = self.start_size<tab>for operation in self.ran_operations:<tab><tab><IF-STMT><tab><tab><tab>size = operation[1][0]<tab><tab>elif operation[0] == ""crop"":<tab><tab><tab>crop = operation[1][0]<tab><tab><tab>size = crop[2] - crop[0], crop[3] - crop[1]<tab>return size",0,"if operation [ 0 ] == ""resize"" :","if operation [ 0 ] == ""size"" :",0.605621305873661,74.19446627365011,1.0
"def migrate_account_metadata(account_id):<tab>from inbox.models.session import session_scope<tab>from inbox.models import Account<tab>with session_scope(versioned=False) as db_session:<tab><tab>account = db_session.query(Account).get(account_id)<tab><tab><IF-STMT><tab><tab><tab>create_categories_for_easfoldersyncstatuses(account, db_session)<tab><tab>else:<tab><tab><tab>create_categories_for_folders(account, db_session)<tab><tab>if account.discriminator == ""gmailaccount"":<tab><tab><tab>set_labels_for_imapuids(account, db_session)<tab><tab>db_session.commit()",0,"if account . discriminator == ""easaccount"" :","if account . discriminator == ""easfoldersyncstatuses"" :",0.574113272471593,70.71067811865478,1.0
"def OnEndDrag(self, event):<tab>self.StopDragging()<tab>dropTarget = event.GetItem()<tab>if not dropTarget:<tab><tab>dropTarget = self.GetRootItem()<tab>if self.IsValidDropTarget(dropTarget):<tab><tab>self.UnselectAll()<tab><tab><IF-STMT><tab><tab><tab>self.SelectItem(dropTarget)<tab><tab>self.OnDrop(dropTarget, self._dragItem)",0,if dropTarget != self . GetRootItem ( ) :,if self . IsValidDropTarget ( dropTarget ) :,0.0421401902558312,13.991316187881289,0.3333333333333333
"def validate(self, frame, value):<tab>if self.sep and isinstance(value, string_types):<tab><tab>value = value.split(self.sep)<tab>if isinstance(value, list):<tab><tab><IF-STMT><tab><tab><tab>return [self.specs[0].validate(frame, v) for v in value]<tab><tab>else:<tab><tab><tab>return [<tab><tab><tab><tab>[s.validate(frame, v) for (v, s) in izip(val, self.specs)]<tab><tab><tab><tab>for val in value<tab><tab><tab>]<tab>raise ValueError(""Invalid MultiSpec data: %r"" % value)",1,if len ( self . specs ) == 1 :,if len ( self . specs ) == 1 :,0.75,100.00000000000004,1.0
"def __init__(self, action_space=None, network=None, network_kwargs=None, hparams=None):<tab>QNetBase.__init__(self, hparams=hparams)<tab>with tf.variable_scope(self.variable_scope):<tab><tab><IF-STMT><tab><tab><tab>action_space = Space(low=0, high=self._hparams.action_space, dtype=np.int32)<tab><tab>self._action_space = action_space<tab><tab>self._append_output_layer()",1,if action_space is None :,if action_space is None :,0.75,100.00000000000004,1.0
"def n_weights(self):<tab>""""""Return the number of weights (parameters) in this network.""""""<tab>n_weights = 0<tab>for i, w in enumerate(self.all_weights):<tab><tab>n = 1<tab><tab># for s in p.eval().shape:<tab><tab>for s in w.get_shape():<tab><tab><tab>try:<tab><tab><tab><tab>s = int(s)<tab><tab><tab>except:<tab><tab><tab><tab>s = 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n = n * s<tab><tab>n_weights = n_weights + n<tab># print(""num of weights (parameters) %d"" % n_weights)<tab>return n_weights",0,if s :,if i % 2 == 0 :,0.04579081141525348,1e-10,0.2916666666666667
"def _arg_desc(name, ctx):<tab>for param in ctx.command.params:<tab><tab>if param.name == name:<tab><tab><tab>desc = param.opts[-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>desc = param.human_readable_name<tab><tab><tab>return desc<tab>raise AssertionError(name)",0,"if desc [ 0 ] != ""-"" :",if param . human_readable_name :,0.01858685153282265,4.540013809283726,0.38181818181818183
"def walk(directory, path_so_far):<tab>for name in sorted(os.listdir(directory)):<tab><tab>if any(fnmatch(name, pattern) for pattern in basename_ignore):<tab><tab><tab>continue<tab><tab>path = path_so_far + ""/"" + name if path_so_far else name<tab><tab>if any(fnmatch(path, pattern) for pattern in path_ignore):<tab><tab><tab>continue<tab><tab>full_name = os.path.join(directory, name)<tab><tab>if os.path.isdir(full_name):<tab><tab><tab>for file_path in walk(full_name, path):<tab><tab><tab><tab>yield file_path<tab><tab><IF-STMT><tab><tab><tab>yield path",1,elif os . path . isfile ( full_name ) :,elif os . path . isfile ( full_name ) :,0.75,100.00000000000004,1.0
"def cache_dst(self):<tab>final_dst = None<tab>final_linenb = None<tab>for linenb, assignblk in enumerate(self):<tab><tab>for dst, src in viewitems(assignblk):<tab><tab><tab>if dst.is_id(""IRDst""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(""Multiple destinations!"")<tab><tab><tab><tab>final_dst = src<tab><tab><tab><tab>final_linenb = linenb<tab>self._dst = final_dst<tab>self._dst_linenb = final_linenb<tab>return final_dst",0,if final_dst is not None :,if len ( src ) > 1 :,0.022316443924793247,6.567274736060395,0.25
"def run(self, args, **kwargs):<tab>if args.resource_ref or args.policy_type:<tab><tab>filters = {}<tab><tab><IF-STMT><tab><tab><tab>filters[""resource_ref""] = args.resource_ref<tab><tab>if args.policy_type:<tab><tab><tab>filters[""policy_type""] = args.policy_type<tab><tab>filters.update(**kwargs)<tab><tab>return self.manager.query(**filters)<tab>else:<tab><tab>return self.manager.get_all(**kwargs)",1,if args . resource_ref :,if args . resource_ref :,0.75,100.00000000000004,1.0
"def __init__(self, folders):<tab>self.folders = folders<tab>self.duplicates = {}<tab>for folder, path in folders.items():<tab><tab>duplicates = []<tab><tab>for other_folder, other_path in folders.items():<tab><tab><tab>if other_folder == folder:<tab><tab><tab><tab>continue<tab><tab><tab>if other_path == path:<tab><tab><tab><tab>duplicates.append(other_folder)<tab><tab><IF-STMT><tab><tab><tab>self.duplicates[folder] = duplicates",0,if len ( duplicates ) :,if duplicates :,0.028363593025821247,1e-10,0.4642857142857143
"def limit_clause(self, select, **kw):<tab>text = """"<tab>if select._limit_clause is not None:<tab><tab>text += ""\n LIMIT "" + self.process(select._limit_clause, **kw)<tab>if select._offset_clause is not None:<tab><tab><IF-STMT><tab><tab><tab>text += ""\n LIMIT "" + self.process(sql.literal(-1))<tab><tab>text += "" OFFSET "" + self.process(select._offset_clause, **kw)<tab>else:<tab><tab>text += "" OFFSET "" + self.process(sql.literal(0), **kw)<tab>return text",0,if select . _limit_clause is None :,if select . _offset_clause is not None :,0.24981588323865592,37.81790427652475,0.6428571428571429
"def _get_activation(self, act):<tab>""""""Get activation block based on the name.""""""<tab>if isinstance(act, str):<tab><tab>if act.lower() == ""gelu"":<tab><tab><tab>return GELU()<tab><tab><IF-STMT><tab><tab><tab>return GELU(approximate=True)<tab><tab>else:<tab><tab><tab>return gluon.nn.Activation(act)<tab>assert isinstance(act, gluon.Block)<tab>return act",0,"elif act . lower ( ) == ""approx_gelu"" :","elif act . lower ( ) == ""gelu"" :",0.6253119268751697,70.63486135430557,1.0
"def __eq__(self, other):<tab>try:<tab><tab>if self.type != other.type:<tab><tab><tab>return False<tab><tab>if self.type == ""ASK"":<tab><tab><tab>return self.askAnswer == other.askAnswer<tab><tab><IF-STMT><tab><tab><tab>return self.vars == other.vars and self.bindings == other.bindings<tab><tab>else:<tab><tab><tab>return self.graph == other.graph<tab>except:<tab><tab>return False",0,"elif self . type == ""SELECT"" :","elif self . type == ""VAR"" :",0.8217294420803809,70.71067811865478,1.0
"def _get_text_nodes(nodes, html_body):<tab>text = []<tab>open_tags = 0<tab>for node in nodes:<tab><tab>if isinstance(node, HtmlTag):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>open_tags += 1<tab><tab><tab>elif node.tag_type == CLOSE_TAG:<tab><tab><tab><tab>open_tags -= 1<tab><tab>elif (<tab><tab><tab>isinstance(node, HtmlDataFragment)<tab><tab><tab>and node.is_text_content<tab><tab><tab>and open_tags == 0<tab><tab>):<tab><tab><tab>text.append(html_body[node.start : node.end])<tab>return text",1,if node . tag_type == OPEN_TAG :,if node . tag_type == OPEN_TAG :,0.75,100.00000000000004,1.0
"def test_do_change(self):<tab>""""""Test if VTK object changes when trait is changed.""""""<tab>p = Prop()<tab>p.edge_visibility = not p.edge_visibility<tab>p.representation = ""p""<tab>p.opacity = 0.5<tab>p.color = (0, 1, 0)<tab>p.diffuse_color = (1, 1, 1)<tab>p.specular_color = (1, 1, 0)<tab>for t, g in p._updateable_traits_:<tab><tab>val = getattr(p._vtk_obj, g)()<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(val, getattr(p, t + ""_""))<tab><tab>else:<tab><tab><tab>self.assertEqual(val, getattr(p, t))",0,"if t == ""representation"" :","if t . endswith ( ""_"" ) :",0.04979441971690225,10.552670315936318,0.7272727272727273
"def update_item(source_doc, target_doc, source_parent):<tab>target_doc.t_warehouse = """"<tab>if source_doc.material_request_item and source_doc.material_request:<tab><tab>add_to_transit = frappe.db.get_value(<tab><tab><tab>""Stock Entry"", source_name, ""add_to_transit""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>warehouse = frappe.get_value(<tab><tab><tab><tab>""Material Request Item"", source_doc.material_request_item, ""warehouse""<tab><tab><tab>)<tab><tab><tab>target_doc.t_warehouse = warehouse<tab>target_doc.s_warehouse = source_doc.t_warehouse<tab>target_doc.qty = source_doc.qty - source_doc.transferred_qty",1,if add_to_transit :,if add_to_transit :,0.5311706625951745,1e-10,1.0
"def get_drive(self, root_path="""", volume_guid_path=""""):<tab>for drive in self.drives:<tab><tab><IF-STMT><tab><tab><tab>config_root_path = drive.get(""root_path"")<tab><tab><tab>if config_root_path and root_path == config_root_path:<tab><tab><tab><tab>return drive<tab><tab>elif volume_guid_path:<tab><tab><tab>config_volume_guid_path = drive.get(""volume_guid_path"")<tab><tab><tab>if config_volume_guid_path and config_volume_guid_path == volume_guid_path:<tab><tab><tab><tab>return drive",1,if root_path :,if root_path :,0.5311706625951745,1e-10,1.0
"def f_freeze(_):<tab>repos = utils.get_repos()<tab>for name, path in repos.items():<tab><tab>url = """"<tab><tab>cp = subprocess.run([""git"", ""remote"", ""-v""], cwd=path, capture_output=True)<tab><tab><IF-STMT><tab><tab><tab>url = cp.stdout.decode(""utf-8"").split(""\n"")[0].split()[1]<tab><tab>print(f""{url},{name},{path}"")",1,if cp . returncode == 0 :,if cp . returncode == 0 :,0.75,100.00000000000004,1.0
"def conj(self):<tab>dtype = self.dtype<tab>if issubclass(self.dtype.type, np.complexfloating):<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""only contiguous arrays may "" ""be used as arguments to this operation""<tab><tab><tab>)<tab><tab>if self.flags.f_contiguous:<tab><tab><tab>order = ""F""<tab><tab>else:<tab><tab><tab>order = ""C""<tab><tab>result = self._new_like_me(order=order)<tab><tab>func = elementwise.get_conj_kernel(dtype)<tab><tab>func.prepared_async_call(<tab><tab><tab>self._grid, self._block, None, self.gpudata, result.gpudata, self.mem_size<tab><tab>)<tab><tab>return result<tab>else:<tab><tab>return self",0,if not self . flags . forc :,if self . flags . c_contiguous :,0.19680975393331712,33.03164318013809,0.2916666666666667
"def detect_reentrancy(self, contract):<tab>for function in contract.functions_and_modifiers_declared:<tab><tab>if function.is_implemented:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self._explore(function.entry_point, [])<tab><tab><tab>function.context[self.KEY] = True",0,if self . KEY in function . context :,if self . KEY in function . entry_point :,0.62709085524794,59.00468726392806,0.8367346938775511
"def test_default_configuration_no_encoding(self):<tab>transformations = []<tab>for i in range(2):<tab><tab>transformation, original = _test_preprocessing(NoEncoding)<tab><tab>self.assertEqual(transformation.shape, original.shape)<tab><tab>self.assertTrue((transformation == original).all())<tab><tab>transformations.append(transformation)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue((transformations[-1] == transformations[-2]).all())",1,if len ( transformations ) > 1 :,if len ( transformations ) > 1 :,0.75,100.00000000000004,1.0
"def main():<tab>""""""main function""""""<tab># todo: lookuo real description<tab>parser = argparse.ArgumentParser(description=""Let a cow speak for you"")<tab>parser.add_argument(""text"", nargs=""*"", default=None, help=""text to say"")<tab>ns = parser.parse_args()<tab>if (ns.text is None) or (len(ns.text) == 0):<tab><tab>text = """"<tab><tab>while True:<tab><tab><tab>inp = sys.stdin.read(4096)<tab><tab><tab>if inp.endswith(""\n""):<tab><tab><tab><tab>inp = inp[:-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>text += inp<tab>else:<tab><tab>text = "" "".join(ns.text)<tab>cow = get_cow(text)<tab>print(cow)",0,if not inp :,"if inp == """" :",0.045150550804307965,8.643019616048525,0.45
"def prehook(self, emu, op, eip):<tab>if op in self.badops:<tab><tab>emu.stopEmu()<tab><tab>raise v_exc.BadOpBytes(op.va)<tab>if op.mnem in STOS:<tab><tab>if self.arch == ""i386"":<tab><tab><tab>reg = emu.getRegister(envi.archs.i386.REG_EDI)<tab><tab>elif self.arch == ""amd64"":<tab><tab><tab>reg = emu.getRegister(envi.archs.amd64.REG_RDI)<tab><tab><IF-STMT><tab><tab><tab>self.vw.makePointer(reg, follow=True)",0,if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,if reg :,0.0036486955893878796,1e-10,0.16428571428571428
"def get_boarding_status(project):<tab>status = ""Pending""<tab>if project:<tab><tab>doc = frappe.get_doc(""Project"", project)<tab><tab>if flt(doc.percent_complete) > 0.0 and flt(doc.percent_complete) < 100.0:<tab><tab><tab>status = ""In Process""<tab><tab><IF-STMT><tab><tab><tab>status = ""Completed""<tab><tab>return status",0,elif flt ( doc . percent_complete ) == 100.0 :,elif flt ( doc . completed ) > 0.0 and flt ( doc . completed ) < 100.0 :,0.38741374052445143,22.537412722674855,0.5246913580246914
"def set_weights(self, new_weights):<tab>weights = self.get_weights()<tab>if len(weights) != len(new_weights):<tab><tab>raise ValueError(""len of lists mismatch"")<tab>tuples = []<tab>for w, new_w in zip(weights, new_weights):<tab><tab><IF-STMT><tab><tab><tab>new_w = new_w.reshape(w.shape)<tab><tab>tuples.append((w, new_w))<tab>nn.batch_set_value(tuples)",0,if len ( w . shape ) != new_w . shape :,"if isinstance ( new_w , nn . BatchNorm ) :",0.05547462258481019,12.545696183524145,0.24166666666666667
"def reload_json_api_settings(*args, **kwargs):<tab>django_setting = kwargs[""setting""]<tab>setting = django_setting.replace(JSON_API_SETTINGS_PREFIX, """")<tab>value = kwargs[""value""]<tab>if setting in DEFAULTS.keys():<tab><tab><IF-STMT><tab><tab><tab>setattr(json_api_settings, setting, value)<tab><tab>elif hasattr(json_api_settings, setting):<tab><tab><tab>delattr(json_api_settings, setting)",1,if value is not None :,if value is not None :,0.75,100.00000000000004,1.0
"def knamn(self, sup, cdict):<tab>cname = cdict[sup].class_name<tab>if not cname:<tab><tab>(namesp, tag) = cdict[sup].name.split(""."")<tab><tab><IF-STMT><tab><tab><tab>ctag = self.root.modul[namesp].factory(tag).__class__.__name__<tab><tab><tab>cname = ""%s.%s"" % (namesp, ctag)<tab><tab>else:<tab><tab><tab>cname = tag + ""_""<tab>return cname",0,if namesp :,if namesp in self . root . modul :,0.08050925452257668,1e-10,0.37142857142857144
"def setdefault(self, key, default=None):<tab>try:<tab><tab>o = self.data[key]()<tab>except KeyError:<tab><tab>o = None<tab>if o is None:<tab><tab><IF-STMT><tab><tab><tab>self._commit_removals()<tab><tab>self.data[key] = KeyedRef(default, self._remove, key)<tab><tab>return default<tab>else:<tab><tab>return o",0,if self . _pending_removals :,if self . _commit_removals :,0.39477865547525276,50.000000000000014,1.0
"def __on_item_activated(self, event):<tab>if self.__module_view:<tab><tab>module = self.get_event_module(event)<tab><tab>self.__module_view.set_selection(module.module_num)<tab><tab><IF-STMT><tab><tab><tab>self.input_list_ctrl.deactivate_active_item()<tab><tab>else:<tab><tab><tab>self.list_ctrl.deactivate_active_item()<tab><tab><tab>for index in range(self.list_ctrl.GetItemCount()):<tab><tab><tab><tab>if self.list_ctrl.IsSelected(index):<tab><tab><tab><tab><tab>self.list_ctrl.Select(index, False)<tab>self.__controller.enable_module_controls_panel_buttons()",0,if event . EventObject is self . list_ctrl :,if self . input_list_ctrl . IsEnabled ( ) :,0.032785197616958806,16.26170171519489,0.2571428571428572
"def _create_valid_graph(graph):<tab>nodes = graph.nodes()<tab>for i in range(len(nodes)):<tab><tab>for j in range(len(nodes)):<tab><tab><tab>if i == j:<tab><tab><tab><tab>continue<tab><tab><tab>edge = (nodes[i], nodes[j])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>graph.del_edge(edge)<tab><tab><tab>graph.add_edge(edge, 1)",1,if graph . has_edge ( edge ) :,if graph . has_edge ( edge ) :,0.75,100.00000000000004,1.0
"def _parse_param_value(name, datatype, default):<tab>if datatype == ""bool"":<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif default.lower() == ""false"":<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>_s = ""{}: Invalid default value '{}' for bool parameter {}""<tab><tab><tab>raise SyntaxError(_s.format(self.name, default, p))<tab>elif datatype == ""int"":<tab><tab>if type(default) == int:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return int(default, 0)<tab>elif datatype == ""real"":<tab><tab>if type(default) == float:<tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return float(default)<tab>else:<tab><tab>return str(default)",1,"if default . lower ( ) == ""true"" :","if default . lower ( ) == ""true"" :",0.75,100.00000000000004,1.0
"def get_size(self, shape_info):<tab># The size is the data, that have constant size.<tab>state = np.random.RandomState().get_state()<tab>size = 0<tab>for elem in state:<tab><tab><IF-STMT><tab><tab><tab>size += len(elem)<tab><tab>elif isinstance(elem, np.ndarray):<tab><tab><tab>size += elem.size * elem.itemsize<tab><tab>elif isinstance(elem, int):<tab><tab><tab>size += np.dtype(""int"").itemsize<tab><tab>elif isinstance(elem, float):<tab><tab><tab>size += np.dtype(""float"").itemsize<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab>return size",0,"if isinstance ( elem , str ) :","if isinstance ( elem , shape_info ) :",0.5490406812970063,45.180100180492246,0.7777777777777778
"def _merge_substs(self, subst, new_substs):<tab>subst = subst.copy()<tab>for new_subst in new_substs:<tab><tab>for name, var in new_subst.items():<tab><tab><tab>if name not in subst:<tab><tab><tab><tab>subst[name] = var<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subst[name].PasteVariable(var)<tab>return subst",0,elif subst [ name ] is not var :,"elif isinstance ( var , PasteVariable ) :",0.07845499514510058,6.413885305524152,0.19444444444444445
"def _load_weights_if_possible(self, model, init_weight_path=None):<tab>""""""Loads model weights when it is provided.""""""<tab>if init_weight_path:<tab><tab>logging.info(""Load weights: {}"".format(init_weight_path))<tab><tab><IF-STMT><tab><tab><tab>checkpoint = tf.train.Checkpoint(<tab><tab><tab><tab>model=model, optimizer=self._create_optimizer()<tab><tab><tab>)<tab><tab><tab>checkpoint.restore(init_weight_path)<tab><tab>else:<tab><tab><tab>model.load_weights(init_weight_path)<tab>else:<tab><tab>logging.info(""Weights not loaded from path:{}"".format(init_weight_path))",0,if self . use_tpu :,if self . training :,0.39477865547525276,28.641904579795423,0.7
"def _cleanup_inactive_receivexlogs(self, site):<tab>if site in self.receivexlogs:<tab><tab>if not self.receivexlogs[site].running:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.receivexlogs[site].join()<tab><tab><tab>del self.receivexlogs[site]",0,if self . receivexlogs [ site ] . is_alive ( ) :,if self . receivinglogs [ site ] . is_active ( ) :,0.44711158089818515,53.33505353503043,0.6666666666666666
"def get_asset(self, path):<tab>""""""Loads an asset by path.""""""<tab>clean_path = cleanup_path(path).strip(""/"")<tab>nodes = [self.asset_root] + self.theme_asset_roots<tab>for node in nodes:<tab><tab>for piece in clean_path.split(""/""):<tab><tab><tab>node = node.get_child(piece)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>if node is not None:<tab><tab><tab>return node<tab>return None",0,if node is None :,if node is not None :,0.2721091316413796,37.99178428257963,0.611111111111111
"def palindromic_substrings(s):<tab>if not s:<tab><tab>return [[]]<tab>results = []<tab>for i in range(len(s), 0, -1):<tab><tab>sub = s[:i]<tab><tab><IF-STMT><tab><tab><tab>for rest in palindromic_substrings(s[i:]):<tab><tab><tab><tab>results.append([sub] + rest)<tab>return results",0,if sub == sub [ : : - 1 ] :,"if sub not in [ """" , """" ] :",0.03107100418941913,10.127993013562818,0.4444444444444444
"def debug_tree(tree):<tab>l = []<tab>for elt in tree:<tab><tab><IF-STMT><tab><tab><tab>l.append(_names.get(elt, elt))<tab><tab>elif isinstance(elt, str):<tab><tab><tab>l.append(elt)<tab><tab>else:<tab><tab><tab>l.append(debug_tree(elt))<tab>return l",0,"if isinstance ( elt , ( int , long ) ) :","if isinstance ( elt , int ) :",0.2874735611119972,37.28878639930421,0.8222222222222223
"def shared_username(account):<tab>username = os.environ.get(""SHARED_USERNAME"", ""PKKid"")<tab>for user in account.users():<tab><tab><IF-STMT><tab><tab><tab>return username<tab><tab>elif (<tab><tab><tab>user.username<tab><tab><tab>and user.email<tab><tab><tab>and user.id<tab><tab><tab>and username.lower()<tab><tab><tab>in (user.username.lower(), user.email.lower(), str(user.id))<tab><tab>):<tab><tab><tab>return username<tab>pytest.skip(""Shared user %s wasn`t found in your MyPlex account"" % username)",0,if user . title . lower ( ) == username . lower ( ) :,if user . username == username :,0.32145600003082286,13.218059591958081,0.48333333333333334
"def process_schema_element(self, e):<tab>if e.name is None:<tab><tab>return<tab>self.debug1(""adding element: %s"", e.name)<tab>t = self.get_type(e.type)<tab>if t:<tab><tab><IF-STMT><tab><tab><tab>del self.pending_elements[e.name]<tab><tab>self.retval[self.tns].elements[e.name] = e<tab>else:<tab><tab>self.pending_elements[e.name] = e",1,if e . name in self . pending_elements :,if e . name in self . pending_elements :,0.75,100.00000000000004,1.0
"def __setitem__(self, key, value):<tab>with self._lock:<tab><tab>try:<tab><tab><tab>link = self._get_link_and_move_to_front_of_ll(key)<tab><tab>except KeyError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._set_key_and_add_to_front_of_ll(key, value)<tab><tab><tab>else:<tab><tab><tab><tab>evicted = self._set_key_and_evict_last_in_ll(key, value)<tab><tab><tab><tab>super(LRI, self).__delitem__(evicted)<tab><tab><tab>super(LRI, self).__setitem__(key, value)<tab><tab>else:<tab><tab><tab>link[VALUE] = value",0,if len ( self ) < self . max_size :,if self . front_of_ll :,0.07693381032505534,8.591316733350183,0.4642857142857143
"def __delattr__(self, name):<tab>if name == ""__dict__"":<tab><tab>raise AttributeError(<tab><tab><tab>""%r object attribute '__dict__' is read-only"" % self.__class__.__name__<tab><tab>)<tab>if name in self._local_type_vars:<tab><tab><IF-STMT><tab><tab><tab># A data descriptor, like a property or a slot.<tab><tab><tab>type_attr = getattr(self._local_type, name, _marker)<tab><tab><tab>type(type_attr).__delete__(type_attr, self)<tab><tab><tab>return<tab># Otherwise it goes directly in the dict<tab># Begin inlined function _get_dict()<tab>dct = _local_get_dict(self)<tab>try:<tab><tab>del dct[name]<tab>except KeyError:<tab><tab>raise AttributeError(name)",0,if name in self . _local_type_del_descriptors :,"if hasattr ( self , ""_local_type"" ) :",0.021135835738089467,20.595660955382233,0.3148148148148148
"def update_participants(self, refresh=True):<tab>for participant in list(self.participants_dict):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.removeItem(self.participants_dict[participant])<tab><tab>self.participant_items.remove(self.participants_dict[participant])<tab><tab>del self.participants_dict[participant]<tab>for participant in self.simulator_config.participants:<tab><tab>if participant in self.participants_dict:<tab><tab><tab>self.participants_dict[participant].refresh()<tab><tab>else:<tab><tab><tab>self.insert_participant(participant)<tab>if refresh:<tab><tab>self.update_view()",0,if participant is None or participant == self . simulator_config . broadcast_part :,if participant not in self . participant_items :,0.1639473164748288,6.133611895779401,0.2804232804232804
"def insert_bigger_b_add(node):<tab>if node.op == theano.tensor.add:<tab><tab>inputs = list(node.inputs)<tab><tab><IF-STMT><tab><tab><tab>inputs[-1] = theano.tensor.concatenate((inputs[-1], inputs[-1]))<tab><tab><tab>return [node.op(*inputs)]<tab>return False",0,if inputs [ - 1 ] . owner is None :,"if isinstance ( inputs [ - 1 ] , theano . Tensor ) :",0.247203105537356,29.89950354998137,0.2
"def _activate_cancel_status(self, cancel_status):<tab>if self._cancel_status is not None:<tab><tab>self._cancel_status._tasks.remove(self)<tab>self._cancel_status = cancel_status<tab>if self._cancel_status is not None:<tab><tab>self._cancel_status._tasks.add(self)<tab><tab><IF-STMT><tab><tab><tab>self._attempt_delivery_of_any_pending_cancel()",0,if self . _cancel_status . effectively_cancelled :,if self . _cancel_status . _tasks :,0.574113272471593,65.52276436414596,1.0
"def writeLibraryGeometry(fp, meshes, config, shapes=None):<tab>progress = Progress(len(meshes), None)<tab>fp.write(""\n  <library_geometries>\n"")<tab>for mIdx, mesh in enumerate(meshes):<tab><tab><IF-STMT><tab><tab><tab>shape = None<tab><tab>else:<tab><tab><tab>shape = shapes[mIdx]<tab><tab>writeGeometry(fp, mesh, config, shape)<tab><tab>progress.step()<tab>fp.write(""  </library_geometries>\n"")",0,if shapes is None :,if mIdx is None :,0.39477865547525276,42.72870063962342,0.6666666666666666
"def init_module_config(module_json, config, config_path=default_config_path):<tab>if ""config"" in module_json[""meta""]:<tab><tab>if module_json[""meta""][""config""]:<tab><tab><tab>if module_json[""name""] not in config:<tab><tab><tab><tab>config.add_section(module_json[""name""])<tab><tab><tab>for config_var in module_json[""meta""][""config""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>config.set(module_json[""name""], config_var, """")<tab>return config",0,"if config_var not in config [ module_json [ ""name"" ] ] :",if config_var not in config :,0.25460193021067423,24.909923021496894,1.0
"def get_const_defines(flags, prefix=""""):<tab>defs = []<tab>for k, v in globals().items():<tab><tab>if isinstance(v, int):<tab><tab><tab>if v & flags:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if k.startswith(prefix):<tab><tab><tab><tab><tab><tab>defs.append(k)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>defs.append(k)<tab>return defs",1,if prefix :,if prefix :,0.5311706625951745,1e-10,1.0
"def __init__(self, source, encoding=DEFAULT_ENCODING):<tab>self.data = {}<tab>with open(source, encoding=encoding) as file_:<tab><tab>for line in file_:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>k, v = line.split(""="", 1)<tab><tab><tab>k = k.strip()<tab><tab><tab>v = v.strip()<tab><tab><tab>if len(v) >= 2 and (<tab><tab><tab><tab>(v[0] == ""'"" and v[-1] == ""'"") or (v[0] == '""' and v[-1] == '""')<tab><tab><tab>):<tab><tab><tab><tab>v = v.strip(""'\"""")<tab><tab><tab>self.data[k] = v",0,"if not line or line . startswith ( ""#"" ) or ""="" not in line :",if not line :,0.026241816645987164,1.2951112459987986,0.39974937343358397
"def __detect_console_logger(self):<tab>logger = self.log<tab>while logger:<tab><tab>for handler in logger.handlers[:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if handler.stream in (sys.stdout, sys.stderr):<tab><tab><tab><tab><tab>self.logger_handlers.append(handler)<tab><tab>if logger.root == logger:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>logger = logger.root",0,"if isinstance ( handler , StreamHandler ) :","if hasattr ( handler , ""stream"" ) :",0.09166808520089226,20.556680845025987,0.48148148148148145
"def check_heuristic_in_sql():<tab>heurs = set()<tab>excluded = [""Equal assembly or pseudo-code"", ""All or most attributes""]<tab>for heur in HEURISTICS:<tab><tab>name = heur[""name""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>sql = heur[""sql""]<tab><tab>if sql.lower().find(name.lower()) == -1:<tab><tab><tab>print((""SQL command not correctly associated to %s"" % repr(name)))<tab><tab><tab>print(sql)<tab><tab><tab>assert sql.find(name) != -1<tab><tab>heurs.add(name)<tab>print(""Heuristics:"")<tab>import pprint<tab>pprint.pprint(heurs)",1,if name in excluded :,if name in excluded :,0.75,100.00000000000004,1.0
"def read(self, size=-1):<tab>buf = bytearray()<tab>while size != 0 and self.cursor < self.maxpos:<tab><tab><IF-STMT><tab><tab><tab>self.seek_to_block(self.cursor)<tab><tab>part = self.current_stream.read(size)<tab><tab>if size > 0:<tab><tab><tab>if len(part) == 0:<tab><tab><tab><tab>raise EOFError()<tab><tab><tab>size -= len(part)<tab><tab>self.cursor += len(part)<tab><tab>buf += part<tab>return bytes(buf)",0,if not self . in_current_block ( self . cursor ) :,if not self . current_stream . eof ( ) :,0.1526990247451932,23.58969193634153,0.5982905982905983
"def get_project_dir(env):<tab>project_file = workon_home / env / "".project""<tab>if project_file.exists():<tab><tab>with project_file.open() as f:<tab><tab><tab>project_dir = f.readline().strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return project_dir<tab><tab><tab>else:<tab><tab><tab><tab>err(<tab><tab><tab><tab><tab>""Corrupted or outdated:"",<tab><tab><tab><tab><tab>project_file,<tab><tab><tab><tab><tab>""\nDirectory"",<tab><tab><tab><tab><tab>project_dir,<tab><tab><tab><tab><tab>""doesn't exist."",<tab><tab><tab><tab>)",0,if os . path . exists ( project_dir ) :,if project_dir :,0.011515134196748902,1e-10,0.36
"def _cache_mem(curr_out, prev_mem, mem_len, reuse_len=None):<tab>""""""cache hidden states into memory.""""""<tab>if mem_len is None or mem_len == 0:<tab><tab>return None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>curr_out = curr_out[:reuse_len]<tab><tab>if prev_mem is None:<tab><tab><tab>new_mem = curr_out[-mem_len:]<tab><tab>else:<tab><tab><tab>new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:]<tab>return tf.keras.backend.stop_gradient(new_mem)",0,if reuse_len is not None and reuse_len > 0 :,if reuse_len is not None :,0.38801046869250244,41.06951993704473,0.6857142857142857
"def cleanup_channel(self, to_cleanup):<tab>public_key, id_ = to_cleanup<tab># TODO: Maybe run it threaded?<tab>try:<tab><tab>with db_session:<tab><tab><tab>channel = self.session.mds.ChannelMetadata.get_for_update(<tab><tab><tab><tab>public_key=public_key, id_=id_<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>channel.local_version = 0<tab><tab><tab>channel.contents.delete(bulk=True)<tab>except Exception as e:<tab><tab>self._logger.warning(""Exception while cleaning unsubscribed channel: %"", str(e))",1,if not channel :,if not channel :,0.75,100.00000000000004,1.0
"def best_image(width, height):<tab># A heuristic for finding closest sized image to required size.<tab>image = images[0]<tab>for img in images:<tab><tab>if img.width == width and img.height == height:<tab><tab><tab># Exact match always used<tab><tab><tab>return img<tab><tab><IF-STMT><tab><tab><tab># At least wide enough, and largest area<tab><tab><tab>image = img<tab>return image",0,elif img . width >= width and img . width * img . height > image . width * image . height :,elif img . width > width and img . height > height :,0.36952168756887094,29.118304199673734,0.6095238095238095
"def add_peer_to_blob(self, contact: ""KademliaPeer"", key: bytes) -> None:<tab>now = self.loop.time()<tab>if key in self._data_store:<tab><tab>current = list(filter(lambda x: x[0] == contact, self._data_store[key]))<tab><tab><IF-STMT><tab><tab><tab>self._data_store[key][self._data_store[key].index(current[0])] = (<tab><tab><tab><tab>contact,<tab><tab><tab><tab>now,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self._data_store[key].append((contact, now))<tab>else:<tab><tab>self._data_store[key] = [(contact, now)]",0,if len ( current ) > 0 :,if current :,0.017267079824235865,1e-10,0.36
"def dump(self):<tab>self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name))<tab>for field in self._fields_:<tab><tab>if isinstance(getattr(self, field[0]), POINTER64):<tab><tab><tab>self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value))<tab><tab>elif isinstance(getattr(self, field[0]), int):<tab><tab><tab>self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0])))<tab><tab><IF-STMT><tab><tab><tab>self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))",1,"elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :",0.75,100.00000000000004,1.0
"def GeneratePageMetatadata(self, task):<tab>address_space = self.session.GetParameter(""default_address_space"")<tab>for vma in task.mm.mmap.walk_list(""vm_next""):<tab><tab>start = vma.vm_start<tab><tab>end = vma.vm_end<tab><tab># Skip the entire region.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Done.<tab><tab>if start > self.plugin_args.end:<tab><tab><tab>break<tab><tab>for vaddr in utils.xrange(start, end, 0x1000):<tab><tab><tab>if self.plugin_args.start <= vaddr <= self.plugin_args.end:<tab><tab><tab><tab>yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",0,if end < self . plugin_args . start :,if start < self . plugin_args . start :,0.62709085524794,80.70557274927978,0.7333333333333333
"def _available_symbols(self, scoperef, expr):<tab>cplns = []<tab>found_names = set()<tab>while scoperef:<tab><tab>elem = self._elem_from_scoperef(scoperef)<tab><tab>for child in elem:<tab><tab><tab>name = child.get(""name"", """")<tab><tab><tab>if name.startswith(expr):<tab><tab><tab><tab>if name not in found_names:<tab><tab><tab><tab><tab>found_names.add(name)<tab><tab><tab><tab><tab>ilk = child.get(""ilk"") or child.tag<tab><tab><tab><tab><tab>cplns.append((ilk, name))<tab><tab>scoperef = self.parent_scoperef_from_scoperef(scoperef)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return sorted(cplns, key=operator.itemgetter(1))",0,if not scoperef :,if scoperef is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def get_xenapi_host(self):<tab>""""""Return the xenapi host on which nova-compute runs on.""""""<tab>with self._get_session() as session:<tab><tab><IF-STMT><tab><tab><tab>return session.xenapi.host.get_by_uuid(self.host_uuid)<tab><tab>else:<tab><tab><tab>return session.xenapi.session.get_this_host(session.handle)",1,if self . host_uuid :,if self . host_uuid :,0.75,100.00000000000004,1.0
"def stream_docker_log(log_stream):<tab>async for line in log_stream:<tab><tab><IF-STMT><tab><tab><tab>logger.debug(line[""stream""].strip())<tab><tab>elif ""status"" in line:<tab><tab><tab>logger.debug(line[""status""].strip())<tab><tab>elif ""error"" in line:<tab><tab><tab>logger.error(line[""error""].strip())<tab><tab><tab>raise DockerBuildError",0,"if ""stream"" in line and line [ ""stream"" ] . strip ( ) :","if ""stream"" in line :",0.0803410095965662,17.469470584451173,0.5847953216374269
"def test_wildcard_import():<tab>bonobo = __import__(""bonobo"")<tab>assert bonobo.__version__<tab>for name in dir(bonobo):<tab><tab># ignore attributes starting by underscores<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>attr = getattr(bonobo, name)<tab><tab>if inspect.ismodule(attr):<tab><tab><tab>continue<tab><tab>assert name in bonobo.__all__",1,"if name . startswith ( ""_"" ) :","if name . startswith ( ""_"" ) :",0.75,100.00000000000004,1.0
"def _coerce_to_bool(self, node, var, true_val=True):<tab>""""""Coerce the values in a variable to bools.""""""<tab>bool_var = self.program.NewVariable()<tab>for b in var.bindings:<tab><tab>v = b.data<tab><tab>if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool):<tab><tab><tab>const = v.pyval is true_val<tab><tab><IF-STMT><tab><tab><tab>const = not true_val<tab><tab>elif not compare.compatible_with(v, False):<tab><tab><tab>const = true_val<tab><tab>else:<tab><tab><tab>const = None<tab><tab>bool_var.AddBinding(self.convert.bool_values[const], {b}, node)<tab>return bool_var",0,"elif not compare . compatible_with ( v , True ) :","elif compare . compatible_with ( v , True ) :",0.4478338245094791,84.96364166597652,0.32051282051282054
"def _parse_policies(self, policies_yaml):<tab>for item in policies_yaml:<tab><tab>id_ = required_key(item, ""id"")<tab><tab>controls_ids = required_key(item, ""controls"")<tab><tab>if not isinstance(controls_ids, list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = ""Policy {id_} contains invalid controls list {controls}."".format(<tab><tab><tab><tab><tab>id_=id_, controls=str(controls_ids)<tab><tab><tab><tab>)<tab><tab><tab><tab>raise ValueError(msg)<tab><tab>self.policies[id_] = controls_ids",0,"if controls_ids != ""all"" :",if id_ not in controls_ids :,0.032294703547118726,18.04438612975343,0.4375
"def pong(self, payload: Union[str, bytes] = """") -> None:<tab>if self.trace_enabled and self.ping_pong_trace_enabled:<tab><tab><IF-STMT><tab><tab><tab>payload = payload.decode(""utf-8"")<tab><tab>self.logger.debug(<tab><tab><tab>""Sending a pong data frame ""<tab><tab><tab>f""(session id: {self.session_id}, payload: {payload})""<tab><tab>)<tab>data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PONG)<tab>with self.sock_send_lock:<tab><tab>self.sock.send(data)",1,"if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",0.75,100.00000000000004,1.0
"def _extract_curve_feature_log(arg):<tab>""""""extract sampled curve feature for log items""""""<tab>try:<tab><tab>inp, res = arg<tab><tab>config = inp.config<tab><tab>with inp.target:<tab><tab><tab>sch, args = inp.task.instantiate(config)<tab><tab>fea = feature.get_buffer_curve_sample_flatten(sch, args, sample_n=20)<tab><tab>x = np.concatenate((fea, list(config.get_other_option().values())))<tab><tab><IF-STMT><tab><tab><tab>y = inp.task.flop / np.mean(res.costs)<tab><tab>else:<tab><tab><tab>y = 0.0<tab><tab>return x, y<tab>except Exception:  # pylint: disable=broad-except<tab><tab>return None",0,if res . error_no == 0 :,if res . costs :,0.09453229110448028,15.719010513286515,0.6
"def messageSourceStamps(self, source_stamps):<tab>text = """"<tab>for ss in source_stamps:<tab><tab>source = """"<tab><tab>if ss[""branch""]:<tab><tab><tab>source += ""[branch %s] "" % ss[""branch""]<tab><tab><IF-STMT><tab><tab><tab>source += str(ss[""revision""])<tab><tab>else:<tab><tab><tab>source += ""HEAD""<tab><tab>if ss[""patch""] is not None:<tab><tab><tab>source += "" (plus patch)""<tab><tab>discriminator = """"<tab><tab>if ss[""codebase""]:<tab><tab><tab>discriminator = "" '%s'"" % ss[""codebase""]<tab><tab>text += ""Build Source Stamp%s: %s\n"" % (discriminator, source)<tab>return text",1,"if ss [ ""revision"" ] :","if ss [ ""revision"" ] :",0.75,100.00000000000004,1.0
"def find_repository():<tab>orig_path = path = os.path.realpath(""."")<tab>drive, path = os.path.splitdrive(path)<tab>while path:<tab><tab>current_path = os.path.join(drive, path)<tab><tab>current_repo = LocalRepository(current_path)<tab><tab>if current_repo.isValid():<tab><tab><tab>return current_repo<tab><tab>path, path_tail = os.path.split(current_path)<tab><tab><IF-STMT><tab><tab><tab>raise CannotFindRepository(""Cannot find repository for %s"" % (orig_path,))",0,if not path_tail :,if path_tail != orig_path :,0.045150550804307965,17.747405280050266,0.6190476190476191
"def compute_indices(text: str, tokens):<tab>indices = []<tab>for i, token in enumerate(tokens):<tab><tab><IF-STMT><tab><tab><tab>current_index = indices[-1] + len(tokens[i - 1][0])<tab><tab><tab>indices.append(current_index + text[current_index:].find(token[0]))<tab><tab>else:<tab><tab><tab>indices.append(text.find(token[0]))<tab>return indices",0,if 1 <= i :,if i > 0 :,0.03654024892898815,11.51015341649912,0.4
"def _add_defaults_data_files(self):<tab># getting distribution.data_files<tab>if self.distribution.has_data_files():<tab><tab>for item in self.distribution.data_files:<tab><tab><tab>if isinstance(item, str):<tab><tab><tab><tab># plain file<tab><tab><tab><tab>item = convert_path(item)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.filelist.append(item)<tab><tab><tab>else:<tab><tab><tab><tab># a (dirname, filenames) tuple<tab><tab><tab><tab>dirname, filenames = item<tab><tab><tab><tab>for f in filenames:<tab><tab><tab><tab><tab>f = convert_path(f)<tab><tab><tab><tab><tab>if os.path.isfile(f):<tab><tab><tab><tab><tab><tab>self.filelist.append(f)",1,if os . path . isfile ( item ) :,if os . path . isfile ( item ) :,0.75,100.00000000000004,1.0
"def libcxx_define(settings):<tab>compiler = _base_compiler(settings)<tab>libcxx = settings.get_safe(""compiler.libcxx"")<tab>if not compiler or not libcxx:<tab><tab>return """"<tab>if str(compiler) in GCC_LIKE:<tab><tab><IF-STMT><tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=0""<tab><tab>elif str(libcxx) == ""libstdc++11"":<tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=1""<tab>return """"",0,"if str ( libcxx ) == ""libstdc++"" :","if str ( libcxx ) == ""libstdc+10"" :",0.605621305873661,79.10665071754353,1.0
"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict):<tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab>elif isinstance(v, bool):<tab><tab><tab>self._populate_bool(element, k, v)<tab><tab><IF-STMT><tab><tab><tab>self._populate_str(element, k, v)<tab><tab>elif type(v) in [int, float, long, complex]:<tab><tab><tab>self._populate_number(element, k, v)",0,"elif isinstance ( v , basestring ) :","elif isinstance ( v , str ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def test_seek(self):<tab><IF-STMT><tab><tab>print(""create large file via seek (may be sparse file) ..."")<tab>with self.open(TESTFN, ""wb"") as f:<tab><tab>f.write(b""z"")<tab><tab>f.seek(0)<tab><tab>f.seek(size)<tab><tab>f.write(b""a"")<tab><tab>f.flush()<tab><tab>if verbose:<tab><tab><tab>print(""check file size with os.fstat"")<tab><tab>self.assertEqual(os.fstat(f.fileno())[stat.ST_SIZE], size + 1)",1,if verbose :,if verbose :,0.5311706625951745,1e-10,1.0
"def serialize_review_url_field(self, obj, **kwargs):<tab>if obj.review_ui:<tab><tab>review_request = obj.get_review_request()<tab><tab><IF-STMT><tab><tab><tab>local_site_name = review_request.local_site.name<tab><tab>else:<tab><tab><tab>local_site_name = None<tab><tab>return local_site_reverse(<tab><tab><tab>""file-attachment"",<tab><tab><tab>local_site_name=local_site_name,<tab><tab><tab>kwargs={<tab><tab><tab><tab>""review_request_id"": review_request.display_id,<tab><tab><tab><tab>""file_attachment_id"": obj.pk,<tab><tab><tab>},<tab><tab>)<tab>return """"",0,if review_request . local_site_id :,if review_request . local_site :,0.39477865547525276,71.19674182275,1.0
"def on_item_down_clicked(self, button):<tab>model = self.treeview.get_model()<tab>for s in self._get_selected():<tab><tab><IF-STMT>  # XXX need model.swap<tab><tab><tab>old = model.get_iter(s[0])<tab><tab><tab>iter = model.insert(s[0] + 2)<tab><tab><tab>for i in range(3):<tab><tab><tab><tab>model.set_value(iter, i, model.get_value(old, i))<tab><tab><tab>model.remove(old)<tab><tab><tab>self.treeview.get_selection().select_iter(iter)<tab>self._update_filter_string()",0,if s [ 0 ] < len ( model ) - 1 :,if len ( s ) == 1 :,0.09820296942730884,9.944759750564794,0.26785714285714285
"def writer(self):<tab>""""""loop forever and copy socket->serial""""""<tab>while self.alive:<tab><tab>try:<tab><tab><tab>data = self.socket.recv(1024)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.serial.write(b"""".join(self.rfc2217.filter(data)))<tab><tab>except socket.error as msg:<tab><tab><tab>self.log.error(""{}"".format(msg))<tab><tab><tab># probably got disconnected<tab><tab><tab>break<tab>self.stop()",1,if not data :,if not data :,0.75,100.00000000000004,1.0
"def __getitem__(self, key):<tab>if key == 1:<tab><tab>return self.get_value()<tab>elif key == 0:<tab><tab>return self.cell[0]<tab>elif isinstance(key, slice):<tab><tab>s = list(self.cell.__getitem__(key))<tab><tab><IF-STMT><tab><tab><tab>s[s.index(self.cell[1])] = self.get_value()<tab><tab>return s<tab>else:<tab><tab>raise IndexError(key)",0,if self . cell [ 1 ] in s :,if len ( s ) == 2 :,0.01500732869315577,5.61480827173619,0.2
"def test_error_stream(environ, start_response):<tab>writer = start_response(""200 OK"", [])<tab>wsgi_errors = environ[""wsgi.errors""]<tab>error_msg = None<tab>for method in [<tab><tab>""flush"",<tab><tab>""write"",<tab><tab>""writelines"",<tab>]:<tab><tab><IF-STMT><tab><tab><tab>error_msg = ""wsgi.errors has no '%s' attr"" % method<tab><tab>if not error_msg and not callable(getattr(wsgi_errors, method)):<tab><tab><tab>error_msg = ""wsgi.errors.%s attr is not callable"" % method<tab><tab>if error_msg:<tab><tab><tab>break<tab>return_msg = error_msg or ""success""<tab>writer(return_msg)<tab>return []",0,"if not hasattr ( wsgi_errors , method ) :","if not error_msg and not hasattr ( wsgi_errors , method ) :",0.39307923023763225,61.28081331864041,0.42063492063492064
"def job_rule_modules(app):<tab>rules_module_list = []<tab>for rules_module_name in __job_rule_module_names(app):<tab><tab>rules_module = sys.modules.get(rules_module_name, None)<tab><tab><IF-STMT><tab><tab><tab># if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first<tab><tab><tab># JobWrapper is created<tab><tab><tab>rules_module = importlib.import_module(rules_module_name)<tab><tab>rules_module_list.append(rules_module)<tab>return rules_module_list",0,if not rules_module :,if rules_module is None :,0.045150550804307965,27.77619034011791,0.36
"def discover_hdfstore(f):<tab>d = dict()<tab>for key in f.keys():<tab><tab>d2 = d<tab><tab>key2 = key.lstrip(""/"")<tab><tab>while ""/"" in key2:<tab><tab><tab>group, key2 = key2.split(""/"", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d2[group] = dict()<tab><tab><tab>d2 = d2[group]<tab><tab>d2[key2] = f.get_storer(key)<tab>return discover(d)",1,if group not in d2 :,if group not in d2 :,0.75,100.00000000000004,1.0
"def test_update_zone(self):<tab>zone = self.driver.list_zones()[0]<tab>updated_zone = self.driver.update_zone(zone=zone, domain="""", extra={""paused"": True})<tab>self.assertEqual(zone.id, updated_zone.id)<tab>self.assertEqual(zone.domain, updated_zone.domain)<tab>self.assertEqual(zone.type, updated_zone.type)<tab>self.assertEqual(zone.ttl, updated_zone.ttl)<tab>for key in set(zone.extra) | set(updated_zone.extra):<tab><tab><IF-STMT><tab><tab><tab>self.assertNotEqual(zone.extra[key], updated_zone.extra[key])<tab><tab>else:<tab><tab><tab>self.assertEqual(zone.extra[key], updated_zone.extra[key])",0,"if key in ( ""paused"" , ""modified_on"" ) :","if key in ( ""domain"" , ""domain"" ) :",0.24891028838715556,40.801564071025986,1.0
"def ESP(phrase):<tab>for num, name in enumerate(devname):<tab><tab><IF-STMT><tab><tab><tab>dev = devid[num]<tab><tab><tab>if custom_action_keyword[""Dict""][""On""] in phrase:<tab><tab><tab><tab>ctrl = ""=ON""<tab><tab><tab><tab>say(""Turning On "" + name)<tab><tab><tab>elif custom_action_keyword[""Dict""][""Off""] in phrase:<tab><tab><tab><tab>ctrl = ""=OFF""<tab><tab><tab><tab>say(""Turning Off "" + name)<tab><tab><tab>rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)",0,if name . lower ( ) in phrase :,if num in devid :,0.0168380461076173,6.316906128202129,0.2361111111111111
"def filter_ports(self, dpid, in_port, nw_id, allow_nw_id_external=None):<tab>assert nw_id != self.nw_id_unknown<tab>ret = []<tab>for port in self.get_ports(dpid):<tab><tab>nw_id_ = port.network_id<tab><tab>if port.port_no == in_port:<tab><tab><tab>continue<tab><tab>if nw_id_ == nw_id:<tab><tab><tab>ret.append(port.port_no)<tab><tab><IF-STMT><tab><tab><tab>ret.append(port.port_no)<tab>return ret",0,elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,elif allow_nw_id_external and port . port_no in allow_nw_id_external :,0.45031634703736934,53.907400325602225,0.23863636363636365
"def tail(filename):<tab>if os.path.isfile(filename):<tab><tab>file = open(filename, ""r"")<tab><tab>st_results = os.stat(filename)<tab><tab>st_size = st_results[6]<tab><tab>file.seek(st_size)<tab><tab>while 1:<tab><tab><tab>where = file.tell()<tab><tab><tab>line = file.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>time.sleep(1)<tab><tab><tab><tab>file.seek(where)<tab><tab><tab>else:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>line,<tab><tab><tab><tab>)  # already has newline<tab>else:<tab><tab>print_error(""File not found, cannot tail."")",0,if not line :,"if line == ""\n"" :",0.045150550804307965,6.27465531099474,0.45
"def proc_day_of_week(d):<tab>if expanded[4][0] != ""*"":<tab><tab>diff_day_of_week = nearest_diff_method(d.isoweekday() % 7, expanded[4], 7)<tab><tab>if diff_day_of_week is not None and diff_day_of_week != 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d += relativedelta(days=diff_day_of_week, hour=23, minute=59, second=59)<tab><tab><tab>else:<tab><tab><tab><tab>d += relativedelta(days=diff_day_of_week, hour=0, minute=0, second=0)<tab><tab><tab>return True, d<tab>return False, d",0,if is_prev :,"if expanded [ 4 ] [ 0 ] == ""*"" :",0.04157467851822123,1e-10,0.36470588235294116
"def __call__(self):<tab>""""""Run all check_* methods.""""""<tab>if self.on:<tab><tab>oldformatwarning = warnings.formatwarning<tab><tab>warnings.formatwarning = self.formatwarning<tab><tab>try:<tab><tab><tab>for name in dir(self):<tab><tab><tab><tab>if name.startswith(""check_""):<tab><tab><tab><tab><tab>method = getattr(self, name)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>method()<tab><tab>finally:<tab><tab><tab>warnings.formatwarning = oldformatwarning",0,if method and callable ( method ) :,if callable ( method ) :,0.38848290322955353,56.98363775444274,0.35
"def get(self, request, *args, **kwargs):<tab>if self.revision:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return send_file(<tab><tab><tab><tab><tab>request,<tab><tab><tab><tab><tab>self.revision.file.path,<tab><tab><tab><tab><tab>self.revision.created,<tab><tab><tab><tab><tab>self.attachment.original_filename,<tab><tab><tab><tab>)<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>return HttpResponseRedirect(self.revision.file.url)<tab>raise Http404",0,if settings . USE_LOCAL_PATH :,if self . revision . created :,0.11306393453128258,6.495032985064742,0.2916666666666667
"def _close(self):<tab>super(Recording, self)._close()<tab>if self._log_n is not None:<tab><tab>for i in range(self.n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._log_n[i].close()<tab><tab><tab><tab>self._log_n[i] = None",1,if self . _log_n [ i ] is not None :,if self . _log_n [ i ] is not None :,0.75,100.00000000000004,1.0
"def addTags(self, rpcObjects=None):<tab>hosts = self._getOnlyHostObjects(rpcObjects)<tab>if hosts:<tab><tab>title = ""Add Tags""<tab><tab>body = ""What tags should be added?\n\nUse a comma or space between each""<tab><tab>(tags, choice) = self.getText(title, body, """")<tab><tab><IF-STMT><tab><tab><tab>tags = str(tags).replace("" "", "","").split("","")<tab><tab><tab>for host in hosts:<tab><tab><tab><tab>self.cuebotCall(<tab><tab><tab><tab><tab>host.addTags, ""Add Tags to %s Failed"" % host.data.name, tags<tab><tab><tab><tab>)<tab><tab><tab>self._update()",1,if choice :,if choice :,0.5311706625951745,1e-10,1.0
"def available_datasets(self):<tab>""""""Automatically determine datasets provided by this file""""""<tab>res = self.resolution<tab>coordinates = [""pixel_longitude"", ""pixel_latitude""]<tab>for var_name, val in self.file_content.items():<tab><tab><IF-STMT><tab><tab><tab>ds_info = {<tab><tab><tab><tab>""file_type"": self.filetype_info[""file_type""],<tab><tab><tab><tab>""resolution"": res,<tab><tab><tab>}<tab><tab><tab>if not self.is_geo:<tab><tab><tab><tab>ds_info[""coordinates""] = coordinates<tab><tab><tab>yield DatasetID(name=var_name, resolution=res), ds_info",0,"if isinstance ( val , netCDF4 . Variable ) :","if self . filetype_info [ ""file_type"" ] == ""dataset"" :",0.06483400893281185,2.6643211213888947,0.25274725274725274
"def extract_from_file(fname: PathIsh) -> Iterator[Extraction]:<tab>path = Path(fname)<tab>fallback_dt = file_mtime(path)<tab>p = Parser(path)<tab>for r in p.walk():<tab><tab><IF-STMT><tab><tab><tab>yield r<tab><tab>else:<tab><tab><tab>yield Visit(<tab><tab><tab><tab>url=r.url,<tab><tab><tab><tab>dt=fallback_dt,<tab><tab><tab><tab>locator=Loc.file(fname),  # TODO line number<tab><tab><tab><tab>context=r.context,<tab><tab><tab>)",0,"if isinstance ( r , Exception ) :",if fallback_dt < r . dt :,0.019627455172827622,6.27465531099474,0.3148148148148148
"def init_module_config(module_json, config, config_path=default_config_path):<tab>if ""config"" in module_json[""meta""]:<tab><tab>if module_json[""meta""][""config""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config.add_section(module_json[""name""])<tab><tab><tab>for config_var in module_json[""meta""][""config""]:<tab><tab><tab><tab>if config_var not in config[module_json[""name""]]:<tab><tab><tab><tab><tab>config.set(module_json[""name""], config_var, """")<tab>return config",0,"if module_json [ ""name"" ] not in config :","if not config . has_section ( module_json [ ""name"" ] ) :",0.2026080701519084,43.039475299861294,0.5882352941176471
"def _create_entities(parsed_entities, sidx, eidx):<tab>entities = []<tab>for k, vs in parsed_entities.items():<tab><tab><IF-STMT><tab><tab><tab>vs = [vs]<tab><tab>for value in vs:<tab><tab><tab>entities.append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""entity"": k,<tab><tab><tab><tab><tab>""start"": sidx,<tab><tab><tab><tab><tab>""end"": eidx,  # can't be more specific<tab><tab><tab><tab><tab>""value"": value,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>return entities",1,"if not isinstance ( vs , list ) :","if not isinstance ( vs , list ) :",0.75,100.00000000000004,1.0
"def _telegram_upload_stream(self, stream, **kwargs):<tab>""""""Perform upload defined in a stream.""""""<tab>msg = None<tab>try:<tab><tab>stream.accept()<tab><tab>msg = self._telegram_special_message(<tab><tab><tab>chat_id=stream.identifier.id,<tab><tab><tab>content=stream.raw,<tab><tab><tab>msg_type=stream.stream_type,<tab><tab><tab>**kwargs,<tab><tab>)<tab>except Exception:<tab><tab>log.exception(f""Upload of {stream.name} to {stream.identifier} failed."")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>stream.error()<tab><tab>else:<tab><tab><tab>stream.success()",1,if msg is None :,if msg is None :,0.75,100.00000000000004,1.0
"def readlines(self, size=-1):<tab>if self._nbr == self._size:<tab><tab>return []<tab># leave all additional logic to our readline method, we just check the size<tab>out = []<tab>nbr = 0<tab>while True:<tab><tab>line = self.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>out.append(line)<tab><tab>if size > -1:<tab><tab><tab>nbr += len(line)<tab><tab><tab>if nbr > size:<tab><tab><tab><tab>break<tab><tab># END handle size constraint<tab># END readline loop<tab>return out",1,if not line :,if not line :,0.75,100.00000000000004,1.0
"def clean_permissions(<tab>cls,<tab>requestor: ""User"",<tab>group: auth_models.Group,<tab>errors: Dict[Optional[str], List[ValidationError]],<tab>cleaned_input: dict,):<tab>field = ""add_permissions""<tab>permission_items = cleaned_input.get(field)<tab>if permission_items:<tab><tab>cleaned_input[field] = get_permissions(permission_items)<tab><tab><IF-STMT><tab><tab><tab>cls.ensure_can_manage_permissions(<tab><tab><tab><tab>requestor, errors, field, permission_items<tab><tab><tab>)",0,if not requestor . is_superuser :,if group . has_permission ( field ) :,0.023749771747382555,5.934202609760488,0.3333333333333333
"def _bwd(subj=None, obj=None, seen=None):<tab>seen.add(obj)<tab>for s, o in evalPath(graph, (None, self.path, obj)):<tab><tab><IF-STMT><tab><tab><tab>yield s, o<tab><tab>if self.more:<tab><tab><tab>if s in seen:<tab><tab><tab><tab>continue<tab><tab><tab>for s2, o2 in _bwd(None, s, seen):<tab><tab><tab><tab>yield s2, o",0,if not subj or subj == s :,"if isinstance ( s , subj ) :",0.020373036588449148,6.892168295481103,0.23809523809523808
"def generate_data(self, request):<tab>""""""Generate data for the widget.""""""<tab>uptime = {}<tab>cache_stats = get_cache_stats()<tab>if cache_stats:<tab><tab>for hosts, stats in cache_stats:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60 / 24<tab><tab><tab><tab>uptime[""unit""] = _(""days"")<tab><tab><tab>elif stats[""uptime""] > 3600:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60<tab><tab><tab><tab>uptime[""unit""] = _(""hours"")<tab><tab><tab>else:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60<tab><tab><tab><tab>uptime[""unit""] = _(""minutes"")<tab>return {""cache_stats"": cache_stats, ""uptime"": uptime}",0,"if stats [ ""uptime"" ] > 86400 :","if stats [ ""uptime"" ] > 3600 :",0.605621305873661,78.25422900366438,0.6
def refresh(self):<tab>if self._handle:<tab><tab>source = self._db.get_repository_from_handle(self._handle)<tab><tab><IF-STMT><tab><tab><tab>self._title = str(source.get_type())<tab><tab><tab>self._value = source.get_name(),1,if source :,if source :,0.5311706625951745,1e-10,1.0
"def _gridconvvalue(self, value):<tab>if isinstance(value, (str, _tkinter.Tcl_Obj)):<tab><tab>try:<tab><tab><tab>svalue = str(value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>elif ""."" in svalue:<tab><tab><tab><tab>return getdouble(svalue)<tab><tab><tab>else:<tab><tab><tab><tab>return getint(svalue)<tab><tab>except ValueError:<tab><tab><tab>pass<tab>return value",0,if not svalue :,"if svalue == """" :",0.045150550804307965,8.643019616048525,0.45
"def parseGrants(self, tree):<tab>for grant in tree.findall("".//Grant""):<tab><tab>grantee = Grantee()<tab><tab>g = grant.find("".//Grantee"")<tab><tab>grantee.xsi_type = g.attrib[""{http://www.w3.org/2001/XMLSchema-instance}type""]<tab><tab>grantee.permission = grant.find(""Permission"").text<tab><tab>for el in g:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>grantee.display_name = el.text<tab><tab><tab>else:<tab><tab><tab><tab>grantee.tag = el.tag<tab><tab><tab><tab>grantee.name = el.text<tab><tab>self.grantees.append(grantee)",0,"if el . tag == ""DisplayName"" :","if el . tag == ""display"" :",0.574113272471593,70.71067811865478,1.0
"def __init__(self, name: Optional[str] = None, order: int = 0):<tab>if name is None:<tab><tab>if order == 0:<tab><tab><tab>name = ""std_dev""<tab><tab><IF-STMT><tab><tab><tab>name = ""sample_std_dev""<tab><tab>else:<tab><tab><tab>name = f""std_dev{order})""<tab>super().__init__(name=name, order=order)<tab>self.order = order",1,elif order == 1 :,elif order == 1 :,1.0,100.00000000000004,1.0
"def _shouldRollover(self):<tab>if self.maxBytes > 0:  # are we rolling over?<tab><tab>try:<tab><tab><tab>self.stream.seek(0, 2)  # due to non-posix-compliant Windows feature<tab><tab>except IOError:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>self._degrade(False, ""Rotation done or not needed at this time"")<tab>return False",0,if self . stream . tell ( ) >= self . maxBytes :,if self . stream . tell ( ) >= self . maxlen :,0.9222061395603371,85.5526185871245,0.7142857142857143
"def userfullname():<tab>""""""Get the user's full name.""""""<tab>global _userfullname<tab>if not _userfullname:<tab><tab>uid = os.getuid()<tab><tab>entry = pwd_from_uid(uid)<tab><tab><IF-STMT><tab><tab><tab>_userfullname = entry[4].split("","")[0] or entry[0]<tab><tab>if not _userfullname:<tab><tab><tab>_userfullname = ""user%d"" % uid<tab>return _userfullname",1,if entry :,if entry :,0.5311706625951745,1e-10,1.0
"def drop(self):<tab># mssql<tab>sql = ""if object_id('%s') is not null drop table %s"" % (self.tname, self.tname)<tab>try:<tab><tab>self.execute(sql)<tab>except Exception as e:<tab><tab>self.conn.rollback()<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab># sqlite<tab><tab>sql = ""drop table if exists %s"" % self.tname<tab><tab>self.execute(sql)",0,"if ""syntax error"" not in str ( e ) :",if e . args [ 0 ] != 2 :,0.014834008932811844,4.503733751056993,0.2222222222222222
"def _find_delimiter(f, block_size=2 ** 16):<tab>delimiter = b""\n""<tab>if f.tell() == 0:<tab><tab>return 0<tab>while True:<tab><tab>b = f.read(block_size)<tab><tab><IF-STMT><tab><tab><tab>return f.tell()<tab><tab>elif delimiter in b:<tab><tab><tab>return f.tell() - len(b) + b.index(delimiter) + 1",1,if not b :,if not b :,0.75,100.00000000000004,1.0
"def _convert(container):<tab>if _value_marker in container:<tab><tab>force_list = False<tab><tab>values = container.pop(_value_marker)<tab><tab><IF-STMT><tab><tab><tab>force_list = True<tab><tab><tab>values.extend(_convert(x[1]) for x in sorted(container.items()))<tab><tab>if not force_list and len(values) == 1:<tab><tab><tab>values = values[0]<tab><tab>if not container:<tab><tab><tab>return values<tab><tab>return _convert(container)<tab>elif container.pop(_list_marker, False):<tab><tab>return [_convert(x[1]) for x in sorted(container.items())]<tab>return dict_cls((k, _convert(v)) for k, v in iteritems(container))",0,"if container . pop ( _list_marker , False ) :",if not container :,0.01378824683147838,2.215745752614824,0.32051282051282054
"def fitting(self, value):<tab>self._fitting = value<tab>if self._fitting is not None:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.makedirs(dirname(self.checkpoint_path()))<tab><tab><tab>except FileExistsError as ex:<tab><tab><tab><tab>pass  # race to create<tab><tab>if not os.path.exists(dirname(self.tensorboard_path())):<tab><tab><tab>try:<tab><tab><tab><tab>os.makedirs(dirname(self.tensorboard_path()))<tab><tab><tab>except FileExistsError as ex:<tab><tab><tab><tab>pass  # race to create",1,if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,0.75,100.00000000000004,1.0
"def _make_headers(self):<tab>libraries = self._df.columns.to_list()<tab>columns = []<tab>for library in libraries:<tab><tab>version = self._package_versions[library]<tab><tab>library_description = self._libraries_description.get(library)<tab><tab><IF-STMT><tab><tab><tab>library += "" {}"".format(library_description)<tab><tab>columns.append(<tab><tab><tab>""{library}<br><small>{version}</small>"".format(<tab><tab><tab><tab>library=library, version=version<tab><tab><tab>)<tab><tab>)<tab>return [""""] + columns",1,if library_description :,if library_description :,0.5311706625951745,1e-10,1.0
"def plugin_on_song_ended(self, song, stopped):<tab>if song is not None:<tab><tab>poll = self.rating_box.poll_vote()<tab><tab><IF-STMT><tab><tab><tab>ups = int(song.get(""~#wins"") or 0)<tab><tab><tab>downs = int(song.get(""~#losses"") or 0)<tab><tab><tab>ups += poll[0]<tab><tab><tab>downs += poll[1]<tab><tab><tab>song[""~#wins""] = ups<tab><tab><tab>song[""~#losses""] = downs<tab><tab><tab>song[""~#rating""] = ups / max((ups + downs), 2)<tab><tab><tab># note: ^^^ Look into implementing w/ confidence intervals!<tab><tab><tab>song[""~#score""] = ups - downs",0,if poll [ 0 ] >= 1 or poll [ 1 ] >= 1 :,if poll :,0.010227354392330742,1e-10,0.39444444444444443
"def submit(self, pig_script, params):<tab>workflow = None<tab>try:<tab><tab>workflow = self._create_workflow(pig_script, params)<tab><tab>mapping = dict(<tab><tab><tab>[(param[""name""], param[""value""]) for param in workflow.get_parameters()]<tab><tab>)<tab><tab>oozie_wf = _submit_workflow(self.user, self.fs, self.jt, workflow, mapping)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>workflow.delete(skip_trash=True)<tab>return oozie_wf",1,if workflow :,if workflow :,0.5311706625951745,1e-10,1.0
"def test_parse(self):<tab>correct = 0<tab>for example in EXAMPLES:<tab><tab>try:<tab><tab><tab>schema.parse(example.schema_string)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Invalid schema was parsed: "" + example.schema_string)<tab><tab>except:<tab><tab><tab>if not example.valid:<tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Valid schema failed to parse: "" + example.schema_string)<tab>fail_msg = ""Parse behavior correct on %d out of %d schemas."" % (<tab><tab>correct,<tab><tab>len(EXAMPLES),<tab>)<tab>self.assertEqual(correct, len(EXAMPLES), fail_msg)",1,if example . valid :,if example . valid :,0.75,100.00000000000004,1.0
"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab>if child.tag in (""wf"", ""punc""):<tab><tab><tab>itm = self.handle_word(child)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sent.extend(itm)<tab><tab><tab>else:<tab><tab><tab><tab>sent.append(itm)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return SemcorSentence(elt.attrib[""snum""], sent)",0,"if self . _unit == ""word"" :","if isinstance ( itm , SemcorSentence ) :",0.019801326568637086,4.513617516969122,0.3
"def _set_property(self, target_widget, pname, value):<tab>if pname == ""text"":<tab><tab>state = target_widget.cget(""state"")<tab><tab><IF-STMT><tab><tab><tab>target_widget.configure(state=tk.NORMAL)<tab><tab><tab>target_widget.insert(""0.0"", value)<tab><tab><tab>target_widget.configure(state=tk.DISABLED)<tab><tab>else:<tab><tab><tab>target_widget.insert(""0.0"", value)<tab>else:<tab><tab>super(TKText, self)._set_property(target_widget, pname, value)",0,if state == tk . DISABLED :,if state == tk . ACTIVE :,0.574113272471593,70.71067811865478,0.6666666666666666
"def get_vrf_tables(self, vrf_rf=None):<tab>vrf_tables = {}<tab>for (scope_id, table_id), table in self._tables.items():<tab><tab>if scope_id is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>vrf_tables[(scope_id, table_id)] = table<tab>return vrf_tables",0,if vrf_rf is not None and table_id != vrf_rf :,if vrf_rf is not None and table_id not in vrf_rf :,0.5146235232576885,76.24658586234858,0.780952380952381
"def new_f(self, *args, **kwargs):<tab>for obj in f(self, *args, **kwargs):<tab><tab>if self.protected == False:<tab><tab><tab>if ""user"" in obj and obj[""user""][""protected""]:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield obj",0,"elif ""protected"" in obj and obj [ ""protected"" ] :","if ""user"" in obj and obj [ ""user"" ] [ ""protected"" ] :",0.6344713730510977,53.392677037961555,0.6666666666666666
"def draw(self, context):<tab>col = self.layout.column()<tab>col.operator(""node.sv_show_latest_commits"")<tab>if context.scene.sv_new_version:<tab><tab>col_alert = self.layout.column()<tab><tab>col_alert.alert = True<tab><tab>col_alert.operator(""node.sverchok_update_addon"", text=""Upgrade Sverchok addon"")<tab>else:<tab><tab>col.operator(""node.sverchok_check_for_upgrades_wsha"", text=""Check for updates"")<tab>with sv_preferences() as prefs:<tab><tab><IF-STMT><tab><tab><tab>col.operator(""node.sv_run_pydoc"")",0,if prefs . developer_mode :,"if prefs . get ( ""node.sv_run_pydoc"" ) :",0.1102731445124358,10.343603005129705,0.7272727272727273
"def generate_tag_1_data(ids):<tab>if len(ids) != SAMPLE_NUM:<tab><tab>raise ValueError(""len ids should equal to sample number"")<tab>counter = 0<tab>for sample_i in range(SAMPLE_NUM):<tab><tab>one_data = [ids[sample_i]]<tab><tab>valid_set = [x for x in range(TAG_INTERVAL[0], TAG_INTERVAL[1])]<tab><tab>features = np.random.choice(valid_set, FEATURE_NUM, replace=False)<tab><tab>one_data += ["":"".join([x, ""1.0""]) for x in features]<tab><tab>counter += 1<tab><tab><IF-STMT><tab><tab><tab>print(""generate data {}"".format(counter))<tab><tab>yield one_data",1,if counter % 10000 == 0 :,if counter % 10000 == 0 :,0.75,100.00000000000004,1.0
"def handle_api_languages(self, http_context):<tab>mgr = PluginManager.get(aj.context)<tab>languages = set()<tab>for id in mgr:<tab><tab>locale_dir = mgr.get_content_path(id, ""locale"")<tab><tab><IF-STMT><tab><tab><tab>for lang in os.listdir(locale_dir):<tab><tab><tab><tab>if lang != ""app.pot"":<tab><tab><tab><tab><tab>languages.add(lang)<tab>return sorted(list(languages))",1,if os . path . isdir ( locale_dir ) :,if os . path . isdir ( locale_dir ) :,0.75,100.00000000000004,1.0
"def update(self, t):<tab># direction right - up<tab>for i in range(self.grid.x):<tab><tab>for j in range(self.grid.y):<tab><tab><tab>distance = self.test_func(i, j, t)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.turn_off_tile(i, j)<tab><tab><tab>elif distance < 1:<tab><tab><tab><tab>self.transform_tile(i, j, distance)<tab><tab><tab>else:<tab><tab><tab><tab>self.turn_on_tile(i, j)",0,if distance == 0 :,if distance > 0 :,0.33141502097923065,24.736929544091932,1.0
"def _handle_autocomplete_request_for_text(text):<tab>if not hasattr(text, ""autocompleter""):<tab><tab>if isinstance(text, (CodeViewText, ShellText)) and text.is_python_text():<tab><tab><tab>if isinstance(text, CodeViewText):<tab><tab><tab><tab>text.autocompleter = Completer(text)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text.autocompleter = ShellCompleter(text)<tab><tab><tab>text.bind(""<1>"", text.autocompleter.on_text_click)<tab><tab>else:<tab><tab><tab>return<tab>text.autocompleter.handle_autocomplete_request()",0,"elif isinstance ( text , ShellText ) :","elif isinstance ( text , ShellCompleter ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def test_create_repository(repo_name, expected_status, client):<tab>with client_with_identity(""devtable"", client) as cl:<tab><tab>body = {<tab><tab><tab>""namespace"": ""devtable"",<tab><tab><tab>""repository"": repo_name,<tab><tab><tab>""visibility"": ""public"",<tab><tab><tab>""description"": ""foo"",<tab><tab>}<tab><tab>result = conduct_api_call(<tab><tab><tab>client, RepositoryList, ""post"", None, body, expected_code=expected_status<tab><tab>).json<tab><tab><IF-STMT><tab><tab><tab>assert result[""name""] == repo_name<tab><tab><tab>assert (<tab><tab><tab><tab>model.repository.get_repository(""devtable"", repo_name).name == repo_name<tab><tab><tab>)",0,if expected_status == 201 :,"if ""name"" in result :",0.03412306583404374,6.770186228657864,0.36
"def _apply_filter(filter_item, filter_list):<tab>for filter_method in filter_list:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>except Exception as e:<tab><tab><tab>raise MessageException(<tab><tab><tab><tab>""Toolbox filter exception from '{}': {}."".format(<tab><tab><tab><tab><tab>filter_method.__name__, unicodify(e)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return True",0,"if not filter_method ( context , filter_item ) :",if filter_method . __name__ in filter_item :,0.017972997699715713,17.678748653651848,0.38461538461538464
"def printsumfp(fp, filename, out=sys.stdout):<tab>m = md5()<tab>try:<tab><tab>while 1:<tab><tab><tab>data = fp.read(bufsize)<tab><tab><tab>if not data:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = data.encode(fp.encoding)<tab><tab><tab>m.update(data)<tab>except IOError as msg:<tab><tab>sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg))<tab><tab>return 1<tab>out.write(""%s %s\n"" % (m.hexdigest(), filename))<tab>return 0",0,"if isinstance ( data , str ) :",if fp . encoding :,0.01858685153282265,6.9717291216921975,0.2698412698412698
"def get_block_loc_keys(block):<tab>""""""Extract loc_keys used by @block""""""<tab>symbols = set()<tab>for instr in block.lines:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(instr.raw, list):<tab><tab><tab><tab>for expr in instr.raw:<tab><tab><tab><tab><tab>symbols.update(get_expr_locs(expr))<tab><tab>else:<tab><tab><tab>for arg in instr.args:<tab><tab><tab><tab>symbols.update(get_expr_locs(arg))<tab>return symbols",0,"if isinstance ( instr , AsmRaw ) :","if instr . name . startswith ( ""@loc_"" ) :",0.03335693520311296,7.141816289329644,0.2857142857142857
"def get_operations(cls, info, operations: List[ProductAttributeAssignInput]):<tab>""""""Resolve all passed global ids into integer PKs of the Attribute type.""""""<tab>product_attrs_pks = []<tab>variant_attrs_pks = []<tab>for operation in operations:<tab><tab>pk = from_global_id_strict_type(<tab><tab><tab>operation.id, only_type=Attribute, field=""operations""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>product_attrs_pks.append(pk)<tab><tab>else:<tab><tab><tab>variant_attrs_pks.append(pk)<tab>return product_attrs_pks, variant_attrs_pks",0,if operation . type == ProductAttributeType . PRODUCT :,if product_attrs_pks :,0.013130313781176673,1e-10,0.27777777777777773
"def _collect_manual_intervention_nodes(pipeline_tree):<tab>for act in pipeline_tree[""activities""].values():<tab><tab>if act[""type""] == ""SubProcess"":<tab><tab><tab>_collect_manual_intervention_nodes(act[""pipeline""])<tab><tab><IF-STMT><tab><tab><tab>manual_intervention_nodes.add(act[""id""])",0,"elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :","elif act [ ""type"" ] == ""Intervention"" :",0.12476748520525588,13.75452701110242,0.7352941176470589
"def prompt_authorization(self, stacks: List[Stack]):<tab>auth_required_per_resource = auth_per_resource(stacks)<tab>for resource, authorization_required in auth_required_per_resource:<tab><tab><IF-STMT><tab><tab><tab>auth_confirm = confirm(<tab><tab><tab><tab>f""\t{self.start_bold}{resource} may not have authorization defined, Is this okay?{self.end_bold}"",<tab><tab><tab><tab>default=False,<tab><tab><tab>)<tab><tab><tab>if not auth_confirm:<tab><tab><tab><tab>raise GuidedDeployFailedError(msg=""Security Constraints Not Satisfied!"")",0,if not authorization_required :,if authorization_required :,0.09648852821835877,1e-10,0.6
"def get_cloud_credential(self):<tab>""""""Return the credential which is directly tied to the inventory source type.""""""<tab>credential = None<tab>for cred in self.credentials.all():<tab><tab>if self.source in CLOUD_PROVIDERS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab># these need to be returned in the API credential field<tab><tab><tab>if cred.credential_type.kind != ""vault"":<tab><tab><tab><tab>credential = cred<tab><tab><tab><tab>break<tab>return credential",0,"if cred . kind == self . source . replace ( ""ec2"" , ""aws"" ) :","if cred . credential_type . kind != ""account"" :",0.11089276420151062,9.33845158151465,0.5527950310559006
"def validate_party_details(self):<tab>if self.party:<tab><tab>if not frappe.db.exists(self.party_type, self.party):<tab><tab><tab>frappe.throw(_(""Invalid {0}: {1}"").format(self.party_type, self.party))<tab><tab><IF-STMT><tab><tab><tab>self.validate_account_type(<tab><tab><tab><tab>self.party_account, [erpnext.get_party_account_type(self.party_type)]<tab><tab><tab>)",0,"if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",if self . party_account :,0.11686153179861736,8.552033621493605,0.5072463768115941
"def __iter__(self):<tab>it = DiskHashMerger.__iter__(self)<tab>direct_upstreams = self.direct_upstreams<tab>for k, groups in it:<tab><tab>t = list([[] for _ in range(self.size)])<tab><tab>for i, g in enumerate(groups):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if i in direct_upstreams:<tab><tab><tab><tab><tab>t[i] = g<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>g.sort(key=itemgetter(0))<tab><tab><tab><tab><tab>g1 = []<tab><tab><tab><tab><tab>for _, vs in g:<tab><tab><tab><tab><tab><tab>g1.extend(vs)<tab><tab><tab><tab><tab>t[i] = g1<tab><tab>yield k, tuple(t)",1,if g :,if g :,0.5311706625951745,1e-10,1.0
"def _unpack_scales(scales, vidxs):<tab>scaleData = [None, None, None]<tab>for i in range(3):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>scale = scales[i]<tab><tab>if not math.isnan(scale):<tab><tab><tab>vidx1, vidx2 = vidxs[i * 2], vidxs[i * 2 + 1]<tab><tab><tab>scaleData[i] = (int(vidx1), int(vidx2), float(scale))<tab>return scaleData",0,"if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",if i >= len ( scales ) :,0.2607933800495541,18.821655523327284,0.3541666666666667
"def _make_ext_obj(self, obj):<tab>ext = self._get_ext_class(obj.objname)()<tab>for name, val in obj.body:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Error val should be a list, this is a python-opcua bug"",<tab><tab><tab><tab>name,<tab><tab><tab><tab>type(val),<tab><tab><tab><tab>val,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>for attname, v in val:<tab><tab><tab><tab>self._set_attr(ext, attname, v)<tab>return ext",1,"if not isinstance ( val , list ) :","if not isinstance ( val , list ) :",0.75,100.00000000000004,1.0
"def insertLine(self, refnum, linenum, line):<tab>i = -1<tab>for i, row in enumerate(self.rows):<tab><tab>if row[0] == linenum:<tab><tab><tab>if row[refnum + 1] is None:<tab><tab><tab><tab>row[refnum + 1] = line<tab><tab><tab><tab>return<tab><tab><tab># else keep looking<tab><tab><IF-STMT><tab><tab><tab>break<tab>self.rows.insert(i, self.newRow(linenum, refnum, line))",0,elif row [ 0 ] > linenum :,if i == len ( self . rows ) - 1 :,0.0112023440944393,3.0890553181566975,0.07792207792207792
"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab>if strip_delimiters:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield line",0,"if "","" in line or "";"" in line :",if len ( line ) == 0 :,0.016959990967165158,4.023185929567685,0.34523809523809523
"def encodingChanged(self, idx):<tab>encoding = str(self.mode_combo.currentText())<tab>validator = None<tab>if encoding == ""hex"":<tab><tab># only clear the box if there are non-hex chars<tab><tab># before setting the validator.<tab><tab>txt = str(self.data_edit.text())<tab><tab><IF-STMT><tab><tab><tab>self.data_edit.setText("""")<tab><tab>regex = QtCore.QRegExp(""^[0-9A-Fa-f]+$"")<tab><tab>validator = QtGui.QRegExpValidator(regex)<tab>self.data_edit.setValidator(validator)<tab>self.renderMemory()",0,if not all ( c in string . hexdigits for c in txt ) :,if len ( txt ) > 0 :,0.016843973573998826,5.789419402078114,0.12777777777777777
"def _compare_single_run(self, compares_done):<tab>try:<tab><tab>compare_id, redo = self.in_queue.get(<tab><tab><tab>timeout=float(self.config[""ExpertSettings""][""block_delay""])<tab><tab>)<tab>except Empty:<tab><tab>pass<tab>else:<tab><tab>if self._decide_whether_to_process(compare_id, redo, compares_done):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.db_interface.delete_old_compare_result(compare_id)<tab><tab><tab>compares_done.add(compare_id)<tab><tab><tab>self._process_compare(compare_id)<tab><tab><tab>if self.callback:<tab><tab><tab><tab>self.callback()",0,if redo :,if self . db_interface :,0.051944022748897464,1e-10,0.5
"def _transform_bin(self, X: DataFrame):<tab>if self._bin_map:<tab><tab><IF-STMT><tab><tab><tab>X = X.copy(deep=True)<tab><tab>with pd.option_context(""mode.chained_assignment"", None):<tab><tab><tab># Pandas complains about SettingWithCopyWarning, but this should be valid.<tab><tab><tab>for column in self._bin_map:<tab><tab><tab><tab>X[column] = binning.bin_column(<tab><tab><tab><tab><tab>series=X[column],<tab><tab><tab><tab><tab>mapping=self._bin_map[column],<tab><tab><tab><tab><tab>dtype=self._astype_map[column],<tab><tab><tab><tab>)<tab>return X",0,if not self . inplace :,if self . _deep :,0.054520976303194774,19.304869754804482,0.3333333333333333
"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text",0,"if ""'"" in text :","if '""' in text :",0.14477865547525276,34.57207846419409,1.0
"def read(self):<tab>""""""Reads the robots.txt URL and feeds it to the parser.""""""<tab>try:<tab><tab>f = urllib.request.urlopen(self.url)<tab>except urllib.error.HTTPError as err:<tab><tab><IF-STMT><tab><tab><tab>self.disallow_all = True<tab><tab>elif err.code >= 400 and err.code < 500:<tab><tab><tab>self.allow_all = True<tab>else:<tab><tab>raw = f.read()<tab><tab>self.parse(raw.decode(""utf-8"").splitlines())",0,"if err . code in ( 401 , 403 ) :",if err . code == 404 :,0.12785238731240015,25.124218547395092,0.4791666666666667
"def post_create(self, user, billing=None):<tab>from weblate.trans.models import Change<tab>if billing:<tab><tab>billing.projects.add(self)<tab><tab><IF-STMT><tab><tab><tab>self.access_control = Project.ACCESS_PRIVATE<tab><tab>else:<tab><tab><tab>self.access_control = Project.ACCESS_PUBLIC<tab><tab>self.save()<tab>if not user.is_superuser:<tab><tab>self.add_user(user, ""@Administration"")<tab>Change.objects.create(<tab><tab>action=Change.ACTION_CREATE_PROJECT, project=self, user=user, author=user<tab>)",0,if billing . plan . change_access_control :,if user . is_private :,0.08634665141965364,5.244835934727967,0.37777777777777777
"def visitConst(self, node):<tab>if self.documentable:<tab><tab><IF-STMT><tab><tab><tab>self.documentable.append(make_docstring(node.value, node.lineno))<tab><tab>else:<tab><tab><tab>self.documentable = None",0,"if type ( node . value ) in ( StringType , UnicodeType ) :","if isinstance ( node . value , ast . Name ) :",0.15207478147279094,22.932873195775016,0.3575757575757576
"def requires(self):<tab>requires = copy.deepcopy(self._requires)<tab># Auto add dependencies when parameters reference the Ouptuts of<tab># another stack.<tab>parameters = self.parameters<tab>for value in parameters.values():<tab><tab>if isinstance(value, basestring) and ""::"" in value:<tab><tab><tab>stack_name, _ = value.split(""::"")<tab><tab>else:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>requires.add(stack_name)<tab>return requires",1,if stack_name not in requires :,if stack_name not in requires :,0.75,100.00000000000004,1.0
"def __load_protos():<tab>g = globals()<tab>for k, v in g.items():<tab><tab><IF-STMT><tab><tab><tab>name = k[4:]<tab><tab><tab>modname = name.lower()<tab><tab><tab>try:<tab><tab><tab><tab>mod = __import__(modname, g, level=1)<tab><tab><tab><tab>PPP.set_p(v, getattr(mod, name))<tab><tab><tab>except (ImportError, AttributeError):<tab><tab><tab><tab>continue",0,"if k . startswith ( ""PPP_"" ) :","if k . startswith ( ""p"" ) :",0.5490406812970063,59.54165059120785,1.0
"def init_weights(self):<tab>""""""Initialize model weights.""""""<tab>for m in self.predict_layers.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>kaiming_init(m)<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>constant_init(m, 1)<tab><tab><IF-STMT><tab><tab><tab>normal_init(m, std=0.01)",1,"elif isinstance ( m , nn . Linear ) :","elif isinstance ( m , nn . Linear ) :",0.75,100.00000000000004,1.0
"def get_data(self):<tab>""""""get all data from sockets""""""<tab>si = self.inputs<tab>parameters = []<tab>for socket in si:<tab><tab><IF-STMT><tab><tab><tab>parameters.append(socket.sv_get())<tab><tab>else:<tab><tab><tab>parameters.append(socket.sv_get(default=[[]]))<tab>return match_long_repeat(parameters)",0,if len ( socket . prop_name ) > 0 :,"if isinstance ( socket . sv_get , str ) :",0.1051596750060956,15.580105704117443,0.42857142857142855
"def test_parse_query_params_comparable_field(self):<tab>query_params = {""filter[int_field][gt]"": 42, ""filter[int_field][lte]"": 9000}<tab>fields = self.view.parse_query_params(query_params)<tab>for key, field_name in fields.items():<tab><tab>if field_name[""int_field""][""op""] == ""gt"":<tab><tab><tab>assert_equal(field_name[""int_field""][""value""], 42)<tab><tab><IF-STMT><tab><tab><tab>assert_equal(field_name[""int_field""][""value""], 9000)<tab><tab>else:<tab><tab><tab>self.fail()",1,"elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :",1.0,100.00000000000004,1.0
"def _create_examples(self, lines, set_type):<tab>""""""Creates examples for the training and dev sets.""""""<tab>examples = []<tab>for (i, line) in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>guid = ""%s-%s"" % (set_type, i)<tab><tab>text = line[0]<tab><tab>bbox = line[1]<tab><tab>label = line[2]<tab><tab>examples.append(<tab><tab><tab>DocExample(guid=guid, text_a=text, text_b=None, bbox=bbox, label=label)<tab><tab>)<tab>return examples",1,if i == 0 :,if i == 0 :,0.75,100.00000000000004,1.0
"def _get_attr(sdk_path, mod_attr_path, checked=True):<tab>try:<tab><tab>attr_mod, attr_path = (<tab><tab><tab>mod_attr_path.split(""#"") if ""#"" in mod_attr_path else (mod_attr_path, """")<tab><tab>)<tab><tab>full_mod_path = ""{}.{}"".format(sdk_path, attr_mod) if attr_mod else sdk_path<tab><tab>op = import_module(full_mod_path)<tab><tab><IF-STMT><tab><tab><tab># Only load attributes if needed<tab><tab><tab>for part in attr_path.split("".""):<tab><tab><tab><tab>op = getattr(op, part)<tab><tab>return op<tab>except (ImportError, AttributeError) as ex:<tab><tab>if checked:<tab><tab><tab>return None<tab><tab>raise ex",0,if attr_path :,"if hasattr ( op , ""__call__"" ) :",0.04422835593777517,1e-10,0.45833333333333337
"def _load_ui_modules(self, modules: Any) -> None:<tab>if isinstance(modules, types.ModuleType):<tab><tab>self._load_ui_modules(dict((n, getattr(modules, n)) for n in dir(modules)))<tab>elif isinstance(modules, list):<tab><tab>for m in modules:<tab><tab><tab>self._load_ui_modules(m)<tab>else:<tab><tab>assert isinstance(modules, dict)<tab><tab>for name, cls in modules.items():<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.ui_modules[name] = cls<tab><tab><tab>except TypeError:<tab><tab><tab><tab>pass",1,"if issubclass ( cls , UIModule ) :","if issubclass ( cls , UIModule ) :",0.75,100.00000000000004,1.0
"def _remove_obsolete_leafs(input_dict):<tab>if not isinstance(input_dict, dict):<tab><tab>return<tab>if input_dict[LEAF_MARKER]:<tab><tab>bottom_leafs = input_dict[LEAF_MARKER]<tab><tab>for leaf in bottom_leafs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>input_dict[LEAF_MARKER].remove(leaf)<tab>for subtree in input_dict.keys():<tab><tab>_remove_obsolete_leafs(input_dict[subtree])",0,if leaf in input_dict :,if leaf in input_dict [ LEAF_MARKER ] :,0.393165501010265,43.36189090348677,1.0
"def decode(self, value, force=False):<tab>""Return a unicode string from the bytes-like representation""<tab>if self.decode_responses or force:<tab><tab><IF-STMT><tab><tab><tab>value = value.tobytes()<tab><tab>if isinstance(value, bytes):<tab><tab><tab>value = value.decode(self.encoding, self.encoding_errors)<tab>return value",0,"if isinstance ( value , memoryview ) :","if isinstance ( value , bytes ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def audit(self, directive):<tab>value = _get_value(directive)<tab>if not value:<tab><tab>return<tab>server_side = directive.name.startswith(""proxy_"")<tab>for var in compile_script(value):<tab><tab>char = """"<tab><tab><IF-STMT><tab><tab><tab>char = ""\\n""<tab><tab>elif not server_side and var.can_contain(""\r""):<tab><tab><tab>char = ""\\r""<tab><tab>else:<tab><tab><tab>continue<tab><tab>reason = 'At least variable ""${var}"" can contain ""{char}""'.format(<tab><tab><tab>var=var.name, char=char<tab><tab>)<tab><tab>self.add_issue(directive=[directive] + var.providers, reason=reason)",0,"if var . can_contain ( ""\n"" ) :","if not server_side and var . can_contain ( ""\n"" ) :",0.3648721541323159,64.70107100770988,0.375
"def checkFilename(filename):  # useful in case of drag and drop<tab>while True:<tab><tab>if filename[0] == ""'"":<tab><tab><tab>filename = filename[1:]<tab><tab><IF-STMT><tab><tab><tab>filename = filename[:-1]<tab><tab>if os.path.exists(filename):<tab><tab><tab>return filename<tab><tab>filename = input(<tab><tab><tab>""[!] Cannot find '%s'.\n[*] Enter a valid name of the file containing the paths to test -> ""<tab><tab><tab>% filename<tab><tab>)",0,"if filename [ len ( filename ) - 1 ] == ""'"" :","if filename [ - 1 ] == '""' :",0.1463608542749632,35.35283345573217,0.5111111111111111
"def findfiles(self, dir, base, rec):<tab>try:<tab><tab>names = os.listdir(dir or os.curdir)<tab>except os.error as msg:<tab><tab>print(msg)<tab><tab>return []<tab>list = []<tab>subdirs = []<tab>for name in names:<tab><tab>fn = os.path.join(dir, name)<tab><tab><IF-STMT><tab><tab><tab>subdirs.append(fn)<tab><tab>else:<tab><tab><tab>if fnmatch.fnmatch(name, base):<tab><tab><tab><tab>list.append(fn)<tab>if rec:<tab><tab>for subdir in subdirs:<tab><tab><tab>list.extend(self.findfiles(subdir, base, rec))<tab>return list",1,if os . path . isdir ( fn ) :,if os . path . isdir ( fn ) :,0.75,100.00000000000004,1.0
"def loop(handler, obj):<tab>handler.response.write(""<table>"")<tab>for k, v in obj.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>style = ""color: red"" if not v else """"<tab><tab><tab>handler.response.write(<tab><tab><tab><tab>'<tr style=""{}""><td>{}:</td><td>{}</td></tr>'.format(style, k, v)<tab><tab><tab>)<tab>handler.response.write(""</table>"")",0,"if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :","if not k . startswith ( ""_"" ) :",0.039464192772939194,5.853821183545375,0.6666666666666666
"def anypython(request):<tab>name = request.param<tab>executable = getexecutable(name)<tab>if executable is None:<tab><tab>if sys.platform == ""win32"":<tab><tab><tab>executable = winpymap.get(name, None)<tab><tab><tab>if executable:<tab><tab><tab><tab>executable = py.path.local(executable)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return executable<tab><tab>pytest.skip(""no suitable %s found"" % (name,))<tab>return executable",0,if executable . check ( ) :,if os . path . exists ( executable ) :,0.03800852328424072,11.044795567078939,0.2619047619047619
"def __init__(self, socketpath=None):<tab>if socketpath is None:<tab><tab><IF-STMT><tab><tab><tab>socketpath = ""/var/run/usbmuxd""<tab><tab>else:<tab><tab><tab>socketpath = ""/var/run/usbmuxd""<tab>self.socketpath = socketpath<tab>self.listener = MuxConnection(socketpath, BinaryProtocol)<tab>try:<tab><tab>self.listener.listen()<tab><tab>self.version = 0<tab><tab>self.protoclass = BinaryProtocol<tab>except MuxVersionError:<tab><tab>self.listener = MuxConnection(socketpath, PlistProtocol)<tab><tab>self.listener.listen()<tab><tab>self.protoclass = PlistProtocol<tab><tab>self.version = 1<tab>self.devices = self.listener.devices",0,"if sys . platform == ""darwin"" :","if sys . platform == ""win32"" :",0.574113272471593,70.71067811865478,1.0
"def _validate_distinct_on_different_types_and_field_orders(<tab>self, collection, query, expected_results, get_mock_result):<tab>self.count = 0<tab>self.get_mock_result = get_mock_result<tab>query_iterable = collection.query_items(query, enable_cross_partition_query=True)<tab>results = list(query_iterable)<tab>for i in range(len(expected_results)):<tab><tab><IF-STMT><tab><tab><tab>self.assertDictEqual(results[i], expected_results[i])<tab><tab>elif isinstance(results[i], list):<tab><tab><tab>self.assertListEqual(results[i], expected_results[i])<tab><tab>else:<tab><tab><tab>self.assertEqual(results[i], expected_results[i])<tab>self.count = 0",1,"if isinstance ( results [ i ] , dict ) :","if isinstance ( results [ i ] , dict ) :",0.75,100.00000000000004,1.0
"def getRootId(self, id):<tab>with self.connect() as cu:<tab><tab>while True:<tab><tab><tab>stmt = ""select parent_path_id from hierarchy where path_id = ?""<tab><tab><tab>cu.execute(stmt, (id,))<tab><tab><tab>parent_id = cu.fetchone()[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return id<tab><tab><tab>id = parent_id",0,if parent_id is None or parent_id == id :,if parent_id == id :,0.23743227507431605,47.23665527410149,0.2878787878787879
"def add(self, path):<tab>with self.get_lock(path):<tab><tab><IF-STMT><tab><tab><tab>self.entries[path] = {}<tab><tab><tab>self.entries[path][""lock""] = self.new_locks[path]<tab><tab><tab>del self.new_locks[path]<tab><tab><tab>self.lru.append(path)",0,if not path in self . entries :,if path not in self . entries :,0.5407153684841097,58.14307369682194,0.7142857142857143
"def _get_coordinates_for_dataset_key(self, dsid):<tab>""""""Get the coordinate dataset keys for *dsid*.""""""<tab>ds_info = self.ids[dsid]<tab>cids = []<tab>for cinfo in ds_info.get(""coordinates"", []):<tab><tab>if not isinstance(cinfo, dict):<tab><tab><tab>cinfo = {""name"": cinfo}<tab><tab>cinfo[""resolution""] = ds_info[""resolution""]<tab><tab><IF-STMT><tab><tab><tab>cinfo[""polarization""] = ds_info[""polarization""]<tab><tab>cid = DatasetID(**cinfo)<tab><tab>cids.append(self.get_dataset_key(cid))<tab>return cids",1,"if ""polarization"" in ds_info :","if ""polarization"" in ds_info :",0.75,100.00000000000004,1.0
"def build_from_gdobj(cls, gdobj, steal=False):<tab># Avoid calling cls.__init__ by first instanciating a placeholder, then<tab># overloading it __class__ to turn it into an instance of the right class<tab>ret = BuiltinInitPlaceholder()<tab>if steal:<tab><tab>assert ffi.typeof(gdobj).kind == ""pointer""<tab><tab>ret._gd_ptr = gdobj<tab>else:<tab><tab><IF-STMT><tab><tab><tab>ret._gd_ptr = cls._copy_gdobj(gdobj)<tab><tab>else:<tab><tab><tab>ret._gd_ptr = cls._copy_gdobj(ffi.addressof(gdobj))<tab>ret.__class__ = cls<tab>return ret",0,"if ffi . typeof ( gdobj ) . kind == ""pointer"" :","if gdobj . kind == ""pointer"" :",0.1716700876684662,48.730396897437764,0.3125
"def _listen_output(self):<tab>""NB! works in background thread""<tab>try:<tab><tab>while True:<tab><tab><tab>chars = self._proc.read(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>as_bytes = chars.encode(self.encoding)<tab><tab><tab><tab>self._make_output_available(as_bytes)<tab><tab><tab>else:<tab><tab><tab><tab>self._error = ""EOF""<tab><tab><tab><tab>break<tab>except Exception as e:<tab><tab>self._error = str(e)",0,if len ( chars ) > 0 :,if chars :,0.017267079824235865,1e-10,0.36
"def result(<tab>metrics: Dict[metric_types.MetricKey, Any]) -> Dict[metric_types.AttributionsKey, Dict[Text, Union[float, np.ndarray]]]:<tab>""""""Returns mean attributions.""""""<tab>total_attributions = metrics[total_attributions_key]<tab>weighted_count = metrics[weighted_example_count_key]<tab>attributions = {}<tab>for k, v in total_attributions.items():<tab><tab><IF-STMT><tab><tab><tab>attributions[k] = float(""nan"")<tab><tab>else:<tab><tab><tab>attributions[k] = v / weighted_count<tab>return {key: attributions}",0,"if np . isclose ( weighted_count , 0.0 ) :",if v is None :,0.013468035777437931,3.1325998243558226,0.27472527472527475
"def write_if_changed(path, data):<tab>if isinstance(data, str):<tab><tab>data = data.encode()<tab>changed = False<tab>with open(os.open(path, os.O_CREAT | os.O_RDWR), ""wb+"") as f:<tab><tab>f.seek(0)<tab><tab>current = f.read()<tab><tab><IF-STMT><tab><tab><tab>changed = True<tab><tab><tab>f.seek(0)<tab><tab><tab>f.write(data)<tab><tab><tab>f.truncate()<tab><tab>os.fsync(f)<tab>return changed",1,if current != data :,if current != data :,0.75,100.00000000000004,1.0
"def detect_ssl_option(self):<tab>for option in self.ssl_options():<tab><tab>if scan_argv(self.argv, option) is not None:<tab><tab><tab>for other_option in self.ssl_options():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if scan_argv(self.argv, other_option) is not None:<tab><tab><tab><tab><tab><tab>raise ConfigurationError(<tab><tab><tab><tab><tab><tab><tab>""Cannot give both %s and %s"" % (option, other_option)<tab><tab><tab><tab><tab><tab>)<tab><tab><tab>return option",1,if option != other_option :,if option != other_option :,0.75,100.00000000000004,1.0
"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(arg, bytes):<tab><tab><tab>if return_type is str:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab>if return_type is bytes:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type",1,if arg is None :,if arg is None :,0.75,100.00000000000004,1.0
"def _get_app(self, body=None):<tab>app = self._app<tab>if app is None:<tab><tab>try:<tab><tab><tab>tasks = self.tasks.tasks  # is a group<tab><tab>except AttributeError:<tab><tab><tab>tasks = self.tasks<tab><tab><IF-STMT><tab><tab><tab>app = tasks[0]._app<tab><tab>if app is None and body is not None:<tab><tab><tab>app = body._app<tab>return app if app is not None else current_app",0,if len ( tasks ) :,if len ( tasks ) == 1 :,0.45908824945524757,46.713797772819994,0.7777777777777778
"def add_field(self, field):<tab>self.remove_field(field.name)<tab>self.fields[field.name] = field<tab>self.columns[field.db_column] = field<tab>self._sorted_field_list.insert(field)<tab>self._update_field_lists()<tab>if field.default is not None:<tab><tab>self.defaults[field] = field.default<tab><tab><IF-STMT><tab><tab><tab>self._default_callables[field] = field.default<tab><tab><tab>self._default_callable_list.append((field.name, field.default))<tab><tab>else:<tab><tab><tab>self._default_dict[field] = field.default<tab><tab><tab>self._default_by_name[field.name] = field.default",0,if callable ( field . default ) :,if field . name in self . _default_callables :,0.03254016854246967,8.516593018819643,0.2361111111111111
"def _get_families(self):<tab>families = []<tab>for name, ext in self._get_family_dirs():<tab><tab><IF-STMT>  # is a directory<tab><tab><tab>family = self.get_resource(<tab><tab><tab><tab>FileSystemPackageFamilyResource.key, location=self.location, name=name<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>family = self.get_resource(<tab><tab><tab><tab>FileSystemCombinedPackageFamilyResource.key,<tab><tab><tab><tab>location=self.location,<tab><tab><tab><tab>name=name,<tab><tab><tab><tab>ext=ext,<tab><tab><tab>)<tab><tab>families.append(family)<tab>return families",0,if ext is None :,"if name . endswith ( ""/"" ) :",0.026407399022921448,4.990049701936832,0.2698412698412698
"def test(model, data_loader, device=None):<tab>device = device or torch.device(""cpu"")<tab>model.eval()<tab>correct = 0<tab>total = 0<tab>with torch.no_grad():<tab><tab>for batch_idx, (data, target) in enumerate(data_loader):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>data, target = data.to(device), target.to(device)<tab><tab><tab>outputs = model(data)<tab><tab><tab>_, predicted = torch.max(outputs.data, 1)<tab><tab><tab>total += target.size(0)<tab><tab><tab>correct += (predicted == target).sum().item()<tab>return correct / total",0,if batch_idx * len ( data ) > TEST_SIZE :,if batch_idx >= len ( data ) :,0.2917379735069444,37.773311868264216,1.0
"def __animate_progress(self):<tab>""""""Change the status message, mostly used to animate progress.""""""<tab>while True:<tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab>with self.__progress_lock:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab><tab>elif self.__show_animation:<tab><tab><tab><tab>self.__progress_status.update_progress(self.__current_operation_name)<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_UPDATE_DELAY<tab><tab><tab>else:<tab><tab><tab><tab>self.__progress_status.show_as_ready()<tab><tab><tab><tab>sleep_time = ThreadPool.PROGRESS_IDLE_DELAY<tab><tab># Allow some time for progress status to be updated.<tab><tab>time.sleep(sleep_time)",0,if not self . __progress_status :,if self . __show_status is None :,0.047631794481620526,29.982213893423374,0.30952380952380953
"def _parse_subtitles(self, video_data, url_key):<tab>subtitles = {}<tab>for translation in video_data.get(""translations"", []):<tab><tab>vtt_path = translation.get(url_key)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>lang = translation.get(""language_w3c"") or ISO639Utils.long2short(<tab><tab><tab>translation[""language_medium""]<tab><tab>)<tab><tab>subtitles.setdefault(lang, []).append(<tab><tab><tab>{<tab><tab><tab><tab>""ext"": ""vtt"",<tab><tab><tab><tab>""url"": vtt_path,<tab><tab><tab>}<tab><tab>)<tab>return subtitles",1,if not vtt_path :,if not vtt_path :,0.75,100.00000000000004,1.0
"def postprocess_message(self, msg):<tab>if msg[""type""] == ""sample"" and msg[""value""] is not None:<tab><tab>fn, value = msg[""fn""], msg[""value""]<tab><tab>value_batch_ndims = jnp.ndim(value) - fn.event_dim<tab><tab>fn_batch_ndim = len(fn.batch_shape)<tab><tab><IF-STMT><tab><tab><tab>prepend_shapes = (1,) * (value_batch_ndims - fn_batch_ndim)<tab><tab><tab>msg[""fn""] = tree_map(<tab><tab><tab><tab>lambda x: jnp.reshape(x, prepend_shapes + jnp.shape(x)), fn<tab><tab><tab>)",0,if fn_batch_ndim < value_batch_ndims :,if fn_batch_ndims < value_batch_ndims :,0.39477865547525276,76.11606003349888,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_filename(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def createError(self, line, pos, description):<tab>global ENABLE_PYIMPORT<tab>msg = ""Line "" + unicode(line) + "": "" + unicode(description)<tab>if ENABLE_JS2PY_ERRORS:<tab><tab><IF-STMT><tab><tab><tab>import js2py.base<tab><tab><tab>return js2py.base.MakeError(""SyntaxError"", msg)<tab><tab>else:<tab><tab><tab>return ENABLE_JS2PY_ERRORS(msg)<tab>else:<tab><tab>return JsSyntaxError(msg)",0,"if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :","if isinstance ( msg , JsSyntaxError ) :",0.34166808520089226,16.409149280404737,0.48148148148148145
"def extract(self, page, start_index=0, end_index=None):<tab>items = []<tab>for extractor in self.extractors:<tab><tab>extracted = extractor.extract(<tab><tab><tab>page, start_index, end_index, self.template.ignored_regions<tab><tab>)<tab><tab>for item in arg_to_iter(extracted):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if isinstance(item, (ItemProcessor, dict)):<tab><tab><tab><tab><tab>item[u""_template""] = self.template.id<tab><tab><tab><tab>items.append(item)<tab>return items",0,if item :,if item is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def create_volume(self, volume):<tab>""""""Create a volume.""""""<tab>try:<tab><tab>cmd = [""volume"", ""create"", volume[""name""], ""%sG"" % (volume[""size""])]<tab><tab><IF-STMT><tab><tab><tab>cmd.append(""pool"")<tab><tab><tab>cmd.append(self.configuration.eqlx_pool)<tab><tab>if self.configuration.san_thin_provision:<tab><tab><tab>cmd.append(""thin-provision"")<tab><tab>out = self._eql_execute(*cmd)<tab><tab>self.add_multihost_access(volume)<tab><tab>return self._get_volume_data(out)<tab>except Exception:<tab><tab>with excutils.save_and_reraise_exception():<tab><tab><tab>LOG.error('Failed to create volume ""%s"".', volume[""name""])",0,"if self . configuration . eqlx_pool != ""default"" :",if self . configuration . eqlx_pool :,0.3138460562882106,51.01469472683877,1.0
"def clean(self):<tab># TODO: check for clashes if the random code is already taken<tab>if not self.code:<tab><tab>self.code = u""static-%s"" % uuid.uuid4()<tab>if not self.site:<tab><tab>placeholders = StaticPlaceholder.objects.filter(<tab><tab><tab>code=self.code, site__isnull=True<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>placeholders = placeholders.exclude(pk=self.pk)<tab><tab>if placeholders.exists():<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""A static placeholder with the same site and code already exists"")<tab><tab><tab>)",1,if self . pk :,if self . pk :,0.75,100.00000000000004,1.0
"def spawnMenu(self, event):<tab>clickedPos = self.getRowByAbs(event.Position)<tab>self.ensureSelection(clickedPos)<tab>selection = self.getSelectedBoosters()<tab>mainBooster = None<tab>if clickedPos != -1:<tab><tab>try:<tab><tab><tab>booster = self.boosters[clickedPos]<tab><tab>except IndexError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mainBooster = booster<tab>itemContext = None if mainBooster is None else _t(""Booster"")<tab>menu = ContextMenu.getMenu(<tab><tab>self,<tab><tab>mainBooster,<tab><tab>selection,<tab><tab>(""boosterItem"", itemContext),<tab><tab>(""boosterItemMisc"", itemContext),<tab>)<tab>if menu:<tab><tab>self.PopupMenu(menu)",0,if booster in self . original :,if mainBooster is None :,0.10558415838324879,8.51528917838043,0.2
"def init_errorhandler():<tab># http error handling<tab>for ex in default_exceptions:<tab><tab><IF-STMT><tab><tab><tab>app.register_error_handler(ex, error_http)<tab><tab>elif ex == 500:<tab><tab><tab>app.register_error_handler(ex, internal_error)<tab>if services.ldap:<tab><tab># Only way of catching the LDAPException upon logging in with LDAP server down<tab><tab>@app.errorhandler(services.ldap.LDAPException)<tab><tab>def handle_exception(e):<tab><tab><tab>log.debug(""LDAP server not accessible while trying to login to opds feed"")<tab><tab><tab>return error_http(FailedDependency())",0,if ex < 500 :,if ex == 500 :,0.33141502097923065,22.957488466614336,1.0
"def reloadCols(self):<tab>self.columns = []<tab>for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr):<tab><tab><IF-STMT><tab><tab><tab>t = anytype<tab><tab>elif ""M"" in fmt:<tab><tab><tab>self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i])))<tab><tab><tab>continue<tab><tab>elif ""i"" in fmt:<tab><tab><tab>t = int<tab><tab>elif ""f"" in fmt:<tab><tab><tab>t = float<tab><tab>else:<tab><tab><tab>t = anytype<tab><tab>self.addColumn(ColumnItem(name, i, type=t))",0,if shape :,"if ""o"" in fmt :",0.051944022748897464,1e-10,0.36
"def Proc2(IntParIO):<tab>IntLoc = IntParIO + 10<tab>while True:<tab><tab>if Char1Glob == ""A"":<tab><tab><tab>IntLoc = IntLoc - 1<tab><tab><tab>IntParIO = IntLoc - IntGlob<tab><tab><tab>EnumLoc = Ident1<tab><tab><IF-STMT><tab><tab><tab>break<tab>return IntParIO",1,if EnumLoc == Ident1 :,if EnumLoc == Ident1 :,0.75,100.00000000000004,1.0
"def opengroup(self, name=None):<tab>gid = self.groups<tab>self.groupwidths.append(None)<tab>if self.groups > MAXGROUPS:<tab><tab>raise error(""too many groups"")<tab>if name is not None:<tab><tab>ogid = self.groupdict.get(name, None)<tab><tab><IF-STMT><tab><tab><tab>raise error(<tab><tab><tab><tab>""redefinition of group name %r as group %d; ""<tab><tab><tab><tab>""was group %d"" % (name, gid, ogid)<tab><tab><tab>)<tab><tab>self.groupdict[name] = gid<tab>return gid",1,if ogid is not None :,if ogid is not None :,0.75,100.00000000000004,1.0
"def __setattr__(self, name: str, val: Any):<tab>if name.startswith(""COMPUTED_""):<tab><tab>if name in self:<tab><tab><tab>old_val = self[name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>raise KeyError(<tab><tab><tab><tab>""Computed attributed '{}' already exists ""<tab><tab><tab><tab>""with a different value! old={}, new={}."".format(name, old_val, val)<tab><tab><tab>)<tab><tab>self[name] = val<tab>else:<tab><tab>super().__setattr__(name, val)",1,if old_val == val :,if old_val == val :,0.75,100.00000000000004,1.0
"def get_all_function_symbols(self, module=""kernel""):<tab>""""""Gets all the function tuples for the given module""""""<tab>ret = []<tab>symtable = self.type_map<tab>if module in symtable:<tab><tab>mod = symtable[module]<tab><tab>for (addr, (name, _sym_types)) in mod.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addr = addr + self.shift_address<tab><tab><tab>ret.append([name, addr])<tab>else:<tab><tab>debug.info(""All symbols requested for non-existent module %s"" % module)<tab>return ret",0,if self . shift_address and addr :,if self . shift_address is not None :,0.3538221078139657,53.7284965911771,0.35714285714285715
"def __call__(self, frame: FrameType, event: str, arg: Any) -> ""CallTracer"":<tab>code = frame.f_code<tab>if (<tab><tab>event not in SUPPORTED_EVENTS<tab><tab>or code.co_name == ""trace_types""<tab><tab>or self.should_trace<tab><tab>and not self.should_trace(code)<tab>):<tab><tab>return self<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.handle_call(frame)<tab><tab>elif event == EVENT_RETURN:<tab><tab><tab>self.handle_return(frame, arg)<tab><tab>else:<tab><tab><tab>logger.error(""Cannot handle event %s"", event)<tab>except Exception:<tab><tab>logger.exception(""Failed collecting trace"")<tab>return self",1,if event == EVENT_CALL :,if event == EVENT_CALL :,0.75,100.00000000000004,1.0
"def test_update_topic(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>topic = ""update topic""<tab><tab>async with self.chat_thread_client:<tab><tab><tab>await self.chat_thread_client.update_topic(topic=topic)<tab><tab># delete chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)",0,if not self . is_playback ( ) :,if self . is_playback ( ) :,0.36108324016767335,79.56371661921447,0.4772727272727273
"def render_observation(self):<tab>x = self.read_head_position<tab>label = ""Observation Grid<tab>: ""<tab>x_str = """"<tab>for j in range(-1, self.rows + 1):<tab><tab>if j != -1:<tab><tab><tab>x_str += "" "" * len(label)<tab><tab>for i in range(-2, self.input_width + 2):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x_str += colorize(self._get_str_obs((i, j)), ""green"", highlight=True)<tab><tab><tab>else:<tab><tab><tab><tab>x_str += self._get_str_obs((i, j))<tab><tab>x_str += ""\n""<tab>x_str = label + x_str<tab>return x_str",0,if i == x [ 0 ] and j == x [ 1 ] :,if i < x :,0.013887228846722825,2.304838145595558,0.42543859649122806
"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""QA-ZRE"")<tab>version = None<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># Mark the data as built.<tab><tab>build_data.mark_done(dpath, version_string=version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100.00000000000004,1.0
"def git_pull(args):<tab>if len(args) <= 1:<tab><tab>repo = _get_repo()<tab><tab>_confirm_dangerous()<tab><tab>url = args[0] if len(args) == 1 else repo.remotes.get(""origin"", """")<tab><tab><IF-STMT><tab><tab><tab>origin = url<tab><tab><tab>url = repo.remotes.get(origin)<tab><tab>if url:<tab><tab><tab>repo.pull(origin_uri=url)<tab><tab>else:<tab><tab><tab>print(""No pull URL."")<tab>else:<tab><tab>print(command_help[""git pull""])",0,if url in repo . remotes :,"if isinstance ( url , str ) :",0.021135835738089467,7.267884212102741,0.23214285714285715
"def FindAndDelete(script, sig):<tab>""""""Consensus critical, see FindAndDelete() in Satoshi codebase""""""<tab>r = b""""<tab>last_sop_idx = sop_idx = 0<tab>skip = True<tab>for (opcode, data, sop_idx) in script.raw_iter():<tab><tab><IF-STMT><tab><tab><tab>r += script[last_sop_idx:sop_idx]<tab><tab>last_sop_idx = sop_idx<tab><tab>if script[sop_idx : sop_idx + len(sig)] == sig:<tab><tab><tab>skip = True<tab><tab>else:<tab><tab><tab>skip = False<tab>if not skip:<tab><tab>r += script[last_sop_idx:]<tab>return CScript(r)",1,if not skip :,if not skip :,0.75,100.00000000000004,1.0
"def get_ip_info(ipaddress):<tab>""""""Returns device information by IP address""""""<tab>result = {}<tab>try:<tab><tab>ip = IPAddress.objects.select_related().get(address=ipaddress)<tab>except IPAddress.DoesNotExist:<tab><tab>pass<tab>else:<tab><tab>if ip.venture is not None:<tab><tab><tab>result[""venture_id""] = ip.venture.id<tab><tab>if ip.device is not None:<tab><tab><tab>result[""device_id""] = ip.device.id<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[""venture_id""] = ip.device.venture.id<tab>return result",0,if ip . device . venture is not None :,if ip . device is not None :,0.4111115727149571,53.849523560640876,0.48214285714285715
"def restore(self, state):<tab>""""""Restore the state of a mesh previously saved using save()""""""<tab>import pickle<tab>state = pickle.loads(state)<tab>for k in state:<tab><tab>if isinstance(state[k], list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state[k] = [[v.x(), v.y(), v.z()] for v in state[k]]<tab><tab><tab>state[k] = np.array(state[k])<tab><tab>setattr(self, k, state[k])",0,"if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) :",if len ( state [ k ] ) == 1 :,0.1657027826875943,25.547968364779425,0.39
"def get_extra_lines(tup):<tab>ext_name, pyopencl_ver = tup<tab>if ext_name is not None:<tab><tab><IF-STMT><tab><tab><tab># capital letters -> CL version, not extension<tab><tab><tab>yield """"<tab><tab><tab>yield ""<tab>Available with OpenCL %s."" % (ext_name[3:])<tab><tab><tab>yield """"<tab><tab>else:<tab><tab><tab>yield """"<tab><tab><tab>yield ""<tab>Available with the ``%s`` extension."" % ext_name<tab><tab><tab>yield """"<tab>if pyopencl_ver is not None:<tab><tab>yield """"<tab><tab>yield ""<tab>.. versionadded:: %s"" % pyopencl_ver<tab><tab>yield """"",0,"if ext_name . startswith ( ""CL_"" ) :","if ext_name . startswith ( ""CL"" ) :",0.5490406812970063,76.7733168433653,1.0
"def _gen_remote_uri(<tab>fileobj: IO[bytes],<tab>remote_uri: Optional[ParseResult],<tab>remote_path_prefix: Optional[str],<tab>remote_path_suffix: Optional[str],<tab>sha256sum: Optional[str],) -> ParseResult:<tab>if remote_uri is None:<tab><tab>assert remote_path_prefix is not None and remote_path_suffix is not None<tab><tab><IF-STMT><tab><tab><tab>sha256sum = _hash_fileobj(fileobj)<tab><tab>return urlparse(<tab><tab><tab>os.path.join(remote_path_prefix, f""{sha256sum}{remote_path_suffix}"")<tab><tab>)<tab>else:<tab><tab>return remote_uri",1,if sha256sum is None :,if sha256sum is None :,0.75,100.00000000000004,1.0
"def queries(self):<tab>if DEV:<tab><tab>cmd = ShellCommand(""docker"", ""ps"", ""-qf"", ""name=%s"" % self.path.k8s)<tab><tab>if not cmd.check(f""docker check for {self.path.k8s}""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log_cmd = ShellCommand(<tab><tab><tab><tab><tab>""docker"", ""logs"", self.path.k8s, stderr=subprocess.STDOUT<tab><tab><tab><tab>)<tab><tab><tab><tab>if log_cmd.check(f""docker logs for {self.path.k8s}""):<tab><tab><tab><tab><tab>print(cmd.stdout)<tab><tab><tab><tab>pytest.exit(f""container failed to start for {self.path.k8s}"")<tab>return ()",0,if not cmd . stdout . strip ( ) :,if cmd . stdout :,0.059382556937524214,16.62083000646927,0.3055555555555556
"def get_range(self):<tab>present = self.xml.find(""{%s}range"" % self.namespace)<tab>if present is not None:<tab><tab>attributes = present.attrib<tab><tab>return_value = dict()<tab><tab><IF-STMT><tab><tab><tab>return_value[""minimum""] = attributes[""min""]<tab><tab>if ""max"" in attributes:<tab><tab><tab>return_value[""maximum""] = attributes[""max""]<tab><tab>return return_value<tab>return False",1,"if ""min"" in attributes :","if ""min"" in attributes :",0.75,100.00000000000004,1.0
"def _configuredOn(self, workerid, builderid=None, masterid=None):<tab>cfg = []<tab>for cs in itervalues(self.configured):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>bid, mid = self.db.builders.builder_masters[cs[""buildermasterid""]]<tab><tab>if builderid is not None and bid != builderid:<tab><tab><tab>continue<tab><tab>if masterid is not None and mid != masterid:<tab><tab><tab>continue<tab><tab>cfg.append({""builderid"": bid, ""masterid"": mid})<tab>return cfg",1,"if cs [ ""workerid"" ] != workerid :","if cs [ ""workerid"" ] != workerid :",0.75,100.00000000000004,1.0
"def __exit__(self, type, value, traceback):<tab>try:<tab><tab>if type is not None:<tab><tab><tab>return self.exception_handler(type, value, traceback)<tab>finally:<tab><tab>final_contexts = _state.contexts<tab><tab>_state.contexts = self.old_contexts<tab><tab><IF-STMT><tab><tab><tab>raise StackContextInconsistentError(<tab><tab><tab><tab>""stack_context inconsistency (may be caused by yield ""<tab><tab><tab><tab>'within a ""with StackContext"" block)'<tab><tab><tab>)<tab><tab># Break up a reference to itself to allow for faster GC on CPython.<tab><tab>self.new_contexts = None",0,if final_contexts is not self . new_contexts :,if _state . contexts != final_contexts :,0.020676460041600547,21.42348888333948,0.3
"def del_(self, key):<tab>initial_hash = hash_ = self.hash(key)<tab>while True:<tab><tab><IF-STMT><tab><tab><tab># That key was never assigned<tab><tab><tab>return None<tab><tab>elif self._keys[hash_] == key:<tab><tab><tab># key found, assign with deleted sentinel<tab><tab><tab>self._keys[hash_] = self._deleted<tab><tab><tab>self._values[hash_] = self._deleted<tab><tab><tab>self._len -= 1<tab><tab><tab>return<tab><tab>hash_ = self._rehash(hash_)<tab><tab>if initial_hash == hash_:<tab><tab><tab># table is full and wrapped around<tab><tab><tab>return None",0,if self . _keys [ hash_ ] is self . _empty :,if hash_ == initial_hash :,0.010805043283377891,6.155947438501932,0.4605263157894737
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_logout_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def data_generator():<tab>i = 0<tab>max_batch_index = len(X_train) // batch_size<tab>tot = 0<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>yield (<tab><tab><tab><tab>np.ones([batch_size, input_dim]) * np.nan,<tab><tab><tab><tab>np.ones([batch_size, num_classes]) * np.nan,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield (<tab><tab><tab><tab>X_train[i * batch_size : (i + 1) * batch_size],<tab><tab><tab><tab>y_train[i * batch_size : (i + 1) * batch_size],<tab><tab><tab>)<tab><tab>i += 1<tab><tab>tot += 1<tab><tab>i = i % max_batch_index",0,if tot > 3 * len ( X_train ) :,if i % max_batch_index == 0 :,0.01398905512335182,4.456882760699063,0.27472527472527475
"def title(self):<tab>ret = theme[""title""]<tab>if isinstance(self.name, six.string_types):<tab><tab>width = self.statwidth()<tab><tab>return (<tab><tab><tab>ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""]<tab><tab>)<tab>for i, name in enumerate(self.name):<tab><tab>width = self.colwidth()<tab><tab>ret = ret + name[0:width].center(width).replace("" "", ""-"")<tab><tab><IF-STMT><tab><tab><tab>if op.color:<tab><tab><tab><tab>ret = ret + theme[""frame""] + char[""dash""] + theme[""title""]<tab><tab><tab>else:<tab><tab><tab><tab>ret = ret + char[""space""]<tab>return ret",0,if i + 1 != len ( self . vars ) :,if i != len ( self . name ) - 1 :,0.3076837512861572,46.35023864143851,0.375
"def get_container_from_dport(dport, docker_client):<tab>for container in docker_client.containers():<tab><tab>try:<tab><tab><tab>ports = container[""Ports""]<tab><tab><tab>for port in ports:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if port[""PublicPort""] == int(dport):<tab><tab><tab><tab><tab><tab>return container<tab><tab>except KeyError:<tab><tab><tab>print(ports)<tab><tab><tab>pass",1,"if ""PublicPort"" in port :","if ""PublicPort"" in port :",0.75,100.00000000000004,1.0
"def _get_parents_data(self, data):<tab>parents = 0<tab>if data[COLUMN_PARENT]:<tab><tab>family = self.db.get_family_from_handle(data[COLUMN_PARENT][0])<tab><tab>if family.get_father_handle():<tab><tab><tab>parents += 1<tab><tab><IF-STMT><tab><tab><tab>parents += 1<tab>return parents",0,if family . get_mother_handle ( ) :,elif family . get_father_handle ( ) :,0.09729240548623488,58.77283725105324,0.5
"def wrapper(filename):<tab>mtime = getmtime(filename)<tab>with lock:<tab><tab>if filename in cache:<tab><tab><tab>old_mtime, result = cache.pop(filename)<tab><tab><tab>if old_mtime == mtime:<tab><tab><tab><tab># Move to the end<tab><tab><tab><tab>cache[filename] = old_mtime, result<tab><tab><tab><tab>return result<tab>result = function(filename)<tab>with lock:<tab><tab>cache[filename] = mtime, result  # at the end<tab><tab><IF-STMT><tab><tab><tab>cache.popitem(last=False)<tab>return result",0,if len ( cache ) > max_size :,if cache [ filename ] > mtime :,0.020373036588449148,6.082317172853824,0.3148148148148148
"def execute(cls, ctx, op: ""DataFrameGroupByAgg""):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab>if op.stage == OperandStage.map:<tab><tab><tab>cls._execute_map(ctx, op)<tab><tab>elif op.stage == OperandStage.combine:<tab><tab><tab>cls._execute_combine(ctx, op)<tab><tab><IF-STMT><tab><tab><tab>cls._execute_agg(ctx, op)<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise ValueError(""Aggregation operand not executable"")<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",0,elif op . stage == OperandStage . agg :,elif op . stage == OperandStage . aggregate :,0.6253119268751697,78.25422900366438,0.7142857142857143
"def FindAndDelete(script, sig):<tab>""""""Consensus critical, see FindAndDelete() in Satoshi codebase""""""<tab>r = b""""<tab>last_sop_idx = sop_idx = 0<tab>skip = True<tab>for (opcode, data, sop_idx) in script.raw_iter():<tab><tab>if not skip:<tab><tab><tab>r += script[last_sop_idx:sop_idx]<tab><tab>last_sop_idx = sop_idx<tab><tab><IF-STMT><tab><tab><tab>skip = True<tab><tab>else:<tab><tab><tab>skip = False<tab>if not skip:<tab><tab>r += script[last_sop_idx:]<tab>return CScript(r)",0,if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,if opcode == sig :,0.029367913422695124,5.210158044842422,0.3181818181818182
"def extractall(zip: typing.Any, path: str) -> NoneType:<tab>for name in zip.namelist():<tab><tab>member = zip.getinfo(name)<tab><tab>extracted_path = zip._extract_member(member, path, None)<tab><tab>attr = member.external_attr >> 16<tab><tab><IF-STMT><tab><tab><tab>os.chmod(extracted_path, attr)",0,if attr != 0 :,if attr & 0x01 :,0.06497877230811641,19.3576934939088,0.6
"def find_all_gyptest_files(directory):<tab>result = []<tab>for root, dirs, files in os.walk(directory):<tab><tab><IF-STMT><tab><tab><tab>dirs.remove("".svn"")<tab><tab>result.extend([os.path.join(root, f) for f in files if is_test_name(f)])<tab>result.sort()<tab>return result",1,"if "".svn"" in dirs :","if "".svn"" in dirs :",0.75,100.00000000000004,1.0
"def load(cls, storefile, template_store):<tab># Did we get file or filename?<tab>if not hasattr(storefile, ""read""):<tab><tab>storefile = open(storefile, ""rb"")<tab># Adjust store to have translations<tab>store = cls.convertfile(storefile, template_store)<tab>for unit in store.units:<tab><tab>if unit.isheader():<tab><tab><tab>continue<tab><tab># HTML does this properly on loading, others need it<tab><tab><IF-STMT><tab><tab><tab>unit.target = unit.source<tab><tab><tab>unit.rich_target = unit.rich_source<tab>return store",0,if cls . needs_target_sync :,if unit . istranslated ( ) :,0.029730601197949243,6.495032985064742,0.37777777777777777
"def postOptions(self):<tab>_BasicOptions.postOptions(self)<tab>if self[""jobs""]:<tab><tab>conflicts = [""debug"", ""profile"", ""debug-stacktraces"", ""exitfirst""]<tab><tab>for option in conflicts:<tab><tab><tab>if self[option]:<tab><tab><tab><tab>raise usage.UsageError(<tab><tab><tab><tab><tab>""You can't specify --%s when using --jobs"" % option<tab><tab><tab><tab>)<tab>if self[""nopm""]:<tab><tab><IF-STMT><tab><tab><tab>raise usage.UsageError(""You must specify --debug when using "" ""--nopm "")<tab><tab>failure.DO_POST_MORTEM = False",0,"if not self [ ""debug"" ] :","if self [ ""debug"" ] :",0.33154408599183977,76.72796459606589,0.4722222222222222
"def filterTokenLocation():<tab>i = None<tab>entry = None<tab>token = None<tab>tokens = []<tab>i = 0<tab>while 1:<tab><tab>if not (i < len(extra.tokens)):<tab><tab><tab>break<tab><tab>entry = extra.tokens[i]<tab><tab>token = jsdict(<tab><tab><tab>{<tab><tab><tab><tab>""type"": entry.type,<tab><tab><tab><tab>""value"": entry.value,<tab><tab><tab>}<tab><tab>)<tab><tab>if extra.range:<tab><tab><tab>token.range = entry.range<tab><tab><IF-STMT><tab><tab><tab>token.loc = entry.loc<tab><tab>tokens.append(token)<tab><tab>i += 1<tab>extra.tokens = tokens",1,if extra . loc :,if extra . loc :,0.75,100.00000000000004,1.0
"def on_rebalance_end(self) -> None:<tab>""""""Call when rebalancing is done.""""""<tab>self.rebalancing = False<tab>if self._rebalancing_span:<tab><tab>self._rebalancing_span.finish()<tab>self._rebalancing_span = None<tab>sensor_state = self._rebalancing_sensor_state<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(<tab><tab><tab><tab>""Missing sensor state for rebalance #%s"", self.rebalancing_count<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.sensors.on_rebalance_end(self, sensor_state)<tab>finally:<tab><tab>self._rebalancing_sensor_state = None",0,if not sensor_state :,if sensor_state is None :,0.045150550804307965,27.77619034011791,0.36
"def decorator(request, *args, **kwargs):<tab>if CALENDAR_VIEW_PERM:<tab><tab>user = request.user<tab><tab>if not user:<tab><tab><tab>return HttpResponseRedirect(settings.LOGIN_URL)<tab><tab>occurrence, event, calendar = get_objects(request, **kwargs)<tab><tab>if calendar:<tab><tab><tab>allowed = CHECK_CALENDAR_PERM_FUNC(calendar, user)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return HttpResponseRedirect(settings.LOGIN_URL)<tab><tab><tab># all checks passed<tab><tab><tab>return function(request, *args, **kwargs)<tab><tab>return HttpResponseNotFound(""<h1>Page not found</h1>"")<tab>return function(request, *args, **kwargs)",1,if not allowed :,if not allowed :,0.75,100.00000000000004,1.0
"def reduce_arguments(self, args):<tab>assert isinstance(args, nodes.Arguments)<tab>if args.incorrect_order():<tab><tab>raise InvalidArguments(<tab><tab><tab>""All keyword arguments must be after positional arguments.""<tab><tab>)<tab>reduced_pos = [self.reduce_single(arg) for arg in args.arguments]<tab>reduced_kw = {}<tab>for key in args.kwargs.keys():<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArguments(""Keyword argument name is not a string."")<tab><tab>a = args.kwargs[key]<tab><tab>reduced_kw[key] = self.reduce_single(a)<tab>return (reduced_pos, reduced_kw)",1,"if not isinstance ( key , str ) :","if not isinstance ( key , str ) :",0.75,100.00000000000004,1.0
"def _encode(n, nbytes, little_endian=False):<tab>retval = []<tab>n = long(n)<tab>for i in range(nbytes):<tab><tab><IF-STMT><tab><tab><tab>retval.append(chr(n & 0xFF))<tab><tab>else:<tab><tab><tab>retval.insert(0, chr(n & 0xFF))<tab><tab>n >>= 8<tab>return """".join(retval)",1,if little_endian :,if little_endian :,0.5311706625951745,1e-10,1.0
"def copy_shell(self):<tab>cls = self.__class__<tab>old_id = cls.id<tab>new_i = cls()  # create a new group<tab>new_i.id = self.id  # with the same id<tab>cls.id = old_id  # Reset the Class counter<tab># Copy all properties<tab>for prop in cls.properties:<tab><tab>if prop is not ""members"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = getattr(self, prop)<tab><tab><tab><tab>setattr(new_i, prop, val)<tab># but no members<tab>new_i.members = []<tab>return new_i",0,if self . has ( prop ) :,"if hasattr ( self , prop ) :",0.08283146545460421,24.446151121745064,0.5
"def dataspec(config):<tab>master = yield fakemaster.make_master()<tab>data = connector.DataConnector()<tab>data.setServiceParent(master)<tab>if config[""out""] != ""--"":<tab><tab>dirs = os.path.dirname(config[""out""])<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dirs)<tab><tab>f = open(config[""out""], ""w"")<tab>else:<tab><tab>f = sys.stdout<tab>if config[""global""] is not None:<tab><tab>f.write(""window."" + config[""global""] + ""="")<tab>f.write(json.dumps(data.allEndpoints(), indent=2))<tab>f.close()<tab>defer.returnValue(0)",0,if dirs and not os . path . exists ( dirs ) :,if not os . path . exists ( dirs ) :,0.4366769823533633,76.26264731696685,0.22916666666666669
"def _parseSCDOCDC(self, src):<tab>""""""[S|CDO|CDC]*""""""<tab>while 1:<tab><tab>src = src.lstrip()<tab><tab><IF-STMT><tab><tab><tab>src = src[4:]<tab><tab>elif src.startswith(""-->""):<tab><tab><tab>src = src[3:]<tab><tab>else:<tab><tab><tab>break<tab>return src",0,"if src . startswith ( ""<!--"" ) :","if src . startswith ( ""<S|CDC>"" ) :",0.5490406812970063,53.16967153331756,1.0
"def command(filenames, dirnames, fix):<tab>for filename in gather_files(dirnames, filenames):<tab><tab>visitor = process_file(filename)<tab><tab>if visitor.needs_fix():<tab><tab><tab>print(""%s: %s"" % (filename, visitor.get_stats()))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""Fixing: %s"" % filename)<tab><tab><tab><tab>fix_file(filename)",1,if fix :,if fix :,0.5311706625951745,1e-10,1.0
"def shutdown(self):<tab>""""""Shutdown host system.""""""<tab>self._check_dbus(MANAGER)<tab>use_logind = self.sys_dbus.logind.is_connected<tab>_LOGGER.info(""Initialize host power off %s"", ""logind"" if use_logind else ""systemd"")<tab>try:<tab><tab>await self.sys_core.shutdown()<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>await self.sys_dbus.logind.power_off()<tab><tab>else:<tab><tab><tab>await self.sys_dbus.systemd.power_off()",1,if use_logind :,if use_logind :,0.5311706625951745,1e-10,1.0
"def _run_split_on_punc(self, text, never_split=None):<tab>""""""Splits punctuation on a piece of text.""""""<tab>if never_split is not None and text in never_split:<tab><tab>return [text]<tab>chars = list(text)<tab>i = 0<tab>start_new_word = True<tab>output = []<tab>while i < len(chars):<tab><tab>char = chars[i]<tab><tab>if _is_punctuation(char):<tab><tab><tab>output.append([char])<tab><tab><tab>start_new_word = True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output.append([])<tab><tab><tab>start_new_word = False<tab><tab><tab>output[-1].append(char)<tab><tab>i += 1<tab>return ["""".join(x) for x in output]",1,if start_new_word :,if start_new_word :,0.5311706625951745,1e-10,1.0
"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout):<tab>try:<tab><tab>if tp == ""write"":<tab><tab><tab>out.write(msg)<tab><tab><IF-STMT><tab><tab><tab>out.flush()<tab><tab>elif tp == ""write_flush"":<tab><tab><tab>out.write(msg)<tab><tab><tab>out.flush()<tab><tab>elif tp == ""print"":<tab><tab><tab>print(msg, file=out)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported type: "" + tp)<tab>except IOError as e:<tab><tab>logger.critical(""{}: {}"".format(type(e).__name__, ucd(e)))<tab><tab>pass",1,"elif tp == ""flush"" :","elif tp == ""flush"" :",1.0,100.00000000000004,1.0
"def checkClassDeclation(file):<tab>localResult = []<tab>with open(file, ""rb"") as f:<tab><tab>lineNumber = 0<tab><tab>for line in f:<tab><tab><tab>m = re.search(""class\s+[^\(]*:"", line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>localResult.append(<tab><tab><tab><tab><tab>""Old class definition found on {0}"".format(m.group())<tab><tab><tab><tab>)<tab>return localResult",1,if m :,if m :,0.5311706625951745,1e-10,1.0
"def _evaluate_local_single(self, iterator):<tab>for batch in iterator:<tab><tab>in_arrays = convert._call_converter(self.converter, batch, self.device)<tab><tab>with function.no_backprop_mode():<tab><tab><tab>if isinstance(in_arrays, tuple):<tab><tab><tab><tab>results = self.calc_local(*in_arrays)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results = self.calc_local(**in_arrays)<tab><tab><tab>else:<tab><tab><tab><tab>results = self.calc_local(in_arrays)<tab><tab>if self._progress_hook:<tab><tab><tab>self._progress_hook(batch)<tab><tab>yield results",0,"elif isinstance ( in_arrays , dict ) :","elif isinstance ( in_arrays , list ) :",0.5473017787506802,70.71067811865478,0.6
"def check_billing_view(user, permission, obj):<tab>if hasattr(obj, ""all_projects""):<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab># This is a billing object<tab><tab>return any(check_permission(user, permission, prj) for prj in obj.all_projects)<tab>return check_permission(user, permission, obj)",0,if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,if obj . all_projects == [ ] :,0.04772593337728594,3.0257072471149775,0.19444444444444445
"def ensure_output_spaces_contain_the_same_data(self, y, y_ensured):<tab>stride = y.shape[1]<tab>self.assertEqual(y.shape[0] * y.shape[1], y_ensured.shape[0])<tab>self.assertEqual(len(y_ensured.shape), 1)<tab>for row in range(y.shape[0]):<tab><tab>for column in range(y.shape[1]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(y[row, column], y_ensured[row * stride + column])<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(y[row][column], y_ensured[row * stride + column])",0,if sp . issparse ( y ) :,if y [ row ] == y_ensured [ column ] :,0.01640831101202203,3.737437943747671,0.2857142857142857
"def train(<tab>self,<tab>training_data: TrainingData,<tab>config: Optional[RasaNLUModelConfig] = None,<tab>**kwargs: Any,) -> None:<tab>""""""Tokenize all training data.""""""<tab>for example in training_data.training_examples:<tab><tab>for attribute in MESSAGE_ATTRIBUTES:<tab><tab><tab>if example.get(attribute) is not None and not example.get(attribute) == """":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>tokens = self._split_name(example, attribute)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>tokens = self.tokenize(example, attribute)<tab><tab><tab><tab>example.set(TOKENS_NAMES[attribute], tokens)",0,"if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] :",if attribute in MESSAGE_NAMES :,0.1740973706214538,6.656592803413299,0.7866666666666667
"def refresh_token(self, strategy, *args, **kwargs):<tab>token = self.extra_data.get(""refresh_token"") or self.extra_data.get(""access_token"")<tab>backend = self.get_backend(strategy)<tab>if token and backend and hasattr(backend, ""refresh_token""):<tab><tab>backend = backend(strategy=strategy)<tab><tab>response = backend.refresh_token(token, *args, **kwargs)<tab><tab>extra_data = backend.extra_data(self, self.uid, response, self.extra_data)<tab><tab><IF-STMT><tab><tab><tab>self.save()",0,if self . set_extra_data ( extra_data ) :,if extra_data :,0.017267079824235865,1e-10,0.6410256410256411
"def _verify_environ(_collected_environ):<tab>try:<tab><tab>yield<tab>finally:<tab><tab>new_environ = dict(os.environ)<tab><tab>current_test = new_environ.pop(""PYTEST_CURRENT_TEST"", None)<tab><tab>old_environ = dict(_collected_environ)<tab><tab>old_environ.pop(""PYTEST_CURRENT_TEST"", None)<tab><tab><IF-STMT><tab><tab><tab>raise DirtyTest(<tab><tab><tab><tab>""Left over environment variables"",<tab><tab><tab><tab>current_test,<tab><tab><tab><tab>_compare_eq_dict(new_environ, old_environ, verbose=2),<tab><tab><tab>)",0,if new_environ != old_environ :,"if not _compare_eq_dict ( new_environ , old_environ ) :",0.027981209555249513,14.44788670919441,0.6444444444444445
"def clean_len(self, line):<tab>""""""Calculate wisible length of string""""""<tab>if isinstance(line, basestring):<tab><tab>return len(self.screen.markup.clean_markup(line))<tab>elif isinstance(line, tuple) or isinstance(line, list):<tab><tab>markups = self.screen.markup.get_markup_vars()<tab><tab>length = 0<tab><tab>for i in line:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>length += len(i)<tab><tab>return length",1,if i not in markups :,if i not in markups :,0.75,100.00000000000004,1.0
"def _build_merged_dataset_args(datasets):<tab>merged_dataset_args = []<tab>for dataset in datasets:<tab><tab>dataset_code_column = _parse_dataset_code(dataset)<tab><tab>arg = dataset_code_column[""code""]<tab><tab>column_index = dataset_code_column[""column_index""]<tab><tab><IF-STMT><tab><tab><tab>arg = (dataset_code_column[""code""], {""column_index"": [column_index]})<tab><tab>merged_dataset_args.append(arg)<tab>return merged_dataset_args",0,if column_index is not None :,if not arg :,0.0806440934254144,7.733712583165139,0.3
"def update_watch_data_table_paths(self):<tab>if hasattr(self.tool_data_watcher, ""monitored_dirs""):<tab><tab>for tool_data_table_path in self.tool_data_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tool_data_watcher.watch_directory(tool_data_table_path)",0,if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,if tool_data_table_path not in self . monitored_dirs :,0.4512375281789748,64.7076654809797,1.0
"def getsource(obj):<tab>""""""Wrapper around inspect.getsource""""""<tab>try:<tab><tab>try:<tab><tab><tab>src = encoding.to_unicode(inspect.getsource(obj))<tab><tab>except TypeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>src = encoding.to_unicode(inspect.getsource(obj.__class__))<tab><tab><tab>else:<tab><tab><tab><tab># Bindings like VTK or ITK require this case<tab><tab><tab><tab>src = getdoc(obj)<tab><tab>return src<tab>except (TypeError, IOError):<tab><tab>return",0,"if hasattr ( obj , ""__class__"" ) :",if inspect . ismodule ( obj ) :,0.044942074429907865,7.80152171018653,0.3148148148148148
"def __iter__(self):<tab>for model in self.app_config.get_models():<tab><tab>admin_model = AdminModel(model, **self.options)<tab><tab>for model_re in self.model_res:<tab><tab><tab>if model_re.search(admin_model.name):<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield admin_model",0,if self . model_res :,if admin_model . name in self . options :,0.21642507548675122,9.864703138979419,0.2878787878787879
"def run(self):<tab>while True:<tab><tab>try:<tab><tab><tab>with DelayedKeyboardInterrupt():<tab><tab><tab><tab>raw_inputs = self._parent_task_queue.get()<tab><tab><tab><tab>if self._has_stop_signal(raw_inputs):<tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>if self._flow_type == BATCH:<tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=True)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>self._rq.put(raw_inputs, block=False)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>pass<tab><tab>except KeyboardInterrupt:<tab><tab><tab>continue",0,elif self . _flow_type == REALTIME :,elif self . _flow_type == READY :,0.8217294420803809,80.70557274927978,0.6
"def dump(self):<tab>self.ql.log.info(""[*] Dumping object: %s"" % (self.sf_name))<tab>for field in self._fields_:<tab><tab><IF-STMT><tab><tab><tab>self.ql.log.info(""%s: 0x%x"" % (field[0], getattr(self, field[0]).value))<tab><tab>elif isinstance(getattr(self, field[0]), int):<tab><tab><tab>self.ql.log.info(""%s: %d"" % (field[0], getattr(self, field[0])))<tab><tab>elif isinstance(getattr(self, field[0]), bytes):<tab><tab><tab>self.ql.log.info(""%s: %s"" % (field[0], getattr(self, field[0]).decode()))",0,"if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) :","if isinstance ( getattr ( self , field [ 0 ] ) , int ) :",0.5263954984850157,83.7117009877792,0.7777777777777778
"def validate_configuration(self, configuration: Optional[ExpectationConfiguration]):<tab>""""""Validating that user has inputted a value set and that configuration has been initialized""""""<tab>super().validate_configuration(configuration)<tab>try:<tab><tab>assert ""value_set"" in configuration.kwargs, ""value_set is required""<tab><tab>assert isinstance(<tab><tab><tab>configuration.kwargs[""value_set""], (list, set, dict)<tab><tab>), ""value_set must be a list or a set""<tab><tab><IF-STMT><tab><tab><tab>assert (<tab><tab><tab><tab>""$PARAMETER"" in configuration.kwargs[""value_set""]<tab><tab><tab>), 'Evaluation Parameter dict for value_set kwarg must have ""$PARAMETER"" key'<tab>except AssertionError as e:<tab><tab>raise InvalidExpectationConfigurationError(str(e))<tab>return True",0,"if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if ""value_set"" in configuration . kwargs :",0.04491670711297176,28.75683693213116,0.5630252100840336
def test_one_dead_branch():<tab>with deterministic_PRNG():<tab><tab>seen = set()<tab><tab>@run_to_buffer<tab><tab>def x(data):<tab><tab><tab>i = data.draw_bytes(1)[0]<tab><tab><tab>if i > 0:<tab><tab><tab><tab>data.mark_invalid()<tab><tab><tab>i = data.draw_bytes(1)[0]<tab><tab><tab>if len(seen) < 255:<tab><tab><tab><tab>seen.add(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data.mark_interesting(),0,elif i not in seen :,if i in seen :,0.11276648907478848,34.98330125272253,0.23809523809523808
"def __on_item_activated(self, event):<tab>if self.__module_view:<tab><tab>module = self.get_event_module(event)<tab><tab>self.__module_view.set_selection(module.module_num)<tab><tab>if event.EventObject is self.list_ctrl:<tab><tab><tab>self.input_list_ctrl.deactivate_active_item()<tab><tab>else:<tab><tab><tab>self.list_ctrl.deactivate_active_item()<tab><tab><tab>for index in range(self.list_ctrl.GetItemCount()):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.list_ctrl.Select(index, False)<tab>self.__controller.enable_module_controls_panel_buttons()",0,if self . list_ctrl . IsSelected ( index ) :,if self . list_ctrl . GetItem ( index ) :,0.5803088707179008,73.48889200874659,0.6666666666666666
"def prime(self, callback):<tab><IF-STMT><tab><tab># import pdb<tab><tab># pdb.set_trace()<tab><tab>self.cbhdl = simulator.register_rwsynch_callback(callback, self)<tab><tab>if self.cbhdl is None:<tab><tab><tab>raise_error(self, ""Unable set up %s Trigger"" % (str(self)))<tab>Trigger.prime(self)",1,if self . cbhdl is None :,if self . cbhdl is None :,0.75,100.00000000000004,1.0
"def fstab_configuration(middleware):<tab>for command in (<tab><tab>[<tab><tab><tab>[""systemctl"", ""daemon-reload""],<tab><tab><tab>[""systemctl"", ""restart"", ""local-fs.target""],<tab><tab>]<tab><tab>if osc.IS_LINUX<tab><tab>else [[""mount"", ""-uw"", ""/""]]<tab>):<tab><tab>ret = subprocess.run(command, capture_output=True)<tab><tab><IF-STMT><tab><tab><tab>middleware.logger.debug(<tab><tab><tab><tab>f'Failed to execute ""{"" "".join(command)}"": {ret.stderr.decode()}'<tab><tab><tab>)",0,if ret . returncode :,if ret . stderr :,0.39477865547525276,42.72870063962342,0.6
"def _generate_table(self, fromdesc, todesc, diffs):<tab>if fromdesc or todesc:<tab><tab>yield (<tab><tab><tab>simple_colorize(fromdesc, ""description""),<tab><tab><tab>simple_colorize(todesc, ""description""),<tab><tab>)<tab>for i, line in enumerate(diffs):<tab><tab><IF-STMT><tab><tab><tab># mdiff yields None on separator lines; skip the bogus ones<tab><tab><tab># generated for the first line<tab><tab><tab>if i > 0:<tab><tab><tab><tab>yield (<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab><tab>simple_colorize(""---"", ""separator""),<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield line",1,if line is None :,if line is None :,0.75,100.00000000000004,1.0
"def update_completion(self):<tab>""""""Update completion model with exist tags""""""<tab>orig_text = self.widget.text()<tab>text = "", "".join(orig_text.replace("", "", "","").split("","")[:-1])<tab>tags = []<tab>for tag in self.tags_list:<tab><tab>if "","" in orig_text:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tags.append(""%s,%s"" % (text, tag))<tab><tab><tab>tags.append(""%s, %s"" % (text, tag))<tab><tab>else:<tab><tab><tab>tags.append(tag)<tab>if tags != self.completer_model.stringList():<tab><tab>self.completer_model.setStringList(tags)",0,"if orig_text [ - 1 ] not in ( "","" , "" "" ) :",if tag == orig_text [ - 1 ] :,0.21625392613710392,30.64173701805117,0.32608695652173914
"def cart_number_checksum_validation(cls, number):<tab>digits = []<tab>even = False<tab>if not number.isdigit():<tab><tab>return False<tab>for digit in reversed(number):<tab><tab>digit = ord(digit) - ord(""0"")<tab><tab><IF-STMT><tab><tab><tab>digit *= 2<tab><tab><tab>if digit >= 10:<tab><tab><tab><tab>digit = digit % 10 + digit // 10<tab><tab>digits.append(digit)<tab><tab>even = not even<tab>return sum(digits) % 10 == 0 if digits else False",1,if even :,if even :,0.5311706625951745,1e-10,1.0
"def __get_param_string__(params):<tab>params_string = []<tab>for key in sorted(params.keys()):<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>value = params[key]<tab><tab>params_string.append("""" if value == ""null"" else str(value))<tab>return ""|"".join(params_string)",0,"if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :","if key == ""params"" :",0.0074589697276959644,2.185297586254204,0.2833333333333333
"def _map_handlers(self, session, event_class, mapfn):<tab>for event in DOC_EVENTS:<tab><tab>event_handler_name = event.replace(""-"", ""_"")<tab><tab><IF-STMT><tab><tab><tab>event_handler = getattr(self, event_handler_name)<tab><tab><tab>format_string = DOC_EVENTS[event]<tab><tab><tab>num_args = len(format_string.split(""."")) - 2<tab><tab><tab>format_args = (event_class,) + (""*"",) * num_args<tab><tab><tab>event_string = event + format_string % format_args<tab><tab><tab>unique_id = event_class + event_handler_name<tab><tab><tab>mapfn(event_string, event_handler, unique_id)",1,"if hasattr ( self , event_handler_name ) :","if hasattr ( self , event_handler_name ) :",0.75,100.00000000000004,1.0
"def _create_param_lr(self, param_and_grad):<tab># create learning rate variable for every parameter<tab>param = param_and_grad[0]<tab>param_lr = param.optimize_attr[""learning_rate""]<tab>if type(param_lr) == Variable:<tab><tab>return param_lr<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self._global_learning_rate()<tab><tab>else:<tab><tab><tab>with default_main_program()._lr_schedule_guard(<tab><tab><tab><tab>is_with_opt=True<tab><tab><tab>), framework.name_scope(""scale_with_param_lr""):<tab><tab><tab><tab>return self._global_learning_rate() * param_lr",0,if param_lr == 1.0 :,if param_lr is None :,0.06497877230811641,37.68499164492418,0.41666666666666663
"def __getitem__(self, key):<tab>try:<tab><tab>return self._clsmap[key]<tab>except KeyError as e:<tab><tab><IF-STMT><tab><tab><tab>self._mutex.acquire()<tab><tab><tab>try:<tab><tab><tab><tab>if not self.initialized:<tab><tab><tab><tab><tab>self._init()<tab><tab><tab><tab><tab>self.initialized = True<tab><tab><tab><tab>return self._clsmap[key]<tab><tab><tab>finally:<tab><tab><tab><tab>self._mutex.release()<tab><tab>raise e",1,if not self . initialized :,if not self . initialized :,0.75,100.00000000000004,1.0
"def save(self, force=False):<tab>if not force:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if time.time() - self.last_save_time < 10:<tab><tab><tab>return<tab>with self.lock:<tab><tab>with open(self.file_path, ""w"") as fd:<tab><tab><tab>for ip in self.cache:<tab><tab><tab><tab>record = self.cache[ip]<tab><tab><tab><tab>rule = record[""r""]<tab><tab><tab><tab>connect_time = record[""c""]<tab><tab><tab><tab>update_time = record[""update""]<tab><tab><tab><tab>fd.write(""%s %s %d %d\n"" % (ip, rule, connect_time, update_time))<tab>self.last_save_time = time.time()<tab>self.need_save = False",0,if not self . need_save :,if self . last_save_time is None :,0.047631794481620526,11.731175160263996,0.30952380952380953
"def pick(items, sel):<tab>for x, s in zip(items, sel):<tab><tab><IF-STMT><tab><tab><tab>yield x<tab><tab>elif not x.is_atom() and not s.is_atom():<tab><tab><tab>yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",0,if match ( s ) :,if x . is_atom ( ) and s . is_atom ( ) :,0.037995926970273784,5.751391809950023,0.3245614035087719
"def isValidFloat(config_param_name, value, constraints):<tab>if isinstance(value, float):<tab><tab>constraints.setdefault(""min"", MIN_VALID_FLOAT_VALUE)<tab><tab>constraints.setdefault(""max"", MAX_VALID_FLOAT_VALUE)<tab><tab>minv = float(constraints.get(""min""))<tab><tab>maxv = float(constraints.get(""max""))<tab><tab><IF-STMT><tab><tab><tab>if value <= maxv:<tab><tab><tab><tab>return value<tab>raise FloatValueError(config_param_name, value, constraints)",1,if value >= minv :,if value >= minv :,0.75,100.00000000000004,1.0
"def get_files(d):<tab>f = []<tab>for root, dirs, files in os.walk(d):<tab><tab>for name in files:<tab><tab><tab>if ""meta-environment"" in root or ""cross-canadian"" in root:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if ""do_build"" not in name and ""do_populate_sdk"" not in name:<tab><tab><tab><tab>f.append(os.path.join(root, name))<tab>return f",0,"if ""qemux86copy-"" in root or ""qemux86-"" in root :","if ""do_build"" in root or ""cross-canadian"" in root :",0.6048262086007482,44.80304273880272,1.0
"def __get_photo(self, person_or_marriage):<tab>""""""returns the first photo in the media list or None""""""<tab>media_list = person_or_marriage.get_media_list()<tab>for media_ref in media_list:<tab><tab>media_handle = media_ref.get_reference_handle()<tab><tab>media = self.database.get_media_from_handle(media_handle)<tab><tab>mime_type = media.get_mime_type()<tab><tab><IF-STMT><tab><tab><tab>return media<tab>return None",0,"if mime_type and mime_type . startswith ( ""image"" ) :","if mime_type == ""photo"" :",0.025595153496315533,16.581659750776073,0.46875
"def filter(this, args):<tab>array = to_object(this, args.space)<tab>callbackfn = get_arg(args, 0)<tab>arr_len = js_arr_length(array)<tab>if not is_callable(callbackfn):<tab><tab>raise MakeError(""TypeError"", ""callbackfn must be a function"")<tab>_this = get_arg(args, 1)<tab>k = 0<tab>res = []<tab>while k < arr_len:<tab><tab>if array.has_property(unicode(k)):<tab><tab><tab>kValue = array.get(unicode(k))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return args.space.ConstructArray(res)",0,"if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :","if is_callable ( callbackfn . call ( _this , kValue ) ) :",0.15987192045779944,32.11798891461292,0.6136363636363636
"def optimize(self, graph: Graph):<tab>for v in graph.inputs:<tab><tab>if not v.has_attribute(SplitTarget):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>DumpGraph().optimize(graph)<tab><tab>raise NotImplementedError(<tab><tab><tab>f""Input Variable {v} is too large to handle in WebGL backend""<tab><tab>)<tab>return graph, False",0,if flags . DEBUG :,"if v . get_name ( ) . endswith ( "".dump"" ) :",0.02446681277480503,3.0098043843528286,0.3333333333333333
"def detach_volume(self, volume):<tab># We need to find the node using this volume<tab>for node in self.list_nodes():<tab><tab>if type(node.image) is not list:<tab><tab><tab># This node has only one associated image. It is not the one we<tab><tab><tab># are after.<tab><tab><tab>continue<tab><tab>for disk in node.image:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Node found. We can now detach the volume<tab><tab><tab><tab>disk_id = disk.extra[""disk_id""]<tab><tab><tab><tab>return self._do_detach_volume(node.id, disk_id)<tab>return False",0,if disk . id == volume . id :,"if disk . extra [ ""disk_id"" ] == volume :",0.13733923645833468,17.678748653651848,0.6515151515151515
"def Yield(value, level=1):<tab>g = greenlet.getcurrent()<tab>while level != 0:<tab><tab>if not isinstance(g, genlet):<tab><tab><tab>raise RuntimeError(""yield outside a genlet"")<tab><tab><IF-STMT><tab><tab><tab>g.parent.set_child(g)<tab><tab>g = g.parent<tab><tab>level -= 1<tab>g.switch(value)",0,if level > 1 :,if g . parent :,0.03412306583404374,12.703318703865365,0.3333333333333333
"def get_all_pipeline_nodes(<tab>pipeline: pipeline_pb2.Pipeline,) -> List[pipeline_pb2.PipelineNode]:<tab>""""""Returns all pipeline nodes in the given pipeline.""""""<tab>result = []<tab>for pipeline_or_node in pipeline.nodes:<tab><tab>which = pipeline_or_node.WhichOneof(""node"")<tab><tab># TODO(goutham): Handle sub-pipelines.<tab><tab># TODO(goutham): Handle system nodes.<tab><tab><IF-STMT><tab><tab><tab>result.append(pipeline_or_node.pipeline_node)<tab><tab>else:<tab><tab><tab>raise NotImplementedError(""Only pipeline nodes supported."")<tab>return result",0,"if which == ""pipeline_node"" :",if which in pipeline_or_node . pipeline_nodes :,0.05286931595839166,10.700801516876487,0.7222222222222222
"def __init__(self, **settings):<tab>default_settings = self.get_default_settings()<tab>for name, value in default_settings.items():<tab><tab>if not hasattr(self, name):<tab><tab><tab>setattr(self, name, value)<tab>for name, value in settings.items():<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Invalid setting '{}' for {}"".format(<tab><tab><tab><tab><tab>name,<tab><tab><tab><tab><tab>self.__class__.__name__,<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>setattr(self, name, value)",0,if name not in default_settings :,"if not hasattr ( self , name ) :",0.02358519221436072,6.742555929751843,0.2698412698412698
"def _check_choice(self):<tab>if self.type == ""choice"":<tab><tab><IF-STMT><tab><tab><tab>raise OptionError(""must supply a list of choices for type 'choice'"", self)<tab><tab>elif type(self.choices) not in (types.TupleType, types.ListType):<tab><tab><tab>raise OptionError(<tab><tab><tab><tab>""choices must be a list of strings ('%s' supplied)""<tab><tab><tab><tab>% str(type(self.choices)).split(""'"")[1],<tab><tab><tab><tab>self,<tab><tab><tab>)<tab>elif self.choices is not None:<tab><tab>raise OptionError(""must not supply choices for type %r"" % self.type, self)",1,if self . choices is None :,if self . choices is None :,0.75,100.00000000000004,1.0
"def prepare(self, size=None):<tab>if _is_seekable(self.file):<tab><tab>start_pos = self.file.tell()<tab><tab>self.file.seek(0, 2)<tab><tab>end_pos = self.file.tell()<tab><tab>self.file.seek(start_pos)<tab><tab>fsize = end_pos - start_pos<tab><tab><IF-STMT><tab><tab><tab>self.remain = fsize<tab><tab>else:<tab><tab><tab>self.remain = min(fsize, size)<tab>return self.remain",1,if size is None :,if size is None :,0.75,100.00000000000004,1.0
"def _setSitemapTargets():<tab>if not conf.sitemapUrl:<tab><tab>return<tab>infoMsg = ""parsing sitemap '%s'"" % conf.sitemapUrl<tab>logger.info(infoMsg)<tab>found = False<tab>for item in parseSitemap(conf.sitemapUrl):<tab><tab><IF-STMT><tab><tab><tab>found = True<tab><tab><tab>kb.targets.add((item.strip(), None, None, None, None))<tab>if not found and not conf.forms and not conf.crawlDepth:<tab><tab>warnMsg = ""no usable links found (with GET parameters)""<tab><tab>logger.warn(warnMsg)",0,"if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :",if item . strip ( ) :,0.01717950139233721,1.1452391509210562,0.2653061224489796
"def test_CY_decomposition(self, tol):<tab>""""""Tests that the decomposition of the CY gate is correct""""""<tab>op = qml.CY(wires=[0, 1])<tab>res = op.decomposition(op.wires)<tab>mats = []<tab>for i in reversed(res):<tab><tab><IF-STMT><tab><tab><tab>mats.append(np.kron(i.matrix, np.eye(2)))<tab><tab>else:<tab><tab><tab>mats.append(i.matrix)<tab>decomposed_matrix = np.linalg.multi_dot(mats)<tab>assert np.allclose(decomposed_matrix, op.matrix, atol=tol, rtol=0)",0,if len ( i . wires ) == 1 :,if i . shape [ 0 ] == 1 :,0.11193323102329442,28.997844147152072,0.375
"def _line_ranges(statements, lines):<tab>""""""Produce a list of ranges for `format_lines`.""""""<tab>statements = sorted(statements)<tab>lines = sorted(lines)<tab>pairs = []<tab>start = None<tab>lidx = 0<tab>for stmt in statements:<tab><tab>if lidx >= len(lines):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>lidx += 1<tab><tab><tab>if not start:<tab><tab><tab><tab>start = stmt<tab><tab><tab>end = stmt<tab><tab>elif start:<tab><tab><tab>pairs.append((start, end))<tab><tab><tab>start = None<tab>if start:<tab><tab>pairs.append((start, end))<tab>return pairs",0,if stmt == lines [ lidx ] :,"if stmt != ""\n"" and lidx < len ( lines ) - 1 :",0.02882195245941782,5.653041175801492,0.4779411764705882
"def init_params(net):<tab>""""""Init layer parameters.""""""<tab>for module in net.modules():<tab><tab>if isinstance(module, nn.Conv2d):<tab><tab><tab>init.kaiming_normal(module.weight, mode=""fan_out"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>init.constant(module.bias, 0)<tab><tab>elif isinstance(module, nn.BatchNorm2d):<tab><tab><tab>init.constant(module.weight, 1)<tab><tab><tab>init.constant(module.bias, 0)<tab><tab>elif isinstance(module, nn.Linear):<tab><tab><tab>init.normal(module.weight, std=1e-3)<tab><tab><tab>if module.bias:<tab><tab><tab><tab>init.constant(module.bias, 0)",1,if module . bias :,if module . bias :,0.75,100.00000000000004,1.0
"def _get_directory_size_in_bytes(directory):<tab>total = 0<tab>try:<tab><tab>for entry in os.scandir(directory):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># if it's a file, use stat() function<tab><tab><tab><tab>total += entry.stat().st_size<tab><tab><tab>elif entry.is_dir():<tab><tab><tab><tab># if it's a directory, recursively call this function<tab><tab><tab><tab>total += _get_directory_size_in_bytes(entry.path)<tab>except NotADirectoryError:<tab><tab># if `directory` isn't a directory, get the file size then<tab><tab>return os.path.getsize(directory)<tab>except PermissionError:<tab><tab># if for whatever reason we can't open the folder, return 0<tab><tab>return 0<tab>return total",1,if entry . is_file ( ) :,if entry . is_file ( ) :,0.75,100.00000000000004,1.0
"def run_cmd(self, util, to, always_push_mark=False):<tab>if to == ""bof"":<tab><tab>util.push_mark_and_goto_position(0)<tab>elif to == ""eof"":<tab><tab>util.push_mark_and_goto_position(self.view.size())<tab>elif to in (""eow"", ""bow""):<tab><tab>visible = self.view.visible_region()<tab><tab>pos = visible.a if to == ""bow"" else visible.b<tab><tab><IF-STMT><tab><tab><tab>util.push_mark_and_goto_position(pos)<tab><tab>else:<tab><tab><tab>util.set_cursors([sublime.Region(pos)])",1,if always_push_mark :,if always_push_mark :,0.5311706625951745,1e-10,1.0
"def parse_results(cwd):<tab>optimal_dd = None<tab>optimal_measure = numpy.inf<tab>for tup in tools.find_conf_files(cwd):<tab><tab>dd = tup[1]<tab><tab>if ""results.train_y_misclass"" in dd:<tab><tab><tab>if dd[""results.train_y_misclass""] < optimal_measure:<tab><tab><tab><tab>optimal_measure = dd[""results.train_y_misclass""]<tab><tab><tab><tab>optimal_dd = dd<tab>print(""Optimal results.train_y_misclass:"", str(optimal_measure))<tab>for key, value in optimal_dd.items():<tab><tab><IF-STMT><tab><tab><tab>print(key + "": "" + str(value))",0,"if ""hyper_parameters"" in key :","if key != ""results.train_y_misclass"" :",0.03654024892898815,4.444587794585869,0.45
"def clean_vc_position(self):<tab>vc_position = self.cleaned_data[""vc_position""]<tab>if self.validate_vc_position:<tab><tab>conflicting_members = Device.objects.filter(<tab><tab><tab>virtual_chassis=self.instance.virtual_chassis, vc_position=vc_position<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(<tab><tab><tab><tab>""A virtual chassis member already exists in position {}."".format(<tab><tab><tab><tab><tab>vc_position<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return vc_position",0,if conflicting_members . exists ( ) :,if conflicts_members . exists ( ) :,0.574113272471593,75.06238537503395,1.0
"def cal_pads(auto_pad, pad_shape):<tab>spatial_size = len(pad_shape)<tab>pads = [0] * spatial_size * 2<tab>for i in range(spatial_size):<tab><tab>if auto_pad == ""SAME_LOWER"":<tab><tab><tab>pads[i + spatial_size] = pad_shape[i] // 2<tab><tab><tab>pads[i] = pad_shape[i] - pads[i + spatial_size]<tab><tab><IF-STMT><tab><tab><tab>pads[i] = pad_shape[i] // 2<tab><tab><tab>pads[i + spatial_size] = pad_shape[i] - pads[i]<tab>return pads",1,"elif auto_pad == ""SAME_UPPER"" :","elif auto_pad == ""SAME_UPPER"" :",1.0,100.00000000000004,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_presence_response().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def test_cwl_rnaseq(self, install_test_files):<tab>with install_cwl_test_files() as work_dir:<tab><tab>with utils.chdir(os.path.join(work_dir, ""rnaseq"")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shutil.rmtree(""cromwell_work"")<tab><tab><tab>subprocess.check_call(<tab><tab><tab><tab>[""bcbio_vm.py"", ""cwlrun"", ""cromwell"", ""rnaseq-workflow""]<tab><tab><tab>)",1,"if os . path . exists ( ""cromwell_work"" ) :","if os . path . exists ( ""cromwell_work"" ) :",0.75,100.00000000000004,1.0
"def files_per_version(self):<tab>xpath = ""./files/file""<tab>files = self.root.findall(xpath)<tab>versions = {}<tab>for file in files:<tab><tab>vfile = file.findall(""version"")<tab><tab>for version in vfile:<tab><tab><tab>nb = version.attrib[""nb""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>versions[nb] = []<tab><tab><tab>versions[nb].append(file.attrib[""url""])<tab>return versions",0,if not nb in versions :,if nb not in versions :,0.2201405707067377,35.930411196308434,0.6666666666666666
"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># SQLite doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""SQLite backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return six.text_type(value)",1,if settings . USE_TZ :,if settings . USE_TZ :,0.75,100.00000000000004,1.0
"def _toplevelTryFunc(func, *args, status=status, **kwargs):<tab>with ThreadProfiler(threading.current_thread()) as prof:<tab><tab>t = threading.current_thread()<tab><tab>t.name = func.__name__<tab><tab>try:<tab><tab><tab>t.status = func(*args, **kwargs)<tab><tab>except EscapeException as e:  # user aborted<tab><tab><tab>t.status = ""aborted by user""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>status(""%s aborted"" % t.name, priority=2)<tab><tab>except Exception as e:<tab><tab><tab>t.exception = e<tab><tab><tab>t.status = ""exception""<tab><tab><tab>vd.exceptionCaught(e)<tab><tab>if t.sheet:<tab><tab><tab>t.sheet.currentThreads.remove(t)",1,if status :,if status :,0.5311706625951745,1e-10,1.0
"def ESP(phrase):<tab>for num, name in enumerate(devname):<tab><tab>if name.lower() in phrase:<tab><tab><tab>dev = devid[num]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ctrl = ""=ON""<tab><tab><tab><tab>say(""Turning On "" + name)<tab><tab><tab>elif custom_action_keyword[""Dict""][""Off""] in phrase:<tab><tab><tab><tab>ctrl = ""=OFF""<tab><tab><tab><tab>say(""Turning Off "" + name)<tab><tab><tab>rq = requests.head(""https://"" + ip + dev + ctrl, verify=False)",1,"if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :",0.75,100.00000000000004,1.0
"def _table_schema(self, table):<tab>rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall()<tab># Build list of fields from table information<tab>result = {}<tab>for _, name, data_type, not_null, _, primary_key in rows:<tab><tab>parts = [data_type]<tab><tab><IF-STMT><tab><tab><tab>parts.append(""PRIMARY KEY"")<tab><tab>if not_null:<tab><tab><tab>parts.append(""NOT NULL"")<tab><tab>result[name] = "" "".join(parts)<tab>return result",1,if primary_key :,if primary_key :,0.5311706625951745,1e-10,1.0
"def _validate_forward_input(x, n_in):<tab>if n_in != 1:<tab><tab>if not isinstance(x, (tuple, list)):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>f""Expected input to be a tuple or list; instead got {type(x)}.""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""Input tuple length ({len(x)}) does not equal required ""<tab><tab><tab><tab>f""number of inputs ({n_in}).""<tab><tab><tab>)",1,if len ( x ) != n_in :,if len ( x ) != n_in :,0.75,100.00000000000004,1.0
"def _table_reprfunc(self, row, col, val):<tab>if self._table.column_names[col].endswith(""Size""):<tab><tab>if isinstance(val, compat.string_types):<tab><tab><tab>return ""  %s"" % val<tab><tab><IF-STMT><tab><tab><tab>return ""  %.1f KB"" % (val / 1024.0 ** 1)<tab><tab>elif val < 1024 ** 3:<tab><tab><tab>return ""  %.1f MB"" % (val / 1024.0 ** 2)<tab><tab>else:<tab><tab><tab>return ""  %.1f GB"" % (val / 1024.0 ** 3)<tab>if col in (0, """"):<tab><tab>return str(val)<tab>else:<tab><tab>return ""  %s"" % val",0,elif val < 1024 ** 2 :,elif val < 1024 ** 1 :,0.5717294420803809,70.71067811865478,0.6666666666666666
"def get_path_name(self):<tab>if self.is_root():<tab><tab>return ""@"" + self.name<tab>else:<tab><tab>parent_name = self.parent.get_path_name()<tab><tab><IF-STMT><tab><tab><tab>return ""/"".join([parent_name, ""@"" + self.name])<tab><tab>else:<tab><tab><tab>return ""@"" + self.name",1,if parent_name :,if parent_name :,0.5311706625951745,1e-10,1.0
"def parse(cls, api, json):<tab>lst = List(api)<tab>setattr(lst, ""_json"", json)<tab>for k, v in json.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(lst, k, User.parse(api, v))<tab><tab>elif k == ""created_at"":<tab><tab><tab>setattr(lst, k, parse_datetime(v))<tab><tab>else:<tab><tab><tab>setattr(lst, k, v)<tab>return lst",1,"if k == ""user"" :","if k == ""user"" :",0.75,100.00000000000004,1.0
"def _bytecode_filenames(self, py_filenames):<tab>bytecode_files = []<tab>for py_file in py_filenames:<tab><tab>if not py_file.endswith("".py""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>bytecode_files.append(py_file + ""c"")<tab><tab>if self.optimize > 0:<tab><tab><tab>bytecode_files.append(py_file + ""o"")<tab>return bytecode_files",0,if self . compile :,if self . optimize > 0 :,0.11726065783135259,26.269098944241588,0.4761904761904762
"def to_json_dict(self):<tab>d = super().to_json_dict()<tab>d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list)<tab>if self.header is not None:<tab><tab><IF-STMT><tab><tab><tab>d[""header""] = self.header.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""header""] = self.header<tab>if self.subheader is not None:<tab><tab>if isinstance(self.subheader, RenderedContent):<tab><tab><tab>d[""subheader""] = self.subheader.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""subheader""] = self.subheader<tab>return d",1,"if isinstance ( self . header , RenderedContent ) :","if isinstance ( self . header , RenderedContent ) :",0.75,100.00000000000004,1.0
"def makeSomeFiles(pathobj, dirdict):<tab>pathdict = {}<tab>for (key, value) in dirdict.items():<tab><tab>child = pathobj.child(key)<tab><tab>if isinstance(value, bytes):<tab><tab><tab>pathdict[key] = child<tab><tab><tab>child.setContent(value)<tab><tab><IF-STMT><tab><tab><tab>child.createDirectory()<tab><tab><tab>pathdict[key] = makeSomeFiles(child, value)<tab><tab>else:<tab><tab><tab>raise ValueError(""only strings and dicts allowed as values"")<tab>return pathdict",0,"elif isinstance ( value , dict ) :",elif not child . exists ( ) :,0.13492671028290049,13.134549472120788,0.25
"def Restore(self):<tab>picker, obj = self._window, self._pObject<tab>value = obj.RestoreValue(PERSIST_FILEDIRPICKER_PATH)<tab>if value is not None:<tab><tab><IF-STMT><tab><tab><tab>if type(value) == list:<tab><tab><tab><tab>value = value[-1]<tab><tab>picker.SetPath(value)<tab><tab>return True<tab>return False",0,"if issubclass ( picker . __class__ , wx . FileDialog ) :",if value is not None :,0.010667164792151046,1.8231094563196564,0.2
"def recv(self, buffer_size):<tab>try:<tab><tab>return super(SSLConnection, self).recv(buffer_size)<tab>except ssl.SSLError as err:<tab><tab><IF-STMT><tab><tab><tab>return b""""<tab><tab>if err.args[0] in (ssl.SSL_ERROR_EOF, ssl.SSL_ERROR_ZERO_RETURN):<tab><tab><tab>self.handle_close()<tab><tab><tab>return b""""<tab><tab>raise",0,"if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) :",if err . args [ 0 ] == ssl . SSL_ERROR_EOF :,0.3099446754742138,29.8820730363045,0.7023809523809523
"def IncrementErrorCount(self, category):<tab>""""""Bumps the module's error statistic.""""""<tab>self.error_count += 1<tab>if self.counting in (""toplevel"", ""detailed""):<tab><tab><IF-STMT><tab><tab><tab>category = category.split(""/"")[0]<tab><tab>if category not in self.errors_by_category:<tab><tab><tab>self.errors_by_category[category] = 0<tab><tab>self.errors_by_category[category] += 1",0,"if self . counting != ""detailed"" :","if ""/"" in category :",0.02225082504991546,6.050259138270144,0.3333333333333333
"def _get_y(self, data_inst):<tab>if self.stratified:<tab><tab>y = [v for i, v in data_inst.mapValues(lambda v: v.label).collect()]<tab><tab><IF-STMT><tab><tab><tab>y = self.transform_regression_label(data_inst)<tab>else:<tab><tab># make dummy y<tab><tab>y = [0] * (data_inst.count())<tab>return y",0,if self . need_transform :,if self . use_regression :,0.39477865547525276,27.77619034011791,1.0
"def test_all_project_files(self):<tab>if sys.platform.startswith(""win""):<tab><tab># XXX something with newlines goes wrong on Windows.<tab><tab>return<tab>for filepath in support.all_project_files():<tab><tab>with open(filepath, ""rb"") as fp:<tab><tab><tab>encoding = tokenize.detect_encoding(fp.readline)[0]<tab><tab>self.assertIsNotNone(encoding, ""can't detect encoding for %s"" % filepath)<tab><tab>with open(filepath, ""r"") as fp:<tab><tab><tab>source = fp.read()<tab><tab><tab>source = source.decode(encoding)<tab><tab>tree = driver.parse_string(source)<tab><tab>new = unicode(tree)<tab><tab><IF-STMT><tab><tab><tab>self.fail(""Idempotency failed: %s"" % filepath)",0,"if diff ( filepath , new , encoding ) :",if len ( new ) != 0 :,0.0667365715238639,6.379653897348568,0.23863636363636365
"def test_resource_arn_override_generator(self):<tab>overrides = set()<tab>for k, v in manager.resources.items():<tab><tab>arn_gen = bool(v.__dict__.get(""get_arns"") or v.__dict__.get(""generate_arn""))<tab><tab><IF-STMT><tab><tab><tab>overrides.add(k)<tab>overrides = overrides.difference(<tab><tab>{<tab><tab><tab>""account"",<tab><tab><tab>""s3"",<tab><tab><tab>""hostedzone"",<tab><tab><tab>""log-group"",<tab><tab><tab>""rest-api"",<tab><tab><tab>""redshift-snapshot"",<tab><tab><tab>""rest-stage"",<tab><tab>}<tab>)<tab>if overrides:<tab><tab>raise ValueError(""unknown arn overrides in %s"" % ("", "".join(overrides)))",1,if arn_gen :,if arn_gen :,0.5311706625951745,1e-10,1.0
"def _check_dsl_runner(self) -> None:<tab>""""""Checks if runner in dsl is Kubeflow V2 runner.""""""<tab>with open(self.flags_dict[labels.PIPELINE_DSL_PATH], ""r"") as f:<tab><tab>dsl_contents = f.read()<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""KubeflowV2DagRunner not found in dsl."")",0,"if ""KubeflowV2DagRunner"" not in dsl_contents :","if dsl_contents == """" :",0.029084142862704995,19.62791284379258,0.4375
"def create_warehouse(warehouse_name, properties=None, company=None):<tab>if not company:<tab><tab>company = ""_Test Company""<tab>warehouse_id = erpnext.encode_company_abbr(warehouse_name, company)<tab>if not frappe.db.exists(""Warehouse"", warehouse_id):<tab><tab>warehouse = frappe.new_doc(""Warehouse"")<tab><tab>warehouse.warehouse_name = warehouse_name<tab><tab>warehouse.parent_warehouse = ""All Warehouses - _TCUV""<tab><tab>warehouse.company = company<tab><tab>warehouse.account = get_warehouse_account(warehouse_name, company)<tab><tab><IF-STMT><tab><tab><tab>warehouse.update(properties)<tab><tab>warehouse.save()<tab><tab>return warehouse.name<tab>else:<tab><tab>return warehouse_id",1,if properties :,if properties :,0.5311706625951745,1e-10,1.0
"def _parse(self, contents):<tab>entries = []<tab>hostnames_found = set()<tab>for line in contents.splitlines():<tab><tab>if not len(line.strip()):<tab><tab><tab>entries.append((""blank"", [line]))<tab><tab><tab>continue<tab><tab>(head, tail) = chop_comment(line.strip(), ""#"")<tab><tab><IF-STMT><tab><tab><tab>entries.append((""all_comment"", [line]))<tab><tab><tab>continue<tab><tab>entries.append((""hostname"", [head, tail]))<tab><tab>hostnames_found.add(head)<tab>if len(hostnames_found) > 1:<tab><tab>raise IOError(""Multiple hostnames (%s) found!"" % (hostnames_found))<tab>return entries",0,if not len ( head ) :,if head in hostnames_found :,0.02384665141965364,8.643019616048525,0.30952380952380953
"def _get_omega(self):<tab>if self._omega is None:<tab><tab>n = self.get_drift_dim() // 2<tab><tab>omg = sympl.calc_omega(n)<tab><tab>if self.oper_dtype == Qobj:<tab><tab><tab>self._omega = Qobj(omg, dims=self.dyn_dims)<tab><tab><tab>self._omega_qobj = self._omega<tab><tab><IF-STMT><tab><tab><tab>self._omega = sp.csr_matrix(omg)<tab><tab>else:<tab><tab><tab>self._omega = omg<tab>return self._omega",0,elif self . oper_dtype == sp . csr_matrix :,elif self . op_dtype == sp . csr_matrix :,0.5484745896009823,78.25422900366432,1.0
"def get_in_inputs(key, data):<tab>if isinstance(data, dict):<tab><tab>for k, v in data.items():<tab><tab><tab>if k == key:<tab><tab><tab><tab>return v<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out = get_in_inputs(key, v)<tab><tab><tab><tab>if out:<tab><tab><tab><tab><tab>return out<tab>elif isinstance(data, (list, tuple)):<tab><tab>out = [get_in_inputs(key, x) for x in data]<tab><tab>out = [x for x in out if x]<tab><tab>if out:<tab><tab><tab>return out[0]",0,"elif isinstance ( v , ( list , tuple , dict ) ) :","elif isinstance ( v , ( list , tuple ) ) :",0.4452752108413118,70.63486135430557,0.8487394957983193
def visit_binary(binary):<tab>if binary.operator == operators.eq:<tab><tab>cols = util.column_set(chain(*[c.proxy_set for c in columns.difference(omit)]))<tab><tab><IF-STMT><tab><tab><tab>for c in reversed(columns):<tab><tab><tab><tab>if c.shares_lineage(binary.right) and (<tab><tab><tab><tab><tab>not only_synonyms or c.name == binary.left.name<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>omit.add(c)<tab><tab><tab><tab><tab>break,0,if binary . left in cols and binary . right in cols :,if only_synonyms :,0.006889958188542428,1e-10,0.175
"def wait_tasks_or_abort(futures, timeout=60, kill_switch_ev=None):<tab>try:<tab><tab>LazySingletonTasksCoordinator.wait_tasks(<tab><tab><tab>futures, return_when=FIRST_EXCEPTION, raise_exceptions=True<tab><tab>)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab># Used when we want to keep both raise the exception and wait for all tasks to finish<tab><tab><tab>kill_switch_ev.set()<tab><tab><tab>LazySingletonTasksCoordinator.wait_tasks(<tab><tab><tab><tab>futures,<tab><tab><tab><tab>return_when=ALL_COMPLETED,<tab><tab><tab><tab>raise_exceptions=False,<tab><tab><tab><tab>timeout=timeout,<tab><tab><tab>)<tab><tab>raise e",1,if kill_switch_ev is not None :,if kill_switch_ev is not None :,0.75,100.00000000000004,1.0
"def is_valid(sample):<tab>if sample is None:<tab><tab>return False<tab>if isinstance(sample, tuple):<tab><tab>for s in sample:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, np.ndarray) and s.size == 0:<tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, collections.abc.Sequence) and len(s) == 0:<tab><tab><tab><tab>return False<tab>return True",0,if s is None :,"if isinstance ( s , str ) and s . size == 0 :",0.023562158811158227,3.4585921141027356,0.175
"def setVaName(self, va, parent=None):<tab>if parent is None:<tab><tab>parent = self<tab>curname = self.vw.getName(va)<tab>if curname is None:<tab><tab>curname = """"<tab>name, ok = QInputDialog.getText(parent, ""Enter..."", ""Name"", text=curname)<tab>if ok:<tab><tab>name = str(name)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Duplicate Name: %s"" % name)<tab><tab>self.vw.makeName(va, name)",0,if self . vw . vaByName ( name ) :,if name in self . vw . getName ( va ) :,0.3568621168201452,27.901593935858266,0.20370370370370372
"def generic_tag_compiler(params, defaults, name, node_class, parser, token):<tab>""Returns a template.Node subclass.""<tab>bits = token.split_contents()[1:]<tab>bmax = len(params)<tab>def_len = defaults and len(defaults) or 0<tab>bmin = bmax - def_len<tab>if len(bits) < bmin or len(bits) > bmax:<tab><tab><IF-STMT><tab><tab><tab>message = ""%s takes %s arguments"" % (name, bmin)<tab><tab>else:<tab><tab><tab>message = ""%s takes between %s and %s arguments"" % (name, bmin, bmax)<tab><tab>raise TemplateSyntaxError(message)<tab>return node_class(bits)",0,if bmin == bmax :,if len ( bits ) == def_len :,0.028001459970687266,8.913765521398126,0.3333333333333333
"def extract_segmentation_mask(annotation):<tab>poly_specs = annotation[DensePoseDataRelative.S_KEY]<tab>if isinstance(poly_specs, torch.Tensor):<tab><tab># data is already given as mask tensors, no need to decode<tab><tab>return poly_specs<tab>import pycocotools.mask as mask_utils<tab>segm = torch.zeros((DensePoseDataRelative.MASK_SIZE,) * 2, dtype=torch.float32)<tab>for i in range(DensePoseDataRelative.N_BODY_PARTS):<tab><tab>poly_i = poly_specs[i]<tab><tab><IF-STMT><tab><tab><tab>mask_i = mask_utils.decode(poly_i)<tab><tab><tab>segm[mask_i > 0] = i + 1<tab>return segm",0,if poly_i :,if pycocotools . is_tensor ( poly_i ) :,0.046522600101893324,1e-10,0.6410256410256411
"def module_list(target, fast):<tab>""""""Find the list of modules to be compiled""""""<tab>modules = []<tab>native = native_modules(target)<tab>basedir = os.path.join(ouroboros_repo_folder(), ""ouroboros"")<tab>for name in os.listdir(basedir):<tab><tab>module_name, ext = os.path.splitext(name)<tab><tab><IF-STMT><tab><tab><tab>if module_name not in IGNORE_MODULES and module_name not in native:<tab><tab><tab><tab>if not (fast and module_name in KNOWN_PROBLEM_MODULES):<tab><tab><tab><tab><tab>modules.append(module_name)<tab>return set(modules)",0,"if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :","if ext == "".py"" :",0.044536052775756035,6.178049532397588,0.21678321678321677
"def filelist_from_patterns(pats, rootdir=None):<tab>if rootdir is None:<tab><tab>rootdir = "".""<tab># filelist = []<tab>fileset = set([])<tab>lines = [line.strip() for line in pats]<tab>for line in lines:<tab><tab>pat = line[2:]<tab><tab>newfiles = glob(osp.join(rootdir, pat))<tab><tab>if line.startswith(""+""):<tab><tab><tab>fileset.update(newfiles)<tab><tab><IF-STMT><tab><tab><tab>fileset.difference_update(newfiles)<tab><tab>else:<tab><tab><tab>raise ValueError(""line must start with + or -"")<tab>filelist = list(fileset)<tab>return filelist",1,"elif line . startswith ( ""-"" ) :","elif line . startswith ( ""-"" ) :",0.75,100.00000000000004,1.0
"def get_upstream_statuses_events(self, upstream: Set) -> Dict[str, V1Statuses]:<tab>statuses_by_refs = {u: [] for u in upstream}<tab>events = self.events or []  # type: List[V1EventTrigger]<tab>for e in events:<tab><tab>entity_ref = contexts_refs.get_entity_ref(e.ref)<tab><tab>if not entity_ref:<tab><tab><tab>continue<tab><tab>if entity_ref not in statuses_by_refs:<tab><tab><tab>continue<tab><tab>for kind in e.kinds:<tab><tab><tab>status = V1EventKind.events_statuses_mapping.get(kind)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statuses_by_refs[entity_ref].append(status)<tab>return statuses_by_refs",1,if status :,if status :,0.5311706625951745,1e-10,1.0
"def __setitem__(self, key, value):<tab>if isinstance(value, (tuple, list)):<tab><tab>info, reference = value<tab><tab><IF-STMT><tab><tab><tab>self._reverse_infos[info] = len(self._infos)<tab><tab><tab>self._infos.append(info)<tab><tab>if reference not in self._reverse_references:<tab><tab><tab>self._reverse_references[reference] = len(self._references)<tab><tab><tab>self._references.append(reference)<tab><tab>self._trails[key] = ""%d,%d"" % (<tab><tab><tab>self._reverse_infos[info],<tab><tab><tab>self._reverse_references[reference],<tab><tab>)<tab>else:<tab><tab>raise Exception(""unsupported type '%s'"" % type(value))",1,if info not in self . _reverse_infos :,if info not in self . _reverse_infos :,0.75,100.00000000000004,1.0
"def ChangeStyle(self, combos):<tab>style = 0<tab>for combo in combos:<tab><tab><IF-STMT><tab><tab><tab>if combo.GetLabel() == ""TR_VIRTUAL"":<tab><tab><tab><tab>style = style | HTL.TR_VIRTUAL<tab><tab><tab>else:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>style = style | eval(""wx."" + combo.GetLabel())<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>style = style | eval(""HTL."" + combo.GetLabel())<tab>if self.GetAGWWindowStyleFlag() != style:<tab><tab>self.SetAGWWindowStyleFlag(style)",0,if combo . GetValue ( ) == 1 :,if combo . IsShown ( ) :,0.18089226606614267,20.95871245288356,0.48484848484848486
"def _parse_csrf(self, response):<tab>for d in response:<tab><tab>if d.startswith(""Set-Cookie:""):<tab><tab><tab>for c in d.split("":"", 1)[1].split("";""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._CSRFtoken = c.strip("" \r\n"")<tab><tab><tab><tab><tab>log.verbose(""Got new cookie: %s"", self._CSRFtoken)<tab><tab><tab><tab><tab>break<tab><tab><tab>if self._CSRFtoken != None:<tab><tab><tab><tab>break",0,"if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :","if c . startswith ( ""CSRFtoken"" ) :",0.1207749174710305,31.697477944241424,0.5882352941176471
"def test_page_size_matching_max_returned_rows(<tab>app_client_returned_rows_matches_page_size,):<tab>fetched = []<tab>path = ""/fixtures/no_primary_key.json""<tab>while path:<tab><tab>response = app_client_returned_rows_matches_page_size.get(path)<tab><tab>fetched.extend(response.json[""rows""])<tab><tab>assert len(response.json[""rows""]) in (1, 50)<tab><tab>path = response.json[""next_url""]<tab><tab><IF-STMT><tab><tab><tab>path = path.replace(""http://localhost"", """")<tab>assert 201 == len(fetched)",0,if path :,"if path . startswith ( ""http://"" ) :",0.08273018186267159,1e-10,0.7272727272727273
"def get_mapping_exception_message(mappings: List[Tuple[Text, Text]]):<tab>""""""Return a message given a list of duplicates.""""""<tab>message = """"<tab>for name, action_name in mappings:<tab><tab><IF-STMT><tab><tab><tab>message += ""\n""<tab><tab>message += (<tab><tab><tab>""Intent '{}' is set to trigger action '{}', which is ""<tab><tab><tab>""not defined in the domain."".format(name, action_name)<tab><tab>)<tab>return message",1,if message :,if message :,0.5311706625951745,1e-10,1.0
def cut(sentence):<tab>sentence = strdecode(sentence)<tab>blocks = re_han.split(sentence)<tab>for blk in blocks:<tab><tab>if re_han.match(blk):<tab><tab><tab>for word in __cut(blk):<tab><tab><tab><tab>if word not in Force_Split_Words:<tab><tab><tab><tab><tab>yield word<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>for c in word:<tab><tab><tab><tab><tab><tab>yield c<tab><tab>else:<tab><tab><tab>tmp = re_skip.split(blk)<tab><tab><tab>for x in tmp:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield x,0,if x :,if x not in Force_Split_Words :,0.09036476851692153,1e-10,0.5333333333333333
"def chop(expr, delta=10.0 ** (-10.0)):<tab>if isinstance(expr, Real):<tab><tab>if -delta < expr.get_float_value() < delta:<tab><tab><tab>return Integer(0)<tab>elif isinstance(expr, Complex) and expr.is_inexact():<tab><tab>real, imag = expr.real, expr.imag<tab><tab>if -delta < real.get_float_value() < delta:<tab><tab><tab>real = Integer(0)<tab><tab><IF-STMT><tab><tab><tab>imag = Integer(0)<tab><tab>return Complex(real, imag)<tab>elif isinstance(expr, Expression):<tab><tab>return Expression(chop(expr.head), *[chop(leaf) for leaf in expr.leaves])<tab>return expr",1,if - delta < imag . get_float_value ( ) < delta :,if - delta < imag . get_float_value ( ) < delta :,1.0,100.00000000000004,1.0
"def make_row(self):<tab>res = []<tab>for i in range(self.num_cols):<tab><tab>t = sqlite3_column_type(self.stmnt, i)<tab><tab># print(""type"", t)<tab><tab>if t == SQLITE_INTEGER:<tab><tab><tab>res.append(sqlite3_column_int(self.stmnt, i))<tab><tab>elif t == SQLITE_FLOAT:<tab><tab><tab>res.append(sqlite3_column_double(self.stmnt, i))<tab><tab><IF-STMT><tab><tab><tab>res.append(sqlite3_column_text(self.stmnt, i))<tab><tab>else:<tab><tab><tab>raise NotImplementedError<tab>return tuple(res)",1,elif t == SQLITE_TEXT :,elif t == SQLITE_TEXT :,1.0,100.00000000000004,1.0
"def try_convert(self, string):<tab>string = string.strip()<tab>try:<tab><tab>return int(string)<tab>except:<tab><tab>try:<tab><tab><tab>return float(string)<tab><tab>except:<tab><tab><tab>if string == ""True"":<tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>return string",1,"if string == ""False"" :","if string == ""False"" :",0.75,100.00000000000004,1.0
"def configure_create_table_epilogue(store):<tab>for val in ["""", "" ENGINE=InnoDB""]:<tab><tab>store.config[""create_table_epilogue""] = val<tab><tab>store._set_sql_flavour()<tab><tab><IF-STMT><tab><tab><tab>store.log.info(""create_table_epilogue='%s'"", val)<tab><tab><tab>return<tab>raise Exception(""Can not create a transactional table."")",0,if store . _test_transaction ( ) :,if store . _is_transactional ( ) :,0.3884893899276739,39.281465090051285,1.0
"def _check_rule(self, match, target_dict, cred_dict):<tab>""""""Recursively checks credentials based on the brains rules.""""""<tab>try:<tab><tab>new_match_list = self.rules[match]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>new_match_list = (""rule:%s"" % self.default_rule,)<tab><tab>else:<tab><tab><tab>return False<tab>return self.check(new_match_list, target_dict, cred_dict)",0,if self . default_rule and match != self . default_rule :,if self . default_rule is not None :,0.30786067365172864,29.48682411907622,0.3333333333333333
"def get_civil_names(self):<tab>congresspeople_ids = self.get_all_congresspeople_ids()<tab>for i, congress_id in enumerate(congresspeople_ids):<tab><tab>if not np.math.isnan(float(congress_id)):<tab><tab><tab>percentage = i / self.total * 100<tab><tab><tab>msg = ""Processed {} out of {} ({:.2f}%)""<tab><tab><tab>print(msg.format(i, self.total, percentage), end=""\r"")<tab><tab><tab>data = self.fetch_data_repository(congress_id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield dict(data)",0,if data is not None :,if data :,0.050438393472541504,1e-10,0.39999999999999997
"def parse_network_whitelist(self, network_whitelist_location):<tab>networks = []<tab>with open(network_whitelist_location, ""r"") as text_file:<tab><tab>for line in text_file:<tab><tab><tab>line = line.strip().strip(""'"").strip('""')<tab><tab><tab><IF-STMT><tab><tab><tab><tab>networks.append(line)<tab>return networks",0,if isIPv4 ( line ) or isIPv6 ( line ) :,"if line and not line . startswith ( ""#"" ) :",0.02690648138901562,8.130850857597444,0.2222222222222222
"def _pick(self, cum):<tab>if self._isleaf():<tab><tab>return self.bd[0], self.s<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self.left._pick(cum)<tab><tab>else:<tab><tab><tab>return self.right._pick(cum - self.left.s)",1,if cum < self . left . s :,if cum < self . left . s :,0.75,100.00000000000004,1.0
"def serialize_content_range(value):<tab>if isinstance(value, (tuple, list)):<tab><tab>if len(value) not in (2, 3):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""When setting content_range to a list/tuple, it must ""<tab><tab><tab><tab>""be length 2 or 3 (not %r)"" % value<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>begin, end = value<tab><tab><tab>length = None<tab><tab>else:<tab><tab><tab>begin, end, length = value<tab><tab>value = ContentRange(begin, end, length)<tab>value = str(value).strip()<tab>if not value:<tab><tab>return None<tab>return value",1,if len ( value ) == 2 :,if len ( value ) == 2 :,0.75,100.00000000000004,1.0
"def make_index_fields(rec):<tab>fields = {}<tab>for k, v in rec.iteritems():<tab><tab><IF-STMT><tab><tab><tab>fields[k] = v<tab><tab><tab>continue<tab><tab>if k == ""full_title"":<tab><tab><tab>fields[""title""] = [read_short_title(v)]<tab>return fields",0,"if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :","if k . startswith ( ""_"" ) :",0.031065767380381068,11.400351384481455,0.6
"def _sample_translation(reference, max_len):<tab>translation = reference[:]<tab>while np.random.uniform() < 0.8 and 1 < len(translation) < max_len:<tab><tab>trans_len = len(translation)<tab><tab>ind = np.random.randint(trans_len)<tab><tab>action = np.random.choice(actions)<tab><tab>if action == ""deletion"":<tab><tab><tab>del translation[ind]<tab><tab><IF-STMT><tab><tab><tab>ind_rep = np.random.randint(trans_len)<tab><tab><tab>translation[ind] = translation[ind_rep]<tab><tab>else:<tab><tab><tab>ind_insert = np.random.randint(trans_len)<tab><tab><tab>translation.insert(ind, translation[ind_insert])<tab>return translation",0,"elif action == ""replacement"" :","elif action == ""insert"" :",0.6428720214849399,59.4603557501361,1.0
"def __call__(self, text: str) -> str:<tab>for t in self.cleaner_types:<tab><tab>if t == ""tacotron"":<tab><tab><tab>text = tacotron_cleaner.cleaners.custom_english_cleaners(text)<tab><tab>elif t == ""jaconv"":<tab><tab><tab>text = jaconv.normalize(text)<tab><tab><IF-STMT><tab><tab><tab>if vietnamese_cleaners is None:<tab><tab><tab><tab>raise RuntimeError(""Please install underthesea"")<tab><tab><tab>text = vietnamese_cleaners.vietnamese_cleaner(text)<tab><tab>else:<tab><tab><tab>raise RuntimeError(f""Not supported: type={t}"")<tab>return text",1,"elif t == ""vietnamese"" :","elif t == ""vietnamese"" :",1.0,100.00000000000004,1.0
"def hook_GetVariable(ql, address, params):<tab>if params[""VariableName""] in ql.env:<tab><tab>var = ql.env[params[""VariableName""]]<tab><tab>read_len = read_int64(ql, params[""DataSize""])<tab><tab><IF-STMT><tab><tab><tab>write_int64(ql, params[""Attributes""], 0)<tab><tab>write_int64(ql, params[""DataSize""], len(var))<tab><tab>if read_len < len(var):<tab><tab><tab>return EFI_BUFFER_TOO_SMALL<tab><tab>if params[""Data""] != 0:<tab><tab><tab>ql.mem.write(params[""Data""], var)<tab><tab>return EFI_SUCCESS<tab>return EFI_NOT_FOUND",0,"if params [ ""Attributes"" ] != 0 :",if read_len == 0 :,0.0354018406734773,15.181939159382823,0.4772727272727273
"def test_setupapp(self, overrideRootMenu):<tab>""Call setupApp with each possible graphics type.""<tab>root = self.root<tab>flist = FileList(root)<tab>for tktype in alltypes:<tab><tab>with self.subTest(tktype=tktype):<tab><tab><tab>macosx._tk_type = tktype<tab><tab><tab>macosx.setupApp(root, flist)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertTrue(overrideRootMenu.called)<tab><tab><tab>overrideRootMenu.reset_mock()",0,"if tktype in ( ""carbon"" , ""cocoa"" ) :",if overrideRootMenu :,0.013130313781176673,1e-10,0.38461538461538464
"def names(self, persistent=None):<tab>u = set()<tab>result = []<tab>for s in [<tab><tab>self.__storage(None),<tab><tab>self.__storage(self.__category),<tab>]:<tab><tab>for b in s:<tab><tab><tab>if persistent is not None and b.persistent != persistent:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if b.name not in u:<tab><tab><tab><tab>result.append(b.name)<tab><tab><tab><tab>u.add(b.name)<tab>return result",0,"if b . name . startswith ( ""__"" ) :",if b . category != self . __category :,0.11176253032761449,15.8636093934526,0.42857142857142855
"def _check_extra_specs(key, value=None):<tab>extra_specs = diff.get(""extra_specs"")<tab>specific_type = extra_specs.get(key) if extra_specs else None<tab>old_type = None<tab>new_type = None<tab>if specific_type:<tab><tab>old_type, new_type = specific_type<tab><tab><IF-STMT><tab><tab><tab>old_type = True if old_type and old_type.upper() == value else False<tab><tab><tab>new_type = True if new_type and new_type.upper() == value else False<tab>return old_type, new_type",0,if value :,"if key == ""extra_specs"" :",0.051944022748897464,1e-10,0.5
"def _write_lock_file(self, repo, force=True):  # type: (Repository, bool) -> None<tab>if force or (self._update and self._write_lock):<tab><tab>updated_lock = self._locker.set_lock_data(self._package, repo.packages)<tab><tab><IF-STMT><tab><tab><tab>self._io.write_line("""")<tab><tab><tab>self._io.write_line(""<info>Writing lock file</>"")",1,if updated_lock :,if updated_lock :,0.5311706625951745,1e-10,1.0
"def process_message(self, msg):<tab>if msg[""type""] == ""sample"":<tab><tab>batch_shape = msg[""fn""].batch_shape<tab><tab><IF-STMT><tab><tab><tab>batch_shape = [1] * (-self.dim - len(batch_shape)) + list(batch_shape)<tab><tab><tab>batch_shape[self.dim] = self.size<tab><tab><tab>msg[""fn""] = msg[""fn""].expand(torch.Size(batch_shape))",0,if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size :,if len ( batch_shape ) > self . dim :,0.19019711096555145,18.60378303404291,0.5721966205837175
"def _test_reducibility(self):<tab># make a copy of the graph<tab>graph = networkx.DiGraph(self._graph)<tab># preprocess: make it a super graph<tab>self._make_supergraph(graph)<tab>while True:<tab><tab>changed = False<tab><tab># find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode<tab><tab>changed |= self._remove_self_loop(graph)<tab><tab># find a node that has only one predecessor, and merge it with its predecessor (replace them with a<tab><tab># MultiNode)<tab><tab>changed |= self._merge_single_entry_node(graph)<tab><tab><IF-STMT><tab><tab><tab># a fixed-point is reached<tab><tab><tab>break",0,if not changed :,if changed :,0.09648852821835877,1e-10,0.41666666666666663
"def __init__(self, roberta, num_classes=2, dropout=0.0, prefix=None, params=None):<tab>super(RoBERTaClassifier, self).__init__(prefix=prefix, params=params)<tab>self.roberta = roberta<tab>self._units = roberta._units<tab>with self.name_scope():<tab><tab>self.classifier = nn.HybridSequential(prefix=prefix)<tab><tab><IF-STMT><tab><tab><tab>self.classifier.add(nn.Dropout(rate=dropout))<tab><tab>self.classifier.add(nn.Dense(units=self._units, activation=""tanh""))<tab><tab>if dropout:<tab><tab><tab>self.classifier.add(nn.Dropout(rate=dropout))<tab><tab>self.classifier.add(nn.Dense(units=num_classes))",1,if dropout :,if dropout :,0.5311706625951745,1e-10,1.0
"def get_object_from_name(self, name, check_symlinks=True):<tab>if not name:<tab><tab>return None<tab>name = name.rstrip(""\\"")<tab>for a, o in self.objects.items():<tab><tab>if not o.name:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return o<tab>if check_symlinks:<tab><tab>m = [sl[1] for sl in self.symlinks if name.lower() == sl[0].lower()]<tab><tab>if m:<tab><tab><tab>name = m[0]<tab><tab>return self.get_object_from_name(name, False)",0,if o . name . lower ( ) == name . lower ( ) :,if o . name == name :,0.25041040587315844,19.0183794978402,0.6799999999999999
"def __call__(self):<tab>""""""Run all check_* methods.""""""<tab>if self.on:<tab><tab>oldformatwarning = warnings.formatwarning<tab><tab>warnings.formatwarning = self.formatwarning<tab><tab>try:<tab><tab><tab>for name in dir(self):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>method = getattr(self, name)<tab><tab><tab><tab><tab>if method and callable(method):<tab><tab><tab><tab><tab><tab>method()<tab><tab>finally:<tab><tab><tab>warnings.formatwarning = oldformatwarning",0,"if name . startswith ( ""check_"" ) :","if not name . startswith ( ""_"" ) :",0.20029483457781472,60.34148992419808,0.38181818181818183
"def __print__(self, defaults=False):<tab>if defaults:<tab><tab>print_func = str<tab>else:<tab><tab>print_func = repr<tab>pieces = []<tab>default_values = self.__defaults__<tab>for k in self.__fields__:<tab><tab>value = getattr(self, k)<tab><tab>if not defaults and value == default_values[k]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>print_func = repr  # keep quotes around strings<tab><tab>pieces.append(""%s=%s"" % (k, print_func(value)))<tab>if pieces or self.__base__:<tab><tab>return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces))<tab>else:<tab><tab>return """"",0,"if isinstance ( value , basestring ) :",if print_func is str :,0.01858685153282265,6.770186228657864,0.2698412698412698
"def apply(self, **kwargs: Any) -> None:<tab>for node in self.document.traverse(nodes.target):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>""ismod"" in node<tab><tab><tab>and node.parent.__class__ is nodes.section<tab><tab><tab>and<tab><tab><tab># index 0 is the section title node<tab><tab><tab>node.parent.index(node) == 1<tab><tab>):<tab><tab><tab>node.parent[""ids""][0:0] = node[""ids""]<tab><tab><tab>node.parent.remove(node)",0,"if not node [ ""ids"" ] :","if ""id"" not in node :",0.024622118794093276,7.6274380401407225,0.5714285714285714
"def add_special_token_2d(<tab>values: List[List[int]], special_token: int = 0, use_first_value: bool = False) -> List[List[int]]:<tab>results = torch.jit.annotate(List[List[int]], [])<tab>for value in values:<tab><tab>result = torch.jit.annotate(List[int], [])<tab><tab><IF-STMT><tab><tab><tab>special_token = value[0]<tab><tab>result.append(special_token)<tab><tab>result.extend(value)<tab><tab>result.append(special_token)<tab><tab>results.append(result)<tab>return results",0,if use_first_value and len ( value ) > 0 :,if use_first_value :,0.020477126045913657,1e-10,0.28571428571428575
"def test_import(self):<tab>TIMEOUT = 5<tab># Test for a deadlock when importing a module that runs the<tab># ThreadedResolver at import-time. See resolve_test.py for<tab># full explanation.<tab>command = [sys.executable, ""-c"", ""import tornado.test.resolve_test_helper""]<tab>start = time.time()<tab>popen = Popen(command, preexec_fn=lambda: signal.alarm(TIMEOUT))<tab>while time.time() - start < TIMEOUT:<tab><tab>return_code = popen.poll()<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(0, return_code)<tab><tab><tab>return  # Success.<tab><tab>time.sleep(0.05)<tab>self.fail(""import timed out"")",0,if return_code is not None :,if return_code != 0 :,0.051719732411378776,36.55552228545123,0.27777777777777773
"def find_item_for_key(self, e):<tab>for item in self._items:<tab><tab>if item.keycode == e.key and item.shift == e.shift and item.alt == e.alt:<tab><tab><tab>focus = get_focus()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self._items.index(item)<tab><tab><tab>else:<tab><tab><tab><tab>return -1<tab>return -1",0,"if self . command_is_enabled ( item , focus ) :",if focus == e . focus :,0.01576559450383198,3.689111847432509,0.4444444444444444
"def check_app_config_brackets(self):<tab>for sn, app in cherrypy.tree.apps.items():<tab><tab>if not isinstance(app, cherrypy.Application):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for key in app.config.keys():<tab><tab><tab>if key.startswith(""["") or key.endswith(""]""):<tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab>""The application mounted at %r has config ""<tab><tab><tab><tab><tab>""section names with extraneous brackets: %r. ""<tab><tab><tab><tab><tab>""Config *files* need brackets; config *dicts* ""<tab><tab><tab><tab><tab>""(e.g. passed to tree.mount) do not."" % (sn, key)<tab><tab><tab><tab>)",0,if not app . config :,"if not isinstance ( app , cherrypy . Application ) :",0.12353182811518904,9.425159511373677,0.3541666666666667
"def got_arbiter_module_type_defined(self, mod_type):<tab>for a in self.arbiters:<tab><tab># Do like the linkify will do after....<tab><tab>for m in getattr(a, ""modules"", []):<tab><tab><tab># So look at what the arbiter try to call as module<tab><tab><tab>m = m.strip()<tab><tab><tab># Ok, now look in modules...<tab><tab><tab>for mod in self.modules:<tab><tab><tab><tab># try to see if this module is the good type<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># if so, the good name?<tab><tab><tab><tab><tab>if getattr(mod, ""module_name"", """").strip() == m:<tab><tab><tab><tab><tab><tab>return True<tab>return False",0,"if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",if mod . type == mod_type :,0.010861990311347372,7.721738836455175,0.3229166666666667
"def write_config_to_file(self, folder, filename, config):<tab>do_not_write = [""hyperparameter_search_space_updates""]<tab>with open(os.path.join(folder, filename), ""w"") as f:<tab><tab>f.write(<tab><tab><tab>""\n"".join(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>(key + ""="" + str(value))<tab><tab><tab><tab><tab>for (key, value) in sorted(config.items(), key=lambda x: x[0])<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>)",0,if not key in do_not_write,if key not in do_not_write,0.32143601074246997,65.00593260343696,0.6
"def parsing(self, parsing):  # type: (bool) -> None<tab>self._parsed = parsing<tab>for k, v in self._body:<tab><tab><IF-STMT><tab><tab><tab>v.value.parsing(parsing)<tab><tab>elif isinstance(v, AoT):<tab><tab><tab>for t in v.body:<tab><tab><tab><tab>t.value.parsing(parsing)",0,"if isinstance ( v , Table ) :","if isinstance ( v , AoT ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def test_crashers_crash(self):<tab>for fname in glob.glob(CRASHER_FILES):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Some ""crashers"" only trigger an exception rather than a<tab><tab># segfault. Consider that an acceptable outcome.<tab><tab>if test.support.verbose:<tab><tab><tab>print(""Checking crasher:"", fname)<tab><tab>assert_python_failure(fname)",0,if os . path . basename ( fname ) in infinite_loops :,if not os . path . isfile ( fname ) :,0.16575639904477457,27.507948153265307,0.2222222222222222
"def __getitem__(self, k) -> ""SimMemView"":<tab>if isinstance(k, slice):<tab><tab>if k.step is not None:<tab><tab><tab>raise ValueError(""Slices with strides are not supported"")<tab><tab>elif k.start is None:<tab><tab><tab>raise ValueError(""Must specify start index"")<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Slices with stop index are not supported"")<tab><tab>else:<tab><tab><tab>addr = k.start<tab>elif self._type is not None and self._type._can_refine_int:<tab><tab>return self._type._refine(self, k)<tab>else:<tab><tab>addr = k<tab>return self._deeper(addr=addr)",1,elif k . stop is not None :,elif k . stop is not None :,0.75,100.00000000000004,1.0
"def get_lowest_wall_time(jsons):<tab>lowest_wall = None<tab>for j in jsons:<tab><tab><IF-STMT><tab><tab><tab>lowest_wall = j[""wall_time""]<tab><tab>if lowest_wall > j[""wall_time""]:<tab><tab><tab>lowest_wall = j[""wall_time""]<tab>return lowest_wall",1,if lowest_wall is None :,if lowest_wall is None :,0.75,100.00000000000004,1.0
"def extract_wav_headers(data):<tab># def search_subchunk(data, subchunk_id):<tab>pos = 12  # The size of the RIFF chunk descriptor<tab>subchunks = []<tab>while pos + 8 <= len(data) and len(subchunks) < 10:<tab><tab>subchunk_id = data[pos : pos + 4]<tab><tab>subchunk_size = struct.unpack_from(""<I"", data[pos + 4 : pos + 8])[0]<tab><tab>subchunks.append(WavSubChunk(subchunk_id, pos, subchunk_size))<tab><tab><IF-STMT><tab><tab><tab># 'data' is the last subchunk<tab><tab><tab>break<tab><tab>pos += subchunk_size + 8<tab>return subchunks",0,"if subchunk_id == b""data"" :",if subchunk_id == 0 :,0.14477865547525276,48.59869096699083,0.6190476190476191
"def _any_targets_have_native_sources(self, targets):<tab># TODO(#5949): convert this to checking if the closure of python requirements has any<tab># platform-specific packages (maybe find the platforms there too?).<tab>for tgt in targets:<tab><tab>for type_constraint, target_predicate in self._native_target_matchers.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,"if target_predicate ( tgt , type_constraint , tgt ) :",0.32091582156819976,31.28248941987991,0.6118421052631579
"def validate_memory(self, value):<tab>for k, v in value.viewitems():<tab><tab>if v is None:  # use NoneType to unset a value<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise serializers.ValidationError(""Process types can only contain [a-z]"")<tab><tab>if not re.match(MEMLIMIT_MATCH, str(v)):<tab><tab><tab>raise serializers.ValidationError(<tab><tab><tab><tab>""Limit format: <number><unit>, where unit = B, K, M or G""<tab><tab><tab>)<tab>return value",0,"if not re . match ( PROCTYPE_MATCH , k ) :","if k . startswith ( ""_"" ) :",0.02707344218606997,8.503662878579146,0.2653061224489796
"def cart_number_checksum_validation(cls, number):<tab>digits = []<tab>even = False<tab>if not number.isdigit():<tab><tab>return False<tab>for digit in reversed(number):<tab><tab>digit = ord(digit) - ord(""0"")<tab><tab>if even:<tab><tab><tab>digit *= 2<tab><tab><tab><IF-STMT><tab><tab><tab><tab>digit = digit % 10 + digit // 10<tab><tab>digits.append(digit)<tab><tab>even = not even<tab>return sum(digits) % 10 == 0 if digits else False",0,if digit >= 10 :,if digit % 10 == 0 :,0.13878247493843046,13.888095170058955,0.7714285714285715
"def transform(a, cmds):<tab>buf = a.split(""\n"")<tab>for cmd in cmds:<tab><tab>ctype, line, col, char = cmd<tab><tab>if ctype == ""D"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>buf[line] = buf[line][:col] + buf[line][col + len(char) :]<tab><tab><tab>else:<tab><tab><tab><tab>buf[line] = buf[line] + buf[line + 1]<tab><tab><tab><tab>del buf[line + 1]<tab><tab>elif ctype == ""I"":<tab><tab><tab>buf[line] = buf[line][:col] + char + buf[line][col:]<tab><tab>buf = ""\n"".join(buf).split(""\n"")<tab>return ""\n"".join(buf)",0,"if char != ""\n"" :",if line + 1 == len ( buf ) :,0.022830036038523988,4.9323515694897075,0.25274725274725274
"def get_partners(self) -> Dict[AbstractNode, Set[int]]:<tab>partners = {}  # type: Dict[AbstractNode, Set[int]]<tab>for edge in self.edges:<tab><tab>if edge.is_dangling():<tab><tab><tab>raise ValueError(""Cannot contract copy tensor with dangling edges"")<tab><tab>if self._is_my_trace(edge):<tab><tab><tab>continue<tab><tab>partner_node, shared_axis = self._get_partner(edge)<tab><tab><IF-STMT><tab><tab><tab>partners[partner_node] = set()<tab><tab>partners[partner_node].add(shared_axis)<tab>return partners",1,if partner_node not in partners :,if partner_node not in partners :,0.75,100.00000000000004,1.0
"def _bind_interactive_rez(self):<tab>if config.set_prompt and self.settings.prompt:<tab><tab>stored_prompt = os.getenv(""REZ_STORED_PROMPT_CMD"")<tab><tab>curr_prompt = stored_prompt or os.getenv(""PROMPT"", """")<tab><tab><IF-STMT><tab><tab><tab>self.setenv(""REZ_STORED_PROMPT_CMD"", curr_prompt)<tab><tab>new_prompt = ""%%REZ_ENV_PROMPT%%""<tab><tab>new_prompt = (<tab><tab><tab>(new_prompt + "" %s"") if config.prefix_prompt else (""%s "" + new_prompt)<tab><tab>)<tab><tab>new_prompt = new_prompt % curr_prompt<tab><tab>self._addline(""set PROMPT=%s"" % new_prompt)",0,if not stored_prompt :,if curr_prompt :,0.05063871203029889,1e-10,0.6
"def __listingColumns(self):<tab>columns = []<tab>for name in self.__getColumns():<tab><tab>definition = column(name)<tab><tab>if not definition:<tab><tab><tab>IECore.msg(<tab><tab><tab><tab>IECore.Msg.Level.Error,<tab><tab><tab><tab>""GafferImageUI.CatalogueUI"",<tab><tab><tab><tab>""No column registered with name '%s'"" % name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name)<tab><tab>else:<tab><tab><tab>c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name)<tab><tab>columns.append(c)<tab>return columns",0,"if isinstance ( definition , IconColumn ) :","if definition == ""icon"" :",0.019907917998500824,7.267884212102741,0.36
"def _check_invalid_keys(self, section_name, section):<tab>for key in section:<tab><tab>key_name = str(key)<tab><tab>valid_key_names = [s[0] for s in self.keys]<tab><tab>is_valid_key = key_name in valid_key_names<tab><tab><IF-STMT><tab><tab><tab>err_msg = (<tab><tab><tab><tab>""'{0}' is not a valid key name for '{1}'. Must "" ""be one of these: {2}""<tab><tab><tab>).format(key_name, section_name, "", "".join(valid_key_names))<tab><tab><tab>raise InvalidConfig(err_msg)",1,if not is_valid_key :,if not is_valid_key :,0.75,100.00000000000004,1.0
"def _get_startup_packages(lib_path: Path, packages) -> Set[str]:<tab>names = set()<tab>for path in lib_path.iterdir():<tab><tab>name = path.name<tab><tab>if name == ""__pycache__"":<tab><tab><tab>continue<tab><tab>if name.endswith("".py""):<tab><tab><tab>names.add(name.split(""."")[0])<tab><tab><IF-STMT><tab><tab><tab>names.add(name)<tab>if packages:<tab><tab>packages = {package.lower().replace(""-"", ""_"") for package in packages}<tab><tab>if len(names & packages) == len(packages):<tab><tab><tab>return packages<tab>return names",0,"elif path . is_dir ( ) and ""."" not in name :","elif name . endswith ( "".py"" ) :",0.1243674937466595,6.9294737277368,0.225
"def sortkeypicker(keynames):<tab>negate = set()<tab>for i, k in enumerate(keynames):<tab><tab><IF-STMT><tab><tab><tab>keynames[i] = k[1:]<tab><tab><tab>negate.add(k[1:])<tab>def getit(adict):<tab><tab>composite = [adict[k] for k in keynames]<tab><tab>for i, (k, v) in enumerate(zip(keynames, composite)):<tab><tab><tab>if k in negate:<tab><tab><tab><tab>composite[i] = -v<tab><tab>return composite<tab>return getit",0,"if k [ : 1 ] == ""-"" :","if k [ 0 ] == ""-"" :",0.22052701951210865,64.07117598241614,0.6
"def iter_symbols(code):<tab>""""""Yield names and strings used by `code` and its nested code objects""""""<tab>for name in code.co_names:<tab><tab>yield name<tab>for const in code.co_consts:<tab><tab>if isinstance(const, six.string_types):<tab><tab><tab>yield const<tab><tab><IF-STMT><tab><tab><tab>for name in iter_symbols(const):<tab><tab><tab><tab>yield name",0,"elif isinstance ( const , CodeType ) :","elif isinstance ( const , ( list , tuple ) ) :",0.3415469384700779,36.462858619364674,0.5619047619047619
"def set_study_directions(<tab>self, study_id: int, directions: Sequence[StudyDirection]) -> None:<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>current_directions = self._studies[study_id].directions<tab><tab><tab>if directions == current_directions:<tab><tab><tab><tab>return<tab><tab><tab>elif (<tab><tab><tab><tab>len(current_directions) == 1<tab><tab><tab><tab>and current_directions[0] == StudyDirection.NOT_SET<tab><tab><tab>):<tab><tab><tab><tab>self._studies[study_id].directions = list(directions)<tab><tab><tab><tab>self._backend.set_study_directions(study_id, directions)<tab><tab><tab><tab>return<tab>self._backend.set_study_directions(study_id, directions)",1,if study_id in self . _studies :,if study_id in self . _studies :,0.75,100.00000000000004,1.0
"def PreprocessConditionalStatement(self, IfList, ReplacedLine):<tab>while self:<tab><tab><IF-STMT><tab><tab><tab>x = 1<tab><tab>elif not IfList:<tab><tab><tab>if self <= 2:<tab><tab><tab><tab>continue<tab><tab><tab>RegionSizeGuid = 3<tab><tab><tab>if not RegionSizeGuid:<tab><tab><tab><tab>RegionLayoutLine = 5<tab><tab><tab><tab>continue<tab><tab><tab>RegionLayoutLine = self.CurrentLineNumber<tab>return 1",0,if self . __Token :,if IfList [ 0 ] == IfList [ 1 ] :,0.0237537216033675,4.02724819242185,0.3
"def _check_blocking(self, current_time):<tab>if self._switch_flag is False:<tab><tab>active_greenlet = self._active_greenlet<tab><tab><IF-STMT><tab><tab><tab>self._notify_greenlet_blocked(active_greenlet, current_time)<tab>self._switch_flag = False",0,if active_greenlet is not None and active_greenlet != self . _hub :,if active_greenlet is not None :,0.3394233587821028,24.909923021496894,0.6938775510204083
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(r""BlockDos\.net"", headers.get(HTTP_HEADER.SERVER, """"), re.I)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.5311706625951745,1e-10,1.0
"def _fastqc_data_section(self, section_name):<tab>out = []<tab>in_section = False<tab>data_file = os.path.join(self._dir, ""fastqc_data.txt"")<tab>if os.path.exists(data_file):<tab><tab>with open(data_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>in_section = True<tab><tab><tab><tab>elif in_section:<tab><tab><tab><tab><tab>if line.startswith("">>END""):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>out.append(line.rstrip(""\r\n""))<tab>return out",0,"if line . startswith ( "">>%s"" % section_name ) :",if line . startswith ( section_name ) :,0.2682544298578143,39.01319655022955,1.0
"def shortcut(self, input, ch_out, stride, is_first, name):<tab>ch_in = input.shape[1]<tab>if ch_in != ch_out or stride != 1:<tab><tab><IF-STMT><tab><tab><tab>return self.conv_bn_layer(input, ch_out, 1, stride, name=name)<tab><tab>else:<tab><tab><tab>return self.conv_bn_layer_new(input, ch_out, 1, stride, name=name)<tab>elif is_first:<tab><tab>return self.conv_bn_layer(input, ch_out, 1, stride, name=name)<tab>else:<tab><tab>return input",0,if is_first or stride == 1 :,if is_first :,0.03885753308224148,1e-10,0.3333333333333333
"def get_value_from_string(self, string_value):<tab>""""""Return internal representation starting from CFN/user-input value.""""""<tab>param_value = self.get_default_value()<tab>try:<tab><tab>if string_value is not None:<tab><tab><tab>string_value = str(string_value).strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>param_value = int(string_value)<tab>except ValueError:<tab><tab>self.pcluster_config.warn(<tab><tab><tab>""Unable to convert the value '{0}' to an Integer. ""<tab><tab><tab>""Using default value for parameter '{1}'"".format(string_value, self.key)<tab><tab>)<tab>return param_value",0,"if string_value != ""NONE"" :",if string_value . isdigit ( ) :,0.05286931595839166,28.24099048856542,0.6363636363636364
"def get_running(workers):<tab>running = []<tab>for worker in workers:<tab><tab>current_test_name = worker.current_test_name<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dt = time.monotonic() - worker.start_time<tab><tab>if dt >= PROGRESS_MIN_TIME:<tab><tab><tab>text = ""%s (%s)"" % (current_test_name, format_duration(dt))<tab><tab><tab>running.append(text)<tab>return running",1,if not current_test_name :,if not current_test_name :,0.75,100.00000000000004,1.0
"def generate_data(self, request):<tab>""""""Generate data for the widget.""""""<tab>uptime = {}<tab>cache_stats = get_cache_stats()<tab>if cache_stats:<tab><tab>for hosts, stats in cache_stats:<tab><tab><tab>if stats[""uptime""] > 86400:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60 / 24<tab><tab><tab><tab>uptime[""unit""] = _(""days"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60 / 60<tab><tab><tab><tab>uptime[""unit""] = _(""hours"")<tab><tab><tab>else:<tab><tab><tab><tab>uptime[""value""] = stats[""uptime""] / 60<tab><tab><tab><tab>uptime[""unit""] = _(""minutes"")<tab>return {""cache_stats"": cache_stats, ""uptime"": uptime}",1,"elif stats [ ""uptime"" ] > 3600 :","elif stats [ ""uptime"" ] > 3600 :",0.75,100.00000000000004,1.0
"def add_actors(self):<tab>""""""Adds `self.actors` to the scene.""""""<tab>if not self._actors_added:<tab><tab>self.reader.render_window = self.scene.render_window<tab><tab>self._update_reader()<tab><tab>self._actors_added = True<tab><tab><IF-STMT><tab><tab><tab>self._visible_changed(self.visible)<tab><tab>self.scene.render()",0,if not self . visible :,if self . visible is not None :,0.10094060174500757,24.446151121745064,0.23809523809523808
"def _add_uniqu_suffix(self, titles):<tab>counters = dict()<tab>titles_with_suffix = []<tab>for title in titles:<tab><tab>counters[title] = counters[title] + 1 if title in counters else 1<tab><tab><IF-STMT><tab><tab><tab>title = f""{title} ({counters[title]})""<tab><tab>titles_with_suffix.append(title)<tab>return titles_with_suffix",0,if counters [ title ] > 1 :,if title in counters :,0.020977836961063236,8.290829875388036,0.3333333333333333
"def _verify_udf_resources(self, job, config):<tab>udf_resources = config.get(""userDefinedFunctionResources"", ())<tab>self.assertEqual(len(job.udf_resources), len(udf_resources))<tab>for found, expected in zip(job.udf_resources, udf_resources):<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(found.udf_type, ""resourceUri"")<tab><tab><tab>self.assertEqual(found.value, expected[""resourceUri""])<tab><tab>else:<tab><tab><tab>self.assertEqual(found.udf_type, ""inlineCode"")<tab><tab><tab>self.assertEqual(found.value, expected[""inlineCode""])",0,"if ""resourceUri"" in expected :","if config . get ( ""udf_strict"" , False ) :",0.02442414353888167,4.016138436407654,0.27472527472527475
"def __init__(<tab>self, layout, value=None, string=None, *, dtype: np.dtype = np.float64) -> None:<tab>""""""Constructor.""""""<tab>self.layout = layout<tab>if value is None:<tab><tab><IF-STMT><tab><tab><tab>self.value = np.zeros((self.layout.gaDims,), dtype=dtype)<tab><tab>else:<tab><tab><tab>self.value = layout.parse_multivector(string).value<tab>else:<tab><tab>self.value = np.array(value)<tab><tab>if self.value.shape != (self.layout.gaDims,):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""value must be a sequence of length %s"" % self.layout.gaDims<tab><tab><tab>)",1,if string is None :,if string is None :,0.75,100.00000000000004,1.0
"def read_file(filename, print_error=True):<tab>""""""Returns the contents of a file.""""""<tab>try:<tab><tab>for encoding in [""utf-8"", ""latin1""]:<tab><tab><tab>try:<tab><tab><tab><tab>with io.open(filename, encoding=encoding) as fp:<tab><tab><tab><tab><tab>return fp.read()<tab><tab><tab>except UnicodeDecodeError:<tab><tab><tab><tab>pass<tab>except IOError as exception:<tab><tab><IF-STMT><tab><tab><tab>print(exception, file=sys.stderr)<tab><tab>return None",1,if print_error :,if print_error :,0.5311706625951745,1e-10,1.0
"def get_albums_for_iter(self, iter_):<tab>obj = self.get_value(iter_)<tab>if isinstance(obj, AlbumNode):<tab><tab>return {obj.album}<tab>albums = set()<tab>for child_iter, value in self.iterrows(iter_):<tab><tab><IF-STMT><tab><tab><tab>albums.add(value.album)<tab><tab>else:<tab><tab><tab>albums.update(self.get_albums_for_iter(child_iter))<tab>return albums",1,"if isinstance ( value , AlbumNode ) :","if isinstance ( value , AlbumNode ) :",0.75,100.00000000000004,1.0
"def wait_til_ready(cls, connector=None):<tab>if connector is None:<tab><tab>connector = cls.connector<tab>while True:<tab><tab>now = time.time()<tab><tab>next_iteration = now // 1.0 + 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>await cls._clock.run_til(next_iteration)<tab><tab>await asyncio.sleep(1.0)",0,if connector . ready :,if cls . connector == connector :,0.031181343770877636,7.809849842300637,0.37142857142857144
"def remove_property(self, key):  # type: (str) -> None<tab>with self.secure() as config:<tab><tab>keys = key.split(""."")<tab><tab>current_config = config<tab><tab>for i, key in enumerate(keys):<tab><tab><tab>if key not in current_config:<tab><tab><tab><tab>return<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del current_config[key]<tab><tab><tab><tab>break<tab><tab><tab>current_config = current_config[key]",1,if i == len ( keys ) - 1 :,if i == len ( keys ) - 1 :,0.75,100.00000000000004,1.0
"def get(self, hash160, default=None):<tab>v = self.p2s_for_hash(hash160)<tab><IF-STMT><tab><tab>return v<tab>if hash160 not in self._secret_exponent_cache:<tab><tab>v = self.path_for_hash160(hash160)<tab><tab>if v:<tab><tab><tab>fingerprint, path = v<tab><tab><tab>for key in self._secrets.get(fingerprint, []):<tab><tab><tab><tab>subkey = key.subkey_for_path(path)<tab><tab><tab><tab>self._add_key_to_cache(subkey)<tab>return self._secret_exponent_cache.get(hash160, default)",1,if v :,if v :,0.5311706625951745,1e-10,1.0
"def fetch_all(self, api_client, fetchstatuslogger, q, targets):<tab>self.fetchstatuslogger = fetchstatuslogger<tab>if targets != None:<tab><tab># Ensure targets is a tuple<tab><tab><IF-STMT><tab><tab><tab>targets = tuple(<tab><tab><tab><tab>targets,<tab><tab><tab>)<tab><tab>elif type(targets) != tuple:<tab><tab><tab>targets = tuple(targets)<tab>for target in targets:<tab><tab>self._fetch_targets(api_client, q, target)",0,if type ( targets ) != list and type ( targets ) != tuple :,"if isinstance ( targets , tuple ) :",0.017906483884352176,4.719073083867901,0.3055555555555556
"def dgl_mp_batchify_fn(data):<tab>if isinstance(data[0], tuple):<tab><tab>data = zip(*data)<tab><tab>return [dgl_mp_batchify_fn(i) for i in data]<tab>for dt in data:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(dt, dgl.DGLGraph):<tab><tab><tab><tab>return [d for d in data if isinstance(d, dgl.DGLGraph)]<tab><tab><tab>elif isinstance(dt, nd.NDArray):<tab><tab><tab><tab>pad = Pad(axis=(1, 2), num_shards=1, ret_length=False)<tab><tab><tab><tab>data_list = [dt for dt in data if dt is not None]<tab><tab><tab><tab>return pad(data_list)",1,if dt is not None :,if dt is not None :,0.75,100.00000000000004,1.0
"def capture_server(evt, buf, serv):<tab>try:<tab><tab>serv.listen(5)<tab><tab>conn, addr = serv.accept()<tab>except socket.timeout:<tab><tab>pass<tab>else:<tab><tab>n = 200<tab><tab>while n > 0:<tab><tab><tab>r, w, e = select.select([conn], [], [])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = conn.recv(10)<tab><tab><tab><tab># keep everything except for the newline terminator<tab><tab><tab><tab>buf.write(data.replace(""\n"", """"))<tab><tab><tab><tab>if ""\n"" in data:<tab><tab><tab><tab><tab>break<tab><tab><tab>n -= 1<tab><tab><tab>time.sleep(0.01)<tab><tab>conn.close()<tab>finally:<tab><tab>serv.close()<tab><tab>evt.set()",1,if r :,if r :,0.5311706625951745,1e-10,1.0
"def elem():<tab>if ints_only:<tab><tab>return random.randint(0, 10000000000)<tab>else:<tab><tab>t = random.randint(0, 2)<tab><tab>if t == 0:<tab><tab><tab>return random.randint(0, 10000000000)<tab><tab>elif t == 1:<tab><tab><tab>return float(random.randint(0, 10000000000))<tab><tab><IF-STMT><tab><tab><tab>return strings[random.randint(0, len(strings) - 1)]<tab><tab>return random_string(random.randint(100, 1000))",0,elif strings is not None :,elif t == 2 :,0.02521535351552144,9.652434877402245,0.1875
"def has_changed(self, initial, data):<tab>if self.disabled:<tab><tab>return False<tab>if initial is None:<tab><tab>initial = ["""" for x in range(0, len(data))]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>initial = self.widget.decompress(initial)<tab>for field, initial, data in zip(self.fields, initial, data):<tab><tab>try:<tab><tab><tab>initial = field.to_python(initial)<tab><tab>except ValidationError:<tab><tab><tab>return True<tab><tab>if field.has_changed(initial, data):<tab><tab><tab>return True<tab>return False",0,"if not isinstance ( initial , list ) :",if self . widget . decompress :,0.015938469653148324,5.868924818816531,0.20987654320987653
"def _load_testfile(filename, package, module_relative):<tab>if module_relative:<tab><tab>package = _normalize_module(package, 3)<tab><tab>filename = _module_relative_path(package, filename)<tab><tab><IF-STMT><tab><tab><tab>if hasattr(package.__loader__, ""get_data""):<tab><tab><tab><tab>file_contents = package.__loader__.get_data(filename)<tab><tab><tab><tab># get_data() opens files as 'rb', so one must do the equivalent<tab><tab><tab><tab># conversion as universal newlines would do.<tab><tab><tab><tab>return file_contents.replace(os.linesep, ""\n""), filename<tab>return open(filename).read(), filename",1,"if hasattr ( package , ""__loader__"" ) :","if hasattr ( package , ""__loader__"" ) :",0.75,100.00000000000004,1.0
"def release(self):<tab>tid = _thread.get_ident()<tab>with self.lock:<tab><tab>if self.owner != tid:<tab><tab><tab>raise RuntimeError(""cannot release un-acquired lock"")<tab><tab>assert self.count > 0<tab><tab>self.count -= 1<tab><tab>if self.count == 0:<tab><tab><tab>self.owner = None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.waiters -= 1<tab><tab><tab><tab>self.wakeup.release()",0,if self . waiters :,if self . waiters > 0 :,0.28545691328288475,43.47208719449914,0.7714285714285715
"def stage(<tab>self, x, num_modules, num_blocks, channels, multi_scale_output=True, name=None):<tab>out = x<tab>for i in range(num_modules):<tab><tab><IF-STMT><tab><tab><tab>out = self.high_resolution_module(<tab><tab><tab><tab>out,<tab><tab><tab><tab>num_blocks,<tab><tab><tab><tab>channels,<tab><tab><tab><tab>multi_scale_output=False,<tab><tab><tab><tab>name=name + ""_"" + str(i + 1),<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>out = self.high_resolution_module(<tab><tab><tab><tab>out, num_blocks, channels, name=name + ""_"" + str(i + 1)<tab><tab><tab>)<tab>return out",0,if i == num_modules - 1 and multi_scale_output == False :,if multi_scale_output :,0.009691017295795235,1e-10,0.2916666666666667
"def changeFrontAlteration(intV, alter):<tab># fati = front alteration transpose interval<tab>fati = self.frontAlterationTransposeInterval<tab>if fati:<tab><tab>newFati = interval.add([fati, intV])<tab><tab>self.frontAlterationTransposeInterval = newFati<tab><tab>self.frontAlterationAccidental.alter = (<tab><tab><tab>self.frontAlterationAccidental.alter + alter<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.frontAlterationTransposeInterval = None<tab><tab><tab>self.frontAlterationAccidental = None<tab>else:<tab><tab>self.frontAlterationTransposeInterval = intV<tab><tab>self.frontAlterationAccidental = pitch.Accidental(alter)",0,if self . frontAlterationAccidental . alter == 0 :,if self . frontAlterationTransposeInterval > intV :,0.11758931074158556,17.112717058426785,0.3611111111111111
"def set_to_train(self):<tab>for T in self.trainable_attributes():<tab><tab>for k, v in T.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c_f.set_requires_grad(v, requires_grad=False)<tab><tab><tab><tab>v.eval()<tab><tab><tab>else:<tab><tab><tab><tab>v.train()<tab>self.maybe_freeze_trunk_batchnorm()",0,if k in self . freeze_these :,"if isinstance ( v , torch . Tensor ) :",0.018941002751756135,5.522397783539471,0.21212121212121213
"def _migrate(self, sig=None, compact=True):<tab>with self.lock:<tab><tab>sig = sig or self.sig<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if sig in self.WORDS and len(self.WORDS[sig]) > 0:<tab><tab><tab>PostingList.Append(<tab><tab><tab><tab>self.session, sig, self.WORDS[sig], sig=sig, compact=compact<tab><tab><tab>)<tab><tab><tab>del self.WORDS[sig]",0,if sig in GPL_NEVER_MIGRATE :,if sig is None :,0.31497877230811644,10.62372743739878,0.4444444444444444
"def on_prediction_step(self, args, state, control, eval_dataloader=None, **kwargs):<tab>if self.prediction_bar is None:<tab><tab><IF-STMT><tab><tab><tab>self.prediction_bar = self.training_tracker.add_child(len(eval_dataloader))<tab><tab>else:<tab><tab><tab>self.prediction_bar = NotebookProgressBar(len(eval_dataloader))<tab><tab>self.prediction_bar.update(1)<tab>else:<tab><tab>self.prediction_bar.update(self.prediction_bar.value + 1)",1,if self . training_tracker is not None :,if self . training_tracker is not None :,0.75,100.00000000000004,1.0
"def show(self, indent=0):<tab>""""""Pretty print this structure.""""""<tab>if indent == 0:<tab><tab>print(""struct {}"".format(self.name))<tab>for field in self.fields:<tab><tab>if field.offset is None:<tab><tab><tab>offset = ""0x??""<tab><tab>else:<tab><tab><tab>offset = ""0x{:02x}"".format(field.offset)<tab><tab>print(""{}+{} {} {}"".format("" "" * indent, offset, field.name, field.type))<tab><tab><IF-STMT><tab><tab><tab>field.type.show(indent + 1)",0,"if isinstance ( field . type , Structure ) :",if field . type is not None :,0.062006595483074536,18.190371142855746,0.20987654320987653
"def __exit__(self, exc, value, tb):<tab>for key in self.overrides.keys():<tab><tab>old_value = self.old[key]<tab><tab><IF-STMT><tab><tab><tab>delattr(self.instance, key)<tab><tab>else:<tab><tab><tab>setattr(self.instance, key, old_value)<tab>self.instance.save()",0,if old_value is NULL :,if old_value is None :,0.39477865547525276,64.34588841607616,0.6
"def complete(self, block):<tab>with self._condition:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if self._complete():<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab>if block:<tab><tab><tab>self._condition.wait_for(self._complete)<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab>return False",0,if not self . _final :,if block :,0.1098188354096215,1e-10,0.37142857142857144
"def parseArguments(self):<tab>args = []<tab>self.expect(""("")<tab>if not self.match("")""):<tab><tab>while self.startIndex < self.length:<tab><tab><tab>args.append(self.isolateCoverGrammar(self.parseAssignmentExpression))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.expectCommaSeparator()<tab>self.expect("")"")<tab>return args",0,"if self . match ( "")"" ) :",if self . startIndex >= self . length :,0.07156798309941814,16.784459625186194,0.41111111111111115
"def isValidDateString(config_param_name, value, valid_value):<tab>try:<tab><tab>if value == ""DD-MM-YYYY"":<tab><tab><tab>return value<tab><tab>day, month, year = value.split(""-"")<tab><tab><IF-STMT><tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(month) < 1 or int(month) > 12:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(year) < 1900 or int(year) > 2013:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>return value<tab>except Exception:<tab><tab>raise DateStringValueError(config_param_name, value)",0,if int ( day ) < 1 or int ( day ) > 31 :,if int ( day ) < 1 or int ( day ) > 12 :,0.9350202139173193,86.66415730847507,0.75
"def build_tree(path):<tab>tree = Tree()<tab>for basename, entry in trees[path].items():<tab><tab><IF-STMT><tab><tab><tab>mode = stat.S_IFDIR<tab><tab><tab>sha = build_tree(pathjoin(path, basename))<tab><tab>else:<tab><tab><tab>(mode, sha) = entry<tab><tab>tree.add(basename, mode, sha)<tab>object_store.add_object(tree)<tab>return tree.id",0,"if isinstance ( entry , dict ) :","if basename . endswith ( "".py"" ) :",0.03622895148520873,8.913765521398126,0.2698412698412698
"def get_quarantine_count(self):<tab>""""""get obj/container/account quarantine counts""""""<tab>qcounts = {""objects"": 0, ""containers"": 0, ""accounts"": 0}<tab>qdir = ""quarantined""<tab>for device in os.listdir(self.devices):<tab><tab>for qtype in qcounts:<tab><tab><tab>qtgt = os.path.join(self.devices, device, qdir, qtype)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>linkcount = os.lstat(qtgt).st_nlink<tab><tab><tab><tab>if linkcount > 2:<tab><tab><tab><tab><tab>qcounts[qtype] += linkcount - 2<tab>return qcounts",1,if os . path . exists ( qtgt ) :,if os . path . exists ( qtgt ) :,0.75,100.00000000000004,1.0
"def _is_static_shape(self, shape):<tab>if shape is None or not isinstance(shape, list):<tab><tab>return False<tab>for dim_value in shape:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if dim_value < 0:<tab><tab><tab>raise Exception(""Negative dimension is illegal: %d"" % dim_value)<tab>return True",0,"if not isinstance ( dim_value , int ) :",if dim_value is None :,0.016261061222697736,15.685718045401451,0.27272727272727276
"def BraceDetectAll(words):<tab># type: (List[compound_word]) -> List[word_t]<tab>""""""Return a new list of words, possibly with BracedTree instances.""""""<tab>out = []  # type: List[word_t]<tab>for w in words:<tab><tab># The shortest possible brace expansion is {,}.  This heuristic prevents<tab><tab># a lot of garbage from being created, since otherwise nearly every word<tab><tab># would be checked.  We could be even more precise but this is cheap.<tab><tab>if len(w.parts) >= 3:<tab><tab><tab>brace_tree = _BraceDetect(w)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out.append(brace_tree)<tab><tab><tab><tab>continue<tab><tab>out.append(w)<tab>return out",0,if brace_tree :,if brace_tree is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def __init__(original, self, *args, **kwargs):<tab>data = args[0] if len(args) > 0 else kwargs.get(""data"")<tab>if data is not None:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>""cannot gather example input when dataset is loaded from a file.""<tab><tab><tab><tab>)<tab><tab><tab>input_example_info = _InputExampleInfo(<tab><tab><tab><tab>input_example=deepcopy(data[:INPUT_EXAMPLE_SAMPLE_ROWS])<tab><tab><tab>)<tab><tab>except Exception as e:<tab><tab><tab>input_example_info = _InputExampleInfo(error_msg=str(e))<tab><tab>setattr(self, ""input_example_info"", input_example_info)<tab>original(self, *args, **kwargs)",0,"if isinstance ( data , str ) :",if len ( data ) < INPUT_EXAMPLE_SAMPLE_ROWS :,0.03779162928217515,7.141816289329644,0.48148148148148145
"def setRow(self, row, vals):<tab>if row > self.rowCount() - 1:<tab><tab>self.setRowCount(row + 1)<tab>for col in range(len(vals)):<tab><tab>val = vals[col]<tab><tab>item = self.itemClass(val, row)<tab><tab>item.setEditable(self.editable)<tab><tab>sortMode = self.sortModes.get(col, None)<tab><tab><IF-STMT><tab><tab><tab>item.setSortMode(sortMode)<tab><tab>format = self._formats.get(col, self._formats[None])<tab><tab>item.setFormat(format)<tab><tab>self.items.append(item)<tab><tab>self.setItem(row, col, item)<tab><tab>item.setValue(val)  # Required--the text-change callback is invoked",1,if sortMode is not None :,if sortMode is not None :,0.75,100.00000000000004,1.0
"def wakeUp(self):<tab>""""""Write one byte to the pipe, and flush it.""""""<tab># We don't use fdesc.writeToFD since we need to distinguish<tab># between EINTR (try again) and EAGAIN (do nothing).<tab>if self.o is not None:<tab><tab>try:<tab><tab><tab>util.untilConcludes(os.write, self.o, b""x"")<tab><tab>except OSError as e:<tab><tab><tab># XXX There is no unit test for raising the exception<tab><tab><tab># for other errnos. See #4285.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",1,if e . errno != errno . EAGAIN :,if e . errno != errno . EAGAIN :,1.0,100.00000000000004,1.0
"def _setup(self, field_name, owner_model):<tab># Resolve possible name-based model references.<tab>resolved_classes = []<tab>for m in self.model_classes:<tab><tab><IF-STMT><tab><tab><tab>if m == owner_model.__name__:<tab><tab><tab><tab>resolved_classes.append(owner_model)<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>""PolyModelType: Unable to resolve model '{}'."".format(m)<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>resolved_classes.append(m)<tab>self.model_classes = tuple(resolved_classes)<tab>super(PolyModelType, self)._setup(field_name, owner_model)",0,"if isinstance ( m , string_type ) :","if isinstance ( m , type ) :",0.5490406812970063,53.849523560640876,0.7777777777777778
"def _wrap_forwarded(self, key, value):<tab>if isinstance(value, SourceCode) and value.late_binding:<tab><tab># get cached return value if present<tab><tab>value_ = self._late_binding_returnvalues.get(key, KeyError)<tab><tab>if value_ is KeyError:<tab><tab><tab># evaluate the late-bound function<tab><tab><tab>value_ = self._eval_late_binding(value)<tab><tab><tab>schema = self.late_bind_schemas.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value_ = schema.validate(value_)<tab><tab><tab># cache result of late bound func<tab><tab><tab>self._late_binding_returnvalues[key] = value_<tab><tab>return value_<tab>else:<tab><tab>return value",0,if schema is not None :,if schema :,0.050438393472541504,1e-10,0.39999999999999997
"def convert(self, ctx, argument):<tab>arg = argument.replace(""0x"", """").lower()<tab>if arg[0] == ""#"":<tab><tab>arg = arg[1:]<tab>try:<tab><tab>value = int(arg, base=16)<tab><tab><IF-STMT><tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return discord.Colour(value=value)<tab>except ValueError:<tab><tab>arg = arg.replace("" "", ""_"")<tab><tab>method = getattr(discord.Colour, arg, None)<tab><tab>if arg.startswith(""from_"") or method is None or not inspect.ismethod(method):<tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return method()",0,if not ( 0 <= value <= 0xFFFFFF ) :,if value < 0 :,0.015145994590617124,6.624642068265613,0.47222222222222227
"def get_versions(*, all=False, quiet=None):<tab>import bonobo<tab>from bonobo.util.pkgs import bonobo_packages<tab>yield _format_version(bonobo, quiet=quiet)<tab>if all:<tab><tab>for name in sorted(bonobo_packages):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>mod = __import__(name.replace(""-"", ""_""))<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>yield _format_version(mod, name=name, quiet=quiet)<tab><tab><tab><tab><tab>except Exception as exc:<tab><tab><tab><tab><tab><tab>yield ""{} ({})"".format(name, exc)<tab><tab><tab><tab>except ImportError as exc:<tab><tab><tab><tab><tab>yield ""{} is not importable ({})."".format(name, exc)",0,"if name != ""bonobo"" :","if not name . startswith ( ""_"" ) :",0.02675254074710682,5.604233375480572,0.3666666666666667
"def assertOperationsInjected(self, plan, **kwargs):<tab>for migration, _backward in plan:<tab><tab>operations = iter(migration.operations)<tab><tab>for operation in operations:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>next_operation = next(operations)<tab><tab><tab><tab>self.assertIsInstance(<tab><tab><tab><tab><tab>next_operation, contenttypes_management.RenameContentType<tab><tab><tab><tab>)<tab><tab><tab><tab>self.assertEqual(next_operation.app_label, migration.app_label)<tab><tab><tab><tab>self.assertEqual(next_operation.old_model, operation.old_name_lower)<tab><tab><tab><tab>self.assertEqual(next_operation.new_model, operation.new_name_lower)",0,"if isinstance ( operation , migrations . RenameModel ) :","if isinstance ( operation , contenttypes_management . RenameContentType ) :",0.485600785330624,37.70063804549471,0.5584415584415584
"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab><IF-STMT><tab><tab><tab>if "","" in line or "";"" in line:<tab><tab><tab><tab>continue<tab><tab>yield line",1,if strip_delimiters :,if strip_delimiters :,0.5311706625951745,1e-10,1.0
"def read_lccn(line, is_marc8=False):<tab>found = []<tab>for k, v in get_raw_subfields(line, [""a""]):<tab><tab>lccn = v.strip()<tab><tab>if re_question.match(lccn):<tab><tab><tab>continue<tab><tab>m = re_lccn.search(lccn)<tab><tab>if not m:<tab><tab><tab>continue<tab><tab># remove letters and bad chars<tab><tab>lccn = re_letters_and_bad.sub("""", m.group(1)).strip()<tab><tab><IF-STMT><tab><tab><tab>found.append(lccn)<tab>return found",0,if lccn :,if is_marc8 and lccn not in found :,0.046522600101893324,1e-10,0.21428571428571427
"def test_named_parameters_and_constraints(self):<tab>likelihood = gpytorch.likelihoods.GaussianLikelihood()<tab>model = ExactGPModel(None, None, likelihood)<tab>for name, _param, constraint in model.named_parameters_and_constraints():<tab><tab>if name == ""likelihood.noise_covar.raw_noise"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan)<tab><tab>elif name == ""mean_module.constant"":<tab><tab><tab>self.assertIsNone(constraint)<tab><tab>elif name == ""covar_module.raw_outputscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)",0,"elif name == ""covar_module.base_kernel.raw_lengthscale"" :","elif name == ""mean_module.raw_outputscale"" :",0.6428720214849399,34.602738553878126,1.0
"def _cleanupSocket(self):<tab>""""""Close the Connection's socket.""""""<tab>try:<tab><tab>self._sock.shutdown(socket.SHUT_WR)<tab>except:<tab><tab>return<tab>try:<tab><tab>while True:<tab><tab><tab>r, w, e = select.select([self._sock], [], [])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>except:<tab><tab>pass<tab>self._sock.close()",0,if not r or not self . _sock . recv ( 1024 ) :,if not r :,0.02997757883318023,4.084626608723862,0.4215686274509804
"def fadeIn(self, acts=None, t=None, duration=None):<tab>""""""Gradually switch on the input list of meshes by increasing opacity.""""""<tab>if self.bookingMode:<tab><tab>acts, t, duration, rng = self._parse(acts, t, duration)<tab><tab>for tt in rng:<tab><tab><tab>alpha = linInterpolate(tt, [t, t + duration], [0, 1])<tab><tab><tab>self.events.append((tt, self.fadeIn, acts, alpha))<tab>else:<tab><tab>for a in self._performers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>a.alpha(self._inputvalues)<tab>return self",0,if a . alpha ( ) >= self . _inputvalues :,if a . _inputvalues is None :,0.11045766124586327,18.505100105615163,0.42857142857142855
"def get_config_updates_recursive(self):<tab>config_updates = self.config_updates.copy()<tab>for sr_path, subrunner in self.subrunners.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>update = subrunner.get_config_updates_recursive()<tab><tab>if update:<tab><tab><tab>config_updates[rel_path(self.path, sr_path)] = update<tab>return config_updates",0,"if not is_prefix ( self . path , sr_path ) :",if subrunner is None :,0.011636451275277468,1.9026155630072006,0.25
"def setArgs(self, **kwargs):<tab>""""""See GridSearchCostGamma""""""<tab>for key, value in list(kwargs.items()):<tab><tab>if key in (""folds"", ""nfolds""):<tab><tab><tab>self._n_folds = int(value)<tab><tab><IF-STMT><tab><tab><tab>self._validator_kwargs[""max_epochs""] = value<tab><tab>else:<tab><tab><tab>GridSearchDOE.setArgs(self, **{key: value})",0,"elif key in ( ""max_epochs"" ) :","elif key == ""max_epochs"" :",0.04341095993537235,42.2683921634124,0.7222222222222222
"def _parse_composite_axis(composite_axis_name: str):<tab>axes_names = [axis for axis in composite_axis_name.split("" "") if len(axis) > 0]<tab>for axis in axes_names:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>assert ""a"" <= axis[0] <= ""z""<tab><tab>for letter in axis:<tab><tab><tab>assert str.isdigit(letter) or ""a"" <= letter <= ""z""<tab>return axes_names",0,"if axis == ""_"" :",if len ( axis ) < 2 :,0.028001459970687266,7.267884212102741,0.36
"def visit_For(self, node, for_branch=""body"", **kwargs):<tab>if for_branch == ""body"":<tab><tab>self.sym_visitor.visit(node.target, store_as_param=True)<tab><tab>branch = node.body<tab>elif for_branch == ""else"":<tab><tab>branch = node.else_<tab>elif for_branch == ""test"":<tab><tab>self.sym_visitor.visit(node.target, store_as_param=True)<tab><tab><IF-STMT><tab><tab><tab>self.sym_visitor.visit(node.test)<tab><tab>return<tab>else:<tab><tab>raise RuntimeError(""Unknown for branch"")<tab>for item in branch or ():<tab><tab>self.sym_visitor.visit(item)",1,if node . test is not None :,if node . test is not None :,0.75,100.00000000000004,1.0
def contains_only_whitespace(node):<tab>if is_tag(node):<tab><tab><IF-STMT><tab><tab><tab>if not any([unicode(s).strip() for s in node.contents]):<tab><tab><tab><tab>return True<tab>return False,0,if not any ( [ not is_text ( s ) for s in node . contents ] ) :,if node . contents :,0.06144638752204731,1.8416404593202451,0.19111111111111112
"def dir_tag_click(event):<tab>mouse_index = self.path_bar.index(""@%d,%d"" % (event.x, event.y))<tab>lineno = int(float(mouse_index))<tab>if lineno == 1:<tab><tab>self.request_focus_into("""")<tab>else:<tab><tab>assert lineno == 2<tab><tab>dir_range = get_dir_range(event)<tab><tab>if dir_range:<tab><tab><tab>_, end_index = dir_range<tab><tab><tab>path = self.path_bar.get(""2.0"", end_index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path += ""\\""<tab><tab><tab>self.request_focus_into(path)",0,"if path . endswith ( "":"" ) :","if path [ - 1 ] != ""\\"" :",0.032180044038651254,9.238430210261097,0.6
"def validate_employee_id(self):<tab>if self.employee:<tab><tab>sales_person = frappe.db.get_value(""Sales Person"", {""employee"": self.employee})<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Another Sales Person {0} exists with the same Employee id"").format(<tab><tab><tab><tab><tab>sales_person<tab><tab><tab><tab>)<tab><tab><tab>)",0,if sales_person and sales_person != self . name :,if sales_person != self . employee :,0.2671560519369194,52.45537838821977,0.3181818181818182
"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/infer""):<tab><tab><tab>if ""stage"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))",1,"if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",0.75,100.00000000000004,1.0
"def poll(self, timeout):<tab>if timeout < 0:<tab><tab>timeout = None  # kqueue behaviour<tab>events = self._kqueue.control(None, KqueueLoop.MAX_EVENTS, timeout)<tab>results = defaultdict(lambda: POLL_NULL)<tab>for e in events:<tab><tab>fd = e.ident<tab><tab>if e.filter == select.KQ_FILTER_READ:<tab><tab><tab>results[fd] |= POLL_IN<tab><tab><IF-STMT><tab><tab><tab>results[fd] |= POLL_OUT<tab>return results.items()",1,elif e . filter == select . KQ_FILTER_WRITE :,elif e . filter == select . KQ_FILTER_WRITE :,0.75,100.00000000000004,1.0
"def _read_dimensions(self, *dimnames, **kwargs):<tab>path = kwargs.get(""path"", ""/"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return [self.rootgrp.dimensions[dname] for dname in dimnames]<tab><tab>group = self.path2group[path]<tab><tab>return [group.dimensions[dname] for dname in dimnames]<tab>except KeyError:<tab><tab>raise self.Error(<tab><tab><tab>""In file %s:\nError while reading dimensions: `%s` with kwargs: `%s`""<tab><tab><tab>% (self.path, dimnames, kwargs)<tab><tab>)",1,"if path == ""/"" :","if path == ""/"" :",0.75,100.00000000000004,1.0
"def spam_to_me(address):<tab>sock = eventlet.connect(address)<tab>while True:<tab><tab>try:<tab><tab><tab>sock.sendall(b""hello world"")<tab><tab><tab># Arbitrary delay to not use all available CPU, keeps the test<tab><tab><tab># running quickly and reliably under a second<tab><tab><tab>time.sleep(0.001)<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>raise",0,if get_errno ( e ) == errno . EPIPE :,if e . args [ 0 ] == errno . EINTR :,0.10750117703988596,22.242469397936766,0.35714285714285715
"def has_hash_of(self, destpath, code, package_level):<tab>""""""Determine if a file has the hash of the code.""""""<tab>if destpath is not None and os.path.isfile(destpath):<tab><tab>with univ_open(destpath, ""r"") as opened:<tab><tab><tab>compiled = readfile(opened)<tab><tab>hashash = gethash(compiled)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,"if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :",if hashash == code :,0.011472239067646843,2.7629077445603603,0.2121212121212121
"def insert(self, index, item):<tab>if len(self.lists) == 1:<tab><tab>self.lists[0].insert(index, item)<tab><tab>self._balance_list(0)<tab>else:<tab><tab>list_idx, rel_idx = self._translate_index(index)<tab><tab><IF-STMT><tab><tab><tab>raise IndexError()<tab><tab>self.lists[list_idx].insert(rel_idx, item)<tab><tab>self._balance_list(list_idx)<tab>return",0,if list_idx is None :,if list_idx >= len ( self . lists ) :,0.04589139340883146,20.448007360218387,0.27472527472527475
"def _parse_class_simplified(symbol):<tab>results = {}<tab>name = symbol.name + ""(""<tab>name += "", "".join([analyzer.expand_attribute(base) for base in symbol.bases])<tab>name += "")""<tab>for sym in symbol.body:<tab><tab>if isinstance(sym, ast.FunctionDef):<tab><tab><tab>result = _parse_function_simplified(sym, symbol.name)<tab><tab><tab>results.update(result)<tab><tab><IF-STMT><tab><tab><tab>result = _parse_class_simplified(sym)<tab><tab><tab>results.update(result)<tab>lineno = symbol.lineno<tab>for decorator in symbol.decorator_list:<tab><tab>lineno += 1<tab>results[lineno] = (name, ""c"")<tab>return results",1,"elif isinstance ( sym , ast . ClassDef ) :","elif isinstance ( sym , ast . ClassDef ) :",0.75,100.00000000000004,1.0
"def append_vars(pairs, result):<tab>for name, value in sorted(pairs.items()):<tab><tab>if isinstance(value, list):<tab><tab><tab>value = ""[%s]"" % "","".join(value)<tab><tab><IF-STMT><tab><tab><tab>result.append(""%s:%s=%s"" % (package, name, value))<tab><tab>else:<tab><tab><tab>result.append(""%s=%s"" % (name, value))",0,if package :,"elif name == ""package"" :",0.15895954273951024,1e-10,0.2
"def nextEditable(self):<tab>""""""Moves focus of the cursor to the next editable window""""""<tab>if self.currentEditable is None:<tab><tab><IF-STMT><tab><tab><tab>self._currentEditableRef = self._editableChildren[0]<tab>else:<tab><tab>for ref in weakref.getweakrefs(self.currentEditable):<tab><tab><tab>if ref in self._editableChildren:<tab><tab><tab><tab>cei = self._editableChildren.index(ref)<tab><tab><tab><tab>nei = cei + 1<tab><tab><tab><tab>if nei >= len(self._editableChildren):<tab><tab><tab><tab><tab>nei = 0<tab><tab><tab><tab>self._currentEditableRef = self._editableChildren[nei]<tab>return self.currentEditable",0,if len ( self . _editableChildren ) :,if self . _editableChildren :,0.0823244657685789,34.1077254951379,0.4772727272727273
"def everythingIsUnicode(d):<tab>""""""Takes a dictionary, recursively verifies that every value is unicode""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict) and k != ""headers"":<tab><tab><tab>if not everythingIsUnicode(v):<tab><tab><tab><tab>return False<tab><tab>elif isinstance(v, list):<tab><tab><tab>for i in v:<tab><tab><tab><tab>if isinstance(i, dict) and not everythingIsUnicode(i):<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>elif isinstance(i, _bytes):<tab><tab><tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",0,"elif isinstance ( v , _bytes ) :","elif not isinstance ( i , unicode ) :",0.14282527019583852,14.923729480049115,0.2571428571428572
"def is_valid(sample):<tab>if sample is None:<tab><tab>return False<tab>if isinstance(sample, tuple):<tab><tab>for s in sample:<tab><tab><tab>if s is None:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(s, collections.abc.Sequence) and len(s) == 0:<tab><tab><tab><tab>return False<tab>return True",0,"elif isinstance ( s , np . ndarray ) and s . size == 0 :","elif isinstance ( s , str ) :",0.1639766690858278,18.256549872061097,0.34035087719298246
"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab>if ""attributes"" in conf[""properties""]:<tab><tab><tab>if ""exp"" in conf[""properties""][""attributes""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",0,"if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :",0.4244691007256021,76.6119563549595,0.4891304347826087
"def encode(self):<tab>if self.expr in gpregs.expr:<tab><tab>self.value = gpregs.expr.index(self.expr)<tab><tab>self.parent.rot2.value = 0<tab>elif isinstance(self.expr, ExprOp) and self.expr.op == allshifts[3]:<tab><tab>reg, value = self.expr.args<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.value = gpregs.expr.index(reg)<tab><tab>if not isinstance(value, ExprInt):<tab><tab><tab>return False<tab><tab>value = int(value)<tab><tab>if not value in [8, 16, 24]:<tab><tab><tab>return False<tab><tab>self.parent.rot2.value = value // 8<tab>return True",1,if reg not in gpregs . expr :,if reg not in gpregs . expr :,0.75,100.00000000000004,1.0
"def validate_transaction_reference(self):<tab>bank_account = self.paid_to if self.payment_type == ""Receive"" else self.paid_from<tab>bank_account_type = frappe.db.get_value(""Account"", bank_account, ""account_type"")<tab>if bank_account_type == ""Bank"":<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Reference No and Reference Date is mandatory for Bank transaction"")<tab><tab><tab>)",0,if not self . reference_no or not self . reference_date :,"if not frappe . db . get_value ( ""Reference No"" , ""Reference Date"" ) :",0.022219243726218793,4.780204393760627,0.36666666666666664
"def monad(self):<tab>if not self.cls_bl_idname:<tab><tab>return None<tab>for monad in bpy.data.node_groups:<tab><tab>if hasattr(monad, ""cls_bl_idname""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return monad<tab>return None",1,if monad . cls_bl_idname == self . cls_bl_idname :,if monad . cls_bl_idname == self . cls_bl_idname :,1.0,100.00000000000004,1.0
"def _create_mask(self, plen):<tab>mask = []<tab>for i in range(16):<tab><tab>if plen >= 8:<tab><tab><tab>mask.append(0xFF)<tab><tab><IF-STMT><tab><tab><tab>mask.append(0xFF >> (8 - plen) << (8 - plen))<tab><tab>else:<tab><tab><tab>mask.append(0x00)<tab><tab>plen -= 8<tab>return mask",0,elif plen > 0 :,elif plen < 8 :,0.31287167148414674,23.643540225079384,0.6
"def dataset_to_stream(dataset, input_name):<tab>""""""Takes a tf.Dataset and creates a numpy stream of ready batches.""""""<tab># All input-pipeline processing should be on CPU.<tab>for example in fastmath.dataset_as_numpy(dataset):<tab><tab>features = example[0]<tab><tab>inp, out = features[input_name], example[1]<tab><tab>mask = features[""mask""] if ""mask"" in features else None<tab><tab># Some accelerators don't handle uint8 well, cast to int.<tab><tab><IF-STMT><tab><tab><tab>inp = inp.astype(np.int32)<tab><tab>if isinstance(out, np.uint8):<tab><tab><tab>out = out.astype(np.int32)<tab><tab>yield (inp, out) if mask is None else (inp, out, mask)",1,"if isinstance ( inp , np . uint8 ) :","if isinstance ( inp , np . uint8 ) :",0.75,100.00000000000004,1.0
"def _idle_redraw_cb(self):<tab>assert self._idle_redraw_src_id is not None<tab>queue = self._idle_redraw_queue<tab>if len(queue) > 0:<tab><tab>bbox = queue.pop(0)<tab><tab><IF-STMT><tab><tab><tab>super(CanvasRenderer, self).queue_draw()<tab><tab>else:<tab><tab><tab>super(CanvasRenderer, self).queue_draw_area(*bbox)<tab>if len(queue) == 0:<tab><tab>self._idle_redraw_src_id = None<tab><tab>return False<tab>return True",1,if bbox is None :,if bbox is None :,0.75,100.00000000000004,1.0
"def mutated(self, indiv):<tab>""""""mutate some genes of the given individual""""""<tab>res = indiv.copy()<tab># to avoid having a child identical to one of the currentpopulation'''<tab>for i in range(self.numParameters):<tab><tab><IF-STMT><tab><tab><tab>if self.xBound is None:<tab><tab><tab><tab>res[i] = indiv[i] + gauss(0, self.mutationStdDev)<tab><tab><tab>else:<tab><tab><tab><tab>res[i] = max(<tab><tab><tab><tab><tab>min(indiv[i] + gauss(0, self.mutationStdDev), self.maxs[i]),<tab><tab><tab><tab><tab>self.mins[i],<tab><tab><tab><tab>)<tab>return res",0,if random ( ) < self . mutationProb :,if res [ i ] is not None :,0.015688072271932925,5.669791110976001,0.175
"def _justifyDrawParaLine(tx, offset, extraspace, words, last=0):<tab>setXPos(tx, offset)<tab>text = b"" "".join(words)<tab>if last:<tab><tab># last one, left align<tab><tab>tx._textOut(text, 1)<tab>else:<tab><tab>nSpaces = len(words) - 1<tab><tab><IF-STMT><tab><tab><tab>tx.setWordSpace(extraspace / float(nSpaces))<tab><tab><tab>tx._textOut(text, 1)<tab><tab><tab>tx.setWordSpace(0)<tab><tab>else:<tab><tab><tab>tx._textOut(text, 1)<tab>setXPos(tx, -offset)<tab>return offset",0,if nSpaces :,if nSpaces > extraspace :,0.09791453445388575,1e-10,0.7
"def _read_0(self, stream):<tab>r = b""""<tab>while True:<tab><tab>c = stream.read(2)<tab><tab><IF-STMT><tab><tab><tab>raise EOFError()<tab><tab>if c == b""\x00\x00"":<tab><tab><tab>break<tab><tab>r += c<tab>return r.decode(self.encoding)",0,if len ( c ) != 2 :,"if c == b"""" :",0.019907917998500824,6.892168295481103,0.36
"def run(self, app, editor, args):<tab>line_nums = []<tab>for cursor in editor.cursors:<tab><tab><IF-STMT><tab><tab><tab>line_nums.append(cursor.y)<tab><tab><tab>data = editor.lines[cursor.y].get_data().upper()<tab><tab><tab>editor.lines[cursor.y].set_data(data)",1,if cursor . y not in line_nums :,if cursor . y not in line_nums :,0.75,100.00000000000004,1.0
"def create_default_energy_point_rules():<tab>for rule in get_default_energy_point_rules():<tab><tab># check if any rule for ref. doctype exists<tab><tab>rule_exists = frappe.db.exists(<tab><tab><tab>""Energy Point Rule"", {""reference_doctype"": rule.get(""reference_doctype"")}<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>doc = frappe.get_doc(rule)<tab><tab>doc.insert(ignore_permissions=True)",0,if rule_exists :,if not rule_exists :,0.11348623737539229,1e-10,0.6
"def __new__(cls, *nodes):<tab>if not nodes:<tab><tab>raise TypeError(""DisjunctionNode() requires at least one node"")<tab>elif len(nodes) == 1:<tab><tab>return nodes[0]<tab>self = super(DisjunctionNode, cls).__new__(cls)<tab>self.__nodes = []<tab># TODO: Remove duplicates?<tab>for node in nodes:<tab><tab>if not isinstance(node, Node):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""DisjunctionNode() expects Node instances as arguments;""<tab><tab><tab><tab>"" received a non-Node instance %r"" % node<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.__nodes.extend(node.__nodes)<tab><tab>else:<tab><tab><tab>self.__nodes.append(node)<tab>return self",0,"if isinstance ( node , DisjunctionNode ) :","if hasattr ( node , ""__nodes"" ) :",0.09166808520089226,16.59038701421971,0.48148148148148145
def dfs(v: str) -> Iterator[Set[str]]:<tab>index[v] = len(stack)<tab>stack.append(v)<tab>boundaries.append(index[v])<tab>for w in edges[v]:<tab><tab>if w not in index:<tab><tab><tab>yield from dfs(w)<tab><tab><IF-STMT><tab><tab><tab>while index[w] < boundaries[-1]:<tab><tab><tab><tab>boundaries.pop()<tab>if boundaries[-1] == index[v]:<tab><tab>boundaries.pop()<tab><tab>scc = set(stack[index[v] :])<tab><tab>del stack[index[v] :]<tab><tab>identified.update(scc)<tab><tab>yield scc,0,elif w not in identified :,if boundaries [ - 1 ] == index [ v ] :,0.014464503771006398,3.0890553181566975,0.09090909090909091
"def unpack_item_obj(map_uuid_global_id, misp_obj):<tab>obj_meta = get_object_metadata(misp_obj)<tab>obj_id = None<tab>io_content = None<tab>for attribute in misp_obj.attributes:<tab><tab><IF-STMT><tab><tab><tab>obj_id = attribute.value  # # TODO: sanitize<tab><tab><tab>io_content = attribute.data  # # TODO: check if type == io<tab>if obj_id and io_content:<tab><tab>res = Item.create_item(obj_id, obj_meta, io_content)<tab><tab>map_uuid_global_id[misp_obj.uuid] = get_global_id(""item"", obj_id)",0,"if attribute . object_relation == ""raw-data"" :","if attribute . name == ""id"" :",0.3444789340715307,24.437032551865375,0.7222222222222222
"def parse(self, response):<tab>soup = BeautifulSoup(response.content.decode(""utf-8"", ""ignore""), ""lxml"")<tab>image_divs = soup.find_all(""div"", class_=""imgpt"")<tab>pattern = re.compile(r""murl\"":\""(.*?)\.jpg"")<tab>for div in image_divs:<tab><tab>href_str = html_parser.HTMLParser().unescape(div.a[""m""])<tab><tab>match = pattern.search(href_str)<tab><tab><IF-STMT><tab><tab><tab>name = match.group(1) if six.PY3 else match.group(1).encode(""utf-8"")<tab><tab><tab>img_url = ""{}.jpg"".format(name)<tab><tab><tab>yield dict(file_url=img_url)",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def filter_errors(self, errors: List[str]) -> List[str]:<tab>real_errors: List[str] = list()<tab>current_file = __file__<tab>current_path = os.path.split(current_file)<tab>for line in errors:<tab><tab>line = line.strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>fn, lno, lvl, msg = self.parse_trace_line(line)<tab><tab><IF-STMT><tab><tab><tab>_path = os.path.split(fn)<tab><tab><tab>if _path[-1] != current_path[-1]:<tab><tab><tab><tab>continue<tab><tab>real_errors.append(line)<tab>return real_errors",0,if fn is not None :,if fn :,0.050438393472541504,1e-10,0.39999999999999997
"def decompileFormat1(self, reader, otFont):<tab>self.classDefs = classDefs = []<tab>startGlyphID = reader.readUShort()<tab>glyphCount = reader.readUShort()<tab>for i in range(glyphCount):<tab><tab>glyphName = otFont.getglyphName(startGlyphID + i)<tab><tab>classValue = reader.readUShort()<tab><tab><IF-STMT><tab><tab><tab>classDefs.append((glyphName, classValue))",0,if classValue :,if classValue != 0 :,0.09791453445388575,1e-10,0.7
"def compress(self, data_list):<tab>if len(data_list) == 2:<tab><tab>value, lookup_expr = data_list<tab><tab><IF-STMT><tab><tab><tab>if lookup_expr not in EMPTY_VALUES:<tab><tab><tab><tab>return Lookup(value=value, lookup_expr=lookup_expr)<tab><tab><tab>else:<tab><tab><tab><tab>raise forms.ValidationError(<tab><tab><tab><tab><tab>self.error_messages[""lookup_required""], code=""lookup_required""<tab><tab><tab><tab>)<tab>return None",0,if value not in EMPTY_VALUES :,if value is not None :,0.30253150069759704,13.83254362586636,0.38095238095238093
"def open_compat(path, mode=""r""):<tab>if mode in [""r"", ""rb""] and not os.path.exists(path):<tab><tab>raise FileNotFoundError(u'The file ""%s"" could not be found' % path)<tab>if sys.version_info >= (3,):<tab><tab>encoding = ""utf-8""<tab><tab>errors = ""replace""<tab><tab><IF-STMT><tab><tab><tab>encoding = None<tab><tab><tab>errors = None<tab><tab>return open(path, mode, encoding=encoding, errors=errors)<tab>else:<tab><tab>return open(path, mode)",0,"if mode in [ ""rb"" , ""wb"" , ""ab"" ] :","if encoding == ""utf-8"" :",0.011636451275277468,2.5354870210011202,0.38823529411764707
"def filter_errors(self, errors: List[str]) -> List[str]:<tab>real_errors: List[str] = list()<tab>current_file = __file__<tab>current_path = os.path.split(current_file)<tab>for line in errors:<tab><tab>line = line.strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>fn, lno, lvl, msg = self.parse_trace_line(line)<tab><tab>if fn is not None:<tab><tab><tab>_path = os.path.split(fn)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>real_errors.append(line)<tab>return real_errors",0,if _path [ - 1 ] != current_path [ - 1 ] :,if _path != current_path :,0.021880396295349106,25.274696573647738,0.6363636363636364
"def filter_by_level(record, level_per_module):<tab>name = record[""name""]<tab>level = 0<tab>if name in level_per_module:<tab><tab>level = level_per_module[name]<tab>elif name is not None:<tab><tab>lookup = """"<tab><tab>if """" in level_per_module:<tab><tab><tab>level = level_per_module[""""]<tab><tab>for n in name.split("".""):<tab><tab><tab>lookup += n<tab><tab><tab><IF-STMT><tab><tab><tab><tab>level = level_per_module[lookup]<tab><tab><tab>lookup += "".""<tab>if level is False:<tab><tab>return False<tab>return record[""level""].no >= level",1,if lookup in level_per_module :,if lookup in level_per_module :,0.75,100.00000000000004,1.0
"def CountButtons(self):<tab>""""""Returns the number of visible buttons in the docked pane.""""""<tab>n = 0<tab>if self.HasCaption() or self.HasCaptionLeft():<tab><tab>if isinstance(wx.GetTopLevelParent(self.window), AuiFloatingFrame):<tab><tab><tab>return 1<tab><tab>if self.HasCloseButton():<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>if self.HasMinimizeButton():<tab><tab><tab>n += 1<tab><tab>if self.HasPinButton():<tab><tab><tab>n += 1<tab>return n",0,if self . HasMaximizeButton ( ) :,if self . HasMinimizeButton ( ) :,0.3884893899276739,41.11336169005196,0.6
"def search(a, b, desired):<tab>if a == b:<tab><tab>return a<tab>if abs(b - a) < 0.005:<tab><tab>ca = count(a)<tab><tab>cb = count(b)<tab><tab>dista = abs(desired - ca)<tab><tab>distb = abs(desired - cb)<tab><tab><IF-STMT><tab><tab><tab>return a<tab><tab>else:<tab><tab><tab>return b<tab>m = (a + b) / 2.0<tab>cm = count(m)<tab>if desired < cm:<tab><tab>return search(m, b, desired)<tab>else:<tab><tab>return search(a, m, desired)",1,if dista < distb :,if dista < distb :,0.75,100.00000000000004,1.0
"def force_ipv4(self, *args):<tab>""""""only ipv4 localhost in /etc/hosts""""""<tab>logg.debug(""checking /etc/hosts for '::1 localhost'"")<tab>lines = []<tab>for line in open(self.etc_hosts()):<tab><tab><IF-STMT><tab><tab><tab>newline = re.sub(""\\slocalhost\\s"", "" "", line)<tab><tab><tab>if line != newline:<tab><tab><tab><tab>logg.info(""/etc/hosts: '%s' => '%s'"", line.rstrip(), newline.rstrip())<tab><tab><tab><tab>line = newline<tab><tab>lines.append(line)<tab>f = open(self.etc_hosts(), ""w"")<tab>for line in lines:<tab><tab>f.write(line)<tab>f.close()",0,"if ""::1"" in line :","if line . startswith ( ""localhost"" ) :",0.028001459970687266,6.27465531099474,0.4
"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]:<tab>yield ""Core"", ""0""<tab>for _dir in data_manager.cog_data_path().iterdir():<tab><tab>fpath = _dir / ""settings.json""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with fpath.open() as f:<tab><tab><tab>try:<tab><tab><tab><tab>data = json.load(f)<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>continue<tab><tab>if not isinstance(data, dict):<tab><tab><tab>continue<tab><tab>cog_name = _dir.stem<tab><tab>for cog_id, inner in data.items():<tab><tab><tab>if not isinstance(inner, dict):<tab><tab><tab><tab>continue<tab><tab><tab>yield cog_name, cog_id",1,if not fpath . exists ( ) :,if not fpath . exists ( ) :,0.75,100.00000000000004,1.0
"def _get_dbutils():<tab>try:<tab><tab>import IPython<tab><tab>ip_shell = IPython.get_ipython()<tab><tab><IF-STMT><tab><tab><tab>raise _NoDbutilsError<tab><tab>return ip_shell.ns_table[""user_global""][""dbutils""]<tab>except ImportError:<tab><tab>raise _NoDbutilsError<tab>except KeyError:<tab><tab>raise _NoDbutilsError",0,if ip_shell is None :,"if ""user_global"" not in ip_shell . ns_table :",0.15300145997068726,10.343603005129705,0.3333333333333333
"def _bytecode_filenames(self, py_filenames):<tab>bytecode_files = []<tab>for py_file in py_filenames:<tab><tab># Since build_py handles package data installation, the<tab><tab># list of outputs can contain more than just .py files.<tab><tab># Make sure we only report bytecode for the .py files.<tab><tab>ext = os.path.splitext(os.path.normcase(py_file))[1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if self.compile:<tab><tab><tab>bytecode_files.append(py_file + ""c"")<tab><tab>if self.optimize > 0:<tab><tab><tab>bytecode_files.append(py_file + ""o"")<tab>return bytecode_files",0,if ext != PYTHON_SOURCE_EXTENSION :,"if ext != "".py"" :",0.14477865547525276,28.24099048856542,1.0
"def compute_distances_mu(line, pts, result, gates, tolerance):<tab>""""""calculate all distances with mathuutils""""""<tab>line_origin = V(line[0])<tab>line_end = V(line[-1])<tab>local_result = [[], [], [], [], []]<tab>for point in pts:<tab><tab>data = compute_distance(V(point), line_origin, line_end, tolerance)<tab><tab>for i, res in enumerate(local_result):<tab><tab><tab>res.append(data[i])<tab>for i, res in enumerate(result):<tab><tab><IF-STMT><tab><tab><tab>res.append(local_result[i])",0,if gates [ i ] :,if i < len ( local_result ) - 1 :,0.021554938761049226,4.456882760699063,0.32051282051282054
"def _get_next_segment(self, segment_path, page_size, segment_cursor=None):<tab>if segment_path:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return Segment(self.client, segment_path, page_size, segment_cursor)<tab>return None",0,if self . end_time and self . _is_later_than_end_time ( segment_path ) :,if segment_cursor is None :,0.04139113949138936,1.2622429207309396,0.3235294117647059
"def _check_number_of_sessions():<tab>nb_desktop_sessions = sessions.get_number_of_desktop_sessions(ignore_gdm=True)<tab>if nb_desktop_sessions > 1:<tab><tab>print(<tab><tab><tab>""WARNING : There are %d other desktop sessions open. The GPU switch will not become effective until you have manually""<tab><tab><tab>"" logged out from ALL desktop sessions.\n""<tab><tab><tab>""Continue ? (y/N)"" % (nb_desktop_sessions - 1)<tab><tab>)<tab><tab>confirmation = ask_confirmation()<tab><tab><IF-STMT><tab><tab><tab>sys.exit(0)",1,if not confirmation :,if not confirmation :,0.75,100.00000000000004,1.0
"def delete_compute_environment(self, compute_environment_name):<tab>if compute_environment_name is None:<tab><tab>raise InvalidParameterValueException(""Missing computeEnvironment parameter"")<tab>compute_env = self.get_compute_environment(compute_environment_name)<tab>if compute_env is not None:<tab><tab># Pop ComputeEnvironment<tab><tab>self._compute_environments.pop(compute_env.arn)<tab><tab># Delete ECS cluster<tab><tab>self.ecs_backend.delete_cluster(compute_env.ecs_name)<tab><tab><IF-STMT><tab><tab><tab># Delete compute environment<tab><tab><tab>instance_ids = [instance.id for instance in compute_env.instances]<tab><tab><tab>self.ec2_backend.terminate_instances(instance_ids)",0,"if compute_env . env_type == ""MANAGED"" :",if compute_env . instances :,0.09453229110448028,23.671529472186084,0.6363636363636364
"def run(self):<tab>results = {}<tab>for func_name in [<tab><tab># Execute every function starting with check_*<tab><tab>fn<tab><tab>for fn in self.check_functions<tab><tab># if the user does not specify any name<tab><tab>if not self.args.get(""check"")<tab><tab># of if specify the current function name<tab><tab>or self.args.get(""check"") == fn<tab>]:<tab><tab>function = getattr(self, func_name)<tab><tab>log.warn(function.__doc__)<tab><tab>result = function()<tab><tab><IF-STMT><tab><tab><tab>log.info(""\n"".join(result))<tab><tab><tab>results.update({func_name: result})<tab>return results",1,if result :,if result :,0.5311706625951745,1e-10,1.0
"def invalidate(self, layers=None):<tab>if layers is None:<tab><tab>layers = Layer.AllLayers<tab>if layers:<tab><tab>layers = set(layers)<tab><tab>self.invalidLayers.update(layers)<tab><tab>blockRenderers = [<tab><tab><tab>br<tab><tab><tab>for br in self.blockRenderers<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if len(blockRenderers) < len(self.blockRenderers):<tab><tab><tab>self.forgetDisplayLists()<tab><tab>self.blockRenderers = blockRenderers<tab><tab>if self.renderer.showRedraw and Layer.Blocks in layers:<tab><tab><tab>self.needsRedisplay = True",0,if br . layer is Layer . Blocks or br . layer not in layers,if br not in layers,0.033766279079555185,6.7667641618306344,0.2128205128205128
"def get_library_dirs(platform, arch=None):<tab>if platform == ""win32"":<tab><tab>jre_home = get_jre_home(platform)<tab><tab>jdk_home = JAVA_HOME<tab><tab><IF-STMT><tab><tab><tab>jre_home = jre_home.decode(""utf-8"")<tab><tab>return [join(jdk_home, ""lib""), join(jdk_home, ""bin"", ""server"")]<tab>elif platform == ""android"":<tab><tab>return [""libs/{}"".format(arch)]<tab>return []",1,"if isinstance ( jre_home , bytes ) :","if isinstance ( jre_home , bytes ) :",0.75,100.00000000000004,1.0
"def save_plugin_options(self):<tab>for name, option_widgets in self._plugin_option_widgets.items():<tab><tab><IF-STMT><tab><tab><tab>self.config[""plugins""][name] = {}<tab><tab>plugin_config = self.config[""plugins""][<tab><tab><tab>name<tab><tab>]  # use or instead of get incase the value is actually None<tab><tab>for option_name, option_widget in option_widgets.items():<tab><tab><tab>plugin_config[option_name] = option_widget.option.get_widget_value(<tab><tab><tab><tab>option_widget.widget<tab><tab><tab>)",1,"if name not in self . config [ ""plugins"" ] :","if name not in self . config [ ""plugins"" ] :",0.75,100.00000000000004,1.0
"def _select_block(str_in, start_tag, end_tag):<tab>""""""Select first block delimited by start_tag and end_tag""""""<tab>start_pos = str_in.find(start_tag)<tab>if start_pos < 0:<tab><tab>raise ValueError(""start_tag not found"")<tab>depth = 0<tab>for pos in range(start_pos, len(str_in)):<tab><tab>if str_in[pos] == start_tag:<tab><tab><tab>depth += 1<tab><tab>elif str_in[pos] == end_tag:<tab><tab><tab>depth -= 1<tab><tab><IF-STMT><tab><tab><tab>break<tab>sel = str_in[start_pos + 1 : pos]<tab>return sel",1,if depth == 0 :,if depth == 0 :,0.75,100.00000000000004,1.0
"def _coerce_to_bool(self, node, var, true_val=True):<tab>""""""Coerce the values in a variable to bools.""""""<tab>bool_var = self.program.NewVariable()<tab>for b in var.bindings:<tab><tab>v = b.data<tab><tab>if isinstance(v, mixin.PythonConstant) and isinstance(v.pyval, bool):<tab><tab><tab>const = v.pyval is true_val<tab><tab>elif not compare.compatible_with(v, True):<tab><tab><tab>const = not true_val<tab><tab><IF-STMT><tab><tab><tab>const = true_val<tab><tab>else:<tab><tab><tab>const = None<tab><tab>bool_var.AddBinding(self.convert.bool_values[const], {b}, node)<tab>return bool_var",0,"elif not compare . compatible_with ( v , False ) :","elif compare . compatible_with ( v , False ) :",0.4478338245094791,84.96364166597652,0.32051282051282054
def multiline_indentation(self):<tab>if self._multiline_indentation is None:<tab><tab>offset = 0<tab><tab><IF-STMT><tab><tab><tab>offset = 2<tab><tab>indentation = make_indentation(3 * self.indent_size + offset)<tab><tab>self._multiline_indentation = indentation<tab>if self.current_rule:<tab><tab>indent_extra = make_indentation(self.indent_size)<tab><tab>return self._multiline_indentation + indent_extra<tab>return self._multiline_indentation,0,if self . show_aligned_keywords :,if self . current_rule :,0.39477865547525276,20.873176328735713,1.0
"def __call__(self, event, data=None):<tab>datatype, delta = event<tab>self.midi_ctrl.delta += delta<tab>if TIMING_CLOCK in datatype and not self.played:<tab><tab>self.midi_ctrl.pulse += 1<tab><tab><IF-STMT><tab><tab><tab>t_master = 60.0<tab><tab><tab>self.midi_ctrl.bpm = round(60.0 / self.midi_ctrl.delta, 0)<tab><tab><tab>self.midi_ctrl.pulse = 0<tab><tab><tab>self.midi_ctrl.delta = 0.0",0,if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,if self . midi_ctrl . pulse > 0 :,0.28472022483660975,36.988348418257935,0.6013071895424836
"def handle_sent(self, elt):<tab>sent = []<tab>for child in elt:<tab><tab><IF-STMT><tab><tab><tab>itm = self.handle_word(child)<tab><tab><tab>if self._unit == ""word"":<tab><tab><tab><tab>sent.extend(itm)<tab><tab><tab>else:<tab><tab><tab><tab>sent.append(itm)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected element %s"" % child.tag)<tab>return SemcorSentence(elt.attrib[""snum""], sent)",0,"if child . tag in ( ""wf"" , ""punc"" ) :","if child . tag == ""sentence"" :",0.12785238731240015,18.32556812998321,0.7866666666666667
"def _handle_def_errors(testdef):<tab># If the test generation had an error, raise<tab>if testdef.error:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(testdef.exception, Exception):<tab><tab><tab><tab>raise testdef.exception<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(testdef.exception)<tab><tab>else:<tab><tab><tab>raise Exception(""Test parse failure"")",1,if testdef . exception :,if testdef . exception :,0.75,100.00000000000004,1.0
"def _authorized_sid(self, jid, sid, ifrom, iq):<tab>with self._preauthed_sids_lock:<tab><tab><IF-STMT><tab><tab><tab>del self._preauthed_sids[(jid, sid, ifrom)]<tab><tab><tab>return True<tab><tab>return False",0,"if ( jid , sid , ifrom ) in self . _preauthed_sids :","if ( jid , sid , ifrom , iq ) in self . _preauthed_sids :",0.4438434568624574,77.7811122305422,0.6176470588235294
"def wait(self, timeout=None):<tab>if self.returncode is None:<tab><tab><IF-STMT><tab><tab><tab>msecs = _subprocess.INFINITE<tab><tab>else:<tab><tab><tab>msecs = max(0, int(timeout * 1000 + 0.5))<tab><tab>res = _subprocess.WaitForSingleObject(int(self._handle), msecs)<tab><tab>if res == _subprocess.WAIT_OBJECT_0:<tab><tab><tab>code = _subprocess.GetExitCodeProcess(self._handle)<tab><tab><tab>if code == TERMINATE:<tab><tab><tab><tab>code = -signal.SIGTERM<tab><tab><tab>self.returncode = code<tab>return self.returncode",1,if timeout is None :,if timeout is None :,0.75,100.00000000000004,1.0
"def _gen_legal_y_s_t(self):<tab>while True:<tab><tab>y = self._gen_random_scalar()<tab><tab>s = self.tec_arithmetic.mul(<tab><tab><tab>scalar=y, a=self.tec_arithmetic.get_generator()<tab><tab>)  # S = yG<tab><tab>t = self._hash_tec_element(s)<tab><tab><IF-STMT><tab><tab><tab># Both S and T are legal<tab><tab><tab>LOGGER.info(""randomly generated y, S, T"")<tab><tab><tab>return y, s, t",0,if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int :,if self . _gen_legal_t ( t ) :,0.08050869945271327,9.427699487556778,0.3541666666666667
"def write_out():<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>time.sleep(0.1)<tab><tab><tab>continue<tab><tab>data_str = self.instrument_queue.get()<tab><tab>data_str = data_str.splitlines()<tab><tab>tb.write("""")  # position cursor to end<tab><tab>for line in data_str:<tab><tab><tab>tb.write(line)<tab><tab>tb.write(""\n"")",0,if self . instrument_queue . empty ( ) :,if self . stop_event . is_set ( ) :,0.3548262086007482,20.78060434846712,0.7307692307692308
"def _parse_preamble(self):<tab>""""""Parse metadata about query (PRIVATE).""""""<tab>meta = {}<tab>while self.line:<tab><tab>regx = re.search(_RE_QUERY, self.line)<tab><tab>if regx:<tab><tab><tab>self.query_id = regx.group(1)<tab><tab><IF-STMT><tab><tab><tab>self.seq_len = int(self.line.strip().split()[1])<tab><tab>self.line = self.handle.readline().strip()<tab>return meta",0,"if self . line . startswith ( ""Match_columns"" ) :",if self . seq_len is None :,0.05928814345545639,11.56970650765539,0.42857142857142855
"def init_sequence(self, coll_name, seq_config):<tab>if not isinstance(seq_config, list):<tab><tab>raise Exception('""sequence"" config must be a list')<tab>handlers = []<tab>for entry in seq_config:<tab><tab><IF-STMT><tab><tab><tab>raise Exception('""sequence"" entry must be a dict')<tab><tab>name = entry.get(""name"", """")<tab><tab>handler = self.load_coll(name, entry)<tab><tab>handlers.append(handler)<tab>return HandlerSeq(handlers)",1,"if not isinstance ( entry , dict ) :","if not isinstance ( entry , dict ) :",0.75,100.00000000000004,1.0
"def change_args_to_dict(string):<tab>if string is None:<tab><tab>return None<tab>ans = []<tab>strings = string.split(""\n"")<tab>ind = 1<tab>start = 0<tab>while ind <= len(strings):<tab><tab>if ind < len(strings) and strings[ind].startswith("" ""):<tab><tab><tab>ind += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ans.append(""\n"".join(strings[start:ind]))<tab><tab><tab>start = ind<tab><tab><tab>ind += 1<tab>d = {}<tab>for line in ans:<tab><tab>if "":"" in line and len(line) > 0:<tab><tab><tab>lines = line.split("":"")<tab><tab><tab>d[lines[0]] = lines[1].strip()<tab>return d",0,if start < ind :,if start :,0.06767423853569741,1e-10,0.7
"def wait(self):<tab>while True:<tab><tab>return_code = self._process.poll()<tab><tab>if return_code is not None:<tab><tab><tab>line = self._process.stdout.readline().decode(""utf-8"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>log.debug(line.strip(""\n""))<tab>return True",0,"if line == """" :",if not line :,0.03944961859844226,9.930283522141846,0.45
"def __getattr__(self, key):<tab>for tag in self.tag.children:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""name"" in tag.attrs and tag.attrs[""name""] in (key,):<tab><tab><tab>from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation<tab><tab><tab>return DOMImplementation.createHTMLElement(self.doc, tag)<tab>raise AttributeError",0,"if tag . name not in ( ""input"" , ) :","if not hasattr ( tag , ""children"" ) :",0.028008597090229327,9.102154483071216,0.27472527472527475
"def compare_hash(hash_of_gold, path_to_file):<tab>with open(path_to_file, ""rb"") as f:<tab><tab>hash_of_file = hashlib.sha256(f.read()).hexdigest()<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""########## Hash sum of"",<tab><tab><tab><tab>path_to_file,<tab><tab><tab><tab>""differs from the target, the topology will be deleted !!! ##########"",<tab><tab><tab>)<tab><tab><tab>shutil.rmtree(os.path.dirname(path_to_file))",0,if hash_of_file != hash_of_gold :,if hash_of_gold != hash_of_file :,0.2901714209472326,79.71755824799465,1.0
def on_completed2():<tab>doner[0] = True<tab>if not qr:<tab><tab><IF-STMT><tab><tab><tab>observer.on_next(False)<tab><tab><tab>observer.on_completed()<tab><tab>elif donel[0]:<tab><tab><tab>observer.on_next(True)<tab><tab><tab>observer.on_completed(),0,if len ( ql ) > 0 :,if doner [ 0 ] :,0.01983074478100545,7.654112967106117,0.3148148148148148
"def get_other(self, data, items):<tab>is_tuple = False<tab>if type(data) == tuple:<tab><tab>data = list(data)<tab><tab>is_tuple = True<tab>if type(data) == list:<tab><tab>m_items = items.copy()<tab><tab>for idx, item in enumerate(items):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>m_items[idx] = len(data) - abs(item)<tab><tab>for i in sorted(set(m_items), reverse=True):<tab><tab><tab>if i < len(data) and i > -1:<tab><tab><tab><tab>del data[i]<tab><tab>if is_tuple:<tab><tab><tab>return tuple(data)<tab><tab>else:<tab><tab><tab>return data<tab>else:<tab><tab>return None",0,if item < 0 :,if abs ( item ) < abs ( data ) :,0.02616748853192985,5.300156689756295,0.30952380952380953
"def _open_url(cls, url):<tab>if config.browser:<tab><tab>cmd = [config.browser, url]<tab><tab><IF-STMT><tab><tab><tab>print(""running command: %s"" % "" "".join(cmd))<tab><tab>p = Popen(cmd)<tab><tab>p.communicate()<tab>else:<tab><tab>if not config.quiet:<tab><tab><tab>print(""opening URL in browser: %s"" % url)<tab><tab>webbrowser.open_new(url)",1,if not config . quiet :,if not config . quiet :,0.75,100.00000000000004,1.0
"def setLabel(self, s, protect=False):<tab>""""""Set the label of the minibuffer.""""""<tab>c, k, w = self.c, self, self.w<tab>if w:<tab><tab># Support for the curses gui.<tab><tab>if hasattr(g.app.gui, ""set_minibuffer_label""):<tab><tab><tab>g.app.gui.set_minibuffer_label(c, s)<tab><tab>w.setAllText(s)<tab><tab>n = len(s)<tab><tab>w.setSelectionRange(n, n, insert=n)<tab><tab><IF-STMT><tab><tab><tab>k.mb_prefix = s",1,if protect :,if protect :,0.5311706625951745,1e-10,1.0
"def __init__(self, path):<tab>self.symcaches = []<tab>for path in path.split("";""):<tab><tab>if os.path.isdir(path):<tab><tab><tab>self.symcaches.append(SymbolCache(dirname=path))<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>import cobra<tab><tab><tab>self.symcaches.append(cobra.CobraProxy(path))<tab><tab><tab>continue",0,"if path . startswith ( ""cobra://"" ) or path . startswith ( ""cobrassl://"" ) :",if os . path . isfile ( path ) :,0.14864193183659058,3.1492572798507688,0.3496240601503759
"def init_params(net):<tab>""""""Init layer parameters.""""""<tab>for module in net.modules():<tab><tab>if isinstance(module, nn.Conv2d):<tab><tab><tab>init.kaiming_normal(module.weight, mode=""fan_out"")<tab><tab><tab>if module.bias:<tab><tab><tab><tab>init.constant(module.bias, 0)<tab><tab><IF-STMT><tab><tab><tab>init.constant(module.weight, 1)<tab><tab><tab>init.constant(module.bias, 0)<tab><tab>elif isinstance(module, nn.Linear):<tab><tab><tab>init.normal(module.weight, std=1e-3)<tab><tab><tab>if module.bias:<tab><tab><tab><tab>init.constant(module.bias, 0)",0,"elif isinstance ( module , nn . BatchNorm2d ) :",elif module . bias > 0 :,0.015069662838730107,6.050259138270144,0.23863636363636365
"def _diff_dict(self, old, new):<tab>diff = {}<tab>removed = []<tab>added = []<tab>for key, value in old.items():<tab><tab><IF-STMT><tab><tab><tab>removed.append(key)<tab><tab>elif old[key] != new[key]:<tab><tab><tab># modified is indicated by a remove and add<tab><tab><tab>removed.append(key)<tab><tab><tab>added.append(key)<tab>for key, value in new.items():<tab><tab>if key not in old:<tab><tab><tab>added.append(key)<tab>if removed:<tab><tab>diff[""removed""] = sorted(removed)<tab>if added:<tab><tab>diff[""added""] = sorted(added)<tab>return diff",1,if key not in new :,if key not in new :,0.75,100.00000000000004,1.0
"def __init__(self, *args, **kwargs):<tab>_kwargs = {<tab><tab>""max_length"": 20,<tab><tab>""widget"": forms.TextInput(attrs={""autocomplete"": ""off""}),<tab><tab>""label"": _(""Card number""),<tab>}<tab>if ""types"" in kwargs:<tab><tab>self.accepted_cards = set(kwargs.pop(""types""))<tab><tab>difference = self.accepted_cards - VALID_CARDS<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""The following accepted_cards are "" ""unknown: %s"" % difference<tab><tab><tab>)<tab>_kwargs.update(kwargs)<tab>super().__init__(*args, **_kwargs)",0,if difference :,if difference != VALID_CARDS :,0.09791453445388575,1e-10,1.0
"def dumps(self):<tab>sections = []<tab>for name, env_info in self._dependencies_.items():<tab><tab>sections.append(""[ENV_%s]"" % name)<tab><tab>for var, values in sorted(env_info.vars.items()):<tab><tab><tab>tmp = ""%s="" % var<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""[%s]"" % "","".join(['""%s""' % val for val in values])<tab><tab><tab>else:<tab><tab><tab><tab>tmp += ""%s"" % values<tab><tab><tab>sections.append(tmp)<tab>return ""\n"".join(sections)",0,"if isinstance ( values , list ) :","if isinstance ( values , ( list , tuple ) ) :",0.24794863335155284,37.70063804549471,0.8222222222222223
"def air_quality(self):<tab>aqi_data = self._get_aqi_data()<tab>if aqi_data:<tab><tab>if aqi_data.get(""status"") == ""ok"":<tab><tab><tab>aqi_data = self._organize(aqi_data)<tab><tab><tab>aqi_data = self._manipulate(aqi_data)<tab><tab><IF-STMT><tab><tab><tab>self.py3.error(aqi_data.get(""data""))<tab>return {<tab><tab>""cached_until"": self.py3.time_in(self.cache_timeout),<tab><tab>""full_text"": self.py3.safe_format(self.format, aqi_data),<tab>}",0,"elif aqi_data . get ( ""status"" ) == ""error"" :","if aqi_data . get ( ""status"" ) == ""error"" :",0.4400558683966967,93.51334836242394,0.5
"def _blend(x, y):  # pylint: disable=invalid-name<tab>""""""Implements the ""blend"" strategy for `deep_merge`.""""""<tab>if isinstance(x, (dict, OrderedDict)):<tab><tab>if not isinstance(y, (dict, OrderedDict)):<tab><tab><tab>return y<tab><tab>return _merge(x, y, recursion_func=_blend)<tab>if isinstance(x, (list, tuple)):<tab><tab><IF-STMT><tab><tab><tab>return y<tab><tab>result = [_blend(*i) for i in zip(x, y)]<tab><tab>if len(x) > len(y):<tab><tab><tab>result += x[len(y) :]<tab><tab>elif len(x) < len(y):<tab><tab><tab>result += y[len(x) :]<tab><tab>return result<tab>return y",0,"if not isinstance ( y , ( list , tuple ) ) :","if not isinstance ( y , list ) :",0.2220412049535349,43.624306402227546,0.8476190476190476
"def _rate(cls, sample1, sample2):<tab>""Simple rate""<tab>try:<tab><tab>interval = sample2[0] - sample1[0]<tab><tab><IF-STMT><tab><tab><tab>raise Infinity()<tab><tab>delta = sample2[1] - sample1[1]<tab><tab>if delta < 0:<tab><tab><tab>raise UnknownValue()<tab><tab>return (sample2[0], delta / interval, sample2[2], sample2[3])<tab>except Infinity:<tab><tab>raise<tab>except UnknownValue:<tab><tab>raise<tab>except Exception as e:<tab><tab>raise NaN(e)",0,if interval == 0 :,if interval < 0 :,0.33141502097923065,24.736929544091932,1.0
"def wrapped_request_method(*args, **kwargs):<tab>""""""Modifies HTTP headers to include a specified user-agent.""""""<tab>if kwargs.get(""headers"") is not None:<tab><tab><IF-STMT><tab><tab><tab>if user_agent not in kwargs[""headers""][""user-agent""]:<tab><tab><tab><tab># Save the existing user-agent header and tack on our own.<tab><tab><tab><tab>kwargs[""headers""][""user-agent""] = (<tab><tab><tab><tab><tab>f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}'<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>kwargs[""headers""][""user-agent""] = user_agent<tab>else:<tab><tab>kwargs[""headers""] = {""user-agent"": user_agent}<tab>return request_method(*args, **kwargs)",0,"if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :","if ""user-agent"" in kwargs [ ""headers"" ] :",0.1382214844111194,43.48783281197403,0.4
"def remove_addons(auth, resource_object_list):<tab>for config in AbstractNode.ADDONS_AVAILABLE:<tab><tab>try:<tab><tab><tab>settings_model = config.node_settings<tab><tab>except LookupError:<tab><tab><tab>settings_model = None<tab><tab><IF-STMT><tab><tab><tab>addon_list = settings_model.objects.filter(<tab><tab><tab><tab>owner__in=resource_object_list, is_deleted=False<tab><tab><tab>)<tab><tab><tab>for addon in addon_list:<tab><tab><tab><tab>addon.after_delete(auth.user)",1,if settings_model :,if settings_model :,0.5311706625951745,1e-10,1.0
"def Decorator(*args, **kwargs):<tab>delay = 0.2<tab>num_attempts = 15<tab>cur_attempt = 0<tab>while True:<tab><tab>try:<tab><tab><tab>return f(*args, **kwargs)<tab><tab>except exceptions.WebDriverException as e:<tab><tab><tab>logging.warning(""Selenium raised %s"", utils.SmartUnicode(e))<tab><tab><tab>cur_attempt += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>time.sleep(delay)",0,if cur_attempt == num_attempts :,if cur_attempt >= num_attempts :,0.33141502097923065,65.80370064762461,1.0
"def _cleanup_parts_dir(parts_dir, local_plugins_dir, parts):<tab>if os.path.exists(parts_dir):<tab><tab>logger.info(""Cleaning up parts directory"")<tab><tab>for subdirectory in os.listdir(parts_dir):<tab><tab><tab>path = os.path.join(parts_dir, subdirectory)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>shutil.rmtree(path)<tab><tab><tab><tab>except NotADirectoryError:<tab><tab><tab><tab><tab>os.remove(path)<tab>for part in parts:<tab><tab>part.mark_cleaned(steps.BUILD)<tab><tab>part.mark_cleaned(steps.PULL)",0,if path != local_plugins_dir :,if os . path . exists ( path ) :,0.025806626984353938,5.522397783539471,0.3538461538461538
"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]):<tab>if node_pos[""reach_leaf_node""].all():<tab><tab>return node_pos<tab>for t_idx, tree in enumerate(trees):<tab><tab>cur_node_idx = node_pos[""node_pos""][t_idx]<tab><tab># reach leaf<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree(<tab><tab><tab>tree, sample, cur_node_idx<tab><tab>)<tab><tab>if reach_leaf:<tab><tab><tab>node_pos[""reach_leaf_node""][t_idx] = True<tab><tab>node_pos[""node_pos""][t_idx] = rs<tab>return node_pos",1,if cur_node_idx == - 1 :,if cur_node_idx == - 1 :,0.75,100.00000000000004,1.0
"def get_measurements(self, pipeline, object_name, category):<tab>if self.get_categories(pipeline, object_name) == [category]:<tab><tab>results = []<tab><tab>if self.do_corr_and_slope:<tab><tab><tab>if object_name == ""Image"":<tab><tab><tab><tab>results += [""Correlation"", ""Slope""]<tab><tab><tab>else:<tab><tab><tab><tab>results += [""Correlation""]<tab><tab>if self.do_overlap:<tab><tab><tab>results += [""Overlap"", ""K""]<tab><tab><IF-STMT><tab><tab><tab>results += [""Manders""]<tab><tab>if self.do_rwc:<tab><tab><tab>results += [""RWC""]<tab><tab>if self.do_costes:<tab><tab><tab>results += [""Costes""]<tab><tab>return results<tab>return []",1,if self . do_manders :,if self . do_manders :,0.75,100.00000000000004,1.0
"def create_connection(self, infos, f2, laddr_infos, protocol):<tab>for family in infos:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for laddr in laddr_infos:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>except OSError:<tab><tab><tab><tab><tab><tab>protocol = ""foo""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>continue<tab><tab>except OSError:<tab><tab><tab>protocol = ""bar""<tab><tab>else:<tab><tab><tab>break<tab>else:<tab><tab>raise<tab>return protocol",0,if f2 :,if family == f2 :,0.09791453445388575,1e-10,0.45
"def app_middleware(next, root, info, **kwargs):<tab>app_auth_header = ""HTTP_AUTHORIZATION""<tab>prefix = ""bearer""<tab>request = info.context<tab>if request.path == API_PATH:<tab><tab>if not hasattr(request, ""app""):<tab><tab><tab>request.app = None<tab><tab><tab>auth = request.META.get(app_auth_header, """").split()<tab><tab><tab>if len(auth) == 2:<tab><tab><tab><tab>auth_prefix, auth_token = auth<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>request.app = SimpleLazyObject(lambda: get_app(auth_token))<tab>return next(root, info, **kwargs)",0,if auth_prefix . lower ( ) == prefix :,if auth_prefix == prefix :,0.07697997421843798,41.938051117049184,0.4807692307692308
"def when(self, matches, context):<tab>ret = []<tab>for episode in matches.named(""episode"", lambda match: len(match.initiator) == 1):<tab><tab>group = matches.markers.at_match(<tab><tab><tab>episode, lambda marker: marker.name == ""group"", index=0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>if not matches.range(<tab><tab><tab><tab>*group.span, predicate=lambda match: match.name == ""title""<tab><tab><tab>):<tab><tab><tab><tab>ret.append(episode)<tab>return ret",1,if group :,if group :,0.5311706625951745,1e-10,1.0
def locate_via_pep514(spec):<tab>with _PY_LOCK:<tab><tab>if not _PY_AVAILABLE:<tab><tab><tab>from . import pep514<tab><tab><tab>_PY_AVAILABLE.extend(pep514.discover_pythons())<tab><tab><tab>_PY_AVAILABLE.append(CURRENT)<tab>for cur_spec in _PY_AVAILABLE:<tab><tab><IF-STMT><tab><tab><tab>return cur_spec.path,0,if cur_spec . satisfies ( spec ) :,if cur_spec . path == spec . path :,0.07458309604039792,34.48444257953326,0.5818181818181818
"def setCorkImageDefault(self):<tab>if settings.corkBackground[""image""] != """":<tab><tab>i = self.cmbCorkImage.findData(settings.corkBackground[""image""])<tab><tab><IF-STMT><tab><tab><tab>self.cmbCorkImage.setCurrentIndex(i)",1,if i != - 1 :,if i != - 1 :,0.75,100.00000000000004,1.0
"def _split_key(key):<tab>if isinstance(key, util.string_types):<tab><tab># coerce fooload('*') into ""default loader strategy""<tab><tab>if key == _WILDCARD_TOKEN:<tab><tab><tab>return (_DEFAULT_TOKEN,)<tab><tab># coerce fooload("".*"") into ""wildcard on default entity""<tab><tab><IF-STMT><tab><tab><tab>key = key[1:]<tab><tab>return key.split(""."")<tab>else:<tab><tab>return (key,)",0,"elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :","elif key . startswith ( ""*"" ) :",0.33586253664386345,36.3194176525749,1.0
"def detach_volume(self, volume):<tab># We need to find the node using this volume<tab>for node in self.list_nodes():<tab><tab><IF-STMT><tab><tab><tab># This node has only one associated image. It is not the one we<tab><tab><tab># are after.<tab><tab><tab>continue<tab><tab>for disk in node.image:<tab><tab><tab>if disk.id == volume.id:<tab><tab><tab><tab># Node found. We can now detach the volume<tab><tab><tab><tab>disk_id = disk.extra[""disk_id""]<tab><tab><tab><tab>return self._do_detach_volume(node.id, disk_id)<tab>return False",0,if type ( node . image ) is not list :,if node . image is None :,0.09232506292562088,16.417223692914014,0.2
"def create(self, private=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Creating private channel %s."", self)<tab><tab><tab>self._bot.api_call(<tab><tab><tab><tab>""conversations.create"", data={""name"": self.name, ""is_private"": True}<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>log.info(""Creating channel %s."", self)<tab><tab><tab>self._bot.api_call(""conversations.create"", data={""name"": self.name})<tab>except SlackAPIResponseError as e:<tab><tab>if e.error == ""user_is_bot"":<tab><tab><tab>raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)",1,if private :,if private :,0.5311706625951745,1e-10,1.0
"def test_dataset_has_valid_etag(self, dataset_name):<tab>py_script_path = list(filter(lambda x: x, dataset_name.split(""/"")))[-1] + "".py""<tab>dataset_url = hf_bucket_url(dataset_name, filename=py_script_path, dataset=True)<tab>etag = None<tab>try:<tab><tab>response = requests.head(<tab><tab><tab>dataset_url, allow_redirects=True, proxies=None, timeout=10<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>etag = response.headers.get(""Etag"")<tab>except (EnvironmentError, requests.exceptions.Timeout):<tab><tab>pass<tab>self.assertIsNotNone(etag)",0,if response . status_code == 200 :,"if response . status_code == 200 and ""Etag"" in response . headers :",0.3716074172103581,46.24892603869298,0.4880952380952381
"def set_dir_modes(self, dirname, mode):<tab>if not self.is_chmod_supported():<tab><tab>return<tab>for dirpath, dirnames, fnames in os.walk(dirname):<tab><tab>if os.path.islink(dirpath):<tab><tab><tab>continue<tab><tab>log.info(""changing mode of %s to %o"", dirpath, mode)<tab><tab><IF-STMT><tab><tab><tab>os.chmod(dirpath, mode)",0,if not self . dry_run :,"if not os . access ( dirpath , os . W_OK ) :",0.11996603225255313,6.608973813188645,0.4033613445378151
"def _clean(self):<tab>logger.info(""Cleaning up..."")<tab>if self._process is not None:<tab><tab><IF-STMT><tab><tab><tab>for _ in range(3):<tab><tab><tab><tab>self._process.terminate()<tab><tab><tab><tab>time.sleep(0.5)<tab><tab><tab><tab>if self._process.poll() is not None:<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self._process.kill()<tab><tab><tab><tab>self._process.wait()<tab><tab><tab><tab>logger.error(""KILLED"")<tab>if os.path.exists(self._tmp_dir):<tab><tab>shutil.rmtree(self._tmp_dir)<tab>self._process = None<tab>self._ws = None<tab>logger.info(""Cleanup complete"")",0,if self . _process . poll ( ) is None :,if self . _process . poll ( ) is not None :,0.5550941651264264,79.10665071754353,0.7032967032967034
"def iter_chars_to_words(self, chars):<tab>current_word = []<tab>for char in chars:<tab><tab>if not self.keep_blank_chars and char[""text""].isspace():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield current_word<tab><tab><tab><tab>current_word = []<tab><tab>elif current_word and self.char_begins_new_word(current_word, char):<tab><tab><tab>yield current_word<tab><tab><tab>current_word = [char]<tab><tab>else:<tab><tab><tab>current_word.append(char)<tab>if current_word:<tab><tab>yield current_word",0,if current_word :,"if current_word and self . char_begins_old_word ( current_word , char ) :",0.0764445915324824,1e-10,0.3684210526315789
"def _lookup(components, specs, provided, name, i, l):<tab>if i < l:<tab><tab>for spec in specs[i].__sro__:<tab><tab><tab>comps = components.get(spec)<tab><tab><tab>if comps:<tab><tab><tab><tab>r = _lookup(comps, specs, provided, name, i + 1, l)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return r<tab>else:<tab><tab>for iface in provided:<tab><tab><tab>comps = components.get(iface)<tab><tab><tab>if comps:<tab><tab><tab><tab>r = comps.get(name)<tab><tab><tab><tab>if r is not None:<tab><tab><tab><tab><tab>return r<tab>return None",1,if r is not None :,if r is not None :,0.75,100.00000000000004,1.0
"def run(cmd, task=None):<tab>process = subprocess.Popen(<tab><tab>cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True<tab>)<tab>output_lines = []<tab>while True:<tab><tab>line = process.stdout.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>line = line.decode(""utf-8"")<tab><tab>output_lines += [line]<tab><tab>logger.info(line.rstrip(""\n""))<tab>process.stdout.close()<tab>exit_code = process.wait()<tab>if exit_code:<tab><tab>output = """".join(output_lines)<tab><tab>raise subprocess.CalledProcessError(exit_code, cmd, output=output)",1,if not line :,if not line :,0.75,100.00000000000004,1.0
"def process_response(self, request, response):<tab>if (<tab><tab>response.status_code == 404<tab><tab>and request.path_info.endswith(""/"")<tab><tab>and not is_valid_path(request.path_info)<tab><tab>and is_valid_path(request.path_info[:-1])<tab>):<tab><tab># Use request.path because we munged app/locale in path_info.<tab><tab>newurl = request.path[:-1]<tab><tab><IF-STMT><tab><tab><tab>with safe_query_string(request):<tab><tab><tab><tab>newurl += ""?"" + request.META[""QUERY_STRING""]<tab><tab>return HttpResponsePermanentRedirect(newurl)<tab>return response",0,if request . GET :,"if request . META [ ""QUERY_STRING"" ] :",0.1102731445124358,13.545994273378144,0.6
"def dependencies(self):<tab>deps = []<tab>midx = None<tab>if self.ref is not None:<tab><tab>query = TypeQuery(self.ref)<tab><tab>super = query.execute(self.schema)<tab><tab>if super is None:<tab><tab><tab>log.debug(self.schema)<tab><tab><tab>raise TypeNotFound(self.ref)<tab><tab><IF-STMT><tab><tab><tab>deps.append(super)<tab><tab><tab>midx = 0<tab>return (midx, deps)",0,if not super . builtin ( ) :,if super not in deps :,0.0212102604246891,8.22487964923291,0.2653061224489796
"def _get_vtkjs(self):<tab>if self._vtkjs is None and self.object is not None:<tab><tab>if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with open(self.object, ""rb"") as f:<tab><tab><tab><tab><tab>vtkjs = f.read()<tab><tab><tab>else:<tab><tab><tab><tab>data_url = urlopen(self.object)<tab><tab><tab><tab>vtkjs = data_url.read()<tab><tab>elif hasattr(self.object, ""read""):<tab><tab><tab>vtkjs = self.object.read()<tab><tab>self._vtkjs = vtkjs<tab>return self._vtkjs",0,if isfile ( self . object ) :,"if hasattr ( self . object , ""open"" ) :",0.23923832013822932,26.20251007173262,0.6666666666666666
"def _save(self):<tab>fd, tempname = tempfile.mkstemp()<tab>fd = os.fdopen(fd, ""w"")<tab>json.dump(self._cache, fd, indent=2, separators=("","", "": ""))<tab>fd.close()<tab># Silently ignore errors<tab>try:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(os.path.dirname(self.filename))<tab><tab>shutil.move(tempname, self.filename)<tab>except (IOError, OSError):<tab><tab>os.remove(tempname)",1,if not os . path . exists ( os . path . dirname ( self . filename ) ) :,if not os . path . exists ( os . path . dirname ( self . filename ) ) :,1.0,100.00000000000004,1.0
"def refiner_configs(self):<tab>rv = {}<tab>for refiner in refiner_manager:<tab><tab><IF-STMT><tab><tab><tab>rv[refiner.name] = {k: v for k, v in self.config.items(refiner.name)}<tab>return rv",0,if self . config . has_section ( refiner . name ) :,if refiner . name in self . config :,0.07764708473603875,18.402097851927994,0.27472527472527475
"def com_slice(self, primary, node, assigning):<tab># short_slice:  [lower_bound] "":"" [upper_bound]<tab>lower = upper = None<tab>if len(node.children) == 2:<tab><tab><IF-STMT><tab><tab><tab>upper = self.com_node(node.children[1])<tab><tab>else:<tab><tab><tab>lower = self.com_node(node.children[0])<tab>elif len(node.children) == 3:<tab><tab>lower = self.com_node(node.children[0])<tab><tab>upper = self.com_node(node.children[2])<tab>return Slice(primary, assigning, lower, upper, lineno=extractLineNo(node))",0,if node . children [ 0 ] . type == token . COLON :,"if node . children [ 0 ] == "":"" :",0.3158656789859435,45.823488902304994,0.6029411764705882
"def close(self, *args, **kwargs):<tab>super(mytqdm, self).close(*args, **kwargs)<tab># If it was not run in a notebook, sp is not assigned, check for it<tab>if hasattr(self, ""sp""):<tab><tab># Try to detect if there was an error or KeyboardInterrupt<tab><tab># in manual mode: if n < total, things probably got wrong<tab><tab>if self.total and self.n < self.total:<tab><tab><tab>self.sp(bar_style=""danger"")<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.sp(bar_style=""success"")<tab><tab><tab>else:<tab><tab><tab><tab>self.sp(close=True)",0,if self . leave :,if self . n > self . n :,0.18855955653510317,19.070828081828378,0.49333333333333335
"def test_alloc(self):<tab>b = bytearray()<tab>alloc = b.__alloc__()<tab>self.assertTrue(alloc >= 0)<tab>seq = [alloc]<tab>for i in range(100):<tab><tab>b += b""x""<tab><tab>alloc = b.__alloc__()<tab><tab>self.assertTrue(alloc >= len(b))<tab><tab><IF-STMT><tab><tab><tab>seq.append(alloc)",0,if alloc not in seq :,if seq :,0.050438393472541504,1e-10,0.2333333333333333
"def flush_file(self, key, f):<tab>f.flush()<tab><IF-STMT><tab><tab>f.compress = zlib.compressobj(<tab><tab><tab>9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0<tab><tab>)<tab>if len(self.files) > self.MAX_OPEN_FILES:<tab><tab>if self.compress:<tab><tab><tab>open_files = sum(1 for f in self.files.values() if f.fileobj is not None)<tab><tab><tab>if open_files > self.MAX_OPEN_FILES:<tab><tab><tab><tab>f.fileobj.close()<tab><tab><tab><tab>f.fileobj = None<tab><tab>else:<tab><tab><tab>f.close()<tab><tab><tab>self.files.pop(key)",0,if self . compress :,if self . compress is None :,0.36879024661621806,43.47208719449914,0.611111111111111
"def _run(self):<tab># Low-level run method to do the actual scheduling loop.<tab>self.running = True<tab>while self.running:<tab><tab>try:<tab><tab><tab>self.sched.run()<tab><tab>except Exception as x:<tab><tab><tab>logging.error(<tab><tab><tab><tab>""Error during scheduler execution: %s"" % str(x), exc_info=True<tab><tab><tab>)<tab><tab># queue is empty; sleep a short while before checking again<tab><tab><IF-STMT><tab><tab><tab>time.sleep(5)",0,if self . running :,if self . queue is empty :,0.2005939911646859,26.269098944241588,0.38095238095238093
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_max_rows(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 16 :,if tt == 16 :,0.75,100.00000000000004,1.0
"def check(dbdef):<tab>""drop script must clear the database""<tab>for version in dbdef:<tab><tab>connector = MemConnector().bound(None)<tab><tab>create(dbdef, version, connector)<tab><tab>drop(dbdef, version, connector)<tab><tab>remaining = connector.execute(<tab><tab><tab>""SELECT * FROM sqlite_master WHERE name NOT LIKE 'sqlite_%'""<tab><tab>).fetchall()<tab><tab><IF-STMT><tab><tab><tab>yield ""{0}:drop.sql"".format(version), remaining",1,if remaining :,if remaining :,0.5311706625951745,1e-10,1.0
"def test_open_overwrite_offset_size(self, sftp):<tab>""""""Test writing data at a specific offset""""""<tab>f = None<tab>try:<tab><tab>self._create_file(""file"", ""xxxxyyyy"")<tab><tab>f = yield from sftp.open(""file"", ""r+"")<tab><tab>yield from f.write(""zz"", 3)<tab><tab>yield from f.close()<tab><tab>with open(""file"") as localf:<tab><tab><tab>self.assertEqual(localf.read(), ""xxxzzyyy"")<tab>finally:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>yield from f.close()<tab><tab>remove(""file"")",1,if f :,if f :,0.5311706625951745,1e-10,1.0
"def pump():<tab>import sys as _sys<tab>while self.countdown_active():<tab><tab>if not (self.connected(""send"") and other.connected(""recv"")):<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>data = other.recv(timeout=0.05)<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if not data:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>self.send(data)<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab>if not _sys:<tab><tab><tab>return<tab>self.shutdown(""send"")<tab>other.shutdown(""recv"")",0,if not _sys :,if not data :,0.34586199776872373,27.534765745159184,0.6666666666666666
"def parse_results(cwd):<tab>optimal_dd = None<tab>optimal_measure = numpy.inf<tab>for tup in tools.find_conf_files(cwd):<tab><tab>dd = tup[1]<tab><tab>if ""results.train_y_misclass"" in dd:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>optimal_measure = dd[""results.train_y_misclass""]<tab><tab><tab><tab>optimal_dd = dd<tab>print(""Optimal results.train_y_misclass:"", str(optimal_measure))<tab>for key, value in optimal_dd.items():<tab><tab>if ""hyper_parameters"" in key:<tab><tab><tab>print(key + "": "" + str(value))",0,"if dd [ ""results.train_y_misclass"" ] < optimal_measure :","if ""results.train_y_misclass"" in dd :",0.020977836961063236,47.3930294822252,0.4772727272727273
"def valid(self):<tab>valid = True<tab><IF-STMT><tab><tab>return valid<tab>else:<tab><tab>try:<tab><tab><tab>with io.open(self.pathfile, ""w"", encoding=""utf-8"") as f:<tab><tab><tab><tab>f.close()  # do nothing<tab><tab>except OSError:<tab><tab><tab>valid = False<tab><tab>if os.path.exists(self.pathfile):<tab><tab><tab>os.remove(self.pathfile)<tab><tab>return valid",1,if os . path . exists ( self . pathfile ) :,if os . path . exists ( self . pathfile ) :,0.75,100.00000000000004,1.0
"def __getitem__(self, key):<tab>try:<tab><tab>value = self.cache[key]<tab>except KeyError:<tab><tab>f = BytesIO(self.dict[key.encode(self.keyencoding)])<tab><tab>value = Unpickler(f).load()<tab><tab><IF-STMT><tab><tab><tab>self.cache[key] = value<tab>return value",0,if self . writeback :,if value is not None :,0.030286782520570012,9.652434877402245,0.1875
"def hasMenu(cls, callingWindow, mainItem, selection, *fullContexts):<tab>for i, fullContext in enumerate(fullContexts):<tab><tab>srcContext = fullContext[0]<tab><tab>for menuHandler in cls.menus:<tab><tab><tab>m = menuHandler()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>return False",0,"if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :",if m == srcContext :,0.015612968593192996,4.3074986800341035,0.40601503759398494
"def lr_read_tables(module=tab_module, optimize=0):<tab>global _lr_action, _lr_goto, _lr_productions, _lr_method<tab>try:<tab><tab>exec(""import %s as parsetab"" % module)<tab><tab>global parsetab  # declare the name of the imported module<tab><tab><IF-STMT><tab><tab><tab>_lr_action = parsetab._lr_action<tab><tab><tab>_lr_goto = parsetab._lr_goto<tab><tab><tab>_lr_productions = parsetab._lr_productions<tab><tab><tab>_lr_method = parsetab._lr_method<tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>return 0<tab>except (ImportError, AttributeError):<tab><tab>return 0",0,if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,if optimize :,0.004788391465025465,1e-10,0.4065934065934066
"def _Determine_Do(self):<tab>if sys.platform.startswith(""win""):<tab><tab>self.applicable = 1<tab><tab>for opt, optarg in self.chosenOptions:<tab><tab><tab>if opt == ""--moz-tools"":<tab><tab><tab><tab>self.value = os.path.abspath(os.path.normpath(optarg))<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.value = os.environ[self.name]<tab><tab><tab>else:<tab><tab><tab><tab>self.value = None<tab>else:<tab><tab>self.applicable = 0<tab>self.determined = 1",0,if os . environ . has_key ( self . name ) :,if self . name in os . environ :,0.07764708473603875,18.402097851927994,0.27472527472527475
"def parse_chunked(self, unreader):<tab>(size, rest) = self.parse_chunk_size(unreader)<tab>while size > 0:<tab><tab>while size > len(rest):<tab><tab><tab>size -= len(rest)<tab><tab><tab>yield rest<tab><tab><tab>rest = unreader.read()<tab><tab><tab>if not rest:<tab><tab><tab><tab>raise NoMoreData()<tab><tab>yield rest[:size]<tab><tab># Remove \r\n after chunk<tab><tab>rest = rest[size:]<tab><tab>while len(rest) < 2:<tab><tab><tab>rest += unreader.read()<tab><tab><IF-STMT><tab><tab><tab>raise ChunkMissingTerminator(rest[:2])<tab><tab>(size, rest) = self.parse_chunk_size(unreader, data=rest[2:])",0,"if rest [ : 2 ] != b""\r\n"" :",if len ( rest ) < 2 :,0.01786335094255824,2.8730831956184355,0.38181818181818183
"def _scroll_down(self, cli):<tab>""Scroll window down.""<tab>info = self.render_info<tab>if self.vertical_scroll < info.content_height - info.window_height:<tab><tab><IF-STMT><tab><tab><tab>self.content.move_cursor_down(cli)<tab><tab>self.vertical_scroll += 1",0,if info . cursor_position . y <= info . configured_scroll_offsets . top :,if self . content :,0.05114397580040156,0.699933150083178,0.2698412698412698
"def _add_defaults_data_files(self):<tab># getting distribution.data_files<tab>if self.distribution.has_data_files():<tab><tab>for item in self.distribution.data_files:<tab><tab><tab>if isinstance(item, str):<tab><tab><tab><tab># plain file<tab><tab><tab><tab>item = convert_path(item)<tab><tab><tab><tab>if os.path.isfile(item):<tab><tab><tab><tab><tab>self.filelist.append(item)<tab><tab><tab>else:<tab><tab><tab><tab># a (dirname, filenames) tuple<tab><tab><tab><tab>dirname, filenames = item<tab><tab><tab><tab>for f in filenames:<tab><tab><tab><tab><tab>f = convert_path(f)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.filelist.append(f)",1,if os . path . isfile ( f ) :,if os . path . isfile ( f ) :,0.75,100.00000000000004,1.0
"def list_stuff(self, upto=10, start_after=-1):<tab>for i in range(upto):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if i == 2 and self.count < 1:<tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>if i == 7 and self.count < 4:<tab><tab><tab>self.count += 1<tab><tab><tab>raise TemporaryProblem<tab><tab>yield i",0,if i <= start_after :,if i < start_after :,0.08141502097923063,51.54486831107658,1.0
"def is_open(self):<tab>if self.signup_code:<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if self.messages.get(""invalid_signup_code""):<tab><tab><tab><tab>messages.add_message(<tab><tab><tab><tab><tab>self.request,<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""level""],<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""text""].format(<tab><tab><tab><tab><tab><tab>**{<tab><tab><tab><tab><tab><tab><tab>""code"": self.get_code(),<tab><tab><tab><tab><tab><tab>}<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>)<tab>return settings.ACCOUNT_OPEN_SIGNUP",0,if self . signup_code_present :,if self . get_code ( ) :,0.11726065783135259,23.356898886410015,1.0
"def on_delete_from_disk(self, widget, data=None):<tab>model, iter = self.get_selection().get_selected()<tab>if iter:<tab><tab>path = model.get_value(iter, COLUMN_PATH)<tab><tab><IF-STMT><tab><tab><tab>ErrorDialog(_(""Can't delete system item from disk."")).launch()<tab><tab>else:<tab><tab><tab>os.remove(path)<tab>self.update_items()",0,if self . is_defaultitem ( path ) :,if not os . path . exists ( path ) :,0.16311705995863668,25.965358893403383,0.25274725274725274
"def get_detections_for_batch(self, images):<tab>images = images[..., ::-1]<tab>detected_faces = self.face_detector.detect_from_batch(images.copy())<tab>results = []<tab>for i, d in enumerate(detected_faces):<tab><tab><IF-STMT><tab><tab><tab>results.append(None)<tab><tab><tab>continue<tab><tab>d = d[0]<tab><tab>d = np.clip(d, 0, None)<tab><tab>x1, y1, x2, y2 = map(int, d[:-1])<tab><tab>results.append((x1, y1, x2, y2))<tab>return results",0,if len ( d ) == 0 :,if i == len ( detected_faces ) - 1 :,0.1345270750519636,10.04916995660316,0.2857142857142857
def on_update(self):<tab>#<tab># Calculate maximum # of planes per well<tab>#<tab>self.max_per_well = 0<tab>for pd in list(self.plate_well_site.values()):<tab><tab>for wd in list(pd.values()):<tab><tab><tab>nplanes = sum([len(x) for x in list(wd.values())])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.max_per_well = nplanes<tab>for registrant in self.registrants:<tab><tab>registrant(),1,if nplanes > self . max_per_well :,if nplanes > self . max_per_well :,0.75,100.00000000000004,1.0
"def is_writable(self, path):<tab>result = False<tab>while not result:<tab><tab>if os.path.exists(path):<tab><tab><tab>result = os.access(path, os.W_OK)<tab><tab><tab>break<tab><tab>parent = os.path.dirname(path)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>path = parent<tab>return result",1,if parent == path :,if parent == path :,0.75,100.00000000000004,1.0
"def _check_seed(self, seed):<tab>if seed is not None:<tab><tab><IF-STMT><tab><tab><tab>self._raise_error(<tab><tab><tab><tab>""The random number generator seed value, seed, should be integer type or None.""<tab><tab><tab>)<tab><tab>if seed < 0:<tab><tab><tab>self._raise_error(<tab><tab><tab><tab>""The random number generator seed value, seed, should be non-negative integer or None.""<tab><tab><tab>)",0,if type ( seed ) != int :,"if not isinstance ( seed , ( int , long ) ) :",0.08089627816227433,8.130850857597444,0.234375
"def write(self, x):<tab># try to use backslash and surrogate escape strategies before failing<tab>self._errors = ""backslashescape"" if self.encoding != ""mbcs"" else ""surrogateescape""<tab>try:<tab><tab>return io.TextIOWrapper.write(self, to_text(x, errors=self._errors))<tab>except UnicodeDecodeError:<tab><tab><IF-STMT><tab><tab><tab>self._errors = ""surrogateescape""<tab><tab>else:<tab><tab><tab>self._errors = ""replace""<tab><tab>return io.TextIOWrapper.write(self, to_text(x, errors=self._errors))",0,"if self . _errors != ""surrogateescape"" :","if self . encoding == ""mbcs"" :",0.3405653141935552,20.772794588721627,0.7222222222222222
"def post(self, request, *args, **kwargs):<tab>validated_session = []<tab>for session_id in request.data:<tab><tab>session = get_object_or_none(Session, id=session_id)<tab><tab><IF-STMT><tab><tab><tab>validated_session.append(session_id)<tab><tab><tab>self.model.objects.create(<tab><tab><tab><tab>name=""kill_session"",<tab><tab><tab><tab>args=session.id,<tab><tab><tab><tab>terminal=session.terminal,<tab><tab><tab>)<tab>return Response({""ok"": validated_session})",0,if session and not session . is_finished :,if session . is_valid :,0.0443627239435392,31.850355294022695,0.4666666666666666
"def _has_list_or_dict_var_value_before(self, arg_index):<tab>for idx, value in enumerate(self.args):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if variablematcher.is_list_variable(<tab><tab><tab>value<tab><tab>) and not variablematcher.is_list_variable_subitem(value):<tab><tab><tab>return True<tab><tab>if robotapi.is_dict_var(value) and not variablematcher.is_dict_var_access(<tab><tab><tab>value<tab><tab>):<tab><tab><tab>return True<tab>return False",0,if idx > arg_index :,if idx != arg_index :,0.33141502097923065,41.11336169005198,1.0
"def test_return_correct_type(self):<tab>for proto in protocols:<tab><tab># Protocol 0 supports only ASCII strings.<tab><tab><IF-STMT><tab><tab><tab>self._check_return_correct_type(""abc"", 0)<tab><tab>else:<tab><tab><tab>for obj in [b""abc\n"", ""abc\n"", -1, -1.1 * 0.1, str]:<tab><tab><tab><tab>self._check_return_correct_type(obj, proto)",1,if proto == 0 :,if proto == 0 :,0.75,100.00000000000004,1.0
"def backward_impl(self, inputs, outputs, prop_down, accum):<tab># inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or<tab># [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph]<tab># Args<tab>axis = self.forward_func.info.args[""axis""]<tab># Compute<tab>## w.r.t. dy<tab>if prop_down[-1]:<tab><tab>g_dy = inputs[-1].grad<tab><tab>g_dy_ = F.stack(*[o.grad for o in outputs], axis=axis)<tab><tab><IF-STMT><tab><tab><tab>g_dy += g_dy_<tab><tab>else:<tab><tab><tab>g_dy.copy_from(g_dy_)",1,if accum [ - 1 ] :,if accum [ - 1 ] :,0.75,100.00000000000004,1.0
"def remove(self, url):<tab>try:<tab><tab>i = self.items.index(url)<tab>except (ValueError, IndexError):<tab><tab>pass<tab>else:<tab><tab>was_selected = i in self.selectedindices()<tab><tab>self.list.delete(i)<tab><tab>del self.items[i]<tab><tab>if not self.items:<tab><tab><tab>self.mp.hidepanel(self.name)<tab><tab>elif was_selected:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>self.list.select_set(i)",0,if i >= len ( self . items ) :,if len ( self . items ) > 1 :,0.4051781302154068,51.7679965241078,0.2857142857142857
"def prepend(self, value):<tab>""""""prepend value to nodes""""""<tab>root, root_text = self._get_root(value)<tab>for i, tag in enumerate(self):<tab><tab>if not tag.text:<tab><tab><tab>tag.text = """"<tab><tab>if len(root) > 0:<tab><tab><tab>root[-1].tail = tag.text<tab><tab><tab>tag.text = root_text<tab><tab>else:<tab><tab><tab>tag.text = root_text + tag.text<tab><tab><IF-STMT><tab><tab><tab>root = deepcopy(list(root))<tab><tab>tag[:0] = root<tab><tab>root = tag[: len(root)]<tab>return self",0,if i > 0 :,if i == len ( root ) - 1 :,0.04589139340883146,8.29519350710986,0.40476190476190477
"def _get_tracks_compositors_list():<tab>tracks_list = []<tab>tracks = current_sequence().tracks<tab>compositors = current_sequence().compositors<tab>for track_index in range(1, len(tracks) - 1):<tab><tab>track_compositors = []<tab><tab>for j in range(0, len(compositors)):<tab><tab><tab>comp = compositors[j]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>track_compositors.append(comp)<tab><tab>tracks_list.append(track_compositors)<tab>return tracks_list",0,if comp . transition . b_track == track_index :,if comp . track_index == track_index :,0.1533711111796332,47.26710158823674,0.7307692307692308
"def __getattr__(self, name):<tab>if name in self._sections:<tab><tab>return ""\n"".join(self._sections[name])<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return """"<tab><tab>else:<tab><tab><tab>raise ConanException(""ConfigParser: Unrecognized field '%s'"" % name)",0,if self . _allowed_fields and name in self . _allowed_fields :,"if name == ""blank"" :",0.012417879185700129,2.3595365419339505,0.28571428571428575
"def get_first_param_index(self, group_id, param_group, partition_id):<tab>for index, param in enumerate(param_group):<tab><tab>param_id = self.get_param_id(param)<tab><tab><IF-STMT><tab><tab><tab>return index<tab>return None",0,if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,if param_id == group_id and param_id == partition_id :,0.012039372658594413,14.272129722834098,0.3904761904761905
"def handle_uv_sockets(self, context):<tab>u_socket = self.inputs[""U""]<tab>v_socket = self.inputs[""V""]<tab>if self.cast_mode == ""Sphere"":<tab><tab>u_socket.hide_safe = True<tab><tab>v_socket.hide_safe = True<tab>elif self.cast_mode in [""Cylinder"", ""Prism""]:<tab><tab>v_socket.hide_safe = True<tab><tab><IF-STMT><tab><tab><tab>u_socket.hide_safe = False<tab>else:<tab><tab>if u_socket.hide_safe:<tab><tab><tab>u_socket.hide_safe = False<tab><tab>if v_socket.hide_safe:<tab><tab><tab>v_socket.hide_safe = False",1,if u_socket . hide_safe :,if u_socket . hide_safe :,0.75,100.00000000000004,1.0
"def _scrub_generated_timestamps(self, target_workdir):<tab>""""""Remove the first line of comment from each file if it contains a timestamp.""""""<tab>for root, _, filenames in safe_walk(target_workdir):<tab><tab>for filename in filenames:<tab><tab><tab>source = os.path.join(root, filename)<tab><tab><tab>with open(source, ""r"") as f:<tab><tab><tab><tab>lines = f.readlines()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>with open(source, ""w"") as f:<tab><tab><tab><tab>if not self._COMMENT_WITH_TIMESTAMP_RE.match(lines[0]):<tab><tab><tab><tab><tab>f.write(lines[0])<tab><tab><tab><tab>for line in lines[1:]:<tab><tab><tab><tab><tab>f.write(line)",0,if len ( lines ) < 1 :,if not lines :,0.019930835999227993,7.733712583165139,0.48148148148148145
"def inner(request, *args, **kwargs):<tab>page = request.current_page<tab>if page:<tab><tab>if page.login_required and not request.user.is_authenticated:<tab><tab><tab>return redirect_to_login(<tab><tab><tab><tab>urlquote(request.get_full_path()), settings.LOGIN_URL<tab><tab><tab>)<tab><tab>site = get_current_site()<tab><tab><IF-STMT><tab><tab><tab>return _handle_no_page(request)<tab>return func(request, *args, **kwargs)",0,"if not user_can_view_page ( request . user , page , site ) :",if site . is_anonymous and not site . is_anonymous :,0.11213639271983505,3.2319379532882193,0.24166666666666667
"def flush(self, *args, **kwargs):<tab>with self._lock:<tab><tab>self._last_updated = time.time()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>mailbox.mbox.flush(self, *args, **kwargs)<tab><tab>except OSError:<tab><tab><tab>if ""_create_temporary"" in traceback.format_exc():<tab><tab><tab><tab>self._locked_flush_without_tempfile()<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab><tab>self._last_updated = time.time()",0,"if kwargs . get ( ""in_place"" , False ) :","if ""_create_temporary"" in traceback . format_exc ( ) :",0.029205697404072792,8.47178590796544,0.27472527472527475
"def sanitize_event_keys(kwargs, valid_keys):<tab># Sanity check: Don't honor keys that we don't recognize.<tab>for key in list(kwargs.keys()):<tab><tab>if key not in valid_keys:<tab><tab><tab>kwargs.pop(key)<tab># Truncate certain values over 1k<tab>for key in [""play"", ""role"", ""task"", ""playbook""]:<tab><tab><IF-STMT><tab><tab><tab>if len(kwargs[""event_data""][key]) > 1024:<tab><tab><tab><tab>kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars(<tab><tab><tab><tab><tab>1024<tab><tab><tab><tab>)",0,"if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :",if key in valid_keys :,0.004276611384459993,0.7098113567559734,0.234375
"def parse_auth(val):<tab>if val is not None:<tab><tab>authtype, params = val.split("" "", 1)<tab><tab><IF-STMT><tab><tab><tab>if authtype == ""Basic"" and '""' not in params:<tab><tab><tab><tab># this is the ""Authentication: Basic XXXXX=="" case<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>params = parse_auth_params(params)<tab><tab>return authtype, params<tab>return val",0,if authtype in known_auth_schemes :,if len ( params ) > 0 :,0.026407399022921448,5.795599612995366,0.2698412698412698
"def _memoized(*args):<tab>now = time.time()<tab>try:<tab><tab>value, last_update = self.cache[args]<tab><tab>age = now - last_update<tab><tab>if self._call_count > self.ctl or age > self.ttl:<tab><tab><tab>self._call_count = 0<tab><tab><tab>raise AttributeError<tab><tab>if self.ctl:<tab><tab><tab>self._call_count += 1<tab><tab>return value<tab>except (KeyError, AttributeError):<tab><tab>value = func(*args)<tab><tab><IF-STMT><tab><tab><tab>self.cache[args] = (value, now)<tab><tab>return value<tab>except TypeError:<tab><tab>return func(*args)",0,if value :,if self . ttl :,0.051944022748897464,1e-10,0.36
"def _get_md_bg_color_down(self):<tab>t = self.theme_cls<tab>c = self.md_bg_color  # Default to no change on touch<tab># Material design specifies using darker hue when on Dark theme<tab>if t.theme_style == ""Dark"":<tab><tab>if self.md_bg_color == t.primary_color:<tab><tab><tab>c = t.primary_dark<tab><tab><IF-STMT><tab><tab><tab>c = t.accent_dark<tab>return c",0,elif self . md_bg_color == t . accent_color :,elif self . md_bg_color == t . accident_color :,0.6253119268751697,81.53551038173119,1.0
def _init_table_h():<tab>_table_h = []<tab>for i in range(256):<tab><tab>part_l = i<tab><tab>part_h = 0<tab><tab>for j in range(8):<tab><tab><tab>rflag = part_l & 1<tab><tab><tab>part_l >>= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>part_l |= 1 << 31<tab><tab><tab>part_h >>= 1<tab><tab><tab>if rflag:<tab><tab><tab><tab>part_h ^= 0xD8000000<tab><tab>_table_h.append(part_h)<tab>return _table_h,0,if part_h & 1 :,if j & 1 :,0.39477865547525276,28.641904579795423,0.45
"def migrate_Stats(self):<tab>for old_obj in self.session_old.query(self.model_from[""Stats""]):<tab><tab>if not old_obj.summary:<tab><tab><tab>self.entries_count[""Stats""] -= 1<tab><tab><tab>continue<tab><tab>new_obj = self.model_to[""Stats""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>setattr(new_obj, key, getattr(old_obj, key))<tab><tab>self.session_new.add(new_obj)",0,if key not in old_obj . __table__ . columns :,"if key == ""summary"" :",0.025595153496315533,4.496618206730097,0.4615384615384615
"def get_in_turn_repetition(pred, is_cn=False):<tab>""""""Get in-turn repetition.""""""<tab>if len(pred) == 0:<tab><tab>return 1.0<tab>if isinstance(pred[0], str):<tab><tab>pred = [tok.lower() for tok in pred]<tab><tab>if is_cn:<tab><tab><tab>pred = """".join(pred)<tab>tri_grams = set()<tab>for i in range(len(pred) - 2):<tab><tab>tri_gram = tuple(pred[i : i + 3])<tab><tab><IF-STMT><tab><tab><tab>return 1.0<tab><tab>tri_grams.add(tri_gram)<tab>return 0.0",1,if tri_gram in tri_grams :,if tri_gram in tri_grams :,0.75,100.00000000000004,1.0
"def translate():<tab>assert Lex.next() is AttributeList<tab>reader.read()  # Discard attribute list from reader.<tab>attrs = {}<tab>d = AttributeList.match.groupdict()<tab>for k, v in d.items():<tab><tab>if v is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v = subs_attrs(v)<tab><tab><tab><tab>if v:<tab><tab><tab><tab><tab>parse_attributes(v, attrs)<tab><tab><tab>else:<tab><tab><tab><tab>AttributeList.attrs[k] = v<tab>AttributeList.subs(attrs)<tab>AttributeList.attrs.update(attrs)",0,"if k == ""attrlist"" :","if isinstance ( v , str ) :",0.026407399022921448,6.567274736060395,0.3
"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab>if ""axis"" in self.args:<tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab>if ""momentum"" in self.args:<tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab>if not isinstance(self.momentum, (int, float)):<tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')",0,"if not isinstance ( self . axis , int ) :","if not isinstance ( self . axis , ( int , float ) ) :",0.4731591644097861,53.2800971987552,0.8676470588235294
"def __getattr__(self, attrname):<tab>if attrname in (""visamp"", ""visamperr"", ""visphi"", ""visphierr""):<tab><tab>return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag)<tab>elif attrname in (""cflux"", ""cfluxerr""):<tab><tab><IF-STMT><tab><tab><tab>return ma.masked_array(self.__dict__[""_"" + attrname], mask=self.flag)<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>raise AttributeError(attrname)",0,"if self . __dict__ [ ""_"" + attrname ] != None :","if self . flag == ""masked"" :",0.08822925726207986,7.848774327547447,0.4901960784313726
"def draw(self, context):<tab>layout = self.layout<tab>presets.draw_presets_ops(layout, context=context)<tab>for category in presets.get_category_names():<tab><tab><IF-STMT><tab><tab><tab>if category in preset_category_menus:<tab><tab><tab><tab>class_name = preset_category_menus[category].__name__<tab><tab><tab><tab>layout.menu(class_name)",0,if category in preset_category_menus :,"if hasattr ( preset_category_menus , category ) :",0.029323260600185464,35.65506208559251,0.4
"def __setitem__(self, key, value):<tab>if isinstance(value, (tuple, list)):<tab><tab>info, reference = value<tab><tab>if info not in self._reverse_infos:<tab><tab><tab>self._reverse_infos[info] = len(self._infos)<tab><tab><tab>self._infos.append(info)<tab><tab><IF-STMT><tab><tab><tab>self._reverse_references[reference] = len(self._references)<tab><tab><tab>self._references.append(reference)<tab><tab>self._trails[key] = ""%d,%d"" % (<tab><tab><tab>self._reverse_infos[info],<tab><tab><tab>self._reverse_references[reference],<tab><tab>)<tab>else:<tab><tab>raise Exception(""unsupported type '%s'"" % type(value))",1,if reference not in self . _reverse_references :,if reference not in self . _reverse_references :,0.75,100.00000000000004,1.0
"def format_bpe_text(symbols, delimiter=b""@@""):<tab>""""""Convert a sequence of bpe words into sentence.""""""<tab>words = []<tab>word = b""""<tab>if isinstance(symbols, str):<tab><tab>symbols = symbols.encode()<tab>delimiter_len = len(delimiter)<tab>for symbol in symbols:<tab><tab><IF-STMT><tab><tab><tab>word += symbol[:-delimiter_len]<tab><tab>else:  # end of a word<tab><tab><tab>word += symbol<tab><tab><tab>words.append(word)<tab><tab><tab>word = b""""<tab>return b"" "".join(words)",0,if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,if symbol . endswith ( delimiter ) :,0.033378984856087854,1.325449986659188,0.2738095238095238
"def output_type(data, request, response):<tab>accept = request.accept<tab>if accept in ("""", ""*"", ""/""):<tab><tab>handler = default or handlers and next(iter(handlers.values()))<tab>else:<tab><tab>handler = default<tab><tab>accepted = [accept_quality(accept_type) for accept_type in accept.split("","")]<tab><tab>accepted.sort(key=itemgetter(0))<tab><tab>for _quality, accepted_content_type in reversed(accepted):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler = handlers[accepted_content_type]<tab><tab><tab><tab>break<tab>if not handler:<tab><tab>raise falcon.HTTPNotAcceptable(error)<tab>response.content_type = handler.content_type<tab>return handler(data, request=request, response=response)",1,if accepted_content_type in handlers :,if accepted_content_type in handlers :,0.75,100.00000000000004,1.0
"def _render_raw_list(bytes_items):<tab>flatten_items = []<tab>for item in bytes_items:<tab><tab>if item is None:<tab><tab><tab>flatten_items.append(b"""")<tab><tab>elif isinstance(item, bytes):<tab><tab><tab>flatten_items.append(item)<tab><tab><IF-STMT><tab><tab><tab>flatten_items.append(str(item).encode())<tab><tab>elif isinstance(item, list):<tab><tab><tab>flatten_items.append(_render_raw_list(item))<tab>return b""\n"".join(flatten_items)",0,"elif isinstance ( item , int ) :","elif isinstance ( item , str ) :",0.5329721308532829,59.4603557501361,0.6666666666666666
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_mime_type(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_quality(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 8 :,if tt == 8 :,0.75,100.00000000000004,1.0
"def delete(self, waiters):<tab># Delete flow.<tab>msgs = self.ofctl.get_all_flow(waiters)<tab>for msg in msgs:<tab><tab>for stats in msg.body:<tab><tab><tab>vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.ofctl.delete_flow(stats)<tab>assert len(self.packet_buffer) == 0",0,if vlan_id == self . vlan_id :,if vlan_id == self . ofctl . vlan_id :,0.6764885828225025,76.70387248467654,0.7307692307692308
def missing_push_allowance(push_allowances: List[PushAllowance]) -> bool:<tab>for push_allowance in push_allowances:<tab><tab># a null databaseId indicates this is not a GitHub App.<tab><tab>if push_allowance.actor.databaseId is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True,0,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,if push_allowance . actor . databaseId != push_allowance . actor . databaseId :,0.44796327661685437,23.993173043521193,0.4
"def _cluster_page(self, htmlpage):<tab>template_cluster, preferred = _CLUSTER_NA, None<tab>if self.clustering:<tab><tab>self.clustering.add_page(htmlpage)<tab><tab><IF-STMT><tab><tab><tab>clt = self.clustering.classify(htmlpage)<tab><tab><tab>if clt != -1:<tab><tab><tab><tab>template_cluster = preferred = self.template_names[clt]<tab><tab><tab>else:<tab><tab><tab><tab>template_cluster = _CLUSTER_OUTLIER<tab>return template_cluster, preferred",0,if self . clustering . is_fit :,if self . testing :,0.15703229110448028,19.199242796476852,0.6
"def readlines(self, size=-1):<tab>if self._nbr == self._size:<tab><tab>return []<tab># leave all additional logic to our readline method, we just check the size<tab>out = []<tab>nbr = 0<tab>while True:<tab><tab>line = self.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab>out.append(line)<tab><tab>if size > -1:<tab><tab><tab>nbr += len(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab># END handle size constraint<tab># END readline loop<tab>return out",0,if nbr > size :,if nbr >= self . _size :,0.05286931595839166,22.31618068926665,0.6
"def post_mortem(t=None):<tab># handling the default<tab><IF-STMT><tab><tab># sys.exc_info() returns (type, value, traceback) if an exception is<tab><tab># being handled, otherwise it returns None<tab><tab>t = sys.exc_info()[2]<tab><tab>if t is None:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""A valid traceback must be passed if no exception is being handled.""<tab><tab><tab>)<tab>p = BPdb()<tab>p.reset()<tab>p.interaction(None, t)",1,if t is None :,if t is None :,0.75,100.00000000000004,1.0
"def fixup(m):<tab>txt = m.group(0)<tab>if txt[:2] == ""&#"":<tab><tab># character reference<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return unichr(int(txt[3:-1], 16))<tab><tab><tab>else:<tab><tab><tab><tab>return unichr(int(txt[2:-1]))<tab><tab>except ValueError:<tab><tab><tab>pass<tab>else:<tab><tab># named entity<tab><tab>try:<tab><tab><tab>txt = unichr(htmlentitydefs.name2codepoint[txt[1:-1]])<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return txt  # leave as is",1,"if txt [ : 3 ] == ""&#x"" :","if txt [ : 3 ] == ""&#x"" :",0.75,100.00000000000004,1.0
"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]:<tab>argstr += "",""<tab>args = []<tab>kwargs = {}<tab>for item in _converter_args_re.finditer(argstr):<tab><tab>value = item.group(""stringval"")<tab><tab><IF-STMT><tab><tab><tab>value = item.group(""value"")<tab><tab>value = _pythonize(value)<tab><tab>if not item.group(""name""):<tab><tab><tab>args.append(value)<tab><tab>else:<tab><tab><tab>name = item.group(""name"")<tab><tab><tab>kwargs[name] = value<tab>return tuple(args), kwargs",0,if value is None :,if value is not None :,0.2721091316413796,37.99178428257963,0.611111111111111
"def IT(cpu):<tab>cc = cpu.instruction.cc<tab>true_case = cpu._evaluate_conditional(cc)<tab># this is incredibly hacky--how else does capstone expose this?<tab># TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13<tab>for c in cpu.instruction.mnemonic[1:]:<tab><tab><IF-STMT><tab><tab><tab>cpu._it_conditional.append(true_case)<tab><tab>elif c == ""e"":<tab><tab><tab>cpu._it_conditional.append(not true_case)",1,"if c == ""t"" :","if c == ""t"" :",0.75,100.00000000000004,1.0
"def flatten(self):<tab># this is similar to fill_messages except it uses a list instead<tab># of a queue to place the messages in.<tab>result = []<tab>channel = await self.messageable._get_channel()<tab>self.channel = channel<tab>while self._get_retrieve():<tab><tab>data = await self._retrieve_messages(self.retrieve)<tab><tab><IF-STMT><tab><tab><tab>self.limit = 0  # terminate the infinite loop<tab><tab>if self.reverse:<tab><tab><tab>data = reversed(data)<tab><tab>if self._filter:<tab><tab><tab>data = filter(self._filter, data)<tab><tab>for element in data:<tab><tab><tab>result.append(self.state.create_message(channel=channel, data=element))<tab>return result",0,if len ( data ) < 100 :,if len ( data ) > self . limit :,0.34166435592571953,41.11336169005198,0.5584415584415584
"def _get_beta_accumulators(self):<tab>with tf.init_scope():<tab><tab><IF-STMT><tab><tab><tab>graph = None<tab><tab>else:<tab><tab><tab>graph = tf.get_default_graph()<tab><tab>return (<tab><tab><tab>self._get_non_slot_variable(""beta1_power"", graph=graph),<tab><tab><tab>self._get_non_slot_variable(""beta2_power"", graph=graph),<tab><tab>)",0,if tf . executing_eagerly ( ) :,if tf . get_default_graph ( ) is None :,0.21863469224710086,15.727800941615351,0.5666666666666667
"def prefixed(self, prefix: _StrType) -> typing.Iterator[""Env""]:<tab>""""""Context manager for parsing envvars with a common prefix.""""""<tab>try:<tab><tab>old_prefix = self._prefix<tab><tab><IF-STMT><tab><tab><tab>self._prefix = prefix<tab><tab>else:<tab><tab><tab>self._prefix = f""{old_prefix}{prefix}""<tab><tab>yield self<tab>finally:<tab><tab># explicitly reset the stored prefix on completion and exceptions<tab><tab>self._prefix = None<tab>self._prefix = old_prefix",1,if old_prefix is None :,if old_prefix is None :,0.75,100.00000000000004,1.0
"def decode_content(self):<tab>""""""Return the best possible representation of the response body.""""""<tab>ct = self.headers.get(""content-type"")<tab>if ct:<tab><tab>ct, options = parse_options_header(ct)<tab><tab>charset = options.get(""charset"")<tab><tab>if ct in JSON_CONTENT_TYPES:<tab><tab><tab>return self.json(charset)<tab><tab><IF-STMT><tab><tab><tab>return self.text(charset)<tab><tab>elif ct == FORM_URL_ENCODED:<tab><tab><tab>return parse_qsl(self.content.decode(charset), keep_blank_values=True)<tab>return self.content",0,"elif ct . startswith ( ""text/"" ) :",elif ct in TEXT_CONTENT_TYPES :,0.07517050226311625,8.449917822620138,0.6
"def test_incrementaldecoder(self):<tab>UTF8Writer = codecs.getwriter(""utf-8"")<tab>for sizehint in [None, -1] + list(range(1, 33)) + [64, 128, 256, 512, 1024]:<tab><tab>istream = BytesIO(self.tstring[0])<tab><tab>ostream = UTF8Writer(BytesIO())<tab><tab>decoder = self.incrementaldecoder()<tab><tab>while 1:<tab><tab><tab>data = istream.read(sizehint)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>u = decoder.decode(data)<tab><tab><tab><tab>ostream.write(u)<tab><tab>self.assertEqual(ostream.getvalue(), self.tstring[1])",1,if not data :,if not data :,0.75,100.00000000000004,1.0
"def delete_all(path):<tab>ppath = os.getcwd()<tab>os.chdir(path)<tab>for fn in glob.glob(""*""):<tab><tab>fn_full = os.path.join(path, fn)<tab><tab><IF-STMT><tab><tab><tab>delete_all(fn_full)<tab><tab>elif fn.endswith("".png""):<tab><tab><tab>os.remove(fn_full)<tab><tab>elif fn.endswith("".md""):<tab><tab><tab>os.remove(fn_full)<tab><tab>elif DELETE_ALL_OLD:<tab><tab><tab>os.remove(fn_full)<tab>os.chdir(ppath)<tab>os.rmdir(path)",0,if os . path . isdir ( fn ) :,"if fn . endswith ( "".py"" ) :",0.030390516601639946,10.252286118120933,0.2619047619047619
"def _delete_reason(self):<tab>for i in range(_lib.X509_REVOKED_get_ext_count(self._revoked)):<tab><tab>ext = _lib.X509_REVOKED_get_ext(self._revoked, i)<tab><tab>obj = _lib.X509_EXTENSION_get_object(ext)<tab><tab><IF-STMT><tab><tab><tab>_lib.X509_EXTENSION_free(ext)<tab><tab><tab>_lib.X509_REVOKED_delete_ext(self._revoked, i)<tab><tab><tab>break",0,if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,if obj . status == _lib . X509_OBJECT_UNUSED :,0.10341596577702394,20.08386140301271,0.7368421052631579
"def hexcmp(x, y):<tab>try:<tab><tab>a = int(x, 16)<tab><tab>b = int(y, 16)<tab><tab>if a < b:<tab><tab><tab>return -1<tab><tab><IF-STMT><tab><tab><tab>return 1<tab><tab>return 0<tab>except:<tab><tab>return cmp(x, y)",0,if a > b :,elif a > b :,0.31152264354151193,66.87403049764218,0.6
"def get_indentation_count(view, start):<tab>indent_count = 0<tab>i = start - 1<tab>while i > 0:<tab><tab>ch = view.substr(i)<tab><tab>scope = view.scope_name(i)<tab><tab># Skip preprocessors, strings, characaters and comments<tab><tab>if ""string.quoted"" in scope or ""comment"" in scope or ""preprocessor"" in scope:<tab><tab><tab>extent = view.extract_scope(i)<tab><tab><tab>i = extent.a - 1<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>i -= 1<tab><tab><IF-STMT><tab><tab><tab>indent_count -= 1<tab><tab>elif ch == ""{"":<tab><tab><tab>indent_count += 1<tab>return indent_count",1,"if ch == ""}"" :","if ch == ""}"" :",0.75,100.00000000000004,1.0
"def set(self, name, value, ex=None, px=None, nx=False, xx=False):<tab>if (<tab><tab>(not nx and not xx)<tab><tab>or (nx and self._db.get(name, None) is None)<tab><tab>or (xx and not self._db.get(name, None) is None)<tab>):<tab><tab>if ex > 0:<tab><tab><tab>self._db.expire(name, datetime.now() + timedelta(seconds=ex))<tab><tab><IF-STMT><tab><tab><tab>self._db.expire(name, datetime.now() + timedelta(milliseconds=px))<tab><tab>self._db[name] = str(value)<tab><tab>return True<tab>else:<tab><tab>return None",0,elif px > 0 :,if px > 0 :,0.334370152488211,66.87403049764218,0.6
"def _get_between(content, start, end=None):<tab>should_yield = False<tab>for line in content.split(""\n""):<tab><tab>if start in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if end and end in line:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>yield line.strip().split("" "")[0]",0,if should_yield and line :,if should_yield :,0.06767423853569741,1e-10,0.41666666666666663
"def iter_event_handlers(<tab>self,<tab>resource: resources_.Resource,<tab>event: bodies.RawEvent,) -> Iterator[handlers.ResourceWatchingHandler]:<tab>warnings.warn(<tab><tab>""SimpleRegistry.iter_event_handlers() is deprecated; use ""<tab><tab>""ResourceWatchingRegistry.iter_handlers()."",<tab><tab>DeprecationWarning,<tab>)<tab>cause = _create_watching_cause(resource, event)<tab>for handler in self._handlers:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif registries.match(handler=handler, cause=cause, ignore_fields=True):<tab><tab><tab>yield handler",0,"if not isinstance ( handler , handlers . ResourceWatchingHandler ) :",if handler is None :,0.012417879185700129,4.234348806659263,0.20370370370370372
"def __enter__(self):<tab>if log_timer:<tab><tab><IF-STMT><tab><tab><tab>self.logger.debug(""%s starting"" % self.name)<tab><tab>else:<tab><tab><tab>print((""[%s starting]..."" % self.name))<tab><tab>self.tstart = time.time()",1,if self . logger :,if self . logger :,0.75,100.00000000000004,1.0
"def _handle_errors(errors):<tab>""""""Log out and possibly reraise errors during import.""""""<tab>if not errors:<tab><tab>return<tab>log_all = True  # pylint: disable=unused-variable<tab>err_msg = ""T2T: skipped importing {num_missing} data_generators modules.""<tab>print(err_msg.format(num_missing=len(errors)))<tab>for module, err in errors:<tab><tab>err_str = str(err)<tab><tab><IF-STMT><tab><tab><tab>print(""Did not import module: %s; Cause: %s"" % (module, err_str))<tab><tab>if not _is_import_err_msg(err_str, module):<tab><tab><tab>print(""From module %s"" % module)<tab><tab><tab>raise err",1,if log_all :,if log_all :,0.5311706625951745,1e-10,1.0
"def _ungroup(sequence, groups=None):<tab>for v in sequence:<tab><tab>if isinstance(v, (list, tuple)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>groups.append(list(_ungroup(v, groups=None)))<tab><tab><tab>for v in _ungroup(v, groups):<tab><tab><tab><tab>yield v<tab><tab>else:<tab><tab><tab>yield v",1,if groups is not None :,if groups is not None :,0.75,100.00000000000004,1.0
def run(self):<tab>while not self.completed:<tab><tab>if self.block:<tab><tab><tab>time.sleep(self.period)<tab><tab>else:<tab><tab><tab>self._completed.wait(self.period)<tab><tab>self.counter += 1<tab><tab>try:<tab><tab><tab>self.callback(self.counter)<tab><tab>except Exception:<tab><tab><tab>self.stop()<tab><tab>if self.timeout is not None:<tab><tab><tab>dt = time.time() - self._start_time<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.stop()<tab><tab>if self.counter == self.count:<tab><tab><tab>self.stop(),1,if dt > self . timeout :,if dt > self . timeout :,0.75,100.00000000000004,1.0
"def dont_let_stderr_buffer():<tab>while True:<tab><tab>line = context.daemon.stderr.readline()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if DEAD_DEPLOYD_WORKER_MESSAGE.encode(""utf-8"") in line:<tab><tab><tab>context.num_workers_crashed += 1<tab><tab>print(f""deployd stderr: {line}"")",1,if not line :,if not line :,0.75,100.00000000000004,1.0
"def mergeHiLo(self, x_stats):<tab>""""""Merge the highs and lows of another accumulator into myself.""""""<tab>if x_stats.firsttime is not None:<tab><tab>if self.firsttime is None or x_stats.firsttime < self.firsttime:<tab><tab><tab>self.firsttime = x_stats.firsttime<tab><tab><tab>self.first = x_stats.first<tab>if x_stats.lasttime is not None:<tab><tab><IF-STMT><tab><tab><tab>self.lasttime = x_stats.lasttime<tab><tab><tab>self.last = x_stats.last",0,if self . lasttime is None or x_stats . lasttime >= self . lasttime :,if self . lasttime is None or x_stats . lasttime > self . lasttime :,0.9009081361505339,84.28014430784187,1.0
"def test_rlimit_get(self):<tab>import resource<tab>p = psutil.Process(os.getpid())<tab>names = [x for x in dir(psutil) if x.startswith(""RLIMIT"")]<tab>assert names<tab>for name in names:<tab><tab>value = getattr(psutil, name)<tab><tab>self.assertGreaterEqual(value, 0)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(value, getattr(resource, name))<tab><tab><tab>self.assertEqual(p.rlimit(value), resource.getrlimit(value))<tab><tab>else:<tab><tab><tab>ret = p.rlimit(value)<tab><tab><tab>self.assertEqual(len(ret), 2)<tab><tab><tab>self.assertGreaterEqual(ret[0], -1)<tab><tab><tab>self.assertGreaterEqual(ret[1], -1)",0,if name in dir ( resource ) :,"if hasattr ( resource , name ) :",0.04657955605120075,17.286039232097043,0.2653061224489796
"def _calculate_writes_for_built_in_indices(self, entity):<tab>writes = 0<tab>for prop_name in entity.keys():<tab><tab>if not prop_name in entity.unindexed_properties():<tab><tab><tab>prop_vals = entity[prop_name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>num_prop_vals = len(prop_vals)<tab><tab><tab>else:<tab><tab><tab><tab>num_prop_vals = 1<tab><tab><tab>writes += 2 * num_prop_vals<tab>return writes",0,"if isinstance ( prop_vals , ( list ) ) :","if isinstance ( prop_vals , list ) :",0.24963887590134531,61.455883305931245,1.0
"def check_value_check(self, x_data, t_data, use_cudnn):<tab>x = chainer.Variable(x_data)<tab>t = chainer.Variable(t_data)<tab>with chainer.using_config(""use_cudnn"", use_cudnn):<tab><tab><IF-STMT><tab><tab><tab># Check if it throws nothing<tab><tab><tab>functions.softmax_cross_entropy(<tab><tab><tab><tab>x, t, enable_double_backprop=self.enable_double_backprop<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>with self.assertRaises(ValueError):<tab><tab><tab><tab>functions.softmax_cross_entropy(<tab><tab><tab><tab><tab>x, t, enable_double_backprop=self.enable_double_backprop<tab><tab><tab><tab>)",0,if self . valid :,if self . use_cudnn :,0.39477865547525276,26.269098944241588,0.7
"def get_note_title_file(note):<tab>mo = note_title_re.match(note.get(""content"", """"))<tab>if mo:<tab><tab>fn = mo.groups()[0]<tab><tab>fn = fn.replace("" "", ""_"")<tab><tab>fn = fn.replace(""/"", ""_"")<tab><tab><IF-STMT><tab><tab><tab>return """"<tab><tab>if isinstance(fn, str):<tab><tab><tab>fn = unicode(fn, ""utf-8"")<tab><tab>else:<tab><tab><tab>fn = unicode(fn)<tab><tab>if note_markdown(note):<tab><tab><tab>fn += "".mkdn""<tab><tab>else:<tab><tab><tab>fn += "".txt""<tab><tab>return fn<tab>else:<tab><tab>return """"",1,if not fn :,if not fn :,0.75,100.00000000000004,1.0
"def _parseparam(s):<tab>plist = []<tab>while s[:1] == "";"":<tab><tab>s = s[1:]<tab><tab>end = s.find("";"")<tab><tab>while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2:<tab><tab><tab>end = s.find("";"", end + 1)<tab><tab>if end < 0:<tab><tab><tab>end = len(s)<tab><tab>f = s[:end]<tab><tab><IF-STMT><tab><tab><tab>i = f.index(""="")<tab><tab><tab>f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip()<tab><tab>plist.append(f.strip())<tab><tab>s = s[end:]<tab>return plist",1,"if ""="" in f :","if ""="" in f :",0.75,100.00000000000004,1.0
"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab>if not isinstance(child, minidom.Element):<tab><tab><tab>continue<tab><tab>if child.tagName == ""Directory"":<tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab>if not isinstance(grandchild, minidom.Element):<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",0,"if grandchild . tagName != ""File"" :","if grandchild . getAttribute ( ""Source"" ) == """" :",0.07470841271651402,15.537125692760354,0.6
"def date_to_format(value, target_format):<tab>""""""Convert date to specified format""""""<tab>if target_format == str:<tab><tab><IF-STMT><tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab>elif isinstance(value, datetime.datetime):<tab><tab><tab>ret = value.strftime(""%d/%m/%y"")<tab><tab>elif isinstance(value, datetime.time):<tab><tab><tab>ret = value.strftime(""%H:%M:%S"")<tab>else:<tab><tab>ret = value<tab>return ret",1,"if isinstance ( value , datetime . date ) :","if isinstance ( value , datetime . date ) :",0.75,100.00000000000004,1.0
"def __listingColumns(self):<tab>columns = []<tab>for name in self.__getColumns():<tab><tab>definition = column(name)<tab><tab><IF-STMT><tab><tab><tab>IECore.msg(<tab><tab><tab><tab>IECore.Msg.Level.Error,<tab><tab><tab><tab>""GafferImageUI.CatalogueUI"",<tab><tab><tab><tab>""No column registered with name '%s'"" % name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>if isinstance(definition, IconColumn):<tab><tab><tab>c = GafferUI.PathListingWidget.IconColumn(definition.title(), """", name)<tab><tab>else:<tab><tab><tab>c = GafferUI.PathListingWidget.StandardColumn(definition.title(), name)<tab><tab>columns.append(c)<tab>return columns",1,if not definition :,if not definition :,0.75,100.00000000000004,1.0
"def metrics_to_scalars(self, metrics):<tab>new_metrics = {}<tab>for k, v in metrics.items():<tab><tab><IF-STMT><tab><tab><tab>v = v.item()<tab><tab>if isinstance(v, dict):<tab><tab><tab>v = self.metrics_to_scalars(v)<tab><tab>new_metrics[k] = v<tab>return new_metrics",0,"if isinstance ( v , torch . Tensor ) :","if isinstance ( v , dict ) :",0.23202903606635522,46.307771619910305,0.5584415584415584
"def start(self, connection):<tab>try:<tab><tab>if self.client_name:<tab><tab><tab>creds = gssapi.Credentials(name=gssapi.Name(self.client_name))<tab><tab>else:<tab><tab><tab>creds = None<tab><tab>hostname = self.get_hostname(connection)<tab><tab>name = gssapi.Name(<tab><tab><tab>b""@"".join([self.service, hostname]), gssapi.NameType.hostbased_service<tab><tab>)<tab><tab>context = gssapi.SecurityContext(name=name, creds=creds)<tab><tab>return context.step(None)<tab>except gssapi.raw.misc.GSSError:<tab><tab><IF-STMT><tab><tab><tab>return NotImplemented<tab><tab>else:<tab><tab><tab>raise",0,if self . fail_soft :,if self . service is None :,0.2005939911646859,26.269098944241588,0.42857142857142855
"def nanmax(self, axis=None, dtype=None, keepdims=None):<tab>ret = self._reduction(<tab><tab>""nanmax"", axis=axis, dtype=dtype, keepdims=keepdims, todense=True<tab>)<tab>if not issparse(ret):<tab><tab><IF-STMT><tab><tab><tab>return ret<tab><tab>xps = get_sparse_module(self.spmatrix)<tab><tab>ret = SparseNDArray(xps.csr_matrix(ret))<tab><tab>return ret<tab>return ret",0,if get_array_module ( ret ) . isscalar ( ret ) :,if self . spmatrix is None :,0.013230836303327505,2.75631563063758,0.2403846153846154
"def utterance_to_sample(query_data, tagging_scheme, language):<tab>tokens, tags = [], []<tab>current_length = 0<tab>for chunk in query_data:<tab><tab>chunk_tokens = tokenize(chunk[TEXT], language)<tab><tab>tokens += [<tab><tab><tab>Token(t.value, current_length + t.start, current_length + t.end)<tab><tab><tab>for t in chunk_tokens<tab><tab>]<tab><tab>current_length += len(chunk[TEXT])<tab><tab><IF-STMT><tab><tab><tab>tags += negative_tagging(len(chunk_tokens))<tab><tab>else:<tab><tab><tab>tags += positive_tagging(<tab><tab><tab><tab>tagging_scheme, chunk[SLOT_NAME], len(chunk_tokens)<tab><tab><tab>)<tab>return {TOKENS: tokens, TAGS: tags}",0,if SLOT_NAME not in chunk :,if chunk [ SLOT_NAME ] < 0 :,0.02492724325929667,18.575057999133595,0.3148148148148148
"def use_index(<tab>self, term: Union[str, Index], *terms: Union[str, Index]) -> ""QueryBuilder"":<tab>for t in (term, *terms):<tab><tab>if isinstance(t, Index):<tab><tab><tab>self._use_indexes.append(t)<tab><tab><IF-STMT><tab><tab><tab>self._use_indexes.append(Index(t))",1,"elif isinstance ( t , str ) :","elif isinstance ( t , str ) :",0.75,100.00000000000004,1.0
"def reconfigServiceWithBuildbotConfig(self, new_config):<tab>if new_config.manhole != self.manhole:<tab><tab>if self.manhole:<tab><tab><tab>yield self.manhole.disownServiceParent()<tab><tab><tab>self.manhole = None<tab><tab><IF-STMT><tab><tab><tab>self.manhole = new_config.manhole<tab><tab><tab>yield self.manhole.setServiceParent(self)<tab># chain up<tab>yield service.ReconfigurableServiceMixin.reconfigServiceWithBuildbotConfig(<tab><tab>self, new_config<tab>)",0,if new_config . manhole :,if self . manhole is None :,0.13878247493843046,15.619699684601283,0.2619047619047619
"def cleanup_folder(target_folder):<tab>for file in os.listdir(target_folder):<tab><tab>file_path = os.path.join(target_folder, file)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(file_path)<tab><tab>except Exception as e:<tab><tab><tab>logging.error(e)",1,if os . path . isfile ( file_path ) :,if os . path . isfile ( file_path ) :,0.75,100.00000000000004,1.0
"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab><IF-STMT><tab><tab><tab>return unicode(float_repr(k))<tab><tab>elif ""regex"" in literal_or_identifier:<tab><tab><tab>return compose_regex(k)<tab><tab>elif isinstance(k, bool):<tab><tab><tab>return ""true"" if k else ""false""<tab><tab>elif k is None:<tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)",1,"if isinstance ( k , float ) :","if isinstance ( k , float ) :",0.75,100.00000000000004,1.0
"def decompile(decompiler):<tab>for pos, next_pos, opname, arg in decompiler.instructions:<tab><tab>if pos in decompiler.targets:<tab><tab><tab>decompiler.process_target(pos)<tab><tab>method = getattr(decompiler, opname, None)<tab><tab><IF-STMT><tab><tab><tab>throw(DecompileError(""Unsupported operation: %s"" % opname))<tab><tab>decompiler.pos = pos<tab><tab>decompiler.next_pos = next_pos<tab><tab>x = method(*arg)<tab><tab>if x is not None:<tab><tab><tab>decompiler.stack.append(x)",1,if method is None :,if method is None :,0.75,100.00000000000004,1.0
"def shutdown(self, timeout, callback=None):<tab>logger.debug(""background worker got shutdown request"")<tab>with self._lock:<tab><tab>if self.is_alive:<tab><tab><tab>self._queue.put_nowait(_TERMINATOR)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._wait_shutdown(timeout, callback)<tab><tab>self._thread = None<tab><tab>self._thread_for_pid = None<tab>logger.debug(""background worker shut down"")",0,if timeout > 0.0 :,if callback is not None :,0.030286782520570012,9.652434877402245,0.19999999999999998
"def getDOMImplementation(features=None):<tab>if features:<tab><tab><IF-STMT><tab><tab><tab>features = domreg._parse_feature_string(features)<tab><tab>for f, v in features:<tab><tab><tab>if not Document.implementation.hasFeature(f, v):<tab><tab><tab><tab>return None<tab>return Document.implementation",0,"if isinstance ( features , str ) :","if isinstance ( features , basestring ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def validate_subevent(self, subevent):<tab>if self.context[""event""].has_subevents:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(""You need to set a subevent."")<tab><tab>if subevent.event != self.context[""event""]:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>""The specified subevent does not belong to this event.""<tab><tab><tab>)<tab>elif subevent:<tab><tab>raise ValidationError(""You cannot set a subevent for this event."")<tab>return subevent",0,if not subevent :,if subevent :,0.09648852821835877,1e-10,0.41666666666666663
"def einsum(job_id, idx, einsum_expr, data_list):<tab>_, all_parties = session_init(job_id, idx)<tab>with SPDZ():<tab><tab><IF-STMT><tab><tab><tab>x = FixedPointTensor.from_source(""x"", data_list[0])<tab><tab><tab>y = FixedPointTensor.from_source(""y"", all_parties[1])<tab><tab>else:<tab><tab><tab>x = FixedPointTensor.from_source(""x"", all_parties[0])<tab><tab><tab>y = FixedPointTensor.from_source(""y"", data_list[1])<tab><tab>return x.einsum(y, einsum_expr).get()",1,if idx == 0 :,if idx == 0 :,0.75,100.00000000000004,1.0
"def slowSorted(qq):<tab>""Reference sort peformed by insertion using only <""<tab>rr = list()<tab>for q in qq:<tab><tab>i = 0<tab><tab>for i in range(len(rr)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rr.insert(i, q)<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>rr.append(q)<tab>return rr",0,if q < rr [ i ] :,if rr [ i ] == q :,0.26248055641091705,34.32945239845197,0.4
"def _format_entry(entry, src):<tab>if entry:<tab><tab>result = []<tab><tab>for x in entry.split("",""):<tab><tab><tab>x = x.strip()<tab><tab><tab>if os.path.exists(os.path.join(src, x)):<tab><tab><tab><tab>result.append(relpath(os.path.join(src, x), src))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(relpath(os.path.abspath(x), src))<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""No entry script %s found"" % x)<tab><tab>return "","".join(result)",0,elif os . path . exists ( x ) :,elif os . path . exists ( os . path . abspath ( x ) ) :,0.43752104199613695,44.09774564143265,0.5986394557823128
"def reloadCols(self):<tab>self.columns = []<tab>for i, (name, fmt, *shape) in enumerate(self.npy.dtype.descr):<tab><tab>if shape:<tab><tab><tab>t = anytype<tab><tab>elif ""M"" in fmt:<tab><tab><tab>self.addColumn(Column(name, type=date, getter=lambda c, r, i=i: str(r[i])))<tab><tab><tab>continue<tab><tab>elif ""i"" in fmt:<tab><tab><tab>t = int<tab><tab><IF-STMT><tab><tab><tab>t = float<tab><tab>else:<tab><tab><tab>t = anytype<tab><tab>self.addColumn(ColumnItem(name, i, type=t))",1,"elif ""f"" in fmt :","elif ""f"" in fmt :",0.75,100.00000000000004,1.0
"def tool_lineages(self, trans):<tab>rval = []<tab>for id, tool in self.app.toolbox.tools():<tab><tab><IF-STMT><tab><tab><tab>lineage_dict = tool.lineage.to_dict()<tab><tab>else:<tab><tab><tab>lineage_dict = None<tab><tab>entry = dict(id=id, lineage=lineage_dict)<tab><tab>rval.append(entry)<tab>return rval",1,"if hasattr ( tool , ""lineage"" ) :","if hasattr ( tool , ""lineage"" ) :",0.75,100.00000000000004,1.0
"def item(self, tensor):<tab>numel = 0<tab>if len(tensor.shape) > 0:<tab><tab>numel = fct.reduce(op.mul, tensor.shape)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""expected tensor with one element, "" f""got {tensor.shape}""<tab><tab><tab>)<tab>if numel == 1:<tab><tab>return tensor[0]<tab>return tensor",0,if numel != 1 :,if numel != 0 :,0.39477865547525276,53.7284965911771,0.6
"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(<tab><tab><tab><tab>self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1<tab><tab><tab>).json()<tab><tab><tab>if ""Version"" in resp:<tab><tab><tab><tab>match = AGENT_VERSION_EXP.search(resp.get(""Version""))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>meta[""ecs_version""] = match.group(1)<tab><tab>except Exception as e:<tab><tab><tab>self.log.debug(""Error getting ECS version: %s"" % str(e))<tab>return meta",0,if match is not None and len ( match . groups ( ) ) == 1 :,if match :,0.008515097949460896,1e-10,0.2303030303030303
"def generate():<tab>for leaf in u.leaves:<tab><tab>if isinstance(leaf, Integer):<tab><tab><tab>val = leaf.get_int_value()<tab><tab><tab>if val in (0, 1):<tab><tab><tab><tab>yield val<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>elif isinstance(leaf, Symbol):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield 1<tab><tab><tab>elif leaf == SymbolFalse:<tab><tab><tab><tab>yield 0<tab><tab><tab>else:<tab><tab><tab><tab>raise _NoBoolVector<tab><tab>else:<tab><tab><tab>raise _NoBoolVector",1,if leaf == SymbolTrue :,if leaf == SymbolTrue :,0.75,100.00000000000004,1.0
"def _test_set_metadata(self, metadata, mask=None):<tab>header = ofproto.OXM_OF_METADATA<tab>match = OFPMatch()<tab>if mask is None:<tab><tab>match.set_metadata(metadata)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>header = ofproto.OXM_OF_METADATA_W<tab><tab>match.set_metadata_masked(metadata, mask)<tab><tab>metadata &= mask<tab>self._test_serialize_and_parser(match, header, metadata, mask)",0,if ( mask + 1 ) >> 64 != 1 :,if mask == 0 :,0.054084545852366786,3.57451796074295,0.4761904761904762
"def pixbufrenderer(self, column, crp, model, it):<tab>tok = model.get_value(it, 0)<tab>if tok.type == ""class"":<tab><tab>icon = ""class""<tab>else:<tab><tab>if tok.visibility == ""private"":<tab><tab><tab>icon = ""method_priv""<tab><tab><IF-STMT><tab><tab><tab>icon = ""method_prot""<tab><tab>else:<tab><tab><tab>icon = ""method""<tab>crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])",0,"elif tok . visibility == ""protected"" :","elif tok . visibility == ""prot"" :",0.8217294420803809,70.71067811865478,1.0
"def path_sum2(root, s):<tab>if root is None:<tab><tab>return []<tab>res = []<tab>stack = [(root, [root.val])]<tab>while stack:<tab><tab>node, ls = stack.pop()<tab><tab>if node.left is None and node.right is None and sum(ls) == s:<tab><tab><tab>res.append(ls)<tab><tab><IF-STMT><tab><tab><tab>stack.append((node.left, ls + [node.left.val]))<tab><tab>if node.right is not None:<tab><tab><tab>stack.append((node.right, ls + [node.right.val]))<tab>return res",1,if node . left is not None :,if node . left is not None :,0.75,100.00000000000004,1.0
"def clear_slot(self, slot_id, trigger_changed):<tab>if self.slots[slot_id] is not None:<tab><tab>old_resource_id = self.slots[slot_id].resource_id<tab><tab><IF-STMT><tab><tab><tab>del self.sell_list[old_resource_id]<tab><tab>else:<tab><tab><tab>del self.buy_list[old_resource_id]<tab>self.slots[slot_id] = None<tab>if trigger_changed:<tab><tab>self._changed()",0,if self . slots [ slot_id ] . selling :,if old_resource_id in self .ell_list :,0.01478624383023101,9.669265690880861,0.32051282051282054
"def OnRightUp(self, event):<tab>self.HandleMouseEvent(event)<tab>self.Unbind(wx.EVT_RIGHT_UP, handler=self.OnRightUp)<tab>self.Unbind(wx.EVT_MOUSE_CAPTURE_LOST, handler=self.OnRightUp)<tab>self._right = False<tab>if not self._left:<tab><tab>self.Unbind(wx.EVT_MOTION, handler=self.OnMotion)<tab><tab>self.SendChangeEvent()<tab><tab>self.SetToolTip(wx.ToolTip(self._tooltip))<tab><tab><IF-STMT><tab><tab><tab>self.ReleaseMouse()",0,if self . HasCapture ( ) :,if self . _right :,0.09453229110448028,27.482545710800192,0.7222222222222222
"def __init__(self, *args, **kwargs):<tab>for arg in args:<tab><tab>for k, v in arg.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>arg[k] = AttrDict(v)<tab><tab><tab>else:<tab><tab><tab><tab>arg[k] = v<tab>super(AttrDict, self).__init__(*args, **kwargs)",1,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,100.00000000000004,1.0
"def _toplevelTryFunc(func, *args, status=status, **kwargs):<tab>with ThreadProfiler(threading.current_thread()) as prof:<tab><tab>t = threading.current_thread()<tab><tab>t.name = func.__name__<tab><tab>try:<tab><tab><tab>t.status = func(*args, **kwargs)<tab><tab>except EscapeException as e:  # user aborted<tab><tab><tab>t.status = ""aborted by user""<tab><tab><tab>if status:<tab><tab><tab><tab>status(""%s aborted"" % t.name, priority=2)<tab><tab>except Exception as e:<tab><tab><tab>t.exception = e<tab><tab><tab>t.status = ""exception""<tab><tab><tab>vd.exceptionCaught(e)<tab><tab><IF-STMT><tab><tab><tab>t.sheet.currentThreads.remove(t)",0,if t . sheet :,if t in t . sheet . currentThreads :,0.12090186182217555,22.31618068926665,0.38888888888888884
"def comboSelectionChanged(self, index):<tab>text = self.comboBox.cb.itemText(index)<tab>for i in range(self.labelList.count()):<tab><tab>if text == """":<tab><tab><tab>self.labelList.item(i).setCheckState(2)<tab><tab><IF-STMT><tab><tab><tab>self.labelList.item(i).setCheckState(0)<tab><tab>else:<tab><tab><tab>self.labelList.item(i).setCheckState(2)",0,elif text != self . labelList . item ( i ) . text ( ) :,elif i == index :,0.13100589500780438,1.8352187133349005,0.2272727272727273
"def __attempt_add_to_linked_match(<tab>self, input_name, hdca, collection_type_description, subcollection_type):<tab>structure = get_structure(<tab><tab>hdca, collection_type_description, leaf_subcollection_type=subcollection_type<tab>)<tab>if not self.linked_structure:<tab><tab>self.linked_structure = structure<tab><tab>self.collections[input_name] = hdca<tab><tab>self.subcollection_types[input_name] = subcollection_type<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise exceptions.MessageException(CANNOT_MATCH_ERROR_MESSAGE)<tab><tab>self.collections[input_name] = hdca<tab><tab>self.subcollection_types[input_name] = subcollection_type",0,if not self . linked_structure . can_match ( structure ) :,if self . linked_structure != structure :,0.05661077721133517,26.796028566766235,0.38666666666666666
"def _wait_for_bot_presense(self, online):<tab>for _ in range(10):<tab><tab>time.sleep(2)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if not online and not self._is_testbot_online():<tab><tab><tab>break<tab>else:<tab><tab>raise AssertionError(<tab><tab><tab>""test bot is still {}"".format(""offline"" if online else ""online"")<tab><tab>)",0,if online and self . _is_testbot_online ( ) :,if online and not self . _is_testbot_offline ( ) :,0.21427874631390026,57.73502691896262,0.6515151515151515
"def find(self, path):<tab>if os.path.isfile(path) or os.path.islink(path):<tab><tab>self.num_files = self.num_files + 1<tab><tab><IF-STMT><tab><tab><tab>self.files.append(path)<tab>elif os.path.isdir(path):<tab><tab>for content in os.listdir(path):<tab><tab><tab>file = os.path.join(path, content)<tab><tab><tab>if os.path.isfile(file) or os.path.islink(file):<tab><tab><tab><tab>self.num_files = self.num_files + 1<tab><tab><tab><tab>if self.match_function(file):<tab><tab><tab><tab><tab>self.files.append(file)<tab><tab><tab>else:<tab><tab><tab><tab>self.find(file)",1,if self . match_function ( path ) :,if self . match_function ( path ) :,0.75,100.00000000000004,1.0
"def optimize(self, graph: Graph):<tab>MAX_TEXTURE_SIZE = config.WEBGL_MAX_TEXTURE_SIZE<tab>flag_changed = False<tab>for v in traverse.listup_variables(graph):<tab><tab>if not Placeholder.check_resolved(v.size):<tab><tab><tab>continue<tab><tab>height, width = TextureShape.get(v)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not v.has_attribute(SplitTarget):<tab><tab><tab>flag_changed = True<tab><tab><tab>v.attributes.add(SplitTarget())<tab>return graph, flag_changed",0,if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE :,if height > MAX_TEXTURE_SIZE :,0.037499275688711114,21.74757062134855,0.5666666666666667
"def brightness_func(args):<tab>device = _get_device_from_filter(args)<tab>if args.set is None:<tab><tab># Get brightness<tab><tab>if args.raw:<tab><tab><tab>print(str(device.brightness))<tab><tab>else:<tab><tab><tab>print(""Brightness: {0}%"".format(device.brightness))<tab>else:<tab><tab>brightness_value = float(_clamp_u8(args.set))<tab><tab><IF-STMT><tab><tab><tab>print(""Setting brightness to {0}%"".format(brightness_value))<tab><tab>device.brightness = brightness_value",0,if not args . raw :,if brightness_value != device . brightness :,0.02547891297464453,5.522397783539471,0.2653061224489796
"def _setup(self, field_name, owner_model):<tab># Resolve possible name-based model reference.<tab>if not self.model_class:<tab><tab><IF-STMT><tab><tab><tab>self.model_class = owner_model<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""ModelType: Unable to resolve model '{}'."".format(self.model_name)<tab><tab><tab>)<tab>super(ModelType, self)._setup(field_name, owner_model)",0,if self . model_name == owner_model . __name__ :,if owner_model :,0.013954293440949377,1e-10,0.6444444444444445
"def build_json_schema_object(cls, parent_builder=None):<tab>builder = builders.ObjectBuilder(cls, parent_builder)<tab>if builder.count_type(builder.type) > 1:<tab><tab>return builder<tab>for _, name, field in cls.iterate_with_name():<tab><tab>if isinstance(field, fields.EmbeddedField):<tab><tab><tab>builder.add_field(name, field, _parse_embedded(field, builder))<tab><tab><IF-STMT><tab><tab><tab>builder.add_field(name, field, _parse_list(field, builder))<tab><tab>else:<tab><tab><tab>builder.add_field(name, field, _create_primitive_field_schema(field))<tab>return builder",1,"elif isinstance ( field , fields . ListField ) :","elif isinstance ( field , fields . ListField ) :",0.75,100.00000000000004,1.0
"def filter_module(mod, type_req=None, subclass_req=None):<tab>for name in dir(mod):<tab><tab>val = getattr(mod, name)<tab><tab>if type_req is not None and not isinstance(val, type_req):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield name, val",1,"if subclass_req is not None and not issubclass ( val , subclass_req ) :","if subclass_req is not None and not issubclass ( val , subclass_req ) :",0.75,100.00000000000004,1.0
"def get_icon(self):<tab>if self.icon is not None:<tab><tab># Load it from an absolute filename<tab><tab>if os.path.exists(self.icon):<tab><tab><tab>try:<tab><tab><tab><tab>return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24)<tab><tab><tab>except GObject.GError as ge:<tab><tab><tab><tab>pass<tab><tab># Load it from the current icon theme<tab><tab>(icon_name, extension) = os.path.splitext(os.path.basename(self.icon))<tab><tab>theme = Gtk.IconTheme()<tab><tab><IF-STMT><tab><tab><tab>return theme.load_icon(icon_name, 24, 0)",0,if theme . has_icon ( icon_name ) :,if theme is not None :,0.03526460512979883,6.60902979597904,0.4444444444444444
"def sysctlTestAndSet(name, limit):<tab>""Helper function to set sysctl limits""<tab># convert non-directory names into directory names<tab>if ""/"" not in name:<tab><tab>name = ""/proc/sys/"" + name.replace(""."", ""/"")<tab># read limit<tab>with open(name, ""r"") as readFile:<tab><tab>oldLimit = readFile.readline()<tab><tab>if isinstance(limit, int):<tab><tab><tab># compare integer limits before overriding<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with open(name, ""w"") as writeFile:<tab><tab><tab><tab><tab>writeFile.write(""%d"" % limit)<tab><tab>else:<tab><tab><tab># overwrite non-integer limits<tab><tab><tab>with open(name, ""w"") as writeFile:<tab><tab><tab><tab>writeFile.write(limit)",0,if int ( oldLimit ) < limit :,if limit != oldLimit :,0.02024553291763975,8.22487964923291,0.5777777777777777
"def _wait_for_bot_presense(self, online):<tab>for _ in range(10):<tab><tab>time.sleep(2)<tab><tab>if online and self._is_testbot_online():<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab>else:<tab><tab>raise AssertionError(<tab><tab><tab>""test bot is still {}"".format(""offline"" if online else ""online"")<tab><tab>)",0,if not online and not self . _is_testbot_online ( ) :,elif online and self . _is_testbot_offline ( ) :,0.1777540578813682,49.68271843768451,0.11904761904761905
"def handle(self, context, sign, *args):<tab>if context.rounding in (ROUND_HALF_UP, ROUND_HALF_EVEN, ROUND_HALF_DOWN, ROUND_UP):<tab><tab>return Infsign[sign]<tab>if sign == 0:<tab><tab>if context.rounding == ROUND_CEILING:<tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))<tab>if sign == 1:<tab><tab><IF-STMT><tab><tab><tab>return Infsign[sign]<tab><tab>return Decimal((sign, (9,) * context.prec, context.Emax - context.prec + 1))",0,if context . rounding == ROUND_FLOOR :,if context . rounding == ROUND_CEILING :,0.574113272471593,78.25422900366438,1.0
"def _get_item_columns_panel(items, rows):<tab>hbox = Gtk.HBox(False, 4)<tab>n_item = 0<tab>col_items = 0<tab>vbox = Gtk.VBox()<tab>hbox.pack_start(vbox, False, False, 0)<tab>while n_item < len(items):<tab><tab>item = items[n_item]<tab><tab>vbox.pack_start(item, False, False, 0)<tab><tab>n_item += 1<tab><tab>col_items += 1<tab><tab><IF-STMT><tab><tab><tab>vbox = Gtk.VBox()<tab><tab><tab>hbox.pack_start(vbox, False, False, 0)<tab><tab><tab>col_items = 0<tab>return hbox",0,if col_items > rows :,if col_items == rows :,0.33141502097923065,41.11336169005198,1.0
"def _changed(self):<tab>if self.gtk_range.get_sensitive():<tab><tab><IF-STMT><tab><tab><tab>self.timer.cancel()<tab><tab>self.timer = _Timer(0.5, lambda: GLib.idle_add(self._write))<tab><tab>self.timer.start()",0,if self . timer :,if self . timer is not None :,0.3514988343435983,36.55552228545123,0.5102040816326531
"def unlock_graph(result, callback, interval=1, propagate=False, max_retries=None):<tab>if result.ready():<tab><tab>second_level_res = result.get()<tab><tab><IF-STMT><tab><tab><tab>with allow_join_result():<tab><tab><tab><tab>signature(callback).delay(<tab><tab><tab><tab><tab>list(joinall(second_level_res, propagate=propagate))<tab><tab><tab><tab>)<tab>else:<tab><tab>unlock_graph.retry(countdown=interval, max_retries=max_retries)",0,if second_level_res . ready ( ) :,if second_level_res :,0.03885753308224148,1e-10,0.6363636363636364
"def update(self, other=None, /, **kwargs):<tab>if self._pending_removals:<tab><tab>self._commit_removals()<tab>d = self.data<tab>if other is not None:<tab><tab><IF-STMT><tab><tab><tab>other = dict(other)<tab><tab>for key, o in other.items():<tab><tab><tab>d[key] = KeyedRef(o, self._remove, key)<tab>for key, o in kwargs.items():<tab><tab>d[key] = KeyedRef(o, self._remove, key)",0,"if not hasattr ( other , ""items"" ) :","if isinstance ( other , dict ) :",0.08038725729605721,18.594002123233256,0.2857142857142857
"def default(self, o):<tab>try:<tab><tab>if type(o) == datetime.datetime:<tab><tab><tab>return str(o)<tab><tab>else:<tab><tab><tab># remove unwanted attributes from the provider object during conversion to json<tab><tab><tab>if hasattr(o, ""profile""):<tab><tab><tab><tab>del o.profile<tab><tab><tab>if hasattr(o, ""credentials""):<tab><tab><tab><tab>del o.credentials<tab><tab><tab>if hasattr(o, ""metadata_path""):<tab><tab><tab><tab>del o.metadata_path<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del o.services_config<tab><tab><tab>return vars(o)<tab>except Exception as e:<tab><tab>return str(o)",1,"if hasattr ( o , ""services_config"" ) :","if hasattr ( o , ""services_config"" ) :",0.75,100.00000000000004,1.0
"def read(self, count=True, timeout=None, ignore_non_errors=True, ignore_timeouts=True):<tab>try:<tab><tab>return self._read(count, timeout)<tab>except usb.USBError as e:<tab><tab><IF-STMT><tab><tab><tab>log.info(<tab><tab><tab><tab>""read: e.errno=%s e.strerror=%s e.message=%s repr=%s""<tab><tab><tab><tab>% (e.errno, e.strerror, e.message, repr(e))<tab><tab><tab>)<tab><tab>if ignore_timeouts and is_timeout(e):<tab><tab><tab>return []<tab><tab>if ignore_non_errors and is_noerr(e):<tab><tab><tab>return []<tab><tab>raise",0,if DEBUG_COMM :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,0.04157467851822123,1e-10,0.2916666666666667
def heal(self):<tab>if not self.doctors:<tab><tab>return<tab>proc_ids = self._get_process_ids()<tab>for proc_id in proc_ids:<tab><tab># get proc every time for latest state<tab><tab>proc = PipelineProcess.objects.get(id=proc_id)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for dr in self.doctors:<tab><tab><tab>if dr.confirm(proc):<tab><tab><tab><tab>dr.cure(proc)<tab><tab><tab><tab>break,0,if not proc . is_alive or proc . is_frozen :,if not proc :,0.05451338893552124,5.2447643832804935,0.7
"def to_value(self, value):<tab># Tip: 'value' is the object returned by<tab>#<tab>  taiga.projects.history.models.HistoryEntry.values_diff()<tab>ret = {}<tab>for key, val in value.items():<tab><tab><IF-STMT><tab><tab><tab>ret[key] = val<tab><tab>elif key == ""points"":<tab><tab><tab>ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()}<tab><tab>else:<tab><tab><tab>ret[key] = {""from"": val[0], ""to"": val[1]}<tab>return ret",0,"if key in [ ""attachments"" , ""custom_attributes"" , ""description_diff"" ] :","if isinstance ( val , dict ) :",0.0133745220801175,1.4311312553952649,0.2761904761904762
"def default_generator(<tab>self, dataset, epochs=1, mode=""fit"", deterministic=True, pad_batches=True):<tab>for epoch in range(epochs):<tab><tab>for (X_b, y_b, w_b, ids_b) in dataset.iterbatches(<tab><tab><tab>batch_size=self.batch_size,<tab><tab><tab>deterministic=deterministic,<tab><tab><tab>pad_batches=pad_batches,<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dropout = np.array(0.0)<tab><tab><tab>else:<tab><tab><tab><tab>dropout = np.array(1.0)<tab><tab><tab>yield ([X_b, dropout], [y_b], [w_b])",0,"if mode == ""predict"" :",if epoch == self . epoch :,0.029730601197949243,13.134549472120788,0.35
"def _cygwin_hack_find_addresses(target):<tab>addresses = []<tab>for h in [<tab><tab>target,<tab><tab>""localhost"",<tab><tab>""127.0.0.1"",<tab>]:<tab><tab>try:<tab><tab><tab>addr = get_local_ip_for(h)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addresses.append(addr)<tab><tab>except socket.gaierror:<tab><tab><tab>pass<tab>return defer.succeed(addresses)",0,if addr not in addresses :,if addr :,0.050438393472541504,1e-10,0.39999999999999997
"def _get_notify(self, action_node):<tab>if action_node.name not in self._skip_notify_tasks:<tab><tab>if action_node.notify:<tab><tab><tab>task_notify = NotificationsHelper.to_model(action_node.notify)<tab><tab><tab>return task_notify<tab><tab><IF-STMT><tab><tab><tab>return self._chain_notify<tab>return None",0,elif self . _chain_notify :,elif action_node . chain_notify :,0.28535533905932736,34.32945239845197,0.6190476190476191
"def filterTokenLocation():<tab>i = None<tab>entry = None<tab>token = None<tab>tokens = []<tab>i = 0<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>entry = extra.tokens[i]<tab><tab>token = jsdict(<tab><tab><tab>{<tab><tab><tab><tab>""type"": entry.type,<tab><tab><tab><tab>""value"": entry.value,<tab><tab><tab>}<tab><tab>)<tab><tab>if extra.range:<tab><tab><tab>token.range = entry.range<tab><tab>if extra.loc:<tab><tab><tab>token.loc = entry.loc<tab><tab>tokens.append(token)<tab><tab>i += 1<tab>extra.tokens = tokens",0,if not ( i < len ( extra . tokens ) ) :,if i >= extra . tokens . length :,0.04691483574145144,13.76074141597786,0.24166666666666667
"def read(self, size=-1):<tab>buf = bytearray()<tab>while size != 0 and self.cursor < self.maxpos:<tab><tab>if not self.in_current_block(self.cursor):<tab><tab><tab>self.seek_to_block(self.cursor)<tab><tab>part = self.current_stream.read(size)<tab><tab><IF-STMT><tab><tab><tab>if len(part) == 0:<tab><tab><tab><tab>raise EOFError()<tab><tab><tab>size -= len(part)<tab><tab>self.cursor += len(part)<tab><tab>buf += part<tab>return bytes(buf)",0,if size > 0 :,if not part :,0.03675197809660419,14.794015674776452,0.3333333333333333
"def get_properties_from_model(model_class):<tab>""""""Show properties from a model""""""<tab>properties = []<tab>attr_names = [name for (name, value) in inspect.getmembers(model_class, isprop)]<tab>for attr_name in attr_names:<tab><tab><IF-STMT><tab><tab><tab>attr_names.remove(attr_name)<tab><tab>else:<tab><tab><tab>properties.append(<tab><tab><tab><tab>dict(label=attr_name, name=attr_name.strip(""_"").replace(""_"", "" ""))<tab><tab><tab>)<tab>return sorted(properties, key=lambda k: k[""label""])",0,"if attr_name . endswith ( ""pk"" ) :",if attr_name in model_class . __dict__ :,0.03676852316447079,18.20705281109213,0.5
"def __getitem__(self, name, set=set, getattr=getattr, id=id):<tab>visited = set()<tab>mydict = self.basedict<tab>while 1:<tab><tab>value = mydict[name]<tab><tab>if value is not None:<tab><tab><tab>return value<tab><tab>myid = id(mydict)<tab><tab>assert myid not in visited<tab><tab>visited.add(myid)<tab><tab>mydict = mydict.Parent<tab><tab><IF-STMT><tab><tab><tab>return",1,if mydict is None :,if mydict is None :,0.75,100.00000000000004,1.0
"def multicolumn(self, list, format, cols=4):<tab>""""""Format a list of items into a multi-column list.""""""<tab>result = """"<tab>rows = (len(list) + cols - 1) // cols<tab>for col in range(cols):<tab><tab>result = result + '<td width=""%d%%"" valign=top>' % (100 // cols)<tab><tab>for i in range(rows * col, rows * col + rows):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = result + format(list[i]) + ""<br>\n""<tab><tab>result = result + ""</td>""<tab>return '<table width=""100%%"" summary=""list""><tr>%s</tr></table>' % result",0,if i < len ( list ) :,if format is not None :,0.018517117658868813,6.916271812933183,0.20634920634920637
"def format_exc(exc=None):<tab>""""""Return exc (or sys.exc_info if None), formatted.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>exc = _exc_info()<tab><tab>if exc == (None, None, None):<tab><tab><tab>return """"<tab><tab>import traceback<tab><tab>return """".join(traceback.format_exception(*exc))<tab>finally:<tab><tab>del exc",1,if exc is None :,if exc is None :,0.75,100.00000000000004,1.0
"def assert_counts(res, lang, files, blank, comment, code):<tab>for line in res:<tab><tab>fields = line.split()<tab><tab>if len(fields) >= 5:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(files, int(fields[1]))<tab><tab><tab><tab>self.assertEqual(blank, int(fields[2]))<tab><tab><tab><tab>self.assertEqual(comment, int(fields[3]))<tab><tab><tab><tab>self.assertEqual(code, int(fields[4]))<tab><tab><tab><tab>return<tab>self.fail(""Found no output line for {}"".format(lang))",0,if fields [ 0 ] == lang :,"if fields [ 0 ] == ""counts"" :",0.41812130587366103,59.00468726392806,0.7777777777777778
"def __iter__(self):<tab>for name, value in self.__class__.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(value, flag_value):<tab><tab><tab>yield (name, self._has_flag(value.flag))",0,"if isinstance ( value , alias_flag_value ) :","if name . startswith ( ""_"" ) :",0.03622895148520873,8.639795714750207,0.3333333333333333
"def optimize_models(args, use_cuda, models):<tab>""""""Optimize ensemble for generation""""""<tab>for model in models:<tab><tab>model.make_generation_fast_(<tab><tab><tab>beamable_mm_beam_size=None if args.no_beamable_mm else args.beam,<tab><tab><tab>need_attn=args.print_alignment,<tab><tab>)<tab><tab>if args.fp16:<tab><tab><tab>model.half()<tab><tab><IF-STMT><tab><tab><tab>model.cuda()",1,if use_cuda :,if use_cuda :,0.5311706625951745,1e-10,1.0
"def convertstore(self, mydict):<tab>targetheader = self.mypofile.header()<tab>targetheader.addnote(""extracted from web2py"", ""developer"")<tab>for source_str in mydict.keys():<tab><tab>target_str = mydict[source_str]<tab><tab>if target_str == source_str:<tab><tab><tab># a convention with new (untranslated) web2py files<tab><tab><tab>target_str = u""""<tab><tab><IF-STMT><tab><tab><tab># an older convention<tab><tab><tab>target_str = u""""<tab><tab>pounit = self.convertunit(source_str, target_str)<tab><tab>self.mypofile.addunit(pounit)<tab>return self.mypofile",0,"elif target_str . startswith ( u""*** "" ) :",elif target_str == source_str :,0.028155587320909295,16.847111051295393,0.6444444444444445
"def __sparse_values_set(instances, static_col_indexes: list):<tab>tmp_result = {idx: set() for idx in static_col_indexes}<tab>for _, instance in instances:<tab><tab>data_generator = instance.features.get_all_data()<tab><tab>for idx, value in data_generator:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>tmp_result[idx].add(value)<tab>result = [tmp_result[x] for x in static_col_indexes]<tab>return result",0,if idx not in tmp_result :,if value is None :,0.12713659235259708,6.9717291216921975,0.25
def puts(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.puts_ is None:<tab><tab><tab><tab>self.puts_ = PutRequest()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.puts_,1,if self . puts_ is None :,if self . puts_ is None :,0.75,100.00000000000004,1.0
"def run(self, args, **kwargs):<tab>if args.resource_ref or args.policy_type:<tab><tab>filters = {}<tab><tab>if args.resource_ref:<tab><tab><tab>filters[""resource_ref""] = args.resource_ref<tab><tab><IF-STMT><tab><tab><tab>filters[""policy_type""] = args.policy_type<tab><tab>filters.update(**kwargs)<tab><tab>return self.manager.query(**filters)<tab>else:<tab><tab>return self.manager.get_all(**kwargs)",1,if args . policy_type :,if args . policy_type :,0.75,100.00000000000004,1.0
"def Get_Gene(self, id):<tab>""""""Retreive the gene name (GN).""""""<tab>entry = self.Get(id)<tab>if not entry:<tab><tab>return None<tab>GN = """"<tab>for line in string.split(entry, ""\n""):<tab><tab>if line[0:5] == ""GN   "":<tab><tab><tab>GN = string.strip(line[5:])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>GN = GN[0:-1]<tab><tab><tab>return GN<tab><tab>if line[0:2] == ""//"":<tab><tab><tab>break<tab>return GN",1,"if GN [ - 1 ] == ""."" :","if GN [ - 1 ] == ""."" :",0.75,100.00000000000004,1.0
"def processMovie(self, atom):<tab>for field in atom:<tab><tab><IF-STMT><tab><tab><tab>self.processTrack(field[""track""])<tab><tab>if ""movie_hdr"" in field:<tab><tab><tab>self.processMovieHeader(field[""movie_hdr""])",1,"if ""track"" in field :","if ""track"" in field :",0.75,100.00000000000004,1.0
"def get_next_video_frame(self, skip_empty_frame=True):<tab>if not self.video_format:<tab><tab>return<tab>while True:<tab><tab># We skip video packets which are not video frames<tab><tab># This happens in mkv files for the first few frames.<tab><tab>video_packet = self._get_video_packet()<tab><tab><IF-STMT><tab><tab><tab>self._decode_video_packet(video_packet)<tab><tab>if video_packet.image is not None or not skip_empty_frame:<tab><tab><tab>break<tab>if _debug:<tab><tab>print(""Returning"", video_packet)<tab>return video_packet.image",0,if video_packet . image == 0 :,if video_packet :,0.03885753308224148,1e-10,0.45
"def get_devices(display=None):<tab>base = ""/dev/input""<tab>for filename in os.listdir(base):<tab><tab>if filename.startswith(""event""):<tab><tab><tab>path = os.path.join(base, filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>try:<tab><tab><tab><tab>_devices[path] = EvdevDevice(display, path)<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass<tab>return list(_devices.values())",0,if path in _devices :,if not os . path . exists ( path ) :,0.02506468314974991,4.9323515694897075,0.25274725274725274
"def _ensure_header_written(self, datasize):<tab>if not self._headerwritten:<tab><tab>if not self._nchannels:<tab><tab><tab>raise Error(""# channels not specified"")<tab><tab><IF-STMT><tab><tab><tab>raise Error(""sample width not specified"")<tab><tab>if not self._framerate:<tab><tab><tab>raise Error(""sampling rate not specified"")<tab><tab>self._write_header(datasize)",1,if not self . _sampwidth :,if not self . _sampwidth :,0.75,100.00000000000004,1.0
"def process(self, fuzzresult):<tab>base_url = urljoin(fuzzresult.url, "".."")<tab>for line in fuzzresult.history.content.splitlines():<tab><tab>record = line.split(""/"")<tab><tab>if len(record) == 6 and record[1]:<tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab># Directory<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab><tab>self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))",0,"if record [ 0 ] == ""D"" :",elif len ( record ) == 3 and record [ 1 ] :,0.027014115775369447,8.889175589171739,0.08333333333333333
"def tearDown(self):<tab>""""""Shutdown the UDP server.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.server.stop(2.0)<tab><tab>if self.sock_hdlr:<tab><tab><tab>self.root_logger.removeHandler(self.sock_hdlr)<tab><tab><tab>self.sock_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",1,if self . server :,if self . server :,0.75,100.00000000000004,1.0
"def get_backend(find_library=None):<tab>try:<tab><tab>global _lib, _ctx<tab><tab><IF-STMT><tab><tab><tab>_lib = _load_library(find_library)<tab><tab><tab>_setup_prototypes(_lib)<tab><tab><tab>_ctx = _Context()<tab><tab>_logger.warning(<tab><tab><tab>""OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284)""<tab><tab>)<tab><tab>return _OpenUSB()<tab>except usb.libloader.LibraryException:<tab><tab># exception already logged (if any)<tab><tab>_logger.error(""Error loading OpenUSB backend"", exc_info=False)<tab><tab>return None<tab>except Exception:<tab><tab>_logger.error(""Error loading OpenUSB backend"", exc_info=True)<tab><tab>return None",1,if _lib is None :,if _lib is None :,0.75,100.00000000000004,1.0
"def __init__(self, event, event_info, fields=[]):<tab>_wmi_object.__init__(self, event, fields=fields)<tab>_set(self, ""event_type"", None)<tab>_set(self, ""timestamp"", None)<tab>_set(self, ""previous"", None)<tab>if event_info:<tab><tab>event_type = self.event_type_re.match(event_info.Path_.Class).group(1).lower()<tab><tab>_set(self, ""event_type"", event_type)<tab><tab>if hasattr(event_info, ""TIME_CREATED""):<tab><tab><tab>_set(self, ""timestamp"", from_1601(event_info.TIME_CREATED))<tab><tab><IF-STMT><tab><tab><tab>_set(self, ""previous"", event_info.PreviousInstance)",1,"if hasattr ( event_info , ""PreviousInstance"" ) :","if hasattr ( event_info , ""PreviousInstance"" ) :",0.75,100.00000000000004,1.0
"def _getListNextPackagesReadyToBuild():<tab>for pkg in Scheduler.listOfPackagesToBuild:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if constants.rpmCheck or Scheduler._checkNextPackageIsReadyToBuild(pkg):<tab><tab><tab>Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg))<tab><tab><tab>Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",0,if pkg in Scheduler . listOfPackagesCurrentlyBuilding :,if pkg in Scheduler . listOfPackagesToBuild :,0.574113272471593,64.34588841607616,0.7142857142857143
"def process_all(self, lines, times=1):<tab>gap = False<tab>for _ in range(times):<tab><tab>for line in lines:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.write("""")<tab><tab><tab>self.process(line)<tab><tab><tab>if not is_command(line):<tab><tab><tab><tab>gap = True<tab>return 0",1,if gap :,if gap :,0.5311706625951745,1e-10,1.0
"def diff(old, new, display=True):<tab>""""""Nice colored diff implementation""""""<tab>if not isinstance(old, list):<tab><tab>old = decolorize(str(old)).splitlines()<tab>if not isinstance(new, list):<tab><tab>new = decolorize(str(new)).splitlines()<tab>line_types = {"" "": ""%Reset"", ""-"": ""%Red"", ""+"": ""%Green"", ""?"": ""%Pink""}<tab>if display:<tab><tab>for line in difflib.Differ().compare(old, new):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>print(colorize(line_types[line[0]], line))<tab>return old != new",0,"if line . startswith ( ""?"" ) :",if line [ 0 ] in line_types :,0.03440097137874616,9.287528999566801,0.48148148148148145
"def get_limit(self, request):<tab>if self.limit_query_param:<tab><tab>try:<tab><tab><tab>limit = int(request.query_params[self.limit_query_param])<tab><tab><tab>if limit < 0:<tab><tab><tab><tab>raise ValueError()<tab><tab><tab># Enforce maximum page size, if defined<tab><tab><tab>if settings.MAX_PAGE_SIZE:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return settings.MAX_PAGE_SIZE<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return min(limit, settings.MAX_PAGE_SIZE)<tab><tab><tab>return limit<tab><tab>except (KeyError, ValueError):<tab><tab><tab>pass<tab>return self.default_limit",1,if limit == 0 :,if limit == 0 :,0.75,100.00000000000004,1.0
"def slice_fill(self, slice_):<tab>""Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true""<tab>if isinstance(self.indexes, int):<tab><tab>new_slice_ = [0]<tab><tab>offset = 0<tab>else:<tab><tab>new_slice_ = [slice_[0]]<tab><tab>offset = 1<tab>for i in range(1, len(self.nums)):<tab><tab>if self.squeeze_dims[i]:<tab><tab><tab>new_slice_.append(0)<tab><tab><IF-STMT><tab><tab><tab>new_slice_.append(slice_[offset])<tab><tab><tab>offset += 1<tab>new_slice_ += slice_[offset:]<tab>return new_slice_",0,elif offset < len ( slice_ ) :,elif len ( slice_ ) > offset :,0.19881768219176266,50.197242487957936,0.5
"def wrapper(*args, **kw):<tab>instance = args[0]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>ret_dict = instance._create_ret_object(<tab><tab><tab><tab>instance.FAILURE, None, True, instance.MUST_JSON<tab><tab><tab>)<tab><tab><tab>instance.logger.error(instance.MUST_JSON)<tab><tab><tab>return jsonify(ret_dict), 400<tab>except BadRequest:<tab><tab>ret_dict = instance._create_ret_object(<tab><tab><tab>instance.FAILURE, None, True, instance.MUST_JSON<tab><tab>)<tab><tab>instance.logger.error(instance.MUST_JSON)<tab><tab>return jsonify(ret_dict), 400<tab>instance.logger.debug(""JSON is valid"")<tab>return f(*args, **kw)",0,if request . get_json ( ) is None :,if not instance . is_valid ( ) :,0.03313893421568771,10.386397294360817,0.27272727272727276
"def add_css(self, data):<tab>if data:<tab><tab>for medium, paths in data.items():<tab><tab><tab>for path in paths:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._css.setdefault(medium, []).append(path)",0,if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,if path not in self . _css :,0.09967413232949798,16.317036991142917,0.19658119658119658
"def mangle_template(template: str, template_vars: Set[str]) -> str:<tab>if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template:<tab><tab>raise Exception(""Cannot parse a template containing reserved strings"")<tab>for var in template_vars:<tab><tab>original = f""{{{var}}}""<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>f'Template string is missing a reference to ""{var}"" referred to in kwargs'<tab><tab><tab>)<tab><tab>template = template.replace(original, mangled_name(var))<tab>return template",0,if original not in template :,if var not in template :,0.5212518808542342,53.7284965911771,0.7142857142857143
"def filterSimilarKeywords(keyword, kwdsIterator):<tab>""""""Return a sorted list of keywords similar to the one given.""""""<tab>seenDict = {}<tab>kwdSndx = soundex(keyword.encode(""ascii"", ""ignore""))<tab>matches = []<tab>matchesappend = matches.append<tab>checkContained = False<tab>if len(keyword) > 4:<tab><tab>checkContained = True<tab>for movieID, key in kwdsIterator:<tab><tab>if key in seenDict:<tab><tab><tab>continue<tab><tab>seenDict[key] = None<tab><tab>if checkContained and keyword in key:<tab><tab><tab>matchesappend(key)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>matchesappend(key)<tab>return _sortKeywords(keyword, matches)",0,"if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :",if kwdSndx in key :,0.013887228846722825,1.26492199361622,0.5646258503401361
"def GetInfo(self):<tab>for k, v in sorted(self.memory_parameters.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not v:<tab><tab><tab>continue<tab><tab>print(""%s: \t%#08x (%s)"" % (k, v, v))<tab>print(""Memory ranges:"")<tab>print(""Start\t\tEnd\t\tLength"")<tab>for start, length in self.runs:<tab><tab>print(""0x%X\t\t0x%X\t\t0x%X"" % (start, start + length, length))",0,"if k . startswith ( ""Pad"" ) :",if k not in self . memory_parameters :,0.03622895148520873,9.980099403873663,0.39285714285714285
"def Children(self):<tab>""""""Returns a list of all of this object's owned (strong) children.""""""<tab>children = []<tab>for property, attributes in self._schema.iteritems():<tab><tab>(is_list, property_type, is_strong) = attributes[0:3]<tab><tab>if is_strong and property in self._properties:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>children.append(self._properties[property])<tab><tab><tab>else:<tab><tab><tab><tab>children.extend(self._properties[property])<tab>return children",0,if not is_list :,if is_list :,0.09648852821835877,1e-10,0.6
"def normalize_res_identifier(self, emu, cw, val):<tab>mask = (16 ** (emu.get_ptr_size() // 2) - 1) << 16<tab>if val & mask:  # not an INTRESOURCE<tab><tab>name = emu.read_mem_string(val, cw)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>name = int(name[1:])<tab><tab><tab>except Exception:<tab><tab><tab><tab>return 0<tab>else:<tab><tab>name = val<tab>return name",0,"if name [ 0 ] == ""#"" :","if name . startswith ( ""0x"" ) :",0.03440097137874616,9.548450962056531,0.6
"def _optimize(self, solutions):<tab>best_a = None<tab>best_silhouette = None<tab>best_k = None<tab>for a, silhouette, k in solutions():<tab><tab>if best_silhouette is None:<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>best_silhouette = silhouette<tab><tab>best_a = a<tab><tab>best_k = k<tab>return best_a, best_silhouette, best_k",0,elif silhouette <= best_silhouette :,elif silhouette == best_silhouette :,0.08034284189446517,59.4603557501361,1.0
"def find_commit_type(sha):<tab>try:<tab><tab>o = obj_store[sha]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>raise<tab>else:<tab><tab>if isinstance(o, Commit):<tab><tab><tab>commits.add(sha)<tab><tab>elif isinstance(o, Tag):<tab><tab><tab>tags.add(sha)<tab><tab><tab>commits.add(o.object[1])<tab><tab>else:<tab><tab><tab>raise KeyError(""Not a commit or a tag: %s"" % sha)",0,if not ignore_unknown :,if o is None :,0.04240785919217091,10.400597689005304,0.25
"def on_search_entry_keypress(self, widget, event):<tab>key = Gdk.keyval_name(event.keyval)<tab>if key == ""Escape"":<tab><tab>self.hide_search_box()<tab>elif key == ""Return"":<tab><tab># Combine with Shift?<tab><tab><IF-STMT><tab><tab><tab>self.search_prev = False<tab><tab><tab>self.do_search(None)<tab><tab>else:<tab><tab><tab>self.search_prev = True",0,if event . state & Gdk . ModifierType . SHIFT_MASK :,if self . search_prev :,0.06241787918570013,3.9413751108533592,0.2571428571428572
"def process_webhook_prop(namespace):<tab>if not isinstance(namespace.webhook_properties, list):<tab><tab>return<tab>result = {}<tab>for each in namespace.webhook_properties:<tab><tab><IF-STMT><tab><tab><tab>if ""="" in each:<tab><tab><tab><tab>key, value = each.split(""="", 1)<tab><tab><tab>else:<tab><tab><tab><tab>key, value = each, """"<tab><tab><tab>result[key] = value<tab>namespace.webhook_properties = result",0,if each :,"if isinstance ( each , str ) :",0.046522600101893324,1e-10,0.36
"def run(self):<tab>global WAITING_BEFORE_START<tab>time.sleep(WAITING_BEFORE_START)<tab>while self.keep_alive:<tab><tab>path_id, module, resolve = self.queue_receive.get()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.lock.acquire()<tab><tab>self.modules[path_id] = module<tab><tab>self.lock.release()<tab><tab>if resolve:<tab><tab><tab>resolution = self._resolve_with_other_modules(resolve)<tab><tab><tab>self._relations[path_id] = []<tab><tab><tab>for package in resolution:<tab><tab><tab><tab>self._relations[path_id].append(resolution[package])<tab><tab><tab>self.queue_send.put((path_id, module, False, resolution))",1,if path_id is None :,if path_id is None :,0.75,100.00000000000004,1.0
"def _get_download_link(self, url, download_type=""torrent""):<tab>links = {<tab><tab>""torrent"": """",<tab><tab>""magnet"": """",<tab>}<tab>try:<tab><tab>data = self.session.get(url).text<tab><tab>with bs4_parser(data) as html:<tab><tab><tab>downloads = html.find(""div"", {""class"": ""download""})<tab><tab><tab>if downloads:<tab><tab><tab><tab>for download in downloads.findAll(""a""):<tab><tab><tab><tab><tab>link = download[""href""]<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>links[""magnet""] = link<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>links[""torrent""] = urljoin(self.urls[""base_url""], link)<tab>except Exception:<tab><tab>pass<tab>return links[download_type]",1,"if link . startswith ( ""magnet"" ) :","if link . startswith ( ""magnet"" ) :",0.75,100.00000000000004,1.0
"def _parse_fields(cls, read):<tab>read = unicode_to_str(read)<tab>if type(read) is not str:<tab><tab>_wrong_type_for_arg(read, ""str"", ""read"")<tab>fields = {}<tab>while read and read[0] != "";"":<tab><tab><IF-STMT><tab><tab><tab>DeserializeError(read, ""does not separate fields with commas"")<tab><tab>read = read[1:]<tab><tab>key, _type, value, read = cls._parse_field(read)<tab><tab>fields[key] = (_type, value)<tab>if read:<tab><tab># read[0] == ';'<tab><tab>read = read[1:]<tab>return fields, read",0,"if read and read [ 0 ] != "","" :","if read [ 0 ] == "","" :",0.2834467988534143,52.01772843458376,0.5
"def _convertDict(self, d):<tab>r = {}<tab>for k, v in d.items():<tab><tab><IF-STMT><tab><tab><tab>v = str(v, ""utf-8"")<tab><tab>elif isinstance(v, list) or isinstance(v, tuple):<tab><tab><tab>v = self._convertList(v)<tab><tab>elif isinstance(v, dict):<tab><tab><tab>v = self._convertDict(v)<tab><tab>if isinstance(k, bytes):<tab><tab><tab>k = str(k, ""utf-8"")<tab><tab>r[k] = v<tab>return r",1,"if isinstance ( v , bytes ) :","if isinstance ( v , bytes ) :",0.75,100.00000000000004,1.0
"def wrapper(filename):<tab>mtime = getmtime(filename)<tab>with lock:<tab><tab>if filename in cache:<tab><tab><tab>old_mtime, result = cache.pop(filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Move to the end<tab><tab><tab><tab>cache[filename] = old_mtime, result<tab><tab><tab><tab>return result<tab>result = function(filename)<tab>with lock:<tab><tab>cache[filename] = mtime, result  # at the end<tab><tab>if len(cache) > max_size:<tab><tab><tab>cache.popitem(last=False)<tab>return result",0,if old_mtime == mtime :,if old_mtime != mtime :,0.33141502097923065,50.000000000000014,1.0
def isFinished(self):<tab># returns true if episode timesteps has reached episode length and resets the task<tab>if self.count > self.epiLen:<tab><tab>self.res()<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.pertGlasPos(0)<tab><tab>if self.count == self.epiLen / 2 + 1:<tab><tab><tab>self.env.reset()<tab><tab><tab>self.pertGlasPos(1)<tab><tab>self.count += 1<tab><tab>return False,0,if self . count == 1 :,if self . count == self . episLen / 2 + 1 :,0.3849273190605245,39.34995962231127,0.49523809523809526
"def _check_vulnerabilities(self, processed_analysis):<tab>matched_vulnerabilities = list()<tab>for vulnerability in self._rule_base_vulnerabilities:<tab><tab><IF-STMT><tab><tab><tab>vulnerability_data = vulnerability.get_dict()<tab><tab><tab>name = vulnerability_data.pop(""short_name"")<tab><tab><tab>matched_vulnerabilities.append((name, vulnerability_data))<tab>return matched_vulnerabilities",0,"if evaluate ( processed_analysis , vulnerability . rule ) :",if vulnerability . get_analysis ( ) == processed_analysis :,0.031226227475275044,15.396503757846457,0.37142857142857144
"def _table_reprfunc(self, row, col, val):<tab>if self._table.column_names[col].endswith(""Size""):<tab><tab><IF-STMT><tab><tab><tab>return ""  %s"" % val<tab><tab>elif val < 1024 ** 2:<tab><tab><tab>return ""  %.1f KB"" % (val / 1024.0 ** 1)<tab><tab>elif val < 1024 ** 3:<tab><tab><tab>return ""  %.1f MB"" % (val / 1024.0 ** 2)<tab><tab>else:<tab><tab><tab>return ""  %.1f GB"" % (val / 1024.0 ** 3)<tab>if col in (0, """"):<tab><tab>return str(val)<tab>else:<tab><tab>return ""  %s"" % val",0,"if isinstance ( val , compat . string_types ) :",if val < 1024 ** 1 :,0.014969815225505462,4.408194605881708,0.2857142857142857
"def serve_until_stopped(self) -> None:<tab>while True:<tab><tab>rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout)<tab><tab>if rd:<tab><tab><tab>self.handle_request()<tab><tab><IF-STMT><tab><tab><tab>break",0,if self . event is not None and self . event . is_set ( ) :,if not rd :,0.00604668680656809,0.6348217867467392,0.18888888888888888
"def resize(self, *e):<tab>bold = (""helvetica"", -self._size.get(), ""bold"")<tab>helv = (""helvetica"", -self._size.get())<tab>xspace = self._size.get()<tab>yspace = self._size.get()<tab>for widget in self._widgets:<tab><tab>widget[""node_font""] = bold<tab><tab>widget[""leaf_font""] = helv<tab><tab>widget[""xspace""] = xspace<tab><tab>widget[""yspace""] = yspace<tab><tab>if self._size.get() < 20:<tab><tab><tab>widget[""line_width""] = 1<tab><tab><IF-STMT><tab><tab><tab>widget[""line_width""] = 2<tab><tab>else:<tab><tab><tab>widget[""line_width""] = 3<tab>self._layout()",0,elif self . _size . get ( ) < 30 :,elif self . _size . get ( ) < 20 :,0.653527863746399,82.651681837938,0.6666666666666666
"def __assertTilesChangedInRegion(self, t1, t2, region):<tab>for tileOriginTuple in t1.keys():<tab><tab>tileOrigin = imath.V2i(*tileOriginTuple)<tab><tab>tileRegion = imath.Box2i(<tab><tab><tab>tileOrigin, tileOrigin + imath.V2i(GafferImage.ImagePlug.tileSize())<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.assertNotEqual(t1[tileOriginTuple], t2[tileOriginTuple])<tab><tab>else:<tab><tab><tab>self.assertEqual(t1[tileOriginTuple], t2[tileOriginTuple])",0,"if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :",if region == tileOriginTuple :,0.010805043283377891,3.9297526283216277,0.225
"def grouped_by_prefix(args, prefixes):<tab>""""""Group behave args by (directory) scope into multiple test-runs.""""""<tab>group_args = []<tab>current_scope = None<tab>for arg in args.strip().split():<tab><tab>assert not arg.startswith(""-""), ""REQUIRE: arg, not options""<tab><tab>scope = select_prefix_for(arg, prefixes)<tab><tab>if scope != current_scope:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># -- DETECTED GROUP-END:<tab><tab><tab><tab>yield "" "".join(group_args)<tab><tab><tab><tab>group_args = []<tab><tab><tab>current_scope = scope<tab><tab>group_args.append(arg)<tab>if group_args:<tab><tab>yield "" "".join(group_args)",1,if group_args :,if group_args :,0.5311706625951745,1e-10,1.0
"def __print__(self, defaults=False):<tab>if defaults:<tab><tab>print_func = str<tab>else:<tab><tab>print_func = repr<tab>pieces = []<tab>default_values = self.__defaults__<tab>for k in self.__fields__:<tab><tab>value = getattr(self, k)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(value, basestring):<tab><tab><tab>print_func = repr  # keep quotes around strings<tab><tab>pieces.append(""%s=%s"" % (k, print_func(value)))<tab>if pieces or self.__base__:<tab><tab>return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces))<tab>else:<tab><tab>return """"",0,if not defaults and value == default_values [ k ] :,if value is default_values :,0.07555571723634326,10.694820729788422,0.22115384615384615
"def setInnerHTML(self, html):<tab>log.HTMLClassifier.classify(<tab><tab>log.ThugLogging.url if log.ThugOpts.local else log.last_url, html<tab>)<tab>self.tag.clear()<tab>for node in bs4.BeautifulSoup(html, ""html.parser"").contents:<tab><tab>self.tag.append(node)<tab><tab>name = getattr(node, ""name"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>handler = getattr(log.DFT, ""handle_%s"" % (name,), None)<tab><tab>if handler:<tab><tab><tab>handler(node)",1,if name is None :,if name is None :,0.75,100.00000000000004,1.0
"def createFields(self):<tab>yield Enum(Bits(self, ""class"", 2), self.CLASS_DESC)<tab>yield Enum(Bit(self, ""form""), self.FORM_DESC)<tab>if self[""class""].value == 0:<tab><tab>yield Enum(Bits(self, ""type"", 5), self.TYPE_DESC)<tab>else:<tab><tab>yield Bits(self, ""type"", 5)<tab>yield ASNInteger(self, ""size"", ""Size in bytes"")<tab>size = self[""size""].value<tab>if size:<tab><tab><IF-STMT><tab><tab><tab>for field in self._handler(self, size):<tab><tab><tab><tab>yield field<tab><tab>else:<tab><tab><tab>yield RawBytes(self, ""raw"", size)",1,if self . _handler :,if self . _handler :,0.75,100.00000000000004,1.0
"def _process_service_request(self, pkttype, pktid, packet):<tab>""""""Process a service request""""""<tab># pylint: disable=unused-argument<tab>service = packet.get_string()<tab>packet.check_end()<tab>if service == self._next_service:<tab><tab>self.logger.debug2(""Accepting request for service %s"", service)<tab><tab>self._next_service = None<tab><tab>self.send_packet(MSG_SERVICE_ACCEPT, String(service))<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>self._auth_in_progress = True<tab><tab><tab>self._send_deferred_packets()<tab>else:<tab><tab>raise DisconnectError(<tab><tab><tab>DISC_SERVICE_NOT_AVAILABLE, ""Unexpected service request received""<tab><tab>)",0,if self . is_server ( ) and service == _USERAUTH_SERVICE :,elif self . _auth_in_progress :,0.0196744990337318,5.484683161991908,0.3125
"def _read_fixed_body(<tab>self, content_length: int, delegate: httputil.HTTPMessageDelegate) -> None:<tab>while content_length > 0:<tab><tab>body = await self.stream.read_bytes(<tab><tab><tab>min(self.params.chunk_size, content_length), partial=True<tab><tab>)<tab><tab>content_length -= len(body)<tab><tab><IF-STMT><tab><tab><tab>with _ExceptionLoggingContext(app_log):<tab><tab><tab><tab>ret = delegate.data_received(body)<tab><tab><tab><tab>if ret is not None:<tab><tab><tab><tab><tab>await ret",0,if not self . _write_finished or self . is_client :,if delegate is not None :,0.08621481525880244,2.5612540390806937,0.25
"def wait_for_child(pid, timeout=1.0):<tab>deadline = mitogen.core.now() + timeout<tab>while timeout < mitogen.core.now():<tab><tab>try:<tab><tab><tab>target_pid, status = os.waitpid(pid, os.WNOHANG)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>if e.args[0] == errno.ECHILD:<tab><tab><tab><tab>return<tab><tab>time.sleep(0.05)<tab>assert False, ""wait_for_child() timed out""",0,if target_pid == pid :,if target_pid == deadline :,0.39477865547525276,70.71067811865478,0.5
"def execute(cls, ctx, op: ""DataFrameGroupByAgg""):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab>if op.stage == OperandStage.map:<tab><tab><tab>cls._execute_map(ctx, op)<tab><tab><IF-STMT><tab><tab><tab>cls._execute_combine(ctx, op)<tab><tab>elif op.stage == OperandStage.agg:<tab><tab><tab>cls._execute_agg(ctx, op)<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise ValueError(""Aggregation operand not executable"")<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",1,elif op . stage == OperandStage . combine :,elif op . stage == OperandStage . combine :,0.75,100.00000000000004,1.0
def cut(sentence):<tab>sentence = strdecode(sentence)<tab>blocks = re_han.split(sentence)<tab>for blk in blocks:<tab><tab>if re_han.match(blk):<tab><tab><tab>for word in __cut(blk):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield word<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>for c in word:<tab><tab><tab><tab><tab><tab>yield c<tab><tab>else:<tab><tab><tab>tmp = re_skip.split(blk)<tab><tab><tab>for x in tmp:<tab><tab><tab><tab>if x:<tab><tab><tab><tab><tab>yield x,0,if word not in Force_Split_Words :,if len ( word ) == 1 :,0.023749771747382555,5.61480827173619,0.2857142857142857
"def _iter_tags(self, type=None):<tab>""""""Yield all raw tags (limit to |type| if specified)""""""<tab>for n in itertools.count():<tab><tab>tag = self._get_tag(n)<tab><tab><IF-STMT><tab><tab><tab>yield tag<tab><tab>if tag[""d_tag""] == ""DT_NULL"":<tab><tab><tab>break",0,"if type is None or tag [ ""d_tag"" ] == type :","if type and tag [ ""d_tag"" ] == type :",0.5125070353543804,72.1350012406248,0.2916666666666667
"def reverse_search_history(self, searchfor, startpos=None):<tab>if startpos is None:<tab><tab>startpos = self.history_cursor<tab>if _ignore_leading_spaces:<tab><tab>res = [<tab><tab><tab>(idx, line.lstrip())<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab>if line.lstrip().startswith(searchfor.lstrip())<tab><tab>]<tab>else:<tab><tab>res = [<tab><tab><tab>(idx, line)<tab><tab><tab>for idx, line in enumerate(self.history[startpos:0:-1])<tab><tab><tab><IF-STMT><tab><tab>]<tab>if res:<tab><tab>self.history_cursor -= res[0][0]<tab><tab>return res[0][1].get_line_text()<tab>return """"",0,if line . startswith ( searchfor ),if line . rstrip ( ) . startswith ( searchfor . rstrip ( ) ),0.20813505308049665,23.793665482062607,0.48333333333333334
"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># Oracle doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Oracle backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return unicode(value)",1,if settings . USE_TZ :,if settings . USE_TZ :,0.75,100.00000000000004,1.0
"def _sniff(filename, oxlitype):<tab>try:<tab><tab>with open(filename, ""rb"") as fileobj:<tab><tab><tab>header = fileobj.read(4)<tab><tab><tab>if header == b""OXLI"":<tab><tab><tab><tab>fileobj.read(1)  # skip the version number<tab><tab><tab><tab>ftype = fileobj.read(1)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab>return False<tab>except OSError:<tab><tab>return False",0,if binascii . hexlify ( ftype ) == oxlitype :,if ftype == oxlitype :,0.059382556937524214,24.439253249722206,0.3055555555555556
"def unget(self, char):<tab># Only one character is allowed to be ungotten at once - it must<tab># be consumed again before any further call to unget<tab>if char is not EOF:<tab><tab><IF-STMT><tab><tab><tab># unget is called quite rarely, so it's a good idea to do<tab><tab><tab># more work here if it saves a bit of work in the frequently<tab><tab><tab># called char and charsUntil.<tab><tab><tab># So, just prepend the ungotten character onto the current<tab><tab><tab># chunk:<tab><tab><tab>self.chunk = char + self.chunk<tab><tab><tab>self.chunkSize += 1<tab><tab>else:<tab><tab><tab>self.chunkOffset -= 1<tab><tab><tab>assert self.chunk[self.chunkOffset] == char",1,if self . chunkOffset == 0 :,if self . chunkOffset == 0 :,0.75,100.00000000000004,1.0
"def scan(rule, extensions, paths, ignore_paths=None):<tab>""""""The libsast scan.""""""<tab>try:<tab><tab>options = {<tab><tab><tab>""match_rules"": rule,<tab><tab><tab>""match_extensions"": extensions,<tab><tab><tab>""ignore_paths"": ignore_paths,<tab><tab><tab>""show_progress"": False,<tab><tab>}<tab><tab>scanner = Scanner(options, paths)<tab><tab>res = scanner.scan()<tab><tab><IF-STMT><tab><tab><tab>return format_findings(res[""pattern_matcher""], paths[0])<tab>except Exception:<tab><tab>logger.exception(""libsast scan"")<tab>return {}",0,if res :,"if res and ""pattern_matcher"" in res :",0.10204000938483246,1e-10,0.44761904761904764
"def _getPatternTemplate(pattern, key=None):<tab>if key is None:<tab><tab>key = pattern<tab><tab><IF-STMT><tab><tab><tab>key = pattern.upper()<tab>template = DD_patternCache.get(key)<tab>if not template:<tab><tab>if key in (""EPOCH"", ""{^LN-BEG}EPOCH"", ""^EPOCH""):<tab><tab><tab>template = DateEpoch(lineBeginOnly=(key != ""EPOCH""))<tab><tab>elif key in (""TAI64N"", ""{^LN-BEG}TAI64N"", ""^TAI64N""):<tab><tab><tab>template = DateTai64n(wordBegin=(""start"" if key != ""TAI64N"" else False))<tab><tab>else:<tab><tab><tab>template = DatePatternRegex(pattern)<tab>DD_patternCache.set(key, template)<tab>return template",0,"if ""%"" not in pattern :","if isinstance ( pattern , str ) :",0.023749771747382555,7.267884212102741,0.2857142857142857
"def _forward_response(self, src, dst):<tab>""""""Forward an SCP response between two remote SCP servers""""""<tab># pylint: disable=no-self-use<tab>try:<tab><tab>exc = yield from src.await_response()<tab><tab><IF-STMT><tab><tab><tab>dst.send_error(exc)<tab><tab><tab>return exc<tab><tab>else:<tab><tab><tab>dst.send_ok()<tab><tab><tab>return None<tab>except OSError as exc:<tab><tab>return exc",1,if exc :,if exc :,0.5311706625951745,1e-10,1.0
"def _maybe_signal_recovery_end() -> None:<tab>if self.in_recovery and not self.active_remaining_total():<tab><tab># apply anything stuck in the buffers<tab><tab>self.flush_buffers()<tab><tab>self._set_recovery_ended()<tab><tab><IF-STMT><tab><tab><tab>self._actives_span.set_tag(""Actives-Ready"", True)<tab><tab>self.signal_recovery_end.set()",0,if self . _actives_span is not None :,if self . _actives_span :,0.2343345094426703,59.755798910891144,0.4444444444444444
"def main():<tab>tmpdir = None<tab>try:<tab><tab># Create a temporary working directory<tab><tab>tmpdir = tempfile.mkdtemp()<tab><tab># Unpack the zipfile into the temporary directory<tab><tab>pip_zip = os.path.join(tmpdir, ""pip.zip"")<tab><tab>with open(pip_zip, ""wb"") as fp:<tab><tab><tab>fp.write(b85decode(DATA.replace(b""\n"", b"""")))<tab><tab># Add the zipfile to sys.path so that we can import it<tab><tab>sys.path.insert(0, pip_zip)<tab><tab># Run the bootstrap<tab><tab>bootstrap(tmpdir=tmpdir)<tab>finally:<tab><tab># Clean up our temporary working directory<tab><tab><IF-STMT><tab><tab><tab>shutil.rmtree(tmpdir, ignore_errors=True)",0,if tmpdir :,if tmpdir is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def __init__(self, api_version_str):<tab>try:<tab><tab>self.latest = self.preview = False<tab><tab>self.yyyy = self.mm = self.dd = None<tab><tab>if api_version_str == ""latest"":<tab><tab><tab>self.latest = True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.preview = True<tab><tab><tab>parts = api_version_str.split(""-"")<tab><tab><tab>self.yyyy = int(parts[0])<tab><tab><tab>self.mm = int(parts[1])<tab><tab><tab>self.dd = int(parts[2])<tab>except (ValueError, TypeError):<tab><tab>raise ValueError(<tab><tab><tab>""The API version {} is not in a "" ""supported format"".format(api_version_str)<tab><tab>)",0,"if ""preview"" in api_version_str :","if api_version_str . endswith ( ""-preview"" ) :",0.028001459970687266,30.79300751569293,0.5
"def _merge(self, items, map_id, dep_id, use_disk, meminfo, mem_limit):<tab>combined = self.combined<tab>merge_combiner = self.aggregator.mergeCombiners<tab>for k, v in items:<tab><tab>o = combined.get(k)<tab><tab>combined[k] = merge_combiner(o, v) if o is not None else v<tab><tab><IF-STMT><tab><tab><tab>mem_limit = self._rotate()",0,if use_disk and meminfo . rss > mem_limit :,if mem_limit < mem_limit :,0.029942750698461862,21.1792418047206,0.3538461538461538
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_value(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 8 :,if tt == 8 :,0.75,100.00000000000004,1.0
"def nice(deltat):<tab># singular,plural<tab>times = _(<tab><tab>""second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years""<tab>).split("":"")<tab>d = abs(int(deltat))<tab>for div, time in zip((60, 60, 24, 7, 4, 12, 100), times):<tab><tab><IF-STMT><tab><tab><tab>return ""%s%i %s"" % (deltat < 0 and ""-"" or """", d, time.split("","")[d != 1])<tab><tab>d /= div",0,if d < div * 5 :,if div == 0 :,0.08634665141965364,9.042266054940777,0.30952380952380953
"def after_get_object(self, event, view_kwargs):<tab>if event and event.state == ""draft"":<tab><tab><IF-STMT><tab><tab><tab>raise ObjectNotFound({""parameter"": ""{id}""}, ""Event: not found"")",0,"if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :",if not event . is_valid ( ) :,0.04490169668624744,2.473625981181925,0.4259259259259259
def daemonize_if_required(self):<tab>if self.options.daemon:<tab><tab><IF-STMT><tab><tab><tab># Stop the logging queue listener for the current process<tab><tab><tab># We'll restart it once forked<tab><tab><tab>log.shutdown_multiprocessing_logging_listener(daemonizing=True)<tab><tab># Late import so logging works correctly<tab><tab>salt.utils.process.daemonize()<tab># Setup the multiprocessing log queue listener if enabled<tab>self._setup_mp_logging_listener(),0,if self . _setup_mp_logging_listener_ is True :,if self . options . use_multiprocessing :,0.14056531419355517,10.353028267053118,0.4761904761904762
"def iter_modules(self, by_clients=False, clients_filter=None):<tab>""""""iterate over all modules""""""<tab>clients = None<tab>if by_clients:<tab><tab>clients = self.get_clients(clients_filter)<tab><tab>if not clients:<tab><tab><tab>return<tab>self._refresh_modules()<tab>for module_name in self.modules:<tab><tab>try:<tab><tab><tab>module = self.get_module(module_name)<tab><tab>except PupyModuleDisabled:<tab><tab><tab>continue<tab><tab>if clients is not None:<tab><tab><tab>for client in clients:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield module<tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield module",0,if module . is_compatible_with ( client ) :,if self . _is_client_active ( client ) :,0.44385439813208943,25.450938600202846,0.6
"def _incremental_avg_dp(self, avg, new_el, idx):<tab>for attr in [""coarse_segm"", ""fine_segm"", ""u"", ""v""]:<tab><tab>setattr(<tab><tab><tab>avg, attr, (getattr(avg, attr) * idx + getattr(new_el, attr)) / (idx + 1)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab># Deletion of the > 0 index intermediary values to prevent GPU OOM<tab><tab><tab>setattr(new_el, attr, None)<tab>return avg",0,if idx :,if idx == 0 :,0.09791453445388575,1e-10,0.7
"def run(self, paths=[]):<tab>collapsed = False<tab>for item in SideBarSelection(paths).getSelectedDirectories():<tab><tab>for view in item.views():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>Window().focus_view(view)<tab><tab><tab><tab>self.collapse_sidebar_folder()<tab><tab><tab><tab>collapsed = True<tab><tab><tab>view.close()",0,if not collapsed :,if collapsed :,0.09648852821835877,1e-10,0.41666666666666663
"def test_reductions(expr, rdd):<tab>result = compute(expr, rdd)<tab>expected = compute(expr, data)<tab>if not result == expected:<tab><tab>print(result)<tab><tab>print(expected)<tab><tab><IF-STMT><tab><tab><tab>assert abs(result - expected) < 0.001<tab><tab>else:<tab><tab><tab>assert result == expected",0,"if isinstance ( result , float ) :",if math . abs ( result - expected ) < 0.001 :,0.029308662998355026,8.516593018819643,0.24166666666666667
"def deltask(task, d):<tab>if task[:3] != ""do_"":<tab><tab>task = ""do_"" + task<tab>bbtasks = d.getVar(""__BBTASKS"", False) or []<tab>if task in bbtasks:<tab><tab>bbtasks.remove(task)<tab><tab>d.delVarFlag(task, ""task"")<tab><tab>d.setVar(""__BBTASKS"", bbtasks)<tab>d.delVarFlag(task, ""deps"")<tab>for bbtask in d.getVar(""__BBTASKS"", False) or []:<tab><tab>deps = d.getVarFlag(bbtask, ""deps"", False) or []<tab><tab><IF-STMT><tab><tab><tab>deps.remove(task)<tab><tab><tab>d.setVarFlag(bbtask, ""deps"", deps)",1,if task in deps :,if task in deps :,0.75,100.00000000000004,1.0
"def _apply_weightnorm(self, list_layers):<tab>""""""Try apply weightnorm for all layer in list_layers.""""""<tab>for i in range(len(list_layers)):<tab><tab>try:<tab><tab><tab>layer_name = list_layers[i].name.lower()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>list_layers[i] = WeightNormalization(list_layers[i])<tab><tab>except Exception:<tab><tab><tab>pass",0,"if ""conv1d"" in layer_name or ""dense"" in layer_name :","if layer_name == ""weightnorm"" :",0.0168380461076173,9.586514611843183,0.4423076923076923
"def __init__(self, execution_context, aggregate_operators):<tab>super(_QueryExecutionAggregateEndpointComponent, self).__init__(execution_context)<tab>self._local_aggregators = []<tab>self._results = None<tab>self._result_index = 0<tab>for operator in aggregate_operators:<tab><tab>if operator == ""Average"":<tab><tab><tab>self._local_aggregators.append(_AverageAggregator())<tab><tab>elif operator == ""Count"":<tab><tab><tab>self._local_aggregators.append(_CountAggregator())<tab><tab><IF-STMT><tab><tab><tab>self._local_aggregators.append(_MaxAggregator())<tab><tab>elif operator == ""Min"":<tab><tab><tab>self._local_aggregators.append(_MinAggregator())<tab><tab>elif operator == ""Sum"":<tab><tab><tab>self._local_aggregators.append(_SumAggregator())",1,"elif operator == ""Max"" :","elif operator == ""Max"" :",1.0,100.00000000000004,1.0
"def _conv_layer(self, sess, bottom, name, trainable=True, padding=""SAME"", relu=True):<tab>with tf.variable_scope(name) as scope:<tab><tab>filt = self._get_conv_filter(sess, name, trainable=trainable)<tab><tab>conv_biases = self._get_bias(sess, name, trainable=trainable)<tab><tab>conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding=padding)<tab><tab>bias = tf.nn.bias_add(conv, conv_biases)<tab><tab><IF-STMT><tab><tab><tab>bias = tf.nn.relu(bias)<tab><tab>return bias",1,if relu :,if relu :,0.5311706625951745,1e-10,1.0
"def get_partners(self) -> Dict[AbstractNode, Set[int]]:<tab>partners = {}  # type: Dict[AbstractNode, Set[int]]<tab>for edge in self.edges:<tab><tab>if edge.is_dangling():<tab><tab><tab>raise ValueError(""Cannot contract copy tensor with dangling edges"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>partner_node, shared_axis = self._get_partner(edge)<tab><tab>if partner_node not in partners:<tab><tab><tab>partners[partner_node] = set()<tab><tab>partners[partner_node].add(shared_axis)<tab>return partners",0,if self . _is_my_trace ( edge ) :,if edge . shared_axis :,0.020977836961063236,4.167496780656209,0.4772727272727273
"def close(self):<tab>with self._lock:<tab><tab>""""""Close this _MultiFileWatcher object forever.""""""<tab><tab><IF-STMT><tab><tab><tab>self._folder_handlers = {}<tab><tab><tab>LOGGER.debug(<tab><tab><tab><tab>""Stopping observer thread even though there is a non-zero ""<tab><tab><tab><tab>""number of event observers!""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>LOGGER.debug(""Stopping observer thread"")<tab><tab>self._observer.stop()<tab><tab>self._observer.join(timeout=5)",0,if len ( self . _folder_handlers ) != 0 :,if self . _folder_handlers is None :,0.06184630531015613,37.23787437496501,0.2857142857142857
"def comboSelectionChanged(self, index):<tab>text = self.comboBox.cb.itemText(index)<tab>for i in range(self.labelList.count()):<tab><tab><IF-STMT><tab><tab><tab>self.labelList.item(i).setCheckState(2)<tab><tab>elif text != self.labelList.item(i).text():<tab><tab><tab>self.labelList.item(i).setCheckState(0)<tab><tab>else:<tab><tab><tab>self.labelList.item(i).setCheckState(2)",0,"if text == """" :",if text == self . labelList . item ( i ) . text ( ) :,0.08969731708716887,15.13851459876605,0.34989648033126297
"def _get_messages(self):<tab>r = []<tab>try:<tab><tab>self._connect()<tab><tab>self._login()<tab><tab>for message in self._fetch():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r.append(message)<tab><tab>self._connection.expunge()<tab><tab>self._connection.close()<tab><tab>self._connection.logout()<tab>except MailFetcherError as e:<tab><tab>self.log(""error"", str(e))<tab>return r",0,if message :,if message is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def get_current_user(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return config.get(""json_authentication_override"")<tab><tab>tkn_header = self.request.headers[""authorization""]<tab>except KeyError:<tab><tab>raise WebAuthNError(reason=""Missing Authorization Header"")<tab>else:<tab><tab>tkn_str = tkn_header.split("" "")[-1]<tab>try:<tab><tab>tkn = self.jwt_validator(tkn_str)<tab>except AuthenticationError as e:<tab><tab>raise WebAuthNError(reason=e.message)<tab>else:<tab><tab>return tkn",0,"if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :","if config . get ( ""json_authentication_override"" ) :",0.3283203066612076,52.578802442578,0.638095238095238
def _get_data(self):<tab>formdata = self._formdata<tab>if formdata:<tab><tab>data = []<tab><tab># TODO: Optimize?<tab><tab>for item in formdata:<tab><tab><tab>model = self.loader.get_one(item) if item else None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data.append(model)<tab><tab><tab>else:<tab><tab><tab><tab>self._invalid_formdata = True<tab><tab>self._set_data(data)<tab>return self._data,1,if model :,if model :,0.5311706625951745,1e-10,1.0
"def _getSubstrings(self, va, size, ltyp):<tab># rip through the desired memory range to populate any substrings<tab>subs = set()<tab>end = va + size<tab>for offs in range(va, end, 1):<tab><tab>loc = self.getLocation(offs, range=True)<tab><tab>if loc and loc[L_LTYPE] == LOC_STRING and loc[L_VA] > va:<tab><tab><tab>subs.add((loc[L_VA], loc[L_SIZE]))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>subs = subs.union(set(loc[L_TINFO]))<tab>return list(subs)",0,if loc [ L_TINFO ] :,if ltyp == LOC_STRING and loc [ L_TINFO ] :,0.3849344197502259,41.374412020518825,0.37142857142857144
def monad(self):<tab>if not self.cls_bl_idname:<tab><tab>return None<tab>for monad in bpy.data.node_groups:<tab><tab><IF-STMT><tab><tab><tab>if monad.cls_bl_idname == self.cls_bl_idname:<tab><tab><tab><tab>return monad<tab>return None,0,"if hasattr ( monad , ""cls_bl_idname"" ) :",if monad . cls_bl_idname is not None :,0.019345087832959386,30.181358455294284,0.25
"def _set_peer_statuses(self):<tab>""""""Set peer statuses.""""""<tab>cutoff = time.time() - STALE_SECS<tab>for peer in self.peers:<tab><tab>if peer.bad:<tab><tab><tab>peer.status = PEER_BAD<tab><tab><IF-STMT><tab><tab><tab>peer.status = PEER_GOOD<tab><tab>elif peer.last_good:<tab><tab><tab>peer.status = PEER_STALE<tab><tab>else:<tab><tab><tab>peer.status = PEER_NEVER",0,elif peer . last_good > cutoff :,elif cutoff < time . time ( ) :,0.10349009800411521,6.742555929751843,0.38181818181818183
"def title_by_index(self, trans, index, context):<tab>d_type = self.get_datatype(trans, context)<tab>for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()):<tab><tab>if i == index:<tab><tab><tab>rval = composite_name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rval = ""{} ({})"".format(rval, composite_file.description)<tab><tab><tab>if composite_file.optional:<tab><tab><tab><tab>rval = ""%s [optional]"" % rval<tab><tab><tab>return rval<tab>if index < self.get_file_count(trans, context):<tab><tab>return ""Extra primary file""<tab>return None",1,if composite_file . description :,if composite_file . description :,0.75,100.00000000000004,1.0
"def testUiViewServerDump_windowIntM1(self):<tab>device = None<tab>try:<tab><tab>device = MockDevice(version=15, startviewserver=True)<tab><tab>vc = ViewClient(device, device.serialno, adb=TRUE, autodump=False)<tab><tab>vc.dump(window=-1)<tab><tab>vc.findViewByIdOrRaise(""id/home"")<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>device.shutdownMockViewServer()",1,if device :,if device :,0.5311706625951745,1e-10,1.0
"def _convertDict(self, d):<tab>r = {}<tab>for k, v in d.items():<tab><tab>if isinstance(v, bytes):<tab><tab><tab>v = str(v, ""utf-8"")<tab><tab>elif isinstance(v, list) or isinstance(v, tuple):<tab><tab><tab>v = self._convertList(v)<tab><tab><IF-STMT><tab><tab><tab>v = self._convertDict(v)<tab><tab>if isinstance(k, bytes):<tab><tab><tab>k = str(k, ""utf-8"")<tab><tab>r[k] = v<tab>return r",0,"elif isinstance ( v , dict ) :","elif isinstance ( v , dict ) or isinstance ( v , dict ) :",0.5189683274103131,47.587330964125236,0.6296296296296297
"def _testSendmsgTimeout(self):<tab>try:<tab><tab>self.cli_sock.settimeout(0.03)<tab><tab>try:<tab><tab><tab>while True:<tab><tab><tab><tab>self.sendmsgToServer([b""a"" * 512])<tab><tab>except socket.timeout:<tab><tab><tab>pass<tab><tab>except OSError as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab># bpo-33937 the test randomly fails on Travis CI with<tab><tab><tab># ""OSError: [Errno 12] Cannot allocate memory""<tab><tab>else:<tab><tab><tab>self.fail(""socket.timeout not raised"")<tab>finally:<tab><tab>self.misc_event.set()",0,if exc . errno != errno . ENOMEM :,if exc . errno != errno . EAGAIN :,0.87709085524794,78.25422900366438,0.6666666666666666
"def addError(self, test, err):<tab>if err[0] is SkipTest:<tab><tab>if self.showAll:<tab><tab><tab>self.stream.writeln(str(err[1]))<tab><tab><IF-STMT><tab><tab><tab>self.stream.write(""s"")<tab><tab><tab>self.stream.flush()<tab><tab>return<tab>_org_AddError(self, test, err)",0,elif self . dots :,if self . stream . tell ( ) > 0 :,0.042464909140380154,8.29519350710986,0.23214285714285715
"def mouse_down(self, event):<tab>if event.button == 1:<tab><tab>if self.scrolling:<tab><tab><tab>p = event.local<tab><tab><tab>if self.scroll_up_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_up()<tab><tab><tab><tab>return<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.scroll_down()<tab><tab><tab><tab>return<tab>if event.button == 4:<tab><tab>self.scroll_up()<tab>if event.button == 5:<tab><tab>self.scroll_down()<tab>GridView.mouse_down(self, event)",0,elif self . scroll_down_rect ( ) . collidepoint ( p ) :,if self . scroll_down_rect ( ) . collidepoint ( p ) :,0.48305100180492244,93.06048591020995,0.6666666666666666
"def find_file_copyright_notices(fname):<tab>ret = set()<tab>f = open(fname)<tab>lines = f.readlines()<tab>for l in lines[:80]:  # hmmm, assume copyright to be in first 80 lines<tab><tab>idx = l.lower().find(""copyright"")<tab><tab>if idx < 0:<tab><tab><tab>continue<tab><tab>copyright = l[idx + 9 :].strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>copyright = sanitise(copyright)<tab><tab># hmm, do a quick check to see if there's a year,<tab><tab># if not, skip it<tab><tab>if not copyright.find(""200"") >= 0 and not copyright.find(""199"") >= 0:<tab><tab><tab>continue<tab><tab>ret.add(copyright)<tab>return ret",1,if not copyright :,if not copyright :,0.75,100.00000000000004,1.0
"def get_selectable_values(self, request):<tab>shop = lfs.core.utils.get_default_shop(request)<tab>countries = []<tab>for country in shop.shipping_countries.all():<tab><tab><IF-STMT><tab><tab><tab>selected = True<tab><tab>else:<tab><tab><tab>selected = False<tab><tab>countries.append(<tab><tab><tab>{<tab><tab><tab><tab>""id"": country.id,<tab><tab><tab><tab>""name"": country.name,<tab><tab><tab><tab>""selected"": selected,<tab><tab><tab>}<tab><tab>)<tab>return countries",0,if country in self . value . all ( ) :,if country . selected :,0.023216713144679484,7.652332131360532,0.34615384615384615
"def _addItemToLayout(self, sample, label):<tab>col = self.layout.columnCount()<tab>row = self.layout.rowCount()<tab>if row:<tab><tab>row -= 1<tab>nCol = self.columnCount * 2<tab># FIRST ROW FULL<tab>if col == nCol:<tab><tab>for col in range(0, nCol, 2):<tab><tab><tab># FIND RIGHT COLUMN<tab><tab><tab>if not self.layout.itemAt(row, col):<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># MAKE NEW ROW<tab><tab><tab>col = 0<tab><tab><tab>row += 1<tab>self.layout.addItem(sample, row, col)<tab>self.layout.addItem(label, row, col + 1)",0,if col + 2 == nCol :,elif col == nCol :,0.08711053828152879,38.49815007763549,0.30952380952380953
def contains_only_whitespace(node):<tab>if is_tag(node):<tab><tab>if not any([not is_text(s) for s in node.contents]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False,0,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,if is_text ( node . contents ) or is_whitespace ( node . contents ) :,0.3042430562990027,9.622795342210285,0.15123456790123457
"def tokenize_generator(cw):<tab>ret = []<tab>done = {}<tab>for op in ops:<tab><tab>ch = op.symbol[0]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>sops = start_symbols[ch]<tab><tab>cw.write(""case '%s':"" % ch)<tab><tab>for t in gen_tests(sops, 1):<tab><tab><tab>cw.write(t)<tab><tab>done[ch] = True<tab>return ret",1,if ch in done :,if ch in done :,0.75,100.00000000000004,1.0
"def _convertNbCharsInNbBits(self, nbChars):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbChars is not None:<tab><tab><IF-STMT><tab><tab><tab>nbMinBit = nbChars * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab>if nbChars[0] is not None:<tab><tab><tab><tab>nbMinBit = nbChars[0] * 8<tab><tab><tab>if nbChars[1] is not None:<tab><tab><tab><tab>nbMaxBit = nbChars[1] * 8<tab>return (nbMinBit, nbMaxBit)",0,"if isinstance ( nbChars , int ) :",if nbChars < nbMinBit :,0.01919965680754916,7.715486568024961,0.3148148148148148
"def init(self, *args, **kwargs):<tab>if ""_state"" not in kwargs:<tab><tab>state = {}<tab><tab># Older versions have the _state entries as individual kwargs<tab><tab>for arg in (""children"", ""windowState"", ""detachedPanels""):<tab><tab><tab>if arg in kwargs:<tab><tab><tab><tab>state[arg] = kwargs[arg]<tab><tab><tab><tab>del kwargs[arg]<tab><tab><IF-STMT><tab><tab><tab>kwargs[""_state""] = state<tab>originalInit(self, *args, **kwargs)",1,if state :,if state :,0.5311706625951745,1e-10,1.0
"def spm_decode(tokens: List[str]) -> List[str]:<tab>words = []<tab>pieces: List[str] = []<tab>for t in tokens:<tab><tab><IF-STMT><tab><tab><tab>if len(pieces) > 0:<tab><tab><tab><tab>words.append("""".join(pieces))<tab><tab><tab>pieces = [t[1:]]<tab><tab>else:<tab><tab><tab>pieces.append(t)<tab>if len(pieces) > 0:<tab><tab>words.append("""".join(pieces))<tab>return words",0,if t [ 0 ] == DecodeMixin . spm_bos_token :,"if t . startswith ( "" "" ) :",0.027998166782031833,5.821935635427797,0.4871794871794872
"def _compare_dirs(self, dir1: str, dir2: str) -> List[str]:<tab># check that dir1 and dir2 are equivalent,<tab># return the diff<tab>diff = []  # type: List[str]<tab>for root, dirs, files in os.walk(dir1):<tab><tab>for file_ in files:<tab><tab><tab>path = os.path.join(root, file_)<tab><tab><tab>target_path = os.path.join(dir2, os.path.split(path)[-1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diff.append(file_)<tab>return diff",0,if not os . path . exists ( target_path ) :,"if os . path . samefile ( target_path , dir1 ) :",0.15656340381243428,40.01601601922502,0.25
"def credentials(self):<tab>""""""The session credentials as a dict""""""<tab>creds = {}<tab>if self._creds:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>creds[""aws_access_key_id""] = self._creds.access_key<tab><tab>if self._creds.secret_key:  # pragma: no branch<tab><tab><tab>creds[""aws_secret_access_key""] = self._creds.secret_key<tab><tab>if self._creds.token:<tab><tab><tab>creds[""aws_session_token""] = self._creds.token<tab>if self._session.region_name:<tab><tab>creds[""aws_region""] = self._session.region_name<tab>if self.requester_pays:<tab><tab>creds[""aws_request_payer""] = ""requester""<tab>return creds",1,if self . _creds . access_key :,if self . _creds . access_key :,0.75,100.00000000000004,1.0
"def got_arbiter_module_type_defined(self, mod_type):<tab>for a in self.arbiters:<tab><tab># Do like the linkify will do after....<tab><tab>for m in getattr(a, ""modules"", []):<tab><tab><tab># So look at what the arbiter try to call as module<tab><tab><tab>m = m.strip()<tab><tab><tab># Ok, now look in modules...<tab><tab><tab>for mod in self.modules:<tab><tab><tab><tab># try to see if this module is the good type<tab><tab><tab><tab>if getattr(mod, ""module_type"", """").strip() == mod_type.strip():<tab><tab><tab><tab><tab># if so, the good name?<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False",0,"if getattr ( mod , ""module_name"" , """" ) . strip ( ) == m :",if m == mod_type :,0.006995992719645875,2.6251815872142057,0.3133333333333333
"def find_file_at_path_with_indexes(self, path, url):<tab>if url.endswith(""/""):<tab><tab>path = os.path.join(path, self.index_file)<tab><tab>return self.get_static_file(path, url)<tab>elif url.endswith(""/"" + self.index_file):<tab><tab>if os.path.isfile(path):<tab><tab><tab>return self.redirect(url, url[: -len(self.index_file)])<tab>else:<tab><tab>try:<tab><tab><tab>return self.get_static_file(path, url)<tab><tab>except IsDirectoryError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.redirect(url, url + ""/"")<tab>raise MissingFileError(path)",0,"if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",if os . path . isdir ( path ) :,0.2824173847428194,13.722896630276955,0.36547619047619045
def _use_full_params(self) -> None:<tab>for p in self.params:<tab><tab>if not p._is_sharded:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert p._fp16_shard.storage().size() != 0<tab><tab><tab><tab>p.data = p._fp16_shard<tab><tab>else:<tab><tab><tab>assert p._full_param_padded.storage().size() != 0<tab><tab><tab>p.data = p._full_param_padded[: p._orig_size.numel()].view(p._orig_size),0,if self . mixed_precision :,if p . _fp16_shard is not None :,0.1113347933040206,5.300156689756295,0.23809523809523808
"def _attrdata(self, cont, name, *val):<tab>if not name:<tab><tab>return None, False<tab>if isinstance(name, Mapping):<tab><tab>if val:<tab><tab><tab>raise TypeError(""Cannot set a value to %s"" % name)<tab><tab>return name, True<tab>else:<tab><tab>if val:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return {name: val[0]}, True<tab><tab><tab>else:<tab><tab><tab><tab>raise TypeError(""Too may arguments"")<tab><tab>else:<tab><tab><tab>cont = self._extra.get(cont)<tab><tab><tab>return cont.get(name) if cont else None, False",1,if len ( val ) == 1 :,if len ( val ) == 1 :,0.75,100.00000000000004,1.0
"def evaluate(env, net, device=""cpu""):<tab>obs = env.reset()<tab>reward = 0.0<tab>steps = 0<tab>while True:<tab><tab>obs_v = ptan.agent.default_states_preprocessor([obs]).to(device)<tab><tab>action_v = net(obs_v)<tab><tab>action = action_v.data.cpu().numpy()[0]<tab><tab>obs, r, done, _ = env.step(action)<tab><tab>reward += r<tab><tab>steps += 1<tab><tab><IF-STMT><tab><tab><tab>break<tab>return reward, steps",1,if done :,if done :,0.5311706625951745,1e-10,1.0
"def convert_html_js_files(app: Sphinx, config: Config) -> None:<tab>""""""This converts string styled html_js_files to tuple styled one.""""""<tab>html_js_files = []  # type: List[Tuple[str, Dict]]<tab>for entry in config.html_js_files:<tab><tab><IF-STMT><tab><tab><tab>html_js_files.append((entry, {}))<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>filename, attrs = entry<tab><tab><tab><tab>html_js_files.append((filename, attrs))<tab><tab><tab>except Exception:<tab><tab><tab><tab>logger.warning(__(""invalid js_file: %r, ignored""), entry)<tab><tab><tab><tab>continue<tab>config.html_js_files = html_js_files  # type: ignore",1,"if isinstance ( entry , str ) :","if isinstance ( entry , str ) :",0.75,100.00000000000004,1.0
"def _check_duplications(self, regs):<tab>""""""n^2 loop which verifies that each reg exists only once.""""""<tab>for reg in regs:<tab><tab>count = 0<tab><tab>for r in regs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count += 1<tab><tab>if count > 1:<tab><tab><tab>genutil.die(""reg %s defined more than once"" % reg)",1,if reg == r :,if reg == r :,0.75,100.00000000000004,1.0
"def PyJsHoisted_vault_(key, forget, this, arguments, var=var):<tab>var = Scope(<tab><tab>{u""this"": this, u""forget"": forget, u""key"": key, u""arguments"": arguments}, var<tab>)<tab>var.registers([u""forget"", u""key""])<tab>if PyJsStrictEq(var.get(u""key""), var.get(u""passkey"")):<tab><tab>return (<tab><tab><tab>var.put(u""secret"", var.get(u""null""))<tab><tab><tab><IF-STMT><tab><tab><tab>else (<tab><tab><tab><tab>var.get(u""secret"")<tab><tab><tab><tab>or var.put(u""secret"", var.get(u""secretCreatorFn"")(var.get(u""object"")))<tab><tab><tab>)<tab><tab>)",0,"if var . get ( u""forget"" )","if PyJsStrictEq ( var . get ( u""secret"" ) , var . get ( u""passkey"" ) )",0.305045411079198,23.4986979900135,0.376
"def sort_nested_dictionary_lists(d):<tab>for k, v in d.items():<tab><tab>if isinstance(v, list):<tab><tab><tab>for i in range(0, len(v)):<tab><tab><tab><tab>if isinstance(v[i], dict):<tab><tab><tab><tab><tab>v[i] = await sort_nested_dictionary_lists(v[i])<tab><tab><tab><tab>d[k] = sorted(v)<tab><tab><IF-STMT><tab><tab><tab>d[k] = await sort_nested_dictionary_lists(v)<tab>return d",0,"if isinstance ( v , dict ) :","elif isinstance ( v , dict ) :",0.40018302522632676,84.08964152537145,0.6666666666666666
"def transceiver(self, data):<tab>out = []<tab>for t in range(8):<tab><tab>if data[t] == 0:<tab><tab><tab>continue<tab><tab>value = data[t]<tab><tab>for b in range(8):<tab><tab><tab>if value & 0x80:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>out.append(""(unknown)"")<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>out.append(TRANSCEIVER[t][b])<tab><tab><tab>value <<= 1<tab>self.annotate(""Transceiver compliance"", "", "".join(out))",0,if len ( TRANSCEIVER [ t ] ) < b + 1 :,if b not in TRANSCEIVER [ t ] :,0.14896245715820322,22.01137162342707,0.2222222222222222
"def process_string(self, remove_repetitions, sequence):<tab>string = """"<tab>for i, char in enumerate(sequence):<tab><tab>if char != self.int_to_char[self.blank_index]:<tab><tab><tab># if this char is a repetition and remove_repetitions=true,<tab><tab><tab># skip.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>elif char == self.labels[self.space_index]:<tab><tab><tab><tab>string += "" ""<tab><tab><tab>else:<tab><tab><tab><tab>string = string + char<tab>return string",0,if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,if i == 0 and remove_repetitions :,0.12923874985387898,11.610218285945827,0.21710526315789475
"def clean(self):<tab>username = self.cleaned_data.get(""username"")<tab>password = self.cleaned_data.get(""password"")<tab>if username and password:<tab><tab>self.user_cache = authenticate(username=username, password=password)<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(self.error_messages[""invalid_login""])<tab><tab>elif not self.user_cache.is_active:<tab><tab><tab>raise forms.ValidationError(self.error_messages[""inactive""])<tab>self.check_for_test_cookie()<tab>return self.cleaned_data",1,if self . user_cache is None :,if self . user_cache is None :,0.75,100.00000000000004,1.0
"def is_listening_for_message(conversation_id: Text, endpoint: EndpointConfig) -> bool:<tab>""""""Check if the conversation is in need for a user message.""""""<tab>tracker = await retrieve_tracker(endpoint, conversation_id, EventVerbosity.APPLIED)<tab>for i, e in enumerate(reversed(tracker.get(""events"", []))):<tab><tab>if e.get(""event"") == UserUttered.type_name:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return e.get(""name"") == ACTION_LISTEN_NAME<tab>return False",1,"elif e . get ( ""event"" ) == ActionExecuted . type_name :","elif e . get ( ""event"" ) == ActionExecuted . type_name :",0.75,100.00000000000004,1.0
"def getReferences(view, name=""""):<tab>""""""Find all reference definitions.""""""<tab># returns {name -> Region}<tab>refs = []<tab>name = re.escape(name)<tab>if name == """":<tab><tab>refs.extend(view.find_all(r""(?<=^\[)([^\]]+)(?=\]:)"", 0))<tab>else:<tab><tab>refs.extend(view.find_all(r""(?<=^\[)(%s)(?=\]:)"" % name, 0))<tab>regions = refs<tab>ids = {}<tab>for reg in regions:<tab><tab>name = view.substr(reg).strip()<tab><tab>key = name.lower()<tab><tab><IF-STMT><tab><tab><tab>ids[key].regions.append(reg)<tab><tab>else:<tab><tab><tab>ids[key] = Obj(regions=[reg], label=name)<tab>return ids",1,if key in ids :,if key in ids :,0.75,100.00000000000004,1.0
"def _get_header(self, requester, header_name):<tab>hits = sum([header_name in headers for _, headers in requester.requests])<tab>self.assertEquals(hits, 2 if self.revs_enabled else 1)<tab>for url, headers in requester.requests:<tab><tab><IF-STMT><tab><tab><tab>if self.revs_enabled:<tab><tab><tab><tab>self.assertTrue(url.endswith(""/latest""), msg=url)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertTrue(url.endswith(""/download_urls""), msg=url)<tab><tab><tab>return headers.get(header_name)",0,if header_name in headers :,if url . startswith ( header_name ) :,0.028001459970687266,17.747405280050266,0.3333333333333333
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_shuffle_name(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def make_release_tree(self, base_dir, files):<tab>""""""Make the release tree.""""""<tab>self.mkpath(base_dir)<tab>create_tree(base_dir, files, dry_run=self.dry_run)<tab>if not files:<tab><tab>self.log.warning(""no files to distribute -- empty manifest?"")<tab>else:<tab><tab>self.log.info(""copying files to %s..."", base_dir)<tab>for filename in files:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(""'%s' not a regular file -- skipping"", filename)<tab><tab>else:<tab><tab><tab>dest = os.path.join(base_dir, filename)<tab><tab><tab>self.copy_file(filename, dest)<tab>self.distribution.metadata.write_pkg_info(base_dir)",0,if not os . path . isfile ( filename ) :,if os . path . isfile ( filename ) :,0.4074990052689752,81.76129038784515,0.27272727272727276
"def _parse_names_set(feature_names):<tab>""""""Helping function of `_parse_feature_names` that parses a set of feature names.""""""<tab>feature_collection = OrderedDict()<tab>for feature_name in feature_names:<tab><tab><IF-STMT><tab><tab><tab>feature_collection[feature_name] = ...<tab><tab>else:<tab><tab><tab>raise ValueError(""Failed to parse {}, expected string"".format(feature_name))<tab>return feature_collection",1,"if isinstance ( feature_name , str ) :","if isinstance ( feature_name , str ) :",0.75,100.00000000000004,1.0
"def get_connection(self, url, proxies=None):<tab>with self.pools.lock:<tab><tab>pool = self.pools.get(url)<tab><tab><IF-STMT><tab><tab><tab>return pool<tab><tab>pool = NpipeHTTPConnectionPool(<tab><tab><tab>self.npipe_path, self.timeout, maxsize=self.max_pool_size<tab><tab>)<tab><tab>self.pools[url] = pool<tab>return pool",1,if pool :,if pool :,0.5311706625951745,1e-10,1.0
"def _parse_dimensions(dimensions):<tab>arrays = []<tab>names = []<tab>for key in dimensions:<tab><tab>values = [v[""name""] for v in key[""values""]]<tab><tab>role = key.get(""role"", None)<tab><tab><IF-STMT><tab><tab><tab>values = [_fix_quarter_values(v) for v in values]<tab><tab><tab>values = pd.DatetimeIndex(values)<tab><tab>arrays.append(values)<tab><tab>names.append(key[""name""])<tab>midx = pd.MultiIndex.from_product(arrays, names=names)<tab>if len(arrays) == 1 and isinstance(midx, pd.MultiIndex):<tab><tab># Fix for pandas >= 0.21<tab><tab>midx = midx.levels[0]<tab>return midx",0,"if role in ( ""time"" , ""TIME_PERIOD"" ) :","if role == ""quarter"" :",0.029942750698461862,5.789419402078114,0.7307692307692308
"def _add_trials(self, name, spec):<tab>""""""Add trial by invoking TrialRunner.""""""<tab>resource = {}<tab>resource[""trials""] = []<tab>trial_generator = BasicVariantGenerator()<tab>trial_generator.add_configurations({name: spec})<tab>while not trial_generator.is_finished():<tab><tab>trial = trial_generator.next_trial()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>runner.add_trial(trial)<tab><tab>resource[""trials""].append(self._trial_info(trial))<tab>return resource",0,if not trial :,if trial is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def _retrieve_key(self):<tab>url = ""http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf""<tab>text = """"<tab>try:<tab><tab>r = requests.get(url, timeout=self.timeout, proxies=self.proxies)<tab><tab>text = r.text<tab>except:<tab><tab>self.error = ""ERROR - URL Connection""<tab>if text:<tab><tab>expression = r""'(....-....-....-....)';""<tab><tab>pattern = re.compile(expression)<tab><tab>match = pattern.search(text)<tab><tab><IF-STMT><tab><tab><tab>self.key = match.group(1)<tab><tab><tab>return self.key<tab><tab>else:<tab><tab><tab>self.error = ""ERROR - No API Key""",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def test_net(net, env, count=10, device=""cpu""):<tab>rewards = 0.0<tab>steps = 0<tab>for _ in range(count):<tab><tab>obs = env.reset()<tab><tab>while True:<tab><tab><tab>obs_v = ptan.agent.float32_preprocessor([obs]).to(device)<tab><tab><tab>mu_v = net(obs_v)[0]<tab><tab><tab>action = mu_v.squeeze(dim=0).data.cpu().numpy()<tab><tab><tab>action = np.clip(action, -1, 1)<tab><tab><tab>obs, reward, done, _ = env.step(action)<tab><tab><tab>rewards += reward<tab><tab><tab>steps += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return rewards / count, steps / count",1,if done :,if done :,0.5311706625951745,1e-10,1.0
"def compile(self, filename, obfuscate=False, raw=False, magic=""\x00"" * 8):<tab>body = marshal.dumps(compile(self.visit(self._source_ast), filename, ""exec""))<tab>if obfuscate:<tab><tab>body_len = len(body)<tab><tab>offset = 0 if raw else 8<tab><tab>output = bytearray(body_len + 8)<tab><tab>for i, x in enumerate(body):<tab><tab><tab>output[i + offset] = ord(x) ^ ((2 ** ((65535 - i) % 65535)) % 251)<tab><tab><IF-STMT><tab><tab><tab>for i in xrange(8):<tab><tab><tab><tab>output[i] = 0<tab><tab>return output<tab>elif raw:<tab><tab>return body<tab>else:<tab><tab>return magic + body",0,if raw :,if len ( output ) == body_len :,0.04422835593777517,1e-10,0.38181818181818183
"def _map_saslprep(s):<tab>""""""Map stringprep table B.1 to nothing and C.1.2 to ASCII space""""""<tab>r = []<tab>for c in s:<tab><tab>if stringprep.in_table_c12(c):<tab><tab><tab>r.append("" "")<tab><tab><IF-STMT><tab><tab><tab>r.append(c)<tab>return """".join(r)",0,elif not stringprep . in_table_b1 ( c ) :,elif stringprep . in_table_b10 ( c ) :,0.22816002488985698,59.74178044844197,0.38181818181818183
"def ensemble(self, pairs, other_preds):<tab>""""""Ensemble the dict with statistical model predictions.""""""<tab>lemmas = []<tab>assert len(pairs) == len(other_preds)<tab>for p, pred in zip(pairs, other_preds):<tab><tab>w, pos = p<tab><tab>if (w, pos) in self.composite_dict:<tab><tab><tab>lemma = self.composite_dict[(w, pos)]<tab><tab><IF-STMT><tab><tab><tab>lemma = self.word_dict[w]<tab><tab>else:<tab><tab><tab>lemma = pred<tab><tab>if lemma is None:<tab><tab><tab>lemma = w<tab><tab>lemmas.append(lemma)<tab>return lemmas",1,elif w in self . word_dict :,elif w in self . word_dict :,0.75,100.00000000000004,1.0
"def quiet_f(*args):<tab>vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)}<tab>value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation)<tab>if expect_list:<tab><tab><IF-STMT><tab><tab><tab>value = [extract_pyreal(item) for item in value.leaves]<tab><tab><tab>if any(item is None for item in value):<tab><tab><tab><tab>return None<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>value = extract_pyreal(value)<tab><tab>if value is None or isinf(value) or isnan(value):<tab><tab><tab>return None<tab><tab>return value",0,"if value . has_form ( ""List"" , None ) :",if expect_list :,0.010867398423934471,1e-10,0.46875
"def _copy_package_apps(<tab>local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None:<tab>for src_unresolved in app_paths:<tab><tab>src = src_unresolved.resolve()<tab><tab>app = src.name<tab><tab>dest = Path(local_bin_dir / add_suffix(app, suffix))<tab><tab>if not dest.parent.is_dir():<tab><tab><tab>mkdir(dest.parent)<tab><tab><IF-STMT><tab><tab><tab>logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"")<tab><tab><tab>dest.unlink()<tab><tab>if src.exists():<tab><tab><tab>shutil.copy(src, dest)",1,if dest . exists ( ) :,if dest . exists ( ) :,0.75,100.00000000000004,1.0
"def assert_readback(vehicle, values):<tab>i = 10<tab>while i > 0:<tab><tab>time.sleep(0.1)<tab><tab>i -= 0.1<tab><tab>for k, v in values.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>break<tab>if i <= 0:<tab><tab>raise Exception(""Did not match in channels readback %s"" % values)",0,if vehicle . channels [ k ] != v :,if v ==vehicle :,0.01378824683147838,5.274846355723257,0.2948717948717949
"def _get_linode_client(self):<tab>api_key = self.credentials.conf(""key"")<tab>api_version = self.credentials.conf(""version"")<tab>if api_version == """":<tab><tab>api_version = None<tab>if not api_version:<tab><tab>api_version = 3<tab><tab># Match for v4 api key<tab><tab>regex_v4 = re.compile(""^[0-9a-f]{64}$"")<tab><tab>regex_match = regex_v4.match(api_key)<tab><tab><IF-STMT><tab><tab><tab>api_version = 4<tab>else:<tab><tab>api_version = int(api_version)<tab>return _LinodeLexiconClient(api_key, api_version)",0,if regex_match :,if not regex_match :,0.11348623737539229,1e-10,0.6
"def mergeHiLo(self, x_stats):<tab>""""""Merge the highs and lows of another accumulator into myself.""""""<tab>if x_stats.firsttime is not None:<tab><tab><IF-STMT><tab><tab><tab>self.firsttime = x_stats.firsttime<tab><tab><tab>self.first = x_stats.first<tab>if x_stats.lasttime is not None:<tab><tab>if self.lasttime is None or x_stats.lasttime >= self.lasttime:<tab><tab><tab>self.lasttime = x_stats.lasttime<tab><tab><tab>self.last = x_stats.last",0,if self . firsttime is None or x_stats . firsttime < self . firsttime :,if self . firsttime is None or x_stats . firsttime >= self . firsttime :,0.600908136150534,77.7811122305422,1.0
"def _check_good_input(self, X, y=None):<tab>if isinstance(X, dict):<tab><tab>lengths = [len(X1) for X1 in X.values()]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Not all values of X are of equal length."")<tab><tab>x_len = lengths[0]<tab>else:<tab><tab>x_len = len(X)<tab>if y is not None:<tab><tab>if len(y) != x_len:<tab><tab><tab>raise ValueError(""X and y are not of equal length."")<tab>if self.regression and y is not None and y.ndim == 1:<tab><tab>y = y.reshape(-1, 1)<tab>return X, y",0,if len ( set ( lengths ) ) > 1 :,if len ( lengths ) != 1 :,0.15974423575173982,26.264048972269727,0.4871794871794872
"def set(self, obj, **kwargs):<tab>""""""Check for missing event functions and substitute these with""""""<tab>""""""the ignore method""""""<tab>ignore = getattr(self, ""ignore"")<tab>for k, v in kwargs.iteritems():<tab><tab>setattr(self, k, getattr(obj, v))<tab><tab>if k in self.combinations:<tab><tab><tab>for k1 in self.combinations[k]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>setattr(self, k1, ignore)",0,"if not hasattr ( self , k1 ) :",if k1 not in ignore :,0.017951424116240698,6.962210312500384,0.25
"def _parse_list(self, tokens):<tab># Process left to right, allow descending in sub lists<tab>assert tokens[0] in (""["", ""("")<tab>delim = ""]"" if tokens.pop(0) == ""["" else "")""<tab>expr = ExpressionList()<tab>while tokens and tokens[0] != delim:<tab><tab>item = self._parse(tokens)<tab><tab><IF-STMT><tab><tab><tab>if tokens.pop(0) != "","":<tab><tab><tab><tab>raise ExpressionSyntaxError('Expected: "",""')<tab><tab>expr.append(item)<tab>if not tokens or tokens[0] != delim:<tab><tab>raise ExpressionSyntaxError('Missing: ""%s""' % delim)<tab>else:<tab><tab>tokens.pop(0)<tab>return expr",0,if tokens and tokens [ 0 ] != delim :,if item is None :,0.08489660720600936,3.8261660656802645,0.2
"def param_value(self):<tab># This is part of the ""handle quoted extended parameters"" hack.<tab>for token in self:<tab><tab>if token.token_type == ""value"":<tab><tab><tab>return token.stripped_value<tab><tab><IF-STMT><tab><tab><tab>for token in token:<tab><tab><tab><tab>if token.token_type == ""bare-quoted-string"":<tab><tab><tab><tab><tab>for token in token:<tab><tab><tab><tab><tab><tab>if token.token_type == ""value"":<tab><tab><tab><tab><tab><tab><tab>return token.stripped_value<tab>return """"",1,"if token . token_type == ""quoted-string"" :","if token . token_type == ""quoted-string"" :",0.75,100.00000000000004,1.0
"def paragraph_is_fully_commented(lines, comment, main_language):<tab>""""""Is the paragraph fully commented?""""""<tab>for i, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>if line[len(comment) :].lstrip().startswith(comment):<tab><tab><tab><tab>continue<tab><tab><tab>if is_magic(line, main_language):<tab><tab><tab><tab>return False<tab><tab><tab>continue<tab><tab>return i > 0 and _BLANK_LINE.match(line)<tab>return True",1,if line . startswith ( comment ) :,if line . startswith ( comment ) :,0.75,100.00000000000004,1.0
"def lots_connected_to_existing_roads(model):<tab>set = []<tab>for h in model.HarvestCells:<tab><tab>for (i, j) in model.ExistingRoads:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if h not in set:<tab><tab><tab><tab><tab>set.append(h)<tab>return set",0,if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,if i == j :,0.003864480998056692,0.6751392346890166,0.3010752688172043
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""\Abarra_counter_session="",<tab><tab><tab><tab>headers.get(HTTP_HEADER.SET_COOKIE, """"),<tab><tab><tab><tab>re.I,<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab>retval |= (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""(\A|\b)barracuda_"", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.5311706625951745,1e-10,1.0
"def test_files(self):<tab># get names of files to test<tab>dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir)<tab>names = []<tab>for d in self.test_directories:<tab><tab>test_dir = os.path.join(dist_dir, d)<tab><tab>for n in os.listdir(test_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.append(os.path.join(test_dir, n))<tab>for filename in names:<tab><tab>if test_support.verbose:<tab><tab><tab>print(""Testing %s"" % filename)<tab><tab>source = read_pyfile(filename)<tab><tab>self.check_roundtrip(source)",0,"if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :","if n . endswith ( "".py"" ) :",0.35447623795950867,38.966271115357685,0.49783549783549785
"def test_calibrate_target(create_target):<tab>mod, params = testing.synthetic.get_workload()<tab>dataset = get_calibration_dataset(mod, ""data"")<tab>with relay.quantize.qconfig(calibrate_mode=""kl_divergence""):<tab><tab><IF-STMT><tab><tab><tab>with tvm.target.Target(""llvm""):<tab><tab><tab><tab>relay.quantize.quantize(mod, params, dataset)<tab><tab>else:<tab><tab><tab># current_target = None<tab><tab><tab>relay.quantize.quantize(mod, params, dataset)",1,if create_target :,if create_target :,0.5311706625951745,1e-10,1.0
"def _cleanSubmodule(self, _=None):<tab>rc = RC_SUCCESS<tab>if self.submodules:<tab><tab>command = [<tab><tab><tab>""submodule"",<tab><tab><tab>""foreach"",<tab><tab><tab>""--recursive"",<tab><tab><tab>""git"",<tab><tab><tab>""clean"",<tab><tab><tab>""-f"",<tab><tab><tab>""-f"",<tab><tab><tab>""-d"",<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>command.append(""-x"")<tab><tab>rc = yield self._dovccmd(command)<tab>defer.returnValue(rc)",0,"if self . mode == ""full"" and self . method == ""fresh"" :",if self . verbose > 1 :,0.06938820899126875,4.730862766911802,0.3177083333333333
"def screen_length_to_bytes_count(string, screen_length_limit, encoding):<tab>bytes_count = 0<tab>screen_length = 0<tab>for unicode_char in string:<tab><tab>screen_length += screen_len(unicode_char)<tab><tab>char_bytes_count = len(unicode_char.encode(encoding))<tab><tab>bytes_count += char_bytes_count<tab><tab><IF-STMT><tab><tab><tab>bytes_count -= char_bytes_count<tab><tab><tab>break<tab>return bytes_count",0,if screen_length > screen_length_limit :,if bytes_count > screen_length_limit :,0.39477865547525276,60.767958081376904,1.0
"def tamper(payload, **kwargs):<tab>junk_chars = ""!#$%&()*~+-_.,:;?@[/|\]^`""<tab>retval = """"<tab>for i, char in enumerate(payload, start=1):<tab><tab>amount = random.randint(10, 15)<tab><tab>if char == "">"":<tab><tab><tab>retval += "">""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab><IF-STMT><tab><tab><tab>retval += ""<""<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>elif char == "" "":<tab><tab><tab>for _ in range(amount):<tab><tab><tab><tab>retval += random.choice(junk_chars)<tab><tab>else:<tab><tab><tab>retval += char<tab>return retval",1,"elif char == ""<"" :","elif char == ""<"" :",1.0,100.00000000000004,1.0
"def test_parse(self):<tab>correct = 0<tab>for example in EXAMPLES:<tab><tab>try:<tab><tab><tab>schema.parse(example.schema_string)<tab><tab><tab>if example.valid:<tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Invalid schema was parsed: "" + example.schema_string)<tab><tab>except:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>correct += 1<tab><tab><tab>else:<tab><tab><tab><tab>self.fail(""Valid schema failed to parse: "" + example.schema_string)<tab>fail_msg = ""Parse behavior correct on %d out of %d schemas."" % (<tab><tab>correct,<tab><tab>len(EXAMPLES),<tab>)<tab>self.assertEqual(correct, len(EXAMPLES), fail_msg)",0,if not example . valid :,if example . valid :,0.281663156243144,57.89300674674101,0.36
"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab><IF-STMT><tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",0,"if isinstance ( value , bool ) :","if isinstance ( value , str ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def normalize(d: Dict[Any, Any]) -> Dict[str, Any]:<tab>first_exception = None<tab>for normalizer in normalizers:<tab><tab>try:<tab><tab><tab>normalized = normalizer(d)<tab><tab>except KeyError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>first_exception = e<tab><tab>else:<tab><tab><tab>return normalized<tab>assert first_exception is not None<tab>raise first_exception",0,if not first_exception :,if first_exception is None :,0.045150550804307965,27.77619034011791,0.36
"def gather_callback_args(self, obj, callbacks):<tab>session = sa.orm.object_session(obj)<tab>for callback in callbacks:<tab><tab>backref = callback.backref<tab><tab>root_objs = getdotattr(obj, backref) if backref else obj<tab><tab>if root_objs:<tab><tab><tab>if not isinstance(root_objs, Iterable):<tab><tab><tab><tab>root_objs = [root_objs]<tab><tab><tab>with session.no_autoflush:<tab><tab><tab><tab>for root_obj in root_objs:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>args = self.get_callback_args(root_obj, callback)<tab><tab><tab><tab><tab><tab>if args:<tab><tab><tab><tab><tab><tab><tab>yield args",0,if root_obj :,"if hasattr ( root_obj , ""get_callback_args"" ) :",0.046522600101893324,1e-10,0.6410256410256411
"def test_opdm_to_oqdm(self):<tab>for file in filter(lambda x: x.endswith("".hdf5""), os.listdir(DATA_DIRECTORY)):<tab><tab>molecule = MolecularData(filename=os.path.join(DATA_DIRECTORY, file))<tab><tab><IF-STMT><tab><tab><tab>test_oqdm = map_one_pdm_to_one_hole_dm(molecule.fci_one_rdm)<tab><tab><tab>true_oqdm = numpy.eye(molecule.n_qubits) - molecule.fci_one_rdm<tab><tab><tab>assert numpy.allclose(test_oqdm, true_oqdm)",1,if molecule . fci_one_rdm is not None :,if molecule . fci_one_rdm is not None :,0.75,100.00000000000004,1.0
"def emitSubDomainData(self, subDomainData, event):<tab>self.emitRawRirData(subDomainData, event)<tab>for subDomainElem in subDomainData:<tab><tab>if self.checkForStop():<tab><tab><tab>return None<tab><tab>subDomain = subDomainElem.get(""subdomain"", """").strip()<tab><tab><IF-STMT><tab><tab><tab>self.emitHostname(subDomain, event)",1,if subDomain :,if subDomain :,0.5311706625951745,1e-10,1.0
"def download_cve(<tab>download_path: str, years: Optional[List[int]] = None, update: bool = False):<tab>if update:<tab><tab>process_url(CVE_URL.format(""modified""), download_path)<tab>else:<tab><tab>all_cve_urls = get_cve_links(CVE_URL, years)<tab><tab><IF-STMT><tab><tab><tab>raise CveLookupException(""Error: No CVE links found"")<tab><tab>for url in all_cve_urls:<tab><tab><tab>process_url(url, download_path)",1,if not all_cve_urls :,if not all_cve_urls :,0.75,100.00000000000004,1.0
"def is_special(s, i, directive):<tab>""""""Return True if the body text contains the @ directive.""""""<tab># j = skip_line(s,i) ; trace(s[i:j],':',directive)<tab>assert directive and directive[0] == ""@""<tab># 10/23/02: all directives except @others must start the line.<tab>skip_flag = directive in (""@others"", ""@all"")<tab>while i < len(s):<tab><tab>if match_word(s, i, directive):<tab><tab><tab>return True, i<tab><tab>else:<tab><tab><tab>i = skip_line(s, i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i = skip_ws(s, i)<tab>return False, -1",1,if skip_flag :,if skip_flag :,0.5311706625951745,1e-10,1.0
"def run_async(self, nuke_cursors):<tab># type: (bool) -> None<tab>interface_type = self.view.settings().get(""git_savvy.interface"")<tab>for cls in subclasses:<tab><tab>if cls.interface_type == interface_type:<tab><tab><tab>vid = self.view.id()<tab><tab><tab>interface = interfaces.get(vid, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>interface = interfaces[vid] = cls(view=self.view)<tab><tab><tab>interface.render(nuke_cursors=nuke_cursors)  # type: ignore[union-attr]<tab><tab><tab>break",1,if not interface :,if not interface :,0.75,100.00000000000004,1.0
"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if str(conf[""properties""][""sslEnforcement""]).lower() == ""enabled"":<tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",1,"if ""sslEnforcement"" in conf [ ""properties"" ] :","if ""sslEnforcement"" in conf [ ""properties"" ] :",0.75,100.00000000000004,1.0
"def do_shorts(<tab>opts: List[Tuple[str, str]], optstring: str, shortopts: str, args: List[str]) -> Tuple[List[Tuple[str, str]], List[str]]:<tab>while optstring != """":<tab><tab>opt, optstring = optstring[0], optstring[1:]<tab><tab>if short_has_arg(opt, shortopts):<tab><tab><tab>if optstring == """":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise GetoptError(""option -%s requires argument"" % opt, opt)<tab><tab><tab><tab>optstring, args = args[0], args[1:]<tab><tab><tab>optarg, optstring = optstring, """"<tab><tab>else:<tab><tab><tab>optarg = """"<tab><tab>opts.append((""-"" + opt, optarg))<tab>return opts, args",0,if not args :,if args is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def release(self):<tab>tid = _thread.get_ident()<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""cannot release un-acquired lock"")<tab><tab>assert self.count > 0<tab><tab>self.count -= 1<tab><tab>if self.count == 0:<tab><tab><tab>self.owner = None<tab><tab><tab>if self.waiters:<tab><tab><tab><tab>self.waiters -= 1<tab><tab><tab><tab>self.wakeup.release()",0,if self . owner != tid :,if tid is _thread . get_ident ( ) :,0.020882522728427784,4.789232204309912,0.3181818181818182
"def _summarize_kraken(fn):<tab>""""""get the value at species level""""""<tab>kraken = {}<tab>list_sp, list_value = [], []<tab>with open(fn) as handle:<tab><tab>for line in handle:<tab><tab><tab>cols = line.strip().split(""\t"")<tab><tab><tab>sp = cols[5].strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>list_sp.append(sp)<tab><tab><tab><tab>list_value.append(cols[0])<tab>kraken = {""kraken_sp"": list_sp, ""kraken_value"": list_value}<tab>return kraken",0,"if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :",if sp :,0.00345460844078153,1e-10,0.19865319865319864
"def _sync_remote_run(remote_run):<tab>assert remote_run.remote<tab>remote_name = remote_run.remote.name<tab>pull_args = click_util.Args(remote=remote_name, delete=False)<tab>try:<tab><tab>remote_impl_support.pull_runs([remote_run], pull_args)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab>log.exception(""pull %s from %s"", remote_run.id, remote_name)<tab><tab>else:<tab><tab><tab>log.error(""error pulling %s from %s: %s"", remote_run.id, remote_name, e)",1,if log . getEffectiveLevel ( ) <= logging . DEBUG :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,0.75,100.00000000000004,1.0
"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x):<tab>sign = None<tab>subseq = []<tab>for i in seq:<tab><tab>ki = key(i)<tab><tab><IF-STMT><tab><tab><tab>subseq.append(i)<tab><tab><tab>if ki != 0:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab>else:<tab><tab><tab>subseq.append(i)<tab><tab><tab>if sign * ki < -slop:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab><tab><tab>yield subseq<tab><tab><tab><tab>subseq = [i]<tab>if subseq:<tab><tab>yield subseq",1,if sign is None :,if sign is None :,0.75,100.00000000000004,1.0
"def import_til(self):<tab>log(""Importing type libraries..."")<tab>cur = self.db_cursor()<tab>sql = ""select name from diff.program_data where type = 'til'""<tab>cur.execute(sql)<tab>for row in cur.fetchall():<tab><tab>til = row[""name""]<tab><tab><IF-STMT><tab><tab><tab>til = til.decode(""utf-8"")<tab><tab>try:<tab><tab><tab>add_default_til(til)<tab><tab>except:<tab><tab><tab>log(""Error loading til %s: %s"" % (row[""name""], str(sys.exc_info()[1])))<tab>cur.close()<tab>auto_wait()",0,if type ( til ) is bytes :,"if isinstance ( til , bytes ) :",0.03916858170756418,14.535768424205482,0.40816326530612246
"def getBranches(self):<tab>returned = []<tab>for git_branch_line in self._executeGitCommandAssertSuccess(""branch"").stdout:<tab><tab><IF-STMT><tab><tab><tab>git_branch_line = git_branch_line[1:]<tab><tab>git_branch_line = git_branch_line.strip()<tab><tab>if BRANCH_ALIAS_MARKER in git_branch_line:<tab><tab><tab>alias_name, aliased = git_branch_line.split(BRANCH_ALIAS_MARKER)<tab><tab><tab>returned.append(branch.LocalBranchAlias(self, alias_name, aliased))<tab><tab>else:<tab><tab><tab>returned.append(branch.LocalBranch(self, git_branch_line))<tab>return returned",0,"if git_branch_line . startswith ( ""*"" ) :","if git_branch_line . startswith ( ""#"" ) :",0.5490406812970063,78.25422900366432,1.0
"def add_include_dirs(self, args):<tab>ids = []<tab>for a in args:<tab><tab># FIXME same hack, forcibly unpack from holder.<tab><tab><IF-STMT><tab><tab><tab>a = a.includedirs<tab><tab>if not isinstance(a, IncludeDirs):<tab><tab><tab>raise InvalidArguments(<tab><tab><tab><tab>""Include directory to be added is not an include directory object.""<tab><tab><tab>)<tab><tab>ids.append(a)<tab>self.include_dirs += ids",1,"if hasattr ( a , ""includedirs"" ) :","if hasattr ( a , ""includedirs"" ) :",0.75,100.00000000000004,1.0
"def _serialize_feature(self, feature):<tab>name = feature.unique_name()<tab><IF-STMT><tab><tab>self._features_dict[feature.unique_name()] = feature.to_dictionary()<tab><tab>for dependency in feature.get_dependencies(deep=True):<tab><tab><tab>name = dependency.unique_name()<tab><tab><tab>if name not in self._features_dict:<tab><tab><tab><tab>self._features_dict[name] = dependency.to_dictionary()",1,if name not in self . _features_dict :,if name not in self . _features_dict :,0.75,100.00000000000004,1.0
"def generate_io(chart_type, race_configs, environment):<tab># output JSON structures<tab>structures = []<tab>for race_config in race_configs:<tab><tab><IF-STMT><tab><tab><tab>title = chart_type.format_title(<tab><tab><tab><tab>environment,<tab><tab><tab><tab>race_config.track,<tab><tab><tab><tab>es_license=race_config.es_license,<tab><tab><tab><tab>suffix=""%s-io"" % race_config.label,<tab><tab><tab>)<tab><tab><tab>structures.append(chart_type.io(title, environment, race_config))<tab>return structures",1,"if ""io"" in race_config . charts :","if ""io"" in race_config . charts :",0.75,100.00000000000004,1.0
"def format_partition(partition, partition_schema):<tab>tokens = []<tab>if isinstance(partition, dict):<tab><tab>for name in partition_schema:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tok = _format_partition_kv(<tab><tab><tab><tab><tab>name, partition[name], partition_schema[name]<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab># dynamic partitioning<tab><tab><tab><tab>tok = name<tab><tab><tab>tokens.append(tok)<tab>else:<tab><tab>for name, value in zip(partition_schema, partition):<tab><tab><tab>tok = _format_partition_kv(name, value, partition_schema[name])<tab><tab><tab>tokens.append(tok)<tab>return ""PARTITION ({})"".format("", "".join(tokens))",1,if name in partition :,if name in partition :,0.75,100.00000000000004,1.0
"def to_dict(self, validate=True, ignore=(), context=None):<tab>context = context or {}<tab>condition = getattr(self, ""condition"", Undefined)<tab>copy = self  # don't copy unless we need to<tab>if condition is not Undefined:<tab><tab>if isinstance(condition, core.SchemaBase):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>kwds = parse_shorthand(condition[""field""], context.get(""data"", None))<tab><tab><tab>copy = self.copy(deep=[""condition""])<tab><tab><tab>copy.condition.update(kwds)<tab>return super(ValueChannelMixin, copy).to_dict(<tab><tab>validate=validate, ignore=ignore, context=context<tab>)",0,"elif ""field"" in condition and ""type"" not in condition :","elif isinstance ( condition , dict ) :",0.1390614149304029,3.4331054109918173,0.29166666666666663
"def _checkForCommand(self):<tab>prompt = b""cftp> ""<tab>if self._expectingCommand and self._lineBuffer == prompt:<tab><tab>buf = b""\n"".join(self._linesReceived)<tab><tab><IF-STMT><tab><tab><tab>buf = buf[len(prompt) :]<tab><tab>self.clearBuffer()<tab><tab>d, self._expectingCommand = self._expectingCommand, None<tab><tab>d.callback(buf)",1,if buf . startswith ( prompt ) :,if buf . startswith ( prompt ) :,0.75,100.00000000000004,1.0
"def schedule_logger(job_id=None, delete=False):<tab>if not job_id:<tab><tab>return getLogger(""fate_flow_schedule"")<tab>else:<tab><tab>if delete:<tab><tab><tab>with LoggerFactory.lock:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>for key in LoggerFactory.schedule_logger_dict.keys():<tab><tab><tab><tab><tab><tab>if job_id in key:<tab><tab><tab><tab><tab><tab><tab>del LoggerFactory.schedule_logger_dict[key]<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab><tab>key = job_id + ""schedule""<tab><tab><IF-STMT><tab><tab><tab>return LoggerFactory.schedule_logger_dict[key]<tab><tab>return LoggerFactory.get_schedule_logger(job_id)",0,if key in LoggerFactory . schedule_logger_dict :,if key in LoggerFactory . schedule_logger_dict . keys ( ) :,0.45519365548069524,64.1386525898168,0.8205128205128206
"def halfMultipartScore(nzb_name):<tab>try:<tab><tab>wrong_found = 0<tab><tab>for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]:<tab><tab><tab>for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]:<tab><tab><tab><tab>if ""%s%s"" % (wrong, nr) in nzb_name.lower():<tab><tab><tab><tab><tab>wrong_found += 1<tab><tab><IF-STMT><tab><tab><tab>return -30<tab><tab>return 0<tab>except:<tab><tab>log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc())<tab>return 0",0,if wrong_found == 1 :,if wrong_found == 3 :,0.39477865547525276,70.71067811865478,0.5
"def parse_converter_args(argstr: str) -> t.Tuple[t.Tuple, t.Dict[str, t.Any]]:<tab>argstr += "",""<tab>args = []<tab>kwargs = {}<tab>for item in _converter_args_re.finditer(argstr):<tab><tab>value = item.group(""stringval"")<tab><tab>if value is None:<tab><tab><tab>value = item.group(""value"")<tab><tab>value = _pythonize(value)<tab><tab><IF-STMT><tab><tab><tab>args.append(value)<tab><tab>else:<tab><tab><tab>name = item.group(""name"")<tab><tab><tab>kwargs[name] = value<tab>return tuple(args), kwargs",0,"if not item . group ( ""name"" ) :","elif item . group ( ""args"" ) :",0.29664910369441866,47.53852732567741,0.15151515151515152
"def leaves(self, unique=True):<tab>""""""Get the leaves of the tree starting at this root.""""""<tab>if not self.children:<tab><tab>return [self]<tab>else:<tab><tab>res = list()<tab><tab>for child in self.children:<tab><tab><tab>for sub_child in child.leaves(unique=unique):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>res.append(sub_child)<tab><tab>return res",0,if not unique or sub_child not in res :,if sub_child not in res :,0.4291271377681715,59.755798910891144,0.3197278911564626
"def to_tree(self, tagname=None, idx=None, namespace=None):<tab>axIds = set((ax.axId for ax in self._axes))<tab>for chart in self._charts:<tab><tab>for id, axis in chart._axes.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(self, axis.tagname, axis)<tab><tab><tab><tab>axIds.add(id)<tab>return super(PlotArea, self).to_tree(tagname)",1,if id not in axIds :,if id not in axIds :,0.75,100.00000000000004,1.0
"def update_neighbor(neigh_ip_address, changes):<tab>rets = []<tab>for k, v in changes.items():<tab><tab>if k == neighbors.MULTI_EXIT_DISC:<tab><tab><tab>rets.append(_update_med(neigh_ip_address, v))<tab><tab>if k == neighbors.ENABLED:<tab><tab><tab>rets.append(update_neighbor_enabled(neigh_ip_address, v))<tab><tab><IF-STMT><tab><tab><tab>rets.append(_update_connect_mode(neigh_ip_address, v))<tab>return all(rets)",1,if k == neighbors . CONNECT_MODE :,if k == neighbors . CONNECT_MODE :,0.75,100.00000000000004,1.0
"def close_all_connections():<tab>global _managers, _lock, _in_use, _timer<tab>_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>_timer.cancel()<tab><tab><tab>_timer = None<tab><tab>for domain, managers in _managers.items():<tab><tab><tab>for manager in managers:<tab><tab><tab><tab>manager.close()<tab><tab>_managers = {}<tab>finally:<tab><tab>_lock.release()",0,if _timer :,if _timer is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def _instrument_model(self, model):<tab>for key, value in list(<tab><tab>model.__dict__.items()<tab>):  # avoid ""dictionary keys changed during iteration""<tab><tab>if isinstance(value, tf.keras.layers.Layer):<tab><tab><tab>new_layer = self._instrument(value)<tab><tab><tab>if new_layer is not value:<tab><tab><tab><tab>setattr(model, key, new_layer)<tab><tab>elif isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value[i] = self._instrument(item)<tab>return model",1,"if isinstance ( item , tf . keras . layers . Layer ) :","if isinstance ( item , tf . keras . layers . Layer ) :",0.75,100.00000000000004,1.0
"def target_glob(tgt, hosts):<tab>ret = {}<tab>for host in hosts:<tab><tab>if fnmatch.fnmatch(tgt, host):<tab><tab><tab>ret[host] = copy.deepcopy(__opts__.get(""roster_defaults"", {}))<tab><tab><tab>ret[host].update({""host"": host})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret[host].update({""user"": __opts__[""ssh_user""]})<tab>return ret",0,"if __opts__ . get ( ""ssh_user"" ) :","elif __opts__ . get ( ""ssh_user"" ) :",0.40018302522632676,93.06048591020995,0.5
"def write(self, data):<tab>if mock_target._mirror_on_stderr:<tab><tab>if self._write_line:<tab><tab><tab>sys.stderr.write(fn + "": "")<tab><tab><IF-STMT><tab><tab><tab>sys.stderr.write(data.decode(""utf8""))<tab><tab>else:<tab><tab><tab>sys.stderr.write(data)<tab><tab>if (data[-1]) == ""\n"":<tab><tab><tab>self._write_line = True<tab><tab>else:<tab><tab><tab>self._write_line = False<tab>super(Buffer, self).write(data)",0,if bytes :,"if isinstance ( data , bytes ) :",0.046522600101893324,1e-10,0.36
"def task_thread():<tab>while not task_queue.empty():<tab><tab>host, port, username, password = task_queue.get()<tab><tab>logger.info(<tab><tab><tab>""try burst {}:{} use username:{} password:{}"".format(<tab><tab><tab><tab>host, port, username, password<tab><tab><tab>)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>with task_queue.mutex:<tab><tab><tab><tab>task_queue.queue.clear()<tab><tab><tab>result_queue.put((username, password))",0,"if telnet_login ( host , port , username , password ) :",if not task_queue . empty ( ) :,0.022443570964435167,7.073666451977357,0.234375
"def _format_results(name, ppl, scores, metrics):<tab>""""""Format results.""""""<tab>result_str = """"<tab>if ppl:<tab><tab>result_str = ""%s ppl %.2f"" % (name, ppl)<tab>if scores:<tab><tab>for metric in metrics:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result_str += "", %s %s %.1f"" % (name, metric, scores[metric])<tab><tab><tab>else:<tab><tab><tab><tab>result_str = ""%s %s %.1f"" % (name, metric, scores[metric])<tab>return result_str",1,if result_str :,if result_str :,0.5311706625951745,1e-10,1.0
"def info_query(self, query):<tab>""""""Send a query which only returns 1 row""""""<tab>self._cmysql.query(query)<tab>first_row = ()<tab>if self._cmysql.have_result_set:<tab><tab>first_row = self._cmysql.fetch_row()<tab><tab><IF-STMT><tab><tab><tab>self._cmysql.free_result()<tab><tab><tab>raise errors.InterfaceError(""Query should not return more than 1 row"")<tab>self._cmysql.free_result()<tab>return first_row",0,if self . _cmysql . fetch_row ( ) :,if first_row > 1 :,0.015736078468693036,7.64649370538093,0.5
"def reset_class(self):<tab>for f in self.fields_order:<tab><tab><IF-STMT><tab><tab><tab>f.value = int(f.strbits, 2)<tab><tab>elif ""default_val"" in f.kargs:<tab><tab><tab>f.value = int(f.kargs[""default_val""], 2)<tab><tab>else:<tab><tab><tab>f.value = None<tab><tab>if f.fname:<tab><tab><tab>setattr(self, f.fname, f)",0,if f . strbits and isbin ( f . strbits ) :,if f . strbits :,0.13177909701988666,17.437038542312457,0.5079365079365079
"def _walk_map_list(self, access_func):<tab>seen = []<tab>cur = self<tab>while cur:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>yield cur<tab><tab>seen.append(cur.obj_offset)<tab><tab># check for signs of infinite looping<tab><tab>if len(seen) > 1024:<tab><tab><tab>break<tab><tab>cur = access_func(cur)",1,if cur . obj_offset in seen :,if cur . obj_offset in seen :,0.75,100.00000000000004,1.0
def bgdel():<tab>q = bgdelq<tab>while True:<tab><tab>name = q.get()<tab><tab>while os.path.exists(name):<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>os.remove(name)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>shutil.rmtree(name)<tab><tab><tab>except:<tab><tab><tab><tab>pass<tab><tab><tab>if os.path.exists(name):<tab><tab><tab><tab>time.sleep(0.1),1,if os . path . isfile ( name ) :,if os . path . isfile ( name ) :,0.75,100.00000000000004,1.0
"def _find_all_variables(transfer_variable):<tab>d = {}<tab>for _k, _v in transfer_variable.__dict__.items():<tab><tab>if isinstance(_v, Variable):<tab><tab><tab>d[_v._name] = _v<tab><tab><IF-STMT><tab><tab><tab>d.update(_find_all_variables(_v))<tab>return d",0,"elif isinstance ( _v , BaseTransferVariables ) :","elif isinstance ( _v , list ) :",0.5473017787506802,66.06328636027612,0.6
"def set_val():<tab>idx = 0<tab>for idx in range(0, len(model)):<tab><tab>row = model[idx]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if idx == len(os_widget.get_model()) - 1:<tab><tab><tab>idx = -1<tab>os_widget.set_active(idx)<tab>if idx == -1:<tab><tab>os_widget.set_active(0)<tab>if idx >= 0:<tab><tab>return row[1]<tab>if self.show_all_os:<tab><tab>return None",0,if value and row [ 0 ] == value :,if row [ 0 ] == 0 :,0.2551537996191364,50.54229726989799,0.3
"def _make_cache_key(group, window, rate, value, methods):<tab>count, period = _split_rate(rate)<tab>safe_rate = ""%d/%ds"" % (count, period)<tab>parts = [group, safe_rate, value, str(window)]<tab>if methods is not None:<tab><tab>if methods == ALL:<tab><tab><tab>methods = """"<tab><tab><IF-STMT><tab><tab><tab>methods = """".join(sorted([m.upper() for m in methods]))<tab><tab>parts.append(methods)<tab>prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"")<tab>return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()",0,"elif isinstance ( methods , ( list , tuple ) ) :",elif methods :,0.007465459175592149,1e-10,0.30392156862745096
"def findfiles(path):<tab>files = []<tab>for name in os.listdir(path):<tab><tab># ignore hidden files/dirs and other unwanted files<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pathname = os.path.join(path, name)<tab><tab>st = os.lstat(pathname)<tab><tab>mode = st.st_mode<tab><tab>if stat.S_ISDIR(mode):<tab><tab><tab>files.extend(findfiles(pathname))<tab><tab>elif stat.S_ISREG(mode):<tab><tab><tab>files.append((pathname, name, st))<tab>return files",0,"if name . startswith ( ""."" ) or name == ""lastsnap.jpg"" :","if name . startswith ( ""_"" ) :",0.2584286750619491,24.345633712861616,0.7083333333333333
"def __getitem__(self, key):<tab>if isinstance(key, str_types):<tab><tab>keys = self.get_keys()<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(' ""{0}"" is an invalid key'.format(key))<tab><tab>else:<tab><tab><tab>return self[keys.index(key)]<tab>else:<tab><tab>return list.__getitem__(self, key)",1,if key not in keys :,if key not in keys :,0.75,100.00000000000004,1.0
"def test_assert_set_equal(estimate: tp.Iterable[int], message: str) -> None:<tab>reference = {1, 2, 3}<tab>try:<tab><tab>testing.assert_set_equal(estimate, reference)<tab>except AssertionError as error:<tab><tab>if not message:<tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>""An error has been raised while it should not.""<tab><tab><tab>) from error<tab><tab>np.testing.assert_equal(error.args[0].split(""\n"")[1:], message)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(""An error should have been raised."")",0,if message :,if not estimate :,0.059856514947849826,1e-10,0.3333333333333333
"def get_directory_info(prefix, pth, recursive):<tab>res = []<tab>directory = os.listdir(pth)<tab>directory.sort()<tab>for p in directory:<tab><tab><IF-STMT><tab><tab><tab>subp = os.path.join(pth, p)<tab><tab><tab>p = os.path.join(prefix, p)<tab><tab><tab>if recursive and os.path.isdir(subp):<tab><tab><tab><tab>res.append([p, get_directory_info(prefix, subp, 1)])<tab><tab><tab>else:<tab><tab><tab><tab>res.append([p, None])<tab>return res",0,"if p [ 0 ] != ""."" :",if os . path . isfile ( p ) :,0.017150254846626058,5.369488567517933,0.2619047619047619
"def check(self, runner, script, info):<tab>if isinstance(info, ast.FunctionDef):<tab><tab>for arg in info.args.args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if arg.id in script.modelVars:<tab><tab><tab><tab><tab>self.problem(<tab><tab><tab><tab><tab><tab>""Function {0} may shadow model variable {1}"".format(<tab><tab><tab><tab><tab><tab><tab>info.name, arg.id<tab><tab><tab><tab><tab><tab>),<tab><tab><tab><tab><tab><tab>lineno=info.lineno,<tab><tab><tab><tab><tab>)",1,"if isinstance ( arg , ast . Name ) :","if isinstance ( arg , ast . Name ) :",0.75,100.00000000000004,1.0
"def db_lookup(field, key, publish_year=None):<tab>sql = ""select sum(ebook_count) as num from subjects where field=$field and key=$key""<tab>if publish_year:<tab><tab><IF-STMT><tab><tab><tab>sql += "" and publish_year between $y1 and $y2""<tab><tab><tab>(y1, y2) = publish_year<tab><tab>else:<tab><tab><tab>sql += "" and publish_year=$publish_year""<tab>return list(ebook_count_db.query(sql, vars=locals()))[0].num",0,"if isinstance ( publish_year , ( tuple , list ) ) :","if field == ""y1"" and key == ""y2"" :",0.011310531243696444,3.1251907639724417,0.25
"def put(self, session):<tab>with sess_lock:<tab><tab>self.parent.put(session)<tab><tab># Do not store the session if skip paths<tab><tab>for sp in self.skip_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>if session.sid in self._cache:<tab><tab><tab>try:<tab><tab><tab><tab>del self._cache[session.sid]<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass<tab><tab>self._cache[session.sid] = session<tab>self._normalize()",0,if request . path . startswith ( sp ) :,if session . sid == sp :,0.06576559450383199,6.082317172853824,0.23863636363636365
"def summarize(self):<tab>if self.bad_commit and self.good_commit:<tab><tab>for subresult in self.subresults.values():<tab><tab><tab>sub = subresult.summarize()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return sub<tab><tab>return ""Detected bad commit in {} repository:\n{} {}"".format(<tab><tab><tab>self.repo_name, self.bad_commit, get_message(self.suite, self.bad_commit)<tab><tab>)<tab>return """"",1,if sub :,if sub :,0.5311706625951745,1e-10,1.0
def compute_nullable_nonterminals(self):<tab>nullable = {}<tab>num_nullable = 0<tab>while 1:<tab><tab>for p in self.grammar.Productions[1:]:<tab><tab><tab>if p.len == 0:<tab><tab><tab><tab>nullable[p.name] = 1<tab><tab><tab><tab>continue<tab><tab><tab>for t in p.prod:<tab><tab><tab><tab>if not t in nullable:<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>nullable[p.name] = 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>num_nullable = len(nullable)<tab>return nullable,0,if len ( nullable ) == num_nullable :,if num_nullable == len ( nullable ) :,0.30556680845025985,39.76353643835254,1.0
"def _cast_float64_to_float32(self, feeds):<tab>for input_name, input_type in self.inputs:<tab><tab><IF-STMT><tab><tab><tab>feed = feeds.get(input_name)<tab><tab><tab>if feed is not None and feed.dtype == np.float64:<tab><tab><tab><tab>feeds[input_name] = feed.astype(np.float32)<tab>return feeds",0,"if input_type == ""tensor(float)"" :","if input_type == ""feed"" :",0.39477865547525276,52.38375874705952,1.0
"def proc_minute(d):<tab>if expanded[0][0] != ""*"":<tab><tab>diff_min = nearest_diff_method(d.minute, expanded[0], 60)<tab><tab><IF-STMT><tab><tab><tab>if is_prev:<tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=59)<tab><tab><tab>else:<tab><tab><tab><tab>d += relativedelta(minutes=diff_min, second=0)<tab><tab><tab>return True, d<tab>return False, d",0,if diff_min is not None and diff_min != 0 :,if diff_min is not None :,0.38801046869250244,36.24372413507827,0.6857142857142857
"def detype(self):<tab>if self._detyped is not None:<tab><tab>return self._detyped<tab>ctx = {}<tab>for key, val in self._d.items():<tab><tab>if not isinstance(key, str):<tab><tab><tab>key = str(key)<tab><tab>detyper = self.get_detyper(key)<tab><tab>if detyper is None:<tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>deval = detyper(val)<tab><tab><IF-STMT><tab><tab><tab># cannot be detyped<tab><tab><tab>continue<tab><tab>ctx[key] = deval<tab>self._detyped = ctx<tab>return ctx",1,if deval is None :,if deval is None :,0.75,100.00000000000004,1.0
"def get_or_create_user(request, user_data):<tab>try:<tab><tab>user = User.objects.get(sso_id=user_data[""id""])<tab><tab><IF-STMT><tab><tab><tab>update_user(user, user_data)<tab><tab>return user<tab>except User.DoesNotExist:<tab><tab>user = User.objects.create_user(<tab><tab><tab>user_data[""username""],<tab><tab><tab>user_data[""email""],<tab><tab><tab>is_active=user_data.get(""is_active"", True),<tab><tab><tab>sso_id=user_data[""id""],<tab><tab>)<tab><tab>user.update_acl_key()<tab><tab>setup_new_user(request.settings, user)<tab><tab>return user",0,"if user_needs_updating ( user , user_data ) :",if user . is_active :,0.019907917998500824,5.746166391236874,1.0
"def _populate_tree(self, element, d):<tab>""""""Populates an etree with attributes & elements, given a dict.""""""<tab>for k, v in d.iteritems():<tab><tab>if isinstance(v, dict):<tab><tab><tab>self._populate_dict(element, k, v)<tab><tab>elif isinstance(v, list):<tab><tab><tab>self._populate_list(element, k, v)<tab><tab><IF-STMT><tab><tab><tab>self._populate_bool(element, k, v)<tab><tab>elif isinstance(v, basestring):<tab><tab><tab>self._populate_str(element, k, v)<tab><tab>elif type(v) in [int, float, long, complex]:<tab><tab><tab>self._populate_number(element, k, v)",1,"elif isinstance ( v , bool ) :","elif isinstance ( v , bool ) :",0.75,100.00000000000004,1.0
"def load(cls):<tab>if not cls._loaded:<tab><tab>cls.log.debug(""Loading action_sets..."")<tab><tab><IF-STMT><tab><tab><tab>cls._find_action_sets(PATHS.ACTION_SETS_DIRECTORY)<tab><tab>else:<tab><tab><tab>cls.action_sets = JsonDecoder.load(PATHS.ACTION_SETS_JSON_FILE)<tab><tab>cls.log.debug(""Done!"")<tab><tab>cls._loaded = True",0,if not horizons . globals . fife . use_atlases :,if Path ( PATHS . ACTION_SETS_DIRECTORY ) . is_dir ( ) :,0.014179937081339813,3.211547431691929,0.234375
"def Resolve(self, updater=None):<tab>if len(self.Conflicts):<tab><tab>for setting, edge in self.Conflicts:<tab><tab><tab>answer = self.AskUser(self.Setting, setting)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = setting.Value.split(""|"")<tab><tab><tab><tab>value.remove(edge)<tab><tab><tab><tab>setting.Value = ""|"".join(value)<tab><tab><tab><tab>if updater:<tab><tab><tab><tab><tab>updater.UpdateSetting(setting)<tab><tab><tab>if answer == Gtk.ResponseType.NO:<tab><tab><tab><tab>return False<tab>return True",0,if answer == Gtk . ResponseType . YES :,if answer == Gtk . ResponseType . NO :,0.62709085524794,78.25422900366438,0.7142857142857143
"def read_tsv(input_file, quotechar=None):<tab>""""""Reads a tab separated value file.""""""<tab>with open(input_file, ""r"", encoding=""utf-8-sig"") as f:<tab><tab>reader = csv.reader(f, delimiter=""\t"", quotechar=quotechar)<tab><tab>lines = []<tab><tab>for line in reader:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = list(str(cell, ""utf-8"") for cell in line)  # noqa: F821<tab><tab><tab>lines.append(line)<tab><tab>return lines",0,if sys . version_info [ 0 ] == 2 :,if quotechar :,0.010867398423934471,1e-10,0.30952380952380953
"def devd_devfs_hook(middleware, data):<tab>if data.get(""subsystem"") != ""CDEV"":<tab><tab>return<tab>if data[""type""] == ""CREATE"":<tab><tab>disks = await middleware.run_in_thread(<tab><tab><tab>lambda: sysctl.filter(""kern.disks"")[0].value.split()<tab><tab>)<tab><tab># Device notified about is not a disk<tab><tab>if data[""cdev""] not in disks:<tab><tab><tab>return<tab><tab>await added_disk(middleware, data[""cdev""])<tab>elif data[""type""] == ""DESTROY"":<tab><tab># Device notified about is not a disk<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>await remove_disk(middleware, data[""cdev""])",0,"if not RE_ISDISK . match ( data [ ""cdev"" ] ) :","if data [ ""cdev"" ] not in disks :",0.18751191231518508,32.43475052602429,0.2761904761904762
"def on_edit_button_clicked(self, event=None, a=None, col=None):<tab>tree, tree_id = self.treeView.get_selection().get_selected()<tab>watchdir_id = str(self.store.get_value(tree_id, 0))<tab>if watchdir_id:<tab><tab><IF-STMT><tab><tab><tab>if self.watchdirs[watchdir_id][""enabled""]:<tab><tab><tab><tab>client.autoadd.disable_watchdir(watchdir_id)<tab><tab><tab>else:<tab><tab><tab><tab>client.autoadd.enable_watchdir(watchdir_id)<tab><tab>else:<tab><tab><tab>self.opts_dialog.show(self.watchdirs[watchdir_id], watchdir_id)",0,"if col and col . get_title ( ) == _ ( ""Active"" ) :","if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :",0.010176316274419986,3.150249737045819,0.3253968253968254
"def _execute(self, options, args):<tab>if len(args) < 1:<tab><tab>raise CommandError(_(""Not enough arguments""))<tab>paths = args<tab>songs = [self.load_song(p) for p in paths]<tab>for song in songs:<tab><tab><IF-STMT><tab><tab><tab>raise CommandError(<tab><tab><tab><tab>_(""Image editing not supported for %(file_name)s "" ""(%(file_format)s)"")<tab><tab><tab><tab>% {""file_name"": song(""~filename""), ""file_format"": song(""~format"")}<tab><tab><tab>)<tab>for song in songs:<tab><tab>try:<tab><tab><tab>song.clear_images()<tab><tab>except AudioFileError as e:<tab><tab><tab>raise CommandError(e)",0,if not song . can_change_images :,"if song . get_format ( ) != ""image"" :",0.04194106169660797,7.141816289329644,0.4807692307692308
"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None):<tab>filtered_pricing_rules = []<tab>if doc:<tab><tab>for pricing_rule in pricing_rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>if frappe.safe_eval(pricing_rule.condition, None, doc.as_dict()):<tab><tab><tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab>else:<tab><tab>filtered_pricing_rules = pricing_rules<tab>return filtered_pricing_rules",0,if pricing_rule . condition :,if doc . has_condition ( pricing_rule . condition ) :,0.10520539798272166,28.917849332325716,0.48333333333333334
"def ProcessStringLiteral(self):<tab>if self._lastToken == None or self._lastToken.type == self.OpenBrace:<tab><tab>text = super(JavaScriptBaseLexer, self).text<tab><tab>if text == '""use strict""' or text == ""'use strict'"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._scopeStrictModes.pop()<tab><tab><tab>self._useStrictCurrent = True<tab><tab><tab>self._scopeStrictModes.append(self._useStrictCurrent)",0,if len ( self . _scopeStrictModes ) > 0 :,if self . _useStrictCurrent :,0.026933810325055336,14.919518511396246,0.37142857142857144
"def _find_remote_inputs(metadata):<tab>out = []<tab>for fr_key in metadata.keys():<tab><tab>if isinstance(fr_key, (list, tuple)):<tab><tab><tab>frs = fr_key<tab><tab>else:<tab><tab><tab>frs = [fr_key]<tab><tab>for fr in frs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out.append(fr)<tab>return out",0,if objectstore . is_remote ( fr ) :,"if _is_remote_input ( metadata , fr ) :",0.07991956560314192,20.78060434846712,0.6
"def sub_paragraph(self, li):<tab>""""""Search for checkbox in sub-paragraph.""""""<tab>found = False<tab>if len(li):<tab><tab>first = list(li)[0]<tab><tab>if first.tag == ""p"" and first.text is not None:<tab><tab><tab>m = RE_CHECKBOX.match(first.text)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>first.text = self.markdown.htmlStash.store(<tab><tab><tab><tab><tab>get_checkbox(m.group(""state"")), safe=True<tab><tab><tab><tab>) + m.group(""line"")<tab><tab><tab><tab>found = True<tab>return found",0,if m is not None :,if m :,0.050438393472541504,1e-10,0.39999999999999997
"def list_files(basedir):<tab>""""""List files in the directory rooted at |basedir|.""""""<tab>if not os.path.isdir(basedir):<tab><tab>raise NoSuchDirectory(basedir)<tab>directories = [""""]<tab>while directories:<tab><tab>d = directories.pop()<tab><tab>for basename in os.listdir(os.path.join(basedir, d)):<tab><tab><tab>filename = os.path.join(d, basename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>directories.append(filename)<tab><tab><tab>elif os.path.exists(os.path.join(basedir, filename)):<tab><tab><tab><tab>yield filename",0,"if os . path . isdir ( os . path . join ( basedir , filename ) ) :",if os . path . isdir ( filename ) :,0.2326831377858849,30.518088481245282,0.5208333333333333
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def _dump(self, fd):<tab>with self.no_unpicklable_properties():<tab><tab><IF-STMT><tab><tab><tab>d = pickle.dumps(self)<tab><tab><tab>module_name = os.path.basename(sys.argv[0]).rsplit(""."", 1)[0]<tab><tab><tab>d = d.replace(b""c__main__"", b""c"" + module_name.encode(""ascii""))<tab><tab><tab>fd.write(d)<tab><tab>else:<tab><tab><tab>pickle.dump(self, fd)",0,"if self . __module__ == ""__main__"" :","if sys . argv [ 0 ] == b""c"" :",0.08236607224087547,6.942470526671953,0.30952380952380953
"def assert_session_stack(classes):<tab>assert len(_SklearnTrainingSession._session_stack) == len(classes)<tab>for idx, (sess, (parent_clazz, clazz)) in enumerate(<tab><tab>zip(_SklearnTrainingSession._session_stack, classes)<tab>):<tab><tab>assert sess.clazz == clazz<tab><tab><IF-STMT><tab><tab><tab>assert sess._parent is None<tab><tab>else:<tab><tab><tab>assert sess._parent.clazz == parent_clazz",1,if idx == 0 :,if idx == 0 :,0.75,100.00000000000004,1.0
"def native_color(c):<tab>try:<tab><tab>color = CACHE[c]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>c = NAMED_COLOR[c]<tab><tab>color = Color.FromArgb(<tab><tab><tab>int(c.rgba.a * 255), int(c.rgba.r), int(c.rgba.g), int(c.rgba.b)<tab><tab>)<tab><tab>CACHE[c] = color<tab>return color",0,"if isinstance ( c , str ) :",if c in NAMED_COLOR :,0.019907917998500824,7.492442692259767,0.3148148148148148
"def callback(name):<tab># XXX: move into Action<tab>for neighbor_name in reactor.configuration.neighbors.keys():<tab><tab>neighbor = reactor.configuration.neighbors.get(neighbor_name, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>neighbor.rib.outgoing.announce_watchdog(name)<tab><tab>yield False<tab>reactor.processes.answer_done(service)",1,if not neighbor :,if not neighbor :,0.75,100.00000000000004,1.0
"def token_producer(source):<tab>token = source.read_uint8()<tab>while token is not None:<tab><tab><IF-STMT><tab><tab><tab>yield DataToken(read_data(token, source))<tab><tab>elif is_small_integer(token):<tab><tab><tab>yield SmallIntegerToken(read_small_integer(token))<tab><tab>else:<tab><tab><tab>yield Token(token)<tab><tab>token = source.read_uint8()",0,if is_push_data_token ( token ) :,if is_data ( token ) :,0.5212518808542342,32.81829856080947,1.0
"def setattr(self, req, ino, attr, to_set, fi):<tab>print(""setattr:"", ino, to_set)<tab>a = self.attr[ino]<tab>for key in to_set:<tab><tab><IF-STMT><tab><tab><tab># Keep the old file type bit fields<tab><tab><tab>a[""st_mode""] = S_IFMT(a[""st_mode""]) | S_IMODE(attr[""st_mode""])<tab><tab>else:<tab><tab><tab>a[key] = attr[key]<tab>self.attr[ino] = a<tab>self.reply_attr(req, a, 1.0)",1,"if key == ""st_mode"" :","if key == ""st_mode"" :",0.75,100.00000000000004,1.0
"def check_enum_exports(module, eq_callback, only=None):<tab>""""""Make sure module exports all mnemonics from enums""""""<tab>for attr in enumerate_module(module, enum.Enum):<tab><tab><IF-STMT><tab><tab><tab>print(""SKIP"", attr)<tab><tab><tab>continue<tab><tab>for flag, value in attr.__members__.items():<tab><tab><tab>print(module, flag, value)<tab><tab><tab>eq_callback(getattr(module, flag), value)",0,if only is not None and attr not in only :,"if only and not hasattr ( attr , ""__members__"" ) :",0.23145193593447017,6.019608768705656,0.26666666666666666
"def remove_edit_vars_to(self, n):<tab>try:<tab><tab>removals = []<tab><tab>for v, cei in self.edit_var_map.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>removals.append(v)<tab><tab>for v in removals:<tab><tab><tab>self.remove_edit_var(v)<tab><tab>assert len(self.edit_var_map) == n<tab>except ConstraintNotFound:<tab><tab>raise InternalError(""Constraint not found during internal removal"")",0,if cei . index >= n :,if cei . edit_var_name == v :,0.3405653141935552,14.323145079400492,0.4761904761904762
"def fix_repeating_arguments(self):<tab>""""""Fix elements that should accumulate/increment values.""""""<tab>either = [list(child.children) for child in transform(self).children]<tab>for case in either:<tab><tab>for e in [child for child in case if case.count(child) > 1]:<tab><tab><tab>if type(e) is Argument or type(e) is Option and e.argcount:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>e.value = []<tab><tab><tab><tab>elif type(e.value) is not list:<tab><tab><tab><tab><tab>e.value = e.value.split()<tab><tab><tab>if type(e) is Command or type(e) is Option and e.argcount == 0:<tab><tab><tab><tab>e.value = 0<tab>return self",0,if e . value is None :,if type ( e . value ) is None :,0.11707955720123385,27.301208627090666,0.2698412698412698
"def add_I_prefix(current_line: List[str], ner: int, tag: str):<tab>for i in range(0, len(current_line)):<tab><tab>if i == 0:<tab><tab><tab>f.write(line_list[i])<tab><tab><IF-STMT><tab><tab><tab>f.write("" I-"" + tag)<tab><tab>else:<tab><tab><tab>f.write("" "" + current_line[i])<tab>f.write(""\n"")",1,elif i == ner :,elif i == ner :,1.0,100.00000000000004,1.0
def select_word_at_cursor(self):<tab>word_region = None<tab>selection = self.view.sel()<tab>for region in selection:<tab><tab>word_region = self.view.word(region)<tab><tab><IF-STMT><tab><tab><tab>selection.clear()<tab><tab><tab>selection.add(word_region)<tab><tab><tab>return word_region<tab>return word_region,0,if not word_region . empty ( ) :,if word_region is not None :,0.020894908942000634,19.03868163669696,0.3148148148148148
"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab>if self.op == ""+"":<tab><tab><tab>self.current += num<tab><tab><IF-STMT><tab><tab><tab>self.current -= num<tab><tab>elif self.op == ""*"":<tab><tab><tab>self.current *= num<tab><tab>elif self.op == ""/"":<tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res",1,"elif self . op == ""-"" :","elif self . op == ""-"" :",1.0,100.00000000000004,1.0
"def strip_pod(lines):<tab>in_pod = False<tab>stripped_lines = []<tab>for line in lines:<tab><tab>if re.match(r""^=(?:end|cut)"", line):<tab><tab><tab>in_pod = False<tab><tab>elif re.match(r""^=\w+"", line):<tab><tab><tab>in_pod = True<tab><tab><IF-STMT><tab><tab><tab>stripped_lines.append(line)<tab>return stripped_lines",0,elif not in_pod :,elif in_pod :,0.09209105436418806,1e-10,0.6
"def __init__(self, patch_files, patch_directories):<tab>files = []<tab>files_data = {}<tab>for filename_data in patch_files:<tab><tab>if isinstance(filename_data, list):<tab><tab><tab>filename, data = filename_data<tab><tab>else:<tab><tab><tab>filename = filename_data<tab><tab><tab>data = None<tab><tab>if not filename.startswith(os.sep):<tab><tab><tab>filename = ""{0}{1}"".format(FakeState.deploy_dir, filename)<tab><tab>files.append(filename)<tab><tab><IF-STMT><tab><tab><tab>files_data[filename] = data<tab>self.files = files<tab>self.files_data = files_data<tab>self.directories = patch_directories",0,if data :,if data is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def loadPerfsFromModule(self, module):<tab>""""""Return a suite of all perfs cases contained in the given module""""""<tab>perfs = []<tab>for name in dir(module):<tab><tab>obj = getattr(module, name)<tab><tab><IF-STMT><tab><tab><tab>perfs.append(self.loadPerfsFromPerfCase(obj))<tab>return self.suiteClass(perfs)",0,"if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :","if inspect . isclass ( obj ) and issubclass ( obj , PerfsCase ) :",0.44450199885475145,30.984710917900085,0.16176470588235295
"def download_subtitle(self, subtitle):<tab>if isinstance(subtitle, XSubsSubtitle):<tab><tab># download the subtitle<tab><tab>logger.info(""Downloading subtitle %r"", subtitle)<tab><tab>r = self.session.get(<tab><tab><tab>subtitle.download_link, headers={""Referer"": subtitle.page_link}, timeout=10<tab><tab>)<tab><tab>r.raise_for_status()<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Unable to download subtitle. No data returned from provider"")<tab><tab><tab>return<tab><tab>subtitle.content = fix_line_ending(r.content)",0,if not r . content :,if r . content is None :,0.10494632798085189,27.77619034011791,0.2571428571428572
"def get_inlaws(self, person):<tab>inlaws = []<tab>family_handles = person.get_family_handle_list()<tab>for handle in family_handles:<tab><tab>fam = self.database.get_family_from_handle(handle)<tab><tab>if fam.father_handle and not fam.father_handle == person.handle:<tab><tab><tab>inlaws.append(self.database.get_person_from_handle(fam.father_handle))<tab><tab><IF-STMT><tab><tab><tab>inlaws.append(self.database.get_person_from_handle(fam.mother_handle))<tab>return inlaws",0,elif fam . mother_handle and not fam . mother_handle == person . handle :,if fam . mother_handle and not fam . mother_handle == person . handle :,0.5707724687235703,94.2615147681512,0.75
"def _check_xorg_conf():<tab>if is_there_a_default_xorg_conf_file():<tab><tab>print(<tab><tab><tab>""WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not""<tab><tab><tab>"" create it yourself, it was likely generated by your distribution or by an Nvidia utility.\n""<tab><tab><tab>""This file may contain hard-coded GPU configuration that could interfere with optimus-manager,""<tab><tab><tab>"" so it is recommended that you delete it before proceeding.\n""<tab><tab><tab>""Ignore this warning and proceed with GPU switching ? (y/N)""<tab><tab>)<tab><tab>confirmation = ask_confirmation()<tab><tab><IF-STMT><tab><tab><tab>sys.exit(0)",1,if not confirmation :,if not confirmation :,0.75,100.00000000000004,1.0
"def _make_cache_key(group, window, rate, value, methods):<tab>count, period = _split_rate(rate)<tab>safe_rate = ""%d/%ds"" % (count, period)<tab>parts = [group, safe_rate, value, str(window)]<tab>if methods is not None:<tab><tab><IF-STMT><tab><tab><tab>methods = """"<tab><tab>elif isinstance(methods, (list, tuple)):<tab><tab><tab>methods = """".join(sorted([m.upper() for m in methods]))<tab><tab>parts.append(methods)<tab>prefix = getattr(settings, ""RATELIMIT_CACHE_PREFIX"", ""rl:"")<tab>return prefix + hashlib.md5(u"""".join(parts).encode(""utf-8"")).hexdigest()",0,if methods == ALL :,if not methods :,0.03944961859844226,12.750736437345598,0.4
"def num_of_mapped_volumes(self, initiator):<tab>cnt = 0<tab>for lm_link in self.req(""lun-maps"")[""lun-maps""]:<tab><tab>idx = lm_link[""href""].split(""/"")[-1]<tab><tab># NOTE(geguileo): There can be races so mapped elements retrieved<tab><tab># in the listing may no longer exist.<tab><tab>try:<tab><tab><tab>lm = self.req(""lun-maps"", idx=int(idx))[""content""]<tab><tab>except exception.NotFound:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>cnt += 1<tab>return cnt",0,"if lm [ ""ig-name"" ] == initiator :","if lm [ ""name"" ] == initiator [ ""name"" ] :",0.16403969652799533,39.375553105513404,1.0
"def _setAbsoluteY(self, value):<tab>if value is None:<tab><tab>self._absoluteY = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>value = 10<tab><tab>elif value == ""below"":<tab><tab><tab>value = -70<tab><tab>try:<tab><tab><tab>value = common.numToIntOrFloat(value)<tab><tab>except ValueError as ve:<tab><tab><tab>raise TextFormatException(<tab><tab><tab><tab>f""Not a supported absoluteY position: {value!r}""<tab><tab><tab>) from ve<tab><tab>self._absoluteY = value",0,"if value == ""above"" :","if value == ""below"" :",0.39477865547525276,59.4603557501361,1.0
"def render_markdown(text):<tab>users = {u.username.lower(): u for u in get_mention_users(text)}<tab>parts = MENTION_RE.split(text)<tab>for pos, part in enumerate(parts):<tab><tab>if not part.startswith(""@""):<tab><tab><tab>continue<tab><tab>username = part[1:].lower()<tab><tab><IF-STMT><tab><tab><tab>user = users[username]<tab><tab><tab>parts[pos] = '**[{}]({} ""{}"")**'.format(<tab><tab><tab><tab>part, user.get_absolute_url(), user.get_visible_name()<tab><tab><tab>)<tab>text = """".join(parts)<tab>return mark_safe(MARKDOWN(text))",1,if username in users :,if username in users :,0.75,100.00000000000004,1.0
def start_process(self):<tab>with self.thread_lock:<tab><tab><IF-STMT><tab><tab><tab>self.allow_process_request = False<tab><tab><tab>t = threading.Thread(target=self.__start)<tab><tab><tab>t.daemon = True<tab><tab><tab>t.start(),1,if self . allow_process_request :,if self . allow_process_request :,0.75,100.00000000000004,1.0
"def close(self):<tab>if self._fh.closed:<tab><tab>return<tab>self._fh.close()<tab>if os.path.isfile(self._filename):<tab><tab><IF-STMT><tab><tab><tab>salt.utils.win_dacl.copy_security(<tab><tab><tab><tab>source=self._filename, target=self._tmp_filename<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>shutil.copymode(self._filename, self._tmp_filename)<tab><tab><tab>st = os.stat(self._filename)<tab><tab><tab>os.chown(self._tmp_filename, st.st_uid, st.st_gid)<tab>atomic_rename(self._tmp_filename, self._filename)",0,if salt . utils . win_dacl . HAS_WIN32 :,"if os . name == ""nt"" :",0.017062028772160696,4.091092899898373,0.3333333333333333
"def _splitSchemaNameDotFieldName(sn_fn, fnRequired=True):<tab>if sn_fn.find(""."") != -1:<tab><tab>schemaName, fieldName = sn_fn.split(""."", 1)<tab><tab>schemaName = schemaName.strip()<tab><tab>fieldName = fieldName.strip()<tab><tab>if schemaName and fieldName:<tab><tab><tab>return (schemaName, fieldName)<tab>elif not fnRequired:<tab><tab>schemaName = sn_fn.strip()<tab><tab><IF-STMT><tab><tab><tab>return (schemaName, None)<tab>controlflow.system_error_exit(<tab><tab>2, f""{sn_fn} is not a valid custom schema.field name.""<tab>)",0,if schemaName :,if schemaName and not fieldName :,0.09036476851692153,1e-10,0.39999999999999997
"def modified(self):<tab>paths = set()<tab>dictionary_list = []<tab>for op_list in self._operations:<tab><tab><IF-STMT><tab><tab><tab>op_list = (op_list,)<tab><tab>for item in chain(*op_list):<tab><tab><tab>if item is None:<tab><tab><tab><tab>continue<tab><tab><tab>dictionary = item.dictionary<tab><tab><tab>if dictionary.path in paths:<tab><tab><tab><tab>continue<tab><tab><tab>paths.add(dictionary.path)<tab><tab><tab>dictionary_list.append(dictionary)<tab>return dictionary_list",0,"if not isinstance ( op_list , list ) :","if not isinstance ( op_list , ( list , tuple ) ) :",0.2802995302189482,53.2800971987552,0.823529411764706
"def apply(self, db, person):<tab>for family_handle in person.get_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab><IF-STMT><tab><tab><tab>for event_ref in family.get_event_ref_list():<tab><tab><tab><tab>if event_ref:<tab><tab><tab><tab><tab>event = db.get_event_from_handle(event_ref.ref)<tab><tab><tab><tab><tab>if not event.get_place_handle():<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab>if not event.get_date_object():<tab><tab><tab><tab><tab><tab>return True<tab>return False",1,if family :,if family :,0.5311706625951745,1e-10,1.0
"def test_cleanup_params(self, body, rpc_mock):<tab>res = self._get_resp_post(body)<tab>self.assertEqual(http_client.ACCEPTED, res.status_code)<tab>rpc_mock.assert_called_once_with(self.context, mock.ANY)<tab>cleanup_request = rpc_mock.call_args[0][1]<tab>for key, value in body.items():<tab><tab><IF-STMT><tab><tab><tab>if value is not None:<tab><tab><tab><tab>value = value == ""true""<tab><tab>self.assertEqual(value, getattr(cleanup_request, key))<tab>self.assertEqual(self._expected_services(*SERVICES), res.json)",0,"if key in ( ""disabled"" , ""is_up"" ) :","if isinstance ( value , bool ) :",0.03313893421568771,5.789419402078114,0.27272727272727276
"def get_billable_and_total_duration(activity, start_time, end_time):<tab>precision = frappe.get_precision(""Timesheet Detail"", ""hours"")<tab>activity_duration = time_diff_in_hours(end_time, start_time)<tab>billing_duration = 0.0<tab>if activity.billable:<tab><tab>billing_duration = activity.billing_hours<tab><tab><IF-STMT><tab><tab><tab>billing_duration = (<tab><tab><tab><tab>activity_duration * activity.billing_hours / activity.hours<tab><tab><tab>)<tab>return flt(activity_duration, precision), flt(billing_duration, precision)",0,if activity_duration != activity . billing_hours :,if activity . hours :,0.12803489387928724,8.718519271156227,0.7222222222222222
"def cpus(self):<tab>try:<tab><tab>cpus = (<tab><tab><tab>self.inspect[""Spec""][""Resources""][""Reservations""][""NanoCPUs""] / 1000000000.0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>cpus = int(cpus)<tab><tab>return cpus<tab>except TypeError:<tab><tab>return None<tab>except KeyError:<tab><tab>return 0",0,if cpus == int ( cpus ) :,if cpus . isdigit ( ) :,0.0440256366632803,14.759564526951554,0.5111111111111111
"def _create_object(self, obj_body):<tab>props = obj_body[SYMBOL_PROPERTIES]<tab>for prop_name, prop_value in props.items():<tab><tab><IF-STMT><tab><tab><tab># get the first key as the convert function<tab><tab><tab>func_name = list(prop_value.keys())[0]<tab><tab><tab>if func_name.startswith(""_""):<tab><tab><tab><tab>func = getattr(self, func_name)<tab><tab><tab><tab>props[prop_name] = func(prop_value[func_name])<tab>if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping:<tab><tab>return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props)<tab>else:<tab><tab>return props",0,"if isinstance ( prop_value , dict ) and prop_value :","if isinstance ( prop_value , dict ) :",0.4623120877637518,60.57025366576469,0.7846153846153847
"def _yield_unescaped(self, string):<tab>while ""\\"" in string:<tab><tab>finder = EscapeFinder(string)<tab><tab>yield finder.before + finder.backslashes<tab><tab><IF-STMT><tab><tab><tab>yield self._unescape(finder.text)<tab><tab>else:<tab><tab><tab>yield finder.text<tab><tab>string = finder.after<tab>yield string",0,if finder . escaped and finder . text :,if self . _is_escaped ( finder ) :,0.01786335094255824,5.604233375480572,0.23809523809523808
"def _check_matches(rule, matches):<tab>errors = 0<tab>for match in matches:<tab><tab>filematch = _match_to_test_file(match)<tab><tab><IF-STMT><tab><tab><tab>utils.error(<tab><tab><tab><tab>""The match '{}' for rule '{}' points to a non existing test module path: {}"",<tab><tab><tab><tab>match,<tab><tab><tab><tab>rule,<tab><tab><tab><tab>filematch,<tab><tab><tab>)<tab><tab><tab>errors += 1<tab>return errors",0,if not filematch . exists ( ) :,if not filematch :,0.07898193091364736,23.50540321304655,0.7777777777777778
"def focused_windows():<tab>tree = i3.get_tree()<tab>workspaces = tree.workspaces()<tab>for workspace in workspaces:<tab><tab>container = workspace<tab><tab>while container:<tab><tab><tab>if not hasattr(container, ""focus"") or not container.focus:<tab><tab><tab><tab>break<tab><tab><tab>container_id = container.focus[0]<tab><tab><tab>container = container.find_by_id(container_id)<tab><tab><IF-STMT><tab><tab><tab>coname = container.name<tab><tab><tab>wsname = workspace.name<tab><tab><tab>print(""WS"", wsname + "":"", coname)",1,if container :,if container :,0.5311706625951745,1e-10,1.0
"def normals(self, value):<tab>if value is not None:<tab><tab>value = np.asanyarray(value, dtype=np.float32)<tab><tab>value = np.ascontiguousarray(value)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Incorrect normals shape"")<tab>self._normals = value",0,if value . shape != self . positions . shape :,if len ( value . shape ) != self . shape :,0.4519784439466152,35.74046404361828,0.35714285714285715
"def test_hexdigest(self):<tab>for cons in self.hash_constructors:<tab><tab>h = cons()<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(h.digest(16), bytes)<tab><tab><tab>self.assertEqual(hexstr(h.digest(16)), h.hexdigest(16))<tab><tab>else:<tab><tab><tab>self.assertIsInstance(h.digest(), bytes)<tab><tab><tab>self.assertEqual(hexstr(h.digest()), h.hexdigest())",0,if h . name in self . shakes :,if h . is_hex ( ) :,0.06758931074158556,19.070828081828378,0.37142857142857144
"def _get_cluster_status(self):<tab>try:<tab><tab>return (<tab><tab><tab>self.dataproc_client.projects()<tab><tab><tab>.regions()<tab><tab><tab>.clusters()<tab><tab><tab>.get(<tab><tab><tab><tab>projectId=self.gcloud_project_id,<tab><tab><tab><tab>region=self.dataproc_region,<tab><tab><tab><tab>clusterName=self.dataproc_cluster_name,<tab><tab><tab><tab>fields=""status"",<tab><tab><tab>)<tab><tab><tab>.execute()<tab><tab>)<tab>except HttpError as e:<tab><tab><IF-STMT><tab><tab><tab>return None  # We got a 404 so the cluster doesn't exist<tab><tab>else:<tab><tab><tab>raise e",0,if e . resp . status == 404 :,if e . status == 404 :,0.34681727425331355,65.48907866815301,0.48148148148148145
"def _items_from(self, context):<tab>self._context = context<tab>if self._is_local_variable(self._keyword_name, context):<tab><tab>for item in self._items_from_controller(context):<tab><tab><tab>yield item<tab>else:<tab><tab>for df in context.datafiles:<tab><tab><tab>self._yield_for_other_threads()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for item in self._items_from_datafile(df):<tab><tab><tab><tab><tab>yield item",0,if self . _items_from_datafile_should_be_checked ( df ) :,if df . exists ( ) :,0.03976571592938584,3.113082773188573,0.4
"def Command(argv, funcs, path_val):<tab>arg, i = COMMAND_SPEC.Parse(argv)<tab>status = 0<tab>if arg.v:<tab><tab>for kind, arg in _ResolveNames(argv[i:], funcs, path_val):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>status = 1  # nothing printed, but we fail<tab><tab><tab>else:<tab><tab><tab><tab># This is for -v, -V is more detailed.<tab><tab><tab><tab>print(arg)<tab>else:<tab><tab>util.warn(""*** command without -v not not implemented ***"")<tab><tab>status = 1<tab>return status",0,if kind is None :,"if kind == ""v"" :",0.06497877230811641,12.22307556087252,0.5
"def delete_doc(elastic_document_id, node, index=None, category=None):<tab>index = index or INDEX<tab>if not category:<tab><tab>if isinstance(node, Preprint):<tab><tab><tab>category = ""preprint""<tab><tab><IF-STMT><tab><tab><tab>category = ""registration""<tab><tab>else:<tab><tab><tab>category = node.project_or_component<tab>client().delete(<tab><tab>index=index,<tab><tab>doc_type=category,<tab><tab>id=elastic_document_id,<tab><tab>refresh=True,<tab><tab>ignore=[404],<tab>)",0,elif node . is_registration :,"elif isinstance ( node , Registration ) :",0.0268165501010265,7.267884212102741,0.36
"def getDictFromTree(tree):<tab>ret_dict = {}<tab>for child in tree.getchildren():<tab><tab><IF-STMT><tab><tab><tab>## Complex-type child. Recurse<tab><tab><tab>content = getDictFromTree(child)<tab><tab>else:<tab><tab><tab>content = child.text<tab><tab>if ret_dict.has_key(child.tag):<tab><tab><tab>if not type(ret_dict[child.tag]) == list:<tab><tab><tab><tab>ret_dict[child.tag] = [ret_dict[child.tag]]<tab><tab><tab>ret_dict[child.tag].append(content or """")<tab><tab>else:<tab><tab><tab>ret_dict[child.tag] = content or """"<tab>return ret_dict",0,if child . getchildren ( ) :,"if isinstance ( child , Leaf ) :",0.04118257290339881,13.888095170058955,0.3148148148148148
"def get(self, block=True, timeout=None, ack=False):<tab>if not block:<tab><tab>return self.get_nowait()<tab>start_time = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>return self.get_nowait(ack)<tab><tab>except BaseQueue.Empty:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lasted = time.time() - start_time<tab><tab><tab><tab>if timeout > lasted:<tab><tab><tab><tab><tab>time.sleep(min(self.max_timeout, timeout - lasted))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(self.max_timeout)",1,if timeout :,if timeout :,0.5311706625951745,1e-10,1.0
"def rewrite(self, string):<tab>string = super(JSReplaceFuzzy, self).rewrite(string)<tab>cdx = self.url_rewriter.rewrite_opts[""cdx""]<tab>if cdx.get(""is_fuzzy""):<tab><tab>expected = unquote(cdx[""url""])<tab><tab>actual = unquote(self.url_rewriter.wburl.url)<tab><tab>exp_m = self.rx_obj.search(expected)<tab><tab>act_m = self.rx_obj.search(actual)<tab><tab><IF-STMT><tab><tab><tab>result = string.replace(exp_m.group(1), act_m.group(1))<tab><tab><tab>if result != string:<tab><tab><tab><tab>string = result<tab>return string",1,if exp_m and act_m :,if exp_m and act_m :,0.75,100.00000000000004,1.0
"def locate_exe_dir(d, check=True):<tab>exe_dir = os.path.join(d, ""Scripts"") if ON_WINDOWS else os.path.join(d, ""bin"")<tab>if not os.path.isdir(exe_dir):<tab><tab><IF-STMT><tab><tab><tab>bin_dir = os.path.join(d, ""bin"")<tab><tab><tab>if os.path.isdir(bin_dir):<tab><tab><tab><tab>return bin_dir<tab><tab>if check:<tab><tab><tab>raise InvalidVirtualEnv(""Unable to locate executables directory."")<tab>return exe_dir",0,if ON_WINDOWS :,if os . path . exists ( exe_dir ) :,0.04224510045373539,1e-10,0.36
"def _ensuresyspath(self, ensuremode, path):<tab>if ensuremode:<tab><tab>s = str(path)<tab><tab>if ensuremode == ""append"":<tab><tab><tab>if s not in sys.path:<tab><tab><tab><tab>sys.path.append(s)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sys.path.insert(0, s)",0,if s != sys . path [ 0 ] :,if s not in sys . path :,0.07112436406141975,18.594002123233256,0.3611111111111111
"def create_season_banners(self, show_obj):<tab>if self.season_banners and show_obj:<tab><tab>result = []<tab><tab>for season, episodes in show_obj.episodes.iteritems():  # @UnusedVariable<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.log(<tab><tab><tab><tab><tab>u""Metadata provider ""<tab><tab><tab><tab><tab>+ self.name<tab><tab><tab><tab><tab>+ "" creating season banners for ""<tab><tab><tab><tab><tab>+ show_obj.name,<tab><tab><tab><tab><tab>logger.DEBUG,<tab><tab><tab><tab>)<tab><tab><tab><tab>result = result + [self.save_season_banners(show_obj, season)]<tab><tab>return all(result)<tab>return False",0,"if not self . _has_season_banner ( show_obj , season ) :",if season not in self . season_banners :,0.08957344218606997,6.341825373820594,0.32051282051282054
"def validate_nb(self, nb):<tab>super(MetadataValidatorV3, self).validate_nb(nb)<tab>ids = set([])<tab>for cell in nb.cells:<tab><tab>if ""nbgrader"" not in cell.metadata:<tab><tab><tab>continue<tab><tab>grade = cell.metadata[""nbgrader""][""grade""]<tab><tab>solution = cell.metadata[""nbgrader""][""solution""]<tab><tab>locked = cell.metadata[""nbgrader""][""locked""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>grade_id = cell.metadata[""nbgrader""][""grade_id""]<tab><tab>if grade_id in ids:<tab><tab><tab>raise ValidationError(""Duplicate grade id: {}"".format(grade_id))<tab><tab>ids.add(grade_id)",0,if not grade and not solution and not locked :,if not grade or not solution or not locked :,0.6006691542685241,29.84745896009822,0.75
"def read_version():<tab>regexp = re.compile(r""^__version__\W*=\W*'([\d.abrc]+)'"")<tab>init_py = os.path.join(os.path.dirname(__file__), ""aiopg"", ""__init__.py"")<tab>with open(init_py) as f:<tab><tab>for line in f:<tab><tab><tab>match = regexp.match(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return match.group(1)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""Cannot find version in aiopg/__init__.py"")",0,if match is not None :,if match :,0.050438393472541504,1e-10,0.39999999999999997
"def _column_keys(self):<tab>""""""Get a dictionary of all columns and their case mapping.""""""<tab>if not self.exists:<tab><tab>return {}<tab>with self.db.lock:<tab><tab>if self._columns is None:<tab><tab><tab># Initialise the table if it doesn't exist<tab><tab><tab>table = self.table<tab><tab><tab>self._columns = {}<tab><tab><tab>for column in table.columns:<tab><tab><tab><tab>name = normalize_column_name(column.name)<tab><tab><tab><tab>key = normalize_column_key(name)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>log.warning(""Duplicate column: %s"", name)<tab><tab><tab><tab>self._columns[key] = name<tab><tab>return self._columns",1,if key in self . _columns :,if key in self . _columns :,0.75,100.00000000000004,1.0
"def find_controller_by_names(self, names, testname):<tab>namestring = ""."".join(names)<tab>if not namestring.startswith(self.name):<tab><tab>return None<tab>if namestring == self.name:<tab><tab>return self<tab>for suite in self.suites:<tab><tab>res = suite.find_controller_by_names(<tab><tab><tab>namestring[len(self.name) + 1 :].split("".""), testname<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return res",1,if res :,if res :,0.5311706625951745,1e-10,1.0
"def _volume_x_metadata_get_item(<tab>context, volume_id, key, model, notfound_exec, session=None):<tab>result = (<tab><tab>_volume_x_metadata_get_query(context, volume_id, model, session=session)<tab><tab>.filter_by(key=key)<tab><tab>.first()<tab>)<tab>if not result:<tab><tab><IF-STMT><tab><tab><tab>raise notfound_exec(id=volume_id)<tab><tab>else:<tab><tab><tab>raise notfound_exec(metadata_key=key, volume_id=volume_id)<tab>return result",0,if model is models . VolumeGlanceMetadata :,if volume_id == volume_id :,0.02225082504991546,4.990049701936832,0.25
"def parse_results(cwd):<tab>optimal_dd = None<tab>optimal_measure = numpy.inf<tab>for tup in tools.find_conf_files(cwd):<tab><tab>dd = tup[1]<tab><tab><IF-STMT><tab><tab><tab>if dd[""results.train_y_misclass""] < optimal_measure:<tab><tab><tab><tab>optimal_measure = dd[""results.train_y_misclass""]<tab><tab><tab><tab>optimal_dd = dd<tab>print(""Optimal results.train_y_misclass:"", str(optimal_measure))<tab>for key, value in optimal_dd.items():<tab><tab>if ""hyper_parameters"" in key:<tab><tab><tab>print(key + "": "" + str(value))",1,"if ""results.train_y_misclass"" in dd :","if ""results.train_y_misclass"" in dd :",0.75,100.00000000000004,1.0
"def _stop_by_max_time_mins(self):<tab>""""""Stop optimization process once maximum minutes have elapsed.""""""<tab>if self.max_time_mins:<tab><tab>total_mins_elapsed = (<tab><tab><tab>datetime.now() - self._start_datetime<tab><tab>).total_seconds() / 60.0<tab><tab><IF-STMT><tab><tab><tab>raise KeyboardInterrupt(<tab><tab><tab><tab>""{:.2f} minutes have elapsed. TPOT will close down."".format(<tab><tab><tab><tab><tab>total_mins_elapsed<tab><tab><tab><tab>)<tab><tab><tab>)",0,if total_mins_elapsed >= self . max_time_mins :,if total_mins_elapsed > self . max_time_mins :,0.4962728306172343,81.96501312471537,1.0
"def __new__(meta, cls_name, bases, cls_dict):<tab>func = cls_dict.get(""func"")<tab>monad_cls = super(FuncMonadMeta, meta).__new__(meta, cls_name, bases, cls_dict)<tab>if func:<tab><tab><IF-STMT><tab><tab><tab>functions = func<tab><tab>else:<tab><tab><tab>functions = (func,)<tab><tab>for func in functions:<tab><tab><tab>registered_functions[func] = monad_cls<tab>return monad_cls",0,if type ( func ) is tuple :,"if isinstance ( func , ( list , tuple ) ) :",0.031693712964910886,8.91376552139813,0.5
"def get_tokens_unprocessed(self, text):<tab>buffered = """"<tab>insertions = []<tab>lng_buffer = []<tab>for i, t, v in self.language_lexer.get_tokens_unprocessed(text):<tab><tab><IF-STMT><tab><tab><tab>if lng_buffer:<tab><tab><tab><tab>insertions.append((len(buffered), lng_buffer))<tab><tab><tab><tab>lng_buffer = []<tab><tab><tab>buffered += v<tab><tab>else:<tab><tab><tab>lng_buffer.append((i, t, v))<tab>if lng_buffer:<tab><tab>insertions.append((len(buffered), lng_buffer))<tab>return do_insertions(insertions, self.root_lexer.get_tokens_unprocessed(buffered))",0,if t is self . needle :,"if t == ""\n"" :",0.04240600921794552,10.552670315936318,0.42857142857142855
"def get_conditions(filters):<tab>conditions = {""docstatus"": (""="", 1)}<tab>if filters.get(""from_date"") and filters.get(""to_date""):<tab><tab>conditions[""result_date""] = (<tab><tab><tab>""between"",<tab><tab><tab>(filters.get(""from_date""), filters.get(""to_date"")),<tab><tab>)<tab><tab>filters.pop(""from_date"")<tab><tab>filters.pop(""to_date"")<tab>for key, value in filters.items():<tab><tab><IF-STMT><tab><tab><tab>conditions[key] = value<tab>return conditions",0,if filters . get ( key ) :,"if isinstance ( value , str ) :",0.03622895148520873,13.134549472120788,0.25
"def _limit_value(key, value, config):<tab>if config[key].get(""upper_limit""):<tab><tab>limit = config[key][""upper_limit""]<tab><tab># auto handle datetime<tab><tab>if isinstance(value, datetime) and isinstance(limit, timedelta):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if (datetime.now() - limit) > value:<tab><tab><tab><tab><tab>value = datetime.now() - limit<tab><tab><tab>else:<tab><tab><tab><tab>if (datetime.now() + limit) < value:<tab><tab><tab><tab><tab>value = datetime.now() + limit<tab><tab>elif value > limit:<tab><tab><tab>value = limit<tab>return value",0,"if config [ key ] [ ""inverse"" ] is True :",if limit > 0 :,0.011636451275277468,2.564755813286796,0.23214285714285715
"def GetCurrentKeySet(self):<tab>""Return CurrentKeys with 'darwin' modifications.""<tab>result = self.GetKeySet(self.CurrentKeys())<tab>if sys.platform == ""darwin"":<tab><tab># macOS (OS X) Tk variants do not support the ""Alt""<tab><tab># keyboard modifier.  Replace it with ""Option"".<tab><tab># TODO (Ned?): the ""Option"" modifier does not work properly<tab><tab>#<tab> for Cocoa Tk and XQuartz Tk so we should not use it<tab><tab>#<tab> in the default 'OSX' keyset.<tab><tab>for k, v in result.items():<tab><tab><tab>v2 = [x.replace(""<Alt-"", ""<Option-"") for x in v]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[k] = v2<tab>return result",1,if v != v2 :,if v != v2 :,0.75,100.00000000000004,1.0
"def _load_testfile(filename, package, module_relative):<tab>if module_relative:<tab><tab>package = _normalize_module(package, 3)<tab><tab>filename = _module_relative_path(package, filename)<tab><tab>if hasattr(package, ""__loader__""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_contents = package.__loader__.get_data(filename)<tab><tab><tab><tab># get_data() opens files as 'rb', so one must do the equivalent<tab><tab><tab><tab># conversion as universal newlines would do.<tab><tab><tab><tab>return file_contents.replace(os.linesep, ""\n""), filename<tab>return open(filename).read(), filename",1,"if hasattr ( package . __loader__ , ""get_data"" ) :","if hasattr ( package . __loader__ , ""get_data"" ) :",0.75,100.00000000000004,1.0
"def iter_from_X_lengths(X, lengths):<tab>if lengths is None:<tab><tab>yield 0, len(X)<tab>else:<tab><tab>n_samples = X.shape[0]<tab><tab>end = np.cumsum(lengths).astype(np.int32)<tab><tab>start = end - lengths<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""more than {:d} samples in lengths array {!s}"".format(<tab><tab><tab><tab><tab>n_samples, lengths<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>for i in range(len(lengths)):<tab><tab><tab>yield start[i], end[i]",0,if end [ - 1 ] > n_samples :,if n_samples != n_samples :,0.029942750698461862,25.13293635022765,0.4642857142857143
"def change_sel(self):<tab>""""""Change the view's selections.""""""<tab>if self.alter_select and len(self.sels) > 0:<tab><tab><IF-STMT><tab><tab><tab>self.view.show(self.sels[0])<tab><tab>self.view.sel().clear()<tab><tab>self.view.sel().add_all(self.sels)",0,if self . multi_select is False :,if len ( self . sels ) == 1 :,0.03532742722429465,8.913765521398126,0.23863636363636365
"def cb_syncthing_device_data_changed(<tab>self, daemon, nid, address, client_version, inbps, outbps, inbytes, outbytes):<tab>if nid in self.devices:  # Should be always<tab><tab>device = self.devices[nid]<tab><tab># Update strings<tab><tab>device[""address""] = address<tab><tab><IF-STMT><tab><tab><tab>device[""version""] = client_version<tab><tab># Update rates<tab><tab>device[""inbps""] = ""%s/s (%s)"" % (sizeof_fmt(inbps), sizeof_fmt(inbytes))<tab><tab>device[""outbps""] = ""%s/s (%s)"" % (sizeof_fmt(outbps), sizeof_fmt(outbytes))",0,"if client_version not in ( ""?"" , None ) :",if client_version :,0.020477126045913657,1e-10,0.36
"def then(self, matches, when_response, context):<tab>if is_iterable(when_response):<tab><tab>ret = []<tab><tab>when_response = list(when_response)<tab><tab>for match in when_response:<tab><tab><tab>if match not in matches:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>match.name = self.match_name<tab><tab><tab><tab>matches.append(match)<tab><tab><tab><tab>ret.append(match)<tab><tab>return ret<tab>if self.match_name:<tab><tab>when_response.name = self.match_name<tab>if when_response not in matches:<tab><tab>matches.append(when_response)<tab><tab>return when_response",1,if self . match_name :,if self . match_name :,0.75,100.00000000000004,1.0
"def __update_parents(self, fileobj, path, delta):<tab>""""""Update all parent atoms with the new size.""""""<tab>if delta == 0:<tab><tab>return<tab>for atom in path:<tab><tab>fileobj.seek(atom.offset)<tab><tab>size = cdata.uint_be(fileobj.read(4))<tab><tab><IF-STMT>  # 64bit<tab><tab><tab># skip name (4B) and read size (8B)<tab><tab><tab>size = cdata.ulonglong_be(fileobj.read(12)[4:])<tab><tab><tab>fileobj.seek(atom.offset + 8)<tab><tab><tab>fileobj.write(cdata.to_ulonglong_be(size + delta))<tab><tab>else:  # 32bit<tab><tab><tab>fileobj.seek(atom.offset)<tab><tab><tab>fileobj.write(cdata.to_uint_be(size + delta))",0,if size == 1 :,if size == 0 :,0.39477865547525276,53.7284965911771,0.6
"def _fields_to_index(cls):<tab>fields = []<tab>for field in cls._meta.sorted_fields:<tab><tab>if field.primary_key:<tab><tab><tab>continue<tab><tab>requires_index = any(<tab><tab><tab>(field.index, field.unique, isinstance(field, ForeignKeyField))<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>fields.append(field)<tab>return fields",1,if requires_index :,if requires_index :,0.5311706625951745,1e-10,1.0
"def __init__(self, value):<tab>""""""Initialize the integer to the given value.""""""<tab>self._mpz_p = new_mpz()<tab>self._initialized = False<tab>if isinstance(value, float):<tab><tab>raise ValueError(""A floating point type is not a natural number"")<tab>self._initialized = True<tab>if isinstance(value, (int, long)):<tab><tab>_gmp.mpz_init(self._mpz_p)<tab><tab>result = _gmp.gmp_sscanf(tobytes(str(value)), b(""%Zd""), self._mpz_p)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Error converting '%d'"" % value)<tab>else:<tab><tab>_gmp.mpz_init_set(self._mpz_p, value._mpz_p)",0,if result != 1 :,if not result :,0.03944961859844226,12.750736437345598,0.4
"def decode(cls, data):<tab>while data:<tab><tab>length, format_type, control_flags, sequence, pid = unpack(<tab><tab><tab>cls.Header.PACK, data[: cls.Header.LEN]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise NetLinkError(""Buffer underrun"")<tab><tab>yield cls.format(<tab><tab><tab>format_type, control_flags, sequence, pid, data[cls.Header.LEN : length]<tab><tab>)<tab><tab>data = data[length:]",0,if len ( data ) < length :,if length < cls . Header .LEN :,0.020373036588449148,6.742555929751843,0.2857142857142857
"def __post_init__(self):<tab>if self._node_id is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""invalid node_id: {}"".format(hexlify(self._node_id).decode())<tab><tab><tab>)<tab>if self.udp_port is not None and not 1 <= self.udp_port <= 65535:<tab><tab>raise ValueError(""invalid udp port"")<tab>if self.tcp_port is not None and not 1 <= self.tcp_port <= 65535:<tab><tab>raise ValueError(""invalid tcp port"")<tab>if not is_valid_public_ipv4(self.address, self.allow_localhost):<tab><tab>raise ValueError(f""invalid ip address: '{self.address}'"")",0,if not len ( self . _node_id ) == constants . HASH_LENGTH :,if not is_valid_node_id ( self . _node_id ) :,0.2240533692616627,42.095675571314295,0.48148148148148145
"def orderUp(self, items):<tab>sel = []  # new selection<tab>undoinfo = []<tab>for bid, lid in items:<tab><tab>if isinstance(lid, int):<tab><tab><tab>undoinfo.append(self.orderUpLineUndo(bid, lid))<tab><tab><tab>sel.append((bid, lid - 1))<tab><tab><IF-STMT><tab><tab><tab>undoinfo.append(self.orderUpBlockUndo(bid))<tab><tab><tab>if bid == 0:<tab><tab><tab><tab>return items<tab><tab><tab>else:<tab><tab><tab><tab>sel.append((bid - 1, None))<tab>self.addUndo(undoinfo, ""Move Up"")<tab>return sel",0,elif lid is None :,"elif isinstance ( lid , block ) :",0.15181655010102652,7.267884212102741,0.2857142857142857
"def filter_data(self, min_len, max_len):<tab>logging.info(f""filtering data, min len: {min_len}, max len: {max_len}"")<tab>initial_len = len(self.src)<tab>filtered_src = []<tab>filtered_tgt = []<tab>for src, tgt in zip(self.src, self.tgt):<tab><tab><IF-STMT><tab><tab><tab>filtered_src.append(src)<tab><tab><tab>filtered_tgt.append(tgt)<tab>self.src = filtered_src<tab>self.tgt = filtered_tgt<tab>filtered_len = len(self.src)<tab>logging.info(f""pairs before: {initial_len}, after: {filtered_len}"")",0,if min_len <= len ( src ) <= max_len and min_len <= len ( tgt ) <= max_len :,if min_len <= tgt and min_len <= tgt < max_len :,0.19582158900747706,34.44597405246593,0.32142857142857145
"def layer_pretrained(self, net, args, options):<tab>model = getattr(torchvision.models, args[0])(pretrained=True)<tab>model.train(True)<tab>if options.layer:<tab><tab>layers = list(model.children())[: options.layer]<tab><tab><IF-STMT><tab><tab><tab>layers[-1] = nn.Sequential(*layers[-1][: options.sublayer])<tab>else:<tab><tab>layers = [model]<tab><tab>print(""List of pretrained layers:"", layers)<tab><tab>raise ValidationException(<tab><tab><tab>""layer=-1 required for pretrained, sublayer=-1 optional.  Layers outputted above.""<tab><tab>)<tab>return nn.Sequential(*layers)",1,if options . sublayer :,if options . sublayer :,0.75,100.00000000000004,1.0
"def deleteCalendar(users):<tab>calendarId = normalizeCalendarId(sys.argv[5])<tab>for user in users:<tab><tab>user, cal = buildCalendarGAPIObject(user)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>gapi.call(cal.calendarList(), ""delete"", soft_errors=True, calendarId=calendarId)",1,if not cal :,if not cal :,0.75,100.00000000000004,1.0
"def iter_modules(self, by_clients=False, clients_filter=None):<tab>""""""iterate over all modules""""""<tab>clients = None<tab>if by_clients:<tab><tab>clients = self.get_clients(clients_filter)<tab><tab><IF-STMT><tab><tab><tab>return<tab>self._refresh_modules()<tab>for module_name in self.modules:<tab><tab>try:<tab><tab><tab>module = self.get_module(module_name)<tab><tab>except PupyModuleDisabled:<tab><tab><tab>continue<tab><tab>if clients is not None:<tab><tab><tab>for client in clients:<tab><tab><tab><tab>if module.is_compatible_with(client):<tab><tab><tab><tab><tab>yield module<tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield module",0,if not clients :,if clients is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def update_me(self):<tab>try:<tab><tab>while 1:<tab><tab><tab>line = self.queue.get_nowait()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.delete(1.0, tk.END)<tab><tab><tab>else:<tab><tab><tab><tab>self.insert(tk.END, str(line))<tab><tab><tab>self.see(tk.END)<tab><tab><tab>self.update_idletasks()<tab>except queue.Empty:<tab><tab>pass<tab>self.after(100, self.update_me)",1,if line is None :,if line is None :,0.75,100.00000000000004,1.0
"def request_power_state(self, state, force=False):<tab>if self.current_state != state or force:<tab><tab><IF-STMT><tab><tab><tab>self.request_in_progress = True<tab><tab><tab>logging.info(""Requesting %s"" % state)<tab><tab><tab>cb = PowerManager.Callback(self, state)<tab><tab><tab>rets = self.parent.Plugins.run(<tab><tab><tab><tab>""on_power_state_change_requested"", self, state, cb<tab><tab><tab>)<tab><tab><tab>cb.num_cb = len(rets)<tab><tab><tab>cb.check()<tab><tab>else:<tab><tab><tab>logging.info(""Another request in progress"")",1,if not self . request_in_progress :,if not self . request_in_progress :,0.75,100.00000000000004,1.0
"def __getitem__(self, idx):<tab>super(BatchDataset, self).__getitem__(idx)<tab>maxidx = len(self.dataset)<tab>samples = []<tab>for i in range(0, self.batchsize):<tab><tab>j = idx * self.batchsize + i<tab><tab>if j >= maxidx:<tab><tab><tab>break<tab><tab>j = self.perm(j, maxidx)<tab><tab>sample = self.dataset[j]<tab><tab><IF-STMT><tab><tab><tab>samples.append(sample)<tab>samples = self.makebatch(samples)<tab>return samples",0,if self . filter ( sample ) :,if sample is not None :,0.01983074478100545,7.654112967106117,0.23214285714285715
"def __call__(self, request, *args, **kwargs):<tab>template_vars = {}<tab>for form_name, form_class in self.forms.iteritems():<tab><tab><IF-STMT><tab><tab><tab>template_vars[form_name] = form_class(request)<tab><tab>else:<tab><tab><tab>template_vars[form_name] = None<tab>if request.method == ""POST"":<tab><tab>action = self.find_post_handler_action(request)<tab><tab>form = self.handlers[action](request, data=request.POST, files=request.FILES)<tab><tab>template_vars.update(form.dispatch(action, request, *args, **kwargs))<tab>return self.GET(template_vars, request, *args, **kwargs)",0,"if form_class . must_display ( request , * args , ** kwargs ) :",if form_class . is_valid ( request ) :,0.05117273863674329,23.2826852566667,0.5818181818181818
"def on_show_all(self, widget, another):<tab>if widget.get_active():<tab><tab><IF-STMT><tab><tab><tab>self.treeview.update_items(all=True, comment=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items(all=True)<tab>else:<tab><tab>if another.get_active():<tab><tab><tab>self.treeview.update_items(comment=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items()",1,if another . get_active ( ) :,if another . get_active ( ) :,0.75,100.00000000000004,1.0
"def close(self):<tab>if self._closed:<tab><tab>return<tab>self._closed = True<tab>for proto in self._pipes.values():<tab><tab>if proto is None:<tab><tab><tab>continue<tab><tab>proto.pipe.close()<tab>if (<tab><tab>self._proc is not None<tab><tab>and<tab><tab># has the child process finished?<tab><tab>self._returncode is None<tab><tab>and<tab><tab># the child process has finished, but the<tab><tab># transport hasn't been notified yet?<tab><tab>self._proc.poll() is None<tab>):<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""Close running child process: kill %r"", self)<tab><tab>try:<tab><tab><tab>self._proc.kill()<tab><tab>except ProcessLookupError:<tab><tab><tab>pass",0,if self . _loop . get_debug ( ) :,if self . _proc is not None :,0.06717697280747224,22.613617379612155,0.4545454545454546
"def runTest(self):<tab>self.poco(text=""wait UI"").click()<tab>bomb_count = 0<tab>while True:<tab><tab>blue_fish = self.poco(""fish_emitter"").child(""blue"")<tab><tab>yellow_fish = self.poco(""fish_emitter"").child(""yellow"")<tab><tab>bomb = self.poco(""fish_emitter"").child(""bomb"")<tab><tab>fish = self.poco.wait_for_any([blue_fish, yellow_fish, bomb])<tab><tab>if fish is bomb:<tab><tab><tab>bomb_count += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>fish.click()<tab><tab>time.sleep(2.5)",0,if bomb_count > 3 :,if bomb_count >= 5 :,0.31497877230811644,54.10822690539397,0.5
"def load_managers(*, loop, only):<tab>managers = {}<tab>for key in DB_CLASSES:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>params = DB_DEFAULTS.get(key) or {}<tab><tab>params.update(DB_OVERRIDES.get(key) or {})<tab><tab>database = DB_CLASSES[key](**params)<tab><tab>managers[key] = peewee_async.Manager(database, loop=loop)<tab>return managers",0,if only and key not in only :,if only and key in only :,0.3981815505525154,51.54486831107658,0.5952380952380951
"def links_extracted(self, request, links):<tab>for link in links:<tab><tab><IF-STMT><tab><tab><tab>r = self._create_request(link.url)<tab><tab><tab>r.meta[b""depth""] = request.meta[b""depth""] + 1<tab><tab><tab>self.schedule(r, self._get_score(r.meta[b""depth""]))<tab><tab><tab>link.meta[b""state""] = States.QUEUED",1,"if link . meta [ b""state"" ] == States . NOT_CRAWLED :","if link . meta [ b""state"" ] == States . NOT_CRAWLED :",0.75,100.00000000000004,1.0
"def find_worktree_git_dir(dotgit):<tab>""""""Search for a gitdir for this worktree.""""""<tab>try:<tab><tab>statbuf = os.stat(dotgit)<tab>except OSError:<tab><tab>return None<tab>if not stat.S_ISREG(statbuf.st_mode):<tab><tab>return None<tab>try:<tab><tab>lines = open(dotgit, ""r"").readlines()<tab><tab>for key, value in [line.strip().split("": "") for line in lines]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return value<tab>except ValueError:<tab><tab>pass<tab>return None",1,"if key == ""gitdir"" :","if key == ""gitdir"" :",0.75,100.00000000000004,1.0
"def _is_static_shape(self, shape):<tab>if shape is None or not isinstance(shape, list):<tab><tab>return False<tab>for dim_value in shape:<tab><tab>if not isinstance(dim_value, int):<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Negative dimension is illegal: %d"" % dim_value)<tab>return True",1,if dim_value < 0 :,if dim_value < 0 :,0.75,100.00000000000004,1.0
"def init_logger():<tab>configured_loggers = [log_config.get(""root"", {})] + [<tab><tab>logger for logger in log_config.get(""loggers"", {}).values()<tab>]<tab>used_handlers = {<tab><tab>handler for log in configured_loggers for handler in log.get(""handlers"", [])<tab>}<tab>for handler_id, handler in list(log_config[""handlers""].items()):<tab><tab>if handler_id not in used_handlers:<tab><tab><tab>del log_config[""handlers""][handler_id]<tab><tab><IF-STMT><tab><tab><tab>filename = handler[""filename""]<tab><tab><tab>logfile_path = Path(filename).expanduser().resolve()<tab><tab><tab>handler[""filename""] = str(logfile_path)<tab>logging.config.dictConfig(log_config)",0,"elif ""filename"" in handler . keys ( ) :","if ""filename"" in handler :",0.06398184717656782,36.337289265247364,0.48484848484848486
"def __call__(self):<tab>dmin, dmax = self.viewlim_to_dt()<tab>ymin = self.base.le(dmin.year)<tab>ymax = self.base.ge(dmax.year)<tab>ticks = [dmin.replace(year=ymin, **self.replaced)]<tab>while 1:<tab><tab>dt = ticks[-1]<tab><tab><IF-STMT><tab><tab><tab>return date2num(ticks)<tab><tab>year = dt.year + self.base.get_base()<tab><tab>ticks.append(dt.replace(year=year, **self.replaced))",0,if dt . year >= ymax :,if dt == dmax :,0.04240600921794552,13.83254362586636,0.4761904761904762
"def taiga(request, trigger_id, key):<tab>signature = request.META.get(""HTTP_X_TAIGA_WEBHOOK_SIGNATURE"")<tab># check that the data are ok with the provided signature<tab>if verify_signature(request._request.body, key, signature):<tab><tab>data = data_filter(trigger_id, **request.data)<tab><tab>status = save_data(trigger_id, data)<tab><tab>return (<tab><tab><tab>Response({""message"": ""Success""})<tab><tab><tab><IF-STMT><tab><tab><tab>else Response({""message"": ""Failed!""})<tab><tab>)<tab>Response({""message"": ""Bad request""})",1,if status,if status,0.408113883008419,1e-10,1.0
"def ParseResponses(<tab>self,<tab>knowledge_base: rdf_client.KnowledgeBase,<tab>responses: Iterable[rdfvalue.RDFValue],) -> Iterator[rdf_client.User]:<tab>for response in responses:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(f""Unexpected response type: `{type(response)}`"")<tab><tab># TODO: `st_mode` has to be an `int`, not `StatMode`.<tab><tab>if stat.S_ISDIR(int(response.st_mode)):<tab><tab><tab>homedir = response.pathspec.path<tab><tab><tab>username = os.path.basename(homedir)<tab><tab><tab>if username not in self._ignore_users:<tab><tab><tab><tab>yield rdf_client.User(username=username, homedir=homedir)",0,"if not isinstance ( response , rdf_client_fs . StatEntry ) :","if not isinstance ( response , rdfvalue . RDFValue ) :",0.331851246099359,37.178099888227045,0.7012987012987013
"def _iter_lines(path=path, response=response, max_next=options.http_max_next):<tab>path.responses = []<tab>n = 0<tab>while response:<tab><tab>path.responses.append(response)<tab><tab>yield from response.iter_lines(decode_unicode=True)<tab><tab>src = response.links.get(""next"", {}).get(""url"", None)<tab><tab>if not src:<tab><tab><tab>break<tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>vd.warning(f""stopping at max {max_next} pages"")<tab><tab><tab>break<tab><tab>vd.status(f""fetching next page from {src}"")<tab><tab>response = requests.get(src, stream=True)",1,if n > max_next :,if n > max_next :,0.75,100.00000000000004,1.0
"def __enter__(self):<tab>""""""Open a file and read it.""""""<tab>if self.code is None:<tab><tab>LOGGER.info(""File is reading: %s"", self.path)<tab><tab><IF-STMT><tab><tab><tab>self._file = open(self.path, encoding=""utf-8"")<tab><tab>else:<tab><tab><tab>self._file = open(self.path, ""rU"")<tab><tab>self.code = self._file.read()<tab>return self",0,"if sys . version_info >= ( 3 , ) :","if sys . version_info < ( 3 , 0 ) :",0.24289666525759693,52.664038784792666,0.7866666666666667
"def facts_for_oauthclients(self, namespace):<tab>""""""Gathers facts for oauthclients used with logging""""""<tab>self.default_keys_for(""oauthclients"")<tab>a_list = self.oc_command(<tab><tab>""get"", ""oauthclients"", namespace=namespace, add_options=[""-l"", LOGGING_SELECTOR]<tab>)<tab>if len(a_list[""items""]) == 0:<tab><tab>return<tab>for item in a_list[""items""]:<tab><tab>name = item[""metadata""][""name""]<tab><tab>comp = self.comp(name)<tab><tab><IF-STMT><tab><tab><tab>result = dict(redirectURIs=item[""redirectURIs""])<tab><tab><tab>self.add_facts_for(comp, ""oauthclients"", name, result)",1,if comp is not None :,if comp is not None :,0.75,100.00000000000004,1.0
"def get(self, k):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self._data1[k] = self._data2[k]<tab><tab><tab>del self._data2[k]<tab>return self._data1.get(k)",0,if k not in self . _data1 and k in self . _data2 :,if k in self . _data2 :,0.2037110662503305,33.241660012938524,0.3333333333333333
"def _parseparam(s):<tab>plist = []<tab>while s[:1] == "";"":<tab><tab>s = s[1:]<tab><tab>end = s.find("";"")<tab><tab>while end > 0 and (s.count('""', 0, end) - s.count('\\""', 0, end)) % 2:<tab><tab><tab>end = s.find("";"", end + 1)<tab><tab><IF-STMT><tab><tab><tab>end = len(s)<tab><tab>f = s[:end]<tab><tab>if ""="" in f:<tab><tab><tab>i = f.index(""="")<tab><tab><tab>f = f[:i].strip().lower() + ""="" + f[i + 1 :].strip()<tab><tab>plist.append(f.strip())<tab><tab>s = s[end:]<tab>return plist",1,if end < 0 :,if end < 0 :,0.75,100.00000000000004,1.0
"def __init__(self, **params):<tab>if ""length"" in params:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Supply either length or start and end to Player not both"")<tab><tab>params[""start""] = 0<tab><tab>params[""end""] = params.pop(""length"") - 1<tab>elif params.get(""start"", 0) > 0 and not ""value"" in params:<tab><tab>params[""value""] = params[""start""]<tab>super(Player, self).__init__(**params)",0,"if ""start"" in params or ""end"" in params :","if params . get ( ""start"" , 0 ) != 0 and not ""end"" in params :",0.3788182638031955,28.479942163807365,0.2046783625730994
"def libcxx_define(settings):<tab>compiler = _base_compiler(settings)<tab>libcxx = settings.get_safe(""compiler.libcxx"")<tab>if not compiler or not libcxx:<tab><tab>return """"<tab>if str(compiler) in GCC_LIKE:<tab><tab>if str(libcxx) == ""libstdc++"":<tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=0""<tab><tab><IF-STMT><tab><tab><tab>return ""_GLIBCXX_USE_CXX11_ABI=1""<tab>return """"",0,"elif str ( libcxx ) == ""libstdc++11"" :","elif str ( libcxx ) == ""libstdc"" :",0.6035533905932737,64.80311409098597,1.0
"def _get_sort_map(tags):<tab>""""""See TAG_TO_SORT""""""<tab>tts = {}<tab>for name, tag in tags.items():<tab><tab>if tag.has_sort:<tab><tab><tab>if tag.user:<tab><tab><tab><tab>tts[name] = ""%ssort"" % name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tts[""~%s"" % name] = ""~%ssort"" % name<tab>return tts",0,if tag . internal :,"elif tag . user != ""~"" :",0.04646619449370824,9.287528999566801,0.3333333333333333
"def quiet_f(*args):<tab>vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)}<tab>value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation)<tab>if expect_list:<tab><tab>if value.has_form(""List"", None):<tab><tab><tab>value = [extract_pyreal(item) for item in value.leaves]<tab><tab><tab>if any(item is None for item in value):<tab><tab><tab><tab>return None<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>value = extract_pyreal(value)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return value",0,if value is None or isinf ( value ) or isnan ( value ) :,if value is None :,0.18251809745518302,9.569649651041097,0.515625
"def on_action_chosen(self, id, action, mark_changed=True):<tab>before = self.set_action(self.current, id, action)<tab>if mark_changed:<tab><tab><IF-STMT><tab><tab><tab># TODO: Maybe better comparison<tab><tab><tab>self.undo.append(UndoRedo(id, before, action))<tab><tab><tab>self.builder.get_object(""btUndo"").set_sensitive(True)<tab><tab>self.on_profile_modified()<tab>else:<tab><tab>self.on_profile_modified(update_ui=False)<tab>return before",0,if before . to_string ( ) != action . to_string ( ) :,"if isinstance ( before ,UndoRedo ) :",0.020506611992481792,3.979005885472728,0.4
"def setUp(self):<tab>super(OperaterTest, self).setUp()<tab>if is_cli:<tab><tab>import clr<tab><tab>self.load_iron_python_test()<tab><tab><IF-STMT><tab><tab><tab>clr.AddReference(""System.Drawing.Primitives"")<tab><tab>else:<tab><tab><tab>clr.AddReference(""System.Drawing"")",0,if is_netcoreapp :,"if sys . platform == ""win32"" :",0.04579081141525348,1e-10,0.45
"def field_to_field_type(field):<tab>field_type = field[""type""]<tab>if isinstance(field_type, dict):<tab><tab>field_type = field_type[""type""]<tab>if isinstance(field_type, list):<tab><tab>field_type_length = len(field_type)<tab><tab>if field_type_length == 0:<tab><tab><tab>raise Exception(""Zero-length type list encountered, invalid CWL?"")<tab><tab><IF-STMT><tab><tab><tab>field_type = field_type[0]<tab>return field_type",0,elif len ( field_type ) == 1 :,if field_type_length == 1 :,0.07085198594944571,34.3763879968285,0.18181818181818182
"def _flatten(*args):<tab>ahs = set()<tab>if len(args) > 0:<tab><tab>for item in args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ahs.add(item)<tab><tab><tab>elif type(item) in (list, tuple, dict, set):<tab><tab><tab><tab>for ah in item:<tab><tab><tab><tab><tab>if type(ah) is not ActionHandle:  # pragma:nocover<tab><tab><tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(ah))<tab><tab><tab><tab><tab>ahs.add(ah)<tab><tab><tab>else:  # pragma:nocover<tab><tab><tab><tab>raise ActionManagerError(""Bad argument type %s"" % str(item))<tab>return ahs",1,if type ( item ) is ActionHandle :,if type ( item ) is ActionHandle :,0.75,100.00000000000004,1.0
"def _Determine_Do(self):<tab>self.applicable = 1<tab>configTokens = black.configure.items[""configTokens""].Get()<tab>buildFlavour = black.configure.items[""buildFlavour""].Get()<tab>if buildFlavour == ""full"":<tab><tab>self.value = False<tab>else:<tab><tab>self.value = True<tab>for opt, optarg in self.chosenOptions:<tab><tab><IF-STMT><tab><tab><tab>if not self.value:<tab><tab><tab><tab>configTokens.append(""tests"")<tab><tab><tab>self.value = True<tab><tab>elif opt == ""--without-tests"":<tab><tab><tab>if self.value:<tab><tab><tab><tab>configTokens.append(""notests"")<tab><tab><tab>self.value = False<tab>self.determined = 1",0,"if opt == ""--with-tests"" :","if opt == ""--tests"" :",0.39477865547525276,59.4603557501361,1.0
"def title_by_index(self, trans, index, context):<tab>d_type = self.get_datatype(trans, context)<tab>for i, (composite_name, composite_file) in enumerate(d_type.writable_files.items()):<tab><tab><IF-STMT><tab><tab><tab>rval = composite_name<tab><tab><tab>if composite_file.description:<tab><tab><tab><tab>rval = ""{} ({})"".format(rval, composite_file.description)<tab><tab><tab>if composite_file.optional:<tab><tab><tab><tab>rval = ""%s [optional]"" % rval<tab><tab><tab>return rval<tab>if index < self.get_file_count(trans, context):<tab><tab>return ""Extra primary file""<tab>return None",1,if i == index :,if i == index :,0.75,100.00000000000004,1.0
"def func(x, y):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>z = x + 2 * math.sin(y)<tab><tab><tab>return z ** 2<tab><tab>elif x == y:<tab><tab><tab>return 4<tab><tab>else:<tab><tab><tab>return 2 ** 3<tab>except ValueError:<tab><tab>foo = 0<tab><tab>for i in range(4):<tab><tab><tab>foo += i<tab><tab>return foo<tab>except TypeError:<tab><tab>return 42<tab>else:<tab><tab>return 33<tab>finally:<tab><tab>print(""finished"")",1,if x > y :,if x > y :,0.75,100.00000000000004,1.0
"def test_suite():<tab>suite = unittest.TestSuite()<tab>for fn in os.listdir(here):<tab><tab><IF-STMT><tab><tab><tab>modname = ""distutils.tests."" + fn[:-3]<tab><tab><tab>__import__(modname)<tab><tab><tab>module = sys.modules[modname]<tab><tab><tab>suite.addTest(module.test_suite())<tab>return suite",0,"if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :","if fn . endswith ( "".py"" ) and fn . endswith ( "".py"" ) :",0.831637802824134,68.91557807535084,0.7777777777777777
"def check_stack_names(self, frame, expected):<tab>names = []<tab>while frame:<tab><tab>name = frame.f_code.co_name<tab><tab># Stop checking frames when we get to our test helper.<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>names.append(name)<tab><tab>frame = frame.f_back<tab>self.assertEqual(names, expected)",0,"if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :",if name == expected :,0.013264132286865363,1.4746738768025476,0.42063492063492064
"def leave(self, reason=None):<tab>try:<tab><tab>if self.id.startswith(""C""):<tab><tab><tab>log.info(""Leaving channel %s (%s)"", self, self.id)<tab><tab><tab>self._bot.api_call(""conversations.leave"", data={""channel"": self.id})<tab><tab>else:<tab><tab><tab>log.info(""Leaving group %s (%s)"", self, self.id)<tab><tab><tab>self._bot.api_call(""conversations.leave"", data={""channel"": self.id})<tab>except SlackAPIResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>raise RoomError(f""Unable to leave channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)<tab>self._id = None",1,"if e . error == ""user_is_bot"" :","if e . error == ""user_is_bot"" :",0.75,100.00000000000004,1.0
"def ident(self):<tab>value = self._ident<tab>if value is False:<tab><tab>value = None<tab><tab># XXX: how will this interact with orig_prefix ?<tab><tab>#<tab>  not exposing attrs for now if orig_prefix is set.<tab><tab><IF-STMT><tab><tab><tab>wrapped = self.wrapped<tab><tab><tab>ident = getattr(wrapped, ""ident"", None)<tab><tab><tab>if ident is not None:<tab><tab><tab><tab>value = self._wrap_hash(ident)<tab><tab>self._ident = value<tab>return value",0,if not self . orig_prefix :,if self . _orig_prefix is not None :,0.046132297882334555,19.72940627795883,0.2916666666666667
"def is_ac_power_connected():<tab>for power_source_path in Path(""/sys/class/power_supply/"").iterdir():<tab><tab>try:<tab><tab><tab>with open(power_source_path / ""type"", ""r"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>with open(power_source_path / ""online"", ""r"") as f:<tab><tab><tab><tab>if f.read(1) == ""1"":<tab><tab><tab><tab><tab>return True<tab><tab>except IOError:<tab><tab><tab>continue<tab>return False",0,"if f . read ( ) . strip ( ) != ""Mains"" :","if f . read ( 1 ) == ""1"" :",0.1614706492289485,30.215132342213096,0.6666666666666666
"def _get_pending_by_app_token(self, app_token):<tab>result = []<tab>with self._pending_lock:<tab><tab>self._remove_stale_pending()<tab><tab>for data in self._pending_decisions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(data)<tab>return result",0,if data . app_token == app_token :,"if data [ ""token"" ] == app_token :",0.09638152409719936,44.08231875586728,1.0
"def do_create(specific_tables=None, base=Base):<tab>engine = get_engine()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>logger.info(<tab><tab><tab><tab>""Initializing only a subset of tables as requested: {}"".format(<tab><tab><tab><tab><tab>specific_tables<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>base.metadata.create_all(engine, tables=specific_tables)<tab><tab>else:<tab><tab><tab>base.metadata.create_all(engine)<tab>except Exception as err:<tab><tab>raise Exception(""could not create/re-create DB tables - exception: "" + str(err))",1,if specific_tables :,if specific_tables :,0.5311706625951745,1e-10,1.0
"def __setitem__(self, ndx, val):<tab>#<tab># Get the expression data object<tab>#<tab>exprdata = None<tab>if ndx in self._data:<tab><tab>exprdata = self._data[ndx]<tab>else:<tab><tab>_ndx = normalize_index(ndx)<tab><tab><IF-STMT><tab><tab><tab>exprdata = self._data[_ndx]<tab>if exprdata is None:<tab><tab>raise KeyError(<tab><tab><tab>""Cannot set the value of Expression '%s' with ""<tab><tab><tab>""invalid index '%s'"" % (self.cname(True), str(ndx))<tab><tab>)<tab>#<tab># Set the value<tab>#<tab>exprdata.set_value(val)",0,if _ndx in self . _data :,if _ndx is not None :,0.16655305992563652,19.740631366145518,0.2653061224489796
"def write(self, *bits):<tab>for bit in bits:<tab><tab><IF-STMT><tab><tab><tab>self.bytestream.append(0)<tab><tab>byte = self.bytestream[self.bytenum]<tab><tab>if self.bitnum == 8:<tab><tab><tab>if self.bytenum == len(self.bytestream) - 1:<tab><tab><tab><tab>byte = 0<tab><tab><tab><tab>self.bytestream += bytes([byte])<tab><tab><tab>self.bytenum += 1<tab><tab><tab>self.bitnum = 0<tab><tab>mask = 2 ** self.bitnum<tab><tab>if bit:<tab><tab><tab>byte |= mask<tab><tab>else:<tab><tab><tab>byte &= ~mask<tab><tab>self.bytestream[self.bytenum] = byte<tab><tab>self.bitnum += 1",1,if not self . bytestream :,if not self . bytestream :,0.75,100.00000000000004,1.0
"def terminate_subprocess(proc, timeout=0.1, log=None):<tab>if proc.poll() is None:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Sending SIGTERM to %r"", proc)<tab><tab>proc.terminate()<tab><tab>timeout_time = time.time() + timeout<tab><tab>while proc.poll() is None and time.time() < timeout_time:<tab><tab><tab>time.sleep(0.02)<tab><tab>if proc.poll() is None:<tab><tab><tab>if log:<tab><tab><tab><tab>log.info(""Sending SIGKILL to %r"", proc)<tab><tab><tab>proc.kill()<tab>return proc.returncode",1,if log :,if log :,0.5311706625951745,1e-10,1.0
"def mkpanel(color, rows, cols, tly, tlx):<tab>win = curses.newwin(rows, cols, tly, tlx)<tab>pan = panel.new_panel(win)<tab>if curses.has_colors():<tab><tab><IF-STMT><tab><tab><tab>fg = curses.COLOR_WHITE<tab><tab>else:<tab><tab><tab>fg = curses.COLOR_BLACK<tab><tab>bg = color<tab><tab>curses.init_pair(color, fg, bg)<tab><tab>win.bkgdset(ord("" ""), curses.color_pair(color))<tab>else:<tab><tab>win.bkgdset(ord("" ""), curses.A_BOLD)<tab>return pan",0,if color == curses . COLOR_BLUE :,if color == curses . COLOR_BLACK :,0.574113272471593,78.25422900366438,1.0
"def all_words(filename):<tab>start_char = True<tab>for c in characters(filename):<tab><tab>if start_char == True:<tab><tab><tab>word = """"<tab><tab><tab><IF-STMT><tab><tab><tab><tab># We found the start of a word<tab><tab><tab><tab>word = c.lower()<tab><tab><tab><tab>start_char = False<tab><tab><tab>else:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>if c.isalnum():<tab><tab><tab><tab>word += c.lower()<tab><tab><tab>else:<tab><tab><tab><tab># We found end of word, emit it<tab><tab><tab><tab>start_char = True<tab><tab><tab><tab>yield word",1,if c . isalnum ( ) :,if c . isalnum ( ) :,0.75,100.00000000000004,1.0
"def get_tf_weights_as_numpy(path=""./ckpt/aeslc/model.ckpt-32000"") -> Dict:<tab>init_vars = tf.train.list_variables(path)<tab>tf_weights = {}<tab>ignore_name = [""Adafactor"", ""global_step""]<tab>for name, shape in tqdm(init_vars, desc=""converting tf checkpoint to dict""):<tab><tab>skip_key = any([pat in name for pat in ignore_name])<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>array = tf.train.load_variable(path, name)<tab><tab>tf_weights[name] = array<tab>return tf_weights",1,if skip_key :,if skip_key :,0.5311706625951745,1e-10,1.0
"def app(scope, receive, send):<tab>while True:<tab><tab>message = await receive()<tab><tab>if message[""type""] == ""websocket.connect"":<tab><tab><tab>await send({""type"": ""websocket.accept""})<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif message[""type""] == ""websocket.disconnect"":<tab><tab><tab>break",1,"elif message [ ""type"" ] == ""websocket.receive"" :","elif message [ ""type"" ] == ""websocket.receive"" :",1.0,100.00000000000004,1.0
"def autoload(self):<tab>if self._app.config.THEME == ""auto"":<tab><tab>if sys.platform == ""darwin"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>theme = DARK<tab><tab><tab>else:<tab><tab><tab><tab>theme = LIGHT<tab><tab>else:<tab><tab><tab>theme = self.guess_system_theme()<tab><tab><tab>if theme == Dark:<tab><tab><tab><tab>theme = MacOSDark<tab>else:  # user settings have highest priority<tab><tab>theme = self._app.config.THEME<tab>self.load_theme(theme)",0,if get_osx_theme ( ) == 1 :,"if self . _app . config .THEME == ""dark"" :",0.018941002751756135,6.608973813188645,0.38666666666666666
"def example_reading_spec(self):<tab>data_fields = {""targets"": tf.VarLenFeature(tf.int64)}<tab><IF-STMT><tab><tab>data_fields[""inputs""] = tf.VarLenFeature(tf.int64)<tab>if self.packed_length:<tab><tab>if self.has_inputs:<tab><tab><tab>data_fields[""inputs_segmentation""] = tf.VarLenFeature(tf.int64)<tab><tab><tab>data_fields[""inputs_position""] = tf.VarLenFeature(tf.int64)<tab><tab>data_fields[""targets_segmentation""] = tf.VarLenFeature(tf.int64)<tab><tab>data_fields[""targets_position""] = tf.VarLenFeature(tf.int64)<tab>data_items_to_decoders = None<tab>return (data_fields, data_items_to_decoders)",1,if self . has_inputs :,if self . has_inputs :,0.75,100.00000000000004,1.0
"def _prepare_travel_graph(self):<tab>for op in self.op_dict.values():<tab><tab>op.const = False<tab><tab>if op.node.op in [""Const"", ""Placeholder""]:<tab><tab><tab>op.resolved = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>op.const = True<tab><tab>else:<tab><tab><tab>op.resolved = False",0,"if op . node . op == ""Const"" :","elif op . node . op in [ ""Const"" , ""Placeholder"" ] :",0.18935150827536362,29.48993986902436,0.4901960784313726
"def get_filestream_file_items(self):<tab>data = {}<tab>fs_file_updates = self.get_filestream_file_updates()<tab>for k, v in six.iteritems(fs_file_updates):<tab><tab>l = []<tab><tab>for d in v:<tab><tab><tab>offset = d.get(""offset"")<tab><tab><tab>content = d.get(""content"")<tab><tab><tab>assert offset is not None<tab><tab><tab>assert content is not None<tab><tab><tab>assert offset == 0 or offset == len(l), (k, v, l, d)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>l = []<tab><tab><tab>l.extend(map(json.loads, content))<tab><tab>data[k] = l<tab>return data",0,if not offset :,if not l :,0.34586199776872373,35.35533905932737,0.6
"def _rewrite_exprs(self, table, what):<tab>from ibis.expr.analysis import substitute_parents<tab>what = util.promote_list(what)<tab>all_exprs = []<tab>for expr in what:<tab><tab><IF-STMT><tab><tab><tab>all_exprs.extend(expr.exprs())<tab><tab>else:<tab><tab><tab>bound_expr = ir.bind_expr(table, expr)<tab><tab><tab>all_exprs.append(bound_expr)<tab>return [substitute_parents(x, past_projection=False) for x in all_exprs]",0,"if isinstance ( expr , ir . ExprList ) :","if isinstance ( expr , ir . Expr ) :",0.6049399806880458,70.71067811865478,0.7777777777777777
"def _group_by_commit_and_time(self, hits):<tab>result = {}<tab>for hit in hits:<tab><tab>source_hit = hit[""_source""]<tab><tab>key = ""%s_%s"" % (source_hit[""commit_info""][""id""], source_hit[""datetime""])<tab><tab>benchmark = self._benchmark_from_es_record(source_hit)<tab><tab><IF-STMT><tab><tab><tab>result[key][""benchmarks""].append(benchmark)<tab><tab>else:<tab><tab><tab>run_info = self._run_info_from_es_record(source_hit)<tab><tab><tab>run_info[""benchmarks""] = [benchmark]<tab><tab><tab>result[key] = run_info<tab>return result",1,if key in result :,if key in result :,0.75,100.00000000000004,1.0
"def _build_index(self):<tab>self._index = {}<tab>for start_char, sorted_offsets in self._offsets.items():<tab><tab>self._index[start_char] = {}<tab><tab>for i, offset in enumerate(sorted_offsets.get_offsets()):<tab><tab><tab>identifier = sorted_offsets.get_identifier_by_offset(offset)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._index[start_char][identifier[0 : self.index_depth]] = i",0,if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,if identifier is not None :,0.06115510987198902,1.13544432449426,0.32407407407407407
"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if ""exp"" in conf[""properties""][""attributes""]:<tab><tab><tab><tab>if conf[""properties""][""attributes""][""exp""]:<tab><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",1,"if ""attributes"" in conf [ ""properties"" ] :","if ""attributes"" in conf [ ""properties"" ] :",0.75,100.00000000000004,1.0
"def _PatchArtifact(self, artifact: rdf_artifacts.Artifact) -> rdf_artifacts.Artifact:<tab>""""""Patches artifact to not contain byte-string source attributes.""""""<tab>patched = False<tab>for source in artifact.sources:<tab><tab>attributes = source.attributes.ToDict()<tab><tab>unicode_attributes = compatibility.UnicodeJson(attributes)<tab><tab><IF-STMT><tab><tab><tab>source.attributes = unicode_attributes<tab><tab><tab>patched = True<tab>if patched:<tab><tab>self.DeleteArtifact(str(artifact.name))<tab><tab>self.WriteArtifact(artifact)<tab>return artifact",0,if attributes != unicode_attributes :,if unicode_attributes :,0.06767423853569741,1e-10,0.6190476190476191
"def edit_file(self, filename):<tab>import subprocess<tab>editor = self.get_editor()<tab>if self.env:<tab><tab>environ = os.environ.copy()<tab><tab>environ.update(self.env)<tab>else:<tab><tab>environ = None<tab>try:<tab><tab>c = subprocess.Popen('%s ""%s""' % (editor, filename), env=environ, shell=True)<tab><tab>exit_code = c.wait()<tab><tab><IF-STMT><tab><tab><tab>raise ClickException(""%s: Editing failed!"" % editor)<tab>except OSError as e:<tab><tab>raise ClickException(""%s: Editing failed: %s"" % (editor, e))",1,if exit_code != 0 :,if exit_code != 0 :,0.75,100.00000000000004,1.0
"def findControlPointsInMesh(glyph, va, subsegments):<tab>controlPointIndices = np.zeros((len(va), 1))<tab>index = 0<tab>for i, c in enumerate(subsegments):<tab><tab>segmentCount = len(glyph.contours[i].segments) - 1<tab><tab>for j, s in enumerate(c):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if glyph.contours[i].segments[j].type == ""line"":<tab><tab><tab><tab><tab>controlPointIndices[index] = 1<tab><tab><tab>index += s[1]<tab>return controlPointIndices",0,if j < segmentCount :,if s [ 0 ] == va [ index ] :,0.0237537216033675,4.02724819242185,0.23214285714285715
"def to_representation(self, value):<tab>old_social_string_fields = [""twitter"", ""github"", ""linkedIn""]<tab>request = self.context.get(""request"")<tab>show_old_format = (<tab><tab>request<tab><tab>and is_deprecated(request.version, self.min_version)<tab><tab>and request.method == ""GET""<tab>)<tab>if show_old_format:<tab><tab>social = value.copy()<tab><tab>for key in old_social_string_fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>social[key] = value[key][0]<tab><tab><tab>elif social.get(key) == []:<tab><tab><tab><tab>social[key] = """"<tab><tab>value = social<tab>return super(SocialField, self).to_representation(value)",0,if social . get ( key ) :,"if isinstance ( value [ key ] , list ) :",0.0318578261816963,9.425159511373677,0.3653846153846154
"def iter_raw_frames(path, packet_sizes, ctx):<tab>with open(path, ""rb"") as f:<tab><tab>for i, size in enumerate(packet_sizes):<tab><tab><tab>packet = Packet(size)<tab><tab><tab>read_size = f.readinto(packet)<tab><tab><tab>assert size<tab><tab><tab>assert read_size == size<tab><tab><tab>if not read_size:<tab><tab><tab><tab>break<tab><tab><tab>for frame in ctx.decode(packet):<tab><tab><tab><tab>yield frame<tab><tab>while True:<tab><tab><tab>try:<tab><tab><tab><tab>frames = ctx.decode(None)<tab><tab><tab>except EOFError:<tab><tab><tab><tab>break<tab><tab><tab>for frame in frames:<tab><tab><tab><tab>yield frame<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break",0,if not frames :,if i >= len ( packet_sizes ) :,0.03469219238104862,4.456882760699063,0.3333333333333333
"def get_shadows_zip(filename):<tab>import zipfile<tab>shadow_pkgs = set()<tab>with zipfile.ZipFile(filename) as lib_zip:<tab><tab>already_test = []<tab><tab>for fname in lib_zip.namelist():<tab><tab><tab>pname, fname = os.path.split(fname)<tab><tab><tab>if fname or (pname and fname):<tab><tab><tab><tab>continue<tab><tab><tab>if pname not in already_test and ""/"" not in pname:<tab><tab><tab><tab>already_test.append(pname)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>shadow_pkgs.add(pname)<tab>return shadow_pkgs",0,if is_shadowing ( pname ) :,if pname not in shadow_pkgs :,0.028043015323814018,7.809849842300637,0.5333333333333333
"def metrics_to_scalars(self, metrics):<tab>new_metrics = {}<tab>for k, v in metrics.items():<tab><tab>if isinstance(v, torch.Tensor):<tab><tab><tab>v = v.item()<tab><tab><IF-STMT><tab><tab><tab>v = self.metrics_to_scalars(v)<tab><tab>new_metrics[k] = v<tab>return new_metrics",0,"if isinstance ( v , dict ) :","elif isinstance ( v , dict ) :",0.40018302522632676,84.08964152537145,0.6666666666666666
"def insert_resets(f):<tab>newsync = dict()<tab>for k, v in f.sync.items():<tab><tab><IF-STMT><tab><tab><tab>newsync[k] = insert_reset(ResetSignal(k), v)<tab><tab>else:<tab><tab><tab>newsync[k] = v<tab>f.sync = newsync",0,if f . clock_domains [ k ] . rst is not None :,"if isinstance ( v , ResetSignal ) :",0.010105031683940181,2.7376474102577792,0.16363636363636364
"def get_attached_nodes(self, external_account):<tab>for node in self.get_nodes_with_oauth_grants(external_account):<tab><tab>if node is None:<tab><tab><tab>continue<tab><tab>node_settings = node.get_addon(self.oauth_provider.short_name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if node_settings.external_account == external_account:<tab><tab><tab>yield node",1,if node_settings is None :,if node_settings is None :,0.75,100.00000000000004,1.0
"def visitIf(self, node, scope):<tab>for test, body in node.tests:<tab><tab>if isinstance(test, ast.Const):<tab><tab><tab>if type(test.value) in self._const_types:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab>self.visit(test, scope)<tab><tab>self.visit(body, scope)<tab>if node.else_:<tab><tab>self.visit(node.else_, scope)",0,if not test . value :,if test . value in self . _const_types :,0.0922214626317771,14.323145079400492,0.2698412698412698
"def flatten(self):<tab># this is similar to fill_messages except it uses a list instead<tab># of a queue to place the messages in.<tab>result = []<tab>channel = await self.messageable._get_channel()<tab>self.channel = channel<tab>while self._get_retrieve():<tab><tab>data = await self._retrieve_messages(self.retrieve)<tab><tab>if len(data) < 100:<tab><tab><tab>self.limit = 0  # terminate the infinite loop<tab><tab><IF-STMT><tab><tab><tab>data = reversed(data)<tab><tab>if self._filter:<tab><tab><tab>data = filter(self._filter, data)<tab><tab>for element in data:<tab><tab><tab>result.append(self.state.create_message(channel=channel, data=element))<tab>return result",1,if self . reverse :,if self . reverse :,0.75,100.00000000000004,1.0
"def compute(self, x, y=None, targets=None):<tab>if targets is None:<tab><tab>targets = self.out_params<tab>in_params = list(self.in_x)<tab>if len(in_params) == 1:<tab><tab>args = [x]<tab>else:<tab><tab>args = list(zip(*x))<tab>if y is None:<tab><tab>pipe = self.pipe<tab>else:<tab><tab>pipe = self.train_pipe<tab><tab><IF-STMT><tab><tab><tab>args.append(y)<tab><tab>else:<tab><tab><tab>args += list(zip(*y))<tab><tab>in_params += self.in_y<tab>return self._compute(*args, pipe=pipe, param_names=in_params, targets=targets)",0,if len ( self . in_y ) == 1 :,if len ( x ) == 1 :,0.19511238466297295,38.27521065936582,0.6666666666666666
"def _import_top_module(self, name):<tab># scan sys.path looking for a location in the filesystem that contains<tab># the module, or an Importer object that can import the module.<tab>for item in sys.path:<tab><tab><IF-STMT><tab><tab><tab>module = self.fs_imp.import_from_dir(item, name)<tab><tab>else:<tab><tab><tab>module = item.import_top(name)<tab><tab>if module:<tab><tab><tab>return module<tab>return None",0,"if isinstance ( item , _StringType ) :",if os . path . isdir ( item ) :,0.03966830467822667,12.549310621989482,0.2619047619047619
"def __getitem__(self, key, _get_mode=False):<tab>if not _get_mode:<tab><tab>if isinstance(key, (int, long)):<tab><tab><tab>return self._list[key]<tab><tab>elif isinstance(key, slice):<tab><tab><tab>return self.__class__(self._list[key])<tab>ikey = key.lower()<tab>for k, v in self._list:<tab><tab><IF-STMT><tab><tab><tab>return v<tab># micro optimization: if we are in get mode we will catch that<tab># exception one stack level down so we can raise a standard<tab># key error instead of our special one.<tab>if _get_mode:<tab><tab>raise KeyError()<tab>raise BadRequestKeyError(key)",1,if k . lower ( ) == ikey :,if k . lower ( ) == ikey :,0.75,100.00000000000004,1.0
"def execute(self, arbiter, props):<tab>watcher = self._get_watcher(arbiter, props.pop(""name""))<tab>action = 0<tab>for key, val in props.get(""options"", {}).items():<tab><tab>if key == ""hooks"":<tab><tab><tab>new_action = 0<tab><tab><tab>for name, _val in val.items():<tab><tab><tab><tab>action = watcher.set_opt(""hooks.%s"" % name, _val)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>new_action = 1<tab><tab>else:<tab><tab><tab>new_action = watcher.set_opt(key, val)<tab><tab>if new_action == 1:<tab><tab><tab>action = 1<tab># trigger needed action<tab>return watcher.do_action(action)",1,if action == 1 :,if action == 1 :,0.75,100.00000000000004,1.0
"def OnBodyClick(self, event=None):<tab>try:<tab><tab>c = self.c<tab><tab>p = c.currentPosition()<tab><tab><IF-STMT><tab><tab><tab>self.OnActivateBody(event=event)<tab><tab>g.doHook(""bodyclick2"", c=c, p=p, v=p, event=event)<tab>except:<tab><tab>g.es_event_exception(""bodyclick"")",0,"if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :","if g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",0.824124731033278,93.20024073195327,0.3662551440329218
"def _class_weights(spec: config.MetricsSpec) -> Optional[Dict[int, float]]:<tab>""""""Returns class weights associated with AggregationOptions at offset.""""""<tab>if spec.aggregate.HasField(""top_k_list""):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""class_weights are not supported when top_k_list used: ""<tab><tab><tab><tab>""spec={}"".format(spec)<tab><tab><tab>)<tab><tab>return None<tab>return dict(spec.aggregate.class_weights) or None",0,if spec . aggregate . class_weights :,if spec . aggregate . class_weights is None :,0.48784249970862475,69.89307622784945,0.6333333333333333
"def _is_perf_file(file_path):<tab>f = get_file(file_path)<tab>for line in f:<tab><tab>if line[0] == ""#"":<tab><tab><tab>continue<tab><tab>r = event_regexp.search(line)<tab><tab><IF-STMT><tab><tab><tab>f.close()<tab><tab><tab>return True<tab><tab>f.close()<tab><tab>return False",1,if r :,if r :,0.5311706625951745,1e-10,1.0
"def _get_before_insertion_node(self):<tab>if self._nodes_stack.is_empty():<tab><tab>return None<tab>line = self._nodes_stack.parsed_until_line + 1<tab>node = self._new_module.get_last_leaf()<tab>while True:<tab><tab>parent = node.parent<tab><tab><IF-STMT><tab><tab><tab>assert node.end_pos[0] <= line<tab><tab><tab>assert node.end_pos[1] == 0 or ""\n"" in self._prefix<tab><tab><tab>return node<tab><tab>node = parent",0,"if parent . type in ( ""suite"" , ""file_input"" ) :",if parent is None :,0.02208245887228144,2.1448935777350973,0.42857142857142855
"def PyJsHoisted_parseClassRanges_(this, arguments, var=var):<tab>var = Scope({u""this"": this, u""arguments"": arguments}, var)<tab>var.registers([u""res""])<tab>pass<tab>if var.get(u""current"")(Js(u""]"")):<tab><tab>return Js([])<tab>else:<tab><tab>var.put(u""res"", var.get(u""parseNonemptyClassRanges"")())<tab><tab><IF-STMT><tab><tab><tab>var.get(u""bail"")(Js(u""nonEmptyClassRanges""))<tab><tab>return var.get(u""res"")",0,"if var . get ( u""res"" ) . neg ( ) :","if var . get ( u""current"" ) ( Js ( u""]"" ) ) ) :",0.2814990032404824,34.00215619680846,0.6666666666666666
"def _recurse_children(self, offset):<tab>""""""Recurses thorugh the available children""""""<tab>while offset < self.obj_offset + self.Length:<tab><tab>item = obj.Object(""VerStruct"", offset=offset, vm=self.obj_vm, parent=self)<tab><tab><IF-STMT><tab><tab><tab>raise StopIteration(<tab><tab><tab><tab>""Could not recover a key for a child at offset {0}"".format(<tab><tab><tab><tab><tab>item.obj_offset<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>yield item.get_key(), item.get_children()<tab><tab>offset = self.offset_pad(offset + item.Length)<tab>raise StopIteration(""No children"")",0,if item . Length < 1 or item . get_key ( ) == None :,if item . get_key ( ) is None :,0.16243220082054927,37.13426189560737,0.31359649122807015
"def _adapt_types(self, descr):<tab>names = []<tab>adapted_types = []<tab>for col in descr:<tab><tab>names.append(col[0])<tab><tab>impala_typename = col[1]<tab><tab>typename = udf._impala_to_ibis_type[impala_typename.lower()]<tab><tab><IF-STMT><tab><tab><tab>precision, scale = col[4:6]<tab><tab><tab>adapted_types.append(dt.Decimal(precision, scale))<tab><tab>else:<tab><tab><tab>adapted_types.append(typename)<tab>return names, adapted_types",0,"if typename == ""decimal"" :",if len ( col ) > 4 :,0.026407399022921448,6.567274736060395,0.3
"def sniff(self, filename):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>with tarfile.open(filename, ""r"") as temptar:<tab><tab><tab><tab>for f in temptar:<tab><tab><tab><tab><tab>if not f.isfile():<tab><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><tab>if f.name.endswith("".fast5""):<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>return False<tab>except Exception as e:<tab><tab>log.warning(""%s, sniff Exception: %s"", self, e)<tab>return False",0,if filename and tarfile . is_tarfile ( filename ) :,if tarfile . is_tarfile ( filename ) :,0.444454944906609,73.98067488982613,0.3666666666666667
"def getValue(self):<tab>if getattr(self.object, ""type"", """") != ""CURVE"":<tab><tab>return BezierSpline()<tab>evaluatedObject = getEvaluatedID(self.object)<tab>bSplines = evaluatedObject.data.splines<tab>if len(bSplines) > 0:<tab><tab>spline = createSplineFromBlenderSpline(bSplines[0])<tab><tab># Is None when the spline type is not supported.<tab><tab>if spline is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>spline.transform(evaluatedObject.matrix_world)<tab><tab><tab>return spline<tab>return BezierSpline()",0,if self . useWorldSpace :,"if hasattr ( evaluatedObject , ""matrix_world"" ) :",0.026407399022921448,4.02724819242185,0.3333333333333333
"def escape(text, newline=False):<tab>""""""Escape special html characters.""""""<tab>if isinstance(text, str):<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""'"" in text:<tab><tab><tab>text = text.replace(""'"", ""&quot;"")<tab><tab>if newline:<tab><tab><tab>if ""\n"" in text:<tab><tab><tab><tab>text = text.replace(""\n"", ""<br>"")<tab>return text",1,"if "">"" in text :","if "">"" in text :",0.75,100.00000000000004,1.0
"def _get_ilo_version(self):<tab>try:<tab><tab>self._get_ilo2('<?xml version=""1.0""?><RIBCL VERSION=""2.0""></RIBCL>')<tab>except ResponseError as e:<tab><tab>if hasattr(e, ""code""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 3<tab><tab><tab>if e.code == 501:<tab><tab><tab><tab>return 1<tab><tab>raise<tab>return 2",0,if e . code == 405 :,if e . code == 501 :,0.574113272471593,70.71067811865478,0.6666666666666666
"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab>if code == Path.MOVETO:<tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab>elif code == Path.CURVE3:<tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab>elif code == Path.CURVE4:<tab><tab><tab>ctx.curve_to(*points)<tab><tab><IF-STMT><tab><tab><tab>ctx.close_path()",1,elif code == Path . CLOSEPOLY :,elif code == Path . CLOSEPOLY :,0.75,100.00000000000004,1.0
"def called_by_shrinker():<tab>frame = sys._getframe(0)<tab>while frame:<tab><tab>fname = frame.f_globals.get(""__file__"", """")<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>frame = frame.f_back<tab>return False",0,"if os . path . basename ( fname ) == ""shrinker.py"" :","if fname and fname . endswith ( "".py"" ) :",0.01380795591814352,11.421985585914943,0.25
"def _ensuresyspath(self, ensuremode, path):<tab>if ensuremode:<tab><tab>s = str(path)<tab><tab>if ensuremode == ""append"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sys.path.append(s)<tab><tab>else:<tab><tab><tab>if s != sys.path[0]:<tab><tab><tab><tab>sys.path.insert(0, s)",1,if s not in sys . path :,if s not in sys . path :,0.75,100.00000000000004,1.0
"def get_instances(self, region: str, vpc: str):<tab>try:<tab><tab>await self._cache_instances(region)<tab><tab>return [<tab><tab><tab>instance<tab><tab><tab>for instance in self._instances_cache[region]<tab><tab><tab><IF-STMT><tab><tab>]<tab>except Exception as e:<tab><tab>print_exception(f""Failed to get RDS instances: {e}"")<tab><tab>return []",1,"if instance [ ""VpcId"" ] == vpc","if instance [ ""VpcId"" ] == vpc",0.75,100.00000000000004,1.0
def get_and_set_all_disambiguation(self):<tab>all_disambiguations = []<tab>for page in self.pages:<tab><tab>if page.relations.disambiguation_links_norm is not None:<tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links_norm)<tab><tab><IF-STMT><tab><tab><tab>all_disambiguations.extend(page.relations.disambiguation_links)<tab>return set(all_disambiguations),1,if page . relations . disambiguation_links is not None :,if page . relations . disambiguation_links is not None :,0.75,100.00000000000004,1.0
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.options_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""options%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>return res",1,if printElemNumber :,if printElemNumber :,0.5311706625951745,1e-10,1.0
"def pre_save_task(self, task, credentials, verrors):<tab>if task[""attributes""][""encryption""] not in (None, """", ""AES256""):<tab><tab>verrors.add(""encryption"", 'Encryption should be null or ""AES256""')<tab>if not credentials[""attributes""].get(""skip_region"", False):<tab><tab><IF-STMT><tab><tab><tab>response = await self.middleware.run_in_thread(<tab><tab><tab><tab>self._get_client(credentials).get_bucket_location,<tab><tab><tab><tab>Bucket=task[""attributes""][""bucket""],<tab><tab><tab>)<tab><tab><tab>task[""attributes""][""region""] = response[""LocationConstraint""] or ""us-east-1""",0,"if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :","if not task [ ""attributes"" ] . get ( ""region"" ) :",0.1951666347470008,48.61466346464043,0.5661375661375662
"def get_best_config_reward(self):<tab>""""""Returns the best configuration found so far, as well as the reward associated with this best config.""""""<tab>with self.LOCK:<tab><tab><IF-STMT><tab><tab><tab>config_pkl = max(self._results, key=self._results.get)<tab><tab><tab>return pickle.loads(config_pkl), self._results[config_pkl]<tab><tab>else:<tab><tab><tab>return dict(), self._reward_while_pending()",1,if self . _results :,if self . _results :,0.75,100.00000000000004,1.0
"def parse_setup_cfg(self):<tab># type: () -> Dict[STRING_TYPE, Any]<tab>if self.setup_cfg is not None and self.setup_cfg.exists():<tab><tab>contents = self.setup_cfg.read_text()<tab><tab>base_dir = self.setup_cfg.absolute().parent.as_posix()<tab><tab>try:<tab><tab><tab>parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix())<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>contents = self.setup_cfg.read_bytes()<tab><tab><tab>parsed = parse_setup_cfg(contents, base_dir)<tab><tab>if not parsed:<tab><tab><tab>return {}<tab><tab>return parsed<tab>return {}",0,if six . PY2 :,if self . setup_cfg is not None :,0.1113347933040206,5.522397783539471,0.21875
"def readall(read_fn, sz):<tab>buff = b""""<tab>have = 0<tab>while have < sz:<tab><tab>chunk = yield from read_fn(sz - have)<tab><tab>have += len(chunk)<tab><tab>buff += chunk<tab><tab><IF-STMT><tab><tab><tab>raise TTransportException(<tab><tab><tab><tab>TTransportException.END_OF_FILE, ""End of file reading from transport""<tab><tab><tab>)<tab>return buff",0,if len ( chunk ) == 0 :,if have >= sz :,0.01858685153282265,6.4790667469036025,0.2698412698412698
"def _get_use_previous(<tab>f,):  # TODO Sort and group features for DateOffset with two different temporal values<tab>if isinstance(f, AggregationFeature) and f.use_previous is not None:<tab><tab><IF-STMT><tab><tab><tab>return ("""", -1)<tab><tab>else:<tab><tab><tab>unit = list(f.use_previous.times.keys())[0]<tab><tab><tab>value = f.use_previous.times[unit]<tab><tab><tab>return (unit, value)<tab>else:<tab><tab>return ("""", -1)",0,if len ( f . use_previous . times . keys ( ) ) > 1 :,if f . use_previous . times is None :,0.12168575487576791,32.15921415238046,0.21693121693121692
"def istrue(self):<tab>try:<tab><tab>return self._istrue()<tab>except Exception:<tab><tab>self.exc = sys.exc_info()<tab><tab><IF-STMT><tab><tab><tab>msg = [<tab><tab><tab><tab>"" "" * (self.exc[1].offset + 4) + ""^"",<tab><tab><tab>]<tab><tab><tab>msg.append(""SyntaxError: invalid syntax"")<tab><tab>else:<tab><tab><tab>msg = traceback.format_exception_only(*self.exc[:2])<tab><tab>pytest.fail(<tab><tab><tab>""Error evaluating %r expression\n""<tab><tab><tab>""<tab>%s\n""<tab><tab><tab>""%s"" % (self.name, self.expr, ""\n"".join(msg)),<tab><tab><tab>pytrace=False,<tab><tab>)",0,"if isinstance ( self . exc [ 1 ] , SyntaxError ) :",if len ( self . exc ) == 1 :,0.159023519493098,23.26303536297059,0.6166666666666667
"def wait_for_crm_operation(operation, crm):<tab>""""""Poll for cloud resource manager operation until finished.""""""<tab>logger.info(<tab><tab>""wait_for_crm_operation: ""<tab><tab>""Waiting for operation {} to finish..."".format(operation)<tab>)<tab>for _ in range(MAX_POLLS):<tab><tab>result = crm.operations().get(name=operation[""name""]).execute()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(result[""error""])<tab><tab>if ""done"" in result and result[""done""]:<tab><tab><tab>logger.info(""wait_for_crm_operation: Operation done."")<tab><tab><tab>break<tab><tab>time.sleep(POLL_INTERVAL)<tab>return result",1,"if ""error"" in result :","if ""error"" in result :",0.75,100.00000000000004,1.0
"def cb_blob_detail_from_elem_and_buf(self, elem, buf):<tab>if elem.get(""lang"") != buf.lang:  # multi-lang doc<tab><tab>return ""%s Code in %s"" % (elem.get(""lang""), buf.path)<tab>else:<tab><tab>dir, base = os.path.split(buf.path)<tab><tab><IF-STMT><tab><tab><tab>return ""%s (%s)"" % (base, dir)<tab><tab>else:<tab><tab><tab>return base",1,if dir :,if dir :,0.5311706625951745,1e-10,1.0
"def removedir(self, path):<tab># type: (Text) -> None<tab>_path = self.validatepath(path)<tab>if _path == ""/"":<tab><tab>raise errors.RemoveRootError()<tab>with ftp_errors(self, path):<tab><tab>try:<tab><tab><tab>self.ftp.rmd(_encode(_path, self.ftp.encoding))<tab><tab>except error_perm as error:<tab><tab><tab>code, _ = _parse_ftp_error(error)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.isfile(path):<tab><tab><tab><tab><tab>raise errors.DirectoryExpected(path)<tab><tab><tab><tab>if not self.isempty(path):<tab><tab><tab><tab><tab>raise errors.DirectoryNotEmpty(path)<tab><tab><tab>raise  # pragma: no cover",0,"if code == ""550"" :",if code == 2 :,0.14477865547525276,38.49815007763549,0.7
"def p_clause(self, node, position):<tab>if isinstance(node, Graph):<tab><tab>self.subjectDone(node)<tab><tab><IF-STMT><tab><tab><tab>self.write("" "")<tab><tab>self.write(""{"")<tab><tab>self.depth += 1<tab><tab>serializer = N3Serializer(node, parent=self)<tab><tab>serializer.serialize(self.stream)<tab><tab>self.depth -= 1<tab><tab>self.write(self.indent() + ""}"")<tab><tab>return True<tab>else:<tab><tab>return False",0,if position is OBJECT :,if self . depth > 0 :,0.027969854500399755,7.809849842300637,0.25
"def get_default_shell_info(shell_name=None, settings=None):<tab>if not shell_name:<tab><tab>settings = settings or load_settings(lazy=True)<tab><tab>shell_name = settings.get(""shell"")<tab><tab>if shell_name:<tab><tab><tab>return shell_name, None<tab><tab>shell_path = os.environ.get(""SHELL"")<tab><tab><IF-STMT><tab><tab><tab>shell_name = basepath(shell_path)<tab><tab>else:<tab><tab><tab>shell_name = DEFAULT_SHELL<tab><tab>return shell_name, shell_path<tab>return shell_name, None",1,if shell_path :,if shell_path :,0.5311706625951745,1e-10,1.0
"def GetCategory(self, pidls):<tab>ret = []<tab>for pidl in pidls:<tab><tab># Why don't we just get the size of the PIDL?<tab><tab>val = self.sf.GetDetailsEx(pidl, PKEY_Sample_AreaSize)<tab><tab>val = int(val)  # it probably came in a VT_BSTR variant<tab><tab>if val < 255 // 3:<tab><tab><tab>cid = IDS_SMALL<tab><tab><IF-STMT><tab><tab><tab>cid = IDS_MEDIUM<tab><tab>else:<tab><tab><tab>cid = IDS_LARGE<tab><tab>ret.append(cid)<tab>return ret",0,elif val < 2 * 255 // 3 :,elif val > 255 // 3 :,0.18059066375564298,46.307771619910305,0.48148148148148145
"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab>if item[0]:<tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab>elif item[1]:<tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab>elif item[2]:<tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab><IF-STMT><tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",1,elif item [ 3 ] :,elif item [ 3 ] :,0.75,100.00000000000004,1.0
"def add_package_declarations(generated_root_path):<tab>file_names = os.listdir(generated_root_path)<tab>for file_name in file_names:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>full_name = os.path.join(generated_root_path, file_name)<tab><tab>add_package(full_name)",0,"if not file_name . endswith ( "".java"" ) :","if file_name . endswith ( "".py"" ) :",0.1884566599936256,63.436083375358535,0.4807692307692308
"def _call_with_retry(out, retry, retry_wait, method, *args, **kwargs):<tab>for counter in range(retry + 1):<tab><tab>try:<tab><tab><tab>return method(*args, **kwargs)<tab><tab>except (<tab><tab><tab>NotFoundException,<tab><tab><tab>ForbiddenException,<tab><tab><tab>AuthenticationException,<tab><tab><tab>RequestErrorException,<tab><tab>):<tab><tab><tab>raise<tab><tab>except ConanException as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>if out:<tab><tab><tab><tab><tab>out.error(exc)<tab><tab><tab><tab><tab>out.info(""Waiting %d seconds to retry..."" % retry_wait)<tab><tab><tab><tab>time.sleep(retry_wait)",0,if counter == retry :,if counter >= retry_wait :,0.31497877230811644,16.515821590069027,0.7
"def to_wburl_str(<tab>url, type=BaseWbUrl.LATEST_REPLAY, mod="""", timestamp="""", end_timestamp=""""):<tab>if WbUrl.is_query_type(type):<tab><tab>tsmod = """"<tab><tab><IF-STMT><tab><tab><tab>tsmod += mod + ""/""<tab><tab>tsmod += timestamp<tab><tab>tsmod += ""*""<tab><tab>tsmod += end_timestamp<tab><tab>tsmod += ""/"" + url<tab><tab>if type == BaseWbUrl.URL_QUERY:<tab><tab><tab>tsmod += ""*""<tab><tab>return tsmod<tab>else:<tab><tab>tsmod = timestamp + mod<tab><tab>if len(tsmod) > 0:<tab><tab><tab>return tsmod + ""/"" + url<tab><tab>else:<tab><tab><tab>return url",0,if mod :,if len ( tsmod ) > 0 :,0.04422835593777517,1e-10,0.3
"def _configured_ploidy(items):<tab>ploidies = collections.defaultdict(set)<tab>for data in items:<tab><tab>ploidy = dd.get_ploidy(data)<tab><tab><IF-STMT><tab><tab><tab>for k, v in ploidy.items():<tab><tab><tab><tab>ploidies[k].add(v)<tab><tab>else:<tab><tab><tab>ploidies[""default""].add(ploidy)<tab>out = {}<tab>for k, vs in ploidies.items():<tab><tab>assert len(vs) == 1, ""Multiple ploidies set for group calling: %s %s"" % (<tab><tab><tab>k,<tab><tab><tab>list(vs),<tab><tab>)<tab><tab>out[k] = vs.pop()<tab>return out",0,"if isinstance ( ploidy , dict ) :",if ploidy :,0.017267079824235865,1e-10,0.36
"def removeUser(self, username):<tab>hideFromOSD = not constants.SHOW_DIFFERENT_ROOM_OSD<tab>if username in self._users:<tab><tab>user = self._users[username]<tab><tab><IF-STMT><tab><tab><tab>if self.isRoomSame(user.room):<tab><tab><tab><tab>hideFromOSD = not constants.SHOW_SAME_ROOM_OSD<tab>if username in self._users:<tab><tab>self._users.pop(username)<tab><tab>message = getMessage(""left-notification"").format(username)<tab><tab>self.ui.showMessage(message, hideFromOSD)<tab><tab>self._client.lastLeftTime = time.time()<tab><tab>self._client.lastLeftUser = username<tab>self.userListChange()",1,if user . room :,if user . room :,0.75,100.00000000000004,1.0
"def _thd_cleanup_instance(self):<tab>container_name = self.getContainerName()<tab>instances = self.client.containers(all=1, filters=dict(name=container_name))<tab>for instance in instances:<tab><tab># hyper filtering will match 'hyper12"" if you search for 'hyper1' !<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>self.client.remove_container(instance[""Id""], v=True, force=True)<tab><tab>except NotFound:<tab><tab><tab>pass  # that's a race condition<tab><tab>except docker.errors.APIError as e:<tab><tab><tab>if ""Conflict operation on container"" not in str(e):<tab><tab><tab><tab>raise",0,"if """" . join ( instance [ ""Names"" ] ) . strip ( ""/"" ) != container_name :","if instance [ ""Name"" ] == ""hyper12"" :",0.04445135608355626,6.325560472894975,0.38666666666666666
"def handle_ctcp(self, conn, evt):<tab>args = evt.arguments()<tab>source = evt.source().split(""!"")[0]<tab>if args:<tab><tab>if args[0] == ""VERSION"":<tab><tab><tab>conn.ctcp_reply(source, ""VERSION "" + BOT_VERSION)<tab><tab><IF-STMT><tab><tab><tab>conn.ctcp_reply(source, ""PING"")<tab><tab>elif args[0] == ""CLIENTINFO"":<tab><tab><tab>conn.ctcp_reply(source, ""CLIENTINFO PING VERSION CLIENTINFO"")",1,"elif args [ 0 ] == ""PING"" :","elif args [ 0 ] == ""PING"" :",1.0,100.00000000000004,1.0
"def new_func(self, *args, **kwargs):<tab>obj = self.obj_ref()<tab>attr = self.attr<tab>if obj is not None:<tab><tab>args = tuple(TrackedValue.make(obj, attr, arg) for arg in args)<tab><tab><IF-STMT><tab><tab><tab>kwargs = {<tab><tab><tab><tab>key: TrackedValue.make(obj, attr, value)<tab><tab><tab><tab>for key, value in iteritems(kwargs)<tab><tab><tab>}<tab>result = func(self, *args, **kwargs)<tab>self._changed_()<tab>return result",0,if kwargs :,if kwargs is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def add_doc(target, variables, body_lines):<tab>if isinstance(target, ast.Name):<tab><tab># if it is a variable name add it to the doc<tab><tab>name = target.id<tab><tab><IF-STMT><tab><tab><tab>doc = find_doc_for(target, body_lines)<tab><tab><tab>if doc is not None:<tab><tab><tab><tab>variables[name] = doc<tab>elif isinstance(target, ast.Tuple):<tab><tab># if it is a tuple then iterate the elements<tab><tab># this can happen like this:<tab><tab># a, b = 1, 2<tab><tab>for e in target.elts:<tab><tab><tab>add_doc(e, variables, body_lines)",0,if name not in variables :,if name is not None :,0.30253150069759704,19.304869754804482,0.375
"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout):<tab>try:<tab><tab>if tp == ""write"":<tab><tab><tab>out.write(msg)<tab><tab>elif tp == ""flush"":<tab><tab><tab>out.flush()<tab><tab><IF-STMT><tab><tab><tab>out.write(msg)<tab><tab><tab>out.flush()<tab><tab>elif tp == ""print"":<tab><tab><tab>print(msg, file=out)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported type: "" + tp)<tab>except IOError as e:<tab><tab>logger.critical(""{}: {}"".format(type(e).__name__, ucd(e)))<tab><tab>pass",0,"elif tp == ""write_flush"" :","elif tp == ""write"" :",0.6428720214849399,59.59429410903773,1.0
"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if os.path.islink(p):<tab><tab><tab>continue<tab><tab>if os.path.isdir(p):<tab><tab><tab>res += get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res",0,if skip_file ( fname ) :,if not pth :,0.028546166806593606,6.988198185490689,0.37142857142857144
"def _list_outputs(self):<tab>outputs = super(VolSymm, self)._list_outputs()<tab># Have to manually check for the grid files.<tab>if os.path.exists(outputs[""trans_file""]):<tab><tab><IF-STMT><tab><tab><tab>outputs[""output_grid""] = re.sub(<tab><tab><tab><tab>"".(nlxfm|xfm)$"", ""_grid_0.mnc"", outputs[""trans_file""]<tab><tab><tab>)<tab>return outputs",0,"if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :","if outputs [ ""output_grid"" ] :",0.04845497296232244,5.454673614807691,0.3148148148148148
"def _set_texture(self, texture):<tab>if texture.id is not self._texture.id:<tab><tab>self._group = SpriteGroup(<tab><tab><tab>texture, self._group.blend_src, self._group.blend_dest, self._group.parent<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._vertex_list.tex_coords[:] = texture.tex_coords<tab><tab>else:<tab><tab><tab>self._vertex_list.delete()<tab><tab><tab>self._texture = texture<tab><tab><tab>self._create_vertex_list()<tab>else:<tab><tab>self._vertex_list.tex_coords[:] = texture.tex_coords<tab>self._texture = texture",0,if self . _batch is None :,if self . _vertex_list is None :,0.3884893899276739,37.99178428257963,1.0
"def got_result(result):<tab>deployment = self.persistence_service.get()<tab>for node in deployment.nodes:<tab><tab><IF-STMT><tab><tab><tab>dataset_ids = [<tab><tab><tab><tab>(m.dataset.deleted, m.dataset.dataset_id)<tab><tab><tab><tab>for m in node.manifestations.values()<tab><tab><tab>]<tab><tab><tab>self.assertIn((True, expected_dataset_id), dataset_ids)<tab><tab><tab>break<tab>else:<tab><tab>self.fail(""Node not found. {}"".format(node.uuid))",0,"if same_node ( node , origin ) :",if node . uuid == result . uuid :,0.01809616860937894,5.522397783539471,0.4666666666666666
"def check_result(result, func, arguments):<tab>if check_warning(result) and (result.value != ReturnCode.WARN_NODATA):<tab><tab>log.warning(UcanWarning(result, func, arguments))<tab>elif check_error(result):<tab><tab><IF-STMT><tab><tab><tab>raise UcanCmdError(result, func, arguments)<tab><tab>else:<tab><tab><tab>raise UcanError(result, func, arguments)<tab>return result",0,if check_error_cmd ( result ) :,if result . value == ReturnCode . EINVAL :,0.02250085252380211,5.522397783539471,0.4545454545454546
"def _compress_and_sort_bdg_files(out_dir, data):<tab>for fn in glob.glob(os.path.join(out_dir, ""*bdg"")):<tab><tab>out_file = fn + "".gz""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>bedtools = config_utils.get_program(""bedtools"", data)<tab><tab>with file_transaction(out_file) as tx_out_file:<tab><tab><tab>cmd = f""sort -k1,1 -k2,2n {fn} | bgzip -c > {tx_out_file}""<tab><tab><tab>message = f""Compressing and sorting {fn}.""<tab><tab><tab>do.run(cmd, message)",0,if utils . file_exists ( out_file ) :,if not os . path . isfile ( out_file ) :,0.16311705995863668,40.89601472043678,0.2571428571428572
"def kill_members(members, sig, hosts=nodes):<tab>for member in sorted(members):<tab><tab>try:<tab><tab><tab>if ha_tools_debug:<tab><tab><tab><tab>print(""killing %s"" % member)<tab><tab><tab>proc = hosts[member][""proc""]<tab><tab><tab># Not sure if cygwin makes sense here...<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.kill(proc.pid, signal.CTRL_C_EVENT)<tab><tab><tab>else:<tab><tab><tab><tab>os.kill(proc.pid, sig)<tab><tab>except OSError:<tab><tab><tab>if ha_tools_debug:<tab><tab><tab><tab>print(""%s already dead?"" % member)",0,"if sys . platform in ( ""win32"" , ""cygwin"" ) :",if proc . is_alive ( ) :,0.025832773087462534,6.155947438501932,0.3125
"def get_top_level_stats(self):<tab>for func, (cc, nc, tt, ct, callers) in self.stats.items():<tab><tab>self.total_calls += nc<tab><tab>self.prim_calls += cc<tab><tab>self.total_tt += tt<tab><tab><IF-STMT><tab><tab><tab>self.top_level[func] = None<tab><tab>if len(func_std_string(func)) > self.max_name_len:<tab><tab><tab>self.max_name_len = len(func_std_string(func))",0,"if ( ""jprofile"" , 0 , ""profiler"" ) in callers :",if func not in callers :,0.05117108770825241,7.244320397501573,0.27472527472527475
"def __str__(self):<tab>""""""Only keeps the True values.""""""<tab>result = [""SlicingSpec(""]<tab>if self.entire_dataset:<tab><tab>result.append("" Entire dataset,"")<tab>if self.by_class:<tab><tab>if isinstance(self.by_class, Iterable):<tab><tab><tab>result.append("" Into classes %s,"" % self.by_class)<tab><tab><IF-STMT><tab><tab><tab>result.append("" Up to class %d,"" % self.by_class)<tab><tab>else:<tab><tab><tab>result.append("" By classes,"")<tab>if self.by_percentiles:<tab><tab>result.append("" By percentiles,"")<tab>if self.by_classification_correctness:<tab><tab>result.append("" By classification correctness,"")<tab>result.append("")"")<tab>return ""\n"".join(result)",0,"elif isinstance ( self . by_class , int ) :","elif isinstance ( self . by_class , Iterable ) :",0.44643438394808627,76.91605673134588,0.6666666666666666
"def save_params(self):<tab>if self._save_controller:<tab><tab>if not os.path.exists(self._save_controller):<tab><tab><tab>os.makedirs(self._save_controller)<tab><tab>output_dir = self._save_controller<tab>else:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(""./.rlnas_controller"")<tab><tab>output_dir = ""./.rlnas_controller""<tab>with open(os.path.join(output_dir, ""rlnas.params""), ""wb"") as f:<tab><tab>pickle.dump(self._params_dict, f)<tab>_logger.debug(""Save params done"")",1,"if not os . path . exists ( ""./.rlnas_controller"" ) :","if not os . path . exists ( ""./.rlnas_controller"" ) :",0.75,100.00000000000004,1.0
"def unexport(self, pin):<tab>with self._lock:<tab><tab>self._pin_refs[pin] -= 1<tab><tab><IF-STMT><tab><tab><tab>with io.open(self.path(""unexport""), ""wb"") as f:<tab><tab><tab><tab>f.write(str(pin).encode(""ascii""))",1,if self . _pin_refs [ pin ] == 0 :,if self . _pin_refs [ pin ] == 0 :,0.75,100.00000000000004,1.0
"def emit(self, type, info=None):<tab># Overload emit() to send events to the proxy object at the other end<tab>ev = super().emit(type, info)<tab>if self._has_proxy is True and self._session.status > 0:<tab><tab># implicit: and self._disposed is False:<tab><tab>if type in self.__proxy_properties__:<tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])<tab><tab><IF-STMT><tab><tab><tab>self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",0,elif type in self . __event_types_at_proxy :,elif type in self . __proxy_properties__ :,0.5717294420803809,47.96047369469662,1.0
"def __call__(self, params):<tab>all_errs = {}<tab>for handler in self.handlers:<tab><tab>out_headers, res, errs = handler(params)<tab><tab>all_errs.update(errs)<tab><tab><IF-STMT><tab><tab><tab>return out_headers, res, all_errs<tab>return None, None, all_errs",0,if res is not None :,if out_headers :,0.026485502076288185,1e-10,0.2222222222222222
"def await_test_end(self):<tab>iterations = 0<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>self.log.debug(""Await: iteration limit reached"")<tab><tab><tab>return<tab><tab>status = self.master.get_status()<tab><tab>if status.get(""status"") == ""ENDED"":<tab><tab><tab>return<tab><tab>iterations += 1<tab><tab>time.sleep(1.0)",0,if iterations > 100 :,ifiterations > self . max_iterations :,0.025927923124545057,7.267884212102741,0.14285714285714285
"def _load(self, path: str):<tab>ds = DataSet()<tab>with open(path, ""r"", encoding=""utf-8"") as f:<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts = line.split(""\t"")<tab><tab><tab><tab>raw_words1 = parts[1]<tab><tab><tab><tab>raw_words2 = parts[2]<tab><tab><tab><tab>target = parts[0]<tab><tab><tab><tab>if raw_words1 and raw_words2 and target:<tab><tab><tab><tab><tab>ds.append(<tab><tab><tab><tab><tab><tab>Instance(<tab><tab><tab><tab><tab><tab><tab>raw_words1=raw_words1, raw_words2=raw_words2, target=target<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>)<tab>return ds",1,if line :,if line :,0.5311706625951745,1e-10,1.0
"def avatar_delete(event_id, speaker_id):<tab>if request.method == ""DELETE"":<tab><tab>speaker = (<tab><tab><tab>DataGetter.get_speakers(event_id)<tab><tab><tab>.filter_by(user_id=login.current_user.id, id=speaker_id)<tab><tab><tab>.first()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>speaker.photo = """"<tab><tab><tab>speaker.small = """"<tab><tab><tab>speaker.thumbnail = """"<tab><tab><tab>speaker.icon = """"<tab><tab><tab>save_to_db(speaker)<tab><tab><tab>return jsonify({""status"": ""ok""})<tab><tab>else:<tab><tab><tab>abort(403)",1,if speaker :,if speaker :,0.5311706625951745,1e-10,1.0
"def getline(filename, lineno, *args, **kwargs):<tab>line = py2exe_getline(filename, lineno, *args, **kwargs)<tab>if not line:<tab><tab>try:<tab><tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab><tab>for i, line in enumerate(f):<tab><tab><tab><tab><tab>line = line.decode(""utf-8"")<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>line = """"<tab><tab>except (IOError, OSError):<tab><tab><tab>line = """"<tab>return line",0,if lineno == i + 1 :,if i == lineno :,0.08873874389756245,15.308225934212231,0.37142857142857144
"def write(self, data):<tab>if not isinstance(data, (bytes, bytearray, memoryview)):<tab><tab>raise TypeError(""data argument must be byte-ish (%r)"", type(data))<tab>if not data:<tab><tab>return<tab>if self._conn_lost:<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""socket.send() raised exception."")<tab><tab>self._conn_lost += 1<tab><tab>return<tab>if not self._buffer:<tab><tab>self._loop.add_writer(self._sock_fd, self._write_ready)<tab># Add it to the buffer.<tab>self._buffer.extend(data)<tab>self._maybe_pause_protocol()",0,if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,if self . _loop . get_debug ( ) :,0.1318322516527846,11.518272556484067,0.7307692307692308
"def _get_x_for_y(self, xValue, x, y):<tab># print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y)<tab>if not self.xmlMap:<tab><tab>return 0<tab>x_value = str(xValue)<tab>for anime in self.xmlMap.findall(""anime""):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(anime.get(y, 0))<tab><tab>except ValueError as e:<tab><tab><tab>continue<tab>return 0",0,"if anime . get ( x , False ) == x_value :","if anime . get ( x , 0 ) == x_value :",0.3684795558138385,80.03203203845001,0.7142857142857143
"def _RewriteModinfo(<tab>self,<tab>modinfo,<tab>obj_kernel_version,<tab>this_kernel_version,<tab>info_strings=None,<tab>to_remove=None,):<tab>new_modinfo = """"<tab>for line in modinfo.split(""\x00""):<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>if to_remove and line.split(""="")[0] == to_remove:<tab><tab><tab>continue<tab><tab>if info_strings is not None:<tab><tab><tab>info_strings.add(line.split(""="")[0])<tab><tab><IF-STMT><tab><tab><tab>line = line.replace(obj_kernel_version, this_kernel_version)<tab><tab>new_modinfo += line + ""\x00""<tab>return new_modinfo",0,"if line . startswith ( ""vermagic"" ) :",if obj_kernel_version in info_strings :,0.01858685153282265,4.456882760699063,0.38181818181818183
"def _score(self, X, y):<tab>for col in self.cols:<tab><tab># Score the column<tab><tab>X[col] = X[col].map(self.mapping[col])<tab><tab># Randomization is meaningful only for training data -> we do it only if y is present<tab><tab><IF-STMT><tab><tab><tab>random_state_generator = check_random_state(self.random_state)<tab><tab><tab>X[col] = X[col] * random_state_generator.normal(<tab><tab><tab><tab>1.0, self.sigma, X[col].shape[0]<tab><tab><tab>)<tab>return X",0,if self . randomized and y is not None :,if y is not None and self . random_state is not None :,0.39726030257134043,30.130404892785695,0.19444444444444445
"def onMouseWheel(self, event):<tab>if self.selectedHuman.isVisible():<tab><tab>zoomOut = event.wheelDelta > 0<tab><tab><IF-STMT><tab><tab><tab>zoomOut = not zoomOut<tab><tab>if event.x is not None:<tab><tab><tab>self.modelCamera.mousePickHumanCenter(event.x, event.y)<tab><tab>if zoomOut:<tab><tab><tab>self.zoomOut()<tab><tab>else:<tab><tab><tab>self.zoomIn()",0,"if self . getSetting ( ""invertMouseWheel"" ) :",if zoomOut :,0.01620058486734747,1e-10,0.38181818181818183
"def prehook(self, emu, op, eip):<tab>if op in self.badops:<tab><tab>emu.stopEmu()<tab><tab>raise v_exc.BadOpBytes(op.va)<tab>if op.mnem in STOS:<tab><tab>if self.arch == ""i386"":<tab><tab><tab>reg = emu.getRegister(envi.archs.i386.REG_EDI)<tab><tab><IF-STMT><tab><tab><tab>reg = emu.getRegister(envi.archs.amd64.REG_RDI)<tab><tab>if self.vw.isValidPointer(reg) and self.vw.getLocation(reg) is None:<tab><tab><tab>self.vw.makePointer(reg, follow=True)",1,"elif self . arch == ""amd64"" :","elif self . arch == ""amd64"" :",1.0,100.00000000000004,1.0
"def callback(actions, form, tablename=None):<tab>if actions:<tab><tab>if tablename and isinstance(actions, dict):<tab><tab><tab>actions = actions.get(tablename, [])<tab><tab><IF-STMT><tab><tab><tab>actions = [actions]<tab><tab>[action(form) for action in actions]",0,"if not isinstance ( actions , ( list , tuple ) ) :","elif isinstance ( actions , list ) :",0.11305433449504623,22.871025343125112,0.109375
"def FetchFn(bigger_than_3_only=None, less_than_7_only=None, even_only=None):<tab>result = []<tab>for i in range(10):<tab><tab># This line introduces a bug.<tab><tab>if bigger_than_3_only and less_than_7_only and i == 4:<tab><tab><tab>continue<tab><tab>if bigger_than_3_only and i <= 3:<tab><tab><tab>continue<tab><tab>if less_than_7_only and i >= 7:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>result.append(i)<tab>return result",1,if even_only and i % 2 != 0 :,if even_only and i % 2 != 0 :,0.75,100.00000000000004,1.0
"def set_trial_values(self, trial_id: int, values: Sequence[float]) -> None:<tab>with self._lock:<tab><tab>cached_trial = self._get_cached_trial(trial_id)<tab><tab><IF-STMT><tab><tab><tab>self._check_trial_is_updatable(cached_trial)<tab><tab><tab>updates = self._get_updates(trial_id)<tab><tab><tab>cached_trial.values = values<tab><tab><tab>updates.values = values<tab><tab><tab>return<tab>self._backend._update_trial(trial_id, values=values)",1,if cached_trial is not None :,if cached_trial is not None :,0.75,100.00000000000004,1.0
"def _get_label_format(self, workunit):<tab>for label, label_format in self.LABEL_FORMATTING.items():<tab><tab>if workunit.has_label(label):<tab><tab><tab>return label_format<tab># Recursively look for a setting to suppress child label formatting.<tab>if workunit.parent:<tab><tab>label_format = self._get_label_format(workunit.parent)<tab><tab>if label_format == LabelFormat.CHILD_DOT:<tab><tab><tab>return LabelFormat.DOT<tab><tab><IF-STMT><tab><tab><tab>return LabelFormat.SUPPRESS<tab>return LabelFormat.FULL",0,if label_format == LabelFormat . CHILD_SUPPRESS :,elif label_format == LabelFormat . SUPPRESS :,0.289081720757637,57.89300674674101,0.37777777777777777
"def open_session(self, app, request):<tab>sid = request.cookies.get(app.session_cookie_name)<tab>if sid:<tab><tab>stored_session = self.cls.objects(sid=sid).first()<tab><tab>if stored_session:<tab><tab><tab>expiration = stored_session.expiration<tab><tab><tab>if not expiration.tzinfo:<tab><tab><tab><tab>expiration = expiration.replace(tzinfo=utc)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return MongoEngineSession(<tab><tab><tab><tab><tab>initial=stored_session.data, sid=stored_session.sid<tab><tab><tab><tab>)<tab>return MongoEngineSession(sid=str(uuid.uuid4()))",0,if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,if expiration :,0.00787716001533043,1e-10,0.34615384615384615
"def _manage_torrent_cache(self):<tab>""""""Carry tracker/peer/file lists over to new torrent list""""""<tab>for torrent in self._torrent_cache:<tab><tab>new_torrent = rtorrentlib.common.find_torrent(torrent.info_hash, self.torrents)<tab><tab><IF-STMT><tab><tab><tab>new_torrent.files = torrent.files<tab><tab><tab>new_torrent.peers = torrent.peers<tab><tab><tab>new_torrent.trackers = torrent.trackers<tab>self._torrent_cache = self.torrents",0,if new_torrent is not None :,if new_torrent :,0.050438393472541504,1e-10,0.3142857142857143
"def _clean_regions(items, region):<tab>""""""Intersect region with target file if it exists""""""<tab>variant_regions = bedutils.population_variant_regions(items, merged=True)<tab>with utils.tmpfile() as tx_out_file:<tab><tab>target = subset_variant_regions(variant_regions, region, tx_out_file, items)<tab><tab>if target:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>target = _load_regions(target)<tab><tab><tab>else:<tab><tab><tab><tab>target = [target]<tab><tab><tab>return target",0,"if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :",if utils . file_exists ( target ) :,0.06216696499995564,10.057285027768634,0.2435897435897436
def _get_stdout(self):<tab>while True:<tab><tab>BUFFER_SIZE = 1000<tab><tab>stdout_buffer = self.kernel.process.GetSTDOUT(BUFFER_SIZE)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>yield stdout_buffer,0,if len ( stdout_buffer ) == 0 :,if not stdout_buffer :,0.019930835999227993,14.919518511396246,0.38181818181818183
"def do_query(data, q):<tab>ret = []<tab>if not q:<tab><tab>return ret<tab>qkey = q[0]<tab>for key, value in iterate(data):<tab><tab>if len(q) == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(value)<tab><tab><tab>elif is_iterable(value):<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab><tab>else:<tab><tab><tab>if not is_iterable(value):<tab><tab><tab><tab>continue<tab><tab><tab>if key == qkey:<tab><tab><tab><tab>ret.extend(do_query(value, q[1:]))<tab><tab><tab>else:<tab><tab><tab><tab>ret.extend(do_query(value, q))<tab>return ret",1,if key == qkey :,if key == qkey :,0.75,100.00000000000004,1.0
"def test_expect_setecho_off(self):<tab>""""""This tests that echo may be toggled off.""""""<tab>p = pexpect.spawn(""cat"", echo=True, timeout=5)<tab>try:<tab><tab>self._expect_echo_toggle(p)<tab>except IOError:<tab><tab><IF-STMT><tab><tab><tab>if hasattr(unittest, ""SkipTest""):<tab><tab><tab><tab>raise unittest.SkipTest(""Not supported on this platform."")<tab><tab><tab>return ""skip""<tab><tab>raise",1,"if sys . platform . lower ( ) . startswith ( ""sunos"" ) :","if sys . platform . lower ( ) . startswith ( ""sunos"" ) :",0.75,100.00000000000004,1.0
"def _resolve_relative_config(dir, config):<tab># Some code shared between Notebook and NotebookInfo<tab># Resolve icon, can be relative<tab>icon = config.get(""icon"")<tab>if icon:<tab><tab><IF-STMT><tab><tab><tab>icon = File(icon)<tab><tab>else:<tab><tab><tab>icon = dir.resolve_file(icon)<tab># Resolve document_root, can also be relative<tab>document_root = config.get(""document_root"")<tab>if document_root:<tab><tab>if zim.fs.isabs(document_root) or not dir:<tab><tab><tab>document_root = Dir(document_root)<tab><tab>else:<tab><tab><tab>document_root = dir.resolve_dir(document_root)<tab>return icon, document_root",0,if zim . fs . isabs ( icon ) or not dir :,if zim . fs . isfile ( icon ) or not dir :,0.6315063136430985,76.11606003349888,0.8
"def _providers(self, descriptor):<tab>res = []<tab>for _md in self.metadata.values():<tab><tab>for ent_id, ent_desc in _md.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ent_id in res:<tab><tab><tab><tab><tab># print(""duplicated entity_id: %s"" % res)<tab><tab><tab><tab><tab>pass<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>res.append(ent_id)<tab>return res",0,if descriptor in ent_desc :,if ent_desc == descriptor :,0.038498786468962445,24.446151121745064,0.7
"def poll_ms(self, timeout=-1):<tab>s = bytearray(self.evbuf)<tab>if timeout >= 0:<tab><tab>deadline = utime.ticks_add(utime.ticks_ms(), timeout)<tab>while True:<tab><tab>n = epoll_wait(self.epfd, s, 1, timeout)<tab><tab>if not os.check_error(n):<tab><tab><tab>break<tab><tab>if timeout >= 0:<tab><tab><tab>timeout = utime.ticks_diff(deadline, utime.ticks_ms())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n = 0<tab><tab><tab><tab>break<tab>res = []<tab>if n > 0:<tab><tab>vals = struct.unpack(epoll_event, s)<tab><tab>res.append((vals[1], vals[0]))<tab>return res",0,if timeout < 0 :,if timeout <= 0 :,0.33141502097923065,37.99178428257963,1.0
"def banned():<tab>if request.endpoint == ""views.themes"":<tab><tab>return<tab>if authed():<tab><tab>user = get_current_user_attrs()<tab><tab>team = get_current_team_attrs()<tab><tab>if user and user.banned:<tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"", error=""You have been banned from this CTF""<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return (<tab><tab><tab><tab>render_template(<tab><tab><tab><tab><tab>""errors/403.html"",<tab><tab><tab><tab><tab>error=""Your team has been banned from this CTF"",<tab><tab><tab><tab>),<tab><tab><tab><tab>403,<tab><tab><tab>)",1,if team and team . banned :,if team and team . banned :,0.75,100.00000000000004,1.0
"def _update_read(self):<tab>""""""Update state when there is read event""""""<tab>try:<tab><tab>msg = bytes(self._sock.recv(4096))<tab><tab>if msg:<tab><tab><tab>self.on_message(msg)<tab><tab><tab>return True<tab><tab># normal close, remote is closed<tab><tab>self.close()<tab>except socket.error as err:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.on_error(err)<tab>return False",0,"if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",if err . args [ 0 ] == EWOULDBLOCK :,0.29219973643531344,32.15921415238046,0.5353535353535354
"def update_topic_attr_as_not(modeladmin, request, queryset, attr):<tab>for topic in queryset:<tab><tab>if attr == ""sticky"":<tab><tab><tab>topic.sticky = not topic.sticky<tab><tab>elif attr == ""closed"":<tab><tab><tab>topic.closed = not topic.closed<tab><tab><IF-STMT><tab><tab><tab>topic.hidden = not topic.hidden<tab><tab>topic.save()",1,"elif attr == ""hidden"" :","elif attr == ""hidden"" :",1.0,100.00000000000004,1.0
"def Startprobe(self, q):<tab>while not self.finished:<tab><tab>try:<tab><tab><tab>sniff(iface=self.interface, count=10, prn=lambda x: q.put(x))<tab><tab>except:<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>break",1,if self . finished :,if self . finished :,0.75,100.00000000000004,1.0
"def _maybe_female(self, path_elements, female, strict):<tab>if female:<tab><tab><IF-STMT><tab><tab><tab>elements = path_elements + [""female""]<tab><tab><tab>try:<tab><tab><tab><tab>return self._get_file(elements, "".png"", strict=strict)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>if strict:<tab><tab><tab><tab><tab>raise<tab><tab>elif strict:<tab><tab><tab>raise ValueError(""Pokemon %s has no gender differences"" % self.species_id)<tab>return self._get_file(path_elements, "".png"", strict=strict)",0,if self . has_gender_differences :,if self .species_id not in path_elements :,0.136202649291725,14.991106946711685,0.55
"def change_args_to_dict(string):<tab>if string is None:<tab><tab>return None<tab>ans = []<tab>strings = string.split(""\n"")<tab>ind = 1<tab>start = 0<tab>while ind <= len(strings):<tab><tab><IF-STMT><tab><tab><tab>ind += 1<tab><tab>else:<tab><tab><tab>if start < ind:<tab><tab><tab><tab>ans.append(""\n"".join(strings[start:ind]))<tab><tab><tab>start = ind<tab><tab><tab>ind += 1<tab>d = {}<tab>for line in ans:<tab><tab>if "":"" in line and len(line) > 0:<tab><tab><tab>lines = line.split("":"")<tab><tab><tab>d[lines[0]] = lines[1].strip()<tab>return d",0,"if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :","if strings [ ind - 1 ] == ""\n"" :",0.028855411021779742,9.451614390129853,0.23076923076923078
"def _send_with_auth(self, req_kwargs, desired_auth, rsession):<tab>if desired_auth.oauth:<tab><tab><IF-STMT><tab><tab><tab>self._oauth_creds.refresh(httplib2.Http())<tab><tab>req_kwargs[""headers""] = req_kwargs.get(""headers"", {})<tab><tab>req_kwargs[""headers""][""Authorization""] = (<tab><tab><tab>""Bearer "" + self._oauth_creds.access_token<tab><tab>)<tab>return rsession.request(**req_kwargs)",0,if self . _oauth_creds . access_token_expired :,if self . _oauth_creds . access_token is None :,0.4050330458634526,77.4403141014203,0.5666666666666667
"def parse_search_response(json_data):<tab>""""""Construct response for any input""""""<tab>if json_data is None:<tab><tab>return {""error"": ""Error parsing empty search engine response""}<tab>try:<tab><tab>return json.loads(json_data)<tab>except json.JSONDecodeError:<tab><tab>logger.exception(""Error parsing search engine response"")<tab><tab>m = re_pre.search(json_data)<tab><tab><IF-STMT><tab><tab><tab>return {""error"": ""Error parsing search engine response""}<tab><tab>error = web.htmlunquote(m.group(1))<tab><tab>solr_error = ""org.apache.lucene.queryParser.ParseException: ""<tab><tab>if error.startswith(solr_error):<tab><tab><tab>error = error[len(solr_error) :]<tab><tab>return {""error"": error}",0,if m is None :,if not m :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def wrapper(*args, **kws):<tab>missing = []<tab>saved = getattr(warnings, ""__warningregistry__"", missing).copy()<tab>try:<tab><tab>return func(*args, **kws)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>del warnings.__warningregistry__<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>warnings.__warningregistry__ = saved",1,if saved is missing :,if saved is missing :,0.75,100.00000000000004,1.0
"def parse_expression(self):<tab>""""""Return string containing command to run.""""""<tab>expression_el = self.root.find(""expression"")<tab>if expression_el is not None:<tab><tab>expression_type = expression_el.get(""type"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Unknown expression type [%s] encountered"" % expression_type<tab><tab><tab>)<tab><tab>return expression_el.text<tab>return None",0,"if expression_type != ""ecma5.1"" :",if expression_type is not None :,0.0574290063711522,28.46946938149361,0.3142857142857143
"def test_geocode():<tab># look for tweets from New York ; the search radius is larger than NYC<tab># so hopefully we'll find one from New York in the first 500?<tab>count = 0<tab>found = False<tab>for tweet in T.search(None, geocode=""40.7484,-73.9857,1mi""):<tab><tab><IF-STMT><tab><tab><tab>found = True<tab><tab><tab>break<tab><tab>if count > 500:<tab><tab><tab>break<tab><tab>count += 1<tab>assert found",0,"if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :","if tweet . get ( ""geocode"" ) . lower ( ) == ""york"" :",0.07133710118956266,23.93655028782605,0.5
"def __init__(self, name: Optional[str] = None, order: int = 0):<tab>if name is None:<tab><tab><IF-STMT><tab><tab><tab>name = ""std_dev""<tab><tab>elif order == 1:<tab><tab><tab>name = ""sample_std_dev""<tab><tab>else:<tab><tab><tab>name = f""std_dev{order})""<tab>super().__init__(name=name, order=order)<tab>self.order = order",1,if order == 0 :,if order == 0 :,0.75,100.00000000000004,1.0
"def __cmp__(self, other):<tab>if isinstance(other, date) or isinstance(other, datetime):<tab><tab>a = self._d.getTime()<tab><tab>b = other._d.getTime()<tab><tab><IF-STMT><tab><tab><tab>return -1<tab><tab>elif a == b:<tab><tab><tab>return 0<tab>else:<tab><tab>raise TypeError(""expected date or datetime object"")<tab>return 1",0,if a < b :,if a > b :,0.08141502097923063,30.213753973567677,1.0
"def run(self):<tab>tid = self.ident<tab>try:<tab><tab>with self._lock:<tab><tab><tab>_GUIS[tid] = self<tab><tab><tab>self._state(True)<tab><tab>self.new_mail_notifications(summarize=True)<tab><tab>loop_count = 0<tab><tab>while self._sock:<tab><tab><tab>loop_count += 1<tab><tab><tab>self._select_sleep(1)  # FIXME: Lengthen this when possible<tab><tab><tab>self.change_state()<tab><tab><tab><IF-STMT><tab><tab><tab><tab># FIXME: This involves a fair number of set operations,<tab><tab><tab><tab>#<tab><tab>should only do this after new mail has arrived.<tab><tab><tab><tab>self.new_mail_notifications()<tab>finally:<tab><tab>del _GUIS[tid]",0,if loop_count % 5 == 0 :,if loop_count == self . _loop_count :,0.04282569298264552,23.90108882452814,0.37777777777777777
"def __cache_dimension_masks(self, *args):<tab># cache masks for each feature map we'll need<tab>if len(self.masks) == 0:<tab><tab>for m1 in args:<tab><tab><tab>batch_size, emb_dim, h, w = m1.size()<tab><tab><tab># make mask<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mask = self.feat_size_w_mask(h, m1)<tab><tab><tab><tab>self.masks[h] = mask",0,if h not in self . masks :,if emb_dim == batch_size :,0.01858685153282265,4.990049701936832,0.20634920634920634
"def __call__(self, *flattened_representation):<tab>unflattened_representation = []<tab>for index, subtree in self.children:<tab><tab><IF-STMT><tab><tab><tab>unflattened_representation.append(flattened_representation[index])<tab><tab>else:<tab><tab><tab>sub_representation = flattened_representation[index]<tab><tab><tab>unflattened_representation.append(subtree(*sub_representation))<tab>return self._cls(*unflattened_representation, **self._kwargs)",1,if subtree is None :,if subtree is None :,0.75,100.00000000000004,1.0
"def click_outside(event):<tab>if event not in d:<tab><tab>x, y, z = self.blockFaceUnderCursor[0]<tab><tab>if y == 0:<tab><tab><tab>y = 64<tab><tab>y += 3<tab><tab>gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z<tab><tab><IF-STMT><tab><tab><tab>d.dismiss(""Goto"")",0,if event . num_clicks == 2 :,"if event == ""Goto"" :",0.044701560545953894,12.862534787413374,0.7222222222222222
"def get_mapped_input_keysequences(self, mode=""global"", prefix=u""""):<tab># get all bindings in this mode<tab>globalmaps, modemaps = self.get_keybindings(mode)<tab>candidates = list(globalmaps.keys()) + list(modemaps.keys())<tab>if prefix is not None:<tab><tab>prefixes = prefix + "" ""<tab><tab>cand = [c for c in candidates if c.startswith(prefixes)]<tab><tab><IF-STMT><tab><tab><tab>candidates = cand + [prefix]<tab><tab>else:<tab><tab><tab>candidates = cand<tab>return candidates",0,if prefix in candidates :,"if prefix is not u"""" :",0.1824290063711522,12.22307556087252,0.42857142857142855
"def _set_length(self, length):<tab>with self._cond:<tab><tab>self._length = length<tab><tab><IF-STMT><tab><tab><tab>self._ready = True<tab><tab><tab>self._cond.notify()<tab><tab><tab>del self._cache[self._job]",0,if self . _index == self . _length :,if self . _length == 0 :,0.15869765835455005,38.03141958086991,0.6666666666666666
"def _pct_encoded_replace_unreserved(mo):<tab>try:<tab><tab>i = int(mo.group(1), 16)<tab><tab><IF-STMT><tab><tab><tab>return chr(i)<tab><tab>else:<tab><tab><tab>return mo.group().upper()<tab>except ValueError:<tab><tab>return mo.group()",0,if _unreserved [ i ] :,if _pct_encoded_unreserved [ i ] :,0.5212518808542342,50.22573937283117,1.0
"def is_open(self):<tab>if self.signup_code:<tab><tab>return True<tab>else:<tab><tab>if self.signup_code_present:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>messages.add_message(<tab><tab><tab><tab><tab>self.request,<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""level""],<tab><tab><tab><tab><tab>self.messages[""invalid_signup_code""][""text""].format(<tab><tab><tab><tab><tab><tab>**{<tab><tab><tab><tab><tab><tab><tab>""code"": self.get_code(),<tab><tab><tab><tab><tab><tab>}<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>)<tab>return settings.ACCOUNT_OPEN_SIGNUP",0,"if self . messages . get ( ""invalid_signup_code"" ) :",if self . get_code ( ) :,0.07093870120674986,13.493219515886366,0.5714285714285714
"def _get_field_value(self, test, key, match):<tab>if test.ver == ofproto_v1_0.OFP_VERSION:<tab><tab>members = inspect.getmembers(match)<tab><tab>for member in members:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>field_value = member[1]<tab><tab><tab>elif member[0] == ""wildcards"":<tab><tab><tab><tab>wildcards = member[1]<tab><tab>if key == ""nw_src"":<tab><tab><tab>field_value = test.nw_src_to_str(wildcards, field_value)<tab><tab>elif key == ""nw_dst"":<tab><tab><tab>field_value = test.nw_dst_to_str(wildcards, field_value)<tab>else:<tab><tab>field_value = match[key]<tab>return field_value",0,if member [ 0 ] == key :,"if member [ 0 ] == ""field"" :",0.41812130587366103,59.00468726392806,0.7777777777777778
"def move_sender_strings_to_sender_model(apps, schema_editor):<tab>sender_model = apps.get_model(""documents"", ""Sender"")<tab>document_model = apps.get_model(""documents"", ""Document"")<tab># Create the sender and log the relationship with the document<tab>for document in document_model.objects.all():<tab><tab><IF-STMT><tab><tab><tab>(<tab><tab><tab><tab>DOCUMENT_SENDER_MAP[document.pk],<tab><tab><tab><tab>created,<tab><tab><tab>) = sender_model.objects.get_or_create(<tab><tab><tab><tab>name=document.sender, defaults={""slug"": slugify(document.sender)}<tab><tab><tab>)",0,if document . sender :,if document . pk in DOCUMENT_SENDER_MAP :,0.2005939911646859,14.991106946711685,0.4761904761904762
"def compute_output_shape(self, input_shape):<tab>if None not in input_shape[1:]:<tab><tab><IF-STMT><tab><tab><tab>total = np.prod(input_shape[2:4]) * self.num_anchors<tab><tab>else:<tab><tab><tab>total = np.prod(input_shape[1:3]) * self.num_anchors<tab><tab>return (input_shape[0], total, 4)<tab>else:<tab><tab>return (input_shape[0], None, 4)",0,"if keras . backend . image_data_format ( ) == ""channels_first"" :",if len ( input_shape ) > 2 :,0.014083696926176809,2.308316689352168,0.3333333333333333
"def decompress(self, value):<tab>if value:<tab><tab>if type(value) == PhoneNumber:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return [<tab><tab><tab><tab><tab>""+%d"" % value.country_code,<tab><tab><tab><tab><tab>national_significant_number(value),<tab><tab><tab><tab>]<tab><tab>else:<tab><tab><tab>return value.split(""."")<tab>return [None, """"]",0,if value . country_code and value . national_number :,if value . country_code :,0.2699356823408008,35.685360466076496,0.625
"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab><IF-STMT><tab><tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab><tab>if self.expr is not None:<tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super(ParseElementEnhance, self).ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",1,if other not in self . ignoreExprs :,if other not in self . ignoreExprs :,0.75,100.00000000000004,1.0
"def mkdir(self, mode=0o777, parents=False, exist_ok=False):<tab>if self._closed:<tab><tab>self._raise_closed()<tab>if not parents:<tab><tab>try:<tab><tab><tab>self._accessor.mkdir(self, mode)<tab><tab>except FileExistsError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab>else:<tab><tab>try:<tab><tab><tab>self._accessor.mkdir(self, mode)<tab><tab>except FileExistsError:<tab><tab><tab>if not exist_ok or not self.is_dir():<tab><tab><tab><tab>raise<tab><tab>except OSError as e:<tab><tab><tab>if e.errno != ENOENT:<tab><tab><tab><tab>raise<tab><tab><tab>self.parent.mkdir(parents=True)<tab><tab><tab>self._accessor.mkdir(self, mode)",1,if not exist_ok or not self . is_dir ( ) :,if not exist_ok or not self . is_dir ( ) :,0.75,100.00000000000004,1.0
"def _mark_lcs(mask, dirs, m, n):<tab>while m != 0 and n != 0:<tab><tab>if dirs[m, n] == ""|"":<tab><tab><tab>m -= 1<tab><tab><tab>n -= 1<tab><tab><tab>mask[m] = 1<tab><tab>elif dirs[m, n] == ""^"":<tab><tab><tab>m -= 1<tab><tab><IF-STMT><tab><tab><tab>n -= 1<tab><tab>else:<tab><tab><tab>raise UnboundLocalError(""Illegal move"")<tab>return mask",0,"elif dirs [ m , n ] == ""<"" :","elif dirs [ m , n ] == ""^"" :",0.6412711450183218,79.10665071754353,1.0
"def clean(self, *args, **kwargs):<tab>data = super().clean(*args, **kwargs)<tab>if isinstance(data, File):<tab><tab>filename = data.name<tab><tab>ext = os.path.splitext(filename)[1]<tab><tab>ext = ext.lower()<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(_(""Filetype not allowed!""))<tab>return data",0,if ext not in self . ext_whitelist :,"if ext not in ( "".py"" , "".py"" ) :",0.29009121125725595,16.94357181593088,0.8181818181818182
"def get_doc_object(obj, what=None):<tab>if what is None:<tab><tab>if inspect.isclass(obj):<tab><tab><tab>what = ""class""<tab><tab><IF-STMT><tab><tab><tab>what = ""module""<tab><tab>elif callable(obj):<tab><tab><tab>what = ""function""<tab><tab>else:<tab><tab><tab>what = ""object""<tab>if what == ""class"":<tab><tab>return SphinxClassDoc(obj, """", func_doc=SphinxFunctionDoc)<tab>elif what in (""function"", ""method""):<tab><tab>return SphinxFunctionDoc(obj, """")<tab>else:<tab><tab>return SphinxDocString(pydoc.getdoc(obj))",1,elif inspect . ismodule ( obj ) :,elif inspect . ismodule ( obj ) :,0.75,100.00000000000004,1.0
"def apply_pssm(val):<tab>if val is not None:<tab><tab>val_c = PSSM_VALUES.get(val, None)<tab><tab><IF-STMT><tab><tab><tab>assert isinstance(<tab><tab><tab><tab>val, tuple(PSSM_VALUES.values())<tab><tab><tab>), ""'store_as' should be one of: %r or an instance of %r not %r"" % (<tab><tab><tab><tab>tuple(PSSM_VALUES.keys()),<tab><tab><tab><tab>tuple(PSSM_VALUES.values()),<tab><tab><tab><tab>val,<tab><tab><tab>)<tab><tab><tab>return val<tab><tab>return val_c()",0,if val_c is None :,if val_c is not None :,0.2721091316413796,59.4603557501361,0.5599999999999999
"def read_postmaster_opts(self):<tab>""""""returns the list of option names/values from postgres.opts, Empty dict if read failed or no file""""""<tab>result = {}<tab>try:<tab><tab>with open(os.path.join(self._postgresql.data_dir, ""postmaster.opts"")) as f:<tab><tab><tab>data = f.read()<tab><tab><tab>for opt in data.split('"" ""'):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>name, val = opt.split(""="", 1)<tab><tab><tab><tab><tab>result[name.strip(""-"")] = val.rstrip('""\n')<tab>except IOError:<tab><tab>logger.exception(""Error when reading postmaster.opts"")<tab>return result",0,"if ""="" in opt and opt . startswith ( ""--"" ) :","if opt . find ( ""="" ) != - 1 :",0.025280259847608906,15.16499358334419,0.23214285714285715
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(r""F5-TrafficShield"", headers.get(HTTP_HEADER.SERVER, """"), re.I)<tab><tab><tab>is not None<tab><tab>)<tab><tab>retval |= (<tab><tab><tab>re.search(r""\AASINFO="", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.5311706625951745,1e-10,1.0
"def on_task_start(self, task, config):<tab>for item in config:<tab><tab>for plugin_name, plugin_config in item.items():<tab><tab><tab>try:<tab><tab><tab><tab>thelist = plugin.get(plugin_name, self).get_list(plugin_config)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>raise PluginError(<tab><tab><tab><tab><tab>""Plugin %s does not support list interface"" % plugin_name<tab><tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise plugin.PluginError(thelist.immutable)",1,if thelist . immutable :,if thelist . immutable :,0.75,100.00000000000004,1.0
"def nq(t):<tab>p = t[0] if (t and t[0] in ""-+"") else """"<tab>t = t[len(p) :]<tab>if t.startswith(""tag:"") or t.startswith(""in:""):<tab><tab>try:<tab><tab><tab>raw_tag = session.config.get_tag(t.split("":"")[1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>t = ""in:%s"" % raw_tag.slug<tab><tab>except (IndexError, KeyError, TypeError):<tab><tab><tab>pass<tab>return p + t",0,if raw_tag and raw_tag . hasattr ( slug ) :,if raw_tag :,0.020477126045913657,1e-10,0.36
"def _recur_strip(s):<tab>if is_str(s):<tab><tab><IF-STMT><tab><tab><tab>return "" "".join(s.strip().split())<tab><tab>else:<tab><tab><tab>return "" "".join(s.strip().split()).replace(bos_token + "" "", """")<tab>else:<tab><tab>s_ = [_recur_strip(si) for si in s]<tab><tab>return _maybe_list_to_array(s_, s)",1,"if bos_token == """" :","if bos_token == """" :",0.75,100.00000000000004,1.0
"def __delitem__(self, key):<tab>""Deleting tag[key] deletes all 'key' attributes for the tag.""<tab>for item in self.attrs:<tab><tab><IF-STMT><tab><tab><tab>self.attrs.remove(item)<tab><tab><tab># We don't break because bad HTML can define the same<tab><tab><tab># attribute multiple times.<tab><tab>self._getAttrMap()<tab><tab>if self.attrMap.has_key(key):<tab><tab><tab>del self.attrMap[key]",0,if item [ 0 ] == key :,"if item . get ( ""key"" ) == key :",0.07806681388336024,22.997519112894437,0.6666666666666666
"def comment_import_help(init_file, out_file):<tab>f_out = open(out_file, ""w"")<tab>output = """"<tab>updated = False<tab>with open(init_file, ""r"") as f_in:<tab><tab>for line in f_in:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>updated = True<tab><tab><tab><tab>line = ""# "" + line<tab><tab><tab>output += line<tab>f_out.write(output)<tab>f_out.close()<tab>return updated",0,"if ""import"" in line and ""_help"" in line and not updated :","if line . startswith ( ""#"" ) :",0.01198879490978343,3.115901613796704,0.1875
"def prepare_text(lines):<tab>out = []<tab>for s in lines.split(""|""):<tab><tab>s = s.strip()<tab><tab><IF-STMT><tab><tab><tab># line beginning with '/' is in italics<tab><tab><tab>s = r""{\i1}%s{\i0}"" % s[1:].strip()<tab><tab>out.append(s)<tab>return ""\\N"".join(out)",1,"if s . startswith ( ""/"" ) :","if s . startswith ( ""/"" ) :",0.75,100.00000000000004,1.0
"def sqlctx(sc):<tab>pytest.importorskip(""pyspark"")<tab>from odo.backends.sparksql import HiveContext<tab>try:<tab><tab>yield HiveContext(sc)<tab>finally:<tab><tab>dbpath = ""metastore_db""<tab><tab>logpath = ""derby.log""<tab><tab><IF-STMT><tab><tab><tab>assert os.path.isdir(dbpath)<tab><tab><tab>shutil.rmtree(dbpath)<tab><tab>if os.path.exists(logpath):<tab><tab><tab>assert os.path.isfile(logpath)<tab><tab><tab>os.remove(logpath)",1,if os . path . exists ( dbpath ) :,if os . path . exists ( dbpath ) :,0.75,100.00000000000004,1.0
"def _user2dict(self, uid):<tab>usdict = None<tab>if uid in self.users:<tab><tab>usdict = self.users[uid]<tab><tab><IF-STMT><tab><tab><tab>infos = self.users_info[uid]<tab><tab><tab>for attr in infos:<tab><tab><tab><tab>usdict[attr[""attr_type""]] = attr[""attr_data""]<tab><tab>usdict[""uid""] = uid<tab>return usdict",0,if uid in self . users_info :,elif uid in self . users_info :,0.4662742315122899,86.33400213704509,0.6666666666666666
"def _validate_options(self):<tab>for option in self.options:<tab><tab># if value type is bool or int, then we know the options is set<tab><tab><IF-STMT><tab><tab><tab>if self.options.required[option] is True and not self.options[option]:<tab><tab><tab><tab>if option == Constants.PASSWORD_CLEAR:<tab><tab><tab><tab><tab>option = ""password"".upper()<tab><tab><tab><tab>raise FrameworkException(<tab><tab><tab><tab><tab>""Value required for the '%s' option."" % (option.upper())<tab><tab><tab><tab>)<tab>return",0,"if not type ( self . options [ option ] ) in [ bool , int ] :","if isinstance ( self . options [ option ] , bool ) and isinstance ( self . options [ option ] , int ) :",0.2835909775887375,28.838945870351704,0.15804597701149425
"def _copy_package_apps(<tab>local_bin_dir: Path, app_paths: List[Path], suffix: str = """") -> None:<tab>for src_unresolved in app_paths:<tab><tab>src = src_unresolved.resolve()<tab><tab>app = src.name<tab><tab>dest = Path(local_bin_dir / add_suffix(app, suffix))<tab><tab><IF-STMT><tab><tab><tab>mkdir(dest.parent)<tab><tab>if dest.exists():<tab><tab><tab>logger.warning(f""{hazard}  Overwriting file {str(dest)} with {str(src)}"")<tab><tab><tab>dest.unlink()<tab><tab>if src.exists():<tab><tab><tab>shutil.copy(src, dest)",0,if not dest . parent . is_dir ( ) :,if dest . exists ( ) :,0.07093870120674986,15.749996500436227,0.32051282051282054
"def truncate_seq_pair(tokens_a, tokens_b, max_length):<tab>""""""Truncates a sequence pair in place to the maximum length.""""""<tab># This is a simple heuristic which will always truncate the longer sequence<tab># one token at a time. This makes more sense than truncating an equal percent<tab># of tokens from each, since if one sequence is very short then each token<tab># that's truncated likely contains more information than a longer sequence.<tab>while True:<tab><tab>total_length = len(tokens_a) + len(tokens_b)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if len(tokens_a) > len(tokens_b):<tab><tab><tab>tokens_a.pop()<tab><tab>else:<tab><tab><tab>tokens_b.pop()",0,if total_length <= max_length :,if total_length > max_length :,0.33141502097923065,53.417359568998464,1.0
"def add_channels(cls, voucher, add_channels):<tab>for add_channel in add_channels:<tab><tab>channel = add_channel[""channel""]<tab><tab>defaults = {""currency"": channel.currency_code}<tab><tab>if ""discount_value"" in add_channel.keys():<tab><tab><tab>defaults[""discount_value""] = add_channel.get(""discount_value"")<tab><tab><IF-STMT><tab><tab><tab>defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None)<tab><tab>models.VoucherChannelListing.objects.update_or_create(<tab><tab><tab>voucher=voucher,<tab><tab><tab>channel=channel,<tab><tab><tab>defaults=defaults,<tab><tab>)",0,"if ""min_amount_spent"" in add_channel . keys ( ) :","if ""min_spent_amount"" in add_channel . keys ( ) :",0.62709085524794,75.98356856515926,1.0
"def services(self, id=None, name=None):<tab>for service_dict in self.service_ls(id=id, name=name):<tab><tab>service_id = service_dict[""ID""]<tab><tab>service_name = service_dict[""NAME""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>task_list = self.service_ps(service_id)<tab><tab>yield DockerService.from_cli(self, service_dict, task_list)",0,if not service_name . startswith ( self . _name_prefix ) :,"if service_name != ""docker"" :",0.012417879185700129,9.739982528168149,0.36470588235294116
"def lll(dirname):<tab>for name in os.listdir(dirname):<tab><tab><IF-STMT><tab><tab><tab>full = os.path.join(dirname, name)<tab><tab><tab>if os.path.islink(full):<tab><tab><tab><tab>print(name, ""->"", os.readlink(full))",0,"if name not in ( os . curdir , os . pardir ) :","if name . endswith ( "".py"" ) :",0.023467448074040373,9.281844047221343,0.30065359477124187
"def convertstore(self, mydict):<tab>targetheader = self.mypofile.header()<tab>targetheader.addnote(""extracted from web2py"", ""developer"")<tab>for source_str in mydict.keys():<tab><tab>target_str = mydict[source_str]<tab><tab><IF-STMT><tab><tab><tab># a convention with new (untranslated) web2py files<tab><tab><tab>target_str = u""""<tab><tab>elif target_str.startswith(u""*** ""):<tab><tab><tab># an older convention<tab><tab><tab>target_str = u""""<tab><tab>pounit = self.convertunit(source_str, target_str)<tab><tab>self.mypofile.addunit(pounit)<tab>return self.mypofile",0,if target_str == source_str :,"if target_str . startswith ( u""*** "" ) :",0.04757349237680735,17.395797375642243,0.6444444444444445
"def __init__(self, **kwargs):<tab>for k, v in kwargs.items():<tab><tab>setattr(self, k, v)<tab>self.attempted_charsets = set()<tab>request = cherrypy.serving.request<tab>if request.handler is not None:<tab><tab># Replace request.handler with self<tab><tab><IF-STMT><tab><tab><tab>cherrypy.log(""Replacing request.handler"", ""TOOLS.ENCODE"")<tab><tab>self.oldhandler = request.handler<tab><tab>request.handler = self",0,if self . debug :,if request . handler != self . oldhandler :,0.1330917421534179,9.980099403873663,0.2571428571428572
"def _fastqc_data_section(self, section_name):<tab>out = []<tab>in_section = False<tab>data_file = os.path.join(self._dir, ""fastqc_data.txt"")<tab>if os.path.exists(data_file):<tab><tab>with open(data_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab>if line.startswith("">>%s"" % section_name):<tab><tab><tab><tab><tab>in_section = True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if line.startswith("">>END""):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab><tab>out.append(line.rstrip(""\r\n""))<tab>return out",0,elif in_section :,if in_section :,0.11293884852539707,1e-10,0.3333333333333333
"def bit_length(n):<tab>try:<tab><tab>return n.bit_length()<tab>except AttributeError:<tab><tab>norm = deflate_long(n, False)<tab><tab>hbyte = byte_ord(norm[0])<tab><tab><IF-STMT><tab><tab><tab>return 1<tab><tab>bitlen = len(norm) * 8<tab><tab>while not (hbyte & 0x80):<tab><tab><tab>hbyte <<= 1<tab><tab><tab>bitlen -= 1<tab><tab>return bitlen",1,if hbyte == 0 :,if hbyte == 0 :,0.75,100.00000000000004,1.0
"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>if i == self._skip - 2:<tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab><IF-STMT><tab><tab><tab>break<tab># Note that the observation on the done=True frame<tab># doesn't matter<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",1,if done :,if done :,0.5311706625951745,1e-10,1.0
"def _sample_translation(reference, max_len):<tab>translation = reference[:]<tab>while np.random.uniform() < 0.8 and 1 < len(translation) < max_len:<tab><tab>trans_len = len(translation)<tab><tab>ind = np.random.randint(trans_len)<tab><tab>action = np.random.choice(actions)<tab><tab><IF-STMT><tab><tab><tab>del translation[ind]<tab><tab>elif action == ""replacement"":<tab><tab><tab>ind_rep = np.random.randint(trans_len)<tab><tab><tab>translation[ind] = translation[ind_rep]<tab><tab>else:<tab><tab><tab>ind_insert = np.random.randint(trans_len)<tab><tab><tab>translation.insert(ind, translation[ind_insert])<tab>return translation",0,"if action == ""deletion"" :","if action == ""delete"" :",0.39477865547525276,59.4603557501361,1.0
"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x):<tab>sign = None<tab>subseq = []<tab>for i in seq:<tab><tab>ki = key(i)<tab><tab>if sign is None:<tab><tab><tab>subseq.append(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab>else:<tab><tab><tab>subseq.append(i)<tab><tab><tab>if sign * ki < -slop:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab><tab><tab>yield subseq<tab><tab><tab><tab>subseq = [i]<tab>if subseq:<tab><tab>yield subseq",0,if ki != 0 :,elif sign * ki > slop :,0.0236109951043748,7.809849842300637,0.12244897959183673
def get_dirlist(_rootdir):<tab>dirlist = []<tab>with os.scandir(_rootdir) as rit:<tab><tab>for entry in rit:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dirlist.append(entry.path)<tab><tab><tab><tab>dirlist += get_dirlist(entry.path)<tab>return dirlist,0,"if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :",if entry . is_dir ( ) :,0.12812790941663804,23.43746816281914,0.2571428571428572
"def __init__(<tab>self,<tab>fixed: MQTTFixedHeader = None,<tab>variable_header: PublishVariableHeader = None,<tab>payload=None,):<tab>if fixed is None:<tab><tab>header = MQTTFixedHeader(PUBLISH, 0x00)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise HBMQTTException(<tab><tab><tab><tab>""Invalid fixed packet type %s for PublishPacket init""<tab><tab><tab><tab>% fixed.packet_type<tab><tab><tab>)<tab><tab>header = fixed<tab>super().__init__(header)<tab>self.variable_header = variable_header<tab>self.payload = payload",1,if fixed . packet_type is not PUBLISH :,if fixed . packet_type is not PUBLISH :,0.75,100.00000000000004,1.0
"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if fname == ""PureMVC_Python_1_0"":<tab><tab><tab>continue<tab><tab>if fname[-4:] == "".pyc"":  # ehmm.. no.<tab><tab><tab>continue<tab><tab>if os.path.isdir(p):<tab><tab><tab>get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res",0,"if fname == ""output"" :",if not fname :,0.03944961859844226,7.733712583165139,0.45
"def reward(self):<tab>""""""Returns a tuple of sum of raw and processed rewards.""""""<tab>raw_rewards, processed_rewards = 0, 0<tab>for ts in self.time_steps:<tab><tab># NOTE: raw_reward and processed_reward are None for the first time-step.<tab><tab><IF-STMT><tab><tab><tab>raw_rewards += ts.raw_reward<tab><tab>if ts.processed_reward is not None:<tab><tab><tab>processed_rewards += ts.processed_reward<tab>return raw_rewards, processed_rewards",1,if ts . raw_reward is not None :,if ts . raw_reward is not None :,0.75,100.00000000000004,1.0
"def _process_file(self, content):<tab>args = []<tab>for line in content.splitlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>args.extend(self._split_option(line))<tab><tab>elif line and not line.startswith(""#""):<tab><tab><tab>args.append(line)<tab>return args",0,"if line . startswith ( ""-"" ) :","if line . startswith ( ""#"" ) :",0.5490406812970063,65.80370064762461,1.0
"def __on_change_button_clicked(self, widget=None):<tab>""""""compute all primary objects and toggle the 'Change' attribute""""""<tab>self.change_status = not self.change_status<tab>for prim_obj, tmp in self.xobjects:<tab><tab>obj_change = self.top.get_object(""%s_change"" % prim_obj)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.change_entries[prim_obj].set_val(self.change_status)<tab><tab>obj_change.set_active(self.change_status)",0,if not obj_change . get_sensitive ( ) :,if obj_change is None :,0.019907917998500824,13.597602315271134,0.38181818181818183
"def aiter_cogs(cls) -> AsyncIterator[Tuple[str, str]]:<tab>yield ""Core"", ""0""<tab>for _dir in data_manager.cog_data_path().iterdir():<tab><tab>fpath = _dir / ""settings.json""<tab><tab>if not fpath.exists():<tab><tab><tab>continue<tab><tab>with fpath.open() as f:<tab><tab><tab>try:<tab><tab><tab><tab>data = json.load(f)<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>cog_name = _dir.stem<tab><tab>for cog_id, inner in data.items():<tab><tab><tab>if not isinstance(inner, dict):<tab><tab><tab><tab>continue<tab><tab><tab>yield cog_name, cog_id",0,"if not isinstance ( data , dict ) :",if not data :,0.030826856959892103,10.88482843823664,0.4666666666666666
"def _verifySubs(self):<tab>for inst in self.subs:<tab><tab>if not isinstance(inst, (_Block, _Instantiator, Cosimulation)):<tab><tab><tab>raise BlockError(_error.ArgType % (self.name,))<tab><tab>if isinstance(inst, (_Block, _Instantiator)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise BlockError(_error.InstanceError % (self.name, inst.callername))",0,if not inst . modctxt :,if inst . callername is not None :,0.046132297882334555,13.888095170058955,0.20833333333333331
"def _is_xml(accepts):<tab>if accepts.startswith(b""application/""):<tab><tab>has_xml = accepts.find(b""xml"")<tab><tab>if has_xml > 0:<tab><tab><tab>semicolon = accepts.find(b"";"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,if semicolon < 0 or has_xml < semicolon :,if has_xml > 0 andsemicolon > 0 :,0.01786335094255824,16.807407519804237,0.3148148148148148
"def _accept_with(cls, orm, target):<tab>if target is orm.mapper:<tab><tab>return mapperlib.Mapper<tab>elif isinstance(target, type):<tab><tab><IF-STMT><tab><tab><tab>return target<tab><tab>else:<tab><tab><tab>mapper = _mapper_or_none(target)<tab><tab><tab>if mapper is not None:<tab><tab><tab><tab>return mapper<tab><tab><tab>else:<tab><tab><tab><tab>return _MapperEventsHold(target)<tab>else:<tab><tab>return target",0,"if issubclass ( target , mapperlib . Mapper ) :",if _mapper_or_none ( target ) :,0.03433764584236603,11.208466750961147,0.2948717948717949
"def _get_font_afm(self, prop):<tab>key = hash(prop)<tab>font = self.afmfontd.get(key)<tab><IF-STMT><tab><tab>fname = findfont(prop, fontext=""afm"")<tab><tab>font = self.afmfontd.get(fname)<tab><tab>if font is None:<tab><tab><tab>font = AFM(file(findfont(prop, fontext=""afm"")))<tab><tab><tab>self.afmfontd[fname] = font<tab><tab>self.afmfontd[key] = font<tab>return font",1,if font is None :,if font is None :,0.75,100.00000000000004,1.0
"def __call__(self, groupby):<tab>normalize_reduction_funcs(self, ndim=groupby.ndim)<tab>df = groupby<tab>while df.op.output_types[0] not in (OutputType.dataframe, OutputType.series):<tab><tab>df = df.inputs[0]<tab>if self.raw_func == ""size"":<tab><tab>self.output_types = [OutputType.series]<tab>else:<tab><tab>self.output_types = (<tab><tab><tab>[OutputType.dataframe]<tab><tab><tab><IF-STMT><tab><tab><tab>else [OutputType.series]<tab><tab>)<tab>if self.output_types[0] == OutputType.dataframe:<tab><tab>return self._call_dataframe(groupby, df)<tab>else:<tab><tab>return self._call_series(groupby, df)",0,if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby,"if self . raw_func == ""size""",0.0517577226397465,4.987920159185045,0.2631578947368421
"def save(self):<tab>if self.preferences.get(ENCRYPT_ON_DISK, False):<tab><tab><IF-STMT><tab><tab><tab>return self.storage.write(<tab><tab><tab><tab>self.to_dict(encrypt_password=self.encryption_password)<tab><tab><tab>)<tab><tab>elif not self.is_locked:<tab><tab><tab>log.warning(<tab><tab><tab><tab>""Disk encryption requested but no password available for encryption. ""<tab><tab><tab><tab>""Resetting encryption preferences and saving wallet in an unencrypted state.""<tab><tab><tab>)<tab><tab><tab>self.preferences[ENCRYPT_ON_DISK] = False<tab>return self.storage.write(self.to_dict())",0,if self . encryption_password is not None :,if self . encryption_password :,0.2343345094426703,54.77927682341229,0.4444444444444444
"def isValidDateString(config_param_name, value, valid_value):<tab>try:<tab><tab>if value == ""DD-MM-YYYY"":<tab><tab><tab>return value<tab><tab>day, month, year = value.split(""-"")<tab><tab>if int(day) < 1 or int(day) > 31:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab><IF-STMT><tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>if int(year) < 1900 or int(year) > 2013:<tab><tab><tab>raise DateStringValueError(config_param_name, value)<tab><tab>return value<tab>except Exception:<tab><tab>raise DateStringValueError(config_param_name, value)",0,if int ( month ) < 1 or int ( month ) > 12 :,if not valid_value :,0.005992008575022817,2.153749340017052,0.2125
"def _capture(self, call_name, data=None, **kwargs):<tab>if data is None:<tab><tab>data = self.get_default_context()<tab>else:<tab><tab>default_context = self.get_default_context()<tab><tab><IF-STMT><tab><tab><tab>default_context.update(data)<tab><tab>else:<tab><tab><tab>default_context[""extra""][""extra_data""] = data<tab><tab>data = default_context<tab>client = self.get_sentry_client()<tab>return getattr(client, call_name)(data=data, **kwargs)",1,"if isinstance ( data , dict ) :","if isinstance ( data , dict ) :",0.75,100.00000000000004,1.0
"def check(input, expected_output=None, expected_ffi_error=False):<tab>import _cffi_backend<tab>ffi = _cffi_backend.FFI()<tab>if not expected_ffi_error:<tab><tab>ct = ffi.typeof(input)<tab><tab>assert isinstance(ct, ffi.CType)<tab><tab>assert ct.cname == (expected_output or input)<tab>else:<tab><tab>e = py.test.raises(ffi.error, ffi.typeof, input)<tab><tab><IF-STMT><tab><tab><tab>assert str(e.value) == expected_ffi_error",0,"if isinstance ( expected_ffi_error , str ) :",if e . value is not None :,0.018078277067547346,3.983253478176822,0.1746031746031746
"def run(self):<tab>""""""Process queries from task queue, stop if processor is None.""""""<tab>while True:<tab><tab>try:<tab><tab><tab>processor, iprot, oprot, otrans, callback = self.queue.get()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>processor.process(iprot, oprot)<tab><tab><tab>callback(True, otrans.getvalue())<tab><tab>except Exception:<tab><tab><tab>logging.exception(""Exception while processing request"")<tab><tab><tab>callback(False, """")",1,if processor is None :,if processor is None :,0.75,100.00000000000004,1.0
"def search(self, query):<tab>query = query.strip().lower()<tab>results = []<tab>for provider in SidebarItemProvider.all(self.context):<tab><tab>for item in provider.provide():<tab><tab><tab>if ""url"" in item:<tab><tab><tab><tab>search_source = ""$"".join(<tab><tab><tab><tab><tab>[item.get(""id"", """"), item.get(""name"", """")]<tab><tab><tab><tab>).lower()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>results.append(<tab><tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab><tab>""title"": item[""name""],<tab><tab><tab><tab><tab><tab><tab>""icon"": item[""icon""],<tab><tab><tab><tab><tab><tab><tab>""url"": item[""url""],<tab><tab><tab><tab><tab><tab>}<tab><tab><tab><tab><tab>)<tab>return results",0,if query in search_source :,if search_source == query :,0.038498786468962445,24.446151121745064,0.7
"def handle(self) -> None:<tab>""""""Handles a request ignoring dropped connections.""""""<tab>try:<tab><tab>BaseHTTPRequestHandler.handle(self)<tab>except (ConnectionError, socket.timeout) as e:<tab><tab>self.connection_dropped(e)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab>self.log_error(""SSL error occurred: %s"", e)<tab><tab>else:<tab><tab><tab>raise<tab>if self.server.shutdown_signal:<tab><tab>self.initiate_shutdown()",0,if self . server . ssl_context is not None and is_ssl_error ( e ) :,"if ""SSL error"" in str ( e ) :",0.10882460779437177,10.461191793182621,0.1616161616161616
"def cdn_url_handler(error, endpoint, kwargs):<tab>if endpoint == ""cdn"":<tab><tab>path = kwargs.pop(""path"")<tab><tab># cdn = app.config.get('cdn', 'http://cdn.staticfile.org/')<tab><tab># cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/')<tab><tab>cdn = app.config.get(""cdn"", ""//cdnjscn.b0.upaiyun.com/libs/"")<tab><tab>return urljoin(cdn, path)<tab>else:<tab><tab>exc_type, exc_value, tb = sys.exc_info()<tab><tab><IF-STMT><tab><tab><tab>reraise(exc_type, exc_value, tb)<tab><tab>else:<tab><tab><tab>raise error",0,if exc_value is error :,if exc_type and exc_value :,0.28654024892898816,26.538560855362217,0.36
"def pairs(self):<tab>for path in os.listdir(""src""):<tab><tab>if path == "".svn"":<tab><tab><tab>continue<tab><tab>dep = join(""src"", path)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield dep, join(build_dir, path)",0,if isdir ( dep ) :,if not os . path . isdir ( dep ) :,0.2906190889391025,36.72056269893591,0.25274725274725274
"def get_condition(self):<tab>""""""Return the condition element's name.""""""<tab>for child in self.xml:<tab><tab><IF-STMT><tab><tab><tab>cond = child.tag.split(""}"", 1)[-1]<tab><tab><tab>if cond in self.conditions:<tab><tab><tab><tab>return cond<tab>return ""not-authorized""",0,"if ""{%s}"" % self . namespace in child . tag :","if ""{%s}"" % child . tag in self . conditions :",0.3445626733703869,58.88018534624091,0.375
"def end(self, tag):<tab># call the appropriate end tag handler<tab>try:<tab><tab>f = self.dispatch[tag]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>return  # unknown tag ?<tab><tab>try:<tab><tab><tab>f = self.dispatch[tag.split("":"")[-1]]<tab><tab>except KeyError:<tab><tab><tab>return  # unknown tag ?<tab>return f(self, """".join(self._data))",1,"if "":"" not in tag :","if "":"" not in tag :",0.75,100.00000000000004,1.0
"def checkIfSessionCodeExists(self, sessionCode):<tab>if self.emrtFile:<tab><tab>sessionsForExperiment = (<tab><tab><tab>self.emrtFile.root.data_collection.session_meta_data.where(<tab><tab><tab><tab>""experiment_id == %d"" % (self.active_experiment_id,)<tab><tab><tab>)<tab><tab>)<tab><tab>sessionCodeMatch = [<tab><tab><tab>sess for sess in sessionsForExperiment if sess[""code""] == sessionCode<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>return False",0,if len ( sessionCodeMatch ) > 0 :,if sessionCodeMatch :,0.017267079824235865,1e-10,0.36
"def save_bytearray(self, obj):<tab>if self.proto < 5:<tab><tab><IF-STMT>  # bytearray is empty<tab><tab><tab>self.save_reduce(bytearray, (), obj=obj)<tab><tab>else:<tab><tab><tab>self.save_reduce(bytearray, (bytes(obj),), obj=obj)<tab><tab>return<tab>n = len(obj)<tab>if n >= self.framer._FRAME_SIZE_TARGET:<tab><tab>self._write_large_bytes(BYTEARRAY8 + pack(""<Q"", n), obj)<tab>else:<tab><tab>self.write(BYTEARRAY8 + pack(""<Q"", n) + obj)",0,if not obj :,if len ( obj ) == 0 :,0.03661176184600709,6.27465531099474,0.48148148148148145
"def _restore_freeze(self, new):<tab>size_change = []<tab>for k, v in six.iteritems(self._freeze_backup):<tab><tab>newv = new.get(k, [])<tab><tab><IF-STMT><tab><tab><tab>size_change.append((self._key_name(k), len(v), len(newv)))<tab>if size_change:<tab><tab>logger.info(<tab><tab><tab>""These collections were modified but restored in {}: {}"".format(<tab><tab><tab><tab>self._name,<tab><tab><tab><tab>"", "".join(map(lambda t: ""({}: {}->{})"".format(*t), size_change)),<tab><tab><tab>)<tab><tab>)<tab>restore_collection(self._freeze_backup)",0,if len ( v ) != len ( newv ) :,if newv :,0.009691017295795237,1e-10,0.36
"def check_options(self, expr, evaluation, options):<tab>for key in options:<tab><tab>if key != ""System`SameTest"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>evaluation.message(""ContainsOnly"", ""optx"", Symbol(key))<tab><tab><tab>else:<tab><tab><tab><tab>return evaluation.message(""ContainsOnly"", ""optx"", Symbol(key), expr)<tab>return None",0,if expr is None :,"if key == ""System`SameTest"" :",0.03412306583404374,4.990049701936832,0.25
"def bundle_directory(self, dirpath):<tab>""""""Bundle all modules/packages in the given directory.""""""<tab>dirpath = os.path.abspath(dirpath)<tab>for nm in os.listdir(dirpath):<tab><tab>nm = _u(nm)<tab><tab>if nm.startswith("".""):<tab><tab><tab>continue<tab><tab>itempath = os.path.join(dirpath, nm)<tab><tab>if os.path.isdir(itempath):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.bundle_package(itempath)<tab><tab>elif nm.endswith("".py""):<tab><tab><tab>self.bundle_module(itempath)",0,"if os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :","if nm . endswith ( "".py"" ) :",0.012143696882022551,7.21025732010192,0.20164609053497942
"def _read_block(self, size):<tab>if self._file_end is not None:<tab><tab>max_size = self._file_end - self._file.tell()<tab><tab><IF-STMT><tab><tab><tab>size = max_size<tab><tab>size = max(min(size, max_size), 0)<tab>return self._file.read(size)",0,if size == - 1 :,if size < 0 :,0.051719732411378776,15.848738972120703,0.6
"def question_mark(self):<tab>""""""Shows help for this command and it's sub-commands.""""""<tab>ret = []<tab>if self.param_help_msg or len(self.subcommands) == 0:<tab><tab>ret.append(self._quick_help())<tab>if len(self.subcommands) > 0:<tab><tab>for k, _ in sorted(self.subcommands.items()):<tab><tab><tab>command_path, param_help, cmd_help = self._instantiate_subcommand(<tab><tab><tab><tab>k<tab><tab><tab>)._quick_help(nested=True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append((command_path, param_help, cmd_help))<tab>return (CommandsResponse(STATUS_OK, self.help_formatter(ret)), self.__class__)",0,if command_path or param_help or cmd_help :,if cmd_help :,0.03885753308224148,1e-10,0.6
"def list_domains(self, r53, **kwargs):<tab>marker = None<tab>domains = []<tab>while True:<tab><tab>if marker:<tab><tab><tab>response = self.wrap_aws_rate_limited_call(r53.list_domains(Marker=marker))<tab><tab>else:<tab><tab><tab>response = self.wrap_aws_rate_limited_call(r53.list_domains)<tab><tab>for domain in response.get(""Domains""):<tab><tab><tab>domains.append(domain)<tab><tab><IF-STMT><tab><tab><tab>marker = response.get(""NextPageMarker"")<tab><tab>else:<tab><tab><tab>break<tab>return domains",0,"if response . get ( ""NextPageMarker"" ) :","if ""NextPageMarker"" in response :",0.020977836961063236,18.938334565508196,0.4
"def writer(stream, items):<tab>sep = """"<tab>for item in items:<tab><tab>stream.write(sep)<tab><tab>sep = "" ""<tab><tab>if not isinstance(item, str):<tab><tab><tab>item = str(item)<tab><tab>if not PY3K:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item = str(item)<tab><tab>stream.write(item)<tab>stream.write(""\n"")",0,"if not isinstance ( item , unicode ) :","if not isinstance ( item , str ) :",0.5818820875411705,66.06328636027612,0.7142857142857143
"def f(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab>view.run_command(""toggle_comment"")<tab><tab><IF-STMT><tab><tab><tab>pt = utils.next_non_white_space_char(view, s.a, white_space="" \t"")<tab><tab>else:<tab><tab><tab>pt = utils.next_non_white_space_char(<tab><tab><tab><tab>view, self.view.line(s.a).a, white_space="" \t""<tab><tab><tab>)<tab><tab>return R(pt, pt)<tab>return s",0,"if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :",if s . a . isspace ( ) :,0.13147495027743875,1.3427683721948058,0.2028985507246377
"def _parse_timestamp(value):<tab>if value:<tab><tab>match = _TIMESTAMP_PATTERN.match(value)<tab><tab><IF-STMT><tab><tab><tab>if match.group(2):<tab><tab><tab><tab>format = ""%Y-%m-%d %H:%M:%S.%f""<tab><tab><tab><tab># use the pattern to truncate the value<tab><tab><tab><tab>value = match.group()<tab><tab><tab>else:<tab><tab><tab><tab>format = ""%Y-%m-%d %H:%M:%S""<tab><tab><tab>value = datetime.datetime.strptime(value, format)<tab><tab>else:<tab><tab><tab>raise Exception('Cannot convert ""{}"" into a datetime'.format(value))<tab>else:<tab><tab>value = None<tab>return value",1,if match :,if match :,0.5311706625951745,1e-10,1.0
"def _compute_log_r(model_trace, guide_trace):<tab>log_r = MultiFrameTensor()<tab>stacks = get_plate_stacks(model_trace)<tab>for name, model_site in model_trace.nodes.items():<tab><tab>if model_site[""type""] == ""sample"":<tab><tab><tab>log_r_term = model_site[""log_prob""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log_r_term = log_r_term - guide_trace.nodes[name][""log_prob""]<tab><tab><tab>log_r.add((stacks[name], log_r_term.detach()))<tab>return log_r",0,"if not model_site [ ""is_observed"" ] :","if guide_trace . nodes [ name ] [ ""log_prob"" ] > 0 :",0.017897410969600198,6.809398432036521,0.31666666666666665
"def get_translationproject(self):<tab>""""""returns the translation project belonging to this directory.""""""<tab>if self.is_language() or self.is_project():<tab><tab>return None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self.translationproject<tab><tab>else:<tab><tab><tab>aux_dir = self<tab><tab><tab>while not aux_dir.is_translationproject() and aux_dir.parent is not None:<tab><tab><tab><tab>aux_dir = aux_dir.parent<tab><tab><tab>return aux_dir.translationproject",0,if self . is_translationproject ( ) :,if self . translationproject is not None :,0.0835778008746384,21.573652645054953,0.35714285714285715
"def get_hosted_content():<tab>try:<tab><tab>scheme, rest = target.split(""://"", 1)<tab><tab>prefix, host_and_port = rest.split("".interactivetool."")<tab><tab>faked_host = rest<tab><tab><IF-STMT><tab><tab><tab>faked_host = rest.split(""/"", 1)[0]<tab><tab>url = ""%s://%s"" % (scheme, host_and_port)<tab><tab>response = requests.get(url, timeout=1, headers={""Host"": faked_host})<tab><tab>return response.text<tab>except Exception as e:<tab><tab>print(e)<tab><tab>return None",0,"if ""/"" in rest :","if prefix == """" :",0.03412306583404374,9.287528999566801,0.36
"def install(self):<tab>log.info(self.openssl_cli)<tab>if not self.has_openssl or self.args.force:<tab><tab><IF-STMT><tab><tab><tab>self._download_src()<tab><tab>else:<tab><tab><tab>log.debug(""Already has src {}"".format(self.src_file))<tab><tab>self._unpack_src()<tab><tab>self._build_src()<tab><tab>self._make_install()<tab>else:<tab><tab>log.info(""Already has installation {}"".format(self.install_dir))<tab># validate installation<tab>version = self.openssl_version<tab>if self.version not in version:<tab><tab>raise ValueError(version)",0,if not self . has_src :,if self . src_file is None :,0.047631794481620526,12.549310621989482,0.30952380952380953
"def format(self, formatstr):<tab>pieces = []<tab>for i, piece in enumerate(re_formatchars.split(force_text(formatstr))):<tab><tab>if i % 2:<tab><tab><tab>pieces.append(force_text(getattr(self, piece)()))<tab><tab><IF-STMT><tab><tab><tab>pieces.append(re_escaped.sub(r""\1"", piece))<tab>return """".join(pieces)",1,elif piece :,elif piece :,0.5143161313935813,1e-10,1.0
"def get_current_events_users(calendar):<tab>now = timezone.make_aware(datetime.now(), timezone.get_current_timezone())<tab>result = []<tab>day = Day(calendar.events.all(), now)<tab>for o in day.get_occurrences():<tab><tab><IF-STMT><tab><tab><tab>usernames = o.event.title.split("","")<tab><tab><tab>for username in usernames:<tab><tab><tab><tab>result.append(User.objects.get(username=username.strip()))<tab>return result",0,if o . start <= now <= o . end :,if o . event :,0.0990973706214538,8.626775877575973,0.347985347985348
"def from_cfn_params(self, cfn_params):<tab>""""""Initialize param value by parsing CFN input only if the scheduler is awsbatch.""""""<tab>cfn_converter = self.definition.get(""cfn_param_mapping"", None)<tab>if cfn_converter and cfn_params:<tab><tab><IF-STMT><tab><tab><tab># we have the same CFN input parameters for both spot_price and spot_bid_percentage<tab><tab><tab># so the CFN input could be a float<tab><tab><tab>self.value = int(float(get_cfn_param(cfn_params, cfn_converter)))<tab>return self",0,"if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :","if get_cfn_param ( cfn_params , cfn_converter ) :",0.21943951390485072,49.777293475833474,1.0
"def onCompletion(self, text):<tab>res = []<tab>for l in text.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>l = l.split("":"")<tab><tab>if len(l) != 2:<tab><tab><tab>continue<tab><tab>res.append([l[0].strip(), l[1].strip()])<tab>self.panel.setChapters(res)",0,if not l :,if len ( l ) < 2 :,0.03661176184600709,7.267884212102741,0.48148148148148145
"def update_ranges(l, i):<tab>for _range in l:<tab><tab># most common case: extend a range<tab><tab>if i == _range[0] - 1:<tab><tab><tab>_range[0] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>_range[1] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab># somewhere outside of range proximity<tab>l.append([i, i])<tab>l.sort(key=lambda x: x[0])",0,elif i == _range [ 1 ] + 1 :,if i == _range [ 1 ] - 1 :,0.33238203515077636,67.0422683816333,0.6
"def process_dollar(token, state, command_line):<tab>if not state.is_range_start_line_parsed:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.start.append(token)<tab>else:<tab><tab>if command_line.line_range.end:<tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.end.append(token)<tab>return parse_line_ref, command_line",1,if command_line . line_range . start :,if command_line . line_range . start :,0.75,100.00000000000004,1.0
"def _parse_description(self, text: str):<tab>result = dict(links=[], versions=[])<tab>for line in text.splitlines():<tab><tab>clean = REX_TAG.sub("""", line.strip())<tab><tab><IF-STMT><tab><tab><tab>result[""severity""] = clean.split()[1]<tab><tab><tab>continue<tab><tab>if clean.startswith(""Affects:""):<tab><tab><tab>result[""name""] = clean.split()[1]<tab><tab><tab>continue<tab><tab>if "" or higher"" in clean:<tab><tab><tab>result[""versions""] = self._get_versions(clean)<tab><tab>result[""links""].extend(REX_LINK.findall(line))<tab>return result",0,"if clean . startswith ( ""Severity:"" ) :","if clean . startswith ( ""severity:"" ) :",0.5490406812970063,70.16879391277372,1.0
"def apply(self, chart, grammar):<tab>for prod in grammar.productions(empty=True):<tab><tab>for index in compat.xrange(chart.num_leaves() + 1):<tab><tab><tab>new_edge = TreeEdge.from_production(prod, index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield new_edge",1,"if chart . insert ( new_edge , ( ) ) :","if chart . insert ( new_edge , ( ) ) :",0.75,100.00000000000004,1.0
"def calc(self, arg):<tab>op = arg[""op""]<tab>if op == ""C"":<tab><tab>self.clear()<tab><tab>return str(self.current)<tab>num = decimal.Decimal(arg[""num""])<tab>if self.op:<tab><tab><IF-STMT><tab><tab><tab>self.current += num<tab><tab>elif self.op == ""-"":<tab><tab><tab>self.current -= num<tab><tab>elif self.op == ""*"":<tab><tab><tab>self.current *= num<tab><tab>elif self.op == ""/"":<tab><tab><tab>self.current /= num<tab><tab>self.op = op<tab>else:<tab><tab>self.op = op<tab><tab>self.current = num<tab>res = str(self.current)<tab>if op == ""="":<tab><tab>self.clear()<tab>return res",1,"if self . op == ""+"" :","if self . op == ""+"" :",0.75,100.00000000000004,1.0
"def cascade(self, event=None):<tab>""""""Cascade all Leo windows.""""""<tab>x, y, delta = 50, 50, 50<tab>for frame in g.app.windowList:<tab><tab>w = frame and frame.top<tab><tab>if w:<tab><tab><tab>r = w.geometry()  # a Qt.Rect<tab><tab><tab># 2011/10/26: Fix bug 823601: cascade-windows fails.<tab><tab><tab>w.setGeometry(QtCore.QRect(x, y, r.width(), r.height()))<tab><tab><tab># Compute the new offsets.<tab><tab><tab>x += 30<tab><tab><tab>y += 30<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = 10 + delta<tab><tab><tab><tab>y = 40 + delta<tab><tab><tab><tab>delta += 10",0,if x > 200 :,if x > 40 + delta :,0.2005939911646859,26.269098944241588,0.4761904761904762
"def redirect(self):<tab>c = self.c<tab>if c.config.getBool(""eval-redirect""):<tab><tab>self.old_stderr = g.stdErrIsRedirected()<tab><tab>self.old_stdout = g.stdOutIsRedirected()<tab><tab><IF-STMT><tab><tab><tab>g.redirectStderr()<tab><tab>if not self.old_stdout:<tab><tab><tab>g.redirectStdout()",1,if not self . old_stderr :,if not self . old_stderr :,0.75,100.00000000000004,1.0
"def on_event(self, c, button, data):<tab>if self.rvGestureGrab.get_reveal_child():<tab><tab><IF-STMT><tab><tab><tab>self.use()<tab><tab>elif button == ""Y"" and data[0] == 0:<tab><tab><tab>self.start_over()",0,"if button == ""A"" and data [ 0 ] == 0 :","if button == ""X"" and data [ 0 ] == 0 :",0.8684795558138385,81.53551038173119,1.0
"def __init__(self, in_feats, out_feats, norm=""both"", bias=True, activation=None):<tab>super(DenseGraphConv, self).__init__()<tab>self._in_feats = in_feats<tab>self._out_feats = out_feats<tab>self._norm = norm<tab>with self.name_scope():<tab><tab>self.weight = self.params.get(<tab><tab><tab>""weight"",<tab><tab><tab>shape=(in_feats, out_feats),<tab><tab><tab>init=mx.init.Xavier(magnitude=math.sqrt(2.0)),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.bias = self.params.get(""bias"", shape=(out_feats,), init=mx.init.Zero())<tab><tab>else:<tab><tab><tab>self.bias = None<tab><tab>self._activation = activation",1,if bias :,if bias :,0.5311706625951745,1e-10,1.0
"def _import_top_module(self, name):<tab># scan sys.path looking for a location in the filesystem that contains<tab># the module, or an Importer object that can import the module.<tab>for item in sys.path:<tab><tab>if isinstance(item, _StringType):<tab><tab><tab>module = self.fs_imp.import_from_dir(item, name)<tab><tab>else:<tab><tab><tab>module = item.import_top(name)<tab><tab><IF-STMT><tab><tab><tab>return module<tab>return None",0,if module :,if module is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def resolver(schemas, f):<tab>if not callable(f):<tab><tab>return<tab>if not hasattr(f, ""accepts""):<tab><tab>return<tab>new_params = []<tab>for p in f.accepts:<tab><tab><IF-STMT><tab><tab><tab>new_params.append(p.resolve(schemas))<tab><tab>else:<tab><tab><tab>raise ResolverError(""Invalid parameter definition {0}"".format(p))<tab># FIXME: for some reason assigning params (f.accepts = new_params) does not work<tab>f.accepts.clear()<tab>f.accepts.extend(new_params)",0,"if isinstance ( p , ( Patch , Ref , Attribute ) ) :","if hasattr ( p , ""resolve"" ) :",0.04618369542066927,13.779555250377765,0.35526315789473684
"def get_files(d):<tab>res = []<tab>for p in glob.glob(os.path.join(d, ""*"")):<tab><tab>if not p:<tab><tab><tab>continue<tab><tab>(pth, fname) = os.path.split(p)<tab><tab>if fname == ""output"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if fname[-4:] == "".pyc"":  # ehmm.. no.<tab><tab><tab>continue<tab><tab>if os.path.isdir(p):<tab><tab><tab>get_dir(p)<tab><tab>else:<tab><tab><tab>res.append(p)<tab>return res",0,"if fname == ""PureMVC_Python_1_0"" :","if fname . endswith ( "".py"" ) :",0.04979441971690225,7.175377580688497,0.7272727272727273
"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True):<tab>if leftname in kerning:<tab><tab>for rightname in kerning[leftname]:<tab><tab><tab>if rightname[0] == ""@"":<tab><tab><tab><tab>for rightname2 in groups[rightname]:<tab><tab><tab><tab><tab>rightnames.add(rightname2)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab># TODO: in this case, pick the one rightname that has the highest<tab><tab><tab><tab><tab><tab># ranking in glyphorder<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>rightnames.add(rightname)",1,if not includeAll :,if not includeAll :,0.75,100.00000000000004,1.0
"def migrate_Stats(self):<tab>for old_obj in self.session_old.query(self.model_from[""Stats""]):<tab><tab><IF-STMT><tab><tab><tab>self.entries_count[""Stats""] -= 1<tab><tab><tab>continue<tab><tab>new_obj = self.model_to[""Stats""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab>if key not in old_obj.__table__.columns:<tab><tab><tab><tab>continue<tab><tab><tab>setattr(new_obj, key, getattr(old_obj, key))<tab><tab>self.session_new.add(new_obj)",0,if not old_obj . summary :,"if old_obj . entries_count [ ""Stats"" ] > 0 :",0.04013352872326966,16.94357181593088,0.38666666666666666
"def _readenv(var, msg):<tab>match = _ENV_VAR_PAT.match(var)<tab>if match and match.groups():<tab><tab>envvar = match.groups()[0]<tab><tab><IF-STMT><tab><tab><tab>value = os.environ[envvar]<tab><tab><tab>if six.PY2:<tab><tab><tab><tab>value = value.decode(""utf8"")<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>raise InvalidConfigException(<tab><tab><tab><tab>""{} - environment variable '{}' not set"".format(msg, var)<tab><tab><tab>)<tab>else:<tab><tab>raise InvalidConfigException(<tab><tab><tab>""{} - environment variable name '{}' does not match pattern '{}'"".format(<tab><tab><tab><tab>msg, var, _ENV_VAR_PAT_STR<tab><tab><tab>)<tab><tab>)",1,if envvar in os . environ :,if envvar in os . environ :,0.75,100.00000000000004,1.0
"def __next__(self):<tab>self._parse_reset()<tab>while True:<tab><tab>try:<tab><tab><tab>line = next(self.input_iter)<tab><tab>except StopIteration:<tab><tab><tab># End of input OR exception<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Error(""newline inside string"")<tab><tab><tab>raise<tab><tab>self.line_num += 1<tab><tab>if ""\0"" in line:<tab><tab><tab>raise Error(""line contains NULL byte"")<tab><tab>pos = 0<tab><tab>while pos < len(line):<tab><tab><tab>pos = self._parse_process_char(line, pos)<tab><tab>self._parse_eol()<tab><tab>if self.state == self.START_RECORD:<tab><tab><tab>break<tab>fields = self.fields<tab>self.fields = []<tab>return fields",0,if len ( self . field ) > 0 :,if self . state == self . START_RECORD :,0.0696648334486985,8.054496384843702,0.27272727272727276
"def createFields(self):<tab>while self.current_size < self.size:<tab><tab>pos = self.stream.searchBytes(<tab><tab><tab>""\0\0\1"", self.current_size, self.current_size + 1024 * 1024 * 8<tab><tab>)  # seek forward by at most 1MB<tab><tab><IF-STMT><tab><tab><tab>padsize = pos - self.current_size<tab><tab><tab>if padsize:<tab><tab><tab><tab>yield PaddingBytes(self, ""pad[]"", padsize // 8)<tab><tab>chunk = Chunk(self, ""chunk[]"")<tab><tab>try:<tab><tab><tab># force chunk to be processed, so that CustomFragments are complete<tab><tab><tab>chunk[""content/data""]<tab><tab>except:<tab><tab><tab>pass<tab><tab>yield chunk",0,if pos is not None :,if pos :,0.050438393472541504,1e-10,0.39999999999999997
"def spew():<tab>seenUID = False<tab>start()<tab>for part in query:<tab><tab>if part.type == ""uid"":<tab><tab><tab>seenUID = True<tab><tab><IF-STMT><tab><tab><tab>yield self.spew_body(part, id, msg, write, flush)<tab><tab>else:<tab><tab><tab>f = getattr(self, ""spew_"" + part.type)<tab><tab><tab>yield f(id, msg, write, flush)<tab><tab>if part is not query[-1]:<tab><tab><tab>space()<tab>if uid and not seenUID:<tab><tab>space()<tab><tab>yield self.spew_uid(id, msg, write, flush)<tab>finish()<tab>flush()",0,"if part . type == ""body"" :",elif part . body :,0.03833350356998184,9.346579571601447,0.3333333333333333
"def _limit_value(key, value, config):<tab>if config[key].get(""upper_limit""):<tab><tab>limit = config[key][""upper_limit""]<tab><tab># auto handle datetime<tab><tab>if isinstance(value, datetime) and isinstance(limit, timedelta):<tab><tab><tab>if config[key][""inverse""] is True:<tab><tab><tab><tab>if (datetime.now() - limit) > value:<tab><tab><tab><tab><tab>value = datetime.now() - limit<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value = datetime.now() + limit<tab><tab>elif value > limit:<tab><tab><tab>value = limit<tab>return value",1,if ( datetime . now ( ) + limit ) < value :,if ( datetime . now ( ) + limit ) < value :,0.75,100.00000000000004,1.0
"def _fix_var_naming(operators, names, mod=""input""):<tab>new_names = []<tab>map = {}<tab>for op in operators:<tab><tab>if mod == ""input"":<tab><tab><tab>iter = op.inputs<tab><tab>else:<tab><tab><tab>iter = op.outputs<tab><tab>for i in iter:<tab><tab><tab>for name in names:<tab><tab><tab><tab>if i.raw_name == name and name not in map:<tab><tab><tab><tab><tab>map[i.raw_name] = i.full_name<tab><tab><IF-STMT><tab><tab><tab>break<tab>for name in names:<tab><tab>new_names.append(map[name])<tab>return new_names",0,if len ( map ) == len ( names ) :,"elif mod == ""output"" :",0.13499725726257544,7.413670083653376,0.1142857142857143
"def traverse(tree):<tab>""""""Generator dropping comment nodes""""""<tab>for entry in tree:<tab><tab># key, values = entry<tab><tab>spaceless = [e for e in entry if not nginxparser.spacey(e)]<tab><tab>if spaceless:<tab><tab><tab>key = spaceless[0]<tab><tab><tab>values = spaceless[1] if len(spaceless) > 1 else None<tab><tab>else:<tab><tab><tab>key = values = """"<tab><tab>if isinstance(key, list):<tab><tab><tab>new = copy.deepcopy(entry)<tab><tab><tab>new[1] = filter_comments(values)<tab><tab><tab>yield new<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield spaceless",0,"if key != ""#"" and spaceless :",if key and values :,0.044701560545953894,9.346579571601447,0.6666666666666666
"def mergeCombiners(self, x, y):<tab>for item in y:<tab><tab><IF-STMT><tab><tab><tab>self.heap.push(x, item)<tab><tab>else:<tab><tab><tab>self.heap.push_pop(x, item)<tab>return x",0,if len ( x ) < self . heap_limit :,"if isinstance ( item , int ) :",0.015805905348207437,4.736913377107212,0.25
"def test_scatter(self, harness: primitive_harness.Harness):<tab>f_name = harness.params[""f_lax""].__name__<tab>dtype = harness.params[""dtype""]<tab>if jtu.device_under_test() == ""tpu"":<tab><tab><IF-STMT><tab><tab><tab>raise unittest.SkipTest(f""TODO: complex {f_name} on TPU fails in JAX"")<tab>self.ConvertAndCompare(harness.dyn_fun, *harness.dyn_args_maker(self.rng()))",0,"if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :","if f_name . endswith ( "".py"" ) or f_name . endswith ( "".py"" ) :",0.00991179842960416,7.758410052509767,0.18421052631578946
"def TryMerge(self, decoder):<tab>while decoder.avail() > 0:<tab><tab>tag = decoder.getVarInt32()<tab><tab>if tag == TAG_BEGIN_ITEM_GROUP:<tab><tab><tab>(type_id, message) = Item.Decode(decoder)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.items[type_id].MergeFrom(Item(message))<tab><tab><tab>else:<tab><tab><tab><tab>self.items[type_id] = Item(message)<tab><tab><tab>continue<tab><tab>if tag == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>decoder.skipData(tag)",1,if type_id in self . items :,if type_id in self . items :,0.75,100.00000000000004,1.0
"def process_continuations(lines):<tab>global continuation_pattern<tab>olines = []<tab>while len(lines) != 0:<tab><tab>line = no_comments(lines[0])<tab><tab>line = line.strip()<tab><tab>lines.pop(0)<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># combine this line with the next line if the next line exists<tab><tab><tab>line = continuation_pattern.sub("""", line)<tab><tab><tab>if len(lines) >= 1:<tab><tab><tab><tab>combined_lines = [line + lines[0]]<tab><tab><tab><tab>lines.pop(0)<tab><tab><tab><tab>lines = combined_lines + lines<tab><tab><tab><tab>continue<tab><tab>olines.append(line)<tab>del lines<tab>return olines",0,if continuation_pattern . search ( line ) :,if continuation_pattern :,0.030705692522937138,1e-10,0.45833333333333337
"def _getListNextPackagesReadyToBuild():<tab>for pkg in Scheduler.listOfPackagesToBuild:<tab><tab>if pkg in Scheduler.listOfPackagesCurrentlyBuilding:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>Scheduler.listOfPackagesNextToBuild.put((-Scheduler._getPriority(pkg), pkg))<tab><tab><tab>Scheduler.logger.debug(""Adding "" + pkg + "" to the schedule list"")",0,if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,if pkg not in Scheduler . listOfPackagesNextToBuild :,0.085905416318389,7.433761660133445,0.3
"def process_signature(app, what, name, obj, options, signature, return_annotation):<tab>if signature:<tab><tab># replace Mock function names<tab><tab>signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature)<tab><tab>signature = re.sub(""tensorflow"", ""tf"", signature)<tab><tab># add scope name to layer signatures:<tab><tab>if hasattr(obj, ""use_scope""):<tab><tab><tab>if obj.use_scope:<tab><tab><tab><tab>signature = signature[0] + ""variable_scope_name, "" + signature[1:]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>signature = signature[0] + ""[variable_scope_name,] "" + signature[1:]<tab># signature: arg list<tab>return signature, return_annotation",0,elif obj . use_scope is None :,elif obj . use_scope :,0.2771771805155177,63.191456189157286,0.55
"def find_distribution_modules(name=__name__, file=__file__):<tab>current_dist_depth = len(name.split(""."")) - 1<tab>current_dist = os.path.join(<tab><tab>os.path.dirname(file), *([os.pardir] * current_dist_depth)<tab>)<tab>abs = os.path.abspath(current_dist)<tab>dist_name = os.path.basename(abs)<tab>for dirpath, dirnames, filenames in os.walk(abs):<tab><tab>package = (dist_name + dirpath[len(abs) :]).replace(""/"", ""."")<tab><tab><IF-STMT><tab><tab><tab>yield package<tab><tab><tab>for filename in filenames:<tab><tab><tab><tab>if filename.endswith("".py"") and filename != ""__init__.py"":<tab><tab><tab><tab><tab>yield ""."".join([package, filename])[:-3]",0,"if ""__init__.py"" in filenames :",if os . path . isfile ( package ) :,0.02442414353888167,4.091092899898373,0.22916666666666669
"def transform_value(i, v, *args):<tab>if i not in converter_functions:<tab><tab># no converter defined on this field, return value as-is<tab><tab>return v<tab>else:<tab><tab>try:<tab><tab><tab>return converter_functions[i](v, *args)<tab><tab>except Exception as e:<tab><tab><tab>if failonerror == ""inline"":<tab><tab><tab><tab>return e<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab><tab><tab>else:<tab><tab><tab><tab>return errorvalue",0,elif failonerror :,"elif failonerror == ""ignore"" :",0.0899445187250913,1e-10,1.0
"def _get_file(self):<tab>if self._file is None:<tab><tab>self._file = SpooledTemporaryFile(<tab><tab><tab>max_size=self._storage.max_memory_size,<tab><tab><tab>suffix="".S3Boto3StorageFile"",<tab><tab><tab>dir=setting(""FILE_UPLOAD_TEMP_DIR""),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._is_dirty = False<tab><tab><tab>self.obj.download_fileobj(self._file)<tab><tab><tab>self._file.seek(0)<tab><tab>if self._storage.gzip and self.obj.content_encoding == ""gzip"":<tab><tab><tab>self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0)<tab>return self._file",0,"if ""r"" in self . _mode :",if self . _is_dirty :,0.044701560545953894,18.190371142855746,0.4722222222222222
"def connect(self, host, port, timeout):<tab>fp = Telnet()<tab>for i in range(50):<tab><tab>try:<tab><tab><tab>fp.sock = socket.create_connection(<tab><tab><tab><tab>(host, int(port)), timeout=int(timeout), source_address=("""", 1023 - i)<tab><tab><tab>)<tab><tab><tab>break<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise e<tab>self.need_handshake = True<tab>return TCP_Connection(fp)",0,"if ( e . errno , e . strerror ) != ( 98 , ""Address already in use"" ) :",if i == 1023 :,0.004395308712033435,0.6282878523720715,0.18275862068965515
"def filtercomments(source):<tab>""""""NOT USED: strips trailing comments and put them at the top.""""""<tab>trailing_comments = []<tab>comment = True<tab>while comment:<tab><tab>if re.search(r""^\s*\/\*"", source):<tab><tab><tab>comment = source[0, source.index(""*/"") + 2]<tab><tab><IF-STMT><tab><tab><tab>comment = re.search(r""^\s*\/\/"", source).group(0)<tab><tab>else:<tab><tab><tab>comment = None<tab><tab>if comment:<tab><tab><tab>source = re.sub(r""^\s+"", """", source[len(comment) :])<tab><tab><tab>trailing_comments.append(comment)<tab>return ""\n"".join(trailing_comments) + source",0,"elif re . search ( r""^\s*\/\/"" , source ) :","elif re . search ( r""^\s*\/*"" , source ) :",0.5790185032381231,80.56920633274976,1.0
"def yview(self, mode=None, value=None, units=None):<tab>if type(value) == str:<tab><tab>value = float(value)<tab>if mode is None:<tab><tab>return self.vsb.get()<tab>elif mode == ""moveto"":<tab><tab>frameHeight = self.innerframe.winfo_reqheight()<tab><tab>self._startY = value * float(frameHeight)<tab>else:  # mode == 'scroll'<tab><tab>clipperHeight = self._clipper.winfo_height()<tab><tab><IF-STMT><tab><tab><tab>jump = int(clipperHeight * self._jfraction)<tab><tab>else:<tab><tab><tab>jump = clipperHeight<tab><tab>self._startY = self._startY + value * jump<tab>self.reposition()",0,"if units == ""units"" :",if self . _jfraction is not None :,0.026407399022921448,5.669791110976001,0.23809523809523808
"def visit(stmt):<tab>""""""Collect information about VTCM buffers and their alignments.""""""<tab>if isinstance(stmt, tvm.tir.AttrStmt):<tab><tab>if stmt.attr_key == ""storage_scope"" and stmt.value == ""local.vtcm"":<tab><tab><tab>vtcm_buffers.append(stmt.node)<tab><tab><IF-STMT><tab><tab><tab>if not stmt.node in alignments:<tab><tab><tab><tab>alignments[stmt.node] = []<tab><tab><tab>alignments[stmt.node].append(stmt.value)",0,"elif stmt . attr_key == ""storage_alignment"" :","elif stmt . attr_key == ""alignments"" :",0.8217294420803809,65.10803637373398,1.0
"def cost(P):<tab># wda loss<tab>loss_b = 0<tab>loss_w = 0<tab>for i, xi in enumerate(xc):<tab><tab>xi = np.dot(xi, P)<tab><tab>for j, xj in enumerate(xc[i:]):<tab><tab><tab>xj = np.dot(xj, P)<tab><tab><tab>M = dist(xi, xj)<tab><tab><tab>G = sinkhorn(wc[i], wc[j + i], M, reg, k)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>loss_w += np.sum(G * M)<tab><tab><tab>else:<tab><tab><tab><tab>loss_b += np.sum(G * M)<tab># loss inversed because minimization<tab>return loss_w / loss_b",0,if j == 0 :,if loss_w :,0.03549272049582243,1e-10,0.41666666666666663
"def __init__(self, comm, in_channels, out_channels, ksize, pad=1):<tab>super(Block, self).__init__()<tab>with self.init_scope():<tab><tab><IF-STMT><tab><tab><tab>self.conv = ParallelConvolution2D(<tab><tab><tab><tab>comm, in_channels, out_channels, ksize, pad=pad, nobias=True<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.conv = chainer.links.Convolution2D(<tab><tab><tab><tab>in_channels, out_channels, ksize, pad=pad, nobias=True<tab><tab><tab>)<tab><tab>self.bn = L.BatchNormalization(out_channels)",0,if comm . size <= in_channels :,"if comm . get_mode ( ) == ""parallel"" :",0.07853087956397244,12.571192676522521,0.7307692307692308
"def halfMultipartScore(nzb_name):<tab>try:<tab><tab>wrong_found = 0<tab><tab>for nr in [1, 2, 3, 4, 5, ""i"", ""ii"", ""iii"", ""iv"", ""v"", ""a"", ""b"", ""c"", ""d"", ""e""]:<tab><tab><tab>for wrong in [""cd"", ""part"", ""dis"", ""disc"", ""dvd""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>wrong_found += 1<tab><tab>if wrong_found == 1:<tab><tab><tab>return -30<tab><tab>return 0<tab>except:<tab><tab>log.error(""Failed doing halfMultipartScore: %s"", traceback.format_exc())<tab>return 0",0,"if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :",if nr == nr and wrong == nzb_name :,0.009997739012278897,7.111803992226879,0.38095238095238093
"def should_include(service):<tab>for f in filt:<tab><tab><IF-STMT><tab><tab><tab>state = filt[f]<tab><tab><tab>containers = project.containers([service.name], stopped=True)<tab><tab><tab>if not has_container_with_state(containers, state):<tab><tab><tab><tab>return False<tab><tab>elif f == ""source"":<tab><tab><tab>source = filt[f]<tab><tab><tab>if source == ""image"" or source == ""build"":<tab><tab><tab><tab>if source not in service.options:<tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>raise UserError(""Invalid value for source filter: %s"" % source)<tab><tab>else:<tab><tab><tab>raise UserError(""Invalid filter: %s"" % f)<tab>return True",0,"if f == ""status"" :","if f == ""state"" :",0.39477865547525276,59.4603557501361,1.0
"def get_blob_type_declaration_sql(self, column):<tab>length = column.get(""length"")<tab>if length:<tab><tab>if length <= self.LENGTH_LIMIT_TINYBLOB:<tab><tab><tab>return ""TINYBLOB""<tab><tab><IF-STMT><tab><tab><tab>return ""BLOB""<tab><tab>if length <= self.LENGTH_LIMIT_MEDIUMBLOB:<tab><tab><tab>return ""MEDIUMBLOB""<tab>return ""LONGBLOB""",1,if length <= self . LENGTH_LIMIT_BLOB :,if length <= self . LENGTH_LIMIT_BLOB :,0.75,100.00000000000004,1.0
"def click_outside(event):<tab>if event not in d:<tab><tab>x, y, z = self.blockFaceUnderCursor[0]<tab><tab><IF-STMT><tab><tab><tab>y = 64<tab><tab>y += 3<tab><tab>gotoPanel.X, gotoPanel.Y, gotoPanel.Z = x, y, z<tab><tab>if event.num_clicks == 2:<tab><tab><tab>d.dismiss(""Goto"")",0,if y == 0 :,if y > 64 :,0.31497877230811644,19.3576934939088,0.6
"def check_related_active_jobs(self, obj):<tab>active_jobs = obj.get_active_jobs()<tab>if len(active_jobs) > 0:<tab><tab>raise ActiveJobConflict(active_jobs)<tab>time_cutoff = now() - dateutil.relativedelta.relativedelta(minutes=1)<tab>recent_jobs = obj._get_related_jobs().filter(finished__gte=time_cutoff)<tab>for unified_job in recent_jobs.get_real_instances():<tab><tab><IF-STMT><tab><tab><tab>raise PermissionDenied(<tab><tab><tab><tab>_(""Related job {} is still processing events."").format(<tab><tab><tab><tab><tab>unified_job.log_format<tab><tab><tab><tab>)<tab><tab><tab>)",0,if not unified_job . event_processing_finished :,if not unified_job . processing_events :,0.5212518808542342,49.02608580435959,1.0
"def run(self):<tab>self.alive = True<tab>if _log.isEnabledFor(_DEBUG):<tab><tab>_log.debug(""started"")<tab>while self.alive:<tab><tab>task = self.queue.get()<tab><tab><IF-STMT><tab><tab><tab>function, args, kwargs = task<tab><tab><tab>assert function<tab><tab><tab>try:<tab><tab><tab><tab>function(*args, **kwargs)<tab><tab><tab>except:<tab><tab><tab><tab>_log.exception(""calling %s"", function)<tab>if _log.isEnabledFor(_DEBUG):<tab><tab>_log.debug(""stopped"")",0,if task :,if task is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def update_sysconfig_file(fn, adjustments, allow_empty=False):<tab>if not adjustments:<tab><tab>return<tab>(exists, contents) = read_sysconfig_file(fn)<tab>updated_am = 0<tab>for (k, v) in adjustments.items():<tab><tab>if v is None:<tab><tab><tab>continue<tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>contents[k] = v<tab><tab>updated_am += 1<tab>if updated_am:<tab><tab>lines = [<tab><tab><tab>str(contents),<tab><tab>]<tab><tab>if not exists:<tab><tab><tab>lines.insert(0, util.make_header())<tab><tab>util.write_file(fn, ""\n"".join(lines) + ""\n"", 0o644)",0,if len ( v ) == 0 and not allow_empty :,if allow_empty and k not in contents :,0.07719009441361999,12.940441182752568,0.2
"def wrapper(  # type: ignore<tab>self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]:<tab>if self.request.path.endswith(""/""):<tab><tab>if self.request.method in (""GET"", ""HEAD""):<tab><tab><tab>uri = self.request.path.rstrip(""/"")<tab><tab><tab><IF-STMT>  # don't try to redirect '/' to ''<tab><tab><tab><tab>if self.request.query:<tab><tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)",1,if uri :,if uri :,0.5311706625951745,1e-10,1.0
def output_handles_from_execution_plan(execution_plan):<tab>output_handles_for_current_run = set()<tab>for step_level in execution_plan.execution_step_levels():<tab><tab>for step in step_level:<tab><tab><tab>for step_input in step.step_inputs:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>output_handles_for_current_run.update(step_input.source_handles)<tab>return output_handles_for_current_run,0,if step_input . source_handles :,if step_input . source_handles is not None :,0.3514988343435983,63.15552371794033,0.34545454545454546
"def _read_value(self, item):<tab>item = _normalize_path(item)<tab>if item in self._store:<tab><tab><IF-STMT><tab><tab><tab>del self._store[item]<tab><tab><tab>raise KeyError(item)<tab><tab>return PathResult(item, value=self._store[item])<tab>elif item in self._children:<tab><tab>return PathResult(item, dir=True)<tab>else:<tab><tab>raise KeyError(item)",0,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,if not self . _children :,0.009368251529820381,1.840235360676039,0.1984126984126984
"def _line_ranges(statements, lines):<tab>""""""Produce a list of ranges for `format_lines`.""""""<tab>statements = sorted(statements)<tab>lines = sorted(lines)<tab>pairs = []<tab>start = None<tab>lidx = 0<tab>for stmt in statements:<tab><tab>if lidx >= len(lines):<tab><tab><tab>break<tab><tab>if stmt == lines[lidx]:<tab><tab><tab>lidx += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = stmt<tab><tab><tab>end = stmt<tab><tab>elif start:<tab><tab><tab>pairs.append((start, end))<tab><tab><tab>start = None<tab>if start:<tab><tab>pairs.append((start, end))<tab>return pairs",0,if not start :,if start is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def _update_help_obj_params(help_obj, data_params, params_equal, attr_key_tups):<tab>loaded_params = []<tab>for param_obj in help_obj.parameters:<tab><tab>loaded_param = next(<tab><tab><tab>(n for n in data_params if params_equal(param_obj, n)), None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>BaseHelpLoader._update_obj_from_data_dict(<tab><tab><tab><tab>param_obj, loaded_param, attr_key_tups<tab><tab><tab>)<tab><tab>loaded_params.append(param_obj)<tab>help_obj.parameters = loaded_params",0,if loaded_param :,if loaded_param is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def __get_ratio(self):<tab>""""""Return splitter ratio of the main splitter.""""""<tab>c = self.c<tab>free_layout = c.free_layout<tab>if free_layout:<tab><tab>w = free_layout.get_main_splitter()<tab><tab><IF-STMT><tab><tab><tab>aList = w.sizes()<tab><tab><tab>if len(aList) == 2:<tab><tab><tab><tab>n1, n2 = aList<tab><tab><tab><tab># 2017/06/07: guard against division by zero.<tab><tab><tab><tab>ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2)<tab><tab><tab><tab>return ratio<tab>return 0.5",1,if w :,if w :,0.5311706625951745,1e-10,1.0
"def _check_required_env_variables(vars):<tab>for var in vars:<tab><tab><IF-STMT><tab><tab><tab>self.tc.logger.error(<tab><tab><tab><tab>""%s is not set. Did you forget to source your build environment setup script?""<tab><tab><tab><tab>% var<tab><tab><tab>)<tab><tab><tab>raise OEQAPreRun",0,if not os . environ . get ( var ) :,"if not getattr ( OEQAPreRun , var , None ) :",0.03199737910750567,11.731175160263996,0.3
"def clean_indexes():<tab>for coll_name in mongo.collection_types.keys():<tab><tab>coll = mongo.get_collection(coll_name)<tab><tab>indexes = coll_indexes[coll_name]<tab><tab>try:<tab><tab><tab>for index in coll.list_indexes():<tab><tab><tab><tab>name = index[""name""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>coll.drop_index(name)<tab><tab>except pymongo.errors.OperationFailure:<tab><tab><tab>pass",0,"if name == ""_id"" or name == ""_id_"" or name in indexes :",if name in indexes :,0.14785210698207035,2.5358201462740055,0.36904761904761907
"def _compare_dirs(self, dir1, dir2):<tab># check that dir1 and dir2 are equivalent,<tab># return the diff<tab>diff = []<tab>for root, dirs, files in os.walk(dir1):<tab><tab>for file_ in files:<tab><tab><tab>path = os.path.join(root, file_)<tab><tab><tab>target_path = os.path.join(dir2, os.path.split(path)[-1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diff.append(file_)<tab>return diff",0,if not os . path . exists ( target_path ) :,"if os . path . samefile ( target_path , dir1 ) :",0.15656340381243428,40.01601601922502,0.25
"def load_state_dict(self, state_dict, strict=True):<tab>""""""Customized load.""""""<tab>self.language_model.load_state_dict(<tab><tab>state_dict[self._language_model_key], strict=strict<tab>)<tab>if mpu.is_pipeline_last_stage():<tab><tab><IF-STMT><tab><tab><tab>self.multichoice_head.load_state_dict(<tab><tab><tab><tab>state_dict[self._multichoice_head_key], strict=strict<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>print_rank_last(<tab><tab><tab><tab>""***WARNING*** could not find {} in the checkpoint, ""<tab><tab><tab><tab>""initializing to random"".format(self._multichoice_head_key)<tab><tab><tab>)",1,if self . _multichoice_head_key in state_dict :,if self . _multichoice_head_key in state_dict :,0.75,100.00000000000004,1.0
"def _parse_timedelta(self, value):<tab>try:<tab><tab>sum = datetime.timedelta()<tab><tab>start = 0<tab><tab>while start < len(value):<tab><tab><tab>m = self._TIMEDELTA_PATTERN.match(value, start)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception()<tab><tab><tab>num = float(m.group(1))<tab><tab><tab>units = m.group(2) or ""seconds""<tab><tab><tab>units = self._TIMEDELTA_ABBREV_DICT.get(units, units)<tab><tab><tab>sum += datetime.timedelta(**{units: num})<tab><tab><tab>start = m.end()<tab><tab>return sum<tab>except:<tab><tab>raise",1,if not m :,if not m :,0.75,100.00000000000004,1.0
"def SetChildMenuBar(self, pChild):<tab>if not pChild:<tab><tab># No Child, set Our menu bar back.<tab><tab>if self._pMyMenuBar:<tab><tab><tab>self.SetMenuBar(self._pMyMenuBar)<tab><tab>else:<tab><tab><tab>self.SetMenuBar(self.GetMenuBar())<tab><tab># Make sure we know our menu bar is in use<tab><tab>self._pMyMenuBar = None<tab>else:<tab><tab>if pChild.GetMenuBar() is None:<tab><tab><tab>return<tab><tab># Do we need to save the current bar?<tab><tab><IF-STMT><tab><tab><tab>self._pMyMenuBar = self.GetMenuBar()<tab><tab>self.SetMenuBar(pChild.GetMenuBar())",1,if self . _pMyMenuBar is None :,if self . _pMyMenuBar is None :,0.75,100.00000000000004,1.0
"def init_weights(self):<tab>""""""Initialize weights of the head.""""""<tab># retinanet_bias_init<tab>bias_cls = bias_init_with_prob(0.01)<tab>normal_init(self.conv_reg, std=0.01)<tab>normal_init(self.conv_centerness, std=0.01)<tab>normal_init(self.conv_cls, std=0.01, bias=bias_cls)<tab>for branch in [self.cls_convs, self.reg_convs]:<tab><tab>for module in branch.modules():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>caffe2_xavier_init(module.conv)",0,"if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :","if hasattr ( module . conv , ""caffe2_xavier"" ) :",0.14264141169938938,22.12006040119351,0.24166666666666664
"def handle_exception(self, e, result):<tab>for k in sorted(result.thrift_spec):<tab><tab>if result.thrift_spec[k][1] == ""success"":<tab><tab><tab>continue<tab><tab>_, exc_name, exc_cls, _ = result.thrift_spec[k]<tab><tab><IF-STMT><tab><tab><tab>setattr(result, exc_name, e)<tab><tab><tab>break<tab>else:<tab><tab>raise",0,"if isinstance ( e , exc_cls ) :","if exc_cls == ""exception"" :",0.019907917998500824,17.747405280050266,0.45833333333333337
"def scripts(self):<tab>application_root = current_app.config.get(""APPLICATION_ROOT"")<tab>subdir = application_root != ""/""<tab>scripts = []<tab>for script in get_registered_scripts():<tab><tab><IF-STMT><tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab><tab>elif subdir:<tab><tab><tab>scripts.append(f'<script defer src=""{application_root}/{script}""></script>')<tab><tab>else:<tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab>return markup(""\n"".join(scripts))",0,"if script . startswith ( ""http"" ) :","if script . startswith ( ""/"" ) :",0.5490406812970063,65.80370064762461,1.0
"def test_related_objects_local(self):<tab>result_key = ""get_all_related_objects_with_model_local""<tab>for model, expected in TEST_RESULTS[result_key].items():<tab><tab>objects = [<tab><tab><tab>(field, self._model(model, field))<tab><tab><tab>for field in model._meta.get_fields(include_parents=False)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>self.assertEqual(<tab><tab><tab>sorted(self._map_related_query_names(objects), key=self.key_name),<tab><tab><tab>sorted(expected, key=self.key_name),<tab><tab>)",0,if field . auto_created and not field . concrete,if not field . rel_to_model,0.09793418984860812,16.14682615668325,0.27777777777777773
"def setTestOutcome(self, event):<tab>""""""Update outcome, exc_info and reason based on configured mappings""""""<tab>if event.exc_info:<tab><tab>ec, ev, tb = event.exc_info<tab><tab>classname = ec.__name__<tab><tab>if classname in self.treatAsFail:<tab><tab><tab>short, long_ = self.labels(classname)<tab><tab><tab>self._setOutcome(event, ""failed"", short, long_)<tab><tab><IF-STMT><tab><tab><tab>short, long_ = self.labels(classname, upper=False)<tab><tab><tab>self._setOutcome(event, ""skipped"", short, ""%s: '%s'"" % (long_, ev), str(ev))",1,elif classname in self . treatAsSkip :,elif classname in self . treatAsSkip :,0.75,100.00000000000004,1.0
"def small_count(v):<tab>if not v:<tab><tab>return 0<tab>z = [<tab><tab>(1000000000, _(""b"")),<tab><tab>(1000000, _(""m"")),<tab><tab>(1000, _(""k"")),<tab>]<tab>v = int(v)<tab>for x, y in z:<tab><tab>o, p = divmod(v, x)<tab><tab>if o:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""%d%s"" % (o, y)<tab><tab><tab>return ""%.1f%s"" % (v / float(x), y)<tab>return v",0,if len ( str ( o ) ) > 2 or not p :,if p :,0.011399193322453306,1e-10,0.18518518518518517
"def __read(self, n):<tab>if self._read_watcher is None:<tab><tab>raise UnsupportedOperation(""read"")<tab>while 1:<tab><tab>try:<tab><tab><tab>return _read(self._fileno, n)<tab><tab>except (IOError, OSError) as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>wait_on_watcher(self._read_watcher, None, None, self.hub)",0,if ex . args [ 0 ] not in ignored_errors :,if ex . errno != errno . EINTR :,0.09477829814934158,12.43423351463457,0.32323232323232326
"def locked(self):<tab>inputfiles = set(self.all_inputfiles())<tab>outputfiles = set(self.all_outputfiles())<tab>if os.path.exists(self._lockdir):<tab><tab>for lockfile in self._locks(""input""):<tab><tab><tab>with open(lockfile) as lock:<tab><tab><tab><tab>for f in lock:<tab><tab><tab><tab><tab>f = f.strip()<tab><tab><tab><tab><tab>if f in outputfiles:<tab><tab><tab><tab><tab><tab>return True<tab><tab>for lockfile in self._locks(""output""):<tab><tab><tab>with open(lockfile) as lock:<tab><tab><tab><tab>for f in lock:<tab><tab><tab><tab><tab>f = f.strip()<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False",0,if f in outputfiles or f in inputfiles :,if f in inputfiles :,0.1935943859967888,37.783911519583654,0.38095238095238093
"def _flags_to_int(flags):<tab># Note, that order does not matter, libev has its own predefined order<tab>if not flags:<tab><tab>return 0<tab>if isinstance(flags, integer_types):<tab><tab>return flags<tab>result = 0<tab>try:<tab><tab><IF-STMT><tab><tab><tab>flags = flags.split("","")<tab><tab>for value in flags:<tab><tab><tab>value = value.strip().lower()<tab><tab><tab>if value:<tab><tab><tab><tab>result |= _flags_str2int[value]<tab>except KeyError as ex:<tab><tab>raise ValueError(<tab><tab><tab>""Invalid backend or flag: %s\nPossible values: %s""<tab><tab><tab>% (ex, "", "".join(sorted(_flags_str2int.keys())))<tab><tab>)<tab>return result",0,"if isinstance ( flags , basestring ) :","if "","" in flags :",0.019907917998500824,8.051153633013374,0.48148148148148145
"def setFg(self, colour, override=False):<tab>if not self.ttkFlag:<tab><tab>self.containerStack[-1][""fg""] = colour<tab><tab>gui.SET_WIDGET_FG(self._getContainerProperty(""container""), colour, override)<tab><tab>for child in self._getContainerProperty(""container"").winfo_children():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>gui.SET_WIDGET_FG(child, colour, override)<tab>else:<tab><tab>gui.trace(""In ttk mode - trying to set FG to %s"", colour)<tab><tab>self.ttkStyle.configure(""TLabel"", foreground=colour)<tab><tab>self.ttkStyle.configure(""TFrame"", foreground=colour)",0,if not self . _isWidgetContainer ( child ) :,if child . fg != colour :,0.017972997699715713,6.082317172853824,0.2857142857142857
"def find_scintilla_constants(f):<tab>lexers = []<tab>states = []<tab>for name in f.order:<tab><tab>v = f.features[name]<tab><tab>if v[""Category""] != ""Deprecated"":<tab><tab><tab>if v[""FeatureType""] == ""val"":<tab><tab><tab><tab>if name.startswith(""SCE_""):<tab><tab><tab><tab><tab>states.append((name, v[""Value""]))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>lexers.append((name, v[""Value""]))<tab>return (lexers, states)",0,"elif name . startswith ( ""SCLEX_"" ) :","elif name . startswith ( ""SCE_"" ) :",0.5473017787506802,70.16879391277372,1.0
"def extract_error_message(response: requests.Response):<tab>if response.content:<tab><tab>try:<tab><tab><tab>content = json.loads(response.content)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return content[""message""]<tab><tab>except:<tab><tab><tab>logging.debug(f""Failed to parse the response content: {response.content}"")<tab>return response.reason",1,"if ""message"" in content :","if ""message"" in content :",0.75,100.00000000000004,1.0
"def canvas_size(self):<tab>""""""Return the width and height for this sprite canvas""""""<tab>width = height = 0<tab>for image in self.images:<tab><tab>x = image.x + image.absolute_width<tab><tab>y = image.y + image.absolute_height<tab><tab><IF-STMT><tab><tab><tab>width = x<tab><tab>if height < y:<tab><tab><tab>height = y<tab>return round_up(width), round_up(height)",1,if width < x :,if width < x :,0.75,100.00000000000004,1.0
"def _load_widgets(self):<tab>logger.info(""Loading plugins preferences widgets"")<tab># Collect the preferences widget for each active plugin<tab>for plugin in self.plugin_manager.get_active_plugins():<tab><tab>plugin_name = plugin.metadata.get(""name"")<tab><tab>try:<tab><tab><tab>preferences_widget = plugin.get_preferences_widget()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._tabs.addTab(preferences_widget, plugin_name)<tab><tab>except Exception as reason:<tab><tab><tab>logger.error(<tab><tab><tab><tab>""Unable to add the preferences widget (%s): %s"", plugin_name, reason<tab><tab><tab>)<tab><tab><tab>continue",0,if preferences_widget :,if preferences_widget is not None :,0.09036476851692153,1e-10,0.3142857142857143
"def clean_objects(string, common_attributes):<tab>""""""Return object and attribute lists""""""<tab>string = clean_string(string)<tab>words = string.split()<tab>if len(words) > 1:<tab><tab>prefix_words_are_adj = True<tab><tab>for att in words[:-1]:<tab><tab><tab>if att not in common_attributes:<tab><tab><tab><tab>prefix_words_are_adj = False<tab><tab><IF-STMT><tab><tab><tab>return words[-1:], words[:-1]<tab><tab>else:<tab><tab><tab>return [string], []<tab>else:<tab><tab>return [string], []",1,if prefix_words_are_adj :,if prefix_words_are_adj :,0.5311706625951745,1e-10,1.0
"def _reader():<tab>if shuffle:<tab><tab>random.shuffle(file_list)<tab>while True:<tab><tab>for fn in file_list:<tab><tab><tab>for line in open(fn, ""r""):<tab><tab><tab><tab>yield self._process_line(line)<tab><tab><IF-STMT><tab><tab><tab>break",0,if not cycle :,if not line :,0.34586199776872373,35.35533905932737,0.6
"def load(weights, model, K, fsz, dil):<tab>index = 0<tab>layers = model.layers<tab>for layer in layers._layers:<tab><tab><IF-STMT><tab><tab><tab>if layer.W.shape == weights[index].shape:<tab><tab><tab><tab>layer.W[:] = weights[index]<tab><tab><tab>else:<tab><tab><tab><tab>layer.W[:] = dilate(weights[index], K, fsz, dil)<tab><tab><tab>index += 1",0,"if hasattr ( layer , ""W"" ) :",if layer . shape is not None :,0.019345087832959386,5.660233915657916,0.19642857142857142
"def upgrade(migrate_engine):<tab>print(__doc__)<tab>metadata.bind = migrate_engine<tab>liftoverjobs = dict()<tab>jobs = context.query(DeferredJob).filter_by(plugin=""LiftOverTransferPlugin"").all()<tab>for job in jobs:<tab><tab><IF-STMT><tab><tab><tab>liftoverjobs[job.params[""parentjob""]] = []<tab><tab>liftoverjobs[job.params[""parentjob""]].append(job.id)<tab>for parent in liftoverjobs:<tab><tab>lifts = liftoverjobs[parent]<tab><tab>deferred = context.query(DeferredJob).filter_by(id=parent).first()<tab><tab>deferred.params[""liftover""] = lifts<tab>context.flush()",0,"if job . params [ ""parentjob"" ] not in liftoverjobs :","if ""parentjob"" not in liftoverjobs :",0.2126844880253655,27.67157888930831,0.2619047619047619
"def get_refs(self, recursive=False):<tab>"""""":see: AbstractExpression.get_refs()""""""<tab>if recursive:<tab><tab>conds_refs = self.refs + sum((c.get_refs(True) for c in self.conds), [])<tab><tab><IF-STMT><tab><tab><tab>conds_refs.extend(self.consequent.get_refs(True))<tab><tab>return conds_refs<tab>else:<tab><tab>return self.refs",0,if self . consequent :,if self .sequent is not None :,0.136202649291725,22.089591134157878,0.38095238095238093
"def _parse(self, engine):<tab>""""""Parse the layer.""""""<tab>if isinstance(self.args, dict):<tab><tab><IF-STMT><tab><tab><tab>self.axis = engine.evaluate(self.args[""axis""], recursive=True)<tab><tab><tab>if not isinstance(self.axis, int):<tab><tab><tab><tab>raise ParsingError('""axis"" must be an integer.')<tab><tab>if ""momentum"" in self.args:<tab><tab><tab>self.momentum = engine.evaluate(self.args[""momentum""], recursive=True)<tab><tab><tab>if not isinstance(self.momentum, (int, float)):<tab><tab><tab><tab>raise ParsingError('""momentum"" must be numeric.')",1,"if ""axis"" in self . args :","if ""axis"" in self . args :",0.75,100.00000000000004,1.0
"def CountMatches(pat, predicate):<tab>num_matches = 0<tab>for i in xrange(256):<tab><tab>b = chr(i)<tab><tab>m = pat.match(b)<tab><tab>left = bool(m)<tab><tab>right = predicate(i)<tab><tab>if left != right:<tab><tab><tab>self.fail(""i = %d, b = %r, match: %s, predicate: %s"" % (i, b, left, right))<tab><tab><IF-STMT><tab><tab><tab>num_matches += 1<tab>return num_matches",1,if m :,if m :,0.5311706625951745,1e-10,1.0
"def __new__(cls, *args, **kwargs):<tab>if len(args) == 1:<tab><tab>if len(kwargs):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""You can either use {} with one positional argument or with keyword arguments, not both."".format(<tab><tab><tab><tab><tab>cls.__name__<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>if not args[0]:<tab><tab><tab>return super().__new__(cls)<tab><tab><IF-STMT><tab><tab><tab>return cls<tab>return super().__new__(cls, *args, **kwargs)",0,"if isinstance ( args [ 0 ] , cls ) :",elif args [ 0 ] == kwargs [ 0 ] :,0.16941475867079037,22.416933501922287,0.125
"def concatenateCharacterTokens(tokens):<tab>pendingCharacters = []<tab>for token in tokens:<tab><tab>type = token[""type""]<tab><tab>if type in (""Characters"", ""SpaceCharacters""):<tab><tab><tab>pendingCharacters.append(token[""data""])<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)}<tab><tab><tab><tab>pendingCharacters = []<tab><tab><tab>yield token<tab>if pendingCharacters:<tab><tab>yield {""type"": ""Characters"", ""data"": """".join(pendingCharacters)}",1,if pendingCharacters :,if pendingCharacters :,0.5311706625951745,1e-10,1.0
"def get_ranges_from_func_set(support_set):<tab>pos_start = 0<tab>pos_end = 0<tab>ranges = []<tab>for pos, func in enumerate(network.function):<tab><tab>if func.type in support_set:<tab><tab><tab>pos_end = pos<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ranges.append((pos_start, pos_end))<tab><tab><tab>pos_start = pos + 1<tab>if pos_end >= pos_start:<tab><tab>ranges.append((pos_start, pos_end))<tab>return ranges",0,if pos_end >= pos_start :,if pos_start >= pos_end :,0.2901714209472326,51.33450480401705,1.0
"def _visit(self, func):<tab>fname = func[0]<tab>if fname in self._flags:<tab><tab><IF-STMT><tab><tab><tab>logger.critical(""Fatal error! network ins not Dag."")<tab><tab><tab>import sys<tab><tab><tab>sys.exit(-1)<tab><tab>else:<tab><tab><tab>return<tab>else:<tab><tab>if fname not in self._flags:<tab><tab><tab>self._flags[fname] = 1<tab><tab>for output in func[3]:<tab><tab><tab>for f in self._orig:<tab><tab><tab><tab>for input in f[2]:<tab><tab><tab><tab><tab>if output == input:<tab><tab><tab><tab><tab><tab>self._visit(f)<tab>self._flags[fname] = 2<tab>self._sorted.insert(0, func)",1,if self . _flags [ fname ] == 1 :,if self . _flags [ fname ] == 1 :,0.75,100.00000000000004,1.0
"def graph_merge_softmax_with_crossentropy_softmax(node):<tab>if node.op == softmax_with_bias:<tab><tab>x, b = node.inputs<tab><tab>for x_client in x.clients:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>big_client = x_client[0]<tab><tab><tab><tab>if big_client in [b_client[0] for b_client in b.clients]:<tab><tab><tab><tab><tab>xx, bb, ll = big_client.inputs<tab><tab><tab><tab><tab>mergeable_client = big_client.op(x, b, ll)<tab><tab><tab><tab><tab>copy_stack_trace(node.outputs[0], mergeable_client[1])<tab><tab><tab><tab><tab>return [mergeable_client[1]]",0,if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias :,"if x_client in [ x , b ] :",0.029205697404072792,9.06473742919665,0.27472527472527475
"def confidence(self):<tab>if self.bbox:<tab><tab># Units are measured in Kilometers<tab><tab>distance = Distance(self.northeast, self.southwest, units=""km"")<tab><tab>for score, maximum in [<tab><tab><tab>(10, 0.25),<tab><tab><tab>(9, 0.5),<tab><tab><tab>(8, 1),<tab><tab><tab>(7, 5),<tab><tab><tab>(6, 7.5),<tab><tab><tab>(5, 10),<tab><tab><tab>(4, 15),<tab><tab><tab>(3, 20),<tab><tab><tab>(2, 25),<tab><tab>]:<tab><tab><tab>if distance < maximum:<tab><tab><tab><tab>return score<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 1<tab># Cannot determine score<tab>return 0",0,if distance >= 25 :,elif distance > maximum :,0.029764206438018782,19.3576934939088,0.3333333333333333
"def OnListEndLabelEdit(self, std, extra):<tab>item = extra[0]<tab>text = item[4]<tab>if text is None:<tab><tab>return<tab>item_id = self.GetItem(item[0])[6]<tab>from bdb import Breakpoint<tab>for bplist in Breakpoint.bplist.itervalues():<tab><tab>for bp in bplist:<tab><tab><tab>if id(bp) == item_id:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>text = None<tab><tab><tab><tab>bp.cond = text<tab><tab><tab><tab>break<tab>self.RespondDebuggerData()",0,"if text . strip ( ) . lower ( ) == ""none"" :",if bp . cond == text :,0.011531715363016518,5.34741036489421,0.2857142857142857
"def _handle_autocomplete_request_for_text(text):<tab>if not hasattr(text, ""autocompleter""):<tab><tab><IF-STMT><tab><tab><tab>if isinstance(text, CodeViewText):<tab><tab><tab><tab>text.autocompleter = Completer(text)<tab><tab><tab>elif isinstance(text, ShellText):<tab><tab><tab><tab>text.autocompleter = ShellCompleter(text)<tab><tab><tab>text.bind(""<1>"", text.autocompleter.on_text_click)<tab><tab>else:<tab><tab><tab>return<tab>text.autocompleter.handle_autocomplete_request()",0,"if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :","if hasattr ( text , ""autocompleter"" ) :",0.03196731530050977,6.191553286648261,0.3141025641025641
"def visit_Macro(self, node, frame):<tab>macro_frame, macro_ref = self.macro_body(node, frame)<tab>self.newline()<tab>if frame.toplevel:<tab><tab><IF-STMT><tab><tab><tab>self.write(""context.exported_vars.add(%r)"" % node.name)<tab><tab>ref = frame.symbols.ref(node.name)<tab><tab>self.writeline(""context.vars[%r] = "" % node.name)<tab>self.write(""%s = "" % frame.symbols.ref(node.name))<tab>self.macro_def(macro_ref, macro_frame)",0,"if not node . name . startswith ( ""_"" ) :",if node . name not in self . context . exported_vars :,0.11841448355213866,13.508625657351418,0.20370370370370372
"def execute(cls, ctx, op):<tab>try:<tab><tab>pd.set_option(""mode.use_inf_as_na"", op.use_inf_as_na)<tab><tab><IF-STMT><tab><tab><tab>return cls._execute_map(ctx, op)<tab><tab>else:<tab><tab><tab>return cls._execute_combine(ctx, op)<tab>finally:<tab><tab>pd.reset_option(""mode.use_inf_as_na"")",0,if op . stage == OperandStage . map :,if op . map :,0.16087164738385357,23.505403213046527,0.4666666666666666
"def ranges(self, start, end):<tab>try:<tab><tab>iterators = [i.ranges(start, end) for i in self.range_iterators]<tab><tab>starts, ends, values = zip(*[next(i) for i in iterators])<tab><tab>starts = list(starts)<tab><tab>ends = list(ends)<tab><tab>values = list(values)<tab><tab>while start < end:<tab><tab><tab>min_end = min(ends)<tab><tab><tab>yield start, min_end, values<tab><tab><tab>start = min_end<tab><tab><tab>for i, iterator in enumerate(iterators):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>starts[i], ends[i], values[i] = next(iterator)<tab>except StopIteration:<tab><tab>return",0,if ends [ i ] == min_end :,if iterator is not None :,0.018517117658868813,4.194930905450255,0.21875
"def get_explanation(self, spec):<tab>""""""Expand an explanation.""""""<tab>if spec:<tab><tab>try:<tab><tab><tab>a = self.dns_txt(spec)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return str(self.expand(to_ascii(a[0]), stripdot=False))<tab><tab>except PermError:<tab><tab><tab># RFC4408 6.2/4 syntax errors cause exp= to be ignored<tab><tab><tab>if self.strict > 1:<tab><tab><tab><tab>raise  # but report in harsh mode for record checking tools<tab><tab><tab>pass<tab>elif self.strict > 1:<tab><tab>raise PermError(""Empty domain-spec on exp="")<tab># RFC4408 6.2/4 empty domain spec is ignored<tab># (unless you give precedence to the grammar).<tab>return None",0,if len ( a ) == 1 :,if a :,0.017267079824235865,1e-10,0.36
"def iter_fields(node, *, include_meta=True, exclude_unset=False):<tab>exclude_meta = not include_meta<tab>for field_name, field in node._fields.items():<tab><tab>if exclude_meta and field.meta:<tab><tab><tab>continue<tab><tab>field_val = getattr(node, field_name, _marker)<tab><tab>if field_val is _marker:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if callable(field.default):<tab><tab><tab><tab>default = field.default()<tab><tab><tab>else:<tab><tab><tab><tab>default = field.default<tab><tab><tab>if field_val == default:<tab><tab><tab><tab>continue<tab><tab>yield field_name, field_val",0,if exclude_unset :,if field_val is _unset :,0.051944022748897464,1e-10,0.6190476190476191
"def __setattr__(self, name, value):<tab>try:<tab><tab>field = self._meta.get_field(name)<tab><tab><IF-STMT><tab><tab><tab>value = value[: field.max_length]<tab>except models.fields.FieldDoesNotExist:<tab><tab>pass  # This happens with foreign keys.<tab>super.__setattr__(self, name, value)",0,"if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str :",if field . max_length :,0.028864480998056694,0.8188135341326943,0.1534090909090909
"def create_child(self, value=None, _id=None):<tab>with atomic(savepoint=False):<tab><tab>child_key = self.get_next_child_key()<tab><tab><IF-STMT><tab><tab><tab>value = child_key<tab><tab>child = self.__class__.objects.create(id=_id, key=child_key, value=value)<tab><tab>return child",1,if value is None :,if value is None :,0.75,100.00000000000004,1.0
"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None):<tab>stream = self.describe_stream(stream_name)<tab>tags = []<tab>result = {""HasMoreTags"": False, ""Tags"": tags}<tab>for key, val in sorted(stream.tags.items(), key=lambda x: x[0]):<tab><tab><IF-STMT><tab><tab><tab>result[""HasMoreTags""] = True<tab><tab><tab>break<tab><tab>if exclusive_start_tag_key and key < exclusive_start_tag_key:<tab><tab><tab>continue<tab><tab>tags.append({""Key"": key, ""Value"": val})<tab>return result",0,if limit and len ( tags ) >= limit :,if limit and val [ 0 ] == limit :,0.16155199957819166,23.462350320527996,0.5
"def emit(self, record):<tab>try:<tab><tab>app = get_app()<tab><tab><IF-STMT><tab><tab><tab>msg = self.format(record)<tab><tab><tab>debug_buffer = app.layout.get_buffer_by_name(""debug_buffer"")<tab><tab><tab>current_document = debug_buffer.document.text<tab><tab><tab>if current_document:<tab><tab><tab><tab>msg = ""\n"".join([current_document, msg])<tab><tab><tab>debug_buffer.set_document(Document(text=msg), bypass_readonly=True)<tab><tab>else:<tab><tab><tab>super().emit(record)<tab>except:<tab><tab>self.handleError(record)",0,"if app . is_running and getattr ( app , ""debug"" , False ) :",if self . format_record ( record ) :,0.019051245413724494,4.96274655104206,0.23026315789473684
"def worker():<tab>global error<tab>while True:<tab><tab>(num, q) = pq.get()<tab><tab><IF-STMT><tab><tab><tab>pq.task_done()<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>process_one(q)<tab><tab>except Exception as e:<tab><tab><tab>error = e<tab><tab>finally:<tab><tab><tab>pq.task_done()",0,if q is None or error is not None :,if num == 0 :,0.013468035777437931,4.955725306405571,0.125
"def transceiver(self, data):<tab>out = []<tab>for t in range(8):<tab><tab>if data[t] == 0:<tab><tab><tab>continue<tab><tab>value = data[t]<tab><tab>for b in range(8):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if len(TRANSCEIVER[t]) < b + 1:<tab><tab><tab><tab><tab>out.append(""(unknown)"")<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>out.append(TRANSCEIVER[t][b])<tab><tab><tab>value <<= 1<tab>self.annotate(""Transceiver compliance"", "", "".join(out))",0,if value & 0x80 :,if value & 1 :,0.14477865547525276,42.72870063962342,0.6
"def skip_to_close_match(self):<tab>nestedCount = 1<tab>while 1:<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab>ttype = tok[""style""]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>elif self.classifier.is_index_op(tok):<tab><tab><tab>tval = tok[""text""]<tab><tab><tab>if self.opHash.has_key(tval):<tab><tab><tab><tab>if self.opHash[tval][1] == 1:<tab><tab><tab><tab><tab>nestedCount += 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>nestedCount -= 1<tab><tab><tab><tab><tab>if nestedCount <= 0:<tab><tab><tab><tab><tab><tab>break",0,if ttype == SCE_PL_UNUSED :,"if ttype == ""eof"" :",0.14477865547525276,28.46946938149361,1.0
"def GenerateVector(self, hits, vector, level):<tab>""""""Generate possible hit vectors which match the rules.""""""<tab>for item in hits.get(level, []):<tab><tab>if vector:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if item > self.max_separation + vector[-1]:<tab><tab><tab><tab>break<tab><tab>new_vector = vector + [item]<tab><tab>if level + 1 == len(hits):<tab><tab><tab>yield new_vector<tab><tab>elif level + 1 < len(hits):<tab><tab><tab>for result in self.GenerateVector(hits, new_vector, level + 1):<tab><tab><tab><tab>yield result",1,if item < vector [ - 1 ] :,if item < vector [ - 1 ] :,0.75,100.00000000000004,1.0
"def __setattr__(self, name, value):<tab>if name == ""path"":<tab><tab><IF-STMT><tab><tab><tab>if value[0] != ""/"":<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>'The page path should always start with a slash (""/"").'<tab><tab><tab><tab>)<tab>elif name == ""load_time"":<tab><tab>if value and not isinstance(value, int):<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Page load time must be specified in integer milliseconds.""<tab><tab><tab>)<tab>object.__setattr__(self, name, value)",0,"if value and value != """" :",if value :,0.03885753308224148,1e-10,0.6041666666666666
"def awaitTermination(self, timeout=None):<tab>if self.scheduler is None:<tab><tab>raise RuntimeError(""StreamimgContext not started"")<tab>try:<tab><tab>deadline = time.time() + timeout if timeout is not None else None<tab><tab>while True:<tab><tab><tab>is_terminated = self._runOnce()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if self.batchCallback:<tab><tab><tab><tab>self.batchCallback()<tab>except KeyboardInterrupt:<tab><tab>pass<tab>finally:<tab><tab>self.sc.stop()<tab><tab>logger.info(""StreamingContext stopped successfully"")",0,if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,if deadline and is_terminated :,0.005940504861532455,4.71691221201104,0.18840579710144928
"def stopbutton(self):<tab>if GPIOcontrol:<tab><tab>while mediastopbutton:<tab><tab><tab>time.sleep(0.25)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""Stopped"")<tab><tab><tab><tab>stop()",0,if not GPIO . input ( stoppushbutton ) :,if mediastopbutton == 0 :,0.015736078468693036,5.854497694024015,0.225
"def test_create_connection_timeout(self):<tab># Issue #9792: create_connection() should not recast timeout errors<tab># as generic socket errors.<tab>with self.mocked_socket_module():<tab><tab>try:<tab><tab><tab>socket.create_connection((HOST, 1234))<tab><tab>except socket.timeout:<tab><tab><tab>pass<tab><tab>except OSError as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>self.fail(""socket.timeout not raised"")",0,if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT :,if exc . errno != errno . ECONNRESET :,0.5819855051161652,37.33976803111327,0.23214285714285715
"def handle_exception_and_die(e):<tab>if hasattr(e, ""kind""):<tab><tab><IF-STMT><tab><tab><tab>sys.stderr.write(""ABORT: "" + e.msg + ""\n"")<tab><tab><tab>sys.exit(e.value)<tab><tab>elif e.kind == ""exit"":<tab><tab><tab>sys.stderr.write(""EXITING\n"")<tab><tab><tab>sys.exit(e.value)<tab>else:<tab><tab>print(str(e))<tab><tab>sys.exit(1)",0,"if e . kind == ""die"" :","if e . kind == ""abort"" :",0.574113272471593,70.71067811865478,1.0
"def gets(self, key):<tab>with self.client_pool.get_and_release(destroy_on_fail=True) as client:<tab><tab>try:<tab><tab><tab>return client.gets(key)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (None, None)<tab><tab><tab>else:<tab><tab><tab><tab>raise",1,if self . ignore_exc :,if self . ignore_exc :,0.75,100.00000000000004,1.0
"def _execute(self, options, args):<tab>if len(args) < 3:<tab><tab>raise CommandError(_(""Not enough arguments""))<tab>tag = fsn2text(args[0])<tab>value = fsn2text(args[1])<tab>paths = args[2:]<tab>songs = []<tab>for path in paths:<tab><tab>song = self.load_song(path)<tab><tab><IF-STMT><tab><tab><tab>raise CommandError(_(""Can not set %r"") % tag)<tab><tab>self.log(""Add %r to %r"" % (value, tag))<tab><tab>song.add(tag, value)<tab><tab>songs.append(song)<tab>self.save_songs(songs)",0,if not song . can_change ( tag ) :,if song is None :,0.0168380461076173,4.234348806659263,0.2857142857142857
"def get_place_name(self, place_handle):<tab>""""""Obtain a place name""""""<tab>text = """"<tab>if place_handle:<tab><tab>place = self.dbstate.db.get_place_from_handle(place_handle)<tab><tab>if place:<tab><tab><tab>place_title = place_displayer.display(self.dbstate.db, place)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if len(place_title) > 25:<tab><tab><tab><tab><tab>text = place_title[:24] + ""...""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>text = place_title<tab>return text",0,"if place_title != """" :",if place_title :,0.06767423853569741,1e-10,1.0
"def _Determine_Do(self):<tab>self.applicable = 1<tab>self.value = os.environ.get(self.name, None)<tab>if self.value is None and black.configure.items.has_key(""buildType""):<tab><tab>buildType = black.configure.items[""buildType""].Get()<tab><tab><IF-STMT><tab><tab><tab>self.value = ""warn""<tab><tab>else:<tab><tab><tab>self.value = None<tab>self.determined = 1",0,"if buildType == ""debug"" :","if buildType == ""warn"" :",0.39477865547525276,59.4603557501361,1.0
"def bundle_directory(self, dirpath):<tab>""""""Bundle all modules/packages in the given directory.""""""<tab>dirpath = os.path.abspath(dirpath)<tab>for nm in os.listdir(dirpath):<tab><tab>nm = _u(nm)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>itempath = os.path.join(dirpath, nm)<tab><tab>if os.path.isdir(itempath):<tab><tab><tab>if os.path.exists(os.path.join(itempath, ""__init__.py"")):<tab><tab><tab><tab>self.bundle_package(itempath)<tab><tab>elif nm.endswith("".py""):<tab><tab><tab>self.bundle_module(itempath)",0,"if nm . startswith ( ""."" ) :",if not os . path . isfile ( nm ) :,0.03295805487236919,10.252286118120933,0.22115384615384615
"def header_fields(self, fields):<tab>headers = dict(self.conn.response.getheaders())<tab>ret = {}<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""%s was not found in response header"" % (field[1]))<tab><tab>try:<tab><tab><tab>ret[field[0]] = int(headers[field[1]])<tab><tab>except ValueError:<tab><tab><tab>ret[field[0]] = headers[field[1]]<tab>return ret",0,if not headers . has_key ( field [ 1 ] ) :,if field [ 0 ] not in headers :,0.0877588507102106,7.483105263003811,0.2403846153846154
"def caesar_cipher(s, k):<tab>result = """"<tab>for char in s:<tab><tab>n = ord(char)<tab><tab><IF-STMT><tab><tab><tab>n = ((n - 65 + k) % 26) + 65<tab><tab>if 96 < n < 123:<tab><tab><tab>n = ((n - 97 + k) % 26) + 97<tab><tab>result = result + chr(n)<tab>return result",0,if 64 < n < 91 :,if 65 < n < k :,0.09447893407153068,27.77619034011791,0.42857142857142855
"def qtTypeIdent(conn, *args):<tab># We're not using the conn object at the moment, but - we will<tab># modify the<tab># logic to use the server version specific keywords later.<tab>res = None<tab>value = None<tab>for val in args:<tab><tab># DataType doesn't have len function then convert it to string<tab><tab>if not hasattr(val, ""__len__""):<tab><tab><tab>val = str(val)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = val<tab><tab>if Driver.needsQuoting(val, True):<tab><tab><tab>value = value.replace('""', '""""')<tab><tab><tab>value = '""' + value + '""'<tab><tab>res = ((res and res + ""."") or """") + value<tab>return res",0,if len ( val ) == 0 :,"if val == """" :",0.020977836961063236,12.411264901419441,0.36
"def _parse_timezone(<tab>value: Optional[str], error: Type[Exception]) -> Union[None, int, timezone]:<tab>if value == ""Z"":<tab><tab>return timezone.utc<tab>elif value is not None:<tab><tab>offset_mins = int(value[-2:]) if len(value) > 3 else 0<tab><tab>offset = 60 * int(value[1:3]) + offset_mins<tab><tab><IF-STMT><tab><tab><tab>offset = -offset<tab><tab>try:<tab><tab><tab>return timezone(timedelta(minutes=offset))<tab><tab>except ValueError:<tab><tab><tab>raise error()<tab>else:<tab><tab>return None",1,"if value [ 0 ] == ""-"" :","if value [ 0 ] == ""-"" :",0.75,100.00000000000004,1.0
"def indent(elem, level=0):<tab>i = ""\n"" + level * ""  ""<tab>if len(elem):<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab>if level and (not elem.tail or not elem.tail.strip()):<tab><tab><tab>elem.tail = i",1,if not elem . tail or not elem . tail . strip ( ) :,if not elem . tail or not elem . tail . strip ( ) :,1.0,100.00000000000004,1.0
"def _make_slices(<tab>shape: tp.Tuple[int, ...],<tab>axes: tp.Tuple[int, ...],<tab>size: int,<tab>rng: np.random.RandomState,) -> tp.List[slice]:<tab>slices = []<tab>for a, s in enumerate(shape):<tab><tab>if a in axes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Cannot crossover on axis with size 1"")<tab><tab><tab>start = rng.randint(s - size)<tab><tab><tab>slices.append(slice(start, start + size))<tab><tab>else:<tab><tab><tab>slices.append(slice(None))<tab>return slices",0,if s <= 1 :,if size < 1 :,0.31497877230811644,20.80119537801062,0.6
"def _loadTestsFromTestCase(self, event, testCaseClass):<tab>evt = events.LoadFromTestCaseEvent(event.loader, testCaseClass)<tab>result = self.session.hooks.loadTestsFromTestCase(evt)<tab>if evt.handled:<tab><tab>loaded_suite = result or event.loader.suiteClass()<tab>else:<tab><tab>names = self._getTestCaseNames(event, testCaseClass)<tab><tab><IF-STMT><tab><tab><tab>names = [""runTest""]<tab><tab># FIXME return failure test case if name not in testcase class<tab><tab>loaded_suite = event.loader.suiteClass(map(testCaseClass, names))<tab>if evt.extraTests:<tab><tab>loaded_suite.addTests(evt.extraTests)<tab>return loaded_suite",0,"if not names and hasattr ( testCaseClass , ""runTest"" ) :",if not names :,0.04614409468537624,6.734410772670761,0.5384615384615384
"def check_settings(self):<tab>if self.settings_dict[""TIME_ZONE""] is not None:<tab><tab>if not settings.USE_TZ:<tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because USE_TZ is ""<tab><tab><tab><tab>""False."" % self.alias<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab>""Connection '%s' cannot set TIME_ZONE because its engine ""<tab><tab><tab><tab>""handles time zones conversions natively."" % self.alias<tab><tab><tab>)",0,elif self . features . supports_timezones :,"if ""TIME_ZONE"" not in self . settings_dict :",0.03557786254320786,6.754312828675707,0.12698412698412698
"def collect_conflicting_diffs(path, decisions):<tab>local_conflict_diffs = []<tab>remote_conflict_diffs = []<tab>for d in decisions:<tab><tab><IF-STMT><tab><tab><tab>ld = adjust_patch_level(path, d.common_path, d.local_diff)<tab><tab><tab>rd = adjust_patch_level(path, d.common_path, d.remote_diff)<tab><tab><tab>local_conflict_diffs.extend(ld)<tab><tab><tab>remote_conflict_diffs.extend(rd)<tab>return local_conflict_diffs, remote_conflict_diffs",0,if d . conflict :,if d . common_path :,0.39477865547525276,26.269098944241588,0.7
"def short_repr(obj):<tab>if isinstance(<tab><tab>obj,<tab><tab>(type, types.ModuleType, types.BuiltinMethodType, types.BuiltinFunctionType),<tab>):<tab><tab>return obj.__name__<tab>if isinstance(obj, types.MethodType):<tab><tab><IF-STMT><tab><tab><tab>return obj.im_func.__name__ + "" (bound)""<tab><tab>else:<tab><tab><tab>return obj.im_func.__name__<tab>if isinstance(obj, (tuple, list, dict, set)):<tab><tab>return ""%d items"" % len(obj)<tab>if isinstance(obj, weakref.ref):<tab><tab>return ""all_weakrefs_are_one""<tab>return repr(obj)[:40]",0,if obj . im_self is not None :,"if obj . im_func . __name__ . startswith ( ""bound"" ) :",0.06233128548440049,18.759202316167208,0.4107142857142857
"def _massage_uri(uri):<tab>if uri:<tab><tab><IF-STMT><tab><tab><tab>uri = uri.replace(""hdfs://"", get_defaultfs())<tab><tab>elif uri.startswith(""/""):<tab><tab><tab>uri = get_defaultfs() + uri<tab>return uri",0,"if uri . startswith ( ""hdfs:///"" ) :","if uri . startswith ( ""hdfs://"" ) :",0.5490406812970063,90.18895596416246,1.0
"def chsub(self, msg, chatid):<tab>(cmd, evt, params) = self.tokenize(msg, 3)<tab>if cmd == ""/sub"":<tab><tab>sql = ""replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?)""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>sql = ""delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1)""  # does not look very elegant, but makes unsub'ing everythign possible<tab><tab>else:<tab><tab><tab>sql = ""delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ?""<tab>with self.bot.database as conn:<tab><tab>conn.execute(sql, [chatid, evt, params])<tab><tab>conn.commit()<tab>return",0,"if evt == ""everything"" :",if evt == 1 :,0.14477865547525276,38.49815007763549,0.7
"def undefined_symbols(self):<tab>result = []<tab>for p in self.Productions:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for s in p.prod:<tab><tab><tab>if not s in self.Prodnames and not s in self.Terminals and s != ""error"":<tab><tab><tab><tab>result.append((s, p))<tab>return result",0,if not p :,"if not isinstance ( p , Symbol ) :",0.06558970101793501,11.339582221952005,0.4666666666666666
"def renumber(self, x1, y1, x2, y2, dx, dy):<tab>out = []<tab>for part in re.split(""(\w+)"", self.formula):<tab><tab>m = re.match(""^([A-Z]+)([1-9][0-9]*)$"", part)<tab><tab>if m is not None:<tab><tab><tab>sx, sy = m.groups()<tab><tab><tab>x = colname2num(sx)<tab><tab><tab>y = int(sy)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>part = cellname(x + dx, y + dy)<tab><tab>out.append(part)<tab>return FormulaCell("""".join(out), self.fmt, self.alignment)",0,if x1 <= x <= x2 and y1 <= y <= y2 :,if x + dx < len ( x ) and y + dy < len ( x ) :,0.010097935037901924,3.292916846800451,0.24166666666666667
"def modify_column(self, column: List[Optional[""Cell""]]):<tab>for i in range(len(column)):<tab><tab>gate = column[i]<tab><tab>if gate is self:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># The first parity control to modify the column must merge all<tab><tab><tab># of the other parity controls into itself.<tab><tab><tab>column[i] = None<tab><tab><tab>self._basis_change += gate._basis_change<tab><tab><tab>self.qubits += gate.qubits<tab><tab>elif gate is not None:<tab><tab><tab>column[i] = gate.controlled_by(self.qubits[0])",0,"elif isinstance ( gate , ParityControlCell ) :",if gate . _basis_change is not None :,0.06651582159006904,4.456882760699063,0.09523809523809523
"def update_neighbor(neigh_ip_address, changes):<tab>rets = []<tab>for k, v in changes.items():<tab><tab><IF-STMT><tab><tab><tab>rets.append(_update_med(neigh_ip_address, v))<tab><tab>if k == neighbors.ENABLED:<tab><tab><tab>rets.append(update_neighbor_enabled(neigh_ip_address, v))<tab><tab>if k == neighbors.CONNECT_MODE:<tab><tab><tab>rets.append(_update_connect_mode(neigh_ip_address, v))<tab>return all(rets)",0,if k == neighbors . MULTI_EXIT_DISC :,if k == neighbors . MAGIC :,0.574113272471593,42.88819424803536,0.7714285714285715
"def writexml(<tab>self,<tab>stream,<tab>indent="""",<tab>addindent="""",<tab>newl="""",<tab>strip=0,<tab>nsprefixes={},<tab>namespace="""",):<tab>w = _streamWriteWrapper(stream)<tab>if self.raw:<tab><tab>val = self.nodeValue<tab><tab>if not isinstance(val, str):<tab><tab><tab>val = str(self.nodeValue)<tab>else:<tab><tab>v = self.nodeValue<tab><tab><IF-STMT><tab><tab><tab>v = str(v)<tab><tab>if strip:<tab><tab><tab>v = "" "".join(v.split())<tab><tab>val = escape(v)<tab>w(val)",1,"if not isinstance ( v , str ) :","if not isinstance ( v , str ) :",0.75,100.00000000000004,1.0
"def _condition(ct):<tab>for qobj in args:<tab><tab><IF-STMT><tab><tab><tab># normal kwargs are an AND anyway, so just use those for now<tab><tab><tab>for child in qobj.children:<tab><tab><tab><tab>kwargs.update(dict([child]))<tab><tab>else:<tab><tab><tab>raise NotImplementedError(""Unsupported Q object"")<tab>for attr, val in kwargs.items():<tab><tab>if getattr(ct, attr) != val:<tab><tab><tab>return False<tab>return True",0,"if qobj . connector == ""AND"" and not qobj . negated :","if isinstance ( qobj , QGroup ) :",0.01198879490978343,3.0297048914466935,0.19658119658119658
"def results_iter(self):<tab><IF-STMT><tab><tab>from django.db.models.fields import DateTimeField<tab><tab>fields = [DateTimeField()]<tab>else:<tab><tab>needs_string_cast = self.connection.features.needs_datetime_string_cast<tab>offset = len(self.query.extra_select)<tab>for rows in self.execute_sql(MULTI):<tab><tab>for row in rows:<tab><tab><tab>date = row[offset]<tab><tab><tab>if self.connection.ops.oracle:<tab><tab><tab><tab>date = self.resolve_columns(row, fields)[offset]<tab><tab><tab>elif needs_string_cast:<tab><tab><tab><tab>date = typecast_timestamp(str(date))<tab><tab><tab>yield date",0,if self . connection . ops . oracle :,if needs_string_cast :,0.013130313781176673,1e-10,0.27777777777777773
"def get_job_type(self):<tab>if int(self.job_runtime_conf.get(""dsl_version"", 1)) == 2:<tab><tab>job_type = (<tab><tab><tab>self.job_runtime_conf[""job_parameters""].get(""common"", {}).get(""job_type"")<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"")<tab>else:<tab><tab>job_type = self.job_runtime_conf[""job_parameters""].get(""job_type"", ""train"")<tab>return job_type",0,if not job_type :,"if job_type == ""train"" :",0.045150550804307965,17.747405280050266,0.6190476190476191
"def validate_assessment_criteria(self):<tab>if self.assessment_criteria:<tab><tab>total_weightage = 0<tab><tab>for criteria in self.assessment_criteria:<tab><tab><tab>total_weightage += criteria.weightage or 0<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Total Weightage of all Assessment Criteria must be 100%""))",0,if total_weightage != 100 :,if total_weightage > 100 :,0.33141502097923065,42.38365628278778,1.0
"def get_list_of_strings_to_mongo_objects(self, notifications_list=None):<tab>result = []<tab>if len(notifications_list) > 0:<tab><tab>for x in notifications_list:<tab><tab><tab>split_provider_id = x.split("":"")  # email:id<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_id = split_provider_id[1]<tab><tab><tab><tab>cursor = self.get_by_id(_id)<tab><tab><tab><tab>if cursor:  # Append if exists<tab><tab><tab><tab><tab>result.append(cursor)<tab>return result",1,if len ( split_provider_id ) == 2 :,if len ( split_provider_id ) == 2 :,0.75,100.00000000000004,1.0
"def dump_predictions_to_database(relation, predictions):<tab>judge = ""iepy-run on {}"".format(datetime.now().strftime(""%Y-%m-%d %H:%M""))<tab>for evidence, relation_is_present in predictions.items():<tab><tab>label = (<tab><tab><tab>EvidenceLabel.YESRELATION<tab><tab><tab><IF-STMT><tab><tab><tab>else EvidenceLabel.NORELATION<tab><tab>)<tab><tab>evidence.set_label(relation, label, judge, labeled_by_machine=True)",1,if relation_is_present,if relation_is_present,0.408113883008419,1e-10,1.0
"def __init__(self, **kwargs):<tab># We hard-code the `to` argument for ForeignKey.__init__<tab>dfl = get_model_label(self.default_model_class)<tab>if ""to"" in kwargs.keys():  # pragma: no cover<tab><tab>old_to = get_model_label(kwargs.pop(""to""))<tab><tab><IF-STMT><tab><tab><tab>msg = ""%s can only be a ForeignKey to %s; %s passed"" % (<tab><tab><tab><tab>self.__class__.__name__,<tab><tab><tab><tab>dfl,<tab><tab><tab><tab>old_to,<tab><tab><tab>)<tab><tab><tab>warnings.warn(msg, SyntaxWarning)<tab>kwargs[""to""] = dfl<tab>super().__init__(**kwargs)",0,if old_to . lower ( ) != dfl . lower ( ) :,"if isinstance ( old_to , ForeignKey ) :",0.021071541928911645,11.7250040531018,0.3245614035087719
"def reverse(self):<tab>""""""Reverse *IN PLACE*.""""""<tab>li = self.leftindex<tab>lb = self.leftblock<tab>ri = self.rightindex<tab>rb = self.rightblock<tab>for i in range(self.len >> 1):<tab><tab>lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li]<tab><tab>li += 1<tab><tab>if li >= BLOCKLEN:<tab><tab><tab>lb = lb.rightlink<tab><tab><tab>li = 0<tab><tab>ri -= 1<tab><tab><IF-STMT><tab><tab><tab>rb = rb.leftlink<tab><tab><tab>ri = BLOCKLEN - 1",0,if ri < 0 :,if ri >= BLOCKLEN :,0.06497877230811641,17.965205598154213,0.6
"def get_api(user, url):<tab>global API_CACHE<tab>if API_CACHE is None or API_CACHE.get(url) is None:<tab><tab>API_CACHE_LOCK.acquire()<tab><tab>try:<tab><tab><tab>if API_CACHE is None:<tab><tab><tab><tab>API_CACHE = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>API_CACHE[url] = ImpalaDaemonApi(url)<tab><tab>finally:<tab><tab><tab>API_CACHE_LOCK.release()<tab>api = API_CACHE[url]<tab>api.set_user(user)<tab>return api",0,if API_CACHE . get ( url ) is None :,elif not API_CACHE . get ( url ) :,0.38505350954404655,63.8194179668201,0.11363636363636363
"def invert_index(cls, index, length):<tab>if np.isscalar(index):<tab><tab>return length - index<tab>elif isinstance(index, slice):<tab><tab>start, stop = index.start, index.stop<tab><tab>new_start, new_stop = None, None<tab><tab>if start is not None:<tab><tab><tab>new_stop = length - start<tab><tab><IF-STMT><tab><tab><tab>new_start = length - stop<tab><tab>return slice(new_start - 1, new_stop - 1)<tab>elif isinstance(index, Iterable):<tab><tab>new_index = []<tab><tab>for ind in index:<tab><tab><tab>new_index.append(length - ind)<tab>return new_index",1,if stop is not None :,if stop is not None :,0.75,100.00000000000004,1.0
"def infer_returned_object(pyfunction, args):<tab>""""""Infer the `PyObject` this `PyFunction` returns after calling""""""<tab>object_info = pyfunction.pycore.object_info<tab>result = object_info.get_exact_returned(pyfunction, args)<tab>if result is not None:<tab><tab>return result<tab>result = _infer_returned(pyfunction, args)<tab>if result is not None:<tab><tab><IF-STMT><tab><tab><tab>params = args.get_arguments(pyfunction.get_param_names(special_args=False))<tab><tab><tab>object_info.function_called(pyfunction, params, result)<tab><tab>return result<tab>return object_info.get_returned(pyfunction, args)",0,if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,if pyfunction . is_python ( ) :,0.08667475854786769,4.72397603164636,0.22282608695652173
"def _check_imports(lib):<tab># Make sure no conflicting libraries have been imported.<tab>libs = [""PyQt4"", ""PyQt5"", ""PySide""]<tab>libs.remove(lib)<tab>for lib2 in libs:<tab><tab>lib2 += "".QtCore""<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Refusing to import %s because %s is already "" ""imported."" % (lib, lib2)<tab><tab><tab>)",0,if lib2 in sys . modules :,if lib . endswith ( lib2 ) :,0.022224573773363735,7.809849842300637,0.23214285714285715
"def _poll(fds, timeout):<tab>if timeout is not None:<tab><tab>timeout = int(timeout * 1000)  # timeout is in milliseconds<tab>fd_map = {}<tab>pollster = select.poll()<tab>for fd in fds:<tab><tab>pollster.register(fd, select.POLLIN)<tab><tab><IF-STMT><tab><tab><tab>fd_map[fd.fileno()] = fd<tab><tab>else:<tab><tab><tab>fd_map[fd] = fd<tab>ls = []<tab>for fd, event in pollster.poll(timeout):<tab><tab>if event & select.POLLNVAL:<tab><tab><tab>raise ValueError(""invalid file descriptor %i"" % fd)<tab><tab>ls.append(fd_map[fd])<tab>return ls",0,"if hasattr ( fd , ""fileno"" ) :",if fd . fileno ( ) in fd_map :,0.01983274868265512,5.865587580131999,0.3181818181818182
"def default(cls, connection=None):<tab>""""""show the default connection, or make CONNECTION the default""""""<tab>if connection is not None:<tab><tab>target = cls._get_config_filename(connection)<tab><tab><IF-STMT><tab><tab><tab>if os.path.exists(cls._default_symlink):<tab><tab><tab><tab>os.remove(cls._default_symlink)<tab><tab><tab>os.symlink(target, cls._default_symlink)<tab><tab>else:<tab><tab><tab>cls._no_config_file_error(target)<tab>if os.path.exists(cls._default_symlink):<tab><tab>print(""Default connection is "" + cls._default_connection())<tab>else:<tab><tab>print(""There is no default connection set"")",1,if os . path . exists ( target ) :,if os . path . exists ( target ) :,0.75,100.00000000000004,1.0
"def process(self, fuzzresult):<tab>base_url = urljoin(fuzzresult.url, "".."")<tab>for line in fuzzresult.history.content.splitlines():<tab><tab>record = line.split(""/"")<tab><tab><IF-STMT><tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab># Directory<tab><tab><tab>if record[0] == ""D"":<tab><tab><tab><tab>self.queue_url(urljoin(base_url, record[1]))<tab><tab><tab><tab>self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))",0,if len ( record ) == 6 and record [ 1 ] :,"if record [ 0 ] == ""A"" :",0.02183107495083518,9.281844047221343,0.21875
"def _GetCSVRow(self, value):<tab>row = []<tab>for type_info in value.__class__.type_infos:<tab><tab><IF-STMT><tab><tab><tab>row.extend(self._GetCSVRow(value.Get(type_info.name)))<tab><tab>elif isinstance(type_info, rdf_structs.ProtoBinary):<tab><tab><tab>row.append(text.Asciify(value.Get(type_info.name)))<tab><tab>else:<tab><tab><tab>row.append(str(value.Get(type_info.name)))<tab>return row",0,"if isinstance ( type_info , rdf_structs . ProtoEmbedded ) :","if isinstance ( type_info , rdf_structs . ProtoStruct ) :",0.6049399806880458,80.91067115702207,0.6
"def get_history(self, state, dict_, passive=PASSIVE_OFF):<tab>if self.key in dict_:<tab><tab>return History.from_scalar_attribute(self, state, dict_[self.key])<tab>else:<tab><tab><IF-STMT><tab><tab><tab>passive ^= INIT_OK<tab><tab>current = self.get(state, dict_, passive=passive)<tab><tab>if current is PASSIVE_NO_RESULT:<tab><tab><tab>return HISTORY_BLANK<tab><tab>else:<tab><tab><tab>return History.from_scalar_attribute(self, state, current)",1,if passive & INIT_OK :,if passive & INIT_OK :,0.75,100.00000000000004,1.0
"def _iterate_self_and_parents(self, upto=None):<tab>current = self<tab>result = ()<tab>while current:<tab><tab>result += (current,)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif current._parent is None:<tab><tab><tab>raise sa_exc.InvalidRequestError(<tab><tab><tab><tab>""Transaction %s is not on the active transaction list"" % (upto)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>current = current._parent<tab>return result",0,if current . _parent is upto :,if current . _upto == upto :,0.1045581281295217,35.49481056010054,0.5714285714285714
"def get_by_uri(self, uri: str) -> bytes:<tab>userId, bucket, key = self._parse_uri(uri)<tab>try:<tab><tab>with db.session_scope() as dbsession:<tab><tab><tab>result = db_archivedocument.get(userId, bucket, key, session=dbsession)<tab><tab><IF-STMT><tab><tab><tab>return utils.ensure_bytes(self._decode(result))<tab><tab>else:<tab><tab><tab>raise ObjectKeyNotFoundError(userId, bucket, key, caused_by=None)<tab>except Exception as err:<tab><tab>logger.debug(""cannot get data: exception - "" + str(err))<tab><tab>raise err",1,if result :,if result :,0.5311706625951745,1e-10,1.0
"def app(scope, receive, send):<tab>while True:<tab><tab>message = await receive()<tab><tab>if message[""type""] == ""websocket.connect"":<tab><tab><tab>await send({""type"": ""websocket.accept""})<tab><tab>elif message[""type""] == ""websocket.receive"":<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>break",1,"elif message [ ""type"" ] == ""websocket.disconnect"" :","elif message [ ""type"" ] == ""websocket.disconnect"" :",1.0,100.00000000000004,1.0
"def recv_some(p, t=0.1, e=1, tr=5, stderr=0):<tab>if tr < 1:<tab><tab>tr = 1<tab>x = time.time() + t<tab>y = []<tab>r = """"<tab>if stderr:<tab><tab>pr = p.recv_err<tab>else:<tab><tab>pr = p.recv<tab>while time.time() < x or r:<tab><tab>r = pr()<tab><tab>if r is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>y.append(r)<tab><tab>else:<tab><tab><tab>time.sleep(max((x - time.time()) / tr, 0))<tab>return """".join(y)",0,elif r :,if e :,0.05340548416168749,1e-10,0.2
"def mouse_down(self, event):<tab>if event.button == 1:<tab><tab><IF-STMT><tab><tab><tab>p = event.local<tab><tab><tab>if self.scroll_up_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_up()<tab><tab><tab><tab>return<tab><tab><tab>elif self.scroll_down_rect().collidepoint(p):<tab><tab><tab><tab>self.scroll_down()<tab><tab><tab><tab>return<tab>if event.button == 4:<tab><tab>self.scroll_up()<tab>if event.button == 5:<tab><tab>self.scroll_down()<tab>GridView.mouse_down(self, event)",0,if self . scrolling :,if event . button == 2 :,0.029730601197949243,7.267884212102741,0.2653061224489796
"def copy_from(self, other):<tab>if self is other:<tab><tab>return  # Myself!<tab>self.strictness = other.strictness  # sets behaviors in bulk<tab>for name in self.all_behaviors:<tab><tab>self.set_behavior(name, other.get_behavior(name))<tab>for name in self._plain_attrs:<tab><tab>val = getattr(other, name)<tab><tab>if isinstance(val, set):<tab><tab><tab>val = val.copy()<tab><tab><IF-STMT><tab><tab><tab>val = val.copy()<tab><tab>setattr(self, name, val)",0,"elif decimal and isinstance ( val , decimal . Decimal ) :","elif isinstance ( val , dict ) :",0.25529694264836755,25.9162669876144,0.25274725274725274
"def __array_wrap__(self, out_arr, context=None):<tab>if self.dim is None:<tab><tab>return out_arr<tab>else:<tab><tab>this = self[:]<tab><tab><IF-STMT><tab><tab><tab>return Quantity.__array_wrap__(self[:], out_arr, context=context)<tab><tab>else:<tab><tab><tab>return out_arr",1,"if isinstance ( this , Quantity ) :","if isinstance ( this , Quantity ) :",0.75,100.00000000000004,1.0
"def _ArgumentListHasDictionaryEntry(self, token):<tab>""""""Check if the function argument list has a dictionary as an arg.""""""<tab>if _IsArgumentToFunction(token):<tab><tab>while token:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>length = token.matching_bracket.total_length - token.total_length<tab><tab><tab><tab>return length + self.stack[-2].indent > self.column_limit<tab><tab><tab>if token.ClosesScope():<tab><tab><tab><tab>break<tab><tab><tab>if token.OpensScope():<tab><tab><tab><tab>token = token.matching_bracket<tab><tab><tab>token = token.next_token<tab>return False",0,"if token . value == ""{"" :",if token . FoundScope ( ) :,0.09056531419355518,17.112717058426785,0.6
"def save_all_changed_extensions(self):<tab>""""""Save configuration changes to the user config file.""""""<tab>has_changes = False<tab>for ext_name in self.extensions:<tab><tab>options = self.extensions[ext_name]<tab><tab>for opt in options:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>has_changes = True<tab>if has_changes:<tab><tab>self.ext_userCfg.Save()",0,"if self . set_extension_value ( ext_name , opt ) :","if opt [ ""name"" ] == ext_name :",0.015805905348207437,10.856421294065939,0.48333333333333334
"def to_dict(self):<tab>out = {}<tab>for key in ACTIVITY_KEYS:<tab><tab>attr = getattr(self, key)<tab><tab><IF-STMT><tab><tab><tab>out[key] = str(attr)<tab><tab>else:<tab><tab><tab>out[key] = attr<tab>if self.streak:<tab><tab>out[""streak""] = self.streak<tab>return out",0,"if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :","if isinstance ( attr , basestring ) :",0.1243916335610931,21.874242445215227,0.5510204081632654
"def clean_publication_date(cls, cleaned_input):<tab>for add_channel in cleaned_input.get(""add_channels"", []):<tab><tab>is_published = add_channel.get(""is_published"")<tab><tab>publication_date = add_channel.get(""publication_date"")<tab><tab><IF-STMT><tab><tab><tab>add_channel[""publication_date""] = datetime.date.today()",1,if is_published and not publication_date :,if is_published and not publication_date :,0.75,100.00000000000004,1.0
"def _random_blur(self, batch, sigma_max):<tab>for i in range(len(batch)):<tab><tab><IF-STMT><tab><tab><tab># Random sigma<tab><tab><tab>sigma = random.uniform(0.0, sigma_max)<tab><tab><tab>batch[i] = scipy.ndimage.filters.gaussian_filter(batch[i], sigma)<tab>return batch",0,if bool ( random . getrandbits ( 1 ) ) :,if random . random ( ) > sigma_max :,0.02715112201222712,9.864703138979419,0.42063492063492064
"def conninfo_parse(dsn):<tab>ret = {}<tab>length = len(dsn)<tab>i = 0<tab>while i < length:<tab><tab>if dsn[i].isspace():<tab><tab><tab>i += 1<tab><tab><tab>continue<tab><tab>param_match = PARAMETER_RE.match(dsn[i:])<tab><tab>if not param_match:<tab><tab><tab>return<tab><tab>param = param_match.group(1)<tab><tab>i += param_match.end()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>value, end = read_param_value(dsn[i:])<tab><tab>if value is None:<tab><tab><tab>return<tab><tab>i += end<tab><tab>ret[param] = value<tab>return ret",0,if i >= length :,if not param :,0.03675197809660419,11.521590992286539,0.3333333333333333
"def set_environment_vars(env, source_env):<tab>""""""Copy allowed environment variables from |source_env|.""""""<tab>if not source_env:<tab><tab>return<tab>for name, value in six.iteritems(source_env):<tab><tab>if is_forwarded_environment_variable(name):<tab><tab><tab># Avoid creating circular dependencies from importing environment by<tab><tab><tab># using os.getenv.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = file_host.rebase_to_worker_root(value)<tab><tab><tab>env[name] = value",0,"if os . getenv ( ""TRUSTED_HOST"" ) and should_rebase_environment_value ( name ) :",if file_host . is_worker_root ( value ) :,0.021071541928911645,4.349481530599887,0.2631578947368421
"def toterminal(self, tw):<tab># the entries might have different styles<tab>last_style = None<tab>for i, entry in enumerate(self.reprentries):<tab><tab>if entry.style == ""long"":<tab><tab><tab>tw.line("""")<tab><tab>entry.toterminal(tw)<tab><tab><IF-STMT><tab><tab><tab>next_entry = self.reprentries[i + 1]<tab><tab><tab>if (<tab><tab><tab><tab>entry.style == ""long""<tab><tab><tab><tab>or entry.style == ""short""<tab><tab><tab><tab>and next_entry.style == ""long""<tab><tab><tab>):<tab><tab><tab><tab>tw.sep(self.entrysep)<tab>if self.extraline:<tab><tab>tw.line(self.extraline)",0,if i < len ( self . reprentries ) - 1 :,if last_style is not None :,0.010667164792151046,3.983253478176822,0.18571428571428572
"def __init__(self, loc, tabs=None):<tab>if os.path.isdir(loc):<tab><tab>for item in os.listdir(loc):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>path = os.path.join(loc, item)<tab><tab><tab>self.append(CronTab(user=False, tabfile=path))<tab>elif os.path.isfile(loc):<tab><tab>self.append(CronTab(user=False, tabfile=loc))",0,"if item [ 0 ] == ""."" :","if item . startswith ( ""_"" ) or item == ""__init__.py"" :",0.02947464511262661,9.314939614341391,0.4236111111111111
"def import_data(self, fname):<tab>""""""Import data in current namespace""""""<tab>if self.count():<tab><tab>nsb = self.currentWidget()<tab><tab>nsb.refresh_table()<tab><tab>nsb.import_data(fname)<tab><tab><IF-STMT><tab><tab><tab>self.dockwidget.setVisible(True)<tab><tab><tab>self.dockwidget.raise_()",0,if self . dockwidget and not self . ismaximized :,if self . dockwidget is not None :,0.29326686023520293,29.797147054518835,0.5026455026455027
"def get_menu_items(node):<tab>aList = []<tab>for child in node.children:<tab><tab>for tag in (""@menu"", ""@item""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = child.h[len(tag) + 1 :].strip()<tab><tab><tab><tab>if tag == ""@menu"":<tab><tab><tab><tab><tab>aList.append((""%s %s"" % (tag, name), get_menu_items(child), None))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>b = g.splitLines("""".join(child.b))<tab><tab><tab><tab><tab>aList.append((tag, name, b[0] if b else """"))<tab><tab><tab><tab>break<tab>return aList",1,if child . h . startswith ( tag ) :,if child . h . startswith ( tag ) :,0.75,100.00000000000004,1.0
"def __init__(self, *args, **kw):<tab>if len(args) > 1:<tab><tab>raise TypeError(""MultiDict can only be called with one positional "" ""argument"")<tab>if args:<tab><tab>if hasattr(args[0], ""iteritems""):<tab><tab><tab>items = list(args[0].iteritems())<tab><tab><IF-STMT><tab><tab><tab>items = list(args[0].items())<tab><tab>else:<tab><tab><tab>items = list(args[0])<tab><tab>self._items = items<tab>else:<tab><tab>self._items = []<tab>if kw:<tab><tab>self._items.extend(kw.items())",1,"elif hasattr ( args [ 0 ] , ""items"" ) :","elif hasattr ( args [ 0 ] , ""items"" ) :",0.75,100.00000000000004,1.0
"def open(self) -> ""KeyValueDb"":<tab>""""""Create a new data base or open existing one""""""<tab>if os.path.exists(self._name):<tab><tab>if not os.path.isfile(self._name):<tab><tab><tab>raise IOError(""%s exists and is not a file"" % self._name)<tab><tab><IF-STMT><tab><tab><tab># ignore empty files<tab><tab><tab>return self<tab><tab>with open(self._name, ""rb"") as _in:  # binary mode<tab><tab><tab>self.set_records(pickle.load(_in))<tab>else:<tab><tab># make sure path exists<tab><tab>mkpath(os.path.dirname(self._name))<tab><tab>self.commit()<tab>return self",1,if os . path . getsize ( self . _name ) == 0 :,if os . path . getsize ( self . _name ) == 0 :,0.75,100.00000000000004,1.0
"def sortModules(self):<tab>super(NeuronDecomposableNetwork, self).sortModules()<tab>self._constructParameterInfo()<tab># contains a list of lists of indices<tab>self.decompositionIndices = {}<tab>for neuron in self._neuronIterator():<tab><tab>self.decompositionIndices[neuron] = []<tab>for w in range(self.paramdim):<tab><tab>inneuron, outneuron = self.paramInfo[w]<tab><tab><IF-STMT><tab><tab><tab>self.decompositionIndices[inneuron].append(w)<tab><tab>else:<tab><tab><tab>self.decompositionIndices[outneuron].append(w)",0,if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules :,if inneuron in self . decompositionIndices :,0.12225970785374402,10.218289380194191,0.15584415584415587
"def visit_Options(self, node: qlast.Options) -> None:<tab>for i, opt in enumerate(node.options.values()):<tab><tab><IF-STMT><tab><tab><tab>self.write("" "")<tab><tab>self.write(opt.name)<tab><tab>if not isinstance(opt, qlast.Flag):<tab><tab><tab>self.write(f"" {opt.val}"")",0,if i > 0 :,"if not isinstance ( opt , qlast . Option ) :",0.0237537216033675,4.456882760699063,0.19658119658119658
"def is_child_of(self, item_hash, possible_child_hash):<tab>if self.get_last(item_hash) != self.get_last(possible_child_hash):<tab><tab>return None<tab>while True:<tab><tab>if possible_child_hash == item_hash:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>possible_child_hash = self.items[possible_child_hash].previous_hash",0,if possible_child_hash not in self . items :,if self . items [ possible_child_hash ] . previous_hash != item_hash :,0.06702404264166083,24.04315522172745,0.3125
"def __call__(self, text, **kargs):<tab>words = jieba.tokenize(text, mode=""search"")<tab>token = Token()<tab>for (w, start_pos, stop_pos) in words:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>token.original = token.text = w<tab><tab>token.pos = start_pos<tab><tab>token.startchar = start_pos<tab><tab>token.endchar = stop_pos<tab><tab>yield token",0,if not accepted_chars . match ( w ) and len ( w ) <= 1 :,if w == 0 :,0.00668934303836217,1.3149916698553998,0.19576719576719576
"def test_analysis_jobs_cypher_syntax(neo4j_session):<tab>parameters = {<tab><tab>""AWS_ID"": None,<tab><tab>""UPDATE_TAG"": None,<tab><tab>""OKTA_ORG_ID"": None,<tab>}<tab>for job_name in contents(""cartography.data.jobs.analysis""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>cartography.util.run_analysis_job(job_name, neo4j_session, parameters)<tab><tab>except Exception as e:<tab><tab><tab>pytest.fail(<tab><tab><tab><tab>f""run_analysis_job failed for analysis job '{job_name}' with exception: {e}""<tab><tab><tab>)",0,"if not job_name . endswith ( "".json"" ) :","if not job_name . endswith ( "".py"" ) :",0.5818820875411705,78.25422900366432,1.0
"def _interleave_dataset_results_and_tensors(dataset_results, flat_run_tensors):<tab>flattened_results = []<tab>for idx in range(len(dataset_results) + len(flat_run_tensors)):<tab><tab><IF-STMT><tab><tab><tab>flattened_results.append(dataset_results[idx])<tab><tab>else:<tab><tab><tab>flattened_results.append(flat_run_tensors.pop(0))<tab>return flattened_results",0,if dataset_results . get ( idx ) :,if len ( flat_run_tensors ) == 1 :,0.08287303658844915,4.6192151051305474,0.3333333333333333
"def test_k_is_stochastic_parameter(self):<tab># k as stochastic parameter<tab>aug = iaa.MedianBlur(k=iap.Choice([3, 5]))<tab>seen = [False, False]<tab>for i in sm.xrange(100):<tab><tab>observed = aug.augment_image(self.base_img)<tab><tab><IF-STMT><tab><tab><tab>seen[0] += True<tab><tab>elif np.array_equal(observed, self.blur5x5):<tab><tab><tab>seen[1] += True<tab><tab>else:<tab><tab><tab>raise Exception(""Unexpected result in MedianBlur@2"")<tab><tab>if all(seen):<tab><tab><tab>break<tab>assert np.all(seen)",1,"if np . array_equal ( observed , self . blur3x3 ) :","if np . array_equal ( observed , self . blur3x3 ) :",0.75,100.00000000000004,1.0
"def pickPath(self, color):<tab>self.path[color] = ()<tab>currentPos = self.starts[color]<tab>while True:<tab><tab>minDist = None<tab><tab>minGuide = None<tab><tab>for guide in self.guides[color]:<tab><tab><tab>guideDist = dist(currentPos, guide)<tab><tab><tab>if minDist == None or guideDist < minDist:<tab><tab><tab><tab>minDist = guideDist<tab><tab><tab><tab>minGuide = guide<tab><tab>if dist(currentPos, self.ends[color]) == 1:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.path[color] = self.path[color] + (minGuide,)<tab><tab>currentPos = minGuide<tab><tab>self.guides[color].remove(minGuide)",0,if minGuide == None :,if minGuide is None :,0.08141502097923063,24.736929544091932,0.5333333333333333
"def UpdateRepository(self):<tab>if hasattr(self, ""commit_update""):<tab><tab><IF-STMT><tab><tab><tab>if not path.isdir("".git/""):<tab><tab><tab><tab>self.gitZipRepo()<tab><tab><tab>call([""git"", ""reset"", ""--hard"", ""origin/{}"".format(self.getBranch)])<tab><tab><tab>self.ProcessCall_([""git"", ""pull"", ""origin"", self.getBranch])<tab><tab><tab>self.ProcessCall_([""pip"", ""install"", ""-r"", ""requirements.txt""])",0,"if self . commit_update [ ""Updates"" ] != [ ] :",if self . commit_update ( ) :,0.12785238731240015,28.046732918876714,1.0
"def callback(result=Cr.NS_OK, message=None, success=None):<tab>if success is None:<tab><tab><IF-STMT><tab><tab><tab>success = Ci.koIAsyncCallback.RESULT_SUCCESSFUL<tab><tab>else:<tab><tab><tab>success = Ci.koIAsyncCallback.RESULT_ERROR<tab>data = Namespace(result=result, message=message, _com_interfaces_=[Ci.koIErrorInfo])<tab>self._invoke_activate_callbacks(success, data)",0,if Cr . NS_SUCCEEDED ( result ) :,if result == cr . NS_OK :,0.020676460041600547,18.575057999133595,0.5
"def get_location(device):<tab>location = []<tab>node = device<tab>while node:<tab><tab>position = node.get_position() or """"<tab><tab><IF-STMT><tab><tab><tab>position = "" [%s]"" % position<tab><tab>location.append(node.name + position)<tab><tab>node = node.parent<tab>return "" / "".join(reversed(location))",0,if position :,"if isinstance ( position , str ) :",0.046522600101893324,1e-10,0.36
"def load_checkpoint(path, model, optimizer, reset_optimizer):<tab>global global_step<tab>global global_epoch<tab>print(""Load checkpoint from: {}"".format(path))<tab>checkpoint = _load(path)<tab>model.load_state_dict(checkpoint[""state_dict""])<tab>if not reset_optimizer:<tab><tab>optimizer_state = checkpoint[""optimizer""]<tab><tab><IF-STMT><tab><tab><tab>print(""Load optimizer state from {}"".format(path))<tab><tab><tab>optimizer.load_state_dict(checkpoint[""optimizer""])<tab>global_step = checkpoint[""global_step""]<tab>global_epoch = checkpoint[""global_epoch""]<tab>return model",1,if optimizer_state is not None :,if optimizer_state is not None :,0.75,100.00000000000004,1.0
"def run_command(self, command: str, data: Dict[str, object]) -> Dict[str, object]:<tab>""""""Run a specific command from the registry.""""""<tab>key = ""cmd_"" + command<tab>method = getattr(self.__class__, key, None)<tab>if method is None:<tab><tab>return {""error"": ""Unrecognized command '%s'"" % command}<tab>else:<tab><tab><IF-STMT><tab><tab><tab># Only the above commands use some error formatting.<tab><tab><tab>del data[""is_tty""]<tab><tab><tab>del data[""terminal_width""]<tab><tab>return method(self, **data)",0,"if command not in { ""check"" , ""recheck"" , ""run"" } :","if ""is_tty"" in data and ""terminal_width"" in data :",0.012099187992702817,3.507403512641166,0.2653061224489796
"def call_init(self, node, instance):<tab># Call __init__ on each binding.<tab>for b in instance.bindings:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._initialized_instances.add(b.data)<tab><tab>node = self._call_init_on_binding(node, b)<tab>return node",1,if b . data in self . _initialized_instances :,if b . data in self . _initialized_instances :,0.75,100.00000000000004,1.0
"def get_request_headers() -> Dict:<tab>url = urlparse(uri)<tab>candidates = [<tab><tab>""%s://%s"" % (url.scheme, url.netloc),<tab><tab>""%s://%s/"" % (url.scheme, url.netloc),<tab><tab>uri,<tab><tab>""*"",<tab>]<tab>for u in candidates:<tab><tab><IF-STMT><tab><tab><tab>headers = dict(DEFAULT_REQUEST_HEADERS)<tab><tab><tab>headers.update(self.config.linkcheck_request_headers[u])<tab><tab><tab>return headers<tab>return {}",1,if u in self . config . linkcheck_request_headers :,if u in self . config . linkcheck_request_headers :,0.75,100.00000000000004,1.0
"def get_next_video_frame(self, skip_empty_frame=True):<tab>if not self.video_format:<tab><tab>return<tab>while True:<tab><tab># We skip video packets which are not video frames<tab><tab># This happens in mkv files for the first few frames.<tab><tab>video_packet = self._get_video_packet()<tab><tab>if video_packet.image == 0:<tab><tab><tab>self._decode_video_packet(video_packet)<tab><tab><IF-STMT><tab><tab><tab>break<tab>if _debug:<tab><tab>print(""Returning"", video_packet)<tab>return video_packet.image",0,if video_packet . image is not None or not skip_empty_frame :,if skip_empty_frame :,0.01723333651944375,1e-10,0.22448979591836735
"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab>if code == Path.MOVETO:<tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab><IF-STMT><tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab>elif code == Path.CURVE4:<tab><tab><tab>ctx.curve_to(*points)<tab><tab>elif code == Path.CLOSEPOLY:<tab><tab><tab>ctx.close_path()",1,elif code == Path . CURVE3 :,elif code == Path . CURVE3 :,0.75,100.00000000000004,1.0
"def __init__(<tab>self, layout, value=None, string=None, *, dtype: np.dtype = np.float64) -> None:<tab>""""""Constructor.""""""<tab>self.layout = layout<tab>if value is None:<tab><tab>if string is None:<tab><tab><tab>self.value = np.zeros((self.layout.gaDims,), dtype=dtype)<tab><tab>else:<tab><tab><tab>self.value = layout.parse_multivector(string).value<tab>else:<tab><tab>self.value = np.array(value)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""value must be a sequence of length %s"" % self.layout.gaDims<tab><tab><tab>)",0,"if self . value . shape != ( self . layout . gaDims , ) :",if len ( self . value ) != self . layout . gaDims :,0.5488083617575322,37.63245937508976,0.5625
"def to_dict(self):<tab>contexts_ = {}<tab>for k, data in self.contexts.items():<tab><tab>data_ = data.copy()<tab><tab>if ""context"" in data_:<tab><tab><tab>del data_[""context""]<tab><tab><IF-STMT><tab><tab><tab>del data_[""loaded""]<tab><tab>contexts_[k] = data_<tab>return dict(contexts=contexts_)",1,"if ""loaded"" in data_ :","if ""loaded"" in data_ :",0.75,100.00000000000004,1.0
"def include_module(module):<tab>if not include_these:<tab><tab>return True<tab>result = False<tab>for check in include_these:<tab><tab>if ""/*"" in check:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab>if (os.getcwd() + ""/"" + check + "".py"") == module:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_status(""Including module: "" + module)<tab>return result",0,if check [ : - 1 ] in module :,"if os . path . isfile ( check + "".py"" ) :",0.01349419472326294,3.4585921141027356,0.2222222222222222
"def extract_from(msg_body, content_type=""text/plain""):<tab>try:<tab><tab>if content_type == ""text/plain"":<tab><tab><tab>return extract_from_plain(msg_body)<tab><tab><IF-STMT><tab><tab><tab>return extract_from_html(msg_body)<tab>except Exception:<tab><tab>log.exception(""ERROR extracting message"")<tab>return msg_body",1,"elif content_type == ""text/html"" :","elif content_type == ""text/html"" :",1.0,100.00000000000004,1.0
"def test_list(self):<tab>self._create_locations()<tab>response = self.client.get(self.geojson_boxedlocation_list_url)<tab>self.assertEqual(response.status_code, 200)<tab>self.assertEqual(len(response.data[""features""]), 2)<tab>for feature in response.data[""features""]:<tab><tab>self.assertIn(""bbox"", feature)<tab><tab>fid = feature[""id""]<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl1.bbox_geometry.extent)<tab><tab>elif fid == 2:<tab><tab><tab>self.assertEqual(feature[""bbox""], self.bl2.bbox_geometry.extent)<tab><tab>else:<tab><tab><tab>self.fail(""Unexpected id: {0}"".format(fid))<tab>BoxedLocation.objects.all().delete()",1,if fid == 1 :,if fid == 1 :,0.75,100.00000000000004,1.0
"def overrideCommand(self, commandName, func):<tab># Override entries in c.k.masterBindingsDict<tab>k = self<tab>d = k.masterBindingsDict<tab>for key in d:<tab><tab>d2 = d.get(key)<tab><tab>for key2 in d2:<tab><tab><tab>bi = d2.get(key2)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>bi.func = func<tab><tab><tab><tab>d2[key2] = bi",0,if bi . commandName == commandName :,if bi is not None :,0.041553059925636515,12.872632311973014,0.39999999999999997
"def _lookup(components, specs, provided, name, i, l):<tab>if i < l:<tab><tab>for spec in specs[i].__sro__:<tab><tab><tab>comps = components.get(spec)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r = _lookup(comps, specs, provided, name, i + 1, l)<tab><tab><tab><tab>if r is not None:<tab><tab><tab><tab><tab>return r<tab>else:<tab><tab>for iface in provided:<tab><tab><tab>comps = components.get(iface)<tab><tab><tab>if comps:<tab><tab><tab><tab>r = comps.get(name)<tab><tab><tab><tab>if r is not None:<tab><tab><tab><tab><tab>return r<tab>return None",1,if comps :,if comps :,0.5311706625951745,1e-10,1.0
"def to_representation(self, value):<tab>old_social_string_fields = [""twitter"", ""github"", ""linkedIn""]<tab>request = self.context.get(""request"")<tab>show_old_format = (<tab><tab>request<tab><tab>and is_deprecated(request.version, self.min_version)<tab><tab>and request.method == ""GET""<tab>)<tab>if show_old_format:<tab><tab>social = value.copy()<tab><tab>for key in old_social_string_fields:<tab><tab><tab>if social.get(key):<tab><tab><tab><tab>social[key] = value[key][0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>social[key] = """"<tab><tab>value = social<tab>return super(SocialField, self).to_representation(value)",0,elif social . get ( key ) == [ ] :,elif not social . get ( key ) :,0.250397818183254,45.22723475922432,0.32051282051282054
"def process_ref_attribute(self, node, array_type=None):<tab>ref = qname_attr(node, ""ref"")<tab>if ref:<tab><tab>ref = self._create_qname(ref)<tab><tab># Some wsdl's reference to xs:schema, we ignore that for now. It<tab><tab># might be better in the future to process the actual schema file<tab><tab># so that it is handled correctly<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>return xsd_elements.RefAttribute(<tab><tab><tab>node.tag, ref, self.schema, array_type=array_type<tab><tab>)",0,"if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :",if ref in self . schema :,0.04282569298264552,1.8324901416400543,0.38095238095238093
"def unescape(text):<tab>""""""Removes '\\' escaping from 'text'.""""""<tab>rv = """"<tab>i = 0<tab>while i < len(text):<tab><tab><IF-STMT><tab><tab><tab>rv += text[i + 1]<tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>rv += text[i]<tab><tab>i += 1<tab>return rv",0,"if i + 1 < len ( text ) and text [ i ] == ""\\"" :","if text [ i ] == ""\\\\"" :",0.1074716737778239,45.42781809921536,0.2546583850931677
"def wait_child_process(signum, frame):<tab>try:<tab><tab>while True:<tab><tab><tab>child_pid, status = os.waitpid(-1, os.WNOHANG)<tab><tab><tab>if child_pid == 0:<tab><tab><tab><tab>stat_logger.info(""no child process was immediately available"")<tab><tab><tab><tab>break<tab><tab><tab>exitcode = status >> 8<tab><tab><tab>stat_logger.info(<tab><tab><tab><tab>""child process %s exit with exitcode %s"", child_pid, exitcode<tab><tab><tab>)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>stat_logger.warning(<tab><tab><tab><tab>""current process has no existing unwaited-for child processes.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise",0,if e . errno == errno . ECHILD :,if e . errno == errno . EINTR :,0.87709085524794,78.25422900366438,0.6666666666666666
"def translate_from_sortname(name, sortname):<tab>""""""'Translate' the artist name by reversing the sortname.""""""<tab>for c in name:<tab><tab>ctg = unicodedata.category(c)<tab><tab>if ctg[0] == ""L"" and unicodedata.name(c).find(""LATIN"") == -1:<tab><tab><tab>for separator in ("" & "", ""; "", "" and "", "" vs. "", "" with "", "" y ""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>parts = sortname.split(separator)<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>parts = [sortname]<tab><tab><tab><tab>separator = """"<tab><tab><tab>return separator.join(map(_reverse_sortname, parts))<tab>return name",0,if separator in sortname :,if sortname . startswith ( separator ) :,0.029323260600185464,7.809849842300637,0.3333333333333333
"def python_value(self, value):<tab>if value:<tab><tab><IF-STMT><tab><tab><tab>pp = lambda x: x.time()<tab><tab><tab>return format_date_time(value, self.formats, pp)<tab><tab>elif isinstance(value, datetime.datetime):<tab><tab><tab>return value.time()<tab>if value is not None and isinstance(value, datetime.timedelta):<tab><tab>return (datetime.datetime.min + value).time()<tab>return value",0,"if isinstance ( value , basestring ) :","if isinstance ( value , datetime . date ) :",0.2633400423728968,45.180100180492246,0.5584415584415584
"def __init__(self, fileobj, info):<tab>pages = []<tab>complete = False<tab>while not complete:<tab><tab>page = OggPage(fileobj)<tab><tab><IF-STMT><tab><tab><tab>pages.append(page)<tab><tab><tab>complete = page.complete or (len(page.packets) > 1)<tab>data = OggPage.to_packets(pages)[0][7:]<tab>super(OggTheoraCommentDict, self).__init__(data, framing=False)<tab>self._padding = len(data) - self._size",0,if page . serial == info . serial :,if page . info == info :,0.3933922660661427,27.98263237576258,0.711111111111111
"def configure(self):<tab># hack to configure 'from_' and 'to' and avoid exception<tab>if ""from_"" in self.wmeta.properties:<tab><tab>from_ = float(self.wmeta.properties[""from_""])<tab><tab>to = float(self.wmeta.properties.get(""to"", 0))<tab><tab><IF-STMT><tab><tab><tab>to = from_ + 1<tab><tab><tab>self.wmeta.properties[""to""] = str(to)<tab>super(TKSpinbox, self).configure()",0,if from_ > to :,if from_ < to :,0.08141502097923063,37.99178428257963,1.0
"def get_error_diagnostics(self):<tab>diagnostics = []<tab>if self.stdout is not None:<tab><tab>with open(self.stdout.name) as fds:<tab><tab><tab>contents = fds.read().strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diagnostics.append(""ab STDOUT:\n"" + contents)<tab>if self.stderr is not None:<tab><tab>with open(self.stderr.name) as fds:<tab><tab><tab>contents = fds.read().strip()<tab><tab><tab>if contents.strip():<tab><tab><tab><tab>diagnostics.append(""ab STDERR:\n"" + contents)<tab>return diagnostics",1,if contents . strip ( ) :,if contents . strip ( ) :,0.75,100.00000000000004,1.0
"def set_environment_vars(env, source_env):<tab>""""""Copy allowed environment variables from |source_env|.""""""<tab>if not source_env:<tab><tab>return<tab>for name, value in six.iteritems(source_env):<tab><tab><IF-STMT><tab><tab><tab># Avoid creating circular dependencies from importing environment by<tab><tab><tab># using os.getenv.<tab><tab><tab>if os.getenv(""TRUSTED_HOST"") and should_rebase_environment_value(name):<tab><tab><tab><tab>value = file_host.rebase_to_worker_root(value)<tab><tab><tab>env[name] = value",0,if is_forwarded_environment_variable ( name ) :,if os . path . isdir ( name ) and os . path . isdir ( name ) :,0.23293270383073875,13.400825781778892,0.24175824175824176
"def update_content(self, more_content: StringList) -> None:<tab>if isinstance(self.object, TypeVar):<tab><tab>attrs = [repr(self.object.__name__)]<tab><tab>for constraint in self.object.__constraints__:<tab><tab><tab>attrs.append(stringify_typehint(constraint))<tab><tab>if self.object.__covariant__:<tab><tab><tab>attrs.append(""covariant=True"")<tab><tab><IF-STMT><tab><tab><tab>attrs.append(""contravariant=True"")<tab><tab>more_content.append(_(""alias of TypeVar(%s)"") % "", "".join(attrs), """")<tab><tab>more_content.append("""", """")<tab>super().update_content(more_content)",1,if self . object . __contravariant__ :,if self . object . __contravariant__ :,0.75,100.00000000000004,1.0
"def after(self, event, state):<tab>group = event.group<tab>for plugin in self.get_plugins():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>metrics.incr(""notifications.sent"", instance=plugin.slug)<tab><tab>yield self.future(plugin.rule_notify)",0,"if not safe_execute ( plugin . should_notify , group = group , event = event ) :",if plugin . rule_notify is None :,0.04438476037296145,3.933852380954249,0.23369565217391303
"def distinct(expr, *on):<tab>fields = frozenset(expr.fields)<tab>_on = []<tab>append = _on.append<tab>for n in on:<tab><tab>if isinstance(n, Field):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n = n._name<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>if not isinstance(n, _strtypes):<tab><tab><tab>raise TypeError(""on must be a name or field, not: {0}"".format(n))<tab><tab>elif n not in fields:<tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>append(n)<tab>return Distinct(expr, tuple(_on))",0,if n . _child . isidentical ( expr ) :,if n . _name :,0.056958074105344536,23.350308364304226,0.5714285714285714
"def build_filter(arg):<tab>filt = {}<tab>if arg is not None:<tab><tab><IF-STMT><tab><tab><tab>raise UserError(""Arguments to --filter should be in form KEY=VAL"")<tab><tab>key, val = arg.split(""="", 1)<tab><tab>filt[key] = val<tab>return filt",1,"if ""="" not in arg :","if ""="" not in arg :",0.75,100.00000000000004,1.0
"def pickline(file, key, casefold=1):<tab>try:<tab><tab>f = open(file, ""r"")<tab>except IOError:<tab><tab>return None<tab>pat = re.escape(key) + "":""<tab>prog = re.compile(pat, casefold and re.IGNORECASE)<tab>while 1:<tab><tab>line = f.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>text = line[len(key) + 1 :]<tab><tab><tab>while 1:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if not line or not line[0].isspace():<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>text = text + line<tab><tab><tab>return text.strip()<tab>return None",0,if prog . match ( line ) :,if prog . search ( line ) :,0.5014622369176811,50.000000000000014,0.6666666666666666
"def delete_doc(elastic_document_id, node, index=None, category=None):<tab>index = index or INDEX<tab>if not category:<tab><tab><IF-STMT><tab><tab><tab>category = ""preprint""<tab><tab>elif node.is_registration:<tab><tab><tab>category = ""registration""<tab><tab>else:<tab><tab><tab>category = node.project_or_component<tab>client().delete(<tab><tab>index=index,<tab><tab>doc_type=category,<tab><tab>id=elastic_document_id,<tab><tab>refresh=True,<tab><tab>ignore=[404],<tab>)",0,"if isinstance ( node , Preprint ) :",if node . is_preprint :,0.019907917998500824,7.492442692259767,0.36
"def update(self, preds, labels):<tab>if not _is_numpy_(labels):<tab><tab>raise ValueError(""The 'labels' must be a numpy ndarray."")<tab>if not _is_numpy_(preds):<tab><tab>raise ValueError(""The 'predictions' must be a numpy ndarray."")<tab>for i, lbl in enumerate(labels):<tab><tab>value = preds[i, 1]<tab><tab>bin_idx = int(value * self._num_thresholds)<tab><tab>assert bin_idx <= self._num_thresholds<tab><tab><IF-STMT><tab><tab><tab>self._stat_pos[bin_idx] += 1.0<tab><tab>else:<tab><tab><tab>self._stat_neg[bin_idx] += 1.0",0,if lbl :,"if lbl == ""pos"" :",0.09791453445388575,1e-10,1.0
"def checkStatusClient(self):<tab>if str(self.comboxBoxIPAddress.currentText()) != """":<tab><tab><IF-STMT><tab><tab><tab>self.btnEnable.setEnabled(False)<tab><tab><tab>self.btncancel.setEnabled(True)<tab><tab><tab>return None<tab><tab>self.btnEnable.setEnabled(True)<tab><tab>self.btncancel.setEnabled(False)",0,"if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :",if self . comboxBoxIPAddress . currentIndex ( ) == 0 :,0.18608007293901516,13.777776425520553,0.28835978835978837
"def colorizeDiffs(sheet, col, row, cellval):<tab>if not row or not col:<tab><tab>return None<tab>vcolidx = sheet.visibleCols.index(col)<tab>rowidx = sheet.rows.index(row)<tab>if vcolidx < len(othersheet.visibleCols) and rowidx < len(othersheet.rows):<tab><tab>otherval = othersheet.visibleCols[vcolidx].getDisplayValue(<tab><tab><tab>othersheet.rows[rowidx]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ""color_diff""<tab>else:<tab><tab>return ""color_diff_add""",0,if cellval . display != otherval :,if otherval != cellval :,0.026238743897562457,15.308225934212231,0.37142857142857144
"def identwaf(self, findall=False):<tab>detected = list()<tab>try:<tab><tab>self.attackres = self.performCheck(self.centralAttack)<tab>except RequestBlocked:<tab><tab>return detected<tab>for wafvendor in self.checklist:<tab><tab>self.log.info(""Checking for %s"" % wafvendor)<tab><tab><IF-STMT><tab><tab><tab>detected.append(wafvendor)<tab><tab><tab>if not findall:<tab><tab><tab><tab>break<tab>self.knowledge[""wafname""] = detected<tab>return detected",0,if self . wafdetections [ wafvendor ] ( self ) :,if wafvendor not in detected :,0.012931044534344783,4.642454187453896,0.25
"def get_repository_metadata_by_repository_id_changeset_revision(<tab>app, id, changeset_revision, metadata_only=False):<tab>""""""Get a specified metadata record for a specified repository in the tool shed.""""""<tab>if metadata_only:<tab><tab>repository_metadata = get_repository_metadata_by_changeset_revision(<tab><tab><tab>app, id, changeset_revision<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return repository_metadata.metadata<tab><tab>return None<tab>return get_repository_metadata_by_changeset_revision(app, id, changeset_revision)",0,if repository_metadata and repository_metadata . metadata :,if repository_metadata :,0.03885753308224148,1e-10,0.45
"def getmultiline(self):<tab>line = self.getline()<tab>if line[3:4] == ""-"":<tab><tab>code = line[:3]<tab><tab>while 1:<tab><tab><tab>nextline = self.getline()<tab><tab><tab>line = line + (""\n"" + nextline)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return line",0,"if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :",if code == nextline :,0.005940504861532455,1.4844687933534808,0.2571428571428572
"def _validate_reports(value, *args, **kwargs):<tab>from osf.models import OSFUser<tab>for key, val in value.items():<tab><tab>if not OSFUser.load(key):<tab><tab><tab>raise ValidationValueError(""Keys must be user IDs"")<tab><tab><IF-STMT><tab><tab><tab>raise ValidationTypeError(""Values must be dictionaries"")<tab><tab>if (<tab><tab><tab>""category"" not in val<tab><tab><tab>or ""text"" not in val<tab><tab><tab>or ""date"" not in val<tab><tab><tab>or ""retracted"" not in val<tab><tab>):<tab><tab><tab>raise ValidationValueError(<tab><tab><tab><tab>(""Values must include `date`, `category`, "", ""`text`, `retracted` keys"")<tab><tab><tab>)",1,"if not isinstance ( val , dict ) :","if not isinstance ( val , dict ) :",0.75,100.00000000000004,1.0
"def deselectItem(self, item):<tab>if self.isSelected(item):<tab><tab><IF-STMT><tab><tab><tab>listItem = self._getListItem(item)<tab><tab><tab>selections = self.getSelectedItems()<tab><tab><tab>selections.remove(self.loadHandler.getSelection(listItem))<tab><tab><tab>self.setSelections(selections)<tab><tab>else:<tab><tab><tab>self.deselectAll()",0,if self . multiSelect :,if self . loadHandler :,0.39477865547525276,42.72870063962342,0.6
"def __init__(self, **kwargs):<tab>if self.name is None:<tab><tab>raise RuntimeError(""RenderPrimitive cannot be used directly"")<tab>self.option_values = {}<tab>for key, val in kwargs.items():<tab><tab>if not key in self.options:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""primitive `{0}' has no option `{1}'"".format(self.name, key)<tab><tab><tab>)<tab><tab>self.option_values[key] = val<tab># set up defaults<tab>for name, (description, default) in self.options.items():<tab><tab><IF-STMT><tab><tab><tab>self.option_values[name] = default",0,if not name in self . option_values :,"if description == ""default"" :",0.01858685153282265,5.11459870708889,0.23809523809523808
"def setup_smart_indent(self, view, lang):<tab># Configure a ""per-view"" instance<tab>if type(view) == gedit.View:<tab><tab><IF-STMT><tab><tab><tab>setattr(view, ""smart_indent_instance"", SmartIndent())<tab><tab><tab>handler_id = view.connect(<tab><tab><tab><tab>""key-press-event"", view.smart_indent_instance.key_press_handler<tab><tab><tab>)<tab><tab><tab>self.handler_ids.append((handler_id, view))<tab><tab>view.smart_indent_instance.set_language(lang, view)",0,"if getattr ( view , ""smart_indent_instance"" , False ) == False :","if hasattr ( view , ""smart_indent_instance"" ) :",0.12381110349048008,50.56231736827433,0.4791666666666667
"def get_strings_of_set(word, char_set, threshold=20):<tab>count = 0<tab>letters = """"<tab>strings = []<tab>for char in word:<tab><tab><IF-STMT><tab><tab><tab>letters += char<tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab>if count > threshold:<tab><tab><tab><tab>strings.append(letters)<tab><tab><tab>letters = """"<tab><tab><tab>count = 0<tab>if count > threshold:<tab><tab>strings.append(letters)<tab>return strings",1,if char in char_set :,if char in char_set :,0.75,100.00000000000004,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_logout_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
def __create_table(self):<tab>for i in range(256):<tab><tab>crcreg = i<tab><tab>for j in range(8):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>crcreg = self.__CRCPOLYNOMIAL ^ (crcreg >> 1)<tab><tab><tab>else:<tab><tab><tab><tab>crcreg >>= 1<tab><tab>self.__crctable[i] = crcreg,0,if ( crcreg & 1 ) != 0 :,if j == 0 :,0.07994275069846186,16.669006580554246,0.3181818181818182
"def destroy(self):<tab>""""""Flush all entries and empty cache""""""<tab># Note: this method is currently also used for dropping the cache<tab>for i in range(len(self.cached_rows)):<tab><tab>id_ = self.cached_rows[i]<tab><tab>self.cached_rows[i] = None<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>inode = self.attrs[id_]<tab><tab><tab>except KeyError:<tab><tab><tab><tab># We may have deleted that inode<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>del self.attrs[id_]<tab><tab><tab><tab>self.setattr(inode)<tab>assert len(self.attrs) == 0",0,if id_ is not None :,if id_ :,0.050438393472541504,1e-10,0.3142857142857143
"def set_config(self):<tab>""""""Set configuration options for QTextEdit.""""""<tab>c = self.c<tab>w = self.widget<tab>w.setWordWrapMode(QtGui.QTextOption.NoWrap)<tab>if 0:  # This only works when there is no style sheet.<tab><tab>n = c.config.getInt(""qt-rich-text-zoom-in"")<tab><tab><IF-STMT><tab><tab><tab>w.zoomIn(n)<tab><tab><tab>w.updateMicroFocus()<tab># tab stop in pixels - no config for this (yet)<tab>w.setTabStopWidth(24)",0,"if n not in ( None , 0 ) :",if n > 0 :,0.026933810325055336,9.346579571601447,0.38961038961038963
"def mouseDragEvent(self, ev):<tab>if self.movable and ev.button() == QtCore.Qt.LeftButton:<tab><tab>if ev.isStart():<tab><tab><tab>self.moving = True<tab><tab><tab>self.cursorOffset = self.pos() - self.mapToParent(ev.buttonDownPos())<tab><tab><tab>self.startPosition = self.pos()<tab><tab>ev.accept()<tab><tab>if not self.moving:<tab><tab><tab>return<tab><tab>self.setPos(self.cursorOffset + self.mapToParent(ev.pos()))<tab><tab>self.sigDragged.emit(self)<tab><tab><IF-STMT><tab><tab><tab>self.moving = False<tab><tab><tab>self.sigPositionChangeFinished.emit(self)",0,if ev . isFinish ( ) :,elif ev . isFinish ( ) :,0.3829408981789566,80.91067115702207,0.6
"def reparentChildren(self, newParent):<tab>if newParent.childNodes:<tab><tab>newParent.childNodes[-1]._element.tail += self._element.text<tab>else:<tab><tab>if not newParent._element.text:<tab><tab><tab>newParent._element.text = """"<tab><tab><IF-STMT><tab><tab><tab>newParent._element.text += self._element.text<tab>self._element.text = """"<tab>base.Node.reparentChildren(self, newParent)",0,if self . _element . text is not None :,elif self . _element . text :,0.1992846805167246,48.59869096699083,0.34090909090909094
"def _no_sp_or_bp(self, bl):<tab>for s in bl.vex.statements:<tab><tab>for e in chain([s], s.expressions):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>reg = self.get_reg_name(self.project.arch, e.offset)<tab><tab><tab><tab>if reg == ""ebp"" or reg == ""esp"":<tab><tab><tab><tab><tab>return False<tab><tab><tab>elif e.tag == ""Ist_Put"":<tab><tab><tab><tab>reg = self.get_reg_name(self.project.arch, e.offset)<tab><tab><tab><tab>if reg == ""ebp"" or reg == ""esp"":<tab><tab><tab><tab><tab>return False<tab>return True",0,"if e . tag == ""Iex_Get"" :","if e . tag == ""Ist_Get"" :",0.574113272471593,73.48889200874659,1.0
"def _get_import_chain(self, *, until=None):<tab>stack = inspect.stack()[2:]<tab>try:<tab><tab>for frameinfo in stack:<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>data = dedent("""".join(frameinfo.code_context))<tab><tab><tab><tab>if data.strip() == until:<tab><tab><tab><tab><tab>raise StopIteration<tab><tab><tab><tab>yield frameinfo.filename, frameinfo.lineno, data.strip()<tab><tab><tab><tab>del data<tab><tab><tab>finally:<tab><tab><tab><tab>del frameinfo<tab>finally:<tab><tab>del stack",0,if not frameinfo . code_context :,if frameinfo . code_context is None :,0.10494632798085189,48.54917717073236,0.30952380952380953
"def stream_docker_log(log_stream):<tab>async for line in log_stream:<tab><tab>if ""stream"" in line and line[""stream""].strip():<tab><tab><tab>logger.debug(line[""stream""].strip())<tab><tab>elif ""status"" in line:<tab><tab><tab>logger.debug(line[""status""].strip())<tab><tab><IF-STMT><tab><tab><tab>logger.error(line[""error""].strip())<tab><tab><tab>raise DockerBuildError",1,"elif ""error"" in line :","elif ""error"" in line :",0.75,100.00000000000004,1.0
"def get_cycle_path(self, curr_node, goal_node_index):<tab>for dep in curr_node[""deps""]:<tab><tab>if dep == goal_node_index:<tab><tab><tab>return [curr_node[""address""]]<tab>for dep in curr_node[""deps""]:<tab><tab>path = self.get_cycle_path(<tab><tab><tab>self.get_by_address(dep), goal_node_index<tab><tab>)  # self.nodelist[dep], goal_node_index)<tab><tab><IF-STMT><tab><tab><tab>path.insert(0, curr_node[""address""])<tab><tab><tab>return path<tab>return []",0,if len ( path ) > 0 :,if path :,0.017267079824235865,1e-10,0.36
"def prompt(default=None):<tab>editor = ""nano""<tab>with tempfile.NamedTemporaryFile(mode=""r+"") as tmpfile:<tab><tab><IF-STMT><tab><tab><tab>tmpfile.write(default)<tab><tab><tab>tmpfile.flush()<tab><tab>child_pid = os.fork()<tab><tab>is_child = child_pid == 0<tab><tab>if is_child:<tab><tab><tab>os.execvp(editor, [editor, tmpfile.name])<tab><tab>else:<tab><tab><tab>os.waitpid(child_pid, 0)<tab><tab><tab>tmpfile.seek(0)<tab><tab><tab>return tmpfile.read().strip()",0,if default :,if default is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def _get_annotated_template(self, template):<tab>changed = False<tab>if template.get(""version"", ""0.12.0"") >= ""0.13.0"":<tab><tab>using_js = self.spider._filter_js_urls(template[""url""])<tab><tab>body = ""rendered_body"" if using_js else ""original_body""<tab><tab><IF-STMT><tab><tab><tab>template[""body""] = body<tab><tab><tab>changed = True<tab>if changed or not template.get(""annotated""):<tab><tab>_build_sample(template)<tab>return template",0,"if template . get ( ""body"" ) != body :",if using_js and body :,0.025595153496315533,6.168585410281235,0.32051282051282054
"def collect(self, paths):<tab>for path in paths or ():<tab><tab>relpath = os.path.relpath(path, self._artifact_root)<tab><tab>dst = os.path.join(self._directory, relpath)<tab><tab>safe_mkdir(os.path.dirname(dst))<tab><tab><IF-STMT><tab><tab><tab>shutil.copytree(path, dst)<tab><tab>else:<tab><tab><tab>shutil.copy(path, dst)<tab><tab>self._relpaths.add(relpath)",1,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1.0,100.00000000000004,1.0
"def dependencies(context=None):<tab>""""""Return all dependencies detected by knowit.""""""<tab>deps = OrderedDict([])<tab>try:<tab><tab>initialize(context)<tab><tab>for name, provider_cls in _provider_map.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>deps[name] = available_providers[name].version<tab><tab><tab>else:<tab><tab><tab><tab>deps[name] = {}<tab>except Exception:<tab><tab>pass<tab>return deps",0,if name in available_providers :,if provider_cls in available_providers :,0.39477865547525276,46.713797772819994,0.45
"def _getaddrinfo(self, host_bytes, port, family, socktype, proto, flags):<tab>while True:<tab><tab>ares = self.cares<tab><tab>try:<tab><tab><tab>return self.__getaddrinfo(host_bytes, port, family, socktype, proto, flags)<tab><tab>except gaierror:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",0,if ares is self . cares :,if ares is None :,0.17786562443781362,28.641904579795423,0.5428571428571428
"def write_entries(cmd, basename, filename):<tab>ep = cmd.distribution.entry_points<tab>if isinstance(ep, basestring) or ep is None:<tab><tab>data = ep<tab>elif ep is not None:<tab><tab>data = []<tab><tab>for section, contents in ep.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>contents = EntryPoint.parse_group(section, contents)<tab><tab><tab><tab>contents = ""\n"".join(map(str, contents.values()))<tab><tab><tab>data.append(""[%s]\n%s\n\n"" % (section, contents))<tab><tab>data = """".join(data)<tab>cmd.write_or_delete_file(""entry points"", filename, data, True)",0,"if not isinstance ( contents , basestring ) :","if isinstance ( contents , dict ) :",0.1884566599936256,37.70794596593207,0.2698412698412698
"def _highlight_do(self):<tab>new_hl_text = self.highlight_text.text()<tab>if new_hl_text != self.hl_text:<tab><tab>self.hl_text = new_hl_text<tab><tab>if self.hl is not None:<tab><tab><tab>self.hl.setDocument(None)<tab><tab><tab>self.hl = None<tab><tab><IF-STMT><tab><tab><tab>self.hl = Highlighter(self.hl_text, parent=self.doc)<tab><tab>self.clear_highlight_button.setEnabled(bool(self.hl))",0,if self . hl_text :,if self . highlight_text . text ( ) != self .hl_text :,0.17932285892008554,30.433504843242837,0.6388888888888888
"def traverse(node, functions=[]):<tab>if hasattr(node, ""grad_fn""):<tab><tab>node = node.grad_fn<tab>if hasattr(node, ""variable""):<tab><tab>node = graph.nodes_by_id.get(id(node.variable))<tab><tab><IF-STMT><tab><tab><tab>node.functions = list(functions)<tab><tab><tab>del functions[:]<tab>if hasattr(node, ""next_functions""):<tab><tab>functions.append(type(node).__name__)<tab><tab>for f in node.next_functions:<tab><tab><tab>if f[0]:<tab><tab><tab><tab>functions.append(type(f[0]).__name__)<tab><tab><tab><tab>traverse(f[0], functions)<tab>if hasattr(node, ""saved_tensors""):<tab><tab>for t in node.saved_tensors:<tab><tab><tab>traverse(t)",0,if node :,if functions :,0.3197504490129165,1e-10,0.5
"def compress(self, data_list):<tab>if data_list:<tab><tab>page_id = data_list[1]<tab><tab>if page_id in EMPTY_VALUES:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>raise forms.ValidationError(self.error_messages[""invalid_page""])<tab><tab>return Page.objects.get(pk=page_id)<tab>return None",0,if not self . required :,if page_id == 0 :,0.02713659235259708,6.567274736060395,0.27777777777777773
"def test_field_attr_existence(self):<tab>for name, item in ast.__dict__.items():<tab><tab>if self._is_ast_node(name, item):<tab><tab><tab>if name == ""Index"":<tab><tab><tab><tab># Index(value) just returns value now.<tab><tab><tab><tab># The argument is required.<tab><tab><tab><tab>continue<tab><tab><tab>x = item()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(type(x._fields), tuple)",0,"if isinstance ( x , ast . AST ) :","if isinstance ( x , ast . Field ) :",0.6049399806880458,70.71067811865478,0.7777777777777777
"def handle_starttag(self, tag, attrs):<tab>if tag == ""base"":<tab><tab>self.base_url = dict(attrs).get(""href"")<tab>if self.scan_tag(tag):<tab><tab>for attr, value in attrs:<tab><tab><tab>if self.scan_attr(attr):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>value = strip_html5_whitespace(value)<tab><tab><tab><tab>url = self.process_attr(value)<tab><tab><tab><tab>link = Link(url=url)<tab><tab><tab><tab>self.links.append(link)<tab><tab><tab><tab>self.current_link = link",0,if self . strip :,if self . strip_html5_whitespace :,0.39477865547525276,31.55984539112946,0.7
"def _initialize_asset_map(cls):<tab># Generating a list of acceptable asset files reduces the possibility of<tab># path attacks.<tab>cls._asset_name_to_path = {}<tab>assets = os.listdir(ASSETS_PATH)<tab>for asset in assets:<tab><tab>path = os.path.join(ASSETS_PATH, asset)<tab><tab><IF-STMT><tab><tab><tab>cls._asset_name_to_path[os.path.basename(path)] = path",1,if os . path . isfile ( path ) :,if os . path . isfile ( path ) :,1.0,100.00000000000004,1.0
"def dataReceived(self, data):<tab>self.buf += data<tab>if self._paused:<tab><tab>log.startLogging(sys.stderr)<tab><tab>log.msg(""dataReceived while transport paused!"")<tab><tab>self.transport.loseConnection()<tab>else:<tab><tab>self.transport.write(data)<tab><tab><IF-STMT><tab><tab><tab>self.transport.loseConnection()<tab><tab>else:<tab><tab><tab>self.pause()",0,"if self . buf . endswith ( b""\n0\n"" ) :",if self . _paused :,0.056958074105344536,6.132184825737391,0.5714285714285714
"def test_case_sensitive(self):<tab>with support.EnvironmentVarGuard() as env:<tab><tab>env.unset(""PYTHONCASEOK"")<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""os.environ changes not reflected in "" ""_os.environ"")<tab><tab>loader = self.find_module()<tab><tab>self.assertIsNone(loader)",0,"if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :","if ""PYTHONCASEOK"" not in self . _os . environ :",0.23077854496554287,40.438437976330746,0.3055555555555556
"def manifest(self):<tab>""""""The current manifest dictionary.""""""<tab>if self.reload:<tab><tab>if not self.exists(self.manifest_path):<tab><tab><tab>return {}<tab><tab>mtime = self.getmtime(self.manifest_path)<tab><tab><IF-STMT><tab><tab><tab>self._manifest = self.get_manifest()<tab><tab><tab>self._mtime = mtime<tab>return self._manifest",0,if self . _mtime is None or mtime > self . _mtime :,if mtime != self . _mtime :,0.1884540284178905,24.925978674400294,0.25
"def test_named_parameters_and_constraints(self):<tab>likelihood = gpytorch.likelihoods.GaussianLikelihood()<tab>model = ExactGPModel(None, None, likelihood)<tab>for name, _param, constraint in model.named_parameters_and_constraints():<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.GreaterThan)<tab><tab>elif name == ""mean_module.constant"":<tab><tab><tab>self.assertIsNone(constraint)<tab><tab>elif name == ""covar_module.raw_outputscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)<tab><tab>elif name == ""covar_module.base_kernel.raw_lengthscale"":<tab><tab><tab>self.assertIsInstance(constraint, gpytorch.constraints.Positive)",0,"if name == ""likelihood.noise_covar.raw_noise"" :","if name == ""mean_module"" :",0.39477865547525276,25.637075783866827,1.0
"def process_plugin_result(name, result):<tab>if result:<tab><tab>try:<tab><tab><tab>jsonify(test=result)<tab><tab>except Exception:<tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Error while jsonifying settings from plugin {}, please contact the plugin author about this"".format(<tab><tab><tab><tab><tab>name<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del result[""__enabled""]<tab><tab><tab>data[name] = result",1,"if ""__enabled"" in result :","if ""__enabled"" in result :",0.75,100.00000000000004,1.0
"def benchmarking(net, ctx, num_iteration, datashape=300, batch_size=64):<tab>input_shape = (batch_size, 3) + (datashape, datashape)<tab>data = mx.random.uniform(-1.0, 1.0, shape=input_shape, ctx=ctx, dtype=""float32"")<tab>dryrun = 5<tab>for i in range(dryrun + num_iteration):<tab><tab><IF-STMT><tab><tab><tab>tic = time.time()<tab><tab>ids, scores, bboxes = net(data)<tab><tab>ids.asnumpy()<tab><tab>scores.asnumpy()<tab><tab>bboxes.asnumpy()<tab>toc = time.time() - tic<tab>return toc",0,if i == dryrun :,if i % 100 == 0 :,0.05544914160509713,16.515821590069027,0.4761904761904762
"def merge_weekdays(base_wd, icu_wd):<tab>result = []<tab>for left, right in zip(base_wd, icu_wd):<tab><tab><IF-STMT><tab><tab><tab>result.append(left)<tab><tab><tab>continue<tab><tab>left = set(left.split(""|""))<tab><tab>right = set(right.split(""|""))<tab><tab>result.append(""|"".join(left | right))<tab>return result",0,if left == right :,if not left or not right :,0.05544914160509713,15.619699684601283,0.2333333333333333
"def create_key(self, request):<tab>if self._ignored_parameters:<tab><tab>url, body = self._remove_ignored_parameters(request)<tab>else:<tab><tab>url, body = request.url, request.body<tab>key = hashlib.sha256()<tab>key.update(_to_bytes(request.method.upper()))<tab>key.update(_to_bytes(url))<tab>if request.body:<tab><tab>key.update(_to_bytes(body))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>for name, value in sorted(request.headers.items()):<tab><tab><tab><tab>key.update(_to_bytes(name))<tab><tab><tab><tab>key.update(_to_bytes(value))<tab>return key.hexdigest()",0,if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,if request . headers :,0.08240600370413219,2.2493847365531097,0.30952380952380953
"def test_invalid_mountinfo(self):<tab>line = (<tab><tab>""20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root""<tab><tab>""rw,errors=remount-ro,data=ordered""<tab>)<tab>elements = line.split()<tab>for i in range(len(elements) + 1):<tab><tab>lines = ["" "".join(elements[0:i])]<tab><tab><IF-STMT><tab><tab><tab>expected = None<tab><tab>else:<tab><tab><tab>expected = (""/dev/mapper/vg0-root"", ""ext4"", ""/"")<tab><tab>self.assertEqual(expected, util.parse_mount_info(""/"", lines))",0,if i < 10 :,if i == 0 :,0.31497877230811644,17.965205598154213,0.6
"def nested_filter(self, items, mask):<tab>keep_current = self.current_mask(mask)<tab>keep_nested_lookup = self.nested_masks(mask)<tab>for k, v in items:<tab><tab>keep_nested = keep_nested_lookup.get(k)<tab><tab>if k in keep_current:<tab><tab><tab>if keep_nested is not None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield k, dict(self.nested_filter(v.items(), keep_nested))<tab><tab><tab>else:<tab><tab><tab><tab>yield k, v",1,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,100.00000000000004,1.0
"def traverse_trees(node_pos, sample, trees: List[HeteroDecisionTreeGuest]):<tab>if node_pos[""reach_leaf_node""].all():<tab><tab>return node_pos<tab>for t_idx, tree in enumerate(trees):<tab><tab>cur_node_idx = node_pos[""node_pos""][t_idx]<tab><tab># reach leaf<tab><tab>if cur_node_idx == -1:<tab><tab><tab>continue<tab><tab>rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree(<tab><tab><tab>tree, sample, cur_node_idx<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>node_pos[""reach_leaf_node""][t_idx] = True<tab><tab>node_pos[""node_pos""][t_idx] = rs<tab>return node_pos",0,if reach_leaf :,if not reach_leaf :,0.11348623737539229,1e-10,0.6
"def _pop_waiting_trial_id(self) -> Optional[int]:<tab># TODO(c-bata): Reduce database query counts for extracting waiting trials.<tab>for trial in self._storage.get_all_trials(self._study_id, deepcopy=False):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not self._storage.set_trial_state(trial._trial_id, TrialState.RUNNING):<tab><tab><tab>continue<tab><tab>_logger.debug(""Trial {} popped from the trial queue."".format(trial.number))<tab><tab>return trial._trial_id<tab>return None",0,if trial . state != TrialState . WAITING :,if trial . _trial_id is None :,0.13008931074158556,16.784459625186194,0.3611111111111111
"def get_step_best(self, step_models):<tab>best_score = None<tab>best_model = """"<tab>for model in step_models:<tab><tab>model_info = self.models_trained[model]<tab><tab>score = model_info.get_score()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if best_score is None or score < best_score:<tab><tab><tab>best_score = score<tab><tab><tab>best_model = model<tab>LOGGER.info(f""step {self.n_step}, best model {best_model}"")<tab>return best_model",1,if score is None :,if score is None :,0.75,100.00000000000004,1.0
"def iter_filters(filters, block_end=False):<tab>queue = deque(filters)<tab>while queue:<tab><tab>f = queue.popleft()<tab><tab>if f is not None and f.type in (""or"", ""and"", ""not""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>queue.appendleft(None)<tab><tab><tab>for gf in f.filters:<tab><tab><tab><tab>queue.appendleft(gf)<tab><tab>yield f",1,if block_end :,if block_end :,0.5311706625951745,1e-10,1.0
"def _buffer_decode(self, input, errors, final):<tab>if self.decoder is None:<tab><tab>(output, consumed, byteorder) = codecs.utf_16_ex_decode(input, errors, 0, final)<tab><tab>if byteorder == -1:<tab><tab><tab>self.decoder = codecs.utf_16_le_decode<tab><tab><IF-STMT><tab><tab><tab>self.decoder = codecs.utf_16_be_decode<tab><tab>elif consumed >= 2:<tab><tab><tab>raise UnicodeError(""UTF-16 stream does not start with BOM"")<tab><tab>return (output, consumed)<tab>return self.decoder(input, self.errors, final)",1,elif byteorder == 1 :,elif byteorder == 1 :,1.0,100.00000000000004,1.0
"def _load_db(self):<tab>try:<tab><tab>with open(self.db) as db:<tab><tab><tab>content = db.read(8)<tab><tab><tab>db.seek(0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = StringIO()<tab><tab><tab><tab>if self.encryptor:<tab><tab><tab><tab><tab>self.encryptor.decrypt(db, data)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>raise EncryptionError(<tab><tab><tab><tab><tab><tab>""Encrpyted credential storage: {}"".format(self.db)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>return json.loads(data.getvalue())<tab><tab><tab>else:<tab><tab><tab><tab>return json.load(db)<tab>except:<tab><tab>return {""creds"": []}",0,"if content == ( ""Salted__"" ) :","if content == b"""" :",0.09453229110448028,24.117803988461304,1.0
"def _getbytes(self, start, l=1):<tab>out = []<tab>for ad in range(l):<tab><tab>offset = ad + start + self.base_address<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""not enough bytes"")<tab><tab>out.append(int_to_byte(Byte(offset)))<tab>return b"""".join(out)",0,if not is_mapped ( offset ) :,if offset > l :,0.02384665141965364,6.316906128202129,0.4
"def cache_sqs_queues_across_accounts() -> bool:<tab>function: str = f""{__name__}.{sys._getframe().f_code.co_name}""<tab># First, get list of accounts<tab>accounts_d: list = async_to_sync(get_account_id_to_name_mapping)()<tab># Second, call tasks to enumerate all the roles across all accounts<tab>for account_id in accounts_d.keys():<tab><tab>if config.get(""environment"") == ""prod"":<tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab>stats.count(f""{function}.success"")<tab>return True",0,"if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",if account_id not in accounts_d . keys ( ) :,0.1345774348712745,12.63053821392549,0.2857142857142857
"def insertLine(self, refnum, linenum, line):<tab>i = -1<tab>for i, row in enumerate(self.rows):<tab><tab>if row[0] == linenum:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>row[refnum + 1] = line<tab><tab><tab><tab>return<tab><tab><tab># else keep looking<tab><tab>elif row[0] > linenum:<tab><tab><tab>break<tab>self.rows.insert(i, self.newRow(linenum, refnum, line))",0,if row [ refnum + 1 ] is None :,if refnum + 1 < len ( self . rows ) :,0.05554117064035497,14.323145079400492,0.2
"def __setattr__(self, name, val):<tab>if self.__dict__.get(name, ""hamster_graphics_no_value_really"") == val:<tab><tab>return<tab>Sprite.__setattr__(self, name, val)<tab>if name == ""image_data"":<tab><tab>self._surface = None<tab><tab><IF-STMT><tab><tab><tab>self.__dict__[""width""] = self.image_data.get_width()<tab><tab><tab>self.__dict__[""height""] = self.image_data.get_height()",0,if self . image_data :,if self . image_data is not None :,0.3514988343435983,53.7284965911771,0.4444444444444444
"def process_signature(app, what, name, obj, options, signature, return_annotation):<tab>if signature:<tab><tab># replace Mock function names<tab><tab>signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature)<tab><tab>signature = re.sub(""tensorflow"", ""tf"", signature)<tab><tab># add scope name to layer signatures:<tab><tab>if hasattr(obj, ""use_scope""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>signature = signature[0] + ""variable_scope_name, "" + signature[1:]<tab><tab><tab>elif obj.use_scope is None:<tab><tab><tab><tab>signature = signature[0] + ""[variable_scope_name,] "" + signature[1:]<tab># signature: arg list<tab>return signature, return_annotation",0,if obj . use_scope :,if obj . use_scope is None :,0.36879024661621806,61.04735835807847,0.55
"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz * (1 - sqr(tanh(x))),)",1,if x . type in discrete_types :,if x . type in discrete_types :,0.75,100.00000000000004,1.0
"def confirm_on_console(topic, msg):<tab>done = False<tab>print(topic)<tab>while not done:<tab><tab>output = raw_input(msg + "":[y/n]"")<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if output.lower() == ""n"":<tab><tab><tab>return False",1,"if output . lower ( ) == ""y"" :","if output . lower ( ) == ""y"" :",0.75,100.00000000000004,1.0
"def replace_documentation_for_matching_shape(self, event_name, section, **kwargs):<tab>if self._shape_name == section.context.get(""shape""):<tab><tab>self._replace_documentation(event_name, section)<tab>for section_name in section.available_sections:<tab><tab>sub_section = section.get_section(section_name)<tab><tab><IF-STMT><tab><tab><tab>self._replace_documentation(event_name, sub_section)<tab><tab>else:<tab><tab><tab>self.replace_documentation_for_matching_shape(event_name, sub_section)",1,"if self . _shape_name == sub_section . context . get ( ""shape"" ) :","if self . _shape_name == sub_section . context . get ( ""shape"" ) :",0.75,100.00000000000004,1.0
"def confirm_on_console(topic, msg):<tab>done = False<tab>print(topic)<tab>while not done:<tab><tab>output = raw_input(msg + "":[y/n]"")<tab><tab>if output.lower() == ""y"":<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False",0,"if output . lower ( ) == ""n"" :","elif output . lower ( ) == ""n"" :",0.4127127708701796,90.36020036098445,0.6
"def __getitem__(self, index):<tab>if self._check():<tab><tab>if isinstance(index, int):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise IndexError(index)<tab><tab><tab>if self.features[index] is None:<tab><tab><tab><tab>feature = self.device.feature_request(FEATURE.FEATURE_SET, 0x10, index)<tab><tab><tab><tab>if feature:<tab><tab><tab><tab><tab>(feature,) = _unpack(""!H"", feature[:2])<tab><tab><tab><tab><tab>self.features[index] = FEATURE[feature]<tab><tab><tab>return self.features[index]<tab><tab>elif isinstance(index, slice):<tab><tab><tab>indices = index.indices(len(self.features))<tab><tab><tab>return [self.__getitem__(i) for i in range(*indices)]",0,if index < 0 or index >= len ( self . features ) :,if index < 0 :,0.12200767626323289,9.569649651041097,0.4215686274509804
"def _parse_locator(self, locator):<tab>prefix = None<tab>criteria = locator<tab>if not locator.startswith(""//""):<tab><tab>locator_parts = locator.partition(""="")<tab><tab><IF-STMT><tab><tab><tab>prefix = locator_parts[0]<tab><tab><tab>criteria = locator_parts[2].strip()<tab>return (prefix, criteria)",0,if len ( locator_parts [ 1 ] ) > 0 :,if len ( locator_parts ) > 2 :,0.14852865108020535,44.360636895626136,0.48888888888888893
"def trakt_episode_data_generate(self, data):<tab># Find how many unique season we have<tab>uniqueSeasons = []<tab>for season, episode in data:<tab><tab><IF-STMT><tab><tab><tab>uniqueSeasons.append(season)<tab># build the query<tab>seasonsList = []<tab>for searchedSeason in uniqueSeasons:<tab><tab>episodesList = []<tab><tab>for season, episode in data:<tab><tab><tab>if season == searchedSeason:<tab><tab><tab><tab>episodesList.append({""number"": episode})<tab><tab>seasonsList.append({""number"": searchedSeason, ""episodes"": episodesList})<tab>post_data = {""seasons"": seasonsList}<tab>return post_data",1,if season not in uniqueSeasons :,if season not in uniqueSeasons :,0.75,100.00000000000004,1.0
"def __init__(self, data, n_bins):<tab>bin_width = span / n_bins<tab>bins = [0] * n_bins<tab>for x in data:<tab><tab>b = int(mpfloor((x - minimum) / bin_width))<tab><tab><IF-STMT><tab><tab><tab>b = 0<tab><tab>elif b >= n_bins:<tab><tab><tab>b = n_bins - 1<tab><tab>bins[b] += 1<tab>self.bins = bins<tab>self.bin_width = bin_width",1,if b < 0 :,if b < 0 :,0.75,100.00000000000004,1.0
"def infer_context(typ, context=""http://schema.org""):<tab>parsed_context = urlparse(typ)<tab>if parsed_context.netloc:<tab><tab>base = """".join([parsed_context.scheme, ""://"", parsed_context.netloc])<tab><tab><IF-STMT><tab><tab><tab>context = urljoin(base, parsed_context.path)<tab><tab><tab>typ = parsed_context.fragment.strip(""/"")<tab><tab>elif parsed_context.path:<tab><tab><tab>context = base<tab><tab><tab>typ = parsed_context.path.strip(""/"")<tab>return context, typ",0,if parsed_context . path and parsed_context . fragment :,if parsed_context . fragment :,0.30073724313964595,42.43728456769501,0.3666666666666667
"def parse(self, items):<tab>for index, item in enumerate(items):<tab><tab>keys = self.build_key(item)<tab><tab>if keys is None:<tab><tab><tab>continue<tab><tab># Update `items`<tab><tab>self.items[tuple(keys)] = (index, item)<tab><tab># Update `table`<tab><tab><IF-STMT><tab><tab><tab>log.info(""Unable to update table (keys: %r)"", keys)",0,"if not self . path_set ( self . table , keys , ( index , item ) ) :",if not self . table_exists ( keys ) :,0.10188614405889386,14.94611618633665,0.4391025641025641
"def dict_to_XML(tag, dictionary, **kwargs):<tab>""""""Return XML element converting dicts recursively.""""""<tab>elem = Element(tag, **kwargs)<tab>for key, val in dictionary.items():<tab><tab>if tag == ""layers"":<tab><tab><tab>child = dict_to_XML(""layer"", val, name=key)<tab><tab>elif isinstance(val, MutableMapping):<tab><tab><tab>child = dict_to_XML(key, val)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child = Element(""variable"", name=key)<tab><tab><tab>else:<tab><tab><tab><tab>child = Element(key)<tab><tab><tab>child.text = str(val)<tab><tab>elem.append(child)<tab>return elem",0,"if tag == ""config"" :","if tag == ""variable"" :",0.39477865547525276,59.4603557501361,1.0
"def _get_config_value(self, section, key):<tab>if section:<tab><tab><IF-STMT><tab><tab><tab>self.log.error(""Error: Config section '%s' not found"", section)<tab><tab><tab>return None<tab><tab>return self.config[section].get(key, self.config[key])<tab>else:<tab><tab>return self.config[key]",1,if section not in self . config :,if section not in self . config :,0.75,100.00000000000004,1.0
"def h_line_down(self, input):<tab>end_this_line = self.value.find(""\n"", self.cursor_position)<tab>if end_this_line == -1:<tab><tab>if self.scroll_exit:<tab><tab><tab>self.h_exit_down(None)<tab><tab>else:<tab><tab><tab>self.cursor_position = len(self.value)<tab>else:<tab><tab>self.cursor_position = end_this_line + 1<tab><tab>for x in range(self.cursorx):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>elif self.value[self.cursor_position] == ""\n"":<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self.cursor_position += 1",0,if self . cursor_position > len ( self . value ) - 1 :,if self . value [ self . cursor_position ] == input :,0.3890695123010187,35.76725172906465,0.42016806722689076
"def printsumfp(fp, filename, out=sys.stdout):<tab>m = md5()<tab>try:<tab><tab>while 1:<tab><tab><tab>data = fp.read(bufsize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if isinstance(data, str):<tab><tab><tab><tab>data = data.encode(fp.encoding)<tab><tab><tab>m.update(data)<tab>except IOError as msg:<tab><tab>sys.stderr.write(""%s: I/O error: %s\n"" % (filename, msg))<tab><tab>return 1<tab>out.write(""%s %s\n"" % (m.hexdigest(), filename))<tab>return 0",1,if not data :,if not data :,0.75,100.00000000000004,1.0
"def main(input):<tab>logging.info(""Running Azure Cloud Custodian Policy %s"", input)<tab>context = {<tab><tab>""config_file"": join(function_directory, ""config.json""),<tab><tab>""auth_file"": join(function_directory, ""auth.json""),<tab>}<tab>event = None<tab>subscription_id = None<tab>if isinstance(input, QueueMessage):<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>event = input.get_json()<tab><tab>subscription_id = ResourceIdParser.get_subscription_id(event[""subject""])<tab>handler.run(event, context, subscription_id)",0,if input . dequeue_count > max_dequeue_count :,if input . get_error ( ) :,0.09056531419355518,12.929367642051732,1.0
"def maybeExtractTarball(self):<tab>if self.tarball:<tab><tab>tar = self.computeTarballOptions() + [""-xvf"", self.tarball]<tab><tab>res = yield self._Cmd(tar, abandonOnFailure=False)<tab><tab><IF-STMT>  # error with tarball.. erase repo dir and tarball<tab><tab><tab>yield self._Cmd([""rm"", ""-f"", self.tarball], abandonOnFailure=False)<tab><tab><tab>yield self.runRmdir(self.repoDir(), abandonOnFailure=False)",0,if res :,if res != 0 :,0.09791453445388575,1e-10,0.7
"def execute(self, arbiter, props):<tab>watcher = self._get_watcher(arbiter, props.pop(""name""))<tab>action = 0<tab>for key, val in props.get(""options"", {}).items():<tab><tab><IF-STMT><tab><tab><tab>new_action = 0<tab><tab><tab>for name, _val in val.items():<tab><tab><tab><tab>action = watcher.set_opt(""hooks.%s"" % name, _val)<tab><tab><tab><tab>if action == 1:<tab><tab><tab><tab><tab>new_action = 1<tab><tab>else:<tab><tab><tab>new_action = watcher.set_opt(key, val)<tab><tab>if new_action == 1:<tab><tab><tab>action = 1<tab># trigger needed action<tab>return watcher.do_action(action)",0,"if key == ""hooks"" :","if isinstance ( val , dict ) :",0.026407399022921448,6.567274736060395,0.3
"def _import_playlists(self, fns, library):<tab>added = 0<tab>for filename in fns:<tab><tab>name = _name_for(filename)<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>playlist = parse_m3u(f, name, library=library)<tab><tab><tab>elif filename.endswith("".pls""):<tab><tab><tab><tab>playlist = parse_pls(f, name, library=library)<tab><tab><tab>else:<tab><tab><tab><tab>print_w(""Unsupported playlist type for '%s'"" % filename)<tab><tab><tab><tab>continue<tab><tab>self.changed(playlist)<tab><tab>library.add(playlist)<tab><tab>added += 1<tab>return added",0,"if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :","if filename . endswith ( "".m3u"" ) :",0.3063106865638814,38.966271115357685,0.638095238095238
"def unwrap_term_buckets(self, timestamp, term_buckets):<tab>for term_data in term_buckets:<tab><tab><IF-STMT><tab><tab><tab>self.unwrap_interval_buckets(<tab><tab><tab><tab>timestamp, term_data[""key""], term_data[""interval_aggs""][""buckets""]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.check_matches(timestamp, term_data[""key""], term_data)",1,"if ""interval_aggs"" in term_data :","if ""interval_aggs"" in term_data :",0.75,100.00000000000004,1.0
"def _get_exception(flags, timeout_ms, payload_size):<tab>if flags & FLAG_ERROR:<tab><tab>if flags & FLAG_TIMEOUT:<tab><tab><tab>return SpicommTimeoutError(timeout_ms / 1000.0)<tab><tab><IF-STMT><tab><tab><tab>return SpicommOverflowError(payload_size)<tab><tab>return SpicommError()<tab>return None",0,if flags & FLAG_OVERFLOW :,elif flags & FLAG_OVERFLOW :,0.31152264354151193,80.91067115702207,0.5
"def _get_pattern(self, pattern_id):<tab>""""""Get pattern item by id.""""""<tab>for key in (Tag.PATTERNS1, Tag.PATTERNS2, Tag.PATTERNS3):<tab><tab>if key in self.tagged_blocks:<tab><tab><tab>data = self.tagged_blocks.get_data(key)<tab><tab><tab>for pattern in data:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return pattern<tab>return None",0,if pattern . pattern_id == pattern_id :,if pattern . id == pattern_id :,0.3884893899276739,64.32188699036833,0.7222222222222222
"def print_quiet(self, context, *args, **kwargs):<tab>for index, (key, value) in enumerate(<tab><tab>itertools.chain(enumerate(args), kwargs.items())<tab>):<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>self.format_quiet(index, key, value, fields=context.get_input_fields())<tab><tab><tab>)",0,"if self . filter ( index , key , value ) :",if value is not None :,0.011387185973035771,3.9297526283216277,0.19230769230769232
"def complete(self, block):<tab>with self._condition:<tab><tab>if not self._final:<tab><tab><tab>return False<tab><tab>if self._complete():<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>self._condition.wait_for(self._complete)<tab><tab><tab>self._calculate_state_root_if_not_already_done()<tab><tab><tab>return True<tab><tab>return False",1,if block :,if block :,0.5311706625951745,1e-10,1.0
"def compression_rotator(source, dest):<tab>with open(source, ""rb"") as sf:<tab><tab>with gzip.open(dest, ""wb"") as wf:<tab><tab><tab>while True:<tab><tab><tab><tab>data = sf.read(CHUNK_SIZE)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>wf.write(data)<tab>os.remove(source)",1,if not data :,if not data :,0.75,100.00000000000004,1.0
"def mockup(self, records):<tab>provider = TransipProvider("""", """", """")<tab>_dns_entries = []<tab>for record in records:<tab><tab><IF-STMT><tab><tab><tab>entries_for = getattr(provider, ""_entries_for_{}"".format(record._type))<tab><tab><tab># Root records have '@' as name<tab><tab><tab>name = record.name<tab><tab><tab>if name == """":<tab><tab><tab><tab>name = provider.ROOT_RECORD<tab><tab><tab>_dns_entries.extend(entries_for(name, record))<tab><tab><tab># NS is not supported as a DNS Entry,<tab><tab><tab># so it should cover the if statement<tab><tab><tab>_dns_entries.append(DnsEntry(""@"", ""3600"", ""NS"", ""ns01.transip.nl.""))<tab>self.mockupEntries = _dns_entries",0,if record . _type in provider . SUPPORTS :,"if hasattr ( record , ""_type"" ) :",0.016959990967165158,9.425159511373677,0.2571428571428572
"def parse_known_args(self, args=None, namespace=None):<tab>entrypoint = self.prog.split("" "")[0]<tab>try:<tab><tab>defs = get_defaults_for_argparse(entrypoint)<tab><tab>ignore = defs.pop(""Ignore"", None)<tab><tab>self.set_defaults(**defs)<tab><tab><IF-STMT><tab><tab><tab>set_notebook_diff_ignores(ignore)<tab>except ValueError:<tab><tab>pass<tab>return super(ConfigBackedParser, self).parse_known_args(<tab><tab>args=args, namespace=namespace<tab>)",0,if ignore :,if ignore is not None :,0.09036476851692153,1e-10,0.39999999999999997
"def _maybeRebuildAtlas(self, threshold=4, minlen=1000):<tab>n = len(self.fragmentAtlas)<tab>if (n > minlen) and (n > threshold * len(self.data)):<tab><tab>self.fragmentAtlas.rebuild(<tab><tab><tab>list(zip(*self._style([""symbol"", ""size"", ""pen"", ""brush""])))<tab><tab>)<tab><tab>self.data[""sourceRect""] = 0<tab><tab><IF-STMT><tab><tab><tab>self._sourceQRect.clear()<tab><tab>self.updateSpots()",0,if _USE_QRECT :,if self . _sourceQRect :,0.051944022748897464,1e-10,0.6190476190476191
"def dispatch_return(self, frame, arg):<tab>if self.stop_here(frame) or frame == self.returnframe:<tab><tab># Ignore return events in generator except when stepping.<tab><tab><IF-STMT><tab><tab><tab>return self.trace_dispatch<tab><tab>try:<tab><tab><tab>self.frame_returning = frame<tab><tab><tab>self.user_return(frame, arg)<tab><tab>finally:<tab><tab><tab>self.frame_returning = None<tab><tab>if self.quitting:<tab><tab><tab>raise BdbQuit<tab><tab># The user issued a 'next' or 'until' command.<tab><tab>if self.stopframe is frame and self.stoplineno != -1:<tab><tab><tab>self._set_stopinfo(None, None)<tab>return self.trace_dispatch",0,if self . stopframe and frame . f_code . co_flags & CO_GENERATOR :,if self . stopframe is None :,0.18482531369684857,7.828988696754741,0.5
"def tearDown(self):<tab>if not self.is_playback():<tab><tab>try:<tab><tab><tab>if self.hosted_service_name is not None:<tab><tab><tab><tab>self.sms.delete_hosted_service(self.hosted_service_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.sms.delete_storage_account(self.storage_account_name)<tab><tab>except:<tab><tab><tab>pass<tab><tab>try:<tab><tab><tab>self.sms.delete_affinity_group(self.affinity_group_name)<tab><tab>except:<tab><tab><tab>pass<tab>return super(LegacyMgmtAffinityGroupTest, self).tearDown()",1,if self . storage_account_name is not None :,if self . storage_account_name is not None :,0.75,100.00000000000004,1.0
"def make_log_msg(self, msg, *other_messages):<tab>MAX_MESSAGE_LENGTH = 1000<tab>if not other_messages:<tab><tab># assume that msg is a single string<tab><tab>return msg[-MAX_MESSAGE_LENGTH:]<tab>else:<tab><tab>if len(msg):<tab><tab><tab>msg += ""\n...\n""<tab><tab><tab>NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len(msg)<tab><tab>else:<tab><tab><tab>NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH<tab><tab><IF-STMT><tab><tab><tab>msg += other_messages[0][-NEXT_MESSAGE_OFFSET:]<tab><tab><tab>return self.make_log_msg(msg, *other_messages[1:])<tab><tab>else:<tab><tab><tab>return self.make_log_msg(msg)",0,if NEXT_MESSAGE_OFFSET > 0 :,if len ( other_messages [ 0 ] ) > NEXT_MESSAGE_OFFSET :,0.02713266086769041,24.797984721910183,0.4852941176470588
"def wrapper(  # type: ignore<tab>self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]:<tab>if self.request.path.endswith(""/""):<tab><tab>if self.request.method in (""GET"", ""HEAD""):<tab><tab><tab>uri = self.request.path.rstrip(""/"")<tab><tab><tab>if uri:  # don't try to redirect '/' to ''<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>uri += ""?"" + self.request.query<tab><tab><tab><tab>self.redirect(uri, permanent=True)<tab><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise HTTPError(404)<tab>return method(self, *args, **kwargs)",1,if self . request . query :,if self . request . query :,0.75,100.00000000000004,1.0
"def process_lib(vars_, coreval):<tab>for d in vars_:<tab><tab>var = d.upper()<tab><tab>if var == ""QTCORE"":<tab><tab><tab>continue<tab><tab>value = env[""LIBPATH_"" + var]<tab><tab><IF-STMT><tab><tab><tab>core = env[coreval]<tab><tab><tab>accu = []<tab><tab><tab>for lib in value:<tab><tab><tab><tab>if lib in core:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>accu.append(lib)<tab><tab><tab>env[""LIBPATH_"" + var] = accu",1,if value :,if value :,0.5311706625951745,1e-10,1.0
"def _attach_children(self, other, exclude_worldbody, dry_run=False):<tab>for other_child in other.all_children():<tab><tab><IF-STMT><tab><tab><tab>self_child = self.get_children(other_child.spec.name)<tab><tab><tab>self_child._attach(<tab><tab><tab><tab>other_child, exclude_worldbody, dry_run<tab><tab><tab>)  # pylint: disable=protected-access",0,if not other_child . spec . repeated :,"if isinstance ( other_child , worldbody . worldbody . worldbody ) :",0.01723566029404934,13.06511329838856,0.2761904761904762
"def getDictFromTree(tree):<tab>ret_dict = {}<tab>for child in tree.getchildren():<tab><tab>if child.getchildren():<tab><tab><tab>## Complex-type child. Recurse<tab><tab><tab>content = getDictFromTree(child)<tab><tab>else:<tab><tab><tab>content = child.text<tab><tab><IF-STMT><tab><tab><tab>if not type(ret_dict[child.tag]) == list:<tab><tab><tab><tab>ret_dict[child.tag] = [ret_dict[child.tag]]<tab><tab><tab>ret_dict[child.tag].append(content or """")<tab><tab>else:<tab><tab><tab>ret_dict[child.tag] = content or """"<tab>return ret_dict",0,if ret_dict . has_key ( child . tag ) :,if child . tag in ret_dict :,0.06410035254389929,18.402097851927994,0.7846153846153847
"def nsUriMatch(self, value, wanted, strict=0, tt=type(())):<tab>""""""Return a true value if two namespace uri values match.""""""<tab>if value == wanted or (type(wanted) is tt) and value in wanted:<tab><tab>return 1<tab>if not strict and value is not None:<tab><tab>wanted = type(wanted) is tt and wanted or (wanted,)<tab><tab>value = value[-1:] != ""/"" and value or value[:-1]<tab><tab>for item in wanted:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 1<tab>return 0",0,if item == value or item [ : - 1 ] == value :,if str ( item ) == value or str ( item ) == str ( value ) :,0.29153653074990404,16.586105071157164,0.2714285714285714
"def update_repository(self, ignore_issues=False, force=False):<tab>""""""Update.""""""<tab>if not await self.common_update(ignore_issues, force):<tab><tab>return<tab># Get appdaemon objects.<tab>if self.repository_manifest:<tab><tab><IF-STMT><tab><tab><tab>self.content.path.remote = """"<tab>if self.content.path.remote == ""apps"":<tab><tab>self.data.domain = get_first_directory_in_directory(<tab><tab><tab>self.tree, self.content.path.remote<tab><tab>)<tab><tab>self.content.path.remote = f""apps/{self.data.name}""<tab># Set local path<tab>self.content.path.local = self.localpath",0,if self . data . content_in_root :,if self . content . path . remote is None :,0.19954207252247816,18.36028134946796,0.2962962962962963
"def addOutput(self, data, isAsync=None, **kwargs):<tab>isAsync = _get_async_param(isAsync, **kwargs)<tab>if isAsync:<tab><tab>self.terminal.eraseLine()<tab><tab>self.terminal.cursorBackward(len(self.lineBuffer) + len(self.ps[self.pn]))<tab>self.terminal.write(data)<tab>if isAsync:<tab><tab><IF-STMT><tab><tab><tab>self.terminal.nextLine()<tab><tab>self.terminal.write(self.ps[self.pn])<tab><tab>if self.lineBuffer:<tab><tab><tab>oldBuffer = self.lineBuffer<tab><tab><tab>self.lineBuffer = []<tab><tab><tab>self.lineBufferIndex = 0<tab><tab><tab>self._deliverBuffer(oldBuffer)",0,if self . _needsNewline ( ) :,if self . ps [ self . pn ] :,0.07470841271651402,16.784459625186194,0.4871794871794872
"def is_installed(self, dlc_title="""") -> bool:<tab>installed = False<tab>if dlc_title:<tab><tab>dlc_version = self.get_dlc_info(""version"", dlc_title)<tab><tab>installed = True if dlc_version else False<tab><tab># Start: Code for compatibility with minigalaxy 1.0<tab><tab><IF-STMT><tab><tab><tab>status = self.legacy_get_dlc_status(dlc_title)<tab><tab><tab>installed = True if status in [""installed"", ""updatable""] else False<tab><tab># End: Code for compatibility with minigalaxy 1.0<tab>else:<tab><tab>if self.install_dir and os.path.exists(self.install_dir):<tab><tab><tab>installed = True<tab>return installed",0,if not installed :,if self . legacy_get_dlc_status :,0.04240785919217091,4.456882760699063,0.36
"def close(self):<tab>self.selector.close()<tab>if self.sock:<tab><tab>sockname = None<tab><tab>try:<tab><tab><tab>sockname = self.sock.getsockname()<tab><tab>except (socket.error, OSError):<tab><tab><tab>pass<tab><tab>self.sock.close()<tab><tab><IF-STMT><tab><tab><tab># it was a Unix domain socket, remove it from the filesystem<tab><tab><tab>if os.path.exists(sockname):<tab><tab><tab><tab>os.remove(sockname)<tab>self.sock = None",0,if type ( sockname ) is str :,"if isinstance ( sockname , str ) :",0.03916858170756418,14.535768424205482,0.40816326530612246
"def post_file(self, file_path, graph_type=""edges"", file_type=""csv""):<tab>dataset_id = self.dataset_id<tab>tok = self.token<tab>base_path = self.server_base_path<tab>with open(file_path, ""rb"") as file:<tab><tab>out = requests.post(<tab><tab><tab>f""{base_path}/api/v2/upload/datasets/{dataset_id}/{graph_type}/{file_type}"",<tab><tab><tab>verify=self.certificate_validation,<tab><tab><tab>headers={""Authorization"": f""Bearer {tok}""},<tab><tab><tab>data=file.read(),<tab><tab>).json()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(out)<tab><tab>return out",0,"if not out [ ""success"" ] :","if ""error"" in out :",0.02384665141965364,7.379782263475772,0.6
"def _get_vqa_v2_image_raw_dataset(directory, image_root_url, image_urls):<tab>""""""Extract the VQA V2 image data set to directory unless it's there.""""""<tab>for url in image_urls:<tab><tab>filename = os.path.basename(url)<tab><tab>download_url = os.path.join(image_root_url, url)<tab><tab>path = generator_utils.maybe_download(directory, filename, download_url)<tab><tab>unzip_dir = os.path.join(directory, filename.strip("".zip""))<tab><tab><IF-STMT><tab><tab><tab>zipfile.ZipFile(path, ""r"").extractall(directory)",0,if not tf . gfile . Exists ( unzip_dir ) :,if os . path . exists ( unzip_dir ) :,0.13824519154542647,42.481820832988255,0.2403846153846154
"def __call__(self, environ, start_response):<tab>for key in ""REQUEST_URL"", ""REQUEST_URI"", ""UNENCODED_URL"":<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>request_uri = unquote(environ[key])<tab><tab>script_name = unquote(environ.get(""SCRIPT_NAME"", """"))<tab><tab>if request_uri.startswith(script_name):<tab><tab><tab>environ[""PATH_INFO""] = request_uri[len(script_name) :].split(""?"", 1)[0]<tab><tab><tab>break<tab>return self.app(environ, start_response)",1,if key not in environ :,if key not in environ :,0.75,100.00000000000004,1.0
"def _instrument_model(self, model):<tab>for key, value in list(<tab><tab>model.__dict__.items()<tab>):  # avoid ""dictionary keys changed during iteration""<tab><tab>if isinstance(value, tf.keras.layers.Layer):<tab><tab><tab>new_layer = self._instrument(value)<tab><tab><tab>if new_layer is not value:<tab><tab><tab><tab>setattr(model, key, new_layer)<tab><tab><IF-STMT><tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, tf.keras.layers.Layer):<tab><tab><tab><tab><tab>value[i] = self._instrument(item)<tab>return model",1,"elif isinstance ( value , list ) :","elif isinstance ( value , list ) :",0.75,100.00000000000004,1.0
"def __init__(self, parent, dir, mask, with_dirs=True):<tab>filelist = []<tab>dirlist = [""..""]<tab>self.dir = dir<tab>self.file = """"<tab>mask = mask.upper()<tab>pattern = self.MakeRegex(mask)<tab>for i in os.listdir(dir):<tab><tab>if i == ""."" or i == "".."":<tab><tab><tab>continue<tab><tab>path = os.path.join(dir, i)<tab><tab>if os.path.isdir(path):<tab><tab><tab>dirlist.append(i)<tab><tab><tab>continue<tab><tab>path = path.upper()<tab><tab>value = i.upper()<tab><tab><IF-STMT><tab><tab><tab>filelist.append(i)<tab>self.files = filelist<tab>if with_dirs:<tab><tab>self.dirs = dirlist",0,if pattern . match ( value ) is not None :,if pattern . search ( value ) :,0.16685713181051098,24.694586397773897,0.41414141414141414
"def get_text(self, nodelist):<tab>""""""Return a string representation of the motif's properties listed on nodelist .""""""<tab>retlist = []<tab>for node in nodelist:<tab><tab>if node.nodeType == Node.TEXT_NODE:<tab><tab><tab>retlist.append(node.wholeText)<tab><tab><IF-STMT><tab><tab><tab>retlist.append(self.get_text(node.childNodes))<tab>return re.sub(r""\s+"", "" "", """".join(retlist))",0,elif node . hasChildNodes :,elif node . nodeType == Node . ELEMENT_NODE :,0.18665292254479038,13.545994273378144,0.5151515151515151
"def _persist_metadata(self, dirname, filename):<tab>metadata_path = ""{0}/{1}.json"".format(dirname, filename)<tab>if self.media_metadata or self.comments or self.include_location:<tab><tab>if self.posts:<tab><tab><tab>if self.latest:<tab><tab><tab><tab>self.merge_json({""GraphImages"": self.posts}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphImages"": self.posts}, metadata_path)<tab><tab><IF-STMT><tab><tab><tab>if self.latest:<tab><tab><tab><tab>self.merge_json({""GraphStories"": self.stories}, metadata_path)<tab><tab><tab>else:<tab><tab><tab><tab>self.save_json({""GraphStories"": self.stories}, metadata_path)",1,if self . stories :,if self . stories :,0.75,100.00000000000004,1.0
"def _get_python_wrapper_content(self, job_class, args):<tab>job = job_class([""-r"", ""hadoop""] + list(args))<tab>job.sandbox()<tab>with job.make_runner() as runner:<tab><tab>runner._create_setup_wrapper_scripts()<tab><tab><IF-STMT><tab><tab><tab>with open(runner._spark_python_wrapper_path) as f:<tab><tab><tab><tab>return f.read()<tab><tab>else:<tab><tab><tab>return None",1,if runner . _spark_python_wrapper_path :,if runner . _spark_python_wrapper_path :,0.75,100.00000000000004,1.0
"def computeLeadingWhitespaceWidth(s, tab_width):<tab>w = 0<tab>for ch in s:<tab><tab><IF-STMT><tab><tab><tab>w += 1<tab><tab>elif ch == ""\t"":<tab><tab><tab>w += abs(tab_width) - (w % abs(tab_width))<tab><tab>else:<tab><tab><tab>break<tab>return w",1,"if ch == "" "" :","if ch == "" "" :",0.75,100.00000000000004,1.0
def run(self):<tab># if the i3status process dies we want to restart it.<tab># We give up restarting if we have died too often<tab>for _ in range(10):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>self.spawn_i3status()<tab><tab># check if we never worked properly and if so quit now<tab><tab>if not self.ready:<tab><tab><tab>break<tab><tab># limit restart rate<tab><tab>self.lock.wait(5),0,if not self . py3_wrapper . running :,if not self . ready :,0.19189611060104994,27.585129929794586,0.6666666666666666
"def translate_len(<tab>builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Optional[Value]:<tab># Special case builtins.len<tab>if len(expr.args) == 1 and expr.arg_kinds == [ARG_POS]:<tab><tab>expr_rtype = builder.node_type(expr.args[0])<tab><tab><IF-STMT><tab><tab><tab># len() of fixed-length tuple can be trivially determined statically,<tab><tab><tab># though we still need to evaluate it.<tab><tab><tab>builder.accept(expr.args[0])<tab><tab><tab>return Integer(len(expr_rtype.types))<tab><tab>else:<tab><tab><tab>obj = builder.accept(expr.args[0])<tab><tab><tab>return builder.builtin_len(obj, -1)<tab>return None",0,"if isinstance ( expr_rtype , RTuple ) :","if isinstance ( expr_rtype , IRType ) :",0.5490406812970063,70.71067811865478,0.6
"def parse_auth(val):<tab>if val is not None:<tab><tab>authtype, params = val.split("" "", 1)<tab><tab>if authtype in known_auth_schemes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># this is the ""Authentication: Basic XXXXX=="" case<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>params = parse_auth_params(params)<tab><tab>return authtype, params<tab>return val",0,"if authtype == ""Basic"" and '""' not in params :",if len ( params ) == 1 :,0.015805905348207437,6.155947438501932,0.2
"def toxml(self):<tab>text = self.value<tab>self.parent.setBidi(getBidiType(text))<tab>if not text.startswith(HTML_PLACEHOLDER_PREFIX):<tab><tab>if self.parent.nodeName == ""p"":<tab><tab><tab>text = text.replace(""\n"", ""\n   "")<tab><tab><IF-STMT><tab><tab><tab>text = ""\n<tab> "" + text.replace(""\n"", ""\n<tab> "")<tab>text = self.doc.normalizeEntities(text)<tab>return text",0,"elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :","elif self . parent . nodeName == ""a"" :",0.27552346813506334,27.474791071543024,0.49198717948717946
"def get_all_related_many_to_many_objects(self):<tab>try:  # Try the cache first.<tab><tab>return self._all_related_many_to_many_objects<tab>except AttributeError:<tab><tab>rel_objs = []<tab><tab>for klass in get_models():<tab><tab><tab>for f in klass._meta.many_to_many:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>rel_objs.append(RelatedObject(f.rel.to, klass, f))<tab><tab>self._all_related_many_to_many_objects = rel_objs<tab><tab>return rel_objs",0,if f . rel and self == f . rel . to . _meta :,if f . rel and f . rel . to . _meta . many_to_many :,0.5260822472685784,53.74512308135862,0.5619047619047619
"def state_highstate(self, state, dirpath):<tab>opts = copy.copy(self.config)<tab>opts[""file_roots""] = dict(base=[dirpath])<tab>HIGHSTATE = HighState(opts)<tab>HIGHSTATE.push_active()<tab>try:<tab><tab>high, errors = HIGHSTATE.render_highstate(state)<tab><tab><IF-STMT><tab><tab><tab>import pprint<tab><tab><tab>pprint.pprint(""\n"".join(errors))<tab><tab><tab>pprint.pprint(high)<tab><tab>out = HIGHSTATE.state.call_high(high)<tab><tab># pprint.pprint(out)<tab>finally:<tab><tab>HIGHSTATE.pop_active()",1,if errors :,if errors :,0.5311706625951745,1e-10,1.0
"def _update_target_host(self, target, target_host):<tab>""""""Update target host.""""""<tab>target_host = None if target_host == """" else target_host<tab>if not target_host:<tab><tab>for device_type, tgt in target.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>target_host = tgt<tab><tab><tab><tab>break<tab>if not target_host:<tab><tab>target_host = ""llvm"" if tvm.runtime.enabled(""llvm"") else ""stackvm""<tab>if isinstance(target_host, str):<tab><tab>target_host = tvm.target.Target(target_host)<tab>return target_host",0,if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,"if device_type == ""target"" :",0.012440829806128465,10.807256086619267,0.2571428571428572
"def __console_writer(self):<tab>while True:<tab><tab>self.__writer_event.wait()<tab><tab>self.__writer_event.clear()<tab><tab>if self.__console_view:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.debug(""Writing console view to STDOUT"")<tab><tab><tab><tab>sys.stdout.write(self.console_markup.clear)<tab><tab><tab><tab>sys.stdout.write(self.__console_view)<tab><tab><tab><tab>sys.stdout.write(self.console_markup.TOTAL_RESET)",0,if not self . short_only :,if self . console_markup . clear :,0.047631794481620526,11.99014838091355,0.4
"def goToPrevMarkedHeadline(self, event=None):<tab>""""""Select the next marked node.""""""<tab>c = self<tab>p = c.p<tab>if not p:<tab><tab>return<tab>p.moveToThreadBack()<tab>wrapped = False<tab>while 1:<tab><tab>if p and p.isMarked():<tab><tab><tab>break<tab><tab>elif p:<tab><tab><tab>p.moveToThreadBack()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>wrapped = True<tab><tab><tab>p = c.rootPosition()<tab>if not p:<tab><tab>g.blue(""done"")<tab>c.treeSelectHelper(p)  # Sets focus.",1,elif wrapped :,elif wrapped :,0.5143161313935813,1e-10,1.0
"def delete_map(self, query=None):<tab>query_map = self.interpolated_map(query=query)<tab>for alias, drivers in six.iteritems(query_map.copy()):<tab><tab>for driver, vms in six.iteritems(drivers.copy()):<tab><tab><tab>for vm_name, vm_details in six.iteritems(vms.copy()):<tab><tab><tab><tab>if vm_details == ""Absent"":<tab><tab><tab><tab><tab>query_map[alias][driver].pop(vm_name)<tab><tab><tab>if not query_map[alias][driver]:<tab><tab><tab><tab>query_map[alias].pop(driver)<tab><tab><IF-STMT><tab><tab><tab>query_map.pop(alias)<tab>return query_map",0,if not query_map [ alias ] :,elif not query_map [ alias ] [ driver ] :,0.2606001131896901,55.41156235972404,0.4871794871794872
"def get_shadows_zip(filename):<tab>import zipfile<tab>shadow_pkgs = set()<tab>with zipfile.ZipFile(filename) as lib_zip:<tab><tab>already_test = []<tab><tab>for fname in lib_zip.namelist():<tab><tab><tab>pname, fname = os.path.split(fname)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if pname not in already_test and ""/"" not in pname:<tab><tab><tab><tab>already_test.append(pname)<tab><tab><tab><tab>if is_shadowing(pname):<tab><tab><tab><tab><tab>shadow_pkgs.add(pname)<tab>return shadow_pkgs",0,if fname or ( pname and fname ) :,if not is_shadowing ( pname ) :,0.03965423395541948,14.25876976452075,0.23809523809523808
"def make_chains(chains_info):<tab>chains = [[] for _ in chains_info[0][1]]<tab>for i, num_ids in enumerate(chains_info[:-1]):<tab><tab>num, ids = num_ids<tab><tab>for j, ident in enumerate(ids):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>next_chain_info = chains_info[i + 1]<tab><tab><tab><tab>previous = next_chain_info[1][j]<tab><tab><tab><tab>block = SimpleBlock(num, ident, previous)<tab><tab><tab><tab>chains[j].append(block)<tab>chains = {i: make_generator(chain) for i, chain in enumerate(chains)}<tab>return chains",0,"if ident != """" :",if i + 1 < len ( ids ) :,0.02442414353888167,4.990049701936832,0.25274725274725274
"def filter_input(mindate, maxdate, files):<tab>mindate = parse(mindate) if mindate is not None else datetime.datetime.min<tab>maxdate = parse(maxdate) if maxdate is not None else datetime.datetime.max<tab>for line in fileinput.input(files):<tab><tab>tweet = json.loads(line)<tab><tab>created_at = parse(tweet[""created_at""])<tab><tab>created_at = created_at.replace(tzinfo=None)<tab><tab><IF-STMT><tab><tab><tab>print(json.dumps(tweet))",0,if mindate < created_at and maxdate > created_at :,if created_at < mindate :,0.0684968360711862,12.821896752346168,0.5666666666666667
"def get(self):<tab>""""""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called.""""""<tab>if self._exception is not _NONE:<tab><tab>if self._exception is None:<tab><tab><tab>return self.value<tab><tab>getcurrent().throw(*self._exception)  # pylint:disable=undefined-variable<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ConcurrentObjectUseError(<tab><tab><tab><tab>""This Waiter is already used by %r"" % (self.greenlet,)<tab><tab><tab>)<tab><tab>self.greenlet = getcurrent()  # pylint:disable=undefined-variable<tab><tab>try:<tab><tab><tab>return self.hub.switch()<tab><tab>finally:<tab><tab><tab>self.greenlet = None",0,if self . greenlet is not None :,if self . greenlet is not _NONE :,0.605621305873661,61.04735835807847,0.8285714285714285
"def default_loader(href, parse, encoding=None):<tab>with open(href) as file:<tab><tab><IF-STMT><tab><tab><tab>data = ElementTree.parse(file).getroot()<tab><tab>else:<tab><tab><tab>data = file.read()<tab><tab><tab>if encoding:<tab><tab><tab><tab>data = data.decode(encoding)<tab>return data",0,"if parse == ""xml"" :",if parse :,0.06767423853569741,1e-10,1.0
def is_all_qud(world):<tab>m = True<tab>for obj in world:<tab><tab><IF-STMT><tab><tab><tab>if obj.nice:<tab><tab><tab><tab>m = m and True<tab><tab><tab>else:<tab><tab><tab><tab>m = m and False<tab><tab>else:<tab><tab><tab>m = m and True<tab>return m,0,if obj . blond :,"if isinstance ( obj , Qud ) :",0.028001459970687266,7.267884212102741,0.3148148148148148
"def run(self, edit):<tab>if not self.has_selection():<tab><tab>region = sublime.Region(0, self.view.size())<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab>if prefixed:<tab><tab><tab>self.view.replace(edit, region, prefixed)<tab><tab>return<tab>for region in self.view.sel():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab>if prefixed:<tab><tab><tab>self.view.replace(edit, region, prefixed)",0,if region . empty ( ) :,if region == region :,0.04240600921794552,15.207218222740094,0.6666666666666666
"def add_fields(self, params):<tab>for (key, val) in params.iteritems():<tab><tab><IF-STMT><tab><tab><tab>new_params = {}<tab><tab><tab>for k in val:<tab><tab><tab><tab>new_params[""%s__%s"" % (key, k)] = val[k]<tab><tab><tab>self.add_fields(new_params)<tab><tab>else:<tab><tab><tab>self.add_field(key, val)",1,"if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",0.75,100.00000000000004,1.0
"def find_magic(self, f, pos, magic):<tab>f.seek(pos)<tab>block = f.read(32 * 1024)<tab>if len(block) < len(magic):<tab><tab>return -1<tab>p = block.find(magic)<tab>while p < 0:<tab><tab>pos += len(block) - len(magic) + 1<tab><tab>block = block[1 - len(magic) :] + f.read(32 << 10)<tab><tab><IF-STMT><tab><tab><tab>return -1<tab><tab>p = block.find(magic)<tab>return pos + p",0,if len ( block ) == len ( magic ) - 1 :,if len ( block ) < 4 :,0.2778016103078403,25.55891661822957,0.5059523809523809
"def check_strings(self):<tab>""""""Check that all strings have been consumed.""""""<tab>for i, aList in enumerate(self.string_tokens):<tab><tab><IF-STMT><tab><tab><tab>g.trace(""warning: line %s. unused strings"" % i)<tab><tab><tab>for z in aList:<tab><tab><tab><tab>print(self.dump_token(z))",0,if aList :,if len ( aList ) == 0 :,0.046522600101893324,1e-10,0.36
"def get_tokens_unprocessed(self, text):<tab>from pygments.lexers._cocoa_builtins import (<tab><tab>COCOA_INTERFACES,<tab><tab>COCOA_PROTOCOLS,<tab><tab>COCOA_PRIMITIVES,<tab>)<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>value in COCOA_INTERFACES<tab><tab><tab><tab>or value in COCOA_PROTOCOLS<tab><tab><tab><tab>or value in COCOA_PRIMITIVES<tab><tab><tab>):<tab><tab><tab><tab>token = Name.Builtin.Pseudo<tab><tab>yield index, token, value",0,if token is Name or token is Name . Class :,if token is Name :,0.26972281613612636,21.297646969725616,0.49206349206349204
"def key_from_key_value_dict(key_info):<tab>res = []<tab>if not ""key_value"" in key_info:<tab><tab>return res<tab>for value in key_info[""key_value""]:<tab><tab><IF-STMT><tab><tab><tab>e = base64_to_long(value[""rsa_key_value""][""exponent""])<tab><tab><tab>m = base64_to_long(value[""rsa_key_value""][""modulus""])<tab><tab><tab>key = RSA.construct((m, e))<tab><tab><tab>res.append(key)<tab>return res",1,"if ""rsa_key_value"" in value :","if ""rsa_key_value"" in value :",0.75,100.00000000000004,1.0
"def run(self, edit):<tab>if not self.has_selection():<tab><tab>region = sublime.Region(0, self.view.size())<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab><IF-STMT><tab><tab><tab>self.view.replace(edit, region, prefixed)<tab><tab>return<tab>for region in self.view.sel():<tab><tab>if region.empty():<tab><tab><tab>continue<tab><tab>originalBuffer = self.view.substr(region)<tab><tab>prefixed = self.prefix(originalBuffer)<tab><tab>if prefixed:<tab><tab><tab>self.view.replace(edit, region, prefixed)",1,if prefixed :,if prefixed :,0.5311706625951745,1e-10,1.0
def finalize(self):<tab>if self.ct < 1:<tab><tab>return<tab>elif self.ct == 1:<tab><tab>return 0<tab>total = ct = 0<tab>dtp = None<tab>while self.heap:<tab><tab><IF-STMT><tab><tab><tab>if dtp is None:<tab><tab><tab><tab>dtp = heapq.heappop(self.heap)<tab><tab><tab><tab>continue<tab><tab>dt = heapq.heappop(self.heap)<tab><tab>diff = dt - dtp<tab><tab>ct += 1<tab><tab>total += total_seconds(diff)<tab><tab>dtp = dt<tab>return float(total) / ct,0,if total == 0 :,if dtp is None :,0.03412306583404374,10.400597689005304,0.23809523809523808
"def _test_configuration(self):<tab>config_path = self._write_config()<tab>try:<tab><tab>self._log.debug(""testing configuration"")<tab><tab>verboseflag = ""-Q""<tab><tab><IF-STMT><tab><tab><tab>verboseflag = ""-v""<tab><tab>p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path])<tab><tab>if p.wait() != 0:<tab><tab><tab>raise RuntimeError(""configuration test failed"")<tab><tab>self._log.debug(""configuration seems ok"")<tab>finally:<tab><tab>os.remove(config_path)",0,if self . _log . isEnabledFor ( logging . DEBUG ) :,"if sys . platform == ""win32"" :",0.09509946640853303,4.091092899898373,0.234375
"def exe(self, ret):<tab>if not ret:<tab><tab>self.assertEqual(ret, """")<tab>else:<tab><tab>assert os.path.isabs(ret), ret<tab><tab># Note: os.stat() may return False even if the file is there<tab><tab># hence we skip the test, see:<tab><tab># http://stackoverflow.com/questions/3112546/os-path-exists-lies<tab><tab><IF-STMT><tab><tab><tab>assert os.path.isfile(ret), ret<tab><tab><tab>if hasattr(os, ""access"") and hasattr(os, ""X_OK""):<tab><tab><tab><tab># XXX may fail on OSX<tab><tab><tab><tab>self.assertTrue(os.access(ret, os.X_OK))",0,if POSIX :,"if hasattr ( os , ""stat"" ) :",0.04422835593777517,1e-10,0.38181818181818183
"def _do_cleanup(sg_name, device_id):<tab>masking_view_list = self.rest.get_masking_views_from_storage_group(array, sg_name)<tab>for masking_view in masking_view_list:<tab><tab><IF-STMT><tab><tab><tab>self.rest.delete_masking_view(array, masking_view)<tab><tab><tab>self.rest.remove_vol_from_sg(array, sg_name, device_id, extra_specs)<tab><tab><tab>self.rest.delete_volume(array, device_id)<tab><tab><tab>self.rest.delete_storage_group(array, sg_name)",0,"if ""STG-"" in masking_view :",if masking_view :,0.06767423853569741,1e-10,0.6190476190476191
"def hide_tooltip_if_necessary(self, key):<tab>""""""Hide calltip when necessary""""""<tab>try:<tab><tab>calltip_char = self.get_character(self.calltip_position)<tab><tab>before = self.is_cursor_before(self.calltip_position, char_offset=1)<tab><tab>other = key in (Qt.Key_ParenRight, Qt.Key_Period, Qt.Key_Tab)<tab><tab><IF-STMT><tab><tab><tab>QToolTip.hideText()<tab>except (IndexError, TypeError):<tab><tab>QToolTip.hideText()",0,"if calltip_char not in ( ""?"" , ""("" ) or before or other :",if before and other and not before :,0.14960219148136927,1.8425889581875001,0.25
"def list_tags_for_stream(self, stream_name, exclusive_start_tag_key=None, limit=None):<tab>stream = self.describe_stream(stream_name)<tab>tags = []<tab>result = {""HasMoreTags"": False, ""Tags"": tags}<tab>for key, val in sorted(stream.tags.items(), key=lambda x: x[0]):<tab><tab>if limit and len(tags) >= limit:<tab><tab><tab>result[""HasMoreTags""] = True<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>tags.append({""Key"": key, ""Value"": val})<tab>return result",0,if exclusive_start_tag_key and key < exclusive_start_tag_key :,if exclusive_start_tag_key and key in exclusive_start_tag_key :,0.34627283061723435,84.92326635760686,0.7714285714285715
"def parametrize_function_name(request, function_name):<tab>suffixes = []<tab>if ""parametrize"" in request.keywords:<tab><tab>argnames = request.keywords[""parametrize""].args[::2]<tab><tab>argnames = [x.strip() for names in argnames for x in names.split("","")]<tab><tab>for name in argnames:<tab><tab><tab>value = request.getfuncargvalue(name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.__name__<tab><tab><tab>suffixes.append(""{}={}"".format(name, value))<tab>return ""+"".join([function_name] + suffixes)",0,if inspect . isclass ( value ) :,"if hasattr ( value , ""__name__"" ) :",0.044942074429907865,8.493098745313148,0.3148148148148148
"def add_entities(self, positions):<tab>e1 = EntityFactory()<tab>for p in positions:<tab><tab><IF-STMT><tab><tab><tab>start, length = p<tab><tab>else:<tab><tab><tab>start, length = p, 1<tab><tab>EntityOccurrenceFactory(<tab><tab><tab>document=self.doc,<tab><tab><tab>entity=e1,<tab><tab><tab>offset=start,<tab><tab><tab>offset_end=start + length,<tab><tab><tab>alias=""AB"",<tab><tab>)",1,"if isinstance ( p , tuple ) :","if isinstance ( p , tuple ) :",0.75,100.00000000000004,1.0
"def transform_value(value):<tab>if isinstance(value, collections.MutableMapping):<tab><tab><IF-STMT><tab><tab><tab>return DBRef(value[""_ns""], transform_value(value[""_id""]))<tab><tab>else:<tab><tab><tab>return transform_dict(SON(value))<tab>elif isinstance(value, list):<tab><tab>return [transform_value(v) for v in value]<tab>return value",0,"if ""_id"" in value and ""_ns"" in value :","if ""_ns"" in value :",0.16279282519794364,39.424375722306635,0.6
"def remove(self, items):<tab>""""""Remove messages from lease management.""""""<tab>with self._add_remove_lock:<tab><tab># Remove the ack ID from lease management, and decrement the<tab><tab># byte counter.<tab><tab>for item in items:<tab><tab><tab>if self._leased_messages.pop(item.ack_id, None) is not None:<tab><tab><tab><tab>self._bytes -= item.byte_size<tab><tab><tab>else:<tab><tab><tab><tab>_LOGGER.debug(""Item %s was not managed."", item.ack_id)<tab><tab><IF-STMT><tab><tab><tab>_LOGGER.debug(""Bytes was unexpectedly negative: %d"", self._bytes)<tab><tab><tab>self._bytes = 0",1,if self . _bytes < 0 :,if self . _bytes < 0 :,0.75,100.00000000000004,1.0
"def parse_hgsub(lines):<tab>""""""Fills OrderedDict with hgsub file content passed as list of lines""""""<tab>rv = OrderedDict()<tab>for l in lines:<tab><tab>ls = l.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>name, value = l.split(""="", 1)<tab><tab>rv[name.strip()] = value.strip()<tab>return rv",0,"if not ls or ls [ 0 ] == ""#"" :","if ls . startswith ( ""#"" ) :",0.014083696926176809,12.451233733093902,0.25274725274725274
"def del_(self, key):<tab>initial_hash = hash_ = self.hash(key)<tab>while True:<tab><tab>if self._keys[hash_] is self._empty:<tab><tab><tab># That key was never assigned<tab><tab><tab>return None<tab><tab>elif self._keys[hash_] == key:<tab><tab><tab># key found, assign with deleted sentinel<tab><tab><tab>self._keys[hash_] = self._deleted<tab><tab><tab>self._values[hash_] = self._deleted<tab><tab><tab>self._len -= 1<tab><tab><tab>return<tab><tab>hash_ = self._rehash(hash_)<tab><tab><IF-STMT><tab><tab><tab># table is full and wrapped around<tab><tab><tab>return None",0,if initial_hash == hash_ :,if hash_ == initial_hash :,0.2901714209472326,27.77619034011791,1.0
"def atom(token, no_symbol=False):<tab>try:<tab><tab>return int(token)<tab>except ValueError:<tab><tab>try:<tab><tab><tab>return float(token)<tab><tab>except ValueError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return token[1:-1]<tab><tab><tab>elif no_symbol:<tab><tab><tab><tab>return token<tab><tab><tab>else:<tab><tab><tab><tab>return Symbol(token)",0,"if token . startswith ( ""'"" ) or token . startswith ( '""' ) :","if token . startswith ( ""'"" ) and token . endswith ( ""'"" ) :",0.4976012394234789,54.261135429262374,0.5238095238095238
"def __Suffix_Noun_Step1b(self, token):<tab>for suffix in self.__suffix_noun_step1b:<tab><tab><IF-STMT><tab><tab><tab>token = token[:-1]<tab><tab><tab>self.suffixe_noun_step1b_success = True<tab><tab><tab>break<tab>return token",0,if token . endswith ( suffix ) and len ( token ) > 5 :,if token . endswith ( suffix ) :,0.28184453892234934,36.24372413507827,0.5555555555555556
"def _guardAgainstUnicode(self, data):<tab># Only accept byte strings or ascii unicode values, otherwise<tab># there is no way to correctly decode the data into bytes.<tab>if _pythonMajorVersion < 3:<tab><tab><IF-STMT><tab><tab><tab>data = data.encode(""utf8"")<tab>else:<tab><tab>if isinstance(data, str):<tab><tab><tab># Only accept ascii unicode values.<tab><tab><tab>try:<tab><tab><tab><tab>return data.encode(""ascii"")<tab><tab><tab>except UnicodeEncodeError:<tab><tab><tab><tab>pass<tab><tab><tab>raise ValueError(""pyDes can only work with encoded strings, not Unicode."")<tab>return data",0,"if isinstance ( data , unicode ) :","if isinstance ( data , bytes ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def populate_resource_parameters(self, tool_source):<tab>root = getattr(tool_source, ""root"", None)<tab>if (<tab><tab>root is not None<tab><tab>and hasattr(self.app, ""job_config"")<tab><tab>and hasattr(self.app.job_config, ""get_tool_resource_xml"")<tab>):<tab><tab>resource_xml = self.app.job_config.get_tool_resource_xml(<tab><tab><tab>root.get(""id""), self.tool_type<tab><tab>)<tab><tab>if resource_xml is not None:<tab><tab><tab>inputs = root.find(""inputs"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>inputs = parse_xml_string(""<inputs/>"")<tab><tab><tab><tab>root.append(inputs)<tab><tab><tab>inputs.append(resource_xml)",0,if inputs is None :,if not inputs :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def test_arguments_regex(self):<tab>argument_matches = (<tab><tab>(""pip=1.1"", (""pip"", ""1.1"")),<tab><tab>(""pip==1.1"", None),<tab><tab>(""pip=1.2=1"", (""pip"", ""1.2=1"")),<tab>)<tab>for argument, match in argument_matches:<tab><tab><IF-STMT><tab><tab><tab>self.assertIsNone(salt.utils.args.KWARG_REGEX.match(argument))<tab><tab>else:<tab><tab><tab>self.assertEqual(<tab><tab><tab><tab>salt.utils.args.KWARG_REGEX.match(argument).groups(), match<tab><tab><tab>)",1,if match is None :,if match is None :,0.75,100.00000000000004,1.0
"def _get_sidebar_selected(self):<tab>sidebar_selected = None<tab>if self.businessline_id:<tab><tab>sidebar_selected = ""bl_%s"" % self.businessline_id<tab><tab>if self.service_id:<tab><tab><tab>sidebar_selected += ""_s_%s"" % self.service_id<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sidebar_selected += ""_env_%s"" % self.environment_id<tab>return sidebar_selected",1,if self . environment_id :,if self . environment_id :,0.75,100.00000000000004,1.0
"def get_ip_info(ipaddress):<tab>""""""Returns device information by IP address""""""<tab>result = {}<tab>try:<tab><tab>ip = IPAddress.objects.select_related().get(address=ipaddress)<tab>except IPAddress.DoesNotExist:<tab><tab>pass<tab>else:<tab><tab>if ip.venture is not None:<tab><tab><tab>result[""venture_id""] = ip.venture.id<tab><tab><IF-STMT><tab><tab><tab>result[""device_id""] = ip.device.id<tab><tab><tab>if ip.device.venture is not None:<tab><tab><tab><tab>result[""venture_id""] = ip.device.venture.id<tab>return result",1,if ip . device is not None :,if ip . device is not None :,0.75,100.00000000000004,1.0
"def apply(self, db, person):<tab>for family_handle in person.get_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab>if family:<tab><tab><tab>for event_ref in family.get_event_ref_list():<tab><tab><tab><tab>if event_ref:<tab><tab><tab><tab><tab>event = db.get_event_from_handle(event_ref.ref)<tab><tab><tab><tab><tab>if not event.get_place_handle():<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False",0,if not event . get_date_object ( ) :,if not event . get_place_handle ( ) :,0.5014622369176811,54.52469119630866,1.0
"def killIfDead():<tab>if not self._isalive:<tab><tab>self.log.debug(<tab><tab><tab>""WampLongPoll: killing inactive WAMP session with transport '{0}'"".format(<tab><tab><tab><tab>self._transport_id<tab><tab><tab>)<tab><tab>)<tab><tab>self.onClose(False, 5000, ""session inactive"")<tab><tab>self._receive._kill()<tab><tab><IF-STMT><tab><tab><tab>del self._parent._transports[self._transport_id]<tab>else:<tab><tab>self.log.debug(<tab><tab><tab>""WampLongPoll: transport '{0}' is still alive"".format(self._transport_id)<tab><tab>)<tab><tab>self._isalive = False<tab><tab>self.reactor.callLater(killAfter, killIfDead)",1,if self . _transport_id in self . _parent . _transports :,if self . _transport_id in self . _parent . _transports :,0.75,100.00000000000004,1.0
"def offsets(self):<tab>offsets = {}<tab>offset_so_far = 0<tab>for name, ty in self.fields.items():<tab><tab><IF-STMT><tab><tab><tab>l.warning(<tab><tab><tab><tab>""Found a bottom field in struct %s. Ignore and increment the offset using the default ""<tab><tab><tab><tab>""element size."",<tab><tab><tab><tab>self.name,<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>if not self._pack:<tab><tab><tab>align = ty.alignment<tab><tab><tab>if offset_so_far % align != 0:<tab><tab><tab><tab>offset_so_far += align - offset_so_far % align<tab><tab>offsets[name] = offset_so_far<tab><tab>offset_so_far += ty.size // self._arch.byte_width<tab>return offsets",0,"if isinstance ( ty , SimTypeBottom ) :","if name == ""bottom"" :",0.01858685153282265,6.567274736060395,0.3
"def get_override_css(self):<tab>""""""handls allow_css_overrides setting.""""""<tab>if self.settings.get(""allow_css_overrides""):<tab><tab>filename = self.view.file_name()<tab><tab>filetypes = self.settings.get(""markdown_filetypes"")<tab><tab><IF-STMT><tab><tab><tab>for filetype in filetypes:<tab><tab><tab><tab>if filename.endswith(filetype):<tab><tab><tab><tab><tab>css_filename = filename.rpartition(filetype)[0] + "".css""<tab><tab><tab><tab><tab>if os.path.isfile(css_filename):<tab><tab><tab><tab><tab><tab>return u""<style>%s</style>"" % load_utf8(css_filename)<tab>return """"",0,if filename and filetypes :,if filetypes :,0.06767423853569741,1e-10,0.3
"def setFullCSSSource(self, fullsrc, inline=False):<tab>self.fullsrc = fullsrc<tab>if type(self.fullsrc) == six.binary_type:<tab><tab>self.fullsrc = six.text_type(self.fullsrc, ""utf-8"")<tab>if inline:<tab><tab>self.inline = inline<tab>if self.fullsrc:<tab><tab>self.srcFullIdx = self.fullsrc.find(self.src)<tab><tab>if self.srcFullIdx < 0:<tab><tab><tab>del self.srcFullIdx<tab><tab>self.ctxsrcFullIdx = self.fullsrc.find(self.ctxsrc)<tab><tab><IF-STMT><tab><tab><tab>del self.ctxsrcFullIdx",1,if self . ctxsrcFullIdx < 0 :,if self . ctxsrcFullIdx < 0 :,0.75,100.00000000000004,1.0
"def title(self):<tab>ret = theme[""title""]<tab>if isinstance(self.name, six.string_types):<tab><tab>width = self.statwidth()<tab><tab>return (<tab><tab><tab>ret + self.name[0:width].center(width).replace("" "", ""-"") + theme[""default""]<tab><tab>)<tab>for i, name in enumerate(self.name):<tab><tab>width = self.colwidth()<tab><tab>ret = ret + name[0:width].center(width).replace("" "", ""-"")<tab><tab>if i + 1 != len(self.vars):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = ret + theme[""frame""] + char[""dash""] + theme[""title""]<tab><tab><tab>else:<tab><tab><tab><tab>ret = ret + char[""space""]<tab>return ret",0,if op . color :,"if self . vars [ i + 1 ] == ""frame"" :",0.02446681277480503,3.4585921141027356,0.234375
"def _get_requested_databases(self):<tab>""""""Returns a list of databases requested, not including ignored dbs""""""<tab>requested_databases = []<tab>if (self._requested_namespaces is not None) and (self._requested_namespaces != []):<tab><tab>for requested_namespace in self._requested_namespaces:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return []<tab><tab><tab>elif requested_namespace[0] not in IGNORE_DBS:<tab><tab><tab><tab>requested_databases.append(requested_namespace[0])<tab>return requested_databases",0,"if requested_namespace [ 0 ] is ""*"" :",if requested_namespace [ 0 ] in IGNORE_DBS :,0.3574848522974078,53.3167536340577,0.6
"def add_channels(cls, voucher, add_channels):<tab>for add_channel in add_channels:<tab><tab>channel = add_channel[""channel""]<tab><tab>defaults = {""currency"": channel.currency_code}<tab><tab><IF-STMT><tab><tab><tab>defaults[""discount_value""] = add_channel.get(""discount_value"")<tab><tab>if ""min_amount_spent"" in add_channel.keys():<tab><tab><tab>defaults[""min_spent_amount""] = add_channel.get(""min_amount_spent"", None)<tab><tab>models.VoucherChannelListing.objects.update_or_create(<tab><tab><tab>voucher=voucher,<tab><tab><tab>channel=channel,<tab><tab><tab>defaults=defaults,<tab><tab>)",1,"if ""discount_value"" in add_channel . keys ( ) :","if ""discount_value"" in add_channel . keys ( ) :",0.75,100.00000000000004,1.0
"def read_xml(path):<tab>with tf.gfile.GFile(path) as f:<tab><tab>root = etree.fromstring(f.read())<tab>annotations = {}<tab>for node in root.getchildren():<tab><tab>key, val = node2dict(node)<tab><tab># If `key` is object, it's actually a list.<tab><tab><IF-STMT><tab><tab><tab>annotations.setdefault(key, []).append(val)<tab><tab>else:<tab><tab><tab>annotations[key] = val<tab>return annotations",0,"if key == ""object"" :","if isinstance ( val , dict ) :",0.026407399022921448,6.567274736060395,0.3
"def get_ip_info(ipaddress):<tab>""""""Returns device information by IP address""""""<tab>result = {}<tab>try:<tab><tab>ip = IPAddress.objects.select_related().get(address=ipaddress)<tab>except IPAddress.DoesNotExist:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>result[""venture_id""] = ip.venture.id<tab><tab>if ip.device is not None:<tab><tab><tab>result[""device_id""] = ip.device.id<tab><tab><tab>if ip.device.venture is not None:<tab><tab><tab><tab>result[""venture_id""] = ip.device.venture.id<tab>return result",0,if ip . venture is not None :,if ip . eventure is not None :,0.5014622369176811,50.000000000000014,0.75
"def test_large_headers(self):<tab>with ExpectLog(gen_log, ""Unsatisfiable read"", required=False):<tab><tab>try:<tab><tab><tab>self.fetch(""/"", headers={""X-Filler"": ""a"" * 1000}, raise_error=True)<tab><tab><tab>self.fail(""did not raise expected exception"")<tab><tab>except HTTPError as e:<tab><tab><tab># 431 is ""Request Header Fields Too Large"", defined in RFC<tab><tab><tab># 6585. However, many implementations just close the<tab><tab><tab># connection in this case, resulting in a missing response.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertIn(e.response.code, (431, 599))",0,if e . response is not None :,if e . response and e . response . code != 431 :,0.3134374204741738,18.798317647335093,0.31666666666666665
"def validate_reserved_serial_no_consumption(self):<tab>for item in self.items:<tab><tab>if item.s_warehouse and not item.t_warehouse and item.serial_no:<tab><tab><tab>for sr in get_serial_nos(item.serial_no):<tab><tab><tab><tab>sales_order = frappe.db.get_value(""Serial No"", sr, ""sales_order"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>msg = _(<tab><tab><tab><tab><tab><tab>""(Serial No: {0}) cannot be consumed as it's reserverd to fullfill Sales Order {1}.""<tab><tab><tab><tab><tab>).format(sr, sales_order)<tab><tab><tab><tab><tab>frappe.throw(_(""Item {0} {1}"").format(item.item_code, msg))",1,if sales_order :,if sales_order :,0.5311706625951745,1e-10,1.0
"def force_decode(string, encoding):<tab>if isinstance(string, str):<tab><tab><IF-STMT><tab><tab><tab>string = string.decode(encoding)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab># try decoding with utf-8, should only work for real UTF-8<tab><tab><tab><tab>string = string.decode(""utf-8"")<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab># last resort -- can't fail<tab><tab><tab><tab>string = string.decode(""latin1"")<tab>return string",1,if encoding :,if encoding :,0.5311706625951745,1e-10,1.0
"def _add_cs(master_cs, sub_cs, prefix, delimiter=""."", parent_hp=None):<tab>new_parameters = []<tab>for hp in sub_cs.get_hyperparameters():<tab><tab>new_parameter = copy.deepcopy(hp)<tab><tab># Allow for an empty top-level parameter<tab><tab>if new_parameter.name == """":<tab><tab><tab>new_parameter.name = prefix<tab><tab><IF-STMT><tab><tab><tab>new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name)<tab><tab>new_parameters.append(new_parameter)<tab>for hp in new_parameters:<tab><tab>_add_hp(master_cs, hp)",0,"elif not prefix == """" :",elif new_parameter . name . endswith ( delimiter ) :,0.01841194960367783,4.02724819242185,0.27472527472527475
"def __call__(self, *args, **kwargs):<tab>if self.log_file is not None:<tab><tab>kwargs[""file""] = self.log_file<tab><tab>print(*args, **kwargs)<tab><tab><IF-STMT><tab><tab><tab># get immediate feedback<tab><tab><tab>self.log_file.flush()<tab>elif self.log_func is not None:<tab><tab>self.log_func(*args, **kwargs)",0,"if hasattr ( self . log_file , ""flush"" ) :",if self . log_file is not None :,0.062006595483074536,28.64190457979541,0.2619047619047619
"def df_index_expr(self, length_expr=None, as_range=False):<tab>""""""Generate expression to get or create index of DF""""""<tab>if isinstance(self.index, types.NoneType):<tab><tab><IF-STMT><tab><tab><tab>length_expr = df_length_expr(self)<tab><tab>if as_range:<tab><tab><tab>return f""range({length_expr})""<tab><tab>else:<tab><tab><tab>return f""numpy.arange({length_expr})""<tab>return ""self._index""",1,if length_expr is None :,if length_expr is None :,0.75,100.00000000000004,1.0
"def _setWeight(self, value):<tab>if value is None:<tab><tab>self._fontWeight = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise TextFormatException(f""Not a supported fontWeight: {value}"")<tab><tab>self._fontWeight = value.lower()",0,"if value . lower ( ) not in ( ""normal"" , ""bold"" ) :","if value . lower ( ) not in ( ""bold"" , ""bold"" ) :",0.6421018880022448,83.94327083733333,1.0
"def _test_configuration(self):<tab>config_path = self._write_config()<tab>try:<tab><tab>self._log.debug(""testing configuration"")<tab><tab>verboseflag = ""-Q""<tab><tab>if self._log.isEnabledFor(logging.DEBUG):<tab><tab><tab>verboseflag = ""-v""<tab><tab>p = subprocess.Popen([self.PATH_SLAPTEST, verboseflag, ""-f"", config_path])<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""configuration test failed"")<tab><tab>self._log.debug(""configuration seems ok"")<tab>finally:<tab><tab>os.remove(config_path)",0,if p . wait ( ) != 0 :,if p . returncode != 0 :,0.10337111117963321,38.940039153570254,0.6666666666666666
"def filter_queryset(self, request, queryset, view):<tab>kwargs = {}<tab>for field in view.filterset_fields:<tab><tab>value = request.GET.get(field)<tab><tab>if not value:<tab><tab><tab>continue<tab><tab>if field == ""node_id"":<tab><tab><tab>value = get_object_or_none(Node, pk=value)<tab><tab><tab>kwargs[""node""] = value<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>field = ""asset""<tab><tab>kwargs[field] = value<tab>if kwargs:<tab><tab>queryset = queryset.filter(**kwargs)<tab>logger.debug(""Filter {}"".format(kwargs))<tab>return queryset",0,"elif field == ""asset_id"" :","if field == ""asset_id"" :",0.334370152488211,88.01117367933934,0.5
"def _find_closing_brace(string, start_pos):<tab>""""""Finds the corresponding closing brace after start_pos.""""""<tab>bracks_open = 1<tab>for idx, char in enumerate(string[start_pos:]):<tab><tab>if char == ""("":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>bracks_open += 1<tab><tab>elif char == "")"":<tab><tab><tab>if string[idx + start_pos - 1] != ""\\"":<tab><tab><tab><tab>bracks_open -= 1<tab><tab><tab>if not bracks_open:<tab><tab><tab><tab>return start_pos + idx + 1",1,"if string [ idx + start_pos - 1 ] != ""\\"" :","if string [ idx + start_pos - 1 ] != ""\\"" :",0.75,100.00000000000004,1.0
"def _set_hostport(self, host, port):<tab>if port is None:<tab><tab>i = host.rfind("":"")<tab><tab>j = host.rfind(""]"")  # ipv6 addresses have [...]<tab><tab>if i > j:<tab><tab><tab>try:<tab><tab><tab><tab>port = int(host[i + 1 :])<tab><tab><tab>except ValueError:<tab><tab><tab><tab>raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :])<tab><tab><tab>host = host[:i]<tab><tab>else:<tab><tab><tab>port = self.default_port<tab><tab><IF-STMT><tab><tab><tab>host = host[1:-1]<tab>self.host = host<tab>self.port = port",0,"if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :","if host [ 0 ] == "":"" and host [ - 1 ] == "":"" :",0.5341140674165504,66.23934495713621,0.38484848484848483
"def __getstate__(self):<tab>state = {}<tab>for cls in type(self).mro():<tab><tab>cls_slots = getattr(cls, ""__slots__"", ())<tab><tab>for slot in cls_slots:<tab><tab><tab>if slot != ""__weakref__"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>state[slot] = getattr(self, slot)<tab>state[""_cookiejar_cookies""] = list(self.cookiejar)<tab>del state[""cookiejar""]<tab>return state",1,"if hasattr ( self , slot ) :","if hasattr ( self , slot ) :",0.75,100.00000000000004,1.0
"def _evp_pkey_from_der_traditional_key(self, bio_data, password):<tab>key = self._lib.d2i_PrivateKey_bio(bio_data.bio, self._ffi.NULL)<tab>if key != self._ffi.NULL:<tab><tab>key = self._ffi.gc(key, self._lib.EVP_PKEY_free)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""Password was given but private key is not encrypted."")<tab><tab>return key<tab>else:<tab><tab>self._consume_errors()<tab><tab>return None",0,if password is not None :,if password != self . _ffi . NULL :,0.040012802751399616,8.29519350710986,0.3611111111111111
"def is_special(s, i, directive):<tab>""""""Return True if the body text contains the @ directive.""""""<tab># j = skip_line(s,i) ; trace(s[i:j],':',directive)<tab>assert directive and directive[0] == ""@""<tab># 10/23/02: all directives except @others must start the line.<tab>skip_flag = directive in (""@others"", ""@all"")<tab>while i < len(s):<tab><tab><IF-STMT><tab><tab><tab>return True, i<tab><tab>else:<tab><tab><tab>i = skip_line(s, i)<tab><tab><tab>if skip_flag:<tab><tab><tab><tab>i = skip_ws(s, i)<tab>return False, -1",0,"if match_word ( s , i , directive ) :",if s [ i ] == directive [ 0 ] :,0.015448530895055629,5.063996506781411,0.8205128205128206
"def _decorator(coro_func):<tab>fut = asyncio.ensure_future(coro_func())<tab>self._tests.append((coro_func.__name__, fut))<tab>if timeout_sec is not None:<tab><tab>timeout_at = self._loop.time() + timeout_sec<tab><tab>handle = self.MASTER_LOOP.call_at(<tab><tab><tab>timeout_at, self._set_exception_if_not_done, fut, asyncio.TimeoutError()<tab><tab>)<tab><tab>fut.add_done_callback(lambda *args: handle.cancel())<tab><tab><IF-STMT><tab><tab><tab>self._global_timeout_at = timeout_at<tab>return coro_func",0,if timeout_at > self . _global_timeout_at :,if self . _global_timeout_at is None :,0.177812267404864,54.88684910025905,0.55
"def _load(self, db, owner):<tab>self.__init(owner)<tab>db_result = db(<tab><tab>""SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ?"",<tab><tab>self.owner.worldid,<tab>)<tab>for (<tab><tab>ship_id,<tab><tab>state_id,<tab>) in db_result:<tab><tab>ship = WorldObject.get_object_by_id(ship_id)<tab><tab>state = self.shipStates[state_id]<tab><tab># add move callbacks corresponding to given state<tab><tab><IF-STMT><tab><tab><tab>ship.add_move_callback(Callback(BehaviorMoveCallback._arrived, ship))<tab><tab>self.add_new_unit(ship, state)",0,if state == self . shipStates . moving :,"if state == ""arrived"" :",0.06668418984860812,28.46946938149361,0.4545454545454546
"def addError(self, test, err):<tab>if err[0] is SkipTest:<tab><tab><IF-STMT><tab><tab><tab>self.stream.writeln(str(err[1]))<tab><tab>elif self.dots:<tab><tab><tab>self.stream.write(""s"")<tab><tab><tab>self.stream.flush()<tab><tab>return<tab>_org_AddError(self, test, err)",0,if self . showAll :,if len ( err ) == 2 :,0.026407399022921448,5.669791110976001,0.2698412698412698
"def _construct(self, node):<tab>self.flatten_mapping(node)<tab>ret = self.construct_pairs(node)<tab>keys = [d[0] for d in ret]<tab>keys_sorted = sorted(keys, key=_natsort_key)<tab>for key in keys:<tab><tab>expected = keys_sorted.pop(0)<tab><tab><IF-STMT><tab><tab><tab>raise ConstructorError(<tab><tab><tab><tab>None,<tab><tab><tab><tab>None,<tab><tab><tab><tab>""keys out of order: ""<tab><tab><tab><tab>""expected {} got {} at {}"".format(expected, key, node.start_mark),<tab><tab><tab>)<tab>return dict(ret)",0,if key != expected :,if expected < key :,0.038498786468962445,12.368464772045972,0.5
"def sample_pos_items_for_u(u, num):<tab># sample num pos items for u-th user<tab>pos_items = self.train_items[u]<tab>n_pos_items = len(pos_items)<tab>pos_batch = []<tab>while True:<tab><tab>if len(pos_batch) == num:<tab><tab><tab>break<tab><tab>pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0]<tab><tab>pos_i_id = pos_items[pos_id]<tab><tab><IF-STMT><tab><tab><tab>pos_batch.append(pos_i_id)<tab>return pos_batch",0,if pos_i_id not in pos_batch :,if pos_i_id != 0 :,0.051719732411378776,43.98917247584221,0.37142857142857144
"def _get_id(self, type, id):<tab>fields = id.split("":"")<tab>if len(fields) >= 3:<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, fields[-2], id<tab><tab><tab>)<tab><tab>return fields[-1]<tab>fields = id.split(""/"")<tab>if len(fields) >= 3:<tab><tab>itype = fields[-2]<tab><tab>if type != itype:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Expected id of type %s but found type %s %s"", type, itype, id<tab><tab><tab>)<tab><tab>return fields[-1].split(""?"")[0]<tab>return id",1,if type != fields [ - 2 ] :,if type != fields [ - 2 ] :,0.75,100.00000000000004,1.0
"def uninstall_environments(self, environments):<tab>environments = [<tab><tab>env<tab><tab>if not env.startswith(self.conda_context.envs_path)<tab><tab>else os.path.basename(env)<tab><tab>for env in environments<tab>]<tab>return_codes = [self.conda_context.exec_remove([env]) for env in environments]<tab>final_return_code = 0<tab>for env, return_code in zip(environments, return_codes):<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Conda environment '%s' successfully removed."" % env)<tab><tab>else:<tab><tab><tab>log.debug(""Conda environment '%s' could not be removed."" % env)<tab><tab><tab>final_return_code = return_code<tab>return final_return_code",1,if return_code == 0 :,if return_code == 0 :,0.75,100.00000000000004,1.0
"def _add_hit_offset(self, context_list, string_name, original_offset, value):<tab>for context in context_list:<tab><tab>hits_by_context_dict = self.hits_by_context.setdefault(context, {})<tab><tab><IF-STMT><tab><tab><tab>hits_by_context_dict[string_name] = (<tab><tab><tab><tab>original_offset,<tab><tab><tab><tab>value.encode(""base64""),<tab><tab><tab>)",1,if string_name not in hits_by_context_dict :,if string_name not in hits_by_context_dict :,0.75,100.00000000000004,1.0
"def detab(self, text, length=None):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>if length is None:<tab><tab>length = self.tab_length<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab>if line.startswith("" "" * length):<tab><tab><tab>newtext.append(line[length:])<tab><tab><IF-STMT><tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",0,elif not line . strip ( ) :,elif len ( lines ) == length :,0.10297406587835899,6.742555929751843,0.25
"def dump(self):<tab>print(self.package_name)<tab>for package, value in self.entries:<tab><tab>print(str(package.version))<tab><tab><IF-STMT><tab><tab><tab>print(""<tab>[FILTERED]"")<tab><tab>elif isinstance(value, list):<tab><tab><tab>variants = value<tab><tab><tab>for variant in variants:<tab><tab><tab><tab>print(""<tab>%s"" % str(variant))<tab><tab>else:<tab><tab><tab>print(""<tab>%s"" % str(package))",1,if value is None :,if value is None :,0.75,100.00000000000004,1.0
"def __lexical_scope(*args, **kwargs):<tab>try:<tab><tab>scope = Scope(quasi)<tab><tab><IF-STMT><tab><tab><tab>binding_name_set_stack[-1].add_child(scope)<tab><tab>binding_name_set_stack.append(scope)<tab><tab>return func(*args, **kwargs)<tab>finally:<tab><tab>if binding_name_set_stack[-1] is scope:<tab><tab><tab>binding_name_set_stack.pop()",0,if quasi :,if binding_name_set_stack [ - 1 ] is scope :,0.04309983002500103,1e-10,0.3055555555555556
"def getnotes(self, origin=None):<tab>if origin is None:<tab><tab>result = self.translator_comments<tab><tab><IF-STMT><tab><tab><tab>if result:<tab><tab><tab><tab>result += ""\n"" + self.developer_comments<tab><tab><tab>else:<tab><tab><tab><tab>result = self.developer_comments<tab><tab>return result<tab>elif origin == ""translator"":<tab><tab>return self.translator_comments<tab>elif origin in (""programmer"", ""developer"", ""source code""):<tab><tab>return self.developer_comments<tab>else:<tab><tab>raise ValueError(""Comment type not valid"")",0,if self . developer_comments :,"elif origin == ""translator"" :",0.025028614496601525,5.522397783539471,0.2
"def fix_datetime_fields(data: TableData, table: TableName) -> None:<tab>for item in data[table]:<tab><tab>for field_name in DATE_FIELDS[table]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item[field_name] = datetime.datetime.fromtimestamp(<tab><tab><tab><tab><tab>item[field_name], tz=datetime.timezone.utc<tab><tab><tab><tab>)",0,if item [ field_name ] is not None :,if field_name in DATE_FIELDS :,0.1168380461076173,16.14682615668325,0.24675324675324675
"def _check_for_cart_error(cart):<tab>if cart._safe_get_element(""Cart.Request.Errors"") is not None:<tab><tab>error = cart._safe_get_element(""Cart.Request.Errors.Error.Code"").text<tab><tab><IF-STMT><tab><tab><tab>raise CartInfoMismatchException(<tab><tab><tab><tab>""CartGet failed: AWS.ECommerceService.CartInfoMismatch ""<tab><tab><tab><tab>""make sure AssociateTag, CartId and HMAC are correct ""<tab><tab><tab><tab>""(dont use URLEncodedHMAC!!!)""<tab><tab><tab>)<tab><tab>raise CartException(""CartGet failed: "" + error)",0,"if error == ""AWS.ECommerceService.CartInfoMismatch"" :","if error . startswith ( ""Invalid CartId"" ) :",0.04757349237680735,9.00746750211399,0.7307692307692308
"def check_bounds(geometry):<tab>if isinstance(geometry[0], (list, tuple)):<tab><tab>return list(map(check_bounds, geometry))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Longitude is out of bounds, check your JSON format or data""<tab><tab><tab>)<tab><tab>if geometry[1] > 90 or geometry[1] < -90:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Latitude is out of bounds, check your JSON format or data""<tab><tab><tab>)",0,if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,if geometry [ 0 ] > 90 or geometry [ 0 ] < - 90 :,0.8444662396759115,68.65065103648593,0.7142857142857143
"def _mapper_output_protocol(self, step_num, step_map):<tab>map_key = self._step_key(step_num, ""mapper"")<tab>if map_key in step_map:<tab><tab><IF-STMT><tab><tab><tab>return self.output_protocol()<tab><tab>else:<tab><tab><tab>return self.internal_protocol()<tab>else:<tab><tab># mapper is not a script substep, so protocols don't apply at all<tab><tab>return RawValueProtocol()",0,if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,"if step_map [ map_key ] == ""output"" :",0.15658233377844857,36.343459007702876,0.4807692307692308
"def asset(*paths):<tab>for path in paths:<tab><tab>fspath = www_root + ""/assets/"" + path<tab><tab>etag = """"<tab><tab>try:<tab><tab><tab>if env.cache_static:<tab><tab><tab><tab>etag = asset_etag(fspath)<tab><tab><tab>else:<tab><tab><tab><tab>os.stat(fspath)<tab><tab>except FileNotFoundError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not os.path.exists(fspath + "".spt""):<tab><tab><tab><tab><tab>tell_sentry(e, {})<tab><tab><tab>else:<tab><tab><tab><tab>continue<tab><tab>except Exception as e:<tab><tab><tab>tell_sentry(e, {})<tab><tab>return asset_url + path + (etag and ""?etag="" + etag)",0,if path == paths [ - 1 ] :,if e . errno == errno . ENOENT :,0.016784918517629303,9.980099403873663,0.2361111111111111
"def ping(self, payload: Union[str, bytes] = """") -> None:<tab>if self.trace_enabled and self.ping_pong_trace_enabled:<tab><tab><IF-STMT><tab><tab><tab>payload = payload.decode(""utf-8"")<tab><tab>self.logger.debug(<tab><tab><tab>""Sending a ping data frame ""<tab><tab><tab>f""(session id: {self.session_id}, payload: {payload})""<tab><tab>)<tab>data = _build_data_frame_for_sending(payload, FrameHeader.OPCODE_PING)<tab>with self.sock_send_lock:<tab><tab>self.sock.send(data)",1,"if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",0.75,100.00000000000004,1.0
"def is_ac_power_connected():<tab>for power_source_path in Path(""/sys/class/power_supply/"").iterdir():<tab><tab>try:<tab><tab><tab>with open(power_source_path / ""type"", ""r"") as f:<tab><tab><tab><tab>if f.read().strip() != ""Mains"":<tab><tab><tab><tab><tab>continue<tab><tab><tab>with open(power_source_path / ""online"", ""r"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab>except IOError:<tab><tab><tab>continue<tab>return False",0,"if f . read ( 1 ) == ""1"" :","if f . read ( ) . strip ( ) == ""Connected"" :",0.20478957134002002,41.69392927528885,0.6666666666666666
"def handle_noargs(self, **options):<tab>self.style = color_style()<tab>print(""Running Django's own validation:"")<tab>self.validate(display_num_errors=True)<tab>for model in loading.get_models():<tab><tab><IF-STMT><tab><tab><tab>self.validate_base_model(model)<tab><tab>if hasattr(model, ""_feincms_content_models""):<tab><tab><tab>self.validate_content_type(model)",0,"if hasattr ( model , ""_create_content_base"" ) :","if hasattr ( model , ""_feincms_base_models"" ) :",0.5490406812970063,54.10822690539399,1.0
"def _init_weights(self, module):<tab>if isinstance(module, nn.Linear):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab><IF-STMT><tab><tab><tab>module.bias.data.zero_()<tab>elif isinstance(module, nn.Embedding):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab>if module.padding_idx is not None:<tab><tab><tab>module.weight.data[module.padding_idx].zero_()",1,if module . bias is not None :,if module . bias is not None :,0.75,100.00000000000004,1.0
"def walk(msg, callback, data):<tab>partnum = 0<tab>for part in msg.walk():<tab><tab># multipart/* are just containers<tab><tab>if part.get_content_maintype() == ""multipart"":<tab><tab><tab>continue<tab><tab>ctype = part.get_content_type()<tab><tab><IF-STMT><tab><tab><tab>ctype = OCTET_TYPE<tab><tab>filename = part.get_filename()<tab><tab>if not filename:<tab><tab><tab>filename = PART_FN_TPL % (partnum)<tab><tab>headers = dict(part)<tab><tab>LOG.debug(headers)<tab><tab>headers[""Content-Type""] = ctype<tab><tab>payload = util.fully_decoded_payload(part)<tab><tab>callback(data, filename, payload, headers)<tab><tab>partnum = partnum + 1",0,if ctype is None :,if not ctype :,0.03944961859844226,16.37226966703825,0.27777777777777773
"def _mark_lcs(mask, dirs, m, n):<tab>while m != 0 and n != 0:<tab><tab>if dirs[m, n] == ""|"":<tab><tab><tab>m -= 1<tab><tab><tab>n -= 1<tab><tab><tab>mask[m] = 1<tab><tab><IF-STMT><tab><tab><tab>m -= 1<tab><tab>elif dirs[m, n] == ""<"":<tab><tab><tab>n -= 1<tab><tab>else:<tab><tab><tab>raise UnboundLocalError(""Illegal move"")<tab>return mask",0,"elif dirs [ m , n ] == ""^"" :","elif dirs [ m , n ] == "">"" :",0.6412711450183218,79.10665071754353,1.0
"def valid_localparts(strip_delimiters=False):<tab>for line in ABRIDGED_LOCALPART_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab># skip over localparts with delimiters<tab><tab>if strip_delimiters:<tab><tab><tab>if "","" in line or "";"" in line:<tab><tab><tab><tab>continue<tab><tab>yield line",0,"if line == """" :",if not line :,0.03944961859844226,9.930283522141846,0.45
"def fetch(self, *tileables, **kw):<tab>ret_list = False<tab>if len(tileables) == 1 and isinstance(tileables[0], (tuple, list)):<tab><tab>ret_list = True<tab><tab>tileables = tileables[0]<tab>elif len(tileables) > 1:<tab><tab>ret_list = True<tab>result = self._sess.fetch(*tileables, **kw)<tab>ret = []<tab>for r, t in zip(result, tileables):<tab><tab><IF-STMT><tab><tab><tab>ret.append(r.item())<tab><tab>else:<tab><tab><tab>ret.append(r)<tab>if ret_list:<tab><tab>return ret<tab>return ret[0]",0,"if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :",if t :,0.034242840963217926,1e-10,0.17567567567567569
"def _convert(container):<tab>if _value_marker in container:<tab><tab>force_list = False<tab><tab>values = container.pop(_value_marker)<tab><tab>if container.pop(_list_marker, False):<tab><tab><tab>force_list = True<tab><tab><tab>values.extend(_convert(x[1]) for x in sorted(container.items()))<tab><tab><IF-STMT><tab><tab><tab>values = values[0]<tab><tab>if not container:<tab><tab><tab>return values<tab><tab>return _convert(container)<tab>elif container.pop(_list_marker, False):<tab><tab>return [_convert(x[1]) for x in sorted(container.items())]<tab>return dict_cls((k, _convert(v)) for k, v in iteritems(container))",0,if not force_list and len ( values ) == 1 :,if force_list :,0.009691017295795237,1e-10,0.23809523809523808
"def _transform_init_kwargs(cls, kwargs):<tab>transformed = []<tab>for field in list(kwargs.keys()):<tab><tab>prop = getattr(cls, field, None)<tab><tab><IF-STMT><tab><tab><tab>value = kwargs.pop(field)<tab><tab><tab>_transform_single_init_kwarg(prop, field, value, kwargs)<tab><tab><tab>transformed.append((field, value))<tab>return transformed",0,"if isinstance ( prop , MoneyProperty ) :",if prop is not None :,0.01983074478100545,7.654112967106117,0.23214285714285715
"def haslayer(self, cls):<tab>""""""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax.""""""<tab>if self.__class__ == cls or self.__class__.__name__ == cls:<tab><tab>return 1<tab>for f in self.packetfields:<tab><tab>fvalue_gen = self.getfieldval(f.name)<tab><tab>if fvalue_gen is None:<tab><tab><tab>continue<tab><tab>if not f.islist:<tab><tab><tab>fvalue_gen = SetGen(fvalue_gen, _iterpacket=0)<tab><tab>for fvalue in fvalue_gen:<tab><tab><tab>if isinstance(fvalue, Packet):<tab><tab><tab><tab>ret = fvalue.haslayer(cls)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return ret<tab>return self.payload.haslayer(cls)",1,if ret :,if ret :,0.5311706625951745,1e-10,1.0
def insert_broken_add_sometimes(node):<tab>if node.op == theano.tensor.add:<tab><tab>last_time_replaced[0] = not last_time_replaced[0]<tab><tab><IF-STMT><tab><tab><tab>return [off_by_half(*node.inputs)]<tab>return False,1,if last_time_replaced [ 0 ] :,if last_time_replaced [ 0 ] :,0.75,100.00000000000004,1.0
"def testReadChunk10(self):<tab># ""Test BZ2File.read() in chunks of 10 bytes""<tab>self.createTempFile()<tab>with BZ2File(self.filename) as bz2f:<tab><tab>text = """"<tab><tab>while 1:<tab><tab><tab>str = bz2f.read(10)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>text += str<tab><tab>self.assertEqual(text, self.TEXT)",1,if not str :,if not str :,0.75,100.00000000000004,1.0
"def generate_sv_faces(dcel_mesh, point_index, only_select=False, del_flag=None):<tab># This part of function creates faces in SV format<tab># It ignores  boundless super face<tab>sv_faces = []<tab>for i, face in enumerate(dcel_mesh.faces):<tab><tab>if face.inners and face.outer:<tab><tab><tab>""Face ({}) has inner components! Sverchok cant show polygons with holes."".format(<tab><tab><tab><tab>i<tab><tab><tab>)<tab><tab>if not face.outer or del_flag in face.flags:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges])<tab>return sv_faces",0,if only_select and not face . select :,if only_select and del_flag in face . flags :,0.2104868942093372,34.38931217657843,0.5
"def __check_dict_contains(dct, dict_name, keys, comment="""", result=True):<tab>for key in keys:<tab><tab><IF-STMT><tab><tab><tab>result = False<tab><tab><tab>comment = __append_comment(<tab><tab><tab><tab>""Missing {0} in {1}"".format(key, dict_name), comment<tab><tab><tab>)<tab>return result, comment",0,if key not in six . iterkeys ( dct ) :,if key not in dct :,0.24046226580314328,24.439253249722206,0.6
"def _dump_arg_defaults(kwargs):<tab>""""""Inject default arguments for dump functions.""""""<tab>if current_app:<tab><tab>kwargs.setdefault(""cls"", current_app.json_encoder)<tab><tab><IF-STMT><tab><tab><tab>kwargs.setdefault(""ensure_ascii"", False)<tab><tab>kwargs.setdefault(""sort_keys"", current_app.config[""JSON_SORT_KEYS""])<tab>else:<tab><tab>kwargs.setdefault(""sort_keys"", True)<tab><tab>kwargs.setdefault(""cls"", JSONEncoder)",0,"if not current_app . config [ ""JSON_AS_ASCII"" ] :","if current_app . config [ ""JSON_AS_ASCII"" ] :",0.38125480330051975,88.84420215438179,0.4807692307692308
"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab>if value != 1:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",0,elif len ( value ) != 0 :,"if self . _set_attr ( key , value ) :",0.030732635569131354,7.347053125977879,0.125
"def parse_win_proxy(val):<tab>proxies = []<tab>for p in val.split("";""):<tab><tab><IF-STMT><tab><tab><tab>tab = p.split(""="", 1)<tab><tab><tab>if tab[0] == ""socks"":<tab><tab><tab><tab>tab[0] = ""SOCKS4""<tab><tab><tab>proxies.append(<tab><tab><tab><tab>(tab[0].upper(), tab[1], None, None)<tab><tab><tab>)  # type, addr:port, username, password<tab><tab>else:<tab><tab><tab>proxies.append((""HTTP"", p, None, None))<tab>return proxies",1,"if ""="" in p :","if ""="" in p :",0.75,100.00000000000004,1.0
"def predict(collect_dir, keys):<tab>run_all = len(keys) == 0<tab>validate_keys(keys)<tab>for exp_cfg in cfg:<tab><tab><IF-STMT><tab><tab><tab>key = exp_cfg[""key""]<tab><tab><tab>_predict(key, exp_cfg[""sample_img""], collect_dir)",0,"if run_all or exp_cfg [ ""key"" ] in keys :","if run_all and exp_cfg [ ""key"" ] in keys :",0.6049399806880458,81.53551038173119,0.6666666666666666
"def convert_port_bindings(port_bindings):<tab>result = {}<tab>for k, v in six.iteritems(port_bindings):<tab><tab>key = str(k)<tab><tab><IF-STMT><tab><tab><tab>key += ""/tcp""<tab><tab>if isinstance(v, list):<tab><tab><tab>result[key] = [_convert_port_binding(binding) for binding in v]<tab><tab>else:<tab><tab><tab>result[key] = [_convert_port_binding(v)]<tab>return result",0,"if ""/"" not in key :","if key . startswith ( ""tcp"" ) :",0.023749771747382555,6.27465531099474,0.3148148148148148
"def assert_conll_writer_output(<tab>dataset: InternalBioNerDataset,<tab>expected_output: List[str],<tab>sentence_splitter: SentenceSplitter = None,):<tab>outfile_path = tempfile.mkstemp()[1]<tab>try:<tab><tab>sentence_splitter = (<tab><tab><tab>sentence_splitter<tab><tab><tab><IF-STMT><tab><tab><tab>else NoSentenceSplitter(tokenizer=SpaceTokenizer())<tab><tab>)<tab><tab>writer = CoNLLWriter(sentence_splitter=sentence_splitter)<tab><tab>writer.write_to_conll(dataset, Path(outfile_path))<tab><tab>contents = [l.strip() for l in open(outfile_path).readlines() if l.strip()]<tab>finally:<tab><tab>os.remove(outfile_path)<tab>assert contents == expected_output",1,if sentence_splitter,if sentence_splitter,0.408113883008419,1e-10,1.0
"def post(self, request, *args, **kwargs):<tab>self.comment_obj = get_object_or_404(Comment, id=request.POST.get(""commentid""))<tab>if request.user == self.comment_obj.commented_by:<tab><tab>form = LeadCommentForm(request.POST, instance=self.comment_obj)<tab><tab><IF-STMT><tab><tab><tab>return self.form_valid(form)<tab><tab>return self.form_invalid(form)<tab>data = {""error"": ""You don't have permission to edit this comment.""}<tab>return JsonResponse(data)",1,if form . is_valid ( ) :,if form . is_valid ( ) :,0.75,100.00000000000004,1.0
"def trivia_list(self, ctx: commands.Context):<tab>""""""List available trivia categories.""""""<tab>lists = set(p.stem for p in self._all_lists())<tab>if await ctx.embed_requested():<tab><tab>await ctx.send(<tab><tab><tab>embed=discord.Embed(<tab><tab><tab><tab>title=_(""Available trivia lists""),<tab><tab><tab><tab>colour=await ctx.embed_colour(),<tab><tab><tab><tab>description="", "".join(sorted(lists)),<tab><tab><tab>)<tab><tab>)<tab>else:<tab><tab>msg = box(bold(_(""Available trivia lists"")) + ""\n\n"" + "", "".join(sorted(lists)))<tab><tab><IF-STMT><tab><tab><tab>await ctx.author.send(msg)<tab><tab>else:<tab><tab><tab>await ctx.send(msg)",0,if len ( msg ) > 1000 :,if ctx . author :,0.01858685153282265,6.9717291216921975,0.2698412698412698
"def validate(self):<tab>result = validators.SUCCESS<tab>msgs = []<tab>for validator in self._validators:<tab><tab>res, err = validator.validate()<tab><tab>if res == validators.ERROR:<tab><tab><tab>result = res<tab><tab>elif res == validators.WARNING and result != validators.ERROR:<tab><tab><tab>result = res<tab><tab><IF-STMT><tab><tab><tab>msgs.append(err)<tab>return result, ""\n"".join(msgs)",0,if len ( err ) > 0 :,elif err :,0.013842083334859196,1e-10,0.13333333333333333
"def get_code(self, fullname=None):<tab>fullname = self._fix_name(fullname)<tab>if self.code is None:<tab><tab>mod_type = self.etc[2]<tab><tab>if mod_type == imp.PY_SOURCE:<tab><tab><tab>source = self.get_source(fullname)<tab><tab><tab>self.code = compile(source, self.filename, ""exec"")<tab><tab><IF-STMT><tab><tab><tab>self._reopen()<tab><tab><tab>try:<tab><tab><tab><tab>self.code = read_code(self.file)<tab><tab><tab>finally:<tab><tab><tab><tab>self.file.close()<tab><tab>elif mod_type == imp.PKG_DIRECTORY:<tab><tab><tab>self.code = self._get_delegate().get_code()<tab>return self.code",0,elif mod_type == imp . PY_COMPILED :,elif mod_type == imp . PKG_DIRECTORY :,0.5717294420803809,64.84115071397645,1.0
"def flush_file(self, key, f):<tab>f.flush()<tab>if self.compress:<tab><tab>f.compress = zlib.compressobj(<tab><tab><tab>9, zlib.DEFLATED, -zlib.MAX_WBITS, zlib.DEF_MEM_LEVEL, 0<tab><tab>)<tab>if len(self.files) > self.MAX_OPEN_FILES:<tab><tab>if self.compress:<tab><tab><tab>open_files = sum(1 for f in self.files.values() if f.fileobj is not None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.fileobj.close()<tab><tab><tab><tab>f.fileobj = None<tab><tab>else:<tab><tab><tab>f.close()<tab><tab><tab>self.files.pop(key)",0,if open_files > self . MAX_OPEN_FILES :,if open_files > 0 :,0.09453229110448028,27.30664777474173,0.5
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.add_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def init_author_file(self):<tab>self.author_map = {}<tab>if self.ui.config(""git"", ""authors""):<tab><tab>f = open(self.repo.wjoin(self.ui.config(""git"", ""authors"")))<tab><tab>try:<tab><tab><tab>for line in f:<tab><tab><tab><tab>line = line.strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>from_, to = RE_AUTHOR_FILE.split(line, 2)<tab><tab><tab><tab>self.author_map[from_] = to<tab><tab>finally:<tab><tab><tab>f.close()",1,"if not line or line . startswith ( ""#"" ) :","if not line or line . startswith ( ""#"" ) :",1.0,100.00000000000004,1.0
"def decode_imsi(self, imsi):<tab>new_imsi = """"<tab>for a in imsi:<tab><tab>c = hex(a)<tab><tab><IF-STMT><tab><tab><tab>new_imsi += str(c[3]) + str(c[2])<tab><tab>else:<tab><tab><tab>new_imsi += str(c[2]) + ""0""<tab>mcc = new_imsi[1:4]<tab>mnc = new_imsi[4:6]<tab>return new_imsi, mcc, mnc",1,if len ( c ) == 4 :,if len ( c ) == 4 :,0.75,100.00000000000004,1.0
"def _get_infoset(self, prefname):<tab>""""""Return methods with the name starting with prefname.""""""<tab>infoset = []<tab>excludes = (""%sinfoset"" % prefname,)<tab>preflen = len(prefname)<tab>for name in dir(self.__class__):<tab><tab>if name.startswith(prefname) and name not in excludes:<tab><tab><tab>member = getattr(self.__class__, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>infoset.append(name[preflen:].replace(""_"", "" ""))<tab>return infoset",0,"if isinstance ( member , MethodType ) :",if member . __name__ == prefname :,0.019627455172827622,4.456882760699063,0.3148148148148148
"def skip_to_close_match(self):<tab>nestedCount = 1<tab>while 1:<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab>ttype = tok[""style""]<tab><tab>if ttype == SCE_PL_UNUSED:<tab><tab><tab>return<tab><tab>elif self.classifier.is_index_op(tok):<tab><tab><tab>tval = tok[""text""]<tab><tab><tab>if self.opHash.has_key(tval):<tab><tab><tab><tab>if self.opHash[tval][1] == 1:<tab><tab><tab><tab><tab>nestedCount += 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>nestedCount -= 1<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break",0,if nestedCount <= 0 :,if nestedCount == 0 :,0.33141502097923065,37.99178428257963,1.0
"def findMarkForUnitTestNodes(self):<tab>""""""return the position of *all* non-ignored @mark-for-unit-test nodes.""""""<tab>c = self.c<tab>p, result, seen = c.rootPosition(), [], []<tab>while p:<tab><tab><IF-STMT><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab>else:<tab><tab><tab>seen.append(p.v)<tab><tab><tab>if g.match_word(p.h, 0, ""@ignore""):<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab>elif p.h.startswith(""@mark-for-unit-tests""):<tab><tab><tab><tab>result.append(p.copy())<tab><tab><tab><tab>p.moveToNodeAfterTree()<tab><tab><tab>else:<tab><tab><tab><tab>p.moveToThreadNext()<tab>return result",1,if p . v in seen :,if p . v in seen :,0.75,100.00000000000004,1.0
"def assert_parts_cleaned(self, earlier_parts, current_parts, expected_parts, hint):<tab>cleaned_parts = []<tab>for earlier in earlier_parts:<tab><tab>earlier_part = earlier[""part""]<tab><tab>earlier_step = earlier[""step""]<tab><tab>found = False<tab><tab>for current in current_parts:<tab><tab><tab>if earlier_part == current[""part""] and earlier_step == current[""step""]:<tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>cleaned_parts.append(dict(part=earlier_part, step=earlier_step))<tab>self.assertThat(cleaned_parts, HasLength(len(expected_parts)), hint)<tab>for expected in expected_parts:<tab><tab>self.assertThat(cleaned_parts, Contains(expected), hint)",0,if not found :,if found :,0.09648852821835877,1e-10,0.41666666666666663
"def unmark_first_parents(event=None):<tab>""""""Mark the node and all its parents.""""""<tab>c = event.get(""c"")<tab>if not c:<tab><tab>return<tab>changed = []<tab>for parent in c.p.self_and_parents():<tab><tab><IF-STMT><tab><tab><tab>parent.v.clearMarked()<tab><tab><tab>parent.setAllAncestorAtFileNodesDirty()<tab><tab><tab>changed.append(parent.copy())<tab>if changed:<tab><tab># g.es(""unmarked: "" + ', '.join([z.h for z in changed]))<tab><tab>c.setChanged()<tab><tab>c.redraw()<tab>return changed",0,if parent . isMarked ( ) :,if parent . v . isDirty ( ) :,0.182154481859014,29.84745896009822,0.48484848484848486
"def stop(self):<tab>self._log(""Monitor stop"")<tab>self._stop_requested = True<tab>try:<tab><tab><IF-STMT><tab><tab><tab>fd = os.open(self.fifo_path, os.O_WRONLY)<tab><tab><tab>os.write(fd, b""X"")<tab><tab><tab>os.close(fd)<tab>except Exception as e:<tab><tab>self._log(""err while closing: {0}"".format(str(e)))<tab>if self._thread:<tab><tab>self._thread.join()<tab><tab>self._thread = None",0,if os . path . exists ( self . fifo_path ) :,if self . fifo_path :,0.04443841236021975,24.601580968354618,0.30392156862745096
"def DeleteEmptyCols(self):<tab>cols2delete = []<tab>for c in range(0, self.GetCols()):<tab><tab>f = True<tab><tab>for r in range(0, self.GetRows()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f = False<tab><tab>if f:<tab><tab><tab>cols2delete.append(c)<tab>for i in range(0, len(cols2delete)):<tab><tab>self.ShiftColsLeft(cols2delete[i] + 1)<tab><tab>cols2delete = [x - 1 for x in cols2delete]",0,"if self . FindItemAtPosition ( ( r , c ) ) is not None :",if self . GetCols ( r ) [ 0 ] == c :,0.047437956292768146,13.919157443507983,0.3522727272727273
"def _load_objects(self, obj_id_zset, limit, chunk_size=1000):<tab>ct = i = 0<tab>while True:<tab><tab>id_chunk = obj_id_zset[i : i + chunk_size]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>i += chunk_size<tab><tab>for raw_data in self._data[id_chunk]:<tab><tab><tab>if not raw_data:<tab><tab><tab><tab>continue<tab><tab><tab>if self._use_json:<tab><tab><tab><tab>yield json.loads(decode(raw_data))<tab><tab><tab>else:<tab><tab><tab><tab>yield raw_data<tab><tab><tab>ct += 1<tab><tab><tab>if limit and ct == limit:<tab><tab><tab><tab>return",0,if not id_chunk :,if id_chunk == 0 :,0.045150550804307965,23.356898886410015,0.5
"def _convert_example(example, use_bfloat16):<tab>""""""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16.""""""<tab>for key in list(example.keys()):<tab><tab>val = example[key]<tab><tab>if tf.keras.backend.is_sparse(val):<tab><tab><tab>val = tf.sparse.to_dense(val)<tab><tab><IF-STMT><tab><tab><tab>val = tf.cast(val, tf.int32)<tab><tab>if use_bfloat16 and val.dtype == tf.float32:<tab><tab><tab>val = tf.cast(val, tf.bfloat16)<tab><tab>example[key] = val",0,if val . dtype == tf . int64 :,if use_bfloat16 and val . dtype == tf . int64 :,0.584517616824489,61.153805769010226,0.27272727272727276
"def print_callees(self, *amount):<tab>width, list = self.get_print_list(amount)<tab>if list:<tab><tab>self.calc_callees()<tab><tab>self.print_call_heading(width, ""called..."")<tab><tab>for func in list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.print_call_line(width, func, self.all_callees[func])<tab><tab><tab>else:<tab><tab><tab><tab>self.print_call_line(width, func, {})<tab><tab>print >>self.stream<tab><tab>print >>self.stream<tab>return self",1,if func in self . all_callees :,if func in self . all_callees :,0.75,100.00000000000004,1.0
"def on_task_input(self, task, config):<tab>if config is False:<tab><tab>return<tab>for entry in task.entries:<tab><tab><IF-STMT><tab><tab><tab>log_once(<tab><tab><tab><tab>""Corrected `%s` url (replaced &amp; with &)"" % entry[""title""],<tab><tab><tab><tab>logger=log,<tab><tab><tab>)<tab><tab><tab>entry[""url""] = entry[""url""].replace(""&amp;"", ""&"")",0,"if ""&amp;"" in entry [ ""url"" ] :","if ""url"" in entry :",0.038928836358151336,22.117541221307572,1.0
"def function(self, inputs, outputs, ignore_empty=False):<tab>f = function(inputs, outputs, mode=self.mode)<tab>if self.mode is not None or theano.config.mode != ""FAST_COMPILE"":<tab><tab>topo = f.maker.fgraph.toposort()<tab><tab>topo_ = [node for node in topo if not isinstance(node.op, self.ignore_topo)]<tab><tab>if ignore_empty:<tab><tab><tab>assert len(topo_) <= 1, topo_<tab><tab>else:<tab><tab><tab>assert len(topo_) == 1, topo_<tab><tab><IF-STMT><tab><tab><tab>assert type(topo_[0].op) is self.op<tab>return f",0,if len ( topo_ ) > 0 :,if len ( topo_ ) == 1 :,0.5241515189640744,53.7284965911771,0.6
"def _get_env_command(self) -> Sequence[str]:<tab>""""""Get command sequence for `env` with configured flags.""""""<tab>env_list = [""env""]<tab># Pass through configurable environment variables.<tab>for key in [""http_proxy"", ""https_proxy""]:<tab><tab>value = self.build_provider_flags.get(key)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Ensure item is treated as string and append it.<tab><tab>value = str(value)<tab><tab>env_list.append(f""{key}={value}"")<tab>return env_list",0,if not value :,if value is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def _compare_single_run(self, compares_done):<tab>try:<tab><tab>compare_id, redo = self.in_queue.get(<tab><tab><tab>timeout=float(self.config[""ExpertSettings""][""block_delay""])<tab><tab>)<tab>except Empty:<tab><tab>pass<tab>else:<tab><tab>if self._decide_whether_to_process(compare_id, redo, compares_done):<tab><tab><tab>if redo:<tab><tab><tab><tab>self.db_interface.delete_old_compare_result(compare_id)<tab><tab><tab>compares_done.add(compare_id)<tab><tab><tab>self._process_compare(compare_id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.callback()",1,if self . callback :,if self . callback :,0.75,100.00000000000004,1.0
"def clean(self):<tab># TODO: check for clashes if the random code is already taken<tab>if not self.code:<tab><tab>self.code = u""static-%s"" % uuid.uuid4()<tab>if not self.site:<tab><tab>placeholders = StaticPlaceholder.objects.filter(<tab><tab><tab>code=self.code, site__isnull=True<tab><tab>)<tab><tab>if self.pk:<tab><tab><tab>placeholders = placeholders.exclude(pk=self.pk)<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""A static placeholder with the same site and code already exists"")<tab><tab><tab>)",0,if placeholders . exists ( ) :,if not placeholders . exists ( ) :,0.3870007991100655,70.71067811865478,0.37777777777777777
"def load_parser(self):<tab>result = OrderedDict()<tab>for name, flags in self.filenames:<tab><tab>filename = self.get_filename(name)<tab><tab>for match in sorted(glob(filename), key=self.file_key):<tab><tab><tab># Needed to allow overlapping globs, more specific first<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>result[match] = TextParser(match, os.path.relpath(match, self.base), flags)<tab>return result",0,if match in result :,if match in self . file_key :,0.2422606578313526,19.070828081828378,0.6666666666666666
"def __init__(self, selectable, name=None):<tab>baseselectable = selectable<tab>while isinstance(baseselectable, Alias):<tab><tab>baseselectable = baseselectable.element<tab>self.original = baseselectable<tab>self.supports_execution = baseselectable.supports_execution<tab>if self.supports_execution:<tab><tab>self._execution_options = baseselectable._execution_options<tab>self.element = selectable<tab>if name is None:<tab><tab><IF-STMT><tab><tab><tab>name = getattr(self.original, ""name"", None)<tab><tab>name = _anonymous_label(""%%(%d %s)s"" % (id(self), name or ""anon""))<tab>self.name = name",0,if self . original . named_with_column :,"if hasattr ( self . original , ""name"" ) :",0.07771230212249913,14.323145079400492,0.38461538461538464
"def load_tour(self, tour_id):<tab>for tour_dir in self.tour_directories:<tab><tab>tour_path = os.path.join(tour_dir, tour_id + "".yaml"")<tab><tab>if not os.path.exists(tour_path):<tab><tab><tab>tour_path = os.path.join(tour_dir, tour_id + "".yml"")<tab><tab><IF-STMT><tab><tab><tab>return self._load_tour_from_path(tour_path)",1,if os . path . exists ( tour_path ) :,if os . path . exists ( tour_path ) :,0.75,100.00000000000004,1.0
"def _get_md_bg_color_down(self):<tab>t = self.theme_cls<tab>c = self.md_bg_color  # Default to no change on touch<tab># Material design specifies using darker hue when on Dark theme<tab>if t.theme_style == ""Dark"":<tab><tab><IF-STMT><tab><tab><tab>c = t.primary_dark<tab><tab>elif self.md_bg_color == t.accent_color:<tab><tab><tab>c = t.accent_dark<tab>return c",1,if self . md_bg_color == t . primary_color :,if self . md_bg_color == t . primary_color :,0.75,100.00000000000004,1.0
"def get_data(self, state=None, request=None):<tab>if self.load_in_memory:<tab><tab>data, shapes = self._in_memory_get_data(state, request)<tab>else:<tab><tab>data, shapes = self._out_of_memory_get_data(state, request)<tab>for i in range(len(data)):<tab><tab>if shapes[i] is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[i] = data[i].reshape(shapes[i])<tab><tab><tab>else:<tab><tab><tab><tab>for j in range(len(data[i])):<tab><tab><tab><tab><tab>data[i][j] = data[i][j].reshape(shapes[i][j])<tab>return tuple(data)",0,"if isinstance ( request , numbers . Integral ) :","if isinstance ( data [ i ] , np . ndarray ) :",0.11305905180060923,15.727800941615351,0.29333333333333333
"def onClicked(event):<tab>if not self.path:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(mh.getPath(""render""))<tab><tab>self.path = mh.getPath(""render"")<tab>filename, ftype = mh.getSaveFileName(<tab><tab>os.path.splitext(self.path)[0],<tab><tab>""PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*)"",<tab>)<tab>if filename:<tab><tab>if ""Thumbnail"" in ftype:<tab><tab><tab>self.image.save(filename, iformat=""PNG"")<tab><tab>else:<tab><tab><tab>self.image.save(filename)<tab><tab>self.path = os.path.dirname(filename)",1,"if not os . path . exists ( mh . getPath ( ""render"" ) ) :","if not os . path . exists ( mh . getPath ( ""render"" ) ) :",0.75,100.00000000000004,1.0
"def _build_dom(cls, content, mode):<tab>assert mode in (""html"", ""xml"")<tab>if mode == ""html"":<tab><tab><IF-STMT><tab><tab><tab>THREAD_STORAGE.html_parser = HTMLParser()<tab><tab>dom = defusedxml.lxml.parse(<tab><tab><tab>StringIO(content), parser=THREAD_STORAGE.html_parser<tab><tab>)<tab><tab>return dom.getroot()<tab>else:<tab><tab>if not hasattr(THREAD_STORAGE, ""xml_parser""):<tab><tab><tab>THREAD_STORAGE.xml_parser = XMLParser()<tab><tab>dom = defusedxml.lxml.parse(BytesIO(content), parser=THREAD_STORAGE.xml_parser)<tab><tab>return dom.getroot()",0,"if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :","if not hasattr (THREAD_STORAGE , ""html_parser"" ) :",0.4705270195121086,100.00000000000004,1.0
"def convert_path(ctx, tpath):<tab>for points, code in tpath.iter_segments():<tab><tab><IF-STMT><tab><tab><tab>ctx.move_to(*points)<tab><tab>elif code == Path.LINETO:<tab><tab><tab>ctx.line_to(*points)<tab><tab>elif code == Path.CURVE3:<tab><tab><tab>ctx.curve_to(<tab><tab><tab><tab>points[0], points[1], points[0], points[1], points[2], points[3]<tab><tab><tab>)<tab><tab>elif code == Path.CURVE4:<tab><tab><tab>ctx.curve_to(*points)<tab><tab>elif code == Path.CLOSEPOLY:<tab><tab><tab>ctx.close_path()",1,if code == Path . MOVETO :,if code == Path . MOVETO :,0.75,100.00000000000004,1.0
"def _targets(self, sigmaparser):<tab># build list of matching target mappings<tab>targets = set()<tab>for condfield in self.conditions:<tab><tab>if condfield in sigmaparser.values:<tab><tab><tab>rulefieldvalues = sigmaparser.values[condfield]<tab><tab><tab>for condvalue in self.conditions[condfield]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>targets.update(self.conditions[condfield][condvalue])<tab>return targets",1,if condvalue in rulefieldvalues :,if condvalue in rulefieldvalues :,0.75,100.00000000000004,1.0
"def create_image_upload():<tab>if request.method == ""POST"":<tab><tab>image = request.form[""image""]<tab><tab><IF-STMT><tab><tab><tab>image_file = uploaded_file(file_content=image)<tab><tab><tab>image_url = upload_local(<tab><tab><tab><tab>image_file, UPLOAD_PATHS[""temp""][""image""].format(uuid=uuid4())<tab><tab><tab>)<tab><tab><tab>return jsonify({""status"": ""ok"", ""image_url"": image_url})<tab><tab>else:<tab><tab><tab>return jsonify({""status"": ""no_image""})",1,if image :,if image :,0.5311706625951745,1e-10,1.0
"def lookup_actions(self, resp):<tab>actions = {}<tab>for action, conditions in self.actions.items():<tab><tab>for condition, opts in conditions:<tab><tab><tab>for key, val in condition:<tab><tab><tab><tab>if key[-1] == ""!"":<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if not resp.match(key, val):<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>actions[action] = opts<tab>return actions",0,"if resp . match ( key [ : - 1 ] , val ) :",if val is None :,0.0074589697276959644,1.9026155630072006,0.2111111111111111
"def accept_quality(accept, default=1):<tab>""""""Separates out the quality score from the accepted content_type""""""<tab>quality = default<tab>if accept and "";"" in accept:<tab><tab>accept, rest = accept.split("";"", 1)<tab><tab>accept_quality = RE_ACCEPT_QUALITY.search(rest)<tab><tab><IF-STMT><tab><tab><tab>quality = float(accept_quality.groupdict().get(""quality"", quality).strip())<tab>return (quality, accept.strip())",1,if accept_quality :,if accept_quality :,0.5311706625951745,1e-10,1.0
"def save(self, session=None, to=None, pickler=None):<tab>if to and pickler:<tab><tab>self._save_to = (pickler, to)<tab>if self._save_to and len(self) > 0:<tab><tab>with self._lock:<tab><tab><tab>pickler, fn = self._save_to<tab><tab><tab><IF-STMT><tab><tab><tab><tab>session.ui.mark(_(""Saving %s state to %s"") % (self, fn))<tab><tab><tab>pickler(self, fn)",0,if session :,if pickler :,0.3197504490129165,1e-10,0.5
"def get_safe_settings():<tab>""Returns a dictionary of the settings module, with sensitive settings blurred out.""<tab>settings_dict = {}<tab>for k in dir(settings):<tab><tab>if k.isupper():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>settings_dict[k] = ""********************""<tab><tab><tab>else:<tab><tab><tab><tab>settings_dict[k] = getattr(settings, k)<tab>return settings_dict",0,if HIDDEN_SETTINGS . search ( k ) :,"if k . startswith ( ""********************"" ) :",0.03916858170756418,3.3868193354396166,0.4
def _init_table_h():<tab>_table_h = []<tab>for i in range(256):<tab><tab>part_l = i<tab><tab>part_h = 0<tab><tab>for j in range(8):<tab><tab><tab>rflag = part_l & 1<tab><tab><tab>part_l >>= 1<tab><tab><tab>if part_h & 1:<tab><tab><tab><tab>part_l |= 1 << 31<tab><tab><tab>part_h >>= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>part_h ^= 0xD8000000<tab><tab>_table_h.append(part_h)<tab>return _table_h,1,if rflag :,if rflag :,0.5311706625951745,1e-10,1.0
"def dns_query(server, timeout, protocol, qname, qtype, qclass):<tab>request = dns.message.make_query(qname, qtype, qclass)<tab>if protocol == ""tcp"":<tab><tab>response = dns.query.tcp(<tab><tab><tab>request, server, timeout=timeout, one_rr_per_rrset=True<tab><tab>)<tab>else:<tab><tab>response = dns.query.udp(<tab><tab><tab>request, server, timeout=timeout, one_rr_per_rrset=True<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>response = dns.query.tcp(<tab><tab><tab><tab>request, server, timeout=timeout, one_rr_per_rrset=True<tab><tab><tab>)<tab>return response",0,if response . flags & dns . flags . TC :,"elif protocol == ""tcp"" :",0.13340665779446886,3.7954847898457067,0.08928571428571429
"def sum_and_divide(self, losses):<tab>if self.total_divisor != 0:<tab><tab>output = torch.sum(losses) / self.total_divisor<tab><tab><IF-STMT><tab><tab><tab># remove from autograd graph if necessary<tab><tab><tab>self.total_divisor = self.total_divisor.item()<tab><tab>return output<tab>return torch.sum(losses * 0)",0,if torch . is_tensor ( self . total_divisor ) :,if self . use_autograd :,0.026933810325055336,6.075831217041839,0.48333333333333334
"def __iter__(self):<tab>for chunk in self.source:<tab><tab>if chunk is not None:<tab><tab><tab>self.wait_counter = 0<tab><tab><tab>yield chunk<tab><tab><IF-STMT><tab><tab><tab>self.wait_counter += 1<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Data poller has been receiving no data for {} seconds.\n""<tab><tab><tab><tab>""Closing data poller"".format(self.wait_cntr_max * self.poll_period)<tab><tab><tab>)<tab><tab><tab>break<tab><tab>time.sleep(self.poll_period)",1,elif self . wait_counter < self . wait_cntr_max :,elif self . wait_counter < self . wait_cntr_max :,1.0,100.00000000000004,1.0
"def test_find_directive_from_block(self):<tab>blocks = self.config.parser_root.find_blocks(""virtualhost"")<tab>found = False<tab>for vh in blocks:<tab><tab><IF-STMT><tab><tab><tab>servername = vh.find_directives(""servername"")<tab><tab><tab>self.assertEqual(servername[0].parameters[0], ""certbot.demo"")<tab><tab><tab>found = True<tab>self.assertTrue(found)",0,"if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :","if vh . name == ""servername"" :",0.1092881434554564,10.194207971045941,0.4871794871794872
"def assign_products(request, discount_id):<tab>""""""Assign products to given property group with given property_group_id.""""""<tab>discount = lfs_get_object_or_404(Discount, pk=discount_id)<tab>for temp_id in request.POST.keys():<tab><tab><IF-STMT><tab><tab><tab>temp_id = temp_id.split(""-"")[1]<tab><tab><tab>product = Product.objects.get(pk=temp_id)<tab><tab><tab>discount.products.add(product)<tab>html = [[""#products-inline"", products_inline(request, discount_id, as_string=True)]]<tab>result = json.dumps(<tab><tab>{""html"": html, ""message"": _(u""Products have been assigned."")}, cls=LazyEncoder<tab>)<tab>return HttpResponse(result, content_type=""application/json"")",0,"if temp_id . startswith ( ""product"" ) :","if ""-"" in temp_id :",0.019907917998500824,15.716803955215932,0.5
"def ChangeStyle(self, combos):<tab>style = 0<tab>for combo in combos:<tab><tab>if combo.GetValue() == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>style = style | HTL.TR_VIRTUAL<tab><tab><tab>else:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>style = style | eval(""wx."" + combo.GetLabel())<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>style = style | eval(""HTL."" + combo.GetLabel())<tab>if self.GetAGWWindowStyleFlag() != style:<tab><tab>self.SetAGWWindowStyleFlag(style)",1,"if combo . GetLabel ( ) == ""TR_VIRTUAL"" :","if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",0.75,100.00000000000004,1.0
"def _set_autocomplete(self, notebook):<tab>if notebook:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>notebook = NotebookInfo(notebook)<tab><tab><tab>obj, x = build_notebook(notebook)<tab><tab><tab>self.form.widgets[""namespace""].notebook = obj<tab><tab><tab>self.form.widgets[""page""].notebook = obj<tab><tab><tab>logger.debug(""Notebook for autocomplete: %s (%s)"", obj, notebook)<tab><tab>except:<tab><tab><tab>logger.exception(""Could not set notebook: %s"", notebook)<tab>else:<tab><tab>self.form.widgets[""namespace""].notebook = None<tab><tab>self.form.widgets[""page""].notebook = None<tab><tab>logger.debug(""Notebook for autocomplete unset"")",0,"if isinstance ( notebook , str ) :","if not isinstance ( notebook , str ) :",0.4050163994100806,75.06238537503395,0.3148148148148148
"def emitSubDomainData(self, subDomainData, event):<tab>self.emitRawRirData(subDomainData, event)<tab>for subDomainElem in subDomainData:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>subDomain = subDomainElem.get(""subdomain"", """").strip()<tab><tab>if subDomain:<tab><tab><tab>self.emitHostname(subDomain, event)",0,if self . checkForStop ( ) :,if subDomainElem is None :,0.02225082504991546,8.51528917838043,0.2653061224489796
"def get_all_subnets(self, subnet_ids=None, filters=None):<tab># Extract a list of all subnets<tab>matches = itertools.chain(*[x.values() for x in self.subnets.values()])<tab>if subnet_ids:<tab><tab>matches = [sn for sn in matches if sn.id in subnet_ids]<tab><tab><IF-STMT><tab><tab><tab>unknown_ids = set(subnet_ids) - set(matches)<tab><tab><tab>raise InvalidSubnetIdError(unknown_ids)<tab>if filters:<tab><tab>matches = generic_filter(filters, matches)<tab>return matches",1,if len ( subnet_ids ) > len ( matches ) :,if len ( subnet_ids ) > len ( matches ) :,1.0,100.00000000000004,1.0
"def _compat_map(self, avs):<tab>apps = {}<tab>for av in avs:<tab><tab>av.version = self<tab><tab>app_id = av.application<tab><tab><IF-STMT><tab><tab><tab>apps[amo.APP_IDS[app_id]] = av<tab>return apps",1,if app_id in amo . APP_IDS :,if app_id in amo . APP_IDS :,0.75,100.00000000000004,1.0
"def generator(self, data):<tab>if self._config.SILENT:<tab><tab>silent_vars = self._get_silent_vars()<tab>for task in data:<tab><tab>for var, val in task.environment_variables():<tab><tab><tab>if self._config.SILENT:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>int(task.UniqueProcessId),<tab><tab><tab><tab><tab>str(task.ImageFileName),<tab><tab><tab><tab><tab>Address(task.Peb.ProcessParameters.Environment),<tab><tab><tab><tab><tab>str(var),<tab><tab><tab><tab><tab>str(val),<tab><tab><tab><tab>],<tab><tab><tab>)",1,if var in silent_vars :,if var in silent_vars :,0.75,100.00000000000004,1.0
"def warn_if_repeatable_read(self):<tab>if ""mysql"" in self.current_engine().lower():<tab><tab>cursor = self.connection_for_read().cursor()<tab><tab>if cursor.execute(""SELECT @@tx_isolation""):<tab><tab><tab>isolation = cursor.fetchone()[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab>TxIsolationWarning(<tab><tab><tab><tab><tab><tab>""Polling results with transaction isolation level ""<tab><tab><tab><tab><tab><tab>""repeatable-read within the same transaction ""<tab><tab><tab><tab><tab><tab>""may give outdated results. Be sure to commit the ""<tab><tab><tab><tab><tab><tab>""transaction for each poll iteration.""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",0,"if isolation == ""REPEATABLE-READ"" :",if isolation != 0 :,0.06497877230811641,13.83254362586636,0.7
"def filter_by_level(record, level_per_module):<tab>name = record[""name""]<tab>level = 0<tab>if name in level_per_module:<tab><tab>level = level_per_module[name]<tab>elif name is not None:<tab><tab>lookup = """"<tab><tab><IF-STMT><tab><tab><tab>level = level_per_module[""""]<tab><tab>for n in name.split("".""):<tab><tab><tab>lookup += n<tab><tab><tab>if lookup in level_per_module:<tab><tab><tab><tab>level = level_per_module[lookup]<tab><tab><tab>lookup += "".""<tab>if level is False:<tab><tab>return False<tab>return record[""level""].no >= level",1,"if """" in level_per_module :","if """" in level_per_module :",0.75,100.00000000000004,1.0
"def _readStream(self, handle: str, path: str) -> None:<tab>eof = False<tab>file = Path(path)<tab>with file.open(""w"") as f:<tab><tab>while not eof:<tab><tab><tab>response = await self._client.send(""IO.read"", {""handle"": handle})<tab><tab><tab>eof = response.get(""eof"", False)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.write(response.get(""data"", """"))<tab>await self._client.send(""IO.close"", {""handle"": handle})",0,if path :,if not eof :,0.059856514947849826,1e-10,0.3333333333333333
"def sendall(self, data, flags=0):<tab>if self._sslobj:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""non-zero flags not allowed in calls to sendall() on %s""<tab><tab><tab><tab>% self.__class__<tab><tab><tab>)<tab><tab>amount = len(data)<tab><tab>count = 0<tab><tab>while count < amount:<tab><tab><tab>v = self.send(data[count:])<tab><tab><tab>count += v<tab><tab>return amount<tab>else:<tab><tab>return socket.sendall(self, data, flags)",1,if flags != 0 :,if flags != 0 :,0.75,100.00000000000004,1.0
"def run(self):<tab>utils.assert_main_thread()<tab># As a convenience, we'll set up the connection<tab># if there isn't one. So F5 (etc) can be hit<tab># to get started.<tab>if not channel:<tab><tab><IF-STMT><tab><tab><tab>SwiDebugStartChromeCommand.run(self)<tab><tab>else:<tab><tab><tab>self.window.run_command(""swi_debug_start"")<tab>elif paused:<tab><tab>logger.info(""Resuming..."")<tab><tab>channel.send(webkit.Debugger.resume())<tab>else:<tab><tab>logger.info(""Pausing..."")<tab><tab>channel.send(webkit.Debugger.setSkipAllPauses(False))<tab><tab>channel.send(webkit.Debugger.pause())",0,if not chrome_launched ( ) :,if is_swi_debug_start :,0.026485502076288185,1e-10,0.6296296296296297
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_presence_response().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def _replace_home(x):<tab>if xp.ON_WINDOWS:<tab><tab>home = (<tab><tab><tab>builtins.__xonsh__.env[""HOMEDRIVE""] + builtins.__xonsh__.env[""HOMEPATH""][0]<tab><tab>)<tab><tab>if x.startswith(home):<tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab><IF-STMT><tab><tab><tab>x = x.replace(os.sep, os.altsep)<tab><tab>return x<tab>else:<tab><tab>home = builtins.__xonsh__.env[""HOME""]<tab><tab>if x.startswith(home):<tab><tab><tab>x = x.replace(home, ""~"", 1)<tab><tab>return x",0,"if builtins . __xonsh__ . env . get ( ""FORCE_POSIX_PATHS"" ) :",elif x . startswith ( os . sep ) :,0.02202489620815485,3.1784032193777274,0.09333333333333334
"def semanticTags(self, semanticTags):<tab>if semanticTags is None:<tab><tab>self.__semanticTags = OrderedDict()<tab># check<tab>for key, value in list(semanticTags.items()):<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""At least one key is not a valid int position"")<tab><tab>if not isinstance(value, list):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab>)<tab><tab>for x in value:<tab><tab><tab>if not isinstance(x, str):<tab><tab><tab><tab>raise TypeError(<tab><tab><tab><tab><tab>""At least one value of the provided dict is not a list of string""<tab><tab><tab><tab>)<tab>self.__semanticTags = semanticTags",1,"if not isinstance ( key , int ) :","if not isinstance ( key , int ) :",0.75,100.00000000000004,1.0
"def _recv():<tab>try:<tab><tab>return sock.recv(bufsize)<tab>except SSLWantReadError:<tab><tab>pass<tab>except socket.error as exc:<tab><tab>error_code = extract_error_code(exc)<tab><tab>if error_code is None:<tab><tab><tab>raise<tab><tab><IF-STMT><tab><tab><tab>raise<tab>r, w, e = select.select((sock,), (), (), sock.gettimeout())<tab>if r:<tab><tab>return sock.recv(bufsize)",0,if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,if error_code != errno . EINTR :,0.23199644600800085,31.81579525928275,0.3557422969187675
"def _authenticate(self):<tab>oauth_token = self.options.get(""oauth_token"")<tab>if oauth_token and not self.api.oauth_token:<tab><tab>self.logger.info(""Attempting to authenticate using OAuth token"")<tab><tab>self.api.oauth_token = oauth_token<tab><tab>user = self.api.user(schema=_user_schema)<tab><tab><IF-STMT><tab><tab><tab>self.logger.info(""Successfully logged in as {0}"", user)<tab><tab>else:<tab><tab><tab>self.logger.error(<tab><tab><tab><tab>""Failed to authenticate, the access token "" ""is not valid""<tab><tab><tab>)<tab>else:<tab><tab>return JustinTVPluginBase._authenticate(self)",1,if user :,if user :,0.5311706625951745,1e-10,1.0
"def reverse(self, *args):<tab>assert self._path is not None, ""Cannot reverse url regex "" + self.regex.pattern<tab>assert len(args) == self._group_count, ""required number of arguments "" ""not found""<tab>if not len(args):<tab><tab>return self._path<tab>converted_args = []<tab>for a in args:<tab><tab><IF-STMT><tab><tab><tab>a = str(a)<tab><tab>converted_args.append(escape.url_escape(utf8(a), plus=False))<tab>return self._path % tuple(converted_args)",0,"if not isinstance ( a , ( unicode_type , bytes ) ) :","if not isinstance ( a , unicode ) :",0.2166383029994029,34.931613812566766,0.7142857142857143
"def determine_block_hints(self, text):<tab>hints = """"<tab>if text:<tab><tab><IF-STMT><tab><tab><tab>hints += str(self.best_indent)<tab><tab>if text[-1] not in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""-""<tab><tab>elif len(text) == 1 or text[-2] in ""\n\x85\u2028\u2029"":<tab><tab><tab>hints += ""+""<tab>return hints",0,"if text [ 0 ] in "" \n\x85\u2028\u2029"" :",if self . best_indent :,0.015736078468693036,1.8716386091619874,0.3055555555555556
"def find_package_modules(package, mask):<tab>import fnmatch<tab>if hasattr(package, ""__loader__"") and hasattr(package.__loader__, ""_files""):<tab><tab>path = package.__name__.replace(""."", os.path.sep)<tab><tab>mask = os.path.join(path, mask)<tab><tab>for fnm in package.__loader__._files.iterkeys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield os.path.splitext(fnm)[0].replace(os.path.sep, ""."")<tab>else:<tab><tab>path = package.__path__[0]<tab><tab>for fnm in os.listdir(path):<tab><tab><tab>if fnmatch.fnmatchcase(fnm, mask):<tab><tab><tab><tab>yield ""%s.%s"" % (package.__name__, os.path.splitext(fnm)[0])",0,"if fnmatch . fnmatchcase ( fnm , mask ) :","if fnmatch . fnmatch ( fnm , mask ) :",0.5803088707179008,65.80370064762461,0.7777777777777777
"def _condition(ct):<tab>for qobj in args:<tab><tab>if qobj.connector == ""AND"" and not qobj.negated:<tab><tab><tab># normal kwargs are an AND anyway, so just use those for now<tab><tab><tab>for child in qobj.children:<tab><tab><tab><tab>kwargs.update(dict([child]))<tab><tab>else:<tab><tab><tab>raise NotImplementedError(""Unsupported Q object"")<tab>for attr, val in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",0,"if getattr ( ct , attr ) != val :",if attr not in ct and val not in ct :,0.015448530895055629,5.604233375480572,0.14285714285714285
"def process(self, resources):<tab>session = local_session(self.manager.session_factory)<tab>client = session.client(""logs"")<tab>state = self.data.get(""state"", True)<tab>key = self.resolve_key(self.data.get(""kms-key""))<tab>for r in resources:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>client.associate_kms_key(logGroupName=r[""logGroupName""], kmsKeyId=key)<tab><tab><tab>else:<tab><tab><tab><tab>client.disassociate_kms_key(logGroupName=r[""logGroupName""])<tab><tab>except client.exceptions.ResourceNotFoundException:<tab><tab><tab>continue",0,if state :,"if state == ""associate"" :",0.09791453445388575,1e-10,1.0
"def get_xmm(env, ii):<tab>if is_gather(ii):<tab><tab><IF-STMT><tab><tab><tab>return gen_reg_simd_unified(env, ""xmm_evex"", True)<tab><tab>return gen_reg_simd_unified(env, ""xmm"", False)<tab>if ii.space == ""evex"":<tab><tab>return gen_reg(env, ""xmm_evex"")<tab>return gen_reg(env, ""xmm"")",1,"if ii . space == ""evex"" :","if ii . space == ""evex"" :",0.75,100.00000000000004,1.0
"def parent(self):<tab>""""""Return the parent device.""""""<tab>if self._has_parent is None:<tab><tab>_parent = self._ctx.backend.get_parent(self._ctx.dev)<tab><tab>self._has_parent = _parent is not None<tab><tab><IF-STMT><tab><tab><tab>self._parent = Device(_parent, self._ctx.backend)<tab><tab>else:<tab><tab><tab>self._parent = None<tab>return self._parent",0,if self . _has_parent :,if _parent is not None :,0.030286782520570012,13.540372457315735,0.27777777777777773
"def cascade(self, event=None):<tab>""""""Cascade all Leo windows.""""""<tab>x, y, delta = 50, 50, 50<tab>for frame in g.app.windowList:<tab><tab>w = frame and frame.top<tab><tab><IF-STMT><tab><tab><tab>r = w.geometry()  # a Qt.Rect<tab><tab><tab># 2011/10/26: Fix bug 823601: cascade-windows fails.<tab><tab><tab>w.setGeometry(QtCore.QRect(x, y, r.width(), r.height()))<tab><tab><tab># Compute the new offsets.<tab><tab><tab>x += 30<tab><tab><tab>y += 30<tab><tab><tab>if x > 200:<tab><tab><tab><tab>x = 10 + delta<tab><tab><tab><tab>y = 40 + delta<tab><tab><tab><tab>delta += 10",1,if w :,if w :,0.5311706625951745,1e-10,1.0
"def _GetGoodDispatchAndUserName(IDispatch, userName, clsctx):<tab># Get a dispatch object, and a 'user name' (ie, the name as<tab># displayed to the user in repr() etc.<tab>if userName is None:<tab><tab>if isinstance(IDispatch, str):<tab><tab><tab>userName = IDispatch<tab><tab><IF-STMT><tab><tab><tab># We always want the displayed name to be a real string<tab><tab><tab>userName = IDispatch.encode(""ascii"", ""replace"")<tab>elif type(userName) == unicode:<tab><tab># As above - always a string...<tab><tab>userName = userName.encode(""ascii"", ""replace"")<tab>else:<tab><tab>userName = str(userName)<tab>return (_GetGoodDispatch(IDispatch, clsctx), userName)",0,"elif isinstance ( IDispatch , unicode ) :",elif type ( IDispatch ) == unicode :,0.13865275878469727,12.549310621989482,0.6666666666666666
"def _infer_return_type(*args):<tab>""""""Look at the type of all args and divine their implied return type.""""""<tab>return_type = None<tab>for arg in args:<tab><tab>if arg is None:<tab><tab><tab>continue<tab><tab>if isinstance(arg, bytes):<tab><tab><tab>if return_type is str:<tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = bytes<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(""Can't mix bytes and non-bytes in "" ""path components."")<tab><tab><tab>return_type = str<tab>if return_type is None:<tab><tab>return str  # tempfile APIs return a str by default.<tab>return return_type",0,if return_type is bytes :,if return_type is str :,0.39477865547525276,64.34588841607616,0.6
"def test_ESPnetDataset_h5file_1(h5file_1):<tab>dataset = IterableESPnetDataset(<tab><tab>path_name_type_list=[(h5file_1, ""data4"", ""hdf5"")],<tab><tab>preprocess=preprocess,<tab>)<tab>for key, data in dataset:<tab><tab>if key == ""a"":<tab><tab><tab>assert data[""data4""].shape == (<tab><tab><tab><tab>100,<tab><tab><tab><tab>80,<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assert data[""data4""].shape == (<tab><tab><tab><tab>150,<tab><tab><tab><tab>80,<tab><tab><tab>)",0,"if key == ""b"" :","elif key == ""b"" :",0.31152264354151193,84.08964152537145,0.5
"def iter_fields(node, *, include_meta=True, exclude_unset=False):<tab>exclude_meta = not include_meta<tab>for field_name, field in node._fields.items():<tab><tab>if exclude_meta and field.meta:<tab><tab><tab>continue<tab><tab>field_val = getattr(node, field_name, _marker)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if exclude_unset:<tab><tab><tab>if callable(field.default):<tab><tab><tab><tab>default = field.default()<tab><tab><tab>else:<tab><tab><tab><tab>default = field.default<tab><tab><tab>if field_val == default:<tab><tab><tab><tab>continue<tab><tab>yield field_name, field_val",0,if field_val is _marker :,if field_val is None :,0.39477865547525276,55.780028607687655,0.7
"def then(self, matches, when_response, context):<tab>if is_iterable(when_response):<tab><tab>ret = []<tab><tab>when_response = list(when_response)<tab><tab>for match in when_response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.match_name:<tab><tab><tab><tab><tab>match.name = self.match_name<tab><tab><tab><tab>matches.append(match)<tab><tab><tab><tab>ret.append(match)<tab><tab>return ret<tab>if self.match_name:<tab><tab>when_response.name = self.match_name<tab>if when_response not in matches:<tab><tab>matches.append(when_response)<tab><tab>return when_response",0,if match not in matches :,if match . name == self . match_name :,0.040012802751399616,7.495553473355845,0.3611111111111111
"def _set_chat_ids(self, chat_id: SLT[int]) -> None:<tab>with self.__lock:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""Can't set {self.chat_id_name} in conjunction with (already set) ""<tab><tab><tab><tab>f""{self.username_name}s.""<tab><tab><tab>)<tab><tab>self._chat_ids = self._parse_chat_id(chat_id)",0,if chat_id and self . _usernames :,if self . _chat_ids :,0.12803489387928724,21.897593220582774,0.4722222222222222
"def discover(self, *objlist):<tab>ret = []<tab>for l in self.splitlines():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if l[0] == ""Filename"":<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>int(l[2])<tab><tab><tab>int(l[3])<tab><tab>except:<tab><tab><tab>continue<tab><tab>#<tab><tab>   ret.append(improve(l[0]))<tab><tab>ret.append(l[0])<tab>ret.sort()<tab>for item in objlist:<tab><tab>ret.append(item)<tab>return ret",0,if len ( l ) < 5 :,if len ( l ) < 3 :,0.605621305873661,70.71067811865478,0.6666666666666666
"def get_changed_module(self):<tab>source = self.resource.read()<tab>change_collector = codeanalyze.ChangeCollector(source)<tab>if self.replacement is not None:<tab><tab>change_collector.add_change(self.skip_start, self.skip_end, self.replacement)<tab>for occurrence in self.occurrence_finder.find_occurrences(self.resource):<tab><tab>start, end = occurrence.get_primary_range()<tab><tab><IF-STMT><tab><tab><tab>self.handle.occurred_inside_skip(change_collector, occurrence)<tab><tab>else:<tab><tab><tab>self.handle.occurred_outside_skip(change_collector, occurrence)<tab>result = change_collector.get_changed()<tab>if result is not None and result != source:<tab><tab>return result",0,if self . skip_start <= start < self . skip_end :,if start >= self . skip_start and end >= self . skip_end :,0.21609665747923623,46.661736281950525,0.3125
"def hpat_pandas_series_var_impl(<tab>self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None):<tab>if skipna is None:<tab><tab>skipna = True<tab>if skipna:<tab><tab>valuable_length = len(self._data) - numpy.sum(numpy.isnan(self._data))<tab><tab><IF-STMT><tab><tab><tab>return numpy.nan<tab><tab>return (<tab><tab><tab>numpy_like.nanvar(self._data) * valuable_length / (valuable_length - ddof)<tab><tab>)<tab>if len(self._data) <= ddof:<tab><tab>return numpy.nan<tab>return self._data.var() * len(self._data) / (len(self._data) - ddof)",1,if valuable_length <= ddof :,if valuable_length <= ddof :,0.75,100.00000000000004,1.0
"def to_dict(self, validate=True, ignore=(), context=None):<tab>context = context or {}<tab>condition = getattr(self, ""condition"", Undefined)<tab>copy = self  # don't copy unless we need to<tab>if condition is not Undefined:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif ""field"" in condition and ""type"" not in condition:<tab><tab><tab>kwds = parse_shorthand(condition[""field""], context.get(""data"", None))<tab><tab><tab>copy = self.copy(deep=[""condition""])<tab><tab><tab>copy.condition.update(kwds)<tab>return super(ValueChannelMixin, copy).to_dict(<tab><tab>validate=validate, ignore=ignore, context=context<tab>)",0,"if isinstance ( condition , core . SchemaBase ) :","if isinstance ( condition , basestring ) :",0.23202903606635522,46.307771619910305,0.5584415584415584
"def get_field_result(self, result, field_name):<tab>if isinstance(result.field, models.ImageField):<tab><tab><IF-STMT><tab><tab><tab>img = getattr(result.obj, field_name)<tab><tab><tab>result.text = mark_safe(<tab><tab><tab><tab>'<a href=""%s"" target=""_blank"" title=""%s"" data-gallery=""gallery""><img src=""%s"" class=""field_img""/></a>'<tab><tab><tab><tab>% (img.url, result.label, img.url)<tab><tab><tab>)<tab><tab><tab>self.include_image = True<tab>return result",0,if result . value :,if not self . include_image :,0.032294703547118726,7.267884212102741,0.3333333333333333
"def run(self):<tab>try:<tab><tab>while True:<tab><tab><tab>dp = self.queue_get_stoppable(self.inq)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab># cannot ignore None here. will lead to unsynced send/recv<tab><tab><tab>obj = self.func(dp)<tab><tab><tab>self.queue_put_stoppable(self.outq, obj)<tab>except Exception:<tab><tab>if self.stopped():<tab><tab><tab>pass  # skip duplicated error messages<tab><tab>else:<tab><tab><tab>raise<tab>finally:<tab><tab>self.stop()",0,if self . stopped ( ) :,if dp is None :,0.02225082504991546,8.51528917838043,0.2653061224489796
"def _evaluate_local_single(self, iterator):<tab>for batch in iterator:<tab><tab>in_arrays = convert._call_converter(self.converter, batch, self.device)<tab><tab>with function.no_backprop_mode():<tab><tab><tab>if isinstance(in_arrays, tuple):<tab><tab><tab><tab>results = self.calc_local(*in_arrays)<tab><tab><tab>elif isinstance(in_arrays, dict):<tab><tab><tab><tab>results = self.calc_local(**in_arrays)<tab><tab><tab>else:<tab><tab><tab><tab>results = self.calc_local(in_arrays)<tab><tab><IF-STMT><tab><tab><tab>self._progress_hook(batch)<tab><tab>yield results",0,if self . _progress_hook :,if self . progress_hook is not None :,0.19360647784576912,27.301208627090666,0.4444444444444444
"def merge(self, other):<tab>d = self._name2ft<tab>for name, (f, t) in other._name2ft.items():<tab><tab><IF-STMT><tab><tab><tab># Don't print here by default, since doing<tab><tab><tab>#<tab> so breaks some of the buildbots<tab><tab><tab># print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \<tab><tab><tab>#<tab>"" testers; summing outcomes.""<tab><tab><tab>f2, t2 = d[name]<tab><tab><tab>f = f + f2<tab><tab><tab>t = t + t2<tab><tab>d[name] = f, t",1,if name in d :,if name in d :,0.75,100.00000000000004,1.0
"def _addSettingsToPanels(self, category, left, right):<tab>count = len(profile.getSubCategoriesFor(category)) + len(<tab><tab>profile.getSettingsForCategory(category)<tab>)<tab>p = left<tab>n = 0<tab>for title in profile.getSubCategoriesFor(category):<tab><tab>n += 1 + len(profile.getSettingsForCategory(category, title))<tab><tab><IF-STMT><tab><tab><tab>p = right<tab><tab>configBase.TitleRow(p, _(title))<tab><tab>for s in profile.getSettingsForCategory(category, title):<tab><tab><tab>configBase.SettingRow(p, s.getName())",0,if n > count / 2 :,if n > count :,0.23093026462960747,47.39878501170795,0.7714285714285715
"def __init__(self, parent, dir, mask, with_dirs=True):<tab>filelist = []<tab>dirlist = [""..""]<tab>self.dir = dir<tab>self.file = """"<tab>mask = mask.upper()<tab>pattern = self.MakeRegex(mask)<tab>for i in os.listdir(dir):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = os.path.join(dir, i)<tab><tab>if os.path.isdir(path):<tab><tab><tab>dirlist.append(i)<tab><tab><tab>continue<tab><tab>path = path.upper()<tab><tab>value = i.upper()<tab><tab>if pattern.match(value) is not None:<tab><tab><tab>filelist.append(i)<tab>self.files = filelist<tab>if with_dirs:<tab><tab>self.dirs = dirlist",0,"if i == ""."" or i == "".."" :","if i == ""__init__.py"" :",0.06668418984860812,27.40623717328051,0.625
def check_network_private(test_network):<tab>test_net = ipaddress.IPNetwork(test_network)<tab>test_start = test_net.network<tab>test_end = test_net.broadcast<tab>for network in settings.vpn.safe_priv_subnets:<tab><tab>network = ipaddress.IPNetwork(network)<tab><tab>net_start = network.network<tab><tab>net_end = network.broadcast<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False,0,if test_start >= net_start and test_end <= net_end :,if net_start == test_start and net_end == test_end :,0.26971048821502464,27.21095546280697,1.0
"def _end_description(self):<tab>if self._summaryKey == ""content"":<tab><tab>self._end_content()<tab>else:<tab><tab>value = self.popContent(""description"")<tab><tab>context = self._getContext()<tab><tab><IF-STMT><tab><tab><tab>context[""textinput""][""description""] = value<tab><tab>elif self.inimage:<tab><tab><tab>context[""image""][""description""] = value<tab>self._summaryKey = None",1,if self . intextinput :,if self . intextinput :,0.75,100.00000000000004,1.0
def compute_nullable_nonterminals(self):<tab>nullable = {}<tab>num_nullable = 0<tab>while 1:<tab><tab>for p in self.grammar.Productions[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nullable[p.name] = 1<tab><tab><tab><tab>continue<tab><tab><tab>for t in p.prod:<tab><tab><tab><tab>if not t in nullable:<tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>nullable[p.name] = 1<tab><tab>if len(nullable) == num_nullable:<tab><tab><tab>break<tab><tab>num_nullable = len(nullable)<tab>return nullable,0,if p . len == 0 :,if p . name not in nullable :,0.0835778008746384,22.089591134157878,0.2962962962962963
"def process_bind_param(self, value, dialect):<tab>if value is not None:<tab><tab>if MAX_METADATA_VALUE_SIZE is not None:<tab><tab><tab>for k, v in list(value.items()):<tab><tab><tab><tab>sz = total_size(v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del value[k]<tab><tab><tab><tab><tab>log.warning(<tab><tab><tab><tab><tab><tab>""Refusing to bind metadata key {} due to size ({})"".format(<tab><tab><tab><tab><tab><tab><tab>k, sz<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>)<tab><tab>value = json_encoder.encode(value).encode()<tab>return value",1,if sz > MAX_METADATA_VALUE_SIZE :,if sz > MAX_METADATA_VALUE_SIZE :,0.75,100.00000000000004,1.0
"def process_input_line(self, line, store_history=True):<tab>""""""process the input, capturing stdout""""""<tab>stdout = sys.stdout<tab>splitter = self.IP.input_splitter<tab>try:<tab><tab>sys.stdout = self.cout<tab><tab>splitter.push(line)<tab><tab>more = splitter.push_accepts_more()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>source_raw = splitter.source_raw_reset()[1]<tab><tab><tab>except:<tab><tab><tab><tab># recent ipython #4504<tab><tab><tab><tab>source_raw = splitter.raw_reset()<tab><tab><tab>self.IP.run_cell(source_raw, store_history=store_history)<tab>finally:<tab><tab>sys.stdout = stdout",1,if not more :,if not more :,0.75,100.00000000000004,1.0
"def _dump_section(self, name, values, f):<tab>doc = ""__doc__""<tab><IF-STMT><tab><tab>print(""# %s"" % values[doc], file=f)<tab>print(""%s("" % name, file=f)<tab>for k, v in values.items():<tab><tab>if k.endswith(""__doc__""):<tab><tab><tab>continue<tab><tab>doc = k + ""__doc__""<tab><tab>if doc in values:<tab><tab><tab>print(""<tab># %s"" % values[doc], file=f)<tab><tab>print(""<tab>%s = %s,"" % (k, pprint.pformat(v, indent=8)), file=f)<tab>print("")\n"", file=f)",1,if doc in values :,if doc in values :,0.75,100.00000000000004,1.0
"def open_session(self, app, request):<tab>sid = request.cookies.get(app.session_cookie_name)<tab>if sid:<tab><tab>stored_session = self.cls.objects(sid=sid).first()<tab><tab>if stored_session:<tab><tab><tab>expiration = stored_session.expiration<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expiration = expiration.replace(tzinfo=utc)<tab><tab><tab>if expiration > datetime.datetime.utcnow().replace(tzinfo=utc):<tab><tab><tab><tab>return MongoEngineSession(<tab><tab><tab><tab><tab>initial=stored_session.data, sid=stored_session.sid<tab><tab><tab><tab>)<tab>return MongoEngineSession(sid=str(uuid.uuid4()))",0,if not expiration . tzinfo :,if expiration :,0.028363593025821247,1e-10,0.3333333333333333
"def table_entry(mode1, bind_type1, mode2, bind_type2):<tab>with sock(mode1) as sock1:<tab><tab>bind(sock1, bind_type1)<tab><tab>try:<tab><tab><tab>with sock(mode2) as sock2:<tab><tab><tab><tab>bind(sock2, bind_type2)<tab><tab>except OSError as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""INUSE""<tab><tab><tab>elif exc.winerror == errno.WSAEACCES:<tab><tab><tab><tab>return ""ACCESS""<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>return ""Success""",0,if exc . winerror == errno . WSAEADDRINUSE :,if exc . winerror == errno . EINVAL :,0.62709085524794,78.25422900366438,0.7142857142857143
"def __init__(self, ruleset):<tab># Organize rules by path<tab>self.ruleset = ruleset<tab>self.rules = {}<tab>for filename in self.ruleset.rules:<tab><tab>for rule in self.ruleset.rules[filename]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>manage_dictionary(self.rules, rule.path, [])<tab><tab><tab>self.rules[rule.path].append(rule)",0,if not rule . enabled :,if rule . path in self . rules :,0.04194106169660797,11.339582221952005,0.19444444444444445
"def talk(self, words):<tab>if self.writeSentence(words) == 0:<tab><tab>return<tab>r = []<tab>while 1:<tab><tab>i = self.readSentence()<tab><tab>if len(i) == 0:<tab><tab><tab>continue<tab><tab>reply = i[0]<tab><tab>attrs = {}<tab><tab>for w in i[1:]:<tab><tab><tab>j = w.find(""="", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>attrs[w] = """"<tab><tab><tab>else:<tab><tab><tab><tab>attrs[w[:j]] = w[j + 1 :]<tab><tab>r.append((reply, attrs))<tab><tab>if reply == ""!done"":<tab><tab><tab>return r",0,if j == - 1 :,if j < 0 :,0.051719732411378776,15.848738972120703,0.6
"def _check_decorator_overload(name: str, old: str, new: str) -> int:<tab>""""""Conditions for a decorator to overload an existing one.""""""<tab>properties = _property_decorators(name)<tab>if old == new:<tab><tab>return _MERGE<tab>elif old in properties and new in properties:<tab><tab>p_old, p_new = properties[old].precedence, properties[new].precedence<tab><tab><IF-STMT><tab><tab><tab>return _DISCARD<tab><tab>elif p_old == p_new:<tab><tab><tab>return _MERGE<tab><tab>else:<tab><tab><tab>return _REPLACE<tab>raise OverloadedDecoratorError(name, """")",1,if p_old > p_new :,if p_old > p_new :,0.75,100.00000000000004,1.0
"def validate_pk(self):<tab>try:<tab><tab>self._key = serialization.load_pem_private_key(<tab><tab><tab>self.key, password=None, backend=default_backend()<tab><tab>)<tab><tab>if self._key.key_size > 2048:<tab><tab><tab>AWSValidationException(<tab><tab><tab><tab>""The private key length is not supported. Only 1024-bit and 2048-bit are allowed.""<tab><tab><tab>)<tab>except Exception as err:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>raise AWSValidationException(<tab><tab><tab>""The private key is not PEM-encoded or is not valid.""<tab><tab>)",0,"if isinstance ( err , AWSValidationException ) :","if err . code != ""InvalidKey.pem"" :",0.019627455172827622,4.456882760699063,0.3148148148148148
"def _add_custom_statement(self, custom_statements):<tab>if custom_statements is None:<tab><tab>return<tab>self.resource_policy[""Version""] = ""2012-10-17""<tab>if self.resource_policy.get(""Statement"") is None:<tab><tab>self.resource_policy[""Statement""] = custom_statements<tab>else:<tab><tab><IF-STMT><tab><tab><tab>custom_statements = [custom_statements]<tab><tab>statement = self.resource_policy[""Statement""]<tab><tab>if not isinstance(statement, list):<tab><tab><tab>statement = [statement]<tab><tab>for s in custom_statements:<tab><tab><tab>if s not in statement:<tab><tab><tab><tab>statement.append(s)<tab><tab>self.resource_policy[""Statement""] = statement",1,"if not isinstance ( custom_statements , list ) :","if not isinstance ( custom_statements , list ) :",0.75,100.00000000000004,1.0
"def load(self, repn):<tab>for key in repn:<tab><tab>tmp = self._convert(key)<tab><tab><IF-STMT><tab><tab><tab>self.declare(tmp)<tab><tab>item = dict.__getitem__(self, tmp)<tab><tab>item._active = True<tab><tab>item.load(repn[key])",0,if tmp not in self :,if not self . _active :,0.02954063371652449,9.287528999566801,0.25
"def on_press_release(x):<tab>""""""Keyboard callback function.""""""<tab>global is_recording, enable_trigger_record<tab>press = keyboard.KeyboardEvent(""down"", 28, ""space"")<tab>release = keyboard.KeyboardEvent(""up"", 28, ""space"")<tab>if x.event_type == ""down"" and x.name == press.name:<tab><tab>if (not is_recording) and enable_trigger_record:<tab><tab><tab>sys.stdout.write(""Start Recording ... "")<tab><tab><tab>sys.stdout.flush()<tab><tab><tab>is_recording = True<tab>if x.event_type == ""up"" and x.name == release.name:<tab><tab><IF-STMT><tab><tab><tab>is_recording = False",0,if is_recording == True :,if ( not is_recording ) and enable_trigger_record :,0.028001459970687266,12.011055432195764,0.38181818181818183
"def apply_mask(self, mask, data_t, data_f):<tab>ind_t, ind_f = 0, 0<tab>out = []<tab>for m in cycle(mask):<tab><tab>if m:<tab><tab><tab>if ind_t == len(data_t):<tab><tab><tab><tab>return out<tab><tab><tab>out.append(data_t[ind_t])<tab><tab><tab>ind_t += 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return out<tab><tab><tab>out.append(data_f[ind_f])<tab><tab><tab>ind_f += 1<tab>return out",1,if ind_f == len ( data_f ) :,if ind_f == len ( data_f ) :,0.75,100.00000000000004,1.0
"def oo_contains_rule(source, apiGroups, resources, verbs):<tab>""""""Return true if the specified rule is contained within the provided source""""""<tab>rules = source[""rules""]<tab>if rules:<tab><tab>for rule in rules:<tab><tab><tab>if set(rule[""apiGroups""]) == set(apiGroups):<tab><tab><tab><tab>if set(rule[""resources""]) == set(resources):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return True<tab>return False",1,"if set ( rule [ ""verbs"" ] ) == set ( verbs ) :","if set ( rule [ ""verbs"" ] ) == set ( verbs ) :",1.0,100.00000000000004,1.0
"def _maybe_commit_artifact(self, artifact_id):<tab>artifact_status = self._artifacts[artifact_id]<tab>if artifact_status[""pending_count""] == 0 and artifact_status[""commit_requested""]:<tab><tab>for callback in artifact_status[""pre_commit_callbacks""]:<tab><tab><tab>callback()<tab><tab><IF-STMT><tab><tab><tab>self._api.commit_artifact(artifact_id)<tab><tab>for callback in artifact_status[""post_commit_callbacks""]:<tab><tab><tab>callback()",0,"if artifact_status [ ""finalize"" ] :","if artifact_status [ ""commit_requested"" ] :",0.37826709512211065,53.107253497886994,1.0
"def shuffler(iterator, pool_size=10 ** 5, refill_threshold=0.9):<tab>yields_between_refills = round(pool_size * (1 - refill_threshold))<tab># initialize pool; this step may or may not exhaust the iterator.<tab>pool = take_n(pool_size, iterator)<tab>while True:<tab><tab>random.shuffle(pool)<tab><tab>for i in range(yields_between_refills):<tab><tab><tab>yield pool.pop()<tab><tab>next_batch = take_n(yields_between_refills, iterator)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>pool.extend(next_batch)<tab># finish consuming whatever's left - no need for further randomization.<tab>yield from pool",1,if not next_batch :,if not next_batch :,0.75,100.00000000000004,1.0
"def __getitem__(self, key, _get_mode=False):<tab>if not _get_mode:<tab><tab>if isinstance(key, (int, long)):<tab><tab><tab>return self._list[key]<tab><tab><IF-STMT><tab><tab><tab>return self.__class__(self._list[key])<tab>ikey = key.lower()<tab>for k, v in self._list:<tab><tab>if k.lower() == ikey:<tab><tab><tab>return v<tab># micro optimization: if we are in get mode we will catch that<tab># exception one stack level down so we can raise a standard<tab># key error instead of our special one.<tab>if _get_mode:<tab><tab>raise KeyError()<tab>raise BadRequestKeyError(key)",0,"elif isinstance ( key , slice ) :","elif isinstance ( key , self . __class__ ) :",0.3616011398265707,30.576902884505124,0.6666666666666666
"def find(self, path):<tab>if os.path.isfile(path) or os.path.islink(path):<tab><tab>self.num_files = self.num_files + 1<tab><tab>if self.match_function(path):<tab><tab><tab>self.files.append(path)<tab>elif os.path.isdir(path):<tab><tab>for content in os.listdir(path):<tab><tab><tab>file = os.path.join(path, content)<tab><tab><tab>if os.path.isfile(file) or os.path.islink(file):<tab><tab><tab><tab>self.num_files = self.num_files + 1<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.files.append(file)<tab><tab><tab>else:<tab><tab><tab><tab>self.find(file)",1,if self . match_function ( file ) :,if self . match_function ( file ) :,0.75,100.00000000000004,1.0
"def validate_nb(self, nb):<tab>super(MetadataValidatorV3, self).validate_nb(nb)<tab>ids = set([])<tab>for cell in nb.cells:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>grade = cell.metadata[""nbgrader""][""grade""]<tab><tab>solution = cell.metadata[""nbgrader""][""solution""]<tab><tab>locked = cell.metadata[""nbgrader""][""locked""]<tab><tab>if not grade and not solution and not locked:<tab><tab><tab>continue<tab><tab>grade_id = cell.metadata[""nbgrader""][""grade_id""]<tab><tab>if grade_id in ids:<tab><tab><tab>raise ValidationError(""Duplicate grade id: {}"".format(grade_id))<tab><tab>ids.add(grade_id)",0,"if ""nbgrader"" not in cell . metadata :","if cell . metadata [ ""nbgrader"" ] is None :",0.07301587394120382,22.781556051062047,0.25
"def _skip_start(self):<tab>start, stop = self.start, self.stop<tab>for chunk in self.app_iter:<tab><tab>self._pos += len(chunk)<tab><tab>if self._pos < start:<tab><tab><tab>continue<tab><tab>elif self._pos == start:<tab><tab><tab>return b""""<tab><tab>else:<tab><tab><tab>chunk = chunk[start - self._pos :]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>chunk = chunk[: stop - self._pos]<tab><tab><tab><tab>assert len(chunk) == stop - start<tab><tab><tab>return chunk<tab>else:<tab><tab>raise StopIteration()",0,if stop is not None and self . _pos > stop :,if self . _pos < stop :,0.055659581558358255,22.871025343125112,0.20192307692307693
"def _SetUser(self, users):<tab>for user in users.items():<tab><tab>username = user[0]<tab><tab>settings = user[1]<tab><tab>room = settings[""room""][""name""] if ""room"" in settings else None<tab><tab>file_ = settings[""file""] if ""file"" in settings else None<tab><tab>if ""event"" in settings:<tab><tab><tab>if ""joined"" in settings[""event""]:<tab><tab><tab><tab>self._client.userlist.addUser(username, room, file_)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._client.removeUser(username)<tab><tab>else:<tab><tab><tab>self._client.userlist.modUser(username, room, file_)",0,"elif ""left"" in settings [ ""event"" ] :","elif ""removed"" in settings [ ""event"" ] :",0.6035533905932737,76.91605673134588,1.0
"def run_tests():<tab># type: () -> None<tab>x = 5<tab>with switch(x) as case:<tab><tab>if case(0):<tab><tab><tab>print(""zero"")<tab><tab><tab>print(""zero"")<tab><tab><IF-STMT><tab><tab><tab>print(""one or two"")<tab><tab>elif case(3, 4):<tab><tab><tab>print(""three or four"")<tab><tab>else:<tab><tab><tab>print(""default"")<tab><tab><tab>print(""another"")",0,"elif case ( 1 , 2 ) :","elif case ( 1 , 3 ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def _populate():<tab>for fname in glob.glob(os.path.join(os.path.dirname(__file__), ""data"", ""*.json"")):<tab><tab>with open(fname) as inf:<tab><tab><tab>data = json.load(inf)<tab><tab><tab>data = data[list(data.keys())[0]]<tab><tab><tab>data = data[list(data.keys())[0]]<tab><tab><tab>for item in data:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>LOGGER.warning(""Repeated emoji {}"".format(item[""key""]))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>TABLE[item[""key""]] = item[""value""]",0,"if item [ ""key"" ] in TABLE :","if ""key"" in item and ""value"" in item :",0.01983274868265512,14.211672443220438,0.2916666666666667
"def slot_to_material(bobject: bpy.types.Object, slot: bpy.types.MaterialSlot):<tab>mat = slot.material<tab># Pick up backed material if present<tab>if mat is not None:<tab><tab>baked_mat = mat.name + ""_"" + bobject.name + ""_baked""<tab><tab><IF-STMT><tab><tab><tab>mat = bpy.data.materials[baked_mat]<tab>return mat",1,if baked_mat in bpy . data . materials :,if baked_mat in bpy . data . materials :,0.75,100.00000000000004,1.0
"def __keyPress(self, widget, event):<tab>if event.key == ""G"" and event.modifiers & event.Modifiers.Control:<tab><tab>if not all(hasattr(p, ""isGanged"") for p in self.getPlugs()):<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>self.__ungang()<tab><tab>else:<tab><tab><tab>self.__gang()<tab><tab>return True<tab>return False",0,if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,"elif not all ( hasattr ( p , ""isungang"" ) for p in self . getPlugs ( ) ) :",0.7179166904294146,52.12485469629971,0.07936507936507936
"def check_expected(result, expected, contains=False):<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(result, str):<tab><tab><tab>result = result.encode(""ascii"")<tab><tab><IF-STMT><tab><tab><tab>expected = expected.encode(""ascii"")<tab>resultlines = result.splitlines()<tab>expectedlines = expected.splitlines()<tab>if len(resultlines) != len(expectedlines):<tab><tab>return False<tab>for rline, eline in zip(resultlines, expectedlines):<tab><tab>if contains:<tab><tab><tab>if eline not in rline:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>if not rline.endswith(eline):<tab><tab><tab><tab>return False<tab>return True",1,"if isinstance ( expected , str ) :","if isinstance ( expected , str ) :",0.75,100.00000000000004,1.0
"def hosts_to_domains(self, hosts, exclusions=[]):<tab>domains = []<tab>for host in hosts:<tab><tab>elements = host.split(""."")<tab><tab># recursively walk through the elements<tab><tab># extracting all possible (sub)domains<tab><tab>while len(elements) >= 2:<tab><tab><tab># account for domains stored as hosts<tab><tab><tab>if len(elements) == 2:<tab><tab><tab><tab>domain = ""."".join(elements)<tab><tab><tab>else:<tab><tab><tab><tab># drop the host element<tab><tab><tab><tab>domain = ""."".join(elements[1:])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>domains.append(domain)<tab><tab><tab>del elements[0]<tab>return domains",0,if domain not in domains + exclusions :,if domain not in exclusions :,0.37002220681953557,43.29820146406896,0.6857142857142857
"def hsconn_sender(self):<tab>while not self.stop_event.is_set():<tab><tab>try:<tab><tab><tab># Block, but timeout, so that we can exit the loop gracefully<tab><tab><tab>request = self.send_queue.get(True, 6.0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Socket got closed and set to None in another thread...<tab><tab><tab><tab>self.socket.sendall(request)<tab><tab><tab>if self.send_queue is not None:<tab><tab><tab><tab>self.send_queue.task_done()<tab><tab>except queue.Empty:<tab><tab><tab>pass<tab><tab>except OSError:<tab><tab><tab>self.stop_event.set()",0,if self . socket is not None :,if request is not None :,0.31689611060104994,38.49815007763549,0.225
"def get_url_args(self, item):<tab>if self.url_args:<tab><tab><IF-STMT><tab><tab><tab>url_args = self.url_args(item)<tab><tab>else:<tab><tab><tab>url_args = dict(self.url_args)<tab><tab>url_args[""id""] = item.id<tab><tab>return url_args<tab>else:<tab><tab>return dict(operation=self.label, id=item.id)",0,"if hasattr ( self . url_args , ""__call__"" ) :",if callable ( self . url_args ) :,0.2167379735069444,26.90608636157671,0.6
"def list_projects(self):<tab>projects = []<tab>page = 1<tab>while True:<tab><tab>repos = self._client.get(<tab><tab><tab>""/user/repos"", {""sort"": ""full_name"", ""page"": page, ""per_page"": 100}<tab><tab>)<tab><tab>page += 1<tab><tab>for repo in repos:<tab><tab><tab>projects.append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""id"": repo[""full_name""],<tab><tab><tab><tab><tab>""name"": repo[""full_name""],<tab><tab><tab><tab><tab>""description"": repo[""description""],<tab><tab><tab><tab><tab>""is_private"": repo[""private""],<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return projects",0,if len ( repos ) < 100 :,if len ( projects ) >= self . _max_projects :,0.17054132944044118,12.011055432195764,0.42857142857142855
"def scripts(self):<tab>application_root = current_app.config.get(""APPLICATION_ROOT"")<tab>subdir = application_root != ""/""<tab>scripts = []<tab>for script in get_registered_scripts():<tab><tab>if script.startswith(""http""):<tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab><tab><IF-STMT><tab><tab><tab>scripts.append(f'<script defer src=""{application_root}/{script}""></script>')<tab><tab>else:<tab><tab><tab>scripts.append(f'<script defer src=""{script}""></script>')<tab>return markup(""\n"".join(scripts))",1,elif subdir :,elif subdir :,0.5143161313935813,1e-10,1.0
"def print_map(node, l):<tab>if node.title not in l:<tab><tab>l[node.title] = []<tab>for n in node.children:<tab><tab><IF-STMT><tab><tab><tab>w = {n.title: []}<tab><tab><tab>l[node.title].append(w)<tab><tab><tab>print_map(n, w)<tab><tab>else:<tab><tab><tab>l[node.title].append(n.title)",0,if len ( n . children ) > 0 :,"if isinstance ( n , Node ) :",0.029321108690485986,10.816059393812111,0.36363636363636365
"def _validate_distinct_on_different_types_and_field_orders(<tab>self, collection, query, expected_results, get_mock_result):<tab>self.count = 0<tab>self.get_mock_result = get_mock_result<tab>query_iterable = collection.query_items(query, enable_cross_partition_query=True)<tab>results = list(query_iterable)<tab>for i in range(len(expected_results)):<tab><tab>if isinstance(results[i], dict):<tab><tab><tab>self.assertDictEqual(results[i], expected_results[i])<tab><tab><IF-STMT><tab><tab><tab>self.assertListEqual(results[i], expected_results[i])<tab><tab>else:<tab><tab><tab>self.assertEqual(results[i], expected_results[i])<tab>self.count = 0",1,"elif isinstance ( results [ i ] , list ) :","elif isinstance ( results [ i ] , list ) :",0.75,100.00000000000004,1.0
"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>v[""_class""] == ""Question""<tab><tab><tab>or v[""_class""] == ""Message""<tab><tab><tab>or v[""_class""] == ""Announcement""<tab><tab>):<tab><tab><tab>v[""admin""] = None<tab>return self.objs",1,"if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",0.75,100.00000000000004,1.0
"def qvec(self):<tab>#<tab><tab>if self.polrep != 'stokes':<tab>#<tab><tab><tab>raise Exception(""qvec is not defined unless self.polrep=='stokes'"")<tab>qvec = np.array([])<tab>if self.polrep == ""stokes"":<tab><tab>qvec = self._imdict[""Q""]<tab>elif self.polrep == ""circ"":<tab><tab><IF-STMT><tab><tab><tab>qvec = np.real(0.5 * (self.lrvec + self.rlvec))<tab>return qvec",0,if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 :,if self . lrvec is not None :,0.06414233069150531,4.599246087297971,0.1652892561983471
"def display_value(self, key, w):<tab>if key == ""vdevices"":<tab><tab># Very special case<tab><tab>nids = [n[""deviceID""] for n in self.get_value(""devices"")]<tab><tab>for device in self.app.devices.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>b = Gtk.CheckButton(device.get_title(), False)<tab><tab><tab><tab>b.set_tooltip_text(device[""id""])<tab><tab><tab><tab>self[""vdevices""].pack_start(b, False, False, 0)<tab><tab><tab><tab>b.set_active(device[""id""] in nids)<tab><tab>self[""vdevices""].show_all()<tab>else:<tab><tab>EditorDialog.display_value(self, key, w)",0,"if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :","if device [ ""type"" ] == ""device"" :",0.06455890515912768,11.450988914355818,0.48
"def _set_xflux_setting(self, **kwargs):<tab>for key, value in kwargs.items():<tab><tab>if key in self._settings_map:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._set_xflux_screen_color(value)<tab><tab><tab><tab>self._current_color = str(value)<tab><tab><tab><tab># hackish - changing the current color unpauses xflux,<tab><tab><tab><tab># must reflect that with state change<tab><tab><tab><tab>if self.state == self.states[""PAUSED""]:<tab><tab><tab><tab><tab>self.state = self.states[""RUNNING""]<tab><tab><tab>else:<tab><tab><tab><tab>self._xflux.sendline(self._settings_map[key] + str(value))<tab><tab><tab>self._c()",0,"if key == ""color"" :","if self . _settings_map [ key ] == ""screen"" :",0.026964759067697196,12.451643194233869,0.48333333333333334
"def apply_acceleration(self, veh_ids, acc):<tab>""""""See parent class.""""""<tab># to hand the case of a single vehicle<tab>if type(veh_ids) == str:<tab><tab>veh_ids = [veh_ids]<tab><tab>acc = [acc]<tab>for i, vid in enumerate(veh_ids):<tab><tab><IF-STMT><tab><tab><tab>this_vel = self.get_speed(vid)<tab><tab><tab>next_vel = max([this_vel + acc[i] * self.sim_step, 0])<tab><tab><tab>self.kernel_api.vehicle.slowDown(vid, next_vel, 1e-3)",0,if acc [ i ] is not None and vid in self . get_ids ( ) :,if acc [ i ] is not None :,0.34809428635232464,29.26985560739962,0.6161616161616161
"def largest_factor_relatively_prime(a, b):<tab>""""""Return the largest factor of a relatively prime to b.""""""<tab>while 1:<tab><tab>d = gcd(a, b)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>b = d<tab><tab>while 1:<tab><tab><tab>q, r = divmod(a, d)<tab><tab><tab>if r > 0:<tab><tab><tab><tab>break<tab><tab><tab>a = q<tab>return a",0,if d <= 1 :,if d > 0 :,0.31497877230811644,19.3576934939088,0.6
"def check_status(self):<tab>try:<tab><tab>du = psutil.disk_usage(""/"")<tab><tab><IF-STMT><tab><tab><tab>raise ServiceWarning(<tab><tab><tab><tab>""{host} {percent}% disk usage exceeds {disk_usage}%"".format(<tab><tab><tab><tab><tab>host=host, percent=du.percent, disk_usage=DISK_USAGE_MAX<tab><tab><tab><tab>)<tab><tab><tab>)<tab>except ValueError as e:<tab><tab>self.add_error(ServiceReturnedUnexpectedResult(""ValueError""), e)",0,if DISK_USAGE_MAX and du . percent >= DISK_USAGE_MAX :,if du . percent > DISK_USAGE_MAX :,0.18803512320899982,38.02970594133841,0.38181818181818183
"def build_reply(self, msg, text=None, private=False, threaded=False):<tab>response = self.build_message(text)<tab>if msg.is_group:<tab><tab><IF-STMT><tab><tab><tab>response.frm = self.bot_identifier<tab><tab><tab>response.to = IRCPerson(str(msg.frm))<tab><tab>else:<tab><tab><tab>response.frm = IRCRoomOccupant(str(self.bot_identifier), msg.frm.room)<tab><tab><tab>response.to = msg.frm.room<tab>else:<tab><tab>response.frm = self.bot_identifier<tab><tab>response.to = msg.frm<tab>return response",1,if private :,if private :,0.5311706625951745,1e-10,1.0
"def _dict_refs(obj, named):<tab>""""""Return key and value objects of a dict/proxy.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for k, v in _items(obj):<tab><tab><tab><tab>s = str(k)<tab><tab><tab><tab>yield _NamedRef(""[K] "" + s, k)<tab><tab><tab><tab>yield _NamedRef(""[V] "" + s + "": "" + _repr(v), v)<tab><tab>else:<tab><tab><tab>for k, v in _items(obj):<tab><tab><tab><tab>yield k<tab><tab><tab><tab>yield v<tab>except (KeyError, ReferenceError, TypeError) as x:<tab><tab>warnings.warn(""Iterating '%s': %r"" % (_classof(obj), x))",1,if named :,if named :,0.5311706625951745,1e-10,1.0
"def fetch_images():<tab>images = []<tab>marker = None<tab>while True:<tab><tab>batch = image_service.detail(<tab><tab><tab>context,<tab><tab><tab>filters=filters,<tab><tab><tab>marker=marker,<tab><tab><tab>sort_key=""created_at"",<tab><tab><tab>sort_dir=""desc"",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>images += batch<tab><tab>marker = batch[-1][""id""]<tab>return images",1,if not batch :,if not batch :,0.75,100.00000000000004,1.0
"def compress(self, data_list):<tab>warn_untested()<tab>if data_list:<tab><tab>if data_list[1] in forms.fields.EMPTY_VALUES:<tab><tab><tab>error = self.error_messages[""invalid_year""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab><IF-STMT><tab><tab><tab>error = self.error_messages[""invalid_month""]<tab><tab><tab>raise forms.ValidationError(error)<tab><tab>year = int(data_list[1])<tab><tab>month = int(data_list[0])<tab><tab># find last day of the month<tab><tab>day = monthrange(year, month)[1]<tab><tab>return date(year, month, day)<tab>return None",1,if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,0.75,100.00000000000004,1.0
"def _diff_dict(self, old, new):<tab>diff = {}<tab>removed = []<tab>added = []<tab>for key, value in old.items():<tab><tab>if key not in new:<tab><tab><tab>removed.append(key)<tab><tab><IF-STMT><tab><tab><tab># modified is indicated by a remove and add<tab><tab><tab>removed.append(key)<tab><tab><tab>added.append(key)<tab>for key, value in new.items():<tab><tab>if key not in old:<tab><tab><tab>added.append(key)<tab>if removed:<tab><tab>diff[""removed""] = sorted(removed)<tab>if added:<tab><tab>diff[""added""] = sorted(added)<tab>return diff",0,elif old [ key ] != new [ key ] :,if value != old [ key ] :,0.17792222285852238,36.782780004878816,0.13186813186813187
"def add_filters(self, function):<tab>try:<tab><tab>subscription = self.exists(function)<tab><tab><IF-STMT><tab><tab><tab>response = self._sns.call(<tab><tab><tab><tab>""set_subscription_attributes"",<tab><tab><tab><tab>SubscriptionArn=subscription[""SubscriptionArn""],<tab><tab><tab><tab>AttributeName=""FilterPolicy"",<tab><tab><tab><tab>AttributeValue=json.dumps(self.filters),<tab><tab><tab>)<tab><tab><tab>kappa.event_source.sns.LOG.debug(response)<tab>except Exception:<tab><tab>kappa.event_source.sns.LOG.exception(<tab><tab><tab>""Unable to add filters for SNS topic %s"", self.arn<tab><tab>)",1,if subscription :,if subscription :,0.5311706625951745,1e-10,1.0
"def init_weights(self, pretrained=None):<tab>if isinstance(pretrained, str):<tab><tab>logger = logging.getLogger()<tab><tab>load_checkpoint(self, pretrained, strict=False, logger=logger)<tab>elif pretrained is None:<tab><tab>for m in self.modules():<tab><tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab><tab>kaiming_init(m)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>constant_init(m, 1)<tab>else:<tab><tab>raise TypeError(""pretrained must be a str or None"")",0,"elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) :","elif isinstance ( m , nn . BatchNorm2d ) :",0.2449377963447635,34.1077254951379,0.7142857142857143
def test_is_native_login(self):<tab>for campaign in self.campaign_lists:<tab><tab>native = campaigns.is_native_login(campaign)<tab><tab><IF-STMT><tab><tab><tab>assert_true(native)<tab><tab>else:<tab><tab><tab>assert_false(native)<tab>native = campaigns.is_proxy_login(self.invalid_campaign)<tab>assert_true(native is None),0,"if campaign == ""prereg"" or campaign == ""erpc"" :",if campaign in self . campaign_lists :,0.10176962588759647,5.821935635427797,0.4444444444444444
"def _process_filter(self, query, host_state):<tab>""""""Recursively parse the query structure.""""""<tab>if not query:<tab><tab>return True<tab>cmd = query[0]<tab>method = self.commands[cmd]<tab>cooked_args = []<tab>for arg in query[1:]:<tab><tab>if isinstance(arg, list):<tab><tab><tab>arg = self._process_filter(arg, host_state)<tab><tab><IF-STMT><tab><tab><tab>arg = self._parse_string(arg, host_state)<tab><tab>if arg is not None:<tab><tab><tab>cooked_args.append(arg)<tab>result = method(self, cooked_args)<tab>return result",1,"elif isinstance ( arg , basestring ) :","elif isinstance ( arg , basestring ) :",0.75,100.00000000000004,1.0
"def find_go_files_mtime(app_files):<tab>files, mtime = [], 0<tab>for f, mt in app_files.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if APP_CONFIG.nobuild_files.match(f):<tab><tab><tab>continue<tab><tab>files.append(f)<tab><tab>mtime = max(mtime, mt)<tab>return files, mtime",1,"if not f . endswith ( "".go"" ) :","if not f . endswith ( "".go"" ) :",0.75,100.00000000000004,1.0
"def ExcludePath(self, path):<tab>""""""Check to see if this is a service url and matches inbound_services.""""""<tab>skip = False<tab>for reserved_path in self.reserved_paths.keys():<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>not self.inbound_services<tab><tab><tab><tab>or self.reserved_paths[reserved_path] not in self.inbound_services<tab><tab><tab>):<tab><tab><tab><tab>return (True, self.reserved_paths[reserved_path])<tab>return (False, None)",0,if path . startswith ( reserved_path ) :,if path . startswith ( reserved_path ) and skip :,0.507518651873186,72.92571723872932,0.638888888888889
"def param_cov(self) -> DataFrame:<tab>""""""Parameter covariance""""""<tab>if self._param_cov is not None:<tab><tab>param_cov = self._param_cov<tab>else:<tab><tab>params = np.asarray(self.params)<tab><tab><IF-STMT><tab><tab><tab>param_cov = self.model.compute_param_cov(params)<tab><tab>else:<tab><tab><tab>param_cov = self.model.compute_param_cov(params, robust=False)<tab>return DataFrame(param_cov, columns=self._names, index=self._names)",0,"if self . cov_type == ""robust"" :",if self . robust :,0.09453229110448028,11.141275535087015,0.7222222222222222
"def test_calculate_all_attentions(module, atype):<tab>m = importlib.import_module(module)<tab>args = make_arg(atype=atype)<tab><IF-STMT><tab><tab>batch = prepare_inputs(""pytorch"")<tab>else:<tab><tab>raise NotImplementedError<tab>model = m.E2E(6, 5, args)<tab>with chainer.no_backprop_mode():<tab><tab>if ""pytorch"" in module:<tab><tab><tab>att_ws = model.calculate_all_attentions(*batch)[0]<tab><tab>else:<tab><tab><tab>raise NotImplementedError<tab><tab>print(att_ws.shape)",1,"if ""pytorch"" in module :","if ""pytorch"" in module :",0.75,100.00000000000004,1.0
"def __eq__(self, other):<tab>try:<tab><tab>if self.type != other.type:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return self.askAnswer == other.askAnswer<tab><tab>elif self.type == ""SELECT"":<tab><tab><tab>return self.vars == other.vars and self.bindings == other.bindings<tab><tab>else:<tab><tab><tab>return self.graph == other.graph<tab>except:<tab><tab>return False",0,"if self . type == ""ASK"" :","elif self . type == ""SELECT"" :",0.20574838742430368,58.14307369682194,0.6
"def validate_memory(self, value):<tab>for k, v in value.viewitems():<tab><tab>if v is None:  # use NoneType to unset a value<tab><tab><tab>continue<tab><tab>if not re.match(PROCTYPE_MATCH, k):<tab><tab><tab>raise serializers.ValidationError(""Process types can only contain [a-z]"")<tab><tab><IF-STMT><tab><tab><tab>raise serializers.ValidationError(<tab><tab><tab><tab>""Limit format: <number><unit>, where unit = B, K, M or G""<tab><tab><tab>)<tab>return value",0,"if not re . match ( MEMLIMIT_MATCH , str ( v ) ) :","if re . match ( LIMIT_FORMAT_MATCH , k ) :",0.11528311151225838,25.504377483159427,0.2361111111111111
"def get_connections(data_about):<tab>data = data_about.find(""h3"", text=""Connections"").findNext()<tab>connections = {}<tab>for row in data.find_all(""tr""):<tab><tab>key = row.find_all(""td"")[0].text<tab><tab>value = row.find_all(""td"")[1]<tab><tab><IF-STMT><tab><tab><tab>connections[key] = get_all_links(value)<tab><tab>else:<tab><tab><tab>connections[key] = value.text<tab>return connections",0,"if ""Teams"" in key :","if key == ""links"" :",0.03654024892898815,8.25791079503452,0.45
"def _compute_map(self, first_byte, second_byte=None):<tab>if first_byte != 0x0F:<tab><tab>return ""XED_ILD_MAP0""<tab>else:<tab><tab>if second_byte == None:<tab><tab><tab>return ""XED_ILD_MAP1""<tab><tab>if second_byte == 0x38:<tab><tab><tab>return ""XED_ILD_MAP2""<tab><tab>if second_byte == 0x3A:<tab><tab><tab>return ""XED_ILD_MAP3""<tab><tab><IF-STMT><tab><tab><tab>return ""XED_ILD_MAPAMD""<tab>die(""Unhandled escape {} / map {} bytes"".format(first_byte, second_byte))",0,if second_byte == 0x0F and self . amd_enabled :,if second_byte == 0x4A :,0.10835085651527479,33.401359264888455,0.3055555555555556
"def compress(self, data_list):<tab>if data_list:<tab><tab>page_id = data_list[1]<tab><tab><IF-STMT><tab><tab><tab>if not self.required:<tab><tab><tab><tab>return None<tab><tab><tab>raise forms.ValidationError(self.error_messages[""invalid_page""])<tab><tab>return Page.objects.get(pk=page_id)<tab>return None",0,if page_id in EMPTY_VALUES :,if page_id not in Page . objects . all ( ) :,0.17039064418793326,19.67497981115564,0.25
"def find_module(self, fullname, path=None):<tab>path = path or self.path_entry<tab># print('looking for ""%s"" in %s ...' % (fullname, path))<tab>for _ext in [""js"", ""pyj"", ""py""]:<tab><tab>_filepath = os.path.join(self.path_entry, ""%s.%s"" % (fullname, _ext))<tab><tab><IF-STMT><tab><tab><tab>print(""module found at %s:%s"" % (_filepath, fullname))<tab><tab><tab>return VFSModuleLoader(_filepath, fullname)<tab>print(""module %s not found"" % fullname)<tab>raise ImportError()<tab>return None",0,if _filepath in VFS :,if os . path . exists ( _filepath ) :,0.025806626984353938,8.913765521398126,0.27472527472527475
"def __decToBin(self, myDec):<tab>n = 0<tab>binOfDec = """"<tab>while myDec > 2 ** n:<tab><tab>n = n + 1<tab>if (myDec < 2 ** n) & (myDec != 0):<tab><tab>n = n - 1<tab>while n >= 0:<tab><tab><IF-STMT><tab><tab><tab>myDec = myDec - 2 ** n<tab><tab><tab>binOfDec = binOfDec + ""1""<tab><tab>else:<tab><tab><tab>binOfDec = binOfDec + ""0""<tab><tab>n = n - 1<tab>return binOfDec",0,if myDec >= 2 ** n :,if n < 2 ** n :,0.4711135200865855,47.750342648354646,0.7333333333333333
"def __str__(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>NVMLError._errcode_to_string[self.value] = str(nvmlErrorString(self.value))<tab><tab>return NVMLError._errcode_to_string[self.value]<tab>except NVMLError_Uninitialized:<tab><tab>return ""NVML Error with code %d"" % self.value",1,if self . value not in NVMLError . _errcode_to_string :,if self . value not in NVMLError . _errcode_to_string :,0.75,100.00000000000004,1.0
"def abspath(pathdir: str) -> str:<tab>if Path is not None and isinstance(pathdir, Path):<tab><tab>return pathdir.abspath()<tab>else:<tab><tab>pathdir = path.abspath(pathdir)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>pathdir = pathdir.decode(fs_encoding)<tab><tab><tab>except UnicodeDecodeError as exc:<tab><tab><tab><tab>raise UnicodeDecodeError(<tab><tab><tab><tab><tab>""multibyte filename not supported on ""<tab><tab><tab><tab><tab>""this filesystem encoding ""<tab><tab><tab><tab><tab>""(%r)"" % fs_encoding<tab><tab><tab><tab>) from exc<tab><tab>return pathdir",0,"if isinstance ( pathdir , bytes ) :",if fs_encoding is not None :,0.018517117658868813,6.567274736060395,0.25
"def _get_vtkjs(self):<tab>if self._vtkjs is None and self.object is not None:<tab><tab><IF-STMT><tab><tab><tab>if isfile(self.object):<tab><tab><tab><tab>with open(self.object, ""rb"") as f:<tab><tab><tab><tab><tab>vtkjs = f.read()<tab><tab><tab>else:<tab><tab><tab><tab>data_url = urlopen(self.object)<tab><tab><tab><tab>vtkjs = data_url.read()<tab><tab>elif hasattr(self.object, ""read""):<tab><tab><tab>vtkjs = self.object.read()<tab><tab>self._vtkjs = vtkjs<tab>return self._vtkjs",0,"if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :","if hasattr ( self . object , ""read"" ) :",0.14264141169938938,16.493457938929108,0.3974358974358974
"def _set_uid(self, val):<tab>if val is not None:<tab><tab>if pwd is None:<tab><tab><tab>self.bus.log(""pwd module not available; ignoring uid."", level=30)<tab><tab><tab>val = None<tab><tab><IF-STMT><tab><tab><tab>val = pwd.getpwnam(val)[2]<tab>self._uid = val",0,"elif isinstance ( val , text_or_bytes ) :","elif hasattr ( pwd , ""getpwnam"" ) :",0.13693049977965305,8.639795714750207,0.3333333333333333
"def get_attached_nodes(self, external_account):<tab>for node in self.get_nodes_with_oauth_grants(external_account):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>node_settings = node.get_addon(self.oauth_provider.short_name)<tab><tab>if node_settings is None:<tab><tab><tab>continue<tab><tab>if node_settings.external_account == external_account:<tab><tab><tab>yield node",0,if node is None :,if node . is_linked :,0.06497877230811641,15.619699684601283,0.5
"def from_obj(cls, py_obj):<tab>if not isinstance(py_obj, Image):<tab><tab>raise TypeError(""py_obj must be a wandb.Image"")<tab>else:<tab><tab>if hasattr(py_obj, ""_boxes"") and py_obj._boxes:<tab><tab><tab>box_keys = list(py_obj._boxes.keys())<tab><tab>else:<tab><tab><tab>box_keys = []<tab><tab><IF-STMT><tab><tab><tab>mask_keys = list(py_obj.masks.keys())<tab><tab>else:<tab><tab><tab>mask_keys = []<tab><tab>return cls(box_keys, mask_keys)",1,"if hasattr ( py_obj , ""masks"" ) and py_obj . masks :","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :",1.0,100.00000000000004,1.0
"def write(self, *bits):<tab>for bit in bits:<tab><tab>if not self.bytestream:<tab><tab><tab>self.bytestream.append(0)<tab><tab>byte = self.bytestream[self.bytenum]<tab><tab>if self.bitnum == 8:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>byte = 0<tab><tab><tab><tab>self.bytestream += bytes([byte])<tab><tab><tab>self.bytenum += 1<tab><tab><tab>self.bitnum = 0<tab><tab>mask = 2 ** self.bitnum<tab><tab>if bit:<tab><tab><tab>byte |= mask<tab><tab>else:<tab><tab><tab>byte &= ~mask<tab><tab>self.bytestream[self.bytenum] = byte<tab><tab>self.bitnum += 1",0,if self . bytenum == len ( self . bytestream ) - 1 :,if not byte :,0.00720912966741127,1.2143667563059621,0.19753086419753085
"def destroy(self, wipe=False):<tab>if self.state == self.UP:<tab><tab>image = self.image()<tab><tab><IF-STMT><tab><tab><tab>return self.confirm_destroy(image, self.full_name, abort=False)<tab><tab>else:<tab><tab><tab>self.warn(""tried to destroy {0} which didn't exist"".format(self.full_name))<tab>return True",0,if image :,if image and image . exists ( ) :,0.08050925452257668,1e-10,0.4787878787878788
"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(<tab><tab><tab><tab>self.agent_url + ECS_AGENT_METADATA_PATH, timeout=1<tab><tab><tab>).json()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>match = AGENT_VERSION_EXP.search(resp.get(""Version""))<tab><tab><tab><tab>if match is not None and len(match.groups()) == 1:<tab><tab><tab><tab><tab>meta[""ecs_version""] = match.group(1)<tab><tab>except Exception as e:<tab><tab><tab>self.log.debug(""Error getting ECS version: %s"" % str(e))<tab>return meta",0,"if ""Version"" in resp :","if resp . get ( ""Status"" ) == 200 :",0.025806626984353938,4.6192151051305474,0.32051282051282054
"def _path_type(st, lst):<tab>parts = []<tab>if st:<tab><tab><IF-STMT><tab><tab><tab>parts.append(""file"")<tab><tab>elif stat.S_ISDIR(st.st_mode):<tab><tab><tab>parts.append(""dir"")<tab><tab>else:<tab><tab><tab>parts.append(""other"")<tab>if lst:<tab><tab>if stat.S_ISLNK(lst.st_mode):<tab><tab><tab>parts.append(""link"")<tab>return "" "".join(parts)",0,if stat . S_ISREG ( st . st_mode ) :,if stat . S_ISFILE ( st . st_mode ) :,0.5803088707179008,78.25422900366432,1.0
"def changed(self, action):<tab># Something was changed in the 'files' list<tab>if len(action.key) >= 1 and action.key[0].lower() == ""files"":<tab><tab># Refresh project files model<tab><tab><IF-STMT><tab><tab><tab># Don't clear the existing items if only inserting new things<tab><tab><tab>self.update_model(clear=False)<tab><tab>else:<tab><tab><tab># Clear existing items<tab><tab><tab>self.update_model(clear=True)",0,"if action . type == ""insert"" :","if action . key [ 0 ] . lower ( ) == ""project"" :",0.13062198125573496,16.267392600305733,0.41428571428571426
"def process(self, resources, event=None):<tab>client = local_session(self.manager.session_factory).client(""es"")<tab>for r in resources:<tab><tab><IF-STMT><tab><tab><tab>result = self.manager.retry(<tab><tab><tab><tab>client.describe_elasticsearch_domain_config,<tab><tab><tab><tab>DomainName=r[""DomainName""],<tab><tab><tab><tab>ignore_err_codes=(""ResourceNotFoundException"",),<tab><tab><tab>)<tab><tab><tab>if result:<tab><tab><tab><tab>r[self.policy_attribute] = json.loads(<tab><tab><tab><tab><tab>result.get(""DomainConfig"").get(""AccessPolicies"").get(""Options"")<tab><tab><tab><tab>)<tab>return super().process(resources)",1,if self . policy_attribute not in r :,if self . policy_attribute not in r :,0.75,100.00000000000004,1.0
"def line_items(self):<tab>line_items = []<tab>for line in self.lines_str:<tab><tab>line = line.split(""|"")<tab><tab>line = line[1:-1]  # del first and last empty item (consequence of split)<tab><tab>items = []<tab><tab>for item in line:<tab><tab><tab>i = re.search(r""(\S+([ \t]+\S+)*)+"", item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>items.append(i.group())<tab><tab><tab>else:<tab><tab><tab><tab>items.append("" "")<tab><tab>line_items.append(items)<tab>return line_items",1,if i :,if i :,0.5311706625951745,1e-10,1.0
"def on_data(res):<tab>if terminate.is_set():<tab><tab>return<tab>if args.strings and not args.no_content:<tab><tab>if type(res) == tuple:<tab><tab><tab>f, v = res<tab><tab><tab>if type(f) == unicode:<tab><tab><tab><tab>f = f.encode(""utf-8"")<tab><tab><tab>if type(v) == unicode:<tab><tab><tab><tab>v = v.encode(""utf-8"")<tab><tab><tab>self.success(""{}: {}"".format(f, v))<tab><tab><IF-STMT><tab><tab><tab>self.success(res)<tab>else:<tab><tab>self.success(res)",0,elif not args . content_only :,elif type ( res ) == str :,0.12039520508771762,5.669791110976001,0.2698412698412698
"def get_servers(self, detail=True, search_opts=None):<tab>rel_url = ""/servers/detail"" if detail else ""/servers""<tab>if search_opts is not None:<tab><tab>qparams = {}<tab><tab>for opt, val in search_opts.iteritems():<tab><tab><tab>qparams[opt] = val<tab><tab><IF-STMT><tab><tab><tab>query_string = ""?%s"" % urllib.urlencode(qparams)<tab><tab><tab>rel_url += query_string<tab>return self.api_get(rel_url)[""servers""]",1,if qparams :,if qparams :,0.5311706625951745,1e-10,1.0
"def run(self):<tab>while not self.__exit__:<tab><tab><IF-STMT><tab><tab><tab>sleep(10)<tab><tab><tab>continue<tab><tab>o = self.playlist[0]<tab><tab>self.playlist.remove(o)<tab><tab>obj = json.loads(o)<tab><tab>if not ""args"" in obj:<tab><tab><tab>obj[""args""] = {""ua"": """", ""header"": """", ""title"": """", ""referer"": """"}<tab><tab>obj[""play""] = False<tab><tab>self.handle = launch_player(obj[""urls""], obj[""ext""], **obj[""args""])<tab><tab>self.handle.wait()",0,if len ( self . playlist ) == 0 :,if not self . playlist :,0.061061928590688125,14.919518511396246,0.5584415584415584
"def get_to_download_runs_ids(session, headers):<tab>last_date = 0<tab>result = []<tab>while 1:<tab><tab>r = session.get(RUN_DATA_API.format(last_date=last_date), headers=headers)<tab><tab><IF-STMT><tab><tab><tab>run_logs = r.json()[""data""][""records""]<tab><tab><tab>result.extend([i[""logs""][0][""stats""][""id""] for i in run_logs])<tab><tab><tab>last_date = r.json()[""data""][""lastTimestamp""]<tab><tab><tab>since_time = datetime.utcfromtimestamp(last_date / 1000)<tab><tab><tab>print(f""pares keep ids data since {since_time}"")<tab><tab><tab>time.sleep(1)  # spider rule<tab><tab><tab>if not last_date:<tab><tab><tab><tab>break<tab>return result",0,if r . ok :,if r . status_code == 200 :,0.11726065783135259,16.784459625186194,0.6
"def __saveWork(self, work, results):<tab>""""""Stores the resulting last log line to the cache with the proxy key""""""<tab>del work<tab># pylint: disable=broad-except<tab>try:<tab><tab><IF-STMT><tab><tab><tab>__cached = self.__cache[results[0]]<tab><tab><tab>__cached[self.__TIME] = time.time()<tab><tab><tab>__cached[self.__LINE] = results[1]<tab><tab><tab>__cached[self.__LLU] = results[2]<tab>except KeyError as e:<tab><tab># Could happen while switching jobs with work in the queue<tab><tab>pass<tab>except Exception as e:<tab><tab>list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",0,if results :,if len ( results ) == 3 :,0.046522600101893324,1e-10,0.36
"def read_notes(rec):<tab>found = []<tab>for tag in range(500, 595):<tab><tab>if tag in (505, 520):<tab><tab><tab>continue<tab><tab>fields = rec.get_fields(str(tag))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for f in fields:<tab><tab><tab>x = f.get_lower_subfields()<tab><tab><tab>if x:<tab><tab><tab><tab>found.append("" "".join(x).strip("" ""))<tab>if found:<tab><tab>return ""\n\n"".join(found)",1,if not fields :,if not fields :,0.75,100.00000000000004,1.0
"def serialize_to(self, stream, alternate_script=None):<tab>stream.write(self.txo_ref.tx_ref.hash)<tab>stream.write_uint32(self.txo_ref.position)<tab>if alternate_script is not None:<tab><tab>stream.write_string(alternate_script)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>stream.write_string(self.coinbase)<tab><tab>else:<tab><tab><tab>stream.write_string(self.script.source)<tab>stream.write_uint32(self.sequence)",0,if self . is_coinbase :,if self . coinbase is not None :,0.19360647784576912,24.446151121745064,0.35714285714285715
"def func_named(self, arg):<tab>result = None<tab>target = ""do_"" + arg<tab>if target in dir(self):<tab><tab>result = target<tab>else:<tab><tab><IF-STMT>  # accept shortened versions of commands<tab><tab><tab>funcs = [fname for fname in self.keywords if fname.startswith(arg)]<tab><tab><tab>if len(funcs) == 1:<tab><tab><tab><tab>result = ""do_"" + funcs[0]<tab>return result",0,if self . abbrev :,if arg in self . keywords :,0.2221158082717638,15.619699684601283,0.23809523809523808
"def static_login(self, token, *, bot):<tab># Necessary to get aiohttp to stop complaining about session creation<tab>self.__session = aiohttp.ClientSession(<tab><tab>connector=self.connector, ws_response_class=DiscordClientWebSocketResponse<tab>)<tab>old_token, old_bot = self.token, self.bot_token<tab>self._token(token, bot=bot)<tab>try:<tab><tab>data = await self.request(Route(""GET"", ""/users/@me""))<tab>except HTTPException as exc:<tab><tab>self._token(old_token, bot=old_bot)<tab><tab><IF-STMT><tab><tab><tab>raise LoginFailure(""Improper token has been passed."") from exc<tab><tab>raise<tab>return data",0,if exc . response . status == 401 :,"if ""Invalid token"" in str ( exc ) :",0.016784918517629303,4.9323515694897075,0.2361111111111111
"def render_buttons(self):<tab>for x, button in enumerate(self.button_list):<tab><tab>gcolor = Gdk.color_parse(self.color_list[x])<tab><tab><IF-STMT><tab><tab><tab>fgcolor = Gdk.color_parse(""#FFFFFF"")<tab><tab>else:<tab><tab><tab>fgcolor = Gdk.color_parse(""#000000"")<tab><tab>button.set_label(self.color_list[x])<tab><tab>button.set_sensitive(True)<tab><tab>button.modify_bg(Gtk.StateType.NORMAL, gcolor)<tab><tab>button.modify_fg(Gtk.StateType.NORMAL, fgcolor)",0,"if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :",if x == 0 :,0.00604053331867027,0.45018791827775173,0.27472527472527475
"def _set_text(self, data):<tab>lines = []<tab>for key, value in data.items():<tab><tab>lines.append("""")<tab><tab>txt = yaml.dump({key: value}, default_flow_style=False)<tab><tab>title = self.titles.get(key)<tab><tab><IF-STMT><tab><tab><tab>lines.append(""# %s"" % title)<tab><tab>lines.append(txt.rstrip())<tab>txt = ""\n"".join(lines) + ""\n""<tab>txt = txt.lstrip()<tab>self.edit.setPlainText(txt)",1,if title :,if title :,0.5311706625951745,1e-10,1.0
"def build_path(self):<tab>for variable in re_path_template.findall(self.path):<tab><tab>name = variable.strip(""{}"")<tab><tab><IF-STMT><tab><tab><tab># No 'user' parameter provided, fetch it from Auth instead.<tab><tab><tab>value = self.api.auth.get_username()<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>value = quote(self.session.params[name])<tab><tab><tab>except KeyError:<tab><tab><tab><tab>raise TweepError(<tab><tab><tab><tab><tab>""No parameter value found for path variable: %s"" % name<tab><tab><tab><tab>)<tab><tab><tab>del self.session.params[name]<tab><tab>self.path = self.path.replace(variable, value)",0,"if name == ""user"" and ""user"" not in self . session . params and self . api . auth :","if name == ""user"" :",0.04386563131478238,10.384000820777368,0.23776223776223776
"def _calculate_writes_for_built_in_indices(self, entity):<tab>writes = 0<tab>for prop_name in entity.keys():<tab><tab><IF-STMT><tab><tab><tab>prop_vals = entity[prop_name]<tab><tab><tab>if isinstance(prop_vals, (list)):<tab><tab><tab><tab>num_prop_vals = len(prop_vals)<tab><tab><tab>else:<tab><tab><tab><tab>num_prop_vals = 1<tab><tab><tab>writes += 2 * num_prop_vals<tab>return writes",0,if not prop_name in entity . unindexed_properties ( ) :,if prop_name in self . built_in_indices :,0.14035642325857545,21.29480760387301,0.32051282051282054
"def create_connection(self, address, protocol_factory=None, **kw):<tab>""""""Helper method for creating a connection to an ``address``.""""""<tab>protocol_factory = protocol_factory or self.create_protocol<tab>if isinstance(address, tuple):<tab><tab>host, port = address<tab><tab><IF-STMT><tab><tab><tab>self.logger.debug(""Create connection %s:%s"", host, port)<tab><tab>_, protocol = await self._loop.create_connection(<tab><tab><tab>protocol_factory, host, port, **kw<tab><tab>)<tab><tab>await protocol.event(""connection_made"")<tab>else:<tab><tab>raise NotImplementedError(""Could not connect to %s"" % str(address))<tab>return protocol",0,if self . debug :,if self . _loop . get_debug ( ) :,0.10522622320176984,14.323145079400492,0.7307692307692308
def _increment_bracket_num(self):<tab>self._current_bracket -= 1<tab>if self._current_bracket < 0:<tab><tab>self._current_bracket = self._get_num_brackets() - 1<tab><tab>self._current_iteration += 1<tab><tab><IF-STMT><tab><tab><tab>self._current_bracket = 0,0,if self . _current_iteration > self . hyperband_iterations :,if self . _current_bracket > self . _max_bracket :,0.6048262086007482,43.33207865423753,1.0
"def get_cycle_path(self, curr_node, goal_node_index):<tab>for dep in curr_node[""deps""]:<tab><tab><IF-STMT><tab><tab><tab>return [curr_node[""address""]]<tab>for dep in curr_node[""deps""]:<tab><tab>path = self.get_cycle_path(<tab><tab><tab>self.get_by_address(dep), goal_node_index<tab><tab>)  # self.nodelist[dep], goal_node_index)<tab><tab>if len(path) > 0:<tab><tab><tab>path.insert(0, curr_node[""address""])<tab><tab><tab>return path<tab>return []",1,if dep == goal_node_index :,if dep == goal_node_index :,0.75,100.00000000000004,1.0
"def as_dict(path="""", version=""latest"", section=""meta-data""):<tab>result = {}<tab>dirs = dir(path, version, section)<tab>if not dirs:<tab><tab>return None<tab>for item in dirs:<tab><tab>if item.endswith(""/""):<tab><tab><tab>records = as_dict(path + item, version, section)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[item[:-1]] = records<tab><tab>elif is_dict.match(item):<tab><tab><tab>idx, name = is_dict.match(item).groups()<tab><tab><tab>records = as_dict(path + idx + ""/"", version, section)<tab><tab><tab>if records:<tab><tab><tab><tab>result[name] = records<tab><tab>else:<tab><tab><tab>result[item] = valueconv(get(path + item, version, section))<tab>return result",1,if records :,if records :,0.5311706625951745,1e-10,1.0
"def preprocess_raw_enwik9(input_filename, output_filename):<tab>with open(input_filename, ""r"") as f1:<tab><tab>with open(output_filename, ""w"") as f2:<tab><tab><tab>while True:<tab><tab><tab><tab>line = f1.readline()<tab><tab><tab><tab>if not line:<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>line = list(enwik9_norm_transform([line]))[0]<tab><tab><tab><tab>if line != "" "" and line != """":<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>line = line[1:]<tab><tab><tab><tab><tab>f2.writelines(line + ""\n"")",0,"if line [ 0 ] == "" "" :","if line [ 0 ] == ""\n"" :",0.5618723018637402,67.0422683816333,1.0
"def _handle_unsubscribe(self, web_sock):<tab>index = None<tab>with await self._subscriber_lock:<tab><tab>for i, (subscriber_web_sock, _) in enumerate(self._subscribers):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>index = i<tab><tab><tab><tab>break<tab><tab>if index is not None:<tab><tab><tab>del self._subscribers[index]<tab><tab>if not self._subscribers:<tab><tab><tab>asyncio.ensure_future(self._unregister_subscriptions())",0,if subscriber_web_sock == web_sock :,if web_sock == subscriber_web_sock :,0.2901714209472326,75.10499815709778,1.0
"def formatmonthname(self, theyear, themonth, withyear=True):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab>s = month_name[themonth]<tab><tab>if encoding is not None:<tab><tab><tab>s = s.decode(encoding)<tab><tab><IF-STMT><tab><tab><tab>s = ""%s %s"" % (s, theyear)<tab><tab>return '<tr><th colspan=""7"" class=""month"">%s</th></tr>' % s",1,if withyear :,if withyear :,0.5311706625951745,1e-10,1.0
"def generate_sitemaps(filename):<tab>rows = (line.strip().split(""\t"") for line in open(filename))<tab>for sortkey, chunk in itertools.groupby(rows, lambda row: row[0]):<tab><tab>things = []<tab><tab>_chunk = list(chunk)<tab><tab>for segment in _chunk:<tab><tab><tab>sortkey = segment.pop(0)<tab><tab><tab>last_modified = segment.pop(-1)<tab><tab><tab>path = """".join(segment)<tab><tab><tab>things.append(web.storage(path=path, last_modified=last_modified))<tab><tab><IF-STMT><tab><tab><tab>write(""sitemaps/sitemap_%s.xml.gz"" % sortkey, sitemap(things))",0,if things :,if len ( things ) > 0 :,0.046522600101893324,1e-10,0.36
"def use_index(<tab>self, term: Union[str, Index], *terms: Union[str, Index]) -> ""QueryBuilder"":<tab>for t in (term, *terms):<tab><tab><IF-STMT><tab><tab><tab>self._use_indexes.append(t)<tab><tab>elif isinstance(t, str):<tab><tab><tab>self._use_indexes.append(Index(t))",1,"if isinstance ( t , Index ) :","if isinstance ( t , Index ) :",0.75,100.00000000000004,1.0
"def get_changed(self):<tab>if self._is_expression():<tab><tab>result = self._get_node_text(self.ast)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>return result<tab>else:<tab><tab>collector = codeanalyze.ChangeCollector(self.source)<tab><tab>last_end = -1<tab><tab>for match in self.matches:<tab><tab><tab>start, end = match.get_region()<tab><tab><tab>if start < last_end:<tab><tab><tab><tab>if not self._is_expression():<tab><tab><tab><tab><tab>continue<tab><tab><tab>last_end = end<tab><tab><tab>replacement = self._get_matched_text(match)<tab><tab><tab>collector.add_change(start, end, replacement)<tab><tab>return collector.get_changed()",0,if result == self . source :,if result is None :,0.04240600921794552,12.975849993980741,0.42857142857142855
"def quiet_f(*args):<tab>vars = {arg_name: Real(arg) for arg_name, arg in zip(arg_names, args)}<tab>value = dynamic_scoping(quiet_expr.evaluate, vars, evaluation)<tab>if expect_list:<tab><tab>if value.has_form(""List"", None):<tab><tab><tab>value = [extract_pyreal(item) for item in value.leaves]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>return value<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>value = extract_pyreal(value)<tab><tab>if value is None or isinf(value) or isnan(value):<tab><tab><tab>return None<tab><tab>return value",0,if any ( item is None for item in value ) :,if value is None or isinf ( value ) or isnan ( value ) :,0.1132751171636144,13.380161378318954,0.1590909090909091
"def _reemit_nested_event(self, event: Event):<tab>source_index = self.index(event.source)<tab>for attr in (""index"", ""new_index""):<tab><tab><IF-STMT><tab><tab><tab>src_index = ensure_tuple_index(event.index)<tab><tab><tab>setattr(event, attr, (source_index,) + src_index)<tab>if not hasattr(event, ""index""):<tab><tab>setattr(event, ""index"", source_index)<tab># reemit with this object's EventEmitter of the same type if present<tab># otherwise just emit with the EmitterGroup itself<tab>getattr(self.events, event.type, self.events)(event)",1,"if hasattr ( event , attr ) :","if hasattr ( event , attr ) :",0.75,100.00000000000004,1.0
"def check(self):<tab>""""""Perform required checks to conclude if it's safe to operate""""""<tab>if self.interpreter.manual is None:<tab><tab><IF-STMT><tab><tab><tab>self.error = self.process.error<tab><tab><tab>self.tip = self.process.tip<tab><tab><tab>return False<tab>start = time.time()<tab>while not self._status():<tab><tab>if time.time() - start >= 2:  # 2s<tab><tab><tab>self.error = ""can't connect to the minserver on {}:{}"".format(<tab><tab><tab><tab>self.interpreter.host, self.interpreter.port<tab><tab><tab>)<tab><tab><tab>self.tip = ""check your vagrant machine is running""<tab><tab><tab>return False<tab><tab>time.sleep(0.1)<tab>return True",0,if not self . process . healthy :,if self . process :,0.0823244657685789,24.795364698947967,0.2916666666666667
"def apply(self):<tab>new_block = self.block.copy()<tab>new_block.clear()<tab>for inst in self.block.body:<tab><tab><IF-STMT><tab><tab><tab>const_assign = self._assign_const(inst)<tab><tab><tab>new_block.append(const_assign)<tab><tab><tab>inst = self._assign_getitem(inst, index=const_assign.target)<tab><tab>new_block.append(inst)<tab>return new_block",0,"if isinstance ( inst , Assign ) and inst . value in self . getattrs :",if self . _is_const ( inst ) :,0.019987954696386305,7.738764559489539,0.22982456140350876
"def _get_orientation(self):<tab>if self.state:<tab><tab>rotation = [0] * 9<tab><tab>inclination = [0] * 9<tab><tab>gravity = []<tab><tab>geomagnetic = []<tab><tab>gravity = self.listener_a.values<tab><tab>geomagnetic = self.listener_m.values<tab><tab><IF-STMT><tab><tab><tab>ff_state = SensorManager.getRotationMatrix(<tab><tab><tab><tab>rotation, inclination, gravity, geomagnetic<tab><tab><tab>)<tab><tab><tab>if ff_state:<tab><tab><tab><tab>values = [0, 0, 0]<tab><tab><tab><tab>values = SensorManager.getOrientation(rotation, values)<tab><tab><tab>return values",0,if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None :,if self . listener_a and self . listener_m :,0.08268051140171255,2.988662868962178,0.15555555555555556
def getFirstSubGraph(graph):<tab>if len(graph) == 0:<tab><tab>return None<tab>subg = {}<tab>todo = [graph.keys()[0]]<tab>while len(todo) > 0:<tab><tab><IF-STMT><tab><tab><tab>subg[todo[0]] = graph[todo[0]]<tab><tab><tab>todo.extend(graph[todo[0]])<tab><tab><tab>del graph[todo[0]]<tab><tab>del todo[0]<tab>return subg,0,if todo [ 0 ] in graph . keys ( ) :,if graph [ todo [ 0 ] ] is None :,0.18761787110317138,24.640511033537816,0.2222222222222222
"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if ""Last-Modified"" not in rv.headers:<tab><tab>try:<tab><tab><tab>result = date<tab><tab><tab>if callable(result):<tab><tab><tab><tab>result = result(rv)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>from werkzeug.http import http_date<tab><tab><tab><tab>result = http_date(result)<tab><tab><tab>if result:<tab><tab><tab><tab>rv.headers[""Last-Modified""] = result<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the lastmodified value for response {!r}"".format(<tab><tab><tab><tab><tab>rv<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return rv",0,"if not isinstance ( result , basestring ) :","if not isinstance ( result , date ) :",0.5818820875411705,66.06328636027612,0.7142857142857143
"def set_invoice_details(self, row):<tab>invoice_details = self.invoice_details.get(row.voucher_no, {})<tab>if row.due_date:<tab><tab>invoice_details.pop(""due_date"", None)<tab>row.update(invoice_details)<tab>if row.voucher_type == ""Sales Invoice"":<tab><tab><IF-STMT><tab><tab><tab>self.set_delivery_notes(row)<tab><tab>if self.filters.show_sales_person and row.sales_team:<tab><tab><tab>row.sales_person = "", "".join(row.sales_team)<tab><tab><tab>del row[""sales_team""]",0,if self . filters . show_delivery_notes :,if self . filters . delivery_notes :,0.574113272471593,59.86908497649472,1.0
"def process(output):<tab>modules = {}<tab>for line in output:<tab><tab>name, size, instances, depends, state, _ = line.split("" "", 5)<tab><tab>instances = int(instances)<tab><tab>module = {<tab><tab><tab>""size"": size,<tab><tab><tab>""instances"": instances,<tab><tab><tab>""state"": state,<tab><tab>}<tab><tab><IF-STMT><tab><tab><tab>module[""depends""] = [value for value in depends.split("","") if value]<tab><tab>modules[name] = module<tab>return modules",0,"if depends != ""-"" :",if depends :,0.06767423853569741,1e-10,1.0
"def _get_host_from_zc_service_info(service_info: zeroconf.ServiceInfo):<tab>""""""Get hostname or IP + port from zeroconf service_info.""""""<tab>host = None<tab>port = None<tab>if (<tab><tab>service_info<tab><tab>and service_info.port<tab><tab>and (service_info.server or len(service_info.addresses) > 0)<tab>):<tab><tab><IF-STMT><tab><tab><tab>host = socket.inet_ntoa(service_info.addresses[0])<tab><tab>else:<tab><tab><tab>host = service_info.server.lower()<tab><tab>port = service_info.port<tab>return (host, port)",0,if len ( service_info . addresses ) > 0 :,if service_info . addresses [ 0 ] :,0.10593478453804159,36.17085516890759,0.38461538461538464
"def _init_weights(self, module):<tab>if isinstance(module, nn.Linear):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab>if module.bias is not None:<tab><tab><tab>module.bias.data.zero_()<tab>elif isinstance(module, nn.Embedding):<tab><tab>module.weight.data.normal_(mean=0.0, std=self.config.init_std)<tab><tab><IF-STMT><tab><tab><tab>module.weight.data[module.padding_idx].zero_()",1,if module . padding_idx is not None :,if module . padding_idx is not None :,0.75,100.00000000000004,1.0
"def visitFromImport(self, import_stmt, import_info):<tab>new_pairs = []<tab>if not import_info.is_star_import():<tab><tab>for name, alias in import_info.names_and_aliases:<tab><tab><tab>try:<tab><tab><tab><tab>pyname = self.pymodule[alias or name]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>except exceptions.AttributeNotFoundError:<tab><tab><tab><tab>pass<tab><tab><tab>new_pairs.append((name, alias))<tab>return importinfo.FromImport(import_info.module_name, import_info.level, new_pairs)",0,"if occurrences . same_pyname ( self . pyname , pyname ) :",if pyname is None :,0.010805043283377891,2.3238598963754593,0.2761904761904762
"def _apply_patches(self):<tab>try:<tab><tab>s = Subprocess(<tab><tab><tab>log=self.logfile, cwd=self.build_dir, verbose=self.options.verbose<tab><tab>)<tab><tab>for patch in self.patches:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for ed, source in patch.items():<tab><tab><tab><tab><tab>s.shell(""ed - %s < %s"" % (source, ed))<tab><tab><tab>else:<tab><tab><tab><tab>s.shell(""patch -p0 < %s"" % patch)<tab>except:<tab><tab>logger.error(""Failed to patch `%s`.\n%s"" % (self.build_dir, sys.exc_info()[1]))<tab><tab>sys.exit(1)",0,if type ( patch ) is dict :,"if isinstance ( patch , dict ) :",0.03916858170756418,14.535768424205482,0.40816326530612246
"def __init__(self, parent, dir, mask, with_dirs=True):<tab>filelist = []<tab>dirlist = [""..""]<tab>self.dir = dir<tab>self.file = """"<tab>mask = mask.upper()<tab>pattern = self.MakeRegex(mask)<tab>for i in os.listdir(dir):<tab><tab>if i == ""."" or i == "".."":<tab><tab><tab>continue<tab><tab>path = os.path.join(dir, i)<tab><tab><IF-STMT><tab><tab><tab>dirlist.append(i)<tab><tab><tab>continue<tab><tab>path = path.upper()<tab><tab>value = i.upper()<tab><tab>if pattern.match(value) is not None:<tab><tab><tab>filelist.append(i)<tab>self.files = filelist<tab>if with_dirs:<tab><tab>self.dirs = dirlist",0,if os . path . isdir ( path ) :,if not os . path . isdir ( path ) :,0.6776644327756607,80.70557274927978,0.3181818181818182
"def remove_invalid_dirs(paths, bp_dir, module_name):<tab>ret = []<tab>for path in paths:<tab><tab><IF-STMT><tab><tab><tab>ret.append(path)<tab><tab>else:<tab><tab><tab>logging.warning('Dir ""%s"" of module ""%s"" does not exist', path, module_name)<tab>return ret",0,"if os . path . isdir ( os . path . join ( bp_dir , path ) ) :",if path . startswith ( bp_dir ) :,0.017027339412004527,12.16827631830745,0.25925925925925924
"def update_sockets(self):<tab>inputs = self.inputs<tab>inputs_n = ""ABabcd""<tab>penta_sockets = pentagon_dict[self.grid_type].input_sockets<tab>for socket in inputs_n:<tab><tab>if socket in penta_sockets:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>inputs[socket].hide_safe = False<tab><tab>else:<tab><tab><tab>inputs[socket].hide_safe = True",1,if inputs [ socket ] . hide_safe :,if inputs [ socket ] . hide_safe :,0.75,100.00000000000004,1.0
"def __cut(sentence):<tab>global emit_P<tab>prob, pos_list = viterbi(sentence, ""BMES"", start_P, trans_P, emit_P)<tab>begin, nexti = 0, 0<tab># print pos_list, sentence<tab>for i, char in enumerate(sentence):<tab><tab>pos = pos_list[i]<tab><tab>if pos == ""B"":<tab><tab><tab>begin = i<tab><tab>elif pos == ""E"":<tab><tab><tab>yield sentence[begin : i + 1]<tab><tab><tab>nexti = i + 1<tab><tab><IF-STMT><tab><tab><tab>yield char<tab><tab><tab>nexti = i + 1<tab>if nexti < len(sentence):<tab><tab>yield sentence[nexti:]",0,"elif pos == ""S"" :","elif pos == ""F"" :",0.6428720214849399,59.4603557501361,1.0
"def validate(self):<tab>if self.data.get(""encrypted"", True):<tab><tab>key = self.data.get(""target_key"")<tab><tab><IF-STMT><tab><tab><tab>raise PolicyValidationError(<tab><tab><tab><tab>""Encrypted snapshot copy requires kms key on %s"" % (self.manager.data,)<tab><tab><tab>)<tab>return self",0,if not key :,"if key is None or key . get ( ""kms_key"" ) is None :",0.15717246068647805,2.8265205879007453,0.203125
"def __init__(self, patch_files, patch_directories):<tab>files = []<tab>files_data = {}<tab>for filename_data in patch_files:<tab><tab>if isinstance(filename_data, list):<tab><tab><tab>filename, data = filename_data<tab><tab>else:<tab><tab><tab>filename = filename_data<tab><tab><tab>data = None<tab><tab><IF-STMT><tab><tab><tab>filename = ""{0}{1}"".format(FakeState.deploy_dir, filename)<tab><tab>files.append(filename)<tab><tab>if data:<tab><tab><tab>files_data[filename] = data<tab>self.files = files<tab>self.files_data = files_data<tab>self.directories = patch_directories",0,if not filename . startswith ( os . sep ) :,if not filename . startswith ( FakeState . deploy_dir ) :,0.519351246099359,44.08231875586728,0.6136363636363636
"def validate_name_and_description(body, check_length=True):<tab>for attribute in [""name"", ""description"", ""display_name"", ""display_description""]:<tab><tab>value = body.get(attribute)<tab><tab>if value is not None:<tab><tab><tab>if isinstance(value, six.string_types):<tab><tab><tab><tab>body[attribute] = value.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>utils.check_string_length(<tab><tab><tab><tab><tab><tab>body[attribute], attribute, min_length=0, max_length=255<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except exception.InvalidInput as error:<tab><tab><tab><tab><tab>raise webob.exc.HTTPBadRequest(explanation=error.msg)",1,if check_length :,if check_length :,0.5311706625951745,1e-10,1.0
"def pick(items, sel):<tab>for x, s in zip(items, sel):<tab><tab>if match(s):<tab><tab><tab>yield x<tab><tab><IF-STMT><tab><tab><tab>yield x.restructure(x.head, pick(x.leaves, s.leaves), evaluation)",0,elif not x . is_atom ( ) and not s . is_atom ( ) :,"elif hasattr ( s , ""leaves"" ) :",0.10739367185045685,4.29039557970495,0.2653061224489796
"def wait_or_kill(self):<tab>""""""Wait for the program to terminate, or kill it after 5s.""""""<tab>if self.instance.poll() is None:<tab><tab># We try one more time to kill gracefully using Ctrl-C.<tab><tab>logger.info(""Interrupting %s and waiting..."", self.coord)<tab><tab>self.instance.send_signal(signal.SIGINT)<tab><tab># FIXME on py3 this becomes self.instance.wait(timeout=5)<tab><tab>t = monotonic_time()<tab><tab>while monotonic_time() - t < 5:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.info(""Terminated %s."", self.coord)<tab><tab><tab><tab>break<tab><tab><tab>time.sleep(0.1)<tab><tab>else:<tab><tab><tab>self.kill()",1,if self . instance . poll ( ) is not None :,if self . instance . poll ( ) is not None :,0.75,100.00000000000004,1.0
"def sort_collection(self, models, many):<tab>ordering = self.ordering<tab>if not many or not ordering:<tab><tab>return models<tab>for key in reversed(ordering):<tab><tab>reverse = key[0] == ""-""<tab><tab><IF-STMT><tab><tab><tab>key = key[1:]<tab><tab>models = sorted(models, key=partial(deep_getattr, key=key), reverse=reverse)<tab>return models",1,if reverse :,if reverse :,0.5311706625951745,1e-10,1.0
"def get_palette_for_custom_classes(self, class_names, palette=None):<tab>if self.label_map is not None:<tab><tab># return subset of palette<tab><tab>palette = []<tab><tab>for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>palette.append(self.PALETTE[old_id])<tab><tab>palette = type(self.PALETTE)(palette)<tab>elif palette is None:<tab><tab>if self.PALETTE is None:<tab><tab><tab>palette = np.random.randint(0, 255, size=(len(class_names), 3))<tab><tab>else:<tab><tab><tab>palette = self.PALETTE<tab>return palette",0,if new_id != - 1 :,if old_id in class_names :,0.02713659235259708,11.339582221952005,0.5
"def _find_tcl_dir():<tab>lib_dirs = [os.path.dirname(_x) for _x in sys.path if _x.lower().endswith(""lib"")]<tab>for lib_dir in lib_dirs:<tab><tab>base_dir = os.path.join(lib_dir, TclLibrary.FOLDER)<tab><tab><IF-STMT><tab><tab><tab>for root, _, files in os.walk(base_dir):<tab><tab><tab><tab>if TclLibrary.INIT_TCL in files:<tab><tab><tab><tab><tab>return root",0,if os . path . exists ( base_dir ) :,if os . path . isdir ( base_dir ) :,0.5803088707179008,73.48889200874659,0.6666666666666666
"def __next__(self):<tab>""""""Special paging functionality""""""<tab>if self.iter is None:<tab><tab>self.iter = iter(self.objs)<tab>try:<tab><tab>return next(self.iter)<tab>except StopIteration:<tab><tab>self.iter = None<tab><tab>self.objs = []<tab><tab><IF-STMT><tab><tab><tab>self.page += 1<tab><tab><tab>self._connection.get_response(self.action, self.params, self.page, self)<tab><tab><tab>return next(self)<tab><tab>else:<tab><tab><tab>raise",0,if int ( self . page ) < int ( self . total_pages ) :,if self . page < self . limit :,0.07489200808026969,10.318351668184548,0.3245614035087719
"def parse(cls, api, json):<tab>lst = List(api)<tab>setattr(lst, ""_json"", json)<tab>for k, v in json.items():<tab><tab>if k == ""user"":<tab><tab><tab>setattr(lst, k, User.parse(api, v))<tab><tab><IF-STMT><tab><tab><tab>setattr(lst, k, parse_datetime(v))<tab><tab>else:<tab><tab><tab>setattr(lst, k, v)<tab>return lst",0,"elif k == ""created_at"" :","elif k == ""date"" :",0.6428720214849399,46.307771619910305,1.0
"def real_type(self):<tab># Find the real type representation by updating it as required<tab>real_type = self.type<tab>if self.flag_indicator:<tab><tab>real_type = ""#""<tab>if self.is_vector:<tab><tab><IF-STMT><tab><tab><tab>real_type = ""Vector<{}>"".format(real_type)<tab><tab>else:<tab><tab><tab>real_type = ""vector<{}>"".format(real_type)<tab>if self.is_generic:<tab><tab>real_type = ""!{}"".format(real_type)<tab>if self.is_flag:<tab><tab>real_type = ""flags.{}?{}"".format(self.flag_index, real_type)<tab>return real_type",0,if self . use_vector_id :,"if real_type . startswith ( ""Vector"" ) :",0.028001459970687266,4.789232204309912,0.5
"def check_fs(path):<tab>with open(path, ""rb"") as f:<tab><tab>code = python_bytes_to_unicode(f.read(), errors=""replace"")<tab><tab><IF-STMT><tab><tab><tab>module = _load_module(evaluator, path, code)<tab><tab><tab>module_name = sys_path.dotted_path_in_sys_path(<tab><tab><tab><tab>evaluator.project.sys_path, path<tab><tab><tab>)<tab><tab><tab>if module_name is not None:<tab><tab><tab><tab>add_module(evaluator, module_name, module)<tab><tab><tab>return module",0,if name in code :,if code is not None :,0.15729470354711872,10.682175159905853,0.20833333333333331
"def infoCalendar(users):<tab>calendarId = normalizeCalendarId(sys.argv[5], checkPrimary=True)<tab>i = 0<tab>count = len(users)<tab>for user in users:<tab><tab>i += 1<tab><tab>user, cal = buildCalendarGAPIObject(user)<tab><tab>if not cal:<tab><tab><tab>continue<tab><tab>result = gapi.call(<tab><tab><tab>cal.calendarList(), ""get"", soft_errors=True, calendarId=calendarId<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>print(f""User: {user}, Calendar:{display.current_count(i, count)}"")<tab><tab><tab>_showCalendar(result, 1, 1)",1,if result :,if result :,0.5311706625951745,1e-10,1.0
"def set_hidestate_input_sockets_to_cope_with_switchnum(self):<tab>tndict = get_indices_that_should_be_visible(self.node_state)<tab>for key, value in tndict.items():<tab><tab>socket = self.inputs[key]<tab><tab>desired_hide_state = not (value)<tab><tab><IF-STMT><tab><tab><tab>socket.hide_safe = desired_hide_state",0,if not socket . hide == desired_hide_state :,if socket . hide_safe :,0.03730445553501224,13.653323887370865,0.36
"def get_class_name(item):<tab>class_name, module_name = None, None<tab>for parent in reversed(item.listchain()):<tab><tab>if isinstance(parent, pytest.Class):<tab><tab><tab>class_name = parent.name<tab><tab><IF-STMT><tab><tab><tab>module_name = parent.module.__name__<tab><tab><tab>break<tab># heuristic:<tab># - better to group gpu and task tests, since tests from those modules<tab>#   are likely to share caching more<tab># - split up the rest by class name because slow tests tend to be in<tab>#   the same module<tab>if class_name and "".tasks."" not in module_name:<tab><tab>return ""{}.{}"".format(module_name, class_name)<tab>else:<tab><tab>return module_name",1,"elif isinstance ( parent , pytest . Module ) :","elif isinstance ( parent , pytest . Module ) :",0.75,100.00000000000004,1.0
"def run(self):<tab>versions = versioneer.get_versions()<tab>tempdir = tempfile.mkdtemp()<tab>generated = os.path.join(tempdir, ""rundemo"")<tab>with open(generated, ""wb"") as f:<tab><tab>for line in open(""src/rundemo-template"", ""rb""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.write((""versions = %r\n"" % (versions,)).encode(""ascii""))<tab><tab><tab>else:<tab><tab><tab><tab>f.write(line)<tab>self.scripts = [generated]<tab>rc = build_scripts.run(self)<tab>os.unlink(generated)<tab>os.rmdir(tempdir)<tab>return rc",0,"if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :","if line == """" :",0.015612968593192996,5.609385563366755,0.5818181818181818
"def get_user_context(request, escape=False):<tab>if isinstance(request, HttpRequest):<tab><tab>user = getattr(request, ""user"", None)<tab><tab>result = {""ip_address"": request.META[""REMOTE_ADDR""]}<tab><tab><IF-STMT><tab><tab><tab>result.update(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""email"": user.email,<tab><tab><tab><tab><tab>""id"": user.id,<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><tab>if user.name:<tab><tab><tab><tab>result[""name""] = user.name<tab>else:<tab><tab>result = {}<tab>return mark_safe(json.dumps(result))",0,if user and user . is_authenticated ( ) :,if user and escape :,0.13811276127717953,12.869637315183779,0.7333333333333333
"def tokens_to_spans() -> Iterable[Tuple[str, Optional[Style]]]:<tab>""""""Convert tokens to spans.""""""<tab>tokens = iter(line_tokenize())<tab>line_no = 0<tab>_line_start = line_start - 1<tab># Skip over tokens until line start<tab>while line_no < _line_start:<tab><tab>_token_type, token = next(tokens)<tab><tab>yield (token, None)<tab><tab><IF-STMT><tab><tab><tab>line_no += 1<tab># Generate spans until line end<tab>for token_type, token in tokens:<tab><tab>yield (token, _get_theme_style(token_type))<tab><tab>if token.endswith(""\n""):<tab><tab><tab>line_no += 1<tab><tab><tab>if line_no >= line_end:<tab><tab><tab><tab>break",1,"if token . endswith ( ""\n"" ) :","if token . endswith ( ""\n"" ) :",0.75,100.00000000000004,1.0
"def encode(self, encodeFun, value, defMode, maxChunkSize):<tab>substrate, isConstructed = self.encodeValue(encodeFun, value, defMode, maxChunkSize)<tab>tagSet = value.getTagSet()<tab>if tagSet:<tab><tab><IF-STMT>  # primitive form implies definite mode<tab><tab><tab>defMode = 1<tab><tab>return (<tab><tab><tab>self.encodeTag(tagSet[-1], isConstructed)<tab><tab><tab>+ self.encodeLength(len(substrate), defMode)<tab><tab><tab>+ substrate<tab><tab><tab>+ self._encodeEndOfOctets(encodeFun, defMode)<tab><tab>)<tab>else:<tab><tab>return substrate  # untagged value",0,if not isConstructed :,if defMode == - 1 :,0.03857157587869719,7.809849842300637,0.3333333333333333
def _run(self):<tab>while True:<tab><tab>request = self._requests.get()<tab><tab><IF-STMT><tab><tab><tab>self.shutdown()<tab><tab><tab>break<tab><tab>self.process(request)<tab><tab>self._requests.task_done(),1,if request is None :,if request is None :,0.75,100.00000000000004,1.0
"def _decode_payload(self, payload):<tab># we need to decrypt it<tab>if payload[""enc""] == ""aes"":<tab><tab>try:<tab><tab><tab>payload[""load""] = self.crypticle.loads(payload[""load""])<tab><tab>except salt.crypt.AuthenticationError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>payload[""load""] = self.crypticle.loads(payload[""load""])<tab>return payload",0,if not self . _update_aes ( ) :,"if payload [ ""enc"" ] != ""aes"" :",0.018078277067547346,4.065425428798724,0.38181818181818183
"def test_row(self, row):<tab>for idx, test in self.patterns.items():<tab><tab>try:<tab><tab><tab>value = row[idx]<tab><tab>except IndexError:<tab><tab><tab>value = """"<tab><tab>result = test(value)<tab><tab>if self.any_match:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return not self.inverse  # True<tab><tab>else:<tab><tab><tab>if not result:<tab><tab><tab><tab>return self.inverse  # False<tab>if self.any_match:<tab><tab>return self.inverse  # False<tab>else:<tab><tab>return not self.inverse  # True",1,if result :,if result :,0.5311706625951745,1e-10,1.0
"def setup_parameter_node(self, param_node):<tab>if param_node.bl_idname == ""SvNumberNode"":<tab><tab>if self.use_prop or self.get_prop_name():<tab><tab><tab>value = self.sv_get()[0][0]<tab><tab><tab>print(""V"", value)<tab><tab><tab>if isinstance(value, int):<tab><tab><tab><tab>param_node.selected_mode = ""int""<tab><tab><tab><tab>param_node.int_ = value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>param_node.selected_mode = ""float""<tab><tab><tab><tab>param_node.float_ = value",1,"elif isinstance ( value , float ) :","elif isinstance ( value , float ) :",0.75,100.00000000000004,1.0
"def iter_modules(self, by_clients=False, clients_filter=None):<tab>""""""iterate over all modules""""""<tab>clients = None<tab>if by_clients:<tab><tab>clients = self.get_clients(clients_filter)<tab><tab>if not clients:<tab><tab><tab>return<tab>self._refresh_modules()<tab>for module_name in self.modules:<tab><tab>try:<tab><tab><tab>module = self.get_module(module_name)<tab><tab>except PupyModuleDisabled:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>for client in clients:<tab><tab><tab><tab>if module.is_compatible_with(client):<tab><tab><tab><tab><tab>yield module<tab><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield module",0,if clients is not None :,if clients :,0.050438393472541504,1e-10,0.39999999999999997
"def filter_pricing_rule_based_on_condition(pricing_rules, doc=None):<tab>filtered_pricing_rules = []<tab>if doc:<tab><tab>for pricing_rule in pricing_rules:<tab><tab><tab>if pricing_rule.condition:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>filtered_pricing_rules.append(pricing_rule)<tab>else:<tab><tab>filtered_pricing_rules = pricing_rules<tab>return filtered_pricing_rules",0,"if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :",if doc . condition in pricing_rule . conditions :,0.01934272834681839,10.014337343721003,0.375
"def build_query_string(kv_data, ignore_none=True):<tab># {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test""<tab>query_string = """"<tab>for k, v in kv_data.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if query_string != """":<tab><tab><tab>query_string += ""&""<tab><tab>else:<tab><tab><tab>query_string = ""?""<tab><tab>query_string += k + ""="" + str(v)<tab>return query_string",0,if ignore_none is True and kv_data [ k ] is None :,"if ignore_none and k in ( ""a"" , ""b"" ) :",0.16650529201750314,16.467029855845905,0.22115384615384615
"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = {}<tab>ret.update(self.data)<tab>kwspaces = self.kwspaces<tab>kwspaces.update(config)<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for k, v in kwspaces.items():<tab><tab>if k in striped_keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub_config = _strip_config_space(config, prefix=k)<tab><tab><tab><tab>ret[k] = v.sample(**sub_config)<tab><tab><tab>else:<tab><tab><tab><tab>ret[k] = v<tab>return ret",0,"if isinstance ( v , NestedSpace ) :","if hasattr ( v , ""sample"" ) :",0.09166808520089226,20.556680845025987,0.48148148148148145
"def task_failed(self, task_id, hostname, reason):<tab>logger.debug(""task %d failed with message %s"", task_id, str(reason))<tab>if hostname in self.host_dict:<tab><tab>host_status = self.host_dict[hostname]<tab><tab>host_status.task_failed(task_id)<tab><tab><IF-STMT><tab><tab><tab>self.task_host_failed_dict[task_id] = set()<tab><tab>self.task_host_failed_dict[task_id].add(hostname)",1,if task_id not in self . task_host_failed_dict :,if task_id not in self . task_host_failed_dict :,0.75,100.00000000000004,1.0
"def match(path):<tab>for pat, _type, _property, default_title in patterns:<tab><tab>m = web.re_compile(""^"" + pat).match(path)<tab><tab><IF-STMT><tab><tab><tab>prefix = m.group()<tab><tab><tab>extra = web.lstrips(path, prefix)<tab><tab><tab>tokens = extra.split(""/"", 2)<tab><tab><tab># `extra` starts with ""/"". So first token is always empty.<tab><tab><tab>middle = web.listget(tokens, 1, """")<tab><tab><tab>suffix = web.listget(tokens, 2, """")<tab><tab><tab>if suffix:<tab><tab><tab><tab>suffix = ""/"" + suffix<tab><tab><tab>return _type, _property, default_title, prefix, middle, suffix<tab>return None, None, None, None, None, None",1,if m :,if m :,0.5311706625951745,1e-10,1.0
"def _get_cached_resources(self, ids):<tab>key = self.get_cache_key(None)<tab>if self._cache.load():<tab><tab>resources = self._cache.get(key)<tab><tab><IF-STMT><tab><tab><tab>self.log.debug(""Using cached results for get_resources"")<tab><tab><tab>m = self.get_model()<tab><tab><tab>id_set = set(ids)<tab><tab><tab>return [r for r in resources if r[m.id] in id_set]<tab>return None",1,if resources is not None :,if resources is not None :,0.75,100.00000000000004,1.0
"def has_api_behaviour(self, protocol):<tab>config = get_config()<tab>try:<tab><tab>r = self.session.get(<tab><tab><tab>f""{protocol}://{self.event.host}:{self.event.port}"",<tab><tab><tab>timeout=config.network_timeout,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>except requests.exceptions.SSLError:<tab><tab>logger.debug(<tab><tab><tab>f""{[protocol]} protocol not accepted on {self.event.host}:{self.event.port}""<tab><tab>)<tab>except Exception:<tab><tab>logger.debug(<tab><tab><tab>f""Failed probing {self.event.host}:{self.event.port}"", exc_info=True<tab><tab>)",0,"if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :",if r . status_code == 200 :,0.1015790161981785,5.330714786499167,0.21875
"def get_file_type(self, context, parent_context=None):<tab>file_type = context.get(self.file_type_name, None)<tab>if file_type == """":<tab><tab><IF-STMT><tab><tab><tab>file_type = parent_context.get(self.file_type_name, self.default_file_type)<tab><tab>else:<tab><tab><tab>file_type = self.default_file_type<tab>return file_type",1,if parent_context :,if parent_context :,0.5311706625951745,1e-10,1.0
"def selectionToChunks(self, remove=False, add=False):<tab>box = self.selectionBox()<tab>if box:<tab><tab>if box == self.level.bounds:<tab><tab><tab>self.selectedChunks = set(self.level.allChunks)<tab><tab><tab>return<tab><tab>selectedChunks = self.selectedChunks<tab><tab>boxedChunks = set(box.chunkPositions)<tab><tab><IF-STMT><tab><tab><tab>remove = True<tab><tab>if remove and not add:<tab><tab><tab>selectedChunks.difference_update(boxedChunks)<tab><tab>else:<tab><tab><tab>selectedChunks.update(boxedChunks)<tab>self.selectionTool.selectNone()",0,if boxedChunks . issubset ( selectedChunks ) :,if remove and not add :,0.018517117658868813,6.916271812933183,0.20634920634920637
"def _run_split_on_punc(self, text, never_split=None):<tab>""""""Splits punctuation on a piece of text.""""""<tab>if never_split is not None and text in never_split:<tab><tab>return [text]<tab>chars = list(text)<tab>i = 0<tab>start_new_word = True<tab>output = []<tab>while i < len(chars):<tab><tab>char = chars[i]<tab><tab><IF-STMT><tab><tab><tab>output.append([char])<tab><tab><tab>start_new_word = True<tab><tab>else:<tab><tab><tab>if start_new_word:<tab><tab><tab><tab>output.append([])<tab><tab><tab>start_new_word = False<tab><tab><tab>output[-1].append(char)<tab><tab>i += 1<tab>return ["""".join(x) for x in output]",1,if _is_punctuation ( char ) :,if _is_punctuation ( char ) :,0.75,100.00000000000004,1.0
"def _save_images(notebook):<tab>if os.getenv(""NB_NO_IMAGES"") == ""1"":<tab><tab>return<tab>logged = False<tab>for filename, img_bytes in _iter_notebook_images(notebook):<tab><tab><IF-STMT><tab><tab><tab>log.info(""Saving images"")<tab><tab><tab>logged = True<tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab>f.write(img_bytes)",1,if not logged :,if not logged :,0.75,100.00000000000004,1.0
"def pickPath(self, color):<tab>self.path[color] = ()<tab>currentPos = self.starts[color]<tab>while True:<tab><tab>minDist = None<tab><tab>minGuide = None<tab><tab>for guide in self.guides[color]:<tab><tab><tab>guideDist = dist(currentPos, guide)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>minDist = guideDist<tab><tab><tab><tab>minGuide = guide<tab><tab>if dist(currentPos, self.ends[color]) == 1:<tab><tab><tab>return<tab><tab>if minGuide == None:<tab><tab><tab>return<tab><tab>self.path[color] = self.path[color] + (minGuide,)<tab><tab>currentPos = minGuide<tab><tab>self.guides[color].remove(minGuide)",0,if minDist == None or guideDist < minDist :,if minDist is None or guideDist < minDist :,0.3318820875411705,59.11602603314155,0.32857142857142857
"def _terminal_messenger(tp=""write"", msg="""", out=sys.stdout):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>out.write(msg)<tab><tab>elif tp == ""flush"":<tab><tab><tab>out.flush()<tab><tab>elif tp == ""write_flush"":<tab><tab><tab>out.write(msg)<tab><tab><tab>out.flush()<tab><tab>elif tp == ""print"":<tab><tab><tab>print(msg, file=out)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported type: "" + tp)<tab>except IOError as e:<tab><tab>logger.critical(""{}: {}"".format(type(e).__name__, ucd(e)))<tab><tab>pass",1,"if tp == ""write"" :","if tp == ""write"" :",0.75,100.00000000000004,1.0
"def __new__(mcs, name, bases, attrs):<tab>include_profile = include_trace = include_garbage = True<tab>bases = list(bases)<tab>if name == ""SaltLoggingClass"":<tab><tab>for base in bases:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>include_trace = False<tab><tab><tab>if hasattr(base, ""garbage""):<tab><tab><tab><tab>include_garbage = False<tab>if include_profile:<tab><tab>bases.append(LoggingProfileMixin)<tab>if include_trace:<tab><tab>bases.append(LoggingTraceMixin)<tab>if include_garbage:<tab><tab>bases.append(LoggingGarbageMixin)<tab>return super(LoggingMixinMeta, mcs).__new__(mcs, name, tuple(bases), attrs)",1,"if hasattr ( base , ""trace"" ) :","if hasattr ( base , ""trace"" ) :",0.75,100.00000000000004,1.0
"def generatePidEncryptionTable():<tab>table = []<tab>for counter1 in range(0, 0x100):<tab><tab>value = counter1<tab><tab>for counter2 in range(0, 8):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value >> 1<tab><tab><tab>else:<tab><tab><tab><tab>value = value >> 1<tab><tab><tab><tab>value = value ^ 0xEDB88320<tab><tab>table.append(value)<tab>return table",0,if value & 1 == 0 :,if counter1 == 0 and counter2 == 0 :,0.07853087956397244,24.808415001701817,0.21875
"def pytest_collection_modifyitems(items):<tab>for item in items:<tab><tab>if item.nodeid.startswith(""tests/params""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item.add_marker(pytest.mark.stage(""unit""))<tab><tab><tab>if ""init"" not in item.keywords:<tab><tab><tab><tab>item.add_marker(pytest.mark.init(rng_seed=123))",1,"if ""stage"" not in item . keywords :","if ""stage"" not in item . keywords :",0.75,100.00000000000004,1.0
"def python_value(self, value):<tab>if value:<tab><tab>if isinstance(value, basestring):<tab><tab><tab>pp = lambda x: x.time()<tab><tab><tab>return format_date_time(value, self.formats, pp)<tab><tab><IF-STMT><tab><tab><tab>return value.time()<tab>if value is not None and isinstance(value, datetime.timedelta):<tab><tab>return (datetime.datetime.min + value).time()<tab>return value",1,"elif isinstance ( value , datetime . datetime ) :","elif isinstance ( value , datetime . datetime ) :",1.0,100.00000000000004,1.0
"def list_interesting_hosts(self):<tab>hosts = []<tab>targets = self.target[""other""]<tab>for target in targets:<tab><tab><IF-STMT><tab><tab><tab>hosts.append(<tab><tab><tab><tab>{""ip"": target.ip, ""description"": target.domain + "" / "" + target.name}<tab><tab><tab>)<tab>return hosts",0,if self . is_interesting ( target ) and target . status and target . status != 400 :,if target . domain :,0.010190386757789579,1.0356305364183098,0.21195652173913043
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_cost().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.add_version(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",0,if tt == 24 :,if tt == 16 :,0.39477865547525276,53.7284965911771,0.6
"def _wait_for_finish(self) -> PollExitResponse:<tab>while True:<tab><tab>if self._backend:<tab><tab><tab>poll_exit_resp = self._backend.interface.communicate_poll_exit()<tab><tab>logger.info(""got exit ret: %s"", poll_exit_resp)<tab><tab>if poll_exit_resp:<tab><tab><tab>done = poll_exit_resp.done<tab><tab><tab>pusher_stats = poll_exit_resp.pusher_stats<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._on_finish_progress(pusher_stats, done)<tab><tab><tab>if done:<tab><tab><tab><tab>return poll_exit_resp<tab><tab>time.sleep(2)",1,if pusher_stats :,if pusher_stats :,0.5311706625951745,1e-10,1.0
"def listing_items(method):<tab>marker = None<tab>once = True<tab>items = []<tab>while once or items:<tab><tab>for i in items:<tab><tab><tab>yield i<tab><tab>if once or marker:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>items = method(parms={""marker"": marker})<tab><tab><tab>else:<tab><tab><tab><tab>items = method()<tab><tab><tab>if len(items) == 10000:<tab><tab><tab><tab>marker = items[-1]<tab><tab><tab>else:<tab><tab><tab><tab>marker = None<tab><tab><tab>once = False<tab><tab>else:<tab><tab><tab>items = []",0,if marker :,"if hasattr ( method , ""parms"" ) :",0.04422835593777517,1e-10,0.38181818181818183
"def call(monad, *args):<tab>for arg, name in izip(args, (""hour"", ""minute"", ""second"", ""microsecond"")):<tab><tab>if not isinstance(arg, NumericMixin) or arg.type is not int:<tab><tab><tab>throw(<tab><tab><tab><tab>TypeError,<tab><tab><tab><tab>""'%s' argument of time(...) function must be of 'int' type. Got: %r""<tab><tab><tab><tab>% (name, type2str(arg.type)),<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>throw(NotImplementedError)<tab>return ConstMonad.new(time(*tuple(arg.value for arg in args)))",0,"if not isinstance ( arg , ConstMonad ) :","elif not isinstance ( arg , ConstMonad ) :",0.4127127708701796,86.33400213704509,0.7142857142857143
"def group_by_sign(seq, slop=sin(pi / 18), key=lambda x: x):<tab>sign = None<tab>subseq = []<tab>for i in seq:<tab><tab>ki = key(i)<tab><tab>if sign is None:<tab><tab><tab>subseq.append(i)<tab><tab><tab>if ki != 0:<tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab>else:<tab><tab><tab>subseq.append(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sign = ki / abs(ki)<tab><tab><tab><tab>yield subseq<tab><tab><tab><tab>subseq = [i]<tab>if subseq:<tab><tab>yield subseq",0,if sign * ki < - slop :,if sign > slop :,0.0943627239435392,16.58165975077607,0.5777777777777777
"def walk_links(self):<tab>link_info_list = []<tab>for item in self.content:<tab><tab><IF-STMT><tab><tab><tab>link_info = LinkInfo(link=item, name=item.name, sections=())<tab><tab><tab>link_info_list.append(link_info)<tab><tab>else:<tab><tab><tab>link_info_list.extend(item.walk_links())<tab>return link_info_list",0,"if isinstance ( item , Link ) :","if isinstance ( item , Node ) :",0.5490406812970063,59.4603557501361,0.6666666666666666
"def get_subkeys(self, key):<tab># TODO: once we revamp the registry emulation,<tab># make this better<tab>parent_path = key.get_path()<tab>subkeys = []<tab>for k in self.keys:<tab><tab>test_path = k.get_path()<tab><tab>if test_path.lower().startswith(parent_path.lower()):<tab><tab><tab>sub = test_path[len(parent_path) :]<tab><tab><tab>if sub.startswith(""\\""):<tab><tab><tab><tab>sub = sub[1:]<tab><tab><tab>end_slash = sub.find(""\\"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub = sub[:end_slash]<tab><tab><tab>if not sub:<tab><tab><tab><tab>continue<tab><tab><tab>subkeys.append(sub)<tab>return subkeys",0,if end_slash >= 0 :,if end_slash != - 1 :,0.0574290063711522,33.03164318013809,0.5
"def load_dict(dict_path, reverse=False):<tab>word_dict = {}<tab>with open(dict_path, ""rb"") as fdict:<tab><tab>for idx, line in enumerate(fdict):<tab><tab><tab>line = cpt.to_text(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>word_dict[idx] = line.strip(""\n"")<tab><tab><tab>else:<tab><tab><tab><tab>word_dict[line.strip(""\n"")] = idx<tab>return word_dict",1,if reverse :,if reverse :,0.5311706625951745,1e-10,1.0
"def test_network(coords, feats, model, batch_sizes, forward_only=True):<tab>for batch_size in batch_sizes:<tab><tab>bcoords = batched_coordinates([coords for i in range(batch_size)])<tab><tab>bfeats = torch.cat([feats for i in range(batch_size)], 0)<tab><tab><IF-STMT><tab><tab><tab>with torch.no_grad():<tab><tab><tab><tab>time, length = forward(bcoords, bfeats, model)<tab><tab>else:<tab><tab><tab>time, length = train(bcoords, bfeats, model)<tab><tab>print(f""{net.__name__}\t{voxel_size}\t{batch_size}\t{length}\t{time}"")<tab><tab>torch.cuda.empty_cache()",1,if forward_only :,if forward_only :,0.5311706625951745,1e-10,1.0
"def markUVs(self, indices=None):<tab>if isinstance(indices, tuple):<tab><tab>indices = indices[0]<tab>ntexco = len(self.texco)<tab>if indices is None:<tab><tab>self.utexc = True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.utexc = np.zeros(ntexco, dtype=bool)<tab><tab>if self.utexc is not True:<tab><tab><tab>self.utexc[indices] = True",0,if self . utexc is False :,if self . utexc is None :,0.574113272471593,64.34588841607616,0.7142857142857143
"def has_module(self, module, version):<tab>has_module = False<tab>for directory in self.directories:<tab><tab>module_directory = join(directory, module)<tab><tab>has_module_directory = isdir(module_directory)<tab><tab><IF-STMT><tab><tab><tab>has_module = has_module_directory or exists(<tab><tab><tab><tab>module_directory<tab><tab><tab>)  # could be a bare modulefile<tab><tab>else:<tab><tab><tab>modulefile = join(module_directory, version)<tab><tab><tab>has_modulefile = exists(modulefile)<tab><tab><tab>has_module = has_module_directory and has_modulefile<tab><tab>if has_module:<tab><tab><tab>break<tab>return has_module",0,if not version :,if version is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def get_editops(self):<tab>if not self._editops:<tab><tab><IF-STMT><tab><tab><tab>self._editops = editops(self._opcodes, self._str1, self._str2)<tab><tab>else:<tab><tab><tab>self._editops = editops(self._str1, self._str2)<tab>return self._editops",1,if self . _opcodes :,if self . _opcodes :,0.75,100.00000000000004,1.0
"def to_representation(self, data):<tab>value = super(CredentialTypeSerializer, self).to_representation(data)<tab># translate labels and help_text for credential fields ""managed by Tower""<tab>if value.get(""managed_by_tower""):<tab><tab>value[""name""] = _(value[""name""])<tab><tab>for field in value.get(""inputs"", {}).get(""fields"", []):<tab><tab><tab>field[""label""] = _(field[""label""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>field[""help_text""] = _(field[""help_text""])<tab>return value",0,"if ""help_text"" in field :","if field . get ( ""help_text"" ) :",0.029323260600185464,35.65506208559251,0.4
"def sort_nested_dictionary_lists(d):<tab>for k, v in d.items():<tab><tab>if isinstance(v, list):<tab><tab><tab>for i in range(0, len(v)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>v[i] = await sort_nested_dictionary_lists(v[i])<tab><tab><tab><tab>d[k] = sorted(v)<tab><tab>if isinstance(v, dict):<tab><tab><tab>d[k] = await sort_nested_dictionary_lists(v)<tab>return d",1,"if isinstance ( v [ i ] , dict ) :","if isinstance ( v [ i ] , dict ) :",0.75,100.00000000000004,1.0
"def messageSourceStamps(self, source_stamps):<tab>text = """"<tab>for ss in source_stamps:<tab><tab>source = """"<tab><tab>if ss[""branch""]:<tab><tab><tab>source += ""[branch %s] "" % ss[""branch""]<tab><tab>if ss[""revision""]:<tab><tab><tab>source += str(ss[""revision""])<tab><tab>else:<tab><tab><tab>source += ""HEAD""<tab><tab><IF-STMT><tab><tab><tab>source += "" (plus patch)""<tab><tab>discriminator = """"<tab><tab>if ss[""codebase""]:<tab><tab><tab>discriminator = "" '%s'"" % ss[""codebase""]<tab><tab>text += ""Build Source Stamp%s: %s\n"" % (discriminator, source)<tab>return text",0,"if ss [ ""patch"" ] is not None :","if ss [ ""patch"" ] :",0.2916271377681715,59.755798910891144,0.4545454545454546
"def fit_one(self, x):<tab>for i, xi in x.items():<tab><tab><IF-STMT><tab><tab><tab>self.median[i].update(xi)<tab><tab>if self.with_scaling:<tab><tab><tab>self.iqr[i].update(xi)<tab>return self",0,if self . with_centering :,if self . with_median :,0.39477865547525276,64.34588841607616,1.0
"def start_response(self, status, headers, exc_info=None):<tab>if exc_info:<tab><tab>try:<tab><tab><tab>if self.started:<tab><tab><tab><tab>six.reraise(exc_info[0], exc_info[1], exc_info[2])<tab><tab>finally:<tab><tab><tab>exc_info = None<tab>self.request.status = int(status[:3])<tab>for key, val in headers:<tab><tab><IF-STMT><tab><tab><tab>self.request.set_content_length(int(val))<tab><tab>elif key.lower() == ""content-type"":<tab><tab><tab>self.request.content_type = val<tab><tab>else:<tab><tab><tab>self.request.headers_out.add(key, val)<tab>return self.write",1,"if key . lower ( ) == ""content-length"" :","if key . lower ( ) == ""content-length"" :",0.75,100.00000000000004,1.0
"def _osp2ec(self, bytes):<tab>compressed = self._from_bytes(bytes)<tab>y = compressed >> self._bits<tab>x = compressed & (1 << self._bits) - 1<tab>if x == 0:<tab><tab>y = self._curve.b<tab>else:<tab><tab>result = self.sqrtp(<tab><tab><tab>x ** 3 + self._curve.a * x + self._curve.b, self._curve.field.p<tab><tab>)<tab><tab>if len(result) == 1:<tab><tab><tab>y = result[0]<tab><tab><IF-STMT><tab><tab><tab>y1, y2 = result<tab><tab><tab>y = y1 if (y1 & 1 == y) else y2<tab><tab>else:<tab><tab><tab>return None<tab>return ec.Point(self._curve, x, y)",1,elif len ( result ) == 2 :,elif len ( result ) == 2 :,0.75,100.00000000000004,1.0
"def trace(self, ee, rname):<tab>print(type(self))<tab>self.traceIndent()<tab>guess = """"<tab>if self.inputState.guessing > 0:<tab><tab>guess = "" [guessing]""<tab>print((ee + rname + guess))<tab>for i in xrange(1, self.k + 1):<tab><tab>if i != 1:<tab><tab><tab>print("", "")<tab><tab><IF-STMT><tab><tab><tab>v = self.LT(i).getText()<tab><tab>else:<tab><tab><tab>v = ""null""<tab><tab>print(""LA(%s) == %s"" % (i, v))<tab>print(""\n"")",0,if self . LT ( i ) :,"if guess == "" "" :",0.018517117658868813,6.770186228657864,0.3
"def _table_schema(self, table):<tab>rows = self.db.execute_sql(""PRAGMA table_info('%s')"" % table).fetchall()<tab># Build list of fields from table information<tab>result = {}<tab>for _, name, data_type, not_null, _, primary_key in rows:<tab><tab>parts = [data_type]<tab><tab>if primary_key:<tab><tab><tab>parts.append(""PRIMARY KEY"")<tab><tab><IF-STMT><tab><tab><tab>parts.append(""NOT NULL"")<tab><tab>result[name] = "" "".join(parts)<tab>return result",1,if not_null :,if not_null :,0.5311706625951745,1e-10,1.0
"def _parse_csrf(self, response):<tab>for d in response:<tab><tab>if d.startswith(""Set-Cookie:""):<tab><tab><tab>for c in d.split("":"", 1)[1].split("";""):<tab><tab><tab><tab>if c.strip().startswith(""CSRF-Token-""):<tab><tab><tab><tab><tab>self._CSRFtoken = c.strip("" \r\n"")<tab><tab><tab><tab><tab>log.verbose(""Got new cookie: %s"", self._CSRFtoken)<tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break",0,if self . _CSRFtoken != None :,if not self . _CSRFtoken :,0.09662402516463689,34.191776499651844,0.4
"def _update_from_item(self, row, download_item):<tab>progress_stats = download_item.progress_stats<tab>for key in self.columns:<tab><tab>column = self.columns[key][0]<tab><tab><IF-STMT><tab><tab><tab># Not the best place but we build the playlist status here<tab><tab><tab>status = ""{0} {1}/{2}"".format(<tab><tab><tab><tab>progress_stats[""status""],<tab><tab><tab><tab>progress_stats[""playlist_index""],<tab><tab><tab><tab>progress_stats[""playlist_size""],<tab><tab><tab>)<tab><tab><tab>self.SetStringItem(row, column, status)<tab><tab>else:<tab><tab><tab>self.SetStringItem(row, column, progress_stats[key])",0,"if key == ""status"" and progress_stats [ ""playlist_index"" ] :","if ""status"" in progress_stats :",0.015145994590617124,10.558266591288652,0.38666666666666666
"def unmarshal_package_repositories(cls, data: Any) -> List[""PackageRepository""]:<tab>repositories = list()<tab>if data is not None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(f""invalid package-repositories: {data!r}"")<tab><tab>for repository in data:<tab><tab><tab>package_repo = cls.unmarshal(repository)<tab><tab><tab>repositories.append(package_repo)<tab>return repositories",1,"if not isinstance ( data , list ) :","if not isinstance ( data , list ) :",0.75,100.00000000000004,1.0
"def remove_message(e=None):<tab>itop = scanbox.nearest(0)<tab>sel = scanbox.curselection()<tab>if not sel:<tab><tab>dialog(<tab><tab><tab>root,<tab><tab><tab>""No Message To Remove"",<tab><tab><tab>""Please select a message to remove"",<tab><tab><tab>"""",<tab><tab><tab>0,<tab><tab><tab>""OK"",<tab><tab>)<tab><tab>return<tab>todo = []<tab>for i in sel:<tab><tab>line = scanbox.get(i)<tab><tab><IF-STMT><tab><tab><tab>todo.append(string.atoi(scanparser.group(1)))<tab>mhf.removemessages(todo)<tab>rescan()<tab>fixfocus(min(todo), itop)",0,if scanparser . match ( line ) >= 0 :,if scanparser . group ( 1 ) in line :,0.06549535136140201,17.467768504457784,0.32098765432098764
"def test_patches():<tab>print(<tab><tab>""Botocore version: {} aiohttp version: {}"".format(<tab><tab><tab>botocore.__version__, aiohttp.__version__<tab><tab>)<tab>)<tab>success = True<tab>for obj, digests in chain(_AIOHTTP_DIGESTS.items(), _API_DIGESTS.items()):<tab><tab>digest = hashlib.sha1(getsource(obj).encode(""utf-8"")).hexdigest()<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""Digest of {}:{} not found in: {}"".format(<tab><tab><tab><tab><tab>obj.__qualname__, digest, digests<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>success = False<tab>assert success",1,if digest not in digests :,if digest not in digests :,0.75,100.00000000000004,1.0
"def sample_admin_user():<tab>""""""List of iris messages""""""<tab>with iris_ctl.db_from_config(sample_db_config) as (conn, cursor):<tab><tab>cursor.execute(<tab><tab><tab>""SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1""<tab><tab>)<tab><tab>result = cursor.fetchone()<tab><tab><IF-STMT><tab><tab><tab>return result[0]",1,if result :,if result :,0.5311706625951745,1e-10,1.0
"def _addRightnames(groups, kerning, leftname, rightnames, includeAll=True):<tab>if leftname in kerning:<tab><tab>for rightname in kerning[leftname]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for rightname2 in groups[rightname]:<tab><tab><tab><tab><tab>rightnames.add(rightname2)<tab><tab><tab><tab><tab>if not includeAll:<tab><tab><tab><tab><tab><tab># TODO: in this case, pick the one rightname that has the highest<tab><tab><tab><tab><tab><tab># ranking in glyphorder<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>rightnames.add(rightname)",0,"if rightname [ 0 ] == ""@"" :",if rightname in groups :,0.0354018406734773,7.121297464907233,0.48148148148148145
"def build(self, input_shape):<tab>if isinstance(input_shape, list) and len(input_shape) == 2:<tab><tab>self.data_mode = ""disjoint""<tab><tab>self.F = input_shape[0][-1]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.data_mode = ""single""<tab><tab>else:<tab><tab><tab>self.data_mode = ""batch""<tab><tab>self.F = input_shape[-1]",0,if len ( input_shape ) == 2 :,if len ( input_shape ) == 1 :,0.605621305873661,80.70557274927978,0.6
"def update_ranges(l, i):<tab>for _range in l:<tab><tab># most common case: extend a range<tab><tab><IF-STMT><tab><tab><tab>_range[0] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab><tab>elif i == _range[1] + 1:<tab><tab><tab>_range[1] = i<tab><tab><tab>merge_ranges(l)<tab><tab><tab>return<tab># somewhere outside of range proximity<tab>l.append([i, i])<tab>l.sort(key=lambda x: x[0])",0,if i == _range [ 0 ] - 1 :,if i == _range [ 0 ] + 1 :,0.6049399806880458,76.91605673134588,1.0
"def transform(a, cmds):<tab>buf = a.split(""\n"")<tab>for cmd in cmds:<tab><tab>ctype, line, col, char = cmd<tab><tab><IF-STMT><tab><tab><tab>if char != ""\n"":<tab><tab><tab><tab>buf[line] = buf[line][:col] + buf[line][col + len(char) :]<tab><tab><tab>else:<tab><tab><tab><tab>buf[line] = buf[line] + buf[line + 1]<tab><tab><tab><tab>del buf[line + 1]<tab><tab>elif ctype == ""I"":<tab><tab><tab>buf[line] = buf[line][:col] + char + buf[line][col:]<tab><tab>buf = ""\n"".join(buf).split(""\n"")<tab>return ""\n"".join(buf)",0,"if ctype == ""D"" :","if ctype == ""S"" :",0.39477865547525276,59.4603557501361,1.0
"def _media_files_drag_received(widget, context, x, y, data, info, timestamp):<tab>uris = data.get_uris()<tab>files = []<tab>for uri in uris:<tab><tab>try:<tab><tab><tab>uri_tuple = GLib.filename_from_uri(uri)<tab><tab>except:<tab><tab><tab>continue<tab><tab>uri, unused = uri_tuple<tab><tab>if os.path.exists(uri) == True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>files.append(uri)<tab>if len(files) == 0:<tab><tab>return<tab>open_dropped_files(files)",0,if utils . is_media_file ( uri ) == True :,if os . path . isfile ( uri ) :,0.11349300833942895,11.266342182414927,0.23863636363636365
"def __walk_proceed_remote_dir_act(self, r, args):<tab>dirjs, filejs = args<tab>j = r.json()<tab>if ""list"" not in j:<tab><tab>self.pd(<tab><tab><tab>""Key 'list' not found in the response of directory listing request:\n{}"".format(<tab><tab><tab><tab>j<tab><tab><tab>)<tab><tab>)<tab><tab>return const.ERequestFailed<tab>paths = j[""list""]<tab>for path in paths:<tab><tab><IF-STMT><tab><tab><tab>dirjs.append(path)<tab><tab>else:<tab><tab><tab>filejs.append(path)<tab>return const.ENoError",0,"if path [ ""isdir"" ] :",if os . path . isdir ( path ) :,0.021554938761049226,5.934202609760488,0.3538461538461538
"def TaskUpdatesVerbose(task, progress):<tab>if isinstance(task.info.progress, int):<tab><tab>info = task.info<tab><tab><IF-STMT><tab><tab><tab>progress = ""%d%% (%s)"" % (info.progress, info.state)<tab><tab>print(<tab><tab><tab>""Task %s (key:%s, desc:%s) - %s""<tab><tab><tab>% (info.name.info.name, info.key, info.description, progress)<tab><tab>)",0,"if not isinstance ( progress , str ) :",if info . state != RUNNING :,0.015938469653148324,5.795599612995366,0.20987654320987653
"def dump_constants(header):<tab>output = StringIO.StringIO()<tab>output.write(header)<tab>for attribute in dir(FSEvents):<tab><tab>value = getattr(FSEvents, attribute)<tab><tab><IF-STMT><tab><tab><tab>output.write(""<tab>%s = %s\n"" % (attribute, hex(value)))<tab>content = output.getvalue()<tab>output.close()<tab>return content",0,"if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :","if attribute . startswith ( ""constants_"" ) :",0.23314123809135226,32.21523132984207,0.475
"def _ensure_data_is_loaded(<tab>self,<tab>sql_object,<tab>input_params,<tab>stdin_file,<tab>stdin_filename=""-"",<tab>stop_after_analysis=False,):<tab>data_loads = []<tab># Get each ""table name"" which is actually the file name<tab>for filename in sql_object.qtable_names:<tab><tab>data_load = self._load_data(<tab><tab><tab>filename,<tab><tab><tab>input_params,<tab><tab><tab>stdin_file=stdin_file,<tab><tab><tab>stdin_filename=stdin_filename,<tab><tab><tab>stop_after_analysis=stop_after_analysis,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>data_loads.append(data_load)<tab>return data_loads",1,if data_load is not None :,if data_load is not None :,0.75,100.00000000000004,1.0
"def _get_instantiation(self):<tab>if self._data is None:<tab><tab>f, l, c, o = c_object_p(), c_uint(), c_uint(), c_uint()<tab><tab>SourceLocation_loc(self, byref(f), byref(l), byref(c), byref(o))<tab><tab><IF-STMT><tab><tab><tab>f = File(f)<tab><tab>else:<tab><tab><tab>f = None<tab><tab>self._data = (f, int(l.value), int(c.value), int(c.value))<tab>return self._data",0,if f :,if f . fileno ( ) == 2 :,0.08050925452257668,1e-10,0.5666666666666667
"def _get_all_info_lines(data):<tab>infos = []<tab>for row in data:<tab><tab>splitrow = row.split()<tab><tab><IF-STMT><tab><tab><tab>if splitrow[0] == ""INFO:"":<tab><tab><tab><tab>infos.append("" "".join(splitrow[1:]))<tab>return infos",0,if len ( splitrow ) > 0 :,if len ( splitrow ) > 1 :,0.605621305873661,70.71067811865478,0.6666666666666666
"def _brush_modified_cb(self, settings):<tab>""""""Updates the brush's base setting adjustments on brush changes""""""<tab>for cname in settings:<tab><tab>adj = self.brush_adjustment.get(cname, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = self.brush.get_base_value(cname)<tab><tab>adj.set_value(value)",1,if adj is None :,if adj is None :,0.75,100.00000000000004,1.0
"def migrate_node_facts(facts):<tab>""""""Migrate facts from various roles into node""""""<tab>params = {<tab><tab>""common"": (""dns_ip""),<tab>}<tab>if ""node"" not in facts:<tab><tab>facts[""node""] = {}<tab># pylint: disable=consider-iterating-dictionary<tab>for role in params.keys():<tab><tab>if role in facts:<tab><tab><tab>for param in params[role]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>facts[""node""][param] = facts[role].pop(param)<tab>return facts",1,if param in facts [ role ] :,if param in facts [ role ] :,0.75,100.00000000000004,1.0
"def serialize_content_range(value):<tab>if isinstance(value, (tuple, list)):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""When setting content_range to a list/tuple, it must ""<tab><tab><tab><tab>""be length 2 or 3 (not %r)"" % value<tab><tab><tab>)<tab><tab>if len(value) == 2:<tab><tab><tab>begin, end = value<tab><tab><tab>length = None<tab><tab>else:<tab><tab><tab>begin, end, length = value<tab><tab>value = ContentRange(begin, end, length)<tab>value = str(value).strip()<tab>if not value:<tab><tab>return None<tab>return value",0,"if len ( value ) not in ( 2 , 3 ) :",if len ( value ) != 3 :,0.24091838787172487,31.128780276284857,0.475
"def clean(self):<tab>data = super().clean()<tab>if data.get(""expires""):<tab><tab><IF-STMT><tab><tab><tab>data[""expires""] = make_aware(<tab><tab><tab><tab>datetime.combine(data[""expires""], time(hour=23, minute=59, second=59)),<tab><tab><tab><tab>self.instance.event.timezone,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>data[""expires""] = data[""expires""].replace(hour=23, minute=59, second=59)<tab><tab>if data[""expires""] < now():<tab><tab><tab>raise ValidationError(_(""The new expiry date needs to be in the future.""))<tab>return data",0,"if isinstance ( data [ ""expires"" ] , date ) :",if self . instance . event :,0.012371040955614452,3.3142882018868,0.25
"def _build(self, obj, stream, context):<tab>if self.include_name:<tab><tab>name, obj = obj<tab><tab>for sc in self.subcons:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sc._build(obj, stream, context)<tab><tab><tab><tab>return<tab>else:<tab><tab>for sc in self.subcons:<tab><tab><tab>stream2 = BytesIO()<tab><tab><tab>context2 = context.__copy__()<tab><tab><tab>try:<tab><tab><tab><tab>sc._build(obj, stream2, context2)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>context.__update__(context2)<tab><tab><tab><tab>stream.write(stream2.getvalue())<tab><tab><tab><tab>return<tab>raise SelectError(""no subconstruct matched"", obj)",1,if sc . name == name :,if sc . name == name :,1.0,100.00000000000004,1.0
"def records(account_id):<tab>""""""Fetch locks data""""""<tab>s = boto3.Session()<tab>table = s.resource(""dynamodb"").Table(""Sphere11.Dev.ResourceLocks"")<tab>results = table.scan()<tab>for r in results[""Items""]:<tab><tab><IF-STMT><tab><tab><tab>r[""LockDate""] = datetime.fromtimestamp(r[""LockDate""])<tab><tab>if ""RevisionDate"" in r:<tab><tab><tab>r[""RevisionDate""] = datetime.fromtimestamp(r[""RevisionDate""])<tab>print(tabulate.tabulate(results[""Items""], headers=""keys"", tablefmt=""fancy_grid""))",1,"if ""LockDate"" in r :","if ""LockDate"" in r :",0.75,100.00000000000004,1.0
"def visitIf(self, node, scope):<tab>for test, body in node.tests:<tab><tab>if isinstance(test, ast.Const):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not test.value:<tab><tab><tab><tab><tab>continue<tab><tab>self.visit(test, scope)<tab><tab>self.visit(body, scope)<tab>if node.else_:<tab><tab>self.visit(node.else_, scope)",0,if type ( test . value ) in self . _const_types :,"if isinstance ( test , ast . If ) :",0.06622107037062638,6.699007141691558,0.28774928774928776
"def validate_max_discount(self):<tab>if self.rate_or_discount == ""Discount Percentage"" and self.get(""items""):<tab><tab>for d in self.items:<tab><tab><tab>max_discount = frappe.get_cached_value(""Item"", d.item_code, ""max_discount"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>throw(<tab><tab><tab><tab><tab>_(""Max discount allowed for item: {0} is {1}%"").format(<tab><tab><tab><tab><tab><tab>self.item_code, max_discount<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",0,if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,if max_discount :,0.010227354392330742,1e-10,0.3666666666666667
"def has_invalid_cce(yaml_file, product_yaml=None):<tab>rule = yaml.open_and_macro_expand(yaml_file, product_yaml)<tab>if ""identifiers"" in rule and rule[""identifiers""] is not None:<tab><tab>for i_type, i_value in rule[""identifiers""].items():<tab><tab><tab>if i_type[0:3] == ""cce"":<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>return False",0,"if not checks . is_cce_value_valid ( ""CCE-"" + str ( i_value ) ) :","if i_value [ 0 : 3 ] == ""invalid"" :",0.010109386587757587,6.6353196221239354,0.2789115646258503
"def parse_calendar_eras(data, calendar):<tab>eras = data.setdefault(""eras"", {})<tab>for width in calendar.findall(""eras/*""):<tab><tab>width_type = NAME_MAP[width.tag]<tab><tab>widths = eras.setdefault(width_type, {})<tab><tab>for elem in width.getiterator():<tab><tab><tab>if elem.tag == ""era"":<tab><tab><tab><tab>_import_type_text(widths, elem, type=int(elem.attrib.get(""type"")))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>eras[width_type] = Alias(<tab><tab><tab><tab><tab>_translate_alias([""eras"", width_type], elem.attrib[""path""])<tab><tab><tab><tab>)",0,"elif elem . tag == ""alias"" :","elif elem . tag == ""width"" :",0.8217294420803809,70.71067811865478,1.0
"def validate_grammar() -> None:<tab>for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE:<tab><tab>fn_productions = get_productions(fn)<tab><tab>if all(p.name == fn_productions[0].name for p in fn_productions):<tab><tab><tab># all the production names are the same, ensure that the `convert_` function<tab><tab><tab># is named correctly<tab><tab><tab>production_name = fn_productions[0].name<tab><tab><tab>expected_name = f""convert_{production_name}""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>f""The conversion function for '{production_name}' ""<tab><tab><tab><tab><tab>+ f""must be called '{expected_name}', not '{fn.__name__}'.""<tab><tab><tab><tab>)",0,if fn . __name__ != expected_name :,if expected_name != production_name :,0.02513753479548833,20.60524114942286,0.6363636363636364
"def split_ratio(row):<tab>if float(row[""Numerator""]) > 0:<tab><tab><IF-STMT><tab><tab><tab>n, m = row[""Splitratio""].split("":"")<tab><tab><tab>return float(m) / float(n)<tab><tab>else:<tab><tab><tab>return eval(row[""Splitratio""])<tab>else:<tab><tab>return 1",0,"if "":"" in row [ ""Splitratio"" ] :","if ""Splitratio"" in row :",0.038928836358151336,22.117541221307572,1.0
"def _handle_def_errors(testdef):<tab># If the test generation had an error, raise<tab>if testdef.error:<tab><tab>if testdef.exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise testdef.exception<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(testdef.exception)<tab><tab>else:<tab><tab><tab>raise Exception(""Test parse failure"")",0,"if isinstance ( testdef . exception , Exception ) :","if isinstance ( testdef . exception , str ) :",0.6049399806880458,70.71067811865478,0.7777777777777777
"def _get_quota_availability(self):<tab>quotas_ok = defaultdict(int)<tab>qa = QuotaAvailability()<tab>qa.queue(*[k for k, v in self._quota_diff.items() if v > 0])<tab>qa.compute(now_dt=self.now_dt)<tab>for quota, count in self._quota_diff.items():<tab><tab>if count <= 0:<tab><tab><tab>quotas_ok[quota] = 0<tab><tab><tab>break<tab><tab>avail = qa.results[quota]<tab><tab><IF-STMT><tab><tab><tab>quotas_ok[quota] = min(count, avail[1])<tab><tab>else:<tab><tab><tab>quotas_ok[quota] = count<tab>return quotas_ok",0,if avail [ 1 ] is not None and avail [ 1 ] < count :,if avail [ 0 ] :,0.10478376286545588,6.483996016841,0.22982456140350876
"def reverse(self):<tab>""""""Reverse *IN PLACE*.""""""<tab>li = self.leftindex<tab>lb = self.leftblock<tab>ri = self.rightindex<tab>rb = self.rightblock<tab>for i in range(self.len >> 1):<tab><tab>lb.data[li], rb.data[ri] = rb.data[ri], lb.data[li]<tab><tab>li += 1<tab><tab><IF-STMT><tab><tab><tab>lb = lb.rightlink<tab><tab><tab>li = 0<tab><tab>ri -= 1<tab><tab>if ri < 0:<tab><tab><tab>rb = rb.leftlink<tab><tab><tab>ri = BLOCKLEN - 1",0,if li >= BLOCKLEN :,if li > BLOCKLEN - 1 :,0.13878247493843046,27.77619034011791,0.7714285714285715
"def __manipulate_item(self, item):<tab>if self._Cursor__manipulate:<tab><tab>db = self._Cursor__collection.database<tab><tab>son = db._fix_outgoing(item, self._Cursor__collection)<tab>else:<tab><tab>son = item<tab>if self.__wrap is not None:<tab><tab><IF-STMT><tab><tab><tab>return getattr(self._Cursor__collection, son[self.__wrap.type_field])(son)<tab><tab>return self.__wrap(son, collection=self._Cursor__collection)<tab>else:<tab><tab>return son",1,if self . __wrap . type_field in son :,if self . __wrap . type_field in son :,0.75,100.00000000000004,1.0
"def apply_transforms(self):<tab>""""""Apply all of the stored transforms, in priority order.""""""<tab>self.document.reporter.attach_observer(self.document.note_transform_message)<tab>while self.transforms:<tab><tab><IF-STMT><tab><tab><tab># Unsorted initially, and whenever a transform is added.<tab><tab><tab>self.transforms.sort()<tab><tab><tab>self.transforms.reverse()<tab><tab><tab>self.sorted = 1<tab><tab>priority, transform_class, pending, kwargs = self.transforms.pop()<tab><tab>transform = transform_class(self.document, startnode=pending)<tab><tab>transform.apply(**kwargs)<tab><tab>self.applied.append((priority, transform_class, pending, kwargs))",0,if not self . sorted :,if self . sorted :,0.281663156243144,57.89300674674101,0.36
"def format_sql(sql, params):<tab>rv = []<tab>if isinstance(params, dict):<tab><tab># convert sql with named parameters to sql with unnamed parameters<tab><tab>conv = _FormatConverter(params)<tab><tab><IF-STMT><tab><tab><tab>sql = sql_to_string(sql)<tab><tab><tab>sql = sql % conv<tab><tab><tab>params = conv.params<tab><tab>else:<tab><tab><tab>params = ()<tab>for param in params or ():<tab><tab>if param is None:<tab><tab><tab>rv.append(""NULL"")<tab><tab>param = safe_repr(param)<tab><tab>rv.append(param)<tab>return sql, rv",0,if params :,if conv is not None :,0.048107739435423735,1e-10,0.19999999999999998
"def on_execution_item(self, cpath, execution):<tab>if not isinstance(execution, dict):<tab><tab>return<tab>if ""executor"" in execution and execution.get(""executor"") != ""jmeter"":<tab><tab>return<tab>scenario = execution.get(""scenario"", None)<tab><IF-STMT><tab><tab>return<tab>if isinstance(scenario, str):<tab><tab>scenario_name = scenario<tab><tab>scenario = self.get_named_scenario(scenario_name)<tab><tab>if not scenario:<tab><tab><tab>scenario = None<tab><tab>scenario_path = Path(""scenarios"", scenario_name)<tab>else:<tab><tab>scenario_path = cpath.copy()<tab><tab>scenario_path.add_component(""scenario"")<tab>if scenario is not None:<tab><tab>self.check_jmeter_scenario(scenario_path, scenario)",1,if not scenario :,if not scenario :,0.75,100.00000000000004,1.0
"def _poll_ipc_requests(self) -> None:<tab>try:<tab><tab>if self._ipc_requests.empty():<tab><tab><tab>return<tab><tab>while not self._ipc_requests.empty():<tab><tab><tab>args = self._ipc_requests.get()<tab><tab><tab>try:<tab><tab><tab><tab>for filename in args:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.get_editor_notebook().show_file(filename)<tab><tab><tab>except Exception as e:<tab><tab><tab><tab>logger.exception(""Problem processing ipc request"", exc_info=e)<tab><tab>self.become_active_window()<tab>finally:<tab><tab>self.after(50, self._poll_ipc_requests)",1,if os . path . isfile ( filename ) :,if os . path . isfile ( filename ) :,0.75,100.00000000000004,1.0
"def get_scroll_distance_to_element(driver, element):<tab>try:<tab><tab>scroll_position = driver.execute_script(""return window.scrollY;"")<tab><tab>element_location = None<tab><tab>element_location = element.location[""y""]<tab><tab>element_location = element_location - 130<tab><tab><IF-STMT><tab><tab><tab>element_location = 0<tab><tab>distance = element_location - scroll_position<tab><tab>return distance<tab>except Exception:<tab><tab>return 0",1,if element_location < 0 :,if element_location < 0 :,0.75,100.00000000000004,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_access_token(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_expiration_time(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 16 :,if tt == 16 :,0.75,100.00000000000004,1.0
"def _validate_and_define(params, key, value):<tab>(key, force_generic) = _validate_key(_unescape(key))<tab>if key in params:<tab><tab>raise SyntaxError(f'duplicate key ""{key}""')<tab>cls = _class_for_key.get(key, GenericParam)<tab>emptiness = cls.emptiness()<tab>if value is None:<tab><tab>if emptiness == Emptiness.NEVER:<tab><tab><tab>raise SyntaxError(""value cannot be empty"")<tab><tab>value = cls.from_value(value)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>value = cls.from_wire_parser(dns.wire.Parser(_unescape(value)))<tab><tab>else:<tab><tab><tab>value = cls.from_value(value)<tab>params[key] = value",1,if force_generic :,if force_generic :,0.5311706625951745,1e-10,1.0
"def iter_fields(node, *, include_meta=True, exclude_unset=False):<tab>exclude_meta = not include_meta<tab>for field_name, field in node._fields.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>field_val = getattr(node, field_name, _marker)<tab><tab>if field_val is _marker:<tab><tab><tab>continue<tab><tab>if exclude_unset:<tab><tab><tab>if callable(field.default):<tab><tab><tab><tab>default = field.default()<tab><tab><tab>else:<tab><tab><tab><tab>default = field.default<tab><tab><tab>if field_val == default:<tab><tab><tab><tab>continue<tab><tab>yield field_name, field_val",0,if exclude_meta and field . meta :,"if field_name . startswith ( ""_"" ) or exclude_meta :",0.019866072240875467,12.451643194233869,0.27472527472527475
"def tearDown(self):<tab>""""""Shutdown the server.""""""<tab>try:<tab><tab>if self.server:<tab><tab><tab>self.server.stop()<tab><tab><IF-STMT><tab><tab><tab>self.root_logger.removeHandler(self.sl_hdlr)<tab><tab><tab>self.sl_hdlr.close()<tab>finally:<tab><tab>BaseTest.tearDown(self)",1,if self . sl_hdlr :,if self . sl_hdlr :,0.75,100.00000000000004,1.0
"def _wait_for_async_copy(self, share_name, file_path):<tab>count = 0<tab>share_client = self.fsc.get_share_client(share_name)<tab>file_client = share_client.get_file_client(file_path)<tab>properties = file_client.get_file_properties()<tab>while properties.copy.status != ""success"":<tab><tab>count = count + 1<tab><tab><IF-STMT><tab><tab><tab>self.fail(""Timed out waiting for async copy to complete."")<tab><tab>self.sleep(6)<tab><tab>properties = file_client.get_file_properties()<tab>self.assertEqual(properties.copy.status, ""success"")",0,if count > 10 :,if count > 5 :,0.39477865547525276,42.72870063962342,0.6
"def __new__(<tab>cls,<tab>message_type: OrderBookMessageType,<tab>content: Dict[str, any],<tab>timestamp: Optional[float] = None,<tab>*args,<tab>**kwargs,):<tab>if timestamp is None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""timestamp must not be None when initializing snapshot messages.""<tab><tab><tab>)<tab><tab>timestamp = int(time.time())<tab>return super(KucoinOrderBookMessage, cls).__new__(<tab><tab>cls, message_type, content, timestamp=timestamp, *args, **kwargs<tab>)",1,if message_type is OrderBookMessageType . SNAPSHOT :,if message_type is OrderBookMessageType . SNAPSHOT :,0.75,100.00000000000004,1.0
"def _drop_unique_features(<tab>X: DataFrame, feature_metadata: FeatureMetadata, max_unique_ratio) -> list:<tab>features_to_drop = []<tab>X_len = len(X)<tab>max_unique_value_count = X_len * max_unique_ratio<tab>for column in X:<tab><tab>unique_value_count = len(X[column].unique())<tab><tab><IF-STMT><tab><tab><tab>features_to_drop.append(column)<tab><tab>elif feature_metadata.get_feature_type_raw(column) in [<tab><tab><tab>R_CATEGORY,<tab><tab><tab>R_OBJECT,<tab><tab>] and (unique_value_count > max_unique_value_count):<tab><tab><tab>features_to_drop.append(column)<tab>return features_to_drop",0,if unique_value_count == 1 :,if unique_value_count == 0 :,0.39477865547525276,78.25422900366438,0.5
"def get_src_findex_by_pad(s, S, padding_mode, align_corners):<tab>if padding_mode == ""zero"":<tab><tab>return get_src_findex_with_zero_pad(s, S)<tab>elif padding_mode == ""reflect"":<tab><tab><IF-STMT><tab><tab><tab>return get_src_findex_with_reflect_pad(s, S, True)<tab><tab>else:<tab><tab><tab>sf = get_src_findex_with_reflect_pad(s, S, False)<tab><tab><tab>return get_src_findex_with_repeat_pad(sf, S)<tab>elif padding_mode == ""repeat"":<tab><tab>return get_src_findex_with_repeat_pad(s, S)",1,if align_corners :,if align_corners :,0.5311706625951745,1e-10,1.0
"def _iterate_self_and_parents(self, upto=None):<tab>current = self<tab>result = ()<tab>while current:<tab><tab>result += (current,)<tab><tab>if current._parent is upto:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise sa_exc.InvalidRequestError(<tab><tab><tab><tab>""Transaction %s is not on the active transaction list"" % (upto)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>current = current._parent<tab>return result",0,elif current . _parent is None :,elif current . _parent is upto :,0.5717294420803809,70.71067811865478,0.6666666666666666
"def __setattr__(self, name: str, val: Any):<tab>if name.startswith(""COMPUTED_""):<tab><tab><IF-STMT><tab><tab><tab>old_val = self[name]<tab><tab><tab>if old_val == val:<tab><tab><tab><tab>return<tab><tab><tab>raise KeyError(<tab><tab><tab><tab>""Computed attributed '{}' already exists ""<tab><tab><tab><tab>""with a different value! old={}, new={}."".format(name, old_val, val)<tab><tab><tab>)<tab><tab>self[name] = val<tab>else:<tab><tab>super().__setattr__(name, val)",1,if name in self :,if name in self :,0.75,100.00000000000004,1.0
"def get_fnlist(bbhandler, pkg_pn, preferred):<tab>""""""Get all recipe file names""""""<tab><IF-STMT><tab><tab>(latest_versions, preferred_versions) = bb.providers.findProviders(<tab><tab><tab>bbhandler.config_data, bbhandler.cooker.recipecaches[""""], pkg_pn<tab><tab>)<tab>fn_list = []<tab>for pn in sorted(pkg_pn):<tab><tab>if preferred:<tab><tab><tab>fn_list.append(preferred_versions[pn][1])<tab><tab>else:<tab><tab><tab>fn_list.extend(pkg_pn[pn])<tab>return fn_list",0,if preferred :,"if """" in pkg_pn :",0.051944022748897464,1e-10,0.5
"def links_extracted(self, _, links):<tab>links_deduped = {}<tab>for link in links:<tab><tab>link_fingerprint = link.meta[FIELD_FINGERPRINT]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>links_deduped[link_fingerprint] = link<tab>[<tab><tab>self._redis_pipeline.hmset(fingerprint, self._create_link_extracted(link))<tab><tab>for (fingerprint, link) in links_deduped.items()<tab>]<tab>self._redis_pipeline.execute()",0,if link_fingerprint in links_deduped :,if not link_fingerprint :,0.03944961859844226,20.82186541080652,0.5
"def __call__(self, name, rawtext, text, lineno, inliner, options=None, content=None):<tab>options = options or {}<tab>content = content or []<tab>issue_nos = [each.strip() for each in utils.unescape(text).split("","")]<tab>config = inliner.document.settings.env.app.config<tab>ret = []<tab>for i, issue_no in enumerate(issue_nos):<tab><tab>node = self.make_node(name, issue_no, config, options=options)<tab><tab>ret.append(node)<tab><tab><IF-STMT><tab><tab><tab>sep = nodes.raw(text="", "", format=""html"")<tab><tab><tab>ret.append(sep)<tab>return ret, []",0,if i != len ( issue_nos ) - 1 :,if i < len ( issue_nos ) - 1 :,0.6049399806880458,70.76618839098694,1.0
"def init_messengers(messengers):<tab>for messenger in messengers:<tab><tab><IF-STMT><tab><tab><tab>module_path = messenger[""type""]<tab><tab><tab>messenger[""type""] = messenger[""type""].split(""."")[-1]<tab><tab>else:<tab><tab><tab>module_path = ""oncall.messengers."" + messenger[""type""]<tab><tab>instance = getattr(importlib.import_module(module_path), messenger[""type""])(<tab><tab><tab>messenger<tab><tab>)<tab><tab>for transport in instance.supports:<tab><tab><tab>_active_messengers[transport].append(instance)",1,"if ""."" in messenger [ ""type"" ] :","if ""."" in messenger [ ""type"" ] :",0.75,100.00000000000004,1.0
"def _process_enum_definition(self, tok):<tab>fields = []<tab>for field in tok.fields:<tab><tab><IF-STMT><tab><tab><tab>expression = self.expression_parser.parse(field.expression)<tab><tab>else:<tab><tab><tab>expression = None<tab><tab>fields.append(c_ast.CEnumField(name=field.name.first, value=expression))<tab>name = tok.enum_name<tab>if name:<tab><tab>name = ""enum %s"" % tok.enum_name.first<tab>else:<tab><tab>name = self._make_anonymous_type(""enum"")<tab>return c_ast.CTypeDefinition(<tab><tab>name=name,<tab><tab>type_definition=c_ast.CEnum(<tab><tab><tab>attributes=tok.attributes, fields=fields, name=name<tab><tab>),<tab>)",1,if field . expression :,if field . expression :,0.75,100.00000000000004,1.0
def result_iterator():<tab>try:<tab><tab># reverse to keep finishing order<tab><tab>fs.reverse()<tab><tab>while fs:<tab><tab><tab># Careful not to keep a reference to the popped future<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield fs.pop().result()<tab><tab><tab>else:<tab><tab><tab><tab>yield fs.pop().result(end_time - time.time())<tab>finally:<tab><tab>for future in fs:<tab><tab><tab>future.cancel(),0,if timeout is None :,if time . time ( ) >= end_time :,0.0252788731101473,4.02724819242185,0.3181818181818182
"def has_encrypted_ssh_key_data(self):<tab>try:<tab><tab>ssh_key_data = self.get_input(""ssh_key_data"")<tab>except AttributeError:<tab><tab>return False<tab>try:<tab><tab>pem_objects = validate_ssh_private_key(ssh_key_data)<tab><tab>for pem_object in pem_objects:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>except ValidationError:<tab><tab>pass<tab>return False",0,"if pem_object . get ( ""key_enc"" , False ) :",if self . get_encrypted_ssh_object ( pem_object ) :,0.030390516601639946,14.62806365365753,0.38666666666666666
"def test_seq_object_transcription_method(self):<tab>for nucleotide_seq in test_seqs:<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(<tab><tab><tab><tab>repr(Seq.transcribe(nucleotide_seq)),<tab><tab><tab><tab>repr(nucleotide_seq.transcribe()),<tab><tab><tab>)",0,"if isinstance ( nucleotide_seq , Seq . Seq ) :","if hasattr ( nucleotide_seq , ""transcribe"" ) :",0.07112436406141975,37.70063804549471,0.37142857142857144
"def max_elevation(self):<tab>max_el = None<tab>for y in xrange(self.height):<tab><tab>for x in xrange(self.width):<tab><tab><tab>el = self.elevation[""data""][y][x]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>max_el = el<tab>return max_el",0,if max_el is None or el > max_el :,if el > max_el :,0.22529282519794364,35.685360466076496,0.2878787878787879
"def stress(mapping, index):<tab>for count in range(OPERATIONS):<tab><tab>function = random.choice(functions)<tab><tab>function(mapping, index)<tab><tab><IF-STMT><tab><tab><tab>print(""\r"", len(mapping), "" "" * 7, end="""")<tab>print()",0,if count % 1000 == 0 :,if count % 10000 == 0 :,0.3884893899276739,50.000000000000014,0.6666666666666666
"def sync_terminology(self):<tab>if self.is_source:<tab><tab>return<tab>store = self.store<tab>missing = []<tab>for source in self.component.get_all_sources():<tab><tab>if ""terminology"" not in source.all_flags:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>_unit, add = store.find_unit(source.context, source.source)<tab><tab>except UnitNotFound:<tab><tab><tab>add = True<tab><tab># Unit is already present<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>missing.append((source.context, source.source, """"))<tab>if missing:<tab><tab>self.add_units(None, missing)",0,if not add :,if add :,0.09648852821835877,1e-10,0.41666666666666663
"def get_generators(self):<tab>""""""Get a dict with all registered generators, indexed by name""""""<tab>generators = {}<tab>for core in self.db.find():<tab><tab><IF-STMT><tab><tab><tab>_generators = core.get_generators({})<tab><tab><tab>if _generators:<tab><tab><tab><tab>generators[str(core.name)] = _generators<tab>return generators",1,"if hasattr ( core , ""get_generators"" ) :","if hasattr ( core , ""get_generators"" ) :",0.75,100.00000000000004,1.0
"def act(self, state):<tab>if self.body.env.clock.frame < self.training_start_step:<tab><tab>return policy_util.random(state, self, self.body).cpu().squeeze().numpy()<tab>else:<tab><tab>action = self.action_policy(state, self, self.body)<tab><tab><IF-STMT><tab><tab><tab>action = self.scale_action(torch.tanh(action))  # continuous action bound<tab><tab>return action.cpu().squeeze().numpy()",0,if not self . body . is_discrete :,"if self . mode == ""scale"" :",0.03676852316447079,9.980099403873663,0.3148148148148148
"def try_open_completions_event(self, event=None):<tab>""(./) Open completion list after pause with no movement.""<tab>lastchar = self.text.get(""insert-1c"")<tab>if lastchar in TRIGGERS:<tab><tab>args = TRY_A if lastchar == ""."" else TRY_F<tab><tab>self._delayed_completion_index = self.text.index(""insert"")<tab><tab><IF-STMT><tab><tab><tab>self.text.after_cancel(self._delayed_completion_id)<tab><tab>self._delayed_completion_id = self.text.after(<tab><tab><tab>self.popupwait, self._delayed_open_completions, args<tab><tab>)",1,if self . _delayed_completion_id is not None :,if self . _delayed_completion_id is not None :,0.75,100.00000000000004,1.0
"def token_is_available(self):<tab>if self.token:<tab><tab>try:<tab><tab><tab>resp = requests.get(<tab><tab><tab><tab>""https://api.shodan.io/account/profile?key={0}"".format(self.token)<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>except Exception as ex:<tab><tab><tab>logger.error(str(ex))<tab>return False",0,"if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :",if resp and resp . status_code == 200 :,0.31337206413010243,40.133982522080174,0.6095238095238095
"def next_bar_(self, event):<tab>bars = event.bar_dict<tab>self._current_minute = self._minutes_since_midnight(<tab><tab>self.ucontext.now.hour, self.ucontext.now.minute<tab>)<tab>for day_rule, time_rule, func in self._registry:<tab><tab><IF-STMT><tab><tab><tab>with ExecutionContext(EXECUTION_PHASE.SCHEDULED):<tab><tab><tab><tab>with ModifyExceptionFromType(EXC_TYPE.USER_EXC):<tab><tab><tab><tab><tab>func(self.ucontext, bars)<tab>self._last_minute = self._current_minute",0,if day_rule ( ) and time_rule ( ) :,"if day_rule ( bars , day_rule , time_rule ) :",0.07483923645833467,33.64932442330151,0.5
"def decoder(s):<tab>r = []<tab>decode = []<tab>for c in s:<tab><tab>if c == ""&"" and not decode:<tab><tab><tab>decode.append(""&"")<tab><tab><IF-STMT><tab><tab><tab>if len(decode) == 1:<tab><tab><tab><tab>r.append(""&"")<tab><tab><tab>else:<tab><tab><tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab><tab><tab>decode = []<tab><tab>elif decode:<tab><tab><tab>decode.append(c)<tab><tab>else:<tab><tab><tab>r.append(c)<tab>if decode:<tab><tab>r.append(modified_unbase64("""".join(decode[1:])))<tab>bin_str = """".join(r)<tab>return (bin_str, len(s))",0,"elif c == ""-"" and decode :","elif c == ""?"" and not decode :",0.49901880150724026,44.97332084013507,0.6428571428571429
"def admin_audit_get(admin_id):<tab>if settings.app.demo_mode:<tab><tab>resp = utils.demo_get_cache()<tab><tab><IF-STMT><tab><tab><tab>return utils.jsonify(resp)<tab>if not flask.g.administrator.super_user:<tab><tab>return utils.jsonify(<tab><tab><tab>{<tab><tab><tab><tab>""error"": REQUIRES_SUPER_USER,<tab><tab><tab><tab>""error_msg"": REQUIRES_SUPER_USER_MSG,<tab><tab><tab>},<tab><tab><tab>400,<tab><tab>)<tab>admin = auth.get_by_id(admin_id)<tab>resp = admin.get_audit_events()<tab>if settings.app.demo_mode:<tab><tab>utils.demo_set_cache(resp)<tab>return utils.jsonify(resp)",0,if resp :,if not flask . g . administrator :,0.04422835593777517,1e-10,0.23809523809523808
"def vjp(self, argnum, outgrad, ans, vs, gvs, args, kwargs):<tab>try:<tab><tab>return self.vjps[argnum](outgrad, ans, vs, gvs, *args, **kwargs)<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>errstr = ""Gradient of {0} not yet implemented.""<tab><tab>else:<tab><tab><tab>errstr = ""Gradient of {0} w.r.t. arg number {1} not yet implemented.""<tab><tab>raise NotImplementedError(errstr.format(self.fun.__name__, argnum))",0,if self . vjps == { } :,if argnum == 0 :,0.019907917998500824,11.708995388048026,0.3333333333333333
"def update(self, *args, **kwargs):<tab>assert not self.readonly<tab>longest_key = 0<tab>_dict = self._dict<tab>reverse = self.reverse<tab>casereverse = self.casereverse<tab>for iterable in args + (kwargs,):<tab><tab><IF-STMT><tab><tab><tab>iterable = iterable.items()<tab><tab>for key, value in iterable:<tab><tab><tab>longest_key = max(longest_key, len(key))<tab><tab><tab>_dict[key] = value<tab><tab><tab>reverse[value].append(key)<tab><tab><tab>casereverse[value.lower()][value] += 1<tab>self._longest_key = max(self._longest_key, longest_key)",0,"if isinstance ( iterable , ( dict , StenoDictionary ) ) :","if isinstance ( iterable , dict ) :",0.19029013543631623,37.28878639930421,0.8222222222222223
"def update_ui(self, window):<tab>view = window.get_active_view()<tab>self.set_status(view)<tab>lang = ""plain_text""<tab>if view:<tab><tab>buf = view.get_buffer()<tab><tab>language = buf.get_language()<tab><tab><IF-STMT><tab><tab><tab>lang = language.get_id()<tab><tab>self.setup_smart_indent(view, lang)",1,if language :,if language :,0.5311706625951745,1e-10,1.0
"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in self.unops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)",1,"if hasattr ( a , name ) :","if hasattr ( a , name ) :",0.75,100.00000000000004,1.0
"def _getItemHeight(self, item, ctrl=None):<tab>""""""Returns the full height of the item to be inserted in the form""""""<tab>if type(ctrl) == psychopy.visual.TextBox2:<tab><tab>return ctrl.size[1]<tab>if type(ctrl) == psychopy.visual.Slider:<tab><tab># Set radio button layout<tab><tab><IF-STMT><tab><tab><tab>return 0.03 + ctrl.labelHeight * 3<tab><tab>elif item[""layout""] == ""vert"":<tab><tab><tab># for vertical take into account the nOptions<tab><tab><tab>return ctrl.labelHeight * len(item[""options""])",0,"if item [ ""layout"" ] == ""horiz"" :","if item [ ""layout"" ] == ""horizontal"" :",0.605621305873661,79.10665071754353,1.0
"def test_cleanup_params(self, body, rpc_mock):<tab>res = self._get_resp_post(body)<tab>self.assertEqual(http_client.ACCEPTED, res.status_code)<tab>rpc_mock.assert_called_once_with(self.context, mock.ANY)<tab>cleanup_request = rpc_mock.call_args[0][1]<tab>for key, value in body.items():<tab><tab>if key in (""disabled"", ""is_up""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value == ""true""<tab><tab>self.assertEqual(value, getattr(cleanup_request, key))<tab>self.assertEqual(self._expected_services(*SERVICES), res.json)",0,if value is not None :,"if key == ""is_up"" :",0.02713659235259708,5.522397783539471,0.19999999999999998
"def _read_json_content(self, body_is_optional=False):<tab>if ""content-length"" not in self.headers:<tab><tab>return self.send_error(411) if not body_is_optional else {}<tab>try:<tab><tab>content_length = int(self.headers.get(""content-length""))<tab><tab>if content_length == 0 and body_is_optional:<tab><tab><tab>return {}<tab><tab>request = json.loads(self.rfile.read(content_length).decode(""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>return request<tab>except Exception:<tab><tab>logger.exception(""Bad request"")<tab>self.send_error(400)",0,"if isinstance ( request , dict ) and ( request or body_is_optional ) :",if request :,0.0064102374790493705,1e-10,0.2481203007518797
"def env_purge_doc(app: Sphinx, env: BuildEnvironment, docname: str) -> None:<tab>modules = getattr(env, ""_viewcode_modules"", {})<tab>for modname, entry in list(modules.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>code, tags, used, refname = entry<tab><tab>for fullname in list(used):<tab><tab><tab>if used[fullname] == docname:<tab><tab><tab><tab>used.pop(fullname)<tab><tab>if len(used) == 0:<tab><tab><tab>modules.pop(modname)",0,if entry is False :,"if modname . startswith ( ""_"" ) :",0.026407399022921448,4.990049701936832,0.2698412698412698
"def frames(self):<tab>""""""an array of all the frames (including iframes) in the current window""""""<tab>from thug.DOM.W3C.HTML.HTMLCollection import HTMLCollection<tab>frames = set()<tab>for frame in self._findAll([""frame"", ""iframe""]):<tab><tab><IF-STMT><tab><tab><tab>from thug.DOM.W3C.Core.DOMImplementation import DOMImplementation<tab><tab><tab>DOMImplementation.createHTMLElement(self.window.doc, frame)<tab><tab>frames.add(frame._node)<tab>return HTMLCollection(self.doc, list(frames))",0,"if not getattr ( frame , ""_node"" , None ) :",if frame . _node is None :,0.013929296510807567,6.866210821983635,0.27472527472527475
"def check(self, **kw):<tab>if not kw:<tab><tab>return exists(self.strpath)<tab>if len(kw) == 1:<tab><tab><IF-STMT><tab><tab><tab>return not kw[""dir""] ^ isdir(self.strpath)<tab><tab>if ""file"" in kw:<tab><tab><tab>return not kw[""file""] ^ isfile(self.strpath)<tab>return super(LocalPath, self).check(**kw)",1,"if ""dir"" in kw :","if ""dir"" in kw :",0.75,100.00000000000004,1.0
"def __init__(self, folders):<tab>self.folders = folders<tab>self.duplicates = {}<tab>for folder, path in folders.items():<tab><tab>duplicates = []<tab><tab>for other_folder, other_path in folders.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if other_path == path:<tab><tab><tab><tab>duplicates.append(other_folder)<tab><tab>if len(duplicates):<tab><tab><tab>self.duplicates[folder] = duplicates",0,if other_folder == folder :,if folder == other_folder :,0.2901714209472326,39.28146509005134,1.0
"def next(self, buf, pos):<tab>if pos >= len(buf):<tab><tab>return EOF, """", pos<tab>mo = self.tokens_re.match(buf, pos)<tab>if mo:<tab><tab>text = mo.group()<tab><tab>type, regexp, test_lit = self.tokens[mo.lastindex - 1]<tab><tab>pos = mo.end()<tab><tab><IF-STMT><tab><tab><tab>type = self.literals.get(text, type)<tab><tab>return type, text, pos<tab>else:<tab><tab>c = buf[pos]<tab><tab>return self.symbols.get(c, None), c, pos + 1",1,if test_lit :,if test_lit :,0.5311706625951745,1e-10,1.0
"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab><IF-STMT><tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab>if done:<tab><tab><tab>break<tab># Note that the observation on the done=True frame<tab># doesn't matter<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",1,if i == self . _skip - 2 :,if i == self . _skip - 2 :,0.75,100.00000000000004,1.0
"def convert(self, ctx, argument):<tab>arg = argument.replace(""0x"", """").lower()<tab>if arg[0] == ""#"":<tab><tab>arg = arg[1:]<tab>try:<tab><tab>value = int(arg, base=16)<tab><tab>if not (0 <= value <= 0xFFFFFF):<tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return discord.Colour(value=value)<tab>except ValueError:<tab><tab>arg = arg.replace("" "", ""_"")<tab><tab>method = getattr(discord.Colour, arg, None)<tab><tab><IF-STMT><tab><tab><tab>raise BadColourArgument(arg)<tab><tab>return method()",0,"if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",if not method :,0.004388749776601787,0.1954422280040373,0.1490909090909091
"def run(self, **inputs):<tab>if self.inputs.copy_inputs:<tab><tab>self.inputs.subjects_dir = os.getcwd()<tab><tab><IF-STMT><tab><tab><tab>inputs[""subjects_dir""] = self.inputs.subjects_dir<tab><tab>for originalfile in [self.inputs.in_file, self.inputs.in_norm]:<tab><tab><tab>copy2subjdir(self, originalfile, folder=""mri"")<tab>return super(SegmentCC, self).run(**inputs)",0,"if ""subjects_dir"" in inputs :",if self . inputs . subjects_dir :,0.029730601197949243,21.10534063187263,0.6
"def get_queryset(self):<tab>if not hasattr(self, ""_queryset""):<tab><tab><IF-STMT><tab><tab><tab>qs = self.queryset<tab><tab>else:<tab><tab><tab>qs = self.model._default_manager.get_queryset()<tab><tab># If the queryset isn't already ordered we need to add an<tab><tab># artificial ordering here to make sure that all formsets<tab><tab># constructed from this queryset have the same form order.<tab><tab>if not qs.ordered:<tab><tab><tab>qs = qs.order_by(self.model._meta.pk.name)<tab><tab># Removed queryset limiting here. As per discussion re: #13023<tab><tab># on django-dev, max_num should not prevent existing<tab><tab># related objects/inlines from being displayed.<tab><tab>self._queryset = qs<tab>return self._queryset",1,if self . queryset is not None :,if self . queryset is not None :,0.75,100.00000000000004,1.0
"def visit_simple_stmt(self, node: Node) -> Iterator[Line]:<tab>""""""Visit a statement without nested statements.""""""<tab>is_suite_like = node.parent and node.parent.type in STATEMENT<tab>if is_suite_like:<tab><tab><IF-STMT><tab><tab><tab>yield from self.visit_default(node)<tab><tab>else:<tab><tab><tab>yield from self.line(+1)<tab><tab><tab>yield from self.visit_default(node)<tab><tab><tab>yield from self.line(-1)<tab>else:<tab><tab>if not self.is_pyi or not node.parent or not is_stub_suite(node.parent):<tab><tab><tab>yield from self.line()<tab><tab>yield from self.visit_default(node)",0,if self . is_pyi and is_stub_body ( node ) :,if self . is_pyi or not is_stub_suite ( node . parent ) :,0.28060642435343985,43.59493824807389,0.359375
"def rawDataReceived(self, data):<tab>if self.timeout > 0:<tab><tab>self.resetTimeout()<tab>self._pendingSize -= len(data)<tab>if self._pendingSize > 0:<tab><tab>self._pendingBuffer.write(data)<tab>else:<tab><tab>passon = b""""<tab><tab><IF-STMT><tab><tab><tab>data, passon = data[: self._pendingSize], data[self._pendingSize :]<tab><tab>self._pendingBuffer.write(data)<tab><tab>rest = self._pendingBuffer<tab><tab>self._pendingBuffer = None<tab><tab>self._pendingSize = None<tab><tab>rest.seek(0, 0)<tab><tab>self._parts.append(rest.read())<tab><tab>self.setLineMode(passon.lstrip(b""\r\n""))",0,if self . _pendingSize < 0 :,if self . _pendingSize > 0 :,0.4962728306172343,59.4603557501361,1.0
"def handle(self, *args, **options):<tab>app_name = options.get(""app_name"")<tab>job_name = options.get(""job_name"")<tab># hack since we are using job_name nargs='?' for -l to work<tab>if app_name and not job_name:<tab><tab>job_name = app_name<tab><tab>app_name = None<tab>if options.get(""list_jobs""):<tab><tab>print_jobs(only_scheduled=False, show_when=True, show_appname=True)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>print(""Run a single maintenance job. Please specify the name of the job."")<tab><tab><tab>return<tab><tab>self.runjob(app_name, job_name, options)",0,if not job_name :,"if options . get ( ""list_jobs"" ) :",0.03469219238104862,4.456882760699063,0.38181818181818183
"def _exportReceived(self, content, error=False, server=None, context={}, **kwargs):<tab>if error:<tab><tab><IF-STMT><tab><tab><tab>self.error.emit(content[""message""], True)<tab><tab>else:<tab><tab><tab>self.error.emit(""Can't export the project from the server"", True)<tab><tab>self.finished.emit()<tab><tab>return<tab>self.finished.emit()",0,if content :,"if ""message"" in content :",0.09791453445388575,1e-10,0.45
"def __iter__(self):<tab>n = self.n<tab>k = self.k<tab>j = int(np.ceil(n / k))<tab>for i in range(k):<tab><tab>test_index = np.zeros(n, dtype=bool)<tab><tab><IF-STMT><tab><tab><tab>test_index[i * j : (i + 1) * j] = True<tab><tab>else:<tab><tab><tab>test_index[i * j :] = True<tab><tab>train_index = np.logical_not(test_index)<tab><tab>yield train_index, test_index",0,if i < k - 1 :,if i % 2 == 0 :,0.04066031774849872,12.22307556087252,0.42857142857142855
"def addType(self, graphene_type):<tab>meta = get_meta(graphene_type)<tab>if meta:<tab><tab><IF-STMT><tab><tab><tab>self._typeMap[meta.name] = graphene_type<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Type {typeName} already exists in the registry."".format(<tab><tab><tab><tab><tab>typeName=meta.name<tab><tab><tab><tab>)<tab><tab><tab>)<tab>else:<tab><tab>raise Exception(""Cannot add unnamed type or a non-type to registry."")",0,if not graphene_type in self . _typeMap :,if meta . name in self . _typeMap :,0.3389987794659729,48.61555413051454,0.2698412698412698
"def test_len(self):<tab>eq = self.assertEqual<tab>eq(base64MIME.base64_len(""hello""), len(base64MIME.encode(""hello"", eol="""")))<tab>for size in range(15):<tab><tab>if size == 0:<tab><tab><tab>bsize = 0<tab><tab>elif size <= 3:<tab><tab><tab>bsize = 4<tab><tab><IF-STMT><tab><tab><tab>bsize = 8<tab><tab>elif size <= 9:<tab><tab><tab>bsize = 12<tab><tab>elif size <= 12:<tab><tab><tab>bsize = 16<tab><tab>else:<tab><tab><tab>bsize = 20<tab><tab>eq(base64MIME.base64_len(""x"" * size), bsize)",0,elif size <= 6 :,elif size <= 5 :,0.39287202148494,53.7284965911771,0.6
"def _asStringList(self, sep=""""):<tab>out = []<tab>for item in self._toklist:<tab><tab><IF-STMT><tab><tab><tab>out.append(sep)<tab><tab>if isinstance(item, ParseResults):<tab><tab><tab>out += item._asStringList()<tab><tab>else:<tab><tab><tab>out.append(str(item))<tab>return out",1,if out and sep :,if out and sep :,0.75,100.00000000000004,1.0
"def open_file_input(cli_parsed):<tab>files = glob.glob(os.path.join(cli_parsed.d, ""*report.html""))<tab>if len(files) > 0:<tab><tab>print(""\n[*] Done! Report written in the "" + cli_parsed.d + "" folder!"")<tab><tab>print(""Would you like to open the report now? [Y/n]"")<tab><tab>while True:<tab><tab><tab>try:<tab><tab><tab><tab>response = input().lower()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return strtobool(response)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>print(""Please respond with y or n"")<tab>else:<tab><tab>print(""[*] No report files found to open, perhaps no hosts were successful"")<tab><tab>return False",0,"if response == """" :","if response == ""y"" :",0.39477865547525276,59.4603557501361,1.0
"def init_values(self):<tab>config = self._raw_config<tab>for valname, value in self.overrides.iteritems():<tab><tab><IF-STMT><tab><tab><tab>realvalname, key = valname.split(""."", 1)<tab><tab><tab>config.setdefault(realvalname, {})[key] = value<tab><tab>else:<tab><tab><tab>config[valname] = value<tab>for name in config:<tab><tab>if name in self.values:<tab><tab><tab>self.__dict__[name] = config[name]<tab>del self._raw_config",1,"if ""."" in valname :","if ""."" in valname :",0.75,100.00000000000004,1.0
"def get_result(self):<tab>result_list = []<tab>exc_info = None<tab>for f in self.children:<tab><tab>try:<tab><tab><tab>result_list.append(f.get_result())<tab><tab>except Exception as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>exc_info = sys.exc_info()<tab><tab><tab>else:<tab><tab><tab><tab>if not isinstance(e, self.quiet_exceptions):<tab><tab><tab><tab><tab>app_log.error(""Multiple exceptions in yield list"", exc_info=True)<tab>if exc_info is not None:<tab><tab>raise_exc_info(exc_info)<tab>if self.keys is not None:<tab><tab>return dict(zip(self.keys, result_list))<tab>else:<tab><tab>return list(result_list)",1,if exc_info is None :,if exc_info is None :,0.75,100.00000000000004,1.0
"def test01e_json(self):<tab>""Testing GeoJSON input/output.""<tab>if not GEOJSON:<tab><tab>return<tab>for g in self.geometries.json_geoms:<tab><tab>geom = OGRGeometry(g.wkt)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(g.json, geom.json)<tab><tab><tab>self.assertEqual(g.json, geom.geojson)<tab><tab>self.assertEqual(OGRGeometry(g.wkt), OGRGeometry(geom.json))",0,"if not hasattr ( g , ""not_equal"" ) :","if hasattr ( geom , ""geojson"" ) :",0.04084739796645766,17.584661674110286,0.3181818181818182
"def __init__(self, hub=None):  # pylint: disable=unused-argument<tab>if resolver._resolver is None:<tab><tab>_resolver = resolver._resolver = _DualResolver()<tab><tab><IF-STMT><tab><tab><tab>_resolver.network_resolver.nameservers[:] = config.resolver_nameservers<tab><tab>if config.resolver_timeout:<tab><tab><tab>_resolver.network_resolver.lifetime = config.resolver_timeout<tab># Different hubs in different threads could be sharing the same<tab># resolver.<tab>assert isinstance(resolver._resolver, _DualResolver)<tab>self._resolver = resolver._resolver",1,if config . resolver_nameservers :,if config . resolver_nameservers :,0.75,100.00000000000004,1.0
"def __iadd__(self, term):<tab>if isinstance(term, (int, long)):<tab><tab><IF-STMT><tab><tab><tab>_gmp.mpz_add_ui(self._mpz_p, self._mpz_p, c_ulong(term))<tab><tab><tab>return self<tab><tab>if -65535 < term < 0:<tab><tab><tab>_gmp.mpz_sub_ui(self._mpz_p, self._mpz_p, c_ulong(-term))<tab><tab><tab>return self<tab><tab>term = Integer(term)<tab>_gmp.mpz_add(self._mpz_p, self._mpz_p, term._mpz_p)<tab>return self",1,if 0 <= term < 65536 :,if 0 <= term < 65536 :,0.75,100.00000000000004,1.0
"def copy(dst, src):<tab>for (k, v) in src.iteritems():<tab><tab><IF-STMT><tab><tab><tab>d = {}<tab><tab><tab>dst[k] = d<tab><tab><tab>copy(d, v)<tab><tab>else:<tab><tab><tab>dst[k] = v",1,"if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",0.75,100.00000000000004,1.0
"def generator(self, data):<tab>self.procs = OrderedDict()<tab>for task in data:<tab><tab>self.recurse_task(task, 0, 0, self.procs)<tab>for offset, name, level, pid, ppid, uid, euid, gid in self.procs.values():<tab><tab><IF-STMT><tab><tab><tab>yield (<tab><tab><tab><tab>0,<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>Address(offset),<tab><tab><tab><tab><tab>str(name),<tab><tab><tab><tab><tab>str(level),<tab><tab><tab><tab><tab>int(pid),<tab><tab><tab><tab><tab>int(ppid),<tab><tab><tab><tab><tab>int(uid),<tab><tab><tab><tab><tab>int(gid),<tab><tab><tab><tab><tab>int(euid),<tab><tab><tab><tab>],<tab><tab><tab>)",0,if offset :,if name is not None :,0.048107739435423735,1e-10,0.19999999999999998
"def apply(self, db, person):<tab>families = person.get_parent_family_handle_list()<tab>if families == []:<tab><tab>return True<tab>for family_handle in person.get_parent_family_handle_list():<tab><tab>family = db.get_family_from_handle(family_handle)<tab><tab><IF-STMT><tab><tab><tab>father_handle = family.get_father_handle()<tab><tab><tab>mother_handle = family.get_mother_handle()<tab><tab><tab>if not father_handle:<tab><tab><tab><tab>return True<tab><tab><tab>if not mother_handle:<tab><tab><tab><tab>return True<tab>return False",1,if family :,if family :,0.5311706625951745,1e-10,1.0
"def _arctic_task_exec(request):<tab>request.start_time = time.time()<tab>logging.debug(<tab><tab>""Executing asynchronous request for {}/{}"".format(<tab><tab><tab>request.library, request.symbol<tab><tab>)<tab>)<tab>result = None<tab>try:<tab><tab>request.is_running = True<tab><tab><IF-STMT><tab><tab><tab>result = mongo_retry(request.fun)(*request.args, **request.kwargs)<tab><tab>else:<tab><tab><tab>result = request.fun(*request.args, **request.kwargs)<tab>except Exception as e:<tab><tab>request.exception = e<tab>finally:<tab><tab>request.data = result<tab><tab>request.end_time = time.time()<tab><tab>request.is_running = False<tab>return result",0,if request . mongo_retry :,if request . is_retry :,0.39477865547525276,41.11336169005196,1.0
"def _setup_styles(self):<tab>for ttype, ndef in self.style:<tab><tab>escape = EscapeSequence()<tab><tab><IF-STMT><tab><tab><tab>escape.fg = self._color_index(ndef[""color""])<tab><tab>if ndef[""bgcolor""]:<tab><tab><tab>escape.bg = self._color_index(ndef[""bgcolor""])<tab><tab>if self.usebold and ndef[""bold""]:<tab><tab><tab>escape.bold = True<tab><tab>if self.useunderline and ndef[""underline""]:<tab><tab><tab>escape.underline = True<tab><tab>self.style_string[str(ttype)] = (escape.color_string(), escape.reset_string())",1,"if ndef [ ""color"" ] :","if ndef [ ""color"" ] :",0.75,100.00000000000004,1.0
"def process_string(self, remove_repetitions, sequence):<tab>string = """"<tab>for i, char in enumerate(sequence):<tab><tab>if char != self.int_to_char[self.blank_index]:<tab><tab><tab># if this char is a repetition and remove_repetitions=true,<tab><tab><tab># skip.<tab><tab><tab>if remove_repetitions and i != 0 and char == sequence[i - 1]:<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>string += "" ""<tab><tab><tab>else:<tab><tab><tab><tab>string = string + char<tab>return string",0,elif char == self . labels [ self . space_index ] :,elif i == len ( sequence ) - 1 :,0.24661491783375064,6.196349981371174,0.2222222222222222
"def arith_expr(self, nodelist):<tab>node = self.com_node(nodelist[0])<tab>for i in range(2, len(nodelist), 2):<tab><tab>right = self.com_node(nodelist[i])<tab><tab><IF-STMT><tab><tab><tab>node = Add(node, right, lineno=nodelist[1].context)<tab><tab>elif nodelist[i - 1].type == token.MINUS:<tab><tab><tab>node = Sub(node, right, lineno=nodelist[1].context)<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected token: %s"" % nodelist[i - 1][0])<tab>return node",0,if nodelist [ i - 1 ] . type == token . PLUS :,if nodelist [ i - 1 ] . type == token . COMMA :,0.6786713152585868,86.66415730847507,0.7777777777777778
"def invert_index(cls, index, length):<tab>if np.isscalar(index):<tab><tab>return length - index<tab>elif isinstance(index, slice):<tab><tab>start, stop = index.start, index.stop<tab><tab>new_start, new_stop = None, None<tab><tab><IF-STMT><tab><tab><tab>new_stop = length - start<tab><tab>if stop is not None:<tab><tab><tab>new_start = length - stop<tab><tab>return slice(new_start - 1, new_stop - 1)<tab>elif isinstance(index, Iterable):<tab><tab>new_index = []<tab><tab>for ind in index:<tab><tab><tab>new_index.append(length - ind)<tab>return new_index",1,if start is not None :,if start is not None :,0.75,100.00000000000004,1.0
"def getRoots(job):<tab>if job not in visited:<tab><tab>visited.add(job)<tab><tab><IF-STMT><tab><tab><tab>list(map(lambda p: getRoots(p), job._directPredecessors))<tab><tab>else:<tab><tab><tab>roots.add(job)<tab><tab># The following call ensures we explore all successor edges.<tab><tab>list(map(lambda c: getRoots(c), job._children + job._followOns))",0,if len ( job . _directPredecessors ) > 0 :,if job . _directPredecessors :,0.059382556937524214,24.439253249722206,0.37142857142857144
"def visit_filter_projection(self, node, value):<tab>base = self.visit(node[""children""][0], value)<tab>if not isinstance(base, list):<tab><tab>return None<tab>comparator_node = node[""children""][2]<tab>collected = []<tab>for element in base:<tab><tab><IF-STMT><tab><tab><tab>current = self.visit(node[""children""][1], element)<tab><tab><tab>if current is not None:<tab><tab><tab><tab>collected.append(current)<tab>return collected",0,"if self . _is_true ( self . visit ( comparator_node , element ) ) :","if self . visit ( comparator_node , element ) is not None :",0.358166339391274,50.66641486392108,0.3194444444444444
"def func(x, y):<tab>try:<tab><tab>if x > y:<tab><tab><tab>z = x + 2 * math.sin(y)<tab><tab><tab>return z ** 2<tab><tab><IF-STMT><tab><tab><tab>return 4<tab><tab>else:<tab><tab><tab>return 2 ** 3<tab>except ValueError:<tab><tab>foo = 0<tab><tab>for i in range(4):<tab><tab><tab>foo += i<tab><tab>return foo<tab>except TypeError:<tab><tab>return 42<tab>else:<tab><tab>return 33<tab>finally:<tab><tab>print(""finished"")",1,elif x == y :,elif x == y :,1.0,100.00000000000004,1.0
"def set_filter(self, dataset_opt):<tab>""""""This function create and set the pre_filter to the obj as attributes""""""<tab>self.pre_filter = None<tab>for key_name in dataset_opt.keys():<tab><tab><IF-STMT><tab><tab><tab>new_name = key_name.replace(""filters"", ""filter"")<tab><tab><tab>try:<tab><tab><tab><tab>filt = instantiate_filters(getattr(dataset_opt, key_name))<tab><tab><tab>except Exception:<tab><tab><tab><tab>log.exception(<tab><tab><tab><tab><tab>""Error trying to create {}, {}"".format(<tab><tab><tab><tab><tab><tab>new_name, getattr(dataset_opt, key_name)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab><tab>continue<tab><tab><tab>setattr(self, new_name, filt)",0,"if ""filter"" in key_name :","if isinstance ( key_name , str ) :",0.028001459970687266,17.747405280050266,0.38181818181818183
"def _add_states_to_lookup(<tab>self, trackers_as_states, trackers_as_actions, domain, online=False):<tab>""""""Add states to lookup dict""""""<tab>for states in trackers_as_states:<tab><tab>active_form = self._get_active_form_name(states[-1])<tab><tab><IF-STMT><tab><tab><tab># modify the states<tab><tab><tab>states = self._modified_states(states)<tab><tab><tab>feature_key = self._create_feature_key(states)<tab><tab><tab># even if there are two identical feature keys<tab><tab><tab># their form will be the same<tab><tab><tab># because of `active_form_...` feature<tab><tab><tab>self.lookup[feature_key] = active_form",0,if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,if active_form and online :,0.08857296421044021,4.917717334762976,0.41428571428571426
"def list_loaded_payloads(self):<tab>print(helpers.color(""\n [*] Available Payloads:\n""))<tab>lastBase = None<tab>x = 1<tab>for name in sorted(self.active_payloads.keys()):<tab><tab>parts = name.split(""/"")<tab><tab><IF-STMT><tab><tab><tab>print()<tab><tab>lastBase = parts[0]<tab><tab>print(""\t%s)\t%s"" % (x, ""{0: <24}"".format(name)))<tab><tab>x += 1<tab>print(""\n"")<tab>return",0,if lastBase and parts [ 0 ] != lastBase :,if lastBase is not None and parts [ 0 ] != lastBase :,0.4677028334257025,64.50001140844256,0.24747474747474751
"def reprSmart(vw, item):<tab>ptype = type(item)<tab>if ptype is int:<tab><tab>if -1024 < item < 1024:<tab><tab><tab>return str(item)<tab><tab><IF-STMT><tab><tab><tab>return vw.reprPointer(item)<tab><tab>else:<tab><tab><tab>return hex(item)<tab>elif ptype in (list, tuple):<tab><tab>return reprComplex(vw, item)  # recurse<tab>elif ptype is dict:<tab><tab>return ""{%s}"" % "","".join(<tab><tab><tab>[""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()]<tab><tab>)<tab>else:<tab><tab>return repr(item)",0,elif vw . isValidPointer ( item ) :,elif - 1024 < item < 1024 :,0.01827776114272562,7.267884212102741,0.3333333333333333
"def ConfigSectionMap(section):<tab>config = ConfigParser.RawConfigParser()<tab>configurations = config_manager()  # Class from mkchromecast.config<tab>configf = configurations.configf<tab>config.read(configf)<tab>dict1 = {}<tab>options = config.options(section)<tab>for option in options:<tab><tab>try:<tab><tab><tab>dict1[option] = config.get(section, option)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>DebugPrint(""skip: %s"" % option)<tab><tab>except:<tab><tab><tab>print(""Exception on %s!"" % option)<tab><tab><tab>dict1[option] = None<tab>return dict1",0,if dict1 [ option ] == - 1 :,if not dict1 . get ( option ) :,0.017675223352396317,6.033504141761816,0.2698412698412698
"def on_success(result):<tab>subtasks = {}<tab>if result:<tab><tab>subtasks = {<tab><tab><tab>self.nodes_keys.inverse[s[""node_id""]]: s.get(""subtask_id"")<tab><tab><tab>for s in result<tab><tab><tab><IF-STMT><tab><tab>}<tab>if subtasks:<tab><tab>print(""subtask finished"")<tab><tab>self.next()<tab>else:<tab><tab>print(""waiting for a subtask to finish"")<tab><tab>time.sleep(10)",0,"if s . get ( ""status"" ) == ""Failure""","if s . get ( ""subtask_id"" ) is not None",0.3238215220509949,39.34995962231127,0.5324675324675325
"def redirect_aware_commmunicate(p, sys=_sys):<tab>""""""Variant of process.communicate that works with in process I/O redirection.""""""<tab>assert sys is not None<tab>out, err = p.communicate()<tab>if redirecting_io(sys=sys):<tab><tab>if out:<tab><tab><tab># We don't unicodify in Python2 because sys.stdout may be a<tab><tab><tab># cStringIO.StringIO object, which does not accept Unicode strings<tab><tab><tab>out = unicodify(out)<tab><tab><tab>sys.stdout.write(out)<tab><tab><tab>out = None<tab><tab><IF-STMT><tab><tab><tab>err = unicodify(err)<tab><tab><tab>sys.stderr.write(err)<tab><tab><tab>err = None<tab>return out, err",1,if err :,if err :,0.5311706625951745,1e-10,1.0
"def __exit__(self, *args, **kwargs):<tab>self._samples_cache = {}<tab>if is_validation_enabled() and isinstance(self.prior, dict):<tab><tab>extra = set(self.prior) - self._param_hits<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""pyro.module prior did not find params ['{}']. ""<tab><tab><tab><tab>""Did you instead mean one of ['{}']?"".format(<tab><tab><tab><tab><tab>""', '"".join(extra), ""', '"".join(self._param_misses)<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return super().__exit__(*args, **kwargs)",1,if extra :,if extra :,0.5311706625951745,1e-10,1.0
def __download_thread(self):<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>self.__current_download = self.__queue.get()<tab><tab><tab>self.__download_file(self.__current_download)<tab><tab>time.sleep(0.1),0,if not self . __queue . empty ( ) :,if self . __current_download is None :,0.02803563209318722,23.708987804092644,0.2857142857142857
"def plot_timer_command(args):<tab>import nnabla.monitor as M<tab>format_unit = dict(<tab><tab>s=""seconds"",<tab><tab>m=""minutes"",<tab><tab>h=""hours"",<tab><tab>d=""days"",<tab>)<tab>if not args.ylabel:<tab><tab><IF-STMT><tab><tab><tab>args.ylabel = ""Total elapsed time [{}]"".format(format_unit[args.time_unit])<tab><tab>else:<tab><tab><tab>args.ylabel = ""Elapsed time [{}/iter]"".format(format_unit[args.time_unit])<tab>plot_any_command(<tab><tab>args, M.plot_time_elapsed, dict(elapsed=args.elapsed, unit=args.time_unit)<tab>)<tab>return True",1,if args . elapsed :,if args . elapsed :,0.75,100.00000000000004,1.0
"def resolve_page(root: ChannelContext[models.MenuItem], info, **kwargs):<tab>if root.node.page_id:<tab><tab>requestor = get_user_or_app_from_context(info.context)<tab><tab>requestor_has_access_to_all = requestor.is_active and requestor.has_perm(<tab><tab><tab>PagePermissions.MANAGE_PAGES<tab><tab>)<tab><tab>return (<tab><tab><tab>PageByIdLoader(info.context)<tab><tab><tab>.load(root.node.page_id)<tab><tab><tab>.then(<tab><tab><tab><tab>lambda page: page<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else None<tab><tab><tab>)<tab><tab>)<tab>return None",0,if requestor_has_access_to_all or page . is_visible,if requestor_has_access_to_all,0.03569919357029252,1e-10,0.4375
"def find(self, pattern):<tab>""""""Find pages in database.""""""<tab>results = self._search_keyword(pattern)<tab>pat = re.compile(""(.*?)(%s)(.*?)( \(.*\))?$"" % re.escape(pattern), re.I)<tab>if results:<tab><tab>for name, keyword, url in results:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keyword = pat.sub(<tab><tab><tab><tab><tab>r""\1\033[1;31m\2\033[0m\3\033[1;33m\4\033[0m"", keyword<tab><tab><tab><tab>)<tab><tab><tab>print(""%s - %s"" % (keyword, name))<tab>else:<tab><tab>raise RuntimeError(""%s: nothing appropriate."" % pattern)",0,if os . isatty ( sys . stdout . fileno ( ) ) :,"if re . search ( r""\1\033[0m"" , keyword ) :",0.01973384179474289,5.401157445454033,0.18888888888888888
"def _certonly_new_request_common(self, mock_client, args=None):<tab>with mock.patch(<tab><tab>""certbot._internal.main._find_lineage_for_domains_and_certname""<tab>) as mock_renewal:<tab><tab>mock_renewal.return_value = (""newcert"", None)<tab><tab>with mock.patch(""certbot._internal.main._init_le_client"") as mock_init:<tab><tab><tab>mock_init.return_value = mock_client<tab><tab><tab><IF-STMT><tab><tab><tab><tab>args = []<tab><tab><tab>args += ""-d foo.bar -a standalone certonly"".split()<tab><tab><tab>self._call(args)",1,if args is None :,if args is None :,0.75,100.00000000000004,1.0
"def __init__(self, *args, **kw):<tab>if len(args) > 1:<tab><tab>raise TypeError(""MultiDict can only be called with one positional "" ""argument"")<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>items = list(args[0].iteritems())<tab><tab>elif hasattr(args[0], ""items""):<tab><tab><tab>items = list(args[0].items())<tab><tab>else:<tab><tab><tab>items = list(args[0])<tab><tab>self._items = items<tab>else:<tab><tab>self._items = []<tab>if kw:<tab><tab>self._items.extend(kw.items())",1,"if hasattr ( args [ 0 ] , ""iteritems"" ) :","if hasattr ( args [ 0 ] , ""iteritems"" ) :",0.75,100.00000000000004,1.0
"def test08_ExceptionTypes(self):<tab>self.assertTrue(issubclass(db.DBError, Exception))<tab>for i, j in db.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(issubclass(j, db.DBError), msg=i)<tab><tab><tab>if i not in (""DBKeyEmptyError"", ""DBNotFoundError""):<tab><tab><tab><tab>self.assertFalse(issubclass(j, KeyError), msg=i)<tab># This two exceptions have two bases<tab>self.assertTrue(issubclass(db.DBKeyEmptyError, KeyError))<tab>self.assertTrue(issubclass(db.DBNotFoundError, KeyError))",0,"if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :","if isinstance ( j , Exception ) :",0.016595411949846713,3.320934179608466,0.2111111111111111
"def _delegate_to_sinks(self, value: Any) -> None:<tab>for sink in self._sinks:<tab><tab>if isinstance(sink, AgentT):<tab><tab><tab>await sink.send(value=value)<tab><tab><IF-STMT><tab><tab><tab>await cast(TopicT, sink).send(value=value)<tab><tab>else:<tab><tab><tab>await maybe_async(cast(Callable, sink)(value))",0,"elif isinstance ( sink , ChannelT ) :","elif isinstance ( sink , TopicT ) :",0.5473017787506802,59.4603557501361,0.6666666666666666
"def _select_block(str_in, start_tag, end_tag):<tab>""""""Select first block delimited by start_tag and end_tag""""""<tab>start_pos = str_in.find(start_tag)<tab>if start_pos < 0:<tab><tab>raise ValueError(""start_tag not found"")<tab>depth = 0<tab>for pos in range(start_pos, len(str_in)):<tab><tab>if str_in[pos] == start_tag:<tab><tab><tab>depth += 1<tab><tab><IF-STMT><tab><tab><tab>depth -= 1<tab><tab>if depth == 0:<tab><tab><tab>break<tab>sel = str_in[start_pos + 1 : pos]<tab>return sel",1,elif str_in [ pos ] == end_tag :,elif str_in [ pos ] == end_tag :,1.0,100.00000000000004,1.0
"def confirm(request):<tab>details = request.session.get(""reauthenticate"")<tab>if not details:<tab><tab>return redirect(""home"")<tab># Monkey patch request<tab>request.user = User.objects.get(pk=details[""user_pk""])<tab>if request.method == ""POST"":<tab><tab>confirm_form = PasswordConfirmForm(request, request.POST)<tab><tab><IF-STMT><tab><tab><tab>request.session.pop(""reauthenticate"")<tab><tab><tab>request.session[""reauthenticate_done""] = True<tab><tab><tab>return redirect(""social:complete"", backend=details[""backend""])<tab>else:<tab><tab>confirm_form = PasswordConfirmForm(request)<tab>context = {""confirm_form"": confirm_form}<tab>context.update(details)<tab>return render(request, ""accounts/confirm.html"", context)",1,if confirm_form . is_valid ( ) :,if confirm_form . is_valid ( ) :,0.75,100.00000000000004,1.0
"def verify_credentials(self):<tab>if self.enabled:<tab><tab>response = requests.get(<tab><tab><tab>""https://api.exotel.com/v1/Accounts/{sid}"".format(sid=self.account_sid),<tab><tab><tab>auth=(self.api_key, self.api_token),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Invalid credentials""))",1,if response . status_code != 200 :,if response . status_code != 200 :,0.75,100.00000000000004,1.0
"def pixbufrenderer(self, column, crp, model, it):<tab>tok = model.get_value(it, 0)<tab>if tok.type == ""class"":<tab><tab>icon = ""class""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>icon = ""method_priv""<tab><tab>elif tok.visibility == ""protected"":<tab><tab><tab>icon = ""method_prot""<tab><tab>else:<tab><tab><tab>icon = ""method""<tab>crp.set_property(""pixbuf"", imagelibrary.pixbufs[icon])",1,"if tok . visibility == ""private"" :","if tok . visibility == ""private"" :",0.75,100.00000000000004,1.0
"def _omit_keywords(self, context):<tab>omitted_kws = 0<tab>for event, elem in context:<tab><tab># Teardowns aren't omitted to allow checking suite teardown status.<tab><tab>omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown""<tab><tab>start = event == ""start""<tab><tab>if omit and start:<tab><tab><tab>omitted_kws += 1<tab><tab>if not omitted_kws:<tab><tab><tab>yield event, elem<tab><tab><IF-STMT><tab><tab><tab>elem.clear()<tab><tab>if omit and not start:<tab><tab><tab>omitted_kws -= 1",0,elif not start :,elif start :,0.09209105436418806,1e-10,0.41666666666666663
"def on_double_click(self, event):<tab># TODO: don't act when the click happens below last item<tab>path = self.get_selected_path()<tab>kind = self.get_selected_kind()<tab>name = self.get_selected_name()<tab>if kind == ""file"":<tab><tab><IF-STMT><tab><tab><tab>self.open_file(path)<tab><tab>else:<tab><tab><tab>self.open_path_with_system_app(path)<tab>elif kind == ""dir"":<tab><tab>self.request_focus_into(path)<tab>return ""break""",0,if self . should_open_name_in_thonny ( name ) :,"if name == ""file"" :",0.019907917998500824,2.673705182447105,0.4772727272727273
"def search_cve(db: DatabaseInterface, product: Product) -> dict:<tab>result = {}<tab>for query_result in db.fetch_multiple(QUERIES[""cve_lookup""]):<tab><tab>cve_entry = CveDbEntry(*query_result)<tab><tab><IF-STMT><tab><tab><tab>result[cve_entry.cve_id] = {<tab><tab><tab><tab>""score2"": cve_entry.cvss_v2_score,<tab><tab><tab><tab>""score3"": cve_entry.cvss_v3_score,<tab><tab><tab><tab>""cpe_version"": build_version_string(cve_entry),<tab><tab><tab>}<tab>return result",0,"if _product_matches_cve ( product , cve_entry ) :",if cve_entry . product == product :,0.020676460041600547,11.708995388048033,0.8585858585858586
"def find_go_files_mtime(app_files):<tab>files, mtime = [], 0<tab>for f, mt in app_files.items():<tab><tab>if not f.endswith("".go""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>files.append(f)<tab><tab>mtime = max(mtime, mt)<tab>return files, mtime",0,if APP_CONFIG . nobuild_files . match ( f ) :,"if not f . endswith ( "".go"" ) :",0.030269723093797447,7.84179508389287,0.4871794871794872
"def wrapper(filename):<tab>mtime = getmtime(filename)<tab>with lock:<tab><tab><IF-STMT><tab><tab><tab>old_mtime, result = cache.pop(filename)<tab><tab><tab>if old_mtime == mtime:<tab><tab><tab><tab># Move to the end<tab><tab><tab><tab>cache[filename] = old_mtime, result<tab><tab><tab><tab>return result<tab>result = function(filename)<tab>with lock:<tab><tab>cache[filename] = mtime, result  # at the end<tab><tab>if len(cache) > max_size:<tab><tab><tab>cache.popitem(last=False)<tab>return result",0,if filename in cache :,if len ( cache ) > max_size :,0.028001459970687266,5.522397783539471,0.3148148148148148
"def Tokenize(s):<tab># type: (str) -> Iterator[Token]<tab>for item in TOKEN_RE.findall(s):<tab><tab># The type checker can't know the true type of item!<tab><tab>item = cast(TupleStr4, item)<tab><tab><IF-STMT><tab><tab><tab>typ = ""number""<tab><tab><tab>val = item[0]<tab><tab>elif item[1]:<tab><tab><tab>typ = ""name""<tab><tab><tab>val = item[1]<tab><tab>elif item[2]:<tab><tab><tab>typ = item[2]<tab><tab><tab>val = item[2]<tab><tab>elif item[3]:<tab><tab><tab>typ = item[3]<tab><tab><tab>val = item[3]<tab><tab>yield Token(typ, val)",1,if item [ 0 ] :,if item [ 0 ] :,0.75,100.00000000000004,1.0
"def _show_encoders(self, *args, **kwargs):<tab>if issubclass(self.current_module.__class__, BasePayload):<tab><tab>encoders = self.current_module.get_encoders()<tab><tab><IF-STMT><tab><tab><tab>headers = (""Encoder"", ""Name"", ""Description"")<tab><tab><tab>print_table(headers, *encoders, max_column_length=100)<tab><tab><tab>return<tab>print_error(""No encoders available"")",1,if encoders :,if encoders :,0.5311706625951745,1e-10,1.0
"def __init__(self):<tab>Builder.__init__(self, commandName=""VCExpress.exe"", formatName=""msvcProject"")<tab>for key in [""VS90COMNTOOLS"", ""VC80COMNTOOLS"", ""VC71COMNTOOLS""]:<tab><tab><IF-STMT><tab><tab><tab>self.programDir = os.path.join(os.environ[key], "".."", ""IDE"")<tab>if self.programDir is None:<tab><tab>for version in [""9.0"", ""8"", "".NET 2003""]:<tab><tab><tab>msvcDir = (<tab><tab><tab><tab>""C:\\Program Files\\Microsoft Visual Studio %s\\Common7\\IDE"" % version<tab><tab><tab>)<tab><tab><tab>if os.path.exists(msvcDir):<tab><tab><tab><tab>self.programDir = msvcDir",0,if os . environ . has_key ( key ) :,if key in os . environ :,0.06410035254389929,14.231728394642222,0.3181818181818182
"def _inner(*args, **kwargs):<tab>component_manager = args[0].component_manager<tab>for condition_name in condition_names:<tab><tab>condition_result, err_msg = component_manager.evaluate_condition(condition_name)<tab><tab><IF-STMT><tab><tab><tab>raise ComponentStartConditionNotMetError(err_msg)<tab>if not component_manager.all_components_running(*components):<tab><tab>raise ComponentsNotStartedError(<tab><tab><tab>f""the following required components have not yet started: {json.dumps(components)}""<tab><tab>)<tab>return method(*args, **kwargs)",1,if not condition_result :,if not condition_result :,0.75,100.00000000000004,1.0
"def _gridconvvalue(self, value):<tab>if isinstance(value, (str, _tkinter.Tcl_Obj)):<tab><tab>try:<tab><tab><tab>svalue = str(value)<tab><tab><tab>if not svalue:<tab><tab><tab><tab>return None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.tk.getdouble(svalue)<tab><tab><tab>else:<tab><tab><tab><tab>return self.tk.getint(svalue)<tab><tab>except (ValueError, TclError):<tab><tab><tab>pass<tab>return value",0,"elif ""."" in svalue :",elif svalue . isdigit ( ) :,0.07854569132828848,9.287528999566801,0.4
"def check_songs():<tab>desc = numeric_phrase(""%d song"", ""%d songs"", len(songs))<tab>with Task(_(""Rescan songs""), desc) as task:<tab><tab>task.copool(check_songs)<tab><tab>for i, song in enumerate(songs):<tab><tab><tab>song = song._song<tab><tab><tab><IF-STMT><tab><tab><tab><tab>app.library.reload(song)<tab><tab><tab>task.update((float(i) + 1) / len(songs))<tab><tab><tab>yield",0,if song in app . library :,if song is not None :,0.16655305992563652,15.207218222740094,0.3333333333333333
"def initialize(self):<tab>nn.init.xavier_uniform_(self.linear.weight.data)<tab>if self.linear.bias is not None:<tab><tab>self.linear.bias.data.uniform_(-1.0, 1.0)<tab>if self.self_layer:<tab><tab>nn.init.xavier_uniform_(self.linear_self.weight.data)<tab><tab><IF-STMT><tab><tab><tab>self.linear_self.bias.data.uniform_(-1.0, 1.0)",0,if self . linear_self . bias is not None :,if self . bias is not None :,0.4690946710361176,57.36212820263841,1.0
"def test_row(self, row):<tab>for idx, test in self.patterns.items():<tab><tab>try:<tab><tab><tab>value = row[idx]<tab><tab>except IndexError:<tab><tab><tab>value = """"<tab><tab>result = test(value)<tab><tab><IF-STMT><tab><tab><tab>if result:<tab><tab><tab><tab>return not self.inverse  # True<tab><tab>else:<tab><tab><tab>if not result:<tab><tab><tab><tab>return self.inverse  # False<tab>if self.any_match:<tab><tab>return self.inverse  # False<tab>else:<tab><tab>return not self.inverse  # True",1,if self . any_match :,if self . any_match :,0.75,100.00000000000004,1.0
"def toterminal(self, tw):<tab>for element in self.chain:<tab><tab>element[0].toterminal(tw)<tab><tab><IF-STMT><tab><tab><tab>tw.line("""")<tab><tab><tab>tw.line(element[2], yellow=True)<tab>super(ExceptionChainRepr, self).toterminal(tw)",0,if element [ 2 ] is not None :,if len ( element ) > 2 :,0.01786335094255824,6.892168295481103,0.21875
"def runMainLoop(self):<tab>""""""The curses gui main loop.""""""<tab># pylint: disable=no-member<tab>#<tab># Do NOT change g.app!<tab>self.curses_app = LeoApp()<tab>stdscr = curses.initscr()<tab>if 1:  # Must follow initscr.<tab><tab>self.dump_keys()<tab>try:<tab><tab>self.curses_app.run()<tab><tab># run calls CApp.main(), which calls CGui.run().<tab>finally:<tab><tab>curses.nocbreak()<tab><tab>stdscr.keypad(0)<tab><tab>curses.echo()<tab><tab>curses.endwin()<tab><tab><IF-STMT><tab><tab><tab>g.pr(""Exiting Leo..."")",0,"if ""shutdown"" in g . app . debug :",if self . curses_app . is_alive ( ) :,0.017675223352396317,7.768562846380176,0.24675324675324675
"def test_chunkcoding(self):<tab>for native, utf8 in zip(*[StringIO(f).readlines() for f in self.tstring]):<tab><tab>u = self.decode(native)[0]<tab><tab>self.assertEqual(u, utf8.decode(""utf-8""))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(native, self.encode(u)[0])",0,if self . roundtriptest :,"if self . charset == ""utf-8"" :",0.11726065783135259,16.784459625186194,0.6
"def reload_sanitize_allowlist(self, explicit=True):<tab>self.sanitize_allowlist = []<tab>try:<tab><tab>with open(self.sanitize_allowlist_file) as f:<tab><tab><tab>for line in f.readlines():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.sanitize_allowlist.append(line.strip())<tab>except OSError:<tab><tab>if explicit:<tab><tab><tab>log.warning(<tab><tab><tab><tab>""Sanitize log file explicitly specified as '%s' but does not exist, continuing with no tools allowlisted."",<tab><tab><tab><tab>self.sanitize_allowlist_file,<tab><tab><tab>)",0,"if not line . startswith ( ""#"" ) :","if line and not line . startswith ( ""#"" ) :",0.522017616824489,75.39221180326287,0.3055555555555556
"def get_all_extensions(subtree=None):<tab>if subtree is None:<tab><tab>subtree = full_extension_tree()<tab>result = []<tab>if isinstance(subtree, dict):<tab><tab>for value in subtree.values():<tab><tab><tab>if isinstance(value, dict):<tab><tab><tab><tab>result += get_all_extensions(value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result += value.extensions<tab><tab><tab>elif isinstance(value, (list, tuple)):<tab><tab><tab><tab>result += value<tab>elif isinstance(subtree, (ContentTypeMapping, ContentTypeDetector)):<tab><tab>result = subtree.extensions<tab>elif isinstance(subtree, (list, tuple)):<tab><tab>result = subtree<tab>return result",0,"elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :","elif isinstance ( value , ContentType ) :",0.2438184685481064,36.06452879987793,0.5619047619047619
"def _configuration_dict_to_commandlist(name, config_dict):<tab>command_list = [""config:%s"" % name]<tab>for key, value in config_dict.items():<tab><tab><IF-STMT><tab><tab><tab>if value:<tab><tab><tab><tab>b = ""true""<tab><tab><tab>else:<tab><tab><tab><tab>b = ""false""<tab><tab><tab>command_list.append(""%s:%s"" % (key, b))<tab><tab>else:<tab><tab><tab>command_list.append(""%s:%s"" % (key, value))<tab>return command_list",0,if type ( value ) is bool :,"if isinstance ( value , bool ) :",0.03916858170756418,14.535768424205482,0.40816326530612246
"def _RewriteModinfo(<tab>self,<tab>modinfo,<tab>obj_kernel_version,<tab>this_kernel_version,<tab>info_strings=None,<tab>to_remove=None,):<tab>new_modinfo = """"<tab>for line in modinfo.split(""\x00""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if to_remove and line.split(""="")[0] == to_remove:<tab><tab><tab>continue<tab><tab>if info_strings is not None:<tab><tab><tab>info_strings.add(line.split(""="")[0])<tab><tab>if line.startswith(""vermagic""):<tab><tab><tab>line = line.replace(obj_kernel_version, this_kernel_version)<tab><tab>new_modinfo += line + ""\x00""<tab>return new_modinfo",0,if not line :,"if line . startswith ( ""#"" ) :",0.03661176184600709,5.522397783539471,0.4
"def zip_random_open_test(self, f, compression):<tab>self.make_test_archive(f, compression)<tab># Read the ZIP archive<tab>with zipfile.ZipFile(f, ""r"", compression) as zipfp:<tab><tab>zipdata1 = []<tab><tab>with zipfp.open(TESTFN) as zipopen1:<tab><tab><tab>while True:<tab><tab><tab><tab>read_data = zipopen1.read(randint(1, 1024))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>zipdata1.append(read_data)<tab><tab>testdata = """".join(zipdata1)<tab><tab>self.assertEqual(len(testdata), len(self.data))<tab><tab>self.assertEqual(testdata, self.data)",1,if not read_data :,if not read_data :,0.75,100.00000000000004,1.0
"def _memoized(*args):<tab>now = time.time()<tab>try:<tab><tab>value, last_update = self.cache[args]<tab><tab>age = now - last_update<tab><tab><IF-STMT><tab><tab><tab>self._call_count = 0<tab><tab><tab>raise AttributeError<tab><tab>if self.ctl:<tab><tab><tab>self._call_count += 1<tab><tab>return value<tab>except (KeyError, AttributeError):<tab><tab>value = func(*args)<tab><tab>if value:<tab><tab><tab>self.cache[args] = (value, now)<tab><tab>return value<tab>except TypeError:<tab><tab>return func(*args)",0,if self . _call_count > self . ctl or age > self . ttl :,if age <= 0 :,0.0074589697276959644,1.4456752008489673,0.21710526315789475
"def on_data(res):<tab>if terminate.is_set():<tab><tab>return<tab>if args.strings and not args.no_content:<tab><tab>if type(res) == tuple:<tab><tab><tab>f, v = res<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f = f.encode(""utf-8"")<tab><tab><tab>if type(v) == unicode:<tab><tab><tab><tab>v = v.encode(""utf-8"")<tab><tab><tab>self.success(""{}: {}"".format(f, v))<tab><tab>elif not args.content_only:<tab><tab><tab>self.success(res)<tab>else:<tab><tab>self.success(res)",1,if type ( f ) == unicode :,if type ( f ) == unicode :,0.75,100.00000000000004,1.0
"def _finalize_setup_keywords(self):<tab>for ep in pkg_resources.iter_entry_points(""distutils.setup_keywords""):<tab><tab>value = getattr(self, ep.name, None)<tab><tab><IF-STMT><tab><tab><tab>ep.require(installer=self.fetch_build_egg)<tab><tab><tab>ep.load()(self, ep.name, value)",1,if value is not None :,if value is not None :,0.75,100.00000000000004,1.0
"def test_attributes_types(self):<tab>if not self.connection.strategy.pooled:<tab><tab><IF-STMT><tab><tab><tab>self.connection.refresh_server_info()<tab><tab>self.assertEqual(<tab><tab><tab>type(self.connection.server.schema.attribute_types[""cn""]), AttributeTypeInfo<tab><tab>)",0,if not self . connection . server . info :,if not self . connection . server . schema . attribute_types :,0.35505889599193163,52.960749334062214,0.75
"def to_key(literal_or_identifier):<tab>""""""returns string representation of this object""""""<tab>if literal_or_identifier[""type""] == ""Identifier"":<tab><tab>return literal_or_identifier[""name""]<tab>elif literal_or_identifier[""type""] == ""Literal"":<tab><tab>k = literal_or_identifier[""value""]<tab><tab>if isinstance(k, float):<tab><tab><tab>return unicode(float_repr(k))<tab><tab>elif ""regex"" in literal_or_identifier:<tab><tab><tab>return compose_regex(k)<tab><tab><IF-STMT><tab><tab><tab>return ""true"" if k else ""false""<tab><tab>elif k is None:<tab><tab><tab>return ""null""<tab><tab>else:<tab><tab><tab>return unicode(k)",1,"elif isinstance ( k , bool ) :","elif isinstance ( k , bool ) :",0.75,100.00000000000004,1.0
"def list2rec(x, test=False):<tab>if test:<tab><tab>vid = ""{}_{:06d}_{:06d}"".format(x[0], int(x[1]), int(x[2]))<tab><tab>label = -1  # label unknown<tab><tab>return vid, label<tab>else:<tab><tab>vid = ""{}_{:06d}_{:06d}"".format(x[1], int(x[2]), int(x[3]))<tab><tab><IF-STMT><tab><tab><tab>vid = ""{}/{}"".format(convert_label(x[0]), vid)<tab><tab>else:<tab><tab><tab>assert level == 1<tab><tab>label = class_mapping[convert_label(x[0])]<tab><tab>return vid, label",0,if level == 2 :,if level == 0 :,0.39477865547525276,53.7284965911771,0.6
"def _expand_env(self, snapcraft_yaml):<tab>environment_keys = [""name"", ""version""]<tab>for key in snapcraft_yaml:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>replacements = environment_to_replacements(<tab><tab><tab>get_snapcraft_global_environment(self.project)<tab><tab>)<tab><tab>snapcraft_yaml[key] = replace_attr(snapcraft_yaml[key], replacements)<tab>return snapcraft_yaml",0,if any ( ( key == env_key for env_key in environment_keys ) ) :,if key not in environment_keys :,0.016977463915441665,7.829904572119011,0.2781954887218045
"def enableCtrls(self):<tab># Check if each ctrl has a requirement or an incompatibility,<tab># look it up, and enable/disable if so<tab>for data in self.storySettingsData:<tab><tab>name = data[""name""]<tab><tab><IF-STMT><tab><tab><tab>if ""requires"" in data:<tab><tab><tab><tab>set = self.getSetting(data[""requires""])<tab><tab><tab><tab>for i in self.ctrls[name]:<tab><tab><tab><tab><tab>i.Enable(set not in [""off"", ""false"", ""0""])",1,if name in self . ctrls :,if name in self . ctrls :,0.75,100.00000000000004,1.0
"def __init__(self, *args, **kwargs):<tab>super(ChallengePhaseCreateSerializer, self).__init__(*args, **kwargs)<tab>context = kwargs.get(""context"")<tab>if context:<tab><tab>challenge = context.get(""challenge"")<tab><tab><IF-STMT><tab><tab><tab>kwargs[""data""][""challenge""] = challenge.pk<tab><tab>test_annotation = context.get(""test_annotation"")<tab><tab>if test_annotation:<tab><tab><tab>kwargs[""data""][""test_annotation""] = test_annotation",1,if challenge :,if challenge :,0.5311706625951745,1e-10,1.0
def set_inactive(self):<tab>for title in self.gramplet_map:<tab><tab>if self.gramplet_map[title].pui:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.gramplet_map[title].pui.active = False,0,"if self . gramplet_map [ title ] . gstate != ""detached"" :",if self .gramplet_map [ title ] . pui . active :,0.2631959372941779,55.94114771766143,0.5619047619047619
"def authenticate(username, password):<tab>try:<tab><tab>u = User.objects.get(username=username)<tab><tab><IF-STMT><tab><tab><tab>userLogger.info(""User logged in : %s"", username)<tab><tab><tab>return u<tab><tab>else:<tab><tab><tab>userLogger.warn(""Attempt to log in to : %s"", username)<tab><tab><tab>return False<tab>except DoesNotExist:<tab><tab>return False",0,"if check_password_hash ( u . password , password ) :","if u . authenticate ( password , password ) :",0.4914922656922091,32.24894519165329,0.6818181818181819
def _check_date(self):<tab>if not self.value:<tab><tab>return None<tab>if not self.allow_date_in_past:<tab><tab>if self.value < self.date_or_datetime().today():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.value = self.date_or_datetime().today()<tab><tab><tab>else:<tab><tab><tab><tab>self.value = self.date_or_datetime().today() + datetime.timedelta(1),0,if self . allow_todays_date :,if self . value > self . date_or_datetime ( ) . today ( ) :,0.0909168838896318,9.313775329024091,0.5072463768115941
"def update(self, E=None, **F):<tab>if E:<tab><tab><IF-STMT><tab><tab><tab># Update with `E` dictionary<tab><tab><tab>for k in E:<tab><tab><tab><tab>self[k] = E[k]<tab><tab>else:<tab><tab><tab># Update with `E` items<tab><tab><tab>for (k, v) in E:<tab><tab><tab><tab>self[k] = v<tab># Update with `F` dictionary<tab>for k in F:<tab><tab>self[k] = F[k]",0,"if hasattr ( E , ""keys"" ) :","if isinstance ( E , dict ) :",0.09166808520089226,21.069764742263047,0.48148148148148145
"def _get_quota_availability(self):<tab>quotas_ok = defaultdict(int)<tab>qa = QuotaAvailability()<tab>qa.queue(*[k for k, v in self._quota_diff.items() if v > 0])<tab>qa.compute(now_dt=self.now_dt)<tab>for quota, count in self._quota_diff.items():<tab><tab><IF-STMT><tab><tab><tab>quotas_ok[quota] = 0<tab><tab><tab>break<tab><tab>avail = qa.results[quota]<tab><tab>if avail[1] is not None and avail[1] < count:<tab><tab><tab>quotas_ok[quota] = min(count, avail[1])<tab><tab>else:<tab><tab><tab>quotas_ok[quota] = count<tab>return quotas_ok",0,if count <= 0 :,if count == 0 :,0.33141502097923065,37.99178428257963,1.0
"def gen_env_vars():<tab>for fd_id, fd in zip(STDIO_DESCRIPTORS, (stdin, stdout, stderr)):<tab><tab>is_atty = fd.isatty()<tab><tab>yield (cls.TTY_ENV_TMPL.format(fd_id), cls.encode_env_var_value(int(is_atty)))<tab><tab><IF-STMT><tab><tab><tab>yield (cls.TTY_PATH_ENV.format(fd_id), os.ttyname(fd.fileno()) or b"""")",1,if is_atty :,if is_atty :,0.5311706625951745,1e-10,1.0
"def _convertDict(self, d):<tab>r = {}<tab>for k, v in d.items():<tab><tab>if isinstance(v, bytes):<tab><tab><tab>v = str(v, ""utf-8"")<tab><tab>elif isinstance(v, list) or isinstance(v, tuple):<tab><tab><tab>v = self._convertList(v)<tab><tab>elif isinstance(v, dict):<tab><tab><tab>v = self._convertDict(v)<tab><tab><IF-STMT><tab><tab><tab>k = str(k, ""utf-8"")<tab><tab>r[k] = v<tab>return r",0,"if isinstance ( k , bytes ) :","elif isinstance ( k , bytes ) :",0.40018302522632676,84.08964152537145,0.6666666666666666
"def get_attribute_value(self, nodeid, attr):<tab>with self._lock:<tab><tab>self.logger.debug(""get attr val: %s %s"", nodeid, attr)<tab><tab>if nodeid not in self._nodes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown)<tab><tab><tab>return dv<tab><tab>node = self._nodes[nodeid]<tab><tab><IF-STMT><tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid)<tab><tab><tab>return dv<tab><tab>attval = node.attributes[attr]<tab><tab>if attval.value_callback:<tab><tab><tab>return attval.value_callback()<tab><tab>return attval.value",1,if attr not in node . attributes :,if attr not in node . attributes :,0.75,100.00000000000004,1.0
"def conninfo_parse(dsn):<tab>ret = {}<tab>length = len(dsn)<tab>i = 0<tab>while i < length:<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>continue<tab><tab>param_match = PARAMETER_RE.match(dsn[i:])<tab><tab>if not param_match:<tab><tab><tab>return<tab><tab>param = param_match.group(1)<tab><tab>i += param_match.end()<tab><tab>if i >= length:<tab><tab><tab>return<tab><tab>value, end = read_param_value(dsn[i:])<tab><tab>if value is None:<tab><tab><tab>return<tab><tab>i += end<tab><tab>ret[param] = value<tab>return ret",0,if dsn [ i ] . isspace ( ) :,if i >= length :,0.014393212535568477,5.484411595600381,0.32051282051282054
"def connect(self, buttons):<tab>for button in buttons:<tab><tab>assert button is not None<tab><tab>handled = False<tab><tab>for handler_idx in range(0, len(self.__signal_handlers)):<tab><tab><tab>(obj_class, signal, handler, handler_id) = self.__signal_handlers[<tab><tab><tab><tab>handler_idx<tab><tab><tab>]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler_id = button.connect(signal, handler)<tab><tab><tab><tab>handled = True<tab><tab><tab>self.__signal_handlers[handler_idx] = (<tab><tab><tab><tab>obj_class,<tab><tab><tab><tab>signal,<tab><tab><tab><tab>handler,<tab><tab><tab><tab>handler_id,<tab><tab><tab>)<tab><tab>assert handled",0,"if isinstance ( button , obj_class ) :",if obj_class is not None :,0.01983074478100545,18.190371142855746,0.2698412698412698
"def _parse_display(display):<tab>""""""Parse an X11 display value""""""<tab>try:<tab><tab>host, dpynum = display.rsplit("":"", 1)<tab><tab>if host.startswith(""["") and host.endswith(""]""):<tab><tab><tab>host = host[1:-1]<tab><tab>idx = dpynum.find(""."")<tab><tab><IF-STMT><tab><tab><tab>screen = int(dpynum[idx + 1 :])<tab><tab><tab>dpynum = dpynum[:idx]<tab><tab>else:<tab><tab><tab>screen = 0<tab>except (ValueError, UnicodeEncodeError):<tab><tab>raise ValueError(""Invalid X11 display"") from None<tab>return host, dpynum, screen",1,if idx >= 0 :,if idx >= 0 :,0.75,100.00000000000004,1.0
"def delete_all(path):<tab>ppath = os.getcwd()<tab>os.chdir(path)<tab>for fn in glob.glob(""*""):<tab><tab>fn_full = os.path.join(path, fn)<tab><tab>if os.path.isdir(fn):<tab><tab><tab>delete_all(fn_full)<tab><tab><IF-STMT><tab><tab><tab>os.remove(fn_full)<tab><tab>elif fn.endswith("".md""):<tab><tab><tab>os.remove(fn_full)<tab><tab>elif DELETE_ALL_OLD:<tab><tab><tab>os.remove(fn_full)<tab>os.chdir(ppath)<tab>os.rmdir(path)",0,"elif fn . endswith ( "".png"" ) :","elif fn . endswith ( "".py"" ) :",0.5473017787506802,70.16879391277372,1.0
"def _sync_get(self, identifier, *args, **kw):<tab>self._mutex.acquire()<tab>try:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self._values[identifier]<tab><tab><tab>else:<tab><tab><tab><tab>self._values[identifier] = value = self.creator(identifier, *args, **kw)<tab><tab><tab><tab>return value<tab><tab>except KeyError:<tab><tab><tab>self._values[identifier] = value = self.creator(identifier, *args, **kw)<tab><tab><tab>return value<tab>finally:<tab><tab>self._mutex.release()",1,if identifier in self . _values :,if identifier in self . _values :,0.75,100.00000000000004,1.0
"def _query_fd(self):<tab>if self.stream is None:<tab><tab>self._last_stat = None, None<tab>else:<tab><tab>try:<tab><tab><tab>st = os.stat(self._filename)<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>self._last_stat = None, None<tab><tab>else:<tab><tab><tab>self._last_stat = st[stat.ST_DEV], st[stat.ST_INO]",1,if e . errno != errno . ENOENT :,if e . errno != errno . ENOENT :,1.0,100.00000000000004,1.0
"def get_place_name(self, place_handle):<tab>""""""Obtain a place name""""""<tab>text = """"<tab>if place_handle:<tab><tab>place = self.dbstate.db.get_place_from_handle(place_handle)<tab><tab><IF-STMT><tab><tab><tab>place_title = place_displayer.display(self.dbstate.db, place)<tab><tab><tab>if place_title != """":<tab><tab><tab><tab>if len(place_title) > 25:<tab><tab><tab><tab><tab>text = place_title[:24] + ""...""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>text = place_title<tab>return text",1,if place :,if place :,0.5311706625951745,1e-10,1.0
"def test_decoder_state(self):<tab># Check that getstate() and setstate() handle the state properly<tab>u = ""abc123""<tab>for encoding in all_unicode_encodings:<tab><tab><IF-STMT><tab><tab><tab>self.check_state_handling_decode(encoding, u, u.encode(encoding))<tab><tab><tab>self.check_state_handling_encode(encoding, u, u.encode(encoding))",0,if encoding not in broken_unicode_with_stateful :,"if encoding != ""utf-8"" :",0.051719732411378776,7.413670083653376,0.5333333333333333
"def cleanup(self):<tab>if os.path.exists(self.meta_gui_dir):<tab><tab>for f in os.listdir(self.meta_gui_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(os.path.join(self.meta_gui_dir, f))",0,"if os . path . splitext ( f ) [ 1 ] == "".desktop"" :","if f . endswith ( "".py"" ) and f . endswith ( "".py"" ) :",0.01104765921360009,5.431360807863856,0.2962962962962963
"def _have_applied_incense(self):<tab>for applied_item in inventory.applied_items().all():<tab><tab>self.logger.info(applied_item)<tab><tab><IF-STMT><tab><tab><tab>mins = format_time(applied_item.expire_ms * 1000)<tab><tab><tab>self.logger.info(<tab><tab><tab><tab>""Not applying incense, currently active: %s, %s minutes remaining"",<tab><tab><tab><tab>applied_item.item.name,<tab><tab><tab><tab>mins,<tab><tab><tab>)<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>self.logger.info("""")<tab><tab><tab>return False<tab>return False",0,if applied_item . expire_ms > 0 :,if applied_item . expiration_ms :,0.09453229110448028,42.500836592944815,0.6363636363636364
"def get_closest_point(self, point):<tab>point = to_point(point)<tab>cp, cd = None, None<tab>for p0, p1 in iter_pairs(self.pts, self.connected):<tab><tab>diff = p1 - p0<tab><tab>l = diff.length<tab><tab>d = diff / l<tab><tab>pp = p0 + d * max(0, min(l, (point - p0).dot(d)))<tab><tab>dist = (point - pp).length<tab><tab><IF-STMT><tab><tab><tab>cp, cd = pp, dist<tab>return cp",0,if not cp or dist < cd :,if cd is not None :,0.12089490894200064,8.22487964923291,0.2
"def process_return(lines):<tab>for line in lines:<tab><tab>m = re.fullmatch(r""(?P<param>\w+)\s+:\s+(?P<type>[\w.]+)"", line)<tab><tab><IF-STMT><tab><tab><tab># Once this is in scanpydoc, we can use the fancy hover stuff<tab><tab><tab>yield f'**{m[""param""]}** : :class:`~{m[""type""]}`'<tab><tab>else:<tab><tab><tab>yield line",1,if m :,if m :,0.5311706625951745,1e-10,1.0
"def _classify(nodes_by_level):<tab>missing, invalid, downloads = [], [], []<tab>for level in nodes_by_level:<tab><tab>for node in level:<tab><tab><tab>if node.binary == BINARY_MISSING:<tab><tab><tab><tab>missing.append(node)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>invalid.append(node)<tab><tab><tab>elif node.binary in (BINARY_UPDATE, BINARY_DOWNLOAD):<tab><tab><tab><tab>downloads.append(node)<tab>return missing, invalid, downloads",1,elif node . binary == BINARY_INVALID :,elif node . binary == BINARY_INVALID :,1.0,100.00000000000004,1.0
"def safe_parse_date(date_hdr):<tab>""""""Parse a Date: or Received: header into a unix timestamp.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>date_hdr = date_hdr.split("";"")[-1].strip()<tab><tab>msg_ts = long(rfc822.mktime_tz(rfc822.parsedate_tz(date_hdr)))<tab><tab>if (msg_ts > (time.time() + 24 * 3600)) or (msg_ts < 1):<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>return msg_ts<tab>except (ValueError, TypeError, OverflowError):<tab><tab>return None",1,"if "";"" in date_hdr :","if "";"" in date_hdr :",0.75,100.00000000000004,1.0
"def _on_change(self):<tab>changed = False<tab>self.save()<tab>for key, value in self.data.items():<tab><tab>if isinstance(value, bool):<tab><tab><tab>if value:<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>if isinstance(value, int):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab><tab>elif value is None:<tab><tab><tab>continue<tab><tab>elif len(value) != 0:<tab><tab><tab>changed = True<tab><tab><tab>break<tab>self._reset_button.disabled = not changed",0,if value != 1 :,if value != 0 :,0.39477865547525276,53.7284965911771,0.6
"def _rewrite_prepend_append(self, string, prepend, append=None):<tab>if append is None:<tab><tab>append = prepend<tab>if not isinstance(string, StringElem):<tab><tab>string = StringElem(string)<tab>string.sub.insert(0, prepend)<tab>if unicode(string).endswith(u""\n""):<tab><tab># Try and remove the last character from the tree<tab><tab>try:<tab><tab><tab>lastnode = string.flatten()[-1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lastnode.sub[-1] = lastnode.sub[-1].rstrip(u""\n"")<tab><tab>except IndexError:<tab><tab><tab>pass<tab><tab>string.sub.append(append + u""\n"")<tab>else:<tab><tab>string.sub.append(append)<tab>return string",0,"if isinstance ( lastnode . sub [ - 1 ] , unicode ) :",if len ( lastnode . sub ) > 0 :,0.1400965076074996,20.252884954471373,0.43790849673202614
"def parse_indentless_sequence_entry(self):<tab>if self.check_token(BlockEntryToken):<tab><tab>token = self.get_token()<tab><tab><IF-STMT><tab><tab><tab>self.states.append(self.parse_indentless_sequence_entry)<tab><tab><tab>return self.parse_block_node()<tab><tab>else:<tab><tab><tab>self.state = self.parse_indentless_sequence_entry<tab><tab><tab>return self.process_empty_scalar(token.end_mark)<tab>token = self.peek_token()<tab>event = SequenceEndEvent(token.start_mark, token.start_mark)<tab>self.state = self.states.pop()<tab>return event",0,"if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :",if self . check_token ( BlockEndToken ) :,0.11803546904711287,33.54930696789255,0.225
"def walk_directory(directory, verbose=False):<tab>""""""Iterates a directory's text files and their contents.""""""<tab>for dir_path, _, filenames in os.walk(directory):<tab><tab>for filename in filenames:<tab><tab><tab>file_path = os.path.join(dir_path, filename)<tab><tab><tab>if os.path.isfile(file_path) and not filename.startswith("".""):<tab><tab><tab><tab>with io.open(file_path, ""r"", encoding=""utf-8"") as file:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>print(""Reading {}"".format(filename))<tab><tab><tab><tab><tab>doc_text = file.read()<tab><tab><tab><tab><tab>yield filename, doc_text",1,if verbose :,if verbose :,0.5311706625951745,1e-10,1.0
"def set_bounds(self, x, y, width, height):<tab>if self.native:<tab><tab># Root level widgets may require vertical adjustment to<tab><tab># account for toolbars, etc.<tab><tab><IF-STMT><tab><tab><tab>vertical_shift = self.frame.vertical_shift<tab><tab>else:<tab><tab><tab>vertical_shift = 0<tab><tab>self.native.Size = Size(width, height)<tab><tab>self.native.Location = Point(x, y + vertical_shift)",0,if self . interface . parent is None :,if self . frame :,0.10610738829520958,19.199242796476852,0.3333333333333333
"def _check_x11(self, command=None, *, exc=None, exit_status=None, **kwargs):<tab>""""""Check requesting X11 forwarding""""""<tab>with (yield from self.connect()) as conn:<tab><tab><IF-STMT><tab><tab><tab>with self.assertRaises(exc):<tab><tab><tab><tab>yield from _create_x11_process(conn, command, **kwargs)<tab><tab>else:<tab><tab><tab>proc = yield from _create_x11_process(conn, command, **kwargs)<tab><tab><tab>yield from proc.wait()<tab><tab><tab>self.assertEqual(proc.exit_status, exit_status)<tab>yield from conn.wait_closed()",1,if exc :,if exc :,0.5311706625951745,1e-10,1.0
"def repr(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>from infogami.infobase.utils import prepr<tab><tab><tab>return prepr(self.obj)<tab><tab>else:<tab><tab><tab>return repr(self.obj)<tab>except:<tab><tab>return ""failed""<tab>return render_template(""admin/memory/object"", self.obj)",0,"if isinstance ( self . obj , ( dict , web . threadeddict ) ) :",if self . _prepr_enabled :,0.012440829806128465,4.831930719842458,0.22282608695652173
"def add(self, tag, values):<tab>if tag not in self.different:<tab><tab>if tag not in self:<tab><tab><tab>self[tag] = values<tab><tab><IF-STMT><tab><tab><tab>self.different.add(tag)<tab><tab><tab>self[tag] = [""""]<tab>self.counts[tag] += 1",0,elif self [ tag ] != values :,elif tag not in self . counts :,0.019640732545025658,6.892168295481103,0.20833333333333331
"def _on_geturl(self, event):<tab>selected = self._status_list.get_selected()<tab>if selected != -1:<tab><tab>object_id = self._status_list.GetItemData(selected)<tab><tab>download_item = self._download_list.get_item(object_id)<tab><tab>url = download_item.url<tab><tab><IF-STMT><tab><tab><tab>clipdata = wx.TextDataObject()<tab><tab><tab>clipdata.SetText(url)<tab><tab><tab>wx.TheClipboard.Open()<tab><tab><tab>wx.TheClipboard.SetData(clipdata)<tab><tab><tab>wx.TheClipboard.Close()",0,if not wx . TheClipboard . IsOpened ( ) :,"if url != """" :",0.013468035777437931,5.08764122072739,0.25274725274725274
"def escape2null(text):<tab>""""""Return a string with escape-backslashes converted to nulls.""""""<tab>parts = []<tab>start = 0<tab>while True:<tab><tab>found = text.find(""\\"", start)<tab><tab><IF-STMT><tab><tab><tab>parts.append(text[start:])<tab><tab><tab>return """".join(parts)<tab><tab>parts.append(text[start:found])<tab><tab>parts.append(""\x00"" + text[found + 1 : found + 2])<tab><tab>start = found + 2  # skip character after escape",1,if found == - 1 :,if found == - 1 :,0.75,100.00000000000004,1.0
def _process_inner_views(self):<tab>for view in self.baseviews:<tab><tab>for inner_class in view.get_uninit_inner_views():<tab><tab><tab>for v in self.baseviews:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>view.get_init_inner_views().append(v),0,"if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :","if isinstance ( v , inner_class ) :",0.23972463590241758,20.76460112463586,0.4311594202898551
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_url(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_app_version_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_method(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 34:<tab><tab><tab>self.set_queue(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100.00000000000004,1.0
"def test_sample_output():<tab>comment = ""SAMPLE OUTPUT""<tab>skip_files = [""__init__.py""]<tab>errors = []<tab>for _file in sorted(MODULE_PATH.iterdir()):<tab><tab>if _file.suffix == "".py"" and _file.name not in skip_files:<tab><tab><tab>with _file.open() as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>errors.append((comment, _file))<tab>if errors:<tab><tab>line = ""Missing sample error(s) detected!\n\n""<tab><tab>for error in errors:<tab><tab><tab>line += ""`{}` is not in module `{}`\n"".format(*error)<tab><tab>print(line[:-1])<tab><tab>assert False",0,if comment not in f . read ( ) :,if comment in f . read ( ) :,0.4690092308819404,71.89393375176813,0.4126984126984127
"def _get_planner(name, path, source):<tab>for klass in _planners:<tab><tab><IF-STMT><tab><tab><tab>LOG.debug(""%r accepted %r (filename %r)"", klass, name, path)<tab><tab><tab>return klass<tab><tab>LOG.debug(""%r rejected %r"", klass, name)<tab>raise ansible.errors.AnsibleError(NO_METHOD_MSG + repr(invocation))",0,"if klass . detect ( path , source ) :",if klass == source :,0.026933810325055336,9.911450612811139,0.47222222222222227
"def _to_string_infix(self, ostream, idx, verbose):<tab>if verbose:<tab><tab>ostream.write("" , "")<tab>else:<tab><tab>hasConst = not (<tab><tab><tab>self._const.__class__ in native_numeric_types and self._const == 0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>idx -= 1<tab><tab>_l = self._coef[id(self._args[idx])]<tab><tab>_lt = _l.__class__<tab><tab>if _lt is _NegationExpression or (_lt in native_numeric_types and _l < 0):<tab><tab><tab>ostream.write("" - "")<tab><tab>else:<tab><tab><tab>ostream.write("" + "")",1,if hasConst :,if hasConst :,0.5311706625951745,1e-10,1.0
"def cluster_info_query(self):<tab>if self._major_version >= 90600:<tab><tab>extra = (<tab><tab><tab>"", CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END,""<tab><tab><tab>"" slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver()""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>extra = ""timeline_id"" + extra + "", pg_catalog.pg_control_checkpoint()""<tab><tab>else:<tab><tab><tab>extra = ""0"" + extra<tab>else:<tab><tab>extra = ""0, NULL, NULL, NULL""<tab>return (""SELECT "" + self.TL_LSN + "", {2}"").format(<tab><tab>self.wal_name, self.lsn_name, extra<tab>)",0,"if self . role == ""standby_leader"" :",if self . _major_version >= 90600 :,0.15306531419355518,15.148694266083963,0.6
"def __init__(self, *args, **kwargs):<tab>self.country = kwargs.pop(""country"")<tab>self.fields_needed = kwargs.pop(""fields_needed"", [])<tab>super(DynamicManagedAccountForm, self).__init__(*args, **kwargs)<tab># build our form using the country specific fields and falling<tab># back to our default set<tab>for f in self.fields_needed:<tab><tab><IF-STMT>  # pragma: no branch<tab><tab><tab>field_name, field = FIELDS_BY_COUNTRY[self.country][f]<tab><tab><tab>self.fields[field_name] = field",0,"if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :",if f in FIELDS_BY_COUNTRY :,0.0714069863440719,29.26985560739962,0.5510204081632654
"def delete_map(self, query=None):<tab>query_map = self.interpolated_map(query=query)<tab>for alias, drivers in six.iteritems(query_map.copy()):<tab><tab>for driver, vms in six.iteritems(drivers.copy()):<tab><tab><tab>for vm_name, vm_details in six.iteritems(vms.copy()):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>query_map[alias][driver].pop(vm_name)<tab><tab><tab>if not query_map[alias][driver]:<tab><tab><tab><tab>query_map[alias].pop(driver)<tab><tab>if not query_map[alias]:<tab><tab><tab>query_map.pop(alias)<tab>return query_map",0,"if vm_details == ""Absent"" :","if vm_details [ ""vm_name"" ] in query_map [ alias ] :",0.0445720099643498,14.576846149722611,0.4722222222222222
"def on_strokes_edited(self):<tab>strokes = self._strokes()<tab>if strokes:<tab><tab>translation = self._engine.raw_lookup(strokes)<tab><tab><IF-STMT><tab><tab><tab>fmt = _(""{strokes} maps to {translation}"")<tab><tab>else:<tab><tab><tab>fmt = _(""{strokes} is not in the dictionary"")<tab><tab>info = self._format_label(fmt, (strokes,), translation)<tab>else:<tab><tab>info = """"<tab>self.strokes_info.setText(info)",0,if translation is not None :,if translation :,0.050438393472541504,1e-10,0.39999999999999997
"def release(self):<tab>tid = _thread.get_ident()<tab>with self.lock:<tab><tab>if self.owner != tid:<tab><tab><tab>raise RuntimeError(""cannot release un-acquired lock"")<tab><tab>assert self.count > 0<tab><tab>self.count -= 1<tab><tab><IF-STMT><tab><tab><tab>self.owner = None<tab><tab><tab>if self.waiters:<tab><tab><tab><tab>self.waiters -= 1<tab><tab><tab><tab>self.wakeup.release()",1,if self . count == 0 :,if self . count == 0 :,0.75,100.00000000000004,1.0
"def _cat_blob(self, gcs_uri):<tab>"""""":py:meth:`cat_file`, minus decompression.""""""<tab>blob = self._get_blob(gcs_uri)<tab>if not blob:<tab><tab>return  # don't cat nonexistent files<tab>start = 0<tab>while True:<tab><tab>end = start + _CAT_CHUNK_SIZE<tab><tab>try:<tab><tab><tab>chunk = blob.download_as_string(start=start, end=end)<tab><tab>except google.api_core.exceptions.RequestRangeNotSatisfiable:<tab><tab><tab>return<tab><tab>yield chunk<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>start = end",0,if len ( chunk ) < _CAT_CHUNK_SIZE :,if not chunk :,0.019930835999227993,2.215745752614824,0.6
"def device_iter(**kwargs):<tab>for dev in backend.enumerate_devices():<tab><tab>d = Device(dev, backend)<tab><tab>tests = (val == _try_getattr(d, key) for key, val in kwargs.items())<tab><tab><IF-STMT><tab><tab><tab>yield d",0,if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,if tests :,0.004127987352981445,1e-10,0.35344827586206895
"def _get_vtkjs(self):<tab>if self._vtkjs is None and self.object is not None:<tab><tab>if isinstance(self.object, string_types) and self.object.endswith("".vtkjs""):<tab><tab><tab>if isfile(self.object):<tab><tab><tab><tab>with open(self.object, ""rb"") as f:<tab><tab><tab><tab><tab>vtkjs = f.read()<tab><tab><tab>else:<tab><tab><tab><tab>data_url = urlopen(self.object)<tab><tab><tab><tab>vtkjs = data_url.read()<tab><tab><IF-STMT><tab><tab><tab>vtkjs = self.object.read()<tab><tab>self._vtkjs = vtkjs<tab>return self._vtkjs",0,"elif hasattr ( self . object , ""read"" ) :","elif isinstance ( self . object , bytes ) :",0.35856898886410005,38.24602282967347,0.5584415584415584
"def _execute_with_error(command, error, message):<tab>try:<tab><tab>cli.invocation = cli.invocation_cls(<tab><tab><tab>cli_ctx=cli,<tab><tab><tab>parser_cls=cli.parser_cls,<tab><tab><tab>commands_loader_cls=cli.commands_loader_cls,<tab><tab><tab>help_cls=cli.help_cls,<tab><tab>)<tab><tab>cli.invocation.execute(command.split())<tab>except CLIError as ex:<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>""{}\nExpected: {}\nActual: {}"".format(message, error, ex)<tab><tab><tab>)<tab><tab>return<tab>except Exception as ex:<tab><tab>raise ex<tab>raise AssertionError(""exception not raised for '{0}'"".format(message))",0,if error not in str ( ex ) :,if ex . args [ 0 ] != error :,0.016658772864844,5.300156689756295,0.20987654320987653
"def ray_intersection(self, p, line):<tab>p = Vector(center(line.sites))<tab>min_r = BIG_FLOAT<tab>nearest = None<tab>for v_i, v_j in self.edges:<tab><tab>bound = LineEquation2D.from_two_points(v_i, v_j)<tab><tab>intersection = bound.intersect_with_line(line)<tab><tab>if intersection is not None:<tab><tab><tab>r = (p - intersection).length<tab><tab><tab># info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nearest = intersection<tab><tab><tab><tab>min_r = r<tab>return nearest",1,if r < min_r :,if r < min_r :,0.75,100.00000000000004,1.0
"def CalculateChecksum(data):<tab># The checksum is just a sum of all the bytes. I swear.<tab>if isinstance(data, bytearray):<tab><tab>total = sum(data)<tab>elif isinstance(data, bytes):<tab><tab><IF-STMT><tab><tab><tab># Python 2 bytes (str) index as single-character strings.<tab><tab><tab>total = sum(map(ord, data))<tab><tab>else:<tab><tab><tab># Python 3 bytes index as numbers (and PY2 empty strings sum() to 0)<tab><tab><tab>total = sum(data)<tab>else:<tab><tab># Unicode strings (should never see?)<tab><tab>total = sum(map(ord, data))<tab>return total & 0xFFFFFFFF",0,"if data and isinstance ( data [ 0 ] , bytes ) :",if PY2 :,0.006889958188542428,1e-10,0.21323529411764708
"def __mul__(self, other: Union[""Tensor"", float]) -> ""Tensor"":<tab>if isinstance(other, Tensor):<tab><tab><IF-STMT><tab><tab><tab>errstr = (<tab><tab><tab><tab>f""Given backens are inconsistent. Found '{self.backend.name}'""<tab><tab><tab><tab>f""and '{other.backend.name}'""<tab><tab><tab>)<tab><tab><tab>raise ValueError(errstr)<tab><tab>other = other.array<tab>array = self.backend.multiply(self.array, other)<tab>return Tensor(array, backend=self.backend)",1,if self . backend . name != other . backend . name :,if self . backend . name != other . backend . name :,1.0,100.00000000000004,1.0
"def next_item(self, direction):<tab>""""""Selects next menu item, based on self._direction""""""<tab>start, i = -1, 0<tab>try:<tab><tab>start = self.items.index(self._selected)<tab><tab>i = start + direction<tab>except:<tab><tab>pass<tab>while True:<tab><tab><IF-STMT><tab><tab><tab># Cannot find valid menu item<tab><tab><tab>self.select(start)<tab><tab><tab>break<tab><tab>if i >= len(self.items):<tab><tab><tab>i = 0<tab><tab><tab>continue<tab><tab>if i < 0:<tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>continue<tab><tab>if self.select(i):<tab><tab><tab>break<tab><tab>i += direction<tab><tab>if start < 0:<tab><tab><tab>start = 0",0,if i == start :,if i == - 1 :,0.127622274935502,43.47208719449914,0.6
"def resolve_none(self, data):<tab># replace None to '_'<tab>for tok_idx in range(len(data)):<tab><tab>for feat_idx in range(len(data[tok_idx])):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[tok_idx][feat_idx] = ""_""<tab>return data",1,if data [ tok_idx ] [ feat_idx ] is None :,if data [ tok_idx ] [ feat_idx ] is None :,0.75,100.00000000000004,1.0
"def distinct(expr, *on):<tab>fields = frozenset(expr.fields)<tab>_on = []<tab>append = _on.append<tab>for n in on:<tab><tab>if isinstance(n, Field):<tab><tab><tab>if n._child.isidentical(expr):<tab><tab><tab><tab>n = n._name<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>if not isinstance(n, _strtypes):<tab><tab><tab>raise TypeError(""on must be a name or field, not: {0}"".format(n))<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""{0} is not a field of {1}"".format(n, expr))<tab><tab>append(n)<tab>return Distinct(expr, tuple(_on))",1,elif n not in fields :,elif n not in fields :,0.75,100.00000000000004,1.0
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_cost().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.add_version(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100.00000000000004,1.0
"def func_std_string(func_name):  # match what old profile produced<tab>if func_name[:2] == (""~"", 0):<tab><tab># special case for built-in functions<tab><tab>name = func_name[2]<tab><tab><IF-STMT><tab><tab><tab>return ""{%s}"" % name[1:-1]<tab><tab>else:<tab><tab><tab>return name<tab>else:<tab><tab>return ""%s:%d(%s)"" % func_name",0,"if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :","if name . startswith ( ""!"" ) :",0.21995662454692788,26.753788181976983,0.5873015873015873
"def f():<tab>try:<tab><tab># Intra-buffer read then buffer-flushing read<tab><tab>for n in cycle([1, 19]):<tab><tab><tab>s = bufio.read(n)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab># list.append() is atomic<tab><tab><tab>results.append(s)<tab>except Exception as e:<tab><tab>errors.append(e)<tab><tab>raise",1,if not s :,if not s :,0.75,100.00000000000004,1.0
"def stop(self):<tab># Try to shut the connection down, but if we get any sort of<tab># errors, go ahead and ignore them.. as we're shutting down anyway<tab>try:<tab><tab>self.rpcserver.stop()<tab><tab>if self.backend_rpcserver:<tab><tab><tab>self.backend_rpcserver.stop()<tab><tab><IF-STMT><tab><tab><tab>self.cluster_rpcserver.stop()<tab>except Exception:<tab><tab>pass<tab>if self.coordination:<tab><tab>try:<tab><tab><tab>coordination.COORDINATOR.stop()<tab><tab>except Exception:<tab><tab><tab>pass<tab>super(Service, self).stop(graceful=True)",1,if self . cluster_rpcserver :,if self . cluster_rpcserver :,0.75,100.00000000000004,1.0
"def download(cls, architecture, path=""./""):<tab>if cls.sanity_check(architecture):<tab><tab>architecture_file = download_file(<tab><tab><tab>cls.architecture_map[architecture], directory=path<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>print(""Coreml model {} is saved in [{}]"".format(architecture, path))<tab><tab>return architecture_file<tab>else:<tab><tab>return None",0,if not architecture_file :,if architecture_file is None :,0.045150550804307965,27.77619034011791,0.36
"def opps_output_converter(kpt_list):<tab>kpts = []<tab>mpii_keys = to_opps_converter.keys()<tab>for mpii_idx in range(0, 16):<tab><tab><IF-STMT><tab><tab><tab>model_idx = to_opps_converter[mpii_idx]<tab><tab><tab>x, y = kpt_list[model_idx]<tab><tab><tab>if x < 0 or y < 0:<tab><tab><tab><tab>kpts += [0.0, 0.0, -1.0]<tab><tab><tab>else:<tab><tab><tab><tab>kpts += [x, y, 1.0]<tab><tab>else:<tab><tab><tab>kpts += [0.0, 0.0, -1.0]<tab>return kpts",1,if mpii_idx in mpii_keys :,if mpii_idx in mpii_keys :,0.75,100.00000000000004,1.0
"def _get_headers(self, headers=None):<tab>request_headers = headers or {}<tab># Auth headers if access_token is present<tab>if self._client.client.config:<tab><tab>config = self._client.client.config<tab><tab>if ""Authorization"" not in request_headers and config.token:<tab><tab><tab>request_headers.update(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""Authorization"": ""{} {}"".format(<tab><tab><tab><tab><tab><tab>config.authentication_type, config.token<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>request_headers.update({config.header: config.header_service})<tab>return request_headers",0,if config . header and config . header_service :,elif config . header_service :,0.14318583270136517,45.691722266180875,0.23232323232323235
"def get_last_traded_prices(cls, trading_pairs: List[str]) -> Dict[str, float]:<tab>results = dict()<tab>async with aiohttp.ClientSession() as client:<tab><tab>resp = await client.get(f""{constants.REST_URL}/tickers"")<tab><tab>resp_json = await resp.json()<tab><tab>for trading_pair in trading_pairs:<tab><tab><tab>resp_record = [<tab><tab><tab><tab>o<tab><tab><tab><tab>for o in resp_json<tab><tab><tab><tab><IF-STMT><tab><tab><tab>][0]<tab><tab><tab>results[trading_pair] = float(resp_record[""price""])<tab>return results",0,"if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )","if o [ ""trading_pair"" ] == trading_pair",0.11260536787341652,27.0381318071177,1.0
"def reset_two_factor_hotp():<tab>uid = request.form[""uid""]<tab>otp_secret = request.form.get(""otp_secret"", None)<tab>if otp_secret:<tab><tab>user = Journalist.query.get(uid)<tab><tab><IF-STMT><tab><tab><tab>return render_template(""admin_edit_hotp_secret.html"", uid=uid)<tab><tab>db.session.commit()<tab><tab>return redirect(url_for(""admin.new_user_two_factor"", uid=uid))<tab>else:<tab><tab>return render_template(""admin_edit_hotp_secret.html"", uid=uid)",0,"if not validate_hotp_secret ( user , otp_secret ) :",if user is None :,0.0168380461076173,1.9026155630072006,0.3181818181818182
"def ctx_for_video(self, vurl):<tab>""Get a context dict for a given video URL""<tab>ctx = self.get_context_dict()<tab>for portal, match, context_fn in self.PORTALS:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>ctx.update(context_fn(vurl))<tab><tab><tab><tab>ctx[""portal""] = portal<tab><tab><tab><tab>break<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>continue<tab>return ctx",0,if match . search ( vurl ) :,if match . match ( vurl ) :,0.5014622369176811,50.000000000000014,0.7333333333333333
"def get(self):<tab>name = request.args.get(""filename"")<tab>if name is not None:<tab><tab>opts = dict()<tab><tab>opts[""type""] = ""episode""<tab><tab>result = guessit(name, options=opts)<tab><tab>res = dict()<tab><tab>if ""episode"" in result:<tab><tab><tab>res[""episode""] = result[""episode""]<tab><tab>else:<tab><tab><tab>res[""episode""] = 0<tab><tab>if ""season"" in result:<tab><tab><tab>res[""season""] = result[""season""]<tab><tab>else:<tab><tab><tab>res[""season""] = 0<tab><tab><IF-STMT><tab><tab><tab>res[""subtitle_language""] = str(result[""subtitle_language""])<tab><tab>return jsonify(data=res)<tab>else:<tab><tab>return """", 400",1,"if ""subtitle_language"" in result :","if ""subtitle_language"" in result :",0.75,100.00000000000004,1.0
"def package_files(package_path, directory_name):<tab>paths = []<tab>directory_path = os.path.join(package_path, directory_name)<tab>for (path, directories, filenames) in os.walk(directory_path):<tab><tab>relative_path = os.path.relpath(path, package_path)<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>paths.append(os.path.join(relative_path, filename))<tab>return paths",0,"if filename [ 0 ] == ""."" :","if filename == ""__init__.py"" :",0.03730445553501224,16.06455374563062,0.7272727272727273
"def parse_simple(d, data):<tab>units = {}<tab>for v in data[d]:<tab><tab>key = v[""name""]<tab><tab>if not key:<tab><tab><tab>continue<tab><tab>key_to_insert = make_key(key)<tab><tab><IF-STMT><tab><tab><tab>index = 2<tab><tab><tab>tmp = f""{key_to_insert}_{index}""<tab><tab><tab>while tmp in units:<tab><tab><tab><tab>index += 1<tab><tab><tab><tab>tmp = f""{key_to_insert}_{index}""<tab><tab><tab>key_to_insert = tmp<tab><tab>units[key_to_insert] = v[""id""]<tab>return units",0,if key_to_insert in units :,if len ( key_to_insert ) > 1 :,0.028001459970687266,34.48444257953326,0.3333333333333333
"def parse_clademodelc(branch_type_no, line_floats, site_classes):<tab>""""""Parse results specific to the clade model C.""""""<tab>if not site_classes or len(line_floats) == 0:<tab><tab>return<tab>for n in range(len(line_floats)):<tab><tab><IF-STMT><tab><tab><tab>site_classes[n][""branch types""] = {}<tab><tab>site_classes[n][""branch types""][branch_type_no] = line_floats[n]<tab>return site_classes",0,"if site_classes [ n ] . get ( ""branch types"" ) is None :",if branch_type_no not in site_classes [ n ] :,0.09986446227124161,29.336180581733043,0.24342105263157893
"def track_modules(self, *modules):<tab>""""""Add module names to the tracked list.""""""<tab>already_tracked = self.session.GetParameter(""autodetect_build_local_tracked"") or []<tab>needed = set(modules)<tab>if not needed.issubset(already_tracked):<tab><tab>needed.update(already_tracked)<tab><tab>with self.session as session:<tab><tab><tab>session.SetParameter(""autodetect_build_local_tracked"", needed)<tab><tab><tab>for module_name in modules:<tab><tab><tab><tab>module_obj = self.GetModuleByName(module_name)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># Clear the module's profile. This will force it to<tab><tab><tab><tab><tab># reload a new profile.<tab><tab><tab><tab><tab>module_obj.profile = None",1,if module_obj :,if module_obj :,0.5311706625951745,1e-10,1.0
"def set_job_on_hold(self, value, blocking=True):<tab>trigger = False<tab># don't run any locking code beyond this...<tab>if not self._job_on_hold.acquire(blocking=blocking):<tab><tab>return False<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self._job_on_hold.set()<tab><tab>else:<tab><tab><tab>self._job_on_hold.clear()<tab><tab><tab>if self._job_on_hold.counter == 0:<tab><tab><tab><tab>trigger = True<tab>finally:<tab><tab>self._job_on_hold.release()<tab># locking code is now safe to run again<tab>if trigger:<tab><tab>self._continue_sending()<tab>return True",1,if value :,if value :,0.5311706625951745,1e-10,1.0
"def moveToThreadNext(self):<tab>""""""Move a position to threadNext position.""""""<tab>p = self<tab>if p.v:<tab><tab><IF-STMT><tab><tab><tab>p.moveToFirstChild()<tab><tab>elif p.hasNext():<tab><tab><tab>p.moveToNext()<tab><tab>else:<tab><tab><tab>p.moveToParent()<tab><tab><tab>while p:<tab><tab><tab><tab>if p.hasNext():<tab><tab><tab><tab><tab>p.moveToNext()<tab><tab><tab><tab><tab>break  # found<tab><tab><tab><tab>p.moveToParent()<tab><tab><tab># not found.<tab>return p",0,if p . v . children :,if p . hasFirstChild ( ) :,0.09056531419355518,26.269098944241588,0.4761904761904762
"def best_image(width, height):<tab># A heuristic for finding closest sized image to required size.<tab>image = images[0]<tab>for img in images:<tab><tab><IF-STMT><tab><tab><tab># Exact match always used<tab><tab><tab>return img<tab><tab>elif img.width >= width and img.width * img.height > image.width * image.height:<tab><tab><tab># At least wide enough, and largest area<tab><tab><tab>image = img<tab>return image",1,if img . width == width and img . height == height :,if img . width == width and img . height == height :,1.0,100.00000000000004,1.0
"def _check_input_types(self):<tab>if len(self.base_features) == 0:<tab><tab>return True<tab>input_types = self.primitive.input_types<tab>if input_types is not None:<tab><tab><IF-STMT><tab><tab><tab>input_types = [input_types]<tab><tab>for t in input_types:<tab><tab><tab>zipped = list(zip(t, self.base_features))<tab><tab><tab>if all([issubclass(f.variable_type, v) for v, f in zipped]):<tab><tab><tab><tab>return True<tab>else:<tab><tab>return True<tab>return False",0,if type ( input_types [ 0 ] ) != list :,"if not isinstance ( input_types , list ) :",0.02715112201222712,21.241494252828044,0.42857142857142855
"def get_result(self):<tab>result_list = []<tab>exc_info = None<tab>for f in self.children:<tab><tab>try:<tab><tab><tab>result_list.append(f.get_result())<tab><tab>except Exception as e:<tab><tab><tab>if exc_info is None:<tab><tab><tab><tab>exc_info = sys.exc_info()<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>app_log.error(""Multiple exceptions in yield list"", exc_info=True)<tab>if exc_info is not None:<tab><tab>raise_exc_info(exc_info)<tab>if self.keys is not None:<tab><tab>return dict(zip(self.keys, result_list))<tab>else:<tab><tab>return list(result_list)",0,"if not isinstance ( e , self . quiet_exceptions ) :",if len ( result_list ) > 1 :,0.014083696926176809,4.648378982882215,0.23214285714285715
"def _update_learning_params(self):<tab>model = self.model<tab>hparams = self.hparams<tab>fd = self.runner.feed_dict<tab>step_num = self.step_num<tab>if hparams.model_type == ""resnet_tf"":<tab><tab>if step_num < hparams.lrn_step:<tab><tab><tab>lrn_rate = hparams.mom_lrn<tab><tab><IF-STMT><tab><tab><tab>lrn_rate = hparams.mom_lrn / 10<tab><tab>elif step_num < 35000:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 100<tab><tab>else:<tab><tab><tab>lrn_rate = hparams.mom_lrn / 1000<tab><tab>fd[model.lrn_rate] = lrn_rate",0,elif step_num < 30000 :,elif step_num < 100 :,0.39287202148494,64.34588841607616,0.5
"def topic_exists(self, arn):<tab>response = self._conn.get_all_topics()<tab>topics = response[""ListTopicsResponse""][""ListTopicsResult""][""Topics""]<tab>current_topics = []<tab>if len(topics) > 0:<tab><tab>for topic in topics:<tab><tab><tab>topic_arn = topic[""TopicArn""]<tab><tab><tab>current_topics.append(topic_arn)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",1,if arn in current_topics :,if arn in current_topics :,0.75,100.00000000000004,1.0
"def assertStartsWith(self, expectedPrefix, text, msg=None):<tab>if not text.startswith(expectedPrefix):<tab><tab><IF-STMT><tab><tab><tab>text = text[: len(expectedPrefix) + 5] + ""...""<tab><tab>standardMsg = ""{} not found at the start of {}"".format(<tab><tab><tab>repr(expectedPrefix), repr(text)<tab><tab>)<tab><tab>self.fail(self._formatMessage(msg, standardMsg))",0,if len ( expectedPrefix ) + 5 < len ( text ) :,if msg is None :,0.008909900253808077,2.564755813286796,0.20833333333333334
"def validate_memory(self, value):<tab>for k, v in value.viewitems():<tab><tab><IF-STMT>  # use NoneType to unset a value<tab><tab><tab>continue<tab><tab>if not re.match(PROCTYPE_MATCH, k):<tab><tab><tab>raise serializers.ValidationError(""Process types can only contain [a-z]"")<tab><tab>if not re.match(MEMLIMIT_MATCH, str(v)):<tab><tab><tab>raise serializers.ValidationError(<tab><tab><tab><tab>""Limit format: <number><unit>, where unit = B, K, M or G""<tab><tab><tab>)<tab>return value",0,if v is None :,if k is None :,0.39477865547525276,42.72870063962342,0.6666666666666666
"def open(self) -> ""KeyValueJsonDb"":<tab>""""""Create a new data base or open existing one""""""<tab>if os.path.exists(self._name):<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""%s exists and is not a file"" % self._name)<tab><tab>try:<tab><tab><tab>with open(self._name, ""r"") as _in:<tab><tab><tab><tab>self.set_records(json.load(_in))<tab><tab>except json.JSONDecodeError:<tab><tab><tab># file corrupted, reset it.<tab><tab><tab>self.commit()<tab>else:<tab><tab># make sure path exists<tab><tab>mkpath(os.path.dirname(self._name))<tab><tab>self.commit()<tab>return self",1,if not os . path . isfile ( self . _name ) :,if not os . path . isfile ( self . _name ) :,0.75,100.00000000000004,1.0
"def _calculate(self):<tab>before = self.before.data<tab>after = self.after.data<tab>self.deleted = {}<tab>self.updated = {}<tab>self.created = after.copy()<tab>for path, f in before.items():<tab><tab><IF-STMT><tab><tab><tab>self.deleted[path] = f<tab><tab><tab>continue<tab><tab>del self.created[path]<tab><tab>if f.mtime < after[path].mtime:<tab><tab><tab>self.updated[path] = after[path]",0,if path not in after :,if self . created [ path ] is None :,0.021554938761049226,5.522397783539471,0.18888888888888888
"def cache_sqs_queues_across_accounts() -> bool:<tab>function: str = f""{__name__}.{sys._getframe().f_code.co_name}""<tab># First, get list of accounts<tab>accounts_d: list = async_to_sync(get_account_id_to_name_mapping)()<tab># Second, call tasks to enumerate all the roles across all accounts<tab>for account_id in accounts_d.keys():<tab><tab><IF-STMT><tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab><tab>else:<tab><tab><tab>if account_id in config.get(""celery.test_account_ids"", []):<tab><tab><tab><tab>cache_sqs_queues_for_account.delay(account_id)<tab>stats.count(f""{function}.success"")<tab>return True",0,"if config . get ( ""environment"" ) == ""prod"" :","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",0.1333536585475483,17.855149299161603,0.3894736842105263
"def remove(self, path, config=None, error_on_path=False, defaults=None):<tab>if not path:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>return<tab>if config is not None or defaults is not None:<tab><tab><IF-STMT><tab><tab><tab>config = self._config<tab><tab>if defaults is None:<tab><tab><tab>defaults = dict(self._map.parents)<tab><tab>chain = HierarchicalChainMap(config, defaults)<tab>else:<tab><tab>chain = self._map<tab>try:<tab><tab>chain.del_by_path(path)<tab><tab>self._mark_dirty()<tab>except KeyError:<tab><tab>if error_on_path:<tab><tab><tab>raise NoSuchSettingsPath()<tab><tab>pass",1,if config is None :,if config is None :,0.75,100.00000000000004,1.0
"def PopulateProjectId(project_id=None):<tab>""""""Fills in a project_id from the boto config file if one is not provided.""""""<tab>if not project_id:<tab><tab>default_id = boto.config.get_value(""GSUtil"", ""default_project_id"")<tab><tab><IF-STMT><tab><tab><tab>raise ProjectIdException(""MissingProjectId"")<tab><tab>return default_id<tab>return project_id",0,if not default_id :,if default_id is None :,0.045150550804307965,27.77619034011791,0.36
"def set(self, name, value):<tab>with self._object_cache_lock:<tab><tab>old_value = self._object_cache.get(name)<tab><tab>ret = not old_value or int(old_value.metadata.resource_version) < int(<tab><tab><tab>value.metadata.resource_version<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._object_cache[name] = value<tab>return ret, old_value",1,if ret :,if ret :,0.5311706625951745,1e-10,1.0
"def remove(self, url):<tab>try:<tab><tab>i = self.items.index(url)<tab>except (ValueError, IndexError):<tab><tab>pass<tab>else:<tab><tab>was_selected = i in self.selectedindices()<tab><tab>self.list.delete(i)<tab><tab>del self.items[i]<tab><tab>if not self.items:<tab><tab><tab>self.mp.hidepanel(self.name)<tab><tab><IF-STMT><tab><tab><tab>if i >= len(self.items):<tab><tab><tab><tab>i = len(self.items) - 1<tab><tab><tab>self.list.select_set(i)",0,elif was_selected :,if was_selected :,0.11293884852539707,1e-10,0.3333333333333333
"def add_directory_csv_files(dir_path, paths=None):<tab>if not paths:<tab><tab>paths = []<tab>for p in listdir(dir_path):<tab><tab>path = join(dir_path, p)<tab><tab><IF-STMT><tab><tab><tab># call recursively for each dir<tab><tab><tab>paths = add_directory_csv_files(path, paths)<tab><tab>elif isfile(path) and path.endswith("".csv""):<tab><tab><tab># add every file to the list<tab><tab><tab>paths.append(path)<tab>return paths",1,if isdir ( path ) :,if isdir ( path ) :,0.75,100.00000000000004,1.0
"def _get_client(rp_mapping, resource_provider):<tab>for key, value in rp_mapping.items():<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, dict):<tab><tab><tab><tab>return GeneralPrivateEndpointClient(<tab><tab><tab><tab><tab>key,<tab><tab><tab><tab><tab>value[""api_version""],<tab><tab><tab><tab><tab>value[""support_list_or_not""],<tab><tab><tab><tab><tab>value[""resource_get_api_version""],<tab><tab><tab><tab>)<tab><tab><tab>return value()<tab>raise CLIError(<tab><tab>""Resource type must be one of {}"".format("", "".join(rp_mapping.keys()))<tab>)",0,if str . lower ( key ) == str . lower ( resource_provider ) :,if resource_provider == key :,0.008113400078521477,8.329134759167514,0.36363636363636365
"def compute_rule_hash(self, rule):<tab>buf = ""%d-%d-%s-"" % (<tab><tab>rule.get(""FromPort"", 0) or 0,<tab><tab>rule.get(""ToPort"", 0) or 0,<tab><tab>rule.get(""IpProtocol"", ""-1"") or ""-1"",<tab>)<tab>for a, ke in self.RULE_ATTRS:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ev = [e[ke] for e in rule[a]]<tab><tab>ev.sort()<tab><tab>for e in ev:<tab><tab><tab>buf += ""%s-"" % e<tab># mask to generate the same numeric value across all Python versions<tab>return zlib.crc32(buf.encode(""ascii"")) & 0xFFFFFFFF",0,if a not in rule :,if not rule [ a ] :,0.02790678127500039,9.820366272512825,0.3
"def analysis_sucess_metrics(analysis_time: float, allow_exception=False):<tab>try:<tab><tab>anchore_engine.subsys.metrics.counter_inc(name=""anchore_analysis_success"")<tab><tab>anchore_engine.subsys.metrics.histogram_observe(<tab><tab><tab>""anchore_analysis_time_seconds"",<tab><tab><tab>analysis_time,<tab><tab><tab>buckets=ANALYSIS_TIME_SECONDS_BUCKETS,<tab><tab><tab>status=""success"",<tab><tab>)<tab>except:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing""<tab><tab><tab>)",1,if allow_exception :,if allow_exception :,0.5311706625951745,1e-10,1.0
"def decide_file_icon(file):<tab>if file.state == File.ERROR:<tab><tab>return FileItem.icon_error<tab>elif isinstance(file.parent, Track):<tab><tab><IF-STMT><tab><tab><tab>return FileItem.icon_saved<tab><tab>elif file.state == File.PENDING:<tab><tab><tab>return FileItem.match_pending_icons[int(file.similarity * 5 + 0.5)]<tab><tab>else:<tab><tab><tab>return FileItem.match_icons[int(file.similarity * 5 + 0.5)]<tab>elif file.state == File.PENDING:<tab><tab>return FileItem.icon_file_pending<tab>else:<tab><tab>return FileItem.icon_file",0,if file . state == File . NORMAL :,if file . state == File . SCREEN :,0.62709085524794,78.25422900366438,0.6666666666666666
"def deleteMenu(self, menuName):<tab>try:<tab><tab>menu = self.getMenu(menuName)<tab><tab><IF-STMT><tab><tab><tab>self.destroy(menu)<tab><tab><tab>self.destroyMenu(menuName)<tab><tab>else:<tab><tab><tab>g.es(""can't delete menu:"", menuName)<tab>except Exception:<tab><tab>g.es(""exception deleting"", menuName, ""menu"")<tab><tab>g.es_exception()",1,if menu :,if menu :,0.5311706625951745,1e-10,1.0
"def parser(cls, buf):<tab>(type_, code, csum) = struct.unpack_from(cls._PACK_STR, buf)<tab>msg = cls(type_, code, csum)<tab>offset = cls._MIN_LEN<tab>if len(buf) > offset:<tab><tab>cls_ = cls._ICMPV6_TYPES.get(type_, None)<tab><tab><IF-STMT><tab><tab><tab>msg.data = cls_.parser(buf, offset)<tab><tab>else:<tab><tab><tab>msg.data = buf[offset:]<tab>return msg, None, None",1,if cls_ :,if cls_ :,0.5311706625951745,1e-10,1.0
"def _load_dataset_area(self, dsid, file_handlers, coords):<tab>""""""Get the area for *dsid*.""""""<tab>try:<tab><tab>return self._load_area_def(dsid, file_handlers)<tab>except NotImplementedError:<tab><tab>if any(x is None for x in coords):<tab><tab><tab>logger.warning(""Failed to load coordinates for '{}'"".format(dsid))<tab><tab><tab>return None<tab><tab>area = self._make_area_from_coords(coords)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""No coordinates found for %s"", str(dsid))<tab><tab>return area",1,if area is None :,if area is None :,0.75,100.00000000000004,1.0
"def __getattr__(self, name):<tab>if Popen.verbose:<tab><tab>sys.stdout.write(""Getattr: %s..."" % name)<tab>if name in Popen.__slots__:<tab><tab>return object.__getattribute__(self, name)<tab>else:<tab><tab>if self.popen is not None:<tab><tab><tab>if Popen.verbose:<tab><tab><tab><tab>print(""from Popen"")<tab><tab><tab>return getattr(self.popen, name)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.emu_wait<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""subprocess emulation: not implemented: %s"" % name)",0,"if name == ""wait"" :",if self . emu_wait is not None :,0.026407399022921448,5.522397783539471,0.23809523809523808
"def update(self, time_delta):<tab>super().update(time_delta)<tab>n = self.menu.selected_option<tab>if n == self.last:<tab><tab>return<tab>self.last = n<tab>s = """"<tab>for i in range(len(self.files)):<tab><tab><IF-STMT><tab><tab><tab>for l in open(self.files[i][1]):<tab><tab><tab><tab>x = l.strip()<tab><tab><tab><tab>if len(x) > 1 and x[0] == ""#"":<tab><tab><tab><tab><tab>x = ""<b><u>"" + x[1:] + "" </u></b>""<tab><tab><tab><tab>s += x + ""<br>""<tab>self.set_text(s)",0,if self . files [ i ] [ 0 ] == n :,"if self . files [ i ] [ 0 ] == ""#"" :",0.5472061395603371,73.67565054628355,0.8476190476190476
"def wrapper(*args, **kwargs):<tab>list_args, empty = _apply_defaults(func, args, kwargs)<tab>if len(dimensions) > len(list_args):<tab><tab>raise TypeError(<tab><tab><tab>""%s takes %i parameters, but %i dimensions were passed""<tab><tab><tab>% (func.__name__, len(list_args), len(dimensions))<tab><tab>)<tab>for dim, value in zip(dimensions, list_args):<tab><tab>if dim is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>val_dim = ureg.get_dimensionality(value)<tab><tab><tab>raise DimensionalityError(value, ""a quantity of"", val_dim, dim)<tab>return func(*args, **kwargs)",0,if not ureg . Quantity ( value ) . check ( dim ) :,"if dim == ""quantity"" :",0.008376751410488981,3.4331054109918173,0.21710526315789475
"def _check(self, name, size=None, *extra):<tab>func = getattr(imageop, name)<tab>for height in VALUES:<tab><tab>for width in VALUES:<tab><tab><tab>strlen = abs(width * height)<tab><tab><tab>if size:<tab><tab><tab><tab>strlen *= size<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = ""A"" * strlen<tab><tab><tab>else:<tab><tab><tab><tab>data = AAAAA<tab><tab><tab>if size:<tab><tab><tab><tab>arguments = (data, size, width, height) + extra<tab><tab><tab>else:<tab><tab><tab><tab>arguments = (data, width, height) + extra<tab><tab><tab>try:<tab><tab><tab><tab>func(*arguments)<tab><tab><tab>except (ValueError, imageop.error):<tab><tab><tab><tab>pass",0,if strlen < MAX_LEN :,ifstrlen > 0 :,0.027239257394205144,7.545383788761362,0.2
"def wait_send_all_might_not_block(self) -> None:<tab>with self._send_conflict_detector:<tab><tab><IF-STMT><tab><tab><tab>raise trio.ClosedResourceError(""file was already closed"")<tab><tab>try:<tab><tab><tab>await trio.lowlevel.wait_writable(self._fd_holder.fd)<tab><tab>except BrokenPipeError as e:<tab><tab><tab># kqueue: raises EPIPE on wait_writable instead<tab><tab><tab># of sending, which is annoying<tab><tab><tab>raise trio.BrokenResourceError from e",0,if self . _fd_holder . closed :,if self . _closed :,0.15703229110448028,31.02451704053729,0.7222222222222222
"def parse_win_proxy(val):<tab>proxies = []<tab>for p in val.split("";""):<tab><tab>if ""="" in p:<tab><tab><tab>tab = p.split(""="", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tab[0] = ""SOCKS4""<tab><tab><tab>proxies.append(<tab><tab><tab><tab>(tab[0].upper(), tab[1], None, None)<tab><tab><tab>)  # type, addr:port, username, password<tab><tab>else:<tab><tab><tab>proxies.append((""HTTP"", p, None, None))<tab>return proxies",0,"if tab [ 0 ] == ""socks"" :",if len ( tab ) < 2 :,0.019345087832959386,4.995138898472386,0.3148148148148148
"def _super_function(args):<tab>passed_class, passed_self = args.get_arguments([""type"", ""self""])<tab>if passed_self is None:<tab><tab>return passed_class<tab>else:<tab><tab># pyclass = passed_self.get_type()<tab><tab>pyclass = passed_class<tab><tab>if isinstance(pyclass, pyobjects.AbstractClass):<tab><tab><tab>supers = pyclass.get_superclasses()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return pyobjects.PyObject(supers[0])<tab><tab>return passed_self",0,if supers :,if len ( supers ) == 1 :,0.046522600101893324,1e-10,0.36
"def update_output_mintime(job):<tab>try:<tab><tab>return output_mintime[job]<tab>except KeyError:<tab><tab>for job_ in chain([job], self.depending[job]):<tab><tab><tab>try:<tab><tab><tab><tab>t = output_mintime[job_]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>t = job_.output_mintime<tab><tab><tab><IF-STMT><tab><tab><tab><tab>output_mintime[job] = t<tab><tab><tab><tab>return<tab><tab>output_mintime[job] = None",1,if t is not None :,if t is not None :,0.75,100.00000000000004,1.0
"def get_list_of_strings_to_mongo_objects(self, notifications_list=None):<tab>result = []<tab>if len(notifications_list) > 0:<tab><tab>for x in notifications_list:<tab><tab><tab>split_provider_id = x.split("":"")  # email:id<tab><tab><tab>if len(split_provider_id) == 2:<tab><tab><tab><tab>_id = split_provider_id[1]<tab><tab><tab><tab>cursor = self.get_by_id(_id)<tab><tab><tab><tab><IF-STMT>  # Append if exists<tab><tab><tab><tab><tab>result.append(cursor)<tab>return result",1,if cursor :,if cursor :,0.5311706625951745,1e-10,1.0
"def stop(self):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.task_queue.put(None)<tab><tab>self.result_queue.put(None)<tab><tab>process = self.process<tab><tab>self.process = None<tab><tab>self.task_queue = None<tab><tab>self.result_queue = None<tab>process.join(timeout=0.1)<tab>if process.exitcode is None:<tab><tab>os.kill(process.pid, signal.SIGKILL)<tab><tab>process.join()",0,if not self . process :,if self . process is None :,0.10494632798085189,27.77619034011791,0.2571428571428572
"def on_api_command(self, command, data):<tab>if command == ""select"":<tab><tab>if not Permissions.PLUGIN_ACTION_COMMAND_PROMPT_INTERACT.can():<tab><tab><tab>return flask.abort(403, ""Insufficient permissions"")<tab><tab><IF-STMT><tab><tab><tab>return flask.abort(409, ""No active prompt"")<tab><tab>choice = data[""choice""]<tab><tab>if not isinstance(choice, int) or not self._prompt.validate_choice(choice):<tab><tab><tab>return flask.abort(<tab><tab><tab><tab>400, ""{!r} is not a valid value for choice"".format(choice)<tab><tab><tab>)<tab><tab>self._answer_prompt(choice)",0,if self . _prompt is None :,"if ""choice"" not in data :",0.07181741358197796,6.567274736060395,0.25
"def application_openFiles_(self, nsapp, filenames):<tab># logging.info('[osx] file open')<tab># logging.info('[osx] file : %s' % (filenames))<tab>for filename in filenames:<tab><tab>logging.info(""[osx] receiving from macOS : %s"", filename)<tab><tab><IF-STMT><tab><tab><tab>if sabnzbd.filesystem.get_ext(filename) in VALID_ARCHIVES + VALID_NZB_FILES:<tab><tab><tab><tab>sabnzbd.add_nzbfile(filename, keep=True)",1,if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,0.75,100.00000000000004,1.0
"def test_error_through_destructor(self):<tab># Test that the exception state is not modified by a destructor,<tab># even if close() fails.<tab>rawio = self.CloseFailureIO()<tab>with support.catch_unraisable_exception() as cm:<tab><tab>with self.assertRaises(AttributeError):<tab><tab><tab>self.tp(rawio).xyzzy<tab><tab><IF-STMT><tab><tab><tab>self.assertIsNone(cm.unraisable)<tab><tab>elif cm.unraisable is not None:<tab><tab><tab>self.assertEqual(cm.unraisable.exc_type, OSError)",0,if not IOBASE_EMITS_UNRAISABLE :,"if hasattr ( cm , ""unraisable"" ) :",0.03469219238104862,4.990049701936832,0.38181818181818183
"def http_wrapper(self, url, postdata={}):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>f = urllib.urlopen(url, postdata)<tab><tab>else:<tab><tab><tab>f = urllib.urlopen(url)<tab><tab>response = f.read()<tab>except:<tab><tab>import traceback<tab><tab>import logging, sys<tab><tab>cla, exc, tb = sys.exc_info()<tab><tab>logging.error(url)<tab><tab>if postdata:<tab><tab><tab>logging.error(""with post data"")<tab><tab>else:<tab><tab><tab>logging.error(""without post data"")<tab><tab>logging.error(exc.args)<tab><tab>logging.error(traceback.format_tb(tb))<tab><tab>response = """"<tab>return response",0,if postdata != { } :,if postdata :,0.1129383934725415,1e-10,1.0
"def check_single_file(fn, fetchuri):<tab>""""""Determine if a single downloaded file is something we can't handle""""""<tab>with open(fn, ""r"", errors=""surrogateescape"") as f:<tab><tab><IF-STMT><tab><tab><tab>logger.error(<tab><tab><tab><tab>'Fetching ""%s"" returned a single HTML page - check the URL is correct and functional'<tab><tab><tab><tab>% fetchuri<tab><tab><tab>)<tab><tab><tab>sys.exit(1)",0,"if ""<html"" in f . read ( 100 ) . lower ( ) :",if fetchuri not in f . read ( ) :,0.2220944868373715,26.089696959105602,0.2222222222222222
"def update_properties(self, update_dict):<tab>signed_attribute_changed = False<tab>for k, value in update_dict.items():<tab><tab>if getattr(self, k) != value:<tab><tab><tab>setattr(self, k, value)<tab><tab><tab>signed_attribute_changed = signed_attribute_changed or (<tab><tab><tab><tab>k in self.payload_arguments<tab><tab><tab>)<tab>if signed_attribute_changed:<tab><tab><IF-STMT><tab><tab><tab>self.status = UPDATED<tab><tab>self.timestamp = clock.tick()<tab><tab>self.sign()<tab>return self",0,if self . status != NEW :,if self . status == UPDATED :,0.4711135200865855,38.260294162784454,0.6666666666666666
"def clean_items(event, items, variations):<tab>for item in items:<tab><tab>if event != item.event:<tab><tab><tab>raise ValidationError(_(""One or more items do not belong to this event.""))<tab><tab>if item.has_variations:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>_(<tab><tab><tab><tab><tab><tab>""One or more items has variations but none of these are in the variations list.""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)",0,if not any ( var . item == item for var in variations ) :,if variations not in item . variations :,0.11011654639336446,3.30451489798952,0.26455026455026454
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_status().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.add_doc_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def connections(self):<tab># Connections look something like this:<tab># socket:[102422]<tab>fds = self.open_files<tab>socket = ""socket:[""<tab>result = []<tab>functions = [pwndbg.net.tcp, pwndbg.net.unix, pwndbg.net.netlink]<tab>for fd, path in fds.items():<tab><tab>if socket not in path:<tab><tab><tab>continue<tab><tab>inode = path[len(socket) : -1]<tab><tab>inode = int(inode)<tab><tab>for func in functions:<tab><tab><tab>for x in func():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>x.fd = fd<tab><tab><tab><tab><tab>result.append(x)<tab>return tuple(result)",1,if x . inode == inode :,if x . inode == inode :,1.0,100.00000000000004,1.0
"def _movement_finished(self):<tab>if self.in_ship_map:<tab><tab># if the movement somehow stops, the position sticks, and the unit isn't at next_target any more<tab><tab><IF-STMT><tab><tab><tab>ship = self.session.world.ship_map.get(self._next_target.to_tuple())<tab><tab><tab>if ship is not None and ship() is self:<tab><tab><tab><tab>del self.session.world.ship_map[self._next_target.to_tuple()]<tab>super()._movement_finished()",1,if self . _next_target is not None :,if self . _next_target is not None :,0.75,100.00000000000004,1.0
"def print_addresses(self):<tab>p = 3<tab>tmp_str = ""[""<tab>if self.get_len() >= 7:  # at least one complete IP address<tab><tab>while 1:<tab><tab><tab>if p + 1 == self.get_ptr():<tab><tab><tab><tab>tmp_str += ""#""<tab><tab><tab>tmp_str += self.get_ip_address(p)<tab><tab><tab>p += 4<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>tmp_str += "", ""<tab>tmp_str += ""] ""<tab>if self.get_ptr() % 4:  # ptr field should be a multiple of 4<tab><tab>tmp_str += ""nonsense ptr field: %d "" % self.get_ptr()<tab>return tmp_str",1,if p >= self . get_len ( ) :,if p >= self . get_len ( ) :,0.75,100.00000000000004,1.0
"def source_shapes(self):<tab>""""""Prints debug information about the sources in this provider.""""""<tab>if logger.isEnabledFor(logging.DEBUG):<tab><tab>for i, source in enumerate(self.sources):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = ""anonymous""<tab><tab><tab>else:<tab><tab><tab><tab>name = self.keys[i]<tab><tab><tab>try:<tab><tab><tab><tab>shape = source.shape()<tab><tab><tab>except NotImplementedError:<tab><tab><tab><tab>shape = ""N/A""<tab><tab><tab>logger.debug(<tab><tab><tab><tab>'Data source ""%s"": entries=%s, shape=%s', name, len(source), shape<tab><tab><tab>)",0,if self . keys is None :,if i == 0 :,0.02225082504991546,8.170609724417774,0.20833333333333331
def swap_actions(actions):<tab>for mutexgroup in mutex_groups:<tab><tab>mutex_actions = mutexgroup._group_actions<tab><tab><IF-STMT><tab><tab><tab># make a best guess as to where we should store the group<tab><tab><tab>targetindex = actions.index(mutexgroup._group_actions[0])<tab><tab><tab># insert the _ArgumentGroup container<tab><tab><tab>actions[targetindex] = mutexgroup<tab><tab><tab># remove the duplicated individual actions<tab><tab><tab>actions = [action for action in actions if action not in mutex_actions]<tab>return actions,0,"if contains_actions ( mutex_actions , actions ) :",if len ( mutex_actions ) == 1 :,0.03779162928217515,26.477952261405967,0.38181818181818183
"def rec_deps(services, container_by_name, cnt, init_service):<tab>deps = cnt[""_deps""]<tab>for dep in deps.copy():<tab><tab>dep_cnts = services.get(dep)<tab><tab>if not dep_cnts:<tab><tab><tab>continue<tab><tab>dep_cnt = container_by_name.get(dep_cnts[0])<tab><tab>if dep_cnt:<tab><tab><tab># TODO: avoid creating loops, A->B->A<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>new_deps = rec_deps(services, container_by_name, dep_cnt, init_service)<tab><tab><tab>deps.update(new_deps)<tab>return deps",0,"if init_service and init_service in dep_cnt [ ""_deps"" ] :",if dep_cnt < 1 :,0.014393212535568477,5.0022783410134535,0.38666666666666666
"def make_dump_list_by_name_list(name_list):<tab>info_list = []<tab>for info_name in name_list:<tab><tab>info = next((x for x in DUMP_LIST if x.info_name == info_name), None)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError('Unknown info name: ""{}""'.format(info_name))<tab><tab>info_list.append(info)<tab>return info_list",0,if not info :,if info is None :,0.045150550804307965,14.058533129758727,0.27777777777777773
"def create(self, private=False):<tab>try:<tab><tab>if private:<tab><tab><tab>log.info(""Creating private channel %s."", self)<tab><tab><tab>self._bot.api_call(<tab><tab><tab><tab>""conversations.create"", data={""name"": self.name, ""is_private"": True}<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>log.info(""Creating channel %s."", self)<tab><tab><tab>self._bot.api_call(""conversations.create"", data={""name"": self.name})<tab>except SlackAPIResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>raise RoomError(f""Unable to create channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)",1,"if e . error == ""user_is_bot"" :","if e . error == ""user_is_bot"" :",0.75,100.00000000000004,1.0
"def talk(self, words):<tab>if self.writeSentence(words) == 0:<tab><tab>return<tab>r = []<tab>while 1:<tab><tab>i = self.readSentence()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>reply = i[0]<tab><tab>attrs = {}<tab><tab>for w in i[1:]:<tab><tab><tab>j = w.find(""="", 1)<tab><tab><tab>if j == -1:<tab><tab><tab><tab>attrs[w] = """"<tab><tab><tab>else:<tab><tab><tab><tab>attrs[w[:j]] = w[j + 1 :]<tab><tab>r.append((reply, attrs))<tab><tab>if reply == ""!done"":<tab><tab><tab>return r",1,if len ( i ) == 0 :,if len ( i ) == 0 :,0.75,100.00000000000004,1.0
"def _load_logfile(self, lfn):<tab>enc_key = self.decryption_key_func()<tab>with open(os.path.join(self.logdir, lfn)) as fd:<tab><tab><IF-STMT><tab><tab><tab>with DecryptingStreamer(<tab><tab><tab><tab>fd, mep_key=enc_key, name=""EventLog/DS(%s)"" % lfn<tab><tab><tab>) as streamer:<tab><tab><tab><tab>lines = streamer.read()<tab><tab><tab><tab>streamer.verify(_raise=IOError)<tab><tab>else:<tab><tab><tab>lines = fd.read()<tab><tab>if lines:<tab><tab><tab>for line in lines.splitlines():<tab><tab><tab><tab>event = Event.Parse(line.strip())<tab><tab><tab><tab>self._events[event.event_id] = event",1,if enc_key :,if enc_key :,0.5311706625951745,1e-10,1.0
"def set_ok_port(self, cookie, request):<tab>if cookie.port_specified:<tab><tab>req_port = request_port(request)<tab><tab>if req_port is None:<tab><tab><tab>req_port = ""80""<tab><tab>else:<tab><tab><tab>req_port = str(req_port)<tab><tab>for p in cookie.port.split("",""):<tab><tab><tab>try:<tab><tab><tab><tab>int(p)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>debug(""   bad port %s (not numeric)"", p)<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>debug(""   request port (%s) not found in %s"", req_port, cookie.port)<tab><tab><tab>return False<tab>return True",1,if p == req_port :,if p == req_port :,0.75,100.00000000000004,1.0
"def get_attribute_value(self, nodeid, attr):<tab>with self._lock:<tab><tab>self.logger.debug(""get attr val: %s %s"", nodeid, attr)<tab><tab><IF-STMT><tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadNodeIdUnknown)<tab><tab><tab>return dv<tab><tab>node = self._nodes[nodeid]<tab><tab>if attr not in node.attributes:<tab><tab><tab>dv = ua.DataValue()<tab><tab><tab>dv.StatusCode = ua.StatusCode(ua.StatusCodes.BadAttributeIdInvalid)<tab><tab><tab>return dv<tab><tab>attval = node.attributes[attr]<tab><tab>if attval.value_callback:<tab><tab><tab>return attval.value_callback()<tab><tab>return attval.value",1,if nodeid not in self . _nodes :,if nodeid not in self . _nodes :,0.75,100.00000000000004,1.0
"def data_logging_status(self, trail_name, trail_details, api_client):<tab>for es in api_client.get_event_selectors(TrailName=trail_name)[""EventSelectors""]:<tab><tab>has_wildcard = {<tab><tab><tab>u""Values"": [u""arn:aws:s3:::""],<tab><tab><tab>u""Type"": u""AWS::S3::Object"",<tab><tab>} in es[""DataResources""]<tab><tab>is_logging = trail_details[""IsLogging""]<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,if has_wildcard and is_logging :,0.21511243035321997,26.191817594980723,0.6388888888888888
"def pytest_deselected(items):<tab>if sb_config.dashboard:<tab><tab>sb_config.item_count -= len(items)<tab><tab>for item in items:<tab><tab><tab>test_id, display_id = _get_test_ids_(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sb_config._results.pop(test_id)",0,if test_id in sb_config . _results . keys ( ) :,if test_id in sb_config . _results :,0.3367670534421162,66.16975066206076,0.7352941176470589
"def _visit(self, func):<tab>fname = func[0]<tab>if fname in self._flags:<tab><tab>if self._flags[fname] == 1:<tab><tab><tab>logger.critical(""Fatal error! network ins not Dag."")<tab><tab><tab>import sys<tab><tab><tab>sys.exit(-1)<tab><tab>else:<tab><tab><tab>return<tab>else:<tab><tab>if fname not in self._flags:<tab><tab><tab>self._flags[fname] = 1<tab><tab>for output in func[3]:<tab><tab><tab>for f in self._orig:<tab><tab><tab><tab>for input in f[2]:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self._visit(f)<tab>self._flags[fname] = 2<tab>self._sorted.insert(0, func)",0,if output == input :,if input == output :,0.2901714209472326,21.3643503198117,0.5
"def printWiki():<tab>firstHeading = False<tab>for m in protocol:<tab><tab><IF-STMT><tab><tab><tab>if firstHeading:<tab><tab><tab><tab>output(""|}"")<tab><tab><tab>__printWikiHeader(m[1], m[2])<tab><tab><tab>firstHeading = True<tab><tab>else:<tab><tab><tab>output(""|-"")<tab><tab><tab>output(<tab><tab><tab><tab>'| <span style=""white-space:nowrap;""><tt>'<tab><tab><tab><tab>+ m[0]<tab><tab><tab><tab>+ ""</tt></span> || || ""<tab><tab><tab><tab>+ m[1]<tab><tab><tab>)<tab>output(""|}"")",0,"if m [ 0 ] == """" :","if m [ 0 ] == ""heading"" :",0.605621305873661,74.19446627365011,1.0
"def test_getitem(self):<tab>n = 200<tab>d = deque(range(n))<tab>l = list(range(n))<tab>for i in range(n):<tab><tab>d.popleft()<tab><tab>l.pop(0)<tab><tab><IF-STMT><tab><tab><tab>d.append(i)<tab><tab><tab>l.append(i)<tab><tab>for j in range(1 - len(l), len(l)):<tab><tab><tab>assert d[j] == l[j]<tab>d = deque(""superman"")<tab>self.assertEqual(d[0], ""s"")<tab>self.assertEqual(d[-1], ""n"")<tab>d = deque()<tab>self.assertRaises(IndexError, d.__getitem__, 0)<tab>self.assertRaises(IndexError, d.__getitem__, -1)",0,if random . random ( ) < 0.5 :,if len ( l ) == n :,0.01786335094255824,6.742555929751843,0.3181818181818182
"def get_num(line, char_ptr, num_chars):<tab>char_ptr = char_ptr + 1<tab>numstr = """"<tab>good = ""-.0123456789""<tab>while char_ptr < num_chars:<tab><tab>digit = line[char_ptr]<tab><tab><IF-STMT><tab><tab><tab>numstr = numstr + digit<tab><tab><tab>char_ptr = char_ptr + 1<tab><tab>else:<tab><tab><tab>break<tab>return numstr",0,if good . find ( digit ) != - 1 :,if digit in good :,0.013055717236343255,3.7253099995802206,0.27472527472527475
"def read_digits(source, start, first_code):<tab>body = source.body<tab>position = start<tab>code = first_code<tab>if code is not None and 48 <= code <= 57:  # 0 - 9<tab><tab>while True:<tab><tab><tab>position += 1<tab><tab><tab>code = char_code_at(body, position)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>return position<tab>raise GraphQLSyntaxError(<tab><tab>source,<tab><tab>position,<tab><tab>u""Invalid number, expected digit but got: {}."".format(print_char_code(code)),<tab>)",0,if not ( code is not None and 48 <= code <= 57 ) :,if code is None :,0.01442789230504292,2.4370696220343815,0.18055555555555555
"def get_aws_metadata(headers, provider=None):<tab>if not provider:<tab><tab>provider = boto.provider.get_default()<tab>metadata_prefix = provider.metadata_prefix<tab>metadata = {}<tab>for hkey in headers.keys():<tab><tab><IF-STMT><tab><tab><tab>val = urllib.unquote_plus(headers[hkey])<tab><tab><tab>try:<tab><tab><tab><tab>metadata[hkey[len(metadata_prefix) :]] = unicode(val, ""utf-8"")<tab><tab><tab>except UnicodeDecodeError:<tab><tab><tab><tab>metadata[hkey[len(metadata_prefix) :]] = val<tab><tab><tab>del headers[hkey]<tab>return metadata",0,if hkey . lower ( ) . startswith ( metadata_prefix ) :,if hkey . startswith ( metadata_prefix ) :,0.3019421647848402,59.60081680007605,0.5882352941176471
"def _process_rtdest(self):<tab>LOG.debug(""Processing RT NLRI destination..."")<tab>if self._rtdest_queue.is_empty():<tab><tab>return<tab>else:<tab><tab>processed_any = False<tab><tab>while not self._rtdest_queue.is_empty():<tab><tab><tab># We process the first destination in the queue.<tab><tab><tab>next_dest = self._rtdest_queue.pop_first()<tab><tab><tab>if next_dest:<tab><tab><tab><tab>next_dest.process()<tab><tab><tab><tab>processed_any = True<tab><tab><IF-STMT><tab><tab><tab># Since RT destination were updated we update RT filters<tab><tab><tab>self._core_service.update_rtfilters()",1,if processed_any :,if processed_any :,0.5311706625951745,1e-10,1.0
"def _get_header(self, requester, header_name):<tab>hits = sum([header_name in headers for _, headers in requester.requests])<tab>self.assertEquals(hits, 2 if self.revs_enabled else 1)<tab>for url, headers in requester.requests:<tab><tab>if header_name in headers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertTrue(url.endswith(""/latest""), msg=url)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertTrue(url.endswith(""/download_urls""), msg=url)<tab><tab><tab>return headers.get(header_name)",0,if self . revs_enabled :,"if ""latest"" in headers :",0.03412306583404374,7.809849842300637,0.36
"def add_external_deps(self, deps):<tab>for dep in deps:<tab><tab>if hasattr(dep, ""el""):<tab><tab><tab>dep = dep.el<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArguments(""Argument is not an external dependency"")<tab><tab>self.external_deps.append(dep)<tab><tab>if isinstance(dep, dependencies.Dependency):<tab><tab><tab>self.process_sourcelist(dep.get_sources())",0,"if not isinstance ( dep , dependencies . Dependency ) :","if not isinstance ( dep , ExternalDependency ) :",0.265205758294317,52.899344348276884,0.6136363636363636
"def _consume_msg(self):<tab>ws = self._ws<tab>try:<tab><tab>while True:<tab><tab><tab>r = await ws.recv()<tab><tab><tab>if isinstance(r, bytes):<tab><tab><tab><tab>r = r.decode(""utf-8"")<tab><tab><tab>msg = json.loads(r)<tab><tab><tab>stream = msg.get(""stream"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await self._dispatch(stream, msg)<tab>except websockets.WebSocketException as wse:<tab><tab>logging.warn(wse)<tab><tab>await self.close()<tab><tab>asyncio.ensure_future(self._ensure_ws())",1,if stream is not None :,if stream is not None :,0.75,100.00000000000004,1.0
"def generate_and_check_random():<tab>random_size = 256<tab>while True:<tab><tab>random = os.urandom(random_size)<tab><tab>a = int.from_bytes(random, ""big"")<tab><tab>A = pow(g, a, p)<tab><tab><IF-STMT><tab><tab><tab>a_for_hash = big_num_for_hash(A)<tab><tab><tab>u = int.from_bytes(sha256(a_for_hash, b_for_hash), ""big"")<tab><tab><tab>if u > 0:<tab><tab><tab><tab>return (a, a_for_hash, u)",0,"if is_good_mod_exp_first ( A , p ) :",if a > 0 :,0.01858685153282265,1.407567834071592,0.6
"def write(self, datagram, address):<tab>""""""Write a datagram.""""""<tab>try:<tab><tab>return self.socket.sendto(datagram, address)<tab>except OSError as se:<tab><tab>no = se.args[0]<tab><tab>if no == EINTR:<tab><tab><tab>return self.write(datagram, address)<tab><tab>elif no == EMSGSIZE:<tab><tab><tab>raise error.MessageLengthError(""message too long"")<tab><tab><IF-STMT><tab><tab><tab># oh, well, drop the data. The only difference from UDP<tab><tab><tab># is that UDP won't ever notice.<tab><tab><tab># TODO: add TCP-like buffering<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise",0,elif no == EAGAIN :,elif no == EBADF :,0.6428720214849399,53.7284965911771,0.6
"def doDir(elem):<tab>for child in elem.childNodes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if child.tagName == ""Directory"":<tab><tab><tab>doDir(child)<tab><tab>elif child.tagName == ""Component"":<tab><tab><tab>for grandchild in child.childNodes:<tab><tab><tab><tab>if not isinstance(grandchild, minidom.Element):<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if grandchild.tagName != ""File"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>files.add(grandchild.getAttribute(""Source"").replace(os.sep, ""/""))",1,"if not isinstance ( child , minidom . Element ) :","if not isinstance ( child , minidom . Element ) :",0.75,100.00000000000004,1.0
"def add_reversed_tensor(i, X, reversed_X):<tab># Do not keep tensors that should stop the mapping.<tab>if X in stop_mapping_at_tensors:<tab><tab>return<tab>if X not in reversed_tensors:<tab><tab>reversed_tensors[X] = {""id"": (nid, i), ""tensor"": reversed_X}<tab>else:<tab><tab>tmp = reversed_tensors[X]<tab><tab>if ""tensor"" in tmp and ""tensors"" in tmp:<tab><tab><tab>raise Exception(""Wrong order, tensors already aggregated!"")<tab><tab><IF-STMT><tab><tab><tab>tmp[""tensors""] = [tmp[""tensor""], reversed_X]<tab><tab><tab>del tmp[""tensor""]<tab><tab>else:<tab><tab><tab>tmp[""tensors""].append(reversed_X)",1,"if ""tensor"" in tmp :","if ""tensor"" in tmp :",0.75,100.00000000000004,1.0
"def walk(source, path, default, delimiter="".""):<tab>""""""Walk the sourch hash given the path and return the value or default if not found""""""<tab>if not isinstance(source, dict):<tab><tab>raise RuntimeError(<tab><tab><tab>""The source is not a walkable dict: {} path: {}"".format(source, path)<tab><tab>)<tab>keys = path.split(delimiter)<tab>max_depth = len(keys)<tab>cur_depth = 0<tab>while cur_depth < max_depth:<tab><tab><IF-STMT><tab><tab><tab>source = source[keys[cur_depth]]<tab><tab><tab>cur_depth = cur_depth + 1<tab><tab>else:<tab><tab><tab>return default<tab>return source",1,if keys [ cur_depth ] in source :,if keys [ cur_depth ] in source :,0.75,100.00000000000004,1.0
"def _from_txt_get_vulns(self):<tab>file_vulns = []<tab>vuln_regex = (<tab><tab>'SQL injection in a .*? was found at: ""(.*?)""'<tab><tab>', using HTTP method (.*?). The sent .*?data was: ""(.*?)""'<tab>)<tab>vuln_re = re.compile(vuln_regex)<tab>for line in file(self.OUTPUT_FILE):<tab><tab>mo = vuln_re.search(line)<tab><tab><IF-STMT><tab><tab><tab>v = MockVuln(""TestCase"", None, ""High"", 1, ""plugin"")<tab><tab><tab>v.set_url(URL(mo.group(1)))<tab><tab><tab>v.set_method(mo.group(2))<tab><tab><tab>file_vulns.append(v)<tab>return file_vulns",1,if mo :,if mo :,0.5311706625951745,1e-10,1.0
"def __get__(self, instance, instance_type=None):<tab>if instance:<tab><tab>if self.att_name not in instance._obj_cache:<tab><tab><tab>rel_obj = self.get_obj(instance)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>instance._obj_cache[self.att_name] = rel_obj<tab><tab>return instance._obj_cache.get(self.att_name)<tab>return self",1,if rel_obj :,if rel_obj :,0.5311706625951745,1e-10,1.0
"def get_ranges_from_func_set(support_set):<tab>pos_start = 0<tab>pos_end = 0<tab>ranges = []<tab>for pos, func in enumerate(network.function):<tab><tab><IF-STMT><tab><tab><tab>pos_end = pos<tab><tab>else:<tab><tab><tab>if pos_end >= pos_start:<tab><tab><tab><tab>ranges.append((pos_start, pos_end))<tab><tab><tab>pos_start = pos + 1<tab>if pos_end >= pos_start:<tab><tab>ranges.append((pos_start, pos_end))<tab>return ranges",0,if func . type in support_set :,"if func . get ( ""support_set"" ) == support_set :",0.08600279969725871,20.706193828327603,0.4871794871794872
"def get_all_active_plugins(self) -> List[BotPlugin]:<tab>""""""This returns the list of plugins in the callback ordered defined from the config.""""""<tab>all_plugins = []<tab>for name in self.plugins_callback_order:<tab><tab># None is a placeholder for any plugin not having a defined order<tab><tab>if name is None:<tab><tab><tab>all_plugins += [<tab><tab><tab><tab>plugin<tab><tab><tab><tab>for name, plugin in self.plugins.items()<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab>else:<tab><tab><tab>plugin = self.plugins[name]<tab><tab><tab>if plugin.is_activated:<tab><tab><tab><tab>all_plugins.append(plugin)<tab>return all_plugins",0,if name not in self . plugins_callback_order and plugin . is_activated,"if isinstance ( plugin ,BotPlugin )",0.012100148512495922,1.8716386091619874,0.18518518518518517
"def render_token_list(self, tokens):<tab>result = []<tab>vars = []<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>result.append(token.contents.replace(""%"", ""%%""))<tab><tab>elif token.token_type == TOKEN_VAR:<tab><tab><tab>result.append(""%%(%s)s"" % token.contents)<tab><tab><tab>vars.append(token.contents)<tab>msg = """".join(result)<tab>if self.trimmed:<tab><tab>msg = translation.trim_whitespace(msg)<tab>return msg, vars",1,if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_TEXT :,0.75,100.00000000000004,1.0
"def test_build_root_config_overwrite(self):<tab>cfg = build_root_config(""tests.files.settings_overwrite"")<tab>for key, val in DEFAULT_SPIDER_GLOBAL_CONFIG.items():<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(cfg[""global""][key], [""zzz""])<tab><tab>else:<tab><tab><tab>self.assertEqual(cfg[""global""][key], val)",0,"if key == ""spider_modules"" :","if val == ""zzz"" :",0.28654024892898816,21.069764742263047,0.5
"def get_limit(self, request):<tab>if self.limit_query_param:<tab><tab>try:<tab><tab><tab>limit = int(request.query_params[self.limit_query_param])<tab><tab><tab>if limit < 0:<tab><tab><tab><tab>raise ValueError()<tab><tab><tab># Enforce maximum page size, if defined<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if limit == 0:<tab><tab><tab><tab><tab>return settings.MAX_PAGE_SIZE<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return min(limit, settings.MAX_PAGE_SIZE)<tab><tab><tab>return limit<tab><tab>except (KeyError, ValueError):<tab><tab><tab>pass<tab>return self.default_limit",0,if settings . MAX_PAGE_SIZE :,if limit > settings . MAX_PAGE_SIZE :,0.36879024661621806,69.89307622784945,0.4722222222222222
"def track_handler(handler):<tab>tid = handler.request.tid<tab>for event in events_monitored:<tab><tab><IF-STMT><tab><tab><tab>e = Event(event, handler.request.execution_time)<tab><tab><tab>State.tenant_state[tid].RecentEventQ.append(e)<tab><tab><tab>State.tenant_state[tid].EventQ.append(e)<tab><tab><tab>break",0,"if event [ ""handler_check"" ] ( handler ) :",if event not in State . tenant_state [ tid ] :,0.029374855171812934,8.130850857597444,0.34615384615384615
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_subscription().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100.00000000000004,1.0
"def GetCreateInstanceBinder(self, info):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>return self._createInstanceBinders[info]<tab><tab>b = runtime.SymplCreateInstanceBinder(info)<tab><tab>self._createInstanceBinders[info] = b<tab>return b",1,if self . _createInstanceBinders . ContainsKey ( info ) :,if self . _createInstanceBinders . ContainsKey ( info ) :,0.75,100.00000000000004,1.0
"def process_task(self, body, message):<tab>if ""control"" in body:<tab><tab>try:<tab><tab><tab>return self.control(body, message)<tab><tab>except Exception:<tab><tab><tab>logger.exception(""Exception handling control message:"")<tab><tab><tab>return<tab>if len(self.pool):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>queue = UUID(body[""uuid""]).int % len(self.pool)<tab><tab><tab>except Exception:<tab><tab><tab><tab>queue = self.total_messages % len(self.pool)<tab><tab>else:<tab><tab><tab>queue = self.total_messages % len(self.pool)<tab>else:<tab><tab>queue = 0<tab>self.pool.write(queue, body)<tab>self.total_messages += 1<tab>message.ack()",0,"if ""uuid"" in body and body [ ""uuid"" ] :","if ""uuid"" in body :",0.13897580794314457,30.93485033266056,0.7
"def is_defined_in_base_class(self, var: Var) -> bool:<tab>if var.info:<tab><tab>for base in var.info.mro[1:]:<tab><tab><tab>if base.get(var.name) is not None:<tab><tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,if var . info . fallback_to_any :,if base . get ( var . name ) is not None :,0.03304620199133804,7.768562846380176,0.16666666666666666
"def ant_map(m):<tab>tmp = ""rows %s\ncols %s\n"" % (len(m), len(m[0]))<tab>players = {}<tab>for row in m:<tab><tab>tmp += ""m ""<tab><tab>for col in row:<tab><tab><tab>if col == LAND:<tab><tab><tab><tab>tmp += "".""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmp += ""%""<tab><tab><tab>elif col == FOOD:<tab><tab><tab><tab>tmp += ""*""<tab><tab><tab>elif col == UNSEEN:<tab><tab><tab><tab>tmp += ""?""<tab><tab><tab>else:<tab><tab><tab><tab>players[col] = True<tab><tab><tab><tab>tmp += chr(col + 97)<tab><tab>tmp += ""\n""<tab>tmp = (""players %s\n"" % len(players)) + tmp<tab>return tmp",0,elif col == BARRIER :,elif col == LEGAL :,0.6428720214849399,53.7284965911771,0.6
"def prompt_for_resume(config):<tab>logger = logging.getLogger(""changeme"")<tab>logger.error(<tab><tab>""A previous scan was interrupted. Type R to resume or F to start a fresh scan""<tab>)<tab>answer = """"<tab>while not (answer == ""R"" or answer == ""F""):<tab><tab>prompt = ""(R/F)> ""<tab><tab>answer = """"<tab><tab>try:<tab><tab><tab>answer = raw_input(prompt)<tab><tab>except NameError:<tab><tab><tab>answer = input(prompt)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Forcing a fresh scan"")<tab><tab>elif answer.upper() == ""R"":<tab><tab><tab>logger.debug(""Resuming previous scan"")<tab><tab><tab>config.resume = True<tab>return config.resume",1,"if answer . upper ( ) == ""F"" :","if answer . upper ( ) == ""F"" :",0.75,100.00000000000004,1.0
"def f(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab><IF-STMT><tab><tab><tab>if view.line(s.b).size() > 0:<tab><tab><tab><tab>eol = view.line(s.b).b<tab><tab><tab><tab>return R(s.b, eol)<tab><tab><tab>return s<tab>return s",0,if count == 1 :,if s . b . size ( ) > 0 :,0.0237537216033675,4.456882760699063,0.23214285714285715
"def flush(self):<tab>if not self.cuts:<tab><tab>return<tab>for move, (x, y, z), cent in douglas(self.cuts, self.tolerance, self.plane):<tab><tab><IF-STMT><tab><tab><tab>self.write(""%s X%.4f Y%.4f Z%.4f %s"" % (move, x, y, z, cent))<tab><tab><tab>self.lastgcode = None<tab><tab><tab>self.lastx = x<tab><tab><tab>self.lasty = y<tab><tab><tab>self.lastz = z<tab><tab>else:<tab><tab><tab>self.move_common(x, y, z, gcode=""G1"")<tab>self.cuts = []",0,if cent :,if self . lastgcode is None :,0.04579081141525348,1e-10,0.22448979591836735
"def copy_shell(self):<tab>cls = self.__class__<tab>old_id = cls.id<tab>new_i = cls()  # create a new group<tab>new_i.id = self.id  # with the same id<tab>cls.id = old_id  # Reset the Class counter<tab># Copy all properties<tab>for prop in cls.properties:<tab><tab><IF-STMT><tab><tab><tab>if self.has(prop):<tab><tab><tab><tab>val = getattr(self, prop)<tab><tab><tab><tab>setattr(new_i, prop, val)<tab># but no members<tab>new_i.members = []<tab>return new_i",0,"if prop is not ""members"" :","if hasattr ( self , prop ) :",0.023749771747382555,7.267884212102741,0.2857142857142857
"def find_region_by_value(key, value):<tab>for region in cognitoidp_backends:<tab><tab>backend = cognitoidp_backends[region]<tab><tab>for user_pool in backend.user_pools.values():<tab><tab><tab>if key == ""client_id"" and value in user_pool.clients:<tab><tab><tab><tab>return region<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return region<tab># If we can't find the `client_id` or `access_token`, we just pass<tab># back a default backend region, which will raise the appropriate<tab># error message (e.g. NotAuthorized or NotFound).<tab>return list(cognitoidp_backends)[0]",1,"if key == ""access_token"" and value in user_pool . access_tokens :","if key == ""access_token"" and value in user_pool . access_tokens :",0.75,100.00000000000004,1.0
"def __init__(<tab>self, fixed: MQTTFixedHeader = None, variable_header: PacketIdVariableHeader = None):<tab>if fixed is None:<tab><tab>header = MQTTFixedHeader(PUBREL, 0x02)  # [MQTT-3.6.1-1]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise HBMQTTException(<tab><tab><tab><tab>""Invalid fixed packet type %s for PubrelPacket init"" % fixed.packet_type<tab><tab><tab>)<tab><tab>header = fixed<tab>super().__init__(header)<tab>self.variable_header = variable_header<tab>self.payload = None",1,if fixed . packet_type is not PUBREL :,if fixed . packet_type is not PUBREL :,0.75,100.00000000000004,1.0
"def _on_event_MetadataStatisticsUpdated(self, event, data):<tab>with self._selectedFileMutex:<tab><tab><IF-STMT><tab><tab><tab>self._setJobData(<tab><tab><tab><tab>self._selectedFile[""filename""],<tab><tab><tab><tab>self._selectedFile[""filesize""],<tab><tab><tab><tab>self._selectedFile[""sd""],<tab><tab><tab><tab>self._selectedFile[""user""],<tab><tab><tab>)",0,if self . _selectedFile :,if self . _selectedFile is not None :,0.3514988343435983,46.713797772819994,0.4444444444444444
"def _validate_parameter_range(self, value_hp, parameter_range):<tab>""""""Placeholder docstring""""""<tab>for (<tab><tab>parameter_range_key,<tab><tab>parameter_range_value,<tab>) in parameter_range.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Categorical ranges<tab><tab>if isinstance(parameter_range_value, list):<tab><tab><tab>for categorical_value in parameter_range_value:<tab><tab><tab><tab>value_hp.validate(categorical_value)<tab><tab># Continuous, Integer ranges<tab><tab>else:<tab><tab><tab>value_hp.validate(parameter_range_value)",0,"if parameter_range_key == ""scaling_type"" :","if parameter_range_key . startswith ( ""_"" ) :",0.04979441971690225,39.75360176263951,0.6410256410256411
"def visit_filter_projection(self, node, value):<tab>base = self.visit(node[""children""][0], value)<tab>if not isinstance(base, list):<tab><tab>return None<tab>comparator_node = node[""children""][2]<tab>collected = []<tab>for element in base:<tab><tab>if self._is_true(self.visit(comparator_node, element)):<tab><tab><tab>current = self.visit(node[""children""][1], element)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>collected.append(current)<tab>return collected",1,if current is not None :,if current is not None :,0.75,100.00000000000004,1.0
"def _getSubstrings(self, va, size, ltyp):<tab># rip through the desired memory range to populate any substrings<tab>subs = set()<tab>end = va + size<tab>for offs in range(va, end, 1):<tab><tab>loc = self.getLocation(offs, range=True)<tab><tab><IF-STMT><tab><tab><tab>subs.add((loc[L_VA], loc[L_SIZE]))<tab><tab><tab>if loc[L_TINFO]:<tab><tab><tab><tab>subs = subs.union(set(loc[L_TINFO]))<tab>return list(subs)",0,if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,if loc [ L_VA ] != ltyp :,0.12924354619609768,16.404210784979526,0.3888888888888889
"def run(self):<tab>while not self._stopped:<tab><tab>try:<tab><tab><tab>try:<tab><tab><tab><tab>test_name = next(self.pending)<tab><tab><tab>except StopIteration:<tab><tab><tab><tab>break<tab><tab><tab>mp_result = self._runtest(test_name)<tab><tab><tab>self.output.put((False, mp_result))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>except ExitThread:<tab><tab><tab>break<tab><tab>except BaseException:<tab><tab><tab>self.output.put((True, traceback.format_exc()))<tab><tab><tab>break",0,"if must_stop ( mp_result . result , self . ns ) :",if mp_result == 0 :,0.010805043283377891,8.5925229098304,0.3148148148148148
"def get_in_inputs(key, data):<tab>if isinstance(data, dict):<tab><tab>for k, v in data.items():<tab><tab><tab>if k == key:<tab><tab><tab><tab>return v<tab><tab><tab>elif isinstance(v, (list, tuple, dict)):<tab><tab><tab><tab>out = get_in_inputs(key, v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return out<tab>elif isinstance(data, (list, tuple)):<tab><tab>out = [get_in_inputs(key, x) for x in data]<tab><tab>out = [x for x in out if x]<tab><tab>if out:<tab><tab><tab>return out[0]",1,if out :,if out :,0.5311706625951745,1e-10,1.0
"def act_mapping(self, items, actions, mapping):<tab>""""""Executes all the actions on the list of pods.""""""<tab>success = True<tab>for action in actions:<tab><tab>for key, method in mapping.items():<tab><tab><tab>if key in action:<tab><tab><tab><tab>params = action.get(key)<tab><tab><tab><tab>ret = method(items, params)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>success = False<tab>return success",0,if not ret :,if ret is not None :,0.16783924089142813,11.478744233307168,0.25
"def _apply(self, plan):<tab>desired = plan.desired<tab>changes = plan.changes<tab>self.log.debug(""_apply: zone=%s, len(changes)=%d"", desired.name, len(changes))<tab>domain_name = desired.name[:-1]<tab>try:<tab><tab>nsone_zone = self._client.loadZone(domain_name)<tab>except ResourceException as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>self.log.debug(""_apply:   no matching zone, creating"")<tab><tab>nsone_zone = self._client.createZone(domain_name)<tab>for change in changes:<tab><tab>class_name = change.__class__.__name__<tab><tab>getattr(self, ""_apply_{}"".format(class_name))(nsone_zone, change)",0,if e . message != self . ZONE_NOT_FOUND_MESSAGE :,if e . errno != errno . ENOENT :,0.3218551389611183,11.7250040531018,0.4126984126984127
"def split_artists(self, json):<tab>if len(json) == 0:<tab><tab>([], [])<tab>elif len(json) == 1:<tab><tab>artist = Artist.query.filter_by(name=json[0][""name""]).first()<tab><tab>return ([artist], [])<tab>my_artists = []<tab>other_artists = []<tab>for artist_dict in json:<tab><tab>artist = Artist.query.filter_by(name=artist_dict[""name""])<tab><tab><IF-STMT><tab><tab><tab>my_artists.append(artist.first())<tab><tab>else:<tab><tab><tab>del artist_dict[""thumb_url""]<tab><tab><tab>other_artists.append(artist_dict)<tab>return (my_artists, other_artists)",0,if artist . count ( ) :,if artist . first ( ) :,0.3884893899276739,41.11336169005196,0.6
"def update_metadata(self):<tab>for attrname in dir(self):<tab><tab>if attrname.startswith(""__""):<tab><tab><tab>continue<tab><tab>attrvalue = getattr(self, attrname, None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if attrname == ""salt_version"":<tab><tab><tab>attrname = ""version""<tab><tab>if hasattr(self.metadata, ""set_{0}"".format(attrname)):<tab><tab><tab>getattr(self.metadata, ""set_{0}"".format(attrname))(attrvalue)<tab><tab>elif hasattr(self.metadata, attrname):<tab><tab><tab>try:<tab><tab><tab><tab>setattr(self.metadata, attrname, attrvalue)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>pass",0,if attrvalue == 0 :,if not attrvalue :,0.03944961859844226,12.750736437345598,0.4
"def close(self, code=errno.ECONNRESET):<tab>with self.shutdown_lock:<tab><tab><IF-STMT><tab><tab><tab>super(RemoteIPRoute, self).close(code=code)<tab><tab><tab>self.closed = True<tab><tab><tab>try:<tab><tab><tab><tab>self._mitogen_call.get()<tab><tab><tab>except mitogen.core.ChannelError:<tab><tab><tab><tab>pass<tab><tab><tab>if self._mitogen_broker is not None:<tab><tab><tab><tab>self._mitogen_broker.shutdown()<tab><tab><tab><tab>self._mitogen_broker.join()",1,if not self . closed :,if not self . closed :,0.75,100.00000000000004,1.0
"def untokenize(self, iterable):<tab>for t in iterable:<tab><tab><IF-STMT><tab><tab><tab>self.compat(t, iterable)<tab><tab><tab>break<tab><tab>tok_type, token, start, end, line = t<tab><tab>self.add_whitespace(start)<tab><tab>self.tokens.append(token)<tab><tab>self.prev_row, self.prev_col = end<tab><tab>if tok_type in (NEWLINE, NL):<tab><tab><tab>self.prev_row += 1<tab><tab><tab>self.prev_col = 0<tab>return """".join(self.tokens)",0,if len ( t ) == 2 :,"if isinstance ( t , ( list , tuple ) ) :",0.030649819819333343,8.516593018819643,0.3666666666666667
"def __call__(self, x, uttid=None):<tab>if self.utt2spk is not None:<tab><tab>spk = self.utt2spk[uttid]<tab>else:<tab><tab>spk = uttid<tab>if not self.reverse:<tab><tab>if self.norm_means:<tab><tab><tab>x = np.add(x, self.bias[spk])<tab><tab><IF-STMT><tab><tab><tab>x = np.multiply(x, self.scale[spk])<tab>else:<tab><tab>if self.norm_vars:<tab><tab><tab>x = np.divide(x, self.scale[spk])<tab><tab>if self.norm_means:<tab><tab><tab>x = np.subtract(x, self.bias[spk])<tab>return x",1,if self . norm_vars :,if self . norm_vars :,0.75,100.00000000000004,1.0
"def get_party_total(self, args):<tab>self.party_total = frappe._dict()<tab>for d in self.receivables:<tab><tab>self.init_party_total(d)<tab><tab># Add all amount columns<tab><tab>for k in list(self.party_total[d.party]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.party_total[d.party][k] += d.get(k, 0.0)<tab><tab># set territory, customer_group, sales person etc<tab><tab>self.set_party_details(d)",0,"if k not in [ ""currency"" , ""sales_person"" ] :",if k in self . party_total [ d . party ] :,0.032335288096614345,8.00859097765977,0.35714285714285715
"def get_databases(request):<tab>dbs = {}<tab>global_env = globals()<tab>for (key, value) in global_env.items():<tab><tab>try:<tab><tab><tab>cond = isinstance(value, GQLDB)<tab><tab>except:<tab><tab><tab>cond = isinstance(value, SQLDB)<tab><tab><IF-STMT><tab><tab><tab>dbs[key] = value<tab>return dbs",1,if cond :,if cond :,0.5311706625951745,1e-10,1.0
"def check_twobit_file(dbkey, GALAXY_DATA_INDEX_DIR):<tab>twobit_file = ""%s/twobit.loc"" % GALAXY_DATA_INDEX_DIR<tab>twobit_path = """"<tab>twobits = {}<tab>for i, line in enumerate(open(twobit_file)):<tab><tab>line = line.rstrip(""\r\n"")<tab><tab>if line and not line.startswith(""#""):<tab><tab><tab>fields = line.split(""\t"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>twobits[(fields[0])] = fields[1]<tab>if dbkey in twobits:<tab><tab>twobit_path = twobits[(dbkey)]<tab>return twobit_path",0,if len ( fields ) < 2 :,if len ( fields ) != 2 :,0.5490406812970063,51.33450480401705,1.0
"def action(scheduler, _):<tab>nonlocal state<tab>nonlocal has_result<tab>nonlocal result<tab>nonlocal first<tab>nonlocal time<tab><IF-STMT><tab><tab>observer.on_next(result)<tab>try:<tab><tab>if first:<tab><tab><tab>first = False<tab><tab>else:<tab><tab><tab>state = iterate(state)<tab><tab>has_result = condition(state)<tab><tab>if has_result:<tab><tab><tab>result = state<tab><tab><tab>time = time_mapper(state)<tab>except Exception as e:  # pylint: disable=broad-except<tab><tab>observer.on_error(e)<tab><tab>return<tab>if has_result:<tab><tab>mad.disposable = scheduler.schedule_relative(time, action)<tab>else:<tab><tab>observer.on_completed()",0,if has_result :,if result is not None :,0.048107739435423735,1e-10,0.2222222222222222
def orthogonalEnd(self):<tab>if self.type == Segment.LINE:<tab><tab>O = self.AB.orthogonal()<tab><tab>O.norm()<tab><tab>return O<tab>else:<tab><tab>O = self.B - self.C<tab><tab>O.norm()<tab><tab><IF-STMT><tab><tab><tab>return -O<tab><tab>else:<tab><tab><tab>return O,1,if self . type == Segment . CCW :,if self . type == Segment . CCW :,0.75,100.00000000000004,1.0
"def remove(self, values):<tab>if not isinstance(values, (list, tuple, set)):<tab><tab>values = [values]<tab>for v in values:<tab><tab>v = str(v)<tab><tab>if isinstance(self._definition, dict):<tab><tab><tab>self._definition.pop(v, None)<tab><tab>elif self._definition == ""ANY"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._definition = []<tab><tab>elif v in self._definition:<tab><tab><tab>self._definition.remove(v)<tab>if (<tab><tab>self._value is not None<tab><tab>and self._value not in self._definition<tab><tab>and self._not_any()<tab>):<tab><tab>raise ConanException(bad_value_msg(self._name, self._value, self.values_range))",0,"if v == ""ANY"" :",if v in self . _definition :,0.05286931595839166,12.22307556087252,0.55
"def __enter__(self) -> None:<tab>try:<tab><tab><IF-STMT><tab><tab><tab>signal.signal(signal.SIGALRM, self.handle_timeout)<tab><tab><tab>signal.alarm(self.seconds)<tab>except ValueError as ex:<tab><tab>logger.warning(""timeout can't be used in the current context"")<tab><tab>logger.exception(ex)",0,if threading . current_thread ( ) == threading . main_thread ( ) :,if self . seconds is not None :,0.01079993947912768,2.0822836897918786,0.22794117647058823
"def __init__(self, fixed: MQTTFixedHeader = None):<tab>if fixed is None:<tab><tab>header = MQTTFixedHeader(PINGRESP, 0x00)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise HBMQTTException(<tab><tab><tab><tab>""Invalid fixed packet type %s for PingRespPacket init""<tab><tab><tab><tab>% fixed.packet_type<tab><tab><tab>)<tab><tab>header = fixed<tab>super().__init__(header)<tab>self.variable_header = None<tab>self.payload = None",1,if fixed . packet_type is not PINGRESP :,if fixed . packet_type is not PINGRESP :,0.75,100.00000000000004,1.0
"def _put_nowait(self, data, *, sender):<tab>if not self._running:<tab><tab>logger.warning(""Pub/Sub listener message after stop: %r, %r"", sender, data)<tab><tab>return<tab>self._queue.put_nowait((sender, data))<tab>if self._waiter is not None:<tab><tab>fut, self._waiter = self._waiter, None<tab><tab><IF-STMT><tab><tab><tab>assert fut.cancelled(), (""Waiting future is in wrong state"", self, fut)<tab><tab><tab>return<tab><tab>fut.set_result(None)",1,if fut . done ( ) :,if fut . done ( ) :,0.75,100.00000000000004,1.0
"def OnAssignBuiltin(self, cmd_val):<tab># type: (cmd_value__Assign) -> None<tab>buf = self._ShTraceBegin()<tab>if not buf:<tab><tab>return<tab>for i, arg in enumerate(cmd_val.argv):<tab><tab><IF-STMT><tab><tab><tab>buf.write("" "")<tab><tab>buf.write(arg)<tab>for pair in cmd_val.pairs:<tab><tab>buf.write("" "")<tab><tab>buf.write(pair.var_name)<tab><tab>buf.write(""="")<tab><tab>if pair.rval:<tab><tab><tab>_PrintShValue(pair.rval, buf)<tab>buf.write(""\n"")<tab>self.f.write(buf.getvalue())",0,if i != 0 :,if arg :,0.03549272049582243,1e-10,0.36
"def convertDict(obj):<tab>obj = dict(obj)<tab>for k, v in obj.items():<tab><tab>del obj[k]<tab><tab>if not (isinstance(k, str) or isinstance(k, unicode)):<tab><tab><tab>k = dumps(k)<tab><tab><tab># Keep track of which keys need to be decoded when loading.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>obj[Types.KEYS] = []<tab><tab><tab>obj[Types.KEYS].append(k)<tab><tab>obj[k] = convertObjects(v)<tab>return obj",0,if Types . KEYS not in obj :,if Type . KEYS not in obj :,0.605621305873661,70.71067811865478,0.75
"def _ArgumentListHasDictionaryEntry(self, token):<tab>""""""Check if the function argument list has a dictionary as an arg.""""""<tab>if _IsArgumentToFunction(token):<tab><tab>while token:<tab><tab><tab>if token.value == ""{"":<tab><tab><tab><tab>length = token.matching_bracket.total_length - token.total_length<tab><tab><tab><tab>return length + self.stack[-2].indent > self.column_limit<tab><tab><tab>if token.ClosesScope():<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = token.matching_bracket<tab><tab><tab>token = token.next_token<tab>return False",0,if token . OpensScope ( ) :,"if token . value == ""}"" :",0.09056531419355518,16.784459625186194,0.6
"def get_editable_dict(self):<tab>ret = {}<tab>for ref, ws_package in self._workspace_packages.items():<tab><tab>path = ws_package.root_folder<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(path, CONANFILE)<tab><tab>ret[ref] = {""path"": path, ""layout"": ws_package.layout}<tab>return ret",0,if os . path . isdir ( path ) :,if not os . path . isabs ( path ) :,0.507149039934324,48.326978309062206,0.27272727272727276
"def serialize(self, name=None):<tab>data = super(WebLink, self).serialize(name)<tab>data[""contentType""] = self.contentType<tab>if self.width:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidWidthException(self.width)<tab><tab>data[""inputOptions""] = {}<tab><tab>data[""width""] = self.width<tab>data.update({""content"": {""url"": self.linkUrl, ""text"": self.linkText}})<tab>return data",0,"if self . width not in [ 100 , 50 , 33 , 25 ] :",if self . width < 0 :,0.07437932149408083,12.01799094826536,0.3397129186602871
"def callback(lexer, match, context):<tab>text = match.group()<tab>extra = """"<tab>if start:<tab><tab>context.next_indent = len(text)<tab><tab><IF-STMT><tab><tab><tab>while context.next_indent < context.indent:<tab><tab><tab><tab>context.indent = context.indent_stack.pop()<tab><tab><tab>if context.next_indent > context.indent:<tab><tab><tab><tab>extra = text[context.indent :]<tab><tab><tab><tab>text = text[: context.indent]<tab>else:<tab><tab>context.next_indent += len(text)<tab>if text:<tab><tab>yield match.start(), TokenClass, text<tab>if extra:<tab><tab>yield match.start() + len(text), TokenClass.Error, extra<tab>context.pos = match.end()",0,if context . next_indent < context . indent :,if context . indent_stack :,0.19168418984860813,21.606281467072083,0.625
"def _handle_unsubscribe(self, web_sock):<tab>index = None<tab>with await self._subscriber_lock:<tab><tab>for i, (subscriber_web_sock, _) in enumerate(self._subscribers):<tab><tab><tab>if subscriber_web_sock == web_sock:<tab><tab><tab><tab>index = i<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>del self._subscribers[index]<tab><tab>if not self._subscribers:<tab><tab><tab>asyncio.ensure_future(self._unregister_subscriptions())",1,if index is not None :,if index is not None :,0.75,100.00000000000004,1.0
"def test_missing_dict_param():<tab>expected_err = ""params dictionary did not contain value for placeholder""<tab>try:<tab><tab>substitute_params(<tab><tab><tab>""SELECT * FROM cust WHERE salesrep = %(name)s"", {""foobar"": ""John Doe""}<tab><tab>)<tab><tab>assert False, ""expected exception b/c dict did not contain replacement value""<tab>except ValueError as exc:<tab><tab><IF-STMT><tab><tab><tab>raise",1,if expected_err not in str ( exc ) :,if expected_err not in str ( exc ) :,0.75,100.00000000000004,1.0
"def one_gpr_reg_one_mem_scalable(ii):<tab>n, r = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>elif op_gprv(op):<tab><tab><tab>r += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and r == 1",0,"if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ ""v"" ] ) :",if op_mem ( op ) :,0.1741679270005077,7.821555054390223,0.33035714285714285
"def on_enter(self):<tab>""""""Fired when mouse enter the bbox of the widget.""""""<tab>if hasattr(self, ""md_bg_color"") and self.focus_behavior:<tab><tab>if hasattr(self, ""theme_cls"") and not self.focus_color:<tab><tab><tab>self.md_bg_color = self.theme_cls.bg_normal<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.md_bg_color = App.get_running_app().theme_cls.bg_normal<tab><tab><tab>else:<tab><tab><tab><tab>self.md_bg_color = self.focus_color",0,if not self . focus_color :,if App . get_running_app ( ) :,0.02547891297464453,5.300156689756295,0.37777777777777777
"def __init__(self, *args, **kwargs):<tab>BaseCellExporter.__init__(self, *args, **kwargs)<tab>self.comment = ""#""<tab>for key in [""cell_marker""]:<tab><tab><IF-STMT><tab><tab><tab>self.metadata[key] = self.unfiltered_metadata[key]<tab>if self.fmt.get(""rst2md""):<tab><tab>raise ValueError(<tab><tab><tab>""The 'rst2md' option is a read only option. The reverse conversion is not ""<tab><tab><tab>""implemented. Please either deactivate the option, or save to another format.""<tab><tab>)  # pragma: no cover",1,if key in self . unfiltered_metadata :,if key in self . unfiltered_metadata :,0.75,100.00000000000004,1.0
"def sendQueryQueueByAfterNate(self):<tab>for i in range(10):<tab><tab>queryQueueByAfterNateRsp = self.session.httpClint.send(urls.get(""queryQueue""))<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>"""".join(queryQueueByAfterNateRsp.get(""messages""))<tab><tab><tab><tab>or queryQueueByAfterNateRsp.get(""validateMessages"")<tab><tab><tab>)<tab><tab><tab>time.sleep(1)<tab><tab>else:<tab><tab><tab>sendEmail(ticket.WAIT_ORDER_SUCCESS)<tab><tab><tab>sendServerChan(ticket.WAIT_ORDER_SUCCESS)<tab><tab><tab>raise ticketIsExitsException(ticket.WAIT_AFTER_NATE_SUCCESS)",0,"if not queryQueueByAfterNateRsp . get ( ""status"" ) :","if queryQueueByAfterNateRsp . get ( ""messages"" ) :",0.1884566599936256,48.959148327580515,0.38181818181818183
"def filter_errors(self, errors: List[str]) -> List[str]:<tab>real_errors: List[str] = list()<tab>current_file = __file__<tab>current_path = os.path.split(current_file)<tab>for line in errors:<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>fn, lno, lvl, msg = self.parse_trace_line(line)<tab><tab>if fn is not None:<tab><tab><tab>_path = os.path.split(fn)<tab><tab><tab>if _path[-1] != current_path[-1]:<tab><tab><tab><tab>continue<tab><tab>real_errors.append(line)<tab>return real_errors",1,if not line :,if not line :,0.75,100.00000000000004,1.0
"def pretty(self, n, comment=True):<tab>if isinstance(n, (str, bytes, list, tuple, dict)):<tab><tab>r = repr(n)<tab><tab>if not comment:  # then it can be inside a comment!<tab><tab><tab>r = r.replace(""*/"", r""\x2a/"")<tab><tab>return r<tab>if not isinstance(n, six.integer_types):<tab><tab>return n<tab>if isinstance(n, constants.Constant):<tab><tab><IF-STMT><tab><tab><tab>return ""%s /* %s */"" % (n, self.pretty(int(n)))<tab><tab>else:<tab><tab><tab>return ""%s (%s)"" % (n, self.pretty(int(n)))<tab>elif abs(n) < 10:<tab><tab>return str(n)<tab>else:<tab><tab>return hex(n)",0,if comment :,if abs ( n ) < 10 :,0.04422835593777517,1e-10,0.3
"def get_pricings(self, subscription_id: str):<tab>try:<tab><tab>client = self.get_client(subscription_id)<tab><tab>pricings_list = await run_concurrently(lambda: client.pricings.list())<tab><tab><IF-STMT><tab><tab><tab>return pricings_list.value<tab><tab>else:<tab><tab><tab>return []<tab>except Exception as e:<tab><tab>print_exception(f""Failed to retrieve pricings: {e}"")<tab><tab>return []",0,"if hasattr ( pricings_list , ""value"" ) :",if pricings_list . done ( ) :,0.03836215687039321,17.39350277271197,0.5
"def add_doc(target, variables, body_lines):<tab>if isinstance(target, ast.Name):<tab><tab># if it is a variable name add it to the doc<tab><tab>name = target.id<tab><tab>if name not in variables:<tab><tab><tab>doc = find_doc_for(target, body_lines)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>variables[name] = doc<tab>elif isinstance(target, ast.Tuple):<tab><tab># if it is a tuple then iterate the elements<tab><tab># this can happen like this:<tab><tab># a, b = 1, 2<tab><tab>for e in target.elts:<tab><tab><tab>add_doc(e, variables, body_lines)",1,if doc is not None :,if doc is not None :,0.75,100.00000000000004,1.0
"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab>if left == 0:<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[left - 1]):<tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab><IF-STMT><tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[right]):<tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",0,if right == len ( text ) :,if self . word_boundary_char ( text [ right ] ) :,0.039193953350871544,8.225964699966553,0.3333333333333333
"def pxrun_nodes(self, *args, **kwargs):<tab>cell = self._px_cell<tab>if re.search(r""^\s*%autopx\b"", cell):<tab><tab>self._disable_autopx()<tab><tab>return False<tab>else:<tab><tab>try:<tab><tab><tab>result = self.view.execute(cell, silent=False, block=False)<tab><tab>except:<tab><tab><tab>self.shell.showtraceback()<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>result.get()<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>self.shell.showtraceback()<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>result.display_outputs()<tab><tab><tab>return False",0,if self . view . block :,if result :,0.020447728119319098,1e-10,0.2916666666666667
"def candidates() -> Generator[""Symbol"", None, None]:<tab>s = self<tab>if Symbol.debug_lookup:<tab><tab>Symbol.debug_print(""searching in self:"")<tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")<tab>while True:<tab><tab>if matchSelf:<tab><tab><tab>yield s<tab><tab>if recurseInAnon:<tab><tab><tab>yield from s.children_recurse_anon<tab><tab>else:<tab><tab><tab>yield from s._children<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>s = s.siblingAbove<tab><tab>if Symbol.debug_lookup:<tab><tab><tab>Symbol.debug_print(""searching in sibling:"")<tab><tab><tab>print(s.to_string(Symbol.debug_indent + 1), end="""")",1,if s . siblingAbove is None :,if s . siblingAbove is None :,0.75,100.00000000000004,1.0
"def decTaskGen():<tab>cnt = intbv(0, min=-n, max=n)<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>cnt[:] = 0<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab># print count<tab><tab><tab>decTaskFunc(cnt, enable, reset, n)<tab><tab><tab>count.next = cnt",1,if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,0.75,100.00000000000004,1.0
"def __call__(self, *args, **kwargs):<tab>if not NET_INITTED:<tab><tab>return self.raw(*args, **kwargs)<tab>for stack in traceback.walk_stack(None):<tab><tab><IF-STMT><tab><tab><tab>layer = stack[0].f_locals[""self""]<tab><tab><tab>if layer in layer_names:<tab><tab><tab><tab>log.pytorch_layer_name = layer_names[layer]<tab><tab><tab><tab>print(layer_names[layer])<tab><tab><tab><tab>break<tab>out = self.obj(self.raw, *args, **kwargs)<tab># if isinstance(out,Variable):<tab>#<tab> out=[out]<tab>return out",0,"if ""self"" in stack [ 0 ] . f_locals :",if stack :,0.011515134196748902,1e-10,0.37142857142857144
"def to_json_dict(self):<tab>d = super().to_json_dict()<tab>d[""bullet_list""] = RenderedContent.rendered_content_list_to_json(self.bullet_list)<tab>if self.header is not None:<tab><tab>if isinstance(self.header, RenderedContent):<tab><tab><tab>d[""header""] = self.header.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""header""] = self.header<tab>if self.subheader is not None:<tab><tab><IF-STMT><tab><tab><tab>d[""subheader""] = self.subheader.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""subheader""] = self.subheader<tab>return d",1,"if isinstance ( self . subheader , RenderedContent ) :","if isinstance ( self . subheader , RenderedContent ) :",0.75,100.00000000000004,1.0
"def add(request):<tab>form_type = ""servers""<tab>if request.method == ""POST"":<tab><tab>form = BookMarkForm(request.POST)<tab><tab><IF-STMT><tab><tab><tab>form_type = form.save()<tab><tab><tab>messages.add_message(request, messages.INFO, ""Bookmark created"")<tab><tab>else:<tab><tab><tab>messages.add_message(request, messages.INFO, form.errors)<tab><tab>if form_type == ""server"":<tab><tab><tab>url = reverse(""servers"")<tab><tab>else:<tab><tab><tab>url = reverse(""metrics"")<tab><tab>return redirect(url)<tab>else:<tab><tab>return redirect(reverse(""servers""))",1,if form . is_valid ( ) :,if form . is_valid ( ) :,0.75,100.00000000000004,1.0
"def fee_amount_in_quote(self, trading_pair: str, price: Decimal, order_amount: Decimal):<tab>fee_amount = Decimal(""0"")<tab>if self.percent > 0:<tab><tab>fee_amount = (price * order_amount) * self.percent<tab>base, quote = trading_pair.split(""-"")<tab>for flat_fee in self.flat_fees:<tab><tab>if interchangeable(flat_fee[0], base):<tab><tab><tab>fee_amount += flat_fee[1] * price<tab><tab><IF-STMT><tab><tab><tab>fee_amount += flat_fee[1]<tab>return fee_amount",1,"elif interchangeable ( flat_fee [ 0 ] , quote ) :","elif interchangeable ( flat_fee [ 0 ] , quote ) :",0.75,100.00000000000004,1.0
"def load_batch(fpath):<tab>with open(fpath, ""rb"") as f:<tab><tab><IF-STMT><tab><tab><tab># Python3<tab><tab><tab>d = pickle.load(f, encoding=""latin1"")<tab><tab>else:<tab><tab><tab># Python2<tab><tab><tab>d = pickle.load(f)<tab>data = d[""data""]<tab>labels = d[""labels""]<tab>return data, labels",0,"if sys . version_info > ( 3 , 0 ) :","if sys . version_info < ( 3 , 0 ) :",0.6020019333126669,76.11606003349888,1.0
"def clear_entries(options):<tab>""""""Clear pending entries""""""<tab>with Session() as session:<tab><tab>query = session.query(db.PendingEntry).filter(db.PendingEntry.approved == False)<tab><tab><IF-STMT><tab><tab><tab>query = query.filter(db.PendingEntry.task_name == options.task_name)<tab><tab>deleted = query.delete()<tab><tab>console(""Successfully deleted %i pending entries"" % deleted)",1,if options . task_name :,if options . task_name :,0.75,100.00000000000004,1.0
"def attribute_table(self, attribute):<tab>""""""Return a tuple (schema, table) for attribute.""""""<tab>dimension = attribute.dimension<tab>if dimension:<tab><tab>schema = self.naming.dimension_schema or self.naming.schema<tab><tab><IF-STMT><tab><tab><tab>table = self.fact_name<tab><tab>else:<tab><tab><tab>table = self.naming.dimension_table_name(dimension)<tab>else:<tab><tab>table = self.fact_name<tab><tab>schema = self.naming.schema<tab>return (schema, table)",0,if dimension . is_flat and not dimension . has_details :,"if dimension == ""fact"" :",0.025595153496315533,5.773772066582297,0.4871794871794872
"def remove_rating(self, songs, librarian):<tab>count = len(songs)<tab>if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""):<tab><tab>parent = qltk.get_menu_item_top_parent(self)<tab><tab>dialog = ConfirmRateMultipleDialog(parent, _(""_Remove Rating""), count, None)<tab><tab>if dialog.run() != Gtk.ResponseType.YES:<tab><tab><tab>return<tab>reset = []<tab>for song in songs:<tab><tab><IF-STMT><tab><tab><tab>del song[""~#rating""]<tab><tab><tab>reset.append(song)<tab>librarian.changed(reset)",0,"if ""~#rating"" in song :","if ""#rating"" in song :",0.39477865547525276,67.5291821812656,1.0
"def find_word_bounds(self, text, index, allowed_chars):<tab>right = left = index<tab>done = False<tab>while not done:<tab><tab>if left == 0:<tab><tab><tab>done = True<tab><tab>elif not self.word_boundary_char(text[left - 1]):<tab><tab><tab>left -= 1<tab><tab>else:<tab><tab><tab>done = True<tab>done = False<tab>while not done:<tab><tab>if right == len(text):<tab><tab><tab>done = True<tab><tab><IF-STMT><tab><tab><tab>right += 1<tab><tab>else:<tab><tab><tab>done = True<tab>return left, right",0,elif not self . word_boundary_char ( text [ right ] ) :,elif self . word_boundary_char ( text [ right + 1 ] ) in allowed_chars :,0.3021312303806978,53.627217165241866,0.24342105263157893
"def handle_read(self):<tab>""""""Called when there is data waiting to be read.""""""<tab>try:<tab><tab>chunk = self.recv(self.ac_in_buffer_size)<tab>except RetryError:<tab><tab>pass<tab>except socket.error:<tab><tab>self.handle_error()<tab>else:<tab><tab>self.tot_bytes_received += len(chunk)<tab><tab>if not chunk:<tab><tab><tab>self.transfer_finished = True<tab><tab><tab># self.close()  # <-- asyncore.recv() already do that...<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>chunk = self._data_wrapper(chunk)<tab><tab>try:<tab><tab><tab>self.file_obj.write(chunk)<tab><tab>except OSError as err:<tab><tab><tab>raise _FileReadWriteError(err)",0,if self . _data_wrapper is not None :,if self . _data_wrapper :,0.2343345094426703,59.755798910891144,0.4444444444444444
"def toggle(self, event=None):<tab>if self.absolute:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 100<tab><tab>if self.split > 20:<tab><tab><tab>self.save = self.split<tab><tab><tab>self.split = 1<tab><tab>else:<tab><tab><tab>self.split = self.save<tab>else:<tab><tab>if self.save == self.split:<tab><tab><tab>self.save = 0.3<tab><tab>if self.split <= self.min or self.split >= self.max:<tab><tab><tab>self.split = self.save<tab><tab><IF-STMT><tab><tab><tab>self.split = self.min<tab><tab>else:<tab><tab><tab>self.split = self.max<tab>self.placeChilds()",0,elif self . split < 0.5 :,elif self . split < self . min :,0.2776492154722404,46.713797772819994,0.6933333333333334
"def readAtOffset(self, offset, size, shortok=False):<tab>ret = b""""<tab>self.fd.seek(offset)<tab>while len(ret) != size:<tab><tab>rlen = size - len(ret)<tab><tab>x = self.fd.read(rlen)<tab><tab>if x == b"""":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return None<tab><tab><tab>return ret<tab><tab>ret += x<tab>return ret",0,if not shortok :,if shortok :,0.09648852821835877,1e-10,0.41666666666666663
"def webfinger(environ, start_response, _):<tab>query = parse_qs(environ[""QUERY_STRING""])<tab>try:<tab><tab>rel = query[""rel""]<tab><tab>resource = query[""resource""][0]<tab>except KeyError:<tab><tab>resp = BadRequest(""Missing parameter in request"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>resp = BadRequest(""Bad issuer in request"")<tab><tab>else:<tab><tab><tab>wf = WebFinger()<tab><tab><tab>resp = Response(wf.response(subject=resource, base=OAS.baseurl))<tab>return resp(environ, start_response)",0,if rel != [ OIC_ISSUER ] :,"if rel != ""issuer"" :",0.09453229110448028,28.46946938149361,1.0
"def _tokenize(self, text):<tab>if format_text(text) == EMPTY_TEXT:<tab><tab>return [self.additional_special_tokens[0]]<tab>split_tokens = []<tab>if self.do_basic_tokenize:<tab><tab>for token in self.basic_tokenizer.tokenize(<tab><tab><tab>text, never_split=self.all_special_tokens<tab><tab>):<tab><tab><tab># If the token is part of the never_split set<tab><tab><tab><IF-STMT><tab><tab><tab><tab>split_tokens.append(token)<tab><tab><tab>else:<tab><tab><tab><tab>split_tokens += self.wordpiece_tokenizer.tokenize(token)<tab>else:<tab><tab>split_tokens = self.wordpiece_tokenizer.tokenize(text)<tab>return split_tokens",1,if token in self . basic_tokenizer . never_split :,if token in self . basic_tokenizer . never_split :,0.75,100.00000000000004,1.0
"def send_packed_command(self, command, check_health=True):<tab>if not self._sock:<tab><tab>self.connect()<tab>try:<tab><tab>if isinstance(command, str):<tab><tab><tab>command = [command]<tab><tab>for item in command:<tab><tab><tab>self._sock.sendall(item)<tab>except socket.error as e:<tab><tab>self.disconnect()<tab><tab><IF-STMT><tab><tab><tab>_errno, errmsg = ""UNKNOWN"", e.args[0]<tab><tab>else:<tab><tab><tab>_errno, errmsg = e.args<tab><tab>raise ConnectionError(<tab><tab><tab>""Error %s while writing to socket. %s."" % (_errno, errmsg)<tab><tab>)<tab>except Exception:<tab><tab>self.disconnect()<tab><tab>raise",0,if len ( e . args ) == 1 :,if check_health :,0.010867398423934471,1e-10,0.28571428571428575
"def to_value(self, value):<tab># Tip: 'value' is the object returned by<tab>#<tab>  taiga.projects.history.models.HistoryEntry.values_diff()<tab>ret = {}<tab>for key, val in value.items():<tab><tab>if key in [""attachments"", ""custom_attributes"", ""description_diff""]:<tab><tab><tab>ret[key] = val<tab><tab><IF-STMT><tab><tab><tab>ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()}<tab><tab>else:<tab><tab><tab>ret[key] = {""from"": val[0], ""to"": val[1]}<tab>return ret",0,"elif key == ""points"" :","elif isinstance ( val , dict ) :",0.024231488401191333,6.567274736060395,0.3
"def to_child(cls, key=None, process=None):<tab>if process is not None:<tab><tab>if type(process) is not dict:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>'Invalid value provided for ""process"" parameter, expected a dictionary'<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab># Merge class `__process__` parameters with provided parameters<tab><tab><tab>result = {}<tab><tab><tab>result.update(deepcopy(cls.__process__))<tab><tab><tab>result.update(process)<tab><tab><tab>process = result<tab>class Child(cls):<tab><tab>__key__ = key<tab><tab>__process__ = process<tab><tab>__root__ = False<tab>Child.__name__ = cls.__name__<tab>return Child",0,if cls . __process__ :,"if hasattr ( cls , ""__process__"" ) :",0.028001459970687266,29.89950354998137,0.4772727272727273
"def _super_function(args):<tab>passed_class, passed_self = args.get_arguments([""type"", ""self""])<tab>if passed_self is None:<tab><tab>return passed_class<tab>else:<tab><tab># pyclass = passed_self.get_type()<tab><tab>pyclass = passed_class<tab><tab><IF-STMT><tab><tab><tab>supers = pyclass.get_superclasses()<tab><tab><tab>if supers:<tab><tab><tab><tab>return pyobjects.PyObject(supers[0])<tab><tab>return passed_self",0,"if isinstance ( pyclass , pyobjects . AbstractClass ) :",if pyclass is not None :,0.01478624383023101,5.484411595600381,0.2222222222222222
"def get_data(row):<tab>data = []<tab>for field_name, field_xpath in fields:<tab><tab>result = row.xpath(field_xpath)<tab><tab><IF-STMT><tab><tab><tab>result = "" "".join(<tab><tab><tab><tab>text<tab><tab><tab><tab>for text in map(<tab><tab><tab><tab><tab>six.text_type.strip, map(six.text_type, map(unescape, result))<tab><tab><tab><tab>)<tab><tab><tab><tab>if text<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>result = None<tab><tab>data.append(result)<tab>return data",1,if result :,if result :,0.5311706625951745,1e-10,1.0
"def say(jarvis, s):<tab>""""""Reads what is typed.""""""<tab>if not s:<tab><tab>jarvis.say(""What should I say?"")<tab>else:<tab><tab>voice_state = jarvis.is_voice_enabled()<tab><tab>jarvis.enable_voice()<tab><tab>jarvis.say(s)<tab><tab><IF-STMT><tab><tab><tab>jarvis.disable_voice()",0,if not voice_state :,if voice_state :,0.09648852821835877,1e-10,0.6
"def __import__(name, globals=None, locals=None, fromlist=(), level=0):<tab>module = orig___import__(name, globals, locals, fromlist, level)<tab>if fromlist and module.__name__ in modules:<tab><tab><IF-STMT><tab><tab><tab>fromlist = list(fromlist)<tab><tab><tab>fromlist.remove(""*"")<tab><tab><tab>fromlist.extend(getattr(module, ""__all__"", []))<tab><tab>for x in fromlist:<tab><tab><tab>if isinstance(getattr(module, x, None), types.ModuleType):<tab><tab><tab><tab>from_name = ""{}.{}"".format(module.__name__, x)<tab><tab><tab><tab>if from_name in modules:<tab><tab><tab><tab><tab>importlib.import_module(from_name)<tab>return module",1,"if ""*"" in fromlist :","if ""*"" in fromlist :",0.75,100.00000000000004,1.0
"def _read_pricing_file(self, region=None, pricing_file=None):<tab>if not self.__pricing_file_cache:<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Reading pricing file..."")<tab><tab><tab>with open(pricing_file) as data_file:<tab><tab><tab><tab>self.__pricing_file_cache = json.load(data_file)<tab><tab>else:<tab><tab><tab>self.__pricing_file_cache = self._download_pricing_file(region)<tab>return self.__pricing_file_cache",1,if pricing_file :,if pricing_file :,0.5311706625951745,1e-10,1.0
